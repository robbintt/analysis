---
ver: rpa2
title: 'Dirichlet-Prior Shaping: Guiding Expert Specialization in Upcycled MoEs'
arxiv_id: '2510.01185'
source_url: https://arxiv.org/abs/2510.01185
tags:
- expert
- experts
- dpsl
- training
- upcycling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses poor expert specialization in upcycled Mixture-of-Experts
  (MoE) vision-language models caused by naive weight replication during sparse upcycling.
  The authors introduce Dirichlet-Prior Shaping Loss (DPSL), a router regularization
  technique that shapes routing probability distributions by matching them to target
  Dirichlet priors, enabling fine-grained control over expert balance and specialization.
---

# Dirichlet-Prior Shaping: Guiding Expert Specialization in Upcycled MoEs

## Quick Facts
- arXiv ID: 2510.01185
- Source URL: https://arxiv.org/abs/2510.01185
- Reference count: 40
- Primary result: DPSL improves expert specialization in upcycled MoEs, achieving 35.92 average accuracy on Llama3.2-1B vs 34.19 dense baseline

## Executive Summary
This paper addresses the problem of poor expert specialization in upcycled Mixture-of-Experts (MoE) vision-language models caused by naive weight replication during sparse upcycling. The authors introduce Dirichlet-Prior Shaping Loss (DPSL), a router regularization technique that shapes routing probability distributions by matching them to target Dirichlet priors, enabling fine-grained control over expert balance and specialization. DPSL allows encoding of inductive biases (e.g., modality-specific or task-specific specialization) without manual intervention and applies broadly to any module outputting categorical distributions. Experiments on upcycled MoE models (Qwen2-1.5B, Phi3-mini 3.8B, Llama3.2-1B) show DPSL consistently outperforms existing upcycling strategies and regularization techniques across standard vision-language benchmarks.

## Method Summary
DPSL computes the squared difference between empirical CDF of router probabilities (from router outputs across a batch) and theoretical Beta CDF for each expert, with the loss applied only during the warm-up phase of training. The method shapes the full distribution of routing probabilities rather than just the mean, pulling them toward desired shapes based on concentration parameter α. For symmetric priors, α controls the spread of marginal Betas (lower α → sparser, corner-biased routing; higher α → uniform, center-biased). Asymmetric priors encode inductive biases by assigning different α values per expert. The loss is scaled by weight λ=0.01 and applied to router outputs during warm-up only, after which the model fine-tunes without regularization to avoid constraining final specialization.

## Key Results
- On Llama3.2-1B with 4 experts and top-2 routing, DPSL achieves 35.92 average accuracy versus 34.19 for the dense baseline
- DPSL produces broader routing distributions compared to methods producing low-confidence, peaked distributions near uniform selection
- Optimal performance achieved at concentration parameter α=0.75 for Llama3.2-1B and α=1.0 for larger models
- DPSL outperforms existing upcycling strategies (Drop-Upcycling, DeRS) and routing regularizations (z-loss, load-balancing)

## Why This Works (Mechanism)

### Mechanism 1: Distribution Shaping via Beta Matching
DPSL computes squared CDF differences between empirical router probabilities and target Beta marginals, forcing routers to develop confident, differentiated expert assignments. By shaping the full distribution profile rather than just means, DPSL spreads probabilities away from uniform centers toward confident corners or controlled spreads depending on α. This distributional pressure creates differentiation signals that guide expert divergence during fine-tuning. The method is most effective when router outputs are initially homogeneous (as in naive upcycling), though gains may diminish if experts are already well-differentiated or if λ/α are poorly tuned.

### Mechanism 2: Symmetric vs. Asymmetric Priors Encode Inductive Biases
Dirichlet concentration parameters provide a single knob to trade off balanced utilization vs. targeted specialization. Symmetric α encourages balanced load across experts, while asymmetric α biases certain experts toward higher probabilities for specific data sources (e.g., vision vs. language tokens), encoding modality-aware priors. The method is robust when domain structure aligns with prior specification, but mis-specified asymmetric priors can degrade performance if the assumed structure doesn't match data characteristics.

### Mechanism 3: Overcoming Upcycling Homogeneity via Router Pressure
DPSL counteracts the naive upcycling problem where identical expert initialization yields weak routing differentiation. In naive upcycling, all experts start as FFN replicas with no signal for the router to differentiate them, leading to low-confidence routing clustered near uniform. DPSL applies external distributional pressure, forcing the router to spread its outputs and thereby create differentiation signals that guide expert divergence during fine-tuning. This is complementary to diversity-enhancing initialization techniques and may be less effective if training budget is too short for meaningful expert divergence.

## Foundational Learning

- **Dirichlet Distribution & Beta Marginals**
  - Why needed here: DPSL relies on the property that each component pk of a Dirichlet random vector follows a Beta(αk, A−αk) distribution; understanding this is essential to set priors meaningfully
  - Quick check question: Given α = (2, 2, 2) for 3 experts, what shape do you expect each marginal Beta to have, and how does it change if α = (0.5, 0.5, 0.5)?

- **Cramér–von Mises Criterion**
  - Why needed here: DPSL adapts this statistical distance (squared CDF difference) to match empirical router distributions to target Betas; understanding CDF-based losses clarifies why DPSL shapes full distributions rather than just means
  - Quick check question: Why match CDFs rather than compare means or variances directly for controlling routing behavior?

- **Mixture-of-Experts (MoE) Routing & Upcycling**
  - Why needed here: The method targets upcycled MoEs where experts are initialized from identical FFN weights; you need to understand top-K routing, load balancing, and the upcycling setup to grasp why specialization fails and how DPSL intervenes
  - Quick check question: In naive upcycling with 4 experts and top-2 routing, why might router probabilities cluster near 0.25 for each expert at initialization?

## Architecture Onboarding

- **Component map:**
  MoE Layer: Router (learned gating network) + N expert FFNs (+ optional shared expert) -> DPSL Module: Computes empirical CDF of router probabilities per expert across batch tokens, compares to target Beta CDF, returns scalar loss per layer -> Training Loop: Standard cross-entropy + DPSL (scaled by λ) applied during warm-up phase only

- **Critical path:**
  1. Collect router probabilities g_i(t) for all tokens in batch (B = S × T tokens)
  2. For each expert k, sort probabilities and compute empirical CDF
  3. Compute target Beta CDF for given αk, A = Σαk
  4. Sum squared CDF differences per expert (Eq. 4); scale by λ
  5. Backprop through router only (experts unaffected by DPSL directly)

- **Design tradeoffs:**
  - α selection: Lower α → sparser, corner-biased routing; higher α → uniform, center-biased. Paper finds optimal α = 0.75–1.5 depending on backbone (Tables 4–5)
  - λ strength: λ = 0.01 works best (Table 7); too low → weak shaping; too high → over-regularization, reduced accuracy
  - Application timing: DPSL applied only during warm-up (Phase II); removed during fine-tuning to avoid constraining final specialization
  - Symmetric vs. asymmetric priors: Symmetric is robust default; asymmetric useful only if domain structure (modality/task) is known and well-defined

- **Failure signatures:**
  - Router probabilities remain clustered near 1/N despite DPSL → λ too low or batch too small for stable CDF estimation
  - Expert collapse (one expert dominates) → asymmetric prior mis-specified or λ too high
  - Training instability → λ > 0.1 or conflicting regularization (e.g., strong z-loss + DPSL)
  - No performance gain over dense baseline → upcycling not beneficial for task scale, or warm-up phase too short

- **First 3 experiments:**
  1. **Baseline sanity check:** Upcycle a small backbone (e.g., Llama3.2-1B) with 4 experts, top-2 routing. Compare: (a) no regularization, (b) load-balancing, (c) DPSL with symmetric α = 1.0, λ = 0.01. Measure routing distribution spread and downstream accuracy on 2–3 benchmarks
  2. **α sensitivity sweep:** Fix λ = 0.01, vary α ∈ {0.5, 0.75, 1.0, 1.25, 1.5}. Plot routing score histograms and accuracy. Confirm paper finding that smaller models prefer lower α
  3. **Modality-aware prior test:** Use a VLM with clear vision/language token separation. Compare symmetric α vs. modality-conditional asymmetric priors (as in Table 2). Verify that asymmetric priors improve metrics without manual hard-routing

## Open Questions the Paper Calls Out

- **Does DPSL provide similar benefits when training MoEs from scratch compared to upcycled MoE training?**
  - Basis: "While this work focused on upcycled MoEs, the principles of DPSL extend naturally to training MoEs from scratch..."
  - Why unresolved: Only evaluated on upcycled MoEs initialized from dense checkpoints; experiments on randomly initialized MoE training are not conducted
  - What evidence would resolve it: Comparative experiments training MoEs with and without DPSL from random initialization, measuring downstream task performance and routing distribution characteristics

- **How does DPSL perform on modules beyond MoE routers that output categorical distributions?**
  - Basis: "DPSL is a general tool applicable to any module that outputs categorical probability distributions, extending its utility beyond MoE training."
  - Why unresolved: No experiments are conducted on non-MoE applications (e.g., attention distributions, classification heads) to validate this broader claim
  - What evidence would resolve it: Application of DPSL to other categorical outputs (e.g., multi-head attention weights, multi-class classification layers) with performance comparisons to standard training

- **Can asymmetric priors be systematically designed to outperform symmetric priors for specific domain structures?**
  - Basis: Task-specific priors underperformed symmetric priors, "possibly due to nonoptimal data subsets or over-constraining experts"—suggesting the prior design space remains poorly understood
  - Why unresolved: The paper tests limited asymmetric configurations; it is unclear whether better prior designs could unlock stronger specialization benefits
  - What evidence would resolve it: Systematic search or optimization over prior configurations with automated alignment to data structure, comparing against symmetric baselines

- **How robust are the reported DPSL improvements across random seeds and training variability?**
  - Basis: "a primary limitation of our work is the inability to perform multiple seeds across the full matrix of backbones, granularities, and priors due to the expense of upcycled MoE training."
  - Why unresolved: Single-seed experiments cannot establish statistical significance or characterize variance in improvements
  - What evidence would resolve it: Multi-seed runs across key configurations with statistical tests confirming improvements are significant and consistent

## Limitations
- The causal mechanism linking CDF matching to expert specialization remains correlative rather than mechanistically proven
- Asymmetric prior benefits depend heavily on correctly identifying domain structure (modality/task separation)
- Optimal α range (0.75-1.0 for smaller models) appears sensitive to backbone and task, suggesting limited transferability without additional tuning
- The method's robustness to adversarial or out-of-distribution inputs is not evaluated

## Confidence
- **High Confidence:** DPSL effectively shapes routing distributions away from uniform clustering and improves average accuracy across multiple upcycled MoE backbones and benchmarks
- **Medium Confidence:** DPSL's superiority over existing upcycling strategies and routing regularizations is well-established for tested configurations, though optimal values appear backbone-specific
- **Low Confidence:** Long-term stability of DPSL-induced specialization beyond warm-up phase is not evaluated; behavior under extreme sparsity or heterogeneous initialization is unexplored; theoretical guarantees are not formally established

## Next Checks
1. **Expert Weight Divergence Analysis:** Track and visualize expert FFN weight L2 distances during training with and without DPSL. Confirm that DPSL's routing pressure directly causes expert specialization rather than merely correlating with it
2. **Adversarial Routing Robustness:** Generate adversarial token sequences designed to fool the router into uniform selection. Test whether DPSL models maintain confident routing and performance under such attacks, comparing to baseline upcycling methods
3. **Cross-Domain Transferability:** Apply a DPSL-trained MoE model (optimized for LLaVA-style tasks with α=0.75) to a non-VLM domain (e.g., code generation or mathematical reasoning). Measure routing confidence and performance degradation to assess sensitivity to prior specification