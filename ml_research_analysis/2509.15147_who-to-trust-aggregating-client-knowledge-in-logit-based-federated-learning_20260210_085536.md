---
ver: rpa2
title: Who to Trust? Aggregating Client Knowledge in Logit-Based Federated Learning
arxiv_id: '2509.15147'
source_url: https://arxiv.org/abs/2509.15147
tags:
- client
- learning
- federated
- clients
- aggregation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes logit-based federated learning to reduce communication
  costs by exchanging only model logits on a shared public dataset instead of gradients
  or weights. Three aggregation strategies are introduced: simple averaging, uncertainty-weighted
  averaging (UWA) using Gaussian mixture models to model client-specific logit distributions,
  and a learned meta-model aggregator.'
---

# Who to Trust? Aggregating Client Knowledge in Logit-Based Federated Learning

## Quick Facts
- arXiv ID: 2509.15147
- Source URL: https://arxiv.org/abs/2509.15147
- Reference count: 22
- Key result: Logit-based FL with meta-model aggregator achieves 0.9597 accuracy on MNIST (2 classes/client) vs 0.8188 with simple averaging

## Executive Summary
This paper introduces logit-based federated learning to reduce communication costs by exchanging only model logits on a shared public dataset instead of gradients or weights. Three aggregation strategies are proposed: simple averaging, uncertainty-weighted averaging (UWA) using Gaussian mixture models, and a learned meta-model aggregator. Evaluated on MNIST and CIFAR-10 with non-IID data (2, 5, or 8 classes per client), the methods show improved accuracy over simple averaging, especially under high heterogeneity.

## Method Summary
The approach exchanges logits computed on a shared public proxy dataset rather than model parameters. Clients train locally on private data, compute logits on the public dataset, and upload these to the server. The server aggregates logits using one of three strategies: simple averaging, uncertainty-weighted averaging via client-specific GMMs, or a learned meta-model. The aggregated logits are then used as soft targets for local refinement. This reduces communication costs while maintaining competitive accuracy.

## Key Results
- UWA improves accuracy significantly under high heterogeneity (0.8188 → 0.9454 on MNIST with 2 classes/client)
- Meta-model aggregator consistently yields best results across all conditions (0.9597 on MNIST with 2 classes/client)
- All methods reduce communication overhead compared to traditional FedAvg
- Performance degrades gracefully as heterogeneity decreases (k increases from 2 to 8 classes/client)

## Why This Works (Mechanism)

### Mechanism 1: Logit-Based Knowledge Transfer via Public Proxy Dataset
Exchanging logits on a shared unlabeled public dataset enables knowledge transfer without transmitting model parameters, reducing communication costs while maintaining competitive accuracy. Each client trains locally on private data, then computes logits on the shared public dataset. These logits are aggregated server-side and returned as soft targets for local refinement.

### Mechanism 2: Uncertainty-Weighted Averaging (UWA) via Client-Specific Logit Distributions
Weighting client logits by their confidence (log-likelihood under client-specific GMM distributions) improves aggregation under high label-distribution shift by down-weighting clients unfamiliar with a given class. Each client fits a Gaussian Mixture Model to their logit distribution on a local validation set. For a test input, the log-likelihood under this GMM becomes a confidence score, normalized via softmax into aggregation weights.

### Mechanism 3: Meta-Model Aggregator Learning to Weight Clients
A learned aggregator (neural network or tree-based model) trained to map concatenated client logits to predicted labels can outperform fixed aggregation schemes by adaptively weighting clients per-input. Client logits are concatenated into a feature vector. An auxiliary model is trained on labeled data to predict y from this feature vector, learning which clients to trust for different inputs.

## Foundational Learning

- **Federated Averaging (FedAvg) and Non-IID Challenges**: FedAvg struggles under data heterogeneity when clients have different class distributions. Understanding this limitation motivates the logit-based approach. Quick check: Why does averaging model weights fail when clients have different class priors?

- **Knowledge Distillation and Soft Targets**: The method uses aggregated logits as "soft targets" for local refinement. Soft targets provide inter-class relationships and confidence information that hard labels do not. Quick check: What information do soft targets provide that hard labels do not?

- **Gaussian Mixture Models for Density Estimation**: UWA relies on fitting GMMs to logit distributions to estimate client confidence. Understanding GMM components, mean-field approximations, and log-likelihood computation is necessary. Quick check: Why might a diagonal covariance assumption fail for correlated logit dimensions?

## Architecture Onboarding

- **Component map**: Client nodes (local model f_i, private dataset D_i, GMM density estimator for UWA) -> Server (aggregation module, public dataset D_pub) -> Meta-model training pipeline (MM Aggregator only)

- **Critical path**: 1) Initialize client models (LeNet for MNIST, ResNet-18 for CIFAR-10) 2) Round 1: Train locally → compute logits on D_pub → aggregate → refine with soft targets 3) For UWA: Fit GMM on local validation logits before first aggregation 4) For MM Aggregator: Train meta-model on labeled subset before first aggregation 5) Repeat for R rounds (convergence typically within 10 rounds)

- **Design tradeoffs**:
  - Simple averaging: Zero overhead, poor under high heterogeneity
  - UWA: Moderate overhead (GMM fitting per client), robust to heterogeneity, handles client addition/removal gracefully
  - Meta-model: Highest accuracy, requires labeled data and retraining on client changes, highest computational cost

- **Failure signatures**:
  - Accuracy collapses near simple averaging baseline → UWA weights not differentiating; check GMM component separation
  - Meta-model overfits → insufficient labeled data; verify held-out validation
  - No improvement over rounds → public dataset lacks class coverage; audit D_pub composition
  - Client dropout causes crashes → MM Aggregator expects fixed M; implement padding or retraining

- **First 3 experiments**:
  1. Baseline replication: Run simple averaging on MNIST with k=2 classes/client; verify accuracy ~0.82 as reported
  2. UWA validation: Enable UWA, check that weights become non-uniform for k=2 (inspect weight distributions on D_pub samples)
  3. Ablation on public dataset size: Reduce D_pub from 5,000 to 1,000 images; observe accuracy degradation to quantify coverage sensitivity

## Open Questions the Paper Calls Out
None

## Limitations

- **Public dataset dependency**: The approach critically relies on the public proxy dataset containing representative samples from all classes. The paper does not validate robustness when class coverage is incomplete or biased.
- **GMM assumptions**: UWA assumes logit distributions can be modeled by class-conditional GMMs with diagonal covariance (mean-field). This may fail when logit dimensions are correlated or when client models produce non-Gaussian logit distributions.
- **Meta-model scalability**: The MM Aggregator concatenates all client logits into a single feature vector, requiring retraining when clients join/leave. This limits scalability and adaptability in dynamic federated settings.

## Confidence

- **High confidence**: The core observation that logit-based FL reduces communication costs while maintaining competitive accuracy is well-supported by experiments on MNIST and CIFAR-10 across multiple heterogeneity levels.
- **Medium confidence**: UWA improves accuracy under high heterogeneity by down-weighting uncertain clients. This is demonstrated empirically but relies on distributional assumptions that warrant deeper validation.
- **Medium confidence**: Meta-model aggregator achieves highest accuracy, but requires labeled data and retraining on topology changes, limiting practical applicability.
- **Low confidence**: Claims about robustness to varying client numbers and public dataset sizes are not empirically validated beyond the specific experimental conditions reported.

## Next Checks

1. **Public dataset coverage sensitivity**: Systematically vary the class composition and size of the public dataset to quantify the minimum coverage required for effective aggregation, especially under high heterogeneity (k=2 classes/client).

2. **GMM assumption validation**: Analyze the actual logit distributions on D_pub for different clients and heterogeneity levels. Test whether alternative density estimators (e.g., kernel density estimation, normalizing flows) outperform GMMs under various conditions.

3. **Dynamic client scenario testing**: Evaluate UWA and MM Aggregator performance when clients join/leave between rounds, measuring accuracy degradation and computational overhead for maintaining/updating the aggregation strategy.