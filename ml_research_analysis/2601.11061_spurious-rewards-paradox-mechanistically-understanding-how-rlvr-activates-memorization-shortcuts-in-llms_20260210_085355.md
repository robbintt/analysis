---
ver: rpa2
title: 'Spurious Rewards Paradox: Mechanistically Understanding How RLVR Activates
  Memorization Shortcuts in LLMs'
arxiv_id: '2601.11061'
source_url: https://arxiv.org/abs/2601.11061
tags:
- layers
- rlvr
- memorization
- spurious
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how spurious rewards in reinforcement learning
  with verifiable rewards (RLVR) can inadvertently activate memorization shortcuts
  in large language models, bypassing genuine reasoning. The authors identify a "Perplexity
  Paradox" where answer-token perplexity decreases while prompt-side coherence degrades,
  suggesting models are retrieving memorized solutions rather than reasoning.
---

# Spurious Rewards Paradox: Mechanistically Understanding How RLVR Activates Memorization Shortcuts in LLMs

## Quick Facts
- arXiv ID: 2601.11061
- Source URL: https://arxiv.org/abs/2601.11061
- Reference count: 14
- Primary result: RLVR with spurious rewards activates Anchor-Adapter circuit that retrieves memorized solutions, bypassing genuine reasoning

## Executive Summary
This paper investigates why spurious rewards in RLVR can paradoxically improve model performance, revealing that such optimization activates memorization shortcuts rather than genuine reasoning improvements. Through mechanistic analysis combining path patching, logit lens, JSD, and neural differential equations, the authors identify a specific Anchor-Adapter circuit: middle-layer MLPs (L18-20) trigger memorized answer retrieval while later layers (L21+) transform representations to accommodate shortcut signals. Crucially, they demonstrate bidirectional causal steering by scaling specific MLP keys, showing that manipulating these neurons can either amplify or suppress contamination-driven performance gains, providing both diagnostic tools and mitigation strategies for data contamination in RLVR-tuned models.

## Method Summary
The study analyzes Qwen2.5-Math-7B base and spurious RLVR checkpoints using perplexity divergence analysis, path patching (swapping MLP activations between leakage and stable samples), counterfactual JSD on MLP sub-components, logit lens token trajectory analysis, neural differential equations to identify bifurcation points, and neuron-level ablation. Key interventions include identifying task-relevant neurons via relevance scoring and applying multiplicative key scaling to demonstrate bidirectional steering effects. The methodology systematically traces how spurious rewards transform model behavior from reasoning to memorization through the identified Anchor-Adapter circuit.

## Key Results
- Perplexity Paradox: Answer-token perplexity decreases while prompt-token perplexity increases during spurious RLVR, indicating memorization shortcuts over reasoning
- Anchor-Adapter circuit: Functional anchor layers (L18-20) trigger memorization retrieval; structural adapter layers (L21+) transform representations to accommodate shortcut signals
- Bidirectional steering: Scaling MLP keys can either amplify (α > 1) or suppress (α < 1) contamination-driven performance gains
- Path Patching confirms: Patching L18-20 activations recovers accuracy; patching L21+ degrades performance, validating causal roles

## Why This Works (Mechanism)

### Mechanism 1: Perplexity Paradox as Memorization Signature
Spurious RLVR creates diagnostic divergence where answer-token perplexity decreases while prompt-side coherence degrades, indicating memorization shortcuts over genuine reasoning. The optimization trajectory sacrifices general language modeling coherence to strengthen direct prompt-to-answer mappings.

### Mechanism 2: Functional Anchor (L18-20) as Retrieval Trigger
Middle-layer MLPs act as causal decision points that trigger memorized answer retrieval. Path Patching shows patching these layers recovers accuracy; Logit Lens shows answer tokens first emerge at these layers.

### Mechanism 3: Structural Adapters (L21+) as Representation Transformers
Later layers undergo weight reorganization to propagate shortcut signals. JSD analysis shows Wup/Wgate divergence peaks at L21-22 then declines—indicating knowledge injection completion—while Wdown maintains high divergence, reflecting output-space reorientation.

## Foundational Learning

- **Path Patching / Activation Patching**: Causally identifies responsible layers by swapping activations between "leakage" and "stable" samples. Quick check: If you replace layer-L activations from a memorization sample into a reasoning sample, does output shift toward the memorized answer?

- **MLP as Key-Value Memory**: Understanding Anchor-Adapter circuit requires decomposing MLP sub-components (Wgate=selector, Wup=feature repository, Wdown=output projection). Quick check: Which sub-component's JSD peak indicates knowledge injection completion vs. ongoing transformation?

- **Residual Stream as Dynamical System**: NDE analysis treats layer-wise hidden states as continuous trajectories to mathematically identify bifurcation points. Quick check: At which layer does the trajectory for memorized samples diverge from reasoning samples (highest separation force)?

## Architecture Onboarding

- **Component map**: Prompt → Early layers (reasoning) → L18-20 anchor (trigger decision) → L21-22 adapter (feature-space rotation) → L23+ (answer injection) → Final logits

- **Critical path**: The model already contains contaminated data from pre-training; spurious RLVR merely activates latent retrieval pathways rather than learning new knowledge.

- **Design tradeoffs**: MLPs vs. Attention (paper shows MLPs are primary storage); Anchor vs. Adapter (anchor more critical but neither alone suffices); Steering direction (α > 1 amplifies contamination).

- **Failure signatures**: Perplexity divergence (answer↓, prompt↑) indicates shortcut formation; no L18-20 patching recovery peak → likely no contamination present; monotonic JSD increase (no peak-decline) → no structural adaptation occurred.

- **First 3 experiments**: 
  1. Run Partial Prompt Evaluation to verify whether your model has pre-existing knowledge of test samples before any RLVR.
  2. Apply Path Patching layer-by-layer comparing leakage vs. stable samples; identify where accuracy recovery peaks.
  3. Perform counterfactual JSD analysis on Wgate/Wup/Wdown to locate structural adaptation signature (peak-decline pattern).

## Open Questions the Paper Calls Out

### Open Question 1
Is the Anchor-Adapter circuit a universal mechanism for contamination retrieval, or is it specific to the Qwen architecture? The study analyzes existing contaminated models rather than inducing contamination in clean architectures to observe resulting circuits.

### Open Question 2
Can the formation of memorization shortcuts be prevented during RLVR training, rather than suppressed post-hoc? The proposed solution relies on post-training intervention; no methodology is proposed for regularizing formation during optimization.

### Open Question 3
Does the "Perplexity Paradox" generalize to non-mathematical domains like coding or general knowledge? While the mechanism is framed generally, the divergence signature is only validated on math reasoning tasks where answers are often discrete tokens.

## Limitations
- Anchor-Adapter circuit locations are architecture-specific (L18-20 for Qwen2.5-Math-7B); other models show different peak layers requiring validation sweeps
- Causal interpretation of Path Patching assumes stable samples represent "ground truth" reasoning rather than alternative shortcuts
- Perplexity increases could reflect distributional shifts in token frequencies during RLVR, not just reasoning loss

## Confidence
- **High**: Existence of spurious reward gains and general perplexity divergence pattern supported by multiple recent papers
- **Medium**: Specific Anchor-Adapter circuit identification relies on Qwen2.5-Math-7B-specific layer analysis
- **Low**: Bidirectional steering results depend critically on precise neuron identification

## Next Checks
1. **Layer Localization Sweep**: Run Path Patching across all layers on a different model family to verify whether anchor locations shift systematically with architecture depth
2. **Prompt-Answer Correlation Test**: Measure correlation between prompt-token and answer-token perplexity changes during RLVR training; if both decrease together, the memorization hypothesis is invalid
3. **Neuron Selection Robustness**: Test steering effectiveness using different neuron selection criteria to determine whether bidirectional effects depend on task-relevant neuron identification procedure