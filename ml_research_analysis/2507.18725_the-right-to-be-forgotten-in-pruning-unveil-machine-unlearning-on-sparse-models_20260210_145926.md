---
ver: rpa2
title: 'The Right to be Forgotten in Pruning: Unveil Machine Unlearning on Sparse
  Models'
arxiv_id: '2507.18725'
source_url: https://arxiv.org/abs/2507.18725
tags:
- un-pruning
- unlearning
- data
- pruning
- original
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces "un-pruning" as a novel approach to machine
  unlearning in sparse models, addressing the right to be forgotten by eliminating
  the impact of deleted data on the pruned topology. The method integrates any existing
  unlearning algorithm with a workflow that activates pruned parameters, estimates
  the influence of deleted data, and updates the model topology to align with retained
  data.
---

# The Right to be Forgotten in Pruning: Unveil Machine Unlearning in Sparse Models

## Quick Facts
- **arXiv ID:** 2507.18725
- **Source URL:** https://arxiv.org/abs/2507.18725
- **Reference count:** 40
- **Primary result:** Un-pruning achieves high structural similarity with retrained models while maintaining unlearning accuracy in sparse neural networks.

## Executive Summary
This paper introduces "un-pruning" as a novel approach to machine unlearning in sparse models, addressing the right to be forgotten by eliminating the impact of deleted data on the pruned topology. The method integrates any existing unlearning algorithm with a workflow that activates pruned parameters, estimates the influence of deleted data, and updates the model topology to align with retained data. Theoretically, the un-pruning error is upper-bounded and characterized by model sparsity. Empirically, the approach is validated across structured and unstructured sparse models, showing that un-pruning achieves high structural similarity (intersection over mask and union) with retrained models while maintaining unlearning accuracy. The paper also highlights the unreliability of Membership Inference Attack (MIA) for evaluating unlearning and proposes new metrics based on neural network representation similarity.

## Method Summary
The un-pruning method addresses machine unlearning in sparse models by integrating any existing unlearning algorithm into a specialized workflow. The approach works by re-initializing pruned parameters using their original initialization values, applying the unlearning algorithm on the dense model, updating the mask by activating top weights by magnitude, and finally pruning to the original sparsity level. The method theoretically bounds the un-pruning error and characterizes it by model sparsity. The approach is validated on various models (ResNet-18, ViT, AlexNet) across multiple datasets (CIFAR-10, FashionMNIST, ImageNet) and sparsity levels (30%, 40%, 60%, 90%, 95%).

## Key Results
- Un-pruning achieves high structural similarity (IoM and IoU metrics) with retrained models while maintaining unlearning accuracy
- The method works across both structured and unstructured sparse models at various sparsity levels
- MIA is shown to be unreliable for evaluating unlearning, with proposed metrics based on neural network representation similarity offering better evaluation

## Why This Works (Mechanism)
The un-pruning mechanism works by leveraging the original parameter initialization to reactivate pruned weights during the unlearning process. When data is deleted, the model's sparse topology may no longer optimally represent the retained data distribution. By temporarily activating pruned parameters and applying unlearning algorithms, the method can discover new important connections that better align with the updated data distribution. The final pruning step ensures the model maintains its desired sparsity level while the structural similarity metrics demonstrate that the resulting topology closely matches what would be obtained through expensive retraining.

## Foundational Learning
- **Lottery Ticket Hypothesis (LTH):** Dense networks contain sparse subnetworks that can be trained in isolation to match the accuracy of the original dense network. *Why needed:* Provides the theoretical foundation for pruning while maintaining performance. *Quick check:* Verify that the pruned subnetworks can achieve comparable accuracy to dense models.
- **Machine Unlearning:** The process of removing the influence of specific data points from a trained model. *Why needed:* Enables the "right to be forgotten" by ensuring deleted data no longer affects model behavior. *Quick check:* Measure accuracy drop on deleted data versus retained data.
- **Structural Similarity Metrics (IoM/IoU):** Metrics that measure the overlap between model masks to evaluate topological similarity. *Why needed:* Provides quantitative evaluation of how well un-pruning aligns with optimal retrained topologies. *Quick check:* Compare IoM scores between un-pruned and retrained models.

## Architecture Onboarding

**Component Map:** Dense Model -> Pruning -> Sparse Model -> Un-pruning (Activate + Unlearn + Update Mask) -> Final Sparse Model

**Critical Path:** The core workflow follows: (1) Initial pruning using LTH or soft pruning, (2) Un-pruning loop with parameter reactivation and unlearning algorithm application, (3) Mask update based on weight magnitude, (4) Final pruning to original sparsity.

**Design Tradeoffs:** The method trades computational efficiency (avoiding full retraining) for potential accuracy loss at extreme sparsity levels. The choice of unlearning algorithm (Fisher vs SCRUB) affects both accuracy and convergence speed. The un-pruning ratio p_Î˜ determines the balance between exploration of new connections and computational cost.

**Failure Signatures:** Low IoM scores indicate poor alignment with optimal topology. Significant accuracy drops suggest incorrect mask updates or insufficient un-pruning. MIA scores that don't correlate with IoM/IoU suggest evaluation metric misalignment.

**First Experiments:**
1. Implement Algorithm 1 on ResNet-18 (60% sparsity) with 10% data deletion, comparing IoM to "Retraining + Repruning" baseline
2. Test un-pruning at 95% sparsity to verify accuracy stability
3. Apply MIA to unlearned models and compare results to IoM/IoU metrics to validate MIA unreliability claim

## Open Questions the Paper Calls Out
None specified in the provided text.

## Limitations
- Performance degradation at extreme sparsity levels (95%) where un-pruning may not sufficiently recover accuracy
- Reliance on unspecified hyperparameters (un-pruning ratio, iteration count) that affect reproducibility
- Internal inconsistency between stated (10%) and reported (20%) deletion ratios in experimental sections

## Confidence

**Structural Similarity Metrics (IoM/IoU):** High - The metric definitions are clear and the comparison to "Retraining + Repruning" is explicitly defined.

**Unlearning Accuracy (UA):** High - The accuracy metric is standard and verifiable.

**MIA Unreliability Claim:** Medium - The paper argues this but the evidence is based on their experiments; independent validation would be stronger.

## Next Checks
1. Re-run Algorithm 1 on a simple case (ResNet-18, 60% sparsity, 10% deletion) and compare the final IoM score to the "Retraining + Repruning" baseline
2. Test the method at 95% sparsity to verify accuracy does not collapse after un-pruning
3. Cross-validate the claimed superiority over MIA by applying MIA to the unlearned models and comparing the results to IoM/IoU scores