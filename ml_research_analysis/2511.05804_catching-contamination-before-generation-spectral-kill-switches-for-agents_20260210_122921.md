---
ver: rpa2
title: 'Catching Contamination Before Generation: Spectral Kill Switches for Agents'
arxiv_id: '2511.05804'
source_url: https://arxiv.org/abs/2511.05804
tags:
- hfer
- spectral
- verification
- signal
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Spectral kill switches detect inconsistent context during transformer
  forward passes by computing high-frequency energy ratio (HFER) over early layers.
  Context-supported statements exhibit HFER around 0.52, while contradicted statements
  collapse to 0.05, creating robust bimodality across model families.
---

# Catching Contamination Before Generation: Spectral Kill Switches for Agents

## Quick Facts
- arXiv ID: 2511.05804
- Source URL: https://arxiv.org/abs/2511.05804
- Reference count: 16
- Key outcome: Spectral kill switches achieve near-perfect AUC for context verification by computing high-frequency energy ratio over early transformer layers

## Executive Summary
Spectral kill switches provide a novel approach to detect contradictory context in transformer-based agents before generation begins. By computing high-frequency energy ratio (HFER) across early layers, the method distinguishes between context-supported statements (HFER ~0.52) and contradicted statements (HFER ~0.05) with near-perfect accuracy. This creates a reliable bimodality that works across multiple model families including LLaMA-3.2-1B, Qwen2.5-7B, and Phi-3-Mini.

The approach operates inline during forward passes without requiring additional training, making it particularly suitable for real-time agent execution where contamination prevention is critical. By integrating with retrieval-augmented generation through three-zone decision rules (supported, contradicted, uncertain), the method provides lightweight verification for trustworthy multi-step reasoning in agentic systems.

## Method Summary
The method computes high-frequency energy ratio (HFER) over early transformer layers to detect inconsistent context during forward passes. It operates on internal activations only, requiring no training or model modifications. The approach creates distinct spectral signatures for context-supported versus contradicted statements, enabling sub-millisecond kill-switch decisions before contamination propagates. The technique integrates naturally with retrieval-augmented generation systems through three-zone decision boundaries.

## Key Results
- Near-perfect AUC (~1.0) for context verification across multiple model families
- Context-supported statements show HFER around 0.52, contradicted statements collapse to 0.05
- Sub-millisecond latency for kill-switch decisions during agent execution
- No training required - operates on internal activations only

## Why This Works (Mechanism)
The method exploits the fundamental property that transformer attention mechanisms generate distinct spectral signatures when processing consistent versus contradictory information. Context-supported statements maintain higher high-frequency energy ratios because the attention patterns distribute information more evenly across tokens and layers. Contradicted statements collapse this energy distribution as the model struggles to reconcile conflicting information, creating a sharp spectral signature that's detectable early in the forward pass.

## Foundational Learning

Attention Mechanism Fundamentals: Understanding how transformers process context through self-attention layers is essential. Each token's representation is updated based on weighted combinations of all tokens, creating rich contextual embeddings.

High-Frequency Energy Detection: The method relies on detecting rapid changes in activation patterns across layers. High-frequency components indicate healthy information flow, while low-frequency patterns suggest information collapse from contradictions.

Layer-wise Analysis: Early layers contain critical information about context consistency. The method specifically targets these layers because contradictions manifest most strongly before deeper processing obscures the signal.

Why needed: These concepts enable understanding how the spectral signature emerges from transformer mechanics and why early layers are optimal for detection.

Quick check: Verify that attention weights in early layers show different distribution patterns for consistent vs contradictory contexts.

## Architecture Onboarding

Component Map: Context Retriever -> Transformer Model -> Early Layer Activations -> HFER Calculator -> Decision Module -> Generation Control

Critical Path: The method interrupts the normal forward pass after early layers to compute HFER before contamination spreads to later layers. This creates a tight feedback loop where decisions happen within milliseconds of context retrieval.

Design Tradeoffs: The approach sacrifices minimal latency for significant reliability gains. By operating on internal activations rather than outputs, it avoids the computational overhead of running full generation before verification.

Failure Signatures: The method can produce false positives when context is genuinely ambiguous or when the retriever provides low-quality information that doesn't clearly support or contradict the query.

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but several implicit questions remain about generalization across different architectures and retrieval quality scenarios.

## Limitations

The method's performance relies heavily on specific architecture choices - it assumes standard transformer attention mechanisms and may not generalize to non-transformer architectures or models with significantly different attention patterns.

Confidence Levels:

High confidence in: the fundamental observation that context-supported vs contradicted statements create distinct spectral signatures (measured through HFER), and the empirical finding that this separation enables reliable binary classification with AUC â‰ˆ 1.0 across tested models.

Medium confidence in: the claim of sub-millisecond latency - while theoretically plausible given the simple computation, actual implementation overhead in production systems may vary significantly. Also medium confidence in the "no training required" claim, as optimal threshold selection still requires labeled data.

Low confidence in: the three-zone decision boundary's robustness across diverse domains and retrieval quality scenarios. The paper doesn't adequately address how varying retrieval precision or context relevance affects the HFER distribution.

## Confidence

High: Distinct spectral signatures between context-supported and contradicted statements, near-perfect AUC across models
Medium: Sub-millisecond latency claims, "no training required" assertion
Low: Three-zone decision boundary robustness across diverse domains and retrieval quality

## Next Checks

1. Test robustness across non-transformer architectures (RNNs, Mamba, hybrid models) to verify the spectral signature generalizes beyond standard attention mechanisms.

2. Evaluate performance degradation under realistic retrieval conditions - using low-quality or partially relevant context to measure how HFER distributions overlap and affect decision boundaries.

3. Implement end-to-end latency measurements in production-grade agent frameworks to validate sub-millisecond claims account for system overhead, context loading, and integration costs.