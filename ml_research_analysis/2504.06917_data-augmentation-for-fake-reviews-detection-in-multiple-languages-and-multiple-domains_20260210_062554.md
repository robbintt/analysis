---
ver: rpa2
title: Data Augmentation for Fake Reviews Detection in Multiple Languages and Multiple
  Domains
arxiv_id: '2504.06917'
source_url: https://arxiv.org/abs/2504.06917
tags:
- data
- fake
- reviews
- review
- generated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a data augmentation approach for detecting
  fake reviews across multiple languages and domains. The authors generate synthetic
  fake reviews using large language models fine-tuned on existing datasets, then use
  these augmented datasets to train fake review detectors.
---

# Data Augmentation for Fake Reviews Detection in Multiple Languages and Multiple Domains

## Quick Facts
- **arXiv ID**: 2504.06917
- **Source URL**: https://arxiv.org/abs/2504.06917
- **Reference count**: 27
- **Primary result**: Data augmentation improves fake review detection accuracy by 0.3-10.9 percentage points across multiple languages and domains

## Executive Summary
This paper presents a data augmentation approach for detecting fake reviews across multiple languages and domains. The authors employ large language models fine-tuned on existing datasets to generate synthetic fake reviews, which are then used to augment training data for fake review detectors. The method is evaluated on three datasets covering English (Amazon book reviews, Yelp hotel reviews) and Chinese (DianPing restaurant reviews) domains, demonstrating consistent improvements in detection accuracy. The cross-domain augmentation approach, where fake reviews are generated from real reviews and vice versa, proves particularly effective in mimicking the style of source data.

## Method Summary
The approach leverages large language models to generate synthetic fake reviews for data augmentation. The process involves fine-tuning LLMs on existing labeled datasets containing both real and fake reviews. Once fine-tuned, these models generate new synthetic reviews that mimic either real or fake review characteristics. The augmented datasets are then used to train fake review detection models. The paper evaluates this approach across three domains (books, hotels, restaurants) and two languages (English, Chinese), testing various augmentation strategies including domain-specific and cross-domain generation.

## Key Results
- Adding augmented data improves detection accuracy by 0.3-10.9 percentage points across all tested domains and languages
- Cross-domain augmentation (generating fake reviews from real ones and vice versa) is particularly effective
- The generated data closely mimics the style of source data, enhancing the quality of augmented training sets

## Why This Works (Mechanism)
The approach works by addressing the fundamental challenge of limited labeled data for fake review detection across diverse domains and languages. By using LLMs to generate synthetic reviews that closely mimic the stylistic characteristics of real and fake reviews from different domains, the method effectively expands the training data distribution. This broader coverage helps detection models learn more robust features that generalize across domain and language boundaries, particularly when synthetic reviews are generated to match the style of the target domain.

## Foundational Learning

1. **Large Language Model Fine-Tuning**
   - *Why needed*: To adapt general-purpose LLMs to generate reviews that match the specific characteristics of real and fake reviews in different domains
   - *Quick check*: Verify that fine-tuned models can generate coherent reviews that capture domain-specific language patterns

2. **Cross-Domain Augmentation**
   - *Why needed*: To improve model generalization by exposing detectors to synthetic reviews that bridge domain gaps
   - *Quick check*: Confirm that cross-domain synthetic reviews contain elements from both source and target domains

3. **Multilingual Review Analysis**
   - *Why needed*: To ensure the approach works effectively across different languages with varying linguistic structures
   - *Quick check*: Validate that the method performs consistently across English and Chinese review datasets

## Architecture Onboarding

**Component Map**: Real reviews -> LLM fine-tuning -> Synthetic reviews generation -> Augmented dataset -> Fake review detector training -> Detection model

**Critical Path**: The critical path flows from real review data through LLM fine-tuning to synthetic review generation, then to augmented dataset creation and finally to detector training. The quality of synthetic reviews directly impacts detection performance.

**Design Tradeoffs**: The approach trades computational resources (LLM fine-tuning and generation) for improved detection accuracy. The authors chose cross-domain augmentation over more complex multilingual generation strategies to balance effectiveness with implementation complexity.

**Failure Signatures**: Poor performance may indicate: (1) synthetic reviews failing to capture authentic review patterns, (2) domain mismatch between synthetic and real data, or (3) overfitting to synthetic data characteristics.

**First Experiments**:
1. Evaluate synthetic review quality through human evaluation or perplexity metrics
2. Test detection performance with varying ratios of real to synthetic data
3. Compare domain-specific vs. cross-domain augmentation effectiveness

## Open Questions the Paper Calls Out
None

## Limitations

- Limited generalizability beyond the three tested domains (books, hotels, restaurants) and two languages (English, Chinese)
- No statistical significance testing to confirm that reported performance improvements are meaningful rather than due to random variation
- Medium confidence in the effectiveness of cross-domain and cross-language augmentation strategies, as the paper demonstrates feasibility but doesn't fully explore underlying mechanisms

## Confidence

- **High confidence**: The basic methodology of using LLM fine-tuning for generating synthetic fake reviews is sound and technically feasible
- **Medium confidence**: The effectiveness of cross-domain and cross-language augmentation strategies
- **Medium confidence**: The specific performance improvements measured on the three test datasets

## Next Checks

1. Conduct statistical significance testing (e.g., paired t-tests) across multiple runs to verify that reported performance improvements are not due to random variation
2. Evaluate the approach on additional domains (e.g., electronics, clothing) and languages to test generalizability beyond the current scope
3. Perform ablation studies to determine the optimal ratio of real to augmented data and identify which types of augmentation (domain-specific vs. cross-domain) provide the most benefit for each language and domain combination