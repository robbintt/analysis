---
ver: rpa2
title: A Representationalist, Functionalist and Naturalistic Conception of Intelligence
  as a Foundation for AGI
arxiv_id: '2503.07600'
source_url: https://arxiv.org/abs/2503.07600
tags:
- world
- which
- intelligence
- only
- example
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a representationalist, functionalist, and naturalistic
  conception of intelligence as a foundation for artificial general intelligence (AGI).
  Intelligence is defined as the ability to create novel skills that allow achieving
  goals under previously unknown conditions.
---

# A Representationalist, Functionalist and Naturalistic Conception of Intelligence as a Foundation for AGI

## Quick Facts
- arXiv ID: 2503.07600
- Source URL: https://arxiv.org/abs/2503.07600
- Reference count: 23
- This paper proposes a representationalist, functionalist, and naturalistic conception of intelligence as a foundation for artificial general intelligence (AGI).

## Executive Summary
This paper presents a theoretical framework for AGI based on a representationalist, functionalist, and naturalistic conception of intelligence. The approach defines intelligence as the ability to create novel skills for achieving goals under previously unknown conditions, emphasizing the role of perception in obtaining indirect representations of the world. The framework argues that AGI systems can develop world models through reasoning methods such as deduction, induction, and abduction, combined with abstraction and classification. This approach dispenses with the need for mental features like consciousness or intentionality, allowing for a purely naturalistic interpretation of intelligence.

## Method Summary
The paper employs a philosophical and theoretical approach to define intelligence and its relationship to AGI. It synthesizes concepts from representationalism, functionalism, and naturalism to construct a coherent framework for understanding intelligence. The methodology involves analyzing the roles of perception, reasoning methods, and world modeling in intelligent behavior, while critically examining the necessity of mental features traditionally associated with intelligence.

## Key Results
- Intelligence is defined as the ability to create novel skills that allow achieving goals under previously unknown conditions
- AGI systems can develop world models through perception, reasoning methods (deduction, induction, abduction), and classification
- The value of world models is functionally determined by their viability in achieving desired goals
- Mental features like consciousness and intentionality are deemed unnecessary for AGI

## Why This Works (Mechanism)
The framework works by establishing a clear functional definition of intelligence that focuses on goal achievement through skill creation. By emphasizing perception as the primary means of obtaining indirect representations of the world, the approach provides a concrete mechanism for how AGI systems can interact with and model their environment. The inclusion of multiple reasoning methods (deduction, induction, abduction) allows for flexible problem-solving under uncertainty. The functionalist perspective ensures that the framework remains practical and testable, as it defines success in terms of goal achievement rather than abstract mental states.

## Foundational Learning
- Representationalism: Understanding that knowledge is based on mental representations of the world
  * Why needed: Provides the theoretical foundation for how AGI systems can process and store information about their environment
  * Quick check: Can the system demonstrate consistent behavior based on learned representations?

- Functionalism: Defining intelligence by what it does rather than what it is
  * Why needed: Allows for a testable, empirical approach to measuring intelligence in AGI systems
  * Quick check: Does the system achieve goals through novel skill creation under novel conditions?

- Naturalism: Interpreting intelligence without reference to supernatural or non-physical mental states
  * Why needed: Ensures the framework remains scientifically grounded and avoids philosophical dead ends
  * Quick check: Can the system's behavior be fully explained through physical processes?

- No Free Lunch Theorems: The principle that no single algorithm works best for all problems
  * Why needed: Establishes fundamental limits on AGI capabilities and the necessity of assumptions
  * Quick check: Can the system demonstrate improved performance when appropriate assumptions are made?

## Architecture Onboarding

Component Map: Perception -> Reasoning Methods -> World Model -> Skill Creation -> Goal Achievement

Critical Path: Perception → Reasoning Methods → World Model → Skill Creation → Goal Achievement

Design Tradeoffs:
- The framework sacrifices potential advantages of consciousness and intentionality for philosophical simplicity
- Emphasizes indirect representation over direct access to the world
- Requires sophisticated reasoning capabilities but eliminates need for self-awareness

Failure Signatures:
- Inability to create novel skills under novel conditions
- Failure to integrate perception with reasoning methods
- World model that doesn't improve goal achievement over time

First Experiments:
1. Test skill creation under novel conditions with varying degrees of environmental uncertainty
2. Evaluate world model viability by measuring goal achievement rates
3. Compare performance with and without specific reasoning methods (deduction, induction, abduction)

## Open Questions the Paper Calls Out
None

## Limitations
- The claim that AGI can achieve more fundamental access to the world than humans lacks empirical validation
- The dismissal of consciousness and intentionality may overlook potential roles these features play in flexible, adaptive intelligence
- The framework assumes that removing human-like cognitive constraints necessarily leads to superior world modeling

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Core framework integrating perception, reasoning, and world modeling | High |
| Functionalist claim about world model viability | Medium |
| AGI's superior access to reality compared to humans | Low |

## Next Checks
1. Design experiments comparing AGI systems with and without human-like perceptual constraints to empirically test whether reduced constraints lead to better world modeling
2. Conduct formal analyses of how the No Free Lunch theorems apply specifically to AGI systems operating under different assumption sets
3. Develop benchmark tests that measure the functional equivalence of consciousness-free and consciousness-inclusive approaches to achieving adaptive goal-directed behavior