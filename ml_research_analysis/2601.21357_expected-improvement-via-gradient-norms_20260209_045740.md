---
ver: rpa2
title: Expected Improvement via Gradient Norms
arxiv_id: '2601.21357'
source_url: https://arxiv.org/abs/2601.21357
tags:
- gradient
- ei-gn
- optimization
- improvement
- acquisition
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Expected Improvement via Gradient Norms (EI-GN),
  a novel acquisition function for Bayesian optimization that incorporates gradient
  information to mitigate EI's tendency toward over-exploitation and convergence to
  suboptimal stationary points. The method applies the improvement principle to an
  auxiliary objective that combines function values with a stationarity penalty derived
  from gradient norms, encouraging exploration in high-performing regions approaching
  first-order stationarity.
---

# Expected Improvement via Gradient Norms

## Quick Facts
- arXiv ID: 2601.21357
- Source URL: https://arxiv.org/abs/2601.21357
- Reference count: 40
- Primary result: Introduces EI-GN, an acquisition function that incorporates gradient information to prevent Bayesian optimization's over-exploitation and convergence to suboptimal stationary points

## Executive Summary
This paper addresses a fundamental limitation of Expected Improvement (EI) in Bayesian optimization: its tendency to over-exploit by repeatedly sampling near local optima, leading to premature convergence. The authors propose Expected Improvement via Gradient Norms (EI-GN), which augments the standard EI objective with a stationarity penalty derived from gradient norms. This creates an auxiliary objective that encourages exploration toward high-performing regions that are approaching first-order stationarity, effectively balancing exploration and exploitation through the lens of gradient information.

The method introduces a tractable closed-form approximation for EI-GN that separates zeroth-order improvement from first-order stationarity terms, enabling efficient computation even in higher dimensions. Through extensive experiments on synthetic benchmarks, GP-sampled objectives, and policy search tasks, EI-GN consistently outperforms standard baselines including EI, Thompson Sampling, CMA-ES, and REINFORCE, particularly in complex multimodal landscapes and higher dimensions where EI typically over-exploits.

## Method Summary
EI-GN modifies standard EI by introducing an auxiliary objective g(x) = f(x) - α‖∇f(x)‖²₂ that combines function values with a soft stationarity penalty. The gradient norm acts as a soft stationarity penalty derived from first-order optimality conditions, creating improvement signal even in regions where standard EI vanishes. The authors derive a tractable lower bound EI_g(x) ≥ EI_f(x) - αEI_s(x), separating zeroth-order improvement from first-order stationarity terms. This decomposition enables closed-form computation using a mean-field approximation via orthant truncation, converting the coupled integral into separable truncated Gaussian moments computable in O(d) per candidate.

## Key Results
- EI-GN consistently outperforms standard EI across synthetic benchmarks (Shekel, Hartmann, Cosine, Griewank, Ackley) and higher-dimensional GP-sampled objectives
- In policy search tasks (Acrobot and Cartpole), EI-GN shows better sample efficiency and lower variance compared to baselines including CMA-ES and REINFORCE
- The method demonstrates robustness to model mismatches, particularly outperforming EI under kernel mismatches (Matérn vs. RBF)
- Extensive experiments (over 20 synthetic functions, 7-9 dimensions, multiple policy tasks) validate the approach across diverse problem types

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Incorporating gradient norms into an auxiliary objective creates acquisition signal in regions where standard EI vanishes, mitigating over-exploitation.
- Mechanism: EI-GN defines an auxiliary objective g(x) = f(x) − α‖∇f(x)‖²₂. The gradient norm acts as a soft stationarity penalty derived from first-order optimality conditions. When f(x) < f(x⁺) but the gradient norm is smaller than the incumbent's, g(x) can still exceed g(x⁺), creating improvement signal even in low-EI regions. This second pathway enables structured exploration toward near-stationary high-performing regions rather than repeatedly querying local optima.
- Core assumption: Interior optima approximately satisfy ∇f(x*) ≈ 0; gradient observations are available at negligible additional cost; the objective is sufficiently smooth for gradient information to be informative.
- Evidence anchors: [abstract]: "EI-GN...promoting sampling in regions that are both high-performing and approaching first-order stationarity"; [section 4.4]: "EIg can remain informative even when P(f(x) > f(x⁺)) ≈ 0"

### Mechanism 2
- Claim: A tractable lower bound on EI_g separates zeroth-order improvement from first-order stationarity terms, enabling closed-form computation.
- Mechanism: The Positive Part Inequality (Lemma A.1) yields EI_g(x) ≥ EI_f(x) − αEI_s(x) (Eq. 6). EI_f is standard Expected Improvement on f; EI_s penalizes gradient norm increases relative to the incumbent. This decomposition allows independent computation of each term under Gaussian posteriors while preserving the bias toward stationary regions.
- Core assumption: The lower bound is sufficiently tight that optimizing it approximates optimizing EI_g; the independent modeling of f and ∇f doesn't introduce unacceptable approximation error.
- Evidence anchors: [section 4.3]: "This lower bound is consistent with the original formulation...reduces to EI when α=0"

### Mechanism 3
- Claim: Mean-field approximation via orthant truncation produces a closed-form EI-GN expression computable in O(d) per candidate.
- Mechanism: The exact EI_s involves a generalized χ² distribution requiring numerical integration. EI-GN approximates the norm-based truncation {‖μ∇(x) + Lz‖²₂ ≥ ‖∇f(x⁺)‖²₂} with an orthant truncation {z ≥_cw z⁺}, converting the coupled integral into separable truncated Gaussian moments. With diagonal posterior covariance from independent GPs, this reduces to element-wise operations.
- Core assumption: The orthant approximation adequately captures the stationarity penalty's intent; per-dimension truncation provides balanced signals across coordinates rather than allowing dominant dimensions to mask others.
- Evidence anchors: [section 4.5]: "The reordering induces a more balanced stationarity signal...per-dimension approach places more emphasis on distributing the stationarity penalty"

## Foundational Learning

- Concept: **Expected Improvement (EI) acquisition function**
  - Why needed here: EI-GN modifies standard EI; understanding EI's myopic over-exploitation is prerequisite to appreciating the gradient-norm correction.
  - Quick check question: Explain why EI(x) = E[max(f(x) − f(x⁺), 0)] can vanish across large search regions.

- Concept: **First-order optimality conditions and stationarity**
  - Why needed here: EI-GN's auxiliary objective uses ‖∇f(x)‖²₂ as a stationarity penalty; intuition requires understanding why interior optima satisfy gradient zero.
  - Quick check question: For g(x) = f(x) − α‖∇f(x)‖²₂, why does g(x*) = f(x*) hold at an interior maximizer x* of f?

- Concept: **Gaussian Process posterior inference**
  - Why needed here: EI-GN requires posterior mean and covariance for both f and ∇f to compute closed-form expressions; the method uses independent GPs to avoid O((d+1)³N³) complexity.
  - Quick check question: Why does the independence assumption (separate GPs for f and each partial derivative) reduce complexity from O((d+1)³N³) to O(N³) with parallel training?

## Architecture Onboarding

- Component map: GP surrogate for f -> d independent gradient GPs -> EI_f computation -> EI_s computation -> EI-GN assembly -> Acquisition optimizer
- Critical path:
  1. Collect (y, ∇y) observations at query point
  2. Train/update GP for f (zeroth-order)
  3. Train/update d independent GPs for partial derivatives
  4. For each candidate x during acquisition optimization:
     - Compute EI_f(x) from f-posterior
     - Compute EI_s(x) via orthant truncation formula
     - Combine: EI-GN(x) = EI_f(x) − α·EI_s(x)
  5. Maximize EI-GN via L-BFGS from multiple restarts
  6. Return argmax as next query point

- Design tradeoffs:
  - **Independent vs. joint GP models**: Independence avoids O((d+1)³N³) complexity but sacrifices cross-correlation information; paper shows robustness to this approximation
  - **α selection**: Paper finds α ∈ [0.4, 0.8] works consistently across benchmarks; α = 0 recovers standard EI
  - **Online rescaling**: Mean/std normalization of EI_f and EI_s components during acquisition maximization improves numerical stability

- Failure signatures:
  - **Numerical instability in gradient GP training**: Large gradient magnitude ranges; mitigated by adaptive Cholesky jitter (10⁻⁹ to 10⁻²)
  - **Over-penalization**: Excessive α causes excessive exploration, slowing convergence
  - **Uninformative gradients**: Neural policy experiments (Cartpole) showed reduced EI-GN advantage due to high-variance gradient estimates
  - **Model mismatch degradation**: EI degrades more than EI-GN under kernel mismatch (Matérn vs. RBF), but both remain functional

- First 3 experiments:
  1. **Hartmann-6D (synthetic)**: 18 Sobol initials, 150 budget. Compare EI-GN vs. EI vs. TS. Expect EI-GN to avoid EI's plateau after initial iterations. Validates gradient signal quality on smooth multimodal landscape.
  2. **Within-model GP-sampled (8D)**: RBF kernel matching prior, no hyperparameter refitting. Isolates acquisition behavior from model mismatch. Expect EI-GN > EI > TS.
  3. **Acrobot policy search (6D linear policy)**: 32 rollouts/episode, 100 episodes. Tests robustness to noisy gradient estimates from policy gradient theorem. Expect EI-GN to show lower variance across seeds than EI.

## Open Questions the Paper Calls Out
- **No open questions explicitly called out in the paper**

## Limitations
- **Stationarity assumptions**: EI-GN's effectiveness relies on interior optima satisfying ∇f(x*) ≈ 0, which may fail for boundary optima or objectives with discontinuous gradients
- **Gradient availability and quality**: The method assumes gradient observations are available at negligible cost; for expensive gradient computations or high-variance estimates, the benefit diminishes significantly
- **Model independence approximation**: While the paper demonstrates robustness to using independent GPs for f and ∇f instead of the theoretically correct joint GP, this remains an approximation that could introduce bias in extreme cases of high cross-correlation

## Confidence
- **High confidence**: The theoretical derivation of the EI-GN lower bound and its decomposition into EI_f and EI_s components is mathematically sound. The mechanism by which gradient norms prevent over-exploitation is clearly articulated and empirically validated.
- **Medium confidence**: The mean-field approximation using orthant truncation is reasonable and computationally necessary, but the approximation error is difficult to quantify. The method's robustness to model mismatches is demonstrated but not systematically characterized.
- **Low confidence**: Claims about EI-GN's behavior on extremely high-dimensional problems (>10D) are extrapolated from 7-9D results. The method's performance with discontinuous or highly noisy gradients is not thoroughly explored.

## Next Checks
1. **Boundary behavior test**: Evaluate EI-GN on constrained optimization problems with known boundary optima to quantify performance degradation when stationarity assumptions fail.

2. **Gradient cost sensitivity**: Systematically vary the relative cost of gradient vs. function evaluations in synthetic benchmarks to identify the break-even point where EI-GN's advantage disappears.

3. **Cross-correlation stress test**: Construct synthetic problems with strong f-∇ correlation and compare independent vs. joint GP performance to quantify the approximation error in the independence assumption.