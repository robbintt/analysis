---
ver: rpa2
title: Auxiliary Metrics Help Decoding Skill Neurons in the Wild
arxiv_id: '2511.21610'
source_url: https://arxiv.org/abs/2511.21610
tags:
- neurons
- language
- prompt
- neuron
- soft
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a lightweight method to identify neurons
  encoding specific skills in large language models (LLMs). The approach trains soft
  prompts and correlates neuron activations with auxiliary metrics such as external
  labels or model confidence scores.
---

# Auxiliary Metrics Help Decoding Skill Neurons in the Wild

## Quick Facts
- arXiv ID: 2511.21610
- Source URL: https://arxiv.org/abs/2511.21610
- Reference count: 9
- Primary result: Lightweight method identifies skill-encoding neurons via soft prompts and auxiliary metrics, revealing interpretable behaviors across diverse tasks

## Executive Summary
This paper introduces a method to identify neurons encoding specific skills in large language models by training soft prompts and correlating neuron activations with auxiliary metrics like external labels or model confidence. The approach successfully detects sparse, interpretable skill neurons across tasks including open-ended generation, natural language inference, and arithmetic reasoning. Notably, it uncovers previously unknown heuristics in arithmetic reasoning without manual token aggregation, demonstrating the framework's ability to reveal fine-grained linguistic skills and model behaviors.

## Method Summary
The method trains 20-token soft prompts appended after instructions while freezing all model weights, then extracts feed-forward network (FFN) neuron activations on these soft tokens during validation. For each neuron, it computes Pearson correlation between activations (maximized across soft-token positions) and an auxiliary metric such as class labels, heuristic indicators, or per-sample loss. Top-K neurons by absolute correlation are selected, and their activation patterns are inspected by examining extremal samples to reveal interpretable skill patterns or heuristics.

## Key Results
- Successfully identifies sparse, interpretable skill neurons across multiple tasks including spatial reasoning, metaphor generation, NLI heuristics, and arithmetic
- Discovers previously unknown last-digit multiplication heuristic in arithmetic reasoning through low-activation samples
- Shows correlation distributions (Figures 6, 7) with clear tails for task-specific neurons, validating the sparse encoding assumption

## Why This Works (Mechanism)

### Mechanism 1
Soft prompts trained on frozen models encode task-specific neural signatures. By training only learnable vectors after the instruction via cross-entropy loss while freezing all weights, the model's internal activations on those soft tokens adapt to reflect task demands, providing a consistent probe point per sample.

### Mechanism 2
Neuron activations on trained soft prompts correlate with auxiliary metrics in sparse subsets. Pearson correlation between activations and metrics identifies neurons predictive of underlying skills or heuristics, with high absolute correlation suggesting the neuron encodes relevant information.

### Mechanism 3
Examining samples that maximally/minimally activate high-correlation neurons reveals interpretable patterns. Sorting validation samples by activation and inspecting extremes uncovers skill patterns or heuristics, as demonstrated by the arithmetic last-digit multiplication shortcut discovery.

## Foundational Learning

- **Pearson correlation**: Measures linear association between two scalar variables, ranging from -1 to +1. Needed to understand what high correlation does and doesn't guarantee (e.g., not causation, not robust to non-linearity). Quick check: If a neuron's activation is perfectly predictive of a binary label via a thresholded step function, will Pearson correlation necessarily be near 1?

- **Feed-forward network (FFN)**: Position-wise two-layer MLP in Transformers where "neuron" refers to intermediate dimensions. Needed to interpret neuron activation formulas. Quick check: For hidden dimension m, how many distinct neuron activations are computed per token per layer?

- **Soft prompt tuning**: Trains continuous embeddings prepended/appended to inputs while keeping model weights frozen. Needed because all downstream neuron activations are measured on these learned soft tokens. Quick check: Why freeze model weights when training the soft prompt for interpretability analysis?

## Architecture Onboarding

- **Component map**: Frozen pretrained decoder LLM -> Embedding -> Transformer layers (Attention + FFN) -> Logits -> Soft prompt vectors p_1...p_l after instruction, trained on S_train -> Metric function m(x, y, model_output) -> scalar per validation sample -> Neuron activation extraction on soft-token positions across S_val -> Correlation computation (Pearson) and top-K selection -> Interpretation via extremal-sample inspection

- **Critical path**: 1) Define task, collect S_train and S_val. 2) Train soft prompt on S_train with frozen model. 3) Choose auxiliary metric m. 4) Forward S_val with soft prompt, extract FFN activations. 5) Compute per-neuron, per-position correlation with m; take max over positions. 6) Select top-K absolute-correlation neurons; inspect extremal samples.

- **Design tradeoffs**: Metric choice (external labels vs. model-internal metrics), soft-token count (more positions vs. signal dilution), correlation method (Pearson vs. alternatives), sparsity vs. coverage in neuron selection.

- **Failure signatures**: All neurons show near-zero correlation (metric uninformative or task not captured), selected neurons don't generalize (overfitting), extremal samples appear random (neuron polysemantic or metric mis-specified), correlation distributions show no clear tail (skill not localized).

- **First 3 experiments**: 1) Reproduce binary classification with known skill (e.g., sentiment) and metric m = class label; verify top neurons separate classes. 2) On HANS-like NLI data, define m as heuristic indicator (e.g., Lexical Overlap); confirm selected neurons show distinct activation distributions. 3) On multiple-choice reasoning without labels, set m = per-sample loss; inspect lowest-activation samples for consistent shortcuts, then validate by constructing counterexamples.

## Open Questions the Paper Calls Out

- **Causal influence**: The paper leaves examining whether identified neurons causally influence model behaviors to future work, noting that high correlation doesn't establish functional dependence.

- **Prompt tuning robustness**: The method depends on soft prompt quality, but the paper doesn't analyze whether different prompt training runs yield consistent neuron sets.

- **Behavioral steering**: While identifying neurons associated with skills, the paper doesn't test whether modifying these neurons can effectively steer model behavior.

## Limitations

- Correlation-based method may miss non-linear skill representations distributed across neural populations
- Soft prompt may learn task-specific shortcuts rather than revealing genuine model circuitry
- Arithmetic heuristic discovery validated only through qualitative inspection of 10 samples without systematic testing

## Confidence

- **High**: Soft prompt training methodology and correlation-based neuron selection framework are clearly specified and reproducible
- **Medium**: Method successfully identifies sparse neurons with interpretable patterns, but claims about revealing genuine "skills" require more rigorous validation
- **Low**: Assertion that method discovers previously unknown model heuristics without external labels is weakest, given limited validation

## Next Checks

1. Construct controlled test sets for claimed heuristics, verifying identified neurons show significantly different activation patterns between relevant and irrelevant conditions, and testing adversarial examples that break the heuristic

2. Implement mutual information-based neuron selection as alternative to Pearson correlation, comparing overlap and interpretability to assess whether linear correlation suffices

3. Apply methodology to larger models (e.g., Qwen-7B or 14B) and compare neuron correlation distributions and interpretability results to test scalability and sparsity properties