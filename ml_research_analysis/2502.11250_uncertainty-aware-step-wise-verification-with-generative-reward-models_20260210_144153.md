---
ver: rpa2
title: Uncertainty-Aware Step-wise Verification with Generative Reward Models
arxiv_id: '2502.11250'
source_url: https://arxiv.org/abs/2502.11250
tags:
- uncertainty
- reasoning
- verification
- step
- entropy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces uncertainty quantification (UQ) to improve
  the reliability of step-wise verification in generative reward models for mathematical
  reasoning tasks. A novel method, CoT Entropy, leverages chain-of-thought (CoT) prompting
  and entropy estimation to capture the uncertainty of a judge-LM in verifying each
  reasoning step.
---

# Uncertainty-Aware Step-wise Verification with Generative Reward Models

## Quick Facts
- **arXiv ID:** 2502.11250
- **Source URL:** https://arxiv.org/abs/2502.11250
- **Reference count:** 9
- **Primary result:** CoT Entropy achieves AUROC 0.68, AUPRC 0.885, and AU-F1C 0.348 on PRM800K, outperforming baselines in detecting verification errors.

## Executive Summary
This work introduces uncertainty quantification to improve the reliability of step-wise verification in generative reward models for mathematical reasoning. The proposed CoT Entropy method leverages chain-of-thought prompting and entropy estimation to capture the uncertainty of a judge-LM in verifying each reasoning step. By clustering generated rationales and computing entropy over semantic clusters, the approach produces a probabilistic confidence measure that outperforms existing uncertainty-aware baselines. Evaluated on PRM800K, the method demonstrates significant improvements in detecting verification errors and enables selective verification that improves F1-score at various rejection thresholds.

## Method Summary
The method uses a judge-LM (Qwen2-Math-72B-Instruct) to verify mathematical reasoning steps by generating chain-of-thought critiques followed by error decisions. For each step, it samples 1 greedy generation (T=0.1) and 10 diverse rationales (T=1.0), clusters outputs by binary decision (error/no-error), normalizes probabilities, and computes entropy over clusters. This CoT Entropy serves as an uncertainty measure that correlates with verification errors, enabling selective rejection of uncertain steps to improve overall accuracy.

## Key Results
- CoT Entropy outperforms existing UQ baselines on PRM800K (AUROC 0.68, AUPRC 0.885, AU-F1C 0.348)
- Selective verification using CoT Entropy's uncertainty estimates improves F1-score at various rejection thresholds
- The method outperforms embedding-based alternatives, showing token probabilities alone can yield effective uncertainty estimates
- Epistemic uncertainty correlates strongly with prediction errors, suggesting most errors stem from knowledge gaps rather than label noise

## Why This Works (Mechanism)

### Mechanism 1: CoT-Conditioned Posterior Marginalization
Marginalizing verification probabilities over diverse chain-of-thought rationales produces more reliable uncertainty estimates than single-pass probability extraction. Instead of directly predicting binary labels, the judge-LM generates rationale-decision pairs, and summing probabilities of sequences leading to the same decision approximates a posterior predictive distribution that integrates diverse reasoning paths.

### Mechanism 2: Epistemic Uncertainty Correlation
Verification errors correlate more strongly with knowledge gaps (epistemic uncertainty) than with data ambiguity (aleatoric uncertainty). By decomposing total uncertainty using Mutual Information between predictions and rationales, the method isolates uncertainty from the model's lack of knowledge, signaling when the model is "guessing" due to missing mathematical concepts.

### Mechanism 3: Probability-Weighted Semantic Consistency
Token probabilities provide superior uncertainty signals compared to embedding similarity or discrete frequency counts. The method clusters outputs by decision but weights them by normalized generation probability, capturing the "strength" of reasoning paths and reflecting confidence gaps that discrete voting misses.

## Foundational Learning

- **Process Reward Models (PRMs):** These assign rewards to intermediate reasoning steps rather than just final outcomes. Understanding this distinction is essential since the paper modifies PRMs for step-wise uncertainty quantification. *Quick check:* How does a PRM differ from an ORM in assigning credit for a correct final answer derived through flawed logic?

- **Semantic Entropy:** CoT Entropy adapts Semantic Entropy by clustering meaning-equivalent outputs to calculate entropy over concepts rather than specific token sequences. *Quick check:* Why does standard entropy over tokens fail when the same logical conclusion can be phrased in syntactically different ways?

- **Epistemic vs. Aleatoric Uncertainty:** The paper attributes success to detecting epistemic uncertainty (knowledge gaps). Distinguishing this from aleatoric (data noise) explains why the method works for math (where truth is absolute) but might struggle in subjective tasks. *Quick check:* In the context of this paper, does high aleatoric uncertainty imply the verifier is confused or the question is ambiguous?

## Architecture Onboarding

- **Component map:** Input (Q, steps_so_far, next_step) -> Judge-LM (Qwen2-Math) -> Sampler (1 greedy + 10 samples) -> UQ Calculator (cluster, normalize, entropy) -> Aggregator (selective verification)
- **Critical path:** The prompt engineering is critical. The paper notes prompts must ensure high JSON parsing success rates as a proxy for the model understanding the verification task.
- **Design tradeoffs:** Cost vs. Reliability (10× more generations per step increases inference compute) and Generative vs. Discriminative (interpretable rationales vs. hallucination risk).
- **Failure signatures:** High Uncertainty on Correct Steps (model weakness in specific domains) and Low Uncertainty on Incorrect Steps (reward hacking or confident hallucination).
- **First 3 experiments:**
  1. Implement Naive Entropy vs. CoT Entropy on PRM800K subset to verify baseline performance.
  2. Ablate sampling temperature (0.5 vs 1.0) to determine optimal diversity vs. noise tradeoff.
  3. Run uncertainty decomposition on 50 incorrect steps to verify epistemic uncertainty correlates with "hard" math concepts.

## Open Questions the Paper Calls Out
- Can uncertainty estimates from CoT Entropy be effectively utilized to mitigate reward hacking during reinforcement learning training?
- Does fine-tuning a generative reward model improve the accuracy of uncertainty estimates compared to the current prompting approach?
- How does CoT Entropy perform in aiding inference-time search algorithms compared to standard verification methods?
- Is the dominance of epistemic uncertainty consistent across different reasoning domains or full-scale datasets?

## Limitations
- Computational cost is 10× higher than standard PRMs, making real-time applications impractical
- Performance heavily depends on sampling temperature settings that aren't thoroughly explored
- Domain specificity limits generalization to subjective domains where aleatoric uncertainty dominates

## Confidence
- **High Confidence:** CoT Entropy outperforms baselines on PRM800K; selective verification improves F1-scores; epistemic uncertainty correlates with errors
- **Medium Confidence:** Token probabilities provide superior uncertainty signals; generated rationales capture valid confidence nuances
- **Low Confidence:** Generalization to non-mathematical domains; performance with smaller judge-LM models

## Next Checks
1. **Temperature Ablation Study:** Systematically evaluate CoT Entropy across temperatures (0.3, 0.5, 0.7, 1.0, 1.5) to determine optimal diversity-vs-noise tradeoff.
2. **Cross-Domain Transfer:** Apply CoT Entropy to a non-mathematical verification task to test whether epistemic uncertainty remains dominant when ground truth is less absolute.
3. **Cost-Benefit Analysis:** Measure computational overhead of 10× sampling against F1 improvement from selective verification to calculate break-even points.