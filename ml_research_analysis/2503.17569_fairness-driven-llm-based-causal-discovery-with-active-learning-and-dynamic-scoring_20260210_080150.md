---
ver: rpa2
title: Fairness-Driven LLM-based Causal Discovery with Active Learning and Dynamic
  Scoring
arxiv_id: '2503.17569'
source_url: https://arxiv.org/abs/2503.17569
tags:
- causal
- graph
- proposed
- fairness
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of causal discovery (CD) in
  machine learning fairness analysis by leveraging Large Language Models (LLMs) with
  an Active Learning (AL) and Dynamic Scoring Mechanism. The proposed method employs
  a breadth-first search (BFS) strategy enhanced by prioritizing queries based on
  mutual information, partial correlation, and LLM confidence scores, reducing the
  number of required queries from quadratic to linear in terms of variable count.
---

# Fairness-Driven LLM-based Causal Discovery with Active Learning and Dynamic Scoring

## Quick Facts
- **arXiv ID**: 2503.17569
- **Source URL**: https://arxiv.org/abs/2503.17569
- **Reference count**: 35
- **Primary result**: LLM-based causal discovery method with BFS + active learning achieves superior F1 scores and better fairness pathway identification compared to baselines like PC, GES, NOTEARS, and DAGMA.

## Executive Summary
This paper presents a novel method for causal discovery in machine learning fairness analysis by leveraging Large Language Models (LLMs) with Active Learning and Dynamic Scoring. The approach addresses scalability challenges by replacing exhaustive pairwise LLM queries with a Breadth-First Search strategy, reducing query complexity from quadratic to linear relative to variable count. By integrating statistical metrics (Mutual Information and Partial Correlation) with LLM confidence scores into a dynamic ranking function, the method prioritizes the most informative variable pairs while minimizing redundant queries. The framework was evaluated on benchmark datasets, demonstrating superior performance in terms of F1 score, precision, and normalized Hamming distance compared to baseline methods, while also providing more accurate causal graphs for fairness analysis.

## Method Summary
The method employs a Breadth-First Search (BFS) strategy enhanced by Active Learning to discover causal relationships from variable metadata using LLMs. It identifies independent variables (root nodes) and iteratively expands the frontier by querying "What does X cause?" rather than checking all possible pairs. A dynamic scoring mechanism combines Mutual Information, Partial Correlation, LLM confidence, and query history to prioritize variable pairs for LLM queries. The system uses Bayesian Optimization to tune weights for the scoring components and enforces DAG constraints through cycle detection. The method also incorporates fairness validation by decomposing causal pathways from sensitive attributes to outcomes, distinguishing direct discriminatory paths from indirect correlations.

## Key Results
- Achieves F1 scores of 0.55-0.65 on benchmark datasets (Child network: 20 nodes, 25 edges; Neuropathic Pain: 221 nodes, 770 edges)
- Reduces query complexity from quadratic to linear relative to variable count compared to pairwise LLM querying
- Produces causal graphs with lower normalized bias contribution and fewer spurious fairness paths compared to PC, GES, NOTEARS, and DAGMA baselines
- Demonstrates superior precision (0.6 on Child network) for fairness auditing, though at the cost of lower recall

## Why This Works (Mechanism)

### Mechanism 1: Scalability via Breadth-First Search (BFS)
Replaces exhaustive pairwise LLM queries with BFS, reducing query complexity from quadratic to linear. Instead of querying every possible pair (x,y), the algorithm identifies independent variables and iteratively expands the frontier by querying "What does X cause?" Context of discovered relationships guides subsequent queries. Assumes valid DAG representation and topological orderings exist. Evidence: abstract states query reduction from quadratic to linear; section 3.1 confirms visiting each node once determines all outgoing edges. Fails if graph is extremely dense or independent node initialization fails.

### Mechanism 2: Informativeness via Dynamic Scoring (Active Learning)
Integrates statistical metrics with LLM confidence scores into dynamic ranking function prioritizing informative pairs. Calculates score S(x,y) combining Mutual Information, Partial Correlation, LLM confidence, and query history penalty. Selects pair maximizing this score for next LLM prompt. Assumes observational statistics align with causal potential and LLM confidence correlates with correctness. Evidence: section 3.2.1 defines S(x,y) as weighted sum; results 5.1.1 show statistical information and query history are significant contributors. Fails if observational statistics are misleading or LLM confidence is poorly calibrated.

### Mechanism 3: Fairness Validation via Pathway Decomposition
Constructs sparse causal graphs via LLMs to facilitate fairness analysis by isolating direct discriminatory paths from spurious correlations. Once DAG is built, traces paths from sensitive attributes to outcomes, distinguishing direct edges from indirect mediated paths. Allows "normalized bias contribution" metric. Assumes LLM-generated graph is accurate enough that missing biased path is less likely than detecting false one. Evidence: section 3.4 defines P_direct and P_indirect; results 5.3 show lowest normalized bias contribution. Fails if LLM omits subtle proxy variables (e.g., Zip Code as Race proxy).

## Foundational Learning

- **Concept: Directed Acyclic Graphs (DAGs) & Topological Ordering**
  - Why needed here: Method relies on acyclicity constraint to function; cannot compute valid "independent nodes" or perform cycle detection without understanding DAG structure.
  - Quick check question: If LLM suggests A→B and B→A, which component rejects the second edge?

- **Concept: Active Learning (AL)**
  - Why needed here: Core efficiency driver; system uses "query strategy" to decide what to ask next based on potential information gain.
  - Quick check question: How does "Query History Score" in Equation 4 prevent system from asking same question repeatedly?

- **Concept: Mutual Information (MI) vs. Correlation**
  - Why needed here: Dynamic scoring uses both; MI captures non-linear dependencies while Partial Correlation handles linear relationships controlled for confounders.
  - Quick check question: Why might pair have high MI but low Partial Correlation, and how does weighting mechanism handle this?

## Architecture Onboarding

- **Component map**: Input Handler (metadata + data) -> Statistical Engine (MI/PC matrices) -> Dynamic Scorer (Eq 1-4) -> LLM Interface (prompts + parsing) -> Graph Builder (adjacency + cycle check) -> Bayesian Optimizer (weight tuning)

- **Critical path**: Initialization (Find Independent Nodes) → Score Unqueried Pairs → Select Top Pair → LLM Query → Cycle Check → Update Graph

- **Design tradeoffs**:
  - Precision vs. Recall: Tuned for higher precision (0.6 in Child network) to avoid spurious fairness paths, at cost of potentially missing true edges
  - Complexity vs. Runtime: Query complexity drops to linear but overhead of scoring and prompt management makes it slower than statistical methods (25s vs 0.12s on small graphs)

- **Failure signatures**:
  - Token Limit Overflow: Fails on large graphs (e.g., Neuropathic with 221 nodes) due to LLM context limits
  - Variable Hallucination: LLM returns typos or non-existent variable names, breaking graph construction
  - Cyclic Logic: If LLM inconsistent, cycle check constantly rejects edges, stalling graph growth

- **First 3 experiments**:
  1. Baseline Validation (Child Network): Run method with default weights against ground truth to verify F1 > 0.5 and compare query count against LLM-Pairwise baseline
  2. Hyperparameter Sensitivity: Run Bayesian optimization on Child dataset to find optimal weights and confirm if w_stat is strongest F1 predictor
  3. Fairness Stress Test (Adult Dataset): Generate graphs for Adult dataset and check if "Sex"→"Salary" path is correctly identified or mediated by "Education", comparing normalized bias contribution against PC algorithm

## Open Questions the Paper Calls Out
- **Open Question 1**: How can framework handle extensive variable definitions exceeding LLM context windows without losing critical causal context? Basis: Section 6.4 states token limits prevent passing full metadata for large networks like Neuropathic, requiring future improvement. Why unresolved: Fixed context windows force trade-off between metadata completeness and variable count. Evidence: Successful application using RAG or summarization maintaining F1 scores comparable to smaller datasets would resolve.

- **Open Question 2**: How can dynamic scoring mechanism be refined to better balance graph sparsity with identification of critical fairness-relevant pathways? Basis: Section 6.3 notes method produces streamlined graphs but raises concerns about missing critical fairness-relevant variables due to low Total Effect and minimal indirect paths. Why unresolved: Active learning prioritizes direct, high-confidence links, potentially pruning indirect paths necessary for comprehensive bias assessment. Evidence: Modified scoring weight configuration increasing recall of sensitive attribute pathways without introducing spurious paths would resolve.

- **Open Question 3**: What mechanisms can standardize LLM outputs to eliminate syntax errors (e.g., variable name typos) and reduce dependency on extensive hyperparameter tuning? Basis: Section 6.4 identifies "typos or variations in variable names" and significant effort required for hyperparameter tuning as limitations. Why unresolved: Stochastic nature of LLMs requires complex Bayesian optimization to manage weights and thresholds, and high temperatures can cause parsing-breaking hallucinations. Evidence: Constrained decoding or robust post-processing eliminating variable name errors and reducing performance variance across temperatures would resolve.

## Limitations
- Reliance on observational statistics assumes linear/non-linear dependencies are valid proxies for causal potential, which may not hold in all domains
- LLM confidence extraction method and prompt formatting for query history are underspecified, creating reproducibility risks
- Scalability constrained by LLM context limits, preventing application to very large graphs (e.g., Neuropathic with 221 nodes)
- Prioritizes precision over recall for fairness analysis, potentially missing subtle proxy discrimination paths
- Runtime complexity incurs significant overhead from scoring and prompt management, making it slower than statistical baselines on small graphs

## Confidence
- **High Confidence**: BFS scalability claims (query count reduction from quadratic to linear) and DAG cycle detection implementation are well-supported by algorithm description and validation on benchmark datasets
- **Medium Confidence**: Dynamic scoring effectiveness (integration of MI/PC with LLM confidence) is supported by ablation studies but relies on assumptions about statistical-causal alignment requiring further empirical validation
- **Low Confidence**: Fairness pathway decomposition claims (ability to isolate direct vs. indirect bias paths) are promising but depend heavily on LLM accuracy; missing proxy variables could lead to false fairness conclusions

## Next Checks
1. **LLM Confidence Calibration Test**: Run method on Child network with three different LLM confidence extraction methods (log-probabilities, verbalized confidence, no confidence) and measure F1 score changes to validate scoring mechanism's sensitivity

2. **Proxy Variable Detection Challenge**: Use synthetic dataset where non-sensitive variable (e.g., "Neighborhood") is known proxy for sensitive attribute (e.g., "Race"). Verify if method correctly identifies mediated path (Race → Neighborhood → Outcome) rather than missing it

3. **Large Graph Stress Test**: Attempt to run method on medium-sized causal graph (50-100 nodes) to empirically determine LLM context limit threshold and document failure modes (token overflow, hallucination rates)