---
ver: rpa2
title: 'Plausibility Vaccine: Injecting LLM Knowledge for Event Plausibility'
arxiv_id: '2503.12667'
source_url: https://arxiv.org/abs/2503.12667
tags:
- association
- plausibility
- language
- adapters
- linguistics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of improving semantic plausibility
  prediction in language models, which struggle to distinguish between plausible and
  implausible events due to sparsity in language data. The authors propose injecting
  latent knowledge from large language models (LLMs) into transformer-based models
  using parameter-efficient fine-tuning.
---

# Plausibility Vaccine: Injecting LLM Knowledge for Event Plausibility

## Quick Facts
- arXiv ID: 2503.12667
- Source URL: https://arxiv.org/abs/2503.12667
- Authors: Jacob Chmura; Jonah Dauvet; Sebastian Sabry
- Reference count: 8
- Improves semantic plausibility prediction by 8-2% over direct fine-tuning using injected LLM knowledge

## Executive Summary
This paper addresses the challenge of improving semantic plausibility prediction in language models, which struggle to distinguish between plausible and implausible events due to sparsity in language data. The authors propose injecting latent knowledge from large language models (LLMs) into transformer-based models using parameter-efficient fine-tuning. Specifically, they train 12 task adapters to learn physical properties (e.g., size, weight, temperature) and selectional association measures (verb-subject and verb-object relationships), then fuse these adapters with pre-trained ALBERT embeddings. To scale their approach, they automate auxiliary task data generation using GPT-4o. Experiments on two plausibility datasets (20Q and PEP-3K) show that property-based adapters improve accuracy by 8-2% over direct fine-tuning, with further marginal gains (2-3%) from adding selectional association adapters. The method demonstrates robustness across different transformer backbones (ALBERT, BERT, RoBERTa) and highlights the utility of grounding semantic representations with physical and relational knowledge.

## Method Summary
The authors propose a parameter-efficient approach to improve semantic plausibility prediction by injecting LLM-derived knowledge into transformer models. They first generate auxiliary training data using GPT-4o for 10 physical properties (Size, Weight, Sentience, Phase, Rigidity, Temperature, Opacity, Shape, Texture, Mobility) and two selectional association tasks (verb-subject and verb-object relationships). These 12 tasks are learned using sequential bottleneck adapters (reduction factor 16) trained on frozen ALBERT-base-v2 embeddings. The adapters are then fused using AdapterFusion to combine their representations. Finally, a single-layer MLP classifier is trained on the fused embeddings for binary plausibility classification. The entire pipeline is evaluated on PEP-3K and 20Q datasets, with results showing significant improvements over direct fine-tuning baselines.

## Key Results
- Property adapters alone improve accuracy by 8-2% over direct fine-tuning on PEP-3K and 20Q datasets
- Selectional association adapters provide additional marginal gains of 2-3% accuracy
- Method generalizes across transformer backbones (ALBERT, BERT, RoBERTa)
- AdapterFusion successfully combines complementary knowledge from different adapters

## Why This Works (Mechanism)
The approach works by augmenting transformer representations with explicit physical and relational knowledge that is often implicit in language but crucial for plausibility reasoning. By pre-training adapters on carefully designed auxiliary tasks, the model learns to represent semantic properties that are directly relevant to plausibility judgment. The AdapterFusion mechanism then combines these complementary representations, allowing the model to leverage both physical property knowledge and selectional preference information simultaneously. This injection of structured knowledge compensates for the sparsity of plausibility-related examples in standard training corpora.

## Foundational Learning
- **AdapterHub/Adapters Library**: Framework for modular adapter insertion into transformers - needed for parameter-efficient fine-tuning of auxiliary tasks
- **AdapterFusion**: Mechanism for combining multiple adapter outputs - needed to integrate complementary knowledge from different auxiliary tasks
- **GPT-4o Prompt Engineering**: Crafting prompts for automated data generation - needed to scale auxiliary task data creation
- **Selectional Association**: Measuring compatibility between verbs and their arguments - needed for capturing syntactic-semantic plausibility constraints
- **Physical Property Classification**: Categorizing entities by size, weight, temperature, etc. - needed for grounding semantic representations in real-world knowledge

## Architecture Onboarding

**Component Map:** ALBERT-base-v2 (frozen) -> 12 Task Adapters (sequential) -> AdapterFusion -> MLP Classifier

**Critical Path:** GPT-4o data generation → Adapter pre-training → AdapterFusion → Fine-tuning → Evaluation

**Design Tradeoffs:** Parameter-efficient adapters vs. full fine-tuning; automated data generation vs. manual annotation; fused representations vs. ensemble methods

**Failure Signatures:** Low adapter pre-training accuracy on ambiguous properties (Shape: 30%, Rigidity: 31%) is expected; Combined dataset training shows no improvement as predicted

**First 3 Experiments:**
1. Verify GPT-4o output quality by manually checking sample property classifications
2. Test adapter pre-training on single property to validate learning capability
3. Evaluate fused adapter performance on held-out plausibility examples before full fine-tuning

## Open Questions the Paper Calls Out
None

## Limitations
- GPT-4o automated data generation quality not validated, raising concerns about auxiliary task reliability
- Selectional association adapters provide only marginal 2-3% improvements despite additional computational complexity
- Limited evidence for cross-domain generalization beyond the specific datasets tested

## Confidence
- **High Confidence**: 8-2% accuracy improvement with property adapters alone on both PEP-3K and 20Q datasets
- **Medium Confidence**: 2-3% additional gains from selectional association adapters are supported but may not justify added complexity
- **Low Confidence**: Claims of cross-backbone generalization lack detailed supporting results

## Next Checks
1. Generate and manually verify a sample of GPT-4o outputs for the 10 physical properties and 2 selectional association tasks
2. Analyze learned AdapterFusion weights to determine if they show meaningful differentiation between adapter contributions
3. Test pre-trained adapters on a held-out plausibility dataset from a different domain to evaluate generalization