---
ver: rpa2
title: 'Fast, Slow, and Tool-augmented Thinking for LLMs: A Review'
arxiv_id: '2508.12265'
source_url: https://arxiv.org/abs/2508.12265
tags:
- reasoning
- arxiv
- external
- fast
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents a comprehensive review of reasoning strategy
  selection in large language models (LLMs), addressing the challenge of efficiently
  adapting reasoning approaches based on task demands. The authors propose a novel
  taxonomy organized along two knowledge boundaries: a fast/slow boundary distinguishing
  intuitive versus deliberative reasoning, and an internal/external boundary differentiating
  reasoning grounded in model parameters from tool-augmented thinking.'
---

# Fast, Slow, and Tool-augmented Thinking for LLMs: A Review

## Quick Facts
- arXiv ID: 2508.12265
- Source URL: https://arxiv.org/abs/2508.12265
- Reference count: 40
- Presents comprehensive review of reasoning strategy selection in LLMs, proposing a novel taxonomy organized along fast/slow and internal/external knowledge boundaries

## Executive Summary
This paper presents a comprehensive review of reasoning strategy selection in large language models (LLMs), addressing the challenge of efficiently adapting reasoning approaches based on task demands. The authors propose a novel taxonomy organized along two knowledge boundaries: a fast/slow boundary distinguishing intuitive versus deliberative reasoning, and an internal/external boundary differentiating reasoning grounded in model parameters from tool-augmented thinking. Through systematic analysis, they categorize existing research based on key decision factors including model confidence, task complexity, and utility gain.

The review surveys methods ranging from implicit selection through supervised fine-tuning and reinforcement learning to explicit selection using rule-based heuristics and learned external routers. A unified formulation characterizes the reasoning strategy selection process, and the authors identify future research directions including pre-training foundations, unified selection mechanisms, reasoning orchestration systems, multimodal selection, personalized reasoning, and robustness considerations.

## Method Summary
The paper employs a systematic literature review methodology to analyze reasoning strategy selection approaches in LLMs. The authors organize existing research along two primary knowledge boundaries: fast/slow thinking (distinguishing intuitive from deliberative reasoning) and internal/external thinking (differentiating reasoning grounded in model parameters from tool-augmented approaches). They categorize methods based on decision factors such as model confidence, task complexity, and utility gain, and provide a unified formulation for reasoning strategy selection. The review synthesizes findings from 40 references to create a comprehensive taxonomy and identify research gaps.

## Key Results
- Proposes a novel taxonomy organizing reasoning strategies along fast/slow and internal/external knowledge boundaries
- Identifies key decision factors for strategy selection including confidence, complexity, and utility gain
- Surveys both implicit (SFT, RL) and explicit (rule-based, learned routers) selection mechanisms
- Provides unified formulation characterizing the reasoning strategy selection process
- Identifies future research directions including pre-training foundations and reasoning orchestration systems

## Why This Works (Mechanism)
The taxonomy framework works by providing a structured way to understand when different reasoning strategies are most appropriate. The fast/slow boundary captures the trade-off between quick, intuitive responses and slower, more deliberative reasoning that requires more computational resources but potentially higher accuracy. The internal/external boundary distinguishes between reasoning that can be performed using the model's existing parameters versus situations requiring external tools or knowledge sources. This dual-axis organization helps researchers and practitioners systematically evaluate which reasoning approaches are most suitable for different task characteristics and constraints.

## Foundational Learning
- **Fast vs. Slow Thinking**: Understanding the distinction between intuitive, quick responses and deliberative, resource-intensive reasoning is essential for optimizing LLM performance across different task types and computational constraints. Quick check: Can you identify examples of tasks that benefit from fast vs. slow reasoning?

- **Internal vs. External Thinking**: Recognizing when model parameters are sufficient versus when external tools or knowledge sources are needed is crucial for effective reasoning strategy selection. Quick check: What types of tasks require external tools versus those that can be solved internally?

- **Decision Factors**: Understanding how confidence, task complexity, and utility gain influence strategy selection helps in designing adaptive reasoning systems. Quick check: How would you measure task complexity for a given reasoning problem?

- **Implicit vs. Explicit Selection**: Knowing the trade-offs between learning-based approaches (SFT, RL) and rule-based or learned router approaches is important for system design. Quick check: What are the advantages and disadvantages of implicit versus explicit strategy selection?

## Architecture Onboarding
**Component Map:** Reasoning Strategy Selection System -> Decision Factors Assessment -> Strategy Router -> Reasoning Module (Fast/Slow, Internal/External) -> Output Evaluation

**Critical Path:** Input Task → Decision Factors Analysis → Strategy Selection → Reasoning Execution → Performance Evaluation → Strategy Update (if learning-based)

**Design Tradeoffs:** Implicit selection offers smoother adaptation but requires extensive training data, while explicit selection provides interpretability and control but may miss nuanced task requirements. Fast reasoning minimizes latency but risks accuracy, while slow reasoning maximizes accuracy but increases computational cost.

**Failure Signatures:** Poor strategy selection occurs when confidence thresholds are miscalibrated, task complexity is misestimated, or utility calculations are inaccurate. System failures manifest as either over-reliance on fast/simple strategies for complex tasks or excessive use of slow/complex strategies for simple tasks.

**3 First Experiments:**
1. Benchmark strategy selection performance across diverse reasoning tasks using both implicit and explicit selection mechanisms
2. Conduct ablation studies on decision factors to quantify their individual contributions to selection accuracy
3. Implement cross-task transfer learning to evaluate how well selection strategies generalize across different reasoning domains

## Open Questions the Paper Calls Out
The paper identifies several key open questions: How can pre-training foundations be established to better support reasoning strategy selection? What unified selection mechanisms can effectively combine implicit and explicit approaches? How can reasoning orchestration systems be designed to handle complex, multi-step reasoning tasks? What approaches enable effective multimodal selection across different data types? How can personalized reasoning strategies be developed for individual users or use cases? How can robustness be ensured when selection mechanisms face adversarial inputs or distribution shifts?

## Limitations
- The comprehensive scope may mask underlying methodological limitations in how reasoning strategies are evaluated and compared
- Lacks quantitative benchmarks demonstrating the effectiveness of the proposed taxonomy in real-world scenarios
- Relies on qualitative synthesis rather than systematic empirical validation, making it difficult to assess practical utility
- The review format inherently limits empirical validation of the proposed knowledge boundaries and framework

## Confidence
- **High**: The basic conceptual framework of organizing reasoning strategies along knowledge boundaries
- **Medium**: The systematic analysis of decision factors and categorization of existing research methods
- **Medium**: The identification of future research directions based on current literature gaps
- **Low**: Claims about the effectiveness of unified formulations and orchestration systems without empirical validation

## Next Checks
1. Conduct systematic empirical evaluation across diverse reasoning tasks to validate whether the proposed knowledge boundaries (fast/slow, internal/external) effectively capture strategy selection dynamics and lead to measurable performance improvements.

2. Implement and benchmark multiple selection mechanisms (implicit, explicit, and hybrid approaches) on standardized reasoning tasks to determine which approaches work best under specific conditions and task characteristics.

3. Design ablation studies to quantify the impact of different decision factors (confidence thresholds, task complexity measures, utility calculations) on strategy selection performance and identify optimal parameter settings for various reasoning domains.