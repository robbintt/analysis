---
ver: rpa2
title: 'Beyond Gemini-3-Pro: Revisiting LLM Routing and Aggregation at Scale'
arxiv_id: '2601.01330'
source_url: https://arxiv.org/abs/2601.01330
tags:
- llms
- aggregation
- routing
- jisi
- chen
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of surpassing state-of-the-art
  closed-source LLMs like Gemini-3-Pro through collaborative multi-agent systems.
  It identifies three key bottlenecks in current LLM routing and aggregation: limited
  query-based routing, static aggregation, and underutilization of routing-aggregation
  complementarity.'
---

# Beyond Gemini-3-Pro: Revisiting LLM Routing and Aggregation at Scale

## Quick Facts
- arXiv ID: 2601.01330
- Source URL: https://arxiv.org/abs/2601.01330
- Reference count: 18
- Surpassed Gemini-3-Pro by 1.15% accuracy while reducing costs by 53.23%

## Executive Summary
This paper tackles the challenge of surpassing state-of-the-art closed-source LLMs like Gemini-3-Pro through collaborative multi-agent systems. The authors identify three key bottlenecks in current LLM routing and aggregation: limited query-based routing, static aggregation, and underutilization of routing-aggregation complementarity. To address these issues, they propose JiSi, a training-free framework featuring three innovations: query-response mixed routing to capture semantic depth and difficulty, support-set-based aggregator selection to balance domain expertise and aggregation ability, and adaptive routing-aggregation switch to filter noise and enhance efficiency.

## Method Summary
JiSi introduces a training-free framework with three core components: (1) Query-Response Mixed Routing that leverages both query embeddings and response embeddings to capture semantic depth and difficulty; (2) Support-Set-based Aggregator Selection that identifies a subset of queries to find an optimal aggregator balancing domain expertise and aggregation ability; and (3) Adaptive Routing-Aggregation Switch that dynamically decides between direct routing and aggregation based on response quality thresholds. The framework was evaluated on nine benchmarks using ten open-source LLMs, demonstrating a 1.15% accuracy improvement over Gemini-3-Pro at 53% lower cost.

## Key Results
- Surpassed Gemini-3-Pro by 1.15% average accuracy across nine benchmarks
- Achieved 53.23% cost reduction compared to Gemini-3-Pro
- Outperformed baseline methods in both accuracy and efficiency metrics

## Why This Works (Mechanism)
The framework works by combining three complementary approaches that address limitations in existing LLM routing systems. Query-response mixed routing captures both the difficulty of the query and the semantic depth of potential responses, enabling more nuanced decision-making. The support-set-based aggregator selection ensures that the chosen aggregator has both domain expertise and aggregation capability by analyzing performance on similar queries. The adaptive routing-aggregation switch dynamically optimizes between routing and aggregation, reducing unnecessary computation for simple queries while leveraging collective intelligence for complex ones.

## Foundational Learning
- Query-response mixed routing: Why needed - Traditional routing only considers query embeddings, missing response quality signals; Quick check - Verify cosine similarity between query and response embeddings correlates with correctness
- Support-set selection mechanism: Why needed - Ensures aggregator selection is based on demonstrated expertise rather than theoretical capability; Quick check - Confirm selected support-set queries are semantically similar to the current query
- Adaptive switch threshold: Why needed - Balances computational efficiency with accuracy gains by avoiding aggregation for simple queries; Quick check - Monitor distribution of N_fm values across query difficulty levels

## Architecture Onboarding
**Component map:** Query -> Router -> (Direct Answer OR Aggregator) -> Final Answer
**Critical path:** Query embedding → Support-set selection → Aggregator selection → Response aggregation → Final answer
**Design tradeoffs:** Training-free approach vs. potential gains from fine-tuning; Single-turn processing vs. multi-turn capabilities
**Failure signatures:** 
- Router consistently selects same model across benchmarks (support-set filtering too aggressive)
- Aggregation performs worse than best single model (aggregator selection favors wrong expertise type)
- API costs exceed target (adaptive switch failing to route simple queries)

**First experiments:**
1. Implement support-set selection and verify it produces consistent base-query sets across multiple runs
2. Test router with known simple and complex queries to confirm adaptive switch behavior
3. Evaluate aggregator selection on a single benchmark using specified judges before scaling

## Open Questions the Paper Calls Out
### Open Question 1
Can the JiSi framework be extended to support multi-turn agentic workflows and interactive tool usage? The current implementation relies on packing all context into a single prompt, bypassing the complexity of state maintenance and tool usage required for general-purpose agents.

### Open Question 2
Is the framework robust in "wild" deployment scenarios where ground-truth labels are unavailable for building capability vectors? The system depends on pre-computed accuracy profiles to select aggregators and route queries, which may not exist for new, unlabeled data distributions.

### Open Question 3
Does the performance advantage persist if the candidate pool is expanded to include the proprietary models currently serving only as baselines? It is unclear if the routing logic holds when the cost and latency differentials between candidate models are drastically different.

## Limitations
- Relies on external judges for 6 of 9 benchmarks without clear evaluation protocols, creating uncertainty about result reproducibility
- Support-set selection mechanism's percentile threshold function introduces potential variability in base-query selection that could significantly impact routing quality
- The claim of being "training-free" requires substantial engineering to construct and maintain the embedding bank, representing an implicit form of training

## Confidence
- Accuracy improvement over Gemini-3-Pro: Medium confidence - results are presented with specific benchmarks but depend on unstated evaluation procedures for 6/9 benchmarks
- Cost reduction claims: Medium confidence - theoretical analysis provided but actual API usage patterns could vary significantly based on implementation details
- Training-free nature: High confidence - framework design is explicitly training-free with all components based on pre-trained models

## Next Checks
1. Reconstruct the embedding bank using the exact OpenRouterBench commit and verify the support-set selection produces consistent base-query sets across multiple runs with the same parameters
2. Implement the adaptive switch logic with detailed logging to confirm it achieves the stated cost reduction by falling back to routing for simple queries
3. Replicate the aggregator selection process on a subset of benchmarks using specified judges (DeepSeek-V3-0324 and o3-mini) to verify the 1.15% improvement claim before scaling to all 9 benchmarks