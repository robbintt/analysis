---
ver: rpa2
title: Enhancing Text-Based Hierarchical Multilabel Classification for Mobile Applications
  via Contrastive Learning
arxiv_id: '2507.04413'
source_url: https://arxiv.org/abs/2507.04413
tags:
- label
- labels
- level
- negative
- classification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of hierarchical multilabel classification
  of mobile applications using only their textual descriptions. The proposed solution,
  HMCN (Hierarchical Multilabel Classification Network) combined with HMCL (Hierarchical
  Multilabel Contrastive Learning), pretrains the text encoder to produce more discriminative
  embeddings.
---

# Enhancing Text-Based Hierarchical Multilabel Classification for Mobile Applications via Contrastive Learning

## Quick Facts
- arXiv ID: 2507.04413
- Source URL: https://arxiv.org/abs/2507.04413
- Authors: Jiawei Guo; Yang Xiao; Weipeng Huang; Guangyuan Piao
- Reference count: 40
- Key outcome: 80.75% micro-F1 and 48.62% macro-F1 on app dataset; 10.70% KS metric improvement in credit risk management deployment

## Executive Summary
This paper addresses the challenge of classifying mobile applications into hierarchical categories using only their textual descriptions. The authors propose HMCN (Hierarchical Multilabel Classification Network) combined with HMCL (Hierarchical Multilabel Contrastive Learning) to improve classification accuracy. HMCN integrates global and local classification strategies to handle the hierarchical nature of app categories, while HMCL uses contrastive learning to produce more discriminative text embeddings. The approach is evaluated on a Tencent App Store dataset and two public datasets, demonstrating significant improvements over state-of-the-art methods.

## Method Summary
The proposed solution consists of two main components: HMCN for hierarchical multilabel classification and HMCL for contrastive learning-based pretraining. HMCN employs a dual strategy that simultaneously considers both global category relationships and local hierarchical structures when classifying apps. The model uses a text encoder to process app descriptions and generate embeddings that capture semantic information relevant to the hierarchical labels. HMCL enhances these embeddings by pretraining the text encoder using contrastive learning objectives that are aware of the hierarchical label structure, forcing the model to learn more discriminative representations that respect the parent-child relationships between categories.

## Key Results
- Achieved 80.75% micro-F1 and 48.62% macro-F1 on the Tencent App Store dataset
- Demonstrated 10.70% improvement in Kolmogorov-Smirnov metric for credit risk management in real-world deployment
- Outperformed five state-of-the-art baselines including BERT-PT and PAMM across multiple datasets

## Why This Works (Mechanism)
The hierarchical structure of app categories creates complex relationships that traditional flat classification approaches fail to capture effectively. By explicitly modeling both global category relationships and local hierarchical structures, HMCN can better understand the semantic context of each category level. The HMCL component further enhances this by using contrastive learning to create embeddings that not only separate different categories but also respect their hierarchical relationships. This pretraining approach helps the model learn more robust and discriminative features from limited labeled data, which is particularly valuable in the app classification domain where obtaining comprehensive annotations can be expensive.

## Foundational Learning
- Hierarchical multilabel classification: Needed because apps can belong to multiple categories at different hierarchy levels simultaneously; quick check is whether the model can handle apps with multiple parent categories
- Contrastive learning: Required to learn discriminative embeddings without extensive labeled data; quick check is whether the contrastive objective improves separation between semantically similar but hierarchically different categories
- Text encoding for app descriptions: Essential since only textual descriptions are available as input; quick check is whether the embeddings capture both category-specific and hierarchical information

## Architecture Onboarding
Component map: Text encoder -> HMCL pretraining -> HMCN classification
Critical path: App description text -> Text encoder -> Contrastive learning (HMCL) -> Hierarchical classification (HMCN) -> Category predictions
Design tradeoffs: The model balances between computational efficiency (using text-only inputs) and classification accuracy (modeling hierarchical relationships); using contrastive learning reduces dependency on large labeled datasets but requires careful tuning of temperature parameters
Failure signatures: Poor performance on apps with ambiguous descriptions, misclassification of sibling categories, failure to capture fine-grained distinctions at lower hierarchy levels
First experiments: 1) Ablation study removing HMCL to measure contrastive learning impact, 2) Evaluation on apps with different description lengths to assess robustness, 3) Testing on out-of-distribution app categories to measure generalization

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation relies on proprietary Tencent App Store data, limiting reproducibility and generalizability
- Limited comparison with only five baseline methods may not comprehensively represent the state of the art
- Real-world deployment results lack detailed context about baseline systems and implementation conditions

## Confidence
Hierarchical classification performance: High
Contrastive learning benefits: Medium
Real-world deployment impact: Low

## Next Checks
1. Conduct ablation studies isolating the impact of hierarchical versus non-hierarchical contrastive learning objectives, and compare against standard contrastive learning methods like SimCLR or MoCo applied to the same task.
2. Evaluate the model on additional publicly available app datasets with different characteristics (e.g., Google Play Store apps, open-source software repositories) to assess generalizability beyond the Tencent dataset.
3. Perform a detailed error analysis on failure cases, particularly focusing on misclassifications at different hierarchy levels, to understand whether the model struggles with specific types of hierarchical relationships or label combinations.