---
ver: rpa2
title: Convergence dynamics of Agent-to-Agent Interactions with Misaligned objectives
arxiv_id: '2511.08710'
source_url: https://arxiv.org/abs/2511.08710
tags:
- agent
- objective
- agents
- each
- convergence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We present a mechanistic framework for analyzing agent-to-agent
  interactions in a simplified in-context linear regression setting. In our model,
  each agent is implemented as a single-layer transformer with linear self-attention
  trained to perform gradient-descent-like updates on quadratic regression objectives.
---

# Convergence dynamics of Agent-to-Agent Interactions with Misaligned objectives

## Quick Facts
- arXiv ID: 2511.08710
- Source URL: https://arxiv.org/abs/2511.08710
- Reference count: 40
- Primary result: Objective misalignment in agent-to-agent interactions leads to biased equilibrium where neither agent reaches its target, with residual errors predictable from the objective gap and prompt-induced geometry.

## Executive Summary
This paper presents a mechanistic framework for analyzing agent-to-agent interactions in a simplified in-context linear regression setting. The authors model each agent as a single-layer transformer with linear self-attention trained to perform gradient-descent-like updates on quadratic regression objectives. They analyze the coupled dynamics when two such agents alternately update from each other's outputs under potentially misaligned fixed objectives.

The key insight is that objective misalignment induces predictable bias in the convergence dynamics, where agents reach equilibrium points that are suboptimal for both parties. The framework provides explicit expressions for limiting errors that depend jointly on the objective misalignment and the anisotropic geometry of agent-specific prompts. This reveals a fundamental tension in multi-agent systems: the same interaction interface that enables cooperation can also lead to mutual degradation when objectives are misaligned.

## Method Summary
The authors construct a simplified model where each agent is implemented as a single-layer transformer with linear self-attention, trained to perform gradient-descent-like updates on quadratic regression objectives. The framework analyzes the coupled dynamics when two such agents alternately update from each other's outputs under potentially misaligned fixed objectives. The theoretical analysis derives explicit expressions for equilibrium errors and characterizes conditions for asymmetric convergence. Empirical validation is performed using trained LSA agents and GPT-5-mini to demonstrate the predictive power of the framework.

## Key Results
- Objective misalignment leads to biased equilibrium where neither agent reaches its target, with residual errors predictable from the objective gap and prompt-induced geometry
- Explicit expressions for each agent's limiting error show convergence plateaus are determined jointly by objective misalignment and anisotropic prompt geometry
- Normalized plateau errors are non-decreasing functions of the alignment angle between objectives, providing a predictive lens on non-cooperative agent-to-agent interactions
- Conditions exist for asymmetric convergence where one agent can attain its objective exactly while the other suffers persistent bias

## Why This Works (Mechanism)

The framework works by analyzing the coupled dynamics of two agents with linear self-attention performing alternating updates on misaligned objectives. When agents exchange outputs under objective misalignment, each update incorporates both its own optimization signal and the other agent's biased perspective. This creates a feedback loop where the equilibrium point is shifted away from either agent's true optimum. The linear self-attention structure enables analytical tractability, allowing explicit characterization of how objective misalignment and prompt geometry jointly determine the convergence plateau.

## Foundational Learning

- **Linear Self-Attention Transformers**: Why needed: Enables analytical tractability for deriving convergence dynamics. Quick check: Verify gradient descent-like behavior through gradient analysis of self-attention weights.

- **Quadratic Objective Structure**: Why needed: Simplifies optimization dynamics to closed-form expressions. Quick check: Confirm convexity ensures unique minimum and predictable gradient flow.

- **Alternating Update Protocol**: Why needed: Models realistic turn-based agent interactions. Quick check: Analyze stability conditions for different update frequencies.

- **Objective Misalignment Geometry**: Why needed: Captures how directional differences in objectives affect convergence. Quick check: Measure angle between objectives and correlate with plateau errors.

## Architecture Onboarding

Component Map: Linear Transformer Agent -> Quadratic Objective -> Alternating Update Protocol -> Coupled Dynamics

Critical Path: Agent output generation → objective gradient computation → parameter update → exchange with other agent → repeat

Design Tradeoffs: Linear self-attention enables analytical tractability but limits expressiveness; quadratic objectives simplify analysis but may not capture complex real-world scenarios; alternating updates model turn-based interactions but may miss continuous feedback dynamics.

Failure Signatures: Persistent bias in convergence plateaus indicates objective misalignment; asymmetric convergence suggests exploitable geometry in prompt structures; oscillation patterns may indicate unstable interaction protocols.

First Experiments:
1. Test convergence dynamics with perfectly aligned objectives to establish baseline behavior
2. Vary objective misalignment angles systematically to validate predictive error expressions
3. Compare single-step vs multi-step update protocols to assess interaction frequency effects

## Open Questions the Paper Calls Out

None

## Limitations

- The framework relies on linear self-attention and quadratic objective assumptions, which may not generalize to more complex architectures and objectives
- Theoretical analysis assumes alternating single-step updates without feedback between agents, potentially oversimplifying real interaction protocols
- Empirical validation is limited to synthetic LSA agents and GPT-5-mini, constraining generalizability to other model architectures

## Confidence

High: The convergence analysis under linear self-attention and quadratic objectives is mathematically rigorous with explicit error expressions derived from first principles.

Medium: The predictive framework for plateau errors based on objective misalignment angle shows strong qualitative agreement with experiments, but quantitative predictions may be sensitive to specific prompt geometries.

Low: The Newton-like acceleration mechanism through turn-based objective adaptation has limited empirical validation, and practical implications for cooperative optimization require further investigation.

## Next Checks

1. Test the predictive accuracy of plateau error expressions across diverse prompt geometries and objective misalignments using a systematic grid of LSA agents with varying initialization conditions.

2. Validate the asymmetric convergence conditions with multi-step update protocols and compare against single-step alternating dynamics to assess robustness to interaction frequency.

3. Implement and evaluate the Newton-like acceleration mechanism with non-quadratic objectives and more complex interaction patterns, measuring the trade-off between cooperative gains and convergence stability.