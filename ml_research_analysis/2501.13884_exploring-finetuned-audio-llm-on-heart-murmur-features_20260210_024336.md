---
ver: rpa2
title: Exploring Finetuned Audio-LLM on Heart Murmur Features
arxiv_id: '2501.13884'
source_url: https://arxiv.org/abs/2501.13884
tags:
- heart
- audio
- arxiv
- features
- murmur
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a novel approach to heart murmur analysis by
  fine-tuning a large language model (LLM) for audio, specifically Qwen2-Audio, on
  the PhysioNet CirCor DigiScope phonocardiogram (PCG) dataset. The authors aim to
  classify 11 expert-labeled murmur features, including timing, grading, harshness,
  pitch, and quality, which are crucial for diagnosing underlying heart conditions.
---

# Exploring Finetuned Audio-LLM on Heart Murmur Features

## Quick Facts
- arXiv ID: 2501.13884
- Source URL: https://arxiv.org/abs/2501.13884
- Authors: Adrian Florea; Xilin Jiang; Nima Mesgarani; Xiaofan Jiang
- Reference count: 40
- Primary result: LLM-based model outperforms state-of-the-art methods in 8 of 11 heart murmur feature classifications

## Executive Summary
This paper proposes a novel approach to heart murmur analysis by fine-tuning a large language model (LLM) for audio, specifically Qwen2-Audio, on the PhysioNet CirCor DigiScope phonocardiogram (PCG) dataset. The authors aim to classify 11 expert-labeled murmur features, including timing, grading, harshness, pitch, and quality, which are crucial for diagnosing underlying heart conditions. To enhance noise robustness and generalizability, they incorporate a preprocessing segmentation algorithm using the audio representation model, SSAMBA. The results demonstrate that the LLM-based model outperforms state-of-the-art methods in 8 of the 11 features and performs comparably in the remaining 3. Moreover, the LLM successfully classifies long-tail murmur features with limited training data, a task that previous methods have failed to accomplish. These findings highlight the potential of audio LLMs as valuable tools for cardiologists in enhancing heart disease diagnosis.

## Method Summary
The study fine-tunes Qwen2-Audio on the PhysioNet CirCor DigiScope phonocardiogram dataset to classify 11 expert-labeled heart murmur features. A preprocessing segmentation algorithm using SSAMBA is applied to improve noise robustness and generalizability. The LLM-based approach is compared against state-of-the-art methods across all 11 murmur features, with particular focus on performance with limited training data for long-tail features.

## Key Results
- LLM-based model outperforms state-of-the-art methods on 8 of 11 heart murmur features
- Successfully classifies long-tail murmur features with limited training data
- Performs comparably to state-of-the-art methods on the remaining 3 features

## Why This Works (Mechanism)
The approach leverages the multimodal capabilities of Qwen2-Audio, which has been pre-trained on diverse audio data, allowing it to capture complex acoustic patterns in heart sounds. The fine-tuning process adapts this general audio understanding to the specific domain of heart murmurs. The SSAMBA preprocessing algorithm enhances the model's ability to handle real-world noise and variability in clinical recordings, while the LLM's inherent capability to process sequential data makes it well-suited for analyzing the temporal characteristics of heart sounds.

## Foundational Learning
1. **Phonocardiogram (PCG) analysis** - Why needed: Provides the clinical foundation for understanding heart sounds and murmurs. Quick check: Can you identify S1, S2, and murmur components in a PCG waveform?
2. **Audio representation learning** - Why needed: Enables the model to extract meaningful features from raw audio signals. Quick check: Do you understand how audio embeddings capture both spectral and temporal information?
3. **Long-tail learning** - Why needed: Critical for handling rare murmur features that are clinically important but underrepresented in training data. Quick check: Can you explain the challenge of learning from imbalanced datasets?
4. **Multimodal LLM adaptation** - Why needed: Allows leveraging pre-trained models for specialized medical audio classification tasks. Quick check: Do you understand how fine-tuning differs from training from scratch?
5. **Medical signal preprocessing** - Why needed: Improves model robustness to real-world noise and variability in clinical recordings. Quick check: Can you describe common preprocessing steps for biomedical signals?
6. **Feature classification in cardiology** - Why needed: Provides context for why classifying 11 specific murmur features is clinically relevant. Quick check: Do you know how murmur characteristics relate to specific heart conditions?

## Architecture Onboarding

**Component Map:**
Qwen2-Audio (pre-trained LLM) -> SSAMBA Preprocessing -> Fine-tuning on PCG dataset -> 11-class murmur feature classification

**Critical Path:**
Audio input → SSAMBA segmentation → Feature extraction → LLM processing → Classification layer → 11 murmur feature outputs

**Design Tradeoffs:**
- Using a pre-trained LLM reduces training time and data requirements but may introduce unnecessary complexity
- SSAMBA preprocessing adds computational overhead but significantly improves noise robustness
- 11-class classification increases clinical utility but also increases model complexity and potential for confusion between similar features

**Failure Signatures:**
- Misclassification of similar murmur features (e.g., harsh vs. musical)
- Sensitivity to recording quality despite preprocessing
- Overconfidence in predictions for rare feature classes

**First 3 Experiments:**
1. Ablation study: Compare performance with and without SSAMBA preprocessing
2. Class activation mapping: Visualize which audio segments influence each classification decision
3. Limited data test: Train on 10%, 25%, and 50% of available data to assess data efficiency

## Open Questions the Paper Calls Out
None

## Limitations
- Limited to a single dataset (PhysioNet CirCor DigiScope), potentially missing real-world clinical diversity
- Comparison with "state-of-the-art methods" constrained by available literature
- Focus on expert-labeled features without validation against clinical outcomes or diagnostic accuracy
- Computational requirements and inference time not discussed, critical for clinical deployment

## Confidence

**High Confidence:**
- LLM outperforms state-of-the-art methods on 8 of 11 murmur features

**Medium Confidence:**
- Superior performance on long-tail features with limited training data
- SSAMBA preprocessing significantly improves noise robustness and generalizability

## Next Checks
1. External validation on multiple independent heart sound datasets to assess generalizability across different recording conditions and patient populations
2. Ablation studies to quantify the specific contribution of the SSAMBA preprocessing compared to other denoising approaches
3. Clinical validation study with cardiologists to evaluate whether the LLM classifications improve diagnostic accuracy or workflow efficiency compared to current clinical practice