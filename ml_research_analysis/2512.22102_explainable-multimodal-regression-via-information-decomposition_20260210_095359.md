---
ver: rpa2
title: Explainable Multimodal Regression via Information Decomposition
arxiv_id: '2512.22102'
source_url: https://arxiv.org/abs/2512.22102
tags:
- information
- multimodal
- pidreg
- regression
- modality
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PIDReg introduces a novel multimodal regression framework that
  leverages Partial Information Decomposition (PID) to provide intrinsic interpretability
  of modality contributions and interactions. By enforcing Gaussianity in the joint
  distribution of modality-specific representations and the target variable, PIDReg
  analytically computes PID components (unique, redundant, and synergistic information)
  even in high-dimensional continuous settings.
---

# Explainable Multimodal Regression via Information Decomposition

## Quick Facts
- arXiv ID: 2512.22102
- Source URL: https://arxiv.org/abs/2512.22102
- Authors: Zhaozhao Ma; Shujian Yu
- Reference count: 40
- Primary result: Introduces PIDReg framework that decomposes multimodal regression predictions into unique, redundant, and synergistic information components via Gaussian PID estimation

## Executive Summary
PIDReg introduces a novel multimodal regression framework that leverages Partial Information Decomposition (PID) to provide intrinsic interpretability of modality contributions and interactions. By enforcing Gaussianity in the joint distribution of modality-specific representations and the target variable, PIDReg analytically computes PID components (unique, redundant, and synergistic information) even in high-dimensional continuous settings. A closed-form conditional independence regularizer promotes isolation of unique information within each modality. Evaluated on six real-world datasets across diverse domains, PIDReg outperforms six state-of-the-art methods in predictive accuracy and interpretability.

## Method Summary
PIDReg employs a two-stage optimization process. First, modality encoders map raw inputs to embeddings, which are then transformed into Gaussian-like latent representations through a linear noise bottleneck. The PID module estimates the covariance of the joint distribution of latent codes and target, solving a convex optimization problem to determine fusion weights that decompose information into unique, redundant, and synergistic components. The fusion layer combines these weighted representations using Hadamard products for synergy modeling. Second, after PID convergence, the fusion weights are fixed and the full network is trained end-to-end. Regularization terms enforce Gaussianity of latent representations and conditional independence between modalities to ensure clean decomposition of information atoms.

## Key Results
- Achieves MAE of 6.29 years and Corr of 0.75 on brain age prediction from multimodal neuroimaging, aligning with clinical evidence
- Outperforms six state-of-the-art methods across six real-world datasets in both predictive accuracy and interpretability
- Successfully recovers known ground-truth information ratios in synthetic data validation experiments
- Demonstrates informed modality selection capability for efficient inference

## Why This Works (Mechanism)

### Mechanism 1: Gaussianity as a Computational Constraint for PID
Enforcing a multivariate Gaussian distribution on latent representations and the target analytically resolves the underdetermined nature of Partial Information Decomposition (PID). The framework applies inverse normal transformation to the target $Y$ and uses Cauchy-Schwarz (CS) divergence to regularize latent embeddings $Z_1, Z_2$ toward Gaussianity. Under this constraint, mutual information terms become functions of covariance matrices (Eq. 5), allowing a closed-form optimization for "Union Information" rather than requiring intractable density estimation.

### Mechanism 2: Conditional Independence for Disentangling Unique Information
Minimizing the conditional mutual information (CMI) between a modality's latent code and the other modality's raw input forces the encoder to isolate unique predictive features. A CS divergence-based regularizer minimizes $I(Z_1; X_2 | X_1)$ and $I(Z_2; X_1 | X_2)$. This theoretically enforces $p(Z_1|X_1, X_2) \approx p(Z_1|X_1)$, ensuring that $Z_1$ does not "leak" information that belongs to $X_2$.

### Mechanism 3: Explicit Synergy Modeling via Interaction Features
Synergistic information can be approximated by the Hadamard product of latent codes, provided those codes are regularized for uniqueness. The fusion module constructs a pseudo-representation $\tilde{Z} = Z_1 \odot Z_2$. By regularizing $Z_1$ and $Z_2$ to be unique, the element-wise product highlights cross-dimensional couplings that would not exist in either modality alone.

## Foundational Learning

- **Concept: Partial Information Decomposition (PID)**
  - Why needed here: Standard multimodal fusion treats information as a monolith. PID splits information into Unique, Redundant, and Synergistic atoms, which defines the architecture's loss functions.
  - Quick check question: If $I(Y; Z_1) = 0.5$ and $I(Y; Z_1, Z_2) = 0.8$, does the difference $0.3$ represent pure synergy?

- **Concept: Cauchy-Schwarz (CS) Divergence**
  - Why needed here: The paper uses CS divergence instead of KL divergence or MMD for regularization. Understanding this is critical to implementing the Gaussianity and independence losses.
  - Quick check question: Why might CS divergence be more stable than KL divergence when supports of distributions have limited overlap?

- **Concept: Inverse Normal Transformation**
  - Why needed here: The Gaussian PID assumption requires the target $Y$ to be Gaussian. Since real-world targets (like age) are often not Gaussian, this transformation is a preprocessing requirement.
  - Quick check question: How does transforming the target variable affect the interpretability of the regression error (e.g., MAE)?

## Architecture Onboarding

- **Component map:** Raw Inputs $\to$ Modality Encoders ($h_\phi$) $\to$ Linear Noise IB $\to$ Gaussian-like Latents ($Z$) $\to$ PID Module $\to$ Fusion Weights $(w_1, w_2, w_3)$ $\to$ Fusion Layer $\to$ Predictor ($f_\theta$) $\to$ $\hat{Y}$

- **Critical path:** The stability of the PID Module is the system bottleneck. If the covariance matrices are degenerate or the regularizers ($L_{CS}, L_{Gauss}$) are too weak, the "Union Information" optimization may fail, leading to meaningless fusion weights.

- **Design tradeoffs:**
  - Gaussianity vs. Capacity: Enforcing Gaussian latents via CS divergence reduces the capacity of the encoders to model complex, multi-modal distributions in the raw data.
  - Hadamard vs. Tensor Fusion: The paper chooses Hadamard for $O(d)$ efficiency and stability, sacrificing the potentially higher representational power of $O(d^2)$ tensor fusion.

- **Failure signatures:**
  - Weight Oscillation: Fusion weights $w$ fail to converge during Stage 1. Fix: Increase batch size for better covariance estimation or increase $\lambda_3$ (Gaussianity regularizer).
  - Synergy Collapse: $w_3 \to 0$ even when modalities are known to interact. Check: Verify CMI regularizer isn't enforcing too much independence, destroying interaction signals.
  - Target Non-Gaussianity: If $L_{Gauss}$ remains high, the PID decomposition is theoretically invalid. Check: Ensure Inverse Normal Transformation is applied correctly to $Y$.

- **First 3 experiments:**
  1. Synthetic Validation: Generate data with known $U, R, S$ ratios (per Section 4.1). Verify if PIDReg recovers the correct ratios.
  2. Ablation of CMI: Train without $L_{CMI}$. Probe if $Z_1$ can predict $X_2$ (information leakage) using a simple MLP, as described in Appendix D.1.2.
  3. Modality Drop: Train on a dataset with a dominant modality (e.g., Vision in Vision&Touch). Verify if PIDReg assigns near-zero weight to the weak modality, confirming interpretability aligns with performance.

## Open Questions the Paper Calls Out

- How can the PIDReg framework be adapted to provide sample-level (instance-level) interpretability for individual predictions, rather than aggregate modality-level contributions?
- Can the framework's reliance on a continuous Gaussian joint distribution be effectively maintained when extending PIDReg to multimodal classification tasks with discrete targets?
- How does the "pragmatic simplification" of aggregating PID atoms (redundancy/synergy) affect the faithfulness of the decomposition when scaling to four or more modalities?

## Limitations

- The Gaussianity assumption may oversimplify complex, non-linear dependencies in real-world data, potentially leading to suboptimal PID estimates.
- The Hadamard product fusion assumes synergy manifests as simple multiplicative interactions, which may not capture higher-order or sub-additive synergies present in some datasets.
- Results are heavily dependent on hyperparameter tuning (Î» values, learning rates, batch sizes), and performance may degrade if these are not optimally set for new datasets.

## Confidence

- **High Confidence:** Predictive performance claims (MAE, Corr) on the evaluated datasets, as they are directly measured.
- **Medium Confidence:** The interpretability claims regarding modality contributions (U, R, S ratios), as they rely on the validity of the Gaussian PID approximation.
- **Low Confidence:** The generalizability of the fusion weight patterns to completely unseen modalities or tasks, as the framework is primarily validated on the six specific datasets.

## Next Checks

1. **Synthetic Stress Test:** Generate a synthetic dataset with known, analytically tractable PID components (e.g., XOR-like synergy or pure redundancy) to verify if PIDReg recovers the correct U, R, S ratios under controlled conditions.
2. **High-Dimensional Modality Test:** Evaluate PIDReg on a dataset with significantly more than two modalities (e.g., adding PET imaging to the MDD dataset) to test the scalability and interpretability of the framework beyond the binary modality case.
3. **Non-Gaussianity Robustness:** Apply PIDReg to a dataset known for heavy-tailed or multi-modal target distributions (e.g., financial time series) to assess the robustness of the Gaussianity assumption and the resulting PID estimates.