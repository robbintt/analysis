---
ver: rpa2
title: Characterising Topic Familiarity and Query Specificity Using Eye-Tracking Data
arxiv_id: '2505.03136'
source_url: https://arxiv.org/abs/2505.03136
tags:
- query
- familiarity
- data
- specificity
- topic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of characterizing user topic familiarity
  and query specificity in search using only eye-tracking data. The core method idea
  involves using pupil dilation and gaze velocity data collected via eye-tracking
  to predict these cognitive states, without relying on additional contextual information.
---

# Characterising Topic Familiarity and Query Specificity Using Eye-Tracking Data

## Quick Facts
- arXiv ID: 2505.03136
- Source URL: https://arxiv.org/abs/2505.03136
- Reference count: 40
- Primary result: Achieved 71.25% Macro F1 for topic familiarity prediction and 60.54% for query specificity using only eye-tracking data

## Executive Summary
This paper presents a novel approach to characterizing user topic familiarity and query specificity in search tasks using eye-tracking data. The study addresses the challenge of understanding user cognitive states during information seeking without relying on additional contextual information. By developing a machine learning pipeline that analyzes pupil dilation and gaze velocity patterns, the authors demonstrate that eye-tracking features can effectively predict whether users are familiar with a topic and whether their queries are specific or non-specific. The research introduces a new annotation guideline for query specificity classification and validates its effectiveness through empirical experiments with 18 participants.

## Method Summary
The authors collected eye-tracking data from 18 participants as they performed search tasks involving natural language questions. They extracted features from pupil dilation and gaze velocity data, then trained machine learning classifiers including Gradient Boosting and K-Nearest Neighbors to predict topic familiarity and query specificity. The study developed a novel annotation guideline for classifying queries as Specific or Non-specific, particularly tailored for natural language questions. The classification models were evaluated using Macro F1 scores to assess their performance in predicting the two cognitive states of interest.

## Key Results
- Achieved 71.25% Macro F1 score for predicting topic familiarity
- Achieved 60.54% Macro F1 score for predicting query specificity
- Demonstrated that eye-tracking features alone can predict user cognitive states during search tasks

## Why This Works (Mechanism)
The approach leverages the physiological responses captured through eye-tracking, specifically pupil dilation and gaze velocity, which correlate with cognitive processing load and attention patterns. When users are familiar with a topic, their cognitive load during search differs from when they are unfamiliar, resulting in distinct eye movement patterns. Similarly, the specificity of queries manifests in different search behaviors that can be captured through these eye-tracking metrics. The machine learning classifiers learn to recognize these patterns, enabling prediction of user cognitive states without requiring additional contextual information.

## Foundational Learning

**Eye-Tracking Data Collection**
- Why needed: To capture physiological indicators of cognitive processing during search tasks
- Quick check: Verify eye-tracker calibration accuracy before each session

**Feature Extraction from Eye Movements**
- Why needed: To transform raw eye-tracking data into meaningful features for machine learning
- Quick check: Validate feature extraction code produces expected statistical distributions

**Query Specificity Annotation**
- Why needed: To create labeled training data for predicting query formulation behavior
- Quick check: Apply annotation guidelines to sample queries and verify consistency

**Machine Learning Classification**
- Why needed: To learn patterns in eye-tracking features that predict cognitive states
- Quick check: Evaluate model performance using cross-validation before final testing

## Architecture Onboarding

Component Map: Eye Tracker -> Feature Extractor -> Classifier -> Prediction Output

Critical Path: Data Collection → Feature Extraction → Model Training → Evaluation

Design Tradeoffs: Model complexity vs. interpretability, feature richness vs. computational efficiency

Failure Signatures: Poor calibration leading to noisy features, insufficient training data causing overfitting

First Experiments:
1. Test basic feature extraction pipeline on sample eye-tracking data
2. Train initial classifier on small labeled dataset to validate approach
3. Perform ablation study to identify most predictive features

## Open Questions the Paper Calls Out
None

## Limitations
- Small sample size of 18 participants limits generalizability
- Simulated search tasks may not reflect real-world search behavior
- Annotation process conducted by authors without inter-rater reliability measures

## Confidence

High confidence in methodological approach for feature extraction from eye-tracking data
Medium confidence in classification performance metrics due to limited sample size
Medium confidence in annotation guidelines' effectiveness without external validation
Low confidence in real-world applicability without testing in naturalistic search environments

## Next Checks

1. Conduct a replication study with a larger, more diverse participant pool (n > 50) across different demographics and search expertise levels
2. Test the classification models on real-world search engine query logs with actual user search behavior, rather than controlled experimental conditions
3. Implement inter-rater reliability testing for the query specificity annotation guidelines with multiple independent annotators to establish reliability scores