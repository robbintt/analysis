---
ver: rpa2
title: Bangla Music Genre Classification Using Bidirectional LSTMS
arxiv_id: '2601.15083'
source_url: https://arxiv.org/abs/2601.15083
tags:
- music
- classification
- genre
- bangla
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a novel Bangla music genre classification
  framework using Bidirectional LSTM networks. The approach addresses the challenge
  of categorizing Bangla music across ten distinct genres by leveraging Mel-Frequency
  Cepstral Coefficients (MFCCs) as acoustic features.
---

# Bangla Music Genre Classification Using Bidirectional LSTMs

## Quick Facts
- arXiv ID: 2601.15083
- Source URL: https://arxiv.org/abs/2601.15083
- Reference count: 25
- Primary result: 78% classification accuracy on Bangla music genre classification

## Executive Summary
This study presents a novel framework for Bangla music genre classification using Bidirectional LSTM (BiLSTM) networks. The research addresses the challenge of categorizing Bangla music across ten distinct genres by extracting Mel-Frequency Cepstral Coefficients (MFCCs) as acoustic features and processing them through a bidirectional sequential model. The BiLSTM architecture captures temporal dependencies in both forward and backward directions, enabling effective pattern recognition across musical sequences. The framework demonstrates superior performance compared to conventional machine learning methods, achieving 78% accuracy with particularly strong results on specific genres like Lalon Geet and Polli Geeti.

## Method Summary
The framework processes Bangla music audio files by extracting MFCCs as feature vectors representing the acoustic characteristics of each track. These feature sequences are fed into a BiLSTM network that processes the temporal data in both directions, capturing context from past and future frames simultaneously. The model architecture consists of multiple BiLSTM layers followed by dense layers for classification into ten Bangla music genres. The system was trained and evaluated on a curated dataset of Bangla music, with performance measured using accuracy and F1-score metrics. The bidirectional processing allows the network to understand musical patterns that depend on both preceding and following temporal contexts, which is particularly important for genre-specific musical structures.

## Key Results
- Achieved 78% overall classification accuracy across ten Bangla music genres
- Outperformed traditional ML methods: Logistic Regression (64%), SVM (21%), K-NN (45%), and ANN (72%)
- Highest individual genre performance on Lalon Geet (F1-score 0.91) and Polli Geeti (F1-score 0.86)

## Why This Works (Mechanism)
The BiLSTM architecture effectively captures the temporal dependencies inherent in musical sequences by processing audio features in both forward and backward directions. This bidirectional processing allows the network to understand context from both past and future frames, which is crucial for recognizing genre-specific musical patterns that may span across temporal boundaries. The MFCC features provide a compact representation of the spectral envelope and timbre characteristics that distinguish different musical genres, while the sequential processing enables the model to learn patterns that evolve over time within each track.

## Foundational Learning
- **Mel-Frequency Cepstral Coefficients (MFCCs)**: Audio features representing the short-term power spectrum of sound, capturing timbre and spectral characteristics. Why needed: Provides compact, discriminative representation of musical audio. Quick check: Verify proper window size and overlap parameters during extraction.
- **Bidirectional LSTM Networks**: Neural architecture processing sequences in both forward and backward directions. Why needed: Captures temporal dependencies that depend on both past and future contexts. Quick check: Confirm bidirectional processing improves performance over unidirectional LSTM.
- **Music Genre Classification**: Task of categorizing music tracks into predefined genre categories. Why needed: Enables automated organization and recommendation of music libraries. Quick check: Ensure genre labels are consistent and mutually exclusive.
- **Sequential Feature Processing**: Method of analyzing time-series data where order matters. Why needed: Music patterns unfold over time and require temporal understanding. Quick check: Validate sequence length and batch processing parameters.

## Architecture Onboarding

**Component Map**: Audio files -> MFCC Extraction -> BiLSTM Layers -> Dense Layers -> Genre Classification

**Critical Path**: Raw audio -> MFCC feature extraction -> BiLSTM sequential processing -> Dense layer classification -> Genre output

**Design Tradeoffs**: The choice of MFCCs balances computational efficiency with sufficient acoustic information, while the bidirectional processing increases model complexity but captures more contextual information. The architecture prioritizes temporal understanding over spatial feature extraction, which is appropriate for sequential musical data.

**Failure Signatures**: Poor performance on underrepresented genres may indicate class imbalance or insufficient feature representation. High variance across genre F1-scores suggests the model may be overfitting to certain musical patterns while struggling with others that have less distinctive temporal characteristics.

**First Experiments**:
1. Compare unidirectional vs bidirectional LSTM performance using identical feature sets
2. Test alternative acoustic features (spectral contrast, chroma) alongside MFCCs
3. Evaluate model performance with different sequence lengths and window sizes

## Open Questions the Paper Calls Out
None

## Limitations
- Dataset composition and preprocessing details are unclear, affecting reproducibility
- Results lack cross-validation metrics and statistical significance testing
- Framework focuses solely on MFCCs, potentially missing complementary feature information

## Confidence

**Major Claim Clusters and Confidence:**

- BiLSTM architecture effectiveness (Medium confidence): Results show superior performance to traditional methods, but lack of ablation studies or comparison with other deep learning architectures limits confidence.
- Genre classification performance (Medium confidence): Individual genre F1-scores vary significantly, suggesting potential class imbalance or feature representation issues.
- Framework generalizability (Low confidence): No external validation on different datasets or real-world implementation testing.

## Next Checks

1. Conduct cross-validation with multiple dataset splits and report statistical significance tests to verify the robustness of the 78% accuracy claim.

2. Implement ablation studies comparing BiLSTM with other deep learning architectures (CNN, GRU) using identical feature sets and preprocessing.

3. Test the framework on an independent Bangla music dataset to evaluate real-world generalizability and identify potential overfitting to the training data.