---
ver: rpa2
title: Mitigating Label Length Bias in Large Language Models
arxiv_id: '2511.14385'
source_url: https://arxiv.org/abs/2511.14385
tags:
- label
- labels
- calibration
- bias
- length
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper identifies a previously overlooked issue called label
  length bias in large language models, where predictions are biased toward labels
  of certain lengths rather than based on semantic alignment with the input. Existing
  calibration methods fail to address this bias, especially for multi-token class
  labels.
---

# Mitigating Label Length Bias in Large Language Models

## Quick Facts
- **arXiv ID:** 2511.14385
- **Source URL:** https://arxiv.org/abs/2511.14385
- **Reference count:** 40
- **Primary result:** Proposed NCC method achieves up to 10% F1 improvement over prior calibration methods on multi-token label datasets

## Executive Summary
This paper identifies label length bias in large language models, where predictions are systematically biased toward shorter labels regardless of semantic alignment. Standard calibration methods fail to address this bias, particularly for multi-token class labels. The authors propose normalized contextual calibration (NCC), which normalizes label probabilities by token count and calibrates using baseline probabilities from content-free inputs. NCC achieves statistically significant improvements across multiple datasets and models, extending beyond text classification to tasks like multiple-choice question answering. The method also demonstrates greater robustness to few-shot example selection and requires fewer examples for competitive performance.

## Method Summary
Normalized Contextual Calibration (NCC) computes label probabilities by first calculating the joint probability of all tokens in a label, then normalizing by the geometric mean of token probabilities to remove length bias. This normalized probability is divided by a baseline prior estimated from content-free inputs (empty string, "N/A", "Lorem ipsum", etc.) to calibrate for intrinsic label biases. The method operates in zero-shot and few-shot settings, requiring one-time baseline computation per label set. NCC is designed specifically for autoregressive LLMs and addresses the fundamental issue that longer labels receive systematically lower probabilities due to multiplicative probability decay across tokens.

## Key Results
- NCC achieves up to 10% F1 improvement over prior calibration methods on multi-token label datasets
- NCC reduces sensitivity to few-shot example selection, with coefficient of variation dropping from 0.103 to 0.058
- NCC extends beyond text classification to multiple-choice question answering tasks
- NCC requires fewer examples for competitive performance compared to standard approaches

## Why This Works (Mechanism)

### Mechanism 1
Joint probability computation systematically penalizes longer multi-token labels regardless of semantic fit. Standard LLM label probability computes P(y|x) = ∏P(tᵢ|context, t₁...tᵢ₋₁), where each additional token multiplies by a value <1, so longer labels receive lower raw probabilities by construction. Length normalization converts this product to a geometric mean (ⁿ√P(y|x)), removing the token-count penalty.

### Mechanism 2
Length normalization alone creates a new bias toward labels with predictable token continuations. After normalization, labels where later tokens are highly conditioned on earlier ones (e.g., "Finance" after "Business &") receive inflated scores because conditional probabilities approach certainty. Calibration divides normalized probabilities by baseline probabilities from content-free inputs (empty string, "N/A", etc.), removing intrinsic label biases unrelated to input.

### Mechanism 3
Full-label calibration is necessary because first-token-only approaches lose semantic distinction and over-generalize. Prior calibration used only the first token of multi-token labels (e.g., "Ab" for "Abbreviation"), which conflates different labels sharing first tokens and ignores probability mass from the full sequence. NCC computes joint probability over all tokens before normalization and calibration.

## Foundational Learning

- **Autoregressive probability factorization** (P(sequence) = ∏P(tᵢ|t<tᵢ)): Label length bias emerges directly from how LLMs compute multi-token probabilities; understanding this is prerequisite to understanding why normalization works.
- **Calibration in classification** (mapping model confidence to true accuracy): NCC is fundamentally a calibration method; understanding that calibrated models should have P(correct|confidence) ≈ confidence helps interpret reliability diagrams.
- **In-context learning (ICL) sensitivity**: The paper shows NCC reduces sensitivity to few-shot example selection; understanding baseline ICL fragility motivates why this matters.

## Architecture Onboarding

- **Component map:** Input Text → [LLM] → Token Log-Probs for Each Label → [Full-Label Probability Computation] → [Length Normalization] → [Baseline Estimation] → [Calibration] → [Argmax] → Predicted Label

- **Critical path:** The baseline estimation step (P_baseline) requires forward passes through the LLM with content-free inputs for ALL labels. This is a one-time cost per label set but must be recomputed if labels change. The paper uses an ensemble of 5 content-free inputs averaged to reduce variance.

- **Design tradeoffs:**
  - Content-free input choice: Empty string vs. diverse placeholders. Paper uses ensemble averaging; more placeholders reduce variance but increase compute.
  - Normalization method: Geometric mean preserves probability semantics for calibration vs. average cross-entropy.
  - First-token space prefixing: Paper prefixes labels with space for tokenizer alignment.

- **Failure signatures:**
  - Near-zero F1 with standard CC on multi-token labels: Indicates length bias in baseline probabilities causing over-compensation toward long labels.
  - High variance across random seeds: Indicates ICL sensitivity; NCC should reduce this.
  - Performance degradation on simple datasets with full label coverage: Indicates unnecessary calibration when label space is already well-specified.

- **First 3 experiments:**
  1. Reproduce label length bias visualization: Take a multi-class dataset, run zero-shot inference, plot prediction frequency by label token length.
  2. Validate calibration on single held-out dataset: Implement NCC on Banking77, compare macro-F1 against raw probabilities, raw+length normalization only, calibration only, and full NCC.
  3. Ablate content-free input ensemble: Test calibration quality with single content-free input vs. 5-input ensemble, measure variance in baseline probabilities.

## Open Questions the Paper Calls Out

- Can NCC be adapted for proprietary or API-based LLMs that only provide limited token probability information (e.g., top-20 tokens)?
- Can calibration methods like NCC be effectively applied to open-ended text generation tasks where the output space is unrestricted?
- Does label length bias manifest similarly across different languages, and does NCC provide equivalent benefits in multilingual settings?
- How does the choice of normalization method (geometric mean vs. average cross-entropy vs. other approaches) affect calibration quality and downstream performance?

## Limitations

- Computational overhead for large label spaces due to baseline probability computation
- Limited evaluation to English-language datasets and autoregressive decoder-only models
- Method not suitable for open-ended generation tasks with unrestricted output spaces
- Effectiveness on encoder-decoder models and multilingual settings remains untested

## Confidence

**High Confidence:**
- Label length bias exists and systematically affects predictions
- NCC improves calibration and F1 on multi-token label datasets
- NCC reduces few-shot sensitivity to example selection

**Medium Confidence:**
- NCC outperforms all prior calibration methods on tested datasets
- NCC is necessary specifically for multi-token labels
- NCC extends naturally to QA tasks beyond text classification

**Low Confidence:**
- NCC will generalize to datasets with >100 labels without modification
- NCC will work equally well on encoder-decoder models
- The 5-content-free-input ensemble is optimal for all scenarios

## Next Checks

1. **Stress Test on Extreme Length Distributions:** Evaluate NCC on a dataset with highly skewed label lengths (e.g., one class with 10+ tokens vs. many 1-2 token labels). Measure whether NCC over-corrects and causes under-prediction of naturally long labels that are semantically important.

2. **Ablation of Baseline Estimation Methods:** Compare NCC performance using: (a) single content-free input, (b) 5-input ensemble, (c) learned baseline estimation via small calibration dataset. Quantify the tradeoff between computational cost and calibration stability.

3. **Cross-Architecture Validation:** Implement NCC on an encoder-decoder model (e.g., T5-XXL) for classification. Measure whether the autoregressive decomposition assumption holds and whether length normalization provides similar benefits when labels are processed differently.