---
ver: rpa2
title: 'MMATH: A Multilingual Benchmark for Mathematical Reasoning'
arxiv_id: '2505.19126'
source_url: https://arxiv.org/abs/2505.19126
tags:
- reasoning
- language
- english
- question
- multilingual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors introduce MMATH, a new multilingual benchmark for complex
  mathematical reasoning spanning 374 problems across 10 typologically diverse languages.
  They identify a significant off-target issue in reasoning models where responses
  are generated in unintended languages.
---

# MMATH: A Multilingual Benchmark for Mathematical Reasoning

## Quick Facts
- arXiv ID: 2505.19126
- Source URL: https://arxiv.org/abs/2505.19126
- Reference count: 40
- Primary result: Off-target thinking is prevalent in multilingual mathematical reasoning; EN-Think training achieves 66.72 average accuracy across 10 languages with 97.61% language consistency

## Executive Summary
MMATH introduces a new multilingual benchmark for complex mathematical reasoning spanning 10 typologically diverse languages. The authors identify a significant off-target issue where reasoning models generate responses in unintended languages. Through a combination of prompting strategies, thinking intervention, and training approaches, they demonstrate that reasoning in English while answering in the target language can simultaneously improve answer accuracy and language consistency. Their best model achieves 66.72 average accuracy across languages with 97.61% language consistency ratio.

## Method Summary
The authors constructed MMATH using a 3-stage pipeline: LLM translation, iterative multi-model revision, and human verification, producing 374 problems across 10 languages. They evaluated base models to identify off-target patterns, then applied thinking interventions (ATP, DIT, QRT) and training strategies (EN-SFT, Native-Think, EN-Think) on Qwen2.5-32B-Instruct. The EN-Think approach trains with English reasoning traces paired with target-language answers, achieving the best balance of accuracy and language consistency.

## Key Results
- Qwen2.5-32B-Instruct trained with EN-Think strategy achieves 66.72 average accuracy across 10 languages
- EN-Think achieves 97.61% language consistency ratio while maintaining 10.04% thinking LCR (reasoning in English)
- Off-target thinking improves accuracy on low-resource languages (Arabic: 0%→44%, Thai: 0%→29%)
- DIT intervention increases answering LCR from 58.94% to 96.20% in QwQ-32B

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Off-target thinking improves accuracy on low-resource language tasks
- Mechanism: Models leverage stronger English reasoning pathways when forced to reason in low-resource languages
- Evidence: DeepSeek-R1-Distill-Qwen-7B achieves 0% accuracy on Arabic with Arabic thinking but 44% with off-target thinking
- Break condition: If target-language reasoning data matched English data volume and quality

### Mechanism 2
- Claim: Thinking intervention via discourse markers increases language consistency without training
- Mechanism: Early language commitment through markers biases generation trajectory toward target language
- Evidence: DIT increases QwQ-32B answering LCR from 58.94% to 96.20%
- Break condition: If model lacks sufficient multilingual instruction-following capability

### Mechanism 3
- Claim: Training with English reasoning traces and target-language answers improves both accuracy and consistency
- Mechanism: Decouples reasoning language (English) from output language (native) during fine-tuning
- Evidence: EN-Think achieves 66.72 avg accuracy vs EN-SFT (62.38) and Native-Think (61.46)
- Break condition: If target-language reasoning capability becomes comparable to English through better multilingual pretraining

## Foundational Learning

- **Language Consistency Ratio (LCR)**: Measures whether model outputs match input language, distinguishing thinking vs answering phases. Quick check: French input with English thinking and French output has thinking LCR=0%, answering LCR=100%.
- **Resource Language Disparity**: Explains why models default to English/Chinese for reasoning due to stronger learned representations. Quick check: Why might Arabic show 33% each across English/Chinese/Arabic for thinking language?
- **Cross-Lingual Reasoning Transfer**: Underlies accepting multilingual input, reasoning in English, and outputting in target language. Quick check: What must be true for a model to understand Thai question, reason in English, and answer in Thai?

## Architecture Onboarding

- **Component map**: Benchmark Construction -> Evaluation Pipeline -> Training Configurations -> Intervention Methods
- **Critical path**: 1) Construct benchmark with validated translations, 2) Evaluate base models to identify off-target patterns, 3) Apply thinking interventions to measure LCR improvement, 4) Fine-tune with EN-Think strategy
- **Design tradeoffs**: Accuracy vs. Language Consistency (DIT/QRT improve LCR but may hurt accuracy in smaller models); Training Data Language (EN-SFT gives strong accuracy but poor LCR; Native-Think gives high LCR but weaker accuracy); Intervention Strength (aggressive intervention can force consistency but degrades performance in undertrained models)
- **Failure signatures**: Distilled smaller models show severe accuracy drops with DIT/QRT; Arabic and Thai inputs showing ~33% each across English/Chinese/target indicates model confusion; EN-SFT training produces ~60% answering LCR
- **First 3 experiments**: 1) Baseline Assessment: Run target model on MMATH with native prompts; compute accuracy and LCR for thinking/answering phases separately, 2) Intervention Ablation: Test ATP, DIT, QRT individually on 3 model sizes to identify interaction effects, 3) Training Data Ablation: Fine-tune on 500 examples each of EN-SFT, Native-Think, and EN-Think to determine optimal configuration

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can accuracy and language consistency be jointly optimized without trade-offs observed in current prompting strategies?
- Basis: Limitations section states balancing accuracy and language consistency remains a significant challenge
- Why unresolved: DIT/QRT achieved near-perfect LCR (>96%) but caused substantial accuracy drops for distilled models
- What evidence would resolve it: A training-free method achieving both >90% LCR and accuracy within 2-3% of baseline across all model sizes

### Open Question 2
- Question: Can native multilingual reasoning data yield superior performance compared to translation-based approach?
- Basis: Limitations section mentions synthesizing multilingual reasoning data remains challenging
- Why unresolved: EN-Think training used machine-translated reasoning traces with potential artifacts
- What evidence would resolve it: Comparing models trained on native multilingual CoT data vs. translated data

### Open Question 3
- Question: Does English-reasoning-with-target-language-answering paradigm generalize to other reasoning domains?
- Basis: Limitations section notes work focuses on mathematical reasoning only
- Why unresolved: Only mathematical reasoning was tested; other domains may have different cross-lingual transfer properties
- What evidence would resolve it: Applying EN-Think strategy to multilingual coding benchmarks and STEM QA datasets

## Limitations
- Data Coverage Gaps: Training data relies heavily on GPT-4o-mini translations without explicit validation of mathematical reasoning quality in low-resource languages
- Model Size Dependency: Thinking interventions show strong model size dependence with 7B models experiencing severe accuracy degradation
- Single Benchmark Scope: Study focuses exclusively on mathematical reasoning, may not apply to other reasoning domains

## Confidence

**High Confidence**: Off-target thinking is widespread across multilingual mathematical reasoning models; EN-Think training achieves superior balance of accuracy and language consistency; Thinking interventions can dramatically improve language consistency

**Medium Confidence**: The mechanism by which off-target thinking improves low-resource language accuracy; The superiority of EN-Think over Native-Think training (limited to 3K examples); The generalizability of intervention effectiveness across model architectures

**Low Confidence**: The specific optimal balance point between intervention strength and model capability; The long-term stability of language consistency improvements; The impact of different mathematical domains on cross-lingual reasoning transfer

## Next Checks

**Check 1: Intervention Robustness Across Mathematical Domains**
Run DIT/QRT interventions on stratified sample of MMATH problems covering different mathematical domains to identify whether accuracy drop in smaller models is uniform or concentrated in specific problem types.

**Check 2: Extended Training Data Analysis**
Analyze distribution of mathematical reasoning complexity in 3K EN-Think training subset versus full MMATH evaluation set to assess whether training data adequately represents problem diversity.

**Check 3: Cross-Lingual Transfer Generalization**
Test EN-Think trained model on non-mathematical multilingual reasoning tasks (scientific reasoning, logical deduction, commonsense reasoning) to determine whether cross-lingual reasoning transfer mechanism generalizes beyond mathematics.