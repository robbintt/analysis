---
ver: rpa2
title: Temporal Basis Function Models for Closed-Loop Neural Stimulation
arxiv_id: '2507.15274'
source_url: https://arxiv.org/abs/2507.15274
tags:
- stimulation
- basis
- data
- function
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces temporal basis function models (TBFMs) for
  closed-loop neural stimulation, addressing challenges in sample efficiency, training
  time, and loop latency. TBFMs predict the state-dependent effects of optogenetic
  stimulation on local field potentials (LFPs) using a forward prediction model that
  leverages initial brain states.
---

# Temporal Basis Function Models for Closed-Loop Neural Stimulation

## Quick Facts
- **arXiv ID:** 2507.15274
- **Source URL:** https://arxiv.org/abs/2507.15274
- **Reference count:** 40
- **Primary result:** TBFMs achieve test R² of 0.462 (164 ms) and 0.787 (40 ms) on LFP prediction while requiring only 2-5 minutes training time

## Executive Summary
This paper introduces temporal basis function models (TBFMs) for closed-loop neural stimulation, addressing challenges in sample efficiency, training time, and loop latency. TBFMs predict state-dependent effects of optogenetic stimulation on local field potentials using a forward prediction model that leverages initial brain states. Evaluated on 40 experimental sessions with two non-human primates, TBFMs outperform linear state-space models and match more complex nonlinear models while requiring only 2-5 minutes of training time. The models successfully controlled simulated neural activity toward target patterns with AUC values of 0.704 and 0.694.

## Method Summary
TBFMs predict spatiotemporal neural responses by decomposing stimulation effects into learned temporal basis functions weighted by state-dependent coefficients. The model takes stimulation descriptors (timing parameters) and a 20ms runway of LFP data as inputs. A multi-layer perceptron generates 12-15 temporal basis functions from stimulation descriptors, while an affine layer maps the runway to basis weights. Predictions are assembled as the last LFP value plus weighted sums of basis functions. The model is trained using L2 loss with Frobenius regularization, optimized via AdamW. State-dependence is evaluated by binning trials by initial-state similarity and comparing predicted vs. actual responses.

## Key Results
- Test set R² of 0.462 for 164 ms predictions and 0.787 for 40 ms predictions on time-domain data
- Inference latency of 0.115-0.174 ms, outperforming recurrent models by 2-3 orders of magnitude
- Sample efficiency: ~17 minutes of data collection enables cross-session generalization
- Closed-loop simulation: AUC values of 0.704 and 0.694 for two different stimulation control tasks
- State-dependent models achieve R² of 0.462 vs. 0.006 for state-agnostic models

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Conditioning predictions on pre-stimulation brain state improves forecast accuracy because stimulation responses are state-dependent.
- **Mechanism:** The model uses a 20ms runway of LFP data immediately before prediction to estimate basis function weights. Different initial states produce different weight combinations, allowing the model to output state-conditioned responses rather than a single averaged response.
- **Core assumption:** The neural system's response to stimulation varies systematically with ongoing activity at stimulation time (state-dependence).
- **Evidence anchors:** 97.4% of channels exhibited statistically significant state dependence; state-dependent models achieved test R² of 0.462 vs. 0.006 for state-agnostic models.
- **Break condition:** If stimulation responses are not state-dependent, the runway input provides no predictive value beyond the stimulation parameters alone.

### Mechanism 2
- **Claim:** Basis function decomposition enables sample efficiency by constraining the hypothesis space to low-dimensional temporal patterns shared across channels.
- **Mechanism:** The MLP generates 12-15 temporal basis functions from stimulation descriptors. An affine weight estimator maps the runway to basis weights. This factorization separates "what temporal shape" from "how much of each," reducing learnable parameters compared to full spatiotemporal models.
- **Core assumption:** Stimulation responses can be approximated as a weighted linear combination of a small set of temporal basis functions.
- **Evidence anchors:** TBFM requires only ~17 minutes of data collection to generalize across sessions; requires N≈6k training examples on average.
- **Break condition:** If stimulation responses require more basis functions than data can support, or if responses cannot be approximated linearly, sample efficiency gains disappear.

### Mechanism 3
- **Claim:** Non-recurrent (parallel) prediction enables sub-millisecond inference latency suitable for closed-loop control.
- **Mechanism:** Unlike RNNs that unroll predictions step-by-step through time, TBFMs compute the entire prediction horizon as a single matrix multiplication: ŷ = x·1 + W·B. The basis functions and weights are computed once, then combined in parallel.
- **Core assumption:** The controller's latency budget is smaller than the neural forecast horizon; faster inference enables more responsive stimulation.
- **Evidence anchors:** TBFMs demonstrated low inference latency (0.115-0.174 ms) vs. AE-LSTM at 41.628ms for 164ms forecast.
- **Break condition:** If the system requires online adaptation where basis functions must be recomputed per-trial, latency increases.

## Foundational Learning

- **Concept: State-space models and latent dynamics**
  - **Why needed here:** TBFMs are positioned as an alternative to linear state-space models and recurrent neural networks. Understanding how latent states compactly represent system dynamics clarifies why basis functions serve a similar role.
  - **Quick check question:** Can you explain why an LSSM with a latent state might fail to capture state-dependent stimulation responses if the latent state is always zero-initialized?

- **Concept: Basis function expansion / dictionary learning**
  - **Why needed here:** The core architectural choice is representing complex temporal responses as weighted sums of simpler basis functions. This is analogous to Fourier decomposition or PCA but with learned bases.
  - **Quick check question:** Given a set of basis functions B₁(t), B₂(t), B₃(t), how would you express a response that looks like B₁(t) with twice the amplitude plus a small contribution from B₃(t)?

- **Concept: Model predictive control (MPC) and forward models**
  - **Why needed here:** The paper demonstrates TBFMs in simulated closed-loop control where the model predicts future states to inform stimulation decisions. Understanding MPC clarifies why prediction accuracy matters for control.
  - **Quick check question:** In a closed-loop stimulator with 20ms latency, why must the controller forecast 20ms into the future before deciding whether to stimulate?

## Architecture Onboarding

- **Component map:**
  1. **Stimulation descriptor** (input): Encodes timing parameters (clock vector + one-hot pulse timing). Shape: [T_horizon, 3]
  2. **Basis function generator** (MLP): 4 layers, width 4, tanh activations. Outputs basis matrix B ∈ ℝ^(b × T_horizon), where b=12-15.
  3. **Runway input** (LFP data): 20ms window across C channels. Shape: [C, 20] after downsampling to 1kHz.
  4. **Z-score normalization**: Per-channel mean/variance computed from training data.
  5. **Affine weight estimator**: Linear layer mapping runway → basis weights W ∈ ℝ^(C × b).
  6. **Prediction assembly**: ŷ_c = x_c,last + Σᵢ W_{c,i} · B_i for each channel c.

- **Critical path:**
  Training: Load runway + target → Z-score runway → forward pass through weight estimator → compute ŷ via weighted basis sum → L2 loss + Frobenius regularization → backprop through weight estimator and basis generator jointly.
  
  Inference (compiled): Pre-compute B for fixed stimulation parameters → receive runway → linear projection to weights → matrix multiply for prediction. Non-recurrent path is the key latency win.

- **Design tradeoffs:**
  - **Prediction horizon vs. accuracy:** R² drops from 0.787 (40ms) to 0.462 (164ms). Shorter horizons are more accurate but provide less control lookahead.
  - **Basis count vs. overfitting:** More bases improve training fit but may overfit. FSAM provides a validation-based stopping rule.
  - **Runway length vs. latency:** Longer runways capture more state information but delay prediction. Paper uses 20ms as a proxy for realistic loop latency.
  - **State-dependent vs. state-agnostic:** State-dependent models require valid runway data; state-agnostic models can predict without recent measurements but sacrifice accuracy (R²: 0.006).

- **Failure signatures:**
  - **R² near 0 on test set but high on train set:** Overfitting. Reduce basis count, increase regularization λ, or expand training data.
  - **State-dependent R² ≈ overall R²:** Model may be ignoring runway input. Verify weight estimator is learning non-trivial weights.
  - **Inference latency >1ms:** Likely not using compiled mode or running unoptimized matrix operations. Ensure basis functions are pre-computed and cached.
  - **Poor control AUC (<0.6):** Prediction accuracy may be insufficient for the horizon required. Shorten prediction horizon or improve model.

- **First 3 experiments:**
  1. **Reproduce prediction accuracy on provided data:** Train TBFM on first 5k trials from a session, evaluate R² on last 2.5k trials. Compare 40ms vs. 164ms horizons. Target: test R² >0.4 for 164ms.
  2. **Ablate state-dependence:** Replace runway input with zeros (sham input). Measure R² drop. Target: confirm state-agnostic R² <0.1, demonstrating runway contributes predictive power.
  3. **Benchmark latency:** Implement compiled inference (pre-compute B, cache weights estimator as linear layer). Measure prediction time for batch of N=10000 trials. Target: <0.2ms per trial on CPU.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can reinforcement learning (RL) frameworks utilizing TBFMs be made sample efficient enough to discover novel stimulation therapies in a clinical setting?
- **Basis in paper:** Section 5.3 states, "Further investigation is needed to determine if an RL-based approach can be made sample efficient enough to perform well in experimental or clinical practice."
- **Why unresolved:** RL is typically data-intensive, which conflicts with the strict safety and time constraints of clinical neural stimulation.
- **Evidence:** An RL agent successfully optimizing a therapeutic reward function using TBFMs without exceeding safe stimulation data limits.

### Open Question 2
- **Question:** How does model accuracy and sample efficiency degrade when expanding the stimulation parameter space to include amplitude, frequency, and electrode location?
- **Basis in paper:** Section 5.3 notes, "It also remains unclear how well an ML approach will adapt to the increase in dimensionality that comes with having a diverse space of stimulation parameters."
- **Why unresolved:** The current study only varied pulse timing; broadening parameters increases the learning space exponentially.
- **Evidence:** Benchmarking TBFM performance on a dataset where stimulation amplitude, frequency, and site locations vary systematically.

### Open Question 3
- **Question:** How does variable hardware latency and signal jitter impact the stability and performance of TBFM-based controllers in real-world deployment?
- **Basis in paper:** Section 5.3 calls for future experiments to "address practical issues associated with ML-based closed-loop stimulation systems, such as measuring and adapting to loop latency and jitter."
- **Why unresolved:** The paper validated control using simulations with fixed latencies, which may not reflect hardware constraints.
- **Evidence:** Closed-loop experiments quantifying control performance (e.g., AUC) under induced latency and jitter conditions.

## Limitations

- **Dataset specificity:** Results based on optogenetic stimulation in non-human primates with specific parameters; generalization to different paradigms (e.g., DBS) remains untested.
- **Simulation-only controller validation:** Closed-loop controller was tested in simulation rather than real hardware, leaving the gap to actual implementation unquantified.
- **Limited state-dependence analysis:** While 97.4% of channels showed statistical significance, the distribution of effect sizes and practical importance across brain states is not reported.

## Confidence

- **High confidence** in prediction accuracy metrics and latency measurements (directly observable from test set)
- **Medium confidence** in state-dependence findings (statistically significant but limited effect size analysis)
- **Medium confidence** in closed-loop controller claims (simulation demonstrates feasibility but lacks real hardware validation)

## Next Checks

1. **Generalization across stimulation paradigms:** Test TBFM performance on a different optogenetic stimulation protocol (e.g., varying pulse widths, frequencies, or continuous stimulation patterns) to assess adaptability beyond the specific parameters used.

2. **Effect size analysis of state-dependence:** Quantify the distribution of state-dependence effect sizes across channels and sessions, reporting both the proportion of variance explained and the minimum detectable effect size given the sample sizes.

3. **Hardware-in-the-loop validation:** Implement TBFM in a real-time closed-loop system with actual neural recording and stimulation hardware, measuring the actual closed-loop latency and control performance under realistic constraints.