---
ver: rpa2
title: 'Navigating through the hidden embedding space: steering LLMs to improve mental
  health assessment'
arxiv_id: '2510.16373'
source_url: https://arxiv.org/abs/2510.16373
tags:
- steering
- llms
- bdi-ii
- relevant
- item
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates that compact Large Language Models (LLMs)
  can be effectively adapted for mental health assessment through steering vectors,
  achieving performance comparable to much larger models. The proposed method uses
  linear transformations of layer activations to guide model behavior, addressing
  the cautious bias that causes overestimation of symptom presence.
---

# Navigating through the hidden embedding space: steering LLMs to improve mental health assessment

## Quick Facts
- **arXiv ID**: 2510.16373
- **Source URL**: https://arxiv.org/abs/2510.16373
- **Reference count**: 40
- **Primary result**: Steering vectors improve non-relevant classification from 4,345 to 5,136 while boosting BDI-II downstream accuracy (48.75% DCHR, 83.63% ADODL) using an 8B model comparable to much larger models.

## Executive Summary
This study demonstrates that compact Large Language Models (LLMs) can be effectively adapted for mental health assessment through steering vectors, achieving performance comparable to much larger models. The proposed method uses linear transformations of layer activations to guide model behavior, addressing the cautious bias that causes overestimation of symptom presence. On the DepresSym dataset, steering vectors improved relevance classification accuracy from 830 to 849 for relevant posts while substantially increasing non-relevant classification from 4,345 to 5,136. When applied to BDI-II questionnaire completion on the eRisk 2021 dataset, the steered Llama 3.1 8B model achieved 48.75% DCHR and 83.63% ADODL, outperforming larger models like qwen-2.5-72b (46.25% DCHR) and matching mistral-medium-3.1.

## Method Summary
The approach extracts steering vectors by computing the difference between mean layer-L/2 activations for correct and incorrect BDI-II responses. These vectors are then applied as linear transformations during inference via forward hooks at layer L/2. The optimal steering strength λ* is calibrated to achieve 99% accuracy on a validation set, balancing between under- and over-steering. For downstream BDI-II completion, an adaptive retrieval strategy (aRAG) with item-specific λ*_j steering is employed. The method addresses the cautious bias in LLMs by explicitly guiding the model toward recognizing non-relevant content while maintaining performance on relevant posts.

## Key Results
- Non-relevant classification accuracy improved from 4,345 to 5,136 (steered Llama 3.1 8B)
- BDI-II downstream performance: 48.75% DCHR and 83.63% ADODL (steered 8B model)
- Outperformed qwen-2.5-72b (46.25% DCHR) while matching mistral-medium-3.1
- Maintained or improved relevant post classification (830→849) while substantially boosting non-relevant detection

## Why This Works (Mechanism)
The method works by identifying and amplifying the activation-space directions that distinguish correct from incorrect responses. By extracting the centroid difference between positive (correct) and negative (incorrect) activation sets at layer L/2, the approach captures the latent decision geometry of the model. Applying this steering vector during inference effectively shifts the model's internal representations toward more accurate predictions. The calibration procedure ensures optimal strength by targeting 99% validation accuracy, preventing overcorrection that could harm relevant post classification while addressing the cautious bias that leads to over-identification of symptoms.

## Foundational Learning
- **Activation-space steering**: Linear transformations of hidden states to guide model behavior; needed to navigate the embedding space toward desired outputs without retraining.
- **Layer-L/2 extraction**: Targeting intermediate layers for intervention; chosen because these layers capture sufficient semantic representation while remaining close enough to the output to be effective.
- **Centroid difference computation**: Using mean activation differences between correct and incorrect responses; provides a robust estimate of the decision boundary direction.
- **Validation-based calibration**: Tuning λ* to achieve target accuracy on validation data; ensures steering strength is neither too weak nor too strong.
- **Forward hook application**: Injecting steering vectors during the forward pass; enables real-time activation modification without architectural changes.
- **Adaptive retrieval (aRAG)**: Context-aware document selection for downstream tasks; improves retrieval relevance for BDI-II item completion.

## Architecture Onboarding

**Component Map**
Llama 3.1 8B -> Layer-L/2 activation extraction -> Steering vector computation (centroid difference) -> Forward hook injection -> Inference with calibrated λ*

**Critical Path**
1. Data preprocessing and train/val/test split
2. Steering vector extraction from train set
3. λ* calibration on validation set
4. Test inference with item-specific steering

**Design Tradeoffs**
- Linear steering vs. non-linear transformations: Simpler and more interpretable but may not capture complex decision boundaries
- Static per-item steering vs. dynamic context-adaptive steering: More stable but potentially less flexible
- Centroid difference vs. hyperplane separation: More robust to outliers but loses discriminative boundary information

**Failure Signatures**
- Cautious bias persists: Non-relevant accuracy doesn't improve, relevant accuracy drops
- Overcorrection: Relevant accuracy decreases significantly while non-relevant accuracy improves
- Inconsistent scores: Results vary across runs due to improper temperature or decoding constraints

**Three First Experiments**
1. Verify steering vector extraction by computing and visualizing centroid differences for a single BDI-II item
2. Test calibration procedure by searching λ* on validation set and plotting accuracy vs. λ curve
3. Apply calibrated steering to test set and measure non-relevant accuracy improvement

## Open Questions the Paper Calls Out
- **Adaptive steering**: Can context-dependent steering dynamically modulated by post content or uncertainty improve performance beyond static steering vectors? The current study applied fixed steering vectors per item without adapting to individual post characteristics or model uncertainty during inference.
- **Cross-lingual generalization**: How well do steering-based interventions generalize across languages and cultures given the domain-specific expression of psychological distress? The study only validated the approach on English-language Reddit data.
- **Domain transferability**: Can steering vectors effectively transfer to other healthcare or domain-specific assessment tasks beyond mental health? The study only demonstrated effectiveness in mental health assessment (depression screening).
- **Linear representation assumptions**: To what extent does the linear representation assumption limit steering effectiveness given the highly non-linear behavior of transformer models? While linear steering showed empirical success, the theoretical justification remains simplified.

## Limitations
- Missing implementation details: Exact token indexing for activation extraction and retrieval hyperparameters are not specified
- Static approach: Fixed steering vectors per item without adaptation to individual post characteristics
- English-only validation: Results may not generalize to other languages or cultural contexts
- Linear assumption: Simplified representation of complex transformer decision boundaries

## Confidence
- **High confidence** in the general feasibility of steering via layer-L/2 activation differences and the empirical gains on non-relevant classification and BDI-II downstream metrics.
- **Medium confidence** in the calibration procedure and overall reproducibility, due to missing low-level details (token indexing, retrieval thresholds, decoding constraints).
- **Low confidence** in exact replication of reported steering vectors and per-item λ* values without the above specifications.

## Next Checks
1. Verify token indexing: confirm the exact token index after prompt formatting where layer-L/2 activations are extracted for steering vector computation.
2. Calibrate λ precisely: reproduce the validation-set λ* search (|Acc_val − 0.99|) for at least one BDI-II item and check if non-relevant accuracy improves as reported.
3. Test constrained decoding: confirm that the 0-3 scoring range is enforced during downstream inference and that this constraint is applied before softmax or logit sampling.