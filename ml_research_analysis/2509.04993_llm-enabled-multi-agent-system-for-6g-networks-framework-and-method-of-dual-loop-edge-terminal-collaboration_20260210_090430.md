---
ver: rpa2
title: 'LLM Enabled Multi-Agent System for 6G Networks: Framework and Method of Dual-Loop
  Edge-Terminal Collaboration'
arxiv_id: '2509.04993'
source_url: https://arxiv.org/abs/2509.04993
tags:
- network
- agent
- planning
- task
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of deploying large language
  model (LLM)-enabled agents in 6G networks, where limited device resources hinder
  efficient multi-level device collaborations. The proposed solution is a dual-loop
  edge-terminal collaboration framework for LLM-enabled multi-agent systems.
---

# LLM Enabled Multi-Agent System for 6G Networks: Framework and Method of Dual-Loop Edge-Terminal Collaboration

## Quick Facts
- arXiv ID: 2509.04993
- Source URL: https://arxiv.org/abs/2509.04993
- Reference count: 16
- Key outcome: Dual-loop edge-terminal collaboration framework improves LLM-enabled multi-agent task planning and execution efficiency in 6G networks

## Executive Summary
This paper proposes a dual-loop edge-terminal collaboration framework for LLM-enabled multi-agent systems to address resource constraints in 6G networks. The outer loop handles hierarchical task decomposition and parallel subtask distribution, while the inner loop focuses on circular reasoning, execution, and replanning with parallel tool calling. Case studies in 6G-supported urban safety governance demonstrate improved task planning capability and execution efficiency compared to baseline approaches.

## Method Summary
The framework implements a dual-loop architecture where the outer loop performs task decomposition through a global agent that distributes parallel subtasks to specialized sub-agents. The inner loop enables circular reasoning with parallel tool calling generation using DAG-based scheduling and offloading strategies. The system uses MiniCPM-V 2.6 for video understanding and GLM-4-0520 for planning, with tools including object detection, map API, file management, and dialing capabilities. Five edge servers and ten terminals with heterogeneous resources execute the parallelized tool calls through priority-based scheduling.

## Key Results
- Hierarchical task decomposition reduces per-agent reasoning complexity and improves task completion rates
- Parallel tool calling via DAG-based scheduling reduces execution latency compared to sequential invocation
- Edge-terminal collaboration with priority-based scheduling improves resource utilization and reduces latency
- Success rate and latency improvements validated on urban safety governance tasks (fire/traffic emergency response)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hierarchical task decomposition reduces per-agent reasoning complexity and improves task completion rates
- Mechanism: Outer loop's global agent decomposes complex tasks into parallel subtasks, assigning each to specialized sub-agents with dedicated roles
- Core assumption: Tasks are meaningfully decomposable into parallelizable subtasks with manageable interdependencies
- Evidence anchors: Abstract mentions enhanced planning through task decomposition; Section III-C-1 describes decomposition preventing loss of contextual information; corpus supports decomposition benefits but lacks direct comparison to non-hierarchical baselines

### Mechanism 2
- Claim: Parallel tool calling via DAG-based scheduling reduces execution latency compared to sequential invocation
- Mechanism: Inner loop uses LLMCompiler to generate tool-calling topologies as Directed Acyclic Graphs (DAGs), enabling concurrent execution of independent tools
- Core assumption: Tool dependencies are correctly identified by the planning model; DAG structure is acyclic and accurate
- Evidence anchors: Abstract mentions parallel tool calling with DAG generation; Section III-C-2 describes DAG-based tool topology; Section IV shows latency comparison outperforming cloud-only and local execution; corpus lacks direct replications of LLMCompiler in 6G contexts

### Mechanism 3
- Claim: Edge-terminal collaboration with priority-based scheduling improves resource utilization and reduces latency
- Mechanism: Tools are offloaded to devices based on resource requirements matched against device capabilities with priority scheduling using critical path length
- Core assumption: Device capabilities are known a priori; communication overhead between devices is lower than local execution time
- Evidence anchors: Section III-D emphasizes matching tool resource demands to device supply; Section IV describes infrastructure setup with 5 edge servers and 10 terminals; corpus references related offloading constraints in robotics but not 6G networks

## Foundational Learning

- Concept: **ReAct (Reasoning + Acting) agent pattern**
  - Why needed here: Dual-loop framework contrasts with ReAct's sequential tool calling; understanding ReAct is essential to see why parallelization helps
  - Quick check question: Can you explain why ReAct's sequential reasoning causes early stops in long-horizon tasks?

- Concept: **Directed Acyclic Graphs (DAGs) for task scheduling**
  - Why needed here: Inner loop represents tool dependencies as DAGs; misunderstanding DAG properties will break scheduling logic
  - Quick check question: Given tools A→B, A→C, B→D, C→D, which tools can execute in parallel?

- Concept: **Edge-terminal computing offloading**
  - Why needed here: Framework's efficiency claim depends on correctly matching tool resource needs to device capabilities
  - Quick check question: What factors determine whether a tool should be offloaded to an edge server versus executed locally?

## Architecture Onboarding

- Component map: Multimodal Perception -> Memory -> Planning (Outer Loop: Global Agent -> Task Decomposition -> Subtask Assignment) -> Planning (Inner Loop: Sub-agents -> DAG Generation -> Parallel Tool Calling) -> Scheduling -> Execution on Edge/Terminal Devices -> Feedback Collection -> Reflection/Replanning -> Memory Update

- Critical path: 1) Multimodal input → Perception module (intent extraction) 2) Global agent (outer loop) → Task decomposition → Subtask assignment 3) Sub-agents (inner loop) → DAG generation → Parallel tool calling 4) Scheduler → Offloading decisions → Execution on edge/terminal devices 5) Feedback collection → Reflection/replanning → Memory update

- Design tradeoffs: Parallelism vs. coordination overhead (more parallel subtasks reduce latency but increase inter-agent communication); Cloud vs. edge deployment (cloud offers stronger LLMs; edge enables lower latency and privacy); DAG complexity vs. scheduling accuracy (fine-grained DAGs capture dependencies better but complicate scheduling)

- Failure signatures: Early stop (sub-agent terminates prematurely from ReAct-style sequential planning with context overflow); Hallucinated dependencies (incorrect DAG edges cause execution deadlocks); Offloading mismatch (tool scheduled to under-resourced device causes timeout); Communication bottleneck (high-frequency cross-device data exchange saturates bandwidth)

- First 3 experiments: 1) Baseline comparison: Implement ReAct and LLMCompiler baselines; measure success rate and latency across easy/medium/hard tasks 2) DAG validation: Inject synthetic tasks with known dependencies; verify DAG generation accuracy and replanning correctness under tool failures 3) Offloading sensitivity test: Vary device heterogeneity; measure latency and success rate changes

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can on-device LLMs be specifically optimized for 6G network operations to balance high reasoning capabilities with the limited computational resources of edge terminals?
- Basis in paper: Section V, point 1 states that limited terminal resources restrict performance and emphasizes the "significant" need to develop on-device LLMs that balance capability requirements with resource consumption
- Why unresolved: While the paper proposes offloading to edge servers, achieving "native intelligence" requires robust local execution, yet current advanced LLMs require parameter amounts that exceed terminal memory and processing limits
- What evidence would resolve it: Benchmark results showing successful execution of 6G-specific tasks by compressed or specialized models running on resource-constrained hardware without offloading

### Open Question 2
- Question: What specific mechanisms can effectively detect and mitigate hallucinations in real-time multi-agent systems to prevent network performance degradation?
- Basis in paper: Section V, point 4 notes that hallucinations can lead to severe declines in network performance and that current agent systems are often insufficient at self-discovering these errors, necessitating "external supervisors and evaluators"
- Why unresolved: The paper implements reflection and replanning loops to reduce errors, but acknowledges that factual errors conflicting with world knowledge still occur and require external verification methods not yet defined
- What evidence would resolve it: A comparative analysis of task success rates in scenarios with and without the proposed "external supervisor" mechanisms, specifically measuring the reduction in factually erroneous outputs

### Open Question 3
- Question: What key information extraction strategies and routing mechanisms are required to minimize communication overhead during the multi-round data exchanges of distributed agent reasoning?
- Basis in paper: Section V, point 3 highlights that multi-round exchanges of parameters put "excessive communication overhead" on the network, calling for the development of specific extraction strategies and routing mechanisms
- Why unresolved: The proposed dual-loop framework relies on frequent interaction between global and sub-agents, but the paper does not define a protocol for filtering non-essential data before transmission
- What evidence would resolve it: Network simulations measuring bandwidth consumption and latency under different data filtering rules versus raw data transmission in a multi-agent collaborative task

### Open Question 4
- Question: How can the context window and long-context reasoning capability of LLMs be expanded to handle complex, multi-step tool calling without succumbing to early stopping or loss of critical information?
- Basis in paper: Section V, point 2 identifies the "limited context window" as a strict restriction that causes early stops or task failure when agents engage in dozens of reasoning steps
- Why unresolved: The case study uses a specific model (GLM-4), but the fundamental limitation of context retention over long planning horizons remains a general hurdle for complex 6G orchestration
- What evidence would resolve it: Evaluation results of the framework using models with extended context windows on "hard" difficulty tasks showing a statistical elimination of early stopping errors

## Limitations

- Limited empirical validation with synthetic urban safety scenarios rather than real-world 6G network deployments
- Missing comparison baselines against alternative approaches like hierarchical reinforcement learning or decentralized multi-agent systems
- Scalability concerns not characterized for larger numbers of devices and more complex task dependencies

## Confidence

- High confidence: Hierarchical task decomposition mechanism is well-supported by established multi-agent literature and logical framework
- Medium confidence: Parallel tool calling through DAG-based scheduling shows promising results but lacks direct comparison with alternative parallel execution strategies
- Medium confidence: Edge-terminal collaboration benefits demonstrated in controlled experiments but require validation under varying network conditions and device failures

## Next Checks

1. Implement and evaluate against alternative task decomposition strategies (e.g., flat vs. hierarchical) to isolate the contribution of the outer loop mechanism
2. Conduct stress tests with synthetic tasks containing known dependency errors to evaluate DAG generation robustness and replanning effectiveness
3. Measure end-to-end performance across different network topologies and communication latencies to quantify the edge-terminal collaboration benefits under realistic 6G conditions