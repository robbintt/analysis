---
ver: rpa2
title: Context-Efficient Retrieval with Factual Decomposition
arxiv_id: '2503.19574'
source_url: https://arxiv.org/abs/2503.19574
tags:
- question
- questions
- what
- retrieval
- chunk
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces FADER, a retrieval-augmented generation system
  that improves efficiency by decomposing external corpora into concise, semi-structured
  entity-description pairs (EDPs) before retrieval. Unlike traditional RAG that uses
  fixed-size text chunks, FADER generates speculative questions to guide the extraction
  of atomic facts and augments the knowledge base through multiple sampling runs.
---

# Context-Efficient Retrieval with Factual Decomposition

## Quick Facts
- arXiv ID: 2503.19574
- Source URL: https://arxiv.org/abs/2503.19574
- Reference count: 40
- Primary result: FADER improves retrieval efficiency by decomposing corpora into entity-description pairs and using speculative questions, achieving higher accuracy with fewer tokens across multiple QA datasets.

## Executive Summary
FADER introduces a novel approach to retrieval-augmented generation that improves efficiency by decomposing external corpora into concise, semi-structured entity-description pairs (EDPs) before retrieval. Unlike traditional RAG that uses fixed-size text chunks, FADER generates speculative questions to guide the extraction of atomic facts and augments the knowledge base through multiple sampling runs. Experiments on NarrativeQA, Qasper, and QuALITY demonstrate that FADER achieves higher accuracy with fewer retrieved tokens across varying context budgets, outperforming baselines including standard retrieval, proposition decomposition, and retrieve-then-summarize methods.

## Method Summary
FADER transforms external corpora into a structured knowledge base of entity-description pairs (EDPs) by first generating speculative questions that capture potential facts within the text. These questions guide the extraction of atomic facts, which are then paired with their corresponding entities to create the EDP structure. During retrieval, the system searches this semi-structured knowledge base rather than raw text chunks, allowing for more targeted and efficient fact extraction. The knowledge base is augmented through multiple sampling runs to capture diverse factual representations. This decomposition approach enables FADER to retrieve more relevant information using fewer tokens, particularly beneficial in short-context regimes where computational efficiency is critical.

## Key Results
- FADER consistently outperforms traditional RAG and baseline methods across NarrativeQA, Qasper, and QuALITY datasets
- The method achieves higher accuracy while using significantly fewer retrieved tokens, especially in short-context scenarios
- Ablation studies confirm the critical role of both question speculation and knowledge base augmentation components

## Why This Works (Mechanism)
FADER's effectiveness stems from its structured decomposition of knowledge into atomic facts paired with entities, enabling more precise retrieval than traditional chunk-based approaches. By generating speculative questions, the system anticipates what information might be relevant before retrieval, effectively pre-filtering the knowledge space. The EDP structure naturally aligns with how language models process information, as it presents facts in a more digestible format than raw text passages. The multiple sampling runs for knowledge base augmentation ensure diverse factual coverage, reducing the risk of missing critical information during retrieval.

## Foundational Learning

**Entity-Description Pairs (EDPs)**: Semi-structured knowledge representations pairing entities with their descriptive facts. Needed to create a more structured yet expressive representation than raw text chunks. Quick check: Verify that EDPs capture the essential facts without losing context or nuance.

**Speculative Question Generation**: Pre-retrieval question generation to anticipate potential information needs. Needed to guide the decomposition process and ensure relevant facts are captured. Quick check: Assess question quality and coverage across diverse document types.

**Knowledge Base Augmentation**: Multiple sampling runs to expand and diversify the factual knowledge base. Needed to capture different perspectives and representations of the same information. Quick check: Measure redundancy reduction while maintaining comprehensive coverage.

## Architecture Onboarding

**Component Map**: Document Corpus -> Speculative Question Generator -> Fact Extractor -> Entity-Description Pairs -> Search Index -> Retriever -> LLM

**Critical Path**: The core workflow flows from document input through speculative question generation, fact extraction, EDP creation, indexing, retrieval, and finally generation. The question speculation and knowledge base augmentation steps are bottlenecks but essential for performance.

**Design Tradeoffs**: FADER trades computational overhead in preprocessing (question generation and multiple sampling) for improved retrieval efficiency and accuracy. The semi-structured EDP format requires more sophisticated indexing but enables more precise fact retrieval than traditional chunking methods.

**Failure Signatures**: Performance degradation occurs when speculative questions miss critical facts, when facts are highly interdependent and lose context in decomposition, or when the entity linking fails to properly associate facts with their subjects.

**First Experiments**: 1) Run ablation studies removing question speculation to measure its impact on retrieval quality. 2) Test with varying numbers of sampling runs to find the optimal balance between coverage and efficiency. 3) Evaluate performance on datasets with different levels of fact interdependence to understand method limitations.

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but several emerge from the limitations discussion. The generalizability of FADER to domains beyond long-form question answering remains uncertain. The method's performance when speculative question generation is imperfect or when dealing with highly interdependent facts requires further investigation. The computational overhead trade-offs between preprocessing costs and retrieval efficiency gains need more thorough analysis.

## Limitations

- Evaluation primarily focused on three long-form QA datasets, limiting generalizability to other tasks or domains
- Method's effectiveness depends heavily on the quality of speculative questions, with no exploration of failure modes when generation is suboptimal
- Computational overhead of question speculation and multiple sampling steps is not thoroughly analyzed against efficiency gains

## Confidence

- FADER consistently outperforms baselines in accuracy while using fewer retrieved tokens across different context budgets. (High)
- The question speculation mechanism and knowledge base augmentation are essential for FADER's performance. (High)
- FADER is particularly effective in short-context regimes, reducing inference costs without sacrificing accuracy. (Medium)
- The method generalizes well beyond the evaluated datasets and domains. (Low)

## Next Checks

1. Conduct experiments on diverse datasets and domains beyond long-form question answering to assess generalizability and robustness.

2. Perform a detailed analysis of computational overhead and cost-benefit trade-offs in different deployment scenarios, including real-time applications.

3. Investigate failure modes and limitations when the speculative question generation is imperfect or when dealing with interdependent facts, to better understand the method's boundaries.