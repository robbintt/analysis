---
ver: rpa2
title: 'Individualized Cognitive Simulation in Large Language Models: Evaluating Different
  Cognitive Representation Methods'
arxiv_id: '2510.20252'
source_url: https://arxiv.org/abs/2510.20252
tags:
- linguistic
- cognitive
- style
- author
- concept
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel task to evaluate different cognitive
  representation methods in individualized cognitive simulation (ICS), aiming to approximate
  the thought processes of specific individuals using large language models (LLMs).
  The authors constructed a dataset from recently published novels and proposed an
  11-condition cognitive evaluation framework to benchmark seven off-the-shelf LLMs
  in the context of authorial style emulation.
---

# Individualized Cognitive Simulation in Large Language Models: Evaluating Different Cognitive Representation Methods

## Quick Facts
- arXiv ID: 2510.20252
- Source URL: https://arxiv.org/abs/2510.20252
- Reference count: 37
- Primary result: Combining conceptual and linguistic features outperforms static profile-based cues in individualized cognitive simulation

## Executive Summary
This paper introduces a novel task to evaluate different cognitive representation methods in individualized cognitive simulation (ICS), aiming to approximate the thought processes of specific individuals using large language models (LLMs). The authors constructed a dataset from recently published novels and proposed an 11-condition cognitive evaluation framework to benchmark seven off-the-shelf LLMs in the context of authorial style emulation. The evaluated cognitive representations included linguistic features, concept mappings, and author profile information. Results showed that combining conceptual and linguistic features was particularly effective in ICS, outperforming static profile-based cues in overall evaluation. Notably, LLMs were more effective at mimicking linguistic style than narrative structure, underscoring their limits in deeper cognitive simulation.

## Method Summary
The study evaluated 7 LLMs (Gemma-7B, Gemini Pro 1.5, Llama-3.2 1B/3B, Qwen1.5 1.8B/4B/7B) across 11 cognitive representation conditions using 5 recently published novels as source material. The 11 conditions included 7 single features (baseline, persona, background, Big Five personality, linguistic features, concept mappings, profile) and 4 multi-feature combinations. For each novel, the opening chapters served as context (truncated to 8,192 tokens) and subsequent chapters as ground truth. The pipeline involved generating 10 outputs per setting with temperature 0.8, filtering malformed outputs via BLEU score, and evaluating with both LLM-as-judge (style/structural similarity) and human experts (1-5 Likert scales on style, structure, overall quality).

## Key Results
- Combining conceptual and linguistic features was particularly effective, outperforming static profile-based cues in overall evaluation
- Profile-based features (persona, background, Big Five) showed limited improvements and sometimes degraded performance when combined with linguistic/conceptual features
- LLMs were more effective at mimicking linguistic style than narrative structure, with larger models improving surface-level style but not deeper structural coherence

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Combining concept mappings with linguistic features creates a complementary signal that outperforms single or biographical inputs.
- **Mechanism:** Linguistic features constrain surface-level expression (lexicon, syntax), while concept mappings align abstract meaning structures (how an author structures thought). This dual constraint likely reduces the search space for generation more effectively than either alone.
- **Core assumption:** The synergy implies that style and thought structure are at least partially independent dimensions that can be independently controlled.
- **Evidence anchors:** Results show that combining conceptual and linguistic features is particularly effective... outperforming static profile-based cues. This synergy suggests that while linguistic cues capture surface-level stylistic habits, concept mappings provide deeper insight...

### Mechanism 2
- **Claim:** Static profile-based features (persona, biography) introduce noise rather than signal when combined with text-derived features.
- **Mechanism:** Profile features are abstract and high-level. Translating "Openness to Experience" or "born in Maine" into specific narrative tokens requires an inference step that LLMs may execute inconsistently, interfering with the more direct guidance from linguistic/conceptual cues.
- **Core assumption:** LLMs lack a robust internal "bridge" connecting biographical facts to specific narrative execution in a way that aligns with the ground truth.
- **Evidence anchors:** ...outperforming static profile-based cues... Profile-based features... yield limited improvements and sometimes even degrade performance when combined... adding it can introduce noise rather than enhance linguistic quality.

### Mechanism 3
- **Claim:** Scaling model size improves linguistic style mimicry but does not inherently improve narrative structure preservation.
- **Mechanism:** Larger models better approximate the statistical distribution of an author's vocabulary and syntax (surface style). However, narrative structure requires long-horizon coherence and planning, which standard auto-regressive training objectives do not explicitly optimize for.
- **Core assumption:** Style is a distributional property; structure is a planning property.
- **Evidence anchors:** Larger models tend to perform better on surface-level linguistic style but not necessarily on deeper structural similarity. ...scaling alone does not close the gap in simulating individualized thought processes.

## Foundational Learning

- **Concept: Conceptual Metaphor Theory**
  - **Why needed here:** This is the theoretical basis for the "Concept Mapping" feature. You must understand that authors structure abstract domains (e.g., "love", "time") through concrete source domains (e.g., "journey", "money").
  - **Quick check question:** If an author consistently frames "arguments" as "buildings" (e.g., "construct a theory," "buttress a point"), what type of feature captures this: Linguistic or Conceptual?

- **Concept: Bayesian Conditioning in Generation**
  - **Why needed here:** The paper frames ICS as conditional generation $P(response|stimulus, cognitive model)$. You need to distinguish between the stimulus (context) and the cognitive model (the injected profile/features).
  - **Quick check question:** In the "Concept + Linguistic" condition, which part represents the stimulus and which represents the cognitive model?

- **Concept: BLEU as a Sanity Filter vs. Quality Metric**
  - **Why needed here:** The paper uses BLEU only to filter malformed outputs, not to judge quality. Relying on BLEU for creative writing evaluation is a common failure mode.
  - **Quick check question:** Why would a high-quality creative continuation score a low BLEU against a ground-truth reference?

## Architecture Onboarding

- **Component map:** Novel Context (Stimulus) + Feature Set (Cognitive Model) -> Feature Extractors (MetaPro, spaCy, Human/DB lookup) -> LLM (Gemma, Gemini, Llama, Qwen) -> BLEU Filter -> LLM-as-Judge + Human Eval
- **Critical path:** The extraction of Linguistic Features and Concept Mappings from the context (not the author's Wikipedia) is the critical path. If these are noisy, the "Concept + Linguistic" advantage is lost.
- **Design tradeoffs:**
  - Text-Derived vs. Profile: Text-derived is effective but requires sufficient context text. Profile is easy to obtain (Wikipedia) but performs poorly.
  - LLM vs. Human Eval: LLM judges are scalable but show bias toward "Profile" features (high scores) that human experts reject (low scores).
- **Failure signatures:**
  - The "Profile" Trap: High LLM-judge scores for Profile-based generation, but low human scores. Do not trust LLM-only eval for Profile conditions.
  - Structure Collapse: Generation matches the author's "voice" (lexicon/tone) but hallucinates characters or fails to progress the plot.
  - Corpus Mismatch: Note that corpus neighbors like SimProcess refer to "Industrial Control Systems" (ICS), not "Individualized Cognitive Simulation." Do not confuse these domains.
- **First 3 experiments:**
  1. Validation Run: Replicate the "Concept + Linguistic" vs. "Profile" comparison on a single novel. Confirm that the Combination yields higher Structural Similarity than Profile.
  2. Ablation: Remove "Concept Mappings" from the best combination. Does "Linguistic-only" preserve style but lose semantic coherence?
  3. Judge Audit: Compare LLM-judge scores vs. Human scores specifically for the "Profile" condition to quantify the evaluation bias mentioned in Section 6.

## Open Questions the Paper Calls Out

- **Open Question 1:** How can static profile-based features (e.g., Big Five, biographical background) be represented or integrated to prevent performance degradation when combined with linguistic and conceptual cues?
  - **Basis in paper:** [inferred] The authors note that Profile-based combinations "underperform" and "introduce noise," yet theoretically, these features should shape cognitive style.
  - **Why unresolved:** The paper demonstrates that current combination methods fail (Profile + Linguistic scored lowest in human evaluation), but does not test alternative encoding strategies that might resolve the information conflict.
  - **What evidence would resolve it:** Experiments using non-linear prompt fusion or fine-tuning to integrate profile data, resulting in performance metrics that exceed single-feature baselines.

- **Open Question 2:** Do specific training interventions or decoding strategies improve narrative structure preservation more effectively than simply increasing model scale?
  - **Basis in paper:** [explicit] The conclusion states that "scaling alone does not close this gap" and suggests "progress in ICS will require new training strategies and data design rather than size increases alone."
  - **Why unresolved:** The results showed larger models improved linguistic fluency but not structural similarity; however, the study did not test specific training objectives designed for structural coherence.
  - **What evidence would resolve it:** A comparison of standard scaled models versus models trained with specialized narrative-structure objectives, showing a statistically significant increase in structural similarity scores.

- **Open Question 3:** What specific misalignments exist between LLM-as-judge evaluations and human judgment in the context of profile-based cognitive simulation?
  - **Basis in paper:** [explicit] The authors observe that "the LLM-as-judge framework may have blind spots," specifically noting the Profile feature ranked highly in LLM evaluation but poorly in human evaluation.
  - **Why unresolved:** The paper identifies the discrepancy but does not isolate whether the LLM is over-indexing on surface-level persona keywords or failing to detect semantic incoherence that humans spot easily.
  - **What evidence would resolve it:** A fine-grained error analysis of LLM evaluators on profile-heavy text, identifying specific failure modes (e.g., rewarding keyword density over logical consistency).

## Limitations

- Profile Feature Evaluation Bias: The finding that profile-based features yield limited improvements is somewhat confounded by the evaluation method. LLM judges showed bias toward profile-based generations while human experts were more critical.
- Evaluation Pipeline Reliability: The dual evaluation system (LLM judge + human expert) creates a reliability concern. While human evaluation is presented as more trustworthy, the paper acknowledges that LLM judges were biased toward profile-based features.
- Novel Dataset Domain: The use of recently published novels (2024-2025) as a test domain introduces uncertainty about generalizability. While this provides fresh, copyright-compliant content, it's unclear whether the findings would hold for other genres or older texts.

## Confidence

- **High Confidence:** "Combining conceptual and linguistic features is particularly effective" - Well-supported by consistent results across multiple evaluation metrics and backed by mechanistic explanation.
- **Medium Confidence:** "Profile-based features yield limited improvements and sometimes degrade performance" - Supported by human evaluation but LLM evaluation bias introduces uncertainty about magnitude.
- **Medium Confidence:** "LLMs are more effective at mimicking linguistic style than narrative structure" - Supported by results but could be influenced by specific structural evaluation method used.

## Next Checks

1. **Cross-Genre Validation:** Replicate the experiment on a different genre (e.g., science fiction vs. romance) to test whether the "Concept + Linguistic" advantage holds across different narrative styles and authorial processes.

2. **Profile Feature Evaluation Correction:** Conduct a controlled experiment where profile-based generations are evaluated exclusively by human experts to determine if the poor performance is real or an artifact of LLM evaluation bias.

3. **Alternative Structural Evaluation:** Implement a different structural evaluation method (e.g., plot arc analysis, character development tracking) to verify whether the structural similarity limitations observed are robust to different measurement approaches.