---
ver: rpa2
title: Exploratory Retrieval-Augmented Planning For Continual Embodied Instruction
  Following
arxiv_id: '2509.08222'
source_url: https://arxiv.org/abs/2509.08222
tags:
- instruction
- exrap
- query
- continual
- instructions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# Exploratory Retrieval-Augmented Planning For Continual Embodied Instruction Following

## Quick Facts
- arXiv ID: 2509.08222
- Source URL: https://arxiv.org/abs/2509.08222
- Reference count: 40
- Primary result: Proposed ExRAP framework improves task success rate and reduces pending steps in non-stationary environments compared to baseline methods.

## Executive Summary
ExRAP introduces an exploration-integrated retrieval-augmented planning framework for continual embodied instruction following in non-stationary environments. The system maintains a Temporal Embodied Knowledge Graph (TEKG) to track environmental states with timestamps, enabling the agent to reason about temporal consistency. By integrating exploration planning with task planning, ExRAP balances between exploiting current knowledge to complete tasks and exploring to update potentially stale information, demonstrating improved performance across VirtualHome, ALFRED, and CARLA simulation environments.

## Method Summary
ExRAP processes continual instructions through an interpreter that decomposes them into queries and executions. A query evaluator checks conditions against the TEKG using an LLM with temporal consistency refinement, while an exploration-integrated planner selects skills by combining exploitation (task completion) and exploration (information gain) values. The system uses Llama-3-8B as the default LLM, retrieves relevant knowledge from the TEKG using DPR+BM25, and maintains environmental context through a contradiction-aware update mechanism. The framework is evaluated across varying degrees of non-stationarity and instruction scales, measuring task success rate (SR) and pending steps (PS).

## Key Results
- ExRAP achieves higher task success rates compared to baselines in non-stationary environments
- The framework reduces pending steps (PS) by efficiently managing multiple concurrent instructions
- Integrated planning outperforms instruction-wise planning in both success rate and execution efficiency
- Temporal consistency refinement prevents the agent from acting on outdated environmental information

## Why This Works (Mechanism)
The framework's effectiveness stems from its dual focus on exploration and exploitation through a unified planning mechanism. By maintaining a temporal knowledge graph that tracks when information was observed, the system can identify when environmental changes likely invalidate previous knowledge. The exploration planner estimates information gain by measuring uncertainty in query evaluations, directing the agent to investigate areas where knowledge is most likely to be outdated. This integration allows the agent to dynamically balance between completing current tasks and updating its understanding of the environment, preventing the "stale knowledge" problem common in non-stationary settings.

## Foundational Learning

- Concept: **Mutual Information & Entropy**
  - Why needed here: The exploration planner uses entropy of query evaluations to estimate uncertainty about environmental states, guiding exploration toward areas where information is most valuable
  - Quick check question: If a query's evaluation entropy is high, does it mean the agent is very certain or very uncertain about that aspect of the environment?

- Concept: **Retrieval-Augmented Generation (RAG)**
  - Why needed here: ExRAP adapts RAG for embodied agents by retrieving relevant environmental facts from the TEKG to ground the LLM's reasoning in real-world observations
  - Quick check question: In a standard RAG system, where does the information used to augment the LLM's prompt come from?

- Concept: **Knowledge Graphs (specifically Temporal)**
  - Why needed here: The TEKG stores environmental facts with timestamps, allowing the agent to reason about knowledge recency and detect when information may be outdated
  - Quick check question: What two key pieces of information are stored in a Temporal Knowledge Graph that are not in a static one?

## Architecture Onboarding

- Component map: Instruction Interpreter -> Query Evaluator (with TEKG and temporal consistency) -> Exploration-Integrated Planner (exploitation + exploration) -> Skill Execution -> TEKG Update

- Critical path: Instruction enters -> Interpreter creates query -> Evaluator checks TEKG (triggers exploration if stale) -> Planner selects skill -> Skill executed -> Observation updates TEKG -> Loop continues

- Design tradeoffs: Computational cost of TEKG management and entropy calculations vs. improved task execution efficiency and robustness to dynamic environments; exploration weight tuning balances between over-exploration and acting on stale information

- Failure signatures:
  - Instruction Starvation: Some instructions never executed due to consistently lower exploration value
  - Looping Behavior: Agent repeatedly checks same state because entropy doesn't decrease as expected
  - Catastrophic Forgetting: TEKG fails to properly discard outdated information, creating conflicting states

- First 3 experiments:
  1. Recreate "Medium Non-Stationarity" experiment in VirtualHome with 3-5 instructions to verify integrated planner produces shorter average PS than naive instruction-wise planner
  2. Ablate Temporal Consistency Refinement: Run same experiment with temporal consistency check disabled and verify if SR drops and exploration heatmap becomes less focused
  3. Vary Exploration Weight (w_R): Systematically change exploration weight and plot resulting SR and PS to find optimal balance for specific environment

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the specific runtime overhead incurred by temporal consistency refinement and TEKG management during high-frequency environment interactions?
- Basis: [explicit] Authors state "further investigation into runtime overhead is desired" due to "increased computation effort" from managing environmental context memory
- Why unresolved: Paper compares inference times with/without retrieval but lacks comprehensive latency analysis for recursive query evaluation in highly dynamic scenarios
- What evidence would resolve it: Profiling data comparing total planning latency against task success rates under varying non-stationarity loads

### Open Question 2
- Question: How robust is the exploration-integrated task planning scheme when transferred to physical embodied agents with noisy sensors and imperfect actuation?
- Basis: [inferred] Methodology restricts evaluation to simulation environments (VirtualHome, ALFRED, CARLA) with deterministic graph updates
- Why unresolved: Sim-to-real transfer introduces sensor noise and execution failures that could break TEKG assumptions about state updates and contradiction detection
- What evidence would resolve it: Benchmark results from physical robot deployments comparing ExRAP's success rate against baselines in real-world household settings

### Open Question 3
- Question: Can the weighting parameters for exploration and exploitation (w_T and w_R) be dynamically adjusted to better adapt to varying degrees of environmental non-stationarity?
- Basis: [inferred] Implementation uses fixed weights (w_T=0.01, w_R=1.0) despite evaluation across varying non-stationarity degrees
- Why unresolved: Fixed weights may cause over-exploration in stable environments or under-exploration in rapidly changing ones, limiting efficiency gains
- What evidence would resolve it: Ablation studies testing adaptive weighting mechanism against static approach across low/medium/high non-stationarity settings

## Limitations

- Framework requires significant computational resources for TEKG management and recursive query evaluation
- Performance heavily dependent on LLM reasoning quality and environmental perception accuracy
- Evaluation limited to simulation environments, with uncertain generalization to real-world physical agents
- Exploration planner's mutual information estimation assumes predictable next states, which may not hold in highly stochastic environments

## Confidence

- **High Confidence**: Core architecture (TEKG + Query Evaluator + Integrated Planner) is well-defined and reproducible; ablation study results showing integrated planning benefits are consistent
- **Medium Confidence**: Improvements in success rate and reduction in pending steps are demonstrated but may vary with specific environment and instruction set
- **Low Confidence**: Generalizability to real-world dynamic environments with complex instructions is uncertain; temporal consistency refinement effectiveness needs further validation

## Next Checks

1. **Generalization Test**: Evaluate ExRAP on diverse environments with varying complexity, non-stationarity, and instruction types to assess robustness and scalability
2. **Real-World Deployment**: Implement simplified ExRAP on physical robot in controlled environment to test performance with real-world noise, sensor limitations, and unexpected obstacles
3. **Human Evaluation**: Conduct user study where evaluators interact with agent in simulated environment, providing instructions and assessing understanding, planning, and execution effectiveness