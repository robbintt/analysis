---
ver: rpa2
title: 'Progress by Pieces: Test-Time Scaling for Autoregressive Image Generation'
arxiv_id: '2511.21185'
source_url: https://arxiv.org/abs/2511.21185
tags:
- generation
- image
- prompt
- scaling
- test-time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of applying test-time computation
  scaling to autoregressive (AR) image generation models. Unlike language models,
  naive approaches like Best-of-N are ineffective for AR image models due to their
  raster-scan decoding scheme, which lacks a global blueprint and wastes computation
  on early errors.
---

# Progress by Pieces: Test-Time Scaling for Autoregressive Image Generation

## Quick Facts
- arXiv ID: 2511.21185
- Source URL: https://arxiv.org/abs/2511.21185
- Authors: Joonhyung Park; Hyeongwon Jang; Joowon Kim; Eunho Yang
- Reference count: 38
- Primary result: GridAR achieves 14.4% higher image quality than Best-of-N with N=8 while reducing computational cost by 25.6% for text-to-image generation

## Executive Summary
This paper addresses the challenge of applying test-time computation scaling to autoregressive (AR) image generation models. Unlike language models, naive approaches like Best-of-N are ineffective for AR image models due to their raster-scan decoding scheme, which lacks a global blueprint and wastes computation on early errors. The authors propose GridAR, a grid-structured progressive generation framework that addresses these limitations by partitioning the image canvas into row-wise tiles, generating multiple partial candidates, and pruning erroneous ones early.

## Method Summary
GridAR introduces a novel approach to test-time scaling for autoregressive image generation by leveraging a grid-based progressive generation strategy. The method partitions the image canvas into row-wise tiles and generates multiple partial candidates for each position. Erroneous candidates are pruned early in the process, while viable ones serve as anchors to guide subsequent decoding. Additionally, GridAR employs a layout-specified prompt reformulation strategy that inspects partial views to infer a feasible layout, which is then used to guide the remaining generation process. This approach addresses the fundamental inefficiency of raster-scan decoding in AR image models by providing a more structured and guided generation process.

## Key Results
- GridAR with N=4 candidates achieves 14.4% higher image quality compared to Best-of-N with N=8 on T2I-CompBench++
- Computational cost reduction of 25.6% while maintaining superior performance
- For image editing on PIE-Bench, GridAR shows comparable edit quality with 13.9% gain in semantic preservation compared to larger-N baselines

## Why This Works (Mechanism)
The core insight is that raster-scan decoding in autoregressive image models lacks a global blueprint, making early errors cascade and waste computation. GridAR addresses this by introducing a grid structure that allows for parallel partial generation and early pruning of erroneous candidates. The layout-specified prompt reformulation strategy enables the model to infer and utilize a feasible layout based on partial views, providing better guidance for subsequent generation steps. This combination of progressive generation with layout awareness creates a more efficient and effective test-time scaling approach for AR image models.

## Foundational Learning
1. **Autoregressive Image Generation**: Sequential pixel-by-pixel generation following raster-scan order
   - Why needed: Understanding the baseline generation approach being improved upon
   - Quick check: Can generate images but suffers from error accumulation and inefficiency

2. **Test-Time Scaling**: Improving model performance during inference by allocating more computational resources
   - Why needed: The fundamental problem GridAR addresses
   - Quick check: Works well for language models but fails for AR image models due to structural differences

3. **Grid-Based Progressive Generation**: Partitioning image into tiles and generating in a structured, parallel manner
   - Why needed: Core innovation that enables efficient test-time scaling
   - Quick check: Allows early error detection and pruning while maintaining global coherence

4. **Layout-Specified Prompt Reformulation**: Inferring feasible layouts from partial views to guide generation
   - Why needed: Provides global guidance to overcome raster-scan limitations
   - Quick check: Uses partial information to create more coherent and efficient generation paths

5. **Early Pruning Mechanism**: Detecting and eliminating erroneous candidates during generation
   - Why needed: Prevents wasted computation on poor-quality partial results
   - Quick check: Must balance aggressive pruning with maintaining generation diversity

## Architecture Onboarding

**Component Map**: Image Canvas -> Tile Partitioning -> Candidate Generation -> Pruning Module -> Layout Inference -> Guided Generation

**Critical Path**: The most critical path is the interaction between the pruning module and layout inference, as early pruning decisions directly impact the quality of layout inference, which in turn guides the remaining generation.

**Design Tradeoffs**: The grid structure trades off some flexibility in generation order for improved efficiency and error handling. The pruning mechanism must balance between eliminating poor candidates and preserving potentially creative but initially uncertain paths.

**Failure Signatures**: Common failure modes include over-aggressive pruning that eliminates viable candidates, layout inference errors that misguide subsequent generation, and tile boundary artifacts where the grid structure becomes visible in the final output.

**First Experiments**:
1. Baseline comparison: Run Best-of-N with varying N values to establish the inefficiency baseline
2. GridAR ablation: Test GridAR without pruning to quantify pruning's contribution
3. Layout inference analysis: Generate images with manually specified layouts versus inferred layouts to measure the impact of the reformulation strategy

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- The pruning mechanism may introduce biases toward conservative generation patterns that could limit creative diversity
- Evaluation focuses on specific benchmarks (T2I-CompBench++ and PIE-Bench) and may not generalize to all autoregressive image generation scenarios
- The semantic preservation metric lacks detailed breakdown of what aspects of semantics are preserved versus altered

## Confidence

High confidence in:
- The fundamental observation that raster-scan decoding creates inefficiency for test-time scaling approaches
- The empirical demonstration that GridAR outperforms Best-of-N in terms of quality-to-compute ratio on tested benchmarks

Medium confidence in:
- The generalizability of GridAR's performance gains across different autoregressive image generation architectures and tasks
- The robustness of the layout inference mechanism under varying input conditions

Low confidence in:
- The long-term implications of the pruning mechanism on generation diversity and creative potential
- The scalability of GridAR to extremely large image resolutions or more complex generation tasks

## Next Checks
1. Conduct ablation studies isolating the contribution of each GridAR component (tile partitioning, candidate generation, pruning, layout reformulation) to quantify their individual impact on performance gains.

2. Test GridAR on additional autoregressive image generation benchmarks with varying image complexity, resolution, and domain specificity to assess generalizability beyond the current evaluation set.

3. Analyze the diversity of generated outputs with and without GridAR to determine whether the pruning mechanism inadvertently reduces creative variation in the generated images.