---
ver: rpa2
title: 'Capability-Driven Skill Generation with LLMs: A RAG-Based Approach for Reusing
  Existing Libraries and Interfaces'
arxiv_id: '2505.03295'
source_url: https://arxiv.org/abs/2505.03295
tags:
- skill
- resource
- interfaces
- capability
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of automating skill implementation
  in industrial automation systems, where manual development is time-consuming and
  requires deep technical expertise. The authors propose LLM-Cap2Skill, a method that
  leverages large language models (LLMs) and retrieval-augmented generation (RAG)
  to automatically generate executable skills from capability models and natural language
  user input.
---

# Capability-Driven Skill Generation with LLMs: A RAG-Based Approach for Reusing Existing Libraries and Interfaces

## Quick Facts
- **arXiv ID**: 2505.03295
- **Source URL**: https://arxiv.org/abs/2505.03295
- **Reference count**: 13
- **Key outcome**: LLM-Cap2Skill automates skill generation from capability models and natural language input, reducing manual coding effort while maintaining executability.

## Executive Summary
This paper presents LLM-Cap2Skill, a method that leverages large language models and retrieval-augmented generation to automatically generate executable skills for industrial automation systems from capability models and natural language user input. The approach integrates existing libraries and resource interfaces, enabling cross-language code generation. Evaluation on a mobile robot platform using ROS 2 and Python demonstrated that generated skills were structurally correct and executable, with most achieving intended behavior with minimal manual corrections. The method significantly reduces manual coding effort and supports automatic generation of skill interfaces, ontologies, and state machines, demonstrating feasibility and flexibility for modular automation systems.

## Method Summary
The LLM-Cap2Skill method combines capability models with natural language user input to generate executable skills using a RAG-based approach with large language models. The system automatically generates skill interfaces, ontologies, and state machines while integrating existing libraries and resource interfaces. The approach supports cross-language code generation and was implemented using Python for a mobile robot platform with ROS 2. The RAG framework enables the LLM to retrieve relevant information from existing libraries and capability models during the generation process, ensuring that generated code adheres to established patterns and interfaces.

## Key Results
- Generated skills were structurally correct and executable in most cases
- Collision avoidance skill implemented correctly in most cases with minimal corrections
- Move-to-point skill succeeded after minor identifier adjustments
- Significant reduction in manual coding effort compared to traditional development

## Why This Works (Mechanism)
The approach works by combining structured capability models with natural language input, allowing LLMs to generate contextually appropriate code while retrieving relevant patterns from existing libraries. The RAG framework ensures that generated code adheres to established interfaces and conventions, while the structured input provides the necessary constraints for correct behavior.

## Foundational Learning
- **Capability models**: Structured representations of system capabilities that provide necessary constraints for skill generation - why needed: ensures generated code has correct structure and interfaces
- **RAG-based generation**: Retrieval-augmented generation approach that combines LLM generation with information retrieval - why needed: ensures generated code leverages existing libraries and patterns
- **ROS 2 framework**: Robot Operating System 2 provides the underlying infrastructure for robotics applications - why needed: enables integration with existing robotics tools and libraries
- **Cross-language code generation**: Ability to generate code in multiple programming languages - why needed: supports integration with diverse system components
- **State machine generation**: Automatic creation of control flow logic - why needed: ensures correct behavior sequencing
- **Ontology generation**: Automatic creation of structured knowledge representations - why needed: enables semantic understanding of capabilities

## Architecture Onboarding

**Component Map**: Capability Model -> RAG Retriever -> LLM Generator -> Code Output -> ROS 2 Integration

**Critical Path**: User Input + Capability Model → RAG Retriever → LLM → Code Generation → Integration Testing

**Design Tradeoffs**: RAG-based approach vs. pure LLM generation (accuracy vs. context awareness), structured models vs. free-form input (constraints vs. flexibility)

**Failure Signatures**: Incorrect identifier usage, missing library imports, structural violations of capability model constraints, semantic mismatches between natural language input and capability model

**First Experiments**: 1) Generate simple skill from basic capability model, 2) Test cross-language generation with existing library integration, 3) Evaluate error handling for ambiguous capability models

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to mobile robot platform using ROS 2 and Python
- Success metrics focused on structural correctness rather than comprehensive functional validation
- Real-time performance implications not addressed
- Error handling for ambiguous or incomplete capability models not explored

## Confidence
- **High confidence** in technical feasibility of using LLMs with RAG for automatic skill generation from capability models
- **Medium confidence** in claim that approach significantly reduces manual coding effort, given limited scope and need for some manual corrections
- **Low confidence** in scalability and real-time performance implications for industrial deployment

## Next Checks
1. Evaluate approach on multiple robotics frameworks (e.g., ROS 1, industrial PLCs) and programming languages to assess cross-platform compatibility
2. Conduct comprehensive functional testing of generated skills in varied operational scenarios to measure robustness and error handling
3. Measure time and effort required for manual corrections versus traditional manual skill development across larger skill set