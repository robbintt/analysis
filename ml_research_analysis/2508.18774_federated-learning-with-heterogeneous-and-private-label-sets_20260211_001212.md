---
ver: rpa2
title: Federated Learning with Heterogeneous and Private Label Sets
arxiv_id: '2508.18774'
source_url: https://arxiv.org/abs/2508.18774
tags:
- client
- labels
- label
- private
- clients
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses federated learning when clients have different
  subsets of labels (heterogeneous label sets), including the challenging private
  setting where label sets are unknown to other clients. The authors adapt FedAvg
  and FedProx for private label sets by having clients send updates only for their
  known labels, and aggregating per-label updates weighted by client sample sizes.
---

# Federated Learning with Heterogeneous and Private Label Sets

## Quick Facts
- **arXiv ID**: 2508.18774
- **Source URL**: https://arxiv.org/abs/2508.18774
- **Reference count**: 40
- **Primary result**: Clients can retain label privacy with minimal accuracy loss compared to public label methods through per-label aggregation and central tuning

## Executive Summary
This work addresses federated learning when clients have different subsets of labels (heterogeneous label sets), including the challenging private setting where label sets are unknown to other clients. The authors adapt FedAvg and FedProx for private label sets by having clients send updates only for their known labels, and aggregating per-label updates weighted by client sample sizes. They also propose central tuning methods (MSE and pairwise loss) to align client classifiers using an unlabeled server dataset. Experiments on CIFAR10 and FashionMNIST show that both adapted methods and central tuning achieve strong performance, with central tuning being particularly effective in the private label setting.

## Method Summary
The method adapts FedAvg and FedProx for private label sets by having clients train only on their known labels and return partial updates. The server aggregates encoder parameters normally but aggregates classifier parameters per-label, weighting by sample sizes of clients possessing each label. For central tuning, an unlabeled server dataset is used to optimize alignment losses (MSE or pairwise) between the global classifier and client predictions on their known labels. This allows classifier alignment without label information.

## Key Results
- Adapted FedAvg and FedProx achieve comparable accuracy to public-label methods when aggregating per-label updates weighted by client sample sizes
- Central tuning with MSE loss on unlabeled server data significantly improves performance in private settings
- Private label methods achieve similar performance to public label methods with minimal accuracy loss
- Pairwise consistency loss exploits relative structure but can fail when labels are absent from all clients in a round

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Clients can train on partial label sets and aggregate updates without knowing the global label set, achieving comparable accuracy to public-label methods.
- Mechanism: The server sends each client only the classifier parameters for their known labels (θ_ψ[Y_k]). Clients train locally and return updates. The server aggregates encoder parameters normally but aggregates classifier parameters per-label, weighting by sample sizes of clients possessing each label.
- Core assumption: Subset-consistent labeling mechanisms (Assumption 1)—client conditional label distributions match the global distribution when conditioned on their label subset. Also assumes a shared optimal feature representation exists across clients.
- Evidence anchors:
  - [abstract]: "The authors adapt FedAvg and FedProx for private label sets by having clients send updates only for their known labels, and aggregating per-label updates weighted by client sample sizes."
  - [section 4.1]: Under Assumption 1 with well-specified softmax, "convex combination of unbiased estimates of client-optimal parameters is unbiased for the server-optimal parameters."
  - [corpus]: Weak corpus support for this specific mechanism; [arxiv 2506.20431] addresses label skew through distillation but not per-label aggregation.
- Break condition: When client representations are poorly aligned (no single optimal encoder exists), or when labeling mechanisms are not subset-consistent across clients.

### Mechanism 2
- Claim: An unlabeled server dataset can align global classifier predictions with client predictions on their known labels, improving performance in private settings.
- Mechanism: After aggregation, the server tunes the central classifier by minimizing MSE between its predictions and client predictions: E[(h_k(y|X) - h(y|X))²] for y ∈ Y_k. This forces the global model to match client predictions on shared labels without label information.
- Core assumption: The server has access to an unlabeled dataset drawn from p(X). Client models approximate true conditionals well enough for alignment to transfer.
- Evidence anchors:
  - [abstract]: "They also propose central tuning methods (MSE and pairwise loss) to align client classifiers using an unlabeled server dataset."
  - [section 5.1]: "In the private setting... the tuning approach is superior to the adapted methods... the MSE loss performs slightly better than the pairwise loss."
  - [corpus]: Limited support; [arxiv 2511.17796] uses semi-supervised FL but with client-side unlabeled data, differing from server-side tuning.
- Break condition: When unlabeled server data is unavailable or not from p(X). When extreme sparsity means labels are absent from all participating clients in a round.

### Mechanism 3
- Claim: A pairwise consistency loss derived from classifier combination theory can aggregate heterogeneous client classifiers into a coherent global classifier.
- Mechanism: Under Proposition 1, perfect classifiers satisfy h_k(y|x)h(y'|x) ≈ h_k(y'|x)h(y|x). The loss minimizes E[(h_k(y|X)h(y'|X) - h_k(y'|X)h(y|X))²] over all label pairs within each client's label set.
- Core assumption: Assumption 1 (subset-consistent labeling). Client classifiers are accurate enough that pairwise consistency implies global correctness.
- Evidence anchors:
  - [section 4.2]: Proposition 1 states "the perfect central classifier p(Y=y|X=x) can be aggregated from perfect client classifiers" under subset-consistency.
  - [section 5.1]: "The pairwise loss performs better than the MSE loss in the public setting and worse in the private setting."
  - [corpus]: Weak corpus support; classical classifier combination literature [6, 20] is cited but not FL-specific.
- Break condition: Appendix B identifies critical failure: when a label is absent from ALL clients in a round, pairwise loss penalizes non-zero probability for that label, harming generalization. More likely with fewer labels per client.

## Foundational Learning

- **Softmax Normalization Cancellation**: Understanding why partial-label training works—the normalization terms cancel when computing p(Y=y|X=x, Y∈Y_k), allowing the same parameters to be optimal locally and globally.
  - Quick check: Given softmax over {A,B,C,D} with logits [la, lb, lc, ld], what is p(Y=A | Y∈{A,B}) expressed using only la and lb?

- **Federated Averaging Weighting**: The per-label aggregation extends FedAvg's sample-weighted averaging to handle missing labels. Understanding w_k = n_k/Σn_k' is essential.
  - Quick check: If client 1 has 100 samples with labels {A,B} and client 2 has 50 samples with {B,C}, what weight should label B's parameters receive from each client?

- **Covariate Shift vs. Label Shift**: Assumption 1 relates to covariate shift (marginal p(X) varies but p(Y|X) is consistent when conditioned on label availability). Section 4.1's remark clarifies this.
  - Quick check: In the pharmaceutical example, if company A tests drugs {1,2} and company B tests {2,3}, and patient populations differ, which shift type describes each variation source?

## Architecture Onboarding

- **Component map**:
  - Client Local Training -> Per-Label Aggregation -> Central Tuning Module (optional) -> Label Set Registry

- **Critical path**:
  1. Server initializes θ⁰ = (θ_ϕ, θ_ψ) with |Y| output dimensions
  2. For each client k: server sends (θ_ϕ, θ_ψ[Y_k])—slicing classifier to known labels
  3. Client k trains locally, returns (θ_ϕ,k, θ_ψ,k)
  4. Server aggregates: θ_ϕ via weighted average; θ_ψ(y) via average over {k : y∈Y_k}
  5. (Optional) If tuning: server optimizes alignment loss on X_tune, updates θ_ψ
  6. Repeat from step 2

- **Design tradeoffs**:
  - Adapted FedAvg vs. Tuning: FedAvg needs no server data and less compute but assumes representation alignment. Tuning handles misalignment but needs unlabeled data and adds variance.
  - MSE vs. Pairwise: MSE more robust to label sparsity (private setting). Pairwise exploits relative structure better but fails when labels are globally absent.
  - Privacy vs. Performance: Private labels achieve similar performance to public in experiments—minimal privacy cost, but depends on label overlap across clients.

- **Failure signatures**:
  - Low accuracy + many labels/client: Likely representation misalignment—try pairwise tuning
  - High variance across seeds: Tuning methods exhibit this; consider adapted FedAvg baseline
  - Specific label accuracy near zero: Label may have insufficient client coverage OR pairwise loss suppressing it (Appendix B)
  - Tuning worse than no tuning (public): Observed on FashionMNIST—task simple enough that tuning interference outweighs benefit

- **First 3 experiments**:
  1. Run adapted FedAvg on CIFAR10 with 5 labels/client, varying seeds (n=10). Record test and per-class accuracy to identify underrepresented labels.
  2. Compare no-tuning vs. MSE vs. pairwise on same configuration. If pairwise underperforms, audit for globally-absent labels per round.
  3. Sweep labels per client from 2-10 on both datasets. Plot accuracy curve to identify degradation threshold and where tuning helps most.

## Open Questions the Paper Calls Out

- **Question**: How do these methods perform on datasets with naturally occurring label set heterogeneity, rather than the synthetic splits used in experiments?
  - Basis: The authors state that in future work, "more realistic datasets could be considered which naturally exhibit label set heterogeneity."
  - Why unresolved: Current experiments rely on artificially splitting CIFAR10 and FashionMNIST where labels are distributed uniformly at random, which may not reflect real-world client data distributions.
  - What evidence would resolve it: Benchmarks on datasets where clients inherently possess disjoint label sets (e.g., medical consortiums) without artificial subsampling.

- **Question**: Can more sophisticated FL algorithms (e.g., SCAFFOLD or Ditto) be effectively modified to handle private label sets?
  - Basis: The discussion suggests that "some other FL methods could perhaps be adapted to the private label set setting."
  - Why unresolved: This work focused on adapting FedAvg and FedProx; algorithms utilizing control variates or personalization layers were not investigated for the private label restriction.
  - What evidence would resolve it: Applying the proposed server-side aggregation logic to advanced optimizers and evaluating convergence speed and accuracy.

- **Question**: Can alternative tuning losses be developed that maintain representational alignment while mitigating the high variance observed in current tuning methods?
  - Basis: The abstract notes that central tuning often comes at the "cost of higher variance," and the discussion invites "further consideration of and comparison with other tuning losses."
  - Why unresolved: The pairwise loss failed to outperform baselines in some private settings due to sparsity issues, and MSE tuning exhibited high variance.
  - What evidence would resolve it: A theoretical analysis or empirical validation of a loss function that provides stable gradients even when specific labels are globally absent in a round.

## Limitations

- The paper does not specify the number of clients in the federation, which affects scalability and communication cost analysis
- Label assignment strategy details are unclear—it's unspecified whether label overlap is guaranteed across clients or purely random
- The source of the unlabeled server tuning dataset (held-out training data vs. separate collection) could impact practical deployment feasibility
- CNN architecture details beyond kernel sizes (channel counts, fully connected dimensions) are unspecified, limiting exact reproduction

## Confidence

- **High confidence**: The core mechanism of per-label aggregation (Mechanism 1) is mathematically sound under the stated assumptions, with clear derivation and theoretical support from subset-consistent labeling theory
- **Medium confidence**: Central tuning methods show empirical promise, but the theoretical grounding is weaker—the alignment assumption (server can match client predictions without labels) needs more rigorous justification
- **Low confidence**: Pairwise consistency loss performance claims, particularly the claim it "exploits relative structure" better than MSE, require careful validation since Appendix B identifies failure modes when labels are globally absent

## Next Checks

1. **Label sparsity audit**: Systematically measure label coverage across rounds (how often labels are absent from ALL clients in a round) and correlate with pairwise loss performance degradation to validate Appendix B's claim

2. **Overlap sensitivity study**: Vary the overlap between client label sets (from disjoint to fully overlapping) while keeping labels per client constant to quantify how much label redundancy is needed for successful representation alignment

3. **Scaling experiment**: Test with increasing numbers of clients (10x, 100x) to measure communication efficiency gains from sending only partial classifiers and to identify at what scale per-label aggregation becomes advantageous over full-parameter aggregation