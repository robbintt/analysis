---
ver: rpa2
title: Developing a Comprehensive Framework for Sentiment Analysis in Turkish
arxiv_id: '2512.00515'
source_url: https://arxiv.org/abs/2512.00515
tags:
- sentiment
- words
- word
- these
- other
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This thesis developed a comprehensive framework for sentiment
  analysis in Turkish, addressing the lack of robust methods for this morphologically-rich
  language. The research introduced five major contributions: (1) a novel feature
  set combining unsupervised, semi-supervised, and supervised metrics, outperforming
  neural networks for Turkish and English datasets; (2) a fine-grained morphological
  analysis assigning sentiment scores to morphemes, adaptable to other agglutinative
  languages; (3) a novel ensemble neural network architecture combining recurrent
  and recursive models for aspect-based sentiment analysis, achieving state-of-the-art
  results; (4) novel word and document embeddings incorporating sentiment, syntactic,
  semantic, and lexical characteristics; and (5) redefining context windows as subclauses
  for word vector models, improving performance over sliding window approaches.'
---

# Developing a Comprehensive Framework for Sentiment Analysis in Turkish

## Quick Facts
- **arXiv ID:** 2512.00515
- **Source URL:** https://arxiv.org/abs/2512.00515
- **Reference count:** 40
- **Primary result:** Comprehensive sentiment analysis framework for Turkish, combining classical ML with engineered features to outperform neural networks

## Executive Summary
This thesis addresses the lack of robust sentiment analysis methods for Turkish, a morphologically-rich language. The research introduces five major contributions: a novel feature set combining unsupervised, semi-supervised, and supervised metrics that outperforms neural networks for both Turkish and English datasets; a fine-grained morphological analysis assigning sentiment scores to morphemes; a novel ensemble neural network architecture combining recurrent and recursive models for aspect-based sentiment analysis; novel word and document embeddings incorporating sentiment, syntactic, semantic, and lexical characteristics; and redefining context windows as subclauses for word vector models. The methods were evaluated on multiple datasets in both Turkish and English, demonstrating significant improvements over existing approaches.

## Method Summary
The framework combines classical machine learning with engineered features for sentiment classification. Preprocessing includes deasciification, morphological parsing, and stop-word removal while retaining intensifiers. The core feature set combines three metrics: unsupervised PMI scores from web search, semi-supervised PPMI graph propagation with factorial weighting, and supervised delta tf-idf scores. These are combined into "3-feats" (minimum, mean, maximum document polarity) fed into a linear SVM. For aspect-based sentiment analysis, a novel ensemble architecture uses dependency parsing to extract sub-reviews per aspect group, trains recursive neural networks on each sub-review, then feeds root embeddings into a recurrent GRU network. The framework also introduces partial surface forms by retaining only top discriminative morphemes based on polarity scores.

## Key Results
- Novel feature engineering approach combining unsupervised, semi-supervised, and supervised metrics outperformed neural networks on Turkish and English datasets
- Fine-grained morphological analysis assigning sentiment scores to morphemes adaptable to other agglutinative languages
- Ensemble recurrent-recursive neural network architecture achieved state-of-the-art results for aspect-based sentiment analysis
- Novel embeddings incorporating sentiment, syntactic, semantic, and lexical characteristics
- Subclause-based context windows improved performance over sliding window approaches

## Why This Works (Mechanism)

### Mechanism 1: Combined Feature Engineering Outperforms Pure Neural Approaches
The approach computes minimum, mean, and maximum sentiment polarity scores per document from combined unsupervised (PMI-based), semi-supervised (graph propagation), and supervised (delta tf-idf) word-level scores. These capture both central tendency and variance of sentiment expression. When unsupervised and supervised scores disagree, a weighted coefficient reduces the supervised contribution to handle ambiguous cases. The advantage may disappear with significantly larger training data where neural networks can learn implicit sentiment patterns more effectively.

### Mechanism 2: Partial Surface Forms Capture Sentiment-Bearing Morphemes
Delta tf-idf scores are computed for all corpus words. Each morpheme receives the average score of words it appears in. The top N% of discriminative morphemes (by absolute polarity) are retained while others are stripped, creating "partial surface forms." This reduces noise from neutral morphemes while preserving sentiment-bearing suffixes. Languages with fewer sentiment-bearing morphemes, or domains where morpheme semantics shift significantly, may not benefit.

### Mechanism 3: Ensemble of Recurrent and Recursive Networks Captures Complementary Information
Reviews are decomposed into sub-reviews per aspect group using dependency parsing. Each sub-review is trained as a recursive tree capturing grammatical structure. The root embedding—representing the sub-review's overall sentiment—concatenates with word embeddings in a GRU-based recurrent model that propagates inter-aspect relations. Excessive parsing errors or very long reviews with complex structures may introduce noise that degrades performance.

## Foundational Learning

- **Concept: Delta tf-idf Weighting**
  - Why needed here: This supervised weighting scheme explicitly encodes class-specific word importance rather than pure frequency, enabling the 3-feats approach
  - Quick check question: Can you explain why multiplying tf-idf by a class-ratio term (delta idf) makes sentiment-bearing words more distinguishable?

- **Concept: Recursive vs. Recurrent Neural Networks**
  - Why needed here: The ensemble architecture requires understanding that recursive networks process tree structures (syntax) while recurrent networks process sequences (temporal order)
  - Quick check question: Given a sentence "The food was good but service was slow," would a constituency parser group "good" and "slow" in separate subtrees?

- **Concept: Agglutinative Morphology**
  - Why needed here: Turkish word formation through suffix concatenation means sentiment can be encoded in morphemes, not just roots
  - Quick check question: If "güzel" (beautiful) has positive polarity, what happens when the negation suffix "-siz" is attached to form "güçsüz" (weak/powerless)?

## Architecture Onboarding

- **Component map:** Preprocessing pipeline → morphological parsing → partial surface form generation → unsupervised/semi-supervised/supervised score computation → combination via Eq. 4.8 → 3-feats extraction → classical ML classifier (SVM ensemble)
- **Critical path:** The 3-feats extraction (min/mean/max document polarity) is the highest-impact component—this single transformation accounts for majority of performance gain over baselines
- **Design tradeoffs:** Partial surface forms: higher accuracy but requires labeled data for morpheme polarity lexicon; Dependency vs. constituency parsing: dependency produces more coherent sub-reviews but requires language-specific parser; Static vs. non-static embeddings: non-static learns sentiment during training but risks overfitting on small corpora
- **Failure signatures:** Twitter data underperforms movie data by 10-15% across all methods due to OOV words and noise; Neutral class not modeled—binary classification only; Morpheme polarity lexicon may not generalize across domains without re-computation
- **First 3 experiments:** 1) Replicate the 3-feats baseline on the provided Turkish movie corpus using delta tf-idf with SVM to validate the reported 90.98% accuracy; 2) Ablate the combination weights (c_s=0.7, c_u=0.3) via grid search on held-out validation to test sensitivity to unsupervised contribution; 3) Implement the sub-review extraction using spaCy dependency parsing on the SemEval-2014 laptop dataset to reproduce the 76.15% accuracy

## Open Questions the Paper Calls Out

### Open Question 1
Can the performance gap between classical machine learning and neural network models for Turkish sentiment analysis be closed by implementing specific strategies to handle Out-of-Vocabulary (OOV) words? The author hypothesizes that OOV handling (e.g., averaging context embeddings) might only yield slight improvements, but this assumption was not verified experimentally against the strong performance of classical models.

### Open Question 2
How can a constituency parser-based recursive neural network be modified to effectively identify and process neutral opinions in Aspect-Based Sentiment Analysis? The current bottom-up algorithm stops expanding the tree once a node with non-neutral (positive/negative) polarity is encountered, thereby failing to handle cases where an aspect is neutral.

### Open Question 3
Does redefining context windows as subclauses improve the performance of architectures such as Word2Vec, Convolutional Neural Networks (CNNs), or LSTMs compared to the tested GloVe and SVD models? The benefits of subclausal context were demonstrated only on count-based (SVD) and log-bilinear regression (GloVe) models; it is uncertain if this linguistic definition benefits predictive neural embeddings or convolutional filters.

## Limitations
- Dataset accessibility issues: Turkish Twitter corpus and specific morphological tools (Zemberek-based deasciifier, parsers) are not publicly available with version specifications
- Binary classification framework excludes neutral sentiment, limiting applicability to datasets with neutral classes
- Morpheme-based partial surface form approach assumes stable sentiment polarity across domains, which may not hold for specialized vocabularies

## Confidence

- **High Confidence**: The core finding that engineered features outperform neural networks on small-to-medium Turkish datasets (consistent with classical ML advantages in low-data regimes)
- **Medium Confidence**: The morpheme-based sentiment scoring mechanism (limited corpus validation for morpheme stability across domains)
- **Low Confidence**: The ensemble ABSA architecture performance claims (no direct benchmark comparison, relies on internal ablation only)

## Next Checks

1. Replicate the 3-feats baseline on the Turkish movie corpus using delta tf-idf with SVM to verify the 90.98% accuracy claim
2. Implement the sub-review extraction using spaCy dependency parsing on SemEval-2014 laptop dataset to reproduce the 76.15% accuracy result
3. Perform ablation study varying the unsupervised/weighted combination coefficients (c_u, c_s) to test sensitivity to the 0.7/0.3 ratio