---
ver: rpa2
title: Leveraging Foundational Models and Simple Fusion for Multi-modal Physiological
  Signal Analysis
arxiv_id: '2512.15250'
source_url: https://arxiv.org/abs/2512.15250
tags:
- multi-modal
- physiological
- signals
- encoder
- fusion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of multi-modal physiological
  signal analysis by proposing a foundation model approach that combines self-supervised
  pretraining with simple fusion strategies. The authors adapt the CBraMod architecture
  for large-scale ECG pretraining, introducing a dual-masking strategy to capture
  both intra-lead temporal patterns and inter-lead spatial dependencies.
---

# Leveraging Foundational Models and Simple Fusion for Multi-modal Physiological Signal Analysis

## Quick Facts
- arXiv ID: 2512.15250
- Source URL: https://arxiv.org/abs/2512.15250
- Reference count: 16
- Primary result: Achieves near state-of-the-art AUC scores of 84.79 for arousal and 86.69 for dominance in emotion recognition using simple fusion of ECG and EEG representations

## Executive Summary
This paper addresses the challenge of multi-modal physiological signal analysis by proposing a foundation model approach that combines self-supervised pretraining with simple fusion strategies. The authors adapt the CBraMod architecture for large-scale ECG pretraining, introducing a dual-masking strategy to capture both intra-lead temporal patterns and inter-lead spatial dependencies. They leverage a pre-trained CBraMod encoder for EEG and pre-train a symmetric ECG encoder, obtaining rich modality-specific representations. These representations are fused via simple embedding concatenation, allowing the classification head to learn cross-modal interactions. Evaluated on emotion recognition using the DREAMER dataset, their approach achieves near state-of-the-art performance, demonstrating that carefully designed physiological encoders combined with straightforward fusion can effectively harness complementary information from ECG and EEG signals.

## Method Summary
The authors propose a foundation model approach for multi-modal physiological signal analysis that combines self-supervised pretraining with simple fusion strategies. They adapt the CBraMod architecture for large-scale ECG pretraining, introducing a dual-masking strategy to capture both intra-lead temporal patterns and inter-lead spatial dependencies. A pre-trained CBraMod encoder is leveraged for EEG, while a symmetric ECG encoder is pre-trained to obtain rich modality-specific representations. These representations are fused via simple embedding concatenation, allowing the classification head to learn cross-modal interactions. The model is evaluated on emotion recognition using the DREAMER dataset, demonstrating the effectiveness of their approach in harnessing complementary information from ECG and EEG signals.

## Key Results
- Achieved AUC scores of 84.79 for arousal and 86.69 for dominance in emotion recognition
- Near state-of-the-art performance on the DREAMER dataset
- Demonstrated effectiveness of simple fusion strategies for multi-modal physiological signal analysis

## Why This Works (Mechanism)
The proposed approach works by leveraging foundation models to extract rich, modality-specific representations from physiological signals, then combining these representations through simple fusion to capture complementary information. The dual-masking strategy in ECG pretraining enables the model to learn both temporal patterns within each lead and spatial dependencies across multiple leads simultaneously. By using pre-trained encoders for both ECG and EEG modalities, the model benefits from transfer learning, reducing the need for large labeled datasets. The simple concatenation fusion allows the classification head to learn cross-modal interactions without introducing complex fusion mechanisms that might overfit or require additional training data.

## Foundational Learning
**Self-supervised Pretraining**
- Why needed: Enables learning rich representations from unlabeled physiological signals, reducing dependency on labeled data
- Quick check: Verify that pretraining improves downstream task performance compared to training from scratch

**Dual-masking Strategy**
- Why needed: Captures both intra-lead temporal patterns and inter-lead spatial dependencies in multi-lead ECG signals
- Quick check: Ablate one masking component and measure impact on downstream task performance

**Modality-specific Encoders**
- Why needed: Allows each physiological signal type (ECG, EEG) to be processed by architectures optimized for its characteristics
- Quick check: Compare performance when using shared encoder versus modality-specific encoders

**Simple Fusion Strategies**
- Why needed: Provides computationally efficient way to combine representations while avoiding overfitting from complex fusion mechanisms
- Quick check: Benchmark simple fusion against attention-based and cross-attention fusion methods

## Architecture Onboarding

**Component Map**
Pretrained CBraMod ECG Encoder -> Dual-masking Strategy -> ECG Representation
Pretrained CBraMod EEG Encoder -> EEG Representation
ECG Representation + EEG Representation -> Concatenation -> Classification Head -> Emotion Recognition Output

**Critical Path**
The critical path for emotion recognition involves: 1) Extracting modality-specific representations using pre-trained CBraMod encoders, 2) Concatenating these representations, and 3) Feeding the combined representation to the classification head. The dual-masking strategy during ECG pretraining is crucial for capturing the spatial and temporal dependencies necessary for effective emotion recognition.

**Design Tradeoffs**
The authors chose simple concatenation fusion over more complex attention-based methods to maintain computational efficiency and reduce overfitting risk. This tradeoff favors label efficiency and scalability over potentially capturing more nuanced cross-modal interactions. The use of pre-trained encoders enables transfer learning but introduces dependency on foundation models that may not generalize to all physiological domains.

**Failure Signatures**
Potential failure modes include: 1) Poor generalization if pretrained encoders are not sufficiently diverse, 2) Suboptimal performance if the simple fusion strategy cannot capture complex cross-modal relationships, 3) Degradation when applied to physiological signals significantly different from those in the pretraining corpus.

**First Experiments**
1. Ablation study: Remove dual-masking from ECG pretraining and measure impact on downstream performance
2. Fusion comparison: Replace concatenation with attention-based fusion and evaluate performance changes
3. Domain transfer: Apply pretrained encoders to a different physiological signal analysis task (e.g., sleep staging) to assess generalizability

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Relies on pre-trained CBraMod encoders, introducing dependency on external foundation models
- Simple concatenation fusion may miss complex cross-modal temporal dynamics
- Evaluation limited to emotion recognition on the DREAMER dataset, raising questions about scalability to clinical applications

## Confidence
- **High confidence** in technical implementation of dual-masking pretraining and foundation model framework
- **Medium confidence** in reported performance metrics based on single benchmark dataset
- **Low confidence** in generalizability of simple fusion strategies to more complex multi-modal physiological scenarios

## Next Checks
1. Test pretrained encoders on clinically diverse dataset (e.g., sleep staging or arrhythmia detection) to assess domain transferability beyond emotion recognition
2. Compare simple concatenation fusion against attention-based and cross-attention fusion methods on same dataset to quantify performance trade-off
3. Evaluate model's robustness to missing modalities and noisy signals by systematically ablating one modality or introducing synthetic noise during inference