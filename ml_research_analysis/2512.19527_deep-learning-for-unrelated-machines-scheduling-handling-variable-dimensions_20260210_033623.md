---
ver: rpa2
title: 'Deep Learning for Unrelated-Machines Scheduling: Handling Variable Dimensions'
arxiv_id: '2512.19527'
source_url: https://arxiv.org/abs/2512.19527
tags:
- scheduling
- machines
- jobs
- network
- machine
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles unrelated-machines scheduling with variable
  input dimensions, where each job-machine pair has unique processing times. The authors
  propose a novel deep learning approach that processes entire scheduling environments
  offline using a sophisticated architecture combining NLP-inspired structures.
---

# Deep Learning for Unrelated-Machines Scheduling: Handling Variable Dimensions

## Quick Facts
- arXiv ID: 2512.19527
- Source URL: https://arxiv.org/abs/2512.19527
- Authors: Diego Hitzges; Guillaume Sagnol
- Reference count: 20
- One-line result: Achieves 2.51% above optimal on small instances and generalizes to 100 jobs/10 machines with 22.22% improvement over dispatching rules

## Executive Summary
This paper addresses unrelated-machines scheduling where each job-machine pair has unique processing times, creating variable input and output dimensions. The authors propose a deep learning architecture that processes entire scheduling environments offline using NLP-inspired structures including bidirectional LSTMs, transformer encoders, and action-pointer decoders. Trained on small instances (8 jobs, 4 machines) with supervised learning using optimal labels, the model achieves costs only 2.51% above optimal and generalizes remarkably well to larger problems (up to 100 jobs, 10 machines). Across all tested configurations, it consistently outperforms an advanced dispatching rule by 22.22% on average.

## Method Summary
The approach reformulates scheduling as a sequential decision-making problem where each state represents when a machine becomes free. For each job, machine-specific data (processing times, machine runtimes, earliness, weights) is embedded using a bidirectional LSTM to produce fixed-size vectors regardless of machine count. A transformer encoder applies self-attention across jobs to capture competitive interactions, followed by an action-pointer decoder that handles variable output dimensions by producing attention weights over job assignments. The network is trained via supervised learning on 100,000 simulated instances using exact optimal solutions computed for small instances as training labels.

## Key Results
- Achieves optimality gap of only 2.51% on 8-job/4-machine test instances
- Generalizes to 100-job/10-machine problems while maintaining strong performance
- Outperforms advanced dispatching rule by 22.22% average improvement across all configurations
- Handles variable input/output dimensions naturally through pointer network architecture

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Treating machine-specific job data as a time series enables fixed-dimensional embeddings regardless of machine count.
- Mechanism: For each job j, the resource matrix X_res^(j) ∈ R^(M×4) is passed through a bidirectional LSTM. The LSTM's final hidden state becomes a fixed-size vector x_res^(j) ∈ R^16, independent of M. This allows the same network to process states with 4 or 10 machines.
- Core assumption: The ordering of machines (sorted by runtime, weight, deadline) provides a meaningful sequence structure that LSTMs can exploit.
- Evidence anchors:
  - [abstract] "leveraging various NLP-inspired architectures, it effectively processes any number of jobs and machines with varying feature dimensions"
  - [Section IV-B] "each X_res^(j) is embedded into a fixed-size representation x_res^(j) by being passed through a bidirectional LSTM"
  - [corpus] Weak direct evidence; related scheduling work focuses on genetic programming rules rather than architecture design for variable dimensions.
- Break condition: If machine ordering becomes arbitrary (e.g., simultaneous availability with identical weights), the sequential assumption degrades.

### Mechanism 2
- Claim: Self-attention over job embeddings captures competitive interactions between jobs for shared machine resources.
- Mechanism: After individual job embedding, a Transformer encoder applies self-attention across all J job vectors. This allows each job's representation to incorporate information about other jobs' processing times on the same machines, enabling the network to learn which job-machine assignments create bottlenecks.
- Core assumption: Inter-job dependencies (not just individual job-machine fit) are predictive of optimal scheduling decisions.
- Evidence anchors:
  - [Section IV-C] "This encoder utilizes a self-attention mechanism, effectively broadening the context of x_emb^(j) to include how other jobs interact with the same machines"
  - [abstract] "generates a complete schedule considering the entire input at once"
  - [corpus] Semantic-Aware Scheduling paper (arXiv:2510.03334) uses similar context-aggregation ideas for GPU cluster scheduling, suggesting transferability.
- Break condition: When jobs are independent with non-overlapping machine preferences, attention provides diminishing returns.

### Mechanism 3
- Claim: Pointer-style decoding enables variable output dimensions matching the action space (J jobs + 1 deactivation).
- Mechanism: The Action-Pointer decoder uses a bidirectional LSTM over encoded job representations to produce hidden states h_B^(1)...h_B^(J), then a second LSTM with cross-attention produces a query q. The attention distribution over [h_B^(1)...h_B^(J+1)] yields probabilities for each action, scaling naturally to any J.
- Core assumption: The pointer mechanism can learn to "point" to the optimal job without explicit enumeration of all permutations.
- Evidence anchors:
  - [Section IV-D] "We employ an Action-Pointer decoder to achieve this flexibility... the neural network's final output is then an attention distribution"
  - [Table I] Action-Pointer total parameters: 103,680, output dimension J+1
  - [corpus] Pointer networks (Vinyals et al. 2015) are cited as foundation; corpus lacks direct replication for scheduling.
- Break condition: When J exceeds training distribution significantly (e.g., >100 jobs with only 8-job training), attention may dilute across too many candidates.

## Foundational Learning

- Concept: **Markov Decision Processes for Scheduling**
  - Why needed here: The paper reformulates scheduling as sequential decision-making where each state (machine becoming free) requires an action (assign job or deactivate). Understanding state transitions and value functions is essential to interpret the training targets.
  - Quick check question: Can you explain why the optimal action at a state depends on future states, not just immediate cost?

- Concept: **Pointer Networks**
  - Why needed here: The output dimension varies with problem size. Standard neural networks require fixed output sizes; pointer networks solve this by producing attention weights over a variable-length input sequence.
  - Quick check question: How does a pointer network differ from a standard classification head when the number of classes changes per input?

- Concept: **Supervised Learning with Optimal Labels**
  - Why needed here: Unlike reinforcement learning, this approach requires precomputed optimal actions (via exact solvers) for small instances. The network learns to imitate optimal decisions, then generalizes.
  - Quick check question: Why might supervised learning on small instances fail to generalize to large instances, and what architectural choices mitigate this?

## Architecture Onboarding

- Component map: Input → Sequential Embedding (Bi-LSTM per job) → Transformer Encoder (self-attention across jobs) → Action-Pointer Decoder (Bi-LSTM + cross-attention) → Output

- Critical path: The Sequential Embedding must produce meaningful fixed-size vectors; if the LSTM fails to compress machine information, the downstream Transformer has garbage input. Validate embedding quality first.

- Design tradeoffs:
  - Bi-LSTM vs. Transformer for machine embedding: LSTM handles variable M naturally but imposes sequential assumption; a Transformer would remove ordering dependency but require positional encodings and more data.
  - Supervised vs. RL training: Supervised requires optimal labels (expensive for large instances) but converges faster; RL is label-free but slower and less stable.
  - Early optimal cutoff (switching to exact solver when ≤2 jobs remain): improves performance but creates dependency on exact solver at inference.

- Failure signatures:
  - If network assigns jobs to clearly suboptimal machines (e.g., ignoring much shorter processing times), check LSTM embedding—may have learned spurious ordering patterns.
  - If deactivation is chosen too frequently, verify the deactivation hidden state h_B^(J+1) construction; FF_deact may need tuning.
  - If generalization to larger M fails (performance degrades beyond 10 machines), the LSTM trained only on M≤4 may not extrapolate.

- First 3 experiments:
  1. **Ablate the Transformer encoder**: Replace with identity pass-through. Compare % cost increase on 8-job/4-machine test set. Expect degradation if inter-job context matters.
  2. **Test embedding robustness to ordering**: Shuffle machine order (break the sorting assumption) before feeding to LSTM. Measure performance drop on held-out instances.
  3. **Probe generalization boundaries**: Train on 8 jobs/4 machines, test systematically on [10, 20, 50, 100] jobs and [4, 6, 8, 10] machines. Plot cost increase relative to dispatching rule to identify where advantage vanishes.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the proposed architecture maintain its performance when adapted for stochastic environments using discrete probability distributions as input vectors?
- Basis in paper: [explicit] The authors state in the Limitations section that "the methodology could be adapted for stochastic environments... for discrete distributions, separate vectors could represent potential processing times and their associated probabilities."
- Why unresolved: The current study exclusively evaluates deterministic settings with fixed processing times, deadlines, and weights.
- What evidence would resolve it: An evaluation of the model's regret (difference between realized and expected cost) when trained and tested on datasets where job durations are stochastic rather than fixed.

### Open Question 2
- Question: Does integrating Reinforcement Learning (RL) into the training framework yield significant performance gains over the supervised learning approach?
- Basis in paper: [explicit] The Conclusion notes that "the framework's compatibility with DRL could be leveraged to further enhance the model's performance while starting from a strong basis."
- Why unresolved: The authors utilized supervised learning to ensure quick convergence and high accuracy but did not implement or test any RL algorithms.
- What evidence would resolve it: A comparative study measuring the optimality gap of the current supervised model against a hybrid model that undergoes RL-based fine-tuning.

### Open Question 3
- Question: Can the network effectively generalize to scheduling problems involving sequence-dependent setup times or precedence constraints with only minimal architectural changes?
- Basis in paper: [explicit] The paper claims in the Limitations section that "Additional constraints can be incorporated with very minimal changes to the network architecture" and suggests this as a direction for future research.
- Why unresolved: The problem formulation (1) used for training and testing excludes sequence-dependent setup times and precedence constraints between jobs.
- What evidence would resolve it: Extending the input state representation to include setup time matrices or precedence graphs and evaluating the resulting schedules against specialized heuristics for those constraints.

## Limitations

- Reliance on exact optimal solutions for training data restricts approach to small instances (8 jobs, 4 machines) due to computational intractability of exact scheduling solvers
- Sequential LSTM assumption for machine ordering may not hold when machines become available simultaneously with similar characteristics
- Performance gap versus optimal solutions for larger instances is unknown, as exact solvers cannot verify optimality for test cases beyond training distribution

## Confidence

- **High confidence**: The architectural framework (Bi-LSTM → Transformer → Action-Pointer) is well-specified and mechanistically sound for handling variable dimensions
- **Medium confidence**: The 2.51% optimality gap on small instances is reliable; the 22.22% improvement over dispatching rules is measurable but depends on the specific rule chosen
- **Medium confidence**: Generalization claims are based on comparison to a dispatching rule, not to optimal solutions for larger instances
- **Low confidence**: The exact computational method for deriving optimal Q* and V* values is unspecified, making exact reproduction difficult

## Next Checks

1. **Validate optimal target computation**: Implement and verify the exact method (DP/MILP) for computing Q*(s,a) and V*(s) values on small instances, ensuring numerical stability of the softmax scaling

2. **Stress test ordering assumption**: Systematically measure performance degradation when machine input order is randomized, quantifying the cost of violating the sequential assumption

3. **Boundary analysis for generalization**: Conduct systematic scaling experiments beyond the training distribution (e.g., 12, 16, 24 jobs and 6, 8, 12 machines) to identify the precise limits where performance advantage over dispatching rules diminishes