---
ver: rpa2
title: Does Weak-to-strong Generalization Happen under Spurious Correlations?
arxiv_id: '2509.24005'
source_url: https://arxiv.org/abs/2509.24005
tags:
- group
- spurious
- teacher
- student
- weak
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work examines weak-to-strong (W2S) generalization when both
  teacher and unlabeled data exhibit group imbalance, which introduces spurious correlations.
  The authors theoretically characterize W2S performance in a ridgeless regression
  setting, showing that W2S gains diminish as the minority proportion gap between
  labeled and unlabeled data grows, and are maximized when these proportions are equal.
---

# Does Weak-to-strong Generalization Happen under Spurious Correlations?
## Quick Facts
- arXiv ID: 2509.24005
- Source URL: https://arxiv.org/abs/2509.24005
- Reference count: 40
- This work examines weak-to-strong generalization when both teacher and unlabeled data exhibit group imbalance, introducing spurious correlations.

## Executive Summary
This paper investigates weak-to-strong (W2S) generalization in the presence of spurious correlations, where both teacher and unlabeled data exhibit group imbalance. The authors provide both theoretical analysis and empirical validation to show that W2S gains diminish as the minority proportion gap between labeled and unlabeled data grows, and are maximized when these proportions are equal. To address W2S failures, they propose a confidence-based retraining method using generalized cross-entropy, which significantly improves performance without requiring group annotations.

## Method Summary
The paper combines theoretical analysis with empirical validation to study W2S generalization under spurious correlations. The theoretical component uses a ridgeless regression setting with Gaussian features to characterize W2S performance, showing that performance is maximized when minority proportions in labeled and unlabeled data are equal. Empirically, the authors validate these findings across multiple vision benchmarks (Waterbirds, BFFHQ, ImageNet-9, BG-COCO) and teacher-student pairs. To mitigate W2S failures, they propose a confidence-based retraining method that uses generalized cross-entropy to refine the student model, achieving up to 32.15% improvement in worst-group accuracy.

## Key Results
- W2S gains diminish as the minority proportion gap between labeled and unlabeled data grows
- W2S performance is maximized when minority proportions in labeled and unlabeled data are equal
- Confidence-based retraining method improves worst-group accuracy by up to 32.15% without requiring group annotations

## Why This Works (Mechanism)
The mechanism behind W2S generalization under spurious correlations relates to how the student model learns to balance between fitting the teacher's predictions and generalizing to the true data distribution. When minority proportions in labeled and unlabeled data are equal, the student can effectively learn to ignore spurious correlations. The confidence-based retraining method works by focusing on high-confidence predictions from the teacher, allowing the student to refine its understanding of the true underlying patterns while avoiding overfitting to spurious correlations present in the training data.

## Foundational Learning
1. **Weak-to-Strong Generalization**: The process where a weaker student model learns from a stronger teacher model. Why needed: Forms the basis of knowledge distillation and transfer learning. Quick check: Verify that student performance improves when learning from a stronger teacher.

2. **Spurious Correlations**: Features that correlate with labels in training data but are not causally related to the true decision boundary. Why needed: Understanding these helps explain why models fail on minority groups. Quick check: Identify features that correlate with labels but are not causally related.

3. **Group Imbalance**: Uneven distribution of data across different groups or classes. Why needed: Critical for understanding fairness and generalization issues. Quick check: Measure the proportion of minority vs majority samples in each dataset.

## Architecture Onboarding
**Component Map**: Labeled Data -> Teacher Model -> Student Model <- Unlabeled Data -> Confidence-based Retraining
**Critical Path**: Teacher generates pseudo-labels from unlabeled data → Student learns from teacher and unlabeled data → Confidence scores filter pseudo-labels → Retraining improves student
**Design Tradeoffs**: The method trades computational cost of confidence estimation for improved generalization to minority groups. Alternative designs could use different confidence metrics or incorporate group information if available.
**Failure Signatures**: Poor performance on minority groups, especially when labeled and unlabeled data have different group distributions. The method specifically addresses failures due to spurious correlations.
**First Experiments**: 1) Measure W2S performance gap across different minority proportion settings, 2) Compare confidence-based retraining with standard fine-tuning, 3) Evaluate worst-group accuracy improvement across different datasets

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Theoretical analysis is limited to ridgeless regression with Gaussian features, which may not fully capture deep neural network behavior
- Empirical validation focuses on vision tasks with well-defined spurious correlations, potentially limiting generalizability to other domains
- The effectiveness of the confidence-based retraining method is evaluated only in the context of W2S fine-tuning, not other transfer learning scenarios

## Confidence
- High confidence: The theoretical characterization of W2S generalization in the ridgeless regression setting is mathematically rigorous and aligns with empirical observations
- Medium confidence: Empirical results across multiple vision benchmarks are convincing, but generalizability to other domains is uncertain
- Low confidence: Applicability of the method in scenarios where group information is unavailable or unreliable is not fully addressed

## Next Checks
1. Extend theoretical analysis to nonlinear teacher models to assess findings in more complex settings
2. Test confidence-based retraining method on datasets from different domains (e.g., NLP, medical imaging)
3. Investigate performance under different retraining strategies such as curriculum learning or meta-learning