---
ver: rpa2
title: What are you sinking? A geometric approach on attention sink
arxiv_id: '2508.02546'
source_url: https://arxiv.org/abs/2508.02546
tags:
- reference
- layer
- attention
- layers
- frames
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper reframes attention sinks in transformers as fundamental
  geometric reference frames that establish stable coordinate systems in high-dimensional
  representation spaces. Through topological, spectral, and information-theoretic
  analysis of diverse architectures (Llama, Qwen, BERT, XLM-RoBERTa, Phi-2, Pythia,
  Gemma, Mistral), the authors identify three distinct reference frame types: centralized
  (decoder-only with standard RoPE), distributed (models with modified position encodings),
  and bidirectional (encoder models with absolute embeddings).'
---

# What are you sinking? A geometric approach on attention sink

## Quick Facts
- arXiv ID: 2508.02546
- Source URL: https://arxiv.org/abs/2508.02546
- Reference count: 40
- Primary result: Attention sinks in transformers are fundamental geometric reference frames establishing stable coordinate systems in high-dimensional representation spaces

## Executive Summary
This paper reframes attention sinks as fundamental geometric reference frames that establish stable coordinate systems in high-dimensional representation spaces. Through topological, spectral, and information-theoretic analysis of diverse architectures, the authors identify three distinct reference frame types: centralized, distributed, and bidirectional. Each type exhibits characteristic signatures in Betti numbers, Fiedler values, KL divergence, and Fisher information distribution. The research reveals that attention sinks emerge early in training as optimal solutions to the geometric constraints imposed by the softmax operation on the probability simplex.

## Method Summary
The authors analyze pre-trained transformer models (Llama, Qwen, BERT, XLM-RoBERTa, Phi-2, Pythia, Gemma, Mistral) using inference-only analysis on a curated dataset of 500 STEM-focused Wikipedia sentences (6-50 tokens). They construct distance matrices from attention weights (1 - Attention Matrix), compute persistent homology using Ripser to calculate Betti-0 and Betti-1 numbers, and analyze graph Laplacian eigenvalues at thresholds [0.001, 0.005, ..., 0.2]. The study measures topological signatures, spectral properties (Fiedler value, degree centralization), and information-theoretic metrics (KL divergence reduction, Fisher Information norm) to classify reference frame types and track their emergence during training.

## Key Results
- Three distinct reference frame types identified: centralized (decoder-only with standard RoPE), distributed (models with modified position encodings), and bidirectional (encoder models with absolute embeddings)
- Attention sinks emerge early in training as optimal solutions to geometric constraints imposed by softmax on the probability simplex
- Architectural choices directly influence which reference frame type develops, with position encoding type being the primary determinant
- Each frame type exhibits characteristic signatures in Betti numbers, Fiedler values, KL divergence, and Fisher information distribution

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Attention sinks function as geometric reference frames establishing coordinate systems for representation manifolds.
- Mechanism: Special tokens (BOS, CLS) maintain high cosine similarity with query vectors while having low ℓ2-norm, creating distinguished manifold points that anchor all other representations through consistent angular relationships.
- Core assumption: Representation spaces require stable reference points for tokens to establish unambiguous relative positions.
- Evidence anchors: [abstract] "AS is not an architectural artifact, but it is the manifestation of a fundamental geometric principle: the establishment of reference frames"; [Section 3] Formalizes R = (M, P, ϕ) where P contains reference points providing coordinate charts.

### Mechanism 2
- Claim: Softmax's probability simplex constraint mathematically necessitates reference frame formation.
- Mechanism: Softmax maps unbounded logits to bounded manifold ∆n-1 with intrinsic curvature, enforcing zero-sum attention allocation that privileges sparse distributions concentrated on minimal token subsets.
- Core assumption: The information bottleneck created by simplex constraint creates geometric pressure toward sparse, reference-anchored distributions.
- Evidence anchors: [Section 3.2] "This constraint mathematically necessitates the emergence of reference frames by creating two critical geometric effects"; [Section A] Details how curvature and conservation law create conditions for reference points.

### Mechanism 3
- Claim: Position encoding type determines which reference frame configuration emerges.
- Mechanism: Standard RoPE gives first token identity rotation (R₀ = I), creating centralized frames; scaled RoPE reduces first-token bias, enabling distributed frames; absolute embeddings support bidirectional dual-anchor structures.
- Core assumption: Architectural inductive biases guide gradient descent toward specific geometric solutions rather than deterministically programming them.
- Evidence anchors: [Section 3.4] Documents rotation matrix properties for each encoding type; [Table 2] Shows distinct spectral signatures correlating encoding with frame type.

## Foundational Learning

- Concept: Probability simplex (∆n-1)
  - Why needed here: Understanding why softmax creates geometric constraints forcing sparse attention distributions
  - Quick check question: Why must attention weights sum to 1, and how does this create zero-sum competition?

- Concept: Persistent homology / Betti numbers
  - Why needed here: Paper uses topological features (Betti₀ for components, Betti₁ for cycles) to classify reference frame types
  - Quick check question: What does Betti₁ = 0 across all layers indicate about the attention graph structure?

- Concept: Fiedler value (algebraic connectivity)
  - Why needed here: Spectral analysis uses Fiedler values to quantify how connected vs. star-like attention graphs are
  - Quick check question: What does a strong negative correlation between Fiedler value and degree centralization suggest?

## Architecture Onboarding

- Component map:
  Position encoding module → determines inductive bias toward frame type → Attention sink tokens → BOS (centralized), multiple tokens (distributed), start/end tokens (bidirectional) → Softmax layer → enforces simplex constraint enabling frame formation → Value transformation → where reference frames influence representation updates

- Critical path:
  1. Choose position encoding (RoPE → centralized; scaled RoPE → distributed; absolute → bidirectional)
  2. Initialize with appropriate special tokens for chosen frame type
  3. Monitor Betti numbers and Fiedler-centralization correlations during early training to verify expected frame emergence

- Design tradeoffs:
  - Centralized: Efficient hub-and-spoke computation, single point of failure, less contextual flexibility
  - Distributed: More adaptive, requires more parameters for coordination, higher information content change
  - Bidirectional: Enables full context access, higher topological complexity in early layers, limited to encoder use cases

- Failure signatures:
  - Removing sink tokens causes performance degradation despite no semantic content loss
  - Negative KL reduction when sinks removed (indicates geometric instability)
  - Unexpected frame type for given position encoding suggests initialization or architecture issues
  - Assumption: Frame type mismatches may indicate training instability

- First 3 experiments:
  1. **Ablation study**: Remove attention sink tokens and measure (a) task performance, (b) representation variance, (c) angular consistency between token pairs. Expect degradation if reference frame hypothesis holds.
  2. **Cross-architecture comparison**: Train identical model with different position encodings (standard RoPE vs. scaled RoPE vs. absolute), measure resulting frame type via Betti numbers and Fiedler-centralization correlations at multiple training checkpoints.
  3. **Early-training emergence tracking**: Use RMT analysis on checkpoints from step 0-1000 to verify when spectral gap and participation ratio diverge from random, confirming whether frames emerge before task performance converges.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can attention sink tokens function as geometric anchoring points to improve the efficiency of transfer learning across different model architectures?
- Basis in paper: [explicit] The conclusion explicitly states that future work will explore using attention sink tokens as anchoring points for transfer learning to preserve geometric stability.
- Why unresolved: The paper establishes the geometric existence and stability of these frames but does not test their utility as transferable structural priors during fine-tuning or domain adaptation.
- What evidence would resolve it: Experiments demonstrating that regularizing or aligning sink tokens during transfer learning results in faster convergence or higher performance compared to standard fine-tuning protocols.

### Open Question 2
- Question: Is it possible to design novel positional encodings that deterministically force a model to adopt a specific reference frame type, such as inducing a distributed frame in an encoder?
- Basis in paper: [inferred] The paper identifies a correlation between existing encodings (e.g., RoPE vs. ALiBi) and frame types, suggesting architectural "biases," but does not demonstrate the reverse engineering of this phenomenon.
- Why unresolved: The research analyzes existing architectures to classify emergent behaviors rather than constructing interventions to control the frame type outcome.
- What evidence would resolve it: The successful design and training of a modified architecture where the reference frame type is constrained by design (e.g., forcing a bidirectional frame in a decoder model) and verified via topological analysis.

### Open Question 3
- Question: Do the geometric structures of reference frames undergo transient reconfigurations during training that are missed by snapshot-based analysis?
- Basis in paper: [explicit] The limitations section notes that the topological and spectral analyses focus on specific network snapshots rather than continuously tracking evolution throughout training.
- Why unresolved: The current RMT analysis relies on discrete checkpoints (e.g., Step 0 to Step 8), which may fail to capture rapid, continuous phase transitions in the manifold's geometry.
- What evidence would resolve it: A high-resolution temporal study plotting Betti numbers and Fiedler values continuously across training iterations to visualize the precise formation trajectory of the reference frame.

## Limitations

- **Measurement assumptions**: Topological analysis depends critically on distance matrix construction (1 - attention) and threshold selection, with validity across diverse model scales unclear
- **Generalizability scope**: Analysis focuses on 9 specific architectures, not exhaustive of transformer landscape including models with hybrid position encodings or novel attention mechanisms
- **Mechanism validity**: Geometric reference frame interpretation requires more direct causal validation through perturbation studies

## Confidence

**High Confidence**: Attention sinks exist across diverse transformer architectures and training paradigms; different position encoding schemes correlate with distinct reference frame signatures; early training emergence of stable topological patterns precedes task performance convergence

**Medium Confidence**: Attention sinks function as geometric reference frames establishing coordinate systems; Softmax's probability simplex constraint mathematically necessitates reference frame formation; Position encoding type determines which reference frame configuration emerges

**Low Confidence**: Reference frames are optimal solutions to geometric constraints rather than training artifacts; the three identified frame types are exhaustive and mutually exclusive; Attention sink patterns transfer predictably across tasks and domains

## Next Checks

1. **Causal Perturbation Experiment**: Systematically remove or replace attention sink tokens across multiple architectures during both inference and fine-tuning. Measure not just performance degradation but also changes in representation geometry (cosine similarity distributions, angular variance, manifold dimensionality).

2. **Cross-Architectural Frame Transfer**: Train models with mixed position encoding schemes (e.g., RoPE in lower layers, absolute in upper layers) and measure resulting frame type evolution. Additionally, examine models with hybrid attention mechanisms to test whether simplex constraints are truly necessary for reference frame emergence.

3. **Alternative Topology Validation**: Repeat topological analysis using multiple distance metrics (cosine distance, Euclidean distance in representation space, KL divergence between attention distributions) and alternative homology computation methods. Compare results across different sentence lengths, domains, and token distributions.