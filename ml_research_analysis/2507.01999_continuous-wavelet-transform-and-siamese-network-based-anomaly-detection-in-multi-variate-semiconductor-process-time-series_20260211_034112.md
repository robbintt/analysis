---
ver: rpa2
title: Continuous Wavelet Transform and Siamese Network-Based Anomaly Detection in
  Multi-variate Semiconductor Process Time Series
arxiv_id: '2507.01999'
source_url: https://arxiv.org/abs/2507.01999
tags:
- time
- data
- process
- anomaly
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel deep-learning framework for anomaly
  detection in semiconductor manufacturing time-series data. The method uses Continuous
  Wavelet Transform (CWT) to convert multivariate time-series signals into time-frequency
  images, then applies a fine-tuned VGG-16 CNN classifier to detect anomalies.
---

# Continuous Wavelet Transform and Siamese Network-Based Anomaly Detection in Multi-variate Semiconductor Process Time Series

## Quick Facts
- **arXiv ID**: 2507.01999
- **Source URL**: https://arxiv.org/abs/2507.01999
- **Reference count**: 30
- **Primary result**: Novel CWT-Siamese network framework achieves 100% anomaly detection accuracy on semiconductor tool data.

## Executive Summary
This paper introduces a deep-learning approach for detecting anomalies in semiconductor manufacturing time-series data. The method transforms multivariate signals into time-frequency images using Continuous Wavelet Transform (CWT), then applies a fine-tuned VGG-16 CNN and Siamese network architecture to identify deviations from normal process behavior. Tested on real tool data, the approach achieves perfect accuracy in identifying both time and amplitude shift-induced anomalies through 20-way cross-validation. The framework supports both supervised and semi-supervised settings, offering flexibility for real-time process monitoring applications.

## Method Summary
The method converts multivariate time-series data into 2D time-frequency images using Continuous Wavelet Transform with a Mexican hat wavelet. Raw signals undergo min-max normalization, baseline estimation via asymmetric least squares, peak detection, and 10-second window extraction centered on peaks. These windows are transformed into CWT images and fed into a fine-tuned VGG-16 CNN (pre-trained on ImageNet, with last four layers frozen). A Siamese network architecture compares pairs of CWT images by computing similarity scores between their embeddings. The framework detects anomalies by measuring how much a query signal deviates from a known-good reference, without requiring explicit reconstruction error calculations.

## Key Results
- 100% accuracy achieved in anomaly identification via 20-way cross-validation
- Method successfully detects both time-shift and amplitude-shift anomalies
- Framework demonstrates effectiveness on real semiconductor tool data from Coat/Develop Track equipment

## Why This Works (Mechanism)

### Mechanism 1
Converting raw time-series into time-frequency images via Continuous Wavelet Transform preserves localized transient information that raw 1D signals or global FFTs might miss. The CWT uses a Mexican hat wavelet to decompose the signal into scale and time, mapping time-shifts to horizontal positional changes and amplitude shifts to color intensity variations in a 2D spectrogram. This creates fixed-size inputs from variable-length signals, allowing CNNs to treat process dynamics as texture recognition problems. The core assumption is that anomalies manifest as distinct spatial patterns in the time-frequency domain that differ visually from normal operating textures.

### Mechanism 2
A pre-trained VGG-16 CNN extracts robust features from CWT images by leveraging transfer learning, allowing effective classification even with limited semiconductor data. The VGG-16 architecture, pre-trained on ImageNet, acts as a feature extractor where early layers detect edges and textures analogous to frequency gradients, while fine-tuned deeper layers learn to distinguish between specific process states and anomaly classes. The core assumption is that visual features learned from natural images transfer meaningfully to the abstract "images" of spectrograms.

### Mechanism 3
A Siamese network architecture enables anomaly detection by measuring the similarity between a known-good reference (anchor) and a query signal, rather than relying on explicit reconstruction error. The network passes both anchor and query images through identical VGG-16 backbones and computes the dot product of resulting embedding vectors. A low similarity score indicates the query deviates from the known-good distribution, flagging an anomaly without requiring a model to reconstruct the exact signal. The core assumption is that normal process variations produce embeddings that cluster tightly while anomalies result in divergent embeddings in the latent space.

## Foundational Learning

- **Concept: Continuous Wavelet Transform (CWT) vs. Fourier Transform**
  - Why needed here: You must understand why the paper chooses CWT over FFT. CWT provides localized time-frequency info crucial for spotting when a glitch happens, whereas FFT only gives global frequency info.
  - Quick check question: If a signal has a sudden 2-second spike, would an FFT tell you exactly when it happened?

- **Concept: Siamese Networks & Metric Learning**
  - Why needed here: The core detection logic isn't classifying an anomaly directly, but measuring distance from normal. You need to understand how the network learns a similarity metric rather than a probability distribution.
  - Quick check question: In a Siamese network, do you need labelled "anomaly" data during training, or just pairs of "same/different" normal data?

- **Concept: Transfer Learning (Freezing Layers)**
  - Why needed here: The paper uses VGG-16 trained on ImageNet. Understanding which layers to freeze (keep generic feature extractors) and which to fine-tune (adapt to spectrograms) is critical for reproducing results.
  - Quick check question: Why would you freeze the early convolutional layers of a VGG-16 model when applying it to CWT images?

## Architecture Onboarding

- **Component map**: Raw Multivariate Time Series -> Min-Max Scaling -> Baseline Estimation (Asymmetric Least Squares) -> Peak Detection -> CWT (Mexican Hat) -> 2D Image -> VGG-16 (Pre-trained, Partially Frozen) -> Dense Layers + Softmax (Classification) -> Siamese Branch (Shared Weights) -> Dot Product Similarity

- **Critical path**: The Preprocessing -> CWT stage is the most fragile. If the baseline estimation removes the actual anomaly (e.g., a slow drift is treated as baseline), the model will fail.

- **Design tradeoffs**: Fixed Window vs. Temporal Context: The paper uses fixed windows (Section 5.4), losing long-range dependencies (LSTMs/Transformers would fix this but increase complexity). Supervised vs. Semi-Supervised: The Siamese setup supports semi-supervised learning (learning from normal data only), but the 100% accuracy claim relies on supervised validation with induced anomalies.

- **Failure signatures**: Overfitting: On small datasets (like Dataset-3), the model memorizes specific intensity profiles rather than learning general amplitude deviations. Concept Drift: If the tool hardware changes, the "known-good" anchor becomes invalid, requiring re-training.

- **First 3 experiments**: 
  1. Sanity Check: Run the CWT pipeline on a raw signal and visually verify that "Time Shifts" appear as horizontal translations in the image and "Amplitude Shifts" as color changes.
  2. Backbone Validation: Train the VGG-16 classifier (Task 1) only on the 3 non-anomalous classes (Dataset-1). Ensure it achieves >95% accuracy before introducing anomaly classes.
  3. Threshold Calibration: Using the Siamese network (Task 2), plot the distribution of similarity scores for "Normal vs. Normal" pairs vs. "Normal vs. Anomaly" pairs to determine a safe operating threshold.

## Open Questions the Paper Calls Out

- **Open Question 1**: What is the optimal time window or number of time-stamp points required to make sufficiently early anomaly predictions to prevent wafer loss? The current study utilizes fixed 10-second windows for feature extraction but does not investigate the theoretical or practical limits of prediction latency relative to fault emergence.

- **Open Question 2**: How effectively does the CWT-Siamese framework generalize to real-world anomalous instances compared to the synthetic time and amplitude shifts used in the study? The methodology relied on artificially induced anomalies because the available FAB data lacked labeled faults, potentially limiting the model's robustness against complex, natural failure modes.

- **Open Question 3**: Can automated optimization techniques replace the manual expert tuning required for wavelet selection, scale ranges, and similarity thresholds? The current framework relies on manual, expert-driven selection of the Mexican hat wavelet and threshold settings, which is non-trivial and may not be optimal across different tools or recipes.

## Limitations
- 100% accuracy claim on small datasets (Dataset-3: 12 samples) raises overfitting concerns and may not generalize to larger, noisier industrial data
- Method's reliance on fixed reference libraries and static Siamese thresholds makes it vulnerable to concept drift in real semiconductor processes
- Computational overhead from CWT and CNN inference may limit real-time deployment on resource-constrained equipment

## Confidence

- **High**: CWT's ability to localize transient features in time-frequency space; Siamese network's general principle for similarity-based anomaly detection
- **Medium**: VGG-16's effectiveness on CWT images (transfer from natural images to spectrograms is unproven); the specific 100% accuracy claim on small datasets
- **Low**: Scalability to larger datasets and variable process conditions; robustness to unlabeled anomalies or gradual process drifts

## Next Checks

1. **Generalization Test**: Evaluate on a held-out recipe/tool not used in training to assess domain transfer
2. **Concept Drift Simulation**: Gradually shift process parameters in test data to measure false positive rates under drift
3. **Scalability Benchmark**: Measure inference latency and memory usage on full-scale production data to validate real-time feasibility