---
ver: rpa2
title: Towards Continuous-Time Approximations for Stochastic Gradient Descent without
  Replacement
arxiv_id: '2512.04703'
source_url: https://arxiv.org/abs/2512.04703
tags:
- brownian
- then
- sgdo
- have
- stochastic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a continuous-time approximation to stochastic
  gradient descent without replacement (SGDo) using Young differential equations driven
  by epoched Brownian motions. The method models the SGDo dynamics as a stochastic
  differential equation with additive noise, where the driving process reflects the
  finite-data reuse pattern of SGDo.
---

# Towards Continuous-Time Approximations for Stochastic Gradient Descent without Replacement

## Quick Facts
- arXiv ID: 2512.04703
- Source URL: https://arxiv.org/abs/2512.04703
- Reference count: 5
- This paper introduces a continuous-time approximation to stochastic gradient descent without replacement (SGDo) using Young differential equations driven by epoched Brownian motions, proving almost sure convergence for learning rate schedules with exponent $\beta \in (0,1)$, including the previously unexplored range $\beta \in (0,1/2]$.

## Executive Summary
This paper presents a novel continuous-time approximation for stochastic gradient descent without replacement (SGDo) using Young differential equations driven by epoched Brownian motions. The method captures the finite-data reuse pattern of SGDo and extends convergence analysis to previously inaccessible learning rate schedules. The approach provides explicit bounds on convergence rates that match or improve upon existing results, particularly for the single shuffle and random reshuffling schemes. The use of Young integration instead of martingale techniques allows analysis of a broader class of learning rate schedules.

## Method Summary
The method models SGDo dynamics as a stochastic differential equation with additive noise, where the driving process is an "epoched Brownian motion" (EBM) that generalizes single shuffle and random reshuffling schemes. The EBM is constructed by concatenating Brownian bridges with a shared Gaussian terminal value, encoding different data permutation strategies. For strongly convex objectives with Hölder continuous Hessians, the authors prove almost sure convergence using Young-Loeve inequalities rather than martingale techniques, allowing coverage of learning rate schedules with exponent $\beta \in (0,1/2]$. The analysis provides explicit upper bounds on asymptotic convergence rates.

## Key Results
- Proves almost sure convergence of SGDo approximations under learning rate schedules $u_t = 1/(1+t)^\beta$ for $\beta \in (0,1)$, including previously unexplored range $\beta \in (0,1/2]$
- Provides explicit upper bounds on convergence rates showing matching or improved performance over existing SGDo results
- Covers both single shuffle case (matching previous work) and random reshuffling settings with better convergence bounds
- Demonstrates $T^{1/2-\beta}$ scaling factor where $T$ is epoch length, controlling noise-accumulation tradeoff

## Why This Works (Mechanism)

### Mechanism 1: Epoched Brownian Motion (EBM) Encoding of Shuffling Schemes
EBM provides a continuous-time driver capturing the finite-sample, epoch-based structure of SGDo with different shuffling schemes. An EBM $\hat{W}$ is constructed by concatenating Brownian bridges $B_j$ (one per epoch) with a shared Gaussian terminal value $V$. The covariance structure encodes shuffling: (a) Single shuffle: all bridges identical, $C_{ij} = s \wedge t$; (b) Random reshuffling: independent bridges, $C_{ij} = st$; (c) Flip-flop variants: alternating correlation patterns. This requires large sample sizes $N$ for scaling limit approximation.

### Mechanism 2: Young Integration Overcoming Martingale Limitations
Using Young-Love inequality instead of martingale techniques enables convergence analysis for $\beta \in (0, 1/2]$, previously inaccessible. The integral $\int_0^t u_s d\hat{W}_s$ is interpreted pathwise as a Young integral (limit of Riemann sums). The Young-Love inequality bounds the integral by $\|u\|_\beta \cdot \|\hat{W}\|_\alpha$ when $\alpha + \beta > 1$, avoiding square-summability requirement of martingale methods ($\sum \eta_n^2 < \infty$ requires $\beta > 1/2$).

### Mechanism 3: Learning Rate Exponent Governs Noise-Accumulation Tradeoff
The exponent $\beta$ controls balance between noise accumulation across epochs and learning rate decay, with $T^{1/2-\beta}$ as key scaling factor. Noise accumulated in epoch $j$ is $\int_{jT}^{(j+1)T} u_t \sigma d\hat{W}_t \approx (cjT)^{-\beta} T^{1/2-\beta} \sigma Z$ for $Z \sim N(0, I)$. For $\beta > 1/2$, noise vanishes as $T \to \infty$; for $\beta < 1/2$, noise diverges; at $\beta = 1/2$, effects balance.

## Foundational Learning

- **Young Integration / Rough Paths Theory**
  - Why needed here: Core mathematical tool replacing Itô calculus for non-semimartingale drivers (EBM). Without this, convergence proof for $\beta \leq 1/2$ would not hold.
  - Quick check question: Can you explain why a Young integral requires $\alpha + \beta > 1$ for Hölder exponents of integrand and integrator?

- **Regular Variation and Karamata Theory**
  - Why needed here: Used extensively to derive asymptotic bounds on integrals of regularly varying functions (e.g., $\int_0^t u_s^\rho e^{-\lambda U_s^t} ds$). Essential for the $o(t^{-\beta})$ error terms.
  - Quick check question: What does it mean for a function to be regularly varying of index $-\beta$, and how does this relate to the learning rate $u_t = (1+ct)^{-\beta}$?

- **Brownian Bridge Construction**
  - Why needed here: EBMs are built from concatenated Brownian bridges. Understanding that a bridge $B_t$ has covariance $\text{Cov}(B_s, B_t) = s \wedge t - st$ (conditioned to return to zero) is critical for shuffling scheme correspondence.
  - Quick check question: How does the covariance of a Brownian bridge differ from that of standard Brownian motion, and what role does the $-st$ term play?

## Architecture Onboarding

- **Component map**: Input (sample data, permutation sequence, learning rate schedule, objective) -> EBM Construction -> Young Integral Computation -> Asymptotic Bound Verification -> Output (convergence bound)
- **Critical path**: 
  1. EBM Construction: Generate Brownian bridges $B_j$ per shuffling scheme and terminal Gaussian $V$
  2. Young Integral Computation: Numerically integrate $Y_t = Y_0 + \int_0^t u_s \nabla R(Y_s) ds + \int_0^t u_s \sqrt{h} \sigma d\hat{W}_s$ using partition-based Young sums
  3. Asymptotic Bound Verification: Track $\|Y_t - Y_\infty\|$ vs. theoretical $C t^{-\beta}$ decay; confirm $T^{1/2-\beta$ scaling with sample size
- **Design tradeoffs**:
  - Additive vs. multiplicative noise: Additive noise (Eq. 3) for simplicity; multiplicative may better capture gradient covariance but complicates analysis
  - General EBM vs. shuffling-specific: General EBM framework is flexible but abstract; concrete shuffling schemes are more actionable but restrictive
  - $\beta$ near 1/2 vs. near 1: Smaller $\beta$ yields slower decay but better constants; larger $\beta$ gives faster asymptotic rate but diverging constants
- **Failure signatures**:
  - $\beta \to 1$ divergence: Constants in $o(t^{-\beta})$ blow up; numerical simulations show poor convergence for fast-decaying schedules
  - Small $N$ regime: EBM approximation degrades; discrete SGDo dynamics not captured
  - Non-convex objectives: Strong convexity is assumed throughout; non-convex $R$ would break linearization argument
  - Non-Hölder Hessian: If $\nabla^2 R$ lacks Hölder continuity, remainder term fails, breaking perturbation analysis
- **First 3 experiments**:
  1. Linear Regression Validation: Replicate linear regression example; generate synthetic data with known $\theta^*$; run Young DE solver with RR-EBM; verify $Y_\infty$ matches OLS estimator in mean and covariance
  2. $\beta$-Sweep Sensitivity: For fixed $N = 1000$, vary $\beta \in \{0.3, 0.5, 0.7, 0.9\}$; measure actual convergence rate $\|Y_t - Y_\infty\|$ vs. theoretical $t^{-\beta}$; confirm $T^{1/2-\beta}$ scaling by repeating for $N \in \{100, 1000, 10000\}$
  3. Shuffling Scheme Comparison: Implement SS, RR, and flip-flop EBMs; compare convergence rates and Hölder path norms $\|\hat{W}\|_\alpha$; test if SS achieves better constants than RR

## Open Questions the Paper Calls Out
None

## Limitations
- Analysis built on specific model