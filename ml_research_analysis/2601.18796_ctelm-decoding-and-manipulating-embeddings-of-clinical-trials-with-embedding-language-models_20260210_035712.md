---
ver: rpa2
title: 'ctELM: Decoding and Manipulating Embeddings of Clinical Trials with Embedding
  Language Models'
arxiv_id: '2601.18796'
source_url: https://arxiv.org/abs/2601.18796
tags:
- embedding
- abstract
- embeddings
- training
- clinical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Embedding Language Models (ELMs) align large language models to
  embedding spaces, enabling text generation from arbitrary embeddings. This work
  develops an open-source ELM architecture and training framework, training ctELM
  to interpret clinical trial embeddings.
---

# ctELM: Decoding and Manipulating Embeddings of Clinical Trials with Embedding Language Models

## Quick Facts
- **arXiv ID**: 2601.18796
- **Source URL**: https://arxiv.org/abs/2601.18796
- **Reference count**: 40
- **Primary result**: Embedding Language Model ctELM achieves up to 0.87 Semantic Consistency for reconstructing clinical trial abstracts and 0.89 for comparing trials, outperforming Vec2Text baselines.

## Executive Summary
ctELM is an open-source Embedding Language Model that enables decoding and manipulating embeddings of clinical trials. The model uses a learned adapter to project external text embeddings into a frozen LLM's token embedding space, enabling text generation from arbitrary embeddings. Trained on 1.2M clinical trial samples across five tasks, ctELM achieves strong semantic consistency (up to 0.87) for reconstructing abstracts and comparing trials. The model also demonstrates controlled generation along clinically meaningful directions using Concept Activation Vectors, and can generate novel (interpolated) trial abstracts that fool human experts 44% of the time.

## Method Summary
The ctELM architecture uses a two-layer MLP adapter to project 1024-dimensional embeddings from BAAI/bge-large-en-v1.5 into the 4096-dimensional token embedding space of Llama-3.1-8B-Instruct. The LLM's token embeddings are frozen while LoRA (r=16, alpha=32, dropout=0.05) is applied to q_proj and k_proj attention parameters. Training uses five tasks: emb2abs (abstract reconstruction), emb2sec (section generation), emb2pls (plain language summaries), emb2com (comparison), and emb2dif (difference). The model is trained on 1.2M instances from PubMed 200K RCT dataset with synthetic labels generated by gpt-4o-mini for non-reconstruction tasks.

## Key Results
- Semantic Consistency of 0.87 for full abstract reconstruction and 0.89 for trial comparison
- Outperforms Vec2Text baselines by 0.03-0.05 points in SC
- Generated trial abstracts from interpolated embeddings fool human experts 44% of the time
- Model outputs responsive to Concept Activation Vectors for sex (100% male to 100% female with α∈[-1,1]) and age manipulation

## Why This Works (Mechanism)

### Mechanism 1: Adapter-Mediated Embedding Alignment
A learned adapter module enables frozen LLMs to process arbitrary text embeddings as semantic tokens. The adapter A is a two-layer MLP that projects embeddings from the external embedding space (Z_emb, 1024-dim) into the base LLM's token embedding space (Z_base, 4096-dim for Llama-3.1-8B). This allows standard transformer layers to attend over both text tokens and dense vectors in a unified sequence.

### Mechanism 2: Multi-Task Semantic Regularization
Training on diverse tasks (reconstruction, comparison, summarization) forces the model to learn a manifold of clinically plausible trials rather than memorizing specific embeddings. Five tasks require extracting different semantic aspects from the same embeddings, preventing overfitting to surface patterns and encouraging learning the underlying clinical trial parameter space.

### Mechanism 3: Concept Activation Vector Manipulation
Linear directions in the embedding space correspond to clinically meaningful attributes (sex, age), enabling controlled generation by vector arithmetic. Linear SVM classifiers identify hyperplanes separating embeddings by attributes. The orthogonal direction (CAV) represents the concept axis. Adding α·CAV to an embedding shifts its semantic content before decoding.

## Foundational Learning

- **Text Embedding Spaces (Contrastive Learning)**: Understanding how embeddings encode semantics is prerequisite for debugging alignment failures. Quick check: Given two clinical trial abstracts with cosine similarity 0.92, what semantic relationship would you expect?
- **Adapter/Fine-tuning Architectures (LoRA, MLP Projection)**: The adapter A is the only randomly initialized component; LoRA modifies attention weights. Understanding parameter-efficient fine-tuning is essential for reproducing results. Quick check: Why does the paper freeze the token embedding layer E_base while training A and LoRA parameters?
- **Embedding Inversion Attacks (Vec2Text Baseline)**: Understanding Vec2Text's failure modes (repetition, hallucination) clarifies why ELMs offer superior generation quality. Quick check: Vec2Text-sect-ft concatenates section-level reconstructions. Why does this approach yield higher SC (0.82) than full-abstract Vec2Text-ft (0.77)?

## Architecture Onboarding

- **Component map**: Clinical trial abstract → BAAI/bge-large-en-v1.5 (frozen) → Z_emb (1024-dim) → Adapter (2-layer MLP) → Z_base-aligned embedding → Llama-3.1-8B-Instruct (frozen embeddings, LoRA) → Task-specific text
- **Critical path**: 1) Prepare data: Concatenate PubMedRCT sections → unstructured abstracts → compute embeddings 2) Generate synthetic labels: Use gpt-4o-mini for emb2pls, emb2com, emb2dif 3) Initialize adapter with Xavier/He; apply LoRA config 4) Train: 1P-1E (13 hours on H100) or 2P-1E (26 hours) 5) Validate: Compute SC on test set; target ≥0.85 for emb2abs with penalty=1.2
- **Design tradeoffs**: One-phase vs. two-phase: 2P-1E yields slightly better SC on small data; 1P-1E is 2× faster. Task diversity: 5-task training matches 1-task on emb2abs while enabling new capabilities. Embedding model: Domain-specific pubmedbert-base-embeddings underperforms (0.81 SC) vs. general bge-large-en-v1.5 (0.86 SC).
- **Failure signatures**: Repetition: emb2abs generates "a single dose of a single dose of..." → apply penalty=1.2. Imprecision: "Tropisetron" → "Granisetron" → increase training data or add explicit drug entity constraints. Hallucination (Vec2Text): "resected apnea," "pharmacokinetics of nisoplaban" → ELMs reduce but don't eliminate this.
- **First 3 experiments**: 1) Reproduce baseline: Train ctELM 1-task (emb2abs only) on 190K data; compare SC to paper's 0.83±0.05 2) Ablate adapter: Replace two-layer MLP with single linear projection; expect SC drop of 0.03–0.05 3) Probe interpolation: Generate 50 abstracts from interpolated embeddings; measure SC on held-out pairs (target: 0.82±0.03)

## Open Questions the Paper Calls Out

- **Question**: Can the ctELM architecture generalize to other biomedical text formats, such as full articles or clinical notes, without retraining on specific manifolds?
  - Basis: Authors state in Limitations that it is unclear how well the model generalizes to data outside of clinical trial abstracts.
  - Why unresolved: Model was trained exclusively on structured abstracts, and ELMs inherently train to specific data manifolds.
  - What evidence would resolve it: Training and testing on diverse datasets like MIMIC-III clinical notes or full biomedical journal articles.

- **Question**: Can the iterative correction method of Vec2Text outperform ctELM when scaled to a larger base model and trained on domain-specific data?
  - Basis: Authors note that Vec2Text was disadvantaged by using a smaller model (T5) compared to ctELM (Llama 3.1).
  - Why unresolved: Performance gap may be due to model size rather than architectural superiority.
  - What evidence would resolve it: Fine-tuning a Vec2Text model using a decoder equivalent in size to Llama 3.1 on the same clinical trial corpus.

- **Question**: How can the clinical feasibility and ethical safety of generated trials be validated, particularly regarding protected populations?
  - Basis: Authors acknowledge generated abstracts, while plausible, are far from real-world studies and may introduce ethical hazards.
  - Why unresolved: Current validation is limited to "fooling" human experts rather than verifying safety or medical applicability.
  - What evidence would resolve it: A validation framework involving clinical experts and bioethicists to review safety and feasibility of generated combinations.

## Limitations
- Adapter architecture assumes linear separability between embedding spaces without systematic ablation testing
- Synthetic labels from gpt-4o-mini oracle quality directly impacts downstream performance but lacks inter-annotator agreement reporting
- Human expert fooling rate (44%) doesn't capture potential safety issues or clinical inaccuracies affecting patient care

## Confidence
- **High confidence**: Core ELM architecture (adapter + LoRA) functions as described, evidenced by consistent SC improvements over Vec2Text baselines
- **Medium confidence**: Superiority of multi-task training demonstrated on PubMedRCT dataset, but benefits may not transfer to other domains
- **Low confidence**: Extrapolation capabilities for interpolated embeddings are promising but distribution and failure modes are uncharacterized

## Next Checks
1. **Adapter architecture ablation**: Systematically compare 2-layer MLP against single linear layer, 3-layer MLP, and attention-based adapters to quantify non-linearity contribution
2. **Domain embedding validation**: Train ctELM with pubmedbert-base-embeddings (768-dim) and compare SC performance to bge-large-en-v1.5 (1024-dim)
3. **Safety and clinical accuracy audit**: Have clinical experts review 100 generated abstracts for factual errors, safety concerns, and clinical plausibility beyond binary discrimination task