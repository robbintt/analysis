---
ver: rpa2
title: Highly Efficient Test-Time Scaling for T2I Diffusion Models with Text Embedding
  Perturbation
arxiv_id: '2512.03996'
source_url: https://arxiv.org/abs/2512.03996
tags:
- text
- perturbation
- embedding
- noise
- randomness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the limitations of existing test-time scaling
  (TTS) methods for text-to-image diffusion models, which rely solely on spatial noise
  randomness and fail to explore the full potential of generative diversity. The authors
  propose text embedding perturbation as a novel randomness format that complements
  spatial noise by targeting different frequency domains - spatial noise favors low
  frequencies while text embedding perturbation enhances high-frequency details.
---

# Highly Efficient Test-Time Scaling for T2I Diffusion Models with Text Embedding Perturbation

## Quick Facts
- arXiv ID: 2512.03996
- Source URL: https://arxiv.org/abs/2512.03996
- Authors: Hang Xu; Linjiang Huang; Feng Zhao
- Reference count: 32
- Primary result: Introduces text embedding perturbation as a novel randomness source that complements spatial noise in TTS, achieving significant improvements across multiple diffusion models and reward metrics

## Executive Summary
This paper addresses the limitations of existing test-time scaling (TTS) methods for text-to-image diffusion models, which rely solely on spatial noise randomness and fail to explore the full potential of generative diversity. The authors propose text embedding perturbation as a novel randomness format that complements spatial noise by targeting different frequency domains - spatial noise favors low frequencies while text embedding perturbation enhances high-frequency details. They develop a framework that applies discriminative perturbation across three dimensions: step-based intensity scheduling, conditional vs unconditional text embedding, and layer depth, with stronger perturbations applied to unconditional embeddings and shallower layers. The method seamlessly integrates with existing TTS approaches (BoN, ZeroOrder, CoDe, SVDD, DAS, SoP) and achieves significant improvements across multiple diffusion models (SDXL, SD3.5) and reward metrics (ImageReward, HPSv2, CLIPScore, AestheticScore) with negligible additional computation.

## Method Summary
The authors introduce text embedding perturbation (TEP) as a complementary randomness source to spatial noise in TTS. TEP applies Gaussian noise to text embeddings with three discriminative dimensions: (1) stronger perturbation to unconditional vs conditional embeddings (w1 >> w2), (2) layer-wise scaling with s_i = 1.5 for shallow layers and 0.5 for deep layers, and (3) step-based intensity with monotonically increasing w(t). High-frequency components from SDE noise are filtered via FFT low-pass filtering with threshold p(t). The method integrates with existing TTS approaches like BoN, ZeroOrder, CoDe, SVDD, DAS, and SoP. Experiments use Open-Image-Pref-v1 dataset (7k+ prompts) and evaluate on ImageReward, HPSv2, CLIPScore, and AestheticScore across SD2.1, SDXL, SD3.5, Flux, and Show-o2 models.

## Key Results
- Text embedding perturbation significantly improves reward scores across all tested TTS methods and diffusion models
- Combining spatial noise and text embedding perturbation yields multiplicative improvements due to frequency-domain complementarity
- Unconditional text embeddings tolerate substantially stronger perturbation than conditional embeddings without quality degradation
- Shallow cross-attention layers benefit from stronger perturbation while deeper layers require minimal perturbation to preserve semantic coherence
- The method achieves these improvements with negligible additional computational overhead

## Why This Works (Mechanism)

### Mechanism 1: Frequency-Domain Complementarity
Spatial noise and text embedding perturbation affect different frequency bands and denoising phases, making them complementary rather than redundant. SDE-injected spatial noise primarily modulates low-frequency structural components during early denoising steps, while text embedding perturbation preferentially influences high-frequency detail refinement during later steps. When combined, they expand the effective search space across the full frequency spectrum.

### Mechanism 2: Differential Perturbation Tolerance Across Embedding Roles
Unconditional text embeddings tolerate substantially stronger perturbation than conditional embeddings without quality degradation. Conditional embeddings encode the target generation region (narrow semantic specification), so perturbation corrupts meaning quickly. Unconditional embeddings define the avoidance region (broad negative space), allowing larger exploration without losing semantic anchor.

### Mechanism 3: Layer-Depth Perturbation Gating
Shallower cross-attention layers tolerate and benefit from stronger perturbation; deeper layers require minimal perturbation to preserve semantic coherence. Shallow layers process coarse spatial-textual alignments and have higher redundancy. Deep layers integrate refined semantic features for final reconstruction—corruption here propagates directly to output degradation.

## Foundational Learning

- **Concept: Classifier-Free Guidance (CFG)**
  - Why needed here: The entire perturbation strategy is built on the conditional/unconditional embedding distinction that CFG introduces. You cannot understand why unconditional embeddings get stronger perturbation without understanding what CFG does.
  - Quick check question: Can you explain why CFG blends conditional and unconditional predictions, and what happens to diversity as CFG scale increases?

- **Concept: SDE vs ODE Sampling in Diffusion**
  - Why needed here: The paper's baseline comparison switches between SDE (stochastic, injects noise each step) and ODE (deterministic) to isolate noise effects. Understanding this distinction is essential for interpreting the frequency-domain experiments.
  - Quick check question: What is the difference between SDE and ODE sampling paths, and why would SDE provide more diverse outputs?

- **Concept: Frequency-Domain Image Analysis (FFT basics)**
  - Why needed here: The core insight relies on low-frequency vs high-frequency image components mapping to structure vs detail. The method also uses FFT to filter high-frequency noise from SDE injection.
  - Quick check question: If you apply a low-pass filter to an image, what visual features are preserved and what is removed?

## Architecture Onboarding

- **Component map:** Text embedding → perturbation scaling (check layer, step, condition type) → cross-attention || SDE noise → FFT → low-pass filter → renormalize → both combine at denoising step

- **Critical path:** Text embedding → perturbation scaling (check layer, step, condition type) → cross-attention || SDE noise → FFT → low-pass filter → renormalize → both combine at denoising step

- **Design tradeoffs:**
  - Higher perturbation on unconditional embeddings trades search diversity vs stability—too high causes semantic drift
  - Aggressive high-frequency filtering on SDE noise trades spatial diversity vs quality—too aggressive removes useful exploration
  - Layer threshold k: Lower k (more layers considered "deep") = more conservative perturbation, less diversity gain

- **Failure signatures:**
  - Text-image misalignment increasing → unconditional perturbation too strong or applied to conditional by mistake
  - Loss of compositional diversity → spatial noise over-filtered or perturbation scheduling too conservative
  - Blurry outputs → high-frequency filtering threshold p(t) too aggressive in early steps
  - No improvement over baseline → perturbation magnitudes may be too small, or your reward model is already saturated

- **First 3 experiments:**
  1. **Sanity check:** Implement text embedding perturbation on unconditional embeddings only with fixed small magnitude (w1=0.1, w2=0). Run BoN with ImageReward on 100 prompts. Expect modest improvement if mechanism is working.
  2. **Ablation by dimension:** Test perturbation on (a) shallow layers only, (b) deep layers only, (c) all layers with uniform strength. Compare reward distributions to validate layer-depth hypothesis on your model.
  3. **Frequency verification:** Generate images with (a) SDE noise only, (b) text perturbation only, (c) both. Compute FFT of differences between perturbed and unperturbed outputs. Confirm spatial noise affects low-frequency bands more in early steps, text perturbation affects high-frequency more in later steps.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the heuristic thresholds for layer depth ($k$) and frequency filtering ($p$) be replaced with adaptive or learnable parameters to optimize the trade-off between diversity and quality?
- Basis in paper: The authors state they "simply set a threshold k" for layer splitting and use a fixed threshold for frequency filtering "for stability," suggesting the current values are manual approximations rather than global optima.
- Why unresolved: The paper manually tunes these static values but does not explore gradient-based or feedback-driven adaptation of these boundaries during inference.
- What evidence would resolve it: Comparative experiments showing that dynamic, per-prompt adjustment of $k$ and $p$ yields higher reward scores or better visual fidelity than the fixed baseline.

### Open Question 2
- Question: Can the token-wise perturbation strategy be refined to weight individual tokens based on their specific semantic contribution rather than just their position (semantic vs. padding)?
- Basis in paper: While the introduction mentions "token-wise adaptive perturbation, accounting for the differential importance of semantic components," the implementation only distinguishes between semantic and padding tokens without differentiating among semantic tokens themselves.
- Why unresolved: The current method applies a uniform relative coefficient to the entire semantic segment, potentially under-perturbing less critical details or over-perturbing core subjects.
- What evidence would resolve it: An ablation study where perturbation magnitude is modulated by attention-map weights for each token, demonstrating improved text-image alignment for complex prompts.

### Open Question 3
- Question: Is the high-frequency attenuation of spatial noise strictly necessary for all reward models, or does it depend on the specific aesthetic preferences captured by the verifier?
- Basis in paper: The paper concludes that spatial noise's high-frequency components negatively impact quality in later steps, but this assessment relies heavily on specific reward metrics like ImageReward which may have specific biases.
- Why unresolved: The causal link between high-frequency spatial noise and "quality degradation" might be an artifact of the specific reward functions used, rather than a fundamental flaw of the noise itself.
- What evidence would resolve it: Experiments across a wider variety of human-aligned or generic reward models showing whether the optimal frequency attenuation schedule shifts significantly.

## Limitations
- The frequency-domain complementarity mechanism may be architecture-specific rather than universal across diffusion models
- The differential perturbation tolerance between conditional and unconditional embeddings assumes this asymmetry holds for text encoders beyond those tested
- The proposed method introduces new hyperparameters (perturbation magnitudes, layer scaling factors, frequency thresholds) that may require per-model tuning rather than being universally applicable

## Confidence
- **High confidence:** The empirical improvements over baselines are substantial and consistent across multiple models and reward metrics. The integration with existing TTS methods is straightforward and the computational overhead is negligible as claimed.
- **Medium confidence:** The frequency-domain complementarity mechanism has strong internal evidence but limited external validation. The layer-depth perturbation sensitivity is demonstrated on SDXL/SD3.5 but lacks broader architecture testing.
- **Low confidence:** The claim that w1 >> w2 for unconditional vs conditional perturbation tolerance is supported by ablation studies but may not generalize to models with different CFG formulations or text encoders.

## Next Checks
1. **Frequency-domain validation across architectures:** Implement FFT analysis of perturbed vs unperturbed outputs for SDXL, SD3.5, and at least one additional diffusion model (e.g., FLUX). Verify that spatial noise consistently affects low frequencies in early steps while text embedding perturbation affects high frequencies in later steps across all models.

2. **Hyperparameter sensitivity analysis:** Systematically vary the unconditional perturbation weight w1 (0.1 to 1.0) and layer threshold k (0 to 10) on SDXL. Identify ranges where improvements persist vs where quality degrades, establishing guidelines for model-specific tuning.

3. **Cross-encoder generalization test:** Apply the same TEP framework to a diffusion model using a different text encoder (e.g., T5 instead of CLIP). Compare whether the conditional/unconditional perturbation asymmetry remains consistent, or if different w1/w2 values are needed, validating the claim about encoder-specific behavior.