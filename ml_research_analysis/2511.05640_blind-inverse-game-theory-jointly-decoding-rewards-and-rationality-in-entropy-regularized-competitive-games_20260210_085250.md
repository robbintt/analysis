---
ver: rpa2
title: 'Blind Inverse Game Theory: Jointly Decoding Rewards and Rationality in Entropy-Regularized
  Competitive Games'
arxiv_id: '2511.05640'
source_url: https://arxiv.org/abs/2511.05640
tags:
- games
- error
- blind-igt
- matrix
- inverse
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work tackles the fundamental challenge in inverse game theory\
  \ of recovering agents' reward parameters and rationality levels from observed behavior\
  \ when the rationality (temperature \u03C4) is unknown. The authors introduce Blind-IGT,\
  \ a statistical framework that resolves the inherent scale ambiguity between rewards\
  \ and temperature by introducing a normalization constraint."
---

# Blind Inverse Game Theory: Jointly Decoding Rewards and Rationality in Entropy-Regularized Competitive Games

## Quick Facts
- **arXiv ID**: 2511.05640
- **Source URL**: https://arxiv.org/abs/2511.05640
- **Reference count**: 40
- **Primary result**: Introduces Blind-IGT framework that jointly recovers reward parameters and unknown rationality temperature with optimal O(N^{-1/2}) convergence in competitive games

## Executive Summary
This paper addresses the fundamental challenge in inverse game theory of recovering agents' reward parameters and rationality levels from observed behavior when the rationality temperature is unknown. The authors introduce Blind-IGT, a statistical framework that resolves the inherent scale ambiguity between rewards and temperature by introducing a normalization constraint. They propose a Normalized Least Squares (NLS) estimator and prove it achieves the optimal O(N^{-1/2}) convergence rate for joint recovery of rewards and temperature in entropy-regularized zero-sum games. The method is extended to Markov games, where empirical results demonstrate optimal convergence rates even when transition dynamics are unknown.

## Method Summary
The Blind-IGT framework jointly estimates reward parameters θ and temperature τ from observed QRE behavior. It works by first computing empirical frequency distributions from samples, then constructing feature matrices and log-ratio vectors that linearize the QRE constraints. The NLS algorithm solves for the direction θ/τ using standard least squares, then recovers the magnitude of θ and τ using a normalization constraint on the reward parameter norm. For Markov games, constraints are aggregated across states, and the method handles unknown transition dynamics by estimating them from data.

## Key Results
- Proves Blind-IGT achieves optimal O(N^{-1/2}) convergence rate for joint parameter recovery
- Demonstrates necessity of jointly estimating temperature through oracle comparisons
- Shows Blind-IGT maintains performance with estimated transition dynamics in Markov games
- Provides partial identification guarantees via confidence sets when strong identifiability conditions fail

## Why This Works (Mechanism)

### Mechanism 1: Scale Ambiguity Resolution via Norm Constraint
The framework resolves the multiplicative coupling between rewards (θ) and rationality temperature (τ) by imposing a normalization constraint on the reward parameter norm (||θ|| = C). This forces the solution to lie on the surface of a sphere, intersecting the linear subspace at a unique point. The system depends only on the ratio θ/τ, creating an equivalence class where (kθ, kτ) produces identical behavior for any k.

### Mechanism 2: Statistical Efficiency via Normalized Least Squares (NLS)
The NLS algorithm achieves optimal parametric convergence rate by first solving for the direction θ/τ using standard least squares on linearized QRE constraints, then disentangling the magnitude of θ and τ using the fixed norm C (τ̂ = C/||θ̂_{LS}||). This two-step process maintains statistical efficiency while handling the bilinear structure.

### Mechanism 3: Robustness to Unknown Dynamics in Markov Games
The framework extends to Markov Games via state-wise aggregation, maintaining convergence rates even when transition dynamics P are unknown and estimated. Constraints are aggregated across states into a global system, and error propagation from the Bellman equation is controlled via Lipschitz continuity of the Value function.

## Foundational Learning

- **Quantal Response Equilibrium (QRE)**: The generative model for bounded rationality that replaces deterministic best-responses with probabilistic softmax policies. Understanding QRE is necessary to grasp why the system Xθ = τy is linearized via log-ratios.
  - *Quick check*: Can you derive why the QRE implies a linear relationship between the log-ratio of action probabilities and the expected payoff difference?

- **Bilinear Inverse Problems**: The joint recovery of (θ, τ) is a bilinear problem (product of two unknowns). This class of problems is generally non-convex and ill-posed without constraints, explaining why standard IGT fails when τ is unknown.
  - *Quick check*: Why does the bilinear structure (Xθ = τy) prevent standard Least Squares from working directly?

- **Identifiability and Scale Ambiguity**: The core contribution is resolving identifiability. Without the normalization constraint, scaling the "stakes" of the game (θ) while simultaneously scaling the "irrationality" (τ) leaves observed behavior unchanged.
  - *Quick check*: If you double the rewards and double the temperature, does the QRE policy change?

## Architecture Onboarding

- **Component map**: Sample Collection → Empirical Frequency Estimation → Log-Ratio Calculation (y) → Least Squares Solve → Norm-Based Scaling
- **Critical path**: Sample Collection → Empirical Frequency Estimation → Log-Ratio Calculation (y) → Least Squares Solve → Norm-Based Scaling
- **Design tradeoffs**: Exact vs. Approximate Normalization requires domain knowledge for setting C; Assumed vs. Estimated Dynamics trades theoretical guarantees for practical implementation
- **Failure signatures**: Uniform Play (rank deficiency when behavior is perfectly uniform); Numerical Instability (log-ratio explosion when probabilities approach zero)
- **First 3 experiments**: 1) Matrix Game Validation (reproduce Figure 1 slope ≈ -0.5), 2) Temperature Misspecification Test (compare Blind-IGT vs. Standard IGT with wrong τ), 3) Markov Game Robustness (implement Algorithm 2 on grid-world, compare Known P vs. Estimated P̂)

## Open Questions the Paper Calls Out

- **Open Question 1**: Can Blind-IGT extend to non-linear function approximation settings like deep neural networks while preserving statistical guarantees? The theoretical analysis relies on linear parameterization, creating a gap for complex environments.

- **Open Question 2**: How does the framework perform with heterogeneous rationality levels (distinct temperatures τ₁ ≠ τ₂) rather than a single global parameter? The current model assumes a single temperature couples with reward parameters.

- **Open Question 3**: Can theoretical convergence guarantees for Markov Games be rigorously established when transition dynamics are unknown and estimated? Theorem 3 assumes known dynamics, creating a gap between theory and empirical performance.

- **Open Question 4**: Do identifiability conditions and NLS approach hold for general-sum games, or are they restricted to zero-sum competitive structure? The current framework explicitly restricts to zero-sum games.

## Limitations

- The theoretical framework assumes known transition dynamics P in Markov games, though empirical results show robustness when P is estimated, creating a gap between theory and practice.
- The "Soft-Min Gap" assumption prevents probabilities from approaching zero but lacks explicit bounds on how small ξ can be before estimation breaks down.
- The framework is restricted to zero-sum competitive games, with unclear extension to general-sum games due to different QRE properties.

## Confidence

- **High confidence**: Optimal O(N^{-1/2}) convergence rate for joint recovery in matrix games (Theorem 1 and 2) is well-supported by theory and empirical validation in Figure 1.
- **Medium confidence**: Extension to Markov games with unknown dynamics maintains convergence rates based on empirical evidence (Figure 4), but lacks complete theoretical guarantees.
- **Medium confidence**: Partial identification guarantees via confidence sets are theoretically sound but practical utility depends on problem-specific rank conditions.

## Next Checks

1. **Stress Test Rank Conditions**: Systematically vary feature dimensions d relative to action spaces (m,n) to empirically map the boundary where rank(X*) < d causes non-unique solutions.

2. **Temperature Sensitivity Analysis**: Quantify how varying τ* affects the soft-min gap violation probability across different game structures to provide practical guidance on safe τ ranges.

3. **Cross-Environment Generalization**: Test Blind-IGT on a suite of Markov games with varying state-space sizes and transition complexities to validate robustness claims beyond the grid-world example.