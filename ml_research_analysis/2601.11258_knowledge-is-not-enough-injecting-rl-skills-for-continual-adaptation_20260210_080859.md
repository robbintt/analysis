---
ver: rpa2
title: 'Knowledge is Not Enough: Injecting RL Skills for Continual Adaptation'
arxiv_id: '2601.11258'
source_url: https://arxiv.org/abs/2601.11258
tags:
- knowledge
- skill
- uni00000011
- uni00000013
- target
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem that Large Language Models (LLMs)
  struggle to effectively use newly incorporated knowledge for reasoning and decision-making,
  even after Supervised Fine-Tuning (SFT). While SFT efficiently memorizes factual
  content, it fails to instill robust reasoning skills, and Reinforcement Learning
  (RL), though essential for acquiring such skills, is computationally expensive for
  continual adaptation.
---

# Knowledge is Not Enough: Injecting RL Skills for Continual Adaptation

## Quick Facts
- arXiv ID: 2601.11258
- Source URL: https://arxiv.org/abs/2601.11258
- Reference count: 40
- Primary result: PaST achieves 56.9% accuracy on SQuAD, surpassing SEAL by 9.9 points

## Executive Summary
This paper addresses a critical limitation of Large Language Models (LLMs) where Supervised Fine-Tuning (SFT) efficiently memorizes factual content but fails to instill robust reasoning skills needed for effective decision-making. The authors introduce Parametric Skill Transfer (PaST), which leverages the empirical finding that parameter updates from SFT and Reinforcement Learning (RL) occupy nearly orthogonal subspaces. This allows skills learned via RL to be disentangled from specific knowledge and transferred across domains without requiring expensive RL training in each new domain.

PaST extracts a domain-agnostic "Skill Vector" by subtracting parameters of an SFT-only model from its RL-refined counterpart in a source domain, then linearly injects this vector into target models after lightweight SFT on new data. The method demonstrates significant improvements across multiple benchmarks: 56.9% accuracy on SQuAD knowledge-incorporation QA (9.9 points above SEAL), 8.0-point gains on LooGLE long-context QA, and +10.3 average zero-shot success rates across 20 tool-use categories in ToolBench, showcasing strong cross-domain transferability and scalability.

## Method Summary
PaST addresses the challenge of continual adaptation in LLMs by exploiting the empirical observation that SFT and RL parameter updates occupy nearly orthogonal subspaces in the parameter space. The method works by first training a model with SFT on source domain data, then refining it with RL to acquire reasoning skills. The Skill Vector is extracted by computing the difference between the RL-refined parameters and the SFT-only parameters, capturing the skill component while discarding domain-specific knowledge. This vector is then linearly injected into target models after they undergo lightweight SFT on new domain data, effectively transferring reasoning capabilities without the computational expense of RL in each target domain.

## Key Results
- SQuAD knowledge-incorporation QA: PaST achieves 56.9% accuracy, surpassing state-of-the-art SEAL by up to 9.9 points
- LooGLE long-context QA: PaST shows 8.0-point absolute accuracy gain over baselines
- ToolBench cross-domain tool-use: PaST improves zero-shot success rates by +10.3 points on average across 20 RL-unseen categories

## Why This Works (Mechanism)
PaST works because SFT and RL parameter updates occupy nearly orthogonal subspaces in the model's parameter space. SFT primarily updates parameters related to factual knowledge and surface-level patterns, while RL updates parameters associated with reasoning strategies, decision-making processes, and policy optimization. By computing the difference between these two sets of parameters (the Skill Vector), PaST effectively isolates the reasoning capabilities learned through RL while discarding the domain-specific knowledge embedded in the SFT parameters. This disentanglement allows the reasoning skills to be transferred to new domains where the same knowledge may not apply, but the underlying reasoning strategies remain valuable.

## Foundational Learning
- **Orthogonal Subspace Property**: The empirical finding that SFT and RL parameter updates occupy nearly orthogonal subspaces in the parameter space. Why needed: This property enables disentanglement of reasoning skills from domain-specific knowledge. Quick check: Verify orthogonality through cosine similarity between update directions in experimental settings.
- **Parameter Space Geometry**: Understanding how different training objectives (SFT vs RL) navigate and modify the high-dimensional parameter space. Why needed: Critical for extracting meaningful Skill Vectors that capture transferable capabilities. Quick check: Analyze parameter update distributions and clustering patterns.
- **Skill Disentanglement**: The concept that reasoning capabilities can be separated from factual knowledge in the parameter space. Why needed: Enables transfer of reasoning skills without carrying over domain-specific information. Quick check: Test Skill Vector effectiveness across semantically distant domains.

## Architecture Onboarding
- **Component Map**: SFT_pretraining -> RL_refinement -> Skill_Vector_extraction -> Target_model_SFT -> Skill_Vector_injection -> Adapted_model
- **Critical Path**: The extraction and injection of the Skill Vector represents the core innovation, where the difference between RL-refined and SFT-only parameters is computed and linearly added to target models.
- **Design Tradeoffs**: PaST trades computational efficiency in target domains against the requirement of performing RL in at least one source domain. This design choice significantly reduces overall computational cost compared to RL for each new domain while maintaining effectiveness.
- **Failure Signatures**: The method would fail if SFT and RL updates are not sufficiently orthogonal, if reasoning skills are too tightly coupled with domain-specific knowledge, or if the linear injection mechanism cannot properly integrate the Skill Vector into target models.
- **First Experiments**: 1) Verify orthogonality of SFT and RL parameter updates through cosine similarity analysis. 2) Test Skill Vector extraction and injection on a simple domain transfer task. 3) Evaluate performance degradation when injecting Skill Vectors from semantically distant domains.

## Open Questions the Paper Calls Out
None

## Limitations
- The orthogonal parameter subspace assumption is empirically observed but not theoretically proven, and may not hold universally across different model architectures or task types
- Effectiveness is primarily demonstrated on extractive QA and tool-use tasks, with uncertainty about generalizability to other reasoning-intensive domains like mathematical problem-solving
- Requires RL in at least one source domain, trading computational efficiency for avoiding RL in target domains rather than eliminating it entirely

## Confidence
- High confidence in: The empirical observation that SFT and RL parameter updates are nearly orthogonal, and the effectiveness of PaST on demonstrated benchmarks
- Medium confidence in: The claim that skills can be truly "disentangled" from domain-specific knowledge and transferred without loss of task-specific optimization
- Medium confidence in: The scalability claims for cross-domain tool-use transfer across 20 categories

## Next Checks
1. Develop mathematical proofs or rigorous bounds showing under what conditions SFT and RL parameter updates remain orthogonal, and test edge cases where this assumption might break down
2. Test PaST on mathematical reasoning, code generation, and creative writing tasks to validate generalizability beyond QA and tool-use domains
3. Evaluate PaST's effectiveness on models ranging from 1B to 70B+ parameters to understand how the orthogonal subspace property scales with model size