---
ver: rpa2
title: Spiking Neural Models for Decision-Making Tasks with Learning
arxiv_id: '2506.09087'
source_url: https://arxiv.org/abs/2506.09087
tags:
- have
- page
- object
- learning
- process
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper bridges the gap between cognitive decision-making models
  and biologically plausible spiking neural networks. It demonstrates that the widely-used
  Drift Diffusion Model (DDM) in cognitive science can be derived from and approximated
  by networks of spiking neurons with a local learning rule.
---

# Spiking Neural Models for Decision-Making Tasks with Learning

## Quick Facts
- arXiv ID: 2506.09087
- Source URL: https://arxiv.org/abs/2506.09087
- Reference count: 23
- Primary result: DDM can be derived from and approximated by spiking neural networks with local learning rules

## Executive Summary
This paper establishes a theoretical bridge between cognitive decision-making models and biologically plausible spiking neural networks. The authors demonstrate that the Drift Diffusion Model (DDM), widely used in cognitive science, can be approximated by networks of spiking neurons governed by Hawkes processes with local learning rules. Through rigorous mathematical proofs, they show that these networks can learn decision categories without backpropagation while maintaining decision-making behavior similar to DDM. The work provides theoretical guarantees for accurate decision-making and validates the model through an online categorization experiment, offering new insights into the relationship between neural activity and behavior.

## Method Summary
The method implements a Spiking Neural Network (SNN) where input neurons fire as Poisson processes encoding object features, and output neurons fire as Hawkes processes with intensities dependent on synaptic weights. Synaptic weights are updated via an Exponentially Weighted Average (EWA) expert aggregation algorithm based on locally computed gains. A decision is made when an output neuron's spike count reaches a threshold θ. The model couples this spiking network to a Drift Diffusion Model (DDM) with correlated noise through mathematical proofs showing that spike counts can approximate Brownian motion accumulation. The behavioral experiment uses Simulation-Based Inference (SBI) to estimate learning rate η and threshold θ from reaction time data.

## Key Results
- Proved coupling between Poisson counter models and DDM, establishing equivalent decision-making behavior
- Demonstrated that local expert aggregation learning enables spiking networks to learn categories without backpropagation
- Showed that Hawkes networks can approximate DDM with correlated noise after learning
- Validated the model through an online categorization experiment with synthetic data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DDM and Poisson counter model produce equivalent decision-making behavior under specific coupling conditions
- Mechanism: Evidence accumulation in DDM (Brownian motion with drift) approximates Poisson spike counts when threshold scales linearly with network size (nθ). Theorem 2.6 proves sup|Π^j_{m,t} - W^j_{m,t}| grows only as O(log(n)) while expected values grow linearly with n.
- Core assumption: All category-coding neurons have strictly positive intensities (γ^j_o > 0 for every j∈J), and threshold scales as nθ for n independent copies
- Evidence anchors: [abstract] "coupling result between the DDM and the Poisson counter model"; [section 2.4] Theorem 2.6 provides explicit bounds; [corpus] Weak external support from related VAE work
- Break condition: If intensity γ^j_o = 0 for some category, coupling fails; if threshold doesn't scale with n, O(log(n)) bound doesn't hold

### Mechanism 2
- Claim: Local expert aggregation learning rule enables spiking networks to learn decision categories without backpropagation
- Mechanism: Each output neuron updates synaptic weights using EWA based on locally computed gains g^i→j_m. Gains are positive when presented object belongs to category j (proportional to presynaptic firing rates) and negative otherwise. Weights converge to limit family w^∞ where output neurons connect only to maximally discriminative input neurons.
- Core assumption: Feature discrepancy d^i→j must have non-zero gap δ_j between most and second-most discriminative features for each category
- Evidence anchors: [abstract] "synaptic weights are updated via an expert aggregation algorithm"; [section 3.2] EWA update rule described; [corpus] CHANI paper proves local learning in discrete-time version
- Break condition: If δ_j → 0, convergence rate becomes arbitrarily slow; if learning rate η too large relative to noise, weight updates become unstable

### Mechanism 3
- Claim: DDM with correlated noise emerges from Hawkes networks of spiking neurons after learning
- Mechanism: After learning phase, Hawkes counter model's spike counts N^j_{m,t} can be coupled to multivariate Brownian motion W^j_{m,t} with drift μ^j_m = nλ̄^j_m and correlated covariance structure. Correlation arises from shared input neurons influencing multiple output neurons.
- Core assumption: Interaction kernel g must have compact support shrinking as n^(-1/2), and all output neurons must have strictly positive asymptotic firing rates (λ̄^j_m > 0)
- Evidence anchors: [abstract] "DDM with correlated noise can be derived from a Hawkes network"; [section 3.4] Theorem 3.6 shows coupling with O(n^(1/4)log(n)^(3/4)) bound; [corpus] No direct external validation found
- Break condition: If g's support doesn't shrink appropriately, mean function doesn't approximate ∥g∥_1t, and Brownian approximation fails; if λ̄^j_m = 0, process stays at zero and coupling undefined

## Foundational Learning

- **Poisson and Hawkes Processes**
  - Why needed here: Entire framework models neural activity as point processes—Poisson for independent input neurons, Hawkes for interacting output neurons. Understanding conditional intensity λ_t = E[dN_t | F_t] is essential
  - Quick check question: Can you explain why a Hawkes process λ_t = ∫ φ(t-s)dN_s is "self-exciting" and how it differs from a Poisson process with the same rate?

- **Drift Diffusion Model (DDM)**
  - Why needed here: Paper aims to derive DDM from spiking networks. Understanding that DDM models evidence accumulation as dW_t = μdt + σdB_t with boundary crossing determining decisions is prerequisite
  - Quick check question: In a two-alternative DDM, what happens to reaction time distribution when drift rate μ increases while threshold θ stays constant?

- **Online Learning / Expert Aggregation**
  - Why needed here: Learning rule comes from online learning theory, specifically Hedge/Exponentiated Weighted Average algorithm. Understanding regret bounds and weight concentration helps interpret convergence results
  - Quick check question: In EWA with learning rate η, how do weights concentrate on expert with highest cumulative gain after M rounds?

## Architecture Onboarding

- **Component map:** Input layer I (Poisson processes Π^i_m) -> Output layer J (Hawkes processes N^j_m) -> Decision mechanism (threshold θ) -> Learning module (EWA updates)

- **Critical path:**
  1. Initialize weights uniformly on simplex (w^i→j_0 = 1/|I|)
  2. For each object m: present for duration T_min, observe input spikes, accumulate output spikes
  3. When first N^j_m reaches θ (or T expires), record decision and reaction time
  4. Compute gains: positive for true category (proportional to observed firing rates), negative for others
  5. Update weights via softmax of cumulative gains with learning rate η = η_0/√M

- **Design tradeoffs:**
  - Threshold θ: Higher values increase accuracy but lengthen reaction times; must satisfy both lower bound (for correct discrimination) and upper bound (for decision within T)
  - Learning rate η: Controls speed of convergence vs. stability; too high causes oscillation, too low slows learning
  - Minimum presentation time T_min: Longer improves gain estimation but reduces data efficiency; must satisfy T_min ≥ O(log(|I||J|)/(γ_min·Δ_λ^2))
  - Kernel g: Compact support reduces computational cost but must shrink as n^(-1/2) for diffusion approximation

- **Failure signatures:**
  - Weights don't converge: Feature discrepancy δ_j too small or learning rate η too large
  - Wrong category consistently selected: Margin Δ_λ violated, or threshold θ set outside valid range
  - Reaction times too long or infinite: Threshold θ too high relative to learned firing rates
  - High variance in decisions: T_min too short for accurate gain estimation

- **First 3 experiments:**
  1. Replicate paper's rocket categorization task with synthetic data: 16 objects, 8 input features, 2 categories, verify Proposition 4.1's prediction that weights converge to single discriminative feature per category. Plot convergence of ‖w^j_M - w^j_∞‖ vs. M for varying δ_j.
  2. Ablate learning mechanism: Use fixed random weights vs. learned weights and compare accuracy/reaction time distributions against DDM predictions. This isolates whether coupling result depends on learned structure.
  3. Stress test coupling bounds: Vary n (network size) and measure actual sup|N^j_{m,t} - W^j_{m,t}| to verify O(n^(1/4)log(n)^(3/4)) scaling predicted by Theorem 3.6.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the Hawkes counter model be extended with hidden layers to handle more complex categorization tasks while maintaining its coupling with the Drift Diffusion Model (DDM)?
- **Basis in paper:** [explicit] Authors state in Conclusion that introducing hidden layers could model more complex concepts, noting that previous work (Jaffard et al., 2024) demonstrated this capability in discrete time networks without reaction times
- **Why unresolved:** Current paper focuses on single-layer network with dynamic durations, hasn't integrated hidden layer architecture required to solve non-linearly separable problems
- **What evidence would resolve it:** Theoretical proof or simulation showing multi-layer Hawkes network can learn complex concepts and still approximate DDM-like accumulation process

### Open Question 2
- **Question:** Can the Drift Diffusion Model (DDM) be approximated by alternative types of spiking neural networks (SNNs) beyond the specific Hawkes process architecture used here?
- **Basis in paper:** [explicit] Conclusion identifies as "ambitious direction for future research" extension of work to "other spiking neural networks... commonly used in neuroscience"
- **Why unresolved:** Theoretical guarantees rely specifically on properties of Hawkes processes and expert aggregation rules
- **What evidence would resolve it:** Deriving similar coupling theorems for other network types, such as leaky integrate-and-fire models with different synaptic plasticity rules

### Open Question 3
- **Question:** How can the model be modified to better capture the variability in reaction times and error rates observed in human behavior?
- **Basis in paper:** [inferred] Section 4.6 and Conclusion note model "tends to produce more regular reaction times and make fewer errors compared to humans" due to deterministic weight updates
- **Why unresolved:** Model currently lacks mechanisms for "distraction" or stochasticity in decision process once weights are learned, leading to performance that is "too good" compared to biological subjects
- **What evidence would resolve it:** Introducing noise into weight update rule or threshold mechanism and demonstrating resulting reaction time distributions statistically match human data

## Limitations
- Coupling theorems rely on asymptotic conditions that may not hold in practical implementations, particularly requirement that feature discrepancy δ_j remains bounded away from zero
- Behavioral experiment validation involves parameter estimation via SBI which introduces additional uncertainty about exact parameter values
- Model lacks mechanisms for capturing human behavioral variability, producing "too good" performance compared to biological subjects

## Confidence
- **High confidence**: Mathematical proofs of coupling between Poisson counter models and DDM, and between Hawkes models and DDM are rigorous under stated assumptions
- **Medium confidence**: Local learning rule's convergence properties follow from established online learning theory, but continuous-time implementation with reaction time constraints adds complexity
- **Low confidence**: Behavioral experiment's parameter estimates depend heavily on SBI methodology, and synthetic categorization task may not fully capture naturalistic decision-making complexity

## Next Checks
1. Verify O(n^(1/4)log(n)^(3/4)) scaling empirically by measuring sup|N^j_{m,t} - W^j_{m,t}| across different network sizes n
2. Test robustness of learning to varying feature discrepancy δ_j by systematically reducing discriminability and measuring convergence rates
3. Validate behavioral experiment results using alternative parameter estimation methods (e.g., ABC-SMC) to confirm SBI-derived learning rate and threshold values