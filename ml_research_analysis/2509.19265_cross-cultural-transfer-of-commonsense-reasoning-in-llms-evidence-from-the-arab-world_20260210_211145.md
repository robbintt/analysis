---
ver: rpa2
title: 'Cross-Cultural Transfer of Commonsense Reasoning in LLMs: Evidence from the
  Arab World'
arxiv_id: '2509.19265'
source_url: https://arxiv.org/abs/2509.19265
tags:
- cultural
- ditto
- completion
- arab
- across
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates cross-cultural transfer of commonsense
  reasoning in LLMs within the Arab world, addressing the challenge of adapting models
  to diverse cultural contexts with limited data. The authors evaluate lightweight
  alignment methods (In-Context Learning and DITTO) using a culturally grounded dataset
  covering 13 Arab countries, demonstrating that as few as 12 culture-specific examples
  from one country can improve performance in others by 10% on average.
---

# Cross-Cultural Transfer of Commonsense Reasoning in LLMs: Evidence from the Arab World

## Quick Facts
- arXiv ID: 2509.19265
- Source URL: https://arxiv.org/abs/2509.19265
- Reference count: 40
- Key outcome: As few as 12 culture-specific examples from one country can improve performance in other Arab countries by 10% on average through cross-cultural transfer

## Executive Summary
This paper investigates cross-cultural transfer of commonsense reasoning in large language models within the Arab world, addressing the challenge of adapting models to diverse cultural contexts with limited data. The authors evaluate lightweight alignment methods (In-Context Learning and DITTO) using a culturally grounded dataset covering 13 Arab countries, demonstrating that as few as 12 culture-specific examples from one country can improve performance in others by 10% on average. The study also shows that out-of-culture demonstrations from Indonesia and US contexts can match or surpass in-culture alignment for multiple-choice reasoning, highlighting cultural commonsense transferability beyond the Arab world. Probing analyses reveal that targeted alignment enhances cultural encoding and that multilingual models show greater cross-cultural transfer effectiveness than Arabic-centric models.

## Method Summary
The study uses the ArabCulture dataset (3.2k examples across 13 countries, 12 topics) with 10% train/90% test split per country. Two alignment methods are evaluated: In-Context Learning (ICL) with 12-shot demonstrations and DITTO (demonstration-based preference optimization) with specific hyperparameters (LoRA rank=32, α=64; SFT LR 3×10⁻⁵; DPO LR 1×10⁻⁶, β=0.05, 10 negatives). Models tested include Qwen2.5-7B-Instruct, Gemma-2-9B-it (multilingual) and ALLaM-7B-Instruct, SILMA-9B-Instruct (Arabic-centric). Evaluation measures country-level accuracy gains for MCQ and completion tasks using lm-eval harness, with probing analysis to validate cultural encoding changes.

## Key Results
- 12 culture-specific demonstrations from one country improve performance in other Arab countries by 10% average
- Out-of-culture demonstrations from Indonesia and US contexts can match or surpass in-culture alignment for MCQ reasoning
- Multilingual models show greater cross-cultural transfer effectiveness than Arabic-centric models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cultural alignment data from one country transfers to improve performance on other Arab countries through shared cultural foundations
- Mechanism: Models develop broader Arab cultural understanding rather than memorizing country-specific features
- Core assumption: Arab cultures possess sufficient underlying similarity (linguistic, historical, social) that demonstrations from one context prime relevant knowledge for others
- Evidence anchors:
  - [abstract] "merely 12 culture-specific examples from one country can improve performance in others by 10% on average"
  - [Section 4] "Strong Cross-Cultural Transfer...training on small demonstration sets from a single Arab country consistently improves model performance on other Arab countries"
  - [Section 5.3] Table 6 shows high cultural similarity scores (0.72–0.89, averaging 0.85) between Arab countries
  - [corpus] Related work "Commonsense Reasoning in Arab Culture" confirms cultural commonsense is geographically/culturally situated
- Break condition: Transfer degrades for highly localized topics (idioms: 0.04 similarity, food: 0.06) vs. structured domains (agriculture: 0.08, family: 0.07)

### Mechanism 2
- Claim: Lightweight alignment methods (ICL, DITTO) achieve cultural adaptation with only 12 demonstrations by leveraging pre-existing cultural representations
- Mechanism: ICL conditions on demonstrations at inference; DITTO uses iterative preference optimization to shift model behavior using demonstrations as implicit rewards
- Core assumption: Models already encode cultural representations from pretraining that can be activated/redirected with minimal signals
- Evidence anchors:
  - [abstract] "merely 12 culture-specific examples from one country can improve performance"
  - [Section 3.2] "DITTO is data-efficient relative to SFT and full RLHF...enabling alignment from few examples"
  - [Section 4] DITTO achieves up to 34% accuracy gains with 12 demonstrations; ICL shows 2–5% consistent gains
- Break condition: Negative transfer occurs with small demonstration sets in DITTO (e.g., ALLaM MCQ: −14.88 pp with ICL)

### Mechanism 3
- Claim: Out-of-culture demonstrations (Indonesia, US) can match in-culture alignment for MCQ reasoning by activating transferable reasoning patterns
- Mechanism: Models learn general cultural reasoning schemas from any cultural context that generalize across cultures
- Core assumption: Cultural commonsense involves learnable reasoning patterns (social norms, relationships, practices) that transcend specific cultural contexts
- Evidence anchors:
  - [abstract] "out-of-culture demonstrations from Indonesia and US contexts can match or surpass in-culture alignment for MCQ reasoning"
  - [Section 5.4] Table 4: Qwen-2.5 US context achieves 68.71–69.94% MCQ vs. Arab average 69.21–69.30%
  - [Section 5.4] "minimal out-of-culture examples can rival in-culture alignment for MCQ reasoning"
- Break condition: Completion tasks show stronger dependence on culturally proximate demonstrations

## Foundational Learning

- Concept: In-Context Learning (ICL)
  - Why needed here: Primary few-shot baseline for cultural alignment; conditions model on demonstrations without parameter updates
  - Quick check question: Can you explain why ICL might outperform DITTO on completion tasks but underperform on MCQ tasks in multilingual models?

- Concept: Demonstration-Based Preference Optimization (DITTO)
  - Why needed here: Lightweight RL alternative requiring only demonstrations; iterative preference updates better suit discriminative MCQ settings
  - Quick check question: What hyperparameters control DITTO's sample efficiency, and how do they affect variance in cultural alignment scenarios?

- Concept: Cultural Probing and Linear Separability
  - Why needed here: Methodology for validating whether alignment changes cultural representations
  - Quick check question: How would you interpret a scenario where probing F1 scores increase for the aligned culture but reasoning improves across all cultures?

## Architecture Onboarding

- Component map:
  - Data Layer: ArabCulture dataset (3.2k examples, 13 countries, 12 topics, 90/10 train/test split)
  - Sampling Module: Topic-stratified (1 per topic, k=12) or single-topic (food-focused, k=12)
  - Alignment Engine: ICL (inference-time conditioning) or DITTO (LoRA rank 32, α=64; SFT LR 3×10⁻⁵; DPO LR 1×10⁻⁶, β=0.05, 10 negatives)
  - Evaluation Framework: lm-eval harness; MCQ accuracy + completion log-likelihood; country-level gain computation
  - Analysis Module: Geographic distance correlation, cultural similarity (cosine), layer-wise probing (one-vs-all + multiclass classifiers)
  - Model Pool: Qwen2.5-7B-Instruct, Gemma-2-9B-It (multilingual); ALLaM-7B-Instruct, SILMA-9B-Instruct (Arabic-centric)

- Critical path:
  1. Split ArabCulture by country (10% train/90% test per country)
  2. Sample 12 demonstrations per source country using topic-stratified or food-focused strategy
  3. Apply ICL (prepend demos to prompt) OR DITTO (iterative preference optimization with LoRA)
  4. Evaluate on held-out test sets from ALL 13 countries (not just source)
  5. Compute accuracy gains vs. baseline per country
  6. Run correlation analyses (geographic distance, cultural similarity) and probing experiments

- Design tradeoffs:
  - ICL vs. DITTO: ICL offers stability, lower negative transfer risk, better completion performance; DITTO achieves higher MCQ ceilings (up to +37.38 pp) with greater variance
  - Multilingual vs. Arabic-centric: Multilingual models show larger MCQ gains from lower baselines; Arabic-centric models achieve better completion improvements from higher baselines
  - Sample size: 12 demos enable data efficiency but increase variance; 100 demos reduce variance (MCQ: 1.13→0.48) at cost of curation effort

- Failure signatures:
  - Negative transfer: ALLaM ICL MCQ −14.88 pp average; SILMA-Lebanon DITTO −3.01 pp
  - Low-transfer topics: Idioms (0.04 similarity), food (0.06) show minimal gains
  - Geographic assumption failure: Distance correlation inconsistent (−0.80 to 0.65); cultural similarity more predictive
  - Cross-culture transfer asymmetry: Non-Arab demos work for MCQ but underperform on completion tasks

- First 3 experiments:
  1. **Baseline establishment**: Run zero-shot evaluation on ArabCulture test sets across all 4 models; record MCQ and completion baselines per country
  2. **Single-country transfer matrix**: Train on each of 3 representative countries (Egypt-high resource, UAE-low resource, Syria-highest improvement) using topic-stratified sampling with both ICL and DITTO; evaluate on all 13 countries
  3. **Out-of-culture probe**: Train on Indonesian (Aceh, Papua) and US contexts using DITTO; evaluate on Arab MCQ and completion tasks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does cross-cultural transferability persist in open-ended generative tasks such as dialogue or narrative generation, or is it specific to structured multiple-choice and completion tasks?
- Basis in paper: [explicit] The authors state in the Limitations section that "The realm of open-ended tasks (e.g., dialogue, narrative generation) introduces additional layers of complexity... underscoring the necessity for a deeper investigation."
- Why unresolved: The current study evaluates performance primarily through accuracy on MCQ and completion tasks, which may not capture the semantic coherence or cultural appropriateness required for free-form text generation
- What evidence would resolve it: Experiments applying DITTO and ICL alignment to open-ended generative benchmarks, evaluated using human assessment or culturally-aware LLM-as-a-judge metrics

### Open Question 2
- Question: What specific latent mechanisms allow out-of-culture demonstrations (e.g., US or Indonesian) to match or surpass in-culture alignment for Arab reasoning tasks?
- Basis in paper: [inferred] Section 5.4 notes the "surprising" result that US/Indonesian contexts can match Arab contexts, speculating that "compatibility and relevance of certain US cultural elements" might be the cause
- Why unresolved: The authors demonstrate that transfer occurs across distant cultures but acknowledge the need for "Further investigation" to explain the drivers of this phenomenon
- What evidence would resolve it: Ablation studies isolating reasoning logic from cultural context in demonstrations, or probing analysis comparing activation patterns triggered by in-culture vs. out-of-culture alignment examples

### Open Question 3
- Question: How does the volume of demonstration data interact with the need for memorization versus reasoning in fine-grained cultural nuance?
- Basis in paper: [explicit] The Limitations section suggests that while 12 examples suffice for broad reasoning, "A larger set of demonstrations and supervised fine-tuning may be required to mastering the intricacy of cultural knowledge that required memorization"
- Why unresolved: The paper focuses on data-efficient alignment (few-shot), but acknowledges that complex topics like idioms or highly specific rituals may not be resolvable via lightweight methods alone
- What evidence would resolve it: A scaling analysis measuring the error rate on high-specificity cultural tasks as the number of demonstrations increases from 12 to several hundred

## Limitations
- Dataset representativeness may not capture full regional variation, particularly for highly localized topics like idioms and food
- Results show strong variation across model architectures, suggesting transfer effectiveness may depend heavily on pretraining corpus
- Out-of-culture generalization shows task-dependent transfer, with completion tasks requiring culturally proximate demonstrations
- Negative transfer risks observed with ICL on MCQ tasks for Arabic-centric models

## Confidence

- **High confidence**: Cross-cultural transfer works with minimal examples (12 demonstrations achieving 10% average improvement); DITTO outperforms ICL for MCQ reasoning in multilingual models; cultural similarity predicts transfer better than geographic distance
- **Medium confidence**: Out-of-culture demonstrations matching in-culture alignment for MCQ reasoning; lightweight alignment achieving cultural adaptation with minimal demonstrations; multilingual models showing better cross-cultural transfer than Arabic-centric models
- **Low confidence**: Completion task performance with out-of-culture demonstrations; negative transfer mechanisms and their mitigation; exact factors determining when transfer succeeds vs. fails for specific topics

## Next Checks
1. Test transfer effectiveness with 100 demonstrations instead of 12 to verify if variance reduction improves reliability for low-resource countries
2. Conduct ablation studies on demonstration quality vs. quantity by comparing curated vs. random sampling strategies across all topics
3. Evaluate transfer to non-Arab cultures beyond Indonesia and US (e.g., African, Asian contexts) to test generalizability of cross-cultural reasoning patterns