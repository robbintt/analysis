---
ver: rpa2
title: Unifying Post-hoc Explanations of Knowledge Graph Completions
arxiv_id: '2507.22951'
source_url: https://arxiv.org/abs/2507.22951
tags:
- explanations
- triples
- explanation
- prediction
- rank
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work unifies post-hoc explainability in Knowledge Graph Completion
  (KGC) by formalizing explanations as solutions to a multi-objective optimization
  problem balancing effectiveness and conciseness. Existing explainability methods
  are unified within this framework, addressing fragmentation in evaluation standards.
---

# Unifying Post-hoc Explanations of Knowledge Graph Completions

## Quick Facts
- arXiv ID: 2507.22951
- Source URL: https://arxiv.org/abs/2507.22951
- Reference count: 40
- Key outcome: Unifies post-hoc explainability in KGC through multi-objective optimization balancing effectiveness and conciseness

## Executive Summary
This paper addresses the fragmentation in post-hoc explainability for Knowledge Graph Completion (KGC) by proposing a unified framework that formulates explanations as solutions to a multi-objective optimization problem. The framework balances effectiveness (how well explanations help KGC models) and conciseness (explanation brevity) while integrating existing explainability methods into a common evaluation standard. Experiments demonstrate that relying on single metrics like Mean Reciprocal Rank (MRR) can be misleading, advocating for multi-metric evaluation approaches.

## Method Summary
The authors formalize post-hoc explanations in KGC as a multi-objective optimization problem where the goal is to find subgraphs that optimize both effectiveness (measured through rank improvements like MRR, Hits@1, and Mean Rank Difference) and conciseness. They unify four existing algorithms—Kelpie, Data Poisoning, CRIAGE, and AnyBURL Explainer—within this framework and evaluate them on ComplEx models using the FB15k-237 dataset. The approach enables systematic comparison of different explanation methods using complementary metrics, addressing the current lack of standardized evaluation protocols in KGC explainability research.

## Key Results
- Single metrics like MRR can be misleading for evaluating explanation quality
- The unified framework enables rigorous comparison of diverse explainability methods
- Mean Rank Difference (MΔR) effectively captures the trade-off between explanation effectiveness and length
- Interpretability should be measured by explanations' ability to address user-relevant queries

## Why This Works (Mechanism)
The framework works by treating explanation generation as an optimization problem where multiple objectives must be balanced. By formalizing effectiveness and conciseness as competing objectives, it captures the inherent trade-off in explanation quality. The multi-metric evaluation approach prevents over-reliance on any single measure, providing a more comprehensive assessment of explanation utility.

## Foundational Learning
**Knowledge Graph Completion (KGC)**: The task of predicting missing links in knowledge graphs using embedding models. Needed to understand the problem domain and evaluation metrics like MRR and Hits@1. Quick check: Can the model predict tail entities given head entities and relations?

**Post-hoc Explainability**: Methods that generate explanations after a model has been trained, rather than being built into the model architecture. Needed to distinguish from intrinsic interpretability approaches. Quick check: Are explanations generated from the final model or during training?

**Multi-objective Optimization**: Mathematical framework for optimizing multiple, potentially conflicting objectives simultaneously. Needed to formalize the balance between effectiveness and conciseness. Quick check: Are all objectives properly normalized before optimization?

**ComplEx Embeddings**: Complex-valued embedding approach for KGC that captures asymmetric relations. Needed as the primary model for evaluation. Quick check: Do embeddings capture both symmetric and asymmetric relationships?

**Mean Reciprocal Rank (MRR)**: Evaluation metric that averages the reciprocal of the rank position of correct predictions. Needed as a standard effectiveness measure. Quick check: Is MRR computed over all test triples or a subset?

## Architecture Onboarding

**Component Map**: Data -> Preprocessed Graph -> KGC Model (ComplEx) -> Explanation Algorithm (Kelpie/Data Poisoning/CRIAGE/AnyBURL) -> Evaluation Metrics (MRR, Hits@1, MΔR)

**Critical Path**: The evaluation pipeline follows: load FB15k-237 → train ComplEx model → generate explanations using each algorithm → compute effectiveness metrics → calculate explanation length → analyze trade-offs between effectiveness and conciseness.

**Design Tradeoffs**: The framework trades computational complexity for evaluation comprehensiveness by requiring multiple metrics rather than single measures. This increases evaluation time but provides more reliable quality assessments.

**Failure Signatures**: Single-metric optimization may lead to explanations that optimize one measure while degrading others. Over-optimized conciseness may produce trivial explanations that don't capture meaningful patterns.

**First Experiments**:
1. Compare MRR changes when using different explanation algorithms on the same test set
2. Analyze the relationship between explanation length and rank improvements
3. Evaluate whether explanations generated by one algorithm transfer to improve other KGC models

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Limited to FB15k-237 knowledge graph and ComplEx/AnyBURL models, potentially constraining generalizability
- Multi-objective optimization framework assumes effectiveness and conciseness can be meaningfully balanced through a single formulation
- Evaluation metrics like MΔR focus on rank changes rather than semantic quality or explanation faithfulness
- Limited user study validation for claims about explanations addressing user-relevant queries

## Confidence

**High confidence**:
- Framework's ability to unify existing explainability methods
- Demonstration that single metrics like MRR can be misleading

**Medium confidence**:
- Practical effectiveness across different algorithms and datasets
- Claims about interpretability addressing user-relevant queries

## Next Checks
1. Test the unified framework across multiple knowledge graphs with varying characteristics (size, domain, density)
2. Conduct user studies to validate whether generated explanations actually address user-relevant queries
3. Extend evaluation to additional KGC models and embedding approaches beyond ComplEx and AnyBURL