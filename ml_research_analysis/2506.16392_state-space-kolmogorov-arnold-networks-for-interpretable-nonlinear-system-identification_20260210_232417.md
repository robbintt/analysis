---
ver: rpa2
title: State-Space Kolmogorov Arnold Networks for Interpretable Nonlinear System Identification
arxiv_id: '2506.16392'
source_url: https://arxiv.org/abs/2506.16392
tags:
- nonlinear
- system
- ss-kan
- state
- linear
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces State-Space Kolmogorov-Arnold Networks (SS-KAN),
  a new approach for interpretable nonlinear system identification that integrates
  Kolmogorov-Arnold Networks into a state-space framework. The method addresses the
  challenge of balancing accuracy with interpretability in nonlinear system identification
  by separating linear state-space dynamics from nonlinear functions modeled using
  KANs.
---

# State-Space Kolmogorov Arnold Networks for Interpretable Nonlinear System Identification

## Quick Facts
- arXiv ID: 2506.16392
- Source URL: https://arxiv.org/abs/2506.16392
- Authors: GonÃ§alo Granjal Cruz; Balazs Renczes; Mark C Runacres; Jan Decuyper
- Reference count: 22
- Primary result: Introduces SS-KAN combining state-space modeling with KANs for interpretable nonlinear system identification

## Executive Summary
This paper presents State-Space Kolmogorov-Arnold Networks (SS-KAN), a novel approach for nonlinear system identification that integrates Kolmogorov-Arnold Networks into a state-space framework. The method addresses the longstanding challenge of balancing model accuracy with interpretability in nonlinear system identification by separating linear state-space dynamics from nonlinear functions modeled using KANs. The authors validate their approach on two benchmark systems, demonstrating that SS-KAN provides a strong balance between accuracy and interpretability while maintaining reasonable computational efficiency.

## Method Summary
SS-KAN integrates Kolmogorov-Arnold Networks into a state-space framework for nonlinear system identification. The approach combines a linear state-space model with KANs to capture nonlinear dynamics, where the state-space component handles linear system behavior and KANs model the nonlinear relationships. This architecture enables interpretable identification by separating linear and nonlinear components while maintaining the ability to capture complex nonlinear dynamics through the KAN framework.

## Key Results
- Achieves RMSE of 0.0039V for Silverbox benchmark and 0.0114V for Wiener-Hammerstein benchmark
- Successfully captures cubic stiffness nonlinearity in Duffing oscillator for Silverbox system
- Reveals saturation characteristics of diode-resistor nonlinearity in Wiener-Hammerstein system
- Demonstrates training times of 1 hour for Silverbox and 6-8 hours for Wiener-Hammerstein on standard hardware

## Why This Works (Mechanism)
SS-KAN works by leveraging the universal approximation properties of KANs while maintaining the interpretability benefits of state-space representations. The separation of linear state dynamics from nonlinear KAN components allows for clear visualization and interpretation of learned univariate functions, enabling identification of physical system characteristics. The modular architecture facilitates both accurate modeling of complex nonlinear dynamics and straightforward interpretation of the learned relationships.

## Foundational Learning
- **State-space modeling**: Why needed - provides structured framework for dynamic systems; Quick check - verify system matrices satisfy stability conditions
- **Kolmogorov-Arnold Networks**: Why needed - enable universal approximation of multivariate functions through univariate compositions; Quick check - validate KAN can approximate known nonlinear functions
- **Nonlinear system identification**: Why needed - captures complex system behaviors beyond linear models; Quick check - compare residual analysis with linear baseline
- **Interpretability in ML**: Why needed - enables understanding and trust in learned models; Quick check - verify univariate function visualizations match expected system characteristics

## Architecture Onboarding

Component Map:
Input -> State-Space Model -> KAN Nonlinear Functions -> Output

Critical Path:
1. Input preprocessing and state initialization
2. State-space dynamic propagation through linear system matrices
3. Nonlinear function evaluation through KAN components
4. Output synthesis combining state and nonlinear contributions

Design Tradeoffs:
- Model complexity vs interpretability balance
- Training time vs accuracy optimization
- Number of basis functions vs computational efficiency
- State dimension selection for adequate representation

Failure Signatures:
- Poor convergence indicating insufficient model capacity
- Unphysical nonlinear function shapes suggesting model misspecification
- Large residuals in linear dynamics suggesting incorrect state-space structure
- Excessive training time indicating computational inefficiency

First Experiments:
1. Single-step prediction accuracy comparison with linear state-space baseline
2. Visualization of learned univariate functions against known system characteristics
3. Sensitivity analysis of training time to number of KAN basis functions

## Open Questions the Paper Calls Out
None

## Limitations
- Stopping criteria based on fixed epochs rather than convergence may affect reported RMSE values
- Computational efficiency claims lack direct runtime benchmarking against deep encoder approaches
- Interpretability claims rely on visualization without formal validation against known physical models

## Confidence
- Core methodology combining state-space modeling with KANs: High confidence
- Accuracy results for both benchmark systems: Medium confidence
- Interpretability demonstrations for Silverbox and Wiener-Hammerstein systems: High confidence

## Next Checks
1. Implement convergence-based stopping criteria and compare final RMSE values to the current fixed-epoch results to verify whether the reported performance represents true converged solutions
2. Conduct direct runtime benchmarking between SS-KAN and deep encoder approaches on identical hardware to quantify the computational efficiency claims
3. Perform systematic ablation studies varying the number of basis functions and state dimensions to characterize the trade-offs between model complexity, accuracy, and interpretability across different system types