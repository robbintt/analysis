---
ver: rpa2
title: 'Threshold-Based Optimal Arm Selection in Monotonic Bandits: Regret Lower Bounds
  and Algorithms'
arxiv_id: '2509.02119'
source_url: https://arxiv.org/abs/2509.02119
tags:
- optimal
- regret
- threshold
- identification
- lower
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper studies threshold-based identification tasks in stochastic\
  \ multi-armed bandit problems where arm means are monotonically increasing or decreasing.\
  \ Instead of maximizing rewards, the goal is to identify an arm based on its position\
  \ relative to a threshold \u03C4\u2014either the first above \u03C4, the \u2113\
  th above/below \u03C4, or the one closest to \u03C4."
---

# Threshold-Based Optimal Arm Selection in Monotonic Bandits: Regret Lower Bounds and Algorithms

## Quick Facts
- **arXiv ID**: 2509.02119
- **Source URL**: https://arxiv.org/abs/2509.02119
- **Reference count**: 20
- **Key outcome**: The paper derives asymptotic regret lower bounds for threshold-based arm identification in monotonic bandit settings and proposes three algorithms that leverage KL-divergence confidence bounds to achieve optimal performance, validated through Monte Carlo simulations.

## Executive Summary
This paper addresses threshold-based arm identification in stochastic multi-armed bandit problems where arm means follow a monotonic ordering. Unlike traditional bandit problems focused on cumulative reward maximization, this work targets identification of arms based on their position relative to a threshold τ—either the first above τ, the ℓth above/below τ, or the arm closest to τ. The authors establish asymptotic regret lower bounds that depend only on arms adjacent to the threshold and develop three specialized algorithms (TOSMB, RTOSMB, POSMB) that achieve these bounds using KL-divergence-based confidence intervals.

## Method Summary
The authors develop three algorithms for different threshold-based identification tasks in monotonic bandit settings. TOSMB addresses threshold-crossing identification using KL-divergence confidence bounds to guide exploration toward arms near the threshold. RTOSMB extends this to ranked threshold identification, while POSMB handles proximity-based identification where the goal is finding the arm closest to τ. All algorithms leverage the monotonicity property to prune arms and use adaptive exploration strategies that balance confidence in arm elimination with exploration of uncertain regions. The theoretical analysis derives asymptotic regret lower bounds that depend solely on the arms immediately adjacent to the threshold, establishing fundamental performance limits for these problems.

## Key Results
- Asymptotic regret lower bounds are derived showing optimal performance depends only on arms adjacent to threshold τ
- Three algorithms (TOSMB, RTOSMB, POSMB) achieve theoretical lower bounds using KL-divergence confidence bounds
- Monte Carlo simulations (30 trials, 10⁶ iterations) demonstrate convergence toward theoretical bounds
- Results extend classical bandit theory to structured, threshold-based objectives with applications in clinical dosing and communication networks

## Why This Works (Mechanism)
The algorithms work by exploiting the monotonicity structure of arm means to eliminate arms confidently below or above the threshold while adaptively exploring uncertain regions. KL-divergence confidence bounds provide statistically sound measures of uncertainty that guide the exploration-exploitation trade-off. The key insight is that only arms immediately adjacent to the threshold require careful exploration, as arms further away can be eliminated with high confidence. This selective exploration strategy enables the algorithms to achieve the derived asymptotic lower bounds.

## Foundational Learning
- **Stochastic Multi-Armed Bandits**: Sequential decision-making framework where actions have uncertain outcomes; needed to understand the baseline problem setting and why threshold-based identification differs from reward maximization; quick check: verify understanding of regret formulation
- **KL-Divergence Confidence Bounds**: Statistical tools for quantifying uncertainty in arm mean estimates; essential for the adaptive exploration strategy that balances confidence with exploration; quick check: confirm KL-divergence calculation for Gaussian/Bernoulli arms
- **Monotonicity Assumptions**: Structural property where arm means follow a strict ordering; enables efficient pruning of arms far from threshold; quick check: validate monotonicity holds in application domain
- **Asymptotic Analysis**: Technique for studying algorithm performance as time horizon approaches infinity; provides fundamental limits on achievable regret; quick check: ensure convergence criteria are met in simulations
- **Threshold-Based Identification**: Objective of finding arms based on position relative to threshold rather than maximizing cumulative reward; represents a different class of bandit problems; quick check: verify identification accuracy vs. traditional reward maximization

## Architecture Onboarding
- **Component Map**: KL-Divergence Confidence Bounds -> Adaptive Exploration Strategy -> Arm Elimination/Retention Decision -> Threshold Identification Output
- **Critical Path**: Arm sampling -> Mean estimate update -> KL-bound calculation -> Confidence-based pruning -> Threshold identification decision
- **Design Tradeoffs**: Conservative KL-bounds ensure statistical validity but may slow exploration; monotonicity assumption enables efficient pruning but limits applicability; adaptive exploration balances exploration and exploitation but requires careful parameter tuning
- **Failure Signatures**: Non-monotonic arm means cause incorrect pruning; overly conservative confidence bounds lead to excessive exploration; insufficient samples prevent reliable identification near threshold
- **First Experiments**: 1) Test algorithm on synthetic monotonic arms with known means to verify convergence to theoretical bounds; 2) Evaluate sensitivity to threshold location by varying τ across different arm configurations; 3) Compare performance against baseline UCB algorithms on threshold identification tasks

## Open Questions the Paper Calls Out
None

## Limitations
- Analysis focuses on asymptotic regret bounds assuming monotonicity, which may not hold in practical scenarios
- Performance validation limited to synthetic Monte Carlo simulations with fixed K=10 arms and τ=0.3
- KL-divergence-based confidence bounds may be overly conservative, potentially affecting empirical performance
- No computational complexity or runtime comparisons with existing methods provided
- Theoretical lower bounds derived under idealized conditions with unclear gap to practice

## Confidence
- **High**: The asymptotic regret lower bounds and their dependence on arms adjacent to τ are well-supported by theoretical analysis
- **Medium**: The proposed algorithms are theoretically sound, but their practical performance depends on the validity of monotonicity assumptions and the choice of confidence bounds
- **Low**: The empirical validation is limited to a narrow set of parameters, and the generalizability to broader settings is uncertain

## Next Checks
1. Test the algorithms on synthetic datasets with varying numbers of arms (K) and threshold values (τ) to assess robustness
2. Evaluate the impact of non-monotonic arm means on algorithm performance to understand the sensitivity to assumptions
3. Compare the computational efficiency and runtime of the proposed algorithms with existing methods in the literature