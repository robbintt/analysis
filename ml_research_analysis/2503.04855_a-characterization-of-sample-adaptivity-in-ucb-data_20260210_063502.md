---
ver: rpa2
title: A characterization of sample adaptivity in UCB data
arxiv_id: '2503.04855'
source_url: https://arxiv.org/abs/2503.04855
tags:
- sample
- lemma
- bandit
- mean
- bias
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper establishes a novel joint central limit theorem (CLT)
  characterizing the correlation structure between the number of pulls and sample
  mean rewards in two-armed stochastic bandit environments under generalized UCB algorithms.
  The result reveals a non-standard CLT for the number of pulls that smoothly interpolates
  between standard and slow-concentration regimes depending on the arm gap, with typical
  deviation scaling as $n2^ T/f(T)$ rather than the standard $\sqrt{n2^ T}$.
---

# A characterization of sample adaptivity in UCB data

## Quick Facts
- arXiv ID: 2503.04855
- Source URL: https://arxiv.org/abs/2503.04855
- Reference count: 40
- This paper establishes a novel joint central limit theorem (CLT) characterizing the correlation structure between the number of pulls and sample mean rewards in two-armed stochastic bandit environments under generalized UCB algorithms.

## Executive Summary
This paper presents a novel characterization of how the adaptive sampling in UCB algorithms affects the correlation between pull counts and sample mean rewards in two-armed stochastic bandit environments. By employing a perturbation analysis around a fluid approximation, the authors derive a non-standard CLT for the number of pulls that interpolates between standard and slow-concentration regimes depending on the arm gap. The analysis also reveals a non-standard CLT for pseudo-regret and provides a heuristic derivation of sample bias, showing it vanishes at a slow rate of $1/\sqrt{\log T}$ in small-gap regimes. The findings have implications for understanding the statistical properties of adaptive sampling and the limitations of standard confidence intervals in such settings.

## Method Summary
The paper analyzes a two-armed stochastic bandit under generalized UCB algorithms with sub-Gaussian rewards. The method employs a perturbation analysis around a deterministic fluid approximation to characterize the joint distribution of pull counts and sample means. The fluid approximation solves a system of equations equating the UCB indices across arms, providing a baseline for the stochastic analysis. The perturbation analysis linearizes the dynamics around this fluid solution, yielding explicit expressions for the asymptotic covariance structure. The approach combines fluid limit theory with high-probability concentration bounds to establish the main results.

## Key Results
- Establishes a non-standard CLT for the number of pulls that smoothly interpolates between standard and slow-concentration regimes depending on the arm gap, with deviation scaling as $n_2^* T/f(T)$ rather than $\sqrt{n_2^* T}$
- Derives a non-standard CLT for pseudo-regret with typical scaling $n_2^* T \Delta_T$ and deviation $\Theta(\sqrt{n_2^* T}/f(T))$
- Provides a heuristic derivation showing sample bias vanishes at rate $1/\sqrt{\log T}$ after normalization in small-gap regimes
- Develops a novel perturbation analysis framework for bandit systems around their fluid approximation

## Why This Works (Mechanism)

### Mechanism 1: Fluid Approximation
The stochastic dynamics of UCB algorithms can be approximated by a deterministic "fluid" system where arm indices remain perfectly balanced. The algorithm pulls the arm with the highest index $\bar{\mu} + f(t)/\sqrt{N}$. In the fluid limit (replacing random rewards with their means and time $t \to \infty$), the algorithm distributes pulls such that the indices of all arms are equal. Solving these equality constraints yields a deterministic "fluid approximation" $n^*_{i,T}$ for the number of pulls, which serves as the baseline for further analysis.

### Mechanism 2: Perturbation Analysis of Index Equality
The correlation between the number of pulls ($N_{i,T}$) and sample means ($\bar{\mu}_{i,T}$) arises from the algorithm's attempt to "equating indices" despite random fluctuations. The authors treat the bandit process as a dynamical system fluctuating around the fluid solution. By performing a first-order Taylor expansion of the index equality condition, they express the deviation in pull counts ($\omega_i = N_{i,T} - n^*_{i,T}$) as a linear combination of the deviations in sample means ($\bar{\varepsilon}_i$). This linear mapping explicitly reveals the covariance structure.

### Mechanism 3: Sample Bias from Adaptive Sampling
The sample mean of an arm exhibits a negative bias that decays at a rate of $1/\sqrt{\log T}$ in small-gap regimes. Because the sample size $N_{i,T}$ is adaptive (stopping rule depends on the observed mean), a high observed mean often leads to more pulls (for the inferior arm) or fewer pulls (for the superior arm). This correlation implies that conditional on the observed mean, the distribution of rewards is skewed. The joint CLT quantifies this correlation, allowing a heuristic calculation of the bias term.

## Foundational Learning

- **Concept: Fluid Approximation (Mean Field Theory)**
  - Why needed here: The paper's primary methodological contribution is analyzing the bandit system as a perturbation around a fluid limit. Without understanding this deterministic baseline, the stochastic fluctuation analysis is unintelligible.
  - Quick check question: Can you solve for the equilibrium number of pulls if you replaced the stochastic rewards in a UCB algorithm with their expected values?

- **Concept: Joint Central Limit Theorem (CLT)**
  - Why needed here: The paper moves beyond single-variable CLTs to a *joint* distribution of pulls and means. Understanding the covariance matrix $\Sigma$ is essential to grasping how pull counts and sample means influence each other.
  - Quick check question: If two random variables $X$ and $Y$ converge jointly to a bivariate normal, does $X$ necessarily converge to a normal if you ignore $Y$?

- **Concept: Concentration Inequalities (Sub-Gaussian)**
  - Why needed here: The proofs rely heavily on the sub-Gaussian property to bound the probability of the system deviating too far from the fluid approximation.
  - Quick check question: Why is the sub-Gaussian assumption critical for bounding the tail probabilities of the sum of rewards in the bandit context?

## Architecture Onboarding

- **Component map:** Environment -> Algorithm (Generalized UCB) -> Analysis Module
- **Critical path:**
  1. Identify the regime (Large, Moderate, or Small gap) to determine $\lambda^*$
  2. Solve fluid equations (Eq. 7) for $n^*_{1,T}, n^*_{2,T}$
  3. Apply Theorem 3.1 to determine if you are in a standard or "slow-concentration" regime
- **Design tradeoffs:**
  - Choosing a faster-growing $f(t)$ (more exploration) reduces the risk of linear regret (tail risk) but *increases* the typical deviation of the pseudo-regret
  - The naive sample mean is asymptotically unbiased but suffers from significant negative bias in finite samples, especially in small-gap regimes
- **Failure signatures:**
  - In small-gap regimes, $N_{2,T}$ will fluctuate wildly (scale $\Theta(T/\sqrt{\log T})$) rather than the tight $\Theta(\sqrt{\log T})$ fluctuation seen in large-gap regimes
  - Standard CLT-based confidence intervals will undercover in moderate/small gap regimes because the sample bias vanishes slower than the standard deviation
- **First 3 experiments:**
  1. Simulate UCB1 with $\Delta=0$ (small gap) and $\Delta=1$ (large gap). Plot the histogram of $(N_{2,T} - n^*_{2,T})$ scaled by the paper's prescribed factors to verify the "non-standard" vs "standard" CLT
  2. Run repeated trials for identical arms ($\mu_1=\mu_2$). Calculate the empirical bias $\hat{\mu}_{2,T} - \mu_2$. Plot this bias scaled by $\sqrt{\log T}$ to check if it converges to a non-zero constant
  3. Estimate the empirical correlation between $N_{2,T}$ and $\bar{\mu}_{2,T}$ from simulation data and compare it to the theoretical correlation derived in Theorem 3.1

## Open Questions the Paper Calls Out

- Can the heuristic derivation of the sample bias in Conjecture 4.3 be rigorously proven?
- Does the joint CLT characterization hold for general $K$-armed settings in arbitrary arm-gap regimes?
- Can the perturbation analysis framework be applied to characterize data from non-index-based algorithms like Thompson Sampling?

## Limitations
- The perturbation analysis around the fluid approximation may break down in extremely small-gap regimes where deviations are large
- The heuristic derivation of sample bias is not rigorously proven, though supported by simulation
- The asymptotic results assume sub-Gaussian rewards and sufficiently large horizons (up to $T=10^{13}$), which may not hold in practical finite-sample settings

## Confidence

- **High Confidence:** The fluid approximation equations and characterization of different gap regimes are mathematically rigorous and well-established in the bandit literature
- **Medium Confidence:** The perturbation analysis leading to the joint CLT follows standard techniques but involves approximations whose validity in edge cases is not fully explored
- **Medium Confidence:** The conjectured sample bias is supported by simulation and heuristic derivation but lacks a formal proof

## Next Checks
1. Simulate UCB1 with varying arm gaps and verify that the scaled pull count fluctuations follow either the standard $\sqrt{\log T}$ or non-standard $T/\sqrt{\log T}$ scaling depending on the regime
2. Run experiments with identical arms ($\mu_1=\mu_2$) and verify that the sample bias scaled by $\sqrt{\log T}$ converges to the conjectured constant from Conjecture 4.3
3. Estimate the empirical correlation between pull counts and sample means from simulation data and compare it to the theoretical correlation matrix derived in Theorem 3.1