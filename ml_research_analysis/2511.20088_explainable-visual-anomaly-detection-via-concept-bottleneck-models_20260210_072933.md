---
ver: rpa2
title: Explainable Visual Anomaly Detection via Concept Bottleneck Models
arxiv_id: '2511.20088'
source_url: https://arxiv.org/abs/2511.20088
tags:
- concept
- anomaly
- detection
- concepts
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work extends Concept Bottleneck Models (CBMs) to the Visual
  Anomaly Detection (VAD) setting, enabling human-interpretable explanations for anomalies
  through learned semantic concepts while maintaining detection performance comparable
  to state-of-the-art VAD methods. The authors tackle three key challenges: creating
  a Concept Dataset for VAD using an automated pipeline with Vision Language Models,
  extending CBM architecture to provide both concept-based and visual explanations
  via a student-teacher paradigm, and generating synthetic anomalies to minimize dependence
  on rare real anomalous samples.'
---

# Explainable Visual Anomaly Detection via Concept Bottleneck Models

## Quick Facts
- arXiv ID: 2511.20088
- Source URL: https://arxiv.org/abs/2511.20088
- Authors: Arianna Stropeni; Valentina Zaccaria; Francesco Borsatti; Davide Dalle Pezze; Manuel Barusco; Gian Antonio Susto
- Reference count: 40
- Primary result: CONVAD achieves I-AUC/I-F1 up to 0.97/0.86 in fully supervised settings while providing concept-based explanations

## Executive Summary
This work extends Concept Bottleneck Models (CBMs) to Visual Anomaly Detection (VAD), enabling human-interpretable explanations for anomalies through learned semantic concepts while maintaining detection performance comparable to state-of-the-art VAD methods. The authors tackle three key challenges: creating a Concept Dataset for VAD using an automated pipeline with Vision Language Models, extending CBM architecture to provide both concept-based and visual explanations via a student-teacher paradigm, and generating synthetic anomalies to minimize dependence on rare real anomalous samples. Their approach, CONVAD, achieves strong image-level and pixel-level detection performance while providing richer, concept-driven explanations that bridge semantic interpretability with visual localization.

## Method Summary
The CONVAD method implements a joint CBM training approach where a MobileNet-v2 backbone extracts features, which are then processed by k parallel linear concept predictors and an 8-neuron FCN for anomaly detection. The system uses a weighted BCE loss to handle class imbalance, with a λ parameter controlling the trade-off between concept and label prediction terms. A student-teacher visual module based on STFPM computes pixel-level anomaly maps by training a randomly initialized student network to match the features of a concept-tuned teacher backbone on normal images. Synthetic anomalies are generated using Nano Banana with controlled defect types, objects, and poses. The entire pipeline includes a VLM-based concept extraction system using Gemma3 for initial concept identification and CLIP ViT-B/32 for concept filtering and grouping.

## Key Results
- CONVAD achieves I-AUC/I-F1 up to 0.97/0.86 in fully supervised settings
- Even minimal real anomaly supervision combined with synthetic anomalies significantly improves performance over unsupervised baselines
- Concept-level interventions can enhance detection accuracy beyond standard VAD approaches
- Visual explanations via student-teacher paradigm provide pixel-level localization while maintaining concept-based interpretability

## Why This Works (Mechanism)
The method works by decomposing anomaly detection into interpretable semantic concepts, allowing the model to reason about anomalies at a human-understandable level. The CBM architecture forces the model to learn meaningful concept representations before making final anomaly predictions, creating a natural explanation mechanism. The student-teacher visual module provides complementary pixel-level explanations by capturing feature differences between normal and potentially anomalous regions. Synthetic anomaly generation addresses the fundamental challenge of limited real anomaly data in VAD, enabling more robust training across diverse defect types.

## Foundational Learning
- **Concept Bottleneck Models**: Neural networks that first predict interpretable concepts before making final predictions - needed to create human-understandable explanations for anomalies; quick check: verify concept predictions align with human semantic understanding
- **Student-Teacher Learning**: Training a student network to mimic a teacher's features or predictions - needed for pixel-level visual explanations without requiring additional labeled data; quick check: measure feature similarity between student and teacher on normal images
- **Vision Language Models**: Models that can understand and generate descriptions of visual content - needed for automated concept extraction from images without manual annotation; quick check: validate extracted concepts against human-annotated ground truth
- **Synthetic Anomaly Generation**: Creating artificial anomalies to augment training data - needed to overcome the rarity of real anomalous samples in VAD datasets; quick check: visualize synthetic vs real anomalies to assess realism
- **Concept Filtering via Similarity**: Using semantic similarity measures to group and filter concepts - needed to reduce concept redundancy and improve annotation quality; quick check: measure concept overlap before and after filtering
- **Weighted BCE Loss**: Loss function that balances multiple prediction tasks with different class distributions - needed to handle imbalanced concept labels and anomaly classes; quick check: monitor concept vs label loss ratios during training

## Architecture Onboarding

**Component Map**
VLM concept extraction -> Concept filtering/grouping -> CBM backbone (MobileNet-v2) -> k concept predictors + 8-neuron FCN -> Student-teacher visual module -> Anomaly maps and explanations

**Critical Path**
Image -> MobileNet-v2 features -> Concept predictors + FCN label predictor (joint training) -> Anomaly detection and concept explanations

**Design Tradeoffs**
- Joint vs sequential training of concept and label predictors: joint training allows better feature sharing but may cause interference
- Number of concepts (k): more concepts provide richer explanations but increase model complexity and annotation burden
- Synthetic vs real anomaly reliance: synthetic anomalies enable better training but may not fully capture real anomaly distribution

**Failure Signatures**
- Distribution shift between synthetic and real anomalies (observed in metal_nut: C-AUC 0.59→0.76 with weakly+SAG)
- Poor concept annotation quality for diffuse features (e.g., "surface discontinuity")
- Weak student-teacher feature matching leading to poor visual explanations

**First Experiments**
1. Train CBM with only concept predictions to validate concept quality before adding anomaly detection
2. Implement student-teacher module on a small dataset to verify feature matching capability
3. Generate synthetic anomalies for one category and measure concept distribution alignment with real anomalies

## Open Questions the Paper Calls Out
None

## Limitations
- Heavy reliance on proprietary Vision Language Models with unspecified prompt templates makes exact replication challenging
- Synthetic anomaly generation quality varies across categories, with distribution shift observed between synthetic and real anomalies
- Performance depends significantly on concept annotation quality, particularly for diffuse or subjective features

## Confidence

**High Confidence**: The core framework architecture (CBM with student-teacher visual module), overall training methodology (joint concept-label prediction with weighted BCE loss), and primary performance metrics (I-AUC, I-F1, P-AUC, P-F1) are clearly specified and reproducible with the given information.

**Medium Confidence**: The data preprocessing pipeline (concept extraction, filtering, annotation) can be implemented using the described methodology, though exact prompt templates and VLM configurations may affect results. The synthetic anomaly generation approach is conceptually sound but implementation details limit exact replication.

**Low Confidence**: Exact hyperparameter values (λ weighting, learning rates, batch sizes) and the complete prompt templates for VLM operations cannot be determined from the paper, potentially affecting performance and requiring extensive hyperparameter tuning.

## Next Checks

1. **Concept Annotation Validation**: Manually annotate a subset of images (e.g., 50 images across 3 categories) with ground truth concepts and compare against VLM-generated annotations to quantify precision/recall and identify systematic biases in concept extraction.

2. **Synthetic-Real Anomaly Alignment**: Perform t-SNE visualization of concept logits for synthetic vs. real anomalies to quantify distribution shift. Measure nearest-neighbor distances and clustering patterns to assess whether synthetic anomalies adequately represent real anomaly space.

3. **Ablation on Concept Quality**: Train CBM variants with different concept annotation qualities (e.g., human-annotated vs. VLM-annotated vs. reduced concept sets) to measure impact on detection performance and validate the sensitivity of the method to concept annotation quality.