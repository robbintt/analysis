---
ver: rpa2
title: Detection Method for Prompt Injection by Integrating Pre-trained Model and
  Heuristic Feature Engineering
arxiv_id: '2506.06384'
source_url: https://arxiv.org/abs/2506.06384
tags:
- feature
- prompt
- attack
- injection
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a dual-channel feature fusion framework called
  DMPI-PMHFE to detect prompt injection attacks on large language models. The method
  integrates DeBERTa-v3-base for semantic feature extraction with heuristic feature
  engineering for explicit structural pattern detection.
---

# Detection Method for Prompt Injection by Integrating Pre-trained Model and Heuristic Feature Engineering

## Quick Facts
- arXiv ID: 2506.06384
- Source URL: https://arxiv.org/abs/2506.06384
- Authors: Yi Ji; Runzhi Li; Baolei Mao
- Reference count: 29
- Primary result: 97.94% accuracy on internal dataset; reduces attack success rate from 71.71% to 14.34% in real-world deployment

## Executive Summary
This paper proposes DMPI-PMHFE, a dual-channel feature fusion framework for detecting prompt injection attacks on large language models. The method combines DeBERTa-v3-base transformer for semantic feature extraction with heuristic feature engineering for explicit structural pattern detection. Experiments show the approach achieves 97.94% accuracy and 98.29% F1-score on internal datasets while significantly reducing attack success rates when deployed against real LLM systems including GLM-4, LLaMA 3, Qwen 2.5, and GPT-4o.

## Method Summary
DMPI-PMHFE processes input text through two parallel channels: a DeBERTa-v3-base transformer for semantic feature extraction and a heuristic engineering module for explicit pattern detection. The semantic channel uses average pooling to create a 768-dimensional vector, while the heuristic channel applies synonym matching and pattern matching rules to generate a 10-dimensional binary vector. These features are concatenated and passed through fully connected neural networks for binary classification. The model is trained with Adam optimizer (lr=2e-5, batch_size=16, weight_decay=0.02) using cross-entropy loss and early stopping.

## Key Results
- Achieves 97.94% accuracy, 98.59% recall, and 98.29% F1-score on the internal safeguard-v2 dataset
- Reduces attack success rates from 71.71% to 14.34% on GLM-4 when deployed as a defense mechanism
- Outperforms baseline methods across all evaluation metrics on both internal and external validation datasets

## Why This Works (Mechanism)

### Mechanism 1: Dual-Channel Feature Fusion
Integrating deep semantic representations with explicit heuristic patterns mitigates coverage limitations of single-channel detection. The framework processes input through two parallel channels - DeBERTa-v3-base for contextual vectors and heuristic engineering for binary features - which are concatenated and passed through a fully connected network. The core assumption is that prompt injection attacks possess distinct signatures detectable via both semantic context and syntactic patterns, providing orthogonal information. Break condition: if attacks evolve to use semantically benign language lacking defined structural patterns, performance may regress to the DeBERTa baseline.

### Mechanism 2: Synonym-Expanded Semantic Triggers
Heuristic detection of semantic-based attacks is enhanced by expanding specific attack keywords into synonym sets rather than exact matching. The system extracts high-frequency keywords (e.g., "ignore") and expands them using WordNet, flagging inputs if tokens match this expanded semantic list. Core assumption: semantic-based attacks consistently utilize vocabulary within the semantic vicinity of seed keywords. Break condition: attackers use synonyms outside the WordNet graph or metaphorical language not captured by the initial keyword list.

### Mechanism 3: Structural Pattern Matching (Regex)
Structure-based attacks like "many-shot" or "repeated token" attacks are detectable via deterministic pattern matching on token sequences. The module applies regular expressions to tokenized text to count Q&A pairs or repetitive sequences, activating a binary feature if counts exceed thresholds. Core assumption: specific attack strategies leave detectable structural artifacts that persist even if semantic content changes. Break condition: if attackers obfuscate structure without changing the core payload, this channel fails.

## Foundational Learning

- **Concept: DeBERTa Disentangled Attention**
  - Why needed: Understanding that DeBERTa-v3 uses a disentangled mechanism to capture context more effectively than standard BERT, critical for the implicit feature path
  - Quick check: How does DeBERTa's attention mechanism differ from BERT's, and why does that matter for detecting subtle context shifts in prompts?

- **Concept: Late Fusion Architecture**
  - Why needed: The model processes features independently and combines them before the classification head, not early fusion
  - Quick check: Why would late fusion (concatenating vectors right before the classifier) be preferred over early fusion for modalities as different as dense embeddings and sparse binary rules?

- **Concept: Precision-Recall Trade-off in Security**
  - Why needed: The paper explicitly notes a trade-off where adding heuristics lowered precision slightly but boosted recall, a common security dynamic
  - Quick check: In the context of an LLM firewall, is a False Positive or False Negative more costly, and how does the F1-score reflect this balance?

## Architecture Onboarding

- **Component map:** Raw text -> DeBERTa Tokenizer -> Transformer Encoder -> Average Pooling -> Dense Vector (768-dim) + en_core_web_sm Tokenizer -> Lemmatization -> [Synonym Matcher + Pattern Matcher] -> Binary Vector (10-dim) -> Concat(Dense, Binary) -> Fully Connected (ReLU) -> Fully Connected (SoftMax) -> [Benign / Injection]

- **Critical path:** Heuristic definition creates the "inductive bias" of the system; FC layers must learn to weigh the strong semantic signal against the sparse binary heuristic signal

- **Design tradeoffs:** Recall vs. Precision - full model achieves peak recall (98.59%) but slightly lower precision (98.00%) compared to semantic-only models (99.58%); Static vs. Dynamic Rules - heuristic rules are interpretable but require manual updates for new attack families

- **Failure signatures:** Semantic Drift - false positives on legitimate instructions containing words like "ignore"; Adversarial Obfuscation - attacks using synonyms outside WordNet set or novel structures not in defined rules

- **First 3 experiments:** 1) Ablation Validation - run inference using only DeBERTa vs. full model to quantify heuristic lift; 2) Threshold Sensitivity - vary "many-shot" detector threshold to find optimal point for benign FAQ prompts; 3) Cross-Model ASR Test - deploy filter before GLM-4 and Llama-3 to verify ASR reduction matches claims

## Open Questions the Paper Calls Out

- How can the feature fusion strategy be refined to improve precision without sacrificing the high recall achieved by the pattern matching module? (The authors note adding pattern matching causes slight precision decrease while boosting recall, and future work will focus on optimizing precision)

- Can advanced data augmentation techniques effectively bridge the performance gap caused by distribution shifts between internal and external validation datasets? (The authors identify performance variations across external datasets as resulting from data distribution differences and propose incorporating data augmentation)

- How resilient is the heuristic-based pattern matching module against adversarial prompt modifications designed to bypass regex rules? (The method relies on static keyword lists and regular expressions, theoretically brittle against adversarial attacks that modify text structure)

## Limitations

- Static rule dependence - heuristic channel uses static rules (WordNet expansions and fixed regex thresholds) requiring manual updates for novel attack families
- Distribution shift risk - effectiveness relies heavily on heuristic feature set matching training data patterns, with unclear absolute performance on unseen injection strategies
- Feature engineering granularity - binary indicators may miss nuanced attack variants where attacks fall below defined thresholds

## Confidence

- **High Confidence**: Dual-channel architecture is technically sound and reported internal metrics are internally consistent
- **Medium Confidence**: Deployment results on real LLM systems are plausible but external validation is limited to one model
- **Low Confidence**: Exact regex patterns and complete synonym expansion lists are not provided, making edge-case coverage difficult to assess

## Next Checks

1. **Cross-Dataset Generalization Test**: Evaluate on ivanleomk-v2 and deepset-v2 without retraining, measuring per-category F1 and recall to identify which attack types heuristics fail to detect

2. **Adversarial Synonym Stress Test**: Generate test set using synonyms outside WordNet expansion to measure recall drop and analyze whether semantic channel compensates

3. **Dynamic Rule Update Simulation**: Simulate new attack family emergence by manually defining new heuristic pattern, integrating it, and measuring F1 change on mixed dataset of old and new attacks