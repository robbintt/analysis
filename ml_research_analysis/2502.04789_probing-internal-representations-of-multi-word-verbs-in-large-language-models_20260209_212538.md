---
ver: rpa2
title: Probing Internal Representations of Multi-Word Verbs in Large Language Models
arxiv_id: '2502.04789'
source_url: https://arxiv.org/abs/2502.04789
tags:
- verbs
- layers
- phrasal
- prepositional
- linguistic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates how BERT encodes distinctions between phrasal
  and prepositional verbs using probing classifiers and separability metrics. Token-level
  probing classifiers achieved high accuracy (up to 0.99) in middle layers (6-9),
  while sentence-level classifiers performed slightly worse.
---

# Probing Internal Representations of Multi-Word Verbs in Large Language Models

## Quick Facts
- arXiv ID: 2502.04789
- Source URL: https://arxiv.org/abs/2502.04789
- Authors: Hassane Kissane; Achim Schilling; Patrick Krauss
- Reference count: 8
- This study investigates how BERT encodes distinctions between phrasal and prepositional verbs using probing classifiers and separability metrics. Token-level probing classifiers achieved high accuracy (up to 0.99) in middle layers (6-9), while sentence-level classifiers performed slightly worse. GDV analysis showed weak linear separability between the two verb types. The mismatch between high classification accuracy and low GDV values suggests that BERT encodes these distinctions in a non-linearly separable manner, supporting usage-based claims about verb-particle constructions and highlighting limitations of linear separability as a sole criterion for assessing linguistic representations.

## Executive Summary
This paper investigates how BERT encodes distinctions between phrasal verbs (e.g., "give up") and prepositional verbs (e.g., "look at") using probing classifiers and geometric separability metrics. The study finds that middle transformer layers (6-9) achieve the highest classification accuracy, with token-level embeddings outperforming sentence-level embeddings. While classifiers achieve high accuracy, geometric analysis reveals weak linear separability between the two verb types, suggesting BERT encodes these distinctions in a non-linearly separable manner. These findings support usage-based linguistic theories and highlight limitations of linear separability metrics for evaluating linguistic representations in large language models.

## Method Summary
The study uses bert-base-uncased to probe internal representations of multi-word verbs. Sentences containing phrasal and prepositional verbs are preprocessed (lowercase, punctuation removed, whitespace normalized) and fed through BERT to extract embeddings at each of the 12 layers. Two probing approaches are employed: token-level classification using the main verb token embedding, and sentence-level classification using mean-pooled token embeddings. Logistic regression and linear SVM classifiers are trained per layer to distinguish between phrasal and prepositional verbs. Geometric separability is assessed using the Generalized Dunn Validity (GDV) metric, which measures linear separability through z-scored Euclidean distances between class clusters. Spearman correlation is computed between classification accuracy and GDV across layers.

## Key Results
- Middle layers (6-9) achieve highest classification accuracy (up to 0.99) for distinguishing phrasal from prepositional verbs
- Token-level embeddings outperform sentence-level embeddings for verb-type classification
- Weak linear separability (low GDV values) despite high classification accuracy suggests non-linear encoding
- No significant Spearman correlation between accuracy and GDV across layers (p>0.05)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Middle transformer layers (6–9) encode the most discriminative linguistic features for distinguishing multi-word verb constructions.
- Mechanism: BERT's layer-wise processing creates a hierarchical representation: early layers capture surface features, middle layers abstract syntactic-semantic properties, and later layers specialize toward task-specific representations. Probing classifiers exploit these mid-layer representations where verb-type distinctions are most salient.
- Core assumption: Linguistic category information is geometrically organized in embedding space such that classifiers can recover it from static snapshots.
- Evidence anchors:
  - [abstract] "The results indicate that the model's middle layers achieve the highest classification accuracies."
  - [section] "Both classifiers show the best accuracy in the middle layers (layers 6–9), suggesting that these layers encode the most significant linguistic features to distinguish between phrasal verbs and prepositional verbs."
  - [corpus] Derivational Probing paper confirms layer-wise syntactic structure derivation in neural LMs; Echoes of BERT extends this finding across 25 models.
- Break condition: If accuracy were uniform across layers or peaked at layer 0, the hierarchical encoding hypothesis would be unsupported.

### Mechanism 2
- Claim: Phrasal and prepositional verb representations are non-linearly separable in BERT's embedding space.
- Mechanism: Probing classifiers (even linear ones like LR/SVM) can leverage high-dimensional distributed representations where class boundaries exist along curved manifolds. GDV measures linear hyperplane separability, which fails when categories require non-linear decision boundaries despite being recoverable by learned classifiers.
- Core assumption: High probing accuracy with low linear separability implies genuine non-linear structure rather than probe memorization or artifacts.
- Evidence anchors:
  - [abstract] "The mismatch between high classification accuracy and low GDV values suggests that BERT encodes these distinctions in a non-linearly separable manner."
  - [section] "Since GDV measures linear separability, it does not capture non-linearly structured representations... the low GDV scores do not suggest that BERT fails to encode multi-word verb distinctions, but rather that these representations may require non-linear transformations."
  - [corpus] Weak direct corpus support for this specific verb-type claim; related work (Hewitt & Liang 2019, cited in paper) discusses probing limitations and non-linearity in linguistic representations.
- Break condition: If a linear probe with appropriate regularization matched GDV trends (both low), non-linearity would be less plausible; if GDV strongly correlated with accuracy (Spearman p<0.05), linear separability would be supported.

### Mechanism 3
- Claim: Token-level embeddings outperform sentence-level averaged embeddings for verb-type classification because localized representations preserve construction-specific features.
- Mechanism: Extracting only the main verb token (e.g., "give" from "give up") captures verb-inherent features plus contextual particle influence via attention. Averaging all sentence tokens dilutes this signal with unrelated lexical content, reducing discriminative power.
- Core assumption: The verb token's contextual embedding incorporates sufficient particle-verb co-occurrence patterns without explicit particle token extraction.
- Evidence anchors:
  - [abstract] "Token-level probing classifiers achieved high accuracy (up to 0.99) in middle layers (6-9), while sentence-level classifiers performed slightly worse."
  - [section] "The accuracies in the token-based classification were higher than those based on sentence embeddings."
  - [corpus] No direct corpus comparison found for token vs. sentence-level probing on multi-word verbs specifically.
- Break condition: If sentence-level embeddings consistently matched or exceeded token-level accuracy, the localized-information hypothesis would be weakened.

## Foundational Learning

- Concept: **Probing classifiers**
  - Why needed here: Probes are the core methodological tool for testing whether BERT embeddings encode linguistic distinctions. Understanding their limitations (can detect correlation without proving causal use) is essential for interpreting results.
  - Quick check question: If a probe achieves 95% accuracy, does this prove the model "uses" that feature for its task?

- Concept: **Linear vs. non-linear separability**
  - Why needed here: The paper's central tension (high probe accuracy, low GDV) hinges on understanding when linear metrics fail to capture learnable structure. GDV assumes cluster separation via hyperplanes; neural probes can learn curved boundaries.
  - Quick check question: If two classes form concentric spheres in 3D space, would a linear separability metric detect they are distinguishable?

- Concept: **Transformer layer hierarchy**
  - Why needed here: The layer-wise accuracy curve (low→peak→decline) reflects BERT's information flow: lexical→syntactic/semantic→task-specific. Middle layers are the sweet spot for linguistic probing.
  - Quick check question: Why might probing accuracy decrease in final layers even if the model performs well on downstream tasks?

## Architecture Onboarding

- Component map:
  - bert-base-uncased -> 12 transformer layers -> 768-dim embeddings -> token-level extraction OR sentence-level pooling -> probing classifiers (LR, SVM) -> accuracy/GDV computation

- Critical path:
  1. Preprocess sentences (lowercase, remove punctuation, normalize whitespace)
  2. Feed through BERT, extract embeddings at each layer (0–11)
  3. Train probes on training set (1,920 phrasal + 2,070 prepositional)
  4. Evaluate on test set (522 + 623); record layer-wise accuracy
  5. Compute GDV per layer on embeddings; assess separability
  6. Run Spearman correlation between accuracy and GDV across layers

- Design tradeoffs:
  - **Token vs. sentence level**: Token preserves local signal but ignores full context; sentence captures context but dilutes verb-specific features
  - **Linear probes only**: Limits probe capacity; non-linear probes might close gap between accuracy and GDV, obscuring non-linearity diagnosis
  - **Single model (BERT)**: Limits generalization claims; modern LLMs may encode differently

- Failure signatures:
  - Uniform accuracy across layers → no hierarchical encoding detected
  - GDV and accuracy strongly correlated (p<0.05) → representations are linearly separable, non-linearity claim fails
  - Sentence-level outperforms token-level → localized verb representation hypothesis unsupported
  - Probe accuracy near chance (0.5) → BERT does not encode this distinction recoverably

- First 3 experiments:
  1. Replicate token-level probing across layers with both LR and SVM; verify peak at layers 6–9 with accuracy ~0.99
  2. Compute GDV for token embeddings at each layer; confirm weak separability (GDV > -0.1) and no significant Spearman correlation with accuracy (p>0.05)
  3. Ablate particle token: probe using particle embedding ("up" from "give up") instead of verb token; assess whether particle contributes complementary information

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific non-linear geometric structures characterize the representation of phrasal versus prepositional verbs in BERT?
- Basis in paper: [explicit] The authors conclude that the "mismatch between high classification accuracy and low GDV values suggests that BERT encodes these distinctions in a non-linearly separable manner."
- Why unresolved: The study measured linear separability (GDV) and found it weak, but did not identify the specific non-linear manifolds or cluster structures the classifiers utilized.
- What evidence would resolve it: Application of non-linear dimensionality reduction techniques (e.g., t-SNE, UMAP) or topological data analysis to visualize and quantify the non-linear geometry of these embeddings.

### Open Question 2
- Question: Which analytical methods beyond linear separability metrics are required to accurately assess linguistic representations in LLMs?
- Basis in paper: [explicit] The discussion highlights the "limitations of linear separability as a sole criterion" and explicitly states the "need for comprehensive analytical methods" to understand how LLMs structure knowledge.
- Why unresolved: The paper demonstrates that existing linear metrics (GDV) fail to explain the high accuracy of non-linear classifiers, leaving a gap in interpretability methodology.
- What evidence would resolve it: The development of new evaluation metrics that quantify class separability in high-dimensional, non-linear spaces and demonstrate a stronger correlation with classifier performance.

### Open Question 3
- Question: Are the distinct layer-wise encoding patterns of multi-word verbs consistent across different transformer architectures?
- Basis in paper: [inferred] The study is restricted to `bert-base-uncased`; the generalizability of the finding that middle layers (6–9) encode these linguistic features is unknown.
- Why unresolved: It is undetermined if the observed peak in middle layers is a universal property of transformer language models or an artifact of BERT's specific bidirectional pre-training objectives.
- What evidence would resolve it: Replicating the probing and GDV experiments across diverse architectures (e.g., GPT, RoBERTa, Llama) to verify if the layer-wise trajectories differ.

## Limitations

- Dataset construction methodology is unclear with no source corpus specified for the custom dataset of phrasal and prepositional verbs
- Probing methodology limited to linear classifiers, potentially underestimating BERT's encoding capacity
- Study focuses exclusively on BERT-base-uncased, limiting generalizability to other transformer architectures

## Confidence

**High Confidence**: The observation that middle layers (6-9) achieve peak classification accuracy is well-supported and aligns with established literature on transformer layer hierarchies.

**Medium Confidence**: The claim about non-linear separability between phrasal and prepositional verbs rests on a reasonable methodological interpretation but requires careful consideration of probe capacity limitations.

**Low Confidence**: The comparative performance between token-level and sentence-level embeddings, while showing clear differences, lacks strong corpus support for this specific linguistic phenomenon.

## Next Checks

1. **Dataset Generalization Test**: Replicate the probing analysis on a publicly available corpus (such as Wikipedia or a standard NLP benchmark) to verify whether the layer-wise accuracy patterns and non-linear separability findings hold across different sentence sources.

2. **Non-linear Probe Validation**: Implement non-linear probing methods (such as multi-layer perceptrons or kernel SVMs) to test whether they can achieve both high accuracy and high GDV scores, which would challenge the current interpretation of non-linear structure.

3. **Cross-model Comparison**: Apply the identical probing methodology to other transformer models (such as RoBERTa, DistilBERT, or GPT variants) to determine whether the observed layer-wise patterns and separability characteristics are specific to BERT or represent broader architectural tendencies.