---
ver: rpa2
title: 'ViToSA: Audio-Based Toxic Spans Detection on Vietnamese Speech Utterances'
arxiv_id: '2506.00636'
source_url: https://arxiv.org/abs/2506.00636
tags:
- toxic
- speech
- vietnamese
- detection
- spans
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces ViToSA, the first Vietnamese dataset for audio-based
  toxic spans detection, containing 11,000 audio samples (25 hours) with human-annotated
  transcripts. The proposed pipeline combines automatic speech recognition (ASR) and
  toxic spans detection (TSD) to identify toxic content in Vietnamese speech.
---

# ViToSA: Audio-Based Toxic Spans Detection on Vietnamese Speech Utterances

## Quick Facts
- arXiv ID: 2506.00636
- Source URL: https://arxiv.org/abs/2506.00636
- Reference count: 0
- ViToSA achieves macro F1 of 0.837 for toxic spans detection using PhoBERT

## Executive Summary
This paper introduces ViToSA, the first Vietnamese dataset for audio-based toxic spans detection, containing 11,000 audio samples (25 hours) with human-annotated transcripts. The study proposes a pipeline combining automatic speech recognition (ASR) and toxic spans detection (TSD) to identify toxic content in Vietnamese speech. By fine-tuning ASR models on domain-specific toxic audio data, the researchers significantly reduced word error rates from 14.7% to 6.6%, particularly for toxic speech. The study demonstrates that text-based TSD models, when applied to ASR-transcribed text, can effectively detect toxic spans, with PhoBERT achieving the highest performance.

## Method Summary
The ViToSA pipeline employs a two-stage approach: first, an ASR system transcribes audio utterances into text, then a text-based TSD model identifies toxic spans within the transcription. The dataset was constructed using a semi-automatic pipeline that collects and annotates toxic Vietnamese speech, creating both audio and corresponding transcript pairs. ASR models were fine-tuned specifically on the ViToSA dataset, which significantly improved performance on toxic speech compared to general ASR models. Multiple TSD models (PhoBERT, XLM-R, ViHateT5) were evaluated on transcribed text, with PhoBERT achieving the best macro F1 score of 0.837.

## Key Results
- PhoBERT achieved the highest macro F1 score of 0.837 for toxic spans detection
- ASR fine-tuning on ViToSA reduced word error rate from 14.7% to 6.6%
- The dataset contains 11,000 audio samples spanning 25 hours of Vietnamese toxic speech
- Toxic ASR models outperformed general ASR models by 8.1% absolute WER reduction on toxic speech

## Why This Works (Mechanism)
The success of the ViToSA approach stems from domain adaptation at both the ASR and TSD stages. By fine-tuning ASR models on toxic speech data, the system better handles domain-specific vocabulary, slurs, and speech patterns common in toxic content. The text-based TSD models benefit from their pre-training on Vietnamese text corpora, allowing them to effectively detect toxicity patterns once the speech is accurately transcribed. The cascaded approach leverages the strengths of both speech recognition and natural language processing in a complementary fashion.

## Foundational Learning
- **Automatic Speech Recognition (ASR)**: Converting spoken language to text - needed to bridge audio and text-based toxicity detection; quick check: evaluate WER on domain-specific versus general test sets
- **Toxic Spans Detection (TSD)**: Identifying toxic words or phrases within text - needed to pinpoint harmful content rather than binary classification; quick check: measure precision-recall tradeoffs for different toxicity severity levels
- **Domain Adaptation**: Fine-tuning models on specialized data - needed to handle toxic speech's unique vocabulary and patterns; quick check: compare performance on in-domain versus out-of-domain toxic speech
- **Vietnamese Language Processing**: Handling tonal language characteristics - needed for accurate transcription and toxicity detection; quick check: analyze error patterns specific to Vietnamese tonal distinctions
- **Semi-automated Data Annotation**: Efficient dataset construction pipeline - needed to create large-scale annotated datasets; quick check: measure inter-annotator agreement rates
- **Cascaded Systems**: Sequential processing of multiple models - needed to combine complementary capabilities of ASR and TSD; quick check: quantify error propagation effects between stages

## Architecture Onboarding
**Component Map:** Audio -> ASR -> Text Transcription -> TSD Model -> Toxic Spans Labels
**Critical Path:** ASR transcription quality directly impacts TSD model performance
**Design Tradeoffs:** The pipeline trades potential end-to-end efficiency for modularity and the ability to leverage state-of-the-art text models
**Failure Signatures:** ASR errors (especially in toxic vocabulary) propagate to incorrect TSD predictions; transcription quality bottlenecks overall performance
**First 3 Experiments:**
1. Compare PhoBERT, XLM-R, and ViHateT5 on ViToSA transcripts
2. Measure WER reduction from general ASR to toxic ASR fine-tuning
3. Evaluate human versus ASR-transcribed performance on the same audio samples

## Open Questions the Paper Calls Out
The paper does not explicitly identify open questions, but the methodology suggests several implicit research directions:
- Can incorporating acoustic and prosodic features improve detection of implicit or sarcasm-laden toxicity compared to the text-only pipeline?
- Does training the TSD component directly on ViToSA human-annotated transcripts yield better performance than pre-training on separate text corpora?
- How does the cascaded pipeline compare to an end-to-end architecture in terms of error propagation and latency for real-time moderation?

## Limitations
- The dataset size of 11,000 samples remains modest compared to large-scale ASR training corpora
- ASR transcription errors propagate to TSD predictions, introducing an additional error source
- Text-based TSD models were evaluated only on transcribed text, not directly on audio features
- The study does not address precision-recall tradeoffs or false positive/negative patterns critical for deployment

## Confidence
- **High Confidence**: ASR fine-tuning methodology and resulting WER improvements are methodologically sound and reproducible
- **Medium Confidence**: TSD model comparisons and PhoBERT's superior performance, as the study design controls for model architecture but not all confounding variables
- **Medium Confidence**: The claim that ViToSA is the first Vietnamese audio-based toxic spans dataset, though comprehensive literature review supports this

## Next Checks
1. Evaluate TSD model performance on human-verified transcriptions versus ASR outputs to quantify error propagation effects
2. Test the pipeline on out-of-domain toxic speech data (different topics, speakers, or Vietnamese dialects) to assess generalization
3. Conduct ablation studies removing ASR transcription to determine if direct audio-to-toxicity models could outperform the transcription-based approach