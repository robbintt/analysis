---
ver: rpa2
title: 'ELM: Ensemble of Language Models for Predicting Tumor Group from Pathology
  Reports'
arxiv_id: '2503.21800'
source_url: https://arxiv.org/abs/2503.21800
tags:
- tumor
- pathology
- group
- reports
- cancer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ELM (Ensemble of Language Models), a novel
  approach for automating tumor group classification from pathology reports in population-based
  cancer registries. The method combines six fine-tuned small language models (SLMs)
  with a large language model (LLM) for arbitration.
---

# ELM: Ensemble of Language Models for Predicting Tumor Group from Pathology Reports

## Quick Facts
- arXiv ID: 2503.21800
- Source URL: https://arxiv.org/abs/2503.21800
- Reference count: 27
- Primary result: Achieves 0.94 average precision and recall on 2,058 pathology reports across 19 tumor groups

## Executive Summary
This paper introduces ELM (Ensemble of Language Models), a novel approach for automating tumor group classification from pathology reports in population-based cancer registries. The method combines six fine-tuned small language models (SLMs) with a large language model (LLM) for arbitration. Three SLMs analyze the top part of reports and three analyze the bottom part to maximize coverage, requiring five out of six models to agree. Disagreements are resolved by an LLM using a curated prompt. Evaluated on 2,058 pathology reports across nineteen tumor groups, ELM achieves an average precision and recall of 0.94, outperforming single-model and ensemble-without-LLM approaches. The method significantly enhances operational efficiency, saving hundreds of person-hours annually in the British Columbia Cancer Registry.

## Method Summary
ELM processes pathology reports using an ensemble of six fine-tuned small language models (SLMs), with three analyzing the first 512 tokens and three analyzing the last 512 tokens of each report. The ensemble uses majority voting requiring 5/6 agreement to determine tumor group classification. When fewer than 5 models agree, or when the predicted group is known to be difficult to classify (skin, cervix, multiple myeloma, primary unknown), an LLM (Mistral Nemo Instruct-2407) arbitrates using a curated prompt that constrains output to SLM-suggested or SME-specified tumor groups. The method is evaluated on 2,058 curated pathology reports across 19 tumor groups, achieving weighted average precision and recall of 0.94.

## Key Results
- ELM achieves 0.94 average precision and recall on 2,058 pathology reports
- Outperforms single-model and ensemble-without-LLM approaches
- Saves hundreds of person-hours annually in British Columbia Cancer Registry operations
- Improves F1 score for difficult tumor groups (e.g., leukemia from 0.76 to 0.88 with LLM arbitration)

## Why This Works (Mechanism)

### Mechanism 1: Spatial partitioning for coverage
- Spatial partitioning of pathology reports across ensemble members improves coverage of diagnostically relevant content
- Three SLMs process the first 512 tokens (top of report) and three process the last 512 tokens (bottom), addressing transformer token limits while ensuring diagnostic signals appearing anywhere in the document can be captured
- Core assumption: Tumor group indicators are distributed throughout pathology reports rather than concentrated in a single section
- Evidence: Abstract states "three SLMs use the top part of the pathology report and three SLMs use the bottom part. This is done to maximize report coverage"

### Mechanism 2: Constrained LLM arbitration
- Constrained LLM arbitration on low-consensus cases improves classification of linguistically ambiguous tumor groups
- When fewer than 5 of 6 SLMs agree, or when predicted groups are known hard-to-classify categories, an LLM receives the report plus a curated prompt restricting output to SLM-suggested or SME-specified tumor groups
- Core assumption: LLMs possess superior contextual reasoning for ambiguous cases when search space is narrowed
- Evidence: Section 4.4 shows F1 improvement from 0.76 to 0.88 for leukemia with LLM arbitration

### Mechanism 3: Selective LLM routing
- Selective LLM routing balances computational cost with accuracy gains
- Only cases failing the 5/6 agreement threshold or belonging to pre-identified difficult tumor groups invoke the LLM, reducing inference cost compared to LLM-only approaches
- Core assumption: SLMs correctly classify the majority of straightforward cases; LLM value is concentrated on edge cases
- Evidence: Section 2.1 states "As LLMs are computationally expensive, even for inference, our method ensures that not all pathology reports need to go to the LLM"

## Foundational Learning

- **Concept**: Ensemble voting with threshold-based routing
  - Why needed here: ELM uses a 5/6 agreement threshold to decide when SLM consensus is sufficient versus when to escalate
  - Quick check question: Given 6 model predictions [A, A, A, B, B, C], what is the maximum vote count and does it meet a 5/6 threshold?

- **Concept**: Transformer input token limits and truncation strategies
  - Why needed here: Pathology reports exceed typical 512-token limits; ELM addresses this via top/bottom partitioning rather than truncation or sliding windows
  - Quick check question: If a report has 1,200 tokens and you can only process 512, what information might be lost with head-only truncation?

- **Concept**: Zero-shot constrained prompting
  - Why needed here: The LLM is used zero-shot (no fine-tuning) but constrained to select from a provided list of tumor groups with reasoning output
  - Quick check question: Why might constraining an LLM to choose from [A, B, C] rather than "any tumor group" improve accuracy for a 19-class problem?

## Architecture Onboarding

- **Component map**: HL7 message parsing -> eMaRC filtering -> reportability classification -> Preprocessing -> SLM Ensemble -> Voting Aggregator -> Hard-Case Router -> LLM Arbitrator -> Final Classification

- **Critical path**:
  1. Tokenize report -> extract first 512 and last 512 tokens
  2. Run all 6 SLMs in parallel -> collect predictions
  3. Sum votes per class -> identify max vote count and winning class
  4. If max_votes < 5 OR winning_class ∈ G -> route to LLM with prompt containing candidate classes
  5. LLM outputs JSON with tumor_group and reason -> final classification

- **Design tradeoffs**:
  - Threshold (v=5): Higher thresholds increase LLM load but may improve accuracy; lower thresholds reduce LLM use but risk SLM errors
  - LLM size (12B vs. 3B): Mistral 12B outperforms smaller models by 2 points F1; smaller models viable if compute-constrained
  - Hard-class set G: Adding more classes to G increases LLM arbitration and accuracy for those classes but raises cost

- **Failure signatures**:
  - High LLM escalation rate: Check if threshold is too aggressive or SLM quality has degraded
  - LLM returning invalid JSON: Prompt engineering issue; validate output parsing resilience
  - Consistent errors on specific tumor groups: May need to add to G or review training data quality
  - SLM ensemble confidence on wrong predictions: All 6 SLMs may agree incorrectly on hard classes—this is why G exists

- **First 3 experiments**:
  1. Ablate spatial partitioning: Train 6 SLMs all on full 512 tokens (head-only) vs. current 3-head/3-bottom split; compare ensemble accuracy to validate coverage hypothesis
  2. Vary voting threshold: Test v ∈ {4, 5, 6} and measure accuracy vs. % cases routed to LLM to find cost-accuracy Pareto frontier
  3. LLM constraint relaxation: Compare constrained prompting (SLM suggestions only) vs. semi-constrained (SLM suggestions + G classes) vs. unconstrained (all 19 classes) to quantify constraint value

## Open Questions the Paper Calls Out

- **Open Question 1**: Does fine-tuning the arbitrating LLM improve performance over the zero-shot approach?
  - Basis: Authors explicitly list "evaluating the impact of fine-tuned LLMs instead of the zero shot approach as used in this paper" as future work
  - Why unresolved: Current implementation utilizes Mistral Nemo in a zero-shot capacity, leaving potential performance gains from domain-specific fine-tuning unquantified

- **Open Question 2**: Does ELM generalize effectively to other Population-Based Cancer Registries (PBCRs) with different reporting standards?
  - Basis: Authors state future work involves "validation of our proposed approach on other data sources (other PBCRs)"
  - Why unresolved: Study is restricted to British Columbia Cancer Registry; it is unclear if model transferability holds given potential variations in HL7 message formatting and linguistic nuances

- **Open Question 3**: Does the strategy of truncating reports to the top and bottom 512 tokens result in information loss for critical diagnostic features located in the middle of the text?
  - Basis: Methodology acknowledges using top and bottom sections to "maximize report coverage" but does not analyze specific failure cases where determining factor was excluded
  - Why unresolved: While ensemble improves coverage, it is unknown if "hard-to-classify" errors are partially driven by exclusion of middle portion of long reports

## Limitations

- Training data noise: Training labels are patient-level rather than report-level, introducing potential noise in supervision signals
- LLM arbitration scope: Effectiveness depends heavily on correctly identifying which tumor groups benefit from LLM intervention
- Spatial coverage strategy: Dual-partition approach may still miss diagnostic information in the middle of long reports

## Confidence

- **High confidence**: Ensemble voting mechanism with 5/6 threshold and observed performance metrics (0.94 precision/recall) on curated test set
- **Medium confidence**: Spatial partitioning (top/bottom token processing) significantly improves coverage, though lacks direct ablation studies
- **Medium confidence**: LLM arbitration is essential for difficult tumor groups, evidenced by performance gains but selection criteria for groups not fully explored

## Next Checks

1. Ablation study on spatial partitioning: Train a control ensemble using six models all on full 512 tokens (head-only) versus the current 3-head/3-bottom split. Compare ensemble accuracy to isolate contribution of spatial coverage strategy.

2. Threshold sensitivity analysis: Systematically vary the voting threshold (v ∈ {4, 5, 6}) and measure both accuracy and percentage of cases routed to LLM to identify optimal cost-accuracy tradeoff.

3. LLM constraint relaxation experiment: Compare constrained prompting (SLM suggestions only) versus semi-constrained (SLM suggestions + G classes) versus unconstrained (all 19 classes) to quantify how much constraint contributes to arbitration accuracy versus simply narrowing decision space.