---
ver: rpa2
title: 'From Idea to CAD: A Language Model-Driven Multi-Agent System for Collaborative
  Design'
arxiv_id: '2503.04417'
source_url: https://arxiv.org/abs/2503.04417
tags:
- design
- code
- user
- engineering
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents a Vision Language Model (VLM)-based Multi-Agent
  System (MAS) for automated Computer-Aided Design (CAD) model generation from sketches
  and textual descriptions. The system mimics human engineering development processes
  by combining three specialized agents: a Requirements Engineer for interactive specification
  clarification, a CAD Engineer for parametric model creation using CadQuery, and
  a Quality Assurance Engineer for verification through visual feedback.'
---

# From Idea to CAD: A Language Model-Driven Multi-Agent System for Collaborative Design

## Quick Facts
- arXiv ID: 2503.04417
- Source URL: https://arxiv.org/abs/2503.04417
- Authors: Felix Ocker; Stefan Menzel; Ahmed Sadik; Thiago Rios
- Reference count: 40
- Primary result: A VLM-based MAS generates specification-compliant CAD models from sketches/text through role-specialized agents and visual feedback

## Executive Summary
This paper presents a Vision Language Model (VLM)-based Multi-Agent System (MAS) for automated Computer-Aided Design (CAD) model generation from sketches and textual descriptions. The system mimics human engineering development processes by combining three specialized agents: a Requirements Engineer for interactive specification clarification, a CAD Engineer for parametric model creation using CadQuery, and a Quality Assurance Engineer for verification through visual feedback. Experiments demonstrate that the MAS produces significantly more complete and specification-compliant CAD models compared to direct VLM code generation. The approach shows promise for both expert engineers and hobbyists, though limitations remain in spatial reasoning for complex geometries and orientation challenges.

## Method Summary
The system uses three specialized agents working sequentially: a RequirementsEngineer clarifies specifications through interactive chat, a CadEngineer generates CadQuery code with documentation retrieval, and a QualityAssuranceEngineer verifies models through 7-view rendering and visual comparison. The architecture includes iterative validation loops where the QA agent provides textual feedback to the CadEngineer until specification compliance is achieved. The system uses GPT-4o for all agent roles and CadQuery for code-based CAD generation, with models rendered via pyvista for verification. Code is validated using Python's ast module before execution.

## Key Results
- MAS produces significantly more specification-compliant CAD models than direct VLM code generation
- Visual feedback loop with 7 views helps compensate for VLM spatial reasoning limitations
- System successfully generates simple to moderately complex models through collaborative human-AI interaction
- Interactive specification clarification reduces ambiguity and improves first-iteration success rates

## Why This Works (Mechanism)

### Mechanism 1: Role-Specialized Agent Decomposition
Dividing CAD generation into specialized agent roles (Requirements, CAD, QA) produces more complete and specification-compliant models than direct VLM code generation. Each agent receives role-specific system prompts that constrain its reasoning scope, with information flowing sequentially between agents to reduce context pollution. The V-model decomposition maps effectively to LLM agent boundaries.

### Mechanism 2: Visual Self-Feedback for Spatial Reasoning Compensation
Rendering multiple views of generated models and feeding them back to a VLM for comparison against specifications helps compensate for VLM spatial reasoning limitations. The QA agent renders 7 views (top, bottom, front, back, left, right, isometric), then the VLM performs visual comparison against the original sketch/specification. Discrepancies are converted to textual feedback for the CadEngineer.

### Mechanism 3: Interactive Specification Refinement with User-in-the-Loop
An interactive clarification phase before code generation reduces specification ambiguity and improves first-iteration success rates. The RequirementsEngineer explicitly identifies insufficiently specified aspects and prompts the user for clarification via chat. Only when ambiguities are resolved does a summary get passed to the CadEngineer.

## Foundational Learning

- **Parametric CAD via Code (CadQuery)**: Why needed here - The system generates Python code rather than manipulating GUI-based CAD. Understanding workplanes, extrusion, and boolean operations is essential to interpret generated code and debug failures. Quick check question: Can you explain what `cq.Workplane("XY").box(10, 10, 2, centered=False)` produces and why workplane selection matters?

- **Multi-Agent System Orchestration**: Why needed here - The system's effectiveness depends on how agents exchange information, handle handoffs, and manage shared state. Understanding agent communication patterns is critical for extending the architecture. Quick check question: What happens if the QA agent's feedback contradicts the user's original specification—which takes precedence?

- **VLM Spatial Reasoning Limitations**: Why needed here - The paper explicitly notes VLMs struggle with orientation and spatial relationships. Knowing these failure modes helps set realistic expectations and design appropriate safeguards. Quick check question: Why might a VLM correctly describe an image but generate code with wrong orientations?

## Architecture Onboarding

- **Component map**: RequirementsEngineer -> CadEngineer -> QualityAssuranceEngineer -> User Validation -> (feedback loop back to CadEngineer)
- **Critical path**: 1. User provides sketch/text → RequirementsEngineer clarifies 2. Clarified spec → CadEngineer plans → generates code → executes → STL 3. STL → QA agent renders views → compares to spec → generates feedback OR approves 4. If feedback exists → CadEngineer revises code (loop to step 2) 5. If approved → User validates (outer loop) → if rejected, user feedback → CadEngineer revises
- **Design tradeoffs**: 7 views vs. fewer (more views improve verification but increase token costs), Interactive clarification vs. VLM assumptions (more user interaction improves accuracy but reduces automation), CadQuery vs. commercial CAD (open-source enables automation but lacks advanced features)
- **Failure signatures**: Orientation errors (model features appear in wrong planes), Hallucinated API calls (VLM generates non-existent methods), Non-converging iterations (feedback loop repeats without resolution), Complex geometry failures (system failed on more complex components)
- **First 3 experiments**: 1. Replicate the block-with-two-holes example using exact specification from Table 1 and generated code from Listing 6 2. Ablation test—remove QA agent and compare output quality 3. Stress test—provide specification requiring non-default workplanes and observe iterations needed

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does implementing a fine-grained, feature-by-feature generation loop with intermediate visual confirmation improve geometric accuracy and convergence speed compared to whole-model generation?
- Basis in paper: Authors suggest code generation might benefit from a "more fine-grained iterative process... potentially using a visual confirmation loop to create the model’s individual features step by step."
- Why unresolved: Current system generates code holistically and struggles with complex geometries; impact of breaking down into smaller, verified feature steps is hypothesized but not tested.

### Open Question 2
- Question: To what extent does adding explicit spatial context—such as coordinate systems and dimension overlays—to QA agent's visual renderings improve VLM's ability to resolve orientation errors?
- Basis in paper: Authors note VLMs struggle with orientation and suggest verification "might also benefit from adding further spatial context... such as including a coordinate system and possibly even dimensions in every rendering."
- Why unresolved: Current implementation uses standard multi-view renderings; specific contribution of visualizing coordinate reference frame within images to aid VLM spatial reasoning remains unexplored.

### Open Question 3
- Question: Can fine-tuning the VLM on a dedicated CAD code corpus (specifically CadQuery) significantly reduce hallucination rates and syntax errors compared to current vanilla VLM implementation?
- Basis in paper: Authors conclude that while vanilla VLMs show impressive capabilities, agents "are likely to benefit from using a VLM finetuned on a dedicated training corpus."
- Why unresolved: Current system relies on general-purpose VLMs using retrieval-augmented documentation; performance gap between this approach and specialized fine-tuned model for CAD API syntax is unknown.

### Open Question 4
- Question: Does enabling interactive, human-initiated code editing within validation loop improve workflow efficiency and final model quality for expert users?
- Basis in paper: Authors identify potential research direction where "for expert users, it may be beneficial to be able to edit the generated code, possibly even in an interactive way."
- Why unresolved: Current system relies on natural language feedback; untested whether allowing experts to directly manipulate code provides shortcut that bypasses VLM interpretation limitations.

## Limitations
- Spatial reasoning limitations remain significant despite visual feedback loops
- Generalization boundaries unclear for complex real-world engineering tasks
- Incomplete ablation studies prevent isolating individual mechanism contributions

## Confidence
- **High confidence**: Role-specialized agent decomposition improves specification compliance over direct VLM code generation
- **Medium confidence**: Visual self-feedback effectively compensates for VLM spatial reasoning limitations
- **Medium confidence**: Interactive specification refinement improves accuracy, but optimal balance with automation unknown

## Next Checks
1. **Ablation test**: Remove the visual feedback loop and compare success rates on orientation-critical tasks
2. **Context window stress test**: Run 10+ consecutive failed iterations on a moderately complex model to test if context pollution prevents convergence
3. **Generalization boundary mapping**: Systematically vary model complexity to identify specific failure thresholds and characterize task complexity vs success probability relationship