---
ver: rpa2
title: Integrating Temporal and Structural Context in Graph Transformers for Relational
  Deep Learning
arxiv_id: '2511.04557'
source_url: https://arxiv.org/abs/2511.04557
tags:
- temporal
- relational
- graph
- learning
- context
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of modeling heterogeneous temporal
  relational graphs for relational deep learning. The proposed Relational Graph Perceiver
  (RGP) introduces a temporal subgraph sampler to retrieve temporally relevant nodes
  beyond the immediate neighborhood, and uses a Perceiver-style cross-attention bottleneck
  to efficiently integrate structural and temporal context.
---

# Integrating Temporal and Structural Context in Graph Transformers for Relational Deep Learning

## Quick Facts
- **arXiv ID**: 2511.04557
- **Source URL**: https://arxiv.org/abs/2511.04557
- **Reference count**: 40
- **Primary result**: RGP achieves state-of-the-art performance on RelBench, CTU, and SALT, with 2.2% average improvement over RelGT and strong multi-task learning capabilities.

## Executive Summary
This paper addresses the challenge of modeling heterogeneous temporal relational graphs for relational deep learning. The proposed Relational Graph Perceiver (RGP) introduces a temporal subgraph sampler to retrieve temporally relevant nodes beyond immediate neighborhood, and uses a Perceiver-style cross-attention bottleneck to efficiently integrate structural and temporal context. The model also features a flexible multi-task decoder enabling joint learning across diverse tasks without task-specific output heads. Experiments on RelBench, CTU, and SALT show RGP achieves state-of-the-art performance, with an average 2.2% improvement over RelGT on RelBench, and strong results on multi-class and ranking tasks. The method balances computational efficiency with modeling power, demonstrating effective multi-task learning.

## Method Summary
RGP processes heterogeneous temporal relational graphs by first tokenizing nodes via a multi-modal encoder (PyTorch Frame) with positional encodings (type, centrality, hop distance, relative time). Two parallel sampling streams retrieve context: (1) standard structural neighborhood sampling, and (2) a time-context sampler that selects edges based on temporal proximity to a reference timestamp regardless of graph connectivity. The encoder uses two parallel cross-attention branches to compress structural and temporal inputs into separate latent bottlenecks, which are fused and processed through self-attention layers. A task-conditioned decoder with text-encoded labels enables multi-task learning without task-specific heads, using dot-product similarity over label embeddings.

## Key Results
- RGP achieves state-of-the-art performance on RelBench, CTU, and SALT benchmarks
- Shows 2.2% average improvement over RelGT on RelBench
- Demonstrates effective multi-task learning across diverse tasks (AUC, F1, MRR) without task-specific output heads
- Ablation studies confirm temporal sampler provides 3% performance gain on rel-f1 dataset
- Cross-attention bottleneck is 2-6x more compute-efficient than full self-attention

## Why This Works (Mechanism)

### Mechanism 1: Temporal Context Sampling Extends Receptive Field Beyond Structural Neighborhoods
The temporal subgraph sampler retrieves nodes that are temporally proximate but structurally distant, providing contextual signals that standard neighborhood sampling misses. Given a reference timestamp t_seed, the sampler selects edges (and incident nodes) based on temporal closeness—either within a time window Δt or top-k nearest in time—independent of graph distance from the target node. This exposes the model to temporally co-occurring events (e.g., market shifts affecting multiple disconnected users). Core assumption: temporal proximity implies semantic relevance for prediction tasks, even without direct graph connectivity.

### Mechanism 2: Cross-Attention Bottleneck Enables Scalable Global Context Integration
The Perceiver-style latent bottleneck compresses heterogeneous node/edge information into fixed-size latent tokens, enabling global reasoning without quadratic self-attention cost. Learnable latent tokens Z_0 attend to all input node embeddings via cross-attention, then undergo L self-attention layers in latent space. Two parallel branches process structural and temporal contexts separately, then fuse via elementwise summation. Complexity scales as O(KN_g + LK²) where K ≪ N_g. Core assumption: a small number of latent tokens (K=8–32) can sufficiently represent the relevant information from large heterogeneous subgraphs.

### Mechanism 3: Task-Conditioned Decoder Enables Parameter-Efficient Multi-Task Learning
A shared decoder with task-conditioned queries and text-encoded label embeddings supports diverse tasks without task-specific output heads. Task embeddings q_task are derived from text descriptions via a pretrained language model. The query q_i = x_i + q_task attends to latent Z_out via cross-attention. Logits are computed via dot product with text-encoded labels E_label, using softmax and cross-entropy. Core assumption: text embeddings capture sufficient semantic structure for label spaces across disparate tasks; task descriptions provide discriminative conditioning.

## Foundational Learning

- **Cross-Attention vs. Self-Attention in Transformers**: RGP uses cross-attention to compress variable-length graph inputs into fixed latents. Understanding this distinction clarifies why the architecture achieves near-linear complexity. Quick check: Given input sequence length N and latent count K, what is the complexity of cross-attention vs. full self-attention?
- **Heterogeneous Temporal Graphs**: The paper models relational databases as graphs with multiple node/edge types and timestamps. This representation underpins the entire RDL framework. Quick check: How would you represent a foreign-key relationship between a "users" table and "sales" table with timestamps in this graph formulation?
- **Subgraph Sampling for Scalability**: Large relational graphs require sampling around target nodes. RGP introduces temporal sampling alongside structural sampling—understanding both is critical for implementation. Quick check: What is the difference between time-restricted neighborhood sampling (prior work) and the Time-Context Sampler introduced here?

## Architecture Onboarding

- **Component map**: Relational database → heterogeneous temporal graph → multi-modal encoder + positional encodings → dual sampler (structural + temporal) → parallel cross-attention branches → latent fusion → L self-attention layers → task-conditioned decoder with text-encoded labels
- **Critical path**: Implement multi-modal encoder for node tokenization (adapt from PyTorch Frame) → implement temporal sampler (edge scoring by |T_e - t_seed|, top-k or window selection) → implement Perceiver cross-attention encoder with dual branches → implement text-based decoder with task embeddings
- **Design tradeoffs**: Latent count K: Higher K improves capacity but increases compute (O(K²) self-attention). Paper finds optimal K varies by task; recommend tuning K ∈ {8, 16, 32}. Full self-attention vs. Perceiver: Self-attention may yield marginal accuracy gains on larger datasets but at 2–6x compute cost. Perceiver regularizes better on small datasets (rel-f1). Single-task vs. multi-task: Multi-task saves parameters but can fail under extreme label/sample imbalance. Consider task grouping by dataset.
- **Failure signatures**: Overfitting on small datasets with full self-attention: Use Perceiver bottleneck, reduce layers L. Multi-task degradation with imbalanced tasks: Normalize task losses, or fall back to single-task models. Temporal sampler adds noise: Disable for static datasets or domains where time is non-predictive. Cold-start nodes with no temporal history: Structural sampler alone insufficient; may need feature imputation or meta-learning.
- **First 3 experiments**: 1) Baseline replication: Run RGP on RelBench with default settings (K=16, L=4) to verify reported AUC values. Compare against RDL/RelGT baselines. 2) Ablation: Temporal sampler: Disable temporal sampler and measure performance drop on rel-f1 (cold-start-heavy) vs. rel-amazon (established entities). Expect larger degradation on rel-f1. 3) Multi-task vs. single-task: Train RGP jointly on all tasks within one dataset (e.g., rel-event). Compare per-task AUC against separately trained models. Analyze sample imbalance effects.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the multi-task decoder be modified to handle severe sample imbalance across tasks without degrading performance on smaller tasks?
- Basis in paper: [explicit] "we observed a notable drop in performance on the rel-f1 dataset under the multi-task setting. This can be attributed to the severe imbalance in the number of training samples across tasks: the driver-top3 task has only ∼1.5k samples, whereas driver-dnf has over 10k."
- Why unresolved: The paper diagnoses the imbalance problem but proposes no mitigation strategies or architectural modifications.
- What evidence would resolve it: Experiments comparing task-specific weighting, sampling strategies, or task-conditioned capacity allocation within the shared decoder.

### Open Question 2
- Question: Under what conditions do relational graph models like RGP outperform flattened tabular methods such as LightGBM on relational data?
- Basis in paper: [inferred] LightGBM outperforms RGP on 2 of 3 CTU tasks. The paper attributes this to datasets where "most predictive information is contained within a single table composed primarily of categorical and factual metadata."
- Why unresolved: The characterization remains qualitative; no formal criteria or dataset statistics predict when relational structure provides benefit.
- What evidence would resolve it: Systematic study varying relational complexity metrics (e.g., join depth, cross-entity dependency ratios) correlated with model performance gaps.

### Open Question 3
- Question: What is the optimal balance between temporal and structural sampling capacity, and does this balance vary by dataset characteristics?
- Basis in paper: [explicit] Ablation studies show removing temporal sampling causes a ~3% drop on rel-f1, but the relative contribution of each sampler across different datasets is not characterized.
- Why unresolved: The fixed allocation of latent tokens to each sampler branch is not ablated or adaptively tuned.
- What evidence would resolve it: Experiments with varying proportions of latent tokens allocated to temporal vs. structural branches, analyzed across datasets with different temporal correlation profiles.

## Limitations
- Temporal sampler criteria ("Temporal decay 0.1" and "Edges per type 10") lack complete clarity in the appendix
- Multi-task performance can degrade under severe label/sample imbalance, suggesting the approach may not generalize to all task distributions
- Text-based decoder assumes label spaces have meaningful semantic structure captured by embeddings, which may not hold for all relational learning tasks

## Confidence
- **High confidence**: The core architecture (dual cross-attention branches + latent bottleneck) is well-specified and the performance improvements are substantial and consistent across benchmarks
- **Medium confidence**: The efficacy of the temporal sampler is supported by ablation studies, but the specific selection criteria lack complete clarity in the appendix
- **Medium confidence**: The text-based multi-task decoder shows promise but has limited direct validation; its success may depend heavily on task description quality and label semantic similarity

## Next Checks
1. **Temporal Sampler Ablation**: Run RGP with temporal sampler disabled on both rel-f1 (cold-start heavy) and rel-amazon (established entities) to quantify the performance drop and verify the claimed 3% decline on rel-f1
2. **Self-Attention vs. Perceiver Efficiency**: Implement full self-attention baseline on RelBench to measure the actual compute savings (2-6x) and accuracy trade-offs across different latent counts K
3. **Multi-Task Under Imbalance**: Create controlled label/sample imbalance scenarios (e.g., 1:10 ratio) within a single dataset and test whether task loss normalization or single-task fallback is necessary for maintaining performance