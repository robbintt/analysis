---
ver: rpa2
title: 'From Macro to Micro: Probing Dataset Diversity in Language Model Fine-Tuning'
arxiv_id: '2505.24768'
source_url: https://arxiv.org/abs/2505.24768
tags:
- diversity
- dataset
- response
- instruction
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work systematically explores dataset diversity in language
  model fine-tuning by proposing a taxonomy across macro-, meso-, and microscopic
  levels for both instruction and response components. The authors construct fixed-size
  SFT datasets using six diversity-control strategies and fine-tune Llama models to
  evaluate their impact.
---

# From Macro to Micro: Probing Dataset Diversity in Language Model Fine-Tuning

## Quick Facts
- **arXiv ID**: 2505.24768
- **Source URL**: https://arxiv.org/abs/2505.24768
- **Reference count**: 40
- **Primary result**: Microscopic diversity strategy on responses shows strongest correlation between diversity and performance at maximum diversity

## Executive Summary
This work systematically explores dataset diversity in language model fine-tuning by proposing a taxonomy across macro-, meso-, and microscopic levels for both instruction and response components. The authors construct fixed-size SFT datasets using six diversity-control strategies and fine-tune Llama models to evaluate their impact. Results show that while macro- and mesoscopic strategies improve performance with increasing diversity, the microscopic strategy on responses demonstrates the strongest correlation between diversity and performance, achieving superior results at maximum diversity.

## Method Summary
The authors construct six diversity-control strategies across three levels (macro, meso, micro) for both instructions and responses from a 117K-sample corpus. For microscopic strategy, they identify mid-frequency tokens (10-500 occurrences) using the model's tokenizer, then apply inverse greedy pruning with token-aware sampling to construct diverse datasets. They create seven diversity levels (min to max) for each strategy, fine-tune Llama-2-7B models on 10K/20K/30K samples, and evaluate using automated pairwise scoring (Arena Hard + AlpopaEval 2.0) judged by Llama-3.1-70B-Nemotron. Multiple diversity metrics are tested to find the strongest estimator of performance correlation.

## Key Results
- Macro- and mesoscopic strategies show positive correlation between diversity and performance as diversity increases
- Microscopic strategy on responses achieves strongest diversity-performance correlation at maximum diversity
- Information entropy emerges as the strongest single estimator of diversity-performance correlation across strategies
- Results are robust across different model scales (7B vs 70B) and tokenization schemes (GPT-2 vs Llama)

## Why This Works (Mechanism)
The microscopic strategy's effectiveness stems from identifying and sampling tokens that appear neither too frequently (generic, uninformative) nor too rarely (noisy, unreliable) in the corpus. By focusing on mid-band tokens (10-500 occurrences) and using inverse greedy pruning with token-aware sampling, the method ensures coverage of diverse semantic concepts while maintaining sample quality. This approach directly addresses the fundamental tension in dataset construction between diversity and reliability, achieving superior performance by balancing these competing factors.

## Foundational Learning
- **HDBSCAN clustering**: Density-based clustering algorithm that handles noise and varying cluster densities; needed for macro/meso strategies to group similar samples. Quick check: Verify that clusters contain semantically coherent samples using manual inspection.
- **Token frequency bands**: Analysis of token occurrence distributions reveals three distinct frequency bands (low, mid, high); needed to identify informative tokens for microscopic strategy. Quick check: Plot token frequency histogram to confirm three-band structure.
- **Inverse greedy pruning**: Algorithm that iteratively selects samples to maximize diversity while maintaining coverage; needed for microscopic strategy implementation. Quick check: Verify that selected samples span diverse token combinations from mid-band.

## Architecture Onboarding
- **Component map**: Raw corpus -> Diversity control (Macro/Meso/Micro) -> Fixed-size subsets -> Model fine-tuning -> Automated evaluation
- **Critical path**: Corpus preparation → Token frequency analysis → Mid-band identification → Inverse greedy sampling → Model training → Performance evaluation
- **Design tradeoffs**: Fixed-size subsets vs. full corpus (computational efficiency vs. completeness), automated evaluation vs. human judgment (scalability vs. nuance), single diversity metric vs. multiple metrics (simplicity vs. robustness)
- **Failure signatures**: Using word segmentation instead of model tokenizer for microscopic strategy results in no positive correlation; including high/low-band tokens instead of mid-band produces weak correlation; response length confounds may create spurious correlations
- **3 first experiments**: 1) Run length-controlled ablation to verify diversity effect persists beyond length effects; 2) Test different token frequency band thresholds (5-100, 50-500, 100-1000) to verify 10-500 optimality; 3) Conduct human evaluation on subset of datasets to validate automated scoring alignment

## Open Questions the Paper Calls Out
None

## Limitations
- Microscopic strategy's effectiveness critically depends on identifying correct mid-band of token frequencies (10-500 occurrences), but paper doesn't fully justify why this range is optimal or how robust it is to different corpus sizes
- Response regeneration pipeline uses Llama-3.1-70B-Nemotron without detailed specification of prompts or filtering criteria, potentially introducing uncontrolled variability
- Study uses fixed-size subsets (10K/20K/30K) from 117K corpus but doesn't explore whether results generalize to larger datasets or different domain distributions
- Evaluation relies on automated pairwise scoring with Nemotron judge rather than human evaluation, which may not capture nuanced aspects of response quality or diversity

## Confidence
- **High confidence**: Macro- and mesoscopic strategies show positive correlation between diversity and performance as diversity increases
- **High confidence**: Microscopic strategy on responses achieves strongest diversity-performance correlation at maximum diversity
- **Medium confidence**: Information entropy is the strongest single estimator of diversity-performance correlation across strategies
- **Medium confidence**: Results are robust across different model scales (7B vs 70B) and tokenization schemes (GPT-2 vs Llama)

## Next Checks
1. Replicate the microscopic strategy ablation with different token frequency band thresholds (e.g., 5-100, 50-500, 100-1000) to verify that the 10-500 range is optimal and not an artifact of corpus size
2. Conduct human evaluation on a subset of datasets across diversity levels to validate that automated Nemotron scoring aligns with human judgments of quality and diversity
3. Test the diversity-control strategies on a different domain corpus (e.g., biomedical or legal texts) to assess generalizability beyond the general web text used in the original study