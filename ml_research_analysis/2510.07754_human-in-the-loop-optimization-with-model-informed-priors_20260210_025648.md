---
ver: rpa2
title: Human-in-the-Loop Optimization with Model-Informed Priors
arxiv_id: '2510.07754'
source_url: https://arxiv.org/abs/2510.07754
tags:
- user
- optimization
- users
- synthetic
- function
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces HOMI, a framework for human-in-the-loop optimization
  that leverages synthetic user models to pretrain optimizers, enabling faster adaptation
  without requiring real user data. To implement HOMI, the authors propose NAF+, a
  Bayesian optimization method with a neural acquisition function trained via reinforcement
  learning on large-scale synthetic data.
---

# Human-in-the-Loop Optimization with Model-Informed Priors

## Quick Facts
- arXiv ID: 2510.07754
- Source URL: https://arxiv.org/abs/2510.07754
- Reference count: 40
- Key outcome: HOMI framework uses synthetic data to pretrain optimizers for faster human-in-the-loop adaptation

## Executive Summary
This paper introduces HOMI, a human-in-the-loop optimization framework that leverages synthetic user models to pretrain optimizers, enabling faster adaptation without requiring real user data. The authors propose NAF+, a Bayesian optimization method with a neural acquisition function trained via reinforcement learning on large-scale synthetic data. Evaluated on mid-air keyboard adaptation in VR, NAF+ significantly outperformed standard Bayesian optimization and manual baselines, achieving optimal keyboard settings in fewer iterations.

## Method Summary
HOMI addresses the challenge of human-in-the-loop optimization by pretraining optimizers on synthetic user models, allowing rapid adaptation to real users. The core innovation is NAF+, which extends neural acquisition functions by incorporating reinforcement learning for training and adding a novelty detector to handle out-of-distribution users. The framework supports dynamic multi-objective weighting and demonstrates sample efficiency improvements over traditional Bayesian optimization methods. The approach shifts from per-user modeling to population-level meta-adaptation, offering a scalable solution for adaptive interface design.

## Key Results
- NAF+ achieved optimal keyboard settings in fewer iterations compared to standard Bayesian optimization and manual baselines
- Synthetic tests confirmed NAF+'s superior sample efficiency and robustness, especially for novel users
- The framework successfully handled dynamic objective trade-offs during the VR keyboard adaptation task

## Why This Works (Mechanism)
The framework's effectiveness stems from pretraining on synthetic data that captures population-level user behavior patterns. By learning from diverse synthetic scenarios, NAF+ develops robust optimization strategies that transfer effectively to real users. The novelty detector enables the system to identify when a user deviates significantly from the training distribution, allowing appropriate adaptation strategies. The reinforcement learning approach to training the neural acquisition function captures complex optimization patterns that traditional acquisition functions miss.

## Foundational Learning
- **Bayesian Optimization**: Why needed - provides principled framework for expensive black-box optimization; Quick check - verifies acquisition function properly balances exploration/exploitation
- **Reinforcement Learning**: Why needed - enables learning complex acquisition functions from experience; Quick check - confirms learned policy generalizes beyond training scenarios
- **Novelty Detection**: Why needed - identifies out-of-distribution users for appropriate handling; Quick check - tests detection accuracy across synthetic and real user distributions
- **Synthetic Data Generation**: Why needed - creates diverse training scenarios without real user data; Quick check - validates synthetic data covers real user behavior space
- **Multi-objective Optimization**: Why needed - balances competing interface design objectives; Quick check - confirms proper weighting across different optimization goals

## Architecture Onboarding

**Component Map:**
Synthetic Data Generator -> Pretraining Pipeline -> NAF+ Optimizer -> Novelty Detector -> Real User Interface

**Critical Path:**
1. Generate synthetic user models and data
2. Pretrain NAF+ acquisition function via reinforcement learning
3. Deploy with real user, using novelty detector for adaptation
4. Continuously optimize interface parameters

**Design Tradeoffs:**
- Pretraining vs. online learning: Prefers pretraining for sample efficiency but may miss user-specific nuances
- Synthetic data quality vs. quantity: More data improves generalization but increases computational cost
- Novelty detection sensitivity: Higher sensitivity catches more outliers but may trigger false positives
- Multi-objective weighting flexibility: Dynamic weighting adapts to user needs but adds optimization complexity

**Failure Signatures:**
- Poor convergence indicates inadequate synthetic data coverage
- High novelty detection rates suggest synthetic models poorly represent real users
- Oscillating parameters reveal unstable acquisition function
- Slow adaptation points to insufficient pretraining or poor transfer learning

**First Experiments:**
1. Test NAF+ on simple synthetic benchmark functions to verify basic optimization capability
2. Evaluate novelty detector performance on controlled distribution shifts
3. Compare convergence rates between pretrained and randomly initialized NAF+ on real user data

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on synthetic user data may not fully capture real-world human behavior complexity
- VR keyboard adaptation represents a narrow application domain with uncertain generalizability
- Computational overhead of pretraining NAF+ on large synthetic datasets may be prohibitive for resource-constrained settings

## Confidence

**High confidence in:**
- Technical implementation and synthetic test results

**Medium confidence in:**
- Real-world performance generalization across different interface domains
- Novelty detection mechanism's robustness in diverse scenarios

## Next Checks

1. Test HOMI across multiple interface domains (e.g., mobile UI layouts, accessibility settings) to assess generalizability
2. Conduct longitudinal studies with real users to evaluate performance degradation over extended adaptation periods
3. Compare computational efficiency and convergence rates against state-of-the-art Bayesian optimization methods on identical hardware configurations