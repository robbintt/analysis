---
ver: rpa2
title: 'Specialized text classification: an approach to classifying Open Banking transactions'
arxiv_id: '2504.12319'
source_url: https://arxiv.org/abs/2504.12319
tags:
- transaction
- data
- classification
- banking
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study developed a specialized text classification system for
  categorizing Open Banking transactions in the French context. The approach involved
  data collection, preprocessing (cleaning, human name anonymization, similarity filtering),
  rule-based labeling, and machine learning modeling using word n-grams or Word2Vec
  features with classifiers like Random Forest and Linear SVM.
---

# Specialized text classification: an approach to classifying Open Banking transactions

## Quick Facts
- arXiv ID: 2504.12319
- Source URL: https://arxiv.org/abs/2504.12319
- Authors: Duc Tuyen TA; Wajdi Ben Saad; Ji Young Oh
- Reference count: 6
- The study developed a specialized text classification system for categorizing Open Banking transactions in the French context, achieving weighted precision, recall, and F1 scores of up to 95% on 203,865 transactions across 84 categories.

## Executive Summary
This paper presents a specialized text classification system for categorizing Open Banking transactions in the French context. The approach involves data collection, preprocessing (cleaning, human name anonymization, similarity filtering), rule-based labeling, and machine learning modeling using word n-grams or Word2Vec features with classifiers like Random Forest and Linear SVM. The system achieves weighted precision, recall, and F1 scores of up to 95% on a dataset of 203,865 French banking transactions across 84 categories. The results demonstrate the effectiveness of tailored preprocessing and language-specific modeling for high-accuracy transaction classification in Open Banking environments.

## Method Summary
The method employs a comprehensive preprocessing pipeline including text cleaning (removing dates, card numbers, currency symbols), human name anonymization using French name dictionaries, and similarity filtering to handle short, domain-specific French text. A rule-based labeling system uses inclusive and exclusive keyword sets with transaction polarity (income vs. expense) to create labels, which are then manually validated. For modeling, the approach uses either TF-IDF n-grams with Linear SVM or Word2Vec embeddings with Random Forest classifiers. The Word2Vec model is trained on the in-domain corpus, with sequences padded to 14 tokens and dimensionality reduced via PCA.

## Key Results
- Achieved weighted precision, recall, and F1 scores of up to 95% on test data
- Random Forest with Word2Vec embeddings outperformed Linear SVM with TF-IDF n-grams (95% vs 84% precision)
- Per-category analysis revealed GROCERIES achieved 87% recall with 97% precision, while TRAVEL scored 81% recall

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Domain-specific preprocessing that removes non-semantic noise significantly improves classification of short banking text.
- Mechanism: Transaction descriptions contain structured noise (dates, masked card numbers, currency codes, locations, gender markers) that dilutes semantic signals. By stripping these elements and normalizing synonyms, the feature space focuses on merchant names and transaction types.
- Core assumption: The removed elements are truly non-predictive for the target categories.
- Evidence anchors: [abstract] "preprocessing steps such as text cleaning, human name anonymization, and similarity filtering"; [section III-B] Figure 1 illustrates step-by-step noise removal; [section III-B-1] five cleaning steps described.

### Mechanism 2
- Claim: Word2Vec embeddings with Random Forest capture semantic similarity in short transaction text better than n-gram TF-IDF alone.
- Mechanism: Transaction descriptions are brief (averaging ~14 tokens after padding). Word2Vec learned on the in-domain corpus captures merchant and category semantics.
- Core assumption: The in-domain Word2Vec corpus is sufficiently representative.
- Evidence anchors: [section IV-C-2] Table III shows Random Forest + Word2Vec achieves 95% precision vs. 84% for Linear SVM with same embeddings.

### Mechanism 3
- Claim: Rule-based labeling using keywords and transaction polarity enables scalable dataset creation without manual annotation.
- Mechanism: Each category is defined by inclusive and exclusive keyword sets. Transactions matching inclusive keywords receive labels, with transaction value sign as a constraint.
- Core assumption: Keyword rules have high precision; edge cases are caught in manual validation.
- Evidence anchors: [section III-C-2] "Each category is defined by a set of inclusive and exclusive keywords... The resulting labels are manually validated."

## Foundational Learning

- Concept: **TF-IDF Vectorization**
  - Why needed here: Transforms preprocessed transaction text into numerical features; used both for classification input and for scalable similarity detection
  - Quick check question: Can you explain why TF-IDF downweights common words like "carte" while emphasizing distinctive merchant names?

- Concept: **Multi-class vs. Pairwise Classification**
  - Why needed here: With 84 categories, pairwise SVM (84×83/2 = 3,486 classifiers) is impractical; multi-class reduces to single model
  - Quick check question: What is the computational complexity difference between one-vs-one and one-vs-rest strategies for 84 classes?

- Concept: **Class Imbalance Handling (Weighted Metrics)**
  - Why needed here: Dataset is heavily imbalanced (GROCERIES: 11,726 samples vs. ADVANCE SALARY: 11 samples); weighted averaging ensures metrics reflect real-world performance
  - Quick check question: Why would macro-average F1 be misleading for this dataset compared to weighted-average F1?

## Architecture Onboarding

- Component map:
Raw Transaction → [Text Cleaning] → [Name Anonymization] → [Similarity Filter] → [Feature Extraction]
                                                                                        ↓
                   [Rule-based Label] ←── Training only ──→ [TF-IDF N-grams OR Word2Vec]
                                                        ↓
                                              [Multi-class Classifier]
                                                        ↓
                                              Predicted Category (84 classes)

- Critical path:
  1. Preprocessing pipeline correctness (garbage in → garbage out)
  2. Name dictionary completeness for French names
  3. Feature extraction consistency between training and inference
  4. Rule-based label quality (upstream of model training)

- Design tradeoffs:
  - **TF-IDF + Linear SVM vs. Word2Vec + Random Forest**: Former is faster to train and more interpretable; latter achieves higher accuracy (95% vs. 94%) but requires embedding training
  - **Rule-based labeling vs. Manual annotation**: Rules scale but may introduce noise; manual annotation is gold standard but expensive at 200K+ samples
  - **Removing location data**: Improves generalization but may hurt location-dependent categories (TRAVEL: 89% F1, lowest among well-represented classes)

- Failure signatures:
  - GROCERIES misclassification (87% recall, 97% precision): False negatives suggest merchant name coverage gaps
  - CREDIT FEES (76% recall): Very low support (84 samples) causes embedding unreliability
  - TRAVEL (81% recall): Location removal may remove discriminative signal
  - Sudden accuracy drop on new merchants: Indicates embedding vocabulary gap

- First 3 experiments:
  1. **Baseline reproducibility**: Implement preprocessing + TF-IDF + Linear SVM pipeline; target ≥90% F1 on held-out test set with 50% training data
  2. **Ablation on preprocessing**: Remove name anonymization step; measure F1 degradation (hypothesis: >2% drop given >10% transactions contain names)
  3. **Embedding comparison**: Train Word2Vec on full corpus vs. use pre-trained French embeddings; compare Random Forest accuracy to quantify domain-specific corpus value

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does incorporating external merchant databases significantly improve classification accuracy for categories where semantic ambiguity is high, such as "Groceries"?
- Basis in paper: [explicit] The authors state in Section IV-C-2 that the classification of "Groceries" relies heavily on merchant names, resulting in relatively low performance, and they explicitly propose using external data like a merchant database as a "future solution."
- Why unresolved: The current study restricted features to the transaction text and Word2Vec embeddings derived solely from the internal dataset, without integrating third-party external data during the modeling phase.
- What evidence would resolve it: A comparative experiment showing F1-score improvements for merchant-dependent categories when the model is augmented with external business registry data or APIs (e.g., Google Places) versus the baseline.

### Open Question 2
- Question: How can the classification system adapt to evolving transaction types and descriptions over time without requiring extensive manual retraining?
- Basis in paper: [explicit] The conclusion notes that "further research and validation are necessary to address challenges such as... evolving transaction types."
- Why unresolved: The experiments were conducted on a static dataset spanning approximately one year; the paper does not propose or test mechanisms for handling temporal drift or the emergence of new, unseen transaction categories.
- What evidence would resolve it: A longitudinal study evaluating the model's performance decay over time and the effectiveness of online learning techniques or dynamic label updating rules.

### Open Question 3
- Question: To what extent does the rule-based labeling method introduce bias or noise compared to a fully human-annotated dataset?
- Basis in paper: [inferred] The authors utilize a rule-based method for labeling, which is manually validated (Section III-C-2). However, the paper does not quantify the error rate or subjectivity inherent in this heuristic approach compared to a "gold standard" ground truth.
- Why unresolved: There is no measurement provided of the noise level in the training data caused by potentially overlapping or imprecise keyword rules, which affects the trustworthiness of the reported 95% accuracy.
- What evidence would resolve it: An analysis of inter-annotator agreement between the rule-based labels and a purely human-annotated sample set, or a robustness test simulating label noise.

### Open Question 4
- Question: Can the proposed language-specific preprocessing pipeline be effectively transferred to other languages with different morphological structures?
- Basis in paper: [inferred] The paper emphasizes that the system is "specifically tailored to... the French context" and employs French-specific stop-word filtering and name dictionaries. It is unstated if this architecture is robust enough for non-French Open Banking data.
- Why unresolved: The preprocessing relies on French-specific logic (e.g., removing "cb" duplicates, French name dictionaries); the efficacy of this specific pipeline on languages with different compound word structures or named entity conventions is not demonstrated.
- What evidence would resolve it: Replicating the experiment on a multilingual dataset (e.g., English or Portuguese bank transactions) and reporting the degradation in performance or the effort required to adapt the anonymization modules.

## Limitations
- Proprietary French banking data not publicly available, making independent validation impossible
- Rule-based labeling system's precision and coverage not empirically verified
- Word2Vec embeddings trained on same corpus as evaluation, creating potential data leakage
- 84 category definitions and keyword rules not disclosed for assessment

## Confidence
- **High confidence**: Preprocessing methodology effectiveness - well-documented with specific implementation details
- **Medium confidence**: Word2Vec + Random Forest performance advantage over TF-IDF + Linear SVM - based on internal comparison but lacks ablation studies
- **Low confidence**: Real-world generalizability - results derived from a single French bank's transaction data without cross-institutional validation

## Next Checks
1. **Label quality audit**: Reconstruct the rule-based labeling system from paper description and measure precision/recall on a manually annotated sample of 1,000 transactions across all 84 categories
2. **Cross-institutional robustness test**: Train and evaluate the system on French banking transaction data from a different institution or time period to measure performance degradation
3. **Embedding data leakage assessment**: Split the corpus temporally (train Word2Vec on 2019-2020 data, evaluate on 2021 data) and measure accuracy drop to quantify overlap between training and test embeddings