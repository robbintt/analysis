---
ver: rpa2
title: 'When Pattern-by-Pattern Works: Theoretical and Empirical Insights for Logistic
  Models with Missing Values'
arxiv_id: '2507.13024'
source_url: https://arxiv.org/abs/2507.13024
tags:
- mice
- missing
- logistic
- mean
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of logistic regression with missing
  covariates, which is challenging because parameter estimation alone is insufficient
  for prediction on incomplete data. The authors introduce a Pattern-by-Pattern (PbP)
  strategy that learns one logistic model per missingness pattern, and prove it closely
  approximates Bayes probabilities under a Gaussian Pattern Mixture Model (GPMM) across
  MCAR, MAR, and MNAR settings.
---

# When Pattern-by-Pattern Works: Theoretical and Empirical Insights for Logistic Models with Missing Values

## Quick Facts
- **arXiv ID:** 2507.13024
- **Source URL:** https://arxiv.org/abs/2507.13024
- **Reference count:** 40
- **Primary result:** Pattern-by-Pattern logistic regression approximates Bayes probabilities under GPMM with bounded error, excelling at large sample sizes while mean imputation works best at small sample sizes

## Executive Summary
This paper addresses logistic regression with missing covariates by introducing a Pattern-by-Pattern (PbP) strategy that learns one logistic model per missingness pattern. The authors prove that under Gaussian Pattern Mixture Models, PbP closely approximates Bayes probabilities with bounded error of approximately 0.018. Their comprehensive empirical analysis across classification, probability estimation, calibration, and inference reveals that mean imputation serves as a strong baseline for small sample sizes, while PbP excels for large sample sizes. The best overall performance is achieved by non-linear multiple iterative imputation techniques (Random Forest MICE with response), though these are more computationally expensive. The paper also demonstrates that real-world missingness is highly concentrated in few patterns, making PbP computationally feasible in practice.

## Method Summary
The Pattern-by-Pattern approach splits the data by missingness pattern and fits a separate logistic regression model to each pattern with sufficient samples. During prediction, inputs are routed to their corresponding pattern-specific model. The method assumes data follows a Gaussian Pattern Mixture Model where X|M=m ~ N(μₘ, Σₘ), and proves this yields Bayes-optimal predictions when combined with per-pattern logistic models. For patterns with insufficient samples, the method falls back to mean imputation. The approach handles MCAR, MAR, and MNAR settings under GPMM assumptions, unlike many imputation methods restricted to MAR.

## Key Results
- PbP logistic regression approximates Bayes probabilities under GPMM with bounded error of approximately 0.018
- Mean imputation serves as a good baseline for low sample sizes (n < 5000), while PbP excels for large sample sizes
- Non-linear multiple iterative imputation (Random Forest MICE with response) achieves the best overall performance across various sample sizes
- Real-world missingness is highly concentrated, with 18 of 20 datasets having top-10 patterns covering over 80% of observations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** PbP logistic regression approximates Bayes probabilities under GPMM with bounded error of approximately 0.018
- **Mechanism:** Under GPMM, the Bayes predictor on each pattern m can be written as σ((α₀,m + αᵀₘx)/√(1 + (π/8)σ̃²ₘ)) plus approximation error. The scaling factor σ̃²ₘ captures variance from missing features integrated out; the probit-sigmoid approximation creates the small bounded error. This decomposition allows fitting separate logistic models per pattern that collectively approximate the global Bayes optimal predictor.
- **Core assumption:** Data follows GPMM (X|M=m ~ N(μₘ, Σₘ)) and Y|X follows a logistic model.
- **Break condition:** Non-Gaussian covariates or complex non-linear feature relationships.

### Mechanism 2
- **Claim:** Probit models remain exactly well-specified across missing patterns under GPMM.
- **Mechanism:** The key property is that E[Φ(t + Z)|X_obs = x] = Φ((t + μ)/√(1 + σ²)) when Z|X_obs ~ N(μ, σ²). Gaussian conditioning preserves normality, and the probit link Φ interacts cleanly with Gaussian integrals. This yields Probit models on each pattern with modified coefficients and variance-dependent scaling.
- **Core assumption:** Y|X follows a Probit model plus GPMM.
- **Break condition:** Logistic link doesn't have this exact property—only approximate.

### Mechanism 3
- **Claim:** Real-world missingness is concentrated in few patterns, making PbP computationally tractable.
- **Mechanism:** Missingness arises from structured causes (measurement protocols, survey designs, sensor configurations) rather than random independent processes. This creates highly concentrated pattern distributions where 10 patterns often cover >80% of observations.
- **Core assumption:** Missingness mechanisms have structured causes rather than fully independent sources.
- **Break condition:** Systems with many independent failure modes per sensor could approach worst-case.

## Foundational Learning

- **Concept: Missing Data Mechanisms (MCAR, MAR, MNAR)**
  - Why needed: Mechanism type determines which methods apply. PbP works across all three under GPMM; SAEM designed for MAR; many imputation methods assume MAR.
  - Quick check question: If sensor A fails more often when temperature (feature B) is high, what mechanism is this?

- **Concept: Bayes Predictor Decomposition**
  - Why needed: The Bayes probability η*(X̃) = Σₘ η*ₘ(X_obs(m))·1(M=m) motivates fitting separate models per pattern rather than seeking a single global model.
  - Quick check question: Why can't complete-case logistic regression coefficients predict on missing data?

- **Concept: Pattern Mixture Models vs. Selection Models**
  - Why needed: GPMM specifies X|M=m rather than M|X. This conditions on the pattern first, making per-pattern modeling natural.
  - Quick check question: In GPMM, do different patterns have different marginal distributions of X?

## Architecture Onboarding

- **Component map:** Data → Pattern analysis → Split by pattern → Fit logistic regression per pattern → Route prediction by pattern → Return probability
- **Critical path:** 1. Analyze pattern distribution (coverage by top-K patterns) → 2. Set minimum samples per pattern threshold → 3. Fit per-pattern models; use fallback for sparse patterns
- **Design tradeoffs:** Sample size vs. pattern specificity (PbP needs large n; Mean.IMP works at small n); Speed vs. accuracy (Mean.IMP ~0.3s, PbP ~4.5s, MICE.RF.Y ~500s at n=50,000); Interpretability (PbP cannot recover single β*; SAEM/MICE can)
- **Failure signatures:** Pattern explosion (>20 patterns each with <5% coverage); Non-Gaussian covariates with missing non-linear features; MNAR where SAEM is misspecified
- **First 3 experiments:** 1. Pattern coverage analysis: Count unique patterns; if top-10 < 80%, reconsider PbP; 2. Baseline: Run Mean.IMP.M as fast, consistent baseline across all settings; 3. Sample size sweep: Compare PbP vs. MICE.RF.Y at n=500, 5000, 50000 to identify crossover point

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the relative performance of PbP versus MICE.RF.Y change as a function of the degree of feature non-linearity and sample size?
- **Basis in paper:** The authors show MICE.RF.Y outperforms PbP when features are non-linear (Section 5.4) and state "PbP is the most promising method for GPMM" but recommend "nonlinear iterative technique in the presence of non-linear features" without delineating the transition boundary between regimes.
- **Why unresolved:** The simulation only uses one configuration of non-linear transformations; the interaction between non-linearity magnitude, dimension, and sample size on method choice remains uncharted.
- **What evidence would resolve it:** A systematic study varying the strength and type of non-linearity across sample sizes, measuring the sample size at which PbP becomes competitive with or superior to MICE.RF.Y for each non-linearity level.

### Open Question 2
- **Question:** Can the theoretical approximation bound (∥ε∥∞ ≃ 0.018) be tightened or extended to quantify performance gaps under different covariance structures or missingness patterns?
- **Basis in paper:** Theorem 3.5 provides a universal bound based on the probit-logistic approximation, but the empirical performance varies across MNAR vs. MCAR and across patterns within a simulation, suggesting the bound does not capture all relevant factors.
- **Why unresolved:** The bound is derived for the logistic-probit difference and does not incorporate the variance terms (σ̃²_m) or the covariance structure, which affect the actual error in practice.
- **What evidence would resolve it:** Deriving pattern-specific or covariance-dependent bounds and validating them against the per-pattern probability estimation errors observed in simulations.

### Open Question 3
- **Question:** Why does adding the missingness mask after imputation deteriorate performance on many real-world datasets, contrary to the benefit seen in some simulations?
- **Basis in paper:** The authors note that in real datasets, "adding a missingness mask after imputation is often detrimental," whereas in simulations (e.g., MNAR) adding the mask improves MICE performance. This discrepancy is observed but not explained.
- **Why unresolved:** The mechanism—whether due to overfitting, violation of assumptions, or the nature of real missingness—is not investigated; the result is purely empirical.
- **What evidence would resolve it:** An analysis of the correlation between mask informativeness, sample size, and the impact of mask inclusion across both simulated and real datasets, potentially including ablations where the mask is included in training but not in the imputation model.

## Limitations
- Theoretical guarantees assume Gaussian Pattern Mixture Models, which may not hold in practice with non-Gaussian covariates or complex interactions
- The 0.018 bound on approximation error is derived for Probit models; the logistic case only achieves approximation
- Computational feasibility of PbP depends on pattern concentration, which may not hold in systems with many independent failure modes

## Confidence
- **High confidence:** PbP performance superiority at large sample sizes, PbP computational tractability in real datasets (18/20 datasets with top-10 patterns covering >80% of observations)
- **Medium confidence:** Theoretical approximation bounds under GPMM assumptions, PbP performance relative to advanced imputation methods across all sample sizes
- **Low confidence:** Generalization to non-Gaussian covariates beyond the exponential simulation, PbP performance in extremely high-dimensional settings (d > 50)

## Next Checks
1. **Pattern coverage analysis:** Before applying PbP, compute the fraction of observations covered by the top-K patterns (K=10) to ensure computational feasibility
2. **Distribution check:** Verify approximate normality of covariates within each missingness pattern to validate GPMM assumptions
3. **Cross-method consistency:** Run PbP alongside Mean.IMP.M as baseline across sample sizes n ∈ {500, 5000, 50000} to identify crossover points in performance