---
ver: rpa2
title: 'Realistic threat perception drives intergroup conflict: A causal, dynamic
  analysis using generative-agent simulations'
arxiv_id: '2512.17066'
source_url: https://arxiv.org/abs/2512.17066
tags:
- threat
- symbolic
- realistic
- group
- hostility
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study used large language model (LLM)-driven agent simulations
  to examine how realistic and symbolic threats drive intergroup conflict. Agents
  were divided into minimal groups and exposed to experimentally manipulated threats
  while their behavior, language, and attitudes were tracked.
---

# Realistic threat perception drives intergroup conflict: A causal, dynamic analysis using generative-agent simulations

## Quick Facts
- arXiv ID: 2512.17066
- Source URL: https://arxiv.org/abs/2512.17066
- Reference count: 40
- Key outcome: Realistic threat perception directly increased hostility more strongly than symbolic threat, which only increased hostility when realistic threat was absent and its effects were fully mediated by ingroup bias.

## Executive Summary
This study used large language model (LLM)-driven agent simulations to examine how realistic and symbolic threats drive intergroup conflict. Agents were divided into minimal groups and exposed to experimentally manipulated threats while their behavior, language, and attitudes were tracked. Results showed that realistic threat perception directly increased hostility more strongly than symbolic threat, which only increased hostility when realistic threat was absent and its effects were fully mediated by ingroup bias. Symbolic threat increased ingroup bias but did not directly drive hostile actions. Non-hostile intergroup contact spontaneously reduced conflict, and structural factors like segregation concentrated hostility among majority groups. Representational analyses confirmed distinct internal states for realistic threat, symbolic threat, and hostility, and causal manipulation of these states influenced behavior. The findings support a context-sensitive model where realistic threat dominates behavioral escalation while symbolic threat primarily shapes attitudes.

## Method Summary
The study used 25 LLM-driven generative agents based on the Park et al. (2023) framework, simulating a virtual town over three days. Agents were assigned minimal group identities and exposed to belief statements injecting realistic threat, symbolic threat, both, or neither. The simulation ran 10 times per condition using the matatonic/Mistral-Small-24B-Instruct model. Hourly behaviors, conversations, and attitudinal probes were logged. Hostile actions were classified using LLM classifiers. Activation vectors were extracted from the model's residual stream to validate threat and hostility representations. Mixed-effects negative binomial models analyzed behavioral outcomes, while Bayesian mediation analysis examined indirect effects through ingroup bias.

## Key Results
- Realistic threat perception directly increased hostile outgroup behavior with large effect sizes (Cohen's d = 3.89 vs. no-threat)
- Symbolic threat increased ingroup bias but only increased hostility when realistic threat was absent, with effects fully mediated by bias
- Non-hostile intergroup contact spontaneously reduced subsequent hostility regardless of threat condition
- Structural factors like segregation concentrated hostility among majority groups (interaction β̂ = 1.03)

## Why This Works (Mechanism)

### Mechanism 1: Realistic Threat → Direct Hostility Pathway
- Claim: Realistic threat perception directly increases hostile outgroup behavior without requiring attitudinal mediation.
- Mechanism: Experimental manipulation injects belief statements into agent memory streams, activating a realistic-threat internal state vector that strongly loads onto a hostility vector (Cohen's d = 3.89), producing hostile actions.
- Core assumption: The LLM's threat→hostility activation cascade approximates human threat-response circuitry; this is only claimed within the simulation context.
- Evidence anchors:
  - [abstract] "realistic threat perception directly increased hostility more strongly than symbolic threat"
  - [section] β̂ = 0.33, p < .001 for realistic threat predicting hostile action rate (Table 2); hostility vector steering increased hostile behavior (d = 5.22)
- Break condition: If LLM priors suppress hostility expression (e.g., ChatGPT/Claude), the cascade may not activate. Paper notes Mistral was chosen specifically because larger models suppressed hostility entirely.

### Mechanism 2: Symbolic Threat → Ingroup Bias → Hostility (Mediated Pathway)
- Claim: Symbolic threat primarily increases ingroup bias, which then predicts hostile actions; direct effects on behavior are minimal or absent.
- Mechanism: Symbolic threat manipulation activates a distinct symbolic-threat vector (separable from realistic threat, d = 3.95 contrast). This shifts attitudinal probes (ingroup bias β̂ = 0.39, p < .001). Bayesian mediation shows the indirect path through bias is credible (β̂indirect = 0.09, CrI [0.02, 0.18]), while the direct path to hostility is near zero (β̂direct = −0.00, CrI [−0.21, 0.21]).
- Core assumption: Attitudinal probe responses reflect persistent internal states rather than context-specific completions.
- Evidence anchors:
  - [abstract] "symbolic threat... effects were fully mediated by ingroup bias and increase hostility only when realistic threat was absent"
  - [section] Figure 5 mediation paths; Table B21 shows symbolic direct effect near zero
- Break condition: If ingroup bias does not persist across time steps (lagged β̂ = 0.12, p < .001 suggests it does), the mediated pathway would weaken.

### Mechanism 3: Non-Hostile Intergroup Contact as Emergent Buffer
- Claim: Spontaneous non-hostile intergroup contact reduces subsequent hostility regardless of threat condition.
- Mechanism: When agents engage in intergroup interactions without hostility, subsequent hostile action rates drop (β̂ = −0.46, p < .001). This emerged autonomously; contact rate was not predicted by threat condition.
- Core assumption: The simulation's spatial environment allows sufficient contact opportunities; structural segregation reduces this buffer.
- Evidence anchors:
  - [abstract] "Non-hostile intergroup contact spontaneously reduced conflict"
  - [section] Table 2 lagged intergroup contact rate; segregation reduced overall contact
- Break condition: If segregation or majority-minority asymmetry strongly reduces contact opportunities, the buffer weakens (segregation × majority interaction β̂ = 1.03 concentrated hostility in majority groups).

## Foundational Learning

- Concept: Integrated Threat Theory (ITT) distinction between realistic vs. symbolic threat
  - Why needed here: The entire experimental design and interpretation depends on distinguishing threats to material conditions vs. threats to values/identity.
  - Quick check question: Can you explain why symbolic threat required ingroup bias mediation while realistic threat operated directly?

- Concept: LLM residual-stream activations and concept vectors
  - Why needed here: The paper extracts "threat vectors" and "hostility vectors" from layer-wise activations; understanding this is essential for the representational analysis.
  - Quick check question: Why did threat separability increase in later layers rather than earlier layers?

- Concept: Bayesian mediation analysis with multilevel structure
  - Why needed here: The key claim about symbolic threat mediation relies on brms models with credible intervals, not NHST p-values.
  - Quick check question: What does it mean when the direct effect credible interval crosses zero but the indirect effect does not?

## Architecture Onboarding

- Component map:
  - Generative-agent core (Park et al. adaptation) -> Threat injection module -> Runtime probing module -> Activation extraction -> Steering module -> Text classifiers

- Critical path:
  1. Initialize agents → assign minimal groups → inject threat beliefs
  2. Run 3-day simulation (72 simulated hours, ~2,400 GPU hours per main set)
  3. Log actions, conversations, probe responses hourly
  4. Extract activations, validate threat vectors on held-out vignettes
  5. Fit mixed-effects negative binomial models (hostility) and Gaussian models (attitudes)
  6. Run Bayesian mediation via brms

- Design tradeoffs:
  - **Mistral vs. aligned models**: Mistral allows hostility emergence; ChatGPT/Claude suppress it. Tradeoff: less safety alignment vs. ecological validity for conflict research.
  - **Minimal groups vs. real identities**: Minimal groups avoid stereotype confounds but may reduce symbolic threat salience.
  - **3-day window**: Captures dynamics but may miss longer-term resolution or entrenchment.

- Failure signatures:
  - **Steering degradation**: At α > 5, outputs become incoherent (repetition, topic drift; see Table D50)
  - **Hostility suppression**: If model is too aligned, all hostile actions → 0 regardless of manipulation
  - **Contact collapse**: Under high segregation + majority-minority, intergroup contact may approach zero, eliminating the buffer

- First 3 experiments:
  1. Replicate with a different LLM backbone (e.g., Llama 3) to test whether threat→hostility cascade generalizes or is Mistral-specific.
  2. Extend simulation to 7 days to observe whether hostility decays, stabilizes, or escalates.
  3. Add an intervention condition where non-hostile contact is actively facilitated (e.g., shared public events) to test causal impact of contact rather than relying on spontaneous emergence.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the dominance of realistic threat over symbolic threat persist when using richer identity structures and elaborate social histories?
- Basis in paper: [explicit] The authors state, "Future work should test whether richer identity structures and more elaborate social histories change the balance between realistic and symbolic threat."
- Why unresolved: Current findings rely on minimal groups with weak self-concepts, which may dampen symbolic threat effects relative to realistic threats compared to real-world identities.
- What evidence would resolve it: Replicating the simulation with agents possessing deep, historically grounded real-world group identities.

### Open Question 2
- Question: How do institutional contexts and extended time horizons shape the emergence and resolution of threat-driven conflict?
- Basis in paper: [explicit] The paper notes, "Future studies should explore how variations in... simulation length, or institutional context affect the emergence and resolution of threat-driven conflict."
- Why unresolved: The current study was limited to a three-day window and a specific town structure without modeling institutional enforcement or governance.
- What evidence would resolve it: Experiments varying environmental rules (e.g., policing, governance) and running simulations for protracted durations to observe resolution patterns.

### Open Question 3
- Question: Do the causal mechanisms identified in simulations generalize to human populations through triangulation with field data?
- Basis in paper: [explicit] The authors propose, "A natural next step is triangulation... testing whether comparable qualitative and quantitative patterns emerge in the corresponding field data."
- Why unresolved: LLM-based agents embed WEIRD biases, and simulation dynamics may not perfectly map onto human behavior outside the computational environment.
- What evidence would resolve it: Field studies comparing simulation trajectories against real-world conflict data in structurally matched settings.

## Limitations
- The study relies on a specific LLM (Mistral) chosen for its willingness to express hostility, raising questions about generalizability across models with different safety alignments
- The minimal group paradigm may not fully capture the complexity of real-world symbolic threats, potentially underestimating symbolic threat effects
- The simulation's spatial structure and contact opportunities are simplified, limiting ecological validity for understanding structural factors like segregation

## Confidence
- **High confidence:** Realistic threat directly increases hostile behavior (supported by strong effect sizes and behavioral measurement); non-hostile contact reduces conflict (emerged spontaneously across conditions)
- **Medium confidence:** Symbolic threat effects are fully mediated by ingroup bias (Bayesian mediation credible intervals support this, but alternative causal structures cannot be ruled out); structural factors concentrate hostility in majority groups (observed pattern but limited structural variation in design)
- **Low confidence:** Generalizability of threat representations across different LLM architectures (tested only with Mistral); persistence of simulated conflict patterns over longer timescales (limited to 3 days)

## Next Checks
1. Replicate the core threat manipulation effects using a different LLM backbone (e.g., Llama 3) to test whether the realistic threat→hostility cascade generalizes beyond Mistral-specific priors
2. Extend simulations to 7 days to examine whether hostility decays, stabilizes, or escalates over longer timeframes, and whether contact buffers persist
3. Add an intervention condition where non-hostile intergroup contact is actively facilitated (e.g., shared public events) rather than relying on spontaneous emergence, to test causal impact of contact opportunities