---
ver: rpa2
title: Differentiable Adversarial Attacks for Marked Temporal Point Processes
arxiv_id: '2501.10606'
source_url: https://arxiv.org/abs/2501.10606
tags:
- adversarial
- event
- noise
- time
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of designing adversarial attacks
  for marked temporal point processes (MTPPs), a powerful model for continuous-time
  event sequences. The key difficulty lies in generating imperceptible perturbations
  that can effectively degrade model performance, due to the sequential nature of
  temporal data and the complex relationship between noise and distance metrics.
---

# Differentiable Adversarial Attacks for Marked Temporal Point Processes

## Quick Facts
- arXiv ID: 2501.10606
- Source URL: https://arxiv.org/abs/2501.10606
- Authors: Pritish Chakraborty; Vinayak Gupta; Rahul R; Srikanta J. Bedathur; Abir De
- Reference count: 11
- Key outcome: PERMTPP achieves up to 50% improvement in mark prediction accuracy and substantial increases in mean absolute error over existing adversarial attack methods for marked temporal point processes

## Executive Summary
This paper addresses the challenge of designing adversarial attacks for marked temporal point processes (MTPPs), a powerful model for continuous-time event sequences. The key difficulty lies in generating imperceptible perturbations that can effectively degrade model performance, due to the sequential nature of temporal data and the complex relationship between noise and distance metrics. The authors propose PERMTPP, a novel differentiable adversarial attack framework that overcomes these challenges through a two-stage approach. First, they employ a Gumbel-Sinkhorn network to learn a soft permutation matrix that reorders events while maintaining differentiability. Then, they add temporal noise to the permuted sequence, constrained to preserve the event order. This approach allows for controlled perturbation generation while maintaining the ability to optimize the adversarial objective.

## Method Summary
The PERMTPP framework introduces a differentiable adversarial attack method for marked temporal point processes through a two-stage process. First, it employs a Gumbel-Sinkhorn network to learn a soft permutation matrix that reorders events while maintaining differentiability. This permutation stage addresses the challenge of optimizing over discrete event orderings. Second, the framework adds temporal noise to the permuted sequence, constrained to preserve the event order. This constrained perturbation ensures that the generated adversarial examples remain imperceptibly close to the original sequences while effectively degrading model performance. The differentiable architecture enables end-to-end optimization of the adversarial objective through gradient-based methods.

## Key Results
- PERMTPP achieves up to 50% improvement in mark prediction accuracy over existing adversarial attack methods
- The framework substantially increases mean absolute error in model predictions across four real-world datasets
- PERMTPP demonstrates strong defensive capabilities when used for adversarial training, providing robustness against various attack strategies

## Why This Works (Mechanism)
The framework works by decoupling the adversarial perturbation problem into two differentiable stages. The Gumbel-Sinkhorn network provides a continuous relaxation of the discrete permutation operation, enabling gradient-based optimization over event orderings. By learning to reorder events before adding noise, the method can more effectively degrade model performance while maintaining the temporal structure necessary for imperceptibility. The constrained temporal noise ensures that perturbations remain small in magnitude while being strategically placed to maximize their adversarial impact.

## Foundational Learning

**Gumbel-Sinkhorn Relaxation**
- Why needed: Provides differentiable approximation of discrete permutations
- Quick check: Verify that temperature parameter annealing converges to near-binary permutation matrices

**Temporal Point Process Modeling**
- Why needed: Understanding continuous-time event sequences and their likelihood functions
- Quick check: Confirm that intensity functions are correctly implemented for the specific MTPP variants used

**Adversarial Objective Design**
- Why needed: Crafting loss functions that balance attack effectiveness with imperceptibility
- Quick check: Ensure that distance metrics properly capture temporal similarity while adversarial losses target model degradation

## Architecture Onboarding

**Component Map**
Gumbel-Sinkhorn Network -> Permutation Layer -> Temporal Noise Injection -> MTPP Model -> Adversarial Loss

**Critical Path**
The critical path flows from the Gumbel-Sinkhorn network through permutation to noise injection, where the differentiable operations enable gradient flow back to the parameters controlling the attack generation.

**Design Tradeoffs**
- Soft permutations vs. hard permutations: The relaxation enables differentiability but introduces approximation error
- Noise magnitude vs. imperceptibility: Larger perturbations are more effective but risk detection
- Computational cost vs. attack quality: The two-stage approach is more expensive but produces superior results

**Failure Signatures**
- Poor convergence of Gumbel-Sinkhorn: May indicate inappropriate temperature scheduling or insufficient model capacity
- Ineffective attacks despite optimization: Could suggest that the temporal noise constraints are too restrictive
- High computational cost: May require optimization of the permutation computation or batching strategy

**First 3 Experiments**
1. Validate permutation quality by comparing soft permutation outputs to optimal hard permutations on small sequences
2. Test attack effectiveness on a simple MTPP variant before scaling to complex datasets
3. Benchmark computational efficiency against baseline attack methods on sequences of increasing length

## Open Questions the Paper Calls Out

None

## Limitations

- The Gumbel-Sinkhorn relaxation may introduce approximation errors that could affect attack quality in high-dimensional temporal spaces
- Performance on extremely sparse or bursty event sequences remains unexplored, as experiments focus on relatively dense temporal patterns
- Computational complexity of the two-stage approach may limit applicability to very long sequences or real-time attack scenarios

## Confidence

- **High Confidence**: The empirical superiority of PERMTPP over existing baselines (50% improvement claims) is well-supported by experimental results across multiple datasets
- **Medium Confidence**: The claim that differentiable architecture enables effective adversarial training for robustness is supported but would benefit from longer-term stability tests and broader attack scenario evaluations
- **Medium Confidence**: The assertion that temporal noise constrained by permutation maintains imperceptibility is theoretically sound but requires more rigorous perceptual studies

## Next Checks

1. Evaluate PERMTPP's performance against adaptive defenses specifically designed to counter permutation-based attacks, including detection mechanisms that identify reordered sequences

2. Assess the framework's computational efficiency and attack quality on sequences with significantly longer time horizons (e.g., thousands of events) compared to current experimental setup

3. Validate whether the temporal noise constraint is optimal by comparing against alternative perturbation strategies, such as mark-space attacks or hybrid approaches that combine multiple perturbation dimensions