---
ver: rpa2
title: 'JSON-Bag: A generic game trajectory representation'
arxiv_id: '2508.00712'
source_url: https://arxiv.org/abs/2508.00712
tags:
- game
- json-bag
- games
- distance
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces JSON-Bag, a generic representation for game
  trajectories using JSON tokenization and Jensen-Shannon distance for similarity
  measurement. The method tokenizes JSON descriptions of game states and interprets
  token frequencies as probability distributions.
---

# JSON-Bag: A generic game trajectory representation

## Quick Facts
- arXiv ID: 2508.00712
- Source URL: https://arxiv.org/abs/2508.00712
- Authors: Dien Nguyen; Diego Perez-Liebana; Simon Lucas
- Reference count: 29
- The method tokenizes JSON descriptions of game states and interprets token frequencies as probability distributions.

## Executive Summary
This paper introduces JSON-Bag, a generic representation for game trajectories that tokenizes JSON descriptions of game states and interprets token frequencies as probability distributions. The approach uses Jensen-Shannon distance to measure similarity between trajectories and was evaluated across six tabletop games for three classification tasks (agents, parameters, seeds). The method demonstrated strong performance compared to hand-crafted features, particularly when combined with Random Forest classifiers that can learn complex feature interactions. JSON-Bag also showed high correlation between its distance metric and actual agent policy differences, suggesting it captures meaningful behavioral distinctions.

## Method Summary
JSON-Bag represents game trajectories by flattening nested JSON game states into path-based tokens (e.g., ".playerResources[0].Wood.2") and aggregating these into frequency distributions. These token counts are normalized to create probability distributions, which are then compared using Jensen-Shannon Distance (JSD) for similarity measurement. The method supports two classification approaches: Prototype-based Nearest Neighbor Search (P-NNS) that compares entire distributions, and Random Forest that treats individual tokens as features to learn complex interactions. The approach was evaluated on 500 trajectories per class across six tabletop games, with game-specific tokenization modes (ordered/unordered/both) determined by the game's structural characteristics.

## Key Results
- JSON-Bag with P-NNS outperformed hand-crafted features in most classification tasks, particularly for rich games like 7 Wonders and Pandemic
- Random Forest significantly improved accuracy on sparse games (Connect4, Dots and Boxes) where P-NNS underperformed, demonstrating automatic feature extraction capability
- JSON-Bag prototype distances showed strong correlation (0.62-0.97 Pearson) with actual agent policy differences across games
- The method proved highly sample-efficient, achieving good accuracy with only 3-5 shots per class for obvious classification tasks

## Why This Works (Mechanism)

### Mechanism 1
Flattening nested game states into path-based tokens preserves structural frequency information sufficient for distinguishing trajectory classes. The architecture serializes JSON game states into atomic "tokens" comprising the full path rather than just values. By aggregating these into a "bag," the model captures the distribution of game events without requiring explicit temporal indexing. The frequency of specific state components correlates strongly with the causal factors generating the trajectory (agent type, seed, or parameters). This works well for rich games but fails on sparse games where insufficient token diversity causes distinct trajectories to collapse into similar bags.

### Mechanism 2
Interpreting token frequencies as probability distributions allows Jensen-Shannon Distance (JSD) to effectively measure behavioral similarity. Normalizing token counts creates a probability distribution per trajectory, and JSD measures similarity between these distributions by comparing them to their mean. This handles the high-dimensional, sparse nature of token vectors better than Euclidean distance by measuring relative entropy rather than absolute geometric distance. Game playing styles manifest as statistically distinguishable distributions over state tokens, though JSD fails when distinct agents generate identical state frequencies.

### Mechanism 3
Random Forest (RF) classifiers can recover complex feature interactions from the flat token representation that Prototype-based Nearest Neighbor Search (P-NNS) misses. While P-NNS compares entire distributions, RF treats individual token frequencies as independent features and constructs decision trees that can isolate specific diagnostic tokens and learn non-linear interactions. The discriminative signal for a specific class is localized in a subset of tokens or their interactions rather than the global distribution shape. This automatic feature extraction capability significantly improves performance on sparse games where P-NNS fails due to lack of sufficient distributional differences.

## Foundational Learning

- **Concept: Bag-of-Words (BoW) & Vector Space Models**
  - Why needed here: JSON-Bag is a direct adaptation of NLP BoW models. Understanding that BoW discards word order but preserves frequency is critical to understanding why temporal dynamics are lost but statistical "style" is retained.
  - Quick check question: If a game trajectory is shuffled, would the JSON-Bag representation change? (Answer: No, unless intermediate states change).

- **Concept: Jensen-Shans Divergence (JSD)**
  - Why needed here: This is the core distance metric. Unlike Euclidean distance, JSD is grounded in Information Theory (Entropy). One must understand it compares probability distributions and is symmetric (unlike KL Divergence).
  - Quick check question: Why is JSD preferred over Kullback-Leibler (KL) divergence for this task? (Answer: JSD is symmetric and bounded, making it a true metric suitable for distance comparison).

- **Concept: Prototype-based Classification**
  - Why needed here: The paper uses P-NNS as a primary baseline. This involves averaging all samples of a class into a single "prototype" vector. This is distinct from K-Nearest Neighbors (KNN) which compares to individual samples.
  - Quick check question: Does P-NNS require storing the entire training dataset in memory during inference? (Answer: No, only the class prototypes are needed).

## Architecture Onboarding

- **Component map:** Game Engine -> Serializer -> Tokenizer -> Vectorizer -> Normalizer -> Comparator
- **Critical path:** The Tokenization Strategy. Deciding between ordered (`.list[0]`) vs unordered (`.list`) tokenization determines if the model captures player-index specific behaviors or just global resource availability.
- **Design tradeoffs:** P-NNS is sample-efficient (fast, few shots) but struggles with sparse games. RF requires more data/tuning but recovers complex interactions. A generic tokenizer works across games but may be outperformed by domain-specific hand-crafted features in simple games.
- **Failure signatures:** Sparse games result in low-entropy bags where differences are negligible. Data leakage occurs when variables explicitly defining the class must be excluded from serialization. Tokenizing grid coordinates as separate features prevents learning spatial patterns.
- **First 3 experiments:**
  1. Implement the tokenizer on a minimal game state (e.g., Tic-Tac-Toe). Verify that distinct states produce distinct token sets and that normalization works correctly.
  2. Replicate the P-NNS + JSD experiment on one "rich" game (e.g., 7 Wonders Agent classification) to verify the high accuracy claim.
  3. Run P-NNS on a "sparse" game (e.g., Dots and Boxes) followed by RF. Confirm that RF accuracy significantly exceeds P-NNS, validating the automatic feature extraction mechanism.

## Open Questions the Paper Calls Out

- Can the JSON-Bag representation be effectively applied to real-time video games with continuous state spaces? The authors state that immediate future work requires extending the types of games tested "beyond turn-based tabletop games" to understand the approach's limitations.

- Does refining tokenization to preserve spatial locality improve performance in grid-based games? The authors note the method struggles with games dependent on spatial relations and suggest refining tokenization, such as pairing x and y coordinates rather than separating them.

- Why does Normalized Compression Distance (NCD) fail on JSON game trajectories where token-frequency methods succeed? The authors list analyzing "how to get NCD working and/or why it fails" as a specific direction for future work after it performed inconsistently.

## Limitations
- The method depends critically on sufficient structural diversity within JSON-serialized game states, failing on "sparse" games with limited unique components
- Careful preprocessing is required to avoid data leakage by excluding variables that explicitly encode the classification target
- The bag-of-words approach discards temporal and spatial information, limiting effectiveness for games where timing and spatial relationships matter significantly

## Confidence
- **High Confidence:** JSON-Bag preserves sufficient structural frequency information to distinguish agent types in resource-rich games; Jensen-Shannon Distance effectively measures similarity between token frequency distributions; Random Forest recovers complex feature interactions that P-NNS misses
- **Medium Confidence:** The method demonstrates strong sample efficiency for obvious classification tasks; high correlation exists between JSON-Bag distances and agent policy differences; the approach generalizes across diverse game mechanics
- **Low Confidence:** JSON-Bag consistently outperforms hand-crafted features across all game types; the method maintains effectiveness when scaled to 100+ classes or significantly larger state spaces; performance remains stable when applied to non-turn-based or real-time games

## Next Checks
1. **Robustness to State Space Size:** Evaluate JSON-Bag on games with 10x-100x larger state spaces (e.g., Go, complex RTS games) to test scalability limits and identify when token frequency distributions become too sparse for effective discrimination.

2. **Temporal Information Preservation:** Implement a modified version that preserves sequential information (e.g., n-gram tokenization of token sequences) and compare classification performance on games where timing and order of actions matter significantly.

3. **Cross-Domain Generalization:** Apply the JSON-Bag approach to non-game domains such as financial transaction sequences or biological pathway data to assess whether the method's success depends on specific game-like properties or represents a more general trajectory representation technique.