---
ver: rpa2
title: 'UPRPRC: Unified Pipeline for Reproducing Parallel Resources -- Corpus from
  the United Nations'
arxiv_id: '2509.15789'
source_url: https://arxiv.org/abs/2509.15789
tags:
- corpus
- alignment
- parallel
- paragraph
- english
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work presents a fully reproducible end-to-end pipeline for\
  \ constructing large-scale parallel corpora from United Nations documents, addressing\
  \ challenges of transparency, scalability, and alignment accuracy. The core innovation\
  \ is a Graph-Aided Paragraph Alignment (GAPA) algorithm that enables flexible M\u2013\
  N paragraph-level mapping via bipartite graph construction and Longest Common Subsequence\
  \ (LCS) detection, outperforming traditional sentence-level approaches."
---

# UPRPRC: Unified Pipeline for Reproducing Parallel Resources -- Corpus from the United Nations

## Quick Facts
- arXiv ID: 2509.15789
- Source URL: https://arxiv.org/abs/2509.15789
- Reference count: 0
- Primary result: Fully reproducible pipeline producing 713M English tokens across 162k aligned UN documents (2000-2023)

## Executive Summary
This work presents a fully reproducible end-to-end pipeline for constructing large-scale parallel corpora from United Nations documents, addressing challenges of transparency, scalability, and alignment accuracy. The core innovation is a Graph-Aided Paragraph Alignment (GAPA) algorithm that enables flexible M–N paragraph-level mapping via bipartite graph construction and Longest Common Subsequence (LCS) detection, outperforming traditional sentence-level approaches. The resulting corpus contains over 713 million English tokens across 162k fully aligned documents, more than doubling prior UN-based resources in size and coverage (2000–2023). An optional distributed computing mode supports scalability. The entire pipeline, including data crawling, table processing, and alignment, is open-sourced, enabling community verification and extension. LLM-based evaluation shows high alignment accuracy (>94%) at a conservative hit-rate threshold, with human audits confirming reliability. This represents the largest publicly available human-translated, non-AI-generated parallel corpus, offering significant value for machine translation research and multilingual language modeling.

## Method Summary
The UPRPRC pipeline constructs parallel corpora through a reproducible workflow: (1) querying the UN Digital Library API for official documents (2000-2023), (2) converting various document formats to standardized DOCX via Microsoft Word COM automation, (3) extracting text with Pandoc, (4) flattening ASCII-style tables to preserve structure, (5) machine translating non-English paragraphs to English using Argos Translate, (6) aligning documents via Graph-Aided Paragraph Alignment (GAPA) using LCS-based bipartite graph matching with hit-rate filtering (h_c = 0.3), and (7) outputting in JSONL format with symbol identifiers. The pipeline supports both single-machine and distributed computing modes, producing the largest human-translated parallel corpus with 713M English tokens across 162k documents in six UN official languages.

## Key Results
- 713 million English tokens across 162,000 fully aligned documents (2000-2023)
- GAPA algorithm achieves >94% document-level accuracy at conservative hit-rate threshold
- Corpus more than doubles the size of prior UN-based parallel resources
- LLM-based evaluation confirms high alignment accuracy with human audits validating reliability

## Why This Works (Mechanism)

### Mechanism 1: Graph-Aided Paragraph Alignment (GAPA) for M–N Mapping
- Claim: GAPA enables flexible many-to-many (M–N) paragraph alignment with superior computational efficiency compared to prior sentence-level approaches.
- Mechanism: GAPA constructs a bipartite graph where each node represents a paragraph in either the source or target document. Links between nodes are established via Longest Common Subsequence (LCS) word matches. Connected subgraphs within this bipartite structure define correspondence groups—allowing one source paragraph to map to multiple target paragraphs (or vice versa) without rigid 1–1 constraints.
- Core assumption: Paragraph-level alignment preserves semantic correspondence better than sentence-level when translations involve splits, merges, or structural reordering.
- Evidence anchors:
  - [abstract]: "core innovation is a Graph-Aided Paragraph Alignment (GAPA) algorithm that enables flexible M–N paragraph-level mapping via bipartite graph construction"
  - [section 3.5]: "GAPA maps two corresponding documents x and y to a bipartite graph G(x, y) where each node in the graph is a paragraph"
  - [corpus]: Weak direct corpus signal; neighbor papers (JaParaPat, BanglaNirTox) involve parallel corpus construction but do not validate GAPA specifically.
- Break condition: If LCS matching produces excessive spurious links (e.g., common words like "a", "the" dominate), connected components become meaningless without aggressive filtering.

### Mechanism 2: LCS Hit-Rate Filtering Suppresses Noisy Links
- Claim: A character-length-weighted LCS hit-rate threshold removes noisy paragraph-node links while preserving genuine alignments.
- Mechanism: For each paragraph, the hit rate h(x_i) is computed as the ratio of total letters in LCS-matched words to total letters in the paragraph. Links connected to nodes below threshold h_c are removed. The paper empirically selects h_c = 0.3 as a balance between noise mitigation and corpus completeness.
- Core assumption: Low hit-rate paragraphs indicate alignment noise rather than legitimate translation variation (e.g., heavy paraphrasing).
- Evidence anchors:
  - [section 3.5]: "If the LCS hit rate of a paragraph (node) x_i ∈ x or y_i ∈ y is below a threshold h_c, then we remove the links connecting to the node"
  - [section 3.5]: "Based on our experiments, h_c = 0.3 is a suitable threshold"
  - [corpus]: No external corpus validation; this is an internal design choice.
- Break condition: If legitimate translations exhibit high paraphrasing (low lexical overlap), the hit-rate filter may over-prune valid alignments.

### Mechanism 3: Machine Translation as Cross-Lingual Bridge for Alignment
- Claim: Translating non-English paragraphs to English enables monolingual LCS-based alignment without requiring parallel sentence-level anchors.
- Mechanism: Non-English paragraphs are machine-translated to English via Argos (offline NMT). The translated text is then aligned to the original English document using LCS. This bypasses the need for cross-lingual word alignment models and allows standard string-matching algorithms to operate in a shared language space.
- Core assumption: MT quality is sufficient for alignment purposes even if translation errors exist, because LCS focuses on high-confidence overlapping terms.
- Evidence anchors:
  - [section 3.5]: "We first process the non-English document by machine translating it into English and then find the Longest Common Subsequence"
  - [section 3.5]: "We adopt Argos for machine translation, an open-source offline Neural Machine Translation (NMT) library"
  - [corpus]: Weak; neighbor papers do not validate this MT-bridge approach.
- Break condition: If MT systematically mistranslates domain-specific UN terminology, LCS matching may produce systematic alignment errors.

## Foundational Learning

- Concept: **Bipartite Graph Matching**
  - Why needed here: GAPA represents document pairs as bipartite graphs where edges encode candidate correspondences; understanding connected components is essential to grasp how M–N alignment emerges from this structure.
  - Quick check question: Given two node sets {A1, A2} and {B1, B2, B3} with edges (A1,B1), (A1,B2), (A2,B3), what are the connected components?

- Concept: **Longest Common Subsequence (LCS)**
  - Why needed here: LCS is the core similarity signal for establishing paragraph links; the Hunt–Szymanski algorithm is explicitly chosen for efficiency over naive dynamic programming.
  - Quick check question: What is the LCS of "translation quality" and "quality of translation"?

- Concept: **Hit Rate / Precision-Recall Tradeoffs in Alignment**
  - Why needed here: The h_c threshold controls the noise-completeness tradeoff; understanding this helps diagnose over- or under-filtering in practice.
  - Quick check question: If you raise h_c from 0.3 to 0.5, would you expect precision to increase or decrease? What about recall?

## Architecture Onboarding

- Component map:
  1. **Data Collection** — UN Digital Library API querying
  2. **Document Download & Verification** — DOC/PDF handling, header verification
  3. **Document Conversion** — Standardization to DOCX via COM automation; text extraction via Pandoc
  4. **Table Processing** — Detection and flattening of ASCII-style tables to preserve structure
  5. **MT Bridge** — Argos-based non-English → English translation
  6. **GAPA Alignment** — LCS computation (Hunt–Szymanski), bipartite graph construction, hit-rate filtering, connected component extraction
  7. **Output Formatting** — JSONL file-level, bilingual paragraph-level, all-language paragraph-block granularity

- Critical path:
  - Data Collection → Document Conversion → Table Processing → MT Bridge → GAPA Alignment → Output
  - Alignment quality is bottlenecked by: (a) table flattening correctness, (b) MT translation quality, (c) h_c threshold selection.

- Design tradeoffs:
  - Paragraph vs sentence granularity: Paragraph-level enables flexible M–N but may require downstream sentence segmentation for some MT systems.
  - Hit-rate threshold (h_c): Higher values increase precision at the cost of corpus coverage.
  - Distributed vs single-machine: Distributed mode supports scalability but adds infrastructure complexity.

- Failure signatures:
  - Low hit-rate warnings across many documents → h_c may be too aggressive or MT quality is poor.
  - Empty aligned outputs for specific language pairs → check table processing or MT failures upstream.
  - Disproportionately short aligned paragraphs → boilerplate or table artifacts not properly filtered.

- First 3 experiments:
  1. **Baseline alignment check**: Run the single-machine pipeline on a 100-document sample; verify paragraph-level alignment counts and average hit rates per language pair.
  2. **Threshold sensitivity analysis**: Vary h_c (e.g., 0.1, 0.3, 0.5) and measure alignment coverage vs LLM-judged accuracy on a held-out sample.
  3. **Table processing validation**: Compare alignment quality on documents with heavy tabular content before and after the table-flattening step to isolate its impact.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the quality of the intermediate machine translation (Argos) impact the recall of the Graph-Aided Paragraph Alignment (GAPA) algorithm for low-resource language pairs?
- Basis in paper: [inferred] The method (§3.5) relies on translating all non-English text to English before finding the Longest Common Subsequence (LCS).
- Why unresolved: The pipeline uses a specific open-source NMT library (Argos), but the paper does not analyze how translation errors or hallucinations in this intermediate step propagate into structural misalignments or missing links in the bipartite graph.
- What evidence would resolve it: An ablation study comparing alignment accuracy using different intermediate translation engines or human-translated reference anchors for low-resource languages like Arabic or Russian.

### Open Question 2
- Question: How can the significant discrepancy in evaluation ratings between LLM judges (e.g., GPT-4 vs. ChatGLM3) be resolved to establish a reliable ground truth?
- Basis in paper: [inferred] Table 5 shows a persistent ~5% gap in accuracy between GPT-4 (~94%) and ChatGLM3 (~99%), yet Table 6 relies on a very limited human audit (100 samples) to validate the models.
- Why unresolved: The paper does not investigate the specific linguistic features or error types driving the divergence between the LLM evaluators, leaving the "true" accuracy uncertain.
- What evidence would resolve it: A larger-scale human annotation effort focusing specifically on the "disagreement" cases between the LLM judges to determine which model is more sensitive to alignment errors.

### Open Question 3
- Question: Does the LCS hit-rate threshold ($h_c=0.3$) generalize effectively across all six official UN languages, or does it introduce language-specific bias?
- Basis in paper: [inferred] Section 3.5 states there is a "trade-off between mitigating noise and maintaining completeness" and settles on 0.3 as a "suitable threshold" based on experiments.
- Why unresolved: The paper presents aggregate statistics but does not report the percentage of data discarded (false negatives) specifically for each language at this threshold, which may be problematic for morphologically rich languages.
- What evidence would resolve it: Reporting the retention rate and alignment accuracy per language pair across a range of threshold values (e.g., 0.1 to 0.5).

## Limitations

- Distributed computing framework details are unspecified, making scalability claims difficult to verify independently
- UN API authentication, rate limiting, and pagination strategy are not documented
- LLM evaluation prompts are not provided, preventing exact replication of the 94% accuracy claim

## Confidence

- **High confidence**: Corpus size metrics (713M tokens, 162k documents) and basic pipeline architecture
- **Medium confidence**: GAPA algorithm description and hit-rate filtering mechanism (h_c = 0.3)
- **Low confidence**: Machine translation quality impact on alignment accuracy and distributed computing scalability claims

## Next Checks

1. Reproduce alignment on a 100-document sample to verify paragraph-level mapping and hit-rate distribution
2. Conduct threshold sensitivity analysis by varying h_c (0.1, 0.3, 0.5) and measuring coverage vs accuracy trade-offs
3. Validate table processing impact by comparing alignment quality on documents with and without tabular content