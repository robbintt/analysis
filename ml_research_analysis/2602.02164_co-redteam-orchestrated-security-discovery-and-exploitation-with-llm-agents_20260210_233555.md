---
ver: rpa2
title: 'Co-RedTeam: Orchestrated Security Discovery and Exploitation with LLM Agents'
arxiv_id: '2602.02164'
source_url: https://arxiv.org/abs/2602.02164
tags:
- vulnerability
- exploitation
- security
- agents
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Co-RedTeam is a security-aware multi-agent framework for automatic
  software vulnerability discovery and exploitation. It addresses the challenge of
  limited interaction, weak execution grounding, and lack of experience reuse in existing
  LLM-based approaches.
---

# Co-RedTeam: Orchestrated Security Discovery and Exploitation with LLM Agents

## Quick Facts
- arXiv ID: 2602.02164
- Source URL: https://arxiv.org/abs/2602.02164
- Reference count: 40
- Primary result: Co-RedTeam achieves over 60% success rate in vulnerability exploitation with over 10% absolute improvement in vulnerability detection versus strong baselines.

## Executive Summary
Co-RedTeam introduces a security-aware multi-agent framework that addresses key limitations in existing LLM-based vulnerability discovery approaches. By implementing role-specialized agents with execution-grounded iterative reasoning and a three-layer long-term memory system, the framework mirrors real-world red-teaming workflows. The system demonstrates consistent performance improvements across diverse benchmarks, showing the critical importance of closed-loop feedback and structured agent coordination for automated cybersecurity tasks.

## Method Summary
Co-RedTeam employs a multi-agent system orchestrated via Google ADK with two main stages. Stage I uses Analysis and Critique agents to discover vulnerabilities through code-browsing and vulnerability documentation tools, generating validated candidates with explicit evidence. Stage II implements a Planner-Validation-Execution-Evaluation loop where exploitation plans are generated, validated, executed in Docker isolation, and refined based on runtime feedback. A three-layer long-term memory (vulnerability patterns, strategies, technical actions) enables experience transfer across tasks through embedding-based retrieval. The framework supports both vulnerability detection from codebase only and exploitation reproduction from descriptions.

## Key Results
- Achieves over 60% success rate in vulnerability exploitation tasks
- Demonstrates over 10% absolute improvement in vulnerability detection accuracy versus baselines
- Ablation studies show 40+ percentage point drops in success when removing execution feedback, confirming the critical role of iterative refinement

## Why This Works (Mechanism)

### Mechanism 1: Execution-Grounded Iterative Refinement
Closed-loop plan-execute-evaluate cycles enable exploitation success through runtime diagnosis and correction. The system continuously refines plans based on actual execution results, with failures triggering explicit plan revisions. This approach addresses incomplete assumptions that plague single-shot generation methods.

### Mechanism 2: Role-Specialized Multi-Agent Coordination
Decomposing red-teaming into specialized agent roles with distinct tool access improves reliability. The orchestrator enforces structure and control while preventing tool misuse through role separation, with checkpoints between analysis and exploitation phases.

### Mechanism 3: Layered Long-Term Memory for Experience Transfer
A three-layer memory architecture enables cumulative improvement by capturing security expertise at multiple granularities. Vulnerability patterns, strategies, and technical actions are extracted from execution traces and research plans, allowing agents to learn from prior trajectories across diverse vulnerability classes.

## Foundational Learning

- **CWE/OWASP vulnerability taxonomies**: Essential for grounding vulnerability hypotheses in established weakness classes. Quick check: Can you name three CWE categories relevant to web applications and their typical sink functions?
- **Closed-loop control systems**: Critical for implementing Stage II's feedback control where evaluation signals drive plan revision. Quick check: How would you detect when an exploitation loop is oscillating rather than progressing?
- **Sandbox isolation (Docker containers)**: Necessary for safely testing exploits without damaging host systems. Quick check: What resource limits would you apply to prevent runaway exploit scripts from consuming host resources?

## Architecture Onboarding

- **Component map**: Orchestrator (control flow) → Stage I (Analysis + Critique agents with code-browsing/vuln-doc tools) → Stage II (Planner → Validation → Execution → Evaluation loop) → Long-term Memory (3-layer, shared across agents)
- **Critical path**: Input validation → Discovery (Analysis generates hypotheses → Critique filters) → Exploitation (Planner grounds in codebase/memory → Validation checks → Execution runs → Evaluation interprets → Planner refines) → Report generation
- **Design tradeoffs**: More iterations improve success but increase latency (saturation around 13–18 iterations); warm-start memory helps early performance but cold-start eventually converges; Validation agent adds overhead but prevents malformed commands from derailing execution
- **Failure signatures**: Loop oscillation (Planner retries similar failed actions), memory drift (irrelevant retrieved experiences), orchestrator deadlock (agents wait on never-triggering conditions), sandbox escape (container limitations affect exploit behavior)
- **First 3 experiments**: 1) Reproduce ablation on CyBench with and without execution feedback to verify 40+ percentage-point drop. 2) Test memory evolution: run sequential CyberGym tasks with cold-start vs. warm-start configurations and plot moving-average success. 3) Measure iteration saturation: cap exploitation at 5, 10, 15, 20 iterations and identify where performance plateaus for your backbone model.

## Open Questions the Paper Calls Out

### Open Question 1
Could replacing the static vulnerability knowledge base with a live search engine improve discovery of novel vulnerabilities versus established CWE patterns? The paper notes this architectural change as a future improvement but doesn't evaluate dynamic retrieval's impact on identifying exploits outside standard definitions.

### Open Question 2
Does unbounded accumulation of experiences in the layered long-term memory eventually degrade performance due to conflicting or low-quality data? While warm-start helps, the system lacks forgetting mechanisms, raising concerns about retrieval precision as memory grows significantly large.

### Open Question 3
Can the system autonomously determine optimal termination points for exploitation loops without fixed iteration caps? The framework currently uses hard-coded maximums rather than adaptive signals based on lack of progress, despite different models saturating at different iteration counts.

## Limitations

- Evaluation primarily benchmarks against static vulnerability datasets without demonstrating performance on live, production-like systems
- Docker sandbox isolation may not fully capture real-world execution differences that could affect exploit reliability
- Memory accumulation lacks consolidation mechanisms, potentially leading to retrieval noise over extended operations

## Confidence

- **High Confidence**: Execution-grounded iterative refinement mechanism and its demonstrated impact on success rates
- **Medium Confidence**: Role-specialized multi-agent coordination benefits
- **Medium Confidence**: Layered long-term memory effectiveness

## Next Checks

1. Deploy CoRedTeam on a live web application with known vulnerabilities (e.g., DVWA) to verify container-based exploits transfer to real systems
2. Conduct A/B testing comparing CoRedTeam's specialized agents against a single-agent baseline with equivalent tool access on identical vulnerability discovery tasks
3. Track memory retrieval relevance scores across 50+ sequential exploitation attempts to quantify whether retrieved experiences improve with task diversity