---
ver: rpa2
title: 'Lemma Dilemma: On Lemma Generation Without Domain- or Language-Specific Training
  Data'
arxiv_id: '2510.07434'
source_url: https://arxiv.org/abs/2510.07434
tags:
- prompt
- language
- computational
- data
- languages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the use of large language models (LLMs)
  for contextual lemmatization without any domain- or language-specific training data.
  The authors compare in-context lemma generation using LLMs against traditional supervised
  approaches, including encoder models fine-tuned out-of-domain and cross-lingual
  transfer methods.
---

# Lemma Dilemma: On Lemma Generation Without Domain- or Language-Specific Training Data

## Quick Facts
- arXiv ID: 2510.07434
- Source URL: https://arxiv.org/abs/2510.07434
- Authors: Olia Toporkov; Alan Akbik; Rodrigo Agerri
- Reference count: 26
- Primary result: LLMs achieve state-of-the-art lemmatization performance without domain- or language-specific training data

## Executive Summary
This paper investigates whether large language models (LLMs) can perform contextual lemmatization without any domain- or language-specific training data. The authors compare in-context lemma generation using LLMs against traditional supervised approaches, including encoder models fine-tuned out-of-domain and cross-lingual transfer methods. Experiments across 12 languages show that while encoder models fine-tuned on gold data remain competitive in out-of-domain settings, LLMs achieve state-of-the-art lemmatization performance by directly generating lemmas in-context with just a few examples.

## Method Summary
The study evaluates lemmatization performance using both traditional encoder models (fine-tuned out-of-domain and via cross-lingual transfer) and LLM-based in-context learning approaches. Experiments are conducted across 12 languages of varying morphological complexity using parallel and out-of-domain corpora. The LLM approach involves providing a few lemmatization examples in-context to guide generation, without any language-specific fine-tuning. Performance is measured against gold lemma annotations, with comparative analysis showing LLMs can match or exceed traditional supervised methods despite lacking language-specific training data.

## Key Results
- LLMs achieve state-of-the-art lemmatization performance for most languages when provided with few in-context examples
- Claude-3.7-Sonnet performs best overall among LLMs, followed closely by Mistral-Large-Instruct-2407
- Encoder models fine-tuned on gold data remain competitive in out-of-domain settings but generally underperform LLMs in the few-shot in-context setting
- LLMs can generate accurate lemmas across languages of varying morphological complexity without domain-specific training

## Why This Works (Mechanism)
The mechanism relies on LLMs' ability to generalize morphological patterns from a few in-context examples, leveraging their broad pretraining across diverse linguistic phenomena. By providing minimal demonstration examples during inference, LLMs can infer the lemmatization rules applicable to the target language and domain without requiring explicit training. This approach bypasses the need for large annotated corpora by exploiting the models' existing knowledge of morphological transformations across languages, enabling zero-shot or few-shot adaptation to new lemmatization tasks.

## Foundational Learning

1. **Lemmatization**: The process of reducing inflected words to their base or dictionary form. Why needed: Fundamental to NLP tasks requiring normalization and morphological analysis. Quick check: Verify understanding by manually lemmatizing sample words from different languages.

2. **In-context learning**: Providing examples within the input prompt to guide LLM behavior without parameter updates. Why needed: Enables few-shot adaptation without training data. Quick check: Test with simple pattern completion tasks to confirm in-context learning capability.

3. **Morphological complexity**: The degree and variety of word form variations in a language. Why needed: Determines the difficulty of lemmatization tasks. Quick check: Compare morphological inflection patterns across the 12 languages studied.

4. **Cross-lingual transfer**: Applying knowledge from one language to another during model training or inference. Why needed: Enables lemmatization for low-resource languages. Quick check: Verify transfer effectiveness by testing models trained on one language on related languages.

5. **Encoder models**: Neural architectures that map inputs to fixed-size representations for downstream tasks. Why needed: Traditional approach for supervised lemmatization. Quick check: Compare encoder model architecture with decoder-only LLMs.

6. **Zero-shot vs few-shot learning**: Zero-shot uses no examples, few-shot uses a small number of examples. Why needed: Differentiates between varying levels of in-context guidance. Quick check: Test both approaches on sample lemmatization tasks.

## Architecture Onboarding

Component map: Input text -> LLM encoder/decoder -> In-context examples -> Generated lemmas

Critical path: Raw text input → Tokenization → In-context example processing → Morphological pattern inference → Lemma generation

Design tradeoffs: LLMs offer superior few-shot performance but higher computational costs versus traditional encoder models; in-context learning eliminates training data requirements but may be sensitive to prompt formulation

Failure signatures: Incorrect morphological transformations, failure to generalize across rare inflection patterns, sensitivity to prompt quality and example selection

First experiments:
1. Test LLM lemmatization with varying numbers of in-context examples (0, 1, 3, 5) to determine minimum effective training
2. Compare performance across different prompt formulations with identical examples to assess prompt sensitivity
3. Evaluate computational latency and cost differences between LLM and encoder model approaches at scale

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Evaluation covers only 12 languages, all Indo-European or with substantial resources, limiting generalizability to truly low-resource or typologically distant languages
- Comparison conflates architectural differences with training methodology differences, making it difficult to isolate whether performance stems from LLM paradigm or model scale
- Experimental setup assumes access to parallel corpora and gold lemma annotations, which may not reflect realistic deployment scenarios for truly unsupervised lemmatization

## Confidence

| Claim | Confidence |
|-------|------------|
| LLMs can perform lemmatization without language-specific training data, and Claude-3.7-Sonnet shows strong performance across languages | High |
| LLMs outperform encoder models in most cases when given only few examples in-context, and traditional supervised models remain competitive in out-of-domain settings | Medium |
| The relative performance differences between LLM variants (Claude vs Mistral vs others) would hold consistently across different prompt formulations and evaluation conditions | Low |

## Next Checks
1. Test the same LLM prompts on truly low-resource languages with minimal available parallel data to assess real-world applicability
2. Conduct ablation studies comparing LLM performance with different numbers of in-context examples to determine minimum effective training
3. Measure and compare computational efficiency (latency and cost) between LLM-based and encoder-based lemmatization approaches at scale