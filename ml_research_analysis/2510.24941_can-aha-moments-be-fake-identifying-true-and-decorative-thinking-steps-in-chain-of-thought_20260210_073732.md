---
ver: rpa2
title: Can Aha Moments Be Fake? Identifying True and Decorative Thinking Steps in
  Chain-of-Thought
arxiv_id: '2510.24941'
source_url: https://arxiv.org/abs/2510.24941
tags:
- steps
- reasoning
- step
- arxiv
- steering
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the True Thinking Score (TTS) to evaluate
  the causal contribution of individual steps in large language models' chain-of-thought
  (CoT) reasoning. The authors find that reasoning steps in CoT can be classified
  as either true-thinking steps that genuinely drive the model's prediction or decorative-thinking
  steps that merely give the appearance of reasoning without causal impact.
---

# Can Aha Moments Be Fake? Identifying True and Decorative Thinking Steps in Chain-of-Thought

## Quick Facts
- arXiv ID: 2510.24941
- Source URL: https://arxiv.org/abs/2510.24941
- Authors: Jiachen Zhao; Yiyou Sun; Weiyan Shi; Dawn Song
- Reference count: 40
- Only 2.3% of CoT steps are true-thinking (TTS≥0.7) on mathematical reasoning tasks

## Executive Summary
This paper challenges the assumption that chain-of-thought (CoT) reasoning reliably reflects internal model reasoning by introducing the True Thinking Score (TTS) to evaluate the causal contribution of individual steps. The authors find that reasoning steps can be classified as either true-thinking steps that genuinely drive predictions or decorative-thinking steps that appear to reason but have no causal impact. Through experiments on GSM8K and MATH datasets, they reveal that only a small fraction of CoT steps are true-thinking, and demonstrate that a latent steering direction can control whether models internally follow or disregard specific reasoning steps.

## Method Summary
The authors develop the True Thinking Score (TTS) to quantify the causal contribution of each reasoning step in CoT. TTS is computed as the logit difference between the CoT prediction (ŷ_CoT) and direct prediction (ŷ_D), divided by the total logit difference between CoT prediction and ground truth. A step is considered true-thinking if its TTS exceeds a threshold (typically 0.7), indicating it substantially contributes to the final prediction. The method evaluates whether individual steps in a CoT sequence causally influence the model's output rather than merely appearing to reason. Additionally, the authors identify a steering direction in the model's residual stream that can be applied to control whether the model truly engages with specific reasoning steps or treats them as decorative.

## Key Results
- Only 2.3% of CoT steps have TTS≥0.7 on mathematical reasoning tasks, indicating most steps are decorative
- Self-verification steps in CoT are predominantly decorative, with TTS scores concentrated near zero
- A steering mechanism can force models to truly engage with self-verification steps, increasing their TTS from near-zero to substantial values
- The steering approach achieves 83.1% reduction in decorative steps on MATH dataset but only 16.9% on GSM8K

## Why This Works (Mechanism)
The mechanism relies on analyzing the causal relationship between intermediate reasoning steps and final predictions. By comparing the logit distributions from CoT versus direct prediction, the TTS quantifies whether each step meaningfully shifts the model's reasoning trajectory toward the correct answer. The steering mechanism works by identifying and applying latent directions in the model's residual stream that bias the model toward either following or ignoring specific reasoning steps during inference.

## Foundational Learning
- **Chain-of-Thought (CoT) reasoning**: Sequential step-by-step problem solving that makes reasoning explicit - needed to understand the target phenomenon being evaluated
- **Causal contribution measurement**: Quantifying whether intermediate steps actually influence final predictions rather than being post-hoc rationalizations - needed to distinguish true from decorative reasoning
- **Logit difference analysis**: Using prediction probability distributions to measure reasoning impact - needed to implement the TTS metric
- **Latent steering directions**: Manipulating model behavior by applying learned vectors in residual stream - needed to demonstrate control over true vs decorative reasoning
- **Self-verification in CoT**: Steps where models check their own work - needed as a concrete example of decorative reasoning
- **True Thinking Score (TTS)**: The proposed metric for evaluating step-level causal contribution - needed as the primary evaluation framework

## Architecture Onboarding

**Component Map**: Input -> Direct Prediction Path -> Final Prediction vs Input -> CoT Steps -> Final Prediction -> TTS Calculation

**Critical Path**: The core methodology flows from input processing through either direct prediction or CoT reasoning, with TTS measuring the causal gap between these paths at each intermediate step.

**Design Tradeoffs**: The TTS approach trades computational overhead (evaluating each step individually) for precise measurement of causal contribution, while the steering mechanism trades potential interference with other reasoning capabilities for targeted control over step engagement.

**Failure Signatures**: Decorative steps may still influence attention patterns or intermediate representations without affecting logits, potentially causing TTS to underestimate their indirect effects. The steering mechanism may have limited effectiveness on simpler datasets like GSM8K.

**3 First Experiments**:
1. Compute TTS scores across all steps in GSM8K and MATH datasets to establish baseline decorative reasoning prevalence
2. Apply steering direction to self-verification steps and measure TTS changes to verify mechanism effectiveness
3. Compare TTS distributions between true-thinking and decorative steps to validate threshold selection

## Open Questions the Paper Calls Out
None

## Limitations
- TTS relies on logit differences which may not capture all ways steps influence model behavior
- Evaluation focuses primarily on mathematical reasoning, limiting generalizability
- Steering mechanism shows only partial effectiveness, particularly on simpler datasets
- Choice of TTS threshold (0.7) may affect results and requires further justification

## Confidence

**High Confidence**: The observation that many CoT steps are decorative is well-supported by multiple experiments showing logit similarity between CoT and direct predictions.

**Medium Confidence**: The claim that only a small fraction of steps are true-thinking depends on the TTS≥0.7 threshold, which could be debated.

**Low Confidence**: Generalizability across different model families, reasoning tasks, and domains remains uncertain.

## Next Checks
1. Apply TTS evaluation to non-mathematical reasoning tasks (commonsense reasoning, logical inference) to test generalizability
2. Systematically vary the TTS threshold and analyze how the proportion of true-thinking steps changes
3. Use circuit analysis or attention pattern examination to independently verify whether identified true-thinking steps show distinct mechanistic signatures compared to decorative steps