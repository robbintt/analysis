---
ver: rpa2
title: Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large
  Language Models
arxiv_id: '2506.17580'
source_url: https://arxiv.org/abs/2506.17580
tags:
- knowledge
- wise
- information
- sources
- content
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: WISE (Workflow for Intelligent Scientific Knowledge Extraction)
  is a novel system that addresses the challenge of efficiently extracting and synthesizing
  knowledge from the rapidly growing volume of scientific literature. It combines
  LLMs with a structured, multi-layered workflow to iteratively filter, refine, and
  rank query-specific information.
---

# Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models

## Quick Facts
- arXiv ID: 2506.17580
- Source URL: https://arxiv.org/abs/2506.17580
- Authors: Sajratul Y. Rubaiat; Hasan M. Jamil
- Reference count: 40
- Primary result: WISE achieves 80% text reduction and 0.84 recall on HBB gene-associated diseases

## Executive Summary
WISE (Workflow for Intelligent Scientific Knowledge Extraction) addresses the challenge of extracting and synthesizing knowledge from rapidly growing scientific literature by combining large language models with a structured, multi-layered workflow. The system uses an LLM-powered, tree-based architecture to iteratively filter, refine, and rank query-specific information, focusing on contextually relevant and non-redundant content. Through dynamic scoring and ranking mechanisms, WISE prioritizes unique contributions from each source while employing adaptive stopping criteria to minimize processing overhead.

Experiments on HBB gene-associated diseases demonstrate that WISE significantly outperforms baseline approaches, reducing processed text by over 80% while achieving substantially higher recall (0.84 vs. 0.47-0.15 for baselines). The system also provides more in-depth information as measured by a novel level-based metric, making it particularly effective for domain-specific scientific knowledge extraction tasks.

## Method Summary
WISE implements a tree-based LLM-powered architecture that iteratively processes scientific literature through multiple filtering layers. The workflow begins with an initial query expansion phase, followed by document retrieval and sentence-level extraction. Each iteration applies context-aware filtering using LLM prompts to identify relevant content while eliminating redundancy. Dynamic scoring mechanisms evaluate the importance of extracted information based on query relevance and novelty. The system employs adaptive stopping criteria that monitor information gain across iterations to determine when to terminate processing, reducing computational overhead while maintaining extraction quality.

## Key Results
- Achieves 80% reduction in processed text compared to baseline approaches
- Demonstrates recall of 0.84 versus 0.47-0.15 for competing methods on HBB gene-associated diseases
- Provides more in-depth information as measured by novel level-based metric

## Why This Works (Mechanism)
The system's effectiveness stems from its multi-layered filtering approach that combines LLM contextual understanding with iterative refinement. By using tree-based architecture, WISE can explore multiple information paths simultaneously while maintaining query focus. The dynamic scoring mechanism ensures that only unique, high-value information is retained, preventing redundancy accumulation across iterations. Adaptive stopping criteria prevent over-processing by monitoring diminishing returns in information gain, making the system both efficient and effective.

## Foundational Learning

1. **LLM-based iterative filtering**
   - Why needed: Traditional keyword matching fails to capture contextual relationships in scientific literature
   - Quick check: Verify LLM prompt templates capture domain-specific terminology variations

2. **Tree-based information architecture**
   - Why needed: Enables parallel exploration of multiple information pathways while maintaining query coherence
- Quick check: Confirm tree depth limits prevent combinatorial explosion

3. **Dynamic scoring mechanisms**
   - Why needed: Static relevance scores cannot adapt to evolving information context across iterations
   - Quick check: Validate scoring weights balance novelty vs. relevance appropriately

4. **Adaptive stopping criteria**
   - Why needed: Prevents unnecessary processing once information gain plateaus
   - Quick check: Test stopping thresholds across different query complexities

## Architecture Onboarding

**Component Map:** Query Expansion -> Document Retrieval -> Sentence Extraction -> LLM Filtering -> Dynamic Scoring -> Ranking -> Adaptive Stopping

**Critical Path:** The core processing pipeline flows from initial query expansion through iterative LLM filtering, with dynamic scoring providing real-time quality assessment and adaptive stopping preventing over-processing.

**Design Tradeoffs:** The system prioritizes information quality over processing speed, using multiple LLM calls per iteration. This increases accuracy but raises computational costs, mitigated by adaptive stopping criteria.

**Failure Signatures:** 
- Poor recall indicates inadequate query expansion or overly aggressive filtering thresholds
- High redundancy suggests dynamic scoring weights need adjustment
- Premature stopping indicates stopping criteria thresholds are too conservative

**First Experiments:**
1. Test with simple gene-disease queries before scaling to complex multi-factor relationships
2. Compare performance with varying tree depths (2-4 levels) to find optimal balance
3. Evaluate different LLM models (GPT-4, Claude, Gemini) for filtering quality

## Open Questions the Paper Calls Out

The paper does not explicitly call out specific open questions, but implicit questions include: How well does the system generalize to other scientific domains beyond HBB gene-associated diseases? What is the optimal balance between computational cost and extraction quality? How reliable is the novel level-based metric compared to established information retrieval measures?

## Limitations

- Performance metrics may not generalize beyond the HBB gene-associated diseases domain due to single-domain evaluation
- Computational efficiency at scale remains uncertain despite adaptive stopping criteria claims
- Novel level-based metric lacks external validation against established quality measures

## Confidence

**High confidence:** The core architecture and workflow description (tree-based LLM-powered filtering with dynamic scoring)

**Medium confidence:** Performance improvements on HBB dataset (limited to single domain)

**Low confidence:** Claims about computational efficiency and generalizability to other domains

## Next Checks

1. Replicate the evaluation on at least two additional scientific domains (e.g., materials science and clinical medicine) to test generalizability
2. Conduct a head-to-head comparison with established knowledge extraction systems using standard IR metrics (MAP, nDCG) in addition to the novel level-based metric
3. Measure actual computational costs (API calls, processing time) for datasets of varying sizes to validate efficiency claims and adaptive stopping criteria effectiveness