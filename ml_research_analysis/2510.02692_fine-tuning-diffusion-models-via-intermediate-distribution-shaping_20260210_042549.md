---
ver: rpa2
title: Fine-Tuning Diffusion Models via Intermediate Distribution Shaping
arxiv_id: '2510.02692'
source_url: https://arxiv.org/abs/2510.02692
tags:
- diffusion
- p-graft
- fine-tuning
- arxiv
- distribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a unified framework for fine-tuning diffusion
  models using rejection sampling (GRAFT) and introduces Partial-GRAFT (P-GRAFT),
  which shapes intermediate distributions to improve fine-tuning. P-GRAFT is theoretically
  justified via a bias-variance tradeoff and outperforms policy gradient methods like
  DDPO on text-to-image generation benchmarks (up to 8.81% relative improvement in
  VQAScore).
---

# Fine-Tuning Diffusion Models via Intermediate Distribution Shaping

## Quick Facts
- arXiv ID: 2510.02692
- Source URL: https://arxiv.org/abs/2510.02692
- Reference count: 40
- Primary result: P-GRAFT improves diffusion fine-tuning via intermediate distribution shaping, achieving 8.81% relative VQAScore improvement over DDPO on text-to-image tasks.

## Executive Summary
This paper proposes a unified framework for fine-tuning diffusion models using rejection sampling (GRAFT) and introduces Partial-GRAFT (P-GRAFT), which shapes intermediate distributions to improve fine-tuning. P-GRAFT is theoretically justified via a bias-variance tradeoff and outperforms policy gradient methods like DDPO on text-to-image generation benchmarks. The authors also introduce Inverse Noise Correction, an adapter-based method that improves flow models without explicit rewards, achieving better FID at lower FLOPs. Experiments span text-to-image, layout, molecule, and unconditional image generation tasks, demonstrating consistent performance gains across domains.

## Method Summary
The paper presents three main contributions: (1) GRAFT, a unified framework reformulating rejection sampling fine-tuning as KL-regularized reward maximization with reshaped rewards; (2) P-GRAFT, which shapes distributions at intermediate denoising timesteps based on a theoretical bias-variance tradeoff in score function complexity; and (3) Inverse Noise Correction, an adapter-based method for improving flow models by training to correct initial noise distribution shifts. The methods are evaluated across multiple domains including text-to-image generation, layout generation, molecule generation, and unconditional image synthesis.

## Key Results
- P-GRAFT achieves up to 8.81% relative improvement in VQAScore compared to DDPO on text-to-image generation
- Inverse Noise Correction improves FID on unconditional image generation while reducing FLOPs
- P-GRAFT shows consistent improvements across text-to-image, layout, and molecule generation tasks
- Optimal intermediate timestep NI ≈ 0.25N across most tasks
- P-GRAFT provides better reward gains with lower sample complexity than existing methods

## Why This Works (Mechanism)

### Mechanism 1: GRAFT's Reformulation of Rejection Sampling
GRAFT mathematically reformulates rejection sampling as KL-regularized reward maximization with a monotonically reshaped reward function. By sampling from a reference model and using an acceptance function based on reward, it implicitly performs fine-tuning that achieves marginal KL regularization without needing intractable marginal likelihoods. The reshaped reward ensures stable optimization by avoiding direct reward maximization.

### Mechanism 2: P-GRAFT's Bias-Variance Tradeoff
P-GRAFT improves efficiency by shaping distributions at intermediate denoising steps, leveraging the fact that score functions at higher noise levels are closer to simple Gaussians (lower bias). This makes them easier to learn despite higher reward variance. The method balances this tradeoff by choosing an optimal intermediate timestep where learning is most efficient.

### Mechanism 3: Inverse Noise Correction for Flow Models
This method improves flow models without explicit rewards by training an adapter to correct the initial noise distribution. Since flow models generate samples from a distribution that differs from true data, the distance between the inverted noise distribution and standard normal equals the distance between generated and true distributions. The adapter compensates for these shifts during inference.

## Foundational Learning

- **KL-regularized reward maximization**: This objective balances reward maximization with staying close to the reference policy. In GRAFT, α parameter controls this tradeoff - higher values prioritize staying close to the reference model, lower values prioritize reward maximization.

- **Score function in diffusion models**: The gradient of log probability with respect to the input. P-GRAFT's theoretical justification relies on score functions becoming simpler (closer to Gaussian) at higher noise levels, making them easier to learn.

- **Rejection Sampling (Generalized)**: The core operation of GRAFT where samples are accepted or rejected based on an acceptance function. In Top-K of M sampling, if M=100 and K=10, the function keeps the 10 samples with highest rewards and rejects the remaining 90.

## Architecture Onboarding

- **Component map**: Reference model -> Sample generation -> Reward computation -> Acceptance function (Top-K) -> Fine-tuning dataset -> Fine-tuned model (LoRA)
- **Critical path**: P-GRAFT training is most complex, requiring saving intermediate latents and recalibrating noise schedule. The noise schedule recalibration is critical - starting from intermediate latents requires adjusting alphas_cumprod to maintain consistent training signals.

- **Design tradeoffs**:
  - Choice of NI in P-GRAFT implements bias-variance tradeoff (smaller NI = lower variance reward but harder learning)
  - LoRA vs full fine-tuning (LoRA is efficient but full fine-tuning might offer greater gains with higher instability risk)
  - Balancing generalization vs optimization (GRAFT optimizes given reward which could lead to overfitting)

- **Failure signatures**:
  - Performance collapse if NI too large (e.g., 0.75N) causing noisy reward signal
  - No improvement with Inverse Noise Correction if model errors aren't primarily from noise shift
  - GRAFT shows no advantage if reward model disconnected from actual quality

- **First 3 experiments**:
  1. Baseline GRAFT reproduction with Top-K sampling on small prompt subset, verify higher VQAScore than base model
  2. P-GRAFT timestep ablation with different NI values (0.25N, 0.5N, 0.75N), plot VQAScore against timestep to observe bias-variance tradeoff
  3. Inverse Noise Correction on small flow model (MNIST subset), compare FID of standard vs corrected noise samples

## Open Questions the Paper Calls Out

The paper explicitly identifies several limitations and open questions in its discussion sections, including the need for better theoretical understanding of optimal hyperparameters, scalability to larger models, and the relationship between rejection sampling and other fine-tuning paradigms.

## Limitations

- Theoretical bias-variance tradeoff in P-GRAFT relies on Ornstein-Uhlenbeck assumptions that may not hold for all diffusion models
- Inverse Noise Correction assumes model errors primarily stem from noise distribution shifts, which may not generalize to all architectures
- Performance improvements are incremental rather than transformative, suggesting the methods may not be universally applicable

## Confidence

- **High confidence**: GRAFT's mathematical reformulation of rejection sampling as KL-regularized optimization is sound and experimentally validated
- **Medium confidence**: P-GRAFT's theoretical bias-variance tradeoff justification is valid but practical effectiveness depends heavily on task-specific hyperparameter tuning
- **Low confidence**: Inverse Noise Correction's generalizability beyond tested flow models is uncertain due to architectural assumptions

## Next Checks

1. **Score function complexity analysis**: Quantify actual difference in score function complexity between intermediate and final timesteps across multiple datasets to validate P-GRAFT theoretical foundation

2. **Inverse Noise Correction ablation**: Test method on flow models with known architectural limitations to determine if improvements stem from noise correction vs other factors

3. **Reward model sensitivity**: Evaluate GRAFT's performance with varying quality reward models to assess robustness to reward signal quality