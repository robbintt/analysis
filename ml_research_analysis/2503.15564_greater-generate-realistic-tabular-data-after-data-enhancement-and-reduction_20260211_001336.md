---
ver: rpa2
title: 'GReaTER: Generate Realistic Tabular data after data Enhancement and Reduction'
arxiv_id: '2503.15564'
source_url: https://arxiv.org/abs/2503.15564
tags:
- data
- tabular
- table
- arxiv
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces GReaTER, a framework that enhances LLM-based
  tabular data synthesis by addressing two key challenges: ambiguous numerical labels
  across features and complex multi-table relationships. GReaTER improves semantic
  understanding through a data semantic enhancement system that transforms categorical
  labels into more meaningful representations, and addresses multi-table synthesis
  through a cross-table connecting method that reduces noise from engaged subject
  bias.'
---

# GReaTER: Generate Realistic Tabular data after data Enhancement and Reduction

## Quick Facts
- arXiv ID: 2503.15564
- Source URL: https://arxiv.org/abs/2503.15564
- Authors: Tung Sum Thomas Kwok; Chi-Hua Wang; Guang Cheng
- Reference count: 40
- Key outcome: GReaTER framework improves LLM-based tabular data synthesis by addressing ambiguous numerical labels and multi-table relationships, achieving better synthetic fidelity measured through distribution similarity metrics

## Executive Summary
GReaTER introduces a framework that enhances LLM-based tabular data synthesis by addressing two key challenges: ambiguous numerical labels across features and complex multi-table relationships. The framework improves semantic understanding through a data semantic enhancement system that transforms categorical labels into more meaningful representations, and addresses multi-table synthesis through a cross-table connecting method that reduces noise from engaged subject bias. Experiments on the Advertisement and Feeds dataset demonstrate that GReaTER outperforms the GReaT baseline and other methods, with improved synthetic data fidelity measured through distribution similarity metrics.

## Method Summary
GReaTER processes tabular data through a pipeline that first extracts contextual variables from multi-table data to form a parent table, then applies semantic enhancement to transform ambiguous numerical categories into unique or meaningful representations. The cross-table connecting method identifies independent features using correlation analysis, reduces dimensionality by removing these features and duplicate rows, then reattaches independent features via bootstrap sampling to preserve validity. The transformed data is textual-encoded and used to fine-tune an LLM synthesizer (typically GPT-2 or ReaLTabFormer), which generates synthetic data that is then inverse-mapped to the original numerical format.

## Key Results
- GReaTER achieves higher distribution similarity metrics (KS p-values and Wasserstein distance) compared to GReaT baseline on Advertisement and Feeds dataset
- Both differentiability-based and understandability-based semantic enhancement modules improve synthetic data fidelity compared to no mapping
- Cross-table connecting method reduces engaged subject bias and improves fidelity over direct flattening and DEREC approaches
- The framework demonstrates effectiveness in handling multi-modal and multi-table tabular data synthesis

## Why This Works (Mechanism)

### Mechanism 1: Data Semantic Enhancement System
Mapping ambiguous numerical labels to semantically distinct representations improves LLM understanding and synthetic data fidelity. The system identifies categorical features with co-occurring numerical labels and maps them to unique representations, reducing token collision and enabling the LLM to leverage pre-trained knowledge for in-context learning. This works when categorical features have meaningful semantic interpretations that can be mapped to distinct tokens.

### Mechanism 2: Cross-table Connecting Method
Restructuring multi-table data by extracting contextual variables as a parent table and using correlation-based dimension reduction reduces engaged subject bias and improves synthesis fidelity. The three-step process transforms many-to-many relationships into one-to-many while modeling cross-child-table interactions simultaneously. This addresses the problem of frequent subjects dominating flattened tables and introducing noise that degrades synthetic fidelity.

### Mechanism 3: Inverse Mapping System
A reversible mapping system ensures synthetic output matches original data format while enabling post-synthesis privacy protection. The system maintains bidirectional mappings from original numerical labels to enhanced semantic representations, with mappings deleted after synthesis to prevent privacy attacks. This assumes the mapping system is complete and unambiguous.

## Foundational Learning

- **GReaT (Generate Realistic Tabular Data) framework**: Understanding GReaT's textual encoder and LLM fine-tuning approach is prerequisite to understanding what GReaTER enhances. Can you explain how GReaT converts a tabular row into a text sequence and why ambiguous numerical labels cause token collision?

- **Parent-child table relationships in relational databases**: The cross-table connecting method assumes familiarity with contextual variables and hierarchical table structures. Given a users table (one row per user) and a transactions table (many rows per user), which columns from transactions would be contextual and extractable to a parent table?

- **Distribution similarity metrics (KS test p-value, Wasserstein distance)**: Paper evaluates synthetic fidelity using Kolmogorov-Smirnov test p-values and Wasserstein distance on pairwise conditional distributions. What does a higher KS test p-value indicate about the similarity between original and synthetic column distributions?

## Architecture Onboarding

- **Component map**: Data Semantic Enhancement System -> Cross-table Connecting Method -> LLM Synthesizer Backbone -> Inverse Mapping System -> Evaluation Pipeline
- **Critical path**: Preprocess multi-table data → identify contextual variables → extract parent table → apply semantic enhancement mapping to child tables → run cross-table connecting method → textual encode transformed rows → fine-tune LLM → generate synthetic rows → inverse transform → evaluate fidelity
- **Design tradeoffs**: Differentiability vs. understandability transformation (automated vs. semantically rich), Threshold Separation vs. Hierarchical Clustering (simpler vs. distance-based), GPT-2 vs. advanced LLMs (limited vs. better semantic reasoning)
- **Failure signatures**: Low synthetic fidelity with high p-values only on well-correlated columns, W-distance near zero but KS p-values low, invalid feature combinations in synthetic output, out-of-mapping categories in synthetic output
- **First 3 experiments**: 1) Implement GReaT on single-table subset to establish baseline fidelity, 2) Apply only differentiability-based transformation to isolate semantic enhancement contribution, 3) Compare direct flattening, DEREC, and cross-table connecting method to verify engaged subject bias reduction

## Open Questions the Paper Calls Out

- **Automation of understandability-based transformation**: Can the manual mapping process be automated using LLMs to generate precise categories without data scientist intervention? The current manual process is a bottleneck for scaling the framework.

- **Robustness for highly correlated data**: How can the Cross-table Connecting Method be modified to remain effective for datasets with highly correlated features, such as financial domains? The current method becomes less effective when features are highly interdependent.

- **Advanced LLM integration**: To what extent does replacing GPT-2 with state-of-the-art LLMs (e.g., GPT-4o, Llama 3.2) improve performance? The limited outperformance of understandability-based transformation on GPT-2 may be due to its limited pre-trained knowledge base.

- **Enhanced textual encoding**: Does upgrading the textual encoder to generate full natural language sentences improve LLM understanding compared to the current "Name: Value" pair structure? The paper suggests this may further improve understanding of LLM.

## Limitations

- **Unknown backbone implementation**: The paper ambiguously switches between "GReaT" (GPT-2) and "ReaLTabFormer" in different sections, creating uncertainty about the exact LLM architecture used.
- **Manual mapping requirement**: The understandability-based transformation depends on domain-specific manual mappings that are not fully specified and may not generalize across datasets.
- **Correlation threshold selection**: The choice of median/mean for threshold separation lacks sensitivity analysis, potentially making the cross-table method unstable across different data distributions.

## Confidence

- **High Confidence**: Core insight that ambiguous numerical labels cause token collision in LLMs is well-supported by ablation study showing both transformation methods improve fidelity over no mapping.
- **Medium Confidence**: Engaged subject bias mitigation through cross-table connecting method is supported by Figure 9 comparisons, but corpus lacks direct validation of this specific approach.
- **Low Confidence**: Claims about downstream task performance improvements are not validated; paper focuses solely on distribution similarity metrics without testing utility for actual prediction tasks.

## Next Checks

1. **Architecture clarification**: Implement both GReaT (GPT-2) and ReaLTabFormer variants to determine which backbone yields the reported performance, then publish exact hyperparameters and training procedures.

2. **Generalization testing**: Apply GReaTER to datasets with inherently non-semantic categorical features (e.g., encoded sensor readings) to verify the semantic enhancement system doesn't introduce spurious correlations.

3. **Downstream task validation**: Train a predictive model on synthetic data generated by GReaTER and GReaT baselines, then measure performance degradation on real test data to assess practical utility beyond distribution matching.