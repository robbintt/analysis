---
ver: rpa2
title: 'Large Language Models for the Summarization of Czech Documents: From History
  to the Present'
arxiv_id: '2511.18848'
source_url: https://arxiv.org/abs/2511.18848
tags:
- czech
- summarization
- dataset
- language
- summaries
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of Czech text summarization,
  particularly for historical documents, due to the language's linguistic complexity
  and lack of high-quality annotated datasets. The authors leverage advanced Large
  Language Models (LLMs), specifically Mistral 7B and mT5, to establish new state-of-the-art
  results on the SumeCzech dataset for modern Czech summarization.
---

# Large Language Models for the Summarization of Czech Documents: From History to the Present

## Quick Facts
- **arXiv ID**: 2511.18848
- **Source URL**: https://arxiv.org/abs/2511.18848
- **Reference count**: 40
- **Primary result**: Advanced LLMs achieve state-of-the-art Czech summarization, with novel translation-based approach for historical texts

## Executive Summary
This study addresses the challenge of Czech text summarization, particularly for historical documents, due to the language's linguistic complexity and lack of high-quality annotated datasets. The authors leverage advanced Large Language Models (LLMs), specifically Mistral 7B and mT5, to establish new state-of-the-art results on the SumeCzech dataset for modern Czech summarization. Additionally, they propose a novel translation-based approach (TST) that translates Czech texts into English, summarizes them using an English-language model, and translates the summaries back into Czech. The authors also introduce a new dataset, Posel od Čerchova, derived from 19th-century Czech publications, for historical text summarization. Experimental results show that the Mistral-based model (M7B-SC) achieves new performance benchmarks on SumeCzech, while the translation-based approach proves highly competitive. These contributions advance Czech summarization research and provide valuable resources for processing historical texts in digital humanities and cultural heritage preservation.

## Method Summary
The authors employ two primary approaches for Czech text summarization. First, they fine-tune pre-trained Czech LLMs (Mistral 7B and mT5) on the SumeCzech dataset, achieving new state-of-the-art results. Second, they develop a translation-based summarization technique (TST) that leverages English-language summarization models by translating Czech input to English, summarizing, then translating back to Czech. This approach uses commercial translation services (DeepL) for the translation steps. The study also introduces a new dataset from 19th-century Czech publications for historical document summarization, addressing the gap in resources for processing historical Czech texts.

## Key Results
- Mistral 7B-based model (M7B-SC) achieves new state-of-the-art performance on the SumeCzech dataset
- Translation-based approach (TST) demonstrates competitive performance with fine-tuned models
- New historical dataset "Posel od Čerchova" successfully created from 19th-century Czech publications

## Why This Works (Mechanism)
The effectiveness stems from leveraging large-scale pre-trained language models adapted to Czech through fine-tuning on domain-specific data. The translation-based approach exploits the maturity of English-language summarization models while addressing the data scarcity problem in Czech by using high-quality translation services as an intermediary step.

## Foundational Learning

**Czech Language Characteristics**: Czech is a morphologically rich Slavic language with complex inflection and free word order, making summarization challenging due to context-dependent meanings. Why needed: Understanding linguistic complexity helps explain why standard approaches fail and why specialized models are necessary. Quick check: Review morphological analysis showing case, gender, and number variations in sample Czech sentences.

**Fine-tuning Process**: Adapting pre-trained models to specific domains by continuing training on task-relevant data while preserving general language understanding. Why needed: Explains how LLMs achieve strong performance on Czech despite limited Czech-specific training data. Quick check: Monitor loss curves during fine-tuning to ensure convergence without catastrophic forgetting.

**Translation-based Approach**: Using translation as a bridge to leverage models trained in high-resource languages when low-resource language models are unavailable. Why needed: Demonstrates how to overcome data scarcity through strategic use of translation services. Quick check: Compare translation quality metrics (BLEU, TER) between translation-only and translation-summarization-translation pipelines.

## Architecture Onboarding

**Component Map**: Czech Text -> Fine-tuned LLM (Mistral 7B/mT5) -> Czech Summary
Czech Text -> DeepL Translation -> English Summary (English LLM) -> DeepL Translation -> Czech Summary

**Critical Path**: The translation-based approach follows: Czech Input → DeepL (Cz→En) → English LLM Summary → DeepL (En→Cz) → Czech Output. This path introduces potential quality degradation at each translation step.

**Design Tradeoffs**: Fine-tuning Czech models requires large annotated datasets and computational resources but maintains language integrity. Translation-based approach requires commercial API costs and introduces potential semantic drift but leverages mature English models.

**Failure Signatures**: Fine-tuned models may fail on out-of-domain texts or rare vocabulary. Translation-based approach may produce awkward phrasing or lose nuance during translation steps. Both approaches struggle with very long documents due to context window limitations.

**First Experiments**:
1. Evaluate translation quality (Cz→En) on sample Czech news articles using BLEU and human assessment
2. Test fine-tuned Mistral 7B on short Czech summaries to establish baseline performance
3. Compare ROUGE scores between direct Czech summarization and translation-based approach on the same documents

## Open Questions the Paper Calls Out
None identified in the provided information.

## Limitations
- Translation-based approach relies on commercial services (DeepL) introducing potential quality variations and ongoing costs
- Historical dataset represents only a single 19th-century source, limiting generalizability to other historical periods or document types
- Evaluation focuses primarily on ROUGE metrics, which may not fully capture quality of summaries for historical texts where preservation of specific terminology and context is crucial

## Confidence

**High confidence**: Performance improvements on the SumeCzech dataset using Mistral 7B and mT5 models
**Medium confidence**: The translation-based approach's effectiveness for Czech summarization
**Medium confidence**: The quality and representativeness of the newly created historical dataset

## Next Checks

1. Test the translation-based approach with multiple translation services to assess robustness and cost implications
2. Expand evaluation to include human assessments of summary quality, particularly for historical documents where semantic preservation matters
3. Create and evaluate additional historical datasets from different time periods and document types to verify generalizability of the proposed methods