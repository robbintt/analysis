---
ver: rpa2
title: 'Discounted Online Convex Optimization: Uniform Regret Across a Continuous
  Interval'
arxiv_id: '2505.19491'
source_url: https://arxiv.org/abs/2505.19491
tags:
- discounted
- regret
- discount
- algorithm
- factor
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper addresses discounted online convex optimization (OCO)\
  \ where the learner must minimize a loss function while forgetting past data through\
  \ a discount factor \u03BB. The challenge is to develop an algorithm that adapts\
  \ to an unknown discount factor \u03BB across a continuous interval [1-1/\u03C4\
  , 1-1/T], where \u03C4 is a minimal window length and T is the total number of rounds."
---

# Discounted Online Convex Optimization: Uniform Regret Across a Continuous Interval

## Quick Facts
- arXiv ID: 2505.19491
- Source URL: https://arxiv.org/abs/2505.19491
- Reference count: 9
- Primary result: Achieves O(√(log T)/(1-λ)) uniform discounted regret across continuous interval [1-1/τ, 1-1/T] without knowing λ

## Executive Summary
This paper addresses discounted online convex optimization where the learner must minimize a loss function while forgetting past data through a discount factor λ. The key challenge is developing an algorithm that adapts to an unknown discount factor λ across a continuous interval without prior knowledge. The authors propose Smoothed OGD (SOGD), a meta-expert framework that discretizes the continuous interval into a geometric series and aggregates OGD experts using Discounted-Normal-Predictor with conservative updating (DNP-cu). The primary contribution is achieving uniform O(√(log T)/(1-λ)) discounted regret across the entire continuous interval simultaneously for all values of λ, representing a significant improvement over existing methods requiring known λ.

## Method Summary
The Smoothed OGD (SOGD) algorithm works by first discretizing the continuous interval [1-1/τ, 1-1/T] into N ≈ log₂(T/τ) points using a geometric series. For each discrete discount factor λᵢ, an OGD expert is instantiated with the optimal step size ηᵢ = (D/G)√(2^i/T). These experts are then sequentially aggregated using Combiner instances that employ DNP-cu as the meta-algorithm. The DNP-cu mechanism can track discounted regret for different discount factors simultaneously, enabling the uniform guarantee. The algorithm maintains N+1 expert states and performs sequential aggregation per round, outputting the final decision from the last combiner.

## Key Results
- SOGD achieves O(√(log T)/(1-λ)) discounted regret uniformly across all λ ∈ [1-1/τ, 1-1/T] simultaneously
- The bound improves over existing methods by eliminating the need to know λ in advance
- The √log T overhead reflects the adaptivity cost compared to optimal known-factor bounds
- Theoretical analysis is supported by three main theorems covering OGD base case, DNP-cu aggregation, and the complete SOGD algorithm

## Why This Works (Mechanism)

### Mechanism 1: OGD with Known λ
OGD with constant step size η = D√(2(1-λ))/G achieves O(1/√(1-λ)) discounted regret when the discount factor λ is known. This follows from standard OGD analysis adapted to the discounted setting, where the discount factor's geometric series sums to 1/(1-λ). The optimal step size balances accumulated gradient variance against distance traveled.

### Mechanism 2: DNP-cu Cross-Discount-Factor Guarantee
DNP-cu can aggregate two experts operating under different discount factors λ₁ ≥ λ₂, providing discounted regret guarantees for both simultaneously. The key insight is that DNP-cu operating with discount factor ρ can provide guarantees for any η ≥ ρ, allowing sequential aggregation to track multiple discount factors. Conservative updating controls deviation to prevent runaway errors.

### Mechanism 3: Sequential Aggregation Uniformity
Sequential aggregation of N ≈ log₂(T/τ) OGD experts with geometrically decreasing step sizes achieves uniform O(√(log T)/(1-λ)) regret for all λ ∈ [1-1/τ, 1-1/T] simultaneously. The continuous interval discretization via geometric series enables covering the entire range, while the sequential combiner structure ensures the uniform bound holds across all values.

## Foundational Learning

- **Online Convex Optimization (OCO)**: The base framework where a learner predicts wt ∈ W each round and receives convex loss ft. Understanding this game protocol and static regret is essential before extending to discounted settings.
  - Quick check: Can you explain why static regret is ill-suited for non-stationary environments?

- **λ-Discounted Regret**: The performance metric where λ^(T-t) weights recent rounds more heavily than distant past. Understanding this temporal weighting is central to the paper's contributions.
  - Quick check: If λ = 0.99 and T = 1000, approximately what fraction of total weight is on the last 100 rounds?

- **Meta-Expert Frameworks (Hedge, Fixed-Share)**: Traditional meta-algorithms that aggregate experts based on unified performance measurements. Understanding why Hedge fails here illuminates the DNP-cu contribution.
  - Quick check: Why does Hedge require all experts to operate under the same performance measure?

## Architecture Onboarding

- **Component map**: OGD₁ → B₁ → OGD₂ → B₂ → ... → OGD_{N+1} → B_{N+1}, where OGDᵢ are experts and Bᵢ are combiners
- **Critical path**: 1) Discretize λ interval into geometric series, 2) Instantiate OGD experts with corresponding step sizes, 3) Chain Combiners sequentially in descending λ order, 4) Run all combiners sequentially per round, output final decision
- **Design tradeoffs**: Uniformity across all λ costs √log T factor vs. knowing λ exactly; requires maintaining N ≈ log₂(T/τ) expert states; sequential combiner execution means O(log T) sequential operations per round
- **Failure signatures**: Exploding regret if DNP-cu deviation exceeds bounds; wrong ordering breaks cross-discount-factor guarantee; boundary violations if λ approaches 1 too closely
- **First 3 experiments**: 1) Implement OGD with known λ to verify O(1/√(1-λ)) regret on synthetic convex losses, 2) Test single combiner with two experts (λ₁=0.95, λ₂=0.9) to verify dual regret guarantees, 3) Run full SOGD on non-stationary losses, sweep λ across interval, plot regret vs. λ

## Open Questions the Paper Calls Out

### Open Question 1
Is the O(√(log T)/(1-λ)) regret bound tight for the unknown discount factor setting, or can the √log T overhead be eliminated? The paper establishes an upper bound but does not prove a lower bound showing whether this additional logarithmic factor is fundamental for uniform adaptation across the interval.

### Open Question 2
Can the proposed method be extended to handle unknown time-varying discount factors without requiring prior knowledge of the sequence? The current analysis relies on fixed discount structures for both base experts and meta-algorithm, while Zhang et al. (2024) studied time-varying factors requiring prior knowledge.

### Open Question 3
Can uniform discounted regret be achieved with computational complexity lower than maintaining a grid of O(log T) experts? The algorithm discretizes into N ≈ log₂(T/τ) experts, which is efficient but still requires maintaining multiple OGD instances simultaneously.

## Limitations

- The algorithm requires maintaining N ≈ log₂(T/τ) expert states simultaneously, which may be memory-intensive for large T
- The analysis assumes bounded gradients (G) and domain diameter (D), which may not hold for all real-world applications
- Numerical stability of the confidence function g(x) for large |x| values is not discussed, potentially leading to practical implementation failures

## Confidence

- **High Confidence**: OGD base case with known λ achieving O(1/√(1-λ)) discounted regret (Theorem 1) is well-established in online optimization literature
- **Medium Confidence**: DNP-cu aggregation mechanism's ability to handle different discount factors (Theorem 2) relies on specific conditions and conservative update rule
- **Medium Confidence**: Uniform regret bound across continuous interval (Theorem 3) follows logically but depends on all lower-level components functioning correctly

## Next Checks

1. **Numerical Stability Test**: Implement the confidence function g(x) with safeguards against overflow in the exponential term. Compare theoretical regret bound with empirical results on synthetic data with varying λ values.

2. **Boundary Condition Analysis**: Test SOGD's performance when λ approaches 1 (very long memory) and when λ approaches 1-1/τ (very short memory). Verify that the uniform bound holds across these extremes.

3. **Cross-Discount-Factor Guarantee**: Construct a controlled experiment with two experts at λ₁ = 0.95 and λ₂ = 0.9. Verify that the Combiner achieves both the λ₁-discounted and λ₂-discounted regret bounds simultaneously, confirming the mechanism in equation (13).