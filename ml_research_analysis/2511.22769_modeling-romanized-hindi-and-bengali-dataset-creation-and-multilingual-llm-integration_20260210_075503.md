---
ver: rpa2
title: 'Modeling Romanized Hindi and Bengali: Dataset Creation and Multilingual LLM
  Integration'
arxiv_id: '2511.22769'
source_url: https://arxiv.org/abs/2511.22769
tags:
- transliteration
- romanized
- hindi
- bengali
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces IndoTranslit, a large-scale dataset and multilingual
  transliteration model for Romanized Hindi and Bengali. The dataset contains over
  2.7 million aligned pairs, including both clean phonetic and noisy user-generated
  Romanized text, making it the largest of its kind for these languages.
---

# Modeling Romanized Hindi and Bengali: Dataset Creation and Multilingual LLM Integration

## Quick Facts
- **arXiv ID:** 2511.22769
- **Source URL:** https://arxiv.org/abs/2511.22769
- **Reference count:** 37
- **Primary result:** IndoTranslit dataset and multilingual transliteration model for Romanized Hindi and Bengali

## Executive Summary
This paper introduces IndoTranslit, a large-scale dataset and multilingual transliteration model for Romanized Hindi and Bengali. The dataset contains over 2.7 million aligned pairs, including both clean phonetic and noisy user-generated Romanized text, making it the largest of its kind for these languages. A compact Marian-based Seq2Seq LLM with 60M parameters is trained using a shared subword vocabulary to handle both languages efficiently. The model achieves strong performance on transliteration benchmarks, with BLEU scores of 77.57 (Hindi) and 77.82 (Bengali), and 73.15 in the multilingual setting, outperforming existing baselines. The work addresses the lack of large-scale, diverse transliteration datasets and models capable of handling informal Romanized script, enabling more accurate downstream NLP applications for Hindi and Bengali speakers.

## Method Summary
The authors created the IndoTranslit dataset by web-crawling and aligning Romanized Hindi and Bengali text with their native script counterparts. The dataset includes both clean phonetic Romanizations and noisy user-generated content. They trained a 60M parameter Marian-based Seq2Seq model using a shared subword vocabulary approach that enables efficient multilingual processing. The model architecture leverages transformer-based sequence-to-sequence learning with byte-pair encoding for vocabulary creation. Training was performed on the full 2.7 million pair dataset, with evaluation on standard transliteration benchmarks.

## Key Results
- IndoTranslit dataset contains over 2.7 million aligned Romanized-to-native script pairs
- Marian-based Seq2Seq model achieves BLEU scores of 77.57 (Hindi) and 77.82 (Bengali)
- Multilingual model achieves 73.15 BLEU, outperforming existing transliteration baselines
- Compact 60M parameter architecture demonstrates efficiency while maintaining high accuracy

## Why This Works (Mechanism)
The shared subword vocabulary approach enables efficient multilingual processing by reducing vocabulary size while maintaining language-specific representations. The large dataset size provides sufficient coverage of both formal and informal Romanization patterns, allowing the model to learn robust mappings between Romanized and native scripts. The Marian framework's efficient implementation enables training of compact models that can handle complex transliteration tasks without excessive computational overhead.

## Foundational Learning
- **Romanization patterns**: Understanding how Hindi and Bengali sounds map to Latin script is essential for creating aligned datasets and evaluating transliteration quality
  - *Why needed*: Forms the basis for dataset creation and model evaluation
  - *Quick check*: Verify that aligned pairs correctly represent phonetic mappings

- **Subword tokenization**: Byte-pair encoding breaks words into subword units that can be shared across languages
  - *Why needed*: Enables compact vocabulary representation and multilingual processing
  - *Quick check*: Confirm that shared vocabulary handles both language-specific characters effectively

- **Seq2Seq architecture**: Transformer-based sequence-to-sequence models learn to map input sequences to output sequences
  - *Why needed*: Core mechanism for learning transliteration mappings
  - *Quick check*: Validate that encoder-decoder attention patterns capture relevant linguistic features

## Architecture Onboarding
**Component Map:** Web crawler -> Data cleaning pipeline -> BPE tokenizer -> 60M Marian Transformer -> BLEU evaluation
**Critical Path:** Dataset creation → Tokenization → Model training → Evaluation
**Design Tradeoffs:** Shared vocabulary reduces memory usage but may sacrifice language-specific optimizations; compact model size enables deployment but may limit generalization
**Failure Signatures:** Poor performance on informal Romanizations indicates insufficient noisy data coverage; multilingual interference suggests vocabulary sharing issues
**First 3 Experiments:**
1. Evaluate model performance on clean vs. noisy Romanized inputs separately
2. Test vocabulary sharing effectiveness by training separate vocabularies for each language
3. Measure model robustness to out-of-vocabulary Romanization patterns

## Open Questions the Paper Calls Out
None

## Limitations
- Dataset construction from web-crawled data may introduce sampling biases and uncharacterized noise
- BLEU scores may not fully capture transliteration quality for informal or phonetic variations
- Multilingual model shows reduced performance compared to monolingual models, suggesting potential interference

## Confidence
- **High Confidence**: Dataset size and general training methodology are well-documented and reproducible
- **Medium Confidence**: Performance metrics on standard benchmarks are reported with appropriate comparisons to baselines
- **Low Confidence**: Claims about handling "informal Romanized script" and model robustness to noise lack systematic validation

## Next Checks
1. Conduct ablation studies removing the noisy user-generated data to quantify its actual contribution to model performance and determine whether it introduces harmful biases or noise
2. Perform human evaluation studies on transliteration quality, particularly focusing on informal and phonetic variations, to validate whether BLEU scores correlate with actual usability
3. Test the model on out-of-domain data and stress-test with adversarial Romanized inputs (intentional misspellings, mixed-script inputs) to assess real-world robustness claims