---
ver: rpa2
title: 'CAMBench-QR : A Structure-Aware Benchmark for Post-Hoc Explanations with QR
  Understanding'
arxiv_id: '2509.16745'
source_url: https://arxiv.org/abs/2509.16745
tags:
- eigengrad-cam
- layercam
- mass
- explanations
- leakage
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CAMBENCH-QR introduces a structure-aware benchmark for evaluating
  class activation maps (CAMs) on QR codes, leveraging their canonical geometry to
  assess whether saliency methods concentrate on essential substructures (finder patterns,
  timing lines) while avoiding background. The benchmark includes synthetic QR/non-QR
  datasets with exact part masks and controlled distortions, alongside metrics like
  finder/timing mass ratios, background leakage, coverage AUCs, and distance-to-structure.
---

# CAMBench-QR : A Structure-Aware Benchmark for Post-Hoc Explanations with QR Understanding

## Quick Facts
- arXiv ID: 2509.16745
- Source URL: https://arxiv.org/abs/2509.16745
- Reference count: 27
- Primary result: Introduces structure-aware benchmark showing EigenGrad-CAM minimizes background leakage while maintaining QR substructure focus.

## Executive Summary
CAMBENCH-QR introduces a structure-aware benchmark for evaluating class activation maps (CAMs) on QR codes, leveraging their canonical geometry to assess whether saliency methods concentrate on essential substructures (finder patterns, timing lines) while avoiding background. The benchmark includes synthetic QR/non-QR datasets with exact part masks and controlled distortions, alongside metrics like finder/timing mass ratios, background leakage, coverage AUCs, and distance-to-structure. Experiments on ResNet-50 and ConvNeXt-B show that EigenGrad-CAM achieves the best structural fidelity with minimal background leakage and low distance-to-structure, especially under fine-tuning with a leakage-minimizing penalty. Last-block fine-tuning alone significantly improves structural alignment, while the penalty further suppresses off-structure mass without collapsing in-QR coverage. These findings demonstrate that lightweight CAMs can be made structurally faithful through targeted adaptation, providing a simple, reproducible framework for structure-aware evaluation of visual explanations.

## Method Summary
The method evaluates post-hoc CAM explanations on QR codes using synthetic datasets with exact structural masks (finder patterns, timing lines, background box). Three training regimes are tested: zero-shot (frozen backbone), fine-tuning last layer only (FT-Struct), and fine-tuning with leakage penalty (FT-LeakMin). The leakage penalty minimizes normalized saliency outside QR boundaries during training. Three CAM methods (LayerCAM, EigenGrad-CAM, XGrad-CAM) are evaluated using structure-aware metrics including finder/timing mass ratios, background leakage, distance-to-structure, and coverage AUCs. The approach combines controlled synthetic data generation with quantitative structural fidelity assessment.

## Key Results
- EigenGrad-CAM achieves lowest background leakage (BL=0.004) and distance-to-structure (DtS=0.170) while maintaining high finder/timing mass ratios
- Last-block fine-tuning alone significantly improves structural alignment (FMR increases from 0.135 to 0.349)
- FT-LeakMin penalty suppresses background leakage without collapsing in-QR coverage when λ≈0.25, α∈[0,0.25]
- LayerCAM provides balanced structure-speed tradeoff; XGrad-CAM is fastest but leakier

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** EigenGrad-CAM's subspace projection reduces background leakage by denoising gradient signals before aggregation.
- **Mechanism:** By projecting gradients onto dominant eigenvectors of the activation space, high-frequency noise in gradient derivatives is suppressed, preventing spurious saliency from accumulating on background textures that correlate with the class label.
- **Core assumption:** Noisy gradient components correspond to non-structural features rather than task-relevant signals.
- **Evidence anchors:** EigenGrad-CAM produces the cleanest maps (BL=0.004, DtS=0.170) by projecting gradients onto dominant directions, damping noisy derivatives.

### Mechanism 2
- **Claim:** Last-block-only fine-tuning reorients high-level features toward canonical structures without introducing texture-sensitive leakage from earlier layers.
- **Mechanism:** The final residual stage (layer4) carries class-level semantics closest to the task; adapting it increases class separability on QR motifs while keeping earlier texture-sensitive filters frozen, preventing them from learning spurious correlations.
- **Core assumption:** Earlier layers encode texture patterns that, if retrained, would overfit to background correlations present in the training distribution.
- **Evidence anchors:** High-level features in the final stage are closest to the task semantics; lightly adapting them should increase class separability. Unfreezing only L4 captures most structural gains while going deeper yields little extra FMR but increases BL.

### Mechanism 3
- **Claim:** A lightweight leakage penalty directly suppresses off-structure mass without collapsing in-QR coverage when balanced with a small pull term.
- **Mechanism:** The FT-LeakMin objective adds λ · ⟨bCθ, M̄B⟩ to the loss, which directly penalizes the normalized fraction of saliency outside the QR box. The optional α term rewards mass inside MB, creating a push-pull dynamic that displaces evidence from background into QR modules.
- **Core assumption:** The Grad-CAM surrogate used during training is sufficiently correlated with the test-time CAM methods for the penalty to transfer.
- **Evidence anchors:** Small λ with α∈[0,0.25] is sufficient to suppress background without collapsing in-QR mass. The penalty term directly penalizes normalized fraction of saliency outside QR boundaries.

## Foundational Learning

- **Concept:** Class Activation Mapping (CAM) and gradient-weighted variants
  - **Why needed here:** The paper assumes familiarity with how CAM methods generate spatial heatmaps from convolutional features, and how gradient-based weighting differs from activation-based approaches.
  - **Quick check question:** Given a 7×7 feature map and class-specific gradients of shape (512,), how would you compute a Grad-CAM heatmap?

- **Concept:** Feature hierarchy and receptive fields in CNNs
  - **Why needed here:** Understanding why layer4 features carry class-level semantics while earlier layers encode textures is essential for interpreting the fine-tuning depth results and the effect of freezing earlier blocks.
  - **Quick check question:** Why does freezing layers 1–3 while fine-tuning layer4 preserve texture filters but allow semantic reorientation?

- **Concept:** Regularization penalties as soft constraints
  - **Why needed here:** The leakage penalty is not a hard mask but a differentiable term in the loss; understanding how λ and α interact requires grasping the tradeoff between constraint strength and optimization dynamics.
  - **Quick check question:** If increasing λ from 0.25 to 1.0 reduces BL but also drops accuracy from 99.5% to 97%, what does this suggest about the penalty's interaction with the classification objective?

## Architecture Onboarding

- **Component map:** ResNet-50/ConvNeXt-B backbone -> CAM explainers (LayerCAM, EigenGrad-CAM, XGrad-CAM) -> Structure-aware metrics (FMR, TMR, BL, DtS, coverage AUCs) -> Causal occlusion tests
- **Critical path:** Generate synthetic QR dataset with masks -> Train classifier under ZS/FT-Struct/FT-LeakMin regimes -> Apply CAM methods at test time -> Compute structure-aware metrics -> Correlate with causal tests
- **Design tradeoffs:**
  - EigenGrad-CAM vs. LayerCAM vs. XGrad-CAM: EigenGrad-CAM offers lowest leakage (~0.002–0.004 BL) with modest latency cost (4.5–5.6 ms); LayerCAM balances structure and speed; XGrad-CAM is fastest (3.8–4.7 ms) but leakier (~0.034–0.061 BL)
  - Fine-tuning depth: Layer4-only yields FMR gains (0.135→0.349) with modest BL (0.012); deeper unfreezing adds little FMR but increases BL substantially
  - Penalty strength (λ, α): λ≈0.25, α∈[0,0.25] suppresses leakage without accuracy loss; higher values show diminishing returns

- **Failure signatures:**
  - High BL (>0.05) with low FMR: Explainer relies on background shortcuts; consider FT-LeakMin or switching to EigenGrad-CAM
  - Low FMR and TMR after fine-tuning: Penalty too aggressive (α too high) or learning rate too low for layer4 adaptation
  - Large gap between ZS and FT metrics: Model was relying on pretrained features misaligned with QR structure; longer fine-tuning may be needed

- **First 3 experiments:**
  1. **Baseline reproduction:** Run ZS inference with all three CAM methods on synthetic test set; verify FMR/TMR/BL/DtS match Table 2 values (±95% CI)
  2. **Ablate fine-tuning depth:** Train head-only, layer4-only, L3–L4, and full backbone variants with CE only; plot FMR vs. BL to confirm layer4 as sweet spot
  3. **Penalty sweep:** With layer4+head trainable, sweep λ∈{0, 0.25, 0.5, 1.0} and α∈{0, 0.25, 0.5}; record BL, FMR, TMR, and accuracy to reproduce Table 6 trends

## Open Questions the Paper Calls Out
- Can the FT-LeakMin training regime and structure-aware metrics generalize to complex domains such as medical imagery or document analysis?
- Do Vision Transformers (ViTs) exhibit similar structural fidelity improvements when fine-tuned with the leakage-minimizing penalty compared to CNNs?
- Does using a Grad-CAM surrogate for the leakage penalty bias the model's features against activation-based CAM methods like LayerCAM?

## Limitations
- Relies on controlled synthetic data with exact ground-truth masks, which may not reflect real-world distributional shifts or dataset biases
- Claims about real-world applicability remain untested without external validation on natural images
- Assumption that dominant eigenvectors suppress background noise is plausible but unverified against scenarios where background shortcuts are encoded in same subspace as true QR features

## Confidence
- **High** for structure-aware metric design and controlled ablation studies
- **Medium** for FT-LeakMin mechanism (untested surrogate correlation assumption)
- **Low** for claims about real-world applicability without external validation

## Next Checks
1. **Real-world transfer test**: Evaluate best-performing CAM-explainer and fine-tuning regime on held-out dataset of real QR codes with occlusions, lighting variations, and partial deformations. Compare FMR/TMR/BL/DtS to synthetic baselines to quantify robustness to distribution shift.

2. **Gradient subspace analysis**: Visualize and correlate dominant eigenvectors of EigenGrad-CAM with background vs. QR mask activations. Confirm that subspace projection actually suppresses non-structural components rather than merely decorrelating them.

3. **Penalty surrogate fidelity check**: Conduct ablation where leakage penalty is computed with each CAM method during training. Measure whether correlation between training surrogate and test-time explainer impacts final structural metrics.