---
ver: rpa2
title: 'MammoDINO: Anatomically Aware Self-Supervision for Mammographic Images'
arxiv_id: '2510.11883'
source_url: https://arxiv.org/abs/2510.11883
tags:
- breast
- tissue
- cancer
- mammodino
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MammoDINO introduces a self-supervised learning framework for mammography
  that addresses the limitations of standard SSL methods, which often focus on irrelevant
  background regions and miss cross-slice anatomical coherence in 3D DBT volumes.
  It incorporates a breast tissue-aware data augmentation sampler that ensures crops
  and masked patches are constrained to clinically meaningful breast tissue, and a
  3D DBT adjacent slice contrastive loss that enforces consistency across neighboring
  slices in DBT volumes.
---

# MammoDINO: Anatomically Aware Self-Supervision for Mammographic Images

## Quick Facts
- **arXiv ID:** 2510.11883
- **Source URL:** https://arxiv.org/abs/2510.11883
- **Reference count:** 0
- **Primary result:** MammoDINO outperforms DINOv2, RadDINO, BiomedCLIP, and MammoCLIP on five mammography benchmark datasets.

## Executive Summary
MammoDINO introduces a self-supervised learning framework for mammography that addresses the limitations of standard SSL methods, which often focus on irrelevant background regions and miss cross-slice anatomical coherence in 3D DBT volumes. It incorporates a breast tissue-aware data augmentation sampler that ensures crops and masked patches are constrained to clinically meaningful breast tissue, and a 3D DBT adjacent slice contrastive loss that enforces consistency across neighboring slices in DBT volumes. Pretrained on 1.4 million mammographic images, MammoDINO outperforms state-of-the-art baselines including DINOv2, RadDINO, BiomedCLIP, and MammoCLIP across five benchmark datasets on tasks such as cancer detection, lesion detection, BIRADS score prediction, and breast density classification. For example, on the VinDr dataset, it achieves AUC of 0.918 for cancer detection and 0.712 for lesion detection, with ablation studies showing consistent performance gains from both innovations.

## Method Summary
MammoDINO is a self-supervised learning framework for mammography that combines two key innovations: a breast tissue-aware data augmentation sampler and a 3D DBT adjacent slice contrastive loss. The sampler ensures that random crops and masked patches are extracted only from clinically relevant breast tissue regions, avoiding irrelevant background areas. The contrastive loss enforces consistency between adjacent slices in 3D DBT volumes, leveraging cross-slice anatomical coherence. The model is pretrained on a large-scale dataset of 1.4 million mammographic images and demonstrates superior performance on downstream tasks including cancer detection, lesion detection, BIRADS score prediction, and breast density classification.

## Key Results
- Achieves AUC of 0.918 for cancer detection and 0.712 for lesion detection on the VinDr dataset.
- Outperforms DINOv2, RadDINO, BiomedCLIP, and MammoCLIP across five benchmark datasets.
- Ablation studies confirm consistent performance gains from both breast tissue-aware sampling and 3D DBT contrastive loss.

## Why This Works (Mechanism)
MammoDINO improves upon standard self-supervised learning by focusing on anatomically relevant regions and leveraging 3D coherence in DBT volumes. The breast tissue-aware sampler prevents the model from learning from irrelevant background, ensuring that learned features are clinically meaningful. The 3D DBT adjacent slice contrastive loss exploits the natural continuity of breast anatomy across slices, improving representation quality for 3D mammography tasks.

## Foundational Learning
- **Breast tissue segmentation**: Required to accurately identify and crop relevant regions; quick check: segmentation accuracy on diverse image qualities.
- **Contrastive learning**: Core to enforcing consistency between adjacent slices; quick check: stability of learned representations across augmentations.
- **Self-supervised pretraining**: Enables learning from unlabeled data; quick check: downstream task performance versus supervised baselines.
- **3D volume processing**: Critical for leveraging cross-slice information; quick check: handling of varying slice thicknesses and orientations.

## Architecture Onboarding

**Component map:** Image input → Breast tissue segmentation → Tissue-aware sampler → Masked patch extraction → Encoder → Contrastive loss (2D) + Adjacent slice contrastive loss (3D) → Representation output

**Critical path:** Image → Segmentation → Sampler → Encoder → Contrastive loss → Pretrained model

**Design tradeoffs:** 
- Tradeoff between segmentation accuracy and computational overhead in tissue-aware sampling.
- Balance between 2D and 3D contrastive losses for mixed dataset types.

**Failure signatures:**
- Poor segmentation leads to irrelevant patches being sampled.
- Inaccurate adjacent slice alignment degrades 3D contrastive loss effectiveness.

**First experiments:**
1. Evaluate tissue segmentation accuracy on heterogeneous image qualities.
2. Compare 2D versus 3D contrastive loss contributions on DBT versus 2D mammography.
3. Test model robustness to varying image resolutions and noise levels.

## Open Questions the Paper Calls Out
None

## Limitations
- Requires large-scale curated mammography datasets (1.4 million images), limiting reproducibility in data-scarce settings.
- Performance depends on accurate breast tissue segmentation, with unclear robustness to heterogeneous clinical image qualities.
- Gains from 3D DBT coherence may not fully transfer to standard 2D mammography.

## Confidence
- **High confidence** in the overall performance improvement over baselines, supported by strong quantitative results across five datasets.
- **Medium confidence** in the generalization of 3D DBT gains to 2D mammography due to limited 2D-specific evaluation.
- **Medium confidence** in the clinical utility, as the paper focuses on technical benchmarks without extensive real-world deployment evidence.

## Next Checks
1. Conduct ablation studies isolating the effects of the breast tissue-aware sampler versus the 3D DBT contrastive loss on both 2D and 3D mammography tasks.
2. Test model robustness to varying image qualities, including low-resolution or noisy clinical images, to assess real-world applicability.
3. Compare MammoDINO against the latest SSL methods (e.g., MAE, SimMIM) to confirm sustained performance advantages.