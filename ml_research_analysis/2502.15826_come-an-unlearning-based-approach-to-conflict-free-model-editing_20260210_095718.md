---
ver: rpa2
title: 'CoME: An Unlearning-based Approach to Conflict-free Model Editing'
arxiv_id: '2502.15826'
source_url: https://arxiv.org/abs/2502.15826
tags:
- knowledge
- editing
- outdated
- arxiv
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of knowledge conflicts in large
  language model (LLM) editing, where outdated information interferes with new knowledge
  during editing. The authors propose Conflict-free Model Editing (CoME), a framework
  that leverages unlearning to selectively remove outdated knowledge while simultaneously
  integrating new information.
---

# CoME: An Unlearning-based Approach to Conflict-free Model Editing

## Quick Facts
- arXiv ID: 2502.15826
- Source URL: https://arxiv.org/abs/2502.15826
- Reference count: 20
- The paper proposes CoME, a framework that improves knowledge editing in LLMs by leveraging unlearning to mitigate conflicts between outdated and new knowledge.

## Executive Summary
CoME addresses knowledge conflicts in large language model editing by using unlearning to selectively remove outdated information while integrating new knowledge. The framework works by extracting parameters associated with outdated knowledge, performing targeted unlearning during knowledge updates, and restricting the unlearning process to critical parameters. Experiments on GPT-J and LLaMA-3 show that applying CoME to existing editing methods significantly improves editing accuracy and model reliability while maintaining generative performance.

## Method Summary
CoME is a conflict-mitigation framework that enhances existing knowledge editing methods (MEMIT and PMET) by incorporating an unlearning stage. The approach extracts parameters associated with outdated knowledge through a separate optimization step, then performs targeted unlearning during the knowledge update process. The unlearning is restricted to the most influential parameters to preserve unrelated knowledge. CoME uses fixed hyperparameters (α=0.1, p=20%) and requires additional computational overhead compared to traditional editing techniques.

## Key Results
- CoMEPMET achieves 89.4% efficacy and 83.1% generality on GPT-J with ZsRE dataset
- Applying CoME to MEMIT and PMET improves both efficacy and generality while maintaining locality
- The method successfully suppresses interference from outdated knowledge during inference
- Ablation studies confirm the necessity of each component (δ′ subtraction, δ′′ preservation, restriction)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Removing outdated knowledge parameters reduces interference during inference.
- Mechanism: Compute δ′ (outdated knowledge update vector) using the same optimization as new knowledge, then subtract it from the updated hidden state z. This reduces competition between old and new representations.
- Core assumption: Outdated and new knowledge occupy overlapping parameter regions that compete during generation.
- Evidence anchors:
  - [abstract] "CoME leverages unlearning to mitigate knowledge interference, allowing new information to be integrated without compromising relevant linguistic features."
  - [section 4.1] "By performing zi − δ′i, we aim to remove the portions of the parameters updated with new knowledge that still contain outdated information."
  - [corpus] Weak direct evidence; related work on knowledge editing (e.g., "Latent Knowledge Scalpel") confirms interference challenges but does not validate subtraction-based unlearning.
- Break condition: If outdated and new knowledge are stored in largely non-overlapping parameter regions, subtraction yields minimal benefit.

### Mechanism 2
- Claim: Preserving shared linguistic features maintains generation quality.
- Mechanism: Extract common direction δ⃗ = δ/|δ| + δ′/|δ′|, then project δ′ onto this direction to isolate shared components δ′′. Only subtract (δ′ − δ′′), preserving linguistic capacity.
- Core assumption: Both update vectors encode task-agnostic linguistic features proportional to their magnitudes.
- Evidence anchors:
  - [section 4.1] "both vectors inherently include the linguistic capacity necessary for the model to generate correct responses based on this information."
  - [Table 3] Removing δ′′ degrades Locality significantly (73.2→69.6 for CoMEMEMIT).
  - [corpus] No corpus papers validate this specific projection technique.
- Break condition: If linguistic features are not linearly recoverable via normalized addition, this extraction fails.

### Mechanism 3
- Claim: Restricting unlearning to top-p% parameters preserves unrelated knowledge.
- Mechanism: Apply unlearning only to parameters where |δ′ − δ′′| is in top-p% (p=20). This localizes changes to parameters most associated with outdated knowledge.
- Core assumption: Outdated knowledge is concentrated in a sparse subset of parameters, identifiable by update magnitude.
- Evidence anchors:
  - [section 4.3] "we confirm that unlearning outdated knowledge negatively affects Locality. To address this... we limit the scope of unlearning to only the parameters most influenced by outdated knowledge."
  - [Table 3] Removing restriction drops Locality from 73.2 to 68.9 for CoMEMEMIT.
  - [corpus] "Edit Less, Achieve More" (arXiv:2510.22139) similarly finds sparse neuron masking effective for lifelong editing.
- Break condition: If outdated knowledge is distributed broadly across parameters, top-p% selection may miss critical weights.

## Foundational Learning

- Concept: **Locate-and-Edit Methods (MEMIT/PMET)**
  - Why needed here: CoME operates as a modification to existing locate-and-edit approaches, assuming familiarity with how these methods compute and distribute layer updates.
  - Quick check question: Can you explain how MEMIT uses covariance matrices to distribute updates across layers?

- Concept: **Machine Unlearning via Gradient Ascent**
  - Why needed here: CoME's subtraction-based approach is conceptually related to unlearning methods that reverse learned associations; understanding unlearning objectives clarifies the design intent.
  - Quick check question: How does gradient ascent differ from weight subtraction as an unlearning mechanism?

- Concept: **Efficacy/Generality/Locality Tradeoffs in Model Editing**
  - Why needed here: CoME explicitly trades Locality for improved Efficacy and Generality; evaluating results requires understanding these metrics.
  - Quick check question: Why might improving generality for edited knowledge harm locality for unrelated knowledge?

## Architecture Onboarding

- Component map:
  - Input: Knowledge triple (s, r, o) → (s, r, o*), prompt xi
  - Baseline Editor: MEMIT or PMET computes δi and distributes updates to target layers
  - Outdated Vector Module: Computes δ′i using Equation 5 with original object o
  - Common Feature Extractor: Normalizes and adds vectors, projects to extract δ′′i (Equations 7-8)
  - Unlearning Applicator: Computes z′i = zi − α(δ′i − δ′′i) with restriction mask (Equations 9-10)
  - Output: Modified parameters θ* for edited model

- Critical path:
  1. Run baseline edit to obtain δi and updated hidden state zi
  2. Compute δ′i by optimizing for outdated object (requires forward/backward pass)
  3. Extract δ′′i via vector projection
  4. Apply restricted subtraction to z′i
  5. Distribute final updates via baseline method's layer allocation

- Design tradeoffs:
  - α controls unlearning strength; higher α improves Efficacy/Generality but degrades Locality (paper uses α=0.1)
  - p controls sparsity; p=20 balances removal effectiveness vs. collateral damage
  - CoME adds computational overhead (additional optimization for δ′i)

- Failure signatures:
  - Locality drops sharply: α too high or p too large; reduce unlearning intensity
  - Efficacy doesn't improve: Outdated knowledge not effectively isolated; check δ′i computation
  - Fluency degrades: Common feature extraction failing; verify normalization in Equation 7

- First 3 experiments:
  1. Reproduce MEMIT baseline on 100 Counterfact samples, verify Efficacy/Generality/Locality match Table 1
  2. Add only δ′ subtraction (no δ′′ preservation), observe Locality degradation per ablation results
  3. Sweep α ∈ {0.05, 0.1, 0.2} on 1000 samples, plot Efficacy vs. Locality tradeoff curve

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the framework be adapted to preserve temporal knowledge validity while still removing genuinely incorrect information?
- Basis in paper: [explicit] The Limitations section states, "CoME is designed to remove outdated or false knowledge, which may not always be desirable in cases of temporal knowledge."
- Why unresolved: The current method treats "outdated" information (e.g., a previous CEO) as noise to be unlearned, potentially erasing valid historical context.
- What evidence would resolve it: Evaluation on temporal datasets where the model must answer questions about both the updated fact and the historical reality correctly.

### Open Question 2
- Question: Can the required computational overhead be reduced without compromising the conflict-mitigation benefits of the unlearning stage?
- Basis in paper: [explicit] The Limitations section notes, "The unlearning process requires additional computational resources... it incurs higher computational costs than traditional model editing techniques."
- Why unresolved: CoME introduces a separate optimization step to extract outdated parameters ($\delta'$), adding latency and resource usage compared to single-pass editing methods.
- What evidence would resolve it: A modified algorithm that approximates the outdated parameter vector with significantly lower latency or FLOPs while maintaining Efficacy scores.

### Open Question 3
- Question: Is it possible to dynamically determine the optimal unlearning weight ($\alpha$) and scope (top-p%) to minimize the trade-off with Locality?
- Basis in paper: [inferred] Section 5.3 and Figure 3 show that increasing unlearning weight improves Efficacy/Generality but strictly decreases Locality.
- Why unresolved: The paper relies on empirically fixed hyperparameters ($\alpha=0.1$, $p=20$); a static setting may be sub-optimal for different types of knowledge relations.
- What evidence would resolve it: An adaptive mechanism that adjusts unlearning intensity per edit, resulting in a Pareto improvement where Locality does not degrade as Efficacy rises.

## Limitations
- The unlearning process requires additional computational resources, incurring higher costs than traditional model editing techniques
- The method is designed to remove outdated or false knowledge, which may not be desirable in cases of temporal knowledge
- The approach may not generalize well to knowledge editing scenarios outside factual knowledge domains

## Confidence

**High confidence**: The experimental methodology and metric definitions are clearly specified. The ablation studies demonstrating the necessity of each component (δ′ subtraction, δ′′ preservation, restriction) are well-structured.

**Medium confidence**: The core mechanism of subtraction-based unlearning is plausible and aligns with related work, but the specific implementation details (vector projection for feature extraction) lack external validation.

**Low confidence**: The generalization of results to other knowledge editing scenarios or larger models remains untested. The paper only evaluates on two specific datasets and two model architectures.

## Next Checks

1. **Parameter Space Analysis**: Map the distribution of outdated vs. new knowledge in parameter space using t-SNE or similar visualization to verify the competing-region assumption.

2. **Cross-Dataset Generalization**: Apply CoME to a knowledge editing task outside the factual knowledge domain (e.g., stylistic editing or task-specific fine-tuning) to test broader applicability.

3. **Ablation of Projection Mechanism**: Replace the vector projection approach with an alternative feature extraction method (e.g., attention-based or sparse coding) to test whether the specific projection is critical to success.