---
ver: rpa2
title: 'Making AI-Enhanced Videos: Analyzing Generative AI Use Cases in YouTube Content
  Creation'
arxiv_id: '2503.03134'
source_url: https://arxiv.org/abs/2503.03134
tags:
- video
- genai
- videos
- content
- tools
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study analyzed 274 YouTube how-to videos to understand how
  content creators use generative AI tools across the video production process. Using
  thematic analysis of video transcripts, the research identified specific use cases
  for AI across four phases: planning (e.g., scriptwriting, topic identification),
  production (e.g., prompt refinement, AI-generated visuals/audio), editing (e.g.,
  upscaling, lip-syncing), and uploading (e.g., subtitle generation, title suggestions).'
---

# Making AI-Enhanced Videos: Analyzing Generative AI Use Cases in YouTube Content Creation
## Quick Facts
- arXiv ID: 2503.03134
- Source URL: https://arxiv.org/abs/2503.03134
- Reference count: 31
- This study analyzed 274 YouTube how-to videos to understand how content creators use generative AI tools across the video production process

## Executive Summary
This study examined 274 YouTube how-to videos to identify how content creators use generative AI tools throughout the video production process. Through thematic analysis of video transcripts, the research identified specific AI use cases across four phases: planning (scriptwriting, topic identification), production (prompt refinement, AI-generated visuals/audio), editing (upscaling, lip-syncing), and uploading (subtitle generation, title suggestions). The findings reveal that 31% of videos use AI for scripting, 60.9% for generating visuals/videos, 33.9% for voiceovers, and 10.2% for adding subtitles. The study provides a conceptual framework mapping these use cases and discusses future research directions for supporting creators with AI tools while maintaining originality and authenticity in content creation.

## Method Summary
The research team collected 3,854 YouTube videos using specific search queries related to AI video creation, then manually filtered to 274 how-to videos that demonstrated generative AI capabilities and outputs. Three annotators independently reviewed videos against criteria requiring demonstration of GenAI tool steps, generative AI features, and video content output. Transcripts were segmented using ChatGPT, and thematic analysis was conducted through affinity diagramming and dual-annotator labeling. Inter-annotator agreement ranged from 0.51 to 0.64 across phases, with Cohen's kappa used as the reliability metric.

## Key Results
- 31% of videos use AI for scripting and 60.9% for generating visuals/videos
- 33.9% of videos use AI for voiceovers and 10.2% for adding subtitles
- Identified specific use cases across four production phases: planning, production, editing, and uploading

## Why This Works (Mechanism)
None

## Foundational Learning
- **Thematic Analysis**: Qualitative research method for identifying patterns in textual data; needed to systematically categorize GenAI use cases from unstructured video transcripts
- **Cohen's Kappa**: Statistical measure of inter-rater reliability; needed to validate consistency between annotators during manual coding
- **YouTube Data API**: Platform interface for programmatic video search and metadata retrieval; needed to efficiently collect large video corpus for analysis
- **Closed Captions**: Text transcripts of spoken content; needed as primary data source for analyzing content creator instructions and techniques
- **Affinity Diagramming**: Method for organizing qualitative data into categories; needed to develop initial codebook from thematic patterns in video transcripts

## Architecture Onboarding
- **Component Map**: YouTube Data API -> Manual Filtering -> ChatGPT Segmentation -> Thematic Analysis -> Use Case Categorization
- **Critical Path**: Data Collection -> Video Filtering -> Transcript Processing -> Annotation & Analysis -> Framework Development
- **Design Tradeoffs**: Large-scale automated collection balanced against manual verification to ensure quality; broad search terms captured diverse use cases but required extensive filtering
- **Failure Signatures**: Low inter-annotator agreement (κ=0.51) indicates unclear use case definitions; inconsistent transcript segmentation suggests prompt refinement needed
- **First Experiments**:
  1. Test YouTube Data API query with different time ranges to assess temporal patterns in GenAI adoption
  2. Run manual filtering on 20 random videos to validate exclusion criteria consistency
  3. Apply thematic analysis to 10 video transcripts to test codebook effectiveness

## Open Questions the Paper Calls Out
None

## Limitations
- Moderate inter-annotator agreement (κ=0.51-0.64) suggests reliability concerns, particularly for the uploading phase
- Manual filtering process introduces potential selection bias with unspecified exclusion criteria
- Exclusive focus on how-to videos limits generalizability to broader YouTube content creation practices

## Confidence
- Claim that 60.9% of videos use AI for generating visuals/videos: **High confidence**
- Identification of specific use cases across production phases: **High confidence**
- Generalizability of findings beyond how-to videos: **Low confidence**

## Next Checks
1. Replicate the filtering process with 10% random sample to verify exclusion criteria consistency
2. Calculate inter-annotator agreement on an additional 20 videos to assess reliability stability
3. Compare use case distributions between how-to videos and general YouTube content to test generalizability assumptions