---
ver: rpa2
title: Subgoaling Relaxation-based Heuristics for Numeric Planning with Infinite Actions
arxiv_id: '2512.22367'
source_url: https://arxiv.org/abs/2512.22367
tags:
- numeric
- planning
- control
- problem
- variables
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles numeric planning with control parameters, where
  action parameters are free numeric variables leading to infinitely many applicable
  actions per state. Standard numeric heuristics fail because they can't handle this
  infinite action space.
---

# Subgoaling Relaxation-based Heuristics for Numeric Planning with Infinite Actions

## Quick Facts
- arXiv ID: 2512.22367
- Source URL: https://arxiv.org/abs/2512.22367
- Reference count: 8
- Primary result: Signature compilation-based heuristics (haddΣ and hmrpΣ) solve 261 out of 280 numeric planning problems with infinite actions, significantly outperforming blind search and goal-counting heuristics.

## Executive Summary
This paper addresses numeric planning problems with control parameters, where action parameters are free numeric variables creating infinitely many applicable actions per state. Standard numeric heuristics fail in this setting because they cannot handle the infinite action space. The authors propose an optimistic compilation that transforms controllable simple numeric problems into tractable simple numeric tasks by abstracting control-dependent expressions into bounded constant effects and relaxed preconditions. They prove this compilation is safe-pruning under the subgoaling relaxation, enabling the use of existing numeric subgoaling heuristics. Experiments on seven domains show the signature compilation-based heuristics solve 261 out of 280 problems, significantly outperforming blind search and goal-counting heuristics.

## Method Summary
The approach introduces an optimistic compilation that transforms numeric planning problems with control parameters into tractable simple numeric planning tasks. The compilation abstracts control-dependent expressions in effects to their extreme (minimum/maximum) valuations using closed interval arithmetic, and relaxes preconditions to lower bounds. This creates a finite superset of behaviors that over-approximates the original problem. The signature compilation further reduces complexity by computing sign choices for each action-condition pair and collapsing signatures by removing irrelevant effect entries. The compiled problems enable direct application of subgoaling relaxation heuristics (h_add, h_mrp) as safe-pruning estimators. The approach uses DPEX search with logarithmic rectification and uniform sampling over control variable domains.

## Key Results
- Signature compilation-based heuristics solve 261 out of 280 problems across seven domains
- h_add^Σ and h_mrp^Σ significantly outperform blind search and goal-counting heuristics (h_mgc)
- The compilation maintains safe-pruning guarantees under subgoaling relaxation
- Polynomial complexity bounds are achieved through signature collapse (Proposition 2)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Optimistic compilation transforms infinite action spaces into finite simple numeric planning problems while preserving solvability.
- Mechanism: Control-dependent expressions in effects are abstracted to their extreme (minimum/maximum) valuations computed via closed interval arithmetic; preconditions are relaxed to lower bounds. This creates a finite superset of behaviors that over-approximates the original problem.
- Core assumption: Conditions are linear with respect to state variables, and effects depend only on control variables (controllable-simple numeric problems).
- Evidence anchors:
  - [abstract] "abstract control-dependent expressions into bounded constant effects and relaxed preconditions"
  - [section: Optimistic Compilation, Definition 6] Formal definition of compilation with extreme valuations
  - [corpus] Weak/missing—no direct corpus validation of this specific compilation technique
- Break condition: If effects are non-linear with respect to control variables, interval arithmetic bounds may not be tight, breaking the tractability guarantee.

### Mechanism 2
- Claim: Signature compilation reduces exponential action set explosion to polynomial size while preserving safe-pruning.
- Mechanism: For each action-condition pair, compute the "sign choice"—select the bound (upper/lower) of each effect expression that contributes positively to that condition's achievement. Collapse signatures by removing irrelevant effect entries, merging equivalent instantiations.
- Core assumption: Only actions with positive net effect on at least one goal-relevant condition need preservation.
- Evidence anchors:
  - [section: Reducing Complexity, Definition 7-8] Sign choice function and signature compilation formalized
  - [section: Proposition 2] Proves |A_Σ| ≤ |A| · |Ψ| (polynomial bound)
  - [corpus] No direct corpus evidence; this is a novel contribution
- Break condition: If many conditions involve conflicting sign requirements for the same effect, signature collapse fails and cardinality approaches optimistic compilation size.

### Mechanism 3
- Claim: Compiled problems enable direct application of subgoaling relaxation heuristics (h_add, h_mrp) as safe-pruning estimators.
- Mechanism: The compilation preserves the subgoaling relaxation property—theorem proves that if original problem has solution, compiled relaxation also has solution. m-times regressor can then identify possible achievers in closed form because compiled actions have constant effects.
- Core assumption: The relaxation remains proper (over-approximating) after compilation.
- Evidence anchors:
  - [section: Theorem 2] Proves Π_P ≠ ∅ ⟹ Π_P¹_O ≠ ∅ (safe-pruning under subgoaling)
  - [section: Experiments, Table 2] h_Σ solves 261/280 problems vs 181 for h_mgc
  - [corpus] Neighbor paper "Lifted Successor Generation" addresses grounding but not this compilation-heuristic pipeline
- Break condition: Over-approximation may commit too aggressively to infeasible actions when control variables participate in many constraints (observed in DRONE, PROCUREMENT domains).

## Foundational Learning

- Concept: **Interval arithmetic for expression bounds**
  - Why needed here: Core mechanism for computing extreme valuations of control-dependent expressions without exhaustive enumeration.
  - Quick check question: Given Dom(u₁)=[1,3] and Dom(u₂)=[0,2], what is Dom(2u₁ - u₂)?

- Concept: **Subgoaling relaxation and m-times regressor**
  - Why needed here: Heuristic computation relies on regressing conditions to identify possible achievers; requires understanding how numeric conditions propagate backwards through linear effects.
  - Quick check question: For condition x > 10 and effect x += 5, how many action repetitions (m) are needed to achieve the condition from state x=2?

- Concept: **Net effect of actions on conditions**
  - Why needed here: Sign choice function depends on computing whether an effect contributes positively or negatively to a condition's achievement.
  - Quick check question: For condition 3x + 2y > 15 and effect (x+=ξ₁, y+=ξ₂), what is the net effect expression?

## Architecture Onboarding

- Component map: Problem parser → Verify controllable-simple → Signature compiler → Heuristic engine → DPEX search
- Critical path: Problem parsing → Verify controllable-simple → Signature compilation → Heuristic setup (~15ms) → DPEX with 5 samples per expansion
- Design tradeoffs:
  - h_add^Σ: Faster, overestimates cost, better when compilation underestimation "balances" heuristic overestimation
  - h_mrp^Σ: More accurate cost estimation via multi-repetition merging, but may fail where overestimation was beneficial
  - Uniform sampling over hypercube vs direct polytope sampling (current: rejection sampling; future: direct polytope)
- Failure signatures:
  - Coverage drops in domains with many control variables or constraint-heavy preconditions (DRONE: 13/20 with h_Σ vs 20/20 in COUNT-D)
  - h_mrp^Σ underperforms h_add^Σ when redundancy correction masks compilation over-approximation (PROCUREMENT, TERRARIA)
  - Timeout correlates with partial expansion count > 1000 in dead-end heavy domains
- First 3 experiments:
  1. **Signature compilation overhead**: Measure |A| vs |A_Σ| vs |A_O| on target domain; verify polynomial scaling with |Ψ|
  2. **Heuristic comparison**: Run h_add^Σ vs h_mrp^Σ vs h_mgc on 20-problem benchmark per domain; plot coverage vs time
  3. **Sampling sensitivity**: Vary K (samples per expansion) from 1 to 10; observe impact on coverage and plan length

## Open Questions the Paper Calls Out
None

## Limitations
- The approach relies on linear control-dependent expressions; non-linear effects could break interval arithmetic bounds and invalidate safe-pruning guarantees
- Optimistic compilation's over-approximation may commit too aggressively to infeasible actions in domains with many constraints
- Current sampling approach (uniform hypercube) is naive and may waste evaluations on infeasible parameter regions

## Confidence
- **High confidence** in the compilation mechanism and safe-pruning theorem: The interval arithmetic bounds and signature collapse are formally proven, with polynomial complexity guarantees (Proposition 2).
- **Medium confidence** in empirical effectiveness: While the 261/280 coverage is strong, the methodology has only been tested on seven domains, and performance drops significantly in constraint-heavy domains (DRONE, PROCUREMENT).
- **Low confidence** in scalability: The approach's behavior with hundreds of control variables or highly non-linear effects remains untested, and the sampling strategy may not scale efficiently.

## Next Checks
1. **Stress test compilation bounds**: Evaluate signature compilation on synthetic domains with quadratic/cubic control-dependent effects to verify interval arithmetic remains tractable and safe-pruning holds.
2. **Direct polytope sampling evaluation**: Replace uniform hypercube sampling with direct polytope sampling for the control variable space; measure impact on coverage and evaluation efficiency.
3. **Cross-validation with non-linear planners**: Compare compiled problem performance against specialized planners (e.g., Lifted Successor Generation) on domains with mixed linear/non-linear effects to identify compilation's edge cases.