---
ver: rpa2
title: Large Language Models for Real-World IoT Device Identification
arxiv_id: '2510.13817'
source_url: https://arxiv.org/abs/2510.13817
tags:
- vendor
- device
- devices
- accuracy
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of IoT device identification
  in real-world, open-set environments where network metadata is often incomplete,
  noisy, or intentionally obfuscated. The authors reframe device identification as
  a language modeling task over heterogeneous network metadata, using large language
  models (LLMs) to generate high-fidelity vendor pseudolabels from the IoT Inspector
  dataset.
---

# Large Language Models for Real-World IoT Device Identification
## Quick Facts
- arXiv ID: 2510.13817
- Source URL: https://arxiv.org/abs/2510.13817
- Reference count: 40
- Key outcome: Reframing IoT device identification as a language modeling task over heterogeneous network metadata using LLMs to generate high-fidelity vendor pseudolabels

## Executive Summary
This paper presents a novel approach to IoT device identification using large language models (LLMs) by reframing the task as language modeling over heterogeneous network metadata. The authors develop a method to generate high-fidelity vendor pseudolabels from the IoT Inspector dataset and instruction-tune a quantized LLaMA 3.1 8B model using curriculum learning. Their approach achieves 98.25% top-1 accuracy and 90.73% macro accuracy across 2,015 vendors, demonstrating resilience to missing fields, protocol drift, and adversarial manipulation. The model is validated on an independent IoT testbed, providing a scalable and interpretable foundation for real-world IoT device identification at scale.

## Method Summary
The authors reframe IoT device identification as a language modeling task over heterogeneous network metadata. They use the IoT Inspector dataset to generate high-fidelity vendor pseudolabels, then instruction-tune a quantized LLaMA 3.1 8B model using curriculum learning. The approach leverages the LLM's ability to process heterogeneous metadata as natural language, enabling identification across diverse network conditions and device types. The curriculum learning strategy helps the model progressively learn from simpler to more complex identification tasks, improving generalization and robustness.

## Key Results
- Achieves 98.25% top-1 accuracy and 90.73% macro accuracy across 2,015 vendors
- Demonstrates resilience to missing fields, protocol drift, and adversarial manipulation
- Validated on an independent IoT testbed, confirming real-world applicability

## Why This Works (Mechanism)
The approach works by leveraging LLMs' natural language processing capabilities to interpret heterogeneous network metadata as text. By treating device identification as a language modeling task, the model can capture complex patterns and relationships in network traffic that traditional rule-based or machine learning approaches might miss. The curriculum learning approach allows the model to build understanding progressively, starting with simpler identification tasks and advancing to more complex scenarios, resulting in better generalization and robustness to real-world network conditions.

## Foundational Learning
- **Language Modeling for Classification**: Why needed - To leverage LLMs' pattern recognition capabilities for non-text data; Quick check - Verify the model can correctly identify text patterns before applying to metadata
- **Curriculum Learning**: Why needed - To progressively build model understanding from simple to complex tasks; Quick check - Monitor performance improvements across curriculum stages
- **Heterogeneous Metadata Processing**: Why needed - To handle diverse network data formats and structures; Quick check - Test model performance with different metadata field combinations
- **Quantized Model Optimization**: Why needed - To enable deployment on resource-constrained edge devices; Quick check - Compare accuracy between full and quantized model versions
- **Adversarial Robustness**: Why needed - To ensure reliable identification under malicious conditions; Quick check - Test model against controlled adversarial scenarios
- **Vendor Pseudolabel Generation**: Why needed - To create high-quality training data from existing datasets; Quick check - Validate pseudolabel accuracy against ground truth

## Architecture Onboarding
**Component Map**: Network Metadata -> Language Model Encoder -> Feature Extraction -> Classification Head -> Vendor Prediction
**Critical Path**: The critical path flows from raw network metadata through the language model encoder, where the heterogeneous data is transformed into a unified representation. This representation then flows through feature extraction layers and into the classification head for final vendor prediction.
**Design Tradeoffs**: The use of quantized models enables edge deployment but may sacrifice some accuracy. Curriculum learning improves generalization but increases training complexity. The language modeling approach provides flexibility but requires significant computational resources during training.
**Failure Signatures**: Performance degradation may occur with novel obfuscation techniques, extreme protocol drift, or when encountering device types significantly different from training data. Model may struggle with edge deployment if quantization artifacts are too severe.
**First Experiments**:
1. Test model accuracy on controlled metadata variations to establish baseline performance
2. Evaluate model resilience to missing metadata fields using ablation studies
3. Assess quantization impact by comparing full vs. quantized model performance on representative hardware

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Potential overfitting to IoT Inspector dataset patterns may limit generalization to all real-world deployments
- Performance under extreme adversarial conditions or novel obfuscation techniques remains untested beyond limited scenarios
- Reliance on quantized models may introduce fidelity losses affecting identification accuracy in edge deployments

## Confidence
- Claim: 98.25% top-1 accuracy and 90.73% macro accuracy across 2,015 vendors - Medium confidence (requires validation on more diverse datasets)
- Claim: Resilience to missing fields, protocol drift, and adversarial manipulation - Medium confidence (current validation focuses on controlled testbeds)
- Claim: Scalable and interpretable foundation for real-world IoT identification - High confidence (strong empirical results support this)

## Next Checks
1. Evaluate the model on a larger, more diverse set of real-world IoT deployments across different geographic regions and network architectures to assess generalization.
2. Conduct adversarial testing with more sophisticated manipulation techniques, including protocol-level obfuscation and metadata injection attacks.
3. Implement the quantized LLaMA 3.1 8B model on edge devices with limited computational resources to verify performance degradation and identify potential bottlenecks.