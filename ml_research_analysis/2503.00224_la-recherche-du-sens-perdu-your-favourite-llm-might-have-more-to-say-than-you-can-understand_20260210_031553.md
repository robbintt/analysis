---
ver: rpa2
title: "\xC0 la recherche du sens perdu: your favourite LLM might have more to say\
  \ than you can understand"
arxiv_id: '2503.00224'
source_url: https://arxiv.org/abs/2503.00224
tags:
- arxiv
- https
- sonnet
- claude-3
- gpt-4o
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Large language models can understand and execute instructions written
  in sequences of seemingly incomprehensible Unicode symbols, such as Byzantine musical
  symbols. This ability, observed across a diverse set of models (Claude-3.5 Haiku,
  Claude-3.5 Sonnet, Claude-3.7 Sonnet, GPT-4o-mini, GPT-4o, o1-mini, Llama-3.3 70B,
  DeepSeek-R1-Distill-Llama 70B, Qwen2.5 1.5B/32B, Phi-3.5 mini, GigaChat-Max, Vikhr-Llama-3.2
  1B), is hypothesized to stem partly from BPE tokenization artifacts.
---

# Ã€ la recherche du sens perdu: your favourite LLM might have more to say than you can understand

## Quick Facts
- **arXiv ID**: 2503.00224
- **Source URL**: https://arxiv.org/abs/2503.00224
- **Reference count**: 40
- **Primary result**: Large language models can understand and execute instructions written in sequences of seemingly incomprehensible Unicode symbols

## Executive Summary
This paper reveals that large language models can understand and execute instructions written in sequences of seemingly incomprehensible Unicode symbols, such as Byzantine musical symbols. The phenomenon was observed across a diverse set of models including Claude-3.5 Haiku, Claude-3.5 Sonnet, Claude-3.7 Sonnet, GPT-4o-mini, GPT-4o, o1-mini, Llama-3.3 70B, DeepSeek-R1-Distill-Llama 70B, Qwen2.5 1.5B/32B, Phi-3.5 mini, GigaChat-Max, and Vikhr-Llama-3.2 1B. The ability is hypothesized to stem partly from BPE tokenization artifacts, where certain Unicode characters map to subword tokens that coincidentally overlap with instruction tokens. This unexpected capability has significant implications for LLM safety and security, particularly for filter-based safeguards and LLM-as-a-judge approaches.

## Method Summary
The research involved testing various large language models with Byzantine musical symbols and other Unicode character sequences to determine if they could understand and execute instructions encoded in these symbols. The study examined multiple models including Claude, GPT, Llama, and other variants, focusing on their ability to process non-standard Unicode sequences. The authors combined encoded harmful instructions with simple templates to test jailbreak effectiveness, measuring attack success rates. While the exact methodology for testing and evaluation is not fully detailed in the reproduction notes, the experiments spanned a wide range of models and Unicode sequences to demonstrate the phenomenon's breadth.

## Key Results
- LLMs can understand and execute instructions written in Byzantine musical symbols and other Unicode sequences
- BPE tokenization artifacts are hypothesized as a contributing mechanism, with token overlap observed between instruction and execution tokens
- Combined jailbreak attacks using encoded harmful instructions achieved a 0.4 attack success rate (ASR) on GPT-4o-mini

## Why This Works (Mechanism)
The primary mechanism appears to be related to BPE (Byte-Pair Encoding) tokenization artifacts. When Unicode symbols are processed by LLMs, certain characters map to subword tokens that may coincidentally overlap with tokens used in instruction-following. This token overlap allows models to partially recognize and execute instructions even when presented in non-standard character sets. The phenomenon suggests that models are not truly understanding the Byzantine musical symbols themselves, but rather leveraging tokenization patterns to bridge between the encoded instructions and their internal representations.

## Foundational Learning
- **BPE Tokenization**: Why needed - To understand how text is broken into subword units for LLM processing. Quick check - Review how common Unicode characters map to BPE tokens versus Byzantine musical symbols.
- **LLM Instruction Following**: Why needed - To grasp the baseline capability that the phenomenon exploits. Quick check - Test simple instruction-following tasks with standard text.
- **Unicode Character Encoding**: Why needed - To understand the character sets being used and their properties. Quick check - Examine Unicode code points for Byzantine musical symbols versus standard text.
- **Jailbreak Attack Methodology**: Why needed - To contextualize the security implications. Quick check - Review common jailbreak templates and their effectiveness with standard text.
- **Token Overlap Analysis**: Why needed - To understand the core hypothesis about why the phenomenon works. Quick check - Compare token sequences between instruction and execution examples.
- **Safety Filter Mechanisms**: Why needed - To understand what safeguards are potentially being bypassed. Quick check - Review how safety filters typically process and evaluate input text.

## Architecture Onboarding
- **Component Map**: Unicode Input -> Tokenizer -> BPE Subword Tokens -> Model Attention -> Instruction Execution
- **Critical Path**: The path from Unicode character input through tokenization to instruction execution is critical, as token overlap appears to enable the phenomenon
- **Design Tradeoffs**: BPE tokenization optimizes for compression and coverage of training data, but may create unintended bridges between disparate character sets
- **Failure Signatures**: Success with Unicode sequences that have token overlap, failure with sequences lacking meaningful token overlap with instruction tokens
- **First Experiments**:
  1. Test instruction-following with Byzantine musical symbols versus random Unicode characters
  2. Measure token overlap between instruction and execution sequences across different Unicode character sets
  3. Compare success rates across models with different tokenization schemes (BPE vs SentencePiece vs WordPiece)

## Open Questions the Paper Calls Out
None

## Limitations
- The BPE tokenization hypothesis remains largely qualitative and correlational rather than definitively proven
- The attack success rate of 0.4 on GPT-4o-mini comes from an unspecified number of trials without statistical validation
- The study focuses primarily on capability demonstration without exploring the full space of Unicode characters or systematic evaluation of token overlap correlation

## Confidence
- **Medium**: LLMs can execute instructions in Byzantine musical symbols and other Unicode sequences - well-demonstrated through examples but mechanism unclear
- **Low**: BPE tokenization artifacts are the primary explanation - suggestive evidence but no definitive proof
- **Medium**: Safety implications are significant - demonstrated through limited jailbreak testing but scope and generalizability uncertain

## Next Checks
1. Conduct controlled experiments varying the degree of token overlap between instruction and execution sequences to quantify the relationship between BPE tokenization and instruction-following success
2. Test the phenomenon across different tokenization schemes (SentencePiece, WordPiece, etc.) and with models using varying vocabulary sizes to isolate the role of BPE-specific artifacts
3. Perform ablation studies with synthetic Unicode sequences designed to maximize/minimize token overlap to determine whether success correlates specifically with shared subword tokens