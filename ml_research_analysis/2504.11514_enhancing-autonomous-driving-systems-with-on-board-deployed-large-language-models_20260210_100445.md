---
ver: rpa2
title: Enhancing Autonomous Driving Systems with On-Board Deployed Large Language
  Models
arxiv_id: '2504.11514'
source_url: https://arxiv.org/abs/2504.11514
tags:
- driving
- llms
- behavior
- human
- decisionxllm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a hybrid architecture integrating low-level
  Model Predictive Control (MPC) with edge-deployed Large Language Models (LLMs) to
  enhance decision-making and Human Machine Interaction (HMI) in autonomous driving
  systems. The DecisionxLLM module evaluates robotic state data against natural language
  instructions to ensure adherence to desired driving behavior, while the MPCxLLM
  module adjusts MPC parameters for control adaptability.
---

# Enhancing Autonomous Driving Systems with On-Board Deployed Large Language Models

## Quick Facts
- arXiv ID: 2504.11514
- Source URL: https://arxiv.org/abs/2504.11514
- Reference count: 40
- Hybrid MPC+LLM architecture improves autonomous driving reasoning accuracy by 10.45%, control adaptability by 52.2%, and computational efficiency by 10.5x

## Executive Summary
This work introduces a hybrid architecture integrating low-level Model Predictive Control (MPC) with edge-deployed Large Language Models (LLMs) to enhance decision-making and Human Machine Interaction (HMI) in autonomous driving systems. The DecisionxLLM module evaluates robotic state data against natural language instructions to ensure adherence to desired driving behavior, while the MPCxLLM module adjusts MPC parameters for control adaptability. The system uses Retrieval Augmented Generation (RAG), Low Rank Adaptation (LoRA) fine-tuning, and quantization to enable efficient on-board deployment on resource-constrained platforms.

## Method Summary
The proposed framework combines a DecisionxLLM module for high-level reasoning and a MPCxLLM module for low-level control adaptation. The DecisionxLLM evaluates driving scenarios against natural language instructions using RAG and LoRA fine-tuning for efficient inference. The MPCxLLM adjusts MPC parameters based on LLM insights to enhance control adaptability. Quantization techniques enable deployment on edge devices with limited computational resources. The architecture bridges the gap between symbolic reasoning and continuous control in autonomous driving systems.

## Key Results
- Reasoning accuracy improved by up to 10.45%
- Control adaptability increased by up to 52.2%
- Computational efficiency improved by up to 10.5x

## Why This Works (Mechanism)
The hybrid architecture leverages LLMs' natural language understanding capabilities to interpret high-level driving instructions and evaluate current robotic states. This symbolic reasoning is then translated into actionable parameters for the MPC controller, enabling adaptive control responses to dynamic driving scenarios. The integration of RAG allows access to external knowledge bases for improved decision-making, while LoRA fine-tuning enables efficient model adaptation without full retraining. Quantization reduces the computational burden, making LLM deployment feasible on edge devices.

## Foundational Learning
- **Model Predictive Control (MPC)**: Predictive control algorithm that optimizes control actions over a finite horizon; needed for real-time trajectory planning in autonomous driving
- **Retrieval Augmented Generation (RAG)**: Technique combining information retrieval with language model generation; needed to incorporate external knowledge into LLM decision-making
- **Low Rank Adaptation (LoRA)**: Parameter-efficient fine-tuning method that reduces computational requirements; needed for efficient LLM adaptation on resource-constrained platforms
- **Quantization**: Process of reducing numerical precision of model parameters; needed to enable LLM deployment on edge devices with limited computational resources

## Architecture Onboarding
- **Component Map**: Sensor Data -> MPC Controller -> DecisionxLLM (RAG+LoRA) -> MPCxLLM -> Actuators
- **Critical Path**: Sensor input → MPC optimization → DecisionxLLM evaluation → MPCxLLM parameter adjustment → Actuator commands
- **Design Tradeoffs**: Accuracy vs. computational efficiency (quantization), model size vs. reasoning capability (LoRA), real-time performance vs. decision quality (MPC horizon length)
- **Failure Signatures**: Degradation in reasoning accuracy with noisy sensor data, control instability with incorrect MPC parameter adjustments, latency issues with insufficient computational resources
- **First Experiments**:
  1. Benchmark reasoning accuracy with and without RAG augmentation
  2. Evaluate control performance across different quantization levels
  3. Test system response time under varying computational loads

## Open Questions the Paper Calls Out
None

## Limitations
- Real-world robustness under diverse environmental conditions and edge cases remains uncertain
- Specific test scenarios, datasets, and validation metrics are not fully detailed
- Generalizability to different autonomous driving platforms is not established

## Confidence
- Performance improvements (accuracy, adaptability, efficiency): Medium
- Architectural innovation (MPC+LLM integration): High

## Next Checks
1. Conduct extensive real-world testing across diverse driving scenarios (urban, highway, adverse weather) to validate robustness and safety
2. Perform ablation studies to isolate the contributions of RAG, LoRA, and quantization to the observed improvements
3. Benchmark the system against state-of-the-art autonomous driving frameworks to quantify relative performance gains and identify potential trade-offs