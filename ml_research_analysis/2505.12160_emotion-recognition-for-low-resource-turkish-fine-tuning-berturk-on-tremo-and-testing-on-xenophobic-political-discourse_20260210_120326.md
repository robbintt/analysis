---
ver: rpa2
title: 'Emotion Recognition for Low-Resource Turkish: Fine-Tuning BERTurk on TREMO
  and Testing on Xenophobic Political Discourse'
arxiv_id: '2505.12160'
source_url: https://arxiv.org/abs/2505.12160
tags:
- emotion
- turkish
- emotions
- sentiment
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# Emotion Recognition for Low-Resource Turkish: Fine-Tuning BERTurk on TREMO and Testing on Xenophobic Political Discourse

## Quick Facts
- **arXiv ID**: 2505.12160
- **Source URL**: https://arxiv.org/abs/2505.12160
- **Reference count**: 40
- **Primary result**: Fine-tuned BERTurk achieved 92.62% accuracy on 6-class Turkish emotion recognition task

## Executive Summary
This paper demonstrates emotion recognition for Turkish, a low-resource language, by fine-tuning BERTurk on the TREMO dataset and applying it to xenophobic political discourse from X/Twitter. The authors address Turkish's agglutinative morphology through language-specific pre-training, balance the dataset across six emotion categories, and apply a confidence threshold to improve prediction reliability. The approach achieves strong performance on the balanced dataset while highlighting challenges in distinguishing semantically similar emotions like anger and fear.

## Method Summary
The method involves fine-tuning BERTurk (`bert-base-turkish-cased`) on the TREMO dataset for 6-class emotion classification. The dataset was balanced to 3,003 sentences per emotion class (18,018 total) by undersampling overrepresented categories. Text underwent normalization (URLs, mentions, emojis replaced with Turkish tokens) and was tokenized using BERTurk's vocabulary. The model trained for 3 epochs with a 90/10 train/test split, and inference applied a 0.6 confidence threshold to filter ambiguous predictions. The trained model was then applied to 47,024 Turkish tweets about "sessiz istila" (silent invasion) from June 2021 to December 2022.

## Key Results
- Achieved 92.62% classification accuracy on balanced TREMO test set
- Confusion matrix revealed challenges distinguishing anger from fear and sadness from anger
- Happiness and disgust were underrepresented in target political discourse data (2.3% and 0.8% respectively)
- Model demonstrated zero-shot capability on X/Twitter xenophobic political discourse

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuning a language-specific pre-trained model (BERTurk) on Turkish emotion data yields higher accuracy than applying multilingual or general-purpose models.
- Mechanism: BERTurk is pre-trained on Turkish corpora, capturing the agglutinative morphology where a single root word conveys different meanings through suffixation. This prior linguistic knowledge reduces the learning burden during fine-tuning, allowing the model to focus on emotion-specific patterns rather than basic language understanding.
- Core assumption: Turkish linguistic structures (agglutination, suffix-based meaning changes) are sufficiently represented in BERTurk's pre-training data.
- Evidence anchors:
  - [abstract] "BERTurk, a specialized pre-trained computational model designed for the Turkish language, has undergone pre-training on Turkish corpora, enhancing its proficiency in comprehending and processing the language while recognizing its distinctive linguistic attributes and subtleties."
  - [section 1] "Turkish is renowned for its agglutinative nature, distinguishing it from other languages in the field. In Turkish, a root word can convey both positive and negative meanings by changing suffixes."
  - [corpus] AfroXLMR-Social similarly demonstrates that adapting pre-trained models to low-resource social media domains improves performance, supporting the transfer-learning mechanism for underrepresented languages.
- Break condition: If target Turkish text contains domain-specific vocabulary or code-switching not present in BERTurk's pre-training data, performance may degrade.

### Mechanism 2
- Claim: Balancing the training dataset across emotion categories improves classification fairness and reduces bias toward majority classes.
- Mechanism: The TREMO dataset was artificially balanced by capping each of the 6 emotion categories at 3,003 sentences (matching the least-represented class, "surprise"). This prevents the model from learning a prior that favors more frequent emotions, forcing it to learn discriminative features for all categories equally.
- Core assumption: Reducing class imbalance directly translates to more equitable per-class performance; synthetic undersampling does not destroy critical patterns.
- Evidence anchors:
  - [section 3.4] "The dataset has been normalized to lowercase for consistency and balance to ensure equal distribution across six emotion categories, thereby minimizing bias and enhancing the reliability of the model's performance."
  - [section 4.1] "To ensure uniformity, we set 3,003 sentences as the limit for each of the remaining five emotions, thus creating a balanced dataset."
  - [corpus] Weak direct corpus evidence for balancing mechanisms specifically in emotion recognition; most related work focuses on model architecture rather than dataset balancing.
- Break condition: If real-world emotion distributions are highly imbalanced, the balanced model may over-predict minority emotions during inference.

### Mechanism 3
- Claim: Applying a confidence threshold (0.6) during inference filters ambiguous predictions, improving the reliability of downstream emotion classification.
- Mechanism: The model outputs raw logits converted to probabilities via softmax. Predictions below 0.6 confidence are labeled as "ambiguous" (-1) rather than assigned a potentially incorrect emotion. This trades recall for precision in high-stakes applications.
- Core assumption: Low-confidence predictions are more likely to be incorrect or semantically ambiguous; excluding them improves aggregate signal quality.
- Evidence anchors:
  - [section 3.5] "The 'predict_emotions' function incorporated a threshold parameter to ensure reliable predictions, setting a minimum confidence level of 0.6 for emotion classification. Predictions falling below this threshold were marked as ambiguous with a value of -1."
  - [corpus] No direct corpus evidence on confidence thresholding for emotion models; this is a methodological contribution specific to this paper.
- Break condition: If the threshold is too high, too many predictions become "ambiguous," reducing coverage. If too low, noise increases.

## Foundational Learning

- Concept: **Transfer Learning for NLP**
  - Why needed here: The entire approach relies on taking a pre-trained BERTurk model and adapting it to emotion classification rather than training from scratch.
  - Quick check question: Can you explain why fine-tuning a pre-trained model requires fewer labeled examples than training a model from random initialization?

- Concept: **Agglutinative Morphology**
  - Why needed here: Turkish word formation through suffix stacking fundamentally differs from English; understanding this explains why language-specific models outperform multilingual alternatives.
  - Quick check question: Given the Turkish root "ev" (house), what meanings might "evlerimizden" convey, and how would a subword tokenizer handle this?

- Concept: **Multi-class Classification with Confidence Thresholding**
  - Why needed here: The model outputs 6 emotion classes but must also handle uncertain cases; understanding softmax and threshold mechanics is essential for deployment.
  - Quick check question: If softmax outputs [0.35, 0.55, 0.03, 0.02, 0.03, 0.02] for [anger, fear, sadness, disgust, surprise, happiness], what is the predicted class and would it pass a 0.6 threshold?

## Architecture Onboarding

- Component map:
  - Tweet text → normalization (URLs, mentions, emojis replaced with Turkish tokens) → tokenizer (bert-base-turkish-cased) → BERTurk encoder → [CLS] embedding → linear classification head → 6 emotion logits → softmax → threshold check → label or "ambiguous"

- Critical path:
  1. Data preprocessing (normalization + emoji translation to Turkish)
  2. Tokenization with BERTurk vocab
  3. Fine-tuning on balanced TREMO (3 epochs, 90/10 split)
  4. Inference with 0.6 confidence threshold

- Design tradeoffs:
  - **Undersampling vs. class weights**: Authors chose undersampling (3,003 per class) which reduces training data but ensures strict balance; class weights could preserve more data but introduce optimization complexity.
  - **Keeping vs. removing stop words**: Citing Alzahrani & Jololian (2021), authors retained stop words because BERT models benefit from full context.
  - **Threshold level**: 0.6 is arbitrary but conservative; no ablation study on alternative values is reported.

- Failure signatures:
  - **Anger/Fear confusion**: Section 5.1 notes the model struggled to differentiate anger and fear due to "semantic overlaps in linguistic expressions."
  - **Underrepresented emotions in target domain**: Happiness and disgust were rare in the X dataset (2.3% and 0.8%), making validation difficult.
  - **Short, informal text**: Normalized tweets may lose sentiment signals from removed emojis or hashtags if translation is incomplete.

- First 3 experiments:
  1. **Baseline reproduction**: Fine-tune BERTurk on TREMO with the documented 90/10 split, 3 epochs, balanced classes. Verify reported 92.62% accuracy and confusion matrix patterns.
  2. **Ablation on confidence threshold**: Re-run inference on held-out data with thresholds [0.4, 0.5, 0.6, 0.7, 0.8] and measure precision/recall tradeoffs per emotion class.
  3. **Cross-domain validation**: Apply the trained model to a different Turkish social media dataset (e.g., product reviews or political tweets unrelated to refugees) to assess generalization beyond the training domain.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Will expanding the emotion taxonomy to include nuanced states like anxiety and hope improve the model's ability to capture complex public sentiment?
- Basis in paper: [explicit] The authors state in Section 5.2 that future research should prioritize "incorporating nuanced states including anxiety, hope, and satisfaction."
- Why unresolved: The current model relies solely on Ekman's six basic emotions, which the authors admit limits the scope by excluding complex emotional categories.
- What evidence would resolve it: Performance metrics comparing the current BERTurk-ERM against a version fine-tuned on a dataset annotated with these nuanced labels.

### Open Question 2
- Question: Can advanced contextual techniques effectively disambiguate the semantic overlap between anger and fear in Turkish text?
- Basis in paper: [explicit] Section 5.1 notes the model struggled to differentiate these emotions due to linguistic overlaps, highlighting the "need for improved contextual representation."
- Why unresolved: The current architecture results in lower F1 scores for sadness and anger, indicating difficulty in distinguishing specific negative emotions.
- What evidence would resolve it: Ablation studies showing improved confusion matrices for anger and fear when using advanced attention mechanisms.

### Open Question 3
- Question: Does data augmentation provide superior generalizability compared to the dataset balancing method of capping sample sizes?
- Basis in paper: [inferred] Section 5.2 proposes using data augmentation to improve generalizability, while Section 4.1 describes the current method of balancing data by capping it at 3,003 samples per class.
- Why unresolved: The authors explicitly suggest the current balanced dataset restricted diversity, potentially limiting the model's robustness.
- What evidence would resolve it: Comparative validation results showing whether augmentation techniques reduce overfitting better than the current static sample-capping approach.

## Limitations
- The evaluation lacks direct validation against ground-truth emotion labels for the X dataset application, limiting assessment of real-world effectiveness
- Confidence threshold of 0.6 is applied without systematic justification or ablation study to determine optimal value
- Class balancing through undersampling may reduce model robustness by discarding informative examples from naturally overrepresented emotions

## Confidence
- **High confidence**: BERTurk's pre-training on Turkish corpora improves emotion recognition compared to multilingual alternatives
- **Medium confidence**: The balanced dataset approach reduces bias and improves fairness, though no ablation study compares balanced versus imbalanced training
- **Low confidence**: The model effectively handles xenophobic political discourse on X/Twitter due to lack of quantitative validation for this application

## Next Checks
1. **Threshold sensitivity analysis**: Apply the trained model to the held-out TREMO test set with confidence thresholds ranging from 0.4 to 0.8 in 0.1 increments. Report precision, recall, F1-score, and "ambiguous" rate for each threshold and per emotion class to identify the optimal tradeoff.

2. **Cross-domain emotion distribution validation**: Manually annotate a small subset (n=100-200) of the X dataset with emotion labels. Compute confusion matrices and per-class metrics when applying the TREMO-trained model to this gold-standard political discourse data, comparing performance to TREMO test set results.

3. **Class imbalance ablation study**: Retrain the model on TREMO with original class distributions (without undersampling) using class weights in the loss function. Compare performance metrics to the balanced approach on both TREMO test set and the annotated X dataset subset to quantify the tradeoff between data efficiency and model robustness.