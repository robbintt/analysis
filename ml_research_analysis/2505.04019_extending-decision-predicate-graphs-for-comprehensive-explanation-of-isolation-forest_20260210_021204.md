---
ver: rpa2
title: Extending Decision Predicate Graphs for Comprehensive Explanation of Isolation
  Forest
arxiv_id: '2505.04019'
source_url: https://arxiv.org/abs/2505.04019
tags:
- iforest
- outlier
- outliers
- predicate
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a Decision Predicate Graph (DPG)-based method
  to explain Isolation Forest (iForest) for outlier detection. Unlike traditional
  approaches that provide only feature importance vectors, our method constructs a
  global, graph-based explanation of iForest's decision-making process.
---

# Extending Decision Predicate Graphs for Comprehensive Explanation of Isolation Forest

## Quick Facts
- arXiv ID: 2505.04019
- Source URL: https://arxiv.org/abs/2505.04019
- Authors: Matteo Ceschin; Leonardo Arrighi; Luca Longo; Sylvio Barbon Junior
- Reference count: 30
- Primary result: Introduces Decision Predicate Graph (DPG)-based method to explain Isolation Forest for outlier detection

## Executive Summary
This study introduces a Decision Predicate Graph (DPG)-based method to explain Isolation Forest (iForest) for outlier detection. Unlike traditional approaches that provide only feature importance vectors, our method constructs a global, graph-based explanation of iForest's decision-making process. We represent the model as a weighted directed graph where nodes are predicates (feature conditions) and edges show decision paths. We introduce the Inlier-Outlier Propagation Score (IOP-Score) to quantify each feature's contribution to outlier identification.

Experiments on synthetic datasets and the Annthyroid benchmark demonstrate that our approach provides comprehensive visual and quantitative explanations, revealing which features and conditions drive anomaly detection. The method offers interpretable insights into both outlier and inlier classification boundaries, advancing iForest explainability beyond feature importance rankings.

## Method Summary
The method trains iForest with 200 trees, extracts split rules as predicate triples (f, σ, v), traverses samples through trees to record predicate sequences, labels by class, removes outlier paths exceeding max depth, converts triples to pairs (f, σ), builds weighted directed graph with consecutive predicate frequencies, applies class-based weighting (wo = (No+Ni)/No, wi = (No+Ni)/Ni), and computes IOP-Score = (fi(v) - fo(v)) / fin(v) per node.

## Key Results
- DPG method provides global, graph-based explanations of iForest's decision-making process
- IOP-Score quantifies each feature's contribution to outlier identification with values from -1 (purely outlier) to +1 (purely inlier)
- Experiments on synthetic datasets and Annthyroid benchmark demonstrate comprehensive visual and quantitative explanations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Aggregating split rules into predicates (f, σ) rather than (f, σ, v) enables cross-tree pattern detection that isolated split values cannot provide.
- Mechanism: iForest randomly selects split values per tree, making exact triples unique and non-aggregable. By abstracting to feature-direction pairs, the method retains meaningful isolation patterns while allowing cross-tree comparison. Edges encode sequential predicate satisfaction frequency, revealing which decision paths the model actually uses.
- Core assumption: Feature-direction information alone, without specific threshold values, is sufficient to characterize the model's isolation logic.
- Evidence anchors: [abstract], [section 3.1], [corpus]
- Break condition: If features have complex multi-threshold decision boundaries where direction alone misrepresents the logic, the abstraction will produce misleading explanations.

### Mechanism 2
- Claim: Class-based frequency weighting neutralizes imbalance between rare outliers and abundant inliers, enabling fair comparison of predicate discriminativeness.
- Mechanism: Outlier predicate transitions naturally appear less frequently due to class imbalance. Weighting multiplies outlier contributions by wo = (No + Ni)/No and inlier contributions by wi = (No + Ni)/Ni, effectively normalizing total contribution from each class before edge weight computation.
- Core assumption: The total information content from outlier and inlier classes should be equalized rather than preserved in raw proportions.
- Evidence anchors: [section 3.1], [section 4.2], [corpus]
- Break condition: If outlier behavior is genuinely heterogeneous (multiple outlier types with different features), equalizing class weights may overemphasize noisy outlier patterns.

### Mechanism 3
- Claim: The IOP-Score quantifies discriminativeness by comparing normalized propagation frequencies toward terminal classes.
- Mechanism: For each predicate node v, IOP-Score(v) = (fi(v) - fo(v)) / fin(v) measures the net tendency to propagate toward inliers versus outliers, normalized by total incoming flow. This isolates the predicate's directional influence independent of raw frequency.
- Core assumption: A predicate's discriminative power is captured by the relative difference in where samples go after satisfying it, not the absolute number of samples.
- Evidence anchors: [abstract], [section 3.1], [section 4.1.1, Table 3], [corpus]
- Break condition: If a predicate appears early in many paths but its discriminative effect depends on subsequent predicates (context-dependent), the local IOP-Score will misrepresent its true contribution.

## Foundational Learning

- Concept: Isolation Forest anomaly scoring
  - Why needed here: Understanding that iForest isolates outliers with fewer splits (shorter paths) is essential to interpreting why certain predicates appear near terminal "Outlier" nodes.
  - Quick check question: If an instance has average path length E(h(x)) close to the theoretical maximum c(n), would its anomaly score be closer to 0.5 or 1.0?

- Concept: Directed graph representation of decision logic
  - Why needed here: The method encodes model behavior as nodes (predicates) and weighted edges (transition frequencies); interpreting the graph requires fluency with this abstraction.
  - Quick check question: What does a thick edge from predicate A to "Outlier" versus a thin edge from predicate A to "Inlier" indicate about predicate A?

- Concept: Class imbalance weighting in frequency statistics
  - Why needed here: Without understanding why wo and wi are computed as ratios of total samples to class samples, the edge weight interpretation will be incorrect.
  - Quick check question: In a dataset with 1000 inliers and 10 outliers, what weight would an outlier transition receive?

## Architecture Onboarding

- Component map: Predicate Extractor -> Traversal Recorder -> Predicate Abstracter -> Graph Builder -> IOP-Score Calculator -> Visualizer
- Critical path: Predicate Extraction → Traversal Recording → Abstraction → Graph Construction → IOP-Score Computation. Errors in abstraction (wrong sign handling) propagate to all downstream interpretation.
- Design tradeoffs:
  - **Abstraction level**: (f, σ) loses threshold information but enables cross-tree aggregation; (f, σ, v) preserves thresholds but fragments patterns
  - **Weighting scheme**: Class-balancing enables outlier detection in imbalanced data but may amplify noise in heterogeneous outlier populations
  - **Path filtering**: Removing max-depth outlier paths aligns with iForest theory but may discard legitimate edge cases
- Failure signatures:
  - All IOP-Scores near 0: Model may not have learned discriminative patterns, or weighting is misconfigured
  - No thick edges to "Outlier" terminal: Outliers may require multi-predicate combinations rather than single-splits; check if filtering removed too many paths
  - Inconsistent IOP-Scores across similar features: Possible data quality issues or feature correlations creating split randomness effects
  - Graph too dense to interpret: High-dimensional data with many features; consider feature filtering before iForest
- First 3 experiments:
  1. Replicate the single-outlier synthetic dataset (Section 4.1.1) and verify that modified features (F0, F3, F4, F5) produce negative IOP-Scores for the > direction where values increased
  2. Test on a dataset with known feature importance (e.g., Annthyroid) and compare IOP-Score rankings against SHAP/feature importance baselines to validate discriminativeness
  3. Stress test with varying contamination ratios (1%, 5%, 10%, 20% outliers) to verify weighting handles imbalance correctly without IOP-Score degradation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the DPG-based approach quantitatively compare to established XAI methods like SHAP and DIFFI in terms of explanation fidelity and computational cost?
- Basis in paper: [explicit] The authors state in Section 5 that "a more in-depth comparison with these techniques is necessary to establish the specific advantages and trade-offs of DPG."
- Why unresolved: The current study focuses on demonstrating feasibility via synthetic data and the Annthyroid benchmark but lacks a systematic head-to-head benchmark against baseline explanation methods.
- What evidence would resolve it: A comparative study measuring metrics such as explanation consistency, runtime, and memory usage across diverse datasets.

### Open Question 2
- Question: Can the graph construction process be optimized to handle the memory demands of large-scale iForest models with high-dimensional data?
- Basis in paper: [explicit] Section 5 highlights "scalability issues" and notes that "constructing and analyzing the DPG for large-scale iForest models can be memory-intensive."
- Why unresolved: The current implementation transforms the entire ensemble into a graph structure, which may become prohibitively expensive for complex models.
- What evidence would resolve it: Benchmarks showing stable memory usage and latency when applying optimized graph construction techniques to datasets with significantly higher dimensions.

### Open Question 3
- Question: What complementary visualization techniques are required to maintain interpretability when the DPG structure becomes highly complex?
- Basis in paper: [explicit] Section 5 acknowledges that "interpreting the graph structure in highly complex datasets requires complementary visualization techniques to enhance clarity."
- Why unresolved: As the number of nodes and edges increases, the graph risks becoming visually cluttered, potentially negating the benefits of global explainability.
- What evidence would resolve it: User studies evaluating the interpretability of the DPG when augmented with interactive filtering or clustering visualizations compared to the static view.

## Limitations
- The predicate abstraction mechanism lacks direct corpus validation for iForest explanation
- Class imbalance weighting may distort explanations when outliers are genuinely heterogeneous
- IOP-Score assumes local predicate discrimination equals contribution, which may fail for context-dependent boundaries

## Confidence
- Mechanism 1: Low—abstraction untested
- Mechanism 2: Medium—weighting mathematically sound but unverified for complex outliers
- Mechanism 3: Medium—scoring intuitive but not validated against ground truth feature importance
- Overall explanation validity: Medium—synthetic results promising but limited to simple scenarios

## Next Checks
1. Test on multi-modal outlier datasets where outliers belong to distinct classes, evaluating if IOP-Scores correctly identify different discriminative features per outlier type
2. Compare IOP-Score rankings against SHAP values on Annthyroid and other benchmarks to validate discriminative accuracy
3. Evaluate sensitivity to weighting scheme variations by testing alternative normalization approaches (e.g., logarithmic scaling) and measuring impact on top-ranked predicates