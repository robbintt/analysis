---
ver: rpa2
title: 'Provable FDR Control for Deep Feature Selection: Deep MLPs and Beyond'
arxiv_id: '2512.04696'
source_url: https://arxiv.org/abs/2512.04696
tags:
- assumption
- feature
- control
- lemma
- power
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a feature selection method for deep neural
  networks that provides provable false discovery rate (FDR) control. The approach
  uses gradient-based input sensitivity to measure feature importance and employs
  data splitting to achieve scale-free FDR control.
---

# Provable FDR Control for Deep Feature Selection: Deep MLPs and Beyond

## Quick Facts
- arXiv ID: 2512.04696
- Source URL: https://arxiv.org/abs/2512.04696
- Reference count: 40
- Key outcome: The first method providing provable FDR control for feature selection in general deep neural networks using gradient-based input sensitivity and data splitting.

## Executive Summary
This paper introduces a feature selection method for deep neural networks that provides provable false discovery rate (FDR) control. The approach uses gradient-based input sensitivity to measure feature importance and employs data splitting to achieve scale-free FDR control. The method works with multilayer perceptrons, convolutional networks, recurrent networks, and other architectures, accommodating arbitrary depth, width, and common neural network components like dropout and residual connections. The theoretical analysis shows that under certain conditions (including right-orthogonal invariance of the design matrix), the input sensitivity for null features converges to a normal distribution, enabling FDR control.

## Method Summary
The method works by first splitting the data into two halves and training two independent networks on each half. For each feature, it computes input sensitivity as the sum of gradients of the network output with respect to that feature across all training samples. It then constructs an aggregated statistic M_j from the sensitivities of both halves, using the product of sensitivities and taking the minimum of their absolute values. Features are selected if their M_j exceeds a threshold τ_α determined by the desired FDR level α. The theoretical guarantee relies on the asymptotic normality of null feature sensitivities under right-orthogonal invariance of the design matrix.

## Key Results
- The method successfully controls FDR at or below the nominal level α across various network architectures and data-generating processes.
- Numerical experiments confirm the asymptotic normality of the feature importance scores for null features.
- The approach maintains reasonable power while providing statistical guarantees, unlike many existing deep feature selection methods.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The gradient-based input sensitivity for null (irrelevant) features asymptotically follows a standard normal distribution, regardless of network depth or non-convexity.
- **Mechanism:** Under the assumption of B-right orthogonal invariance, the projected input sensitivity vector P^⊥_B ξ^(t) is uniformly distributed on a sphere in the null space. As feature dimension n increases relative to latent dimension q^*, the marginal distribution of any null coordinate converges to Gaussian (by the geometry of high-dimensional spheres).
- **Core assumption:** The design matrix X satisfies B-right orthogonal invariance (Assumption 1), and q^* = o(n).
- **Evidence anchors:**
  - [Abstract]: "input sensitivity for null features converges to a normal distribution"
  - [Section 3]: Theorem 1 establishes √n ξ^(t)_j / ||P^⊥_B ξ^(t)|| →d N(0,1).
  - [Corpus]: Related works like DeepLINK and GRIP2 address similar FDR problems but often lack the theoretical convergence guarantees provided here for general SGD iterates.
- **Break condition:** Fails if the design matrix has specific column correlations violating the B-ROI property (e.g., discrete features or non-elliptical dependencies).

### Mechanism 2
- **Claim:** A data-splitting aggregation scheme creates a "scale-free" statistic that enables FDR control without estimating the unknown variance of the feature importance scores.
- **Mechanism:** Data is split into two halves. For each feature, a statistic M_j is constructed from the product/minimum of sensitivities from both halves. Under the null, M_j is symmetric around zero; under the signal, it is positive. By comparing counts of negative vs. positive statistics, one can set a threshold τ_α that caps the FDR at α.
- **Core assumption:** Symmetry of the null distribution (Theorem 2) and sufficiently strong signals to ensure power (Assumption 7).
- **Evidence anchors:**
  - [Abstract]: "employs data splitting to achieve scale-free FDR control"
  - [Section 4]: Algorithm 1 defines the procedure using M_j = sign(ξ_j1·ξ_j2)ψ(|ξ_j1|, |ξ_j2|).
  - [Corpus]: GRIP2 and DiffKnock also utilize advanced statistical architectures for robustness, reflecting a trend toward integrating FDR into deep learning pipelines.
- **Break condition:** Fails if the sample size is too small to support the split, or if the optimization trajectory on the split data is not identically distributed (violating Assumption 6).

### Mechanism 3
- **Claim:** The theoretical guarantees hold for every iteration t of Stochastic Gradient Descent (SGD), independent of convergence to a global minimum.
- **Mechanism:** The proof relies on the recursive inheritance of orthogonal invariance through SGD updates. Since the analysis applies to the iterates W^(t) rather than a converged estimator, it bypasses the non-convexity issues typical of deep networks.
- **Core assumption:** Initialization W^(0) is data-independent and satisfies orthogonal invariance (Assumption 4).
- **Evidence anchors:**
  - [Section 3]: "results do not rely on... convergence of the optimization path."
  - [Page 6]: Proposition 1 shows the invariance holds for any t ∈ N.
  - [Corpus]: Standard feature selection (e.g., Lasso) relies on convexity; this mechanism extends validity to non-convex training dynamics.
- **Break condition:** Fails if initialization depends on the data (y, X).

## Foundational Learning

- **Concept:** **False Discovery Rate (FDR)**
  - **Why needed here:** This is the core metric the paper seeks to control. Unlike simple error rates, FDR manages the proportion of false positives among all selected features, which is critical in high-dimensional discovery settings.
  - **Quick check question:** How does FDR differ from Family-Wise Error Rate (FWER) in the context of selecting hundreds of features?

- **Concept:** **Orthogonal Invariance**
  - **Why needed here:** This geometric property of the design matrix X is the theoretical engine of the paper. It allows the derivation of the null distribution without knowing the specific network weights.
  - **Quick check question:** If a matrix X is right-orthogonally invariant, what does that imply about the distribution of its singular vectors or rotational symmetry?

- **Concept:** **Input Sensitivity (Saliency)**
  - **Why needed here:** This is the proxy for "feature importance." The method interprets the gradient of the output w.r.t. input as a measure of feature relevance.
  - **Quick check question:** Why might raw gradient magnitude be a noisy estimator of importance, necessitating the statistical aggregation proposed in this paper?

## Architecture Onboarding

- **Component map:**
  1. Input Layer: Dense/Linear layer (W_1^T x)
  2. Network Body: Any architecture (MLP, CNN, LSTM, Transformer) taking the linear embedding as input
  3. Aggregation Layer: Post-processing step computing ξ^(t) and M_j

- **Critical path:**
  1. Verify data satisfies assumptions (or augment with random projections if needed)
  2. Split data 50/50 into (X^(1), y^(1)) and (X^(2), y^(2))
  3. Initialize and train two independent networks (or runs) using SGD
  4. At iteration t, compute gradients ξ^(t)_1 and ξ^(t)_2
  5. Compute M_j and threshold τ_α to select features

- **Design tradeoffs:**
  - **Flexibility vs. Architecture:** The first layer must be linear/dense to satisfy Assumption 3. You cannot use a raw CNN or LSTM directly on the input without a dense lifting layer first.
  - **Sample Size vs. Control:** Data splitting reduces effective sample size, potentially reducing power (Type-II error), but guarantees FDR control.
  - **Early Stopping:** Power may vary with iteration t; the paper suggests early stopping might help or hurt depending on signal strength (Remark 5.1).

- **Failure signatures:**
  - **Correlated Features:** FDR control may fail if features have strong, specific correlations not handled by the B-ROI assumption (Appendix B/C notes this limitation).
  - **First Layer Constraint:** Using a convolutional layer as the first layer violates Assumption 3 and breaks the theoretical guarantee.
  - **Low Power:** If the training loss doesn't decrease or the signal is weak, M_j might not exhibit the positive shift required for detection (Figure 10).

- **First 3 experiments:**
  1. **Sanity Check (Null Case):** Generate data with S = ∅ (no true features). Run the pipeline to verify that the FDP is controlled at level α (ideally close to 0).
  2. **Normality Verification:** Train a model, compute ξ^(t), and plot the histogram/QQ-plot of normalized scores for known null indices to confirm asymptotic normality (replicate Figure 2).
  3. **Power vs. Iteration:** Plot FDR and Power against training iterations (t) to observe if power stabilizes or if early stopping is required to maintain FDR (replicate Figure 3).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the theoretical guarantees for FDR control be extended to sophisticated feature attribution methods like Integrated Gradients or DeepLIFT?
- **Basis in paper:** [explicit] The discussion section explicitly identifies "A promising direction for future work is to extend our analysis to more sophisticated feature attribution methods, including Integrated Gradients... DeepLIFT... and SmoothGrad."
- **Why unresolved:** The current theoretical analysis relies specifically on the properties of raw input gradients derived from SGD iterates, which may differ structurally from integrated or smoothed attribution scores.
- **What evidence would resolve it:** A theoretical proof establishing the asymptotic distribution of these alternative attribution scores for null features, or empirical studies demonstrating FDR control using these methods.

### Open Question 2
- **Question:** Can the framework be modified to handle more severe correlation structures that violate the B-right orthogonal invariance assumption?
- **Basis in paper:** [explicit] The authors state in the Discussion: "Exploring the behavior of our algorithm under more severe correlation structures is an appealing direction for future work."
- **Why unresolved:** The current proof of asymptotic normality fundamentally relies on the B-right orthogonal invariance of the design matrix, which restricts the specific forms of feature correlation allowed.
- **What evidence would resolve it:** A modification of the theoretical assumptions that accommodates arbitrary covariance matrices, or a robustness analysis showing FDR control holds for non-invariant designs.

### Open Question 3
- **Question:** How can input sensitivity be characterized at the single-instance level while maintaining error control?
- **Basis in paper:** [explicit] The Discussion notes: "It would be interesting to investigate how this sensitivity can be characterized at the single-instance level."
- **Why unresolved:** The current method aggregates gradient sensitivity across samples (ξ^(t)) to form a test statistic, smoothing out instance-specific noise which may be necessary for valid statistical inference.
- **What evidence would resolve it:** A procedure that produces valid p-values or feature selections for individual data points (e.g., specific images) rather than aggregating across the dataset.

## Limitations
- **First layer constraint:** The method requires the first layer to be a dense/linear transformation, preventing direct application to architectures without this component.
- **Assumption sensitivity:** The B-right orthogonal invariance assumption may be violated by correlated features or discrete data, potentially breaking FDR control.
- **Power tradeoff:** Data splitting reduces effective sample size, which may decrease detection power compared to methods that use all available data.

## Confidence
- **FDR control guarantees:** High confidence based on rigorous theoretical analysis with explicit assumptions and proofs
- **Normality assumption:** High confidence from both theoretical derivation and numerical verification in experiments
- **Method flexibility:** Medium confidence - while the method claims to work with various architectures, the first-layer constraint limits practical applicability
- **Power performance:** Medium confidence - numerical results show reasonable power but the data-splitting approach inherently reduces detection capability

## Next Checks
1. Implement the data generation procedure from Section 5.1 and verify the design matrix satisfies B-right orthogonal invariance
2. Reproduce Figure 2 by training a small MLP, computing input sensitivities, and verifying asymptotic normality for null features
3. Run the FDR control experiment with synthetic data containing no true features to verify the FDP is controlled at the nominal level α