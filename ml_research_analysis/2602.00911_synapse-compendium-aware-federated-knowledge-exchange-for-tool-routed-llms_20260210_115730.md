---
ver: rpa2
title: Synapse Compendium Aware Federated Knowledge Exchange for Tool Routed LLMs
arxiv_id: '2602.00911'
source_url: https://arxiv.org/abs/2602.00911
tags:
- federated
- privacy
- tool
- arxiv
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SYNAPSE introduces a federated framework that trains a shared global
  knowledge model for tool-usage behavior in LLM systems. Client agents with fixed
  LLMs learn patterns locally, transmitting structured compendiums for federated aggregation
  through edge coordinators.
---

# Synapse Compendium Aware Federated Knowledge Exchange for Tool Routed LLMs

## Quick Facts
- arXiv ID: 2602.00911
- Source URL: https://arxiv.org/abs/2602.00911
- Reference count: 40
- Primary result: SYNAPSE achieves 92-93% tool-routing accuracy on GSM8k tasks while using only 5,334 bytes per client per round versus 320 GB for weight-sharing baselines

## Executive Summary
SYNAPSE introduces a federated framework where clients transmit structured compendiums of tool-usage patterns rather than model weights or raw prompts. The system uses hierarchical aggregation (client → edge → server) with semantic retrieval and LLM reranking to guide tool selection. Privacy is maintained through adaptive text masking and Laplace noise injection, achieving strong defense against prompt extraction attacks while maintaining routing accuracy. Results show SYNAPSE reduces communication overhead by orders of magnitude compared to weight-sharing approaches while preserving tool-routing effectiveness across heterogeneous data distributions.

## Method Summary
SYNAPSE operates through client agents with fixed LLMs that extract local tool-usage patterns into structured JSON compendiums containing metadata, scenarios, precautions, and templates. These compendiums are transmitted to edge coordinators for deduplication and summarization before hierarchical aggregation at a central server. During inference, user queries trigger embedding retrieval over the global compendium, followed by LLM reranking to select appropriate tools. Privacy is enforced through adaptive masking of sensitive tokens and Laplace noise on numeric metadata, with theoretical (ε,δ)-DP guarantees. The framework demonstrates 92-93% accuracy on GSM8k tasks while using only 5,334 bytes per client per round versus 320 GB for weight-sharing baselines.

## Key Results
- Achieves 92-93% accuracy on GSM8k tool-routing tasks using only 5,334 bytes per client per round versus 320 GB for weight-sharing baselines
- Routing accuracy drops only 3-6% when transitioning from centralized to federated aggregation
- Demonstrates convergence under privacy-preserving noise with Δ_tool and Δ_score approaching zero within initial rounds for ε∈{0.5,1.0,2.0} and λ∈{0.5,1.0,1.5}

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Structured compendiums achieve orders-of-magnitude communication reduction while preserving routing utility compared to weight-sharing or prompt-sharing baselines.
- **Mechanism:** Clients exchange JSON-structured "compendiums" containing tool metadata, usage scenarios, precautions, and prompt templates rather than model weights or raw prompts. These compendiums are aggregated hierarchically (client → edge → server) with deduplication and summarization, producing a global snapshot that guides inference-time tool routing. The structured schema enables semantic retrieval while keeping payloads compact (~5KB per client per round).
- **Core assumption:** Tool-usage behavior can be sufficiently captured in structured textual artifacts rather than distributed through gradient-based weight updates.
- **Evidence anchors:**
  - [abstract] "transmit structured compendiums for federated aggregation...achieving 92-93% accuracy on GSM8k tasks while using only 5,334 bytes per client per round versus 320 GB for weight-sharing baselines"
  - [Section 4.3, Table 5] Communication cost comparison showing 5,334 bytes/client/round for SYNAPSE vs 64×10^9 bytes for weight-sharing (Llama-3.1-8b fp32)
  - [corpus] Limited direct corpus support for compendium-specific approaches; closest is "Quantized Rank Reduction" for communication-efficient FL, but this uses gradient compression rather than knowledge artifacts
- **Break condition:** If tool-usage patterns require implicit procedural knowledge not capturable in textual descriptions, compendium expressivity will saturate and accuracy gains will plateau regardless of schema complexity.

### Mechanism 2
- **Claim:** Embedding retrieval with LLM reranking enables stable tool-selection convergence even under privacy-preserving noise and client heterogeneity.
- **Mechanism:** The routing pipeline performs vector search over usage scenarios (top-k=5, cosine similarity), then an LLM reranker (llama-3.1-8b-instruct) assesses candidate relevance and constraints. This "retrieve → rerank → plan" chain produces stable tool selections. Under fixed privacy noise (Laplace with ε∈{0.5,1.0,2.0}, adaptive masking with λ∈{0.5,1.0,1.5}), tool-selection (Δ_tool) and reranker scores (Δ_score) converge within initial rounds.
- **Core assumption:** The reranking LLM can discriminate among retrieved candidates more robustly than pure embedding similarity, and privacy perturbations do not fundamentally alter ranking order.
- **Evidence anchors:**
  - [Section 3, Retrieval and Routing Pipeline] "The pipeline begins with a user query triggering a vector search across usage scenarios to retrieve top-k=5 relevant candidates...An LLM reranker assesses candidates for relevance and constraints"
  - [Section 4.3, Figure 7] "Under stationary conditions, routing stabilizes with Δ_tool and Δ_score approaching zero within initial rounds for all parameters (ε∈{0.5,1.0,2.0} and λ∈{0.5,1.0,1.5})"
  - [corpus] "Teaching LLMs to Learn Tool Trialing" addresses tool-learning through environment interaction but does not specifically address federated routing convergence; corpus lacks direct comparables for reranking-based federation
- **Break condition:** If noise distributions shift between rounds (unfixed/resampled), Δ_tool and Δ_score oscillate persistently and convergence fails.

### Mechanism 3
- **Claim:** Adaptive text masking with Laplace noise provides tunable privacy-utility tradeoffs without requiring enclaves or homomorphic encryption.
- **Mechanism:** Privacy controls operate at compendium generation time: (1) Laplace noise on numeric metadata (counts, scores) calibrated by ε, (2) adaptive token masking on usage scenario text based on saliency scores κ(w) with probability p(w)=min(1, λκ(w)), (3) summarization truncation (L_max, S_max). Clients apply transformations locally before transmission. Theoretical analysis (Theorem A.1, A.3) bounds embedding distortion and provides (ε,δ)-DP guarantees.
- **Core assumption:** Embedding functions are Lipschitz continuous, and privacy perturbations induce bounded expected distortion in similarity space.
- **Evidence anchors:**
  - [Section 4.2] "findings demonstrate SYNAPSE protects against prompt extraction attacks by limiting exposed information without raw data transfer"
  - [Appendix A, Figure 12] "adaptive masking, controlled by λ, reduces Recall@1 from 0.620 at λ=0.5 to 0.280 at λ=1.5...DP on metadata provides efficient privacy, strong text masking requires careful adjustment"
  - [corpus] "ZTFed-MAS2S" addresses zero-trust FL with verifiable privacy but uses cryptographic approaches; no corpus papers evaluate adaptive text masking specifically
- **Break condition:** If token saliency scoring fails to identify sensitive tokens (e.g., contextual sensitivity not captured by pattern-based rules), masking will leak information or destroy utility.

## Foundational Learning

- **Concept: Federated Learning (FL) fundamentals**
  - Why needed here: SYNAPSE assumes familiarity with client-server federation, aggregation rounds, and the non-IID heterogeneity problem. Without this, the motivation for compendium-based exchange over FedAvg-style weight aggregation is unclear.
  - Quick check question: Can you explain why non-IID data partitions cause FedAvg to converge slower or to inferior minima compared to IID splits?

- **Concept: Retrieval-Augmented Generation (RAG)**
  - Why needed here: The compendium functions as a structured RAG index for tool-routing. Understanding embedding-based retrieval, top-k selection, and the role of rerankers is prerequisite to following the inference pipeline.
  - Quick check question: What is the difference between dense embedding retrieval and lexical retrieval (BM25), and why might an LLM reranker improve over pure embedding similarity?

- **Concept: Differential Privacy (DP) mechanisms**
  - Why needed here: SYNAPSE exposes ε and λ as tunable privacy parameters. Interpreting these requires understanding Laplace mechanism sensitivity, privacy budget composition, and the privacy-utility tradeoff curve.
  - Quick check question: If you run 3 federated rounds with per-round ε=1.0, what happens to the total privacy loss under advanced composition?

## Architecture Onboarding

- **Component map:** Client agents -> Edge aggregators -> Central server -> Inference routing pipeline
- **Critical path:** 1. Local compendium generation (client-side extraction of usage scenarios) 2. Privacy transformation application (DP + masking) 3. Edge aggregation with deduplication 4. Server merge into global snapshot 5. Inference-time retrieval + reranking for tool selection. Failure at any stage propagates: poor local scenarios → degraded global compendium → retrieval misses → routing errors.
- **Design tradeoffs:**
  - Compendium size vs. routing accuracy: Larger compendiums improve Recall@5 but increase latency (Figure 6)
  - Masking strength (λ) vs. retrieval performance: Higher λ protects more but drops Recall@1 from 0.62 to 0.28 (Figure 12)
  - Federation rounds vs. convergence: More rounds help non-IID settings but increase cumulative privacy loss
  - Centralized vs. federated: Centralized-SYNAPSE achieves slightly higher accuracy; federation trades ~3-6% accuracy for privacy (Table 3)
- **Failure signatures:**
  - Retrieval failures: Recall drops from 92% to 72% when vector search misses relevant scenarios (Figure 8)
  - Rerank mismatches: Accuracy drops to 49% when LLM reranker selects wrong candidate (Figure 8)
  - Parent-tool misassignment: 55% mismatch rate during planning phase (Figure 8)
  - Adversarial client threshold: Performance degrades sharply beyond 40% adversarial clients (Figure 9)
  - Privacy-convergence conflict: Unfixed noise (resampled each round) prevents Δ_tool convergence (Figure 7)
- **First 3 experiments:**
  1. Reproduce IID vs. non-IID split behavior: Run SYNAPSE on GSM8k with 5 clients under both partitioning strategies; verify global accuracy (0.96 IID vs. 0.92 non-IID) and macro accuracy spread (Table 1). This validates the heterogeneity handling claim.
  2. Sweep privacy parameters: Test ε∈{0.5,1.0,2.0} and λ∈{0.5,1.0,1.5} on BBH Object Counting; plot Recall@1, Recall@5, and embedding distortion (reproduce Figure 12). This calibrates privacy-utility tradeoffs for your deployment constraints.
  3. Stress-test adversarial robustness: Inject 20%, 40%, 60% adversarial clients with cross-source, random, and tool-confusion attack modes; measure routing accuracy degradation (reproduce Figure 9). This establishes your safe operating envelope before production deployment.

## Open Questions the Paper Calls Out
None

## Limitations
- Structured compendium schema may not capture complex multi-step procedural dependencies, limiting scalability beyond simple tool-selection tasks
- Privacy guarantees rely on theoretical DP bounds that may not hold under adaptive adversaries who observe multiple rounds of compendium updates
- Performance comparisons use weight-sharing baselines with fp32 storage; practical quantization schemes could significantly reduce communication costs

## Confidence
- **High confidence**: Communication efficiency claims (5,334 bytes vs 320 GB baselines) supported by explicit size calculations and Table 5; routing convergence under stationary noise conditions validated by Figure 7
- **Medium confidence**: Privacy-utility tradeoff curves require external validation as corpus lacks comparable adaptive masking evaluations; claims depend heavily on assumptions about saliency scoring effectiveness
- **Medium confidence**: Adversarial robustness thresholds (40% client corruption) based on limited attack scenarios; real-world adversaries may employ more sophisticated poisoning strategies

## Next Checks
1. **Cross-task generalization test**: Deploy SYNAPSE on a multi-modal tool task (e.g., visual tool selection) and measure compendium expressivity limits as task complexity increases
2. **Adaptive adversary simulation**: Implement an active attacker that observes multiple rounds and adapts attack patterns; measure privacy budget exhaustion and routing accuracy degradation beyond the 40% threshold
3. **Communication cost sensitivity analysis**: Compare SYNAPSE against practical weight-sharing with 8-bit quantization and gradient sparsification; measure actual bandwidth requirements under realistic network conditions rather than theoretical fp32 storage