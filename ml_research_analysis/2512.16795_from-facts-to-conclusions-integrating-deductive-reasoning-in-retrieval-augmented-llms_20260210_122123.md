---
ver: rpa2
title: 'From Facts to Conclusions : Integrating Deductive Reasoning in Retrieval-Augmented
  LLMs'
arxiv_id: '2512.16795'
source_url: https://arxiv.org/abs/2512.16795
tags:
- conflict
- reasoning
- answer
- supports
- label
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work addresses the challenge of retrieval-augmented language
  models (RAG) handling conflicting or unreliable evidence. The authors propose a
  reasoning-trace-augmented RAG framework that introduces structured, interpretable
  reasoning across three stages: document-level adjudication, conflict analysis, and
  grounded synthesis.'
---

# From Facts to Conclusions : Integrating Deductive Reasoning in Retrieval-Augmented LLMs

## Quick Facts
- arXiv ID: 2512.16795
- Source URL: https://arxiv.org/abs/2512.16795
- Reference count: 40
- Primary result: Fine-tuning Qwen improved end-to-end answer correctness from 0.069 to 0.883

## Executive Summary
This work addresses the challenge of retrieval-augmented language models (RAG) handling conflicting or unreliable evidence. The authors propose a reasoning-trace-augmented RAG framework that introduces structured, interpretable reasoning across three stages: document-level adjudication, conflict analysis, and grounded synthesis. A Conflict-Aware Trust-Score (CATS) pipeline is introduced to evaluate groundedness, factual correctness, refusal accuracy, and conflict-behavior alignment. Experimental results show substantial gains over baselines, particularly for Qwen, where fine-tuning improved end-to-end answer correctness from 0.069 to 0.883 and behavioral adherence from 0.074 to 0.722.

## Method Summary
The framework introduces a reasoning-trace-augmented RAG pipeline with three sequential stages. First, document-level adjudication uses confidence-weighted voting to resolve initial conflicts among retrieved documents. Second, conflict analysis traces and resolves contradictions through comparative reasoning, identifying spurious patterns. Third, grounded synthesis produces final answers while explicitly referencing evidence and maintaining consistency. The CATS pipeline evaluates outputs across four dimensions: groundedness (answer support from evidence), factual correctness (alignment with ground truth), refusal accuracy (appropriate handling of unanswerable questions), and conflict-behavior alignment (proper reasoning about contradictions). The approach is validated through fine-tuning experiments on the Qwen model using a synthetic WikiData-based corpus with varying conflict scenarios.

## Key Results
- Qwen fine-tuning improved end-to-end answer correctness from 0.069 to 0.883
- Behavioral adherence increased from 0.074 to 0.722 after fine-tuning
- Framework demonstrates strong performance on document-level adjudication and conflict resolution tasks

## Why This Works (Mechanism)
The framework's effectiveness stems from its structured approach to evidence evaluation and contradiction resolution. By introducing explicit reasoning traces at each stage, the system can identify and resolve conflicts systematically rather than relying on opaque model decisions. The document-level adjudication stage prevents cascade failures by resolving contradictions early, while the conflict analysis stage ensures spurious patterns are detected and corrected. The grounded synthesis stage maintains consistency by explicitly referencing evidence, reducing hallucination risks. The CATS pipeline provides targeted feedback for fine-tuning, enabling the model to learn specific patterns of reliable reasoning.

## Foundational Learning

**RAG Architecture**: Why needed - Understanding how retrieval augments generation; Quick check - Can trace document retrieval and generation flow

**Conflict Resolution**: Why needed - Core challenge in multi-document scenarios; Quick check - Can identify when and how conflicts arise in retrieved documents

**Reasoning Traces**: Why needed - Enables interpretability and debugging; Quick check - Can distinguish between different reasoning paths in model outputs

**Fine-tuning for Reliability**: Why needed - Standard pretraining doesn't optimize for consistency; Quick check - Can explain how feedback loops improve model behavior

**Trust Scoring**: Why needed - Quantitative evaluation of reliability dimensions; Quick check - Can compute and interpret CATS scores

## Architecture Onboarding

**Component Map**: Document Retriever -> Document Adjudicator -> Conflict Analyzer -> Grounded Synthesizer -> CATS Evaluator

**Critical Path**: Retrieval → Adjudication → Conflict Analysis → Synthesis → Evaluation

**Design Tradeoffs**: Explicit reasoning traces increase computational cost but improve interpretability and reliability; early conflict resolution prevents cascade failures but may discard potentially useful evidence; fine-tuning for specific behaviors improves performance but may reduce general capability

**Failure Signatures**: Cascade failures from unresolved conflicts; spurious reasoning patterns; hallucination when evidence is insufficient; inconsistent handling of contradictory information

**First Experiments**: 1) Test conflict resolution on synthetic contradictory documents; 2) Evaluate CATS scoring on known reliable vs unreliable answers; 3) Measure performance degradation when reasoning traces are disabled

## Open Questions the Paper Calls Out
None

## Limitations
- Experimental scope limited to Qwen model and WikiData domain, limiting generalizability claims
- Conflict detection mechanism relies on internal reasoning traces whose reliability outside controlled conditions is unclear
- Evaluation metrics combine multiple factors into single scores without clear justification for weighting

## Confidence

| Claim | Confidence |
|-------|------------|
| Qwen fine-tuning effectiveness | High |
| Framework generalizability | Medium |
| CATS pipeline reliability | Medium |
| Reasoning trace interpretability | Low |

## Next Checks

1. Evaluate the framework on multiple model families (GPT, Llama, Claude) to test generalizability beyond Qwen
2. Test performance on adversarial queries designed to trigger reasoning errors or exploit conflict detection weaknesses
3. Conduct ablation studies isolating the contribution of each reasoning stage to identify the most critical components