---
ver: rpa2
title: 'Multimodal Mathematical Reasoning Embedded in Aerial Vehicle Imagery: Benchmarking,
  Analysis, and Exploration'
arxiv_id: '2509.10059'
source_url: https://arxiv.org/abs/2509.10059
tags:
- vehicles
- reasoning
- image
- vehicle
- vlms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AVI-MATH, the first benchmark for evaluating
  multimodal mathematical reasoning in aerial vehicle imagery. The dataset contains
  3,773 high-quality vehicle-related questions covering 6 mathematical subjects and
  20 topics, collected from UAV imagery at varying altitudes and angles to reflect
  real-world scenarios.
---

# Multimodal Mathematical Reasoning Embedded in Aerial Vehicle Imagery: Benchmarking, Analysis, and Exploration

## Quick Facts
- arXiv ID: 2509.10059
- Source URL: https://arxiv.org/abs/2509.10059
- Reference count: 6
- Primary result: Best model (GPT-4o) achieves only 34.6% accuracy on UAV mathematical reasoning benchmark

## Executive Summary
This paper introduces AVI-MATH, the first benchmark for evaluating multimodal mathematical reasoning in aerial vehicle imagery. The dataset contains 3,773 high-quality vehicle-related questions covering 6 mathematical subjects and 20 topics, collected from UAV imagery at varying altitudes and angles to reflect real-world scenarios. When benchmarked on 14 prominent vision-language models, even the best model (GPT-4o) achieved only 34.6% accuracy, highlighting significant limitations in current models' mathematical reasoning capabilities. The paper also explores Chain-of-Thought prompting and fine-tuning techniques, demonstrating their potential to improve performance. A 215K-sample instruction set (AVI-MATH-215K) is introduced to enable models to learn domain-specific knowledge in UAV scenarios.

## Method Summary
The study evaluates 14 prominent vision-language models on the AVI-MATH benchmark using a two-stage inference process: first generating reasoning, then extracting answers via regex. Fine-tuning experiments use LoRA (rank 64) applied only to LLM attention layers while freezing visual encoders and projectors. Training employs AdamW optimizer with learning rate 1e-4, linear decay, and 0.03 warmup ratio. Models are fine-tuned on AVI-MATH-215K instruction set using 8x NVIDIA V100 (32GB) GPUs with ZeRO-2 stage optimization for memory efficiency. The evaluation protocol requires processing 4K UAV images while preserving fine-grained details for mathematical calculations.

## Key Results
- Best-performing model (GPT-4o) achieves only 34.6% accuracy on AVI-MATH benchmark
- Standard VLMs struggle with mathematical reasoning in UAV imagery due to resolution constraints and domain knowledge gaps
- LoRA fine-tuning on AVI-MATH-215K improves performance by 68% for DeepSeek-VL
- CLIP's token constraints and low input resolutions significantly harm mathematical reasoning capabilities

## Why This Works (Mechanism)

### Mechanism 1: Domain-Specialized Instruction Tuning
Parameter-efficient fine-tuning (LoRA) on domain-specific instruction sets substantially improves VLM performance on UAV mathematical reasoning. By injecting curated reasoning chains and domain-specific knowledge into LLM adaptor layers, models learn to map high-resolution aerial features to mathematical operations previously absent from pre-training. Performance gap is primarily due to distribution shift and lack of domain knowledge rather than fundamental architectural limitations.

### Mechanism 2: High-Resolution Visual Token Retention
Mathematical reasoning in aerial imagery relies heavily on preserving fine-grained visual details, hindered by vision encoders with aggressive token constraints. Standard VLMs downsample 4K UAV images to low resolutions (e.g., 336x336), obliterating pixel-level data required for precise coordinate transformation and small object recognition. Models using dynamic resolution or native higher-token encoders retain more spatial information, enabling better geometric reasoning.

### Mechanism 3: Chain-of-Thought Dependency on Baseline Knowledge
Chain-of-Thought prompting improves reasoning accuracy only when models possess sufficient baseline domain knowledge. For models lacking this, CoT can induce performance degradation through hallucination or refusals. CoT elicits existing capabilities but does not "teach" missing domain knowledge during inference.

## Foundational Learning

- **Coordinate System Transformation (Pinhole Camera Model)**: Converting 2D pixel coordinates from UAV images into 3D camera or world coordinates for distance and area calculations. Quick check: Given drone altitude $H$ and pitch angle $\theta$, can you derive mapping from pixel $(u, v)$ to ground plane coordinate $Y_C$?

- **Parameter-Efficient Fine-Tuning (LoRA)**: Understanding how rank-$r$ updates are applied to attention layers for domain adaptation without full model retraining. Quick check: How does freezing vision encoder weights during LoRA affect adaptation to new visual scales?

- **Multimodal Answer Extraction (Regex & Formatting)**: The two-stage evaluation process where free-form responses must be parsed using regex patterns. Quick check: If model outputs "distance is approx 23.0m" but ground truth is float `23.0`, would regex stripping units correctly align these?

## Architecture Onboarding

- **Component map**: Visual Encoder -> Projector -> LLM Backbone -> Evaluation Pipeline
- **Critical path**: High-Res Input Handling (4K resolution) -> Context Injection (metadata) -> Generation (reasoning + answer) -> Parsing (regex extraction)
- **Design tradeoffs**: Resolution vs. Context Window (high-res inputs consume massive context), Generalist vs. Specialist (fine-tuning improves scores but risks forgetting)
- **Failure signatures**: Refusal Loops ("Not possible" outputs), Projection Hallucination (physically impossible distances), Format Mismatch (text vs. expected format)
- **First 3 experiments**: Resolution Ablation (336px vs. 2000px testing), Zero-Shot CoT Baseline (standard prompting verification), LoRA Overfitting Test (single topic training and cross-topic evaluation)

## Open Questions the Paper Calls Out

### Open Question 1
Can reinforcement fine-tuning replace supervised fine-tuning to prevent generalization degradation in Remote Sensing VLMs? The authors suggest supervised fine-tuned models perform well on in-domain datasets but significantly lag on out-domain tests, indicating reinforcement learning could be a promising alternative.

### Open Question 2
How can VLM architectures be adapted to effectively process 4K input resolutions without losing critical visual features? Current models struggle with token limits and visual encoder constraints, showing performance collapse when resolution exceeds 2000 pixels.

### Open Question 3
What specific training data augmentations are needed to improve VLM generalization across non-orthographic viewing angles? Models perform significantly worse at 45-degree pitch angles compared to 90 degrees, suggesting the need for balanced viewing angle distributions.

## Limitations
- Evaluation protocol's two-stage inference (generation + regex extraction) introduces parsing fragility, particularly for numerical and list-based answers
- Benchmark's focus on vehicle-centric scenarios (urban roads, parking lots) may not generalize to other UAV applications
- Performance improvements from fine-tuning may represent overfitting to AVI-MATH domain rather than genuine reasoning capability transfer

## Confidence

- **High Confidence**: VLMs struggle with multimodal mathematical reasoning in UAV imagery (34.6% accuracy for best model) and CLIP's token constraints as bottleneck are empirically validated
- **Medium Confidence**: LoRA fine-tuning effectiveness and CoT dependency on baseline knowledge are supported but rely on indirect inference
- **Low Confidence**: CoT prompting universally degrades performance when domain knowledge is lacking, based on single model behavior

## Next Checks

1. **Evaluation Protocol Robustness**: Re-run benchmark using direct answer formatting (JSON templates) instead of regex extraction to determine if parsing errors artificially suppress scores

2. **Cross-Domain Generalization Test**: Fine-tune VLM on AVI-MATH-215K and evaluate performance on non-vehicle mathematical reasoning tasks to quantify potential catastrophic forgetting

3. **Resolution Sensitivity Analysis**: Systematically vary input resolution across full range (336px to 4K) for multiple model architectures to quantify visual token retention threshold where performance plateaus or degrades