---
ver: rpa2
title: Integrating Neural and Symbolic Components in a Model of Pragmatic Question-Answering
arxiv_id: '2506.01474'
source_url: https://arxiv.org/abs/2506.01474
tags:
- pragmatic
- question
- human
- questioner
- responses
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a neuro-symbolic framework that integrates
  large language models (LLMs) with probabilistic cognitive models to simulate pragmatic
  question-answering. The method replaces hand-specified components of cognitive models
  with LLM-based evaluators and proposers, systematically varying the degree of neural
  integration.
---

# Integrating Neural and Symbolic Components in a Model of Pragmatic Question-Answering

## Quick Facts
- arXiv ID: 2506.01474
- Source URL: https://arxiv.org/abs/2506.01474
- Reference count: 40
- One-line primary result: Hybrid neuro-symbolic models achieve human-like pragmatic question-answering performance by integrating LLMs with probabilistic cognitive models, matching or exceeding traditional approaches.

## Executive Summary
This paper introduces a neuro-symbolic framework that integrates large language models (LLMs) with probabilistic cognitive models to simulate pragmatic question-answering. The method replaces hand-specified components of cognitive models with LLM-based evaluators and proposers, systematically varying the degree of neural integration. The primary result shows that hybrid models achieve performance on par with or exceeding traditional probabilistic models in predicting human answer patterns (matching a baseline of 0.154 Jensen-Shannon divergence), particularly when LLMs are used for utility evaluation and alternative generation rather than truth-conditional semantics. The framework offers a promising path toward more flexible, scalable models of pragmatic language use while highlighting key design considerations for balancing neural and symbolic components.

## Method Summary
The neuro-symbolic framework integrates LLMs with a probabilistic cognitive model (RSA) for pragmatic question-answering. The symbolic scaffolding decomposes the task into subtasks: goal inference, utility evaluation, response selection, and semantic checking. LLMs execute individual subtasks while the symbolic architecture orchestrates information flow and Bayesian inference. The method incrementally replaces components of a WebPPL-based QA model with LLM modules, testing various integration strategies including prompt-based questioners, one-shot CoT, and full neuro-symbolic systems. The framework uses 30 commonsense vignettes and evaluates models using Jensen-Shannon divergence against human response distributions.

## Key Results
- Hybrid models match or exceed traditional probabilistic models, achieving Jensen-Shannon divergence comparable to the baseline (0.154)
- LLM-based utility evaluation correlates highly with human ratings (R = 0.92), improving model fit
- Fine-grained task decomposition based on cognitive theory is essential for good performance with LLM modules
- Truth-conditional semantic evaluation remains a bottleneck, with LLMs over-accepting unrelated responses

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-grained task decomposition based on cognitive theory scaffolds LLM performance for complex pragmatic reasoning.
- Mechanism: The Rational Speech Act (RSA) framework provides a symbolic task analysis that decomposes question-answering into subtasks: goal inference, utility evaluation, response selection, and semantic checking. LLMs execute individual subtasks while the symbolic architecture orchestrates information flow and Bayesian inference