---
ver: rpa2
title: Network of Theseus (like the ship)
arxiv_id: '2512.04198'
source_url: https://arxiv.org/abs/2512.04198
tags:
- network
- training
- guide
- architecture
- replacement
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Network of Theseus (NoT), a method for progressively
  converting a trained or untrained guide network architecture into an entirely different
  target network architecture while preserving performance. The method incrementally
  replaces components of the guide network with target modules and aligns them using
  representational similarity metrics like CKA and a newly introduced D-MNN metric.
---

# Network of Theseus (like the ship)

## Quick Facts
- arXiv ID: 2512.04198
- Source URL: https://arxiv.org/abs/2512.04198
- Reference count: 39
- Progressive architectural conversion while preserving performance

## Executive Summary
Network of Theseus (NoT) is a method for converting a trained or untrained guide network architecture into an entirely different target architecture while preserving performance. The approach incrementally replaces components of the guide network with target modules and aligns them using representational similarity metrics like CKA and a newly introduced D-MNN metric. NoT enables architectural transfer across families such as CNNs to MLPs, vision transformers to patch-wise MLPs, and transformers to RNNs, even working with untrained guide networks to transfer useful inductive biases.

## Method Summary
The method works by progressively replacing components of a guide network with target architecture modules while maintaining alignment through representational similarity metrics. It uses a sequential replacement schedule where components are swapped one at a time, followed by training to align the representations. The approach employs CKA (Centered Kernel Alignment) and a newly introduced D-MNN (Distribution-based Maximum Neural Network) metric to measure and optimize representational similarity during the transfer process. The progressive replacement schedule outperforms alternatives like joint or independent replacement, with different replacement rates (slow, medium, fast) showing varying trade-offs between preservation of performance and convergence speed.

## Key Results
- Progressive replacement outperforms joint and independent replacement strategies
- Works effectively even with untrained guide networks, transferring inductive biases
- Smaller target networks can match or exceed baseline performance after conversion
- Successfully transfers between diverse architectures: CNNs→MLPs, ViTs→patch-wise MLPs, transformers→RNNs

## Why This Works (Mechanism)
The method leverages the observation that architectural priors primarily serve as training scaffolds rather than being fundamental to inference. By progressively replacing components while maintaining representational alignment through similarity metrics, the network can transfer learned representations and inductive biases from the guide architecture to the target architecture. The use of both CKA and D-MNN metrics provides complementary views of representational similarity, with D-MNN offering better sensitivity to distributional differences. The sequential nature of replacement allows the target architecture to gradually adapt to the guide's learned representations rather than facing the complexity of wholesale transformation.

## Foundational Learning
- **Representational similarity metrics (CKA, D-MNN)**: Why needed - to measure and optimize alignment between architectures; Quick check - compare metric values across different network pairs
- **Progressive vs. joint replacement**: Why needed - gradual adaptation prevents catastrophic forgetting; Quick check - test convergence curves for different replacement schedules
- **Architectural transfer across families**: Why needed - enables design freedom in deployment architectures; Quick check - validate on diverse architecture pairs
- **Inductive bias transfer**: Why needed - allows untrained networks to benefit from architectural advantages; Quick check - compare trained vs. untrained guide performance

## Architecture Onboarding
- **Component map**: Guide network → Sequential component replacement → Target network alignment → Performance preservation
- **Critical path**: Component replacement → Representation alignment (CKA/D-MNN) → Performance validation
- **Design tradeoffs**: Slow replacement preserves more performance but takes longer; fast replacement converges quicker but may lose some accuracy
- **Failure signatures**: Performance drop indicates misalignment; poor convergence suggests replacement rate too aggressive
- **First experiments**: 1) Test progressive vs. joint replacement on simple architecture pairs, 2) Compare CKA vs. D-MNN alignment effectiveness, 3) Validate untrained guide network transfer capability

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided material.

## Limitations
- Primarily tested on relatively small-scale architectures, scalability to larger networks uncertain
- Representational similarity metrics may not capture all relevant functional aspects
- Impact of different initialization strategies on progressive replacement not thoroughly investigated

## Confidence
- High Confidence: The core methodology of progressive replacement and alignment using representational similarity metrics is sound and well-demonstrated
- Medium Confidence: The claim that architectural priors are primarily training scaffolds rather than inference constraints is supported but may not generalize to all network types
- Low Confidence: The assertion that NoT can effectively transfer between vastly different architectural families with consistently good results needs more extensive validation

## Next Checks
1. Test NoT on larger-scale architectures (e.g., ResNet-50 to EfficientNet-B0) to assess scalability and performance preservation
2. Evaluate the method's robustness to different initialization strategies and compare the impact on final performance
3. Conduct extensive experiments across multiple diverse tasks and datasets to validate the generality of architectural transfer claims