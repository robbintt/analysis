---
ver: rpa2
title: Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning
  large language model agent
arxiv_id: '2512.20586'
source_url: https://arxiv.org/abs/2512.20586
tags:
- reasoning
- planning
- clinical
- dose
- treatment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "SAGE, an LLM-based agent for automated SRS treatment planning,\
  \ was developed and tested using 41 retrospective brain metastases cases. Two model\
  \ variants\u2014non-reasoning (Llama 3.1-70B) and reasoning (Qwen QwQ-32B-Reasoning)\u2014\
  were compared."
---

# Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent

## Quick Facts
- arXiv ID: 2512.20586
- Source URL: https://arxiv.org/abs/2512.20586
- Reference count: 40
- LLM-based SRS planning agent achieves comparable clinical outcomes to human planners

## Executive Summary
This study presents SAGE, a human-in-the-loop LLM-based agent for automated stereotactic radiosurgery (SRS) treatment planning. The agent was evaluated on 41 retrospective brain metastases cases using two model variants: a non-reasoning model (Llama 3.1-70B) and a reasoning model (Qwen QwQ-32B-Reasoning). Both models achieved comparable target coverage and organ-at-risk (OAR) sparing to human planners, with the reasoning model demonstrating specific advantages in constraint handling and plan refinement. The reasoning model showed significantly lower cochlear doses (p=0.022) and improved conformity index after refinement, while also exhibiting fewer format errors.

## Method Summary
SAGE is a clinician-in-the-loop LLM-based agent for automated SRS treatment planning. The system uses iterative refinement through Monte Carlo tree search (MCTS) and planning agents that generate and modify dose plans. The study evaluated two model variants on 41 retrospective brain metastases cases, comparing their performance against human planner-generated plans using clinical metrics including target coverage, conformity index, homogeneity index, Paddick conformity index, and organ-at-risk doses. The reasoning model incorporated prospective constraint verification, trade-off deliberation, and forward simulation mechanisms.

## Key Results
- Both LLM agents achieved comparable target coverage and OAR sparing to human planners
- Reasoning model produced significantly lower cochlear doses (p=0.022) compared to non-reasoning model
- Reasoning model showed improved conformity index after refinement and fewer format errors (median 0 vs. 3 per patient)
- Mechanistic analysis revealed 457 instances of prospective constraint verification, 609 trade-off deliberations, and 1,888 forward simulations by reasoning model

## Why This Works (Mechanism)
The reasoning model's architectural advantages enable more sophisticated constraint handling and plan optimization. The Monte Carlo tree search with look-ahead planning allows the model to simulate multiple planning scenarios before committing to modifications. This deliberative approach enables the system to identify potential constraint violations early and explore trade-offs systematically rather than making local adjustments. The human-in-the-loop design ensures clinical oversight while leveraging the model's ability to explore the planning space more exhaustively than manual approaches.

## Foundational Learning
- Monte Carlo tree search in optimization (why needed: enables systematic exploration of planning alternatives; quick check: compare MCTS-based planning to greedy approaches)
- Constraint satisfaction in radiation oncology (why needed: ensures safe delivery of therapeutic dose; quick check: verify OAR dose limits are consistently met)
- Multi-objective optimization tradeoffs (why needed: balances target coverage against OAR sparing; quick check: analyze Pareto fronts of competing objectives)
- LLM-based reasoning architectures (why needed: enables deliberative planning over sequential decisions; quick check: compare reasoning vs non-reasoning model performance)
- Clinical metric validation (why needed: ensures plans meet safety and efficacy standards; quick check: compare against physician-generated plans using standardized metrics)
- Iterative refinement processes (why needed: improves initial plan quality through multiple passes; quick check: measure improvement in metrics across refinement iterations)

## Architecture Onboarding
**Component Map:** Input case data -> Preprocessor -> LLM Reasoning Engine -> MCTS Planner -> Output Dose Plan -> Human Clinician Review
**Critical Path:** The reasoning engine with MCTS is the critical path, as it performs the core optimization and constraint satisfaction work that distinguishes the system's performance
**Design Tradeoffs:** Reasoning architecture provides better constraint handling but requires more computational resources; non-reasoning model is faster but makes more format errors
**Failure Signatures:** Format errors (median 3 per patient for non-reasoning model), constraint violations, suboptimal conformity indices
**First Experiments:**
1. Compare reasoning vs non-reasoning model performance on a small test set of 5 cases
2. Test MCTS planning depth impact on plan quality metrics
3. Evaluate human clinician agreement with LLM-generated plans on critical OAR constraints

## Open Questions the Paper Calls Out
None

## Limitations
- Retrospective single-institution study with limited dataset of 41 cases
- Validation metrics don't capture all aspects of plan quality or long-term clinical outcomes
- Reasoning model advantages require prospective validation to confirm clinical significance

## Confidence
- Target coverage and OAR sparing equivalence: High
- Reasoning model superiority in constraint handling: Medium
- Generalizability across institutions: Low

## Next Checks
1. Conduct prospective clinical trials comparing LLM-generated plans with physician-generated plans across multiple institutions
2. Evaluate reasoning model performance on more complex cases with multiple targets and irregular anatomies
3. Assess long-term clinical outcomes and toxicity profiles of patients receiving LLM-generated SRS plans