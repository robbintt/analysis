---
ver: rpa2
title: 'When Structure Doesn''t Help: LLMs Do Not Read Text-Attributed Graphs as Effectively
  as We Expected'
arxiv_id: '2511.16767'
source_url: https://arxiv.org/abs/2511.16767
tags:
- graph
- structural
- llms
- graphs
- uni00000011
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper systematically challenges the assumption that graph\
  \ structure is inherently beneficial for LLM-based graph reasoning. Through extensive\
  \ experiments on text-attributed graphs (TAGs) and molecular datasets, the authors\
  \ demonstrate that explicit structural encodings\u2014whether handcrafted templates\
  \ like Laplacian embeddings or learned GNN-based adapters\u2014often provide little\
  \ to no performance gain."
---

# When Structure Doesn't Help: LLMs Do Not Read Text-Attributed Graphs as Effectively as We Expected

## Quick Facts
- **arXiv ID**: 2511.16767
- **Source URL**: https://arxiv.org/abs/2511.16767
- **Reference count**: 23
- **Primary result**: LLMs perform competitively or better on text-attributed graphs using only node textual descriptions, with explicit structural encodings often providing no benefit or even degrading performance.

## Executive Summary
This paper systematically challenges the assumption that graph structure is inherently beneficial for LLM-based graph reasoning. Through extensive experiments on text-attributed graphs (TAGs) and molecular datasets, the authors demonstrate that explicit structural encodings—whether handcrafted templates like Laplacian embeddings or learned GNN-based adapters—often provide little to no performance gain. Surprisingly, LLMs perform competitively or even better when relying solely on node textual descriptions, effectively treating graphs as unordered sets of semantic content. These findings hold across different model scales, semantic richness levels, and graph types, suggesting that rich node semantics dominate over explicit topology. The work advocates for semantics-driven graph learning in the LLM era, where structural augmentation is often redundant or even detrimental, and calls for rethinking how structure should be represented and utilized in future graph foundation models.

## Method Summary
The authors conducted systematic experiments across multiple datasets (OGB-MOL, OGB-PCQM4M, IMDB-BINARY, IMDB-MULTI, COLLAB) comparing three representation strategies: (1) text-only node descriptions, (2) handcrafted Laplacian embedding templates, and (3) learned GNN-based adapters. They evaluated performance across different LLM scales (7B, 13B, 70B parameters) and semantic richness levels. The experimental design included both zero-shot and few-shot settings, with careful control for confounding factors like prompt formatting and token efficiency. The study systematically varied graph density and semantic richness to understand when structure might become beneficial.

## Key Results
- LLMs using only node textual descriptions achieved performance comparable to or better than models using explicit structural encodings across multiple datasets
- Handcrafted Laplacian embedding templates and learned GNN adapters provided minimal to negative performance impact
- The advantage of text-only representations was consistent across different model scales (7B to 70B parameters)
- Rich node semantics dominated over explicit topology, with LLMs effectively treating graphs as unordered sets of semantic content

## Why This Works (Mechanism)
The paper demonstrates that when node textual descriptions are semantically rich, they contain sufficient information for LLMs to infer implicit relationships and patterns without explicit structural encoding. LLMs appear to extract relational information directly from the semantic content of node descriptions, making additional structural signals redundant or even confusing. The negative impact of structural augmentation on certain models suggests architectural mismatches where explicit topology interferes with the LLM's natural pattern recognition capabilities.

## Foundational Learning
- **Text-attributed graphs (TAGs)**: Graphs where nodes have rich textual descriptions rather than simple categorical labels - needed because this is the specific graph type being studied, quick check: verify datasets actually contain detailed node text
- **Graph neural networks (GNNs)**: Neural architectures designed to process graph-structured data - needed as baseline comparison method, quick check: understand how GNNs typically handle structure
- **Laplacian embeddings**: Mathematical representations capturing graph topology - needed as one of the structural encoding methods tested, quick check: know what graph properties these encode
- **Semantic richness**: The depth and informativeness of node textual descriptions - needed to understand when structure becomes redundant, quick check: measure vocabulary diversity and information content
- **Zero-shot vs few-shot learning**: Different prompting paradigms for LLMs - needed to test generalizability across usage scenarios, quick check: understand prompt engineering differences
- **Token efficiency**: How effectively LLMs use their input token budget - needed to understand performance tradeoffs, quick check: track token usage across methods

## Architecture Onboarding

**Component Map**: Text Descriptions + Optional Structure Encodings -> LLM Processing -> Output Predictions

**Critical Path**: Raw node text descriptions → Tokenization → LLM context window → Reasoning → Classification

**Design Tradeoffs**: The core tradeoff is between simplicity (text-only) and completeness (text+structure). While structural encodings theoretically provide additional information, they introduce complexity, token overhead, and potential interference with the LLM's natural semantic processing capabilities.

**Failure Signatures**: Negative performance impact from structural augmentation suggests architectural mismatches where explicit topology conflicts with the LLM's learned semantic representations. Token inefficiency and prompt formatting issues can also degrade performance.

**First Experiments**: 1) Ablation study removing structure from high-performing models to isolate semantic contribution, 2) Analysis of token usage patterns to quantify efficiency gains, 3) Qualitative error analysis comparing text-only vs structure-augmented predictions to identify systematic differences

## Open Questions the Paper Calls Out
The authors note that their findings may not generalize to domains with sparse or noisy textual attributes, where structural signals might become more critical. They also acknowledge that structure-sensitive tasks like link prediction or node clustering, which were not covered in their evaluation, might show different patterns. The observed negative impact of structural augmentation suggests potential architectural mismatches that require deeper investigation.

## Limitations
- The findings rely heavily on experimental setups where node textual descriptions are already rich and detailed, which may not generalize to domains where text is sparse or noisy
- The evaluation focuses on classification and reasoning tasks; other downstream applications such as link prediction or node clustering, which are more structure-dependent, are not covered
- The observed negative impact of structural augmentation on certain models suggests potential architectural mismatches, but the root causes are not deeply investigated

## Confidence
- **High confidence**: The core empirical finding that explicit structural encodings rarely improve LLM performance on text-attributed graphs when node descriptions are semantically rich
- **Medium confidence**: The broader claim that semantics dominate over structure in LLM-based graph reasoning, given the limited exploration of sparse/noisy text scenarios
- **Low confidence**: The generalizability of these results to all graph learning tasks, especially those more reliant on topology (e.g., link prediction, community detection)

## Next Checks
1. Test the same experimental setup on datasets with sparse or noisy node textual attributes to assess whether structure becomes more beneficial under low semantic richness
2. Evaluate performance on structure-sensitive tasks such as link prediction or node clustering to determine if the observed pattern holds across diverse graph learning objectives
3. Investigate architectural reasons for the negative impact of structural augmentation by conducting ablation studies on the learned GNN adapter modules