---
ver: rpa2
title: Finetuning LLMs for EvaCun 2025 token prediction shared task
arxiv_id: '2510.15561'
source_url: https://arxiv.org/abs/2510.15561
tags:
- masked
- task
- word
- words
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper presents a token prediction system for EvaCun 2025,
  targeting missing word restoration in Akkadian and Sumerian cuneiform texts. The
  authors fine-tuned three autoregressive LLMs (Command-R, Mistral, and Aya Expanse)
  on transliterated task data using three different prompting strategies: generating
  all missing words at once, predicting one word at a time, and restoring the full
  document.'
---

# Finetuning LLMs for EvaCun 2025 token prediction shared task

## Quick Facts
- **arXiv ID:** 2510.15561
- **Source URL:** https://arxiv.org/abs/2510.15561
- **Reference count:** 2
- **Primary result:** Fine-tuned LLMs achieved 22.1% token prediction accuracy for cuneiform text restoration, with majority voting across 60 checkpoints improving performance to 26.9%

## Executive Summary
This paper presents a token prediction system for EvaCun 2025's shared task on missing word restoration in Akkadian and Sumerian cuneiform texts. The authors fine-tuned three autoregressive large language models (Command-R, Mistral, and Aya Expanse) using transliterated task data and three different prompting strategies. The approach demonstrates the feasibility of using modern LLMs for cuneiform text restoration, providing a baseline for future work in this specialized domain.

## Method Summary
The authors fine-tuned three autoregressive LLMs on transliterated cuneiform text data using three prompting strategies: generating all missing words at once, predicting one word at a time, and restoring full documents. They trained 60 checkpoints per model and employed majority voting across these checkpoints to improve prediction accuracy. The system targeted the EvaCun 2025 shared task's objective of restoring missing words in ancient Mesopotamian texts.

## Key Results
- Best-performing approach achieved 22.1% accuracy on held-out validation data
- Majority voting across 60 checkpoints improved performance to 26.9% accuracy
- Fine-tuning three different LLMs (Command-R, Mistral, Aya Expanse) established baseline performance for cuneiform text restoration

## Why This Works (Mechanism)
The system leverages the strong contextual understanding of large language models, which have been trained on vast multilingual corpora including ancient languages. By fine-tuning these models on transliterated cuneiform texts, they learn the specific patterns, grammar, and vocabulary of Akkadian and Sumerian. The majority voting mechanism across multiple checkpoints helps reduce individual model errors and improves overall prediction reliability by aggregating diverse outputs.

## Foundational Learning

**Transliteration of cuneiform texts** - The conversion of cuneiform script into Latin characters is essential for computational processing. *Why needed:* Modern NLP tools work with text, not symbolic scripts. *Quick check:* Verify that transliterated outputs maintain semantic equivalence to original cuneiform.

**Autoregressive language modeling** - Models that predict tokens sequentially based on previous context. *Why needed:* Enables step-by-step reconstruction of missing words in context. *Quick check:* Confirm that token dependencies are properly captured in the model's attention mechanisms.

**Fine-tuning vs. prompting** - Adjusting pre-trained model weights on domain-specific data versus using zero/few-shot prompting. *Why needed:* Domain adaptation improves performance on specialized tasks like cuneiform restoration. *Quick check:* Compare fine-tuned model performance against prompt-based approaches on validation data.

## Architecture Onboarding

**Component map:** Data preprocessing -> Model fine-tuning -> Inference generation -> Majority voting -> Accuracy evaluation

**Critical path:** Transliterated text → Fine-tuned LLM → Predicted tokens → Majority voting → Final prediction

**Design tradeoffs:** The choice between single-pass generation versus iterative word-by-word prediction represents a fundamental tradeoff between computational efficiency and accuracy potential.

**Failure signatures:** Low accuracy may stem from insufficient training data, poor transliteration quality, or models failing to capture the unique linguistic features of ancient languages.

**First experiments:** 1) Test model performance on short, simple sentences before scaling to complex texts, 2) Evaluate individual checkpoint predictions to identify patterns in errors, 3) Compare majority voting effectiveness across different numbers of checkpoints

## Open Questions the Paper Calls Out
None

## Limitations
- Accuracy figures (22.1% best case) suggest significant room for improvement
- Validation data may not fully represent the complexity of real-world cuneiform texts
- Fine-tuning used only 10 epochs with early stopping, potentially suboptimal training duration
- Three prompting strategies represent a narrow exploration of possible approaches

## Confidence
- **Foundational feasibility of LLM-based restoration:** Medium
- **Reported accuracy numbers:** Medium
- **Generalizability to unseen text types:** Low
- **Effectiveness of majority voting mechanism:** Medium

## Next Checks
1. Evaluate the system on a held-out test set with no overlap with training data to verify true generalization performance
2. Test the robustness of predictions across different cuneiform genres and time periods not represented in the training corpus
3. Compare the LLM-based approach against traditional rule-based restoration methods used by Assyriologists to establish whether the computational approach provides genuine advantages