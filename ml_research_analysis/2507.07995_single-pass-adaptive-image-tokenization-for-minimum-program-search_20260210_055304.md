---
ver: rpa2
title: Single-pass Adaptive Image Tokenization for Minimum Program Search
arxiv_id: '2507.07995'
source_url: https://arxiv.org/abs/2507.07995
tags:
- token
- tokens
- image
- reconstruction
- complexity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: KARL introduces a single-pass adaptive image tokenizer that predicts
  the appropriate number of tokens for each image in one forward pass, rather than
  requiring iterative search. Inspired by Kolmogorov Complexity, it learns to halt
  token generation once the desired reconstruction quality is achieved.
---

# Single-pass Adaptive Image Tokenization for Minimum Program Search

## Quick Facts
- arXiv ID: 2507.07995
- Source URL: https://arxiv.org/abs/2507.07995
- Authors: Shivam Duggal; Sanghyun Byun; William T. Freeman; Antonio Torralba; Phillip Isola
- Reference count: 40
- Key outcome: KARL achieves single-pass adaptive tokenization, predicting optimal token counts in one forward pass while matching or exceeding state-of-the-art reconstruction metrics without iterative search

## Executive Summary
KARL introduces a novel single-pass adaptive image tokenizer that predicts the appropriate number of tokens for each image in one forward pass, rather than requiring iterative search. Inspired by Kolmogorov Complexity, it learns to halt token generation once the desired reconstruction quality is achieved. The training strategy mimics upside-down reinforcement learning: first attempting lossless compression, then using the resulting loss as a condition to learn when to stop. This enables efficient, adaptive inference without multiple encoder-decoder runs.

The method matches or exceeds the performance of recent adaptive tokenizers on image reconstruction metrics (LPIPS, SSIM, PSNR, DreamSim) while being uniquely single-pass. It also aligns predicted token counts with human judgments of image complexity, offering a conceptual link between adaptive tokenization and Algorithmic Information Theory.

## Method Summary
KARL is a single-pass adaptive image tokenizer that predicts the optimal number of tokens for each image without iterative search. The core innovation is a halting mechanism that learns when to stop token generation based on reconstruction quality. Training follows an upside-down RL approach: first training for lossless compression to establish a target quality threshold, then training the halting mechanism to stop at that quality level. The tokenizer takes an image and outputs both tokens and a halting prediction, enabling efficient inference in one forward pass. This design eliminates the need for multiple encoder-decoder runs required by previous adaptive methods.

## Key Results
- Achieves state-of-the-art or comparable performance on image reconstruction metrics (LPIPS, SSIM, PSNR, DreamSim) compared to adaptive tokenizers requiring iterative search
- Successfully predicts token counts in a single forward pass without multiple encoder-decoder runs
- Demonstrates alignment between predicted token counts and human judgments of image complexity, providing a practical link to Kolmogorov Complexity principles

## Why This Works (Mechanism)
KARL works by learning a halting policy that predicts when sufficient information has been captured for reconstruction. The two-stage training approach first establishes a quality threshold through lossless compression training, then conditions the halting decision on the reconstruction loss. This creates a self-supervised signal that teaches the model when to stop generating tokens. The single-pass nature eliminates computational overhead from iterative search while maintaining adaptive capability. By aligning with Kolmogorov Complexity principles, the method naturally balances compression efficiency with reconstruction fidelity.

## Foundational Learning
- Kolmogorov Complexity - why needed: Provides theoretical foundation for adaptive tokenization based on image information content; quick check: compare predicted token counts to established complexity measures
- Upside-down Reinforcement Learning - why needed: Enables training of halting policy without explicit reward engineering; quick check: verify training stability across different image categories
- Image Reconstruction Metrics (LPIPS, SSIM, PSNR, DreamSim) - why needed: Quantify reconstruction quality for different perceptual aspects; quick check: ensure metric improvements correlate with human perception studies

## Architecture Onboarding

Component map: Input Image -> Encoder -> Token Generator -> Halting Predictor -> Output Tokens
                         \-> Loss Calculator (for training)

Critical path: Input → Encoder → Token Generator → Halting Predictor → Output, with reconstruction loss feeding back to train the halting decision

Design tradeoffs: Single-pass efficiency vs. potential loss in optimization flexibility compared to iterative methods; simpler inference but potentially more complex training procedure

Failure signatures: Over-generation of tokens leading to inefficiency; under-generation causing poor reconstruction; halting predictor instability during training

First experiments:
1. Train on a small dataset with fixed token counts to establish baseline reconstruction quality
2. Implement the two-stage training with simple halting conditions to verify training stability
3. Test single-pass prediction on held-out images and compare token counts to human judgments

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focuses on reconstruction metrics without addressing downstream task performance or practical utility of generated tokens
- Two-stage training process may introduce instability or sensitivity to hyperparameters not fully explored
- Alignment with human complexity judgments mentioned but not rigorously validated with user studies

## Confidence
- Single-pass efficiency and reconstruction quality: High
- Alignment with human complexity judgments: Medium
- Robustness and generalizability of training approach: Medium

## Next Checks
1. Conduct user studies to statistically validate the alignment between predicted token counts and human judgments of image complexity across diverse image categories
2. Evaluate the utility of KARL-generated tokens in downstream vision tasks (e.g., classification, segmentation) compared to fixed-token baselines to assess practical value beyond reconstruction metrics
3. Perform ablation studies on the two-stage training process and analyze sensitivity to hyperparameters, including training stability and convergence behavior across different datasets