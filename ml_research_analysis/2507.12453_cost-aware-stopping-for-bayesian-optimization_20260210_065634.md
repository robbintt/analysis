---
ver: rpa2
title: Cost-aware Stopping for Bayesian Optimization
arxiv_id: '2507.12453'
source_url: https://arxiv.org/abs/2507.12453
tags:
- pbgi
- logeipc
- stopping
- regret
- cost-adjusted
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the practical challenge of cost-aware stopping
  in Bayesian optimization, a setting where evaluation costs vary across the search
  space and must be balanced against solution quality. The authors propose a principled
  stopping rule grounded in the connection between the Pandora's Box Gittins Index
  (PBGI) and log expected improvement per cost (LogEIPC) acquisition functions.
---

# Cost-aware Stopping for Bayesian Optimization

## Quick Facts
- arXiv ID: 2507.12453
- Source URL: https://arxiv.org/abs/2507.12453
- Reference count: 40
- Key outcome: A principled stopping rule for Bayesian optimization that balances evaluation costs and solution quality, grounded in the connection between Pandora's Box Gittins Index and log expected improvement per cost acquisition functions.

## Executive Summary
This paper tackles the practical challenge of cost-aware stopping in Bayesian optimization, a setting where evaluation costs vary across the search space and must be balanced against solution quality. The authors propose a principled stopping rule grounded in the connection between the Pandora's Box Gittins Index (PBGI) and log expected improvement per cost (LogEIPC) acquisition functions. The key insight is that the Bayesian-optimal stopping condition for PBGI—stop when the minimum Gittins index equals the best observed value—can be equivalently expressed in terms of LogEIPC, yielding a unified stopping rule applicable to both acquisition functions.

Theoretically, the authors prove that their stopping rule, when paired with either PBGI or LogEIPC, guarantees cost-adjusted simple regret no worse than stopping immediately after the first evaluation. Empirically, across synthetic Bayesian regret benchmarks and real-world tasks including hyperparameter tuning and neural architecture search, the proposed stopping rule consistently matches or outperforms existing acquisition-function-stopping-rule pairs in terms of cost-adjusted simple regret. The method is particularly effective in high-cost scenarios and demonstrates robustness even under model mismatch, though performance depends on appropriate choice of acquisition function.

## Method Summary
The proposed method introduces a cost-aware stopping rule for Bayesian optimization that determines when to halt evaluation based on the maximum log expected improvement per cost (LogEIPC) value. The stopping condition triggers when this value drops to zero or below, indicating that no unevaluated point offers expected improvement worth its evaluation cost. This approach is mathematically equivalent to stopping when the minimum PBGI index exceeds the best observed value. The method requires a Gaussian Process surrogate for the objective function and a cost model, with acquisition optimization to find the point maximizing LogEIPC. For high-dimensional problems, a moving average filter is applied to the stopping signal to prevent spurious stops caused by acquisition optimization noise.

## Key Results
- The proposed stopping rule guarantees cost-adjusted simple regret no worse than stopping immediately after the first evaluation.
- Across synthetic benchmarks and real-world tasks, the method consistently matches or outperforms existing acquisition-function-stopping-rule pairs.
- The approach is particularly effective in high-cost scenarios and demonstrates robustness under model mismatch, though performance depends on appropriate acquisition function choice.
- In neural architecture search and hyperparameter tuning tasks, the method achieves competitive results while reducing evaluation costs compared to standard BO approaches.

## Why This Works (Mechanism)

### Mechanism 1: Cost-Adjusted Improvement Threshold
The stopping rule halts optimization exactly when no unevaluated point offers an expected improvement greater than its evaluation cost. It monitors the maximum LogEIPC value and triggers when this drops below zero. This is mathematically equivalent to the condition EI(x) ≤ c(x) for all remaining x.

### Mechanism 2: Theoretical Regret Safety Net
The stopping rule bounds the expected cost-adjusted simple regret to be no worse than stopping immediately after the first evaluation. By ensuring every evaluation yields expected improvement ≥ cost, the cumulative cost is offset by the reduction in simple regret.

### Mechanism 3: Posterior Update Feedback
The stopping decision utilizes the posterior update after observing the current iteration's data, making it more accurate than forward-looking heuristics. The rule recalculates PBGI/LogEIPC using the posterior f|x₁:ₜ, y₁:ₜ, ensuring the stopping signal reflects the most recent reduction in uncertainty.

## Foundational Learning

- **Concept: Pandora's Box Problem (Weitzman)**
  - Why needed here: This is the theoretical origin of the PBGI acquisition function. Understanding "reservation values" explains why the stopping rule compares index values to the best-observed value.
  - Quick check question: How does the "reservation price" in Pandora's Box relate to the PBGI index in this paper?

- **Concept: Gaussian Process (GP) Posterior**
  - Why needed here: The stopping rule depends entirely on the GP's ability to quantify uncertainty. The Expected Improvement term is derived directly from the predictive mean and variance of the GP.
  - Quick check question: What happens to the Expected Improvement as the GP posterior variance shrinks?

- **Concept: Simple Regret vs. Cumulative Regret**
  - Why needed here: The paper optimizes for cost-adjusted simple regret (quality of the best point found at the end), not cumulative regret (performance over all time). This distinction is crucial for understanding why aggressive stopping is a valid strategy here.
  - Quick check question: Why is simple regret the correct metric for hyperparameter tuning, whereas cumulative regret might be better for online recommendation systems?

## Architecture Onboarding

- **Component map:** Surrogate Model (GP) -> Cost Model (GP) -> Acquisition Optimizer -> Stopping Manager
- **Critical path:** The Acquisition Optimization step is the bottleneck for the stopping rule. If the optimizer returns a sub-optimal x with a misleadingly low acquisition value, the Stopping Manager might trigger a spurious halt.
- **Design tradeoffs:**
  - LogEIPC vs. PBGI: LogEIPC uses maximization (easier to integrate with standard BO libraries); PBGI requires root-finding (bisection) per point. LogEIPC is numerically stabler; PBGI is theoretically cleaner for Pandora's Box connections.
  - Debounce Window: Implementing a moving average (window size ≈ 20) on the stopping signal trades immediate reaction for stability, preventing premature stops due to transient optimization failures.
- **Failure signatures:**
  - Spurious Stops: Early in optimization, GP hyperparameters fluctuate, causing unstable stopping signals. Mitigation: Enforce a "stabilization period" (e.g., first 10-20 iterations) where stopping is disabled.
  - Cost Model Mismatch: If c(x) is significantly underestimated, the algorithm stops too late, racking up real costs while the surrogate thinks they are low.
- **First 3 experiments:**
  1. Synthetic 1D Validation: Run on a known function (e.g., Forrester) with uniform cost. Visualize the acquisition function crossing the zero-threshold (LogEIPC) to verify the mechanism matches Figure 1.
  2. Ablation on Cost Scaling (λ): Test varying λ (e.g., 10⁻¹ to 10⁻⁵). Confirm that high λ (expensive evaluations) triggers early stopping while low λ allows longer runs.
  3. Debounce Stress Test: In 8D+ dimensions, compare raw stopping signals vs. moving-average signals to quantify the rate of "spurious stops" caused by acquisition optimization noise.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the PBGI/LogEIPC stopping rule be extended to settings involving noisy evaluations, multi-fidelity approximations, or batched parallel evaluations?
- Basis: The conclusion explicitly states, "We believe our framework can be extended to settings involving noisy, multi-fidelity or batched evaluations..."
- Why unresolved: The theoretical guarantees and empirical validation currently assume sequential, noiseless evaluations where the posterior updates deterministically based on exact observations.
- Evidence: Derivation of theoretical bounds for noisy or batch settings, or empirical benchmarks showing the stopping rule maintains low cost-adjusted regret in these regimes.

### Open Question 2
- Question: How does the stopping rule behave under alternative objective formulations, such as non-linear transformations of the target metric?
- Basis: The conclusion suggests exploring "alternative objective formulations—for instance, applying a sigmoid transformation to test error rather than a linear one, to reflect real-world user preferences."
- Why unresolved: The current work focuses on minimizing raw validation error or synthetic function values; non-linear transformations could skew the relationship between expected improvement and cost.
- Evidence: Empirical studies comparing the stopping time and regret when optimizing transformed objectives versus raw objectives.

### Open Question 3
- Question: How can the framework be adapted to maintain robustness under severe objective model misspecification?
- Basis: The paper notes in Section 4.2 that the LogEIPC acquisition function performs worse under model mismatch, implying the paired stopping rule may inherit this sensitivity.
- Why unresolved: The stopping threshold relies on the GP posterior; if the prior poorly matches the true function, the expected improvement estimate may be inaccurate, leading to suboptimal stopping.
- Evidence: Theoretical analysis of regret bounds under model error or experiments measuring performance degradation when kernel hyperparameters are misspecified.

## Limitations
- Strong dependence on GP modeling assumptions and acquisition optimization quality.
- Performance sensitivity to acquisition optimizer reliability and cost model accuracy.
- Limited empirical characterization of failure modes under severe model mismatch or in high-dimensional search spaces.

## Confidence

- **High confidence:** The theoretical connection between PBGI and LogEIPC stopping conditions (Theorem 2), and the no-worse-than-immediate-stopping guarantee (Lemma 1).
- **Medium confidence:** Empirical performance claims, particularly the robustness under model mismatch, as the validation scenarios remain relatively controlled.
- **Low confidence:** The general applicability of the stopping rule to arbitrary cost functions without GP modeling, as the paper primarily validates against cost GPs.

## Next Checks

1. **Stress Test Model Mismatch:** Systematically degrade the GP's fit to the true objective (e.g., using wrong kernel family) and measure degradation in cost-adjusted regret to quantify the robustness claim.

2. **High-Dimensional Acquisition Failure:** In dimensions d ≥ 16, quantify the rate of spurious stops due to acquisition optimizer local minima, comparing raw vs. moving-average stopping signals.

3. **Cost Function Sensitivity:** Validate the rule's performance when the cost function c(x) is not GP-modelled but instead deterministic and non-smooth (e.g., step function), to assess the generality of the approach.