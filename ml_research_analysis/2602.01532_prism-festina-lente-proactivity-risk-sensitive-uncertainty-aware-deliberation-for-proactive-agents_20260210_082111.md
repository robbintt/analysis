---
ver: rpa2
title: 'PRISM: Festina Lente Proactivity -- Risk-Sensitive, Uncertainty-Aware Deliberation
  for Proactive Agents'
arxiv_id: '2602.01532'
source_url: https://arxiv.org/abs/2602.01532
tags:
- prism
- need
- cost
- slow
- decision
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PRISM addresses the challenge of proactive AI agents that must
  decide when and whether to intervene without becoming intrusive. It formulates the
  problem as cost-sensitive selective intervention, coupling a decision-theoretic
  gate with a dual-process reasoning architecture.
---

# PRISM: Festina Lente Proactivity -- Risk-Sensitive, Uncertainty-Aware Deliberation for Proactive Agents

## Quick Facts
- arXiv ID: 2602.01532
- Source URL: https://arxiv.org/abs/2602.01532
- Reference count: 40
- Reduces false alarms by 22.78% and improves F1 by 20.14% over strong baselines on ProactiveBench

## Executive Summary
PRISM addresses the challenge of proactive AI agents that must decide when and whether to intervene without becoming intrusive. It formulates the problem as cost-sensitive selective intervention, coupling a decision-theoretic gate with a dual-process reasoning architecture. The agent intervenes only when calibrated acceptance probability exceeds a dynamic threshold derived from asymmetric costs of missed help and false alarms, concentrating slow reasoning near decision boundaries. Training uses gate-aligned distillation with explicit decoupling of the response policy from the intervention gate. On ProactiveBench, PRISM reduces false alarms by 22.78% and improves F1 by 20.14% over strong baselines, demonstrating precise, computationally efficient, and controllable proactive assistance.

## Method Summary
PRISM implements a cost-sensitive dual-probability gate that estimates both user need and acceptance likelihood, intervening only when calibrated acceptance probability exceeds a dynamic threshold τ(p_need) = C_FA/(C_FA + p_need·C_FN). A fast model provides initial estimates, with a resource-intensive slow mode invoked only when acceptance probability falls within a margin δ_slow of the decision boundary. The system is trained via RDC-SFT distillation, where a teacher generates traces with structured need/acceptance signals, and a ranking score filters high-quality, well-calibrated examples for student training. Post-hoc temperature scaling improves probability calibration. The approach achieves precise intervention decisions with minimal latency overhead by allocating slow reasoning only to high-stakes boundary cases.

## Key Results
- Reduces false alarms by 22.78% compared to baselines
- Improves F1-score by 20.14% on ProactiveBench
- Achieves F1=88.15% with only 20ms additional latency versus fast-only mode

## Why This Works (Mechanism)

### Mechanism 1: Cost-Sensitive Dual-Probability Gating
- Claim: Separating need estimation (p_need) from acceptance estimation (p_accept) enables interpretable control of the intervention decision boundary.
- Mechanism: At each timestep, the model estimates two calibrated probabilities. The decision threshold τ(p_need) = C_FA / (C_FA + p_need × C_FN) adapts based on need certainty and asymmetric costs. Higher p_need lowers the acceptance threshold, permitting intervention even with moderate acceptance probability.
- Core assumption: Probabilities are well-calibrated and reflect true underlying distributions; costs C_FA and C_FN are stationary during interaction.
- Evidence anchors:
  - [abstract] "calibrated probability of user acceptance exceeds a threshold derived from asymmetric costs of missed help and false alarms"
  - [section 4.3, Table 5] Ablation D shows combining both signals reduces false alarms from 62.50% (p_accept only) to 22.94% (calibrated dual signals)
  - [corpus] Limited direct evidence; related work on proactive agents (Proactive Agent/ProactiveBench) formalizes acceptance-supervised intervention but does not explicitly decouple need/acceptance
- Break condition: Calibration degrades severely under distribution shift, making τ(p_need) unreliable; or costs become time-varying faster than the gate can adapt.

### Mechanism 2: Selective Slow Reasoning (Festina Lente Margin)
- Claim: Invoking resource-intensive reasoning only near the decision boundary captures most accuracy gains with minimal latency overhead.
- Mechanism: A fast model provides initial (p^F_need, p^F_accept). Slow mode triggers only when |p^F_accept - τ(p^F_need)| ≤ δ_slow. This concentrates computation on ambiguous, high-stakes cases where additional deliberation is most likely to change the outcome.
- Core assumption: Cases near the decision boundary benefit most from additional reasoning; the margin δ_slow correctly identifies these cases.
- Evidence anchors:
  - [abstract] "invoke a resource-intensive Slow mode with counterfactual checks only near the decision boundary"
  - [section 4.3, Table 3] Slow-on-margin (δ=0.1) routes ~11% to slow path, achieves F1=88.15% with P95 latency only 20ms higher than Fast-only
  - [corpus] Related work on selective prediction (Geifman & El-Yaniv, 2017) provides theoretical grounding; corpus papers on proactive agents do not implement margin-based compute allocation
- Break condition: The boundary region expands too broadly (δ too large), negating efficiency gains; or boundary cases do not actually benefit from slow reasoning (e.g., inherently ambiguous situations where even deliberation fails).

### Mechanism 3: Decision-Consistent Curation (RDC-SFT) Distillation
- Claim: Filtering supervision with a ranking score that rewards accepted interventions and penalizes miscalibrated estimates produces a student that surpasses the teacher in precision.
- Mechanism: Teacher generates traces with (q_need, q_accept). Ranking score R_DC = y_accept - (q_need - y_need)^2 - 1{y^pred_need=1}(q_accept - y_accept)^2 prioritizes high-quality, well-calibrated examples. Student trained on filtered subset learns explicit (p_need, p_accept) targets decoupled from the intervention gate.
- Core assumption: Teacher's structured outputs contain latent need/accept signals that can be extracted; filtering removes noisy or miscalibrated supervision.
- Evidence anchors:
  - [section 3, Eq. 3.2] Formal definition of R_DC ranking score
  - [section 4.3, Table 4] RDC-SFT achieves F1=86.61% vs. SFT=76.09% and Weighted-SFT=80.59% on same backbone
  - [corpus] Self-generated instruction pipelines (Wang et al., 2023) support synthetic supervision but do not implement calibration-aware filtering
- Break condition: Teacher bias is inherited and amplified by filtering; or the filtered dataset is too small to support generalization.

## Foundational Learning

- Concept: **Bayes-optimal decision thresholds under asymmetric costs**
  - Why needed here: PRISM's gate derives from minimizing expected cost where C_FA ≠ C_FN. Understanding how τ(p_need) shifts with cost ratios is essential for tuning deployment behavior.
  - Quick check question: If C_FA doubles while C_FN stays constant, does the threshold τ increase, decrease, or stay the same? (Answer: increases, making intervention more conservative)

- Concept: **Probability calibration (temperature scaling, ECE)**
  - Why needed here: The gate's reliability depends on calibrated probabilities. Post-hoc temperature scaling (T_need=0.5, T_accept=0.7) reduced ECE from 21.53% to 12.16% for p_need.
  - Quick check question: A model with 85% accuracy outputs confidence 0.99 on all correct predictions. Is it well-calibrated? (Answer: No—calibration requires predicted probability to match empirical accuracy)

- Concept: **Dual-process reasoning (System 1 / System 2)**
  - Why needed here: PRISM operationalizes "festina lente" by treating slow reasoning as a scarce resource allocated via expected value of computation.
  - Quick check question: Why invoke slow mode only near the decision boundary rather than on all uncertain cases? (Answer: Uncertainty far from the boundary doesn't change the decision; only boundary-proximal uncertainty has actionable expected value)

## Architecture Onboarding

- Component map:
  Context -> Fast Estimator -> [Calibration] -> Gate evaluation -> (if boundary) Slow Reasoner -> Intervention decision -> Response generation

- Critical path:
  Context → Fast Estimator → [Calibration] → Gate evaluation → (if boundary) Slow Reasoner → Intervention decision → Response generation

- Design tradeoffs:
  - δ_slow: Larger margin → more slow calls, higher accuracy, higher latency. Paper finds δ=0.1 optimal on ProactiveBench.
  - C_FA : C_FN ratio: Controls precision/recall tradeoff without retraining. Higher C_FA → higher precision, lower recall.
  - Training data size: RDC filtering reduces to <1/3 of original (1,800 instances). Smaller but higher-quality data outperforms larger noisy data.

- Failure signatures:
  - High false-alarm rate with good recall → p_need underestimated or p_accept miscalibrated; check ECE
  - Low recall with high precision → C_FA set too high relative to C_FN; or threshold implementation bug (verify odds vs. Bayes formulation)
  - Latency spikes → δ_slow too large; slow rate should be ~10-15%
  - Performance collapse on new domain → calibration shift; apply domain-specific temperature scaling

- First 3 experiments:
  1. **Threshold sanity check**: Run base model (no RDC-SFT, no calibration) with fixed τ=0.5, static-cost τ, and dynamic τ(p_need). Expect dynamic to underperform fixed if p_need is uncalibrated (replicates Table 2 pattern).
  2. **Margin sweep**: With RDC-SFT student, sweep δ_slow ∈ {0, 0.05, 0.10, 0.15}. Expect F1 to peak around 0.1 with minimal latency increase (replicates Table 9 / Figure 5).
  3. **Cost ratio robustness**: Sweep C_FA : C_FN from 1:4 to 1.2:1. Expect precision to increase and slow rate to decrease as C_FA rises (replicates Table 11). Verify AUDBC remains stable.

## Open Questions the Paper Calls Out
None

## Limitations
- Limited mechanistic detail on slow reasoning: The counterfactual deliberation mechanism is described only abstractly without specifying implementation
- Unknown teacher-student signal extraction: Exact prompt schema and extraction method for calibrated need/acceptance probabilities are not provided
- Calibration dependency without proactive domain priors: No empirical evidence that base model's probabilities are well-calibrated on proactive agent data prior to post-hoc scaling

## Confidence

- **High confidence**: Cost-sensitive dual-probability gating (Table 5 shows clear ablation evidence), selective slow reasoning margin (Table 3 latency/accuracy tradeoff), and dynamic threshold formulation (explicit derivation from Bayes decision theory)
- **Medium confidence**: RDC-SFT distillation effectiveness (relies on assumed teacher signal quality and ranking score formulation not fully specified), calibration temperature scaling (post-hoc application works but pre-training calibration unknown), and proactive agent formalism (benchmark exists but domain-specific calibration data unavailable)
- **Low confidence**: Slow reasoning counterfactual mechanism (implementation unspecified), exact RDC ranking score application to unlabeled data (schema unclear), and selection bias correction via inverse propensity scoring (formula not provided)

## Next Checks

1. **Calibration baseline verification**: Before applying PRISM, measure ECE of a Qwen3-8B model on ProactiveBench. If pre-training ECE >20%, the claimed gains from temperature scaling may reflect baseline correction rather than gate improvement.

2. **Margin sensitivity replication**: Implement δ_slow sweep (0.05, 0.10, 0.15) on the base model without RDC-SFT. Verify that slow rate remains ~10-15% at δ=0.1 and that F1 peaks there, confirming the festina lente principle operates independently of distillation.

3. **Cost-ratio robustness bounds**: Systematically sweep C_FA:C_FN from 1:4 to 1.2:1 while holding other parameters constant. Measure whether precision increases monotonically with C_FA while AUDBC stays stable, validating the gate's cost sensitivity without retraining.