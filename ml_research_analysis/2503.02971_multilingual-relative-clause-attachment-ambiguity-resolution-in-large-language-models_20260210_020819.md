---
ver: rpa2
title: Multilingual Relative Clause Attachment Ambiguity Resolution in Large Language
  Models
arxiv_id: '2503.02971'
source_url: https://arxiv.org/abs/2503.02971
tags:
- languages
- english
- language
- attachment
- wang
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study examined how large language models (LLMs) resolve relative
  clause (RC) attachment ambiguities and compared their performance to human sentence
  processing. Focusing on two linguistic factors, namely the length of RCs and the
  syntactic position of complex determiner phrases (DPs), we assessed whether LLMs
  can achieve human-like interpretations amid the complexities of language.
---

# Multilingual Relative Clause Attachment Ambiguity Resolution in Large Language Models

## Quick Facts
- arXiv ID: 2503.02971
- Source URL: https://arxiv.org/abs/2503.02971
- Reference count: 14
- Primary result: LLMs show language-specific attachment preferences in Indo-European languages but systematic failures in Asian languages, often defaulting to English translations

## Executive Summary
This study examined how large language models resolve relative clause attachment ambiguities across six languages, comparing their performance to human sentence processing patterns. The research evaluated five prominent LLMs (Claude 3 Opus, Gemini-1.5 Pro, GPT-3.5, GPT-4o, and Llama 3 70B) using a forced-choice comprehension task that varied relative clause length and determiner phrase position. While models performed well in Indo-European languages (English, Spanish, French, German), they encountered significant difficulties with Asian languages (Japanese, Korean), often producing English responses despite being prompted in the target language. The findings reveal both language-specific processing capabilities and fundamental limitations in multilingual models' handling of syntactic ambiguities.

## Method Summary
The study employed a forced-choice comprehension task where models identified relative clauses and their modified nouns from 32 sentence sets per language. The experimental design crossed two factors: relative clause length (short/long) and determiner phrase syntactic position (subject/object). Five LLMs were evaluated across six languages, with responses filtered to exclude cases where models failed to correctly identify the relative clause. Mixed-effects logistic regression was used to analyze attachment preferences, predicting high attachment (HA) versus low attachment (LA) responses while controlling for item-level variation.

## Key Results
- Models showed language-specific attachment preferences in Indo-European languages (LA for English/Spanish, HA for French/German) matching human psycholinguistic patterns
- Asian languages (Japanese, Korean) showed consistent LA preferences across all models despite human HA preferences for Korean
- RC length increased HA preference slightly across all languages, mirroring human prosodic processing effects
- Over 50% of Japanese and Korean responses were excluded due to RC identification failures versus less than 5% for Indo-European languages
- Models frequently responded in English when prompted in Japanese or Korean, suggesting internal translation mechanisms

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs exhibit language-specific attachment preferences that partially align with human psycholinguistic patterns in Indo-European languages but diverge significantly for head-final Asian languages.
- Mechanism: Models draw on statistical regularities encoded during training to resolve syntactic ambiguities. For high-resource Indo-European languages, these regularities approximate human attachment preferences (LA for English/Spanish, HA for French/German). The effect of RC length on HA preference mirrors human processing, where longer RCs increase HA choices particularly in object positions.
- Core assumption: The paper assumes that alignment with human attachment preferences indicates more sophisticated language-specific syntactic processing, though this remains correlational rather than causal.
- Evidence anchors:
  - [abstract] "While these models performed well in Indo-European languages (English, Spanish, French, and German), they encountered difficulties in Asian languages (Japanese and Korean), often defaulting to incorrect English translations."
  - [Section 5.2] Table 3 shows English LA preference across all models (0.78-27.61% HA), matching human patterns, while Korean shows consistent LA across all models (0-12.96% HA) despite human HA preference.
  - [corpus] Related work (arXiv:2504.09886) confirms multilingual transformers show human-like RC attachment preferences modulated by lexical factors in Italian and English.
- Break condition: If models were simply applying universal parsing heuristics, we would expect consistent patterns across languages rather than the observed language-specific variation. The Korean divergence (human HA vs. model LA) suggests training data bias, not universal grammar.

### Mechanism 2
- Claim: Internal translation to English degrades RC identification and attachment resolution in low-resource head-final languages.
- Mechanism: When processing Japanese/Korean inputs, models appear to internally translate to English intermediate representations before generating responses. This introduces systematic errors because: (1) head-final Japanese/Korean use prenominal RCs with different attachment sites, (2) these languages lack explicit relative pronouns, using morphological markers that are ambiguous with other modifiers, and (3) back-translation reconstructs RCs based on English patterns rather than original input structure.
- Core assumption: Assumption: The observed English responses in Japanese/Korean conditions indicate internal translation rather than simple training data imbalance, though the paper does not directly test this mechanism.
- Evidence anchors:
  - [Section 6] "Notably, in Japanese and Korean, we observed that despite the language of the input not being English, most responses were still generated in English... This phenomenon was not observed in European languages."
  - [Section 6] References Wendler et al. (2024) showing Llama-2 intermediate layers correspond to English tokens even during non-English tasks.
  - [corpus] Related work (arXiv:2601.07041) on cross-lingual knowledge conflict supports the hypothesis of language-dependent internal representations causing processing failures.
- Break condition: If Claude 3 Opus's superior Japanese/Korean RC identification (Figure 4) resulted from better architecture rather than better multilingual training data, we would expect similar patterns across all languages, not the observed cross-linguistic variation.

### Mechanism 3
- Claim: The combined effects of RC length and DP syntactic position on attachment preferences emerge from implicit prosodic phrasing encoded in training data, but these effects are attenuated or distorted in multilingual models.
- Mechanism: Longer RCs bias toward HA to maintain prosodic balance (Fodor's Balanced Sister hypothesis). Object positions receive broad focus, favoring HA for the first DP. LLMs capture these effects weakly—long RCs slightly increase HA across languages, but the strength varies by model and language, suggesting superficial rather than principled acquisition of prosodic constraints.
- Core assumption: The paper assumes that observing similar directional effects (longer RC → more HA) implies similar underlying mechanisms, though LLMs lack true prosodic processing.
- Evidence anchors:
  - [Section 5.3] "Notably, when analyzing conditions involving long RCs, there is a slight increase in the preference for HA across languages."
  - [Appendix B] Statistical tables show Length:short coefficients are negative (increasing HA for long) across languages, significant only for Japanese (p=0.007).
  - [corpus] Weak corpus support—no directly comparable studies on prosodic effects in LLM RC resolution found in neighbor corpus.
- Break condition: If LLMs genuinely encoded prosodic principles, we would expect stronger and more consistent position effects (object vs. subject) across models, rather than the observed model-specific variation.

## Foundational Learning

- Concept: Relative Clause Attachment Ambiguity
  - Why needed here: This is the core linguistic phenomenon being investigated. Without understanding that sentences like "the relative of the actor who drank" can attach "who drank" to either "relative" (DP1, HA) or "actor" (DP2, LA), you cannot interpret the experimental design or results.
  - Quick check question: Given "The boss of the man who had a beard was on vacation," who had the beard under HA vs. LA interpretation?

- Concept: Head-Initial vs. Head-Final Typology
  - Why needed here: The paper explicitly contrasts SVO head-initial languages (English, Spanish, French, German) with SOV head-final languages (Japanese, Korean). RC position differs: postnominal in head-initial, prenominal in head-final, creating mirror-image attachment configurations.
  - Quick check question: In Japanese "actor-no relative-ga [RC] hate-da," does the RC precede or follow "relative," and which DP is local vs. non-local?

- Concept: Implicit Prosodic Phrasing in Sentence Processing
  - Why needed here: The paper invokes prosodic balance (Fodor 1998) to explain RC length effects. Humans weight constituents for prosodic harmony; whether LLMs capture this determines whether their behavior is human-like or merely statistical.
  - Quick check question: Why would a longer RC ("who frequently attended lavish court gatherings") prefer HA more than a shorter one ("who drank") according to prosodic accounts?

## Architecture Onboarding

- Component map:
  - Input Layer: Forced-choice comprehension task prompting models to identify RC and modified noun
  - Model Layer: Five LLMs (Claude 3 Opus, Gemini-1.5 Pro, GPT-3.5, GPT-4o, Llama 3 70B)
  - Stimulus Matrix: 2×2 design crossing RC length × DP position × 6 languages × 32 items
  - Evaluation Layer: Mixed-effects logistic regression predicting HA vs. LA responses

- Critical path:
  1. Translate stimuli to target languages (existing for EN/ES/FR/DE, GPT-4o + native speaker verification for JA/KO)
  2. Prompt each model with language-matched instructions
  3. Filter responses by RC identification accuracy (exclude ~54% of JA/KO responses vs. <5% for Indo-European)
  4. Code attachment choice (DP1 = HA, DP2 = LA)
  5. Fit mixed models per language with length × position interaction

- Design tradeoffs:
  - Aggregated vs. per-model analysis: Limited sample size forced language-level analysis, obscuring model-specific mechanisms
  - Forced-choice vs. open-ended: Eliminates "both acceptable" responses but forces models into possibly unnatural choices
  - Translation-based extension: Japanese/Korean stimuli were machine-translated then verified, potentially introducing artifacts distinct from natural corpus examples

- Failure signatures:
  - RC identification failure: 53-58% exclusion rate for Japanese/Korean (vs. <5% for Indo-European) indicates fundamental parsing breakdown
  - Language confusion: Models respond in English when prompted in Japanese/Korean (e.g., Llama 3 70B "responded almost entirely in English")
  - Attachment reversal: Korean shows universal LA (0-12.96% HA) despite human HA preference, suggesting English bias dominates

- First 3 experiments:
  1. Baseline verification: Replicate English conditions exactly to confirm your implementation matches reported LA preference (~1-28% HA across models) before attempting under-resourced languages.
  2. Language isolation test: Prompt with explicit "Respond only in [target language]" instructions for Japanese/Korean to test whether English intrusion decreases and RC identification improves.
  3. Ablation by training resource: Correlate each model's HA/LA accuracy gap with estimated training data proportions for each language to distinguish training data vs. architectural explanations.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent does internal translation to English act as the causal mechanism for incorrect relative clause attachment resolution in head-final languages?
- Basis in paper: [inferred] The Discussion section speculates that the models' poor performance in Asian languages is due to "internal machine translation" defaulting to English structures (p. 7), but does not mechanistically verify this hypothesis.
- Why unresolved: The study observes the output (English responses in Korean/Japanese tasks) but lacks access to internal model states to confirm if the model is "thinking" in English during processing.
- What evidence would resolve it: A layer-wise analysis of latent representations (e.g., probing classifiers) to detect if English token representations are activated when models process Japanese or Korean relative clauses.

### Open Question 2
- Question: Why do LLMs exhibit divergent attachment preferences between Japanese and Korean despite their shared head-final typology and similar linguistic structures?
- Basis in paper: [inferred] The authors highlight a discrepancy where models aligned with human High Attachment preferences in Japanese but universally failed (defaulting to Low Attachment) in Korean (p. 8).
- Why unresolved: The paper suggests "resource availability" as a potential cause (classifying Korean as lower-resource), but does not rule out other factors such as differences in training data composition or tokenization.
- What evidence would resolve it: A controlled comparison using models trained on carefully balanced, equal-size corpora of Japanese and Korean text to isolate the effect of syntactic structure from training data volume.

### Open Question 3
- Question: Does the explicit requirement to identify relative clauses prior to resolving ambiguity artificially inflate error rates for head-final languages?
- Basis in paper: [inferred] The methodology excluded over 50% of Japanese and Korean data points because the models failed the initial "RC identification" step (p. 5-6), raising the question of whether the attachment failure is a parsing issue or an instruction-following issue.
- Why unresolved: It is unclear if the models failed to resolve the attachment because they lack the linguistic capability, or simply because they could not explicitly delineate the clause boundaries in the prompt format used.
- What evidence would resolve it: A follow-up experiment comparing the current prompt-based results with implicit measures (e.g., surprisal scores or continued text generation) that do not require the model to explicitly identify the clause.

## Limitations
- High exclusion rate for Japanese/Korean (53-58%) raises questions about whether models are truly failing to parse these languages or whether identification criteria are too strict
- Reliance on translated stimuli rather than naturally occurring examples may introduce artifacts not present in real-world usage
- Analysis aggregated across models rather than examining each model individually, obscuring whether observed patterns reflect model-specific architectures or general trends

## Confidence
- High confidence: The finding that Indo-European languages show language-specific attachment preferences aligned with human psycholinguistic patterns, while Asian languages show systematic failures defaulting to English patterns
- Medium confidence: The claim about internal translation to English for Japanese/Korean processing, as this is inferred from output patterns rather than directly tested
- Low confidence: The interpretation that observed prosodic effects (longer RC → more HA) reflect genuine prosodic processing rather than statistical correlations in training data

## Next Checks
1. Replication with controlled inference parameters: Run the exact English conditions with specified temperature=0 and documented API versions to verify the baseline LA preference before extending to other languages
2. Language isolation test: Add explicit instructions requiring responses in the target language for Japanese/Korean conditions, then measure changes in RC identification accuracy and attachment patterns
3. Training data correlation analysis: Estimate training data proportions for each language across models and correlate with HA/LA accuracy gaps to distinguish between training data and architectural explanations for cross-linguistic variation