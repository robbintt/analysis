---
ver: rpa2
title: Entropy-Based Block Pruning for Efficient Large Language Models
arxiv_id: '2504.03794'
source_url: https://arxiv.org/abs/2504.03794
tags:
- pruning
- entropy
- arxiv
- layers
- block
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes EntroDrop, an entropy-based block pruning strategy
  for efficient large language model deployment. The method leverages the observation
  that entropy of hidden representations decreases in early layers but increases progressively
  in later layers, suggesting entropy serves as an effective measure of information
  richness within computation blocks.
---

# Entropy-Based Block Pruning for Efficient Large Language Models

## Quick Facts
- **arXiv ID**: 2504.03794
- **Source URL**: https://arxiv.org/abs/2504.03794
- **Reference count**: 12
- **Primary result**: EntroDrop achieves 37.5% pruning on Llama3.1-8B while retaining >95% performance using entropy-based block pruning

## Executive Summary
This paper introduces EntroDrop, an entropy-based block pruning strategy for efficient large language model deployment. The method leverages the observation that entropy of hidden representations decreases in early layers but increases progressively in later layers, suggesting entropy serves as an effective measure of information richness within computation blocks. Unlike cosine similarity which primarily captures geometric relationships, entropy directly quantifies uncertainty and information content. The approach identifies and prunes computation blocks with minimal entropy increase while preserving model performance.

Experiments demonstrate EntroDrop surpasses cosine similarity-based pruning methods in reducing model size while maintaining accuracy. On Llama3.1-8B, pruning 12 attention layers (37.5% of total) retained over 95% of original performance. The method shows consistent effectiveness across different models and datasets, with entropy estimation sensitivity analysis confirming the robustness of bucket-based and KNN-based approaches over alternatives.

## Method Summary
EntroDrop introduces entropy-based block pruning that identifies and removes computation blocks with minimal impact on model performance. The core insight is that entropy serves as a more fundamental measure of information richness than cosine similarity, which primarily captures geometric relationships. The method tracks entropy changes across layers, exploiting the observation that entropy decreases in early layers and increases in later layers. Blocks with lower entropy contribution are candidates for pruning. The implementation uses either bucket-based or KNN-based entropy estimation methods, which demonstrated robustness compared to alternatives. The pruning process iteratively removes blocks while monitoring performance degradation to ensure the 95% performance retention threshold is met.

## Key Results
- EntroDrop achieves 37.5% pruning (12 attention layers) on Llama3.1-8B while retaining >95% performance
- Entropy-based pruning outperforms cosine similarity-based methods in model size reduction
- Bucket-based and KNN-based entropy estimation methods show superior robustness compared to alternatives
- The approach demonstrates consistent effectiveness across different models and datasets

## Why This Works (Mechanism)
EntroDrop works by leveraging entropy as a measure of information content and uncertainty in hidden representations. Unlike cosine similarity which captures geometric relationships between vectors, entropy directly quantifies the amount of information and uncertainty present in computation blocks. The method exploits the architectural observation that entropy decreases in early layers (suggesting redundancy or compression) and increases in later layers (suggesting information enrichment). By pruning blocks that contribute minimally to entropy increase, the approach removes redundant computation while preserving the model's ability to generate rich, informative representations. This information-theoretic approach provides a more fundamental criterion for identifying essential computation than geometric similarity measures.

## Foundational Learning

**Entropy and Information Theory**
- *Why needed*: Understanding entropy as a measure of uncertainty and information content is crucial for grasping why it serves as a pruning criterion
- *Quick check*: Verify that entropy H(X) = -Î£ p(x)log p(x) captures uncertainty better than geometric similarity measures

**Transformer Architecture**
- *Why needed*: Understanding how attention layers and block computations work is essential for interpreting pruning impacts
- *Quick check*: Confirm understanding of how attention mechanisms process information across layers

**Cosine Similarity vs Information Measures**
- *Why needed*: Differentiating between geometric similarity (cosine) and information content (entropy) explains the methodological advantage
- *Quick check*: Compare cases where geometric similarity might fail to capture functional importance

## Architecture Onboarding

**Component Map**
Input -> Early Layers (entropy decreasing) -> Middle Layers -> Late Layers (entropy increasing) -> Output

**Critical Path**
The critical path involves entropy calculation at each block, comparison across layers to identify minimal entropy contribution, and iterative pruning while monitoring performance degradation thresholds.

**Design Tradeoffs**
- Information richness vs computational efficiency: Higher entropy preservation ensures better performance but reduces pruning potential
- Estimation method choice: Bucket-based vs KNN-based methods offer different tradeoffs in accuracy and computational overhead
- Layer-wise vs block-wise pruning: Granularity affects both effectiveness and implementation complexity

**Failure Signatures**
- Performance degradation below 95% threshold indicates excessive pruning
- Inconsistent entropy patterns across different architectures suggest limited generalizability
- Sensitivity to entropy estimation parameters may indicate methodological instability

**First Experiments**
1. Compare entropy trends across different transformer architectures to validate the universal layer-wise pattern
2. Systematically vary pruning percentages to characterize the performance-pruning tradeoff curve
3. Test alternative entropy estimation methods beyond bucket-based and KNN-based approaches

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- The claim that entropy better captures "information richness" than cosine similarity lacks rigorous theoretical justification, with empirical superiority demonstrated but fundamental advantages not established
- The observation that entropy decreases then increases across layers is presented as universal but is based only on Llama3.1-8B analysis, potentially limiting generalizability to architectures with different layer structures
- The 37.5% pruning rate achieving 95% performance retention represents a specific operating point, but the systematic relationship between pruning percentage and performance degradation is not characterized

## Confidence
- **High**: The empirical demonstration that entropy-based pruning outperforms cosine similarity on the tested model and datasets
- **Medium**: The general framework of using entropy as a pruning criterion and the specific implementation details
- **Low**: Claims about entropy being fundamentally superior for capturing information richness and the universality of the entropy trend across layers

## Next Checks
1. Test EntroDrop on transformer architectures with different layer configurations (e.g., decoder-only vs encoder-decoder, varying attention mechanisms) to assess generalizability
2. Conduct ablation studies systematically varying pruning percentages to characterize the performance-pruning trade-off curve
3. Compare EntroDrop against recent information-theoretic pruning methods like MI-PRUN to establish relative effectiveness in a broader context