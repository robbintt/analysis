---
ver: rpa2
title: Improving Existing Optimization Algorithms with LLMs
arxiv_id: '2502.08298'
source_url: https://arxiv.org/abs/2502.08298
tags:
- cmsa
- code
- optimization
- llms
- algorithms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores the use of large language models (LLMs) to
  enhance existing optimization algorithms. The authors apply GPT-4o to improve the
  Construct, Merge, Solve, and Adapt (CMSA) hybrid metaheuristic for the Maximum Independent
  Set problem.
---

# Improving Existing Optimization Algorithms with LLMs

## Quick Facts
- arXiv ID: 2502.08298
- Source URL: https://arxiv.org/abs/2502.08298
- Authors: Camilo Chacón Sartori; Christian Blum
- Reference count: 40
- Primary result: GPT-4o improved the CMSA hybrid metaheuristic for Maximum Independent Set by proposing age-weighted heuristics that statistically outperformed expert-designed solutions

## Executive Summary
This paper demonstrates that large language models can enhance existing optimization algorithms by identifying underutilized parameters and proposing novel heuristic improvements. The authors applied GPT-4o to improve the CMSA (Construct, Merge, Solve & Adapt) hybrid metaheuristic for the Maximum Independent Set problem. By providing the complete algorithm implementation as context, the LLM recognized that the age parameter—used for subproblem management—could be repurposed for solution construction. The resulting age-weighted heuristic produced statistically significant improvements over the expert-designed baseline, particularly on larger and denser graphs.

## Method Summary
The study used GPT-4o with in-context prompting to analyze the full ~400-line C++ CMSA implementation and propose heuristic improvements. The LLM suggested incorporating the age parameter into vertex selection through a composite weight function. Two variants were generated: V1 using weighted selection with age+degree, and V2 using entropy-adjusted probabilities. Human review identified and corrected implementation errors (division by zero, memory management issues). All three variants (original CMSA, V1, V2) were tuned using irace on benchmark instances. Performance was evaluated on 1440 test instances across three graph types (Barabási-Albert, Watts-Strogatz, Erdős-Rényi) with varying sizes and densities, using solution quality and statistical significance as metrics.

## Key Results
- Both LLM-generated CMSA variants (V1 and V2) statistically outperformed the standard CMSA with age-weighted heuristics
- Improvements were most pronounced on larger graphs (|V|=2000) and denser graphs (average degree=30)
- Variant V1 (weighted selection using age+degree) outperformed V2 (entropy-adjusted probabilities) across all graph types
- Performance-optimized variants with improved data structures showed no statistically significant difference in solution quality compared to non-optimized versions

## Why This Works (Mechanism)

### Mechanism 1: In-Context Code Comprehension Enables Heuristic Discovery
When provided complete algorithm implementations as context, LLMs can identify underutilized parameters and propose novel heuristic integrations that domain experts overlooked. GPT-4o was given the full CMSA implementation and recognized that the "age" parameter could be repurposed for solution construction by selecting vertices based on degree and age combinations.

### Mechanism 2: Age-Weighted Probabilistic Selection Improves Diversity
Incorporating the CMSA age parameter into vertex selection via a composite weight function produces statistically significant improvements over degree-only heuristics, with gains increasing on larger/denser graphs. The heuristic uses Pw(vj) = w(vj)/Σw(vl), where w(v) = 1/(2 + age(v) + 1/(1 + degree(v))), deprioritizing vertices with high age values.

### Mechanism 3: Iterative Human-LLM Feedback Corrects Implementation Errors
LLM-generated optimization code requires human-in-the-loop validation, as models produce syntactically correct but semantically flawed implementations that domain experts can identify and repair. The LLM proposed weight = 1.0/(1 + age[v]), which causes division by zero when age = -1 (initialization value for unused components).

## Foundational Learning

- **CMSA (Construct, Merge, Solve & Adapt) hybrid metaheuristic**: Four-phase structure balancing metaheuristic exploration with exact solver precision. Why needed: Understanding CMSA's age parameter and subproblem management is central to understanding the LLM's improvement. Quick check: Can you explain why CMSA uses an exact ILP solver on a reduced subproblem rather than the full problem?

- **Maximum Independent Set (MIS) problem**: Selecting non-adjacent vertices to maximize set size. Why needed: The problem structure determines what makes a good heuristic—degree-based selection makes sense because low-degree vertices conflict with fewer neighbors. Quick check: Why would selecting low-degree vertices first tend to produce larger independent sets?

- **In-context prompting strategy**: Providing complete code as context rather than tasking the LLM with generating algorithms from scratch. Why needed: The paper's approach relies on this distinction for reproducing results. Quick check: What is the difference between asking an LLM to "design a new optimization algorithm" versus "improve this existing implementation"?

## Architecture Onboarding

- **Component map**:
Original CMSA Code (C++) → Prompt Construction (external context: full code; internal context: improvement target) → LLM (GPT-4o) → Heuristic Proposal (weighted age-degree selection) → Human Review → Error Detection (division by zero, memory issues) → Corrected Implementation → Parameter Tuning (irace) → Benchmark Evaluation (Barabási-Albert, Watts-Strogatz, Erdős-Rényi graphs)

- **Critical path**: The key innovation is the LLM correctly identifying that age is an underutilized parameter and proposing a mathematically sound integration. The paper's reproducibility website provides pre-built prompts to standardize this interaction.

- **Design tradeoffs**:
  - V1 (age-degree weighting) vs V2 (entropy-adjusted probabilities): V1 outperformed V2 with statistical significance across all graph types
  - Performance-optimized variants: improved data structures but statistically equivalent solution quality to non-optimized versions
  - Manual interaction vs autonomous agents: current approach requires human feedback; future work proposes autonomous code agents

- **Failure signatures**:
  - Division by zero when age = -1 (unused components)
  - Segmentation faults from LLM-proposed C++ optimizations (memory access errors)
  - Entropy-based variants may reduce solution quality by over-diversifying

- **First 3 experiments**:
  1. Reproduce the core result: Run original CMSA vs LLM-CMSA-V1 on provided benchmark graphs (start with |V|=500 to verify setup before scaling to |V|=2000)
  2. Test generalization: Apply the same prompting strategy to a different CMSA application (e.g., Minimum Dominating Set) to assess whether age-based heuristics transfer across problems
  3. Ablation study: Isolate the contribution of age vs degree in the weight function by testing each component independently

## Open Questions the Paper Calls Out

- **Can LLMs consistently improve optimization algorithms other than CMSA applied to problems other than Maximum Independent Set?**: The authors acknowledge they did not explore using GPT-4o to enhance other complex algorithms for additional optimization problems, identifying this as a limitation to be addressed in future work.

- **Can autonomous LLM-based agents replace the manual human-in-the-loop required for error correction and heuristic refinement?**: The authors suggest future work should explore the "integration of LLM-based agents" where "tasks such as executing code and correcting errors... could be delegated to autonomous code agents."

- **What specialized benchmarks are needed to effectively evaluate LLMs on their ability to discover novel optimization heuristics?**: The authors state there is "a clear need for specialized benchmarks tailored to optimization" to assess which models can effectively "discover" better heuristics.

## Limitations

- The reliance on stochastic LLM outputs makes exact replication of proposed heuristics impossible
- The irace-tuned parameter values were omitted for space, requiring re-tuning for reproduction
- The human-in-the-loop correction process introduces researcher bias, as error detection depends on domain expertise that may vary between practitioners

## Confidence

- **High confidence**: The core mechanism of age-weighted selection improving solution quality (supported by statistical significance across multiple graph types and sizes)
- **Medium confidence**: The claim that GPT-4o can identify underutilized parameters in existing code (limited evidence, though related work supports code comprehension capabilities)
- **Medium confidence**: The necessity of human validation for LLM-generated code (supported by documented implementation errors, but limited to division by zero and memory management issues)

## Next Checks

1. **Generalization test**: Apply the same prompting strategy to a different CMSA application (e.g., Minimum Dominating Set) to assess whether age-based heuristics transfer across problems

2. **Ablation study**: Isolate the contribution of age vs degree in the weight function by testing each component independently to understand which drives improvement

3. **Robustness validation**: Generate multiple LLM outputs with identical prompts and measure solution quality variance to quantify the stochastic nature of the approach