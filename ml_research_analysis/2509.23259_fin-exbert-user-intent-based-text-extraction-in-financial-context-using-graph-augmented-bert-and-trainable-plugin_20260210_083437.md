---
ver: rpa2
title: 'Fin-ExBERT: User Intent based Text Extraction in Financial Context using Graph-Augmented
  BERT and trainable Plugin'
arxiv_id: '2509.23259'
source_url: https://arxiv.org/abs/2509.23259
tags:
- arxiv
- financial
- extraction
- fin-exbert
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Fin-ExBERT addresses sentence-level information extraction in financial
  dialogue transcripts by integrating a GNN-augmented BERT backbone with LoRA-based
  domain adaptation and a trainable plugin head for span extraction. It uses a two-stage
  training strategy with progressive unfreezing and dynamic thresholding based on
  probability curvature to improve precision under uncertainty.
---

# Fin-ExBERT: User Intent based Text Extraction in Financial Context using Graph-Augmented BERT and trainable Plugin

## Quick Facts
- arXiv ID: 2509.23259
- Source URL: https://arxiv.org/abs/2509.23259
- Authors: Soumick Sarker; Abhijit Kumar Rai
- Reference count: 13
- Primary result: F1-score up to 0.84 on financial dialogue extraction with lightweight BERT-based architecture

## Executive Summary
Fin-ExBERT addresses sentence-level information extraction in financial dialogue transcripts by integrating a GNN-augmented BERT backbone with LoRA-based domain adaptation and a trainable plugin head for span extraction. The framework uses a two-stage training strategy with progressive unfreezing and dynamic thresholding based on probability curvature to improve precision under uncertainty. Evaluated on a newly curated CreditCall12H dataset and two general QA benchmarks, the model achieves strong performance with F1-scores up to 0.84 on financial calls and average LLM judge scores of 4.93/5 and 4.84/5 on SQuAD and FinQA respectively. The architecture is designed for real-world deployment in financial dialogue mining while maintaining interpretability and computational efficiency.

## Method Summary
Fin-ExBERT combines a GNN-augmented BERT encoder with a trainable plugin head for financial dialogue extraction. The model first pretrains on SNLI using dependency graph processing through GNN layers, then applies LoRA adapters for financial domain adaptation on fingpt-fiqa_qa data. The main training uses a two-stage progressive unfreezing approach on CreditCall12H: initial head training with frozen encoder, followed by encoder unfreezing with differential learning rates. Dynamic thresholding based on median probability curvature replaces fixed cutoff heuristics during inference. The architecture processes premise-hypothesis pairs through BERT, enhances them with syntactic dependency graphs via GNN, and uses an MLP plugin head to predict span start/end positions and no-span logits.

## Key Results
- Achieves F1-score of 0.84 on CreditCall12H financial dialogue dataset
- Demonstrates 2-5% performance improvement when using GNN module (ablation test)
- Shows LLM judge scores of 4.93/5 on SQuAD and 4.84/5 on FinQA for general QA evaluation
- Maintains lightweight architecture with 109M BERT parameters plus 2.1M plugin head

## Why This Works (Mechanism)

### Mechanism 1
- Syntactic dependency graphs processed through GNN layers improve relational reasoning in financial dialogue extraction
- spaCy generates dependency trees, GNN layers perform message-passing over token nodes and syntactic edges, capturing structural relationships that BERT's sequential attention may miss
- Financial intent detection benefits from explicit syntactic structure beyond contextual embeddings alone
- Evidence: integration of GNN-augmented BERT backbone; no direct corpus support for this specific GNN-BERT fusion

### Mechanism 2
- Two-stage progressive unfreezing with differential learning rates enables stable head training followed by effective backbone fine-tuning
- Stage 1 freezes BERT+GNN encoder, trains only classifier head at lr=2×10⁻⁵; Stage 2 unfreezes encoder with lr=10⁻⁵ while keeping head at lr=10⁻³
- Head learns meaningful decision boundary before backbone weights shift, managing class imbalance (~0.8% positive labels)
- Evidence: two-stage training strategy with progressive unfreezing; validation F1 improvement after epoch 4; no direct corpus support

### Mechanism 3
- Dynamic thresholding based on within-transcript probability curvature improves extraction precision under class imbalance
- Compute local median μ_S of sigmoid scores S for all sentences in a transcript; select sentence i if s_i ≥ μ_S + δ (δ=0.15 default)
- Relevant sentences exhibit relatively higher confidence than surrounding irrelevant sentences within the same transcript
- Evidence: dynamic thresholding strategy based on probability curvature; Equation 8 and precision gains discussion; no corpus evidence

## Foundational Learning

- **Natural Language Inference (NLI)**: Entailment, contradiction, neutral relationships between premise-hypothesis pairs. Needed because base model is pretrained on SNLI to learn semantic alignment; sentence extraction framed as entailment problem. Quick check: Given "Customer: I can't find the interest charges on my last bill" and intent "Customer asking about credit card interest rates," would an NLI model predict entailment?

- **Low-Rank Adaptation (LoRA)**: Efficient fine-tuning via trainable low-rank matrices injected into attention layers. Needed for financial domain adaptation (401k, 529 terms) without updating full BERT parameters. Quick check: If LoRA rank r=8 and BERT hidden size D=768, how many trainable parameters does one LoRA module add per attention weight matrix?

- **Message-Passing in Graph Neural Networks**: Aggregating neighbor node features to update node representations. Needed for dependency graphs processed through two rounds of message-passing to enhance relational reasoning. Quick check: In a dependency tree with edges (root→A, A→B, A→C), after one message-passing step, what information does node B's representation incorporate?

## Architecture Onboarding

- **Component map**: Tokenized premise-hypothesis pairs -> BERT Encoder -> GNN Module (spaCy dependency graphs) -> Fusion Layer ([CLS] + GNN_premise + GNN_hypothesis) -> LoRA Adapters (attention layers) -> Plugin Head (MLP) -> Output Layer (start/end logits, no_span logit)

- **Critical path**: 1) Load pretrained bert-base-uncased, 2) Attach GNN modules for dependency graph processing, 3) Pretrain base model on SNLI (3-way NLI classification), 4) Insert LoRA adapters; fine-tune on fingpt-fiqa_qa, 5) Attach plugin head; train on CreditCall12H with 2-stage progressive unfreezing, 6) Apply dynamic thresholding at inference

- **Design tradeoffs**: Lightweight vs. expressiveness (BERT-base 109M + GNN 196K + plugin 2.1M smaller than LLMs but may underfit complex reasoning chains); Precision vs. recall (dynamic thresholding optimizes precision, paper acknowledges moderate recall); Synthetic vs. real data (CreditCall12H synthetically generated via GPT-4o with human verification)

- **Failure signatures**: Training divergence after unfreezing (learning rate too high → validation loss spikes; reduce encoder lr below 10⁻⁵); All sentences rejected (dynamic threshold too aggressive or no_span_logit threshold misconfigured → no extractions; lower δ or check no_span sigmoid calibration); GNN output degradation (dependency parsing errors on informal text → noisy graph signals; inspect spaCy parse quality)

- **First 3 experiments**: 1) Ablate GNN module: Train without GNN (BERT-only) on CreditCall12H; compare F1 to validate Figure 3 ablation claim (expect ~2-5% drop), 2) Vary dynamic threshold δ: Test δ ∈ {0.10, 0.15, 0.20} on validation set; plot precision-recall curve to find optimal operating point, 3) Compare fixed vs. dynamic thresholding: Run inference with fixed threshold 0.5 vs. dynamic δ=0.15; measure precision, recall, F1 on test split to quantify improvement

## Open Questions the Paper Calls Out

- **Multi-hop reasoning mechanisms**: Does incorporating multi-hop reasoning mechanisms improve recall for indirectly phrased intents in long conversational dependencies? The authors explicitly state in Limitations that current recall is moderate and propose future work involving "multi-hop reasoning and enhanced context propagation through conversational history." Empirical results comparing existing Fin-ExBERT against multi-hop augmented variant on dataset for long-range intent dependency would resolve this.

- **LLM-as-a-judge correlation**: To what extent do LLM-as-a-judge evaluation scores correlate with human expert assessments in the financial domain? The paper acknowledges that "LLM-based evaluation offers scalable semantic scoring" but notes that "these scores may still inherit biases," stating that human evaluation would offer more consistent grounding. A correlation study comparing LLM judges against ground truth established by human domain experts on CreditCall12H would resolve this.

- **Real-world transcript robustness**: How robust is the model when applied to non-synthetic, real-world call transcripts containing natural disfluencies and noise? While the paper demonstrates success on CreditCall12H, the methodology reveals this dataset is "synthetic," generated via LLM prompting. The authors list "expanding the evaluation to real-world call center deployments" as a future step. Evaluation on held-out set of actual recorded and transcribed financial service calls would resolve this.

- **Attention-based explainability**: Can attention-based rationales or saliency methods be integrated into the plugin head to improve explainability without degrading extraction performance? The authors identify "Plugin Head Interpretability" as a limitation, noting that the MLP head's "inner workings are less interpretable than symbolic or rule-based extractors." A study implementing attention visualization in plugin head, measuring if explanations align with human reasoning while maintaining F1-score of 0.84 would resolve this.

## Limitations

- GNN architecture lacks precise specifications (layer dimensions, aggregation functions, edge feature encoding) limiting full reproducibility
- LoRA fine-tuning stage omits critical hyperparameters (learning rate, epochs, whether full model or only LoRA parameters updated)
- CreditCall12H dataset synthetically generated via GPT-4o with human verification may not capture all real-world transcript noise and variability
- Model demonstrates moderate recall and relies on synthetic data, representing practical limitations for diverse financial contexts

## Confidence

- GNN-augmented BERT backbone improves relational reasoning: Medium confidence (mechanism well-explained but ablation results depend on precise GNN architecture details that are underspecified)
- Two-stage progressive unfreezing with differential learning rates enables stable training: Medium confidence (training schedule described but critical hyperparameters for LoRA stage are missing)
- Dynamic thresholding based on probability curvature improves precision: Medium confidence (concept valid but performance gains depend on transcript characteristics and may not generalize)
- Overall F1-score of 0.84 on financial calls: Low confidence (claim cannot be fully verified without CreditCall12H dataset and complete implementation details)

## Next Checks

1. **Reconstruct and ablate the GNN module**: Implement dependency graph processing with spaCy, two rounds of message-passing, and fusion with BERT [CLS]. Train base model on SNLI with and without GNN to measure performance impact on CreditCall12H.

2. **Validate the two-stage training schedule**: Implement progressive unfreezing with specified learning rates (10^-3 head, 10^-5 encoder). Monitor validation loss before and after unfreezing epoch 4 to confirm stability and performance gains.

3. **Test dynamic thresholding robustness**: Run inference with varying δ values (0.10, 0.15, 0.20) on validation transcripts. Plot precision-recall curves and compare against fixed threshold 0.5 to quantify improvements and identify optimal operating points.