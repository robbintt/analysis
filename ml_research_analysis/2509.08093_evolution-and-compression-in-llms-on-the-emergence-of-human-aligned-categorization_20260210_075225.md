---
ver: rpa2
title: 'Evolution and compression in LLMs: On the emergence of human-aligned categorization'
arxiv_id: '2509.08093'
source_url: https://arxiv.org/abs/2509.08093
tags:
- color
- systems
- llms
- naming
- iicll
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study investigates whether large language models (LLMs) can
  develop human-like semantic categories, focusing on color naming. Using a cognitively-motivated
  framework based on the Information Bottleneck principle, the authors replicate two
  influential human studies: an English color-naming task and a cultural transmission
  experiment via Iterated in-Context Language Learning (IICLL).'
---

# Evolution and compression in LLMs: On the emergence of human-aligned categorization

## Quick Facts
- **arXiv ID**: 2509.08093
- **Source URL**: https://arxiv.org/abs/2509.08093
- **Reference count**: 40
- **Primary result**: LLMs can develop human-like semantic categories through iterative cultural transmission, with larger, instruction-tuned models showing greater alignment and efficiency.

## Executive Summary
This study investigates whether large language models can develop human-like semantic categories using the Information Bottleneck (IB) principle. The authors examine color naming through two complementary approaches: replicating an English color-naming task and simulating cultural transmission via Iterated in-Context Language Learning (IICLL). Results show that most models fail to capture the English color system, but larger, instruction-tuned models achieve higher alignment and efficiency. Through IICLL, models iteratively restructure random color systems toward greater IB-efficiency and human-alignment, with Gemini 2.0 uniquely recapitulating the wide range of near-optimal tradeoffs observed in humans.

## Method Summary
The study employs a cognitively-motivated framework based on the Information Bottleneck principle to evaluate LLM semantic category development. Two experimental paradigms are used: (1) an English color-naming task where models label 330 WCS color chips using 14 basic color terms, and (2) IICLL, which simulates cultural transmission by having models iteratively learn and reproduce color-pseudo word mappings across generations. Models are evaluated on IB complexity and accuracy tradeoffs, efficiency loss (deviation from IB optimality), and alignment with human systems via Normalized Information Distance. The IICLL process involves initializing random color systems, sampling training pairs, prompting for full grid labeling, and iterating through up to 13 generations with a sliding window of 10 prior interactions.

## Key Results
- Most LLMs fail to capture the English color system, but larger, instruction-tuned models show higher alignment and efficiency
- IICLL drives LLMs to restructure random color systems toward greater IB-efficiency and human-alignment
- Gemini 2.0 uniquely recapitulates the wide range of near-optimal tradeoffs observed in human color categorization

## Why This Works (Mechanism)
The mechanism relies on the Information Bottleneck principle, which formalizes the trade-off between compression (complexity) and accuracy in semantic systems. Through iterative cultural transmission (IICLL), models experience selective pressure toward more efficient and human-aligned category systems. This process reveals the inductive biases of LLMs, showing that human-aligned semantic categories can emerge without explicit training for this objective. The efficiency-driven restructuring occurs because more optimal systems achieve better performance in subsequent generations, creating an evolutionary pressure toward IB-efficient solutions.

## Foundational Learning
- **Information Bottleneck Principle**: A framework quantifying the trade-off between compression and accuracy in semantic systems; needed to measure efficiency and alignment of color naming systems
- **Iterated Learning**: A method for studying cultural evolution and language change through sequential learning and transmission; needed to simulate how semantic categories evolve across generations
- **Normalized Information Distance**: A metric for quantifying similarity between probability distributions; needed to measure alignment with human color systems
- **Color Naming Systems**: The structured mapping between color chips and linguistic terms; needed as the domain for studying semantic category emergence
- **Pseudo-word Generation**: Creating nonsense terms for controlled transmission experiments; needed to eliminate prior semantic associations in IICLL

## Architecture Onboarding
- **Component Map**: WCS color grid -> IB color naming model -> LLM color labeling -> Efficiency calculation -> IICLL generation pipeline -> NID alignment measurement
- **Critical Path**: Color input → Model prediction → IB efficiency calculation → Alignment measurement → Cultural transmission iteration
- **Design Tradeoffs**: Model size vs. alignment quality; instruction-tuning vs. base models; history window length vs. convergence speed; temperature settings vs. diversity of outputs
- **Failure Signatures**: Early collapse to single category; low comprehension accuracy on training examples; degenerate systems with poor IB efficiency; inability to maintain vocabulary size
- **First Experiments**: 1) Run English naming task on 2-3 target models with 330 chips; 2) Implement IICLL for k=2,3,4 conditions on smallest model; 3) Verify NID calculation matches human benchmarks

## Open Questions the Paper Calls Out
None specified in the provided notes.

## Limitations
- Results may not generalize beyond color naming to other semantic domains
- Limited to models available through standard APIs with token constraints
- The IICLL process requires significant computational resources across multiple generations
- English color system alignment may reflect cultural bias rather than universal semantic principles

## Confidence
- **Methodological Soundness**: High - well-established IB framework and IICLL methodology
- **Reproducibility**: Medium - requires specific model access and computational resources
- **Generalizability**: Low - results limited to color naming domain

## Next Checks
1. Verify IB efficiency calculations match reported values for human color systems as baseline
2. Confirm model comprehension accuracy exceeds 80% on in-context training examples before production phase
3. Test IICLL convergence with varying history window sizes to identify optimal sliding window parameters