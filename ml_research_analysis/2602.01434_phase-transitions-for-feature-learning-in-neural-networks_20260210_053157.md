---
ver: rpa2
title: Phase Transitions for Feature Learning in Neural Networks
arxiv_id: '2602.01434'
source_url: https://arxiv.org/abs/2602.01434
tags:
- lemma
- learning
- have
- page
- hard
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies feature learning in neural networks through
  the lens of multi-index models. The authors analyze when two-layer neural networks
  can learn low-dimensional representations by studying the spectrum of the Hessian
  along the gradient descent trajectory.
---

# Phase Transitions for Feature Learning in Neural Networks

## Quick Facts
- arXiv ID: 2602.01434
- Source URL: https://arxiv.org/abs/2602.01434
- Authors: Andrea Montanari; Zihao Wang
- Reference count: 40
- This paper studies feature learning in neural networks through the lens of multi-index models, identifying a threshold in sample complexity at which Hessian spectral transitions enable learning of "hard" latent directions.

## Executive Summary
This paper analyzes when two-layer neural networks can learn low-dimensional representations by studying the spectrum of the Hessian along the gradient descent trajectory. The authors identify a critical threshold δNN in the number of samples per dimension at which the Hessian develops negative outlier eigenvalues aligned with "hard" directions in the latent space. For δ > δNN, these negative directions enable feature learning; for δ < δNN, they do not exist. The analysis explains the grokking phenomenon as arising from this two-stage learning process where generalization error first increases then decreases.

## Method Summary
The paper uses dynamical mean field theory (DMFT) to characterize the gradient descent trajectory in high dimensions. It analyzes a two-layer neural network with random initialization on a multi-index model where the target depends on low-dimensional projections of the input. The key technique involves characterizing the Hessian spectrum along the optimization path and identifying when BBP-type phase transitions occur, creating negative outlier eigenvalues that align with hard-to-learn directions in the latent space.

## Key Results
- The threshold δNN corresponds to a phase transition in the spectrum of the Hessian, enabling feature learning when exceeded
- Learning "hard" directions requires a spectral transition that only occurs when sample complexity δ > δNN
- The analysis explains grokking as arising from the separation between initial O(1) training (overfitting) and the later Hessian-driven feature learning phase

## Why This Works (Mechanism)

### Mechanism 1: Easy Subspace Learning via Gradient Alignment
- **Claim:** Neural networks can identify "easy" latent directions (where target signal correlates with the gradient) in O(1) gradient steps, but remain orthogonal to "hard" directions during this initial phase.
- **Mechanism:** In a multi-index model, the latent space splits into easy and hard subspaces. Gradient descent rapidly aligns weights with directions where the expected gradient E[∇L] carries signal, effectively solving the "easy" part of the representation learning problem before entering a saddle point.
- **Core assumption:** The data follows a multi-index model where y depends on a low-dimensional projection Θ^T x (Assumption 1).
- **Evidence anchors:**
  - [abstract] The paper studies when networks learn representations by first identifying low-dimensional projections.
  - [section 1.1.2] "Hard directions cannot be learned in O(1) time."
  - [corpus] "Overparametrization bends the landscape" supports the idea of rapid initial alignment in high dimensions.
- **Break condition:** If the activation function or loss function suppresses the gradient signal for "easy" directions, this rapid learning phase fails.

### Mechanism 2: Hard Subspace Learning via Hessian Spectral Transition
- **Claim:** Learning "hard" directions (uncorrelated with gradients) requires a spectral phase transition in the Hessian at a threshold δNN (samples per dimension).
- **Mechanism:** After the initial phase, the dynamics are dominated by the Hessian ∇²Risk(Θ(t)). The paper characterizes a threshold δNN: if δ > δNN, the Hessian develops a negative outlier eigenvalue (BBP-type transition) whose eigenvector aligns with the hard latent direction. Gradient descent effectively performs a power iteration on this curvature direction to escape the saddle.
- **Core assumption:** The number of samples n and dimension d scale proportionally (n/d → δ) while the latent dimension k remains fixed.
- **Evidence anchors:**
  - [abstract] "The threshold δNN corresponds to a phase transition in the spectrum of the Hessian."
  - [section 2.5] "Outliers of the Hessian and phase transitions."
  - [corpus] "Overparametrization bends the landscape" provides background on BBP transitions in neural network Hessians.
- **Break condition:** If the sample complexity δ falls below the threshold δNN, no informative negative curvature exists; the network is trapped in the saddle point induced by the easy subspace solution.

### Mechanism 3: Grokking as Delayed Feature Discovery
- **Claim:** The "grokking" phenomenon (delayed generalization) arises from the separation between the initial O(1) training phase (overfitting) and the Hessian-driven feature learning phase.
- **Mechanism:** Initially, the network fits "easy" directions while misaligning with "hard" directions, causing high generalization error despite low training loss (overfitting plateau). Once the dynamics allow the network to utilize the Hessian's negative curvature (requiring more time steps near the threshold), the model suddenly learns the hard features, causing the generalization error to drop sharply.
- **Core assumption:** The training time is sufficiently long for the gradient descent trajectory to probe the Hessian's spectral gap.
- **Evidence anchors:**
  - [abstract] "Analysis also explains the grokking phenomenon... as arising from this two-stage learning process."
  - [section 3.2] "Grokking... generalization error first increases... then decreases."
  - [corpus] Corpus evidence for grokking specifically is weak; mostly general scaling laws.
- **Break condition:** If δ ≫ δNN, the spectral gap is large and the transition happens immediately, eliminating the "grokking" plateau.

## Foundational Learning

- **Concept:** **Multi-index Models & Latent Subspaces**
  - **Why needed here:** This is the mathematical scaffolding for the problem. You must understand that the target function y depends on a k-dimensional projection Θ^T x to grasp why "feature learning" is defined as recovering this subspace.
  - **Quick check question:** Can you explain why learning a single-index model (k=1) is fundamentally different from a multi-index model with a "hard" subspace?

- **Concept:** **Random Matrix Theory (RMT) & Spectral Transitions**
  - **Why needed here:** The core result relies on identifying when an eigenvalue "pops out" of the bulk spectrum (BBP transition). Without RMT, the definition of the threshold δNN is opaque.
  - **Quick check question:** What does the "bulk of the spectrum" represent in the context of the Hessian, and what does an "outlier" represent?

- **Concept:** **Dynamical Mean Field Theory (DMFT)**
  - **Why needed here:** The paper uses DMFT to tractably characterize the GD trajectory in high dimensions. This simplifies the infinite-dimensional analysis to low-dimensional stochastic processes.
  - **Quick check question:** How does DMFT simplify the analysis of the Hessian along the trajectory compared to a standard finite-sample analysis?

## Architecture Onboarding

- **Component map:** Input (Isotropic Gaussian x) -> Model (Two-layer NN with Θ) -> Optimizer (Full-batch GD) -> Analyzer (Hessian spectral decomposition)

- **Critical path:**
  1. Initialize weights randomly (e.g., Unif(S^{d-1}))
  2. Run GD for O(1) steps (Easy Subspace Learning)
  3. Compute Hessian at current point Θ(t)
  4. Check for negative outlier eigenvalue: If present and aligned with hard direction, proceed to feature learning. If absent, you are below threshold δNN

- **Design tradeoffs:**
  - **Activation Function:** Determines the threshold δNN. GeLU requires more samples (δ ≈ 6) than Quad (δ ≈ 3.6) for the same task (Figures 4, 5)
  - **Optimization:** The derived δNN is suboptimal compared to ideal spectral methods (δ_alg). The choice of architecture directly limits sample efficiency

- **Failure signatures:**
  - **Plateauing:** Training loss decreases but test loss remains high (overfitting)
  - **No Alignment:** The minimum eigenvector of the Hessian shows no correlation with the target latent space
  - **Condition:** This implies δ < δNN

- **First 3 experiments:**
  1. **Threshold Sweep:** Vary δ = n/d for a single-neuron network on a phase retrieval task to empirically find δNN and match the predicted "cliff" in generalization error
  2. **Hessian Spectroscopy:** Monitor the minimum eigenvalue and its eigenvector alignment during training. Verify that the generalization drop coincides with the emergence of the negative outlier
  3. **Activation Comparison:** Repeat the sweep for GeLU vs. Quad activations to validate that δNN shifts according to theoretical predictions

## Open Questions the Paper Calls Out
None

## Limitations
- The theoretical analysis relies heavily on the multi-index model assumption, which may not fully capture real-world data distributions
- Results are derived for two-layer networks with specific activation functions and initialization schemes, potentially limiting generalizability
- The DMFT approximation, while mathematically tractable, may not accurately represent finite-sample behavior in practical scenarios

## Confidence

- **High Confidence:** The existence of the spectral phase transition in the Hessian (Mechanism 2) and its mathematical characterization using RMT techniques. This is supported by rigorous theoretical analysis and corroborated by numerical experiments in Figures 4 and 5.
- **Medium Confidence:** The grokking phenomenon explanation (Mechanism 3) and the specific numerical predictions for the threshold δNN across different activation functions. While the theoretical framework is sound, the empirical validation of grokking behavior is limited to specific synthetic tasks.
- **Low Confidence:** The extension of these results to deeper networks, practical optimization algorithms, and non-Gaussian data distributions. These remain open questions not addressed by the current analysis.

## Next Checks

1. **Finite-Sample Validation:** Conduct experiments with varying batch sizes and compare against the theoretical predictions to quantify the impact of stochasticity on the spectral transition threshold δNN.

2. **Activation Function Generalization:** Test the theoretical predictions for additional activation functions (e.g., ReLU, Swish) not covered in the current analysis to assess the robustness of the δNN characterization across different nonlinearities.

3. **Data Distribution Robustness:** Evaluate the theoretical framework on non-Gaussian data distributions (e.g., heavy-tailed or structured data) to determine whether the multi-index model assumption is essential for the observed phenomena or whether the results extend to more general settings.