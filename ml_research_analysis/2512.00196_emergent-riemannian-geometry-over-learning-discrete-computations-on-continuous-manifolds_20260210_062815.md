---
ver: rpa2
title: Emergent Riemannian geometry over learning discrete computations on continuous
  manifolds
arxiv_id: '2512.00196'
source_url: https://arxiv.org/abs/2512.00196
tags:
- networks
- input
- network
- neural
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper uses Riemannian geometry to study how neural networks
  perform discrete computations on continuous manifolds. The authors analyze the pullback
  metric tensor across network layers, revealing that computation decomposes into
  discretizing continuous inputs and performing logical operations on discretized
  variables.
---

# Emergent Riemannian geometry over learning discrete computations on continuous manifolds

## Quick Facts
- arXiv ID: 2512.00196
- Source URL: https://arxiv.org/abs/2512.00196
- Reference count: 40
- Primary result: Neural networks perform discrete computations on continuous manifolds by discretizing inputs through geometric warping measured by pullback metrics, with rich learning regimes yielding structured geometries that generalize better than random lazy regime geometries.

## Executive Summary
This paper develops a geometric framework for understanding how neural networks perform discrete computations on continuous input manifolds. By analyzing the Riemannian pullback metric tensor across network layers, the authors demonstrate that network computation can be decomposed into two distinct functions: discretizing continuous input features and performing logical operations on these discretized variables. The framework reveals how different learning regimes produce qualitatively different geometric structures, with rich regimes (small initial weights) generating structured, low-dimensional representations that generalize better than the random geometries produced by lazy regimes (large initial weights).

## Method Summary
The authors analyze MLPs trained on Boolean functions (XOR, AND, OR) operating on continuous manifolds (flat torus or plane). They compute the Jacobian of hidden layer activations with respect to input angles, then calculate the pullback metric tensor G = J^T J and its Gaussian curvature. The framework distinguishes between rich learning regimes (small initial weights, σ² ≪ 1) and lazy regimes (large initial weights), analyzing how each affects the geometry of learned representations. They also study the effect of input noise during training on the emergent geometry.

## Key Results
- Network computation decomposes into discretization of continuous inputs (stretching space near decision boundaries) and logical operations on discretized variables
- Rich learning regimes produce structured, low-dimensional geometries with curvature peaks at class centers that generalize better than lazy regime random geometries
- Input noise during training smooths geometry by lowering curvature, corresponding to flatter posterior distributions of network outputs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The pullback metric tensor emerges in network hidden layers to discretize continuous input manifolds by stretching space near decision boundaries and compressing it elsewhere.
- Mechanism: The network learns to warp the representational geometry, as measured by the Riemannian pullback metric G = J^T J, where J is the Jacobian of hidden activations. This causes the metric to become large near class boundaries (stretching) and small far from them (compression), effectively implementing a discretization of continuous inputs.
- Core assumption: The input data lies on a low-dimensional manifold (the manifold hypothesis).
- Evidence anchors:
  - [abstract]: "By analysing the Riemannian pullback metric across layers of a neural network, we find that network computation can be decomposed into two functions: discretising continuous input features and performing logical operations on these discretised variables."
  - [section]: "Visualising the entries of the metric tensor in the input coordinates highlighted that space near decision boundaries is stretched, while space far from them is compressed" (Section 3.2, Page 6-7).
  - [corpus]: "RNNs perform task computations by dynamically warping neural representations" (arXiv:2512.04310) supports representational warping for task computation in RNNs.
- Break condition: The manifold hypothesis does not hold for input data, or the network is too shallow to separate discretization from logical operations.

### Mechanism 2
- Claim: Rich learning regimes (small initial weights) produce structured, low-dimensional representational geometries that generalize better than the random, high-dimensional geometries of lazy regimes (large initial weights).
- Mechanism: In the rich regime (σ² ≪ 1), the perpendicular metric component G^⊥ is small, allowing the task-relevant component G^task to dominate as learning progresses. This leads to sparse, low-rank weight structures and curvature peaks at class centers, which generalize to unseen inputs.
- Core assumption: The learning dynamics are dominated by a small number of modes (low-rank structure) related to the task.
- Evidence anchors:
  - [abstract]: "rich learning regimes (small initial weights) lead to structured geometries with low-dimensional representations that generalize better, while lazy regimes (large initial weights) produce random geometries with poor generalization."
  - [section]: "Rich networks learned low-dimensional representations... the rich network representation had peaks in positive curvature near the class centres... the lazy network had a mostly flat curvature, with small, randomly spread out peaks" (Section 3.3, Pages 7-8).
  - [corpus]: Corpus evidence on rich vs. lazy regimes in this specific geometric context is weak or missing.
- Break condition: The task does not have a low-rank structure amenable to feature learning, or initialization scale is not the primary driver of the regime.

### Mechanism 3
- Claim: Input noise during training smooths the representational geometry (lowering curvature) and corresponds to the network learning a flatter posterior distribution of outputs.
- Mechanism: Noise forces the network to be less confident at boundaries, leading to less warping (smaller metric changes) and a qualitative shift from positive to negative curvature past a certain noise threshold. This reflects a Bayesian averaging over the noisy input distribution.
- Core assumption: Assumption: The noise distribution is known and its effect can be modeled as a Bayesian posterior.
- Evidence anchors:
  - [abstract]: "Input noise during training smooths the geometry, corresponding to flatter posterior distributions of network outputs."
  - [section]: "The curvature near the class centres decreased, even below zero past a certain noise level... This effect was correlated with the model output learning the flatter posterior distribution of the output" (Section 3.4, Pages 9-10).
  - [corpus]: Corpus evidence on the link between noise, curvature, and Bayesian posteriors is weak or missing.
- Break condition: Noise is not tangent to the manifold, or the noise model is misspecified relative to actual perturbations.

## Foundational Learning

- Concept: Riemannian Pullback Metric
  - Why needed here: It is the core mathematical tool used to characterize the intrinsic geometry of hidden layer representations.
  - Quick check question: Can you explain how the pullback metric measures the distance between two nearby points on a manifold as represented in a higher-dimensional space?

- Concept: Rich vs. Lazy Learning Regimes
  - Why needed here: Understanding the difference in generalization performance requires knowing how initialization scale affects the learned geometry.
  - Quick check question: What is the primary difference in the learned representations between a network trained in the "rich" regime versus the "lazy" regime?

- Concept: Manifold Hypothesis
  - Why needed here: The entire framework rests on the assumption that input data lies on low-dimensional continuous manifolds.
  - Quick check question: State the manifold hypothesis and give a simple example of data that might satisfy it.

## Architecture Onboarding

- Component map: MLP with inputs embedded from a continuous manifold (e.g., torus, plane), hidden layers with nonlinearities (e.g., tanh), and an output layer producing discrete class labels. Key analytical components: Jacobian of hidden activations (J_z), pullback metric tensor (G_z = J_z^T J_z), and Gaussian curvature (K).

- Critical path: 1) Define input manifold and task (e.g., XOR on torus), 2) Train network, 3) Compute Jacobian of hidden activations, 4) Compute pullback metric and curvature, 5) Visualize metric components and curvature over input manifold to identify discretization and logical operation phases.

- Design tradeoffs: Deeper networks (2+ layers) allow cleaner separation of discretization (early layers) and logical operations (later layers), while shallow networks may combine them in a single, more complex geometry. Rich regimes offer better generalization but may have slower initial convergence.

- Failure signatures:
  - Random, high-dimensional curvature patterns with no clear structure: Likely stuck in lazy regime. Remedy: Reduce weight initialization scale.
  - Curvature does not decrease with noise: Check if noise is properly applied tangent to the manifold.
  - Metric does not show stretching at boundaries: Network may not have learned proper discretization; check task difficulty or network capacity.

- First 3 experiments:
  1. Train an MLP on XOR-on-torus with varying weight initialization scales. Plot participation ratio and mean curvature to confirm transition from structured (rich) to random (lazy) geometries.
  2. Apply input noise (varying σ) during training and plot hidden layer curvature against noise level. Compare learned output distribution to analytic Bayesian posterior.
  3. Compare 1-layer vs. 2-layer network geometry on the same task. Visualize metric tensors to show how deeper networks partition computation across layers.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the intrinsic structure of the input manifold quantitatively influence the sample complexity required to learn discrete computations?
- Basis in paper: [explicit] The conclusion states that future work could use these toy models to understand "how the manifold structure of data influences sample complexity."
- Why unresolved: The current study characterizes the geometry of the final solution but does not derive theoretical bounds or empirical scaling laws relating manifold properties (e.g., curvature) to the number of training samples needed.
- What evidence would resolve it: A theoretical framework or empirical data demonstrating that sample complexity scales with specific geometric properties of the input manifold.

### Open Question 2
- Question: Can constraining the pullback metric tensor during training force networks to learn desired geometric invariances or equivariances?
- Basis in paper: [explicit] The authors suggest taking a "prescriptive approach by manipulating representational geometry via constraints on the metric during training" to design invariant models.
- Why unresolved: The paper analyzes geometry as an emergent property (descriptive) but does not experiment with utilizing the metric as a regularization term to shape the learning process.
- What evidence would resolve it: Experiments showing that adding a loss term based on the metric tensor successfully imposes geometric biases, improving generalization on specific transformation tasks.

### Open Question 3
- Question: Do the geometric signatures of discretization and logical operations persist in deep architectures trained on high-dimensional, real-world data?
- Basis in paper: [explicit] The conclusion notes that "future work could extend these analyses to more complex architectures trained on real-world data."
- Why unresolved: The findings are based on small MLPs with 4 hidden neurons and synthetic toroidal inputs; it is unknown if the "discretization-then-logic" decomposition exists in deep non-linear hierarchies like CNNs or Transformers.
- What evidence would resolve it: Analysis of pullback metrics in large-scale vision models (e.g., ResNets on ImageNet) revealing similar localization of the metric tensor near class boundaries.

## Limitations
- The framework relies heavily on the manifold hypothesis, which may not hold for all real-world datasets.
- The transition between rich and lazy regimes lacks precise quantitative thresholds and is described primarily qualitatively.
- The connection between curvature and Bayesian posteriors, while theoretically appealing, lacks rigorous mathematical proof.

## Confidence

**High Confidence**: The geometric interpretation of network computation through pullback metrics is mathematically sound and the visualization results showing metric stretching/compression are compelling. The distinction between rich and lazy regimes in terms of generalization performance is well-supported by empirical evidence.

**Medium Confidence**: The characterization of computation as separating into discretization and logical operations is conceptually clear but the exact mathematical decomposition could be more rigorously defined. The mechanism linking input noise to curvature changes and flatter posteriors is plausible but the theoretical connection needs stronger formalization.

**Low Confidence**: The generalizability of these geometric insights to deep networks with skip connections, batch normalization, or other modern architectural elements remains unclear. The framework's applicability to non-Boolean classification tasks is not demonstrated.

## Next Checks

1. **Rich/Lazy Transition Quantification**: Systematically vary initialization scale σ across several orders of magnitude and precisely measure the transition point where curvature patterns shift from structured to random, establishing quantitative criteria for regime classification.

2. **Beyond Boolean Functions**: Apply the geometric analysis framework to multi-class classification tasks (e.g., MNIST or CIFAR-10) to determine whether similar geometric structures emerge and whether the discretization/logical operation decomposition still applies.

3. **Real-World Manifold Validation**: Test the framework on datasets with known manifold structure (e.g., pose manifolds in computer vision) to validate whether the observed geometric patterns correspond to the underlying data geometry rather than being artifacts of the synthetic setup.