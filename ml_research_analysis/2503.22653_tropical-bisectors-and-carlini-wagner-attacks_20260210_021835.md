---
ver: rpa2
title: Tropical Bisectors and Carlini-Wagner Attacks
arxiv_id: '2503.22653'
source_url: https://arxiv.org/abs/2503.22653
tags:
- tropical
- layer
- then
- attacks
- gradient
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper analyzes the robustness of tropical convolutional neural
  networks against Carlini-Wagner attacks. The authors first prove an upper bound
  on the number of linear segments in tropical bisectors, which form the decision
  boundary of these networks.
---

# Tropical Bisectors and Carlini-Wagner Attacks

## Quick Facts
- arXiv ID: 2503.22653
- Source URL: https://arxiv.org/abs/2503.22653
- Reference count: 16
- Primary result: Modified Carlini-Wagner attack improves success rates from 61% to 72% on tropical networks

## Executive Summary
This paper investigates the robustness of tropical convolutional neural networks against Carlini-Wagner (CW) attacks. The authors demonstrate that tropical CNNs, which use max-plus algebra in their final layer, exhibit natural resistance to standard gradient-based attacks due to non-differentiable decision boundaries that cause gradient oscillations. They prove an upper bound on the number of linear segments in tropical bisectors that form the decision boundary, and propose a modified CW attack that smooths the gradient by penalizing all coordinates within a threshold of the maximum. Experiments on MNIST show the modified attack significantly improves success rates while requiring more computational resources.

## Method Summary
The authors train tropical CNNs on MNIST using LeNet5 and ModifiedLeNet5 architectures, replacing the final linear layer with a tropical embedding layer that computes distances using max-plus algebra. They implement a modified CW attack that uses a threshold-based gradient approximation to overcome the sparse gradient problem inherent in tropical layers. The attack initializes the threshold at the 7th highest value and dynamically updates it during optimization. Training uses learning rate 0.001 with plateau reduction, while the attack uses learning rate 0.1 with binary search for the constant parameter.

## Key Results
- Standard CW attack achieves only 42% success rate on tropical CNNs
- Modified CW attack with threshold-based gradients achieves 63% success rate
- Adding multiple starting points (MSP) strategy increases success to 98%
- The tropical bisector decision boundary has an upper bound of 4 · C(d+1,4) + ... linear segments
- Non-smooth tropical gradients cause oscillation that prevents successful attacks

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The robustness of Tropical CNNs against standard Carlini-Wagner (CW) attacks is primarily caused by the non-smoothness and sparsity of the gradients at the decision boundary, which induces oscillation in gradient descent optimizers.
- **Mechanism:** The tropical metric relies on `max` and `min` operations (Eq. 1). When calculating gradients for the CW attack objective, the derivative depends only on the coordinates achieving these maximum or minimum values (often just 4 non-zero entries in high dimensions). Standard gradient descent alternates between these sparse coordinates, causing the optimization to oscillate between regions rather than converging on a successful adversarial perturbation.
- **Core assumption:** Assumption: The failure of the attack is due to optimization dynamics (oscillation) rather than the intrinsic impossibility of finding a perturbation.
- **Evidence anchors:**
  - [Section 4.3]: "The gradient of a tropical CNN is not continuously differentiable, and in fact depends on a relatively low proportion of input coordinates. This may produce oscillatory effects..."
  - [Figure 7]: Visualizes gradient descent oscillation on a simple `max(h(x))` function.
- **Break condition:** If an optimizer uses non-gradient-based methods or smoothed gradients, this robustness mechanism fails.

### Mechanism 2
- **Claim:** The decision boundary of a Tropical CNN is piecewise linear with a finite upper bound on complexity, formally characterized by tropical bisectors.
- **Mechanism:** The decision boundary is defined by `bis(a,b)`, the locus of points equidistant to class representatives under the tropical metric. The paper proves an upper bound on the number of linear segments $C(b)$ in this boundary (Theorem 3.8). This geometric rigidity constrains how the boundary can curve, theoretically limiting (or defining) the surface area vulnerable to perturbations.
- **Core assumption:** Assumes class weights $w$ behave like generic points in the tropical projective torus.
- **Evidence anchors:**
  - [Abstract]: "Proving an upper bound on the number of linear segments in the decision boundary of tropical CNNs."
  - [Section 3]: Defines `bis(a,b)` and proves $C(b) \le 4 \cdot \binom{d+1}{4} + \dots$
- **Break condition:** If the dimension $d$ is low or the points are non-generic (collinear in the tropical sense), the bound may change, though the paper argues it generically holds.

### Mechanism 3
- **Claim:** The robustness can be significantly reduced by modifying the CW attack to use a "threshold-based" gradient approximation.
- **Mechanism:** Instead of differentiating only the strict `max` or `min` (which yields sparse gradients), the modified attack penalizes *all* coordinates within a threshold $\tau$ of the maximum (Eq. 42). This transforms the sparse, binary gradient into a denser, smoother signal that allows the optimizer to traverse the tropical bisector.
- **Core assumption:** Assumption: Choosing $\tau$ correctly (e.g., 7th highest value) effectively approximates the local geometry for optimization.
- **Evidence anchors:**
  - [Section 4.4]: Introduces modified distance $\tilde{d}_{tr}$ and the threshold $\tau$.
  - [Table 2]: Shows success rates increasing from 42% to 63% (ModifiedLeNet5) using this altered gradient descent.
- **Break condition:** If $\tau$ is set too low, it reverts to sparse oscillation; if too high, it may lose directionality.

## Foundational Learning

- **Concept:** Tropical Arithmetic & Geometry
  - **Why needed here:** The core architecture replaces standard Euclidean layers with operations from tropical geometry (max-plus algebra). You cannot debug the gradient flow without understanding the "tropical metric" ($d_{tr}$) defined as $max_i(x_i - y_i) - min_i(x_i - y_i)$.
  - **Quick check question:** If vector $x = (0,0)$ and $y = (1,2)$, what is the tropical distance $d_{tr}(x,y)$? (Answer: $max(0-1, 0-2) - min(0-1, 0-2) = -1 - (-2) = 1$).

- **Concept:** Carlini-Wagner (CW) Attack Formulation
  - **Why needed here:** The paper modifies the objective function $g(x') = \|x'-x\|_2 + \lambda \cdot f(x')$. Understanding that $f(x')$ is designed to push logits across a boundary is essential to seeing why the "tropical" gradient breaks this process.
  - **Quick check question:** In the CW attack, what does the constant $\kappa$ (kappa) control in the function $f$? (Answer: Confidence margin; the paper sets $\kappa=0$ for simplicity).

- **Concept:** Non-Smooth Optimization
  - **Why needed here:** The tropical metric is piecewise linear. Standard backpropagation assumes smooth derivatives to predict loss decrease. Here, the gradient can flip direction instantaneously at the "kinks" of the tropical bisector.
  - **Quick check question:** Why does Sub-Gradient Descent struggle with functions like $max(x, y)$ compared to $x^2$? (Answer: The gradient for $max$ is constant (1 or 0) depending on input, offering no "slope" information to slow down near the optimum, causing overshooting).

## Architecture Onboarding

- **Component map:** Input -> Base CNN (LeNet5/ModifiedLeNet5) -> Tropical Embedding Layer -> Softmin Output

- **Critical path:** The gradient flows from the Softmin $\to$ Tropical Distance $d_{tr} \to$ Base CNN weights. The failure mode occurs at the interface between Softmin and $d_{tr}$, where the `max/min` operators sparsify the gradient signal to only 2-4 coordinates.

- **Design tradeoffs:**
  - **Standard vs. Tropical Layer:** Standard layers are differentiable (easy to attack/optimize) but brittle. Tropical layers are non-differentiable (robust to standard attacks), but harder to optimize during training and attacking.
  - **Attack Complexity:** Using the "Altered Gradient" (Mechanism 3) improves attack success (e.g., to 98% with MSP) but requires tuning the threshold $\tau$.

- **Failure signatures:**
  - **Symptom:** Low attack success rate (~42%) on Tropical CNN using standard CW, despite the model having high accuracy.
  - **Cause:** Gradient oscillation; the loss does not converge because the gradient flips between sparse coordinates (See Figure 7).
  - **Fix:** Implement threshold-based gradient smoothing.

- **First 3 experiments:**
  1. **Baseline Verification:** Train a Tropical LeNet5 on MNIST. Run standard CW attack. Verify success rate is low (~42%).
  2. **Gradient Smoothing Test:** Implement the $\tilde{d}_{tr}$ function with a threshold $\tau$ (e.g., 7th highest coordinate value). Rerun the attack. Verify success rate jumps to ~63%+.
  3. **Boundary Visualization:** For a 2D toy dataset, plot the tropical bisector `bis(a,b)` and overlay the trajectory of the standard CW gradient vs. the modified gradient to visualize the oscillation vs. convergence.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Is the upper bound on the number of linear segments in tropical bisectors provided in Theorem 3.8 tight for all dimensions?
- Basis: [explicit] Page 12 states, "we conjecture that the bound in Theorem 3.8 is tight," noting that computational results achieve this bound for a subset of generic vectors.
- Why unresolved: While the authors prove the upper bound, the proof does not guarantee that this maximum is achieved for all generic configurations, only that it is theoretically possible.
- What evidence would resolve it: A formal proof confirming that the bound is the least upper bound for all generic vectors, or a counter-example showing a lower maximum in specific dimensions.

### Open Question 2
- Question: Does the efficacy of the modified Carlini-Wagner attack and the robustness of tropical layers scale to complex, high-dimensional datasets?
- Basis: [inferred] The paper’s empirical validation is restricted to the MNIST dataset using the relatively simple LeNet5 architecture (Section 4.4).
- Why unresolved: The interaction between the threshold-based gradient modification and high-dimensional data manifolds (e.g., ImageNet) is unknown; the "oscillation" effect might differ or the heuristic threshold $\tau$ may fail to converge.
- What evidence would resolve it: Computational experiments applying the tropical CNN and the modified attack to standard high-dimensional benchmarks (e.g., CIFAR-10, ImageNet) with deeper architectures.

### Open Question 3
- Question: What is the theoretically optimal method for selecting and adapting the threshold parameter $\tau$ in the modified gradient descent?
- Basis: [inferred] The paper introduces a threshold $\tau$ to improve the attack (Section 4.4) but defines its initialization and decay heuristically in the Appendix (Page 22).
- Why unresolved: The reliance on arbitrary initializations (e.g., "7th highest value") suggests a lack of theoretical grounding for how $\tau$ relates to the tropical geometry of the decision boundary.
- What evidence would resolve it: A sensitivity analysis on $\tau$ or a derived formulation linking $\tau$ to the distribution of coordinate values in the tropical embedding space.

## Limitations

- The theoretical upper bound on linear segments assumes generic weight configurations that may not hold for trained models
- The modified attack requires tuning the threshold parameter τ, which lacks theoretical justification for its heuristic initialization
- The computational budget and number of random restarts for achieving the reported success rates are not specified

## Confidence

**High Confidence**: The core observation that tropical CNNs exhibit lower attack success rates with standard CW attacks is well-supported by the experimental results (42% baseline vs 72% with modification). The geometric analysis of tropical bisectors and their linear segment count appears mathematically sound.

**Medium Confidence**: The mechanism explaining gradient oscillation is plausible and supported by the visualization in Figure 7, but the connection between sparse gradients and practical attack failure requires further empirical validation across different datasets and architectures. The claim that threshold-based smoothing significantly improves attack success is supported but could benefit from ablation studies varying τ.

**Low Confidence**: The theoretical upper bound on linear segments in tropical bisectors, while mathematically rigorous, may have limited practical relevance since it's derived under assumptions about generic weight configurations that aren't empirically verified for trained models.

## Next Checks

1. **Threshold Sensitivity Analysis**: Systematically vary the threshold parameter τ across a wide range and measure attack success rates to determine optimal values and understand the trade-off between gradient smoothness and attack effectiveness.

2. **Gradient Dynamics Visualization**: For multiple attack runs, record the gradient magnitude and direction at each iteration to quantitatively demonstrate the oscillation pattern described in Mechanism 1, comparing standard vs. modified attacks.

3. **Boundary Complexity Measurement**: For trained tropical CNN models, empirically measure the actual number of linear segments in tropical bisectors by sampling points along the decision boundary and comparing against the theoretical upper bound to assess its practical tightness.