---
ver: rpa2
title: 'C-ing Clearly: Enhanced Binary Code Explanations using C code'
arxiv_id: '2512.14500'
source_url: https://arxiv.org/abs/2512.14500
tags:
- code
- assembly
- c-ing
- clearly
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces C-ing Clearly, a method to improve Large
  Language Models' understanding of assembly code by leveraging corresponding C source
  code during training. The approach generates synthetic datasets of {assembly, report}
  pairs using prompts that include both assembly and C code, helping the model use
  C as a high-resource anchor to better reason about assembly.
---

# C-ing Clearly: Enhanced Binary Code Explanations using C code

## Quick Facts
- arXiv ID: 2512.14500
- Source URL: https://arxiv.org/abs/2512.14500
- Reference count: 32
- Primary result: C-ing Clearly improves binary code analysis by using C code as an anchor during synthetic data generation, achieving 66.8% win rate for BCS and F1 score of 8.66 vs 3.08 for VD baselines

## Executive Summary
This paper introduces C-ing Clearly, a method to improve Large Language Models' understanding of assembly code by leveraging corresponding C source code during training. The approach generates synthetic datasets of {assembly, report} pairs using prompts that include both assembly and C code, helping the model use C as a high-resource anchor to better reason about assembly. The method is applied to two tasks: binary code summarization and vulnerability detection, with Llama-3.1-8B-Instruct fine-tuned on datasets constructed from C/C++ code with known vulnerabilities. Results show that C-ing Clearly consistently outperforms baselines across model families and sizes.

## Method Summary
The method generates synthetic training data by prompting a strong LLM (Llama-3.1-Nemotron-70B-Instruct) with both C source code and corresponding assembly, producing high-quality {assembly, report} pairs. The C code acts as a semantic anchor that enables the generator to produce more accurate assembly analyses. These synthetic pairs are then used to fine-tune a smaller student model (Llama-3.1-8B-Instruct) on assembly-only input, effectively transferring the analytical capabilities learned from the C-anchored generation. The approach supports both single-turn and multi-turn prompting strategies, with the latter showing particular benefits for vulnerability detection tasks.

## Key Results
- C-ing Clearly achieves 66.8% win rate in BCS tasks compared to strong baselines
- For vulnerability detection, the method achieves F1 score of 8.66 versus 3.08 for baseline approaches
- The method works across different model families including Llama and Qwen, with consistent improvements
- Multi-turn prompting strategy yields best results for vulnerability detection (F1 12.78) while single-turn performs better for BCS

## Why This Works (Mechanism)

### Mechanism 1: High-Resource Language Anchoring
Providing C code alongside assembly during synthetic data generation enables the generator LLM to produce more semantically accurate assembly analyses. The C code serves as a semantic "anchor" that activates the model's existing knowledge about program logic, control flow, and purpose, which then informs the assembly-level explanation. This works because LLMs possess strong internal representations for high-resource languages (C, Python) from pre-training but weak representations for assembly.

### Mechanism 2: Distillation from Anchored Generation to Assembly-Only Inference
Fine-tuning on C-anchored synthetic data transfers analytical capabilities to the student model, which then performs assembly-only inference without needing C code at test time. The synthetic {assembly, report} pairs encode high-quality reasoning patterns produced by the C-anchored generator. Through supervised fine-tuning, the student model internalizes these patterns—learning to recognize assembly idioms, infer high-level functionality, and structure analyses—without requiring the C scaffold at inference.

### Mechanism 3: Multi-Turn Decomposition for Complex Reasoning Tasks
Decomposing the analysis into sequential turns (C analysis → cross-reference → assembly-only synthesis) improves performance on tasks requiring deeper reasoning, such as vulnerability detection. The multi-turn variant forces the model to first build a high-level understanding of C logic, then map that to assembly structures, and finally synthesize an assembly-only explanation. This staged reasoning reduces cognitive load per turn and creates explicit intermediate representations that the model can reference.

## Foundational Learning

- **Concept: Synthetic Data Generation for Low-Resource Domains**
  - Why needed here: The method's core innovation is generating training data using a stronger model with privileged information (C code) that won't be available at test time. Understanding this paradigm is essential for replicating or extending the approach.
  - Quick check question: Can you explain why the generator sees C code but the student model does not, and what risk this asymmetry introduces?

- **Concept: Supervised Fine-Tuning vs. In-Context Learning**
  - Why needed here: The paper compares zero-shot baselines (in-context) against fine-tuned models. Understanding when fine-tuning outperforms prompting—and at what cost—is critical for practical deployment.
  - Quick check question: Given a 1B-token fine-tuning budget, what factors would determine whether fine-tuning is preferable to RAG or few-shot prompting for a binary analysis task?

- **Concept: Assembly Fundamentals (Calling Conventions, Control Flow, Stack Frames)**
  - Why needed here: The outputs include detailed assembly analysis with references to prologues, jump tables, and register usage. Practitioners need sufficient assembly literacy to evaluate output quality and design task-specific prompts.
  - Quick check question: In x86-64 assembly compiled from C, what does the `pushq %rbp; movq %rsp, %rbp` sequence typically indicate, and how might optimization flags alter this?

## Architecture Onboarding

- **Component map**: C/C++ source files -> GCC compilation (gcc -S) -> assembly files -> paired with original C -> Generator LLM (Llama-3.1-Nemotron-70B) prompted with {C, assembly} -> produces {assembly, report} pairs -> Fine-tuning of student model (Llama-3.1-8B-Instruct) on {task_prefix + assembly, report} pairs -> Evaluation using GPT-4o judge (BCS) or micro F1 (VD)

- **Critical path**: The synthetic data quality is the bottleneck. If generator outputs are inconsistent or hallucinate, downstream fine-tuning degrades. Rejection sampling is critical when generator-ground-truth alignment is imperfect (58-59% for Qwen vs. 97-99% for Nemotron).

- **Design tradeoffs**: Single-turn vs. Multi-turn: Single-turn yields better BCS summaries; multi-turn excels at VD. Task-specific selection required. Generator size: Larger generators (70B) produce higher-quality synthetic data but at higher cost. Smaller generators may require aggressive rejection sampling. Token budget: Scaling from 1B to 5B tokens improves VD F1, but diminishing returns are likely beyond a dataset-specific threshold.

- **Failure signatures**: Reports that reference C code explicitly (prompt violation), low CWE match rates in synthetic VD data (generator misalignment), student model outputs that are verbose but lack "core functionality" insights (judge feedback), overfitting to training distribution: poor generalization to different compilers, optimization levels, or instruction sets (ARM, RISC-V not covered).

- **First 3 experiments**:
  1. Replicate BCS baseline: Generate a small synthetic dataset (~10K pairs) using the single-turn C-ing Clearly prompt, fine-tune Llama-3.1-8B for 1 epoch, and compare zero-shot vs. fine-tuned outputs using GPT-4o as judge.
  2. Ablate the C anchor: Generate synthetic data using "No C-ing" (assembly-only prompts) vs. "C-ing Clearly" and compare downstream VD F1 scores.
  3. Test generalization to optimized code: Compile the same C source with `-O2` and `-O3` flags, generate synthetic reports, and evaluate whether C-anchored generation maintains quality under optimization.

## Open Questions the Paper Calls Out

- **Open Question 1**: Does the C-ing Clearly method retain its effectiveness when applied to binaries compiled with aggressive compiler optimizations (e.g., -O2, -O3)?
  - Basis in paper: The authors state experiments relied on `gcc -S` with no optimization, and hypothesize that the C anchor might help interpret "more compact representations" found in optimized code.
  - Why unresolved: Optimizations often inline functions, unroll loops, and reorder instructions, potentially breaking the "anchoring" logic the prompts depend on.
  - What evidence would resolve it: Ablation studies evaluating performance on datasets compiled with various optimization levels.

- **Open Question 2**: Can the approach generalize to instruction set architectures (ISAs) other than x86-64, such as ARM or RISC-V?
  - Basis in paper: Section 7 explicitly lists this as a limitation, noting results are "demonstrated on the x86-64 instruction set, without covering other instruction sets."
  - Why unresolved: x86-64 is a CISC architecture while ARM/RISC-V are RISC architectures with different register sets and calling conventions.
  - What evidence would resolve it: Cross-architecture evaluation where the same C-source datasets are compiled for ARM64/RISC-V.

- **Open Question 3**: How does the method perform on longer binaries that exceed the current 16K token context limit?
  - Basis in paper: The authors acknowledge a "practical limitation lies in the size of the assembly programs," restricting inputs to 16K tokens.
  - Why unresolved: Larger binaries provide more context but also more noise; it's unknown if the model can maintain focus on the "C anchor" logic over longer sequences.
  - What evidence would resolve it: Application using long-context models (e.g., 128k context windows) on large, stripped binaries.

## Limitations

- The method's effectiveness degrades when assembly-to-C correspondence breaks down due to compiler optimizations (-O2/-O3) or obfuscation, though this is not experimentally validated
- Multi-turn prompting adds complexity without clear guidance on when to prefer it over single-turn approaches
- Rejection sampling for quality control is described but not quantitatively evaluated—we don't know how many synthetic examples are discarded

## Confidence

**High Confidence**: The empirical results showing consistent improvements across multiple model families (Llama, Qwen) and task types (BCS and VD) are well-supported by the data.

**Medium Confidence**: The mechanism explaining why C-ing Clearly works—that C code serves as a high-resource anchor enabling better assembly reasoning—is plausible but not definitively proven.

**Low Confidence**: The claim that C-ing Clearly is "particularly effective" for low-resource domains is stated but not substantiated with systematic experiments varying dataset size or model parameter count.

## Next Checks

1. **Ablation on C Anchor**: Generate synthetic data using identical prompts but with C code removed ("No C-ing" condition) and compare downstream performance to the published results. This would directly test whether the C-anchoring mechanism is responsible for the observed improvements.

2. **Optimization Flag Robustness**: Repeat the synthetic data generation and fine-tuning pipeline using C source compiled with -O2 and -O3 optimization flags. Evaluate whether C-ing Clearly maintains its performance advantage when the assembly-to-C correspondence is weakened.

3. **Scaling Study**: Vary the synthetic training data budget from 100M to 5B tokens and measure the performance curves for both BCS and VD tasks. This would reveal whether C-ing Clearly's benefits scale proportionally with data volume or if diminishing returns set in.