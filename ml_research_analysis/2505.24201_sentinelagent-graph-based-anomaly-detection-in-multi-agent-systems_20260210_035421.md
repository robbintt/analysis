---
ver: rpa2
title: 'SentinelAgent: Graph-based Anomaly Detection in Multi-Agent Systems'
arxiv_id: '2505.24201'
source_url: https://arxiv.org/abs/2505.24201
tags:
- agent
- system
- content
- detection
- email
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses security and reliability challenges in large
  language model (LLM)-based multi-agent systems (MAS), which face risks including
  prompt manipulation, unsafe tool usage, and emergent agent miscoordination. The
  authors propose a graph-based anomaly detection framework that models agent interactions
  as dynamic execution graphs, enabling semantic anomaly detection at node, edge,
  and path levels.
---

# SentinelAgent: Graph-based Anomaly Detection in Multi-Agent Systems

## Quick Facts
- arXiv ID: 2505.24201
- Source URL: https://arxiv.org/abs/2505.24201
- Authors: Xu He; Di Wu; Yan Zhai; Kun Sun
- Reference count: 40
- Key outcome: Graph-based anomaly detection framework for LLM-based multi-agent systems that detects prompt manipulation, tool misuse, and agent coordination risks through semantic analysis at node, edge, and path levels.

## Executive Summary
This paper addresses security and reliability challenges in large language model-based multi-agent systems (MAS) by proposing a graph-based anomaly detection framework. The approach models agent interactions as dynamic execution graphs, enabling semantic anomaly detection at multiple levels. The authors implement this through SentinelAgent, an LLM-powered oversight agent that observes, analyzes, and intervenes in MAS execution based on security policies. The framework is validated through two case studies demonstrating detection of unauthorized tool use, prompt manipulation, and multi-agent collusion with explainable root-cause attribution.

## Method Summary
The framework constructs dynamic execution graphs during runtime where nodes represent agents/tools and edges represent interactions. SentinelAgent operates through three modules: Event Monitor (collects traces via OpenTelemetry/Phoenix), Behavior Analyzer (applies LLM-as-Judge using Granite Guardian 3.2 and LlamaFirewall to label status), and Risk Responder (provides tiered alerts). The system decouples node and edge status for isolated failure detection, uses attack path tracing via subgraph matching, and employs runtime oversight through LLM judgment. Detection is configured per MAS topology (Round Robin, Orchestrator, Ledger) with human-in-the-loop refinement of LLM-generated policies.

## Key Results
- Successfully detects prompt injection, jailbreak, and tool misuse through node-level and edge-level semantic analysis
- Identifies multi-agent collusion and latent exploit paths through attack path tracing
- Provides explainable root-cause attribution in two case studies (CrewAI email assistant and Magentic-One)
- Demonstrates pluggable architecture that can be integrated with existing MAS frameworks

## Why This Works (Mechanism)

### Mechanism 1: Dual-Status Graph Decoupling
Modeling agent systems as a directed interaction graph with decoupled node and edge status allows isolation of distinct failure modes. Node status checks for role conformity (e.g., hallucinated plans), while edge status checks for adversarial content or control flow anomalies (e.g., prompt injection). This enables the framework to differentiate between compromised agents and malicious interactions.

### Mechanism 2: Attack Path Tracing via Subgraph Matching
Detecting complex multi-point failures requires analyzing the execution trajectory as a whole rather than isolated steps. The system constructs dynamic execution graphs and matches subgraphs against an attack path library to identify sequences of actions that are individually benign but collectively harmful, such as prompt injection propagating through an orchestrator to trigger unsafe tool use.

### Mechanism 3: Runtime Oversight via LLM-as-Judge
An independent LLM-powered agent provides effective runtime oversight by observing traces and enforcing policies. The SentinelAgent intercepts events, builds the graph, and uses specific models (Granite Guardian, LlamaFirewall) to judge semantic content against security policies, intervening via alerts or rewrites when violations are detected.

## Foundational Learning

- **MAS Topologies (Round Robin vs. Orchestrator vs. Ledger):** The graph structure and resulting anomaly detection logic depend entirely on the system's topology. A centralized orchestrator creates a hub-and-spoke graph, while a ledger system requires reasoning over temporal state evolution. Quick check: Can you identify how the "attack path" for a compromised orchestrator differs from a compromised worker agent in a ledger-based topology?

- **Dynamic Execution Graphs:** This core data structure captures actual runtime flow (who called whom with what data) necessary for semantic anomaly detection. Unlike static call graphs, dynamic graphs reflect real execution patterns. Quick check: How does a "dynamic" graph differ from a static architecture diagram in detecting a "latent exploit path"?

- **LLM-based Guardrails (Prompt Injection vs. Tool Misuse):** The SentinelAgent uses specific guardrail models to label nodes and edges. Understanding the difference between detecting jailbreak (prompt-level) and unsafe tool parameters (tool-level) is crucial for configuring the Behavior Analyzer. Quick check: Which component would flag a benign-looking prompt that eventually leads to an unauthorized API call: node status check or attack path analysis?

## Architecture Onboarding

- **Component map:** Event Monitor -> Graph Builder -> Behavior Analyzer -> Risk Responder
- **Critical path:** Event Interception -> Graph Instantiation -> Policy Application (Node/Edge checks) -> Path Matching -> Intervention
- **Design tradeoffs:** Latency vs. Security (LLM checks introduce significant latency), Generalization vs. Specificity (human-in-the-loop refinement needed), Observability (unobservable channels will be missed)
- **Failure signatures:** High False Positives (narrow expected behavior catalog), Cascade Latency (lag in high-frequency MAS), Blind Spots (direct ledger/memory manipulation)
- **First 3 experiments:**
  1. Implement Event Monitor on simple Round Robin system to verify graph construction fidelity
  2. In Email Assistant case study, inject prompt injection into Classifier agent to test Node Status check
  3. Replicate Magentic-One code execution scenario to test multi-step attack path detection

## Open Questions the Paper Calls Out

1. Can automated policy learning mechanisms (reinforcement learning, program synthesis, fine-tuning) effectively bootstrap anomaly detection logic from empirical traces and adversarial simulation?

2. How can the inherent vulnerabilities of the LLM-powered SentinelAgent (hallucination, inconsistency, adversarial susceptibility) be systematically quantified and mitigated without introducing detection blind spots?

3. What are the precision, recall, and false positive rates of the graph-based detection framework across standardized benchmarks, and how does performance vary by MAS topology and attack category?

4. What graph optimization techniques (pruning, event filtering, asynchronous monitoring) can reduce computational overhead in large-scale MAS while maintaining detection coverage for multi-round attack paths?

5. Can formal verification tools (model checking, static analysis) be integrated with runtime graph analysis to provide provable correctness guarantees for safety-critical MAS deployments?

## Limitations

- No quantitative validation metrics (precision, recall, F1-score) provided across attack scenarios
- No implementation artifacts (prompts, thresholds, attack path libraries) available for replication
- LLM-as-judge approach introduces latency that may be prohibitive for high-frequency MAS execution
- Framework validated only on two specific MAS architectures, limiting generalization claims

## Confidence

**High Confidence:** Graph-based approach to modeling MAS execution is sound and well-established in cybersecurity literature.

**Medium Confidence:** Detection mechanisms (Granite Guardian for jailbreak/hallucination, LlamaFirewall for prompt injection) are effective based on individual reputations.

**Low Confidence:** Attack path detection capability for zero-day or novel multi-agent collusion patterns relies heavily on unspecified attack path library and LLM reasoning without demonstrated accuracy.

## Next Checks

1. **False Positive Rate Analysis:** Instrument SentinelAgent in CrewAI email assistant case study to measure false positive rates across normal execution patterns and compare against manually annotated ground truth.

2. **Performance Overhead Benchmarking:** Measure end-to-end latency impact of SentinelAgent intervention in high-frequency MAS (e.g., rapid code generation loops in Magentic-One) to document security-coverage vs. execution-speed tradeoffs.

3. **Cross-Topology Generalization:** Implement SentinelAgent in a ledger-based MAS (e.g., ReAct-based system with shared memory) and evaluate detection accuracy for temporal state manipulation attacks not present in original case studies.