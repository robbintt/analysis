---
ver: rpa2
title: On Self-Adaptive Perception Loss Function for Sequential Lossy Compression
arxiv_id: '2502.10628'
source_url: https://arxiv.org/abs/2502.10628
tags:
- frame
- following
- follows
- where
- step
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper studies sequential lossy video compression with both
  mean squared error (MSE) distortion and a perception loss function (PLF) to enhance
  reconstruction realism. Previous PLF approaches suffer from error permanence (PLF-JD)
  or fail to exploit temporal correlation (PLF-FMD).
---

# On Self-Adaptive Perception Loss Function for Sequential Lossy Compression

## Quick Facts
- arXiv ID: 2502.10628
- Source URL: https://arxiv.org/abs/2502.10628
- Reference count: 40
- One-line primary result: Proposed self-adaptive perception loss function simultaneously avoids error permanence and better exploits temporal correlation in sequential video compression.

## Executive Summary
This paper addresses sequential lossy video compression by introducing a self-adaptive perception loss function (PLF-SA) that balances mean squared error distortion with perception quality. Previous approaches suffer from either error permanence (PLF-JD) or failure to exploit temporal correlation (PLF-FMD). The proposed PLF-SA considers the joint distribution between current source frame and previous reconstructions, adapting its behavior based on the quality of prior reconstructions. Theoretical analysis for first-order Markov sources establishes rate-distortion-perception bounds, while experiments on MovingMNIST and UVG datasets demonstrate superior performance in both distortion and perceptual quality metrics compared to existing approaches.

## Method Summary
The method extends sequential lossy compression frameworks by introducing a perception loss function that conditions on the quality of previous reconstructions. The core innovation is a self-adaptive constraint comparing P(Ẑ₁...ⱼ₋₁, Xⱼ) against P(Ẑ₁...ⱼ₋₁, Ẑⱼ) rather than requiring full joint distribution preservation. This is implemented using a Wasserstein-2 distance computed via a WGAN discriminator. The framework uses scale-space flow encoder-decoder architecture with dithered quantization for shared randomness simulation. Training follows a two-stage approach: pre-training with MSE only, then fine-tuning with joint distortion-perception loss. The self-adaptive nature allows the system to recover from low-quality reconstructions when high-quality frames become available, while maintaining temporal consistency when prior reconstructions are accurate.

## Key Results
- PLF-SA simultaneously avoids error permanence (unlike PLF-JD) and better exploits temporal correlation (unlike PLF-FMD)
- When first frame is compressed at low bitrate, PLF-SA recovers from errors like PLF-FMD but unlike PLF-JD
- When first frame is compressed at high bitrate, PLF-SA maintains temporal consistency unlike PLF-FMD while avoiding error propagation unlike PLF-JD
- Theoretical analysis for Gauss-Markov sources shows PLF-SA reduces to PLF-JD under high-quality previous reconstructions and to PLF-FMD under poor reconstructions

## Why This Works (Mechanism)

### Mechanism 1: Adaptive Perception Constraint Conditioning on Previous Reconstruction Quality
The perception loss compares P(Ẑ₁...ⱼ₋₁, Xⱼ) against P(Ẑ₁...ⱼ₋₁, Ẑⱼ) rather than requiring P(X₁...ⱼ) = P(Ẑ₁...ⱼ). When Ẑⱼ₋₁ has high distortion, the constraint does not force Ẑⱼ to inherit those errors, allowing the decoder to incorporate new information from Xⱼ.

### Mechanism 2: Conditional Reduction to Joint Distribution Matching Under High-Quality Previous Reconstructions
When previous reconstructions are high-quality (R₁ → ∞, Ẑ₁ = X₁), PLF-SA's constraint P(Ẑ₁X₂) = P(Ẑ₁Ẑ₂) reduces to P(X₁X₂) = P(X₁Ẑ₂), equivalent to PLF-JD's constraint, enabling temporal correlation exploitation.

### Mechanism 3: Noise Propagation Attenuation Through Conditional Independence Structure
PLF-SA limits noise propagation by not requiring the reconstruction to depend on noise from prior low-rate frames when higher-rate information becomes available. For the third frame with R₁ → ∞, R₃ → ∞, PLF-SA achieves Ẑ₃ = X₃ directly, while PLF-JD has Ẑ₃ dependent on propagated noise from frame 2.

## Foundational Learning

- Concept: Rate-Distortion-Perception (RDP) Tradeoff
  - Why needed here: The paper extends classical rate-distortion theory with perception constraints; understanding the three-way tradeoff is essential for interpreting the RDP region definitions and Gaussian analysis.
  - Quick check question: Can you explain why perfect perceptual quality (P=0) may require higher rate than minimum MSE distortion at the same D?

- Concept: Wasserstein-2 Distance
  - Why needed here: The perception metric ϕⱼ is defined as W₂² distance between joint distributions; the theoretical analysis for Gauss-Markov sources uses W₂ properties explicitly.
  - Quick check question: For two Gaussian distributions N(μ₁, σ₁²) and N(μ₂, σ₂²), what is the Wasserstein-2 distance?

- Concept: First-Order Markov Sources (Gauss-Markov)
  - Why needed here: All theoretical derivations assume Xⱼ = ρXⱼ₋₁ + Nⱼ₋₁ structure; coefficients ω, τ in reconstructions depend on understanding this temporal correlation model.
  - Quick check question: If X₂ = ρX₁ + N₁ with N₁ ~ N(0, (1-ρ²)σ²), what is Cov(X₁, X₂)?

## Architecture Onboarding

- Component map: Source (X₁...T) → Sequential Encoder {fⱼ} → Messages (M₁...T) → Shared Randomness K → Sequential Decoder {gⱼ} → Reconstructions (Ẑ₁...T) → WGAN Discriminator ← Perception loss

- Critical path:
  1. Implement scale-space flow encoder-decoder backbone per frame
  2. Add WGAN discriminator to compute Wasserstein perception loss
  3. Modify perception constraint to use P(Ẑ₁...ⱼ₋₁, Xⱼ) vs P(Ẑ₁...ⱼ₋₁, Ẑⱼ)
  4. Use dithered quantization for shared randomness simulation

- Design tradeoffs:
  - Lagrangian λ selection: Controls distortion-perception balance; pre-train with MMSE first, then fine-tune with joint loss
  - Latent dimension vs. bitrate: Adjust latent representation dimension while fixing quantization interval to 2
  - Frame-wise vs. sequential training: Paper optimizes each frame's encoder-decoder using representations from previous frames

- Failure signatures:
  - If Ẑⱼ exhibits color tone errors propagating from frame 1: Likely using PLF-JD-style full joint constraint; verify perception loss implementation
  - If Ẑⱼ shows temporal inconsistency (digit identity changes): Likely using PLF-FMD-style marginal constraint; check if joint conditioning on Ẑⱼ₋₁ is applied
  - If training instability with WGAN: Check gradient penalty implementation (Gulrajani et al., 2017 reference)

- First 3 experiments:
  1. Low-rate first frame validation: Compress frame 1 at R₁=12 bits (MovingMNIST) or 0.144 bpp (UVG), verify that frames 2-3 recover from errors (compare Fig. 1a/b outputs visually)
  2. High-rate first frame validation: Compress frame 1 at R₁→∞ (lossless), R₂=2 bits, R₃=16 bits, verify temporal correlation preservation vs. PLF-FMD baseline (compare Fig. 5 outputs)
  3. Ablation on correlation coefficient ρ: Test both sharp movement (small ρ) and smooth movement (large ρ) scenarios to verify adaptive behavior matches Table 2 theoretical predictions

## Open Questions the Paper Calls Out
- How does PLF-SA perform on longer video sequences beyond the 3-frame scenarios primarily analyzed?
- How does the choice of perception metric affect the distortion-perception-temporal consistency trade-offs, and is Wasserstein-2 distance optimal among alternatives?
- What is the computational complexity of PLF-SA relative to PLF-FMD and PLF-JD, and can the approach scale to real-time video compression with strict latency constraints?

## Limitations
- Theoretical analysis limited to Gaussian-Markov sources that may not capture complex temporal dynamics in natural video
- Empirical validation relies on relatively simple datasets (MovingMNIST with synthetic trajectories, UVG with limited diversity)
- Adaptive benefits depend critically on bitrate allocation patterns across frames, which may not be controllable in practical systems

## Confidence
- High confidence: The mathematical formulation of PLF-SA and its distinction from PLF-JD/PLF-FMD (Theorem 1 proof is rigorous)
- Medium confidence: The empirical demonstration on MovingMNIST and UVG (dataset limitations acknowledged but methodology is sound)
- Medium confidence: The claim that PLF-SA "simultaneously avoids error permanence and better exploits temporal correlation" (supported by experiments but dependent on specific test conditions)

## Next Checks
1. Test PLF-SA on a third dataset with different temporal characteristics (e.g., DAVIS or UCF-101) to verify adaptive behavior generalizes beyond MovingMNIST synthetic sequences
2. Conduct ablation studies varying ρ across multiple orders of magnitude to confirm the theoretical predictions in Table 2 hold empirically for diverse motion patterns
3. Implement an online bitrate allocation strategy that automatically adjusts Rⱼ based on previous reconstruction quality, then evaluate whether PLF-SA maintains advantages without manual bitrate control