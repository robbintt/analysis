---
ver: rpa2
title: Quantitative Analysis of Deeply Quantized Tiny Neural Networks Robust to Adversarial
  Attacks
arxiv_id: '2503.08973'
source_url: https://arxiv.org/abs/2503.08973
tags:
- attacks
- adversarial
- robustness
- neural
- networks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a tiny, quantized DNN model that is adversarially
  robust. It is trained with Jacobian Regularization (JR) using the QKeras framework,
  where deep quantization inherently introduces per-layer JR.
---

# Quantitative Analysis of Deeply Quantized Tiny Neural Networks Robust to Adversarial Attacks

## Quick Facts
- arXiv ID: 2503.08973
- Source URL: https://arxiv.org/abs/2503.08973
- Authors: Idris Zakariyya; Ferheen Ayaz; Mounia Kharbouche-Harrari; Jeremy Singer; Sye Loong Keoh; Danilo Pau; José Cano
- Reference count: 40
- One-line primary result: Tiny, quantized DNN model adversarially robust via Jacobian Regularization from QKeras quantization-aware training, achieving 410 KB memory footprint with strong accuracy under multiple attacks.

## Executive Summary
This paper presents a tiny, quantized DNN model that is adversarially robust. It is trained with Jacobian Regularization (JR) using the QKeras framework, where deep quantization inherently introduces per-layer JR. The resulting Stochastic Ternary Quantized (STQ) model uses heterogeneous quantization to reduce memory footprint while maintaining accuracy. Evaluations show the STQ model (410 KB) outperforms existing TinyML benchmarks in accuracy across CIFAR-10 and Google Speech Commands datasets under multiple white-box and black-box attacks. The STQ-T50 variant also surpasses state-of-the-art defenses like QUANOS and RND-AT in several attack scenarios. The work demonstrates that deep quantization via QKeras provides a lightweight path to robust, deployable edge models.

## Method Summary
The paper proposes a Stochastic Ternary Quantized (STQ) model built on QKeras framework with heterogeneous quantization. The model uses 6 convolutional layers (including depthwise and separable convolutions) and 3 fully connected layers with residual connections. Training employs quantization-aware training with stochastic ternary quantization, defensive distillation (T=50), and Jacobian Regularization inherent to QKeras. The model is evaluated on CIFAR-10, SVHN, and Google Speech Commands datasets under white-box attacks (FGSM, PGD, C&W) and black-box attacks (Square, Boundary, ZOO) using IBM ART library.

## Key Results
- STQ model (410 KB) achieves 80.57% CIFAR-10 accuracy vs. 75.20% baseline FP model (4496 KB)
- STQ-T50 outperforms state-of-the-art defenses QUANOS and RND-AT across multiple attack scenarios
- Maintains competitive accuracy on Google Speech Commands (90.55% clean, 88.85% under attack)
- Binary quantization (140 KB) collapses accuracy to 37.30% on CIFAR-10

## Why This Works (Mechanism)

### Mechanism 1: Per-Layer Jacobian Regularization via Quantization-Aware Training
QKeras introduces per-layer Jacobian Regularization and therefore increases the robustness of DNNs against adversarial attacks. During backpropagation, quantization of gradients at each layer computes the Jacobian matrix, effectively minimizing the Frobenius norm and expanding classification margins. This requires quantization-aware training (not post-training quantization) to apply.

### Mechanism 2: Stochastic Ternary Quantization for Error Compensation
Stochastic quantization incrementally compensates quantization error while preserving accuracy. Instead of quantizing all parameters at once, STQ quantizes a portion stochastically (probability inversely proportional to quantization error) while keeping remaining parameters in full precision. The quantized portion gradually increases per iteration, allowing the network to learn to overcome quantization noise progressively.

### Mechanism 3: Defensive Distillation Smoothing via Temperature Scaling
Defensive distillation mitigates white-box and black-box attacks by smoothing the learned model. Temperature parameter T=50 in softmax smoothing reduces gradient-based attack effectiveness by flattening decision boundaries. This reduces gradient magnitudes that white-box attacks exploit for perturbation direction.

## Foundational Learning

- **Quantization-Aware Training (QAT) vs. Post-Training Quantization:** Why needed here: The paper's core contribution relies on QAT-specific mechanisms; conflating with PTQ will lead to incorrect implementation. Quick check question: During training, are gradients quantized in the backward pass? If no, this is PTQ and won't produce JR effects.

- **Jacobian Matrix and Frobenius Norm:** Why needed here: Understanding why minimizing ||J(x_i)||_F^2 expands classification margins is essential for debugging robustness failures. Quick check question: If a network has high Frobenius norm for input x_i, would you expect larger or smaller input perturbations to cause misclassification?

- **White-box vs. Black-box Attack Taxonomy:** Why needed here: The paper evaluates six attacks with fundamentally different assumptions; misinterpreting attack capabilities invalidates robustness claims. Quick check question: Can a Square attack access model gradients? (Answer: No—it's a query-based random search method.)

## Architecture Onboarding

- **Component map:** Input → [QConv2D + BatchNorm + QReLU] × 6 layers (some depthwise/separable) → [Residual connections in multi-branch topology] → [QDense + QActivation] × 3 layers → Softmax (temperature T ∈ {1, 50})

- **Critical path:**
  1. Define FP Keras model architecture first (998K parameters, 4MB)
  2. Replace layers with QKeras equivalents using qconv2d, qdense, quantized_relu
  3. Configure stochastic ternary quantizers per layer (heterogeneous scheme)
  4. Train with quantization-aware training (1000 epochs, cosine annealing LR)
  5. Apply defensive distillation with T=50 if targeting white-box robustness

- **Design tradeoffs:**
  - Memory vs. Accuracy: STQ (410 KB) achieves 80.57% CIFAR-10 accuracy vs. FP model (4496 KB) at 75.20%
  - Robustness vs. Clean Accuracy: STQ-T50 slightly underperforms STQ-T1 on clean GSC (88.85% vs. 90.55%) but shows better robustness on CIFAR-10
  - Training Time: JR introduction increases training computation time (acknowledged in Section 3.1)

- **Failure signatures:**
  - Binary quantization (140 KB) collapses accuracy to 37.30% CIFAR-10—excessive compression
  - 8-bit quantization (1124 KB) drops to 33.82% accuracy—suggests architecture-quantizer mismatch
  - If Square attack accuracy approaches clean accuracy, model may be underfitting or perturbations too weak

- **First 3 experiments:**
  1. Baseline sanity check: Train FP model and STQ model on CIFAR-10; verify STQ-T50 achieves ~80% clean accuracy with 410 KB footprint. If accuracy <70%, check quantizer configuration (bit-width, stochastic schedule).
  2. JR mechanism validation: Compare STQ trained with QKeras vs. identical architecture with post-training ternary quantization. Expect QKeras version to show 5-15% higher accuracy under FGSM (ε=0.3).
  3. Attack surface coverage: Run all six attacks (FGSM, PGD, C&W, Square, Boundary, ZOO) on STQ-T50 for CIFAR-10. If white-box robustness >> black-box robustness, distillation is working but random-noise defenses (RND-AT style) may need augmentation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the quantitative resilience of the MobileNetV2-STQ-T50 architecture to adversarial attacks compared to the proposed custom STQ model?
- Basis in paper: [explicit] Page 14 states, "A task that remains open at this point in time is the quantitative resilience of MobileNetV2-STQ-T50 to adversarial attacks."
- Why unresolved: While the authors applied STQ to MobileNetV2 and measured clean accuracy and memory footprint, they did not evaluate this specific state-of-the-art variant against the adversarial attacks used for the custom model.
- Evidence to resolve it: Benchmarking MobileNetV2-STQ-T50 against white-box attacks (FGSM, PGD, C&W) and black-box attacks (Square, Boundary, Zoo) to obtain comparative robustness metrics.

### Open Question 2
- Question: Does the inherent robustness of the STQ model hold against newer, more sophisticated adversarial attacks?
- Basis in paper: [explicit] Page 15 notes, "Future work will further assess the effectiveness of the proposed STQ QKeras model against new and latest attacks..."
- Why unresolved: The study was restricted to a specific set of standard attacks (FGSM, PGD, C&W, Square, Boundary, Zoo), leaving the model's performance against adaptive or emerging attack vectors unknown.
- Evidence to resolve it: Evaluating the STQ model against advanced attack libraries (e.g., AutoAttack) or stronger adaptive attacks designed to bypass quantization defenses.

### Open Question 3
- Question: How does the inclusion of color processing affect the robustness and accuracy trade-offs of the STQ model?
- Basis in paper: [explicit] Page 9 states color processing "was out of scope in this work and may be considered as future extensions for problems where the color components are essential."
- Why unresolved: The input images were converted to grayscale to reduce computational cost, but it is unclear if removing color channels eliminates critical features or masks vulnerabilities in more complex datasets.
- Evidence to resolve it: Replicating the training and evaluation pipeline using RGB inputs on color-sensitive datasets and comparing the adversarial accuracy against the grayscale baseline.

## Limitations
- The paper's claims about Jacobian Regularization via quantization-aware training, while mathematically grounded, lack direct empirical validation beyond the proposed STQ model.
- The heterogeneous quantization scheme's per-layer bit-width configurations are not fully specified, potentially affecting reproducibility.
- Defensive distillation effectiveness, particularly against black-box attacks, shows mixed results compared to state-of-the-art defenses.

## Confidence
- High: STQ model achieves significant memory reduction (410 KB vs. 4 MB baseline) while maintaining competitive accuracy
- Medium: Claims about per-layer Jacobian Regularization mechanism improving robustness are plausible but require further validation
- Medium: Defensive distillation effectiveness is demonstrated but shows inconsistent performance across attack types

## Next Checks
1. Verify per-layer Jacobian Regularization mechanism by comparing QKeras-trained STQ with post-training quantized baseline under identical attack conditions
2. Implement the exact heterogeneous quantization scheme by systematically varying bit-widths per layer and measuring accuracy/robustness tradeoffs
3. Test defensive distillation effectiveness by running comprehensive black-box attack suite (Square, Boundary, ZOO) against STQ-T1 vs. STQ-T50 variants