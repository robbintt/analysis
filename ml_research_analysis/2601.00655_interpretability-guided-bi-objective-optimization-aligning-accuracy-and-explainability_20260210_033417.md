---
ver: rpa2
title: 'Interpretability-Guided Bi-objective Optimization: Aligning Accuracy and Explainability'
arxiv_id: '2601.00655'
source_url: https://arxiv.org/abs/2601.00655
tags:
- igbo
- path
- training
- gradients
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: IGBO introduces a principled framework for training interpretable
  models by integrating structured domain knowledge through bi-objective optimization.
  The method encodes feature importance hierarchies as a Directed Acyclic Graph (DAG)
  and employs Temporal Integrated Gradients (TIG) to measure feature importance, addressing
  Out-of-Distribution (OOD) issues via an Optimal Path Oracle that generates data-manifold-aware
  integration paths.
---

# Interpretability-Guided Bi-objective Optimization: Aligning Accuracy and Explainability

## Quick Facts
- **arXiv ID:** 2601.00655
- **Source URL:** https://arxiv.org/abs/2601.00655
- **Reference count:** 26
- **Primary result:** Introduces IGBO framework integrating structured domain knowledge via bi-objective optimization, encoding feature importance hierarchies as DAG and using Temporal Integrated Gradients to measure importance while addressing OOD issues.

## Executive Summary
IGBO introduces a principled framework for training interpretable models by integrating structured domain knowledge through bi-objective optimization. The method encodes feature importance hierarchies as a Directed Acyclic Graph (DAG) and employs Temporal Integrated Gradients (TIG) to measure feature importance, addressing Out-of-Distribution (OOD) issues via an Optimal Path Oracle that generates data-manifold-aware integration paths. Theoretical analysis establishes convergence properties and robustness to gradient noise, while empirical results demonstrate IGBO's effectiveness in enforcing DAG constraints with minimal accuracy loss, outperforming standard regularization baselines on time-series data.

## Method Summary
IGBO trains sequential models (RNN/LSTM/Transformer) using bi-objective optimization to simultaneously minimize task loss and interpretability loss. The method computes feature importance via Temporal Integrated Gradients (TIG) along data-manifold-aware paths generated by an Optimal Path Oracle. A Directed Acyclic Graph encodes domain knowledge about feature importance hierarchies, with the interpretability loss enforcing these constraints through hinge penalties. The projection mapping P combines task and interpretability gradients geometrically, resolving conflicts when gradients oppose each other. The framework operates in phases: training a GAN discriminator, training the oracle to generate valid paths, constructing the DAG, and finally training the model with bi-objective optimization.

## Key Results
- Enforces DAG constraints with minimal accuracy loss on time-series data
- Outperforms standard regularization baselines in DAG satisfaction rate
- Addresses OOD issues in gradient attribution via manifold-aware path integration
- Theoretical analysis establishes convergence properties and robustness to gradient noise

## Why This Works (Mechanism)

### Mechanism 1: Geometric Gradient Projection for Bi-Objective Descent
The paper claims that using a geometric projection mapping $P$ allows simultaneous descent in both task loss and interpretability loss, even when their gradients conflict. The algorithm computes gradients for the primary task ($g_1$) and interpretability ($g_2$). If they conflict ($g_1 \cdot g_2 < 0$), it projects them onto their orthogonal components ($g_{2 \perp 1}, g_{1 \perp 2}$) to find a direction that reduces both losses. If aligned, it uses a convex combination. The method fails if gradients are exactly opposite, implying no simultaneous descent direction exists.

### Mechanism 2: Manifold-Aware Path Integration (TIG)
The paper claims that an Optimal Path Oracle improves the reliability of Temporal Integrated Gradients (TIG) by avoiding Out-of-Distribution (OOD) regions during integration. Instead of a straight line between input and baseline, a learned Recurrent Neural Network generates a piecewise-linear path constrained to stay on the data manifold. This is achieved by training the Oracle with a validity loss (using a frozen GAN discriminator) and a path shortness loss. Gradients computed "on-manifold" are more semantically meaningful and less noisy than those computed in untrained OOD regions.

### Mechanism 3: Structural Enforcement via DAG Constraints
The paper claims that encoding domain knowledge as a Directed Acyclic Graph (DAG) allows for the enforcement of relative feature importance hierarchies with minimal accuracy loss. It constructs an "Argument Satisfaction" score $H_k$ per feature. The interpretability loss is a sum of hinge penalties that activate if the difference in importance scores between connected nodes violates the edge direction. The DAG structure accurately reflects the "ground truth" causal or semantic hierarchy, and enforcing it acts as a beneficial regularizer rather than a harmful bias.

## Foundational Learning

- **Concept: Integrated Gradients (IG)**
  - **Why needed here:** IG is the mathematical foundation for the Temporal Integrated Gradients (TIG) used to calculate feature importance. Without understanding the baseline integral, the Oracle's purpose is unclear.
  - **Quick check question:** How does the choice of baseline affect the attribution score in standard Integrated Gradients?

- **Concept: Multi-Objective Optimization (MOO)**
  - **Why needed here:** IGBO formulates training as balancing two competing objectives (Accuracy vs. Interpretability). Understanding concepts like Pareto efficiency and gradient conflict is essential.
  - **Quick check question:** In MOO, what does it mean for two gradient vectors to be "conflicting," and why does a simple weighted sum fail in that case?

- **Concept: Manifold Hypothesis**
  - **Why needed here:** The Optimal Path Oracle relies on the idea that real data lies on a lower-dimensional manifold. This justifies why "straight line" paths traverse meaningless OOD space.
  - **Quick check question:** Why would a neural network's output behavior be unpredictable for inputs that are interpolated directly between two real data points?

## Architecture Onboarding

- **Component map:** Model $F_\theta$ -> Temporal Integrated Gradients -> Argument Satisfaction $H_k$ -> Interpretability Loss $H(\theta)$ -> Projection Unit $P$ -> Updated Model $F_\theta$
- **Critical path:**
  1. Train/Load GAN to get a robust Discriminator $D$
  2. Train Oracle $G$ using $D$ to find manifold-aware paths
  3. Construct DAG (automatically via CLT or manually)
  4. Train Model $F_\theta$ using the Projection Unit $P$ to balance standard loss and DAG-constrained TIG loss

- **Design tradeoffs:**
  - **Path Fidelity ($K$ vs $M$):** Increasing Oracle anchor points ($K$) increases path fidelity but raises compute cost per training step
  - **Trade-off Parameter ($\lambda$):** High $\lambda$ prioritizes accuracy; low $\lambda$ prioritizes interpretability constraints
  - **DAG Rigidity ($\epsilon, \delta$):** Tight intervals enforce strict hierarchies but may prevent the model from learning valid exceptions present in the data

- **Failure signatures:**
  - **Accuracy Collapse:** Training loss diverges or stalls; gradients for task and interpretability are persistently opposite
  - **Noisy Attribution:** TIG scores fluctuate wildly; Oracle fails to produce points with high $D$ scores
  - **Graph Violation:** Interpretability loss $H(\theta)$ remains high; model architecture is insufficient to satisfy DAG constraints without sacrificing task performance

- **First 3 experiments:**
  1. **Oracle Validation:** Visualize paths generated by $G$ vs. linear paths in latent space to verify they lie on the data manifold (e.g., by plotting $D(p_i)$ scores)
  2. **Gradient Conflict Analysis:** Plot the cosine similarity of $g_1$ (task) and $g_2$ (interpretability) over time to verify the Projection Unit is necessary and active
  3. **Ablation on DAG Strictness:** Train with varying margin parameters $[\epsilon, \delta]$ to chart the Pareto frontier of Accuracy vs. DAG Satisfaction rate

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the geometric update rule be generalized to optimize three or more objectives simultaneously (e.g., adding fairness or robustness to accuracy and interpretability)?
- **Basis in paper:** The authors state in Section VI that extending the geometric update principle to handle "three or more concurrent objectives" is a "challenging but promising direction."
- **Why unresolved:** The current projection mapping $P$ and the analysis of the "simultaneous descent" set $C_{SD}$ rely on a closed-form solution specific to the geometric relationship between two gradient vectors.
- **What evidence would resolve it:** A formal extension of the projection mapping theorems (V-B3, V-B4) to high-dimensional gradient subspaces or an algorithm demonstrating Pareto-stationarity for $n > 2$ objectives.

### Open Question 2
- **Question:** Can approximate attribution methods be developed to reduce the computational overhead of Temporal Integrated Gradients (TIG) while retaining differentiability and theoretical convergence guarantees?
- **Basis in paper:** Section VI identifies computational overhead as a limitation, noting that future work should investigate "efficient, approximate attribution methods that retain differentiability."
- **Why unresolved:** IGBO requires multiple gradient evaluations for the path integral, incurring a complexity of $O(M \cdot T \cdot F)$, which is significantly costlier than standard training.
- **What evidence would resolve it:** An approximation technique that lowers the time complexity (e.g., to $O(T \cdot F)$) while maintaining the noise robustness properties established in Theorem V-C1.

### Open Question 3
- **Question:** Can the interpretability DAG be constructed reliably using only pairwise comparisons from human domain experts, bypassing the need for gradient-based feature importance calculations?
- **Basis in paper:** Section VI suggests exploring the use of "pairwise comparison data from domain experts to construct the DAG, bypassing gradient computation entirely" for black-box scenarios.
- **Why unresolved:** The current methodology relies on CLT-based construction using $H_k(X, \theta)$, which requires backpropagation access; mapping discrete expert comparisons to the required interval constraints $[\epsilon, \delta]$ is undefined.
- **What evidence would resolve it:** A pipeline that translates human pairwise rankings into statistical edge weights and interval bounds that satisfy the acyclicity and transitivity conditions of Theorem V-A5.

## Limitations
- Effectiveness depends critically on the quality of DAG specification and Optimal Path Oracle training
- Theoretical convergence guarantees assume specific gradient landscape properties that may not hold in practice
- Computational overhead of TIG with manifold-aware paths is significant

## Confidence
- **High Confidence:** The geometric projection mechanism for handling conflicting gradients (Mechanism 1) is mathematically sound and well-specified in the algorithmic description
- **Medium Confidence:** The TIG computation with manifold-aware paths (Mechanism 2) is conceptually valid, but the empirical validation of the Oracle's effectiveness is limited
- **Medium Confidence:** The DAG constraint enforcement (Mechanism 3) provides a clear method for incorporating domain knowledge, but its practical impact depends heavily on the accuracy of the domain expertise encoded in the DAG

## Next Checks
1. **Oracle Path Quality:** Visualize and quantitatively assess the paths generated by the Optimal Path Oracle versus linear interpolation in latent space, measuring discriminator scores (D(p_i)) to verify manifold adherence
2. **Gradient Conflict Frequency:** Track the cosine similarity between task and interpretability gradients throughout training to determine how often the projection mechanism is activated and whether it effectively resolves conflicts
3. **DAG Sensitivity Analysis:** Systematically vary the margin parameters [ϵ, δ] in the DAG constraints and measure the resulting trade-off between DAG satisfaction rate and accuracy to map the Pareto frontier