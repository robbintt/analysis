---
ver: rpa2
title: 'TDHook: A Lightweight Framework for Interpretability'
arxiv_id: '2509.25475'
source_url: https://arxiv.org/abs/2509.25475
tags:
- methods
- attribution
- interpretability
- tdhook
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TDHook is a lightweight, generic interpretability framework designed
  for complex deep learning models. Built on torch and tensordict, it supports attribution,
  latent manipulation, and weights-based methods through a unified API.
---

# TDHook: A Lightweight Framework for Interpretability

## Quick Facts
- arXiv ID: 2509.25475
- Source URL: https://arxiv.org/abs/2509.25475
- Reference count: 40
- Key result: Up to 2x speed-up over captum for integrated gradients on multi-target pipelines

## Executive Summary
TDHook is a lightweight interpretability framework built on PyTorch and TensorDict that enables unified support for attribution, latent manipulation, and weights-based methods across complex deep learning models. The framework handles multi-input/output and composed models across domains like computer vision, NLP, and reinforcement learning. Through its unified API and composable pipelines, TDHook achieves significant performance improvements while requiring roughly half the disk space of comparable frameworks like transformer_lens.

## Method Summary
TDHook implements a hook-based architecture using PyTorch's hook mechanism combined with TensorDict data structures to create a unified interpretability framework. The system provides ready-to-use methods through context managers while also offering a flexible get-set API for custom interventions. Methods are implemented as TensorDictModules operating on structured tensor collections, enabling composition and chaining. The framework supports attribution methods like integrated gradients, latent manipulation techniques, and weights-based approaches through a consistent interface that works across arbitrary PyTorch models.

## Key Results
- Achieves up to 2x speed-up over captum for integrated gradients on multi-target pipelines
- Requires roughly 50% of the disk space compared to transformer_lens (383MB vs 739MB)
- Supports over 25 ready-to-use interpretability methods across multiple domains
- Successfully demonstrates concept attribution, attribution patching, and analysis of multi-output models

## Why This Works (Mechanism)

### Mechanism 1: Unified TensorDict Artifact Stream
Standardizing interpretability outputs as TensorDict objects enables method composition. Interpretability artifacts are structured into key-value tensor collections, allowing methods to consume or produce these artifacts as TensorDictModule instances. This allows chaining where one method's output becomes another's input, facilitating multi-step pipelines like concept attribution.

### Mechanism 2: Context-Managed Hook Registration
Context managers provide a clean and safe mechanism for temporary model instrumentation. A HookedModel wrapper or context factory registers torch hooks on model modules upon entering a with block, capturing or altering data during the forward pass. Hooks are automatically removed upon exit, restoring the original model state.

### Mechanism 3: Proxy-Based Get-Set API for Interventions
The get-set API allows declarative definition of interventions separate from execution. Users define intervention logic using .get() and .set() methods inside a run context, which return proxy objects representing future values. The context defers actual execution until exit, optimizing hook placement and data flow, with the intervention applied in a single forward pass.

## Foundational Learning

- **PyTorch Hooks**: Understanding how to attach functions to module forward/backward passes to capture inputs/outputs is essential for TDHook's hook-based architecture.
  - Quick check: Can you write a small script that attaches a forward hook to a simple nn.Linear layer to print the shape of its output during a forward pass?

- **tensordict library**: TDHook's architecture is built around tensordict for managing data and composing methods.
  - Quick check: What is the primary benefit of using a TensorDict over a standard Python dictionary for managing tensors with batch dimensions?

- **Context Managers**: The framework relies heavily on context managers for resource management (hook registration/removal).
  - Quick check: What happens if an error occurs inside a with block that is managing hooks? How does a context manager help?

## Architecture Onboarding

- **Component map**: User instantiates method class → calls .prepare(model) → enters context with HookingContext → gets hooked_model → runs forward pass → retrieves artifacts from output TensorDict
- **Critical path**: 1) Instantiate method class (e.g., Saliency(multiply_by_inputs=True)) 2) Call .prepare(model) to get HookingContext 3) Enter context with statement to get hooked_model 4) Pass TensorDict inputs to hooked_model 5) Retrieve artifacts from output TensorDict using keys like ("attr", "input_name")
- **Design tradeoffs**: Generality vs. specialization (generic Any Torch compatibility vs. domain-specific optimizations); ease of use vs. flexibility (ready-to-use methods vs. flexible get-set API requiring more user code)
- **Failure signatures**: Attribution/artifact not found (incorrect key retrieval); performance degradation (not using TensorDict for multi-input models); incompatible model structure (highly unusual forward pass structures)
- **First 3 experiments**: 1) Basic Saliency: Compute saliency map for single image using pre-trained model from timm 2) Multi-Input Intervention: Create two-input model, get activation from one stream and set as input to another 3) Comparative Benchmark: Replicate integrated gradients experiment from Captum documentation using TDHook

## Open Questions the Paper Calls Out

- Can TDHook effectively scale to distributed, multi-GPU training environments? The current architecture is optimized for single-node efficiency; extending it to distributed systems requires complex state synchronization and hook management across devices.
- To what extent can memory-mapped tensors reduce peak RAM usage in large-scale analyses? While the underlying library supports these features, it's unclear if hooking mechanism overhead negates memory benefits during gradient computation or activation caching.
- How do the implemented concept attribution methods perform on localization or robustness metrics? The paper evaluates concept attribution primarily using pixel-flipping and relative concept drop, leaving performance on standard localization benchmarks unverified.

## Limitations
- Performance claims rely on undisclosed benchmark configurations regarding batch sizes, model variants, and specific implementations
- Practical compatibility with highly specialized model architectures remains untested despite theoretical generality
- Dependency on torch and tensordict creates coupling risks if either library's hook API changes significantly

## Confidence
- High confidence: The unified TensorDict artifact stream mechanism and context-managed hook registration are well-supported by code examples and align with standard PyTorch patterns
- Medium confidence: The proxy-based get-set API is described clearly but lacks external validation through comparison with established intervention frameworks
- Medium confidence: Performance claims are based on undisclosed benchmark configurations, making independent verification difficult

## Next Checks
1. Replicate the integrated gradients benchmark using Captum's official example, implementing the same method in TDHook with identical model and inputs, measuring both runtime and memory usage
2. Test the get-set API intervention pattern on a simple two-stream model, attempting to get an intermediate activation from one stream and set it as input to another, verifying the intervention propagates correctly
3. Chain two interpretability methods (e.g., attribution followed by concept attribution) using TensorDict outputs, confirming that the composed pipeline produces expected results and that artifacts flow correctly between methods