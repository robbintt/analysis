---
ver: rpa2
title: Automated scientific minimization of regret
arxiv_id: '2505.17661'
source_url: https://arxiv.org/abs/2505.17661
tags:
- option
- cognitive
- value
- asmr
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Automated Scientific Minimization of Regret
  (ASMR), a framework that uses foundation models of human cognition to automate cognitive
  modeling. ASMR identifies gaps in interpretable models by comparing them to Centaur,
  a predictive model of human behavior, and iteratively refines the models using reasoning
  models like Qwen3-32B.
---

# Automated scientific minimization of regret
## Quick Facts
- arXiv ID: 2505.17661
- Source URL: https://arxiv.org/abs/2505.17661
- Authors: Marcel Binz; Akshay K. Jagadish; Milena Rmus; Eric Schulz
- Reference count: 5
- Key outcome: ASMR discovers interpretable cognitive models matching predictive accuracy of black-box models

## Executive Summary
The paper introduces Automated Scientific Minimization of Regret (ASMR), a framework that uses foundation models of human cognition to automate cognitive modeling. ASMR identifies gaps in interpretable models by comparing them to Centaur, a predictive model of human behavior, and iteratively refines the models using reasoning models like Qwen3-32B. Applied to a multi-attribute decision-making task, ASMR discovered models that matched Centaur's predictive accuracy while remaining interpretable.

The framework demonstrates the potential for automating core components of cognitive modeling, reducing reliance on manual analysis. The best-performing model achieved an AIC of 71.73, slightly better than Centaur's 72.5. ASMR consistently improved model performance across participants, with discovered models exhibiting adaptive weighting strategies. Future work may explore different feedback signals and larger-scale benchmarks to further validate the approach.

## Method Summary
ASMR uses a two-stage process where interpretable cognitive models are first compared against a high-performing but non-interpretable baseline (Centaur), then refined through automated reasoning about performance gaps. The framework employs Qwen3-32B as the reasoning model to analyze discrepancies and suggest model modifications. The iterative refinement process continues until performance improvements plateau or interpretability constraints are violated. The approach was validated on a multi-attribute decision-making task where participants made choices based on various attribute combinations.

## Key Results
- Discovered models achieved AIC of 71.73, slightly better than Centaur's 72.5
- ASMR consistently improved model performance across all participants
- Models exhibited adaptive weighting strategies that varied with task context

## Why This Works (Mechanism)
ASMR leverages foundation models' ability to reason about model performance gaps and generate interpretable modifications. The framework creates a feedback loop where predictive accuracy drives model refinement while maintaining interpretability constraints. By comparing interpretable models against a strong baseline, ASMR identifies specific weaknesses and systematically addresses them through automated reasoning.

## Foundational Learning
- Cognitive modeling fundamentals: Why needed - Understanding the core challenge of balancing interpretability with predictive accuracy. Quick check - Can you explain the tradeoff between interpretable and black-box models?
- Model comparison metrics (AIC): Why needed - Essential for evaluating model quality while accounting for complexity. Quick check - Can you calculate and interpret AIC for competing models?
- Foundation model reasoning capabilities: Why needed - Critical for understanding how Qwen3-32B can analyze and improve cognitive models. Quick check - Can you describe how reasoning models differ from standard language models?

## Architecture Onboarding
Component map: Human data -> Centaur baseline -> Interpretable initial model -> Qwen3-32B analysis -> Model refinement -> Final interpretable model

Critical path: The iterative refinement loop where Qwen3-32B analyzes performance gaps between interpretable models and Centaur, then suggests modifications that maintain interpretability while improving accuracy.

Design tradeoffs: Balancing model complexity with interpretability constraints, computational cost of multiple refinement iterations versus manual modeling effort, and the reliability of automated reasoning versus human expertise.

Failure signatures: Poor initial interpretable models may limit refinement potential, Qwen3-32B may generate non-interpretable suggestions, performance improvements may plateau prematurely, and the framework may overfit to specific task characteristics.

First experiments:
1. Run ASMR with different initial interpretable models to test sensitivity to starting points
2. Vary the number of refinement iterations to find optimal stopping criteria
3. Test with different foundation models (beyond Qwen3-32B) to assess generalizability

## Open Questions the Paper Calls Out
None provided in the source material.

## Limitations
- Framework relies heavily on specific foundation models, raising generalizability concerns
- Validation limited to single multi-attribute decision-making task
- Marginal AIC improvement (71.73 vs 72.5) may not justify widespread adoption
- Interpretability claims require further validation with human cognitive scientists

## Confidence
- High confidence in ASMR's ability to automate cognitive modeling components
- Medium confidence in generalizability to other cognitive tasks
- Medium confidence in actual cognitive interpretability of discovered models
- Low confidence in practical significance of marginal performance improvements

## Next Checks
1. Test ASMR across multiple cognitive modeling tasks (e.g., memory tasks, reinforcement learning paradigms) to assess generalizability
2. Conduct human interpretability studies where cognitive scientists evaluate whether discovered models provide genuine insights versus being merely technically interpretable
3. Benchmark against alternative automated modeling approaches and assess computational efficiency relative to manual modeling time savings