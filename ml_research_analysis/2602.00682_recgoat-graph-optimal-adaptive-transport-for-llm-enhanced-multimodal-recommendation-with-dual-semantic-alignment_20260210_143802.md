---
ver: rpa2
title: 'RecGOAT: Graph Optimal Adaptive Transport for LLM-Enhanced Multimodal Recommendation
  with Dual Semantic Alignment'
arxiv_id: '2602.00682'
source_url: https://arxiv.org/abs/2602.00682
tags:
- alignment
- recommendation
- multimodal
- item
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces RecGOAT, a dual semantic alignment framework
  for LLM-enhanced multimodal recommendation. The key innovation is addressing the
  semantic heterogeneity between large model representations and traditional ID-based
  recommendation features by using graph attention networks for collaborative signal
  enrichment and a dual-granularity alignment strategy combining instance-level contrastive
  learning and distribution-level optimal adaptive transport.
---

# RecGOAT: Graph Optimal Adaptive Transport for LLM-Enhanced Multimodal Recommendation with Dual Semantic Alignment

## Quick Facts
- arXiv ID: 2602.00682
- Source URL: https://arxiv.org/abs/2602.00682
- Reference count: 40
- Primary result: Up to 8.84% improvement in NDCG@10 and 4.63% in Recall@10 over state-of-the-art multimodal recommendation methods on Amazon datasets.

## Executive Summary
This paper introduces RecGOAT, a dual semantic alignment framework for LLM-enhanced multimodal recommendation. The key innovation addresses semantic heterogeneity between large model representations and traditional ID-based recommendation features through graph attention networks for collaborative signal enrichment and a dual-granularity alignment strategy combining instance-level contrastive learning and distribution-level optimal adaptive transport. The framework achieves state-of-the-art performance on three Amazon datasets while demonstrating industrial scalability through A/B testing on a large-scale advertising platform.

## Method Summary
RecGOAT employs LLM encoders (Qwen3-Embedding-8B for text, LLaVA-1.5-7B for visual, QwQ-32B for user reasoning) to generate initial item and user representations. These features are enriched through multi-relational graph propagation using GAT and LightGCN. The dual-granularity alignment module performs instance-level alignment via cross-modal contrastive learning (InfoNCE) and distribution-level alignment via optimal adaptive transport (OAT) with learnable residual matrices. Aligned representations are fused through weighted averaging and optimized with BPR loss for recommendation.

## Key Results
- Achieves up to 8.84% improvement in NDCG@10 and 4.63% in Recall@10 compared to existing methods on Amazon datasets
- Outperforms state-of-the-art baselines including MMT, UCCS, and LLaVA4Rec
- Demonstrates industrial applicability through A/B testing on large-scale online advertising platform
- Theoretical analysis shows unified representations achieve lower target error than any individual modality, bounded by Wasserstein distance and InfoNCE loss

## Why This Works (Mechanism)

### Mechanism 1: Dual-Granularity Semantic Alignment
Combining instance-level contrastive learning with distribution-level optimal transport resolves semantic heterogeneity more effectively than either approach alone. Instance-level alignment uses InfoNCE loss to pull together representations of the same item across modalities while pushing apart different items. Distribution-level alignment minimizes 1-Wasserstein distance between LLM-enhanced modal distributions and ID embedding distributions with a learnable residual matrix. The unified representation is formed via weighted fusion.

### Mechanism 2: Graph-Enhanced Collaborative Signal Propagation
Multi-relational graph structures with attention-based propagation capture high-order collaborative signals that single-modality representations miss. Three graph types are constructed: item-item multimodal graphs via KNN on LM features with GAT propagation, user-item interaction graph with LightGCN-style message passing incorporating rating attention, and user-user textual graph from LLM-inferred preferences. Multi-head attention aggregates neighborhood information with learned weights.

### Mechanism 3: LM-Enhanced Feature Initialization with User Reasoning
Large model-derived representations provide semantically rich initializations that enable better alignment than randomly initialized or simply aggregated features. Text embeddings from Qwen3-Embedding-8B, visual features from LLaVA-1.5-7B, and user preference profiles from QwQ-32B via structured behavioral prompts. The prompt design extracts multi-dimensional preference reasoning from interaction history.

## Foundational Learning

- **Concept: Optimal Transport and Wasserstein Distance**
  - Why needed here: Core mathematical foundation for OAT component; understanding why Wasserstein outperforms KL divergence is essential for debugging alignment failures.
  - Quick check question: Why would aligning "red" to "purple" incur a lower Wasserstein cost than aligning "red" to "indoor item," but similar KL cost?

- **Concept: Contrastive Learning (InfoNCE)**
  - Why needed here: Foundation of CMCL; determines how positive/negative pairs are formed across modalities.
  - Quick check question: In cross-modal contrastive learning, what makes (ID, text) for item i a positive pair, and what serves as negatives?

- **Concept: Graph Attention Networks**
  - Why needed here: Used across all three graph constructions; understanding multi-head attention aggregation is critical for debugging graph quality.
  - Quick check question: How does GAT differ from standard GCN in weighting neighbor contributions?

## Architecture Onboarding

- **Component map**: LM Encoders → Graph Module → Alignment Module → Fusion Module → Recommendation Head
- **Critical path**: LM feature extraction → Graph construction (KNN, K=per-modality) → Graph propagation → CMCL alignment → OAT alignment → Weighted fusion → BPR optimization
- **Design tradeoffs**: Frozen KNN graphs vs. learnable adjacency (chose frozen for efficiency), Wasserstein vs. KL divergence (chose Wasserstein for geometric sensitivity), separate vs. shared alignment parameters per modality (chose separate)
- **Failure signatures**: Performance worse than ID-only baseline → check alignment components, NaN losses during training → check Sinkhorn numerical stability, uniform attention weights → check GAT initialization, degenerate contrastive representations → check temperature and batch size
- **First 3 experiments**:
  1. Ablation study: Run LightGCN (ID-only), naive fusion (concat/sum), CMCL-only, OAT-only, and full RecGOAT on one dataset to quantify contribution of each alignment component
  2. Weight sensitivity analysis: Vary γ_t and γ_v across [0.1, 0.9] grid to validate alignment consistency claim
  3. Single modality vs. fusion comparison: Compare recommendation performance using only aligned text, only aligned visual, only ID, vs. fused representation to validate comprehensiveness guarantee

## Open Questions the Paper Calls Out
- Can the dual semantic alignment framework be effectively extended to omni-modal recommendation models?
- How do multiple optimal transport alignments interact, and does mutual interference exist?
- Does freezing the item-item graph structure restrict the model's adaptability to evolving user preferences?

## Limitations
- Scalability and generalizability beyond three Amazon datasets tested remains uncertain
- Industrial applicability claim supported only by A/B testing without detailed results disclosure
- Theoretical bounds on unified representation error rely on idealized conditions that may not hold in more heterogeneous or sparse recommendation scenarios

## Confidence
- Dual-granularity alignment mechanism: High (strong mathematical formulation and ablation evidence)
- Graph-enhanced collaborative signal claim: Medium (sound methodology but limited exploration across graph topologies)
- LM-enhanced initialization effectiveness: Medium (clear theoretical motivation but untested robustness across domains)

## Next Checks
1. Cross-domain robustness test: Evaluate RecGOAT on non-Amazon datasets (e.g., MovieLens with external text reviews, or Pinterest image data)
2. Sinkhorn stability analysis: Systematically vary the regularization parameter λ and scaling factor s to determine sensitivity to numerical precision
3. Human evaluation of semantic alignment: Conduct user studies comparing aligned representations against original LLM features to verify semantic preservation