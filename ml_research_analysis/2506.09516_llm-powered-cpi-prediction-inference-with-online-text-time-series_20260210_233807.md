---
ver: rpa2
title: LLM-Powered CPI Prediction Inference with Online Text Time Series
arxiv_id: '2506.09516'
source_url: https://arxiv.org/abs/2506.09516
tags:
- prediction
- inflation
- llm-cpi
- property
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of forecasting the Consumer
  Price Index (CPI) using high-frequency online text data. The authors propose LLM-CPI,
  a method that integrates large language models (LLMs) with traditional time series
  models.
---

# LLM-Powered CPI Prediction Inference with Online Text Time Series

## Quick Facts
- **arXiv ID:** 2506.09516
- **Source URL:** https://arxiv.org/abs/2506.09516
- **Reference count:** 40
- **Primary result:** LLM-CPI integrates ChatGPT and BERT models to forecast monthly CPI using daily social media inflation indices, outperforming traditional models in rPMSE and rSign while maintaining nominal coverage with narrower prediction intervals.

## Executive Summary
This paper introduces LLM-CPI, a method that leverages large language models to forecast the Consumer Price Index (CPI) using high-frequency social media text. The approach constructs a daily inflation index from Weibo posts using fine-tuned BERT models and ChatGPT annotations, then integrates this surrogate with monthly CPI data through a joint ARX-VARX time series framework. The model exploits error correlation between monthly and daily series to reduce prediction variance, providing both accurate point forecasts and tight prediction intervals. Empirical results demonstrate superior performance over traditional ARX models while maintaining proper coverage rates.

## Method Summary
LLM-CPI employs a hierarchical text processing pipeline to filter and score inflation-related social media posts, creating a daily inflation index. This index is smoothed into three ten-day periods per month and used as a high-frequency surrogate in a VARX model. The monthly CPI is modeled using an ARX structure with exogenous variables. The key innovation is linking these models through joint error correlation, allowing the daily surrogate to inform monthly predictions. The framework estimates parameters in two steps and provides prediction intervals via Box-Jenkins methodology, with bootstrap alternatives available for robustness.

## Key Results
- LLM-CPI achieves rPMSE of 0.442 versus 0.508 for standard ARX model
- Sign prediction error (rSign) improves from 0.171 to 0.096
- Prediction intervals maintain nominal 95% coverage with average length of 3.254 versus 4.159 for AR model
- The method demonstrates effectiveness of high-frequency text data for low-frequency economic forecasting

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Noise Filtering and Surrogate Construction
LLMs act as semantic filters to convert noisy social media text into a structured daily inflation index that correlates with official CPI. The three-stage framework uses Advertisement-BERT to filter commercial noise, Category-BERT to isolate inflation-related posts, and CPI-BERT to assign continuous inflation scores. These scores are aggregated into a daily index serving as a high-frequency proxy for monthly CPI.

### Mechanism 2: Variance Reduction via Error Correlation
Joint modeling reduces prediction error variance by linking the errors of ARX (monthly CPI) and VARX (daily index) models through their cross-covariance. The target error is decomposed into portions explained by the surrogate error and orthogonal residuals, with efficiency gains proportional to the error correlation squared.

### Mechanism 3: Time-bridging via Interval Aggregation
Daily LLM-generated indices are smoothed into three ten-day periods per month to bridge the frequency gap with monthly CPI. This VARX(3) structure captures intra-month trends that monthly CPI smooths over, providing early warning signals for the monthly ARX model through error correlation linking.

## Foundational Learning

- **Autoregressive Models with Exogenous Variables (ARX/VARX):** Essential for understanding the mathematical architecture. Quick check: If lag order $q_1$ is too high relative to sample size $T$, what happens to estimator variance? (Answer: Increases/degrades).

- **Joint Normal Distribution and Covariance Decomposition:** Critical for understanding how conditioning one normal variable on another works in the error correlation mechanism. Quick check: If two variables are jointly normal, does a linear combination follow a normal distribution? (Answer: Yes).

- **Text Embeddings (LDA vs. BERT):** Required for mapping unstructured text to numerical vectors. Quick check: LDA provides interpretable topic distributions while BERT provides dense contextual vectors. Which captures nuance better but requires more data to train? (Answer: BERT).

## Architecture Onboarding

- **Component map:** Weibo Text → Annotator (ChatGPT few-shot) → Filter (Fine-tuned BERTs) → LDA/BERT Extractors → Model Selector → Selected Embeddings → Joint Model Layer (VARX for surrogate, ARX for CPI) → Fusion Layer (Joint Error Correlation)

- **Critical path:** Prediction interval validity depends entirely on accurate residual covariance estimation. Small sample sizes (< 30 months) may violate eigenvalue bounds, causing interval failure.

- **Design tradeoffs:** LDA embeddings worked well independently while BERT embeddings required the joint model to perform well. This suggests the joint model stabilizes high-dimensional embeddings. Box-Jenkins intervals are faster but assume normality; bootstrap intervals are more robust but computationally heavier.

- **Failure signatures:** Sign inversion occurs if coefficient vector has opposite sign to correlation. Coverage collapse below 90% indicates violated stationarity or error independence assumptions.

- **First 3 experiments:**
  1. Residual Correlation Check: Fit models separately and verify elliptical-shaped residual density plots indicating correlation.
  2. Correlation Sensitivity Simulation: Vary $\rho$ from 0.1 to 0.9 and confirm rPMSE decreases strictly as correlation increases.
  3. Ablation on Frequency: Compare 3-period model against monthly average (K=1) to quantify intra-month granularity value.

## Open Questions the Paper Calls Out

- **Different LLM tools:** How would incorporating inflation labels from different LLM tools (beyond ChatGPT and BERT) affect the joint model's performance? This remains unexplored as the current framework uses only ChatGPT for annotation.

- **General time series models:** Can more general models with sparsity and latent factor structures improve upon the ARX/VARX framework? The paper suggests exploring models beyond the current parametric structures.

- **Small-sample prediction bias:** How can small-sample prediction bias in the LLM-CPI framework be corrected? The paper acknowledges this issue but leaves detailed exploration for future work.

## Limitations

- The framework relies heavily on the validity of error correlation structure between monthly CPI and LLM-generated daily index
- Empirical validation is limited to a single country's CPI with only 16 months of out-of-sample data
- BERT fine-tuning was trained on a relatively small sample (1.5k posts), raising concerns about generalizability to evolving internet language
- Robustness to structural breaks and sudden economic shocks remains untested

## Confidence

- **High Confidence:** Theoretical derivation of efficiency gain from correlated errors and mathematical formulation of joint ARX-VARX model
- **Medium Confidence:** Empirical results showing improved rPMSE and rSign over baselines, though limited to single country and short out-of-sample period
- **Low Confidence:** Absolute effectiveness of hierarchical BERT fine-tuning pipeline due to lack of direct quantification of surrogate's correlation with actual CPI

## Next Checks

1. **Residual Correlation Validation:** Extract residuals from both ARX and VARX models and compute empirical correlation coefficient $\rho$. If $\rho < 0.3$, the method's claimed improvements are likely invalid.

2. **Temporal Robustness Check:** Split data into pre-2021 and post-2021 periods, retrain model on each, and compare rPMSE and prediction interval coverage. Significant performance drop in later period indicates model degradation.

3. **Cross-Country Generalization:** Apply LLM-CPI framework to CPI data from another country (e.g., US or Japan) using same fine-tuning prompts and BERT models to assess generalizability across economic contexts.