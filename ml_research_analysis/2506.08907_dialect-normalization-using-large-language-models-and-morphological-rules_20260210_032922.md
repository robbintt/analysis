---
ver: rpa2
title: Dialect Normalization using Large Language Models and Morphological Rules
arxiv_id: '2506.08907'
source_url: https://arxiv.org/abs/2506.08907
tags:
- data
- greek
- thrace
- dialectal
- standard
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a dialect-to-standard normalization method
  for Greek dialects that combines rule-based linguistic transformations with large
  language models (LLMs) using targeted few-shot prompting. The method applies morphological
  rules to preprocess dialectal text, then uses GPT-4o or Llama 3.1-70B with dialect-specific
  examples to produce normalized output.
---

# Dialect Normalization using Large Language Models and Morphological Rules

## Quick Facts
- arXiv ID: 2506.08907
- Source URL: https://arxiv.org/abs/2506.08907
- Reference count: 40
- Method achieves human evaluation scores of 4.68/5 (form) and 4.62/5 (meaning) for dialect-to-standard Greek normalization

## Executive Summary
This paper introduces a hybrid method for dialect-to-standard text normalization that combines rule-based morphological transformations with large language models (LLMs) using targeted few-shot prompting. The approach preprocesses dialectal Greek text through 14 dialect-specific string replacement rules that handle systematic phonological variations, then uses GPT-4o with 3 dialect-specific examples to normalize remaining facultative features. Human evaluation demonstrates high-quality output (4.68/5 form, 4.62/5 meaning), while downstream geolocation experiments show that normalization reduces performance from F1=0.33 to F1=0.13, confirming that previous results relied on orthographic artifacts rather than semantic content.

## Method Summary
The method implements a two-stage pipeline: (1) Rule-Based Normalization (RBN) applies 14 dialect-specific string replacement rules per dialect group (Northern, Southern, Pontic) to handle obligatory phonological transformations; (2) Few-shot prompting uses GPT-4o or Llama 3.1-70B with 3 dialect-specific examples, region name, and explicit instructions to preserve style and vocabulary. The approach eliminates the need for parallel training data by leveraging LLMs' pre-training and few-shot learning capabilities. RBN targets predictable phonological changes while LLMs handle facultative features and rare vocabulary through example-based generalization.

## Key Results
- GPT-4o with full pipeline achieves 4.68/5 form and 4.62/5 meaning scores on human evaluation
- Annotators preferred GPT-4o output 90% of the time over alternatives
- Downstream geolocation accuracy drops from F1=0.33 to F1=0.13 after normalization
- K-means clustering produces more meaningful geographic groupings with normalized data

## Why This Works (Mechanism)

### Mechanism 1
Rule-based preprocessing handles systematic phonological transformations that LLMs may misinterpret as semantic differences. String replacement rules convert predictable dialectal patterns before LLM inference, reducing ambiguity in the few-shot stage. This works because systematic phonological changes are reversible through pattern matching without contextual ambiguity.

### Mechanism 2
Few-shot prompting with dialect-specific examples enables the LLM to handle facultative features unaddressable by deterministic rules. The prompt provides region name, explicit instructions to preserve style and avoid over-formalization, lexical preservation guidance, and 3 examples displaying non-rule-encodable features per dialect group. This works because LLMs generalize from 3 examples to handle similar facultative patterns in novel inputs.

### Mechanism 3
Normalization acts as a diagnostic: downstream performance drop indicates reliance on superficial linguistic features rather than semantics. Removing orthographic artifacts and dialectal markers via normalization isolates semantic content; if geolocation accuracy drops (F1: 0.33→0.13), original predictions exploited linguistic surface features. This works because dialectal features and semantic content can be meaningfully separated.

## Foundational Learning

- **Concept: Dialect-to-Standard Normalization**
  - Why needed here: This is the core task—transforming dialectal text so standard-language NLU tools can process it.
  - Quick check question: Can you distinguish phonological variation (systematic sound changes) from lexical variation (different word choices)?

- **Concept: Few-Shot Prompting**
  - Why needed here: The method relies on 3 examples per dialect group to guide the LLM without parallel training data.
  - Quick check question: Why might including the region name in the prompt help if the LLM was pretrained on diverse text?

- **Concept: Obligatory vs. Facultative Linguistic Features**
  - Why needed here: Rules target obligatory features (predictable); LLM handles facultative ones (context-dependent, speaker-optional).
  - Quick check question: If a phonological rule applies 80% of the time in a dialect, is it safe to apply it deterministically during normalization?

## Architecture Onboarding

- **Component map:**
  Input text → Dialect group lookup (by source region) → RBN (14 rules, group-specific) → Prompt construction (region + instructions + 3 examples) → LLM (GPT-4o or Llama 3.1-70B) → Normalized output

- **Critical path:**
  1. Correct dialect group assignment (Northern/Southern/Pontic) determines which RBN rules apply.
  2. RBN must handle predictable patterns before LLM sees them (prevents misinterpretation).
  3. Prompt must include style/lexical preservation instructions or LLM over-formalizes.

- **Design tradeoffs:**
  - **RBN vs. LLM-only:** GPT 3s+RBN scores 4.68/5 (form), 4.62/5 (meaning); GPT 3s alone scores 4.46/5, 4.26/5. RBN adds minimal overhead but requires linguistic expertise.
  - **Model selection:** GPT-4o outperforms Llama 3.1-70B substantially (Llama 3s+RBN: 3.1/5, 3.0/5); cost vs. quality tradeoff.
  - **Shot count:** Paper uses 3 shots; Llama 9s (9 shots without dialect grouping) performs worst (2.52/5, 2.34/5), suggesting dialect-specific grouping matters more than example quantity.

- **Failure signatures:**
  - Rare dialectal vocabulary without standard cognates—annotators report this as main failure case.
  - Incorrect dialect group assignment leads to wrong RBN rules.
  - Over-formalization if style instructions omitted.

- **First 3 experiments:**
  1. **Ablation study:** Run GPT-4o with RBN vs. without RBN on 50 samples; compare form/meaning scores to quantify RBN contribution.
  2. **Error analysis:** Identify sentences where meaning score <3; categorize failures (lexical gaps, ambiguous phonology, other).
  3. **Dialect group validation:** Test whether misassigning dialect groups (e.g., applying Northern rules to Southern text) degrades performance measurably.

## Open Questions the Paper Calls Out

### Open Question 1
Would incorporating comprehensive dictionaries of dialectal terms without standard cognates significantly improve normalization quality for low-resource dialects? The authors identify vocabulary without clear cognates as "the main failure case currently complicating automatic processing for these dialects" and suggest creating comprehensive dictionaries as future work.

### Open Question 2
How well does the combined rule-based and LLM approach generalize to dialects of other languages beyond Greek? The method is implemented only for Greek dialects using 14 language-specific string replacement rules derived from comparative grammar, and generalization to other language families remains untested.

### Open Question 3
Does the method preserve meaningful semantic distinctions when normalizing longer, syntactically complex texts compared to short proverbs? The evaluation uses only proverbs, which are typically short, formulaic expressions, while longer narrative or conversational texts may contain more context-dependent dialectal meanings.

## Limitations
- Rule set completeness: Only one illustrative example per dialect group provided; full rule specifications require accessing released code
- Lexical coverage gaps: Cannot handle rare dialectal vocabulary lacking standard cognates, affecting approximately 20% of cases
- Model dependency: Results heavily depend on high-quality LLMs, with significant performance differences between GPT-4o and Llama 3.1-70B

## Confidence

**High Confidence**:
- GPT-4o with full pipeline achieves high human evaluation scores (4.68/5 form, 4.62/5 meaning)
- Downstream geolocation accuracy drops from F1=0.33 to F1=0.13 after normalization
- Rule-based preprocessing provides measurable benefit over LLM-only approaches

**Medium Confidence**:
- Dialect grouping (Northern/Southern/Pontic) is optimal for Greek
- 3-shot prompting is sufficient for the task
- The mechanism of separating phonological from facultative features is correctly identified

**Low Confidence**:
- Results generalize to other language families
- The approach scales to more than three dialect groups
- Similar performance can be achieved with open-source LLMs of comparable size

## Next Checks
1. **Ablation study**: Run GPT-4o with RBN vs. without RBN on 50 samples; compare form/meaning scores to quantify RBN contribution and test the mechanism that systematic phonological changes require preprocessing.

2. **Error analysis protocol**: Identify sentences where meaning score <3; categorize failures into lexical gaps, ambiguous phonology, and other categories to validate the facultative vs. obligatory feature distinction.

3. **Dialect group validation**: Test whether misassigning dialect groups (applying Northern rules to Southern text) degrades performance measurably, confirming the critical path dependency on correct dialect classification.