---
ver: rpa2
title: Contrastive Self-Supervised Network Intrusion Detection using Augmented Negative
  Pairs
arxiv_id: '2509.06550'
source_url: https://arxiv.org/abs/2509.06550
tags:
- learning
- benign
- detection
- traffic
- clan
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces CLAN (Contrastive Learning using Augmented
  Negative pairs), a novel self-supervised learning approach for network intrusion
  detection that treats augmented samples as negative pairs instead of positive pairs.
  This contrasts with existing methods and enables learning a single cohesive distribution
  of benign traffic rather than distinct distributions for each sample.
---

# Contrastive Self-Supervised Network Intrusion Detection using Augmented Negative Pairs

## Quick Facts
- arXiv ID: 2509.06550
- Source URL: https://arxiv.org/abs/2509.06550
- Authors: Jack Wilkie; Hanan Hindy; Christos Tachtatzis; Robert Atkinson
- Reference count: 40
- Primary result: CLAN achieves 0.031370 AUROC improvement over leading SSL approaches and 0.056484 over anomaly detection methods on Lycos2017 dataset

## Executive Summary
This paper introduces CLAN (Contrastive Learning using Augmented Negative pairs), a novel self-supervised learning approach for network intrusion detection that inverts the standard contrastive learning paradigm. Instead of treating augmented views of the same sample as positive pairs, CLAN treats them as negative pairs, forcing the model to learn a single cohesive distribution of benign traffic rather than distinct distributions for each sample. This approach enables both binary anomaly detection and multi-class classification with improved accuracy and computational efficiency compared to existing methods.

## Method Summary
CLAN uses a modified MLP encoder with a contrastive loss that treats other batch samples as positives and augmented views of batch samples as negatives, with a hinge margin. The augmentation strategy randomly resamples features within a range [-b, b] to create surrogate malicious distributions. During inference, the model computes a single centroid of the benign latent representations and classifies samples based on their distance to this centroid, achieving O(1) complexity compared to O(N) for existing approaches. The method is evaluated on the Lycos2017 dataset with benign-only pretraining for binary classification and optional fine-tuning for multi-class classification.

## Key Results
- Binary classification AUROC improvement of 0.031370 over leading SSL approaches
- Binary classification AUROC improvement of 0.056484 over anomaly detection methods
- Multi-class classification outperforms existing SSL models across various training set sizes (except marginally on 256 samples per class where BYOL outperforms)
- Computational efficiency advantage with O(1) inference complexity versus O(Ntrain) for existing methods

## Why This Works (Mechanism)

### Mechanism 1: Inverted Contrastive Signal
Standard contrastive learning pulls augmented views closer to their source (instance-level invariance). CLAN inverts this by pushing augmented views away while pulling other benign samples closer, optimizing the latent space to cluster benign traffic into one Gaussian-like blob and pushing augmentations to the periphery. This forces learning of a single cohesive distribution rather than instance-specific features.

### Mechanism 2: Surrogate Malicious Distribution
The augmentation strategy (uniform feature resampling) acts as a proxy for unknown malicious traffic during training. By destroying statistical correlations typical of benign traffic, the model learns to distinguish structured benign traffic from unstructured or out-of-distribution inputs, effectively learning a boundary between benign and "surrogate malicious" distributions.

### Mechanism 3: Fixed-Centroid Inference
Modeling benign traffic as a homoscedastic Gaussian distribution allows for O(1) inference complexity by caching a single centroid. Instead of comparing test samples against the entire training database (O(N) complexity), the model computes distance to a pre-computed mean vector of the benign latent space, trading potential accuracy for massive speed gains.

## Foundational Learning

- **Concept: Contrastive Learning (SimCLR/InfoNCE)**
  - Why needed here: Understanding the standard "pull positive, push negative" paradigm is essential to grasp why CLAN inverts it to achieve different geometric goals.
  - Quick check question: In SimCLR, are two augmented views of the same image treated as a positive or negative pair?

- **Concept: Homoscedastic Gaussian vs. von Mises-Fisher Distributions**
  - Why needed here: The paper assumes latent features follow specific statistical shapes (Gaussian for Euclidean distance, vMF for Cosine distance), explaining the switch to Cosine distance for better performance.
  - Quick check question: Does the paper assume different classes have the same variance (isotropic covariance)?

- **Concept: Data Augmentation for Tabular Data**
  - Why needed here: Understanding the specific uniform resampling augmentation is critical since CLAN uses this to generate "fake" malicious samples.
  - Quick check question: How does the CLAN augmentation strategy ψ(x) differ from standard Mixup or Cutout used in other IDS papers?

## Architecture Onboarding

- **Component map:** Raw network flow features -> MLP encoder -> Projection head -> Latent space -> Centroid-based inference
- **Critical path:**
  1. Pre-training: Calculate CLAN loss (push away ψ(x), pull closer other batch samples)
  2. Post-training: Pass benign training data through frozen encoder to compute and cache centroid μ₀
  3. Inference: Encode test sample -> Compute distance to μ₀ -> Threshold
- **Design tradeoffs:**
  - Centroid vs. KNN: Trades potential accuracy for massive speed (Centroid is O(1))
  - Resampling Range (b): Controls how "far" negative samples are pushed
- **Failure signatures:**
  - High False Positives: Training data contains malicious traffic, shifting centroid toward attack cluster
  - Dimensional Collapse: Regularization margin m not tuned, latent space collapses to single point
- **First 3 experiments:**
  1. Centroid Stability Check: Visualize latent space to verify benign cluster and augmentation separation
  2. Hyperparameter Sensitivity (p_resample): Find sweet spot where model learns structure without overfitting
  3. Inference Speed Benchmark: Compare wall-clock time of CLAN vs KNN on 1M+ flows

## Open Questions the Paper Calls Out
- Data pollution robustness: How does performance degrade when malicious samples are present in pretraining data?
- Augmentation sensitivity: How does performance vary with different augmentation strategies beyond uniform resampling?
- Cross-dataset generalization: Does CLAN generalize effectively to diverse network environments and traffic distributions?

## Limitations
- Assumes benign traffic forms a single cohesive distribution, which may not hold for multi-modal traffic
- Limited evaluation to Lycos2017 dataset, with unknown performance on other network datasets
- Sensitive to hyperparameter configuration found through random search, which was not disclosed
- Requires benign-only training data, limiting applicability when clean training data is unavailable

## Confidence
- **High Confidence**: Core contrastive mechanism and geometric interpretation are well-supported
- **Medium Confidence**: Computational efficiency claims are theoretically sound but need independent benchmarking
- **Low Confidence**: Surrogate malicious distribution mechanism relies on untested assumptions about random resampling representing malicious traffic

## Next Checks
1. Centroid Stability Analysis: Visualize latent representations to verify distinct cluster formation and centroid representativeness
2. Multi-Modal Traffic Test: Evaluate on datasets with clearly separable benign traffic modes to test single-centroid assumption
3. Cross-Dataset Generalization: Test on at least two additional network intrusion datasets to validate performance consistency beyond Lycos2017