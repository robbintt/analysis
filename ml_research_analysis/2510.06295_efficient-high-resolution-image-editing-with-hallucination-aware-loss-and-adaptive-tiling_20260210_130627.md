---
ver: rpa2
title: Efficient High-Resolution Image Editing with Hallucination-Aware Loss and Adaptive
  Tiling
arxiv_id: '2510.06295'
source_url: https://arxiv.org/abs/2510.06295
tags:
- image
- editing
- tile
- padding
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents MobilePicasso, an on-device system for efficient
  4K image editing that addresses hallucinations, memory constraints, and computational
  overhead. The key idea is a 3-stage hybrid pipeline: (1) standard-resolution editing
  with hallucination-aware loss, (2) learnable latent projection, and (3) adaptive
  context-preserving tiling for upscaling.'
---

# Efficient High-Resolution Image Editing with Hallucination-Aware Loss and Adaptive Tiling

## Quick Facts
- **arXiv ID**: 2510.06295
- **Source URL**: https://arxiv.org/abs/2510.06295
- **Reference count**: 40
- **Primary result**: MobilePicasso achieves up to 55.8× faster latency and 14-51% hallucination reduction for on-device 4K image editing

## Executive Summary
This paper presents MobilePicasso, an on-device system for efficient 4K image editing that addresses hallucinations, memory constraints, and computational overhead. The key idea is a 3-stage hybrid pipeline: (1) standard-resolution editing with hallucination-aware loss, (2) learnable latent projection, and (3) adaptive context-preserving tiling for upscaling. MobilePicasso reduces hallucinations by 14-51%, improves image quality by 18-48%, and text alignment by 22-54% over baselines through human evaluation. It achieves up to 55.8× faster latency and only 9% more memory than tiling approaches. Notably, MobilePicasso is 4.71× faster than a server-based baseline on an A100 GPU. The adaptive context-preserving tiling eliminates visible seams while avoiding redundant computation from tile overlaps. This work enables practical high-resolution image editing on mobile devices while maintaining quality and efficiency.

## Method Summary
MobilePicasso is a 3-stage hybrid pipeline for efficient 4K image editing. Stage 1 performs semantic editing at 512×512 resolution using SD v1.5 with hallucination-aware loss that penalizes unrealistic artifacts detected by an external model. Stage 2 uses a learnable latent projection (Tiny AutoEncoder + lightweight CNN) to map the edited latent to higher resolution without costly VAE decoding/encoding. Stage 3 applies adaptive context-preserving tiling (ACPT) with adjacent padding for super-resolution, enabling 0% overlap without seams. The system is trained on IP2P (~300K synthetic pairs) and PIPE (1M pairs) datasets, with dataset filtering to remove high-artifact samples (~15% threshold).

## Key Results
- **Hallucination reduction**: 14-51% reduction compared to baselines through human evaluation
- **Speed and memory**: Up to 55.8× faster latency and only 9% more memory than traditional tiling approaches
- **Quality improvements**: 18-48% better image quality and 22-54% better text alignment over baselines
- **GPU efficiency**: 4.71× faster than server-based baseline on A100 GPU despite being mobile-optimized

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Adding a hallucination-aware regularization term reduces the generation of unrealistic artifacts (hallucinations) in the edited image.
- **Mechanism**: The system employs an external hallucination detection model to compute the area of artifacts in a generated sample. This area is added as a penalty term ($L_{Hallu}$) to the standard diffusion loss ($L_{LDM}$), explicitly optimizing the model weights to minimize unrealistic regions. This is complemented by filtering the training dataset to remove existing high-artifact samples.
- **Core assumption**: The external hallucination detection model provides a reliable gradient signal; errors in the detector could misguide the training.
- **Evidence anchors**: [abstract] "MobilePicasso reduces hallucinations by 14-51%... over baselines." [section 3.2] "Hallucination-aware loss captures the amount of the hallucinated area... and penalises the model... we filter out images that exceed a certain threshold."
- **Break condition**: If the detection model produces false positives (flagging valid textures as artifacts), the loss may over-regularize the model, leading to blurry outputs or loss of detail.

### Mechanism 2
- **Claim**: Decomposing high-resolution editing into a 3-stage hybrid pipeline drastically reduces latency and memory consumption compared to end-to-end high-resolution diffusion.
- **Mechanism**: Instead of running the full diffusion process at 4K, the system operates at standard resolution (512x512) for the semantic edit. It then uses a lightweight **Learnable Latent Projection** to map the edited latent to a higher-resolution latent space, bypassing the expensive VAE decoding/encoding cycle. Finally, a super-resolution model is applied.
- **Core assumption**: The semantic edit can be effectively captured at 512x512, and the latent projection can bridge the resolution gap without losing structural fidelity.
- **Evidence anchors**: [abstract] "...upscaling the edited image latent to a higher resolution... achieves up to 55.8× faster latency." [section 3.1] "...performing most operations in the latent space, eliminating the need of costly encoding and decoding steps..."
- **Break condition**: If an edit requires precise manipulation of high-frequency details (e.g., changing a tiny distant sign), the downsampling to 512x512 may destroy the necessary information, making recovery impossible.

### Mechanism 3
- **Claim**: Adaptive Context-Preserving Tiling (ACPT) with Adjacent Padding eliminates visible seams without the computational redundancy of traditional overlapping tiles.
- **Mechanism**: Standard tiling often uses zero-padding or reflection, which lacks context, leading to seams. Large overlaps provide context but multiply computation. ACPT uses **Adjacent Padding**, borrowing real pixel data from neighboring tiles as padding for the current tile. This provides the necessary context for the super-resolution model to generate consistent boundaries with 0% overlap.
- **Core assumption**: The super-resolution model primarily needs local pixel context to maintain consistency across tile boundaries.
- **Evidence anchors**: [section 3.3] "Adjacent padding... uses surrounding tiles as padding so that it ensures that padding is naturally smooth... enables 0% tile overlap without image quality degradation." [corpus] Related work "Image Tiling for High-Resolution Reasoning" emphasizes balancing local detail with global context, supporting the need for context-aware tiling strategies.
- **Break condition**: If the tile size is too small or the model architecture has a very large receptive field, adjacent padding might fail to capture global structural coherence, leading to "patchwork" inconsistencies.

## Foundational Learning

- **Concept**: **Latent Space Operations (VAEs & Encoders)**
  - **Why needed here**: The core efficiency gain comes from "Learnable Latent Projection," which assumes the user understands the difference between processing in pixel space vs. compressed latent space.
  - **Quick check question**: Why does avoiding the VAE Decoder/Encoder cycle save significant latency?

- **Concept**: **Diffusion Guidance Scales ($s_I$, $s_T$)**
  - **Why needed here**: The image editing stage relies on Classifier-Free Guidance (CFG) to balance fidelity to the input image ($s_I$) vs. adherence to the text prompt ($s_T$).
  - **Quick check question**: What happens to the output if $s_I$ is set too low compared to $s_T$?

- **Concept**: **Tiling & Overlap Trade-offs**
  - **Why needed here**: Understanding the "quadratic overhead" of overlaps is necessary to appreciate the efficiency of the 0% overlap ACPT approach.
  - **Quick check question**: Why does a 50% overlap typically result in smoother images but 4x slower inference than 0% overlap?

## Architecture Onboarding

- **Component map**: Editor (SD v1.5 U-Net) -> Projector (Tiny AutoEncoder + CNN) -> Upscaler (SR model with ACPT)
- **Critical path**: The **Stage 2 Latent Projection** is the most critical bottleneck. If the projection model fails to preserve semantic structure, the subsequent ACPT upscaler will magnify these errors into 4K artifacts.
- **Design tradeoffs**:
  - **Resolution vs. Semantic Precision**: By forcing edits to 512x512, the system gains massive speed (55.8×) but sacrifices the ability to edit high-frequency details directly.
  - **Memory vs. Seam Quality**: The ACPT enables low memory usage via tiling but requires correct implementation of "adjacent padding" to prevent visual seams.
- **Failure signatures**:
  - **Seams/Grid artifacts**: Indicates ACPT adjacent padding is misconfigured or padding size is insufficient for the SR model's receptive field.
  - **Hallucinations**: If hallucinations persist, check if the dataset filtering threshold was too permissive or if the Hallucination Loss weight ($\lambda$) is too low.
  - **Blur/Detail Loss**: Likely an issue with the Learnable Latent Projection model capacity or training convergence.
- **First 3 experiments**:
  1. **Padding Ablation**: Run the upscaler with *Reflection Padding* vs. *Adjacent Padding* on a 4K image to visually confirm seam reduction.
  2. **Projection Baseline**: Replace the learned projection with simple Bilinear Upscaling in latent space to quantify the quality drop (validating the need for the learned component).
  3. **Latency Profiling**: Measure memory and time for Stage 3 specifically with 0% overlap vs. 25% overlap to validate the "quadratic overhead" claim on the target hardware.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can MobilePicasso's 3-stage hybrid pipeline and hallucination-aware loss be effectively generalized to other generative AI tasks like inpainting, outpainting, and style transfer on mobile devices?
- Basis in paper: [explicit] The Conclusion and Appendix H explicitly state the authors will "extend beyond the immediate application of image editing to other generative AI tasks such as text/sketch-to-image generation, style transfer, and image inpainting/outpainting."
- Why unresolved: The current framework is optimized and evaluated strictly for image editing; the efficacy of the hallucination-aware loss or adaptive tiling for tasks requiring structural filling or style migration is not yet demonstrated.
- What evidence would resolve it: Experimental results applying the MobilePicasso framework to standard inpainting or style transfer benchmarks, measuring consistency and hallucination rates in those contexts.

### Open Question 2
- Question: How can MobilePicasso be adapted to leverage recent larger diffusion architectures, such as SD3.5 or Flux.1, which currently exceed mobile NPU memory capacity?
- Basis in paper: [explicit] Appendix H notes that while SDv1.5 was used for deployability, "it is worth investigating these advanced pretrained models to further improve the image editing quality."
- Why unresolved: The paper highlights that these newer models possess 8B–11B parameters, exceeding the memory capacity of target mobile NPUs, making direct deployment infeasible without architectural modification.
- What evidence would resolve it: A modified system design or compression technique that allows larger models to operate within the 2GB mobile memory constraint while maintaining the latency advantages of the 3-stage pipeline.

### Open Question 3
- Question: What specific efficiency gains and quality trade-offs result from combining MobilePicasso with aggressive quantization techniques like INT4 or SVDQuant?
- Basis in paper: [explicit] Appendix H suggests "further research could combine our approach with recent quantisation approaches... to achieve even greater mobile efficiency."
- Why unresolved: While the current work optimizes for latency and memory, it has not yet evaluated the impact of extremely low-bit quantization (e.g., 4-bit) on the pipeline's visual fidelity or hallucination metrics.
- What evidence would resolve it: Ablation studies presenting latency, memory, and image quality metrics (e.g., CLIP, FID) when MobilePicasso components are quantized to 4-bit.

## Limitations
- **Hardware specificity**: The claimed 55.8× speedup assumes perfect hardware compatibility and may not translate directly to other mobile SoCs
- **Detection model reliability**: The hallucination detection model's reliability is critical - if detection gradients are noisy, the hallucination-aware loss could degrade quality rather than improve it
- **Dataset filtering bias**: Dataset filtering (~15% removed) may introduce bias toward cleaner but less diverse training examples

## Confidence

**High Confidence**: Stage 1 hallucination-aware loss mechanism and its integration with standard diffusion training. The concept of filtering training data based on artifact detection is well-established. The 3-stage pipeline architecture (edit → project → upscale) is clearly specified.

**Medium Confidence**: Quantitative claims about hallucination reduction (14-51%) and quality improvements (18-48%) rely on human evaluation methodology not fully detailed. The specific performance gains depend heavily on implementation details of the latent projection and ACPT components.

**Low Confidence**: Claims about A100 GPU performance (4.71× faster than server baseline) seem counterintuitive for a mobile-optimized system and may involve different workload characteristics or benchmarking conditions.

## Next Checks

1. **Hallucination Detection Ablation**: Train the editing model with and without hallucination-aware loss while measuring both hallucination scores and overall image quality to verify the tradeoff is positive and not causing over-regularization.

2. **ACPT Seam Analysis**: Generate side-by-side comparisons of 4K outputs using 0% overlap adjacent padding vs. traditional overlapping tiling to empirically validate the seam-free claim across diverse image content.

3. **Latent Projection Capacity Study**: Systematically vary the Tiny AutoEncoder capacity (number of parameters) to determine the minimum viable size that maintains quality, validating the claimed efficiency gains aren't due to architectural underspecification.