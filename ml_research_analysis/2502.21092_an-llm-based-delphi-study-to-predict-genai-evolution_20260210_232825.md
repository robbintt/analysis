---
ver: rpa2
title: An LLM-based Delphi Study to Predict GenAI Evolution
arxiv_id: '2502.21092'
source_url: https://arxiv.org/abs/2502.21092
tags:
- experiment
- genai
- delphi
- could
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study introduces a novel LLM-based Delphi methodology to conduct
  qualitative forecasting on the evolution of Generative Artificial Intelligence (GenAI).
  By leveraging LLMs as expert agents, the approach addresses challenges of traditional
  Delphi studies such as respondent fatigue and knowledge cutoffs.
---

# An LLM-based Delphi Study to Predict GenAI Evolution

## Quick Facts
- arXiv ID: 2502.21092
- Source URL: https://arxiv.org/abs/2502.21092
- Reference count: 13
- The study introduces a novel LLM-based Delphi methodology to conduct qualitative forecasting on the evolution of Generative Artificial Intelligence (GenAI).

## Executive Summary
This paper presents a novel LLM-based Delphi methodology for qualitative forecasting on GenAI evolution, replacing human experts with LLM agents. The approach addresses traditional Delphi challenges like respondent fatigue and knowledge cutoffs by using role-conditioned LLM agents in iterative rounds of open and closed-ended questions. Results demonstrate that this method can generate insights on key factors like geopolitical tensions, economic disparities, regulatory frameworks, and ethical considerations while identifying challenges such as data privacy and sustainability. The methodology offers a promising tool for structured foresight in complex, data-scarce domains, though further research is needed to refine reliability and integrate external data sources.

## Method Summary
The methodology employs gpt-4o-mini-2024-07-18 via OpenAI API with temperature = 0.7, conducting 5 rounds of Delphi-style deliberation. Two agent types are used: an organizing agent that synthesizes responses and generates questions, and responding agents assigned diverse roles (nationality, educational background, experience type/field, specialization). Question filtering uses sentence embeddings and cosine similarity thresholds to remove redundancy while preserving diversity. The process is repeated 3 times to assess variability, with experiments testing 5-15 agents and 5-15 responses per agent.

## Key Results
- LLM-based Delphi method successfully identifies key factors influencing GenAI evolution including geopolitical tensions, economic disparities, and regulatory frameworks
- Role-based persona assignment generates heterogeneous perspectives comparable to multi-expert panels
- Knowledge cutoff limitations (15-month gap) constrain applicability to rapidly evolving domains
- Stochastic sampling with temperature > 0 enables uncertainty quantification through repeated runs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Assigning diverse role personas to LLM agents may generate heterogeneous perspectives comparable to a multi-expert panel.
- Mechanism: System prompts define agent attributes (nationality, educational background, field of specialization). These attributes condition response patterns, creating simulated expertise diversity without human participants.
- Core assumption: LLMs can simulate domain-relevant reasoning patterns when prompted with expert personas, and this simulation produces substantively different outputs than unprompted generation.
- Evidence anchors:
  - [abstract]: "agents assigned diverse roles to generate insights on key factors like geopolitical tensions, economic disparities, regulatory frameworks"
  - [section 2.1]: "each LLM is defined by nationality, educational background, type of experience, the field of experience, and the field of specialization"
  - [corpus]: Related work on AI-augmented forecasting (Schoenegger et al.) supports LLM-assisted prediction improvement, though specific role-persona effects remain understudied.
- Break condition: If role prompts produce near-identical outputs across agents (high response correlation), heterogeneity assumption fails.

### Mechanism 2
- Claim: Iterative rounds with semantic filtering may enable exploration of scenarios beyond initial conditions while maintaining computational tractability.
- Mechanism: After each round, an organizing agent summarizes responses and generates new questions. Two filters remove redundant questions: (1) threshold-based cosine similarity removal, and (2) iterative removal of highest mean-similarity questions. This constrains question proliferation while preserving diversity.
- Core assumption: Semantic similarity approximates question redundancy adequately, and removing similar questions does not systematically exclude valuable perspectives.
- Evidence anchors:
  - [section 2.1]: "Removing these redundant questions reduces computational load without compromising the quality of the process"
  - [section 2.1]: "ensures that the final set of questions remains as diverse and dispersed as possible"
  - [corpus]: No direct corpus evidence on semantic filtering for Delphi; this is a novel contribution requiring validation.
- Break condition: If embedding similarity poorly captures semantic redundancy (e.g., same question phrased differently passes filter), question explosion or information loss occurs.

### Mechanism 3
- Claim: Stochastic sampling with temperature > 0 enables reproducible uncertainty quantification through repeated runs.
- Mechanism: Temperature-induced variability propagates through agent interactions. Running the same configuration multiple times produces distributional outputs, allowing uncertainty estimation impossible in single-run human Delphi studies.
- Core assumption: Observed variability reflects meaningful exploration rather than noise, and repeated runs sample a stable underlying distribution.
- Evidence anchors:
  - [section 2.3]: "a temperature greater than zero was deliberately chosen, ensuring that the system's agent components exhibit stochastic behavior"
  - [section 4.1]: "To assess this variability, each combination of questions and the number of agents was repeated three times"
  - [corpus]: Weak corpus evidence; related work on LLM uncertainty exists but not specifically for Delphi-style deliberation.
- Break condition: If variability is dominated by random noise rather than systematic exploration, repeated runs provide no convergent signal.

## Foundational Learning

- Concept: Traditional Delphi method
  - Why needed here: The LLM-based approach modifies classic Delphi (consensus-seeking, iterative expert surveys). Understanding the original helps identify what changes and why.
  - Quick check question: Can you explain why classic Delphi stops at consensus achievement while this method uses fixed rounds?

- Concept: LLM temperature and sampling
  - Why needed here: Temperature controls response diversity. The paper uses 0.7 deliberately; understanding this parameter is essential for tuning exploration vs. consistency.
  - Quick check question: What happens to output diversity if temperature is set to 0 versus 1.0?

- Concept: Sentence embeddings and cosine similarity
  - Why needed here: The redundancy filtering mechanism relies on embedding-based similarity thresholds. Implementation requires selecting embedding models and threshold values.
  - Quick check question: Why might cosine similarity on embeddings fail to capture true semantic equivalence for domain-specific questions?

## Architecture Onboarding

- Component map: Organizing agent -> Responding agents (N) -> Question filter pipeline -> Iteration controller
- Critical path: Initial open questions → responding agents generate answers → organizing agent synthesizes → generates closed questions → Likert responses collected → new open questions generated → filtering applied → next round. Repeat 5 times, then summarize.
- Design tradeoffs:
  - Round count vs. computational cost: More rounds increase exploration but linearly increase API costs.
  - Filter threshold vs. diversity: Stricter similarity thresholds reduce redundancy but may prematurely converge on narrow question sets.
  - Agent count vs. heterogeneity: More agents increase perspective diversity but raise costs and may amplify noise.
- Failure signatures:
  - Low heterogeneity: All agents produce similar responses despite role differences → check prompt effectiveness.
  - Question collapse: Filter removes too many questions → adjust similarity threshold upward.
  - Theme fixation: Same topics dominate every round → initial questions may be overly constraining.
  - Knowledge staleness: Outputs reflect outdated information → model knowledge cutoff is limiting (paper notes 15-month gap).
- First 3 experiments:
  1. Baseline run with documented configuration (5 agents, 5 rounds, temperature 0.7) to establish reference outputs and variability patterns.
  2. Temperature sweep (0.3, 0.7, 1.0) on identical initial conditions to quantify sensitivity to stochasticity.
  3. Role diversity test: Compare homogeneous roles vs. heterogeneous roles to validate persona effect on response diversity.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does utilizing multiple distinct LLM architectures (multi-model ensembles) yield higher output diversity than using persona-based prompts on a single model?
- Basis in paper: [explicit] The Conclusion suggests "introducing heterogeneity in the respondent agents by mixing different LLMs" to examine if this increases the diversity of individual responses.
- Why unresolved: The current study relied exclusively on a single model (GPT-4o-mini) with varying system prompts, leaving the potential benefits of architectural diversity untested.
- What evidence would resolve it: A comparative study measuring the semantic variance and novelty of ideas generated by a multi-model panel versus a single-model panel.

### Open Question 2
- Question: Does integrating Retrieval-Augmented Generation (RAG) effectively mitigate knowledge cutoff limitations in LLM-based Delphi studies?
- Basis in paper: [explicit] The Abstract states research is needed to "integrate external data sources," and Section 4.1 explicitly proposes implementing RAG systems to address the knowledge cutoff limitation.
- Why unresolved: The study utilized a model with a 15-month knowledge gap, potentially hindering accuracy in rapidly evolving fields, but did not test external data integration methods.
- What evidence would resolve it: Experiments comparing the predictive validity and relevance of insights from standard LLM agents against RAG-enabled agents provided with up-to-date documentation.

### Open Question 3
- Question: How sensitive is the LLM-based Delphi process to initial conditions, specifically regarding prompt phrasing, temperature settings, and question order?
- Basis in paper: [explicit] Section 4.1 identifies "sensitivity to initial conditions" as a key limitation and calls for future analysis on how hyperparameters and prompt design affect stability.
- Why unresolved: The chaotic nature of the multi-agent interaction suggests that minor input variations could lead to significantly different outputs, but this variance is currently unquantified.
- What evidence would resolve it: A sensitivity analysis repeating the simulation while systematically varying temperature and initial prompt structures to measure the statistical divergence of the final consensus.

## Limitations
- Knowledge cutoff limitations constrain applicability to rapidly evolving domains (15-month gap)
- Semantic filtering mechanism lacks validation against domain-expert judgment
- Role-based heterogeneity assumption remains empirically unverified
- Only 3-run variability assessment provides limited statistical power for uncertainty quantification

## Confidence
- High confidence: Core methodology framework (iterative rounds, organizing agent, filtering pipeline) is clearly specified and reproducible
- Medium confidence: Claim that LLM agents can simulate multi-expert panels with diverse perspectives (supported by role assignment but unverified heterogeneity)
- Low confidence: Uncertainty quantification through stochastic sampling (only 3 runs, unclear if variability reflects meaningful exploration)

## Next Checks
1. **Heterogeneity validation**: Run identical configurations with homogeneous agent roles versus heterogeneous roles, measure response correlation and semantic diversity to test if persona prompts produce meaningful perspective variation
2. **Filter sensitivity analysis**: Systematically vary cosine similarity thresholds and document impact on question diversity, convergence patterns, and computational efficiency to optimize the filtering pipeline
3. **External knowledge integration test**: Implement RAG-based augmentation with current domain literature for each agent role and compare output quality and knowledge currency against base model performance