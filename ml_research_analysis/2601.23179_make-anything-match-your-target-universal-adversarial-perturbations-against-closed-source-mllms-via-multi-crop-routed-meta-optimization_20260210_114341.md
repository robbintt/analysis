---
ver: rpa2
title: 'Make Anything Match Your Target: Universal Adversarial Perturbations against
  Closed-Source MLLMs via Multi-Crop Routed Meta Optimization'
arxiv_id: '2601.23179'
source_url: https://arxiv.org/abs/2601.23179
tags:
- adversarial
- target
- universal
- attacks
- optimization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of crafting universal adversarial
  perturbations that can consistently steer any input image toward a specified target
  across unknown commercial multimodal large language models (MLLMs). The core method,
  MCRMO-Attack, introduces Multi-Crop Aggregation with an Attention-Guided Crop to
  stabilize target supervision, Token Routing to selectively align informative tokens
  while preserving non-alignable ones, and Meta-Initialization to learn a transferable
  perturbation prior.
---

# Make Anything Match Your Target: Universal Adversarial Perturbations against Closed-Source MLLMs via Multi-Crop Routed Meta Optimization

## Quick Facts
- arXiv ID: 2601.23179
- Source URL: https://arxiv.org/abs/2601.23179
- Authors: Hui Lu; Yi Yu; Yiming Yang; Chenyu Yi; Xueyi Ke; Qixing Zhang; Bingquan Shen; Alex Kot; Xudong Jiang
- Reference count: 16
- Primary result: Universal perturbations achieve 23.7% higher attack success on GPT-4o and 19.9% on Gemini-2.0 compared to strongest baseline

## Executive Summary
This paper introduces MCRMO-Attack, a method for generating universal adversarial perturbations that can reliably steer any input image toward a specified target across unknown commercial multimodal large language models (MLLMs). The approach addresses the challenge of closed-source models by combining multi-crop aggregation, attention-guided cropping, token routing, and meta-initialization techniques. The method demonstrates strong generalization to unseen images while maintaining effectiveness against specific target MLLMs.

## Method Summary
MCRMO-Attack generates universal perturbations through a multi-stage optimization process. It uses multi-crop aggregation to capture diverse visual features, an attention-guided crop mechanism to stabilize target supervision, and token routing to selectively align informative tokens while preserving non-alignable ones. The meta-initialization component learns a transferable perturbation prior across different models. The method operates in a black-box setting without requiring access to model internals or gradients.

## Key Results
- Achieves 23.7% absolute increase in attack success rate on GPT-4o over strongest universal baseline
- Demonstrates 19.9% improvement on Gemini-2.0 compared to existing methods
- Shows strong generalization to unseen images while maintaining target specificity

## Why This Works (Mechanism)
The method succeeds by addressing key challenges in universal adversarial attack generation: maintaining target specificity across diverse inputs, ensuring transferability to unknown models, and preserving attack effectiveness on unseen images. The multi-crop aggregation captures comprehensive visual information, while attention-guided cropping focuses optimization on relevant regions. Token routing selectively preserves useful features while aligning targets, and meta-initialization provides a transferable starting point for perturbation generation.

## Foundational Learning
- **Multi-crop aggregation**: Combines multiple cropped views of input images to capture diverse visual features and improve robustness
  - Why needed: Single crops may miss important features; multiple views provide comprehensive coverage
  - Quick check: Verify that aggregated features capture both global context and local details

- **Attention-guided crop**: Uses attention mechanisms to identify and focus on regions most relevant to target manipulation
  - Why needed: Prevents optimization from being distracted by irrelevant image regions
  - Quick check: Confirm attention weights correlate with successful target alignment

- **Token routing**: Selectively processes tokens based on their alignment potential while preserving non-alignable ones
  - Why needed: Different tokens have varying relevance to target manipulation; routing optimizes this selection
  - Quick check: Measure routing decisions' correlation with attack success rates

- **Meta-initialization**: Learns transferable perturbation priors across different models to improve black-box attack effectiveness
  - Why needed: Commercial models are unknown; meta-learning provides a starting point for optimization
  - Quick check: Compare initialization quality across different model families

## Architecture Onboarding

**Component map**: Input Image -> Multi-Crop Aggregation -> Attention-Guided Crop -> Token Routing -> Perturbation Optimization -> Output Perturbation

**Critical path**: The core optimization pipeline flows from input through multi-crop processing to final perturbation generation, with token routing serving as the key decision point for selective alignment.

**Design tradeoffs**: The method balances comprehensiveness (multi-crop) against computational efficiency, and specificity (attention-guided) against generalization. Token routing adds complexity but enables selective optimization.

**Failure signatures**: Attacks may fail when attention guidance misidentifies relevant regions, token routing incorrectly preserves non-alignable tokens, or meta-initialization provides poor starting points for specific model architectures.

**First experiments**:
1. Test multi-crop aggregation effectiveness by comparing single vs. multi-crop attack success rates
2. Validate attention-guided crop by measuring target alignment before and after attention-based region selection
3. Assess meta-initialization transferability by comparing attack success across different model families

## Open Questions the Paper Calls Out
None

## Limitations
- Limited evaluation scope: Only tested on GPT-4o and Gemini-2.0 despite broader generalization claims
- Black-box assumptions: Heavy reliance on surrogate model transferability without systematic validation across diverse architectures
- Temporal stability: No testing of perturbation effectiveness against evolving model versions over time

## Confidence

**High confidence**: Technical implementation of MCRMO-Attack components is sound and methodology is clearly articulated.

**Medium confidence**: Generalization claims to unseen images are supported by experimental results within tested scope.

**Low confidence**: Universal applicability across all commercial MLLMs and long-term stability of perturbations lack empirical support.

## Next Checks
1. Evaluate attack success rates across 5-7 additional commercial MLLMs to validate true universality claims
2. Test perturbation effectiveness against multiple versions of the same MLLM over time to assess temporal stability
3. Conduct systematic ablation studies removing each component to quantify individual contributions to attack success