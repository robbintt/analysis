---
ver: rpa2
title: 'Demystifying Sequential Recommendations: Counterfactual Explanations via Genetic
  Algorithms'
arxiv_id: '2508.03606'
source_url: https://arxiv.org/abs/2508.03606
tags:
- counterfactual
- sequence
- sequential
- explanations
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generating counterfactual
  explanations for sequential recommender systems (SRSs), a problem proven to be NP-Complete.
  The authors propose GECE (GEnetic Counterfactual Explanations), a novel approach
  using a genetic algorithm tailored for discrete sequences to find minimal modifications
  in user interaction histories that lead to different recommendations.
---

# Demystifying Sequential Recommendations: Counterfactual Explanations via Genetic Algorithms

## Quick Facts
- arXiv ID: 2508.03606
- Source URL: https://arxiv.org/abs/2508.03606
- Reference count: 40
- This paper introduces GECE, the first specialized method for generating counterfactual explanations in Sequential Recommender Systems, proving the problem is NP-Complete and demonstrating effectiveness across four distinct scenarios.

## Executive Summary
This paper addresses the challenge of generating counterfactual explanations for sequential recommender systems (SRSs), a problem proven to be NP-Complete. The authors propose GECE (GEnetic Counterfactual Explanations), a novel approach using a genetic algorithm tailored for discrete sequences to find minimal modifications in user interaction histories that lead to different recommendations. Experiments across four distinct scenarios—varying between targeted/untargeted and categorized/uncategorized settings—demonstrate GECE's effectiveness. The method achieves model fidelity close to one (often exactly one in targeted-categorized settings) and outperforms baseline approaches (random and educated) in both fidelity and edit distance metrics. These results validate GECE as the first specialized counterfactual explanation technique for SRSs, contributing to explainability in AI while maintaining recommendation quality.

## Method Summary
The paper proposes GECE, a genetic algorithm that generates counterfactual explanations for sequential recommender systems by finding minimal modifications to user interaction histories. The method treats the recommender as a black box, using mutation operations (replace, add, delete) to explore the discrete sequence space. A fitness function balances edit distance minimization with maximizing logit differences. The approach is validated on three architectures (BERT4Rec, GRU4Rec, SASRec) using MovieLens-100K/1M and Steam datasets, demonstrating effectiveness across targeted/untargeted and categorized/uncategorized settings.

## Key Results
- GECE achieves model fidelity close to one (often exactly one in targeted-categorized settings) across four experimental scenarios
- The method outperforms random and educated baselines in both fidelity and edit distance metrics
- GECE is validated on three distinct recommender architectures (BERT4Rec, GRU4Rec, SASRec) demonstrating generalizability
- The paper proves that finding optimal counterfactual sequences is NP-Complete, justifying the need for the genetic algorithm approach

## Why This Works (Mechanism)

### Mechanism 1: Genetic Search for NP-Complete Spaces
- **Claim:** Exact solutions for optimal counterfactual sequences are computationally intractable; evolutionary search provides a viable approximation.
- **Mechanism:** The authors formally prove that finding a minimal counterfactual sequence is **NP-Complete** (reduction from Vertex Cover). To navigate this intractable search space, GECE employs a genetic algorithm (GA) that samples the space stochastically rather than exhaustively, iterating toward a solution that satisfies the counterfactual condition.
- **Core assumption:** The fitness landscape defined by the recommendation model allows for gradient-free optimization via mutation and crossover without getting trapped in local minima too frequently.
- **Evidence anchors:** [abstract] "...show that generating counterfactual explanations for sequential data is an NP-Complete problem." [section] **Theorem 3.5** proves the decision problem is NP-complete; **Section 3.3** introduces the genetic algorithm to tackle this complexity.

### Mechanism 2: Sequence-Preserving Mutation Operations
- **Claim:** Standard genetic mutations fail on ordered data; tailored discrete operations (add, delete, replace) preserve semantic integrity while altering outcomes.
- **Mechanism:** Unlike tabular data where features are independent, sequential data relies on order. GECE uses specific mutation operators (Replace, Add, Delete) that respect sequence alignment. These mutations are selected to minimize the **Hamming distance** (cost) while maximizing the change in model output (logits), effectively finding the "sparsest" explanation.
- **Core assumption:** The model's sensitivity to specific item indices allows for a valid counterfactual to be found within a reasonable number of mutations (sparse modification).
- **Evidence anchors:** [abstract] "...uses mutation operations like replace, add, and delete to efficiently search for counterfactual sequences." [section] **Section 3.3** explicitly defines the three mutation operations and the fitness function based on edit distance and logit difference.

### Mechanism 3: Model-Agnostic Black-Box Querying
- **Claim:** The method functions independently of the internal model architecture by treating the recommender as a queryable black box.
- **Mechanism:** GECE does not require gradients or access to model weights. It queries the model $M$ with candidate sequences and observes the output logits. This decouples the explanation mechanism from the underlying architecture (e.g., RNN vs. Transformer), relying solely on input-output behavior.
- **Core assumption:** The model provides stable, differentiable-enough logit outputs for similar sequences to guide the genetic search.
- **Evidence anchors:** [abstract] "...three models (BERT4Rec, GRU4Rec, SASRec) demonstrate GECE's effectiveness." [section] **Section 4.2** lists the diverse architectures used for validation.

## Foundational Learning

- **Concept: Sequential Recommender Systems (SRS)**
  - **Why needed here:** You must understand that SRSs (like BERT4Rec) process ordered lists of user actions, unlike traditional collaborative filtering. The explanation's validity depends on *where* in the sequence a change occurs.
  - **Quick check question:** Does the order of items in the input sequence matter for the model's prediction? (Yes, that is the defining feature of an SRS).

- **Concept: Counterfactual Explanations**
  - **Why needed here:** The goal is not just "why this prediction?" but "what minimal change yields a different prediction?" (e.g., "If you hadn't watched *Inception*, you wouldn't have been recommended *Interstellar*").
  - **Quick check question:** Is a counterfactual explanation focused on attributing credit to features (feature importance) or identifying a minimal actionable change (actionability)?

- **Concept: Genetic Algorithms (GA)**
  - **Why needed here:** GECE is essentially a GA wrapper. You need to know how "fitness" drives evolution and why "mutation" is used here instead of gradient descent (because the sequence space is discrete and non-differentiable).
  - **Quick check question:** Why is a Genetic Algorithm suitable for discrete sequences where Gradient Descent is not? (GAs don't require differentiability and handle discrete "jumps" in the search space).

## Architecture Onboarding

- **Component map:** Original sequence ($S$) $\to$ Population Initialization (Copies of $S$) $\to$ **Mutation/Crossover** $\to$ **Fitness Evaluation** (Min Hamming distance + Max Logit change) $\to$ Selection $\to$ Counterfactual Sequence ($S'$)

- **Critical path:** The **Fitness Evaluation** (Section 3.3, Algorithm 2) is the bottleneck. It requires inferring the model $M$ on the entire population (batch size 128, population 8192) every generation.

- **Design tradeoffs:**
  - **Population Size (8192) vs. Speed:** A large population (as set in Section 4.4) ensures diversity to solve the NP-complete search but requires significant memory and compute (inference on 8192 sequences per generation).
  - **Targeted vs. Untargeted:** "Targeted" (finding a specific item) is computationally harder and yields lower fidelity than "Untargeted" (any different item), as shown in Figure 3 vs. Figure 4.

- **Failure signatures:**
  - **Stagnation:** The GA fails to find a sequence with fitness above the threshold (0.5), usually in "Targeted-Uncategorized" scenarios where the search space is too vast compared to the sparse target.
  - **Semantic Drift:** Generated sequences, while valid counterfactuals, might be nonsensical to a human (e.g., random items inserted) if the dataset lacks strong categorical structure.

- **First 3 experiments:**
  1. **Sanity Check (Untargeted-Uncategorized):** Run GECE on ML-100k with BERT4Rec. You expect Fidelity@1 $\approx$ 1.0 (Figure 3a) to verify the pipeline works.
  2. **Constraint Stress Test:** Compare "Targeted-Uncategorized" vs. "Targeted-Categorized". Verify that categorization acts as a regularizer, improving Fidelity and lowering Hamming distance (Table 2).
  3. **Ablation on Mutations:** Disable the "Add" and "Delete" operations, leaving only "Replace". Check if the Hamming distance increases or Fidelity drops, proving the necessity of dynamic sequence length adjustment in the mutation logic.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the genetic algorithm's search strategy be modified to effectively identify specific target items in the "Targeted-Uncategorized" setting, where the current method shows no statistical improvement over baselines?
- **Basis in paper:** [explicit] The results section (Page 7) notes that in the Targeted-Uncategorized scenario, "none of these scenarios have statistical differences in Fidelity with respect to the baselines," leading the authors to shift focus to category-based recommendations.
- **Why unresolved:** The authors state that the large size of the item set $I$ makes finding specific items "considerably more challenging," and they effectively abandoned this specific optimization constraint in favor of categorized settings.
- **What evidence would resolve it:** A modification of GECE (or a new algorithm) that achieves significantly higher Fidelity@k than random/educated baselines in the Targeted-Uncategorized setting with statistical significance ($p < 0.01$).

### Open Question 2
- **Question:** Is GECE computationally efficient enough to be applied to the full user populations of large-scale datasets without sampling constraints?
- **Basis in paper:** [explicit] The experimental setup (Page 6) mentions that for the larger ML-1M and Steam datasets, the authors "randomly sample 200 users... due to computational constraints" rather than evaluating the entire user base.
- **Why unresolved:** The NP-completeness of the problem and the high population size used in the genetic algorithm (8192) create a high computational load, limiting the evaluation to small samples.
- **What evidence would resolve it:** Runtime and resource usage statistics showing GECE can process all users in ML-1M or Steam in a reasonable timeframe without performance degradation.

### Open Question 3
- **Question:** How does GECE compare to general-purpose counterfactual methods (e.g., gradient-based or reinforcement learning approaches) when adapted for sequential data?
- **Basis in paper:** [explicit] The authors state (Page 5): "We chose not to include any of the methods presented in Section 2... as we believe that adapting techniques developed for different domains... constitutes a substantial research effort on its own."
- **Why unresolved:** The paper compares GECE only against "random" and "educated" baselines, leaving a gap in understanding how it fares against state-of-the-art explainability methods adapted for sequences.
- **What evidence would resolve it:** A comparative study evaluating GECE against adapted versions of general counterfactual algorithms on the same fidelity and Hamming distance metrics.

### Open Question 4
- **Question:** Do the counterfactual sequences generated by GECE actually enhance user trust or understanding in a real-world recommendation scenario?
- **Basis in paper:** [inferred] The introduction and abstract frame "enhancing user trust and system transparency" as the primary motivation (Page 1), but the evaluation relies solely on computational metrics (Fidelity and Hamming distance) without human subject testing.
- **Why unresolved:** Optimizing for minimal edit distance does not guarantee that the "story" told by the counterfactual sequence is plausible or interpretable to a human user.
- **What evidence would resolve it:** A user study measuring perceived transparency, satisfaction, or trust when users are presented with GECE explanations versus no explanation or alternative explanations.

## Limitations
- **Scalability constraints:** The GA requires 8192 model inferences per generation, making it computationally expensive for large-scale production systems with millions of users.
- **Semantic validity uncertainty:** High model fidelity does not guarantee the counterfactuals are semantically meaningful to users; minimal edits might produce implausible recommendation scenarios.
- **Targeted-uncategorized performance:** The method shows no statistical improvement over baselines in the targeted-uncategorized setting due to the vast item space.

## Confidence
- **High Confidence:** The NP-Completeness proof and basic GECE mechanics (mutation operations, fitness function) are well-founded and clearly demonstrated through experimental results.
- **Medium Confidence:** The choice of hyperparameters (population size, mutation rate, generation count) appears effective but may not be optimal for all datasets or model architectures.
- **Low Confidence:** The semantic plausibility of generated counterfactuals to end-users has not been validated through user studies.

## Next Checks
1. **Semantic Plausibility Test:** Conduct a user study to evaluate whether generated counterfactuals make intuitive sense to humans and could lead to actionable recommendations.
2. **Scalability Benchmark:** Measure GECE's performance on larger datasets (e.g., MovieLens-25M) and compare runtime and memory usage against the claimed computational costs.
3. **Cross-Domain Transfer:** Apply GECE to a non-sequential recommendation task (e.g., content-based image recommendation) to test the generalizability of the genetic algorithm approach.