---
ver: rpa2
title: Improving Group Fairness in Knowledge Distillation via Laplace Approximation
  of Early Exits
arxiv_id: '2505.01070'
source_url: https://arxiv.org/abs/2505.01070
tags:
- student
- teacher
- auxiliary
- layer
- laplace
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses group fairness in knowledge distillation by
  improving uncertainty estimation in early-exit neural networks. The authors propose
  using Laplace approximation to obtain well-calibrated uncertainty estimates from
  intermediate layers, replacing the margin-based approach in the DEDIER model.
---

# Improving Group Fairness in Knowledge Distillation via Laplace Approximation of Early Exits

## Quick Facts
- **arXiv ID:** 2505.01070
- **Source URL:** https://arxiv.org/abs/2505.01070
- **Reference count:** 2
- **Primary result:** Laplace approximation improves group fairness in knowledge distillation by better identifying difficult instances through calibrated uncertainty estimates

## Executive Summary
This paper addresses group fairness in knowledge distillation by improving uncertainty estimation in early-exit neural networks. The authors propose using Laplace approximation to obtain well-calibrated uncertainty estimates from intermediate layers, replacing the margin-based approach in the DEDIER model. Their method approximates the posterior distribution of auxiliary network weights using Bayesian updates, providing more robust identification of difficult instances. Experiments on the MultiNLI dataset show that this approach yields slightly better accuracy than the original DEDIER model, particularly when the auxiliary network is placed on earlier layers (layer 3 vs. layer 6). The Laplace-based method also produces lower confidence margins, suggesting increased uncertainty calibration.

## Method Summary
The method combines knowledge distillation with Laplace approximation-based uncertainty estimation for early-exit neural networks. A student model (DistilBERT) learns from a teacher (BERT-base) while an auxiliary classifier is attached to an intermediate layer. The auxiliary network is trained with cross-entropy, and Laplace approximation is used to estimate predictive uncertainty from the auxiliary's final layer weights. This uncertainty is quantified via entropy from Monte Carlo samples of the predictive distribution, which then reweights the knowledge distillation loss. The approach aims to reduce reliance on spurious correlations by downweighting overconfident predictions on biased instances.

## Key Results
- Layer 3 auxiliary placement outperforms layer 6, achieving 0.835 accuracy vs 0.830 baseline
- Laplace-based uncertainty produces lower confidence margins than margin-based approaches
- Computational efficiency is maintained through single-layer auxiliary networks
- Accuracy improvements observed without requiring prior group knowledge

## Why This Works (Mechanism)

### Mechanism 1: Laplace Approximation for Uncertainty Quantification
Laplace approximation provides well-calibrated uncertainty estimates that better identify difficult or ambiguous instances compared to margin-based confidence scores. The method treats the final layer weights of the auxiliary classifier as Bayesian parameters, computing predictive variance from both feature covariance and weight posterior. Monte Carlo sampling followed by softmax averaging yields entropy-based uncertainty estimates. Core assumption: high predictive entropy in early exit layers correlates with instances relying on spurious correlations.

### Mechanism 2: Entropy-Based Loss Reweighting
Reweighting the knowledge distillation loss using entropy from Laplace-approximated predictions reduces the influence of biased teacher signals on difficult instances. For each sample, compute weight w = exp(β · H(p)^α) where H(p) is the entropy of averaged softmax distribution. The total loss becomes L = w · L_KD + L_CE, meaning high-uncertainty instances receive stronger KD loss weighting.

### Mechanism 3: Intermediate-Layer Intervention
Placing the auxiliary uncertainty-estimation network on intermediate layers (layer 3 of 6) is more effective than final-layer placement for bias mitigation. Earlier layers capture more fundamental representations where spurious feature reliance can be detected and corrected before propagating through the network.

## Foundational Learning

- **Concept: Knowledge Distillation (KD) Fundamentals**
  - Why needed here: The entire method operates within a teacher-student framework where a compact student learns from a larger teacher's soft targets
  - Quick check question: Can you explain why temperature-scaled softmax outputs from a teacher contain more information than hard labels?

- **Concept: Laplace Approximation in Bayesian Deep Learning**
  - Why needed here: The core technical contribution applies last-layer Laplace approximation to estimate epistemic uncertainty without full Bayesian inference
  - Quick check question: Given a MAP-estimated weight matrix and feature covariance, how would you approximate the predictive variance for a new input?

- **Concept: Group Fairness and Spurious Correlations**
  - Why needed here: The paper targets fairness degradation when labels spuriously correlate with input attributes (e.g., negation patterns in NLI)
  - Quick check question: Why might overall accuracy remain high while worst-group accuracy degrades significantly?

## Architecture Onboarding

- **Component map:** BERT-base teacher -> DistilBERT student (6 layers) -> auxiliary linear classifier on layer 3 or 6 -> Laplace uncertainty module -> weighted loss combiner

- **Critical path:**
  1. Forward pass through student to target layer
  2. Extract CLS embedding φ
  3. Train auxiliary on (φ, y) with cross-entropy
  4. Compute Laplace covariance Σ_φ over batch
  5. Monte Carlo sample logits → softmax → entropy
  6. Compute weight w and combine losses
  7. Backprop through student only

- **Design tradeoffs:**
  - Auxiliary layer depth: Earlier layers (layer 3) showed better results but may require more careful tuning; later layers provide more mature features but less intervention opportunity
  - Simple vs. complex auxiliary: Single-layer auxiliary is computationally cheap but may underestimate uncertainty; multi-layer or ensembled approaches could improve calibration at cost of complexity
  - Reweighting target: Paper reweights L_KD only; simultaneous L_CE reweighting is unexplored

- **Failure signatures:**
  - Nan in covariance: Σ_φ may not be positive-definite with small batches; add ridge regularization
  - No accuracy improvement: Check that entropy actually varies across samples; constant entropy indicates Laplace not capturing meaningful uncertainty
  - Worse worst-group performance: May indicate inverted weighting logic or hyperparameter mismatch (α, β)

- **First 3 experiments:**
  1. Reproduce baseline: Run original DEDIER on MultiNLI subset with same hyperparameters; verify confidence margin distributions match Figure 1 pattern
  2. Ablation on auxiliary layer: Compare layer 3 vs. layer 6 placement with identical hyperparameters; expect layer 3 to show lower confidence margins and slightly higher accuracy
  3. Entropy distribution analysis: Before/after Laplace, plot entropy distributions for worst-group vs. other groups; verify that Laplace entropy distinguishes groups better than margin-based confidence

## Open Questions the Paper Calls Out

### Open Question 1
Does aggregating predictions across multiple early exit layers (deep ensembles) provide superior uncertainty estimates for reweighting compared to the single-layer auxiliary network used in this study? The current experiments utilized a simple, single-layer linear classifier for the auxiliary network to test the concept, leaving the potential benefits of multi-layer ensembling unexplored.

### Open Question 2
Can the Laplace approximation-based reweighting method maintain its effectiveness on datasets with different modalities or spurious correlation structures, such as Waterbirds or CelebA? The paper’s validation is currently restricted to the MultiNLI text dataset; performance on image datasets or datasets with different group biases is unknown.

### Open Question 3
Do the lower confidence margins observed in the Laplace-based approach indicate beneficial uncertainty (improved calibration) or detrimental weaker separation between correct and incorrect classes? While the paper reports improved accuracy, it does not provide calibration metrics to confirm if the reduced margins correlate with better probability estimation.

## Limitations
- Key hyperparameters (α, β, Monte Carlo sample count, ridge regularization) are unspecified and critical for reproduction
- Group fairness improvement claims lack direct subgroup performance validation; only aggregate accuracy metrics provided
- Assumption that entropy correlates with group-level bias is not empirically demonstrated
- Computational efficiency claims are asserted but not quantified with actual runtime or memory comparisons

## Confidence

- **High confidence:** Technical feasibility of Laplace approximation for uncertainty estimation in knowledge distillation (well-established Bayesian methods, directly implemented per Section 2 equations)
- **Medium confidence:** Layer 3 auxiliary placement outperforms layer 6 (supported by Table 1 results, but only one dataset tested)
- **Low confidence:** Method specifically improves group fairness (no subgroup accuracy data provided, only aggregate metrics)

## Next Checks

1. **Group-level validation:** Evaluate worst-group vs. other-group accuracy on MultiNLI negation subset to directly test the fairness improvement claim; reproduce Figure 1 confidence margin patterns for both group types

2. **Hyperparameter sensitivity:** Systematically sweep α and β values to identify optimal weighting; test whether performance improvements persist across different uncertainty weighting schemes

3. **Mechanism ablation:** Compare Laplace uncertainty estimates against simple margin-based confidence scores using identical reweighting framework; verify that Laplace provides meaningful additional information beyond basic confidence metrics