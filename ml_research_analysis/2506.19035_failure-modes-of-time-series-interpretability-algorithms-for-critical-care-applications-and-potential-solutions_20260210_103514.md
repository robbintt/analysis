---
ver: rpa2
title: Failure Modes of Time Series Interpretability Algorithms for Critical Care
  Applications and Potential Solutions
arxiv_id: '2506.19035'
source_url: https://arxiv.org/abs/2506.19035
tags:
- failure
- patient
- time
- methods
- circulatory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates interpretability algorithms for time series
  prediction in critical care, specifically dynamic circulatory failure prediction.
  It identifies two main failure modes in conventional methods: difficulty handling
  time-varying multi-output models and lack of temporal smoothness in attributions.'
---

# Failure Modes of Time Series Interpretability Algorithms for Critical Care Applications and Potential Solutions

## Quick Facts
- arXiv ID: 2506.19035
- Source URL: https://arxiv.org/abs/2506.19035
- Reference count: 22
- Primary result: Gradient, occlusion, and permutation-based methods produce temporally incoherent attributions that violate clinical causality; mask-based methods like DynaMask and ExtremalMask address these issues with temporal continuity constraints

## Executive Summary
This paper investigates interpretability algorithms for time series prediction in critical care, specifically dynamic circulatory failure prediction. It identifies two main failure modes in conventional methods: difficulty handling time-varying multi-output models and lack of temporal smoothness in attributions. Gradient, occlusion, and permutation-based methods produce attributions that violate clinical causality and lack temporal coherence, making it hard to trace the evolution of patient deterioration. The authors demonstrate that learnable mask-based methods like DynaMask and ExtremalMask address these issues by incorporating temporal continuity and label consistency constraints. Using a causal CrossFormer model on the HiRID-ICU dataset, they achieve 97.19% AUC-ROC and 68.05% AUC-PR, outperforming standard transformers. Mask-based approaches provide temporally coherent and causally consistent feature importance, offering more reliable insights for dynamic organ failure prediction tasks.

## Method Summary
The authors address dynamic circulatory failure prediction using a causal CrossFormer-Encoder architecture with triangular attention masking to prevent future information leakage. They evaluate 14 interpretability methods across gradient-based (GradientSHAP, DeepLift, Integrated Gradients), occlusion-based (Occlusion, Feature Ablation), permutation-based (Permutation), and mask-based approaches (DynaMask, ExtremalMask). The model processes 2016 timesteps × 231 features from the HiRID-ICU dataset, producing continuous binary predictions. Mask-based methods optimize learnable masks with temporal continuity and label consistency constraints, addressing the failure modes of conventional methods that struggle with temporal smoothness and causality violations.

## Key Results
- Causal CrossFormer achieves 97.19% AUC-ROC and 68.05% AUC-PR, outperforming standard transformers (90.26% AUC-ROC, 34.84% AUC-PR) while using 98% fewer parameters (28.6K vs 1.64M)
- Gradient, occlusion, and permutation methods produce attributions that violate clinical causality by incorporating future information to explain past events
- Mask-based methods (DynaMask, ExtremalMask) achieve significantly lower variance in attributions across time steps, ensuring temporal smoothness
- Feature-time attributions from mask-based methods score higher values before or close to event onset, demonstrating predictive rather than retrospective interpretation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Learnable mask-based interpretability methods produce more temporally coherent and causally consistent feature attributions than gradient, occlusion, or permutation-based methods for dynamic prediction tasks.
- Mechanism: DynaMask and ExtremalMask optimize masks over input time series by incorporating explicit constraints—temporal continuity, label consistency, sparsity, and minimal entropy—during the optimization process. DynaMask uses fixed local perturbations (e.g., Gaussian blur) on masked regions while optimizing the mask itself. ExtremalMask jointly learns both a binary mask and a context-aware perturbation function that adapts to the global temporal structure. These constraints prevent abrupt attribution changes between adjacent timesteps and ensure attribution scores reflect sustained pathophysiological patterns rather than isolated perturbations.
- Core assumption: Temporal smoothness in feature importance aligns with clinical reality—that patient deterioration evolves gradually and feature importance should reflect this continuity rather than pointwise fluctuations.
- Evidence anchors:
  - [abstract]: "Gradient, Occlusion, and Permutation-based methods often struggle with time-varying target dependency and temporal smoothness... learnable mask-based interpretability frameworks... can incorporate temporal continuity and label consistency constraints."
  - [Section 3.4]: "We observed that these methods achieve significantly lower variance in attributions across time steps, ensuring better temporal smoothness. Notably, the feature-time attributions produced by these mask-based methods score higher values before or close to the event onset."
  - [corpus]: Related work on dynamic clinical prediction (DynaGraph, Neural Point Processes) emphasizes capturing temporal trajectories, but corpus evidence specifically validating mask-based interpretability constraints is limited.
- Break condition: If clinical ground truth requires abrupt feature importance changes (e.g., sudden treatment interventions causing immediate state shifts), temporal smoothness constraints may obscure genuine discontinuities.

### Mechanism 2
- Claim: Causal attention masking prevents future information leakage in dynamic prediction, ensuring interpretations respect clinical causality.
- Mechanism: The authors modified CrossFormer-Encoder by applying a triangular causal attention mask that sets attention scores for future timesteps to negative infinity before softmax. This ensures predictions at timestep T depend only on timesteps ≤ T. When combined with interpretability methods, this architecture-level causality propagates to attribution maps—preventing the violation where "interpretability heatmaps at a specific time T often incorporate attribution scores influenced by future observations."
- Core assumption: Clinical decision-making strictly follows temporal causality—future observations should not influence interpretations of past events.
- Evidence anchors:
  - [Section 2.2]: "We modified the CrossFormer-Encoder model by introducing a causal attention mask... ensuring that predictions at each timestep strictly adheres to temporal causality."
  - [Section 3.2]: "This observation violates clinical causality by allowing future information to influence interpretations of past events."
  - [corpus]: Causally-informed DL approaches for critical care (arxiv:2502.02109) similarly emphasize causal structure for explainable predictions.
- Break condition: If the model architecture is non-causal (e.g., bidirectional processing for retrospective analysis), this mechanism does not apply.

### Mechanism 3
- Claim: Higher-performing models provide clearer, more informative interpretations, improving downstream interpretability quality.
- Mechanism: The causal CrossFormer (97.19% AUC-ROC, 68.05% AUC-PR) outperforms the standard transformer (90.26% AUC-ROC, 34.84% AUC-PR) while using 98% fewer parameters (28.6K vs 1.64M). The authors cite evidence that models with lower generalization error produce more meaningful attribution patterns. CrossFormer's segment-based embedding and cross-dimensional attention capture temporal dependencies more effectively, resulting in attribution maps that better reflect pathophysiological patterns.
- Core assumption: Model accuracy correlates positively with interpretation quality—better predictive patterns yield more meaningful feature attributions.
- Evidence anchors:
  - [Section 3.1]: "Recent research has indicated that models that achieve higher performance provide better interpretations—providing clearer insights into model behavior."
  - [Section 3.1, Table 3]: Quantitative performance comparison showing CrossFormer superiority across AUC-ROC, AUC-PR, F1, and MCC.
  - [corpus]: Limited corpus validation for accuracy-interpretability correlation in clinical time series specifically.
- Break condition: High accuracy through spurious correlations could produce confident but misleading interpretations; accuracy alone does not guarantee clinically meaningful attributions.

## Foundational Learning

- **Concept: Time-varying multi-output attribution structure (T × T × F × C)**
  - Why needed here: Dynamic prediction generates outputs at every timestep, creating high-dimensional attribution tensors that lack standard aggregation methods. Understanding this structure is essential for diagnosing Failure Mode 1.
  - Quick check question: For a model producing predictions at 2016 timesteps with 231 features and binary output, what is the full attribution shape for GradientSHAP, and why is temporal aggregation non-trivial?

- **Concept: Temporal smoothness vs. pointwise attribution**
  - Why needed here: Clinical deterioration evolves gradually. Methods like FIT use pointwise KL divergence, which "risks overemphasizing transient perturbations" rather than sustained patterns. Distinguishing smooth vs. abrupt attribution behavior is critical for method selection.
  - Quick check question: Why would a pointwise divergence measure produce noisy attributions in a 5-minute resolution ICU time series?

- **Concept: Causal vs. non-causal interpretation**
  - Why needed here: Interpretability methods may violate causality by allowing future timesteps to influence past attributions. Recognizing when occlusion/ablation methods introduce this leakage is necessary for valid clinical interpretation.
  - Quick check question: If feature occlusion at timestep T+100 affects the attribution map at timestep T=0, what clinical assumption has been violated?

## Architecture Onboarding

- **Component map**:
  - HiRID-ICU dataset (2016 timesteps × 231 features) -> Causal CrossFormer-Encoder (28.6K params, triangular attention mask) -> Dynamic binary predictions -> 14 interpretability methods -> Attribution maps (T × F)

- **Critical path**:
  1. Implement causal CrossFormer with triangular attention mask (prevents future leakage)
  2. Train on dynamic prediction task to convergence (target: >95% AUC-ROC)
  3. Apply DynaMask or ExtremalMask with temporal continuity + label consistency constraints
  4. Validate attribution coherence across adjacent timesteps during failure events

- **Design tradeoffs**:
  - DynaMask: Simpler, uses fixed local perturbations; may miss long-range dependencies
  - ExtremalMask: Learns context-aware perturbations; more complex but captures global temporal structure
  - Parameter efficiency (28.6K) vs. interpretability computation cost (mask optimization adds training overhead)

- **Failure signatures**:
  - Attributions vary significantly between adjacent 5-minute timesteps during stable patient states → indicates temporal incoherence
  - Non-empty attributions only at current timestep, empty for past timesteps → recency bias in gradient/SHAP methods
  - High attributions after failure onset rather than before → retrospective rather than predictive interpretation
  - Attribution maps resembling Gaussian noise → pointwise perturbation methods disrupting temporal continuity

- **First 3 experiments**:
  1. Reproduce causal CrossFormer performance on HiRID-ICU test set; verify AUC-ROC >97%, AUC-PR >68%
  2. Apply GradientSHAP vs. DynaMask to two patient records with multiple failure events; compare attribution variance across adjacent timesteps during failure events
  3. Quantify temporal coherence: compute attribution variance for consecutive timesteps (T=199,200 and T=1099,1100) across all 14 methods; validate that mask-based methods show lowest variance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do temporally coherent attributions perform in practical clinical settings, specifically within clinician-in-the-loop evaluations?
- Basis in paper: [explicit] The Discussion states that future research "could examine how temporally coherent attributions perform in practical settings, such as through clinician-in-the-loop evaluations."
- Why unresolved: The current study focuses on interpretability as a tool for model debugging rather than bedside decision support, leaving the clinical utility of these explanations untested.
- What evidence would resolve it: User studies with clinicians measuring decision quality, trust, or efficiency when using mask-based interpretability tools during patient monitoring.

### Open Question 2
- Question: What effective aggregation strategies exist for multi-dimensional attribution maps ($T \times T \times F \times C$) to identify sustained pathophysiological patterns?
- Basis in paper: [inferred] The authors note in Section 3.2 that for these complex maps, "it is not clear whether these maps should be averaged, merged using a rolling window or combined by some other method" to reveal persistent patterns.
- Why unresolved: Without standard aggregation methods, it remains difficult to trace how early indicators contribute to outcomes across dynamic time steps.
- What evidence would resolve it: Development and validation of aggregation algorithms that can summarize $T \times T$ attributions into a coherent temporal trajectory without violating causality.

### Open Question 3
- Question: Can learnable mask-based methods be enhanced to model long-range temporal dependencies in clinical time series?
- Basis in paper: [inferred] The authors state in Section 3.4 that DynaMask's "reliance on local perturbations limits the modeling of long-range dependencies common in clinical time series."
- Why unresolved: Clinical deterioration often depends on distant historical context, which current local perturbation strategies in mask-based methods may miss.
- What evidence would resolve it: Modifications to mask-based objective functions that successfully capture feature importance over extended time horizons.

## Limitations

- Clinical validation is primarily theoretical, relying on dataset statistics rather than physician review of attribution maps
- Comparison of interpretability methods focuses on two patient cases without systematic quantitative evaluation of temporal coherence across the full test set
- Assumes temporal smoothness is always desirable, but abrupt clinical events may require different treatment

## Confidence

- Causal CrossFormer performance claims (97.19% AUC-ROC, 68.05% AUC-PR): High
- Identified failure modes in conventional interpretability methods: High
- Clinical validity of interpretability quality: Low
- Accuracy-interpretability correlation evidence: Medium

## Next Checks

1. Quantitatively measure attribution variance across adjacent timesteps for all 14 methods on the full test set to validate temporal coherence claims
2. Conduct physician review of attribution maps from mask-based vs. gradient/occlusion methods to assess clinical validity
3. Test interpretability methods on synthetic time series with known temporal patterns to verify they capture ground truth feature importance