---
ver: rpa2
title: Rehearsal with Auxiliary-Informed Sampling for Audio Deepfake Detection
arxiv_id: '2505.24486'
source_url: https://arxiv.org/abs/2505.24486
tags:
- audio
- learning
- detection
- deepfake
- auxiliary
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces RAIS, a rehearsal-based continual learning
  approach for audio deepfake detection that improves sample diversity by generating
  auxiliary labels to guide sample selection. RAIS employs a label generation network
  to infer auxiliary labels via masked prediction, ensuring diverse and informative
  samples are retained in the memory buffer.
---

# Rehearsal with Auxiliary-Informed Sampling for Audio Deepfake Detection

## Quick Facts
- arXiv ID: 2505.24486
- Source URL: https://arxiv.org/abs/2505.24486
- Reference count: 0
- RAIS achieves average EER of 1.953% across five sequential audio deepfake detection experiences

## Executive Summary
This paper introduces RAIS (Rehearsal with Auxiliary-Informed Sampling), a rehearsal-based continual learning approach for audio deepfake detection that addresses catastrophic forgetting while maintaining high detection performance. The method uses a dual-module architecture with ADDM for binary classification and AAGM for generating auxiliary labels via masked prediction. RAIS outperforms state-of-the-art methods by achieving an average Equal Error Rate of 1.953% across five sequential experiences, closely matching the best possible performance of training on all data while being significantly more efficient through selective memory buffer management.

## Method Summary
RAIS employs a rehearsal-based continual learning framework that maintains a memory buffer of 256-512 samples and uses auxiliary-informed sampling to ensure diversity. The method uses two jointly trained modules: ADDM (Audio Deepfake Detection Module) for binary classification and AAGM (Audio Auxiliary Label Generation Module) for generating K=90 auxiliary labels. AAGM creates these labels through masked prediction, where 50% of the labels are masked and predicted to ensure diverse label assignment. The importance score s = ½(p_ŷ + p_mask[ŷ_aux]) combines primary classification confidence and auxiliary prediction to guide sample selection, with round-robin sampling across auxiliary label groups maintaining a fake/bona fide ratio of r=0.8.

## Key Results
- RAIS achieves average EER of 1.953% across five sequential experiences, outperforming joint training (3.509% EER) and other rehearsal methods (FAR=11.84%, BCT=7.70%, EWC=3.30%)
- Maintains strong performance on ASVspoof 2019 LA evaluation set after sequential learning (EER=0.30-1.61% across experiences)
- The auxiliary-informed sampling strategy reduces forgetting rate to F1=1.1%, significantly better than baseline rehearsal methods

## Why This Works (Mechanism)
RAIS addresses catastrophic forgetting in audio deepfake detection by maintaining sample diversity through auxiliary labels. The AAGM generates K=90 auxiliary labels via masked prediction, creating a diverse label space that captures different acoustic characteristics of deepfake attacks. By using importance scores that combine primary classification confidence and auxiliary prediction, RAIS ensures the memory buffer contains samples that are both informative for the main task and diverse across the auxiliary label space. This diversity helps prevent overfitting to specific attack types and maintains detection capability across new, unseen deepfake generation methods.

## Foundational Learning
- **Audio Deepfake Detection**: Identifying whether an audio sample is genuine or synthetically generated - needed for understanding the core task RAIS addresses
- **Catastrophic Forgetting**: When neural networks lose previously learned information when trained on new data - critical for understanding why continual learning is challenging
- **Rehearsal-based Continual Learning**: Maintaining a memory buffer of past samples to mitigate forgetting - the baseline approach RAIS improves upon
- **Masked Prediction**: A self-supervised learning technique where part of the input is masked and predicted - the mechanism AAGM uses to generate auxiliary labels
- **Equal Error Rate (EER)**: The error rate where false acceptance rate equals false rejection rate - the primary metric for evaluating deepfake detection performance
- **Importance Scoring**: Using confidence measures to select the most informative samples for memory buffer retention - the key innovation in RAIS's sample selection

## Architecture Onboarding
**Component Map**: Audio Input -> Wav2Vec2 -> AASIST -> ADDM/AAGM Heads -> Output
**Critical Path**: Wav2Vec2 (xls-r-300m) -> AASIST Feature Extraction -> ADDM (Classification) -> Binary Decision
**Design Tradeoffs**: Joint training of ADDM and AAGM enables coordinated learning but requires careful stop-gradient implementation; buffer size of 256-512 balances memory efficiency with performance; K=90 auxiliary labels provides sufficient diversity without excessive computational overhead
**Failure Signatures**: High EER on later experiences indicates catastrophic forgetting; poor auxiliary label diversity suggests masked prediction isn't generating informative labels; buffer imbalance (deviation from r=0.8 ratio) indicates sampling strategy issues
**First Experiments**: 1) Train ADDM alone on ASVspoof 2019 LA to establish baseline EER, 2) Implement AAGM with masked prediction to verify auxiliary label generation, 3) Test AIS with synthetic data to confirm round-robin sampling maintains diversity

## Open Questions the Paper Calls Out
### Open Question 1
What specific acoustic or paralinguistic features do the automatically generated auxiliary labels represent, and how do these latent representations evolve over sequential learning experiences? The paper notes that while AAGM optimizes for diversity via masked prediction, it does not guarantee semantically meaningful clusters, and future research should examine what these labels capture and how they evolve over time.

### Open Question 2
Can privacy-preserving mechanisms, such as differential privacy, be successfully integrated into RAIS without degrading the sample selection diversity or the final deepfake detection accuracy? The authors highlight that storing genuine audio may pose privacy concerns and suggest investigating privacy-preserving techniques like differential privacy to mitigate these risks.

### Open Question 3
How does RAIS perform in extensive continual learning scenarios involving significantly more than five experiences or infinite data streams? The paper mentions that future work should explore scalability for larger CL scenarios, as the current study is limited to five experiences and it's unclear if the fixed buffer size remains effective as the number of experiences grows.

## Limitations
- The interpretability of auxiliary labels remains unclear, as they are generated through masked prediction without semantic meaning guarantees
- Privacy concerns exist due to the rehearsal approach storing raw audio samples, which could be mitigated with differential privacy techniques
- Scalability to many more than five experiences is unproven, with potential issues around buffer saturation and segment fragmentation

## Confidence
**High**: The core RAIS methodology and reported average EER of 1.953% are well-supported by the paper's results and ablation studies, with reliable comparisons to joint training and other rehearsal methods.

**Medium**: Implementation details for data preprocessing and model architecture are likely correct but require verification, particularly the exact AASIST variant used and memory buffer management specifics.

## Next Checks
1. Verify AASIST feature extraction pipeline by reproducing results on ASVspoof 2019 LA alone before implementing the full CL sequence
2. Test the stop-gradient implementation by training with and without it to confirm its necessity for performance
3. Validate the round-robin sampling strategy by analyzing the auxiliary label distribution in the buffer after each experience