---
ver: rpa2
title: Bridging the AI Trustworthiness Gap between Functions and Norms
arxiv_id: '2512.20671'
source_url: https://arxiv.org/abs/2512.20671
tags:
- systems
- system
- trustworthiness
- functional
- framework
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper identifies a gap between functional and normative approaches
  to trustworthy AI, noting that developers struggle to map regulatory requirements
  to technical implementations. To address this, the authors propose a conceptual
  semantic language that bridges functional AI system properties to normative trustworthiness
  principles from frameworks like the EU AI Act.
---

# Bridging the AI Trustworthiness Gap between Functions and Norms

## Quick Facts
- arXiv ID: 2512.20671
- Source URL: https://arxiv.org/abs/2512.20671
- Reference count: 32
- The paper identifies a gap between functional and normative approaches to trustworthy AI, noting that developers struggle to map regulatory requirements to technical implementations.

## Executive Summary
The paper addresses the disconnect between technical AI system development and regulatory frameworks for trustworthy AI. Developers face challenges in translating abstract normative requirements from frameworks like the EU AI Act into concrete technical implementations. The authors propose a conceptual semantic language that bridges this gap by systematically linking AI system components' functions to trustworthiness principles, enabling developers to assess compliance and guide implementation decisions.

## Method Summary
The authors present a conceptual framework for a semantic language that maps functional AI system properties to normative trustworthiness principles. The approach involves creating systematic links between AI components and their trustworthiness aspects based on relevant standards and regulations. The proposed tool would support AI system description and generate trustworthiness insights to help developers navigate the compliance landscape. The methodology emphasizes the need for formalization (potentially in RDF format) and validation through real-world use cases.

## Key Results
- Identification of a critical gap between functional AI development and normative trustworthiness requirements
- Proposal of a conceptual semantic language to bridge functional AI components with trustworthiness principles
- Vision for a tool that enables systematic compliance assessment and implementation guidance for developers

## Why This Works (Mechanism)
The approach works by creating a structured mapping between the technical implementation space (functions, components, capabilities) and the normative space (principles, regulations, standards). This semantic bridge allows developers to reason about trustworthiness requirements in terms of their system's actual architecture and functionality, rather than abstract principles alone. By formalizing these relationships, the framework enables systematic compliance checking and provides actionable guidance for implementation decisions.

## Foundational Learning
- **Functional- Normative Gap Understanding**: Why needed - to recognize why developers struggle with regulatory compliance; Quick check - can you explain the difference between what an AI system does versus what it should do from a trustworthiness perspective?
- **Semantic Mapping Principles**: Why needed - to understand how abstract concepts can be linked to concrete implementations; Quick check - can you describe how one trustworthiness principle might map to multiple functional components?
- **RDF and Knowledge Representation**: Why needed - for formalizing the semantic language; Quick check - can you explain how RDF triples could represent the relationship between an AI component and a trustworthiness requirement?
- **EU AI Act Requirements**: Why needed - to ground the framework in actual regulatory obligations; Quick check - can you identify which trustworthiness principles map to specific AI Act requirements?

## Architecture Onboarding
- **Component Map**: AI System Components -> Functional Properties -> Normative Principles -> Compliance Assessment
- **Critical Path**: Developer describes AI system -> Tool maps components to trustworthiness aspects -> System generates compliance insights -> Developer implements required changes
- **Design Tradeoffs**: Flexibility vs. precision in semantic mappings; comprehensiveness vs. usability; abstraction level vs. practical applicability
- **Failure Signatures**: Incomplete mappings leading to compliance gaps; overly complex mappings reducing developer adoption; misalignment between technical capabilities and normative expectations
- **First Experiments**: 1) Map a simple AI system's components to basic trustworthiness principles; 2) Test the mapping process with developers unfamiliar with regulatory requirements; 3) Evaluate the completeness of the semantic links for a mid-complexity AI system

## Open Questions the Paper Calls Out
None

## Limitations
- The framework remains conceptual without empirical validation in real-world AI development scenarios
- No evidence provided that developers can successfully translate regulatory requirements into technical implementations using this approach
- The language's ability to capture the full complexity of both functional and normative AI trustworthiness dimensions is unverified

## Confidence
- High confidence in the identification of the gap between functional and normative approaches to trustworthy AI
- Medium confidence in the conceptual framework for bridging this gap
- Low confidence in the proposed semantic language's utility and practical applicability

## Next Checks
1. Implement a prototype of the semantic language in RDF format and test it with a small set of AI developers to assess usability and effectiveness in translating regulatory requirements to technical implementations.
2. Conduct a case study using the language to analyze an existing AI system against EU AI Act requirements, documenting the mapping process and identifying any gaps or ambiguities in the framework.
3. Perform a comparative analysis between the proposed semantic language approach and existing AI trustworthiness assessment tools to evaluate its unique value proposition and potential advantages in practical deployment scenarios.