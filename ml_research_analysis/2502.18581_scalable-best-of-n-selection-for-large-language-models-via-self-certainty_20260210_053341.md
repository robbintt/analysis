---
ver: rpa2
title: Scalable Best-of-N Selection for Large Language Models via Self-Certainty
arxiv_id: '2502.18581'
source_url: https://arxiv.org/abs/2502.18581
tags:
- self-certainty
- reasoning
- confidence
- borda
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes self-certainty, a novel metric for selecting
  the best response from multiple LLM-generated candidates in Best-of-N selection
  tasks. Self-certainty measures the divergence of the predicted token distribution
  from a uniform distribution, quantifying the model's confidence in its output.
---

# Scalable Best-of-N Selection for Large Language Models via Self-Certainty

## Quick Facts
- arXiv ID: 2502.18581
- Source URL: https://arxiv.org/abs/2502.18581
- Reference count: 38
- Authors: Zhewei Kang; Xuandong Zhao; Dawn Song
- One-line primary result: Self-certainty + Borda voting achieves 88.06% accuracy on MATH at N=64, outperforming self-consistency (87.62%) and greedy decoding (77.54%)

## Executive Summary
This paper introduces self-certainty, a novel metric for Best-of-N selection that measures distributional confidence via KL divergence from uniform. The method evaluates how peaked a model's predicted token distribution is at each position, with higher divergence indicating greater confidence. When combined with Borda voting that integrates frequency and confidence rankings, self-certainty-based selection consistently outperforms both self-consistency and greedy decoding across diverse reasoning benchmarks. The approach is computationally efficient as it leverages intrinsic LLM probability distributions without requiring external reward models.

## Method Summary
Self-certainty quantifies model confidence by computing the average KL divergence between the predicted token distribution and a uniform distribution across all tokens in a response. For each candidate response, token-level scores are averaged to produce an overall self-certainty score. These scores are then used to rank candidates, which are fed into a Borda voting system where votes are weighted by rank position using a power function v(r)=(N-r+1)^p. The method is designed to scale effectively with sample size N, complement chain-of-thought reasoning, and generalize to open-ended tasks.

## Key Results
- Self-certainty + Borda voting achieves 88.06% accuracy on MATH dataset at N=64
- Outperforms self-consistency (87.62%) and greedy decoding (77.54%) on same benchmark
- Self-certainty is more robust than perplexity to length bias and no-answer responses
- Method generalizes to open-ended tasks like code generation on LiveCodeBench
- Optimal Borda exponent p increases with sample size N (p≈0.3 for N≤16, p≈1.2 for N≥32)

## Why This Works (Mechanism)

### Mechanism 1: Distributional Confidence via KL Divergence from Uniform
- **Claim:** Higher self-certainty correlates with response correctness through peaked token distributions.
- **Mechanism:** Models trained via maximum likelihood produce peaked distributions when confident in correct outputs. The KL divergence from uniform quantifies this peakedness.
- **Core assumption:** Model calibration ensures peaked distributions reflect genuine knowledge rather than miscalibration.
- **Evidence anchors:** [abstract] "higher distributional self-certainty... correlates with improved response accuracy"; [section 3.4] "KL-divergence-inspired distributional confidence more effectively distinguishes correct samples"; [corpus] Similar confidence approaches exist but use external aggregation.

### Mechanism 2: Error Propagation Detection Through Averaged Token Scores
- **Claim:** Self-certainty identifies reasoning paths containing early errors because subsequent tokens inherit reduced confidence.
- **Mechanism:** When a reasoning step is incorrect, the model's distribution becomes less certain (more uniform-like) for tokens that follow, as the context diverges from training distribution.
- **Core assumption:** Errors early in reasoning produce distributional uncertainty that propagates forward.
- **Evidence anchors:** [section 3.5] "early errors propagate, reducing confidence in subsequent steps"; [Figure 2] Shows self-certainty distinguishing correct vs. incorrect reasoning paths; [corpus] No direct corpus evidence for this specific propagation mechanism.

### Mechanism 3: Borda Voting Integrates Frequency and Confidence Ranking
- **Claim:** Combining self-consistency (answer frequency) with self-certainty rankings via Borda-style weighted voting outperforms either method alone.
- **Mechanism:** Rank N candidates by self-certainty. Assign votes using v(r) = (N − r + 1)^p where r is rank and p is a tunable exponent. Each answer receives votes from all candidates producing it.
- **Core assumption:** Neither frequency nor confidence alone is sufficient; the optimal selection lies in their integration.
- **Evidence anchors:** [abstract] "When combined with Borda voting, self-certainty-based selection consistently outperforms self-consistency"; [section 4, Figure 3] Illustrates Borda voting correctly selecting an answer that both pure self-consistency and pure self-certainty miss; [corpus] ModeX similarly addresses evaluator-free selection but uses mode-finding.

## Foundational Learning

- **Concept: KL Divergence**
  - **Why needed here:** Self-certainty is defined as KL divergence from a uniform distribution. Understanding KL divergence as measuring "how different" one distribution is from another is essential.
  - **Quick check question:** If distribution p = [0.9, 0.1] and uniform U = [0.5, 0.5] over 2 tokens, is KL(U || p) higher or lower than if p = [0.6, 0.4]?

- **Concept: Best-of-N Selection**
  - **Why needed here:** The entire method operates within the Best-of-N paradigm—generate N candidates, select the best. Understanding this workflow and why it improves reasoning (coverage of solution space) is prerequisite.
  - **Quick check question:** Why might selecting the highest-reward candidate fail if the reward model is poorly calibrated?

- **Concept: Autoregressive Language Model Decoding**
  - **Why needed here:** Self-certainty operates on the token distributions produced at each decoding step. Understanding that p(y_i | x, y_{<i}) represents model belief over the vocabulary at position i is foundational.
  - **Quick check question:** At temperature T=0.6 with top-p=0.9, how does sampling differ from greedy decoding, and why does this matter for Best-of-N?

## Architecture Onboarding

- **Component map:** Sampling Module -> Self-Certainty Scorer -> Answer Extractor -> Borda Aggregator
- **Critical path:** Generate samples → Compute self-certainty for each → Extract answers → Rank candidates → Apply Borda weighting → Select highest-voted answer
- **Design tradeoffs:**
  - **Uniform vs. empirical reference distribution:** Paper tested empirical token distributions (Section B.4)—performed worse on GSM8K due to distribution shift. Uniform is more robust but ignores token-frequency priors.
  - **Averaging vs. min-pooling:** Paper uses averaging; PRMs/ORMs often use minimum scores. Averaging works here because error propagation naturally depresses scores; min-pooling is unnecessary.
  - **Parameter p tuning:** Optimal p scales with N. Heuristic: p≈0.3 for N≤16, p≈1.2 for N≥32. Grid search on validation set recommended.

- **Failure signatures:**
  - **High-confidence wrong answers:** If model is confidently wrong, self-certainty will rank these highly. Borda voting mitigates but doesn't eliminate this.
  - **No-answer responses:** Self-certainty correctly assigns low scores (Figure 1 shows this); perplexity incorrectly favors them.
  - **USC context overflow:** For large N with long CoT, universal self-consistency may exceed context windows (Table 1 notes omitted USC results).

- **First 3 experiments:**
  1. **Reproduce Figure 4 on a held-out dataset:** Compare KL-based self-certainty against perplexity, entropy, Gini across N=4,8,16,32,64. Verify KL continues improving at high N.
  2. **Ablate p parameter:** On a validation split of MATH, sweep p ∈ {0, 0.3, 0.5, 0.7, 1.0, 1.2, 1.5, 2.0} for N=16 and N=64. Confirm optimal p shifts upward with N.
  3. **Test on open-ended task:** Apply self-certainty (without voting) to code generation (LiveCodeBench or similar). Compare against greedy and USC; verify self-certainty generalizes where self-consistency cannot apply.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can data-driven approaches or non-linear aggregation functions improve upon the simple averaging and power-function voting currently used for self-certainty?
- **Basis in paper:** [explicit] Section 7: "Future work should explore more sophisticated aggregation functions or data-driven approaches for learning optimal vote weighting schemes to improve accuracy in specialized applications."
- **Why unresolved:** The current implementation relies on simple mean of token-level confidence and basic power function for Borda voting. It is unknown if these heuristics are optimal across different domains or model architectures.
- **What evidence would resolve it:** Experiments demonstrating that learned aggregation weights or adaptive functions yield statistically significant accuracy improvements over the mean-aggregation baseline on diverse reasoning benchmarks.

### Open Question 2
- **Question:** Is there a principled, adaptive method to determine the optimal Borda exponent \( p \) that avoids the computational cost of manual grid search?
- **Basis in paper:** [inferred] Section 6.2 notes that the optimal \( p \) varies significantly with sample size \( N \) and the specific task, and currently "grid search remains the most effective approach" for tuning this hyperparameter.
- **Why unresolved:** The reliance on grid search implies a lack of theoretical understanding or heuristics for dynamically setting \( p \). A fixed heuristic (e.g., \( p=1.2 \) for \( N \geq 32 \)) is proposed but not rigorously validated across all scenarios.
- **What evidence would resolve it:** The formulation of a theoretical relationship or an adaptive algorithm that sets \( p \) based on sample statistics (e.g., variance of confidence scores) and achieves performance comparable to exhaustive grid search.

### Open Question 3
- **Question:** Can self-certainty effectively serve as an intrinsic reward signal for reinforcement learning or fine-tuning, reducing reliance on external reward models?
- **Basis in paper:** [explicit] Section 7 suggests that self-certainty "offers potential value in... reinforcement learning pipelines... Specifically, self-certainty could guide reward shaping or provide intrinsic signals for autonomous agents."
- **Why unresolved:** The paper focuses exclusively on inference-time selection (Best-of-N). It does not investigate whether maximizing self-certainty during training actually improves reasoning capabilities or if it leads to reward hacking (e.g., generating overly peaked distributions without semantic correctness).
- **What evidence would resolve it:** Results from RL experiments (e.g., RLHF) where agents are trained to maximize self-certainty, showing improved reasoning performance without the computational overhead of training external reward models.

## Limitations

- **Calibration vulnerability:** Self-certainty relies on the assumption that distributional confidence accurately reflects correctness; systematic miscalibration could cause the method to fail.
- **Task dependence:** While effective on convergent-answer reasoning tasks, the method's effectiveness on truly open-ended generation remains less validated with limited experimental coverage.
- **Parameter tuning requirement:** The Borda voting exponent p requires careful tuning that depends on sample size and task, introducing computational overhead through grid search.

## Confidence

**High Confidence:** The core mechanism of self-certainty as KL divergence from uniform distribution is mathematically sound and the empirical results on MATH (88.06% at N=64) and GSM8K are compelling. The claim that self-certainty is more robust than perplexity to length bias is well-supported by Figure 5.

**Medium Confidence:** The assertion that self-certainty scales effectively with N is supported by experiments, but the diminishing returns at very