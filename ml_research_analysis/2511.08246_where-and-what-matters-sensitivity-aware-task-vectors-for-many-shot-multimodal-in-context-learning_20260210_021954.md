---
ver: rpa2
title: 'Where and What Matters: Sensitivity-Aware Task Vectors for Many-Shot Multimodal
  In-Context Learning'
arxiv_id: '2511.08246'
source_url: https://arxiv.org/abs/2511.08246
tags:
- task
- arxiv
- in-context
- vectors
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of scaling in-context learning
  for large multimodal models (LMMs) to many-shot scenarios, where the number of demonstrations
  is large, but context length and computational costs are limited. To address this,
  the authors propose a sensitivity-aware task vector insertion framework (STV) that
  identifies where and what to insert into the model's activation space.
---

# Where and What Matters: Sensitivity-Aware Task Vectors for Many-Shot Multimodal In-Context Learning

## Quick Facts
- arXiv ID: 2511.08246
- Source URL: https://arxiv.org/abs/2511.08246
- Authors: Ziyu Ma; Chenhui Gou; Yiming Hu; Yong Wang; Xiangxiang Chu; Bohan Zhuang; Jianfei Cai
- Reference count: 7
- Primary result: Sensitivity-aware task vector insertion achieves up to +26.7% accuracy gains over standard ICL for many-shot multimodal in-context learning

## Executive Summary
This paper addresses the challenge of scaling in-context learning for large multimodal models (LMMs) to many-shot scenarios while managing context length and computational costs. The authors propose a sensitivity-aware task vector insertion framework (STV) that identifies where and what to insert into the model's activation space. Their method uses activation deltas to locate context-sensitive attention heads and reinforcement learning to select the most effective task vectors from a pre-clustered bank. Evaluated on Qwen-VL and Idefics2 across five vision-language benchmarks, STV consistently outperforms previous task-vector-based methods while reducing location search time by 98%.

## Method Summary
STV uses a two-stage approach: first, it computes activation deltas across query-context pairs to identify the top-K=64 sensitive attention heads as insertion locations; second, it builds a pre-clustered activation bank using K-means clustering and employs reinforcement learning to select the most effective task vectors from this bank. The method inserts learned task vectors into the activation space at identified sensitive locations, enabling many-shot in-context learning without increasing context length. The RL policy optimizes learnable logits over categorical distributions of clustered candidates, with variance-normalized rewards guiding the selection process.

## Key Results
- Achieves up to +26.7% accuracy gains over standard ICL and +20.15% over previous state-of-the-art
- Reduces location search time by 98% while maintaining strong performance
- Demonstrates consistent improvements across five benchmarks (VizWiz, OK-VQA, DTD, Flowers, CUB) using Qwen-VL-7B and Idefics2-8B models
- Ablation studies show optimal performance with K=64 insertion locations

## Why This Works (Mechanism)
The method works by identifying attention heads that are most sensitive to context changes through activation delta analysis, then inserting learned task vectors at these locations to guide model behavior. The reinforcement learning component selects the most effective vectors from a pre-clustered bank, allowing the model to leverage many-shot demonstrations without exceeding context length limits. This approach combines precise location identification with efficient vector selection to optimize the in-context learning process.

## Foundational Learning

**Attention Head Activations**: Internal representations from transformer attention mechanisms
- Why needed: Forms the basis for identifying sensitive locations and storing task-relevant information
- Quick check: Verify attention head outputs have expected dimensionality and values

**Activation Deltas**: Difference between query-only and query-context activations
- Why needed: Quantifies which attention heads are most affected by context, indicating sensitivity
- Quick check: Compute deltas across sample pairs and verify sensitivity patterns

**K-means Clustering**: Unsupervised grouping of activation vectors into clusters
- Why needed: Creates a discrete bank of task vectors that can be efficiently searched via RL
- Quick check: Validate cluster centroids capture meaningful variation in activation space

**REINFORCE Algorithm**: Policy gradient method for discrete action selection
- Why needed: Optimizes the selection of task vectors from the clustered bank
- Quick check: Monitor policy loss convergence and reward variance normalization

## Architecture Onboarding

**Component Map**: Query -> Attention Heads -> Activation Extraction -> Delta Computation -> Location Selection -> Activation Bank -> RL Policy -> Task Vector Insertion -> Output

**Critical Path**: The RL policy optimization loop is critical, as it determines which task vectors are selected for insertion at sensitive locations

## Open Questions the Paper Calls Out
The paper identifies several areas for future research, including exploring more sophisticated clustering methods beyond K-means, investigating alternative reinforcement learning algorithms for task vector selection, and extending the framework to handle even longer context lengths. The authors also note that understanding the semantic meaning of selected task vectors and their relationship to specific tasks remains an open question.

## Limitations
The primary limitation is the computational overhead of the initial sensitivity analysis phase, which requires computing activation deltas across all query-context pairs. While the location search is reduced by 98%, the upfront cost may be prohibitive for extremely large models or datasets. Additionally, the method relies on having a pre-clustered activation bank, which requires significant storage and may not generalize well to novel tasks. The performance gains, while substantial, may not justify the additional complexity for all use cases.

## Confidence
High confidence in the technical accuracy of the method description and results. The paper provides clear experimental details and ablation studies supporting their claims. The approach appears novel in combining sensitivity analysis with reinforcement learning for task vector selection in multimodal settings.

## Next Checks
- Verify the computational complexity of the sensitivity analysis phase scales linearly with context size
- Investigate whether the pre-clustered activation bank can be dynamically updated during training
- Test the framework on additional multimodal tasks beyond the five benchmarks presented
- Compare STV performance against other context compression techniques for many-shot ICL