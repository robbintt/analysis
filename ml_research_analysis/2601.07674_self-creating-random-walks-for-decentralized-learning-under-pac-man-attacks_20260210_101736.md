---
ver: rpa2
title: Self-Creating Random Walks for Decentralized Learning under Pac-Man Attacks
arxiv_id: '2601.07674'
source_url: https://arxiv.org/abs/2601.07674
tags:
- pac-man
- node
- graph
- algorithm
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the vulnerability of random-walk (RW)-based
  decentralized learning algorithms to a novel "Pac-Man" attack, where a malicious
  node probabilistically terminates any RW that visits it, effectively halting the
  learning process. The authors propose the CREATE-IF-LATE (CIL) algorithm, a fully
  decentralized mechanism that enables self-creating RWs to prevent extinction.
---

# Self-Creating Random Walks for Decentralized Learning under Pac-Man Attacks

## Quick Facts
- arXiv ID: 2601.07674
- Source URL: https://arxiv.org/abs/2601.07674
- Reference count: 40
- One-line primary result: A fully decentralized algorithm that enables random walks to self-create, preventing extinction under Pac-Man attacks while guaranteeing convergence to a biased but quantifiable optimum.

## Executive Summary
This paper introduces a novel "Pac-Man" attack on decentralized learning, where a malicious node probabilistically terminates any random walk that visits it, halting the learning process. The authors propose the CREATE-IF-LATE (CIL) algorithm, a fully decentralized mechanism that enables random walks to self-create, preventing extinction. CIL ensures almost sure non-extinction and boundedness of the random walk population, and convergence of RW-SGD even under attack, with quantifiable deviation from the true optimum. Theoretical analysis shows the RW population remains bounded at O(qN²/ζ), and convergence is achieved with a lower bound of N/(N + A - 1 + 1/q) on effective learning iterations.

## Method Summary
The CREATE-IF-LATE (CIL) algorithm enables decentralized learning under Pac-Man attacks by allowing nodes to probabilistically spawn new random walks when their local timer exceeds a threshold. Each node tracks the last visit time of a random walk and, if the elapsed time exceeds A_u, creates a new walk by replicating the most recent visitor's state with probability q. This decentralized timeout mechanism acts as a heartbeat monitor, ensuring regeneration if all walks die. The algorithm guarantees system stability (no resource blowup) despite unregulated creation, as termination is global and introduces a negative drift term in population dynamics. For convergence, RW-SGD converges to a biased solution due to the altered sampling distribution from the Pac-Man attack, with the error quantified under strong convexity and smoothness assumptions.

## Key Results
- CIL guarantees almost sure non-extinction and boundedness of the RW population under Pac-Man attacks.
- Theoretical analysis shows the RW population remains bounded at O(qN²/ζ), with a quantifiable deviation from the true optimum.
- Convergence is achieved with a lower bound of N/(N + A - 1 + 1/q) on the fraction of effective learning iterations.
- Empirical results validate theoretical findings, demonstrating CIL maintains learning effectiveness under adversarial conditions while avoiding permanent extinction.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The CREATE-IF-LATE (CIL) mechanism prevents permanent system halt by ensuring the Random Walk (RW) population recovers from zero without global coordination.
- **Mechanism:** Each benign node maintains a local timer L(u)_t recording the last time a RW visited. If the elapsed time exceeds a local threshold A_u, the node probabilistically creates a new RW by cloning the state of the most recent visitor. This decentralized timeout acts as a "heartbeat" monitor; if all walks die, timers eventually expire, triggering regeneration.
- **Core assumption:** Benign nodes have sufficient local memory to store the model state of the last visiting RW and the timer.
- **Evidence anchors:**
  - [abstract] "fully decentralized, resilient mechanism that enables self-creating RWs"
  - [section III] "node u infers a possible RW termination... and probabilistically creates a new RW by replicating the most recently visited one."
  - [corpus] Weak support; neighbors focus on general FL attacks rather than RW regeneration mechanics.
- **Break condition:** If malicious nodes can manipulate the local timer logic or prevent the storage of the last-visited state, regeneration fails.

### Mechanism 2
- **Claim:** The algorithm guarantees system stability (no resource blowup) despite unregulated RW creation.
- **Mechanism:** While creation is local, termination is global. The expected "death rate" of RWs scales with the number of active RWs (more walks mean more chances to hit the malicious node). This introduces a negative drift term -cζZ_t in the population dynamics, mathematically forcing the population to remain almost surely bounded regardless of the creation threshold A_u.
- **Core assumption:** The graph is "robustly connected," meaning the Pac-Man node cannot partition the network, and the mixing time allows visits to the malicious node.
- **Evidence anchors:**
  - [section V] "Theorem 1... lim sup Z_t < infinity almost surely."
  - [section V] "E[Z_{t+d} - Z_t | F_t] <= -cζZ_t + (N-1)d"
  - [corpus] Not explicitly covered in neighbor abstracts.
- **Break condition:** If the graph diameter d is extremely large or the probability of hitting the Pac-Man c is negligible (e.g., the malicious node is isolated), the negative drift may fail to counteract creation.

### Mechanism 3
- **Claim:** RW-SGD converges to a solution, but the solution is biased relative to the true global optimum.
- **Mechanism:** Because the RW is eventually terminated upon visiting the malicious node, the effective sampling distribution excludes (or under-samples) the malicious node's data. The paper models the "chain" of regenerated RWs as a single effective RW following a quasi-stationary distribution. Convergence is guaranteed to the minimum of this skewed objective, not the true global objective.
- **Core assumption:** The local loss functions are strongly convex and smooth (Assumption 3).
- **Evidence anchors:**
  - [abstract] "convergence... with a quantifiable deviation from the true optimum."
  - [section VI] "RW-SGD converges to the minimizer of... [a modified objective]... effectively transition matrix depends explicitly on the termination probability."
  - [corpus] Weak support; general FL papers mention convergence but not quasi-stationary distributions.
- **Break condition:** If the malicious node holds critical data that shifts the global optimum significantly, the error bound ||x̃* - x*|| becomes large, rendering the "biased optimum" useless.

## Foundational Learning

### Concept: Markov Chain Mixing Times & Stationary Distributions
- **Why needed here:** To understand why the optimum shifts. Standard RW-SGD relies on the stationary distribution to sample data proportionally. The Pac-Man attack alters the effective transition matrix, changing the stationary distribution to the "quasi-stationary" one, which the engineer must grasp to diagnose bias.
- **Quick check question:** If you block a node in a Markov chain, does the new stationary distribution re-weight the remaining nodes uniformly or proportional to their original connectivity?

### Concept: Drift Analysis (Lyapunov Functions)
- **Why needed here:** To trust the stability guarantees. The paper proves boundedness not by hard limits, but by showing the expected change in population (drift) becomes negative when the population is high. This is critical for understanding why the system doesn't crash.
- **Quick check question:** In a birth-death process, if the expected "death rate" scales linearly with population while the "birth rate" is constant, what happens to the population size as time goes to infinity?

### Concept: Decentralized Random Walk SGD
- **Why needed here:** This is the underlying workload. Unlike Gossip, which broadcasts, RW-SGD passes a single token. Understanding this distinction is vital for implementing the "local update" logic correctly.
- **Quick check question:** How does the communication overhead of RW-SGD scale with the number of edges compared to Gossip-based SGD?

## Architecture Onboarding

### Component map:
- **Benign Nodes:** Store local model x, timer L(u)_t, and a cache of the last visiting RW's state.
- **Pac-Man Node:** A logical sink that absorbs tokens with probability ζ (effectively removing them from the network).
- **Token/RW:** A packet containing the current global model parameters x_t.
- **CIL Logic:** A local guard routine checking if current_time - last_visit_time > threshold.

### Critical path:
1. RW arrives at Node u.
2. Node u updates model: x_{t+1} = x_t - γ∇f_u(x_t).
3. Node u resets timer L(u)_t and caches x_{t+1}.
4. Node u checks CIL logic (if timer expired, spawn child RW).
5. RW moves to random neighbor v.

### Design tradeoffs:
- **Threshold A:** Low A implies faster recovery from attacks (less "inactive time") but higher steady-state RW population (higher bandwidth). High A saves bandwidth but risks long learning pauses.
- **Creation Prob q:** High q ensures robust recovery but increases the peak population bound O(qN²/ζ).

### Failure signatures:
- **Permanent Extinction:** (Theoretical in CIL, but monitorable) Z_t = 0 for extended periods suggests logic bugs or parameter misconfiguration (e.g., thresholds too high relative to attack rate).
- **Bias Drift:** Model converges to a value that performs well on benign nodes but fails validation on the global dataset.

### First 3 experiments:
1. **Population Stability Test:** Run CIL on a complete graph (N=100) with one Pac-Man. Plot Z_t vs. time. Verify it remains bounded (Section VII, Fig 5) and recovers from 0.
2. **Convergence Bias Measurement:** Compare final model accuracy of CIL-RW-SGD vs. Standard SGD (no attack) on non-IID data. Quantify the gap ||x̃* - x*|| (Section VII, Table IV).
3. **Threshold Sensitivity:** Vary A (e.g., 10 vs 350). Measure the "inactive time" (flat segments in loss curve) and total convergence time to validate the linear delay bound.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the bias induced by the Pac-Man's non-participation be corrected online, or can the malicious node be identified using the local timing data?
- **Basis in paper:** [explicit] Theorem 3 and Proposition 1 prove that RW-SGD converges to a biased optimum x̃*, quantifying the deviation from the true global minimum x*.
- **Why unresolved:** The paper establishes the existence and bounds of this bias but does not propose a mechanism to recover the true gradient direction or to isolate the malicious node based on visitation timestamps.
- **What evidence would resolve it:** An extension of the CIL framework that achieves convergence to the true optimum x* or a provably correct identification protocol for the malicious node.

### Open Question 2
- **Question:** What are the precise population bounds and convergence rates for CIL on sparse or irregular graph topologies?
- **Basis in paper:** [explicit] Theorem 2 provides an upper bound on the peak RW population (O(qN²/ζ)) only for complete graphs, noting in Remark 8 that bounds for other topologies become "more complicated."
- **Why unresolved:** The mixing properties of sparse graphs (e.g., rings) differ significantly from complete graphs, potentially altering the creation rate and stability thresholds derived in the current analysis.
- **What evidence would resolve it:** A derivation of the expected peak population Z̄* as a function of graph diameter or spectral gap for general connected graphs.

### Open Question 3
- **Question:** How can the creation threshold A_u and probability q be dynamically optimized to balance communication overhead against convergence speed?
- **Basis in paper:** [inferred] Section III.A discusses the trade-off where large A reduces cost but slows task completion, while small A increases cost and speed.
- **Why unresolved:** The paper analyzes stability for fixed parameters but does not explore adaptive parameter tuning to minimize total communication cost while guaranteeing convergence time constraints.
- **What evidence would resolve it:** An adaptive control algorithm for A_u that minimizes a utility function combining communication cost and loss decay rate.

## Limitations

- **Population bound tightness:** The theoretical bound O(qN²/ζ) on the expected peak RW population is derived under idealized assumptions. Empirical validation is limited to specific graph structures and attack configurations, leaving open the question of scalability in highly sparse or adversarial networks.
- **Convergence error characterization:** While the paper quantifies the deviation from the true global optimum, the error bounds rely on strong convexity and smoothness assumptions. For non-convex, real-world models (e.g., deep neural networks), the convergence guarantees and bias effects remain unclear.
- **Parameter sensitivity:** The choice of creation threshold A and probability q critically impacts both population stability and learning speed. The paper uses q=1, but the theoretical recommendation q=O(1/N²) suggests that higher q values may lead to resource blowup in larger networks, though this is not explicitly explored.

## Confidence

- **High:** Claims about almost sure non-extinction and boundedness of the RW population under the CIL mechanism, as these are rigorously proven via stochastic process analysis.
- **Medium:** Convergence of RW-SGD to a biased optimum, given that the error bounds depend on strong assumptions (convexity, smoothness) that may not hold in practice.
- **Low:** Generalization of results to large-scale, non-convex models and highly sparse or adversarial networks, due to limited empirical validation and strong theoretical assumptions.

## Next Validation Checks

1. **Population Stability Across Graph Topologies:** Reproduce the population stability experiments on highly sparse graphs (e.g., ring with d=2) and scale up to N=1000 nodes. Measure whether the population remains bounded and whether the O(qN²/ζ) scaling holds.
2. **Convergence under Non-Convex Models:** Implement CIL-RW-SGD with a convolutional neural network (e.g., LeNet-5) on MNIST or CIFAR-10. Compare final test accuracy against centralized SGD and standard RW-SGD (no attack) to quantify the impact of bias and convergence slowdown.
3. **Robustness to Multi-Malicious Node Attacks:** Introduce multiple Pac-Man nodes (e.g., 10% of nodes) in a complete graph. Measure the effective learning rate (fraction of non-terminated RW iterations) and population dynamics. Test whether CIL still prevents permanent extinction or if a new attack threshold emerges.