---
ver: rpa2
title: Logit-Entropy Adaptive Stopping Heuristic for Efficient Chain-of-Thought Reasoning
arxiv_id: '2511.04654'
source_url: https://arxiv.org/abs/2511.04654
tags:
- reasoning
- latency
- entropy
- stopping
- rationale
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces LEASH, a training-free decoding algorithm\
  \ that adaptively halts chain-of-thought generation in large language models by\
  \ monitoring intrinsic signals\u2014token-level entropy slope and top-logit margin\
  \ improvement. LEASH stops generation when both signals plateau, indicating reasoning\
  \ convergence."
---

# Logit-Entropy Adaptive Stopping Heuristic for Efficient Chain-of-Thought Reasoning

## Quick Facts
- **arXiv ID**: 2511.04654
- **Source URL**: https://arxiv.org/abs/2511.04654
- **Reference count**: 11
- **Primary result**: LEASH achieves 30-35% token reduction and ~27% latency reduction in CoT reasoning, at ~10 p.p. accuracy drop

## Executive Summary
This paper introduces LEASH, a training-free decoding algorithm that adaptively halts chain-of-thought generation in large language models by monitoring intrinsic signals—token-level entropy slope and top-logit margin improvement. LEASH stops generation when both signals plateau, indicating reasoning convergence. Evaluated across four instruction-tuned models on GSM8K and AQuA-RAT benchmarks, LEASH reduces average token generation by 30–35% and latency by ~27%, while incurring a ~10 percentage point accuracy drop compared to standard CoT. The method is model-agnostic, requires no additional training or supervision, and integrates seamlessly with standard decoding APIs, including quantized inference.

## Method Summary
LEASH is a training-free adaptive early stopping heuristic for chain-of-thought reasoning. It computes per-token entropy and top-two log-probability margin, tracks their windowed slopes, and halts generation when both signals plateau (entropy slope flattens, margin improvement stalls) after a warm-up period and with majority voting over non-saturated steps. The method uses ring buffers for O(1) memory, requires only logit access, and triggers a final answer prompt after stopping.

## Key Results
- Token reduction: 30-35% fewer tokens generated on average
- Latency reduction: ~27% faster inference
- Accuracy trade-off: ~10 p.p. drop vs vanilla CoT on GSM8K
- Model coverage: Evaluated on Llama-3.1-8B-Instruct, Mistral-7B-v0.1, Phi-3-Mini-128k-Instruct, Qwen2.5-7B-Instruct

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Flattening entropy slope indicates reasoning convergence.
- Mechanism: LEASH computes a windowed slope sH(t;k) = (Ht - Ht-k)/k over token-level entropy. When uncertainty stops decreasing, the slope approaches zero, suggesting the model has extracted most informational value from the reasoning chain.
- Core assumption: Decreasing entropy correlates with progress toward a stable answer state.
- Evidence anchors:
  - [abstract] "monitors two intrinsic signals: the slope of token-level entropy and the improvement in the top-logit margin. It terminates the generation once both signals plateau, indicating the model has reached a stable reasoning state."
  - [section 2] Equation (4) defines entropy slope; Equation (6) requires sH(t;k) ≥ -εH for plateau detection.
  - [corpus] Neighbor paper "Early Stopping Chain-of-thoughts in Large Language Models" (ES-CoT) similarly uses answer convergence signals, though via different metrics.
- Break condition: If entropy remains high but flat (model is stuck uncertain), stopping may be premature.

### Mechanism 2
- Claim: Stalling margin improvement signals confidence saturation.
- Mechanism: The top-logit margin Mt = ℓt^(1) - ℓt^(2) measures the gap between the top two token probabilities. When ΔM(t;k) ≤ δM over the window, the model is no longer gaining confidence in its top choice.
- Core assumption: Margin improvement reflects meaningful reasoning progress; stalling means diminishing returns.
- Evidence anchors:
  - [section 2] "Mt = ℓt^(1) - ℓt^(2) ... While Mt is algebraically equivalent to the logit-space margin, we compute it using log-probabilities for numerical stability."
  - [section 2] Equation (6) requires ΔM(t;k) ≤ δM alongside entropy condition.
  - [corpus] Limited direct corpus support for margin specifically; most related work uses entropy or external verifiers.
- Break condition: High margin early (very confident) could trigger premature halt if not guarded.

### Mechanism 3
- Claim: Dual-signal voting with warm-up and saturation guards prevents premature and spurious stops.
- Mechanism: Three safety layers: (i) warm-up period tmin ensures minimum reasoning; (ii) saturation guard Σt excludes steps where pmax ≥ τp (already confident); (iii) majority voting over L non-saturated steps requires consensus before halting.
- Core assumption: Early tokens are exploratory; saturated steps shouldn't influence stopping; consensus reduces noise.
- Evidence anchors:
  - [section 2] "Highly confident steps, where pmax ≥ τp, are treated as 'saturated' and are excluded from our trend analysis."
  - [section 2] Equation (7) defines stopping time with tmin, voting threshold, and entropy-drop gate Href - Ht ≥ γ.
  - [corpus] "Stop When Enough" paper similarly uses adaptive thresholds but requires training; LEASH is training-free.
- Break condition: Poorly tuned τp or γ could either over-exclude or fail to guard against noise.

## Foundational Learning

- Concept: Token-level entropy in language models
  - Why needed here: LEASH relies on entropy as a proxy for model uncertainty. You must understand H = -Σ p(v)log p(v) to interpret why flattening entropy might indicate convergence.
  - Quick check question: If a model assigns probabilities [0.7, 0.2, 0.1] to three tokens, what is the entropy? Would it be higher or lower if the distribution were [0.95, 0.03, 0.02]?

- Concept: Logit margin vs. probability margin
  - Why needed here: The paper computes margin in log-probability space for stability. Understanding why log-space helps with numerical precision is essential for correct implementation.
  - Quick check question: Why might log-probability margins be more numerically stable than raw probability margins when values approach 0?

- Concept: Sliding window statistics and voting logic
  - Why needed here: LEASH uses windowed slopes and majority voting over L steps. Understanding how window size affects signal smoothness vs. responsiveness is critical for tuning.
  - Quick check question: If L=5 and 2 of the last 5 non-saturated steps pass the plateau test, does LEASH halt? What if L=3?

## Architecture Onboarding

- Component map:
  - Logit extractor: upcasts to fp32, clips to [-B, B], computes softmax and log-softmax
  - Signal buffer: ring buffers (O(1) memory) storing last k values of Ht and Mt
  - Plateau detector: computes sH and ΔM, applies tolerances εH, δM
  - Saturation filter: checks pmax ≥ τp, marks steps as Σt
  - Voting aggregator: counts Πj over JL(t), triggers halt on majority
  - Answer prompter: after halt, queries model for short final answer

- Critical path: Decode token → compute logits → calculate Ht, Mt → check saturation → update buffers → evaluate plateau test → aggregate votes → halt or continue. The entropy-drop gate (Href - Ht ≥ γ) is evaluated at t ≥ tmin and must pass before voting is checked.

- Design tradeoffs:
  - Smaller k: more responsive but noisier slopes; larger k: smoother but slower to react
  - Larger L: more robust consensus but may delay stopping
  - Higher τp: more steps excluded from voting (may under-utilize signal); lower τp: risk including overconfident noise
  - The 10 p.p. accuracy drop vs. 30-35% token savings is the core tradeoff; tuning hyperparameters shifts this frontier

- Failure signatures:
  - Premature stops on hard problems: check if γ is too low or warm-up too short
  - No stops until max length: check if εH, δM are too tight; verify saturation filter isn't excluding all steps
  - High variance across temperatures: LEASH hyperparameters may need temperature-specific tuning (paper claims robustness, but verify)

- First 3 experiments:
  1. Replicate GSM8K results on Llama-3.1-8B-Instruct with paper's hyperparameters (k=8, L=5, εH=0.005, δM=0.05, m=64, M=320). Verify token reduction matches ~31% and accuracy ~62%.
  2. Ablate each signal individually (entropy-only, margin-only) to measure contribution of dual-signal design vs. single-signal variants.
  3. Stress-test on out-of-domain tasks (e.g., longer-form reasoning or non-numeric answers) to characterize where the entropy-margin convergence assumption breaks down.

## Open Questions the Paper Calls Out
- Can LEASH be effectively extended to long-form, non-numeric targets and tool-augmented reasoning settings?
- What theoretical guarantees can be derived regarding the stopping criteria relative to reasoning convergence?
- Can adaptive stopping be achieved in black-box API settings where raw token logits are unavailable?

## Limitations
- Underspecified hyperparameters (τp, γ, B, w) block exact reproduction
- Limited task diversity: only evaluated on GSM8K and AQuA-RAT arithmetic benchmarks
- Single-shot CoT without verification or refinement; cannot recover from early stopping errors
- 10 p.p. accuracy drop is the dominant efficiency-accuracy tradeoff

## Confidence
- **High confidence**: The core mechanism (entropy slope + margin improvement + voting) is clearly described and implemented in a training-free, model-agnostic way. The dual-signal design is novel and technically sound.
- **Medium confidence**: The 30-35% token reduction and ~27% latency improvement are plausible given the reported average reasoning length (~200 tokens) and latency measurements. However, these depend heavily on the unspecified hyperparameters.
- **Low confidence**: The 10 percentage point accuracy drop is the dominant limitation. Without the exact stopping hyperparameters and prompt templates, it is unclear whether this drop is inherent to the method or a result of suboptimal tuning.

## Next Checks
1. Replicate the core results on GSM8K with Llama-3.1-8B-Instruct using the paper's exact hyperparameters (k=8, L=5, εH=0.005, δM=0.05, m=64, M=320). Verify token reduction (~31%) and accuracy (~62%) match the paper. If not, vary τp and γ to understand their impact.
2. Ablation study: Compare LEASH's dual-signal stopping to entropy-only and margin-only variants. Measure token savings and accuracy for each to quantify the marginal benefit of the dual-signal design.
3. Cross-task robustness check: Apply LEASH to a non-arithmetic reasoning task (e.g., strategyQA or common sense reasoning) and measure whether entropy-margin convergence still predicts successful stopping. Compare accuracy retention and token savings to GSM8K.