---
ver: rpa2
title: 'PtyGenography: using generative models for regularization of the phase retrieval
  problem'
arxiv_id: '2502.01338'
source_url: https://arxiv.org/abs/2502.01338
tags:
- generative
- reconstruction
- phase
- retrieval
- noise
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the stability of phase retrieval solutions
  across varying noise levels. The authors analyze the reconstruction error of classical
  (Tikhonov) and generative model-based approaches, showing that generative models
  reduce noise amplification at the cost of introducing bias.
---

# PtyGenography: using generative models for regularization of the phase retrieval problem

## Quick Facts
- arXiv ID: 2502.01338
- Source URL: https://arxiv.org/abs/2502.01338
- Reference count: 27
- Primary result: Generative models reduce noise amplification in phase retrieval at the cost of introducing bias; a unified variational framework interpolates between classical and generative approaches for improved performance across noise levels.

## Executive Summary
This paper addresses the stability of phase retrieval solutions across varying noise levels by analyzing classical (Tikhonov) and generative model-based approaches. The authors show that generative models improve conditioning and reduce noise amplification, but introduce bias proportional to model mismatch. They propose a unified variational framework that interpolates between these methods, achieving better performance for both low and high noise levels. Numerical experiments on masked Fourier phase retrieval with handwritten digits demonstrate that the combined approach outperforms both pure classical and pure generative methods, particularly in out-of-distribution scenarios.

## Method Summary
The method tackles phase retrieval from masked Fourier measurements, recovering signals from noisy intensity measurements. A generative model G(z) = Gz + b is trained via PCA on domain-specific data. Three formulations are compared: classical (Tikhonov regularization), generative (constraining solutions to range of G), and unified (combining both with interpolation parameter λ). L-BFGS optimization solves the unified objective min_{z,f} ||A(f) - y||₂² + λ²||G(z) - f||₂². The approach is validated on 8×8 handwritten digits with 100 random binary probes.

## Key Results
- Generative models reduce noise amplification in phase retrieval by improving operator conditioning
- The unified approach with adaptive λ achieves lower reconstruction error than pure classical or generative methods
- Out-of-distribution signals show bias floors with generative approaches that the unified method mitigates

## Why This Works (Mechanism)

### Mechanism 1: Generative Prior as Conditioning Improver
Constraining solutions to the range of G improves conditioning of A∘G relative to A alone. Under bi-Lipschitz assumptions, the composite operator has favorable Lipschitz constant γ < α, reducing noise amplification. The derived error bound shows improved stability: ∥f̃ − f₀∥₂ ≤ (1 + 2αβ/γ)∥G(z₀) − f₀∥₂ + 2β/γ∥ε∥₂.

### Mechanism 2: Bias-Variance Trade-off with Detectable Residual
The generative approach introduces bias proportional to model mismatch ∥G(z₀) − f₀∥₂ while reducing variance proportional to noise ∥ε∥₂. The residual ̃ρ = ∥A∘G(̃z) − y∥₂ provides bounds on this bias: α⁻¹(̃ρ − σ) ≤ ∥G(̃z) − f₀∥₂ ≤ α(̃ρ + σ).

### Mechanism 3: Unified Interpolation with Adaptive λ
The combined formulation min_{z,f} ∥A(f) − y∥₂² + λ²∥G(z) − f∥₂² interpolates between extremes. Setting λ ∝ ∥ε∥₂ yields error bounded by C∥ε∥₂ asymptotically as ∥ε∥₂ → 0, balancing bias and variance adaptively.

## Foundational Learning

- **Bi-Lipschitz continuity**: Essential for all error bounds; determines conditioning of operators. Quick check: Given ∥A(f) − A(f′)∥₂ ≤ α∥f − f′∥₂ and ∥A(f) − A(f′)∥₂ ≥ α⁻¹∥f − f′∥₂, what happens to reconstruction error when α is large?

- **Phase retrieval and measurement maps**: The nonlinear map A(f) = |Af|² loses phase information, making the problem ill-posed without regularization. Quick check: Why does A(f) = |Af|² require more measurements than unknowns for injectivity?

- **Bias-variance decomposition in inverse problems**: Central to understanding generative regularization trade-offs. Quick check: In ∥f̃ − f₀∥₂ ≤ bias_term + variance_term, which term dominates for out-of-distribution vs high noise scenarios?

## Architecture Onboarding

- **Component map**: Measurement operator A (masked Fourier) → Generative model G (PCA) → Optimizer (L-BFGS) → Unified objective with λ

- **Critical path**: 1) Train G on domain data via PCA 2) Construct A with ℓ probes 3) Acquire noisy measurements y = A(f₀) + ε 4) Initialize (z,f) 5) Run L-BFGS on unified objective 6) Extract reconstruction f̃

- **Design tradeoffs**: Latent dimension k (smaller = less variance, more bias), probe count ℓ (more = better conditioning), λ selection (adaptive vs fixed), model complexity (linear vs neural)

- **Failure signatures**: Out-of-distribution bias floor, high noise collapse, over-regularization, optimizer stagnation

- **First 3 experiments**: 1) In-distribution vs out-of-distribution test with varying SNR 2) λ sweep at fixed noise level 3) Probe count ablation study

## Open Questions the Paper Calls Out

- **Open Question 1**: Does the unified approach remain stable in high noise regime (∥ε∥₂ → ∞) if λ ∝ ∥ε∥₂? The authors note uncertainty about whether λ increases fast enough as noise approaches infinity.

- **Open Question 2**: Can the bias introduced by generative models be detected and quantified more precisely than current error bounds allow? Current bounds are described as "rather crude."

- **Open Question 3**: Can the unified optimization framework be scaled efficiently to high-dimensional problems? The conclusion states further research is needed for high-dimensional feasibility.

## Limitations

- Theoretical analysis relies heavily on bi-Lipschitz assumptions that may not hold in practice
- Experimental validation limited to single dataset (MNIST) and specific measurement model
- Assumes known noise level σ for parameter selection, rarely available in real applications
- Optimization convergence and initialization sensitivity not extensively discussed

## Confidence

**High Confidence**: Bias-variance trade-off mechanism and bi-Lipschitz conditioning framework are mathematically sound and well-supported experimentally.

**Medium Confidence**: Unified interpolation approach shows promise but adaptive λ selection lacks sufficient validation and theoretical justification.

**Low Confidence**: Generalization claims to other datasets and measurement models are not substantiated; performance relative to modern regularization techniques not evaluated.

## Next Checks

1. **Out-of-distribution generalization test**: Apply methods to Fashion-MNIST or CIFAR-10 downsampled with MNIST-trained generative model to verify bias floor persistence.

2. **Robustness to λ misspecification**: Systematically vary λ around proposed values to quantify reconstruction error sensitivity when noise level is over/underestimated.

3. **Alternative measurement models**: Replace masked Fourier with Gaussian random measurements or coded diffraction patterns to assess conditioning improvements across different operators.