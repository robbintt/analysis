---
ver: rpa2
title: 'ReaLM: Residual Quantization Bridging Knowledge Graph Embeddings and Large
  Language Models'
arxiv_id: '2510.09711'
source_url: https://arxiv.org/abs/2510.09711
tags:
- knowledge
- embeddings
- entity
- code
- semantic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ReaLM, a novel framework that bridges knowledge
  graph embeddings and large language models (LLMs) by leveraging residual vector
  quantization and ontology-guided class constraints. Traditional LLM-based knowledge
  graph completion (KGC) methods struggle with semantic misalignment between continuous
  KG embeddings and discrete LLM token spaces, leading to inconsistent entity mapping
  and scalability issues.
---

# ReaLM: Residual Quantization Bridging Knowledge Graph Embeddings and Large Language Models

## Quick Facts
- **arXiv ID:** 2510.09711
- **Source URL:** https://arxiv.org/abs/2510.09711
- **Reference count:** 40
- **Primary result:** Achieves state-of-the-art performance on FB15K237 and WN18RR, significantly outperforming existing LLM-based and traditional KG embedding methods.

## Executive Summary
This paper introduces ReaLM, a novel framework that bridges knowledge graph embeddings and large language models (LLMs) by leveraging residual vector quantization and ontology-guided class constraints. Traditional LLM-based knowledge graph completion (KGC) methods struggle with semantic misalignment between continuous KG embeddings and discrete LLM token spaces, leading to inconsistent entity mapping and scalability issues. ReaLM addresses this by discretizing pretrained KG embeddings into compact code sequences via residual vector quantization, which are then integrated as learnable tokens within the LLM vocabulary. Additionally, ontology-guided class constraints ensure semantic consistency by refining entity predictions based on class-level compatibility. Experiments on benchmark datasets FB15K237 and WN18RR demonstrate that ReaLM achieves state-of-the-art performance, significantly outperforming existing LLM-based and traditional embedding methods. The approach effectively aligns structured knowledge with large-scale language models while preserving semantic fidelity and computational efficiency.

## Method Summary
ReaLM integrates KG embeddings into LLMs through a two-stage process. First, it pretrains RotatE KG embeddings (2048-dim complex vectors) on the target graph, converts them to real space (4096-dim), and discretizes them into compact integer code sequences using residual vector quantization with 32 stages and 1000-1500 codewords per stage. Second, it extends the LLM vocabulary with new code tokens initialized from summed codebook embeddings and fine-tunes the LLM using LoRA adapters while preserving original linguistic capabilities. The framework incorporates ontology-guided class constraints that filter entity predictions based on predicted class compatibility, ensuring semantic consistency.

## Key Results
- Achieves state-of-the-art performance on FB15K237 and WN18RR benchmarks
- Significant improvements in MRR and Hits@k metrics compared to both traditional embedding methods and LLM-based approaches
- Ablation studies show both residual quantization and ontology constraints contribute meaningfully to performance gains
- Effective alignment of structured knowledge with large-scale language models while preserving semantic fidelity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Residual vector quantization converts continuous KG embeddings into discrete token sequences compatible with LLM vocabularies while preserving semantic structure.
- Mechanism: RVQ iteratively approximates each continuous entity embedding via a sequence of codebook lookups. At each stage, the residual from the previous approximation is quantized by selecting the nearest codeword from a stage-specific codebook. The final quantized representation preserves relational structure while producing a compact code sequence that can be added to the LLM vocabulary.
- Core assumption: Pretrained KG embeddings encode semantically meaningful relational structure that can be preserved through multi-stage vector quantization.
- Evidence anchors: Abstract mentions discretization of pretrained KG embeddings; Section 4.2 describes the RVQ process and its preservation of semantic structure; corpus shows related quantization approaches but limited direct validation for KG-LLM alignment.
- Break condition: Poor pretrained KG embeddings or insufficient codebook size leads to reconstruction fidelity degradation; Figure 5 shows reconstruction MSE improves with larger codebook sizes.

### Mechanism 2
- Claim: Ontology-guided class constraints enforce semantic consistency by filtering entity predictions against predicted class types.
- Mechanism: Each entity is associated with a class. The model predicts both target entity and class. If the predicted entity doesn't belong to the predicted class, the prediction is refined by selecting an alternative entity that matches the predicted class. Class prediction is more accurate due to the smaller label space.
- Core assumption: Entity-class relationships in the ontology are correct and the LLM can predict classes more reliably than individual entities.
- Evidence anchors: Abstract mentions ontology-guided class constraints; Section 4.4 shows performance degradation when removing ontology knowledge; corpus contains limited evidence for ontology-guided KG-LLM integration.
- Break condition: Noisy or incomplete ontology, or unreliable class predictions, may incorrectly reject valid entities or accept invalid ones.

### Mechanism 3
- Claim: LoRA-based fine-tuning with trainable code token embeddings enables the LLM to internalize KG semantics without destabilizing pretrained linguistic capabilities.
- Mechanism: New code tokens are initialized from summed codeword embeddings and added to the LLM vocabulary. Original token embeddings are frozen. LoRA adapters inject low-rank updates into attention and feed-forward layers, allowing efficient adaptation.
- Core assumption: The LLM's pretrained knowledge can be preserved while learning to interpret and generate discrete KG code sequences.
- Evidence anchors: Section 4.3 describes LoRA fine-tuning preserving original linguistic proficiency; Section 5.5 t-SNE visualization shows semantic alignment; corpus contains related LoRA applications but limited evidence for this specific dual-adaptation scheme.
- Break condition: Insufficient LoRA rank or poor learning rate tuning prevents proper alignment of code tokens with the LLM's semantic space.

## Foundational Learning

- Concept: Vector Quantization and Residual Coding
  - Why needed here: RVQ is the core technique for converting continuous embeddings into discrete tokens. Understanding codebook learning, reconstruction loss, and commitment loss is essential for diagnosing quantization quality.
  - Quick check question: Given a residual vector and codebook, how would you compute the quantized approximation and the new residual?

- Concept: Knowledge Graph Embeddings (RotatE)
  - Why needed here: RotatE provides the pretrained entity embeddings that RVQ quantizes. Understanding rotational scoring functions and complex-space embeddings helps interpret what semantic information is preserved.
  - Quick check question: In RotatE, why are relations modeled as rotations in complex space, and what relational patterns does this capture?

- Concept: Low-Rank Adaptation (LoRA)
  - Why needed here: LoRA enables parameter-efficient fine-tuning of large LLMs. Understanding low-rank decomposition and where adapters are injected is critical for training ReaLM effectively.
  - Quick check question: If the original weight matrix is 4096×4096 and LoRA rank is 8, how many trainable parameters does LoRA add per layer?

## Architecture Onboarding

- Component map: RotatE pretraining -> Residual Vector Quantization -> Token Vocabulary Extension -> LoRA Fine-tuning -> Ontology Class Integration

- Critical path: 1) Train RotatE on target KG until convergence; 2) Run RVQ to produce codebooks and code sequences for all entities; 3) Extend LLM tokenizer with code tokens; 4) Format training data as mixed text-code prompts; 5) Fine-tune with LoRA on next-token prediction objective; 6) At inference, decode generated codes back to entity space via nearest neighbor search

- Design tradeoffs:
  - Codebook size K: Larger K improves reconstruction but increases vocabulary and memory; optimal K ≈ 1000-1500
  - Number of stages S: More stages improve fidelity; S=32 used empirically
  - LoRA rank r: Higher rank increases capacity but more parameters; r=8 used
  - Ontology integration: Adds semantic filtering but requires clean ontology data

- Failure signatures:
  - High reconstruction MSE (>0.0004): Codebook too small or undertrained
  - Low Hits@1 but decent Hits@10: Ontology constraints may be too loose or missing
  - Generated codes decode to wrong entities: Nearest-neighbor search failing; check embedding alignment
  - Training instability: LoRA learning rate too high or code token learning rate imbalance

- First 3 experiments:
  1. Ablate ontology: Train ReaLM without class constraints on FB15K237; expect ~3-5% MRR drop
  2. Vary codebook size K: Test K ∈ {500, 1000, 2000, 4000}; expect peak at K≈1000-1500
  3. Check reconstruction quality: Monitor reconstruction MSE and cosine similarity during RVQ training; target MSE <0.00035, cosine >0.98

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the computational efficiency of the training pipeline be improved to support industrial-scale knowledge graphs?
- Basis in paper: Appendix B reports approximately 187 hours on two NVIDIA H100 GPUs for FB15k237 dataset, citing complexity of dynamic candidate sampling and parameter updates.
- Why unresolved: Current training duration suggests cost-prohibitive scaling to graphs with millions of entities, limiting practical applicability despite strong benchmark performance.
- What evidence would resolve it: Scaling analysis on larger datasets like Freebase or OGB-WikiKG2, or introduction of optimized sampling/indexing strategies reducing training time to feasible industrial range.

### Open Question 2
- Question: Is there a principled, automatic method for determining optimal codebook size and number of quantization stages without requiring exhaustive grid search?
- Basis in paper: Section 5.2 states performance is sensitive to K and S, with peak at K≈1000-1500 and S=32 found through empirical grid search.
- Why unresolved: Reliance on manual grid search adds significant overhead when adapting to new domains or datasets with different semantic densities.
- What evidence would resolve it: Development of adaptive quantization mechanism or theoretical framework setting K and S based on intrinsic dimensionality or entropy of source KG embeddings.

### Open Question 3
- Question: Can the residual vector quantization framework support inductive reasoning for entities unseen during initial embedding pre-training?
- Basis in paper: Methodology relies exclusively on pretrained semantic embeddings from RotatE on known graph, but Introduction notes KGs are "continuously evolving."
- Why unresolved: Real-world KGs constantly integrate new nodes; purely transductive approach requiring full re-rotation and re-quantization may be too rigid for dynamic environments.
- What evidence would resolve it: Experiments on inductive KGC benchmarks demonstrating ability to generate valid quantized codes for entities added after initial training phase.

## Limitations
- Strong dependence on high-quality pretrained KG embeddings and clean ontology data
- Limited ablation studies on KG embedding quality or alternative embedding methods
- Reliance on manual grid search for critical hyperparameters (codebook size, stages)
- No thorough evaluation of performance degradation under noisy or incomplete ontologies

## Confidence
- Experimental results on standard benchmarks demonstrate clear performance improvements: High
- Ablation studies provide convincing evidence of contribution from both RVQ and ontology constraints: Medium
- Limited evaluation of robustness to real-world data imperfections: Medium
- Confidence tempered by lack of extensive hyperparameter sensitivity analysis: Medium

## Next Checks
1. **Robustness to ontology noise**: Systematically corrupt the ontology with varying levels of incorrect entity-class mappings and measure performance degradation, particularly for the ontology-guided filtering mechanism.
2. **Embedding quality dependence**: Compare RVQ performance when using KG embeddings from different methods (TransE, ComplEx) or with varying training quality/stability to isolate the impact of embedding fidelity.
3. **Generalization to unseen entities**: Evaluate the model's ability to handle entities absent from the original KG during inference, testing the limits of the discretization approach and nearest-neighbor decoding.