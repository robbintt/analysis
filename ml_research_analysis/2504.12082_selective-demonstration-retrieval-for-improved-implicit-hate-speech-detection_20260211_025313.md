---
ver: rpa2
title: Selective Demonstration Retrieval for Improved Implicit Hate Speech Detection
arxiv_id: '2504.12082'
source_url: https://arxiv.org/abs/2504.12082
tags:
- hate
- detection
- speech
- demonstrations
- reticl
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of detecting implicit hate speech,
  which is subtle and indirect, making it difficult for language models to distinguish
  between harmful and benign statements. The authors propose ARIIHA (Adaptive Retrieval-based
  In-context Learning for Implicit Hate Speech Detection), a method that adaptively
  retrieves demonstrations to enhance contextual comprehension without requiring model
  fine-tuning.
---

# Selective Demonstration Retrieval for Improved Implicit Hate Speech Detection

## Quick Facts
- arXiv ID: 2504.12082
- Source URL: https://arxiv.org/abs/2504.12082
- Authors: Yumin Kim; Hwanhee Lee
- Reference count: 26
- Primary result: ARIIHA achieves 76.79% Macro-F1 and 77.54% Balanced Accuracy on IHC dataset

## Executive Summary
This paper addresses the challenge of detecting implicit hate speech, which is subtle and indirect, making it difficult for language models to distinguish between harmful and benign statements. The authors propose ARIIHA (Adaptive Retrieval-based In-context Learning for Implicit Hate Speech Detection), a method that adaptively retrieves demonstrations to enhance contextual comprehension without requiring model fine-tuning. By prioritizing demonstrations that focus on similar target groups or those with the highest similarity scores, ARIIHA improves detection accuracy. Experimental results on the Implicit Hate Corpus (IHC) dataset show that ARIIHA outperforms state-of-the-art baselines, achieving a Macro-F1 score of 76.79% and a Balanced Accuracy of 77.54%.

## Method Summary
ARIIHA uses Qwen2.5-7B-Instruct with BM25 sparse retrieval for binary classification of implicit hate speech. The method employs two retrieval strategies: standard RetICL (top-k by BM25 similarity) and Target-prioritized RetICL (predict target groups via 8-shot ICL, then prioritize exact target match > similar target > BM25 fallback). An adaptive selector switches between strategies based on a similarity threshold (optimized at 10 via grid search) and detection of shortcut reasoning (1-3 word quoted phrases). The approach requires no fine-tuning and operates entirely through in-context learning.

## Key Results
- ARIIHA achieves 76.79% Macro-F1 and 77.54% Balanced Accuracy on IHC test set
- Outperforms state-of-the-art baselines by reducing over-sensitivity and dataset subjectivity
- Effectively mitigates false positives and false negatives through adaptive demonstration selection

## Why This Works (Mechanism)
ARIIHA works by strategically selecting relevant demonstrations for in-context learning, focusing on both semantic similarity and target group alignment. The adaptive switching between retrieval strategies helps the model avoid shortcut reasoning patterns while maintaining contextual relevance. The target-prioritization mechanism ensures that demonstrations addressing the same protected groups as the input text are given precedence, improving the model's ability to recognize subtle hate speech patterns specific to those groups.

## Foundational Learning
- **BM25 retrieval**: Vector-space similarity ranking using term frequency and inverse document frequency; needed to efficiently find relevant demonstrations from the retrieval pool. Quick check: Verify BM25 scores correlate with semantic relevance.
- **In-context learning**: Few-shot prompting without parameter updates; needed to leverage demonstrations without fine-tuning. Quick check: Confirm 8-shot prompting format follows standard conventions.
- **Target group prediction**: Classification of protected groups in text; needed to prioritize relevant demonstrations. Quick check: Validate target prediction accuracy exceeds 80%.
- **Shortcut detection**: Pattern recognition for shallow reasoning; needed to identify when model relies on superficial cues. Quick check: Test regex for quoted phrases correctly identifies shortcut reasoning.
- **Adaptive thresholding**: Dynamic strategy selection based on similarity scores; needed to optimize between retrieval strategies. Quick check: Confirm threshold optimization improves dev set performance.

## Architecture Onboarding

Component map: Target prediction -> BM25 retrieval -> Adaptive selector -> Demonstration selection -> In-context classification

Critical path: The pipeline's success depends on accurate target prediction, as errors cascade through retrieval and adaptive selection. The adaptive selector is the core innovation, determining when to switch between RetICL and Target-prioritized strategies based on similarity thresholds and shortcut detection.

Design tradeoffs: The method trades computational overhead (multiple retrieval passes and adaptive selection) for improved accuracy without fine-tuning. The reliance on a single similarity threshold may not generalize across domains, but provides simplicity and interpretability.

Failure signatures: High over-sensitivity scores (>15%) indicate the model is making false positive errors on texts containing protected-group keywords. Low target prediction accuracy (<80%) suggests the initial step is failing, causing cascading errors through the pipeline.

First experiments:
1. Validate target prediction accuracy on dev set before proceeding with full pipeline
2. Test adaptive selector behavior by varying similarity threshold and measuring classification performance
3. Implement shortcut detection and verify it correctly identifies shallow reasoning patterns

## Open Questions the Paper Calls Out

**Open Question 1**: Can the framework be improved to distinguish implicit hate speech from benign subjective opinions when harmful intent is masked as personal sentiment?
- Basis: Case Study (Table 5, Case B) shows misclassification of hateful text as personal opinion
- Unresolved: Current retrieval prioritizes target groups but may lack sentiment-aware heuristics
- Resolution evidence: Analysis of error rates on "opinion-type" implicit hate subsets with sentiment-aware retrieval

**Open Question 2**: How robust is the ARIIHA pipeline to errors in the initial target group prediction step?
- Basis: Section 2.2 warns that pipeline "risks collapsing at the initial step" if target prediction fails
- Unresolved: Downstream impact of prediction errors on final classification not quantified
- Resolution evidence: Ablation study measuring performance degradation under synthetic target prediction noise

**Open Question 3**: Does ARIIHA generalize effectively to diverse Large Language Models and datasets beyond Qwen2.5-7B-Instruct and IHC?
- Basis: Results limited to single model and dataset, yet conclusion claims general enhancement
- Unresolved: In-context learning sensitivity varies across architectures and distributions
- Resolution evidence: Evaluation on multiple LLM families (Llama, GPT series) and alternative benchmarks

**Open Question 4**: Is the BM25 similarity score threshold stable across different domains, or does it require tuning for every new dataset?
- Basis: Optimal threshold (10) found via nested loop on IHC dev set; transferability untested
- Unresolved: Unclear if threshold is universal constant or dataset-dependent
- Resolution evidence: Cross-domain experiments applying IHC threshold to other implicit hate speech datasets

## Limitations
- No publicly available code or complete prompt templates, creating significant reproducibility barriers
- Limited evaluation to single dataset (IHC), raising questions about generalizability
- Modest performance improvements (1-2% Macro-F1) over comparable methods

## Confidence
- Methodology: Medium - clearly described but lacks implementation details
- Results: Medium - well-supported by metrics but cannot be independently verified
- Generalizability: Low - limited to single model and dataset
- Reproducibility: Low - missing code and complete prompt templates

## Next Checks
1. Request and examine complete prompt templates and demonstration formatting for both target prediction and classification tasks
2. Implement BM25 retrieval and target similarity matching components independently to confirm retrieval quality
3. Test shortcut detection heuristic on held-out validation set to assess reliability and false positive rate