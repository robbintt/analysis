---
ver: rpa2
title: Investigating the Scalability of Approximate Sparse Retrieval Algorithms to
  Massive Datasets
arxiv_id: '2501.11628'
source_url: https://arxiv.org/abs/2501.11628
tags:
- retrieval
- sparse
- seismic
- index
- embeddings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the scalability of approximate sparse retrieval
  algorithms on massive datasets, specifically focusing on the recently proposed Seismic
  and graph-based solutions adapted from dense retrieval. The authors evaluate these
  algorithms on Splade embeddings of 138M passages from MsMarco-v2, comparing their
  efficiency and effectiveness.
---

# Investigating the Scalability of Approximate Sparse Retrieval Algorithms to Massive Datasets

## Quick Facts
- arXiv ID: 2501.11628
- Source URL: https://arxiv.org/abs/2501.11628
- Reference count: 32
- Primary result: Seismic with κ-NN graph achieves 3ms latency at 98% accuracy@10 vs 20.7ms for HNSW in 2× memory budget

## Executive Summary
This paper investigates the scalability of approximate sparse retrieval algorithms on massive datasets, specifically comparing Seismic (a block-pruning algorithm) against graph-based methods like HNSW. The authors evaluate these algorithms on SPLADE embeddings of 138M passages from MsMarco-v2, measuring query latency, accuracy, index size, and indexing time across different memory budgets. The study reveals that while Seismic's query latency scales less favorably than HNSW as dataset size grows, it remains Pareto-efficient, particularly when the κ-NN graph is enabled. The κ-NN graph significantly improves query latency at higher accuracy levels but substantially increases indexing time, creating a trade-off between retrieval speed and construction costs.

## Method Summary
The study compares Seismic and HNSW algorithms for approximate sparse retrieval on SPLADE embeddings. Seismic uses inverted lists organized into geometric blocks with summary vectors for pruning, with an optional κ-NN graph expansion phase. HNSW uses graph-based traversal. Both are evaluated on MsMarco-v2 (138M passages) using cocondenser-ensembledistil SPLADE embeddings. Experiments measure accuracy@10, query latency, index size, and indexing time under 1.5× and 2× memory budgets relative to the dataset size (~66GB base). The authors sweep hyperparameters to find Pareto-optimal configurations and analyze scaling behavior by comparing performance on subsets of different sizes.

## Key Results
- Seismic with κ-NN graph achieves 3ms latency at 98% accuracy@10, while HNSW requires 20.7ms (6.9× slower) in 2× memory budget
- Enabling the κ-NN graph reduces query latency by up to 7× at high accuracy thresholds (≥97%)
- Seismic's query latency scales 8× slower than HNSW as dataset size grows (2.5× vs 8× slowdown)
- κ-NN graph construction increases indexing time from 0.5 hours to 16.6 hours, requiring substantial computational resources

## Why This Works (Mechanism)

### Mechanism 1: Block-Based Pruning via Summary Vectors
Seismic reduces query latency by skipping large groups of documents that mathematically cannot contain the top-k results. The algorithm clusters posting lists into geometric blocks and represents each block with a summary vector (maximum value per coordinate). During retrieval, it computes the inner product between the query and block summary. If this potential score is lower than the lowest score in the top-k heap, the entire block is skipped without inspecting individual vectors. The core assumption is that summary vectors provide tight upper bounds on actual scores within blocks.

### Mechanism 2: Recall Recovery via Graph Expansion
Adding a proximity graph (κ-NN) allows the system to recover relevant documents missed by aggressive block-pruning. The retrieval process has two phases: first, pruned inverted index search finds initial candidates S, then the algorithm expands this set by looking up neighbors N(u) for all u in S. These expanded candidates are re-scored using the full forward index. The core assumption is that relevant documents missed by initial pruning are likely to be graph neighbors of found documents (cluster hypothesis).

### Mechanism 3: Sparse-Specific Indexing vs. General Graph Traversal
Specialized sparse indexing (Seismic) outperforms general-purpose graph traversal (HNSW) in absolute latency at scale because it exploits specific distributional properties of sparse embeddings. Graph methods like HNSW treat vectors as generic points, suffering from the "curse of dimensionality" in high-dimensional sparse spaces. Seismic leverages the inverted index structure, intersecting only non-zero dimensions. While HNSW scales better relative to dataset growth, Seismic starts with a lower absolute baseline.

## Foundational Learning

- **Concept:** Maximum Inner Product Search (MIPS)
  - **Why needed here:** Learned sparse retrieval relies on inner product (dot product) of weights, not Euclidean or Cosine distance. Algorithms must be specifically optimized for this metric.
  - **Quick check question:** Why does the paper specify that similarity is by "inner product" rather than Cosine similarity? (Hint: Check norm preservation in sparse expansions)

- **Concept:** Learned Sparse Representations (e.g., SPLADE)
  - **Why needed here:** These are not traditional bag-of-words (TF-IDF/BM25). They involve vocabulary expansion and learned weights, resulting in high-dimensional vectors (vocab size ~30k-100k) but with few non-zeros (sparsity).
  - **Quick check question:** How does the "distributional idiosyncrasy" of SPLADE embeddings differ from standard BM25 term frequencies?

- **Concept:** Pareto Efficiency & Pareto Frontier
  - **Why needed here:** The paper evaluates algorithms based on the trade-off between accuracy and latency. "Pareto-efficient" means that for a given accuracy, Seismic has the lowest latency, or for a given latency, it has the highest accuracy.
  - **Quick check question:** If HNSW were 10x faster but 5% less accurate, could it still be Pareto-efficient compared to Seismic?

## Architecture Onboarding

- **Component map:**
  - Inverted Index -> Summary Store -> Forward Index -> κ-NN Graph

- **Critical path:**
  1. Query Parsing: Convert query to sparse vector
  2. Summary Pruning: Scan posting lists; compare query to block summaries; discard low-scoring blocks
  3. Accumulation: Score surviving blocks to populate the top-k heap (S)
  4. Graph Expansion: Retrieve neighbors N(u) for all u in S
  5. Refinement: Re-score expanded set S̃ using Forward Index
  6. Return: Final top-k

- **Design tradeoffs:**
  - Memory vs. Latency: Enabling κ-NN graph adds 27 bits per document overhead but required for <4ms latency at >97% accuracy
  - Indexing Time vs. Query Speed: Building κ-NN graph is resource-intensive (0.5 to 16.6 hours)
  - Block Size (λ): Smaller blocks improve pruning precision but increase summary storage overhead

- **Failure signatures:**
  - High Latency at Low Accuracy: Heap threshold not rising fast enough; heap_factor may need adjustment
  - Low Recall despite Graph: Graph construction parameters were too aggressive/approximate
  - Memory Overflow: κ-NN graph memory footprint scales linearly with collection size (n)

- **First 3 experiments:**
  1. Baseline Latency/Accuracy: Run Seismic (no graph) vs. HNSW on 1M subset to validate Pareto frontier before scaling to 138M
  2. Indexing Cost Analysis: Measure wall-clock time and memory peak specifically during κ-NN graph construction phase
  3. Block Sensitivity: Vary λ (number of postings per block) to find "knee" where summary overhead equals block scanning cost

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can efficient retrieval be achieved when indexes cannot fit completely in main memory for massive sparse datasets?
- Basis in paper: [explicit] The authors state: "We leave the study of cases where the index does not fit in the main memory to future work" and mention investigating "efficient retrieval where indexes cannot fit completely in main memory."
- Why unresolved: All experiments assumed sufficient RAM (256GiB per CPU node) to store entire indexes; disk-based or distributed scenarios were not tested.
- What evidence would resolve it: Benchmarks on datasets where index size exceeds available RAM, measuring latency, accuracy, and throughput under memory-constrained conditions.

### Open Question 2
- Question: Can memory-efficient encodings (e.g., delta encoding) for the κ-NN graph improve Seismic's query latency at fixed memory budgets?
- Basis in paper: [explicit] The authors suggest: "reducing the memory impact of the κ-NN graph, for example, using delta encoding to store the ids of the documents, may help Seismic become even faster at a given memory budget."
- Why unresolved: The κ-NN graph currently requires 27 bits per document; no alternative encodings were evaluated.
- What evidence would resolve it: Empirical comparison of query latency vs. accuracy trade-offs using compressed graph representations against current implementation.

### Open Question 3
- Question: How can approximate sparse retrieval be optimized for low-resource environments with limited compute, memory, or disk?
- Basis in paper: [explicit] Future work includes "efficient retrieval in low-resource environments (i.e., on devices with low computational resources, memory, or disk)."
- Why unresolved: Experiments used a high-end NUMA server (192 cores, 1TiB RAM); performance on constrained hardware remains unknown.
- What evidence would resolve it: Benchmarks on edge devices or low-memory VMs, profiling indexing time, latency, and accuracy degradation.

## Limitations

- Scalability results are based on a single dataset (MsMarco-v2) and sparse embedding type (SPLADE), limiting generalizability to other domains
- The paper doesn't report sensitivity analyses for hyperparameters beyond specific combinations tested, making it unclear how robust performance gains are
- The memory overhead of the κ-NN graph (27 bits per document) may become prohibitive at scales beyond 138M passages

## Confidence

- **High confidence:** Query latency comparisons between Seismic with κ-NN and HNSW (measured directly with controlled conditions)
- **Medium confidence:** Pareto-efficiency claims (depend on choosing appropriate parameter sweeps)
- **Low confidence:** Scalability extrapolation beyond MsMarco-v2 (based on a single scaling experiment)

## Next Checks

1. Replicate the latency scaling experiment on a 10× larger dataset to verify the 2.5× vs 8× slowdown ratios hold
2. Test with alternative sparse embeddings (e.g., SparTerm) to confirm algorithmic advantages are embedding-agnostic
3. Profile memory usage during κ-NN graph construction to identify bottlenecks and verify the 27 bits/document overhead calculation