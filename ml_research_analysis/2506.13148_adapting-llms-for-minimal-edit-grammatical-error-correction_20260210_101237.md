---
ver: rpa2
title: Adapting LLMs for Minimal-edit Grammatical Error Correction
arxiv_id: '2506.13148'
source_url: https://arxiv.org/abs/2506.13148
tags:
- datasets
- error
- dataset
- examples
- computational
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper explores adapting decoder-only LLMs for minimal-edit
  grammatical error correction (GEC). The core method involves detokenizing popular
  GEC datasets to match natural text format, using a Llama 3 70b model to detect and
  correct annotation errors, and introducing a novel training schedule that first
  trains on erroneous examples then fine-tunes on correct ones with reduced learning
  rate to control precision-recall trade-off.
---

# Adapting LLMs for Minimal-edit Grammatical Error Correction

## Quick Facts
- arXiv ID: 2506.13148
- Source URL: https://arxiv.org/abs/2506.13148
- Reference count: 13
- New SoTA single-model F0.5 score of 77.41 on BEA-test set with Gemma 2 9B

## Executive Summary
This paper addresses the challenge of adapting decoder-only large language models (LLMs) for minimal-edit grammatical error correction (GEC). The authors develop a comprehensive approach that includes detokenizing popular GEC datasets, automatically detecting and correcting annotation errors using a Llama 3 70b model, and introducing a novel training schedule that first trains on erroneous examples then fine-tunes on correct ones with reduced learning rate. The method also incorporates data augmentation by adding unedited pairs. The approach achieves state-of-the-art results on the BEA-test set, demonstrating that careful dataset curation and training design can make LLMs effective for minimal-edit GEC without requiring large-scale pre-training.

## Method Summary
The method involves several key components: detokenizing popular GEC datasets to match natural text format, using a Llama 3 70b model to detect and correct annotation errors in training data, and introducing a novel training schedule that first trains on erroneous examples then fine-tunes on correct ones with reduced learning rate to control precision-recall trade-off. Data augmentation is applied by adding unedited pairs to the training data. The authors focus on decoder-only LLMs and demonstrate that their approach significantly improves performance on minimal-edit GEC tasks.

## Key Results
- Achieved new state-of-the-art single-model F0.5 score of 77.41 on BEA-test set with Gemma 2 9B
- Training on detokenized datasets with corrected annotations improves results
- Proposed training schedule with proper learning rate tuning enables effective minimal-edit corrections
- Data augmentation by adding unedited pairs contributes to improved performance

## Why This Works (Mechanism)
The approach works by addressing several key challenges in GEC. First, detokenizing datasets ensures that the model learns from natural text format rather than artificial token sequences. Second, correcting annotation errors removes noise from the training data, allowing the model to learn more accurate patterns. Third, the two-phase training schedule with learning rate reduction enables the model to first learn error detection capabilities, then refine precision to achieve minimal edits. Finally, data augmentation helps the model learn when not to edit, improving precision on correct text.

## Foundational Learning

1. **Minimal-edit GEC**: A paradigm focusing on making the smallest possible corrections to grammatical errors
   - Why needed: Reduces unnecessary changes and improves precision
   - Quick check: Model should correct errors with minimal token changes

2. **Dataset detokenization**: Converting token sequences back to natural text format
   - Why needed: Training on natural text improves generalization
   - Quick check: Compare performance on detokenized vs. tokenized datasets

3. **Annotation error detection**: Identifying and correcting errors in human-annotated GEC datasets
   - Why needed: Reduces noise in training data
   - Quick check: Validate corrected annotations with human review

4. **Two-phase training schedule**: First training on errors, then fine-tuning on correct examples
   - Why needed: Enables learning error detection then precision refinement
   - Quick check: Compare single-phase vs. two-phase training results

5. **Learning rate reduction**: Decreasing learning rate during fine-tuning phase
   - Why needed: Controls precision-recall trade-off
- Quick check: Experiment with different learning rate reduction factors

## Architecture Onboarding

**Component Map**: Dataset -> Preprocessing (detokenization + error correction) -> Training (two-phase) -> Evaluation

**Critical Path**: The two-phase training schedule is critical - first phase builds error detection capability, second phase with reduced learning rate achieves precision for minimal edits.

**Design Tradeoffs**: 
- Large model vs. efficiency: 70b model for error detection is computationally expensive but effective
- Precision vs. recall: Reduced learning rate favors precision (minimal edits) over recall (error coverage)
- Dataset size vs. quality: Corrected annotations improve quality but reduce dataset size

**Failure Signatures**: 
- Over-editing: Model makes unnecessary changes to correct text
- Under-editing: Model misses grammatical errors
- Inconsistency: Model behavior varies significantly across similar error types

**First Experiments**:
1. Compare detokenized vs. tokenized dataset performance on validation set
2. Evaluate impact of learning rate reduction factor on F0.5 score
3. Test single-phase vs. two-phase training schedule on minimal-edit capability

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but implicit questions remain about the scalability of the approach to other languages and error types, the generalizability of the two-phase training schedule to different LLM architectures, and the potential for further optimization of the precision-recall trade-off.

## Limitations

- Reliance on automatic annotation error detection with limited human validation (only 56 out of 68 flagged errors confirmed)
- Focus exclusively on English GEC, limiting multilingual applicability
- Computational resources required for fine-tuning large LLMs may limit accessibility

## Confidence

- Dataset detokenization improvements: **High** - straightforward technical modification with clear measurable impact
- Annotation correction methodology: **Medium** - limited human validation sample size
- Minimal-edit effectiveness: **Medium-High** - state-of-the-art results but dependent on specific test set characteristics

## Next Checks

1. Conduct comprehensive human evaluation on a broader sample of the corrected annotations to verify the Llama 3 70b model's error detection accuracy and identify potential systematic biases in the automatic correction process.

2. Test the proposed training schedule on alternative LLM architectures (e.g., Mistral, LLaMA-2 variants) to determine if the two-phase approach with learning rate reduction generalizes beyond the specific models used in this study.

3. Evaluate the minimal-edit models on diverse GEC test sets with varying error types and densities to assess whether the precision-recall trade-off optimization maintains effectiveness across different error distributions and writing styles.