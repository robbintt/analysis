---
ver: rpa2
title: 'AudioTurbo: Fast Text-to-Audio Generation with Rectified Diffusion'
arxiv_id: '2505.22106'
source_url: https://arxiv.org/abs/2505.22106
tags:
- audio
- diffusion
- generation
- steps
- audioturbo
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses slow inference speed in diffusion-based text-to-audio
  (TTA) generation. It introduces AudioTurbo, which applies rectified diffusion to
  pre-trained TTA models to improve efficiency.
---

# AudioTurbo: Fast Text-to-Audio Generation with Rectified Diffusion

## Quick Facts
- arXiv ID: 2505.22106
- Source URL: https://arxiv.org/abs/2505.22106
- Reference count: 0
- Primary result: AudioTurbo achieves high-quality text-to-audio generation with only 10 sampling steps, outperforming baselines on AudioCaps dataset metrics.

## Executive Summary
AudioTurbo addresses the slow inference speed of diffusion-based text-to-audio generation by introducing rectified diffusion. The method pairs deterministic noise-sample pairs from a pre-trained model (Auffusion) and retrains the diffusion model to maintain consistent predictions along ODE trajectories. This approach enables faster sampling while preserving audio quality, achieving competitive results with significantly fewer steps than traditional diffusion methods.

## Method Summary
AudioTurbo implements rectified diffusion by first sampling deterministic noise trajectories from a pre-trained TTA model (Auffusion). These noise-sample pairs are then used to retrain the diffusion model, enforcing consistency in predictions along the ODE trajectory. The training objective ensures that the model maintains coherent predictions even with aggressive step reduction. During inference, this allows the model to generate high-quality audio with only 10 sampling steps, and match flow-matching-based models in just 3 steps.

## Key Results
- Achieves state-of-the-art objective metrics on AudioCaps: FD 20.65, KL 1.29, IS 9.40, CLAP 29.8
- Outperforms baselines in both objective metrics and subjective quality with just 10 sampling steps
- Matches flow-matching-based model performance in only 3 sampling steps

## Why This Works (Mechanism)
The rectified diffusion approach works by enforcing consistency constraints during training. By pairing deterministic noise trajectories with their corresponding samples from a pre-trained model, the method ensures that the diffusion model learns to make consistent predictions along the ODE trajectory. This consistency allows the model to take larger steps during sampling without losing quality, effectively reducing the number of required sampling steps while maintaining audio fidelity.

## Foundational Learning

**Diffusion Models**
- Why needed: Understanding the base framework for AudioTurbo's improvements
- Quick check: Can generate samples by gradually denoising random noise

**ODE Trajectory Consistency**
- Why needed: Core concept enabling faster sampling without quality loss
- Quick check: Predictions remain stable along the reverse-time ODE path

**Deterministic Noise Sampling**
- Why needed: Provides paired data for training consistency
- Quick check: Same noise input always produces same trajectory

## Architecture Onboarding

**Component Map**
Pretrained TTA Model -> Deterministic Noise Sampler -> Rectified Diffusion Trainer -> Fast Sampling Model

**Critical Path**
Noise trajectory generation → Consistency enforcement training → Accelerated sampling inference

**Design Tradeoffs**
- Training complexity vs inference speed
- Model capacity vs sampling efficiency
- Generalization vs task-specific optimization

**Failure Signatures**
- Inconsistent predictions along ODE trajectory
- Quality degradation with aggressive step reduction
- Training instability from mismatched noise trajectories

**First 3 Experiments**
1. Verify deterministic noise trajectory generation matches original model outputs
2. Test consistency training with varying step counts and learning rates
3. Benchmark inference speed and quality trade-offs at different sampling step counts

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation relies heavily on single dataset (AudioCaps) and baseline (Auffusion)
- Applicability to other pre-trained TTA models and longer audio clips remains unclear
- Computational cost of rectified diffusion training phase is not discussed

## Confidence
- High confidence: Novel rectified diffusion approach well-motivated, clear inference speed improvements
- Medium confidence: Specific objective metrics reported but interpretation dataset-dependent, subjective quality claims plausible but not independently validated
- Low confidence: Claims about scalability to other models and complex prompts speculative without empirical support

## Next Checks
1. Apply AudioTurbo to at least two additional pre-trained TTA models to test cross-model generalization
2. Evaluate performance on prompts with longer durations (10-30 seconds) and complex multi-component descriptions
3. Measure and report computational cost and time required for rectified diffusion training phase, including hyperparameter sensitivity