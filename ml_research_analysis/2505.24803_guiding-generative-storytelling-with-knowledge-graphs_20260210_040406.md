---
ver: rpa2
title: Guiding Generative Storytelling with Knowledge Graphs
arxiv_id: '2505.24803'
source_url: https://arxiv.org/abs/2505.24803
tags:
- story
- participants
- narrative
- generation
- stage
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors integrated a knowledge graph (KG) into an LLM-driven
  story generation pipeline to improve long-form coherence and user control. Users
  could edit the KG after each generated scene, allowing them to reshape the narrative
  structure and details in real time.
---

# Guiding Generative Storytelling with Knowledge Graphs

## Quick Facts
- **arXiv ID**: 2505.24803
- **Source URL**: https://arxiv.org/abs/2505.24803
- **Reference count**: 16
- **Primary result**: KG-assisted stories showed statistically significant improvements in action narratives (characters p=0.016, pace p=0.053, structure p=0.083) but not in introspective genres

## Executive Summary
This paper introduces a knowledge graph (KG)-assisted approach to generative storytelling that enables users to maintain narrative coherence and exert control over long-form story generation. By integrating a KG into an LLM pipeline, users can edit story elements after each generated scene, allowing real-time reshaping of narrative structure. The approach was evaluated through a user study (N=15) comparing KG-assisted versus non-KG story generation across action-oriented and introspective genres. Results showed significant improvements in action narratives for character development, pacing, and structural coherence, while introspective stories showed no significant differences. Users reported high engagement and strong sense of control when editing the KG, particularly for kinetic, task-driven narratives.

## Method Summary
The system integrates a knowledge graph into an LLM-driven story generation pipeline, where the KG serves as both a structural backbone and an interactive editing interface. Users generate stories scene by scene, with the option to modify the KG after each scene to influence subsequent narrative development. The knowledge graph captures character relationships, plot points, and world-building elements that the LLM references during generation. The user study compared two conditions: KG-assisted generation versus standard LLM generation, across two genre types (action-oriented vs introspective). Participants rated story quality across multiple dimensions including character development, pacing, and structural coherence.

## Key Results
- KG-assisted stories significantly outperformed non-KG stories in action-oriented narratives (p=0.016 for characters, p=0.053 for pace, p=0.083 for structure)
- No significant differences found between KG and non-KG conditions for introspective genres
- Participants reported high engagement and strong sense of narrative control when editing the KG
- The approach proved particularly effective for kinetic, task-driven stories requiring clear progression and character development

## Why This Works (Mechanism)
The knowledge graph provides a persistent, editable representation of narrative elements that grounds the LLM's generation process. By allowing users to modify the KG after each scene, the system creates a feedback loop where structural changes immediately influence subsequent story development. This addresses the core challenge of maintaining long-form coherence in LLM-generated narratives, where context windows and attention mechanisms often lead to drift over extended sequences. The KG acts as an external memory system that preserves narrative consistency while giving users explicit control over story direction.

## Foundational Learning
- **Knowledge Graph Representation**: Why needed - provides structured, persistent storage of narrative elements; Quick check - can you trace character relationships and plot points through the graph
- **Interactive Narrative Editing**: Why needed - enables real-time user control over story direction; Quick check - can users modify story elements mid-generation and see immediate effects
- **Genre-Specific Narrative Requirements**: Why needed - different genres require different structural approaches; Quick check - does the system adapt appropriately to action vs introspective storytelling needs
- **Statistical Significance Testing**: Why needed - validates observed differences are not due to chance; Quick check - are p-values below conventional thresholds (0.05) for key metrics
- **User Experience Evaluation**: Why needed - measures subjective effectiveness beyond objective metrics; Quick check - do participants report high engagement and sense of control

## Architecture Onboarding

**Component Map**: User Interface -> KG Editor -> LLM Generator -> Story Output -> KG Updater -> (back to KG Editor)

**Critical Path**: User edits KG → KG influences LLM prompts → LLM generates scene → User evaluates output → KG updates with new elements → Repeat

**Design Tradeoffs**: Real-time editing capability vs. generation latency; Structured KG constraints vs. creative freedom; User control vs. system autonomy

**Failure Signatures**: Narrative drift in non-KG condition; User confusion when KG becomes too complex; Performance degradation with overly large KGs

**First Experiments**: 1) Generate single scene with/without KG to establish baseline difference; 2) Edit KG mid-generation and observe impact on subsequent scenes; 3) Compare story coherence metrics across 5-scene sequences

## Open Questions the Paper Calls Out
None

## Limitations
- Small sample size (N=15) may not capture full population variance in user preferences and abilities
- Genre restriction to action-oriented vs introspective stories limits generalizability to other narrative styles
- System design may have favored action narratives through specific task selection, potentially biasing results

## Confidence
- **High confidence**: KG assistance improves user control and story coherence for action narratives (supported by statistically significant results)
- **Medium confidence**: Genre-generalization claims (introspective genre showed no significant differences, but sample may be insufficient)
- **Medium confidence**: User engagement metrics (positive qualitative feedback but small sample size)

## Next Checks
1. Replicate with larger, more diverse participant pool (N>50) across multiple narrative genres to test generalizability
2. Conduct longitudinal study tracking story coherence over longer narrative arcs (10+ scenes) to assess sustained effectiveness
3. Implement blind evaluation where raters assess story quality without knowing whether KG assistance was used, to eliminate potential bias