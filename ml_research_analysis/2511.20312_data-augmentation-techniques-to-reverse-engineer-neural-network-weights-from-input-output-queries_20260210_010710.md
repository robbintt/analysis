---
ver: rpa2
title: Data Augmentation Techniques to Reverse-Engineer Neural Network Weights from
  Input-Output Queries
arxiv_id: '2511.20312'
source_url: https://arxiv.org/abs/2511.20312
tags:
- teacher
- mnist
- grid-comp
- loss
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates weight recovery from overparameterized neural
  networks when the number of parameters exceeds the number of training data points.
  The authors show that querying a teacher network only with its original training
  data leads to student overfitting and failed reconstruction.
---

# Data Augmentation Techniques to Reverse-Engineer Neural Network Weights from Input-Output Queries

## Quick Facts
- arXiv ID: 2511.20312
- Source URL: https://arxiv.org/abs/2511.20312
- Reference count: 40
- One-line primary result: Novel data augmentations enable weight reconstruction for networks up to 100× larger than training dataset

## Executive Summary
This work addresses weight recovery from overparameterized neural networks when parameters exceed training data points. Standard data augmentations fail because they produce negligible pre-activation variability in high dimensions, preventing successful weight reconstruction. The authors introduce biased-noise (±η[0,1] and ±η[-1,0]) and grid composition augmentations that systematically induce variability along teacher weight directions. Using these techniques, they successfully reconstruct networks with up to 512 hidden neurons using only 60,000 MNIST samples, extending state-of-the-art by two orders of magnitude.

## Method Summary
The method uses a teacher-student setup where students are overparameterized (4× teacher neurons) and trained to imitate teacher logits via MSE loss. The Expand-and-Cluster (EC) framework trains multiple students and clusters their neurons to extract weight centroids as reconstructions. Two novel augmentations are introduced: biased-noise that creates directional perturbations (±η[0,1] and ±η[-1,0]) to induce pre-activation variability, and grid composition that combines 9 image patches into composite images. Students are trained with Adam optimizer and plateau learning rate scheduling on augmented queries, then clustered to recover teacher weights.

## Key Results
- Standard augmentations (rotation, flipping, zero-mean noise) fail to improve reconstruction beyond 16 neurons
- Biased-noise augmentation (±η[0,1]) successfully reconstructs 512-neuron teachers with cosine distance <1e-7
- Grid composition enables reconstruction for networks up to 100× larger than training dataset
- Test error on FashionMNIST remains orders of magnitude higher than training error, confirming genuine weight recovery

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pre-activation variability is necessary for successful weight reconstruction in high-dimensional settings.
- Mechanism: Standard augmentations fail because they produce w* · x_aug ≈ 0 in high dimensions, providing non-informative teaching signals. Effective augmentations must induce variability along teacher weight vectors to constrain the nonlinear activation function.
- Core assumption: Teacher neurons have bounded nonlinear activation regions; samples must span both sides of the hyperplane (w* · x + b* = 0) to provide informative gradients.
- Evidence anchors: [abstract] "standard augmentations such as rotation, flipping, and adding noise, bring little to no improvement"; [section 3.3] "we hypothesize that the failure of standard augmentation techniques stems from little to no variability in teacher pre-activation"

### Mechanism 2
- Claim: Biased-noise augmentation (η[0,1] and η[-1,0]) induces directional perturbations that zero-mean noise cannot achieve.
- Mechanism: Zero-mean uniform noise (η[-1,1]) cancels across dimensions, yielding negligible net perturbation. Biased noise creates consistent directional shifts: for each input x, one augmented sample adds positive bias, another negative bias, systematically spanning pre-activation space.
- Core assumption: Perturbation magnitude of 1 (matching MNIST standard deviation) scales appropriately to other datasets.
- Evidence anchors: [section 3.3] "adding zero-mean uniform noise, η[-1,1], to such samples does not induce a high variability of pre-activations"; [table 1] MNIST ±η[-1,1]: avg cosine distance 5.04e-1 (failure); MNIST ±η[0,1]: avg cosine distance 2.53e-8 (success)

### Mechanism 3
- Claim: Grid composition extends effective dataset size while maintaining distributional similarity to training data.
- Mechanism: Combining 9 image patches (3×3 grid) creates D^9 composite images that remain visually similar to original data distribution, avoiding degenerate non-informative samples that pure noise augmentation produces at scale.
- Core assumption: Composite images preserve statistical properties that activate teacher neurons similarly to real samples.
- Evidence anchors: [section 3.4] "augmentation of the dataset from 5k to 180k with simple noise addition might lead to non-informative images"; [table 1] Grid-Comp. ±η[0,1]: avg cosine distance 9.74e-6 (success at 512 neurons)

## Foundational Learning

- Concept: **Teacher-student setup with over-parameterization**
  - Why needed here: The entire reconstruction framework assumes students with 4× more neurons than teachers can reach zero loss, enabling weight clustering.
  - Quick check question: Can you explain why over-parameterization helps gradient descent find zero-loss solutions in the loss landscape?

- Concept: **Pre-activation vs. post-activation**
  - Why needed here: The core insight is that augmentations must vary pre-activations (w* · x + b*), not just inputs, to sample the nonlinear region of activation functions.
  - Quick check question: For a teacher neuron with weight vector w* and input x, what is the pre-activation, and why would random perturbations to x leave it unchanged in high dimensions?

- Concept: **Cosine distance as alignment metric**
  - Why needed here: Reconstruction success is measured by cosine distance between reconstructed and true weight vectors; values <1e-6 indicate near-perfect alignment.
  - Quick check question: Why is cosine distance preferred over L2 distance for measuring weight alignment across neurons of potentially different scales?

## Architecture Onboarding

- Component map:
```
Teacher N (black-box) → Query Strategy (augmentation) → Student Training (ρ=4 overparameterized, N=30 runs) → Clustering → Reconstructed Network
```

- Critical path:
  1. Select augmentation strategy (biased-noise ±η[0,1] + grid composition for scalability)
  2. Query teacher to generate N(X) labels
  3. Train 30 independent over-parameterized students
  4. Cluster student neurons; extract centroids as reconstructed weights
  5. Fine-tune on teacher queries

- Design tradeoffs:
  - Biased noise magnitude: 1.0 matches MNIST std; smaller (0.5) underperforms, larger (2.0) approaches asymptotic regime
  - Grid composition size: 3×3 balances sample diversity (D^9) vs. distributional similarity
  - Over-parameterization factor: ρ=4 chosen empirically; lower risks missing zero-loss solutions

- Failure signatures:
  - Training loss near zero but test loss (FashionMNIST) orders of magnitude higher → overfitting, not alignment
  - Pre-activation histograms narrow/gaussian → augmentation not inducing variability
  - Clustering yields fewer clusters than teacher neurons → students converged to local minima

- First 3 experiments:
  1. Reproduce 512-neuron teacher reconstruction on MNIST with biased-noise (±η[0,1]) alone; verify cosine distance <1e-7
  2. Test scaling limit: train teacher on 5k MNIST subset, apply Grid-Comp. ±η[0,1]; confirm reconstruction up to 256-neuron teachers
  3. Ablation: compare pre-activation variability histograms for η[-1,1] vs. η[0,1]; quantify std increase in pre-activation distribution

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can a rigorous theoretical framework be established to mathematically guarantee weight recovery using these specific data augmentations?
- Basis in paper: [explicit] The authors state in the Appendix: "Our results are, at the moment, strictly empirical. We are working towards a rigorous theoretical framework of teacher reconstruction..."
- Why unresolved: The current work relies on empirical success and the intuition of "pre-activation variability" without providing formal mathematical proofs or bounds.
- What evidence would resolve it: Derivation of theoretical guarantees showing that biased-noise and grid composition sufficiently constrain the student solution space to ensure parameter alignment.

### Open Question 2
- Question: How can these augmentation techniques be adapted for networks with symmetric activation functions like ReLU, where the authors note variability alone fails?
- Basis in paper: [inferred] The paper restricts experiments to a specific asymmetric activation function and shows in the Appendix (Figure 3) that for ReLU, "pre-activations do not suffice" and data variability can lead to functional equivalence without weight recovery.
- Why unresolved: The failure mode for ReLU suggests the current augmentation strategy does not break the symmetries inherent in standard activations.
- What evidence would resolve it: Modified augmentation protocols that successfully reconstruct teacher weights in deep ReLU-based networks with the same fidelity achieved for the asymmetric custom activation.

### Open Question 3
- Question: Do the "grid composition" and "biased-noise" methods effectively scale to more complex architectures like CNNs or Transformers?
- Basis in paper: [explicit] The Conclusion expresses the belief that the methodology "will be useful to scale the field of reverse engineering network weights to more complex network architectures..."
- Why unresolved: The experiments are limited to one-hidden-layer MLPs on MNIST; the interaction of these input-space augmentations with convolutional layers or attention mechanisms is unknown.
- What evidence would resolve it: Successful parameter recovery experiments on convolutional neural networks (e.g., ResNets) or Transformer models using the proposed augmentation strategies.

## Limitations
- Approach relies on overparameterization (ρ=4) which may not scale efficiently to deeper architectures
- Biased-noise augmentation assumes uniform input distributions; performance on non-uniform or sparse inputs remains unclear
- Grid composition introduces computational overhead scaling as D^9 for D input dimensions

## Confidence
- **High confidence**: Biased-noise augmentation improves pre-activation variability over zero-mean noise (Section 3.3, Table 1)
- **Medium confidence**: Grid composition enables scaling to 100× larger networks (Section 3.4, Table 1)
- **Low confidence**: Generalization to non-image domains or alternative activation functions

## Next Checks
1. **Ablation study**: Compare biased-noise magnitudes (0.5, 1.0, 2.0) on pre-activation variability and reconstruction accuracy to validate the 1.0 magnitude choice.
2. **Activation robustness**: Test reconstruction on non-softmax activations (tanh, sigmoid) to assess dependence on specific activation properties.
3. **Scaling analysis**: Systematically evaluate reconstruction success rate vs. teacher size (4→1024 neurons) to identify theoretical scaling limits.