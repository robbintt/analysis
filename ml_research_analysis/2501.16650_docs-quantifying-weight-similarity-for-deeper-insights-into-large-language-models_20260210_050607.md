---
ver: rpa2
title: 'DOCS: Quantifying Weight Similarity for Deeper Insights into Large Language
  Models'
arxiv_id: '2501.16650'
source_url: https://arxiv.org/abs/2501.16650
tags:
- similarity
- matrices
- docs
- orthogonal
- weight
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces the Distribution of Cosine Similarity (DOCS),
  a novel index for quantitatively assessing similarity between weight matrices in
  large language models (LLMs). Unlike existing methods that focus on representational
  similarity, DOCS directly examines weight matrices to uncover structural patterns
  within LLMs.
---

# DOCS: Quantifying Weight Similarity for Deeper Insights into Large Language Models

## Quick Facts
- arXiv ID: 2501.16650
- Source URL: https://arxiv.org/abs/2501.16650
- Reference count: 40
- The paper introduces DOCS, a novel index for quantitatively assessing similarity between weight matrices in large language models (LLMs), overcoming limitations of existing methods that focus on representational similarity.

## Executive Summary
The paper introduces DOCS (Distribution of Cosine Similarity), a novel index for quantitatively assessing similarity between weight matrices in large language models. Unlike existing methods that focus on representational similarity, DOCS directly examines weight matrices to uncover structural patterns within LLMs. The method computes cosine similarities between parameter vectors, extracts maximum similarities, and fits Gumbel distributions to derive a similarity index. Experiments reveal that adjacent layers exhibit high weight similarity and tend to form clusters, suggesting functional specialization. DOCS outperforms other similarity indices in identifying meaningful structural patterns, as evidenced by higher Gini coefficients and more pronounced diagonal structures in similarity heatmaps.

## Method Summary
DOCS computes weight matrix similarity by first calculating cosine similarity between all pairs of column vectors from two weight matrices. For each column in the first matrix, it extracts the maximum absolute cosine similarity with any column in the second matrix, and vice versa. These maximum values are fitted to Gumbel distributions using maximum likelihood estimation, and the similarity score is computed as the average of the location parameters from both distributions. The method is designed to be discriminative for orthogonal matrices, which are common in LLMs, by focusing on maximum alignments rather than aggregated statistics. DOCS satisfies key properties including reflexivity, symmetry, and permutation invariance, and is invariant to matrix transposition.

## Key Results
- DOCS reveals structural patterns in LLMs, with adjacent layers showing high similarity and forming clusters, suggesting functional specialization
- DOCS outperforms existing methods (Linear CKA, SVCCA) on weight matrices, achieving higher Gini coefficients (0.0745 vs 0.0488) and clearer diagonal structures in heatmaps
- DOCS effectively distinguishes between experts in MoE architectures while showing high similarity between base and instruction-tuned models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Maximum cosine similarity captures structural differences in orthogonal matrices that aggregate methods miss.
- Mechanism: Instead of aggregating all pairwise cosine similarities (which dilutes signal), DOCS extracts the maximum alignment for each column vector. This preserves the strongest correspondences. The Gumbel distribution then models the central tendency of these extreme values, yielding a single similarity score.
- Core assumption: Weight matrices in trained LLMs retain meaningful column-wise structure that reflects functional specialization (not purely random orthogonal matrices).
- Evidence anchors:
  - [Section 2] Table 1 shows DOCS is "Discriminative on Orthogonal Matrices" while CCA, SVCCA, Linear CKA are "Constant."
  - [Section 3.1] Theorem 1 proves DOCS can distinguish between orthogonal matrices X, Y with Frobenius difference Ω(√m) and DOCS score 1/√m.
  - [Corpus] Limited direct corpus validation; related work (ProcrustesGPT, POET) addresses orthogonal transformations but doesn't directly benchmark DOCS.
- Break condition: If weight matrices are near-identity with no functional structure, maximum cosine similarities converge uniformly, and DOCS loses discriminative power.

### Mechanism 2
- Claim: Residual connections decouple representation similarity from weight similarity.
- Mechanism: In transformers, y = F(x, W) + x creates direct input-output correlation across layers via skip connections. Two layers can produce similar representations even with dissimilar weights, because the identity shortcut dominates. DOCS bypasses this by analyzing weights directly.
- Core assumption: Weight matrices encode functional specializations that are obscured when analyzing representations alone.
- Evidence anchors:
  - [Section 1] Equation 1 and explanation of residual connections creating "correlations between the inputs of different layers."
  - [Section 1] Figures 1a, 1b show representation similarity (Linear CKA) has similar patterns at FFN input and output, while Figure 1d (DOCS) reveals distinct weight structures.
  - [Corpus] No corpus papers directly address this weight-vs-representation distinction.
- Break condition: In architectures without residual connections, representation similarity may correlate more strongly with weight similarity, reducing DOCS's relative advantage.

### Mechanism 3
- Claim: Fitting Gumbel distributions to max similarities provides robust similarity quantification insensitive to outliers.
- Mechanism: The maximum of many random variables follows an extreme value distribution (Gumbel). By fitting this distribution and extracting the location parameter, DOCS summarizes the "typical maximum alignment" rather than being skewed by individual outliers or averaging over weak alignments.
- Core assumption: Maximum cosine similarities across vector pairs follow approximately Gumbel distributions in trained LLM weight matrices.
- Evidence anchors:
  - [Section 3] Algorithm 1 specifies Gumbel fitting with MLE for location parameters.
  - [Appendix G] Figure 12 shows empirical histograms of max cosine similarities closely matching fitted Gumbel distributions for Llama-3.1-8B layers 4 and 8.
  - [Corpus] No corpus validation of Gumbel assumption in other model families.
- Break condition: If max similarities are uniformly distributed or bimodal (not Gumbel-like), the location parameter may not meaningfully represent central tendency.

## Foundational Learning

- Concept: **Orthogonal matrices and their properties**
  - Why needed here: LLM weight matrices often approach orthogonality (Q^T Q = I). Existing similarity indices (CCA, CKA, SVCCA) return constant values for any pair of orthogonal matrices, making them useless for this domain.
  - Quick check question: Given two 3×3 orthogonal matrices with Frobenius norm √3 each, what would Linear CKA return as their similarity score?

- Concept: **Extreme value distributions (Gumbel)**
  - Why needed here: DOCS models the distribution of maximum cosine similarities using Gumbel distributions. Understanding that maxima of random samples converge to Gumbel helps justify this design choice.
  - Quick check question: If you take the maximum of 100 samples from a uniform(0,1) distribution and repeat this 1000 times, what distribution will your 1000 maxima approximate?

- Concept: **Residual connections in transformers**
  - Why needed here: Residual connections (y = F(x) + x) create correlations between layer representations regardless of weight similarity. This is why representation-based similarity metrics (Linear CKA on activations) can miss weight-level structural patterns.
  - Quick check question: If layer 5's output feeds directly into layer 6's output via a residual connection, would you expect their activations to be similar even if their weights are unrelated?

## Architecture Onboarding

- Component map:
```
Input: Two weight matrices X, Y ∈ R^(n×m)
  ↓
[Cosine Similarity Matrix] Compute C_jk = (X_j^T · Y_k) / (||X_j|| · ||Y_k||)
  ↓
[Max Extraction] For each column j: s_X[j] = max_k |C_jk|, s_Y[k] = max_j |C_jk|
  ↓
[Gumbel Fitting] Fit Gumbel distributions to s_X and s_Y via MLE → location params u_X, u_Y
  ↓
[Score Aggregation] S_DOCS = (u_X + u_Y) / 2
  ↓
Output: Scalar similarity ∈ [0, 1]
```

- Critical path:
  1. Transpose weight matrices correctly (paper notes W_v, W_k, W_q, MLP-UP need transposition to treat columns as parameter vectors).
  2. Maximum extraction step is essential—Appendix G Figure 13 shows averaging instead produces noisy heatmaps with no structure.
  3. Gumbel fitting via MLE; verify convergence on your data.

- Design tradeoffs:
  - Maximum vs. average: Max operation focuses on strongest alignments (better structure detection) but may miss global patterns.
  - Gumbel vs. empirical statistics: Gumbel provides robustness but assumes extreme value distribution; verify this holds (Appendix G Figure 12 shows validation approach).
  - Permutation invariance: DOCS satisfies this (Appendix A.1), meaning neuron ordering doesn't affect scores—useful when comparing models with different internal orderings.

- Failure signatures:
  - Heatmap appears uniformly random → Check if matrices are truly trained weights vs. random initialization (Figure 11 shows random init produces no structure).
  - DOCS ≈ 1 for all pairs → Matrices may be near-identical; verify by checking Frobenius norm difference.
  - Gumbel fit fails → Max similarity distribution may be degenerate (all 1s or all same value); check data diversity.

- First 3 experiments:
  1. Replicate Figure 2 on a single model: Compute DOCS, Linear CKA, SVCCA heatmaps for MLP-UP weights. Verify DOCS shows clearer diagonal structure and higher Gini coefficient (Table 2: 0.0745 vs. 0.0488).
  2. Orthogonal matrix test: Generate random orthogonal matrices X, Y of varying dimensions. Confirm Linear CKA returns ~1.0 for all pairs while DOCS varies (Appendix A.5 shows example: 0.88 vs. 0.76 for different pairs).
  3. Base vs. instruct model comparison: Compute DOCS between corresponding layers of Llama-3.1-8B (base) and Llama-3.1-8B-Instruct. Verify scores exceed 0.7 and cluster by matrix type (Figure 6: MLP-UP/MLP-DOWN grouped, W_q/W_k grouped, W_v/W_o grouped).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Is the distinctiveness of specific experts in Mixture of Experts (MoE) models directly caused by data load imbalance during training?
- Basis in paper: [explicit] The authors observe distinct experts in Mixtral-8x7B and state, "We hypothesize that this may be related to data load imbalance during the MoE training process."
- Why unresolved: The paper establishes the observation of distinct experts but only offers a hypothesis for the causal mechanism without experimental validation.
- What evidence would resolve it: Analyzing routing logs to correlate the degree of expert dissimilarity (measured by DOCS) with the volume of tokens processed by each expert.

### Open Question 2
- Question: Can the layer clusters identified by DOCS be utilized to design non-uniform layer configurations that improve model efficiency?
- Basis in paper: [explicit] The authors argue that observed clusters "challenge the common practice of uniform layer configurations" and suggest applying "distinct configuration to those layers, such as adjusting neuron sizes."
- Why unresolved: While the paper identifies the clusters, it does not experiment with architectural modifications to test if leveraging these clusters actually yields efficiency gains.
- What evidence would resolve it: Training models with variable layer widths or sparsity levels aligned with DOCS-identified clusters and comparing performance/efficiency against uniform baselines.

### Open Question 3
- Question: Does DOCS maintain its discriminative power and structural clarity when applied to encoder-only or encoder-decoder architectures?
- Basis in paper: [inferred] The paper states it "primarily focus on decoder-only architectures," leaving the method's effectiveness on other major transformer families unstated.
- Why unresolved: Weight matrix structures and the role of residual connections may differ in encoder architectures, potentially affecting the validity of the Gumbel distribution assumptions.
- What evidence would resolve it: Applying DOCS to models like BERT or T5 and evaluating the resulting Gini coefficients and heatmap structures against the decoder-only baselines.

## Limitations
- The Gumbel distribution assumption for maximum cosine similarities remains empirically validated only on Llama-3.1-8B (Figure 12), with no corpus evidence confirming this holds across diverse model architectures.
- The method's performance on convolutional networks, recurrent architectures, or models with alternative weight initialization schemes is unknown.
- Generalization claims across model architectures and training paradigms lack corpus validation.

## Confidence
- **High Confidence**: DOCS outperforms existing similarity indices on Llama-3.1-8B for weight matrix comparison (Table 2 Gini coefficients, Figure 2 heatmap structures)
- **Medium Confidence**: DOCS reveals meaningful structural patterns (adjacent layer clustering, expert differentiation) based on single model family evidence
- **Low Confidence**: Generalization claims across model architectures and training paradigms lack corpus validation

## Next Checks
1. **Distribution Validation Across Architectures**: Test Gumbel fit quality on weight matrices from at least 3 different model families (e.g., GPT, BERT, OPT) and 2 different sizes. Document fit quality metrics (KS test p-values, visual QQ plots) for each case.

2. **Architectural Transfer**: Apply DOCS to non-transformer architectures (ConvNets, RNNs) to verify whether weight similarity patterns remain interpretable. Compare DOCS heatmaps with established architectural patterns.

3. **Training Dynamics Study**: Track DOCS scores across training checkpoints (e.g., every 10% of training) to validate whether similarity patterns emerge consistently and correlate with known training phenomena like lottery ticket behavior or weight decay effects.