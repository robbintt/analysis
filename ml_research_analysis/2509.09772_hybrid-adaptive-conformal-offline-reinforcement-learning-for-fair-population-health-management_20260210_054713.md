---
ver: rpa2
title: Hybrid Adaptive Conformal Offline Reinforcement Learning for Fair Population
  Health Management
arxiv_id: '2509.09772'
source_url: https://arxiv.org/abs/2509.09772
tags:
- risk
- conformal
- subgroup
- safe
- calibration
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper addresses safe and fair decision-making in population\
  \ health management (PHM) programs, where care coordinators must choose among coordination\
  \ actions (e.g., outreach modality, service routing) while minimizing near-term\
  \ risk of adverse events (e.g., emergency department visits). To tackle this, the\
  \ authors propose HACO (Hybrid Adaptive Conformal Offline Reinforcement Learning),\
  \ a two-stage framework that decouples risk calibration from preference optimization:\
  \ a conformal risk model first identifies a safe action set at a tunable risk level\
  \ \u03B1, and a preference policy is then trained on this subset."
---

# Hybrid Adaptive Conformal Offline Reinforcement Learning for Fair Population Health Management

## Quick Facts
- arXiv ID: 2509.09772
- Source URL: https://arxiv.org/abs/2509.09772
- Reference count: 21
- One-line primary result: HACO achieves AUC~0.81 risk prediction, reduces observed harm rate from ~1.82% to ~1.15% at α=0.10 while retaining ~88% of steps as safe.

## Executive Summary
This paper tackles safe and fair decision-making in population health management (PHM) programs, where care coordinators must select from coordination actions while minimizing near-term risk of adverse events. The authors propose HACO (Hybrid Adaptive Conformal Offline Reinforcement Learning), a two-stage framework that first calibrates a risk model using conformal prediction to identify a safe action set at a tunable risk level α, then trains a preference policy only on this safe subset. Evaluated on a de-identified dataset of 2.77 million steps from Waymark's Medicaid PHM operations, HACO demonstrates that conformal gating can provide a conservative, auditable safety layer while maintaining reasonable coverage and performance. Subgroup analyses reveal systematic differences in estimated value across demographics, highlighting the need for fairness auditing in healthcare RL applications.

## Method Summary
HACO implements a two-stage offline RL pipeline for safe population health management. First, a logistic regression risk model estimates p(harm|s_t) using state features from JSON data, time step, and previous reward. A conformal calibration procedure then computes a threshold τ on a held-out slice such that the probability of observing a risk score above τ is bounded by user-specified error rate α. This threshold acts as a hard gate, masking actions that exceed the allowable risk level before the preference policy is trained. The preference model (multinomial logistic regression) learns only on the "safe" subset of offline data, prioritizing high-value actions among those that survived the risk gate. Policy evaluation uses a version-agnostic Fitted Q Evaluation (FQE) with linear function approximation and ridge regression, enabling consistent comparison across different offline RL methods without requiring live deployment.

## Key Results
- Risk model achieves AUC ~0.81 on held-out test data
- At α=0.10, HACO reduces observed harm rate from ~1.82% to ~1.15% while retaining ~88% of steps as safe
- Subgroup analyses across age, sex, and race reveal systematic differences in estimated value
- FQE-estimated value (V₀) shows HACO performs comparably to behavior cloning while enforcing safety constraints

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Conformal calibration provides a statistically grounded safety threshold that filters high-risk actions before policy optimization.
- Mechanism: A lightweight risk model estimates p(harm|s_t) using logistic regression. A threshold τ is computed on a held-out calibration slice such that the probability of observing a risk score above τ is bounded by a user-specified error rate α. This threshold acts as a hard gate, masking actions that exceed the allowable risk level before the preference policy is trained.
- Core assumption: The calibration data is exchangeable with the test distribution; if dataset shift occurs, the finite-sample guarantee may degrade.
- Evidence anchors:
  - [abstract] "derives a conformal threshold to mask unsafe actions at a target risk level"
  - [Section 5.1] "We then compute a conformal threshold τ(α)... yielding a safe action set mask at risk level α."
  - [corpus] "Adaptive Conformal Prediction via Bayesian Uncertainty Weighting" (arXiv:2601.01223) supports the utility of hybrid conformal methods in hierarchical healthcare data.
- Break condition: Significant non-stationarity in patient risk profiles violates exchangeability, rendering the marginal guarantee invalid.

### Mechanism 2
- Claim: Decoupling risk calibration from preference learning preserves a "safety dial" without restricting the policy's ability to optimize value.
- Mechanism: By separating the architecture into two stages—first a binary risk filter, then a preference optimizer—HACO avoids the difficulty of balancing safety constraints inside the RL loss function. The preference model (a multinomial logistic regression) learns only on the "safe" subset of offline data, prioritizing high-value actions among those that survived the risk gate.
- Core assumption: The "safe" subset of data retains sufficient diversity and volume to learn a meaningful preference ranking.
- Evidence anchors:
  - [abstract] "separates risk calibration from preference optimization... generates conservative action recommendations"
  - [Section 5.1] "This separation gives a tunable safety dial without constraining the preference model class."
  - [corpus] "Feasibility-Guided Fair Adaptive Offline RL" (arXiv:2509.09655) similarly explores calibrating safety thresholds distinct from policy optimization.
- Break condition: If the conformal threshold is overly aggressive (low α), the safe set becomes too sparse for the preference model to differentiate action quality.

### Mechanism 3
- Claim: A version-agnostic Fitted Q Evaluation (FQE) enables consistent, apples-to-apples comparison of offline policies without requiring a live environment.
- Mechanism: FQE learns a Q-function Q(s,a) by iteratively applying Bellman backups on the offline dataset using a linear function approximator (ridge regression). It estimates the initial value V₀ for any policy (e.g., HACO, BC, IQL) by simulating policy rollout through the learned Q-function, avoiding library-specific instabilities.
- Core assumption: The linear function approximator is sufficiently expressive to capture the value differences for the audit to be meaningful.
- Evidence anchors:
  - [Section 5.3] "We implement a version-agnostic fitted Q evaluation (FQE)... robust to environment/library drift."
  - [Table 4] Shows comparative V₀ scores derived from FQE.
  - [corpus] "PyCFRL" (arXiv:2510.06935) discusses counterfactually fair OPE, validating the need for stable offline evaluation in RL.
- Break condition: High bias in the linear Q-approximator could obscure real differences in policy performance, making harmful policies appear acceptable.

## Foundational Learning

- **Concept: Conformal Prediction**
  - Why needed here: To convert raw risk probabilities into a binary decision boundary with a mathematically provable upper bound on error rates (e.g., "we guarantee <10% of recommended actions are high-risk").
  - Quick check question: If the underlying data distribution shifts (e.g., a new patient population), does the conformal guarantee still hold?

- **Concept: Offline Reinforcement Learning (Offline RL)**
  - Why needed here: To learn decision policies from fixed historical datasets without risking patient harm through trial-and-error exploration in the real world.
  - Quick check question: Why do standard RL algorithms (like DQN) fail when trained solely on offline data? (Answer: Extrapolation error/Distributional shift).

- **Concept: Off-Policy Evaluation (OPE)**
  - Why needed here: To estimate the performance of a new policy (HACO) using historical data generated by a different policy (the human care coordinators).
  - Quick check question: Why is Importance Sampling often high-variance in healthcare trajectories, and how does FQE offer a more stable alternative?

## Architecture Onboarding

- **Component map**: Data Loader -> Risk Model -> Conformal Calibrator -> Safety Filter -> Preference Policy -> FQE Auditor

- **Critical path**: The integrity of the Conformal Calibrator is the single point of failure for safety. If the calibration set is not exchangeable with deployment data (e.g., temporal drift), the safety guarantee collapses.

- **Design tradeoffs**:
  - **Safety vs. Coverage**: Lowering α (stricter safety) reduces the "safe fraction" (Figure 2), potentially leaving the system with too few actions to recommend.
  - **Model Capacity vs. Auditability**: The paper uses simple Logistic Regression for risk and preference to maintain interpretability and stability, sacrificing the potential performance gains of deep neural networks.

- **Failure signatures**:
  - **Coverage Collapse**: Safe fraction drops < 50%, causing the policy to default to "do nothing" or random actions.
  - **Subgroup Decoupling**: Calibration plots (Figure 3) show specific demographic groups (e.g., age 65+) consistently above the identity line (under-estimated risk).
  - **FQE Divergence**: Q-values explode or oscillate, indicating the linear approximator cannot fit the value function.

- **First 3 experiments**:
  1. **Calibration Sensitivity**: Sweep α ∈ [0.05, 0.20] and plot the trade-off curve between "Observed Harm Rate" and "Safe Action Coverage."
  2. **Subgroup Audit**: Generate calibration plots by race and age (mimicking Figure 3) to verify that the single global threshold τ does not systematically underserve specific subgroups.
  3. **Baseline Comparison**: Run FQE on HACO vs. Behavior Cloning (BC) vs. IQL on a stratified subset to verify that HACO maintains comparable V₀ while enforcing the safety constraint.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can contextual or conditional conformal coverage guarantees be achieved in sequential decision-making settings, rather than only marginal guarantees?
- Basis in paper: [explicit] "Although conformal calibration provides finite-sample marginal guarantees, contextual or conditional coverage remains an open area for future adaptation in sequential settings."
- Why unresolved: Standard conformal prediction assumes exchangeability, which may be violated in sequential RL trajectories where state distributions shift over time and across patient subgroups.
- What evidence would resolve it: A modified conformal procedure that maintains coverage guarantees conditional on patient demographics or state features, validated on held-out sequential data.

### Open Question 2
- Question: Would richer representation learning (e.g., recurrent or transformer architectures) meaningfully improve preference policy ranking over the current multinomial logistic regression?
- Basis in paper: [explicit] "Our preference model is deliberately simple; richer representation learning (e.g., recurrent or transformer architectures) may improve policy ranking."
- Why unresolved: The paper prioritized interpretability and scalability; the potential gains from more expressive architectures remain unquantified.
- What evidence would resolve it: Head-to-head comparison of HACO with transformer-based preference models on the same dataset, reporting FQE values and safe coverage metrics.

### Open Question 3
- Question: Why does HACO achieve nearly identical FQE-estimated value to behavior cloning (both ≈-0.1669), and under what conditions would the conformal gate provide demonstrable policy improvement?
- Basis in paper: [inferred] Table 4 shows HACO and BC have equivalent V₀ despite HACO's conformal safety gating; the paper does not explain this parity or when separation would emerge.
- Why unresolved: The FQE uses a linear function approximator that may lack discriminability; alternatively, the safe subset may already align closely with the behavior policy's high-value actions.
- What evidence would resolve it: Ablation studies with richer FQE function classes, and analysis of action distribution divergence between HACO and BC on the safe set.

### Open Question 4
- Question: How does HACO generalize across different Medicaid plans, geographic regions, and care coordination workflows beyond the single Waymark dataset?
- Basis in paper: [explicit] "Generalizability may be constrained by geography and plan-specific practices."
- Why unresolved: The model was trained and evaluated on one operational dataset; risk distributions and action semantics may differ substantially across payers or states.
- What evidence would resolve it: External validation on independent Medicaid PHM datasets from different plans or regions, with subgroup calibration and safety metrics reported.

## Limitations

- The conformal safety guarantee critically depends on the calibration data being exchangeable with deployment data; temporal drift or demographic shifts could invalidate the safety threshold.
- The single global conformal threshold τ may systematically underserve certain subgroups, as calibration curves show different risk distributions across demographics.
- Feature engineering opacity exists due to unspecified exact feature set derived from JSON and time step, making exact replication challenging.

## Confidence

- **High confidence**: The core mechanism of decoupling risk calibration from preference optimization is well-supported by methodology and experimental results. The AUC≈0.81 for the risk model and the empirical safety-coverage trade-off are directly measurable and reproducible.
- **Medium confidence**: The FQE implementation using linear function approximation is appropriate for the audit purpose, but the paper does not validate whether the linear capacity is sufficient to capture meaningful value differences between policies.
- **Low confidence**: The behavior of HACO under significant dataset shift or when the safe subset becomes too sparse (coverage <50%) is not empirically characterized.

## Next Checks

1. **Temporal robustness test**: Re-split the data using a later period for calibration (e.g., 2020-2021) and evaluate whether the conformal threshold maintains its safety guarantee on a held-out recent test set. This directly tests the exchangeability assumption.

2. **Subgroup-specific calibration**: Implement and compare subgroup-specific conformal thresholds versus the global threshold. Measure the impact on both safety (harm rate) and fairness (value distribution across subgroups) to validate the identified fairness trade-off.

3. **Coverage sensitivity analysis**: Systematically sweep α from 0.05 to 0.20 and plot the resulting safe coverage and observed harm rate. Verify that the coverage does not drop below a critical threshold (e.g., 50%) where the policy becomes non-functional.