---
ver: rpa2
title: 'Tracing Multilingual Knowledge Acquisition Dynamics in Domain Adaptation:
  A Case Study of English-Japanese Biomedical Adaptation'
arxiv_id: '2510.12115'
source_url: https://arxiv.org/abs/2510.12115
tags:
- knowledge
- loss
- training
- domain
- evaluation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates multilingual knowledge acquisition dynamics
  in domain adaptation, focusing on English-Japanese biomedical adaptation. The authors
  introduce AdaXEval, an adaptive evaluation pipeline that generates multiple-choice
  QA datasets from the same bilingual domain corpus used for training, enabling direct
  assessment of knowledge memorization, intralingual generalization, and cross-lingual
  transfer.
---

# Tracing Multilingual Knowledge Acquisition Dynamics in Domain Adaptation: A Case Study of English-Japanese Biomedical Adaptation

## Quick Facts
- arXiv ID: 2510.12115
- Source URL: https://arxiv.org/abs/2510.12115
- Reference count: 40
- Primary result: Introduces AdaXEval to trace knowledge acquisition dynamics in English-Japanese biomedical adaptation

## Executive Summary
This paper investigates how large language models acquire and transfer domain knowledge across languages, focusing on English-Japanese biomedical adaptation. The authors develop AdaXEval, an adaptive evaluation pipeline that generates multiple-choice QA datasets from the same bilingual corpus used for training, enabling direct assessment of knowledge memorization, intralingual generalization, and cross-lingual transfer. Through experiments with a 13B parameter bilingual LLM, they identify a "loss shielding" pattern where correct sequences resist rapid loss growth despite overfitting, and demonstrate that cross-lingual transfer remains challenging even with high-quality bilingual corpora.

## Method Summary
The authors introduce AdaXEval, an adaptive evaluation pipeline that generates multiple-choice QA datasets directly from the same bilingual domain corpus used for training. This approach enables direct measurement of three key phenomena: knowledge memorization (retention of training examples), intralingual generalization (applying knowledge within the same language), and cross-lingual transfer (applying knowledge across languages). The method employs monolingual and multilingual continual training on a 13B bilingual LLM using English-Japanese biomedical data, with systematic perturbation studies to assess model sensitivity to training data variations.

## Key Results
- Knowledge acquisition follows a "loss shielding" pattern where correct sequences resist rapid loss growth despite overfitting
- Cross-lingual transfer remains challenging even with high-quality bilingual corpora
- Token overlap in related domains is crucial for effective transfer
- LLMs are highly sensitive to training data variations as revealed by perturbation studies

## Why This Works (Mechanism)
The study reveals that knowledge acquisition dynamics in multilingual domain adaptation follow predictable patterns that can be traced through careful evaluation. The "loss shielding" phenomenon occurs because correct sequences develop resistance to loss growth during overfitting, likely due to attention pattern stabilization and embedding space convergence. Token overlap serves as a bridge for cross-lingual transfer by providing shared semantic anchors between languages, while perturbation sensitivity reflects the model's reliance on specific training data distributions for optimal performance.

## Foundational Learning
- **Domain Adaptation**: The process of adapting models trained on general data to perform well on specific domains; needed to understand why specialized biomedical knowledge requires different training approaches than general language understanding; quick check: compare model performance on general vs. domain-specific tasks
- **Cross-Lingual Transfer**: The ability of models to apply knowledge learned in one language to another language; critical for understanding multilingual knowledge acquisition; quick check: measure performance drop when applying knowledge across language pairs
- **Loss Shielding**: The observed phenomenon where correct sequences resist rapid loss growth during overfitting; important for understanding knowledge retention mechanisms; quick check: track loss trajectories for correct vs. incorrect sequences during training
- **Token Overlap**: The shared vocabulary between related domains or languages; essential for understanding transfer effectiveness; quick check: measure token overlap between source and target domains
- **Perturbation Studies**: Systematic variations in training data to assess model sensitivity; necessary for understanding robustness; quick check: compare performance across different perturbation magnitudes

## Architecture Onboarding

**Component Map**: Training Corpus -> Bilingual LLM (13B) -> AdaXEval Pipeline -> Multiple-Choice QA Datasets -> Knowledge Acquisition Metrics

**Critical Path**: Training data preparation → model training → evaluation dataset generation → metric computation → analysis of memorization/generalization/transfer patterns

**Design Tradeoffs**: The authors chose to use the same corpus for both training and evaluation (tradeoff: realistic assessment vs. potential overfitting bias) and focused on a single language pair (tradeoff: deep analysis vs. limited generalizability)

**Failure Signatures**: Poor cross-lingual transfer indicates insufficient token overlap or bilingual corpus quality issues; high perturbation sensitivity suggests over-reliance on specific training distributions; absence of loss shielding may indicate insufficient model capacity or training instability

**First 3 Experiments**:
1. Replicate the loss shielding analysis on a different domain to test generalizability
2. Conduct ablation studies on token overlap to quantify its impact on cross-lingual transfer
3. Perform attention visualization on shielded vs. non-shielded sequences to identify architectural mechanisms

## Open Questions the Paper Calls Out
None

## Limitations
- Experimental scope limited to English-Japanese biomedical adaptation, restricting generalizability to other language pairs
- Focus on single 13B parameter bilingual LLM architecture limits conclusions about architectural effects
- "Loss shielding" phenomenon requires further theoretical grounding for underlying mechanisms
- Evaluation pipeline depends heavily on source corpus quality, introducing potential assessment biases
- Perturbation studies only examine limited perturbation types and magnitudes

## Confidence

**High Confidence**: Core empirical observations about loss shielding patterns, model sensitivity to training perturbations, and cross-lingual transfer challenges are well-supported by experimental evidence.

**Medium Confidence**: Conclusions about token overlap importance and knowledge memorization vs. generalization dynamics are supported but could benefit from additional experiments across domains and language pairs.

**Low Confidence**: Theoretical explanations for loss shielding and cross-lingual knowledge acquisition mechanisms remain speculative and require further investigation.

## Next Checks

1. **Architecture Transferability**: Replicate AdaXEval pipeline and training experiments across different LLM architectures (varying parameter counts, attention mechanisms, and pretraining objectives) to assess whether observed dynamics are architecture-dependent or universal.

2. **Cross-Domain Generalization**: Extend experimental setup to multiple domain pairs beyond biomedical (legal, technical documentation) to validate whether token overlap importance and transfer challenges generalize across domains and semantic complexity levels.

3. **Theoretical Mechanistic Analysis**: Conduct ablation studies and attention visualization analyses to develop mechanistic explanations for loss shielding, investigating whether it relates to attention pattern stabilization, embedding space convergence, or other architectural factors.