---
ver: rpa2
title: 'Chat-Ghosting: A Comparative Study of Methods for Auto-Completion in Dialog
  Systems'
arxiv_id: '2507.05940'
source_url: https://arxiv.org/abs/2507.05940
tags:
- context
- prefix
- phi-2
- user
- p-rec
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies chat-ghosting, the task of auto-completing user
  input in dialog systems as they type. The authors curate and repurpose four public
  dialog datasets (DailyDialog, DSTC7-Ubuntu, Open Assistant, ShareGPT) for training
  and evaluating ghosting models.
---

# Chat-Ghosting: A Comparative Study of Methods for Auto-Completion in Dialog Systems

## Quick Facts
- **arXiv ID:** 2507.05940
- **Source URL:** https://arxiv.org/abs/2507.05940
- **Reference count:** 40
- **Primary result:** Trie-based QAC excels on seen prefixes while neural models and n-gram-based QB perform better on unseen ones; context integration improves quality especially for human-bot datasets.

## Executive Summary
This paper studies chat-ghosting—auto-completing user input in dialog systems as users type. The authors curate and repurpose four public dialog datasets (DailyDialog, DSTC7-Ubuntu, Open Assistant, ShareGPT) to train and evaluate ghosting models. They compare trie-based methods, n-gram models, neural language models (T5, GPT-2), and prompt-engineered models (Phi-2, Mistral, GPT-4) with and without dialog context. A novel entropy-based dynamic early stopping strategy is proposed to adaptively halt generation when model confidence drops. Experiments reveal that trie-based QAC excels on seen prefixes while neural models and n-gram-based QB perform better on unseen ones. Adding conversational context significantly improves quality, especially for human-bot datasets. The study highlights a trade-off between accuracy and latency, motivating future work on hybrid methods.

## Method Summary
The authors curate four dialog datasets and create ghosting datasets by splitting each utterance into prefix-completion pairs. They compare trie-based QAC (MPC/MPC++), n-gram models (QueryBlazer), neural models (GPT-2, T5), and prompt-engineered LLMs (Phi-2, Mistral, GPT-4) for auto-completion. All models can use conversation history as context, with different integration strategies (reranking for tries/n-grams, prompt engineering for LLMs). They introduce an entropy-based early stopping mechanism to halt generation when confidence drops. Models are evaluated on seen vs. unseen prefixes using task-specific metrics including Match Rate, Partial Recall/Precision, Trigger Rate, and Typing Effort Saved.

## Key Results
- Trie-based MPC achieves 86.49% Match Rate on seen prefixes but 0.00% on unseen prefixes
- Neural models (T5) achieve 6.10% Match Rate on unseen prefixes vs 0.00% for MPC
- Adding conversation context significantly improves neural model performance, especially for human-bot datasets
- Entropy-based early stopping increases T5's Partial Precision from 25.16 to 43.95 and TES from 20.88 to 45.80

## Why This Works (Mechanism)

### Mechanism 1: Trie-based Retrieval for Exact Match Dominance
The trie-based Most Popular Completion (MPC) provides superior performance on seen prefixes through deterministic retrieval, bypassing probability estimation for high accuracy on memorized sequences. The system constructs a character-level trie from historical utterances and returns the most frequent completion for any prefix found in the trie. This mechanism fails on unseen data where no exact match exists in the training logs.

### Mechanism 2: Neural Sequence Modeling for Unseen Generalization
Transformer-based models (T5, GPT-2) outperform frequency-based methods on unseen prefixes by generalizing syntactic and semantic patterns through distributed representations. Unlike tries that return 0 for unknown paths, neural models generate completions by predicting the next likely token based on learned language patterns, allowing them to handle novel inputs that weren't present in training data.

### Mechanism 3: Entropy-Based Dynamic Early Stopping
Halting generation when token probability entropy rises improves precision and typing effort saved compared to static truncation. The model calculates output distribution entropy at each generation step and stops when it exceeds a threshold (0.6), preventing "hallucination" of low-confidence continuations that would annoy users with incorrect predictions.

## Foundational Learning

- **Concept: Prefix-Suffix Splitting & Tokenizer Edge Cases**
  - Why needed: Ghosting requires completing the user's current word, not predicting the next word. Standard tokenizers handle leading spaces and word breaks differently, affecting whether the model continues a word or starts a new one.
  - Quick check: How does the T5 tokenizer handle a prefix ending in a space versus a prefix ending in the middle of a word?

- **Concept: Trigger Rate (TR) vs. Match Rate (MR) Trade-off**
  - Why needed: A model can achieve 100% accuracy if it only triggers on one easy character, or trigger on everything and be wrong often. You cannot evaluate ghosting models without understanding this operating curve.
  - Quick check: If a model has a high Match Rate but a Trigger Rate of only 10%, is it a better user experience than a model with a lower Match Rate but 90% Trigger Rate?

- **Concept: Typing Effort Saved (TES)**
  - Why needed: MR is too strict (binary). TES captures the economic value of the system—how many actual keystrokes did the user save? It simulates the user accepting partial matches.
  - Quick check: If a prediction is "apple pie" but the ground truth is "apple juice," does TES give credit for "apple "? (Yes, partial match).

## Architecture Onboarding

- **Component map:** Input Layer (Context History + Current Prefix) -> Router (Optional Trie Check) -> Model Branch (Trie/MPC or Neural/QB) -> Post-Processor (Entropy Filter + Length Penalty) -> Scorer (Ranks candidates using TF-IDF context similarity)

- **Critical path:** The interaction between the Tokenizer and the Prefix State. You must correctly inject special tokens (like `<tspace>` for T5 or handling mid-word breaks for GPT-2) so the model knows it is continuing a word, not starting a new one. Failure here causes the model to predict valid but irrelevant words that don't complete the user's typing.

- **Design tradeoffs:**
  - Latency vs. Coverage: Trie/MPC is <50ms but 0% coverage on unseen data. T5 is ~100ms but generalizes. Phi-2/Mistral are >1s (too slow for real-time typing).
  - Context Window: Adding history improves T5 significantly but increases inference time and noise for MPC (via reranking).

- **Failure signatures:**
  - The "New Word" Bug: Model predicts " has..." when user typed "I won..." (intending "wonderful") because the tokenizer treated "won" as a complete token and started a new prediction.
  - Empty Predictions: MPC++ returns nothing if the prefix isn't in the trie and the suffix trie fails.
  - Hallucination Loop: Neural models generating long, fluent but incorrect completions (mitigated by the entropy mechanism).

- **First 3 experiments:**
  1. Tokenizer Alignment Test: Verify T5/GPT-2 can correctly complete mid-word prefixes (e.g., input "hel", target "lo") vs. word-boundary prefixes (input "hel", target "lo there").
  2. Seen vs. Unseen Ablation: Run MPC and T5 on a split test set. Confirm MPC dominates seen queries and measure the performance gap where T5 takes over on unseen queries.
  3. Entropy Threshold Sweep: Plot TES and P-Prec against Trigger Rate for the neural model. Find the "elbow" where reducing confidence threshold yields diminishing returns in TES.

## Open Questions the Paper Calls Out

- **Question:** How can hybrid architectures combine trie-based methods for seen prefixes with neural models for unseen prefixes to optimize the accuracy-latency trade-off?
- **Question:** What advanced context modeling techniques can mitigate noise and irrelevance in conversation history to improve ghosting quality?
- **Question:** How can chat-ghosting be personalized by incorporating user traits like typing speed or domain expertise?
- **Question:** How can models be made robust against noisy or adversarial prefixes?

## Limitations
- The study relies on repurposed dialog datasets rather than purpose-built ghosting corpora, potentially introducing domain-specific biases
- Evaluation focuses on task-specific metrics without extensive user studies to validate claimed user experience improvements
- Neural model comparisons are limited to base-sized models, leaving questions about larger models' impact on accuracy-latency tradeoff

## Confidence

- **High Confidence:** The superiority of trie-based MPC on seen prefixes and neural models on unseen prefixes
- **Medium Confidence:** The claimed trade-off between accuracy and latency
- **Medium Confidence:** The effectiveness of entropy-based early stopping
- **Low Confidence:** The generalization of findings to real-time production systems

## Next Checks

1. **Cross-Domain Generalization Test:** Evaluate the best-performing models (T5 with context + entropy stopping) on a held-out domain not present in any training set to measure true generalization beyond the repurposing assumption.

2. **User Study Validation:** Conduct a controlled experiment measuring actual keystroke savings and user satisfaction when interacting with trie-based, neural, and hybrid systems in a realistic chat interface, comparing against the greedy TES metric predictions.

3. **Confidence Calibration Analysis:** Systematically vary the entropy threshold and measure whether it correlates with actual prediction accuracy across different prefix lengths and context types, determining if the mechanism is capturing genuine uncertainty or merely token frequency effects.