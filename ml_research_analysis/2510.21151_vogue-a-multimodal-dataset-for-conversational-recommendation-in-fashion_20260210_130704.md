---
ver: rpa2
title: 'VOGUE: A Multimodal Dataset for Conversational Recommendation in Fashion'
arxiv_id: '2510.21151'
source_url: https://arxiv.org/abs/2510.21151
tags:
- seeker
- assistant
- recommendation
- personal
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: VOGUE is a multimodal conversational recommendation dataset for
  fashion shopping featuring 60 real human dialogues with visual catalogs, user profiles,
  and post-conversation item ratings. The dataset enables evaluation of preference
  alignment, calibration, and user satisfaction in visually grounded dialogue.
---

# VOGUE: A Multimodal Dataset for Conversational Recommendation in Fashion

## Quick Facts
- arXiv ID: 2510.21151
- Source URL: https://arxiv.org/abs/2510.21151
- Reference count: 40
- Key outcome: MLLMs exhibit systematic rating distribution errors and poor generalization in fashion CRS, while human Assistants achieve high preference alignment and satisfaction.

## Executive Summary
VOGUE is a multimodal conversational recommendation dataset for fashion shopping featuring 60 real human dialogues with visual catalogs, user profiles, and post-conversation item ratings. The dataset enables evaluation of preference alignment, calibration, and user satisfaction in visually grounded dialogue. Analysis reveals a five-stage conversation structure with grouped item recommendations, comparative reasoning, and iterative refinement. Human Assistants achieve high preference alignment (Pearson correlation ~0.64) and satisfaction scores (>4.5/5), while state-of-the-art MLLMs like GPT-4o-mini, GPT-5-mini, and Gemini-2.5-Flash underperform, exhibiting systematic rating distribution errors and poor generalization beyond explicitly discussed items. VOGUE thus establishes a benchmark for multimodal CRS and highlights key challenges for advancing MLLM-based recommenders.

## Method Summary
VOGUE is constructed from 60 human-human dialogues about fashion shopping, where Seekers discuss their preferences with Assistants using a visual catalog of 12 items each. The dataset includes complete dialogue transcripts, item metadata (images + descriptions), user profiles, and post-conversation item ratings from both parties. MLLMs are evaluated zero-shot using a prompt template that provides the full item catalog, metadata, and tagged transcript. Performance is measured against Seeker ground-truth ratings using Pearson Correlation, MAE, Macro-MAE, and per-class MAE metrics. Baselines include Random sampling and Mode Rating (always predict 1).

## Key Results
- Human Assistants achieve Pearson correlation ~0.64 and satisfaction scores >4.5/5 in rating prediction.
- MLLMs exhibit systematic rating distribution errors: Gemini over-predicts low ratings, GPT-4o-mini collapses to normal distribution.
- MLLMs struggle to generalize preference inference to undiscussed items, relying heavily on explicit dialogue cues.

## Why This Works (Mechanism)

### Mechanism 1: Visual Grounding Enables Parallel Item Exploration
Visual catalogs allow grouped recommendations (2–4 items simultaneously) that accelerate preference convergence compared to sequential text-only flows. This creates bimodal recommendation waves—initial broad exploration followed by refinement—rather than linear item-by-item presentation.

### Mechanism 2: Five-Stage Dialogue Structure Emerges from Role Dynamics
Fashion CRS dialogues follow a predictable five-stage pattern (Elicitation → Recommendation → Critique → Refinement → Agreement) where initiative oscillates between roles. Visual grounding keeps stages compact (avg. 14.8 turns, 36 tokens/turn).

### Mechanism 3: Rating Distribution Miscalibration Undermines MLLM Preference Modeling
MLLMs exhibit systematic distribution errors—Gemini over-predicts low ratings, GPT-4o-mini collapses to a normal distribution—that weaken preference alignment, even when aggregate accuracy appears competitive.

## Foundational Learning

- **Concept: Preference Alignment Metrics (Pearson Correlation vs. MAE)**
  - Why needed here: The paper uses PC to measure directional preference recovery and MAE to measure intensity accuracy. High PC with high MAE indicates correct ranking but poor calibration—critical for understanding MLLM limitations.
  - Quick check question: If a model predicts ratings [5, 4, 3, 2, 1] for items a user rated [4, 3, 2, 1, 5], what would PC and MAE reveal about alignment?

- **Concept: Conversational Intent Taxonomy**
  - Why needed here: The paper extends prior taxonomies to fashion-specific intents (e.g., Critique-Compare, Explain-Preference). Understanding these is essential for stage analysis and system design.
  - Quick check question: Which Seeker intent signals transition from Stage 2 (Recommendation) to Stage 3 (Critique)?

- **Concept: Rating Distribution Calibration**
  - Why needed here: Class imbalance (44% 1s) makes accuracy misleading; Macro-MAE and per-class MAE reveal systematic biases masked by aggregate metrics.
  - Quick check question: Why does a "Mode Rating" baseline (predicting all 1s) achieve competitive accuracy but fail as a useful recommender?

## Architecture Onboarding

- **Component map:** Dialogue Module -> Preference Model -> Recommendation Engine -> Evaluation Layer
- **Critical path:** Accurate intent tagging → Stage detection → Context-aware recommendation grouping → Preference model maintains calibrated rating distributions AND generalizes beyond explicitly discussed items → Alignment with Seeker ground truth (PC ~0.64 human baseline) → correlates with satisfaction (>4.5/5)
- **Design tradeoffs:** Grouped vs. Sequential Recommendations (accelerates convergence vs. cognitive overload); Fine-grained vs. Coarse Intent Tags (precise stage modeling vs. annotation effort); Accuracy vs. Calibration (trivial strategies vs. preference intensity)
- **Failure signatures:** Rating distribution collapse (MLLM outputs cluster around 3 or over-predict extremes); Stage confusion (recommends before sufficient elicitation or fails to refine after critique); Generalization gap (high accuracy on mentioned items, poor on unmentioned)
- **First 3 experiments:** 1) Baseline calibration check: Run MLLM on VOGUE, plot predicted vs. ground-truth rating distributions; compute per-class MAE to identify systematic biases. 2) Stage-aware prompting: Modify prompt to include stage indicators; measure impact on alignment and convergence speed. 3) Ablate visual grounding: Run dialogue evaluation with text-only metadata; compare turn counts, recommendation grouping behavior, and alignment.

## Open Questions the Paper Calls Out

- **Open Question 1:** How can the identified five-stage dialogue structure and grouped recommendation patterns be operationalized in automated CRS architectures?
- **Open Question 2:** How can MLLMs be enhanced to generalize preference inference to items not explicitly discussed in the conversation?
- **Open Question 3:** What training interventions or architectural modifications are required to correct the systematic rating distribution errors in MLLMs?

## Limitations

- The five-stage dialogue structure may not generalize beyond the specific dataset's elicitation protocol and geographic market.
- MLLM evaluations use zero-shot prompting without fine-tuning, not isolating whether gaps stem from fundamental limitations or insufficient task-specific adaptation.
- Rating prediction assumes static user preferences post-dialogue, not accounting for evolving preferences in dynamic CRS systems.

## Confidence

- **High Confidence:** Dataset construction methodology, basic statistics (60 dialogues, 12 items per catalog, 5-stage structure), and human performance benchmarks (PC ~0.64, satisfaction >4.5/5).
- **Medium Confidence:** Claims about MLLM systematic calibration failures are supported but interpretation as fundamental limitations requires validation.
- **Medium Confidence:** Visual grounding's contribution to grouped recommendations is observed but not experimentally isolated.

## Next Checks

1. Analyze an additional 30 dialogues from a different fashion retailer to test whether the five-stage structure holds across different elicitation protocols.
2. Fine-tune a smaller MLLM on VOGUE's rating distributions to evaluate whether distributional calibration improves.
3. Create a text-only version of VOGUE and rerun dialogue analysis to quantify the specific contribution of visual features to recommendation grouping and stage dynamics.