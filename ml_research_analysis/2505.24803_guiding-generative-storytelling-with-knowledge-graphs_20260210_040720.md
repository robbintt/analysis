---
ver: rpa2
title: Guiding Generative Storytelling with Knowledge Graphs
arxiv_id: '2505.24803'
source_url: https://arxiv.org/abs/2505.24803
tags:
- story
- participants
- narrative
- generation
- stage
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors integrated a knowledge graph (KG) into an LLM-driven
  story generation pipeline to improve long-form coherence and user control. Users
  could edit the KG after each generated scene, allowing them to reshape the narrative
  structure and details in real time.
---

# Guiding Generative Storytelling with Knowledge Graphs

## Quick Facts
- arXiv ID: 2505.24803
- Source URL: https://arxiv.org/abs/2505.24803
- Reference count: 16
- Authors integrated KG into LLM pipeline for long-form coherence and user control

## Executive Summary
This paper presents a knowledge graph (KG)-augmented pipeline for interactive story generation that improves long-form coherence and user control. The system extracts entities and relationships from each generated scene into a KG, retrieves relevant subgraphs for subsequent scenes, and allows users to edit the KG structure directly. In a user study (N=15), KG-assisted stories significantly outperformed non-KG stories in action-oriented narratives across multiple quality dimensions, while showing no advantage for introspective genres.

## Method Summary
The authors developed a three-stage loop for story generation: (1) extract entities and relations from the previous scene into a KG, (2) retrieve a relevant subgraph based on current context, and (3) inject this subgraph into the prompt to generate the next scene. Users could edit the KG after each scene, with changes either regenerating the current scene or updating context for the next. The system was implemented using Llama 3.1 8B models and tested with both "Kinetic" (action-oriented) and "Introspective" (emotion-focused) story prompts in a user study comparing KG and non-KG conditions.

## Key Results
- KG-assisted stories significantly outperformed non-KG stories in action-oriented narratives (characters: p=0.016, pace: p=0.053, structure: p=0.083)
- No significant improvements for introspective genres with KG assistance
- Participants reported high engagement and strong sense of control when editing the KG
- The approach proved effective for interactive, action-focused storytelling but less suitable for emotionally complex narratives

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Externalizing narrative state into a Knowledge Graph (KG) improves long-form coherence by grounding the LLM in established entities and relationships, reducing hallucinations.
- **Mechanism:** The system uses a three-stage loop: (1) Extract entities/relations from the previous scene into the KG; (2) Retrieve a relevant subgraph ($kg_i$) based on the current context; (3) Inject this subgraph into the prompt to generate the next scene. This bypasses the LLM's limited context window and tendency to "forget" details.
- **Core assumption:** The LLM adheres more strictly to structured, explicit constraints (nodes/edges) than to unstructured context in a long prompt.
- **Evidence anchors:** [abstract]: "...integrated a knowledge graph (KG) into an LLM-driven story generation pipeline to improve long-form coherence..."; [section]: "By structuring information into interconnected entities and relationships, KGs can systematically track story elements, mitigating hallucination..." (Page 2, Related Work).

### Mechanism 2
- **Claim:** Direct user editing of the Knowledge Graph provides a higher sense of agency and control compared to prompt engineering alone.
- **Mechanism:** The interface allows users to intervene at the structural level (adding/removing nodes/edges) rather than the lexical level. When a user edits the graph, the system regenerates the scene or updates the context for the next scene, forcing the LLM to adhere to the new structural constraints.
- **Core assumption:** Users can effectively translate abstract creative intent into structural graph edits (e.g., adding a "Hostile" relationship to increase conflict).
- **Evidence anchors:** [abstract]: "Participants reported high engagement and a strong sense of control when editing the KG..."; [section]: "...editable KG offers a direct interface for end users to modify narrative elements at the structural level, potentially making control more transparent than prompt-only workflows." (Page 2, Section 1).

### Mechanism 3
- **Claim:** The effectiveness of KG guidance is conditional on the narrative type; it significantly aids "Kinetic" (action-oriented) stories but hinders "Introspective" (internal/emotional) stories.
- **Mechanism:** Action stories rely on external, verifiable states (location, objects, physical status) which map 1:1 to graph nodes. Introspective stories rely on internal states (emotions, memory) which are fluid and often contradictory; forcing them into a rigid graph structure appears to make the story "bland" or "literal" (Page 14).
- **Core assumption:** The specific 8B model used lacks the Theory of Mind required to bridge the gap between rigid graph states and subtle emotional subtext.
- **Evidence anchors:** [abstract]: "...KG-assisted stories outperformed non-KG stories in action-oriented narratives... but not in introspective genres."; [section]: "Kinetic Narratives draw heavily on physical objects... [Introspective stories]... are difficult to represent in a purely externalized, node-edge format." (Page 17, Discussion).

## Foundational Learning

- **Concept:** Retrieval-Augmented Generation (RAG)
  - **Why needed here:** The core architecture relies on Graph RAG (retrieving a subgraph $kg_i$) to ground the LLM. Without understanding RAG, the flow of data from "Graph" to "Prompt" is opaque.
  - **Quick check question:** Does the system retrieve the *entire* graph for every scene, or a subset? (See Page 6, Algorithm 1).

- **Concept:** Knowledge Graph Schemas (Ontology)
  - **Why needed here:** The paper defines a specific format: `A! B! R : D`. You must understand that the system can only track what the schema allows (Characters, Locations). The failure in "Introspective" stories is largely a schema limitation.
  - **Quick check question:** Based on the paper's results, what new schema element would be required to support "Introspective" narratives?

- **Concept:** Iterative Context Management
  - **Why needed here:** The system uses a rolling context summary ($C$) alongside the KG. You need to understand that the KG handles *facts* while the context summary handles *narrative flow*.
  - **Quick check question:** If the `CleanUp` function (Algorithm 1, Line 30) is disabled, what specific failure mode is likely to occur?

## Architecture Onboarding

- **Component map:** User Prompt -> ExtractKG -> KG Store -> Query -> LLM Generate -> UpdateKG -> CleanUp -> Next Scene
- **Critical path:**
  1. **Init:** User Prompt -> `ExtractKG` -> Initialize Graph
  2. **Loop (per scene):** `Query` Graph -> `Generate` Scene -> `Update` Graph -> `CleanUp`
  3. **Edit:** User modifies Graph -> `Regenerate` Scene OR `Generate` Next Scene
- **Design tradeoffs:**
  - Model Size: Chose Llama 3.1 8B over GPT-4 for transparency and cost, explicitly trading off "introspective capability" for observability
  - Literalism: The graph enforces consistency but creates "bland" literal descriptions (Page 14). This is a feature for action stories, but a bug for emotional ones
- **Failure signatures:**
  - Repetitive/Rigid Text: Occurs in Introspective stories when the graph forces explicit statements about internal states (Page 16)
  - Hallucination Lock-in: If `ExtractKG` hallucinates a fact from a previous scene, it is cemented into the graph and retrieved for all future scenes
  - Control Mismatch: User edits intended as "subtext" are rendered as "explicit dialogue" because the model interprets the graph change too literally
- **First 3 experiments:**
  1. **Schema Extension:** Modify the graph schema to include "HiddenState" nodes. Run the "Introspective" prompts again to see if ratings improve
  2. **Ablation (CleanUp):** Disable the `CleanUp` function to measure the degradation in coherence and token usage over 10+ scenes
  3. **Model Swap:** Replace Llama 8B with a larger model (e.g., Llama 70B or GPT-4) *without* the KG to verify if the improvements are truly from the graph or just better reasoning

## Open Questions the Paper Calls Out
None

## Limitations
- Effectiveness is modality-dependent, excelling with action-oriented narratives but underperforming with introspective ones due to rigid graph structures
- Small sample size (N=15) raises questions about statistical power, particularly for p=0.053 and p=0.083 results
- Reliance on accurate entity extraction creates failure cascade where hallucinations become permanently embedded and propagate through scenes

## Confidence
**High Confidence**: Core mechanism of using KGs to reduce hallucinations and improve coherence in action-oriented narratives is well-supported by quantitative results and qualitative feedback about user control.

**Medium Confidence**: User control claims are supported by participant feedback but could benefit from more granular analysis of specific graph-edit types and their effects.

**Low Confidence**: Statistical significance of some improvements (pace at p=0.053, structure at p=0.083) falls just above conventional threshold, suggesting need for replication with larger samples.

## Next Checks
1. **Schema Extension Test**: Modify the graph schema to include "HiddenState" or "InternalEmotion" nodes and rerun the introspective prompts to determine if ratings improve
2. **Ablation Study**: Disable the `CleanUp` function to measure degradation in coherence and token usage over 10+ scenes
3. **Model Capability Comparison**: Replace Llama 8B with Llama 70B or GPT-4 without KG guidance to verify whether observed improvements are truly from graph structure or simply better reasoning from larger model