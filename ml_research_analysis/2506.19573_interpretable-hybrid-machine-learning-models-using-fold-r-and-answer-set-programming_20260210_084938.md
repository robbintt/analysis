---
ver: rpa2
title: Interpretable Hybrid Machine Learning Models Using FOLD-R++ and Answer Set
  Programming
arxiv_id: '2506.19573'
source_url: https://arxiv.org/abs/2506.19573
tags:
- hybrid
- rules
- fold-r
- rule
- were
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study proposes a hybrid model combining interpretable ASP
  rules from the FOLD-R++ algorithm with black-box ML classifiers to improve both
  predictive performance and interpretability. The method uses ASP rules to correct
  uncertain ML predictions and provide human-readable explanations.
---

# Interpretable Hybrid Machine Learning Models Using FOLD-R++ and Answer Set Programming

## Quick Facts
- arXiv ID: 2506.19573
- Source URL: https://arxiv.org/abs/2506.19573
- Reference count: 2
- Key outcome: Hybrid ASP-ML model improved accuracy from 72.6% to 94.0% (p<10^-10) on Autism Screening dataset

## Executive Summary
This study presents a hybrid machine learning architecture that combines interpretable Answer Set Programming (ASP) rules from the FOLD-R++ algorithm with black-box classifiers to improve both predictive performance and interpretability. The method uses a confidence threshold to selectively override uncertain ML predictions with ASP rule-based predictions, providing human-readable explanations through proof trees. Experiments on five medical datasets demonstrate statistically significant accuracy and F1 score improvements, particularly when base ML models perform suboptimally. The approach preserves ML model integrity while adding transparency through symbolic reasoning.

## Method Summary
The hybrid model trains both traditional ML classifiers (Random Forest, SVM, KNN, MLP) and induces ASP rules using FOLD-R++ from the same training data. During inference, predictions from the ML model are used when confidence exceeds 0.6; otherwise, the ASP solver (Clingo) provides the prediction based on the induced rules. Numeric features are scaled by 10x for compatibility with Clingo. The system generates explanations using proof trees from the FOLD-R++ algorithm. Evaluation uses 80-20 stratified train-test splits with 10 repeated experiments and statistical significance testing via paired t-tests.

## Key Results
- SVM accuracy improved from 72.6% to 94.0% on Autism Screening dataset (p<10^-10)
- Hybrid model consistently outperformed individual ML models across all five medical datasets
- Statistically significant improvements in both accuracy and F1 scores
- Enhanced interpretability through human-readable ASP rules and proof tree explanations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The hybrid model improves accuracy primarily by correcting low-confidence predictions made by suboptimal black-box classifiers.
- **Mechanism:** A fixed confidence threshold (0.6) partitions the prediction space. When the ML model's prediction probability falls below this threshold, the system defers to the ASP solver (Clingo), which applies logical rules induced by FOLD-R++.
- **Core assumption:** The confidence score of the base ML model is inversely correlated with error probability, and the symbolic rules provide a better-than-random prior for these uncertain cases.
- **Evidence anchors:**
  - [abstract]: "...integrates ASP-derived rules... to selectively correct uncertain predictions..."
  - [section 4.4]: "If the confidence score of the ML model for a prediction was above 0.6, the ML prediction was used; otherwise, the prediction of the ASP rule was used."
  - [corpus]: Evidence is weak in direct corpus neighbors regarding this specific confidence-threshold switching mechanism, though "Neuro-symbolic Weak Supervision" discusses logic-constrained learning generally.
- **Break condition:** If the base ML model is well-calibrated and high-performing (e.g., Random Forest on Chronic Kidney Disease), the symbolic intervention may introduce noise or unnecessary complexity without accuracy gains.

### Mechanism 2
- **Claim:** FOLD-R++ generates human-readable rules by transforming decision-tree logic into non-monotonic Answer Set Programming (ASP) syntax.
- **Mechanism:** FOLD-R++ recursively partitions data to find literals that separate classes, converting these splits into rules with default conditions and explicit exceptions (e.g., `label(X) :- Conditions(X), not Exceptions(X)`).
- **Core assumption:** The decision boundaries learned via tree-based partitioning translate effectively into logical literals without losing critical nuance from the training data.
- **Evidence anchors:**
  - [section 3.2]: "It operates by recursively partitioning the data... [and] transforms the decision tree into an ASP."
  - [corpus]: "Comparative Analysis of FOLD-SE vs. FOLD-R++..." confirms the general efficacy of FOLD-R++ in binary classification contexts.
- **Break condition:** Performance degrades if the rule induction overfits the training split, resulting in complex rules with too many exceptions that fail to generalize to the test set (noted in Limitations).

### Mechanism 3
- **Claim:** Interpretability is achieved by decoupling the explanation from the ML model and deriving it solely from the symbolic proof tree.
- **Mechanism:** When a prediction is corrected or confirmed by the ASP component, the system generates an explanation based on which rule literals were satisfied or which exceptions failed.
- **Core assumption:** Domain experts prefer logical predicates (e.g., `chest_pain(4)`) over feature importance weights (e.g., SHAP values).
- **Evidence anchors:**
  - [section 5.2]: "When ML models make correct predictions with high confidence, the hybrid model confirms these predictions while adding transparent explanations."
  - [section 4.5]: "Explanations were generated... using proof trees from the FOLD-R++ algorithm."
  - [corpus]: "A Proof-of-Concept for Explainable Disease Diagnosis Using LLMs and ASP" supports the viability of ASP for explainable diagnosis.
- **Break condition:** If the ML model is correct with high confidence but the ASP rules disagree (or are absent), the system may produce a correct prediction but lack a corresponding symbolic explanation, creating a fidelity gap.

## Foundational Learning

- **Concept: Non-monotonic Reasoning (Defaults & Exceptions)**
  - **Why needed here:** The core logic format relies on "negation as failure" (e.g., `not ab2(X)`). You must understand how ASP handles incomplete information to debug why a rule failed to fire.
  - **Quick check question:** If a patient has `chest_pain(4)` but the rule for `absent` requires `not ab2(X)`, does the presence of chest_pain trigger the exception `ab2`?

- **Concept: Probability Calibration**
  - **Why needed here:** The hybrid switch depends on a 0.6 threshold. You need to know if your base classifier's `predict_proba` outputs true probabilities or just rankings.
  - **Quick check question:** Does an SVM with `probability=False` (default in many libraries) support the gating mechanism required for this architecture?

- **Concept: Inductive Logic Programming (ILP)**
  - **Why needed here:** FOLD-R++ is an ILP tool. Understanding the trade-off between rule coverage (support) and precision (confidence) helps explain why rules might overfit.
  - **Quick check question:** Will the induced rule change if a single outlier is removed from the training data?

## Architecture Onboarding

- **Component map:** Data Ingest -> Train ML & FOLD-R++ separately -> For test instance: Calculate ML Confidence -> (If < 0.6) -> Convert instance to ASP facts -> Invoke clingo -> Parse Answer Set -> Output Label + Explanation

- **Critical path:** Data -> Train ML & FOLD-R++ separately -> **For test instance**: Calculate ML Confidence -> (If < 0.6) -> Convert instance to ASP facts -> Invoke `clingo` -> Parse Answer Set -> Output Label + Explanation

- **Design tradeoffs:**
  - **Fixed vs. Dynamic Threshold:** The authors used a fixed 0.6 threshold to avoid overfitting, but this may be suboptimal for models with very high or very low baseline calibration.
  - **Scalability:** `clingo` introduces computational overhead. This architecture is better suited for smaller, high-stakes medical datasets than high-frequency streaming data.

- **Failure signatures:**
  - **Silent Overrides:** The hybrid model corrects an ML prediction, but the ASP rule is actually incorrect (false positive logic), degrading performance compared to the pure ML baseline.
  - **Explanation Fidelity Gap:** ML predicts "Present" with high confidence (accepted), but the ASP rules indicate "Absent" (rejected). The system outputs the correct label but has no valid proof tree to explain it.

- **First 3 experiments:**
  1. **Threshold Sensitivity Analysis:** Re-run the Autism Screening SVM experiment with thresholds [0.4, 0.5, 0.6, 0.7] to verify if 0.6 is locally optimal or arbitrary.
  2. **Rule Inspection:** On the Heart Disease dataset, extract the exact ASP rules for "Present" vs. "Absent" and verify if "Exceptions" (`ab1`, `ab2`...) align with known clinical contraindicators.
  3. **Base Model Swap:** Replace the `MLPClassifier` with a `GradientBoostingClassifier` to test if the hybrid approach still yields gains when the baseline is significantly stronger.

## Open Questions the Paper Calls Out
None

## Limitations
- Rule quality and confidence thresholds critically affect reliability, with potential for overfitting in rule induction
- Computational overhead from ASP solving limits scalability to larger datasets
- Explanation fidelity gap when ML predictions with high confidence are accepted without symbolic justification

## Confidence
- **High confidence**: Accuracy and F1 score improvements are statistically significant with p-values < 10^-10 on multiple datasets. The hybrid architecture is well-specified and reproducible.
- **Medium confidence**: The interpretability claims are valid for cases where ASP rules override ML predictions, but explanation fidelity is questionable when ML predictions with high confidence are accepted without symbolic justification.
- **Low confidence**: Generalizability beyond the five medical datasets tested remains unproven, particularly for domains with different data characteristics or higher dimensionality.

## Next Checks
1. **Threshold Sensitivity Analysis**: Re-run experiments with confidence thresholds [0.4, 0.5, 0.6, 0.7] to determine if 0.6 is locally optimal or arbitrarily chosen.
2. **Rule Quality Audit**: Extract and manually verify ASP rules for Heart Disease dataset to assess if exceptions align with clinical knowledge and capture meaningful patterns vs. noise.
3. **Base Model Robustness Test**: Replace MLPClassifier with GradientBoostingClassifier to test hybrid gains against stronger ML baselines.