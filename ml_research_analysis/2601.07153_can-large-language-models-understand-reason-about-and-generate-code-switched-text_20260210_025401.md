---
ver: rpa2
title: Can Large Language Models Understand, Reason About, and Generate Code-Switched
  Text?
arxiv_id: '2601.07153'
source_url: https://arxiv.org/abs/2601.07153
tags:
- language
- code-switched
- english
- text
- code-switching
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CODEMIXQA, a benchmark for evaluating large
  language models on code-switched text understanding, reasoning, and generation.
  The dataset includes 16 parallel language pairs in original scripts and transliterations,
  enabling evaluation across diverse code-switching patterns.
---

# Can Large Language Models Understand, Reason About, and Generate Code-Switched Text?

## Quick Facts
- arXiv ID: 2601.07153
- Source URL: https://arxiv.org/abs/2601.07153
- Reference count: 40
- This paper introduces CODEMIXQA, a benchmark for evaluating large language models on code-switched text understanding, reasoning, and generation.

## Executive Summary
This paper introduces CODEMIXQA, a benchmark for evaluating large language models on code-switched text understanding, reasoning, and generation. The dataset includes 16 parallel language pairs in original scripts and transliterations, enabling evaluation across diverse code-switching patterns. Results show an average 11% performance drop under code-switching conditions, with higher code-mixing density correlating with better task robustness. Models generate more natural outputs when preserving the non-English language as the matrix language, but English-dominant structures yield higher task performance. Reasoning traces remain English-centric even for non-English inputs, leading to misalignment errors.

## Method Summary
The study uses CODEMIXQA dataset (64k samples) derived from SimpleQA Verified, applying four perturbation strategies to generate code-switched variants: RANDOMSWITCHING (unconstrained word replacement), SELECTIVESWITCHING (natural code-switching), GRAMMARFORCING(SRC) (preserve source-language grammar), and GRAMMARFORCING(TGT) (preserve target-language grammar). Evaluation includes F1 comprehension scoring, LLM-as-judge reasoning analysis with 9-category error taxonomy, and human evaluation of naturalness and semantic accuracy. The code-mixing index (CMI) and switch-point fraction (SPF) metrics quantify mixing density and switch frequency.

## Key Results
- Code-switching causes an average 11% performance drop in comprehension tasks
- Higher code-mixing density correlates with better task robustness
- English-centric reasoning traces persist even for non-English inputs, creating misalignment errors
- GRAMMARFORCING(TGT) yields highest naturalness scores but lower comprehension performance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Code-switching perturbations degrade LLM comprehension by introducing misalignment between input encoding and reasoning processes.
- **Mechanism:** Mixed-language inputs increase token-level ambiguity during encoding, causing models to produce "unsupported claims, illogical leaps, and ambiguous facts" in reasoning traces. Higher code-mixing density (CMI/SPF) correlates with improved robustness, suggesting models benefit from consistent mixing patterns rather than sparse alternation.
- **Core assumption:** Models encode monolingual text more reliably than intra-sentential language alternation.
- **Evidence anchors:**
  - [abstract] "code-switching causes an average 11% performance drop"
  - [section 5.1] "misalignment errors increase when code-switched text is used compared to the original English input"
  - [corpus] "Lost in the Mix" (arXiv:2506.14012) reports similar degradation patterns

### Mechanism 2
- **Claim:** Reasoning traces remain English-centric because thinking-oriented model training data is predominantly English.
- **Mechanism:** Even when inputs are predominantly non-English, the internal reasoning representations activate English-dominant pathways. This creates a bottleneck where non-English semantic content must be "translated" to English reasoning frames, introducing alignment errors at the input-reasoning boundary.
- **Core assumption:** Chain-of-thought training correlates with language distribution in pre-training corpora.
- **Evidence anchors:**
  - [section 5.1] "reasoning traces are consistently in English, even when the inputs are predominantly in non-English languages"
  - [section 5.1] "models are highly English-centric, likely reflecting that their training data for thinking-oriented models is largely English"
  - [corpus] OLA paper (arXiv:2601.03589) addresses output language alignment challenges

### Mechanism 3
- **Claim:** Grammar-forcing with target-language (non-English) syntax improves human-rated naturalness but reduces comprehension task performance—revealing a naturalness-accuracy tradeoff.
- **Mechanism:** GRAMMARFORCING(TGT) preserves matrix-language structure (non-English), which native speakers rate as more natural. However, LLMs better comprehend inputs with English-dominant syntax (GRAMMARFORCING(SRC)) because English dominates their training distribution.
- **Core assumption:** Human naturalness judgments correlate with grammatical consistency in the matrix language.
- **Evidence anchors:**
  - [section 5.1] "outputs preserving the non-English language as the matrix language are rated as significantly more natural by native speakers"
  - [table 5] GRAMMARFORCING(TGT) achieves highest naturalness scores across most language pairs

## Foundational Learning

- **Concept: Matrix Language Frame (MLF) Theory**
  - **Why needed here:** The paper uses MLF and Equivalence Constraint theories to constrain grammar-forcing generation. Understanding that code-switching follows predictable patterns where one language provides syntactic structure is essential for interpreting why TGT forcing improves naturalness.
  - **Quick check question:** In a Hindi-English utterance, if Hindi word order (SOV) dominates, which language is the matrix language?

- **Concept: Code-Mixing Index (CMI) and Switch-Point Fraction (SPF)**
  - **Why needed here:** These metrics quantify mixing density and switch frequency. The paper correlates higher CMI/SPF with improved robustness, suggesting density effects matter for model comprehension.
  - **Quick check question:** If an utterance has 10 tokens with 3 language switches and 4 tokens in the non-dominant language, what is the SPF?

- **Concept: Transliteration vs. Script Variation**
  - **Why needed here:** Indian languages (Bengali, Hindi, Marathi, Urdu) commonly appear in romanized form in informal code-switching. The paper evaluates both forms, finding transliteration sometimes reduces reasoning errors.
  - **Quick check question:** Why might a model process romanized Hindi differently than Devanagari script for code-switched inputs?

## Architecture Onboarding

- **Component map:** SimpleQA Verified (source data) -> GPT-5.2 perturbation generation -> CODEMIXQA dataset (4 variants per sample) -> F1 comprehension evaluation -> LLM-as-judge reasoning analysis -> Human naturalness/accuracy ratings

- **Critical path:**
  1. Generate code-switched variants from English source using GPT-5.2 with prompting strategies
  2. Evaluate comprehension via F1 on perturbed vs. unperturbed questions
  3. Analyze reasoning traces with GPT-OSS 120B judge using 9-category error taxonomy
  4. Human evaluation: 5-point Likert for naturalness + semantic accuracy

- **Design tradeoffs:**
  - **SRC vs. TGT grammar forcing:** SRC optimizes for model comprehension; TGT optimizes for human naturalness. No single strategy dominates both.
  - **Script vs. transliteration:** Transliteration reduces reasoning errors for some languages but may reduce naturalness where scripts have cultural significance.
  - **Judge selection:** QWEN3-30B-A3B chosen over GPT-4.1 for cost (κ=0.95 agreement), but may introduce model-specific biases.

- **Failure signatures:**
  - English-centric reasoning traces on non-English inputs (architectural bias)
  - "Unsupported Claims" and "Illogical Leap" errors spike in code-switched conditions
  - Semantic accuracy preserved but naturalness drops when SRC grammar dominates

- **First 3 experiments:**
  1. **Baseline degradation measurement:** Run comprehension F1 on English → each perturbation strategy → calculate per-language drop. Expect ~11% average; identify outlier languages.
  2. **Reasoning trace audit:** Sample 50 code-switched inputs per language pair. Use judge to categorize errors. Confirm "Unsupported Claims" and "Illogical Leap" dominate.
  3. **Naturalness-accuracy correlation:** Plot human naturalness scores vs. F1 comprehension scores by perturbation strategy. Confirm negative correlation for SRC-forced outputs.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can LLMs be trained or prompted to produce reasoning traces in non-English languages when processing code-switched or non-English inputs? The authors note that "their reasoning traces are consistently in English, even when the inputs are predominantly in non-English languages" due to English-dominant training data for thinking-oriented models.

- **Open Question 2:** How can the tradeoff between naturalness and task performance in code-switching generation be reconciled? The paper observes that "outputs preserving the non-English language as the matrix language are rated as significantly more natural by native speakers, whereas English-dominant grammatical structures achieve higher downstream task performance but lower naturalness."

- **Open Question 3:** Why do transliterated code-switched inputs result in fewer reasoning misalignment errors compared to original-script inputs? The paper notes that "these errors are much less pronounced for transliterated text" but does not investigate underlying causes.

## Limitations
- Dependency on GPT-5.2 for perturbation generation creates access constraints and potential model-specific biases
- Unspecified exact parameters for "percentage" placeholders in generation prompts hinder reproducibility
- Single LLM-as-judge (QWEN3-30B-A3B) may introduce systematic biases despite high agreement with GPT-4.1

## Confidence
- **Performance degradation under code-switching:** High confidence - well-supported by systematic F1 measurements across multiple models and language pairs
- **English-centric reasoning traces:** Medium confidence - observation is consistent but mechanism requires additional validation
- **Naturalness-accuracy tradeoff:** Medium confidence - empirically observed but underlying assumptions warrant further investigation
- **CMI/SPF correlation with robustness:** Medium confidence - reported correlation but causal mechanism remains unclear

## Next Checks
1. **Cross-model reasoning analysis:** Repeat the reasoning trace error analysis using a multilingual reasoning model to determine if English-centricity is universal or model-specific.

2. **Controlled CMI/SPF experiments:** Systematically vary CMI and SPF values in a controlled manner for a single language pair to isolate the effect of mixing density from other confounding factors.

3. **Human vs. model alignment study:** Conduct a detailed comparison between human naturalness judgments and LLM-based naturalness scoring for GRAMMARFORCING variants to quantify the alignment between human perception and automated evaluation metrics.