---
ver: rpa2
title: Surrogate-based Optimization via Clustering for Box-Constrained Problems
arxiv_id: '2601.07442'
source_url: https://arxiv.org/abs/2601.07442
tags:
- optimization
- global
- algorithms
- points
- surrogate
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Surrogate-based optimization for black-box systems is challenging
  due to expensive function evaluations and lack of derivatives. SBOC (Surrogate-Based
  Optimization via Clustering) is proposed to address this by using a single global
  surrogate model and k-means clustering to identify under-explored regions.
---

# Surrogate-based Optimization via Clustering for Box-Constrained Problems

## Quick Facts
- **arXiv ID**: 2601.07442
- **Source URL**: https://arxiv.org/abs/2601.07442
- **Reference count**: 40
- **Primary result**: SBOC successfully identifies global minima for 63.5-65.4% of test functions with substantially lower computational effort than 15 other algorithms

## Executive Summary
Surrogate-based optimization (SBO) addresses the challenge of expensive black-box function evaluations by building global surrogate models to guide the search for optimal solutions. Traditional SBO approaches suffer from the "curse of dimensionality" when using multiple local surrogate models or fail to balance exploration and exploitation with single global models. SBOC (Surrogate-Based Optimization via Clustering) introduces a novel approach that uses k-means clustering to identify under-explored regions while maintaining a single global surrogate model. At each iteration, the algorithm strategically adds three new sample points: one via surrogate minimization for exploitation, one in a large inter-cluster space for exploration, and one near the current best point for local refinement. Tested against 16 algorithms on 52 diverse test functions (N=2-10 dimensions), SBOC achieved global optimum identification rates of 63.5-65.4% while requiring substantially less computational effort than competitors, particularly excelling on high-dimensional problems.

## Method Summary
SBOC combines a single global surrogate model with k-means clustering to balance exploration and exploitation in black-box optimization. The algorithm begins by sampling the search space using a Latin hypercube design, then iteratively builds a surrogate model (typically a radial basis function network) to approximate the objective function. K-means clustering partitions the sampled points into k clusters, and the algorithm identifies the cluster containing the current best point. At each iteration, SBOC adds three strategically chosen points: one that minimizes the surrogate model for exploitation, one positioned in a large inter-cluster space to promote exploration, and one near the current best point for local refinement. The process continues until a stopping criterion is met, typically based on maximum function evaluations or convergence of the surrogate model. This approach maintains computational efficiency by avoiding the curse of dimensionality associated with multiple local surrogate models while ensuring thorough exploration through clustering-based space partitioning.

## Key Results
- SBOC identified global minima for 63.5-65.4% of 52 test functions, outperforming many competitors
- The algorithm required substantially fewer function evaluations than alternative methods, demonstrating superior computational efficiency
- SBOC ranked among the top six algorithms for solution accuracy and showed particular effectiveness on high-dimensional problems (N=10)
- Comparative testing against 16 other optimization algorithms demonstrated robust performance across diverse test function landscapes

## Why This Works (Mechanism)
SBOC addresses the fundamental challenge in surrogate-based optimization: balancing exploration of unknown regions with exploitation of promising areas while managing computational expense. The mechanism works by leveraging clustering to identify under-explored regions in the search space, then strategically placing new sample points to maximize information gain. The k-means clustering partitions the existing sample points, revealing gaps in the search space coverage. By adding points both at the surrogate minimum and in large inter-cluster spaces, SBOC simultaneously refines promising regions and explores uncharted territory. The neighborhood sampling around the current best point ensures local refinement without getting trapped in local optima. This three-pronged sampling strategy, combined with a single global surrogate model, avoids the computational burden of maintaining multiple local models while preventing premature convergence to suboptimal solutions.

## Foundational Learning
- **Surrogate modeling**: Creating computationally inexpensive approximations of expensive black-box functions to enable efficient optimization
  - Why needed: Direct function evaluations are too costly to allow exhaustive search
  - Quick check: RBF networks can approximate complex nonlinear relationships with relatively few sample points
- **K-means clustering**: Unsupervised partitioning of data points into k clusters based on distance metrics
  - Why needed: Identifies regions of the search space that lack sample coverage
  - Quick check: Clusters should reflect the underlying structure of the objective function landscape
- **Exploration vs. exploitation tradeoff**: The fundamental dilemma in optimization between searching new areas versus refining known good solutions
  - Why needed: Pure exploration wastes resources on unpromising regions; pure exploitation risks missing global optima
  - Quick check: The algorithm must maintain diversity in sample locations while progressively improving the best solution
- **Latin hypercube sampling**: Space-filling experimental design that ensures representative coverage of the search space
  - Why needed: Provides initial diverse sample points to build an accurate initial surrogate model
  - Quick check: Initial samples should span the entire feasible region without clustering
- **Radial basis function networks**: A type of artificial neural network particularly suited for function approximation
  - Why needed: Provides smooth, differentiable surrogate models that can be efficiently minimized
  - Quick check: The surrogate should capture major features of the true objective function with limited data

## Architecture Onboarding

Component Map:
Initial LHS samples -> Surrogate Model (RBF) -> K-means Clustering -> Point Selection (3 types) -> New Sample Points -> Updated Model

Critical Path:
The critical path flows from initial Latin hypercube sampling through surrogate model construction, clustering analysis, strategic point selection, and iterative model refinement until convergence. Each iteration depends on the previous model's accuracy and the clustering quality, making surrogate fidelity and appropriate cluster count critical success factors.

Design Tradeoffs:
- Single global surrogate vs. multiple local models: SBOC chooses global model for computational efficiency, accepting potential loss of local accuracy
- Fixed three-point addition per iteration vs. adaptive sampling: The three-point strategy provides predictable computational cost but may miss opportunities for more aggressive or conservative sampling
- K-means clustering sensitivity vs. simplicity: Simple to implement but can be affected by initialization and cluster count selection

Failure Signatures:
- Poor surrogate accuracy due to insufficient initial sampling or highly multimodal landscapes
- Clustering that creates artificial boundaries, leading to redundant sampling in already-explored regions
- Premature convergence when exploration points consistently land in already-sampled regions
- Computational inefficiency if the RBF network requires excessive training time for large sample sets

First Experiments:
1. Test on simple 2D benchmark functions (Sphere, Rosenbrock) to verify basic functionality and convergence behavior
2. Evaluate sensitivity to initial Latin hypercube sample size on a representative test function
3. Compare performance with different numbers of clusters (k) on a multi-modal test function to assess clustering impact

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can SBOC be extended to efficiently handle large-scale constrained optimization problems with both continuous and discrete variables?
- Basis in paper: The conclusion states: "A natural extension of this work is to modify SBOC to tackle large-scale, complex constrained problems with continuous and discrete variables."
- Why unresolved: SBOC currently only addresses box-constrained problems with continuous variables; constrained and mixed-integer formulations require new mechanisms for constraint handling and discrete variable sampling
- What evidence would resolve it: Implementation and benchmarking of a modified SBOC algorithm on constrained and mixed-integer test problems, with comparison to existing constrained/mixed-integer SBO algorithms

### Open Question 2
- Question: How does SBOC perform on noisy objective functions or stochastic black-box systems?
- Basis in paper: The paper tests only deterministic analytical functions; real-world industrial simulators often exhibit numerical noise or stochasticity
- Why unresolved: The current exploitation strategy (Eq. 6) weights points by objective values without accounting for uncertainty, and no replicate evaluations are performed
- What evidence would resolve it: Comparative experiments on noisy benchmark functions showing whether SBOC maintains its performance advantage, or requires modifications such as uncertainty-weighted sampling or replicate evaluations

### Open Question 3
- Question: How sensitive is SBOC's performance to the arbitrary parameter choices (three points per iteration, the 0.2 factor for neighborhood size, the 10% elbow threshold)?
- Basis in paper: The algorithm uses fixed heuristics (adding 3 points per iteration, ceil[0.2Ki] neighbors, 10% threshold in Eq. 4) without systematic justification or sensitivity analysis
- Why unresolved: No ablation study explores whether alternative values would improve or degrade performance
- What evidence would resolve it: Systematic parameter sensitivity analysis across test functions to identify optimal ranges or adaptive strategies for these parameters

## Limitations
- Success rates (63.5-65.4% global optimum identification) lack statistical significance testing across the 16 algorithms
- Claims of "substantially lower computational effort" require verification of statistical significance rather than anecdotal comparison
- Effectiveness on "high-dimensional problems" only tested up to N=10 dimensions, with unclear performance degradation beyond this range
- Clustering approach sensitivity to parameter choices (k-means initialization, cluster count) is not discussed, potentially affecting reproducibility

## Confidence

**High**: Algorithm framework and methodology description
**Medium**: Comparative performance claims without statistical validation
**Medium**: Effectiveness on high-dimensional problems (limited dimensional range tested)

## Next Checks

1. Conduct statistical significance tests (e.g., Wilcoxon signed-rank) comparing SBOC to top competitors across all test functions
2. Test algorithm scalability on problems with dimensions N>10 to verify high-dimensional effectiveness claims
3. Perform sensitivity analysis on clustering parameters (k value, initialization methods) to assess robustness to parameter choices