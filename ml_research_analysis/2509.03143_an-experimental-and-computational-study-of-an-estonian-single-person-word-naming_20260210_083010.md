---
ver: rpa2
title: An experimental and computational study of an Estonian single-person word naming
arxiv_id: '2509.03143'
source_url: https://arxiv.org/abs/2509.03143
tags:
- word
- words
- naming
- estonian
- lexical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The study examines lexical processing in Estonian using a single-participant
  mega-experiment combining word naming with eye-tracking. Five response variables
  were measured: first fixation duration, total fixation duration, number of fixations,
  naming latency, and spoken word duration.'
---

# An experimental and computational study of an Estonian single-person word naming

## Quick Facts
- **arXiv ID:** 2509.03143
- **Source URL:** https://arxiv.org/abs/2509.03143
- **Reference count:** 8
- **Primary result:** Discriminative Lexicon Model (DLM) measures, particularly target correlation and contextual independence, were powerful predictors of lexical processing measures in Estonian word naming, outperforming or matching classical predictors for most response variables except first fixation duration and number of fixations.

## Executive Summary
This study combines a single-participant mega-experiment with computational modeling to examine lexical processing in Estonian. Eye-tracking and naming data were collected for Estonian nouns, and five response variables were analyzed: first fixation duration, total fixation duration, number of fixations, naming latency, and spoken word duration. The research compares classical predictors (word frequency, neighborhood density, paradigm size) with DLM-based measures (target correlation and contextual independence) derived from form-to-meaning mappings. The findings demonstrate that DLM measures are particularly effective for predicting temporal measures, suggesting semantic involvement in the naming task, while also showing less predictor collinearity than classical models.

## Method Summary
The study employed generalized additive mixed models (GAMs) to analyze behavioral data from a single-participant word naming experiment. Two computational models were implemented to derive predictors: FIL (Frequency-Informed Linear) using the JudiLing Julia package for linear regression, and FIDDL (Frequency-Informed Deep Discriminative Learning) with a single hidden layer of 1000 units trained via Adam optimizer. Both models map orthographic form (letter trigrams) to semantic meaning (fastText embeddings) to predict behavioral response variables. The primary computational metric was "target correlation" (Pearson correlation between predicted and gold standard semantic vectors), which was then used as a predictor in GAMs alongside measures of contextual independence.

## Key Results
- DLM-based measures were powerful predictors for all response variables except first fixation duration and number of fixations
- For total fixation duration, FIL and classical predictors performed equally well
- For naming latency and spoken word duration, classical predictors provided better fits than DLM measures
- DLM measures showed less predictor collinearity compared to classical models
- Target correlation and contextual independence interact in predicting naming latency and spoken word duration, capturing distinct aspects of lexical processing

## Why This Works (Mechanism)
The study demonstrates that form-to-meaning mappings computed via discriminative learning models can capture aspects of lexical processing that are not fully accounted for by traditional frequency-based measures. The predictive power of these mappings for temporal measures (naming latency and spoken word duration) suggests that the mapping process itself involves semantic processing, rather than being purely form-based. The interaction between target correlation and contextual independence indicates that these measures capture different dimensions of lexical processing: target correlation reflects the accuracy of form-to-meaning mapping, while contextual independence captures the uniqueness of the mapping relative to other words.

## Foundational Learning
- **Discriminative Lexicon Models:** Computational models that learn mappings from orthographic form to semantic meaning, needed to derive predictors that capture form-to-meaning mapping quality; quick check: verify the model learns to map unseen words to appropriate semantic vectors.
- **Target Correlation:** Pearson correlation between predicted and gold standard semantic vectors, measuring the quality of form-to-meaning mapping; quick check: calculate correlation values and verify they range from -1 to 1.
- **Contextual Independence:** Measure of how uniquely a word's form maps to its meaning relative to other words, capturing distinctiveness of lexical representations; quick check: verify that high-frequency words have higher contextual independence values.
- **Generalized Additive Mixed Models:** Statistical models that can handle non-linear relationships and random effects, needed to analyze the behavioral data while accounting for individual differences; quick check: ensure model residuals are normally distributed.
- **Letter Trigram Features:** Binary vectors indicating presence of letter trigrams as orthographic form representation, providing a sparse but comprehensive encoding of word structure; quick check: verify the feature matrix is sparse with most values being zero.

## Architecture Onboarding
**Component Map:** Estonian Lexicon (19,314 words) -> C matrix (trigram features) -> S matrix (fastText embeddings) -> FIL/FIDDL models -> Target Correlation & Contextual Independence -> GAMs -> Behavioral Predictions

**Critical Path:** Orthographic form representation (C) -> Semantic mapping (FIL/FIDDL) -> Behavioral prediction (GAMs)

**Design Tradeoffs:** The choice between linear (FIL) and deep (FIDDL) models represents a bias-variance tradeoff, where the linear model may underfit complex patterns while the deep model risks overfitting on the relatively small lexicon.

**Failure Signatures:** 
- FIL model instability due to matrix inversion problems in highly collinear trigram features
- FIDDL overfitting indicated by high training accuracy but poor generalization to behavioral data
- GAMs failing to converge due to multicollinearity between classical and DLM predictors

**First Experiments:**
1. Train FIL model on a subset of the lexicon and verify target correlation values match expected ranges
2. Implement FIDDL with reduced hidden layer size (100 units) to test for overfitting before scaling up
3. Calculate contextual independence for high and low frequency words to verify the expected pattern

## Open Questions the Paper Calls Out
None

## Limitations
- The exact word list used for training is not provided, preventing exact replication of the computational models
- FIDDL architecture details, particularly the activation function, are not specified
- The random seed for token shuffling in FIDDL training is not reported, introducing potential variability
- The claim of "semantic involvement" in temporal measures is inferred from predictive power rather than directly tested through experimental manipulation

## Confidence
- **High Confidence:** The implementation details of FIL and FIDDL models are sufficiently specified for replication, assuming the missing word list can be approximated
- **Medium Confidence:** The downstream analysis using GAMs is described, but exact model specifications and validation procedures are not fully detailed
- **Low Confidence:** The claim of "semantic involvement" in temporal measures is inferred from predictive power and requires further validation to establish causal link

## Next Checks
1. Reconstruct the 19,314-word dataset using the Estonian National Corpus 2023 and fastText vectors, then compare resulting form and semantic matrices to those described in the paper
2. Train both FIL and FIDDL models using the reconstructed dataset, calculate target correlations and contextual independence measures, and compare these values to those reported in the paper
3. Use the calculated DLM measures as predictors in GAMs to model behavioral response variables (total fixation duration, naming latency, spoken word duration) and compare goodness of fit (AIC) to classical predictors to verify reported performance differences