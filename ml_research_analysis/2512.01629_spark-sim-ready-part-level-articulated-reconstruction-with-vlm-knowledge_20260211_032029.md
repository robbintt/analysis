---
ver: rpa2
title: 'SPARK: Sim-ready Part-level Articulated Reconstruction with VLM Knowledge'
arxiv_id: '2512.01629'
source_url: https://arxiv.org/abs/2512.01629
tags:
- part
- joint
- articulated
- urdf
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SPARK is a framework that reconstructs simulation-ready articulated
  3D objects from a single image by combining vision-language model (VLM) priors with
  a diffusion transformer. It generates per-part reference images and coarse URDF
  parameters from the input, then uses hierarchical attention mechanisms to synthesize
  consistent part-level geometry.
---

# SPARK: Sim-ready Part-level Articulated Reconstruction with VLM Knowledge

## Quick Facts
- arXiv ID: 2512.01629
- Source URL: https://arxiv.org/abs/2512.01629
- Reference count: 40
- Key outcome: F-score 0.4214@0.1 and 0.8934@0.5 for articulated 3D reconstruction from single image, outperforming baselines

## Executive Summary
SPARK is a framework for reconstructing simulation-ready articulated 3D objects from a single RGB image. It combines Vision-Language Model (VLM) reasoning with a Diffusion Transformer (DiT) to generate per-part 3D geometry and complete URDF parameters. The system first uses VLMs to extract structural information and generate part-level reference images, then synthesizes consistent part-level geometry through hierarchical attention mechanisms. A differentiable optimization module refines joint parameters using VLM-generated open-state supervision, producing physically plausible and simulation-ready articulated assets.

## Method Summary
SPARK processes a single RGB image through a VLM-guided pipeline to reconstruct articulated 3D objects. The VLM (GPT-4o) extracts coarse URDF parameters (part hierarchy, joint types, axes, origins) and generates per-part reference images and an open-state image. A DiT with hierarchical attention mechanisms synthesizes consistent part-level geometry conditioned on these VLM priors. A differentiable optimizer then refines continuous joint parameters by minimizing the discrepancy between a rendered open state and the VLM-generated supervision image. The system outputs textured part meshes and a complete URDF file, evaluated on PartNet-Mobility with F-scores of 0.4214@0.1 and 0.8934@0.5.

## Key Results
- Achieves F-score 0.4214@0.1 and 0.8934@0.5 for shape reconstruction on PartNet-Mobility
- Outperforms baseline methods in both geometric accuracy and articulation fidelity
- Demonstrates strong URDF parameter estimation suitable for downstream robotic manipulation

## Why This Works (Mechanism)

### Mechanism 1
Combining VLM-generated structural priors with a diffusion transformer improves part-level articulated object reconstruction from a single image. A VLM first performs high-level reasoning on the input image to infer the object's kinematic structure, outputting a coarse URDF template and synthesizing per-part reference images. This semantic and structural guidance is fed into a Diffusion Transformer (DiT) that uses hierarchical attention mechanisms to generate consistent 3D geometry for each part. The core assumption is that the VLM can reliably infer correct kinematic structure and the DiT can synthesize coherent 3D parts based on this guidance. Evidence includes the abstract's description of integrating VLM priors into a generative DiT and section 3.2's explanation of hierarchical attention over parent-child pairs. The mechanism fails if the VLM produces an incorrect kinematic structure.

### Mechanism 2
A differentiable optimization module refines continuous joint parameters by comparing a rendered prediction against a VLM-synthesized supervision signal. After initial geometry generation and coarse URDF provision, the refinement step optimizes joint parameters using differentiable forward kinematics to simulate an "open" state and differentiable rendering to produce its silhouette. This silhouette is compared to a VLM-generated image of the object in its predicted open state, minimizing pixel-level discrepancy to fine-tune joint origins and motion limits. The core assumption is that the VLM can generate a geometrically plausible open-state image serving as valid ground truth. Evidence includes the abstract's mention of optimizing under VLM-generated open-state supervision and section 3.3's description of the optimization process. The mechanism fails if the VLM-generated open-state image is geometrically impossible.

### Mechanism 3
Hierarchical attention over a VLM-inferred kinematic graph enforces structural consistency across generated parts, overcoming limitations of purely appearance-driven segmentation. The DiT's generation process uses a specialized attention mechanism structured by the inferred kinematic graph, employing child-to-parent and parent-to-child attention layers. This allows tokens from related parts to exchange information, enforcing geometric constraints defined by the articulation hierarchy. The core assumption is that the VLM-inferred parent-child relationships are correct and the attention mechanism is sufficient to enforce necessary geometric consistency. Evidence includes the abstract's mention of hierarchical attention mechanisms and section 3.2's description of bidirectional information exchange between parent-child pairs. The mechanism fails if the VLM produces an incorrect kinematic graph.

## Foundational Learning

- **Concept: Unified Robot Description Format (URDF)**
  - Why needed: URDF is the target output and core data structure describing a robot or articulated object as a kinematic tree of links connected by joints
  - Quick check: What are the two primary elements in a URDF file that describe an articulated object's structure, and what does each define?

- **Concept: Diffusion Transformers (DiT)**
  - Why needed: SPARK uses a DiT as its generative backbone, applying transformer attention mechanisms to latent tokens during denoising
  - Quick check: What is the primary architectural difference between a standard U-Net diffusion model and a Diffusion Transformer (DiT) in terms of how they process spatial or latent information?

- **Concept: Differentiable Forward Kinematics and Rendering**
  - Why needed: These are core mathematical tools for the joint optimization module, allowing gradient-based optimization of URDF parameters using 2D supervision
  - Quick check: Why is "differentiability" a crucial property for the forward kinematics function and the renderer used in the optimization loop?

## Architecture Onboarding

- **Component map:** Input image -> VLM-Guided Parser -> DiT with hierarchical attention -> Texture Generator -> Differentiable Optimizer -> Final URDF and meshes

- **Critical path:** The VLM-Guided Parser is most critical; failure here (wrong kinematic graph) corrupts all downstream components. The DiT's hierarchical attention is the next critical element for ensuring geometric consistency.

- **Design tradeoffs:**
  - Generative vs. Retrieval: SPARK generates geometry from scratch (flexible but can introduce artifacts) vs. retrieval-based methods (more constrained but potentially cleaner)
  - Single-Image Constraint: Heavy reliance on VLM priors due to limited information about occluded regions and articulation
  - Differentiable Optimization: Adds computational cost but yields more accurate kinematic parameters compared to purely feed-forward prediction

- **Failure signatures:**
  - VLM Failure: Incorrect part counts, implausible joint types, or incoherent part reference images leading to structurally invalid objects
  - DiT Hallucination: Low-quality parts, disconnections, or interpenetration if attention mechanisms fail
  - Optimizer Divergence: Failure to converge or produce unrealistic joint limits if initial geometry is poor or supervision is inconsistent

- **First 3 experiments:**
  1. Ablation on VLM Guidance: Remove part-level images or structural graph from DiT input and compare F-score
  2. Ablation on Attention Mechanisms: Disable hierarchical attention layers and evaluate impact on part consistency and geometric fidelity
  3. Ablation on Joint Optimization: Run pipeline without differentiable optimization and measure URDF parameter error

## Open Questions the Paper Calls Out

- Can the framework be extended to handle complex kinematic structures such as multi-DOF joints, compound mechanisms, and closed-chain linkages?
- How robust is the reconstruction pipeline to errors or hallucinations in the initial VLM-generated URDF parameters?
- Does relying on VLM-generated "open-state" images for supervision introduce optimization biases or physical implausibilities?

## Limitations

- Heavy reliance on VLM priors for correct kinematic structure and coherent part images
- Synthetic VLM-generated open-state supervision may introduce geometric inconsistencies or impossible poses
- Uncertainty about how robust hierarchical attention is to errors in VLM-inferred kinematic graphs

## Confidence

- High confidence: Reported F-score metrics (0.4214@0.1 and 0.8934@0.5) are directly measurable from generated meshes and ground truth
- Medium confidence: URDF parameter improvements reported but exact VLM prompts for supervision not provided
- Medium confidence: Claim that hierarchical attention is key innovation supported by ablation results but specific geometric constraints not fully detailed

## Next Checks

1. VLM Ablation for Structural Integrity: Remove VLM-generated structural graph from DiT conditioning and compare F-scores and generated assemblies for missing parts or incorrect joint configurations

2. Attention Mechanism Stress Test: Remove hierarchical attention layers from DiT and evaluate impact on geometric consistency by measuring part interpenetration and spatial misalignment

3. Optimization Supervision Source Analysis: Replace VLM-generated open-state image with ground-truth open-state rendering and compare resulting URDF parameters to determine contribution of VLM supervision quality versus optimization process