---
ver: rpa2
title: Insider Threat Detection Using GCN and Bi-LSTM with Explicit and Implicit Graph
  Representations
arxiv_id: '2512.18483'
source_url: https://arxiv.org/abs/2512.18483
tags:
- graph
- detection
- insider
- activity
- explicit
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper tackles insider threat detection in cybersecurity, where
  trusted users perform subtle malicious activities. The core idea is to combine explicit
  and implicit graph representations with temporal modeling to capture complex user
  behavior patterns.
---

# Insider Threat Detection Using GCN and Bi-LSTM with Explicit and Implicit Graph Representations

## Quick Facts
- **arXiv ID**: 2512.18483
- **Source URL**: https://arxiv.org/abs/2512.18483
- **Reference count**: 40
- **Primary result**: State-of-the-art insider threat detection using combined explicit/implicit graph representations and temporal modeling on CERT r5.2 and r6.2 datasets

## Executive Summary
This paper addresses insider threat detection in cybersecurity, where trusted users perform subtle malicious activities. The authors propose a novel approach that combines explicit and implicit graph representations with temporal modeling to capture complex user behavior patterns. The method uses Graph Convolutional Networks (GCN) to process both explicit organizational rules-based graphs and implicitly learned feature similarity graphs, then feeds these representations into a Bi-LSTM to capture temporal dependencies. The model achieves state-of-the-art performance on CERT datasets with AUC of 98.62 and 88.48, detection rates of 100% and 80.15%, and false positive rates of 0.05 and 0.15 respectively.

## Method Summary
The proposed method constructs explicit graphs based on predefined organizational rules (such as reporting relationships and team structures) while simultaneously learning implicit graphs from feature similarities using the Gumbel-Softmax trick. Both graph types are processed through GCN layers to extract spatial features, which are then refined using attention mechanisms to capture the most relevant relationships. The resulting representations are fed into a Bi-LSTM to model temporal dependencies in user behavior. Activities are flagged as anomalous based on probability scores generated by the model. This hybrid approach leverages both domain knowledge (explicit graphs) and data-driven learning (implicit graphs) to achieve robust insider threat detection.

## Key Results
- On CERT r5.2 dataset: AUC of 98.62, detection rate of 100%, and false positive rate of 0.05
- On CERT r6.2 dataset: AUC of 88.48, detection rate of 80.15%, and false positive rate of 0.15
- Achieves state-of-the-art performance compared to existing methods in the literature

## Why This Works (Mechanism)
The model works by integrating two complementary graph representations: explicit graphs capture organizational structure and predefined relationships, while implicit graphs learn complex feature interactions from data. GCNs effectively extract spatial features from both graph types, preserving relational information that traditional feature-based methods miss. The attention mechanism helps focus on the most relevant relationships, while the Bi-LSTM captures temporal patterns in user behavior. This combination allows the model to detect subtle anomalies that evolve over time and involve complex interactions between users and organizational resources.

## Foundational Learning

**Graph Convolutional Networks (GCN)**: Neural networks designed to operate on graph-structured data by aggregating information from neighboring nodes. *Why needed*: Traditional CNNs cannot handle non-Euclidean graph structures. *Quick check*: Verify that node features are properly normalized before GCN application.

**Gumbel-Softmax trick**: A continuous relaxation technique that enables differentiable sampling from discrete distributions. *Why needed*: Allows backpropagation through graph construction when learning implicit relationships. *Quick check*: Monitor temperature parameter during training to ensure proper convergence.

**Attention mechanisms**: Techniques that weight the importance of different elements in the input when producing output. *Why needed*: Helps focus on the most relevant relationships in the graph representations. *Quick check*: Verify attention weights sum to 1 across features.

**Bi-LSTM**: Bidirectional Long Short-Term Memory networks that process sequences in both forward and backward directions. *Why needed*: Captures temporal dependencies that may exist in both past and future contexts. *Quick check*: Ensure sequence padding is consistent across batches.

## Architecture Onboarding

**Component map**: Raw features -> Explicit graph construction -> Implicit graph learning (Gumbel-Softmax) -> GCN layers -> Attention mechanism -> Bi-LSTM -> Anomaly score

**Critical path**: Feature extraction → Graph construction (explicit + implicit) → GCN feature extraction → Attention refinement → Bi-LSTM temporal modeling → Classification

**Design tradeoffs**: The paper trades computational complexity for improved detection accuracy by combining multiple sophisticated components (GCN + attention + Bi-LSTM). While this achieves state-of-the-art results, it may not scale well to very large organizations with millions of daily activities.

**Failure signatures**: The model may struggle with sparse graph data where user interactions are limited, potentially leading to poor implicit graph learning. Additionally, if organizational rules change frequently, the explicit graph component may become outdated, requiring regular updates.

**Three first experiments**:
1. Validate that both explicit and implicit graph representations contribute positively to detection performance through ablation studies
2. Test model sensitivity to different attention mechanisms (e.g., self-attention vs. graph attention)
3. Evaluate performance degradation when varying the temporal window size for Bi-LSTM input

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but several areas remain unaddressed in the discussion section regarding model generalizability, computational efficiency, and real-world applicability.

## Limitations

- Limited generalizability across different organizational contexts and dataset sizes, as experiments are confined to CERT datasets
- Does not address performance with sparse or incomplete graph data, which is common in practical scenarios
- Computational complexity of combining GCN with Bi-LSTM and attention mechanisms is not discussed, raising concerns about scalability

## Confidence

**High confidence**: The claimed performance metrics on CERT datasets are well-supported by detailed experimental setup and comparison with state-of-the-art methods.

**Medium confidence**: The novelty of combining explicit and implicit graph representations, as the paper lacks thorough discussion of how this differs from existing hybrid methods in literature.

**Low confidence**: The model's real-world applicability given the reliance on standardized CERT datasets that may not reflect diverse organizational structures.

## Next Checks

1. Test the model on a diverse set of real-world datasets from different organizational domains to assess generalizability
2. Conduct ablation studies to isolate the contribution of explicit vs. implicit graph representations to overall performance
3. Evaluate the model's robustness to incomplete or noisy graph data by introducing synthetic perturbations to the CERT datasets