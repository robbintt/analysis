---
ver: rpa2
title: Heterogeneous Multisource Transfer Learning via Model Averaging for Positive-Unlabeled
  Data
arxiv_id: '2511.10919'
source_url: https://arxiv.org/abs/2511.10919
tags:
- data
- learning
- target
- condition
- domain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study proposes a transfer learning framework for Positive-Unlabeled
  (PU) data that integrates heterogeneous data sources without direct data sharing.
  The method employs model averaging to combine logistic regression models from fully
  labeled, semi-supervised, and PU data sources, with optimal weights determined via
  cross-validation minimizing Kullback-Leibler divergence.
---

# Heterogeneous Multisource Transfer Learning via Model Averaging for Positive-Unlabeled Data

## Quick Facts
- arXiv ID: 2511.10919
- Source URL: https://arxiv.org/abs/2511.10919
- Reference count: 13
- One-line primary result: Model averaging framework integrates heterogeneous data sources for PU learning without raw data sharing, achieving superior performance under limited labeled data

## Executive Summary
This paper introduces a transfer learning framework for Positive-Unlabeled (PU) data that integrates heterogeneous data sources without direct data sharing. The method employs model averaging to combine logistic regression models from fully labeled, semi-supervised, and PU data sources, with optimal weights determined via cross-validation minimizing Kullback-Leibler divergence. Theoretical guarantees are established for weight optimality under both misspecified and correctly specified target models, with extensions to high-dimensional settings using ℓ1 penalties. Comprehensive simulations and real-world credit risk data demonstrate superior predictive accuracy and robustness compared to existing methods, particularly under limited labeled data and heterogeneous environments.

## Method Summary
The framework addresses transfer learning when the target domain contains only positive-labeled and unlabeled data. For each source domain, domain-specific logistic regression models are fitted: standard likelihood for fully labeled data, PU-corrected likelihood for PU data, and semi-supervised likelihood for partially labeled data. These models are combined via weighted parameter averaging, where weights are optimized through K-fold cross-validation on the target domain to minimize the expected KL divergence. The approach achieves privacy preservation by transferring only model parameters rather than raw data, and extends to high-dimensional settings through ℓ1 regularization.

## Key Results
- The KL-divergence optimized model averaging outperforms single-source and naively merged models across diverse simulation scenarios
- The method demonstrates robustness to uninformative source domains, with asymptotic weight convergence to zero for misspecified sources
- Real-world credit risk data experiments show superior performance compared to existing transfer learning methods under privacy constraints
- The framework maintains effectiveness when labeled data is scarce in the target domain, validating its practical utility

## Why This Works (Mechanism)

### Mechanism 1: Non-Canonical PU Likelihood Correction
Standard logistic regression fails in PU settings because treating unlabeled data as negative causes systematic bias. The framework corrects this by modifying the likelihood to account for the SCAR labeling mechanism, where the probability of observing a positive label depends on the ratio of labeled positives to expected positives in the unlabeled pool. This separates the labeling mechanism from the classification boundary.

### Mechanism 2: KL-Divergence Optimized Model Averaging
Rather than pooling data or using simple voting, the framework computes a transfer estimator as a weighted combination of source model parameters. Weights are optimized via K-fold cross-validation to minimize the expected out-of-sample KL divergence between the averaged model and the true target distribution. This allows automatic down-weighting of distant or misspecified source domains.

### Mechanism 3: Privacy-Preserving Parameter Transfer
The architecture enables knowledge transfer under privacy constraints by communicating only parameter vectors rather than raw gradients or data. Each source computes its MLE locally, transmits only the coefficient vector, and the target domain performs cross-validation for weights using local data. This decouples source training from aggregation.

## Foundational Learning

### Concept: Positive-Unlabeled (PU) Learning
- **Why needed here:** Target domain lacks negative labels, making standard binary classification impossible without biasing toward the unlabeled class
- **Quick check question:** Why does treating unlabeled data as "negative" cause the decision boundary to shift away from the true boundary in a PU setting?

### Concept: Kullback-Leibler (KL) Divergence
- **Why needed here:** Used as the loss function to optimize transfer weights, measuring difference between probability distributions rather than point estimates
- **Quick check question:** Why is KL divergence preferred over Mean Squared Error when optimizing probabilistic classifiers for likelihood-based models?

### Concept: Model Averaging / Ensembling
- **Why needed here:** Core strategy for integrating heterogeneous sources; understanding parameter averaging vs prediction averaging is critical
- **Quick check question:** How does averaging parameters (β_avg = Σw_i·β_i) differ from averaging predictions, and what constraint does this place on model architectures?

## Architecture Onboarding

### Component map:
Source Encoders (Local) -> Weight Optimizer (Target) -> Aggregator

### Critical path:
The calculation of class priors (π^(m)_1) for each domain and subsequent computation of b^(m) (labeling ratio) in the likelihood. Misestimation of these priors invalidates the likelihood correction and propagates error to the weighted average.

### Design tradeoffs:
- Theory vs. Computation: Proven optimality vs. computational intensity of non-convex penalized MLE in high dimensions
- Generality vs. Specificity: Hand-crafted likelihoods for three specific data types; new data types require new derivations

### Failure signatures:
- Weight Collapse: Cross-validation returns w_0 = 1.0 despite good sources, indicating parameter scaling mismatch
- Negative Transfer: High weights assigned to contradictory source signals (method claims robustness but extreme outliers could break this)

### First 3 experiments:
1. Ablation on Likelihoods: Compare "Standard Logistic" vs "PU-Corrected Likelihood" on synthetic PU data to validate bias correction
2. Weight Profiling: Run simulation (Case 2) and plot weights for informative vs uninformative sources to verify convergence to 0 for bad sources
3. Sensitivity Analysis: Perturb class prior π_1 in target domain to measure sensitivity, testing theoretical assumption of correct priors

## Open Questions the Paper Calls Out
None

## Limitations
- Relies on SCAR condition for PU data labeling, which may not hold in active or targeted labeling scenarios
- Assumes aligned feature spaces across all domains without explicit domain adaptation mechanisms
- Class prior estimation methods are not specified, creating uncertainty in practical implementation

## Confidence

**High Confidence:**
- Mathematical formulation of KL-divergence optimized model averaging is sound
- Privacy-preserving parameter-only transfer is technically correct
- High-dimensional extension with ℓ1 regularization follows standard principles

**Medium Confidence:**
- Asymptotic optimality of weights relies on strong assumptions about parameter space geometry
- Empirical superiority demonstrated through simulations but may not generalize to all distributions
- Robustness to uninformative sources is theoretically supported but limited by numerical optimization

**Low Confidence:**
- Class prior estimation methods are not provided, creating implementation uncertainty
- Cross-validation sensitivity to K-fold selection and initialization is not thoroughly explored
- Performance guarantees in high-dimensional settings are less established than classical regime

## Next Checks

1. **Class Prior Sensitivity Analysis**: Systematically vary the class prior π₁ in the target domain across multiple orders of magnitude to quantify impact on performance and weight optimization stability.

2. **Cross-Validation Robustness Testing**: Implement multiple K-fold cross-validation schemes (different K values, stratified vs random splits) and compare resulting weight distributions and performance metrics.

3. **Real-World Distribution Shift Benchmark**: Apply framework to real-world dataset with known distribution shift (e.g., medical imaging across hospitals or financial data across market conditions) and compare against standard transfer learning baselines.