---
ver: rpa2
title: Improve Language Model and Brain Alignment via Associative Memory
arxiv_id: '2505.13844'
source_url: https://arxiv.org/abs/2505.13844
tags:
- brain
- memory
- language
- associative
- score
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether simulating associative memory in
  language models can improve their alignment with human brain activity during speech
  comprehension. The authors evaluate brain score alignment between language models
  (GPT-2, LLaMA-2) and fMRI recordings of subjects listening to stories, then augment
  the text with simulated associative memory (both human and GPT-4 generated) to observe
  changes in brain score.
---

# Improve Language Model and Brain Alignment via Associative Memory

## Quick Facts
- arXiv ID: 2505.13844
- Source URL: https://arxiv.org/abs/2505.13844
- Reference count: 24
- Primary result: Simulated associative memory improves language model-brain alignment (0.0014-0.02 brain score improvement)

## Executive Summary
This paper investigates whether simulating associative memory in language models can improve their alignment with human brain activity during speech comprehension. The authors evaluate brain score alignment between language models (GPT-2, LLaMA-2) and fMRI recordings of subjects listening to stories, then augment the text with simulated associative memory (both human and GPT-4 generated) to observe changes in brain score. They find significant improvements in brain score across multiple brain regions when associative memory content is added. Additionally, they create an Association dataset with 1000 samples to fine-tune LLaMA-2 via instruction tuning, achieving 2-7% brain score improvements in regions related to associative memory.

## Method Summary
The study employs a two-pronged approach to improve language model-brain alignment. First, they augment input text with simulated associative memory content generated by either humans or GPT-4, then measure changes in brain score alignment between language models and fMRI recordings. Second, they create a specialized Association dataset with 1000 samples and perform instruction tuning on LLaMA-2 to generate more brain-aligned associative content. Brain alignment is quantified using a brain score metric that measures correlation between model surprisal and neural activity patterns across multiple brain regions during story comprehension.

## Key Results
- Brain score improvements of 0.0014-0.02 across multiple brain regions including frontal gyrus, frontal sulcus, parietal lobule, and medial temporal lobe
- 2-7% brain score improvements in associative memory-related regions after instruction tuning LLaMA-2 with the Association dataset
- Both human-generated and GPT-4-generated associative memory content produced significant alignment improvements

## Why This Works (Mechanism)
The improvement in brain alignment occurs because associative memory processes bridge the gap between language model predictions and the rich, context-dependent neural representations that occur during human language comprehension. When language models incorporate associative memory, they better capture the contextual associations and semantic connections that human brains naturally form during story comprehension. This additional context helps language models generate predictions that more closely match the neural patterns observed in fMRI data.

## Foundational Learning

**fMRI brain recording analysis**: Understanding how to measure neural activity during language comprehension - needed to establish baseline brain alignment metrics and validate improvements. Quick check: Can you interpret correlation between model surprisal and BOLD signal changes?

**Brain score metric**: Quantifying language model-brain alignment through correlation analysis - essential for measuring alignment improvements. Quick check: What constitutes a statistically significant brain score improvement in this context?

**Associative memory simulation**: Generating contextually relevant associations that complement language model predictions - required to test whether additional context improves alignment. Quick check: How do human-generated vs. model-generated associations differ in effectiveness?

**Instruction tuning methodology**: Fine-tuning language models on specialized datasets to improve specific capabilities - necessary for creating models that can generate brain-aligned associative content. Quick check: What dataset size and quality are required for effective instruction tuning?

## Architecture Onboarding

**Component map**: Language model -> Associative memory generator -> Text augmentation -> Brain score calculation -> fMRI comparison

**Critical path**: Original text → Associative memory augmentation → Language model prediction → Brain score calculation → fMRI alignment measurement

**Design tradeoffs**: The study balances between adding associative content (which improves alignment but may alter original meaning) and maintaining text fidelity. They chose to use both human and model-generated associations to test generality of the approach.

**Failure signatures**: Poor brain alignment would manifest as minimal or negative brain score changes after associative memory augmentation, or inconsistent improvements across different brain regions.

**First experiments**:
1. Baseline brain score calculation without associative memory augmentation
2. Brain score measurement with human-generated associative memory content
3. Brain score measurement with GPT-4-generated associative memory content

## Open Questions the Paper Calls Out
None

## Limitations
- Brain score improvements of 0.0014-0.02 represent relatively modest gains with uncertain practical significance
- fMRI data from passive listening introduces variability in individual comprehension and attention
- Study does not investigate whether brain alignment improvements translate to enhanced language generation quality

## Confidence

**High confidence**: Experimental methodology and statistical significance of brain score improvements
**Medium confidence**: Generalizability across different language models and brain regions
**Medium confidence**: Practical significance of observed improvements for real-world applications
**Low confidence**: Whether improved brain alignment translates to enhanced language understanding capabilities

## Next Checks

1. Conduct ablation studies removing individual brain regions to determine which areas contribute most to observed improvements and whether effects are additive across regions
2. Test the instruction-tuned LLaMA-2 model on standardized language understanding benchmarks to verify that brain alignment improvements correspond to enhanced comprehension abilities
3. Perform cross-modal validation using alternative neuroimaging modalities (e.g., MEG or EEG) to confirm that improvements are not specific to fMRI measurement constraints