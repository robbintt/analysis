---
ver: rpa2
title: Gradient Descent Robustly Learns the Intrinsic Dimension of Data in Training
  Convolutional Neural Networks
arxiv_id: '2504.08628'
source_url: https://arxiv.org/abs/2504.08628
tags:
- rank
- data
- noise
- lemma
- then
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the rank of convolutional neural networks (CNNs)
  trained by gradient descent, focusing on robustness to image background noises.
  The authors demonstrate that CNN ranks are more robust to background noise compared
  to data ranks.
---

# Gradient Descent Robustly Learns the Intrinsic Dimension of Data in Training Convolutional Neural Networks

## Quick Facts
- arXiv ID: 2504.08628
- Source URL: https://arxiv.org/abs/2504.08628
- Reference count: 6
- CNNs trained by gradient descent can robustly learn the intrinsic dimension of clean images despite background noise, with filter stable rank approaching clean data rank while data matrix rank explodes.

## Executive Summary
This paper studies how convolutional neural networks (CNNs) trained by gradient descent develop filter structures that are robust to background noise in input images. The authors demonstrate that while the stable rank of the input data matrix explodes with increasing noise levels, the stable rank of the trained CNN filters remains close to the intrinsic dimension of the clean data. They provide theoretical analysis proving this phenomenon for two-layer CNNs under specific conditions, showing that different filters align with distinct basis vectors of the clean data. The results suggest CNNs can extract meaningful signal from noisy inputs by learning a compressed representation that filters out background noise.

## Method Summary
The study uses two-layer CNNs with average global pooling and Huberized ReLU activation, trained via full-batch gradient descent on both synthetic and real datasets (MNIST, CIFAR-10). The theoretical analysis focuses on binary classification with specific initialization conditions (small Gaussian initialization) and proves that filter updates converge to directions aligned with the intrinsic basis vectors of clean data. The key innovation is showing that different filters are updated in distinct directions based on their random initialization, allowing the network to capture the clean data's low-rank structure even when the input data matrix has high rank due to noise. The experiments validate this by showing filter stable ranks remain stable across noise levels while data ranks increase dramatically.

## Key Results
- Theoretical proof that CNN filter stable rank approaches 2K (clean data rank) within polynomial iterations, even as data matrix stable rank explodes
- Experimental validation on MNIST, CIFAR-10, and synthetic datasets showing filter ranks remain stable across varying noise levels
- Demonstration that different convolutional filters align with distinct basis vectors of clean data based on initialization

## Why This Works (Mechanism)
The mechanism relies on the specific dynamics of gradient descent updates for convolutional filters. When initialized with small Gaussian noise, different filters in the first layer naturally align with different basis vectors of the clean data subspace. During training, each filter's update direction is determined by its initial alignment with these basis vectors, causing them to converge to orthogonal directions that span the clean data manifold. The Huberized ReLU activation prevents gradient explosion while maintaining the theoretical properties needed for the analysis. Average global pooling ensures the final representation captures the entire image content, allowing the filters to learn robust features.

## Foundational Learning
- **Stable Rank**: Defined as $\|A\|_F^2 / \|A\|_2^2$, measures effective dimensionality of a matrix
  - *Why needed*: Primary metric for quantifying how CNN filters compress information
  - *Quick check*: Compute stable rank for identity matrix (should equal dimension) and rank-1 matrix (should equal 1)
- **Huberized ReLU**: Activation function combining ReLU with smooth transition near zero
  - *Why needed*: Theoretical analysis requires bounded gradients while maintaining ReLU-like properties
  - *Quick check*: Verify function is smooth at origin and behaves like ReLU elsewhere
- **PCA Rank Reduction**: Preprocessing step reducing data to intrinsic dimension K
  - *Why needed*: Creates controlled experiments with known clean data structure
  - *Quick check*: Verify reduced data matrix has rank exactly K
- **Random Initialization Alignment**: Filters initialized randomly but converge to specific directions
  - *Why needed*: Key mechanism for learning distinct basis vectors
  - *Quick check*: Track filter directions during training to confirm convergence patterns
- **Background Noise Robustness**: Network maintains performance despite input corruption
  - *Why needed*: Demonstrates practical value of the theoretical findings
  - *Quick check*: Compare test accuracy on clean vs. noisy inputs

## Architecture Onboarding

**Component Map:**
MNIST/CIFAR-10 -> PCA Rank Reduction -> Circular Noise Padding -> Two-Layer CNN -> Average Global Pooling -> Classification

**Critical Path:**
Data Preprocessing (PCA + Noise) -> Model Training (GD + Huberized ReLU) -> Filter Rank Analysis -> Data Rank Analysis

**Design Tradeoffs:**
- Small initialization variance ensures theoretical bounds but may slow convergence
- Huberized ReLU provides theoretical guarantees but differs from standard practice
- Full-batch GD simplifies analysis but is computationally expensive for large datasets

**Failure Signatures:**
- Filter rank explosion indicates initialization scale too large or learning rate too high
- Data rank not increasing suggests noise level too low or preprocessing incorrect
- Poor classification accuracy indicates model capacity insufficient or training not converged

**First 3 Experiments:**
1. Verify PCA preprocessing correctly reduces MNIST to specified rank K
2. Test Huberized ReLU implementation with different κ values
3. Train on synthetic data with controlled noise levels to observe rank dynamics

## Open Questions the Paper Calls Out
- Can the rank robustness phenomenon be generalized to deep convolutional neural networks, and how should the rank of the model be defined in that context?
- Do Vision Transformers (ViTs) exhibit similar rank robustness to background noise as CNNs?
- Does the intrinsic dimension learning property hold for unsupervised or generative tasks?

## Limitations
- Theoretical analysis restricted to two-layer CNNs, limiting generalizability to deeper architectures
- Requires specific conditions: small initialization, Huberized ReLU, training to near-zero loss
- Experimental validation primarily on relatively simple datasets (MNIST, synthetic)

## Confidence
- **High confidence**: The general phenomenon that CNN filters develop low-rank structure during training is well-established
- **Medium confidence**: The specific claim about robustness to background noise requires precise experimental conditions
- **Low confidence**: Exact numerical values for learning rate, Huberized ReLU parameters, and theoretical bounds remain uncertain

## Next Checks
1. Verify the MNIST preprocessing pipeline: apply PCA to rank K, reshape, add circular noise padding, and confirm data rank explosion occurs at specified noise levels
2. Implement Huberized ReLU with q=3 and test different κ values (0.5, 1.0) to assess sensitivity of filter rank stability
3. Systematically vary initialization scale σ₀ and learning rate η to identify the regime where filter rank remains stable despite increasing data rank