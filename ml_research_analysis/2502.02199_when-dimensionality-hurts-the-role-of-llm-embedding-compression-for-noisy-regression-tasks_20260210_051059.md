---
ver: rpa2
title: 'When Dimensionality Hurts: The Role of LLM Embedding Compression for Noisy
  Regression Tasks'
arxiv_id: '2502.02199'
source_url: https://arxiv.org/abs/2502.02199
tags:
- tasks
- dataset
- language
- dimensionality
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how embedding dimensionality affects performance
  on noisy regression tasks, particularly stock return prediction from news. The authors
  compress high-dimensional LLM embeddings using a simple autoencoder and evaluate
  the compressed representations across multiple domains with varying signal-to-noise
  ratios.
---

# When Dimensionality Hurts: The Role of LLM Embedding Compression for Noisy Regression Tasks

## Quick Facts
- **arXiv ID:** 2502.02199
- **Source URL:** https://arxiv.org/abs/2502.02199
- **Reference count:** 22
- **Key finding:** Optimal embedding dimensionality for noisy regression tasks is much lower than the original 768 dimensions, with 8 dimensions often outperforming higher dimensions.

## Executive Summary
This paper investigates how embedding dimensionality affects performance on noisy regression tasks, particularly stock return prediction from news. The authors compress high-dimensional LLM embeddings using a simple autoencoder and evaluate the compressed representations across multiple domains with varying signal-to-noise ratios. Key findings show that for noisy tasks like financial return prediction, optimal performance occurs at much lower dimensions (e.g., 8 dimensions) than the original 768-dimensional embeddings. This compressed representation reduces overfitting to noise while maintaining essential predictive information. The study finds that compressed embeddings outperform interpretable features like sentiment or emotion in noisy tasks, suggesting that previous successes of these features may primarily stem from their dimensionality reduction effect rather than inherent informativeness.

## Method Summary
The method uses all-mpnet-base-v2 embeddings (768-dim) compressed via autoencoders with latent dimensions dz ∈ {1, 2, 4, 8, 16, 32, 128, 256, 512}. The autoencoder is trained to minimize MSE reconstruction loss over 100 epochs with early stopping. Compressed embeddings (encoder outputs) are fed to Random Forest regression models. The study evaluates on financial news data (30K training samples) and high-signal datasets (Yelp, App Reviews, Amazon Reviews, ELL Grading). Performance is measured using Huber loss (δ=1), with statistical significance assessed via T-tests between error distributions at different latent dimensions.

## Key Results
- For noisy financial return prediction, optimal performance occurs at dz=8 dimensions, significantly outperforming raw 768-dimensional embeddings
- Compressed embeddings at dz=8 outperform interpretable features like sentiment and emotion classifiers in noisy tasks
- Optimal dimensionality is inversely related to signal-to-noise ratio: high-noise tasks benefit from aggressive compression (4-32d), while high-signal tasks perform well at surprisingly low dimensions (8-32d)
- Random Forest regression consistently outperforms MLP baselines for these noisy regression tasks

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Dimensionality reduction acts as a regularizer that mitigates overfitting in noisy regression tasks.
- **Mechanism:** High-dimensional embeddings (768d) contain redundant and noisy features that enable models to memorize spurious correlations. Autoencoder compression to a bottleneck layer (e.g., 8d) forces the representation to retain only the most salient information, reducing model capacity for noise-fitting while preserving predictive signal.
- **Core assumption:** The autoencoder's reconstruction objective prioritizes encoding task-relevant variance over noise; this transfers to downstream regression.
- **Evidence anchors:** [abstract] "compressing embeddings, in a minimally supervised manner using an autoencoder's hidden representation, can mitigate overfitting and improve performance on noisy tasks"; [section 1] "feature selection or compression can act as a regularising component... When input dimensionality is too large, models risk overfitting by memorising noise"
- **Break condition:** If the autoencoder reconstruction loss plateaus before reaching low dimensions (e.g., Figure 4 shows semantic loss at optimal dz=8), downstream performance may degrade due to information loss.

### Mechanism 2
- **Claim:** Optimal embedding dimensionality is inversely related to task signal-to-noise ratio.
- **Mechanism:** Noisy tasks (financial returns) have weak input-target dependencies, so aggressive compression (4-32d) prevents overfitting. High-signal tasks (reviews, essays) tolerate higher dimensions but still achieve strong performance at surprisingly low dimensions (8-32d), suggesting "intrinsic dimensionality" of regression-relevant information is low across domains.
- **Core assumption:** Signal-to-noise ratio can be characterized at the task level and is relatively stable within a domain.
- **Evidence anchors:** [abstract] "optimal dimensionality is task-dependent and inversely related to signal-to-noise ratio"; [section 4.1] "for the financial returns task, there is a convex relationship between performance and dimensionality, whereas the relationship approximates a negative exponential in tasks with a strong signal"
- **Break condition:** If task SNR varies significantly within a dataset, a single compression level may be suboptimal for all samples.

### Mechanism 3
- **Claim:** The success of interpretable features (sentiment, emotion) in financial tasks stems primarily from dimensionality reduction rather than feature informativeness.
- **Mechanism:** Sentiment and emotion classifiers produce low-dimensional outputs (typically 3-10 classes). Their performance gain comes from the regularization effect of this compression, not from capturing domain-specific semantics. Autoencoder-compressed embeddings at equivalent dimensions match or exceed these features.
- **Core assumption:** Autoencoder latent features can capture equivalent or greater predictive information than hand-designed sentiment/emotion features when dimensionality is matched.
- **Evidence anchors:** [abstract] "compressed embeddings outperform interpretable features like sentiment or emotion in noisy tasks, suggesting that previous successes of these features may primarily stem from their dimensionality reduction effect"; [section 4, Figure 1] "Both representations do not exceed the expected performance of the autoencoder features at their respective dimensions dz"
- **Break condition:** If sentiment/emotion features capture domain knowledge not present in pre-trained embeddings, they may outperform unsupervised autoencoder compression.

## Foundational Learning

- **Concept:** Overfitting and Regularization in High-Dimensional Spaces
  - **Why needed here:** The paper's core argument hinges on understanding how excessive dimensionality enables noise memorization and how compression regularizes.
  - **Quick check question:** Given a 768-dimensional embedding and 30K training samples, why might a Random Forest overfit, and how does reducing to 8 dimensions help?

- **Concept:** Autoencoder Bottleneck Representations
  - **Why needed here:** The compression method uses an autoencoder's hidden layer as the compressed representation; understanding what information survives the bottleneck is critical.
  - **Quick check question:** If an autoencoder trained on 768d→8d→768d achieves 0.7 cosine similarity on reconstruction, what types of information are likely lost vs. preserved?

- **Concept:** Signal-to-Noise Ratio in Regression Tasks
  - **Why needed here:** The paper frames task selection around SNR; practitioners need to assess their own task's noise level to apply findings.
  - **Quick check question:** Why might stock return prediction have lower SNR than review score prediction, and what are observable indicators of low SNR in your data?

## Architecture Onboarding

- **Component map:** Text Encoder -> Autoencoder Compression -> Random Forest Regression
- **Critical path:** Text → Chunking/Tokenization → LLM Embedding (768d) → Autoencoder Compression (dz) → Random Forest → Prediction
- **Design tradeoffs:**
  - **Autoencoder vs. PCA/UMAP:** Paper uses autoencoders but acknowledges PCA, t-SNE, UMAP as alternatives (Section 7). Autoencoders may capture nonlinear structure; PCA is faster and deterministic.
  - **Random Forest vs. MLP:** MLP showed high variance and no significant results (Appendix C). Random Forest is more robust for noisy, small-sample regimes.
  - **dz selection:** Paper finds dz ∈ {4, 8, 16, 32} statistically indistinguishable for financial task (Figure 1); err toward 8-16 for aggressive regularization in noisy domains.
- **Failure signatures:**
  - **Autoencoder under-reconstruction:** If cosine similarity (Figure 4) is <0.5 at target dz, information loss may harm downstream performance.
  - **MLP instability:** High variance in prediction errors signals model is not learning stable patterns (Appendix C).
  - **No improvement over raw embeddings:** If compression doesn't help, task may have high SNR; try higher dz or skip compression.
- **First 3 experiments:**
  1. **Baseline calibration:** Run regression with raw 768d embeddings to establish upper bound; compare against dz ∈ {1, 2, 4, 8, 16, 32, 64, 128, 256, 512} to find optimal point.
  2. **SNR proxy test:** Split data by target variance or prediction confidence; verify that high-noise subsets benefit more from aggressive compression.
  3. **Feature comparison benchmark:** Compare autoencoder-compressed embeddings (dz=8) against sentiment/emotion classifier outputs at equivalent dimensions to replicate paper's interpretable feature analysis.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can signal-to-noise ratio be estimated a priori to enable adaptive dimensionality compression that dynamically adjusts to task characteristics?
  - **Basis in paper:** [explicit] The authors state that adaptive compression methods based on signal-to-noise ratio are desirable, "however, to do this, a measure of signal-to-noise is required before processing the input features."
  - **Why unresolved:** No known method exists to quantify signal-to-noise ratio before feature extraction and model training, yet this is necessary for truly adaptive approaches.
  - **What evidence would resolve it:** Development of a pre-processing metric that correlates with downstream optimal dimensionality across diverse regression tasks.

- **Open Question 2:** How do alternative dimensionality reduction techniques (PCA, t-SNE, UMAP) compare to autoencoder-based compression for noisy regression tasks?
  - **Basis in paper:** [explicit] The limitations section acknowledges: "This current version of the paper does not provide comparisons with these techniques, but we will provide the comparison in future versions of this paper."
  - **Why unresolved:** Only autoencoder compression was tested; it remains unknown whether the findings generalize to other compression paradigms.
  - **What evidence would resolve it:** Systematic benchmarking of PCA, t-SNE, and UMAP compression on the same financial returns and high-signal datasets using identical evaluation protocols.

- **Open Question 3:** Do the optimal dimensionality findings generalize to other noisy regression domains beyond financial returns prediction?
  - **Basis in paper:** [inferred] The study focuses on "a specific financial returns dataset with a single definition of 'noisy' data" and explicitly notes this as a limitation requiring broader exploration.
  - **Why unresolved:** Financial returns represent only one type of noisy task; other domains (e.g., medical outcomes, social phenomena) may exhibit different noise characteristics and dimensionality optima.
  - **What evidence would resolve it:** Replication of the compression experiments across multiple additional low signal-to-noise domains with quantified noise characteristics.

## Limitations

- Autoencoder architecture and hyperparameters remain underspecified, creating reproducibility uncertainty
- Results hinge on Random Forest regression; MLP baseline failed but failure mode not deeply explored
- Financial dataset filtering process (NER model and company dictionary) is mentioned but not provided
- Signal-to-noise ratio relationship is plausible but based on limited domain sampling and lacks formal statistical characterization

## Confidence

**High Confidence:** The core empirical observation that dimensionality reduction improves noisy regression performance (financial return prediction) is well-supported by the data. The comparison showing autoencoder-compressed features outperforming interpretable features at equivalent dimensions is robust and clearly demonstrated.

**Medium Confidence:** The claim that optimal dimensionality is inversely related to task signal-to-noise ratio is plausible but based on limited domain sampling (three datasets). The relationship appears in the results but lacks formal statistical characterization.

**Low Confidence:** The assertion that previous successes of sentiment/emotion features in finance primarily stem from dimensionality reduction rather than domain knowledge is suggestive but not definitively proven. The paper shows autoencoder features can match these features at equivalent dimensions, but doesn't prove sentiment features don't capture unique information.

## Next Checks

1. **Replicate the fundamental claim:** Train autoencoders with varying dz ∈ {4, 8, 16, 32} on the financial dataset and verify that dz=8 outperforms both raw 768d embeddings and dz=256 in terms of Huber loss. Check if results match Figure 1.

2. **Test the SNR hypothesis:** Systematically vary the noise level in the financial task (e.g., subsample data, add synthetic noise to targets) and measure how optimal dz shifts. This would validate the inverse relationship between SNR and optimal dimensionality.

3. **Cross-validate the sentiment comparison:** Implement sentiment and emotion classifiers on the financial dataset, generate low-dimensional outputs, and compare their performance against autoencoder-compressed embeddings at matched dimensions. This tests whether the autoencoder truly captures equivalent or superior predictive information.