---
ver: rpa2
title: 'Compose and Fuse: Revisiting the Foundational Bottlenecks in Multimodal Reasoning'
arxiv_id: '2509.23744'
source_url: https://arxiv.org/abs/2509.23744
tags:
- reasoning
- erin
- modalities
- modality
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates whether and how additional modalities enhance
  or impair multimodal reasoning in large language models. It introduces a logic-grounded
  evaluation framework with six interaction patterns, systematically varying how facts
  are distributed across modalities and combined for inference.
---

# Compose and Fuse: Revisiting the Foundational Bottlenecks in Multimodal Reasoning

## Quick Facts
- arXiv ID: 2509.23744
- Source URL: https://arxiv.org/abs/2509.23744
- Reference count: 40
- Key outcome: Multimodal reasoning failures stem from integration, not perception; composition-aware training and early fusion control are promising directions.

## Executive Summary
This work investigates whether and how additional modalities enhance or impair multimodal reasoning in large language models. It introduces a logic-grounded evaluation framework with six interaction patterns, systematically varying how facts are distributed across modalities and combined for inference. Results show that multimodal input helps only when it provides independent, sufficient reasoning paths, while redundant or chained entailment often degrades performance. The best accuracy comes from text-only baselines, indicating that the bottleneck lies not in perception but in integration. Two core failures are identified: a task-composition bottleneck, where recognition and reasoning cannot be jointly executed in one pass, and a fusion bottleneck, where early integration introduces modality bias. Internal probing reveals that attention patterns fail to encode fact usefulness, but simple two-step prompting or softening early attention significantly restores reasoning performance. Overall, multimodal reasoning failures stem from integration, not perception, suggesting composition-aware training and early fusion control as promising directions.

## Method Summary
The authors introduce a logic-grounded evaluation framework to systematically assess how facts distributed across modalities affect reasoning performance. Six interaction patterns are defined, ranging from facts entirely in one modality to independent facts in each modality. Experiments are conducted on synthetic tasks (ProPara, an algebra word problem benchmark, and a new image algebra task) using state-of-the-art multimodal models. Performance is measured under varying input modalities, and internal probing of attention patterns is performed to diagnose integration failures.

## Key Results
- Multimodal input helps only when it provides independent, sufficient reasoning paths.
- Redundant or chained entailment often degrades performance.
- Best accuracy comes from text-only baselines, indicating integration, not perception, is the bottleneck.

## Why This Works (Mechanism)
The paper identifies two core failures in multimodal reasoning: a task-composition bottleneck, where recognition and reasoning cannot be jointly executed in one pass, and a fusion bottleneck, where early integration introduces modality bias. Attention patterns are shown to fail in encoding fact usefulness, but simple two-step prompting or softening early attention significantly restores reasoning performance.

## Foundational Learning
- **Logic-grounded evaluation framework**: A systematic way to vary fact distribution across modalities for controlled reasoning experiments. Why needed: isolates integration effects from perception. Quick check: Define six interaction patterns (e.g., facts in text only, independent in each modality).
- **Task-composition bottleneck**: Recognition and reasoning cannot be jointly executed in one pass. Why needed: identifies the core limitation of current multimodal models. Quick check: Compare single-step vs. two-step prompting performance.
- **Fusion bottleneck**: Early integration introduces modality bias. Why needed: explains why redundant or chained entailment degrades performance. Quick check: Analyze attention patterns for modality bias.

## Architecture Onboarding
- **Component map**: Input modalities (text, image) -> Early fusion layers -> Cross-attention layers -> Reasoning module -> Output.
- **Critical path**: Recognition (modality-specific encoders) -> Fusion (cross-attention) -> Reasoning (language model).
- **Design tradeoffs**: Early fusion enables joint processing but risks modality bias; late fusion preserves modality independence but may miss cross-modal interactions.
- **Failure signatures**: Attention patterns fail to encode fact usefulness; modality bias in early fusion degrades performance on redundant or chained entailment tasks.
- **Exactly 3 first experiments**:
  1. Compare single-step vs. two-step prompting on logic-grounded tasks.
  2. Analyze attention patterns for modality bias and fact usefulness encoding.
  3. Implement gating mechanisms in early fusion layers and measure impact on reasoning accuracy.

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focuses on synthetic, logic-grounded tasks, raising questions about generalizability to real-world, noisy multimodal scenarios.
- Two-step prompting may introduce task-specific inductive biases that do not transfer to models trained end-to-end for multimodal fusion.
- Attention pattern analysis offers suggestive but correlational evidence for fusion failures; direct causal interventions would strengthen the claim.

## Confidence
- Multimodal reasoning degrades with redundant or chained entailment: High
- Integration (not perception) is the bottleneck: Medium
- Attention patterns do not encode fact usefulness: Medium
- Two-step prompting restores performance: Medium

## Next Checks
1. Replicate the synthetic logic-grounded experiments with real-world, noisy multimodal datasets (e.g., VQA, GQA) to test robustness.
2. Perform causal ablation studies on cross-attention layers to directly test whether fusion failures arise from attention patterns.
3. Implement and evaluate architectural modifications to early fusion layers (e.g., gating mechanisms, adaptive attention) as a systematic alternative to two-step prompting.