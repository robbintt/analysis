---
ver: rpa2
title: 'HOMURA: Taming the Sand-Glass for Time-Constrained LLM Translation via Reinforcement
  Learning'
arxiv_id: '2601.10187'
source_url: https://arxiv.org/abs/2601.10187
tags:
- uni00000044
- uni00000011
- translation
- uni00000003
- uni00000051
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces HOMURA, a reinforcement learning framework
  for time-constrained LLM translation. The method employs a KL-regularized objective
  with a dynamic syllable-ratio reward to optimize the trade-off between semantic
  preservation and strict temporal compliance.
---

# HOMURA: Taming the Sand-Glass for Time-Constrained LLM Translation via Reinforcement Learning

## Quick Facts
- arXiv ID: 2601.10187
- Source URL: https://arxiv.org/abs/2601.10187
- Reference count: 40
- Key outcome: HOMURA outperforms strong LLM baselines on Sand-Glass benchmark, achieving precise length control across languages without compromising semantic adequacy, with BLEU-ρ scores reaching 0.701 on Zh→En translation.

## Executive Summary
This paper introduces HOMURA, a reinforcement learning framework for time-constrained LLM translation that employs a KL-regularized objective with dynamic syllable-ratio reward to optimize the trade-off between semantic preservation and strict temporal compliance. The method addresses cross-lingual verbosity bias by implementing language-aware length control that respects cross-lingual information density hierarchies, achieving precise syllable-level duration budgets while maintaining semantic fidelity. HOMURA demonstrates superior efficiency and effectiveness compared to strong LLM baselines, with BLEU-ρ scores reaching 0.701 on Chinese-to-English translation while maintaining high core event retention rates.

## Method Summary
HOMURA is a reinforcement learning framework that optimizes time-constrained LLM translation through GRPO with β=0 and dynamic syllable-ratio rewards. The method uses Qwen3-8B-Chat as base model, training on 70K instances with batch size 16 and 16 rollouts per prompt. The reward function combines R_len (dynamic syllable-ratio with squared exponential decay) and R_qual (either rubric-based or GenRM), where dynamic bounds [L(x), R(x)] adapt to utterance length via scaling factor γ(x). The framework removes KL regularization to enable structural rewriting necessary for compression while maintaining stability through GRPO's token-level trust region and sequence-level semantic rewards.

## Key Results
- HOMURA Reason achieves BLEU-ρ score of 0.701 on Zh→En translation while maintaining in-bounds rate (IB=✓)
- GenRM with explicit CoT reasoning provides marginally better BT-CERR scores than rubric-based compositional rewards on two of three target languages
- The method demonstrates effective length control across Chinese→En/De/Es translation with target bounds [0.8,0.9], [0.9,1.0], [1.0,1.1] respectively
- Compression wall observed at ρ≈0.49 for Zh→En, beyond which semantic collapse occurs

## Why This Works (Mechanism)

### Mechanism 1
Dynamic syllable-ratio reward enables language-aware length control that respects cross-lingual information density hierarchies. The reward function R_len uses a dynamic acceptance interval [L(x), R(x)] initialized from language-specific Target Bounds (B_L), then adaptively relaxes lower thresholds for shorter utterances via scaling factor γ(x) to mitigate discretization noise inherent in syllable counting. Core assumption: Syllable count serves as a valid proxy for spoken duration; the Iso-Information Principle holds across tested language pairs.

### Mechanism 2
Removing KL regularization (β→0) allows structural rewriting necessary for compression while GRPO's token-level trust region and sequence-level semantic rewards provide sufficient stability. GRPO's clipping mechanism enforces trust region relative to π_θ^old, and group-relative advantage normalization prevents global drift. The back-translation reward R_bt acts as implicit semantic regularizer—constraining what information is preserved without penalizing how it's expressed lexically. Core assumption: The reference model P_0 carries a "verbosity prior" that actively conflicts with compression objectives.

### Mechanism 3
Reason-based GenRM (Generative Reward Model) with explicit CoT reasoning provides more robust quality signals than rubric-based compositional rewards for compression tasks. GenRM performs back-translation, semantic consistency check, and translation quality assessment in a single CoT process, outputting binary reward that enforces conjunction of information preservation AND quality—rather than averaging separate signals that may conflict. Core assumption: CoT reasoning can reliably detect semantic drift under compression; synthesized training data from Gemini-2.5-Pro transfers to this domain.

## Foundational Learning

**Rate-Distortion Theory in NLP**
Why needed: The paper frames translation compression as approaching a rate-distortion limit—syllable budget is "rate," semantic loss is "distortion." Understanding this trade-off is essential for interpreting why aggressive compression eventually fails at a "compression wall."
Quick check: Can you explain why ρ≈0.49 might represent a feasibility boundary for Zh→En translation?

**GRPO (Group Relative Policy Optimization)**
Why needed: This is the core optimizer. Unlike standard PPO, GRPO normalizes advantages within groups of samples from the same prompt, enabling stable training without a separate value function.
Quick check: How does group-relative advantage normalization differ from standard advantage estimation, and why might it help when β=0?

**Cross-Lingual Information Density**
Why needed: The method explicitly calibrates bounds to linguistic density (e.g., Spanish ID=0.63 vs. Mandarin ID=0.94). Without this, you'd misdiagnose legitimate expansion as verbosity bias.
Quick check: Why does translating from high-density Mandarin to low-density Spanish require ~1.49× expansion rather than 1:1 syllable mapping?

## Architecture Onboarding

**Component map:**
Input layer (source utterance x + syllable-ratio budget c) -> Policy network (Qwen3-8B-Chat) -> Length reward (R_len) + Quality reward (R_qual) -> Optimizer (GRPO) -> Frozen evaluators (DeepSeek-V3, Qwen-Embedding-0.6B)

**Critical path:**
1. Sample 16 candidates per prompt from current policy
2. Compute R_len (syllable ratio check) + R_qual (rubric or GenRM)
3. Normalize rewards within group → advantages
4. Update via clipped surrogate loss (no KL term)
5. Repeat for 1 epoch over 70K training instances

**Design tradeoffs:**
- **β=0 vs. β>0**: Maximum compression freedom vs. stability; paper shows β=0 wins for structural adaptation
- **Rubric vs. GenRM**: Interpretable modular rewards vs. end-to-end learned evaluation; GenRM slightly better on BT-CERR
- **Static vs. dynamic bounds**: Simple implementation vs. handling short-utterance noise; dynamic converges faster

**Failure signatures:**
- Reward hacking: Output becomes telegraphic (dropping function words) while technically satisfying constraints
- Compression wall collision: Model rebounds to higher ρ when targets are set too aggressively (e.g., [0.3, 0.4])
- Semantic drift: High IB compliance but BT-CERR drops—model meets length but omits core events

**First 3 experiments:**
1. **Baseline reproduction**: Run HOMURA on Sand-Glass Zh→En with B_L ∈ [0.8, 0.9]; verify BLEU-ρ ≈ 0.70 and IB=✓
2. **Ablation: β sensitivity**: Compare β ∈ {0, 0.01, 0.05}; expect β=0 to achieve highest BT-CERR but observe gradient stability
3. **Generalization test**: Apply trained model to unseen domain (e.g., ACGN) without fine-tuning; measure length compliance and semantic retention to assess domain transfer

## Open Questions the Paper Calls Out

**Open Question 1**
Does the observed compression feasibility boundary (ρ≈0.49 for Zh→En) generalize across linguistically distant pairs and low-resource languages? The boundary may be language-pair-specific rather than universal, dependent on typological distance and available training resources. Experiments extending HOMURA to diverse language pairs (e.g., Japanese→Arabic, Finnish→Swahili) measuring whether similar compression walls emerge would resolve this.

**Open Question 2**
How can multimodal constraints such as lip-synchronization and isochrony be integrated into the syllable-based duration approximation? Physical duration is heavily influenced by prosodic features and speech tempo, which pure syllable counting cannot capture; real-world dubbing requires visual-phonetic alignment. Extending HOMURA to incorporate acoustic duration modeling and visual speech features, then evaluating synchronization quality in actual dubbing scenarios would resolve this.

**Open Question 3**
Can HOMURA be extended to end-to-end speech translation with joint semantic and duration optimization? The current framework operates on text; direct speech-to-speech translation requires handling continuous audio signals, speaker characteristics, and temporal alignment without intermediate text representations. Implementing a speech-to-speech variant with learned duration predictors and evaluating on spoken translation benchmarks with temporal constraints would resolve this.

## Limitations

- Experimental scope confined to Sand-Glass benchmark with 1,000 instances across 5 colloquial domains; performance on formal or technical translation remains unknown
- Several critical components lack full specification including exact syllabification method for target languages and synthetic data generation protocol for GenRM
- Single model architecture (Qwen3-8B-Chat) limits generalizability; performance characteristics may differ with other architectures

## Confidence

**High Confidence:**
- HOMURA Reason outperforms baseline models on Sand-Glass benchmark with BLEU-ρ scores reaching 0.701 for Zh→En translation
- Dynamic syllable-ratio reward with adaptive relaxation effectively handles discretization noise in short utterances
- Removing KL regularization (β→0) enables greater structural adaptation for compression while maintaining stability through GRPO mechanisms
- GenRM with explicit CoT reasoning provides marginally better BT-CERR scores than rubric-based compositional rewards

**Medium Confidence:**
- The observed compression wall (~ρ=0.49 for Zh→En) represents a fundamental feasibility boundary for this language pair
- Cross-lingual information density hierarchies accurately predict required expansion ratios between language pairs
- The back-translation reward serves as sufficient semantic regularizer when KL is removed

**Low Confidence:**
- GenRM's superiority over rubric-based rewards generalizes beyond the tested language pairs
- The method's performance transfers to formal or technical translation domains
- The dynamic bounds mechanism generalizes to languages with very different prosodic characteristics

## Next Checks

**Check 1: Domain Transfer Validation**
Apply HOMURA to formal translation domains (e.g., legal, medical, technical documentation) using the same trained model without fine-tuning. Measure BLEU-ρ, BT-CERR, and IB compliance to assess whether the compression capabilities generalize beyond colloquial speech domains.

**Check 2: Language Pair Expansion**
Test HOMURA on additional high-density to low-density language pairs (e.g., Arabic→English, Korean→English) and low-density to high-density pairs (e.g., English→Japanese). Measure the compression wall threshold and compare against predictions from the Iso-Information Principle.

**Check 3: Real-Time Constraint Adaptation**
Modify HOMURA to accept variable syllable budgets at inference time rather than fixed language-pair bounds. Evaluate on a dynamic subtitling dataset where speaking rates vary within and across utterances. Measure performance degradation and adaptability to validate whether the method can handle real-world time-constrained scenarios with speaker-dependent duration variations.