---
ver: rpa2
title: Enhancing Interpretability and Effectiveness in Recommendation with Numerical
  Features via Learning to Contrast the Counterfactual samples
arxiv_id: '2509.03187'
source_url: https://arxiv.org/abs/2509.03187
tags:
- numerical
- feature
- features
- sample
- samples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the lack of modeling the monotonicity between
  neural network outputs and numerical features in recommender systems, which is critical
  for both interpretability and effectiveness. The authors propose a model-agnostic
  Contrastive learning framework with Counterfactual Samples Synthesizing (CCSS) that
  consists of a Counterfactual Samples Synthesizer and a Contrastive Objective Function
  Module.
---

# Enhancing Interpretability and Effectiveness in Recommendation with Numerical Features via Learning to Contrast the Counterfactual samples

## Quick Facts
- **arXiv ID**: 2509.03187
- **Source URL**: https://arxiv.org/abs/2509.03187
- **Reference count**: 29
- **Primary result**: Achieves up to 30.0% AUC improvement and 87.5% Mono_rate improvement on public and industrial datasets

## Executive Summary
This paper addresses the challenge of modeling monotonicity between neural network outputs and numerical features in recommender systems. The authors propose CCSS (Contrastive learning framework with Counterfactual Samples Synthesizing), a model-agnostic approach that generates counterfactual and factual samples by locally disturbing numerical feature values. By enforcing contrastive ranking constraints between these synthesized samples and originals, CCSS successfully improves both interpretability (measured by Mono_rate) and effectiveness (measured by AUC/GAUC) across multiple backbone models. The method has been deployed in a large-scale industrial system serving hundreds of millions of users.

## Method Summary
CCSS is a two-stage framework consisting of a Counterfactual Samples Synthesizer and a Contrastive Objective Function Module. For each training sample, one numerical feature is selected based on feature importance (Shapley Value) and disturbed to generate counterfactual (C) and factual (F) samples by shifting to adjacent bucket centers. The contrastive objective combines pointwise losses on original and factual samples with pairwise hinge losses ranking (F, O) and (O, C) pairs. This enforces monotonic relationships where feature increases lead to predicted score increases (for positive labels). The method is model-agnostic and works with DNN, Wide&Deep, DCN, DeepFM, and PNN backbones.

## Key Results
- AUC improvements up to 30.0% on public and industrial datasets
- GAUC improvements up to 48.7% across all tested models
- Mono_rate improvements up to 87.5%, demonstrating effective monotonicity enforcement
- Successful deployment in industrial recommender system with 3.93% collect rate improvement

## Why This Works (Mechanism)

### Mechanism 1
Synthesizing counterfactual and factual samples by disturbing numerical features enables explicit monotonicity modeling. The synthesizer selects features based on importance, then generates samples by moving values to adjacent buckets in the "correct" direction. This creates ordered triplets (counterfactual < original < factual) for the model to learn from, directly encoding domain knowledge about monotonic relationships.

### Mechanism 2
Contrastive pairwise loss between factual/counterfactual and original samples enforces monotonic ranking constraints. For positive labels with increasing monotonicity, hinge loss terms penalize when factual scores don't exceed original scores or original scores don't exceed counterfactual scores. This creates explicit gradient signals pushing the model to score higher values higher.

### Mechanism 3
Using feature importance (Shapley Values) to guide disturbance focuses learning on influential features. Rather than uniform random selection, features are disturbed with probability proportional to their importance, creating more informative training signals and avoiding wasted computation on irrelevant features.

## Foundational Learning

- **Concept**: Monotonicity constraints in neural networks
  - Why needed: Neural networks can learn arbitrary non-monotonic relationships that violate domain knowledge. CCSS explicitly enforces that certain numerical features should monotonically increase/decrease model outputs.
  - Quick check: For a feature like `video_ctr`, should the model predict higher or lower scores as this value increases?

- **Concept**: Contrastive learning with pairwise ranking loss
  - Why needed: CCSS uses pairwise hinge loss to rank outputs (factual > original > counterfactual), which is a form of contrastive learning that pushes representations apart.
  - Quick check: For hinge loss max(0, margin - (score_positive - score_negative)), what happens when score_positive already exceeds score_negative by more than the margin?

- **Concept**: Counterfactual reasoning in supervised learning
  - Why needed: CCSS generates "what if" samples to teach the model causal expectations, not just data augmentation.
  - Quick check: If you have a sample with `user_ctr = 0.05` and positive label, what is the expected label if you synthetically set `user_ctr = 0.10`?

## Architecture Onboarding

- **Component map**:
  ```
  Input Sample (O) -> Base Model (DNN/Wide&Deep/DCN/DeepFM/PNN) -> ŷ_O
          |
          v
  Feature Importance Module (Shapley Values)
          |
          v
  Counterfactual Synthesizer
          |
          ├── Factual Sample (F) -> Base Model -> ŷ_F
          |
          └── Counterfactual Sample (C) -> Base Model -> ŷ_C
          |
          v
  Contrastive Objective
  L = l_pointwise(O) + l_pointwise(F) + α × (l_pairwise(O,F) + l_pairwise(C,O))
  ```

- **Critical path**:
  1. Specify monotonicity direction for each numerical feature before training
  2. Compute feature importance for disturbance probability distribution
  3. Synthesize F and C samples for each O during training
  4. Compute combined loss and monitor both prediction and interpretability metrics

- **Design tradeoffs**:
  - Discretization granularity: More buckets enable finer disturbances but increase computational cost
  - α parameter: Higher α strengthens monotonicity enforcement but risks degrading overall AUC
  - Single vs. multi-feature disturbance: Disturbing one feature per sample creates realistic counterfactuals but weaker contrast

- **Failure signatures**:
  - Mono_rate stuck near baseline (~50-60%) indicates contrastive loss not being applied
  - Significant AUC drops while Mono_rate improves suggests α too high
  - Training divergence suggests boundary conditions causing empty sample generation
  - Uneven Mono_rate across features suggests biased feature importance estimation

- **First 3 experiments**:
  1. Baseline replication on KuaiRand-Pure with DNN backbone to verify AUC and Mono_rate improvements
  2. Ablation comparing feature importance-guided vs. random disturbance strategies
  3. α sensitivity analysis sweeping from 0.1 to 5.0 to identify optimal Pareto frontier

## Open Questions the Paper Calls Out
None specified in the paper.

## Limitations
- Requires pre-specified monotonicity direction for each numerical feature, which may not be available or accurate for all features
- Computational overhead from generating and training on synthesized samples, effectively tripling batch size
- Discretization granularity significantly impacts effectiveness but optimal settings are not discussed
- Shapley Value computation for feature importance may be expensive and unstable across training iterations

## Confidence
- **High Confidence**: Contrastive learning mechanism is technically sound and internally consistent Mono_rate improvements
- **Medium Confidence**: Feature importance-guided disturbance shows significant improvements but computational overhead is unclear
- **Low Confidence**: Assumption that monotonicity direction is known for all numerical features is questionable in practice

## Next Checks
1. Verify monotonicity direction by computing correlation between each numerical feature and target label, documenting any mismatches with assumed directions
2. Implement CCSS with varying discretization granularities (5, 10, 20, 50 buckets) and measure impact on both AUC and Mono_rate
3. Compare training time and convergence behavior with exact Shapley computation vs. approximation methods vs. random feature selection to quantify computational trade-offs