---
ver: rpa2
title: Benchmarking Ethical and Safety Risks of Healthcare LLMs in China-Toward Systemic
  Governance under Healthy China 2030
arxiv_id: '2505.07205'
source_url: https://arxiv.org/abs/2505.07205
tags:
- safety
- medical
- ethical
- ethics
- healthcare
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study benchmarks the ethical and safety performance of Chinese
  healthcare LLMs using a novel 12,000-item dataset covering 20 medical ethics and
  safety dimensions. Evaluations of models like Qwen 2.5-32B and DeepSeek show moderate
  baseline accuracy (42.7% for Qwen 2.5-32B) and significant improvement after fine-tuning
  (up to 50.8% accuracy), indicating substantial gaps in LLM decision-making on ethics
  and safety.
---

# Benchmarking Ethical and Safety Risks of Healthcare LLMs in China-Toward Systemic Governance under Healthy China 2030

## Quick Facts
- arXiv ID: 2505.07205
- Source URL: https://arxiv.org/abs/2505.07205
- Reference count: 19
- Primary result: Moderate baseline accuracy (42.7%) in Chinese healthcare LLMs' ethical and safety performance, improving to 50.8% after fine-tuning, highlighting need for institutional governance.

## Executive Summary
This study benchmarks the ethical and safety performance of Chinese healthcare LLMs using a novel 12,000-item dataset spanning 20 medical ethics and safety dimensions. Evaluations of models like Qwen 2.5-32B and DeepSeek show baseline accuracy of 42.7%, rising to 50.8% after fine-tuning. The findings reveal significant gaps in LLM decision-making on ethics and safety, reflecting insufficient institutional governance—such as lack of audit protocols, slow IRB adaptation, and insufficient monitoring tools. The authors propose a governance framework for healthcare institutions that includes embedding LLM auditing teams, enacting data ethics guidelines, and implementing safety simulation pipelines. This work underscores the urgent need for robust institutional governance to align AI innovation with patient safety and ethical standards under China’s Healthy China 2030 initiative.

## Method Summary
The study developed a comprehensive 12,000-item dataset covering 20 medical ethics and safety dimensions. Chinese healthcare LLMs, including Qwen 2.5-32B and DeepSeek, were evaluated on this dataset. Baseline performance was measured, followed by fine-tuning to assess improvements. The evaluation focused on identifying gaps in ethical and safety decision-making, with results informing the design of a governance framework for healthcare institutions.

## Key Results
- Baseline accuracy for Chinese healthcare LLMs on ethical and safety tasks: 42.7% (Qwen 2.5-32B)
- Post-fine-tuning accuracy: up to 50.8%
- Significant gaps in LLM decision-making on ethics and safety identified
- Insufficient institutional governance mechanisms (lack of audit protocols, slow IRB adaptation, insufficient monitoring tools)

## Why This Works (Mechanism)
The study leverages a large, specialized dataset to rigorously benchmark LLM performance on ethics and safety, revealing practical governance gaps. Fine-tuning demonstrates that targeted training can improve model behavior, but improvements remain modest, indicating systemic issues. The governance framework addresses these by institutionalizing oversight and safety protocols, aligning with national health policy objectives.

## Foundational Learning
- **Medical Ethics Dimensions**: Why needed—to ensure LLMs respect patient rights and confidentiality; Quick check—verify dataset covers informed consent, privacy, and non-maleficence.
- **Safety Risk Assessment**: Why needed—to prevent harm from incorrect or unethical medical advice; Quick check—confirm evaluation includes adverse event scenarios.
- **Institutional Governance Frameworks**: Why needed—to embed accountability and oversight in AI deployment; Quick check—ensure framework includes audit, monitoring, and IRB adaptation.
- **LLM Auditing Protocols**: Why needed—to systematically review model outputs for compliance; Quick check—validate existence of clear audit criteria and team roles.
- **Data Ethics Guidelines**: Why needed—to govern data use and model training ethically; Quick check—review guidelines for fairness, transparency, and consent.
- **Safety Simulation Pipelines**: Why needed—to proactively identify and mitigate risks; Quick check—test simulation scenarios cover edge cases and rare events.

## Architecture Onboarding
- **Component Map**: Dataset (12,000 items) -> LLM Models (Qwen, DeepSeek) -> Baseline Evaluation -> Fine-tuning -> Governance Framework
- **Critical Path**: Dataset creation → Model evaluation → Governance gap identification → Framework design
- **Design Tradeoffs**: Comprehensive dataset ensures coverage but may limit generalizability; governance framework is conceptual, lacking empirical validation.
- **Failure Signatures**: Modest accuracy gains after fine-tuning suggest inherent model limitations; lack of institutional protocols may allow ethical lapses.
- **First Experiments**:
  1. Replicate benchmarking with diverse, multi-jurisdictional datasets.
  2. Conduct controlled trial of governance framework in a healthcare institution.
  3. Perform bias and robustness audit of the evaluation dataset.

## Open Questions the Paper Calls Out
None provided.

## Limitations
- Representativeness and comprehensiveness of the 12,000-item dataset uncertain.
- Focus on Chinese models and governance contexts limits generalizability.
- Modest accuracy improvements (42.7% to 50.8%) may not translate to meaningful harm reduction.
- Proposed governance framework is conceptual, lacking empirical validation.
- No assessment of biases in the evaluation dataset or fine-tuning transparency.

## Confidence
- **High confidence** in the identification of governance gaps and the need for institutional oversight mechanisms.
- **Medium confidence** in the empirical benchmarking results and the feasibility of the proposed governance framework.
- **Low confidence** in the generalizability of findings beyond the Chinese context and the real-world impact of the suggested improvements.

## Next Checks
1. Replicate the benchmarking study using a diverse, multi-jurisdictional dataset to assess generalizability.
2. Conduct a controlled trial of the proposed governance framework in a healthcare institution to measure practical impact on LLM safety and ethics.
3. Perform a bias and robustness audit of the 12,000-item evaluation dataset to ensure fair and comprehensive coverage of ethical and safety dimensions.