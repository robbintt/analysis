---
ver: rpa2
title: 'The Tonogenesis Continuum in Tibetan: A Computational Investigation'
arxiv_id: '2510.22485'
source_url: https://arxiv.org/abs/2510.22485
tags:
- pitch
- tibetan
- tone
- tonal
- languages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates how Tibetan dialects at different stages
  of tonogenesis rely on pitch for lexical contrast by systematically removing pitch
  contours from speech and measuring the resulting degradation in automatic speech
  recognition (ASR) performance. Using fine-tuned XLS-R models on six Tibetan varieties,
  the authors compare word and character error rates with and without pitch information.
---

# The Tonogenesis Continuum in Tibetan: A Computational Investigation

## Quick Facts
- arXiv ID: 2510.22485
- Source URL: https://arxiv.org/abs/2510.22485
- Reference count: 13
- Primary result: Tibetan dialects show gradient reliance on pitch for lexical contrast, with tonal Ü-Tsang varieties most affected by pitch removal and atonal Amdo varieties least affected.

## Executive Summary
This study investigates how Tibetan dialects at different stages of tonogenesis rely on pitch for lexical contrast by systematically removing pitch contours from speech and measuring the resulting degradation in automatic speech recognition (ASR) performance. Using fine-tuned XLS-R models on six Tibetan varieties, the authors compare word and character error rates with and without pitch information. Fully tonal Ü-Tsang dialects (Lhasa, Shigatse) show large error increases when pitch is removed (up to +0.139 CER for Shigatse), indicating heavy reliance on tone for word distinction. Intermediate Kham dialects show moderate degradation, while atonal Amdo varieties are minimally affected. These results reveal a continuum of pitch dependence that reflects historical tonogenesis and demonstrate that computational methods can capture nuanced stages of sound change beyond traditional text-based functional load measures.

## Method Summary
The study uses fine-tuned XLS-R models on six Tibetan varieties, comparing character and word error rates between original and pitch-flattened audio. Pitch flattening is performed using Praat's PSOLA algorithm, which replaces natural f0 contours with mean pitch while preserving spectral envelope and temporal structure. Tibetan script transcriptions are converted to Wylie transliteration and segmented into character-level vocabularies. The methodology measures ASR degradation as a proxy for functional load of pitch across dialects at different tonogenesis stages.

## Key Results
- Amdo dialects show minimal degradation when pitch is removed (ΔCER 0.020-0.025), indicating low reliance on tone
- Kham dialects show moderate degradation (ΔCER 0.017-0.056), reflecting transitional status
- Ü-Tsang dialects show severe degradation (ΔCER 0.060-0.139), demonstrating high tone dependence
- Lhasa achieves highest baseline accuracy (WER 0.087) while Dege shows lowest (WER 0.475)
- Shigatse shows the largest pitch effect (ΔCER 0.139), highlighting full tonal contrast

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Pitch-flattening provides a computational proxy for functional load of tone by measuring ASR degradation when f0 is systematically removed.
- **Mechanism:** The PSOLA algorithm replaces natural f0 contours with mean pitch, preserving spectral envelope and temporal structure while eliminating tonal cues. ASR models that learned to depend on pitch for lexical disambiguation will show increased error rates proportional to that dependence.
- **Core assumption:** ASR models learn to weight acoustic features according to their information-theoretic value for word identification; removing a critical feature causes commensurate confusion.
- **Evidence anchors:**
  - [abstract] "measuring how pitch manipulation affects automatic speech recognition (ASR) performance"
  - [section 3.2] "Pitch flattening was performed using Praat's Pitch-Synchronous OverLap and Add (PSOLA) algorithm"
  - [corpus] Related work (Liang and Levow, 2025) establishes this methodology cross-linguistically, though direct corpus support for Tibetan-specific application is limited.
- **Break condition:** If segmental cues alone fully predict lexical identity, flattening should cause minimal degradation regardless of tonal status.

### Mechanism 2
- **Claim:** The gradient pattern of ASR degradation across Tibetan varieties reflects their position along the tonogenesis continuum—from consonant-based to pitch-based lexical systems.
- **Mechanism:** As languages undergo tonogenesis, consonantal contrasts (voicing, aspiration) weaken while f0 perturbations become phonologized. ASR models trained on these varieties implicitly learn the current weighting of segmental vs. suprasegmental cues.
- **Core assumption:** The ASR model's learned feature weights approximate the actual functional importance of pitch in the language's current phonological system.
- **Evidence anchors:**
  - [abstract] "atonal Amdo dialects tolerate pitch removal the most, while fully tonal Ü-Tsang varieties show severe degradation, and intermediate Kham dialects fall measurably between"
  - [section 4, Table 2] Quantitative deltas: Amdo (ΔCER 0.020-0.025), Kham (ΔCER 0.017-0.056), Ü-Tsang (ΔCER 0.060-0.139)
  - [corpus] Weak direct evidence; no corpus papers directly validate the continuum hypothesis computationally.
- **Break condition:** If all varieties showed similar degradation patterns, the continuum hypothesis would not be supported.

### Mechanism 3
- **Claim:** Traditional functional load metrics based on minimal pair counts overestimate pitch dependence in transitional systems because they fail to account for residual segmental cues that co-vary with tone.
- **Mechanism:** In languages undergoing tonogenesis, pitch often correlates with residual voicing, breathiness, or phonation cues. Minimal pair counts treat tone as independent, but acoustic reality involves cue redundancy. ASR captures this holistically.
- **Core assumption:** ASR models learn the full acoustic signal, including covarying features that minimal pair analysis treats as separate.
- **Evidence anchors:**
  - [abstract] "traditional functional load metrics, based solely on minimal pairs, may overestimate pitch dependence in transitional systems where segmental and suprasegmental cues remain phonetically intertwined"
  - [section 2.4] "pitch may be correlated with, or redundant to, residual voicing or breathiness cues"
  - [corpus] No direct corpus validation; this remains a methodological hypothesis requiring further testing.
- **Break condition:** If controlled experiments showed minimal pair counts predicted ASR degradation accurately, the claim about overestimation would weaken.

## Foundational Learning

- **Concept: Tonogenesis**
  - **Why needed here:** The entire study frames Tibetan varieties along a historical sound change trajectory; understanding that tone emerges from consonantal contrasts (voicing → f0 perturbation → phonologized tone) is prerequisite.
  - **Quick check question:** Can you explain why a language might develop tone after losing voicing contrasts in onset consonants?

- **Concept: Functional Load**
  - **Why needed here:** The paper's central contribution is a computational method for measuring functional load; understanding this as "how crucial a contrast is for distinguishing words" grounds the methodology.
  - **Quick check question:** If removing a phonemic contrast causes many word confusions, does it have high or low functional load?

- **Concept: CTC Loss in ASR**
  - **Why needed here:** The XLS-R models use Connectionist Temporal Classification; understanding that this handles alignment-free training helps interpret why models learn implicit cue weighting without explicit phoneme boundaries.
  - **Quick check question:** Why does CTC training require a blank token?

## Architecture Onboarding

- **Component map:**
  - 16kHz audio → Wav2Vec2/XLS-R feature encoder → transformer layers → CTC head
  - Pitch manipulation: Praat PSOLA preprocessing (applied to test audio only)
  - Output: Character-level predictions mapped to Wylie transliterations

- **Critical path:**
  1. Data preparation: Tibetan script → Wylie transliteration → character vocabulary
  2. Model fine-tuning: XLS-R 300M pretrained weights, CTC loss, AdamW optimizer (lr=3e-4)
  3. Evaluation: Original audio vs. pitch-flattened audio → CER/WER comparison

- **Design tradeoffs:**
  - Character-level (not phoneme-level) output: Preserves orthographic fidelity but conflates historical spellings with modern pronunciations
  - Per-dialect models vs. unified model: Chosen approach allows isolation of each variety's pitch dependence but requires more training compute
  - PSOLA vs. other flattening methods: PSOLA preserves spectral envelope well but may introduce artifacts that affect ASR independently of tone removal

- **Failure signatures:**
  - High baseline error rates (>40% CER) may indicate insufficient training data or vocabulary issues, making delta comparisons noisy (cf. Dege at 47.5% baseline)
  - Speaker overlap between train/test (acknowledged limitation) may artificially lower error rates and mask true pitch dependence
  - Inconsistent transcription conventions across varieties complicate cross-dialect comparison

- **First 3 experiments:**
  1. Replicate on a single variety (e.g., Lhasa) with held-out speakers to establish baseline without speaker leakage
  2. Test whether adding explicit pitch features (f0 contour as auxiliary input) improves performance for Ü-Tsang varieties specifically
  3. Perform error analysis on confusion patterns—are specific segment types or syllable structures more vulnerable to pitch removal in Kham dialects?

## Open Questions the Paper Calls Out
- How do specific segment types or syllable structures correlate with ASR error patterns under pitch-flattening in transitional dialects?
- To what extent do non-pitch acoustic cues like breathiness or phonation compensate for pitch removal in emergent tone systems?
- Do the observed gradients of pitch dependence generalize to completely unseen speakers within these dialect groups?

## Limitations
- Modest corpus size per dialect (~2 hours) may not capture full phonological diversity
- Acknowledged speaker overlap between training and test sets creates artificial performance ceiling
- PSOLA pitch flattening may introduce artifacts affecting ASR performance independently of tone removal

## Confidence
- **High confidence** in the core finding that pitch-flattening methodology reveals differential reliance on tone across Tibetan varieties
- **Medium confidence** in the claim that traditional minimal pair counts overestimate pitch dependence in transitional systems
- **Medium confidence** in the interpretation that the gradient pattern reflects historical tonogenesis stages

## Next Checks
1. **Speaker-independent validation**: Re-run the analysis with strict speaker disjoint train/test splits to confirm that observed pitch effects aren't artifacts of speaker overlap, and to establish upper bounds on pitch dependence.
2. **Cross-method comparison**: Apply the pitch-flattening methodology to a language with well-documented tonogenesis (e.g., Vietnamese historical stages) where traditional functional load measures are established, to validate whether ASR-based measures capture similar patterns.
3. **Feature attribution analysis**: Use integrated gradients or similar techniques to identify which acoustic features XLS-R models actually rely on for each variety, providing direct evidence for whether pitch removal specifically causes the observed errors rather than general acoustic degradation.