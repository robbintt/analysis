---
ver: rpa2
title: 'COMPASS: Robust Feature Conformal Prediction for Medical Segmentation Metrics'
arxiv_id: '2509.22240'
source_url: https://arxiv.org/abs/2509.22240
tags:
- compass
- segmentation
- prediction
- coverage
- calibration
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces COMPASS, a framework for generating efficient,
  metric-based conformal prediction intervals for medical image segmentation tasks.
  The core method performs calibration directly in the model's representation space
  by perturbing intermediate features along low-dimensional subspaces maximally sensitive
  to the target metric.
---

# COMPASS: Robust Feature Conformal Prediction for Medical Segmentation Metrics

## Quick Facts
- arXiv ID: 2509.22240
- Source URL: https://arxiv.org/abs/2509.22240
- Reference count: 40
- Primary result: COMPASS generates efficient, metric-based conformal prediction intervals for medical image segmentation by perturbing model features along metric-sensitive subspaces.

## Executive Summary
This paper introduces COMPASS, a framework for generating efficient, metric-based conformal prediction intervals for medical image segmentation tasks. The core method performs calibration directly in the model's representation space by perturbing intermediate features along low-dimensional subspaces maximally sensitive to the target metric. The authors prove that COMPASS achieves valid marginal coverage under exchangeability and nestedness assumptions. Empirically, they demonstrate that COMPASS produces significantly tighter intervals than traditional conformal prediction baselines on four medical image segmentation tasks for area estimation.

## Method Summary
COMPASS performs calibration directly in the model's representation space by perturbing intermediate features along low-dimensional subspaces maximally sensitive to the target metric. The method uses a pre-trained segmentation model (U-Net), computes Jacobians of the metric with respect to latent features, applies PCA to find sensitive directions, and uses these directions for conformal calibration. For each calibration sample, COMPASS finds the minimal perturbation magnitude needed to cover the ground-truth metric value, then uses the quantile of these scores as the threshold for test-time coverage.

## Key Results
- COMPASS produces significantly tighter intervals than traditional CP baselines on four medical image segmentation tasks
- The method achieves valid marginal coverage under exchangeability and nestedness assumptions
- Leveraging learned internal features to estimate importance weights allows COMPASS to recover target coverage under covariate shifts

## Why This Works (Mechanism)

### Mechanism 1
Direct feature-space perturbation produces tighter prediction intervals than output-space calibration. COMPASS perturbs latent representations along low-dimensional, metric-sensitive subspaces. This exploits the model's internal structure, capturing the non-linear relationship between features and the target metric more efficiently than treating the pipeline as a black box. A compressive power-law relationship between latent-space perturbation magnitudes and output-space errors leads to a compression of the score distribution's tail, resulting in smaller quantiles and tighter intervals. Core assumption: Nestedness; the prediction set must monotonically expand with the perturbation magnitude.

### Mechanism 2
Valid marginal coverage is achieved by framing metric-sensitive perturbations as a form of conformal risk control. Under the assumption that calibration and test data are exchangeable, the non-conformity score is defined as the minimal perturbation magnitude required to include the ground-truth metric value within a prediction interval. The calibrated quantile of these scores, computed over the calibration set, is guaranteed to provide the target coverage level on new test points. Core assumption: Exchangeability of data points.

### Mechanism 3
Coverage guarantees can be restored under covariate shift by re-weighting calibration samples. COMPASS employs Weighted Conformal Prediction (WCP), which uses importance weights (estimated density ratios between test and calibration distributions) to adjust the empirical score distribution. This effectively gives more influence to calibration samples that are more representative of the test distribution, recovering the target coverage. Weights can be estimated using model features, Jacobians, or class labels. Core assumption: The covariate shift is moderate, and the calibration and test distributions have significant overlap in the feature space.

## Foundational Learning

- **Conformal Prediction (CP)**: A framework for creating prediction intervals with statistical guarantees of coverage. Why needed: COMPASS is built on this framework. You must understand the core idea of using non-conformity scores and a calibration set to create prediction intervals with statistical guarantees of coverage. Quick check: If you have 100 calibration points and want 90% coverage, which score do you select as your threshold?

- **Split Conformal Prediction**: A specific CP variant that splits data into training and calibration sets. Why needed: The paper uses this specific CP variant. It's critical to understand the data splitting into training and calibration sets, which is a prerequisite for Theorem 1. Quick check: Explain the trade-off introduced by setting aside a portion of your data exclusively for calibration.

- **Covariate Shift**: A type of distribution shift where the input distribution P(X) changes while P(Y|X) remains the same. Why needed: This is the specific type of distribution shift COMPASS's weighted variant is designed to handle. Understanding this concept is essential for interpreting the weighted variant's effectiveness. Quick check: In a medical imaging context, give an example of a covariate shift between training data from one hospital and test data from another.

## Architecture Onboarding

- **Component map**: Trained Segmentation Model (U-Net encoder f and decoder g) -> Sensitive Subspace Learner (computes Jacobians, applies PCA) -> Sample-Specific Direction Finder (projects Jacobian onto V_L) -> Binary Search Calibration (finds minimal β) -> Quantile Computer (calculates β_hat) -> Weight Estimator (optional, for covariate shift)

- **Critical path**: Training (standard segmentation model training) -> Subspace Learning (Jacobians computed, PCA performed to learn V_L) -> Calibration (compute perturbation direction Δ, find non-conformity score R via binary search, compute quantile β_hat) -> Inference (compute latent features z, perturbation direction Δ, construct prediction interval)

- **Design tradeoffs**:
  - COMPASS-L (logits) vs. COMPASS-J (internal features): Simpler/faster vs. more expressive but computationally intensive
  - Symmetric vs. Asymmetric Perturbation: Simpler but assumes equal sensitivity vs. more flexible for tighter intervals
  - Choice of L (PCA components): Smaller L is more efficient but may miss important directions vs. larger L captures more variance but risks noise
  - Binary Search Granularity: Fewer iterations is faster but less precise vs. more iterations yields better precision

- **Failure signatures**:
  - Invalid Coverage: Violations of exchangeability or nestedness
  - Wide Intervals: Poorly aligned features with target metric
  - Non-Monotonic Metric Response: Violation of nestedness assumption

- **First 3 experiments**:
  1. Reproduce the Core Result: Using a pre-trained U-Net on HAM10000, run the full COMPASS-J pipeline and compare average interval width and empirical coverage against SCP baseline
  2. Ablate the Subspace: Run experiment where sensitive subspace is defined by random directions instead of PCA-derived ones and compare interval widths
  3. Test for Covariate Shift Robustness: Artificially create covariate shift by oversampling a class and measure coverage drop, then apply Jacobian weighting and measure recovery

## Open Questions the Paper Calls Out

- **Question**: How can COMPASS be adapted to ensure valid coverage when the pre-trained model's intermediate features lack a monotonic relationship with the target metric, potentially violating the nestedness assumption? Basis: The authors state in the Limitations section that if features are poorly aligned, the "resulting perturbation direction may be inefficient or non-monotonic, leading to wide or invalid intervals."

- **Question**: Can the weighted COMPASS framework be extended to maintain reliable uncertainty quantification under severe covariate shifts where calibration and test distributions have minimal feature overlap? Basis: The paper notes that Weighted CP is effective for moderate shifts but "for large shifts, the estimated weights may be inaccurate, which can compromise the validity of the final interval."

- **Question**: Does the efficiency of COMPASS transfer to complex, non-linear downstream metrics (e.g., texture features or shape indices) beyond the simple area estimation tested? Basis: While the Introduction mentions "radiomics" such as texture patterns, the experimental validation is restricted to "area estimation."

## Limitations
- COMPASS's validity relies on the exchangeability assumption, which is often violated in medical imaging due to site-specific artifacts and demographic shifts
- The nestedness assumption requires that metric sensitivity directions be semantically meaningful and monotonic, which may not hold for arbitrary pre-trained models
- The method's computational cost scales with the number of calibration samples and binary search iterations

## Confidence
- Coverage guarantees under stated assumptions: High
- Efficiency gains in real-world scenarios with complex distribution shifts: Medium

## Next Checks
1. Evaluate COMPASS under a realistic multi-site distribution shift where the covariate shift cannot be fully corrected by weighting, measuring both coverage degradation and interval inflation
2. Perform ablation studies varying L (PCA components) and latent layer selection to quantify their impact on interval tightness and validate the importance of learning meaningful sensitive subspaces
3. Test nestedness empirically by visualizing metric trajectories along learned perturbation directions and checking for monotonicity violations across diverse samples