---
ver: rpa2
title: 'Adapt, But Don''t Forget: Fine-Tuning and Contrastive Routing for Lane Detection
  under Distribution Shift'
arxiv_id: '2507.18653'
source_url: https://arxiv.org/abs/2507.18653
tags:
- lane
- detection
- distribution
- fine-tuning
- source
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of catastrophic forgetting in
  lane detection models when adapting to new datasets under distribution shift. The
  proposed method introduces a modular branching strategy that fine-tunes only target-specific
  components while keeping the source branch fixed, along with a supervised contrastive
  learning model for distribution-aware routing during inference.
---

# Adapt, But Don't Forget: Fine-Tuning and Contrastive Routing for Lane Detection under Distribution Shift

## Quick Facts
- arXiv ID: 2507.18653
- Source URL: https://arxiv.org/abs/2507.18653
- Reference count: 40
- Near-optimal F1-scores on multiple datasets while preventing catastrophic forgetting through modular branching and contrastive routing

## Executive Summary
This paper addresses catastrophic forgetting in lane detection models when adapting to new datasets under distribution shift. The proposed method introduces a modular branching strategy that fine-tunes only target-specific components while keeping the source branch fixed, along with a supervised contrastive learning model for distribution-aware routing during inference. Experiments on three datasets (CULane, CurveLanes, AssistTaxi) with CLRerNet and ERFNet backbones show that the approach achieves near-optimal F1-scores (e.g., 94.5 on AssistTaxi, 80.0 on CurveLanes) while using significantly fewer parameters than training separate models, and completely avoids source forgetting.

## Method Summary
The method trains a base lane detection model on a source distribution, then creates distribution-specific branches by cloning and fine-tuning selected network components (bias-only, head-only, neck+head, or backbone+neck+head). The original source branch remains completely frozen. A supervised contrastive learning (SCL) router classifies inputs to determine which branch to use during inference. Training proceeds in three phases: 15 epochs for source model, 3 epochs for fine-tuning target branches, and SCL router training on all distributions. The routing strategy adapts to shift severity—moderate shifts use N+H fine-tuning, while extreme shifts require backbone adaptation (B(k)+N+H).

## Key Results
- Near-perfect contrastive routing accuracy (99.6-99.9%) with minimal 3.2% inference overhead
- Zero source forgetting demonstrated by consistent F1 scores (79.1) across all routing configurations
- Strong target performance with parameter efficiency: N+H fine-tuning uses only 5.1% of total parameters while achieving 77.8 F1 on CurveLanes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Modular branching with frozen source components prevents catastrophic forgetting by isolating parameter updates to distribution-specific branches.
- Mechanism: The source branch remains completely frozen after initial training. For each target distribution, only selected components (H, N+H, or B(k)+N+H) are cloned and fine-tuned. During inference, the contrastive router directs inputs to the appropriate branch, ensuring source parameters never receive gradient updates that could overwrite learned representations.
- Core assumption: Distribution-specific knowledge is localized to particular network modules rather than distributed uniformly across all parameters.
- Evidence anchors:
  - [abstract] "...fine-tuning only selected components while keeping the original source branch fixed."
  - [Table 3] Source F1 remains constant at 79.1 across all routing configurations when CULane is source, demonstrating zero forgetting.
  - [corpus] Related work on efficient fine-tuning (NoRA) suggests selective parameter adaptation is effective, though not specifically for forgetting prevention.
- Break condition: If source and target distributions require conflicting representations in shared frozen layers (e.g., early backbone features), performance may degrade on both. Severe distribution shifts like AssistTaxi→CULane show this—lighter branches (H, N+H) fail to adapt effectively.

### Mechanism 2
- Claim: Component-wise fine-tuning reveals a hierarchy of adaptation capacity versus retention stability across network modules.
- Mechanism: Bias-only updates (~1-2K params) adjust activation thresholds without altering features—sufficient for similar distributions (CULane→CurveLanes: +6.6 F1) but inadequate for severe shifts. Head-only (~430K params) reparameterizes anchor priors but operates on frozen features, causing misalignment. N+H (~600K params, 5.1% of total) recalibrates multi-scale feature fusion, achieving strong target performance (CurveLanes: 77.8, AssistTaxi: 82.8) with moderate source degradation. Partial backbone adaptation (B(k=3)+N+H) enables mid-level feature re-encoding critical for severe shifts (AssistTaxi: 93.5 F1).
- Core assumption: Different network layers encode different levels of distribution-specific priors—low-level textures in early layers, spatial semantics in deeper layers.
- Evidence anchors:
  - [Page 6] "With only ~600K parameters (5.1% of total), N+H achieves strong target performance... suggesting the frozen backbone retains transferable structure."
  - [Page 5-6, Table 1] Progressive adaptation gains and forgetting patterns across configurations validate the hierarchy.
  - [corpus] No direct corpus evidence for this specific component-wise analysis in lane detection.
- Break condition: Full fine-tuning (B+N+H) overwrites source knowledge despite achieving best target performance—source F1 drops to 68.7 (from 80.4) for ResNet-18 on CULane→CurveLanes.

### Mechanism 3
- Claim: Supervised contrastive learning creates distribution-separable embeddings enabling near-perfect routing accuracy with minimal inference overhead.
- Mechanism: A ResNet encoder extracts road-surface features, which are projected through an MLP head trained with SupCon loss. This pulls same-distribution samples together while pushing different-distribution samples apart. At inference, inputs are classified via nearest-centroid assignment and routed to the corresponding branch.
- Core assumption: Distribution-specific visual patterns (lane edge orientation, texture gradients, spatial arrangement) are extractable from road surface regions and separable in learned embedding space.
- Evidence anchors:
  - [Page 7] "The distribution classifier using supervised contrastive learning (SCL) model achieves near-perfect accuracy across all three datasets—99.6% on CULane, 99.7% on CurveLanes, and 99.9% on AssistTaxi."
  - [Page 7] "Contrastive routing adds only 0.31 ms, resulting in just 3.2% overhead."
  - [corpus] Cost-Aware Contrastive Routing for LLMs applies similar routing principles but in a different domain; LetheViT uses contrastive learning for unlearning, not routing.
- Break condition: If distributions are visually indistinguishable in the encoder's feature space (e.g., same road types with different annotation schemes), contrastive learning may fail to separate them. The paper does not test this scenario.

## Foundational Learning

- Concept: Catastrophic Forgetting
  - Why needed here: The entire framework is designed to prevent this phenomenon where adapting to new data overwrites previously learned representations.
  - Quick check question: Can you explain why fine-tuning all parameters on AssistTaxi after training on CULane causes CULane performance to collapse to near-zero?

- Concept: Supervised Contrastive Learning
  - Why needed here: The routing mechanism depends on understanding how contrastive losses structure embedding spaces for classification.
  - Quick check question: How does the SupCon loss differ from standard cross-entropy, and why might it produce better distribution separation?

- Concept: Anchor-Based Lane Detection
  - Why needed here: CLRerNet's architecture (anchor priors, iterative refinement, LaneIoU loss) determines which components are most sensitive to distribution shift.
  - Quick check question: Why would anchor priors learned on side-lane datasets (CULane) fail on center-lane datasets (AssistTaxi)?

## Architecture Onboarding

- Component map:
  - Backbone (B) -> Neck (N) -> Head (H) -> Output
  - SCL Router: Encoder -> MLP Projection -> Centroid Classifier

- Critical path:
  1. Train base model on source distribution (15 epochs).
  2. Analyze source→target shift severity (similar geometry vs. fundamentally different anchor assumptions).
  3. Select routing point: N+H for moderate shifts, B(k=2)+N+H for severe shifts.
  4. Clone selected modules, fine-tune on target (3 epochs, lr=6×10⁻⁴).
  5. Train SCL router on all distribution images.
  6. Deploy with inference-time routing.

- Design tradeoffs:
  - **Routing depth vs. parameter efficiency**: Routing@N+H uses 41% params vs. Routing@B+N+H at 100%, but fails on AssistTaxi→CULane (F1: 30.4 vs. 77.2).
  - **Adaptation capacity vs. forgetting**: Deeper fine-tuning improves target but risks source overwriting if not isolated via branching.
  - **Router accuracy vs. overhead**: SCL adds 3.2% latency; a simpler classifier might be faster but less accurate—paper does not compare alternatives.

- Failure signatures:
  - **Target F1 near zero with bias-only fine-tuning**: Distribution shift too severe for threshold adjustment (AssistTaxi→CULane).
  - **Source F1 collapse after head-only fine-tuning**: Frozen upstream features misaligned with new anchor priors, causing overfitting.
  - **Router misclassification**: If SCL accuracy drops, wrong branch receives input—paper reports 99.6-99.9% accuracy but does not analyze failure cases.

- First 3 experiments:
  1. **Reproduce component-wise analysis** (Table 1): Train CLRerNet on CULane, fine-tune each configuration on CurveLanes, plot source F1 vs. target F1 to verify the adaptation-retention tradeoff curve.
  2. **Test SCL router robustness**: Train router on subset of data (e.g., 10% of images), measure accuracy degradation to understand data requirements.
  3. **Pilot deployment on new distribution**: Add a fourth dataset (e.g., TuSimple) without retraining source branches—measure zero-shot performance, then fine-tune only N+H branch to validate modularity claims.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can student-teacher distillation or shared-feature decoders effectively consolidate knowledge across branches to reduce parameter overhead as the number of target distributions increases?
- Basis in paper: [explicit] Section 5 (Limitations) explicitly states that the framework requires maintaining separate branches, leading to "increased parameter overhead," and implores the community to explore distillation or shared decoders as future directions.
- Why unresolved: The current study proves the efficacy of branching but does not implement or test methods for merging these branches or sharing weights more aggressively to save memory.
- What evidence would resolve it: A study demonstrating a distillation method that retains the F1-scores of the branching approach while reducing the total parameter count to a level comparable to a single model.

### Open Question 2
- Question: Do the component-wise fine-tuning strategies (e.g., freezing backbone, fine-tuning Neck+Head) generalize to non-anchor-based architectures like segmentation-based or parametric lane detectors?
- Basis in paper: [explicit] Section 5 notes that while the method is demonstrated on CLRerNet, the authors encourage future work to "explore this generalization" to other architectures.
- Why unresolved: The paper analyzes anchor-based models where anchor priors are sensitive to distribution shifts; it is unverified if segmentation-based or parametric models exhibit the same adaptation-forgetting trade-offs in the same network components.
- What evidence would resolve it: Experimental results applying the modular branching strategy to architectures like CondLaneNet (row-wise) or LaneATT (anchor-based with different mechanisms) showing similar retention and adaptation metrics.

### Open Question 3
- Question: How robust is the supervised contrastive routing mechanism when encountering out-of-distribution inputs or ambiguous scenes that do not clearly belong to a specific training centroid?
- Basis in paper: [inferred] The paper reports high routing accuracy (99.6%+) on known test sets (Section 4.4) but does not analyze the system's behavior when the contrastive model encounters inputs that deviate significantly from the source or target distributions.
- Why unresolved: The routing relies on centroid-based classification which assumes the input belongs to one of the defined distributions; a failure mode analysis for OOD data is missing.
- What evidence would resolve it: An evaluation of the routing model's confidence scores and detection performance on synthetic OOD data or mixed-domain datasets to determine if a "rejection" or "fallback" option is needed.

## Limitations

- The method requires maintaining separate branches for each target distribution, leading to increased parameter overhead.
- The effectiveness for extreme distribution shifts (like AssistTaxi→CULane) requires deeper fine-tuning, which partially undermines the parameter efficiency claim.
- The contrastive routing mechanism assumes distributions are visually separable in road surface features, but does not test scenarios where distributions are visually similar but differ in annotation schemes.

## Confidence

- **High Confidence**: The catastrophic forgetting prevention mechanism (completely frozen source branch with isolated fine-tuning) is well-validated by consistent source F1 scores across experiments. The contrastive routing accuracy (99.6-99.9%) is empirically demonstrated.
- **Medium Confidence**: The component-wise adaptation hierarchy (bias-only → head-only → N+H → B(k)+N+H) is supported by extensive experiments, but the generalizability to other architectures and tasks requires validation.
- **Low Confidence**: The claim that different network layers encode different levels of distribution-specific priors is inferred from the experiments but lacks direct mechanistic validation or theoretical grounding.

## Next Checks

1. **Test contrastive routing on visually similar distributions**: Create a controlled experiment where two datasets have identical road scenes but different annotation schemes (e.g., centerline vs. edge detection), and evaluate whether the SCL router can still achieve high accuracy.

2. **Validate generalization to other backbones**: Apply the same modular branching and contrastive routing framework to ERFNet and DLA architectures, and compare whether the N+H vs. B(k)+N+H routing decisions remain optimal or if different components become more critical.

3. **Analyze failure cases of contrastive routing**: Systematically collect misclassified samples from the SCL router, visualize their embeddings, and identify patterns in what causes distribution separation to fail (e.g., lighting conditions, weather, annotation style).