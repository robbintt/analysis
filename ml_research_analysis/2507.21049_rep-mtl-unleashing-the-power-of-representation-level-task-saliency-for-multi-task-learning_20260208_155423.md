---
ver: rpa2
title: 'Rep-MTL: Unleashing the Power of Representation-level Task Saliency for Multi-Task
  Learning'
arxiv_id: '2507.21049'
source_url: https://arxiv.org/abs/2507.21049
tags:
- learning
- rep-mtl
- task
- task-specific
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'Rep-MTL introduces a representation-centric approach to multi-task
  learning that leverages task saliency in the shared representation space. Instead
  of relying solely on optimizer-centric strategies like loss scaling or gradient
  manipulation, Rep-MTL employs two complementary modules: Task-specific Saliency
  Regulation (TSR) that preserves task-specific patterns through entropy-based regularization,
  and Cross-task Saliency Alignment (CSA) that promotes information sharing via contrastive
  learning.'
---

# Rep-MTL: Unleashing the Power of Representation-level Task Saliency for Multi-Task Learning

## Quick Facts
- arXiv ID: 2507.21049
- Source URL: https://arxiv.org/abs/2507.21049
- Authors: Zedong Wang, Siyuan Li, Dan Xu
- Reference count: 40
- Primary result: Task-level improvements of +3.48 on NYUv2 and +2.67 on Cityscapes using representation-level task saliency regulation and alignment

## Executive Summary
Rep-MTL introduces a representation-centric approach to multi-task learning that leverages task saliency in the shared representation space. Instead of relying solely on optimizer-centric strategies like loss scaling or gradient manipulation, Rep-MTL employs two complementary modules: Task-specific Saliency Regulation (TSR) that preserves task-specific patterns through entropy-based regularization, and Cross-task Saliency Alignment (CSA) that promotes information sharing via contrastive learning. This approach addresses negative transfer while explicitly facilitating positive complementarity between tasks. Experiments on four challenging benchmarks (NYUv2, Cityscapes, Office-31, Office-Home) demonstrate that Rep-MTL consistently achieves competitive performance gains even with basic equal weighting.

## Method Summary
Rep-MTL computes task saliency as gradients with respect to the shared representation Z (not parameters), quantifying how sensitively each task responds to representation changes. TSR applies entropy-based regularization on spatial saliency distributions to preserve task-specific learning patterns and mitigate negative transfer. CSA computes channel interaction affinity maps and applies contrastive learning to align sample-wise saliency patterns across tasks, promoting complementary information sharing. The framework combines these with standard task losses: LRep = ΣLt + λtsr·Ltsr + λcsa·Lcsa, where λtsr and λcsa ∈ [0.7, 1.5] are regularization strengths.

## Key Results
- Achieves consistent task-level improvements across multiple benchmarks: +3.48 on NYUv2, +2.67 on Cityscapes
- Maintains competitive average performance even with equal weighting (EW), surpassing specialized optimizers like Nash-MTL
- Power Law exponent analysis confirms effective balance between task-specific learning and cross-task sharing, with backbone α values indicating well-trained models

## Why This Works (Mechanism)

### Mechanism 1: Task-specific Saliency Regulation (TSR)
- **Claim:** Entropy-based regularization on spatial saliency distributions preserves task-specific learning patterns, mitigating negative transfer.
- **Mechanism:** For each task, compute channel-averaged saliency maps Ŝt = mean_c(St) capturing spatial importance. Normalize into task-wise probability distributions Pi,t, then apply entropy penalty L_tsr = -Σ Pi,t log Pi,t. Low entropy indicates task-salient regions; penalizing high entropy prevents excessive feature sharing that causes negative transfer.
- **Core assumption:** Tasks benefit from maintaining distinctive spatial activation patterns rather than collapsing to shared representations.

### Mechanism 2: Cross-task Saliency Alignment (CSA)
- **Claim:** Contrastive alignment of sample-wise saliency affinity maps explicitly excavates inter-task complementarity.
- **Mechanism:** Compute affinity maps Mt = St St^T capturing channel interaction patterns per task. For each sample b, derive anchors Âb from spatially-pooled saliency. Apply contrastive loss L_csa where (anchor, same-sample task affinity) = positive pairs, (anchor, different-sample anchors) = negatives. This pulls task-specific patterns toward sample-consistent representations while pushing apart irrelevant samples.
- **Core assumption:** Similar intra-sample saliency patterns across tasks indicate transferable, task-generic information.

### Mechanism 3: Representation-level Task Saliency as Optimization Signal
- **Claim:** Gradients w.r.t. shared representation Z provide richer diagnostic signals than parameter gradients for modulating task interactions.
- **Mechanism:** Instead of manipulating ∇θ L directly (optimizer-centric), compute St = ∇Z Lt ∈ R^{B×C×H×W}. This quantifies how sensitively each task responds to representation changes at each spatial location and channel. These saliencies serve as "dynamic indicators of representation-level task dependencies" for downstream regularization.
- **Core assumption:** Representation space is where task interactions naturally manifest; modulating there is more direct than indirect parameter updates.

## Foundational Learning

- **Concept: Multi-Task Optimization (MTO) paradigms**
  - **Why needed here:** Rep-MTL positions itself against loss scaling (e.g., UW, GLS) and gradient manipulation (e.g., PCGrad, MGDA). Understanding these baselines is essential to appreciate why representation-level operations are proposed as complementary.
  - **Quick check question:** Can you explain why PCGrad projects conflicting gradients and how this differs from Rep-MTL's entropy-based approach?

- **Concept: Contrastive learning fundamentals (positive/negative pairs, temperature τ)**
  - **Why needed here:** CSA module uses InfoNCE-style contrastive loss. Understanding why same-sample task affinities are positives vs. different-sample anchors as negatives is critical for debugging alignment failures.
  - **Quick check question:** In CSA, why are (za_b, zt_b) positive pairs? What would happen if we used task affinities from different samples as positives?

- **Concept: Power Law exponent analysis (HT-SR theory)**
  - **Why needed here:** The paper uses PL exponent α to validate training quality without test data. Values in [2, 4] indicate well-trained models; values outside suggest over/under-training. This is the paper's primary diagnostic tool for ablation.
  - **Quick check question:** If backbone α = 5.2 but task heads have balanced α ≈ 2.5, what does this suggest about cross-task sharing vs. task-specific learning?

## Architecture Onboarding

- **Component map:**
  Input X → Shared Encoder E_θs → Representation Z ∈ R^{C×H×W}
                                       ↓
                         ┌─────────────┼─────────────┐
                         ↓             ↓             ↓
                    Task Head 1   Task Head 2   Task Head T
                         ↓             ↓             ↓
                    Loss L_1       Loss L_2       Loss L_T
                         ↓             ↓             ↓
              Saliency S_1=∇Z L_1  S_2=∇Z L_2   S_T=∇Z L_T
                         └─────────────┼─────────────┘
                                       ↓
                          TSR: Entropy on spatial Ŝt
                          CSA: Contrastive on affinities Mt
                                       ↓
                              L_Rep = ΣL_t + λ_tsr·L_tsr + λ_csa·L_csa

- **Critical path:**
  1. Forward pass through encoder + task heads → compute task losses
  2. **Stop-gradient on Z** → compute ∇Z L_t for each task (requires backward through task heads only, not full encoder)
  3. From saliencies {S_t}: (a) aggregate spatial → entropy penalty; (b) compute affinities → contrastive alignment
  4. Combine L_Rep and backprop through encoder with implicit saliency-influenced gradients

- **Design tradeoffs:**
  - **Efficiency:** Requires computing T saliency maps per batch (backward through T task heads but not full network). Paper reports ~26% faster than Nash-MTL but slower than pure loss scaling.
  - **Regularization strength:** λ_tsr, λ_csa ∈ [0.7, 1.5] recommended. Too high → over-regularize, suppress sharing; too low → negligible effect.
  - **Assumption:** Requires hard parameter sharing architecture; adaptability to soft-sharing or architecture-search methods is unexplored.

- **Failure signatures:**
  - **TSR failure:** Task heads show imbalanced PL exponents (e.g., one at 2.3, another at 5.1) → entropy not creating distinctiveness; check if Pi,t distributions are collapsing to uniform.
  - **CSA failure:** Backbone α ≫ 4 (over-training) or < 2 (under-training) → alignment not promoting useful sharing; inspect affinity map similarity across tasks.
  - **Negative transfer persists:** Δp_task still negative → possible λ misconfiguration or fundamentally conflicting tasks requiring architecture changes.

- **First 3 experiments:**
  1. **Baseline sanity check:** Run EW baseline on NYUv2 with DeepLabV3+. Confirm negative Δp_task (-1.78 reported). Then enable TSR-only → should see positive Δp_task (+0.23 per Table 4).
  2. **Ablation by component:** With fixed λ_tsr=λ_csa=0.9, compare: (a) TSR-only, (b) CSA-only, (c) full Rep-MTL. Log PL exponents for backbone and each task head. Expect CSA → lower backbone α; TSR → balanced head α values.
  3. **Hyperparameter sweep:** Fix one λ at 0.9, sweep the other in {0.1, 0.5, 0.9, 1.3, 1.7}. Plot Δp_task curve. Confirm stability band [0.7, 1.5] as reported. If curve is sharply peaked → implementation may differ from paper.

## Open Questions the Paper Calls Out

- **Can the Rep-MTL framework be refined to achieve state-of-the-art performance on every individual sub-task, rather than prioritizing balanced average performance?**
  - **Basis in paper:** [Explicit] Appendix B notes that while Rep-MTL achieves the best average results, "it may not consistently achieve significant gains across all sub-tasks simultaneously," specifically suggesting future work should push "the boundaries of task-specific excellence."
  - **Why unresolved:** The current CSA and TSR modules are designed for stability and general balance, which appears to limit peak performance on specific tasks (e.g., DSLR in Office-31) compared to methods that might aggressively optimize for a single objective.

- **How does Rep-MTL scale to multi-task settings with a significantly larger number of tasks (e.g., >10 tasks) compared to the 2–4 task benchmarks evaluated?**
  - **Basis in paper:** [Inferred] The paper evaluates NYUv2 (3 tasks), Cityscapes (2 tasks), and Office datasets (3-4 tasks). The sample-wise contrastive alignment (Eq. 9) and channel-wise affinity maps (Eq. 7) may face computational or optimization challenges as the task space T expands.
  - **Why unresolved:** The contrastive loss relies on negative pairs within a batch, and the entropy regularization assumes a certain distribution of saliency; these dynamics might change or saturate in high-task-density regimes.

- **Can the computational overhead of computing representation-level task saliencies be reduced to match the speed of simple loss scaling methods?**
  - **Basis in paper:** [Inferred] Appendix D.2 identifies the runtime cost as a "fundamental trade-off and room for further improvement," noting that Rep-MTL is slower than loss scaling methods because it requires computing gradients ∇Z Lt.
  - **Why unresolved:** The method currently requires backpropagation to the representation layer for every task to determine saliency, which is inherently more expensive than scalar loss weighting.

## Limitations
- Computational overhead remains higher than simple loss scaling methods due to gradient computation at representation level
- May not consistently achieve significant gains across all sub-tasks simultaneously, potentially sacrificing peak performance on specific tasks
- Limited evaluation on large-scale multi-task settings (>4 tasks), leaving scalability questions unanswered

## Confidence
- **High confidence** in TSR mechanism and entropy-based regularization approach (well-grounded in representation learning theory)
- **Medium confidence** in CSA contrastive alignment effectiveness (novel approach without direct comparative studies)
- **Medium confidence** in aggregate performance claims (Δptask reported but individual task gains not detailed)

## Next Checks
1. **Hyperparameter sensitivity analysis**: Systematically sweep λ_tsr and λ_csa values while monitoring PL exponents for backbone and task heads to identify optimal operating regions
2. **Task correlation dependency**: Evaluate Rep-MTL performance across tasks with varying degrees of correlation (from highly complementary to antagonistic) to identify break points
3. **Individual task fairness audit**: Report per-task performance changes alongside aggregate metrics to verify that TSR/CSA improvements aren't achieved at the expense of specific tasks