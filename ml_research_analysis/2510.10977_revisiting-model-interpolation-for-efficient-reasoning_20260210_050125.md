---
ver: rpa2
title: Revisiting Model Interpolation for Efficient Reasoning
arxiv_id: '2510.10977'
source_url: https://arxiv.org/abs/2510.10977
tags:
- arxiv
- reasoning
- thinking
- mean
- interpolation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper revisits direct model interpolation between Instruct\
  \ and Thinking models, revealing a three-stage evolutionary paradigm in performance\
  \ dynamics. Rather than evolving linearly, the model\u2019s reasoning capability,\
  \ token efficiency, and accuracy transition through distinct phases as the interpolation\
  \ coefficient \u03BB varies."
---

# Revisiting Model Interpolation for Efficient Reasoning

## Quick Facts
- **arXiv ID**: 2510.10977
- **Source URL**: https://arxiv.org/abs/2510.10977
- **Reference count**: 32
- **Primary result**: Three-stage interpolation dynamics discovered; λ≈0.8 outperforms sophisticated baselines on reasoning benchmarks.

## Executive Summary
This paper revisits direct model interpolation between Instruct and Thinking models, revealing a three-stage evolutionary paradigm in performance dynamics. Rather than evolving linearly, the model's reasoning capability, token efficiency, and accuracy transition through distinct phases as the interpolation coefficient λ varies. Empirical results on Qwen3 models show that a strategically interpolated model (e.g., λ=0.8) consistently outperforms sophisticated merging baselines like Task Arithmetic and TIES on benchmarks such as AIME'25, IFEval, and GPQA-Diamond.

## Method Summary
The paper investigates direct weight interpolation between Instruct and Thinking models, where merged weights are computed as Θ(Merge) = λΘ(Thi) + (1-λ)Θ(Ins). The study reveals a three-stage evolutionary paradigm: Stage #1 (λ∈[0,0.4)) with no explicit reasoning, Stage #2 (λ∈[0.4,0.6]) where Chain-of-Thought emerges abruptly, and Stage #3 (λ∈(0.6,1.0]) characterized by overthinking with rising token counts but diminishing returns. The approach is evaluated on Qwen3-4B models using benchmarks AIME'25, IFEval, and GPQA-Diamond with specific decoding parameters (T=0.6, Top-p=0.95).

## Key Results
- Three-stage interpolation dynamics discovered: Stage #1 (no reasoning), Stage #2 (CoT emergence), Stage #3 (overthinking)
- Merged model with λ=0.8 outperforms sophisticated baselines (Task Arithmetic, TIES) on multiple benchmarks
- Stage #2 shows abrupt CoT emergence rather than gradual development as λ increases
- Overthinking phenomenon observed in Stage #3 with monotonic token increase but diminishing accuracy gains

## Why This Works (Mechanism)
The three-stage evolutionary paradigm emerges from how reasoning capabilities distribute across the weight space. The abrupt transition in Stage #2 suggests that explicit reasoning emerges when the merged model crosses a representational threshold, activating latent reasoning pathways. The overthinking in Stage #3 occurs when additional Thinking model influence introduces redundant reasoning steps without corresponding performance gains.

## Foundational Learning
- **Model interpolation**: Combining weights from different models to create a new model
  - *Why needed*: To balance reasoning quality with efficiency by blending different capabilities
  - *Quick check*: Verify weighted sum formula and implementation
- **Chain-of-Thought reasoning**: Explicit reasoning steps shown in model outputs
  - *Why needed*: Critical for understanding when reasoning emerges in the interpolation process
  - *Quick check*: Look for `|thought|` token presence in outputs
- **Three-stage paradigm**: Non-linear evolution of model capabilities as λ varies
  - *Why needed*: Framework for understanding interpolation dynamics
  - *Quick check*: Plot performance metrics vs λ to identify stage boundaries
- **Task Arithmetic and TIES**: Sophisticated model merging baselines
  - *Why needed*: Context for comparing direct interpolation effectiveness
  - *Quick check*: Review baseline implementations and comparison methodology
- **IFEval, AIME'25, GPQA-Diamond**: Benchmark suites for evaluating reasoning
  - *Why needed*: Standard evaluation metrics for reasoning capability
  - *Quick check*: Confirm benchmark details and evaluation protocols

## Architecture Onboarding

**Component Map**: Qwen3-4B-Instruct + Qwen3-4B-Thinking -> Interpolation -> Merged Model -> Evaluation

**Critical Path**: Weight interpolation → Model generation → Benchmark evaluation → Performance analysis

**Design Tradeoffs**: Direct interpolation is simple but may miss sophisticated blending opportunities; all-layer interpolation is necessary for CoT emergence but computationally expensive

**Failure Signatures**: 
- No CoT emergence when using partial-layer interpolation
- Suboptimal performance if using Instruct decoding settings on merged models
- Computational cost scales linearly with λ sweep granularity

**First Experiments**:
1. Implement basic interpolation with λ=0.5 and verify output structure
2. Run λ-sweep from 0 to 1 with step size 0.1 to identify stage boundaries
3. Compare merged model performance against individual Instruct and Thinking models

## Open Questions the Paper Calls Out

**Open Question 1**: Does the three-stage evolutionary paradigm generalize to other model families beyond Qwen3, such as Llama or Mistral? [explicit] The paper notes this would strengthen findings but validation was centered on Qwen3 models only.

**Open Question 2**: Can the model interpolation framework be extended to simultaneously merge three or more specialist models while preserving predictable performance dynamics? [explicit] Current formulation only addresses pairwise interpolation between Instruct and Thinking models.

**Open Question 3**: Why does the optimal interpolation coefficient λ shift to higher values for larger models (e.g., λ∈[0.8,0.95] for 30B vs λ≈0.8 for 4B)? [inferred] The paper observes different optimal λ ranges across model scales but offers no theoretical explanation.

**Open Question 4**: What mechanistic or theoretical principles explain the abrupt phase transition in Stage #2 where Think Ratio jumps from ~0 to ~1? [inferred] The paper documents the three-stage paradigm but lacks theoretical grounding for why the transition is sharp rather than gradual.

## Limitations

- Exact 0-shot prompt templates for benchmarks are unspecified, potentially affecting CoT emergence timing
- Computational cost of full λ sweeps may hinder replication at scale
- Partial-layer interpolation results are mentioned but not experimentally validated
- Baseline merging methods (Task Arithmetic, TIES) are described briefly without shared implementations

## Confidence

- Three-stage interpolation dynamics: High
- Superiority over Task Arithmetic and TIES on Qwen3-4B: High
- Generalization of λ≈0.8 as broadly optimal: Medium
- Overthinking in Stage #3 is universal: Medium

## Next Checks

1. Replicate the λ-sweep on Qwen3-4B using the same decoding settings and prompt templates to confirm the three-stage pattern and optimal λ.
2. Apply the same interpolation pipeline to a different model family (e.g., Llama-3.1 or Mistral) to test the generalizability of the λ≈0.8 heuristic.
3. Implement and benchmark Task Arithmetic and TIES using the authors' reported procedures to verify the claimed performance gaps.