---
ver: rpa2
title: 'OnSET: Ontology and Semantic Exploration Toolkit'
arxiv_id: '2504.08373'
source_url: https://arxiv.org/abs/2504.08373
tags:
- user
- graph
- knowledge
- ontology
- query
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces OnSET, a system enabling novice users to explore
  knowledge graphs without prior expertise in SPARQL or the ontology schema. It addresses
  the challenge of making knowledge graph retrieval accessible by combining topic
  modeling, semantic search, and visual interfaces.
---

# OnSET: Ontology and Semantic Exploration Toolkit

## Quick Facts
- arXiv ID: 2504.08373
- Source URL: https://arxiv.org/abs/2504.08373
- Reference count: 21
- Primary result: OnSET enables novice users to explore knowledge graphs via visual query building without SPARQL expertise

## Executive Summary
OnSET addresses the challenge of making knowledge graph exploration accessible to novice users by combining topic modeling, semantic search, and visual interfaces. The system uses BERTopic to provide hierarchical topic guidance, semantic embeddings for intuitive query building, and displays results as small multiples for immediate feedback. Two case studies demonstrate effectiveness with DBpedia and BrainTeaser Ontology, showing the approach significantly lowers barriers to entry while maintaining fast response times on commodity hardware.

## Method Summary
OnSET processes ontologies by treating each class as a document (combining class name, parent classes, and properties) and applying BERTopic for hierarchical topic modeling. Semantic embeddings are pre-computed for all links and classes using the stella_en_400M_v5 model and stored in PostgreSQL with pgvector extension. Users interact through a Vue.js frontend with a node-based visual query editor, where semantic search suggests relevant ontology links based on natural language queries. The system translates prototype graphs into SPARQL queries processed by QLever engine, returning sub-graph instances displayed as small multiples for comparison.

## Key Results
- Successfully demonstrated novice exploration of DBpedia and BrainTeaser Ontology without SPARQL expertise
- Achieved fast response times suitable for interactive exploration on commodity hardware
- Topic modeling provided effective initial guidance for users unfamiliar with ontology structure
- Semantic search enabled intuitive query building using natural language terms

## Why This Works (Mechanism)

### Mechanism 1: Topic Modeling as Initial User Guidance
Representing each ontology class as a document using templates for the class, parent classes, and associated properties enables BERTopic to group classes into hierarchical topics. These topics are labeled by an LLM and presented as a human-readable menu, guiding users toward relevant starting points without requiring schema knowledge.

### Mechanism 2: Semantic Search for Fuzzy Query Building
Pre-computed semantic vector embeddings for all ontology links enable users to expand and constrain query graphs using natural language terms. When users type queries like "sicknesses," the system embeds this term and performs similarity search against stored link embeddings, suggesting semantically similar links like "hasDisease."

### Mechanism 3: Immediate Result Feedback via Small Multiples
As users build prototype graphs, the system retrieves matching sub-graph instances and displays them as identically structured but distinct graphs. This gallery view allows users to quickly scan and compare results, creating a rapid feedback loop that helps refine queries and understand data patterns.

## Foundational Learning

- **Knowledge Graphs & Ontologies**: Data structured as entities (nodes), classes (types), and relationships (links). Why needed: OnSET is designed to explore these structures. Quick check: Can you explain the difference between an ontology (schema/definition) and a knowledge graph (actual data/instances)?

- **SPARQL & Basic Graph Patterns**: Visual query editor is a front-end for generating SPARQL queries. Why needed: User's prototype graph corresponds to a SPARQL BGP. Quick check: How would you write a SPARQL query to find all instances of a `Person` who `livesIn` a `City`?

- **Vector Embeddings & Semantic Search**: Text converted into high-dimensional vectors with similarity measured by distance. Why needed: Enables "fuzzy" search between natural language and formal ontology terms. Quick check: Why might a semantic search for "bank" return results for both a river bank and financial institution?

## Architecture Onboarding

- **Component map**: Frontend (Vue.js + D3.js/three.js) -> Backend Guidance Service (BERTopic) -> Semantic Search Store (PostgreSQL + pgvector) -> Query Engine (QLever)

- **Critical path**: User selects topic -> Frontend requests start links -> Backend queries Semantic Search Store -> User builds prototype graph -> Frontend sends graph to Backend -> Backend translates graph to SPARQL -> Backend sends query to QLever -> QLever returns sub-graph instances -> Frontend renders as small multiples

- **Design tradeoffs**: Pre-computation vs. real-time performance, tree-like vs. general graphs simplicity, visual simplicity vs. expressiveness for large result sets

- **Failure signatures**: Empty result sets from overly specific queries, incoherent topics from poor ontology labels, slow query times breaking interactive feedback

- **First 3 experiments**: 1) Run BERTopic on new ontology and manually inspect topic coherence, 2) Create test set of natural language queries and measure correct ontology link retrieval, 3) Measure time from graph modification to result display for interactivity validation

## Open Questions the Paper Calls Out

1. How can OnSET be extended to support complete, cyclic graphs rather than limiting users to tree-like structures? (Section 6 limitation on inability to specify complete graphs)

2. How can the interface visually represent the filtering strength of constraints to better guide users toward non-empty result sets? (Section 6 notes unclear visual definition of constraint filtering strength)

3. Does the topic-modeling approach effectively lower the barrier to entry for novice users compared to existing visual query builders? (Lack of formal comparative user study despite qualitative claims)

## Limitations

- Current restriction to tree-like prototype graphs limits expressiveness compared to full SPARQL capabilities
- Effectiveness depends on ontologies having sufficiently rich textual labels and properties for meaningful topics and embeddings
- No systematic user testing or quantitative metrics to validate usability claims beyond case studies

## Confidence

- **High confidence**: Technical architecture combining BERTopic, semantic embeddings, and SPARQL translation is clearly specified and technically sound
- **Medium confidence**: Usability claims supported by case studies but lack systematic user testing or quantitative metrics
- **Low confidence**: Claims about scalability and performance on very large ontologies not empirically validated beyond presented examples

## Next Checks

1. **Topic Quality Assessment**: Run BERTopic on a new, unfamiliar ontology and conduct blind evaluation with domain experts to rate topic coherence and relevance

2. **Semantic Search Precision Test**: Create controlled test set of natural language queries and measure accuracy of retrieved ontology links against ground truth

3. **End-to-End Latency Benchmark**: Measure system response times across varying ontology sizes and query complexities to establish performance boundaries