---
ver: rpa2
title: 'Learning to Land Anywhere: Transferable Generative Models for Aircraft Trajectories'
arxiv_id: '2511.04155'
source_url: https://arxiv.org/abs/2511.04155
tags:
- data
- trajectory
- generative
- split
- dublin
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores transfer learning to enable generative trajectory
  models in data-scarce aviation settings. The authors pretrain diffusion-based and
  flow-based models on Zurich landing data, then fine-tune on Dublin data with varying
  amounts from 0% to 100%.
---

# Learning to Land Anywhere: Transferable Generative Models for Aircraft Trajectories

## Quick Facts
- arXiv ID: 2511.04155
- Source URL: https://arxiv.org/abs/2511.04155
- Reference count: 31
- Primary result: Pretrained diffusion models achieve competitive trajectory generation performance with as little as 5% of local data.

## Executive Summary
This paper investigates transfer learning for generative trajectory models in air traffic management, addressing data scarcity at individual airports. The authors pretrain diffusion-based and flow-based models on Zurich landing data, then fine-tune on Dublin data with varying amounts from 0% to 100%. Diffusion models achieve strong performance with minimal local data—reaching baseline-level performance around 20%—while latent flow matching shows the largest relative gains despite starting from a weaker baseline. The findings demonstrate that pretraining can substantially reduce local data requirements for high-quality trajectory generation in ATM contexts.

## Method Summary
The paper explores transfer learning for generative trajectory models by pretraining on Zurich landing data and fine-tuning on Dublin data. Four architectures are tested: Diffusion Models (DM), Flow Matching (FM), Latent Diffusion (LDM), and Latent Flow Matching (LFM). Trajectories are represented in kinematic form (track, groundspeed, altitude, elapsed time) to ensure airport-agnostic generalization. The models are evaluated using energy distance, MMD, and DTW metrics, with N=100 condition-matched samples per experiment. Pretraining enables strong performance with as little as 5% of local target data, with DM showing the best sample efficiency.

## Key Results
- Diffusion models achieve competitive performance with only 5% of Dublin data, matching full-data baselines around 20%.
- Latent flow matching shows the largest relative gains despite starting from a weaker baseline.
- Quantitative metrics (energy distance, MMD, DTW) consistently improve with pretraining, and trajectory visualizations confirm realistic reproduction of dominant approach patterns.
- Pretraining enables substantial reduction in local data requirements for high-quality trajectory generation in ATM contexts.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pretraining on data-rich source airports enables efficient adaptation to data-scarce targets with minimal local data.
- Mechanism: Models learn generalizable trajectory dynamics from the source domain. Fine-tuning then adjusts the learned distribution to local terminal-area geometry and runway configurations. The pretrained weights provide a strong initialization that captures universal flight dynamics, reducing the data needed to learn airport-specific patterns.
- Core assumption: Aircraft landing trajectories share common kinematic and procedural structure across airports that transfer, even when spatial geometry differs.
- Evidence anchors:
  - [abstract] "Models are pretrained on Zurich and fine-tuned on Dublin with varying amounts of local data... diffusion-based models achieve competitive performance with as little as 5% target data and reach baseline-level performance around 20%."
  - [section V] "With only 5% of Dublin labels, the pretrained DM already surpasses the baseline on DTW (23.21 vs. 29.10)... At 20%, the DM essentially closes the e-distance gap."
- Break condition: If source and target airports have fundamentally different operational procedures or aircraft types/density, transfer gains may diminish significantly.

### Mechanism 2
- Claim: Airport-agnostic kinematic representation enables cross-airport transfer by preventing geographic overfitting.
- Mechanism: By encoding trajectories in relative kinematic terms rather than absolute latitude/longitude coordinates, the model learns motion dynamics invariant to geographic location. This prevents the model from memorizing Zurich-specific spatial patterns that would not transfer to Dublin.
- Core assumption: Kinematic features capture the essential transferable information; geographic coordinates introduce location-specific bias that hinders transfer.
- Evidence anchors:
  - [section IV.A] "To ensure airport-agnostic generalization and avoid geographic leakage, we train primarily in a kinematic representation—track, groundspeed, altitude, and elapsed time—rather than raw latitude–longitude."
  - [section V] "This representation is explicitly airport-agnostic: it encodes kinematics rather than absolute geography, requires no choice of map projection... and is invariant to rigid transforms."
- Break condition: If airports have significantly different approach procedures that manifest in altitude or speed profiles, kinematic transfer may be less effective.

### Mechanism 3
- Claim: Diffusion-based architectures exhibit stronger transfer learning properties than flow matching due to their denoising objective and noise schedule structure.
- Mechanism: Diffusion models learn to reverse a gradual corruption process, developing robust feature representations at multiple noise levels. This multi-scale learning may provide better initialization for fine-tuning. Flow matching, which learns continuous velocity fields directly, may have less favorable loss landscapes for transfer.
- Core assumption: The iterative denoising objective in diffusion models learns more transferable intermediate representations than the direct transport objective in flow matching.
- Evidence anchors:
  - [abstract] "Diffusion-based models... achieve strong performance with as little as 5% target data... Flow Matching shows weaker generalization."
  - [section V] "FM exhibits smaller and less consistent transfer gains than DM... At 50% split achieves a large DTW improvement (21.61), yet coincides with a spike in MMD, suggesting a sharper geometric fit along a subset of approach corridors at the expense of distributional coverage."
- Break condition: This is an empirical observation from one source-target pair. The mechanism is not theoretically proven—alternative explanations cannot be ruled out.

## Foundational Learning

- Concept: **Diffusion Probabilistic Models**
  - Why needed here: Core generative architecture showing strongest transfer results. Understanding the forward/reverse process, noise schedules, and UNet backbone is essential for adapting DiffTraj to aviation.
  - Quick check question: Can you explain how the denoising network is trained to reverse a Gaussian noise corruption process?

- Concept: **Transfer Learning Paradigm**
  - Why needed here: The paper's central contribution is demonstrating transfer from Zurich to Dublin. Understanding pretraining, fine-tuning, and domain shift is critical.
  - Quick check question: What is the difference between zero-shot transfer (0% target data) and fine-tuning with limited target data, and why might performance differ?

- Concept: **Temporal Convolutional Variational Autoencoder (TCVAE)**
  - Why needed here: Underlies LDM and LFM architectures. Compresses variable-length trajectories into latent representations for efficient generation.
  - Quick check question: How does a VAE's latent space enable generation, and why might operating in latent space improve sample efficiency?

## Architecture Onboarding

- Component map:
  Data Pipeline -> Kinematic Representation -> TCVAE Encoder -> Generative Core (DM/LDM or FM/LFM) -> TCVAE Decoder -> Evaluation Metrics

- Critical path:
  1. Preprocess trajectories to kinematic representation (track/groundspeed/altitude/Δt)
  2. Pretrain on source airport (Zurich) with full data
  3. Fine-tune on target airport (Dublin) with limited data fraction (5%, 20%, 50%, 100%)
  4. Generate N=100 condition-matched samples per experiment
  5. Compute e-distance, MMD, DTW against held-out test set

- Design tradeoffs:
  - **DM vs. FM**: DM shows better sample efficiency and transfer; FM may offer faster sampling but weaker transfer
  - **Raw vs. Latent**: Latent variants (LDM, LFM) reduce dimensionality and accelerate training but may lose fine-grained spatial detail; paper shows LDM gains are smaller than DM gains
  - **Kinematic vs. Geographic**: Kinematic enables transfer but requires reconstruction for evaluation; geographic would be airport-specific
  - **Runway conditioning**: Source has runway labels, target doesn't—using airport token only reduces specificity but maintains comparability

- Failure signatures:
  - **Zero-shot failure**: DM at 0% shows e-distance 1.228 vs. baseline 0.662, confirming no transfer without target supervision
  - **Mode collapse in FM**: "FM tends to favor specific high-density sectors... producing more outliers on the left-hand side"
  - **Rare pattern underrepresentation**: Across all models, "west-facing arrivals at Dublin remained underrepresented"
  - **MMD instability**: MMD uptick at larger splits attributed to finite-sample variability with N=100

- First 3 experiments:
  1. **Reproduce baseline comparison**: Train DM from scratch on 100% Dublin data to establish baseline metrics; compare against pretrained DM fine-tuned on 20% Dublin to verify reported ~4x sample efficiency
  2. **Ablate representation**: Train DM on lat/lon representation instead of kinematic; compare transfer performance to isolate contribution of airport-agnostic representation
  3. **Probe rare mode capture**: Oversample rare trajectory patterns (e.g., west-facing approaches) in target fine-tuning data; measure whether MMD improves without degrading DTW on dominant corridors

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can multimodal conditioning (e.g., integrating weather data) or curriculum-based fine-tuning effectively mitigate the underrepresentation of rare trajectory patterns in transfer learning?
- Basis in paper: [explicit] The conclusion states, "Future work should explore strategies to better capture rare trajectory patterns... and multimodal conditioning (e.g., weather)."
- Why unresolved: Current results show that while dominant corridors are reproduced, rare modes (e.g., west-facing arrivals) remain underrepresented even with 100% target data.
- What evidence would resolve it: A comparative study showing improved coverage of minority trajectory classes when weather variables are added as conditioning inputs.

### Open Question 2
- Question: Does the strong transfer performance observed between major hubs (Zurich to Dublin) generalize to airports with significantly different topological constraints or operational procedures?
- Basis in paper: [inferred] The introduction identifies data scarcity at "secondary and regional airports," but the experimental validation is restricted to two major, structurally similar international airports.
- Why unresolved: It is unclear if the kinematic representations learned from Zurich's approach patterns are flexible enough to handle vastly different runway configurations or terrain constraints at smaller regional airports without negative transfer.
- What evidence would resolve it: Experiments pretraining on hub data and fine-tuning on diverse regional airports with distinct approach geometries.

### Open Question 3
- Question: To what extent do the statistically realistic trajectories generated via transfer learning satisfy the physical constraints required for operational air traffic simulation?
- Basis in paper: [inferred] Section IV.B notes that while statistical metrics are reproducible, they "do not certify operational validity," and resource-intensive physics-aware simulation was not performed.
- Why unresolved: The paper relies on distributional metrics and visual inspection, leaving a gap between statistical fidelity and physical/operational plausibility.
- What evidence would resolve it: Validation of the synthetic trajectories in a physics-aware simulator to check for aerodynamic feasibility and conflict resolution.

## Limitations
- The strongest empirical claim (DM's 5% data efficiency vs. baseline) is based on a single source-target airport pair; generalization across different airport geometries remains untested.
- The superiority of diffusion over flow matching for transfer is observational, not proven by ablations or theoretical analysis.
- Rare trajectory modes (e.g., west-facing arrivals) remain underrepresented across all models, indicating potential mode collapse.
- Latent variants (LDM/LFM) show smaller gains, but the exact cause (information loss in VAE, training instability, or architecture choice) is unclear.

## Confidence
- **High Confidence**: Pretraining enables transfer (0% vs. 5% performance gap is large and consistent); kinematic representation prevents geographic overfitting; quantitative improvements (e-distance, MMD, DTW) are well-documented.
- **Medium Confidence**: Diffusion models are more transfer-efficient than flow matching; latent variants trade sample efficiency for training speed; transfer gains generalize beyond this Zurich-Dublin pair.
- **Low Confidence**: The exact mechanism behind diffusion's superior transfer; latent space compression's impact on fine-grained spatial accuracy; robustness to radically different airport procedures.

## Next Checks
1. **Cross-Airport Validation**: Repeat the full pretraining-finetuning pipeline on a different source-target pair (e.g., Heathrow to Manchester) to test generalization of transfer gains.
2. **Representation Ablation**: Train a DM directly on geographic coordinates and compare transfer performance to isolate the contribution of the kinematic representation.
3. **Rare Mode Recovery**: Design a fine-tuning curriculum that oversamples underrepresented trajectory patterns (e.g., west-facing approaches) and measure MMD improvement without degrading DTW on dominant corridors.