---
ver: rpa2
title: 'Point, Detect, Count: Multi-Task Medical Image Understanding with Instruction-Tuned
  Vision-Language Models'
arxiv_id: '2505.16647'
source_url: https://arxiv.org/abs/2505.16647
tags:
- medical
- tasks
- counting
- multimodal
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study explores multi-task learning for medical image understanding
  using instruction-tuned vision-language models. The authors fine-tune Qwen2.5-VL-7B-Instruct
  with LoRA on MedMultiPoints, a dataset containing endoscopy and microscopy images
  with detection, counting, and localization annotations.
---

# Point, Detect, Count: Multi-Task Medical Image Understanding with Instruction-Tuned Vision-Language Models

## Quick Facts
- **arXiv ID:** 2505.16647
- **Source URL:** https://arxiv.org/abs/2505.16647
- **Reference count:** 33
- **Primary result:** Multi-task fine-tuning of Qwen2.5-VL-7B-Instruct with LoRA improves detection, counting, and pointing accuracy on MedMultiPoints dataset, though trade-offs emerge in edge-case reliability.

## Executive Summary
This paper presents a multi-task learning approach for medical image understanding using instruction-tuned vision-language models. The authors fine-tune Qwen2.5-VL-7B-Instruct with LoRA on MedMultiPoints, a dataset containing endoscopy and microscopy images with detection, counting, and localization annotations. By reformulating these tasks as instruction-based prompts, they train a single model to perform object detection, counting, and pointing simultaneously. Results show that multi-task training improves overall robustness and accuracy, with notable reductions in count MAE and increased matching accuracy in combined tasks. However, trade-offs emerge, including more zero-case point predictions, indicating reliability issues in edge cases. The approach demonstrates how general-purpose VLMs can be adapted for composite diagnostic reasoning in medical AI, producing interpretable structured outputs.

## Method Summary
The authors fine-tune Qwen2.5-VL-7B-Instruct with LoRA adapters (rank 16) on the MedMultiPoints dataset, which contains endoscopy and microscopy images with bounding boxes, points, and counts. The model is trained for 5 epochs using AdamW optimizer (lr=2e-4, batch size 4 with gradient accumulation) while freezing the vision encoder. Tasks are reformulated as instruction-based prompts that require JSON-formatted text outputs containing coordinates and counts. The training objective is standard cross-entropy over tokens, enabling the model to generate structured spatial outputs through text generation. Evaluation includes task-specific metrics like MAE for counting, Matching Accuracy for pointing, and mAP for detection.

## Key Results
- Multi-task training reduces Count Mean Absolute Error (MAE) and increases Matching Accuracy in combined counting+pointing tasks
- Improved robustness through shared visual representations that benefit from co-training across detection, counting, and localization
- Trade-offs emerge with increased zero-case point predictions (3 to 29) indicating edge-case reliability issues
- LoRA-based fine-tuning enables efficient adaptation while preserving pre-trained visual-language alignment

## Why This Works (Mechanism)

### Mechanism 1
Multi-task training on detection, counting, and pointing improves individual task performance through shared visual representations. Joint optimization on related spatial tasks creates inductive transfer—the model learns richer visual features that generalize across tasks. For example, learning to count reinforces spatial reasoning, and accurate localization supports better enumeration. Core assumption: Tasks share underlying visual representations that benefit from co-training. Evidence: Results show that multi-task training improves robustness and accuracy, with lower Count MAE aligning with higher Matching Accuracy. Break condition: If tasks have conflicting gradient signals or require fundamentally different visual features, multi-task training may degrade performance.

### Mechanism 2
Instruction-tuned VLMs can produce structured spatial outputs (bounding boxes, points, counts) by reformulating vision tasks as text generation. Detection and counting are converted to JSON-formatted text outputs via task-specific prompts. The language modeling objective (cross-entropy over tokens) trains the model to generate syntactically valid coordinates and counts alongside natural language. Core assumption: The pre-trained VLM has sufficient visual grounding to learn coordinate generation through text-based fine-tuning alone. Evidence: The unified text-based output allows the VLM to be trained with a standard language modeling objective. Break condition: Text-based coordinate generation may fail when precise sub-pixel accuracy is required, or when JSON parsing fails due to malformed outputs.

### Mechanism 3
LoRA-based fine-tuning enables efficient domain adaptation while preserving pre-trained visual-language alignment. Freezing the vision encoder and training only low-rank adapters on LLM linear layers reduces trainable parameters from billions to millions. This prevents catastrophic forgetting while allowing task-specific adaptation. Core assumption: The pre-trained vision encoder already captures sufficient visual features; only the language-to-output mapping needs adaptation. Evidence: LoRA introduces small trainable rank-decomposition matrices into the model's linear layers, reducing trainable parameters while maintaining performance. Break condition: If medical images differ significantly from pre-training data, frozen encoder may lack relevant features.

## Foundational Learning

- **Vision-Language Models (VLMs)** - Neural architectures combining a visual encoder (typically ViT) with a language model decoder, enabling multimodal reasoning. *Why needed:* Understanding how visual features are tokenized and processed by the LLM is essential for debugging output failures and designing effective prompts. *Quick check:* Can you explain how an image is converted into tokens that the language model processes?

- **Low-Rank Adaptation (LoRA)** - Parameter-efficient fine-tuning that adds trainable low-rank matrices to existing weights rather than updating all parameters. *Why needed:* The entire experimental setup depends on LoRA; understanding rank selection and which layers to adapt is critical for reproduction. *Quick check:* What is the effect of increasing LoRA rank on model capacity versus overfitting risk?

- **Multi-Task Learning Trade-offs** - Joint training can improve average performance while increasing failure rates on hard examples due to gradient competition or distribution shift. *Why needed:* The paper explicitly documents this trade-off (improved MAE but increased zero-case predictions), which is critical for clinical deployment decisions. *Quick check:* What metrics beyond average accuracy should you monitor to detect edge-case degradation?

## Architecture Onboarding

- **Component map:** Vision Encoder (ViT-based, frozen) -> Visual Tokens -> Language Model (Qwen2.5-VL-7B-Instruct) -> LoRA Adapters (rank=16) -> Task-specific Outputs -> JSON Parser
- **Critical path:** 1. Data preparation → Format MedMultiPoints annotations as instruction-response pairs with JSON outputs 2. LoRA setup → Apply adapters to LLM, freeze vision encoder, configure rank=16 3. Training → 5 epochs, AdamW optimizer, lr=2e-4, batch size 4 with gradient accumulation 4. Evaluation → Parse JSON outputs, compute task-specific metrics
- **Design tradeoffs:** Single-task vs. multi-task training (multi-task improves average metrics but increases zero-case failures); LoRA rank selection (higher rank provides more capacity but risks overfitting); frozen vs. fine-tuned encoder (freezing reduces overfitting but may limit adaptation); epoch count (extended training improves accuracy but may reduce edge-case reliability)
- **Failure signatures:** Zero-case predictions (model outputs nothing on difficult samples, rose from 3 to 29); high MSE with low MAE (indicates outlier predictions dominating error variance); JSON parsing failures (malformed outputs due to tokenization or formatting issues); task competition (improvement in one metric coinciding with degradation in another)
- **First 3 experiments:** 1. Baseline comparison: Evaluate public Qwen2.5-VL-7B-Instruct on MedMultiPoints test set to establish zero-shot performance 2. Single-task ablation: Train separate models for counting-only, pointing-only, and detection-only tasks; compare against multi-task model 3. LoRA rank sensitivity: Test ranks 4, 8, 16, 32 on validation set, monitoring both aggregate metrics and failure metrics

## Open Questions the Paper Calls Out

### Open Question 1
Can uncertainty-aware prediction mechanisms or abstention-based outputs mitigate the increase in zero-case point predictions observed during extended fine-tuning? The authors note that zero-case point predictions rise sharply from 3 to 29 in Counting + Pointing tasks and suggest the need for mechanisms like uncertainty estimation, abstention-based prediction, or fallback triggers to handle uncertain or ambiguous cases more gracefully. This remains unresolved because the current training objective optimizes for aggregate accuracy without explicit modeling of prediction confidence, causing the model to silently fail on harder samples. Evidence that would resolve it: Experiments incorporating uncertainty heads or confidence thresholds that reduce zero-case predictions while maintaining or improving Count MAE and Matching Accuracy.

### Open Question 2
What dynamic loss balancing strategies can prevent task prioritization skew in multi-task fine-tuning of medical VLMs? The authors state that aggressive optimization toward one task (e.g., minimizing counting error) can cause degradation in complementary metrics (e.g., missing point predictions), suggesting a delicate balance in loss weighting is essential. This remains unresolved because all tasks currently use unified language modeling loss without task-specific weighting, leading to implicit and uncontrolled trade-offs during training. Evidence that would resolve it: Comparative studies using gradient-based task weighting, uncertainty-weighted losses, or curriculum strategies that show stable or improved performance across all metrics without edge-case degradation.

### Open Question 3
Does instruction-tuned multi-task learning transfer effectively to volumetric medical imaging modalities such as CT and MRI? The authors acknowledge that their dataset primarily focuses on GI imaging and spermogram, and generalizing the model to more modalities like CT or MRI would require targeted adaptation, which they leave as future work. This remains unresolved because MedMultiPoints contains only 2D endoscopy and microscopy images; the ViT-based vision encoder processes single-frame inputs, and it remains unclear whether spatial reasoning learned from 2D bounding boxes generalizes to 3D volumetric data. Evidence that would resolve it: Fine-tuning experiments on CT/MRI datasets with slice-level or volumetric annotations, reporting detection mAP, counting MAE, and localization accuracy comparable to 2D results.

## Limitations
- **Prompt template variability** - Exact instruction prompt templates are not specified, creating uncertainty in reproducibility and performance sensitivity
- **Multi-task trade-offs** - Dramatic increase in zero-case predictions (3 to 29) indicates the model may be learning to abstain on difficult examples rather than developing robust reasoning
- **Evaluation infrastructure fragility** - JSON parsing failures due to formatting inconsistencies pose reliability concerns for clinical deployment

## Confidence

- **High Confidence:** LoRA-based fine-tuning mechanism for efficient parameter adaptation; multi-task training framework and instruction-based reformulation approach
- **Medium Confidence:** Performance improvements on specific metrics (Count MAE reduction, Matching Accuracy increase); clinical significance and generalizability remain uncertain
- **Low Confidence:** Text-based coordinate generation through JSON-formatted outputs as a robust approach for precise spatial reasoning in medical AI; lacks extensive validation

## Next Checks

1. **Prompt Template Sensitivity Analysis** - Systematically vary instruction prompt wording and structure to quantify performance sensitivity. Test different formulations and measure impact on output quality, parsing success rate, and task accuracy to identify optimal prompt designs.

2. **Failure Case Analysis** - Conduct detailed analysis of zero-case predictions and JSON parsing failures. Examine the distribution of failed samples across difficulty levels, image types, and task combinations. Use uncertainty quantification methods to determine whether the model is making informed abstentions or exhibiting systematic failure patterns.

3. **Cross-Modality Generalization Test** - Evaluate the fine-tuned model on a held-out medical imaging modality (e.g., chest X-rays or brain MRI) that was not in the training distribution. Measure performance degradation and analyze whether the frozen vision encoder limits adaptation to novel imaging characteristics, informing decisions about whether encoder fine-tuning is necessary for broader medical applications.