---
ver: rpa2
title: 'ASTRA: A Scene-aware TRAnsformer-based model for trajectory prediction'
arxiv_id: '2501.09878'
source_url: https://arxiv.org/abs/2501.09878
tags:
- prediction
- trajectory
- social
- scene
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ASTRA, a lightweight pedestrian trajectory
  forecasting model that achieves state-of-the-art performance with significantly
  fewer parameters than existing models. ASTRA integrates scene context, spatial dynamics,
  social interactions, and temporal progressions through a novel architecture combining
  a U-Net-based feature extractor, graph-aware transformer encoder, and a weighted
  penalty loss function.
---

# ASTRA: A Scene-aware TRAnsformer-based model for trajectory prediction

## Quick Facts
- arXiv ID: 2501.09878
- Source URL: https://arxiv.org/abs/2501.09878
- Reference count: 40
- Primary result: Achieves state-of-the-art trajectory prediction with 7x fewer parameters than existing models

## Executive Summary
ASTRA introduces a lightweight pedestrian trajectory forecasting model that achieves state-of-the-art performance while using significantly fewer parameters than existing approaches. The model integrates scene context, spatial dynamics, social interactions, and temporal progressions through a novel architecture combining a U-Net-based feature extractor, graph-aware transformer encoder, and a weighted penalty loss function. ASTRA generates both deterministic and stochastic predictions and demonstrates strong generalization across Bird's Eye View and Ego-Vehicle View datasets.

## Method Summary
ASTRA uses a U-Net encoder pre-trained on scene images with Weighted Hausdorff Distance loss to extract latent scene representations, which are then processed through a single-layer scene-aware transformer. Agent features are encoded through spatial MLPs, sinusoidal temporal encodings, and Random Walk Positional Encodings (RWPE) from a fully connected graph with reciprocal distance edge weights. These embeddings are concatenated and processed by a single-layer agent transformer, with outputs decoded through an MLP or CVAE for stochastic predictions. The model is trained using AdamW optimizer with cosine annealing, employing a novel parabolic weighted penalty loss function that emphasizes early and late timesteps.

## Key Results
- 27% average improvement in deterministic settings on ETH-UCY dataset compared to state-of-the-art
- 10% average improvement in stochastic settings on ETH-UCY dataset
- 26% improvement on PIE dataset while using 7x fewer parameters than current state-of-the-art
- Ablation studies confirm contribution of each component (temporal, social, U-Net, augmentation)

## Why This Works (Mechanism)

### Mechanism 1: Graph-Structure Injection into Transformer Tokens
Embedding RWPE directly into transformer tokens enables concurrent spatial-temporal-social processing without separate GNN blocks. A fully connected undirected graph with reciprocal distance edge weights allows the transformer to be inherently "graph-aware" rather than requiring sequential GNN→Transformer processing.

### Mechanism 2: Pre-trained Frozen Scene Encoder with Latent Key-point Extraction
A U-Net pre-trained with Weighted Hausdorff Distance loss captures scene walkability and implicit pedestrian presence without requiring explicit segmentation masks. The frozen encoder provides consistent scene context tokens to a single-layer scene-aware transformer.

### Mechanism 3: Parabolic Weighted Penalty Loss
A parabolic weighting function that emphasizes early and late timesteps while reducing mid-horizon penalty yields more accurate trajectory predictions than linear or quadratic weighting. This counteracts observed "offset drift" in early predictions seen with purely progressive penalties.

## Foundational Learning

- **Transformer Attention and Positional Encoding**: Understanding why position is injected via addition to embeddings is essential before modifying the architecture. Quick check: Can you explain why transformer attention is permutation-invariant without positional encoding, and what happens if you concatenate instead of add positional encodings?

- **Random Walk on Graphs and Structural Encoding**: RWPE is the core novelty for making transformers "graph-aware." Quick check: Given a 3-node graph with edges (A-B, B-C), what does the 2-step random walk probability from A to C represent?

- **Conditional Variational Autoencoders (CVAE)**: Stochastic prediction mode uses CVAE with prior/recognition/generation networks. Quick check: During inference, why do we sample from the prior distribution rather than the posterior, and what failure mode occurs if KL divergence collapses to near-zero?

## Architecture Onboarding

- **Component map**:
```
Input: Coordinates X + Frames I
  │
  ├─→ [U-Net Encoder (FROZEN)] → MLP → Scene Tokens
  │                              ↓
  │                    [Scene Transformer (1 layer)] → ΦScene
  │
  ├─→ [Spatial MLP] → ΦSpatial
  │
  ├─→ [Sinusoidal Encoding] → ΦTemporal
  │
  └─→ [Graph Construction] → [RWPE] → [Social MLP] → ΦSocial
             ↓
    [ΦSpatial; ΦTemporal; ΦSocial] → [Agent Transformer (1 layer)] → ΦAgents
                                                                      ↓
                                        [ΦScene; ΦAgents] → [MLP Decoder] → Ŷ
                                                                      ↓
                                                [CVAE for stochastic] → K trajectories
```

- **Critical path**:
  1. U-Net pre-training quality directly affects scene embeddings—validate with Grad-CAM before freezing
  2. Graph construction (fully connected with distance-reciprocal edges) → RWPE computation → social encoding quality
  3. Concatenation point: All three embeddings must be same dimension before agent transformer
  4. Loss weighting: Parabolic function parameters (α, β) control early/late emphasis—sensitive to prediction horizon

- **Design tradeoffs**:
  - Single-layer transformers reduce parameters 7x vs SOTA but may limit modeling capacity for complex multi-agent scenarios
  - Frozen U-Net reduces training compute but sacrifices scene adaptation to new environments
  - Fully connected graph captures all interactions but scales O(A²) with agent count—may need sparse approximation for dense crowds
  - CVAE vs deterministic: Stochastic mode adds ~0.2M parameters and KL tuning complexity but enables multi-modal prediction

- **Failure signatures**:
  1. Early-timestep drift with monotonic loss: Switch to parabolic if using linear/quadratic penalty
  2. Collapsed KL divergence (stochastic mode): Increase KL weight or check recognition network capacity
  3. Scene attention on irrelevant regions: Verify Grad-CAM shows U-Net focusing on pedestrians
  4. Social encoding degradation in sparse scenes: Consider fallback to spatial-only encoding with <3 agents

- **First 3 experiments**:
  1. Replicate Table 3 on UNIV dataset—disable each component sequentially to confirm contribution hierarchy
  2. Compare Parabolic vs Linear vs Quadratic vs Unpenalised on one ETH-UCY split; plot prediction error by timestep
  3. Synthetically increase agent count on PIE dataset; measure inference time and accuracy degradation to identify scaling breakpoints

## Open Questions the Paper Calls Out

- **Non-human agents**: How effectively can ASTRA be adapted to predict trajectories of vehicles or cyclists in shared environments? Current evaluation is restricted to pedestrian-only datasets.
- **Transformer-based scene representation**: Do transformer-based architectures for scene representation generation provide superior feature extraction compared to the current U-Net-based approach?
- **Gated cross-attention fusion**: Does fusing social representations via gated cross-attention mechanisms yield better performance than the current concatenation strategy?

## Limitations

- RWPE implementation details and hyperparameters are not fully specified, requiring reconstruction from referenced work
- Parabolic loss function parameters (α, β) are not provided, leaving critical weighting strategy ambiguous
- Fully connected graph construction may not scale efficiently to dense crowds (>50 agents), creating computational bottlenecks
- U-Net architecture specifics are underspecified beyond following referenced work, potentially affecting scene representation quality

## Confidence

- **High confidence**: Overall architecture design and core claim of achieving SOTA with 7x fewer parameters
- **Medium confidence**: Parabolic weighted penalty mechanism—empirical rather than theoretically derived
- **Medium confidence**: RWPE contribution—novel to ASTRA but no corpus validation exists for this application
- **Low confidence**: Reproducibility without missing hyperparameters for loss functions and graph construction details

## Next Checks

1. Replicate ablation study (Table 3) on UNIV dataset, disabling each component sequentially to verify contribution hierarchy
2. Implement and test the parabolic weighted penalty function with multiple α/β configurations; compare prediction error by timestep
3. Stress test graph construction by synthetically increasing agent density on PIE dataset; measure accuracy and inference time degradation to identify scaling limits