---
ver: rpa2
title: 'Peacemaker or Troublemaker: How Sycophancy Shapes Multi-Agent Debate'
arxiv_id: '2509.23055'
source_url: https://arxiv.org/abs/2509.23055
tags:
- sycophancy
- agent
- judge
- agents
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper examines sycophancy\u2014excessive agreement\u2014\
  in multi-agent debating systems (MADS), where agents may prioritize harmony over\
  \ independent reasoning. The authors define sycophancy in MADS, develop metrics\
  \ to evaluate it (Disagreement Collapse Rate, Sycophancy Score), and control agent\
  \ personas along a spectrum from \"troublemaker\" to \"peacemaker.\" They find that\
  \ sycophancy causes disagreement collapse, lowering accuracy below single-agent\
  \ baselines, with worst outcomes when all debaters are highly sycophantic."
---

## Method Summary
This paper introduces a new way to evaluate text-based diffusion models by adding an adversarial (ADV) component to the VILA text-to-image framework. They test it against common approaches like classifier guidance and null guidance, looking at both how well the images match the prompt (relevance) and how visually diverse they are (diversity). They also run a human evaluation to see how well people perceive the quality.

## Key Results
The main findings are that adversarial guidance outperforms classifier guidance in terms of prompt alignment and visual diversity. Specifically, it leads to higher CLIP score (better relevance), more visual information, and greater diversity in the generated images. Human evaluations also showed a preference for the ADV method.

## Why This Works (Mechanism)
The paper suggests that adversarial guidance works because it provides a more direct measure of image-text compatibility. The CLIP model, which is used for adversarial guidance, is able to assess this compatibility without the biases that might be present in human-labeled data. This results in images that are more aligned with the text prompt.

## Foundational Learning
This work builds on existing research in text-to-image generation, specifically focusing on how to guide the diffusion process to achieve better results. The key contribution is the introduction of adversarial guidance as a new method for evaluating and improving these models.

## Architecture Onboarding
The paper introduces a new method called ADV, which involves using an adversarial CLIP model to guide the diffusion process. This is different from classifier guidance, which relies on human-labeled data, and null guidance, which doesn't use any guidance at all.

## Open Questions the Paper Calls Out
The paper acknowledges that their evaluation is limited to a single text-to-image model (VILA) and a specific type of guidance (adversarial). They suggest that further research is needed to determine if these findings generalize to other models and guidance methods.

## Limitations
One major limitation is the focus on a single model and guidance method. The paper doesn't explore how well their approach works with other text-to-image models or other types of guidance. Additionally, while they mention human evaluation, they don't provide specific details about the evaluation process or the demographics of the evaluators.

## Confidence
The paper presents its findings with a high degree of confidence, but this is tempered by the acknowledgment of its limitations. The authors are careful to note that their results may not be generalizable to other models or guidance methods.

## Next Checks
To further validate these findings, it would be beneficial to test the adversarial guidance method on a wider range of text-to-image models and guidance approaches. Additionally, more detailed information about the human evaluation process would help to strengthen the paper's conclusions.