---
ver: rpa2
title: Stochastically Constrained Best Arm Identification with Thompson Sampling
arxiv_id: '2501.03877'
source_url: https://arxiv.org/abs/2501.03877
tags:
- feasible
- arms
- best
- sampling
- probability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper tackles the Best Feasible Arm Identification (BFAI)\
  \ problem in a Bayesian setting, where the goal is to identify the best arm subject\
  \ to stochastic constraints on multiple performance measures. The authors extend\
  \ Thompson Sampling (TS) to BFAI by introducing a parameter \u03B2 to control sampling\
  \ probabilities, creating the BFAI-TS algorithm."
---

# Stochastically Constrained Best Arm Identification with Thompson Sampling

## Quick Facts
- arXiv ID: 2501.03877
- Source URL: https://arxiv.org/abs/2501.03877
- Reference count: 40
- Primary result: BFAI-TS achieves asymptotic optimality in sample allocation and posterior convergence rate

## Executive Summary
This paper addresses the Best Feasible Arm Identification (BFAI) problem under multiple stochastic constraints in a Bayesian setting. The authors extend Thompson Sampling to BFAI by introducing a parameter β to control sampling probabilities, creating the BFAI-TS algorithm. The algorithm is theoretically analyzed to show asymptotic optimality in both sample allocation and posterior convergence rate, characterized by Γβ. Numerical experiments on synthetic and real-world datasets demonstrate that BFAI-TS outperforms several benchmarks, particularly in small-sample regimes.

## Method Summary
The paper proposes BFAI-TS, an extension of Thompson Sampling to handle stochastic constraints in best arm identification. The algorithm uses a parameter β to control the sampling probability of arms, balancing exploration and exploitation while respecting constraints. Theoretical analysis establishes that BFAI-TS achieves the optimal convergence rate Γβ when β is set to β*. The algorithm maintains posterior distributions for each arm's performance measures and samples from these posteriors to make decisions about which arms to pull, incorporating the constraint satisfaction probability into the sampling strategy.

## Key Results
- BFAI-TS achieves asymptotic optimality in sample allocation and posterior convergence rate
- The convergence rate is characterized by Γβ, which depends on the parameter β
- Numerical experiments show BFAI-TS outperforms benchmarks, especially in small-sample regimes

## Why This Works (Mechanism)
The algorithm works by extending Thompson Sampling to incorporate stochastic constraints through the β parameter. This parameter controls the exploration-exploitation tradeoff while ensuring constraint satisfaction. By maintaining posterior distributions for each arm and sampling from them, BFAI-TS naturally balances the need to identify the best arm with the requirement to respect constraints. The asymptotic analysis shows that with the optimal β*, the algorithm achieves the fastest possible convergence rate while maintaining constraint satisfaction.

## Foundational Learning
- Thompson Sampling: Bayesian approach for balancing exploration and exploitation; needed for posterior-based decision making in bandit problems; quick check: verify understanding of posterior sampling mechanism
- Best Arm Identification: Problem of finding the optimal arm with minimal samples; needed as the base problem being solved; quick check: confirm understanding of regret vs. identification objectives
- Stochastic Constraints: Performance measures that must satisfy certain probability thresholds; needed to model real-world limitations; quick check: ensure understanding of how constraints affect sampling decisions
- Asymptotic Optimality: Property where algorithm performance approaches theoretical optimum as sample size grows; needed for theoretical guarantees; quick check: verify understanding of convergence rate analysis

## Architecture Onboarding

Component Map: Posterior distributions -> Sampling mechanism -> Constraint satisfaction check -> Arm selection -> Reward observation -> Update posteriors

Critical Path: The algorithm iteratively samples from posterior distributions, evaluates constraint satisfaction, selects arms based on both utility and constraints, observes rewards, and updates posteriors. This loop continues until sufficient confidence is achieved in identifying the best feasible arm.

Design Tradeoffs: The β parameter controls the exploration-exploitation tradeoff but requires careful tuning. A higher β encourages more exploration but may slow convergence, while a lower β may converge faster but risk constraint violations. The algorithm trades computational complexity for theoretical guarantees of optimality.

Failure Signatures: Poor performance may occur when constraints are too tight relative to arm distributions, when β is mis-specified, or when reward distributions have heavy tails. The algorithm may also struggle with high-dimensional constraint spaces or when arms have very similar performance characteristics.

First Experiments:
1. Verify posterior updates converge correctly for simple bandit problems with known solutions
2. Test constraint satisfaction probability under various β settings
3. Compare convergence rates against standard Thompson Sampling on constrained vs unconstrained problems

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical assumptions may not hold in practical scenarios with limited samples or non-standard reward distributions
- Analysis focuses on Bayesian regret without addressing computational complexity for large-scale problems
- Numerical experiments limited to specific synthetic and real-world datasets, potentially not capturing diverse problem settings

## Confidence

| Claim | Confidence |
|-------|------------|
| Theoretical analysis of asymptotic optimality | High |
| Practical effectiveness demonstrated through experiments | Medium |
| Generalization to broader problem classes | Low |

## Next Checks
1. Test BFAI-TS on additional real-world datasets with different constraint structures and reward distributions to assess robustness.
2. Conduct runtime complexity analysis and benchmarking against other BFAB algorithms to evaluate computational efficiency.
3. Investigate the sensitivity of β parameter selection in practice, particularly for non-asymptotic regimes and small sample sizes.