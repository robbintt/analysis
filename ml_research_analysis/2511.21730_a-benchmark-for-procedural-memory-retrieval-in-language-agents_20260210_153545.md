---
ver: rpa2
title: A Benchmark for Procedural Memory Retrieval in Language Agents
arxiv_id: '2511.21730'
source_url: https://arxiv.org/abs/2511.21730
tags:
- procedural
- retrieval
- memory
- corpus
- trajectories
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces the first benchmark for evaluating procedural
  memory retrieval in language agents, isolating retrieval from execution to measure
  genuine procedural understanding. Using ALFWorld, the authors construct dual corpora
  of expert and LLM-generated trajectories, evaluating six retrieval methods on both
  seen and unseen task contexts.
---

# A Benchmark for Procedural Memory Retrieval in Language Agents

## Quick Facts
- arXiv ID: 2511.21730
- Source URL: https://arxiv.org/abs/2511.21730
- Authors: Ishant Kohar; Aswanth Krishnan
- Reference count: 4
- Primary result: Introduces first benchmark isolating procedural memory retrieval from execution, revealing a 30% generalization cliff in embedding-based methods

## Executive Summary
This work introduces the first benchmark for evaluating procedural memory retrieval in language agents, isolating retrieval from execution to measure genuine procedural understanding. Using ALFWorld, the authors construct dual corpora of expert and LLM-generated trajectories, evaluating six retrieval methods on both seen and unseen task contexts. Embedding-based methods perform strongly on familiar tasks (84% MAP) but degrade sharply on novel ones (59% MAP, −30% drop), revealing a "generalization cliff" rooted in their inability to capture temporal structure. In contrast, LLM-generated procedural abstractions show stable cross-context transfer. Controlled ablations confirm that current sentence-transformer encoders behave as "bag-of-words" models, with corpus scale delivering larger gains than representation enrichment. The benchmark provides a diagnostic framework for developing more robust procedural memory systems.

## Method Summary
The benchmark uses ALFWorld to create dual corpora of expert trajectories (78) and LLM-generated trajectories (336), evaluating six retrieval methods on both seen and unseen task contexts. Queries are stratified by complexity (EASY/MEDIUM/HARD) and balanced across coverage levels. Retrieval methods include action-only embeddings, state-enriched embeddings, LLM-generated summaries, and combined representations, all using mean-pooled sentence transformers (all-MiniLM-L6-v2). Relevance is scored by an LLM-as-judge (GPT-5) on a 1-10 scale with threshold ≥6 for binary relevance. The primary metric is Mean Average Precision (MAP), with P@k and NDCG as secondary metrics.

## Key Results
- Embedding-based methods achieve 84% MAP on familiar contexts but drop to 59% MAP on novel ones (30% degradation)
- Corpus scale (336 vs 78 trajectories) delivers 27.7% improvement, outperforming representation enrichment (9.9% gain)
- LLM-generated procedural abstractions show stable cross-context transfer where embedding methods fail
- State-aware representations help simple tasks but introduce noise for complex multi-step procedures
- Current sentence-transformers behave as "bag-of-words" models, unable to distinguish temporal orderings

## Why This Works (Mechanism)

### Mechanism 1: The Generalization Cliff in Embedding-Based Retrieval
Embedding-based retrieval systems overfit to familiar object vocabularies and fail to generalize procedural patterns to novel contexts. Mean pooling in sentence-transformer encoders averages token embeddings, discarding temporal ordering and treating trajectories as unordered token collections. Two procedurally distinct sequences with identical tokens but different orderings produce nearly identical embeddings.

### Mechanism 2: LLM-Generated Procedural Abstractions Enable Cross-Context Transfer
Procedural summaries generated by LLMs generalize better because they decouple procedures from object identities before embedding. LLMs explicitly extract structural patterns (e.g., "locate item → heat item → place in storage") that are object-agnostic. The downstream embedding model then operates on higher-level procedural concepts rather than surface tokens.

### Mechanism 3: Corpus Scale Dominates Representation Enrichment
For current sentence-transformer architectures, increasing procedural coverage yields larger gains than adding contextual detail. Mean pooling dilutes the contribution of individual tokens, so adding 10× more state information produces modest gains. Larger corpora provide more diverse procedural patterns to match against.

## Foundational Learning

- **Mean pooling and permutation invariance**: Explains why embedding methods fail to capture temporal structure—they produce near-identical representations for reordered sequences. *Quick check*: Given sequences [A→B→C] and [B→A→C], would a mean-pooled encoder distinguish them?
- **Procedural similarity vs lexical similarity**: The benchmark specifically evaluates functional equivalence independent of object vocabularies, requiring understanding of this distinction. *Quick check*: Are "clean apple, place in cabinet" and "clean fork, place in drawer" procedurally similar?
- **Information retrieval metrics (MAP, NDCG)**: The benchmark reports MAP as the primary metric; understanding it is essential for interpreting results. *Quick check*: If a system retrieves 3 relevant items in ranks 1, 3, 5 out of 5 retrieved, what is the MAP for that query?

## Architecture Onboarding

- **Component map**: Corpus (78 expert trajectories, 336 LLM-generated trajectories) -> Query bank (40 coverage-balanced queries) -> Retrieval methods (6 evaluated) -> LLM-as-judge scoring -> Evaluation metrics (MAP, P@k, NDCG)
- **Critical path**: Convert trajectories to representation format -> Generate embeddings using all-MiniLM-L6-v2 -> Retrieve top-K via cosine similarity in ChromaDB -> Score relevance with LLM-as-judge -> Compute MAP, P@k, NDCG
- **Design tradeoffs**: Memorization vs. abstraction (methods optimized for seen contexts sacrifice generalization); State-aware vs. action-only (state context helps simple tasks but introduces noise); Corpus scale vs. representation richness (scale delivers ~3× the gains of enrichment)
- **Failure signatures**: Rank reversal (methods ranked highly on seen tasks drop sharply on unseen tasks); Transformation confusion (embeddings fail to distinguish CLEAN vs. HEAT vs. COOL under vocabulary shift); Zero-relevant queries at high thresholds (≥10 threshold yields 50% queries with no relevant retrievals)
- **First 3 experiments**: Reproduce the generalization cliff (action-only embeddings on 18 seen vs. 18 unseen queries; expect ~30% MAP drop); Test summary embeddings (generate LLM summaries for subset, embed, evaluate on unseen queries; expect stable performance); Corpus ablation (compare retrieval on 78-trajectory vs. 336-trajectory corpora; expect ~20–28% improvement from scale)

## Open Questions the Paper Calls Out

### Open Question 1
Can sequence-aware encoders (e.g., causal-attention transformers, hierarchical trajectory encoders) substantially close the generalization cliff by preserving temporal dependencies that mean-pooled sentence transformers discard? The paper only evaluates mean-pooled sentence transformers, which formally cannot distinguish action orderings.

### Open Question 2
Do the observed generalization patterns transfer to domains beyond household tasks, such as robotics manipulation, software workflows, or multi-agent coordination? All experiments use ALFWorld's six task types; no cross-domain validation was conducted.

### Open Question 3
Does a two-stage retrieval architecture—separating procedural structure extraction (e.g., LLM summarization) from similarity computation—consistently outperform single-stage approaches across corpus scales? Summary embeddings were evaluated only on the 78-trajectory corpus due to computational cost.

## Limitations

- The LLM-as-judge scoring introduces potential subjectivity in relevance judgments, though thresholds (score ≥6) provide some objectivity
- The benchmark's reliance on ALFWorld may limit generalizability to other procedural domains, as the vocabulary and action space are domain-specific
- The summary generation quality depends entirely on the LLM's procedural understanding, which wasn't directly evaluated

## Confidence

- **High confidence**: The generalization cliff observation (84% → 59% MAP drop) is directly measurable and well-supported by experimental results across multiple retrieval methods
- **Medium confidence**: The claim that mean pooling causes permutation invariance and temporal structure loss is mechanistically sound but requires further validation with alternative architectures
- **Medium confidence**: The superiority of corpus scale over representation enrichment (27.7% vs 9.9% improvement) is demonstrated, but scaling beyond 336 trajectories remains untested

## Next Checks

1. **Architectural validation**: Test sequence-aware retrieval methods (e.g., Transformer-XH or temporal knowledge graphs) on the same benchmark to confirm whether the generalization cliff persists when temporal structure is explicitly modeled

2. **Domain transfer**: Apply the benchmark methodology to a different procedural domain (e.g., robotic manipulation tasks) to assess whether the observed patterns hold beyond ALFWorld's kitchen-cleaning context

3. **Judge consistency**: Conduct human evaluations on a subset of retrievals to validate the reliability and consistency of the LLM-as-judge scoring mechanism