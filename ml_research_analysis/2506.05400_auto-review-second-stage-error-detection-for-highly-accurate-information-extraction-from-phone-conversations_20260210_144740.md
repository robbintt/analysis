---
ver: rpa2
title: 'Auto Review: Second Stage Error Detection for Highly Accurate Information
  Extraction from Phone Conversations'
arxiv_id: '2506.05400'
source_url: https://arxiv.org/abs/2506.05400
tags:
- transcript
- name
- correct
- error
- field
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents Auto Review, a two-stage pipeline for highly
  accurate information extraction from healthcare benefit verification phone calls.
  The system addresses the challenge of extracting correct field values from noisy
  ASR transcripts, which is critical for patient healthcare journeys.
---

# Auto Review: Second Stage Error Detection for Highly Accurate Information Extraction from Phone Conversations

## Quick Facts
- arXiv ID: 2506.05400
- Source URL: https://arxiv.org/abs/2506.05400
- Reference count: 38
- Primary result: Two-stage pipeline using pseudo-labeling with multiple ASR alternatives and LLMs significantly improves information extraction accuracy from healthcare phone calls

## Executive Summary
Auto Review presents a two-stage pipeline for extracting highly accurate information from healthcare benefit verification phone conversations. The system addresses the challenge of noisy ASR transcripts by employing a pseudo-labeling approach that generates corrected transcripts without requiring manually corrected data. By leveraging multiple ASR alternatives and Large Language Models, Auto Review substantially improves transcript quality and reduces manual human review effort while maintaining high accuracy for domain-specific information extraction.

## Method Summary
The Auto Review system employs a two-stage pipeline that first generates multiple ASR alternatives for phone conversation transcripts, then applies pseudo-labeling with Large Language Models to create corrected transcripts. The pseudo-labeling approach allows the system to learn from noisy data without requiring manually corrected examples. The pipeline can be implemented with either general-purpose LLMs or feature-based model architectures, with both approaches showing substantial improvements in transcript quality and downstream information extraction accuracy.

## Key Results
- Substantial improvements in corrected call transcript quality through pseudo-labeling approach
- Significant reduction in manual human review effort while maintaining high accuracy
- Particularly effective for domain-specific jargon including agent names and group numbers

## Why This Works (Mechanism)
The system's effectiveness stems from combining multiple ASR hypotheses with LLM-based pseudo-labeling to create a more robust transcript correction mechanism. By using multiple ASR alternatives, the system captures different interpretations of the same conversation, allowing the LLM to identify and correct errors that any single ASR system might miss. The pseudo-labeling approach eliminates the need for expensive manual transcript correction while still enabling the system to learn from its own corrections.

## Foundational Learning
- ASR alternatives generation: Why needed - provides multiple interpretations of same conversation; Quick check - verify multiple ASR outputs differ meaningfully
- Pseudo-labeling technique: Why needed - enables learning from noisy data without manual corrections; Quick check - ensure pseudo-labels are sufficiently accurate
- LLM-based correction: Why needed - leverages large language understanding for error detection and correction; Quick check - validate correction quality against ground truth
- Domain-specific terminology handling: Why needed - critical for healthcare benefit verification accuracy; Quick check - measure performance on specialized vocabulary
- Information extraction pipeline: Why needed - transforms corrected transcripts into structured data; Quick check - verify extraction accuracy metrics

## Architecture Onboarding

Component map: ASR Systems -> Pseudo-Label Generator -> LLM Corrector -> Information Extractor -> Validation Layer

Critical path: The core workflow processes multiple ASR outputs through the pseudo-labeling stage, where an LLM generates corrected transcripts by reconciling differences between ASR alternatives. These corrected transcripts then flow to the information extraction component, which identifies and structures relevant fields. The validation layer provides confidence scores and flags uncertain extractions for potential human review.

Design tradeoffs: The system trades computational overhead (processing multiple ASR outputs and LLM corrections) for accuracy gains, eliminating the need for manual transcript correction. Using proprietary healthcare data limits generalizability but ensures domain relevance. The pseudo-labeling approach requires careful calibration to avoid propagating errors.

Failure signatures: Performance degradation may occur when ASR alternatives are consistently wrong, when domain-specific jargon is poorly represented in LLM training data, or when conversation context is insufficient for disambiguation. System may struggle with heavy accents, background noise, or rapid speech patterns that all ASR systems miss.

First experiments: 1) Compare extraction accuracy using single ASR vs. multiple ASR alternatives 2) Measure pseudo-label quality against human-corrected transcripts 3) Evaluate domain-specific term recognition before and after correction

## Open Questions the Paper Calls Out
None

## Limitations
- No specific performance metrics provided for information extraction accuracy improvements
- Reliance on proprietary healthcare benefit verification data limits generalizability
- Effectiveness depends heavily on quality of multiple ASR alternatives without detailed characterization of ASR systems used

## Confidence

| Claim | Confidence |
|-------|------------|
| Reduced manual human review effort while maintaining high accuracy | Medium |
| Substantial improvements in corrected transcript quality | Medium |
| Particularly effective for domain-specific jargon | Medium |

## Next Checks
1. Conduct ablation studies to measure individual contributions of multiple ASR alternatives versus LLM-based corrections
2. Test system on publicly available conversational datasets to assess cross-domain applicability
3. Implement human evaluation study comparing two-stage pipeline accuracy against single-stage approaches with inter-annotator agreement metrics