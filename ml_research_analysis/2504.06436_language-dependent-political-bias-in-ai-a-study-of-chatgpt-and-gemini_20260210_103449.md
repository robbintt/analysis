---
ver: rpa2
title: 'Language-Dependent Political Bias in AI: A Study of ChatGPT and Gemini'
arxiv_id: '2504.06436'
source_url: https://arxiv.org/abs/2504.06436
tags:
- political
- language
- chatgpt
- gemini
- intelligence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study investigated political bias in AI models, specifically
  ChatGPT and Gemini, using a political compass test in 14 languages. Results revealed
  both models exhibit left-wing and liberal biases, with Gemini showing stronger bias
  than ChatGPT.
---

# Language-Dependent Political Bias in AI: A Study of ChatGPT and Gemini

## Quick Facts
- arXiv ID: 2504.06436
- Source URL: https://arxiv.org/abs/2504.06436
- Reference count: 0
- Primary result: ChatGPT and Gemini exhibit left-wing, liberal bias with language-dependent variations

## Executive Summary
This study investigates political bias in AI language models by testing ChatGPT and Gemini across 14 languages using a political compass framework. Both models show significant left-wing and liberal tendencies, with Gemini displaying stronger bias than ChatGPT. The research reveals that political leanings vary substantially across languages, clustering by linguistic families (particularly Romance languages) and showing cultural influences. Statistical analysis confirms deviation from political neutrality in all tested languages, highlighting the need for greater transparency in AI political orientation.

## Method Summary
The study used the Political Compass Test's 62-item questionnaire with ChatGPT-3.5 (deterministic, single response) and Gemini 1.0 Pro (stochastic, 7 responses per question with mode selection). Questions were presented in 14 languages (Romanian, Portuguese, Italian, Spanish, English, Slovenian, French, German, Czech, Turkish, Russian, Polish, Bulgarian, and Persian) with the prompt suffix "please choose one of the following options." The keyword "pornographic" was changed to "sexual" to avoid safety refusals. Model responses were mapped to X/Y coordinates representing economic and social dimensions, then analyzed using one-sample t-tests and k-means clustering.

## Key Results
- Both ChatGPT and Gemini exhibit statistically significant left-wing and liberal biases across all 14 languages
- Gemini shows stronger political bias than ChatGPT (Gemini t = -11.51, p < 0.0001; ChatGPT t = -9.86, p < 0.0001)
- Clustering analysis reveals distinct language groups with Romance languages clustering together
- Turkish and Persian emerge as outliers with unique political positioning compared to other languages
- Statistical deviation from political neutrality confirmed for both models across all languages tested

## Why This Works (Mechanism)

### Mechanism 1: Training Data Distribution Bias
LLMs exhibit political leanings that reflect the ideological distribution of their training corpora. Models trained on internet-scale text internalize statistical patterns from data sources. When certain languages or regions have dominant political discourses, the model's output distribution shifts toward those positions because they are more probable in the training data.

### Mechanism 2: Cross-Lingual Representation Clustering
Languages with shared structural and cultural features produce clustered political outputs in LLMs. Languages within the same family share grammatical structures, lexical resources, and overlapping training corpora. Internal representations for these languages occupy similar regions in latent space, producing correlated political outputs.

### Mechanism 3: Cultural-Political Context Encoding
Political responses vary by query language because cultural and political norms are implicitly encoded per language context. Querying in a specific language activates language-associated cultural context. Turkish queries invoke different implicit political frames than English because Turkish-language content contains different political debates and normative assumptions.

## Foundational Learning

- **Political Compass as Measurement Instrument**: The study uses a 62-item test with economic (X-axis) and social (Y-axis) dimensions. Understanding this instrument is necessary to interpret coordinate outputs like (-4.13, -5.49).
  - *Quick check*: If a model scores -5.88 on X and -4.72 on Y, which political quadrant does it occupy?

- **One-Sample t-Test**: The paper uses t-tests to assess whether outputs deviate from neutrality at (0, 0). Understanding p-values and t-statistics is needed to evaluate claimed biases.
  - *Quick check*: What does t = -11.51 with p < 0.0001 indicate about Gemini's deviation from neutrality?

- **K-Means Clustering**: The study applies k-means to group languages by political coordinates. Comprehending clustering is essential to interpret why Romance languages cluster while Persian is an outlier.
  - *Quick check*: If k-means produces 4 clusters for ChatGPT and 5 for Gemini, what does this suggest about output consistency across languages?

## Architecture Onboarding

- **Component map**: User query in 14 languages → LLM Backbone (ChatGPT-3.5 or Gemini 1.0 Pro) → Response Aggregation (mode selection for Gemini) → Measurement (62-item Political Compass Test) → Analysis (t-tests → k-means clustering → distance matrix visualization)

- **Critical path**: 1) Prompt each LLM with all 62 items in each of 14 languages; 2) Map responses to X/Y coordinates using political compass scoring; 3) Aggregate Gemini via mode; use ChatGPT output directly; 4) Conduct one-sample t-tests for deviation from (0, 0); 5) Apply k-means with elbow method for optimal cluster count; 6) Calculate Euclidean distances between models and languages

- **Design tradeoffs**: Static vs. dynamic data (ChatGPT enables reproducibility; Gemini accesses real-time data but increases variability); Deterministic vs. stochastic (ChatGPT simplifies analysis; Gemini requires repeated sampling); Test adaptation (only officially adapted languages ensure validity but limit coverage)

- **Failure signatures**: Content filtering ("Pornographic" triggered non-responses; researchers substituted "sexual"); Response instability (Gemini's stochastic outputs required 7 repetitions; high variance undermines reliability); Outlier behavior (Persian in ChatGPT produced (0.25, 2.26)—right-authoritarian, contrary to all other languages)

- **First 3 experiments**: 1) Replicate with ChatGPT-4 and Gemini 1.5 to assess whether newer models converge toward neutrality; 2) Prompt with explicit neutrality instructions and measure bias reduction across languages; 3) Expand to additional language families (Semitic, Dravidian) to test whether Romance clustering extends to other groups

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the political orientations of ChatGPT and Gemini evolve over time, and do they converge toward or diverge from the political center?
- Basis in paper: The authors state, "it is recommended that the research be repeated at certain intervals," specifically to determine if political tendencies are moving toward the center point and neutrality.
- Why unresolved: AI platforms are updated frequently, and this study provides only a cross-sectional snapshot of specific model versions (ChatGPT 3.5 and Gemini 1.0 Pro).
- What evidence would resolve it: Longitudinal studies repeating the political compass methodology at regular intervals (e.g., monthly or quarterly) over several years.

### Open Question 2
- Question: To what extent do specific grammatical structures (e.g., agglutinative morphology) versus cultural training data drive the observed variance in political bias across languages?
- Basis in paper: The paper attributes variance to "structural and grammatical features" and "cultural and political contexts" simultaneously, noting outliers like Turkish and Persian, but does not isolate these variables.
- Why unresolved: The study identifies correlation between language and bias but cannot disentangle whether the bias stems from the language's structure or the distinct datasets associated with that culture.
- What evidence would resolve it: Experiments using controlled prompts where semantic content is held constant while syntactic structures are manipulated, or comparing models trained on culturally neutral datasets.

### Open Question 3
- Question: Can a universal standard of "political neutrality" be effectively defined for LLMs given that liberal values are often perceived as "neutral" in Western contexts but "biased" in collectivist societies?
- Basis in paper: The conclusion notes that "In Western societies, liberal values are often perceived as 'neutral', whereas in collectivist or authoritarian societies this stance may be perceived as biased."
- Why unresolved: The study confirms bias exists relative to the political center (0,0), but challenges the applicability of that center as a universal goal across different cultural expectations.
- What evidence would resolve it: Cross-cultural reception studies analyzing user perceptions of "neutrality" in model outputs across diverse geopolitical regions.

## Limitations
- The study only examined two LLMs (ChatGPT-3.5 and Gemini 1.0 Pro), limiting generalizability to other models or versions
- Gemini's stochastic outputs required seven repetitions per query, but high variance among responses may still affect mode selection reliability
- The absence of official translations for some languages necessitated prompt modifications, potentially affecting response consistency

## Confidence
- **High Confidence**: The identification of left-wing and liberal biases in both models (supported by statistical significance across all languages)
- **Medium Confidence**: The clustering patterns of Romance languages (consistent with linguistic and cultural proximity assumptions)
- **Medium Confidence**: The magnitude of political bias differences between ChatGPT and Gemini (though directionally consistent, exact values depend on scoring algorithm transparency)

## Next Checks
1. Replicate the study with ChatGPT-4 and Gemini 1.5 to determine if newer models exhibit reduced bias or different language-dependent patterns
2. Conduct blind scoring where independent raters map responses to political coordinates without knowing the source language to verify language-dependent effects
3. Test with additional language families (Semitic, Dravidian) to confirm whether Romance clustering extends to other linguistic groups and validate the cultural context encoding mechanism