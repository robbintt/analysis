---
ver: rpa2
title: Density Ratio-based Proxy Causal Learning Without Density Ratios
arxiv_id: '2503.08371'
source_url: https://arxiv.org/abs/2503.08371
tags:
- kernel
- proxy
- assumption
- where
- function
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of causal effect estimation in the
  presence of unobserved confounding by introducing a novel treatment bridge function-based
  approach called Kernel Alternative Proxy. Unlike previous methods that rely on outcome
  bridge functions or explicit density ratio estimation, this method bypasses density
  ratio estimation entirely, making it practical for continuous and high-dimensional
  treatments.
---

# Density Ratio-based Proxy Causal Learning Without Density Ratios

## Quick Facts
- **arXiv ID**: 2503.08371
- **Source URL**: https://arxiv.org/abs/2503.08371
- **Reference count**: 40
- **Primary result**: Novel treatment bridge function approach that bypasses density ratio estimation, enabling causal effect estimation with continuous and high-dimensional treatments while demonstrating superior performance to existing proxy causal learning methods.

## Executive Summary
This paper introduces Kernel Alternative Proxy (KAP), a novel approach to proxy causal learning that estimates treatment effects in the presence of unobserved confounding without explicitly computing density ratios. The method reformulates the causal estimation problem using treatment bridge functions and kernel ridge regression in reproducing kernel Hilbert spaces. By decomposing the optimization objective into decoupled expectations, KAP avoids the computational and statistical challenges of density ratio estimation that plague existing methods. The authors prove consistency guarantees and demonstrate that KAP outperforms or matches existing proxy causal learning techniques on both synthetic and real-world datasets, including high-dimensional image treatments and legal abortion-crime data.

## Method Summary
The authors propose a three-stage kernel regression framework that estimates causal effects by learning a treatment bridge function in an RKHS without explicit density ratio estimation. Stage 1 uses conditional mean embeddings to map treatment-proxy pairs to treatment variables. Stage 2 estimates the bridge function by solving a reformulated least-squares problem that decomposes into decoupled expectations, avoiding density ratio computation. Stage 3 computes the final causal estimate through kernel ridge regression. The method provides closed-form solutions at each stage and is particularly effective when outcome proxies are more informative than treatment proxies.

## Key Results
- Bypasses explicit density ratio estimation through expectation decomposition, enabling continuous and high-dimensional treatment applications
- Derives closed-form solutions using kernel ridge regression and conditional mean embeddings in RKHS
- Proves consistency guarantees for the proposed method
- Demonstrates superior or comparable performance to existing frameworks on synthetic and real-world datasets including dSprite images and legal abortion-crime data
- Shows effectiveness particularly when outcome proxies are more informative than treatment proxies

## Why This Works (Mechanism)

### Mechanism 1: Bypassing Density Ratios via Decoupled Expectations
The method reformulates the least-squares objective to decompose integrals involving density ratios into products of expectations, enabling use of U-statistics for the second-stage regression. This eliminates the need for explicit density ratio estimation while maintaining the same underlying statistical assumptions.

### Mechanism 2: Identification via Treatment Bridge Weighting
The causal dose-response curve is identified through conditional expectation involving weighted outcomes, where weights are determined by the treatment proxy. The treatment bridge function satisfies a functional equation that serves as an inverse propensity score-like weight derived from proxies.

### Mechanism 3: Closed-Form Kernel Ridge Regression
By assuming the bridge function lies in an RKHS, the authors use kernel ridge regression to solve the inverse problem, yielding closed-form solutions expressed in terms of kernel matrices and regularization parameters.

## Foundational Learning

- **Concept: Proxy Causal Learning (PCL) & Negative Controls**
  - Why needed: Understanding the DAG where unobserved confounder U affects both Treatment A and Outcome Y, and how PCL uses causally related proxies Z and W to disentangle causal effects
  - Quick check: Can you distinguish why Z (treatment proxy) is distinct from W (outcome proxy) in the causal graph?

- **Concept: Conditional Mean Embeddings (CME)**
  - Why needed: Stage 1 estimates conditional mean embedding μ_{Z|W,A}, allowing kernel methods to operate on conditional distributions without density estimation
  - Quick check: How does CME represent E[φ(Z)|W=w, A=a] as an element in an RKHS?

- **Concept: Bridge Functions (Fredholm Integral Equations)**
  - Why needed: The core method solves for a bridge function connecting proxy distributions to causal queries, an ill-posed inverse problem solved via regularization
  - Quick check: Why is regularization necessary when solving for the bridge function in finite samples?

## Architecture Onboarding

- **Component map**: Dataset {A, Y, Z, W} -> Stage 1 (CME Estimation) -> Stage 2 (Bridge Estimation) -> Stage 3 (Causal Estimation)
- **Critical path**: Stage 2 regression is the novel component consuming CMEs from Stage 1; errors from under-regularized Stage 1 propagate to invalidate Stage 3 results
- **Design tradeoffs**: Treatment-Bridge vs Outcome-Bridge - use treatment-bridge when outcome proxies W are more informative than treatment proxies Z; otherwise use outcome-bridge methods
- **Failure signatures**: Violation of completeness assumption causes unstable bridge function solutions; density ratio collapse occurs when support of p(A|W) is effectively empty
- **First 3 experiments**: 
  1. Replicate Figure 2a synthetic low-dimensional test to verify MSE decreases with sample size
  2. Generate data where W is noisy vs Z is noisy to confirm method outperforms outcome-bridge methods only when W is informative
  3. Run dSprite experiment with images as treatments to validate handling of high-dimensional A

## Open Questions the Paper Calls Out

- Can alternative spectral regularization techniques achieve optimal rates for bridge functions with smoothness β_i > 3? Current Tikhonov regularization limits performance gains for functions with smoothness beyond β_i=3.

- What are the theoretical trade-offs between treatment and outcome bridge methods regarding robustness to violations of completeness and existence assumptions? Empirical evidence suggests differing robustness, but formal theoretical characterization is missing.

- Why does the proposed method empirically outperform outcome bridge methods despite a theoretical disadvantage in third-stage convergence rates? It's unclear if "ease of estimation" fully compensates for the theoretical rate gap in finite samples.

## Limitations

- Density ratio-free claim is context-dependent - the method avoids explicit density ratio estimation but relies on the same conditional independence assumptions as density ratio methods
- Completeness assumption vulnerability - the method's identification relies on completeness of proxy variables which is untestable in practice
- Computational scaling challenges - the three-stage kernel regression pipeline has cubic complexity in sample size

## Confidence

- **High confidence**: The theoretical framework (RKHS representation, Fredholm equation formulation) is mathematically sound and the closed-form solutions are correctly derived
- **Medium confidence**: Empirical performance claims - the method shows strong results on synthetic and real data, but comparison framework only includes a limited set of baselines
- **Low confidence**: Completeness assumption implications - the paper acknowledges this is untestable, but practical consequences for real-world applications are not fully characterized

## Next Checks

1. **Support overlap sensitivity test** - Systematically vary the overlap between treatment distributions conditioned on proxy values to quantify how violations of the overlap assumption affect estimation accuracy.

2. **High-dimensional proxy stress test** - Evaluate performance as dimensionality of both treatment and proxy variables increases, using subsampling or random Fourier feature approximations to manage computational cost.

3. **Outcome bridge function comparison** - Implement and compare against outcome bridge function methods (KPV/KNC) on datasets where treatment proxies are actually more informative than outcome proxies.