---
ver: rpa2
title: Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy
  Recommendation
arxiv_id: '2507.10911'
source_url: https://arxiv.org/abs/2507.10911
tags:
- clinical
- conflicts
- case
- systems
- ratio
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explored LLM-based multi-agent systems for therapy recommendations
  in multimorbidity cases, simulating multidisciplinary team collaboration. Four LLM
  models were evaluated using a conflict resolution workflow involving a general practitioner
  coordinating specialist agents.
---

# Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation

## Quick Facts
- arXiv ID: 2507.10911
- Source URL: https://arxiv.org/abs/2507.10911
- Reference count: 0
- Primary result: Multi-agent LLM systems show promise in reducing conflicts while maintaining medication levels, though current models show limitations in completeness and clinical reasoning

## Executive Summary
This study evaluated four LLM models using a multi-agent conflict resolution workflow for therapy recommendations in multimorbidity cases. The system simulated multidisciplinary team collaboration with a general practitioner coordinating specialist agents. Compared to single-agent approaches, multi-agent systems demonstrated improved conflict resolution while maintaining medication levels and aligning with expert judgment. However, current LLMs exhibited limitations in completeness and clinical reasoning, with most errors being omissions rather than commissions.

## Method Summary
The study evaluated LLM-based multi-agent systems for therapy recommendations in multimorbidity cases through a conflict resolution workflow. Four LLM models were tested, simulating multidisciplinary team collaboration where a general practitioner coordinated specialist agents. The evaluation used synthetic case studies with 6 medications per case, measuring correctness, completeness, DDI ratio, contraindication ratio, and medication ratio. Single-agent systems with intermediate reasoning were compared against multi-agent systems to assess performance differences.

## Key Results
- Multi-agent systems showed promise in reducing conflicts while maintaining medication levels
- Single-agent systems with intermediate reasoning performed comparably to multi-agent systems
- Most LLM errors were omissions rather than commissions
- Current LLMs rarely cite clinical guidelines or explain dosing decisions without structured prompting

## Why This Works (Mechanism)
Multi-agent collaboration improves conflict resolution by distributing clinical expertise across specialist agents, allowing for more comprehensive evaluation of medication interactions and contraindications. The general practitioner coordinator can synthesize recommendations from multiple perspectives, potentially identifying conflicts that single agents might miss. However, the effectiveness depends critically on each agent's ability to provide complete and accurate recommendations, which current LLMs struggle with due to limitations in clinical reasoning and knowledge retrieval.

## Foundational Learning
- Conflict resolution workflow: Needed to simulate multidisciplinary team collaboration and improve recommendation quality
- Evaluation metrics (correctness, completeness, DDI ratio): Required to systematically compare different LLM approaches
- Synthetic case generation: Necessary to create controlled test environments with known ground truth
- Medication interaction knowledge: Critical for accurate therapy recommendations in polypharmacy
- Clinical reasoning limitations: Important to understand model constraints and error patterns

## Architecture Onboarding
**Component Map:** Case Input -> Multi-agent System (GP + Specialists) -> Conflict Resolution -> Recommendation Output

**Critical Path:** Patient case data → GP agent → Specialist agents → Recommendation synthesis → Output validation

**Design Tradeoffs:** Multi-agent complexity vs. single-agent simplicity; completeness vs. computational cost; guideline adherence vs. model flexibility

**Failure Signatures:** Omissions of medications rather than incorrect additions; incomplete reasoning; failure to suggest appropriate substitutions

**First Experiments:**
1. Compare single-agent vs. multi-agent performance on synthetic cases
2. Test different LLM models within the multi-agent framework
3. Evaluate impact of intermediate reasoning steps on recommendation quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does multi-agent collaboration provide meaningful advantages over single-agent systems with intermediate reasoning as LLM capabilities improve?
- Basis in paper: [explicit] The authors state "with current LLMs, a single agent GP performs as well as MDTs" but note "this needs to be evaluated again in the future as LLMs evolve."
- Why unresolved: Current LLM limitations (omissions, incomplete reasoning) may mask potential benefits of multi-agent architectures that could emerge with more capable models.
- What evidence would resolve it: Longitudinal evaluation using the same benchmark as newer LLM versions are released, tracking whether performance gaps between single-agent and multi-agent systems widen or narrow.

### Open Question 2
- Question: Can retrieval-augmented generation (RAG) frameworks or medical-specialized foundation models improve the completeness and guideline adherence of LLM-based therapy recommendations?
- Basis in paper: [explicit] The authors note "LLMs rarely cite clinical guidelines or explain dosing decisions without structured prompting" and suggest "incorporating retrieval-augmented generation (RAG) frameworks or leveraging medical-specialized foundation models."
- Why unresolved: Current models rely on pretrained knowledge without explicit citation, and their ability to leverage clinical literature depends critically on prompt framing.
- What evidence would resolve it: Comparative study of standard LLMs versus RAG-enhanced or medically fine-tuned models on the same benchmark, measuring improvements in completeness scores and guideline citation rates.

### Open Question 3
- Question: What mechanisms can enable LLM-based CDSS to generate comprehensive multi-option recommendations rather than single-best-answer outputs?
- Basis in paper: [explicit] The authors state "A good CDSS should not only identify one preferred solution, but rather present the full range of appropriate options" and note that "LLM-generated recommendations didn't include all valid therapeutic options."
- Why unresolved: Current architectures and prompting strategies optimize for single outputs rather than enumerating clinically acceptable alternatives with preference rankings.
- What evidence would resolve it: Development and testing of prompt architectures or decoding strategies explicitly designed for multi-option generation, evaluated on ability to produce complete option sets matching gold standards.

### Open Question 4
- Question: How can the conflict resolution workflow be optimized when base models lack capability to suggest appropriate medication substitutions?
- Basis in paper: [explicit] The authors observe that "some LLM agents were capable of recommending appropriate substitutions, we observed that others tended to recommend adding or removing medications but struggled to suggest suitable alternatives."
- Why unresolved: Substitution decisions require integrating knowledge about therapeutic equivalence, contraindications, and patient-specific factors in ways that current models handle inconsistently.
- What evidence would resolve it: Analysis of substitution failure patterns across models and cases, followed by targeted interventions (specialized prompting, fine-tuning, or tool use) with pre-post comparison of substitution success rates.

## Limitations
- Synthetic case studies rather than real patient data
- Limited sample size (5 cases)
- Potential bias from synthetic ground truth generation
- Lack of real-world validation with clinicians

## Confidence
- **High Confidence**: Multi-agent systems can reduce conflicts while maintaining medication levels compared to single-agent approaches
- **Medium Confidence**: Current LLMs show limitations in completeness and clinical reasoning, with most errors being omissions rather than commissions
- **Low Confidence**: Claims about comparable performance between single-agent intermediate reasoning and multi-agent systems due to small sample size and synthetic case limitations

## Next Checks
1. Validate findings using real patient cases from electronic health records with clinician oversight
2. Conduct prospective clinical studies comparing LLM recommendations with standard care outcomes
3. Expand evaluation to include broader medication classes and more complex polypharmacy scenarios with larger sample sizes