---
ver: rpa2
title: 'Symbolic Knowledge Extraction and Injection with Sub-symbolic Predictors:
  A Systematic Literature Review'
arxiv_id: '2501.14836'
source_url: https://arxiv.org/abs/2501.14836
tags:
- https
- knowledge
- learning
- methods
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This systematic literature review synthesizes 132 symbolic knowledge
  extraction (SKE) and 117 symbolic knowledge injection (SKI) methods from 40+ years
  of research, categorizing them by predictor types, data formats, output expressiveness,
  and injection strategies. SKE methods primarily target neural networks and support
  vector machines using pedagogical (black-box) or decompositional (white-box) approaches,
  producing propositional rules, decision trees, or knowledge graphs.
---

# Symbolic Knowledge Extraction and Injection with Sub-symbolic Predictors: A Systematic Literature Review

## Quick Facts
- arXiv ID: 2501.14836
- Source URL: https://arxiv.org/abs/2501.14836
- Reference count: 40
- Primary result: Synthesizes 132 SKE and 117 SKI methods into taxonomies covering predictor types, data formats, output expressiveness, and injection strategies.

## Executive Summary
This systematic literature review analyzes 40+ years of research on symbolic knowledge extraction (SKE) and symbolic knowledge injection (SKI) methods for sub-symbolic predictors like neural networks. The review identifies 249 primary works, categorizing SKE methods by translucency (pedagogical vs. decompositional) and output formats (rules, trees, knowledge graphs), and SKI methods by injection strategies (structuring, embedding, guided learning) and knowledge types (knowledge graphs, FOL). A key finding is the chronological shift from SKE dominance (1980s-2010s) to SKI growth (post-2015), driven by deep learning advances. Only 34.9% of methods have runnable software implementations, highlighting a technology readiness gap. These taxonomies provide a framework for selecting appropriate SKE/SKI methods and identifying research opportunities in explainable AI.

## Method Summary
The authors conducted a systematic literature review using 5 search queries executed on Google Scholar, Scopus, Springer Link, ACM DL, and DBLP. They identified 249 primary works (132 SKE, 117 SKI) by examining the first two pages of results per query and recursively exploring bibliographies of 11 secondary works. The review employed a Goal-Question-Metric approach to classify methods by translucency, strategy, and software availability. Key taxonomies include SKE methods targeting neural networks and SVMs using pedagogical or decompositional approaches, and SKI methods employing predictor structuring, knowledge embedding, or guided learning to inject knowledge into neural networks.

## Key Results
- 132 SKE methods primarily target neural networks and SVMs, producing propositional rules, decision trees, or knowledge graphs
- 117 SKI methods predominantly use knowledge graphs or first-order logic, injecting knowledge into neural networks via structuring, embedding, or guided learning
- Chronological shift from SKE dominance (1980s-2010s) to SKI growth (post-2015) driven by deep learning advances
- Only 34.9% of methods have runnable software implementations, highlighting technology readiness gap

## Why This Works (Mechanism)

### Mechanism 1
- Claim: IF a SKE method is applied to a trained sub-symbolic predictor, THEN it may produce an intelligible symbolic representation that approximates the predictor's behavior, PROVIDED the extraction achieves high fidelity.
- Mechanism: SKE algorithms query or inspect trained predictors to distill decision logic into symbolic forms like rules or trees, transforming opaque models into inspectable surrogates.
- Core assumption: Extracted symbolic knowledge can meaningfully capture the predictor's functional mapping without prohibitive accuracy loss.
- Evidence anchors: [abstract], [section 3.1.1]
- Break condition: If extracted knowledge has low fidelity or is too complex to be human-interpretable.

### Mechanism 2
- Claim: IF an SKI method incorporates symbolic knowledge into a sub-symbolic predictor, THEN the predictor's behavior may become more constrained or aligned with that knowledge, PROVIDED the injection strategy is compatible with the predictor's architecture.
- Mechanism: SKI methods enforce consistency via predictor structuring (mirroring symbolic logic in topology), knowledge embedding (converting symbols to vectors), or guided learning (penalizing violations during training).
- Core assumption: Symbolic knowledge is correct, relevant, and can be faithfully represented within the predictor's computational framework.
- Evidence anchors: [abstract], [section 3.1.2]
- Break condition: If symbolic knowledge conflicts with training data or injection introduces optimization instabilities.

### Mechanism 3
- Claim: IF SKE and SKI are combined iteratively, THEN they can form a debugging loop where extracted knowledge is edited and re-injected to refine the predictor, PROVIDED the human expert correctly interprets and fixes the extracted knowledge.
- Mechanism: The "train-extract-fix-inject" (TEFI) loop uses SKE to expose predictor logic, allows human editing of symbolic knowledge, and uses SKI to re-incorporate fixes for iterative refinement without full retraining.
- Core assumption: Human experts can accurately identify and correct errors in extracted symbolic knowledge, and SKI can translate corrections into effective predictor adjustments.
- Evidence anchors: [section 5.4.1]
- Break condition: If expert misinterprets extracted knowledge or SKI cannot precisely encode edited knowledge.

## Foundational Learning

**Concept: Sub-symbolic vs. Symbolic AI**
- Why needed here: The paper contrasts opaque sub-symbolic predictors (e.g., neural networks) with intelligible symbolic representations (e.g., logic rules), essential for understanding SKE/SKI goals.
- Quick check question: Can you explain why a neural network is considered sub-symbolic while a decision tree is considered symbolic?

**Concept: Opacity and the interpretability-performance trade-off**
- Why needed here: The paper motivates SKE/SKI as solutions to opacity of high-performing but inscrutable models, clarifying design goals.
- Quick check question: Why might a highly accurate deep neural network be unusable in a safety-critical application?

**Concept: First-Order Logic (FOL) and its subsets**
- Why needed here: SKE/SKI often involve logic formalisms. The review covers methods using FOL, knowledge graphs, etc.
- Quick check question: What is a key difference between propositional logic and first-order logic in terms of expressiveness?

## Architecture Onboarding

**Component map:** SKE: Translucency (pedagogical → decompositional) → Input Data Type → Output Shape/Expressiveness. SKI: Input Knowledge Type → Injection Strategy (structuring → embedding → guided learning) → Target Predictor → Purpose (manipulation → enrich).

**Critical path:** 1) Select predictor (commonly NN, SVM). 2) Choose SKE/SKI method based on needs (e.g., human-readable rules? Try pedagogical SKE. Expert rules? Consider SKI via guided learning). 3) Implement or integrate existing software (only ~35% have runnable code). 4) Evaluate fidelity/consistency and usability.

**Design tradeoffs:**
- **Generality vs. precision:** Pedagogical SKE works on any predictor but may be less precise than decompositional methods exploiting internal structure.
- **Expressiveness vs. tractability:** Extracting/injecting rich FOL knowledge is hard; most methods use simpler logics (propositional, knowledge graphs).
- **Software availability vs. recency:** Many foundational SKE methods lack modern code; newer SKI methods often have experimental implementations.

**Failure signatures:**
- Low fidelity in SKE output (e.g., extracted rules misclassify many examples)
- Poor consistency after SKI (e.g., predictor violates injected knowledge)
- Excessive complexity in extracted symbolic knowledge, hindering interpretability

**First 3 experiments:**
1. Implement pedagogical SKE: Train neural network on Iris dataset, generate rule list using CART, measure fidelity.
2. Experiment with SKI via embedding: Embed country capitals knowledge graph using TransE, use as additional input features for neural network on related classification task.
3. Test basic TEFI loop: After Experiment 1, manually edit incorrect extracted rule, use SKI to penalize violations in loss function, fine-tune network, assess performance improvement.

## Open Questions the Paper Calls Out
None

## Limitations
- Search reproducibility is limited due to evolving search indices and unspecified execution dates, making exact 249 primary works unreproducible
- Classification into taxonomies sometimes relies on implicit methodological details not explicitly stated in primary sources
- Review does not directly evaluate functional claims of SKE/SKI methods—synthesizes reported outcomes rather than conducting empirical validation

## Confidence
- **High Confidence:** Characterization of SKE as transforming sub-symbolic predictor behavior into symbolic representations, and SKI as constraining predictor behavior via symbolic knowledge
- **Medium Confidence:** Claim that SKE dominated research until ~2010 and SKI grew post-2015 based on publication counts
- **Low Confidence:** Assertion that only 34.9% of methods have runnable software implementations due to incomplete availability data

## Next Checks
1. Reproduce classification boundaries: Independently classify 10 randomly sampled primary works into SKE/SKI categories and subcategories to assess inter-rater reliability
2. Test TEFI loop feasibility: Implement minimal end-to-end TEFI loop using publicly available datasets and open-source SKE/SKI tools to verify practical viability
3. Analyze software availability bias: Cross-reference 34.9% implementation rate with publication venues and years to determine if certain subfields systematically have higher implementation rates than others