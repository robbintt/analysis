---
ver: rpa2
title: Emergence of Phonemic, Syntactic, and Semantic Representations in Artificial
  Neural Networks
arxiv_id: '2601.18617'
source_url: https://arxiv.org/abs/2601.18617
tags:
- semantic
- syntactic
- probe
- language
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study investigates how phonemic, lexical, and syntactic linguistic
  structures emerge in the activation spaces of artificial neural networks during
  training, aiming to uncover the computational mechanisms underlying language acquisition.
  A generalized structural probe is developed to identify linear subspaces in neural
  network activations that encode distances corresponding to linguistic structures
  such as articulatory features, WordNet semantic graphs, and dependency syntax.
---

# Emergence of Phonemic, Syntactic, and Semantic Representations in Artificial Neural Networks

## Quick Facts
- **arXiv ID**: 2601.18617
- **Source URL**: https://arxiv.org/abs/2601.18617
- **Reference count**: 40
- **Primary result**: Self-supervised models develop distinct linear subspaces encoding phonemic, semantic, and syntactic structures, emerging sequentially during training.

## Executive Summary
This study investigates how linguistic structures emerge in the activation spaces of artificial neural networks during training. The authors develop a generalized structural probe to identify linear subspaces in neural network activations that encode distances corresponding to linguistic structures such as articulatory features, WordNet semantic graphs, and dependency syntax. The probe is applied to both speech-based (Wav2Vec 2.0) and text-based (Pythia, Llama 2) models across training checkpoints. Results show that speech models develop phonemic representations aligned with articulatory features in mid-to-late layers, while both speech and text models build subspaces representing lexical semantics and syntactic trees, with emergence occurring sequentially—phonemic first, followed by lexical-semantic, then syntactic. Performance scales with model size and training data, but requires 2-4 orders of magnitude more input than humans.

## Method Summary
The study extends Hewitt & Manning's (2019) structural probe to identify linear subspaces where activation distances correlate with linguistic structures. For each structure, a linear probe $B \in \mathbb{R}^{k \times p}$ is trained to minimize the difference between squared Euclidean distances in the projected space and gold-standard linguistic distances. The method is applied to three linguistic structures: phonemic (articulatory features), lexical semantic (WordNet hypernymy), and syntactic (dependency trees). Probes are trained on UD-EWT corpus for syntax, WordNet-Nouns for semantics, and TTS-synthesized speech with Montreal Forced Aligner timestamps for speech modalities. Evaluation uses Spearman correlation between predicted and gold distances across layers and training checkpoints.

## Key Results
- Phonemic representations emerge first in mid-to-late layers of speech models, aligning with articulatory features (vowel trapezium geometry).
- Both speech and text models develop subspaces for lexical semantics and syntactic trees, with semantic emergence preceding or concurrent with syntax.
- Emergence requires 2-4 orders of magnitude more input than humans, though scaling improves performance.
- Control experiments confirm representations are specific to linguistic content (French/music models show degraded scores).

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Self-supervised models organize linguistic features into distinct **linear subspaces** where the Euclidean geometry of activation vectors correlates with theoretical linguistic distances.
- **Mechanism**: A "Structural Probe" learns a linear transformation $B$ that projects high-dimensional activations into a lower-dimensional space. In this space, the squared Euclidean distance between vectors $||h_i B - h_j B||^2$ approximates the linguistic distance.
- **Core assumption**: Linguistic structures can be fully captured by metric systems, and the model learns to represent these relationships linearly to facilitate readout by downstream neurons.
- **Evidence anchors**: Abstract states neural activations build subspaces where geometry represents linguistic structure; Section 2.1 describes the optimization objective.

### Mechanism 2
- **Claim**: Linguistic representations emerge in a specific **sequential order** (Phonemic → Semantic/Syntactic) driven by data scale and model capacity.
- **Mechanism**: The self-supervised objective first solves lower-level acoustic clustering (phonemes) before building higher-order dependencies. This emergence is contingent on model size and data exposure.
- **Core assumption**: The staged developmental trajectory observed in humans is a necessary computational consequence of learning from speech/text statistics.
- **Evidence anchors**: Section 3.4 observes phonemic emergence followed by lexical semantic and finally syntactic abilities; Figure 5 shows phonemic scores rising before syntactic/semantic scores.

### Mechanism 3
- **Claim**: Linear readout accessibility ensures these structured representations are **functionally usable** by downstream attention mechanisms.
- **Mechanism**: By encoding information in linear subspaces, the model ensures that simple operations can extract complex linguistic relations without requiring non-linear decoding logic.
- **Core assumption**: Representation utility is defined by linear separability; if a subspace exists but cannot be linearly decoded, it is not considered a "representation."
- **Evidence anchors**: Section 2.1 states representations can be directly used by downstream neurons through simple linear readout; Section 4 discusses accessibility to attention mechanisms.

## Foundational Learning

- **Concept**: **Structural Probing (Hewitt & Manning, 2019)**
  - **Why needed here**: This paper generalizes this technique from syntax to phonemes and semantics. You must understand we are measuring if distances between tokens match a tree or graph, not classifying tokens.
  - **Quick check question**: Does a structural probe predict a label (e.g., "Noun") or a relational distance (e.g., "3 edges from the root")? (Answer: Relational distance).

- **Concept**: **Self-Supervised Learning (SSL) Objective**
  - **Why needed here**: The emergence is spontaneous ("self-supervised"), meaning no explicit labels were provided. Understanding what the model predicts explains why it must build these internal structures.
  - **Quick check question**: In Wav2Vec 2.0, is the model trained to classify phonemes, or to reconstruct masked latent representations? (Answer: Reconstruct latent representations).

- **Concept**: **Linear Subpace Geometry**
  - **Why needed here**: The paper relies on the idea that high-dimensional activation space contains intersecting planes (subspaces) that individually explain different variables.
  - **Quick check question**: If two subspaces are "orthogonal," does information in one subspace interfere with distances in the other? (Answer: No, ideally).

## Architecture Onboarding

- **Component map**: Raw Waveform/Text -> Transformer Backbone (Wav2Vec 2.0/Pythia/Llama) -> Hidden States -> Linear Probe (B) -> Projected Space with Linguistic Distances

- **Critical path**:
  1. **Input Processing**: Raw audio/text enters the Transformer backbone
  2. **Activation Extraction**: Capture hidden states at specific relative depths
  3. **Probe Training**: Train B to minimize | ||(h_i - h_j)B||^2 - d_gold |
  4. **Evaluation**: Spearman correlation between probe distances and linguistic theory distances

- **Design tradeoffs**:
  - **Probe Dimensionality**: 2D for visualization (Fig 2A), 200D for evaluation. 2D loses precision but recovers "shape" (e.g., vowel trapezium).
  - **Distance vs. Contrastive**: Paper uses distance-based probes (MSE) but validates with contrastive objectives. Distance is stricter on geometry; contrastive is stricter on topology.

- **Failure signatures**:
  - **Language Mismatch**: Wav2Vec 2.0 trained on French or Music achieving high phoneme scores on English data. (Mitigation: Strict control experiments shown in Fig 2D).
  - **Linear Tree Artifacts**: Models predicting linear neighbor-connections instead of true syntax. (Mitigation: Compare probe performance against a "linear tree" baseline).

- **First 3 experiments**:
  1. **Visual Validation**: Train a 2D structural probe on Wav2Vec 2.0 Base model using UD-EWT-TTS dataset. Confirm visually that vowel plot resembles vowel trapezium.
  2. **Control Run**: Evaluate phoneme probe on "random" or "music-trained" checkpoint. Verify Spearman correlation drops to ≈0.2.
  3. **Scaling Test**: Run syntactic probe across Pythia model sizes (70M vs 1.4B). Verify "U-shape" of syntactic score across layers shifts or improves.

## Open Questions the Paper Calls Out

- **Open Question 1**: Does lexical semantic structure genuinely precede or follow syntactic structure emergence during training? The study found phonemic representations emerge first, but the "partial emergence" of lexical semantics makes it difficult to definitively sequence the later stages relative to syntax.

- **Open Question 2**: Are the lexical semantic structures identified in audio models derived from abstract semantics or acoustic correlates? Control models trained on non-speech audio showed significant semantic scores, suggesting the probe may be detecting acoustic similarity rather than intended semantic hierarchy.

- **Open Question 3**: Are the identified linear subspaces functionally utilized by the model for downstream inference? The paper demonstrates structured representations exist and are linearly readable, but doesn't test whether perturbing these subspaces degrades downstream task performance.

## Limitations
- **Data efficiency gap**: Models require 2-4 orders of magnitude more input than humans, raising questions about the computational efficiency of the learning mechanisms.
- **Post-hoc analysis**: The study relies entirely on post-hoc linear probes rather than analyzing actual training dynamics or attention patterns.
- **Structural vs. functional**: The existence of probeable subspaces doesn't guarantee they're used for inference; they could be epiphenomenal.

## Confidence

**High Confidence**: The technical validity of the structural probe method and its successful application to multiple linguistic structures.

**Medium Confidence**: The emergence patterns across model sizes and training stages, and comparative performance across speech vs. text models.

**Low Confidence**: Claims about direct implications for human language acquisition mechanisms.

## Next Checks

**Validation Check 1**: Perform targeted ablation experiments where the identified subspaces are selectively perturbed during inference to measure actual downstream performance degradation.

**Validation Check 2**: Conduct controlled training experiments where the sequence of linguistic information presentation is varied to determine whether the observed emergence sequence is driven by data statistics or is an inherent property of learning dynamics.

**Validation Check 3**: Implement a non-linear control probe (e.g., small MLP) to test whether the linear subspace assumption is restrictive. If non-linear probes achieve significantly better reconstruction of linguistic distances, it would suggest representations are more complex than the linear model assumes.