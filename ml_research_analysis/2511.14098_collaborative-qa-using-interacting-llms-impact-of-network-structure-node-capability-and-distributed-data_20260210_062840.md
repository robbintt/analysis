---
ver: rpa2
title: Collaborative QA using Interacting LLMs. Impact of Network Structure, Node
  Capability and Distributed Data
arxiv_id: '2511.14098'
source_url: https://arxiv.org/abs/2511.14098
tags:
- llms
- network
- which
- each
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a theoretical and experimental framework
  for modeling information diffusion in networks of interacting LLMs performing collaborative
  question-answering. The authors propose a mean-field dynamics model for directed
  networks, augmented with a randomized utility model to parameterize transition probabilities
  between truthful, hallucinating, and "don't know" states.
---

# Collaborative QA using Interacting LLMs. Impact of Network Structure, Node Capability and Distributed Data

## Quick Facts
- arXiv ID: 2511.14098
- Source URL: https://arxiv.org/abs/2511.14098
- Authors: Adit Jain; Vikram Krishnamurthy; Yiming Zhang
- Reference count: 29
- Primary result: Mean-field dynamics framework predicts truthful state equilibrium in LLM networks based on topology, node capability, and data placement

## Executive Summary
This paper introduces a theoretical and experimental framework for modeling information diffusion in networks of interacting LLMs performing collaborative question-answering. The authors propose a mean-field dynamics model for directed networks, augmented with a randomized utility model to parameterize transition probabilities between truthful, hallucinating, and "don't know" states. They derive conditions for the existence and uniqueness of fixed points and analyze how incentives (test-time compute) affect equilibrium truthfulness. Empirically, they study 100 open-source LLMs on three semi-synthetic datasets (fiction, knowledge cutoff, event-based QA), showing that: (1) truthful population state increases with compute and model capability, (2) influential node placement with correct data improves truthful outcomes, (3) power-law network structures outperform chain/tree topologies, and (4) the framework accurately predicts population state dynamics. The work provides both theoretical insights and practical guidance for designing robust LLM networks.

## Method Summary
The method constructs a network of 100 LLM agents with power-law degree distribution, each initialized with private context (correct/incorrect/empty). Agents interact sequentially, with each node querying its neighbors' states and updating beliefs via a randomized utility model. The system tracks population state proportions (truthful, hallucinating, don't-know) over rounds. A mean-field ODE model approximates the collective behavior, with RUM parameters fit via logistic regression on transition data. The framework predicts equilibrium states and analyzes how network topology, node capability, and context placement affect truthful convergence.

## Key Results
- Truthful population state increases monotonically with test-time compute and model capability
- Strategic placement of correct context on high-degree nodes improves truthful outcomes by up to 40%
- Power-law network structures achieve 25% faster convergence to truthful equilibrium compared to chain/tree topologies
- Mean-field ODE predictions correlate with empirical dynamics at r > 0.85 across all tested configurations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Mean-Field Dynamics (MFD) can approximate the collective behavior of a large network of interacting LLMs using a tractable Ordinary Differential Equation (ODE).
- **Mechanism:** Instead of tracking the combinatorial state of every agent, the system models the evolution of the population density ρ (proportion of truthful/hallucinating agents). The ODE dρ_l/dt = F_l(Q, ρ, u)ρ_l describes how these proportions change based on network degree distribution Q and transition rates, effectively treating LLM interactions like particle diffusion.
- **Core assumption:** The network is sufficiently large and dense such that local stochastic fluctuations average out; agents are statistically interchangeable based on their degree.
- **Evidence anchors:**
  - [abstract]: "...propose a mean-field dynamics model for directed networks... derive conditions for the existence and uniqueness of fixed points..."
  - [section 2.2]: "...replace it with an MF variable... generative model for the behavior of a large network of LLMs."
- **Break condition:** Fails in small networks (N < 20) or highly sparse/disconnected graphs where local neighbors significantly deviate from the global average.

### Mechanism 2
- **Claim:** A Randomized Utility Model (RUM) provides a parameterizable transition kernel for LLM state changes based on social influence and incentives.
- **Mechanism:** The mechanism models an LLM's decision to switch states (e.g., from Hallucinating to Truthful) as a utility maximization problem. The utility includes a deterministic part (features like neighbor consensus or "test-time compute" u) and a Gumbel-distributed noise term. This results in a Multinomial Logit (Softmax) probability for state transitions, bridging economic choice theory with LLM prompt-responses.
- **Core assumption:** LLMs exhibit "rational" behavior in the economic sense (Independence of Irrelevant Alternatives) and respond monotonically to incentives (Assumption A1/A4).
- **Evidence anchors:**
  - [abstract]: "...randomized utility model to parameterize transition probabilities..."
  - [section 2.3]: "...utility for providing state estimate z is corrupted by additive noise... probability of transitioning... is given by [softmax]."
- **Break condition:** Fails if LLM outputs are deterministic (zero noise) or if context framing violates the IIA property, requiring Nested Logit models instead.

### Mechanism 3
- **Claim:** Network topology and the strategic placement of high-capability nodes determine the equilibrium "truthfulness" of the system.
- **Mechanism:** High-out-degree nodes (influencers) weight the global transition map Φ(θ; u, Q). If these influential nodes hold "correct data" or high "compute u", they bias the network's fixed point θ* toward the Truthful state. Power-law structures propagate truth more efficiently than chain structures because they amplify these high-degree signals.
- **Core assumption:** "Monotone social influence"—an agent is more likely to switch to Truthful if its neighbors are Truthful (Theorem 1, A1).
- **Evidence anchors:**
  - [abstract]: "...truthful population state increases... [when] influential node placement with correct data improves truthful outcomes."
  - [section 3.2, Experiment 3]: "placing the correct data on influential nodes leads to an improved proportion of truthful nodes..."
- **Break condition:** Fails if high-degree nodes are adversarial or hallucinating, which would drive the system to a "Hallucination" fixed point.

## Foundational Learning

- **Concept: Mean-Field Approximation**
  - **Why needed here:** Required to move from simulating individual LLM calls to analyzing the system-level ODEs for stability and convergence speed.
  - **Quick check question:** Does the ODE track the specific message history of Node 5, or the probability distribution of states for nodes with degree 5?

- **Concept: Discrete Choice Theory (Logit)**
  - **Why needed here:** Provides the mathematical bridge to estimate transition probabilities κ from observable features (context, neighbors) via logistic regression.
  - **Quick check question:** If the "incentive" u increases the utility of the Truthful state, does the probability of selecting Truthful increase or decrease?

- **Concept: Fixed Point Stability**
  - **Why needed here:** Determines if the network will eventually settle on a consensus (Truth or Hallucination) or oscillate indefinitely.
  - **Quick check question:** If the map Φ is a contraction, what does that imply about the number of possible equilibrium points?

## Architecture Onboarding

- **Component map:** Agents (100 LLMs) -> Network (Power-law directed graph) -> Local Engine (RUM-based Softmax decision logic) -> Global Observer (MFD ODE solver)

- **Critical path:**
  1. Initialize network topology and assign data contexts (35% correct, random rest)
  2. Execute sequential edge interactions: Sample edge (i,j), i queries LLM with neighbor j's state
  3. Update population state ρ; check for convergence to fixed point θ*

- **Design tradeoffs:**
  - **Sequential vs. Parallel:** The theoretical model assumes sequential interactions (tractable ODE), but real implementation uses parallel rounds (computationally faster). This creates a sim-to-real gap.
  - **RUM vs. Plug-in estimates:** RUM allows extrapolation to unseen controls u; plug-in estimates require massive data for every configuration.

- **Failure signatures:**
  - **Consensus on Falsehood:** High ρ_H convergence caused by influential nodes initialized with incorrect context
  - **Model Collapse:** MFD prediction diverges from actual simulation due to IIA assumption violation in LLM outputs

- **First 3 experiments:**
  1. **Topology Ablation:** Compare ρ_T convergence speed in Power-law vs. Chain vs. Tree networks using the "Fiction" dataset
  2. **Influence Injection:** Place the "Correct Context" on the highest-degree node vs. a random low-degree node and measure the delta in final θ*
  3. **Compute Scaling:** Increase test-time compute (deliberation steps) u and verify the predicted monotonic increase in the Truthful fixed point (Theorem 1)

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does the Glass-Ceiling Effect emerge in dynamic LLM networks where influential nodes with privileged information systematically dominate smaller models' beliefs?
- **Basis in paper:** [explicit] Future work section: "One can extend dynamic networks and preferential attachment methods...to analyze the Glass-Ceiling Effect, wherein influential nodes have privileged information and can influence other smaller models."
- **Why unresolved:** Current work uses static networks and does not model power dynamics as networks evolve or track whether smaller models become permanently disadvantaged.
- **What evidence would resolve it:** Experiments tracking belief convergence over time in preferential attachment networks, measuring whether low-degree nodes' truth rates plateau below high-degree nodes regardless of context quality.

### Open Question 2
- **Question:** What is the optimal distribution of documents across a network to maximize truthful convergence under the Strength of Weak Ties principle?
- **Basis in paper:** [explicit] Future work section: "For knowledge retrieval tasks, one can study the optimal distribution of datasets on a graph and analyze the network from the perspective of Strength of Weak Ties."
- **Why unresolved:** The paper fixes 35% of LLMs with correct context uniformly; it does not explore strategic placement across bridge edges or weak-tie connections between clusters.
- **What evidence would resolve it:** Systematic experiments varying context placement (e.g., bridging nodes vs. within-cluster nodes) and measuring final ρ_T across topologies.

### Open Question 3
- **Question:** Does the Independence of Irrelevant Alternatives (IIA) assumption hold empirically for LLM state transitions, and would nested/mixed logit models improve predictive accuracy?
- **Basis in paper:** [inferred] Section 2.3 states: "if empirical tests reject IIA, one can replace the soft-max transition probabilities with mixed or nested logit"—but no empirical validation is provided.
- **Why unresolved:** The multinomial logit choice rule derived from Gumbel noise assumes IIA, which may not reflect how LLMs actually weigh alternatives when neighbor configurations change.
- **What evidence would resolve it:** Statistical tests (e.g., Hausman-McFadden) on transition data comparing multinomial logit against nested logit fits; predictive accuracy comparisons on held-out trajectories.

## Limitations
- The framework assumes homogeneous LLM agents, ignoring potential architectural or capability differences between models
- Strong statistical assumptions (large N, well-mixed interactions) may not hold in real-world sparse or small networks
- RUM model assumes economic rationality (IIA) which requires empirical validation for LLM behavior

## Confidence

- **High confidence:** Mathematical framework derivation, fixed point existence/uniqueness conditions, and empirical observation that topology affects consensus formation
- **Medium confidence:** RUM parameter estimation methodology and ODE prediction accuracy on held-out configurations
- **Low confidence:** Generalizability across different LLM architectures and robustness under adversarial conditions

## Next Checks

1. **IIA Assumption Validation:** Conduct controlled experiments varying the number of choice options (e.g., adding decoy answers) to test whether LLM transition probabilities satisfy Independence of Irrelevant Alternatives. Compare RUM predictions against Nested Logit or Mixed Logit alternatives if violated.

2. **Sim-to-Real Gap Analysis:** Implement both the theoretical sequential interaction model and the practical parallel interaction scheme on identical network configurations. Quantify the divergence in population state trajectories and ODE prediction accuracy to identify specific modeling assumptions that break down.

3. **Adversarial Robustness Test:** Initialize high-degree nodes with systematically incorrect context and measure the system's susceptibility to consensus on falsehood. Compare the time-to-convergence and final equilibrium state against the benign case to establish the vulnerability surface of different network topologies.