---
ver: rpa2
title: 'Online Inference of Constrained Optimization: Primal-Dual Optimality and Sequential
  Quadratic Programming'
arxiv_id: '2512.08948'
source_url: https://arxiv.org/abs/2512.08948
tags:
- page
- have
- proof
- lemma
- stochastic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies online statistical inference for constrained
  stochastic optimization problems with both equality and inequality constraints.
  The authors propose a Stochastic Sequential Quadratic Programming (SSQP) method
  that addresses key challenges in such problems, including biased step directions
  and infeasibility of linearized constraints.
---

# Online Inference of Constrained Optimization: Primal-Dual Optimality and Sequential Quadratic Programming

## Quick Facts
- arXiv ID: 2512.08948
- Source URL: https://arxiv.org/abs/2512.08948
- Reference count: 40
- Primary result: First fully online method achieving primal-dual asymptotic minimax optimality for constrained stochastic optimization without projection operators

## Executive Summary
This paper develops a Stochastic Sequential Quadratic Programming (SSQP) method for online statistical inference in constrained optimization problems with both equality and inequality constraints. The method addresses key challenges in such problems, including biased step directions from inequality constraints and infeasibility of linearized constraints. By combining sequential quadratic approximations with constraint relaxation and momentum-style gradient moving-average techniques, SSQP achieves global almost-sure convergence to KKT points while maintaining optimal primal-dual asymptotic normality with a consistent plug-in covariance estimator. Extensive experiments demonstrate superior performance compared to state-of-the-art methods across benchmark problems.

## Method Summary
The SSQP method uses a primal-dual approach with adaptive random stepsizes and maintains both primal and dual variables. At each iteration, it solves a convex QP subproblem with constraint relaxation to handle potential infeasibility of linearized constraints. The method applies momentum-style gradient moving averages to debias the step direction caused by non-linear truncation from inequality constraints. For optimal inference, it averages Hessian approximations to estimate the Lagrangian Hessian. The algorithm uses a backtracking scheme for constraint relaxation and adaptive stepsize selection within a specified range. All convergence and inference results are established under standard constraint qualifications (LICQ, EGMFCQ) and second-order sufficiency conditions.

## Key Results
- Global almost-sure convergence of KKT residual to zero from any initialization
- Local asymptotic normality with optimal primal-dual limiting covariance matrix matching theoretical lower bound
- Consistent plug-in covariance matrix estimator for practical inference
- First fully online approach achieving primal-dual asymptotic minimax optimality without projection operators

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Momentum-style gradient moving averages debias the step direction in the presence of inequality constraints that otherwise truncate gradient noise non-linearly.
- Mechanism: Inequality constraints induce a non-linear projection that causes E[step|state] ≠ deterministic_step even when gradient estimates are unbiased. The moving average ḡ_k = (1−β_k)ḡ_{k−1} + β_k∇F(x_k; ζ_k) reduces stochastic noise while maintaining E[‖ḡ_k − ∇f_k‖²] → 0 as k → ∞ when β_k decays appropriately slower than stepsize α_k.
- Core assumption: The averaging weight sequence β_k must satisfy b_2 ∈ (0.5, b_1) where α_k ∝ (k+1)^{−b_1} and β_k ∝ (k+1)^{−b_2}; Assumption 3.6 requires unbiased gradients with bounded variance.
- Evidence anchors:
  - [abstract] "we apply a momentum-style gradient moving-average technique within SSQP to debias the step"
  - [Section 3.1, Remark 3.3] Explicit illustration of bias: "inequality constraints truncate the gradient noise in a nonlinear manner...E[Δ̄_x_k | x_k] ≠ −Project(E[∇F(x_k; ζ_k) | x_k], [−u, −l])"
  - [corpus] Related work on primal-dual algorithms exists (paper 25198) but does not address this debiasing mechanism specifically.
- Break condition: If β_k decays too fast (b_2 ≥ b_1), gradient averaging cannot keep up with step direction changes, breaking convergence; if too slow, the method cannot achieve optimal asymptotic normality.

### Mechanism 2
- Claim: Constraint relaxation parameter θ_k ensures subproblem feasibility when linearized constraints become infeasible, while preserving convergence to KKT points.
- Mechanism: At each iteration, initialize θ_k = 1 and backtrack by factor τ ∈ (0,1) until the convex QP (12) has zero optimal value, meaning Ω(x_k; θ_k) ≠ ∅. Theorem 2.2 guarantees existence of θ_k > 0 under EGMFCQ; if θ_k → 0, accumulation points fail EGMFCQ (and thus LICQ), indicating numerical failure rather than algorithmic flaw.
- Core assumption: Assumption 3.4 requires θ_k bounded away from zero; Theorem 2.2 connects this to EGMFCQ holding at accumulation points.
- Evidence anchors:
  - [Section 2.1] "an intrinsic difficulty of linearization is the issue of infeasibility: even if the original constraint set Ω ≠ ∅, the linearized constraints may end up with an empty set"
  - [Theorem 2.2] Formal statement of when θ_k exists and when θ_k → 0 signals constraint qualification failure
  - [corpus] No directly comparable relaxation mechanism in neighbors; related SSQP papers assume equality constraints only (paper 68363, 96951).
- Break condition: θ_k falling below a numerical tolerance (e.g., 10^{−12}) indicates the iterate is approaching a point where EGMFCQ fails; algorithm should re-initialize.

### Mechanism 3
- Claim: The averaged Hessian B̄_k approximating the Lagrangian Hessian ∇²_x L^⋆ enables primal-dual asymptotic normality with optimal limiting covariance Ω^⋆.
- Mechanism: The subproblem (17) uses B̄_k = Q̄_k + Σ[λ_k]_i ∇²c_i(x_k) + Δ_k where Δ_k convexifies to ensure strong convexity. Under LICQ and SOSC at x^⋆, Lemma 4.4 shows B̄_k → ∇²_x L^⋆ almost surely. This approximation is essential for local convergence analysis—the limiting covariance Ω^⋆ = (H^⋆)^{−1}Σ^⋆(H^⋆)^{−1} matches the minimax lower bound.
- Core assumption: Assumption 4.1 (LICQ, strict complementarity, SOSC at x^⋆); Assumption 4.3 (unbiased Hessian estimates with bounded variance); γ_k decay rate b_3 ∈ (0.5, 1].
- Evidence anchors:
  - [Section 4.1] "for the local analysis...we expect B̄_k to serve as a good approximation to the Lagrangian Hessian ∇²_x L_k"
  - [Corollary 4.7] "√k(w_k − w^⋆) →_d N(0, Ω^⋆)" when ι_1 = b_1 = 1
  - [corpus] Paper 2505.18327 addresses constrained inference via random scaling but relies on projections rather than SQP structure.
- Break condition: If Hessian averaging weight γ_k decays too slowly (b_3 > 1) or if constraint curvature estimates are inaccurate, B̄_k may not converge to ∇²_x L^⋆, breaking asymptotic optimality.

## Foundational Learning

- Concept: **KKT Conditions and Lagrangian Duality**
  - Why needed here: The entire method targets KKT triplets (x^⋆, λ^⋆, μ^⋆); understanding stationarity, feasibility, complementary slackness, and dual variable roles is essential to interpret convergence and inference outputs.
  - Quick check question: Given equality constraints c(x) = 0 and box constraints ℓ ≤ x ≤ u, write the KKT conditions and identify which dual variables correspond to which constraints.

- Concept: **Stochastic Approximation Convergence Rates**
  - Why needed here: The stepsize sequence α_k ∝ (k+1)^{−b_1} and averaging weights β_k, γ_k determine both convergence (Theorem 3.8) and asymptotic normality (Theorem 4.6). Misunderstanding these leads to parameter misconfiguration.
  - Quick check question: For Robbins-Monro conditions (∑α_k = ∞, ∑α_k² < ∞), what range of b_1 satisfies both? What additional constraint does b_2 < b_1 impose?

- Concept: **Asymptotic Normality and Covariance Estimation**
  - Why needed here: The paper's main contribution is achieving optimal asymptotic normality Ω^⋆ with a plug-in estimator Ω_k for practical inference (confidence intervals, hypothesis testing).
  - Quick check question: In unconstrained SGD, the limiting covariance involves the Hessian inverse and gradient covariance. How does this extend to constrained problems with active constraints?

## Architecture Onboarding

- Component map: Sample ζ_k → Constraint Relaxation (QP with backtracking θ_k) → Gradient/Hessian Averaging (ḡ_k, Q̄_k, B̄_k) → SSQP Subproblem (QP (17)) → Primal-Dual Update (18) → Covariance Estimation (Ω_k)
- Critical path: The SSQP subproblem (17) is the computational bottleneck—solving a convex QP with d variables, m equality constraints, and 2d box constraints per iteration. The gradient averaging is O(d) and Hessian averaging is O(d²) per iteration.
- Design tradeoffs:
  - **Stepsize b_1 vs. gradient weight b_2**: Larger b_1 (faster stepsize decay) accelerates early convergence but requires b_2 ∈ (2−2b_1, 2b_1−1), tightening feasible range. Recommended: b_1 ∈ (0.75, 1], b_2 ≈ 0.5b_1 + 0.25.
  - **Hessian approximation**: For global convergence only, set B̄_k = I (no second-order info). For optimal inference, need true Lagrangian Hessian approximation via averaging.
  - **Adaptive stepsize**: Safeguard condition ᾱ_k ∈ [α_k, α_k + ψα_k^p] with p ≥ 1.5 allows flexibility but complicates theoretical analysis.
- Failure signatures:
  - θ_k → 0 numerically: Accumulation point fails EGMFCQ; re-initialize or switch to different local solution search.
  - Dual multipliers (λ_k, μ_k) diverge: May indicate LICQ violation or incorrect active set; check constraint Jacobian rank.
  - Coverage rates significantly below nominal: Covariance estimator Ω_k may not have converged; increase iterations or verify Hessian approximation accuracy.
  - KKT residual stagnates above zero: Step direction bias may persist; verify β_k decay rate is slower than α_k.
- First 3 experiments:
  1. **Toy problem validation**: Implement on d = 2 problem with simple equality + box constraints (e.g., HS41 from CUTEst) with known solution; verify KKT residual → 0 and confidence interval coverage ≈ 95% over 200 independent runs.
  2. **Parameter sensitivity**: Sweep b_1 ∈ {0.8, 0.9, 1.0} and b_2 ∈ {0.4, 0.5, 0.6} on a d = 10 constrained regression; plot convergence rate vs. final coverage rate to identify optimal regime.
  3. **Comparison to baselines**: Compare against ActiveSet-SSQP (batch) and Biased-SSQP (online without momentum) on constrained logistic regression with simplex constraints; measure KKT residual, feasibility error, and coverage rate vs. iteration count.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What non-asymptotic bounds can characterize how quickly the SSQP iterates approach the limiting normal distribution, and how do these bounds depend on problem dimension, constraint structure, and noise characteristics?
- Basis in paper: [explicit] The authors explicitly state: "it would be significant to provide a non-asymptotic analysis that quantifies how quickly the stochastic iterates approach the limiting distribution" (Section 6).
- Why unresolved: The current analysis only establishes asymptotic normality via martingale CLT arguments, without quantifying finite-sample convergence rates to the limiting distribution.
- What evidence would resolve it: Derivation of explicit convergence bounds in Wasserstein or Kolmogorov distance between the scaled iterate distribution and the limiting normal, potentially using non-asymptotic martingale CLT techniques as referenced (Anastasiou et al., 2019).

### Open Question 2
- Question: How can the SSQP framework be extended to high-dimensional constrained estimation with regularization (e.g., sparsity-inducing penalties or manifold constraints) while maintaining valid statistical inference?
- Basis in paper: [explicit] The authors state: "Developing a high-dimensional theory for constrained model estimation would require incorporating regularization techniques such as sparsity-inducing penalties, manifold constraints, or low-rank constraints to enable valid analysis" (Section 6).
- Why unresolved: Current theory assumes fixed dimension; extending to d > n regimes requires fundamentally different analytical tools and may affect constraint qualification conditions and covariance estimation.
- What evidence would resolve it: Modified SSQP algorithm with regularization terms, theoretical analysis establishing asymptotic properties when d grows with n, and empirical validation on high-dimensional constrained problems.

### Open Question 3
- Question: Can the SSQP method be extended to handle Markovian or dependent data streams while preserving the global convergence and asymptotic optimality guarantees?
- Basis in paper: [inferred] Assumption 3.6 assumes unbiased gradient estimates, and the analysis treats samples as iid. Many online learning scenarios involve temporal dependencies (e.g., reinforcement learning, time series).
- Why unresolved: The current gradient momentum analysis relies on conditional independence of stochastic gradients; dependent data introduces additional bias and variance structures that complicate both the debiasing mechanism and asymptotic normality proofs.
- What evidence would resolve it: Modified assumptions accommodating geometric ergodicity of Markov chains, adjusted conditions on momentum weights β_k relative to mixing times, and theoretical/empirical validation on Markovian data.

### Open Question 4
- Question: How does the method perform when constraint qualifications (LICQ or EGMFCQ) fail or nearly fail at the solution, and can inference still proceed with modified limiting distributions?
- Basis in paper: [inferred] The method requires LICQ for asymptotic minimax optimality (Assumption 4.1) and EGMFCQ for constraint relaxation (Theorem 2.2). Theorem 2.2 indicates θ_k → 0 signals constraint qualification failure.
- Why unresolved: Degenerate constraint structures lead to non-unique dual multipliers and potentially non-normal limiting distributions, which the current framework cannot handle.
- What evidence would resolve it: Characterization of limiting distributions under weaker constraint qualifications, development of diagnostic procedures for detecting near-degeneracy, and alternative inference methods for degenerate cases.

## Limitations
- The method relies heavily on EGMFCQ holding at accumulation points, with no algorithmic safeguard if θ_k → 0 numerically.
- Hessian approximation B̄_k requires accurate curvature estimates and proper modification Δ_k to ensure strong convexity, but implementation details are underspecified.
- Parameter tuning is critical: the relationship b₂ ∈ (2−2b₁, 2b₁−1) for optimal inference creates a narrow feasible window that may be difficult to navigate in practice.

## Confidence
- **High confidence** in convergence theory (Theorem 3.8): Based on well-established stochastic approximation techniques with clear Robbins-Monro conditions and explicit verification of bias reduction through momentum averaging.
- **Medium confidence** in asymptotic normality (Theorem 4.6): While the theoretical framework is sound, the optimal Ω^⋆ covariance requires precise Hessian approximation that may be sensitive to implementation choices.
- **Medium confidence** in practical utility: Extensive experiments demonstrate effectiveness, but real-world performance depends critically on parameter tuning and numerical stability of constraint relaxation.

## Next Checks
1. **Constraint qualification sensitivity**: Systematically test θ_k behavior across CUTEst problems with varying constraint geometries; document when EGMFCQ violations occur and how SSQP responds.
2. **Hessian approximation accuracy**: Compare B̄_k convergence to true Lagrangian Hessian on problems with known solutions; quantify impact on asymptotic covariance estimation accuracy.
3. **Parameter regime robustness**: Conduct systematic sweeps of (b₁, b₂, b₃) combinations on constrained regression problems; identify regions where theoretical requirements (b₂ ∈ (2−2b₁, 2b₁−1), b₃ ∈ (0.5,1]) align with practical performance.