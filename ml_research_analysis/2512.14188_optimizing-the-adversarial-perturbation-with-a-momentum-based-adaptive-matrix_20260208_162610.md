---
ver: rpa2
title: Optimizing the Adversarial Perturbation with a Momentum-based Adaptive Matrix
arxiv_id: '2512.14188'
source_url: https://arxiv.org/abs/2512.14188
tags:
- adaptive
- attacks
- adversarial
- adami
- ours
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the non-convergence issue of momentum-based
  adversarial attacks by introducing a momentum-based adaptive matrix to scale perturbations.
  The authors reveal that PGD is a specific reformulation of projected gradient method
  and propose AdaMI, a novel attack that replaces the sign function with an adaptive
  diagonal matrix using accumulated momentum vectors.
---

# Optimizing the Adversarial Perturbation with a Momentum-based Adaptive Matrix

## Quick Facts
- arXiv ID: 2512.14188
- Source URL: https://arxiv.org/abs/2512.14188
- Reference count: 40
- One-line primary result: AdaMI attack with momentum-based adaptive matrix consistently outperforms state-of-the-art methods in transferability while maintaining better imperceptibility and stability.

## Executive Summary
This paper addresses the non-convergence issue of momentum-based adversarial attacks by introducing a momentum-based adaptive matrix to scale perturbations. The authors reveal that PGD is a specific reformulation of projected gradient method and propose AdaMI, a novel attack that replaces the sign function with an adaptive diagonal matrix using accumulated momentum vectors. AdaMI is proven to achieve optimal convergence for convex problems, ensuring stability during optimization. Experiments show that AdaMI and its variants consistently outperform state-of-the-art methods in terms of transferability across different neural network architectures while maintaining better imperceptibility and stability.

## Method Summary
The method introduces AdaMI, an adversarial attack that replaces the standard sign function with a momentum-based adaptive diagonal matrix. The algorithm accumulates momentum vectors and uses them to compute an adaptive scaling matrix that element-wise adjusts the perturbation update. This approach addresses the non-convergence issues of standard momentum-based attacks and theoretically guarantees optimal convergence for convex problems. The adaptive matrix is constructed using the exponential moving average of squared momentum vectors rather than raw gradients, preserving the transferability properties inherent to momentum-based attacks.

## Key Results
- AdaMI consistently achieves higher attack success rates across multiple target architectures compared to MI-FGSM and other state-of-the-art methods
- The method demonstrates superior imperceptibility with lower FID scores and average L∞ distortion
- Theoretical proof shows AdaMI achieves optimal convergence for convex problems, addressing the non-convergence issues of MI-FGSM
- The momentum-based adaptive matrix approach is demonstrated as a general technique to boost adversarial transferability

## Why This Works (Mechanism)

### Mechanism 1: Adaptive Diagonal Scaling vs. Sign Function
Replacing the binary sign function with a momentum-based adaptive diagonal matrix stabilizes the optimization trajectory and improves transferability. Standard attacks like PGD and MI-FGSM use sign(gradient), which discards magnitude information and can cause non-convergence in convex settings. This method uses a diagonal matrix $V_t$ to scale the perturbation element-wise, with the update scaled by $\hat{V}_{t+1}^{-1/2}$ as an adaptive step-size that dampens large gradient coordinates and amplifies small ones.

### Mechanism 2: Momentum-Based History in Adaptive Matrix
Constructing the adaptive matrix using the accumulation of momentum vectors (rather than raw gradients) better preserves the transferability properties inherent to momentum-based attacks. Unlike AdaGrad or Adam, which use past gradients ($(\nabla J)^2$), this method computes the diagonal matrix using past momentum vectors ($g_{t+1}^2$). Since $g_{t+1}$ already contains historical gradient information via the decay factor $\mu$, the adaptive matrix reflects a smoother, "inertial" landscape of the optimization path.

### Mechanism 3: Time-Varying Step-Size for Convergence
Using a diminishing step-size $\alpha_t = \alpha/\sqrt{t}$ allows the method to satisfy theoretical convergence criteria for convex problems, unlike fixed step-size attacks. Fixed step-sizes (common in PGD) can oscillate, but decaying the step-size based on iteration count $t$ forces convergence as $t \to \infty$, theoretically guaranteeing finding the optimal perturbation within the convex hull.

## Foundational Learning

- **Concept:** Projected Gradient Descent (PGM)
  - **Why needed here:** The paper reframes PGD as a specific reformulation of PGM with specific step-size logic, helping understand why standard attacks are "unstable" and why this method proposes a different projection approach.
  - **Quick check question:** How does the projection operator in Equation 2 differ from the clipping operation in Equation 8/9?

- **Concept:** Momentum (Polyak's Heavy Ball)
  - **Why needed here:** The proposed method modifies MI-FGSM, which is grounded in the Heavy Ball method. Understanding how momentum accumulates past gradients ($\mu g_t$) is essential to see why using this accumulated vector for the adaptive matrix is a distinct design choice.
  - **Quick check question:** In Equation 10 (MI-FGSM), what is the physical interpretation of the term $\frac{\nabla J}{\|\nabla J\|_1}$ inside the momentum update?

- **Concept:** Adaptive Gradient Methods (AdaGrad/RMSProp)
  - **Why needed here:** The core contribution is a new "momentum-based adaptive matrix." Understanding how standard adaptive methods use $V_t^{-1/2}$ to scale coordinates is crucial to see why replacing gradient-squared accumulator with momentum-squared accumulator is novel.
  - **Quick check question:** Why does dividing the gradient by $\sqrt{v_{t,i}}$ help in sparse learning scenarios?

## Architecture Onboarding

- **Component map:** Input Image x -> Momentum Module (accumulates gradients into $g_{t+1}$) -> Adaptive Matrix Module (computes diagonal matrix $V_{t+1}$ using EMA of squared momentum) -> Update Logic (projects and applies perturbation) -> Output Adversarial Example $x_{adv}$

- **Critical path:** The calculation of $V_{t+1}$ is critical. Implementers must use the momentum vector $g_{t+1}$ (calculated in the previous step) to update the adaptive matrix, ensuring the matrix reflects the "inertial" history rather than raw gradient information.

- **Design tradeoffs:**
  - EMA Parameter $\beta$: Controls how "fast" the adaptive matrix forgets. High $\beta$ = more stability/smoother but slower reaction to new geometry.
  - Step-size Decay: Using $\alpha/\sqrt{t}$ ensures theoretical convergence but might require more iterations to saturate the budget $\epsilon$ compared to fixed $\alpha$.
  - Complexity: Slightly higher computational overhead than vanilla MI-FGSM due to element-wise matrix operations, but negligible compared to forward/backward pass.

- **Failure signatures:**
  - High FID (Low Imperceptibility): Using gradient-based adaptive matrix (AdaMI-G) instead of momentum-based one degrades imperceptibility.
  - Oscillation: If $\beta$ is too low and the gradient is sparse, $V_t$ might fluctuate, causing instability similar to non-convergence issues of PGD.

- **First 3 experiments:**
  1. Convergence Check: Plot the loss $J(x_{adv})$ vs. iterations for AdaMI vs. MI-FGSM to verify smoother, more consistent convergence.
  2. Transferability Benchmark: Attack ResNet-34 surrogate and test generated AEs on Inc-v3, VGG-16, ViT-S to compare AdaMI vs. MI-FGSM and AdaMI-G.
  3. Imperceptibility Ablation: Measure Average L∞ Distortion (ALD) and FID for AdaMI vs. AdaMI-G to validate momentum-based matrices preserve better imperceptibility.

## Open Questions the Paper Calls Out

- **Question:** Does the momentum-based adaptive matrix approach guarantee convergence for non-convex objective functions typical of deep neural networks?
  - **Basis in paper:** Theorem 1 and Assumption 1 state AdaMI attains optimal convergence only under concave objective condition.
  - **Why unresolved:** The paper assumes small constrained domains allow treating functions as concave "without loss of generality," but lacks formal proof for complex, non-convex DNN loss landscapes.
  - **What evidence would resolve it:** Formal convergence analysis for non-convex stochastic settings or empirical studies comparing convergence trajectories on highly non-convex surfaces.

- **Question:** Can the momentum-based adaptive matrix improve generalization and training speed in standard deep learning optimization tasks?
  - **Basis in paper:** Section V states this "may be a new design paradigm... even beyond adversarial attacks to the broader context of optimization."
  - **Why unresolved:** Experimental validation is strictly limited to generating adversarial examples; properties that aid transferability haven't been tested for standard model training.
  - **What evidence would resolve it:** Applying AdaMI update rule to standard benchmarks (e.g., training ResNet on CIFAR-10/ImageNet) comparing loss convergence and test accuracy against Adam or SGD.

- **Question:** What is the relationship between the momentum-based adaptive matrix and the reduction of interactions among perturbation units in terms of boosting transferability?
  - **Basis in paper:** The paper notes high transferability is negatively correlated with interaction among perturbation units, but the mechanism (optimization stability vs. interaction reduction) is not explicitly decoupled.
  - **Why unresolved:** It's unclear if improved transferability comes solely from better optimization stability or if adaptive scaling inherently reduces perturbation interactions.
  - **What evidence would resolve it:** Quantitative analysis of perturbation interactions (as defined in [65]) for AEs generated by AdaMI compared to baseline momentum methods.

## Limitations
- Theoretical convergence guarantees apply only to convex problems, not the highly non-convex landscapes typical of DNNs
- Limited ablation studies on hyperparameter sensitivity and convergence behavior across different architectures
- Potential overfitting to surrogate model geometry without addressing transferability to diverse target architectures
- Computational overhead, while claimed negligible, could accumulate in large-scale applications

## Confidence

**High Confidence:** The mechanism of using momentum-based adaptive scaling for improved optimization stability is well-supported by both theoretical analysis and empirical results. The claim that AdaMI outperforms MI-FGSM in transferability across multiple architectures is strongly validated.

**Medium Confidence:** The claim that AdaMI "ensures optimal convergence for convex problems" is theoretically sound but its practical relevance to adversarial attacks is uncertain given the non-convex nature of real classification problems. The imperceptibility advantages are demonstrated but could be architecture-dependent.

**Low Confidence:** The generalizability claim that "momentum-based adaptive matrix is a general technique to boost adversarial transferability" is based on limited experiments. The method's performance on defense-aware attacks or ensemble-based strategies hasn't been thoroughly explored.

## Next Checks

1. **Convergence Behavior Analysis:** Plot loss vs. iteration curves for AdaMI, MI-FGSM, and AdaMI-G on multiple surrogate models to verify that AdaMI consistently shows smoother convergence and faster loss reduction.

2. **Hyperparameter Sensitivity Study:** Systematically vary β (EMA parameter), μ (momentum decay), and α (step-size) across their plausible ranges to identify the stability bounds and quantify the method's robustness to hyperparameter choices.

3. **Transferability Robustness Test:** Evaluate AdaMI against an ensemble of diverse surrogate models (including architectures not used in the original experiments) and test transferability to black-box models with different capacities and training paradigms to assess true generalizability.