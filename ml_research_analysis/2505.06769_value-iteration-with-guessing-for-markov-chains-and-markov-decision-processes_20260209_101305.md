---
ver: rpa2
title: Value Iteration with Guessing for Markov Chains and Markov Decision Processes
arxiv_id: '2505.06769'
source_url: https://arxiv.org/abs/2505.06769
tags:
- time
- value
- states
- algorithm
- instances
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the long-standing open problem of achieving
  sub-exponential convergence for Value Iteration (VI) algorithms on Markov chains
  (MCs) and Markov decision processes (MDPs). The core method introduces "guessing"
  values during preprocessing, combined with Bellman updates, to dramatically reduce
  the number of iterations needed.
---

# Value Iteration with Guessing for Markov Chains and Markov Decision Processes

## Quick Facts
- **arXiv ID:** 2505.06769
- **Source URL:** https://arxiv.org/abs/2505.06769
- **Reference count:** 40
- **Primary result:** Introduces "Guessing VI" achieving sub-exponential convergence for Value Iteration on Markov Chains, with practical improvements on 474 benchmark MDP instances.

## Executive Summary
This paper addresses the long-standing challenge of accelerating Value Iteration (VI) for Markov Chains (MCs) and Markov Decision Processes (MDPs). The core innovation is a preprocessing step that "guesses" values for specific states, effectively reducing the problem's depth and enabling sub-exponentially many Bellman updates for MCs. For MDPs, the approach provides improved theoretical convergence bounds and a practical Guessing VI algorithm. Experimental results on the Quantitative Verification Benchmark Set demonstrate significant speedups over existing VI-based methods in numerous instances.

## Method Summary
The method introduces "guessing" values for specific states during preprocessing, combined with Bellman updates, to reduce the number of iterations needed for convergence. For MCs, the preprocessing algorithm identifies a small set of states to guess, converting them into targets and recursively splitting the problem to limit depth. For MDPs, the approach uses a practical Guessing VI algorithm with heuristic state selection. The implementation is integrated into the STORM model checker and tested on 474 benchmark instances from the Quantitative Verification Benchmark Set, comparing wall-clock time against IVI, OVI, and SVI baselines.

## Key Results
- Achieves sub-exponential Bellman updates (|S| log(wmax/ε)/δmin)^O(√|S|) for MCs, compared to polynomial bounds for standard VI
- Outperforms existing VI-based methods (IVI, OVI, SVI) in 86 out of 474 benchmark instances with an average improvement of at least 27%
- Demonstrates practical efficiency with O(log(1/ε)) dependency on epsilon in benchmarks, despite theoretical predictions of log(1/ε)^O(√|S|)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Convergence speed of VI on MCs is bounded by structural "levels" of the graph rather than total state count
- **Mechanism:** Partitions states into levels based on shortest path distance to target set; convergence bounds shrink based on k·t iterations where k is number of levels
- **Core assumption:** δmin is non-zero, allowing probability mass to propagate through levels
- **Evidence anchors:** Section 3.1 defines levels and proves convergence bounds are parameterized by k; corpus analysis supports VI convergence properties via probability sequences
- **Break condition:** "Deep" MCs (linear chains where k≈|S|) offer no speedup over standard VI

### Mechanism 2
- **Claim:** Guessing values for specific states effectively "flattens" the MC, reducing maximum depth k
- **Mechanism:** Identifies "middle" level between k/3 and 2k/3; guesses values for states in this band and converts them to targets, recursively splitting problem
- **Core assumption:** Structural graph properties (BFS levels) are sufficient to guide guessing strategy
- **Evidence anchors:** Abstract mentions guessing values during preprocessing; Section 3.3 Algorithm 1 proves existence of small level set to guess
- **Break condition:** Poor guess selection increases recursion depth, approaching standard VI complexity

### Mechanism 3
- **Claim:** Guesses can be verified as valid bounds using constant Bellman updates on reduced system
- **Mechanism:** Checks if guessed value γ at state s satisfies Bellman inequality relative to neighbors' values using local update
- **Core assumption:** Bellman update operator preserves monotonicity, allowing local check to validate global bounds
- **Evidence anchors:** Section 3.2 Lemma 2 and Corollary 1 formalize guess verification; Section 5 Algorithm 4 implements practical verification
- **Break condition:** Frequent "Inconclusive" branches in verification increase computational cost

## Foundational Learning

- **Concept:** Bellman Updates & Fixpoints
  - **Why needed here:** Paper modifies standard VI by interrupting convergence to fixpoints with "guesses"; understanding update operator propagation is essential
  - **Quick check question:** For a Stochastic Shortest Path (SSP) problem, does the Bellman update use max or min, and does it add current state's cost before or after looking at neighbors?

- **Concept:** Graph Levels & BFS (Breadth-First Search)
  - **Why needed here:** Core speedup relies on partitioning graph into levels based on distance to target; understanding BFS is required for O(|S|+|E|) preprocessing
  - **Quick check question:** In this paper, does a "level" represent geometric distance or probabilistic expected distance to target?

- **Concept:** Interval Value Iteration (IVI)
  - **Why needed here:** Guessing VI uses IVI internally to verify guesses; stopping condition depends on interval width
  - **Quick check question:** Why does maintaining both upper and lower bound vectors provide more information than standard VI?

## Architecture Onboarding

- **Component map:** Preprocessor (MarkToGuess) -> Solver (PickVerify) -> Heuristic (PickState) -> Verifier (Verify)
- **Critical path:** PickVerify recursion (Algorithm 6); efficiency hinges on Verify step returning conclusive bounds quickly
- **Design tradeoffs:**
  - Theoretical vs. Practical State Selection: Middle level selection (Alg 1) vs. random-walk heuristic (Alg 5) for better average-case performance
  - Iteration Limits: Hard limits (K1, K2) on Bellman updates during verification trade guaranteed bounds for practical timeout safety
- **Failure signatures:**
  - Precision Blow-up: Extremely small δmin causes numerical instability in error bounds ε·δ|S|min
  - Inconclusive Loops: Frequent verification failures degrade to standard VI with high overhead
- **First 3 experiments:**
  1. Reproduce "Embedded Control System" result: Run GVI on embedded model to verify 0s vs ~1s speedup against IVI/SVI
  2. Test "Deep Chain" adversarial case: Construct linear chain MC and confirm GVI reduces levels via guessing
  3. Ablation on Heuristics: Replace PickState random-walk with random choice on crowds/csm benchmarks

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does there exist a polynomial-time preprocessing algorithm for MDPs that enables sub-exponentially many Bellman updates to approximate the value vector?
- **Basis in paper:** Section 7 states this remains open; Appendix A provides counterexample showing natural extension of MC approach fails
- **Why unresolved:** MC preprocessing relies on level structure via BFS, but MDPs have nondeterminism making levels depend on optimal strategies
- **What evidence would resolve it:** Polynomial-time preprocessing algorithm achieving sub-exponential Bellman updates for general MDPs, or lower bound showing insufficiency

### Open Question 2
- **Question:** Can Guessing VI approach be extended to stochastic games while maintaining sub-exponential Bellman updates?
- **Basis in paper:** Section 7 identifies this as promising research path
- **Why unresolved:** Stochastic games introduce additional adversarial player, making value computation more complex
- **What evidence would resolve it:** Formal extension of Theorem 1 to stochastic games, or analysis showing which components fail to generalize

### Open Question 3
- **Question:** Why does practical GVI achieve O(log(1/ε)) dependency on ε in benchmarks when theory predicts log(1/ε)^O(√|S|)?
- **Basis in paper:** Appendix B notes theoretical dependency would be log(1/ε)^O(√|S|) but experiments show negligible effect on running time
- **Why unresolved:** Gap between worst-case theoretical bounds and empirical behavior not explained
- **What evidence would resolve it:** Identification of benchmark instances exhibiting theoretical polynomial-in-√|S| behavior, or refined analysis tightening theoretical bound

## Limitations

- Theoretical speedup depends critically on MC/MDP being recursively partitionable into logarithmic number of levels, which may not hold for arbitrary instances
- Practical algorithm relies on random-walk heuristic (Algorithm 5) without same theoretical guarantees as middle-level selection used in proofs
- Numerical stability concerns for extremely small δmin where terms like ε·δ|S|min can underflow

## Confidence

- **High Confidence:** Correctness of Bellman update verification mechanism and basic STORM integration
- **Medium Confidence:** Asymptotic theoretical bounds (sub-exponential convergence) for MCs, as they rely on structural assumptions
- **Low Confidence:** Consistent practical performance of random-walk heuristic across all problem types, especially adversarial cases

## Next Checks

1. **Adversarial Case Testing:** Construct deep linear-chain MC and verify GVI reduces level count via guessing
2. **Heuristic Ablation Study:** Replace PickState random-walk with random choice on standard benchmark to quantify performance gain
3. **Numerical Stability Analysis:** Test algorithm on MCs with very small δmin (e.g., 10^-10) to observe guess verification failures due to underflow