---
ver: rpa2
title: Learning Hierarchical Procedural Memory for LLM Agents through Bayesian Selection
  and Contrastive Refinement
arxiv_id: '2512.18950'
source_url: https://arxiv.org/abs/2512.18950
tags:
- uni00000013
- procedures
- uni00000048
- memory
- macla
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MACLA introduces a framework that decouples LLM reasoning from
  adaptation by maintaining a frozen LLM and performing all learning externally in
  a hierarchical procedural memory. The system extracts structured procedures from
  trajectories, tracks reliability with Bayesian posteriors, selects actions via expected-utility
  scoring, and refines procedures through contrastive analysis of successes and failures.
---

# Learning Hierarchical Procedural Memory for LLM Agents through Bayesian Selection and Contrastive Refinement

## Quick Facts
- **arXiv ID**: 2512.18950
- **Source URL**: https://arxiv.org/abs/2512.18950
- **Reference count**: 40
- **Primary result**: MACLA achieves 78.1% average performance across four benchmarks using a frozen 7B LLM, constructing memory in 56 seconds (2,800× faster than fine-tuning baselines).

## Executive Summary
MACLA introduces a framework that decouples LLM reasoning from adaptation by maintaining a frozen LLM and performing all learning externally in a hierarchical procedural memory. The system extracts structured procedures from trajectories, tracks reliability with Bayesian posteriors, selects actions via expected-utility scoring, and refines procedures through contrastive analysis of successes and failures. Across four benchmarks (ALFWorld, WebShop, TravelPlanner, InterCodeSQL), MACLA achieves 78.1% average performance—the highest among all methods—using only a 7B model. On ALFWorld unseen tasks, it reaches 90.3% with +3.1% positive generalization. The system constructs memory in 56 seconds (2,800× faster than state-of-the-art LLM fine-tuning baselines), compressing 2,851 trajectories into 187 procedures.

## Method Summary
MACLA maintains a frozen LLM and performs all learning externally in a hierarchical procedural memory. The system extracts structured procedures from trajectories, tracks reliability with Bayesian posteriors, selects actions via expected-utility scoring, and refines procedures through contrastive analysis of successes and failures. The approach decouples reasoning from adaptation, enabling efficient learning without fine-tuning the underlying LLM.

## Key Results
- MACLA achieves 78.1% average performance across four benchmarks, the highest among all methods
- On unseen ALFWorld tasks, MACLA reaches 90.3% success rate with +3.1% positive generalization
- Memory construction completes in 56 seconds, 2,800× faster than LLM fine-tuning baselines

## Why This Works (Mechanism)
The system works by maintaining a frozen LLM and performing all adaptation externally in a hierarchical procedural memory. This separation allows the LLM to focus purely on reasoning while the memory system handles learning from experience. Bayesian posteriors track procedure reliability, enabling intelligent selection through expected-utility scoring. Contrastive refinement analyzes differences between successful and failed attempts to improve procedures over time.

## Foundational Learning
- **Bayesian posterior tracking**: Used to estimate reliability of procedures; needed for intelligent selection among alternatives; quick check: verify posterior updates match observed success rates
- **Hierarchical procedural memory**: Organizes knowledge in multi-level structure; needed for efficient retrieval and generalization; quick check: test retrieval accuracy at different hierarchy levels
- **Contrastive analysis**: Compares successful vs. failed trajectories; needed to identify critical decision points; quick check: measure improvement in procedure success rate after refinement
- **Expected-utility scoring**: Ranks candidate actions based on predicted outcomes; needed for optimal action selection; quick check: validate scoring correlates with actual success probabilities
- **Trajectory decomposition**: Extracts structured procedures from raw interaction data; needed to build procedural memory; quick check: assess completeness and correctness of extracted procedures

## Architecture Onboarding

Component Map:
User Request -> Memory Retrieval -> Bayesian Selection -> LLM Reasoning -> Environment Action -> Memory Update

Critical Path:
The critical path flows from user request through memory retrieval, where candidate procedures are fetched based on task similarity. Bayesian selection then scores these candidates using reliability estimates and expected utility. The highest-scoring procedure guides LLM reasoning, which generates environment actions. After execution, the system updates memory with new experience and refines procedures through contrastive analysis of outcomes.

Design Tradeoffs:
The key tradeoff is between model size and performance. MACLA achieves state-of-the-art results using only a 7B LLM, avoiding the computational cost of fine-tuning larger models. This comes at the expense of requiring high-quality demonstrations for initial memory construction. The external memory approach trades off some integration complexity for the benefit of rapid adaptation without model retraining.

Failure Signatures:
Failures typically manifest as memory retrieval mismatches, where relevant procedures aren't found due to poor indexing or insufficient similarity. Bayesian selection can fail when posterior estimates are inaccurate, leading to suboptimal action choices. Contrastive refinement may produce inadequate improvements if success/failure patterns are too subtle or noisy. The system may also struggle with tasks requiring long-term reasoning that exceeds procedural memory capabilities.

Three First Experiments:
1. Test memory retrieval accuracy on held-out task variations to verify the indexing mechanism works
2. Measure Bayesian posterior calibration by comparing predicted success probabilities with actual outcomes
3. Evaluate contrastive refinement effectiveness by comparing procedure success rates before and after refinement cycles

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, though several limitations suggest areas for future work including performance on open-ended tasks, long-term memory retention, and generalization to noisy real-world data.

## Limitations
- Evaluation restricted to structured, goal-oriented environments; uncertain effectiveness in ambiguous real-world tasks
- No ablation studies on individual components like Bayesian selection or contrastive refinement
- Method depends heavily on structured, high-quality demonstrations for memory construction

## Confidence
High - The claim that MACLA achieves state-of-the-art average performance of 78.1% across four benchmarks is directly supported by the reported results and is methodologically sound.
Medium - The 90.3% success rate on unseen ALFWorld tasks with +3.1% positive generalization is promising but lacks robustness checks against diverse unseen task distributions.
Medium - The 2,800× speedup over fine-tuning is derived from specific comparisons but would benefit from broader benchmarking against other non-fine-tuning procedural memory methods.

## Next Checks
1. Conduct ablation studies removing Bayesian selection and contrastive refinement separately to quantify their individual impact on performance
2. Test MACLA on open-ended, multi-domain real-world tasks to assess generalization beyond structured benchmarks
3. Perform long-term memory retention experiments to measure catastrophic forgetting and adaptation over extended operational periods