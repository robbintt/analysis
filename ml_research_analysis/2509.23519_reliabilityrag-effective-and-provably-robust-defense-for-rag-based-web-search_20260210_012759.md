---
ver: rpa2
title: 'ReliabilityRAG: Effective and Provably Robust Defense for RAG-based Web-Search'
arxiv_id: '2509.23519'
source_url: https://arxiv.org/abs/2509.23519
tags:
- documents
- attack
- document
- malicious
- benign
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces ReliabilityRAG, a framework designed to
  defend retrieval-augmented generation (RAG) systems against adversarial document
  corruption by leveraging document reliability signals. The core method uses a graph-theoretic
  approach: documents are retrieved, contradictions between them are detected using
  a natural language inference (NLI) model to construct a contradiction graph, and
  a rank-aware maximum independent set (MIS) is found to identify the most consistent,
  reliable subset of documents.'
---

# ReliabilityRAG: Effective and Provably Robust Defense for RAG-based Web-Search

## Quick Facts
- **arXiv ID:** 2509.23519
- **Source URL:** https://arxiv.org/abs/2509.23519
- **Reference count:** 40
- **Primary result:** ReliabilityRAG defends RAG systems against adversarial document corruption using rank-aware maximum independent set (MIS) filtering with NLI contradiction detection, maintaining high benign accuracy while significantly reducing attack success rates.

## Executive Summary
ReliabilityRAG introduces a framework to defend retrieval-augmented generation (RAG) systems against adversarial document corruption by filtering documents based on reliability signals. The core approach constructs a contradiction graph from document answers using NLI, then finds the rank-aware maximum independent set to identify the most consistent, reliable subset. For scalability to large retrieval sets, a weighted sampling framework preserves theoretical robustness guarantees. The method demonstrates superior robustness to adversarial attacks while maintaining high performance on benign queries and excelling at long-form generation tasks where prior methods struggle.

## Method Summary
ReliabilityRAG operates through three main stages: (1) Isolated Answering - generate per-document answers using an LLM, (2) Contradiction Graph Construction - use NLI to detect contradictions between answers and build a graph, (3) Rank-Aware MIS Filtering - find the maximum independent set, breaking ties by document rank to prioritize higher-reliability documents. For large retrieval sets (k>20), a weighted sampling framework selects smaller subsets based on reliability scores while preserving theoretical guarantees through concentration bounds. The method combines graph-theoretic filtering with statistical sampling to balance robustness and scalability.

## Key Results
- ReliabilityRAG reduces attack success rates by 20-30% compared to RobustRAG while maintaining or improving benign accuracy
- The method excels at long-form generation tasks where previous robustness-focused approaches show significant performance degradation
- Weighted sampling with T=20 rounds and m=2 context size achieves 97.86% success probability in preserving clean context dominance
- NLI-based contradiction detection with DeBERTa-v3-large achieves 91.2% accuracy on MNLI, providing reliable edge detection for the contradiction graph

## Why This Works (Mechanism)

### Mechanism 1: Maximum Independent Set for Consistent Majority Selection
Finding the largest subset of mutually non-contradictory documents filters malicious content while preserving benign information. Documents are encoded as nodes in a contradiction graph; edges connect documents whose answers NLI classifies as contradictory. The MIS identifies the largest independent set (no edges between any two nodes), with rank-aware tie-breaking preferring higher-reliability documents. Core assumption: malicious documents will contradict benign documents, and benign documents will be mutually consistent under the targeted attack model.

### Mechanism 2: NLI-Based Contradiction Detection Over Isolated Answers
NLI models can detect semantic contradictions between LLM answers generated from individual documents. Each document generates an "isolated answer" via LLM; NLI compares all answer pairs; if contradiction probability exceeds threshold β=0.5, an edge is added. The paper uses DeBERTa-v3-large achieving 91.2% MNLI accuracy. Core assumption: NLI has bounded error—ϵ₁ for benign-benign pairs, ϵ₂ for benign-malicious pairs—with theoretical bounds ensuring reliable filtering.

### Mechanism 3: Weighted Sample-Aggregate for Scalability
Sampling smaller subsets based on reliability weights preserves robustness guarantees while scaling to k≥50 documents. Documents receive weights (e.g., exponential decay w(xᵢ) ∝ γ^(i-1)); T rounds sample m documents with replacement using weighted probabilities; intermediate answers are aggregated via MIS or other methods. With m=2, T=20, η=0.1: 97.86% success probability (Theorem 3). Core assumption: total malicious weight η is bounded; clean context probability p_clean > 1-α enables Hoeffding-bound guarantees.

## Foundational Learning

- **Maximum Independent Set (MIS) in Graphs**
  - Why needed: Core combinatorial optimization for selecting maximal non-contradictory document subsets
  - Quick check question: For a 4-node graph with edges {(1,2), (2,3), (3,4)}, list all MIS

- **Natural Language Inference (NLI)**
  - Why needed: Provides contradiction detection signal for graph edge creation
  - Quick check question: What are the three NLI classification labels, and which signals contradiction?

- **Hoeffding's Inequality / Concentration Bounds**
  - Why needed: Theorem 3 uses Hoeffding bounds to guarantee clean-context dominance over T rounds
  - Quick check question: Given T=20 trials with success probability p=0.81, what's the failure bound per Hoeffding?

## Architecture Onboarding

- **Component map:** Retriever (ranked docs) -> Isolated Answering (per-document LLM calls) -> NLI Contradiction Graph Construction -> MIS/Sampling+MIS Selection -> Final LLM Query with filtered docs

- **Critical path:** Isolated answering stage dominates latency (~0.27s for k=10 per Table 3); NLI checks and MIS are sub-5ms. For k=50, sampling reduces isolated calls to T×m contexts.

- **Design tradeoffs:**
  - MIS (k≤20): Exact, provable guarantees; latency scales with k
  - Sampling+MIS (k>20): Scales via parameters T, m; trades theoretical tightness for practicality
  - Weight decay γ: Lower γ trusts top ranks more (robust to low-rank attacks, fragile to top-rank corruption)
  - Context size m: Larger m increases malicious sampling risk; smaller m may miss relevant docs

- **Failure signatures:**
  - High benign accuracy drop: NLI threshold β too aggressive or "I don't know" filter over-prunes
  - Low robustness under attack: T insufficient, or malicious docs hold high weight (check η)
  - Latency spikes: Isolated answering not batched; consider smaller LLM for this stage

- **First 3 experiments:**
  1. Establish benign baseline: Run MIS (k=10) on clean RQA/NQ with re-ranking; measure accuracy vs. Vanilla RAG
  2. Single-position robustness test: Inject prompt-injection at Position 1 and Position k; compare MIS vs. RobustRAG
  3. Scalability validation: Run Sampling+MIS (k=50) with T=20, m=2; sweep attack positions 1/25/50; verify reliability-awareness (accuracy should improve as attack position drops)

## Open Questions the Paper Calls Out

### Open Question 1
How resilient is ReliabilityRAG against "context-aware" adaptive attacks where a malicious document behaves benignly during isolated answering but triggers malicious output during final aggregation? The theoretical guarantees rely on NLI detecting contradictions based on stable semantic content, which may fail if the attack specifically exploits the difference between the single-document context (used for NLI) and the multi-document context (used for generation). Empirical evaluation against attacks specifically optimized to output benign answers in isolation while retaining malicious payload for the final generation step would resolve this.

### Open Question 2
Can the framework be extended to identify and preserve multiple valid perspectives for ambiguous queries rather than forcing a single "consistent majority"? The current algorithm is designed to find a single Maximum Independent Set (MIS), inherently discarding documents that contradict this set even if they represent a valid minority opinion. A modified algorithm capable of detecting multiple high-reliability MIS clusters and a study measuring the system's ability to generate multi-faceted answers on a dataset of subjective or ambiguous queries would address this.

### Open Question 3
Does utilizing a Maximum Weighted Independent Set (MWIS) algorithm provide superior robustness or utility compared to the current rank-aware lexicographic tie-breaking? Exploring the use of a maximum weighted independent set could offer a more direct integration of cardinal reliability scores than the current tie-breaking implementation. A comparative ablation study substituting the lexicographic selection with an MWIS solver and evaluating the trade-off between computational cost and defense performance (ASR/Accuracy) would resolve this.

## Limitations

- NLI Model Robustness: Limited empirical evidence on how the NLI model performs specifically under adversarial document corruption scenarios, despite theoretical error bounds
- Rank-Aware Sampling Assumptions: Adaptive attacks targeting high-weight positions could violate the assumptions about bounded malicious weight and clean context dominance
- Scalability vs. Robustness Trade-off: Limited ablation studies on how different (T, m, γ) configurations affect performance across diverse attack vectors

## Confidence

- **High Confidence**: The core mechanism of using MIS for selecting consistent document subsets is well-established graph theory. Empirical results showing superior robustness compared to baseline methods are well-supported by experimental data.
- **Medium Confidence**: Theoretical guarantees depend on assumptions about NLI error bounds and weight distributions that may not hold under sophisticated adaptive attacks. The paper provides theoretical bounds but limited empirical validation of these specific conditions.
- **Low Confidence**: Scalability claims for the weighted sampling framework are based on limited parameter sweeps. Different configurations or attack patterns could significantly impact performance, but these scenarios aren't thoroughly explored.

## Next Checks

1. **NLI Model Stress Testing**: Conduct systematic evaluation of DeBERTa-v3-large's contradiction detection under adversarial document scenarios, including edge cases where malicious documents contain subtle contradictions or disjunctive attacks designed to evade detection.

2. **Adaptive Attack Vulnerability Assessment**: Test ReliabilityRAG against adaptive attacks that specifically target the rank-aware sampling mechanism, such as injecting malicious content at high-weight positions or crafting documents that maximize NLI uncertainty.

3. **Parameter Sensitivity Analysis**: Perform comprehensive ablation studies varying (T, m, γ) across different query types and document lengths to identify optimal configurations and understand the robustness-scalability trade-offs more precisely.