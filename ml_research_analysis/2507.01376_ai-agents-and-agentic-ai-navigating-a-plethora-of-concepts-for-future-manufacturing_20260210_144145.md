---
ver: rpa2
title: AI Agents and Agentic AI-Navigating a Plethora of Concepts for Future Manufacturing
arxiv_id: '2507.01376'
source_url: https://arxiv.org/abs/2507.01376
tags:
- manufacturing
- agents
- systems
- agentic
- decision-making
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides a systematic review of the evolution of AI
  and agent technologies, focusing on LLM-Agents, MLLM-Agents, and Agentic AI in the
  context of smart manufacturing. It outlines how these technologies enhance manufacturing
  capabilities through semantic retrieval, multimodal perception, adaptive learning,
  and autonomous decision-making.
---

# AI Agents and Agentic AI-Navigating a Plethora of Concepts for Future Manufacturing

## Quick Facts
- arXiv ID: 2507.01376
- Source URL: https://arxiv.org/abs/2507.01376
- Authors: Yinwang Ren; Yangyang Liu; Tang Ji; Xun Xu
- Reference count: 40
- This paper provides a systematic review of the evolution of AI and agent technologies, focusing on LLM-Agents, MLLM-Agents, and Agentic AI in the context of smart manufacturing.

## Executive Summary
This paper provides a systematic review of AI agent technologies and their evolution within smart manufacturing contexts. It distinguishes between three categories: LLM-Agents (leveraging large language models for semantic retrieval), MLLM-Agents (multimodal perception and fusion), and Agentic AI (autonomous, goal-directed systems). The review highlights how these technologies can bridge IT/OT data silos, enhance diagnostic accuracy through multimodal sensing, and enable adaptive manufacturing through continuous learning. Key challenges include data integration, workforce adaptation, accountability, and the difficulty of quantifying ROI for autonomous systems.

## Method Summary
The paper conducts a systematic literature review to synthesize current understanding of AI agents in manufacturing, organizing findings around a conceptual framework of three agent categories. It identifies core architectural components including Profiling, Memory, Planning, and Action modules, and proposes mechanisms for semantic retrieval (RAG), multimodal fusion, and adaptive learning. Rather than presenting empirical results, the work outlines theoretical capabilities and potential applications while identifying open research challenges. The review serves as a conceptual roadmap for researchers and practitioners seeking to implement AI agents in manufacturing contexts.

## Key Results
- Semantic retrieval through RAG enables LLM-Agents to bridge heterogeneous IT/OT data silos by mapping natural language queries to structured system outputs
- MLLM-Agents enhance diagnostic accuracy by fusing real-time sensor data with static domain knowledge through multimodal perception
- Agentic AI systems can autonomously adjust production goals via continuous learning loops using reinforcement learning and self-supervised learning

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** LLM-based agents utilizing Retrieval-Augmented Generation (RAG) can bridge heterogeneous IT and OT data silos by mapping unstructured natural language queries to structured system outputs.
- **Mechanism:** The agent employs a Profiling Module to define role constraints and a Memory Module for context, while RAG maps natural language queries against knowledge graphs constructed from technical manuals and maintenance logs, facilitating semantic knowledge retrieval.
- **Core assumption:** Unstructured documents (PDFs, logs) can be parsed without significant semantic loss, despite acknowledged challenges in text fragmentation and formula distortion.
- **Evidence anchors:**
  - [abstract]: "...focusing on LLM-Agents... to enhance manufacturing capabilities through semantic retrieval..."
  - [section 4.1]: "...GenAI-enabled AI Agents, leveraging Retrieval-Augmented Generation (RAG) and knowledge graphs... bridge these gaps by facilitating semantic knowledge retrieval."
  - [corpus]: "InfoDeepSeek" benchmarks information seeking for RAG, reinforcing the complexity of agentic retrieval processes.
- **Break condition:** If document parsing fails to maintain semantic consistency (e.g., vector graphic loss or formula distortion), the retrieval mechanism will yield incomplete or misleading context.

### Mechanism 2
- **Claim:** MLLM-based agents enhance diagnostic accuracy in manufacturing by fusing real-time sensor data (visual, thermal, vibration) with static domain knowledge.
- **Mechanism:** A "Fusion and Reasoning Module" synthesizes inputs from a "Multimodal Perception Module" to create a unified environmental representation. This allows the system to move beyond simple anomaly detection to causal inference and prescriptive recommendations.
- **Core assumption:** Fine-grained cross-modal semantic alignment is achievable between textual descriptions and engineering schematics/sensor feeds.
- **Evidence anchors:**
  - [abstract]: "...MLLMs have significantly improved AI agents' capabilities in... multimodal perception..."
  - [section 4.2]: "By fusing real-time sensor data... with retrieved domain knowledge... they provide accurate diagnostics and proactive recommendations."
  - [corpus]: "UAVs Meet Agentic AI" supports the necessity of multidomain perception for autonomous operation in physical environments.
- **Break condition:** If cross-modal alignment fails (e.g., disconnecting a visual defect from its textual definition in a manual), the system confuses correlations with causation.

### Mechanism 3
- **Claim:** Agentic AI systems can transition from executing fixed schedules to autonomously adjusting production goals via continuous learning loops.
- **Mechanism:** The mechanism relies on "Independent Execution" and "Adaptability" dimensions of Agenticness. It utilizes reinforcement learning and self-supervised learning to refine decision-making strategies in real-time, rather than relying on periodic offline retraining.
- **Core assumption:** The system has sufficient "Goal Complexity" handling to operate with minimal human oversight in safety-critical environments without catastrophic errors.
- **Evidence anchors:**
  - [abstract]: "...Agentic AI highlights adaptability and goal-directed autonomy in dynamic and complex environments."
  - [section 5.4]: "Agentic AI integrates self-supervised learning and reinforcement learning... enabling manufacturing systems to refine decision-making strategies in real time."
  - [corpus]: "Self-Evolving Agentic AI for Wireless Networks" describes a similar autonomous evolution cycle, supporting the conceptual viability of self-updating systems.
- **Break condition:** If the "adaptive learning" loop reinforces sub-optimal behaviors (reward hacking) or if environmental complexity exceeds the model's representation capacity.

## Foundational Learning

- **Concept: Retrieval-Augmented Generation (RAG)**
  - **Why needed here:** Section 4.1 identifies RAG as the primary mechanism for harmonizing structured (ERP) and unstructured (manuals) data to overcome information fragmentation.
  - **Quick check question:** Can you explain how RAG reduces hallucination compared to a standalone LLM when querying a maintenance log?

- **Concept: Multimodal Fusion vs. Alignment**
  - **Why needed here:** Section 3.2 distinguishes MLLM-Agents by their ability to synthesize data types. Understanding the difference between simply concatenating inputs and "semantic alignment" is critical for diagnostics.
  - **Quick check question:** What is the specific challenge in aligning a CAD schematic with a textual maintenance instruction?

- **Concept: The "Agenticness" Spectrum**
  - **Why needed here:** Section 3.3 defines Agentic AI not as a binary state but as a spectrum (Goal Complexity, Environmental Complexity, Adaptability, Independent Execution).
  - **Quick check question:** Why does the paper classify a standard rule-based robot as "non-agentic" while classifying a self-optimizing scheduler as "agentic"?

## Architecture Onboarding

- **Component map:**
  - Profiling Module -> Memory Module -> Planning Module -> Multimodal Perception -> Fusion & Reasoning -> Action

- **Critical path:**
  1.  **Data Grounding:** Establish the RAG pipeline connecting IT/OT systems (ERP/MES) to the Memory Module.
  2.  **Perception Extension:** Integrate the Multimodal Perception Module to ingest sensor/camera data.
  3.  **Agentic Layer:** Overlay the Planning Module to transition from reactive responses to proactive goal optimization.

- **Design tradeoffs:**
  - **Interpretability vs. Autonomy:** Section 6.1.3 notes that higher autonomy (Agentic AI) often results in "opaque black-box" models, making auditability difficult.
  - **Computational Cost vs. Multimodality:** Section 3.2 notes MLLM-Agents require significant power for fusing data streams.

- **Failure signatures:**
  - **Semantic Fragmentation:** Agent fails to parse a PDF manual correctly (Section 6.1.1), leading to nonsensical advice.
  - **Modal Disconnect:** The agent detects a visual anomaly but fails to correlate it with the correct textual repair procedure (Section 6.1.2).
  - **Goal Drift:** An Agentic system optimizes for a metric (e.g., speed) that inadvertently violates safety constraints not explicitly hardcoded (Assumption based on Section 6.3).

- **First 3 experiments:**
  1.  **ChatCNC Simulation:** Build a unimodal LLM-Agent to query a simulated machine log using natural language (based on Section 4.1 examples).
  2.  **Visual Defect RAG:** Implement a basic MLLM-Agent that retrieves text procedures based on an input image of a product defect (based on Section 4.2).
  3.  **Adaptive Scheduling:** Create a constrained Agentic loop that re-optimizes a 3-step production schedule when a simulated "machine downtime" event occurs (based on Section 5.2).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can fine-grained cross-modal semantic alignment be achieved to accurately correlate textual descriptions, mathematical derivations, and visual representations within a unified manufacturing knowledge framework?
- Basis in paper: [explicit] Section 6.1.2 identifies a "critical challenge" in achieving this alignment to ensure diverse data formats complement each other.
- Why unresolved: Current LLMs struggle to extract implicit parameters and constraints from unstructured, multimodal engineering documents effectively.
- What evidence would resolve it: A framework capable of parsing and semantically linking text, LaTeX equations, and CAD files into a consistent knowledge graph without manual intervention.

### Open Question 2
- Question: How can causal inference and physics-informed modeling be integrated into AI agents to ensure traceable and auditable decision-making in high-stakes manufacturing environments?
- Basis in paper: [explicit] Section 6.1.3 states that overcoming the "black-box" limitation of LLMs necessitates integrating these specific modeling techniques.
- Why unresolved: Current models lack the structured reasoning required to verify decisions against domain-specific physical constraints, limiting reliability.
- What evidence would resolve it: An AI agent deployment where specific autonomous decisions are verified as consistent with physics laws and are fully auditable.

### Open Question 3
- Question: What methodologies can effectively quantify the Return on Investment (ROI) for Agentic AI systems in manufacturing when benefits are not immediately measurable?
- Basis in paper: [explicit] Section 6.3 notes that quantifying ROI remains challenging as efficiency gains may not be immediately measurable.
- Why unresolved: The gap between high implementation costs and the difficulty in measuring long-term or intangible benefits hinders business justification.
- What evidence would resolve it: A validated economic model or longitudinal case study demonstrating a clear financial metric for autonomous system integration.

## Limitations
- The review lacks empirical validation data, creating uncertainty about real-world performance of proposed mechanisms
- Key challenges around data integration and workforce adaptation are acknowledged but not deeply explored with concrete mitigation strategies
- Claims about autonomous goal-directed behavior in safety-critical environments may overestimate current technological readiness

## Confidence
- **High Confidence**: The conceptual distinction between LLM-Agents, MLLM-Agents, and Agentic AI is well-supported by the literature and provides a useful taxonomy for understanding AI agent evolution in manufacturing.
- **Medium Confidence**: The proposed architectural components are theoretically coherent, but their practical implementation complexity and effectiveness in real manufacturing environments remain unproven.
- **Low Confidence**: Claims about autonomous goal-directed behavior and real-time adaptive learning in safety-critical manufacturing settings lack empirical validation.

## Next Checks
1. Conduct a pilot study implementing the ChatCNC simulation to evaluate whether a basic LLM-Agent can reliably retrieve and synthesize maintenance procedures from technical documentation without hallucinating critical safety information.
2. Design a controlled experiment testing cross-modal alignment accuracy by having MLLM-Agents match visual defect images with corresponding textual repair procedures from maintenance manuals, measuring precision and recall.
3. Develop a small-scale reinforcement learning testbed where an Agentic scheduling system must adapt production plans in response to simulated equipment failures, tracking goal achievement while monitoring for unintended optimization behaviors.