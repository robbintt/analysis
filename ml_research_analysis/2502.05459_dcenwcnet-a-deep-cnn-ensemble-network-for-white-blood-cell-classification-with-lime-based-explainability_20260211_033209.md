---
ver: rpa2
title: 'DCENWCNet: A Deep CNN Ensemble Network for White Blood Cell Classification
  with LIME-Based Explainability'
arxiv_id: '2502.05459'
source_url: https://arxiv.org/abs/2502.05459
tags:
- classification
- blood
- accuracy
- https
- white
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents DCENWCNet, a novel ensemble-based deep convolutional
  neural network (CNN) architecture designed for white blood cell (WBC) classification.
  The model integrates three customized CNNs, each configured with distinct dropout
  and max-pooling layers to optimize feature learning and improve classification accuracy.
---

# DCENWCNet: A Deep CNN Ensemble Network for White Blood Cell Classification with LIME-Based Explainability

## Quick Facts
- **arXiv ID:** 2502.05459
- **Source URL:** https://arxiv.org/abs/2502.05459
- **Reference count:** 0
- **Primary result:** DCENWCNet achieves 98.53% accuracy on Raabin-WBC WBC classification using ensemble learning with LIME explainability

## Executive Summary
This paper presents DCENWCNet, a novel ensemble-based deep convolutional neural network architecture designed for white blood cell classification. The model integrates three customized CNNs with distinct dropout and max-pooling configurations to optimize feature learning and improve classification accuracy. Using the Raabin-WBC dataset, DCENWCNet achieves 98.53% accuracy with high precision, recall, F1-score, and specificity. The approach combines pixel standardization, aggressive data augmentation, and the Adam optimizer to enhance performance. Additionally, LIME-based explainability is employed to interpret model predictions, improving transparency and reliability.

## Method Summary
DCENWCNet uses an ensemble of three customized CNNs trained on the Raabin-WBC dataset (14,514 images, 64x64x3 RGB). The model employs Gaussian pixel standardization and extensive data augmentation (expanding from ~14k to ~50k images) to address class imbalance. The ensemble architecture uses varying dropout rates and max-pooling configurations across constituent networks. Adam optimizer outperforms RMSprop in training. LIME-based explainability provides post-hoc interpretation of predictions. The model achieves 98.53% accuracy with 0.9782 precision, 0.9817 recall, and 0.9834 F1-score.

## Key Results
- **Accuracy:** 98.53% on Raabin-WBC test set
- **Per-class performance:** Precision 0.9782, Recall 0.9817, F1-score 0.9834, Specificity 0.9865
- **State-of-the-art:** Outperforms existing models including VGG16, ResNet50, and MobileNetV2

## Why This Works (Mechanism)

### Mechanism 1: Heterogeneous Ensemble Architecture
Combining three distinct CNN configurations improves generalization by capturing diverse feature representations. Different dropout rates and max-pooling layers force the ensemble to learn varied intermediate representations, reducing bias dominance when aggregated.

### Mechanism 2: Targeted Data Expansion
Aggressive augmentation (random rotations, shifts, flips) expands dataset from ~14k to ~50k images, mitigating severe class imbalance. This prevents majority-class memorization and forces learning of invariant shape and texture properties.

### Mechanism 3: Post-hoc Local Explainability
LIME provides conditional validation that the model identifies cells rather than background artifacts by highlighting specific regions (nucleus vs. cytoplasm) that contributed most to classification decisions.

## Foundational Learning

- **Concept: Bias-Variance Tradeoff**
  - Why needed: The ensemble balances this tradeoff better than a single CNN
  - Quick check: If you add more layers to a single CNN, which part of the tradeoff typically increases on a small dataset?

- **Concept: Class Imbalance Strategies**
  - Why needed: Raabin-WBC has ~8,800 Neutrophils but only ~300 Basophils
  - Quick check: Why is "Accuracy" a dangerous metric if the model simply predicts "Neutrophil" for every image?

- **Concept: Adam vs. RMSprop Optimization**
  - Why needed: Adam (98.53% acc) significantly outperformed RMSprop (93.93% acc)
  - Quick check: How does momentum (used in Adam) help navigate the loss landscape differently than vanilla gradient descent?

## Architecture Onboarding

- **Component map:** Input -> 3 Parallel Custom CNNs (VGG-style or Custom) -> Ensemble Aggregation layer (Dense/Softmax) -> Output

- **Critical path:**
  1. Preprocessing: Gaussian standardization (mean-centering/std-dev scaling) aids stability
  2. Augmentation: Expansion to 50,024 images prevents overfitting
  3. Optimization: Adam optimizer selection is critical; RMSprop is inferior

- **Design tradeoffs:**
  - Custom vs. Pre-trained: Custom ensemble chosen over pre-trained models to reduce computational overhead
  - Image Resolution: 64x64 lowers computational cost but risks losing fine-grained texture data

- **Failure signatures:**
  - Confusion Clusters: Sometimes confuses Neutrophils with Lymphocytes or Eosinophils
  - Overfitting: Loss curves show gap opening between training and validation loss in later epochs

- **First 3 experiments:**
  1. Baseline Sanity Check: Train a single constituent CNN on unaugmented data
  2. Optimizer Validation: Replicate Adam vs. RMSprop comparison to verify 5% performance gap
  3. Ablation on Augmentation: Train full ensemble without specific augmentation parameters to quantify synthetic data gain

## Open Questions the Paper Calls Out
- Can DCENWCNet maintain high accuracy on multi-cell images containing overlapping or occluded white blood cells?
- Does integrating transfer learning into DCENWCNet yield significant accuracy improvements over scratch-trained implementation?
- Is DCENWCNet robust to domain shifts when tested on external datasets with different staining protocols?

## Limitations
- Underspecified ensemble architecture details, particularly layer configurations and fusion strategy
- Performance depends heavily on specific data augmentation parameters and Adam optimizer configuration
- LIME explainability results difficult to verify without exact segmentation parameters

## Confidence
- **High Confidence:** Ensemble learning approach for WBC classification is well-established
- **Medium Confidence:** Architectural choices (dropout rates, max-pooling) are plausible but lack detailed specifications
- **Low Confidence:** LIME explainability results verification requires specific implementation details

## Next Checks
1. Attempt to reproduce the ensemble model using architectural hints (VGG19-ResNet101-TETD) to verify claimed performance
2. Examine per-class metrics beyond aggregate scores to identify challenging WBC types
3. Test trained model on independent WBC dataset to assess generalization beyond Raabin-WBC