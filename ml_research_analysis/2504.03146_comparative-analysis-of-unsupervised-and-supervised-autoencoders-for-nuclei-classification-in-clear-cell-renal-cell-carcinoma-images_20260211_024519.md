---
ver: rpa2
title: Comparative Analysis of Unsupervised and Supervised Autoencoders for Nuclei
  Classification in Clear Cell Renal Cell Carcinoma Images
arxiv_id: '2504.03146'
source_url: https://arxiv.org/abs/2504.03146
tags:
- latent
- classification
- space
- nuclei
- supervised
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the use of supervised and unsupervised
  autoencoders (AEs) for automating nuclei classification in clear cell renal cell
  carcinoma (ccRCC) images. The research compares various AE architectures, including
  standard AEs, contractive AEs (CAEs), discriminative AEs (DAEs), and a classifier-based
  discriminative AE (CDAE), using Optuna for hyperparameter optimization.
---

# Comparative Analysis of Unsupervised and Supervised Autoencoders for Nuclei Classification in Clear Cell Renal Cell Carcinoma Images

## Quick Facts
- **arXiv ID**: 2504.03146
- **Source URL**: https://arxiv.org/abs/2504.03146
- **Reference count**: 0
- **Primary result**: CDAE-CNN achieves F1 score of 0.6994 for four-class ccRCC nuclei classification, outperforming unsupervised AEs and CHR-Network

## Executive Summary
This study compares supervised and unsupervised autoencoder architectures for nuclei classification in clear cell renal cell carcinoma (ccRCC) images. The research introduces a contractive discriminative autoencoder with a supervised classifier branch (CDAE) and optimizes it using Optuna. The model achieves significant improvements in identifying aggressive ccRCC grades, particularly excelling at distinguishing between grades 2 and 3. The CDAE architecture demonstrates superior performance in both latent space separation and classification accuracy compared to unsupervised variants.

## Method Summary
The study employs a CDAE-CNN architecture with a 9-layer encoder (filters: 26→2, kernel=7, stride=1), batch normalization, ReLU activation, and a 10-dimensional latent space. A classification branch is added to the latent space, and the model is optimized using a combined loss function incorporating reconstruction, discriminative, and classification components. Optuna is used for hyperparameter optimization (up to 1000 trials), tuning loss weights and architecture dimensions. The Bhattacharyya distance metric is employed to assess latent space class separability during optimization.

## Key Results
- CDAE-CNN achieves F1 score of 0.6994, precision of 0.6985, and recall of 0.7008 for four-class ccRCC classification
- Model excels at distinguishing grade 2 vs grade 3 nuclei (F1 scores: 0.5481 and 0.7821 respectively)
- F1-optimized CDAE-CNN shows improved classification despite lower Bhattacharyya distance (36.90 vs 47.23)
- Outperforms CHR-Network across all evaluated metrics

## Why This Works (Mechanism)

### Mechanism 1
Adding a supervised classifier branch to an autoencoder improves latent space class separation for fine-grained nuclei grading tasks. The CDAE architecture routes latent embeddings through a dense classification layer with LogSoftMax output, adding a weighted negative log-likelihood loss to the combined objective. This creates gradient signals that pull same-class embeddings together while pushing different-class embeddings apart, explicitly structuring the latent space around target labels rather than relying solely on reconstruction fidelity.

### Mechanism 2
Bhattacharyya distance provides a more robust metric for latent space separability assessment than cohesion-dispersion metrics treated independently. Bhattacharyya distance directly quantifies distributional overlap between class histograms in the normalized latent space. Unlike Silhouette Score or Davies-Bouldin Index, which can give contradictory signals when intra-class cohesion is high but inter-class separation is low, Bhattacharyya distance symmetrically measures total overlap, yielding a single scalar for optimization.

### Mechanism 3
Optimizing neural architecture search for F1 score rather than Bhattacharyya distance yields better classification performance despite lower measured latent space separation. The F1-optimized CDAE-CNN sacrifices some latent space cluster distinctness in exchange for decision boundaries that better balance precision and recall. This suggests that maximizing geometric separation does not guarantee optimal classifier decision thresholds—the classifier branch can learn non-linear boundaries that work well even when clusters partially overlap.

## Foundational Learning

- **Autoencoder reconstruction loss vs. discriminative structuring**: Understanding how MSE reconstruction incentivizes feature retention while discriminative losses reshape the latent space is essential for debugging why a model might reconstruct well but classify poorly. *Quick check*: If your autoencoder achieves near-zero reconstruction error but random-classification accuracy, which loss weight should you increase?

- **Within-class vs. between-class scatter in metric learning**: The DAE formulation uses explicit within-class (dw) and between-class (db) losses with centroids updated iteratively. This is foundational to understanding why unsupervised DAEs still underperform supervised CDAEs—centroid-based dispersion may not align with decision boundaries needed for classification. *Quick check*: What happens to db if all class centroids collapse to the same point, and how would this affect the discriminative loss?

- **Optuna trial-based hyperparameter optimization**: The paper runs up to 1000 trials with a "funnel effect" for layer dimension reduction. Understanding how Optuna samples the search space and how to define the objective function is critical for reproducing or extending this work. *Quick check*: If you switch the Optuna objective from Bhattacharyya distance to F1 score mid-search, should you resume from existing trials or start fresh?

## Architecture Onboarding

- **Component map**: Input patch → Encoder Conv2D layers → Flatten → Dense(7) → Latent(10) → Parallel: Decoder transpose convs / Classification branch Dense(18) → Output(4, LogSoftMax)
- **Critical path**: Input nucleus patch (background-removed, normalized) → Encoder latent embedding → Parallel paths: (1) Decoder reconstruction, (2) Classification branch prediction → Combined loss → Backprop
- **Design tradeoffs**: Bhattacharyya vs. F1 optimization (higher latent separation vs. higher classification accuracy), MLP vs. CNN encoder (CNN better for spatial morphology), background removal (focuses on intrinsic features but omits context)
- **Failure signatures**: Latent space collapse (CAE contractive loss weight too high), class confusion (Grades 2 vs. 3, check data augmentation and class balance), overfitting to reconstruction (if reconstruction loss drops but classification plateaus)
- **First 3 experiments**:
  1. Baseline reproduction: Train standard AE-CNN with MSE loss only, compute Bhattacharyya distance and F1 to establish lower bounds
  2. Ablation on loss terms: Train DAE vs. CDAE with identical architecture to isolate supervised signal contribution
  3. Objective function swap: Run two Optuna searches (50 trials each)—one maximizing Bhattacharyya, one maximizing F1—and compare architectures and metrics

## Open Questions the Paper Calls Out

- **Semi-supervised learning adaptation**: Can the CDAE-CNN architecture be effectively adapted for semi-supervised learning to reduce reliance on extensive manual annotations while maintaining high accuracy? The authors explicitly state future work aims to extend this method to semi-supervised learning by leveraging unlabeled data.

- **Context restoration impact**: Does the re-introduction of spatial distribution and tissue context improve the model's ability to distinguish between adjacent grades (e.g., Grade 2 vs. Grade 3)? The methodology explicitly isolated nuclei by removing background, which the authors note "omitted information about distribution and positioning."

- **Joint optimization strategy**: Can a joint optimization strategy be developed to maximize both latent space separability (Bhattacharyya distance) and classification accuracy (F1 score) simultaneously? The results showed a trade-off where optimizing for F1 score improved classification but lowered Bhattacharyya distance compared to optimizing for distance directly.

## Limitations

- Focus on isolated nuclei without contextual spatial information, potentially missing distribution patterns critical for accurate grading
- Relatively small dataset size (6,941 nuclei) limiting generalizability
- Use of Bhattacharyya distance as proxy for classification performance may not capture non-linear decision boundaries needed for fine-grained classification

## Confidence

- **High confidence**: CDAE architecture outperforms unsupervised AEs in both latent space separation and classification accuracy, as demonstrated by direct comparisons across multiple architectures and metrics
- **Medium confidence**: Bhattacharyya distance metric provides more robust assessment of latent space separability than traditional clustering metrics, though limited direct comparison evidence exists
- **Medium confidence**: F1 score optimization yields better classification performance despite lower Bhattacharyya distance, based on observed performance differences but lacking systematic validation across other datasets

## Next Checks

1. **Ablation study on loss weights**: Systematically vary the classification branch weight (1-10) while keeping other hyperparameters fixed to quantify its contribution to performance gains
2. **Cross-dataset generalization**: Test the CDAE-CNN model on an independent ccRCC dataset to assess robustness beyond the TCGA data used in training
3. **Context restoration analysis**: Train a variant that includes surrounding tissue context alongside isolated nuclei to measure the impact of background removal on classification accuracy