---
ver: rpa2
title: Can AI Make Energy Retrofit Decisions? An Evaluation of Large Language Models
arxiv_id: '2509.06307'
source_url: https://arxiv.org/abs/2509.06307
tags:
- energy
- retrofit
- llms
- building
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study evaluates the performance of seven large language models\
  \ (LLMs) in residential building energy retrofit decision-making, focusing on CO\u2082\
  \ reduction and payback period objectives. LLMs are tested on 400 homes across 49\
  \ U.S."
---

# Can AI Make Energy Retrofit Decisions? An Evaluation of Large Language Models

## Quick Facts
- arXiv ID: 2509.06307
- Source URL: https://arxiv.org/abs/2509.06307
- Reference count: 40
- Seven LLMs achieve up to 54.5% top-1 accuracy for CO₂ reduction recommendations without fine-tuning

## Executive Summary
This study evaluates seven large language models (LLMs) as "house retrofit specialists" for selecting optimal energy retrofit packages across 400 homes in 49 U.S. states. Without any domain fine-tuning, the models achieve up to 54.5% top-1 accuracy and 92.8% top-5 accuracy for CO₂ reduction recommendations, but struggle with payback period optimization (max 14.3% top-1). The evaluation reveals that LLMs perform best when their feature importance aligns with physics-based baselines, particularly for location and building geometry. However, they show significant limitations in consistency, contextual understanding, and balancing technical with economic objectives.

## Method Summary
The study uses zero-shot prompting to test seven LLMs (ChatGPT o1/o3, DeepSeek R1, Grok 3, Gemini 2.0, Llama 3.2, Claude 3.7) on 400 homes from the ResStock 2024.2 dataset. Each home's 28 key parameters (location, geometry, envelope, HVAC, appliances, occupancy) are converted to natural language via GPT-4o. Models recommend retrofit packages for two objectives: maximizing CO₂ reduction and minimizing payback period. Ground truth is established using EnergyPlus simulations for CO₂ and NREM cost data for payback calculations. Performance is evaluated using Top-k accuracy (k=1,3,5), consistency metrics (Fleiss'/Cohen's Kappa), feature importance analysis, and qualitative reasoning assessment.

## Key Results
- CO₂ reduction accuracy: 54.5% top-1, 78.3% top-3, 92.8% top-5
- Payback period accuracy: 14.3% top-1, 37.5% top-3, 64.8% top-5
- LLMs show negative Fleiss' Kappa for selection agreement, indicating divergent reasoning paths
- Location and building geometry are most important features for accurate recommendations
- Models exhibit step-by-step reasoning but lack deep contextual awareness

## Why This Works (Mechanism)

### Mechanism 1: Feature Importance Alignment Enables Near-Optimal Recommendations
When LLMs assign similar feature importance to physics-based baselines, they achieve higher accuracy in recommending near-optimal retrofits. LLMs correctly prioritize location (county/state) and building geometry (floor area, space combination) as primary decision factors, which aligns with how EnergyPlus simulations weight these variables for thermal load calculations. This alignment allows LLMs to filter the 16 retrofit packages toward climate-appropriate options.

### Mechanism 2: Simplified Engineering Reasoning Chains Produce Coherent but Incomplete Decisions
Models that expose structured reasoning chains (ChatGPT o3, DeepSeek R1) follow engineering-consistent logic, improving interpretability and partial accuracy. These models apply a five-step workflow: (1) estimate baseline energy from location/area, (2) apply envelope upgrade percentage reductions, (3) calculate HVAC efficiency gains, (4) estimate appliance changes, (5) compare outcomes. This mirrors physics-based simulation structure at a coarse level.

### Mechanism 3: Prompt Engineering Determines Context Representation Completeness
Explicit prompt instructions about variable necessity cause LLMs to incorporate more features into their context representation, affecting decision quality. LLMs construct internal representations using language-based associations rather than explicit variable interdependencies. Features with lower salience get dropped unless prompts state their necessity. Adding "considering both initial investment and energy cost savings" triggered more comprehensive reasoning.

## Foundational Learning

- **Physics-based vs. data-driven retrofit decision methods**: The paper positions LLMs as a potential alternative to EnergyPlus simulations; understanding each method's assumptions clarifies why LLMs succeed on CO₂ reduction (technical optimization) but struggle with payback period (sociotechnical trade-offs).
  - Quick check: Why would a model trained on general text perform better at maximizing CO₂ reduction than at minimizing payback period for a specific house?

- **Top-k accuracy and inter-rater reliability (Fleiss' Kappa, Cohen's Kappa)**: The evaluation uses Top-1/3/5 accuracy (allowing near-optimal recommendations) and Kappa metrics to measure whether models agree with each other and with baseline; low agreement among high-accuracy models indicates divergent reasoning paths.
  - Quick check: If seven LLMs all achieve 50% Top-1 accuracy but have negative Fleiss' Kappa for selection agreement, what does this tell you about their decision processes?

- **Feature importance via Random Forest classifiers**: The paper derives percentage feature importance to compare LLMs' input sensitivity against the physics-based baseline, revealing whether LLMs "weight" building characteristics appropriately.
  - Quick check: If an LLM assigns 40% importance to "heating fuel" while the baseline assigns 5%, how might this explain accuracy differences?

## Architecture Onboarding

- **Component map**: ResStock data (28 parameters) -> GPT-4o natural language conversion -> Prompt template -> 7 LLMs -> 10 consolidated retrofit categories -> Top-k accuracy evaluation -> Feature importance analysis
- **Critical path**: Extract 28 parameters per house from ResStock dataset → Construct prompt with retrofit package descriptions + role assignment + house-specific data → Query each LLM for two recommendations → Map LLM output to 10 consolidated retrofit categories → Compare against EnergyPlus-derived baseline at Top-1/3/5 levels → Run sensitivity analysis (feature importance) and consistency analysis (Kappa)
- **Design tradeoffs**: Consolidated 16→10 retrofit categories reduces evaluation complexity but may obscure efficiency tier differences; Using GPT-4o to reframe technical parameters as "household perspective" improves LLM interpretability but introduces another model's biases; Top-k evaluation is more lenient than single-answer accuracy, appropriate given retrofit decisions often have near-equivalent options
- **Failure signatures**: Grok 3 pattern: Disproportionate feature weighting (heating fuel, cooking range) → 25.5% Top-1 accuracy (lowest); Payback period failure: All models struggle (max 14.3% Top-1) due to inability to balance upfront cost vs. energy savings; Negative Fleiss' Kappa for selection: Models make different choices even when accuracy is similar, indicating no consensus reasoning
- **First 3 experiments**: 1) Prompt ablation test: Remove explicit cost-savings instruction and measure payback period accuracy degradation; 2) Feature perturbation test: Mask "county name" in inputs and measure accuracy drop; 3) Reasoning trace validation: For ChatGPT o3/DeepSeek R1, manually compare their assumed baseline energy loads and percentage reduction factors against EnergyPlus outputs

## Open Questions the Paper Calls Out

- **Open Question 1**: Can domain-specific fine-tuning significantly improve LLM accuracy and consistency in energy retrofit decision-making beyond the 54.5% top-1 accuracy achieved without fine-tuning? (basis: paper reports results "without model fine-tuning" and suggests fine-tuning could reduce variability)
- **Open Question 2**: What prompt engineering strategies most effectively integrate less salient but essential features (e.g., occupant behavior, usage level) into LLM context representation for retrofit decisions? (basis: features like "usage level" received moderate importance but "played no role in the reasoning")
- **Open Question 3**: Can hybrid modeling approaches that combine LLMs with physics-based simulations achieve both the interpretability of LLMs and the reliability required for high-stakes retrofit decisions? (basis: discussion proposes hybrid modeling to leverage LLMs for interpreting inputs while physics-based simulations validate results)
- **Open Question 4**: To what extent do LLM retrofit recommendations generalize beyond US residential buildings to commercial buildings, multi-family housing, and international climates with different energy infrastructure? (basis: study limited to 400 US residential homes across 49 states, using US-specific datasets)

## Limitations

- The exact mapping methodology from 16 retrofit packages to 10 consolidated evaluation categories is not explicitly defined, potentially affecting reproducibility
- Model sensitivity to prompt engineering variations remains unclear, with results heavily dependent on specific prompt formulations
- The absence of domain fine-tuning means models rely entirely on pre-trained knowledge, which may not capture building science nuances

## Confidence

- **High Confidence**: Top-k accuracy metrics (0.545/0.783/0.928 for CO₂ reduction) and feature importance rankings are well-documented and reproducible
- **Medium Confidence**: Qualitative reasoning analysis conclusions, as they depend on subjective interpretation of model outputs
- **Low Confidence**: Generalizability beyond the 400 sampled homes and 49 U.S. states tested

## Next Checks

1. **Prompt Sensitivity Test**: Systematically vary prompt formulations (e.g., removing "considering both initial investment and energy cost savings") to quantify impact on payback period accuracy
2. **Geographic Boundary Test**: Evaluate model performance on homes from states not included in the original 49-state sample to assess geographic generalization
3. **Temporal Consistency Test**: Run identical prompts across multiple days/weeks to measure consistency variance and identify probabilistic generation patterns