---
ver: rpa2
title: Landmark-Assisted Monte Carlo Planning
arxiv_id: '2508.11493'
source_url: https://arxiv.org/abs/2508.11493
tags:
- e-01
- greedy
- problem
- e-02
- landmark
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper formalizes probabilistic landmarks for stochastic planning
  and adapts the UCT algorithm to use them as subgoals during rollouts, balancing
  between greedy landmark achievement and final goal achievement. LAMP learns three
  Q-functions to estimate the expected utility of achieving the current landmark,
  the final goal, and the next landmark.
---

# Landmark-Assisted Monte Carlo Planning

## Quick Facts
- arXiv ID: 2508.11493
- Source URL: https://arxiv.org/abs/2508.11493
- Reference count: 40
- Landmark-guided UCT improves planning in most stochastic domains by decomposing problems into subgoals

## Executive Summary
Landmark-Assisted Monte Carlo Planning (LAMP) formalizes probabilistic landmarks for stochastic planning and adapts the UCT algorithm to use them as subgoals during rollouts. The method learns three Q-functions to estimate the expected utility of achieving the current landmark, the final goal, and the next landmark. By balancing between greedy landmark achievement and final goal achievement through a tunable parameter α, LAMP can significantly improve UCT performance in five of six benchmark domains. The optimal balance between greedy and long-term goal focus is problem-dependent, with domains containing deadlocks requiring more conservative approaches.

## Method Summary
LAMP extracts deterministic landmarks from a stochastic planning problem using all-outcomes determinization and the LMRHW algorithm, then uses these landmarks as subgoals in a modified UCT framework. The planner maintains three Q-value tables: one for the final goal, one for the current landmark, and one for landmark selection. During action selection, it combines goal-oriented and landmark-oriented Q-values using a weighting parameter α. The algorithm backpropagates separate cost and reward signals for both the current landmark and the final goal, allowing it to estimate both the cost of achieving subgoals and their utility for reaching the final solution. The method uses GUBS (Goal-Utility-Based Search) criteria with exponential cost weighting.

## Key Results
- LAMP improves UCT performance in 5 of 6 benchmark domains when using well-chosen landmarks
- The optimal α balance between greedy and long-term goal focus is problem-dependent
- In deadlock-free domains, a greedy approach (α→1) often outperforms standard UCT with fewer rollouts
- Domains with probabilistically interesting deadlocks (like triangle_tireworld) show failure when α is too high, as the agent achieves landmarks via unsafe paths

## Why This Works (Mechanism)

### Mechanism 1: Decomposition via Deterministic Landmarks
Using landmarks derived from a deterministic approximation of a stochastic problem can speed up convergence by focusing search on achievable subgoals. LAMP computes a landmark graph by applying "all-outcomes determinization" to the probabilistic domain, and by Theorem 2, any landmark in this determinized version is guaranteed to be a landmark in the original stochastic problem. The planner then treats these necessary conditions as sequential subgoals, reducing the depth of the search tree required to find a heuristic path.

### Mechanism 2: Dual-Criteria Action Selection (The α-Balance)
Balancing greedy pursuit of the next landmark with long-term goal utility improves performance over purely greedy or purely global planning. LAMP maintains two separate value estimations: Q_φ (utility relative to the current landmark φ) and Q_g (utility relative to the final goal). During action selection, it selects the action a that maximizes αQ_φ(s,a) + (1-α)Q_g(s,a), where α→1 focuses on clearing the current subgoal and α→0 focuses on the global horizon.

### Mechanism 3: Hierarchical Value Backpropagation
Simultaneously learning values for subgoals and the final goal allows the agent to estimate the cost of achieving a landmark and the utility of doing so for the final solution. During a rollout, the agent tracks costs for both the current subgoal (λ_φ) and the global goal (λ_g). When the goal or a landmark is reached, these values are backpropagated to update the respective Q-tables (Q_φ, Q_g, Q_LM), allowing Q_LM to learn the expected utility of choosing a specific landmark ordering.

## Foundational Learning

- **Concept: Markov Decision Processes (MDPs) with Dead-ends**
  - Why needed here: LAMP operates on SSPs (Stochastic Shortest Path problems) that may contain states from which the goal is unreachable. Standard UCT minimizes expected cost, but fails in dead-end domains without specific handling.
  - Quick check question: How does the presence of a deadlock state change the objective function of a planner compared to a standard shortest-path problem?

- **Concept: Monte Carlo Tree Search (UCT)**
  - Why needed here: LAMP is a modification of UCT. You must understand how Upper Confidence Bounds (UCB1) balance exploration vs. exploitation to grasp how LAMP modulates this balance using landmarks.
  - Quick check question: In UCT, why does the exploration bonus term C√(ln N(s)/N(s,a)) eventually drive the agent to try less-visited actions?

- **Concept: Classical Planning Landmarks**
  - Why needed here: The "subgoals" in LAMP are not learned online but extracted via classical planning heuristics (LMRHW) on a determinized model.
  - Quick check question: What is the "all-outcomes determinization" of a stochastic action, and why does it yield a superset of the necessary landmarks for the stochastic version?

## Architecture Onboarding

- **Component map:** Fast Downward (LMRHW) -> Landmark Generator -> LAMP Planner (Q-tables) -> Rollout Worker -> GUBS Evaluator
- **Critical path:** The Action Selection Logic (Alg 2, Line 11). This is where α determines if the agent acts "locally" (landmark) or "globally" (goal). Debugging this weighting is the primary lever for performance tuning.
- **Design tradeoffs:**
  - Pre-processing vs. Online: LAMP spends zero time learning landmarks online; it relies entirely on the pre-computed graph
  - Completeness: LAMP trades the theoretical asymptotic optimality of UCT (α=0) for anytime performance (α>0). In deadlock domains, it trades speed for safety
- **Failure signatures:**
  - The "Tireworld" Trap: Success rate drops to 0 as rollouts increase. This implies the landmarks are actively guiding the agent into deadlocks. Fix: Lower α or implement deadlock detection
  - Budget Exhaustion: Average cost ≈ max budget (200). The planner is failing to reach any goal. Fix: Check if landmarks are ordered correctly or if the heuristic is misleading
- **First 3 experiments:**
  1. Hyperparameter Sensitivity (α): Run LAMP on Probabilistic Blocksworld with fixed rollouts (100) and sweep α ∈ {0.0, 0.2, 0.5, 0.8, 1.0}. Plot average cost. Expect a "U-shaped" curve where mid-range α performs best
  2. Deadlock Stress Test: Run on Triangle Tireworld with α=1.0 (Fully Greedy) vs α=0.0 (Standard UCT). Observe the collapse of success rate for the greedy agent
  3. Ablation on Guidance: Remove the landmark graph (force Φ = {g}). Verify the system degrades to standard UCT to ensure your baseline implementation is correct

## Open Questions the Paper Calls Out

- **Question:** How can the greediness parameter α be adapted dynamically during the planning process?
  - Basis in paper: The authors state in the conclusion, "future work could investigate the potential for an adaptive α-value that changes as planning progresses," noting that the optimal value varies by domain and rollout budget
  - Why unresolved: The current implementation requires manual tuning of α, which is problem-dependent
  - What evidence would resolve it: An algorithm that automatically adjusts α based on state features or search progress, demonstrating robust performance without manual tuning

- **Question:** How can LAMP integrate deadlock detection to prevent the selection of landmarks that lead to unsafe states?
  - Basis in paper: The paper highlights "triangle_tireworld" as a worst-case scenario where landmarks mislead the planner into deadlocks, suggesting future work should focus on "integrating deadlock detection and avoidance"
  - Why unresolved: The current greedy approach can inadvertently achieve a landmark while sacrificing the achievability of the final goal
  - What evidence would resolve it: A modified LAMP algorithm that prunes landmark paths leading to deadlocks, improving success rates in "probabilistically interesting" domains with dead-ends

- **Question:** Can non-sampling-based planning algorithms effectively implement the landmark-based decomposition strategy used in LAMP?
  - Basis in paper: The authors note that "using other probabilistic planning techniques, including non-sampling-based approaches, to implement the general landmark-based decomposition approach... could yield improvements"
  - Why unresolved: LAMP is a specific instance based on UCT (MCTS), and it is unclear if the benefits translate to classical Dynamic Programming methods
  - What evidence would resolve it: A comparative study showing improved convergence or solution quality when applying landmark decomposition to algorithms like Value Iteration or Policy Iteration

## Limitations
- Theoretical guarantees are limited to landmark validity, not performance improvement
- Hyperparameter α is highly sensitive and requires manual tuning
- Results are based on specific IPC5 probabilistic domains with discrete actions

## Confidence
- **High confidence:** The core mechanism of using pre-computed landmarks as subgoals is clearly explained and implemented
- **Medium confidence:** Experimental results showing LAMP outperforming standard UCT are convincing but statistical significance testing details are limited
- **Low confidence:** Exponential speed-up claims lack empirical validation and wall-clock time comparisons are not reported

## Next Checks
1. Deadlock sensitivity analysis: Systematically vary the probability of deadlock states in triangle_tireworld and measure how α affects success rate
2. Landmark quality ablation: Compare LAMP performance using landmarks from all-outcomes determinization versus landmarks from the probabilistic problem directly
3. Anytime performance evaluation: Measure LAMP's performance at different rollout budgets to verify it provides meaningful anytime behavior compared to standard UCT