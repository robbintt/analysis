---
ver: rpa2
title: 'Interpersonal Memory Matters: A New Task for Proactive Dialogue Utilizing
  Conversational History'
arxiv_id: '2503.05150'
source_url: https://arxiv.org/abs/2503.05150
tags:
- dialogue
- topic
- user
- chatbot
- proactive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Memory-aware Proactive Dialogue (MapDia),
  a new task integrating memory mechanisms into proactive dialogue systems to enable
  human-like topic transitions based on conversational history. The authors propose
  an automated data construction method and create the first Chinese Memory-aware
  Proactive Dataset (ChMapData), containing 5,453 dialogues across memorable and general
  subjects.
---

# Interpersonal Memory Matters: A New Task for Proactive Dialogue Utilizing Conversational History

## Quick Facts
- arXiv ID: 2503.05150
- Source URL: https://arxiv.org/abs/2503.05150
- Reference count: 25
- Introduces Memory-aware Proactive Dialogue (MapDia) with automated data construction and RAG-based framework

## Executive Summary
This paper introduces Memory-aware Proactive Dialogue (MapDia), a new task that integrates memory mechanisms into proactive dialogue systems to enable human-like topic transitions based on conversational history. The authors propose an automated data construction method and create the first Chinese Memory-aware Proactive Dataset (ChMapData), containing 5,453 dialogues across memorable and general subjects. They develop a RAG-based framework with three components: Topic Summarization, Topic Retrieval, and Proactive Topic-shifting Detection and Generation. Human evaluation shows their model outperforms both a 7B Qwen baseline and GPT-4 on two test sets, achieving higher scores in engagement (1.18 vs. 0.74), overall quality (3.23 vs. 2.70), and topic achievement (0.82 vs. 0.39). Integration testing in a real dialogue system demonstrated a 12.2% improvement in topic-shift ratios and a 27.9% increase in conversation turns per session.

## Method Summary
The authors propose an automated data construction method using heuristic rules and predefined keyword lists to create the Chinese Memory-aware Proactive Dataset (ChMapData) with 5,453 dialogues. Their RAG-based framework consists of three components: Topic Summarization extracts key information from conversational history, Topic Retrieval uses vector similarity to find relevant memories, and Proactive Topic-shifting Detection and Generation handles topic transitions. The framework was evaluated through human assessment and real-world integration testing in a dialogue system, showing improvements in topic-shift ratios and conversation length.

## Key Results
- Human evaluation shows model outperforms 7B Qwen baseline and GPT-4 on two test sets
- Higher engagement scores (1.18 vs. 0.74), overall quality (3.23 vs. 2.70), and topic achievement (0.82 vs. 0.39)
- Real-world integration testing demonstrated 12.2% improvement in topic-shift ratios and 27.9% increase in conversation turns per session
- Ablation studies confirm effectiveness of each framework component

## Why This Works (Mechanism)
The approach works by treating conversational history as a form of memory that can be retrieved and utilized for proactive topic transitions. The RAG-based framework enables the system to summarize conversations, retrieve relevant memories based on semantic similarity, and generate contextually appropriate topic shifts. This mimics human conversational behavior where people naturally reference past experiences and memories when changing topics. The automated data construction method provides large-scale training data that captures the relationship between memories and topic transitions, while the multi-component architecture allows for specialized processing of different aspects of the memory-to-topic pipeline.

## Foundational Learning
- Memory-aware dialogue systems: Needed to enable human-like conversations that reference past experiences; Quick check: Does the system appropriately recall and reference relevant past conversations?
- RAG (Retrieval-Augmented Generation): Needed to combine information retrieval with generation for contextually appropriate responses; Quick check: Are retrieved memories semantically relevant to current conversation context?
- Proactive dialogue: Needed for systems that can initiate topic changes rather than just respond; Quick check: Does the system successfully transition topics without explicit user prompting?
- Vector similarity for memory retrieval: Needed to find semantically relevant memories from large conversation histories; Quick check: Are similar memories retrieved based on semantic meaning rather than exact keyword matches?
- Automated data construction: Needed to create large-scale training data without manual annotation; Quick check: Do generated dialogues capture natural patterns of memory-based topic transitions?

## Architecture Onboarding

Component Map: User Input -> Topic Summarization -> Topic Retrieval -> Proactive Topic-shifting Detection and Generation -> Response Output

Critical Path: The core pipeline flows from user input through summarization, retrieval, detection/generation, and response. Each component must perform effectively for successful topic transitions.

Design Tradeoffs: The automated data construction trades natural conversation complexity for scalability, using heuristic rules and keyword lists. The RAG approach balances retrieval precision with generation flexibility but may struggle with ambiguous or conflicting memories.

Failure Signatures: Topic transitions may fail when memories are incorrectly retrieved (semantic mismatch), when the detection component misidentifies appropriate transition points, or when the generation component produces irrelevant topics. Performance degradation is likely when conversational context becomes too complex or when memories conflict.

Three First Experiments:
1. Test topic summarization accuracy on 100 conversation samples with human evaluation
2. Evaluate memory retrieval precision using known conversation-memory pairs
3. Validate topic-shifting detection performance on conversations with annotated transition points

## Open Questions the Paper Calls Out
None

## Limitations
- Automated data construction relies on heuristic rules and predefined keyword lists that may not capture natural conversational complexity
- Evaluation focuses on surface-level metrics without deeper analysis of genuine memory utilization versus pattern matching
- 7B Qwen baseline comparison doesn't isolate whether improvements come from memory mechanism or model capacity
- Real-world integration testing lacks statistical significance measures and proper control group comparisons

## Confidence

High confidence in dataset construction methodology and baseline performance improvements
Medium confidence in framework's ability to generalize beyond Chinese dialogues and in real-world integration results
Low confidence in system's ability to handle edge cases like conflicting memories or ambiguous contexts

## Next Checks

1. Conduct cross-cultural validation testing with diverse Chinese-speaking populations to assess generalizability across regional dialects and cultural backgrounds
2. Implement A/B testing in real-world deployment comparing the system against rule-based conversational memory systems
3. Perform error analysis on 100+ failed topic transitions to identify whether failures stem from memory retrieval, topic detection, or generation components