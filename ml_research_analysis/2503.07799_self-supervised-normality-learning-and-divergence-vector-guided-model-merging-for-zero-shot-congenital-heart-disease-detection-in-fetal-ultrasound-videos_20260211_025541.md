---
ver: rpa2
title: Self-supervised Normality Learning and Divergence Vector-guided Model Merging
  for Zero-shot Congenital Heart Disease Detection in Fetal Ultrasound Videos
arxiv_id: '2503.07799'
source_url: https://arxiv.org/abs/2503.07799
tags:
- fetal
- data
- sites
- merging
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of detecting Congenital Heart
  Disease (CHD) in fetal ultrasound videos, a task complicated by the scarcity of
  labeled data, strict privacy regulations, and rare occurrence of CHD cases. The
  proposed method introduces a privacy-preserving framework that treats CHD detection
  as a normality modeling problem, integrating self-supervised video anomaly detection
  with model merging.
---

# Self-supervised Normality Learning and Divergence Vector-guided Model Merging for Zero-shot Congenital Heart Disease Detection in Fetal Ultrasound Videos

## Quick Facts
- **arXiv ID**: 2503.07799
- **Source URL**: https://arxiv.org/abs/2503.07799
- **Reference count**: 20
- **Primary result**: Merged model outperforms individual site-specific models by 23.77% in accuracy and 30.13% in F1-score on external test sets.

## Executive Summary
This paper addresses the challenge of detecting Congenital Heart Disease (CHD) in fetal ultrasound videos using a privacy-preserving framework that treats CHD detection as a normality modeling problem. The proposed method integrates self-supervised video anomaly detection with model merging, introducing the Sparse Tube Ultrasound Distillation (STUD) model and Divergence Vector-Guided Model Merging (DiVMerge). The approach achieves strong zero-shot generalization capabilities under domain shifts, outperforming both individual site-specific models and centralized training on unseen data.

## Method Summary
The method involves two key components: (1) Sparse Tube Ultrasound Distillation (STUD) - a self-supervised video anomaly detection model that learns the distribution of healthy fetal hearts using sparse tube sampling and self-distillation loss, and (2) Divergence Vector-Guided Model Merging (DiVMerge) - a two-step process that computes a geometric median to reduce noise and uses divergence vectors to adaptively weight and merge site-specific models. The approach is evaluated on real-world fetal ultrasound data from five hospital sites, demonstrating superior performance in detecting previously unseen CHD anomalies while addressing privacy concerns.

## Key Results
- The merged model outperforms individual site-specific models by 23.77% in accuracy and 30.13% in F1-score on external test sets.
- The merged model improves upon centralized training by 20% in accuracy and 54.6% in F1-score on unseen data, demonstrating strong zero-shot generalization capabilities.
- DiVMerge effectively addresses privacy concerns while achieving superior performance in detecting previously unseen CHD anomalies.

## Why This Works (Mechanism)
### Mechanism 1: Sparse Tube Sampling Preserves Spatio-Temporal Structure While Reducing Token Redundancy
The sparse tube sampling strategy enables computationally efficient video processing without losing clinically relevant temporal dynamics in fetal ultrasound. By using multi-scale 3D tubes with stride 16, the model reduces token count from ~12,522 to 1,176 while capturing both fine spatial detail and long-duration motion patterns.

### Mechanism 2: Self-Distillation with Asymmetric View Processing Learns Normality Without Labels
Teacher-student distillation on augmented views of healthy clips creates a robust normality representation that flags deviations at inference. The teacher network processes only 2 global views, while the student processes both global and 8 local views, ensuring stable representation learning of healthy cardiac motion.

### Mechanism 3: Divergence Vector-Guided Merging Mitigates Inter-Site Model Conflicts
Geometric median computation followed by divergence-weighted parameter selection produces a merged model that outperforms both individual site models and centralized training under domain shift. Parameters with large divergence from median are treated as site-specific noise and replaced with median values.

## Foundational Learning
- **Self-Supervised Video Representation Learning (e.g., VideoMAE, DINO)**: The STUD framework builds on self-distillation principles from DINO, adapted for video with multi-view augmentation. Quick check: Can you explain why the teacher network only processes global views while the student processes both global and local views?
- **Model Merging / Weight Averaging (e.g., Model Soup, Task Arithmetic)**: DiVMerge builds on and compares against prior merging methods. Quick check: What is the key limitation of simple weight averaging when merging models trained on heterogeneous data distributions?
- **Anomaly Detection via Normality Modeling (e.g., one-class classification, reconstruction error)**: The paper reformulates CHD detection as anomaly detection—learning healthy distributions and flagging deviations. Quick check: Why does this approach require no labeled CHD examples during training?

## Architecture Onboarding
- **Component map**: Video clips -> Sparse Tube Tokenizer -> Vision Transformer Backbone -> Self-Distillation Head -> Feature representations -> Geometric Median Solver -> Divergence Vector Computer -> Merged model -> Inference KNN Module
- **Critical path**: 1) Preprocess videos with cropping model, 2) Train STUD locally at each site on healthy clips, 3) Collect site model checkpoints -> compute geometric median, 4) Compute divergence vectors -> apply selective retention and dynamic weighting, 5) Evaluate merged model: extract features from N clips per video -> KNN classification
- **Design tradeoffs**: Token count vs. temporal resolution (stride 16 as balance point), γ threshold for retention (low γ retains more site-specific parameters, high γ relies more on median), number of local views (more views increase compute but capture finer details)
- **Failure signatures**: 1) Merged model underperforms best individual site (divergence threshold too aggressive), 2) High false positive rate on external sites (normality model overfit to training site characteristics), 3) KNN gives inconsistent predictions across clips from same video (feature representation may be unstable)
- **First 3 experiments**: 1) Reproduce site-specific STUD baseline (target: ~64-67% F1), 2) Ablate tube configurations (image tubes vs. video tubes vs. full multi-scale), 3) Pilot merge with 2 sites (compare to Model Soup baseline)

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several implicit questions arise from the analysis:
- How does the definition of "normality" generalize across diverse patient demographics without misclassifying healthy but anatomically distinct cases?
- To what extent does the sparse tube sampling strategy compromise the detection of subtle, fine-grained structural anomalies compared to dense sampling methods?
- What are the specific failure modes of the centralized training approach that cause it to underperform the merged model so significantly on external datasets?

## Limitations
- The paper lacks direct experimental comparison to alternative model merging baselines (e.g., Model Soup, signSGD) on the same dataset.
- The self-supervised normality learning pipeline is evaluated primarily on healthy data, with no analysis of false positive rates on CHD cases.
- The paper does not address potential biases from site-specific scanning protocols or equipment, which could limit real-world generalization.

## Confidence
- **High confidence**: Zero-shot detection performance on external sites - the 20% accuracy and 54.6% F1 improvement over centralized training is well-supported by the results.
- **Medium confidence**: DiVMerge mechanism effectiveness - while the performance gains are significant, the lack of direct baseline comparisons and detailed analysis of divergence vector contributions introduces uncertainty.
- **Low confidence**: Sparse tube sampling's clinical validity - the paper provides performance metrics but lacks ablation studies or clinical validation of whether the reduced token count preserves diagnostically relevant temporal dynamics.

## Next Checks
1. **Baseline Comparison**: Implement and compare DiVMerge against Model Soup and simple weight averaging on the same dataset to quantify the contribution of divergence-vector weighting versus geometric median computation.
2. **Temporal Resolution Ablation**: Train and evaluate STUD models with different temporal sampling strides (stride 8, 16, 32) to determine the impact on detection performance and validate that stride 16 preserves clinically relevant motion patterns.
3. **False Positive Analysis**: Analyze the false positive rates on CHD cases and conduct qualitative analysis of misclassified samples to identify potential failure modes in the normality modeling approach.