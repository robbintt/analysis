---
ver: rpa2
title: Mitigating Hallucinations on Object Attributes using Multiview Images and Negative
  Instructions
arxiv_id: '2501.10011'
source_url: https://arxiv.org/abs/2501.10011
tags:
- image
- arxiv
- lvlms
- images
- input
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses hallucinations on object attributes (HoOA)
  in large vision-language models (LVLMs), where models incorrectly determine fine-grained
  attributes in input images. The authors propose a method leveraging multiview images
  sampled from generated 3D representations as visual prompts to provide more visual
  information from different viewpoints.
---

# Mitigating Hallucinations on Object Attributes using Multiview Images and Negative Instructions

## Quick Facts
- **arXiv ID:** 2501.10011
- **Source URL:** https://arxiv.org/abs/2501.10011
- **Reference count:** 38
- **Primary result:** Proposed MIAVLM achieves 0.787 HoOA metric (average accuracy on positive and negative questions) compared to 0.545-0.634 for existing models.

## Executive Summary
This paper addresses hallucinations on object attributes (HoOA) in large vision-language models (LVLMs), where models incorrectly determine fine-grained attributes in input images. The authors propose a method leveraging multiview images sampled from generated 3D representations as visual prompts to provide more visual information from different viewpoints. They introduce a novel Multiview Image Augmented VLM (MIAVLM) with a Multiview Attributes Perceiver (MAP) submodule that eliminates input image order influence and aligns multiview visual information with LLMs. Additionally, they designed and employed negative instructions to mitigate LVLMs' bias towards "Yes" responses. Comprehensive experiments on their newly proposed HoOA benchmark demonstrate effectiveness, with MIAVLM achieving 0.787 HoOA metric compared to 0.545-0.634 for existing models. The method also shows robustness to multiview image input order, unlike baseline LVLMs.

## Method Summary
The authors propose MIAVLM, which uses multiview images sampled from generated 3D representations to augment visual prompts and mitigate hallucinations on object attributes. The core innovation is the Multiview Attributes Perceiver (MAP) module, which processes multiple views through a Visual Extractor (6 transformer decoder blocks) and a Multihead Sampler (4 heads) to eliminate order dependence. The model is trained with both positive and negative instructions, where negative questions are adversarially modified from positive ones to counter the "Yes" bias prevalent in LVLMs. The training uses a Language Modeling loss with shuffled positive and negative instructions, and only the MAP module is trained while keeping the ViT and LLM frozen.

## Key Results
- MIAVLM achieves 0.787 HoOA metric (average accuracy on positive and negative questions), significantly outperforming baselines (0.545-0.634).
- The model shows robustness to multiview image input order, unlike baseline LVLMs.
- Negative instructions improve negative question accuracy from 0.540 to 0.812, though at the cost of some positive question accuracy degradation.

## Why This Works (Mechanism)
The method works by providing LVLMs with richer visual information through multiview images generated from 3D representations, which captures attributes from multiple perspectives. The MAP module's design ensures that the model's output is invariant to the order of input views, addressing a limitation of baseline models. The inclusion of negative instructions during training helps mitigate the model's inherent bias towards affirmative responses, improving its ability to correctly reject false attributes.

## Foundational Learning
- **3D Generation from Single Images**: Using HFGI3D to create 3D representations from 2D images enables multiview sampling. Why needed: To provide multiple perspectives of the same object without requiring multiple camera shots. Quick check: Verify that 3D models can be generated and that 8 additional views can be sampled from each.
- **Adversarial Question Generation**: Converting positive attribute questions into negative ones by adding "not" or "doesn't have" requires careful phrasing to avoid ambiguity. Why needed: To train the model to correctly reject false attributes rather than always answering "Yes." Quick check: Validate that negative questions are grammatically correct and unambiguous.
- **Order-Invariant Attention Mechanisms**: The Multihead Sampler uses weighted averaging that should be independent of input order. Why needed: To ensure consistent predictions regardless of how multiview images are presented. Quick check: Test model output consistency across different permutations of the same 9 images.

## Architecture Onboarding

**Component Map:** Input images → HFGI3D (3D generation) → Multiview sampling → Frozen ViT-L/16 encoder → MAP module (Visual Extractor + Multihead Sampler) → Soft prompts → Frozen Flan-T5-large LLM → Output

**Critical Path:** Multiview images → MAP module processing → Soft prompt conditioning → LLM generation

**Design Tradeoffs:** The approach trades increased computational cost (processing 9 images per sample) for improved attribute accuracy and robustness. Using frozen backbone models reduces training complexity but limits adaptation potential.

**Failure Signatures:**
- High positive accuracy but low negative accuracy indicates insufficient negative instruction training
- Order-dependent outputs suggest incorrect Multihead Sampler implementation
- Poor performance on the HoOA benchmark suggests issues with 3D generation quality or attribute extraction

**3 First Experiments:**
1. Verify that MAP module outputs are invariant to input order by testing with different permutations of the same 9 images
2. Compare positive vs negative question accuracy to confirm "Yes" bias mitigation
3. Evaluate 3D generation quality by visually inspecting multiview samples for attribute consistency

## Open Questions the Paper Calls Out

**Open Question 1:** Can the MIAVLM method generalize to effectively mitigate HoOA in non-face object domains? The paper constructs the HoOA benchmark exclusively using the CelebAText-HQ dataset, which focuses on "face captioning," and notes that face captioning is used as a "foundational task." Real-world hallucinations often involve the interplay of attributes, existence, and relationships. It is unclear if multiview augmentation for single objects scales or conflicts with scene-level context in multi-object images.

**Open Question 2:** How can the performance trade-off between positive and negative question accuracy be optimized? The authors report that using negative instructions leads to performance degradation on positive questions, dropping accuracy from 0.790 to 0.762. While negative instructions successfully improve negative accuracy (0.540 to 0.812), the current training approach introduces a bias that harms the model's ability to affirm true attributes.

**Open Question 3:** Does the MIAVLM architecture maintain its robustness and accuracy in complex, multi-object scenes? The authors explicitly limit the benchmark to "individual objects (faces)" to "exclude issues related to HoOE [Existence] and HoOR [Relationships]," thereby decoupling the problem. Real-world hallucinations often involve the interplay of attributes, existence, and relationships.

## Limitations
- The method requires computationally expensive 3D generation (HFGI3D) and processing of multiple views per image
- Reliance on proprietary models (Yi-CHAT-34B) for negative instruction generation may limit exact reproduction
- The benchmark is limited to face attributes, raising questions about generalization to other object domains
- Training on a single GPU (NVIDIA 3090) with large models and multiple views may face memory constraints

## Confidence

**High confidence:** The core problem statement (HoOA in LVLMs) is clearly defined and the overall methodology (multiview augmentation + negative instructions) is well-specified.

**Medium confidence:** The architectural details of the MAP module are provided, but exact initialization and implementation details are missing.

**Low confidence:** The experimental validation is difficult to reproduce exactly due to unknown hyperparameters and proprietary data generation components.

## Next Checks
1. Verify that MAP module outputs are invariant to input order by testing with different permutations of the same 9 images
2. Systematically vary batch size on available hardware to identify memory constraints and performance trade-offs
3. Verify that positive and negative question accuracies are balanced after training, confirming the "Yes" bias mitigation