---
ver: rpa2
title: Unified Generative Search and Recommendation
arxiv_id: '2504.05730'
source_url: https://arxiv.org/abs/2504.05730
tags:
- search
- recommendation
- information
- semantic
- item
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the trade-off between search and recommendation
  performance in joint modeling. While existing methods show mutual benefits, improving
  one task often degrades the other due to their distinct information needs: search
  relies on semantic relevance while recommendation depends on collaborative signals.'
---

# Unified Generative Search and Recommendation

## Quick Facts
- arXiv ID: 2504.05730
- Source URL: https://arxiv.org/abs/2504.05730
- Authors: Teng Shi; Jun Xu; Xiao Zhang; Xiaoxue Zang; Kai Zheng; Yang Song; Enyun Yu
- Reference count: 40
- Primary result: GenSAR achieves 12.8% improvement in recommendation NDCG@5 and 25.4% improvement in search NDCG@5 over previous best methods

## Executive Summary
This paper introduces GenSAR, a unified generative framework that addresses the inherent trade-off between search and recommendation performance. The authors demonstrate that while existing joint modeling approaches show mutual benefits, improving one task typically degrades the other due to their distinct information needs - search relies on semantic relevance while recommendation depends on collaborative signals. GenSAR tackles this challenge through dual-purpose identifiers and tailored training strategies, encoding items using both semantic and collaborative embeddings and learning separate identifiers for each through shared and task-specific codebooks.

## Method Summary
GenSAR employs a large language model trained with task-specific prompts to predict next behaviors across search and recommendation contexts. The framework encodes items using both semantic and collaborative embeddings, then learns separate identifiers for each through shared and task-specific codebooks. The training strategy is carefully designed to balance the requirements of both tasks, enabling the model to capture both semantic relevance for search and collaborative signals for recommendation. This dual-purpose approach allows GenSAR to achieve state-of-the-art performance on both tasks simultaneously.

## Key Results
- On commercial dataset: 12.8% improvement in recommendation NDCG@5
- On commercial dataset: 25.4% improvement in search NDCG@5
- Ablation studies confirm effectiveness of joint identifiers and training tasks
- State-of-the-art performance on both public and commercial datasets

## Why This Works (Mechanism)
The mechanism works by balancing the distinct information needs of search and recommendation through a unified generative framework. By using dual-purpose identifiers that capture both semantic and collaborative information, GenSAR can simultaneously optimize for both tasks. The shared and task-specific codebooks allow the model to learn representations that are both task-agnostic and task-specific, enabling effective transfer between search and recommendation contexts. The tailored training strategies ensure that the model learns to prioritize different aspects of user behavior depending on the task context.

## Foundational Learning

1. **Dual-purpose identifiers**
   - Why needed: To capture both semantic and collaborative information simultaneously
   - Quick check: Verify that identifiers encode both content and user interaction patterns

2. **Task-specific codebooks**
   - Why needed: To maintain distinct representations for search and recommendation
   - Quick check: Ensure codebooks produce task-appropriate embeddings

3. **Unified generative framework**
   - Why needed: To leverage shared representations across both tasks
   - Quick check: Validate that model can generate predictions for both search and recommendation

4. **Tailored training strategies**
   - Why needed: To balance the optimization of both tasks
   - Quick check: Monitor task-specific performance during training

5. **Semantic-collaborative embedding fusion**
   - Why needed: To address the trade-off between content-based and collaborative filtering
   - Quick check: Verify that embeddings contain both semantic and collaborative signals

## Architecture Onboarding

**Component Map:**
User Context -> Shared Encoder -> Task-Specific Codebooks -> LLM Prompt Generator -> Next Behavior Predictor

**Critical Path:**
User context and item information flow through shared encoder, then split into task-specific codebooks before generating LLM prompts for behavior prediction.

**Design Tradeoffs:**
- Shared vs. task-specific representations: Balance between parameter efficiency and task-specific optimization
- Semantic vs. collaborative embeddings: Trade-off between content understanding and user preference modeling
- Unified vs. separate training: Balance between joint optimization benefits and task interference

**Failure Signatures:**
- Degradation in one task when optimizing for the other
- Loss of semantic coherence in search results
- Over-reliance on collaborative signals in recommendation

**First Experiments:**
1. Compare performance with only semantic embeddings vs. only collaborative embeddings
2. Test unified training vs. separate training for search and recommendation
3. Evaluate different ratios of shared vs. task-specific parameters

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation primarily focuses on NDCG@5, potentially missing other important metrics
- Limited discussion of computational resources and scalability
- Generalizability to other domains beyond tested datasets not fully explored

## Confidence
- High confidence in core methodology and experimental design
- Medium confidence in scalability claims
- Medium confidence in generalizability to other domains

## Next Checks
1. Conduct user studies to validate whether NDCG improvements translate to actual user satisfaction
2. Test model performance on additional datasets with different characteristics
3. Evaluate computational efficiency and scalability with larger item catalogs and user bases