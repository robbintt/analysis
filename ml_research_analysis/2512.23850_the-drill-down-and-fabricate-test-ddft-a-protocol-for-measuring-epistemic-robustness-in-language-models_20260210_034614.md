---
ver: rpa2
title: 'The Drill-Down and Fabricate Test (DDFT): A Protocol for Measuring Epistemic
  Robustness in Language Models'
arxiv_id: '2512.23850'
source_url: https://arxiv.org/abs/2512.23850
tags:
- epistemic
- robustness
- turn
- ddft
- compression
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "DDFT introduces a novel evaluation protocol that measures epistemic\
  \ robustness\u2014a model\u2019s ability to maintain factual accuracy under progressive\
  \ information degradation and adversarial fabrication. The protocol employs a two-system\
  \ cognitive model: a Semantic System generating fluent text and an Epistemic Verifier\
  \ validating factual accuracy."
---

# The Drill-Down and Fabricate Test (DDFT): A Protocol for Measuring Epistemic Robustness in Language Models

## Quick Facts
- arXiv ID: 2512.23850
- Source URL: https://arxiv.org/abs/2512.23850
- Reference count: 27
- Primary result: Epistemic robustness is orthogonal to model scale and architecture; error detection is the critical bottleneck

## Executive Summary
The Drill-Down and Fabricate Test (DDFT) introduces a novel evaluation protocol that measures epistemic robustness—a model's ability to maintain factual accuracy under progressive information degradation and adversarial fabrication. The protocol employs a two-system cognitive model: a Semantic System generating fluent text and an Epistemic Verifier validating factual accuracy. Testing nine frontier models across eight knowledge domains at five compression levels (1,800 evaluations), DDFT reveals that parameter count shows no significant correlation with robustness while error detection capability emerges as the critical bottleneck.

## Method Summary
DDFT measures epistemic robustness through a 5-turn dialogue protocol with progressive context compression (c ∈ {0.0, 0.25, 0.5, 0.75, 1.0}) and an adversarial fabrication trap in Turn 4. Nine frontier models are evaluated across eight knowledge domains using three-judge LLM juries (GPT-5.1, DeepSeek-v3.1, Claude Opus 4.1) that score responses on Factuality Accuracy Rate (FAR) and Semantic Accuracy Score (SAS) from 0.0-1.0. The Comprehension Integrity (CI) metric combines Hallucination Onset Compression (HOC), Compression Response Integrity (CRI), and adjusted FAR/SAS thresholds to quantify robustness. The protocol assumes substitution of available models for unavailable judge models and provides detailed templates for the fabrication trap and jury rubrics.

## Key Results
- Epistemic robustness shows no significant correlation with parameter count (r=0.083, p=0.832)
- Error detection capability is the critical bottleneck, with Turn 4 performance correlating strongly with CI (ρ=-0.817, p=0.007)
- Smaller models can achieve robust performance comparable to or exceeding flagship models
- Flagship models exhibit brittleness despite their scale, as demonstrated by the Comprehension Integrity index

## Why This Works (Mechanism)
DDFT works by systematically degrading the reference context while maintaining consistent questioning across five turns. The protocol creates conditions where models must rely increasingly on their internal knowledge versus the provided context, revealing epistemic robustness through their ability to detect and reject fabricated information. The two-system cognitive model separates fluent text generation from factual verification, allowing the protocol to measure how well models maintain epistemic integrity under stress.

## Foundational Learning
- **Two-system cognitive architecture**: Why needed—to separate semantic generation from factual verification; Quick check—verify that FAR and SAS scores show dissociation patterns
- **Progressive context compression**: Why needed—to simulate real-world information degradation; Quick check—ensure compression levels produce measurable changes in FAR/SAS scores
- **Adversarial fabrication trap**: Why needed—to test error detection capability; Quick check—verify that Turn 4 responses show significant FAR degradation compared to other turns
- **Three-judge LLM jury**: Why needed—to reduce individual model bias; Quick check—measure inter-rater reliability (target κ>0.79)
- **Comprehension Integrity metric**: Why needed—to quantify epistemic robustness holistically; Quick check—validate CI scores show expected correlations with known robust models

## Architecture Onboarding
- **Component map**: Interviewer Agent -> Semantic System -> Epistemic Verifier -> Jury Scoring -> CI Calculation
- **Critical path**: Turn 1 → Turn 2 → Turn 3 → Turn 4 (fabrication) → Turn 5 → Jury scoring → Metric computation
- **Design tradeoffs**: Uses future LLM judges (unavailable) vs. establishing reliable inter-rater reliability; progressive compression vs. realistic context degradation patterns
- **Failure signatures**: Inconsistent jury scoring (κ<0.70), HOC calculation errors at threshold boundaries, compression methodology not reflecting real-world degradation
- **Three first experiments**: 1) Implement DDFT with available models and measure inter-rater reliability; 2) Test alternative compression methods and measure impact on HOC/CRI; 3) Validate CI metric sensitivity by comparing known robust vs. brittle models

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Do specific training methodologies or data compositions (e.g., RLHF techniques, dataset quality) causally determine epistemic robustness independent of parameter count?
- Basis in paper: The authors state in Section 8.2.1 and 9.4 that "future work should investigate training methodology... What makes o4-mini robust despite small size?" given the observed orthogonality to scale.
- Why unresolved: This study was an observational evaluation of 9 existing frontier models; it did not conduct interventional training experiments to isolate the variables causing robustness.
- What evidence would resolve it: Training ablation studies where models are trained with varied datasets or loss functions (specifically targeting fabrication detection), demonstrating a causal increase in Comprehension Integrity (CI) scores.

### Open Question 2
- Question: Does the Comprehension Integrity (CI) index generalize to dynamic, non-Western, or contested knowledge domains?
- Basis in paper: Section 9.6 lists "Current events," "Non-Western traditions," and "Contested knowledge" as explicit limitations, noting the current concepts "share characteristics... that may not generalize."
- Why unresolved: The evaluated concepts (e.g., Newton's Laws, Impressionism) have static, verifiable ground truths and Western academic origins, potentially biasing the "Epistemic Verifier" evaluation.
- What evidence would resolve it: Replicating the DDFT protocol on concepts with fluid ground truths (e.g., legal precedents) or diverse cultural origins to verify if the two-system dissociation patterns persist.

### Open Question 3
- Question: Can adversarial verification training explicitly strengthen the "Epistemic Verifier" (V_E) more effectively than simply scaling parameters?
- Basis in paper: Section 9.2 proposes "adversarial verification training" as a new paradigm, and Section 9.4 predicts such interventions "should improve Turn 4 performance... more than interventions targeting knowledge expansion."
- Why unresolved: The paper validates that error detection is the bottleneck (Turn 4 correlation) but does not prove that specific training on fabrication detection successfully fixes this bottleneck.
- What evidence would resolve it: A controlled experiment comparing the CI scores of models fine-tuned on fabrication detection tasks against models fine-tuned on standard knowledge retrieval tasks.

## Limitations
- Dependence on unavailable future judge models (GPT-5.1, Claude Opus 4.1, DeepSeek-v3.1) creates uncertainty about result reproducibility
- Compression methodology using truncation/removal may not accurately represent real-world context degradation patterns
- Limited to eight specific knowledge domains that may not capture epistemic robustness across diverse domains

## Confidence
- **High Confidence**: Epistemic robustness is orthogonal to model scale and architecture (supported by n=1,800 evaluations, multiple model families)
- **Medium Confidence**: Error detection is the critical bottleneck for epistemic robustness (supported by correlation analysis ρ=-0.817, p=0.007)
- **Low Confidence**: Smaller models achieve robust performance comparable to flagship models (requires validation with available judge models)

## Next Checks
1. **Judge Model Substitution**: Implement DDFT using available frontier models (e.g., GPT-4, Claude 3.5, Gemini 1.5) and measure inter-rater reliability. Compare CI scores across substitution models to assess consistency with original results.
2. **Domain Generalization**: Extend DDFT to five additional knowledge domains (e.g., quantum computing, epidemiology, constitutional law) and test whether the orthogonality between scale and robustness holds across broader knowledge areas.
3. **Compression Method Variation**: Implement alternative compression methods (progressive word deletion, semantic compression, context window truncation) and measure their impact on HOC and CRI metrics to validate the robustness of findings across compression techniques.