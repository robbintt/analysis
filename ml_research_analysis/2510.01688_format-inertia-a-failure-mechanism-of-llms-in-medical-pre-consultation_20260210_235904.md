---
ver: rpa2
title: 'Format Inertia: A Failure Mechanism of LLMs in Medical Pre-Consultation'
arxiv_id: '2510.01688'
source_url: https://arxiv.org/abs/2510.01688
tags:
- format
- medical
- turn-count
- dialogues
- patient
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'Format Inertia is a failure mechanism in LLMs trained on skewed
  turn-count distributions, causing repetitive, diagnostically uninformative questions
  in long medical dialogues. We propose a data-centric solution: rebalancing the training
  dataset to create a uniform turn-count distribution.'
---

# Format Inertia: A Failure Mechanism of LLMs in Medical Pre-Consultation

## Quick Facts
- arXiv ID: 2510.01688
- Source URL: https://arxiv.org/abs/2510.01688
- Reference count: 26
- One-line primary result: Format Inertia causes repetitive, uninformative questions in LLMs trained on skewed turn-count distributions; uniform sampling mitigates this while maintaining format compliance.

## Executive Summary
Format Inertia is a failure mechanism in LLMs trained on skewed turn-count distributions, causing repetitive, diagnostically uninformative questions in long medical dialogues. We propose a data-centric solution: rebalancing the training dataset to create a uniform turn-count distribution. Experiments show that fine-tuning on this balanced dataset substantially mitigates Format Inertia, improving Task-Constraint Satisfaction Rate from 0.824 to 0.891 for Gemma-3 and from 0.746 to 0.812 for Qwen2.5, while maintaining high Format-Constraint Satisfaction Rate.

## Method Summary
The approach involves analyzing training data turn-count distribution, implementing uniform sampling across turn-count bins, and fine-tuning with QLoRA. Training sets include skewed (1k and 8k samples) and uniform (1k samples) variants. Evaluation uses simulated doctor-patient dialogues with LLM-as-Judge (GPT-4.1-mini) for Task-Constraint Satisfaction Rate and automated validators for Format-Constraint Satisfaction Rate. The key innovation is rebalancing turn-count distribution rather than simply increasing training volume.

## Key Results
- Format Inertia causes progressive degradation in task performance (TCSR) while maintaining format compliance (FCSR)
- Uniform sampling improves TCSR from 0.824 to 0.891 for Gemma-3 and from 0.746 to 0.812 for Qwen2.5
- Data quality and distributional balance matter more than volume (1k uniform > 8k skewed)
- Progressive increase in Jaccard/Cosine similarity across turns confirms repetitive questioning

## Why This Works (Mechanism)

### Mechanism 1: Skewed Turn-Count Distribution Induces Repetitive Pattern Collapse
Training on naturally skewed turn-count distributions (where short dialogues dominate) causes models to generate repetitive, format-correct but diagnostically uninformative questions when dialogues extend beyond typical training lengths. The model receives insufficient exposure to long-dialogue patterns during SFT. When encountering under-represented long contexts at inference, the model falls back to familiar short-dialogue question templates that satisfy format constraints but fail to elicit new diagnostic information. The repetition intensifies as turn count increases.

### Mechanism 2: Uniform Turn-Count Sampling Recovers Task Performance
Rebalancing training data to uniform turn-count distribution improves Task-Constraint Satisfaction Rate while maintaining high Format-Constraint Satisfaction Rate. Equal exposure across dialogue lengths allows the model to learn distinct strategies for long-context information gathering rather than overfitting to short-dialogue patterns. The model develops robust questioning patterns that remain effective beyond the majority training distribution.

### Mechanism 3: Data Volume Amplifies Distributional Bias
Increasing training data volume under skewed distribution exacerbates Format Inertia rather than alleviating it. More skewed data amplifies the model's exposure to short-dialogue patterns, strengthening the overfitting to format-preserving but task-failing behaviors. Distributional bias compounds with scale.

## Foundational Learning

- **Concept:** Format vs. Task Constraint Distinction
  - **Why needed here:** Format Inertia is specifically diagnosable by the gap between high format adherence (FCSR) and low task adherence (TCSR). Understanding this distinction is essential for identifying the failure mode.
  - **Quick check question:** If a model achieves 0.96 FCSR and 0.74 TCSR, what does this pattern specifically indicate about its training data distribution?

- **Concept:** Turn-Count Distribution Analysis
  - **Why needed here:** The entire mechanism hinges on skewed turn-count distributions. Practitioners must be able to analyze and visualize their training data's turn-count histogram before attempting mitigation.
  - **Quick check question:** In a dataset where 12-turn dialogues represent only 1.4% of samples (111 of 8,000), what behavior would you expect from a model at turn 10 of an inference dialogue?

- **Concept:** SFT Distributional Sensitivity
  - **Why needed here:** Standard SFT practice assumes more data is better. This work demonstrates that distributional balance can matter more than volume for specific constraint types.
  - **Quick check question:** Before adding more training data to improve long-dialogue performance, what analysis should you perform to avoid exacerbating Format Inertia?

## Architecture Onboarding

- **Component map:** Data Pipeline (Turn-count binning → quota determination → uniform sampling across bins) → Training (QLoRA fine-tuning with rank 32, alpha 64) → Inference (Doctor model ↔ Patient model multi-turn simulation) → Evaluation (LLM-as-Judge for TCSR; strict validator for FCSR)

- **Critical path:** 1) Analyze source dataset turn-count distribution (histogram, bin sizes) 2) Set sampling quota = minimum bin size; sample uniformly across eligible bins 3) Fine-tune with QLoRA on uniform dataset 4) Evaluate using patient simulation with held-out profiles

- **Design tradeoffs:** Uniform sampling reduces total training samples (999 vs. 8,000) but improves TCSR by 8+ points; longer dialogues inherently contain more complex cases; uniform sampling broadens clinical scenario exposure but sacrifices natural distribution fidelity; strict FCSR validation is automated; TCSR requires LLM judge with inherent subjectivity

- **Failure signatures:** Progressive increase in Jaccard/Cosine similarity across turns; FCSR > 0.90 with TCSR < 0.75; identical or near-identical questions appearing in turns 8+ despite prior answers; patient frustration signals (redundant questioning in production logs)

- **First 3 experiments:** 1) Baseline characterization: Run base model (no SFT) and skewed-SFT model on evaluation set; plot FCSR vs. TCSR gap and similarity curves across turns 2) Distribution ablation: Compare Skewed 1k, Skewed 8k, and Uniform 1k on same evaluation set; isolate volume vs. distribution effects 3) Turn-level analysis: For each model variant, compute per-turn TCSR and similarity scores; confirm correlation between training data turn-frequency and failure rate

## Open Questions the Paper Calls Out

1. **Cross-domain generalization:** Does Format Inertia generalize to other conversational domains like legal counseling or technical support? The paper explicitly states this as a valuable future research direction, noting that the phenomenon's transferability remains untested beyond medical pre-consultation.

2. **Contributing factors:** How do factors other than turn-count distribution—specifically dialogue scenario diversity and model architecture—contribute to or mitigate Format Inertia? The authors acknowledge that other factors could contribute but did not perform ablation studies to isolate these effects.

3. **Evaluation framework adequacy:** Does the LLM-as-a-Judge evaluation framework fully capture nuanced judgments of human medical experts regarding clinical utility? The authors note this limitation and suggest systematic analysis comparing LLM-based assessments with human expert judgments.

## Limitations

- Findings rely on proprietary medical dialogue dataset from AITRICS' VDoc platform, limiting reproducibility and generalizability
- Evaluation uses LLM-as-a-Judge with inherent subjectivity despite reasonable inter-rater agreement (κ=0.8091)
- Optimal turn-count threshold for uniform sampling not systematically explored across different skew patterns
- Generalization to other medical dialogue tasks, languages, or model architectures remains untested

## Confidence

**High confidence:** The empirical demonstration that skewed turn-count distributions cause progressive degradation in task performance (TCSR) while maintaining format compliance (FCSR), with uniform sampling effectively mitigating this specific failure mode.

**Medium confidence:** The mechanism explanation that Format Inertia results specifically from insufficient exposure to long-dialogue patterns during training, though alternative explanations cannot be fully ruled out without additional ablation studies.

**Low confidence:** Generalization to other medical dialogue tasks, languages, or model architectures beyond the specific Korean medical pre-consultation domain studied.

## Next Checks

1. **Cross-dataset validation:** Apply uniform sampling approach to publicly available medical dialogue dataset (e.g., MedDialog) with similar turn-count skew to assess generalizability.

2. **Turn-count threshold ablation:** Systematically vary Tmin (3, 4, 5, 6) and measure corresponding TCSR improvements to identify optimal threshold for different skew patterns.

3. **Alternative evaluation protocol:** Replace LLM-as-a-Judge with human expert panel evaluating subset of outputs for clinical utility to assess whether κ=0.8091 metric holds across evaluator types.