---
ver: rpa2
title: Algorithmic Primitives and Compositional Geometry of Reasoning in Language
  Models
arxiv_id: '2510.15987'
source_url: https://arxiv.org/abs/2510.15987
tags:
- reasoning
- primitive
- primitives
- cluster
- algorithmic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a framework for identifying and steering
  algorithmic primitives underlying LLM reasoning by clustering neural activations
  and linking them to reasoning traces. Primitive vectors are extracted using function
  vector methods and injected into residual streams to induce specific algorithmic
  behaviors.
---

# Algorithmic Primitives and Compositional Geometry of Reasoning in Language Models

## Quick Facts
- **arXiv ID**: 2510.15987
- **Source URL**: https://arxiv.org/abs/2510.15987
- **Reference count**: 40
- **Primary result**: Primitive vectors extracted via activation clustering and function vector methods can be injected into LLMs to steer reasoning behaviors, with geometric composition and transfer across tasks.

## Executive Summary
This paper introduces a framework for identifying and steering algorithmic primitives underlying LLM reasoning by clustering neural activations and linking them to reasoning traces. Primitive vectors are extracted using function vector methods and injected into residual streams to induce specific algorithmic behaviors. The approach is validated across four reasoning tasks (TSP, 3SAT, AIME, graph navigation) using Phi-4, Phi-4-Reasoning, and Llama-3-8B models. Results show that primitives compose geometrically through vector arithmetic, transfer across tasks, and differ between base and reasoning-finetuned models.

## Method Summary
The framework extracts algorithmic primitives from LLM reasoning traces through activation clustering and function vector methods. Layer-17 token representations are clustered (k=50) across reasoning examples, then mapped to algorithmic steps via manual annotation. Primitive vectors are computed as weighted averages of attention head outputs over cluster tokens. These vectors are injected into residual streams at various layers and magnitudes to steer model behavior. Behavioral changes are measured through task-specific hallmarks including path generation patterns, verification counts, and solution quality metrics. The approach demonstrates geometric composition of primitives through vector arithmetic and transfer across reasoning tasks.

## Key Results
- Primitive vectors can be extracted from activation clusters and injected to induce specific algorithmic behaviors (e.g., nearest neighbor paths, verification steps)
- Geometric composition works: adding nearest-neighbor + L1-distance vectors yields L2-distance behavior
- Cross-task transfer: nearest neighbor primitive from TSP affects GraphNav behavior similarly
- Reasoning-finetuned models show more systematic primitive usage: Phi-4-Reasoning exhibits stronger verification/verification primitives than base Phi-4

## Why This Works (Mechanism)
The framework exploits the hypothesis that LLMs decompose complex reasoning into reusable algorithmic primitives represented as distributed patterns in activation space. By clustering these activations and extracting function vectors, the method identifies the neural substrate of specific algorithmic steps. Vector injection manipulates these representations directly, steering reasoning behavior without fine-tuning. Geometric composition emerges because primitives correspond to linear directions in representation space that can be added or subtracted to create new behaviors, reflecting the compositional nature of algorithmic reasoning.

## Foundational Learning
- **Activation clustering**: Grouping neural representations to identify patterns - needed to discover primitive boundaries; quick check: run k-means on layer activations and visualize cluster centers
- **Function vector extraction**: Computing average attention outputs over cluster tokens - needed to create manipulable representations of primitives; quick check: verify injection induces target behavior
- **Residual stream injection**: Adding vectors to hidden states at specific layers - needed to steer model behavior; quick check: measure behavioral hallmark changes across layers
- **Behavioral hallmark metrics**: Task-specific measurements (NN paths, verifications, etc.) - needed to quantify primitive effects; quick check: ensure metrics align with human-interpretable algorithmic steps
- **Geometric composition**: Vector addition/subtraction to combine primitives - needed to demonstrate primitive composability; quick check: verify arithmetic combinations produce expected behaviors
- **Cross-task transfer**: Testing primitives across different reasoning domains - needed to establish generality; quick check: inject TSP primitive into GraphNav and measure similar effects

## Architecture Onboarding

**Component Map**
Input prompts -> Residual stream extraction (layer 17) -> k-means clustering (k=50) -> Manual cluster annotation -> Primitive vector extraction -> Residual stream injection (layers 10-30) -> Behavioral hallmark measurement

**Critical Path**
Token generation → Layer 17 activation extraction → Clustering → Primitive mapping → Vector injection → Behavior measurement

**Design Tradeoffs**
Manual annotation vs. automatic clustering provides interpretability but introduces subjectivity; layer 17 selection balances abstraction level with task-specific detail; k=50 clusters balances granularity with computational tractability.

**Failure Signatures**
Clusters fail to map to interpretable algorithmic steps; primitive injection causes generation collapse or incoherent outputs; geometric composition produces no behavioral change; cross-task transfer fails to generalize.

**First Experiments**
1. Run clustering on TSP layer 17 activations and manually map top 10 clusters to algorithmic steps
2. Inject nearest neighbor primitive vector at layer 15 with α=1 and measure % NN paths in output
3. Test geometric composition by adding NN + L1 vectors and measure emergence of L2-distance behavior

## Open Questions the Paper Calls Out

**Open Question 1**: How do non-linear interactions and manifold geometries govern the composition of algorithmic primitives beyond simple linear vector arithmetic? The current framework only demonstrates linear composition, but complex reasoning likely involves non-linear dependencies.

**Open Question 2**: Can LLMs be directly trained or finetuned using objectives based on algorithmic primitives to enhance compositional generalization? The work extracts existing primitives but doesn't explore incorporating them into training objectives.

**Open Question 3**: Do universal algorithmic primitives and their compositional geometries exist across fundamentally different architectures, such as vision or diffusion models? The framework is demonstrated only on decoder-only LLMs.

**Open Question 4**: To what extent do the geometric representations of algorithmic primitives in LLMs align with human neural representations during analogous reasoning tasks? No empirical comparison with human reasoning data is provided.

## Limitations
- Manual cluster annotation introduces subjectivity and may not generalize across models
- Indirect effect computation method for head selection depends on external work not fully specified
- Behavioral hallmark metrics lack formal definitions in some cases
- Geometric composition experiments are qualitative rather than rigorously quantitative
- Cross-task transfer claims rest on small-scale demonstrations without systematic ablation

## Confidence

- **High Confidence**: Basic pipeline of clustering activations, extracting primitive vectors, and measuring behavioral changes works as described; geometric composition shows consistent qualitative effects
- **Medium Confidence**: Claims about systematic primitive usage differences between base and reasoning-finetuned models need more rigorous statistical validation
- **Low Confidence**: Cross-task primitive transfer and generality of geometric composition across all reasoning primitives need substantially more empirical validation

## Next Checks
1. Implement a formal ablation study on head selection: inject primitive vectors using top 1, 5, 10, 20, 35 heads individually to identify which heads contribute most to behavioral changes
2. Conduct cross-validation of cluster annotations by having multiple independent annotators map clusters to primitives on a held-out subset
3. Design a controlled experiment varying only the prompt (keeping model fixed) to test whether observed differences in primitive usage reflect true model capability differences or prompt-induced behavioral changes