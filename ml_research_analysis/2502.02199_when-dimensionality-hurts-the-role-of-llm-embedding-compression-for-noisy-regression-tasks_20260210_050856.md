---
ver: rpa2
title: 'When Dimensionality Hurts: The Role of LLM Embedding Compression for Noisy
  Regression Tasks'
arxiv_id: '2502.02199'
source_url: https://arxiv.org/abs/2502.02199
tags:
- tasks
- dataset
- language
- dimensionality
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how embedding dimensionality affects performance
  on noisy regression tasks, particularly stock return prediction from news. The authors
  compress high-dimensional LLM embeddings using a simple autoencoder and evaluate
  the compressed representations across multiple domains with varying signal-to-noise
  ratios.
---

# When Dimensionality Hurts: The Role of LLM Embedding Compression for Noisy Regression Tasks

## Quick Facts
- arXiv ID: 2502.02199
- Source URL: https://arxiv.org/abs/2502.02199
- Reference count: 22
- Primary result: Compressed embeddings (8-32 dimensions) outperform high-dimensional (768d) embeddings on noisy regression tasks like stock return prediction

## Executive Summary
This paper demonstrates that high-dimensional LLM embeddings (768 dimensions) can hurt performance on noisy regression tasks by overfitting to noise rather than learning signal. Through systematic compression using autoencoders, the authors show that optimal performance for noisy tasks like stock return prediction occurs at much lower dimensions (8-32) than the original embeddings. The study reveals that gains from interpretable features like sentiment and emotion primarily stem from their dimensionality reduction effect rather than inherent feature informativeness. The optimal dimensionality is shown to be inversely related to signal-to-noise ratio, with noisy tasks benefiting from aggressive compression while high-signal tasks maintain performance across a wider dimensional range.

## Method Summary
The method encodes text using all-mpnet-base-v2 (768-dim), chunks and mean-pools token representations, then compresses via autoencoder bottleneck to varying latent dimensions (dz = 1 to 512). Autoencoder training uses MSE reconstruction loss with early stopping. Compressed embeddings are fed to Random Forest regressors (default parameters) for Huber loss-based evaluation. Three task domains are tested: stock return prediction (noisy), review scoring, and writing quality assessment (high-signal). Targets are standardized and evaluation includes statistical significance testing via T-tests.

## Key Results
- Compressed embeddings (8-32 dimensions) outperform raw 768-dimensional embeddings on noisy tasks like financial return prediction
- Optimal dimensionality varies inversely with signal-to-noise ratio across tasks
- Gains from interpretable features (sentiment, emotion) are primarily due to regularization effects rather than inherent feature value
- High-signal tasks maintain stable performance across dimensions but drop at extreme compression levels

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Compressing LLM embeddings via an autoencoder bottleneck acts as a regularizer that mitigates overfitting in low signal-to-noise tasks.
- **Mechanism:** High-dimensional embeddings (768+ dimensions) contain redundant and noisy features. When passed directly to regression models, models can memorize noise rather than learning signal. The autoencoder bottleneck forces information through fewer dimensions, discarding variance that correlates with noise while preserving task-relevant structure.
- **Core assumption:** The autoencoder reconstruction objective preferentially preserves signal-bearing dimensions over noise dimensions during compression.
- **Evidence anchors:**
  - [abstract] "compressing embeddings, in a minimally supervised manner using an autoencoder's hidden representation, can mitigate overfitting and improve performance on noisy tasks"
  - [section 1] "feature selection or compression can act as a regularising component. When input dimensionality is too large, models risk overfitting by memorising noise rather than learning meaningful patterns"
  - [corpus] Related work on intrinsic dimensionality (arXiv:2506.01435) finds prompt-based embeddings contain substantial redundancy, supporting the regularization hypothesis
- **Break condition:** If task signal is high (direct causal dependency between input and target), compression removes informative features and hurts performance.

### Mechanism 2
- **Claim:** Optimal embedding dimensionality varies inversely with task signal-to-noise ratio.
- **Mechanism:** Noisy tasks (e.g., financial returns) have weak, sparse signal buried in high-dimensional noise—compression helps by regularizing. High-signal tasks (e.g., review scoring) have direct text-score mappings where dimensionality matters less until extreme compression loses critical information.
- **Core assumption:** Task noise level can be characterized independently of the embedding dimension choice.
- **Evidence anchors:**
  - [abstract] "lower-dimensional representations improve performance on noisy tasks like stock return prediction... For high-signal tasks like review scoring and writing quality assessment, performance remains stable across dimensions but drops at extreme compression levels"
  - [section 4.1] "for the financial returns task, there is a convex relationship between performance and dimensionality, whereas the relationship approximates a negative exponential in tasks with a strong signal"
  - [corpus] Weak direct corpus evidence on signal-to-noise tuning; related compression papers focus on retrieval quality, not regression noise
- **Break condition:** If signal-to-noise cannot be estimated a priori, tuning dimensionality requires empirical search.

### Mechanism 3
- **Claim:** Gains from interpretable features (sentiment, emotion) in noisy tasks stem primarily from dimensional regularization, not feature informativeness.
- **Mechanism:** Sentiment/emotion classifiers output low-dimensional probability vectors (e.g., 3-7 dimensions). Their success in financial prediction may arise because this compression regularizes, not because the features capture unique signal. Autoencoder latent features at similar dimensions perform comparably.
- **Core assumption:** The autoencoder learns representations of comparable regularizing quality to human-designed features when dimensionality is matched.
- **Evidence anchors:**
  - [abstract] "gains from interpretable features like sentiment and emotion are primarily due to regularization effects rather than inherent feature value"
  - [section 4] "both representations do not exceed the expected performance of the autoencoder features at their respective dimensions... most of this performance improvement can be explained due to the regularising effect of dimensionality reduction"
  - [corpus] No corpus papers directly test this regularization vs. feature-value claim
- **Break condition:** If sentiment/emotion features encode domain knowledge not captured by general autoencoder, they may outperform matched-dimension latent features.

## Foundational Learning

- **Concept:** Autoencoder bottleneck compression
  - **Why needed here:** Core technique for reducing embedding dimensionality while preserving reconstructable information
  - **Quick check question:** Can you explain why a narrower bottleneck forces the encoder to prioritize which information to keep?

- **Concept:** Signal-to-noise ratio in regression
  - **Why needed here:** Determines whether compression helps or hurts; noisy tasks benefit, high-signal tasks tolerate high dimensions
  - **Quick check question:** Given a new regression task, what signals would suggest it has low vs. high signal-to-noise?

- **Concept:** Regularization via representation constraints
  - **Why needed here:** Alternative view of compression—not feature selection but capacity restriction that prevents overfitting
  - **Quick check question:** How does limiting representation dimensionality differ from L2 regularization or dropout in mechanism?

## Architecture Onboarding

- **Component map:** Text → Tokenization → Chunking (max context window C, M chunks) → LLM encoder (all-mpnet-base-v2, 768d) → Mean pooling across chunks → Autoencoder encoder E (768d → d_z) → Compressed representation z → Random Forest regressor → Prediction

- **Critical path:** Embedding quality → Compression dimension d_z → Regression performance. The d_z hyperparameter is the primary lever; encoder choice and regression model are secondary.

- **Design tradeoffs:**
  - d_z too high (128-512): Overfitting on noisy tasks, no benefit on high-signal tasks
  - d_z too low (1-2): Information loss, underfitting across all tasks
  - Sweet spot: 8-32 dimensions for tested tasks; tune empirically

- **Failure signatures:**
  - Training loss decreases but validation loss increases with high d_z on noisy tasks → overfitting, reduce dimension
  - Both training and validation errors high at low d_z → underfitting, increase dimension
  - High variance in predictions across runs → Random Forest may be unstable; MLP was tried but showed inadequate performance and high variance

- **First 3 experiments:**
  1. Establish baseline: Run regression with raw 768d embeddings (no compression) to measure uncompressed performance and variance
  2. Sweep d_z values: Test d_z ∈ {1, 2, 4, 8, 16, 32, 64, 128, 256, 512} with Huber loss; identify convex region optimal for your task's noise level
  3. Compare interpretable features: Add sentiment/emotion probability vectors as controls at their native dimensions to test whether their performance exceeds matched-d_z autoencoder features

## Open Questions the Paper Calls Out

- **Open Question 1:** Can adaptive compression methods be developed that dynamically adjust dimensionality based on the signal-to-noise ratio of a given task?
  - Basis in paper: [explicit] "Future research could explore adaptive dimensionality compression methods that dynamically adjust based on the signal-to-noise ratio; however, to do this, a measure of signal-to-noise is required before processing the input features."
  - Why unresolved: No pre-processing metric exists to quantify task noise level before feature extraction and model training.
  - What evidence would resolve it: Development of a signal-to-noise estimation method applicable to unlabeled text corpora, followed by experiments showing adaptive compression outperforms fixed dimensionality.

- **Open Question 2:** How does autoencoder-based compression compare to other dimensionality reduction techniques (PCA, t-SNE, UMAP) for noisy regression tasks?
  - Basis in paper: [explicit] "The paper does not explore other ways of compressing the text representations. PCA, t-SNE, UMAP are all options for dimensionality compression."
  - Why unresolved: Only autoencoder compression was tested; the relative advantages of supervised versus unsupervised compression remain unknown.
  - What evidence would resolve it: Controlled experiments comparing reconstruction fidelity and downstream regression performance across compression methods at matched dimensionalities.

- **Open Question 3:** Do the findings on optimal dimensionality generalize across different LLM embedding architectures?
  - Basis in paper: [explicit] "The findings are only reported for one model" (all-mpnet-base-v2).
  - Why unresolved: Different embedding models may encode information differently, potentially affecting compression characteristics.
  - What evidence would resolve it: Replication of the compression experiments using decoder-based embeddings (e.g., LLM2Vec) or larger encoder models, confirming whether the 8-32 dimension optimum holds.

## Limitations

- The autoencoder architecture specification is incomplete, with unspecified internal layer structure, activation functions, and training hyperparameters
- The study assumes a universal optimal dimensionality range (8-32) across diverse regression tasks, which may be task-specific beyond tested domains
- The claim that interpretable features succeed primarily through regularization rather than informativeness lacks direct experimental evidence isolating feature content from dimensionality effects

## Confidence

**High confidence:** The core empirical finding that dimensionality reduction improves noisy regression performance and that optimal dimensions vary inversely with signal-to-noise ratio. This is directly observable from the performance curves across the three test domains and supported by clear statistical comparisons.

**Medium confidence:** The generalization that aggressive compression (8-32 dimensions) represents an optimal sweet spot for noisy regression tasks broadly. While well-supported for the tested domains, the claim extends beyond the specific datasets and requires validation on additional task types.

**Low confidence:** The specific claim that sentiment/emotion features' success is "primarily" due to regularization effects rather than inherent feature value. This is inferred from comparable performance to matched-dimension autoencoder features but lacks direct experimental evidence isolating feature content from dimensionality effects.

## Next Checks

1. **Reconstruct the autoencoder architecture:** Implement the autoencoder with multiple reasonable architectures (varying depth, width, activation) and verify whether optimal dimensionality remains stable across implementations or varies significantly with architectural choices.

2. **Test additional noisy regression tasks:** Apply the dimensionality sweep to at least two new noisy regression domains (e.g., social media engagement prediction, weather forecasting from text) to validate whether the 8-32 dimension sweet spot generalizes beyond the tested domains.

3. **Feature content ablation study:** Create synthetic interpretable features that match sentiment/emotion dimensions but contain no domain-specific information (e.g., random probability vectors, uniform distributions) and test whether they achieve comparable performance, directly testing the regularization hypothesis.