---
ver: rpa2
title: Improving French Synthetic Speech Quality via SSML Prosody Control
arxiv_id: '2508.17494'
source_url: https://arxiv.org/abs/2508.17494
tags:
- prosodic
- speech
- prosody
- ssml
- break
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper introduces the first end-to-end pipeline that automatically
  converts French speech into SSML-compliant markup for controlling pitch, speaking
  rate, volume, and pause duration in TTS systems. The cascaded architecture uses
  two QLoRA-fine-tuned Qwen 2.5-7B models: one predicts phrase-break positions and
  the other performs regression on prosodic targets.'
---

# Improving French Synthetic Speech Quality via SSML Prosody Control

## Quick Facts
- arXiv ID: 2508.17494
- Source URL: https://arxiv.org/abs/2508.17494
- Reference count: 17
- First end-to-end pipeline that automatically converts French speech into SSML-compliant markup for controlling pitch, speaking rate, volume, and pause duration in TTS systems

## Executive Summary
This paper introduces a cascaded architecture using two QLoRA-fine-tuned Qwen 2.5-7B models to automatically generate SSML markup for controlling French TTS prosody. The system achieves 99.2% F1 for break placement and reduces mean absolute error on pitch, rate, and volume by 25-40% compared to LLM prompting and BiLSTM baselines. Perceptual evaluation with 18 participants shows a significant increase in naturalness, with MOS rising from 3.20 to 3.87 (p < 0.005) and 15 out of 18 listeners preferring the enhanced synthesis. The approach bridges the expressiveness gap between synthetic and natural French speech while ensuring compatibility with commercial TTS engines.

## Method Summary
The method uses a cascaded pipeline where QwenA predicts `<break>` tag positions using next-token prediction, then QwenB performs regression on prosodic parameters to fill empty `<prosody>` placeholders. Both models are QLoRA-fine-tuned Qwen 2.5-7B with 4-bit quantization. Prosody features (pitch, volume, rate) are computed as deltas relative to a synthetic baseline voice, normalized via sliding-window medians, and converted to SSML-compatible percentages. The system processes French podcast audio through Demucs source separation, Whisper alignment, syntagm segmentation, and feature extraction before generating SSML markup for TTS synthesis.

## Key Results
- Cascaded model achieves F1=99.24% for break placement and MAE <1.1% for pitch/volume/rate
- MOS increases from 3.20 to 3.87 (p < 0.005) with 15/18 participants preferring enhanced synthesis
- Outperforms BiLSTM and few-shot LLM baselines by 25-40% on objective metrics
- Maintains SSML validity while improving naturalness across multiple prosodic dimensions

## Why This Works (Mechanism)

### Mechanism 1: Disentangled Structural and Numerical Prediction
Separating break placement from prosody parameter regression improves both accuracy and markup validity. Two QLoRA-fine-tuned Qwen 2.5-7B models operate in cascade: QwenA predicts `<break>` tag positions using next-token prediction (F1=99.24%, perplexity=1.001), then QwenB fills empty `<prosody>` placeholders with numerical attributes (pitch/rate/volume). The structural model ensures syntactically valid SSML; the regression model focuses capacity on numerical precision.

### Mechanism 2: Relative Prosody Normalization Against Synthetic Baseline
Normalizing prosodic features relative to a commercial TTS baseline produces transferable SSML deltas compatible with standard engines. For each syntagm, pitch/volume/rate are computed for both natural speech and synthetic baseline (Azure Henri voice). Deltas are normalized via sliding-window medians (w=10 segments), converted to SSML-compatible percentages with asymmetric clipping, and exponentially smoothed (α=0.2). This yields engine-agnostic adjustments rather than absolute acoustic values.

### Mechanism 3: Prosodic Syntagm Segmentation via Acoustic-Punctuation Fusion
Combining acoustic pause detection with linguistic constraints yields stable prosodic units for feature extraction. Whisper Timestamped alignment produces word/pause sequences; pauses following function words are filtered (POS-based), punctuation-triggered pauses are clamped to ≥500ms, and missing sentence boundaries are injected. This produces "syntagms"—linguistically meaningful prosodic units—that anchor subsequent feature extraction and SSML tag placement.

## Foundational Learning

- **SSML (Speech Synthesis Markup Language)**: Why needed: SSML provides the standardized interface for controlling commercial TTS prosody via tags (`<prosody>`, `<break>`). Quick check: Given the SSML tag `<prosody rate="+10%" pitch="-5%">`, what would happen if an engine does not support negative pitch adjustments?

- **QLoRA Fine-Tuning**: Why needed: The paper uses QLoRA (rank=8, α=16, 4-bit quantization) to adapt Qwen 2.5-7B for prosody tasks. Quick check: Why would computing loss only on numeric tokens help the adapter specialize for regression?

- **French Prosodic Structure (Syntagms)**: Why needed: French prosody differs from English—phrase-final rises, liaison effects, and specific pause patterns. Quick check: How might the authors' 500ms minimum pause for sentence boundaries interact with French phenomena like enchaînement or liaison?

## Architecture Onboarding

- **Component map**: Demucs source separation -> 16kHz downsampling -> Whisper Timestamped alignment -> syntagm segmentation -> feature extraction -> QwenA break prediction -> QwenB prosody regression -> SSML generation -> TTS synthesis

- **Critical path**: Alignment accuracy (Whisper ARR=96.3%) -> syntagm segmentation quality -> prosody delta computation -> QwenA break prediction (F1=99.24%) -> QwenB coefficient regression (MAE<1.1%) -> final SSML validity and perceptual quality (MOS 3.87)

- **Design tradeoffs**: Cascaded vs. single model separation improves specialization but risks error propagation; Qwen 2.5-7B vs. larger LLMs chosen for fine-tuning feasibility and latency; relative vs. absolute prosody improves engine compatibility but requires voice-specific recalibration; prompting vs. fine-tuning ensures structural completeness but requires labeled data

- **Failure signatures**: SSML under-generation (output contains fewer `<break>` or `<prosody>` tags than expected), high perplexity on breaks (QwenA perplexity >1.1), MAE spike on volume (volume MAE >5%), alignment drift (text-audio misalignment causing incorrect syntagm boundaries)

- **First 3 experiments**: 1) Validate alignment pipeline: Run Whisper Timestamped on 1 hour of manually annotated audio; compute ARR and start/duration MAE against gold TextGrids. 2) Ablate cascaded architecture: Compare (a) QwenA+QwenB cascade, (b) single Qwen 2.5-7B fine-tuned for joint SSML generation, (c) few-shot Qwen 2.5-7B. 3) Cross-voice generalization test: Train prosody deltas using Azure Henri baseline; synthesize SSML-enhanced audio with different Azure French voices; measure MOS degradation and identify systematic recalibration needs.

## Open Questions the Paper Calls Out

### Open Question 1
Can the cascaded architecture be unified into a single end-to-end model without sacrificing the structural-numerical disentanglement benefits that enable its current performance? The current two-model design explicitly separates tasks, achieving near-perfect F1 and low MAE. It remains unknown whether a unified model can maintain this disentanglement or would suffer from interference between structural and numerical objectives.

### Open Question 2
Does the approach generalize to languages with fundamentally different prosodic systems (e.g., tonal languages, mora-timed languages) without architecture modifications? French has specific prosodic features that guided feature engineering. The normalization strategies and 500ms pause clamping rule were designed for French; their transferability to tonal languages like Mandarin or mora-timed Japanese is untested.

### Open Question 3
Can multimodal audio embeddings improve prosody prediction beyond text-derived features alone, particularly for capturing speaker-specific characteristics the current system cannot model? The current system predicts prosody from text only; speaker identity, affect, and acoustic context are not encoded. The paper shows cross-speaker pitch variability that text-only models cannot capture, suggesting a ceiling on personalization.

## Limitations
- Engine compatibility limited to single Azure TTS baseline; cross-engine transfer untested
- French language specificity may not generalize to other languages with different prosodic structures
- Causal attribution unclear as perceptual improvement conflates multiple system components

## Confidence

**High Confidence**: Break placement accuracy (F1=99.24%, perplexity=1.001) from QwenA fine-tuning; cascaded architecture outperforming BiLSTM and few-shot LLM baselines by 25-40% in MAE metrics; perceptual naturalness improvement validated by 18 participants with statistical significance

**Medium Confidence**: Relative normalization strategy produces "engine-agnostic adjustments" (no direct cross-engine validation); Whisper alignment achieving 96.3% ARR (assumed from reported metrics, but no gold standard comparison shown); QLoRA efficiency claims (15GB GPU, 190ms latency) without ablation of quantization parameters

**Low Confidence**: "Transferable SSML deltas" claim (directly contradicted by Section 7 acknowledgment of voice-specific recalibration needs); "Sufficiently distinct linguistic cues" assumption for cascaded separation (no joint dependency analysis provided); "96.3% Alignment Recall Rate" metric without definition of false positive/negative handling

## Next Checks

1. **Cross-Voice Transfer Test**: Train prosody deltas using Azure Henri baseline, then synthesize SSML-enhanced audio with three different Azure French voices (e.g., Denise, Paul, Alice). Measure MOS degradation and compute per-voice calibration factors needed to maintain target naturalness levels.

2. **Causal Mechanism Ablation**: Systematically disable individual prosody controls (pitch only, rate only, volume only, breaks only) in the cascaded pipeline. Generate SSML markup with each control removed and measure both objective metrics (MAE on remaining parameters) and perceptual MOS to isolate contribution of each mechanism.

3. **Error Propagation Analysis**: Create controlled test cases with known break placement errors (e.g., artificially misalign 10% of breaks). Pass these through QwenB to measure how structural errors propagate to prosody coefficient regression accuracy. Quantify the cascade's error amplification factor.