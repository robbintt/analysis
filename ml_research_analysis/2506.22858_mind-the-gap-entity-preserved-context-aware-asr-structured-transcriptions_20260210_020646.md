---
ver: rpa2
title: 'Mind the Gap: Entity-Preserved Context-Aware ASR Structured Transcriptions'
arxiv_id: '2506.22858'
source_url: https://arxiv.org/abs/2506.22858
tags:
- entity
- entities
- second
- chunk
- audio
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of improving named entity recognition
  (NER) and formatting accuracy in automatic speech recognition (ASR) systems, particularly
  for long-form audio and complex entity types like phone numbers and monetary values.
  The authors propose a novel training approach that extends the semantic context
  of ASR models by adding overlapping context windows during training.
---

# Mind the Gap: Entity-Preserved Context-Aware ASR Structured Transcriptions

## Quick Facts
- arXiv ID: 2506.22858
- Source URL: https://arxiv.org/abs/2506.22858
- Reference count: 13
- Key outcome: Proposed method significantly improves NER F1 scores and reduces CER for numerical entities in ASR transcriptions.

## Executive Summary
This work addresses the challenge of improving named entity recognition (NER) and formatting accuracy in automatic speech recognition (ASR) systems, particularly for long-form audio and complex entity types like phone numbers and monetary values. The authors propose a novel training approach that extends the semantic context of ASR models by adding overlapping context windows during training. Specifically, they slide 5-second overlaps on both sides of 30-second training chunks, creating a 40-second "effective semantic window," while focusing predictions on the central 30 seconds. Entities spanning chunk boundaries are reassigned entirely to the right-hand chunk to ensure proper formatting. The model is trained on enriched data with embedded entity labels to learn both recognition and type-specific formatting.

Evaluated on the Spoken Wikipedia dataset, the proposed method significantly improves performance across semantic tasks, including NER and entity formatting. The baseline Whisper-Medium model achieved a 38% word error rate (WER), which was reduced to 26% with fine-tuning. The windowed approach further improved NER F1 scores (e.g., from 0.50 to 0.65 for PERSON entities) and reduced character error rates (CER) for numerical entities (e.g., from 0.25 to 0.12 for CARDINAL entities). These results highlight the effectiveness of context-aware training in addressing ASR limitations for long-form transcription and complex entity recognition tasks.

## Method Summary
The authors propose a context-aware training strategy for ASR models that addresses entity recognition and formatting challenges. The approach involves sliding 5-second overlaps on both sides of 30-second training chunks, creating a 40-second effective semantic window while focusing predictions on the central 30 seconds. Boundary-spanning entities are reassigned to the right chunk to ensure proper formatting. The model is trained on enriched data with embedded entity labels to learn both recognition and type-specific formatting. This method extends the semantic context available during training, helping the model better handle long-form audio and complex entity types that often span segment boundaries.

## Key Results
- Baseline Whisper-Medium achieved 38% WER, reduced to 26% with fine-tuning
- PERSON NER F1 improved from 0.50 to 0.65 with windowed approach
- CARDINAL CER reduced from 0.25 to 0.12 for numerical entities

## Why This Works (Mechanism)
The mechanism works by extending the effective semantic context available during ASR training. Standard ASR models process fixed-length chunks in isolation, which causes context loss for entities spanning chunk boundaries. By adding 5-second overlaps on both sides of training segments, the model gains additional contextual information that helps resolve entity boundaries and formatting. The reassignment of boundary-spanning entities to the right chunk ensures consistent entity formatting across segment transitions. Training with embedded entity labels helps the model learn type-specific formatting patterns for different entity categories.

## Foundational Learning

**Named Entity Recognition (NER)**: Identifying and classifying named entities in text into predefined categories like persons, organizations, locations, dates, etc. Why needed: ASR output often contains errors in entity recognition and formatting, requiring specialized training approaches. Quick check: Can the model correctly identify and classify "New York" as a location entity?

**Context Windows in ASR**: Fixed-length audio segments processed independently by ASR models. Why needed: Standard ASR training uses non-overlapping chunks, causing context loss for entities spanning boundaries. Quick check: Does the model maintain entity consistency across segment transitions?

**Entity Formatting**: Converting raw entity mentions into standardized formats (e.g., phone numbers, monetary values, dates). Why needed: ASR systems often fail to properly format complex numerical entities. Quick check: Can the model correctly format "five hundred dollars" as "$500"?

## Architecture Onboarding

**Component Map**: Audio Input -> Overlap Windowing -> ASR Model -> Entity Prediction -> Formatting Layer

**Critical Path**: The core workflow processes 30-second chunks with 5-second overlaps on each side, where the model receives 40 seconds of contextual audio but predicts only the central 30 seconds. Boundary-spanning entities are detected and reassigned to the right chunk during post-processing.

**Design Tradeoffs**: The 5-second overlap represents a balance between computational efficiency and contextual coverage. Larger overlaps would provide more context but increase computational cost and training time. The reassignment strategy prioritizes formatting consistency over strict segment boundaries.

**Failure Signatures**: The system may struggle with entities that span more than 5 seconds, entities with ambiguous boundaries, or cases where context from the overlap region is insufficient for disambiguation. Performance may degrade in noisy audio conditions or with unfamiliar entity types.

**First Experiments**:
1. Test entity recognition accuracy on single, well-defined entities within the central 30-second window
2. Evaluate boundary-crossing entity handling by creating synthetic test cases with entities spanning chunk boundaries
3. Measure formatting accuracy for numerical entities (phone numbers, monetary values, dates) compared to baseline models

## Open Questions the Paper Calls Out

None

## Limitations

- Single dataset evaluation (Spoken Wikipedia) may limit generalizability to other domains
- No ablation studies to isolate impact of overlapping context versus other model modifications
- Entity reassignment strategy could introduce bias for truly split entities
- Lacks human judgment or downstream task performance measures for real-world utility assessment

## Confidence

- **High**: Core claims about improved NER F1 scores and reduced CER for numerical entities are well-supported by specific quantitative results
- **Medium**: Effectiveness of 5-second overlap strategy is demonstrated but not compared against alternative context window sizes
- **Low**: Broader applicability of method is uncertain due to single-dataset evaluation and lack of cross-domain validation

## Next Checks

1. Evaluate the proposed method on additional ASR datasets with diverse entity types and audio conditions (e.g., conversational speech, noisy environments) to assess generalizability.

2. Conduct ablation studies to isolate the contribution of overlapping context windows versus other model components (e.g., entity label embeddings, training objectives).

3. Perform human evaluation or downstream task performance tests (e.g., information retrieval, entity linking) to measure the practical impact of improved NER and formatting accuracy.