---
ver: rpa2
title: A Trustworthiness-based Metaphysics of Artificial Intelligence Systems
arxiv_id: '2506.03233'
source_url: https://arxiv.org/abs/2506.03233
tags:
- identity
- systems
- system
- kinds
- artifacts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a metaphysics of artificial intelligence
  systems grounded in the concept of trustworthiness, proposing identity criteria
  for AI artifacts. The core method involves defining AI system kinds via techno-functions
  (technical capabilities) and trustworthiness profiles (collections of capabilities
  maintained over time), and formulating identity criteria for synchronic and diachronic
  identity.
---

# A Trustworthiness-based Metaphysics of Artificial Intelligence Systems

## Quick Facts
- arXiv ID: 2506.03233
- Source URL: https://arxiv.org/abs/2506.03233
- Authors: Andrea Ferrario
- Reference count: 40
- Primary result: AI systems can be treated as real kinds with well-posed identity and persistence conditions based on trustworthiness

## Executive Summary
This paper proposes a metaphysics of artificial intelligence systems grounded in trustworthiness, challenging the traditional view that artifacts lack proper identity criteria. The framework defines AI system kinds through techno-functions (technical capabilities) and trustworthiness profiles (collections of capabilities maintained over time), establishing formal identity criteria for both synchronic and diachronic identity. The approach demonstrates that AI systems can be treated as real kinds rather than mere artifacts, providing a metaphysical foundation for epistemological, ethical, and legal discussions about AI systems.

## Method Summary
The paper employs formal metaphysical analysis to establish identity criteria for AI systems, defining AI kinds through techno-functions and trustworthiness profiles. The method involves creating formal criteria for synchronic identity (same time) and diachronic identity (across time), showing that two AI systems are identical if they share the same techno-function, trustworthiness profile, and equal trustworthiness levels. The approach treats AI systems as real kinds rather than traditional artifacts, enabling coherent discussion of their identity and persistence conditions.

## Key Results
- AI systems can be treated as real kinds with well-posed identity and persistence conditions
- Formal identity criteria established: same techno-function, trustworthiness profile, and equal trustworthiness levels
- Trustworthiness profiles provide a unified basis for metaphysical, epistemological, ethical, and legal discussions about AI systems

## Why This Works (Mechanism)
The framework works by grounding AI system identity in trustworthiness rather than traditional artifact characteristics. By defining AI kinds through techno-functions and trustworthiness profiles, the approach creates measurable, comparable criteria that can be applied across different AI implementations. The formal identity criteria provide clear conditions for determining when AI systems are identical or when they persist through changes, addressing fundamental metaphysical questions about AI system identity.

## Foundational Learning
- **Techno-functions**: Technical capabilities that define what an AI system does. Why needed: Provides the functional basis for AI system kinds. Quick check: Can identify the core capabilities of any given AI system.
- **Trustworthiness profiles**: Collections of capabilities maintained over time. Why needed: Captures the dynamic nature of AI systems while preserving identity. Quick check: Can track how capabilities evolve while maintaining system identity.
- **Synchronic identity criteria**: Conditions for identity at the same time. Why needed: Establishes when two AI systems are considered the same entity. Quick check: Can determine if two systems are identical at a given moment.
- **Diachronic identity criteria**: Conditions for identity across time. Why needed: Determines when an AI system persists through changes. Quick check: Can track system identity through transformations and updates.
- **Real kinds vs. artifacts**: Philosophical distinction about what constitutes a proper kind. Why needed: Challenges traditional views about artifact identity. Quick check: Can classify AI systems as real kinds rather than mere artifacts.
- **Trustworthiness quantification**: Measuring and comparing trustworthiness levels. Why needed: Enables practical application of identity criteria. Quick check: Can reliably measure trustworthiness across different AI systems.

## Architecture Onboarding

**Component Map**: AI System -> Techno-function + Trustworthiness Profile -> Identity Criteria (Synchronic/Diachronic)

**Critical Path**: Define AI kind → Establish techno-function → Create trustworthiness profile → Apply identity criteria → Validate persistence

**Design Tradeoffs**: The framework prioritizes metaphysical rigor over practical measurability, potentially limiting immediate real-world applicability but providing a solid theoretical foundation.

**Failure Signatures**: 
- Inability to reliably quantify trustworthiness levels
- Inconsistency between techno-functions and actual capabilities
- Loss of identity during radical system transformations
- Difficulty comparing trustworthiness across different architectures

**First Experiments**:
1. Apply identity criteria to a case study of an AI system undergoing iterative updates
2. Test trustworthiness profile consistency across different AI architectures
3. Validate the framework's utility for ethical decision-making in AI deployment scenarios

## Open Questions the Paper Calls Out
None explicitly identified in the provided information.

## Limitations
- Operationalization of trustworthiness profiles remains abstract and may vary across implementations
- Assumes meaningful comparison and quantification of trustworthiness levels across systems
- Does not fully address edge cases of radical transformations or system integration
- Practical applicability of metaphysical distinctions requires real-world validation

## Confidence
- Core metaphysical framework: Medium
- Practical utility for ethical/legal discussions: Medium
- Feasibility of trustworthiness quantification: Low

## Next Checks
1. Empirical validation through case studies examining how the identity criteria apply to real AI systems undergoing various transformations
2. Cross-disciplinary testing with ethicists and legal scholars to assess the practical utility of the framework for addressing real-world AI governance challenges
3. Technical assessment of the feasibility of reliably measuring and comparing trustworthiness profiles across diverse AI system architectures