---
ver: rpa2
title: 'Affective-ROPTester: Capability and Bias Analysis of LLMs in Predicting Retinopathy
  of Prematurity'
arxiv_id: '2507.05816'
source_url: https://arxiv.org/abs/2507.05816
tags:
- risk
- llms
- scheme
- affective
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study introduces Affective-ROPTester, a framework for evaluating
  large language models (LLMs) in predicting retinopathy of prematurity (ROP) risk
  using only admission notes from preterm infants. It constructs the CROP dataset
  of 993 Chinese records labeled by risk level (low, medium, high).
---

# Affective-ROPTester: Capability and Bias Analysis of LLMs in Predicting Retinopathy of Prematurity

## Quick Facts
- arXiv ID: 2507.05816
- Source URL: https://arxiv.org/abs/2507.05816
- Authors: Shuai Zhao; Yulin Zhang; Luwei Xiao; Xinyi Wu; Yanhao Jia; Zhongliang Guo; Xiaobao Wu; Cong-Duy Nguyen; Guoming Zhang; Anh Tuan Luu
- Reference count: 40
- Primary result: Affective framing reduces LLM bias toward overestimating ROP risk, especially in medium- and high-risk cases

## Executive Summary
Affective-ROPTester introduces a framework for evaluating large language models (LLMs) in predicting retinopathy of prematurity (ROP) risk using only admission notes from preterm infants. The study constructs the CROP dataset of 993 Chinese records labeled by risk level (low, medium, high) and employs three prompting strategies—Instruction, Chain-of-Thought (CoT), and In-Context Learning (ICL)—with affective framing (negative, neutral, positive) integrated into the Instruction scheme. Results demonstrate that LLMs perform poorly using intrinsic knowledge alone but improve significantly with structured external inputs. Notably, models exhibit bias toward overestimating medium- and high-risk cases, which is mitigated by positive emotional framing and the introduction of known risk factors.

## Method Summary
The study constructs the CROP dataset from admission notes of 993 preterm infants at Henan Provincial People's Hospital, labeled by ROP risk level (low, medium, high). It evaluates three prompting strategies—Instruction, Chain-of-Thought (CoT), and In-Context Learning (ICL)—with affective framing (negative, neutral, positive) integrated into the Instruction scheme. The framework tests LLM performance using intrinsic knowledge alone versus structured external inputs (known risk factors). Performance is measured through classification accuracy, precision, recall, and F1 scores, with bias analysis focusing on overestimation of medium- and high-risk cases.

## Key Results
- LLMs perform poorly using intrinsic knowledge alone but improve significantly with structured external inputs
- Models exhibit bias toward overestimating medium- and high-risk cases
- Positive emotional framing and known risk factors mitigate bias in risk prediction

## Why This Works (Mechanism)
The study demonstrates that affective framing influences LLM reasoning pathways, reducing bias in clinical risk prediction. Positive emotional framing and structured external inputs (known risk factors) guide models toward more balanced risk assessments, particularly for medium- and high-risk cases. This suggests that prompt engineering can modulate model behavior beyond pure factual recall, introducing a dimension of affect-sensitive reasoning that improves diagnostic reliability.

## Foundational Learning
- **Prompt engineering for bias mitigation**: Why needed - to reduce systematic errors in clinical predictions; Quick check - compare bias metrics across different affective frames
- **Affective framing in clinical NLP**: Why needed - to address emotional bias in medical decision support; Quick check - measure prediction shifts with emotional valence changes
- **Multi-strategy prompting evaluation**: Why needed - to identify optimal prompt structures for specific tasks; Quick check - benchmark accuracy across Instruction, CoT, and ICL approaches

## Architecture Onboarding
- **Component map**: CROP dataset -> Affective-ROPTester framework -> Three prompting strategies (Instruction, CoT, ICL) -> Model evaluation
- **Critical path**: Data labeling → Prompt engineering → Model inference → Bias analysis → Performance validation
- **Design tradeoffs**: Single-source dataset limits generalizability vs. controlled experimental conditions; manual affective framing vs. automated prompt generation
- **Failure signatures**: Overestimation of medium- and high-risk cases when using intrinsic knowledge; poor performance without structured external inputs
- **First experiments**: 1) Replicate bias analysis with different emotional framing intensities; 2) Test model performance on external ROP datasets; 3) Conduct ablation study removing affective elements from prompts

## Open Questions the Paper Calls Out
None

## Limitations
- Single-source dataset limits generalizability to other clinical environments
- Manual affective framing raises questions about scalability across diverse clinical conditions
- Omitted sensitivity analysis for demographic variables and comorbidities

## Confidence
- **High Confidence**: LLM performance gains with structured external inputs over intrinsic knowledge alone
- **Medium Confidence**: Affective framing reduces medium- and high-risk overestimation
- **Low Confidence**: CROP dataset findings apply to non-Chinese clinical settings or different ROP diagnostic protocols

## Next Checks
1. Test Affective-ROPTester models on multi-site datasets from diverse geographic regions to assess generalizability
2. Conduct a study linking model predictions to actual clinical outcomes to validate clinical utility
3. Perform ablation studies varying emotional framing intensities to determine optimal affective prompt structure