---
ver: rpa2
title: 'Two Heads are Better than One: Distilling Large Language Model Features Into
  Small Models with Feature Decomposition and Mixture'
arxiv_id: '2511.07110'
source_url: https://arxiv.org/abs/2511.07110
tags:
- feature
- market
- features
- different
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of slow inference speeds when
  applying large language models (LLMs) to market-making tasks in financial trading.
  The authors propose Cooperative Market Making (CMM), a novel framework that decomposes
  complex LLM features into simpler components across three orthogonal dimensions:
  layer, task, and data type/market regime.'
---

# Two Heads are Better than One: Distilling Large Language Model Features Into Small Models with Feature Decomposition and Mixture

## Quick Facts
- arXiv ID: 2511.07110
- Source URL: https://arxiv.org/abs/2511.07110
- Reference count: 18
- Primary result: Distills LLM features into lightweight models with 6.3× lower latency while improving profitability metrics in market making

## Executive Summary
This paper proposes Cooperative Market Making (CMM), a framework that decomposes complex LLM features into simpler components across three orthogonal dimensions (layer, task, and data type/market regime) to enable efficient market making. Each specialized component is learned by dedicated lightweight models, and CMM introduces Hájek-MoE to integrate these models through projection-based confidence scores. Evaluated on four real-world market datasets, CMM demonstrates superior performance compared to existing distillation methods and RL-based market-making strategies, achieving 6.3× lower latency while maintaining or improving profitability.

## Method Summary
The CMM framework addresses slow LLM inference in market making by decomposing LLM features across three orthogonal dimensions: layer, task, and data type/market regime. The Orthogonal Feature Decomposition Distillation (OFDD) stage uses a Normalized Fluorescent Probe to identify which LLM modules most influence each output, guiding targeted distillation to specialized lightweight models. Each student model learns a decoupled sub-problem (shallow layers → mid-price, middle layers → spread, deep layers → volume). To integrate these models, Hájek-MoE uses a kernel function-generated common feature space to quantify each model's contribution through projection-based confidence scores, ensuring input-adaptive expert weighting based on geometric alignment with consensus.

## Key Results
- Achieves 6.3× lower latency (0.3s vs 1.9s) compared to LLM baseline
- Maintains profitability with EPnL of 31.39×10³ vs 30.47×10³ for LLM baseline
- Demonstrates superior risk-adjusted performance with PnLMAP of 1.67 vs 1.52 for LLM baseline
- Shows robustness under extreme market conditions with EPnL of 10.50±2.10 vs 6.50±2.45 for LLM baseline

## Why This Works (Mechanism)

### Mechanism 1: Orthogonal Feature Decomposition
- Claim: Decomposing LLM features along orthogonal dimensions enables lightweight models to collectively approximate complex teacher representations that no single small model could capture alone.
- Mechanism: The Normalized Fluorescent Probe uses noise perturbation to identify which LLM modules most influence each output, constructing a causal attribution map revealing functional specialization. This guides targeted distillation: shallow-layer features → mid-price predictors; middle-layer features → spread predictors; deep-layer features → volume predictors.
- Core assumption: LLM features are meaningfully decomposable along these dimensions, and resulting clusters are sufficiently independent for specialized learners.
- Break condition: If probe attribution maps show high cross-module overlap or decomposed features remain tightly coupled, the benefit of specialization disappears and ensemble overhead dominates.

### Mechanism 2: Hájek-MoE Confidence Scoring
- Claim: Hájek projection-based confidence scoring provides input-adaptive expert weighting by measuring alignment between each expert's feature vector and the consensus direction in a shared kernel space.
- Mechanism: A kernel function (shallow MLP) maps each expert's output features and predictions to a 2D space. The consensus vector serves as reference axis, and each expert's confidence quantifies projection length—experts aligned with consensus receive higher weights.
- Core assumption: The kernel function can be trained to produce a meaningful shared representation where consensus alignment correlates with expert reliability for the current input.
- Break condition: If the kernel function fails to generalize or consensus is dominated by systematically wrong experts during regime shifts, confidence scores become misleading and aggregation degrades.

### Mechanism 3: Data-Type Decomposition for Market Adaptation
- Claim: Data-type (volatility regime) decomposition enables market-adaptive specialization, reducing risk during turbulence by prioritizing conservative experts when appropriate.
- Mechanism: Historical 5-day volatility stratifies data into low/medium/high bands. Separate models train on each regime, implicitly learning conservative (low-vol), neutral (mid-vol), and aggressive (high-vol) strategies.
- Core assumption: Volatility regimes are predictable proxies for optimal strategy parameters, and regime-specific training produces meaningfully distinct behaviors.
- Break condition: If volatility regime boundaries are misspecified or market dynamics shift such that historical volatility no longer predicts optimal strategy, specialist mismatch causes systematic errors.

## Foundational Learning

- **Knowledge Distillation**: CMM is fundamentally a cross-architecture distillation method (LLM → lightweight MLP/CNN-style models), requiring understanding of how soft labels, feature matching, and logit distillation transfer representational knowledge. *Quick check: Can you explain why matching intermediate features might preserve more teacher knowledge than just output logits?*

- **Mixture of Experts (MoE)**: Hájek-MoE replaces learned router gates with projection-based confidence; understanding standard MoE (Shazeer et al., Switch Transformers) clarifies what design choice is being modified and why. *Quick check: In standard MoE, how does the gating network decide which experts to activate? How does this differ from the Hájek approach?*

- **Market Making Fundamentals**: The task involves predicting mid-price, spread, and volume to construct orders; understanding inventory risk (MAP metric) and spread capture (RPT metric) is essential to interpret evaluation results. *Quick check: Why does a market maker care about Mean Absolute Position (MAP) as a risk metric, not just total PnL?*

## Architecture Onboarding

- **Component map**:
```
Input (Order Book)
    ↓
[Volatility Regime Classifier] → determines data type bucket
    ↓
[Teacher LLM] → frozen, provides distillation targets
    ↓
[OFDD Stage]
├── Layer-Task Aligned Experts (shallow→mid-price, mid→spread, deep→volume)
├── Task-Specialized Heads (3 output dimensions)
└── Regime-Specific Variants (low/med/high volatility)
    ↓
[Hájek-MoE Stage]
├── Kernel Function φ (2-layer MLP) → maps to shared space
├── Consensus Vector V_avg → reference axis
└── Confidence Scores C_i → scalar projections
    ↓
[Weighted Aggregation] → final predictions (mid-price, spread, volume)
    ↓
[Order Construction] → trapezoidal algorithm
```

- **Critical path**:
  1. Run Normalized Fluorescent Probe on teacher LLM to identify layer-task attribution map
  2. Train regime-specific, layer-task aligned student experts with feature+logit distillation loss
  3. Train Hájek kernel function φ on validation data to produce discriminative consensus space
  4. End-to-end inference: classify regime → activate relevant experts → compute confidence-weighted aggregation

- **Design tradeoffs**:
  - More decomposition dimensions → simpler per-expert learning task, but more models to train/coordinate and higher inference overhead
  - 2D kernel projection space → computationally cheap, but may lose discriminative power vs. higher-dimensional alternatives
  - Frozen teacher → stable distillation target, but cannot adapt to domain shift without re-probing

- **Failure signatures**:
  - Experts produce near-identical outputs → check probe attribution clarity and training data stratification
  - Confidence scores collapse to uniform weights → kernel φ may not be learning meaningful representations
  - Strong train performance, weak test performance → overfitting to volatility regime distribution
  - Inference latency not meeting subsecond target → profile expert count and kernel computation

- **First 3 experiments**:
  1. **Probe validation**: Apply Normalized Fluorescent Probe to teacher LLM on held-out market data; visualize attribution map to confirm layer-task specialization holds outside training period
  2. **Ablation sweep**: Train CMM variants with each decomposition dimension removed to quantify individual contributions
  3. **Regime shift stress test**: Evaluate trained model on synthetic flash-crash data and analyze which experts receive highest confidence

## Open Questions the Paper Calls Out
None explicitly called out in the paper.

## Limitations
- The orthogonal decomposition assumption lacks direct validation—probe attribution maps proving layer-task independence across market data are not shown
- Student model architectures remain underspecified (layer count, hidden dimensions), making exact reproduction difficult
- The kernel function's ability to generalize across regime shifts is untested beyond the provided robustness table

## Confidence
- **High confidence**: Market-making evaluation setup (EPnL, MAP metrics, real-world data provenance), inference latency measurements, and general distillation methodology
- **Medium confidence**: OFDD decomposition framework is theoretically sound but depends critically on unverified probe results; Hájek-MoE's confidence scoring mechanism is novel but lacks ablation showing its superiority over standard gating
- **Low confidence**: Claims about Hájek-MoE's superiority rely heavily on aggregate results without showing individual contribution breakdowns or probing failures during regime shifts

## Next Checks
1. **Probe attribution validation**: Apply Normalized Fluorescent Probe to teacher LLM on held-out market data and visualize layer-task attribution maps to verify functional specialization claims
2. **Ablation study**: Train CMM variants removing each decomposition dimension (layer-only, task-only, data-only) to quantify individual contributions against Table 2 results
3. **Regime shift analysis**: During flash-crash stress testing, analyze which experts receive highest confidence scores and verify conservative experts activate appropriately