---
ver: rpa2
title: 'Predicting Case Suffixes With Activity Start and End Times: A Sweep-Line Based
  Approach'
arxiv_id: '2509.14536'
source_url: https://arxiv.org/abs/2509.14536
tags:
- activity
- time
- start
- case
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a multi-model approach to predict the complete
  suffix of ongoing business process cases, including activity sequences with both
  start and end timestamps. It addresses the limitation of single-model methods that
  predict only one timestamp, which is insufficient for capacity planning.
---

# Predicting Case Suffixes With Activity Start and End Times: A Sweep-Line Based Approach

## Quick Facts
- **arXiv ID:** 2509.14536
- **Source URL:** https://arxiv.org/abs/2509.14536
- **Reference count:** 27
- **Key outcome:** Multi-model approach predicts complete case suffixes (activities, inter-start times, processing times) with 6.89% reduction in control-flow error, 24.44% reduction in processing time MAE, and 18.35% reduction in inter-start time MAE versus single-model baselines.

## Executive Summary
This paper introduces a multi-model approach for predicting complete suffixes of ongoing business process cases, including both activity sequences and their start/end timestamps. Unlike prior work that predicts only end timestamps, this method provides a complete temporal picture essential for capacity planning and resource allocation. The approach uses three specialized BiLSTM models to predict the next activity, inter-start time, and processing time in lockstep via a sweep-line algorithm, enabling dynamic capture of workload across concurrent cases.

## Method Summary
The method decomposes suffix prediction into three specialized BiLSTM models: α predicts the next activity, β predicts the inter-start time (waiting time between activities), and γ predicts the processing time (duration of the activity). These models are trained independently on n-gram encoded prefixes and features including intra-case (activity, inter-start, processing time) and inter-case (WIP, utilization, arrival rate) attributes. During inference, a sweep-line algorithm advances chronologically across all cases, predicting their suffixes in lockstep to maintain temporal consistency across concurrent processes.

## Key Results
- Multi-model approach achieves 6.89% reduction in Damerau-Levenshtein distance for control-flow prediction versus single-model baselines
- Processing time MAE improves by 24.44% compared to baselines
- Inter-start time MAE improves by 18.35% compared to baselines
- Best performance observed in logs with fewer distinct activities and higher variability

## Why This Works (Mechanism)

### Mechanism 1: Task Decomposition
The multi-model approach isolates learning of categorical control flow from continuous temporal dynamics by using separate BiLSTMs for activity prediction (α) and time prediction (β, γ). This reduces the loss function's complexity compared to joint single-model approaches, as temporal models can condition on the predicted activity and inter-start time. The core assumption is that error propagation from activity predictor to time predictors is lower than the approximation error introduced by learning both tasks jointly.

### Mechanism 2: Inter-Case Feature Integration
Dynamic inter-case features (Work in Progress, Utilization) improve waiting time prediction by capturing resource contention. The mechanism relies on queuing theory principles where waiting time correlates with system load. By computing WIP and utilization at the evaluation time across all active cases, the model encodes system congestion, allowing the β model to adjust inter-start times based on current workload rather than historical averages. This assumes processes are resource-constrained enough that higher concurrency directly increases delays.

### Mechanism 3: Sweep-Line Temporal Causality
The sweep-line approach maintains temporal causality during multi-case inference by advancing a global time pointer to the next earliest predicted start time across all cases. This prevents "time travel" in predictions and ensures that when predicting the next step for one case, the algorithm accounts for the predicted start times of concurrent cases, keeping the global workload snapshot consistent. The assumption is that future states of concurrent cases influence each other via shared resources.

## Foundational Learning

- **Concept: BiLSTM (Bidirectional Long Short-Term Memory)**
  - **Why needed here:** BiLSTMs process sequences both forwards and backwards, capturing context from both past activities and "future" context (during training) to predict the immediate next step
  - **Quick check question:** Why is a BiLSTM preferred over a standard LSTM for training on complete trace prefixes, even though inference only predicts the "next" step?

- **Concept: N-gram Sequence Construction**
  - **Why needed here:** Converts variable-length traces into fixed-size inputs using n-grams, allowing the LSTM to receive a consistent window of history rather than the entire potentially infinite history
  - **Quick check question:** If an ongoing case has only 2 activities but the model is trained on n-grams of size 5, how must the input be padded?

- **Concept: Activity Instance Log vs. Event Log**
  - **Why needed here:** Activity instance logs with explicit Start and End timestamps are required to separate processing time (End - Start) from waiting time, unlike standard event logs with only one timestamp per event
  - **Quick check question:** In a standard event log with only one timestamp per event, which component of time (waiting vs. processing) is impossible to calculate?

## Architecture Onboarding

- **Component map:** Log → Feature Extractor (Alg 1) → N-gram Encoder → Three parallel BiLSTM Trainers (Models α, β, γ) → Online Engine (State Manager, Inter-Case Calculator, Inference Loop)
- **Critical path:** The Inter-Case Feature Extraction (Algorithm 1) is the computational bottleneck, requiring recalculation of WIP/utilization across all cases at each prediction step
- **Design tradeoffs:** MM vs. SM tradeoff is increased training complexity and inference latency (3 models vs 1) for improved flexibility and accuracy. Embedding strategy works well for logs with fewer activities (<20) but performance drops for logs with many distinct activities
- **Failure signatures:** Temporal Collapse (sweep line gets stuck with negative/near-zero inter-start times), Control Loop (activity predictor enters repetitive cycle), Resource Blindness (features misconfigured causing constant inter-start times regardless of system load)
- **First 3 experiments:** 1) Baseline Reproduction: Train SM baseline on BPI12W and verify MAE/DL metrics, 2) Feature Ablation: Run MM model with inter-case features disabled and verify inter-start time MAE increases significantly, 3) Sweep-Line Stress Test: Generate synthetic log with massive concurrent case spike and verify predicted inter-start times increase with simulated congestion

## Open Questions the Paper Calls Out

1. Can hierarchical classification or adaptive embeddings improve prediction accuracy in event logs with more than 20 distinct activities, where current 3-gram embeddings show limited effectiveness?
2. Does mixing predicted activities with ground-truth activities during training (reducing teacher forcing) improve the robustness of the sweep-line approach?
3. Do Transformer-based or encoder-decoder architectures outperform the current BiLSTM implementation within this specific multi-model, sweep-line framework?

## Limitations
- Performance evaluation relies heavily on synthetic logs that may not capture real-world process dynamics
- BiLSTM architectural details (number of layers, dropout rates, embedding dimensions) are underspecified
- "Daemon action" sampling method referenced from [1] is mentioned but not detailed in the paper

## Confidence
- **High Confidence:** Multi-model approach outperforming single-model baselines is well-supported by quantitative results across multiple metrics and datasets
- **Medium Confidence:** Superiority of sweep-line approach is demonstrated but comparison primarily shows it outperforms isolated prediction rather than directly comparing to alternative joint prediction methods
- **Medium Confidence:** Claim that inter-case features improve inter-start time prediction is supported by results, though improvement is modest

## Next Checks
1. **Data Realism Check:** Compare performance on synthetic logs versus real-world logs to quantify realism gap and identify which components are most sensitive to data characteristics
2. **Architectural Sensitivity:** Systematically vary BiLSTM hyperparameters (layers, dropout, embedding size) to establish robustness and identify which components most influence improvements
3. **Baseline Completeness:** Implement and test additional baseline approaches, particularly joint prediction models that learn activity and time distributions simultaneously, to better establish the relative advantage of multi-model decomposition