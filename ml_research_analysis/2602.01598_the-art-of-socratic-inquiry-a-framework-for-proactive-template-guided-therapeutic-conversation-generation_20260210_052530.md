---
ver: rpa2
title: 'The Art of Socratic Inquiry: A Framework for Proactive Template-Guided Therapeutic
  Conversation Generation'
arxiv_id: '2602.01598'
source_url: https://arxiv.org/abs/2602.01598
tags:
- llms
- arxiv
- socratic
- strategy
- therapeutic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study introduces the Socratic Inquiry Framework (SIF) to address
  the limitation of current psychological large language models, which are predominantly
  reactive and fail to engage in structured, cognition-guiding inquiries essential
  for cognitive behavioral therapy (CBT). SIF decouples the decision of when to ask
  therapeutic questions (via Strategy Anchoring) from what type of Socratic question
  to pose (via Template Retrieval), enabling context-aware, theory-grounded questioning
  without end-to-end retraining.
---

# The Art of Socratic Inquiry: A Framework for Proactive Template-Guided Therapeutic Conversation Generation

## Quick Facts
- **arXiv ID:** 2602.01598
- **Source URL:** https://arxiv.org/abs/2602.01598
- **Reference count:** 29
- **Primary result:** SIF framework enables LLMs to generate proactive, CBT-aligned Socratic questions, shifting dialogue from reactive comfort to structured cognitive exploration.

## Executive Summary
This paper introduces the Socratic Inquiry Framework (SIF), a novel approach to enable large language models to engage in proactive, theory-grounded therapeutic questioning aligned with cognitive behavioral therapy (CBT) principles. Current psychological LLMs are predominantly reactive, providing comfort rather than guiding users through structured cognitive exploration. SIF addresses this by decoupling the decision of when to ask therapeutic questions (via Strategy Anchoring) from what type of Socratic question to pose (via Template Retrieval), enabling context-aware questioning without requiring end-to-end retraining. The framework is trained on a high-quality dataset, Socratic-QA, and demonstrates significant improvements in proactive questioning frequency, conversational depth, and therapeutic alignment.

## Method Summary
SIF operates through a two-stage pipeline: Strategy Anchoring (SA) and Template Retrieval (TR), followed by a Conversation Generator (CG). SA is a 10-class classifier trained on Psy-Insight that determines the appropriate therapeutic strategy (e.g., emotion recognition, cognitive restructuring) based on conversation context. TR is a 6-class classifier trained on Socratic-QA that selects the most suitable Socratic template (e.g., clarification, perspective exploration) given the strategy and conversation history. The CG, a fine-tuned Qwen2.5-7B-Instruct model, generates the final response conditioned on the predicted strategy, template, and context. Training involves constructing Socratic-QA from EmoLLM through template-based generation, quality filtering using a 7-dimensional rubric, and contrastive preference filtering. Inference constructs a Sequence(ŝ, t̂, C, xi) to guide LLM generation, enabling proactive questioning without end-to-end retraining.

## Key Results
- SIF significantly increases proactive questioning frequency, shifting dialogue from reactive comfort to structured cognitive exploration.
- The framework improves conversational depth and therapeutic alignment across both open-domain and domain-specific datasets.
- Automatic metrics (PQA, Distinct-n) show substantial gains, while human evaluations confirm enhanced strategy comprehensiveness and professionalism.

## Why This Works (Mechanism)
SIF works by explicitly separating the "when" (strategy selection) from the "what" (template selection) of therapeutic questioning. This decoupling allows the model to first identify the appropriate therapeutic approach using Strategy Anchoring, then select the most suitable Socratic template via Template Retrieval, before generating a context-aware response. By training on high-quality Socratic-QA data with explicit supervision for proactive reasoning, the framework overcomes the limitations of reactive LLMs that lack structured cognitive guidance. The approach enables LLMs to act as active cognitive guides rather than passive responders, aligning with CBT principles of guided discovery and cognitive restructuring.

## Foundational Learning
- **Socratic Questioning in CBT:** Structured inquiry technique to guide self-discovery; needed to shift from comfort to cognitive exploration; quick check: verify question types align with CBT objectives.
- **Strategy Anchoring:** 10-class classification to determine therapeutic approach; needed to identify when to initiate Socratic questioning; quick check: ensure strategy labels are balanced and clinically valid.
- **Template Retrieval:** 6-class classification to select Socratic question format; needed to provide structured question templates; quick check: validate template diversity and therapeutic appropriateness.
- **Proactive vs Reactive Dialogue:** Proactive involves guided exploration; reactive involves responding to user prompts; needed to enable cognitive restructuring; quick check: measure shift in question initiation patterns.
- **LoRA Fine-tuning:** Parameter-efficient adaptation of LLMs; needed to avoid full retraining while maintaining performance; quick check: compare full fine-tuning vs LoRA performance.

## Architecture Onboarding

**Component map:** Psy-Insight/EmoLLM -> Strategy Anchoring (SA) -> Template Retrieval (TR) -> Conversation Generator (CG) -> Socratic-QA

**Critical path:** SA predicts strategy ŝ from conversation context C → TR predicts template t̂ given ŝ and C → CG generates response conditioned on ŝ, t̂, C, and user utterance xi

**Design tradeoffs:** Decoupling SA/TR from CG enables modularity and avoids end-to-end retraining, but introduces potential misalignment between strategy/template signals and CG's internal priors (observed negative transfer with CBT-LLM).

**Failure signatures:** Low TR accuracy (≈48.5%) indicates template selection bottleneck; misalignment between LPP signals and model's internal CBT priors can cause negative gains; template generation may lack contextual relevance.

**Three first experiments:**
1. Train and evaluate SA classifier on Psy-Insight to verify strategy prediction accuracy.
2. Test TR classifier on Socratic-QA to identify template selection accuracy and bottlenecks.
3. Fine-tune CG on Socratic-QA and evaluate response quality with and without LPP conditioning.

## Open Questions the Paper Calls Out
None

## Limitations
- Socratic-QA dataset construction pipeline lacks full specification of the 7-dimensional scoring rubric and contrastive preference filtering criteria.
- Exact configuration of instruct-tuned encoder architecture for LPP remains unspecified, creating potential variability in classifier performance.
- Framework focus on Chinese-language datasets (Psy-Insight, EmoLLM) limits generalizability to other languages and cultural contexts.

## Confidence
- **High confidence:** Decoupling architecture of Strategy Anchoring and Template Retrieval is technically sound and well-implemented; automatic metric improvements (PQA, Distinct-n) are reliably demonstrated.
- **Medium confidence:** Human evaluation results showing improved therapeutic alignment and conversational depth are convincing but limited to 6 annotators; claim about shifting from reactive to proactive dialogue is supported but could benefit from longitudinal analysis.
- **Low confidence:** Assertion that SIF makes LLMs "more effective as active cognitive guides" extends beyond demonstrated capabilities into therapeutic efficacy, which was not clinically validated.

## Next Checks
1. Replicate the Socratic-QA dataset construction pipeline with the full 7-dimensional scoring rubric and contrastive preference filtering to verify dataset quality consistency.
2. Test SIF performance across multiple LLM base models (not just Qwen2.5-7B-Instruct) to assess framework generalizability and identify potential negative transfer scenarios.
3. Conduct a pilot study with licensed therapists to evaluate whether SIF-generated questions maintain therapeutic value across diverse clinical scenarios and patient populations.