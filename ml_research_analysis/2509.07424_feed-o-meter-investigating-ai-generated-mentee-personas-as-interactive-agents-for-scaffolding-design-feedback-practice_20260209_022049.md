---
ver: rpa2
title: 'Feed-O-Meter: Investigating AI-Generated Mentee Personas as Interactive Agents
  for Scaffolding Design Feedback Practice'
arxiv_id: '2509.07424'
source_url: https://arxiv.org/abs/2509.07424
tags:
- feedback
- design
- mentee
- urlhttps
- participants
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Feed-O-Meter, a system that enables design
  students to practice giving feedback by role-playing with an AI mentee. The system
  uses large language models to simulate a novice design student and includes features
  like a feedback reflection interface and counter-questions to help users reflect
  on and improve their feedback.
---

# Feed-O-Meter: Investigating AI-Generated Mentee Personas as Interactive Agents for Scaffolding Design Feedback Practice

## Quick Facts
- arXiv ID: 2509.07424
- Source URL: https://arxiv.org/abs/2509.07424
- Reference count: 40
- Primary result: AI-driven feedback practice system increases engagement and improves feedback quality in design education

## Executive Summary
Feed-O-Meter is a system that enables design students to practice giving feedback by role-playing with an AI mentee. The system uses large language models to simulate a novice design student and includes features like a feedback reflection interface and counter-questions to help users reflect on and improve their feedback. A user study with 24 participants showed that Feed-O-Meter increased engagement and motivation, helped users adjust feedback for clarity, and improved the quality of their feedback. The findings suggest that such AI-driven systems can effectively support the development of feedback skills in design education.

## Method Summary
Feed-O-Meter employs a React frontend with Flask backend and MySQL database, orchestrating GPT-4o API calls through five core modules: categorizer, evaluator, knowledge extractor, response generator, and idea updater. Users role-play as mentors giving feedback to an AI mentee (Alex) with constrained knowledge that advances only through user-provided feedback. The system visualizes feedback quality metrics and mentee reactions in real-time, triggering counter-questions when feedback becomes repetitive. The study involved 24 Korean design students in 20-minute sessions across three design topics.

## Key Results
- Role-switching increased engagement and helped users adjust feedback for clarity and comprehension
- Real-time feedback visualization promoted self-reflection and iterative adjustment of feedback strategies
- Counter-questions prompted users to explore feedback dimensions they had not initially considered
- 22/24 participants found the visualized information helped them reflect on feedback patterns
- Users perceived the AI mentee as believable enough to maintain immersion during role-play

## Why This Works (Mechanism)

### Mechanism 1: Role-Switching with Constrained Knowledge State
- **Claim:** Placing users in the mentor role while constraining the AI mentee's knowledge to advance only through user-provided feedback increases engagement and promotes reflective practice.
- **Mechanism:** Role reversal forces users to articulate design concepts clearly and consider the mentee's perspective. The constrained knowledge state prevents the AI from solving problems independently, requiring users to provide substantive guidance rather than relying on AI-generated solutions.
- **Core assumption:** Users will authentically adopt the mentor role and perceive the novice AI persona as believable enough to maintain immersion.
- **Evidence anchors:**
  - [abstract] "role-switching and helped them adjust feedback to be more comprehensible for an AI mentee"
  - [section 3.1.1] "This role-switching encourages users to adopt a new perspective and become more engaged in the task while also providing a learning experience similar to learning by teaching"
  - [corpus] Novobo demonstrates similar patterns where teachers develop instructional skills by teaching a mentee AI-agent together.
- **Break condition:** If the AI's responses become too sophisticated or knowledge constraints are too loose, users may disengage or over-rely on the AI, diminishing skill development.

### Mechanism 2: Real-Time Feedback Visualization with Consequence Mapping
- **Claim:** Visualizing feedback quality metrics and mentee reactions in real-time promotes self-reflection and iterative adjustment of feedback strategies.
- **Mechanism:** The Feedback Reflection Interface (FRI) displays feedback categories, quality scores, mentee facial expressions, and "inner thoughts" immediately after each input. This makes the consequences of feedback visible and tangible, creating a feedback loop that encourages adjustment toward clearer, more constructive feedback.
- **Core assumption:** Users will attend to and act on visual feedback signals rather than ignoring or gaming them.
- **Evidence anchors:**
  - [abstract] "includes features like a feedback reflection interface and counter-questions to help users reflect on and improve their feedback"
  - [section 5.2.2] "22/24 participants found that the visualized information on the FRI helped them reflect on their feedback patterns and how Alex perceived them"
  - [corpus] FeedQUAC shows relevance of real-time AI commentary for design feedback; SRLAgent demonstrates gamification and LLM assistance for self-regulated learning.
- **Break condition:** If visualizations become overwhelming, users may ignore them; if metrics are gamed without improving actual feedback quality, learning is superficial.

### Mechanism 3: Counter-Questions to Surface Feedback Blind Spots
- **Claim:** AI-generated counter-questions prompt users to explore feedback dimensions they had not initially considered.
- **Mechanism:** When feedback is repetitive, shallow, or narrow, the system generates targeted questions to encourage deeper or more diverse responses. This scaffolds exploration of new feedback angles and prevents stagnation.
- **Core assumption:** Counter-questions will be sufficiently relevant and well-timed to feel helpful rather than disruptive.
- **Evidence anchors:**
  - [abstract] "counter-questions to help users reflect on and improve their feedback"
  - [section 3.4.3] "counter-questions are triggered when users give repetitive feedback... prompting them to vary their responses"
  - [corpus] Limited direct corpus evidence for this specific mechanism; prior work on questioning skills (Lim et al., questioning for design problem identification) is cited but not directly validated.
- **Break condition:** If counter-questions are poorly timed, irrelevant, or triggered too frequently, they disrupt the conversational flow and reduce engagement.

## Foundational Learning

- **Concept: Feedback Typology (Question vs. Statement, Divergent vs. Convergent)**
  - **Why needed here:** The FRI visualizes feedback types (e.g., low-level questions, recommendations, evaluations) and divergence/convergence ratios. Without understanding these distinctions, users cannot interpret or act on the visualizations meaningfully.
  - **Quick check question:** Can you explain the difference between a "deep reasoning question" and a "generative design question" in feedback?

- **Concept: Role Immersion in Simulated Scenarios**
  - **Why needed here:** The system's effectiveness depends on users authentically adopting the mentor role. Without buy-in, interactions become superficial.
  - **Quick check question:** When role-playing, do you consciously adjust your communication style to match your assigned role?

- **Concept: Basic Design Knowledge and Principles**
  - **Why needed here:** Without foundational design knowledge, users cannot provide substantive feedback even with system scaffolding. The system assumes users have some design background to leverage.
  - **Quick check question:** Can you articulate at least three criteria for evaluating a design concept beyond personal preference?

## Architecture Onboarding

- **Component map:** React frontend (Idea Proposal -> Chat Interface -> Feedback Reflection Interface) -> Flask backend -> GPT-4o API modules (Categorizer -> Evaluator -> Knowledge Extractor -> Response Generator -> Idea Updater) -> MySQL database -> Persona layer (Alex with 25 facial expressions, constrained knowledge state)

- **Critical path:**
  1. User submits feedback via Chat Interface
  2. Categorizer classifies feedback type (question family vs. statement family)
  3. Evaluator scores feedback on type-specific criteria (e.g., specificity, justification, action for statements)
  4. Knowledge Extractor extracts "knowledge" and "action plans" from substantive feedback
  5. Response Generator creates mentee response informed by current knowledge state
  6. FRI updates: dashboard metrics, facial expression, inner thoughts
  7. Counter-question triggered if conditions met (e.g., 4 consecutive repetitive feedback)
  8. User clicks "Update Idea" â†’ Idea Updater revises mentee's design using action plans

- **Design tradeoffs:**
  - **Temperature=0 for all LLM calls:** Ensures consistent, predictable outputs but reduces response variety
  - **Novice-only persona:** Simplifies persona management and ensures consistent difficulty, but limits scenario diversity (noted by participants as sometimes too simplistic)
  - **Threshold of 4 consecutive repetitions for counter-questions:** Balances helpful prompting against disruption, but may miss earlier intervention opportunities
  - **LLM-based evaluation:** Enables real-time, scalable feedback assessment, but introduces potential for hallucination or inconsistent scoring

- **Failure signatures:**
  - **Categorizer misclassification:** Cascades to incorrect evaluation criteria and inappropriate mentee responses
  - **Overly sophisticated mentee responses:** Breaks immersion; users perceive AI as too knowledgeable for novice persona
  - **Excessive counter-questions:** Disrupts conversational flow; users report frustration or pressure
  - **Hallucinated mentee background:** If unscripted responses contradict established persona, immersion breaks (though some participants found this "lifelike")

- **First 3 experiments:**
  1. **Validate categorizer accuracy:** Test the LLM categorizer on held-out feedback samples with human ground truth to confirm Cohen's Kappa remains above 0.70 across diverse inputs
  2. **Tune counter-question thresholds:** A/B test different trigger thresholds (e.g., 3 vs. 4 vs. 5 consecutive repetitions) to optimize for engagement without disruption
  3. **Compare mentee persona complexity:** Run within-subject comparison of novice-only vs. intermediate vs. mixed-skill mentee personas to assess impact on engagement and feedback quality diversity

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** To what extent does practicing with Feed-O-Meter lead to sustained, transferable improvements in real-world design feedback skills?
- **Basis in paper:** [explicit] Page 38: "we were unable to verify its long-term effectiveness... future work should investigate its long-term and educational effects in extended, real-world settings."
- **Why unresolved:** The study relied on short-term sessions (20 minutes) and immediate self-reporting, which cannot measure skill retention or behavioral change over time.
- **Evidence to resolve it:** A longitudinal study tracking participants' feedback quality in actual studio courses over a semester following system usage.

### Open Question 2
- **Question:** How does varying the skill level and persona of the AI mentee influence the development of a mentor's feedback strategies?
- **Basis in paper:** [explicit] Page 37: "Future work should explore how to develop multiple personas that align with real-world learning needs and how they can enhance training by exposing students to a broader range of feedback dynamics."
- **Why unresolved:** The study used a single "novice" persona (Alex), which participants noted felt overly simplistic compared to the diverse skill levels of real students.
- **Evidence to resolve it:** A comparative study where participants interact with AI mentees of varying expertise (e.g., novice vs. intermediate) to see if feedback strategies adapt appropriately.

### Open Question 3
- **Question:** How does integrating multimodal interactions (visual/auditory) affect the quality and nature of feedback in AI-driven design education tools?
- **Basis in paper:** [explicit] Page 40: "Future research should explore integrating multimodal interactions (e.g., visual and auditory elements)."
- **Why unresolved:** The current system confined design ideas and feedback to text formats, whereas real design processes heavily rely on visual representations and sketches.
- **Evidence to resolve it:** Iterating the system to accept sketch inputs and analyzing if the modality changes the specificity or type of feedback provided (e.g., more references to visual elements).

### Open Question 4
- **Question:** Do cultural norms regarding feedback reception impact the effectiveness of role-playing with AI agents in design education?
- **Basis in paper:** [explicit] Page 39: "Cultural norms and contexts can significantly influence how people give and receive feedback... future research could include additional participants from diverse cultural backgrounds."
- **Why unresolved:** The study was limited to 24 Korean participants, and the authors acknowledge that cultural dimensions (like those identified by Hofstede) affect feedback reception.
- **Evidence to resolve it:** A cross-cultural user study comparing the system's efficacy and user comfort levels across distinct cultural groups.

## Limitations
- Small, homogeneous sample (n=24 Korean students) limits generalizability
- Heavy reliance on self-reported measures rather than objective skill assessment
- Short-term evaluation cannot verify long-term learning outcomes or skill transfer
- Single novice persona may not reflect real-world diversity of mentee skill levels

## Confidence
- **High Confidence:** Role-switching and constrained knowledge states demonstrably increase engagement and promote reflection
- **Medium Confidence:** Feedback visualization system's effectiveness in improving feedback quality requires larger, more diverse samples and longer-term follow-up
- **Low Confidence:** Counter-question mechanism's impact on feedback quality diversity is less substantiated with limited direct evidence

## Next Checks
1. Conduct a longitudinal study tracking participants' feedback quality over multiple sessions and assessing transfer to real design feedback scenarios outside the system
2. Perform a larger-scale evaluation with diverse participants including experienced design professionals to assess the system's effectiveness across different skill levels and educational contexts
3. Implement A/B testing of counter-question thresholds to empirically determine optimal trigger conditions that maximize learning benefits while minimizing conversational disruption