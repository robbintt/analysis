---
ver: rpa2
title: A Semantic Decoupling-Based Two-Stage Rainy-Day Attack for Revealing Weather
  Robustness Deficiencies in Vision-Language Models
arxiv_id: '2601.13238'
source_url: https://arxiv.org/abs/2601.13238
tags:
- image
- semantic
- stage
- attack
- visual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the first adversarial framework exploiting
  realistic rainy weather to reveal semantic robustness deficiencies in Vision-Language
  Models (VLMs). The two-stage framework operates by first weakening semantic decision
  boundaries through global rain-layer mixing, then optimizing physically grounded
  rain and illumination parameters to induce stable semantic misalignment.
---

# A Semantic Decoupling-Based Two-Stage Rainy-Day Attack for Revealing Weather Robustness Deficiencies in Vision-Language Models

## Quick Facts
- **arXiv ID:** 2601.13238
- **Source URL:** https://arxiv.org/abs/2601.13238
- **Reference count:** 40
- **Primary result:** Introduces a two-stage rainy-day attack framework to expose semantic robustness deficiencies in VLMs, causing up to 62% accuracy drops in zero-shot classification.

## Executive Summary
This paper presents the first adversarial framework exploiting realistic rainy weather to reveal semantic robustness deficiencies in Vision-Language Models (VLMs). The method employs a two-stage approach: first weakening semantic decision boundaries through global rain-layer mixing, then optimizing physically grounded rain and illumination parameters to induce stable semantic misalignment. Using CMA-ES in a non-pixel parameter space, the attack generates perturbations that are both interpretable and physically plausible. Evaluations across zero-shot classification, image captioning, and visual question answering show significant performance degradation in mainstream VLMs.

## Method Summary
The framework operates through a semantic decoupling mechanism where physical rain parameters (raindrop streaks, blurring) are optimized in a multi-scale space to weaken semantic boundaries, followed by illumination adjustment to maximize misalignment. The optimization uses CMA-ES in a non-pixel parameter space, generating perturbations that are interpretable and physically plausible. The attack targets the intersection of vision and language understanding, exploiting the fact that rainy conditions affect both visual perception and semantic grounding.

## Key Results
- Up to 62% accuracy drops in zero-shot classification tasks
- Significant performance degradation across captioning and VQA tasks
- Ablation studies confirm both multi-scale raindrop structures and illumination modeling are key drivers
- Generated perturbations are both interpretable and physically plausible

## Why This Works (Mechanism)
The attack exploits the fact that rainy conditions create physical changes in visual input that can mislead semantic understanding in VLMs. By decoupling the semantic components through controlled weather perturbations, the framework reveals how these models fail to maintain robustness when faced with realistic environmental conditions. The two-stage optimization ensures that perturbations are not just visually similar to rain but are specifically tuned to cause semantic misalignment.

## Foundational Learning
- **CMA-ES optimization**: Non-gradient based evolutionary strategy needed for continuous parameter space optimization of physical rain parameters; quick check: verify convergence properties on synthetic test functions
- **Multi-scale raindrop modeling**: Captures the physical reality that rain appears differently at different distances; quick check: validate scale distributions against real rain photography
- **Semantic decoupling**: The concept that visual perturbations can separate visual features from semantic understanding; quick check: test with controlled synthetic semantic tasks
- **Physical plausibility constraints**: Ensures generated rain patterns remain realistic rather than adversarial artifacts; quick check: compare with meteorological rain models
- **Non-pixel parameter space**: Optimization occurs in physical parameter space rather than direct pixel manipulation; quick check: verify parameter interpretability
- **Zero-shot evaluation**: Tests model performance without task-specific fine-tuning; quick check: confirm task definitions match standard benchmarks

## Architecture Onboarding
- **Component map:** Input image → Rain layer generation → Semantic boundary weakening → Illumination optimization → Output perturbed image → VLM evaluation
- **Critical path:** Physical rain parameter generation → CMA-ES optimization → Semantic misalignment measurement → Iterative refinement
- **Design tradeoffs:** Physical plausibility vs. attack strength; computational cost of multi-scale modeling vs. attack effectiveness; interpretability vs. stealth
- **Failure signatures:** Limited degradation on models with weather augmentation; failure to transfer to non-vision-language models; reduced effectiveness in low-resolution images
- **First experiments:** 1) Test baseline CMA-ES convergence on synthetic rain parameters; 2) Evaluate single-scale vs multi-scale rain effectiveness; 3) Measure illumination sensitivity across different weather conditions

## Open Questions the Paper Calls Out
### Open Question 1
- **Question:** Can the semantic decoupling framework be effectively generalized to other adverse weather conditions, such as fog, haze, or snow, while maintaining physical plausibility?
- **Basis in paper:** [explicit] The Limitations section states the study focuses on rainy conditions and "does not explicitly cover other complex environmental factors such as fog, haze, or snow."
- **Why unresolved:** The current parameterization is specifically tailored to raindrop physics (streaks, blurring) which differ physically from the scattering effects of fog or the accumulation patterns of snow.
- **What evidence would resolve it:** Successful application of the two-stage optimization to foggy or snowy datasets using distinct physical parameter sets, showing similar semantic degradation in VLMs.

### Open Question 2
- **Question:** What specific defense mechanisms or training paradigms can mitigate the semantic misalignment caused by physically grounded weather perturbations?
- **Basis in paper:** [explicit] The Conclusion explicitly identifies "corresponding defense strategies" as a direction for future work.
- **Why unresolved:** The paper establishes the vulnerability ("robustness deficiencies") via an attack framework but does not propose or test methods to improve model resilience against such structured, non-pixel perturbations.
- **What evidence would resolve it:** Experiments demonstrating that VLMs trained with weather-augmented data or specific robustness regularization maintain higher zero-shot accuracy under the proposed attack.

### Open Question 3
- **Question:** Are the performance degradation effects caused by multi-scale raindrops and illumination modulation synergistic, or do they accumulate linearly?
- **Basis in paper:** [inferred] The Limitations section notes a need for "deeper investigation into... the interactions among different environmental factors," and ablations show both contribute to the attack success.
- **Why unresolved:** While component ablations show both are necessary for peak performance, the paper does not quantify the non-linear interaction between the raindrop parameter space and the illumination field during the optimization process.
- **What evidence would resolve it:** A comparative analysis of the loss landscape and semantic shift magnitude when optimizing rain and illumination parameters jointly versus independently.

## Limitations
- Focus on rainy conditions only, excluding other weather factors like fog, haze, or snow
- Performance gains stem from combined rain augmentation and illumination optimization, making it difficult to isolate individual contributions
- Physical realism of generated patterns lacks quantitative validation against real-world rain physics
- Evaluation limited to mainstream VLMs without testing transferability to smaller or domain-specific models

## Confidence
- **High:** The two-stage framework design and use of CMA-ES for non-pixel parameter space optimization are methodologically sound and clearly described
- **Medium:** The performance degradation results are reproducible within the tested VLMs and tasks, but generalizability to other models or domains is uncertain
- **Low:** Claims about physical plausibility and interpretability of perturbations lack quantitative validation against real-world rain or human perception benchmarks

## Next Checks
1. Conduct perceptual studies with human raters to assess whether generated rain patterns are indistinguishable from real rain in terms of both visual appearance and impact on semantic interpretation
2. Test attack transferability to smaller or domain-specific VLMs, and evaluate the effectiveness of fine-tuning or data augmentation as defense mechanisms
3. Compare the framework's performance against simpler perturbation methods (e.g., uniform noise, single-scale rain) to determine if the added complexity yields proportionally greater semantic misalignment