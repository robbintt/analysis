---
ver: rpa2
title: Optimizing Multi-Hop Document Retrieval Through Intermediate Representations
arxiv_id: '2503.04796'
source_url: https://arxiv.org/abs/2503.04796
tags:
- information
- transformation
- reasoning
- intermediate
- representations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Layer-wise Retrieval-Augmented Generation (L-RAG),
  a method that leverages intermediate representations from middle layers of LLMs
  to retrieve external documents for multi-hop question answering. The authors identify
  a three-stage information processing pattern in LLMs using Singular Value Decomposition
  (SVD) analysis of weight matrices, showing that intermediate representations contain
  richer information for retrieval compared to final layer representations.
---

# Optimizing Multi-Hop Document Retrieval Through Intermediate Representations

## Quick Facts
- arXiv ID: 2503.04796
- Source URL: https://arxiv.org/abs/2503.04796
- Authors: Jiaen Lin, Jingyu Liu, Yingbo Liu
- Reference count: 17
- One-line primary result: L-RAG achieves multi-hop QA accuracy comparable to multi-step approaches while maintaining inference overhead similar to standard RAG

## Executive Summary
This paper introduces Layer-wise Retrieval-Augmented Generation (L-RAG), a method that leverages intermediate representations from middle layers of LLMs to retrieve external documents for multi-hop question answering. The authors identify a three-stage information processing pattern in LLMs using Singular Value Decomposition (SVD) analysis of weight matrices, showing that intermediate representations contain richer information for retrieval compared to final layer representations. L-RAG achieves performance comparable to multi-step approaches while maintaining inference overhead similar to standard RAG, outperforming existing RAG methods on datasets including MuSiQue, HotpotQA, and 2WikiMultiHopQA.

## Method Summary
L-RAG combines traditional first-hop retrieval with representation-based higher-hop retrieval. The method first retrieves first-hop documents using BM25 or Contriever, then generates intermediate representations from a target LLM layer. These representations are projected through a trained MLP adapter into Contriever embedding space to retrieve higher-hop documents. The final answer is generated using all retrieved documents. The optimal retrieval layer is selected based on Transformation Divergence (TD) analysis of attention weight matrices, identifying layers with low TD that correspond to information extraction phases.

## Key Results
- On MuSiQue, L-RAG achieves 35.2% accuracy (vs 29.7% for vanilla RAG@8)
- On 2WikiMultiHopQA, L-RAG achieves 41.8% accuracy (vs 35.5% for vanilla RAG@8)
- On 2WikiMQA, L-RAG@8 achieves 48.0% recall for higher-hop documents (vs 7.4% for vanilla RAG@8)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** LLMs exhibit a three-stage information processing pattern (extraction → processing → extraction) across layers, where intermediate layers contain richer representations for multi-hop reasoning than final layers.
- **Mechanism:** SVD analysis of attention weight matrices ($W_v$) reveals that Transformation Divergence (TD) follows a consistent pattern: initial low TD (information extraction), middle high TD (contextual processing), final low TD (token-generation alignment). Low TD concentrates information along principal directions; high TD distributes processing across multiple directions.
- **Core assumption:** TD patterns in attention weights correlate with representational quality for retrieval tasks.
- **Evidence anchors:** [abstract] "identify a three-stage information processing pattern in LLMs during layer-by-layer reasoning, consisting of extraction, processing, and subsequent extraction steps"; [Section 3.2-3.3] Definition 3.2 formalizes TD; Figure 4 shows consistent three-phase TD progression across GPT-J, Vicuna, Llama-3.1, Mistral; [corpus] Weak/no direct validation of TD mechanism in related work; corpus focuses on alternative RAG architectures rather than intermediate-layer analysis.
- **Break condition:** If TD patterns don't generalize to architectures without standard attention-MLP blocks (e.g., Mamba, hybrid models), layer selection via TD may not apply.

### Mechanism 2
- **Claim:** Intermediate layer representations capture next-hop entity information before it appears in final token predictions.
- **Mechanism:** LogitLens analysis shows intermediate answers emerge earlier in the layer stack than final answers. The structured/comprehensive representations (formed during/after the low-TD extraction phase) encode bridge entities needed for subsequent retrieval.
- **Core assumption:** Earlier emergence of intermediate answers in logits indicates representations at those layers are better suited for retrieving next-hop documents.
- **Evidence anchors:** [Section 3.4] "intermediate answers emerge earlier than final answers across various LLMs" (Figure 5); [Section 5.3, Appendix D] Recall rates peak at layers during/after low-TD period (Figure 10); [corpus] No direct validation; related work (Query-Centric Graph RAG, Hierarchical Lexical Graph) focuses on external graph construction rather than internal representation analysis.
- **Break condition:** If multi-hop queries require reasoning not reflected in single-token intermediate answers (e.g., multi-entity synthesis), representation-based retrieval may underperform.

### Mechanism 3
- **Claim:** A trained MLP adapter can align LLM intermediate representations with Contriever embedding space for effective document retrieval.
- **Mechanism:** An MLP projection head $g(\cdot)$ maps intermediate representations to Contriever space; contrastive InfoNCE loss trains the adapter to distinguish positive/negative documents. Relevance score: $s(r,d) = f(g(r))^T \cdot f(d)$
- **Core assumption:** The mapping preserves next-hop information while aligning with dense retrieval semantics.
- **Evidence anchors:** [Section 4.2] Equation 3-5 define the training procedure; [Section 5.3, Table 2] L-RAG@8 achieves 48.0% recall on 2WikiMQA (vs 7.4% vanilla RAG@8); [corpus] No external validation of this specific adapter architecture; standard practice uses query encoders directly.
- **Break condition:** If intermediate representations encode task-specific patterns not generalizable across corpora, the trained retriever may require per-dataset retraining (as the authors do).

## Foundational Learning

- **Singular Value Decomposition (SVD):**
  - Why needed here: SVD decomposes weight matrices into rotation-scaling-rotation operations, enabling TD quantification for layer analysis.
  - Quick check: Can you explain what high vs. low singular value entropy indicates about a transformation's information processing behavior?

- **Contrastive Learning (InfoNCE Loss):**
  - Why needed here: The representation retriever is trained via contrastive loss to pull positive document pairs closer and push negatives apart in embedding space.
  - Quick check: Given a batch of representations and documents, how does InfoNCE compute the loss for a single positive pair?

- **LogitLens Interpretability:**
  - Why needed here: Validates that intermediate layers encode bridge-entity information by projecting hidden states to vocabulary logits.
  - Quick check: How would you extract the top-k token probabilities from a hidden state at layer $l$?

## Architecture Onboarding

- **Component map:** Traditional Retriever (BM25/Contriever) -> LLM Backbone (partial forward pass to target layer) -> Representation Retriever (MLP adapter + Contriever) -> Fusion (concatenate all docs) -> LLM (full forward) -> Final answer

- **Critical path:**
  1. Query → Traditional Retriever → First-hop docs
  2. Query + First-hop docs → LLM (partial forward pass to target layer) → Intermediate representation
  3. Intermediate representation → MLP adapter → Contriever embedding → Higher-hop docs
  4. Query + All docs → LLM (full forward) → Final answer

- **Design tradeoffs:**
  - Layer selection: Earlier layers retain more raw information; later layers have more task-specific processing. Authors recommend minimum TD layer ± neighbors.
  - Corpus dependency: Retriever trained per-dataset; cross-dataset generalization not evaluated.
  - Assumption: Multi-hop = 2-hop focus; extension to 3+ hops unclear.

- **Failure signatures:**
  - Low recall on datasets with high information leakage (e.g., HotpotQA) suggests representation retriever adds minimal value over query-based retrieval
  - High TD at target layer indicates processing phase, not extraction—may yield noisy representations
  - Discrepancy between intermediate answer emergence layer and retrieval-optimal layer

- **First 3 experiments:**
  1. **TD profiling:** Compute TD across all attention layers for your target LLM; identify the local minimum in the first half of the network.
  2. **Layer ablation:** Train representation retrievers at layers {min_TD − 4, min_TD, min_TD + 4, min_TD + 8}; evaluate recall@K on a held-out multi-hop subset.
  3. **Baseline comparison:** Against vanilla RAG@8 and IRCoT on 2WikiMQA (lowest information leakage per Table 2), measuring accuracy and latency per query.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the three-stage information processing pattern identified via Transformation Divergence (TD) persist in larger-scale LLMs (e.g., >70B parameters) or alternative architectures like Mixture-of-Experts (MoE)?
- Basis in paper: [inferred] The "Limitations" section notes that reasoning pattern characterization requires "broader empirical support beyond current validation scope," and experiments were restricted to 6B-8B dense models.
- Why unresolved: The TD analysis was only validated on a limited set of standard dense architectures (GPT-2, Llama 2, Mistral 7B).
- What evidence would resolve it: SVD analysis of weight matrices in larger or sparse models showing the same low-TD / high-TD / low-TD progression.

### Open Question 2
- Question: Can the optimal intermediate layer for retrieval be determined theoretically or via a zero-shot proxy, rather than requiring a grid search over candidate layers?
- Basis in paper: [inferred] Section 4.2 states that L-RAG must "train retrievers using each layer in candidate layers" to identify the optimal one, which is computationally inefficient.
- Why unresolved: The current methodology requires training separate retrievers for multiple layers to empirically select the best performer.
- What evidence would resolve it: A theoretical mapping or unsupervised metric (other than TD directly) that predicts the optimal retrieval layer without training a downstream retriever.

### Open Question 3
- Question: To what extent does the representation retriever generalize to unseen multi-hop datasets without dataset-specific fine-tuning?
- Basis in paper: [inferred] Section 4.2 notes, "We train L-RAG separately for each dataset to achieve better performance," leaving cross-domain generalization unexplored.
- Why unresolved: It is unclear if the model learns a universal intermediate representation or overfits to the specific reasoning distribution of the training dataset.
- What evidence would resolve it: Evaluation of a single retriever trained on one dataset (e.g., HotpotQA) and tested on others (e.g., MuSiQue) without further fine-tuning.

## Limitations

- The core claims about layer selection via TD analysis rely on patterns observed in transformer-based LLMs with standard attention-MLP architectures, limiting generalizability to non-transformer architectures.
- The representation retriever is trained per dataset, raising questions about cross-dataset generalization and the need for per-dataset retraining.
- The focus on 2-hop reasoning limits applicability to more complex multi-hop scenarios, and the paper doesn't evaluate whether intermediate representations capture multi-entity synthesis or other complex reasoning patterns.

## Confidence

- **High Confidence:** The three-stage information processing pattern observed through SVD analysis and the consistent TD progression across multiple LLM architectures are well-supported by empirical evidence and visualizations.
- **Medium Confidence:** The claim that intermediate representations contain richer information for retrieval compared to final layers is supported by recall rate improvements but requires further validation across diverse architectures and tasks.
- **Medium Confidence:** The trained MLP adapter successfully aligns intermediate representations with Contriever embedding space, as demonstrated by significant recall improvements on 2WikiMQA, though the specific adapter architecture details remain unspecified.

## Next Checks

1. **Architecture Generalization Test:** Apply TD analysis to non-transformer architectures (Mamba, hybrid models) to determine if layer selection mechanisms transfer beyond standard attention-MLP designs.

2. **Cross-Dataset Transfer Evaluation:** Train representation retrievers on one multi-hop dataset and evaluate performance on unseen datasets to measure generalization capabilities and identify any per-dataset retraining requirements.

3. **Multi-Hop Extension Study:** Evaluate L-RAG on 3+ hop reasoning tasks to assess scalability beyond the 2-hop focus, measuring both accuracy degradation and retrieval effectiveness as hop count increases.