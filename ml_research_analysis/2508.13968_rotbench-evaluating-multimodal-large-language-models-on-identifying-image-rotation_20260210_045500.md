---
ver: rpa2
title: 'RotBench: Evaluating Multimodal Large Language Models on Identifying Image
  Rotation'
arxiv_id: '2508.13968'
source_url: https://arxiv.org/abs/2508.13968
tags:
- image
- rotation
- images
- rotbench
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the ability of Multimodal Large Language
  Models (MLLMs) to identify the orientation of rotated images. The authors introduce
  RotBench, a benchmark consisting of 350 manually filtered images from the Spatial-MM
  dataset, divided into lifestyle, portrait, and landscape categories.
---

# RotBench: Evaluating Multimodal Large Language Models on Identifying Image Rotation

## Quick Facts
- arXiv ID: 2508.13968
- Source URL: https://arxiv.org/abs/2508.13968
- Reference count: 40
- Primary result: State-of-the-art MLLMs struggle to identify 90° vs 270° image rotations despite excelling at 0° and 180° orientations

## Executive Summary
This paper introduces RotBench, a benchmark for evaluating Multimodal Large Language Models' ability to identify image rotations. The benchmark consists of 350 carefully curated images from the Spatial-MM dataset across lifestyle, portrait, and landscape categories. The study reveals a surprising gap in MLLMs' spatial reasoning capabilities - while models like GPT-4o, o3, and Gemini-2.5-Pro perform well on identifying upright (0°) and upside-down (180°) images, they consistently fail to distinguish between 90° and 270° rotations. This limitation persists even with auxiliary information such as captions, depth maps, and chain-of-thought prompting. Fine-tuning improves performance on 180° images but does not resolve the 90°/270° confusion, highlighting a fundamental difference between MLLM spatial reasoning and human perception.

## Method Summary
The researchers developed RotBench by selecting 350 images from the Spatial-MM dataset, filtering out ambiguous cases to ensure clear rotation identification. Images were categorized into lifestyle, portrait, and landscape groups. The benchmark tests MLLMs on identifying rotations at 0°, 90°, 180°, and 270° orientations. Multiple state-of-the-art models were evaluated including GPT-4o, o3, Gemini-2.5-Pro, and Qwen2-VL. The study tested various prompting strategies including chain-of-thought prompting and the provision of auxiliary information like captions and depth maps. Fine-tuning experiments were conducted to assess whether additional training could improve rotation identification performance, particularly for the problematic 90°/270° distinction.

## Key Results
- MLLMs achieve high accuracy on 0° and 180° rotations but consistently confuse 90° with 270° rotations
- Chain-of-thought prompting and auxiliary information (captions, depth maps) provide only minor, inconsistent improvements
- Fine-tuning significantly improves 180° identification but fails to resolve 90°/270° confusion
- The 90°/270° failure pattern persists across multiple state-of-the-art MLLMs including GPT-4o, o3, and Gemini-2.5-Pro

## Why This Works (Mechanism)
The mechanism behind MLLMs' failure to distinguish 90° from 270° rotations likely relates to their training data distribution and the inherent symmetry in visual features at these orientations. Models trained primarily on upright images may develop strong priors for 0° and 180° orientations (where text and gravity cues are most reliable), but lack sufficient exposure to distinguish between clockwise and counterclockwise rotations. The failure suggests MLLMs may be relying on global visual patterns rather than geometric reasoning about orientation, leading to confusion when local features appear similar at 90° and 270° rotations.

## Foundational Learning
- Multimodal Large Language Models: AI systems that process both text and images, needed for tasks requiring visual understanding combined with reasoning
- Spatial reasoning in vision models: The ability to understand object orientation and spatial relationships, critical for tasks like navigation and object manipulation
- Image rotation symmetry: The property that certain rotations produce visually similar patterns, important for understanding why models confuse 90° and 270°
- Chain-of-thought prompting: A technique that encourages step-by-step reasoning, used here to test if explicit reasoning helps rotation identification
- Fine-tuning: The process of adapting pre-trained models to specific tasks, tested here to improve rotation recognition

## Architecture Onboarding
Component map: Input image -> Vision encoder -> Feature extraction -> Reasoning module -> Output classification
Critical path: Image processing through vision encoder is the most critical component, as it directly affects the model's ability to extract rotation-relevant features
Design tradeoffs: The study implicitly highlights the tradeoff between general-purpose vision capabilities and specialized spatial reasoning tasks
Failure signatures: Consistent confusion between 90° and 270° rotations across models suggests a fundamental limitation in how MLLMs process rotational information
First experiments: 1) Test model performance on continuous rotation angles rather than discrete values, 2) Evaluate models on videos or sequential images to provide temporal context, 3) Test geometric reasoning modules specifically designed for orientation tasks

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- The RotBench dataset contains only 350 images, which may not capture full real-world diversity
- The study focuses exclusively on four discrete rotation angles (0°, 90°, 180°, 270°), ignoring continuous rotation variations
- Experiments are limited to static image recognition without considering temporal or contextual cues

## Confidence
- MLLMs struggle with rotation identification overall: High confidence
- Models perform poorly at distinguishing 90° from 270° rotations: High confidence
- Auxiliary information and fine-tuning provide only minor improvements: Medium confidence

## Next Checks
1. Test model performance on a larger dataset with continuous rotation angles to determine if 90°/270° confusion persists across the full rotation spectrum
2. Evaluate whether providing temporal context (such as video frames or sequential images) improves rotation identification
3. Test whether pre-training MLLMs on rotation-specific data or incorporating geometric reasoning modules can address the identified limitations, particularly for 90°/270° distinction