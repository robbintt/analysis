---
ver: rpa2
title: Crowdsourcing-Based Knowledge Graph Construction for Drug Side Effects Using
  Large Language Models with an Application on Semaglutide
arxiv_id: '2504.04346'
source_url: https://arxiv.org/abs/2504.04346
tags:
- side
- effects
- semaglutide
- data
- reddit
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a systematic framework that leverages large
  language models (LLMs) to extract medication side effects from social media and
  organize them into a knowledge graph (KG). The pipeline was applied to semaglutide
  for weight loss using data from Reddit.
---

# Crowdsourcing-Based Knowledge Graph Construction for Drug Side Effects Using Large Language Models with an Application on Semaglutide

## Quick Facts
- arXiv ID: 2504.04346
- Source URL: https://arxiv.org/abs/2504.04346
- Reference count: 40
- Primary result: Demonstrated LLM-based extraction of semaglutide side effects from Reddit, organized into validated knowledge graph with comparison to FAERS database

## Executive Summary
This study presents a systematic framework that leverages large language models (LLMs) to extract medication side effects from social media and organize them into a knowledge graph (KG). The pipeline was applied to semaglutide for weight loss using data from Reddit. Through prompt design and few-shot in-context learning, the LLM extracted side effects, associated medications, and attributes such as severity, duration, and dosage. The extracted information was visualized using D3.js, creating an interactive knowledge graph linking semaglutide products to their reported side effects. The constructed KG was validated by comparing extracted side effects with adverse events reported in the FAERS database.

## Method Summary
The method employs a few-shot in-context learning approach using GPT-4o mini to extract medication-side effect triples from Reddit posts about semaglutide. Five manually curated examples (three positive, two null) condition the LLM to recognize the target relation schema. The extracted side effects undergo normalization through semantic similarity clustering using SentenceTransformer embeddings (all-MiniLM-L6-v2), with terms having similarity > 0.9 clustered together. GPT assists in grouping these clusters, which are then manually reviewed and mapped to MedDRA Preferred Terms. The final KG is visualized using D3.js and validated by comparing with FAERS database frequencies.

## Key Results
- Successfully extracted 2,284 unique side effect terms from Reddit semaglutide discussions
- Normalized diverse user-reported terms into 605 consistent clusters mapped to MedDRA Preferred Terms
- Validated KG by comparing top 20 extracted side effects with FAERS database, showing correlation with known adverse events
- Created interactive visualization linking semaglutide products to reported side effects with attributes

## Why This Works (Mechanism)

### Mechanism 1
Few-shot in-context learning with GPT-4o mini enables reliable extraction of medication-side effect triples from noisy social media text. Five manually curated examples (three positive, two negative/null) are provided in the prompt, conditioning the LLM to recognize the target relation schema (Medication-SideEffect-Attributes) and desired output format (JSON), while teaching it to reject irrelevant content via null examples. Core assumption: Selected examples provide sufficient coverage of linguistic patterns and semantic relations present in Reddit corpus.

### Mechanism 2
Semantic similarity clustering (SentenceTransformer embeddings) followed by LLM-assisted grouping normalizes diverse user-reported side effect terms into consistent ontology. The all-MiniLM-L6-v2 model generates embeddings for 2,284 unique side effect terms. A similarity matrix is computed, and terms with similarity > 0.9 are clustered. GPT iteratively assigns these clusters to keys, which are manually reviewed and mapped to MedDRA Preferred Terms. Core assumption: Semantic embedding space captures medically relevant similarity.

### Mechanism 3
Comparison with FAERS database serves as external validity check, demonstrating crowdsourced social media data captures known adverse events while surfacing patient-centric signals underrepresented in official reports. Top 20 side effects from Reddit KG are manually matched to top 20 AEs in FAERS. Frequency metrics are computed for each data source and compared. Spearman correlation quantifies overall relationship, and binomial regression identifies specific AEs with statistically different reporting rates. Core assumption: Frequency of side effect mentions on Reddit is meaningful proxy for propensity comparable to AE frequencies in FAERS.

## Foundational Learning

- **Knowledge Graph (KG) as a Triple Store (Subject-Predicate-Object)**
  - Why needed here: Entire output of pipeline is KG structured as triples. Understanding this foundational data model is necessary to interpret visualization, query data, or extend schema.
  - Quick check question: Given relation `{ "start": {"label": "Medication", "properties": {"name": "Ozempic"}}, "end": {"label": "SideEffect", "properties": {"name": "Nausea"}}, "properties": {"severity": "severe"} }`, what are subject, object, and predicate?

- **Few-Shot In-Context Learning (ICL)**
  - Why needed here: Core technique used to make LLM perform specific information extraction task. Engineers must understand ICL to debug extraction failures or adapt pipeline to new medications.
  - Quick check question: If you want to change pipeline to also extract user's age, what part of prompt would you modify and what would you need to add?

- **Semantic Embeddings and Similarity**
  - Why needed here: Mechanism for normalizing noisy, user-generated side effect terms. Engineers need this to understand normalization step and adjust similarity threshold if over/under-merging terms.
  - Quick check question: Why is simple string match (e.g., "Headache" == "Headache") insufficient for normalizing side effects from social media text? What does semantic embedding capture that string match does not?

## Architecture Onboarding

- **Component map:**
  Data Ingestion: PRAW library → Raw Reddit data (posts, comments, replies) stored in flattened format
  Cleaning & Preprocessing: Remove emojis, non-English text, bot-generated content → Clean text corpus
  LLM Extraction Service: Accepts clean text, uses GPT-4o mini API with few-shot prompt → JSON array of relations (triples with properties)
  Post-Processing & Normalization: De-duplication → Normalization (SentenceTransformer embeddings → Similarity calculation → GPT-based clustering → Manual review to MedDRA PTs)
  Knowledge Graph Store: Stores final, normalized triples (graph database or document store)
  Visualization & Frontend: D3.js force-directed graph application consuming KG data and rendering interactive UI

- **Critical path:**
  1. Data Quality & Prompt Engineering: Fidelity of entire KG depends on quality of Reddit data and effectiveness of few-shot prompt. Poorly designed prompt yields garbage triples.
  2. Normalization Logic: Semantic similarity threshold and GPT clustering logic directly determine final number of unique side effect nodes. Too low threshold merges distinct symptoms; too high leaves many duplicates.

- **Design tradeoffs:**
  - Model Choice: GPT-4o mini chosen for balance of performance and cost-efficiency over more powerful models like GPT-4, limiting performance on complex or ambiguous text.
  - Automation vs. Manual Review: Normalization step partially automated (embeddings, GPT clustering) but requires final manual review and alignment to MedDRA, adding human effort but ensuring higher quality.
  - Validation Source: FAERS provides strong external benchmark but may not capture full spectrum of patient-centric concerns (e.g., "Ozempic face") prominent on social media.

- **Failure signatures:**
  - Hallucination/Extraction Errors: LLM extracts side effects for different medication or misinterprets negation (e.g., "I had no nausea" → extracts "Nausea")
  - Normalization Collapse: Similarity threshold set too aggressively, causing distinct medical concepts (e.g., "fatigue" and "drowsiness") to be merged
  - Concept Drift: Reddit corpus evolves with new slang or medication brands not covered in original prompt, leading to drop in extraction recall

- **First 3 experiments:**
  1. Quantify Extraction Error Types: Manually review larger sample of extracted triples to categorize errors (wrong medication, wrong severity, hallucination) to establish baseline for prompt improvement
  2. Ablation Study on Prompt Examples: Systematically remove or change few-shot examples to measure impact on extraction accuracy and null-rate
  3. Benchmark Normalization Threshold: Run normalization pipeline with different similarity thresholds on held-out set of raw side effect terms to quantify trade-off between unique nodes count and semantic consistency

## Open Questions the Paper Calls Out

### Open Question 1
How can prompt engineering or model selection be optimized to eliminate extraction of side effects attributed to incorrect medications (e.g., Zepbound) in multi-drug discussions? The authors note GPT-4o mini "occasionally misinterprets prompts—for instance, including side effects related to other drugs like Zepbound," and suggest exploring "alternative models and refined prompt engineering." Evidence would require comparative evaluation of different LLMs or prompt strategies showing statistically significant reduction in false-positive extractions.

### Open Question 2
What computational frameworks can effectively integrate subjective "side effects" from social media with clinically verified "adverse events" from regulatory databases? Authors identify "conceptual challenge in distinguishing AEs from side effects" and state that "Future research can focus on better integrating official and user-generated data sources." Evidence would require development of unified ontology or probabilistic model that successfully maps colloquial social media terms to MedDRA preferred terms while filtering non-causal associations.

### Open Question 3
Does pipeline maintain high extraction accuracy when applied to drugs with lower social media volume or on platforms with different structural constraints (e.g., character limits)? Study validates framework solely on Semaglutide and Reddit; authors note "Rybelsus" had very low mention volume, suggesting pipeline's sensitivity to data density remains unknown. Evidence would require replicating study on different drug class (e.g., statins) and different platform (e.g., X/Twitter) to compare extraction performance metrics.

## Limitations
- Generalizability of few-shot prompt may not extend to medications with different side effect profiles or linguistic patterns
- Validation comparison with FAERS may miss patient-centric concerns unique to social media that don't map to standard MedDRA terms
- Temporal dynamics could degrade extraction performance as Reddit discussion patterns evolve with new slang or medication brands

## Confidence

- **High Confidence:** Technical pipeline architecture (data ingestion → LLM extraction → normalization → KG construction) is clearly specified and reproducible. Comparison methodology with FAERS is methodologically sound.
- **Medium Confidence:** Specific five-shot prompt examples effectively capture semantic relations needed for semaglutide, but effectiveness for other medications is unproven. 0.9 similarity threshold for clustering appears reasonable but may require tuning.
- **Low Confidence:** Extent to which this approach captures full spectrum of patient experiences versus official reporting systems, and whether computational savings justify potential loss in precision versus fully supervised approaches.

## Next Checks
1. **Prompt Transferability Test:** Apply exact same five-shot prompt to Reddit data for different drug class (e.g., GLP-1 agonists other than semaglutide, or SSRIs) and measure extraction accuracy, false positive rates, and required prompt modifications.
2. **Temporal Drift Analysis:** Re-run extraction pipeline on chronologically segmented subset of Reddit data (e.g., 2017-2020 vs 2021-2025) to quantify how extraction performance changes over time and identify specific linguistic patterns that break.
3. **FAERS Coverage Gap Analysis:** Manually categorize top 20 social media side effects that don't appear in FAERS to determine whether these represent genuine patient-centric concerns missing from official reporting versus extraction errors or noise.