---
ver: rpa2
title: Realized Volatility Forecasting for New Issues and Spin-Offs using Multi-Source
  Transfer Learning
arxiv_id: '2503.12648'
source_url: https://arxiv.org/abs/2503.12648
tags:
- data
- target
- source
- learning
- volatility
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of forecasting realized volatility
  for new issues and spin-offs, which typically have limited historical data. The
  authors propose a multi-source transfer learning approach that selects subsequences
  from complementary assets with substantial historical data, based on their similarity
  to the target asset's data using Dynamic Time Warping (DTW).
---

# Realized Volatility Forecasting for New Issues and Spin-Offs using Multi-Source Transfer Learning

## Quick Facts
- **arXiv ID**: 2503.12648
- **Source URL**: https://arxiv.org/abs/2503.12648
- **Reference count**: 28
- **One-line primary result**: Multi-source transfer learning with DTW-based instance selection significantly outperforms target-only and naive pooling approaches for forecasting realized volatility of new issues and spin-offs.

## Executive Summary
This paper addresses the challenge of forecasting realized volatility for new issues and spin-offs that have limited historical data. The authors propose a multi-source transfer learning approach that selects similar subsequences from complementary assets using Dynamic Time Warping (DTW) distance. These selected subsequences are combined with the target asset's data to train various forecasting models including HAR, FNN, and XGBoost. The results demonstrate significant improvements over baseline models, with the transfer learning approach achieving up to 33.2% reduction in MSE compared to the naive forecast and up to 15.4% improvement over target-only HAR-STD models.

## Method Summary
The proposed method uses instance-based transfer learning to address data scarcity for new issues and spin-offs. Source assets' historical volatility data is split into non-overlapping subsequences of fixed length. The DTW distance between the target asset's recent volatility profile and each source subsequence is calculated. Subsequences below a specified distance threshold are pooled with the target data to train forecasting models. The approach uses three model types: HAR (OLS), FNN (3 hidden layers), and XGBoost (40 trees, depth 5). Models are evaluated using rolling window forecasting with 1-day ahead predictions.

## Key Results
- The MTL approach outperforms target-only and naive pooling models across all forecasting architectures
- XGBoost models achieve the strongest performance with up to 33.2% MSE reduction vs. naive forecast
- Transfer learning provides superior forecasts immediately after the first trading day (1-models)
- MTL-50 and MTL-75 (selecting 50th and 75th percentile closest subsequences) perform best
- The approach is robust across different asset types and market conditions

## Why This Works (Mechanism)

### Mechanism 1: Instance Selection via Dynamic Time Warping (DTW)
- **Claim**: Selecting source subsequences based on similarity to target data improves forecasting accuracy
- **Mechanism**: DTW distance measures similarity between target's lagged volatility components and source subsequences. Subsequences below threshold ε are pooled with target data for training
- **Core assumption**: Conditional probability distribution of realized variance is more similar between target and selected source subsequences than between target and entire source dataset
- **Evidence anchors**: Abstract shows MTL outperforms models trained on entire source/target data. Section 6.1 analysis reveals selected subsequences aren't limited to target's GICS sector or recent observations
- **Break condition**: May fail if target asset's volatility dynamics are structurally different from all source assets

### Mechanism 2: Model-Agnostic Pooling of Selected Instances
- **Claim**: Combining instance selection with diverse models consistently improves performance, with XGBoost showing strongest gains
- **Mechanism**: Filtered training dataset (target + selected source subsequences) trains forecasting models. XGBoost benefits most from enriched dataset due to regularization and complex dependency capture
- **Core assumption**: Relationship between lagged volatility and future volatility is similar across target and selected source assets
- **Evidence anchors**: Section 6.1 shows MTL-75 XGB-EXT achieves cross-sectional MSE and MAE ratios of one or less relative to all other models
- **Break condition**: Performance may degrade if selected model is overly complex for available data size

### Mechanism 3: Immediate Post-Listing Forecasting via Dynamic Predictor Sets
- **Claim**: Approach generates forecasts immediately after first trading day using dynamically adjusted predictor sets
- **Mechanism**: Different predictor sets ("1-models", "5-models", "22-models") correspond to available lagged features, allowing transfer learning from day one
- **Core assumption**: Single day of target data combined with similar source subsequences is sufficient to train useful forecasting model
- **Evidence anchors**: Section 6.3 shows strong performance of 1-models using only most reduced predictor set
- **Break condition**: Highly sensitive to quality of single initial target observation and relevance of selected source subsequences

## Foundational Learning

**Transfer Learning (Instance-Based)**
- Why needed: Addresses data scarcity problem for new assets by leveraging data from other assets
- Quick check: How does instance-based transfer differ from feature-based transfer in time series context?

**Dynamic Time Warping (DTW)**
- Why needed: Quantifies similarity between time series of different lengths with potential temporal misalignments
- Quick check: Why is DTW preferred over Euclidean distance for comparing volatility subsequences?

**Realized Volatility (RV)**
- Why needed: Specific financial quantity being forecast, constructed from high-frequency intraday returns
- Quick check: What is trade-off when choosing sampling frequency for constructing Realized Volatility?

## Architecture Onboarding

**Component map**: Target Asset Data + Source Asset Pool -> DTW Selector -> Pooled Training Set -> Forecasting Model -> Prediction

**Critical path**: Target Data + Source Pool -> DTW Selector -> Pooled Training Set -> Forecasting Model -> Prediction. Performance hinges entirely on DTW Selector effectiveness.

**Design tradeoffs**:
- **Subsequence length (m)**: Shorter lengths increase computation and may reduce robustness; longer lengths may contain structural breaks
- **Selection threshold (ε)**: Lower percentile more selective (e.g., 25th) vs. higher percentile risks including dissimilar data (e.g., 75th)
- **Model choice**: XGBoost provides best results but is more complex than HAR model

**Failure signatures**:
- **Negative Transfer**: MTL model worse than Target-Only (TO) model, indicating DTW selector including harmful source data
- **Naive Pooling Outperformance**: NP model beats MTL model, suggesting instance selection too aggressive
- **Early-Stage Collapse**: "1-models" produce wildly inaccurate forecasts, indicating insufficient data for meaningful transfer

**First 3 experiments**:
1. **Ablation on Threshold ε**: Train MTL models with ε at 10th, 25th, 50th, 75th, and 90th percentiles. Measure MSE/MAE against naive forecast
2. **Alternative Similarity Metrics**: Replace DTW with Pearson correlation or Euclidean distance on normalized series. Compare resulting MTL performance
3. **Model-Agnostic Validation**: Apply best-performing MTL pipeline to train different architectures (LSTM, Transformer). Confirm performance gains hold across model types

## Open Questions the Paper Calls Out

**Open Question 1**: Can transfer learning improve forecasting for established assets with extensive historical data?
- Basis: Conclusion states results "motivate an assessment of how complementary source data can be used to improve volatility predictions for target assets that already have an extensive data history"
- Why unresolved: Current study strictly focuses on data-scarce new issues and spin-offs
- What evidence would resolve it: Empirical testing on mature stocks with >5 years of data comparing MTL performance against target-only models

**Open Question 2**: To what degree does extensive hyperparameter optimization improve XGBoost and FNN performance?
- Basis: Authors note future research "may involve an extensive hyperparameter optimization"
- Why unresolved: Fixed hyperparameters to maintain computational feasibility and avoid data splitting issues
- What evidence would resolve it: Comparative study utilizing grid search or Bayesian optimization for tree depth, learning rates, and network architecture

**Open Question 3**: How sensitive is forecast accuracy to subsequence length (m) and use of overlapping vs. non-overlapping subsequences?
- Basis: Authors fix m=22 for computational efficiency but discuss trade-off where small m increases computation and large m risks structural breaks
- Why unresolved: Empirical evaluation only tests fixed m=22 and non-overlapping sequences
- What evidence would resolve it: Robustness checks reporting MSE across range of subsequence lengths (m=5, 10, 22, 44) and overlapping configurations

**Open Question 4**: Do transformer networks outperform XGBoost and HAR models in this instance-based transfer learning setup?
- Basis: Conclusion suggests exploring "application of different forecasting models such as transformer networks"
- Why unresolved: Paper restricted scope to linear HAR models and standard non-linear machine learning models
- What evidence would resolve it: Implementing transformer-based architecture on selected source subsequences and comparing against XGB-EXT benchmarks

## Limitations

- Study focuses exclusively on new issues and spin-offs, limiting generalizability to established assets
- Fixed hyperparameters for complex models (XGBoost, FNN) without extensive optimization
- Computational constraints led to specific design choices (m=22, non-overlapping subsequences) that may not be optimal
- Results may not generalize to assets with fundamentally different volatility dynamics than the source pool

## Confidence

| Claim | Confidence |
|-------|------------|
| Transfer learning improves forecasting for new issues | High |
| DTW-based instance selection outperforms naive pooling | High |
| XGBoost performs best among tested models | High |
| Approach works immediately after first trading day | Medium |
| Results generalize across different asset types | Medium |

## Next Checks

1. **Reproduce baseline results**: Implement the rolling window forecasting framework and verify that target-only models underperform the naive forecast baseline as reported

2. **Validate DTW selection**: Compare performance of models trained on DTW-selected subsequences against models trained on randomly selected subsequences of equal size

3. **Test early-stage forecasting**: Implement the 1-model configuration and verify that transfer learning provides meaningful improvements when only one day of target data is available