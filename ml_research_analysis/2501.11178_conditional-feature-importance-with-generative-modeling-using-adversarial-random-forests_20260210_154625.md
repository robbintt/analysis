---
ver: rpa2
title: Conditional Feature Importance with Generative Modeling Using Adversarial Random
  Forests
arxiv_id: '2501.11178'
source_url: https://arxiv.org/abs/2501.11178
tags:
- feature
- importance
- conditional
- data
- carfi
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces cARFi, a method for measuring conditional
  feature importance in explainable AI using generative modeling with adversarial
  random forests. The key innovation is leveraging ARF's ability to efficiently estimate
  and sample from conditional distributions without intensive tuning or computational
  resources, addressing the challenge of generating on-manifold feature values for
  mixed categorical and continuous tabular data.
---

# Conditional Feature Importance with Generative Modeling Using Adversarial Random Forests

## Quick Facts
- arXiv ID: 2501.11178
- Source URL: https://arxiv.org/abs/2501.11178
- Reference count: 40
- Key outcome: cARFi method for conditional feature importance using ARF generative modeling achieves valid inference with controlled type I error and high power, outperforming related methods in speed while maintaining accuracy

## Executive Summary
This paper introduces cARFi, a novel method for measuring conditional feature importance in explainable AI by leveraging Adversarial Random Forests (ARF) as a generative model. The key innovation is using ARF's ability to efficiently estimate and sample from conditional distributions without intensive tuning or computational resources, addressing the challenge of generating on-manifold feature values for mixed categorical and continuous tabular data. cARFi works by sampling multiple feature values from ARF-estimated conditional distributions and evaluating changes in predictive performance, offering robust importance scores that can flexibly adapt between conditional and marginal notions of importance. Experiments show cARFi achieves valid inference with controlled type I error and high power, performing competitively with related methods like CPI while being computationally faster.

## Method Summary
cARFi measures conditional feature importance by replacing feature values with samples drawn from ARF-estimated conditional distributions and measuring the resulting performance degradation. The method trains an ARF on the feature space to learn joint densities, then samples from conditional distributions $\hat{p}(x_j|X_C)$ to create perturbed datasets where feature $X_j$ is conditionally independent of target $Y$. The importance score is calculated as the average increase in loss when the feature is replaced, aggregated over multiple samples and instances. This approach addresses the correlation leak problem by ensuring perturbations maintain dependencies with conditioning features while breaking the link to the target.

## Key Results
- cARFi achieves valid statistical inference with controlled type I error rates at nominal significance levels
- The method demonstrates high power in detecting true feature importance across various simulation scenarios
- cARFi outperforms knockoff-based methods (CPI) in computational speed while maintaining comparable accuracy
- The method successfully handles mixed categorical and continuous data without requiring separate treatment
- Hyperparameter tuning allows flexible control between conditional and marginal importance notions

## Why This Works (Mechanism)

### Mechanism 1: On-Manifold Generation with ARF
ARF generates on-manifold feature values by iteratively distinguishing real data from synthetic data until features in terminal nodes are mutually independent. The forest structure derives conditional densities $\hat{p}(x_j|X_C)$ via updated leaf weights, allowing sampling that respects existing correlations without retraining for every conditioning set. This avoids the intensive tuning required by deep generative models while maintaining the crucial property that samples stay on the data manifold.

### Mechanism 2: Performance Degradation Isolation
Feature importance is isolated by measuring predictive performance degradation when a feature is replaced by its conditionally sampled counterpart. Because $\tilde{X}_j$ maintains dependency with $X_C$ but is conditionally independent of $Y$, the resulting performance drop $\Delta$ is attributed solely to the unique information lost from $X_j$. Stability is increased by averaging over $R$ samples, ensuring the estimate is not driven by sampling variability.

### Mechanism 3: Statistical Inference Control
cARFi facilitates valid statistical inference by ensuring the importance estimator is asymptotically normally distributed, enabling paired t-tests. The "minimum node size" hyperparameter controls the strictness of conditioning: small nodes enforce strict conditional importance (conservative), while large nodes approximate marginal importance (higher power but risk of Type I error). This tunable trade-off allows users to balance discovery power with error control.

## Foundational Learning

### Concept: Conditional vs. Marginal Feature Importance
- **Why needed here**: cARFi addresses the "correlation leak" problem where marginal methods assign credit to correlated features that don't actually influence the target
- **Quick check**: If feature A is correlated with feature B, and only B causes the outcome, what importance should cARFi assign to A when conditioning on B?

### Concept: The "On-Manifold" Requirement
- **Why needed here**: Off-manifold perturbations create unrealistic data points that can confuse the model, leading to misleading importance scores
- **Quick check**: Why does replacing a feature value with a random constant potentially yield "unfair" feedback about model reliability?

### Concept: Adversarial Random Forests (ARF)
- **Why needed here**: ARFs provide a lighter-weight alternative to GANs/VAEs for tabular data by iteratively refining splits to achieve independence in leaves
- **Quick check**: In an ARF, what does it imply when the discriminator's accuracy drops to 50% (random guessing)?

## Architecture Onboarding

### Component map:
Data Splitter -> Black-box Trainer -> ARF Density Estimator -> Perturbation Module -> Evaluator

### Critical path:
The fitting of the ARF is the sequential bottleneck. While the Black-box model is independent, the ARF must fully converge before any explanation can be generated. Sampling during the explanation phase is fast but scales linearly with the number of features and replicates ($R$).

### Design tradeoffs:
- **Min Node Size (Strictness vs. Power)**: Small values (deep trees) enforce strict conditional logic (reducing Type I error but potentially lowering power); Large values (shallow trees) increase power but risk attributing importance to correlated, non-causal features
- **Replicates ($R$) (Stability vs. Speed)**: Higher $R$ stabilizes the estimate (reduces variance) but linearly increases computation time during the explanation phase

### Failure signatures:
- **Type I Error Inflation**: If tests reject the null (effect size 0) more than 5% of the time, the "min node size" is likely too large (trees too shallow)
- **Conservative Estimates (Low Power)**: If tests fail to detect true effects, the "min node size" may be too small (trees too deep), reducing variance in the generated samples
- **Convergence Failure**: If ARF accuracy never drops to ~50%, the density estimation is flawed, potentially requiring more data or different ARF hyperparameters

### First 3 experiments:
1. **Null Simulation (Type I Error)**: Train on data where $Y$ is independent of $X$. Run cARFi to ensure rejection rate is $\approx \alpha$ (e.g., 0.05)
2. **Node Size Sensitivity Analysis**: Run cARFi on a dataset with known correlation structures while sweeping `min.node.size`
3. **Comparative Efficiency**: Compare wall-clock time of cARFi (with $R=20$) against knockoff-based method (CPI)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does cARFi's robustness change under systematic variations of sample size, data dimensionality, and hyperparameters like minimum node size?
- Basis: The discussion states that robustness "may be further studied" by systematically varying these specific parameters
- Why unresolved: The current study focuses on the general methodological proposition rather than a comprehensive sensitivity analysis across all data regimes
- What evidence would resolve it: A large-scale simulation benchmark analyzing type I error and power across varied dimensionalities and hyperparameter settings

### Open Question 2
- Question: Can cARFi effectively facilitate conditional independence testing within causal structure learning algorithms?
- Basis: The authors suggest that cARFi's testing procedure "may facilitate applying algorithms in causal structure learning"
- Why unresolved: The method was validated for feature importance but has not yet been applied to the specific task of causal discovery
- What evidence would resolve it: Successful integration of cARFi into a causal discovery algorithm (e.g., PC algorithm) to accurately identify graph structures

### Open Question 3
- Question: Can ARF's fast subset conditioning be leveraged to improve the efficiency of Shapley-based methods like SHAP and SAGE?
- Basis: The authors propose "exploiting the fast subset conditioning of ARF" for these specific explainability methods
- Why unresolved: Shapley methods often rely on marginal sampling; the integration of ARF for conditional sampling is proposed but not yet implemented
- What evidence would resolve it: An ARF-enhanced SHAP implementation demonstrating faster computation or better adherence to conditional distributions than existing baselines

## Limitations

- Performance heavily depends on ARF's ability to accurately estimate joint feature distributions, which may fail on complex, high-dimensional data
- The method requires careful hyperparameter tuning (particularly min.node.size) to balance between conditional and marginal importance notions
- Statistical validity claims are based on specific experimental settings and may not generalize to all data regimes

## Confidence

- **High Confidence**: The core algorithmic mechanism is sound and well-justified; computational efficiency claims relative to knockoff-based methods are supported
- **Medium Confidence**: Statistical validity claims are based on specific experiments and require careful hyperparameter calibration per dataset
- **Low Confidence**: Limited discussion on how ARF's internal density estimators affect final importance scores and robustness to feature redundancy

## Next Checks

1. **Generalization Test**: Apply cARFi to a high-dimensional dataset (>50 features) with known causal structure to assess performance beyond tested scenarios
2. **ARF Robustness Check**: Systematically vary ARF hyperparameters (number of trees, split criteria) to determine impact on stability and validity of importance scores
3. **Conditional vs. Marginal Spectrum**: Conduct controlled experiment with datasets exhibiting varying degrees of feature correlation to empirically validate how min.node.size shifts behavior along conditional-to-marginal spectrum