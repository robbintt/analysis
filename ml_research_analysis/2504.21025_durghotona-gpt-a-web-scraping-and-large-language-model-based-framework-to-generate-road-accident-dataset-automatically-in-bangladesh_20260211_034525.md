---
ver: rpa2
title: 'Durghotona GPT: A Web Scraping and Large Language Model Based Framework to
  Generate Road Accident Dataset Automatically in Bangladesh'
arxiv_id: '2504.21025'
source_url: https://arxiv.org/abs/2504.21025
tags:
- data
- accident
- scraping
- authors
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents 'Durghotona GPT', an automated framework integrating
  web scraping and Large Language Models (LLMs) to generate road accident datasets
  from Bangladeshi newspapers. The framework overcomes limitations of manual data
  collection methods by efficiently extracting, categorizing, and compiling detailed
  accident reports from Prothom Alo, Dhaka Tribune, and The Daily Star.
---

# Durghotona GPT: A Web Scraping and Large Language Model Based Framework to Generate Road Accident Dataset Automatically in Bangladesh

## Quick Facts
- arXiv ID: 2504.21025
- Source URL: https://arxiv.org/abs/2504.21025
- Reference count: 26
- One-line primary result: Automated web scraping and LLM pipeline extracts road accident data from Bangladeshi newspapers with 89-91% accuracy

## Executive Summary
This paper presents Durghotona GPT, an automated framework that integrates web scraping with Large Language Models (LLMs) to generate structured road accident datasets from Bangladeshi newspapers. The framework overcomes limitations of manual data collection by efficiently extracting, categorizing, and compiling detailed accident reports from Prothom Alo, Dhaka Tribune, and The Daily Star. Evaluation shows Llama-3 (89% accuracy) performs comparably to GPT-4 (91% accuracy), establishing it as a cost-effective alternative for similar tasks. The authors also developed a user-friendly interface. Future work will focus on expanding data sources and refining LLM capabilities to further improve dataset accuracy and applicability.

## Method Summary
The framework employs a two-stage pipeline combining web scraping and LLM processing. First, Selenium WebDriver automates browser navigation to target newspaper websites, using XPath expressions to locate and extract news titles, links, and publish dates, with the newspaper3k module downloading full article content into a pandas DataFrame. Next, a two-stage LLM chain processes the articles: an initial categorization stage filters reports as "General" (aggregate statistics, opinions) or "Specific" (individual incidents), with only "Specific" reports proceeding to the extraction stage where structured fields (date, time, casualties, location, vehicle types, etc.) are extracted via LangChain prompt templates. The pipeline uses standardized settings (temperature=0.7, max_retries=2, n=1) across GPT-3.5, GPT-4, and Llama-3 models, with accuracy measured against a manually verified gold standard of 195 reports.

## Key Results
- Llama-3-70b achieved 89% extraction accuracy, comparable to GPT-4's 91% accuracy
- Framework successfully extracted structured data from 195 accident reports across three major Bangladeshi newspapers
- User-friendly interface developed for non-technical users to access the generated datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Web scraping from established newspaper sources can provide a continuous, low-latency stream of accident data that supplements traditional sources plagued by delays and gaps.
- Mechanism: Selenium WebDriver automates browser navigation to target newspaper websites; XPath expressions locate and extract news titles, links, and publish dates; the newspaper3k module downloads full article content; results are stored in a pandas DataFrame for downstream processing.
- Core assumption: Online newspaper archives consistently publish accident reports with sufficient detail and that their site structures remain stable enough for XPath-based extraction.
- Evidence anchors: [abstract] "The authors collected accident reports from three major newspapers: Prothom Alo, Dhaka Tribune, and The Daily Star."; [section IV.A] "In this manner, news from three renowned national dailies... are extracted. Thus, this program can effectively collect latest accident news from newspaper without any intensive labor."; [corpus] Weak direct corpus validation; one neighbor paper discusses general web scraping automation but not accident-specific applications.
- Break condition: If target newspapers change their HTML structure frequently, block automated access, or reduce accident reporting coverage, the scraping pipeline will require continuous maintenance or fail.

### Mechanism 2
- Claim: LLMs can reliably extract structured accident information from unstructured news text through a two-stage categorization and extraction pipeline.
- Mechanism: First LLM chain classifies reports as "General" (aggregate statistics, opinions) or "Specific" (individual incidents), filtering out non-incident reports. Second LLM chain extracts structured fields (date, time, location, casualties, vehicle types, pedestrian involvement, road characteristics) from "Specific" reports via LangChain prompt templates.
- Core assumption: News articles contain the target fields with sufficient explicit mention and that LLMs can infer missing values without hallucinating.
- Evidence anchors: [abstract] "The framework efficiently extracts relevant information, categorizes reports, and compiles detailed datasets."; [section IV.B] "These 'Specific' accident reports are also passed through the LLM chain one by one again and the following information are extracted—Accident date, Time, Number of injured, Number of killed, Location, Road characteristics..."; [corpus] Neighbor paper validates the broader approach of LLM-based accident data extraction, though not this specific two-stage architecture.
- Break condition: If news articles use ambiguous language, omit key details, or if LLM temperature/settings cause hallucination, extraction accuracy degrades.

### Mechanism 3
- Claim: Open-source Llama-3 achieves comparable accuracy to proprietary GPT-4 for structured extraction tasks, enabling cost-effective deployment.
- Mechanism: Standardized comparison across GPT-3.5, GPT-4 (via OpenAI API), and Llama-3-70b (via Groq API) with identical temperature (0.7), max_retries (2), and single-response (n=1) settings; accuracy measured against manually verified gold standard from 195 reports.
- Core assumption: The 195-report validation set is representative of broader accident report patterns and that accuracy metrics generalize across time periods and sources.
- Evidence anchors: [abstract] "Evaluation shows Llama-3 (89% accuracy) performs comparably to GPT-4 (91% accuracy)."; [section V, Table II] "1450 correct, 177 wrong" for Llama-3 vs. "1499 correct, 145 wrong" for GPT-4 across extracted fields.; [corpus] No direct corpus validation of this specific Llama-3 vs. GPT-4 comparison for accident extraction; benchmarking remains paper-internal.
- Break condition: If task requirements shift to more nuanced extraction (e.g., causality, contributing factors), the accuracy gap between open and proprietary models may widen.

## Foundational Learning

- Concept: **XPath and HTML DOM Structure**
  - Why needed here: Web scraping requires understanding how to locate elements within HTML documents; XPath provides the query syntax to identify news titles, links, and content containers.
  - Quick check question: Given an HTML snippet `<div class="news-item"><h2><a href="/article/123">Accident Report</a></h2></div>`, what XPath expression would extract the hyperlink URL?

- Concept: **LLM Temperature and Hallucination**
  - Why needed here: Temperature controls output randomness; lower values reduce creativity but increase consistency for structured extraction tasks; hallucination is the failure mode where LLMs generate confident but incorrect information.
  - Quick check question: If an LLM with temperature=0.7 extracts "5 casualties" from an article mentioning "five-vehicle collision" with no casualty count, is this extraction error or hallucination?

- Concept: **LangChain LLM Chains and Prompt Templates**
  - Why needed here: The framework uses LangChain to orchestrate sequential LLM calls (categorization → extraction) with structured prompts; understanding chains is essential for modifying or extending the pipeline.
  - Quick check question: What is the difference between a single LLM call and an LLM chain, and why might a two-stage chain improve extraction accuracy?

## Architecture Onboarding

- Component map: Web Scraper Module (Selenium + newspaper3k) -> LLM Processing Module (LangChain + OpenAI/Groq APIs) -> Validation Layer (Manual gold standard) -> User Interface (GUI wrapper)

- Critical path:
  1. Configure Selenium with target newspaper URLs and XPath selectors
  2. Execute scraping to collect raw article DataFrame
  3. Initialize LLM APIs (OpenAI for GPT-4/GPT-3.5, Groq for Llama-3)
  4. Run Stage 1 chain to filter "Specific" incidents
  5. Run Stage 2 chain to extract structured fields
  6. Export results to Excel; validate against manual inspection

- Design tradeoffs:
  - **Cost vs. Accuracy**: GPT-4 (91%) outperforms Llama-3 (89%) but incurs API costs; Llama-3 via Groq is free but may lag on complex extractions
  - **Speed vs. Reliability**: Higher retry counts and longer timeouts improve robustness but slow processing; current settings (max_retries=2, 5-10 second waits) balance both
  - **Generalization vs. Specificity**: Generic prompts work across newspapers but may miss source-specific phrasing; custom prompts per source could improve accuracy but increase maintenance

- Failure signatures:
  - **"No Such Element Exception"**: XPath selectors outdated due to website structure changes; requires re-inspecting target pages and updating selectors
  - **Low accuracy on 'Accident Date' field**: All LLMs struggle; suggests news articles often omit or ambiguously report dates
  - **High 'General' classification rate**: If too many articles are filtered out, prompt tuning may be needed to distinguish incident reports from commentary

- First 3 experiments:
  1. **Reproduce baseline accuracy**: Run the provided code on 50 new articles from each newspaper; compare GPT-4 and Llama-3 accuracy against manual labeling to validate reported 89-91% range
  2. **Ablate temperature setting**: Test Llama-3 with temperature=0.0, 0.3, 0.7, 1.0 on a fixed validation set; measure impact on extraction consistency and hallucination rate
  3. **Add a third newspaper**: Extend the scraper to a fourth Bangladeshi source; identify XPath changes needed and measure any accuracy degradation from different reporting styles

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can Retrieval Augmented Generation (RAG) or advanced prompt engineering significantly improve the extraction accuracy of the "Accident Date" variable, which currently performs poorly across all tested models?
- Basis in paper: [explicit] The authors note that all LLMs performed unsatisfactorily on the 'Date' variable and suggest that "with additional prompt engineering and RAG... it can be drastically improved."
- Why unresolved: The current study only evaluated base models without implementing these specific architectural enhancements.
- What evidence would resolve it: A comparative evaluation of date extraction accuracy using RAG-enhanced prompts versus the baseline models on the same news corpus.

### Open Question 2
- Question: How effective is the automatically generated dataset when integrated into a complete machine learning pipeline for accident severity prediction or urban planning analysis?
- Basis in paper: [explicit] The conclusion states that "integrating this framework with a machine learning framework to build a complete pipeline can also be a further research topic."
- Why unresolved: The current paper focuses on data generation and extraction validation, but does not test the dataset's utility in downstream predictive modeling tasks.
- What evidence would resolve it: Performance metrics (e.g., F1-score, RMSE) of predictive models trained on the Durghotona GPT dataset compared to those trained on manual datasets.

### Open Question 3
- Question: To what extent do agent-based systems or LLM fine-tuning improve extraction accuracy compared to the base Llama-3 and GPT-4 models currently employed?
- Basis in paper: [explicit] The authors list "agent-based systems" and "LLM finetuning" as specific capabilities to explore in future work to improve dataset accuracy.
- Why unresolved: The study relied on pre-trained models accessed via API without fine-tuning or agentic workflows, leaving the potential performance gains from these methods unknown.
- What evidence would resolve it: Ablation studies measuring extraction accuracy improvements when using fine-tuned local models or multi-step agent frameworks.

## Limitations
- Accuracy for 'Accident Date' extraction remains unsatisfactory across all tested models, suggesting inherent difficulty in date inference from news text
- Reliance on XPath selectors creates brittleness to website structure changes, requiring continuous maintenance
- No external validation or benchmarking against established accident databases limits generalizability claims

## Confidence
- **Medium**: Confidence in core claim (automated LLM extraction can match manual efforts) based on paper-internal validation; accuracy gap (89% vs 91%) between Llama-3 and GPT-4 needs external verification
- **High**: Confidence in web scraping component due to straightforward Selenium+newspaper3k methodology, though acknowledged brittleness to site changes
- **Low**: Confidence in downstream utility claims since the study doesn't test dataset integration with predictive modeling

## Next Checks
1. Run the pipeline on 50 new articles from each source; compare extracted accuracy to manual labels to verify the 89-91% range holds
2. Ablate temperature from 0.0 to 1.0 on a fixed test set; quantify impact on hallucination rate and extraction consistency
3. Add a fourth Bangladeshi newspaper; measure accuracy degradation and identify required XPath or prompt adaptations