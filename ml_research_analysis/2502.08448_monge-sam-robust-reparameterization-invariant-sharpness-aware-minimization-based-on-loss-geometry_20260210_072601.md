---
ver: rpa2
title: 'Monge SAM: Robust Reparameterization-Invariant Sharpness-Aware Minimization
  Based on Loss Geometry'
arxiv_id: '2502.08448'
source_url: https://arxiv.org/abs/2502.08448
tags:
- m-sam
- loss
- perturbation
- metric
- monge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of reparameterization invariance
  in Sharpness-Aware Minimization (SAM), a popular optimization technique for deep
  learning that seeks flat minima for better generalization. The authors propose Monge
  SAM (M-SAM), which uses a Riemannian metric induced by the loss surface geometry
  to make SAM reparameterization-invariant.
---

# Monge SAM: Robust Reparameterization-Invariant Sharpness-Aware Minimization Based on Loss Geometry

## Quick Facts
- **arXiv ID**: 2502.08448
- **Source URL**: https://arxiv.org/abs/2502.08448
- **Reference count**: 40
- **Primary result**: Proposes a reparameterization-invariant SAM variant using Monge metric that achieves ~6% better generalization on CIFAR-10 fine-tuning and 9.5% improvement on cross-modal alignment tasks.

## Executive Summary
This paper addresses the problem of reparameterization invariance in Sharpness-Aware Minimization (SAM), a popular optimization technique for deep learning that seeks flat minima for better generalization. The authors propose Monge SAM (M-SAM), which uses a Riemannian metric induced by the loss surface geometry to make SAM reparameterization-invariant. The key idea is to equip the parameter space with the Monge metric, which naturally captures the local geometry of the loss surface. This leads to a closed-form expression for the adversarial perturbation that is a rescaled version of SAM's perturbation, making M-SAM more conservative.

## Method Summary
M-SAM modifies standard SAM by replacing the Euclidean ball constraint with a Riemannian ball defined by the Monge metric G(θ) = I + ∇ℓ(θ)∇ℓ(θ)ᵀ. This yields a closed-form perturbation δ_M-SAM = (1/√(1 + ||∇ℓ(θ)||²)) · (ρ/||∇ℓ(θ)||) · ∇ℓ(θ), which scales down the perturbation in steep regions of the loss landscape. The method is implemented as a wrapper around standard SAM, computing gradient norms and applying the scaling factor before the inner optimization step. M-SAM is shown to vary between SAM and gradient descent behavior, reducing attraction to suboptimal equilibria like saddle points while maintaining reparameterization invariance.

## Key Results
- Achieves approximately 6% improvement in generalization compared to standard SGD when fine-tuning a pre-trained ResNet-18 on CIFAR-10 for certain perturbation radii
- On a cross-modal alignment task with CLIP models, achieves a 9.5% improvement in representational alignment scores compared to the pre-trained model, outperforming SAM in stability and performance
- Demonstrates improved robustness to hyperparameter selection compared to SAM, particularly in fine-tuning tasks and multi-modal representation alignment

## Why This Works (Mechanism)

### Mechanism 1
M-SAM acts as a conservative variant of SAM by adaptively shrinking the perturbation size in steep regions of the loss landscape. Standard SAM computes a perturbation δ_SAM ∝ ∇ℓ(θ). M-SAM derives its perturbation using the Monge metric G(θ) = I + ∇ℓ(θ)∇ℓ(θ)ᵀ, yielding a closed-form solution where the M-SAM perturbation is a rescaled version: δ_M-SAM = (1/√(1 + ||∇ℓ(θ)||²)) δ_SAM. When the gradient norm is large (steep regions), the scaling factor approaches 0, reducing the perturbation.

### Mechanism 2
M-SAM reduces attraction to suboptimal equilibria (saddle points and maxima) compared to standard SAM. Standard SAM can find saddle points "stable" if the perturbation radius ρ is large relative to local curvature. Because M-SAM implicitly reduces the effective perturbation size (ρ̃_M-SAM ≤ ρ̃_SAM), it fails the stability criteria for saddles more often than SAM, allowing it to escape.

### Mechanism 3
The method achieves reparameterization invariance without requiring probabilistic model assumptions or diagonal approximations. By equipping the parameter space with the Monge metric, the method searches for adversarial perturbations within a Riemannian ball rather than a Euclidean one. This metric depends on the loss surface geometry (intrinsic property) rather than the specific parameter coordinates, making the "sharpness" measure invariant to how the network is parameterized.

## Foundational Learning

### Concept: Sharpness-Aware Minimization (SAM)
- **Why needed here**: This is the base algorithm M-SAM modifies. Understanding that SAM minimizes the "worst-case" loss in a neighborhood is crucial to understanding why the shape of that neighborhood (Euclidean vs. Riemannian) matters.
- **Quick check question**: Why does standard SAM using a Euclidean ball fail to be invariant to weight rescaling?

### Concept: Riemannian Geometry & Metrics
- **Why needed here**: The paper replaces the Euclidean "ruler" with a "Monge metric." You need to grasp that a metric defines how distances and angles are measured locally, and changing the metric changes the "shape" of the optimization landscape.
- **Quick check question**: How does the Monge metric G(θ) = I + ∇ℓ(∇ℓ)ᵀ differ from the Fisher Metric used in other SAM variants?

### Concept: Generalization & Flat Minima
- **Why needed here**: The entire motivation for SAM and M-SAM is the hypothesis that "flat" minima generalize better. M-SAM attempts to define "flatness" more rigorously via loss geometry.
- **Quick check question**: Does M-SAM always converge to a flatter minimum than SAM, or does it prioritize stability?

## Architecture Onboarding

### Component map:
1. Standard Backprop: Computes ∇ℓ(θ) (Standard)
2. Scaling Module: Computes norm ||∇ℓ(θ)|| and scaling factor κ = 1/√(1 + ||∇ℓ(θ)||²)
3. Perturbation Engine: Computes δ = κ · (ρ · (∇ℓ(θ)/||∇ℓ(θ)||))
4. Inner Step: θ_perturbed ← θ + δ
5. Outer Step: Compute gradient at θ_perturbed and update θ

### Critical path:
The calculation of the global gradient norm ||∇ℓ(θ)||₂ before the inner step. In distributed training, this requires an extra synchronization (all-reduce) if the gradient is sharded, or it can be approximated locally per-device.

### Design tradeoffs:
- **Robustness vs. Exploration**: M-SAM is more stable (robust to ρ) but potentially less exploratory than SAM; it may fail to escape a "bad" sharp minimum if the valley is too steep.
- **Simplicity vs. Specificity**: Uses simple gradient info (valid for any loss) rather than Fisher info (requires probabilistic output) or Hessian (too expensive).

### Failure signatures:
- **Stalling**: If the gradient norm is consistently high, the scaling factor ≈ 0, and M-SAM behaves like GD with very small steps, potentially slowing convergence significantly.
- **Divergence**: While more robust, it can still diverge if the base learning rate is too high, similar to standard SAM.

### First 3 experiments:
1. **Sanity Check (Toy 2D)**: Replicate the "Banana" or "Sinc" function experiment. Verify that M-SAM trajectories do not converge to the saddle point at (0,0) while SAM does with high ρ.
2. **Hyperparameter Sensitivity**: Fine-tune a standard model (e.g., ResNet on CIFAR-10) sweeping ρ ∈ [0.01, 0.1]. Plot performance vs. ρ for SAM vs. M-SAM. Expect to see a flatter curve (higher robustness) for M-SAM.
3. **Fine-Tuning Stability**: Fine-tune a pre-trained CLIP model. Monitor alignment scores. Compare M-SAM vs. SAM at a high learning rate (10⁻⁴) to verify M-SAM maintains stability where SAM diverges.

## Open Questions the Paper Calls Out

### Open Question 1
Does averaging the Monge metric over iterations or sampling it from the local neighborhood improve the method's ability to capture the local geometry compared to the current point-wise estimation? The authors explicitly state this as future work, noting that the current instantaneous metric may miss broader structural context.

### Open Question 2
What is the deeper theoretical connection between the Monge metric and the Fisher metric, and can this relationship be exploited to improve sample quality or computational efficiency? The authors identify this as an interesting direction, noting that while both metrics induce geometry in parameter space, the Monge metric is loss-dependent and non-probabilistic, whereas the Fisher metric is probabilistic.

### Open Question 3
How can the conservative nature of M-SAM be modified to better escape valleys of bad global minima without sacrificing its robustness to saddle points? The authors note that M-SAM's conservativeness potentially prevents it from escaping suboptimal valleys for finding globally flatter regions of the parameter space.

## Limitations
- The method relies on a first-order Taylor expansion to approximate adversarial perturbations, which may not capture highly non-linear regions of the loss landscape
- The conservative nature of M-SAM, while providing robustness, potentially prevents it from escaping suboptimal valleys for finding globally flatter regions of the parameter space
- Computational overhead is comparable to SAM but not explicitly quantified for large-scale models

## Confidence
- **High Confidence**: The core mathematical derivation of the Monge metric and its closed-form perturbation solution is sound and internally consistent
- **Medium Confidence**: The empirical claims about robustness to hyperparameter selection are supported by the presented experiments but would benefit from broader validation
- **Low Confidence**: The theoretical claims about reduced attraction to suboptimal equilibria are based on idealized stability analysis that may not fully capture discrete optimization dynamics

## Next Checks
1. **Cross-domain robustness test**: Apply M-SAM to a diverse set of tasks including NLP fine-tuning, object detection, and reinforcement learning to verify the robustness claims generalize beyond vision tasks
2. **Scalability benchmark**: Measure wall-clock training time and memory usage of M-SAM versus SAM on large-scale models (e.g., ViT-L/14, BERT-large) to quantify the practical overhead
3. **Loss landscape visualization**: Generate 2D loss surface plots around converged solutions for both SAM and M-SAM on the same task to empirically verify differences in flatness and sharpness