---
ver: rpa2
title: Multilingual LLMs Struggle to Link Orthography and Semantics in Bilingual Word
  Processing
arxiv_id: '2501.09127'
source_url: https://arxiv.org/abs/2501.09127
tags:
- word
- language
- meaning
- homographs
- english
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates multilingual LLMs' ability to process bilingual
  words, focusing on English-Spanish, English-French, and English-German cognates,
  non-cognates, and interlingual homographs. The research investigates whether models
  can disambiguate meanings and make semantic judgments, both in isolation and within
  sentence contexts.
---

# Multilingual LLMs Struggle to Link Orthography and Semantics in Bilingual Word Processing

## Quick Facts
- arXiv ID: 2501.09127
- Source URL: https://arxiv.org/abs/2501.09127
- Reference count: 40
- Key outcome: Multilingual LLMs struggle with interlingual homographs, performing below random baselines and showing no correlation between isolated and semantic processing performance

## Executive Summary
This study investigates how multilingual large language models (LLMs) process bilingual words, specifically examining English-Spanish, English-French, and English-German language pairs. The research focuses on three types of word relationships: cognates (words with similar form and meaning), non-cognates (words with different forms but related meanings), and interlingual homographs (words with identical form but different meanings across languages). The findings reveal that while LLMs perform well on cognates and non-cognates, they significantly struggle with interlingual homographs, often performing below random baselines. This suggests that current models rely more on orthographic similarities than genuine semantic understanding when processing bilingual words.

## Method Summary
The researchers evaluated multilingual LLMs using carefully constructed test sets containing cognates, non-cognates, and interlingual homographs across three language pairs. They tested model performance in two contexts: word isolation (where words appear without context) and within sentence contexts (both congruent and incongruent). The study employed perplexity-based measures and semantic judgment tasks to assess whether models could correctly disambiguate meanings based on context. Multiple state-of-the-art multilingual models were tested to ensure robustness of findings across different architectures.

## Key Results
- LLMs achieved significantly higher performance on cognates and non-cognates compared to interlingual homographs
- Models performed below random baselines on interlingual homograph disambiguation tasks, indicating systematic failure rather than chance
- No correlation was found between performance in word isolation and semantic understanding, suggesting lack of grounding in word meanings
- Models used different disambiguation strategies for English versus non-English homographs in incongruent sentences

## Why This Works (Mechanism)
The study reveals that current multilingual LLMs lack genuine semantic grounding in bilingual word processing. Instead of understanding the semantic differences between homographs, models appear to rely heavily on orthographic patterns and statistical correlations in their training data. This explains why they perform well on cognates (which share both form and meaning) but fail on interlingual homographs (which share form but differ in meaning). The lack of correlation between isolated word performance and semantic understanding further supports that models are not building robust semantic representations that transfer across contexts.

## Foundational Learning
- Cross-lingual semantic representation: Models need to represent word meanings that transcend individual languages; quick check: test if embeddings of semantically equivalent words across languages cluster together
- Contextual word disambiguation: Ability to resolve word meanings based on surrounding context; quick check: evaluate performance on ambiguous words in controlled sentence contexts
- Orthographic pattern recognition: Models' tendency to rely on surface form similarities rather than semantic content; quick check: compare performance on orthographically similar vs. dissimilar word pairs with same semantic relationship

## Architecture Onboarding
Component map: Input tokens -> Embedding layer -> Transformer blocks -> Attention mechanisms -> Output layer
Critical path: Tokenization → Embedding projection → Multi-head attention → Feed-forward network → Output prediction
Design tradeoffs: Models prioritize learning orthographic patterns (easier to capture statistically) over semantic grounding (requires deeper understanding)
Failure signatures: Below-random performance on semantic disambiguation tasks, performance drop when orthographic cues are absent
First experiments: 1) Test models on interlingual homographs with masked orthography to isolate semantic processing, 2) Compare attention patterns between cognate and homograph processing, 3) Evaluate transfer learning from cognate-rich to homograph-rich tasks

## Open Questions the Paper Calls Out
None specified in the source material.

## Limitations
- Study limited to three language pairs (English-Spanish, English-French, English-German), limiting generalizability to other language combinations
- Evaluation relies on specific test sets for interlingual homographs which may not capture full complexity of real-world bilingual processing
- Lack of comparison with human performance makes it difficult to assess whether LLM struggles are unique or reflect general processing challenges
- Does not explore potential architectural modifications or mitigation strategies for improving homograph processing

## Confidence
High confidence: Models' superior performance on cognates and non-cognates compared to interlingual homographs is well-supported and consistent with orthographic over semantic processing hypothesis.

Medium confidence: Models using different strategies for English versus non-English homographs is supported but needs more detailed analysis of specific strategies employed.

## Next Checks
1. Replicate study with additional language pairs including languages with different writing systems (English-Chinese or English-Arabic) to test generalizability across diverse linguistic contexts.

2. Conduct human subject experiments using same test sets to establish baseline performance and determine whether LLM struggles reflect unique model limitations or general processing challenges.

3. Investigate whether fine-tuning or architectural modifications (incorporating explicit cross-lingual semantic embeddings) can improve models' performance on interlingual homographs and reduce orthographic reliance.