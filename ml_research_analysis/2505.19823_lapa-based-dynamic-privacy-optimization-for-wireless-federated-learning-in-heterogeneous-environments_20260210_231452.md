---
ver: rpa2
title: LAPA-based Dynamic Privacy Optimization for Wireless Federated Learning in
  Heterogeneous Environments
arxiv_id: '2505.19823'
source_url: https://arxiv.org/abs/2505.19823
tags:
- noise
- privacy
- data
- aggregation
- communication
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a Lightweight Adaptive Privacy Allocation (LAPA)
  strategy for wireless federated learning (FL) in heterogeneous environments. The
  core challenge is to protect privacy against gradient leakage attacks while maintaining
  FL performance, especially under non-independent and identically distributed (Non-IID)
  data conditions.
---

# LAPA-based Dynamic Privacy Optimization for Wireless Federated Learning in Heterogeneous Environments

## Quick Facts
- **arXiv ID**: 2505.19823
- **Source URL**: https://arxiv.org/abs/2505.19823
- **Reference count**: 37
- **Primary result**: LAPA-based dynamic noise control improves FL convergence under Non-IID conditions while maintaining DP privacy through gradient-based privacy budget allocation and artificial-to-environmental noise switching.

## Executive Summary
This paper addresses the challenge of protecting privacy in wireless federated learning while maintaining performance under Non-IID data conditions. The proposed Lightweight Adaptive Privacy Allocation (LAPA) strategy assigns personalized privacy budgets to devices based on their local gradient contributions, avoiding additional communication overhead. A dynamic noise control mechanism switches from artificial to environmental noise when optimal, using DDPG to optimize transmission power. The approach integrates communication quality and data heterogeneity through Wasserstein distance-based aggregation weights and SINR-based device selection, demonstrating improved convergence performance while satisfying differential privacy requirements.

## Method Summary
LAPA implements personalized privacy budget allocation based on gradient angle alignment with global gradients, dynamically switches from artificial to environmental noise using DDPG-optimized transmission power, and employs Wasserstein distance-based aggregation weights with SINR-based device selection. The system operates by first computing local gradients at devices, adding LAPA-determined Gaussian noise, and transmitting at optimized power levels. The base station receives noisy gradients, computes SINR and Wasserstein distances, applies device selection, and aggregates using weighted contributions. The DDPG agent continuously updates the power allocation policy to minimize convergence bounds while maintaining privacy guarantees.

## Key Results
- LAPA improves convergence performance under Non-IID conditions compared to uniform DP noise allocation
- Dynamic switching from artificial to environmental noise maintains privacy while reducing noise overhead
- Wasserstein distance-based aggregation with SINR gating outperforms angle-based and FedAvg baselines by 0.397-0.800% accuracy
- The system satisfies DP privacy requirements while improving model utility in heterogeneous wireless environments

## Why This Works (Mechanism)

### Mechanism 1: Gradient-Contribution-Based Privacy Budget Allocation
LAPA assigns personalized privacy budgets based on the angle ϑ_k between each device's local gradient and the global gradient. Devices with smaller angles (closer alignment) receive tighter privacy budgets (less noise) as they contribute more to global updates. This mechanism assumes risk of privacy leakage decreases exponentially as training progresses, and gradient angle captures data heterogeneity contribution. The privacy budget per round is allocated proportionally via ϵ_k ∝ f(ϑ_k), where f is a monotonically non-decreasing mapping.

### Mechanism 2: Artificial-to-Environmental Noise Switching
The system adds artificial Gaussian noise via LAPA until round Tth, when the required noise level drops to match the inherent communication noise σ_n0 / (p_k ||h_k||). DDPG optimizes transmission power p_k to find the optimal switching point, enabling environmental noise to substitute for artificial DP noise once training progress reduces the required noise level. This mechanism assumes channel noise is sufficiently random and unpredictable to serve as a DP noise source, and transmission power can be controlled precisely enough to align artificial and environmental noise levels.

### Mechanism 3: Wasserstein-Distance-Based Aggregation Weighting with SINR Gating
LAPA uses Wasserstein distance W_k(pmf_k, pmf_G) between local and global label distributions to weight aggregation, combined with SINR-based device selection. Aggregation weights are assigned inversely via Softmax: G_k ∝ |D_k| · e^(1/W_k). Devices with SINR below threshold γ_th are excluded. This mechanism assumes label distribution divergence is a stable proxy for gradient divergence, and SINR thresholding removes devices whose transmissions would introduce excessive error.

## Foundational Learning

- **Differential Privacy (ε, δ-DP, sensitivity, Gaussian mechanism)**: Understanding how noise variance σ² relates to privacy budget ε, failure probability δ, and sensitivity Δs is essential for implementing LAPA's noise allocation. Quick check: Given a fixed sensitivity Δs and noise scale σ, does increasing ε strengthen or weaken privacy?

- **Federated Learning under Non-IID Data**: The motivation for personalized privacy budgets stems from understanding how gradient divergence and local dissimilarity affect convergence. Quick check: Why does FedAvg weight by dataset size |D_k| fail under severe Non-IID conditions?

- **Wireless Channel Model (SNR/SINR, AWGN, power constraints)**: The noise-switching mechanism relies on channel noise σ_n0 and received SINR, requiring understanding of how transmission power p_k affects the ratio of artificial to environmental noise. Quick check: How does reducing transmission power p_k affect the ratio of artificial to environmental noise in the received signal?

## Architecture Onboarding

- **Component map**: BS maintains global gradient history -> Devices compute local gradients and add LAPA noise -> Devices transmit at DDPG-optimized power -> BS receives noisy gradients and computes SINR -> BS applies device selection and Wasserstein-based aggregation -> BS updates global model -> DDPG updates power policy

- **Critical path**: 1) BS broadcasts global model w[t] 2) Devices compute local gradients, clip, add LAPA-determined noise 3) Devices transmit noisy gradients at power p_k (from DDPG policy) 4) BS receives noisy gradients + channel noise, computes SINR, applies device selection 5) BS aggregates using Wasserstein-based weights G_k, updates global model 6) DDPG updates power policy based on convergence bound and reward

- **Design tradeoffs**: Higher SINR threshold reduces devices but improves gradient quality; lower threshold increases participation but adds noise. Higher transmission power reduces channel noise contribution but requires more artificial DP noise. Lower transmission power enables environmental noise to meet DP requirements but may harm convergence.

- **Failure signatures**: Model divergence with error bound A ≥ 1 indicates learning rate too high or heterogeneity too extreme. Persistent high artificial noise after many rounds suggests Tth not reached or DDPG stuck in suboptimal policy. Aggregation instability with fluctuating Wasserstein weights indicates smoothing issues. Privacy breach occurs when accumulated ε exceeds budget ε_T.

- **First 3 experiments**: 1) Validate LAPA on MNIST with IID vs. Non-IID partitions against uniform DP and ARB baselines 2) Disable dynamic switching (force artificial noise all rounds) and compare against full LAPA with DDPG-optimized Tth 3) Replace Wasserstein weights with FedAvg or angle-based weights while keeping other components fixed

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does imperfect Channel State Information (CSI) estimation at the BS impact the DDPG agent's ability to accurately determine the optimal noise-switching time $T_{th}$?
- Basis in paper: The paper assumes perfect channel state information is available at both the BS and the devices.
- Why unresolved: Real-world wireless environments inevitably introduce estimation errors, which could disrupt the calculated balance between artificial noise and environmental noise required for the dynamic control mechanism.
- What evidence would resolve it: Simulation results analyzing the convergence bound and privacy leakage under varying degrees of CSI estimation error.

### Open Question 2
- Question: How does the LAPA strategy perform in time-varying fast-fading channels where the assumption of constant channel coefficients per round is violated?
- Basis in paper: The system model assumes a "block fading channel model, where the channel coefficients remain constant throughout the training process."
- Why unresolved: Rapid channel fluctuations would cause the environmental noise to vary within a single aggregation round, potentially invalidating the static power allocation decisions made by the DDPG.
- What evidence would resolve it: Convergence analysis and experimental validation in a simulator that models fast-fading channels rather than block-fading.

### Open Question 3
- Question: Can the Wasserstein distance-based aggregation weights be adapted to maintain robustness against malicious Byzantine attacks where clients actively poison gradients?
- Basis in paper: The threat model assumes participants are "honest-but-curious," meaning they follow protocols but attempt to infer data.
- Why unresolved: The current weighting strategy prioritizes contribution and SNR but does not account for adversarial clients manipulating gradients to skew the global model, which could bypass the privacy-focused noise allocation.
- What evidence would resolve it: Integration of robust aggregation rules (e.g., Krum or trimmed mean) into the LAPA framework and testing against gradient poisoning attacks.

## Limitations

- Strong assumptions about perfect CSI and block-fading channels may not hold in real wireless environments
- Gradient angle mechanism may fail under extreme Non-IID conditions where local gradients become orthogonal to global gradients
- Wasserstein-based aggregation assumes label distributions adequately represent gradient behavior, which may fail with feature-level heterogeneity
- System assumes honest-but-curious devices that apply noise correctly and report gradients honestly

## Confidence

- **High confidence**: Mathematical framework for differential privacy composition and basic DDPG optimization structure are well-established. Claim that personalized privacy budgets improve convergence under Non-IID conditions is supported by simulation results.
- **Medium confidence**: Gradient angle mechanism for per-device privacy allocation is novel but lacks extensive validation across diverse data distributions. Noise-switching strategy's optimality is shown in simulation but not proven analytically.
- **Low confidence**: Claim that Wasserstein distance-based aggregation significantly outperforms existing methods is based on limited experiments. Interaction between all three mechanisms is not fully characterized.

## Next Checks

1. **Robustness to extreme Non-IID**: Test LAPA on highly skewed label distributions (e.g., power-law class imbalance) and compare convergence against baselines. Measure whether the gradient angle mechanism fails when local gradients become uninformative.

2. **Channel dynamics impact**: Simulate time-varying channel conditions and measure how often the DDPG policy fails to maintain the artificial-to-environmental noise alignment. Test sensitivity to power control errors and noise estimation inaccuracies.

3. **Aggregation weight sensitivity**: Vary the SINR threshold γ_th across orders of magnitude and measure the tradeoff between device participation and aggregation stability. Test whether the Wasserstein weighting degrades when label distributions become too similar across devices.