---
ver: rpa2
title: 'Deep Learning for School Dropout Detection: A Comparison of Tabular and Graph-Based
  Models for Predicting At-Risk Students'
arxiv_id: '2508.14057'
source_url: https://arxiv.org/abs/2508.14057
tags:
- graph
- tabular
- dropout
- data
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigated whether transforming tabular student data
  into graph structures via clustering could improve dropout prediction accuracy.
  We compared Graph Neural Networks (GNNs), including a custom Graph Convolutional
  Network (GCN) and GraphSAGE, against traditional tabular models (Random Forest,
  XGBoost, TabNet) using a real-world student dataset.
---

# Deep Learning for School Dropout Detection: A Comparison of Tabular and Graph-Based Models for Predicting At-Risk Students

## Quick Facts
- arXiv ID: 2508.14057
- Source URL: https://arxiv.org/abs/2508.14057
- Reference count: 32
- GraphSAGE on UMAP+HDBSCAN achieved macro F1 76.58% and accuracy 77.56%, outperforming XGBoost by 1.3-1.5 percentage points

## Executive Summary
This study investigated whether transforming tabular student data into graph structures via clustering could improve dropout prediction accuracy. We compared Graph Neural Networks (GNNs), including a custom Graph Convolutional Network (GCN) and GraphSAGE, against traditional tabular models (Random Forest, XGBoost, TabNet) using a real-world student dataset. Graphs were constructed using clustering algorithms (K-Means, HDBSCAN) combined with dimensionality reduction techniques (PCA, UMAP). The GraphSAGE model on a graph derived from UMAP followed by HDBSCAN clustering achieved the best performance, with a macro F1-score of 76.58% and accuracy of 77.56%, outperforming the strongest tabular baseline (XGBoost: macro F1 75.30%, accuracy 76.05%) by approximately 1.3 and 1.5 percentage points, respectively. However, performance gains were not consistent across all graph construction strategies, highlighting the critical role of graph generation and GNN architecture selection. This suggests GNNs have potential for tabular educational data but require careful design of graph representations.

## Method Summary
The study employed a comparative experimental design to evaluate whether Graph Neural Networks (GNNs) could outperform traditional tabular models for predicting student dropout risk. Five distinct approaches were tested: Random Forest, XGBoost, TabNet, Graph Convolutional Network (GCN), and GraphSAGE. Student data was transformed into graph structures using two clustering algorithms (K-Means and HDBSCAN) applied to either PCA or UMAP reduced embeddings. The resulting graphs were fed into the GNN models. Performance was evaluated using accuracy, precision, recall, F1-score, and AUC metrics on a held-out test set. Each model was trained and evaluated using a stratified split to ensure class balance.

## Key Results
- GraphSAGE on UMAP+HDBSCAN achieved the highest performance with macro F1 76.58% and accuracy 77.56%
- This outperformed the strongest tabular baseline (XGBoost: macro F1 75.30%, accuracy 76.05%) by 1.3-1.5 percentage points
- Performance gains were inconsistent across different graph construction strategies, indicating graph generation method critically impacts results

## Why This Works (Mechanism)
Assumption: GraphSAGE outperformed other approaches because it uses neighborhood sampling, which allows it to capture local structural patterns in student data without the computational overhead of full-batch methods. The UMAP+HDBSCAN combination likely created graphs with meaningful structural relationships between students that traditional tabular models cannot capture, as UMAP preserves non-linear manifold structures while HDBSCAN identifies clusters of varying densities. This combination may have revealed latent groupings in student behavior or characteristics that correlate with dropout risk.

## Foundational Learning
- **Graph Neural Networks**: Deep learning models designed to operate on graph-structured data, enabling learning of node representations through message passing between connected nodes. Why needed: Traditional neural networks cannot directly process graph-structured data. Quick check: Understand how GNNs aggregate information from neighboring nodes.
- **GraphSAGE**: A GNN architecture that learns node embeddings by sampling and aggregating features from a node's local neighborhood. Why needed: Enables scalable representation learning on large graphs by sampling rather than using full neighborhoods. Quick check: Know the difference between GraphSAGE and vanilla GCN.
- **Graph Convolutional Networks (GCN)**: A GNN architecture that applies convolutional operations on graphs using spectral graph theory. Why needed: Provides a principled way to define convolutional filters on non-Euclidean graph data. Quick check: Understand the difference between spectral and spatial GCN approaches.
- **Dimensionality Reduction (PCA, UMAP)**: Techniques to reduce high-dimensional feature spaces to lower dimensions while preserving important structure. Why needed: Essential for visualization and as preprocessing for clustering algorithms. Quick check: Know when to use PCA vs UMAP based on data characteristics.
- **HDBSCAN Clustering**: Density-based hierarchical clustering algorithm that can find clusters of varying densities. Why needed: Can identify meaningful groupings in student data without requiring pre-specified cluster counts. Quick check: Understand how HDBSCAN differs from K-Means in handling cluster shape and density.

## Architecture Onboarding

**Component Map**: Student features -> Dimensionality reduction (PCA/UMAP) -> Clustering (K-Means/HDBSCAN) -> Graph construction -> GNN (GraphSAGE/GCN) -> Dropout prediction

**Critical Path**: Feature preprocessing -> Dimensionality reduction -> Clustering -> Graph construction -> GNN training -> Evaluation

**Design Tradeoffs**: 
- PCA offers linear reduction and faster computation but may miss non-linear relationships
- UMAP preserves more complex manifold structure but is computationally heavier
- K-Means is deterministic and faster but requires pre-specifying cluster count
- HDBSCAN finds clusters of varying densities without requiring cluster count but is slower and stochastic
- GraphSAGE scales better to larger graphs through neighborhood sampling compared to full-batch GCN

**Failure Signatures**:
- Poor clustering quality leading to disconnected or poorly structured graphs
- Over-smoothing in GNNs where node representations become too similar
- Insufficient graph density preventing effective message passing
- High computational cost of graph construction and GNN training

**First Experiments**:
1. Compare PCA vs UMAP reduction quality using silhouette scores on clustering results
2. Test different neighborhood sampling rates in GraphSAGE to balance computational cost and representation quality
3. Evaluate graph connectivity metrics (average path length, clustering coefficient) to ensure meaningful graph structure

## Open Questions the Paper Calls Out
Unknown: The paper does not explicitly identify open questions, but implicit questions remain about the scalability of these approaches to larger institutions, the interpretability of graph-based predictions compared to tabular models, and whether the performance gains justify the added complexity in practical educational settings.

## Limitations
- The dataset used was not described in detail, making it difficult to assess generalizability across different educational contexts
- Performance gains over tabular baselines were relatively modest (approximately 1-1.5 percentage points), raising questions about whether added complexity is justified
- The study did not thoroughly explore why performance varied across different graph construction strategies

## Confidence
- **High**: Graph generation and GNN architecture selection are critical for performance
- **Medium**: GNNs can improve dropout prediction, but with small margins that may not justify complexity
- **Medium**: Findings may not generalize well due to lack of dataset details and modest performance gains

## Next Checks
1. Replicate the study using multiple datasets from different educational institutions and countries to assess generalizability
2. Conduct ablation studies to isolate the contribution of graph structure versus GNN architecture to performance improvements
3. Test whether simpler ensemble methods combining tabular and graph features can achieve comparable or better results than pure GNN approaches