---
ver: rpa2
title: 'Clustering Discourses: Racial Biases in Short Stories about Women Generated
  by Large Language Models'
arxiv_id: '2509.02834'
source_url: https://arxiv.org/abs/2509.02834
tags:
- stories
- women
- black
- white
- about
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study combines computational clustering with qualitative discourse
  analysis to examine racial and gender biases in Portuguese short stories generated
  by LLaMA 3.2-3B. The researchers used feature embeddings to cluster 2,100 stories
  and manually analyzed 18 representative texts.
---

# Clustering Discourses: Racial Biases in Short Stories about Women Generated by Large Language Models

## Quick Facts
- **arXiv ID**: 2509.02834
- **Source URL**: https://arxiv.org/abs/2509.02834
- **Reference count**: 3
- **Primary result**: Computational clustering combined with qualitative discourse analysis reveals racialized narrative patterns in Portuguese short stories generated by LLMs

## Executive Summary
This study investigates racial and gender biases in Portuguese short stories generated by LLaMA 3.2-3B through a hybrid computational-qualitative approach. The researchers generated 2,100 stories about Black and white women using controlled prompts, then clustered them using BGE M3 embeddings and DBSCAN. SVM classifiers achieved up to 100% accuracy in predicting character race from story content, while qualitative analysis of 18 representative stories revealed three distinct narrative patterns: overcoming social barriers, ancestral mythification, and subjective self-realization. The findings demonstrate how LLM outputs can perpetuate essentialized racial representations.

## Method Summary
The methodology combines computational clustering with qualitative discourse analysis. Researchers generated 2,100 short stories using LLaMA 3.2-3B-Instruct with two prompt templates (with and without character names) in Portuguese. Stories were encoded using BGE M3 embeddings (1024 dimensions), then validated through SVM classification across multiple kernels and parameters. DBSCAN clustering was optimized using Variance Ratio Criterion, yielding three interpretable clusters. UMAP visualization facilitated manual selection of 18 representative stories (3 per cluster at minimum and maximum intra-cluster distances) for qualitative analysis.

## Key Results
- SVM classifiers predicted character race with up to 100% accuracy, averaging 94.89% ± 4.31%
- DBSCAN clustering produced three interpretable clusters with VRC=114.41
- Black women were predominantly portrayed as strong, resilient figures facing adversity
- White women were more often depicted in introspective, self-discovery narratives
- Three narrative patterns emerged: overcoming social barriers, ancestral mythification, and subjective self-realization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Text embeddings encode sufficient semantic signal to distinguish narratives by protagonist race with high accuracy
- Mechanism: BGE M3 embeddings capture lexical, thematic, and discursive patterns (e.g., "resistência", "comunidade" vs. "descoberta", "jornada") that correlate with racialized narrative structures. SVM classifiers leverage these high-dimensional separations
- Core assumption: Embeddings faithfully represent narrative content; classifier accuracy implies meaningful semantic differences rather than spurious correlations
- Evidence anchors:
  - [abstract]: "SVM classifiers predicted character race with up to 100% accuracy"
  - [section 4.1]: "The classifiers averaged 94.89 ± 4.31%, with the Gaussian kernel SVM peaking 100% accuracy"
  - [corpus]: Limited direct corpus evidence for BGE M3's transferability to Portuguese discourse; relies on paper's validation
- Break condition: If embeddings fail to capture Portuguese-specific discursive patterns, or if classifier overfits to name tokens rather than narrative content, cluster interpretability degrades

### Mechanism 2
- Claim: Unsupervised clustering isolates coherent narrative archetypes that align with racialized discourse patterns
- Mechanism: DBSCAN groups semantically similar stories; VRC optimization yields three clusters plus outliers. The racial composition of clusters (98–100% homogeneous) indicates that narrative patterns differ systematically by race
- Core assumption: Semantic similarity in embedding space corresponds to meaningful discursive/ideological patterns accessible to qualitative interpretation
- Evidence anchors:
  - [abstract]: "DBSCAN yielded three interpretable clusters"
  - [section 4.2]: "The resulting VRC for DBSCAN was 114.41, leading to three main clusters"
  - [section 5]: "Each cluster was associated with a distinct narrative pattern: overcoming social barriers, ancestral mythification, and subjective self-realization"

## Foundational Learning

### Text Embeddings (BGE M3)
- Why needed: Convert stories into high-dimensional vectors that capture semantic meaning for clustering and classification
- Quick check: Verify embeddings produce 1024-dimensional vectors and maintain multilingual capabilities for Portuguese

### Variance Ratio Criterion (VRC)
- Why needed: Quantify cluster quality by measuring separation between clusters relative to within-cluster variance
- Quick check: Higher VRC values indicate better-separated clusters; VRC=114.41 suggests strong separation

### DBSCAN Clustering
- Why needed: Identify dense regions of semantically similar stories while handling outliers
- Quick check: Verify three main clusters plus outliers are produced; adjust eps/min_samples if clustering fails

## Architecture Onboarding

### Component Map
Story Generation -> BGE M3 Embedding -> SVM Validation -> DBSCAN Clustering -> UMAP Visualization -> Manual Story Selection -> Qualitative Analysis

### Critical Path
BGE M3 Embedding -> SVM Validation -> DBSCAN Clustering (VRC optimization determines final cluster structure)

### Design Tradeoffs
- Embedding choice: BGE M3 (multilingual, 1024-dim) vs. alternatives (tradeoff between semantic richness and computational cost)
- Clustering method: DBSCAN (handles noise/outliers) vs. K-means (requires pre-specifying K)
- Qualitative sample size: 18 stories (comprehensive coverage vs. analysis depth)

### Failure Signatures
- Low SVM accuracy (<70%): Embeddings fail to capture racial signal; check prompt formulation and embedding model
- DBSCAN produces all noise: Insufficient density in embedding space; check embedding quality or adjust DBSCAN parameters
- VRC much lower than 114.41: Poor cluster separation; verify data quality and preprocessing

### First 3 Experiments
1. Generate 10 stories per prompt template and verify embedding dimensions
2. Train SVM on 100 stories to validate racial signal detection
3. Run DBSCAN on 500 stories to test clustering parameters before full-scale analysis

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do the racialized narrative patterns identified in Portuguese persist when generating stories in English?
- Basis in paper: [explicit] The authors state, "As future work, we propose a comparative analysis between stories generated in English and Portuguese."
- Why unresolved: The current study was restricted to a corpus of 2,100 texts generated exclusively in Portuguese
- What evidence would resolve it: A replication of the clustering and qualitative analysis pipeline on an English-language corpus generated with equivalent prompts

### Open Question 2
- Question: To what extent do character names independently activate nationality-based biases in narrative construction?
- Basis in paper: [explicit] The authors propose "a deeper investigation into the influence of character names — particularly about activating a third type of bias: nationality."
- Why unresolved: While names were controlled to isolate racial bias, their specific influence as markers of nationality was not analyzed in this dataset
- What evidence would resolve it: An ablation study varying names by national origin while keeping racial descriptors constant to observe shifts in narrative themes

### Open Question 3
- Question: Are the three distinct narrative clusters (social overcoming, ancestral mythification, and subjective self-realization) consistent across different LLM architectures?
- Basis in paper: [inferred] The study relies exclusively on LLaMA 3.2-3B, leaving open the question of whether these specific discursive patterns are artifacts of this specific model or systemic to LLMs
- Why unresolved: Different training data and alignment techniques in other models (e.g., GPT, Claude) might produce different narrative segregations or levels of bias
- What evidence would resolve it: Applying the same SVM classification and DBSCAN clustering methodology to outputs from other state-of-the-art language models

## Limitations

- Unspecified DBSCAN and UMAP hyperparameters limit reproducibility of clustering results
- Analysis based on only 18 manually selected stories may not capture full narrative diversity
- Reliance on single LLM model (LLaMA 3.2-3B) without cross-model validation

## Confidence

- **High Confidence**: The computational methodology (embedding, clustering, SVM validation) is well-specified and reproducible given the provided parameters. The 94.89% ± 4.31% SVM accuracy strongly supports the claim that embeddings capture meaningful semantic differences between stories about different racial groups
- **Medium Confidence**: The qualitative discourse analysis findings are internally consistent but based on a small sample size (18 stories). The observed patterns of resilience vs. introspection align with broader research on racial representation but require validation with larger samples
- **Low Confidence**: Claims about specific narrative archetypes (overcoming barriers, ancestral mythification, self-realization) are based on limited manual analysis and may not fully represent the diversity of generated stories

## Next Checks

1. **Hyperparameter Sensitivity Analysis**: Systematically vary DBSCAN (eps, min_samples) and UMAP (n_neighbors, min_dist) parameters to assess stability of the three-cluster solution and qualitative patterns
2. **Cross-Model Validation**: Replicate the full pipeline with different LLMs (e.g., GPT-4, Mistral) to determine whether observed racial bias patterns are model-specific or generalizable across architectures
3. **Expanded Qualitative Sampling**: Conduct manual analysis of 50+ stories across clusters to validate whether the three discourse patterns hold and to identify additional narrative variations not captured in the initial sample