---
ver: rpa2
title: 'BOLT-GAN: Bayes-Optimal Loss for Stable GAN Training'
arxiv_id: '2510.25609'
source_url: https://arxiv.org/abs/2510.25609
tags:
- bolt
- lipschitz
- bayes
- training
- discriminator
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: BOLT-GAN introduces a Bayes-error-motivated objective for stable
  GAN training. It trains a bounded 1-Lipschitz discriminator using the BOLT loss,
  which implicitly minimizes an integral probability metric (IPM) bounded by the Wasserstein-1
  distance.
---

# BOLT-GAN: Bayes-Optimal Loss for Stable GAN Training

## Quick Facts
- arXiv ID: 2510.25609
- Source URL: https://arxiv.org/abs/2510.25609
- Reference count: 40
- Primary result: 10-60% lower FID than WGAN on CIFAR-10, CelebA-64, LSUN datasets

## Executive Summary
BOLT-GAN introduces a Bayes-error-motivated objective for stable GAN training by framing the problem as minimizing the Bayes error rate of a discrimination task. The approach trains a bounded 1-Lipschitz discriminator using a novel BOLT loss that implicitly minimizes an integral probability metric bounded by Wasserstein-1 distance. By having the generator adversarially maximize the Bayes error rate, the framework achieves better convergence to the true data distribution. Empirical evaluations demonstrate consistent superiority over WGAN, with 10-60% lower Fréchet Inception Distance (FID) and improved precision and recall metrics, indicating enhanced sample quality and mode coverage.

## Method Summary
BOLT-GAN employs a novel training objective based on the Maximum Bayes Error Rate (Max-BER) principle. The BOLT loss $L_{BG}^{(\pi)}(g,h) = \pi \mathbb{E}_{x \sim P_{data}}[h(x)] - (1-\pi)\mathbb{E}_{z \sim P_z}[h(g(z))]$ with prior $\pi=0.5$ is maximized by a 1-Lipschitz discriminator while the generator minimizes the negative fake-term. The discriminator uses residual DCGAN architecture with LeakyReLU activations and no BatchNorm, while the generator uses BatchNorm+ReLU. Gradient Penalty with $\lambda_{GP}=10$ is applied to raw critic outputs, and training follows a 5:1 critic-to-generator update ratio using Adam optimizer. The framework is evaluated on CIFAR-10, CelebA-64, LSUN Bedroom-64, and LSUN Church-64 datasets with standard preprocessing.

## Key Results
- 10-60% lower Fréchet Inception Distance (FID) compared to WGAN baseline
- Improved precision and recall metrics indicating better sample quality and mode coverage
- Consistent performance improvements across multiple benchmark datasets
- Stable training convergence to true data distribution

## Why This Works (Mechanism)
BOLT-GAN's stability stems from its connection to Bayes-optimal classification and the bounded nature of its discriminator. By framing GAN training as a min-max Bayes error criterion, the framework avoids the instability associated with unbounded discriminator outputs in WGAN. The sigmoid-bounded critic with gradient penalty creates a well-behaved optimization landscape where the generator is incentivized to produce samples that maximize the classifier's Bayes error rate, leading to better coverage of the data distribution modes.

## Foundational Learning
- **Integral Probability Metrics (IPM)**: A class of divergences between probability measures defined by the maximum difference in expectations of functions from a specified class. Needed to understand BOLT-GAN's theoretical foundation; quick check: verify the IPM bound to Wasserstein-1 distance.
- **1-Lipschitz constraint**: Ensures the discriminator's output changes smoothly with input, preventing gradient explosion. Critical for stable training; quick check: monitor gradient norms during training.
- **Bayes error rate**: The minimum achievable classification error for a given data distribution. Forms the theoretical basis for BOLT-GAN's objective; quick check: confirm sigmoid-bounded outputs.

## Architecture Onboarding
- **Component map**: Generator (ResNet blocks, BatchNorm+ReLU) -> Critic (ResNet blocks, LeakyReLU, no BatchNorm) -> Gradient Penalty on raw outputs
- **Critical path**: Data preprocessing → BOLT loss computation → 1-Lipschitz enforcement → Adversarial optimization
- **Design tradeoffs**: Bounded discriminator vs. unbounded WGAN critic; residual architecture vs. standard DCGAN
- **Failure signatures**: Training instability without gradient penalty; vanishing gradients when penalty applied to sigmoid output
- **First experiments**: 1) Verify 5:1 critic-to-generator update ratio, 2) Test both 64-D and 128-D latent dimensions, 3) Compare GP on raw vs. sigmoid outputs

## Open Questions the Paper Calls Out
The paper identifies several directions for future research, including understanding how alternative discriminator constraints like spectral normalization impact the convergence behavior of the Max-BER approach compared to gradient penalty. Additionally, the theoretical guarantees regarding whether the global minimum of the BOLT-GAN objective strictly implies $P_{data} = P_g$ remain open, as does the question of whether the framework can maintain stable training and competitive FID scores when applied to high-resolution image generation using modern architectures like StyleGAN.

## Limitations
- Exact architectural details (filter counts, channel multipliers) are unspecified
- Latent dimension discrepancy between main text (128-D) and appendix (64-D)
- Limited to standard benchmarks without testing on high-resolution images
- No comparison with other modern GAN variants beyond WGAN

## Confidence
- **High confidence**: Theoretical framework linking Bayes error to GAN training is sound
- **Medium confidence**: 10-60% FID improvement likely real but exact replication requires resolving latent dimension ambiguity
- **Low confidence**: Specific architectural choices may be crucial but are underspecified

## Next Checks
1. Run ablation studies comparing BOLT-GAN with $\lambda_{GP}=10$ versus $\lambda_{GP}=0$ to verify gradient penalty's critical role
2. Test both latent dimensions (64 vs 128) to identify which produces results matching reported FIDs
3. Validate critic's Lipschitz constraint by monitoring gradient norms throughout training