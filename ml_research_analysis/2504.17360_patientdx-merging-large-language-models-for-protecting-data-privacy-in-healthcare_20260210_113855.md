---
ver: rpa2
title: 'PatientDx: Merging Large Language Models for Protecting Data-Privacy in Healthcare'
arxiv_id: '2504.17360'
source_url: https://arxiv.org/abs/2504.17360
tags:
- data
- patientdx
- llms
- merging
- patient
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents PatientDx, a model merging framework for designing
  effective large language models (LLMs) for healthcare tasks without requiring fine-tuning
  on private patient data. The approach leverages recent model merging techniques,
  using a math-focused LLM as a pivotal model and optimizing hyperparameters without
  training on sensitive data.
---

# PatientDx: Merging Large Language Models for Protecting Data-Privacy in Healthcare

## Quick Facts
- **arXiv ID**: 2504.17360
- **Source URL**: https://arxiv.org/abs/2504.17360
- **Reference count**: 17
- **Primary result**: Improves AUROC by up to 7% on MIMIC-IV mortality prediction without fine-tuning on private patient data

## Executive Summary
PatientDx presents a model merging framework that combines pre-trained large language models to create effective healthcare prediction systems without requiring fine-tuning on sensitive patient data. The approach uses weight interpolation techniques (Model Soup or SLerp) to merge models, with a math-specialized LLM serving as a pivotal model to enhance numerical reasoning capabilities for EHR analysis. Experiments on MIMIC-IV demonstrate significant performance improvements over individual models while maintaining privacy advantages compared to fine-tuned approaches. The framework also shows strong transfer abilities to downstream medical tasks.

## Method Summary
PatientDx leverages model merging techniques to combine pre-trained LLMs without training on private patient data. The framework uses SLerp (Spherical Linear Interpolation) or Model Soup to interpolate model weights based on hyperparameters λ, optimized via grid search on pilot tasks. A math-specialized LLM serves as the pivotal model to enhance numerical reasoning for healthcare tasks. The approach is evaluated on MIMIC-IV Mortality datasets using AUROC/AUPRC metrics and DLT leakage assessment via perplexity differences. Three configurations are presented: PatientDx 7B, PatientDx 8B, and PatientBioDx 8B.

## Key Results
- Improves AUROC by up to 7% compared to individual input models on MIMIC-IV mortality prediction
- Less prone to data leakage than fine-tuned models, as measured by DLT metrics
- Demonstrates strong transfer abilities to downstream medical tasks including question answering and information retrieval
- SLerp outperforms linear weight averaging, with 9.0-17.4% AUROC drops when removed in ablation studies

## Why This Works (Mechanism)

### Mechanism 1
- Merging pre-trained models preserves privacy because no gradient updates occur on private patient data
- Weight interpolation via parametric functions (Model Soup or SLerp) requires only scalar hyperparameters λ
- Core assumption: Memorization requires gradient-based exposure; weight interpolation alone does not encode specific training examples
- Break condition: If input models were already fine-tuned on private data, merging would inherit their leakage risks

### Mechanism 2
- A math-specialized LLM as the pivotal model improves numerical reasoning on EHR data without domain training
- Numerical comprehension is critical for clinical tasks involving lab values, demographics, and time-series measurements
- Core assumption: Numerical reasoning is a transferable capability across domains; math pre-training generalizes to clinical numeracy
- Break condition: If patient tasks require domain-specific knowledge rather than raw numeracy, math models provide diminishing returns

### Mechanism 3
- SLerp (Spherical Linear Interpolation) outperforms linear weight averaging for healthcare tasks
- SLerp operates on angular combinations in weight space, preserving geometric relationships between model capabilities
- Core assumption: Model weights occupy meaningful regions in a shared spherical space where angular interpolation preserves functional properties
- Break condition: If input models share insufficient weight space overlap, SLerp may produce unstable interpolations

## Foundational Learning

- **Model merging / weight interpolation**
  - Why needed: Core technique PatientDx relies on; different from fine-tuning or ensembling
  - Quick check: Can you explain why averaging model weights doesn't require training data?

- **Data leakage metrics (∆₁, ∆₂ perplexity differences)**
  - Why needed: Paper uses DLT metrics to quantify memorization risk; understanding perplexity-based leakage detection is essential
  - Quick check: What does a negative ∆₁ value indicate about a model's leakage risk?

- **AUROC/AUPRC under class imbalance**
  - Why needed: Mortality dataset has ~10% positive class; paper prioritizes AUROC for this reason
  - Quick check: Why is AUPRC more sensitive than AUROC to class imbalance?

## Architecture Onboarding

- **Component map**: Mistral/Llama base + BioMedical variants + Math variants -> Merge function (SLerp/Model Soup) -> Hyperparameter optimizer -> Evaluation on MIMIC-IV

- **Critical path**:
  1. Select two input models of identical architecture (e.g., Llama-3.1-8B-Instruct + DART-math-8B)
  2. Define λ search space (paper uses discrete values; optimal λ*=0.4 for PatientDx 8B)
  3. Merge via SLerp using MergeKit
  4. Evaluate on pilot task; select λ maximizing AUROC
  5. Verify leakage via DLT (∆₁ should remain positive, ∆₂ near zero)

- **Design tradeoffs**:
  - Math model weight vs. instruct model weight: Higher math weight improves numerical tasks but may reduce coherence (λ*=0.4 favors instruct)
  - SLerp vs. Model Soup: SLerp more stable but requires angular computation; linear soup faster
  - Dataset specificity: λ optimized on Mortality may not transfer optimally to other tasks

- **Failure signatures**:
  - AUROC near 0.5: Input models lack relevant capabilities; check model selection
  - Negative ∆₁ on DLT: Accidental fine-tuning occurred; verify no gradient updates
  - Incoherent outputs: λ too extreme (near 0 or 1); effectively using single model

- **First 3 experiments**:
  1. Reproduce PatientDx 8B: Merge Llama-3.1-8B-Instruct with DART-math-8B using SLerp, λ=0.4, evaluate on MIMIC-IV Mortality
  2. Ablate pivotal model: Replace DART-math with generic instruct model; expect ~14-21% AUROC drop per Table 3
  3. Leakage comparison: Fine-tune a baseline on Mortality training data; compare ∆₁/∆₂ against PatientDx to verify privacy advantage

## Open Questions the Paper Calls Out

- Can more optimal ways to combine model weights improve performance without increasing computational costs?
- Can the discrete and exhaustive evaluation required by PatientDx be made more efficient or automated?
- How does the framework perform across a broader range of patient-oriented healthcare tasks beyond mortality prediction?
- How do different choices of pivotal models impact the effectiveness of the merged model for healthcare applications?

## Limitations

- Major uncertainty about privacy claims - lack of empirical validation against state-of-the-art privacy attacks like membership inference
- DLT leakage metrics are novel to this work and their sensitivity to different attack vectors remains unclear
- Pivotal model hypothesis lacks direct ablation studies isolating numerical reasoning benefits from other capabilities

## Confidence

- **High confidence**: Model merging improves AUROC vs. individual models (7% gain empirically demonstrated on MIMIC-IV)
- **Medium confidence**: SLerp outperforms linear interpolation (ablated with 9-17% AUROC drops, but corpus lacks SLerp-specific validation)
- **Medium confidence**: No fine-tuning = no data leakage (theoretical mechanism sound, but limited empirical leakage testing)
- **Low confidence**: Math-pivotal model design (observation supported but not rigorously tested against other domain pivots)

## Next Checks

1. Test PatientDx against membership inference attacks to verify claimed privacy advantages over fine-tuned baselines
2. Conduct controlled ablation replacing the math pivotal model with domain-specific biomedical or general instruction models to isolate numerical reasoning benefits
3. Evaluate SLerp performance on diverse model pairs beyond the presented configurations to test generalizability of angular interpolation advantages