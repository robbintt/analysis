---
ver: rpa2
title: Can LLMs Learn to Map the World from Local Descriptions?
arxiv_id: '2505.20874'
source_url: https://arxiv.org/abs/2505.20874
tags:
- spatial
- distance
- training
- data
- path
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'Large Language Models (LLMs) were trained in two stages: first
  on fragmented spatial relational descriptions (distances and azimuths between POIs)
  and then on trajectory-based shortest path data. The models successfully inferred
  unseen POI relationships with low error (0.11% MRPE for distance, 0.79 for Spearman
  correlation on azimuth) and generalized shortest path planning to unseen POI pairs
  (83.63% exact match accuracy).'
---

# Can LLMs Learn to Map the World from Local Descriptions?

## Quick Facts
- arXiv ID: 2505.20874
- Source URL: https://arxiv.org/abs/2505.20874
- Reference count: 40
- One-line primary result: Two-stage CPT enables LLMs to infer global spatial layouts from fragmented local descriptions with high accuracy.

## Executive Summary
This paper demonstrates that large language models can develop global spatial cognition by training on fragmented local descriptions of distances and azimuths between points of interest (POIs), followed by trajectory-based shortest path data. The model successfully infers unseen POI relationships with low error rates and generalizes shortest path planning to unseen POI pairs. Latent space analysis reveals the model encodes absolute coordinates and spatial geometry without explicit training, enabling dynamic position tracking during navigation. However, robustness to path perturbations is limited and highly dependent on training data distribution, suggesting fragmented rather than globally coherent spatial understanding.

## Method Summary
The approach uses a two-stage Continual Pre-training (CPT) strategy on a synthetic 100×100 grid environment with 1024 POIs and 200 roads. Stage 1 trains on fragmented pairwise relational descriptions (distances and azimuths) to develop spatial perception. Stage 2 trains on trajectory descriptions of shortest paths to develop navigation capabilities. The QWEN 2.5-0.5B model is trained with specific hyperparameters (batch size 128, LR 1e-4, 10 epochs) and evaluated using explicit prediction metrics (MRPE, Spearman correlation, exact match accuracy) plus latent space probing with MLP probes to decode absolute coordinates from hidden states.

## Key Results
- Spatial perception: 0.11% MRPE for distance and 1.00 Spearman correlation for azimuth on unseen POI pairs
- Navigation: 83.63% exact match accuracy for shortest path planning on unseen POI pairs
- Latent space: MLP probes achieve R²=1.00 for both X and Y coordinates with MAE <1.0 from frozen representations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can construct global spatial layouts by integrating fragmented pairwise relational descriptions during continual pre-training.
- Mechan: The model learns to reconcile overlapping pairwise constraints (distances and azimuths) across POI pairs, implicitly solving a constraint satisfaction problem that yields coherent global coordinates—similar to how triangulation works in surveying.
- Core assumption: The relational descriptions provide sufficient coverage and consistency for the model to resolve global structure without contradictory signals.
- Evidence anchors:
  - [abstract] "LLMs not only generalize to unseen spatial relationships between points of interest (POIs) but also exhibit latent representations aligned with real-world spatial distributions."
  - [section 3.1] Table 1 shows MRPE of 0.11% for distance and Spearman correlation of 1.00 for azimuth at 80:20 split, with degradation as training data decreases.
  - [corpus] Weak direct corpus support; related work on spatial cognition in LLMs (Momennejad et al., Ramakrishnan et al.) focuses on evaluation rather than training mechanisms.
- Break condition: Insufficient pairwise coverage (<60% training data) causes error rates to increase substantially (MRPE rises from 0.11% to 2.63%).

### Mechanism 2
- Claim: Absolute spatial coordinates emerge in latent representations without explicit coordinate supervision during training.
- Mechan: The last hidden states of POI name tokens encode geometric structure because the model must predict relative relationships, which forces it to internalize an implicit coordinate system. MLP probes can then decode these coordinates from frozen representations.
- Core assumption: The model's hidden states preserve geometric information in a structured, probe-accessible format rather than distributing it across computation.
- Evidence anchors:
  - [section 3.2] Table 2 shows MLP probe achieves R²=1.00 for both X and Y coordinates with MAE <1.0, compared to base model R²≈-0.01.
  - [section 3.2] Figure 2 shows strong Spearman/Pearson correlations (0.82-0.91) between latent space distances/angles and actual geography.
  - [corpus] Related work (Gurnee & Tegmark, Liétard et al.) demonstrates pretrained LLMs encode geospatial information, but source of these capabilities was previously unexplored.
- Break condition: SFT training fails to produce structured latent representations (R² drops to 0.46-0.53) because POI tokens don't directly contribute to loss calculation.

### Mechanism 3
- Claim: Navigation robustness depends on training data frequency at turning points rather than global road network understanding.
- Mechan: The model learns statistical patterns of entry/exit transitions at frequently visited intersections, enabling recovery at high-frequency points but failing at rare locations—suggesting memorized turn patterns rather than continuous spatial reasoning.
- Core assumption: Performance correlates with exposure frequency; the model lacks a truly compositional understanding of road connectivity.
- Evidence anchors:
  - [section 4.3] Table 6 shows road perturbation FSA of only 11.85%, indicating poor understanding of available roads at current position.
  - [section 4.3] Figure 5 shows FSA improves from ~20% to ~70% as high-frequency point threshold increases from 1000 to 60000.
  - [corpus] Corpus lacks comparable robustness analysis for spatial navigation in LLMs.
- Break condition: Random perturbations at low-frequency locations cause severe destination deviation (DD >50km for direction perturbations).

## Foundational Learning

- Concept: **Continual Pre-training (CPT) vs. Supervised Fine-Tuning (SFT)**
  - Why needed here: CPT produces structured latent spatial representations while SFT achieves better surface prediction but weaker internal geometry—a critical tradeoff for interpretability.
  - Quick check question: Does your task require explainable internal representations, or only accurate endpoint predictions?

- Concept: **Latent Space Probing**
  - Why needed here: The paper relies on MLP probes to demonstrate that spatial coordinates are encoded; understanding linear vs. non-linear probe limitations is essential for valid inference.
  - Quick check question: Can a linear probe extract the information you care about, or does it require non-linear transformation?

- Concept: **Spatial Cognition Components**
  - Why needed here: The paper distinguishes spatial perception (static layout inference) from spatial navigation (dynamic path planning)—these require different evaluation approaches.
  - Quick check question: Are you evaluating static understanding of locations or dynamic reasoning about movement?

## Architecture Onboarding

- Component map: QWEN 2.5-0.5B -> CPT Stage 1 (relational descriptions) -> MODEL_per -> CPT Stage 2 (trajectory descriptions) -> MODEL_nav
- Critical path:
  1. Generate synthetic 100×100 grid with 1024 POIs, 200 roads with random traversal weights
  2. Create relational dataset (pairwise distance/azimuth templates) and trajectory dataset (Dijkstra shortest paths → natural language)
  3. Train MODEL_per with 80:20 split, validate on unseen POI pairs
  4. Train MODEL_nav with Bridged Exposure setting (hold out POI pairs between held-out set)
  5. Probe latent representations and test perturbation robustness

- Design tradeoffs:
  - CPT vs. SFT: CPT yields structured latent space (R²=1.00 for coordinates) while SFT achieves better surface accuracy but no internal structure
  - Model scale: QWEN 2.5-0.5B sufficient for controlled study; LLaMA-3.2-1B shows degraded navigation (27.4% vs 83.63% SPA)
  - Train/test split: Performance degrades sharply below 60% training data

- Failure signatures:
  - Road perturbation FSA <15%: Model lacks coherent road network understanding
  - Low-frequency turning point perturbations: High destination deviation (>20km)
  - SFT training: Latent space probe R² drops to 0.25-0.53 despite good surface predictions

- First 3 experiments:
  1. Replicate Table 1 with varying train/test splits to validate that spatial perception scales with data coverage
  2. Train with SFT strategy and compare latent probe performance (Table 15) to confirm CPT necessity for structured representations
  3. Apply road perturbations at different frequency thresholds (Figure 5) to map the boundary between memorized and generalized navigation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can models be trained to acquire specific spatial cognition without losing their original general language capabilities?
- Basis in paper: [explicit] The authors state in the Limitations section: "Furthermore, our training process has caused the model to lose its original general language capabilities. How to balance the model’s general abilities with its internal spatial cognition remains an open research question."
- Why unresolved: The current training regime (continual pre-training) successfully induced spatial skills but degraded the model's broader linguistic proficiency, indicating a conflict in optimization objectives.
- Evidence: Experiments showing that the spatially-trained model maintains performance on standard NLP benchmarks (e.g., MMLU, HellaSwag) comparable to the base model, or the identification of a training method that mitigates catastrophic forgetting.

### Open Question 2
- Question: Do LLMs actually rely on their latent "mental maps" to generate spatial predictions, or do they use superficial heuristics?
- Basis in paper: [explicit] The authors admit that "how it utilizes this spatial understanding information has not been fully analyzed. Our experiments lack an in-depth analysis of the internal mechanisms behind the model’s explicit prediction..."
- Why unresolved: While probing shows that coordinate information *exists* in the hidden states, correlation does not imply causation; the model might ignore these representations during generation in favor of statistical patterns.
- Evidence: Causal tracing or activation patching experiments that demonstrate manipulating the latent coordinate vectors directly and predictably alters the model's output regarding distances and paths.

### Open Question 3
- Question: How can the transition from fragmented, frequency-dependent understanding to globally coherent spatial reasoning be achieved?
- Basis in paper: [inferred] The paper concludes that the model's ability to recover from navigational perturbations is "highly dependent on the distribution of training data," suggesting the model relies on "fragmented rather than globally coherent spatial understanding."
- Why unresolved: The model currently appears to memorize high-frequency turning points rather than maintaining a continuous, geometric state of the world, leading to fragility in unseen or low-frequency map regions.
- Evidence: Successful navigation and perturbation recovery in regions specifically excluded from the high-frequency training distribution, or uniform performance across the map regardless of node connectivity density.

## Limitations
- Synthetic evaluation environment may not capture real-world geographic complexity with irregular road networks and ambiguous spatial descriptions
- Model relies on memorized turning patterns at frequently visited intersections rather than true spatial reasoning, showing only 11.85% First-Step Accuracy under random perturbations
- Claims about dynamic position tracking during navigation are based on perturbation experiments with specific road weight distributions, requiring validation across multiple real-world road networks

## Confidence
- High confidence: Core mechanism of spatial layout inference from fragmented relational descriptions is well-supported by quantitative evidence (0.11% MRPE, perfect Spearman correlation, R²=1.00 for coordinate reconstruction)
- Medium confidence: Generalization to shortest path planning (83.63% exact match) is supported by controlled experiments, but Bridged Exposure setting may not fully capture real-world navigation challenges
- Low confidence: Claims about dynamic position tracking during navigation are based on perturbation experiments with specific road weight distributions, requiring validation across multiple real-world road networks

## Next Checks
1. **Real-world transfer validation**: Apply the trained model to a real geographic dataset (e.g., OpenStreetMap data for a medium-sized city) with actual street networks and POI distributions. Compare performance metrics (MRPE, SPA) against the synthetic environment to quantify transfer capability.

2. **Frequency-based ablation study**: Systematically vary the training data frequency distribution for different POI pairs and road segments. Measure how exact match accuracy and robustness degrade as exposure frequency decreases, mapping the boundary between learned patterns and genuine spatial reasoning.

3. **Cross-model scalability test**: Repeat the two-stage training with larger models (1B, 3B parameters) using the same synthetic environment and training regime. Evaluate whether performance gains scale linearly or if there are diminishing returns, and whether larger models show improved robustness to perturbations.