---
ver: rpa2
title: Learning Provably Correct Distributed Protocols Without Human Knowledge
arxiv_id: '2601.22369'
source_url: https://arxiv.org/abs/2601.22369
tags:
- state
- ggms
- protocol
- process
- correct
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of automatically designing distributed
  protocols that are provably correct, without requiring human-designed examples.
  The authors frame the problem as searching for state machines in an imperfect-information
  game, where correctness is verified by exhaustive model checking.
---

# Learning Provably Correct Distributed Protocols Without Human Knowledge

## Quick Facts
- arXiv ID: 2601.22369
- Source URL: https://arxiv.org/abs/2601.22369
- Reference count: 40
- This paper presents GGMS, a method that automatically learns distributed protocols provably correct via exhaustive model checking, without requiring human-designed examples.

## Executive Summary
This paper tackles the challenge of automatically designing distributed protocols that are provably correct, without requiring human-designed examples. The authors frame the problem as searching for state machines in an imperfect-information game, where correctness is verified by exhaustive model checking. Their solution, GGMS, combines Monte Carlo Tree Search with a transformer-based action encoder, global depth-first search to break out of local minima, and iterative feedback from a model checker. The key innovation is using model checking as a hard oracle—any candidate protocol must pass exhaustive verification before being accepted.

## Method Summary
GGMS learns distributed protocols by combining MCTS with a transformer-based policy network, using exhaustive model checking as a correctness oracle. The method employs a global DFS approach to freeze and unfreeze transitions when the superposition problem arises, and uses a phased curriculum that starts with unambiguous scenarios before relaxing constraints. The policy network maps (round, procID, inputStates) to transition probabilities, while MCTS explores the state space through self-play with adversarial message loss selection. Validation is performed exhaustively for each phase, with counterexamples fed back for retraining.

## Key Results
- GGMS successfully learns correct protocols for larger settings than existing methods, including discovering a novel atomic commit protocol
- The framework achieves substantially higher success rates than MCTS baselines across all tested configurations, scaling to 4 processes with 3 failures
- GGMS achieves 100% success rate on all feasible settings tested, while MCTS and MCTS+DFS show degraded performance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Exhaustive model checking provides hard correctness guarantees that learning alone cannot achieve.
- **Mechanism:** A verifier enumerates all initial state configurations and message loss patterns for the bounded process count, rejecting any candidate state machine with violating executions. Counterexamples are fed back as training data, creating a CEGIS-like loop.
- **Core assumption:** The protocol must be verified for a fixed number of processes N; the method does not prove correctness for arbitrary N.
- **Evidence anchors:**
  - [abstract] "Protocols output by GGMS are verified correct via exhaustive model checking for all executions within the bounded setting."
  - [Section 4.4] "Exhaustive verification is what makes GGMS outputs provably correct... A protocol is returned only if it passes this complete check."
  - [corpus] Limited direct corpus support for model checking as synthesis oracle; related work uses verification as shaping signal rather than hard constraint.
- **Break condition:** If verification is approximated or sampled rather than exhaustive, provable correctness is lost; the method becomes probabilistic.

### Mechanism 2
- **Claim:** Global depth-first search (DFS) combined with MCTS prevents the superposition problem—where learning mixes transitions from multiple correct protocols into an incorrect one.
- **Mechanism:** When multiple transitions from the same input have similar probabilities, GGMS "freezes" one choice and continues training. If no correct protocol exists under current freezes, it backtracks systematically. DFS guarantees eventual exploration of all state machines if a correct one exists.
- **Core assumption:** The unfreezing condition is accurate (currently based on exhaustive search); incorrect unfreezing logic could cause infinite loops or missed solutions.
- **Evidence anchors:**
  - [abstract] "global depth-first search to break out of local minima"
  - [Section 4.2] "MCTS may end up in a situation where it learns some transitions from one version and some other transitions from another version, but when these transitions are combined, they do not generate a correct state machine."
  - [Theorem 4.1] "With a feasible setting, assuming GGMS's unfreezing condition is accurate, GGMS can eventually find a correct state machine."
  - [corpus] No direct corpus precedent for DFS + MCTS hybrid in protocol synthesis.
- **Break condition:** If freeze/unfreeze heuristics are poorly tuned, convergence time grows exponentially; naive DFS over all 2^54 state machines is intractable.

### Mechanism 3
- **Claim:** A phased curriculum starting with unambiguous scenarios accelerates convergence by allowing frozen transition effects to propagate before harder cases are explored.
- **Mechanism:** GGMS first simulates scenarios where message losses occur only in the final round and initial states lead to definite decisions. After correctness is achieved, constraints relax progressively (failures in last two rounds, then all rounds, then all initial states).
- **Core assumption:** Earlier rounds and ambiguous initial states introduce more "noise" from the superposition problem; controlled relaxation mitigates this.
- **Evidence anchors:**
  - [Section 4.3] "There is less ambiguity when the protocol is in later rounds and when the protocol starts with initial states that lead to definite decisions."
  - [Table 1] GGMS achieves 100% success rate on all feasible settings tested, while MCTS and MCTS+DFS show degraded performance, suggesting curriculum matters.
  - [corpus] No direct corpus comparison for curriculum-based protocol synthesis.
- **Break condition:** If relaxation schedule is too aggressive, the model may lock in incorrect transitions before propagation completes.

## Foundational Learning

- **Concept: Monte Carlo Tree Search (MCTS)**
  - Why needed here: GGMS uses MCTS to explore the space of state machine transitions through self-play between protocol and adversarial players.
  - Quick check question: Can you explain how UCB-based selection balances exploration and exploitation in MCTS?

- **Concept: Model Checking / SMT Solvers**
  - Why needed here: Formal verification is the correctness oracle; understanding how properties are encoded (e.g., agreement as SMT constraints) is essential.
  - Quick check question: How would you express the consensus agreement property as an SMT formula over final decisions?

- **Concept: Distributed Systems Fundamentals (Consensus, Atomic Commit, Fault Models)**
  - Why needed here: The target protocols and their properties (agreement, validity, termination) define the search space and verification criteria.
  - Quick check question: Why does FloodSet require f+1 rounds where f is the maximum number of failures?

## Architecture Onboarding

- **Component map:**
  Policy network (Transformer) -> MCTS simulator -> Freeze list (stack) -> Verifier -> Phase controller

- **Critical path:**
  1. Initialize policy network randomly
  2. Run MCTS on sampled scenarios → collect (state, transition probabilities) pairs
  3. Detect ambiguous transitions → freeze one choice
  4. Update policy with training buffer
  5. Validate with model checker → if counterexamples exist, add to failed_scenarios and retrain
  6. If validation passes, relax phase constraints; repeat until all phases complete
  7. If MCTS fails on frozen configuration → unfreeze and backtrack

- **Design tradeoffs:**
  - Transformer vs MLP policy: Transformer achieves higher success rates on harder settings (con-4-2: 90% vs 40%) but increases computational cost
  - Exhaustive vs Z3-based validation: Current exhaustive search is accurate but scales poorly; Z3-based would be faster but requires implementation
  - Freeze threshold (p_min=0.2, diff_max=0.1): Looser thresholds cause more frequent freezing (slower convergence); tighter thresholds risk superposition

- **Failure signatures:**
  - Superposition: Transitions from same input converge to different states across scenarios → multiple outputs with similar probabilities in training buffer
  - Incorrect freeze: Validation fails repeatedly after freeze; unfreeze triggered but no progress
  - Local minima: Reward stays negative despite many episodes; freeze list grows without correctness improvement

- **First 3 experiments:**
  1. **Sanity check:** Run GGMS on consensus with (n=2, f=1, r=2, k=2). Verify it finds FloodSet-like protocol within ~15 minutes. Check that frozen transitions appear in internal state assignments.
  2. **Ablation:** Disable guided sampling (start with all scenarios). Measure success rate drop on con-3-2. Expect degradation from 100% to ~80% based on MCTS+DFS baseline.
  3. **Scalability probe:** Run atomic commit on ac-4-2. Log freeze/unfreeze events and counterexample counts per episode. Identify which phase transitions are bottlenecks.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can GGMS be extended to synthesize protocols provably correct for an arbitrary number of processes (unbounded N)?
- Basis in paper: [explicit] The paper states "Proving correctness for arbitrary N requires inductive formal verification... an important direction we leave to future work."
- Why unresolved: The current methodology relies on exhaustive model checking for a concrete, bounded number of processes.
- What evidence would resolve it: A synthesis pipeline that outputs a generic protocol along with automatically generated inductive invariants verifiable for all N.

### Open Question 2
- Question: Can the framework effectively synthesize protocols for asynchronous networks or Byzantine failure models?
- Basis in paper: [explicit] The authors list "To model asynchronous networking... To model Byzantine processes" under future extensions in Section 6.
- Why unresolved: The current implementation assumes synchronous timing and crash failures, which simplifies the search space and verification logic.
- What evidence would resolve it: Successful synthesis and verification of a known complex protocol (e.g., PBFT) within the modified GGMS framework.

### Open Question 3
- Question: Can Large Language Models (LLMs) be integrated to generalize bounded protocols found by GGMS into generic algorithms?
- Basis in paper: [explicit] The paper notes "LLMs can synthesize a generic protocol that works for an arbitrary number of processes, which is a challenge for our work."
- Why unresolved: GGMS currently provides solutions only for specific finite settings; it lacks the capability to abstract these into general human-readable algorithms.
- What evidence would resolve it: A hybrid system where GGMS provides finite examples and counterexamples to train an LLM to output a correct, generic protocol.

## Limitations
- The exhaustive model checking approach limits scalability to protocols with more than ~4 processes due to state space explosion
- The method requires a fixed, bounded number of processes and cannot currently prove correctness for arbitrary N
- Unknown transformer hyperparameters and unfreezing conditions create uncertainty in faithful reproduction

## Confidence
- **High confidence:** The core mechanism of using model checking as a hard correctness oracle is sound and well-established. The superposition problem in MCTS-based protocol synthesis is correctly identified and the DFS approach provides a valid solution strategy.
- **Medium confidence:** The curriculum-based phased learning approach shows strong empirical results but lacks theoretical justification for why this particular relaxation schedule is optimal. The transformer policy network architecture appears effective but could potentially be simplified.
- **Low confidence:** The scalability claims are limited by the exhaustive verification approach. The paper doesn't address how the method would perform on protocols requiring more than 4 processes or those with richer state spaces.

## Next Checks
1. Implement a Z3-based verification component to replace exhaustive search and measure the impact on both scalability and success rates across all tested configurations.
2. Systematically vary the freezing threshold parameters (p_min and diff_max) to identify optimal values and measure their impact on convergence speed and success rates.
3. Add a comparison against a pure RL baseline (e.g., PPO) without MCTS to isolate the contribution of the tree search component to the overall success rate.