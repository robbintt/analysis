---
ver: rpa2
title: 'C-PATH: Conversational Patient Assistance and Triage in Healthcare System'
arxiv_id: '2506.06737'
source_url: https://arxiv.org/abs/2506.06737
tags:
- medical
- patient
- data
- conversational
- clinical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: C-PATH is an LLM-based conversational system designed to assist
  patients in symptom recognition and triage to appropriate medical departments. It
  employs a three-stage fine-tuning pipeline (medical knowledge injection, dialogue
  tuning, summarization) using LLaMA3 and a novel GPT-augmented dataset construction
  approach that transforms clinical cases into patient-friendly dialogues.
---

# C-PATH: Conversational Patient Assistance and Triage in Healthcare System

## Quick Facts
- arXiv ID: 2506.06737
- Source URL: https://arxiv.org/abs/2506.06737
- Authors: Qi Shi; Qiwei Han; Cláudia Soares
- Reference count: 40
- Primary result: Three-stage fine-tuning pipeline achieves 100% accuracy on department triage using GPT-rewritten clinical dialogues

## Executive Summary
C-PATH is an LLM-based conversational system designed to assist patients in symptom recognition and triage to appropriate medical departments. It employs a three-stage fine-tuning pipeline (medical knowledge injection, dialogue tuning, summarization) using LLaMA3 and a novel GPT-augmented dataset construction approach that transforms clinical cases into patient-friendly dialogues. The system also features scalable conversation history management to maintain coherence within context limits. Evaluations using GPTScore show strong performance in understandability, informativeness, and accuracy, with the GPT-rewritten dataset outperforming baselines. The approach improves patient accessibility, reduces provider burden, and supports EHR integration for clinical documentation.

## Method Summary
C-PATH uses a three-stage fine-tuning pipeline on LLaMA3-8B with LoRA (r=8) across 2x Nvidia A10 GPUs. Stage 1 injects medical knowledge via PubMedQA, MedQA-USMLE, and MedMCQA datasets. Stage 2 aligns knowledge to dialogue format using GPT-rewritten DDXPlus conversations. Stage 3 adds summarization capability for EHR compatibility using MTS-Dialog and ACI-BENCH. The system manages long conversations through sliding window pruning with optional summarization, maintaining coherence while respecting token limits. Input conversations use ### end-of-turn markers with explicit [Patient]/[Assistant] speaker tags.

## Key Results
- GPTScore achieves UND=94.57, ACC=100%, SPE=19.92 for GPT-rewritten data vs. UND=76.26, ACC=100%, SPE=70.02 for raw data
- Department classification achieves F1=0.996 and Accuracy=100% on test set
- GPT-rewritten dataset outperforms manual rewriting in structure and consistency metrics
- Context management successfully handles multi-turn conversations within 1024-token limits

## Why This Works (Mechanism)

### Mechanism 1
Sequential multi-stage fine-tuning enables progressive capability building from medical knowledge to conversational competence. Stage 1 injects domain knowledge via medical QA datasets; Stage 2 aligns this knowledge to dialogue format; Stage 3 adds summarization for EHR compatibility. The ordering assumes foundational knowledge must precede task-specific tuning.

### Mechanism 2
GPT-based rewriting of structured clinical data into layperson-friendly dialogue improves understandability without sacrificing accuracy. DDXPlus structured data is transformed into natural multi-turn conversations with accessible language, achieving higher GPTScore on understandability while preserving accuracy.

### Mechanism 3
Sliding window pruning with optional summarization maintains multi-turn coherence while respecting token limits. Three strategies work together: keep only recent N turns, summarize earlier turns, and use explicit speaker tagging to preserve role boundaries.

## Foundational Learning

- **LoRA**: Parameter-efficient fine-tuning reduces memory requirements compared to full fine-tuning. Rank parameter controls the low-rank decomposition of weight updates.
- **Context Window Management**: Medical triage requires multi-turn dialogue that can exceed model context limits. Understanding token limits and information decay is essential for the pruning + summarization strategy.
- **GPTScore Evaluation**: Traditional NLG metrics fail for medical dialogue. GPTScore uses LLM-as-judge for multi-dimensional evaluation, but may be both more appropriate and more risky than human evaluation.

## Architecture Onboarding

- **Component map**: LLaMA3-8B -> LMFlow with LoRA -> DDXPlus GPT rewriting -> Three-stage fine-tuning -> Sliding window history manager -> EHR-compatible summary
- **Critical path**: Data preparation (DDXPlus → GPT rewriting → conversation formatting) → Stage 1 (medical QA) → Stage 2 (dialogue tuning) → Stage 3 (summarization) → GPTScore + F1 evaluation
- **Design tradeoffs**: GPT-rewritten vs. manual rewriting (better structure but lower specificity); token length vs. information preservation; open-source LLaMA3 vs. proprietary models (control vs. performance)
- **Failure signatures**: Hallucination in triage, Reversal Curse in logical reasoning, department imbalance affecting underrepresented specialties
- **First 3 experiments**: 1) Baseline reproduction without GPT rewriting or staging; 2) History ablation testing triage accuracy with different context management strategies; 3) Department balance analysis per specialty performance

## Open Questions the Paper Calls Out

- How does RLHF with clinical expert supervision affect safety and alignment compared to current instruction-tuned version?
- To what extent do high automated evaluation scores translate to real-world clinical accuracy and user trust?
- Can the model maintain high triage accuracy for underrepresented medical departments despite training data imbalance?
- What specific failure modes arise from the "Reversal Curse" in complex differential diagnosis tasks?

## Limitations

- GPT-based data augmentation lacks direct human clinical validation for medical accuracy
- Context management strategy may lose critical diagnostic information from early conversation turns
- Performance on rare medical departments remains unclear due to DDXPlus dataset imbalance
- Model has not been tested in real-world clinical deployments with actual patients

## Confidence

- **High Confidence**: Three-stage fine-tuning pipeline architecture and sequential approach are well-specified and technically sound. LoRA fine-tuning is standard practice.
- **Medium Confidence**: GPT-rewritten dataset shows improved understandability metrics, but without human clinical validation, medical accuracy cannot be confirmed.
- **Low Confidence**: Performance on rare medical departments and handling of complex, multi-condition presentations remains untested.

## Next Checks

1. Conduct human clinical validation comparing GPT-rewritten conversations against original clinical cases to verify medical accuracy and rule out diagnostic errors.
2. Evaluate F1-score and confusion matrix per medical department on test set to identify performance gaps and implement targeted data augmentation for underrepresented specialties.
3. Design test suite of extended dialogues (30+ turns) with critical information distributed throughout to measure impact of context pruning on triage accuracy under realistic clinical scenarios.