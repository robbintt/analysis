---
ver: rpa2
title: Are you In or Out (of gallery)? Wisdom from the Same-Identity Crowd
arxiv_id: '2508.06357'
source_url: https://arxiv.org/abs/2508.06357
tags:
- probe
- images
- face
- in-gallery
- out-of-gallery
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of distinguishing whether a rank-one
  match in a one-to-many facial identification is from an identity present in the
  gallery (In-gallery) or not (Out-of-gallery). The core method leverages the ranks
  of additional images of the rank-one identity to predict this, rather than relying
  on a simple similarity score threshold.
---

# Are you In or Out (of gallery)? Wisdom from the Same-Identity Crowd

## Quick Facts
- arXiv ID: 2508.06357
- Source URL: https://arxiv.org/abs/2508.06357
- Authors: Aman Bhatta; Maria Dhakal; Michael C. King; Kevin W. Bowyer
- Reference count: 40
- Primary result: Rank-pattern-based classifier achieves high accuracy for In/Out gallery prediction, especially with AdaFace/TransFace embeddings

## Executive Summary
This paper introduces a novel approach to the In/Out gallery problem in face identification by leveraging rank patterns of multiple images belonging to the rank-one matched identity. Rather than relying on similarity score thresholds, the method trains a classifier on the ranks of non-matched images from the retrieved identity. The approach demonstrates robust performance across different embedding models and degraded probe conditions, with particular success using modern embeddings like AdaFace and TransFace. Results show consistent accuracy across demographic groups and significant improvements over thresholding methods.

## Method Summary
The core method extracts rank patterns from gallery images belonging to the rank-one matched identity to determine if the match is genuine (In-gallery) or false (Out-of-gallery). For each probe, the method records the ranks of three non-rank-one images from the retrieved identity, creating a 3-dimensional feature vector. An MLP classifier is trained on these rank patterns, with permutation augmentation applied during training to enhance robustness. The approach is tested across multiple face embedding networks and degradation conditions including blur, downsampling, atmospheric turbulence, and sunglasses. Gallery images are strictly sampled from the same demographic group as the probe to ensure learning of within-group rank patterns.

## Key Results
- The rank-pattern-based classifier achieves high accuracy for In/Out gallery prediction, particularly with AdaFace and TransFace embeddings
- Performance degrades significantly with FaceNet under degraded conditions, highlighting the importance of modern margin-based loss functions
- The method maintains consistent accuracy across demographic groups when gallery images are strictly from the same demographic as the probe
- Outperforms both simple thresholding and statistical classifier approaches across multiple datasets and conditions

## Why This Works (Mechanism)
The method works by recognizing that genuine matches (In-gallery) exhibit distinct rank patterns compared to false matches (Out-of-gallery) when multiple images of the retrieved identity are considered. When the rank-one identity is truly present in the gallery, its other images tend to have low ranks (close to 1), while false matches show more dispersed rank patterns. The classifier learns these subtle differences in rank distributions, making it more robust than single-score thresholding approaches.

## Foundational Learning
- **Rank pattern analysis**: Understanding how the distribution of ranks for multiple images of an identity differs between genuine and false matches - needed to design effective feature vectors for the classifier
- **Same-identity sampling**: Gallery images must come from the same demographic group as the probe - needed to ensure the classifier learns within-group patterns rather than cross-group distinctions
- **Margin-based embedding loss**: Modern embeddings like AdaFace and TransFace use margin-based losses that create better-separated embeddings - needed to explain why these models perform better under degradation

## Architecture Onboarding

**Component map**: Probe images -> Face embedding model -> Rank retrieval -> Rank pattern extraction (3 ranks) -> MLP classifier (2 hidden layers) -> In/Out prediction

**Critical path**: The classifier relies on having multiple gallery images per identity and the rank patterns of non-retrieved images from the rank-one identity

**Design tradeoffs**: The method requires multiple images per gallery identity and strict demographic grouping, trading operational flexibility for improved accuracy

**Failure signatures**: 
- Low accuracy with FaceNet under degradation (expected behavior)
- Failed feature vector construction when rank-1 identity has insufficient gallery images
- High variance across demographic groups (indicates sampling issues)

**3 first experiments**:
1. Test MLP classifier with synthetic rank patterns to verify learning capability
2. Evaluate performance with varying numbers of gallery images per identity
3. Compare classifier performance across demographic groups with mixed vs. same-group galleries

## Open Questions the Paper Calls Out
None

## Limitations
- Requires multiple gallery images per identity, limiting applicability to single-image-per-identity galleries
- Strict demographic grouping requirement may not reflect real-world operational scenarios
- Performance significantly degrades with older embedding models like FaceNet under degraded conditions

## Confidence
- **High confidence**: The core methodology of using rank patterns for In/Out gallery classification is well-specified and reproducible
- **Medium confidence**: The general trend of AdaFace/TransFace outperforming FaceNet is supported, but exact numerical values depend on implementation details
- **Medium confidence**: Claims about outperforming thresholding methods are reasonable but require independent verification

## Next Checks
1. Validate atmospheric turbulence implementation with $D/r_0=1.5$ parameter to ensure consistent degradation simulation
2. Test classifier performance when gallery images are not strictly from the same demographic group as the probe
3. Implement and compare against statistical baseline classifiers using the same rank-based features