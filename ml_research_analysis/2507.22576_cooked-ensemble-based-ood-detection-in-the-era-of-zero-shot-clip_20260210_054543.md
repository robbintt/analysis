---
ver: rpa2
title: 'COOkeD: Ensemble-based OOD detection in the era of zero-shot CLIP'
arxiv_id: '2507.22576'
source_url: https://arxiv.org/abs/2507.22576
tags:
- clip
- detection
- classifier
- probe
- zero-shot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work addresses the challenge of out-of-distribution (OOD)
  detection in image recognition, where classifiers must identify inputs from unseen
  classes at test-time. The authors propose COOkeD, an ensemble-based approach that
  combines predictions from three models: a standard classifier trained end-to-end,
  a zero-shot CLIP classifier, and a linear probe trained on CLIP features.'
---

# COOkeD: Ensemble-based OOD detection in the era of zero-shot CLIP

## Quick Facts
- arXiv ID: 2507.22576
- Source URL: https://arxiv.org/abs/2507.22576
- Authors: Galadrielle Humblot-Renaux; Gianni Franchi; Sergio Escalera; Thomas B. Moeslund
- Reference count: 40
- Primary result: Ensemble approach combining end-to-end classifier, CLIP zero-shot classifier, and CLIP linear probe achieves state-of-the-art OOD detection across diverse scenarios

## Executive Summary
This paper addresses the critical challenge of out-of-distribution (OOD) detection in image recognition, where classifiers must identify inputs from unseen classes at test-time. The authors propose COOkeD, an ensemble-based approach that combines predictions from three complementary models: a standard classifier trained end-to-end, a zero-shot CLIP classifier, and a linear probe trained on CLIP features. By integrating these diverse approaches, COOkeD achieves state-of-the-art OOD detection performance across various settings including near-OOD, far-OOD, covariate shift, and zero-shot shift scenarios. The method demonstrates consistent robustness and accuracy, significantly outperforming both classical and CLIP-based OOD detection methods on popular benchmarks like CIFAR100, ImageNet200, and ImageNet1K.

## Method Summary
COOkeD is an ensemble-based OOD detection method that leverages three distinct model architectures to capture complementary aspects of image classification. The ensemble combines predictions from an end-to-end trained classifier, a zero-shot CLIP classifier, and a linear probe trained on CLIP features. This multi-pronged approach allows the system to handle both traditional OOD scenarios and the emerging zero-shot setting where test-time classes were never seen during training. The method's strength lies in its ability to integrate diverse prediction strategies, with each component addressing different aspects of the OOD detection challenge. The ensemble framework provides robust performance across various OOD scenarios by aggregating evidence from multiple complementary sources.

## Key Results
- Achieves state-of-the-art OOD detection performance across near-OOD, far-OOD, covariate shift, and zero-shot shift scenarios
- Demonstrates consistent robustness and accuracy on popular benchmarks including CIFAR100, ImageNet200, and ImageNet1K
- Significantly outperforms both classical and CLIP-based OOD detection methods

## Why This Works (Mechanism)
The ensemble approach works by combining complementary prediction strategies that capture different aspects of image classification and OOD detection. The end-to-end classifier provides traditional discriminative learning, the zero-shot CLIP classifier leverages pre-trained vision-language knowledge, and the CLIP linear probe exploits rich feature representations. This multi-faceted approach allows the system to detect OOD samples through multiple independent signals, increasing overall robustness compared to single-model approaches.

## Foundational Learning
- **Out-of-distribution detection**: The ability to identify inputs from classes not seen during training is crucial for reliable deployment of classifiers in real-world settings. Quick check: Understanding this concept is essential as it defines the core problem COOkeD addresses.
- **Zero-shot learning**: Using pre-trained models like CLIP to classify without task-specific training allows handling unseen classes at test-time. Quick check: This capability is fundamental to COOkeD's approach for handling zero-shot shift scenarios.
- **Ensemble methods**: Combining multiple model predictions can improve robustness and reduce individual model biases. Quick check: The ensemble framework is the central architectural choice that enables COOkeD's superior performance.

## Architecture Onboarding
**Component Map**: End-to-end classifier -> CLIP zero-shot classifier -> CLIP linear probe -> Ensemble aggregation
**Critical Path**: Input image → Three parallel model predictions → Score combination → OOD decision
**Design Tradeoffs**: Computational overhead from running three models vs. improved detection accuracy and robustness
**Failure Signatures**: Poor performance when all three models fail simultaneously or when model predictions are highly correlated in their errors
**First Experiments**:
1. Evaluate each ensemble component individually on OOD detection tasks to quantify their independent contributions
2. Test the ensemble on controlled covariate shift scenarios to verify robustness claims
3. Compare inference time and memory requirements against single-model baselines

## Open Questions the Paper Calls Out
None

## Limitations
- Significant computational overhead during inference due to running three distinct model architectures
- Evaluation primarily focused on image classification benchmarks, limiting generalizability assessment
- Does not extensively address temporal stability or continuous distribution shift scenarios

## Confidence
- **High Confidence**: State-of-the-art performance on benchmark datasets is well-supported by empirical results
- **Medium Confidence**: Robustness across diverse OOD scenarios is supported but could benefit from more extreme stress-testing
- **Medium Confidence**: Computational overhead characterization is reasonable but lacks precise measurements

## Next Checks
1. Conduct ablation studies removing individual ensemble components to quantify their relative contributions and identify potential redundancy
2. Evaluate the method on additional dataset pairs with varying domain gaps, including medical imaging or satellite imagery
3. Perform extensive timing analysis comparing single-model inference versus ensemble approach, including memory requirements and potential optimizations for practical deployment