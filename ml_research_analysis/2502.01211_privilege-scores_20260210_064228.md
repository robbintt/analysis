---
ver: rpa2
title: Privilege Scores
arxiv_id: '2502.01211'
source_url: https://arxiv.org/abs/2502.01211
tags:
- intercept
- privscore
- value
- global
- negative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Privilege Scores (PS) are introduced as a quantitative measure
  to assess the level of privilege or disadvantage individuals experience due to a
  protected attribute (PA) in decision-making contexts. The method compares model
  predictions in the real world with those in a hypothetical fair world where the
  PA has no causal effect on the target.
---

# Privilege Scores

## Quick Facts
- **arXiv ID**: 2502.01211
- **Source URL**: https://arxiv.org/abs/2502.01211
- **Reference count**: 40
- **Primary result**: Introduces Privilege Scores to quantify individual advantage/disadvantage due to protected attributes by comparing real-world and counterfactual fair-world predictions

## Executive Summary
Privilege Scores (PS) provide a quantitative framework to measure how protected attributes confer advantage or disadvantage in decision-making systems. The method estimates individual privilege by comparing model predictions in the real world versus a hypothetical fair world where protected attributes have no causal effect on outcomes. By warping features to approximate this fair world and computing probability differences, PS reveal systemic biases such as racial disparities in loan approvals and LSAT score impacts on law school outcomes. The framework also introduces Privilege Score Contributions to attribute privilege to specific causal pathways, enabling interpretability through Shapley value decomposition.

## Method Summary
The method constructs a hypothetical "fair world" by warping features using causal DAGs, where protected attributes have no causal effect on the target. Two models are trained—one on real data and one on warped data—and privilege scores are computed as the difference in their predictions. Shapley values decompose total privilege into pathway-specific contributions. The framework provides confidence intervals via bootstrapping and demonstrates effectiveness through simulation and real-world experiments on mortgage lending and law school admissions.

## Key Results
- PS effectively quantify privilege, revealing racial disparities of ~0.22 in loan approval rates for Louisiana applicants
- PSC decomposition identifies specific pathways contributing to privilege, such as LSAT scores in law school admissions
- Confidence intervals successfully capture uncertainty, with coverage rates meeting nominal levels in simulation experiments
- Residual-based warping shows greater robustness to DAG misspecification compared to fairadapt

## Why This Works (Mechanism)

### Mechanism 1
- Feature warping approximates a hypothetical "fair world" where protected attributes have no causal effect on the target
- Causal warping methods transform observed features by removing PA-descending edges in a DAG, mapping individuals to counterfactual profiles
- Core assumption: A correctly specified causal DAG exists with PA influence propagating only through modeled pathways
- Break condition: DAG misspecification introduces bias; simulation experiments show coverage drops under misspecification

### Mechanism 2
- The difference between real-world and warped-world predicted probabilities quantifies individual privilege
- Two models are trained—one on real data and one on warped data—with privilege score δ̂ = π̂(x) - φ̂(x̃)
- Core assumption: Unbiased ML models and effective warping; otherwise δ̂ is biased
- Break condition: High-variance models or poor warping reduce estimator reliability

### Mechanism 3
- Shapley-based PSCs decompose total privilege into pathway-specific attributions
- Each PA-descending edge is a "player" with value function v(S) = π̂(x) - π̂(xS) measuring privilege when arrows in set S are removed
- Core assumption: Small number of k pathways enables tractable k! computation
- Break condition: Features affected by multiple privileges require "partial warping" not fully supported by current methods

## Foundational Learning

- **Directed Acyclic Graphs (DAGs) for causal modeling**: Why needed here—entire warping mechanism relies on specifying which features descend from the PA; misspecification directly biases estimates. Quick check: Can you draw a DAG for loan approval with race→income→approval and identify all PA-descending features?

- **Counterfactual fairness (Pearl's 3-step abduction-action-prediction)**: Why needed here—PS operationalizes counterfactual reasoning by comparing factual vs. fair-world predictions. Quick check: What would an individual's predicted outcome be if their PA value were changed to the advantaged group while preserving other characteristics?

- **Shapley values for attribution**: Why needed here—PSCs use Shapley's axioms to fairly allocate privilege contributions across causal pathways. Quick check: Given 3 players with marginal contributions, compute Shapley values ensuring Σγj = total value.

## Architecture Onboarding

- **Component map**: DAG specification → Warping engine → Dual model training → PS computation → PSC decomposition → Bootstrap CI
- **Critical path**: DAG → Warping → Dual model training → PS → PSC → CI. Errors propagate; DAG quality gates everything downstream
- **Design tradeoffs**: fairadapt vs. res-based warping (res-based more robust to misspecification), interpretability vs. complexity (Shapley over k! tractable only for small k), variance vs. fairness (lower variance when worlds are close reduces signal)
- **Failure signatures**: CI coverage below nominal α → DAG misspecification or warping failure, large δg → systematic shift from unobserved mediators, negative CI width → bootstrap sample too small
- **First 3 experiments**: 1) Validate warping on simulated data with known ground-truth DAG and PS values; measure bias/MSE/coverage, 2) Intentionally misspecify DAG and observe coverage degradation; confirm res-based warping is more robust, 3) Apply to real data (e.g., HMDA mortgage), compute subgroup PS distributions, and verify known disparities

## Open Questions the Paper Calls Out

### Open Question 1
- How can causal discovery methods be integrated into the Privilege Score framework to automatically infer the causal graph required for estimation?
- Basis: Authors state investigating causal discovery methods would be a worthwhile direction
- Why unresolved: Current framework assumes pre-defined DAG; misspecification leads to questionable estimation success
- What evidence would resolve it: Methodological extension with learned DAG and empirical analysis showing comparable performance

### Open Question 2
- Can rigorous statistical tests or inference methods be developed to establish the significance of global PSC importance?
- Basis: Authors mention leaving development of appropriate tests for PSC importance to future work
- Why unresolved: While CIs are provided for individual scores, formal statistical tests for global PSC importance are lacking
- What evidence would resolve it: Hypothesis test formulation providing valid p-values or confidence bounds with appropriate coverage

### Open Question 3
- How can Privilege Scores be utilized as an objective or regularization component during model training to generate fairer predictions?
- Basis: Conclusion lists using PS in model training to produce fairer models as future work
- Why unresolved: Paper focuses on PS as post-hoc auditing metric without exploring backpropagation or optimization during learning
- What evidence would resolve it: In-processing algorithm that minimizes Privilege Scores with experiments showing improved fairness metrics

## Limitations

- Framework critically relies on correctly specified causal DAGs, but real-world causal structures are often unknown or contested
- Current implementation handles only small numbers of PA-descending pathways (k), limiting applicability to complex scenarios
- Residual-based warping method for categorical variables is only referenced from prior work without detailed specification

## Confidence

- **High Confidence**: Mathematical framework for PS computation and Shapley-based PSC decomposition are rigorously proven and empirically validated on simulation data with known ground truth
- **Medium Confidence**: Real-world applications show expected disparities but validation relies on face validity rather than objective verification
- **Low Confidence**: Claims about robustness to DAG misspecification are supported only by limited simulation experiments

## Next Checks

1. **DAG Sensitivity Analysis**: Systematically vary DAG structure in simulation experiments to quantify how different misspecifications affect PS bias and CI coverage
2. **Scalability Test**: Apply the method to a dataset with multiple interacting privilege pathways to evaluate whether current k-pathway limitation produces reasonable results
3. **Cross-Method Validation**: Compare PS estimates against alternative fairness metrics on the same datasets to assess convergent validity and identify potential methodological disagreements