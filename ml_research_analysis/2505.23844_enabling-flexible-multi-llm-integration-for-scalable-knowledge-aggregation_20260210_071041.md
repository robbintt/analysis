---
ver: rpa2
title: Enabling Flexible Multi-LLM Integration for Scalable Knowledge Aggregation
arxiv_id: '2505.23844'
source_url: https://arxiv.org/abs/2505.23844
tags:
- llms
- training
- arxiv
- knowledge
- selection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of integrating multiple large
  language models (LLMs) to build a stronger composite model while avoiding knowledge
  interference and performance degradation that occurs in existing fusion approaches.
  The proposed method introduces an adaptive selection network that dynamically evaluates
  and selects the most relevant source LLMs based on their performance scores, along
  with a dynamic weighted fusion strategy that accounts for the inherent strengths
  of candidate models.
---

# Enabling Flexible Multi-LLM Integration for Scalable Knowledge Aggregation

## Quick Facts
- **arXiv ID**: 2505.23844
- **Source URL**: https://arxiv.org/abs/2505.23844
- **Reference count**: 40
- **One-line primary result**: Adaptive selection and dynamic fusion of multiple LLMs reduces knowledge interference by up to 50% while achieving consistent accuracy improvements across multiple benchmarks.

## Executive Summary
This paper addresses the problem of integrating multiple large language models (LLMs) to build a stronger composite model while avoiding knowledge interference and performance degradation that occurs in existing fusion approaches. The proposed method introduces an adaptive selection network that dynamically evaluates and selects the most relevant source LLMs based on their performance scores, along with a dynamic weighted fusion strategy that accounts for the inherent strengths of candidate models. A feedback-driven loss function prevents the selector from converging on a single subset of sources. Experimental results show that the approach reduces knowledge interference by up to 50% compared to existing methods while achieving consistent accuracy improvements across multiple benchmarks including Commonsense, Big-Bench Hard, and MMLU. The method demonstrates superior training efficiency, requiring fewer training steps and tokens to achieve comparable or better performance than baseline approaches.

## Method Summary
The method trains a target LLM by dynamically fusing knowledge from multiple source LLMs using their output probability distributions. An Adaptive Selection Network (ASN) evaluates source models' probabilistic outputs to assign selection scores, which are used with a threshold (τ=0.15) to select a subset of candidates. A dynamic weighted fusion combines the selected models' distributions based on their normalized selection probabilities. A feedback-driven loss term prevents the selector from collapsing to a small subset of sources. The target LLM is trained end-to-end with a combined loss function incorporating language modeling, fusion, and feedback components.

## Key Results
- Reduces knowledge interference by up to 50% compared to existing fusion methods
- Achieves consistent accuracy improvements across Commonsense, Big-Bench Hard, and MMLU benchmarks
- Demonstrates superior training efficiency with fewer training steps and tokens needed
- Shows the adaptive selection mechanism effectively prevents selector collapse

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Adaptive selection of source LLMs reduces knowledge interference.
- **Mechanism**: An Adaptive Selection Network (ASN) evaluates the probabilistic distribution matrices of source LLMs to assign a score to each. By applying a dynamic threshold (τ=0.15), the framework selectively integrates a subset of candidates (1 ≤ K ≤ M) for each training step, filtering out models whose contributions would be detrimental for a given input.
- **Core assumption**: Knowledge interference is input-dependent; a model that degrades performance on one task may be beneficial on another.
- **Evidence anchors**: [abstract] "...an adaptive selection network to evaluate and choose the most relevant source models based on their performance scores... reduces knowledge interference." [section] "We design an adaptive selection network that identifies the most relevant source LLMs based on their scores, thereby reducing knowledge interference."

### Mechanism 2
- **Claim**: Dynamic weighted fusion prioritizes more influential candidates.
- **Mechanism**: The fusion process assigns weights to selected candidates based on their normalized selection probabilities from the ASN. These weights are used to compute a weighted sum of the candidates' probabilistic distribution matrices, creating a fused representation that guides the target model's training.
- **Core assumption**: Models with higher selection scores contain more relevant and beneficial knowledge for the target model.
- **Evidence anchors**: [abstract] "...dynamic weighted fusion strategy that accounts for each model's inherent strengths." [section] "This dynamic fusion process can constantly let the more influential candidates have a greater effect on the final model."

### Mechanism 3
- **Claim**: A feedback-driven loss prevents the selector from converging on a small subset of sources.
- **Mechanism**: A feedback loss term, defined as the squared coefficient of variation of the batch-wise importance values of source models, is added to the overall training objective. This encourages a more uniform distribution of importance across candidates over time, preventing the ASN from consistently favoring only a few models.
- **Core assumption**: A diverse set of source models contributes positively to overall aggregation, and preventing collapse is beneficial.
- **Evidence anchors**: [abstract] "...feedback-driven loss function prevents the selector from converging on a small subset of sources." [section] "In practice, we find that the selection network often converges to a state in which it consistently assigns large weights to a small subset of candidates. To mitigate this, we implement a feedback approach..."

## Foundational Learning

- **Concept**: **Probabilistic Distribution Matrices (P)**
  - **Why needed here**: The method operates on the output probability distributions of LLMs over a vocabulary. Understanding how these matrices represent a model's knowledge and how they are aligned across different tokenizers is fundamental to the fusion process.
  - **Quick check question**: Given two LLMs with different vocabularies, how would you align their predicted probability distributions for the same input text?

- **Concept**: **Adaptive Selection Network (ASN)**
  - **Why needed here**: The core of the proposed framework. It's a learned function that maps a source LLM's probabilistic output to a scalar score, enabling dynamic, data-driven model selection.
  - **Quick check question**: What are the inputs and outputs of the ASN, and what is its primary role during training?

- **Concept**: **Token and Distribution Alignment**
  - **Why needed here**: Before fusing knowledge from models with different architectures, their outputs must be aligned. This involves matching token sequences (token-wise) and mapping distributions across different vocabularies (distribution-wise).
  - **Quick check question**: Why can't we simply average the output probabilities from two LLMs with different tokenizers without an alignment step?

## Architecture Onboarding

- **Component map**: Input text -> Source LLMs (inference) -> Token Alignment -> ASN (scoring) -> Dynamic Selection -> Weighted Fusion -> Target LLM (training step with combined loss)

- **Critical path**: Input text flows through source LLMs to generate probability distributions, which are aligned and scored by the ASN. Based on selection scores and threshold, a subset of models is dynamically selected and fused via weighted sum. The fused representation trains the target LLM with the combined loss function.

- **Design tradeoffs**:
  - **Threshold (τ) Value**: A lower τ includes more candidates, increasing diversity but risking interference. A higher τ is more selective but might discard useful models. The paper sets τ=0.15.
  - **Loss Weights (λfuse, λfeed)**: Balancing the fusion objective against the feedback loss is critical. Too much feedback loss might force poor uniform selection; too little allows the ASN to collapse. The paper uses λfuse=0.1 and λfeed=0.5.

- **Failure signatures**:
  - **Performance Degradation**: The target model's performance drops below the baseline on certain tasks, a sign of knowledge interference not mitigated by the selector.
  - **Selector Collapse**: Analysis of ASN outputs shows it consistently assigns near-zero weights to most source models, ignoring the feedback loss.
  - **Training Instability**: High variance or non-convergence in the overall loss, potentially from an imbalanced loss function or poor hyperparameter choices.

- **First 3 experiments**:
  1. **Baseline Comparison**: Replicate the FuseLLM baseline (fusing all models without selection) to quantify the initial knowledge interference problem as shown in Figure 1.
  2. **Ablation on Selection**: Run the framework with the ASN but without the feedback loss (Lfeed=0) to verify that the selector collapses to a small subset of models, as described in Section 4.3.
  3. **Hyperparameter Sensitivity**: Perform a grid search for the threshold τ and loss weights (λfuse, λfeed) on a validation set, following the procedure in Appendix B, to establish stable training settings.

## Open Questions the Paper Calls Out
- **Open Question 1**: How does the framework perform when trained on diverse datasets outside the MiniPile corpus?
  - **Basis in paper**: [explicit] The conclusion explicitly states that "limitations remain" and "future work should explore training on diverse datasets."
  - **Why unresolved**: The current study validates the method primarily on the MiniPile dataset, leaving the selection network's robustness and interference mitigation capabilities untested across broader, more heterogeneous data distributions.
  - **What evidence would resolve it**: Benchmark results from experiments conducted on multi-domain or cross-modal datasets distinct from the MiniPile distribution.

- **Open Question 2**: Can the token alignment requirement be removed or optimized to reduce preprocessing overhead?
  - **Basis in paper**: [explicit] The conclusion lists the "additional token alignment required prior to training" as a specific limitation of the proposed approach.
  - **Why unresolved**: The method currently relies on a specific alignment technique (MinED) to handle vocabulary differences, which adds complexity and computational cost before training begins.
  - **What evidence would resolve it**: A modified fusion mechanism that operates effectively on heterogeneous vocabularies without explicit pre-processing alignment, showing comparable performance metrics.

- **Open Question 3**: Does the feedback-driven loss effectively prevent selector convergence when scaling to a significantly larger pool of source models?
  - **Basis in paper**: [inferred] While the title claims "Scalable Knowledge Aggregation," experiments are limited to integrating only 3 to 5 models.
  - **Why unresolved**: It is unclear if the feedback loss is sufficient to prevent the selector from collapsing to a small subset when choosing from dozens of candidates, a scenario suggested by the goal of scalability.
  - **What evidence would resolve it**: Experimental results showing the selection distribution and model performance when fusing 10 or more candidate LLMs simultaneously.

## Limitations
- The framework requires token alignment preprocessing for source models with different vocabularies, adding computational overhead
- Performance relies heavily on the adaptive selection network's ability to correctly identify beneficial source models, creating potential feedback loops
- The method assumes a diverse set of source models is generally beneficial, which may not hold for highly imbalanced source model quality

## Confidence

**High Confidence**: The core mechanism of using an adaptive selection network with dynamic weighted fusion is well-specified and the general approach to preventing selector collapse through feedback loss is clearly described. The reduction in knowledge interference compared to baseline fusion methods is a direct and measurable outcome.

**Medium Confidence**: The experimental results showing consistent accuracy improvements across multiple benchmarks. While the paper reports these improvements, the exact implementation details of token alignment, the ASN architecture, and training hyperparameters have some ambiguities that could affect reproducibility.

**Low Confidence**: The generalizability of the method to very large numbers of source models (>10) or to domains significantly different from the tested benchmarks. The paper's focus on 7B-parameter models also raises questions about scalability to larger models where computational constraints become more severe.

## Next Checks
1. **Selector Collapse Analysis**: Run the framework with the ASN but set λfeed=0 to verify that the selector indeed converges to a small subset of source models, as claimed. Monitor the distribution of selection weights over training steps to confirm the feedback loss is preventing collapse.

2. **Knowledge Interference Quantification**: Implement the FuseLLM baseline exactly as described and measure the absolute magnitude of knowledge interference (performance drop of target-only vs. fused model) on at least two benchmarks. This would validate the claimed 50% reduction in interference.

3. **Threshold Sensitivity Study**: Perform a grid search for τ in the range [0.05, 0.25] on a held-out validation set and report how the choice affects both the number of selected candidates per batch and the final task performance. This would clarify whether τ=0.15 is a robust default or task-dependent.