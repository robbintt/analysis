---
ver: rpa2
title: 'BOOST: Out-of-Distribution-Informed Adaptive Sampling for Bias Mitigation
  in Stylistic Convolutional Neural Networks'
arxiv_id: '2507.07134'
source_url: https://arxiv.org/abs/2507.07134
tags:
- samples
- classes
- class
- bias
- sampler
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses bias in AI-based painting classification caused
  by imbalanced training datasets, where dominant artistic styles lead to poor performance
  on rare classes. To tackle this, it proposes BOOST (Bias-Oriented OOD Sampling and
  Tuning), a novel adaptive sampling method that dynamically adjusts temperature scaling
  and sampling probabilities using an out-of-distribution detector.
---

# BOOST: Out-of-Distribution-Informed Adaptive Sampling for Bias Mitigation in Stylistic Convolutional Neural Networks

## Quick Facts
- arXiv ID: 2507.07134
- Source URL: https://arxiv.org/abs/2507.07134
- Reference count: 40
- Key outcome: BOOST reduces bias in painting classification with 84.44% accuracy and 79.79% F1 score, achieving significantly lower class-wise bias (Mean Absolute Bias 2.94%, Standard Deviation of Bias 3.51%)

## Executive Summary
This paper addresses bias in AI-based painting classification caused by imbalanced training datasets, where dominant artistic styles lead to poor performance on rare classes. The authors propose BOOST (Bias-Oriented OOD Sampling and Tuning), a novel adaptive sampling method that dynamically adjusts temperature scaling and sampling probabilities using an out-of-distribution detector. This approach promotes equitable representation of all classes by prioritizing hard or ambiguous samples early in training and gradually shifting to uniform sampling. BOOST was evaluated on KaoKore and PACS datasets, achieving state-of-the-art results in both classification accuracy and fairness metrics.

## Method Summary
BOOST combines adaptive temperature scaling with an out-of-distribution detector to create a dynamic sampling strategy that reduces bias in painting classification. The method uses a two-stage approach: first, it identifies and prioritizes OOD samples (rare or ambiguous classes) during early training phases, then gradually shifts to uniform sampling as training progresses. The temperature scaling mechanism controls the sampling probability distribution, with higher temperatures emphasizing rare classes and lower temperatures promoting diversity. A novel Same-Dataset OOD Detection Score (SODC) metric was introduced to evaluate class-wise separation and bias reduction.

## Key Results
- Achieved 84.44% classification accuracy and 79.79% F1 score on KaoKore and PACS datasets
- Significantly reduced class-wise bias with Mean Absolute Bias of 2.94% and Standard Deviation of Bias 3.51%
- Demonstrated superior performance compared to baseline models in both accuracy and fairness metrics
- Introduced and validated the SODC metric for assessing bias reduction in same-dataset OOD detection

## Why This Works (Mechanism)
BOOST works by dynamically adjusting the sampling distribution during training based on OOD detection. Early in training, when the model is uncertain, it emphasizes rare and ambiguous samples that would otherwise be overlooked. As the model becomes more confident, the sampling distribution gradually shifts toward uniformity, preventing overfitting to the minority classes while maintaining their representation. This adaptive approach addresses the fundamental challenge of imbalanced datasets where dominant classes can overshadow rare but important samples.

## Foundational Learning
- **Temperature scaling in sampling**: Controls the sharpness of probability distributions in sampling strategies; needed to balance between exploration of rare classes and exploitation of confident predictions; quick check: verify temperature affects sampling probabilities as expected
- **Out-of-distribution detection**: Identifies samples that deviate from the dominant data distribution; needed to find rare or ambiguous classes in imbalanced datasets; quick check: confirm OOD detector identifies known rare classes
- **Class imbalance in deep learning**: Occurs when training data has disproportionate representation of different classes; needed context for understanding bias problems in painting classification; quick check: analyze class distribution in training data
- **Adaptive learning rate schedules**: Adjusts learning parameters during training based on model performance; needed to understand dynamic adjustment mechanisms; quick check: verify learning rate changes correlate with training progress
- **Convolutional neural networks for style classification**: CNN architectures specialized for recognizing artistic styles and patterns; needed foundation for understanding the classification task; quick check: confirm CNN extracts relevant style features
- **Bias metrics in classification**: Quantitative measures of fairness and representation across classes; needed to evaluate the effectiveness of bias mitigation; quick check: compare multiple bias metrics for consistency

## Architecture Onboarding

Component map: Data loader -> OOD detector -> Temperature scaler -> Sampler -> CNN classifier -> Loss function -> Optimizer

Critical path: OOD detection -> Temperature scaling -> Adaptive sampling -> CNN training -> Bias evaluation

Design tradeoffs: The method balances between emphasizing rare classes early (risk of overfitting) and maintaining diversity later (risk of forgetting rare classes). The temperature scaling parameter requires careful tuning to avoid extremes.

Failure signatures: If temperature scaling is too aggressive, the model may overfit to rare classes. If OOD detection is too sensitive, normal variations might be incorrectly classified as rare, wasting training resources.

First experiments:
1. Visualize the sampling probability distribution across training epochs to verify the adaptive behavior
2. Test OOD detector performance on known rare classes in validation set
3. Compare class activation maps before and after BOOST training to identify learned bias patterns

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Limited evaluation scope with only two datasets (KaoKore and PACS), both focusing on artistic style classification
- Proposed SODC metric lacks comparison with established OOD detection benchmarks
- Computational overhead of the OOD detector during training is not quantified
- Performance on larger-scale or more diverse art datasets remains untested

## Confidence
- High confidence: The general methodology of adaptive sampling based on OOD detection is sound and well-explained
- Medium confidence: The reported improvements in bias metrics (Mean Absolute Bias 2.94%, Standard Deviation of Bias 3.51%) are likely valid for the tested datasets
- Medium confidence: The classification accuracy improvements (84.44% accuracy, 79.79% F1) are plausible but need validation on more diverse datasets

## Next Checks
1. Test BOOST on larger, more diverse art datasets including contemporary digital art and photography to assess generalizability
2. Benchmark SODC against established OOD detection metrics like AUROC and AUPR on standard datasets
3. Measure and report the computational overhead and training time impact of the OOD detector component