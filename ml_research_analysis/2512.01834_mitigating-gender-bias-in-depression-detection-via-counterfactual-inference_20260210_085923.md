---
ver: rpa2
title: Mitigating Gender Bias in Depression Detection via Counterfactual Inference
arxiv_id: '2512.01834'
source_url: https://arxiv.org/abs/2512.01834
tags:
- depression
- gender
- bias
- causal
- inference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Audio-based depression detection models often exhibit gender bias
  due to imbalanced training data, where females are over-represented and diagnosed
  more frequently. This study proposes a Counterfactual Debiasing Framework grounded
  in causal inference to mitigate such bias.
---

# Mitigating Gender Bias in Depression Detection via Counterfactual Inference

## Quick Facts
- **arXiv ID:** 2512.01834
- **Source URL:** https://arxiv.org/abs/2512.01834
- **Reference count:** 29
- **Primary result:** Counterfactual inference framework reduces gender bias in audio depression detection, improving fairness (EA: 0.013/0.007, DI: 0.719/0.745) and accuracy (F1: 0.644/0.804, Acc: 0.702/0.830) on DAIC-WOZ dataset

## Executive Summary
Audio-based depression detection models often exhibit gender bias due to imbalanced training data, where females are over-represented and diagnosed more frequently. This study proposes a Counterfactual Debiasing Framework grounded in causal inference to mitigate such bias. The framework identifies and removes the direct causal effect of gender on predictions by employing counterfactual inference during inference. Experiments on the DAIC-WOZ dataset using two advanced acoustic backbones (STA-based and NetVLAD-based) demonstrate that the proposed method significantly reduces gender bias while enhancing overall performance compared to existing debiasing strategies.

## Method Summary
The framework constructs a causal graph where Gender (G) and Acoustic cues (C) jointly influence the fused feature representation (F), which then determines depression status (D). A spurious direct edge G→D captures bias. During training, two models are used: M_G (gender-only MLP) and M_F (fusion backbone+MLP). The loss function combines classification loss L_cls with KL divergence loss L_kl for calibrating the counterfactual baseline ε. During inference, the Total Indirect Effect (TIE) formula subtracts the counterfactual prediction from the factual prediction to isolate the diagnostic pathway and remove bias.

## Key Results
- EA reduced to 0.013 (STA) and 0.007 (NetVLAD) from baseline levels
- DI improved to 0.719 (STA) and 0.745 (NetVLAD) from baseline
- F1-scores increased to 0.644 (STA) and 0.804 (NetVLAD)
- Accuracies improved to 0.702 (STA) and 0.830 (NetVLAD)

## Why This Works (Mechanism)

### Mechanism 1: Causal Decomposition of Gender Effect via Structural Causal Model
The framework isolates gender bias as the direct causal path from gender to prediction, separable from legitimate diagnostic pathways. By constructing a causal graph where G→D represents bias, the method can formally subtract this spurious correlation while preserving valid acoustic-based depression signals.

### Mechanism 2: Counterfactual Intervention for Bias Quantification
The magnitude of gender bias is estimated by simulating a counterfactual scenario where acoustic and gender inputs are intervened to null values. Using a learnable parameter ε to represent the model's baseline prediction distribution under no informative input enables accurate bias quantification through KL divergence minimization.

### Mechanism 3: Dual-Model Architecture with Additive Fusion
Separating gender-only processing (M_G) from fusion processing (M_F) enables explicit modeling and subsequent removal of gender contribution. The additive fusion in log-space correctly captures the compositional relationship between bias and diagnostic effects, allowing for precise subtraction of the bias component.

## Foundational Learning

- **Structural Causal Models (SCMs) and Causal Graphs**: Understanding nodes (variables) vs. edges (causal mechanisms) is essential for the framework's causal graph construction. Quick check: Given a causal graph A→B→C, can you identify the direct effect of A on C vs. the indirect effect through B?

- **Counterfactual Intervention (do-calculus)**: The method requires computing predictions under hypothetical interventions. Quick check: What does P(Y|do(X=x)) represent, and how does it differ from P(Y|X=x)?

- **Logit-Space Arithmetic for Probability Manipulation**: The fusion and subtraction operations occur in logit space. Quick check: If logit L₁ corresponds to probability p₁ and logit L₂ corresponds to probability p₂, what probability does L₁ - L₂ approximately represent?

## Architecture Onboarding

- **Component map:**
  ```
  Training Path:
  [Gender g] → M_G (MLP) → D_g ─┐
                                 ├→ h(·) = log σ(+) → L_cls
  [Audio c] + [Gender g] → M_F (STA/NetVLAD+MLP) → D_Fg,c ─┘
                                            ↓
                                        L_kl (vs. D_Fg,c with ε)
  
  Inference Path:
  [g, c] → M_G → D_g ─┐
                       ├→ h(D_g, D_Fg,c) - h(D_g, M_F(ε)) → Final prediction
  [g, c] → M_F → D_Fg,c ─┘
  ```

- **Critical path:** The KL loss L_kl updating ε is the single most failure-prone step. If ε is poorly calibrated, the counterfactual baseline will be wrong, causing under/over-correction of bias.

- **Design tradeoffs:**
  - MLP for M_G vs. complex architecture: Paper uses simple MLP; assumption is gender is a 1-dimensional signal requiring minimal processing
  - Additive fusion vs. multiplicative: Additive assumes independence of bias and signal effects
  - Shared ε across all samples vs. per-sample: Global ε assumes uniform baseline

- **Failure signatures:**
  - Over-correction: Male and Female F1 diverge in opposite direction
  - Under-correction: DI remains far from 1.0 (e.g., >1.5 or <0.67)
  - ε collapse: If L_kl dominates, M_F may learn to ignore inputs

- **First 3 experiments:**
  1. Sanity check—bias quantification: Train M_G alone on gender→depression task
  2. Ablation—ε initialization sensitivity: Test 3-5 different ε initializations
  3. Hyperparameter sweep—L_kl weight: Test λ ∈ {0.1, 0.5, 1.0, 2.0} for L = L_cls + λ·L_kl

## Open Questions the Paper Calls Out

### Open Question 1
How can the counterfactual debiasing framework be extended to a multimodal setting to handle gender bias that varies across visual and linguistic cues alongside audio? The current study validates the framework solely on the audio modality; visual and linguistic features introduce distinct causal pathways and interactions that the current single-modality causal graph does not address.

### Open Question 2
Is the proposed causal intervention effective for mitigating other demographic biases, such as age or race, within depression detection models? The experimental validation is restricted to the male/female binary distinction; the acoustic correlates of other demographic groups might interact differently with pathological features.

### Open Question 3
How sensitive is the debiasing performance to the implementation of the counterfactual baseline (parameter ε) used to approximate the absence of input cues? The method assumes a global learnable parameter ε represents the model's "random guess" when input cues are removed, but the paper does not analyze if this proxy accurately simulates the counterfactual state for different acoustic backbones.

## Limitations

- The framework's effectiveness depends on accurate specification of the causal graph, particularly the assumption that the direct G→D edge exclusively represents bias
- The method assumes gender should not have direct causal effect on depression beyond acoustic features, which may not hold if gender encodes valid diagnostic information
- The additive fusion in log-space assumes independence between bias and diagnostic effects, which may not hold if interaction exists

## Confidence

- **High confidence:** Experimental results demonstrating reduced EA and improved DI/F1 scores; general approach of using counterfactual inference for bias mitigation
- **Medium confidence:** Causal graph specification (identifying G→D as the bias path); assumption that gender should not have direct causal effect
- **Low confidence:** Universal applicability to other depression detection datasets and clinical contexts; robustness when gender encodes legitimate diagnostic information

## Next Checks

1. **Clinical validity check:** Conduct expert clinician review of whether gender-related acoustic patterns removed by the method represent spurious bias or legitimate clinical signals that vary by gender

2. **Generalization test:** Apply the framework to depression detection datasets with different gender distributions and demographic compositions to verify robustness beyond DAIC-WOZ

3. **Ablation study on ε initialization:** Systematically vary ε initialization strategies and L_kl weighting to determine sensitivity and identify optimal configuration for different dataset characteristics