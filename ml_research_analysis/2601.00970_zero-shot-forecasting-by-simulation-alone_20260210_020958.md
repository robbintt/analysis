---
ver: rpa2
title: Zero-shot Forecasting by Simulation Alone
arxiv_id: '2601.00970'
source_url: https://arxiv.org/abs/2601.00970
tags:
- series
- time
- forecasting
- data
- zero-shot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses zero-shot time series forecasting, which is
  challenging due to limited real data and leakage risks. The authors propose SarSim0,
  a fast SARIMA-based simulator that generates realistic time series on-the-fly.
---

# Zero-shot Forecasting by Simulation Alone

## Quick Facts
- **arXiv ID:** 2601.00970
- **Source URL:** https://arxiv.org/abs/2601.00970
- **Reference count:** 40
- **Primary result:** Synthetic data alone can substitute for real data in zero-shot time series forecasting

## Executive Summary
This work introduces SarSim0, a SARIMA-based simulator that generates realistic time series data on-the-fly, enabling zero-shot forecasting where models are trained exclusively on synthetic data without exposure to target datasets. The key innovation is stable simulation via pole sampling rather than coefficient sampling, combined with superposition for multi-seasonality and heavy-tailed noise for burstiness. Models pretrained on SarSim0-generated data achieve strong performance on M-Series and GiftEval benchmarks, often matching or exceeding models trained on real data. Notably, on GiftEval, SarSim0-pretrained models even surpass their statistical "teacher" AutoARIMA.

## Method Summary
SarSim0 uses a three-stage pipeline: (1) stable SARIMA generation via pole sampling from the unit disk to guarantee well-behaved trajectories, (2) SARIMA-2 superposition combining base and envelope series through additive or multiplicative mixing to capture multi-scale seasonality, and (3) rate-based heavy-tailed noisers (Poisson, Gamma, Lognormal) conditioned on series level to simulate burstiness and intermittency. The simulator generates ~1B unique synthetic series on-the-fly during training, avoiding storage requirements. Models including NBEATS, PatchTST, and Chronos-Small are trained for 250k-500k steps on synthetic data only, then evaluated zero-shot on real benchmarks using multi-horizon, multi-quantile loss metrics (sCRPS, MASE).

## Key Results
- SarSim0-pretrained models match or exceed real-data-trained models on M-Series and GiftEval benchmarks
- On GiftEval, models surpass AutoARIMA "teacher" in zero-shot setting
- SARIMA-2 component identified as strongest driver of generalization (largest drop when removed)
- Heavy-tailed noise critical for capturing "erratic" domains like retail spare parts and web traffic

## Why This Works (Mechanism)

### Mechanism 1: Stability via Constrained Pole Sampling
Sampling poles directly from the unit circle stability region guarantees well-behaved synthetic trajectories, preventing the exponential divergence common in naive coefficient sampling. For AR(p) processes, this ensures roots of the characteristic polynomial lie within the unit circle, maintaining stationarity during training.

### Mechanism 2: Superposition for Multi-Scale Seasonality
Combining multiple independent SARIMA processes via additive or multiplicative modulation captures complex, hierarchical seasonality better than monolithic models. The envelope-on-carrier structure explicitly models amplitude modulation between high and low-frequency components.

### Mechanism 3: Heavy-Tailed Noise for Regime Coverage
Replacing Gaussian innovations with level-dependent, heavy-tailed noise (Poisson, Gamma, Lognormal) enables generalization to intermittent and volatile real-world domains. This ensures neural networks encounter rare but realistic extreme values during pretraining.

## Foundational Learning

**Concept: Unit Circle Stability (AR processes)**
- Why needed: To understand why the paper samples "poles" rather than coefficients
- Quick check: If you sample an AR(1) coefficient φ = 1.1, will the simulated trajectory explode or stabilize?

**Concept: Superposition/Modulation**
- Why needed: To understand the SARIMA-2 component mixing of two waveforms
- Quick check: Does multiplicative modulation (y_t = y^(b)_t · y^(e)_t) create constant variance or heteroscedasticity?

**Concept: Zero-Shot Protocol**
- Why needed: To distinguish this work from standard forecasting with target data exposure
- Quick check: If you perform a grid search on the M4 dataset to pick the best SarSim0 learning rate, are you still in a "zero-shot" regime?

## Architecture Onboarding

**Component map:** Pole Sampler → Poly Converter → SARIMA Unroller → SARIMA-2 Mixer → Noiser

**Critical path:** The sequential dependency is: Pole Sampling → Coefficient Calculation → Time Unrolling. Time unrolling cannot be vectorized over time, creating a bottleneck that's optimized by vectorizing over the batch dimension (B=256).

**Design tradeoffs:**
- AR Order (p_max): Paper uses p=10; higher orders capture more complex autocorrelation but slow simulation
- Pole Radius (r_max): 0.9 ensures stability; too close to 1.0 risks numerical instability, too small creates overly smooth series
- Simulation vs. Storage: On-the-fly generation saves disk space (1B series) but requires constant compute during training

**Failure signatures:**
- Divergent Paths: Check integration orders (d, D ≤ 1) and pole radius constraints if max values hit float32 limits
- Mode Collapse: Verify Noiser module is active and r_max isn't too small if all series look like smooth sine waves
- Slow Training: Ensure data loader generates in parallel with GPU forward passes, not sequentially

**First 3 experiments:**
1. Pole Stability Audit: Generate 1,000 series with "Naive" (coeff) vs. SarSim0 (pole) sampler; plot histogram of max absolute values
2. Ablation on Synthetic Domain: Train NBEATS on SarSim0 with only Gaussian noise vs. full SarSim0 with heavy-tailed noise on GiftEval "Sales" domain
3. Teacher-Student Gap: Run AutoARIMA (Teacher) and NBEATS-SarSim0 (Student) on M4-Monthly subset; verify student beats teacher on overlapping simulation parameters

## Open Questions the Paper Calls Out
- Under what conditions does a neural "student" trained on synthetic data surpass its statistical "teacher" (e.g., AutoARIMA), and what is the theoretical basis?
- Can hybrid training (synthetic-real co-training) outperform purely synthetic pretraining while maintaining strict zero-shot guarantees?
- How can the simulation pipeline be extended to incorporate exogenous covariates and multivariate dependencies?
- Can integration of regime-switching components (e.g., GARCH) into SarSim0 improve forecasting for series with abrupt structural breaks?

## Limitations
- The zero-shot protocol enforcement details are not fully specified, raising concerns about potential implicit dataset-specific tuning
- Simulator realism ceiling untested on domains with fundamentally different dynamics from M-Series benchmarks
- No formal generalization bounds established for synthetic-to-real transfer across all time series domains

## Confidence
- **High Confidence:** Core technical contribution (stable SARIMA simulation via pole sampling) is well-justified and empirically validated
- **Medium Confidence:** Claim of zero-shot superiority over AutoARIMA is supported but relies on proper protocol adherence
- **Low Confidence:** Broader claim that synthetic data can fully substitute for real data lacks theoretical grounding and may not extend to all domains

## Next Checks
1. Protocol Audit: Replicate zero-shot evaluation on GiftEval with strict enforcement; freeze all hyperparameters and verify no target dataset statistics used
2. Domain Transfer Test: Evaluate SarSim0-pretrained models on datasets with known structural differences (chaotic financial series, multivariate sensor data)
3. Simulator Bias Analysis: Generate synthetic series across full parameter space; compare statistical properties (ACF, spectral density, kurtosis) to real datasets to identify potential overfitting