---
ver: rpa2
title: Improving Multimodal Brain Encoding Model with Dynamic Subject-awareness Routing
arxiv_id: '2510.04670'
source_url: https://arxiv.org/abs/2510.04670
tags:
- decoder
- subject
- afire
- mind
- multimodal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AFIRE, an agnostic framework that standardizes
  multimodal fusion outputs into time-aligned tokens for brain encoding, and MIND,
  a Mixture-of-Experts decoder with a subject-aware dynamic gating module (SADGate).
  AFIRE decouples upstream fusion from downstream prediction, enabling consistent
  decoding across diverse encoders.
---

# Improving Multimodal Brain Encoding Model with Dynamic Subject-awareness Routing

## Quick Facts
- arXiv ID: 2510.04670
- Source URL: https://arxiv.org/abs/2510.04670
- Authors: Xuanhua Yin; Runkai Zhao; Weidong Cai
- Reference count: 0
- Primary result: MIND improves brain encoding prediction by 0.017-0.095 in Pearson r over baselines using fusion-agnostic decoding

## Executive Summary
This paper introduces AFIRE, an agnostic framework that standardizes multimodal fusion outputs into time-aligned tokens for brain encoding, and MIND, a Mixture-of-Experts decoder with a subject-aware dynamic gating module (SADGate). AFIRE decouples upstream fusion from downstream prediction, enabling consistent decoding across diverse encoders. MIND uses sparse Top-K routing combining token-dependent and subject-prior expert allocation to personalize decoding while maintaining stability. Evaluated on the Algonauts 2025 dataset using TRIBE, ImageBind, and Qwen2.5-Omni backbones, MIND improves Pearson r by +0.017 to +0.095, Spearman ρ by +0.019 to +0.082, R² by +0.011 to +0.038, and Inter-Subject Generalization by +0.054 to +0.065 over baselines. Results show fusion-agnostic performance and interpretable subject-specific expert usage. The framework offers a simple, plug-and-improve approach for robust cross-subject generalization in multimodal brain encoding.

## Method Summary
The framework consists of AFIRE, a lightweight interface that projects heterogeneous multimodal fusion features into a shared token space, and MIND, a sparse Mixture-of-Experts decoder with subject-aware dynamic gating. AFIRE takes TR-aligned features from diverse fusion backbones (TRIBE, ImageBind, Qwen2.5-Omni), projects them to a shared dimension D, and applies a temporal MLP with positional encoding to create standardized tokens. MIND employs a subject-specific bias matrix B and a token-dependent router to compute routing weights, combining them multiplicatively before applying Top-K sparsity. The experts are MLPs that predict parcel-level brain activity, trained end-to-end with MSE loss plus load-balancing and regularization terms. The approach enables plug-and-play across fusion backbones while maintaining personalized decoding through SADGate.

## Key Results
- MIND achieves 0.017-0.095 improvement in Pearson r over baselines across three fusion backbones
- Inter-Subject Generalization improves by 0.054-0.065 when using subject-aware routing
- Ablation confirms both token-dependent and subject-prior components contribute to performance
- Expert routing shows interpretable, subject-specific patterns correlating with content type

## Why This Works (Mechanism)

### Mechanism 1: Post-Fusion Token Standardization Enables Cross-Backbone Decoupling
Standardizing heterogeneous fusion outputs into a unified token space allows a single decoder architecture to operate across diverse multimodal backbones. AFIRE's lightweight projector maps backbone-specific features to a shared dimension D, then applies a temporal MLP with positional encoding. This creates a stable interface that insulates the decoder from upstream architectural choices, allowing gradients to flow back without backbone-specific tuning.

### Mechanism 2: Dual-Path Routing Factorizes Stable and Transient Subject Variability
Separating subject-specific expert preferences (persistent bias) from token-dependent routing (transient context) allows personalization without overfitting. SADGate computes token-dependent scores via subject-augmented embeddings, then multiplies by a subject prior derived from a global logit vector and subject-expert bias matrix. Top-K sparsity forces selective expert engagement.

### Mechanism 3: Load-Balanced Sparse MoE Prevents Expert Collapse While Enforcing Specialization
Top-K selection with load-balancing regularization encourages functional expert specialization without degenerate routing. Sparse gating limits active experts per token, creating capacity pressure that drives specialization. The load-balancing loss penalizes imbalanced expert usage, preventing scenarios where a few experts dominate.

## Foundational Learning

- **Concept: Sparse Mixture-of-Experts (MoE) Routing**
  - Why needed here: Core to MIND's subject-aware decoding; understanding Top-K selection and load balancing is essential for debugging routing behavior.
  - Quick check question: Why does Top-K selection alone risk expert collapse, and how does load-balancing loss mitigate this?

- **Concept: fMRI Temporal Alignment (TR Synchronization)**
  - Why needed here: AFIRE aggregates 2 Hz features into TR bins; misalignment breaks the encoding relationship between stimulus and response.
  - Quick check question: Given TR=0.5s and 2 Hz features, how many feature frames aggregate per TR, and what are the implications of averaging vs. sampling?

- **Concept: Subject Embedding + Bias Factorization**
  - Why needed here: SADGate injects subject identity at two points (embedding addition and prior bias); understanding their distinct roles is key to interpreting routing patterns.
  - Quick check question: If you removed the subject-expert bias matrix B and kept only the subject embedding in the token router, what behavior would you expect for ISG on a new subject?

## Architecture Onboarding

- **Component map:** Fusion backbone -> AFIRE Projector -> AFIRE Temporal MLP -> Token Router + Subject Prior Router -> SADGate Combiner -> Top-K Sparsity -> Expert Bank -> Weighted Sum -> Output

- **Critical path:**
  1. Extract per-layer features from fusion backbone (TRIBE/ImageBind/Qwen2.5-Omni)
  2. Aggregate 2 Hz frames within each TR bin (averaging)
  3. Project via AFIRE projector; apply temporal MLP
  4. For each (subject s, token z_t): compute token routing p_t and prior π(s)
  5. Combine -> Top-K -> sparse weights ŵ_t
  6. Weighted sum of expert outputs -> parcel predictions y_t
  7. MSE loss + load balancing + L2 penalty on B -> backprop end-to-end

- **Design tradeoffs:**
  - E (num experts): Capacity vs. routing complexity; paper uses E=8 (implied from Fig. 4)
  - K (active experts): Specialization vs. coverage; too small risks gaps
  - β (load balance weight): Stability vs. forced uniformity
  - λ (bias regularization): Personalization vs. generalization to new subjects
  - D (token dim): Representation capacity vs. projection bottleneck

- **Failure signatures:**
  - Expert collapse: >80% routing mass to 1-2 experts; check expert usage histogram
  - Poor ISG: Held-out subject performance near zero; may indicate overfitting to training subject priors
  - Backbone-specific gains: Large performance variance across TRIBE/ImageBind/Qwen; suggests AFIRE projection not stabilizing tokens
  - Flat routing over time: No temporal dynamics in expert weights; token router may not be learning

- **First 3 experiments:**
  1. **Baseline sanity check:** Train MIND with only token router (no subject prior) on TRIBE; verify parcel-wise r > 0.1 on average and identify high-performing regions (visual/auditory cortex expected).
  2. **Routing ablation:** Replicate Table 2—compare token-only, prior-only, and combined routing across all three backbones; confirm both components contribute.
  3. **Cross-backbone plug-and-play:** Train AFIRE+MIND on TRIBE features, freeze MIND, swap to ImageBind features (re-train only AFIRE projector); verify performance gap < 0.02 r vs. end-to-end ImageBind training.

## Open Questions the Paper Calls Out

- **Open Question 1:** Does jointly optimizing the upstream multimodal encoders with the AFIRE interface yield significant performance gains over the current frozen-encoder approach?
  - Basis: The conclusion states that future work will "jointly optimize encoders with AFIRE."
  - Why unresolved: The current methodology freezes upstream backbones and only trains the AFIRE projector and MIND decoder end-to-end.
  - What evidence would resolve it: Experiments comparing validation metrics when fine-tuning the backbone weights against the current static baseline.

- **Open Question 2:** How does the framework perform when specific input modalities are missing or when TR sampling rates vary across datasets?
  - Basis: The authors identify the need to "enhance robustness to missing modalities and variable TRs" as a key limitation.
  - Why unresolved: The current architecture assumes complete post-fusion tokens and a fixed aggregation strategy (2 Hz to TR resolution).
  - What evidence would resolve it: Ablation studies simulating modality dropout (e.g., audio missing) and evaluations on datasets with different repetition times.

- **Open Question 3:** Can the subject-aware routing mechanism be modified to provide uncertainty estimates for the predicted brain responses?
  - Basis: The paper lists "uncertainty-aware encoding" as a specific goal for future research.
  - Why unresolved: The current MIND module produces deterministic predictions without quantifying the confidence of the expert routing or final output.
  - What evidence would resolve it: Integration of probabilistic methods (e.g., Monte Carlo dropout) into the experts and analysis of calibration on ambiguous stimuli.

## Limitations

- Hyperparameter sensitivity (E, K, β, λ, D) is not explored; reported gains could be specific to exact choices rather than robust to scaling.
- Subject prior effectiveness relies on the assumption that inter-subject variability is decomposable into stable and dynamic components; this is plausible but not directly validated.
- The AFIRE projector architecture is underspecified; performance gains could be partially due to backbone-specific tuning rather than true fusion-agnostic standardization.
- The dataset (4 subjects, Algonauts 2025) is small; claims about generalization may not hold on larger, more diverse cohorts.

## Confidence

- **High confidence:** AFIRE enables plug-and-play across multimodal backbones; the framework works as described and yields measurable gains.
- **Medium confidence:** SADGate's dual-path routing meaningfully improves ISG over single-path alternatives; ablation supports this but mechanism is not deeply probed.
- **Low confidence:** The subject prior captures interpretable trait-level variability; expert usage patterns are shown but not validated as functionally meaningful.

## Next Checks

1. **Cross-backbone stability test:** Train MIND end-to-end on TRIBE features, freeze the model, and evaluate on ImageBind features (after minimal AFIRE adaptation). Measure drop in r/ρ/R²; if < 0.02, supports fusion-agnostic claim.

2. **Subject prior ablation with transfer:** Train on subjects S1-S3, evaluate on S5 with and without subject prior. If gains disappear without prior, validates its role in generalization; if not, it may be overfitting.

3. **Expert load distribution audit:** Plot expert usage histograms across tokens and subjects. If >80% tokens route to 1-2 experts, increase β and retrain; confirm load balancing is working as intended.