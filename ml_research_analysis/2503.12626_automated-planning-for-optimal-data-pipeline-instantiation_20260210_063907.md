---
ver: rpa2
title: Automated Planning for Optimal Data Pipeline Instantiation
arxiv_id: '2503.12626'
source_url: https://arxiv.org/abs/2503.12626
tags:
- data
- operators
- pipeline
- operator
- planning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the problem of optimal deployment of data pipelines
  on distributed computing clusters, specifically focusing on how to group operators
  with different runtime requirements to minimize total execution time. The authors
  model this optimization problem as planning with action costs and propose heuristic
  search methods using automated planning techniques.
---

# Automated Planning for Optimal Data Pipeline Instantiation

## Quick Facts
- arXiv ID: 2503.12626
- Source URL: https://arxiv.org/abs/2503.12626
- Reference count: 25
- This work models data pipeline deployment as planning with action costs and shows connection-based heuristics consistently minimize total execution time.

## Executive Summary
This work addresses the problem of optimal deployment of data pipelines on distributed computing clusters by grouping operators with different runtime requirements to minimize total execution time. The authors model this optimization problem as planning with action costs and propose heuristic search methods using automated planning techniques. Experiments using synthetic Fibonacci sequence workloads in sequential and parallel pipeline topologies show that connection-based grouping consistently outperforms other methods, particularly in execution time, while random grouping can outperform heuristics in parallel execution scenarios when workloads are high.

## Method Summary
The authors model data pipeline deployment as an optimization problem under constraints, where constraints are operator tags that determine compatible images. They use PDDL to encode state-space search problems with action costs representing setup time penalties and communication costs. Four approaches are implemented: two greedy heuristics (connection-based and node-based), a random baseline, and a default single-group baseline. The heuristics are encoded in PDDL and solved using the ENHSP planner. The pipeline involves converting JSON graphs to PDDL, generating planning problems, solving with ENHSP, and converting the plan back to optimized JSON for deployment on a Kubernetes cluster running SAP Data Intelligence VFlow engine.

## Key Results
- Connection-based grouping reduces total execution time by minimizing intergroup communication overhead
- Automated planning with state-dependent action costs successfully models deployment constraints as optimization problems
- Random grouping can outperform heuristics in parallel topologies when execution time gains outweigh setup overhead

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Connection-based grouping reduces total execution time by minimizing intergroup communication overhead.
- Mechanism: The connection heuristic assigns differential weights (intragroup=5, intergroup=20) to operator connections in PDDL, causing the planner to prefer groupings that keep heavily-connected operators together, reducing serialization overhead at group boundaries.
- Core assumption: Communication overhead between groups dominates total execution cost in sequential pipelines.
- Evidence anchors:
  - [abstract] "a heuristic based on connections outperforms other strategies"
  - [Section 4.1] "we use different weights for intragroup and intergroup communication, respectively 5 and 20"
  - [corpus] Weak direct corpus support; related work on automated planning heuristics exists but doesn't specifically address pipeline optimization.
- Break condition: When pipeline topology has high natural parallelism, the connection heuristic's single-group bias may reduce execution parallelism.

### Mechanism 2
- Claim: Automated planning with state-dependent action costs can model deployment constraints as optimization problems.
- Mechanism: PDDL domain encoding represents operators, tags, and images as planning state; action costs encode setup time penalties for group creation and communication costs for intergroup data transfer. The ENHSP planner searches for minimum-cost action sequences.
- Core assumption: Deployment constraints (tags, SDK requirements) and performance costs can be accurately modeled in STRIPS-style planning formalism.
- Evidence anchors:
  - [Section 3] "It is therefore an optimization problem under constraints, where the constraints are the tags of operators"
  - [Section 4] "We use PDDL to create descriptions of state-space search problems"
  - [corpus] Related work "LLMs as Planning Formalizers" confirms PDDL's applicability for structured planning but doesn't validate this specific application.
- Break condition: If state space explodes with large operator counts or complex tag combinations, planner performance may degrade.

### Mechanism 3
- Claim: Random grouping can outperform heuristics in parallel topologies when execution time gains outweigh setup overhead.
- Mechanism: Random grouping creates more groups, enabling greater parallelism in execution; when workload per operator is high (large Fibonacci step), the execution speedup compensates for increased setup time from multiple group instantiations.
- Core assumption: Parallel execution speedup scales linearly with group count for independent pipeline branches.
- Evidence anchors:
  - [Section 6.3] "the random approach creates many groups that are capable of executing the processing steps in parallel"
  - [Section 7] "the random strategy with more groups has the best results for the parallel topology"
  - [corpus] No direct corpus support for this specific trade-off pattern.
- Break condition: When setup time dominates (cold starts, low workloads), random grouping's overhead becomes prohibitive.

## Foundational Learning

- Concept: **PDDL (Planning Domain Definition Language)**
  - Why needed here: Core formalism for encoding pipeline optimization as planning; understanding STRIPS-style actions and state transitions is prerequisite to modifying the domain definitions.
  - Quick check question: Can you explain how an action's preconditions and effects define valid state transitions in PDDL?

- Concept: **Flow-based programming and operator graphs**
  - Why needed here: The optimization target is a DAG of operators; understanding edges as data flow and nodes as transformation units is essential for reasoning about grouping strategies.
  - Quick check question: Given a pipeline with operators A→B→C and A→D→C, which pairs would benefit most from co-location in the same group?

- Concept: **Container orchestration overhead (Kubernetes/Docker)**
  - Why needed here: Setup time penalties come from container image pulls and pod instantiation; this drives the cost model for group creation decisions.
  - Quick check question: Why might minimizing group count reduce total deployment time even if execution parallelism is reduced?

## Architecture Onboarding

- Component map:
  VFlow Graph (JSON) → JSON-to-PDDL Converter → PDDL Domain + Problem files → ENHSP Planner → Plan (grouping actions) → Plan-to-JSON Converter → Optimized VFlow Graph → Kubernetes Cluster Execution

- Critical path:
  1. Tag constraint validation (operators must match image capabilities)
  2. PDDL problem generation (encoding current graph topology)
  3. Planner execution (search for minimum-cost grouping)
  4. Plan interpretation (extract group assignments from action sequence)
  5. Container instantiation (setup time bottleneck)

- Design tradeoffs:
  - **Connection heuristic**: Lower setup time, fewer groups, better for sequential pipelines; may sacrifice parallelism
  - **Node heuristic**: Minimizes groups but ignores communication patterns; highest intergroup overhead
  - **Random**: Maximum parallelism potential, high setup overhead; best for heavy parallel workloads after warmup
  - **Default (single group)**: Minimal setup, no parallelism; fails when tag constraints require multiple images

- Failure signatures:
  - **Cold start timeout**: Random heuristic creating too many groups; check Fibonacci step parameter (workload size)
  - **Tag constraint violation**: Planner returns no solution; verify all operator tags have matching images in available set
  - **High intergroup latency**: Connection heuristic producing too many groups in complex topology; check special_ops count
  - **No speedup despite parallelism**: Default grouping used; verify PDDL plan is being applied to deployment

- First 3 experiments:
  1. Reproduce line topology with fibo_step=1, special_ops=2; verify connection heuristic outperforms random in total time (setup should dominate)
  2. Run parallel topology with fibo_step=3, special_ops=4; confirm random heuristic achieves lower execution time but higher setup; observe crossover point
  3. Introduce new special tag with no matching image; verify planner returns no solution and system reports constraint violation (not silent failure)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can a hybrid strategy optimize parallel topologies by treating individual lines independently?
- Basis in paper: [explicit] The authors state "A hybrid strategy could also be explored to optimize each line of the parallel topology individually."
- Why unresolved: Current heuristics apply globally, but the random baseline sometimes outperformed them in parallel setups by creating more groups, suggesting topology-specific decomposition is needed.
- Evidence: Implementation of a planner that decomposes a parallel graph into sequential sub-problems to apply the connection heuristic locally.

### Open Question 2
- Question: How does optimizing for Total Cost of Ownership (TCO) or infrastructure cost alter the optimal grouping strategy?
- Basis in paper: [explicit] "In future work, we could evaluate grouping strategies based on TCO metrics that measure the total performance time per dollar."
- Why unresolved: The current model minimizes execution time, ignoring the monetary costs associated with the number of pods or resource usage in a cloud environment.
- Evidence: Experiments using a modified cost function in the PDDL domain that includes infrastructure pricing models alongside execution time.

### Open Question 3
- Question: How does the grouping strategy impact the resilience and fault tolerance of the deployed graph?
- Basis in paper: [explicit] Section 7 lists "the resilience of the deployed graph" as a desirable evaluation metric to include in future work.
- Why unresolved: Minimizing connections (creating fewer groups) might create single points of failure, but this trade-off between efficiency and reliability has not been measured.
- Evidence: Fault injection experiments comparing the recovery time of dense (few groups) versus sparse (many groups) pipeline configurations.

## Limitations
- Evaluation uses synthetic Fibonacci pipelines with fixed operator counts, limiting scalability insights
- PDDL encoding details and specific state transitions are not fully specified
- Connection heuristic's weight choices appear arbitrary without sensitivity analysis
- Study focuses solely on setup and execution time, ignoring resource utilization metrics

## Confidence
- **High**: Connection heuristic consistently outperforms others in sequential topologies; automated planning framework successfully models grouping as optimization
- **Medium**: Random heuristic superiority in parallel topologies with high workloads; the trade-off between setup time and execution parallelism
- **Low**: Generalizability to complex, heterogeneous real-world pipelines; sensitivity of weight parameters; performance on larger operator graphs

## Next Checks
1. Test the connection heuristic with varying weight ratios (3:1 to 10:1) to identify optimal parameter sensitivity
2. Scale experiments to 50+ operator pipelines with realistic branching factors and measure planner runtime
3. Implement resource-aware cost modeling (CPU/memory) in PDDL and compare against time-only optimization