---
ver: rpa2
title: 'Characterizing Bias: Benchmarking Large Language Models in Simplified versus
  Traditional Chinese'
arxiv_id: '2505.22645'
source_url: https://arxiv.org/abs/2505.22645
tags:
- chinese
- names
- name
- traditional
- simplified
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Large Language Models (LLMs) exhibit differential performance when
  prompted in Simplified versus Traditional Chinese, with most models favoring Simplified
  Chinese regional terms and Traditional Chinese names. This bias is partially explained
  by training data imbalances, character-level preferences, and tokenization differences
  between scripts.
---

# Characterizing Bias: Benchmarking Large Language Models in Simplified versus Traditional Chinese

## Quick Facts
- arXiv ID: 2505.22645
- Source URL: https://arxiv.org/abs/2505.22645
- Reference count: 40
- Primary result: Large Language Models (LLMs) exhibit differential performance when prompted in Simplified versus Traditional Chinese, with most models favoring Simplified Chinese regional terms and Traditional Chinese names.

## Executive Summary
This paper systematically benchmarks 11 leading Large Language Models (LLMs) on their ability to handle Simplified Chinese (SC) and Traditional Chinese (TC) scripts across two real-world tasks: regional term choice and regional name choice. The study reveals that most LLMs show a bias toward Simplified Chinese regional terms and Traditional Chinese names, even when prompted in the opposite script. The authors attribute this bias to three main factors: training data imbalances, character-level token preferences, and tokenization differences between scripts. To enable reproducible evaluations, the authors release an open-sourced dataset (SC-TC-Bench) and call for further research into equitable tokenization methods and balanced training data for cross-linguistic applications.

## Method Summary
The study benchmarks 11 LLMs across two tasks using the SC-TC-Bench dataset: (1) Regional Term Choice—LLMs select the correct regional term variant (SC or TC) for a given definition, and (2) Regional Name Choice—LLMs select one name from a list of 20 candidates (10 Mainland Chinese, 10 Taiwanese) for a hiring scenario. The authors run 15 trials per term prompt and 100 trials with randomized candidate lists for names. They evaluate bias by comparing model outputs to the prompting script and conduct controlled experiments to isolate the effects of training data frequency, character token probabilities, and tokenization differences. Corpus frequency analysis and token generation probability measurements are used as proxies to explain observed biases.

## Key Results
- Most LLMs favor Simplified Chinese regional terms when prompted in Traditional Chinese, and vice versa.
- LLMs show a preference for Traditional Chinese names in the hiring task, even when Mainland Chinese names are equally qualified.
- The bias is partially explained by training data imbalances, character-level token preferences, and tokenization differences between scripts.
- The study releases SC-TC-Bench, an open-sourced dataset for reproducible cross-linguistic bias evaluation.

## Why This Works (Mechanism)

### Mechanism 1: Training Data Imbalance Drives Regional Term Bias
LLMs disproportionately produce Simplified Chinese regional terms because corresponding Traditional Chinese variants are underrepresented in their training corpora. Models learn statistical associations between definitions and terms. When a term's Simplified Chinese form appears far more frequently than its Traditional Chinese counterpart in the training data, the model's learned association favors the Simplified variant, even when prompted in Traditional Chinese. The frequency of a term in publicly accessible text corpora is a reliable proxy for its frequency in an LLM's training data.

### Mechanism 2: Character-Level Token Probability Biases Name Selection
LLMs' preferences for specific characters, quantifiable via token generation probabilities, partially explain their tendency to favor certain regional names (e.g., Taiwanese names in this study). When generating names, the model's decision is influenced by the relative probability of generating each character in the sequence. Characters that consistently receive higher generation probabilities (a learned "preference") make names containing them more likely to be selected, independent of the name's regional origin or popularity. A higher token generation probability for a character equates to the model having a learned preference for that character, which causally influences selection tasks.

### Mechanism 3: Script-Specific Tokenization Fragmentation Affects Semantic Representation
Differences in how tokenizers segment the same name written in Simplified vs. Traditional Chinese contribute to selection bias by affecting the model's internal representation of the name. Traditional Chinese characters are often more complex and sometimes less common in training data. Tokenizers may therefore fragment a Traditional Chinese name into more tokens than its Simplified Chinese equivalent. This over-fragmentation can lead to a "diluted" or less coherent semantic representation in the model, making the name less likely to be selected in a context requiring semantic evaluation (like the hiring prompt). A name represented by more tokens in a sequence has a less semantically robust representation, making it less likely to be selected as a strong candidate in a context-dependent choice.

## Foundational Learning

- **Concept: Chinese Script Variants (Simplified vs. Traditional)**
  - Why needed here: The entire paper's premise rests on understanding that these are not merely different fonts but distinct writing systems with regional, cultural, and political associations. They use different character sets for some words and different vocabulary for the same concepts.
  - Quick check question: Can you name one reason beyond visual complexity why an LLM might process "网络" (Simplified) differently from "網絡" (Traditional)?

- **Concept: Subword Tokenization in LLMs**
  - Why needed here: The bias analysis for the name-choice task hinges on understanding how tokenizers break text into units. The number and type of tokens for a name can affect the model's output probability and "attention" to that name.
  - Quick check question: How might a tokenizer's vocabulary, built from a predominantly Simplified Chinese corpus, behave differently when processing a Traditional Chinese name?

- **Concept: Corpus Bias and Proxy Evaluation**
  - Why needed here: The paper uses public text corpora as *proxies* for proprietary LLM training data to explain biases. Understanding this method—its value and its limitations—is critical to evaluating the strength of the "training data imbalance" claim.
  - Quick check question: What is the primary limitation of using Common Crawl or Wikipedia as a proxy for an LLM like GPT-4's training dataset?

## Architecture Onboarding

- **Component map:** Benchmark Datasets (SC-TC-Bench) -> Prompting Engine -> Model Suite (11 LLMs) -> Evaluation & Analysis Pipeline
- **Critical path:** Data Curation -> Prompt Construction -> Model Inference -> Quantitative Analysis -> Root Cause Investigation
- **Design tradeoffs:** Generalizability vs. Specificity (focus on Mainland China vs. Taiwan); Task Realism vs. Controllability (simplified hiring prompt); Proxy Use vs. Direct Evidence (public corpora for training data).
- **Failure signatures:** Task-Dependent Bias (bias direction flips between tasks); Inconsistent Performance Across Prompts (small changes cause significant shifts); Low Instruction Adherence (some models refuse or output invalid responses).
- **First 3 experiments:**
  1. Replicate the core benchmark: Run the 110 regional term prompts in both Simplified and Traditional Chinese on a new LLM not in the study. Calculate the "misaligned response rate" for Traditional Chinese prompts to see if the bias holds.
  2. Isolate tokenization effect: Take the 6 "same-name, different-script" name pairs from the study. Present them in a neutral, non-hiring context (e.g., "Which name is more pleasant?") and measure selection rates to test if the script bias persists without the semantic hiring frame.
  3. Test the character preference hypothesis: Using the paper's methodology, measure the token generation probability for the last names of 5 popular Mainland Chinese and 5 popular Taiwanese names not in the original dataset. See if the probability correlates with their selection rates in a new name-choice experiment.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent are the observed biases the result of the independent effects of training data representation, character-level preferences, and tokenization differences, versus the result of complex interactions among these three factors?
- Basis in paper: The Discussion section states: "Although we discuss multiple contributing factors... these factors are deeply intertwined in practice, making it challenging to isolate their individual effects. We identify this as an important avenue for future research."
- Why unresolved: The current study identifies these three factors as partial explanations but does not disentangle their confounding relationships (e.g., training data informing tokenizer design) to determine their relative weights.
- What evidence would resolve it: Ablation studies on controlled LLMs where specific variables (e.g., tokenizer type, corpus frequency) are isolated while others are held constant.

### Open Question 2
- Question: Does the differential performance and bias observed between Simplified and Traditional Chinese generalize to other Traditional Chinese variants, specifically those used in Hong Kong and Macau?
- Basis in paper: Section 2.1.1 and Section 5 explicitly limit the scope: "we leave the examination of the terms used in other regions such as Hong Kong and Macau to future work."
- Why unresolved: The study restricted its dataset and analysis to regional terms and names specific to Mainland China and Taiwan, excluding other significant regions where Traditional Chinese is standard.
- What evidence would resolve it: Extending the SC-TC-Bench dataset to include regional terms and naming conventions specific to Hong Kong and Macau and re-evaluating the models.

### Open Question 3
- Question: Can the specific bias favoring Traditional Chinese names in the selection task be mitigated through the development of equitable tokenization methods that prevent the fragmentation of Traditional Chinese characters?
- Basis in paper: The "Calls to Action" section states: "We call for... more research into tokenization methods for different script systems with an eye towards equity."
- Why unresolved: The paper identifies tokenization fragmentation of Traditional Chinese names as a likely driver of the bias but does not propose or test a modified tokenizer to solve the issue.
- What evidence would resolve it: A comparative study using models re-trained or fine-tuned with script-agnostic tokenizers that yield similar token counts for equivalent names in both scripts.

## Limitations

- The study relies on public datasets as proxies for proprietary LLM training data, introducing uncertainty about the strength of causal claims.
- The claim that character-level token generation probabilities causally explain name selection bias is only partially supported by correlation data.
- Results are based on Mainland China versus Taiwan terms and names, limiting generalizability to other Chinese-speaking regions like Hong Kong and Macau.
- Some models show high rates of invalid responses or refusals, suggesting they may be optimized for different task types and complicating fair comparison.

## Confidence

- **High Confidence:** The observation that LLMs show systematic bias between Simplified and Traditional Chinese in both tasks is well-supported by multiple trials (15-100 per prompt) across 11 diverse models.
- **Medium Confidence:** The explanation that training data imbalance drives term bias is supported by corpus analysis but relies on proxy data.
- **Low Confidence:** The claim that character-level token generation probabilities causally explain name selection bias is the weakest, as it is only partially supported by correlation data.

## Next Checks

1. **Cross-region extension test:** Replicate the benchmark using Hong Kong and Macau regional terms/names to test whether the bias patterns hold across different Chinese-speaking regions and whether they align with or diverge from Mainland China/Taiwan patterns.

2. **Tokenizer audit:** Conduct a detailed semantic analysis of names tokenized differently across scripts (e.g., using BERTScore or similar metrics) to empirically validate whether higher token counts correlate with reduced semantic coherence, strengthening the tokenization hypothesis.

3. **Training data verification:** For one open-source model (e.g., Qwen or Llama), obtain and analyze its actual training corpus composition for Simplified vs. Traditional Chinese regional terms to directly test whether observed biases match training data frequencies, moving beyond proxy data assumptions.