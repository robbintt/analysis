---
ver: rpa2
title: On the Theoretical Limitations of Embedding-Based Retrieval
arxiv_id: '2508.21038'
source_url: https://arxiv.org/abs/2508.21038
tags:
- embed
- embedding
- arxiv
- retrieval
- documents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper connects theoretical results from communication complexity
  theory to the fundamental limitations of vector embeddings in information retrieval.
  The authors prove that the number of top-k document subsets that can be returned
  by an embedding-based model is bounded by the embedding dimension.
---

# On the Theoretical Limitations of Embedding-Based Retrieval

## Quick Facts
- arXiv ID: 2508.21038
- Source URL: https://arxiv.org/abs/2508.21038
- Reference count: 31
- Primary result: Single-vector embedding models are fundamentally limited by embedding dimension; they cannot represent all possible top-k document subsets for complex retrieval tasks.

## Executive Summary
This paper establishes theoretical limits on embedding-based retrieval by connecting communication complexity theory to the representational capacity of vector embeddings. The authors prove that the number of distinct top-k document subsets that can be returned by an embedding model is bounded by the embedding dimension, not the number of documents. They validate this through free-parameter optimization experiments and demonstrate practical limitations using a synthetic dataset called LIMIT, which requires representing all combinations of document attributes. The results show that as retrieval tasks become more complex, single-vector embedding models reach fundamental geometric limits, suggesting the need for alternative approaches like multi-vector or sparse models.

## Method Summary
The authors establish theoretical bounds by connecting sign rank of the relevance matrix to embedding dimension requirements. They validate this by directly optimizing unconstrained vector embeddings (treating vectors as free parameters) to fit specific relevance patterns, establishing a "critical-n" point where optimization fails. For empirical validation, they create the LIMIT dataset containing 50k documents with person names and attributes, constructing queries that test all possible combinations of attribute pairs. They evaluate both their free embedding optimization and state-of-the-art embedding models (GritLM, Qwen3 Embed, Gemini 2.5 Pro, etc.) on this dataset, measuring recall@k across different embedding dimensions.

## Key Results
- The number of top-k subsets representable by d-dimensional embeddings is fundamentally limited by d, not the number of documents
- Free embedding optimization fails to achieve 100% accuracy beyond a "critical-n" point that scales polynomially with dimension
- On the LIMIT dataset, even state-of-the-art models struggle to achieve more than 20% recall@100 on complex queries requiring combinatorial reasoning
- Sparse retrieval models (BM25, GTE-ModernColBERT) maintain high performance on complex queries where dense embeddings fail

## Why This Works (Mechanism)

### Mechanism 1: Sign Rank Bounds on Representable Subsets
- **Claim:** If a retrieval task requires representing a specific set of top-$k$ relevant documents for queries, and the "sign rank" of the ground-truth relevance matrix exceeds the embedding dimension $d$, then a single-vector embedding model cannot perfectly solve the task.
- **Mechanism:** The paper connects the minimum embedding dimension required to linearly separate relevant from irrelevant documents to the **sign rank** of the binary relevance matrix (qrel). A single vector in $\mathbb{R}^d$ defines a hyperplane. The number of distinct top-$k$ subsets that can be carved out by these hyperplanes is fundamentally limited by $d$. If the qrel matrix has a high sign rank (implying complex, non-linearly-separable combinations of relevant documents), low-dimensional embeddings fail.
- **Core assumption:** The retrieval model uses a single vector per query/document and relies on dot product (linear separation) for ranking.
- **Evidence anchors:**
  - [