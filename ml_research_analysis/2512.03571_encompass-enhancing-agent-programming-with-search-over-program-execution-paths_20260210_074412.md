---
ver: rpa2
title: 'EnCompass: Enhancing Agent Programming with Search Over Program Execution
  Paths'
arxiv_id: '2512.03571'
source_url: https://arxiv.org/abs/2512.03571
tags:
- state
- code
- search
- agent
- score
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces EnCompass, a Python framework for agent programming
  that separates core workflow logic from inference-time scaling strategies through
  probabilistic angelic nondeterminism. By marking unreliable operations with branchpoints
  and compiling agent programs into searchable execution paths, EnCompass enables
  flexible experimentation with search strategies like beam search and Monte Carlo
  tree search without modifying core agent logic.
---

# EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths

## Quick Facts
- arXiv ID: 2512.03571
- Source URL: https://arxiv.org/abs/2512.03571
- Reference count: 40
- Primary result: 3-6x code reduction with superior inference-time scaling via search over execution paths

## Executive Summary
EnCompass is a Python framework that separates agent workflow logic from inference-time scaling strategies through probabilistic angelic nondeterminism. By marking unreliable operations with `branchpoint()` markers and compiling agent programs into searchable execution paths, EnCompass enables flexible experimentation with search strategies like beam search and Monte Carlo tree search without modifying core agent logic. Three case studies demonstrate superior performance: beam search outperforms simpler sampling methods in code repository translation, global best-of-N sampling improves accuracy in hypothesis search, and reexpand best-first search scales more cost-efficiently than iterative refinement in Reflexion. The framework achieves 3-6x code reduction compared to plain Python implementations while enabling previously difficult-to-implement strategies.

## Method Summary
EnCompass uses a Python decorator `@encompass.compile` to transform agent functions into Continuation-Passing Style (CPS), creating a searchable execution tree. Programmers mark unreliable operations with `branchpoint()` calls, which pause execution and return `Checkpoint` objects containing the current state. Search algorithms traverse this tree using `Checkpoint.step()` to explore different execution paths, guided by `record_score()` signals. The framework supports memory sharing across branches via `NoCopy` annotations for iterative refinement patterns. Three case studies validate the approach: code translation with self-validation, ARC-AGI reasoning with hypothesis search, and LeetCode problem solving with reexpand best-first search.

## Key Results
- 3-6x code reduction compared to plain Python implementations
- Beam search achieves 2-3x higher self-validation rates than global best-of-N in code translation
- Reexpand best-first search provides 1.5-2x better pass rate per cost than iterative refinement in Reflexion
- Global best-of-N sampling improves ARC-AGI accuracy by 15-20% over local sampling

## Why This Works (Mechanism)

### Mechanism 1: Branchpoint-driven Search Space Construction
The EnCompass framework separates agent workflow definition from inference-time search strategies by using `branchpoint()` markers to dynamically create a searchable execution tree. The `@encompass.compile` decorator transforms the function into Continuation-Passing Style (CPS) representation. Each `branchpoint()` call stops execution and returns a `Checkpoint` object (encapsulating the current `frame`, `info`, and continuation `rest`). A search algorithm can then repeatedly call `Checkpoint.step()` to sample different child states from that branchpoint, effectively exploring multiple possible futures.

### Mechanism 2: Inference-time Scaling via Configurable Search
Different inference-time strategies (Best-of-N, Beam Search, Refinement) are instantiations of search over the execution path tree, configurable via simple parameters. The search space defined by branchpoints can be traversed by different algorithms. By selecting an algorithm (e.g., "dfs", "beam") and its parameters (e.g., `beam_width`, `branching_factor`), the runtime explores the tree differently. Beam Search interpolates between local and global Best-of-N, balancing local verification with global variety.

### Mechanism 3: Angelic Nondeterminism with Memory Sharing
EnCompass supports iterative refinement and backtracking with memory by allowing shared state (`NoCopy`) across parallel execution branches. The `var: NoCopy` annotation signals the compiler not to deep-copy a variable when creating a new execution branch. This allows child branches to share a reference to the same mutable object (e.g., a list of feedbacks). When one branch modifies it, other branches can see the update, enabling patterns where later attempts build on earlier feedback.

## Foundational Learning

- **Concept: Continuation-Passing Style (CPS)**
  - Why needed here: The EnCompass compiler transforms user code into CPS to make the control flow explicit. Understanding CPS is essential to grasp how the decorator captures the program's state and "future" (the rest of the code) into a `Checkpoint` object.
  - Quick check question: How does converting a function to CPS allow an external function (like a search algorithm) to take control of the execution flow?

- **Concept: Tree Search Algorithms (BFS, DFS, Beam Search, MCTS)**
  - Why needed here: The paper frames inference-time scaling as a search problem over a tree of execution paths. To use EnCompass, one must understand how these algorithms explore a tree and how their parameters (e.g., `beam_width`) control the exploration-exploitation trade-off.
  - Quick check question: In a tree of possible agent actions, how does a Beam Search with a beam width of 3 differ from a Breadth-First Search?

- **Concept: State Management and Deep Copying**
  - Why needed here: EnCompass's `branchpoint()` mechanism relies on creating independent copies of the program state for each branch. Understanding deep vs. shallow copying is critical to understanding the `NoCopy` feature and avoiding unintended side effects between branches.
  - Quick check question: What is the potential problem if a mutable object (like a list) is shared between two branches of execution without proper copying or explicit `NoCopy` intent?

## Architecture Onboarding

- **Component map:**
  - `@encompass.compile` Decorator -> Compiler -> CPS transformation
  - branchpoint() -> Checkpoint creation -> Program state capture
  - SearchSpace -> .search() interface -> Algorithm selection
  - Checkpoint -> .step() method -> Execution continuation
  - record_score() -> Search guidance -> Performance evaluation

- **Critical path:**
  1. User annotates a function with `@encompass.compile` and inserts `branchpoint()` calls
  2. User invokes the function with arguments, creating a `SearchSpace` object
  3. User calls `.search("beam", ...)` on the `SearchSpace`
  4. The search algorithm gets an initial `Checkpoint` from `SearchSpace.start()`
  5. The algorithm repeatedly calls `Checkpoint.step()` to expand nodes, using scores to guide which nodes to explore, and finally returns the result from the best-performing path

- **Design tradeoffs:**
  - Readability vs. Control: EnCompass prioritizes readable workflow code but places search control in the framework's algorithms, unlike a hand-coded state machine
  - Generality vs. Complexity: The PAN model is highly general, but requires understanding its compiler and state management model
  - Memory vs. Parallelism: The `NoCopy` feature enables sophisticated patterns but complicates parallel execution due to shared mutable state

- **Failure signatures:**
  - Unintended State Sharing: A mutable variable is modified in one branch, affecting another unexpectedly. Fix: Use `var: NeedsCopy` (default) or ensure deep copies
  - Sparse Rewards: Search algorithm fails to find good paths because `record_score()` provides a poor signal. Fix: Add more granular intermediate scoring
  - Performance Bottleneck: Search is too slow. Fix: Reduce `beam_width` or `branching_factor`

- **First 3 experiments:**
  1. Implement a simple agent (e.g., from Sec 3.1) with one `branchpoint()` and use `.search("dfs", ...)` to verify it samples multiple outputs and selects the best one based on a simple `record_score`
  2. On a small task (e.g., from Case Study 2), run the same agent with two different search strategies: `search("dfs", ...)` (global Best-of-N) and `search("beam", ...)`. Compare performance and cost
  3. Implement a simple refinement loop using a `NoCopy` list for feedback. Use a search algorithm that benefits from this (e.g., Best-of-N with refinement) and verify the shared feedback works by logging its contents across branches

## Open Questions the Paper Calls Out

- **Open Question 1:** Can EnCompass be extended to support "LLM+program-in-control" hybrid agents where the LLM writes the agent code? The authors explicitly identify interest in exploring EnCompass for hybrid architectures where an LLM writes programs implementing inference-time strategies.

- **Open Question 2:** Can branchpoint placement and reward signal generation be automated to remove the need for manual code annotations? The Limitations section suggests EnCompass could be improved to "eliminate the need for source code modifications" by solving the challenge of choosing branchpoints and rewards.

- **Open Question 3:** Do search strategies that utilize dynamic sampling (beyond fixed branching factors) offer superior performance within the EnCompass framework? Section 2.1 states it is worth exploring search strategies beyond fixing the branching factor, noting the current dominance of graph search adaptations.

## Limitations
- No public implementation available - EnCompass described as "Company code" preventing independent validation
- Limited ablation studies - effectiveness of PAN model vs simpler alternatives not rigorously compared
- Search space complexity not characterized - potential exponential blowup with multiple branchpoints

## Confidence

- **High**: Core mechanism of using branchpoints for search space construction; 3-6x code reduction claim; basic beam search vs DFS comparison
- **Medium**: Performance comparisons across case studies (beam search outperforming other methods, reexpand best-first scaling benefits); effectiveness of NoCopy pattern
- **Low**: Claims about EnCompass enabling "previously difficult-to-implement" strategies; generalizability beyond demonstrated domains

## Next Checks

1. Implement a minimal EnCompass clone from the CPS compilation description in Section C and verify the branchpoint mechanism works as claimed
2. Run controlled experiments comparing beam search vs global best-of-N on a simple synthetic task with known optimal solutions to quantify the "interpolation" benefit
3. Profile memory usage and execution time scaling with increasing numbers of branchpoints to characterize practical limits of the search space size