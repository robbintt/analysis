---
ver: rpa2
title: Neurosymbolic Decision Trees
arxiv_id: '2503.08762'
source_url: https://arxiv.org/abs/2503.08762
tags:
- neural
- learning
- tests
- decision
- probabilistic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces neurosymbolic decision trees (NDTs) and NeuID3,
  a novel structure learning algorithm that combines neural networks with symbolic
  logic. NDTs extend probabilistic decision trees by using neural networks to parameterize
  probabilities, enabling both symbolic and subsymbolic data (e.g., images) as features.
---

# Neurosymbolic Decision Trees

## Quick Facts
- arXiv ID: 2503.08762
- Source URL: https://arxiv.org/abs/2503.08762
- Reference count: 40
- Primary result: Neurosymbolic Decision Trees (NDTs) with NeuID3 outperform standard MLPs, especially on image-based data, by integrating neural networks with symbolic logic

## Executive Summary
Neurosymbolic Decision Trees (NDTs) extend probabilistic decision trees by parameterizing probabilities with neural networks, enabling both symbolic and subsymbolic (e.g., image) data as features. The NeuID3 algorithm learns NDT structure from scratch using a weighted cross-entropy loss and fractional information gain for test selection. Experiments demonstrate NDTs significantly outperform standard neural networks when binary features are replaced with images, and benefit from incorporating background knowledge through neurosymbolic rules.

## Method Summary
NeuID3 learns NDT structure through iterative top-down induction, where neural tests are trained using weighted cross-entropy loss and selected based on fractional information gain. The approach translates NDTs into DeepProbLog programs for inference, handling fractional examples through probabilistic logic programming. Neural tests are parameterized networks that classify feature values, with the algorithm simultaneously learning both structure and parameters while incorporating background knowledge through predefined neurosymbolic rules.

## Key Results
- NDTs outperform MLPs when binary features are replaced with MNIST images (UCI MNIST experiments)
- Background knowledge incorporation through neurosymbolic rules improves learning efficiency and accuracy
- NDTs maintain competitive accuracy on symbolic data while extending to subsymbolic features
- The approach successfully learns interpretable tree structures for the Eleusis card game benchmark

## Why This Works (Mechanism)
NDTs combine the interpretability of decision trees with the feature extraction power of neural networks by using neural networks to parameterize test outcomes at internal nodes. The weighted cross-entropy loss handles fractional examples from probabilistic inference, while fractional information gain provides a principled way to select tests in the presence of uncertainty. The neurosymbolic framework allows background knowledge to be encoded as logic rules, guiding the learning process toward more efficient and interpretable solutions.

## Foundational Learning
- **Probabilistic Logic Programming (e.g., ProbLog/DeepProbLog)**: NDTs are implemented by translating them into DeepProbLog programs. You must understand concepts like probabilistic facts, logic programs as probability distributions, and how inference (weighted model counting) computes query probabilities. Quick check: Given a probabilistic fact `0.8 :: rain` and a rule `wet :- rain`, what is P(wet)?
- **Decision Tree Learning (e.g., ID3 Algorithm)**: NeuID3 is an extension of top-down decision tree induction. You need to understand the core loop: selecting the best attribute to split on based on a metric like information gain, creating child nodes, and recursing. Quick check: What is the primary criterion ID3 uses to choose the best attribute for a split?
- **Gradient-Based Training of Neural Networks**: The "neural tests" in an NDT are neural networks whose weights must be learned. The paper uses a weighted cross-entropy loss and requires backpropagation through the logic program's inference. Quick check: How does a weighted cross-entropy loss differ from a standard cross-entropy loss, and why might it be used?

## Architecture Onboarding

**Component map**:
Input -> NeuID3 Learner -> Test Trainer -> Test Scorer -> DeepProbLog Oracle -> NDT Model (Output)

**Critical path**:
1. Initialization: Start with a single leaf node
2. Recursive Induction (at each node):
   a. Train all available neural tests on the node's subset of data
   b. Score all tests (neural and symbolic) using the fractional information gain (fIG)
   c. Select the highest-scoring test
   d. Create two child nodes based on the test and recurse
3. Inference: For a new example, evaluate all neural tests along the paths, compute the probability of reaching each leaf, and aggregate the leaf class distributions

**Design tradeoffs**:
- Interpretability vs. Power: A tree with only simple symbolic facts is highly interpretable but may have low accuracy on raw data. Adding neural facts/rules increases power but makes tests less transparent
- Pre-defined Tests vs. Learning from Scratch: Providing a rich set of relevant neurosymbolic rules can greatly accelerate learning and improve accuracy, but requires domain expertise
- Structure vs. Parameter Learning: This system learns both simultaneously, which is more flexible than systems that require a fixed structure but is computationally more expensive than pure parameter learning

**Failure signatures**:
- Performance collapse to default: If neural predicates fail to learn, the model's accuracy may drop to the frequency of the most common class
- Failure to generalize: The model may overfit to training data if the tree becomes too deep or if neural tests memorize examples
- Runaway computation: If the test set T is too large, training all neural tests at every node will be prohibitively slow
- Suboptimal structure: Greedy search may create a suboptimal tree if early split choices hide more globally important features

**First 3 experiments**:
1. Sanity Check on Symbolic Data: Recreate a classic UCI experiment using only symbolic features to verify NeuID3 produces comparable performance to standard decision trees
2. Subsymbolic Integration Test: Use UCI MNIST setup where binary features are replaced by images, comparing NDT's performance against a standard MLP
3. Background Knowledge Ablation: Replicate the Eleusis experiment comparing T_nf (neural facts only) vs. T_opt (with tailored neurosymbolic rules) to demonstrate benefits of background knowledge

## Open Questions the Paper Calls Out
- How can established decision tree extensions like pruning or ensemble methods be effectively integrated into the NDT framework?
- Can the computational efficiency of NeuID3 be improved to close the significant gap in training time compared to standard neural networks?
- How does extending the current propositional logic implementation of NDTs to First-Order Logic affect the tractability of inference and learning processes?

## Limitations
- Computational overhead: Training takes several hours for small datasets, orders of magnitude slower than standard neural networks
- Neural architecture unspecified: The exact neural network architectures used in tests are not fully specified
- Scalability concerns: The approach may not scale well to larger, more complex datasets due to computational requirements

## Confidence

**High Confidence**: The core methodology of combining neural networks with symbolic decision trees is sound and well-implemented. The theoretical framework (fractional information gain, weighted cross-entropy) is clearly defined.

**Medium Confidence**: The experimental results showing performance improvements are likely valid, but the magnitude of these improvements may be dataset-dependent. The scalability claims are concerning.

**Low Confidence**: The practical applicability of this approach to real-world problems due to the computational overhead and the need for carefully curated background knowledge.

## Next Checks
1. Scalability Test: Measure training time and memory usage on progressively larger UCI datasets to quantify computational overhead and identify breaking points
2. Architecture Sensitivity: Systematically vary neural network architectures (depth, width, activation functions) in tests to determine impact on performance and training time
3. Background Knowledge Dependency: Conduct an ablation study on the Eleusis dataset, systematically removing neurosymbolic rules from T_opt to quantify the exact contribution of background knowledge to final performance