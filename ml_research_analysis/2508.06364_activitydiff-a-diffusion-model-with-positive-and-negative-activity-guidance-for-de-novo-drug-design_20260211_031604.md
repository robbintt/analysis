---
ver: rpa2
title: 'ActivityDiff: A diffusion model with Positive and Negative Activity Guidance
  for De Novo Drug Design'
arxiv_id: '2508.06364'
source_url: https://arxiv.org/abs/2508.06364
tags:
- molecules
- target
- guidance
- generation
- drug
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes ActivityDiff, a diffusion model with Positive
  and Negative Activity Guidance for De Novo Drug Design. The method leverages separately
  trained drug-target classifiers for both positive and negative guidance, enabling
  the model to enhance desired activities while minimizing harmful off-target effects.
---

# ActivityDiff: A diffusion model with Positive and Negative Activity Guidance for De Novo Drug Design

## Quick Facts
- arXiv ID: 2508.06364
- Source URL: https://arxiv.org/abs/2508.06364
- Reference count: 0
- Primary result: Proposes ActivityDiff, a diffusion model that uses separately trained drug-target classifiers for positive and negative activity guidance to enhance desired molecular activities while minimizing off-target effects.

## Executive Summary
ActivityDiff introduces a novel approach to de novo drug design by combining discrete denoising diffusion probabilistic models with classifier-guided sampling. The framework leverages separately trained drug-target classifiers to provide both positive guidance (encouraging desired target activity) and negative guidance (suppressing off-target interactions). This dual-guidance system enables precise control over molecular generation toward specific pharmacological objectives while maintaining high validity and novelty in generated molecules.

## Method Summary
ActivityDiff employs discrete denoising diffusion probabilistic models (D3PM) to generate molecular graphs, using separately trained message passing neural network classifiers for activity guidance. The system corrupts categorical node and edge features during the forward diffusion process and predicts original features during reverse sampling. Classifiers are trained on BindingDB data with SNR-weighted BCE loss and structural negative sampling. During generation, gradients from both positive and negative classifiers are incorporated into the denoising process to steer molecule generation toward desired activity profiles while avoiding off-target interactions.

## Key Results
- Successfully generates molecules with high affinity for desired targets through positive guidance
- Effectively suppresses off-target interactions through negative guidance, reducing potential toxicity
- Demonstrates effectiveness across multiple drug design tasks including single-target, dual-target, fragment-constrained, and selective generation
- Achieves high validity (0.978) and uniqueness (0.999) in generated molecular structures

## Why This Works (Mechanism)

### Mechanism 1: Decoupled Gradient-Based Guidance
The model decouples molecular generation from property optimization by using gradients from separately trained classifiers to guide a base diffusion model. During reverse diffusion, a pre-trained drug-target classifier evaluates intermediate noisy molecules and computes gradients that push sampling toward regions satisfying target conditions. This flexibility allows property optimization without retraining the generator.

### Mechanism 2: Negative Activity Suppression
Negative guidance allows explicit minimization of off-target interactions by calculating gradients from classifiers trained on undesirable targets. These gradients are applied inversely during denoising, actively repelling molecules away from structural motifs associated with off-targets. This acts as a repulsive force in chemical space to reduce toxicity.

### Mechanism 3: Discrete Graph Diffusion
Modeling molecules as discrete graphs enables fine-grained control over specific atoms and bonds during guidance. The model corrupts categorical node and edge features, with guidance modifying probability distributions of these discrete features at each step. This allows chemical "editing" by changing atom types or modifying bonds to satisfy classifier requirements.

## Foundational Learning

- **Concept: Discrete Denoising Diffusion Probabilistic Models (D3PM)**
  - Why needed here: Molecules are discrete graphs, requiring noise application to categories (atoms/bonds) and prediction of original categories from noisy states
  - Quick check question: How does the model handle the transition from a noisy "maybe-carbon-maybe-nitrogen" state back to a definite atom type?

- **Concept: Classifier Guidance**
  - Why needed here: This is the steering wheel of the system, using classifier gradients to adjust diffusion sampling
  - Quick check question: What happens to the generated sample if the gradient from the classifier points in a direction that the base diffusion model considers "impossible" (low probability)?

- **Concept: Message Passing Neural Networks (MPNN)**
  - Why needed here: The "classifiers" used for guidance are MPNNs that encode molecular topology into predictions
  - Quick check question: If the classifier predicts high activity for a molecule, which specific atoms or bonds contributed most to that score?

## Architecture Onboarding

- **Component map:** Input Noise -> **Backbone** (DiGress-based denoising network) -> **Classifier** (MPNN) scores & computes gradient -> **Guidance Controller** (Taylor expansion logic) -> Next Denoising Step

- **Critical path:** Random atoms/bonds -> Backbone predicts clean graph -> Classifier scores clean graph & computes gradient -> Guidance Controller modifies noise prediction -> Next Denoising Step

- **Design tradeoffs:**
  - Flexibility vs. Complexity: Avoids retraining generator for every new target (flexibility) but requires training/maintaining distinct classifier for every target and off-target (complexity)
  - Efficacy vs. Safety: Strong negative guidance reduces toxicity but may inadvertently lower binding affinity for primary target if pharmacophores overlap significantly

- **Failure signatures:**
  - Mode Collapse: Generating same high-activity molecule repeatedly due to steep guidance gradient
  - Chemical Nonsense: High classifier scores but invalid SMILES/valencies
  - Homology Conflict: Generation fails when trying to separate activities of highly similar proteins

- **First 3 experiments:**
  1. **Sanity Check (Unconditional):** Run diffusion without guidance to verify validity and novelty match Table 1
  2. **Bidirectional Control:** Generate molecules for a target with positive guidance, then same target with negative guidance; plot classifier score distributions
  3. **Selectivity Stress Test:** Attempt generation for target while negatively guiding against close homolog (e.g., HER2 vs EGFR) to identify limits

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can precise control over relative binding affinities be achieved when optimizing for multiple targets simultaneously?
- Basis in paper: The authors state that "Balancing affinities across multiple targets requires further investigation," noting the current framework establishes feasibility but lacks mechanisms to tune specific affinity ratios.
- Why unresolved: While the paper demonstrates generation of molecules active against two targets, it does not provide a method to explicitly dictate the balance or relative potency between them, which is critical for synergistic drug design.

### Open Question 2
- Question: How can the ActivityDiff framework be integrated with systems-level biological networks to account for drug–drug and protein–protein interactions?
- Basis in paper: The Discussion identifies "Integrating drug design into a systems-level biological network —taking into account drug–protein, protein–protein, and drug–drug interactions —represents a promising direction for future research."
- Why unresolved: The current model operates on isolated targets or simple combinations, ignoring the complex network context that influences clinical efficacy and safety in complex diseases.

### Open Question 3
- Question: What strategies can effectively leverage the vast amount of inactive compound data to improve the robustness of the guidance classifiers?
- Basis in paper: The authors note that "more effective utilization of inactive compound data... is essential for enhancing model reliability."
- Why unresolved: While the method currently uses random negative sampling of inactive compounds, the authors imply this approach is suboptimal and that the wealth of inactive data remains underutilized for discriminative learning.

## Limitations
- Negative guidance effectiveness depends on chemical separability of on-target and off-target pharmacophores, which may fail for highly homologous proteins
- The mechanism for combining two posterior approximations (Eq. 2 and 3) is briefly described without implementation details
- Claims about superiority for highly selective generation against close homologs are not fully supported by systematic analysis

## Confidence
- **High confidence:** The discrete diffusion framework and classifier guidance mechanism are well-established; implementation follows standard practices
- **Medium confidence:** Separation of positive and negative guidance is novel and well-motivated, but performance gains depend heavily on quality of negative data and classifier generalization
- **Low confidence:** Claims about the model's ability to handle highly selective generation against close homologs are not fully supported

## Next Checks
1. **Classifier robustness test:** Evaluate MPNN classifier accuracy on molecules corrupted at different noise levels (t/T) to verify gradients are meaningful during guidance
2. **Guidance scale sweep:** Systematically vary guidance scale hyperparameter on validation target and plot activity score vs. validity rate to find optimal balance
3. **Homology stress test:** Attempt selective generation for target while negatively guiding against close homolog (e.g., kinase family members) and measure trade-off between on-target affinity and off-target suppression