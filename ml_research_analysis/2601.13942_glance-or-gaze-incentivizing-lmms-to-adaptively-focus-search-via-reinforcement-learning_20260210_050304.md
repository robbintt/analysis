---
ver: rpa2
title: 'Glance-or-Gaze: Incentivizing LMMs to Adaptively Focus Search via Reinforcement
  Learning'
arxiv_id: '2601.13942'
source_url: https://arxiv.org/abs/2601.13942
tags:
- search
- visual
- image
- answer
- question
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of knowledge-intensive visual
  question answering where Large Multimodal Models struggle due to static parametric
  knowledge and inability to handle long-tail or evolving visual information. The
  authors propose Glance-or-Gaze (GoG), a framework that shifts from passive image
  perception to active visual planning by introducing a Selective Gaze mechanism that
  dynamically chooses between global context (glance) and fine-grained region analysis
  (gaze) before retrieval.
---

# Glance-or-Gaze: Incentivizing LMMs to Adaptively Focus Search via Reinforcement Learning

## Quick Facts
- arXiv ID: 2601.13942
- Source URL: https://arxiv.org/abs/2601.13942
- Reference count: 23
- Primary result: State-of-the-art performance on knowledge-intensive visual question answering with 5-20 point gains over baselines

## Executive Summary
This paper addresses the limitations of Large Multimodal Models (LMMs) in knowledge-intensive visual question answering by proposing a framework that shifts from static parametric knowledge to dynamic retrieval-based approaches. The Glance-or-Gaze (GoG) framework introduces a Selective Gaze mechanism that dynamically chooses between global context (glance) and fine-grained region analysis (gaze) before retrieval. The approach employs a dual-stage training strategy combining supervised fine-tuning with complexity-adaptive reinforcement learning, achieving significant performance improvements across six benchmarks.

## Method Summary
The Glance-or-Gaze framework implements a two-stage training approach for knowledge-intensive visual question answering. First, Reflective GoG Behavior Alignment uses supervised fine-tuning to teach the model active selection between global and fine-grained visual analysis. Second, Complexity-Adaptive Reinforcement Learning enhances planning capabilities for complex queries by rewarding adaptive decision-making. The framework integrates a Selective Gaze mechanism that determines whether to perform global glance or focused gaze analysis based on query complexity, enabling dynamic adaptation to different visual question answering scenarios.

## Key Results
- Achieved state-of-the-art performance across six benchmarks for knowledge-intensive visual question answering
- Demonstrated 5-20 point performance gains over strong existing baselines
- Validated effectiveness of adaptive planning paradigm through comprehensive experimental evaluation

## Why This Works (Mechanism)
The framework succeeds by addressing the fundamental limitation of LMMs: their reliance on static parametric knowledge. By introducing dynamic visual planning through the glance-or-gaze paradigm, the model can adaptively determine the appropriate level of visual analysis needed for each query. The Selective Gaze mechanism enables intelligent decision-making about when to perform global context analysis versus when to focus on specific regions, optimizing both accuracy and computational efficiency. The dual-stage training approach ensures the model first learns proper behavioral patterns through supervised fine-tuning before enhancing its planning capabilities through reinforcement learning.

## Foundational Learning
1. **Knowledge-intensive visual question answering** - why needed: Requires models to handle queries demanding external knowledge beyond static parametric knowledge; quick check: Benchmark performance on complex queries
2. **Dynamic visual planning** - why needed: Enables adaptive response to varying query complexity rather than one-size-fits-all approach; quick check: Query-type dependent performance variations
3. **Reinforcement learning for planning** - why needed: Trains models to make sequential decisions about visual analysis strategies; quick check: Reward structures and convergence behavior

## Architecture Onboarding

**Component Map:**
Input Query -> Selective Gaze Module -> (Glance Path | Gaze Path) -> Retrieval Module -> Answer Generation

**Critical Path:**
Query Analysis → Gaze Selection → Visual Analysis (Global or Fine-grained) → Retrieval → Answer Generation

**Design Tradeoffs:**
The framework trades increased computational complexity during decision-making for improved accuracy and adaptability. The glance-or-gaze selection introduces overhead but enables more targeted information retrieval. The dual-stage training approach requires more resources but results in better performance on complex queries.

**Failure Signatures:**
- Incorrect gaze selection leading to irrelevant visual analysis
- Over-reliance on glance path for complex queries requiring fine-grained analysis
- Under-utilization of gaze path for queries that could benefit from focused attention
- Reinforcement learning instability affecting decision-making consistency

**First Experiments:**
1. Ablation study removing gaze selection to quantify the contribution of adaptive decision-making
2. Performance comparison on simple versus complex queries to validate selective processing
3. Analysis of computational overhead introduced by the complexity-adaptive components

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Computational overhead from complexity-adaptive reinforcement learning may limit practical deployment
- Framework's effectiveness assumes all queries benefit from glance-or-gaze paradigm, which may not generalize
- Evaluation focuses on performance metrics without extensive analysis of computational efficiency

## Confidence

**High confidence:** The framework's core methodology and validity of performance improvements on established benchmarks
**Medium confidence:** Generalizability to real-world applications and diverse query types
**Medium confidence:** Scalability of the complexity-adaptive reinforcement learning component

## Next Checks
1. Conduct ablation studies to quantify individual contributions of glance versus gaze components and assess necessity for all query types
2. Evaluate framework performance on queries requiring temporal reasoning or multi-step visual understanding to test generalizability beyond current benchmark scope
3. Analyze computational overhead introduced by complexity-adaptive reinforcement learning component and assess practical deployment feasibility