---
ver: rpa2
title: 'Optimizing the Training Diet: Data Mixture Search for Robust Time Series Forecasting'
arxiv_id: '2512.11546'
source_url: https://arxiv.org/abs/2512.11546
tags:
- data
- arxiv
- training
- dataset
- clusters
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a data-centric optimization framework for
  time series forecasting that treats the selection of training data as a hyperparameter
  optimization problem. Instead of assuming more data is always better, the method
  uses a pre-trained encoder (MOMENT-1) to embed raw sensor streams, then applies
  k-means clustering to partition the dataset into behaviorally consistent groups.
---

# Optimizing the Training Diet: Data Mixture Search for Robust Time Series Forecasting

## Quick Facts
- arXiv ID: 2512.11546
- Source URL: https://arxiv.org/abs/2512.11546
- Authors: Federico Pennino; Maurizio Gabbrielli
- Reference count: 30
- One-line result: 19.41% MSE reduction (1.70→1.37) using 43% of original data via cluster-based data mixture optimization

## Executive Summary
This paper introduces a data-centric optimization framework for time series forecasting that treats training data selection as a hyperparameter optimization problem. Instead of assuming more data is always better, the method uses a pre-trained encoder (MOMENT-1) to embed raw sensor streams, then applies k-means clustering to partition the dataset into behaviorally consistent groups. Optuna is used to search for optimal sampling ratios across clusters, constructing training sets that maximize downstream model performance. Evaluated on the PMSM dataset, the approach improves test MSE from 1.70 to 1.37 while using only 43% of the original data. Qualitative LLM analysis confirms that up-weighted clusters capture rich, structured dynamics while down-weighted ones are mostly uninformative.

## Method Summary
The framework embeds multivariate time series windows using MOMENT-1, clusters embeddings with k-means, and optimizes cluster sampling ratios via Optuna's TPE sampler. Each trial constructs a training mixture by sampling n_k = C_k × w_k examples per cluster, trains a fixed PatchTST model, and returns validation MSE. The process discovers data mixtures that are both smaller and more balanced than the full dataset, with cluster weights ranging from near-zero to near-one based on their predictive value.

## Key Results
- Test MSE reduced from 1.70 to 1.37 (19.41% improvement)
- Final training set uses only 43% of original data volume
- Cluster weights show high differentiation, from near-zero to near-one
- LLM analysis reveals pruned clusters contain mostly uninformative flatline patterns

## Why This Works (Mechanism)

### Mechanism 1
Embedding-based clustering surfaces behaviorally meaningful data partitions that random sampling cannot recover. The MOMENT-1 encoder transforms raw time series into dense embeddings capturing temporal dynamics, and k-means partitions this space into clusters representing coherent operational regimes. These clusters become atomic units for data selection.

### Mechanism 2
Direct optimization of cluster sampling ratios via black-box search outperforms heuristic data balancing. Optuna's TPE searches the space of K-dimensional weight vectors, constructing training sets and returning validation MSE. TPE iteratively proposes weights favoring high-performing regions.

### Mechanism 3
Pruning high-volume, low-information clusters reduces redundancy-induced gradient noise and improves sample efficiency. The optimization assigns near-zero weights to populous but uninformative clusters, removing redundant samples that would otherwise dominate gradient updates without contributing to generalization.

## Foundational Learning

- **K-means clustering**: Partitions embedded time series into K discrete groups; each cluster becomes a tunable "ingredient" in the training mixture. Understanding centroid-based assignment and cluster cardinality tradeoffs is essential.
  - Quick check: If you double K from 36 to 72, what happens to cluster granularity and optimization search space dimensionality?

- **Foundation model embeddings (time series)**: MOMENT-1 provides task-agnostic representations; quality of downstream clustering depends on encoder's ability to capture predictive structure. You must understand what pre-training objectives the encoder learned.
  - Quick check: Would an encoder trained only on univariate financial series transfer well to multivariate motor sensor data? Why or why not?

- **Black-box hyperparameter optimization (TPE)**: Optuna's TPE sampler proposes weight vectors based on historical trial outcomes. Understanding the explore-exploit tradeoff helps diagnose convergence issues.
  - Quick check: After 50 trials, Optuna keeps proposing similar weight vectors with marginal MSE improvements. Is this convergence or premature exploitation?

## Architecture Onboarding

- **Component map**: MOMENT-1 encoder -> K-means clustering -> Optuna optimizer -> Data mixer -> PatchTST trainer
- **Critical path**: 1. Preprocess dataset into 300-timestep windows with EWMA features and normalization. 2. Encode all windows with MOMENT-1. 3. Run K-means (K=36) on embeddings. 4. Initialize Optuna study with 100 TPE trials. 5. For each trial: propose weights, construct mixture, train PatchTST, return validation MSE. 6. Select best mixture and train final model.
- **Design tradeoffs**: Cluster count (K) affects control granularity vs. search space dimensionality; trial budget impacts optimization quality vs. computational cost; encoder choice determines embedding quality; fixed token normalization confounds composition with training duration.
- **Failure signatures**: All weights converging to ~0.5 indicates poor differentiation; best mixture using 95%+ of data suggests inadequate redundancy detection; large validation-test gap indicates overfitting; specific target degradation may indicate pruned rare operational modes.
- **First 3 experiments**: 1. Baseline: full dataset vs. random 43% subset vs. stratified random 43%. 2. Cluster count sensitivity: K={12, 24, 36, 48} for 50 trials each. 3. Encoder ablation: MOMENT-1 vs. raw features vs. PCA vs. alternative encoder.

## Open Questions the Paper Calls Out

- How can the framework preserve minimal coverage of rare but critical regimes that may be heavily pruned during optimization? The current optimization may eliminate rare operational modes essential for robustness or safety-critical applications.
- Does the data mixture optimization framework generalize to diverse time-series domains beyond sensor data? The method's effectiveness on financial, healthcare, or other domains remains untested.
- Can the approach be extended to unsupervised or multi-task learning scenarios? The current framework requires labeled data for MSE-based optimization.
- How sensitive are the discovered mixtures to the choice of embedding model and number of clusters? The paper used MOMENT-1 with K=36 without systematic sensitivity analysis.

## Limitations

- The method assumes behavioral clusters identified by MOMENT-1 embeddings are predictive of downstream forecasting utility, but this correlation is not explicitly validated.
- Pruning high-volume clusters assumes those regions are redundant rather than representing rare but critical operational modes, potentially introducing blind spots.
- The empirical improvement lacks ablation studies on critical components like encoder quality, cluster granularity, and training normalization.

## Confidence

- **High Confidence**: The optimization framework's implementation (Optuna TPE, k-means clustering, PatchTST training pipeline) is technically sound and reproducible.
- **Medium Confidence**: The empirical improvement (1.70→1.37 MSE) is validated on PMSM dataset but lacks component ablation studies.
- **Low Confidence**: The claim that behavioral clustering alone drives performance without independent validation of encoder representation quality is speculative.

## Next Checks

1. **Encoder representation validation**: Compare mixture optimization performance using MOMENT-1 embeddings vs. raw features, PCA-reduced features, and domain-specific encoder to isolate the foundation model's contribution.
2. **Cluster granularity sensitivity**: Repeat full optimization with K={12, 24, 48} while keeping 100-trial budget constant to identify optimal granularity-cost tradeoff.
3. **Rare event retention check**: Manually inspect pruned clusters for anomalous patterns, retrain final model including these clusters, and measure degradation in normal operation vs. improvement in rare-event prediction.