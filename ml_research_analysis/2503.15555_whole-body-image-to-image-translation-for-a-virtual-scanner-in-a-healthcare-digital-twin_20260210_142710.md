---
ver: rpa2
title: Whole-Body Image-to-Image Translation for a Virtual Scanner in a Healthcare
  Digital Twin
arxiv_id: '2503.15555'
source_url: https://arxiv.org/abs/2503.15555
tags:
- whole-body
- images
- imaging
- anatomical
- scans
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a district-specific GAN framework for translating
  CT scans into synthetic PET images to support virtual scanning in healthcare Digital
  Twins. The approach segments whole-body CT images into four anatomical districts
  (head, trunk, arms, legs) and applies tailored GAN models (Pix2Pix and CycleGAN)
  to each region before stitching the outputs into a full-body PET scan.
---

# Whole-Body Image-to-Image Translation for a Virtual Scanner in a Healthcare Digital Twin

## Quick Facts
- arXiv ID: 2503.15555
- Source URL: https://arxiv.org/abs/2503.15555
- Reference count: 27
- This paper introduces a district-specific GAN framework for translating CT scans into synthetic PET images to support virtual scanning in healthcare Digital Twins

## Executive Summary
This paper introduces a district-specific GAN framework for translating CT scans into synthetic PET images to support virtual scanning in healthcare Digital Twins. The approach segments whole-body CT images into four anatomical districts (head, trunk, arms, legs) and applies tailored GAN models (Pix2Pix and CycleGAN) to each region before stitching the outputs into a full-body PET scan. Evaluated on a dataset of 1,014 FDG-PET/CT scans from oncology patients, the method outperformed a baseline whole-body GAN in MAE, PSNR, and SSIM across all districts, whole-body scans, lesion regions, and oncological conditions. Pix2Pix consistently yielded the best results. This district-level specialization effectively addresses anatomical heterogeneity, producing more accurate, high-quality synthetic PET images while reducing radiation exposure and costs in clinical settings.

## Method Summary
The method segments whole-body CT images into four anatomical districts (head, trunk, arms, legs) using MOOSE segmentator. For each district, separate 3D Pix2Pix or CycleGAN models translate CT patches to synthetic PET patches. Volumes are divided into 32³ voxel patches with 16-voxel overlap, with overlapping predictions averaged during inference. The synthetic PET patches are then stitched back together using district masks to form complete whole-body synthetic PET images. The framework uses FDG-PET/CT Lesions dataset with 1,014 paired scans, training four district-specific GANs with patch-based 3D convolutions, Adam optimizer, and extensive data augmentation.

## Key Results
- District-specific GANs achieved lower MAE (0.011±0.006 vs 0.020±0.005 whole-body) and higher PSNR (31.43 vs 28.50) across all districts
- Pix2Pix consistently outperformed CycleGAN due to supervised paired training with L1 reconstruction loss
- Framework demonstrated superior performance across all districts, whole-body scans, lesion regions, and oncological conditions
- Successfully reduced radiation exposure and costs by generating synthetic PET images from existing CT scans

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** District-specific GAN specialization improves CT-to-PET translation accuracy compared to single whole-body models.
- **Mechanism:** By partitioning the body into anatomically coherent regions (head, trunk, arms, legs), each GAN learns a narrower mapping distribution with reduced intra-class variance. This addresses the "heterogeneity of anatomical structures and physiological functions across body regions" that "can adversely affect the performance of image-to-image translation models trained on the entire body."
- **Core assumption:** Anatomical heterogeneity is the primary bottleneck limiting whole-body translation, and region-specific features can be captured more effectively with specialized models.
- **Evidence anchors:**
  - [abstract] "district-level specialization effectively addresses anatomical heterogeneity, producing more accurate, high-quality synthetic PET images"
  - [section V, Table I] District-specific GANs achieved lower MAE (0.011±0.006 vs 0.020±0.005 whole-body) and higher PSNR (31.43 vs 28.50) across all districts
  - [corpus] Weak direct validation; neighboring papers focus on alternative approaches (diffusion models, foundation models) rather than district specialization
- **Break condition:** If anatomical regions exhibit similar CT-to-PET mapping characteristics, or if segmentation errors introduce more noise than specialization removes.

### Mechanism 2
- **Claim:** 3D patch-based training with overlap-averaging enables volumetric GAN processing while managing GPU memory constraints.
- **Mechanism:** Volumes are divided into 32³ voxel patches with 16-voxel overlap. During inference, a sliding window generates overlapping predictions that are averaged at stitch boundaries, "smooth[ing] transitions and reduc[ing] edge artifacts."
- **Core assumption:** 32³ patches contain sufficient anatomical context for the GAN to learn meaningful CT-to-PET mappings, and averaging overlapping predictions produces coherent outputs.
- **Evidence anchors:**
  - [section III.B] "we adopted a patch-based training approach. We divided the district-specific CT and PET volumes into smaller 3D patches of size s × s × s, where s = 32"
  - [section III.C] "overlapping regions between patches were averaged to ensure smooth transitions"
  - [corpus] No direct corpus validation of patch size optimality
- **Break condition:** If patches are too small to capture organ-level context, or if averaging introduces blur in clinically critical regions.

### Mechanism 3
- **Claim:** Pix2Pix (paired supervision) outperforms CycleGAN (cycle consistency) when aligned CT-PET pairs are available.
- **Mechanism:** Pix2Pix's L1 reconstruction loss provides direct pixel-level supervision between predicted and ground-truth PET, while CycleGAN relies on indirect cycle-consistency constraints that may not preserve precise metabolic patterns.
- **Core assumption:** The paired CT-PET alignment quality is sufficient for supervised learning to provide meaningful signal.
- **Evidence anchors:**
  - [abstract] "Pix2Pix consistently yielded the best results"
  - [section V] "Pix2Pix models generally outperformed the CycleGAN models. This outcome can be attributed to the supervised nature of Pix2Pix, which benefits from paired training data"
  - [corpus] Related work (Plasma-CycleGAN) explores conditional CycleGAN variants, suggesting unpaired approaches remain relevant when paired data unavailable
- **Break condition:** If CT-PET registration quality is poor, paired supervision may propagate misalignment errors.

## Foundational Learning

- **Concept: Conditional GANs (Pix2Pix architecture)**
  - **Why needed here:** Core generative model for each district. Must understand generator-discriminator dynamics, adversarial loss combined with L1 reconstruction loss (λ=100 weighting), and why U-Net generators are standard.
  - **Quick check question:** Why does Pix2Pix use both adversarial loss and L1 loss rather than adversarial alone?

- **Concept: 3D volumetric convolutions vs 2D slice-by-slice processing**
  - **Why needed here:** The paper uses 3D convolutions to "fully exploit the volumetric nature of medical imaging data." Understanding memory tradeoffs and why patch-based strategies are necessary.
  - **Quick check question:** What is the memory complexity increase when moving from 2D to 3D convolutions with kernel size k on a volume of D×H×W?

- **Concept: CT-PET imaging modalities and SUV normalization**
  - **Why needed here:** CT provides anatomical density; PET provides metabolic activity via FDG radiotracer. SUV normalization (accounting for injected dose and body weight) is critical preprocessing.
  - **Quick check question:** Why can't CT intensity values directly predict PET metabolic activity without learning a complex non-linear mapping?

## Architecture Onboarding

- **Component map:**
  Whole-body CT -> [MOOSE Segmentator] -> 4 district masks (head/trunk/arms/legs)
                    ↓
  District CTs -> [4 separate 3D Pix2Pix GANs] -> District synthetic PETs
                    ↓
  District PETs -> [Stitching module with overlap averaging] -> Whole-body synthetic PET

- **Critical path:**
  1. **Segmentation accuracy:** MOOSE segmentator must produce anatomically correct district boundaries; errors propagate to all downstream GANs.
  2. **Patch extraction alignment:** CT and PET patches must be spatially paired during training (equations 10-11).
  3. **Boundary handling:** Overlap averaging (equation 14) must prevent visible seams between districts.

- **Design tradeoffs:**
  | Decision | Option A | Option B | Paper choice |
  |----------|----------|----------|--------------|
  | District count | 4 regions | More granular (organ-level) | 4 (cites future work for finer subdivision) |
  | Architecture | Pix2Pix (paired) | CycleGAN (unpaired) | Pix2Pix primary, CycleGAN for extensibility demo |
  | Patch size | 32³ | Larger for more context | 32³ (memory-constrained) |
  | Normalization | SUV range 0-20 | Full dynamic range | 0-20 SUV clipped to clinical range |

- **Failure signatures:**
  - **Seam artifacts at district boundaries:** Indicates overlap-averaging insufficient; consider larger overlap or learned blending.
  - **Poor trunk performance relative to other districts:** Trunk contains highest anatomical complexity; may need further subdivision.
  - **Mode collapse in lesion synthesis:** GAN generating average PET patterns; check discriminator capacity and training stability.
  - **High variance in SSIM across patients:** Suggests overfitting to specific anatomical patterns; increase augmentation.

- **First 3 experiments:**
  1. **Baseline replication:** Train single whole-body Pix2Pix GAN on all data (no district segmentation) to establish baseline MAE/PSNR/SSIM metrics.
  2. **Single-district pilot:** Implement district segmentation + train Pix2Pix on trunk only (highest clinical relevance) to validate specialization benefit before full 4-district implementation.
  3. **Ablation on overlap size:** Test overlap values {0, 8, 16, 24} to quantify impact on boundary artifacts and identify optimal tradeoff between redundancy and computational cost.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Would replacing the four-district segmentation with finer organ-specific subdivisions improve the accuracy of synthetic PET translation?
- **Basis in paper:** [explicit] The authors state future work will "refine the segmentation process by including more detailed subdivisions or organ-specific segmentation."
- **Why unresolved:** The current study only tested broad anatomical districts (head, trunk, arms, legs), leaving the potential benefits of higher anatomical granularity unexplored.
- **What evidence would resolve it:** A comparative study measuring MAE and SSIM of district-specific models versus organ-specific models trained on the same dataset.

### Open Question 2
- **Question:** How robust is the district-specific GAN framework when applied to multi-center datasets with varying scanner protocols?
- **Basis in paper:** [explicit] The authors aim to "evaluate the generalizability of our approach across diverse datasets to ensure robustness."
- **Why unresolved:** The current validation relies on a single-institution dataset (Tübingen), which the authors note may limit generalizability due to specific acquisition parameters.
- **What evidence would resolve it:** Performance metrics obtained by testing the pre-trained models on external datasets from different hospitals using different scanner hardware.

### Open Question 3
- **Question:** Can the integration of explainable artificial intelligence (XAI) techniques enhance clinical trust in the generated synthetic images?
- **Basis in paper:** [explicit] The authors propose to "integrate explainable artificial intelligence techniques to enhance transparency and trust."
- **Why unresolved:** The current methodology focuses on image synthesis without explaining the features driving the generation, which is critical for clinical adoption.
- **What evidence would resolve it:** A user study with radiologists assessing diagnostic confidence and interpretability when XAI visualizations are applied to the synthetic PET outputs.

## Limitations

- The study relies on a single-institution dataset (Tübingen), which may limit generalizability to different scanner protocols and patient populations
- The evaluation focuses on MAE, PSNR, and SSIM metrics that may not fully capture clinical utility or lesion detectability in synthetic PET images
- Optimal district granularity remains unexplored, with the current 4-district division potentially suboptimal for certain clinical applications

## Confidence

- **High confidence**: The district specialization mechanism (Mechanism 1) and its empirical validation through quantitative metrics. The consistent improvement across MAE, PSNR, and SSIM suggests robust findings.
- **Medium confidence**: The superiority of Pix2Pix over CycleGAN, as this depends on the quality of CT-PET alignment and paired supervision availability. The paper acknowledges this is dataset-dependent.
- **Medium confidence**: The patch-based training approach (Mechanism 2), as the 32³ patch size appears empirically chosen rather than theoretically justified, with no corpus validation of this specific choice.

## Next Checks

1. **District granularity study**: Systematically vary the number of anatomical districts (e.g., 2, 4, 8, 16) to identify the optimal granularity for CT-to-PET translation and determine whether further subdivision of the trunk region yields additional gains.
2. **Clinical utility assessment**: Conduct radiologist reader study comparing synthetic PET quality between district-specialized and whole-body GANs, focusing on lesion detection, characterization, and diagnostic confidence rather than purely numerical metrics.
3. **Cross-scanner validation**: Test the trained district-specific GANs on PET/CT scans from different manufacturers and acquisition protocols to assess robustness and determine whether district boundaries or GAN parameters require adaptation.