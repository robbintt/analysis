---
ver: rpa2
title: 'Beyond Turn-taking: Introducing Text-based Overlap into Human-LLM Interactions'
arxiv_id: '2501.18103'
source_url: https://arxiv.org/abs/2501.18103
tags:
- chatbot
- overlap
- interactions
- typing
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces overlapping messages into text-based human-AI
  interactions, moving beyond traditional turn-taking. Through a formative study,
  the authors observed users naturally engage in overlapping behaviors like backchanneling
  and preemptive responses during text-based conversations.
---

# Beyond Turn-taking: Introducing Text-based Overlap into Human-LLM Interactions

## Quick Facts
- arXiv ID: 2501.18103
- Source URL: https://arxiv.org/abs/2501.18103
- Authors: JiWoo Kim; Minsuk Chang; JinYeong Bak
- Reference count: 40
- This paper introduces overlapping messages into text-based human-AI interactions, moving beyond traditional turn-taking

## Executive Summary
This paper introduces overlapping messages into text-based human-AI interactions, moving beyond traditional turn-taking. Through a formative study, the authors observed users naturally engage in overlapping behaviors like backchanneling and preemptive responses during text-based conversations. Based on these insights, they developed OverlapBot, an LLM-powered chatbot capable of overlapping its typing with users through backchanneling and preemptive answering. A user study with 18 participants showed that OverlapBot was perceived as more communicative and immersive than traditional turn-taking chatbots, fostering faster and more natural interactions.

## Method Summary
The authors finetuned Llama3-8B using parameter-efficient finetuning (LoRA) via HuggingFace API on a dataset combining the SwitchBoard Dialogue Act Corpus (SWDA) with Alpaca instruction tuning data. The model was trained to classify timing ([Overlap]/[Await]) and dialogue acts ([Understanding]/[Answer]), then generate appropriate utterances. The system implements real-time text streaming with typing indicators and dynamic message bubbles that can update or delete responses when interrupted.

## Key Results
- OverlapBot perceived as more communicative and immersive than traditional turn-taking chatbots
- Timing classification accuracy of 67% and dialogue act classification accuracy of 85%
- Users reported faster and more natural interactions with the overlapping chatbot

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Rendering user keystrokes in real-time creates a shared temporal context, allowing the AI to infer user intent prior to explicit submission, thereby reducing conversational latency.
- **Mechanism:** By streaming input character-by-character, the system removes the "artificial pause" inherent in turn-taking interfaces. This allows the model to trigger preemptive generation (predicting the end of a turn) rather than waiting for a `send` event.
- **Core assumption:** Users type predictable patterns that can be accurately classified as questions or statements before completion.
- **Evidence anchors:**
  - [abstract] "Overlapping messages... mirroring natural human conversations."
  - [section 4.1] "Displaying participants' typing activities is a foundational element... it creates opportunities for overlap."
  - [corpus] Related work on "Full-Duplex" models supports this duplex capability, though specific text-based keystroke visualization is less explored in the provided corpus neighbors.
- **Break condition:** If typing visualization causes user anxiety (self-monitoring) or if the model predicts intent incorrectly too often, the mechanism creates friction rather than flow.

### Mechanism 2
- **Claim:** Preemptive responses function as "active listening" cues, increasing the perceived attentiveness of the agent.
- **Mechanism:** Users interpret the AI generating a response before they finish typing as a sign of intelligence and engagement (Section 5.1.2). This mimics human terminal overlap, signaling "I am with you," which shifts the user's mental model of the AI from a search engine to a conversational partner.
- **Core assumption:** Users prefer immediate feedback over fully formed, delayed answers in casual or iterative contexts.
- **Evidence anchors:**
  - [abstract] "OverlapBot was perceived as more communicative and immersive."
  - [section 5.1.2] "Participants used OverlapBotâ€™s preemptive answering to assess how well it understood the topic."
  - [corpus] Weak direct evidence in corpus; neighbors focus on audio turn-taking dynamics.
- **Break condition:** If the task requires high-precision (e.g., coding, legal drafting), preemptive guessing may be perceived as intrusive or "annoying" (P13).

### Mechanism 3
- **Claim:** Dynamic deletion and regeneration upon interruption preserve the user's sense of control over the conversation floor.
- **Mechanism:** In human conversation, competitive overlap requires a resolution. The system implements a "yield" mechanism where the AI discards its current generation if the user initiates an overlap (interrupts), preventing the interface from talking over the user.
- **Core assumption:** Text-based interruptions (typing while the AI is typing) are interpreted by the user as a command to stop, not a collaborative addition.
- **Evidence anchors:**
  - [section 4.3] "The chatbot is programmed to delete its prior response... when interrupted by the user."
  - [section 5.1.2] "Users interrupt an LLM with brief commands... prompting it to stop typing."
  - [corpus] "Full-Duplex-Bench" corpus neighbor discusses similar duplex turn-taking challenges in speech.
- **Break condition:** High latency in the deletion/regeneration cycle could result in "ghost text" or confusing UI states where the old response persists visually after the user has interrupted.

## Foundational Learning

- **Concept:** **Cooperative vs. Competitive Overlap**
  - **Why needed here:** The system must distinguish between *backchanneling* (cooperative: "yeah," "uh-huh") which requires no user response, and *interruptions* (competitive: changing the topic) which requires the AI to yield. Misclassifying these leads to the AI talking over the user or spamming acknowledgments.
  - **Quick check question:** Does an "Uh-huh" from the AI require a response from the user according to the paper? (No, see Section 5.1.2).

- **Concept:** **Timing Classification in LLMs**
  - **Why needed here:** Unlike standard chatbots that always await a turn, OverlapBot requires a classifier to decide *when* to speak. It must balance the [Overlap] probability against the [Await] probability to avoid premature guessing.
  - **Quick check question:** What accuracy did the finetuned Llama3-8B achieve in deciding whether to overlap or wait? (67%, see Abstract).

- **Concept:** **Streaming UX and Mental Load**
  - **Why needed here:** The paper highlights that real-time visibility of typing can increase psychological burden (Section 3.1). Engineers must understand that lower latency is not always better if it increases user self-consciousness.
  - **Quick check question:** Why might a user prefer the "Conventional" chatbot over OverlapBot for complex tasks? (To avoid the pressure of being "monitored" and to receive more structured, elaborate answers).

## Architecture Onboarding

- **Component map:** User keystrokes -> Real-time streaming interface -> Model timing classification -> [Overlap] action or [Await] -> Dialogue act classification -> Utterance generation -> Dynamic UI update/delete
- **Critical path:**
  1. **Input:** User keystroke stream captured.
  2. **Inference:** Model evaluates partial string -> Probability of [Overlap].
  3. **Action:** If [Overlap], generate [Understanding] (brief) or [Answer] (preemptive).
  4. **Interrupt Handling:** If user keystrokes detected during AI generation -> Trigger deletion API -> Reset context -> Regenerate.

- **Design tradeoffs:**
  - **Latency vs. Stability:** Single-threaded generation (used in the paper to avoid race conditions) can cause delays if a user deletes and retypes rapidly. Multi-threading is needed but complex to implement.
  - **Brevity vs. Detail:** OverlapBot produces shorter messages (133 chars avg vs 177 in conventional) to maintain flow, sacrificing depth.
  - **Dataset Fidelity:** The SWDA dataset is telephonic speech; mapping speech overlaps to text-based typing behaviors requires data manipulation assumptions.

- **Failure signatures:**
  - **Premature Commitment:** AI guesses the wrong end of the sentence and provides an irrelevant preemptive answer.
  - **Thread Blocking:** User types "A", deletes, types "B". AI hangs on generating response for "A" due to single-thread limitations (Section 7).
  - **Intrusion:** AI interrupts a thoughtful pause with backchanneling, breaking the user's train of thought.

- **First 3 experiments:**
  1. **Timing Accuracy Test:** Benchmark the finetuned model against GPT-4o specifically on the [Overlap] vs [Await] decision task using the custom dataset.
  2. **Latency Tolerance Test:** Measure at what character count (e.g., 130 chars) the "deletion" mechanism becomes too slow for a seamless user experience.
  3. **Qualitative Intrusion Test:** Run a user study comparing different overlap frequencies (e.g., high-backchanneling vs. low-backchanneling) to identify the threshold where "immersive" becomes "annoying."

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the effectiveness of overlapping text-based interactions vary between goal-oriented tasks (e.g., summarization) and open-ended social dialogue?
- **Basis in paper:** [explicit] The section "Overlap Across Tasks and Relationships" states, "how overlapping interactions unfold in detail for each task remain open questions for future research."
- **Why unresolved:** The user study focused primarily on free-topic, social conversations rather than systematically comparing different task types.
- **What evidence would resolve it:** A comparative user study measuring efficiency, accuracy, and satisfaction across distinct task categories (e.g., brainstorming vs. data retrieval).

### Open Question 2
- **Question:** How do cultural differences in conversational norms influence the perception of overlapping AI behavior as engaging versus disruptive?
- **Basis in paper:** [explicit] The limitations section notes that "cultural dynamics... were not explicitly considered," and the discussion highlights the need for "Culturally Adaptive Overlap."
- **Why unresolved:** The participant pool was linguistically homogeneous (mostly Korean), yet the authors note that cultures prioritizing strict turn-taking might find overlap rude.
- **What evidence would resolve it:** A cross-cultural study comparing user tolerance and perceived rudeness of interruptions across diverse communication styles.

### Open Question 3
- **Question:** How can system architectures mitigate the response latency and irrelevance caused when users delete or modify text mid-type?
- **Basis in paper:** [explicit] The limitations section identifies a "technical issue when users begin typing a response, delete it, and then input a different prompt," causing premature responses.
- **Why unresolved:** The prototype relied on single-thread generation via Huggingface API, which could not effectively handle rapid changes in user intent during generation.
- **What evidence would resolve it:** Development of specialized decoding algorithms or multi-threaded handling that can abort or pivot generation instantly upon user deletion.

### Open Question 4
- **Question:** How does the "companionship" aspect of overlapping interactions differ for older adults compared to the younger demographic studied?
- **Basis in paper:** [explicit] The limitations state the participant pool "lacked age diversity" and suggest that interaction dynamics may change for "older individuals" regarding the sense of presence.
- **Why unresolved:** The study focused on university-aged participants, leaving the effects of overlap on populations potentially suffering from isolation unexplored.
- **What evidence would resolve it:** A user study with elderly participants focusing on qualitative measures of loneliness and perceived social presence.

## Limitations

- Timing classification accuracy of 67% represents a fundamental constraint with one-third of overlap decisions incorrect
- Study sample size of 18 participants lacks statistical power for definitive conclusions across different task types
- Evaluation focused on a single use case (question-answering chatbot), limiting understanding of overlap dynamics in other interaction types
- Real-time typing visibility may increase user anxiety, creating a trade-off between efficiency and comfort
- Single-threaded generation creates latency issues when users rapidly edit their input

## Confidence

**High Confidence:** The observation that users naturally engage in overlapping behaviors (backchanneling and preemptive responses) during text-based conversations is well-supported by the formative study data. The mechanism by which real-time typing visualization enables predictive overlap is also clearly demonstrated.

**Medium Confidence:** The claim that OverlapBot is perceived as more communicative and immersive than traditional turn-taking chatbots is supported by user study results, but the small sample size and lack of comparative metrics beyond subjective ratings reduce confidence in broad generalizability.

**Low Confidence:** The assertion that overlap capabilities will enhance text-based conversation fluidity and engagement across diverse applications requires further validation. The current evidence is limited to a single chatbot use case and may not extend to collaborative or professional contexts.

## Next Checks

1. **Generalization Test:** Evaluate OverlapBot across different interaction types (collaborative writing, coding assistance, creative brainstorming) to identify contexts where overlap enhances versus hinders communication.

2. **Scalability Assessment:** Measure timing classification accuracy and user experience metrics with a larger, more diverse participant pool (n=50+) across different cultural backgrounds and communication styles.

3. **Technical Robustness Test:** Implement multi-threaded generation with proper race condition handling and measure the impact on latency, deletion accuracy, and overall user experience compared to the current single-threaded approach.