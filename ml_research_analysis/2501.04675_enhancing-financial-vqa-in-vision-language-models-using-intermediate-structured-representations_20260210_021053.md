---
ver: rpa2
title: Enhancing Financial VQA in Vision Language Models using Intermediate Structured
  Representations
arxiv_id: '2501.04675'
source_url: https://arxiv.org/abs/2501.04675
tags:
- chart
- value
- data
- table
- charts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study fine-tuned DEPLOT on 50,000 bar charts to improve chart-to-table
  conversion for financial data. The fine-tuned model significantly outperformed the
  base model, achieving an RMS F1 score of 91.06% and RNSS of 98.07%, compared to
  50.93% and 86.67% respectively.
---

# Enhancing Financial VQA in Vision Language Models using Intermediate Structured Representations

## Quick Facts
- **arXiv ID:** 2501.04675
- **Source URL:** https://arxiv.org/abs/2501.04675
- **Authors:** Archita Srivastava; Abhas Kumar; Rajesh Kumar; Prabhakar Srinivasan
- **Reference count:** 40
- **Primary result:** Fine-tuned DEPLOT achieved 91.06% RMS F1 score vs 50.93% for base model on financial chart interpretation

## Executive Summary
This study addresses the challenge of financial visual question answering (VQA) by introducing a two-stage approach that first converts bar charts to structured tables before feeding them to language models. The researchers fine-tuned DEPLOT, a chart-to-table conversion model, on 50,000 synthetic bar charts to create a specialized financial chart parser. They then evaluated how providing these intermediate structured representations affects LLM performance on financial reasoning tasks.

The results demonstrate that this intermediate representation approach significantly enhances LLM reasoning capabilities, with smaller models like Qwen2-VL-7B and LLaMA-11B outperforming GPT-4o when given accurate tabular data. The study establishes that domain-specific fine-tuning combined with structured intermediate representations provides a powerful framework for accurate visual data interpretation in financial contexts.

## Method Summary
The researchers employed a two-stage methodology to improve financial VQA performance. First, they fine-tuned DEPLOT on 50,000 synthetic bar charts specifically generated for financial data interpretation. This fine-tuning process aimed to create a robust chart-to-table conversion model capable of accurately extracting numerical and categorical information from financial visualizations.

In the second stage, they evaluated various vision-language models (VLMs) on financial reasoning tasks under two conditions: with and without intermediate structured tables. The models tested included GPT-4o, Qwen2-VL-7B, and LLaMA-11B, with performance measured using RMS F1 score and RNSS metrics. The study systematically compared model performance when given raw charts versus when provided with the structured table representations generated by the fine-tuned DEPLOT model.

## Key Results
- Fine-tuned DEPLOT achieved 91.06% RMS F1 score and 98.07% RNSS compared to 50.93% and 86.67% for base model
- Smaller models (Qwen2-VL-7B, LLaMA-11B) outperformed GPT-4o when given accurate tabular data
- Providing intermediate structured tables alongside charts significantly enhanced LLM reasoning performance

## Why This Works (Mechanism)
The effectiveness of this approach stems from decomposing the complex task of visual understanding and reasoning into two specialized subtasks. Chart-to-table conversion transforms visual patterns into structured numerical data that LLMs can process more efficiently than raw images. This intermediate representation eliminates the need for VLMs to perform both visual parsing and reasoning simultaneously, reducing cognitive load and potential error propagation. The domain-specific fine-tuning ensures the conversion model understands financial chart conventions and terminology, producing more accurate structured outputs. By providing clean, structured data to LLMs, the approach leverages their strengths in logical reasoning while bypassing their limitations in visual processing.

## Foundational Learning

**Chart-to-table conversion:** The process of extracting structured data from visual charts, critical for transforming visual information into machine-readable formats that language models can process effectively.

**Visual Question Answering (VQA):** A multimodal task combining computer vision and natural language processing where models answer questions about visual content, requiring both understanding of visual elements and reasoning capabilities.

**Vision-Language Models (VLMs):** AI systems that process both visual and textual information, enabling applications that require understanding of images combined with language comprehension and generation.

**Financial chart interpretation:** The specialized domain of understanding bar charts, line graphs, and other visualizations used in financial analysis, requiring knowledge of financial terminology and conventions.

## Architecture Onboarding

**Component map:** DEPLOT fine-tuned model -> Structured table output -> LLM (Qwen2-VL-7B, LLaMA-11B, GPT-4o) -> Answer generation

**Critical path:** Chart input → DEPLOT conversion → Structured table → LLM reasoning → Answer output

**Design tradeoffs:** The two-stage approach trades computational overhead (additional conversion step) for improved accuracy and reduced complexity in the final reasoning stage. While this adds latency, it significantly improves performance on complex financial reasoning tasks.

**Failure signatures:** Poor chart-to-table conversion propagates errors to LLM reasoning; LLMs may still misinterpret structured data if financial context is missing; performance degrades when charts contain complex annotations or non-standard formats.

**First experiments:** 1) Test DEPLOT conversion accuracy on edge cases and real-world charts 2) Evaluate LLM performance with incomplete or noisy structured tables 3) Compare two-stage approach against end-to-end VQA models on mixed chart types

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation relies entirely on synthetically generated bar charts, potentially missing real-world complexity
- Model focuses exclusively on bar charts, limiting generalizability to other financial visualization types
- 50,000-chart training dataset created through automated methods may not capture all edge cases

## Confidence

**Chart-to-table conversion effectiveness:** High confidence - Clear quantitative improvements with statistically significant differences across multiple metrics

**Intermediate representation benefits:** High confidence - Dramatic performance improvements across multiple model sizes support the approach

**Smaller models outperforming GPT-4o:** Medium confidence - Results show this for specific conditions but comparisons involve different evaluation methodologies

## Next Checks

1. Test the fine-tuned DEPLOT model on real-world financial charts from diverse sources to assess robustness beyond synthetic data
2. Evaluate performance across additional chart types (line graphs, candlestick charts, scatter plots) to determine model generalizability
3. Conduct ablation studies removing the chart-to-table intermediate step to quantify the exact contribution of structured representations versus improved VQA capabilities