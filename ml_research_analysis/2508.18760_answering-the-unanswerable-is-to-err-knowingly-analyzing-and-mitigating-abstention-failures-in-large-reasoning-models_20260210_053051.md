---
ver: rpa2
title: 'Answering the Unanswerable Is to Err Knowingly: Analyzing and Mitigating Abstention
  Failures in Large Reasoning Models'
arxiv_id: '2508.18760'
source_url: https://arxiv.org/abs/2508.18760
tags:
- abstention
- lrms
- reasoning
- unanswerable
- questions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of large reasoning models failing
  to abstain from answering inherently unanswerable questions. The authors analyze
  why LRMs struggle to abstain despite possessing cognitive capabilities to recognize
  question flaws.
---

# Answering the Unanswerable Is to Err Knowingly: Analyzing and Mitigating Abstention Failures in Large Reasoning Models

## Quick Facts
- arXiv ID: 2508.18760
- Source URL: https://arxiv.org/abs/2508.18760
- Reference count: 35
- Key outcome: A two-stage method increases abstention rates from 16.9% to 60.9% for R1-Distill-Llama-8B while maintaining answer accuracy and reducing token usage by 30-50% on unanswerable questions

## Executive Summary
This paper addresses a critical failure mode in large reasoning models: their inability to abstain from answering inherently unanswerable questions despite having the cognitive capability to recognize such flaws. The authors analyze this paradox and propose a novel two-stage approach that combines cognitive monitoring with inference-time intervention. The method demonstrates significant improvements in abstention rates while maintaining accuracy on answerable questions and reducing computational costs through token savings.

## Method Summary
The proposed two-stage method addresses LRM abstention failures through cognitive monitoring and inference-time intervention. The first stage employs linear probes to monitor intermediate reasoning activations, detecting patterns that indicate question unanswerability. The second stage implements instructional guidance prompts and early exit strategies to intervene when unanswerable questions are detected. This approach leverages the models' existing reasoning capabilities while adding targeted control mechanisms to improve abstention behavior.

## Key Results
- Abstention rate improvement: R1-Distill-Llama-8B increased from 16.9% to 60.9% on unanswerable questions
- Maintained accuracy: Answer quality preserved on answerable questions while significantly improving abstention on unanswerable ones
- Token efficiency: Achieved 30-50% reduction in token usage when early exiting on unanswerable questions

## Why This Works (Mechanism)
Large reasoning models possess cognitive capabilities to recognize question flaws but fail to abstain due to their training objectives and generation patterns. The two-stage method works by first detecting unanswerability signals during the reasoning process through linear probe monitoring, then applying targeted interventions that override the model's default generation behavior. The cognitive monitoring captures the moment when models recognize question defects, while the intervention strategies provide explicit instructions to abstain rather than generate incorrect answers.

## Foundational Learning
- Linear probe monitoring: Detects unanswerability patterns in intermediate activations - needed for real-time detection without full model retraining; quick check: probe accuracy on held-out unanswerable samples
- Instructional guidance: Provides explicit abstention instructions during inference - needed to override default generation tendencies; quick check: effectiveness of different prompt formulations
- Early exit strategies: Terminates reasoning early on detected unanswerable questions - needed for computational efficiency; quick check: optimal timing for intervention

## Architecture Onboarding

**Component map:** Input Question -> Linear Probe Monitor -> Cognitive State Analysis -> Intervention Decision -> Instructional Guidance/Early Exit -> Final Output

**Critical path:** The cognitive monitoring path is critical as it determines when interventions should occur. The linear probe must accurately detect unanswerability signals in intermediate reasoning states before the model commits to an answer.

**Design tradeoffs:** The method trades additional inference-time computation (for monitoring and intervention) against improved abstention accuracy and token savings. The linear probe approach is simpler than full model retraining but may miss nuanced unanswerability patterns.

**Failure signatures:** False positives in unanswerability detection lead to unnecessary abstention on answerable questions; false negatives result in continued incorrect answering; overly aggressive early exit may truncate valid reasoning.

**Three first experiments:**
1. Test linear probe detection accuracy across different intermediate reasoning stages
2. Compare different instructional prompt formulations for abstention guidance
3. Evaluate early exit timing optimization on unanswerable question detection

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to specific datasets (AdvFact and NYT_Sarcasm) and model architectures, raising generalizability concerns
- Linear probe assumption that unanswerability manifests in specific intermediate activations may not hold universally across different reasoning processes
- Additional computational overhead from instruction tuning and monitoring may not scale efficiently for all deployment scenarios

## Confidence

**Major claim clusters and confidence assessments:**
- Two-stage method effectiveness (High confidence): Consistent improvements across multiple LRMs and datasets with statistically significant results
- Cognitive monitoring via linear probes (Medium confidence): Effective on studied datasets but generalizability to other reasoning patterns uncertain
- Inference-time intervention strategies (High confidence): Robust performance improvements with strong empirical evidence for token savings and accuracy maintenance

## Next Checks
1. Cross-dataset generalization: Evaluate the two-stage method on additional benchmark datasets with different question types to assess robustness across domains
2. Probe architecture sensitivity: Test alternative cognitive monitoring approaches to validate whether linear probes are optimal for detecting unanswerability signals
3. Real-world deployment testing: Implement the method in production environments with live user queries to measure practical performance gains and identify edge cases not captured in benchmark datasets