---
ver: rpa2
title: 'MedReason: Eliciting Factual Medical Reasoning Steps in LLMs via Knowledge
  Graphs'
arxiv_id: '2504.00993'
source_url: https://arxiv.org/abs/2504.00993
tags:
- reasoning
- medical
- data
- arxiv
- preprint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MedReason addresses the challenge of generating high-quality, factually
  accurate Chain-of-Thought (CoT) data for medical reasoning by leveraging a structured
  medical knowledge graph to guide the reasoning process. The method converts clinical
  question-answer pairs into logical reasoning paths that trace connections from question
  elements to answers via relevant KG entities, ensuring each step is validated for
  clinical logic and evidence-based medicine.
---

# MedReason: Eliciting Factual Medical Reasoning Steps in LLMs via Knowledge Graphs

## Quick Facts
- arXiv ID: 2504.00993
- Source URL: https://arxiv.org/abs/2504.00993
- Authors: Juncheng Wu, Wenlong Deng, Xingxuan Li, Sheng Liu, Taomian Mi, Yifan Peng, Ziyang Xu, Yi Liu, Hyunjin Cho, Chang-In Choi, Yihan Cao, Hui Ren, Xiang Li, Xiaoxiao Li, Yuyin Zhou
- Reference count: 24
- Primary result: Generates factually accurate medical Chain-of-Thought reasoning via knowledge graphs, achieving up to 7.7% gains on DeepSeek-Distill-8B and outperforming state-of-the-art Huatuo-o1-8B by 4.2% on MedBullets benchmark

## Executive Summary
MedReason addresses the challenge of generating high-quality, factually accurate Chain-of-Thought (CoT) data for medical reasoning by leveraging a structured medical knowledge graph to guide the reasoning process. The method converts clinical question-answer pairs into logical reasoning paths that trace connections from question elements to answers via relevant KG entities, ensuring each step is validated for clinical logic and evidence-based medicine. Experiments show that fine-tuning with MedReason significantly improves medical problem-solving capabilities, achieving up to 7.7% gains on DeepSeek-Distill-8B and outperforming the state-of-the-art Huatuo-o1-8B by up to 4.2% on the clinical benchmark MedBullets. Expert evaluations confirm that MedReason produces more medically precise and coherent reasoning across multiple specialties. The resulting MedReason-8B model achieves state-of-the-art performance among 7-8B parameter models on various medical benchmarks.

## Method Summary
MedReason generates medical Chain-of-Thought reasoning data by first extracting entities from question-answer pairs using GPT-4o, then mapping these entities to a medical knowledge graph (PrimeKG) through a multi-stage process of exact matching, embedding similarity (threshold τ=0.85), and LLM-based selection. Shortest paths are found between question and answer entity pairs, with an LLM pruning to the top K=3 most relevant paths. These paths serve as scaffolds for generating CoT responses, which are then quality-filtered to ensure they lead to correct answers. The resulting 32,682 high-quality CoT samples are used to fine-tune LLMs (3 epochs, lr=5e-6, batch_size=128, DeepSpeed ZeRO-3), significantly improving medical reasoning performance across multiple benchmarks.

## Key Results
- Achieves up to 7.7% gain on DeepSeek-Distill-8B compared to standard fine-tuning
- Outperforms state-of-the-art Huatuo-o1-8B by up to 4.2% on MedBullets clinical benchmark
- MedReason-8B achieves state-of-the-art performance among 7-8B parameter models on MedQA, MedMCQA, MMLU-Pro, PubMedQA, MedBullets, MedXpert, and HLE-medical
- Expert evaluations confirm improved medical precision and coherence in reasoning steps across specialties

## Why This Works (Mechanism)
The method works by grounding LLM reasoning in a structured knowledge graph, forcing the model to trace factual medical connections rather than generating potentially incorrect or hallucinated reasoning steps. By converting QA pairs into verifiable path sequences through the KG, the approach ensures each reasoning step corresponds to established medical knowledge relationships. The quality filtering step removes samples where the generated reasoning fails to reach the correct answer, creating a dataset of self-verifying reasoning paths that reinforce accurate medical logic during fine-tuning.

## Foundational Learning
- **Medical Knowledge Graph Navigation**: Understanding how to traverse semantic relationships in medical ontologies - needed to create valid reasoning paths; quick check: can trace logical connections between symptoms, diagnoses, and treatments in PrimeKG
- **Entity Extraction and Mapping**: Converting natural language medical concepts into structured KG nodes - needed to bridge unstructured text and structured knowledge; quick check: 90%+ success rate mapping medical entities to KG nodes
- **Chain-of-Thought Generation with Constraints**: Generating coherent reasoning that follows predetermined logical paths - needed to ensure factual consistency; quick check: generated CoT strictly follows KG path order and reaches correct answer
- **Quality Filtering of Generated Data**: Implementing verification mechanisms to ensure training data validity - needed to maintain dataset quality; quick check: filtering removes samples where CoT reasoning diverges from correct answer
- **Knowledge-Guided Fine-tuning**: Using structured knowledge paths to improve model reasoning capabilities - needed to transfer KG structure into model parameters; quick check: downstream performance improves on medical reasoning benchmarks

## Architecture Onboarding

**Component Map**: QA pairs -> GPT-4o entity extraction -> Entity-to-KG mapping (exact→similarity→LLM) -> Shortest path finding -> LLM path pruning (K=3) -> CoT generation -> Quality filtering -> Fine-tuning

**Critical Path**: The quality filtering step is critical as it ensures only factually accurate reasoning paths enter the training data. Without this verification, the model would learn incorrect medical reasoning patterns.

**Design Tradeoffs**: Using GPT-4o for entity extraction and path selection ensures high quality but introduces dependency on external API and cost barriers. The KG-based approach trades flexibility for factual accuracy, potentially limiting reasoning to known KG relationships. The aggressive quality filtering (28% sample reduction) prioritizes accuracy over dataset size.

**Failure Signatures**: Entity mapping failures occur when medical terms aren't present in KG (common for rare conditions or numeric answers). Quality filtering rejections indicate either poor path selection or CoT generation errors. Poor downstream performance suggests either KG incompleteness or insufficient training data diversity.

**3 First Experiments**:
1. Test entity extraction and mapping pipeline on 100 sample QA pairs to measure success rates and identify common failure patterns
2. Generate CoT for a small set of paths and verify quality filtering correctly identifies accurate vs. inaccurate reasoning
3. Fine-tune a small medical LLM on a subset of generated CoT data and measure performance on a held-out medical reasoning task

## Open Questions the Paper Calls Out
None

## Limitations
- Heavy reliance on GPT-4o API for entity extraction and path selection creates cost barriers and potential variability
- Quality of generated CoT depends entirely on completeness and accuracy of the PrimeKG knowledge graph, which lacks independent validation
- Filtering criteria that discards samples with non-extractable answers (e.g., numeric values) may introduce systematic bias toward certain question types
- Exact prompt templates for LLM steps are incomplete in the provided text, making faithful reproduction difficult

## Confidence
**High confidence**: Core methodology of using knowledge graphs to scaffold medical reasoning and reported accuracy improvements (7.7% gain)
**Medium confidence**: Clinical relevance and factual accuracy of generated reasoning steps (expert evaluation mentioned but limited details)
**Low confidence**: Reproducibility of exact implementation due to missing prompt templates and unspecified embedding models

## Next Checks
1. **Entity Mapping Pipeline Validation**: Implement and test the entity-to-KG mapping pipeline with sample medical entities, measuring success rates at each filtering stage to verify the reported 28% sample reduction is realistic
2. **Prompt Template Reconstruction**: Based on partially provided templates, reconstruct and test the full prompt sequences for Iselect, Iprune, Igen, and Ieval steps on sample QA pairs to ensure generated CoTs follow the intended path-guided reasoning structure
3. **Quality Filter Effectiveness**: Implement the answer-verification quality filter and test on a small set of generated CoTs to determine if the filter correctly identifies factually accurate vs. inaccurate reasoning, measuring the practical impact on dataset size and quality