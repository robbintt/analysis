---
ver: rpa2
title: Estimating Time Series Foundation Model Transferability via In-Context Learning
arxiv_id: '2509.23695'
source_url: https://arxiv.org/abs/2509.23695
tags:
- performance
- transferability
- time
- forecasting
- table
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of selecting the best time series
  foundation model (TSFM) for fine-tuning on a downstream dataset with limited data.
  With the growing number of TSFMs, efficiently identifying the most suitable model
  without exhaustive fine-tuning is critical but difficult.
---

# Estimating Time Series Foundation Model Transferability via In-Context Learning

## Quick Facts
- **arXiv ID**: 2509.23695
- **Source URL**: https://arxiv.org/abs/2509.23695
- **Reference count**: 35
- **Primary result**: TIMETIC achieves ~0.6 rank correlation in predicting TSFM transferability, delivering 30% improvement over zero-shot baselines

## Executive Summary
This paper addresses the challenge of selecting optimal time series foundation models (TSFMs) for fine-tuning on downstream datasets with limited data. With numerous TSFMs available, efficiently identifying the most suitable model without exhaustive fine-tuning is critical. The proposed TIMETIC method reframes transferability estimation as an in-context learning problem, using a tabular foundation model (TabPFN) to predict fine-tuned performance based on structured input encoding both data characteristics and model properties. Experiments demonstrate TIMETIC provides useful guidance for model selection while generalizing to unseen models and datasets.

## Method Summary
TIMETIC addresses TSFM selection by constructing a structured table encoding three key dimensions: data characteristics (via 20 informative time series features), model characteristics (via entropy profiles across model layers), and performance metrics. This table serves as context for a tabular foundation model (TabPFN) to predict fine-tuned performance on new datasets. The entropy profile provides an architecture-agnostic representation of models, enabling generalization across unseen architectures. The method reframes transferability estimation as an in-context learning task, allowing the TabPFN to leverage patterns across multiple model-dataset combinations to make predictions for new pairs.

## Key Results
- Achieves mean rank correlation of approximately 0.6 between predicted and actual fine-tuned performance
- Delivers 30% improvement in model ranking accuracy compared to zero-shot performance baselines
- Demonstrates generalization capability to unseen models and datasets while maintaining strong performance under few-shot conditions

## Why This Works (Mechanism)
The method works by transforming the transferability estimation problem into a structured prediction task. By encoding both data characteristics (through comprehensive time series features) and model properties (through entropy profiles), TIMETIC creates a rich representation space that captures the interactions between models and datasets. The TabPFN learns to map these representations to performance outcomes across multiple model-dataset pairs, enabling it to generalize predictions to new combinations. This in-context learning approach leverages the foundation model's ability to identify patterns across diverse scenarios rather than requiring task-specific training.

## Foundational Learning

**Time Series Feature Extraction** - Needed because raw time series data must be summarized into informative descriptors that capture relevant characteristics for transferability prediction. Quick check: Verify the 20 features cover stationarity, seasonality, trend, entropy, and spectral properties.

**Entropy Profile Computation** - Required to create architecture-agnostic model representations that capture information flow through different layers. Quick check: Ensure entropy profiles are normalized and capture both activation diversity and layer-wise information retention.

**Tabular Foundation Model (TabPFN)** - Essential for learning transferable patterns across model-dataset combinations without task-specific fine-tuning. Quick check: Validate that TabPFN can handle the structured input format and maintain performance across varying table sizes.

## Architecture Onboarding

**Component Map**: Time Series Features -> Entropy Profiles -> Structured Table -> TabPFN -> Performance Predictions

**Critical Path**: Data preprocessing → Feature extraction → Model encoding → Table construction → TabPFN prediction

**Design Tradeoffs**: Architecture-agnostic model representation (entropy profiles) vs. potentially missing model-specific architectural advantages; comprehensive feature engineering vs. computational overhead; TabPFN flexibility vs. potential overfitting to training combinations.

**Failure Signatures**: Poor correlation between predicted and actual performance; failure to generalize to novel model architectures; sensitivity to specific feature choices; computational bottlenecks in feature extraction or TabPFN inference.

**First Experiments**: 1) Validate feature extraction pipeline on diverse time series datasets, 2) Test entropy profile generation across different model architectures, 3) Benchmark TabPFN performance on synthetic transferability prediction tasks before full integration.

## Open Questions the Paper Calls Out
None

## Limitations
- Transferability predictions show only moderate correlation (0.6) with actual fine-tuned performance, limiting accuracy
- Method depends on having computed performance data for some model-dataset combinations, creating cold-start problems
- Computational costs of TabPFN predictions and runtime comparisons with baselines are not addressed

## Confidence
**High confidence**: Experimental methodology is sound with appropriate evaluation metrics and clear baseline comparisons.
**Medium confidence**: 30% improvement claims are based on specific experimental setup and may vary with different protocols.
**Medium confidence**: Generalization claims to unseen models are supported but would benefit from broader testing across diverse architectures.

## Next Checks
1. Test TIMETIC's predictions on at least 5-10 additional time series foundation models with different architectures (attention-based vs convolutional, different embedding strategies).
2. Conduct experiments on extreme few-shot scenarios (1-5 samples per dataset) to validate performance in low-data regimes.
3. Measure and report computational overhead of TabPFN predictions compared to direct fine-tuning approaches, including both training and inference times.