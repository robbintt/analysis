---
ver: rpa2
title: 'Curate, Connect, Inquire: A System for Findable Accessible Interoperable and
  Reusable (FAIR) Human-Robot Centered Datasets'
arxiv_id: '2506.00220'
source_url: https://arxiv.org/abs/2506.00220
tags:
- data
- datasets
- robotics
- system
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a system for curating, publishing, and accessing
  human-robot interaction (HRI) datasets using FAIR principles and a ChatGPT-based
  conversational interface. The system addresses the challenge of scattered, inconsistently
  described, and hard-to-access robotics datasets by implementing a structured data
  model, a data report template, a knowledge graph, and a chatbot interface.
---

# Curate, Connect, Inquire: A System for Findable Accessible Interoperable and Reusable (FAIR) Human-Robot Centered Datasets

## Quick Facts
- arXiv ID: 2506.00220
- Source URL: https://arxiv.org/abs/2506.00220
- Reference count: 40
- Expert evaluation showed chatbot achieved 4.65/5 for Information Retrieval, 4.9/5 for Answer Stability, Factual Accuracy, and Comparison Capability

## Executive Summary
This paper presents a system for curating, publishing, and accessing human-robot interaction (HRI) datasets using FAIR principles and a ChatGPT-based conversational interface. The system addresses the challenge of scattered, inconsistently described, and hard-to-access robotics datasets by implementing a structured data model, a data report template, a knowledge graph, and a chatbot interface. Expert evaluation showed the chatbot achieved high performance across four dimensions: Information Retrieval (4.65/5), Answer Stability (4.9), Factual Accuracy (4.9), and Comparison Capability (4.9). A pilot user session confirmed the system's effectiveness in helping researchers discover and explore datasets intuitively. The system improves dataset findability, accessibility, interoperability, and reuse, demonstrating the value of structured curation and metadata standardization in HRI research.

## Method Summary
The system implements a structured data model and data report template for HRI datasets, which are then integrated into a knowledge graph. A ChatGPT-based chatbot interface enables conversational access to this knowledge graph, allowing researchers to discover and explore datasets through natural language queries. The approach standardizes metadata representation across HRI datasets, making them more discoverable and comparable. Expert reviewers evaluated the chatbot's performance across four dimensions, while a pilot user session tested the system's usability for real-world research tasks.

## Key Results
- Chatbot achieved high expert ratings: 4.65/5 for Information Retrieval, 4.9/5 for Answer Stability, Factual Accuracy, and Comparison Capability
- Expert reviewers successfully identified datasets meeting specific criteria through conversational queries
- Pilot user session demonstrated intuitive dataset discovery and exploration capabilities
- The system enables standardized metadata representation, improving dataset comparability across HRI research

## Why This Works (Mechanism)
The system works by standardizing metadata representation across HRI datasets through a structured data model and report template. This standardization enables the construction of a comprehensive knowledge graph that captures relationships between datasets, making them more discoverable and comparable. The ChatGPT interface provides an intuitive conversational layer that allows researchers to query this knowledge graph using natural language, lowering the barrier to dataset discovery and exploration. By implementing FAIR principles (Findable, Accessible, Interoperable, Reusable), the system addresses the fundamental challenge of scattered and inconsistently described robotics datasets.

## Foundational Learning
- **FAIR Principles**: Why needed - Ensure datasets are findable, accessible, interoperable, and reusable across research communities. Quick check - Can datasets be discovered through standard search methods and used by different research groups?
- **Knowledge Graph Construction**: Why needed - Enable relationship discovery between datasets and facilitate complex queries. Quick check - Can the graph answer multi-hop queries about dataset relationships?
- **ChatGPT Integration**: Why needed - Provide intuitive conversational interface for dataset exploration. Quick check - Can users find relevant datasets through natural language queries without technical expertise?
- **Metadata Standardization**: Why needed - Enable consistent dataset description and comparison across HRI research. Quick check - Are datasets consistently described using the same terminology and structure?

## Architecture Onboarding

**Component Map**: User -> Chatbot Interface -> Knowledge Graph <- Data Model & Templates <- HRI Datasets

**Critical Path**: User query → Chatbot → Knowledge Graph traversal → Metadata matching → Result presentation

**Design Tradeoffs**: ChatGPT integration provides intuitive interface but introduces API dependency and potential cost; knowledge graph enables powerful queries but requires significant upfront metadata standardization effort; FAIR principles improve discoverability but may increase curation burden

**Failure Signatures**: Poor query results indicate knowledge graph gaps or inadequate metadata; system downtime suggests API or infrastructure issues; inconsistent answers reveal knowledge graph synchronization problems

**First Experiments**:
1. Test basic dataset discovery with simple queries across different HRI domains
2. Evaluate chatbot response consistency across repeated identical queries
3. Assess knowledge graph coverage by attempting to answer complex multi-dataset comparison queries

## Open Questions the Paper Calls Out
None specified in the source material.

## Limitations
- Evaluation relies on small sample of four expert reviewers and one pilot user session
- Performance metrics are self-reported rather than independently verified
- Knowledge graph construction process lacks transparency regarding scalability and maintenance requirements
- System's applicability beyond HRI domains remains untested

## Confidence

**High Confidence**:
- System architecture design and implementation details
- Expert evaluation methodology and results
- Chatbot performance across measured dimensions

**Medium Confidence**:
- Generalizability of results to broader HRI community
- Scalability of knowledge graph construction and maintenance
- Long-term sustainability of the curation approach

**Low Confidence**:
- Cross-domain applicability of the system
- Cost and privacy implications of ChatGPT integration
- Long-term dataset discoverability and reuse rates

## Next Checks

1. Independent replication of knowledge graph construction and chatbot performance evaluation by external researchers
2. Longitudinal study tracking dataset discoverability and reuse rates over 12+ months across multiple HRI research groups
3. Stress testing the system with 100+ diverse HRI datasets to evaluate scalability and performance degradation under load