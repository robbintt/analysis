---
ver: rpa2
title: 'Hermes the Polyglot: A Unified Framework to Enhance Expressiveness for Multimodal
  Interlingual Subtitling'
arxiv_id: '2602.00597'
source_url: https://arxiv.org/abs/2602.00597
tags:
- translation
- speaker
- lines
- hermes
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces Hermes, a unified multimodal framework for
  interlingual subtitling that addresses key challenges in translating subtitle dialogues,
  including semantic coherence, pronoun and terminology translation, and expressiveness.
  Hermes integrates three modules: Speaker Diarization uses both visual and audio
  modalities to accurately assign speakers to dialogue lines; Terminology Identification
  leverages LLM knowledge distillation to identify and translate domain-specific terms;
  and Expressiveness Enhancement employs a novel Segment-wise Adaptive Preference
  Optimization (SAPO) technique with LLM-as-a-Judge to enhance translation quality.'
---

# Hermes the Polyglot: A Unified Framework to Enhance Expressiveness for Multimodal Interlingual Subtitling

## Quick Facts
- arXiv ID: 2602.00597
- Source URL: https://arxiv.org/abs/2602.00597
- Reference count: 40
- Primary result: Introduces Hermes, a unified multimodal framework for interlingual subtitling that enhances expressiveness and translation quality across multiple language pairs.

## Executive Summary
Hermes addresses key challenges in interlingual subtitling by integrating speaker diarization, terminology identification, and expressiveness enhancement into a unified multimodal framework. The system leverages visual and audio modalities for accurate speaker assignment, uses LLM knowledge distillation for domain-specific terminology translation, and employs a novel Segment-wise Adaptive Preference Optimization (SAPO) technique with LLM-as-a-Judge to enhance translation quality. The framework demonstrates state-of-the-art performance in speaker diarization and generates contextually coherent, expressive translations that significantly outperform existing baselines across multiple language pairs, particularly excelling in low-resource translation directions.

## Method Summary
Hermes is a unified multimodal framework that addresses interlingual subtitling challenges through three integrated modules. Speaker Diarization combines visual and audio features using self-supervised learning and cross-modal attention to accurately assign speakers to dialogue lines. Terminology Identification leverages LLM knowledge distillation to identify and translate domain-specific terms while maintaining semantic coherence. Expressiveness Enhancement employs a novel Segment-wise Adaptive Preference Optimization (SAPO) technique that uses LLM-as-a-Judge to fine-tune translations for improved naturalness, vividness, and contextual appropriateness. The framework processes multimodal inputs simultaneously to generate high-quality subtitle translations that preserve speaker identity, domain terminology, and expressive quality.

## Key Results
- Achieves state-of-the-art speaker diarization performance with superior accuracy in assigning speakers to dialogue lines
- Generates significantly more expressive and contextually coherent translations compared to existing baselines
- Demonstrates superior performance in low-resource language pairs (Korean-to-Chinese, Chinese-to-Thai) with improvements in translation accuracy, naturalness, and vividness
- Outperforms existing approaches across multiple evaluation metrics including BLEU, METEOR, and human evaluation scores

## Why This Works (Mechanism)
Hermes works by addressing three critical subtitling challenges through multimodal integration. The Speaker Diarization module uses visual face recognition and audio speaker embeddings combined with cross-modal attention to accurately identify who is speaking, solving the fundamental problem of speaker attribution in dialogue translation. The Terminology Identification module leverages LLM knowledge distillation to identify domain-specific terms and maintain consistency across translations, preserving technical accuracy. The Expressiveness Enhancement module uses SAPO with LLM-as-a-Judge to iteratively refine translations, optimizing for multiple quality dimensions including naturalness, vividness, and contextual appropriateness. By unifying these components into a single framework, Hermes achieves synergistic improvements where each module reinforces the others' outputs.

## Foundational Learning
- **Multimodal Integration**: Combining visual and audio modalities is essential for accurate speaker diarization in video content, as it captures both visual identity and acoustic characteristics of speakers.
- **Knowledge Distillation from LLMs**: Using large language models as teachers for terminology identification and quality assessment enables transfer of semantic understanding to specialized translation tasks.
- **Preference Optimization**: Segment-wise Adaptive Preference Optimization (SAPO) allows fine-tuning of translation outputs based on multiple quality criteria, moving beyond simple accuracy metrics.
- **Speaker Diarization in Subtitling**: Accurate speaker assignment is crucial for maintaining dialogue coherence and context in translated subtitles, especially in multi-speaker scenarios.
- **Domain-Specific Terminology Translation**: Preserving technical and domain-specific terms across languages is critical for maintaining semantic accuracy in specialized content like TED Talks.

## Architecture Onboarding

**Component Map**: Speaker Diarization -> Terminology Identification -> Expressiveness Enhancement -> Translation Output

**Critical Path**: Multimodal input (video+audio) → Speaker Diarization (visual+audio features) → Terminology Identification (LLM distillation) → SAPO fine-tuning (LLM-as-Judge) → Final subtitle translation

**Design Tradeoffs**: 
- Multimodal integration increases accuracy but requires more computational resources and complex feature alignment
- LLM knowledge distillation provides semantic understanding but may introduce latency and dependency on large model APIs
- SAPO optimization improves quality but adds computational overhead to the translation pipeline

**Failure Signatures**: 
- Speaker Diarization failures manifest as incorrect speaker attribution, causing dialogue confusion in translations
- Terminology Identification errors result in inconsistent or incorrect domain term translation
- SAPO optimization failures lead to unnatural phrasing or loss of original meaning in pursuit of expressiveness

**First Experiments**:
1. Evaluate speaker diarization accuracy on benchmark video datasets with multiple speakers
2. Test terminology identification accuracy on domain-specific text corpora
3. Compare SAPO-enhanced translations against baseline models using automated metrics and human evaluation

## Open Questions the Paper Calls Out
None identified in the provided material.

## Limitations
- Primary evaluation on TED Talk subtitles may limit generalizability to other subtitling domains like movies or live broadcasts
- Computational efficiency and inference speed not detailed, critical for real-world subtitling applications
- Performance in low-resource language pairs needs further validation with more comprehensive datasets and metrics
- Heavy reliance on automated metrics without sufficient human evaluation to validate expressiveness claims

## Confidence
- **High Confidence**: Speaker Diarization performance and its contribution to speaker assignment accuracy
- **Medium Confidence**: Expressiveness Enhancement via SAPO and its impact on translation quality, given the lack of ablation studies
- **Low Confidence**: Generalization to non-TED subtitling domains and low-resource language pair performance due to limited dataset details

## Next Checks
1. Conduct ablation studies to quantify the individual contributions of Speaker Diarization, Terminology Identification, and SAPO to overall performance
2. Test Hermes on subtitling datasets from diverse domains (movies, TV shows, live broadcasts) to assess generalizability
3. Perform comprehensive human evaluations to validate claims of improved naturalness, vividness, and expressiveness in translations, particularly for low-resource language pairs