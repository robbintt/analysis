---
ver: rpa2
title: Exploring bidirectional bounds for minimax-training of Energy-based models
arxiv_id: '2506.04609'
source_url: https://arxiv.org/abs/2506.04609
tags:
- bound
- training
- lower
- learning
- upper
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses the instability of training Energy-Based Models
  (EBMs) through minimax games by proposing bidirectional bounds instead of minimizing
  a single lower bound. The core method involves maximizing a lower bound and minimizing
  an upper bound on the negative log-likelihood, using four different bounds: two
  lower bounds based on singular values of the generator Jacobian and mutual information,
  and two upper bounds based on gradient penalties and diffusion processes.'
---

# Exploring bidirectional bounds for minimax-training of Energy-based models

## Quick Facts
- arXiv ID: 2506.04609
- Source URL: https://arxiv.org/abs/2506.04609
- Authors: Cong Geng; Jia Wang; Li Chen; Zhiyong Gao; Jes Frellsen; Søren Hauberg
- Reference count: 40
- Primary result: Bidirectional bounds stabilize EBM training by sandwiching negative log-likelihood between upper and lower bounds, improving density estimation and sample generation

## Executive Summary
This paper addresses the instability of training Energy-Based Models (EBMs) through minimax games by proposing bidirectional bounds instead of minimizing a single lower bound. The core method involves maximizing a lower bound and minimizing an upper bound on the negative log-likelihood, using four different bounds: two lower bounds based on singular values of the generator Jacobian and mutual information, and two upper bounds based on gradient penalties and diffusion processes. The authors provide algorithms for evaluating these bounds and compare their empirical behavior. Results demonstrate that bidirectional bounds stabilize EBM training and yield high-quality density estimation and sample generation, outperforming or matching state-of-the-art on various tasks.

## Method Summary
The paper proposes to train EBMs by sandwiching the negative log-likelihood between an upper bound and a lower bound, then alternately minimizing the upper bound and maximizing the lower bound. This bidirectional approach contrasts with standard EBM training that minimizes only a lower bound, which can lead to instability when the bound is loose. The method uses four different bounds: singular value-based and mutual information-based lower bounds, paired with gradient penalty-based and diffusion-based upper bounds. The lower bounds approximate the negative entropy of the generator, while the upper bounds provide tractable approximations to the KL divergence. The training alternates between updating the energy function to minimize the upper bound and updating the generator to maximize the lower bound.

## Key Results
- Bidirectional bounds stabilize EBM training, avoiding energy divergence toward -∞ observed in standard minimax training
- On CIFAR-10, the method achieves FID scores around 28-30 and Inception Scores around 7.4-7.5
- On ImageNet 32x32, achieves FID scores around 6.6-14.6
- Shows good performance in mode counting and out-of-distribution detection

## Why This Works (Mechanism)

### Mechanism 1: Bidirectional Bounds Avoid Minimizing a Loose Lower Bound
Standard EBM training minimizes a lower bound L(θ) ≥ L(θ) on negative log-likelihood. When loose, minimization can drive parameters toward where the bound is loosest rather than optimal—potentially toward -∞. By sandwiching the objective (⌊L(θ)⌋ ≤ L(θ) ≤ ⌈L(θ)⌉) and alternately minimizing the upper bound (for Eθ) while maximizing the lower bound (for pg), training is constrained to regions where the objective is well-approximated.

### Mechanism 2: Gradient Penalty as Upper Bound on KL Divergence
Theorem 1 proves that for L-Lipschitz continuous f, the gap between log E[f(x)] and E[log f(x)] is bounded by M(E[∥∇log f(x)∥p] + m). Setting f(x) = exp(-Eθ(x))/pg(x) means this gap equals KL(pg∥pθ). When pθ = pg, the gradient term equals 0 and the bound is tight.

### Mechanism 3: Singular Value-Based Lower Bound on Generator Entropy
For generator G: Rd → RD with Jacobian Jz, change-of-variables gives log det(J⊺zJz) = Σlog(si²) ≥ d·log(s1²). This yields H[pg] ≥ H[p0] + Ez[d·log s1(z)]. The minimum singular value is computed via LOBPCG optimization of the Rayleigh quotient, using efficient Jacobian-vector products.

## Foundational Learning

- Concept: Energy-Based Models (EBMs)
  - Why needed here: The framework builds on EBMs defining distributions via unnormalized energy functions pθ(x) = exp(-Eθ(x))/Zθ. The intractable normalization constant Zθ motivates the entire bound-based approach.
  - Quick check question: Can you explain why computing Zθ = ∫exp(-Eθ(x))dx is intractable for high-dimensional data?

- Concept: Variational Lower Bounds via Jensen's Inequality
  - Why needed here: Eq. (5) uses Jensen's inequality to derive the core lower bound. Understanding variational inference principles is essential for grasping why the bounds work.
  - Quick check question: Why does Jensen's inequality give a lower bound when applied to log(E[f(x)])?

- Concept: Minimax Optimization (GAN-style training)
  - Why needed here: The bidirectional approach modifies the standard GAN minimax game. Understanding why min-max on a single bound causes instability illuminates the need for bidirectional bounds.
  - Quick check question: In standard adversarial training, what happens if the discriminator/bound becomes too loose?

## Architecture Onboarding

- Component map:
  - Energy function Eθ(x): Neural network outputting scalar energy values
  - Generator G(z): Maps latent z ~ N(0,I) to data space as x = G(z) + ε where ε ~ N(0, σ²I)
  - Discriminator T(x,z): Required only for mutual information lower bound (EBMMI+diff variant)
  - Optional: Normalizing flow for exact likelihood evaluation during testing

- Critical path:
  1. Sample real data x ~ pdata and latent z ~ N(0,I)
  2. Generate samples: x̃ = G(z) + ε
  3. Compute lower bound ⌊L(θ)⌋ via SV (requires minimum singular value via LOBPCG) or MI (requires discriminator forward pass)
  4. Compute upper bound ⌈L(θ)⌉ via GP (requires ∇xEθ and ∇xlog pg) or diffusion (requires score matching)
  5. Update Eθ by minimizing upper bound; update G by maximizing lower bound

- Design tradeoffs:
  - EBMSV+GP: Memory efficient (no extra network), but ~2.5× slower due to iterative singular value computation
  - EBMMI+diff: Time efficient (~1.3× baseline), but requires extra discriminator network and memory
  - SV bound may be unstable with CNN architectures (mode collapse observed on MNIST)
  - Diffusion bound has heuristic components (Fokker-Planck constraint not strictly enforced)

- Failure signatures:
  - Energy diverging toward -∞: Standard minimax without upper bound active
  - Mode collapse in generated samples: Insufficient entropy maximization or SV bound with incompatible architecture
  - High anisotropy index (>3): Generator not using full capacity; upper bound may be too weak
  - NaN during training: Singular value approaching zero or learning rate too high

- First 3 experiments:
  1. Reproduce toy data results (25-Gaussians, swiss-roll) with MLPs to verify bidirectional bounds stabilize training. Monitor both upper and lower bound curves for convergence.
  2. Compare EBMSV+GP vs EBMMI+diff on MNIST with fully-connected networks. Track mode capture on StackedMNIST and test log-likelihood using normalizing flow energy function.
  3. Scale to CIFAR-10 with DCGAN architecture using λ=0.0001 and Ms1²=0.1·zdim. Monitor FID, IS, and anisotropy index. If unstable, reduce λ or switch from GP to diffusion upper bound.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the energy function $E_\theta(x,t)$ be parameterized to strictly satisfy the Fokker-Planck equation for the diffusion-based upper bound?
- Basis in paper: [explicit] The authors state in the Limitations section that it is "not clear how to design $E_\theta(x,t)$ to make it satisfy the Fokker-Planck equation," noting the current implementation remains heuristic.
- Why unresolved: The current approximation ($E_\theta(x,t) = E_\theta(x)/\sigma(t)$) lacks a theoretical guarantee to satisfy the differential equation governing the diffusion process.
- What evidence would resolve it: A derivation of a network architecture or regularization term that analytically enforces the Fokker-Planck constraint, or proof that the approximation error is bounded.

### Open Question 2
- Question: Why does the singular value-based lower bound (EBMSV+GP) suffer from mode collapse with convolutional architectures while performing well with fully connected networks?
- Basis in paper: [explicit] Section 4.3 notes the model "is sensitive to the choice of network structure," observing that it "suffers from mode-collapse when using a CNN network" on StackedMNIST.
- Why unresolved: The paper observes the empirical failure but does not provide a theoretical analysis of how convolutional weight sharing interacts with the Jacobian singular value estimation.
- What evidence would resolve it: An ablation study or theoretical analysis linking convolutional inductive biases to instability in the singular value entropy estimator.

### Open Question 3
- Question: Can the theoretical violation caused by prematurely stopping the singular value solver be mathematically justified as a valid approximation?
- Basis in paper: [inferred] The Limitations section notes that the practical implementation stops the iterative solver prematurely to save computation, which "technically violates the bound," yet empirically works well.
- Why unresolved: There is a discrepancy between the mathematical requirement for a lower bound and the practical implementation which uses a low-precision estimate.
- What evidence would resolve it: A convergence analysis proving that the optimization landscape of the premature estimate approximates the true gradient sufficiently to maintain training stability.

## Limitations
- The paper provides limited analysis of bound tightness during training, with no systematic study of how bound gaps evolve across training iterations or datasets
- The SV-based lower bound shows instability with CNN architectures, yet the paper scales to CIFAR-10 and ImageNet using CNNs without addressing this limitation
- Several theoretical contributions lack strong empirical validation, including the gradient penalty bound's practical tightness and the mutual information bound's advantage

## Confidence
- High confidence: The core bidirectional bound framework addresses a real problem (minimax training instability), and the basic empirical results (CIFAR-10 FID/IS scores) are reproducible
- Medium confidence: The proposed bounds provide practical stabilization, but the extent of their advantage over existing methods isn't definitively established
- Low confidence: Claims about the mutual information bound's superiority and the diffusion upper bound's effectiveness are weakly supported by empirical evidence

## Next Checks
1. Implement systematic tracking of upper-lower bound gaps during training across multiple datasets and architectures. Quantify how gap magnitude correlates with training stability metrics.
2. Systematically vary the upper bound strength (λ parameter) and measure the tradeoff between training stability and final sample quality. Compare against using gradient penalty alone without bidirectional bounds.
3. Evaluate all four bound variants (SV/GP, MI/diff, SV/diff, MI/GP) on the same CNN architectures across multiple datasets to definitively determine which combinations work robustly versus which show architecture-dependent failures.