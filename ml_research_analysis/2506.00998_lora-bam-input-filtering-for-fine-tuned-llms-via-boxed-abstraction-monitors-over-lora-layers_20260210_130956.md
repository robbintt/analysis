---
ver: rpa2
title: 'LoRA-BAM: Input Filtering for Fine-tuned LLMs via Boxed Abstraction Monitors
  over LoRA Layers'
arxiv_id: '2506.00998'
source_url: https://arxiv.org/abs/2506.00998
tags:
- detection
- lora-bam
- lora
- learning
- out-of-distribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LoRA-BAM addresses the problem of unreliable outputs from fine-tuned
  LLMs on out-of-distribution (OoD) queries by introducing an input filtering mechanism.
  The core method uses boxed abstraction monitors applied to the LoRA layers of fine-tuned
  models.
---

# LoRA-BAM: Input Filtering for Fine-tuned LLMs via Boxed Abstraction Monitors over LoRA Layers

## Quick Facts
- **arXiv ID:** 2506.00998
- **Source URL:** https://arxiv.org/abs/2506.00998
- **Reference count:** 11
- **Primary result:** Up to 99% rejection rate on far-OoD datasets while maintaining only 3% rejection of paraphrased in-distribution queries.

## Executive Summary
LoRA-BAM introduces an input filtering mechanism for fine-tuned LLMs that detects out-of-distribution (OoD) queries by monitoring feature vectors extracted from LoRA adapter layers. The method clusters fine-tuning data features and encloses each cluster in an axis-aligned box, rejecting queries that fall outside all boxes. A novel paraphrase-aware regularization loss during fine-tuning ensures semantically equivalent queries cluster tightly in the feature space, improving monitor robustness. The approach significantly outperforms Mahalanobis distance and cosine similarity baselines on OoD detection tasks.

## Method Summary
LoRA-BAM operates by first fine-tuning a pretrained LLM with LoRA adapters on in-distribution data (e.g., MedMCQA), incorporating a combined loss of cross-entropy for response correctness and Euclidean distance regularization between original and paraphrased queries. Feature vectors are extracted from the LoRA-modified projection layer, clustered using k-means, and each cluster is enclosed in an axis-aligned box with variance-based enlargement. At inference, queries are rejected as OoD if their feature vectors lie outside all boxes. The box enlargement factor Δ is calibrated using FPR95 on held-out ID data to balance false positive and false negative rates.

## Key Results
- Achieves up to 99% rejection rates on far-OoD datasets (Law, CS) while maintaining only 3% rejection of paraphrased in-distribution queries.
- Outperforms Mahalanobis distance and cosine similarity baselines by significant margins on OoD detection tasks.
- Paraphrase regularization loss is critical: without it, OoD detection degrades substantially (22-55% rejection vs 90-99% with regularization).

## Why This Works (Mechanism)

### Mechanism 1: LoRA Feature Extraction for Domain Specificity
Feature vectors extracted from LoRA adapter layers (specifically A⃗vin) carry domain-specific adaptations, providing a discriminative signal for OoD detection. LoRA adapters (matrices A and B) are the only parameters modified during fine-tuning, so extracting the intermediate representation A⃗vin captures how the model processes inputs through its adapted pathways. The core assumption is that the LoRA feature space reflects semantic domain boundaries rather than superficial token patterns.

### Mechanism 2: Non-Convex Boxed Abstraction for Decision Boundaries
A finite union of axis-aligned boxes creates non-convex decision boundaries that better capture the irregular geometry of in-distribution feature clusters than convex methods. K-means partitions training features into clusters, each enclosed by an axis-aligned box defined by per-dimension min/max bounds enlarged by variance-based margins. The core assumption is that in-distribution features form clusterable, approximately axis-aligned regions.

### Mechanism 3: Paraphrase-Aware Regularization for Robust Monitoring
Adding a Euclidean distance regularization loss between original and paraphrased queries during fine-tuning shapes the feature space so semantically equivalent queries cluster tightly, improving monitor robustness. The core assumption is that paraphrase pairs are semantically equivalent and minimizing their feature distance does not collapse OoD discrimination.

## Foundational Learning

- **Concept: LoRA (Low-Rank Adaptation)**
  - **Why needed:** LoRA-BAM monitors operate specifically on LoRA adapter layers; understanding that W' = W + BA is essential to grasp where feature vectors originate.
  - **Quick check:** Can you explain why A⃗vin (the output of matrix A applied to input) would carry domain-specific information rather than the base model's frozen weights?

- **Concept: Out-of-Distribution Detection Thresholds (FPR95/TPR)**
  - **Why needed:** The paper calibrates box enlargement Δ using FPR95—ensuring 95% of ID samples are accepted. Understanding this tradeoff is critical for deployment.
  - **Quick check:** If you set Δ too low, what happens to false positives vs. false negatives in OoD detection?

- **Concept: K-means Clustering and Axis-Aligned Bounding Boxes**
  - **Why needed:** The monitor's geometry depends on k-means cluster quality and box tightness. Poor clustering propagates to poor OoD boundaries.
  - **Quick check:** Why might axis-aligned boxes struggle with highly correlated feature dimensions, and how does variance-based enlargement partially mitigate this?

## Architecture Onboarding

- **Component map:**
  Input Query q -> [Pretrained LLM + LoRA Adapters] -> Extract f_A(q) <- (A⃗vin from LoRA layer) -> [Box Containment Check] -> [Decision] If outside ALL boxes → Reject as OoD If inside ANY box → Accept for generation

- **Critical path:**
  1. Training phase: Fine-tune with combined loss (cross-entropy + paraphrase regularization)
  2. Monitor construction: Extract f_A(q) for all training queries → k-means cluster → compute boxes → enlarge by Δ·σ
  3. Calibration: Tune Δ to achieve FPR95 on held-out ID data
  4. Inference: O(md) box containment check before generation

- **Design tradeoffs:**
  - Δ (box enlargement factor): Larger Δ → more permissive (fewer false ID rejections) but lower OoD sensitivity
  - m (number of clusters): More clusters → tighter boxes but risk overfitting; fewer clusters → looser coverage
  - Regularization weight λ: Higher λ → tighter paraphrase clustering but potential loss of task performance
  - Feature dimension d: Higher d → more expressive but noisier boxes; PCA reduction (future work) may help

- **Failure signatures:**
  - High paraphrase rejection rate: Δ too small or regularization insufficient
  - Low far-OoD rejection: Boxes too loose; reduce Δ or increase cluster granularity
  - Near-OoD confused with ID: Feature space insufficiently discriminative; consider deeper LoRA layers or dimensionality reduction
  - Inconsistent results across seeds: Cluster instability; increase k-means initialization runs

- **First 3 experiments:**
  1. Reproduce baseline comparison: Implement Mahalanobis and cosine similarity OoD detectors on the same Qwen2.5-0.5B + MedQA setup; verify LoRA-BAM achieves the ~55-99% rejection rates.
  2. Ablate regularization: Train two models—one with, one without paraphrase regularization—and compare box tightness (average per-dimension variance σ_i,j) and paraphrase rejection rates.
  3. Stress-test box geometry: Visualize 2D PCA projections of f_A(q) for ID, near-OoD, and far-OoD; verify that boxes form reasonable boundaries and identify any pathological overlaps.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does LoRA-BAM maintain its superior OoD detection efficacy when applied to significantly larger model architectures (e.g., 70B parameters) and diverse model families?
- **Basis in paper:** [explicit] The authors state in the Limitations section that experiments are currently "limited to Qwen2.5:0.5B" and they "intend to scale our experiments to larger models of up to 70B parameters."
- **Why unresolved:** The feature distributions in LoRA layers may behave differently or require different clustering strategies in much larger, more complex models compared to the 0.5B parameter model tested.
- **What evidence would resolve it:** Empirical results from LoRA-BAM on 70B parameter models (e.g., Llama-3-70B) showing comparable or superior rejection rates on far-OoD datasets relative to baselines.

### Open Question 2
- **Question:** Can dimensionality reduction techniques like PCA be effectively integrated to improve interpretability without degrading the geometric tightness of the boxed abstraction?
- **Basis in paper:** [explicit] The authors mention in Concluding Remarks that they "consider future work by introducing dimensionality reduction techniques such as PCA" to help visualize the scope of the model's capabilities.
- **Why unresolved:** Projecting high-dimensional LoRA features to a lower dimension could distort the cluster structures, potentially leading to looser boxes and higher false positive rates for paraphrased queries.
- **What evidence would resolve it:** A study comparing the OoD detection performance (FPR95) and visualization utility in the reduced space versus the full feature space.

### Open Question 3
- **Question:** How sensitive is LoRA-BAM to the choice of fine-tuning domain and experimental randomness compared to baselines?
- **Basis in paper:** [explicit] The Limitations section notes the fine-tuning dataset is "restricted" to prior work's data and the study was conducted with "limited random seeds."
- **Why unresolved:** It is unclear if the method's success is specific to the medical domain (MedMCQA) or if the clustering results are stable across different initializations.
- **What evidence would resolve it:** Statistical analysis of performance variance across multiple random seeds and evaluation on diverse fine-tuning domains (e.g., legal, coding, or finance).

## Limitations

- **Architecture specificity:** The monitor relies on LoRA adapters being the only trainable components; performance on full fine-tuning or other parameter-efficient methods is unknown.
- **Cluster stability:** K-means initialization and m (number of clusters) are not specified; results may vary significantly across seeds or cluster counts.
- **Paraphrase generation:** No details on paraphrase model, prompt, or diversity metrics; quality of paraphrases directly affects regularization effectiveness.

## Confidence

- **High confidence:** Core mechanism of boxed abstraction monitors + LoRA feature extraction (mathematical formulation and experimental results are consistent).
- **Medium confidence:** Paraphrase regularization's contribution (ablated in Table 1, but no ablation for k-means m or box enlargement strategy).
- **Low confidence:** Generalization to other LoRA configurations (rank≠32), base model sizes (Qwen2.5-0.5B only), or fine-tuning datasets beyond MedMCQA.

## Next Checks

1. **K-means sensitivity test:** Vary m (clusters) from 3 to 15; measure impact on OoD rejection rates and paraphrased ID rejection. Report stability metrics.
2. **Regularization ablation:** Remove paraphrase loss entirely; compare feature space geometry (average intra-cluster variance) and OoD detection performance.
3. **Cross-dataset generalization:** Apply trained LoRA-BAM monitor to a different fine-tuning task (e.g., legal Q&A or biomedical QA); evaluate whether boxed abstraction remains effective.