---
ver: rpa2
title: 'Beyond Scaling Curves: Internal Dynamics of Neural Networks Through the NTK
  Lens'
arxiv_id: '2507.05035'
source_url: https://arxiv.org/abs/2507.05035
tags:
- scaling
- effective
- learning
- rank
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper examines neural scaling laws through the lens of the
  Neural Tangent Kernel (NTK) to understand the internal dynamics that drive performance
  improvements. The authors analyze how scaling model size versus dataset size affects
  neural network behavior by tracking two NTK-based metrics: the trace (measuring
  magnitude) and effective rank (measuring dimensionality).'
---

# Beyond Scaling Curves: Internal Dynamics of Neural Networks Through the NTK Lens

## Quick Facts
- **arXiv ID**: 2507.05035
- **Source URL**: https://arxiv.org/abs/2507.05035
- **Reference count**: 40
- **Key outcome**: Performance scaling alone is insufficient for understanding neural network mechanisms; internal NTK dynamics reveal divergent learning behaviors even with identical loss exponents.

## Executive Summary
This paper examines neural scaling laws through the Neural Tangent Kernel (NTK) to understand the internal dynamics driving performance improvements. The authors analyze how scaling model size versus dataset size affects neural networks by tracking two NTK-based metrics: the trace (measuring magnitude) and effective rank (measuring dimensionality). They find that similar loss scaling exponents can arise from opposite internal dynamics - model scaling increases initial trace while data scaling increases trace adaptation rate. The effective rank decreases with data scaling but increases with model scaling. Additionally, the study investigates the transition from feature learning to kernel behavior as model width increases, identifying the maximum width supporting feature learning to be more than ten times smaller than typical large language model widths.

## Method Summary
The study employs dense MLPs with LeCun initialization, ReLU activations, and Adam optimizer on MNIST, Fashion-MNIST, and CIFAR-10 datasets. NTK is computed on held-out test data throughout training using Neural Tangents library. Key metrics include trace dynamics (Tr(Θ)), effective rank (Γ(Θ) = exp(S_vN(Θ))), adaptation rate (χ(Θ) = δTrΘ/δlog L_train), and trace ratio (β = (TrΘ_min - TrΘ_0)/TrΘ_0). The analysis compares model scaling (varying width) and data scaling (varying dataset size) effects on these NTK properties, with 20 ensemble seeds per configuration.

## Key Results
- Model scaling and data scaling produce identical loss exponents (~0.5) through fundamentally opposite NTK dynamics
- Effective rank increases with model width (feature learning) but decreases with data scaling (kernel regime)
- The transition from feature learning to kernel behavior occurs at widths 500-1000, significantly smaller than LLM scales
- Initial NTK trace correlates with model scaling, while adaptation rate correlates with data scaling

## Why This Works (Mechanism)

### Mechanism 1: Divergent Internal Dynamics Under Identical Loss Scaling
Model scaling and data scaling produce similar power-law loss exponents (~0.5) through fundamentally opposite internal dynamics. Model scaling increases the initial NTK trace (Tr(Θ₀) ∝ model width) while keeping adaptation rate constant. Data scaling increases the trace adaptation rate (χ(Θ) = δTrΘ/δlog L_train) while keeping initial trace constant. Both pathways improve loss but through distinct NTK modifications. This effect is cleanest in variance-limited regimes where one factor bottlenecks scaling.

### Mechanism 2: Effective Rank as Feature Learning Indicator
The effective rank Γ(Θ) = exp(S_vN(Θ)) tracks the number of active learning dimensions; its power-law increase with model width signals active feature learning, while saturation/decline signals kernel regime onset. Finite-width networks modify their NTK during training. The effective rank captures how many eigenmodes meaningfully contribute. When Γ(Θ_min) ∝ m^α_Γ (width m), the network allocates capacity to new dimensions—feature learning. When this saturates, additional width yields diminishing representational returns.

### Mechanism 3: Trace Ratio Quantifies Feature-Kernel Transition Width
The dimensionless trace ratio β = (TrΘ_min - TrΘ₀)/TrΘ₀ converges to zero at the kernel limit; its power-law decline (β ∝ m^α_β, α_β ≈ -0.7 to -0.8) identifies when feature learning degrades. In the infinite-width limit, the NTK becomes static (Jacot et al., 2018). The trace ratio measures relative NTK change during training. As width increases, initialization dominates and training-driven NTK evolution becomes negligible—marking the kernel regime.

## Foundational Learning

- **Neural Tangent Kernel (NTK)**: The entire analysis framework decomposes learning through the NTK eigenspectrum. Understanding that Θ = ∇_θf(X,θ)^⊤∇_θf(X,θ) describes how gradient updates propagate through parameter space is essential. Quick check: Can you explain why the NTK of an infinitely wide network remains static during training?

- **Eigenvalue Spectrum Decomposition**: The paper decomposes NTK into trace (magnitude) and effective rank (dimensionality via eigenvalue distribution). Understanding that Θ = Tr(Θ) · Q^⊤ΛQ connects magnitude to directional structure is essential. Quick check: What does it mean for the effective rank to be the exponential of von Neumann entropy?

- **Feature Learning vs. Kernel/Lazy Training Regime**: The paper's central claim is that LLM-scale widths may operate in or near the kernel regime, losing feature learning. This requires distinguishing representation evolution from kernel regression behavior. Quick check: In the lazy training regime, why do features remain fixed at initialization?

## Architecture Onboarding

- **Component map**: Dense MLP -> NTK computation (Neural Tangents) -> Eigenvalue decomposition -> Trace and effective rank extraction -> Trace dynamics analysis

- **Critical path**: 1) Train network with gradient flow/SGD while checkpointing at each epoch 2) Compute NTK on test set at each checkpoint 3) Extract trace and compute eigendecomposition for effective rank 4) Plot Tr(Θ) vs. log(L_train) to compute adaptation rate 5) Identify minimum test loss point and extract Γ(Θ_min), χ(Θ_min) 6) For transition analysis: sweep widths and compute β ratio

- **Design tradeoffs**: Full-batch vs. mini-batch (paper uses full-batch for clean gradient flow); test NTK sample size (128 samples balances computation with statistical stability); ensemble size (20 random seeds used); width sweep density (need sufficient points to identify power-law exponents)

- **Failure signatures**: Effective rank increases monotonically without saturation (may need wider sweep or deeper architecture); trace ratio doesn't decline (likely insufficient width range or non-standard initialization); transition points differ between trace ratio and effective rank (depth-dependence effect)

- **First 3 experiments**: 1) Replicate MNIST width scaling (widths 32-8192, 3-layer dense, 100 training samples) to validate trace dynamics 2) Compute effective rank and trace ratio for widths 256-16384 on CIFAR-10 to identify transition width; compare 3-layer vs. 4-layer architectures 3) Sweep dataset size (128-16384) with fixed small model (8-unit 4-layer) to confirm data scaling reduces effective rank

## Open Questions the Paper Calls Out

- **Open Question 1**: Does the transition from feature learning to kernel behavior occur at significantly larger widths in state-of-the-art LLMs compared to the dense feed-forward networks analyzed in this study? The authors identify the maximum width supporting feature learning in their setups as "more than ten times smaller than typical large language model widths" and call for addressing whether kernel-like behavior affects LLM performance.

- **Open Question 2**: How does network depth quantitatively shift the transition point where feature learning diminishes and kernel behavior begins to dominate? Section 5.1 notes that for deeper architectures, transition points for trace ratio and effective rank coincide, whereas they diverge for shallower networks, concluding that "the interplay of width and depth is crucial."

- **Open Question 3**: How do the opposing internal dynamics of model scaling (initial trace) and data scaling (adaptation rate) interact when model capacity and dataset size are increased simultaneously? The limitations section notes the analysis focuses on regimes where one factor is small while the other is scaled large, stating dynamics "may not directly be comparable to scenarios where the model and data have more similar levels of complexity."

## Limitations

- The analysis is limited to dense MLPs on image classification tasks, which may not generalize to convolutional architectures, transformers, or different problem domains
- The study uses full-batch training and small datasets, which may not reflect the stochastic optimization dynamics of large-scale deep learning
- Effective rank and trace ratio metrics may not fully capture the transition from feature learning to kernel behavior, as they measure NTK eigenvalue structure rather than direct feature evolution

## Confidence

**High Confidence**: The observation that model scaling and data scaling produce similar loss exponents through opposite NTK dynamics is well-supported by empirical results across multiple datasets and architectures.

**Medium Confidence**: The identification of the feature-to-kernel transition width and interpretation of effective rank as a feature learning indicator, while mathematically consistent, requires additional validation across architectures and tasks to confirm generalizability.

**Low Confidence**: The claim that LLM-scale models may operate in the kernel regime is largely theoretical extrapolation from small-scale experiments, as modern LLMs have vastly different architectures and training regimes.

## Next Checks

1. **Cross-architecture validation**: Repeat the effective rank and trace ratio analysis on convolutional networks (CNNs) and transformer architectures to verify that the feature-kernel transition dynamics are architecture-independent.

2. **Deeper transition characterization**: Implement layer-wise NTK analysis to determine whether the effective rank and trace ratio transitions occur simultaneously across all layers or at different widths, particularly for deep networks on complex datasets.

3. **Dynamic range extension**: Scale up the width sweep to 32K-64K units on MNIST/Fashion-MNIST to precisely identify the asymptotic behavior of the effective rank and trace ratio, confirming whether power-law trends continue or exhibit different scaling regimes.