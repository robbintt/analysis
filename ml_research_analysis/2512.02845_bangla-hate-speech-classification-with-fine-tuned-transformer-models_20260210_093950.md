---
ver: rpa2
title: Bangla Hate Speech Classification with Fine-tuned Transformer Models
arxiv_id: '2512.02845'
source_url: https://arxiv.org/abs/2512.02845
tags:
- hate
- speech
- bangla
- detection
- transformer-based
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses hate speech classification in Bangla, a low-resource
  language with limited annotated datasets. The authors focus on Subtask 1A (hate
  type classification) and Subtask 1B (target identification) from the BLP 2025 shared
  task, using YouTube comments as input.
---

# Bangla Hate Speech Classification with Fine-tuned Transformer Models

## Quick Facts
- **arXiv ID:** 2512.02845
- **Source URL:** https://arxiv.org/abs/2512.02845
- **Reference count:** 9
- **Primary result:** Fine-tuned BanglaBERT outperforms other transformer models and traditional baselines for hate speech classification in Bangla, achieving 0.71 accuracy and 0.70 micro-F1 on Subtask 1A.

## Executive Summary
This paper tackles hate speech classification in Bangla, a low-resource language, through participation in the BLP 2025 shared task. The authors implement multiple baseline methods (SVM, logistic regression, random forest, decision tree) alongside fine-tuned transformer models (DistilBERT, BanglaBERT, m-BERT, XLM-RoBERTa) for two subtasks: hate type classification and target identification. Due to computational constraints, they downsample the dataset to one-third of its original size. BanglaBERT achieves the highest performance across both subtasks, demonstrating that language-specific pretraining is more effective than multilingual models for this low-resource setting.

## Method Summary
The authors implement traditional machine learning baselines including SVM, logistic regression, random forest, and decision tree, alongside fine-tuned transformer models such as DistilBERT, BanglaBERT, m-BERT, and XLM-RoBERTa. All models are evaluated on two subtasks from the BLP 2025 shared task using YouTube comments as input data. The evaluation employs standard metrics including accuracy, precision, recall, and micro-F1. Due to computational constraints, the dataset is downsampled to one-third of its original size before training and evaluation.

## Key Results
- BanglaBERT achieves highest performance with 0.71 accuracy and 0.70 micro-F1 on Subtask 1A
- All transformer models outperform baseline methods except DistilBERT, which underperforms relative to best baselines
- BanglaBERT (smaller model) outperforms larger multilingual models, indicating language-specific pretraining superiority
- Subtask 1B results show BanglaBERT achieving 0.71 accuracy and 0.68 micro-F1

## Why This Works (Mechanism)
The superior performance of BanglaBERT stems from its language-specific pretraining on Bangla text, which enables better capture of linguistic nuances, morphological features, and contextual patterns specific to the language. Unlike multilingual models that must balance multiple languages during pretraining, BanglaBERT can focus entirely on the target language's characteristics. This specialized pretraining is particularly valuable for low-resource languages where general multilingual models may lack sufficient exposure to language-specific phenomena. The transformer architecture's attention mechanisms effectively handle the noisy nature of social media text, capturing long-range dependencies and contextual relationships critical for hate speech detection.

## Foundational Learning

**Tokenization**
- *Why needed:* Converts raw text into subword units that models can process
- *Quick check:* Verify tokenization preserves meaning of hate-related terms and handles Bangla script correctly

**Attention Mechanisms**
- *Why needed:* Enables models to focus on relevant words when determining hate speech context
- *Quick check:* Examine attention weights to confirm model focuses on key hate indicators

**Fine-tuning**
- *Why needed:* Adapts pretrained language models to specific classification task using limited labeled data
- *Quick check:* Monitor validation loss to ensure model is learning task-specific patterns without overfitting

## Architecture Onboarding

**Component Map**
Preprocessing -> Tokenizer -> Transformer Backbone (BanglaBERT) -> Classification Head -> Output Layer

**Critical Path**
BanglaBERT encoder processes tokenized input through multiple self-attention layers, extracting contextual representations that feed into a linear classification layer for final prediction

**Design Tradeoffs**
- Language-specific pretraining vs. multilingual coverage: BanglaBERT sacrifices breadth for depth in Bangla language understanding
- Model size vs. performance: Smaller BanglaBERT outperforms larger multilingual models, suggesting efficiency gains from focused pretraining
- Computational cost vs. accuracy: Downsampling enabled experimentation but may limit generalizability

**Failure Signatures**
- Confusion between overlapping hate categories due to similar linguistic patterns
- Poor performance on out-of-domain text from platforms other than YouTube
- Sensitivity to spelling variations and code-mixing common in social media

**First Experiments**
1. Ablation study removing self-attention layers to measure impact on hate detection accuracy
2. Cross-domain evaluation testing model on Twitter/Facebook data to assess generalization
3. Error analysis categorizing misclassifications by hate type and input characteristics

## Open Questions the Paper Calls Out
None identified in the paper.

## Limitations
- Dataset downsampling to one-third original size due to computational constraints may affect performance generalization
- Evaluation limited to YouTube comments, potentially limiting cross-platform applicability
- No statistical significance testing between model performances to validate observed differences

## Confidence
- **High confidence:** Transformer models generally outperform traditional baselines in text classification
- **Medium confidence:** BanglaBERT performance metrics are reliable but affected by downsampling
- **Medium confidence:** Language-specific pretraining superiority claim needs validation across more tasks
- **Low confidence:** DistilBERT underperformance may be implementation-specific rather than inherent limitation

## Next Checks
1. Re-run experiments on full dataset to verify performance rankings and scores are robust to data size
2. Conduct statistical significance testing to determine if performance differences between models are meaningful
3. Perform cross-validation and learning curve analysis to assess model stability and identify overfitting/underfitting issues