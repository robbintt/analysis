---
ver: rpa2
title: PAC Learnability in the Presence of Performativity
arxiv_id: '2510.08335'
source_url: https://arxiv.org/abs/2510.08335
tags:
- performative
- distribution
- risk
- learning
- probability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper establishes learnability for binary classification under
  performativity, where a classifier influences its own test distribution. The authors
  introduce a performative empirical risk (PER) estimator that uses only training
  data to estimate risk on the shifted distribution.
---

# PAC Learnability in the Presence of Performativity

## Quick Facts
- arXiv ID: 2510.08335
- Source URL: https://arxiv.org/abs/2510.08335
- Reference count: 40
- Primary result: Any PAC-learnable hypothesis class remains PAC-learnable under linear posterior performative drifts using a novel performative empirical risk estimator.

## Executive Summary
This paper establishes learnability for binary classification under performativity, where a classifier influences its own test distribution. The authors introduce a performative empirical risk (PER) estimator that uses only training data to estimate risk on the shifted distribution. They prove that any hypothesis class PAC-learnable in standard binary classification remains PAC-learnable under linear posterior performative drifts. Generalization bounds show that minimizing PER yields near-optimal performative risk with high probability. Experiments on synthetic and real datasets (Credit Score, Folktables) demonstrate PERM's superior performance compared to standard ERM as performativity strength increases, with accuracy improvements up to 30% in strong performativity regimes.

## Method Summary
The method introduces a performative empirical risk (PER) estimator that provides an unbiased estimate of the true performative risk under linear posterior performative drifts. The PERM framework constructs a custom surrogate loss function that captures the classifier-dependent terms separately, allowing standard convex optimization techniques to be applied. The approach handles both perfect information (known shift parameters) and imperfect information (parameters within known intervals) scenarios, with generalization bounds showing learnability is preserved in both cases. The surrogate loss uses logistic functions to transform the non-smooth 0-1 performative risk into a differentiable objective.

## Key Results
- Any hypothesis class PAC-learnable in standard binary classification remains PAC-learnable under linear posterior performative drifts.
- PERM achieves accuracy improvements up to 30% over standard ERM in strong performativity regimes.
- Generalization bounds show that minimizing PER yields near-optimal performative risk with high probability.
- The framework remains robust to parameter uncertainty, with learnability preserved when shift parameters lie within known bounded intervals.

## Why This Works (Mechanism)

### Mechanism 1: Linear Posterior Risk Reweighting
- **Claim:** If the performative distribution shift affects the label posterior linearly, the true performative risk can be estimated unbiasedly using only data from the original distribution.
- **Mechanism:** The authors model the shift in P(Y|X) as a linear function of the classifier's prediction h(x). Under this specific "linear posterior performative drift," the expected loss on the shifted distribution decomposes into a linear combination of expectations over the original distribution (Lemma 4.1). This allows construction of a Performative Empirical Risk (PER) estimator, PR_n(h), which acts as a reweighting layer over standard empirical risk terms.
- **Core assumption:** The performative effect is strictly confined to the conditional label distribution Y|X and follows the linear relationship defined by parameters a_1, ..., a_4 in Eq. (2).
- **Evidence anchors:**
  - [abstract] "We construct a performative empirical risk function... and is yet an unbiased estimate of the true risk."
  - [section 4.1] "Lemma 4.1... an unbiased estimator of PR(h) is the performative empirical risk PR_n(h)."
  - [corpus] Corpus neighbors confirm "Performative Risk Control" relies on similar reweighting/calibration principles, though specific linear decomposition is unique to this work.
- **Break condition:** If the distribution shift includes non-linear dependencies or covariate shifts (changes in X) not captured by the Radon-Nikodym derivative assumptions in Section 5, the unbiasedness of PER fails.

### Mechanism 2: Surrogate Loss Optimization
- **Claim:** Standard convex optimization techniques remain effective if the loss function is modified to capture performative dependency terms separately.
- **Mechanism:** Unlike standard binary classification where loss depends on the product y h(x), the performative risk depends on y and h(x) separately. The authors derive a custom surrogate loss (Eq. 6) using logistic functions to upper bound the performative risk. This transforms the non-smooth 0-1 performative risk into a differentiable objective that accounts for the shift parameters α_i.
- **Core assumption:** The coefficients satisfy α_1 ≤ 0 and α_3 ≤ 0 to ensure the surrogate loss remains a convex upper bound.
- **Evidence anchors:**
  - [section 6.1] "We propose the following surrogate for the performative risk... This surrogate loss captures all classifier-dependent terms."
  - [abstract] "Minimizing this notion of performative risk allows us to show that any PAC-learnable hypothesis space... remains PAC-learnable."
- **Break condition:** Using standard cross-entropy or logistic loss without the α-weighted adjustments will converge to a suboptimal classifier that minimizes original risk rather than performative risk.

### Mechanism 3: Robustness to Parameter Uncertainty
- **Claim:** Learnability is preserved even if the exact shift parameters are unknown, provided they lie within known bounded intervals.
- **Mechanism:** The paper extends the PERM framework to an "imperfect information" setting (Theorem 4.2). By minimizing PER using midpoints of parameter intervals, the error bound increases linearly with the size of the uncertainty intervals (ε), rather than invalidating the learnability entirely.
- **Core assumption:** The true shift parameters lie within known intervals I_i of finite total length ε.
- **Evidence anchors:**
  - [section 4.3] "The bound features a term of O(ε), reflecting the uncertainty... PER can only recover an O(ε)-optimal hypothesis."
  - [corpus] Neighbor papers on "Statistical Inference under Performativity" highlight the difficulty of unknown shifts; this paper offers a bounded robustness.
- **Break condition:** If parameter uncertainty intervals are unbounded or the intervals do not contain the true shift parameters, the O(ε) optimality guarantee fails.

## Foundational Learning

- **Concept: Probably Approximately Correct (PAC) Learning**
  - **Why needed here:** The paper's main theoretical contribution is defining and proving "Performative PAC Learnability." Without grasping standard PAC (sample complexity, hypothesis class complexity), the generalization bounds in Theorem 4.1 are unintelligible.
  - **Quick check question:** Can you explain why a finite VC-dimension is necessary for the generalization error to converge to zero as sample size n → ∞?

- **Concept: Rademacher Complexity**
  - **Why needed here:** The paper uses Rademacher complexity to measure the capacity of the function class F_H induced by the performative risk. It is the primary tool for deriving the generalization bounds that prove learnability.
  - **Quick check question:** How does Rademacher complexity differ from VC-dimension as a measure of model complexity, particularly for real-valued function classes?

- **Concept: Radon-Nikodym Derivatives (Density Ratios)**
  - **Why needed here:** Section 5 generalizes the mechanism beyond linear drifts using RN derivatives to reweight the original distribution to the shifted one. This connects the paper to importance weighting techniques in domain adaptation.
  - **Quick check question:** Why is absolute continuity a necessary condition for the existence of a Radon-Nikodym derivative between two measures?

## Architecture Onboarding

- **Component map:** Data Loader -> Shift Simulator (Optional/Test-time) -> PERM Loss Module -> Optimizer

- **Critical path:** Implementing the **PERM Loss Module** is the critical step. You cannot simply swap labels; you must construct the loss term α_1(1-2φ(f(x))) + α_3(1-2φ(yf(x))) + ... precisely. A bug in the signs of α terms (e.g., α_3) will cause the model to maximize performative risk rather than minimize it.

- **Design tradeoffs:**
  - **Knowledge of Shift:** Using the exact shift parameters a_i (Theorem 4.1) vs. interval-averaged parameters (Theorem 4.2). The former offers tighter bounds; the latter is more robust to estimation error.
  - **Surrogate Loss:** Using the proposed logistic surrogate (convex, stable) vs. trying to optimize the 0-1 loss directly (non-convex, potentially more accurate if solved perfectly).

- **Failure signatures:**
  - **Oscillation:** If using RERM (Repeated ERM) adapted for this setting, the model may oscillate between classifiers (Figure 2, Right) rather than converging.
  - **Degradation under Non-linearity:** If the true shift is quadratic in h(x) but you implement a linear PERM, the unbiasedness property vanishes, and accuracy may degrade below standard ERM.

- **First 3 experiments:**
  1.  **Sanity Check (Synthetic):** Replicate the "Placebo Effect" experiment (Section 6.2). Train a linear model with standard ERM vs. PERM on data where P(Y=1|X) shifts by parameter a. Verify PERM accuracy ≈ 1 when a ≈ 1 while ERM lags.
  2.  **Ablation on Shift Strength:** Plot accuracy vs. effect strength a (Figure 1). Confirm the "crossover" point where PERM begins to significantly outperform ERM.
  3.  **Imperfect Information Test:** Introduce noise into the shift parameters a_i used in the loss function. Compare the degradation of the "Perfect Info" PERM vs. the theoretical bound derived in Theorem 4.2.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can theoretical convergence guarantees be established for the adapted Repeated Empirical Risk Minimization (RERM) algorithm under general distribution maps?
  - **Basis in paper:** [explicit] The conclusion states that "analyzing the adapted version of RERM theoretically may enable guarantees for more general distribution maps."
  - **Why unresolved:** The authors demonstrate empirically (Fig 2) that while RERM sometimes converges to the PERM optimum, it can also oscillate indefinitely depending on the performative parameters.
  - **What evidence would resolve it:** A formal proof of convergence conditions for the adapted RERM algorithm or a characterization of the specific distribution maps under which oscillation is unavoidable.

- **Open Question 2:** How can the PERM framework be extended to general parametric classes of distribution shifts, such as the linear adjustment model?
  - **Basis in paper:** [explicit] The conclusion identifies the "development and analysis of performative equivalents of parametric classes of distribution shifts" as an exciting direction for future work.
  - **Why unresolved:** The current theoretical results rely specifically on the linear posterior drift assumption (Eq. 2) to derive the unbiased risk estimator.
  - **What evidence would resolve it:** Derivation of a performative empirical risk estimator that remains unbiased for non-linear or parameterized shift families.

- **Open Question 3:** Is the hypothesis class preservation guarantee (standard PAC implies performative PAC) maintained for multi-class classification or regression tasks?
  - **Basis in paper:** [inferred] The paper explicitly restricts its scope to "performative binary classification problems" (Abstract) and defines the label space as Y = {-1, 1}.
  - **Why unresolved:** The proof of Lemma 4.1 and the derivation of the surrogate loss (Eq. 6) utilize properties specific to binary labels, such as the reduction of higher-order terms involving Y ∈ {-1, 1}.
  - **What evidence would resolve it:** Extending Theorem 4.1 to a multi-class setting or showing a counter-example where standard PAC learnability does not imply performative PAC learnability.

## Limitations

- Theoretical guarantees depend critically on the assumption that performative distribution shifts are linear in the posterior probabilities, which may not hold in many real-world scenarios.
- The generalization bounds rely on Rademacher complexity of the function class F_H, which can grow with dimensionality, potentially limiting practical applicability to high-dimensional models.
- The framework's practical applicability to complex neural networks remains unexplored, as experiments use relatively simple architectures.

## Confidence

- **High Confidence:** The unbiasedness of the PER estimator under linear posterior drift (Lemma 4.1) - this follows directly from the mathematical derivation and the specific structure of the linear model. The experimental results showing PERM outperforming ERM in strong performativity regimes (Figure 1) are also highly replicable given the detailed implementation specifications.
- **Medium Confidence:** The learnability guarantee in Theorem 4.1 - while the proof structure is sound, it relies on several technical conditions (absolute continuity, boundedness of Radon-Nikodym derivatives) that may not hold in practice. The extension to imperfect information (Theorem 4.2) is mathematically correct but the O(ε) degradation bound may be loose for small uncertainty intervals.
- **Low Confidence:** The practical applicability of the framework to complex neural networks - the experiments use relatively simple architectures, and the performance on high-dimensional, non-linear datasets remains unexplored. The assumption that P(Y|X) can be accurately estimated using a random forest on the original data may not scale to high-dimensional feature spaces.

## Next Checks

1. **Non-linear Shift Robustness:** Test PERM on synthetic data where the performative shift follows a quadratic or exponential relationship in h(x) rather than linear. Measure the degradation in performance compared to the theoretical prediction that unbiasedness requires linearity.

2. **Covariate Shift Sensitivity:** Modify the experimental setup to include simultaneous shifts in P(X) along with P(Y|X). Evaluate whether PERM maintains its advantage or if standard domain adaptation techniques (e.g., importance weighting) become necessary.

3. **High-Dimensional Scalability:** Apply PERM to image classification tasks where performative shifts might occur (e.g., medical diagnosis systems where classifier deployment changes patient behavior). Compare performance against ERM and specialized domain adaptation methods as the number of features increases.