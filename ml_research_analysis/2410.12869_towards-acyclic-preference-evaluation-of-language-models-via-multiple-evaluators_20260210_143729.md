---
ver: rpa2
title: Towards Acyclic Preference Evaluation of Language Models via Multiple Evaluators
arxiv_id: '2410.12869'
source_url: https://arxiv.org/abs/2410.12869
tags:
- preference
- pged
- evaluators
- graph
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PGED addresses cyclic preference issues in LLM evaluation by aggregating
  and denoising multiple evaluator preference graphs. It combines graph ensemble and
  denoising to recover acyclic, consistent rankings, with theoretical guarantees for
  recovering the ground truth DAG.
---

# Towards Acyclic Preference Evaluation of Language Models via Multiple Evaluators

## Quick Facts
- **arXiv ID:** 2410.12869
- **Source URL:** https://arxiv.org/abs/2410.12869
- **Reference count:** 40
- **One-line result:** PGED uses multiple smaller evaluators to outperform single strong evaluators in LLM preference evaluation by aggregating and denoising preference graphs.

## Executive Summary
This paper introduces PGED (Preference Graph Ensemble and Denoising), a framework that addresses cyclic preference issues in LLM evaluation by aggregating pairwise preferences from multiple evaluators and denoising the resulting graph to produce consistent rankings. The method combines graph ensemble techniques with a greedy weighted feedback arc set algorithm to remove cycles and recover a directed acyclic graph. Experiments across ten benchmarks demonstrate that PGED using smaller evaluators (Llama3-8B, Mistral-7B, Qwen2-7B) can surpass a single strong evaluator (Qwen2-72B) in accuracy and correlation with ground truth rankings.

## Method Summary
PGED constructs individual preference graphs from multiple LLM evaluators performing pairwise comparisons, then aggregates these into a weighted ensemble graph. The method applies a greedy weighted feedback arc set (WFAS) algorithm to remove cycles and produce a DAG, which is then converted to a ranking. The framework includes theoretical guarantees for recovering ground truth DAGs under a specific noise model where edges are randomly flipped or inserted. The approach is validated through response selection accuracy and ranking correlation metrics across multiple benchmarks including HumanEval, AlpacaEval, MATH, GSM8k, and GAIA.

## Key Results
- PGED using smaller evaluators (Llama3-8B, Mistral-7B, Qwen2-7B) surpasses Qwen2-72B in performance
- Achieves 5.29% average accuracy improvement in response selection over single strong evaluators
- Shows 2.50% improvement in model ranking correlation and 2.12% in instruction tuning performance

## Why This Works (Mechanism)

### Mechanism 1: Multi-Evaluator Aggregation
- **Claim:** Aggregating evaluations from multiple smaller evaluators produces more robust, accurate, and cost-effective preference rankings than relying on a single, stronger evaluator.
- **Mechanism:** Multiple LLM-based evaluators independently perform pairwise comparisons of responses or model outputs. These pairwise preferences are aggregated into a single weighted ensemble preference graph, which is then processed to remove cycles (inconsistencies) and produce a final ranked list.
- **Core assumption:** The individual evaluators' errors are somewhat uncorrelated (noise is random), allowing for it to be "averaged out" during aggregation. A ground-truth preference exists and is transitive.
- **Evidence anchors:** Abstract shows smaller evaluators surpassing Qwen2-72B; section 3.2 defines graph ensemble as summing weights; corpus work on self-preference in LLM evaluators supports need for multi-evaluator systems.
- **Break condition:** If evaluator errors are highly correlated (shared systematic bias) or if running multiple smaller models costs more than a single larger model.

### Mechanism 2: Graph Denoising for Consistency
- **Claim:** Applying a graph denoising algorithm to the aggregated preference graph enforces global consistency by resolving cyclic contradictions, leading to a more reliable final ranking.
- **Mechanism:** The aggregated preference graph may contain cycles (e.g., A>B, B>C, C>A), which represent inconsistencies. The denoising process frames this as a weighted feedback arc set (WFAS) problem, seeking to remove the minimum total weight set of edges to render the graph acyclic (a DAG). A greedy algorithm is used to find an approximate solution.
- **Core assumption:** Most observed cycles in LLM preference data are the result of evaluation noise and not genuine intransitive human preferences. The edges with the lowest weights in the graph are the most likely to be erroneous.
- **Evidence anchors:** Abstract states denoising produces "acyclic, non-contradictory evaluation results"; section 3.3 describes casting this as WFAS problem with greedy algorithm.
- **Break condition:** If human preference is genuinely cyclic or if denoising removes edges crucial to the correct ranking.

### Mechanism 3: Theoretical Guarantees
- **Claim:** The framework provides theoretical guarantees for recovering a ground-truth ranking under a specific noise model, which increases confidence in its output validity.
- **Mechanism:** The method models each individual preference graph as a random perturbation of a ground-truth directed acyclic graph (DAG). Edges can be flipped with probability δ₁, and new edges can be added with probability δ₂. The paper provides a theorem stating that as the number of evaluators (samples) increases, the probability of recovering the ground-truth DAG approaches one.
- **Core assumption:** The noise model (random edge flips and insertions) accurately reflects how real-world LLM evaluators err. The ground-truth preference structure is indeed a DAG.
- **Evidence anchors:** Abstract mentions theoretical guarantees for recovering ground truth preference structure; section 5 shows framework can recover ground truth DAG with high probability.
- **Break condition:** If actual noise doesn't follow assumed i.i.d. random perturbation model or if systematic errors exist.

## Foundational Learning

**Concept: Preference Graphs and Cycles**
- **Why needed here:** This is the core data structure of the PGED method. Understanding that a preference graph represents pairwise comparisons and that cycles (A>B>C>A) are fundamental inconsistencies is essential for grasping the problem PGED solves.
- **Quick check question:** In a graph of three nodes (A, B, C), if edges A→B and B→C exist, what does an edge C→A create?

**Concept: Weighted Feedback Arc Set (WFAS)**
- **Why needed here:** This is the formal computational problem PGED solves during the denoising step. Understanding WFAS is necessary to understand how the system decides which contradictory preferences to discard to achieve a consistent ranking.
- **Quick check question:** Given a cyclic directed graph with weighted edges, what is the objective of the WFAS problem?

**Concept: Aggregation/Ensembling of Weak Signals**
- **Why needed here:** The core empirical result is that multiple weak evaluators can surpass a strong one. This relies on the principle that independent noisy signals can be combined to form a more accurate signal.
- **Quick check question:** Why might the average of three noisy measurements be more reliable than a single noisy measurement?

## Architecture Onboarding

**Component map:** Evaluators -> Graph Constructor -> Graph Ensemble -> Denoising Module -> Ranking Converter

**Critical path:** The denoising step (WFAS) is NP-hard for the optimal solution. PGED uses a greedy approximation which must be efficient enough to run quickly on graphs with many nodes. The performance of the entire system hinges on the quality of this approximation.

**Design tradeoffs:**
- **Number of evaluators:** More evaluators increase robustness and theoretical guarantees but increase inference cost and latency
- **Denoising algorithm:** The paper uses a greedy approach for O(m) time complexity. A more complex algorithm might find a better solution but would be slower
- **Evaluator selection:** Using larger, more capable models as evaluators improves performance but at a higher cost. The "weak-to-strong" result suggests a sweet spot with capable but smaller models

**Failure signatures:**
- **High Inconsistency:** If the resulting graph is very dense with cycles (very high cycle rate), the denoising step has too many conflicting signals and may produce an arbitrary or poor ranking
- **Correlated Errors:** If evaluators share a common bias (e.g., all favoring longer answers), the ensemble graph will amplify this bias, and the denoising step will not remove it, leading to a biased final ranking
- **Cost Overrun:** The total inference cost of running multiple evaluators across all pairs can exceed the budget or the cost of a single strong model evaluation

**First 3 experiments:**
1. **Reproduce the "Weak-to-Strong" result:** Using the PGED framework, compare the ranking accuracy of an ensemble of three 7B-scale models against a single 70B-scale model evaluator on a held-out set of preference data. This validates the core claim.
2. **Ablate the denoising step:** Run the full PGED pipeline but skip the graph denoising, directly converting the ensembled graph to a ranking. Compare the consistency and accuracy of results to quantify the specific contribution of the denoising mechanism.
3. **Stress test with noisy evaluators:** Create a synthetic scenario where evaluators have a very high error rate (flipping probability δ₁). Measure how many evaluators (N) are needed for PGED to recover a known ground-truth ranking, and compare this to the theoretical predictions from Theorem 1.

## Open Questions the Paper Calls Out

**Open Question 1:** How can PGED principles be extended to multi-agent systems and human-AI interaction tasks?
- **Basis in paper:** [explicit] The Conclusion states, "Future work will explore extending PGED to broader evaluation frameworks and applying its principles to more complex decision-making tasks, including multi-agent systems and human-AI interaction."
- **Why unresolved:** The current framework validates static pairwise comparisons of text/code outputs, but dynamic agent interactions introduce temporal dependencies and evolving preferences not modeled by the current DAG recovery.
- **What evidence would resolve it:** Successful application of PGED to agent trajectory evaluation or real-time human feedback loops, demonstrating acyclic consistency in dynamic environments.

**Open Question 2:** Does the enforcement of acyclic preference structures inadvertently suppress legitimate minority viewpoints or cultural nuances?
- **Basis in paper:** [inferred] Appendix C (Limitations) notes that the framework "implicitly promotes a 'majority view'... This may inadvertently suppress minority or dissenting preferences, especially in cases where subjectivity... plays a critical role."
- **Why unresolved:** The theoretical guarantees rely on recovering a single "ground truth" DAG, which assumes transitivity that may not exist in subjective human values, potentially treating meaningful disagreement as noise.
- **What evidence would resolve it:** A comparative analysis in socially sensitive domains showing whether PGED's "denoising" correlates with a loss of diverse but valid perspectives compared to human ground truth.

**Open Question 3:** Can evaluator weights be systematically learned or dynamically optimized rather than statically assigned?
- **Basis in paper:** [explicit] Appendix K suggests that while "WeightGED" shows promise, "Systematically designing and optimizing these weighting schemes could lead to more robust and accurate evaluation frameworks."
- **Why unresolved:** The current implementation uses uniform weights or simple performance-based normalization, lacking a mechanism to adapt evaluator authority based on specific domains or instance difficulty.
- **What evidence would resolve it:** A learned weighting mechanism that dynamically adjusts evaluator influence based on query context, outperforming the static baselines described in the appendix.

**Open Question 4:** How does the performance of the proposed active learning strategy (ActiveGED) scale with significantly larger candidate sets?
- **Basis in paper:** [inferred] Appendix O introduces ActiveGED to reduce cost, but the analysis is limited to specific budget percentages on sets of 10 candidates. The efficiency of the uncertainty estimation (PageRank) for massive output spaces remains unquantified.
- **Why unresolved:** As the number of candidates grows, the quadratic nature of pairwise comparisons and the complexity of maintaining accurate uncertainty estimates for active selection may degrade the cost-performance trade-off.
- **What evidence would resolve it:** Benchmarks of ActiveGED on candidate sets significantly larger than 10 (e.g., 50 or 100), maintaining high accuracy with a sub-quadratic query budget.

## Limitations

- The method assumes evaluation errors follow an i.i.d. random perturbation model, which may not hold if evaluators share systematic biases
- The greedy WFAS algorithm provides only an approximate solution to an NP-hard problem, and its effectiveness depends heavily on the error model being accurate
- While improvements are shown on ten benchmarks, evaluation focuses primarily on response selection accuracy rather than more nuanced aspects of preference quality

## Confidence

- **Multi-evaluator aggregation outperforms single strong evaluator:** High confidence. Empirical results show consistent improvements across multiple benchmarks, and the mechanism (averaging uncorrelated noise) is theoretically sound.
- **Graph denoising resolves cyclic contradictions:** Medium confidence. The approach is well-defined and the WFAS framing is appropriate, but the greedy algorithm's effectiveness depends on error model accuracy, and there's limited ablation testing of the denoising step itself.
- **Theoretical guarantees for ground truth recovery:** Low confidence in practical applicability. The theorem provides asymptotic guarantees under specific noise assumptions, but real-world LLM evaluation noise likely deviates from the assumed i.i.d. model.

## Next Checks

1. **Ablation of denoising mechanism:** Run the full PGED pipeline but skip the graph denoising step, directly converting the ensembled graph to a ranking. Compare the consistency and accuracy of results to quantify the specific contribution of the denoising mechanism and test whether the improvements are primarily from aggregation or denoising.

2. **Correlation analysis of evaluator errors:** Measure the pairwise correlation of preference judgments between evaluators on a held-out dataset. High correlations would indicate shared systematic biases that the ensemble cannot mitigate, potentially invalidating the core assumption of uncorrelated noise.

3. **Stress test with synthetic bias:** Create a controlled experiment where evaluators have a known systematic bias (e.g., all favor longer responses). Measure how PGED's ensemble and denoising perform compared to a single strong evaluator, testing whether the framework can actually mitigate rather than amplify systematic errors.