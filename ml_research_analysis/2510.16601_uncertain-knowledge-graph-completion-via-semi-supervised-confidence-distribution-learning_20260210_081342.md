---
ver: rpa2
title: Uncertain Knowledge Graph Completion via Semi-Supervised Confidence Distribution
  Learning
arxiv_id: '2510.16601'
source_url: https://arxiv.org/abs/2510.16601
tags:
- confidence
- data
- learning
- labeled
- sscdl
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of uncertain knowledge graph (UKG)
  completion, where triples have associated confidence scores, and the confidence
  distributions are extremely imbalanced. Existing methods struggle because they don't
  effectively learn from low-confidence triples, which are crucial for improving model
  performance.
---

# Uncertain Knowledge Graph Completion via Semi-Supervised Confidence Distribution Learning

## Quick Facts
- arXiv ID: 2510.16601
- Source URL: https://arxiv.org/abs/2510.16601
- Reference count: 32
- This paper introduces ssCDL, a method that transforms confidence scores into distributions and uses meta-learning to improve uncertain knowledge graph completion, achieving up to 63.8% MSE reduction in confidence prediction.

## Executive Summary
This paper addresses the challenge of uncertain knowledge graph (UKG) completion, where triples have associated confidence scores and the confidence distributions are highly imbalanced. Existing methods struggle to learn from low-confidence triples, which are crucial for model performance. The authors propose a semi-supervised confidence distribution learning (ssCDL) method that transforms confidence scores into confidence distributions, allowing the model to learn from a broader range of confidences. The method employs meta self-training, using pseudo-labels generated for unlabeled data to further improve learning. Experiments on two real-world UKG datasets demonstrate that ssCDL consistently outperforms state-of-the-art baselines in both confidence prediction and link prediction tasks.

## Method Summary
ssCDL addresses UKG completion by transforming confidence scores into 101-dimensional distributions using Gaussian smoothing, then training a CDL-based relational learner with both labeled data and pseudo-labels generated via meta-learning. The framework consists of two identical neural networks: a CDL-based Relational Learner (CDL-RL) that outputs both confidence distributions and link prediction scores, and a Pseudo Confidence Distribution Generator (PCDG) that generates pseudo-labels for unlabeled triples. The meta-optimizer coordinates a bi-level training process where PCDG is updated based on how well its pseudo-labels improve CDL-RL's performance on real labeled data. After a warm-up period, high-quality pseudo-labels are integrated into CDL-RL's training set, with performance evaluated on confidence prediction (MSE, MAE) and link prediction (Hits@1, WMRR) metrics.

## Key Results
- ssCDL reduces confidence prediction MSE by up to 63.8% and MAE by up to 53.2% compared to state-of-the-art baselines
- On CN15k, ssCDL achieves 0.8730 confidence prediction MAE, outperforming the best baseline by 6.1%
- On NL27k, ssCDL achieves 0.8160 confidence prediction MAE, outperforming the best baseline by 5.6%
- Link prediction performance also improves, with Hits@1 increasing by 4.7% on CN15k

## Why This Works (Mechanism)
The core innovation addresses the fundamental data imbalance problem in UKG completion. Traditional models treat confidence as a single scalar target, making them blind to the rare low-confidence examples that are crucial for robust performance. By transforming confidences into distributions (via Gaussian smoothing over 101 bins), the model can learn from the presence of high-confidence examples to infer information about nearby, under-represented confidences. The meta self-training mechanism further enhances this by using a feedback loop: the PCDG generates pseudo-labels, CDL-RL trains on them, and the resulting model's performance on real data provides gradients to improve PCDG. This creates a quality control mechanism that produces better pseudo-labels than standard self-training, enabling effective learning from the long tail of low-confidence triples.

## Foundational Learning

- **Concept: Label Distribution Learning (LDL)**
  - **Why needed here:** This is the core technique for handling the "imbalanced confidence" problem. Standard models treat confidence as a single scalar target. LDL treats it as a distribution, allowing a single high-confidence example (e.g., 0.9) to provide a weaker training signal to nearby, under-represented confidences (e.g., 0.89, 0.88). This is the key to "solving" the data imbalance without collecting more data.
  - **Quick check question:** Can you explain why using a KL-divergence loss on a distribution (over 101 confidence bins) is different from using a Mean Squared Error loss on a single scalar confidence value?

- **Concept: Meta-Learning for Self-Training**
  - **Why needed here:** Traditional self-training uses a model's own high-confidence predictions as new labels. This can suffer from "gradual drift," where errors reinforce themselves. This paper uses meta-learning: the pseudo-label generator is trained based on whether its generated labels help the main model perform better on a trusted validation set. This creates a feedback loop designed to produce higher-quality pseudo-labels than standard self-training.
  - **Quick check question:** In the ssCDL framework, what data is used to compute the meta-loss that updates the Pseudo Confidence Distribution Generator (PCDG)? (Hint: It's not the unlabeled data).

- **Concept: Uncertain Knowledge Graphs (UKG)**
  - **Why needed here:** Unlike standard KGs where a triple is either True or False, UKGs attach a continuous `confidence` score (0-1). The problem isn't just structural existence (is the link there?) but semantic veracity (how likely is the link to be true?). The architecture must output a continuous value, not a binary classification.
  - **Quick check question:** How does the goal of "confidence prediction" differ from "link prediction," and what does the paper's results suggest about ssCDL's comparative strength in each?

## Architecture Onboarding

- **Component map:** CDL-RL -> PCDG (meta-updated) -> CDL-RL (with pseudo-labels)

- **Critical path:**
  1. Gaussian Transformation: All initial confidence scores `s` in the labeled set are converted to 101-dimensional distributions using `N(s, σ)`.
  2. Warm-up: CDL-RL is trained alone on labeled data until embeddings stabilize (epoch `T_PCDG`).
  3. Meta-Training Loop: PCDG generates pseudo-labels. CDL-RL trains on them. The performance of the updated CDL-RL on real labeled data provides the gradient to improve PCDG.
  4. Pseudo-Label Integration: After epoch `T_CDLRL`, high-quality pseudo-labels (where the maximum description degree > threshold) are added to CDL-RL's training set.

- **Design tradeoffs:**
  - **Granularity vs. Fuzziness:** The number of confidence labels (`n=100`) determines resolution. The Gaussian `σ` determines fuzziness. A high `σ` helps with imbalance but blurs distinct confidences. A low `σ` preserves distinctions but doesn't help with missing confidences.
  - **Quality vs. Quantity in Pseudo-Labeling:** The threshold for pseudo-label selection is critical. The paper finds 0.03 (NL27k) and 0.015 (CN15k). A higher threshold ensures quality but may discard too many rare, low-confidence training examples.
  - **Joint Task Weighting:** The balance between confidence prediction loss and link prediction loss is managed by learned uncertainty parameters (`λ_CP`, `λ_LP`), but is also fundamentally limited by the fact that most pseudo-labels are only used for the confidence task.

- **Failure signatures:**
  - **Imbalance Persists:** If validation loss on low-confidence examples doesn't improve, the Gaussian `σ` may be too small, or the pseudo-label threshold too high.
  - **Model Collapse:** If overall performance degrades after `T_CDLRL`, the PCDG is likely generating poor labels. This could be due to insufficient warm-up or a flawed meta-objective.
  - **Dominating Loss:** If link prediction metrics are good but confidence prediction is poor, the weighting `ϕ` or learned uncertainties (`λ`) may be overly favoring the ranking loss.

- **First 3 experiments:**
  1. **Reproduce Ablation:** Run `w/o cdl` (without confidence distribution learning). This confirms the single most important mechanism. Expect a significant drop in confidence prediction metrics (MAE/MSE).
  2. **Sensitivity Scan on `σ`:** Run a parameter sweep on the Gaussian standard deviation (e.g., 0.2, 0.6, 1.0). Plot the MAE for low-confidence triples. This validates the core hypothesis about modeling "fuzzy" confidences.
  3. **Analyze Pseudo-Label Quality:** After training, inspect the distribution of generated pseudo-labels. Are they actually populating the low-confidence regions (<0.5)? If they cluster near 0.9, the generator isn't solving the imbalance problem.

## Open Questions the Paper Calls Out
- **Open Question 1:** How can the proposed Confidence Distribution Learning (CDL) framework be effectively integrated with Large Language Models (LLMs) to enhance UKG completion? The authors state in the Conclusion, "We will also explore to apply large language model to UKG completion, and use UKGs for reliable retrieval-augmented generation." The current architecture relies on specific structural learners (CDL-RL) and meta-learning; it is unclear how the continuous confidence distributions would interact with the discrete token spaces or probabilistic outputs of LLMs.

- **Open Question 2:** How does the ssCDL method perform on datasets where low-confidence triples are semantically distinct or noisy, rather than just statistically infrequent? The authors note in Appendix D (Limitation) that in CN15k, "most triples... are generally correct," meaning "there is no significant distinction in reliability between high-confidence and low-confidence triples." The current validation is limited to datasets where low confidence does not necessarily imply high noise, leaving the model's robustness to truly erroneous low-confidence data unverified.

- **Open Question 3:** Is the Gaussian assumption for transforming confidence scores into distributions optimal for all UKG domains? The method transforms scores using a Gaussian distribution (Sec 3.2), based on the assumption that confidence is "fuzzy" similar to facial age. However, in some domains, confidence might be discrete or skewed, making the symmetric Gaussian smoothing potentially suboptimal.

## Limitations
- The effectiveness of the method relies heavily on the Gaussian assumption for transforming confidence scores, which may not be optimal for all domains
- The pseudo-label generation threshold and weight parameters require careful tuning and may not generalize well across different datasets
- The method's performance on datasets where low-confidence triples are truly noisy (not just infrequent) remains unverified

## Confidence
- **High Confidence:** The core contribution of transforming confidence scores into distributions and using meta-learning for pseudo-label generation is well-articulated and addresses a clear gap in UKG completion. The reported improvements in confidence prediction metrics (MSE, MAE) are substantial and directly tied to this innovation.
- **Medium Confidence:** The link prediction improvements (Hits@1, WMRR) are reported, but the magnitude of gain (e.g., 4.7% Hits@1 on CN15k) is more modest than the confidence prediction gains. This suggests the method's primary strength is in the novel confidence learning task.
- **Medium Confidence:** The choice of hyperparameters (σ=0.6, n=100, specific thresholds) is shown to work, but the sensitivity analysis is limited. The paper claims robustness, but a broader parameter sweep would strengthen this claim.

## Next Checks
1. **Parameter Sensitivity Analysis:** Conduct a thorough sweep of the Gaussian standard deviation (σ) and the number of confidence bins (n). Plot confidence prediction performance against these parameters to identify the optimal configuration and test the robustness of the reported results.

2. **Pseudo-Label Distribution Analysis:** After training, visualize the distribution of confidence scores generated by the PCDG for unlabeled data. Quantify the proportion of pseudo-labels assigned to the underrepresented, low-confidence regions (<0.5) to directly verify if the method is solving the stated imbalance problem.

3. **Architecture Ablation:** Implement a simplified version of the CDL-RL with a different number of hidden layers (e.g., one layer instead of two) or different activation functions (e.g., ReLU vs. Tanh). This will help isolate the impact of the confidence distribution learning framework from the specific neural network architecture.