---
ver: rpa2
title: There Was Never a Bottleneck in Concept Bottleneck Models
arxiv_id: '2506.04877'
source_url: https://arxiv.org/abs/2506.04877
tags:
- information
- concept
- cbms
- concepts
- bottleneck
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper identifies a critical limitation in Concept Bottleneck
  Models (CBMs): while CBMs ensure each representation component can predict its associated
  concept, they fail to constrain it from encoding additional nuisance information.
  This information leakage undermines both interpretability and the validity of interventions.'
---

# There Was Never a Bottleneck in Concept Bottleneck Models

## Quick Facts
- arXiv ID: 2506.04877
- Source URL: https://arxiv.org/abs/2506.04877
- Authors: Antonio Almudévar; José Miguel Hernández-Lobato; Alfonso Ortega
- Reference count: 40
- Primary result: MCBMs enforce that each representation component contains only information relevant to its concept, enabling valid interventions and superior interpretability.

## Executive Summary
Concept Bottleneck Models (CBMs) have been assumed to learn bottleneck representations where each component z_j contains only information about its associated concept c_j. This paper reveals this assumption is false: CBMs fail to constrain z_j from encoding additional nuisance information, undermining interpretability and intervention validity. The authors propose Minimal Concept Bottleneck Models (MCBMs) that incorporate an Information Bottleneck objective via a variational regularization term, forcing each representation component to retain only information relevant to its corresponding concept. Experiments demonstrate MCBMs effectively remove nuisance information while preserving concept-relevant content, achieving superior disentanglement and concept alignment metrics, and enabling more reliable interventions compared to existing CBM variants.

## Method Summary
MCBMs extend CBMs by adding an Information Bottleneck objective that constrains each representation component z_j to retain only information relevant to its corresponding concept c_j. This is implemented via a variational regularization term that penalizes the mutual information between z_j and the input x given c_j. The model introduces a representation head that predicts z_j from c_j, and the KL divergence between this prediction and the encoder's distribution on z_j serves as the regularization term. Under Gaussian assumptions, this reduces to mean squared error between the encoder output and the representation head prediction. The total loss combines task prediction, concept prediction, and this IB regularization with hyperparameter γ controlling the tradeoff between task performance and interpretability.

## Key Results
- MCBMs achieve lower Uncertainty Reduction Ratio (URR) than CBMs on MPI3D, Shapes3D, and CIFAR-10, indicating reduced nuisance information leakage
- On CIFAR-10, MCBMs reduce error by 6.9% and 14.5% compared to baselines when intervening on least-confident concepts
- CKA and Oracle Information Score (OIS) serve as reliable proxies for nuisance information leakage, correlating with URR metrics

## Why This Works (Mechanism)

### Mechanism 1
The variational Information Bottleneck (IB) objective forces each representation component z_j to retain only information relevant to its associated concept c_j, excluding nuisance information. MCBMs minimize the conditional mutual information I(Z_j; X|C_j) by adding a KL divergence regularization term between the encoder distribution p_θ(z_j|x) and a representation head q_ϕ(ẑ_j|c_j). Under Gaussian assumptions, this KL reduces to mean squared error between f_θ(x)_j and g^z_ϕ(c_j). When optimized, this enforces the Markov chain X ↔ C_j ↔ Z_j, meaning z_j becomes conditionally independent of x given c_j.

### Mechanism 2
By making z_j a minimal sufficient statistic of c_j, MCBMs restore the validity of concept-level interventions that CBMs only approximate heuristically. In CBMs, p(z_j|c_j) is undefined because z_j may encode information beyond c_j. MCBMs explicitly introduce a directed path c_j → ẑ_j → z_j via the representation head, making p(z_j|c_j) = q_ϕ(z_j|c_j) computable in closed form. Interventions then modify z_j knowing that only c_j is affected.

### Mechanism 3
The bottleneck hyperparameter γ provides a controllable tradeoff between task performance and interpretability/intervenability. The total loss combines task prediction (VM objective), concept prediction (CBM objective), and IB regularization with weight γ. Higher γ enforces stricter minimization of I(Z_j; X|C_j), reducing nuisance leakage but potentially sacrificing predictive information when c alone is insufficient for y.

## Foundational Learning

- **Mutual Information I(X;Y) and Conditional Mutual Information I(X;Y|Z)**: The entire MCBM framework is built on minimizing I(Z_j; X|C_j) to enforce a true bottleneck. Without understanding that I(Z_j; X|C_j) = 0 ⇔ Markov chain X ↔ C_j ↔ Z_j, the mechanism remains opaque.
  - Quick check: If I(Z_j; X|C_j) = 0, what does this imply about whether z_j contains information beyond c_j?

- **Variational Inference and KL Divergence**: The IB objective is intractable directly; the paper derives a variational upper bound using KL divergence. Understanding why D_KL(p_θ(z_j|x) || q_ϕ(ẑ_j|c_j)) approximates I(Z_j; X|C_j) is essential.
  - Quick check: Why does minimizing the expected KL divergence between encoder and representation head provide a tractable proxy for the mutual information objective?

- **Sufficient vs. Minimal Sufficient Statistics**: The paper frames CBMs as learning sufficient statistics (z_j predicts c_j) and MCBMs as learning minimal sufficient statistics (z_j predicts c_j AND contains nothing else). This distinction motivates the architecture change.
  - Quick check: A representation z_j that perfectly predicts c_j but also encodes some nuisance n—is it a sufficient statistic of c_j? Is it minimal?

## Architecture Onboarding

- **Component map**: Input x → Encoder f_θ → z → (Task head → ŷ) AND (Concept heads → ĉ_j) AND (inverse: Representation heads reconstruct z_j from c_j for IB loss)
- **Critical path**: Input x → Encoder f_θ → z → (Task head → ŷ) AND (Concept heads → ĉ_j) AND (inverse: Representation heads reconstruct z_j from c_j for IB loss). The IB loss flows backward through the encoder, penalizing z_j for containing information not predictable from c_j.
- **Design tradeoffs**:
  - Higher γ: Stronger bottleneck, better interpretability and intervention validity, lower task accuracy if concepts incomplete
  - Stochastic vs. deterministic encoder: Stochastic (σ_x > 0) required for tractable KL; adds noise but enables gradient flow
  - Representation head architecture: Small MLP (3 hidden units in experiments) adds negligible parameters; fixed prototype vectors for binary/categorical concepts avoid learning
- **Failure signatures**:
  - Concept accuracy drops significantly: γ may be too high, over-regularizing. Check CKA/OIS to confirm leakage reduction
  - Task accuracy collapses but concept accuracy unchanged: Concepts may be insufficient for the task; the bottleneck correctly removes necessary nuisance information
  - Interventions still unreliable: Verify σ_x, σ_ẑ are set correctly (1.0 for MCBMs); check that representation head is being optimized
- **First 3 experiments**:
  1. On MPI3D or Shapes3D, train MCBM with varying γ (low/medium/high). Verify that URR for known nuisance factors (n_y, n̄_y) decreases monotonically with γ while concept accuracy remains stable up to a point
  2. On CIFAR-10/CUB, intervene on the k least-confident concepts. Plot error vs. % concepts intervened. MCBMs should show steeper error reduction than CBMs, especially at medium/high γ
  3. Compute CKA and OIS on validation data across γ values. Correlate with proxy-based URR estimates (if some nuisance labels available) to confirm these metrics predict leakage reliably before committing to full deployment

## Open Questions the Paper Calls Out

- **Open Question 1**: Can an auxiliary latent variable zm+1 capture task-relevant nuisance factors while keeping z1,...,zm strictly interpretable? MCBMs currently sacrifice task accuracy when concepts are incomplete, because removing ny from z reduces predictive performance. The trade-off between interpretability and task performance remains open.
- **Open Question 2**: How does the choice of prior distribution qϕ(zj|cj) affect representation quality and evaluation metrics? The current MCBM formulation uses fixed Gaussian priors with predetermined means (λ or −λ) for binary/categorical concepts. The impact of alternative prior choices on model behavior is unexplored.
- **Open Question 3**: What architectural properties of the backbone encoder determine MCBM's ability to achieve complete nuisance removal? MCBMs show varying effectiveness across datasets, with CIFAR-10 showing higher residual URR values than MPI3D/Shapes3D even at high γ. The relationship between encoder capacity, dataset complexity, and bottleneck effectiveness remains unclear.

## Limitations
- MCBMs sacrifice task accuracy when concepts are incomplete, as removing task-relevant nuisance information necessarily reduces predictive performance
- The assumption that ground-truth concepts are available limits real-world applicability
- Reliance on proxy metrics (CKA, OIS) when nuisance labels are unavailable may not always accurately reflect true interpretability

## Confidence
- Theoretical framework: **High** - The probabilistic argument for information leakage in CBMs and the IB solution are sound
- Empirical validation: **Medium** - Results show consistent improvements across datasets, but the magnitude varies with dataset complexity
- Practical applicability: **Medium** - Requires ground-truth concepts and careful hyperparameter tuning

## Next Checks
1. Test MCBM on a real-world dataset without ground-truth concepts (e.g., medical imaging) using only proxy metrics to tune γ, and evaluate whether interpretability gains translate to human-in-the-loop settings
2. Compare MCBM's intervention reliability against non-probabilistic CBM variants (e.g., "Improved Concept Bottleneck Models") to isolate whether the IB objective or architectural changes drive the gains
3. Analyze the effect of using non-Gaussian priors (e.g., Laplace, mixture models) for the representation head on both bottleneck strength and task accuracy