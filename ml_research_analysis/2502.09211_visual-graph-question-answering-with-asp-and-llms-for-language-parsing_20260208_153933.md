---
ver: rpa2
title: Visual Graph Question Answering with ASP and LLMs for Language Parsing
arxiv_id: '2502.09211'
source_url: https://arxiv.org/abs/2502.09211
tags:
- question
- language
- graph
- station
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a new Visual Graph Question Answering (VGQA)
  task and dataset where questions must be answered based on images of transit-network-style
  graphs. The authors develop a modular neuro-symbolic system (NSGRAPH) that combines
  optical graph recognition, OCR, and Answer Set Programming (ASP) for reasoning.
---

# Visual Graph Question Answering with ASP and LLMs for Language Parsing

## Quick Facts
- arXiv ID: 2502.09211
- Source URL: https://arxiv.org/abs/2502.09211
- Reference count: 40
- Key outcome: 73% overall accuracy on VGQA dataset, 85% accuracy with GPT-4 on related dataset

## Executive Summary
This paper introduces a new Visual Graph Question Answering (VGQA) task and dataset where questions must be answered based on images of transit-network-style graphs. The authors develop a modular neuro-symbolic system (NSGRAPH) that combines optical graph recognition, OCR, and Answer Set Programming (ASP) for reasoning. The system achieves 73% overall accuracy on the VGQA dataset, with higher accuracy on smaller graphs. The paper also explores using Large Language Models for question parsing, with GPT-4 achieving 85% accuracy on a related dataset. This work demonstrates the potential of combining pretrained vision and language models with logic programming for complex VQA tasks, while providing a new benchmark dataset for future research.

## Method Summary
NSGRAPH is a modular neuro-symbolic pipeline that processes visual graph questions through four stages: (1) Optical Graph Recognition (OGR) extracts node coordinates and adjacency matrices from graph images, (2) EasyOCR performs label extraction with nearest-node association, (3) a RegEx parser or LLM translates natural language questions into formal ASP predicates, and (4) ASP reasoning with Clingo solver computes answers. The system operates in a zero-shot manner without task-specific training, leveraging pretrained models for each component. Questions are encoded as functional programs and processed through graph-ASP (GASP) and question-ASP (QASP) modules before reasoning.

## Key Results
- NSGRAPH achieves 73% overall accuracy on the VGQA dataset
- Performance varies by graph size: 80.9% (small), 71.0% (medium), 67.2% (large)
- GPT-4 achieves 85% parsing accuracy on CLEGR+ dataset with in-context learning
- GPT-4 produces 94% correct responses on CLEGR-Human paraphrased questions
- OCR+GT (ground truth) accuracy reaches 86.4%, indicating OGR is primary bottleneck

## Why This Works (Mechanism)

### Mechanism 1: Zero-Shot Modular Decomposition
- Claim: Decomposing VQA into specialized pretrained modules enables solving graph-based visual reasoning without task-specific training.
- Mechanism: The NSGRAPH pipeline separates visual parsing (OGR+OCR), language parsing (RegEx or LLM), and symbolic reasoning (ASP), allowing each component to operate independently while passing structured symbolic representations between modules.
- Core assumption: Pretrained models can generalize to transit-network-style graph images without fine-tuning.
- Evidence anchors:
  - [abstract]: "Our modular neuro-symbolic approach combines optical graph recognition for graph parsing, a pretrained optical character recognition neural network for parsing labels, Large Language Models (LLMs) for language processing, and ASP for reasoning."
  - [section]: "That our system does not require any training related to a particular set of examples—hence solving the dataset in a zero-shot manner—is a practical feature."
  - [corpus]: Limited direct corpus support for zero-shot modular VQA; neighbor papers like "mKG-RAG" and "MGA-VQA" focus on retrieval-augmented or trained approaches.
- Break condition: Accuracy degrades as graph complexity increases (80.9% → 67.2% from small to large graphs), indicating visual module limits.

### Mechanism 2: ASP for Explainable Reasoning Over Uncertain Neural Outputs
- Claim: Answer Set Programming provides deterministic, interpretable reasoning that can handle uncertainty from upstream neural modules.
- Mechanism: Neural modules produce noisy symbolic facts (nodes, edges, labels); ASP encodes question semantics with choice rules and constraints, allowing the solver to explore multiple plausible interpretations and optimize for best solutions (e.g., shortest path via weak constraints).
- Core assumption: Visual modules extract sufficiently accurate symbolic representations for ASP to complete successfully.
- Evidence anchors:
  - [abstract]: "Answer-Set Programming (ASP) has shown great potential in this regard to add interpretability and explainability to modular VQA architectures."
  - [section]: "Another strength is that uncertainties from the underlying modules can be expressed using disjunctions (or choice rules), and we are not limited to inferring one answer, but several plausible ones in a nondeterministic manner."
  - [corpus]: "Abduction of Domain Relationships from Data for VQA" similarly uses ASP programs for VQA symbolic grounding.
- Break condition: If OGR or OCR error rates exceed threshold (Assumption: >15-20% error on critical nodes/labels), ASP reasoning cascades into incorrect answers.

### Mechanism 3: In-Context Learning Bridges Natural Language to Formal Predicates
- Claim: Large Language Models with few-shot prompting can reliably translate natural language questions into formal ASP predicate encodings.
- Mechanism: A prompt containing 36 examples (3 per question type) instructs the LLM to output structured ASP facts; the LLM leverages pre-trained semantic understanding to generalize to paraphrased questions without weight updates.
- Core assumption: The prompt format and examples align with the LLM's training distribution.
- Evidence anchors:
  - [abstract]: "The paper also explores using Large Language Models for question parsing, with GPT-4 achieving 85% accuracy on a related dataset."
  - [section]: "GPT-4 performed best among the considered LLMs as it produced 85% completely correct responses on CLEGR+ and even 94% on CLEGR-Human."
  - [corpus]: "Bridging Natural Language and ASP: A Hybrid Approach Using LLMs and AMR Parsing" supports LLM-to-ASP translation feasibility.
- Break condition: Smaller models (GPT4All: 23% contains solution, Vicuna: 34% no answer) fail to follow prompt format or suffer context overflow.

## Foundational Learning

- Concept: Answer Set Programming (ASP)
  - Why needed here: Core reasoning engine encoding question semantics (shortest path, adjacency, cycles) as logic rules with constraints.
  - Quick check question: How does a choice rule `{ in_path(T,S1,S2) } :- edge(S1,S2).` differ from a definite rule in ASP?

- Concept: Optical Graph Recognition (OGR)
  - Why needed here: Extracts topological structure (nodes, edges, adjacency) from pixel-space images before symbolic reasoning.
  - Quick check question: In a metro-map image, how would you algorithmically distinguish a line intersection from a transfer station node?

- Concept: In-Context Learning / Few-Shot Prompting
  - Why needed here: Enables LLMs to parse varied natural language phrasings into consistent ASP predicates without fine-tuning.
  - Quick check question: What happens to parsing accuracy if you exceed the LLM's context window with too many examples?

## Architecture Onboarding

- Component map:
  - **Vision Module**: OGR script (Auer et al. method) → node coordinates + adjacency matrix → EasyOCR → label strings + coordinates → nearest-node association → `edge/2`, `station/1` facts
  - **Language Module**: Natural language question → RegEx parser (35 templates) OR LLM prompt (36 examples) → functional program facts (e.g., `shortestPath(1). station(0,S1). station(0,S2).`)
  - **Reasoning Module**: Graph facts + question facts + ASP encoding → Clingo solver → answer sets → extracted answer

- Critical path: OGR accuracy (primary bottleneck) → OCR accuracy → language parsing correctness → ASP solver output
  - Paper identifies OGR as main error source: OCR+GT achieves 86.4% vs. 73% full pipeline

- Design tradeoffs:
  - RegEx vs. LLM: RegEx deterministic but brittle (35 templates only); LLM robust to paraphrasing but may hallucinate predicates
  - Model scale: GPT-4 (85% full match, paid API) vs. Zephyr-7b (0% full match, 61% contains solution, free/local)
  - Graph size: Small (80.9%) vs. large (67.2%)—denser graphs increase OGR/OCR collision errors

- Failure signatures:
  - OGR: Misses nodes in dense regions, produces spurious edges at line crossings
  - OCR: Confuses similar station names, fails on overlapping labels
  - LLM: GPT-3.5 invents non-existent predicates (50% task missed); smaller models output empty responses
  - ASP: Weak constraint optimization (shortest path) may timeout on large graphs with many cycles

- First 3 experiments:
  1. **Ground truth ablation**: Replace OGR output with symbolic ground truth (expected: ~86% accuracy per Table 2) to quantify OGR error contribution.
  2. **LLM generalization test**: Run GPT-4, GPT-3.5, and Zephyr on CLEGR-Human paraphrased questions to measure out-of-distribution robustness.
  3. **Graph complexity scaling**: Test NSGRAPH on synthetically generated graphs with 30-50 nodes to identify where OGR/ASP pipeline breaks down.

## Open Questions the Paper Calls Out

- **Open Question 1**: How can the visual module be improved to handle complicated graph images where current optical graph recognition (OGR) fails?
  - Basis in paper: [explicit] The conclusion states the authors plan to "look into better alternatives for the visual module that is more suitable for complicated images of graphs, which is currently the limiting factor."
  - Why unresolved: The current OGR component was identified as the main source of errors, causing a drop in accuracy from 100% (symbolic input) to 73% (visual input).
  - Evidence would resolve it: An updated system utilizing a more robust OGR method that achieves significantly higher accuracy on the "Large" graph subset of the CLEGRV dataset.

- **Open Question 2**: Can the proposed neuro-symbolic architecture effectively generalize to real-world transit maps?
  - Basis in paper: [explicit] The paper lists working with "real-world metro networks for which currently no VQA datasets exist" as a specific direction for future work.
  - Why unresolved: The current study relies exclusively on the synthetic CLEGRV dataset, and it is unclear if the pipeline handles the noise and complexity of real-world maps.
  - Evidence would resolve it: Evaluation of the NSGRAPH system on a newly curated dataset of actual metro network images demonstrating comparable reasoning accuracy.

- **Open Question 3**: Can smaller, open-source models be optimized to match GPT-4's semantic parsing capabilities for this task?
  - Basis in paper: [inferred] The evaluation shows that while GPT-4 achieved 85% parsing accuracy, smaller models like Vicuna and GPT4All failed to provide reliable formal representations (task missed/no answer).
  - Why unresolved: The authors aimed to find a trade-off between scale and cost (R2), but the results show a significant gap in reliability between large API models and local ones.
  - Evidence would resolve it: Fine-tuning an open-source LLM (e.g., Zephyr 7b) to achieve a "full match" rate statistically indistinguishable from GPT-4 on the CLEGR-Human dataset.

## Limitations

- The visual parsing pipeline struggles with graph complexity, showing a 27-point accuracy drop from small to large graphs
- Current OGR component is identified as the primary bottleneck limiting overall system performance
- System has only been evaluated on synthetic transit-network-style graphs, not real-world metro maps
- Smaller LLM models fail to provide reliable semantic parsing compared to GPT-4

## Confidence

- **High** confidence in ASP reasoning module correctness given valid symbolic inputs
- **Medium** confidence in modular decomposition strategy as viable zero-shot approach
- **Low** confidence in visual parsing pipeline generalizability beyond transit-network-style graphs
- **Low** confidence in language parsing robustness to diverse graph visualizations and question phrasings

## Next Checks

1. **Error Analysis**: Compare NSGRAPH outputs to ground truth on CLEGR-V to quantify and categorize OGR, OCR, and language parsing failures separately.

2. **Cross-Dataset Generalization**: Evaluate NSGRAPH on CLEGR-Human and CLEGR+ to test robustness to paraphrased questions and different graph styles.

3. **Scaling Limits**: Generate synthetic graphs with increasing node/edge density (e.g., 30-50 nodes) to empirically determine where OGR accuracy and ASP solver performance degrade significantly.