---
ver: rpa2
title: Speculative Sampling for Parametric Temporal Point Processes
arxiv_id: '2510.20031'
source_url: https://arxiv.org/abs/2510.20031
tags:
- sampling
- distribution
- rejection
- constant
- events
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces speculative sampling for temporal point processes
  (TPPs) to address the inefficiency of sequential sampling in autoregressive models.
  The method leverages rejection sampling to generate multiple future events in parallel
  without modifying or retraining existing models.
---

# Speculative Sampling for Parametric Temporal Point Processes

## Quick Facts
- arXiv ID: 2510.20031
- Source URL: https://arxiv.org/abs/2510.20031
- Authors: Marin BiloÅ¡; Anderson Schneider; Yuriy Nevmyvaka
- Reference count: 40
- Key outcome: Up to 8x faster sampling from temporal point processes while maintaining sample quality

## Executive Summary
This paper introduces speculative sampling for temporal point processes (TPPs) to address the inefficiency of sequential sampling in autoregressive models. The method leverages rejection sampling to generate multiple future events in parallel without modifying or retraining existing models. By using the model's predicted distribution as a proposal and accepting proposed samples until the first divergence from the target distribution, the approach achieves significant runtime improvements while maintaining sample quality. The authors provide theoretical guarantees and efficient algorithms for computing rejection constants for common distributions.

## Method Summary
The speculative sampling method operates by generating multiple candidate events in parallel using the model's predicted distribution as a proposal. For each speculative step, the algorithm proposes multiple future events and uses rejection sampling to accept or reject them based on whether they match the target distribution. The process continues until the first rejection occurs, at which point the algorithm outputs the accepted events and restarts the speculative sampling process. The key innovation is that this can be implemented as a plug-in modification to existing autoregressive TPP models without requiring retraining, making it highly practical for real-world applications.

## Key Results
- Up to 8x speedup in sampling runtime across benchmark datasets
- Average acceptance rates of 2-9 events per speculative step
- Maintains sample quality while significantly improving computational efficiency
- Particularly effective for non-stationary real-world data and financial applications

## Why This Works (Mechanism)
The method works by exploiting the fact that autoregressive TPP models can predict the distribution of future events given past events. Instead of generating events sequentially, speculative sampling generates multiple candidate events in parallel using the predicted distribution as a proposal. The rejection sampling mechanism ensures that only events consistent with the true target distribution are accepted, while the parallel generation allows multiple events to be processed in a single speculative step. This approach maintains the correctness of the sampling process while dramatically reducing the number of sequential operations required.

## Foundational Learning

**Temporal Point Processes** - Stochastic processes that model the occurrence of discrete events over continuous time. *Why needed:* TPPs are the fundamental mathematical framework for modeling event sequences. *Quick check:* Can represent both stationary and non-stationary event patterns.

**Autoregressive Models for TPPs** - Models that predict the distribution of the next event given the history of previous events. *Why needed:* These models provide the predictive distribution used as the proposal in speculative sampling. *Quick check:* Must maintain conditional independence properties for the sampling algorithm to work.

**Rejection Sampling** - A Monte Carlo method for generating samples from a target distribution using a proposal distribution. *Why needed:* Provides the theoretical foundation for accepting/rejecting speculative samples. *Quick check:* Requires computing the rejection constant as the maximum ratio between target and proposal densities.

**Closed-form Probability Densities** - Mathematical expressions for the probability density functions of the TPP distributions. *Why needed:* Required to compute acceptance probabilities in rejection sampling. *Quick check:* Must be available for the specific TPP model being used.

## Architecture Onboarding

**Component Map:** Input sequence -> Autoregressive TPP model -> Predictive distribution -> Speculative sampling engine -> Rejection sampling filter -> Output sequence

**Critical Path:** The most time-consuming operation is generating the predictive distribution from the autoregressive model, which must be done for each speculative step. The rejection sampling step adds computational overhead but is typically much faster than sequential sampling.

**Design Tradeoffs:** The method trades increased parallel computation for reduced sequential computation. Higher parallelism (generating more candidate events) increases the likelihood of rejection but reduces the number of speculative steps needed.

**Failure Signatures:** Poor performance occurs when the proposal distribution poorly matches the target distribution, leading to high rejection rates. This is most likely with complex, multimodal distributions or when the autoregressive model is poorly trained.

**First Experiments:** 1) Test on simple stationary TPP models with known distributions to verify correctness. 2) Measure acceptance rates and speedup on benchmark datasets. 3) Compare sample quality metrics (e.g., log-likelihood, Wasserstein distance) between speculative and sequential sampling.

## Open Questions the Paper Calls Out
None

## Limitations
- Performance depends critically on quality of proposal distribution matching target
- May experience high rejection rates with complex or multimodal event distributions
- Requires closed-form probability density functions, limiting applicability to some model architectures

## Confidence

**High confidence:** The core theoretical framework for speculative sampling with rejection sampling is sound and well-established. The runtime improvement measurements appear robust across the tested datasets.

**Medium confidence:** The claim of "up to 8x faster" sampling represents the best-case scenario and may not generalize to all TPP models or data distributions. The practical impact on downstream tasks (beyond sampling speed) is not extensively evaluated.

## Next Checks

1. Test the method on TPP models with more complex, multimodal event distributions to quantify how rejection rates scale with distribution complexity.

2. Evaluate the impact of speculative sampling on downstream task performance (e.g., anomaly detection, forecasting accuracy) rather than just sampling speed.

3. Assess computational overhead when extending the approach to multi-dimensional event spaces or continuous-time prediction windows.