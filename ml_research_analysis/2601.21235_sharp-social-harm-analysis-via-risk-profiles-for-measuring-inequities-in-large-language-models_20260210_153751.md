---
ver: rpa2
title: 'SHARP: Social Harm Analysis via Risk Profiles for Measuring Inequities in
  Large Language Models'
arxiv_id: '2601.21235'
source_url: https://arxiv.org/abs/2601.21235
tags:
- harm
- risk
- sharp
- tail
- across
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SHARP addresses the problem that prevailing LLM evaluation benchmarks
  reduce complex social harm to scalar averages, obscuring distributional structure,
  cross-dimensional interactions, and worst-case behavior that dominate risk in high-stakes
  deployment. It introduces a multidimensional, distribution-aware evaluation framework
  that decomposes harm into bias, fairness, ethics, and epistemic reliability; models
  compounded harm via additive cumulative log-risk; and characterizes model behavior
  using tail-sensitive statistics such as Conditional Value at Risk (CVaR95).
---

# SHARP: Social Harm Analysis via Risk Profiles for Measuring Inequities in Large Language Models

## Quick Facts
- arXiv ID: 2601.21235
- Source URL: https://arxiv.org/abs/2601.21235
- Reference count: 40
- Models with similar average risk can exhibit more than twofold differences in tail exposure and volatility, with epistemic and bias risks driving tail severity more consistently than fairness or ethics.

## Executive Summary
SHARP addresses a critical limitation in LLM evaluation: prevailing benchmarks reduce complex social harm to scalar averages, obscuring distributional structure, cross-dimensional interactions, and worst-case behavior that dominate risk in high-stakes deployment. The framework introduces a multidimensional, distribution-aware evaluation approach that decomposes harm into bias, fairness, ethics, and epistemic reliability; models compounded harm via additive cumulative log-risk; and characterizes model behavior using tail-sensitive statistics such as Conditional Value at Risk (CVaR95). Application to eleven frontier LLMs on 901 socially sensitive prompts reveals significant variations in tail exposure that scalar benchmarks would miss, demonstrating that effective LLM governance requires moving beyond scalar benchmarks toward multidimensional, tail-sensitive risk profiling.

## Method Summary
SHARP introduces a multidimensional evaluation framework that decomposes social harm into four core dimensions: bias, fairness, ethics, and epistemic reliability. The framework employs additive cumulative log-risk modeling to capture compounded harm across these dimensions, using Conditional Value at Risk (CVaR95) as the primary tail-sensitivity metric. The evaluation is applied to eleven frontier LLMs using a proprietary test suite of 901 socially sensitive prompts, generating comprehensive risk profiles that reveal distributional characteristics beyond scalar averages.

## Key Results
- Models with similar average risk can exhibit more than twofold differences in tail exposure and volatility
- Epistemic and bias risks drive tail severity more consistently than fairness or ethics
- Scalar benchmarks miss critical distributional information about worst-case behavior in socially sensitive contexts

## Why This Works (Mechanism)
SHARP works by recognizing that social harm in LLMs is inherently multidimensional and distribution-dependent rather than scalar. By decomposing harm into bias, fairness, ethics, and epistemic reliability, the framework captures the complex nature of social risks. The additive cumulative log-risk model accounts for how these dimensions compound, while CVaR95 provides a principled way to measure tail risk that's sensitive to worst-case scenarios without being dominated by outliers. This multidimensional, tail-sensitive approach reveals behavioral patterns and risk concentrations that average-based metrics systematically miss.

## Foundational Learning

**Conditional Value at Risk (CVaR)**: A tail-sensitivity metric that measures the expected value in the worst 5% of cases, providing robust characterization of extreme outcomes. Needed to capture worst-case behavior that dominates risk in high-stakes deployment; quick check: verify that CVaR captures meaningful tail behavior beyond simple maximum values.

**Log-risk additive modeling**: Mathematical framework for combining multiple risk dimensions through logarithmic transformation and addition. Needed to properly model compounded harm where multiple dimensions interact; quick check: ensure the additive model doesn't oversimplify complex interactions between harm dimensions.

**Multidimensional harm decomposition**: Systematic breakdown of social harm into bias, fairness, ethics, and epistemic reliability. Needed to move beyond oversimplified scalar metrics that conflate distinct types of harm; quick check: validate that these four dimensions comprehensively cover relevant social harm categories.

## Architecture Onboarding

**Component map**: Prompt generation -> Multidimensional harm assessment -> Log-risk aggregation -> CVaR95 calculation -> Risk profile generation

**Critical path**: The evaluation pipeline processes 901 socially sensitive prompts through four harm dimension assessors, aggregates results using log-risk addition, and computes CVaR95 to generate tail-sensitive risk profiles that reveal distributional characteristics.

**Design tradeoffs**: The framework trades computational simplicity for comprehensive coverage by using additive log-risk modeling, which assumes independence between harm dimensions. This choice enables tractable computation but may miss complex interactions. The use of CVaR95 balances tail sensitivity with robustness to extreme outliers.

**Failure signatures**: The framework may miss nuanced interactions between harm dimensions due to additive assumptions, and the proprietary nature of the prompt set limits reproducibility. Results may be sensitive to prompt construction and content coverage, potentially limiting generalizability.

**First experiments**:
1. Apply SHARP to a subset of 100 prompts to verify computational efficiency and initial risk profile patterns
2. Compare CVaR95 results with simpler tail metrics (e.g., maximum values) to validate the choice of tail-sensitivity measure
3. Conduct ablation studies by removing individual harm dimensions to assess their relative contribution to overall risk profiles

## Open Questions the Paper Calls Out
None

## Limitations
- The additive cumulative log-risk model assumes independence between harm dimensions, which may not hold in real-world scenarios
- Results are based on a proprietary test suite of 901 prompts, limiting independent verification
- The choice of CVaR95 as the tail-sensitivity metric represents one approach among several alternatives

## Confidence
**High confidence**: The core observation that scalar benchmarks obscure important distributional information and tail behavior
**Medium confidence**: The finding that models with similar average risk exhibit >2x differences in tail exposure, pending independent replication with the same test suite
**Medium confidence**: The relative importance of epistemic and bias risks in driving tail severity, though this may vary with prompt selection and evaluation criteria

## Next Checks
1. Replicate the tail-sensitivity findings using alternative tail metrics (e.g., Value at Risk, worst-case performance) to verify robustness of the CVaR95 results
2. Conduct ablation studies on the prompt set to determine sensitivity of results to prompt construction and content coverage
3. Apply the SHARP framework to additional model families and training paradigms to assess generalizability across different LLM architectures and development approaches