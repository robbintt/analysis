---
ver: rpa2
title: Relating System Safety and Machine Learnt Model Performance
arxiv_id: '2507.20135'
source_url: https://arxiv.org/abs/2507.20135
tags:
- performance
- safety
- detection
- requirements
- sign
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents an initial method to relate system safety objectives,
  expressed as quantitative safety objectives (QSOs), to machine learnt model (MLM)
  performance requirements and metrics. Using an aircraft emergency braking system
  (AEBS) with a deep neural network for runway sign detection as an example, the authors
  develop a binomial model abstraction for the machine learnt component (MLC) behavior,
  deriving safety-related performance requirements from the allocated QSO.
---

# Relating System Safety and Machine Learnt Model Performance

## Quick Facts
- **arXiv ID:** 2507.20135
- **Source URL:** https://arxiv.org/abs/2507.20135
- **Reference count:** 26
- **Primary result:** Method to derive MLM performance requirements from system safety objectives using binomial model abstraction

## Executive Summary
This paper presents the first systematic method to relate civil aviation system safety objectives, expressed as quantitative safety objectives (QSOs), to machine learnt model (MLM) performance requirements and metrics. Using an aircraft emergency braking system (AEBS) with a deep neural network for runway sign detection as an example, the authors develop a binomial model abstraction for the machine learnt component (MLC) behavior. The method derives safety-related performance requirements from allocated QSOs and relates these to measurable MLM generalization error bounds and testing requirements.

## Method Summary
The method uses a top-down approach to translate system-level safety targets into concrete MLM performance thresholds. It begins with a fault tree analysis (FTA) to allocate the top-level QSO (e.g., 10^-3 per flight hour for MINOR severity) to an MLC-level QSO. This allocation treats insufficient ML performance as a probabilistic basic event. The method then applies a binomial model abstraction, treating detection confirmation as a K-of-M voting gate where the probability of confirming detection equals the cumulative binomial probability of achieving ≥ K hits in a fixed-size detection vector. By inverting this relationship against the allocated QSO, the method derives admissible ranges for per-image miss probability, confirmation thresholds, and tolerable miss ratios. Finally, it connects these requirements to measurable ML metrics through the mathematical equivalence of generalization error and failure probability under zero-one loss.

## Key Results
- Derived per-image probability of non-detection (miss probability) of 0.1 from QSO of 2×10^-4 per flight
- Established confirmation threshold of 6 detections out of 12 images for meeting safety requirements
- Determined tolerable miss ratio of 0.187 and related generalization error bound of 0.124
- Calculated required test sample size of 26,393 samples for tolerance of 0.012 and confidence of 0.001

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** A binomial model abstraction can translate system-level safety targets into concrete MLM performance thresholds.
- **Mechanism:** Detection confirmation is modeled as a K-of-M voting gate where the probability of confirming detection equals the cumulative binomial probability of achieving ≥ K hits in a fixed-size detection vector. By inverting this relationship against an allocated QSO, the method derives admissible ranges for per-image miss probability, confirmation thresholds, and tolerable miss ratios.
- **Core assumption:** Per-image detection outcomes behave as independent, identically distributed Bernoulli trials with constant miss probability across the detection vector.
- **Evidence anchors:** [abstract]: "develop a binomial model abstraction for the machine learnt component (MLC) behavior, deriving safety-related performance requirements from the allocated QSO"; [Section 5.1, Eq. 2-4]: Formalizes Pr(T=1) = Pr(H ≥ xmin) using binomial distribution; [corpus]: Weak direct corpus support—neighbor papers focus on safety metrics for perception but do not replicate this binomial abstraction method.
- **Break condition:** IID assumption violated by correlated sequential image inputs; pmiss non-stationary due to distribution drift; detection vector size varies operationally.

### Mechanism 2
- **Claim:** System-level QSOs can be systematically decomposed to component-level performance requirements through fault tree analysis (FTA), treating insufficient ML performance as a probabilistic basic event.
- **Mechanism:** The FTA models MLC malfunction (specifically false negatives) as a basic event with allocated failure probability budget. The top-level QSO is allocated downward using fault tree logic, yielding an effective MLC-level QSO that becomes the constraint for deriving performance requirements.
- **Core assumption:** Insufficient ML performance can be validly modeled as a random failure event with an associated probability, analogous to hardware failures in conventional FTA.
- **Evidence anchors:** [Section 4.2, Fig. 2]: Revised fault tree showing ProxAlertMalfn → EBCMalfn → SgnDetMalfn with budget allocation; [Section 6.1.1]: Justifies single-channel architecture as "tolerable worst-case" making requirements conservative; [corpus]: Burton et al. (2019, 2024) discuss assume-guarantee safety contracts for ML but do not formalize FTA-based allocation.
- **Break condition:** Architectural changes (redundancy, diversity) alter allocation; dependent failures between branches; development errors in non-ML software excluded from quantitative model.

### Mechanism 3
- **Claim:** Under zero-one loss, the ML generalization error is mathematically equivalent to the failure probability, enabling direct traceability from safety targets to ML metrics.
- **Mechanism:** The paper proves (Theorem 1) that for binary classification, the population risk with zero-one loss equals the probability of incorrect classification—i.e., Pr(f(x) ≠ y). This establishes that the required generalization error bound directly corresponds to the maximum tolerable per-image miss probability, which can then be empirically estimated via false negative rate on test data.
- **Core assumption:** The joint distribution Pr_{X,Y}(x,y) is well-defined and representative; test data is sampled from this distribution.
- **Evidence anchors:** [Section 5.3.1, Theorem 1]: Formal proof that Rp(f) = Pr(f(x) ≠ y) under zero-one loss; [Section 5.3.1, Req. 8-10]: Translates generalization error bound to concrete FNR/recall test requirements; [corpus]: Dong et al. (2023) and Scheerer et al. (2024) address ML reliability metrics but use bottom-up data-driven approaches rather than top-down derivation from safety objectives.
- **Break condition:** Non-representative test distribution; loss function differs from zero-one; multi-class classification requires multinomial extension.

## Foundational Learning

- **Concept: Quantitative Safety Objectives (QSOs) and Development Assurance Levels (DALs)**
  - Why needed here: The entire method presupposes understanding that civil aviation assigns numerical probability targets to failure conditions based on severity, and that DALs address development errors while QSOs address failure probabilities.
  - Quick check question: For a HAZARDOUS failure condition, would the QSO be more or less stringent than 10^-3 pfh, and why doesn't DAL alone suffice for ML components?

- **Concept: Binomial Distribution and K-of-M Voting Logic**
  - Why needed here: The core abstraction treats detection confirmation as cumulative binomial probability; understanding how n, p, and cumulative thresholds interact is essential to derive requirements.
  - Quick check question: If n=12 and the confirmation threshold is 6, what happens to Pr(T=1) when pmiss increases from 0.1 to 0.2?

- **Concept: Generalization Error vs. Empirical Risk**
  - Why needed here: The method bridges theoretical generalization error (unknowable exactly) with empirically measurable test metrics (FNR, recall), using probabilistic bounds to determine required sample sizes.
  - Quick check question: Why does Eq. (10) yield a worst-case lower bound on sample size, and what assumption makes Hoeffding's inequality conservative?

## Architecture Onboarding

- **Component map:** Video Camera -> Pre-processing -> MLSD (DNN) -> Post-processing -> EBC -> FWS
- **Critical path:** QSO allocation (FTA) → MLC-level QSO (2×10^-4) → binomial model inversion → concrete requirements (pmiss ≤ 0.1, xmin ≥ 6, mt ≤ 0.187, Rp(f) ≤ 0.124) → test requirements (FNR ≤ 0.1, sample size ≥ 26,393)
- **Design tradeoffs:**
  - Conservative single-channel architecture vs. redundant/diverse architectures (affects QSO allocation tightness)
  - IID assumption enables tractable binomial model but does not hold for correlated image sequences—valid for requirement derivation, not for verification
  - Larger detection vectors (n) allow higher per-image miss probability but increase latency
- **Failure signatures:**
  - **False Negative (SgnDetFlr):** Fewer than xmin hits in detection vector when NER sign present → no alert when required → QSO violation if Pr(T=0) > 2×10^-4
  - **False Positive (SgnDetFlsAlrm):** Detection confirmed when no sign present → spurious alert (currently out of scope but noted as limitation)
  - **Distribution drift:** pmiss increases over operational life → QSO exceeded → requires ODD monitoring and revalidation
- **First 3 experiments:**
  1. **Validate binomial approximation:** Collect sequences of MLSD outputs on held-out test data with known NER sign presence; empirically measure hit count distribution and compare to Binomial(n=12, p=0.9) to assess deviation from IID assumption.
  2. **Sensitivity analysis on confirmation threshold:** Vary xmin from 4 to 8 while holding pmiss constant; plot Pr(T=0) to identify margin between derived threshold (6) and QSO boundary.
  3. **Sample size verification:** Using Eq. (10) with δ=10^-3, ϵ=0.012, construct test sets of varying sizes around η=26,393; measure empirical FNR stability to confirm bound adequacy.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can robustness-related failures be formally separated from standard generalization errors within the safety performance requirements?
- **Basis in paper:** [explicit] Section 6.3.2 states that future work must explore expressing the robustness portion of the generalization error to account for model fragility under input perturbation.
- **Why unresolved:** The current method aggregates robustness and generalization failures into a single metric, lacking a distinct mathematical formulation for safety requirements specific to robustness.
- **What evidence would resolve it:** A mathematical decomposition of the generalization error that isolates robustness contributions and a derivation of corresponding safety targets for the MLSD.

### Open Question 2
- **Question:** How can the current binomial abstraction be extended to a multinomial or Bayesian model to account for false positives and false classifications?
- **Basis in paper:** [explicit] Section 7.2 notes that addressing per-image false positives is necessary because the current binary (hit/miss) model renders requirements "more optimistic than they should be."
- **Why unresolved:** The existing method assumes a binary outcome (detection/non-detection) and does not mathematically model the distinct failure modes of false alarms or misclassification, which are critical for the "ProxAlertMalfn" hazard.
- **What evidence would resolve it:** A derived set of safety requirements using a multinomial distribution that constrains false positive rates while maintaining the allocated Quantitative Safety Objective (QSO).

### Open Question 3
- **Question:** What statistical approaches are required to verify MLC performance given that input data violates the Independent and Identically Distributed (IID) assumption?
- **Basis in paper:** [inferred] Section 6.2 states that the IID constraint is not met because the input is a correlated time series; consequently, the binomial model abstraction cannot be used for verification, only for requirement specification.
- **Why unresolved:** While the method constructs valid requirements, it leaves undefined the specific verification protocol needed to confirm an implementation meets those requirements using non-independent data.
- **What evidence would resolve it:** A verification method or statistical bound that remains valid for temporally correlated image sequences to prove the QSO is met.

## Limitations
- **Single failure mode focus:** The approach specifically addresses false negatives but does not account for false positives or other failure modes that could impact system safety.
- **IID assumption violation:** The binomial model relies on independent detection trials, which may not hold for temporally correlated image sequences.
- **Architectural scope:** The method currently applies to single-channel ML components without architectural redundancy.

## Confidence
- **High Confidence:** The mathematical framework connecting QSOs to binomial model parameters is rigorously derived and internally consistent.
- **Medium Confidence:** The applicability to real-world ML systems depends on validating the IID assumption and confirming the single-channel architecture claim.
- **Low Confidence:** The method's scalability to complex multi-class scenarios and its treatment of development errors versus operational failures require further validation.

## Next Checks
1. **Independence Validation:** Collect empirical detection sequences from a deployed ML system and statistically test for temporal correlation to validate or refute the IID assumption underlying the binomial model.
2. **Architecture Sensitivity:** Apply the method to ML architectures with redundancy (e.g., dual ML channels) to determine how QSO allocation changes and whether the single-channel requirements remain valid bounds.
3. **Multi-Class Extension:** Extend the binomial model abstraction to multi-class classification scenarios to assess the method's generalizability beyond binary detection tasks.