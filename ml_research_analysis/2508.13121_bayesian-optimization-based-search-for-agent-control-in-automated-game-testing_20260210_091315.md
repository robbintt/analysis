---
ver: rpa2
title: Bayesian Optimization-based Search for Agent Control in Automated Game Testing
arxiv_id: '2508.13121'
source_url: https://arxiv.org/abs/2508.13121
tags:
- game
- testing
- agent
- level
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a Bayesian Optimization (BO)-based hierarchical
  approach for automated game testing. The key idea is to decouple the exploration
  process into a high-level BO module that determines optimal locations to explore
  and a low-level learned policy module that executes navigation to those locations.
---

# Bayesian Optimization-based Search for Agent Control in Automated Game Testing

## Quick Facts
- arXiv ID: 2508.13121
- Source URL: https://arxiv.org/abs/2508.13121
- Reference count: 12
- Key outcome: BO-based hierarchical approach achieves 2.52× better map coverage and improved bug detection in automated game testing

## Executive Summary
This paper introduces a Bayesian Optimization-based hierarchical system for automated game testing that decouples exploration into high-level BO module for determining optimal exploration locations and low-level learned policy for navigation execution. The key innovation is a grid map-based surrogate model that maintains constant size regardless of dataset growth, using Gaussian kernels for efficient interpolation and uncertainty estimation. The system significantly improves map coverage and bug detection capabilities compared to baseline methods, demonstrating adaptive exploration through uncertainty-based navigation.

## Method Summary
The proposed system implements a two-tier architecture where a Bayesian Optimization module handles strategic exploration decisions at a high level, while a learned policy module executes the actual navigation to target locations. To address scalability challenges with traditional BO models that grow with dataset size, the authors introduce a grid map surrogate model with fixed dimensions. This model uses Gaussian kernels to interpolate values and estimate uncertainty across the game environment, enabling efficient optimization without computational overhead from expanding datasets. The hierarchical approach allows for systematic exploration while maintaining real-time performance characteristics.

## Key Results
- Achieves 2.52× better map coverage compared to baseline methods
- Demonstrates more uniform exploration distribution across game environments
- Shows improved detection of specific issues like "ghost walls" through adaptive exploration based on model uncertainty

## Why This Works (Mechanism)
The system's effectiveness stems from the strategic decoupling of exploration planning and execution. The high-level BO module can focus on global optimization without being constrained by the complexities of real-time navigation, while the low-level policy handles the practical challenges of movement and obstacle avoidance. The grid map surrogate model enables constant-time complexity for BO operations regardless of exploration progress, making the approach scalable for extended testing sessions. The Gaussian kernel interpolation provides smooth value estimates while maintaining uncertainty quantification for adaptive exploration.

## Foundational Learning
1. Bayesian Optimization fundamentals: Why needed - core optimization technique for expensive black-box functions; Quick check - understand acquisition functions and surrogate modeling
2. Gaussian Process regression: Why needed - provides probabilistic predictions and uncertainty estimates; Quick check - familiarity with kernel functions and covariance matrices
3. Hierarchical reinforcement learning: Why needed - enables separation of high-level planning from low-level execution; Quick check - knowledge of option frameworks and temporal abstraction
4. Grid-based spatial modeling: Why needed - enables scalable representation of continuous environments; Quick check - understanding of discretization trade-offs
5. Automated game testing principles: Why needed - domain-specific requirements for coverage and bug detection; Quick check - familiarity with game state spaces and testing objectives
6. Uncertainty quantification: Why needed - drives adaptive exploration strategies; Quick check - grasp of exploration-exploitation trade-offs

## Architecture Onboarding

Component Map:
BO Module -> Grid Map Surrogate -> Gaussian Kernel Interpolation -> Uncertainty Estimation -> Location Selection -> Learned Policy -> Navigation Execution

Critical Path:
The critical execution path flows from the BO module through the grid map surrogate model, where Gaussian kernel interpolation generates uncertainty estimates that drive location selection. These selected locations are then passed to the learned policy for navigation execution. The path is critical because each stage directly enables the next, with the surrogate model serving as the central coordination point.

Design Tradeoffs:
The primary design tradeoff involves balancing exploration efficiency with computational overhead. The constant-size grid map model sacrifices fine-grained resolution for scalability, potentially missing subtle environmental features. The hierarchical separation enables specialized optimization but introduces coordination overhead between modules. The Gaussian kernel approach trades exact interpolation for computational efficiency and uncertainty estimation capabilities.

Failure Signatures:
Common failure modes include: grid discretization causing missed narrow passages or small objects; learned policy getting stuck in local minima or complex terrain; BO module selecting suboptimal locations due to inaccurate surrogate model predictions; uncertainty estimates becoming unreliable in highly dynamic environments; and the system converging prematurely to suboptimal exploration patterns.

3 First Experiments:
1. Compare coverage metrics across different grid resolutions to identify optimal discretization granularity
2. Evaluate navigation policy performance in controlled obstacle courses to benchmark movement capabilities
3. Test BO optimization efficiency with synthetic reward landscapes to validate surrogate model accuracy

## Open Questions the Paper Calls Out
None

## Limitations
- Experimental validation relies heavily on a single custom game environment, limiting generalizability to commercial games
- Grid map surrogate model may introduce discretization artifacts affecting exploration quality in continuous environments
- Computational overhead trade-offs between BO optimization and policy execution are not thoroughly addressed

## Confidence
- 2.52× better coverage claim: High confidence based on quantitative results presented
- Improved "ghost wall" detection: Medium confidence due to limited qualitative examples
- Scalability improvements: Supported by methodology but needs more extensive ablation studies

## Next Checks
1. Test the approach across multiple diverse game genres to evaluate generalizability
2. Conduct ablation studies comparing different surrogate model granularities and their impact on exploration efficiency
3. Measure end-to-end computational costs including both BO optimization and policy execution times to assess practical deployment feasibility