---
ver: rpa2
title: Decision-Oriented Text Evaluation
arxiv_id: '2507.01923'
source_url: https://arxiv.org/abs/2507.01923
tags:
- human
- market
- evaluation
- investors
- morning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a decision-oriented framework for evaluating
  natural language generation by measuring its direct impact on human and LLM decision
  outcomes, rather than relying on intrinsic metrics like n-gram overlap. Using market
  digest texts as test cases, it assesses decision quality based on financial performance
  of trades made by human investors and autonomous LLM agents using only the provided
  texts.
---

# Decision-Oriented Text Evaluation

## Quick Facts
- arXiv ID: 2507.01923
- Source URL: https://arxiv.org/abs/2507.01923
- Reference count: 14
- Primary result: Decision-oriented evaluation framework measuring text impact on financial trading outcomes reveals limitations of traditional n-gram metrics

## Executive Summary
This paper introduces a decision-oriented framework for evaluating natural language generation by measuring its direct impact on human and LLM decision outcomes, rather than relying on intrinsic metrics like n-gram overlap. Using market digest texts as test cases, it assesses decision quality based on financial performance of trades made by human investors and autonomous LLM agents using only the provided texts. Experiments reveal that neither humans nor LLM agents consistently outperform random baselines when relying solely on objective summaries, but richer analytical commentaries enable collaborative human-LLM teams to significantly outperform individual baselines. The findings highlight the limitations of traditional evaluation methods and underscore the value of decision-oriented assessment for generated text.

## Method Summary
The framework evaluates NLG quality by measuring decision outcomes from trading activities based on market digest texts. It uses a two-stage pipeline: (1) asset selection via performance-based metrics (volatility, volume, institutional flow) or professional-insight extraction from journalist transcripts, and (2) GPT-4o generation of morning briefs (objective summaries) and closing-bell reports (analytical commentaries). Human investors (3 participants) and LLM agents (GPT-4o, Gemini-2.0-Flash, Claude-3.5-Sonnet) make buy/sell decisions using only the provided text. Decision quality is measured through thresholded accuracy against actual price movements (+0.55% rise / -0.50% fall).

## Key Results
- Neither humans nor LLMs consistently beat random baselines on objective summaries alone
- Richer analytical commentaries enable collaborative human-LLM teams to outperform individual baselines
- LLM-generated summaries can outperform professional journalism for certain decision tasks by reducing transaction frequency and presenting more distilled information

## Why This Works (Mechanism)

### Mechanism 1
Decision outcomes provide more meaningful evaluation signals than surface-level metrics by treating text as input to a decision process and measuring economic accuracy of resulting actions. The framework assumes the decision task is well-specified enough that poor text causes poor decisions. Short evaluation windows help mitigate market manipulation and breaking news confounds.

### Mechanism 2
Human-LLM complementarity emerges with analytical depth rather than pure summarization. Analytical commentary creates "synergistic decision-making" where humans and LLMs compensate for each other's blind spots through different weighting of signals and uncertainty interpretation.

### Mechanism 3
LLM-generated summaries outperform professional journalism by reducing transaction frequency and presenting more distilled information. Traditional journalism's reference to many assets without directional emphasis creates decision noise, particularly for LLM agents that may interpret weak signals as actionable.

## Foundational Learning

- Concept: **Extrinsic vs. Intrinsic Evaluation**
  - Why needed here: The entire framework rejects intrinsic metrics (BLEU, ROUGE) in favor of extrinsic decision outcomes
  - Quick check question: Can you explain why a high ROUGE score doesn't guarantee a summary helps an investor make profitable trades?

- Concept: **Decision Theory Basics (Utility, Threshold, Ground Truth)**
  - Why needed here: The evaluation uses thresholded accuracy as a binary classification proxy
  - Quick check question: Why might threshold choice affect which text source appears "better"?

- Concept: **Human-AI Complementarity**
  - Why needed here: The key finding is that teams outperform individuals
  - Quick check question: What complementary strengths did the paper identify between human investors and LLM agents?

## Architecture Onboarding

- Component map: Raw news corpus (~2,400 articles/day) → Asset selection pipeline → LLM digest generator → Market digest output
- Critical path: 1) Asset selection determines candidate universe, 2) Digest generation (morning brief = objective summary; closing-bell = analytical commentary), 3) Decision isolation (no external information; short time horizons), 4) Accuracy measurement (binary thresholds on price movement)
- Design tradeoffs: Short vs. long evaluation windows, LLM as evaluator vs. human, constrained vs. open asset selection
- Failure signatures: Random baseline parity, high transaction volume with journalist text, source guessing by participants
- First 3 experiments:
  1. Reproduce the baseline with same three LLM agents on 10-day sample of morning briefs with temperature=0
  2. Isolate the selection effect by comparing performance-based vs. professional-insight pipelines
  3. Stress-test the collaboration protocol with explicit human-LLM team decision mechanism

## Open Questions the Paper Calls Out

- **Cross-domain generalizability**: Can decision-oriented evaluation frameworks be effectively generalized from financial market digests to other high-stakes domains such as clinical decision support or legal analysis?
- **Textual feature isolation**: What specific textual features of "richer analytical commentaries" enable effective human-LLM collaborative decision-making?
- **Bias quantification**: To what extent does LLM-generated content's implicit bias toward positive framing systematically skew decision-making behavior?
- **Long-term performance**: How do decision-oriented evaluation findings change when using longer investment horizons and risk-adjusted performance metrics?

## Limitations
- Limited generalizability to domains with ambiguous ground truth or longer planning horizons
- Collaboration protocol ambiguity without standardized mechanisms
- Signal-to-noise ratio concerns with performance near random baseline on objective summaries

## Confidence
- High confidence: Decision outcomes provide more meaningful evaluation signals than n-gram metrics
- Medium confidence: Complementary strengths between humans (asset selection) and LLMs (synthesis)
- Low confidence: Structured human-LLM collaboration consistently outperforms individuals

## Next Checks
1. Apply the decision framework to a non-financial domain with quantifiable ground truth (e.g., medical discharge notes predicting readmission)
2. Design and test explicit human-LLM collaboration protocols to isolate structured vs. unstructured teamwork contributions
3. Systematically vary text quality while controlling for asset selection to quantify relative contributions of text generation vs. information selection