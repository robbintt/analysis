---
ver: rpa2
title: 'Meaning Is Not A Metric: Using LLMs to make cultural context legible at scale'
arxiv_id: '2505.23785'
source_url: https://arxiv.org/abs/2505.23785
tags:
- meaning
- social
- human
- thick
- cultural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes using large language models (LLMs) to make
  human meaning legible at scale in AI-based sociotechnical systems. The authors argue
  that current systems rely on "thin descriptions" (numerical metrics that strip away
  cultural context) and cannot adequately represent human meaning.
---

# Meaning Is Not A Metric: Using LLMs to make cultural context legible at scale

## Quick Facts
- arXiv ID: 2505.23785
- Source URL: https://arxiv.org/abs/2505.23785
- Reference count: 40
- This paper proposes using large language models (LLMs) to make human meaning legible at scale in AI-based sociotechnical systems

## Executive Summary
This paper addresses the fundamental challenge of representing human meaning and cultural context in AI systems, arguing that current approaches rely on "thin descriptions" - numerical metrics that strip away cultural nuance and context. The authors propose leveraging LLMs to generate and process "thick descriptions" - verbal representations that retain contextual information, drawing from humanities scholarship methods. The framework identifies five key challenges: preserving context, maintaining interpretive pluralism, integrating lived experience with critical distance, distinguishing qualitative content from quantitative magnitude, and acknowledging meaning as dynamic rather than static.

## Method Summary
The paper presents a conceptual framework rather than empirical results, proposing how LLMs could be used to generate and process thick descriptions at scale. The approach draws from humanities methodologies of thick description, suggesting that LLMs can partially automate the generation and processing of verbal representations that retain cultural context. The framework focuses on identifying key challenges and theoretical considerations for implementing thick descriptions in AI systems, though it does not provide concrete implementation details or empirical validation.

## Key Results
- Identifies five key challenges in making human meaning legible at scale using LLMs
- Proposes a framework for using thick descriptions (verbal representations) instead of thin metrics (numerical measures)
- Argues that meaning is inherently dynamic and cannot be reduced to static metrics

## Why This Works (Mechanism)
The mechanism relies on LLMs' ability to process and generate natural language, which can capture nuanced cultural meanings and contextual information that numerical metrics cannot. By using language models to create and analyze thick descriptions, the approach preserves the richness and complexity of human meaning that gets lost in quantitative reduction. The framework leverages the fact that LLMs can understand and generate contextual language, potentially allowing for scalable processing of culturally rich information while maintaining interpretive pluralism.

## Foundational Learning
- Thick vs Thin Descriptions: Why needed - to understand the fundamental difference between context-preserving and context-stripping representations; Quick check - can you explain why a numerical rating fails to capture cultural nuance that a narrative description might preserve?
- Interpretive Pluralism: Why needed - to recognize that cultural meanings are multiple and contested rather than singular; Quick check - can you identify at least two different valid interpretations of the same cultural artifact?
- Critical Distance vs Lived Experience: Why needed - to balance subjective experience with objective analysis in cultural interpretation; Quick check - can you explain how personal experience both enriches and potentially biases cultural analysis?
- Dynamic Meaning: Why needed - to understand that cultural significance evolves over time and context; Quick check - can you identify an example of how the meaning of a cultural symbol has changed over time?

## Architecture Onboarding

**Component Map:** Cultural Data Sources -> LLM Processing Layer -> Thick Description Generation -> Context Preservation Module -> Interpretive Pluralism Management -> Dynamic Meaning Integration

**Critical Path:** The system must first receive culturally diverse input data, then process it through LLMs to generate thick descriptions while simultaneously preserving context, managing multiple interpretations, and maintaining awareness of meaning's dynamic nature.

**Design Tradeoffs:** The framework trades quantitative precision and standardization for qualitative richness and contextual accuracy. This means sacrificing the ability to perform certain mathematical operations on the data in exchange for preserving cultural nuance and multiple valid interpretations.

**Failure Signatures:** The system may fail when LLMs oversimplify complex cultural meanings, when context gets lost in processing, when interpretive pluralism collapses into singular interpretations, or when dynamic meanings are treated as static. Failures manifest as cultural misrepresentation, loss of nuance, or inappropriate standardization of diverse meanings.

**First 3 Experiments:**
1. Compare thick description outputs from LLMs against human-generated thick descriptions for the same cultural content
2. Test context preservation by removing specific contextual elements and measuring LLM performance degradation
3. Evaluate interpretive pluralism by having multiple LLM instances process identical cultural content and measuring consistency versus divergence

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- The work remains theoretical without validation through actual implementation or testing of the proposed framework
- No concrete examples of how LLMs would generate or process thick descriptions in practice
- No discussion of potential risks or failures in applying LLMs to cultural interpretation

## Confidence
- Conceptual framework for thick description in AI systems: Medium
- LLMs can preserve cultural context at scale: Low
- Interpretive pluralism can be maintained through LLM processing: Low
- Meaning can be represented without metric reduction: Medium

## Next Checks
1. Implement a proof-of-concept system using LLMs to generate thick descriptions from culturally diverse data sources and evaluate context preservation
2. Conduct user studies comparing interpretations generated through thin metrics versus thick descriptions for the same cultural phenomena
3. Test the framework's ability to maintain interpretive pluralism by having multiple LLM agents process identical cultural content and measuring consistency versus divergence