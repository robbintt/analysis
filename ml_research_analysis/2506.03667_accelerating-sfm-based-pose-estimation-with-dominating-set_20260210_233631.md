---
ver: rpa2
title: Accelerating SfM-based Pose Estimation with Dominating Set
arxiv_id: '2506.03667'
source_url: https://arxiv.org/abs/2506.03667
tags:
- dominating
- pose
- images
- estimation
- reference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a preprocessing technique to accelerate SfM-based
  pose estimation using the concept of a dominating set from graph theory. The method
  reduces the number of reference images and 3D points required for pose estimation,
  improving processing speed while maintaining accuracy.
---

# Accelerating SfM-based Pose Estimation with Dominating Set

## Quick Facts
- arXiv ID: 2506.03667
- Source URL: https://arxiv.org/abs/2506.03667
- Reference count: 37
- Primary result: Preprocessing technique using dominating set reduces reference images (17-23x) and point cloud size (2.27-4x), achieving 1.5-14.48x speed improvements while maintaining accuracy on OnePose dataset.

## Executive Summary
This paper introduces a preprocessing technique to accelerate SfM-based pose estimation by reducing the number of reference images and 3D points required. The method uses graph theory's dominating set concept to identify a minimal subset of reference images that can "cover" the pose estimation requirements of all images. By pruning the SfM model to only include points visible in this dominating set, the approach achieves significant speed improvements (1.5-14.48x) while maintaining accuracy. The technique was evaluated on the OnePose dataset across multiple SfM-based methods, demonstrating a promising balance between speed and accuracy for real-time applications.

## Method Summary
The method constructs a directed graph where nodes represent reference images and edges indicate whether one image can localize another within a specified error threshold (0.05d). A minimum dominating set is computed to identify the smallest subset of images sufficient to cover all pose estimation requirements. The 3D point cloud is then pruned to retain only points observed by the dominating set images. During inference, pose estimation operates on this reduced SfM model, significantly decreasing the computational cost of feature matching and PnP solving. The approach trades a one-time O(N²) preprocessing cost for perpetual inference speedups.

## Key Results
- Speed improvements of 1.5 to 14.48 times across multiple SfM-based methods
- Reduction in reference images by factors of 17-23
- Reduction in point cloud size by factors of 2.27-4
- Maintained accuracy with minimal drop in ADD-0.1d metrics
- Evaluated on OnePose dataset (80 objects) with reference and query images from different videos

## Why This Works (Mechanism)

### Mechanism 1: Graph-Based Reference Reduction via Dominating Set
- Processing speed increases proportionally to the reduction in reference images by eliminating redundant feature matching steps while maintaining pose estimation coverage
- The SfM model is modeled as a directed graph where nodes are reference images, with edges indicating localization capability within a 0.05d error threshold
- Minimum dominating set (MDS) identifies the smallest subset of images sufficient to "cover" all pose estimation requirements
- Core assumption: Visual features within the dominating set are sufficiently representative to generalize to novel query images
- Break condition: Query images requiring features present only in pruned non-dominating images will experience localization accuracy degradation

### Mechanism 2: Point Cloud Pruning via Visibility Association
- Inference speed is further improved by reducing the 3D point cloud size, lowering the computational cost of matching 2D query features against 3D model points
- 3D points are filtered based on the dominating set: a point is retained only if observed by at least one image in the dominating set
- Core assumption: Points observed by the dominating set provide sufficiently dense geometric constraints for accurate PnP convergence on novel views
- Break condition: PnP solvers fail if remaining point density is too low to establish robust 2D-3D correspondences for specific query views

### Mechanism 3: Approximate Optimization via Randomized Greedy Search
- Practical preprocessing times are achieved by using a randomized greedy algorithm to approximate the NP-hard minimum dominating set problem
- The algorithm iteratively selects random nodes, adds them to the set, and removes them and their neighbors from the candidate pool (1000 iterations)
- Core assumption: Variability in randomized greedy solution does not result in significantly larger dominating sets than theoretical minimum
- Break condition: High variance in preprocessing results if iteration count is too low, yielding sub-optimal dominating sets that hamper speed gains

## Foundational Learning

- **Concept: Dominating Set (Graph Theory)**
  - Why needed: Core mathematical tool to identify minimal set of reference images that "dominate" pose estimation requirements
  - Quick check: Given a graph of 4 nodes connected in a line (A-B-C-D), is {B, D} a valid dominating set?

- **Concept: Perspective-n-Point (PnP)**
  - Why needed: Algorithm that consumes 2D-3D correspondences to output final pose; complexity sensitive to number of correspondences
  - Quick check: How does PnP behavior change when provided with exactly 3 points versus 4 points regarding solution uniqueness?

- **Concept: Structure-from-Motion (SfM)**
  - Why needed: Input data structure being optimized; generates both sparse 3D point cloud and camera poses (reference images)
  - Quick check: What are the two primary outputs of a Structure-from-Motion pipeline used by this acceleration method?

## Architecture Onboarding

- Component map: SfM Input -> Graph Constructor -> Dominating Set Solver -> Pruning Engine -> Standard Pipeline (Feature Matcher -> PnP)
- Critical path: Graph Constructor is the bottleneck during preprocessing (O(N²) pairwise pose estimations), while Feature Matcher benefits during inference with reduced search space
- Design tradeoffs:
  - Preprocessing Time vs. Inference Speed: One-time O(N²) graph construction cost for perpetual inference speedups
  - Threshold Selection: Localization error threshold (0.05d) controls graph density and dominating set size
- Failure signatures:
  - Boundary Failure: Query images observing object regions only visible in pruned "boundary" reference images will fail to localize
  - Accuracy Drop: Significant drops in ADD-0.1d metrics indicate dominating set is too sparse or threshold too loose
- First 3 experiments:
  1. Graph Construction Validation: Implement Algorithm 2 on a small synthetic scene (10 images) to verify "dominating" images are most central/representative views
  2. Threshold Sensitivity Analysis: Run pipeline with varying error thresholds (0.01d vs. 0.1d) to plot Reference Image Reduction % vs. Accuracy Retention %
  3. Random Baseline Comparison: Compare "Dominating Set" selection against "Random Sampling" baseline of equal size to confirm graph-theoretic selection adds value

## Open Questions the Paper Calls Out

- **Open Question 1:** Can integrating a temporal tracking module recover accuracy lost due to dominating set pruning without compromising real-time performance?
  - Basis: Conclusion states future work includes integrating tracking module leveraging pose history
  - Why unresolved: Current experiments evaluate static pose estimation on individual frames; proposed solution is hypothetical
  - What evidence would resolve it: Experiments combining dominating set preprocessing with visual odometry/Kalman filters showing improved ADD-0.1d scores while maintaining high FPS

- **Open Question 2:** Can the dominating set approach maintain its speed/accuracy trade-off when applied to large-scale outdoor SfM datasets or different SfM backbones?
  - Basis: Authors explicitly list broadening application "across additional Structure-from-Motion (SfM)-based pose estimation techniques" as future work
  - Why unresolved: Evaluation restricted to OnePose dataset (objects) and specific methods; generalization to large-scale scenes unproven
  - What evidence would resolve it: Benchmark results on outdoor localization datasets (Aachen Day-Night) or integration with hierarchical localization methods (HF-Net)

- **Open Question 3:** How can the method be modified to ensure robustness when reference images provide incomplete coverage of the object?
  - Basis: Limitations section notes hemispherical coverage issues where algorithm might remove boundary images, causing failure on query images viewing removed areas
  - Why unresolved: Current greedy algorithm optimizes for coverage based on available edges but lacks mechanism to preserve "boundary" views critical for generalizing to unseen viewpoints
  - What evidence would resolve it: Algorithm modification penalizing removal of boundary nodes or comparative analysis showing success rates on sparsely sampled hemispherical data

## Limitations
- Excessive preprocessing time due to O(N²) graph construction complexity, computationally expensive for large SfM models
- Limited evaluation scope restricted to OnePose dataset (objects) without ablation studies on error threshold or iteration count effects
- Brief discussion of failure modes without systematic study of when and why the method fails, particularly for boundary cases and sparse coverage

## Confidence
- **High Confidence:** Core claim that dominating set can reduce reference images and 3D points while maintaining accuracy is well-supported by quantitative results (1.5-14.48x speedups with minimal accuracy loss)
- **Medium Confidence:** Randomized greedy algorithm finding near-optimal dominating set is theoretically sound, but lack of comparison to exact methods or other heuristics leaves optimality uncertainty
- **Low Confidence:** Discussion of failure modes is brief; mentions boundary failures for unseen angles but lacks systematic study of failure conditions

## Next Checks
1. Graph Construction Validation: Implement Algorithm 2 on a small synthetic scene (10 images) to verify "dominating" images are most central/representative views
2. Threshold Sensitivity Analysis: Run pipeline with varying error thresholds (0.01d vs. 0.1d) to plot Reference Image Reduction % vs. Accuracy Retention %
3. Random Baseline Comparison: Compare "Dominating Set" selection against "Random Sampling" baseline of equal size to confirm graph-theoretic selection adds value over simple subsampling