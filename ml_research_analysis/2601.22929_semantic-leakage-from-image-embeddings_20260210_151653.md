---
ver: rpa2
title: Semantic Leakage from Image Embeddings
arxiv_id: '2601.22929'
source_url: https://arxiv.org/abs/2601.22929
tags:
- image
- semantic
- embeddings
- captions
- leakage
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper shows that image embeddings are vulnerable to semantic
  leakage, where an attacker can recover meaningful information from compressed image
  representations without requiring exact pixel reconstruction. The proposed SLImE
  framework exploits the retrieval-oriented nature of embeddings by training a lightweight
  local retriever and using off-the-shelf models to progressively infer semantic information
  through multiple stages.
---

# Semantic Leakage from Image Embeddings

## Quick Facts
- arXiv ID: 2601.22929
- Source URL: https://arxiv.org/abs/2601.22929
- Reference count: 40
- This paper demonstrates that retrieval-optimized image embeddings are vulnerable to semantic leakage, where meaningful information can be recovered without pixel reconstruction.

## Executive Summary
This paper reveals that image embeddings optimized for retrieval are fundamentally vulnerable to semantic leakage, where an attacker can recover meaningful information without exact pixel reconstruction. The proposed SLImE framework exploits the retrieval-oriented nature of embeddings by training a lightweight local retriever and using off-the-shelf models to progressively infer semantic information through multiple stages. The method demonstrates that preserving local semantic neighborhoods under embedding alignment is sufficient to enable leakage, with F1 scores reaching 0.8 for neighborhood preservation and Rouge-L scores of 40+ for caption reconstruction.

## Method Summary
SLImE attacks exploit the retrieval-optimized nature of image embeddings through a multi-stage pipeline. First, captions are preprocessed into relational tags using Stanza NLP. A local retriever is trained on a separate corpus using contrastive learning and a DCN v2 ranker with hard negative mining. The attack aligns victim embeddings to the attack space via least-squares optimization using a small number of alignment samples. During inference, aligned embeddings retrieve top-K semantic tags, which are then fed to an LLM for caption generation. An adaptive variant generates low-fidelity images from embeddings and uses VLMs to infer objects, relations, and scenes for refined captioning. The framework demonstrates that semantic leakage is a fundamental vulnerability of retrieval-optimized embeddings rather than an artifact of specific implementations.

## Key Results
- F1 scores for neighborhood preservation reach 0.8 at neighborhood size m=50
- Rouge-L scores of 40+ for caption reconstruction when evaluated against ground truth captions
- Attacks generalize across domains and multiple embedding models
- Semantic leakage persists even with minimal alignment samples (as few as 1 sample)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Linear alignment between embedding spaces preserves local semantic neighborhoods sufficiently for information recovery.
- **Mechanism:** The least-squares optimal alignment matrix W = (Eᵀ_V E_V)⁻¹Eᵀ_V E_A maps victim embeddings to attack space while maintaining cosine similarity relationships. Retrieved tags from aligned embeddings fall within semantic neighborhoods of reference tags (Definition 3.2), achieving F1 scores up to 0.8 at neighborhood size m=50 (Figure 2).
- **Core assumption:** Victim and attack embedding spaces share semantically aligned structure due to contrastive pretraining objectives.
- **Evidence anchors:**
  - [abstract] "Preserving local semantic neighborhoods under embedding alignment is sufficient to expose the intrinsic vulnerability"
  - [Section 3.3] F1 increases monotonically with m and saturates at m=50; leakage driven by local neighborhood preservation rather than global semantic overlap
  - [corpus] Related work on embedding space alignment for privacy-preserving retrieval (arxiv:2507.18518) suggests alignment properties are exploitable across systems
- **Break condition:** If victim encoder uses fundamentally different contrastive objectives (e.g., not retrieval-oriented), neighborhood preservation may degrade substantially.

### Mechanism 2
- **Claim:** Retrieval itself functions as an inference mechanism without requiring task-specific decoders.
- **Mechanism:** The locally trained retriever (DCN v2 ranker on top of frozen dual encoder) maps aligned embeddings to discrete semantic tags. Off-the-shelf LLMs then amplify partial tag signals into coherent captions, achieving Rouge-L scores of 40+ against ground-truth captions from tags (Table 1).
- **Core assumption:** Contemporary generative models can reconstruct coherent descriptions from incomplete semantic signals.
- **Evidence anchors:**
  - [abstract] "incorporating a locally trained semantic retriever with off-the-shelf models, without training task-specific decoders"
  - [Section 5.2] K=10 yields best performance; key information retrieved early; Rouge-L > 20 even with single alignment sample
  - [corpus] GEIA framework (arxiv:2504.16609) demonstrates similar generative inversion attacks on text embeddings, suggesting cross-modal generality
- **Break condition:** If tag vocabulary is extremely sparse or LLMs lack strong priors for the target domain, caption quality degrades.

### Mechanism 3
- **Claim:** Semantic information propagates through a sequence of lossy mappings via neighborhood preservation.
- **Mechanism:** The pipeline e_V → e_A → {e_t} → t → {C} introduces cumulative distortion at each stage (alignment, retrieval, discretization, generation). Yet local semantic structure persists: scene-level F1 remains high (0.75-0.88) even when fine-grained relation recovery is limited (Figure 6).
- **Core assumption:** Semantic neighborhoods encode redundant information that survives quantization and transformation.
- **Evidence anchors:**
  - [abstract] "this preserved neighborhood structure allows semantic information to propagate through a sequence of lossy mappings"
  - [Section 4.4] Formalizes propagation through lossy stages; "preserving local semantic neighborhoods at retrieval suffices"
  - [corpus] CompLeak (arxiv:2507.16872) shows compression can exacerbate leakage—consistent with lossy mappings preserving key semantic structure
- **Break condition:** If alignment samples are severely mismatched (domain shift without adaptation), cosine similarity drops and propagation fails.

## Foundational Learning

- **Concept: Contrastive Learning and Dual Encoders**
  - Why needed here: SLImE builds on frozen dual encoders (CLIP architecture) and extends them with trainable projection layers; understanding contrastive loss (L_i→t, L_t→i) is essential for comprehending the retriever training.
  - Quick check question: Can you explain why contrastive learning produces embeddings where semantically similar items cluster together?

- **Concept: Embedding Space Geometry (Cosine Similarity, Neighborhoods)**
  - Why needed here: The entire attack hinges on cosine similarity preserving neighborhood structure after linear transformation; the F1 metric depends on Top-m semantic neighborhoods.
  - Quick check question: Given two normalized vectors with cosine similarity 0.9, what does this imply about their angular distance?

- **Concept: Moore-Penrose Pseudoinverse and Least-Squares Optimization**
  - Why needed here: The alignment matrix W is derived via closed-form least-squares solution (Equation 2); understanding this derivation is necessary to implement or modify alignment strategies.
  - Quick check question: Why does the least-squares solution minimize ||E_A - E_V·W||², and what happens if Eᵀ_V E_V is not invertible?

## Architecture Onboarding

- **Component map:**
  - Caption → relational tags via Stanza NLP (triples <subject, verb, object>, attribute tuples)
  - Local Retriever Training: Frozen dual encoder (CLIP ViT-bigG-14) → trainable projection layers (L_contrastive) → DCN v2 ranker (L_rank with hard negative mining)
  - Alignment Stage: Compute W via least-squares on b alignment samples (Equation 2)
  - Inference Pipeline: e_V → e_V→A → Top-K tag retrieval → LLM caption generation
  - Adaptive Attacks: Diffusion model generates low-fidelity image from e_V→A → VLM infers objects/relations/scenes → refined caption generation

- **Critical path:**
  1. **Tag quality directly bounds downstream performance**—noisy or incomplete tags propagate errors through LLM generation (Section 3.1 notes relational tags outperform tokens).
  2. **Alignment sample count vs. quality tradeoff**—10K samples yield best results (Figure 3), but even 1 sample enables meaningful leakage.
  3. **K selection matters**—K=10 optimal for COCO with ~15 tags/image; early retrieval captures most semantic signal (Figure 9).

- **Design tradeoffs:**
  - **Retrieval K vs. precision**: Larger K improves recall but introduces noise; ablation shows K=10 balances coverage and specificity.
  - **VLM choice for adaptive attacks**: GEMINI-FLASH outperforms GPT-5.1 and Qwen2.5-VL for scene graph inference (Figure 6), but all VLMs struggle with fine-grained relations.
  - **Open vs. closed victim embedders**: GEMINI achieves strongest alignment (Figure 3 top), but differences are minor—vulnerability is largely embedder-agnostic.

- **Failure signatures:**
  - **Exact match retrieval F1 < 0.25** (Figure 10): Do not optimize for exact tag recovery; neighborhood preservation is the correct signal.
  - **Rouge-L plateau with increasing K**: Indicates retrieval saturation; semantic information exhausted at current alignment quality.
  - **Cross-domain degradation but not collapse** (Table 2): Near-domain → out-domain shows ~3-5 point Rouge-L drop; if drop exceeds 10 points, check alignment sample diversity.

- **First 3 experiments:**
  1. **Reproduce alignment ablation**: Train local retriever on COCO train, compute W with varying sample counts (1, 10, 100, 1000, 10000), measure cosine similarity and Rouge-L against {C_gt} for a single victim embedder (e.g., CLIP). Verify monotonic improvement curve.
  2. **Probe neighborhood preservation**: For fixed K=30, vary m (5, 10, 20, 30, 50) and compute neighborhood F1 against both {t_gt} and {t_A}. Confirm saturation around m=50 and gap between ground-truth and attack-reference evaluations.
  3. **Single-stage vs. adaptive attack comparison**: Generate captions from retrieved tags alone vs. tags + low-fidelity image + VLM-inferred relations. Measure Rouge-L difference to quantify adaptive attack contribution (expected: ~2-5 point improvement from relations+scenes conditioning per Figure 7).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can semantic leakage be mitigated in image embeddings without significantly degrading their retrieval utility?
- Basis in paper: [explicit] The conclusion explicitly encourages "future work on mitigation at this level."
- Why unresolved: The paper characterizes leakage as intrinsic to the retrieval objective (neighborhood preservation), suggesting a fundamental trade-off.
- What evidence would resolve it: Novel training objectives or perturbations that decouple semantic inference from retrieval performance.

### Open Question 2
- Question: Are standard privacy-enhancing technologies, such as differential privacy or noise injection, robust against the SLImE attack framework?
- Basis in paper: [inferred] The paper demonstrates that lossy compression fails to prevent leakage but does not evaluate active defenses like differential privacy.
- Why unresolved: It is unclear if the noise required to obscure local semantic neighborhoods would destroy the embedding's utility.
- What evidence would resolve it: Empirical evaluation of SLImE on embeddings trained with differential privacy guarantees.

### Open Question 3
- Question: Does the vulnerability of neighborhood preservation generalize to temporal modalities like video embeddings?
- Basis in paper: [inferred] The study focuses on static images, but the theoretical basis relies on general retrieval properties common in multimodal systems.
- Why unresolved: Temporal dependencies in video might provide different semantic barriers or, conversely, more leakage vectors than static images.
- What evidence would resolve it: Application of the SLImE framework to video retrieval benchmarks.

## Limitations
- **Hyperparameter uncertainty**: Training hyperparameters for contrastive learning and ranker (learning rate, epochs, batch size, margin m, hard negative ratio ρ) are unspecified, potentially affecting reproducibility.
- **Evaluation scope**: The evaluation focuses primarily on COCO and limited cross-domain tests, leaving generalization to other visual domains uncertain.
- **Assumption of attacker access**: The study assumes attacker access to a local retriever training corpus overlapping with victim embeddings, which may not hold in all threat models.

## Confidence

- **High confidence:** The mechanism of linear alignment preserving local semantic neighborhoods (Mechanism 1) is well-supported by F1 metrics and geometric analysis. The effectiveness of retrieval as an inference mechanism (Mechanism 2) is validated through quantitative text reconstruction metrics.
- **Medium confidence:** The claim about cumulative distortion through lossy mappings (Mechanism 3) is conceptually sound but less directly quantified. The assertion that leakage is embedder-agnostic requires more extensive testing across diverse architectures.
- **Low confidence:** The generalizability claim to "any retrieval-optimized embedding" exceeds the empirical scope of tested models (four embedders, primarily CLIP variants).

## Next Checks
1. **Alignment stability test:** Evaluate cosine similarity and F1 metrics when alignment samples contain domain shift (e.g., align COCO-style embeddings to domain-specific victim embeddings like medical or satellite imagery). Measure performance degradation threshold.
2. **Defense ablation:** Implement and test a simple defense (e.g., random rotation of embedding space + secret key) against SLImE. Quantify whether neighborhood preservation can be disrupted without breaking retrieval utility.
3. **Model dependency analysis:** Replace the current LLM (DEEPSEEK-V3.2) and VLM (GEMINI-FLASH) with alternatives (e.g., GPT-4o, Qwen2.5-VL) while holding alignment and retrieval constant. Measure variation in Rouge-L and adaptive attack F1 scores to assess attack robustness to generative model choice.