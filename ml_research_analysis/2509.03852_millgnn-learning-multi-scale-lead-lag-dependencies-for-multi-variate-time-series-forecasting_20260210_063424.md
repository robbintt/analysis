---
ver: rpa2
title: 'MillGNN: Learning Multi-Scale Lead-Lag Dependencies for Multi-Variate Time
  Series Forecasting'
arxiv_id: '2509.03852'
source_url: https://arxiv.org/abs/2509.03852
tags:
- lead-lag
- time
- dependencies
- forecasting
- scale
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MillGNN is a graph neural network method for multivariate time
  series forecasting that learns multi-scale lead-lag dependencies. It addresses the
  challenge of capturing hierarchical lead-lag effects across individual variates
  and variate groups at different scales.
---

# MillGNN: Learning Multi-Scale Lead-Lag Dependencies for Multi-Variate Time Series Forecasting

## Quick Facts
- **arXiv ID:** 2509.03852
- **Source URL:** https://arxiv.org/abs/2509.03852
- **Reference count:** 40
- **Key result:** MillGNN achieves state-of-the-art MTS forecasting performance, outperforming 16 baselines on 11 datasets, with MSE of 0.373 on ETTm1 and 0.170 on Electricity.

## Executive Summary
MillGNN introduces a graph neural network framework designed to capture hierarchical lead-lag dependencies in multivariate time series forecasting. By integrating statistical rigor through FFT-based cross-correlation with dynamic learnable decay mechanisms, the model identifies and models time lags at multiple scales. The method outperforms existing approaches on long-term and short-term forecasting tasks while maintaining computational efficiency.

## Method Summary
MillGNN operates through a hierarchical grouping of variates based on DTW similarity, followed by scale-specific lead-lag graph learning and hierarchical message passing. The SiLL-GL module initializes graph topology using FFT-based cross-correlation and refines edge weights with Decay-Aware Attention. The HiLL-MP module then propagates information both within and across scales using an efficient duplication strategy. The model is trained end-to-end with Adam optimization and early stopping.

## Key Results
- Outperforms 16 state-of-the-art methods on 11 real-world datasets
- Achieves MSE of 0.373 on ETTm1 and 0.170 on Electricity
- Demonstrates superior performance for both long-term and short-term forecasting tasks
- Maintains efficient training with linear complexity in the number of variates

## Why This Works (Mechanism)

### Mechanism 1: Statistical-Dynamic Fusion for Lag Detection
Effective lead-lag modeling requires initializing dependencies with statistical rigor (FFT cross-correlation) before refining them with learnable temporal dynamics. The model first uses FFT-based cross-correlation to identify Top-K candidate lags efficiently, then applies Decay-Aware Attention to dynamically adjust edge strengths using excitatory and inhibitory embeddings. This assumes lag structure is stable but influence strength decays over time.

### Mechanism 2: Hierarchical Multi-Scale Grouping
Complex systems exhibit lead-lag dependencies at different granularities; modeling only individual variate relationships misses coarse-grained system-wide propagation. Variates are clustered into groups using DTW similarity, creating a hierarchy where each scale captures different temporal characteristics. This allows the model to capture both local fast-changing signals and global stable trends.

### Mechanism 3: Efficient Inter-Scale Message Duplication
Propagating information across scales can be computationally prohibitive unless constrained by structural sparsity. The HiLL-MP module uses duplication, assuming variates within a group share the aggregate lag characteristic of that group. This reduces complexity from O(N²) to O(1) for inter-scale passing while maintaining effectiveness.

## Foundational Learning

- **Concept: Fast Fourier Transform (FFT) for Cross-Correlation**
  - **Why needed here:** Used to initialize the graph topology efficiently
  - **Quick check question:** Why does the paper use FFT instead of standard sliding-window correlation to identify lags? (Answer: Complexity reduction from O(L²) to O(L log L))

- **Concept: Message Passing in Graph Neural Networks (GNNs)**
  - **Why needed here:** The core of the model is passing "lag messages" across the graph structure
  - **Quick check question:** In the context of this paper, what constitutes the "Message" and what constitutes the "Aggregation" strategy in the HiLL-MP module?

- **Concept: Attention Mechanisms with Decay (Exponential Kernels)**
  - **Why needed here:** The model injects a decay factor (e^(-βΔ)) to model how influence fades over time
  - **Quick check question:** How do the excitatory (β_e) and inhibitory (β_i) rates compete in Equation 9 to model the decay of influence?

## Architecture Onboarding

- **Component map:** Input -> Patching + DTW-based Clustering -> SiLL-GL (FFT Cross-Corr + Decay Attention) -> HiLL-MP (Intra-scale + Inter-scale Duplication) -> Flatten + Linear Head
- **Critical path:** The SiLL-GL module (Section 4.2) is the most complex novel component. Onboarding should focus on how Eq. 2 (FFT) feeds into Eq. 10 (Adjacency Matrix construction) and how learnable decay embeddings modify this.
- **Design tradeoffs:**
  - Clustering Algorithm: Spectral clustering yields better accuracy but is computationally heavy; K-Means offers better speed-accuracy trade-off for large datasets
  - Inter-Scale Passing: "Duplication" is faster and lighter but theoretically less expressive than "Learnable" or "Bi-direction" weighting
- **Failure signatures:**
  - Lag Drift: If validation loss improves but test performance is poor, check for "Lag Distribution Drift"
  - Over-smoothing: If the model predicts the mean of the group rather than specific variate behavior, the Duplication mechanism or patching length may be too coarse
- **First 3 experiments:**
  1. Scale Ablation: Run with only Scale 0 vs. Multi-Scale to verify performance gain of hierarchical grouping
  2. Topology Validation: Visualize learned lead-lag graph on known dataset to confirm identified lags match physical reality
  3. Efficiency Benchmark: Compare training throughput and GPU memory against Transformer baseline to validate linear complexity claims

## Open Questions the Paper Calls Out
1. How can the framework be extended to capture high-order lead-lag dependencies and remain robust to distributional data drifts?
2. Can the variate grouping strategy be made differentiable and end-to-end learnable, particularly using trend-seasonal characteristics?
3. Is there an adaptive mechanism to automatically determine the optimal number of grouping scales and candidate time lags?

## Limitations
- The stability of FFT-initialized graph topology under non-stationary lag distributions remains uncertain, as evidenced by degraded performance on ETTh2
- The scalability of DTW-based clustering for very large variate sets (hundreds of features) is not addressed, potentially limiting practical deployment
- The optimal balance between patch length and temporal resolution across scales is not explicitly derived

## Confidence
- **High confidence** in the multi-scale architecture's ability to capture hierarchical dependencies
- **Medium confidence** in the statistical-dynamic fusion approach for lag detection
- **Low confidence** in the practical scalability of the full method given computational intensity of DTW

## Next Checks
1. **Lag drift sensitivity test:** Systematically vary the temporal offset between training and test sets to quantify the model's robustness to non-stationarity
2. **Computational scaling analysis:** Benchmark DTW clustering time and memory usage as a function of variate count, comparing against approximate methods
3. **Hierarchy depth ablation:** Conduct controlled experiments varying the number of scales and patch length growth factors to identify optimal trade-off between model capacity and computational efficiency