---
ver: rpa2
title: 'DRAG: Distilling RAG for SLMs from LLMs to Transfer Knowledge and Mitigate
  Hallucination via Evidence and Graph-based Distillation'
arxiv_id: '2506.01954'
source_url: https://arxiv.org/abs/2506.01954
tags:
- evidence
- graph
- b-instruct
- arxiv
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DRAG is a novel framework that distills retrieval-augmented generation
  (RAG) capabilities from large language models (LLMs) into small language models
  (SLMs) using evidence- and knowledge graph-based distillation. The method transfers
  structured knowledge through ranked textual evidence and relational graphs, effectively
  reducing hallucinations while maintaining high factual accuracy.
---

# DRAG: Distilling RAG for SLMs from LLMs to Transfer Knowledge and Mitigate Hallucination via Evidence and Graph-based Distillation

## Quick Facts
- arXiv ID: 2506.01954
- Source URL: https://arxiv.org/abs/2506.01954
- Reference count: 30
- Primary result: DRAG improves SLM performance by up to 27.7% compared to prior RAG methods while reducing hallucinations and supporting privacy-preserving query processing.

## Executive Summary
DRAG is a novel framework designed to distill retrieval-augmented generation (RAG) capabilities from large language models (LLMs) into small language models (SLMs), enabling high-quality, factually consistent, and privacy-preserving retrieval-augmented generation in resource-constrained environments. The approach leverages both evidence- and knowledge graph-based distillation to transfer structured knowledge, improving SLM performance while mitigating hallucinations. Experiments demonstrate significant accuracy gains and robustness across multiple benchmarks, with DRAG approaching the performance of its LLM teacher models.

## Method Summary
DRAG transfers RAG capabilities from LLMs to SLMs by using two complementary distillation mechanisms: evidence-based and graph-based distillation. In evidence-based distillation, DRAG ranks and distills textual evidence retrieved by the LLM to inform the SLM. In graph-based distillation, relational knowledge is encoded into structured knowledge graphs and distilled into the SLM. This dual approach ensures that the SLM learns not only factual information but also the underlying relationships between concepts, enhancing both factual accuracy and robustness against hallucinations. DRAG also includes privacy-preserving query processing by filtering sensitive information before engaging cloud-based models.

## Key Results
- DRAG improves SLM performance by up to 27.7% compared to prior competitive RAG methods like MiniRAG.
- The method achieves factual accuracy close to that of teacher LLMs while significantly reducing hallucinations.
- DRAG enables privacy-preserving query processing by filtering sensitive information before cloud-based model engagement.

## Why This Works (Mechanism)
DRAG works by distilling both the explicit evidence and implicit knowledge graphs used by LLMs into SLMs, enabling the latter to replicate the reasoning and retrieval patterns of larger models. Evidence-based distillation transfers ranked, contextually relevant information, while graph-based distillation captures relational knowledge, ensuring that SLMs can reason over structured data and maintain factual consistency. This dual mechanism allows SLMs to access high-quality retrieval-augmented outputs without the computational overhead of LLMs, effectively bridging the performance gap while supporting privacy and efficiency.

## Foundational Learning
- **Knowledge Graph Distillation**: Needed to transfer structured, relational knowledge from LLMs to SLMs; quick check: verify graph integrity after distillation.
- **Evidence Ranking**: Essential for prioritizing relevant information during retrieval; quick check: confirm ranking accuracy with retrieval benchmarks.
- **Privacy-Preserving Query Processing**: Required to filter sensitive data before cloud engagement; quick check: validate privacy filters on sensitive datasets.
- **RAG Pipeline Optimization**: Critical for efficient retrieval and generation; quick check: benchmark retrieval latency and accuracy.
- **Hallucination Mitigation**: Necessary for maintaining factual consistency; quick check: compare hallucination rates pre- and post-distillation.
- **Model Distillation Techniques**: Foundational for transferring knowledge from large to small models; quick check: assess knowledge retention after distillation.

## Architecture Onboarding

**Component Map**: User Query -> Privacy Filter -> Evidence Retriever -> Knowledge Graph Generator -> SLM with Distilled RAG

**Critical Path**: Privacy Filter -> Evidence Retriever -> Knowledge Graph Generator -> SLM Inference

**Design Tradeoffs**: Balances model size and performance by distilling only essential RAG knowledge; prioritizes privacy and efficiency over exhaustive knowledge transfer.

**Failure Signatures**: Degraded accuracy if teacher LLM contains biases; scalability issues with very large knowledge graphs; privacy filter failures may expose sensitive data.

**First Experiments**:
1. Validate retrieval accuracy and hallucination reduction on standard RAG benchmarks.
2. Test privacy filter effectiveness by measuring information leakage on sensitive queries.
3. Benchmark computational efficiency and latency compared to baseline RAG methods.

## Open Questions the Paper Calls Out
None

## Limitations
- Potential dependence on the quality and biases of the LLM teacher model.
- Unclear scalability with very large knowledge graphs or highly diverse domains.
- Limited empirical validation of privacy benefits and computational overhead in extreme resource constraints.

## Confidence
- Performance gains (up to 27.7%): High
- Privacy preservation: Medium
- Computational efficiency: Medium

## Next Checks
1. Conduct ablation studies to isolate the contributions of evidence-based vs. graph-based distillation components to overall performance.
2. Evaluate DRAG's robustness when the LLM teacher model is replaced with models of varying sizes and quality to assess sensitivity to source model characteristics.
3. Test the method's scalability and accuracy retention on significantly larger knowledge graphs and more diverse, real-world datasets beyond the reported benchmarks.