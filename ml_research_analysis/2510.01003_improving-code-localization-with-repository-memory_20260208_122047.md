---
ver: rpa2
title: Improving Code Localization with Repository Memory
arxiv_id: '2510.01003'
source_url: https://arxiv.org/abs/2510.01003
tags:
- memory
- code
- migrations
- commit
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces repository memory to improve code localization\
  \ in large language model (LLM)-based agents. Current localization methods treat\
  \ each problem from scratch, ignoring the valuable historical context available\
  \ in a repository\u2019s commit history."
---

# Improving Code Localization with Repository Memory

## Quick Facts
- arXiv ID: 2510.01003
- Source URL: https://arxiv.org/abs/2510.01003
- Authors: Boshi Wang; Weijian Xu; Yunsheng Li; Mei Gao; Yujia Xie; Huan Sun; Dongdong Chen
- Reference count: 6
- Primary result: 4.9% improvement in code localization accuracy on SWE-bench-verified

## Executive Summary
This paper introduces repository memory to improve code localization in large language model (LLM)-based agents. Current localization methods treat each problem from scratch, ignoring the valuable historical context available in a repository's commit history. The authors propose two complementary memory components: an episodic memory that allows the agent to search and examine past commits and issues, and a semantic memory that summarizes the functionality of frequently edited files. Both memory stores are lightweight, easily integrated into existing frameworks, and designed to help agents emulate the knowledge and intuition of experienced developers. Experiments on SWE-bench-verified and SWE-bench-live show that integrating repository memory into the LocAgent framework improves localization accuracy by 4.9% (Acc@5 from 71.6% to 76.5%) and 1.6% (from 63.1% to 64.6%) respectively.

## Method Summary
The method integrates two memory modules into the LocAgent framework: episodic memory that retrieves and examines past commits using BM25 with LLM-based tokenization, and semantic memory that summarizes frequently edited files using LLM-generated descriptions. The episodic memory allows agents to search commit messages and examine patches and linked issues, while semantic memory provides functional summaries of top-200 most-edited files. Both are exposed as tools in the agent's action space, enabling targeted, hypothesis-driven investigation rather than exhaustive exploration. The approach uses GPT-4o as the backbone model and operates on heterogeneous code graphs constructed from repository structure.

## Key Results
- Repository memory improves Acc@5 from 71.6% to 76.5% on SWE-bench-verified (4.9% absolute improvement)
- Memory integration achieves 64.6% Acc@5 on SWE-bench-live, up from 63.1% (1.6% improvement)
- Episodic memory contributes more than semantic memory, with both components being complementary
- Agent behavior shifts from exhaustive graph traversal to targeted investigation using memory cues

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Episodic memory of past commits provides concrete exemplars that guide localization by anchoring new problems to historically similar solutions.
- Mechanism: BM25 search over commit messages retrieves relevant historical commits; agents examine patches and linked issues to form hypotheses about where similar bugs reside. This bypasses exhaustive code traversal by leveraging the repository's own problem-solution history.
- Core assumption: New issues exhibit patterns similar to past issues, and commit messages contain sufficient signal to retrieve relevant history.
- Evidence anchors:
  - [abstract]: "episodic memory that allows the agent to search and examine past commits and issues"
  - [section 3.1]: "SearchCommit(query, top_k)... returns a ranked list of the top-k relevant commits, including their unique IDs (commit SHAs), messages, and modified files"
  - [corpus]: Related work "From Knowledge to Noise: CTIM-Rover and the Pitfalls of Episodic Memory" explicitly warns episodic memory can introduce distraction, suggesting the mechanism is conditionally beneficial.
- Break condition: Repositories with sparse or irrelevant commit history yield low-quality retrieval; agents may be misled by noise rather than aided.

### Mechanism 2
- Claim: Semantic memory of actively edited files provides architectural priors that bias exploration toward development hotspots.
- Mechanism: Commit frequency analysis identifies top-k most-edited files; an LLM summarizes each file's functionality. Agents query these summaries to quickly understand module purpose without reading full source, focusing attention on dynamic code regions.
- Core assumption: Frequently modified files are more likely relevant to new issues; LLM summaries capture sufficient functional signal.
- Evidence anchors:
  - [abstract]: "semantic memory that summarizes the functionality of frequently edited files"
  - [section 3.2]: "files frequently modified in the recent past are 'development hotspots'â€”areas that are either central to the repository's functionality or are undergoing active change"
  - [corpus]: Weak direct corpus validation on semantic memory specifically; most related work focuses on episodic/experiential memory.
- Break condition: If relevant fix locations lie in stable, rarely-modified files, semantic memory provides no signal and may misdirect attention.

### Mechanism 3
- Claim: Integrating memory tools shifts agent strategy from exhaustive graph traversal to targeted, hypothesis-driven investigation.
- Mechanism: Memory tools expand the action space; agents retrieve historical or functional context first, then use structural tools (TraverseGraph, RetrieveEntity) to verify hypotheses. This reduces blind exploration and mirrors expert developer workflows.
- Core assumption: Agents can effectively combine high-level memory cues with low-level structural analysis; retrieved memory is relevant enough to form useful hypotheses.
- Evidence anchors:
  - [abstract]: "shifting agent behavior from exhaustive exploration to targeted, hypothesis-driven investigation"
  - [section 4.3, Figure 3]: "RepoMem significantly reduces its reliance on exhaustive exploration tools like TraverseGraph and direct code reading (RetrieveEntity)"
  - [corpus]: "Reformulate, Retrieve, Localize" paper supports multi-stage agentic localization but does not directly validate this strategic shift mechanism.
- Break condition: If memory retrieval returns irrelevant results, agents waste turns examining noise; cost increases without accuracy gains.

## Foundational Learning

- Concept: **BM25 sparse retrieval**
  - Why needed here: Episodic and semantic memory both use BM25 for matching queries against commit messages and file summaries. Understanding term frequency weighting and tokenization is critical for debugging retrieval quality.
  - Quick check question: Why would exact keyword matching outperform dense semantic embeddings for commit messages containing specific entity names like "MigrationWriter"?

- Concept: **Commit frequency analysis**
  - Why needed here: Semantic memory construction depends on identifying "hotspot" files via edit frequency. Without this, you cannot prioritize which files to summarize.
  - Quick check question: If a repository has 10,000 files but only 200 are frequently edited, how would you set the threshold for "active" files?

- Concept: **ReAct agent loop (Thought-Act-Observation)**
  - Why needed here: LocAgent operates on the ReAct framework; memory tools are integrated as additional actions. Understanding this loop is essential for tracing agent behavior and debugging tool selection.
  - Quick check question: In a ReAct loop, what happens if an agent receives an observation that contradicts its prior hypothesis?

## Architecture Onboarding

- Component map:
  Memory Construction Pipeline -> Memory Interfaces -> LocAgent Core -> Integration Layer

- Critical path:
  1. For a new issue, agent calls SearchCommit with keywords from bug description.
  2. Agent examines retrieved commits (ExamineCommit) to identify relevant files or patterns.
  3. Agent optionally calls SearchSummary or ViewSummary to understand module functionality.
  4. Agent uses LocAgent's structural tools to traverse from hypothesized entry points to exact error location.
  5. Agent outputs localized file list.

- Design tradeoffs:
  - **BM25 vs. dense retrieval**: Paper finds BM25 with LLM-based tokenizer outperforms dense embeddings (Table 4); dense retrieval may miss exact entity matches.
  - **Memory size vs. noise**: Using more commits/files increases coverage but introduces irrelevant entries that can distract agents.
  - **Cost vs. accuracy**: Memory adds overhead; per-example cost is highly variable (Figure 4), with savings on some tasks and overhead on others.

- Failure signatures:
  - **Low-history repositories**: Acc@5 drops in "others" group (Table 2) where commit history is sparse; memory provides little signal.
  - **Irrelevant retrieval**: If SearchCommit returns unrelated commits, agent reasoning can be polluted, leading to worse-than-baseline performance.
  - **Tokenizer mismatch**: Standard whitespace tokenization underperforms LLM-based tokenizer (Table 4); poor tokenization yields weak retrieval.

- First 3 experiments:
  1. **Ablate each memory component separately** (episodic-only, semantic-only) on a held-out subset of SWE-bench-verified to confirm individual contributions match Table 1.
  2. **Vary commit history depth** (e.g., 1K, 3K, 7K, 10K prior commits) on django repository to measure sensitivity to history richness.
  3. **Swap BM25 for dense retrieval** on commit messages and file summaries using GritLM-7B to replicate Table 4 and confirm sparse retrieval advantage.

## Open Questions the Paper Calls Out

- Can agents be trained to dynamically decide when to access repository memory versus relying on first-principles exploration?
  - Basis in paper: [explicit] The conclusion suggests future work should train agents to assess problem novelty, relying on memory only for issues related to past experiences to optimize cost-effectiveness.
  - Why unresolved: The current implementation always provides memory tools, leading to high variance in API costs where memory sometimes adds overhead without benefit.
  - What evidence would resolve it: A learned policy that selectively activates memory tools based on problem type, reducing average costs without compromising localization accuracy.

- How can memory retrieval interfaces better handle the "rigid vocabulary" of code entities where semantically similar terms are functionally distinct?
  - Basis in paper: [explicit] The analysis notes that dense retrieval underperforms compared to BM25 because functionally distinct code entities (e.g., `MigrationWriter` vs. `OperationWriter`) often appear semantically similar to embedding models.
  - Why unresolved: Current dense retrievers fail to capture the precise, rigid nature of code terminology, limiting the quality of episodic memory retrieval.
  - What evidence would resolve it: A hybrid or domain-specific retrieval method that outperforms the current BM25 baseline by effectively disambiguating functionally unique code entities.

- What mechanisms can prevent performance degradation when retrieved history is irrelevant or noisy?
  - Basis in paper: [explicit] The error analysis highlights that in repositories with sparse history, irrelevant retrieved information can "pollute" the reasoning context, causing the agent to perform worse than the baseline.
  - Why unresolved: The agent currently lacks the ability to filter out unhelpful context or ignore the memory store when retrieval confidence is low.
  - What evidence would resolve it: A filtering mechanism or robustness intervention that prevents performance drops in repositories with limited historical data.

## Limitations

- Episodic memory performance degrades significantly in repositories with sparse commit history, showing a 13.1% drop in accuracy on low-history repositories
- The exact implementation of the "LLM-based tokenizer" for BM25 is unspecified, making it difficult to reproduce the claimed performance advantage
- The semantic memory heuristic assumes frequently edited files are more relevant, which may misdirect agents when fixes lie in stable code regions

## Confidence

- **High confidence**: The integration approach and overall accuracy improvements on SWE-bench benchmarks are well-supported by quantitative results (4.9% and 1.6% improvements on verified and live splits).
- **Medium confidence**: The mechanism explaining how episodic memory guides localization through historical exemplars is plausible but relies on unvalidated assumptions about commit message quality and pattern similarity.
- **Medium confidence**: The semantic memory mechanism assumes frequently edited files are more likely to be relevant, but this is a heuristic that may misdirect agents when fixes lie in stable code regions.

## Next Checks

1. Conduct a controlled ablation study varying commit history depth (1K, 3K, 7K, 10K) on representative repositories to quantify sensitivity to history richness and identify minimum viable history size.
2. Implement the exact BM25 with LLM-based tokenizer (specifying which LLM tokenizer is used) and compare against both standard whitespace tokenization and dense retrieval baselines to validate the claimed retrieval advantages.
3. Design an error analysis protocol that categorizes localization failures into: (a) irrelevant memory retrieval, (b) insufficient historical patterns, (c) semantic memory misdirection, and (d) agent reasoning errors, to identify which failure modes dominate in different repository types.