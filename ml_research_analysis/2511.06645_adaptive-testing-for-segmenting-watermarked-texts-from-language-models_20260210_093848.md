---
ver: rpa2
title: Adaptive Testing for Segmenting Watermarked Texts From Language Models
arxiv_id: '2511.06645'
source_url: https://arxiv.org/abs/2511.06645
tags:
- setting
- prompt
- test
- change
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# Adaptive Testing for Segmenting Watermarked Texts From Language Models

## Quick Facts
- **arXiv ID:** 2511.06645
- **Source URL:** https://arxiv.org/abs/2511.06645
- **Authors:** Xingchi Li; Xiaochi Liu; Guanxun Li
- **Reference count:** 40
- **Key outcome:** Achieves Rand index > 0.9 for segmenting watermarked text across multiple attack scenarios

## Executive Summary
This paper introduces an adaptive testing framework for segmenting watermarked text from language models into watermarked and non-watermarked substrings. The method uses change-point detection on p-value sequences generated through randomization tests, allowing it to handle text modifications like insertion and substitution attacks. The framework works with both Exponential Minimum Sampling (EMS) and Inverse Transform Sampling (ITS) watermarking schemes, and notably removes the need for prompt estimation by using preceding tokens as local context. Experimental results demonstrate high accuracy in localizing watermark boundaries across various attack scenarios using Llama-3-8B and Mistral-7B models.

## Method Summary
The method segments partially watermarked text by computing adaptive test statistics between sliding windows and a watermark key, then generating p-value sequences via randomization tests. It employs a change-point detection algorithm (SeedBS-NOT) to identify boundaries between watermarked and non-watermarked segments. The framework estimates next-token probabilities using preceding tokens as local context, eliminating the need for prompt optimization. It handles both EMS and ITS watermarking schemes through likelihood ratio tests, with ITS requiring a robust variant using Huber's contamination model to tolerate misalignments. The approach uses sliding windows of size B and regularization parameter λ=0.5 for probability estimation.

## Key Results
- Achieves Rand index > 0.9 for segmenting watermarked text across insertion, substitution, and combined attack scenarios
- Removes dependency on prompt estimation by using preceding tokens as local context
- Extends to both EMS and ITS watermarking schemes with high detection accuracy
- Demonstrates effectiveness on both Llama-3-8B and Mistral-7B models

## Why This Works (Mechanism)

### Mechanism 1: Adaptive Weighting via Likelihood Ratios
- **Claim:** Assigning higher weights to tokens with lower next-token probabilities (NTPs) amplifies the detectability of watermarks.
- **Mechanism:** The method employs a log-likelihood ratio (LR) test statistic. Under watermarking schemes like Exponential Minimum Sampling (EMS), the log-likelihood for a token $y_i$ scales with $(1-p_i)/p_i$. By weighting tokens with small $p_i$ (low predictability) higher, the detector maximizes the signal from "surprising" tokens, which carry more information about the watermark key than high-probability tokens.
- **Core assumption:** The language model's probability distribution is accessible to the detector to compute $p_i$, and the watermark preserves the original distribution (unbiased watermarking).
- **Evidence anchors:**
  - [Section 3.1] "Tokens with smaller $p_i$ contribute more substantially... tokens with lower $p_i$ play a more critical role in distinguishing watermarked text."
  - [Corpus] "BiMarker" (neighbor paper) also notes that detection improves by moving beyond coarse estimates, aligning with the need for finer token-level analysis.
- **Break condition:** If the text is heavily edited such that the NTP estimates $q_i$ deviate significantly from true $p_i$, the weighting becomes noisy, potentially reducing detection power.

### Mechanism 2: Robust ITS Detection via Huber's Contamination Model
- **Claim:** The standard Likelihood Ratio test fails for Inverse Transform Sampling (ITS) in segmented text; a robust alternative using Huber's model restores functionality.
- **Mechanism:** In ITS, the standard LR is non-zero only if *every* token in a sequence aligns perfectly with the key—a fragile requirement. To fix this, the authors model the token distribution under the alternative hypothesis as a mixture (Huber's $\epsilon$-contamination): valid watermarked tokens plus uniform noise. This allows the test statistic to tolerate misalignments (edits) while still weighing low-probability tokens higher.
- **Core assumption:** A subset of tokens in the segment remains correlated with the watermark key despite edits.
- **Evidence anchors:**
  - [Section 3.2.2] "The overall likelihood ratio statistic... is equal to 0 otherwise... rendering it ineffective." The paper proposes the statistic in (11) to overcome this.
  - [Abstract] "Adapt this approach to the inverse transform sampling method."
- **Break condition:** If the "contamination" (edits) exceeds the tolerance threshold $\epsilon$ effectively breaking the correlation between the key $\xi$ and the token $y$ across the entire window.

### Mechanism 3: Localized Prompt-Free NTP Estimation
- **Claim:** Segmenting text and using preceding tokens as context removes the dependency on estimating the unknown original prompt.
- **Mechanism:** Standard detection requires the initial prompt $y_{-n_0:0}$ to calculate probabilities. This framework partitions text into small segments. For any segment at position $t$, the tokens in $t-1$ serve as the local context (prompt). Since the true prompt only affects the very first segment, initializing with an empty set allows the rest of the text to "bootstrap" its own context.
- **Core assumption:** The context window provided by the preceding segment is sufficient to approximate the conditional probability $p(y_i | \text{past})$ accurately.
- **Evidence anchors:**
  - [Section 4] "Our framework removes the need for precise prompt estimation... preceding tokens naturally serve as prompts."
  - [Section 5.1] Comparing "empty" vs "optim" methods to validate that prompt optimization is redundant.
- **Break condition:** Very short texts where the initial segment constitutes the majority of the content, or if the model's context window requirement exceeds the segment length.

## Foundational Learning

- **Concept: Unbiased Watermarking (EMS & ITS)**
  - **Why needed here:** The paper specifically targets "unbiased" schemes where the watermark does not degrade text quality. Understanding how $\xi$ (key) interacts with $\mu$ (distribution) to select token $y$ without changing $P(y)$ is essential.
  - **Quick check question:** How does Exponential Minimum Sampling ensure $P(y_i=k) = p_i(k)$ despite the modification?

- **Concept: Change Point Detection (Binary Segmentation)**
  - **Why needed here:** The segmentation task is framed as identifying points where the statistical properties of the text (specifically the p-value sequence) shift from "human" (uniform) to "watermarked" (concentrated near 0).
  - **Quick check question:** Why does the "Wild Binary Segmentation" or "Narrowest-Over-Threshold" (NOT) approach improve upon standard Binary Segmentation for multiple change points?

- **Concept: Randomization Testing**
  - **Why needed here:** The detector uses a randomization test to generate p-values. One must understand that the test compares the observed statistic against statistics generated with *dummy* keys to determine significance.
  - **Quick check question:** If the watermark key $\xi$ is independent of the text, what distribution should the test statistic follow under the Null Hypothesis?

## Architecture Onboarding

- **Component map:** Tokenizer & Segmenter -> Probability Estimator -> Statistic Calculator -> Randomization Engine -> Change Point Algorithm (SeedBS-NOT)
- **Critical path:** The accuracy of the **Probability Estimator** is the bottleneck. If the local context does not provide good NTPs, the adaptive weighting fails, and the p-values will not distinguish watermarked from non-watermarked segments.
- **Design tradeoffs:**
  - **Window Size ($B$):** A small $B$ localizes changes better but produces noisy p-values. A large $B$ stabilizes p-values but smears the change point location (edge effect). Paper suggests $B \approx 3n^{1/3}$.
  - **Statistic Choice:** EMS statistic is simpler; ITS statistic requires solving the optimization in (11) but is necessary for the ITS scheme.
- **Failure signatures:**
  - **High False Positives:** P-value sequence appears non-uniform in non-watermarked regions (often due to poor NTP estimation or model overfitting).
  - **Localization Drift:** Detected change points $\hat{\tau}$ lag behind true points due to large window size $B$.
- **First 3 experiments:**
  1. **Sanity Check (Null):** Run the detector on purely human text. Verify the output p-value sequence is uniformly distributed and no change points are detected.
  2. **Single Insertion Attack:** Generate 500 watermarked tokens, insert 250 human tokens in the middle. Verify the algorithm detects exactly 2 change points near the boundaries of the insertion.
  3. **Ablation on Context:** Compare the "Empty Prompt" method (using local context) against a "Blind" method (ignoring context) to quantify the performance gain from the prompt-free estimation strategy.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the segmentation framework be adapted to handle texts containing mixed watermarked content generated by different LLMs using distinct watermarking schemes?
- **Basis:** [explicit] The conclusion identifies this as an "important direction for future work," noting the challenge of segmenting text into substrings attributable to different LLMs with distinct key sequences.
- **Why unresolved:** The current binary segmentation approach assumes a single source of watermarking; mixing schemes requires aggregating and analyzing results from multiple distinct detection processes simultaneously.
- **What evidence would resolve it:** An algorithm capable of identifying multiple change points associated with different LLM sources within a single document.

### Open Question 2
- **Question:** What is the theoretically optimal strategy for selecting the window size $B$ to minimize edge effects while maintaining statistical power?
- **Basis:** [explicit] Appendix D discusses the trade-off regarding the window size $B$ and explicitly states that "A more thorough investigation of the choice of $B$ is deferred to future research."
- **Why unresolved:** Selecting $B$ involves a trade-off where small windows reduce localization error (edge effects) but may lack sufficient tokens for reliable detection, whereas large windows do the opposite.
- **What evidence would resolve it:** A theoretical derivation or comprehensive empirical study establishing the optimal relationship between $B$, text length $n$, and watermark strength.

### Open Question 3
- **Question:** How sensitive is the detection accuracy to the choice of the shrinkage parameter $\lambda$ used to regularize estimated next-token probabilities?
- **Basis:** [inferred] The method fixes the shrinkage parameter at $\lambda = 0.5$ (Equation 16) to handle small estimated NTPs, but provides no analysis on how this specific value impacts performance.
- **Why unresolved:** If $\lambda$ is chosen poorly, the regularization might either fail to stabilize the test statistic or overly dampen the signal from low-probability tokens.
- **What evidence would resolve it:** A sensitivity analysis showing the variation in Rand Index and p-value quality across a range of $\lambda$ values.

## Limitations

- **Experimental scope limited to simulated attacks:** The evaluation relies on controlled insertion and substitution scenarios using C4 prompts, not naturally occurring mixed AI-human text.
- **Computationally expensive randomization tests:** The method requires 99 dummy keys per window, creating potential scalability issues for large-scale applications.
- **Requires access to the generating LLM:** The framework assumes availability of the exact language model for accurate next-token probability estimation, which may not be practical for unknown or proprietary models.

## Confidence

- **High Confidence:** The theoretical justification for adaptive weighting using likelihood ratios under EMS watermarking.
- **Medium Confidence:** The extension to ITS watermarking using Huber's contamination model.
- **Low Confidence:** The prompt-free estimation approach's effectiveness across diverse text types.

## Next Checks

1. **Runtime Performance Analysis:** Measure the wall-clock time for the full detection pipeline (including randomization tests) on texts of varying lengths. Compare against baseline methods and assess whether the computational overhead is acceptable for practical deployment.

2. **Cross-Model Generalization Test:** Evaluate the detector on watermarked text generated by a different LLM than the one used for NTP estimation. For example, generate text with Llama-3 but perform detection using Mistral's probability estimates.

3. **Real-World Data Validation:** Apply the segmentation method to naturally occurring mixed AI-human text samples (e.g., edited LLM outputs, collaborative writing) rather than simulated insertion attacks. Compare the detected segments against human annotations to assess practical utility.