---
ver: rpa2
title: 'CATCH: A Novel Data Synthesis Framework for High Therapy Fidelity and Memory-Driven
  Planning Chain of Thought in AI Counseling'
arxiv_id: '2509.25733'
source_url: https://arxiv.org/abs/2509.25733
tags:
- client
- counselor
- counseling
- dialogue
- goal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CATCH addresses low therapy fidelity and lack of decision-making
  transparency in AI counseling by proposing a Progressive Dialogue Synthesis (PDS)
  strategy and a Memory-driven Dynamic Planning (MDP) Chain-of-Thought (CoT) framework.
  PDS incrementally generates stage-aligned counseling dialogues from client self-reports,
  while MDP explicitly models counselor reasoning through a collaborative multi-agent
  system.
---

# CATCH: A Novel Data Synthesis Framework for High Therapy Fidelity and Memory-Driven Planning Chain of Thought in AI Counseling

## Quick Facts
- arXiv ID: 2509.25733
- Source URL: https://arxiv.org/abs/2509.25733
- Authors: Mingyu Chen; Jingkai Lin; Zhaojie Chu; Xiaofen Xing; Yirong Chen; Xiangmin Xu
- Reference count: 40
- Primary result: Achieves 91.7% accuracy in goal identification and 87.1% in working stage identification using Progressive Dialogue Synthesis and Memory-driven Dynamic Planning Chain-of-Thought framework

## Executive Summary
CATCH addresses low therapy fidelity and lack of transparency in AI counseling by proposing a two-part framework: Progressive Dialogue Synthesis (PDS) and Memory-driven Dynamic Planning (MDP) Chain-of-Thought. PDS incrementally generates stage-aligned counseling dialogues from client self-reports, ensuring adherence to Single-Session Therapy protocol. MDP explicitly models counselor reasoning through a collaborative multi-agent system, producing interpretable thought chains. Human evaluations demonstrate CATCH outperforms baselines in goal identification, working stage accuracy, and SST-specific skills like solution focus and resource activation.

## Method Summary
CATCH synthesizes high-fidelity counseling dialogues through a pipeline combining PDS and MDP-CoT. PDS extracts goals, resources, and solutions from client self-reports, then incrementally generates stage-aligned dialogues (goal identification → working → ending). Data is filtered for therapeutic structure and jargon using DeepSeek-R1 and keyword matching. MDP-CoT employs three generative agents (Memory Capture, Global Planning, Strategy Reasoning) with checking agents for consistency, producing first-person thought chains. The resulting dataset (233 dialogues, 6,898 MDP-CoT responses) fine-tunes Qwen3-8B/14B with LoRA, placing SST knowledge in system prompts and training to predict concatenated [MDP-CoT, response] given [SST knowledge, dialogue history].

## Key Results
- Achieves 91.7% accuracy in goal identification and 87.1% accuracy in working stage identification
- Outperforms one-time generation baselines across therapeutic implementation effectiveness (GIS: 95% vs 5%, WS: 88% vs 12%, ES: 78% vs 22%)
- MDP-CoT ablation shows significant performance drops across all SST metrics (e.g., Goal Orientation: 4.30 → 4.16 without MDP)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Incremental stage-aligned dialogue synthesis improves therapy fidelity by enforcing structured therapeutic progression
- Mechanism: PDS decomposes generation into discrete SST stages, extracting goals/resources/solutions before generation to constrain protocol adherence
- Core assumption: Protocol deviation causes therapy drift; structured stages prevent this
- Evidence anchors: Expert evaluation shows PDS outperforms one-time generation (GIS: 95% vs 5%, WS: 88% vs 12%, ES: 78% vs 22%); related work uses staged decomposition for CBT
- Break condition: If therapy protocol is ill-defined or stages are not empirically validated, PDS may enforce inappropriate structure

### Mechanism 2
- Claim: Explicit turn-level reasoning chains (MDP-CoT) enable models to internalize therapeutic decision-making logic
- Mechanism: MDP decomposes counselor cognition into Memory, Planning, and Strategy modules with multi-agent verification before fusion
- Core assumption: Counselor reasoning can be modularly decomposed and learned from explicit traces
- Evidence anchors: MDP ablation causes performance drops across all SST metrics; Psy-Copilot visualizes CoT but doesn't train models
- Break condition: If reasoning traces are noisy or verification agents are poorly calibrated, MDP-CoT may introduce inconsistency

### Mechanism 3
- Claim: Data quality filtering and jargon reduction improve real-world applicability by ensuring naturalistic language
- Mechanism: DeepSeek-R1 assesses therapeutic structure and goal focus via majority voting; keyword matching flags over-technical language
- Core assumption: Natural language correlates with client engagement; technical jargon reduces therapeutic alliance
- Evidence anchors: DeepSeek-R1 used for structure assessment; keyword matching identifies specialized terms; no direct evidence linking jargon to outcomes
- Break condition: If filtering criteria are too strict, dataset diversity may be reduced; if too loose, low-quality samples persist

## Foundational Learning

- Concept: **Treatment Fidelity**
  - Why needed here: Core problem is low therapy fidelity; essential to evaluate whether PDS improves protocol adherence
  - Quick check question: Can you define treatment fidelity and distinguish it from therapeutic outcome?

- Concept: **Single-Session Therapy (SST) Protocol**
  - Why needed here: CATCH implements SST specifically; understanding three-stage structure is required to interpret design and metrics
  - Quick check question: What are the three stages of SST and what happens in each?

- Concept: **Multi-Agent Verification**
  - Why needed here: MDP-CoT synthesis relies on checking agents; necessary to debug CoT generation failures
  - Quick check question: What does a checking agent do when it detects a contradiction?

## Architecture Onboarding

- Component map: Client Self-Report → [PDS: Goal/Resource/Solution Extraction] → Stage Outlines → [PDS: Stage-wise Dialogue Generation] → [Data Filtering: Structure + Jargon] → [MDP: Memory → Planning → Strategy Agents] → [Checking Agents ×3] → [Fusion Agent] → Final Dialogue + MDP-CoT → SFT Training

- Critical path:
  1. Goal extraction from self-report (if this fails, downstream stages are misaligned)
  2. Resource-to-solution mapping (determines actionability of working stage)
  3. MDP memory capture accuracy (propagates errors to planning and strategy)

- Design tradeoffs:
  - **PDS vs. one-time generation**: Higher fidelity but higher computational cost (multiple LLM calls per dialogue)
  - **Multi-agent MDP vs. single-agent CoT**: Better consistency but more complex pipeline with more failure points
  - **Dataset scale (233 dialogues)**: High quality but limited diversity; may not generalize across populations

- Failure signatures:
  - **Therapy drift**: Model deviates from stage structure mid-dialogue → check MDP global planning outputs for stage misclassification
  - **Jargon overuse**: Responses contain technical terms → verify keyword filtering logs for missed flags
  - **Inconsistent memory**: Counselor forgets earlier client information → inspect Memory Capture Agent outputs for extraction gaps

- First 3 experiments:
  1. Replicate PDS vs. one-time generation comparison on held-out case set to validate stage fidelity improvements
  2. Ablate each MDP component (Memory/Planning/Strategy) independently to isolate contribution of each module
  3. Evaluate trained model on negative-attitude clients specifically to assess robustness

## Open Questions the Paper Calls Out
None

## Limitations
- Limited dataset scale: 233 dialogues may not capture full SST variability across populations, potentially limiting generalizability
- Absence of direct jargon filtering validation: Paper assumes jargon reduction improves outcomes but provides no empirical evidence linking technical language to therapeutic alliance or client engagement
- SST-specific design: Framework tailored to SST protocol; applicability to longer-term therapies or different counseling modalities untested

## Confidence
- **High**: PDS effectiveness (stage alignment improvements validated by expert evaluation), MDP-CoT architecture implementation
- **Medium**: Data filtering quality impact, generalizability beyond SST protocol
- **Low**: Direct causal link between jargon reduction and therapeutic outcomes, long-term model behavior with unseen client profiles

## Next Checks
1. Test CATCH on extended counseling sessions (multiple sessions) to evaluate framework adaptability beyond SST protocol
2. Conduct user studies measuring client engagement and satisfaction with jargon-reduced vs. technical responses
3. Scale dataset to 1000+ dialogues and measure performance degradation/gains to assess current dataset adequacy