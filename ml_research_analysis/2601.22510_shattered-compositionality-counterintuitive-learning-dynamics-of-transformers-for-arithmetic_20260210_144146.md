---
ver: rpa2
title: 'Shattered Compositionality: Counterintuitive Learning Dynamics of Transformers
  for Arithmetic'
arxiv_id: '2601.22510'
source_url: https://arxiv.org/abs/2601.22510
tags:
- digit
- training
- learning
- digits
- error
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper reveals that transformers acquire compositional arithmetic\
  \ skills in non-human learning orders\u2014often starting from higher digits and\
  \ progressing downward, or learning in parallel\u2014contrary to sequential human\
  \ rules. These counterintuitive trajectories lead to \"shattered compositionality,\"\
  \ where partial skill acquisition and competition cause brittle, mixing errors that\
  \ worsen under distribution shifts."
---

# Shattered Compositionality: Counterintuitive Learning Dynamics of Transformers for Transformers

## Quick Facts
- arXiv ID: 2601.22510
- Source URL: https://arxiv.org/abs/2601.22510
- Authors: Xingyu Zhao; Darsh Sharma; Rheeya Uppaal; Yiqiao Zhong
- Reference count: 40
- Primary result: Transformers acquire arithmetic subskills in reverse or parallel order (not human-like sequential), driven by correlational matching to training data, leading to brittle mixing errors under distribution shifts.

## Executive Summary
Transformers trained on arithmetic tasks learn compositional skills in counterintuitive orders—often mastering higher digits before lower ones, or acquiring multiple subskills in parallel—contrary to human procedural rules. This "shattered compositionality" arises from the model matching correlational patterns in training data rather than discovering procedural structure. The result is brittle behavior: partial skill acquisition and competition between subskills cause mixing errors that worsen under distribution shifts. Scaling and scratchpad-based reasoning do not mitigate this phenomenon.

## Method Summary
The authors train transformers on synthetic arithmetic tasks (4-operand addition, multiplication, comparison, sorting) using character-level tokenization and autoregressive cross-entropy loss. They use NanoGPT architecture (6-layer, 6-head, 384-dim) and scale to 20M/100M/1B parameters. Learning dynamics are tracked via digit-wise error rates, mutual information metrics (MI and conditional MI), and ablations (randomizing digits). They test both plain and reverse output formats and evaluate under distribution shifts (contrast pairs, extended clauses).

## Key Results
- Transformers learn arithmetic skills in reverse order (thousands before units) or in parallel, not human-like sequential order.
- Higher-digit skills are prerequisites for lower-digit learning; ablating higher digits blocks downstream acquisition.
- Parallel skill acquisition causes transient competition, yielding mixing errors (swapping/repeating terms) that worsen under distribution shifts.
- Shattered compositionality persists in larger models and scratchpad formats; scaling does not fix it.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Transformers acquire arithmetic subskills in reverse or parallel order because learning is driven by correlational matching to training data statistics, not procedural rule discovery.
- **Mechanism:** Gradient descent finds input-output correlations with the strongest mutual information first. For addition, I(a₁; e₀) > 0 (highest digit correlation) is nonzero and available early, while I(aᵢ; eⱼ) = 0 for most lower-place pairs. Once a higher-place skill is acquired (e.g., carry cᵢ₋₁), conditional MI I(aᵢ; eᵢ | cᵢ₋₁) becomes nonzero, enabling the next skill downstream. This creates a cascading dependency that often runs backward from human procedural order.
- **Core assumption:** The model does not discover latent procedural structure; it mirrors the correlational statistics accessible at each training stage.
- **Evidence anchors:**
  - [abstract]: "correlational matching to the training data, rather than causal or procedural composition, shapes learning dynamics"
  - [Section 5, Theorem 5.1]: Proves I(a₁; e₀) > 0 and I(aᵢ; eⱼ) = 0 for j > 0 under uniform sampling, with conditional MI I(aᵢ; eᵢ | cᵢ₋₁) > 0
  - [Figure 7]: Sharp loss descents occur exactly when model MI metrics match training-data MI baselines
  - [corpus]: Weak direct corpus support; neighbor papers discuss compositionality but not this specific correlational-matching mechanism
- **Break condition:** If training data were explicitly structured to make lower-digit correlations stronger and earlier (e.g., highly imbalanced digit distributions), the reverse-order pattern may weaken or invert.

### Mechanism 2
- **Claim:** Parallel acquisition of multiple subskills creates transient competition, yielding mixing errors where partial behaviors recombine incorrectly.
- **Mechanism:** When two skills (e.g., "compare digits" vs. "detect equality") are learned concurrently, their gradient signals can oppose each other. During the competition window, the model may apply fragments of one skill when another is appropriate. This produces errors like swapping digit fragments between numbers in sorting or missing/repeating terms in multi-operand addition.
- **Core assumption:** Skills are not learned as monolithic procedures but as overlapping pattern-matching circuits that can interfere before resolving.
- **Evidence anchors:**
  - [Section 4.3, Figure 5]: Comparison task shows non-monotone error at thousands-place when learning "=" temporarily interferes with digit comparison
  - [Section 4.4, Table 3]: Conflicting skill pairs yield significantly higher mixing errors (6.63%) than agreeing pairs (3.61%)
  - [Section 6, Figure 8]: LLMs on GSM8K with added clauses show missing/repeated terms in summation—analogs of mixing errors
  - [corpus]: Limited; neighbor papers on adversarial compositionality touch on error modes but not this specific competition mechanism
- **Break condition:** If subskills are curriculum-separated (trained sequentially with isolation), competition-induced mixing errors should reduce, though this does not fix the underlying correlational matching issue.

### Mechanism 3
- **Claim:** Higher-digit skills are prerequisites for lower-digit learning; ablating them blocks downstream acquisition.
- **Mechanism:** The model's reverse-order learning is not merely a preference but a structural dependency. When the thousands-place signal is destroyed (randomized), the model cannot ground the conditional correlations needed for lower places, and they fail to learn even after 400K steps. This suggests the model uses acquired higher-digit representations as conditioning context for lower-digit prediction.
- **Core assumption:** The cascading MI structure (I(aᵢ; eᵢ | cᵢ₋₁)) means higher-digit skills must be partially learned before lower-digit signals become actionable.
- **Evidence anchors:**
  - [Section 4.1, Figure 3]: Randomizing thousands-place digits causes all lower digits to fail to learn (error rates at random baseline)
  - [Section C.1.5, Figure 14-15]: Ablation results show asymmetric dependency—higher digits are critical, lower digits are not
  - [corpus]: No direct corpus support for this specific ablation finding
- **Break condition:** If the task is reformulated so that lower-digit predictions do not depend on higher-digit conditioning (e.g., explicit carry as input token), the dependency chain may break.

## Foundational Learning
- **Concept: Mutual Information (MI) and Conditional MI**
  - **Why needed here:** The paper uses MI I(X; Y) and conditional MI I(X; Y | Z) to quantify correlational structure in training data and track when the model internalizes each signal.
  - **Quick check question:** If I(a₁; e₀) = 0 in your data distribution, would you expect the model to still learn the thousands-place first? (No—absent correlation, no learnable signal.)

- **Concept: Distribution Shift**
  - **Why needed here:** Shattered compositionality is most visible under distribution shifts (e.g., contrast pairs in comparison, extended clauses in GSM8K), where mixing errors spike.
  - **Quick check question:** If your test distribution exactly matches training, will mixing errors be visible? (Likely minimal; they surface when the model's brittle composition is stressed.)

- **Concept: Autoregressive Training**
  - **Why needed here:** The reverse output format was intended to align autoregressive generation with human addition order (units first), yet the model still learned in reverse, showing that autoregressive factorization alone does not override correlational structure.
  - **Quick check question:** If you reverse the output token order, does that guarantee the model will learn in that order? (No—the paper shows it does not.)

## Architecture Onboarding
- **Component map:**
  - NanoGPT (6-layer, 6-head, 384-dim) as default; scaled to 20M/100M and Pythia-1B for robustness checks
  - Digit-wise tokenization: each character is a separate token
  - Autoregressive cross-entropy loss over output tokens
  - MI metrics computed from softmax distributions at each output position

- **Critical path:**
  1. Generate synthetic task data with controlled correlational structure (e.g., uniform vs. balanced sampling)
  2. Track digit-wise error rates across training steps to identify learning order
  3. Compute dataset MI baselines and model MI estimates; identify alignment points
  4. Run ablations (randomize digits) to test dependency hypotheses
  5. Test under distribution shift (contrast pairs, extended clauses) to surface mixing errors

- **Design tradeoffs:**
  - Uniform sampling: simpler but underrepresents "hard" examples (e.g., numbers differing only in low digits)
  - Balanced/doubly-balanced sampling: ensures coverage of NCID groups but may alter correlational structure
  - Scratchpad formats: accelerate convergence but do not fix reverse order; format-sensitive

- **Failure signatures:**
  - Reverse-order learning: thousands-place error drops first, units-place last or never
  - Mixing errors: swapping/repeating digits in sorting; missing/repeating terms in addition
  - Stalled learning: ablated high-digit conditions leave lower-digit error at random baseline indefinitely

- **First 3 experiments:**
  1. **Replicate addition learning curves** (plain and reverse format) on NanoGPT; verify reverse-order pattern and identify critical training steps for each digit.
  2. **Run MI alignment analysis**: compute I(a₁; e₀) and I(aᵢ; eᵢ | cᵢ₋₁) from data; track model MI across training; confirm sharp loss drops coincide with MI matching.
  3. **Ablation test**: randomize thousands-place in training data; confirm lower digits fail to learn (error rates at baseline), validating the dependency hypothesis.

## Open Questions the Paper Calls Out
- **Question:** Can reinforcement learning or alternative training paradigms (beyond autoregressive training) overcome shattered compositionality and enforce human-like learning orders?
  - **Basis in paper:** [explicit] Section 8 states: "We are also interested in going beyond autoregressive training and studying the effects of the reinforcement learning, and propose methods to mitigate the brittleness of shattered compositions."
  - **Why unresolved:** All experiments use standard autoregressive training; the paper only analyzes this paradigm and does not test RL-based training methods.
  - **What evidence would resolve it:** Train transformers on arithmetic tasks using RL fine-tuning (e.g., RLHF-style) and track whether subskills are acquired in human-like sequential order rather than reverse or parallel.

- **Question:** Does shattered compositionality manifest in non-arithmetic compositional domains such as logical reasoning, multi-hop QA, or code generation?
  - **Basis in paper:** [explicit] Impact Statement: "our results should be validated across broader task domains and model families before being used to inform policy or deployment decisions."
  - **Why unresolved:** The paper studies only synthetic arithmetic tasks (addition, multiplication, comparison, sorting) and provides limited validation on GSM8K.
  - **What evidence would resolve it:** Design analogous fine-grained subskill decomposition for tasks like syllogistic reasoning or multi-step code completion, then track learning dynamics to identify parallel/reverse learning or mixing errors under distribution shift.

- **Question:** What training interventions or data curriculum strategies can reliably enforce human-like compositional learning orders in transformers?
  - **Basis in paper:** [inferred] The paper shows scratchpads are highly format-sensitive (Section 7) and pure scaling does not fix shattered compositionality (Figure 9), leaving the mitigation problem open.
  - **Why unresolved:** Neither model scaling (10M→100M→1B) nor scratchpad reasoning formats consistently restore sequential learning; the paper does not propose successful interventions.
  - **What evidence would resolve it:** Test curriculum learning strategies that progressively mask correlational signals for higher digits, or modify loss functions to penalize learning higher-place skills before lower-place skills, and evaluate whether this yields human-like learning order.

## Limitations
- The mechanistic claims rely heavily on correlational-matching assumptions without direct causal intervention studies beyond ablation.
- Corpus support for key mechanisms (correlational matching, competition-induced mixing) is minimal, with only indirect or neighboring literature references.
- The analysis assumes uniform sampling is the natural baseline, but real-world data distributions often deviate.
- The reverse-order learning pattern is robust across scales but its underlying cause (correlational matching vs. architectural bias) remains debated.

## Confidence
- **High confidence:** Observed reverse-order learning patterns, ablation dependency results, and MI alignment evidence are empirically strong and reproducible.
- **Medium confidence:** The correlational-matching mechanism and competition-induced mixing errors are well-supported by data but lack direct causal validation beyond ablation studies.
- **Low confidence:** Claims about shattered compositionality being irreducible to scaling or scratchpad formats are based on limited experimental scope and require broader validation.

## Next Checks
1. **Causal Intervention Study:** Design an experiment that explicitly controls correlational structure (e.g., curriculum training that forces lower-digit skills first) to test whether reverse-order learning is truly driven by MI availability rather than architectural bias.
2. **Cross-Domain Replication:** Apply the same MI and ablation methodology to non-arithmetic compositional tasks (e.g., symbolic reasoning or language tasks) to test whether shattered compositionality generalizes beyond arithmetic.
3. **Real-World Data Analysis:** Train transformers on naturally occurring compositional datasets (e.g., code completion or mathematical word problems) and measure whether shattered compositionality and reverse-order learning patterns persist under realistic data distributions.