---
ver: rpa2
title: 'Agentic AI and Multiagentic: Are We Reinventing the Wheel?'
arxiv_id: '2506.01463'
source_url: https://arxiv.org/abs/2506.01463
tags:
- agents
- agent
- systems
- agentic
- these
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper argues that terms like "Agentic AI" and "Multiagentic
  AI" are often misused buzzwords for well-established concepts in AI: intelligent
  agents and multi-agent systems. The author reviews decades of research on agent
  architectures (reactive, deliberative, hybrid, BDI), properties (autonomy, reactivity,
  proactivity, social capability), and frameworks (FIPA standards, KQML, etc.).'
---

# Agentic AI and Multiagentic: Are We Reinventing the Wheel?

## Quick Facts
- arXiv ID: 2506.01463
- Source URL: https://arxiv.org/abs/2506.01463
- Authors: V. Botti
- Reference count: 26
- Primary result: Terms like "Agentic AI" and "Multiagentic AI" are buzzwords for established intelligent agents and multi-agent systems concepts.

## Executive Summary
This paper argues that modern terminology around "Agentic AI" and "Multiagentic AI" represents a rebranding of well-established concepts from decades of intelligent agent and multi-agent systems (MAS) research. The author demonstrates that current LLM-based autonomous agents and multi-agent frameworks functionally implement classical agent architectures (reactive, deliberative, hybrid, BDI) rather than introducing fundamentally new paradigms. By surveying the historical development of agent theory, communication standards, and coordination algorithms, the paper advocates for precise terminology and leveraging existing MAS knowledge to avoid reinventing solutions to coordination, communication, and agreement problems.

## Method Summary
The paper conducts a comprehensive literature review spanning 26 references, tracing the evolution of intelligent agent theory from foundational definitions through various architectural approaches to modern LLM-based implementations. The methodology involves conceptual mapping between classical MAS concepts (agent properties, BDI architecture, FIPA standards, agreement technologies) and current "Agentic AI" frameworks, identifying functional equivalences rather than novel innovations. No quantitative experiments are performed; the analysis is conceptual and historical.

## Key Results
- Modern LLM-based "agentic" systems functionally implement classical intelligent agent architectures without fundamental innovation
- Multi-agent coordination problems in LLM systems are isomorphic to classical MAS coordination challenges
- Terminological precision enables knowledge transfer from established MAS research to current implementations

## Why This Works (Mechanism)

### Mechanism 1
Modern LLM-based "agentic" systems functionally implement classical intelligent agent architectures, not novel paradigms. LLMs provide flexible reasoning that serves as the decision-making component within the traditional perceive-think-act cycle, while the surrounding architecture remains structurally identical to 1990s agent designs. This equivalence means existing MAS solutions to coordination, communication, and safety transfer directly to LLM-based systems.

### Mechanism 2
Multi-agent coordination problems in LLM systems are isomorphic to classical MAS coordination, making existing algorithms applicable. When multiple LLM agents interact, they face task allocation, consensus, and conflict resolution problems that MAS research addressed through auction mechanisms, negotiation protocols, and argumentation frameworks. These formal methods reduce coordination failures compared to ad-hoc natural language exchanges.

### Mechanism 3
Terminological precision accelerates progress by enabling knowledge transfer from decades of agent research. Using established terms (intelligent agent, multi-agent system, BDI, FIPA-ACL) connects practitioners to existing solutions for communication standards, safety frameworks, and coordination algorithms. Buzzword proliferation creates silos where known problems are re-solved inefficiently.

## Foundational Learning

- **Intelligent Agent Properties** (autonomy, reactivity, proactivity, social capability): These four properties define whether a system qualifies as an "agent" versus a program. Understanding them prevents misclassifying simple LLM wrappers as agentic systems. Quick check: Does your system initiate actions without explicit user prompts (proactivity) and interact with other agents through defined protocols (social capability)?

- **BDI Architecture** (Beliefs-Desires-Intentions): BDI provides a structured mental-state model for deliberative agents. Many LLM-based "planning" agents implicitly implement BDI cycles without recognizing it. Quick check: Can you identify where your agent maintains beliefs (world state), filters desires (goal prioritization), and commits to intentions (persistent plans)?

- **Agreement Technologies** (negotiation, argumentation, trust, reputation): Multi-agent systems require mechanisms for reaching and enforcing agreements. These become critical when LLM agents must coordinate without human intervention. Quick check: How do your agents resolve conflicting goals or resource disputes—through ad-hoc prompts or formal negotiation/argumentation protocols?

## Architecture Onboarding

- **Component map**: Perception layer (sensors/APIs → belief update) → Deliberation layer (LLM reasoning → option generation + intention filtering) → Action layer (tool/API execution → environment modification) → Communication layer (inter-agent messaging) → Coordination layer (task allocation, consensus, conflict resolution)

- **Critical path**: Define agent boundaries → specify communication protocol → implement deliberation cycle (perceive-update-beliefs-generate-options-filter-intentions-act) → add coordination mechanisms for multi-agent scenarios

- **Design tradeoffs**: Reactive vs. deliberative (speed vs. strategic foresight); natural language vs. structured protocols (flexibility vs. reliability); single monolithic agent vs. specialized multi-agent (simplicity vs. modularity)

- **Failure signatures**: Infinite loops in multi-agent conversations; goal drift; communication failures from ambiguous natural language; lack of commitment to intentions

- **First 3 experiments**:
  1. Implement a single BDI-structured agent with explicit belief, desire, and intention data structures; compare behavior to an ad-hoc LLM agent
  2. Build a two-agent coordination scenario; test natural language vs. speech-act-inspired message formats for task handoff reliability
  3. Introduce a conflict scenario; implement a simple auction-based allocation mechanism and measure resolution success vs. unstructured negotiation

## Open Questions the Paper Calls Out

### Open Question 1
Can the operational logic of LLM-based autonomous agents be formally mapped to classical Belief-Desire-Intention (BDI) architectures? While functional similarities exist, the internal "black box" reasoning of LLMs lacks the explicit, formal data structures defined in classic BDI models. Resolution would require formal architectural analysis demonstrating that specific prompting strategies functionally replicate the BDI deliberation loop.

### Open Question 2
Do structured Agent Communication Languages (ACLs) provide superior reliability compared to ad-hoc natural language in multi-LLM systems? Current inter-agent communication is ad-hoc natural language, but speech-act-based communication protocols from the 1990s could reduce misunderstandings and verbosity. Resolution would require comparative benchmarks measuring task completion rates and token efficiency.

### Open Question 3
How can established Agreement Technologies (negotiation, argumentation) be effectively integrated into LLM-based orchestration frameworks? There is a disconnect between the symbolic logic required for traditional automated negotiation and the probabilistic nature of LLMs. Resolution would require successful deployment of hybrid frameworks where LLM agents utilize symbolic negotiation algorithms.

## Limitations
- The equivalence claim between classical MAS architectures and LLM-based agents lacks systematic empirical validation across modern frameworks
- Literature review scope and selection criteria are not explicitly defined, making it unclear whether counterexamples were considered
- No quantitative metrics are provided to support claims, as this is fundamentally a conceptual position paper

## Confidence
- High confidence: Historical overview of agent architectures and their defining properties is well-established and accurately presented
- Medium confidence: Claim that LLM-based systems functionally implement classical architectures is logically sound but requires more systematic mapping
- Medium confidence: Assertion that structured coordination protocols outperform natural language communication needs empirical testing

## Next Checks
1. Conduct a systematic mapping study of 10+ popular "Agentic AI" frameworks, classifying their architectures against classical categories using a standardized rubric
2. Design a controlled experiment comparing task completion rates between LLM agents using FIPA-inspired structured protocols versus ad-hoc natural language communication
3. Survey LLM framework documentation to quantify how often they reference established MAS concepts versus presenting approaches as novel innovations