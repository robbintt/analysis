---
ver: rpa2
title: 'Keep It on a Leash: Controllable Pseudo-label Generation Towards Realistic
  Long-Tailed Semi-Supervised Learning'
arxiv_id: '2510.03993'
source_url: https://arxiv.org/abs/2510.03993
tags:
- data
- unlabeled
- distribution
- labeled
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of realistic long-tailed semi-supervised
  learning (LTSSL), where labeled data follow a long-tailed distribution while unlabeled
  data may follow an unknown arbitrary distribution. The authors propose a Controllable
  Pseudo-label Generation (CPG) framework that iteratively expands the labeled dataset
  with reliable pseudo-labels from unlabeled data, training the model on an updated
  labeled dataset with a known distribution to avoid distribution mismatch issues.
---

# Keep It on a Leash: Controllable Pseudo-label Generation Towards Realistic Long-Tailed Semi-Supervised Learning

## Quick Facts
- **arXiv ID:** 2510.03993
- **Source URL:** https://arxiv.org/abs/2510.03993
- **Reference count:** 40
- **Primary result:** Proposes CPG framework for realistic long-tailed semi-supervised learning, achieving up to 15.97% accuracy improvement over existing methods.

## Executive Summary
This paper addresses the challenge of realistic long-tailed semi-supervised learning (LTSSL), where labeled data follows a long-tailed distribution while unlabeled data may have an arbitrary unknown distribution. The authors propose a Controllable Pseudo-label Generation (CPG) framework that iteratively expands the labeled dataset with reliable pseudo-labels from unlabeled data, training the model on an updated labeled dataset with a known distribution to avoid distribution mismatch issues. The method employs a controllable self-reinforcing optimization cycle with dynamic filtering, logit adjustment for Bayes-optimal classifier construction, class-aware adaptive augmentation for minority classes, and an auxiliary branch for data utilization. Theoretical analysis proves the optimization cycle reduces generalization error, and extensive experiments demonstrate state-of-the-art performance across various distribution scenarios.

## Method Summary
The CPG framework addresses realistic LTSSL by decoupling the training process from the unknown unlabeled data distribution. It operates through a controllable self-reinforcing optimization cycle that progressively expands the labeled dataset with high-confidence pseudo-labels, ensuring the model is always trained on a known distribution. The method employs strict dynamic filtering requiring both high confidence and view agreement, a voting strategy to ensure consistent pseudo-label assignments, and an auxiliary branch that leverages consistency regularization on all data. The primary branch trains on the updated labeled set using Logit Adjustment to handle class imbalance, while the auxiliary branch stabilizes representation learning through consistency regularization on both labeled and unlabeled samples.

## Key Results
- Achieves up to 15.97% accuracy improvement over existing methods on CIFAR-10-LT, CIFAR-100-LT, Food-101-LT, and SVHN-LT datasets
- Demonstrates superior performance across various distribution scenarios including long-tailed, inverse long-tailed, and consistent distributions
- Reduces pseudo-label error rates by 12% compared to state-of-the-art methods through the voting strategy mechanism
- Maintains stable performance with threshold sensitivity analysis showing consistent results across τ ∈ {0.75, 0.85, 0.95}

## Why This Works (Mechanism)

### Mechanism 1: Controllable Self-Reinforcing Optimization Cycle
Decoupling the training process from the unknown unlabeled data distribution reduces generalization error caused by distribution mismatch. Instead of estimating the unlabeled distribution, the framework progressively expands the labeled dataset with only high-confidence pseudo-labels, ensuring the model is always trained on a "known" distribution. As the labeled set grows, the classifier improves, which in turn improves the quality of the next batch of pseudo-labels.

### Mechanism 2: Dynamic Controllable Filtering (The "Leash")
Strict, history-aware filtering prevents confirmation bias typical in standard semi-supervised learning. The framework uses a binary mask requiring high confidence and agreement between weak/strong views, combined with a voting strategy to ensure consistent pseudo-label assignments before permanent promotion to the labeled set.

### Mechanism 3: Hybrid Training with Auxiliary Branch
Maximizing data utilization via consistency regularization in an auxiliary branch stabilizes representation learning without contaminating the primary classifier. The primary branch trains only on the clean, expanded labeled set using Logit Adjustment, while the auxiliary branch applies standard consistency regularization to all data, forcing the encoder to learn robust features from noisy data.

## Foundational Learning

- **Concept: Logit Adjustment**
  - **Why needed here:** This is the core technique used to construct the "Bayes-optimal classifier." Standard cross-entropy fails on long-tailed data because the decision boundary shifts toward minority classes. Logit adjustment shifts the boundary back by adding ln(P_y) to the logits, compensating for class imbalance.
  - **Quick check question:** If a class has a prior P_y = 0.01, does logit adjustment add a positive or negative term to its logit before the final softmax?

- **Concept: Confirmation Bias in SSL**
  - **Why needed here:** The paper explicitly claims to solve this. Confirmation bias occurs when a model incorrectly labels data early in training, and then reinforces those errors as "ground truth" in later epochs.
  - **Quick check question:** Why does the "voting strategy" specifically mitigate confirmation bias compared to a single high-confidence threshold?

- **Concept: Class Prior / Distribution Estimation**
  - **Why needed here:** Unlike standard LTSSL methods, this method does not estimate the unlabeled class prior. You need to understand the difference between "estimating the target distribution" vs. "imposing a known source distribution."
  - **Quick check question:** Does CPG need to know the distribution of the unlabeled data D_u to train the Bayes-optimal classifier?

## Architecture Onboarding

- **Component map:** Encoder g(·) -> Primary Branch (Logit-Adjusted classifier) + Auxiliary Branch (Standard classifier) -> Pseudo-label Manager (Voting Strategy + Filtering)

- **Critical path:**
  1. Warmup (Epochs 1-30): Train both branches using only labeled data D_l to stabilize the encoder
  2. Inference on Unlabeled: Generate weak and strong predictions for unlabeled data
  3. Filtering & Voting: Check confidence and agreement conditions, update voting history, promote stable samples to D_l^(t)
  4. Update Distribution: Recalculate class priors π^(t) based on the expanded labeled set
  5. Optimization: Backprop using Logit Adjustment loss and Auxiliary consistency loss

- **Design tradeoffs:**
  - Strictness vs. Speed: The Voting Strategy and high threshold (τ=0.95) reduce error but slow down labeled set expansion; the auxiliary branch compensates by keeping the encoder learning on all data
  - Augmentation Radius: For minority classes, CAA uses smaller radius r = 1/α for compact minority classes to avoid destroying rare valid features

- **Failure signatures:**
  - Pseudo-label Utilization ≈ 0: Threshold is too high or warmup was insufficient; model never catches unlabeled distribution
  - Majority Class Collapse: Incorrect Logit Adjustment weights (using unlabeled stats) may over-compensate and degrade majority class accuracy
  - Voting Memory Overflow: Voting strategy requires maintaining state for every unlabeled sample, potentially exceeding RAM on massive datasets

- **First 3 experiments:**
  1. Ablation on Voting: Disable voting strategy and measure pseudo-label error rate to verify voting holds the "Leash"
  2. Threshold Sensitivity: Run CPG with τ ∈ {0.75, 0.85, 0.95} to confirm stable performance
  3. Distribution Mismatch Test: Create dataset where D_l is long-tailed but D_u is inverse long-tailed, compare CPG against baselines

## Open Questions the Paper Calls Out

- **Open Question 1:** How can CPG be adapted to handle scenarios where labeled training data contains noisy labels, given its current reliance on clean labels to initialize the Bayes-optimal classifier? (Appendix H states the method assumes labeled data is noise-free)
- **Open Question 2:** Does CPG's performance degrade when labeled data follows a uniform distribution with extremely limited supervision rather than a long-tailed distribution? (Appendix H identifies this as a potential limitation)
- **Open Question 3:** How does the dynamic controllable filtering mechanism perform in Open-Set LTSSL scenarios where unlabeled data contains classes not present in the labeled set? (Section 3.1 assumes identical label spaces)

## Limitations
- The theoretical claims rest on the assumption that cumulative pseudo-labeling error remains bounded, which is not empirically validated across all dataset scenarios
- The voting strategy for pseudo-label consistency lacks specific implementation details including window size and update frequency
- Performance may degrade when the initial labeled set is extremely imbalanced or when the unlabeled data distribution is severely adversarial

## Confidence

- **High Confidence:** The decoupling mechanism and its effectiveness in avoiding distribution mismatch - strongly supported by theoretical analysis and experimental results
- **Medium Confidence:** The voting strategy's role in preventing confirmation bias - while Figure 1 shows fewer false positives, lack of implementation details makes exact replication uncertain
- **Medium Confidence:** The auxiliary branch's contribution to data utilization - the hybrid training approach is sound, but the specific weight parameter (ω) is not extensively ablated

## Next Checks

1. **Voting Strategy Ablation:** Run CPG with and without the voting mechanism to quantify its exact contribution to reducing pseudo-label error rates, measuring the difference in false positive rates
2. **Adversarial Distribution Test:** Construct a scenario where unlabeled data follows an inverse long-tailed distribution compared to labeled data, and compare CPG's performance against standard LTSSL methods that estimate the unlabeled distribution
3. **Memory Efficiency Analysis:** Profile the voting strategy's memory consumption on large-scale datasets (e.g., Food-101-LT) to identify potential bottlenecks when maintaining state for every unlabeled sample