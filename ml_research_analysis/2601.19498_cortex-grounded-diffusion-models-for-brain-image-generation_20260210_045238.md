---
ver: rpa2
title: Cortex-Grounded Diffusion Models for Brain Image Generation
arxiv_id: '2601.19498'
source_url: https://arxiv.org/abs/2601.19498
tags:
- cortical
- image
- cor2vox
- brain
- shape
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of generating anatomically plausible
  brain MRIs with fine-grained cortical control, a critical need for synthetic data
  in neuroimaging. Existing generative models rely on weak conditioning (labels, text)
  and fail to preserve cortical morphology, leading to implausible anatomies.
---

# Cortex-Grounded Diffusion Models for Brain Image Generation

## Quick Facts
- arXiv ID: 2601.19498
- Source URL: https://arxiv.org/abs/2601.19498
- Reference count: 40
- Primary result: Anatomically plausible 3D brain MRI synthesis with continuous cortical control using signed distance fields and Brownian bridge diffusion

## Executive Summary
Cor2Vox introduces a cortex-grounded generative framework that addresses the challenge of generating anatomically plausible brain MRIs with fine-grained cortical control. The method uses signed distance fields (SDFs) of the cerebral cortex as structured priors and a Brownian bridge diffusion process to map from cortical geometry to image space. By incorporating auxiliary shape conditions (pial/white matter SDFs, edges, cortical ribbon mask) and leveraging a large-scale statistical shape model derived from 33k+ UK Biobank scans, Cor2Vox achieves strict consistency between synthesized images and conditional inputs. The model outperforms baseline methods in geometric consistency (ASSD ~0.28 mm) and whole-brain image fidelity (SSIM ~0.91), validated through cortical surface reconstruction and automatic segmentation.

## Method Summary
Cor2Vox generates 3D brain MRIs by conditioning on cortical surfaces using a Brownian bridge diffusion process. The method takes T1-weighted MRIs and their corresponding cortical meshes (pial and white matter surfaces) as input. Cortical geometries are converted to signed distance fields, combined with auxiliary shape conditions (edge maps, cortical ribbon masks), and fed into a 3D residual UNet with attention. A PCA-based shape model ensures sampled geometries lie on the manifold of realistic anatomies. The diffusion process maps from a Cortex SDF to the output image, guided by auxiliary conditions at every timestep. The model is trained on 1,155 ADNI scans with 400 epochs on H100 GPUs, achieving SSIM ~0.91 and ASSD ~0.28 mm on test data.

## Key Results
- Geometric consistency: ASSD ~0.28 mm for white matter/pial surfaces, significantly better than baselines
- Image fidelity: SSIM ~0.91 and competitive PSNR scores on whole-brain reconstruction
- Cross-dataset generalization: Maintains quality on ADNI data without retraining
- Sub-voxel cortical atrophy simulation: Mean error ~0.14 mm in thickness manipulation
- Anatomical plausibility: Synthetic samples preserve regional cortical thickness distributions consistent with real data

## Why This Works (Mechanism)

### Mechanism 1: Structured Stochastic Bridge (Source-to-Target Mapping)
Standard diffusion models map from unstructured Gaussian noise to image space, severing the link between anatomy and texture. Cor2Vox replaces this with a Brownian Bridge Diffusion Model that maps from a structured anatomical prior (Cortex SDF) to the target MRI. The variance schedule peaks at t=T/2 and is zero at endpoints, anchoring generation to input geometry while allowing appearance variation.

### Mechanism 2: Dense Multi-Resolution Auxiliary Guidance
A single geometric condition is insufficient for sub-voxel accuracy. During reverse diffusion, the denoising network receives concatenated auxiliary conditions (Pial SDF, White Matter SDF, edge map, cortical ribbon mask) at every timestep. This forces predictions to align with specific anatomical boundaries, improving geometric consistency from ~0.38mm to ~0.28mm ASSD.

### Mechanism 3: Manifold-Constrained Sampling via Statistical Shape Models
Random geometric inputs often violate biological constraints. A PCA-based shape model fitted to 33k+ cortical surfaces enables anatomically plausible sampling through spherical interpolation in latent space. This prevents impossible topologies (broken sulci) that plagued baseline DDPMs by ensuring all sampled shapes lie on the manifold of realistic brain anatomies.

## Foundational Learning

- **Concept: Signed Distance Fields (SDFs)**
  - Why needed here: Raw 3D meshes cannot be directly fed into a 3D UNet; SDFs convert meshes to dense voxel grids where values represent distance to surface
  - Quick check question: In Cor2Vox's "Cortex SDF," what does a value of 0.0 represent? (Answer: The cortical ribbon region, or space between pial and white matter surfaces)

- **Concept: Brownian Bridge Diffusion**
  - Why needed here: This is the core engine; unlike standard diffusion which goes Noise → Image, this goes Shape → Image
  - Quick check question: Why is variance set to zero at both start (t=T) and end (t=0) of diffusion process? (Answer: To ensure process strictly begins at input SDF and ends exactly at output Image)

- **Concept: Spherical Interpolation (Slerp)**
  - Why needed here: To generate new brains, you don't pick random points; you interpolate between real ones
  - Quick check question: Why use spherical interpolation in latent space rather than linear interpolation? (Answer: Linear interpolation moves through "center" resulting in implausibly smooth/average shapes; spherical interpolation stays on surface of probability manifold)

## Architecture Onboarding

- **Component map:** T1 MRI + Cortical Meshes -> Mesh-to-SDF converter -> PCA shape model -> 3D UNet with Attention -> Brownian Bridge scheduler
- **Critical path:** Preparation of Joint Cortex SDF (S_c). The paper details specific logic to merge Pial and White matter SDFs (taking min/max values based on region signs). Errors here propagate directly, creating "holes" in the cortex
- **Design tradeoffs:**
  - Resolution vs. Memory: Model operates at 128³ internally; fine details handled via sub-voxel surface supervision, not raw voxel resolution
  - DDPM vs. BBDM: Paper ablates this (Cor2Vox vs. Cor2Vox/DDPM). BBDM is strictly better for controllable synthesis because DDPMs "forget" conditioning
- **Failure signatures:**
  - "Missing Sulci" (Topology break): If input SDF is too smooth or model under-trained, central sulcus will vanish
  - Ribbon Artifacts: If SDF fusion logic is implemented incorrectly, you may see "gap" between white matter and pial surfaces in generated MRI
- **First 3 experiments:**
  1. Overfit Single Subject: Train on one MRI/SDF pair. Model should reconstruct image perfectly (down to noise pattern) to verify UNet and Bridge implementation
  2. Visualize the Bridge: Run forward process to see MRI gradually turn into SDF. Run reverse to see SDF turn to MRI. If intermediate steps look like static noise, you've implemented standard DDPM, not Bridge
  3. Ablate Auxiliary Inputs: Run inference using only unified Cortex SDF (S_c) vs. S_c + Auxiliaries. Measure surface distance (ASSD). Version with auxiliaries should show lower error on White Matter boundary specifically

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can Cor2Vox be extended to condition on subcortical structures, white matter lesions, or brain tumors while maintaining the same geometric fidelity achieved for cortical surfaces?
- Basis in paper: The authors state "Future work will investigate these directions to broaden the applicability of shape-grounded generative modeling" and acknowledge they "have not yet explored conditioning on additional anatomical or pathological structures beyond the cerebral cortex"
- Why unresolved: Subcortical structures have different geometric complexity but lack paired-surface representation used for cortex; lesion shapes are heterogeneous and lack population shape models
- What evidence would resolve it: Successful generation of MRIs conditioned on subcortical SDFs or lesion masks with geometric consistency verified via surface reconstruction or segmentation accuracy comparable to cortical results (~0.28 mm ASSD)

### Open Question 2
- Question: How well does the UK Biobank-derived shape model generalize to populations with different demographics (pediatric, diverse ethnicities) or extreme pathological anatomy not represented in training distribution?
- Basis in paper: The shape model is built from 33k+ UK Biobank subjects, which has known demographic biases. The FTD experiment used only 10 in-house samples, and the paper notes generated samples must "lie on the manifold of anatomically realistic cortical geometry"
- Why unresolved: Shape models can produce implausible results outside their training distribution; severe pathologies may fall outside modeled shape space
- What evidence would resolve it: Validation of geometric consistency and anatomical plausibility when generating MRIs for external populations or extreme phenotypes not present in UK Biobank

### Open Question 3
- Question: Can the framework be adapted for multi-modal synthesis (T2, FLAIR, DWI) that preserves consistent anatomy across modalities?
- Basis in paper: The paper focuses exclusively on T1-weighted MRI and does not address other clinical sequences. Multi-modal synthesis is critical for realistic training data augmentation
- Why unresolved: Different MRI sequences capture distinct tissue contrasts; whether a single shape condition can guide multiple appearance domains remains untested
- What evidence would resolve it: Demonstrating paired multi-modal synthesis with consistent cortical geometry across T1, T2, and FLAIR outputs, validated via cross-modal registration or joint segmentation accuracy

## Limitations
- Relies on proprietary cortical surface extraction tools (V2C-Flow) and UK Biobank PCA model that are not publicly available
- Edge map generation method and exact SDF computation parameters remain underspecified, creating potential reproducibility gaps
- Validation primarily uses ADNI data with limited testing across diverse acquisition protocols or disease states

## Confidence

| Claim | Confidence |
|-------|------------|
| Core mechanism (BBDM + SDF conditioning) and geometric validation | High |
| Cross-dataset generalization claims | Medium |
| UK Biobank PCA shape model composition and biological plausibility | Low |

## Next Checks

1. **Anatomical Plausibility Audit:** Run generated MRIs through multiple independent segmentation tools (not just SynthSeg+) and manually verify cortical ribbon continuity and sulcus preservation across 50 random samples

2. **Distribution Consistency Test:** Compare cortical thickness distributions (using FreeSurfer or equivalent) between real ADNI scans and 1,000 Cor2Vox samples to ensure no systematic bias in regional morphology

3. **Protocol Robustness Validation:** Test the model on at least two additional datasets with different scanners (e.g., OASIS, ABIDE) to verify the claimed cross-dataset harmonization without retraining actually generalizes beyond ADNI