---
ver: rpa2
title: 'Riemannian Lyapunov Optimizer: A Unified Framework for Optimization'
arxiv_id: '2601.22284'
source_url: https://arxiv.org/abs/2601.22284
tags:
- learning
- direction
- optimization
- target
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents Riemannian Lyapunov Optimizers (RLOs), a unified
  geometric framework for understanding and designing optimization algorithms. The
  key innovation is reinterpreting optimization as a closed-loop controlled dynamical
  system evolving on a Riemannian manifold, with the Normally Attracting Invariant
  Manifold (NAIM) serving as the geometric skeleton organizing training dynamics into
  fast residual alignment and slow manifold evolution.
---

# Riemannian Lyapunov Optimizer: A Unified Framework for Optimization

## Quick Facts
- **arXiv ID:** 2601.22284
- **Source URL:** https://arxiv.org/abs/2601.22284
- **Reference count:** 40
- **Primary result:** RLO-Λ achieves 73.98% Top-1 accuracy on ImageNet (ResNet-50) vs 73.87% for AdamW

## Executive Summary
This paper introduces Riemannian Lyapunov Optimizers (RLOs), a unified geometric framework that reinterprets optimization as a closed-loop dynamical system evolving on a Riemannian manifold. The key innovation is the Normally Attracting Invariant Manifold (NAIM), which organizes training dynamics into rapid velocity alignment followed by controlled manifold evolution. RLO recovers existing optimizers (SGD, Adam, Lion) as special cases while enabling principled design of new algorithms through Lyapunov stability theory and backstepping control synthesis.

## Method Summary
RLO formulates optimization on a Riemannian manifold M with parameter θ, velocity v, and internal state y. The method computes gradients, updates internal state via Ψ, generates target direction via Φ, lifts velocity with parameter η, retracts to manifold, and transports velocity. Three variants exist: RLO (standard), RLO-Λ (direct parameter update), and RLO-Lifted (explicit velocity state). The framework derives from backstepping control theory, ensuring strict Lyapunov descent through the NAIM structure.

## Key Results
- RLO-Λ achieves 73.98% Top-1 on ImageNet (ResNet-50) vs 73.87% for AdamW
- On ViT-B/16, RLO-Λ reaches 76.47% vs 71.42% for AdamW
- Ablation shows smooth direction fields (tanh) outperform discontinuous ones (sign) when global normalization is disabled

## Why This Works (Mechanism)

### Mechanism 1: Two-Time-Scale NAIM Dynamics
The system organizes dynamics around a Normally Attracting Invariant Manifold (NAIM), creating separation between fast velocity alignment and slow manifold drift. The residual z = v - d contracts via z_{k+1} ≈ (1-η_k)z_k, creating a "thick tube" around Λ where the Lyapunov function satisfies boundedness under stochastic disturbances.

### Mechanism 2: Geometric Backstepping Controller Synthesis
RLO updates derive from continuous backstepping controller design for NAIM stabilization. Starting from open-loop dynamics, the control input cancels cross-coupling terms in V̇. Discretization maps continuous 1/τ → discrete η ∈ (0,1], yielding the lifted velocity update ṽ_{k+1} = (1-η)v_k + ηd_k.

### Mechanism 3: Direction Field Smoothness Reduces Steady-State Error
Smooth direction field generators (tanh) yield lower steady-state loss than discontinuous ones (sign) by minimizing the forcing disturbance δ_k. Theorem 3.1 bounds final error by (c₃/ρη_k h_k) sup||δ_k||². Discontinuous Φ causes large jumps in target d_k even for small gradient changes.

## Foundational Learning

- **Riemannian Manifolds and Tangent Bundles**: Defines geometry where gradients live in tangent space T_θM and velocity v lives in tangent bundle TM. Quick check: Why is a retraction R_θ: T_θM → M needed to map velocity vectors back to the manifold after updates?

- **Lyapunov Stability Theory**: Uses strict Lyapunov functions V to certify convergence and derive control laws. Quick check: What does uniform ultimate boundedness mean, and why does stochastic gradient noise prevent exact convergence to V = 0?

- **Backstepping Control**: Treats v as "virtual control" for θ, with residual z as backstepping error. Quick check: Why must the control input u account for both feedforward tracking (∇_θ̇ Φ) and error feedback (-z/τ)?

## Architecture Onboarding

- **Component map**: (M, g) → Ψ(y_k, ĝ_k) → Φ(y_k, ĝ_k) → η → V_k
- **Critical path**: Compute gradient → update internal state y via Ψ → construct target d via Φ → lift velocity ṽ = (1-η)v + ηd → retract parameters θ via R → transport velocity via T
- **Design tradeoffs**: η controls fiber contraction rate (low η provides smoothing, high η gives precise tracking); Φ smoothness affects stability (tanh more stable without normalization); global normalization provides implicit learning rate scaling but creates sharp stability boundaries
- **Failure signatures**: ViT-S/16 with RLO-Lifted (η=0.7) achieves only 71.43% vs 76.18% for RLO-Λ; sign-based Φ without normalization causes accuracy collapse; global normalization with LR >3×10^{-4} drops accuracy to random chance
- **First 3 experiments**: 1) Reproduce ablation (Table 2) comparing tanh vs sign with/without global normalization on CIFAR-10/ResNet-18; 2) Sweep η on CIFAR-10 and monitor residual thickness and alignment; 3) Compare RLO-Λ vs RLO-Lifted on ViT-S/16 and ViT-B/16

## Open Questions the Paper Calls Out

### Open Question 1
Why does the explicit velocity state in RLO-Lifted degrade performance on smaller architectures like ViT-S/16 while succeeding on larger models? The authors observe a 4.75% deficit for RLO-Lifted on ViT-S/16 compared to RLO-Λ, hypothesizing that smaller models require faster adaptation (η → 1), but do not provide a formal relationship between model capacity and the required fiber contraction rate.

### Open Question 2
Does the RLO framework's advantage over AdamW generalize to language modeling tasks and LLM training? The paper validates exclusively on computer vision benchmarks despite claims of unifying "modern machine learning optimization," while AdamW remains dominant for LLMs and Transformer loss landscapes differ structurally from vision models.

### Open Question 3
Can the convergence guarantees be extended to generic non-convex settings without relying on the Polyak-Lojasiewicz (PL) condition? Theorem 3.1 requires the PL condition to prove linear convergence, an assumption that may not hold for general deep learning loss landscapes, limiting the "Uniformly Ultimate Boundedness" result.

## Limitations

- The NAIM manifold structure lacks direct empirical validation beyond convergence diagnostics
- Global normalization's role remains unclear with sharp stability boundaries not fully explained by geometric theory
- Empirical gains are primarily demonstrated on vision tasks with unproven generalization to other domains

## Confidence

- **High**: The Lyapunov stability proof framework (Theorem 3.1) is mathematically rigorous and the derivation from backstepping control is sound
- **Medium**: The claim that smoothness of direction fields reduces steady-state error is well-supported by CIFAR-10 ablation but lacks broader validation
- **Low**: The assertion that RLO-Λ is universally superior across architectures relies on limited ImageNet experiments with architecture-specific tuning requirements

## Next Checks

1. **NAIM Structure Verification**: Implement Lyapunov-based manifold learning to visualize the NAIM skeleton on CIFAR-10 and confirm two-stage dynamics (fast alignment, slow drift)
2. **Cross-Domain Generalization**: Test RLO-Λ on language modeling (WikiText-103) and reinforcement learning (D4RL) to assess geometric benefits beyond vision
3. **Global Normalization Isolation**: Design experiments decoupling global normalization's implicit learning rate scaling from regularization effects by comparing with explicit learning rate schedules and gradient clipping