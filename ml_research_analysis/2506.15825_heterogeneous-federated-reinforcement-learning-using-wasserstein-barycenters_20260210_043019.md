---
ver: rpa2
title: Heterogeneous Federated Reinforcement Learning Using Wasserstein Barycenters
arxiv_id: '2506.15825'
source_url: https://arxiv.org/abs/2506.15825
tags:
- learning
- global
- training
- agents
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FedWB, a federated learning algorithm that
  uses Wasserstein barycenters for model fusion in distributed deep learning and reinforcement
  learning. The method addresses the challenge of training a global model across heterogeneous
  environments without centralizing data.
---

# Heterogeneous Federated Reinforcement Learning Using Wasserstein Barycenters

## Quick Facts
- arXiv ID: 2506.15825
- Source URL: https://arxiv.org/abs/2506.15825
- Reference count: 29
- Key outcome: FedWB uses Wasserstein barycenters for federated model aggregation, showing faster early convergence than FedAvg on MNIST and better early performance in heterogeneous federated RL with CartPole

## Executive Summary
This paper introduces FedWB, a federated learning algorithm that uses Wasserstein barycenters for model fusion in distributed deep learning and reinforcement learning. The method addresses the challenge of training a global model across heterogeneous environments without centralizing data. Instead of averaging weights (as in FedAvg), FedWB uses Wasserstein barycenters to preserve the geometric structure of weight distributions during aggregation. The approach is first demonstrated on MNIST classification, where FedWB achieves faster early convergence than FedAvg, though with higher per-iteration computational cost. FedWB is then extended to heterogeneous federated reinforcement learning using the CartPole environment, where it produces a global DQN that performs well across all environments with superior early performance compared to FedAvg.

## Method Summary
FedWB aggregates model weights using Wasserstein barycenters by first flattening each layer's weight matrix, adding the minimum value to ensure non-negativity, normalizing to create probability distributions, computing the Wasserstein barycenter, and then rescaling using averaged scaling factors. For MNIST classification, agents train local models on distributed data subsets and synchronize periodically via FedWB aggregation. For heterogeneous federated RL, agents train DQNs in environments with varying pole lengths, periodically aggregating weights via Wasserstein barycenters to produce a global policy that generalizes across environment variations. The method contrasts with traditional FedAvg by preserving geometric structure in weight distributions rather than using arithmetic averaging.

## Key Results
- FedWB reaches 95% test accuracy within 25 epochs on MNIST with 10 agents, faster early convergence than FedAvg
- In heterogeneous federated RL with CartPole, FedWB shows superior early performance compared to FedAvg, with both methods eventually converging to similar control capabilities
- More agents lead to faster wall-clock convergence but require more epochs for convergence in MNIST experiments

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Wasserstein barycenters may preserve geometric structure in model weight distributions better than arithmetic averaging during aggregation.
- Mechanism: Treats flattened neural network weights as probability distributions and computes a barycenter that lies on a geodesic connecting input distributions, rather than placing mass underneath each distribution's location as arithmetic averaging does.
- Core assumption: Assumption: Weight distributions encode geometric relationships that arithmetic averaging distorts, particularly relevant in early training when models diverge more.
- Evidence anchors:
  - [section 3.2.2] "Unlike other averaging methods... Wasserstein barycenters focus on the retaining geometry. In 1D unimodal probability distributions, traditional averaging yields a bimodal distribution... WBs yield a unimodal distribution that lies on a geodesic"
  - [section 5.1] "FedWB has a more rapid increase in test accuracy but flattens out quickly... FedAvg takes longer to reach more acceptable results"
  - [corpus] Weak direct evidence; neighbor papers discuss Wasserstein barycenters for domain alignment and privacy, not specifically for federated aggregation geometry.
- Break condition: When models have converged similarly (late training), the geometric advantage diminishes—both FedWB and FedAvg converge to similar performance per Figure 6.

### Mechanism 2
- Claim: Layer-wise flattening with min-shifting and normalization enables Wasserstein barycenter computation while preserving recoverable weight information.
- Mechanism: Each layer's weight matrix is flattened to 1D, shifted by its minimum value to ensure non-negativity, normalized to sum to 1 (probability distribution), aggregated via WB, then rescaled using the averaged scaling factors and minimum values.
- Core assumption: Assumption: The relative structure matters more than absolute scale, and the scaling factors capture enough information to recover functional weights.
- Evidence anchors:
  - [section 4.1, Algorithm 1] "WB requires us to work with probability distributions, so we add the smallest value... flatten the matrix, and divide each term by the sum"
  - [section 5.1] Global model reaches 95% test accuracy within 25 epochs with 10 agents, indicating the transformation preserves functional information.
  - [corpus] No direct corpus validation of this specific scaling approach.
- Break condition: If weight matrices have extreme outliers or highly uneven distributions, normalization may compress important variation.

### Mechanism 3
- Claim: Intermittent aggregation in heterogeneous federated RL can produce a global policy that generalizes across environment variations without centralized data.
- Mechanism: Each agent trains a DQN in its local environment (varying pole lengths), periodically synchronizes via global aggregation, and receives the updated global model—allowing knowledge transfer across heterogeneous dynamics.
- Core assumption: Assumption: Local Q-functions from different environments contain complementary information that, when properly aggregated, yields a policy robust to environmental variation.
- Evidence anchors:
  - [abstract] "the end outcome is a global DQN that functions across all environments"
  - [section 5.2] "By the end of training epochs, we noticed both models were capable of balancing the pole to the maximum allowed number of actions, 500 actions"
  - [corpus] Jin et al. (2022) in neighbor papers show QAvg/PAvg for heterogeneous FRL with arithmetic averaging, providing baseline comparison.
- Break condition: If environment heterogeneity is too extreme (e.g., fundamentally different dynamics), shared representations may not transfer effectively.

## Foundational Learning

- **Concept: Optimal Transport and Wasserstein Distance**
  - Why needed here: Core mathematical tool for FedWB's aggregation—understanding how Wasserstein barycenters differ from Euclidean averaging is essential.
  - Quick check question: Can you explain why Wasserstein barycenters preserve unimodality when averaging unimodal distributions while arithmetic averaging does not?

- **Concept: Federated Learning Synchronization**
  - Why needed here: FedWB operates within a federated architecture—local training, periodic aggregation, model broadcasting.
  - Quick check question: What is the tradeoff between synchronization frequency and convergence speed in federated systems?

- **Concept: Deep Q-Learning with Experience Replay**
  - Why needed here: The HFRL extension uses DQN architecture with target/online networks; understanding TD-learning is necessary for the RL experiments.
  - Quick check question: Why does DQN use separate target and online networks, and how does this interact with federated aggregation?

## Architecture Onboarding

- **Component map:**
  - Central server: Performs aggregation via Wasserstein barycenters (Algorithm 1), stores global model
  - Distributed agents (D): Each holds local model, local dataset/environment, performs local training
  - Communication channels: Weights uploaded to server, global model broadcast back
  - For RL: Additional target network + experience replay buffer per agent

- **Critical path:**
  1. Initialize identical model architectures across all agents
  2. Local training loop (SGD for MNIST, DQN steps for CartPole)
  3. Aggregate weights at server using Algorithm 1 (flatten → shift → normalize → WB → rescale)
  4. Broadcast global model; agents replace local weights
  5. Repeat until convergence criteria met

- **Design tradeoffs:**
  - FedWB vs FedAvg: Faster early convergence (Figure 5, 7) but higher per-iteration cost from OT computation
  - Number of agents: More agents = faster wall-clock convergence (Table 1) but more epochs needed (Figure 3)
  - Synchronization frequency: Paper suggests potential hybrid approach—use FedWB early, switch to FedAvg later

- **Failure signatures:**
  - Convergence stalls without improvement: May indicate scaling factor issues or WB solver instability
  - Local models diverge excessively: Reduce number of agents or increase synchronization frequency
  - High variance in RL training: Normal for DQN; monitor 50-episode moving average (Figure 6)
  - Communication bottleneck: Too many agents causing synchronization overhead

- **First 3 experiments:**
  1. **MNIST with 2 agents, 10 epochs**: Validate basic FedWB functionality against single-agent baseline; expect global model jump from ~0% to ~80% after first aggregation per Figure 4.
  2. **MNIST with 10 agents, compare FedWB vs FedAvg**: Replicate Figure 5 comparison; FedWB should reach 95% faster in epochs but verify wall-clock time tradeoff.
  3. **CartPole with 3 heterogeneous environments (varying pole lengths)**: Implement Algorithm 3 with 200-300 episodes; compare FedWB vs FedAvg on episode-averaged duration per Figure 7.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Would a hybrid formulation that switches from FedWB to FedAvg during training achieve both faster early convergence and lower overall computational cost?
- Basis in paper: [explicit] "It is possible a hybrid formulation yields the optimal solution, where for the first few epochs FedWB yields a better global model which is then swapped out for the speed of FedAvg, to reach potentially higher accuracy in a faster time frame."
- Why unresolved: The authors propose this idea but do not implement or test any hybrid switching strategy.
- What evidence would resolve it: Empirical comparison of hybrid switching strategies at various epoch thresholds, measuring wall-clock time and final accuracy on both MNIST and RL tasks.

### Open Question 2
- Question: What causes the non-monotonic relationship between the number of agents and epochs required for convergence, specifically the spike when increasing from 4 to 5 agents followed by a rapid decrease at 10 agents?
- Basis in paper: [explicit] "This phenomenon was neither expected, nor will it be studied or explored in this paper."
- Why unresolved: Authors observe the anomaly in Figure 3 but defer investigation, offering only a conjecture about data partitioning effects on local model convergence.
- What evidence would resolve it: Systematic ablation studies varying data heterogeneity, class distribution across agents, and agent count to isolate the cause of non-monotonic convergence behavior.

### Open Question 3
- Question: How does communication overhead scale with the number of agents in real distributed deployments, and at what point does synchronization cost outweigh parallelization benefits?
- Basis in paper: [inferred] The authors acknowledge their speed comparison is "extrapolated based on architecture type rather than wall-clock time" and that "miss-handling of distributed computing can lead to large communication overhead."
- Why unresolved: All experiments ran on a single machine; the theoretical speedup calculations ignore actual network latency, synchronization delays, and aggregation bottlenecks.
- What evidence would resolve it: Deployment across geographically distributed nodes with varying bandwidth and latency, measuring actual wall-clock speedup as agent count increases.

### Open Question 4
- Question: Does FedWB provide similar early-convergence benefits in more complex RL environments (e.g., continuous action spaces, higher-dimensional state spaces, or multi-agent settings)?
- Basis in paper: [inferred] Experiments are limited to MNIST classification and CartPole (a simple toy problem with discrete actions and low-dimensional states).
- Why unresolved: The scalability and effectiveness of Wasserstein barycenter aggregation for complex DNN architectures or policy networks in sophisticated environments remains untested.
- What evidence would resolve it: Evaluation on benchmark RL environments such as MuJoCo locomotion tasks, Atari games, or multi-agent cooperative scenarios comparing FedWB against FedAvg.

## Limitations

- Computational overhead of Wasserstein barycenter computation may limit scalability with agent count
- Limited evaluation to simple MNIST and CartPole environments raises questions about effectiveness in complex domains
- Lack of detailed hyperparameter specifications (learning rates, batch sizes, aggregation frequency) hinders faithful reproduction

## Confidence

- **High Confidence**: FedWB's basic mechanism (weight flattening → probability conversion → WB aggregation → rescaling) is well-defined and validated on MNIST
- **Medium Confidence**: Early convergence benefits are demonstrated, but long-term performance parity with FedAvg and computational scalability need verification
- **Low Confidence**: Extension to heterogeneous RL relies on limited evidence (one environment type); generalization to broader heterogeneity remains unproven

## Next Checks

1. **Replicate MNIST convergence curves** with exact agent counts (2, 5, 10) to verify the claimed epoch-count vs. agent-count relationship and wall-clock time tradeoff
2. **Implement the WB solver** with and without entropic regularization to quantify the computational overhead and identify acceptable speed-accuracy tradeoffs
3. **Test HFRL with more heterogeneous environments** (varying pole lengths, masses, or friction) to assess whether FedWB maintains advantages beyond the single CartPole variation studied