---
ver: rpa2
title: Enhancing Non-English Capabilities of English-Centric Large Language Models
  through Deep Supervision Fine-Tuning
arxiv_id: '2503.01275'
source_url: https://arxiv.org/abs/2503.01275
tags:
- language
- english
- supervision
- arxiv
- layers
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes deep supervision fine-tuning (DFT) to enhance
  the non-English capabilities of English-centric large language models. The key insight
  is that LLMs implicitly convert non-English queries to English at the bottom layers
  and perform English reasoning at the middle layers, but lack explicit supervision
  for this internal workflow.
---

# Enhancing Non-English Capabilities of English-Centric Large Language Models through Deep Supervision Fine-Tuning

## Quick Facts
- arXiv ID: 2503.01275
- Source URL: https://arxiv.org/abs/2503.01275
- Reference count: 14
- Primary result: DFT significantly outperforms traditional fine-tuning for non-English QA and NLU tasks

## Executive Summary
This paper addresses the challenge of enhancing non-English capabilities in English-centric LLMs by introducing deep supervision fine-tuning (DFT). The key insight is that these models implicitly convert non-English inputs to English at bottom layers and perform English reasoning at middle layers, but lack explicit supervision for this internal workflow. DFT introduces supervision signals at different processing stages - constraining language conversion at bottom layers and English reasoning at middle layers - which significantly improves performance on multilingual tasks compared to traditional fine-tuning methods.

## Method Summary
DFT modifies standard fine-tuning by adding supervision at intermediate layers of English-centric LLMs. The method identifies critical layers using entropy analysis of hidden states, then applies two types of supervision: logits-based (predicting English text at intermediate layers) and feature-based (aligning hidden states across languages). During training, losses are computed at both intermediate layers and the final output layer, with supervision targets corresponding to English versions of the non-English inputs. The approach requires parallel English-target language instruction pairs for training and uses entropy drops to identify optimal supervision layers.

## Key Results
- DFT outperforms traditional fine-tuning on 8 multilingual datasets across 3 languages (Chinese, Vietnamese, Arabic)
- Feature-based supervision is more robust than logits-based for understanding tasks and cross-lingual transfer
- Entropy analysis reveals two critical drops corresponding to language conversion and English thinking stages
- Layer 15 (second entropy drop) is optimal for English thinking supervision on LLaMA-2-7B

## Why This Works (Mechanism)

### Mechanism 1
English-centric LLMs process non-English inputs through a three-stage pipeline: language conversion (bottom layers), English reasoning (middle layers), and language reversion (top layers). The model's intermediate layers perform implicit cross-lingual transfer, but lack explicit supervision causes representation drift during these transformations.

### Mechanism 2
Adding supervision signals at intermediate layers improves non-English task performance by ensuring accurate internal representations during cross-lingual transfer. DFT introduces logits-based (predicting English text) and feature-based (aligning hidden states) objectives that constrain the model's internal processing.

### Mechanism 3
Entropy drops in layer-wise hidden states indicate critical transition points between processing stages. The first entropy drop corresponds to language-to-English conversion; the second corresponds to completion of reasoning. Supervision applied at these inflection points yields optimal performance.

## Foundational Learning

- **Concept: Deep Supervision Networks (DSNs)**
  - Why needed here: DFT adapts the DSN principle - adding loss at intermediate layers - but differs by using supervision targets (English text) distinct from the final output (target language text)
  - Quick check question: Can you explain why traditional DSNs use the same target at all layers, but DFT uses different targets at intermediate vs. final layers?

- **Concept: Cross-Lingual Representation Alignment**
  - Why needed here: Feature-based supervision relies on aligning hidden states between semantically equivalent English and non-English inputs using cosine similarity
  - Quick check question: Why might feature alignment be more robust than logits prediction for some tasks?

- **Concept: Transformer Hidden State Extraction**
  - Why needed here: Implementing DFT requires extracting hidden representations from intermediate layers and applying the model's output projection matrix at non-final layers
  - Quick check question: How do you extract and project a hidden state from layer i to vocabulary space?

## Architecture Onboarding

- **Component map**: Input text -> Base English-centric LLM (LLaMA-2/Gemma-2) -> Extract hidden states at layers i, j, L -> Apply supervision losses -> Combined loss backpropagation

- **Critical path**: 
  1. Identify critical layers using entropy analysis on validation data
  2. Prepare parallel English-target language instruction pairs
  3. Forward pass extracts hidden states at layers i, j, L
  4. Compute three losses based on chosen supervision type (logits vs. feature)
  5. Backpropagate combined loss

- **Design tradeoffs**: 
  - Logits vs. feature supervision: Logits is stricter, better for generation tasks; feature is more relaxed, better for understanding tasks and cross-lingual transfer
  - Layer selection: Earlier supervision may interfere with model's original capabilities; later supervision may conflict with language reversion stage

- **Failure signatures**: 
  - Catastrophic translation performance in enâ†’target direction when using logits-based language conversion supervision
  - Performance degradation when English thinking supervision applied too late (after model begins language reversion)
  - Minimal improvement if selected layers don't align with actual processing stages

- **First 3 experiments**: 
  1. **Entropy profiling**: Pass non-English inputs through base model, compute layer-wise entropy to identify critical layers i and j for your specific model and language pair
  2. **Supervision type ablation**: Compare DFT-logits vs. DFT-feature on a single language pair across QA and NLU tasks to determine optimal supervision type for your use case
  3. **Single-stage supervision**: Test language conversion (LC) and English thinking (ET) supervision independently to understand which stage contributes more to your target task performance

## Open Questions the Paper Calls Out

### Open Question 1
How can critical layer selection be made more precise than the entropy-based approach, given that token-level variations within samples cause the current method to be imprecise? The conclusion states variations among tokens suggest this guidance is still imprecise.

### Open Question 2
Why does logits-based language conversion supervision cause catastrophic degradation in English-to-target-language translation (en-zh drops from 68.37 to 36.79 COMET), and can this interference with the Language Reversion stage be mitigated?

### Open Question 3
Does DFT generalize to low-resource languages lacking parallel instruction data for supervision signal construction? Experiments cover only Chinese, Vietnamese, and Arabic using translated Stanford Alpaca data.

### Open Question 4
What determines the optimal choice between logits-based and feature-based supervision for a given task type, and can they be combined dynamically? The ablation study shows task-dependent preferences but no principled selection criterion.

## Limitations

- Language Pair Generalization: Effectiveness may not generalize uniformly across all language families, particularly languages with non-Latin scripts
- Critical Layer Selection Precision: Entropy-based method remains imprecise with token-level variations within samples
- Performance Trade-offs: Logits-based supervision at early layers can cause performance degradation in translation tasks

## Confidence

**High Confidence**: DFT significantly outperforms traditional fine-tuning across multiple tasks and languages; feature-based supervision is more robust for understanding tasks; entropy analysis reveals two distinct processing stages

**Medium Confidence**: The three-stage processing pipeline is universal across English-centric LLMs; layer 15 is optimal for English thinking supervision; performance improvements transfer to languages beyond tested ones

**Low Confidence**: Entropy-based layer selection reliably identifies critical supervision points for any language pair; method generalizes to extremely low-resource languages; computational overhead is negligible

## Next Checks

1. **Cross-Lingual Generalization Test**: Apply DFT to a language pair with significantly different script (e.g., English-Japanese) and verify whether the three-stage pipeline holds

2. **Dynamic Layer Selection**: Implement token-level entropy analysis rather than layer-level to determine if critical points vary significantly across tokens within the same sample

3. **Computational Overhead Benchmarking**: Measure exact increase in training time, memory usage, and convergence speed when applying DFT compared to standard fine-tuning