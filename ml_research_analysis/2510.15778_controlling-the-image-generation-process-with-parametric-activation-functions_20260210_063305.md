---
ver: rpa2
title: Controlling the image generation process with parametric activation functions
arxiv_id: '2510.15778'
source_url: https://arxiv.org/abs/2510.15778
tags:
- functions
- activation
- network
- image
- generative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a novel interactive system for controlling
  image generative models by replacing static activation functions with parametric
  ones. The system provides a graphical interface allowing users to select and adjust
  activation function parameters in real-time while observing the resulting changes
  in generated images.
---

# Controlling the image generation process with parametric activation functions

## Quick Facts
- arXiv ID: 2510.15778
- Source URL: https://arxiv.org/abs/2510.15778
- Reference count: 4
- This paper presents a novel interactive system for controlling image generative models by replacing static activation functions with parametric ones.

## Executive Summary
This paper introduces an interactive system that enables real-time control of image generative models by replacing static activation functions with parametric versions. The system provides a graphical interface where users can select activation functions and adjust their parameters while observing immediate changes in generated images. Demonstrated on StyleGAN2 and BigGAN models, the method allows users to manipulate image structure and style through intuitive parameter adjustments rather than requiring deep technical knowledge of neural networks.

## Method Summary
The method operates entirely at inference time, requiring no training. Pre-trained StyleGAN2 and BigGAN models are modified by replacing static activation functions with parametric alternatives including SinLU, ReLUN, ShiLU, and polynomial functions. These parametric functions introduce tunable parameters that can be adjusted via a graphical interface in real-time. The system allows users to select specific layers (mapping network vs. generator, early vs. late) and apply different parametric activation functions to each, with immediate visual feedback showing how changes affect the generated output.

## Key Results
- Parametric activation functions in the mapping network affect image structure by altering the disentangled latent vector
- Earlier network layers provide higher granularity of control compared to later layers, which mainly affect coloration
- The approach offers an interpretable way to interact with generative models, potentially improving AI literacy among non-expert users

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Modifying activation functions in the mapping network affects image structure by altering the disentangled latent vector.
- Mechanism: Parametric activation functions change intermediate feature maps during inference. When applied to the mapping network (which disentangles the input latent vector), these changes propagate to the disentangled representation, causing structural changes in the final output.
- Core assumption: The mapping network's role in disentanglement makes it sensitive to activation function modifications in ways that affect downstream structural generation.
- Evidence anchors:
  - [abstract] "parametric activation functions in the mapping network affected image structure"
  - [section] "Using them in the mapping network affected the image structure. These structural changes are due to parametric activation functions affecting the resulting output of the mapping network, i.e. the disentangled latent vector."
  - [corpus] Limited direct corpus support; neighboring papers focus on different control methods rather than mapping network manipulation.
- Break condition: If the mapping network is already highly robust to activation perturbations, or if the disentangled representation has redundancies that buffer against changes, structural effects would diminish or become unpredictable.

### Mechanism 2
- Claim: Earlier network layers provide higher granularity of control compared to later layers.
- Mechanism: Earlier layers process more fundamental features that cascade through subsequent processing stages. Changes at early stages compound through the network hierarchy, while later layers have already received highly processed features and can mainly modify surface-level attributes like coloration.
- Core assumption: Feature hierarchy in generative models means early-layer modifications have more extensive downstream effects than late-layer modifications.
- Evidence anchors:
  - [abstract] "Earlier layers provided a higher granularity of control, while later layers mainly affected coloration"
  - [section] "Earlier layers of the mapping network offered a high level of granularity with respect to changes in the image" and "Later layers of the generator network caused changes to images in a more basic manner, such as altering the overall coloration of the image"
  - [corpus] Corpus neighbor "Gradient Descent as a Shrinkage Operator for Spectral Bias" discusses activation function influence on spectral bias, potentially supporting hierarchical feature processing assumptions.
- Break condition: If network architecture doesn't follow hierarchical feature abstraction (e.g., highly skip-connected architectures), or if early layers are specifically trained to be robust to perturbations.

### Mechanism 3
- Claim: Real-time visual feedback enables users to learn network behavior through trial-and-error experimentation, even without precise feature targeting.
- Mechanism: The GUI provides immediate visual response to parameter changes, allowing users to build mental models of how network structure affects output. This creates an interpretable interaction loop where users can correlate specific architectural modifications with visual changes.
- Core assumption: Users can develop useful intuitions about neural network behavior through observation-based learning, even without understanding the underlying mathematics.
- Evidence anchors:
  - [abstract] "The approach offers an interpretable way to interact with generative models, potentially improving AI literacy among non-expert users"
  - [section] "Through continued use and real-time visual feedback, users can learn how the structural state of the network influences the output of the generation process"
  - [corpus] "POET: Supporting Prompting Creativity" addresses user interaction with generative models, though focused on prompting rather than architectural manipulation.
- Break condition: If the relationship between parameters and outputs is too complex or non-monotonic for humans to learn patterns; paper explicitly notes "a user study will need to be conducted" to confirm educational effectiveness.

## Foundational Learning

- Concept: **Activation Functions in Neural Networks**
  - Why needed here: The entire method relies on understanding that activation functions introduce non-linearity and that parametric versions allow dynamic behavior modification during inference.
  - Quick check question: Can you explain why replacing ReLU with a sigmoid would change network behavior differently than changing network weights?

- Concept: **Latent Space and Disentanglement**
  - Why needed here: StyleGAN2's mapping network specifically disentangles the latent vector; understanding this explains why mapping network modifications affect structure while generator modifications affect style/appearance.
  - Quick check question: What does it mean for a latent representation to be "disentangled," and why might this matter for controllability?

- Concept: **Feature Map Hierarchy in CNNs**
  - Why needed here: The observation that early vs. late layers provide different control granularity depends on understanding how features evolve through network depth.
  - Quick check question: Why do early convolutional layers typically learn edges/textures while later layers learn object-level features?

## Architecture Onboarding

- Component map:
  - Base Generator (StyleGAN2 or BigGAN) -> Parametric Activation Layer Wrapper -> GUI Frontend
  - Base Generator (StyleGAN2 or BigGAN) -> Latent Vector Editor (optional)
  - Base Generator (StyleGAN2 or BigGAN) -> Layer Disabler (optional)

- Critical path:
  1. Load pre-trained StyleGAN2/BigGAN model
  2. Identify target layers (mapping network vs. generator, early vs. late)
  3. Replace static activation functions with parametric versions (SinLU, ReLUN, ShiLU, or polynomial)
  4. Initialize parameters to approximate original activation behavior
  5. User adjusts parameters via GUI sliders with real-time image generation feedback
  6. Iterate through layer/parameter combinations for exploration

- Design tradeoffs:
  - **SinLU vs. ReLUN vs. ShiLU**: SinLU offers most expressiveness (amplitude + frequency) but can produce unpredictable results at high parameter values; ReLUN simplest (single parameter) but limited control range; ShiLU balances simplicity with 2D control
  - **Polynomial activations**: Extremely sensitive to parameter changes, limited to 1-2 layers before output degrades; not recommended for beginners
  - **Mapping network vs. generator targeting**: Mapping network provides structural control but requires understanding of latent space; generator more intuitive but mixes style/structure effects

- Failure signatures:
  - **Image collapse/completely unrecognizable output**: Parameter values too extreme (e.g., SinLU amplitude/frequency set too high); reset to near-original values
  - **No visible change despite parameter adjustment**: Layer has minimal contribution to current image features; try different layer or different input latent vector
  - **Color artifacts only, no structural change**: Likely modifying late generator layers; move to earlier layers or mapping network
  - **Gradient-like artifacts or grid patterns**: Polynomial activation instability; reduce parameter range or switch to non-polynomial functions
  - **Inconsistent results across similar inputs**: Network is highly sensitive to specific latent regions; this is expected behavior, not a bug

- First 3 experiments:
  1. **Baseline calibration**: Load StyleGAN2-FFHQ, generate 5-10 faces with default settings. Then replace one activation in the first mapping network layer with SinLU. Slowly adjust amplitude parameter from 0.0 to 2.0 while observing structural changes. Document the parameter range where changes remain realistic vs. become abstract.
  2. **Layer depth comparison**: Using the same base image, apply identical SinLU parameters to (a) an early mapping network layer, (b) an early generator layer, and (c) a late generator layer. Compare the nature and magnitude of changes to verify the paper's claims about granularity and control type.
  3. **Activation function comparison**: Fix a specific layer and input image. Test SinLU, ReLUN, and ShiLU with comparable parameter modifications. Document which function provides the most intuitive control for your use case, noting that paper suggests SinLU enables more abstract/creative outputs while ReLUN/ShiLU may be more predictable.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does interactive manipulation of parametric activation functions improve non-expert users' understanding of generative model mechanics and increase AI literacy?
- Basis in paper: [explicit] The conclusion states "But to confirm these speculations, a user study will need to be conducted" regarding the tool's potential to teach users "the importance of its various parts" and "promote an increase in AI literacy."
- Why unresolved: No user study was conducted; educational benefit remains theoretical speculation based on tool design.
- What evidence would resolve it: Controlled user study measuring AI literacy before and after tool use, compared against a control group using standard interfaces.

### Open Question 2
- Question: Can parametric activation function control be effectively adapted to text-to-image diffusion models?
- Basis in paper: [explicit] The conclusion suggests "applying this method to the text-to-image generative network can alleviate this problem" (imprecision), but notes "there are still no guarantees that users will be able to find a satisfactory collection of activation functions and their parameters."
- Why unresolved: Only tested on GAN architectures (StyleGAN2, BigGAN); diffusion models have fundamentally different architectures (U-Net with attention).
- What evidence would resolve it: Successful implementation on a diffusion model with demonstrated user control over generation outcomes.

### Open Question 3
- Question: How can the method be enhanced to enable feature-specific control rather than global trial-and-error manipulation?
- Basis in paper: [explicit] The paper acknowledges "our method does not offer any way to single out any specific feature of the image, the process largely consists of trial-and-error experimentation."
- Why unresolved: No mechanism currently maps activation parameters to semantic attributes or specific image features.
- What evidence would resolve it: Development of a mapping between parameter configurations and semantic changes, validated through targeted editing tasks.

### Open Question 4
- Question: Are there more stable parametric activation function formulations that maintain control across deeper network layers?
- Basis in paper: [inferred] Polynomial functions "were extremely sensitive to small changes in parameter values" and yielded "non-ideal results" beyond 2 layers, suggesting stability remains an unsolved design challenge.
- Why unresolved: Only three parametric function families were tested; broader function space remains unexplored.
- What evidence would resolve it: Systematic evaluation of alternative parametric families measuring stability and usable depth range.

## Limitations
- Lack of precision for guided image generation, making it unsuitable for professional creative workflows
- Sensitivity to parameter values, with high values causing unpredictable outputs
- No quantitative metrics for control effectiveness or user experience

## Confidence
- **High** confidence in core mechanism effectiveness based on documented visual results
- **Low** confidence in educational effectiveness claims pending user studies
- **Medium** confidence in cross-architecture generalizability based on current GAN-only testing

## Next Checks
1. Conduct a controlled user study measuring learning outcomes and task completion rates for non-expert users interacting with the system versus traditional GAN interfaces.
2. Implement a quantitative metric for control granularity by measuring the correlation between parameter changes and specific visual feature modifications across different layers.
3. Test the method on diffusion-based generative models to assess cross-architecture applicability and identify whether similar layer-depth control patterns emerge.