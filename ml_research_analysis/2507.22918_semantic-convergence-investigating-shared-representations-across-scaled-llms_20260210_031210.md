---
ver: rpa2
title: 'Semantic Convergence: Investigating Shared Representations Across Scaled LLMs'
arxiv_id: '2507.22918'
source_url: https://arxiv.org/abs/2507.22918
tags:
- layers
- svcca
- features
- feature
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study examines whether two language models of different sizes
  (Gemma-2-2B and Gemma-2-9B) develop shared internal representations despite their
  four-fold scale difference. Using sparse autoencoders to decompose activations into
  interpretable features, the authors aligned features across models via correlation
  and compared their spaces using SVCCA and RSA metrics.
---

# Semantic Convergence: Investigating Shared Representations Across Scaled LLMs
## Quick Facts
- arXiv ID: 2507.22918
- Source URL: https://arxiv.org/abs/2507.22918
- Reference count: 14
- Key outcome: Middle layers of 2B and 9B Gemma models align most strongly (SVCCA ~0.7, RSA ~0.15-0.2), suggesting shared semantic features across scales.

## Executive Summary
This study investigates whether language models of different sizes develop shared internal representations by comparing a 2B and 9B parameter Gemma model. Using sparse autoencoders to decompose activations into interpretable features, the authors align and compare feature spaces across models using SVCCA and RSA metrics. Results show strongest alignment in middle layers, with consistent patterns across single-token, multi-token, and semantic subspace analyses, supporting the hypothesis of feature universality across model scales.

## Method Summary
The researchers employed sparse autoencoders to decompose model activations into interpretable features, then aligned features across the 2B and 9B Gemma models using correlation-based matching. They compared the aligned feature spaces using SVCCA (Singular Vector Canonical Correlation Analysis) and RSA (Representational Similarity Analysis) metrics across different layers. The study examined alignment patterns using single-token inputs, multi-token inputs, and semantic subgroups, with random baseline comparisons to establish statistical significance.

## Key Results
- Middle layers show strongest alignment (SVCCA ~0.7, RSA ~0.15-0.2) between models
- Early and late layers demonstrate significantly less similarity than middle layers
- Alignment patterns persist across single-token, multi-token, and overlapping semantic subspaces
- Statistical significance confirmed (p < 0.001) against random pairing baselines

## Why This Works (Mechanism)
The convergence of internal representations across different model scales suggests that language models, despite architectural differences, converge on similar solutions for encoding semantic information. The middle layer alignment indicates that semantic abstraction occurs at similar representational depths regardless of model size. Sparse autoencoders successfully decompose activations into interpretable features that capture meaningful semantic relationships, allowing for cross-model comparison through correlation-based alignment.

## Foundational Learning
- Sparse Autoencoders: Decompose high-dimensional activations into sparse, interpretable feature vectors; needed for extracting meaningful semantic units from model activations; check by visualizing top activating examples for each feature.
- SVCCA Analysis: Measures representational similarity by comparing aligned subspaces; needed to quantify alignment quality beyond correlation; check by examining canonical correlation values and alignment stability across runs.
- RSA (Representational Similarity Analysis): Compares representational geometries using distance matrices; needed to capture higher-order similarity patterns; check by visualizing representational dissimilarity matrices.

## Architecture Onboarding
Component map: Input tokens -> Sparse Autoencoder decomposition -> Feature correlation alignment -> SVCCA/RSA comparison -> Statistical validation
Critical path: SAE extraction → correlation-based alignment → similarity metric computation → baseline comparison
Design tradeoffs: Sparse autoencoders balance interpretability with reconstruction accuracy; correlation-based alignment assumes semantic equivalence implies high correlation; single-architecture focus limits generalizability claims
Failure signatures: Poor reconstruction quality in SAEs → noisy feature alignment; low correlation values → failed alignment; inconsistent layer patterns → methodological issues
First experiments: 1) Verify SAE feature interpretability with manual inspection of top activations, 2) Test alignment robustness by varying SAE hyperparameters, 3) Compare alignment results using alternative similarity metrics (e.g., centered kernel alignment)

## Open Questions the Paper Calls Out
None identified in the provided materials.

## Limitations
- Reliance on sparse autoencoders with unexamined hyperparameter sensitivity
- Correlation-based alignment may conflate statistical with functional similarity
- Results limited to single architecture family (Gemma), restricting universality claims
- No control for potential dataset overlap between training corpora

## Confidence
High confidence: Layer-specific alignment peaks and statistical significance against random baselines
Medium confidence: Interpretation of aligned features as shared semantic concepts
Low confidence: Claims about universal feature convergence across all architectures and scales

## Next Checks
1. Replicate alignment results using alternative feature decomposition methods to test SAE hyperparameter robustness
2. Conduct targeted intervention experiments to measure functional correspondence of aligned features
3. Extend cross-model alignment tests to different architectural families and non-overlapping datasets