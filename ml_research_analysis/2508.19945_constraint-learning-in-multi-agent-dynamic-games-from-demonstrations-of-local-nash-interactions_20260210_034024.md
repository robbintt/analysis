---
ver: rpa2
title: Constraint Learning in Multi-Agent Dynamic Games from Demonstrations of Local
  Nash Interactions
arxiv_id: '2508.19945'
source_url: https://arxiv.org/abs/2508.19945
tags:
- constraints
- constraint
- each
- agent
- safe
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes an inverse dynamic game framework to learn
  multi-agent interaction constraints from demonstrations. The key idea is to formulate
  a mixed-integer linear program (MILP) that encodes the Karush-Kuhn-Tucker (KKT)
  conditions of a forward dynamic game, where agents interact strategically under
  coupled constraints.
---

# Constraint Learning in Multi-Agent Dynamic Games from Demonstrations of Local Nash Interactions

## Quick Facts
- **arXiv ID:** 2508.19945
- **Source URL:** https://arxiv.org/abs/2508.19945
- **Reference count:** 40
- **Primary result:** Inverse dynamic game framework learns multi-agent interaction constraints from Nash equilibrium demonstrations using MILP-encoded KKT conditions, providing inner approximations of safe sets.

## Executive Summary
This paper addresses the problem of learning unknown interaction constraints in multi-agent dynamic games from demonstrations of local Nash equilibrium behavior. The key insight is that KKT conditions (stationarity, primal/dual feasibility, complementary slackness) provide a bridge between observed trajectories and constraint parameters. By formulating an inverse optimization problem that finds constraint parameters consistent with these KKT conditions, the method recovers the structure of interaction constraints like collision avoidance, velocity-dependent obstacles, and polytopic safety regions. The approach uses mixed-integer linear programming to handle the logical structure of constraints and provides theoretical guarantees that the learned constraints form conservative (inner) approximations of true safe sets, enabling safe motion planning under uncertainty.

## Method Summary
The method formulates an inverse problem to recover unknown constraint parameters θ from demonstrations D assumed to be at local Nash equilibrium. It encodes the KKT conditions of the forward dynamic game as a feasibility problem (Eq. 7) or relaxed minimization (Eq. 12), using mixed-integer linear programming with Big-M formulations to handle logical constraints like unions of polytopes and complementary slackness. The solution yields a set of feasible parameters F(D) that are consistent with the demonstrated equilibrium behavior. Volume extraction over this parameter set provides guaranteed safe and unsafe regions for downstream motion planning, with theoretical guarantees that these regions are inner approximations of the true sets.

## Key Results
- Recovers constraint parameters across multiple types: elliptical, polytopic, spherical, velocity-dependent, and nonlinear constraints
- Works with various agent dynamics: double integrator, unicycle, and quadcopter models
- Validated in both simulation and hardware experiments with up to 5 agents
- Learned constraints enable safe motion planning that outperforms baseline cost inference methods
- Computational tractability demonstrated even for large-scale problems with many agents

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Unknown interaction constraints can be recovered by finding constraint parameters and Lagrange multipliers that satisfy the KKT conditions of the forward dynamic game for provided demonstrations.
- **Mechanism:** Treats demonstrations as evidence of local Nash equilibrium, setting up a feasibility problem (Eq. 7) to solve for constraint parameter θ and dual variables λ such that primal feasibility, dual feasibility, complementary slackness, and stationarity hold simultaneously.
- **Core assumption:** Demonstrations are generated by agents playing local Nash equilibrium strategies under unknown constraints.
- **Evidence anchors:** [abstract] "Specifically, we introduce mixed-integer linear programs (MILP) encoding the Karush-Kuhn-Tucker (KKT) conditions... which recover constraints consistent with the Nash stationarity." [section IV-A] "Conversely, the solution set of (7) encodes parameter values θ consistent with the local Nash stationarity of D."

### Mechanism 2
- **Claim:** The feasible set of parameters learned from the inverse problem provides an inner approximation of the true safe set, guaranteeing safety in downstream planning.
- **Mechanism:** The solution yields a set of valid parameters F(D), and any trajectory safe for every parameter in F(D) is guaranteed safe for the unknown true parameter θ*.
- **Core assumption:** Demonstrations contain at least one trajectory that activates unknown constraints.
- **Evidence anchors:** [abstract] "Theoretical results establish that the learned constraints provide inner approximations of the true safe and unsafe sets." [section IV-A] Theorem 1 proves G_s(D) ⊆ S(θ*).

### Mechanism 3
- **Claim:** The nonlinear logic of union constraints and complementary slackness can be encoded as a Mixed-Integer Linear Program for tractable computation.
- **Mechanism:** Uses Big-M formulations to convert logical conditions into linear constraints with binary variables, transforming non-convex inverse optimization into a linear structure solvable by standard solvers.
- **Core assumption:** Unknown constraints can be parameterized as affine functions of state or parameterized offsets allowing linearization.
- **Evidence anchors:** [section IV-B] "We now reformulate the KKT conditions (4) as an MILP... via the big-M formulation." [abstract] "...introduce mixed-integer linear programs (MILP) encoding the KKT conditions..."

## Foundational Learning

- **Concept: Generalized Nash Equilibrium (GNE)**
  - **Why needed here:** Multi-agent interactions require modeling coupled constraints where one agent's admissible state space depends on another's (e.g., collision avoidance).
  - **Quick check question:** Can you explain why a trajectory that minimizes cost for Agent 1 might not be a Nash equilibrium if Agent 2 is also moving strategically?

- **Concept: KKT Conditions (Karush-Kuhn-Tucker)**
  - **Why needed here:** This is the mathematical bridge between "optimal behavior" and "constraint parameters."
  - **Quick check question:** If a constraint is strictly satisfied (inequality is strict, e.g., distance > 0), what must be true of the corresponding Lagrange multiplier, and how does the "Big-M" method enforce this?

- **Concept: Mixed-Integer Linear Programming (MILP)**
  - **Why needed here:** To implement the solver for the inverse problem.
  - **Quick check question:** Why is "Big-M" formulation necessary to linearize the complementary slackness condition λ · g = 0?

## Architecture Onboarding

- **Component map:** Demonstrations (D) + Known Costs (J_i) + Constraint Structure (g_k, h) -> Inverse Solver (MILP) -> Parameter Extractor (F(D)) -> Volume Extractor -> Motion Planner
- **Critical path:** The formulation of Eq. (33) in Section B.1 of the Appendix, specifically ensuring slack variables R correctly linearize the product of binary variables and Lagrange multipliers.
- **Design tradeoffs:**
  - Completeness vs. Tractability: MILP is exact for offset-parameterized constraints but relies on linearization relaxations for affine-parameterized ones (Sec B.2)
  - Constraint Shape: Method assumes parametric family; misspecification degrades accuracy (Sec V-F)
- **Failure signatures:**
  - Unbounded Solutions: M (Big-M constant) too small or too large
  - Stationarity Error: Demos far from Nash equilibrium; switch to relaxed formulation (Eq. 12)
  - Ambiguity: Trajectories too safe; constraints never active; returns wide parameter range (Theorem 4)
- **First 3 experiments:**
  1. **Sanity Check (Double Integrator):** Generate trajectories using known ground-truth constraints, then feed into inverse solver. Verify if recovered θ matches ground truth exactly (Sec V-B).
  2. **Robustness Test (Volume Extraction):** Provide demonstration activating only 3 out of 4 sides of box constraint. Verify planner generates trajectory respecting un-activated side via conservative volume extraction (Fig. 10).
  3. **Sub-optimality Handling (Hardware):** Run solver on noisy hardware data using relaxed cost formulation (Eq. 12). Check if safe planning remains possible despite imperfect stationarity (Sec V-G).

## Open Questions the Paper Calls Out

- **Temporally-extended interaction constraints:** The method infers instantaneous constraints but doesn't address constraints that depend on the history or sequence of interactions.
- **Unknown parameterization inference:** Current method relies on known parametric forms; future work will explore Gaussian processes for non-parametric constraint inference.
- **Joint inference of costs and constraints:** The paper assumes known cost functions, but in practice agent objectives are often unknown.

## Limitations
- Relies heavily on demonstrations being generated at local Nash equilibrium; performance degrades with noisy or suboptimal demonstrations
- Requires at least one demonstration to activate each constraint boundary for unique recovery; insufficient activation leads to trivially large safe sets
- Linearization approximations for affine-parameterized constraints introduce error that is not quantified

## Confidence

**High:** Theoretical guarantees (Theorem 1) that learned constraints provide inner approximations of true safe sets, with proof structure clearly established.

**Medium:** MILP formulation correctly handles logical constraints through Big-M formulations, but linearization relaxations for affine-parameterized constraints introduce approximation error not fully characterized.

**Low:** Sensitivity to demonstration quality is acknowledged but not systematically analyzed; the relaxed formulation (Eq. 12) admits feasibility under imperfect stationarity, but degradation in constraint quality is unclear.

## Next Checks

1. **Sensitivity Analysis:** Systematically vary the deviation from Nash equilibrium in demonstrations and measure the impact on constraint recovery accuracy to quantify robustness of the relaxed formulation (Eq. 12).

2. **Constraint Sufficiency Test:** Design experiments providing demonstrations that activate only subsets of constraint boundaries and measure the volume of resulting feasible parameter set to verify against theoretical predictions from Theorem 4.

3. **Linearization Error Quantification:** Implement both exact MILP (for offset parameters) and linearized version (for affine parameters) on identical problems and measure constraint recovery error to establish practical impact of linearization approximation.