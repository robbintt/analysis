---
ver: rpa2
title: 'The Irrational Machine: Neurosis and the Limits of Algorithmic Safety'
arxiv_id: '2510.10823'
source_url: https://arxiv.org/abs/2510.10823
tags:
- when
- energy
- agent
- cost
- while
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work catalogues neurosis-like behaviours in embodied AI\u2014\
  such as flip-flop, plan churn, perseveration loops, paralysis, hypervigilance, futile\
  \ search, belief incoherence, tie-break thrashing, corridor thrashing, optimality\
  \ compulsion, metric mismatch, policy oscillation, myopic ping-pong, and exploration\
  \ paralysis\u2014and pairs each with lightweight detectors and deterministic escape\
  \ policies (short commitments, margins to switch, temporal smoothing, and principled\
  \ arbitration). It shows that phobic avoidance can persist under full visibility\
  \ when learned aversive costs dominate local choice, producing long detours despite\
  \ globally safe routes."
---

# The Irrational Machine: Neurosis and the Limits of Algorithmic Safety

## Quick Facts
- arXiv ID: 2510.10823
- Source URL: https://arxiv.org/abs/2510.10823
- Reference count: 28
- This work catalogues neurosis-like behaviours in embodied AI and proposes lightweight detectors with deterministic escape policies

## Executive Summary
This paper presents a comprehensive taxonomy of neurosis-like behaviours in embodied AI systems, ranging from flip-flop and plan churn to hypervigilance and optimality compulsion. The work demonstrates that even under full visibility, agents can exhibit phobic avoidance behaviours that persist despite globally safe routes being available. To surface these failures systematically, the paper introduces a genetic programming approach for destructive testing that evolves adversarial scenarios to maximise safety, compliance, and efficiency pressures.

## Method Summary
The approach pairs each identified neurosis with lightweight detectors and deterministic escape policies, including short commitments, margins to switch, temporal smoothing, and principled arbitration. For surfacing global failures, genetic programming evolves worlds and perturbations to maximise conflicting objectives, generating adversarial curricula and counterfactual traces. This framework aims to expose where architectural revision is required rather than merely applying symptom-level patches.

## Key Results
- Catalogued nine distinct neurosis behaviours including flip-flop, perseveration loops, paralysis, and hypervigilance
- Demonstrated that phobic avoidance can persist under full visibility when learned aversive costs dominate local choice
- Proposed genetic programming approach for destructive testing that evolves adversarial scenarios to maximise safety, compliance, and efficiency pressures

## Why This Works (Mechanism)
The framework works by treating neuroses as systematic failure modes with detectable signatures and deterministic countermeasures. Each neurosis emerges from specific interaction patterns between agent architecture and environmental structureâ€”for instance, metric mismatch occurs when local optimization criteria diverge from global objectives. The genetic programming approach systematically explores the space of possible environmental configurations and perturbations to identify where these divergences manifest as catastrophic failures.

## Foundational Learning
**Neurosis Detection** - Why needed: To identify failure modes before they cause real-world harm. Quick check: Verify detectors trigger reliably across diverse agent architectures and scenarios.
**Deterministic Escape Policies** - Why needed: To provide immediate, predictable recovery mechanisms. Quick check: Test escape policies under varying stress conditions to ensure they don't introduce new failure modes.
**Genetic Programming for Destructive Testing** - Why needed: To systematically discover failure modes that manual testing might miss. Quick check: Validate that evolved scenarios are genuinely challenging and not trivially escapable.

## Architecture Onboarding

**Component Map**: Sensors -> State Estimator -> Policy Generator -> Action Executor -> Environment -> Reward/Cost Monitor

**Critical Path**: Perception -> Decision-making -> Action -> Feedback loop with real-time neurosis detection

**Design Tradeoffs**: Deterministic escape policies offer predictability but may sacrifice efficiency; genetic programming provides thorough testing but requires significant computational resources

**Failure Signatures**: Metric mismatch shows as suboptimal path choices despite known better routes; hypervigilance manifests as excessive computation on minor state variations; paralysis appears as decision deadlock under uncertainty

**First Experiments**:
1. Implement flip-flop detector and escape policy on a simple grid-world agent
2. Test metric mismatch detection on a pathfinding task with conflicting reward structures
3. Evaluate genetic programming's ability to surface corridor thrashing in maze navigation

## Open Questions the Paper Calls Out
None

## Limitations
- Empirical validation across diverse agent architectures remains limited
- Genetic programming approach has unclear scalability for real-world applications
- Effectiveness depends heavily on fitness function design and may miss complex multi-agent failure modes

## Confidence
- Taxonomy comprehensiveness: Medium
- Phobic avoidance demonstration: Medium
- Genetic programming scalability: Low

## Next Checks
1. Implement cross-architecture validation testing the nine neurosis detectors across at least three distinct RL frameworks (e.g., PPO, DQN, model-based planners) to assess detector robustness.
2. Conduct ablation studies on the genetic programming fitness function components to determine which pressures most effectively surface safety-critical failures versus false positives.
3. Design controlled experiments comparing the deterministic escape policies against learned recovery strategies to quantify performance trade-offs in safety-critical versus efficiency-critical scenarios.