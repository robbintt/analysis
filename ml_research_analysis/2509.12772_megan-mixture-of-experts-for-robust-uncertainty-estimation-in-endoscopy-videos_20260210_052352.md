---
ver: rpa2
title: 'MEGAN: Mixture of Experts for Robust Uncertainty Estimation in Endoscopy Videos'
arxiv_id: '2509.12772'
source_url: https://arxiv.org/abs/2509.12772
tags:
- uncertainty
- megan
- predictions
- estimation
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MEGAN, a novel uncertainty quantification
  (UQ) framework that addresses inter-rater variability in medical image analysis
  by aggregating predictions and uncertainties from multiple EDL models trained on
  diverse expert annotations. MEGAN employs a gating network to optimally combine
  outputs from six independently trained EDL models, each using different expert labels
  and modeling strategies.
---

# MEGAN: Mixture of Experts for Robust Uncertainty Estimation in Endoscopy Videos

## Quick Facts
- arXiv ID: 2509.12772
- Source URL: https://arxiv.org/abs/2509.12772
- Reference count: 27
- Primary result: 3.5% improvement in F1-score and 30.5% reduction in Expected Calibration Error (ECE) for ulcerative colitis severity assessment

## Executive Summary
MEGAN introduces a novel uncertainty quantification framework that addresses inter-rater variability in medical image analysis by aggregating predictions and uncertainties from multiple Evidential Deep Learning (EDL) models trained on diverse expert annotations. The framework employs a gating network to optimally combine outputs from six independently trained EDL models, each using different expert labels and modeling strategies. Evaluated on endoscopy videos for ulcerative colitis severity assessment, MEGAN achieved significant improvements in both accuracy and calibration compared to existing methods, while also demonstrating the ability to identify cases requiring expert review.

## Method Summary
MEGAN combines six independently trained EDL models (four using central reader scores, two using local reader scores) with different architectures to capture inter-rater variability. Each EDL model uses Softplus activation to generate non-negative evidence values that parameterize Dirichlet distributions for uncertainty estimation. A gating network, trained with a composite loss function (classification + uncertainty regularization + epsilon refinement), optimally aggregates the outputs. The framework uses a foundation model (ViT-B + DINOv2) for feature extraction, applies attention-based multiple instance learning (ABMIL) for video aggregation, and implements heuristic penalty weights to improve calibration.

## Key Results
- Achieved 3.5% improvement in F1-score compared to existing methods
- Reduced Expected Calibration Error (ECE) by 30.5% on unseen QUASAR data
- Identified confident and uncertain cases enabling selective expert review and potentially reducing annotation burden by 10%

## Why This Works (Mechanism)

### Mechanism 1: EDL for Single-Pass Uncertainty
Evidential Deep Learning models class probabilities as Dirichlet distributions rather than point estimates. The Softplus activation generates non-negative evidence values that parameterize these distributions, with uncertainty u_i = C/S_i emerging directly from total evidence strength. This enables computationally efficient uncertainty estimation without requiring multiple forward passes like Monte Carlo Dropout or Deep Ensembles.

### Mechanism 2: Multi-Expert Aggregation
Training multiple EDL models on different expert annotations captures inter-rater variability as signal rather than noise. Six independent models (using central and local reader labels with diverse architectures) encode different expert perspectives as evidence distributions. The gating network learns which expert model to trust for different input features, creating a more robust aggregation than simple averaging.

### Mechanism 3: Composite Loss for Calibration
The gating network's three-loss training function (classification + uncertainty regularization + epsilon refinement) improves calibration by explicitly penalizing confident-wrong predictions and rewarding uncertain-correct ones. Heuristic penalty weights (β₁=γ₁=1.0, β₂=γ₂=5.0) create gradient pressure toward calibrated confidence, with the epsilon term allowing fine-grained uncertainty adjustment.

## Foundational Learning

- **Dirichlet Distribution for Uncertainty**
  - Why needed here: Core mathematical object EDL uses to represent uncertainty; understanding concentration parameters α is essential for interpreting model outputs
  - Quick check question: If α = [2, 2, 2, 2] for 4-class MES scoring, what is the uncertainty and what does it mean clinically?

- **Expected Calibration Error (ECE)**
  - Why needed here: Primary evaluation metric; measures whether predicted confidence matches empirical accuracy
  - Quick check question: A model with ECE=0.15 makes predictions with average confidence 0.85. What can you infer about its accuracy?

- **Multiple Instance Learning (MIL) with Attention**
  - Why needed here: Videos have N frames but single MES label; ABMIL aggregates frame-level features into video-level predictions
  - Quick check question: Why would attention-based aggregation outperform mean-pooling for endoscopy videos where only some frames show disease?

## Architecture Onboarding

- **Component map:**
  Input Video → Frame Extraction → Foundation Model (ViT-B + DINOv2) → N×D features → [×6 parallel EDL models] → Transformer → ABMIL → Dense → Softplus → Dirichlet(α) → Gating Network → Weighted Aggregation → Final MES prediction + Uncertainty

- **Critical path:** Foundation model feature quality → EDL model diversity (different expert labels + architectures) → Gating network training with frozen EDL weights → Composite loss optimization

- **Design tradeoffs:**
  - 6× EDL models = 6× inference cost vs. single model (but still 1× forward pass per model, unlike MC Dropout's 40×)
  - MEGAN-Naive (simple averaging) vs. MEGAN-Gated (learned weighting): Gated adds ~4 MLP training complexity but achieves 2.6% better ECE
  - Heuristic penalty weights (β, γ) require validation set tuning; may not transfer across clinical trial populations

- **Failure signatures:**
  - Class 2 uncertainty separation fails (paper notes: "this pattern reverses for class 2, which remains ambiguous even for experts")
  - ECE increases on unseen trial data → gating network overfit to training expert label distributions
  - Uncertainty scores don't distinguish correct/incorrect predictions → L_unc regularization insufficient

- **First 3 experiments:**
  1. **Reproduce EDL baseline:** Train single EDL model on central reader labels; verify ECE < 0.2 on held-out set before proceeding to multi-model
  2. **Ablate gating components:** Compare MEGAN-Naive vs. MEGAN-Gated with L_eps=0 vs. full loss; quantify contribution of epsilon refinement
  3. **Validate uncertainty stratification:** Apply class-specific thresholds (t_c) to unseen data; confirm confident samples achieve ≥10% higher F1 than uncertain samples

## Open Questions the Paper Calls Out
- Can MEGAN maintain its superior calibration and accuracy when applied to medical imaging modalities beyond endoscopy, such as histopathology or radiology?
- How can the framework be refined to better handle "ambiguous" intermediate disease classes where the uncertainty signal currently fails to distinguish correct from incorrect predictions?
- To what extent does the heuristic selection of uncertainty penalty weights (β, γ) impact the robustness of the gating network across diverse datasets?

## Limitations
- Framework's dependence on multiple expert annotations per case limits applicability to datasets where such annotations are unavailable
- Computational overhead of training and maintaining six EDL models may be prohibitive for resource-constrained settings
- Class-specific uncertainty thresholds show promising separation for classes 0, 1, and 3, but fail to provide reliable separation for class 2

## Confidence
- High confidence: Core methodology combining EDL with multi-expert aggregation is well-specified and theoretically grounded
- Medium confidence: Generalization of heuristic penalty weights across different clinical populations remains uncertain
- Low confidence: Class-specific uncertainty thresholds fail to distinguish correct from incorrect predictions for class 2

## Next Checks
1. **Generalization testing:** Evaluate MEGAN on endoscopy datasets from different manufacturers or disease types to verify uncertainty estimates remain calibrated under domain shift
2. **Ablation study:** Systematically remove components (L_eps, specific expert models) to quantify their individual contributions to the observed performance improvements
3. **Clinical utility validation:** Measure actual annotation burden reduction by having human experts review only the 10% most uncertain cases predicted by MEGAN, then compare to random selection