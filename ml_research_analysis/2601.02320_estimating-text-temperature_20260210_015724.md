---
ver: rpa2
title: Estimating Text Temperature
arxiv_id: '2601.02320'
source_url: https://arxiv.org/abs/2601.02320
tags:
- temperature
- text
- estimate
- generation
- estimated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method to estimate the temperature of any
  text (including human-written text) with respect to a given language model. The
  approach uses maximum likelihood estimation to calculate the temperature that best
  explains the observed token probabilities given the model's logits.
---

# Estimating Text Temperature

## Quick Facts
- arXiv ID: 2601.02320
- Source URL: https://arxiv.org/abs/2601.02320
- Authors: Nikolay Mikhaylovskiy
- Reference count: 4
- Key outcome: Proposes a method to estimate text temperature using maximum likelihood estimation on token probabilities, finding Qwen3-14B-Base as the best estimator and revealing corpus-specific temperature patterns.

## Executive Summary
This paper introduces a novel method to estimate the temperature of any text (including human-written text) with respect to a given language model. The approach uses maximum likelihood estimation to calculate the temperature that best explains the observed token probabilities given the model's logits. The author evaluates various small-to-medium LLMs on their ability to estimate temperatures of texts generated by other models, finding that models within the same family perform better at estimating each other's temperatures. Qwen3-14B-Base emerges as the best estimator overall. When applied to popular corpora, most texts show temperatures close to 1, with notable exceptions including jokes, GSM8K, and AG News (higher temperature around 1.1) and Python code (lower temperature around 0.9).

## Method Summary
The paper proposes estimating text temperature through maximum likelihood estimation on token probabilities. Given a text and a language model, the method calculates the temperature parameter that maximizes the likelihood of observing the given token probabilities under the model's logits. The temperature τ is estimated by solving for the parameter that best explains the observed distribution of tokens. The approach assumes a log-uniform prior over temperature values and uses numerical optimization to find the maximum likelihood estimate. The method is evaluated across multiple model families (Qwen, Llama, granite) and applied to various corpora to reveal temperature patterns in different text types.

## Key Results
- Qwen3-14B-Base achieves the best performance in estimating temperatures of texts generated by other models
- Texts from the same model family are estimated more accurately by models within that family
- Most popular English corpora show temperatures close to 1, with jokes/GSM8K/AG News at ~1.1 and Python code at ~0.9
- The method reveals systematic temperature differences across text types but shows discrepancies between estimated and generation temperatures at high values

## Why This Works (Mechanism)
The temperature parameter in language models controls the randomness of token selection by scaling the logits before applying softmax. Higher temperatures produce more uniform probability distributions, while lower temperatures create more peaked distributions. By working backwards from observed token probabilities to infer the temperature that best explains them, the method captures how deterministic or random a given text appears relative to a specific model's distribution. The maximum likelihood approach finds the temperature parameter that maximizes the probability of observing the actual token sequence under the model's predicted logits.

## Foundational Learning

**Language Model Logits**: Raw, unnormalized scores output by the model before softmax transformation.
*Why needed*: Form the basis for temperature scaling and probability calculation.
*Quick check*: Verify logits sum to non-zero values and have appropriate magnitude.

**Softmax Function**: Converts logits into probability distributions.
*Why needed*: Temperature scaling directly modifies logits before softmax application.
*Quick check*: Confirm probabilities sum to 1.0 after softmax.

**Temperature Scaling**: Multiplies logits by 1/τ before softmax.
*Why needed*: Core mechanism for controlling output randomness.
*Quick check*: Test with τ=1 (no scaling), τ>1 (more uniform), τ<1 (more peaked).

**Maximum Likelihood Estimation**: Statistical method for finding parameters that best explain observed data.
*Why needed*: Provides the mathematical framework for temperature inference.
*Quick check*: Verify optimization converges and likelihood increases monotonically.

## Architecture Onboarding

**Component Map**: Text -> Tokenization -> Model Logits -> Temperature Scaling -> Probability Distribution -> Likelihood Calculation -> Temperature Estimation

**Critical Path**: The estimation process requires computing token probabilities under different temperature hypotheses and finding the temperature that maximizes likelihood. This involves iterating through possible temperature values and evaluating the joint probability of the observed text under each hypothesis.

**Design Tradeoffs**: The method trades computational efficiency for accuracy, as it requires multiple likelihood calculations across temperature values. Using log-uniform priors assumes equal probability across temperature scales, which may not reflect actual generation practices.

**Failure Signatures**: Estimation fails at low temperatures due to saturation (multiple temperatures produce identical outputs), and shows systematic bias at high temperatures where estimated values diverge from generation temperatures. Models from different families show reduced estimation accuracy.

**First 3 Experiments**:
1. Test temperature estimation on synthetic texts with known temperatures (0.1, 0.5, 1.0, 2.0) to verify accuracy
2. Compare estimation performance across different model families using held-out validation texts
3. Apply the method to diverse text types (news, code, creative writing) to characterize temperature distributions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can regularization techniques resolve the ill-posed problem of temperature estimation in low-temperature saturation regions?
- Basis in paper: The author notes that estimation at low temperatures is an "ill-posed problem" because different temperatures produce identical results (saturation), suggesting regularization as a future direction.
- Why unresolved: The current maximum likelihood approach fails to distinguish between generation parameters when the text is nearly deterministic.
- What evidence would resolve it: A modified estimation algorithm incorporating regularization that successfully recovers distinct temperature values for texts generated at T < 0.1.

### Open Question 2
- Question: What explains the systematic discrepancy between estimated and generation temperatures in high-temperature ranges?
- Basis in paper: The paper observes that the estimated temperature diverges from the generation temperature at high values, stating, "We don’t yet have an explanation for the discrepancy."
- Why unresolved: The observed phenomenon is documented empirically but lacks a theoretical justification regarding the model's probability distributions or the estimation equation's behavior at extreme values.
- What evidence would resolve it: A theoretical analysis or ablation study identifying the specific mathematical property of the softmax or logits that causes the estimator to bias low/high at high temperatures.

### Open Question 3
- Question: Why do specific corpora such as jokes and math problems yield higher estimated temperatures while code yields lower ones?
- Basis in paper: The author finds statistically significant deviations (1.1 for Jokes/GSM8K vs. 0.9 for Python) and lists "explaining these temperature phenomena" as a topic for future research.
- Why unresolved: The paper demonstrates the method's ability to detect these differences but does not investigate the underlying linguistic or structural features driving them.
- What evidence would resolve it: A study correlating specific textual attributes (e.g., lexical diversity, syntactic constraints, reasoning steps) with the estimated temperature shift.

## Limitations

- All experiments use English text only, limiting generalizability to other languages
- Evaluation focuses on small-to-medium models (7-14B parameters) rather than frontier models
- The method assumes log-uniform temperature priors which may not reflect actual generation practices
- Estimation accuracy varies significantly across model families, with cross-family estimation showing reduced performance

## Confidence

- Temperature estimation method: High - The mathematical framework is sound and the estimation procedure is clearly defined
- Model family temperature estimation patterns: Medium - While consistent patterns emerge, the sample size of model families is limited
- Temperature values for specific corpora: Medium - The measurements appear reliable but may not generalize to all English text types
- Cross-lingual applicability: Low - No non-English validation was performed

## Next Checks

1. Test temperature estimation accuracy on larger frontier models (70B+ parameters) to assess scalability and potential changes in estimation patterns
2. Conduct cross-lingual experiments with non-English corpora to evaluate method applicability across languages
3. Compare estimated temperatures with alternative measures of text diversity and randomness to validate the temperature interpretation