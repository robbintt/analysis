---
ver: rpa2
title: Ordering-based Causal Discovery via Generalized Score Matching
arxiv_id: '2601.16249'
source_url: https://arxiv.org/abs/2601.16249
tags:
- score
- causal
- data
- discrete
- matching
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a score matching framework for causal discovery
  from discrete observational data, a previously unexplored extension beyond continuous
  domains. The authors propose a novel identifiability theory that leverages a generalized
  discrete score function to infer topological ordering of DAGs without assuming additive
  noise or parametric functional forms.
---

# Ordering-based Causal Discovery via Generalized Score Matching

## Quick Facts
- **arXiv ID:** 2601.16249
- **Source URL:** https://arxiv.org/abs/2601.16249
- **Reference count:** 40
- **Primary result:** Novel score matching framework extends causal discovery to discrete observational data, improving F1 accuracy and SID metrics across synthetic and real-world datasets.

## Executive Summary
This paper introduces a score matching framework for causal discovery from discrete observational data, a previously unexplored extension beyond continuous domains. The authors propose a novel identifiability theory that leverages a generalized discrete score function to infer topological ordering of DAGs without assuming additive noise or parametric functional forms. Their key contribution is Condition 2, which establishes that leaf node identifiability is guaranteed under a non-decreasing randomness property w.r.t. a measure of entropy/variance-like functions. Empirically, the proposed discrete SCORE method improves F1 accuracy and SID metrics across simulated and real-world datasets, even under loose assumptions. The framework also offers practical diagnostic tools for validating inferred orders, marking a significant advance in causal discovery from categorical variables.

## Method Summary
The method learns a topological ordering of a DAG from discrete (categorical) observational data through iterative leaf identification. It defines a generalized discrete score function using marginalization instead of gradients, then applies Fisher divergence concepts to categorical data. The algorithm identifies leaf nodes by maximizing the expected randomness (entropy or variance) of the reciprocal discrete score, iteratively removes identified leaves, and uses the resulting order to constrain standard DAG learning algorithms like PC or GES. A continuous-time discrete diffusion model (Transformer-based) estimates the intractable singleton conditionals required for score calculation.

## Key Results
- Improved F1 accuracy and SID metrics compared to baseline methods on both synthetic (ER and Scale-Free graphs) and real-world datasets
- Successful inference of topological orders with low D_top divergence even under loose assumptions about data generation
- Validated effectiveness across sample sizes from 10,000 to 20,000 observations and variable cardinalities of 3-6

## Why This Works (Mechanism)

### Mechanism 1: Leaf Identification via Discrete Score Discriminant
The method identifies leaf nodes by finding the variable that maximizes the expected randomness of its reciprocal discrete score. This works because Condition 2 guarantees that if the "non-decreasing randomness" property holds across the causal graph, the leaf will have the highest expected score randomness. The discrete score is defined as 1/p(x_i|x_{-i}), making it applicable to categorical data where gradients are undefined.

### Mechanism 2: Generalized Score Matching for Discrete Domains
Unlike continuous score matching which uses gradients, this framework uses a marginalization operator to define the score as M_i p(x) / p(x) = 1/p(x_i|x_{-i}). This generalization enables the application of Fisher divergence concepts to categorical data without requiring gradient information, making score matching theoretically sound for discrete variables.

### Mechanism 3: Iterative Topological Ordering
The algorithm recovers a full causal order by repeatedly identifying and removing the leaf node. This transforms the combinatorial DAG search problem into a sequential node-sorting problem, where each iteration prunes one variable and appends it to the ordering. The process continues until all variables are ordered, then uses this order to constrain standard DAG learning algorithms.

## Foundational Learning

- **Schur-concavity and Majorization**: Needed because the paper relies on measures of randomness (like Entropy) which must be Schur-concave functions to theoretically guarantee that "more uniform" distributions yield higher scores. Quick check: Why is Shannon Entropy a valid measure of "randomness" for identifying leaves in this framework?

- **Topological Ordering in DAGs**: Essential because the entire method hinges on the equivalence between a valid DAG and the existence of a topological order. Understanding that parents must precede children is crucial for the pruning step. Quick check: If we have a topological order, how does that constrain the search space for parent sets?

- **Continuous-time Discrete Diffusion Models**: Used to estimate the intractable singleton conditionals p(x_i|x_{-i}). The authors adopt the approach from Sun et al. (2022) to handle discrete states without gradients. Quick check: How does a diffusion model estimate probabilities for discrete states without a gradient?

## Architecture Onboarding

- **Component map**: Input (Discrete dataset X) -> Estimator (Discrete diffusion model) -> Scorer (Expected randomness calculation) -> Selector (Leaf identification) -> Iterator (Removal and repeat) -> Pruner (Edge constraint application)
- **Critical path**: The estimation of singleton conditionals p(X_j|x_{-j}) via the diffusion model is the computational bottleneck and primary source of statistical error.
- **Design tradeoffs**: 
  - Accuracy vs. Speed: Diffusion model must be retrained at every iteration (O(d) × Training Time), versus faster amortized models that may lose accuracy
  - Randomness Measure: Choice between Entropy vs. Variance depends on dataset properties; paper suggests diagnosing data to choose
- **Failure signatures**:
  - High SHD with Low D_top: Failure in Pruning step (edge insertion/deletion logic), not order inference
  - Order Collapse: Noisy entropy estimates may identify non-leaves as leaves, resulting in random permutation
- **First 3 experiments**:
  1. Synthetic Validation (ER Graphs): Generate random Erdos-Rényi DAGs with uniform CPTs, run algorithm to verify D_top ≈ 0
  2. Ablation on Randomness Measure: Compare Shannon Entropy vs. Variance on real dataset (e.g., Sachs) to observe which better satisfies non-decreasing randomness
  3. Pruning Strategy Comparison: Apply fixed inferred order to PC algorithm, compare "Edge Pruning" vs. "Edge Insertion" strategies to optimize F1 score

## Open Questions the Paper Calls Out
None

## Limitations
- Computational cost of retraining diffusion model at every iteration scales exponentially (O(1.1^d) hours), limiting scalability to larger graphs
- Empirical validation of Condition 2's non-decreasing randomness property on real-world datasets remains partially unverified
- Practical diagnosis tool for selecting between variance and entropy lacks specific implementation thresholds

## Confidence

- **High confidence**: Mathematical framework for generalized score matching in discrete domains (Section 2) and formal statement of leaf identification theorem (Theorem 1)
- **Medium confidence**: Empirical results showing improved F1 and SID metrics across synthetic and real datasets, though underlying assumptions' validity on real data remains partially unverified
- **Low confidence**: Practical applicability of Condition 2 to arbitrary real-world categorical datasets without systematic validation of randomness monotonicity property

## Next Checks

1. **Condition verification on real data**: Apply practical diagnosis tool to Sachs and Alarm datasets to empirically verify non-decreasing randomness holds locally at each iteration, documenting cases where it fails

2. **Scalability benchmark**: Measure training time and order quality (D_top) for graphs with d=20, 30, and 40 nodes to quantify exponential scaling and identify practical limits

3. **Randomness measure ablation**: Systematically compare Shannon Entropy vs. Variance as randomness measure φ across multiple synthetic datasets with varying conditional dependence strength to determine which measure is more robust to violations of Condition 2