---
ver: rpa2
title: 'Generative AI Practices, Literacy, and Divides: An Empirical Analysis in the
  Italian Context'
arxiv_id: '2512.03671'
source_url: https://arxiv.org/abs/2512.03671
tags:
- genai
- users
- usage
- adoption
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study provides the first comprehensive empirical analysis
  of Generative AI (GenAI) chatbot adoption, usage patterns, and literacy in Italy.
  Analyzing survey data from 1,906 Italian-speaking adults, the research reveals widespread
  GenAI adoption (80.5%) that surpasses established technologies like voice assistants.
---

# Generative AI Practices, Literacy, and Divides: An Empirical Analysis in the Italian Context

## Quick Facts
- arXiv ID: 2512.03671
- Source URL: https://arxiv.org/abs/2512.03671
- Reference count: 40
- Key outcome: First comprehensive empirical analysis revealing widespread GenAI adoption (80.5%) exceeding voice assistants, driven by convenience over accuracy, with significant gender gaps unexplained by literacy alone

## Executive Summary
This study provides the first comprehensive empirical analysis of Generative AI chatbot adoption, usage patterns, and literacy in Italy. Analyzing survey data from 1,906 Italian-speaking adults, the research reveals widespread GenAI adoption (80.5%) that surpasses established technologies like voice assistants. Users primarily adopt GenAI for convenience and versatility rather than accuracy, with learning and information retrieval being the most frequent uses. However, literacy levels remain low even among users, with many unable to recognize errors or distinguish AI-generated content from human text. The study identifies significant gender disparities in both adoption and usage frequency, with women half as likely to adopt GenAI and using it less frequently across all intents. Notably, literacy only partially explains these gender gaps, suggesting other barriers beyond technical competence are at play.

## Method Summary
Survey-based empirical analysis of GenAI chatbot adoption, usage patterns, and digital literacy among Italian-speaking adults. Data from n=1,906 Italian-speaking adults (1,533 users, 373 non-users) collected May-August 2025 via Qualtrics, publicly available. Primary outcomes are GenAI adoption (binary) and usage frequency across 6 intents (0-3 scale). Literacy measured via 6-item Likert scale (0-1 normalized). Method includes logistic regression predicting adoption with odds ratios, six separate OLS regressions predicting usage frequency per intent, and BERTopic clustering for open-ended responses. VIF multicollinearity checks performed (all <1.2).

## Key Results
- GenAI adoption (80.5%) exceeds voice assistants (47.4%), smartphones (93.6%), and social media (82.4%)
- Users adopt primarily for convenience (38%) and flexibility/personalization (30%), not accuracy (19%) or reliability (8%)
- Women have half the odds of men adopting GenAI (OR=0.50), with literacy explaining only 34% of adoption gap and ~15% of usage gaps
- Literacy strongly predicts adoption but NOT usage frequency for information retrieval, creating vulnerability where low-literacy users engage most with potentially unreliable outputs

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** GenAI adoption is driven by usability advantages (convenience, flexibility) rather than perceived accuracy or trustworthiness, leading to displacement of existing technologies.
- **Mechanism:** Users replace specialized tools with general-purpose GenAI chatbots because conversational interfaces reduce friction across multiple workflows, regardless of whether outputs are more accurate.
- **Core assumption:** Users optimize for interaction efficiency over output reliability when both options are "good enough" for common tasks.
- **Evidence anchors:** [abstract] "Users primarily adopt GenAI for convenience and versatility rather than accuracy"; [section 4.1] "convenience (38%) and flexibility/personalization (30%) dominate users' motivations, while accuracy (19%), reliability (8%), and transparency (2%) play secondary roles"

### Mechanism 2
- **Claim:** Literacy strongly predicts GenAI adoption but does NOT predict usage frequency for all intents—creating a vulnerability where the most accessible use cases (information retrieval) attract users with the lowest error-detection capacity.
- **Mechanism:** Information Retrieval requires minimal prompt engineering and is therefore accessed regardless of literacy; other intents (Content Creation, Problem Solving) show literacy-dependent frequency patterns.
- **Core assumption:** Information-seeking via chatbots has lower cognitive barriers than creative or analytical tasks.
- **Evidence anchors:** [section 4.4] "LT literacy—the strongest predictor of GenAI adoption—has no predictive power for how frequently a user would rely on GenAI to search for new information"; [section 4.4] "Information Retrieval...shows striking anomalies regarding digital factors—neither LT literacy nor prior experience significantly predict information-seeking frequency"

### Mechanism 3
- **Claim:** Gender gaps in GenAI adoption and usage persist even after controlling for literacy, education, and socioeconomic status—suggesting mechanisms beyond technical competence.
- **Mechanism:** Women adopt at half the rate of men (OR=0.50) and use less frequently across ALL intents, but measured factors explain only 34% of adoption gap and ~15% of usage gaps.
- **Core assumption:** Unmeasured factors (trust, perceived utility, social norms, privacy concerns) drive the residual gap.
- **Evidence anchors:** [abstract] "literacy only partially explains these gender gaps, suggesting other barriers beyond technical competence are at play"; [section 4.4] "women have half the odds of men (OR = 0.50)...the majority of gender disparities remain unexplained by measured factors"

## Foundational Learning

- **Concept: Digital divide decomposition (adoption vs. usage)**
  - Why needed here: The paper shows different predictors for initial adoption vs. ongoing usage patterns; conflating these leads to incorrect intervention design.
  - Quick check question: "Does this intervention target the adoption barrier (getting started) or the usage barrier (continued engagement)?"

- **Concept: Odds ratios vs. marginal effects**
  - Why needed here: OR=20.82 for literacy sounds massive, but translating to probability differences requires marginal effect calculation; the gender OR=0.50 translates to ~half the adoption probability.
  - Quick check question: "If I double this odds ratio, does the probability double, increase slightly, or depend on baseline?"

- **Concept: Self-reported literacy limitations**
  - Why needed here: Users rate themselves around neutral (0.23 on -1.5 to +1.5 scale) on recognizing errors; actual error-detection ability may be lower than self-reports suggest.
  - Quick check question: "Is this literacy measure based on demonstrated skill or self-perception, and how might they diverge?"

## Architecture Onboarding

- **Component map:** Adoption layer (onboarding flows, first-use tutorials, platform discovery) -> Usage tracking (intent classification, frequency logging, work/personal context) -> Literacy assessment (error recognition tests, bias awareness probes, limitation understanding) -> Demographic monitoring (gender, age, education, SES stratification for gap detection)

- **Critical path:** 1. User discovers GenAI → 2. Initial adoption (literacy- and experience-gated) → 3. Intent-specific usage (patterns vary by demographics) → 4. Error encounters (39.5% report errors; 24.3% unsure) → 5. Continued use OR abandonment

- **Design tradeoffs:**
  - Accessibility vs. safety: Making Information Retrieval easy increases adoption among low-literacy users who cannot evaluate outputs
  - Personalization vs. privacy: Voice input convenience (12 prefer it) vs. audio data concerns (14 cite privacy)
  - English vs. local language: 52% use English for perceived reliability, but this excludes non-English speakers

- **Failure signatures:**
  - High adoption + low literacy: Users treating chatbot outputs as authoritative without verification
  - Intent-skewed usage: Over-reliance on Information Retrieval among older adults (65+ show lowest literacy, highest info-seeking)
  - Demographic blindspots: Underrepresentation of women in usage data biasing future model improvements

- **First 3 experiments:**
  1. **Literacy-embedded onboarding:** Add brief error-recognition exercises at first use; measure whether post-onboarding usage shows more diverse intents and lower error-blindness.
  2. **Intent-specific safety UI:** For high-risk intents (Medical Advice, Fact Checking—24.3% and 23.5% usage), append visible uncertainty indicators; A/B test impact on user trust calibration.
  3. **Gender gap root cause probe:** Survey non-adopting women with targeted questions on trust, privacy, and social norms; compare against adopting women and men to isolate residual factors.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** What sociocultural and psychological mechanisms beyond technical competence explain the persistent gender gap in GenAI adoption and usage intensity?
- **Basis in paper:** [explicit] The authors state that literacy only partially explains gender disparities, "suggesting the gap operates through mechanisms beyond technical competence, education, or socioeconomic status—potentially including differences in interest, perceived utility, privacy concerns, or gendered norms around technology adoption."
- **Why unresolved:** Regression models with controls explained only 34% of the gender gap in adoption and 15% in usage frequency, leaving most disparity unaccounted for.
- **What evidence would resolve it:** Mixed-methods research combining surveys on attitudes, trust, and social norms with qualitative interviews probing motivations, perceived risks, and social influences on technology use among men and women.

### Open Question 2
- **Question:** How do urban-rural differences affect GenAI adoption patterns in Italy?
- **Basis in paper:** [explicit] The authors note their analysis "did not capture urban-rural distinctions, which concurrent research identifies as a meaningful predictor of GenAI adoption in the US, thus suggesting an important avenue for future investigation."
- **Why unresolved:** The online survey methodology equalized internet access across geographic regions, masking potential divides; only macro-regional (North/Centre/South) data were collected.
- **What evidence would resolve it:** A stratified survey sampling urban, suburban, and rural populations with questions about infrastructure access, local social networks, and community technology norms.

### Open Question 3
- **Question:** How will GenAI adoption, literacy, and usage divides evolve longitudinally as the technology matures?
- **Basis in paper:** [inferred] The cross-sectional 2025 snapshot cannot capture trends; the authors acknowledge rapid evolution and make data publicly available "to enable longitudinal monitoring."
- **Why unresolved:** Adoption patterns may shift as GenAI becomes normalized; literacy may improve or stagnate; demographic gaps may narrow, persist, or widen.
- **What evidence would resolve it:** Repeated waves of the same survey with comparable measures over multiple years, tracking changes within demographic cohorts and identifying temporal drivers of convergence or divergence.

## Limitations
- Self-reported literacy bias: Literacy measure relies on self-perception rather than demonstrated error-detection ability, likely overestimating actual competence
- Temporal validity: Data collection (May-August 2025) captures snapshot during rapid GenAI evolution; adoption patterns may shift significantly within months
- Demographic sampling constraints: Sample over-represents educated individuals (69.4% graduates vs. 15% nationally), potentially underestimating literacy gaps

## Confidence

**High confidence:** GenAI adoption exceeds voice assistants (80.5% vs. 47.4%), gender disparities in adoption and usage are real and substantial, literacy predicts adoption but not information-seeking frequency.

**Medium confidence:** Literacy only partially explains gender gaps; unmeasured factors drive residual differences. GenAI displaces existing technologies through convenience advantages rather than accuracy.

**Low confidence:** Literacy levels among users are "low" - this depends heavily on self-report validity and lacks external benchmarks for comparison.

## Next Checks
1. **Error-detection validation:** Conduct blinded experiments comparing users' self-reported ability to recognize AI errors against actual performance on controlled test sets.
2. **Longitudinal tracking:** Re-survey the same cohort after 6-12 months to measure how adoption, literacy, and usage patterns evolve with interface changes and increased exposure.
3. **Non-adopter barrier analysis:** Deep-dive interviews with women who declined adoption to identify trust, privacy, and utility factors beyond technical competence that explain the residual gender gap.