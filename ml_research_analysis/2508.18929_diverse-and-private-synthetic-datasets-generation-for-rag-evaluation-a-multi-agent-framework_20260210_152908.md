---
ver: rpa2
title: 'Diverse And Private Synthetic Datasets Generation for RAG evaluation: A multi-agent
  framework'
arxiv_id: '2508.18929'
source_url: https://arxiv.org/abs/2508.18929
tags:
- generation
- evaluation
- privacy
- diversity
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the need for evaluation datasets that are both
  diverse and privacy-preserving in Retrieval-Augmented Generation (RAG) systems.
  The authors propose a multi-agent framework that generates synthetic QA datasets
  for RAG evaluation.
---

# Diverse And Private Synthetic Datasets Generation for RAG evaluation: A multi-agent framework

## Quick Facts
- arXiv ID: 2508.18929
- Source URL: https://arxiv.org/abs/2508.18929
- Reference count: 34
- Primary result: Multi-agent framework generates diverse and privacy-preserving synthetic QA datasets for RAG evaluation, outperforming baselines in diversity and achieving 75-90% privacy masking accuracy.

## Executive Summary
This paper introduces a three-agent LangGraph framework for generating synthetic QA datasets tailored for RAG evaluation. The system addresses the dual challenges of maximizing semantic diversity while preserving privacy through PII detection and masking. By decoupling these objectives into specialized agents (Diversity, Privacy, and QA Curation), the framework achieves strong performance on both diversity metrics and privacy compliance across multiple domains.

## Method Summary
The framework employs a sequential three-agent pipeline orchestrated by LangGraph. First, the Diversity Agent embeds the input corpus and applies k-means clustering to select representative samples that maximize topical coverage. Second, the Privacy Agent (GPT-4.1) scans these samples for predefined PII categories and applies context-aware pseudonymization. Finally, the QA Curation Agent (GPT-4o) synthesizes diverse and private QA pairs from the sanitized content. The optimal number of clusters is selected via intra-cluster distance scores, and all LLM interactions use temperature=0 for deterministic outputs.

## Key Results
- Outperforms RagasGen and DirPrmpt baselines in all evaluated settings for diversity
- Achieves strong privacy masking accuracy (75-90%) across PII, PHI, and PWI entity types
- CosineSim2toDiversity score becomes less negative (closer to zero) compared to baselines
- Consistently improves diversity metrics while maintaining robust PII detection and masking performance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Cluster-based sampling reduces semantic redundancy more effectively than random or direct prompting methods.
- **Mechanism:** Diversity Agent embeds corpus and applies k-means clustering, selecting representatives from each cluster to ensure coverage of latent topics rather than over-sampling high-frequency themes.
- **Core assumption:** Text embeddings accurately capture semantic similarity such that cluster centroids represent distinct topical clusters.
- **Evidence anchors:** Diversity agent leverages clustering techniques; outperforms baselines with less negative CosineSim2toDiversity scores; related work supports diversity challenges in synthetic generation.
- **Break condition:** If embedding model fails to distinguish nuanced domain concepts, clusters will conflate distinct topics, reducing effective diversity.

### Mechanism 2
- **Claim:** Decoupling privacy detection into specialized agent improves masking accuracy over standard generation constraints.
- **Mechanism:** Privacy Agent (GPT-4.1) explicitly scans for defined PII categories and applies context-aware pseudonymization before QA synthesis, preventing leakage of sensitive data.
- **Core assumption:** LLM has reliable reasoning capabilities to identify entity boundaries and types without dedicated NER model.
- **Evidence anchors:** Privacy Agent shows strong performance with 75-90% accuracy; active research in privacy-preserving synthetic generation validates approach.
- **Break condition:** If agent encounters novel PII types not covered in instructions or prompt context window truncates sensitive sections, masking will fail.

### Mechanism 3
- **Claim:** Sequential pipeline architecture allows optimization of individual objectives without direct trade-offs in single generation step.
- **Mechanism:** Chaining Diversity → Privacy → QA Curation separates selection from sanitization and generation phases, preventing diversity mechanism from being constrained by privacy filters.
- **Core assumption:** Errors do not compound significantly across stages (diverse samples not rendered useless by aggressive masking).
- **Evidence anchors:** Algorithm 1 outlines sequential interaction; LangGraph orchestrates inter-agent communication; multi-agent structures validated by related work like GAMA and MAGneT.
- **Break condition:** If Privacy Agent removes critical context necessary for complex reasoning questions, QA Curation Agent may generate trivial or unanswerable questions.

## Foundational Learning

- **Concept: RAG (Retrieval-Augmented Generation)**
  - **Why needed here:** Framework is designed to evaluate RAG systems, which retrieve external context to augment LLM prompts. Understanding this distinction is necessary to see why "ground truth" QA pairs must be derived from specific documents.
  - **Quick check question:** Can you explain why evaluating a RAG system requires a different dataset strategy than evaluating a standard LLM?

- **Concept: Vector Embeddings & Clustering**
  - **Why needed here:** Diversity Agent relies on k-means clustering of text embeddings. Without understanding text-to-vector conversion where distance implies similarity, the diversity mechanism is opaque.
  - **Quick check question:** If two documents are far apart in the vector space used by Diversity Agent, what does that imply about their semantic content?

- **Concept: PII vs. PHI vs. PWI**
  - **Why needed here:** Privacy Agent distinguishes between Personally Identifiable Information (PII), Protected Health Information (PHI), and Professional Work Information (PWI). Distinguishing these is critical for configuring privacy agent for specific domains.
  - **Quick check question:** Which entity type would be most critical to mask in a dataset derived from HR employee records?

## Architecture Onboarding

- **Component map:** Input Corpus (D) → Diversity Agent (Embedding → Clustering → Sampling) → Privacy Agent (PII Scan → Pseudonymization) → QA Curation Agent (QA Synthesis) → Output Datasets
- **Critical path:** Strictly linear dependency chain (Diversity → Privacy → QA). Failure or timeout in Privacy Agent blocks QA Curation Agent entirely. Latency dominated by sequential LLM calls.
- **Design tradeoffs:**
  - Speed vs. Diversity: Increasing clusters (k) improves coverage but increases volume for downstream processing
  - Context vs. Privacy: Aggressive pseudonymization protects privacy but may strip context necessary for complex reasoning questions
  - Static vs. Dynamic Tools: Current tools use static PII lists; future work could adaptively identify entities, suggesting current definitions might miss edge cases
- **Failure signatures:**
  - Low Diversity Scores: Check if k is too low for corpus size or if embeddings are poor quality
  - Missed PII: Check if Privacy Agent temperature >0 or if prompt definitions are too narrow for domain
  - Hallucinated QA: If QA pairs reference information not in source text, check if Curation Agent prompt strictly enforces grounding constraints
- **First 3 experiments:**
  1. Implement "DirPmpt" baseline and clustering method on small sample (10-20 docs), compare pairwise cosine similarity of generated questions
  2. Feed Privacy Agent synthetic sentences with edge-case entities, measure precision/recall of masking
  3. Run pipeline with varying k values (5, 10, 20) on EU AI Act text, plot LLM-as-Judge Diversity Score vs. k

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How resilient are the generated synthetic datasets against active privacy attacks, such as membership inference or data reconstruction attempts?
- **Basis in paper:** Authors state future work will include "rigorous evaluation of the framework's resilience to privacy attacks, helping to clarify its defensive boundaries and inform improvements."
- **Why unresolved:** Current evaluation focuses on Privacy Agent's masking accuracy but does not test robustness against adversarial attacks designed to extract original private data.
- **What evidence would resolve it:** Results from adversarial simulations showing success rate of recovering original PII from synthetic QA pairs compared to baseline datasets.

### Open Question 2
- **Question:** Can the privacy agent improve detection capabilities by dynamically identifying sensitive entities beyond current reliance on static predefined lists?
- **Basis in paper:** Authors list "adaptively identify and transform PIIs beyond static entity lists" as specific goal for enhancing agent autonomy.
- **Why unresolved:** Current implementation relies on "predefined set of PII categories" which may fail to capture novel or context-dependent sensitive information.
- **What evidence would resolve it:** Comparative study evaluating recall of sensitive entities between current static-list agent and tool-augmented agent on dataset with previously unseen PII types.

### Open Question 3
- **Question:** To what extent would implementing explicit agent-to-agent communication protocols improve coordination and output quality?
- **Basis in paper:** Authors state they "plan to explore agent-to-agent communication protocols and effective independent agent collaboration to improve coordination and task delegation among agents."
- **Why unresolved:** Current framework relies on sequential pipeline; unknown if dynamic feedback loops would enhance final dataset quality.
- **What evidence would resolve it:** Ablation studies comparing semantic diversity and privacy compliance of datasets generated using sequential pipeline versus dynamic communication protocols like Model Context Protocol (MCP).

## Limitations
- Prompt transparency issues: Exact agent instructions not disclosed, making reproduction of claimed performance challenging
- Underspecified sampling strategy: Number of samples per cluster and selection criteria could significantly impact diversity metrics
- LLM-as-a-Judge subjectivity: Reliance on LLM evaluation introduces subjectivity without explicit human validation data
- Domain generalizability uncertainty: Performance outside tested EU AI Act and AI4Privacy datasets remains unverified

## Confidence

- **High Confidence:** Sequential pipeline architecture is logically sound and aligns with established multi-agent design patterns; diversity clustering mechanism is well-established
- **Medium Confidence:** Privacy masking performance claims (75-90% accuracy) are plausible but unverified without exact prompts; diversity improvements supported by metrics but depend on LLM judge consistency
- **Low Confidence:** Generalizability to new domains is uncertain; impact of aggressive pseudonymization on QA quality mentioned but not empirically validated

## Next Checks

1. **Prompt Transparency Test:** Contact authors for exact agent prompts or conduct sensitivity analysis by varying prompt instructions and measuring impact on privacy accuracy and QA quality
2. **Human Evaluation Correlation:** Replicate LLM-as-Judge diversity scoring on small subset of generated datasets and compare against human-annotated diversity scores to validate judge's reliability
3. **Ablation on Cluster Sampling:** Systematically vary number of samples per cluster (1, 3, 5) and measure marginal gain in diversity metrics to identify optimal sampling strategy