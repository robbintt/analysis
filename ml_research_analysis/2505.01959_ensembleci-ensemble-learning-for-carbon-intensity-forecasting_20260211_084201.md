---
ver: rpa2
title: 'EnsembleCI: Ensemble Learning for Carbon Intensity Forecasting'
arxiv_id: '2505.01959'
source_url: https://arxiv.org/abs/2505.01959
tags:
- ensembleci
- carboncast
- grids
- carbon
- energy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces EnsembleCI, an adaptive ensemble learning
  approach for carbon intensity forecasting that addresses the limitations of the
  state-of-the-art CarbonCast method. EnsembleCI combines weighted predictions from
  multiple sublearners (LightGBM, CatBoost, and NN) using multi-layer stacking to
  achieve greater flexibility and regional adaptability across 11 different power
  grids.
---

# EnsembleCI: EnsembleCI: Ensemble Learning for Carbon Intensity Forecasting

## Quick Facts
- arXiv ID: 2505.01959
- Source URL: https://arxiv.org/abs/2505.01959
- Reference count: 38
- Primary result: Adaptive ensemble learning approach achieves 19.58% average improvement over state-of-the-art CarbonCast method

## Executive Summary
EnsembleCI introduces an adaptive ensemble learning framework for carbon intensity forecasting that addresses the limitations of the state-of-the-art CarbonCast method. By combining weighted predictions from multiple sublearners (LightGBM, CatBoost, and NN) through multi-layer stacking, EnsembleCI achieves greater flexibility and regional adaptability across 11 different power grids. The method consistently outperforms CarbonCast, achieving the lowest mean absolute percentage error (MAPE) in 10-11 grids while improving prediction accuracy by an average of 19.58% across day-1 through day-4 forecasts.

## Method Summary
EnsembleCI employs a multi-layer stacking approach that combines predictions from three sublearners: LightGBM, CatBoost, and neural networks. The framework uses weighted aggregation of these predictions to create an adaptive ensemble that can be fine-tuned for different power grids. This approach allows for greater flexibility compared to single-model methods and enables region-specific optimization. The ensemble learns optimal weightings for each sublearner based on historical performance, creating a dynamic system that adapts to varying grid characteristics and forecasting horizons.

## Key Results
- EnsembleCI achieves lowest MAPE in 10-11 power grids compared to CarbonCast baseline
- Prediction accuracy improves by average of 19.58% across day-1 through day-4 forecasts
- Shows greater robustness in long-term forecasting with only 3.63% MAPE increase by day 4 (vs CarbonCast's 5.43%)

## Why This Works (Mechanism)
The multi-layer stacking approach allows EnsembleCI to capture diverse patterns in carbon intensity data by leveraging the complementary strengths of different sublearners. LightGBM handles tabular data efficiently, CatBoost manages categorical features well, and neural networks can capture complex non-linear relationships. By learning optimal weightings for each sublearner, the ensemble can adapt to regional variations in power grid characteristics and generation mixes.

## Foundational Learning
- Carbon intensity forecasting: Predicts grams of CO2 per kWh for power grids
  - Why needed: Essential for optimizing electricity consumption timing and reducing emissions
  - Quick check: MAPE values should be below 10% for practical utility

- Ensemble learning: Combines multiple models to improve overall prediction accuracy
  - Why needed: Single models often have blind spots that ensemble methods can overcome
  - Quick check: Ensemble performance should exceed individual sublearner performance

- Multi-layer stacking: Uses predictions from base models as features for meta-learner
  - Why needed: Allows complex interactions between different model predictions
  - Quick check: Cross-validation should show consistent improvement over simple averaging

## Architecture Onboarding
- Component map: Data preprocessing -> Sublearner training (LightGBM, CatBoost, NN) -> Multi-layer stacking -> Weighted aggregation -> Final prediction
- Critical path: Historical data ingestion -> Feature engineering -> Parallel sublearner training -> Stacking layer integration -> Adaptive weighting -> Forecast output
- Design tradeoffs: Computational overhead of multi-layer stacking vs accuracy gains; model complexity vs interpretability
- Failure signatures: Poor performance when grid characteristics significantly differ from training data; overfitting when training data is limited
- First experiments: 1) Compare ensemble performance against individual sublearners on single grid, 2) Test adaptation to new grid with transfer learning, 3) Measure computational latency for real-time deployment

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation relies on historical data from 11 power grids, potentially missing extreme weather events or rapid energy transitions
- Performance in grids with significantly different characteristics than tested remains uncertain
- Computational overhead of multi-layer stacking could pose deployment challenges for real-time applications

## Confidence
- Performance improvement claims: High
- Regional adaptability claims: Medium
- Interpretability claims: Medium

## Next Checks
1. Test EnsembleCI's performance during extreme weather events and grid stress conditions to assess robustness
2. Evaluate computational latency and resource requirements for real-time deployment scenarios
3. Validate feature importance findings across additional power grids with different generation mixes and regulatory frameworks