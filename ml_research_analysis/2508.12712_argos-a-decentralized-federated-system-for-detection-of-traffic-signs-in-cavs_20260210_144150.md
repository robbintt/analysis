---
ver: rpa2
title: 'Argos: A Decentralized Federated System for Detection of Traffic Signs in
  CAVs'
arxiv_id: '2508.12712'
source_url: https://arxiv.org/abs/2508.12712
tags:
- data
- federated
- server
- training
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study proposes a decentralized federated learning framework
  for traffic sign detection in connected and automated vehicles. The method partitions
  traffic sign classes across vehicles, enabling specialized local training with lightweight
  object detectors while preserving privacy by only exchanging model parameters.
---

# Argos: A Decentralized Federated System for Detection of Traffic Signs in CAVs

## Quick Facts
- arXiv ID: 2508.12712
- Source URL: https://arxiv.org/abs/2508.12712
- Reference count: 22
- Primary result: Decentralized federated learning framework for traffic sign detection that improves accuracy from below 0.1 to over 0.8 by increasing server rounds from 2 to 20

## Executive Summary
This study proposes a decentralized federated learning framework for traffic sign detection in connected and automated vehicles. The method partitions traffic sign classes across vehicles, enabling specialized local training with lightweight object detectors while preserving privacy by only exchanging model parameters. Experiments in a simulated environment using the Flower framework evaluated configurations including server rounds (2-20), local epochs (1-20), client participation fractions (10-100%), and data distributions (IID vs non-IID). Results showed accuracy increased from below 0.1 to over 0.8 as server rounds increased from 2 to 20, moderate local epochs (8-10) provided optimal efficiency with accuracies around 0.67, higher client participation fractions enhanced generalization up to 0.83, FedProx outperformed other aggregators in handling heterogeneity, and non-IID distributions reduced performance compared to IID. Training duration primarily scaled with the number of rounds rather than aggregation strategy. The framework offers a scalable, privacy-preserving solution for real-world vehicular deployments, with future work needed to validate on real testbeds and integrate stronger privacy mechanisms.

## Method Summary
The Argos framework uses Flower to coordinate federated learning among simulated connected vehicles for traffic sign detection. Each vehicle runs a fasterrcnn_mobilenet_v3_large_320 model locally on class-partitioned subsets of the Traffic Signs Dataset (Mapillary and DFG Kaggle datasets with 19,000+ images and 30,000+ annotations across 76 classes). Local training uses Adam optimizer (learning rate 0.001) with batch size 4 and data augmentation (scaling, flipping, blurring). The server aggregates model weights using FedAvg, FedAdam, or FedProx strategies across 2-20 rounds, with clients training for 1-20 local epochs. Experiments varied client participation fractions (10-100%) and tested both IID and non-IID data distributions. Evaluation used IoU threshold of 0.1 on a single NVIDIA Tesla P100 GPU.

## Key Results
- Accuracy scales dramatically with server rounds: 2 rounds yields below 0.1 accuracy, while 20 rounds achieves over 0.8 accuracy
- Moderate local epochs (8-10) provide optimal efficiency, with accuracies around 0.67 and diminishing returns beyond 10 epochs
- Higher client participation fractions (up to 100%) enhance generalization, achieving peak accuracy of approximately 0.83
- FedProx outperforms other aggregators in handling non-IID data heterogeneity
- Training duration scales primarily with number of rounds rather than aggregation strategy

## Why This Works (Mechanism)

### Mechanism 1: Iterative Global Coordination Through Server Rounds
Multiple rounds of parameter exchange allow locally-diverged models (trained on class-partitioned data) to incrementally align toward a shared representation that captures all traffic sign classes. Each round reduces divergence caused by heterogeneous local data.

### Mechanism 2: Proximal Regularization for Heterogeneous Data
FedProx adds a proximal term to the local loss function, penalizing deviations from the global model. This bounds how far local optimization can drift when clients only see narrow subsets of sign classes.

### Mechanism 3: Generalization Through Diverse Client Sampling
Each vehicle observes a limited sign-class subset based on local driving environment. Sampling more clients per round ensures the aggregated gradient reflects a fuller label space, reducing overfitting to any subgroup.

## Foundational Learning

### Concept: Federated Learning Basics (FedAvg, Local vs. Global Updates)
- Why needed here: The entire system depends on understanding how local model weights are aggregated without sharing raw data, and why multiple rounds are necessary.
- Quick check question: If three clients have datasets of size 100, 200, and 300 samples respectively, how would FedAvg weight their contributions during aggregation?

### Concept: Object Detection Annotation Formats (YOLO)
- Why needed here: Traffic sign annotations are provided in YOLO format [x_center, y_center, width, height]; misinterpreting these leads to training failures.
- Quick check question: For a 640×480 image, convert a YOLO annotation [0.5, 0.5, 0.1, 0.2] into pixel-space bounding box coordinates.

### Concept: IID vs. Non-IID Data Distribution
- Why needed here: Performance degradation under non-IID conditions is a central finding; understanding why heterogeneity breaks FedAvg is essential for selecting FedProx appropriately.
- Quick check question: If Vehicle A only observes speed-limit signs and Vehicle B only observes stop signs, which aggregator should you expect to perform better—FedAvg or FedProx—and why?

## Architecture Onboarding

### Component Map:
Client Layer (Vehicles) -> Aggregation Server (Flower) -> Communication Layer (V2I)

### Critical Path:
1. Parse YOLO labels → distribute class-partitioned subsets to simulated clients
2. Per-client: Train locally (configurable epochs), extract weights
3. Server: Select client fraction → aggregate weights → update global model
4. Redistribute → repeat for N rounds → evaluate at IoU threshold 0.1

### Design Tradeoffs:
- Server rounds vs. training time: 20 rounds yielded >0.8 accuracy but took 31,000+ seconds; 5 rounds completed in ~12,000 seconds at lower accuracy
- Local epochs vs. returns: 8–10 epochs optimal (~0.67); 20 epochs showed negligible gain over 10 (66.7% vs. 67.0%)
- Participation vs. cost: 100% participation achieved 0.83 accuracy; 10% participation plateaued at ~0.55
- Aggregator choice: FedProx for peak non-IID performance; FedAdam for stable, predictable gains; FedAvg showed erratic behavior in this task

### Failure Signatures:
- Accuracy < 0.2 after 5 rounds: Likely insufficient rounds or near-zero participation; increase round count or participation fraction
- High variance across rounds with FedAvg: Non-IID data causing client drift; switch to FedProx
- IID–Non-IID gap > 15%: Heterogeneity exceeds aggregator robustness; consider clustering clients or limited data sharing
- Training time explosion: Caused by excessive rounds or epochs; cap at 10–15 rounds, 8–10 local epochs

### First 3 Experiments:
1. **IID baseline**: 10 rounds, 8 epochs, FedAdam, 100% participation → establish accuracy upper bound
2. **Non-IID aggregator comparison**: Same setup, class-partitioned data → evaluate FedAvg vs. FedProx vs. FedAdam, select winner
3. **Epoch sweep**: With chosen aggregator, sweep epochs (1, 5, 10, 20) → identify accuracy/efficiency sweet spot before scaling rounds

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the Argos framework maintain detection accuracy and convergence speeds when deployed on real vehicular testbeds with actual network latency?
- Basis in paper: The conclusion states that future work must "validate the approach on real vehicular testbeds," acknowledging the current study relied on a simulated environment.
- Why unresolved: The simulation utilized a single GPU and did not capture real-world variables such as packet loss, bandwidth fluctuations, or hardware constraints of embedded vehicular systems.
- What evidence would resolve it: Experimental results from a physical deployment across moving vehicles demonstrating convergence and latency metrics comparable to the simulation.

### Open Question 2
- Question: How does the framework perform when evaluated using standardized object detection metrics like mAP at stricter IoU thresholds (0.5 and 0.75)?
- Basis in paper: The authors identify the use of a "relaxed IoU threshold" (0.1) as a practical limitation and suggest reporting "standard detection metrics" in future work.
- Why unresolved: The low IoU threshold used in the study may inflate accuracy figures; performance under strict localization requirements remains unproven.
- What evidence would resolve it: A re-evaluation of the trained global models reporting mAP@0.5 and mAP@0.75 scores.

### Open Question 3
- Question: What is the trade-off between privacy and utility when integrating stronger privacy mechanisms like secure aggregation or differential privacy?
- Basis in paper: The paper lists "integrate stronger privacy mechanisms (secure aggregation / differential privacy)" as a specific avenue for future research.
- Why unresolved: While the framework preserves privacy by avoiding raw data sharing, the authors note that model updates can still leak information, yet the cost of mitigating this is unknown.
- What evidence would resolve it: Comparative analysis of accuracy degradation and communication overhead when differential privacy noise or encryption is applied to the weight updates.

## Limitations

- The evaluation used a relaxed IoU threshold of 0.1, which may inflate accuracy figures compared to standard detection metrics
- The study relied on a simulated environment rather than real vehicular testbeds, leaving open questions about performance under actual network conditions
- The framework's privacy protection relies on parameter-only exchange, but model updates can still potentially leak information without stronger mechanisms like differential privacy

## Confidence

- **High Confidence**: The core finding that accuracy scales with server rounds (2→20 rounds: <0.1→>0.8 accuracy) is well-supported by the described experimental sweep and aligns with established federated learning theory about iterative global coordination
- **Medium Confidence**: The FedProx superiority claim for heterogeneous data is plausible given theoretical foundations, but the magnitude of improvement relative to FedAvg under the specific experimental conditions cannot be precisely verified without knowing the partitioning scheme and hyperparameters
- **Medium Confidence**: The local epoch efficiency finding (8-10 epochs optimal) is supported by the described sweeps, though the negligible difference between 10 and 20 epochs (66.7% vs 67.0%) suggests the sweet spot may be even lower than reported

## Next Checks

1. **Reproduce the accuracy-round relationship**: Run a minimal experiment with 5, 10, and 20 server rounds using FedAdam and IID data to verify the dramatic accuracy increase described (below 0.1 at 2 rounds to over 0.8 at 20 rounds)

2. **Test FedProx vs FedAvg under controlled heterogeneity**: Implement a clear non-IID partitioning scheme (e.g., Dirichlet alpha=0.1) and run both aggregators for 10-15 rounds to measure the actual performance gap, ensuring the proximal term (mu) is specified

3. **Validate the epoch efficiency claim**: Run experiments with 1, 5, 8, 10, and 15 local epochs while keeping other parameters constant to precisely identify the point of diminishing returns, particularly to verify whether 8-10 epochs truly represents the optimal trade-off or if the sweet spot is lower