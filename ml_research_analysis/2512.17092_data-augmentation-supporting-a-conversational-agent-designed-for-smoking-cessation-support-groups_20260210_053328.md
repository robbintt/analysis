---
ver: rpa2
title: Data Augmentation Supporting a Conversational Agent Designed for Smoking Cessation
  Support Groups
arxiv_id: '2512.17092'
source_url: https://arxiv.org/abs/2512.17092
tags:
- posts
- data
- support
- conversational
- synthetic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of improving intent detection
  for a conversational agent supporting smoking cessation support groups, where low
  engagement and stigma hinder user participation. To overcome insufficient high-quality
  data for training intent classifiers, the authors employ a two-level data augmentation
  strategy: (1) synthetic data generation using GPT-4 for intents with low F1 scores,
  and (2) real data scraping from a related online support community.'
---

# Data Augmentation Supporting a Conversational Agent Designed for Smoking Cessation Support Groups

## Quick Facts
- arXiv ID: 2512.17092
- Source URL: https://arxiv.org/abs/2512.17092
- Reference count: 21
- Primary result: 32% F1 improvement for intent classifier through synthetic and real data augmentation

## Executive Summary
This paper addresses data scarcity challenges for intent classification in conversational agents supporting smoking cessation groups. The authors employ a two-level augmentation strategy: synthetic data generation using GPT-4 for low-performing intents and real data scraping from an external support community. Human annotators validate both data sources to ensure quality. The augmented dataset achieves a 32% improvement in F1 score, with both synthetic and real augmentation contributing similarly to performance gains. The study demonstrates a replicable framework for enhancing conversational agent performance in data-scarce domains.

## Method Summary
The authors fine-tuned an open-source LLM on 82,000 posts from prior support groups to identify intents with F1 scores below 80%. For these low-performing intents, they implemented a two-pronged augmentation approach: (1) synthetic data generation using GPT-4, where quality-screened original posts are transformed into prompts to generate additional responses, and (2) real data scraping from the Ex-Community forum, extracting over 10,000 posts. Both synthetic and real posts undergo dual human annotator validation for relevance, fluency, and intent alignment. The validated augmented dataset is then used to retrain the intent classifier.

## Key Results
- 32% improvement in F1 score for intent classification
- Synthetic and real post augmentation led to similar performance improvements
- 87% of generated synthetic posts deemed high quality by human annotators
- 73% of scraped real posts validated as good quality by human annotators

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Targeted augmentation of low-performing intent classes improves classifier F1 scores more efficiently than uniform data expansion.
- **Mechanism:** The authors identify intents with F1 < 80% from the original fine-tuned model, then selectively augment only those classes using synthetic generation and real data scraping. This concentrates resources where the model has insufficient training examples.
- **Core assumption:** Low F1 scores are primarily caused by data scarcity for specific intents rather than inherent class difficulty or label ambiguity.
- **Evidence anchors:**
  - [abstract] "we fine-tuned an open source LLM to classify posts... and identify intents with low F1 (precision+recall) scores. Then, for these intents, we generate additional synthetic data"
  - [Section 3.1] "if the F1 score for any intent is below 80 percent, we view that as too low, necessitating data augmentation"
  - [corpus] SynBullying paper (arXiv:2511.11599) similarly uses targeted synthetic data generation for specific conversational patterns, achieving scalable results.
- **Break condition:** If low F1 scores persist after augmentation >2x original data volume, the issue may be label confusion or inherently ambiguous intent boundaries rather than data scarcity.

### Mechanism 2
- **Claim:** Human-in-the-loop validation filters synthetic and scraped data to maintain training quality, preventing model degradation from noisy augmentation.
- **Mechanism:** Two independent annotators evaluate each synthetic and scraped post for relevance, fluency, and intent alignment. Disagreements are resolved through discussion or expert adjudication. This prevents semantic drift and off-topic contamination.
- **Core assumption:** Human annotators can reliably judge intent fit and quality; annotation errors are random rather than systematically biased.
- **Evidence anchors:**
  - [abstract] "with an average of 87% of the generated synthetic posts deemed high quality by human annotators... 73% were validated as good quality by human annotators"
  - [Section 3.1.4] "Each synthetic post is independently evaluated by two human annotators... If annotators disagree, they discuss and attempt to reach agreement"
  - [corpus] Limited direct corpus evidence on human validation protocols for synthetic data; related papers do not emphasize this step.
- **Break condition:** If inter-annotator agreement drops below ~70% for specific intents, the intent definitions may be too ambiguous for reliable labeling.

### Mechanism 3
- **Claim:** Combining synthetic and real augmentation sources provides complementary coverage that neither achieves alone.
- **Mechanism:** Synthetic data (GPT-4 generated) provides controlled, intent-aligned expansion with consistent quality. Real scraped data (Ex-Community) introduces natural language variation and authentic phrasing. Both contribute similarly to the 32% F1 improvement.
- **Core assumption:** The scraped external community (Ex-Community) shares sufficiently similar intent distributions and language patterns to the target support groups.
- **Evidence anchors:**
  - [abstract] "Synthetic and real post augmentation led to similar performance improvements"
  - [Section 3.2] "we scrape over 10,000 posts from the Ex-Community... Posts annotated as fitting focal intents are included"
  - [corpus] ConvoGen (arXiv:2503.17460) uses multi-agent synthetic data generation, but does not compare synthetic vs. real sources directly.
- **Break condition:** If domain shift between scraped source and target domain is high (e.g., different demographic, different cessation stage), real data may introduce noise rather than signal.

## Foundational Learning

- **Concept:** Intent Classification in Conversational Agents
  - **Why needed here:** This is the core task being improved. Understanding that intent classification maps user utterances to predefined action categories is essential before applying augmentation strategies.
  - **Quick check question:** Given the utterance "I keep having crazy dreams since starting the patch," which intent from Table 1 would this map to?

- **Concept:** F1 Score as Balance of Precision and Recall
  - **Why needed here:** The paper uses F1 < 80% as the threshold for augmentation. Understanding why F1 (harmonic mean) is preferred over accuracy for imbalanced classes explains the targeting logic.
  - **Quick check question:** If a model has 90% precision but 50% recall for the "nrt_dontwork" intent, what is the F1 score? Should this intent be augmented?

- **Concept:** Semantic Drift in Generative Augmentation
  - **Why needed here:** Section 3.1.5 identifies semantic drift as a stopping criterion. Recognizing when synthetic outputs deviate from target intents is critical for quality control.
  - **Quick check question:** A prompt about "craving management" generates responses about "stress eating." Is this semantic drift or valid augmentation?

## Architecture Onboarding

- **Component map:** Original Intent Classifier -> F1 Evaluation -> Threshold Filter -> Quality Screener -> Prompt Crafter -> (parallel: Synthetic Generator AND Real Scraper) -> Quality Assurance -> Augmented Dataset -> Retrained Classifier

- **Critical path:** F1 evaluation -> threshold filtering -> quality screening -> (parallel: synthetic generation AND real scraping) -> human validation -> dataset merge -> retraining -> re-evaluation

- **Design tradeoffs:**
  - Synthetic data is controllable but may lack natural variation; real data is authentic but requires more cleaning and may have domain shift
  - Human validation is expensive but prevents noise; skipping it risks model degradation
  - 80% F1 threshold is arbitrary; lower threshold = less augmentation, higher threshold = more cost

- **Failure signatures:**
  - F1 does not improve after augmentation -> check for label confusion, domain mismatch in scraped data, or annotation inconsistency
  - Synthetic quality rate drops below 70