---
ver: rpa2
title: 'Framing the Game: How Context Shapes LLM Decision-Making'
arxiv_id: '2503.04840'
source_url: https://arxiv.org/abs/2503.04840
tags:
- decision
- game
- decision-making
- both
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a procedurally generated evaluation framework
  for analyzing Large Language Model (LLM) decision-making in game-theoretic scenarios,
  focusing on the Prisoner's Dilemma. The method dynamically generates diverse vignettes
  by varying topics, world types, and actor relationships, then systematically evaluates
  LLM choices across these contexts.
---

# Framing the Game: How Context Shapes LLM Decision-Making

## Quick Facts
- arXiv ID: 2503.04840
- Source URL: https://arxiv.org/abs/2503.04840
- Authors: Isaac Robinson; John Burden
- Reference count: 36
- The paper introduces a procedurally generated evaluation framework for analyzing Large Language Model (LLM) decision-making in game-theoretic scenarios, focusing on the Prisoner's Dilemma.

## Executive Summary
This paper introduces a procedurally generated evaluation framework for analyzing how Large Language Models make decisions in game-theoretic scenarios, particularly the Prisoner's Dilemma. The method dynamically generates diverse vignettes by varying topics, world types, and actor relationships, then systematically evaluates LLM choices across these contexts. The framework reveals that LLM decisions are highly sensitive to contextual framing, showing significant variation in cooperation/defection choices even when the underlying game structure remains constant.

The study demonstrates that while LLM decision patterns are largely predictable based on context, inherent stochasticity remains in their choices. This work offers a more robust evaluation methodology for real-world LLM deployments by accounting for contextual variability in decision-making, while also mitigating benchmark contamination risks through its procedurally generated approach.

## Method Summary
The researchers developed a procedurally generated framework that creates diverse game-theoretic scenarios by systematically varying contextual elements such as topics, world types, and actor relationships. For each vignette, the framework presents LLMs with a Prisoner's Dilemma scenario and records their cooperation or defection choices. This approach allows for controlled testing of how different framings affect decision-making while maintaining consistent underlying game mechanics. The method generates a large number of unique scenarios to capture the full range of context-dependent variability in LLM responses.

## Key Results
- LLM choices show significant context-dependent variability in cooperation/defection decisions across different vignettes
- Decision patterns are largely predictable based on contextual features, though inherent LLM stochasticity remains
- The framework successfully mitigates benchmark contamination risks while providing insights into real-world LLM decision-making

## Why This Works (Mechanism)
The framework works by leveraging the LLMs' sensitivity to contextual cues while maintaining controlled game-theoretic structures. By procedurally generating diverse scenarios, it isolates the impact of framing effects on decision-making. The approach reveals that LLMs don't simply recognize game structures in isolation but integrate contextual information into their strategic choices, making their behavior more reflective of real-world deployment scenarios where context varies continuously.

## Foundational Learning
- **Game Theory Fundamentals**: Understanding Prisoner's Dilemma payoff structures and equilibrium concepts is essential for interpreting LLM choices and their strategic implications
- **Procedural Content Generation**: The ability to systematically vary scenario elements while maintaining core mechanics is crucial for isolating context effects
- **Context Sensitivity in LLMs**: Knowledge of how LLMs process and integrate contextual information helps explain why framing significantly impacts decision-making
- **Benchmark Contamination**: Understanding how traditional static benchmarks can lead to overfitting and why procedural generation mitigates this risk
- **Stochastic Decision-Making**: Recognition that LLMs exhibit inherent randomness in choices, even when patterns are predictable

## Architecture Onboarding
- **Component Map**: Procedural Generator -> Scenario Framer -> LLM Interface -> Decision Analyzer -> Pattern Detector
- **Critical Path**: The framework's core workflow processes each generated vignette through the LLM, analyzes the cooperation/defection choice, and aggregates results to identify context-dependent patterns
- **Design Tradeoffs**: Balancing scenario diversity against computational cost, and between controlled conditions and real-world complexity
- **Failure Signatures**: LLMs consistently choosing one strategy regardless of context, or failing to recognize game structures altogether
- **First 3 Experiments**:
  1. Test baseline cooperation rates across neutral contexts to establish reference points
  2. Systematically vary single contextual features (e.g., relationship type) to isolate individual effects
  3. Compare patterns across different LLM architectures to assess generalizability

## Open Questions the Paper Calls Out
None

## Limitations
- The procedurally generated vignettes may not capture the full complexity of real-world decision-making contexts, potentially underestimating real-world context effects
- The analysis focuses on binary cooperation/defection outcomes, potentially missing more subtle decision-making patterns in richer payoff structures
- The framework's insights remain inferential regarding real-world LLM behavior, as empirical validation against actual deployed systems is beyond the paper's scope

## Confidence
- **High Confidence**: LLM choices vary significantly across contextual framings is well-supported by systematic experimental design and large sample size
- **Medium Confidence**: Patterns are "largely predictable" while exhibiting "inherent LLM stochasticity" needs more rigorous statistical characterization
- **Medium Confidence**: The framework offers "more robust evaluation methodology for real-world LLM deployments" is conceptually sound but empirically unverified

## Next Checks
1. Validate whether the framework's insights extend to more complex game-theoretic scenarios beyond Prisoner's Dilemma, such as iterated games or multi-player games
2. Conduct a study comparing LLM decisions in procedurally generated vignettes against their behavior in actual deployed applications to quantify real-world generalization
3. Test whether observed context-dependent variability patterns hold across different LLM architectures and training paradigms