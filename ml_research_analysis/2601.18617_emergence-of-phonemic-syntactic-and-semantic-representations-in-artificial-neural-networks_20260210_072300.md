---
ver: rpa2
title: Emergence of Phonemic, Syntactic, and Semantic Representations in Artificial
  Neural Networks
arxiv_id: '2601.18617'
source_url: https://arxiv.org/abs/2601.18617
tags:
- semantic
- syntactic
- probe
- language
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study investigates how phonemic, lexical, and syntactic linguistic
  structures emerge in the activation spaces of artificial neural networks during
  training, aiming to uncover the computational mechanisms underlying language acquisition.
  A generalized structural probe is developed to identify linear subspaces in neural
  network activations that encode distances corresponding to linguistic structures
  such as articulatory features, WordNet semantic graphs, and dependency syntax.
---

# Emergence of Phonemic, Syntactic, and Semantic Representations in Artificial Neural Networks

## Quick Facts
- arXiv ID: 2601.18617
- Source URL: https://arxiv.org/abs/2601.18617
- Reference count: 40
- The study develops a generalized structural probe to reveal that speech and text models build linear subspaces encoding phonemic, lexical-semantic, and syntactic structures, with emergence occurring sequentially and requiring 2-4 orders of magnitude more input than humans.

## Executive Summary
This paper investigates how linguistic structures emerge in neural network activations during training by developing a generalized structural probe that identifies linear subspaces where squared Euclidean distances correspond to linguistically-defined distances. The probe is applied to both speech (Wav2Vec 2.0) and text (Pythia, Llama 2) models across training checkpoints, revealing that phonemic structure emerges first, followed by lexical-semantic and then syntactic structure. The findings show that these models develop similar geometric codes for linguistic structures despite different modalities, though they require vastly more data than human learners.

## Method Summary
The method uses a generalized structural probe that learns a linear transformation B mapping high-dimensional activations to a lower-dimensional subspace where squared Euclidean distances approximate linguistically-defined distances. The probe is trained via minimizing the absolute difference between predicted and gold distances using AMSGrad Adam optimization. The approach is applied layer-wise across transformer models, with evaluation using Spearman correlation between predicted and ground-truth distances. Datasets include UD-EWT for syntax, WordNet-Nouns for semantics, and UD-EWT-TTS synthesized speech with MFA alignment for phonemic structure in speech models. Training dynamics are tracked by applying probes to models at different checkpoints.

## Key Results
- Speech models develop phonemic representations aligned with articulatory features in mid-to-late layers (Spearman ~0.7)
- Both speech and text models build subspaces representing lexical semantics and syntactic trees, with emergence occurring sequentially
- Performance scales with model size and training data, but requires 2-4 orders of magnitude more input than humans
- Semantic scores in audio models may be driven by acoustic properties rather than genuine lexical semantics

## Why This Works (Mechanism)

### Mechanism 1
Linguistic structures are encoded in linear subspaces where squared Euclidean distances between activation vectors correlate with linguistically-defined distances. A linear transformation B maps high-dimensional activations to a lower-dimensional subspace; distances in this subspace approximate target distances (articulatory feature dissimilarities, WordNet path lengths, dependency tree edges). This enables downstream neurons to read structure via simple linear operations.

### Mechanism 2
Linguistic representations emerge sequentially during training in speech models: phonemic structure emerges first (~10⁷ tokens), followed by lexical-semantic (~10⁸ tokens), then syntactic structure (~10⁹ tokens). Self-supervised learning progressively constructs increasingly abstract subspaces. Early layers/mid-training capture low-level acoustic-phonemic regularities; subsequent training builds semantic and then syntactic subspaces on top of these foundations.

### Mechanism 3
Representation quality scales with model size and training data, but with domain-specific saturation patterns: syntactic scores plateau quickly in text models while semantic scores continue improving with scale. Larger models provide higher-dimensional activation spaces, enabling more accurate linear subspace identification. Syntactic structure may be computationally simpler compared to the full lexical-semantic graph.

## Foundational Learning

- **Structural Probing / Linear Readout**: The methodology hinges on finding linear subspaces that preserve linguistic distances. Understanding that a linear probe tests whether downstream neurons could directly read this structure is essential for interpretation.
  - Quick check: Can you explain why a linear probe (vs. non-linear) provides mechanistic interpretability value?

- **Linguistic Formalisms (Dependency Trees, WordNet Hypernymy, Articulatory Features)**: Each probe requires a ground-truth distance metric derived from linguistic theory. Understanding what these structures encode is essential for interpreting results.
  - Quick check: What does a WordNet path length of 3 between two nouns indicate?

- **Self-Supervised Speech/Text Learning (Wav2Vec 2.0, CLM Objectives)**: The emergence patterns are properties of models trained without explicit linguistic supervision. Understanding what the pretraining objective optimizes helps explain why these structures emerge.
  - Quick check: What is the Wav2Vec 2.0 pretraining objective, and why might it encourage phonemic representations?

## Architecture Onboarding

- **Component map**: Input layer (raw audio or tokenized text) -> Transformer encoder (stacked layers) -> Activation extraction (extract h ∈ R^{n,k}) -> Structural probe (linear transformation B ∈ R^{k,p}) -> Distance computation (squared Euclidean distance) -> Evaluation (Spearman correlation)

- **Critical path**: 1) Extract activations from each transformer layer for all tokens/phonemes 2) Train probe B to minimize distance prediction error 3) Evaluate Spearman correlation on held-out test pairs 4) Repeat across training checkpoints to trace emergence

- **Design tradeoffs**: Probe dimensionality (higher dimensions improve evaluation but reduce interpretability), distance vs. contrastive objectives (distance preserves metric structure, contrastive preserves topology), layer selection (mid-to-late layers typically show strongest structure)

- **Failure signatures**: Control models match English-exposed models (indicates probe recovering acoustic/text statistics rather than linguistic structure), linear tree performance = dependency tree performance (suggests model only encodes sequential structure), no layer-wise variation (may indicate probe overfitting)

- **First 3 experiments**: 1) Reproduce phonemic probe on Wav2Vec 2.0 base: extract layer 9 activations, train 200D probe on UD-EWT-TTS phoneme pairs, verify Spearman > 0.70 2) Run emergence analysis across checkpoints: for Pythia-1B, extract activations at log-spaced checkpoints, train semantic and syntactic probes, plot scores vs. training tokens 3) Control experiment: train syntactic probe on Wav2Vec 2.0 trained on environmental sounds; verify Spearman with dependency tree ≈ Spearman with linear tree

## Open Questions the Paper Calls Out

### Open Question 1
To what extent are the semantic scores observed in speech models derived from genuine lexical semantics versus acoustic correlates? The paper notes that audio model saturation questions whether they discovered semantic structure or if these scores could be explained by the acoustic properties of the words. Control models trained on music/environmental sounds also achieved significant semantic scores, suggesting acoustic features may artificially inflate semantic metrics.

### Open Question 2
Does lexical semantic structure definitively emerge before syntactic structure in audio models? The Limitations section states the developmental ordering between syntax and lexical semantics remains unresolved, as the semantic code in audio models only partially emerges, complicating direct comparison of developmental timing.

### Open Question 3
Do these linear geometric representations causally contribute to the model's linguistic processing capabilities? The paper notes the evaluation relies exclusively on structural probing rather than prediction-based tests, meaning conclusions concern representation rather than inference. The existence of a linear subspace encoding a linguistic structure does not confirm that the network utilizes this geometry for downstream tasks.

## Limitations
- Linear probe methodology may miss non-linear encodings of linguistic structure
- Sequential emergence ordering is observational rather than causally established
- Massive data requirements (2-4 orders of magnitude more than humans) raise questions about generalization to efficient learning regimes

## Confidence

- **High confidence**: Detection of linear subspaces encoding linguistic structures across multiple models and tasks; control experiments provide strong evidence of genuine linguistic rather than acoustic/text statistics; scaling relationships with model size and data volume are robust
- **Medium confidence**: Sequential emergence ordering (data shows temporal separation but causal interpretation requires additional assumptions)
- **Medium confidence**: Quantitative comparison to human learning efficiency (based on reasonable estimates but involves multiple uncertain parameters)

## Next Checks

1. **Probe sensitivity validation**: Train a non-linear probe (e.g., small MLP) on the same datasets and compare performance to the linear probe. If non-linear probes show dramatically better performance, this would indicate the linear probe is missing substantial structure.

2. **Alternative emergence ordering test**: Modify the training curriculum to force early exposure to syntactic structure (e.g., via curriculum learning or multi-task pretraining) and observe whether the emergence sequence changes. This would test whether the observed ordering reflects genuine computational dependencies or just the default learning trajectory.

3. **Cross-linguistic generalization**: Apply the full probe suite to multilingual models trained on typologically diverse languages (e.g., languages with free word order, polysynthetic morphology). If the sequential emergence pattern and scaling laws hold across languages, this strengthens claims about fundamental computational principles.