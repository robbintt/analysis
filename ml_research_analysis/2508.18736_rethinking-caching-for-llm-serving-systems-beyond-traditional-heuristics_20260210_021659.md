---
ver: rpa2
title: 'Rethinking Caching for LLM Serving Systems: Beyond Traditional Heuristics'
arxiv_id: '2508.18736'
source_url: https://arxiv.org/abs/2508.18736
tags:
- siso
- cache
- caching
- semantic
- queries
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SISO, a semantic caching system designed
  to improve the efficiency of serving Large Language Models (LLMs) by caching semantically
  similar queries rather than exact matches. Traditional caching methods fail to recognize
  semantically similar queries, leading to inefficiencies in memory usage and cache
  performance.
---

# Rethinking Caching for LLM Serving Systems: Beyond Traditional Heuristics

## Quick Facts
- **arXiv ID:** 2508.18736
- **Source URL:** https://arxiv.org/abs/2508.18736
- **Reference count:** 40
- **Primary result:** SISO delivers up to 1.71× higher hit ratios and stronger SLO attainment compared to vLLM and GPTCache.

## Executive Summary
SISO introduces a semantic caching system for LLM serving that overcomes the limitations of exact-match and LRU-based semantic caches. By clustering semantically similar queries into centroids and caching these representatives, SISO increases memory efficiency and hit ratios. The system employs semantic locality-aware eviction and dynamic threshold adjustment based on system load to balance accuracy and latency. Across diverse datasets and two LLM models, SISO achieves significant performance improvements while maintaining high output quality with only marginal accuracy loss.

## Method Summary
SISO operates through an offline-online workflow. Offline, it embeds historical queries using `paraphrase-albert-small-v2`, clusters them via Community Detection (θC=0.86), and generates centroids representing semantically similar groups. These centroids are stored in a repository and selectively promoted to an in-memory semantic cache based on semantic locality (cluster size) rather than LRU. Online, incoming queries are embedded and searched against the HNSW-indexed centroids. A dynamic similarity threshold (θR) adjusts based on system load using an M/D/1 queuing model to balance hit ratio against SLO attainment. The system replaces cache entries only when semantic locality indicates staleness, maintaining stability over time.

## Key Results
- Achieves up to 1.71× higher cache hit ratios compared to GPTCache at identical memory capacities
- Maintains higher Service Level Objective (SLO) attainment under heavy load while preserving output quality
- Outperforms vLLM and GPTCache across diverse datasets including Quora, Reddit, MSMARCO, NQ, and ShareGPT
- Shows only marginal accuracy degradation (<6.9% F1 drop) when trading accuracy for latency under peak loads

## Why This Works (Mechanism)

### Mechanism 1: Centroid-based Cache Density
SISO clusters historical queries offline and caches only cluster centroids instead of individual query vectors. This approach increases effective memory utilization because a single cached centroid can satisfy a semantically diverse set of similar queries. The system assumes that texts with high cosine similarity share meaning and produce acceptable similar outputs. Evidence shows Centroid-based caching achieves higher hit ratios than GPTCache at identical capacities. The mechanism breaks when query semantics shift rapidly or clusters become too broad, causing semantic collisions.

### Mechanism 2: Semantic Locality-aware Retention
Unlike LRU policies, SISO evicts centroids based on "semantic locality" - measured by cluster size and popularity stability. This approach retains centroids representing large volumes of similar queries while evicting those with low coverage. The core assumption is that semantic locality remains relatively stable over time. Evidence shows >96% of centroids had <10% rank variation over four weeks. The mechanism fails when sudden viral trends or workload changes introduce frequent new, unseen query types.

### Mechanism 3: SLO-driven Dynamic Thresholding
SISO adjusts the similarity threshold (θR) based on system load using an M/D/1 queuing model. When wait time exceeds the SLO, the system lowers θR to increase cache hit probability and reduce LLM load. When load is light, it raises θR to ensure only high-quality matches are returned. The core assumption is a linear relationship between input similarity and output utility. Evidence shows SISO maintains higher F1 scores than baselines under high RPS by trading accuracy strategically. The mechanism breaks for tasks where small semantic differences cause large output divergences.

## Foundational Learning

**Semantic vs. Exact Caching**: SISO moves beyond exact/prefix matching, betting that "similar input ≈ similar output." Quick check: Does the system return the exact response generated for the centroid, or re-generate based on the centroid?

**Clustering High-Dimensional Vectors**: The efficacy of centroid-based caching relies entirely on clustering quality. If the embedding space isn't well-clustered, centroids are poor representatives. Quick check: Why did authors choose Community Detection over K-Means or DBSCAN? (Hint: See Table 2)

**Queueing Theory (M/D/1)**: Mechanism 3 uses the M/D/1 model to predict latency, where ρ = λ × Service Time must remain < 1. Quick check: In Eq. (2), how does increasing hit ratio h(θR) affect effective service time S?

## Architecture Onboarding

**Component map**: SISO-Cluster (Offline) -> SISO-CacheManager (Offline) -> Semantic Cache -> SISO-Server (Online) -> HNSW Index

**Critical path**: Query → Embed → HNSW Search → Threshold Check. Latency added must be significantly lower than LLM inference time (ms vs s).

**Design tradeoffs**: Memory vs. Granularity (storing centroids saves space but loses specific query nuances), Freshness vs. Stability (re-clustering is expensive), Accuracy vs. SLO (explicitly sacrifices response quality to guarantee latency during peaks).

**Failure signatures**: "Semantic Drift" (hit rate drops despite high cache usage), "Accuracy Collapse" (irrelevant answers during peak hours), "Clustering Noise" (outliers form own centroids).

**First 3 experiments**: 1) Baseline Hit Ratio: Compare SISO vs. GPTCache on Quora dataset while varying cache capacity. 2) Stress Test SLO: Ramp up RPS on limited GPU setup, plot SLO attainment vs. Accuracy. 3) Category Analysis: Run SISO on "Coding" vs. "Information Seeking" queries to confirm break conditions.

## Open Questions the Paper Calls Out
- How can semantic caching systems be adapted to support context-dependent multi-turn queries where meaning is derived from conversation history?
- How can caching systems differentiate between queries where semantic similarity implies answer equivalence versus those where it does not (e.g., coding tasks)?
- Does the M/D/1 queuing model remain accurate for real-world traffic with non-Poisson arrival patterns?

## Limitations
- Relies on fixed clustering parameters (θC=0.86) that may not generalize across domains
- HNSW implementation with semantic-aware layer construction lacks implementation details
- Assumes Poisson arrivals and deterministic service times, which may not hold for real-world bursty traffic

## Confidence
**High Confidence**: Centroid-based caching improves hit ratios, semantic locality-aware eviction outperforms LRU, core accuracy-SLO trade-off is measurable.

**Medium Confidence**: Dynamic thresholding maintains SLO without catastrophic accuracy loss, 1.71× hit ratio improvement generalizes, correlation between input similarity and output quality is sufficiently linear.

**Low Confidence**: Clustering threshold θC=0.86 works universally, modified HNSW implementation achieves stated gains, system performs well under highly variable workloads.

## Next Checks
1. **Clustering Sensitivity Analysis**: Reproduce centroid generation on Quora dataset while systematically varying clustering threshold (θC from 0.7 to 0.95) to quantify impact on hit ratio and accuracy.
2. **Burst Workload Simulation**: Create synthetic workload alternating between stable traffic and sudden bursts (10× increase) to test dynamic thresholding mechanism's response time and effectiveness.
3. **Cross-Domain Transferability**: Apply trained SISO system (using Quora centroids) to unseen dataset like ShareGPT or coding corpus to measure degradation in hit ratio and accuracy.