---
ver: rpa2
title: 'POEMS: Product of Experts for Interpretable Multi-omic Integration using Sparse
  Decoding'
arxiv_id: '2511.03464'
source_url: https://arxiv.org/abs/2511.03464
tags:
- latent
- each
- sparse
- poems
- interpretability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces POEMS, a novel deep generative model for
  multi-omic data integration that achieves both strong predictive performance and
  interpretability. POEMS uses a Product-of-Experts (PoE) posterior to fuse modality-specific
  posteriors into a shared latent space, sparse feature-to-factor mappings to enable
  biomarker discovery, and a gating network to quantify each omic's contribution.
---

# POEMS: Product of Experts for Interpretable Multi-omic Integration using Sparse Decoding

## Quick Facts
- **arXiv ID**: 2511.03464
- **Source URL**: https://arxiv.org/abs/2511.03464
- **Reference count**: 40
- **Primary result**: Novel deep generative model achieving competitive performance and interpretability in multi-omic integration

## Executive Summary
This paper introduces POEMS, a deep generative model designed for multi-omic data integration that uniquely balances strong predictive performance with interpretability. The model employs a Product-of-Experts (PoE) posterior to fuse modality-specific posteriors into a shared latent space, enabling coherent representation across diverse omics types. By incorporating sparse feature-to-factor mappings, POEMS facilitates biomarker discovery while maintaining interpretability. Additionally, a gating network quantifies each omic's contribution to the shared representation. Through these innovations, POEMS demonstrates superior or competitive clustering and classification performance on breast cancer (BRCA) and kidney cancer (KIRC) datasets, while also providing insights into cross-omic associations and per-omic contributions.

## Method Summary
POEMS is a deep generative model that integrates multi-omic data by combining modality-specific posteriors into a shared latent space using a Product-of-Experts (PoE) approach. The model employs sparse decoding to map high-dimensional omics data to interpretable latent factors, enabling biomarker discovery. A gating network dynamically adjusts the contribution of each omic modality to the shared representation. To handle high-dimensional data efficiently, a vectorized decoder is implemented, scaling Sparse VAEs to large-scale omics datasets. The architecture is trained to optimize both predictive accuracy and interpretability, with evaluations on BRCA and KIRC datasets demonstrating competitive clustering and classification results alongside meaningful biological insights.

## Key Results
- Achieves highest K-means clustering accuracy (0.63), NMI (0.45), and KNN classification accuracy (0.78) on BRCA dataset
- Demonstrates competitive or superior performance compared to state-of-the-art methods on both BRCA and KIRC datasets
- Provides interpretable insights through sparse associations between latent factors and features, cross-omic associations, and adaptive per-omic contribution estimation

## Why This Works (Mechanism)
POEMS leverages a Product-of-Experts (PoE) posterior to effectively fuse modality-specific posteriors, ensuring that the shared latent space captures coherent representations across different omics types. The sparse feature-to-factor mappings enhance interpretability by identifying key biomarkers while reducing noise. The gating network dynamically balances contributions from each omic modality, allowing the model to adaptively prioritize relevant information. Additionally, the vectorized decoder enables efficient scaling to high-dimensional omics data, maintaining computational feasibility without sacrificing performance.

## Foundational Learning
- **Product-of-Experts (PoE)**: Combines multiple expert models to form a unified posterior, improving representation learning in multi-modal settings. *Why needed*: Enables coherent integration of diverse omics data. *Quick check*: Verify that PoE effectively merges modality-specific posteriors.
- **Sparse decoding**: Maps high-dimensional data to a lower-dimensional latent space with sparse connections, enhancing interpretability. *Why needed*: Facilitates biomarker discovery by identifying key features. *Quick check*: Confirm sparsity patterns align with known biological markers.
- **Gating networks**: Dynamically adjusts the contribution of each modality to the shared representation. *Why needed*: Ensures balanced integration of diverse data sources. *Quick check*: Evaluate per-omic contribution estimates for consistency.
- **Vectorized decoder**: Scales sparse VAEs to handle high-dimensional omics data efficiently. *Why needed*: Maintains computational feasibility for large-scale datasets. *Quick check*: Benchmark computational performance on high-dimensional data.

## Architecture Onboarding

**Component Map**
Input omics modalities → Modality-specific encoders → Product-of-Experts posterior → Shared latent space → Sparse decoder → Output predictions

**Critical Path**
Data preprocessing → Modality-specific encoding → PoE fusion → Sparse decoding → Interpretation and evaluation

**Design Tradeoffs**
- Interpretability vs. predictive performance: Sparse decoding enhances interpretability but may reduce flexibility.
- Computational efficiency vs. model complexity: Vectorized decoder improves scalability but may limit model expressiveness.
- Dynamic vs. fixed modality contributions: Gating network allows adaptive integration but introduces additional hyperparameters.

**Failure Signatures**
- Poor clustering/classification performance may indicate ineffective PoE fusion or inadequate sparse mappings.
- Unstable sparse associations could suggest overfitting or insufficient training data.
- Inconsistent per-omic contributions may result from suboptimal gating network configuration.

**First 3 Experiments**
1. Evaluate clustering and classification performance on BRCA and KIRC datasets.
2. Analyze sparse feature-to-factor mappings for biomarker discovery.
3. Assess per-omic contribution estimates using the gating network.

## Open Questions the Paper Calls Out
None

## Limitations
- Performance robustness across diverse cancer types beyond BRCA and KIRC remains uncertain.
- Stability of sparse feature-to-factor mappings in smaller sample sizes is unclear.
- Interpretability of cross-omic associations may be limited by the complexity of multi-omic data.
- Reliance on specific hyperparameters for sparse decoding and gating may affect generalizability.
- Lack of comparison with emerging deep learning methods may limit assessment of competitive edge.

## Confidence

| Claim | Label |
|-------|-------|
| Competitive clustering and classification performance on BRCA and KIRC datasets | High |
| Interpretability through sparse associations and per-omic contribution estimation | Medium |
| Robustness of performance across diverse cancer types | Low |
| Stability of sparse mappings in smaller datasets | Low |

## Next Checks
1. Test POEMS on additional cancer types or multi-omic datasets to evaluate generalizability.
2. Assess the stability of sparse feature-to-factor mappings with varying sample sizes and hyperparameter settings.
3. Compare POEMS against emerging deep learning methods for multi-omic integration to validate its competitive edge.