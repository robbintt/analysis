---
ver: rpa2
title: Leveraging Log Probabilities in Language Models to Forecast Future Events
arxiv_id: '2501.04880'
source_url: https://arxiv.org/abs/2501.04880
tags:
- probability
- forecast
- event
- future
- forecasting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses the challenge of improving AI-driven event
  forecasting by leveraging Large Language Models (LLMs) and their log probability
  outputs. The core method involves a three-component system: a Forecast Generator
  that creates potential future events from topics using current trends, a Probability
  Estimator that calculates event probabilities and uncertainties using weighted log
  probabilities from LLM outputs, and a Fact Checker that verifies if events occurred.'
---

# Leveraging Log Probabilities in Language Models to Forecast Future Events

## Quick Facts
- **arXiv ID:** 2501.04880
- **Source URL:** https://arxiv.org/abs/2501.04880
- **Authors:** Tommaso Soru; Jim Marshall
- **Reference count:** 12
- **Primary result:** 19% improvement in Brier score (0.186) over vanilla GPT-4o using log probability weighting

## Executive Summary
This paper addresses the challenge of improving AI-driven event forecasting by leveraging Large Language Models (LLMs) and their log probability outputs. The authors propose a three-component system that generates potential future events from topics, estimates their probabilities and uncertainties using weighted log probabilities from LLM outputs, and verifies if events occurred. The core innovation is the Probability Estimator, which uses log probabilities to compute both weighted average probability estimates and uncertainty measures. Tested on 72 backtested forecasts, the system achieves a Brier score of 0.186—a 19% improvement over vanilla GPT-4o and 26% better than random chance. The results suggest LLMs can provide strategic forecasting advantages when uncertainty quantification is incorporated.

## Method Summary
The system consists of three components: a Forecast Generator that creates potential future events from topics using current trends, a Probability Estimator that calculates event probabilities and uncertainties using weighted log probabilities from LLM outputs, and a Fact Checker that verifies if events occurred. The Probability Estimator is the key innovation, using log probabilities to compute both weighted averages and uncertainty measures. The system was tested on 72 backtested forecasts, achieving a Brier score of 0.186—a 19% improvement over vanilla GPT-4o and 26% better than random chance. The results suggest LLMs can provide strategic forecasting advantages when uncertainty quantification is incorporated.

## Key Results
- Achieved Brier score of 0.186, representing 19% improvement over vanilla GPT-4o
- 26% better performance compared to random chance baseline
- System generates 72 test forecasts from 15 topics with 50/50 train-test split
- Uncertainty quantification provides additional insight beyond point probability estimates

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Leveraging log probabilities across multiple LLM completions improves probability estimation accuracy compared to single-completion approaches.
- Mechanism: The system generates multiple probability guesses P_i for an event, then weights each guess by e^(w_i) where w_i is the log probability of the token representing that guess. This yields both a weighted average probability estimate (P̂) and an uncertainty measure (Û) via weighted standard deviation. Higher-confidence token outputs contribute more to the final estimate.
- Core assumption: Token log probabilities correlate with the model's confidence in its probability estimates, and aggregating across the full distribution captures information lost by taking only the top completion.

### Mechanism 2
- Claim: Augmenting LLMs with semantically-filtered trend data compensates for knowledge cutoff limitations and improves forecast grounding.
- Mechanism: The Forecast Generator collects trends from ~45,000 articles over 6 months, then semantically filters them by relevance to the input topic at query time. This external context is combined with LLM background knowledge to generate forecasts.
- Core assumption: Recent trend trajectories contain predictive signal that can be extracted and applied to specific topics through semantic similarity.

### Mechanism 3
- Claim: Support Vector Regression calibration transforms raw LLM probability outputs into better-calibrated forecasts.
- Mechanism: After discarding invalid forecasts (already-happened events), the system splits data into training/test sets and learns a transformation function via SVR to map LLM-returned probabilities to calibrated outputs.
- Core assumption: The relationship between raw LLM probabilities and actual outcomes is systematic and learnable from a relatively small dataset (N=75 training samples).

## Foundational Learning

- **Concept: Brier Score**
  - Why needed here: The paper uses Brier score as the primary evaluation metric; understanding it is essential to interpret the claimed 19-26% improvements.
  - Quick check question: A Brier score of 0.186 means the average squared difference between forecasted probabilities and binary outcomes is 0.186—is lower or higher better?

- **Concept: Log Probabilities (logprobs)**
  - Why needed here: The core innovation relies on extracting and weighting by log probabilities from LLM token outputs.
  - Quick check question: If a model assigns logprob of -0.5 to token "70" and -2.0 to token "30", which probability estimate receives higher weight in the aggregation?

- **Concept: Model Calibration**
  - Why needed here: The paper applies SVR calibration to correct systematic biases in raw probability outputs.
  - Quick check question: If a model outputs 80% probability for events that only occur 60% of the time, is the model overconfident or underconfident?

## Architecture Onboarding

- **Component map:**
Forecast Generator → [Topic + Trends] → Event descriptions
                                          ↓
Probability Estimator → [Event + Trends + Sources] → P̂, Û
                                          ↓
Fact Checker → [Event + Timeframe] → {1, 0, -1}

- **Critical path:** The Probability Estimator's 6-step pipeline (reformulate → search trends → collect sources → extract events → check exclusivity → estimate probability) is where the logprob weighting mechanism is applied. Errors in trend retrieval or source collection propagate directly to probability estimates.

- **Design tradeoffs:**
  - Temperature/top-P set to minimum for determinism vs. potential loss of diversity in probability estimates
  - N=150 dataset enables rapid iteration but limits calibration robustness
  - 240-day forecast horizon provides substantial evaluation window but reduces comparability to shorter-horizon benchmarks

- **Failure signatures:**
  - High uncertainty (Û) values across multiple runs may indicate incoherent model behavior or ambiguous event formulations
  - Probability sums exceeding 100% for mutually exclusive events indicate inconsistency checks not triggering correctly
  - Fact Checker returning excessive "Inconclusive" (0) results suggests source retrieval gaps

- **First 3 experiments:**
  1. Replicate the probability estimation pipeline on a held-out set of 20 events, comparing single-completion vs. logprob-weighted aggregation to validate the 19% improvement claim.
  2. Ablate the trend augmentation component by running the Probability Estimator with and without semantic trend filtering to isolate its contribution.
  3. Test calibration stability by training SVR on different train/test splits (e.g., 50/50, 70/30) and measuring Brier score variance across splits.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does incorporating the semantic dimension (topic context) into the calibration function significantly reduce the error rates observed in specific domains like Climate Change (underestimated) and Energy (overestimated)?
- Basis in paper: The authors state, "In the future, even the semantic dimension may be used to calibrate probabilities better," and provide a figure showing performance variance by topic.
- Why unresolved: The current calibration model employs a global Support Vector Regression approach that does not explicitly adjust for the semantic nuances or specific biases associated with individual topics.
- What evidence would resolve it: A comparative evaluation showing lower Brier scores or reduced systematic bias when a topic-aware calibration function is applied versus the current global method.

### Open Question 2
- Question: How can the practical utility of the generated forecasts be evaluated distinct from their raw probabilistic accuracy?
- Basis in paper: The conclusion suggests that "future evaluations may target the utility of the forecast themselves" after having primarily tested the quality of the returned probabilities.
- Why unresolved: The current study evaluates performance solely using Brier scores (probabilistic accuracy) compared to baselines, without measuring the usefulness or actionability of the generated foresight in a real-world decision pipeline.
- What evidence would resolve it: A user study or decision-theoretic framework measuring the value of strategic decisions made using these forecasts versus decisions made without them.

### Open Question 3
- Question: Can the system be extended to reliably model the interactions between multiple simultaneous forecasts to create coherent, complex future scenarios?
- Basis in paper: The paper proposes exploiting the Forecast Generator to "create complex multi-forecast scenarios and analyse their interactions with the environment."
- Why unresolved: The current evaluation is limited to individual, isolated forecasts (N=72); the system has not yet been tested on its ability to handle dependencies or logical consistency between multiple generated events.
- What evidence would resolve it: A demonstration of the system generating a web of interrelated forecasts where the joint probabilities are logically consistent (e.g., mutual exclusivity or dependency is preserved).

### Open Question 4
- Question: Does the integration of this probability estimation system measurably improve the reliability of LLM-powered agent simulations?
- Basis in paper: The paper claims simulations "can become more reliable having a system which can compute probabilities," but provides no experimental data from agent simulations to substantiate this potential application.
- Why unresolved: The inference is based on the theoretical utility of uncertainty quantification, but the paper only validates the forecaster, not the downstream impact on agent behavior.
- What evidence would resolve it: A comparative study of LLM-agent simulation outcomes (e.g., in a strategy game or market simulation) with and without the Probability Estimator module.

## Limitations

- **Dataset representativeness and size:** The study relies on N=72 test forecasts from a hand-curated set of 150 forecasts across 15 topics, raising concerns about overfitting and generalizability to different forecasting domains.

- **Log probability calibration assumptions:** The core innovation assumes that token log probabilities from GPT-4o accurately reflect the model's confidence in its probability estimates, but this assumption is not empirically validated.

- **Implementation opacity:** Critical details are missing, including exact prompt templates for each component, the semantic search implementation for trend filtering, and SVR hyperparameters, making it difficult to assess reproducibility.

## Confidence

**High confidence:** The general framework of combining LLM probability outputs with log probability weighting is sound and aligns with established practices in LLM calibration and uncertainty quantification.

**Medium confidence:** The claimed 19% Brier score improvement over GPT-4o and 26% improvement over random baselines. While the methodology is plausible, the small test set (N=72) and lack of ablation studies on individual components make it difficult to isolate the true sources of improvement.

**Low confidence:** The claim that log probability weighting alone provides the primary performance benefit. Without ablations comparing weighted vs. unweighted aggregation, and without validation that log probabilities correlate with estimation accuracy, this remains speculative.

## Next Checks

1. **Replicate the core probability estimation pipeline** on a held-out set of 20 events using the same methodology. Compare single-completion probability estimates against logprob-weighted aggregation to empirically verify the 19% improvement claim and test the stability of the logprob weighting mechanism.

2. **Ablate the trend augmentation component** by running the Probability Estimator pipeline twice: once with semantic trend filtering and once without. Measure the change in Brier score to isolate the contribution of external trend data to overall performance.

3. **Test calibration robustness** by training the SVR model on different train/test splits (e.g., 50/50, 70/30, 5-fold cross-validation) and measuring Brier score variance across splits. This will reveal whether the calibration procedure is stable or overfitting to a particular data partition.