---
ver: rpa2
title: Why Can't I Open My Drawer? Mitigating Object-Driven Shortcuts in Zero-Shot
  Compositional Action Recognition
arxiv_id: '2601.16211'
source_url: https://arxiv.org/abs/2601.16211
tags:
- seen
- unseen
- verb
- learning
- object
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper identifies object-driven verb shortcuts as a critical
  failure mode in Zero-Shot Compositional Action Recognition (ZS-CAR). These shortcuts
  arise from compositional sparsity and the asymmetric learning difficulty between
  verbs (requiring temporal reasoning) and objects (recognizable from single frames).
---

# Why Can't I Open My Drawer? Mitigating Object-Driven Shortcuts in Zero-Shot Compositional Action Recognition

## Quick Facts
- **arXiv ID:** 2601.16211
- **Source URL:** https://arxiv.org/abs/2601.16211
- **Authors:** Geo Ahn; Inwoong Lee; Taeoh Kim; Minho Shim; Dongyoon Wee; Jinwoo Choi
- **Reference count:** 40
- **Primary result:** RCORE framework significantly improves unseen composition accuracy in ZS-CAR by mitigating object-driven shortcuts

## Executive Summary
This paper identifies object-driven verb shortcuts as a critical failure mode in Zero-Shot Compositional Action Recognition (ZS-CAR). These shortcuts arise from compositional sparsity and the asymmetric learning difficulty between verbs (requiring temporal reasoning) and objects (recognizable from single frames). Existing ZS-CAR models increasingly rely on object cues and co-occurrence statistics during training, leading to negative compositional gaps and poor generalization to unseen verb-object combinations.

The authors propose RCORE, a framework that includes VOCAMix (a composition-aware augmentation that synthesizes plausible unseen combinations while preserving temporal structure) and TORC (a temporal order regularization loss that penalizes reliance on static cues). Across two benchmarks (Sth-com and EK100-com), RCORE significantly improves unseen composition accuracy, reduces co-occurrence bias, achieves positive compositional gaps, and demonstrates that object-driven shortcuts—not model capacity—are the primary obstacle in compositional video understanding.

## Method Summary
The RCORE framework addresses object-driven shortcuts in ZS-CAR through two main components: VOCAMix augmentation and TORC regularization. VOCAMix creates synthetic compositions by combining objects from different training samples while preserving their temporal relationships, effectively simulating plausible unseen verb-object combinations. TORC introduces a temporal order regularization loss that encourages models to rely on temporal cues rather than static visual features, directly penalizing object-driven shortcuts. The framework is evaluated on Sth-com and EK100-com benchmarks, showing significant improvements in unseen composition accuracy and compositional gaps compared to existing methods.

## Key Results
- RCORE achieves significant improvements in unseen composition accuracy across both Sth-com and EK100-com benchmarks
- The framework reduces co-occurrence bias and achieves positive compositional gaps, indicating better generalization to unseen combinations
- Object-driven shortcuts are identified as the primary obstacle in compositional video understanding, not model capacity limitations

## Why This Works (Mechanism)
RCORE works by addressing the fundamental mismatch between how verbs and objects are learned in ZS-CAR. Verbs require temporal reasoning to understand the action dynamics, while objects can often be recognized from single frames. This creates an asymmetric learning difficulty that existing models exploit through object-driven shortcuts. By synthesizing plausible unseen compositions through VOCAMix and enforcing temporal reasoning through TORC, RCORE forces models to learn the true compositional relationships rather than relying on spurious correlations between objects and verbs.

## Foundational Learning
- **Compositional sparsity**: Why needed - explains why models overfit to training co-occurrences; Quick check - measure verb-object co-occurrence distribution in training data
- **Temporal reasoning**: Why needed - distinguishes verb understanding from object recognition; Quick check - analyze model performance on static vs. dynamic cues
- **Zero-shot learning**: Why needed - framework must generalize to unseen compositions; Quick check - validate on held-out verb-object combinations
- **Augmentation strategies**: Why needed - synthetic data can simulate rare/unseen compositions; Quick check - evaluate plausibility of generated compositions

## Architecture Onboarding

**Component map:** Input videos → Feature extraction → VOCAMix augmentation → Temporal modeling → TORC regularization → Compositional classifier

**Critical path:** Feature extraction → VOCAMix → Temporal modeling → Compositional classifier (TORC regularization is applied during training only)

**Design tradeoffs:** VOCAMix trades computational overhead for improved generalization; TORC adds regularization complexity but reduces shortcut reliance

**Failure signatures:** Decreased performance on rare compositions; increased reliance on object co-occurrence statistics; negative compositional gaps

**Three first experiments:**
1. Ablation study: VOCAMix only vs. TORC only vs. combined RCORE
2. Analysis of temporal vs. static feature reliance with and without TORC
3. Evaluation of synthetic composition plausibility through human studies

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- VOCAMix augmentation assumes object-object co-occurrence statistics can generate plausible unseen combinations, which may not hold for complex interactions
- The framing of verbs as requiring "temporal reasoning" is reductive, as some verbs like "exist" or "stand" can be recognized from static frames
- Compositional gap metric depends on specific train/validation splits and may not generalize across different benchmark configurations

## Confidence
- **High confidence:** Object-driven shortcuts are a primary failure mode in ZS-CAR (well-supported empirical evidence)
- **Medium confidence:** TORC effectively reduces reliance on static cues (novel but impact intertwined with VOCAMix)
- **High confidence:** RCORE achieves positive compositional gaps (supported by reported results, though practical significance needs validation)

## Next Checks
1. Ablation studies isolating VOCAMix augmentation versus TORC regularization contributions
2. Testing RCORE on datasets with different compositional sparsity levels
3. Human evaluation studies to verify synthetic compositions generated by VOCAMix are plausible and representative of real-world unseen combinations