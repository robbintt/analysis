---
ver: rpa2
title: 'TokenPowerBench: Benchmarking the Power Consumption of LLM Inference'
arxiv_id: '2512.03024'
source_url: https://arxiv.org/abs/2512.03024
tags:
- uni00000157
- uni00000156
- energy
- power
- inference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TokenPowerBench introduces the first comprehensive, open-source
  benchmark for measuring and analyzing the power consumption of large language model
  (LLM) inference. The tool provides a modular, extensible framework with phase-aware
  telemetry that captures energy usage at the GPU, node, and system levels without
  requiring specialized power meters.
---

# TokenPowerBench: Benchmarking the Power Consumption of LLM Inference

## Quick Facts
- arXiv ID: 2512.03024
- Source URL: https://arxiv.org/abs/2512.03024
- Reference count: 11
- First comprehensive open-source benchmark for LLM inference power consumption

## Executive Summary
TokenPowerBench introduces a modular, extensible framework for measuring and analyzing the power consumption of large language model (LLM) inference. The tool provides phase-aware telemetry that captures energy usage at GPU, node, and system levels without requiring specialized power meters. It supports over 15 open-source LLMs ranging from 1B to 405B parameters, enabling systematic exploration of how configuration parameters affect energy efficiency. Evaluations demonstrate that quantization can reduce energy per token by approximately 30% while improving throughput, offering actionable insights for reducing operational costs and meeting sustainability targets in LLM deployments.

## Method Summary
TokenPowerBench employs a comprehensive telemetry approach that captures energy usage across multiple system levels. The framework integrates with popular inference engines like vLLM and supports various parallelization strategies. Power measurement is achieved through software-based monitoring of GPU utilization, memory bandwidth, and thermal metrics, validated against hardware power meters for accuracy. The benchmark suite systematically varies parameters including batch size, context length, and quantization levels to characterize their impact on power consumption. Data collection is automated and reproducible, enabling comparative analysis across different models and deployment configurations.

## Key Results
- Power consumption varies significantly with model size, prompt length, and inference engine choice
- Quantization reduces energy per token by approximately 30% while improving throughput
- System-level telemetry provides reliable power measurements without specialized hardware

## Why This Works (Mechanism)
The benchmark's effectiveness stems from its phase-aware telemetry architecture that captures energy consumption patterns across different stages of LLM inference. By monitoring at GPU, node, and system levels simultaneously, it provides a holistic view of power usage that correlates with computational intensity and memory access patterns. The modular design allows for easy integration with existing inference frameworks and supports various quantization techniques, enabling direct comparison of their energy efficiency impacts.

## Foundational Learning
- **GPU power telemetry APIs**: Understanding NVIDIA's NVML and system-level power monitoring is crucial for accurate measurements. Quick check: Verify power readings against a hardware meter.
- **Quantization techniques**: Knowledge of 8-bit and 4-bit quantization methods helps interpret energy savings. Quick check: Compare FP16 vs INT8 model performance.
- **Parallelization strategies**: Understanding tensor and pipeline parallelism is essential for analyzing configuration impacts. Quick check: Measure power differences between data and tensor parallelism.
- **Phase-aware monitoring**: Recognizing distinct phases of inference (prefill, decode) enables targeted optimizations. Quick check: Profile power consumption per phase.

## Architecture Onboarding
**Component Map**: Telemetry Collector -> Power Analyzer -> Benchmark Orchestrator -> Model Registry
**Critical Path**: Model loading → Telemetry initialization → Inference execution → Power data collection → Analysis and reporting
**Design Tradeoffs**: Software-based monitoring offers accessibility but may lack precision of hardware meters; modular design enables extensibility but adds complexity
**Failure Signatures**: Inconsistent power readings may indicate thermal throttling; missing telemetry data suggests API compatibility issues
**First Experiments**:
1. Run a simple 7B parameter model with default settings to validate baseline measurements
2. Compare power consumption between vLLM and native PyTorch inference
3. Test quantization impact on a medium-sized model (20B parameters)

## Open Questions the Paper Calls Out
None

## Limitations
- Energy measurement methodology relies on software telemetry that may introduce calibration drift across heterogeneous GPU architectures
- Analysis focuses primarily on NVIDIA GPUs, limiting generalizability to other accelerator types
- Does not account for thermal throttling effects over extended inference sessions

## Confidence
- Quantization reduces energy per token by ~30%: High
- Software telemetry provides reliable measurements: Medium
- Results generalize across all GPU architectures: Low

## Next Checks
1. Validate cross-architecture portability by running the same benchmark suite on AMD Instinct and Google TPU accelerators, documenting telemetry API compatibility and measurement variance
2. Conduct thermal stress testing over 24-hour continuous inference runs to quantify performance degradation and power draw evolution under sustained load
3. Extend the model corpus to include at least three proprietary frontier models (e.g., GPT-4, Claude 3) through API-based measurement to assess whether observed energy-efficiency patterns hold at the upper end of the capability spectrum