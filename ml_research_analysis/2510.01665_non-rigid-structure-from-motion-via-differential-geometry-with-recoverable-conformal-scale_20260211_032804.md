---
ver: rpa2
title: Non-Rigid Structure-from-Motion via Differential Geometry with Recoverable
  Conformal Scale
arxiv_id: '2510.01665'
source_url: https://arxiv.org/abs/2510.01665
tags:
- dataset
- conformal
- ieee
- image
- depth
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents Con-NRSfM, a novel method for non-rigid structure-from-motion
  (NRSfM) under conformal deformations. The core idea is to leverage the rotational
  invariance of connections under conformal deformation to decouple depth and conformal
  scale estimation, overcoming limitations of existing methods that rely on strict
  assumptions like locally planar surfaces or locally linear deformations.
---

# Non-Rigid Structure-from-Motion via Differential Geometry with Recoverable Conformal Scale

## Quick Facts
- **arXiv ID:** 2510.01665
- **Source URL:** https://arxiv.org/abs/2510.01665
- **Reference count:** 40
- **Primary result:** Novel Con-NRSfM method leverages rotational invariance of connections under conformal deformation to decouple depth and scale estimation, outperforming existing methods on synthetic and real datasets.

## Executive Summary
This paper introduces Con-NRSfM, a novel approach to non-rigid structure-from-motion (NRSfM) that generalizes beyond isometric assumptions by explicitly modeling conformal deformations. The method exploits the rotational invariance of Cartan's connections under conformal deformation to decouple depth and conformal scale estimation, overcoming limitations of existing methods that rely on strict assumptions like locally planar surfaces or locally linear deformations. By formulating the problem using 2D image warps and solving it with a parallel separable iterative optimization strategy, Con-NRSfM achieves superior reconstruction accuracy and robustness, especially for strongly bending and non-isometric deformations.

## Method Summary
Con-NRSfM uses differential geometry to formulate NRSfM under conformal deformations, establishing that connections are rotationally invariant under such deformations. The method constructs a graph of image pairs, computes 2D image warps, and solves for depth and conformal scale using a parallel separable iterative optimization that alternates between updating second-order terms, first-order terms, depth, and scale. A self-supervised encoder-decoder network generates dense textured point clouds from sparse normal fields, trained on synthetic polynomial surfaces. The approach handles $N_m$ images efficiently without computing all $O(N_m^2)$ warps by selecting a maximum spanning tree based on tree-connectivity.

## Key Results
- Outperforms existing state-of-the-art methods in reconstruction accuracy and robustness
- Achieves lower mean 3D errors and shape errors across various challenging datasets
- Successfully handles non-isometric and strongly bending deformations where competitors fail
- Dense network generates textured point clouds from sparse normal fields

## Why This Works (Mechanism)

### Mechanism 1: Decoupling via Rotational Invariance of Connections
The paper establishes that conformal deformations preserve the rotational invariance of Cartan's connections ($\Gamma$), allowing the framework to treat rotation $R$ as a nuisance variable that cancels out in connection constraints. This isolates conformal scale $\lambda$ and depth $\beta$ into separate terms, enabling more precise depth estimation for non-isometric shapes.

### Mechanism 2: Parallel Separable Iterative Optimization
Instead of solving for all variables simultaneously in a massive NLLS, the method iterates through them in distinct steps (Pre-Step → Steps 1-4). This exploits independence of point-wise factors for parallelization while maintaining global consistency through the graph structure, improving robustness to initialization.

### Mechanism 3: Dense Geometry Hallucination from Sparse Normals
A self-supervised encoder-decoder network learns to reconstruct dense textured surfaces from sparse normal fields by training on simulated fifth-degree polynomial surfaces, filling gaps left by the sparse graph optimization.

## Foundational Learning

- **Differential Geometry (Cartan's Moving Frames & Connections):** Needed to express surface properties using moving frames $E$ and connection matrices $\Gamma$ rather than coordinates. Quick check: Can you explain how a "connection" measures the change in a moving frame relative to a coordinate direction?

- **Conformal vs. Isometric Deformation:** Needed to generalize NRSfM from isometric (distance-preserving) to conformal (angle-preserving) by explicitly modeling conformal scale $\lambda$. Quick check: What happens to the Jacobian of the deformation mapping if the deformation is strictly isometric versus conformal?

- **Graph-based Optimization (Edge Selection):** Needed to handle $N_m$ images efficiently without computing all $O(N_m^2)$ warps by selecting a maximum spanning tree based on tree-connectivity. Quick check: Why is maximizing tree connectivity (log-determinant) preferred over simply maximizing the sum of edge weights for SLAM/NRSfM graphs?

## Architecture Onboarding

- **Component map:** Input (Monocular images + Feature Correspondences) → Graph Selector (Kruskal's) → Image Warp Calculator → Parallel Optimizer (Depth, Normals, Scale) → DenseNet-169 Encoder-Decoder → Dense Point Cloud + Texture

- **Critical path:** 1) Graph Selection: Construct $G_{opt}$ from image matches. 2) Warping: Compute 2D image warps $\eta_{ij}$ and derivatives. 3) Initialization (Pre-Step): Estimate normals and depth assuming isometry. 4) Iterative Refinement: Loop Steps 1-4 (update 2nd-order terms → 1st-order → integrate depth → optimize scale $\lambda$). 5) Densification: Feed sparse normals to trained network for textured dense output.

- **Design tradeoffs:** Separable vs. Joint Optimization (trading theoretical convergence guarantees for numerical stability and parallel efficiency); LP/LL vs. Second-Order (retaining second-order derivatives increases accuracy for bending surfaces but introduces more variables).

- **Failure signatures:** Non-Manifold Geometry (fails on self-intersections or detached components); Memory Overflow (struggles with massive datasets due to MATLAB TRR constraints).

- **First 3 experiments:** 1) Sanity Check (Synthetic Balls): Verify computed connection invariance is satisfied exactly using second-order terms. 2) Noise Robustness (T-shirt): Run ablation with Gaussian noise to verify "Without separable opt." baseline degrades faster. 3) Scale Recovery (Conformal Balloon): Test on self-collected conformal dataset to ensure estimated $\lambda$ correctly tracks inflation scale change.

## Open Questions the Paper Calls Out

1. **Integration with 4D Gaussian Splatting:** Can the local physical constraints (conformal scale and connections) be effectively integrated into a 4D Gaussian Splatting SLAM system to enhance reconstruction accuracy? The paper proposes combining image rendering with assumed physical information.

2. **Handling Topological Changes and Self-Occlusions:** How can the framework be extended to handle topological changes and self-occlusions without invalidating the underlying Riemannian manifold assumption? The current mathematical formulation relies on diffeomorphic mappings that presuppose a continuous, smooth manifold.

3. **Real-time Processing for Online SLAM:** Can the separable optimization framework be reformulated to remove memory constraints and enable real-time processing for online monocular deformable SLAM? The current MATLAB implementation faces memory constraints on large datasets.

## Limitations

- **Scale-Translation Ambiguity:** Inherits inherent ambiguity between global scale and translation; absolute metric reconstruction remains unanchored without additional constraints.
- **Conformal Assumption Strictness:** Theoretical guarantees rely on exact conformal deformation; real-world deformations often exhibit local deviations from perfect angle preservation.
- **Memory Scalability:** Current MATLAB implementation shows limitations with large-scale datasets, requiring dataset segmentation.

## Confidence

**High Confidence (8/10):**
- Theorem 1 on rotational invariance of connections under conformal deformation
- Ablation study results showing separable optimization improves robustness
- Comparison against established baselines on standard datasets

**Medium Confidence (6/10):**
- Performance claims on self-collected conformal balloon dataset
- Dense network generalization claims
- Memory scalability limitations based on MATLAB implementation

## Next Checks

1. **Conformal Deformation Stress Test:** Apply method to synthetic sequence transitioning from conformal to non-conformal regions (balloon inflation then stretching) to quantify conformal assumption limits.

2. **Polynomial Domain Gap Analysis:** Test dense reconstruction network on real-world datasets with sharp features (cloth folding with creases, articulated body parts) to identify limitations of polynomial-based training.

3. **Memory Scaling Benchmark:** Implement C++ version of graph optimization core and benchmark memory usage/runtime on progressively larger datasets (100, 500, 1000 frames) to identify practical bottlenecks.