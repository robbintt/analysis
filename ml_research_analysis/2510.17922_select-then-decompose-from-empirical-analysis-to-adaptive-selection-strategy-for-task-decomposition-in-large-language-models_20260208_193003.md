---
ver: rpa2
title: 'Select-Then-Decompose: From Empirical Analysis to Adaptive Selection Strategy
  for Task Decomposition in Large Language Models'
arxiv_id: '2510.17922'
source_url: https://arxiv.org/abs/2510.17922
tags:
- task
- decomposition
- subtask
- performance
- approaches
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of balancing performance and
  computational cost in task decomposition using large language models (LLMs). The
  authors systematically analyze existing task decomposition methods, identifying
  six categorization schemes and conducting empirical experiments to uncover three
  key insights: task decomposition approaches face a performance-cost dilemma, task
  characteristics determine the optimal decomposition strategy, and execution model
  scaling has greater impact than decomposition model scaling.'
---

# Select-Then-Decompose: From Empirical Analysis to Adaptive Selection Strategy for Task Decomposition in Large Language Models

## Quick Facts
- **arXiv ID**: 2510.17922
- **Source URL**: https://arxiv.org/abs/2510.17922
- **Reference count**: 40
- **Primary result**: Dynamic task decomposition selection achieves 5-7% better performance with 24-35% of the token cost compared to fixed methods

## Executive Summary
This paper addresses the challenge of balancing performance and computational cost in task decomposition using large language models (LLMs). The authors systematically analyze existing task decomposition methods, identifying six categorization schemes and conducting empirical experiments to uncover three key insights: task decomposition approaches face a performance-cost dilemma, task characteristics determine the optimal decomposition strategy, and execution model scaling has greater impact than decomposition model scaling. Based on these findings, they propose the Select-Then-Decompose (S&D) strategy, a closed-loop framework that dynamically selects appropriate decomposition approaches based on task complexity and verifies solution confidence. Comprehensive experiments across five benchmarks show that S&D consistently achieves Pareto optimality, outperforming individual methods by 5-7% on average while using only 24-35% of the token cost.

## Method Summary
The Select-Then-Decompose strategy is a three-stage closed-loop framework: (1) Selection Module uses an LLM with a prompt to analyze task characteristics (logical rigor, iterativity, divergent thinking) and select the optimal decomposition approach; (2) Execution Module applies the chosen decomposition method (IO, CoT, P&S, ReAct, P&E, or P&E-DAG) to generate a solution; (3) Validation Module scores solution confidence and triggers fallback escalation through a hierarchy of method groups if confidence falls below threshold T=0.7. The framework defaults to cheaper implicit methods (CoT, P&S) and escalates to explicit methods (ReAct, P&E) only when verification fails, with maximum 3 attempts per query. The system uses GPT-4o-mini as the base model with temperature=0 and seed=42.

## Key Results
- S&D achieves Pareto-optimal performance-cost trade-off, outperforming individual methods by 5-7% on average while using only 24-35% of the token cost
- Implicit decomposition approaches dominate, comprising approximately 85% of final selections across benchmarks, with explicit approaches used only 15% of the time
- Validation module significantly improves performance (2.90% increase on HumanEval) and provides calibrated confidence thresholds for optimal switching
- S&D consistently lies on or near the Pareto frontier across all five benchmarks (GSM8K, MATH, HumanEval, Trivia Creative Writing, HotpotQA)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dynamic selection of decomposition approaches based on task characteristics improves the performance-cost tradeoff compared to fixed approaches.
- Mechanism: An LLM-based Selection Module analyzes the input question along three dimensions—logical rigor (clear goals/steps), iterativity (need for multiple attempts/corrections), and divergent thinking (information synthesis)—then maps these to suitable decomposition strategies: CoT/P&S for logical tasks, ReAct for iterative tasks, P&E(DAG) for divergent tasks.
- Core assumption: The selection LLM can accurately classify task characteristics and map them to optimal decomposition strategies via prompting alone (no training).
- Evidence anchors:
  - [abstract] "This strategy dynamically selects the most suitable decomposition approach based on task characteristics and enhances the reliability of the results through a verification module."
  - [section 3.2] "Task characteristics determine the sequence, calling form, and topology of task decomposition... CoT is suitable for mathematical problems, P&E (DAG) for writing tasks, and ReAct for coding tasks."
  - [corpus] Related work on adaptive planning (SDA-PLANNER, arXiv:2509.26375) supports state-dependency aware selection but operates in embodied settings; limited direct corpus evidence for task-to-method mapping in text-based decomposition.
- Break condition: If the selection LLM is too weak to reliably classify tasks, or if task characteristics are ambiguous (e.g., hybrid tasks with both logical and divergent components), selection quality degrades, potentially increasing cost without performance gain.

### Mechanism 2
- Claim: A staged confidence-based fallback mechanism prevents low-quality solutions while controlling escalation costs.
- Mechanism: After execution, a Validation Module scores solution confidence C∈[0,1]. If C < T (threshold, default 0.7), the system escalates through a fixed hierarchy: {IO} → implicit {CoT, P&S} → explicit {ReAct, P&E, P&E(DAG)}, sampling uniformly within each group. This prevents premature commitment to expensive methods while ensuring quality floors.
- Core assumption: The validation LLM can produce calibrated confidence scores that correlate with actual solution correctness; threshold T generalizes across task types.
- Evidence anchors:
  - [section 4.1] "If C≥T, where T is a predefined threshold, the solution is accepted; otherwise, the system initiates a staged switching mechanism that sequentially explores {IO}, implicit approaches {CoT, P&S}, and explicit approaches..."
  - [section 5.3] Ablation shows removing validation reduces performance by 2.90% on HumanEval; sensitivity analysis (Figure 7) shows T=0.7 balances cost and performance.
  - [corpus] Uncertainty Profiles for LLMs (arXiv:2505.07309) explores uncertainty decomposition for hallucination detection, supporting confidence-based verification but not specifically for decomposition fallback.
- Break condition: If confidence scores are miscalibrated (e.g., high confidence in wrong answers for complex reasoning), the fallback mechanism either escalates unnecessarily (high cost) or accepts incorrect solutions (low quality).

### Mechanism 3
- Claim: Starting with cheaper implicit approaches and escalating only on verification failure achieves Pareto-optimal cost-performance balance.
- Mechanism: Implicit methods (CoT, P&S) use ~1 LLM call; explicit methods (ReAct, P&E) use 5-8+ calls. S&D defaults to implicit (~85% of final selections across benchmarks), reserving explicit for complex/failed cases. This exploits the insight that many tasks are over-decomposed by expensive methods.
- Core assumption: Most tasks can be solved adequately by implicit methods; explicit escalation is needed only for a minority of complex cases.
- Evidence anchors:
  - [abstract] "Comprehensive evaluations across multiple benchmarks show that the Select-Then-Decompose consistently lies on the Pareto frontier... outperforming individual methods by 5-7% on average while using only 24-35% of the token cost."
  - [section 5.2, Figure 6] "Implicit decomposition approaches dominate, comprising approximately 85%, while explicit approaches account for only about 15%."
  - [corpus] Weak direct corpus evidence; related work on PEFT (arXiv:2506.15251) addresses cost reduction via parameter-efficient adaptation, not decomposition strategy selection.
- Break condition: On tasks where implicit methods consistently fail (e.g., highly structured multi-hop reasoning requiring explicit planning), S&D's first-attempt bias increases retry overhead, potentially matching or exceeding fixed explicit method costs.

## Foundational Learning

- Concept: **Task Decomposition Taxonomy** (decomposition-first vs. interleaved; implicit vs. explicit; linear vs. DAG)
  - Why needed here: Understanding the six categorization schemes is prerequisite to reasoning about which approach fits which task type; without this, the selection module's mapping is opaque.
  - Quick check question: Given a multi-hop QA task requiring parallel information retrieval followed by synthesis, which topology (linear vs. DAG) is appropriate and why?

- Concept: **Pareto Optimality in Performance-Cost Tradeoffs**
  - Why needed here: S&D's core claim is achieving Pareto frontier position; engineers must understand that "better" means improving performance without proportional cost increase, not just maximizing either dimension.
  - Quick check question: If Method A achieves 90% accuracy at 1000 tokens and Method B achieves 92% at 5000 tokens, which lies closer to the Pareto frontier and how would you verify this empirically?

- Concept: **LLM Confidence Calibration**
  - Why needed here: The validation module's threshold T assumes confidence scores correlate with correctness; miscalibration breaks the fallback logic.
  - Quick check question: How would you test whether your validation LLM's confidence scores are calibrated (i.e., P(correct | confidence=0.8) ≈ 0.8) across task types?

## Architecture Onboarding

- Component map: Question Q → Selection Module → method A → Execution Module → solution S → Validation Module → confidence C → (if C<T) Fallback Controller → (next method) → repeat from Execution

- Critical path:
  1. Question Q enters Selection Module → method A selected
  2. Execution Module applies A → solution S generated
  3. Validation Module scores S → confidence C computed
  4. If C < T: Fallback Controller increments attempt, selects next method from hierarchy, repeat from step 2
  5. If C ≥ T or max attempts reached: return S

- Design tradeoffs:
  - **Threshold T**: Lower T reduces cost but accepts lower-quality solutions; higher T improves quality but increases retries. Paper uses T=0.7 based on sensitivity analysis (Figure 7).
  - **Max attempts K**: Higher K increases robustness but risks runaway costs; default K=3 balances coverage and constraint.
  - **Selection LLM choice**: Stronger models improve selection accuracy but increase per-query overhead; paper uses GPT-4o-mini.
  - **Assumption**: Validation uses same LLM family as selection; separating these (e.g., smaller validator) could reduce cost but may miscalibrate confidence.

- Failure signatures:
  - **Runaway retries**: If T is set too high or validation is overly strict, system exhausts K attempts without accepting solutions. Symptom: high API call counts, low successful return rate.
  - **Selection degradation**: Weak selection LLM misclassifies tasks, defaulting to suboptimal methods. Symptom: implicit methods used for tasks requiring explicit planning, low accuracy.
  - **False confidence**: Validation assigns high C to incorrect solutions. Symptom: high accepted-solution error rate, especially on novel task distributions.
  - **Cost explosion on complex tasks**: Tasks requiring explicit methods trigger full escalation path. Symptom: token cost approaches or exceeds fixed explicit baselines.

- First 3 experiments:
  1. **Reproduce Pareto frontier analysis**: Run S&D and all baseline methods on 2-3 benchmarks (e.g., GSM8K, HumanEval, HotpotQA). Plot accuracy vs. log(token cost). Verify S&D lies on or near the Pareto frontier. Compare to paper's Figure 5.
  2. **Ablate validation threshold**: On Trivia Creative Writing, sweep T ∈ {0.5, 0.6, 0.7, 0.8, 0.9}. Plot accuracy and token cost vs. T. Identify optimal T for your target task distribution; compare to paper's T=0.7 finding.
  3. **Selection accuracy audit**: Manually label 50-100 samples from each benchmark with "ideal method" ground truth. Compare S&D's selections to ground truth. Compute selection accuracy per task type; identify systematic misclassification patterns (e.g., over-selection of implicit for structured tasks).

## Open Questions the Paper Calls Out

- How does the integration of external tools or specific representation formats (code vs. text) affect the Pareto optimality of the Select-Then-Decompose strategy?
- Can dedicated training or fine-tuning of the selection module outperform the current prompt-based approach, particularly for weaker models?
- How does the choice of verification module (e.g., LLM-based confidence vs. deterministic external validation) influence the switching frequency and total cost of the framework?

## Limitations

- The adaptive selection mechanism depends critically on the selection LLM's ability to classify task characteristics accurately across diverse domains, with potential generalization issues to novel task types.
- The staged fallback hierarchy assumes implicit methods are sufficient for most tasks, which may not hold for highly structured reasoning tasks requiring explicit planning from the start.
- The validation module's confidence calibration could be domain-specific, with potential miscalibration on tasks outside the evaluated benchmarks.

## Confidence

**High confidence**: The empirical demonstration that task decomposition approaches face a fundamental performance-cost tradeoff (Mechanism 1, Section 5.2).

**Medium confidence**: The effectiveness of the Select-Then-Decompose strategy in achieving Pareto optimality (Abstract claim).

**Medium confidence**: The staged confidence-based fallback mechanism's ability to prevent low-quality solutions while controlling costs (Mechanism 2).

## Next Checks

1. **Cross-domain generalization test**: Apply S&D to three novel task types not in the original benchmarks (e.g., legal reasoning, medical diagnosis, financial analysis). Measure selection accuracy and whether the performance-cost tradeoff holds.

2. **Hybrid task analysis**: Construct tasks that combine multiple characteristics (e.g., logical multi-hop reasoning requiring both CoT and ReAct-style tool use). Evaluate whether the selection module can identify optimal hybrid strategies or defaults to suboptimal single approaches.

3. **Confidence calibration audit**: Systematically vary the validation threshold T from 0.5 to 0.95 on a held-out test set. Plot accuracy vs. confidence threshold to identify regions where calibration breaks down.