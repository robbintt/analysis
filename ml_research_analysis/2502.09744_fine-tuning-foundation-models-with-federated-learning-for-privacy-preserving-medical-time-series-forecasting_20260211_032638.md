---
ver: rpa2
title: Fine-Tuning Foundation Models with Federated Learning for Privacy Preserving
  Medical Time Series Forecasting
arxiv_id: '2502.09744'
source_url: https://arxiv.org/abs/2502.09744
tags:
- data
- clients
- local
- fine-tuning
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study explores federated learning (FL) for fine-tuning foundation
  models (FMs) on medical time series forecasting tasks using ECG and ICG data. FL
  is applied to enable privacy-preserving training across decentralized clients, with
  three FL approaches compared: FedAvg, FedProx, and Fed-LA.'
---

# Fine-Tuning Foundation Models with Federated Learning for Privacy Preserving Medical Time Series Forecasting

## Quick Facts
- arXiv ID: 2502.09744
- Source URL: https://arxiv.org/abs/2502.09744
- Reference count: 26
- Primary result: Federated Learning can outperform zero-shot Foundation Model baselines for medical time series forecasting, but local fine-tuning often achieves better accuracy when client data distributions are similar

## Executive Summary
This study investigates Federated Learning for fine-tuning foundation models on medical time series forecasting tasks using ECG and ICG data. The research compares three FL approaches (FedAvg, FedProx, and Fed-LA) against zero-shot and local fine-tuning baselines across different data distribution scenarios. Results demonstrate that FL effectiveness depends critically on client data heterogeneity, with FL outperforming local fine-tuning when each client has independent data distributions, but underperforming when distributions are IID. The work highlights the trade-offs between privacy preservation and model accuracy in medical applications.

## Method Summary
The study uses the Chronos foundation model (8M parameters) fine-tuned via Federated Learning on ECG and ICG data from Vital Signs and PTB-XL datasets. Three FL strategies were evaluated: FedAvg (baseline), FedProx (with proximal regularization), and Fed-LA (hybrid approach). Data was partitioned across 20 simulated clients using three strategies: IID partitioning (similar distributions), site-based non-IID partitioning (independent distributions), and modality-imbalanced partitioning (19 ECG + 1 ICG client). Models were trained for 30 rounds with 400 local steps per round, and performance was measured using RMSE, MAE, and sMAPE on 64-step forecasts.

## Key Results
- FL fine-tuning can outperform zero-shot baselines when client data distributions differ significantly
- Local fine-tuning achieves better accuracy than FL when client data distributions are IID and similar
- In heterogeneous scenarios with independent client distributions, FL methods marginally outperform local fine-tuning
- Severe modality underrepresentation (1 ICG client among 19 ECG clients) causes FL to match zero-shot performance on minority modality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Federated averaging can fine-tune Foundation Models on medical time series, outperforming zero-shot baselines when client data distributions differ.
- Mechanism: The global server distributes pretrained Chronos weights to clients, who perform local gradient updates on private ECG/ICG data. Updated weights are returned and aggregated via weighted averaging, refining the global model over 30 communication rounds.
- Core assumption: Aggregated gradient updates across diverse clients produce representations that generalize better than the frozen pretrained model.
- Evidence anchors:
  - [abstract] "Our empirical results demonstrated that while FL can be effective for fine-tuning FMs on time series forecasting tasks, its benefits depend on the data distribution across clients."
  - [section IV-A] "FL effectively fine-tunes the pre-trained Chronos FM for ECG time series data in this case. FL outperforms zero-shot across all metrics."
  - [corpus] Limited direct evidence on FM+FL for time series; "Closer to Reality: Practical Semi-Supervised Federated Learning for Foundation Model Adaptation" discusses FL for privacy-aware FM adaptation but in different domains.
- Break condition: When client data distributions are IID and similar to overall distribution, local fine-tuning outperforms FL (Strategy #1: local RMSE 0.049 vs. FedAvg 0.061).

### Mechanism 2
- Claim: FedProx's proximal term constrains local model drift, improving robustness under statistical heterogeneity.
- Mechanism: FedProx adds regularization term (α/2)|θᵢ,ᵣ₊₁ - θᵣ|² to each client's loss, penalizing deviation from the global model. This allows partial updates even when clients cannot complete full local convergence.
- Core assumption: Constraining local models closer to the global model improves aggregated quality when data distributions differ across clients.
- Evidence anchors:
  - [section III-A] "FedProx aims to mitigate the effects of statistical and system heterogeneity in FedAvg by introducing a proximal term in the local objective function."
  - [section IV-B] Table III shows FedProx achieving marginally better RMSE (0.082) than FedAvg (0.083) under non-IID partitioning.
  - [corpus] No direct corpus corroboration for this mechanism specifically in FM fine-tuning.
- Break condition: Poorly tuned α or extreme heterogeneity prevents sufficient adaptation to local patterns.

### Mechanism 3
- Claim: In heterogeneous scenarios where each client's distribution is independent of others, FL aggregation outperforms local fine-tuning by enabling cross-client knowledge transfer.
- Mechanism: When clients have independently different distributions (Strategy #2, PTB-XL sites), federated averaging combines complementary learning signals, producing a model that generalizes better than any single client's locally-tuned model.
- Core assumption: Distribution diversity across clients provides complementary signal benefiting all participants through aggregation.
- Evidence anchors:
  - [section IV-B] "FL algorithms performing better than the local fine-tuning and zero-shot approaches over the PTB-XL dataset with non-IID partitioning."
  - [section IV conclusion] "In scenarios where each client's local data distribution is independent of others (Strategy #2), FL techniques outperformed local fine-tuning, albeit by a small margin."
  - [corpus] "Foundation Models in Medical Image Analysis" notes FM generalization across imaging tasks but doesn't address FL specifically.
- Break condition: When one modality is severely underrepresented (1 ICG client among 19 ECG clients), the aggregated model matches zero-shot on the minority modality (Table IV: ICG FedAvg RMSE 0.065 vs. zero-shot 0.061).

## Foundational Learning

- **Federated Averaging (FedAvg)**
  - Why needed here: Baseline FL algorithm enabling collaborative learning without sharing raw medical data. Understanding weighted averaging by client data size is essential before exploring variants.
  - Quick check question: Why does FedAvg weight client updates by local data size rather than using simple parameter averaging?

- **Statistical Heterogeneity (non-IID data)**
  - Why needed here: The paper's core finding is that FL effectiveness depends critically on data distribution patterns. IID vs. non-IID determines whether FL deployment is worthwhile.
  - Quick check question: If Hospital A serves cardiac patients, Hospital B serves athletes, and Hospital C serves elderly patients—all collecting ECG data—is this IID or non-IID?

- **Zero-Shot Foundation Models**
  - Why needed here: The comparison baseline. Chronos is pretrained on large time series corpora and can forecast without task-specific training. The paper measures whether FL fine-tuning adds value beyond this.
  - Quick check question: What does "zero-shot" mean for time series forecasting, and why is it a meaningful baseline for medical applications?

## Architecture Onboarding

- **Component map:**
  - Central Server -> FlowerAI framework -> 20 Clients -> Chronos-tiny (8M params) -> PTB-XL/Vital Signs datasets -> Evaluation metrics (RMSE, MAE, sMAPE)

- **Critical path:**
  1. Initialize with pretrained Chronos weights (8M parameters)
  2. Server broadcasts global model θᵣ to all clients
  3. Each client performs 400 local training steps (batch size 64)
  4. Clients return updated weights θᵢ,ᵣ₊₁
  5. Server aggregates via weighted averaging: θᵣ₊₁ = (1/|D|)Σᵢ|dᵢ|θᵢ,ᵣ₊₁
  6. Repeat for R=30 rounds
  7. Evaluate using RMSE, MAE, sMAPE on client-held test sets

- **Design tradeoffs:**
  - Privacy vs. Performance: FL preserves locality but may underperform local fine-tuning in IID scenarios (Table II: local RMSE 0.049 vs. FedAvg 0.061)
  - Generalization vs. Specialization: Fed-LA attempts balance but convergence issues arose—"fine-tuning process in FL can impact convergence"
  - Participation incentives: If local fine-tuning outperforms FL, clients have no incentive to join federation
  - Communication overhead: More rounds improve quality but increase network costs

- **Failure signatures:**
  - IID underperformance: Local training outperforms all FL methods when distributions align (Table II)
  - Modality collapse: Single ICG client causes FL to match zero-shot on ICG (Table IV: FedAvg 0.065 ≈ zero-shot 0.061)
  - Fed-LA convergence difficulty: Post-FL local adaptation struggles—"more difficult for the model to effectively adapt to clients' local data"

- **First 3 experiments:**
  1. **Reproduce Strategy #1 (IID baseline):** Partition vital signs ECG data equally across 20 clients. Run FedAvg 30 rounds, compare vs. local fine-tuning and zero-shot. Expected: Local fine-tuning should match or exceed FL.
  2. **Introduce statistical heterogeneity:** Use PTB-XL site-based partitioning (varying 10–8910 samples per client). Compare FedAvg, FedProx, local training. Expected: FL methods marginally outperform local.
  3. **Test modality imbalance:** Replicate Strategy #3 (19 ECG + 1 ICG client). Measure per-modality performance to quantify minority modality penalty. Expected: Large ECG vs. ICG performance gap.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can meta-learning approaches (e.g., MAML, Personalized Federated Learning) improve convergence and adaptability when fine-tuning foundation models in federated settings for medical time series?
- Basis in paper: [explicit] The conclusion states: "Meta-learning approaches, such as Model-Agnostic Meta-Learning (MAML)... offer a compelling direction. Personalized Federated Learning (PFL) techniques... could enhance adaptability by enabling FMs to be fine-tuned on local clients with better convergence guarantees."
- Why unresolved: The paper only evaluated FedAvg, FedProx, and Fed-LA; meta-learning integration with FL for FM fine-tuning was proposed but not tested.
- What evidence would resolve it: Comparative experiments applying MAML-based FL to ECG/ICG forecasting tasks, measuring convergence rates and forecasting accuracy against the three tested approaches.

### Open Question 2
- Question: What causes convergence degradation in hybrid FL-local adaptation approaches, and how can it be mitigated?
- Basis in paper: [explicit] The authors note: "Further convergence analysis is needed to better understand its impact" regarding Fed-LA, and that "the fine-tuning process in FL can impact the model's convergence, making it more difficult for the model to effectively adapt to clients' local data during the subsequent fine-tuning stage."
- Why unresolved: Fed-LA showed no significant improvement over standard FL, suggesting the regularization term may interfere with effective local adaptation, but root causes were not investigated.
- What evidence would resolve it: Analysis of gradient dynamics during the local adaptation phase, and experiments with alternative regularization strategies or adaptive regularization strengths.

### Open Question 3
- Question: How can FL aggregation strategies be modified to prevent performance degradation on underrepresented data modalities?
- Basis in paper: [explicit] Strategy #3 experiments revealed: "This indicates a significant challenge in fine-tuning FMs for time series forecasting when there is underrepresented data across clients." ICG performance under FL was similar to zero-shot (RMSE 0.065 vs 0.061) while ECG showed substantial improvement.
- Why unresolved: Current FL aggregation appears dominated by majority modalities, causing minority modality performance to stagnate.
- What evidence would resolve it: Experiments with modality-aware weighted aggregation, clustering-based FL, or separate model branches for different modalities.

### Open Question 4
- Question: How does FL performance differ when clients have access to multiple modalities simultaneously rather than single modalities per client?
- Basis in paper: [explicit] The authors acknowledge: "Our setup, where each client is restricted to a single modality, is a limitation, as a more realistic scenario would involve clients with access to multiple modalities."
- Why unresolved: Real-world medical facilities typically collect multiple signal types; the artificial constraint may not reflect actual deployment conditions.
- What evidence would resolve it: Experiments with heterogeneous clients each holding both ECG and ICG data in varying proportions, comparing against the single-modality-per-client baseline.

## Limitations
- Critical hyperparameters (learning rate, optimizer, FedProx coefficient) not specified, preventing exact reproduction
- Performance claims rely on simulation rather than real-world federated deployments across healthcare institutions
- Severe statistical imbalance with 1 ICG client among 19 ECG clients may not generalize to more balanced scenarios

## Confidence
- Mechanism 1 (FL outperforming zero-shot): **Medium** - Results show benefit exists but depend heavily on data heterogeneity assumptions
- Mechanism 2 (FedProx regularization): **Low** - Limited empirical evidence and no corpus corroboration for FM fine-tuning specifically
- Mechanism 3 (FL outperforming local in heterogeneous scenarios): **Medium** - Supported by results but effect size is small and breaks under modality imbalance

## Next Checks
1. Implement controlled experiments varying client data distribution heterogeneity to quantify the threshold where FL becomes beneficial over local fine-tuning
2. Test Fed-LA with different weight decay strengths (λ) to identify optimal balance between global and local adaptation
3. Validate findings using real-world federated deployment across multiple healthcare institutions rather than simulated environments