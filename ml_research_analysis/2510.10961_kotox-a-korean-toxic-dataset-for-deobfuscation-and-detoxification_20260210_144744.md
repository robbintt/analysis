---
ver: rpa2
title: 'KOTOX: A Korean Toxic Dataset for Deobfuscation and Detoxification'
arxiv_id: '2510.10961'
source_url: https://arxiv.org/abs/2510.10961
tags:
- toxic
- korean
- dataset
- obfuscated
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "KOTOX is the first Korean dataset designed to address the challenge\
  \ of obfuscated toxic content in low-resource languages. It systematically categorizes\
  \ Korean obfuscation into five linguistic classes\u2014phonological, iconological,\
  \ transliteration-based, syntactic, and pragmatic\u2014and generates paired neutral-toxic\
  \ sentences with corresponding obfuscated variants."
---

# KOTOX: A Korean Toxic Dataset for Deobfuscation and Detoxification

## Quick Facts
- arXiv ID: 2510.10961
- Source URL: https://arxiv.org/abs/2510.10961
- Reference count: 40
- Primary result: KOTOX is the first Korean dataset addressing obfuscated toxic content, systematically categorizing five types of Korean obfuscation and enabling deobfuscation and detoxification tasks.

## Executive Summary
KOTOX is the first Korean dataset specifically designed to address the challenge of obfuscated toxic content in low-resource languages. It systematically categorizes Korean obfuscation into five linguistic classes—phonological, iconological, transliteration-based, syntactic, and pragmatic—and generates paired neutral-toxic sentences with corresponding obfuscated variants. The dataset supports three tasks: obfuscated toxic text classification, neutral text deobfuscation, and obfuscated toxic text sanitization. Experiments across multiple models show that fine-tuning on KOTOX improves robustness to obfuscated inputs while maintaining performance on clean data. For example, HateBERT trained on KOTOX reduces the performance gap on obfuscated text from 10.81% to 5.54% F1-score compared to training only on non-obfuscated toxic data. Human evaluation confirms high semantic preservation, and results on wild data demonstrate real-world applicability. The findings indicate that existing LLMs have limited understanding of obfuscated Korean text, making KOTOX a critical resource for advancing robustness against such content.

## Method Summary
KOTOX was constructed by first curating a seed set of 30,000 Korean sentences from the Dang, NIE, and SIMPA datasets, filtering for those containing obfuscation and toxicity. These sentences were manually classified into five obfuscation types: phonological, iconological, transliteration-based, syntactic, and pragmatic. Using these seeds, a systematic generation process created paired neutral-toxic sentences and their obfuscated variants, resulting in a dataset of 31,000 toxic sentences and 31,000 neutral sentences, each with obfuscated versions. The dataset was split into training, validation, and test sets. Three tasks were defined: classifying obfuscated toxic text, deobfuscating neutral text, and sanitizing obfuscated toxic text. Models including BERT, HateBERT, and various LLMs were fine-tuned on KOTOX, and their performance was evaluated using standard classification metrics and human assessment of semantic preservation.

## Key Results
- KOTOX systematically categorizes Korean obfuscation into five linguistic classes and supports three tasks: obfuscated toxic classification, neutral deobfuscation, and toxic sanitization.
- Fine-tuning on KOTOX improves model robustness to obfuscated inputs, reducing the performance gap on obfuscated text from 10.81% to 5.54% F1-score for HateBERT.
- Human evaluation confirms high semantic preservation, and experiments on wild data demonstrate real-world applicability of KOTOX-trained models.

## Why This Works (Mechanism)
KOTOX works by exposing models to systematically generated obfuscated toxic and neutral sentence pairs across five linguistic categories, enabling them to learn robust patterns for deobfuscation and detoxification. By fine-tuning on this diverse dataset, models gain the ability to recognize and process both clean and obfuscated text, reducing performance gaps when faced with real-world, obfuscated inputs.

## Foundational Learning
- **Korean linguistic obfuscation types** (phonological, iconological, transliteration-based, syntactic, pragmatic): Needed to systematically generate diverse obfuscated data; Quick check: Review dataset examples for each type.
- **Deobfuscation and detoxification tasks**: Needed to define clear model objectives; Quick check: Verify task definitions align with dataset structure.
- **Multilingual toxic language processing**: Needed to contextualize KOTOX in low-resource language challenges; Quick check: Compare KOTOX to similar datasets in other languages.
- **Fine-tuning multilingual transformers**: Needed to adapt models for Korean obfuscation; Quick check: Review model training and evaluation protocols.
- **Semantic preservation metrics**: Needed to ensure deobfuscation does not alter meaning; Quick check: Examine human evaluation methodology.
- **Wild data validation**: Needed to confirm real-world applicability; Quick check: Analyze results on external, unseen data.

## Architecture Onboarding
- **Component map**: Seed sentences → Manual classification → Synthetic generation → Dataset splits → Model fine-tuning → Evaluation
- **Critical path**: Seed curation → Classification → Generation → Fine-tuning → Evaluation
- **Design tradeoffs**: Synthetic generation ensures controlled diversity but may not capture all real-world obfuscation; manual classification ensures quality but limits scalability.
- **Failure signatures**: Overfitting to specific obfuscation patterns, loss of semantic meaning in deobfuscation, poor generalization to unseen obfuscation.
- **First experiments**:
  1. Fine-tune a Korean BERT model on KOTOX and evaluate on obfuscated and clean test sets.
  2. Perform human evaluation of semantic preservation on deobfuscated outputs.
  3. Test model robustness on live, dynamically generated obfuscated content from social media.

## Open Questions the Paper Calls Out
None

## Limitations
- Potential overfitting to specific obfuscation patterns used in dataset generation, limiting generalization.
- Evaluation relies on in-house annotators and automated metrics, which may introduce bias or miss subtle semantic shifts.
- Dataset focus on Korean limits generalizability to other low-resource languages; manual effort required constrains scalability.
- Performance gains on wild data are promising but not extensively validated across diverse domains.

## Confidence
- **High**: Dataset's novelty and systematic categorization of Korean obfuscation types are clearly demonstrated.
- **Medium**: Claims of significant improvement in model robustness to obfuscated inputs are supported, but depend on controlled conditions and may not capture all real-world scenarios.
- **Low**: Claims about semantic preservation and real-world applicability are supported by limited human evaluation and wild data experiments without extensive external validation.

## Next Checks
1. Conduct large-scale human evaluation across multiple annotator pools to verify semantic preservation and detect subtle meaning shifts.
2. Test KOTOX fine-tuned models on diverse, multilingual datasets to assess generalization to other low-resource languages.
3. Evaluate model performance on live, dynamically generated obfuscated content from social media to ensure robustness against evolving obfuscation techniques.