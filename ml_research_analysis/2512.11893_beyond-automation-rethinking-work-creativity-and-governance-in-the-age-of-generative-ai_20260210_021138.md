---
ver: rpa2
title: 'Beyond Automation: Rethinking Work, Creativity, and Governance in the Age
  of Generative AI'
arxiv_id: '2512.11893'
source_url: https://arxiv.org/abs/2512.11893
tags:
- governance
- systems
- autonomy
- human
- these
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study develops an Inclusive AI Governance Framework that addresses
  the complex interplay between generative AI deployment, labour market volatility,
  creative expression, and economic security. Through mixed-method analysis combining
  labour-market task-exposure modelling, sectoral diffusion mapping, and qualitative
  discourse critique, the research demonstrates that AI adoption creates uneven skill
  development and task redistribution across sectors and socio-demographic groups.
---

# Beyond Automation: Rethinking Work, Creativity, and Governance in the Age of Generative AI

## Quick Facts
- arXiv ID: 2512.11893
- Source URL: https://arxiv.org/abs/2512.11893
- Authors: Haocheng Lin
- Reference count: 0
- Primary result: Develops an Inclusive AI Governance Framework integrating task-exposure modelling, sectoral diffusion mapping, and Level 1.5 autonomy to address AI's impact on labour markets, creativity, and economic security

## Executive Summary
This study presents an Inclusive AI Governance Framework that addresses the complex interplay between generative AI deployment, labour market volatility, creative expression, and economic security. The research demonstrates that AI adoption creates uneven skill development and task redistribution across sectors and socio-demographic groups, with newer AI generations showing evidence of creative regression and sycophantic behavior. The framework introduces Level 1.5 autonomy as a human-centered design principle that preserves evaluative authority while enabling partial automation. The study positions Universal Basic Income as an essential economic stabilizer within a broader governance ecosystem encompassing skills development, proportional regulation, and creativity preservation.

## Method Summary
The research employs a mixed-method approach combining quantitative simulation with qualitative policy analysis. Task-exposure modelling uses O*NET and OECD task-intensity indices to classify occupations by automation susceptibility. Sectoral diffusion mapping visualizes AI adoption disparities across sectors and demographics using publicly available metrics. Cross-model behavioral comparison tests GPT-5.1, Microsoft Copilot (GPT-5), Google Gemini, and Anthropic Claude for failure modes including overconfidence, silent interruptions, factual fragility, and sycophancy. The Level 1.5 autonomy framework implements a human-AI workflow where AI proposes solutions, humans evaluate with alignment threshold α, and iterations continue until acceptance. Technical validation uses a Flask application prototype available on GitHub.

## Key Results
- AI adoption creates uneven skill development and task redistribution across sectors and socio-demographic groups
- Cross-model comparison reveals sycophantic behavior and creative regression in newer AI generations
- Level 1.5 autonomy framework preserves human evaluative authority while enabling partial automation
- UBI functions as an economic stabilizer within a broader governance ecosystem rather than standalone welfare

## Why This Works (Mechanism)
The framework succeeds by integrating economic, creative, and governance dimensions rather than treating them in isolation. Task-exposure modelling quantifies which occupations face algorithmic replication versus those requiring human creativity and contextual reasoning. Sectoral diffusion mapping reveals the "second-order digital divide" where access does not equal meaningful integration. Level 1.5 autonomy maintains human oversight while capturing efficiency gains from partial automation. The framework treats UBI as one component of a comprehensive ecosystem addressing skills gaps, regulatory proportionality, and creative preservation.

## Foundational Learning
- Task-exposure modelling: Quantifies proportion of work tasks algorithmically replicable vs. requiring human creativity/contextual reasoning. Why needed: To identify which occupations face genuine displacement versus augmentation. Quick check: Compare automation susceptibility classifications across different occupation categories.
- Sectoral diffusion mapping: Visualizes AI adoption disparities across sectors and demographics. Why needed: To reveal that access alone doesn't guarantee productive integration or skill accumulation. Quick check: Map AI-rich vs. AI-poor sector divides using public adoption surveys.
- Level 1.5 autonomy: Human-AI workflow where AI proposes, human evaluates with alignment threshold, iterates until acceptance. Why needed: Preserves human evaluative authority while enabling efficiency gains from partial automation. Quick check: Measure decision accuracy and cognitive load at different alignment thresholds.
- Cross-model behavioral analysis: Documents failure modes like sycophancy, silent interruptions, and creative regression. Why needed: Identifies erosion of epistemic trust and authentic expression in newer AI generations. Quick check: Run identical prompts across multiple model versions documenting failure patterns.

## Architecture Onboarding
- Component map: Task-exposure modelling -> Sectoral diffusion mapping -> Level 1.5 autonomy implementation -> Cross-model behavioral analysis -> UBI integration assessment
- Critical path: Quantify task exposure → Map diffusion disparities → Validate Level 1.5 workflows → Document model failures → Integrate economic stabilization mechanisms
- Design tradeoffs: Full automation maximizes efficiency but risks oversight loss; Level 1.5 maintains control but requires human cognitive resources; UBI alone insufficient without complementary skills development
- Failure signatures: Silent interruptions in AI responses, sycophantic agreement with incorrect premises, creative regression in storytelling, uneven skill development across demographics
- First experiments: 1) Run Flask prototype to validate human override functionality; 2) Execute cross-model comparison documenting refusal rates and output completeness; 3) Build task-exposure model using O*NET data to classify occupations by automation susceptibility

## Open Questions the Paper Calls Out
- Longitudinal creativity benchmarks: How can standardized test suites track generational drift in storytelling and speculative reasoning capabilities across successive model releases? Current evaluations are anecdotal; no established method quantifies creative regression over time.
- Second-order digital divide determinants: What explains why specific sectors and demographics fail to translate nominal access into productive workflow integration? Existing research lacks unified model explaining disparities in meaningful, sustained use.
- Safety-expression balance metrics: Can systematic methods quantify frequency of safety mechanisms over-triggering on legitimate creative or academic content? No current method measures extent of expression suppression or context misclassification errors.

## Limitations
- Incomplete methodological specification: Cross-model behavioral experiment lacks exact prompts; task-exposure modelling methodology not detailed; diffusion mapping sources not enumerated
- Technical implementation gaps: Level 1.5 autonomy depends on unspecified alignment threshold α and alignment_score() function; cannot reproduce exact decision-making loop
- Model behavior verification: Claims about sycophancy and creative regression require independent replication with controlled prompts across multiple model versions

## Confidence
- High confidence: Conceptual framework combining UBI with skills development and proportional regulation is well-articulated; uneven AI diffusion across sectors and demographics is supported by literature
- Medium confidence: Level 1.5 autonomy technical implementation described but not fully specified; mixed-method approach methodologically sound but requires more detail
- Low confidence: Specific model behavior claims (sycophancy, creative regression) cannot be independently verified without exact prompts and experimental conditions

## Next Checks
1. Replicate cross-model behavioural experiment using technical prototype and identical prompts across multiple GPT-4/Claude/Gemini versions, documenting refusal rates, silent interruptions, and output completeness with timestamps
2. Reconstruct task-exposure model using O*NET data with paper's criteria, testing whether occupation classifications match reported AI-rich/AI-poor categorization and documenting feature extraction methodology
3. Implement Level 1.5 autonomy loop with various α thresholds on standardized dataset, measuring how different alignment thresholds affect decision accuracy, cognitive load, and perceived autonomy compared to full automation