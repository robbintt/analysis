---
ver: rpa2
title: 'Not All Instances Are Equally Valuable: Towards Influence-Weighted Dataset
  Distillation'
arxiv_id: '2510.27253'
source_url: https://arxiv.org/abs/2510.27253
tags:
- dataset
- distillation
- real
- influence
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Influence-Weighted Distillation (IWD), a
  novel framework that enhances dataset distillation by incorporating influence functions
  to adaptively weight training instances. Traditional dataset distillation methods
  assume all real instances contribute equally, but in practice, datasets often contain
  redundant or harmful samples that degrade performance.
---

# Not All Instances Are Equally Valuable: Towards Influence-Weighted Dataset Distillation

## Quick Facts
- arXiv ID: 2510.27253
- Source URL: https://arxiv.org/abs/2510.27253
- Reference count: 14
- Primary result: Influence-weighted distillation consistently improves distilled dataset quality and model performance by up to 7.8% over baseline methods.

## Executive Summary
This paper introduces Influence-Weighted Distillation (IWD), a novel framework that enhances dataset distillation by incorporating influence functions to adaptively weight training instances. Traditional dataset distillation methods assume all real instances contribute equally, but in practice, datasets often contain redundant or harmful samples that degrade performance. IWD addresses this by estimating each instance's influence on the distillation objective and using these scores as soft, adaptive weights—prioritizing beneficial data while downweighting less useful or harmful ones. The framework is modular and can be seamlessly integrated into existing distillation methods. Extensive experiments on CIFAR10, CIFAR100, and SVHN demonstrate that IWD consistently improves distilled dataset quality and model performance, achieving accuracy gains of up to 7.8% over baseline methods.

## Method Summary
IWD replaces uniform instance averaging in dataset distillation with adaptive influence-based weights. The framework computes an influence score for each real instance relative to the synthetic set, then uses these scores (normalized via softmax) as soft weights in the distillation loss. This prioritizes instances that maximize the distillation objective while suppressing redundant or harmful gradients. The method is modular and can be integrated into existing distillation pipelines.

## Key Results
- IWD consistently improves distilled dataset quality and model performance by up to 7.8% over baseline methods
- The framework is robust across different datasets (CIFAR10, CIFAR100, SVHN) and neural network architectures
- IWD outperforms both uniform weighting and hard pruning approaches in ablation studies

## Why This Works (Mechanism)

### Mechanism 1: Influence-Weighted Objective Optimization
The framework computes an influence score for each real instance and uses these scores as adaptive weights in the loss function. This prioritizes instances that maximize the distillation objective while suppressing redundant or harmful gradients.

### Mechanism 2: Decomposed Influence Propagation
The total influence of an instance is decomposed into explicit (direct contribution to real-data statistics) and implicit (contribution propagated through parameter changes) terms, allowing the framework to account for how instances shift the model's internal state.

### Mechanism 3: Soft Weighting vs. Hard Pruning
Softly downweighting instances is more robust than hard pruning because it retains the information capacity of the full dataset distribution while still de-emphasizing low-value samples.

## Foundational Learning

- **Concept: Dataset Distillation (Bi-level Optimization)**
  - Why needed here: IWD is a plug-in for this process. One must understand the outer loop (optimizing synthetic data) vs. inner loop (training on synthetic data) to see where influence weighting fits.
  - Quick check question: Can you distinguish between the gradient update for the model weights θ and the gradient update for the synthetic data S?

- **Concept: Influence Functions (Robust Statistics)**
  - Why needed here: Core theoretical engine of IWD. It approximates the "leave-one-out" effect without retraining, using the inverse Hessian to measure parameter sensitivity.
  - Quick check question: What does the term -H⁻¹∇ℓ represent in the context of upweighting a training sample?

- **Concept: Softmax Temperature Scaling**
  - Why needed here: Controls the "sharpness" of the influence weights. Critical for balancing between focusing on high-influence samples and maintaining data diversity.
  - Quick check question: As temperature τ → 0, how does the weight distribution change compared to τ → ∞?

## Architecture Onboarding

- **Component map:** Real Data Loader -> Distillation Loop -> Influence Estimator -> Weighting Layer -> Weighted Loss
- **Critical path:**
  1. Initialization: Start with random synthetic data
  2. Score Calculation: Compute influence scores for each batch
  3. Weight Assignment: Normalize scores via temperature-scaled softmax
  4. Update: Apply gradients to synthetic data from weighted loss

- **Design tradeoffs:**
  - Precision vs. Cost: Computing exact influence is costly; approximations may be needed for scalability
  - Stability: High influence scores can lead to gradient explosion if not normalized or capped
  - Temperature τ: A hyperparameter that requires tuning per dataset/IPC

- **Failure signatures:**
  - Mode Collapse: Synthetic data converges to a single high-influence prototype
  - Stagnation: Performance identical to baseline
  - Numerical Instability: NaNs during training

- **First 3 experiments:**
  1. Sanity Check (Ablation): Reproduce the "Random vs. IWD" comparison on CIFAR-10 (IPC=1) using a simple ConvNet
  2. Hyperparameter Sensitivity: Sweep temperature τ on CIFAR-10 to find the optimal value
  3. Cross-Architecture Transfer: Train ResNet-10 on synthetic data distilled via ConvNet-3 + IWD

## Open Questions the Paper Calls Out

- Can the IWD framework scale effectively to high-resolution datasets (e.g., ImageNet) or non-vision domains like NLP?
- What is the specific computational overhead introduced by the influence estimation loop compared to baseline distillation methods?
- Can the optimal softmax temperature τ be determined adaptively based on dataset characteristics?

## Limitations

- The influence computation requires either costly Hessian approximations or effective stochastic estimation, but the exact approximation method is not specified
- The reported gains depend on careful temperature tuning, which is dataset- and IPC-specific
- The paper claims the method is "modular," but no ablation is shown for the explicit vs. implicit term contributions

## Confidence

- **High:** Claims about the general benefit of influence-weighted distillation over uniform weighting and hard pruning
- **Medium:** Claims about the specific decomposition into explicit/implicit terms
- **Medium:** Claims about the robustness across architectures

## Next Checks

1. **Efficiency Audit:** Measure the wall-clock overhead of influence estimation in a small-scale reproduction (e.g., CIFAR-10, IPC=1) and compare against the theoretical O(n) per-step cost
2. **Decomposition Ablation:** Run IWD with only the explicit term (setting u_t=0) to verify the implicit term meaningfully contributes to the reported gains
3. **Cross-IPC Temperature Transfer:** Test whether a τ value optimal for IPC=1 remains optimal when scaling to IPC=50, or if the "unimodal" peak shifts predictably