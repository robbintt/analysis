---
ver: rpa2
title: 'MALT: Mechanistic Ablation of Lossy Translation in LLMs for a Low-Resource
  Language: Urdu'
arxiv_id: '2502.00041'
source_url: https://arxiv.org/abs/2502.00041
tags:
- llms
- translation
- languages
- language
- low-resource
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of low-resource language performance
  in large language models (LLMs) by focusing on Urdu as a use case. The study reveals
  that LLMs process low-resource languages primarily through lossy translation features
  in their final layers, resulting in poor performance despite coherent internal English
  responses.
---

# MALT: Mechanistic Ablation of Lossy Translation in LLMs for a Low-Resource Language: Urdu

## Quick Facts
- **arXiv ID**: 2502.00041
- **Source URL**: https://arxiv.org/abs/2502.00041
- **Reference count**: 11
- **Key outcome**: MALT improves Urdu response quality from 0% to 15.6% (Gemma-2-2b) and 11.6% to 55% (Llama-3.2-3b) by ablating lossy translation features and using external MT.

## Executive Summary
This paper addresses the performance gap of LLMs on low-resource languages by focusing on Urdu as a use case. The study reveals that LLMs process low-resource languages primarily through lossy translation features in their final layers, resulting in poor performance despite coherent internal English responses. The proposed method, MALT (Mechanistic Ablation of Lossy Translation), removes these translation features and replaces them with a dedicated machine translation model. When applied to Gemma-2-2b and Llama-3.2-3b, MALT significantly improved performance in generating coherent and relevant Urdu responses while preserving cultural nuances. The study demonstrates that LLMs are better at understanding low-resource languages than generating responses in them.

## Method Summary
MALT operates by identifying and ablating a single direction in the residual stream of late transformer layers that encodes lossy translation features for low-resource languages. The method first identifies this translation direction by computing the normalized difference between mean activations for English and Urdu prompts at a specific layer (ℓ = 24 for Gemma-2-2b, ℓ = 25 for Llama-3.2-3b). During inference, this direction is subtracted from all activations at the target layer, effectively removing the translation mechanism. The resulting English latent response is then translated to Urdu using an external machine translation model (mBART). The approach assumes translation features are linearly represented and localized to one direction in the final layers, allowing selective removal while preserving the model's reasoning capabilities.

## Key Results
- Gemma-2-2b: Improved from 0% to 15.6% success rate in generating coherent and relevant Urdu responses
- Llama-3.2-3b: Improved from 11.6% to 55% success rate in generating coherent and relevant Urdu responses
- The method preserves cultural nuances of the input language
- Internal English latent responses show higher coherence than original Urdu outputs after ablation

## Why This Works (Mechanism)

### Mechanism 1: English-Mediated Latent Reasoning
LLMs process non-English prompts by reasoning internally in English, with language conversion occurring primarily in final layers. The model encodes input semantics, performs reasoning in a latent English representation (due to English-dominant training), then translates to the output language via specialized neurons in final layers.

### Mechanism 2: Lossy Translation Features in Low-Resource Settings
Translation features for low-resource languages are undertrained and produce degraded outputs despite coherent internal English representations. Final-layer neurons responsible for Urdu receive insufficient training signal, causing semantic drift or incoherence during the translation step.

### Mechanism 3: Direction-Based Feature Ablation
Translation behavior can be removed by ablating a single direction in the residual stream of a specific late layer. Compute the normalized difference vector between mean activations for English vs. Urdu prompts at layer ℓ, then subtract this direction from all activations at inference time.

## Foundational Learning

- **Residual Stream & Direction Ablation**
  - Why needed here: MALT operates by identifying and removing a direction in the residual stream
  - Quick check question: Can you explain why subtracting a normalized direction vector from a residual activation might selectively remove one feature while preserving others?

- **Polysemanticity**
  - Why needed here: The paper attributes some errors to inadvertent ablation of non-translation features, since neurons are polysemantic
  - Quick check question: Why might ablating a "translation direction" also degrade unrelated capabilities?

- **Low-Resource Language Challenges in LLMs**
  - Why needed here: The entire method is motivated by the performance gap between high- and low-resource languages due to training data imbalance
  - Quick check question: What percentage of Llama 3's training data is non-English, and how does this affect low-resource language support?

## Architecture Onboarding

- **Component map:** Input Prompt (Urdu) -> Early Layers (encode semantics) -> Middle Layers (reason in latent English) -> Late Layers (translation direction) -> Ablation Module -> External MT Model (mBART) -> Urdu Output

- **Critical path:**
  1. Identify the correct ablation layer via hit-and-trial (ℓ = 24 for Gemma-2-2b, ℓ = 25 for Llama-3.2-3b)
  2. Compute translation direction using N=16 paired English/Urdu prompts
  3. Apply ablation at inference; extract English latent response
  4. Translate to Urdu using external MT model

- **Design tradeoffs:**
  - Layer selection: Too early → incomplete reasoning; too late → translation already applied
  - Ablation precision: Broader ablation removes more translation but risks collateral damage to other features
  - MT model choice: Better MT improves output but adds latency and dependency

- **Failure signatures:**
  - Fluency errors: Incoherent/gibberish output → suggests over-ablation or wrong layer
  - Repetition errors: Model repeats query → polysemantic interference
  - Non-relevance errors: Coherent but off-topic → poor understanding of input or ablation of reasoning features

- **First 3 experiments:**
  1. Layer sweep: Ablate at layers 20–28 and measure English latent coherence to verify optimal ℓ for a new model
  2. Direction magnitude test: Scale the ablation strength (partial vs. full subtraction) and observe error type distribution
  3. Cross-language transfer: Apply the same method to a different low-resource language (e.g., Bengali) to test generalization

## Open Questions the Paper Calls Out

### Open Question 1
Does MALT generalize effectively to low-resource languages with linguistic structures significantly different from Urdu? The study exclusively utilized Urdu, leaving the method's efficacy on other language families unverified.

### Open Question 2
Does the distribution of translation features in larger LLMs (>3B parameters) inhibit the efficacy of single-direction ablation? Computational constraints limited the study to smaller models (2-3B parameters), where features may be more localized than in larger architectures.

### Open Question 3
To what extent does MALT preserve cultural nuances compared to the baseline, and can this preservation be quantified? Current evidence is observational (e.g., citing Quranic references), lacking a standardized metric for cultural fidelity.

### Open Question 4
Are the observed error types (fluency, non-relevance) primarily caused by the ablation of polysemantic neurons containing non-translation features? The current ablation technique may be too coarse, removing capabilities unrelated to translation that are stored in the same direction.

## Limitations
- The study focuses exclusively on Urdu, a single low-resource language, leaving generalization to other languages untested
- The method relies on translation features being localized to a single direction, which may not hold for larger or differently architected models
- Human evaluation introduces subjectivity and the study doesn't specify rater qualifications or inter-rater agreement metrics

## Confidence
- **High Confidence**: The empirical observation that ablation improves Urdu output quality and the mechanistic claim that translation features concentrate in final layers
- **Medium Confidence**: The English-mediated reasoning hypothesis and the single-direction ablation approach are plausible but need broader validation
- **Low Confidence**: Generalization to other low-resource languages and larger models remains speculative without additional testing

## Next Checks
1. Apply MALT to at least two additional low-resource languages (e.g., Bengali and Swahili) to test whether the method generalizes beyond Urdu and whether optimal ablation layers vary by language.

2. Systematically test whether ablating multiple final layers (rather than a single direction) improves performance or whether the single-direction approach is optimal across different model architectures.

3. Conduct a fine-grained analysis of ablation strength (partial vs. full projection subtraction) to determine the optimal trade-off between removing translation features and preserving reasoning capabilities, while measuring which error types (fluency, repetition, relevance) are most sensitive to ablation magnitude.