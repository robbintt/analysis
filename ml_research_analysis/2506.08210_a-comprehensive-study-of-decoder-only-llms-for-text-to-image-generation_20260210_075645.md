---
ver: rpa2
title: A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation
arxiv_id: '2506.08210'
source_url: https://arxiv.org/abs/2506.08210
tags:
- embeddings
- arxiv
- layer
- text
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates using modern decoder-only LLMs as text
  encoders for text-to-image diffusion models, replacing the traditional T5 and CLIP
  encoders. The authors train 27 text-to-image models with 12 different text encoders,
  evaluating performance across compositional reasoning skills.
---

# A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation

## Quick Facts
- **arXiv ID:** 2506.08210
- **Source URL:** https://arxiv.org/abs/2506.08210
- **Reference count:** 40
- **Primary result:** Aggregating embeddings across all layers of decoder-only LLMs with layer normalization significantly outperforms using only last-layer embeddings for text-to-image generation, surpassing traditional T5 encoders.

## Executive Summary
This study investigates the potential of modern decoder-only large language models (LLMs) as text encoders for text-to-image diffusion models, challenging the dominance of traditional encoders like T5 and CLIP. Through systematic experiments with 27 text-to-image models using 12 different text encoders, the authors demonstrate that proper utilization of all layers in LLMs, combined with layer normalization, can achieve superior performance compared to conventional approaches. The research reveals that while simply using last-layer embeddings from LLMs underperforms T5, aggregating embeddings across all layers with appropriate normalization techniques significantly enhances compositional reasoning capabilities. These findings suggest that architectural innovation in text encoding may be more impactful than pure model scaling for advancing text-to-image generation systems.

## Method Summary
The authors conduct a comprehensive empirical study by training 27 text-to-image diffusion models using 12 different text encoders, including various decoder-only LLMs, T5, and CLIP models. They evaluate performance across multiple compositional reasoning skills including spatial reasoning, color recognition, attribute recognition, object recognition, and relative positioning. The key methodological innovation involves comparing different approaches to extracting text embeddings from LLMs, specifically testing last-layer embeddings versus aggregated embeddings across all layers with and without layer normalization. The study also examines the impact of scaling LLM size and fine-tuning on performance. All models are trained and evaluated on the same dataset with consistent hyperparameters to ensure fair comparison.

## Key Results
- Last-layer embeddings from decoder-only LLMs perform worse than T5 across all compositional reasoning skills
- Aggregating embeddings across all layers with layer normalization significantly improves performance, surpassing T5 in all aspects
- Scaling up LLM size improves overall performance but does not uniformly enhance all compositional skills
- Among fine-tuned embedding models, bge-Gemma2 achieves the best results, though the sample size is limited

## Why This Works (Mechanism)
The improved performance of layer-aggregated embeddings stems from capturing richer linguistic representations across different abstraction levels. While last-layer embeddings focus on high-level semantic understanding, lower layers retain syntactic and positional information crucial for compositional reasoning. Layer normalization ensures consistent scaling across different layers, preventing dominance by any single layer. This multi-level aggregation allows the model to better understand complex relationships between objects, attributes, and spatial configurations in text prompts.

## Foundational Learning

**Diffusion Models**
- Why needed: Core framework for generating images from text embeddings
- Quick check: Model learns to reverse noise addition process

**Compositional Reasoning**
- Why needed: Critical capability for generating images matching complex text descriptions
- Quick check: Model must understand relationships between multiple objects and attributes

**Layer Normalization**
- Why needed: Essential for combining embeddings from different layers with varying scales
- Quick check: Ensures stable training and prevents gradient explosion

**Decoder-only LLM Architecture**
- Why needed: Alternative text encoder paradigm that can capture rich linguistic representations
- Quick check: Model generates text autoregressively without explicit encoder-decoder separation

**Text-to-Image Diffusion Pipeline**
- Why needed: End-to-end system for converting text descriptions into images
- Quick check: Text encoder output conditions diffusion model during image generation

## Architecture Onboarding

**Component Map**
Text Prompt -> Text Encoder (LLM/T5/CLIP) -> Text Embeddings -> Diffusion Model -> Generated Image

**Critical Path**
Text Encoder -> Text Embeddings -> Diffusion Score -> Image Generation

**Design Tradeoffs**
LLM-based encoders offer richer linguistic representations but require more computational resources than traditional encoders. Layer aggregation improves performance but increases complexity. Fine-tuning enables task-specific optimization but reduces model flexibility.

**Failure Signatures**
Poor compositional reasoning indicates inadequate text encoding. Inconsistent style across generated images suggests unstable embedding normalization. Mode collapse manifests as repetitive image patterns regardless of prompt variation.

**3 First Experiments**
1. Compare last-layer vs aggregated embeddings from same LLM base model
2. Test different normalization techniques for layer aggregation
3. Evaluate impact of fine-tuning on embedding quality for specific tasks

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Evaluation focused primarily on compositional reasoning skills without broader assessment of image quality metrics
- Limited sample size for fine-tuned models (only 4 models tested) constrains generalizability of findings
- Study uses relatively small LLM sizes (up to 7B parameters) when modern LLMs are much larger
- Computational efficiency trade-offs of using decoder-only LLMs versus traditional encoders are not addressed

## Confidence

**Medium:** Claims about layer aggregation outperforming last-layer embeddings
**Medium:** Conclusions about scaling effects on compositional skills
**Low:** Claims about fine-tuned embedding models' superiority

## Next Checks
1. Test the layer aggregation approach with larger LLM models (30B+ parameters) to verify if the findings scale to state-of-the-art model sizes
2. Expand evaluation to include standard image quality metrics (FID, IS) and human perceptual studies beyond compositional reasoning scores
3. Conduct ablation studies specifically on the normalization technique and different aggregation methods to isolate their individual contributions to performance improvements