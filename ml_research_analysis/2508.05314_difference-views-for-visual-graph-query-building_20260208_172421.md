---
ver: rpa2
title: Difference Views for Visual Graph Query Building
arxiv_id: '2508.05314'
source_url: https://arxiv.org/abs/2508.05314
tags:
- query
- graph
- user
- difference
- visual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a visual query builder for knowledge graphs
  that incorporates difference views to communicate changes between iterative query
  steps. The system enables non-expert users to explore and refine queries using natural
  language prompts, with a language model generating constrained graph modifications
  based on semantic similarity to the ontology.
---

# Difference Views for Visual Graph Query Building

## Quick Facts
- arXiv ID: 2508.05314
- Source URL: https://arxiv.org/abs/2508.05314
- Reference count: 37
- Primary result: Visual query builder with difference views highlights additions (green) and deletions (red) between iterative query steps to aid non-expert exploration of knowledge graphs

## Executive Summary
This paper introduces a visual query builder for knowledge graphs that incorporates difference views to communicate changes between iterative query steps. The system enables non-expert users to explore and refine queries using natural language prompts, with a language model generating constrained graph modifications based on semantic similarity to the ontology. Key innovations include visual highlighting of additions (green) and deletions (red) in both the query graph and result set, as well as comparative visualizations of result distributions. The approach was demonstrated on DBpedia and BTO ontologies, showing how difference views facilitate exploratory search and enable users to track the evolution of their information needs.

## Method Summary
The system implements a visual query builder that combines natural language processing with graph visualization for knowledge graph exploration. It uses a prototype graph approach where users can iteratively modify queries through natural language prompts. The system retrieves semantically similar ontology terms using embeddings, constrains a language model to generate valid graph modifications, and visually highlights differences between query iterations using green (additions) and red (deletions). The interface also includes comparative visualizations of result distributions to show how data landscapes shift with query modifications. The implementation uses QLever for SPARQL execution, PostgreSQL with pgvector for embedding storage, and a language model for structured output generation.

## Key Results
- Visual difference tracking via set operations reduces cognitive load for query evolution
- Schema-constrained language model integration prevents invalid graph states while enabling natural language modifications
- Comparative result distribution visualization enables rapid assessment of quantitative impacts from qualitative query changes
- Demonstrated effectiveness on DBpedia and BTO ontologies for exploratory search tasks

## Why This Works (Mechanism)

### Mechanism 1: Visual Difference Tracking via Set Operations
- **Claim:** Rendering structural changes between query iterations directly onto the graph canvas reduces the cognitive load required to track query evolution, provided the user understands the color encoding.
- **Mechanism:** The system computes set differences between the previous graph state ($G_{proto,l}$) and the current state ($G_{proto,r}$). It identifies added nodes ($N_{proto,add}$), deleted nodes ($N_{proto,del}$), and shared nodes. These sets are visually encoded using green (additions) and red (deletions) overlays on the nodes and edges.
- **Core assumption:** Users can interpret a single "delta" view more effectively than comparing two separate side-by-side graph states.
- **Evidence anchors:** [abstract] "Key innovations include visual highlighting of additions (green) and deletions (red) in both the query graph..." [section 3.2] "We highlight the added nodes in green, and the deleted ones in red... updated dynamically."

### Mechanism 2: Schema-Constrained Language Model Integration
- **Claim:** Constraining a Large Language Model (LM) to output only valid ontology terms allows for robust natural language modifications without inducing invalid graph states.
- **Mechanism:** User prompts are embedded and used to retrieve semantically similar classes and links. These retrieved elements form a "highly constrained schema" that restricts the LM's output tokens. The system then applies post-processing rules (e.g., flipping edge directions) to ensure graph validity before updating the visual state.
- **Core assumption:** The semantic embedding space of the user's natural language query aligns sufficiently with the ontology labels to retrieve the correct constraints.
- **Evidence anchors:** [abstract] "...language model generating constrained graph modifications based on semantic similarity to the ontology." [section 3.4] "This highly constrained schema is then used for the output constraints of the LM with strict rules... preventing hallucination."

### Mechanism 3: Comparative Result Distribution Visualization
- **Claim:** Visualizing the shift in result distributions (rather than just lists) enables users to rapidly assess the quantitative impact of qualitative query changes.
- **Mechanism:** The system queries value attributes for the result set and buckets them (e.g., histograms for dates, scatter plots for continuous variables). It calculates the difference between the "old" and "new" result distributions and renders this comparison (e.g., overlaid histograms) to show how the data landscape shifted.
- **Core assumption:** Users are searching for trends or distributions rather than specific singleton facts.
- **Evidence anchors:** [abstract] "...comparative visualizations of result distributions." [section 3.3] "We integrate these result set charts with our difference view by comparing the different result sets of the two prototype graphs..."

## Foundational Learning

- **Concept:** **Basic Graph Patterns (BGP)**
  - **Why needed here:** The system relies on a "prototype graph" ($G_{proto}$) which functions as a BGP—a template of nodes and edges matched against the Knowledge Graph. Understanding that the visual graph is a *pattern* to be matched, not the data itself, is crucial.
  - **Quick check question:** If the visual graph shows `Person -> worksFor -> Company`, does the system return that specific drawing, or all instances in the database matching that structure?

- **Concept:** **Ontology Constraints & Types**
  - **Why needed here:** The system prevents "broken" queries by enforcing ontology rules (e.g., a `birthPlace` link must connect a `Person` to a `Place`). The LM mechanism depends on these constraints to limit hallucinations.
  - **Quick check question:** Why would the system reject a user request to connect "a Building" to "a Date" via a "birthDate" link?

- **Concept:** **Semantic Embeddings & Vector Search**
  - **Why needed here:** The natural language interface does not use keyword matching. It uses vector embeddings to find concepts that are *semantically* close to the user's prompt. Understanding this helps explain why synonyms work (sometimes better than exact terms).
  - **Quick check question:** If a user searches for "automobile" but the ontology only contains "car," how does the system correctly map the request?

## Architecture Onboarding

- **Component map:** Vue.js (UI orchestration) -> D3.js (2D charts/distributions), Three.js (Graph visualization) -> OnSET system (Difference calculator, Query builder) -> QLever (SPARQL engine for fast KG retrieval), PostgreSQL with pgvector (Storing ontology embeddings) -> Hermes Llama 3.2 8B (Structured output generation), stella_en_400M_v5 (Embedding model)

- **Critical path:** 1. Input: User enters NL prompt or manual edit. 2. Retrieval: System embeds prompt → Vector search in Postgres retrieves top-k valid ontology classes/links. 3. Generation: LM generates a structured change set constrained *only* to those retrieved classes/links. 4. State Update: System applies changes to $G_{proto}$ and calculates the difference sets ($N_{add}, N_{del}$). 5. Visual Feedback: Frontend renders the Green/Red diff graph and updates the result distribution charts.

- **Design tradeoffs:** Performance vs. Freshness: Embeddings are pre-computed at startup to ensure fast retrieval. Tradeoff: If the ontology changes, the system requires a restart/re-index; it does not support real-time ontology updates. Safety vs. Flexibility: The LM is highly constrained. Tradeoff: It reduces errors/hallucinations but may struggle with highly creative or complex multi-step reasoning requests that fall outside the immediate schema vicinity.

- **Failure signatures:** "Empty Delta" Loop: User prompts the LM, the visualization flickers, but no change appears. This implies the semantic retrieval failed to find matching ontology terms for the prompt. Hallucinated Edges: The LM suggests a relationship that *sounds* right but isn't in the ontology (mitigated but not eliminated by constrained decoding). Visual Clutter: In dense queries, the Red/Green overlays obscure node labels, requiring the user to toggle the "difference" view off to read the graph.

- **First 3 experiments:** 1. Semantic Sensitivity Test: Prompt the system with synonyms for known ontology terms (e.g., "director" vs. "film director") to verify the robustness of the `stella_en_400M_v5` embedding retrieval layer. 2. Constraint Stress Test: Ask the LM to perform an illegal join (e.g., "connect a Person to a Number via a birthPlace link") to verify if the schema constraint layer successfully blocks the modification or corrects it. 3. Result Diff Latency: Execute a query returning >1000 results, then modify a constraint. Measure the latency of the "Difference View" update to determine if the comparative visualization scales with result set size.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can visual query interfaces effectively represent versioning and graph evolution across more than two iterative steps?
- Basis in paper: [explicit] The authors state that "versioning of the graph over multiple iterations, where the visual representation of small steps and grouping changes automatically poses a challenge," is a required step toward a complete evolutionary representation.
- Why unresolved: The current implementation only compares the immediate previous state to the current state (binary difference), lacking a mechanism to visualize or rollback through a longer history of query refinements.
- What evidence would resolve it: A visualization design study proposing an interaction model for browsing multi-step query history, validated by user ability to navigate complex query evolution paths.

### Open Question 2
- Question: To what extent do difference views improve user performance in exploratory search tasks compared to standard visual query builders?
- Basis in paper: [inferred] The paper relies on descriptive case studies (Section 5) to demonstrate the system's utility but does not present a controlled user study comparing the system against baselines like SPARKLIS or SPARNATURAL.
- Why unresolved: While the authors argue that difference views foster understanding, there is no quantitative data on whether the interface reduces query formulation time, lowers error rates, or improves insight acquisition.
- What evidence would resolve it: A controlled comparative experiment measuring task completion times and accuracy for users with and without the difference view feature.

### Open Question 3
- Question: Does fine-tuning the Language Model offer significant improvements in suggestion accuracy over the current few-shot prompting approach?
- Basis in paper: [explicit] The authors list "fine-tuning the LM to enhance the suggested changes" as future work, noting they currently utilize few-shot prompting to refine suggestions (Section 6.1).
- Why unresolved: It is unclear if the computational cost of fine-tuning is justified by better semantic matching or fewer hallucinations compared to the existing retrieval-based constraint method.
- What evidence would resolve it: An ablation study comparing the semantic relevance and ontological validity of graph modifications generated by fine-tuned vs. few-shot prompted models.

## Limitations

- Semantic embedding alignment is critical: Low semantic similarity between user prompts and ontology terms will cause the constrained LM to fail
- Visual clutter becomes problematic with dense queries, potentially obscuring node labels
- No quantitative user studies validate the claimed cognitive benefits of difference views over traditional comparison methods

## Confidence

- **High Confidence:** The mechanism of visual difference tracking via set operations (green/red highlighting) is directly supported by the paper's description of the difference view implementation and is a straightforward visualization technique.
- **Medium Confidence:** The schema-constrained LM integration is well-described, but the specific prompt templates and correction logic are not detailed, introducing some uncertainty about the robustness of the constraint enforcement.
- **Low Confidence:** The claimed benefits of the comparative result distribution visualization are not empirically validated in the paper. The evidence relies on general principles of visual analytics rather than specific user studies or quantitative metrics.

## Next Checks

1. **Semantic Sensitivity Test:** Input a series of synonyms and related terms for known ontology concepts (e.g., "automobile," "car," "vehicle") to verify the embedding retrieval layer correctly maps user intent to valid ontology classes, and measure the success rate of the LM in generating appropriate modifications.

2. **Constraint Robustness Test:** Attempt to generate queries that violate core ontology constraints (e.g., connecting a `Person` to a `Date` via a `birthPlace` link). Observe whether the system correctly blocks the modification or automatically corrects it based on the schema rules, and document the failure mode.

3. **Difference View Scalability Test:** Execute a query with a large result set (>1000 instances) and measure the latency of the difference view update when a constraint is modified. Assess whether the comparative visualization (e.g., overlaid histograms) remains responsive and interpretable at scale, or if it becomes a bottleneck or source of visual noise.