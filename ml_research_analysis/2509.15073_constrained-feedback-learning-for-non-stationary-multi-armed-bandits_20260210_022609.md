---
ver: rpa2
title: Constrained Feedback Learning for Non-Stationary Multi-Armed Bandits
arxiv_id: '2509.15073'
source_url: https://arxiv.org/abs/2509.15073
tags:
- query
- rounds
- regret
- algorithm
- feedback
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CONFEE-NSMAB, a new model for non-stationary
  multi-armed bandits with constrained feedback, where reward observations are limited
  by a query budget B. The key challenge is balancing exploration, exploitation, and
  query efficiency in dynamic environments without prior knowledge of non-stationarity.
---

# Constrained Feedback Learning for Non-Stationary Multi-Armed Bandits

## Quick Facts
- arXiv ID: 2509.15073
- Source URL: https://arxiv.org/abs/2509.15073
- Reference count: 40
- Primary result: Introduces HYQUE, achieving Õ(K^(1/3)V_T^(1/3)T/B^(1/3)) dynamic regret with at most B queries, matching the lower bound.

## Executive Summary
This paper introduces CONFEE-NSMAB, a non-stationary multi-armed bandit model with constrained feedback where reward observations are limited by a query budget B. The key challenge is balancing exploration, exploitation, and query efficiency in dynamic environments without prior knowledge of non-stationarity. The authors propose HYQUE, a hybrid query allocation algorithm that combines baseline and on-demand mechanisms to achieve near-optimal dynamic regret. HYQUE guarantees at most B queries and attains regret Õ(K^(1/3)V_T^(1/3)T/B^(1/3)), matching the lower bound up to logarithmic factors. The algorithm is prior-free, requiring no prior knowledge of the variation budget V_T.

## Method Summary
HYQUE is a hybrid query allocation algorithm that combines baseline allocation (BAQUE) with on-demand allocation. It partitions the time horizon into blocks with multiple parallel UCB1 instances at different time scales. BAQUE pre-allocates a baseline query quota to each instance, ensuring minimal coverage across scales. On-demand allocation monitors cumulative query usage and injects additional queries when usage falls behind near-linear pacing, using a buffer term to prevent over-querying. The algorithm employs multi-scale instance restart for change detection and achieves near-optimal dynamic regret through a novel decomposition separating regret during query and non-query rounds.

## Key Results
- HYQUE achieves regret Õ(K^(1/3)V_T^(1/3)T/B^(1/3)), matching the lower bound up to logarithmic factors
- The algorithm guarantees at most B queries while maintaining near-optimal performance
- A lower bound proof shows Ω(K^(1/3)V_T^(1/3)T/B^(1/3)) regret is unavoidable in this setting
- HYQUE is prior-free, requiring no prior knowledge of the variation budget V_T

## Why This Works (Mechanism)

### Mechanism 1: Hybrid Query Allocation (BAQUE + On-Demand)
HYQUE achieves near-optimal dynamic regret by balancing baseline query allocation for worst-case robustness with on-demand allocation for smoother environments. The algorithm partitions the time horizon into blocks with multiple parallel UCB1 instances at different time scales. BAQUE pre-allocates a baseline query quota (~B/T fraction) to each instance, ensuring minimal coverage across scales. On-demand allocation monitors cumulative query usage and injects additional queries when usage falls behind near-linear pacing (t·B/T), using a buffer term to prevent over-querying.

### Mechanism 2: Multi-Scale Instance Restart for Change Detection
Running multiple instances of UCB1 at exponentially increasing time scales with probabilistic scheduling enables detection of both abrupt and gradual environmental changes without prior knowledge of non-stationarity. At each time τ, an instance at scale m is initiated with probability 2^((m-n)/2) if τ is divisible by b·2^m, where b = ⌈2T/B⌉. Finer-scale instances (smaller m) take precedence over coarser ones, ensuring hierarchical masking. Each instance performs environmental change tests: (i) end-of-instance test comparing average reward to minimum estimated reward, and (ii) discrepancy test comparing UCB index to observed reward.

### Mechanism 3: Regret Decomposition for Limited Feedback
Separating regret into query, error, and drift components enables independent analysis and bounding of each source, revealing how constrained feedback impacts overall performance. Total regret R_T is decomposed as: R_T = R_T^query + R_T^error + R_T^drift. R_T^query comes from rounds with active feedback. R_T^error arises from decision inaccuracies using stale information during non-query rounds. R_T^drift captures environmental changes not detected due to lack of feedback. The bounds are: R_T^query ≤ Õ(K^(1/3)V_T^(1/3)B^(2/3)), R_T^error ≤ Õ(K^(1/3)V_T^(1/3)T/B^(1/3)), R_T^drift ≤ Õ(K^(1/3)V_T^(1/3)T/B^(1/3)).

## Foundational Learning

- **Multi-Armed Bandits (MAB) and Exploration-Exploitation Trade-off**: HYQUE builds on UCB1, a standard MAB algorithm. Understanding how UCB1 balances exploring uncertain arms versus exploiting known high-reward arms is essential to grasp how the multi-scale instances behave during query rounds.
  - Quick check question: Can you explain why UCB1 uses an "optimism in the face of uncertainty" principle by adding a confidence bonus to empirical mean estimates?

- **Non-Stationarity and Variation Budget (V_T)**: The CONFEE-NSMAB model assumes reward distributions change over time, bounded by total variation V_T. The algorithm's performance guarantees depend on this measure, and understanding it is key to interpreting the regret bounds.
  - Quick check question: How does the variation budget V_T differ from the number of change points in piecewise-stationary bandits, and why is it a more general measure of non-stationarity?

- **Dynamic Regret vs. Static Regret**: In non-stationary settings, dynamic regret (comparing to the best action at each round) is the appropriate metric, not static regret (comparing to a single best overall action). The paper's theoretical analysis focuses entirely on dynamic regret.
  - Quick check question: Why might an algorithm with low static regret still perform poorly in a rapidly changing non-stationary environment?

## Architecture Onboarding

- **Component map**: Block Partitioner -> BAQUE Subroutine -> UCB1 Base Algorithm -> Change Detector -> (If no restart) On-Demand Query Allocator -> Non-Query Action Selector -> Query allocation

- **Critical path**: Query allocation → UCB1 execution → Change detection → (If no restart) On-demand check → Non-query action. This loop repeats per round, with restarts resetting the phase.

- **Design tradeoffs**:
  1. **Baseline vs. On-Demand Allocation**: Baseline ensures robustness to frequent changes but may over-query in stable periods; on-demand adapts to stability but relies on buffer terms to avoid budget exhaustion. The hybrid approach balances both.
  2. **Time-Scale Granularity**: More scales (larger n) improve detection of diverse change patterns but increase computational overhead and query fragmentation across instances.
  3. **Buffer Term Tuning**: The buffer min{T/√B, 2^n, T-t} prevents excessive queries but may underutilize budget in stable environments if set too conservatively.

- **Failure signatures**:
  1. **Budget Exhaustion Before Horizon**: Total queries exceed B, violating feasibility. Likely due to buffer term misconfiguration or excessively aggressive on-demand allocation.
  2. **Prolonged Non-Query Sequences**: Exceeding T/√B consecutive non-query rounds, causing high drift regret. Indicates insufficient instance initiation probability or scale coverage.
  3. **Frequent Unnecessary Restarts**: Change detector triggers too often in stable environments, fragmenting phases and degrading performance. Suggests overly sensitive detection thresholds (e.g., confidence bound ˆρ(t) parameters).

- **First 3 experiments**:
  1. **Budget Feasibility Test**: Implement HYQUE with varying B (e.g., B = 0.5T, 0.3T, 0.1T) on a synthetic non-stationary environment with known V_T. Verify total queries never exceed B across multiple runs.
  2. **Scale Sensitivity Analysis**: Run HYQUE with different maximum scales (n = 3, 5, 7) on environments with varying change frequencies (abrupt vs. gradual). Measure dynamic regret and query distribution across scales to validate multi-scale effectiveness.
  3. **Component Ablation**: Compare full HYQUE against (a) BAQUE-only (no on-demand) and (b) on-demand-only (no baseline) on both worst-case (frequent changes) and benign (infrequent changes) environments. Quantify regret increase to understand each component's contribution.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can near-optimal dynamic regret guarantees be achieved in non-stationary reinforcement learning settings with constrained feedback?
- Basis in paper: The authors state in the "Limitations and Future Work" section that "extending these guarantees to more complex decision-making frameworks, such as non-stationary reinforcement learning with constrained feedback, remains an open challenge."
- Why unresolved: The HYQUE algorithm and its analysis are specific to the multi-armed bandit framework and do not immediately generalize to the state-space complexity of reinforcement learning.
- What evidence would resolve it: An algorithm designed for non-stationary RL with a constrained feedback budget, accompanied by a rigorous dynamic regret analysis.

### Open Question 2
- Question: How can an algorithm dynamically adjust the query budget in real-time based on observed feedback patterns rather than relying on a predefined fixed budget?
- Basis in paper: The authors identify that HYQUE relies on a predefined query budget and note that "future work could explore adaptive mechanisms that adjust the query budget in real-time based on observed feedback patterns or external constraints."
- Why unresolved: The current model assumes a fixed budget B, whereas practical applications may require adaptive budgeting not covered by the current theoretical framework.
- What evidence would resolve it: A modified algorithmic framework that allows for variable query costs or adaptive budget consumption with corresponding regret bounds.

### Open Question 3
- Question: What are the optimal regret bounds for CONFEE-NSMAB when the query budget is strictly small, specifically B ≤ O(T^(3/4))?
- Basis in paper: The main theoretical result (Theorem 4.1) relies on the assumption that the query budget B = ω(T^(3/4)). The performance guarantees for budgets below this threshold are not established.
- Why unresolved: The theoretical analysis does not hold for smaller budgets, leaving a gap in understanding the algorithm's behavior in severely resource-constrained environments.
- What evidence would resolve it: A theoretical derivation of regret bounds that explicitly cover the regime where B ≤ T^(3/4), or a proof of a new lower bound for this specific case.

## Limitations
- The algorithm assumes the variation budget V_T falls within [K^(-1), K^(-1)√B], and performance guarantees may degrade if this assumption is violated
- Precise implementation of change detection tests requires unknown parameters (U_t computation, ˆρ(t) formula)
- The buffer term in on-demand allocation requires careful tuning to balance budget utilization against the risk of excessive non-query sequences
- Performance guarantees for strictly small budgets (B ≤ O(T^(3/4))) are not established

## Confidence
- **High Confidence**: The hybrid query allocation mechanism (BAQUE + on-demand) and its regret decomposition are well-specified and theoretically grounded. The matching lower bound proof establishes near-optimality.
- **Medium Confidence**: The multi-scale instance restart mechanism for change detection is conceptually sound, but practical effectiveness depends on parameter choices and the unknown change detection test thresholds.
- **Medium Confidence**: The regret decomposition framework (query + error + drift components) is rigorously proven, though its empirical performance may vary with environment characteristics and parameter tuning.

## Next Checks
1. **Feasibility Validation**: Implement HYQUE with varying query budgets B on synthetic non-stationary environments. Verify that total queries never exceed B across multiple runs, particularly for challenging parameter combinations (small B, high V_T).
2. **Component Contribution Analysis**: Compare full HYQUE against (a) BAQUE-only and (b) on-demand-only variants across both worst-case (frequent changes) and benign (stable) environments. Quantify regret increases to empirically validate each component's contribution.
3. **Parameter Sensitivity Testing**: Systematically vary key parameters (maximum scale n, confidence parameter δ, buffer term configuration) and measure impact on regret performance and query efficiency. Identify parameter regimes where performance degrades or breaks.