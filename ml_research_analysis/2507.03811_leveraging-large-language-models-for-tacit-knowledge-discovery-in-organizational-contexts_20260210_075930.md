---
ver: rpa2
title: Leveraging Large Language Models for Tacit Knowledge Discovery in Organizational
  Contexts
arxiv_id: '2507.03811'
source_url: https://arxiv.org/abs/2507.03811
tags:
- knowledge
- agent
- table
- these
- score
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a novel approach to tacit knowledge discovery
  in organizations using LLM-based agents. The core method involves simulating organizational
  knowledge dissemination through epidemic models and employing an agent that iteratively
  interacts with employees to reconstruct dataset descriptions.
---

# Leveraging Large Language Models for Tacit Knowledge Discovery in Organizational Contexts

## Quick Facts
- arXiv ID: 2507.03811
- Source URL: https://arxiv.org/abs/2507.03811
- Authors: Gianlucca Zuin; Saulo Mastelini; Túlio Loures; Adriano Veloso
- Reference count: 32
- Primary result: 94.9% full-knowledge recall achieved through LLM-based agent navigating organizational knowledge networks

## Executive Summary
This paper introduces a novel approach for discovering tacit organizational knowledge using LLM-based agents that simulate knowledge dissemination through epidemic models. The method models knowledge spread as an SI epidemic process with waning infectivity, fragmenting information across employees. An agent iteratively interacts with employees using prompt-chaining and self-critical feedback to reconstruct dataset descriptions, achieving 94.9% full-knowledge recall across 864 simulations. The approach demonstrates success in recovering information without direct access to the domain specialist, showcasing its ability to navigate complex organizational structures and extract otherwise inaccessible knowledge.

## Method Summary
The method simulates organizational knowledge dissemination using an SI epidemic model with waning infectivity, where knowledge fragments as it spreads through hierarchy and informal networks. An LLM agent traverses this network, iteratively querying employees to reconstruct table descriptions through prompt-chaining. After each interaction, the agent performs self-critical feedback (scoring 0-10, reasoning about deficiencies, and generating suggestions) to refine subsequent questions. The agent prioritizes lower-hierarchy employees and uses referral chains to navigate the network, achieving high recall rates while maintaining realistic organizational dynamics.

## Key Results
- Achieved 94.9% full-knowledge recall across 864 simulations with various company structures
- Successfully recovered information without direct access to the domain specialist (patient zero)
- Self-critical feedback scores showed strong correlation (0.73 Spearman) with external evaluation metrics
- Average path length of 8-36 employees contacted per simulation with high-quality descriptions

## Why This Works (Mechanism)

### Mechanism 1
Self-critical feedback enables iterative knowledge gap identification without ground truth access. After each employee interaction, the agent scores its current description (0-10), generates reasoning about deficiencies, and produces actionable suggestions. This meta-cognitive step is chained into the next question-generation prompt, creating a refinement loop. The correlation of 0.73 between self-critical score with and without ground truth validates this mechanism's effectiveness in capturing tacit knowledge.

### Mechanism 2
Modeling knowledge dissemination as an SI epidemic process with waning infectivity creates realistic fragmented knowledge distributions. Knowledge spreads from patient zero through formal hierarchy and informal relationship networks with transmission rate β(t) = β₀e^(-γt) decaying over time. This means early recipients retain full sharing capacity while later ones become dead ends, naturally fragmenting knowledge across employees for the agent to reconstruct through aggregation.

### Mechanism 3
Prioritized network traversal starting from lower hierarchy levels with dynamic rerouting based on employee referrals efficiently locates knowledge holders. The agent maintains an employee stack initialized from hierarchy bottom and moves referred colleagues to stack top. This "follow-the-referral" path trims the search space once any partial-knowledge holder is found, enabling the agent to recover information without requiring direct access to the sole domain specialist.

## Foundational Learning

- **Markov Decision Process (MDP) formulation for knowledge acquisition**: The agent's task is framed as navigating states (knowledge completeness), actions (questions), and rewards (description quality). Understanding MDPs helps grasp why the agent needs implicit policy learning. Quick check: Can you explain how the transition model P(k'|k,a) captures uncertainty in employee responses?

- **Epidemic models (SI/SIR) and waning infectivity**: The simulation backbone uses disease-spread metaphors for knowledge diffusion. The β(t) decay function is critical to understanding why knowledge fragments. Quick check: If β₀ = 0.5 and γ = 0.8, what happens to transmission probability after 3 time steps?

- **Chain-of-thought and self-reflection prompting**: The agent's self-critical stage relies on LLM metacognition—generating intermediate reasoning before scoring. Quick check: How does the self-critic prompt differ from a simple "rate this description" instruction?

## Architecture Onboarding

- Component map: Employee Network Simulator -> Synthetic Company -> SI Epidemic Model -> Fragmented Knowledge States -> LLM Agent Core -> Employee LLMs -> Knowledge Integrator -> Table Description State -> Self-Critic Module -> Termination Check

- Critical path: 1) Build company hierarchy + informal relationships, 2) Run SI dissemination to distribute facts, 3) Agent starts at random bottom-level employee, 4) Loop: question → response → integrate → critique → decide next employee, 5) Terminate when score ≥ 8 or max turns reached

- Design tradeoffs: Visible hierarchy vs. hidden relationships (agent knows formal structure but must infer informal connections), self-critical threshold (ε=8) balances quality vs. interaction count, bottom-up traversal reduces burden on senior staff but may require longer paths

- Failure signatures: Hub exhaustion (# Hubs metric spikes indicates circular referrals), premature termination (high self-scores but low external metrics suggests miscalibration), patient-zero dependency (high correlation between quality and patient-zero contact indicates referral failure), path explosion (Len(path) grows without score improvement in large organizations)

- First 3 experiments: 1) Replicate single simulation run with 25-employee, 4-level hierarchy to verify self-critic scoring, 2) Vary alpha (0.1 vs 0.5) and decay (0.5 vs 0.8) to compare path lengths and scores against Table I baselines, 3) Ablate self-critic to measure drop in full-knowledge recall from 94.9% baseline

## Open Questions the Paper Calls Out

1. How does the agent's performance compare when interacting with real human employees versus synthetic LLM-based employees? The 94.9% recall rate was achieved in a fully synthetic environment; real human responses introduce noise and unpredictable dynamics not captured by synthetic personas.

2. To what extent do LLM-simulated employees accurately model the referral behaviors and partial knowledge states of real humans? If simulations are too consistent, the reported navigation efficiency may be artificially high compared to real organizational dynamics.

3. Is the self-critical prompt-chaining approach robust across different LLM architectures, or dependent on GPT-4o mini's specific reasoning capabilities? The approach may not generalize to weaker models that fail to follow complex meta-prompts or stronger models that are more efficient.

## Limitations

- Simulation assumptions may not reflect real organizational knowledge diffusion patterns, which could follow centralized documentation or broadcast communication models rather than epidemic dynamics
- Employee response generation mechanism lacks specification, creating potential reproducibility gaps in the agent's interaction framework
- Self-critical feedback correlation (0.73) shows moderate strength, suggesting the LLM's metacognition may not perfectly align with actual knowledge completeness

## Confidence

- High Confidence: Full-knowledge recall (94.9%) and correlation results—these are simulation-based and internally consistent
- Medium Confidence: Self-critical feedback effectiveness—moderate correlation with external metrics suggests partial validity but potential calibration issues
- Medium Confidence: Organizational traversal mechanism—successful in simulation but depends on assumed referral accuracy and network density

## Next Checks

1. Correlation robustness test: Systematically vary self-critical scoring thresholds (7 vs 8 vs 9) and measure correlation decay with external metrics to identify calibration boundaries

2. Simulation realism audit: Compare SI model predictions against empirical organizational knowledge-sharing data (e.g., internal communication logs) to validate transmission parameters

3. Ablation study extension: Test agent performance with progressively degraded referral accuracy (employees give random vs accurate referrals) to quantify referral mechanism contribution