---
ver: rpa2
title: Dynamical Properties of Tokens in Self-Attention and Effects of Positional
  Encoding
arxiv_id: '2512.03058'
source_url: https://arxiv.org/abs/2512.03058
tags:
- tokens
- positional
- token
- encoding
- transformer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the dynamical properties of tokens in pre-trained
  Transformer models and explores their application to improving Transformers. To
  this end, we analyze the dynamical system governing the continuous-time limit of
  the pre-trained model and characterize the asymptotic behavior of its solutions.
---

# Dynamical Properties of Tokens in Self-Attention and Effects of Positional Encoding

## Quick Facts
- **arXiv ID**: 2512.03058
- **Source URL**: https://arxiv.org/abs/2512.03058
- **Reference count**: 40
- **Primary result**: Theoretical and empirical analysis of token dynamics in Transformers, showing that token convergence to zero harms performance while divergence preserves information density.

## Executive Summary
This paper investigates the long-term behavior of tokens in self-attention mechanisms by modeling Transformers as continuous-time dynamical systems. The authors characterize when tokens converge to zero (collapse regime) or diverge to infinity (clustering regime) based on the definiteness of composite matrices derived from query, key, and value projections. They demonstrate that rotary positional encoding inherently promotes the divergence regime, while absolute positional encoding behaves similarly to no encoding. The theoretical insights lead to simple architectural modifications that improve model performance by preventing undesirable convergence behavior.

## Method Summary
The paper analyzes Transformer dynamics through continuous-time ODE modeling, deriving sufficient conditions for token convergence or divergence based on matrix definiteness properties. The core method involves characterizing the composite matrices $W = QK^\top$ and $A = W(V^\top)^{-1}$ and their symmetric parts. The authors implement constrained attention mechanisms using LDL decomposition to control definiteness during training, with modifications like adding learnable regularization terms to the diagonal of attention matrices. Experiments validate the theory across language modeling (WikiText-103, EnWik8) and image classification (ImageNet-1K) tasks.

## Key Results
- Token convergence to zero (when $A \prec 0$ and $W \succ 0$) degrades model performance, while divergence preserves token separation and improves results
- Rotary positional encoding (RoPE) inherently inhibits convergence conditions by introducing position-dependent interaction terms
- Simple modifications like adding $\lambda I$ to attention matrices can improve RoPE-based models by enforcing divergence behavior
- The theoretical predictions about dynamical regimes are validated empirically across multiple model architectures and tasks

## Why This Works (Mechanism)

### Mechanism 1
The long-term behavior of tokens in self-attention is determined by the definiteness of composite matrices $W = QK^\top$ and $A = W(V^\top)^{-1}$. When $A_{sym} \prec 0$ and $W_{sym} \succ 0$, all tokens converge to zero, creating a "collapse" regime that degrades performance. Conversely, when $V$ has positive eigenvalues and tokens are initially separated, they diverge to infinity, creating a "clustering" regime that preserves information density. The analysis assumes time-invariant parameters and focuses on self-attention, omitting LayerNorm and FFN components in theoretical proofs.

### Mechanism 2
Rotary Positional Encoding promotes divergence by introducing position-dependent interaction terms $\Delta W_{li}$ in the query-key matrix. This term inhibits the condition $A \prec 0$, blocking the convergence-to-zero pathway and forcing the system into a divergence regime. Absolute positional encoding, in contrast, merely shifts the equilibrium point without fundamentally altering the dynamics. The protective effect of RoPE against convergence is supported by empirical observations of faster token norm and distance divergence.

### Mechanism 3
Performance in RoPE-based models can be improved by penalizing convergence conditions through learnable regularization. The paper proposes modifying attention by subtracting positive quantities from the diagonal of the interaction matrix, achieved by adding learnable terms $\lambda I$ or $\lambda A$ where $\lambda$ is a negative scalar. This forces eigenvalues away from the positive-definite convergence criteria, solidifying the divergence regime and improving downstream performance.

## Foundational Learning

- **Continuous-time Dynamical Systems (ODEs)**: Required to understand how discrete Transformer layers map to continuous differential equations $dx/dt$, where "infinite time" corresponds to "deep layers." Quick check: How does the derivative $dx/dt$ relate to the residual connection in a standard Transformer block?

- **Quadratic Forms and Matrix Definiteness**: Essential for understanding why the core conditions for collapse or divergence depend on whether matrices $A$ and $W$ are positive or negative definite. Quick check: If a matrix $B$ is negative definite ($B \prec 0$), does the quadratic form $x^\top B x$ yield positive or negative values for non-zero $x$?

- **Lyapunov Stability (Intuition)**: The proofs rely on showing that certain energy functions (like token distances) decrease over time. Quick check: If the norm of a token $\|x(t)\|$ decreases continuously as $t \to \infty$, what is the asymptotic behavior of the token?

## Architecture Onboarding

- **Component map**: Token embeddings $X$ -> Positional Encodings (Absolute or RoPE) -> Parameters $Q, K, V$ -> Derived Matrices $W = QK^\top$ and $A = W(V^\top)^{-1}$ -> ODE solver updating token states -> Optional $\lambda I$ modification

- **Critical path**: Verify the definiteness of $W_{sym}$ and $A_{sym}$ in pre-trained weights to classify layers into Convergence, Divergence, or Intermediate regimes. The paper suggests practical models tend to avoid the convergence regime naturally.

- **Design tradeoffs**: Convergence ($A \prec 0$) is mathematically stable but degrades performance through token collapse. Divergence ($A \succ 0$) maintains token separation for better performance but risks unbounded growth, handled by LayerNorm in practice. Absolute PE shifts the zero point while RoPE fundamentally alters dynamics.

- **Failure signatures**: Token collapse occurs when early layers show token norms rapidly shrinking toward zero. Missing divergence in RoPE models happens when the $\Delta W_{li}$ term is suppressed or weights drift to $A \prec 0$.

- **First 3 experiments**:
  1. Extract $Q, K, V$ matrices from a pre-trained Transformer and compute eigenvalues of $W_{sym}$ and $A_{sym}$ to classify dynamical regimes
  2. Run a forward pass on a small batch and plot mean token norm and pairwise distance vs. layer depth to verify theoretical predictions
  3. Implement the $\lambda I$ modification for a RoPE-based model and compare validation perplexity against baseline RoPE implementation

## Open Questions the Paper Calls Out

1. How do Layer Normalization and Feed-Forward Networks quantitatively alter the asymptotic token dynamics, specifically preventing the unbounded divergence or zero convergence predicted by the simplified self-attention ODE? The theoretical analysis omits these components, creating a gap between theory and practice.

2. Can rigorous theoretical bounds be established when the matrix $A = W(V^\top)^{-1}$ is not symmetric, or when definiteness conditions are mixed? Current theorems require symmetry, though simulations suggest broader applicability.

3. How does the discrete, layer-wise nature of standard Transformers affect the transferability of continuous-time conditions? The theoretical results model infinite time for time-invariant systems, while real models have finite depth with layer-specific weights.

## Limitations
- Theoretical framework assumes time-invariant parameters and excludes LayerNorm and FFN components, which significantly affect token dynamics in practice
- Claims about performance degradation from convergence are plausible but not definitively proven; other factors like optimization dynamics could contribute
- The proposed modifications show performance improvements, but exact magnitude and robustness across different scales and tasks remain to be fully established

## Confidence
- **High Confidence**: Characterization of dynamical regimes based on matrix definiteness is mathematically rigorous and well-supported by theory and empirical validation
- **Medium Confidence**: The claim that convergence harms performance due to information loss is plausible but not definitively proven
- **Medium Confidence**: Proposed modifications show performance improvements, but exact magnitude and robustness across tasks need further validation

## Next Checks
1. Run controlled experiments comparing token dynamics with and without LayerNorm/FFN in simplified models to quantify how much these components dampen theoretical effects
2. Apply dynamical regime analysis to diverse Transformer architectures (BERT, ViT, GPT variants) to test whether definiteness patterns generalize across scales and tasks
3. Implement and compare alternative methods for enforcing divergence (e.g., spectral normalization of V, attention temperature scaling) to validate whether the proposed Î»I modification is optimal