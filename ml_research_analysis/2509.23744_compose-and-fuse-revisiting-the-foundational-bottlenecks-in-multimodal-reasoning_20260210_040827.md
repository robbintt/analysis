---
ver: rpa2
title: 'Compose and Fuse: Revisiting the Foundational Bottlenecks in Multimodal Reasoning'
arxiv_id: '2509.23744'
source_url: https://arxiv.org/abs/2509.23744
tags:
- reasoning
- erin
- modalities
- modality
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates whether and how additional modalities enhance
  or impair multimodal reasoning in large language models. It introduces a logic-grounded
  evaluation framework with six interaction patterns, systematically varying how facts
  are distributed across modalities and combined for inference.
---

# Compose and Fuse: Revisiting the Foundational Bottlenecks in Multimodal Reasoning

## Quick Facts
- arXiv ID: 2509.23744
- Source URL: https://arxiv.org/abs/2509.23744
- Reference count: 40
- Primary result: Multimodal reasoning bottlenecks stem from integration failures, not perception

## Executive Summary
This work systematically investigates when and why multimodal input helps or harms reasoning in large language models. Through a logic-grounded evaluation framework with six interaction patterns, it reveals that additional modalities improve performance only when they provide independent reasoning paths, while redundant or chained entailment often degrades accuracy. The study identifies two core bottlenecks: task-composition failure (inability to jointly execute recognition and reasoning) and fusion failure (early integration introduces modality bias). Surprisingly, text-only baselines achieve the best performance, indicating that integration—not perception—is the limiting factor in multimodal reasoning.

## Method Summary
The authors introduce a logic-grounded evaluation framework that systematically varies how facts are distributed across modalities and combined for inference. Six interaction patterns are defined: independent, complement, redundant, conjunction, partial-entailment, and full-entailment. The framework evaluates whether multimodal models can properly compose recognition and reasoning tasks, and whether early fusion introduces modality bias. Experiments are conducted across multiple model families including LLaVA-1.5, LLaVA-NeXT, Qwen-VL, and InternVL, comparing against text-only baselines. Internal probing analyzes attention patterns to understand integration failures, while targeted interventions like chain-of-thought prompting and attention temperature scaling test whether bottlenecks can be mitigated.

## Key Results
- Text-only baselines achieve 79.7% accuracy, outperforming multimodal models on average
- Multimodal input helps only when it provides independent, sufficient reasoning paths
- Chain-of-thought prompting and attention temperature scaling significantly restore reasoning performance
- Attention patterns fail to encode fact usefulness, revealing fusion bottlenecks

## Why This Works (Mechanism)
The paper demonstrates that multimodal reasoning failures are not due to perceptual limitations but rather to integration bottlenecks in how models compose and fuse information across modalities. The mechanism centers on two failures: the inability to jointly execute recognition and reasoning in a single pass (task-composition bottleneck), and early integration that introduces modality bias (fusion bottleneck). When facts are distributed across modalities, models struggle to determine which modality to attend to and when, leading to incorrect fusion decisions. The attention analysis reveals that models do not effectively encode the usefulness of different modalities for specific reasoning steps, resulting in suboptimal integration strategies.

## Foundational Learning
- **Multimodal reasoning patterns**: Understanding how facts distributed across modalities affect reasoning performance. Why needed: To identify when additional modalities help versus harm. Quick check: Test whether model performance correlates with the independence of reasoning paths.
- **Task composition vs. fusion bottlenecks**: Distinguishing between failures in executing multiple tasks versus failures in early integration. Why needed: To target interventions appropriately. Quick check: Apply chain-of-thought prompting to see if composition improves without addressing fusion.
- **Attention-based integration analysis**: Using attention weights to probe how models integrate multimodal information. Why needed: To identify where integration fails at the architectural level. Quick check: Analyze attention entropy across reasoning steps.
- **Synthetic vs. natural evaluation**: Comparing controlled logic-grounded tests with open-ended multimodal datasets. Why needed: To validate findings beyond synthetic scenarios. Quick check: Apply interaction patterns to VQA datasets.
- **Early vs. late fusion dynamics**: Understanding how timing of modality integration affects reasoning. Why needed: To determine whether fusion should be delayed or controlled. Quick check: Compare models with different fusion architectures.
- **Modality sufficiency principles**: Identifying when modalities provide independent versus redundant information. Why needed: To predict when multimodal input will help. Quick check: Measure correlation between modality independence and performance gains.

## Architecture Onboarding
**Component map**: Perception module (vision encoder) -> Fusion layer (cross-attention) -> Reasoning module (LLM) -> Output generation
**Critical path**: Input processing -> Modality integration (fusion) -> Reasoning execution -> Answer generation
**Design tradeoffs**: Early fusion enables rich cross-modal interactions but risks modality bias; late fusion preserves modality independence but may miss synergistic information; intermediate fusion attempts balance but adds complexity
**Failure signatures**: Attention patterns that do not reflect fact usefulness; degraded performance on conjunction and entailment patterns; inability to decompose recognition and reasoning tasks
**First 3 experiments**:
1. Test chain-of-thought prompting on conjunction pattern to verify task-composition bottleneck
2. Apply attention temperature scaling to full-entailment pattern to assess fusion bottleneck
3. Compare performance across interaction patterns to identify which distributions cause most degradation

## Open Questions the Paper Calls Out
None

## Limitations
- Analysis relies on controlled synthetic datasets that may not capture real-world complexity
- Binary, fact-based evaluation framework may not reflect graded, contextual reasoning requirements
- Causal link between attention patterns and reasoning performance remains correlative rather than definitively established
- Fusion bottleneck characterization based on simple heuristics that may not generalize to complex multimodal inputs

## Confidence
- Multimodal reasoning failures stem from integration, not perception: Medium
- Task-composition bottleneck identification: High
- Fusion bottleneck characterization: Medium

## Next Checks
1. Apply the interaction pattern framework to open-ended datasets like VQA or image captioning to verify whether identified bottlenecks persist in real-world settings
2. Track how attention distributions evolve across reasoning steps in chain-of-thought prompting to determine whether composition bottlenecks stem from early-stage modality selection or sustained integration challenges
3. Test whether integration bottlenecks diminish with larger models or more capable multimodal architectures to clarify whether these are fundamental limitations or artifacts of current model scale