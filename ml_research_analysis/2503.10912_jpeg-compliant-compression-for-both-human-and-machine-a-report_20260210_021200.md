---
ver: rpa2
title: JPEG Compliant Compression for Both Human and Machine, A Report
arxiv_id: '2503.10912'
source_url: https://arxiv.org/abs/2503.10912
tags:
- compression
- image
- images
- jpeg
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of lossy image compression degrading
  DNN accuracy by formulating a multi-objective optimization problem balancing compression
  rate, human visual quality, and DNN accuracy. The authors propose Human and Machine-Oriented
  Error (HMOE) as a new distortion measure and develop the Human and Machine Oriented
  Soft Decision Quantization (HMOSDQ) algorithm based on it.
---

# JPEG Compliant Compression for Both Human and Machine, A Report

## Quick Facts
- arXiv ID: 2503.10912
- Source URL: https://arxiv.org/abs/2503.10912
- Reference count: 40
- This paper proposes HMOSDQ, a JPEG-compliant compression method that jointly optimizes quantization tables, run-length coding, and Huffman coding to balance compression rate, human visual quality, and DNN accuracy, achieving up to 2.1 dB PSNR improvement at 2.69 BPP for VGG-16.

## Executive Summary
This paper addresses the challenge of lossy image compression degrading DNN accuracy by formulating a multi-objective optimization problem balancing compression rate, human visual quality, and DNN accuracy. The authors propose Human and Machine-Oriented Error (HMOE) as a new distortion measure and develop the Human and Machine Oriented Soft Decision Quantization (HMOSDQ) algorithm based on it. HMOSDQ is fully JPEG-compliant and jointly optimizes quantization tables, run-length coding, and Huffman coding. Experimental results on AlexNet and VGG-16 models using ImageNet subsets show that HMOSDQ outperforms default JPEG compression.

## Method Summary
The method consists of three main components: (1) offline sensitivity estimation using gradients of surrogate loss w.r.t. DCT coefficients computed from 10,000 training images at 224×224 resolution; (2) Adaptive Sensitivity Mapping (ASM) to transform sensitivity values from the base resolution to target image resolutions using a linear Jacobian-based transformation; and (3) HMOSDQ algorithm that extends Soft Decision Quantization by replacing MSE with HMOE (λ-weighted combination of human and machine distortion) and iteratively optimizes quantization tables, run-length coding, and Huffman coding for both luma and chroma channels.

## Key Results
- HMOSDQ improves AlexNet's validation accuracy by over 0.81% at 0.61 BPP or reduces compression rate by 9.6× while maintaining the same accuracy compared to baseline JPEG
- HMOSDQ achieves up to 2.1 dB PSNR improvement at 2.69 BPP for VGG-16 in rate-distortion performance
- Ablation study confirms HMOE distortion measure effectiveness in preserving DNN accuracy

## Why This Works (Mechanism)

### Mechanism 1
Quantization distortion on DCT coefficients can be upper-bounded by a weighted MSE measure, where weights ("sensitivity") reflect how much each coefficient affects DNN surrogate loss. Through Taylor expansion and Cauchy-Schwarz inequality, the squared change in surrogate loss is bounded by Σᵢ Sᵢ · ‖Δxᶠᵢ‖², where Sᵢ = Σⱼ(∂L/∂xᶠᵢ,ⱼ)² aggregates per-coefficient gradient magnitudes across blocks. Minimizing this weighted distortion under a rate constraint indirectly reduces both surrogate loss change and MSE. Core assumption: Gradients on DCT coefficients are i.i.d. and zero-mean.

### Mechanism 2
Sensitivity estimated at one resolution can be accurately mapped to other resolutions via a linear Jacobian-based transformation. ASM computes a fixed Jacobian matrix J for the composite of inverse DCT → center-padding → resize → DCT. Estimated sensitivity at higher resolution is approximated as Ŝ′ᵢ = Σₖ J²ᵢ,ₖ · Ŝₖ. This enables offline estimation on a fixed resolution (e.g., 224×224) and reuse for arbitrary input sizes. Core assumption: Linear operations preserve sensitivity statistics under resolution change.

### Mechanism 3
Replacing MSE with HMOE (a λ-weighted combination of human and machine distortion) in SDQ optimization yields a JPEG-compliant bitstream that better preserves DNN accuracy at equivalent or lower bitrates. HMOE = Σᵢ(1 + λ · Ŝᵢ)(xᶠᵢ - IᵢQᵢ)². SDQ iteratively optimizes (r,s,a), Huffman probabilities, and quantization table Q to minimize HMOE + β·Rate. For chroma, both Cb/Cr are optimized jointly. The λ parameter controls the human/machine trade-off. Core assumption: The linear combination (1 + λ·Ŝ) appropriately balances human MSE and machine surrogate loss.

## Foundational Learning

- **JPEG pipeline (DCT, quantization, run-length/Huffman coding)**: Understanding the baseline is essential since HMOSDQ modifies quantization and entropy coding while maintaining JPEG compliance. Quick check: Can you explain why quantization table entries directly affect both bitrate and distortion?

- **Gradient-based sensitivity analysis for neural networks**: The core mechanism uses gradients of surrogate loss w.r.t. DCT coefficients to define sensitivity. Quick check: How would you compute ∂L/∂xᶠᵢ,ⱼ given a pretrained classifier and an input image?

- **Multi-objective optimization via Lagrangian formulation**: HMOE combines human and machine distortion into a single objective with λ as the trade-off parameter. Quick check: What happens to the rate-distortion-accuracy frontier as λ varies from 0 to large positive values?

## Architecture Onboarding

- **Component map**: Sensitivity estimator (offline) -> ASM module -> HMOE distortion calculator -> SDQ optimizer (extended for color) -> JPEG encoder/decoder wrapper

- **Critical path**: 1. Estimate Ŝ offline on 224×224 ImageNet training samples. 2. For each input image, apply ASM to get resolution-specific Ŝ′. 3. Initialize Q with OPs method. 4. Run SDQ iterations minimizing HMOE + β·Rate until convergence. 5. Output JPEG bitstream; decode and preprocess for DNN inference.

- **Design tradeoffs**: Larger λ → more accuracy preservation, potentially lower PSNR. More SDQ iterations → better convergence but higher encoding latency. Chroma joint optimization → better color fidelity but increased complexity. Offline vs. online sensitivity estimation: offline is faster but assumes dataset/model stability.

- **Failure signatures**: Accuracy gains not realized: λ too small, surrogate loss does not correlate with accuracy, or model/task mismatch. Excessive PSNR drop: λ too large or sensitivity overestimated for certain coefficients. Non-compliant JPEG: Bug in entropy coding or quantization table encoding. Slow encoding: SDQ not converging; check initialization and iteration cap.

- **First 3 experiments**: 1. Reproduce rate-accuracy curve for AlexNet on S512: Vary λ ∈ {0, 10⁻¹¹, 10⁻¹², 10⁻¹³}, compare BPP vs. top-1 accuracy against baseline JPEG. 2. Ablation: HMOE vs. MSE in SDQ: Set λ=0 (pure SDQ without machine term) and verify that accuracy-rate trade-off degrades, confirming HMOE's contribution. 3. Cross-model transfer: Compute sensitivity for VGG-16 but apply HMOSDQ to AlexNet inference; measure how much accuracy gain transfers to assess model specificity of Ŝ.

## Open Questions the Paper Calls Out
None

## Limitations
- The method's effectiveness is demonstrated only on AlexNet and VGG-16 architectures, leaving generalization to modern models uncertain
- The linear sensitivity mapping (ASM) assumes resolution changes are smooth and well-approximated by resize operations, potentially breaking down for extreme aspect ratios
- The computational overhead of sensitivity estimation and SDQ optimization may limit real-time deployment

## Confidence

- **High Confidence**: Claims about HMOSDQ improving rate-distortion-accuracy trade-offs over baseline JPEG for the tested models and datasets
- **Medium Confidence**: The HMOE formulation effectively balancing human and machine objectives, though optimal λ values appear dataset-specific
- **Medium Confidence**: The sensitivity estimation and ASM mechanisms work as described for standard ImageNet resolutions
- **Low Confidence**: Claims about model transferability of sensitivity are not experimentally validated in the paper

## Next Checks
1. Test HMOSDQ on images with extreme aspect ratios (e.g., 1:10, 10:1) and very small sizes (e.g., 64×64) to assess ASM robustness and identify resolution ranges where the linear mapping assumption breaks down.
2. Apply HMOSDQ to a modern architecture like ResNet-50 or MobileNet-v2 on ImageNet to verify if the sensitivity estimation and optimization framework generalize beyond the tested AlexNet/VGG-16 models.
3. Benchmark encoding/decoding latency of HMOSDQ compared to baseline JPEG at various quality settings to quantify the practical deployment cost of the accuracy-preserving optimization.