---
ver: rpa2
title: 'C-VARC: A Large-Scale Chinese Value Rule Corpus for Value Alignment of Large
  Language Models'
arxiv_id: '2506.01495'
source_url: https://arxiv.org/abs/2506.01495
tags:
- value
- rule
- chinese
- values
- rules
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study constructs the first large-scale, culturally grounded
  Chinese Value Rule Corpus (C-V ARC) to address the lack of value alignment benchmarks
  that reflect Chinese norms. Building on a hierarchical value framework rooted in
  socialist core values, the authors collected and curated over 250,000 high-quality
  value rules, validated through human annotation and expanded using LLMs.
---

# C-VARC: A Large-Scale Chinese Value Rule Corpus for Value Alignment of Large Language Models

## Quick Facts
- arXiv ID: 2506.01495
- Source URL: https://arxiv.org/abs/2506.01495
- Authors: Ping Wu; Guobin Shen; Dongcheng Zhao; Yuwei Wang; Yiting Dong; Yu Shi; Enmeng Lu; Feifei Zhao; Yi Zeng
- Reference count: 40
- Key outcome: Constructed the first large-scale Chinese Value Rule Corpus (C-VARC) with 250K+ rules, validated through human annotation and LLM expansion, showing improved scenario generation and value alignment evaluation.

## Executive Summary
This study addresses the lack of culturally grounded Chinese value alignment benchmarks by constructing C-VARC, a large-scale corpus of value rules rooted in socialist core values. The authors developed a hierarchical value framework and collected over 250,000 high-quality value rules through a combination of filtering existing datasets, LLM extraction, and human annotation. Experiments demonstrate that C-VARC-guided scenario generation produces more diverse and thematically coherent outputs compared to direct generation, and that C-VARC enables effective evaluation of LLM value alignment across 17 models using automatically generated moral dilemmas.

## Method Summary
The C-VARC corpus was built using a hierarchical value framework (3 dimensions → 12 core → 50 derived values) grounded in Chinese cultural norms. The authors filtered and combined existing Western datasets (SC101, MIC) with Chinese sources (Zhihu, People's Daily, FLAMES), retaining only culturally aligned rules. Qwen2.5-72B was used for rule extraction and expansion, with 36,000 rules validated by human annotators achieving κ > 0.85 agreement. The corpus enabled rule-guided scenario generation and automated dilemma creation through semantic similarity and contradiction scoring. Evaluation involved 17 LLMs across 10,998 moral dilemmas, with human annotators showing 87.5% alignment with C-VARC-guided preferences.

## Key Results
- C-VARC contains 257,609 rules with 92.33% human agreement on LLM-extracted rules
- Rule-guided scenarios show higher diversity (0.79 vs 0.71 intra-class distance) than direct generation
- Across 6 sensitive themes, 7 mainstream LLMs preferred C-VARC options in 70.5%+ of cases
- Human annotators aligned with C-VARC preferences at 87.5% rate
- 404,505 moral dilemmas generated, revealing 7,191 instances of divergent model responses

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A structured hierarchical value taxonomy enables systematic rule extraction and culturally coherent scenario generation.
- Mechanism: The 3-12-50 structure provides semantic anchors that guide LLM rule extraction and scenario generation, reducing cultural misalignment by constraining outputs to explicit value categories.
- Core assumption: Hierarchical taxonomies transfer cultural values more faithfully than flat classification schemes or Western-derived frameworks like MFT.
- Evidence anchors:
  - [abstract]: "hierarchical value framework grounded in core Chinese values, encompassing three main dimensions, 12 core values, and 50 derived values"
  - [section 2.1]: "The resulting 3-12-50 structure offers a coherent and comprehensive value taxonomy that not only operationalizes core values in real-world contexts, but also provides semantically rich labels for rule construction."
  - [corpus]: Limited direct corpus evidence; related work COIG-P notes "narrow domain coverage" in existing Chinese preference datasets, suggesting hierarchical breadth matters.
- Break condition: If the hierarchy is too abstract or too granular, rule extraction becomes inconsistent or scenarios lack semantic coherence.

### Mechanism 2
- Claim: Explicit rule constraints during generation produce scenarios with clearer value boundaries and higher diversity than free-form generation.
- Mechanism: Providing specific value rules as prompts constrains the LLM's output space while simultaneously increasing intra-category diversity through rule variation—rules act as semantic anchors that prevent topic drift while introducing varied perspectives.
- Core assumption: Rule specificity improves semantic coherence without sacrificing diversity.
- Evidence anchors:
  - [abstract]: "scenarios guided by C-VARC exhibit clearer value boundaries and greater content diversity compared to those produced through direct generation"
  - [section 4.1, Table 2]: Rule-guided scenarios show average intra-category distance of 0.79 vs 0.71 for unguided; "Rule of Law" shows +0.36 improvement.
  - [corpus]: No direct corpus evidence for rule-guided generation mechanism; ALIGN focuses on word association learning, not rule constraints.
- Break condition: If rules are too restrictive or contradictory, scenario diversity may collapse or outputs become formulaic.

### Mechanism 3
- Claim: Semantic similarity combined with contradiction probability scoring identifies rule pairs that produce morally challenging dilemmas.
- Mechanism: Using NLI-based similarity (>0.5) ensures topical relevance while contradiction scoring (>0.8) ensures the rules create mutually exclusive choices, producing authentic value conflicts rather than superficial disagreements.
- Core assumption: High semantic similarity + high contradiction = authentic moral tension that reveals underlying value priorities.
- Evidence anchors:
  - [section 4.3]: "we adopt a two-step process: (1) We use roberta-large-mnli... semantic similarity, retaining pairs with scores above 0.5; (2) we apply all-mpnet-base-v2 to assess contradiction probability, keeping only pairs above 0.8"
  - [section 4.3, Table 6]: Example pairs show similarity 0.53–0.64 and collision 0.81–0.99 (e.g., "It is important to stay humble" vs "Maintaining honor is also important").
  - [corpus]: Weak corpus evidence; VALUEFLOW addresses value-based alignment but not contradiction-based dilemma generation.
- Break condition: If similarity or contradiction thresholds are mis-calibrated, dilemmas become either trivially resolvable or semantically incoherent.

## Foundational Learning

- Concept: Moral Foundations Theory (MFT) limitations
  - Why needed here: The paper explicitly contrasts its approach with MFT, arguing MFT is Western-centric and insufficient for capturing Chinese collectivist and state-oriented values.
  - Quick check question: Can you explain why "care/harm" and "fairness/cheating" dimensions from MFT might underrepresent collectivist or state-centric moral reasoning?

- Concept: Rules of Thumb (RoTs) formalization
  - Why needed here: The corpus builds on the SC101 definition of RoTs; understanding the required judgment + action structure is essential for validating extracted rules.
  - Quick check question: What three components must a valid rule of thumb contain per the paper's guidelines (hint: see Appendix A.4)?

- Concept: Value priority conflicts vs positive-negative contradictions
  - Why needed here: The dilemma generation mechanism relies on distinguishing "both positively framed but mutually exclusive" rules from simple right/wrong pairs.
  - Quick check question: Why is the trolley problem a "value priority conflict" rather than a choice between a good and bad action?

## Architecture Onboarding

- Component map:
  Value Framework (3 dimensions → 12 core → 50 derived values) → Data Sources (filtered SC101/MIC + Chinese sources) → Rule Extraction (Qwen2.5-72B with filtering/extraction prompts) → Quality Control (36K human-annotated rules, κ > 0.85; LLM-assisted expansion) → Scenario Generator (rule-guided vs direct prompt templates) → Dilemma Generator (rule pair selection via similarity + contradiction) → Evaluation Suite (17 LLMs, 10,998 dilemmas, 7,191 divergent responses)

- Critical path:
  Data collection → Filtering (dedup + cultural alignment) → Rule extraction → Human annotation → Rule-guided generation → Dilemma pair selection → Model evaluation
  (Failure at filtering propagates cultural misalignment; failure at annotation propagates low rule quality.)

- Design tradeoffs:
  - Scale vs cultural authenticity: SC101/MIC provide scale but require aggressive filtering (11–34% retention rates).
  - Automation vs reliability: LLM extraction achieves 92.33% human agreement vs full manual annotation at κ > 0.85.
  - Coverage vs focus: National/societal rules underrepresented due to source data bias toward personal-level content.

- Failure signatures:
  - Low annotation agreement (κ < 0.7): Indicates unclear value framework or ambiguous rule definitions.
  - High distractor selection rate (>15%): Suggests dilemma options don't represent genuine moral choices.
  - t-SNE cluster overlap in rule-guided scenarios: Rules failing to provide semantic constraint.

- First 3 experiments:
  1. Replicate filtering retention rates: Run SC101/MIC rules through Qwen2.5-72B with the provided filtering prompt (Appendix A.2); verify ~11% and ~34% retention.
  2. A/B test scenario generation: Generate 100 scenarios per core value with/without rules; compute intra-category Euclidean distances; verify +0.08 average improvement.
  3. Validate contradiction scoring: Sample 100 rule pairs; manually verify that similarity >0.5 AND contradiction >0.8 yields actionable dilemmas vs pairs outside thresholds.

## Open Questions the Paper Calls Out

None

## Limitations

- The corpus relies heavily on LLM-based filtering and extraction, with only 11-34% retention rates for existing datasets, raising concerns about representativeness.
- The evaluation depends on comparing LLMs against each other rather than against ground truth human value priorities.
- The claim of improved scenario diversity is based on a single distance metric without examining content quality or cultural appropriateness.

## Confidence

- **High confidence:** The corpus construction methodology is well-documented and reproducible; the core claim that C-VARC provides a large-scale Chinese value corpus is well-supported.
- **Medium confidence:** The superiority of rule-guided scenario generation is demonstrated but limited to a single metric; LLM preference results are compelling but depend on operationalization.
- **Low confidence:** The claim that C-VARC captures authentic Chinese moral reasoning is difficult to verify given dependence on automated filtering and lack of human-generated value rule comparison.

## Next Checks

1. **Cultural validation study:** Conduct human evaluation with 100+ native Chinese speakers to assess whether randomly sampled C-VARC rules accurately reflect authentic Chinese moral reasoning and whether the 3-12-50 hierarchical structure adequately captures their value system.

2. **Cross-corpus comparison:** Compare C-VARC's rule distribution and scenario outputs against manually curated Chinese moral philosophy texts to identify gaps in coverage, particularly for national/societal values that were underrepresented in the source data.

3. **Alternative generation baseline:** Test rule-guided generation against a simpler baseline (e.g., direct prompting with value keywords rather than full rules) to determine whether the added complexity of rule extraction provides measurable benefits in scenario quality and diversity.