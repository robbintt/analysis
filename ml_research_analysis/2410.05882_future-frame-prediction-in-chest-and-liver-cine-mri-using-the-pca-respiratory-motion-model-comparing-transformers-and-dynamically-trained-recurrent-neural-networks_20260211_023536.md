---
ver: rpa2
title: 'Future frame prediction in chest and liver cine MRI using the PCA respiratory
  motion model: comparing transformers and dynamically trained recurrent neural networks'
arxiv_id: '2410.05882'
source_url: https://arxiv.org/abs/2410.05882
tags:
- motion
- prediction
- sequence
- each
- transformer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study compares transformers and dynamically trained recurrent
  neural networks (RNNs) for forecasting future frames in chest and liver cine MRI,
  addressing the challenge of respiratory motion in radiotherapy. A modular approach
  combines motion estimation via Lucas-Kanade optical flow, principal component analysis
  (PCA) to reduce dimensionality, and time-series forecasting of PCA weights.
---

# Future frame prediction in chest and liver cine MRI using the PCA respiratory motion model: comparing transformers and dynamically trained recurrent neural networks

## Quick Facts
- **arXiv ID:** 2410.05882
- **Source URL:** https://arxiv.org/abs/2410.05882
- **Reference count:** 40
- **Primary result:** Dynamically trained RNNs (RTRL, SnAp-1) achieved lowest geometrical errors (below 1.4mm on ETH, 2.8mm on OvGU), outperforming transformers and linear regression in forecasting respiratory motion for radiotherapy.

## Executive Summary
This study evaluates transformers and dynamically trained recurrent neural networks for forecasting future frames in chest and liver cine MRI, addressing respiratory motion challenges in radiotherapy. The authors employ a modular approach: motion estimation via Lucas-Kanade optical flow, dimensionality reduction through PCA, and time-series forecasting of PCA weights. Experiments on 12 MRI sequences from ETH Zürich and OvGU datasets show that online-trained RNNs (particularly RTRL and SnAp-1) achieved superior accuracy and stability with mean geometrical errors below 1.4mm and 2.8mm, respectively. Transformers showed competitive performance at short horizons but were limited by data scarcity and domain shift. The modular approach enhances interpretability and enables robust learning in low-data medical imaging regimes.

## Method Summary
The method combines motion estimation using pyramidal Lucas-Kanade optical flow to compute dense displacement vector fields (DVFs), PCA to project these fields onto a low-dimensional subspace, and time-series forecasting of the resulting PCA weights. Future frames are synthesized by warping a reference image using predicted DVFs and Nadaraya-Watson regression. The approach is evaluated using online-trained RNNs (RTRL, SnAp-1, UORO, DNI), offline-trained transformers, and linear regression, with the modular pipeline enabling interpretability and sample-efficient learning.

## Key Results
- Online-trained RNNs (RTRL, SnAp-1) achieved lowest geometrical errors: below 1.4mm on ETH Zürich and 2.8mm on OvGU datasets
- Transformers performed competitively at short horizons but degraded rapidly at longer horizons due to data scarcity
- Linear regression excelled at very short horizons (<0.5s) but failed at longer predictions
- Predicted frames visually resembled ground truth, with errors concentrated near the diaphragm and regions affected by out-of-plane motion
- Online learning enabled adaptation to non-stationary respiratory patterns, critical for clinical radiotherapy applications

## Why This Works (Mechanism)

### Mechanism 1: Low-Rank Motion Subspace Projection
Forecasting accuracy improves when high-dimensional optical-flow fields are projected onto a low-dimensional PCA subspace before temporal prediction. Respiratory motion lies on a low-dimensional linear manifold, allowing complex organ deformation to be approximated by a linear combination of a few static principal DVFs. The Lucas-Kanade optical flow extracts deformation fields, and PCA isolates dominant respiratory modes from noise.

### Mechanism 2: Online Parameter Adaptation (Dynamic Training)
Dynamically trained RNNs outperform static transformers because they adapt to non-stationary respiratory patterns (drifts and irregularities) during inference. Algorithms like RTRL and SnAp-1 update network weights at every time step based on instantaneous error, allowing the model to "track" changing patient breathing cycles without requiring massive pre-training datasets.

### Mechanism 3: Warping-Based Resynthesis (Vector-based Resampling)
Generating future frames by warping a reference image using predicted flow fields preserves anatomical texture better than direct pixel synthesis. Rather than hallucinating pixel intensities, the system predicts a dense motion field and uses it to resample pixels from a high-quality reference frame, separating the problem of "where things move" from "what things look like."

## Foundational Learning

**Principal Component Analysis (PCA) of Vector Fields**
*Why needed:* To understand why the model predicts "weights" rather than images. One must grasp that a 50x50 motion field is compressed into 2-3 scalar numbers representing "breathing in" or "heart beating."
*Quick check:* If the first PCA component represents the superior-inferior motion of the liver, what does the corresponding time-dependent weight $w_1(t)$ represent physically?

**Online vs. Offline Learning**
*Why needed:* To distinguish why a Transformer (offline) fails here while an RNN (online) succeeds. The distinction lies in *when* the weights update—during a distinct training phase vs. continuously during inference.
*Quick check:* Why would a model trained offline on "regular breathing" fail if a patient suddenly sighs (amplitude shift)?

**Optical Flow (Lucas-Kanade)**
*Why needed:* This is the input representation. One must understand that the input is not the MRI intensity, but the *displacement vector* calculated between frames.
*Quick check:* Does the optical flow algorithm predict the future, or does it just measure the displacement that already happened?

## Architecture Onboarding

**Component map:** Input MRI frames -> Lucas-Kanade Optical Flow -> PCA projection -> Forecaster (RNN/Transformer) -> Inverse PCA + Warping -> Synthesized future frame

**Critical path:** The Forecaster is the performance bottleneck. If the PCA weights are not predicted accurately, the subsequent warping will misalign the anatomy, regardless of image quality.

**Design tradeoffs:**
- **Transformer vs. RNN:** Transformers capture long-term dependencies but require massive data and fail under domain shift. RNNs with online learning are sample-efficient and adapt to drift but may struggle with very long sequences without truncation.
- **$n_{cp}$ Selection:** Increasing components captures more detail (e.g., cardiac motion) but introduces noise. The paper optimizes this dynamically.

**Failure signatures:**
- **Diaphragm misalignment:** Occurs at End-Inspiration where motion variability is highest
- **Blurring/Artifacts:** Occurs if Optical Flow fails due to low contrast or noise
- **Out-of-plane errors:** The model assumes 2D motion; if vessels move out of the slice, the warping cannot reproduce them

**First 3 experiments:**
1. **Baseline Stability Check:** Implement Linear Regression to predict PCA weights and verify it beats a "persistence model" at short horizons ($h < 0.5s$)
2. **Ablation on Learning Mode:** Train standard LSTM (offline) and compare against RTRL-enabled RNN on OvGU dataset to quantify value of online adaptation
3. **Component Sensitivity:** Vary $n_{cp}$ (1 to 4) and plot geometrical error to confirm $n_{cp}=2$ is often the "elbow" where respiratory motion is captured without overfitting

## Open Questions the Paper Calls Out

**Open Question 1:** Does integrating deep learning-based deformable image registration improve prediction accuracy compared to Lucas-Kanade optical flow?
- *Basis:* Section 4.4 identifies that "oracle" accuracy was limited by registration method's inability to handle noise and brightness variations
- *Evidence needed:* Comparative experiments substituting Lucas-Kanade with learning-based methods (e.g., VoxelMorph), demonstrating higher SSIM for oracle baseline

**Open Question 2:** Can combining population-level pretraining with patient-specific online fine-tuning enable transformers to outperform dynamically trained RNNs at medium-to-long horizons?
- *Basis:* Section 5 suggests future work on "training transformer-based models with more extensive data" and "online adaptation of pretrained population models"
- *Evidence needed:* Experiment where transformer is pretrained on large dataset and fine-tuned online on target sequence, showing lower nRMSE at $h \geq 1.0s$

**Open Question 3:** Do non-linear dimensionality reduction techniques (e.g., VAEs or kernel PCA) better mitigate domain shift and capture complex motion patterns than standard PCA?
- *Basis:* Section 4.4 notes future work could investigate "more expressive dimensionality-reduction methods... to better capture complex motion patterns and mitigate domain shift"
- *Evidence needed:* Ablation studies replacing PCA with VAE, showing improved generalization when trained on one dataset and tested on another with differing motion characteristics

## Limitations

- Limited dataset size (12 sequences total) raises questions about generalizability to diverse patient populations and breathing patterns
- Paper does not specify hyperparameter tuning procedures for Nadaraya-Watson regression or PCA component selection, affecting reproducibility
- Evaluation focuses primarily on geometrical accuracy metrics without extensive clinical validation of utility in actual radiotherapy workflows

## Confidence

**High Confidence:** The modular PCA-optical flow framework for dimensionality reduction is well-established in motion modeling literature and the paper's implementation follows standard approaches.

**Medium Confidence:** Claims about online RNN superiority over transformers are supported by results but limited by small sample size and domain shift effects that weren't fully explored.

**Medium Confidence:** Visual quality assessments showing predicted frames resemble ground truth are subjective and lack quantitative comparison with alternative synthesis methods.

## Next Checks

1. Test model generalization by evaluating on an independent, diverse patient cohort with varying breathing patterns and disease states to assess robustness beyond the two specific datasets used.

2. Implement ablation studies comparing the full PCA-weight forecasting pipeline against direct image-to-image prediction models to quantify the benefit of the modular approach.

3. Conduct clinical relevance testing by measuring actual radiotherapy system latency reduction and dosimetric impact when using predicted frames versus standard gating approaches.