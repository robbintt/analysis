---
ver: rpa2
title: 'Counting Still Counts: Understanding Neural Complex Query Answering Through
  Query Relaxation'
arxiv_id: '2511.22565'
source_url: https://arxiv.org/abs/2511.22565
tags:
- query
- neural
- relaxation
- methods
- relax
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates whether neural complex query answering (CQA)
  models learn to go beyond the reach of explicit graph structure by comparing them
  to a training-free query relaxation strategy that retrieves answers by progressively
  relaxing query constraints and counting resulting paths. Across multiple datasets
  and query types, the authors find that neural models do not consistently outperform
  the relaxation strategy, with no model reliably surpassing it.
---

# Counting Still Counts: Understanding Neural Complex Query Answering Through Query Relaxation

## Quick Facts
- **arXiv ID:** 2511.22565
- **Source URL:** https://arxiv.org/abs/2511.22565
- **Reference count:** 31
- **One-line primary result:** Neural CQA models do not consistently outperform a training-free query relaxation strategy; combining both approaches yields significant gains.

## Executive Summary
This work investigates whether neural complex query answering (CQA) models learn to go beyond the reach of explicit graph structure by comparing them to a training-free query relaxation strategy that retrieves answers by progressively relaxing query constraints and counting resulting paths. Across multiple datasets and query types, the authors find that neural models do not consistently outperform the relaxation strategy, with no model reliably surpassing it. Furthermore, a similarity analysis shows that the top-ranked answers from both approaches differ substantially, indicating complementary reasoning patterns. Combining their outputs consistently improves performance, particularly for path queries. These findings challenge the assumption that learned representations inherently generalize beyond symbolic reasoning, highlighting the importance of stronger non-neural baselines and suggesting future neural architectures could benefit from integrating relaxation-based principles.

## Method Summary
The paper compares neural CQA models against a training-free query relaxation baseline (RELAX) across three datasets (FB15k237+H, NELL995+H, ICEWS18+H) and seven query types (1p, 2p, 3p, 2i, 3i, ip, pi). RELAX works by replacing anchor entities with variables and counting matching graph paths, progressively relaxing constraints and using entity in-degree as a tiebreaker. Neural baselines include GNN-QE, ULTRAQ, CQD, ConE, and QTO. The primary metric is filtered Mean Reciprocal Rank (MRR), with Jaccard similarity used to measure answer overlap between methods.

## Key Results
- Neural models and RELAX achieve similar MRR scores, but with little overlap in their top-ranked answers
- Oracle combination of neural and relaxation predictions yields consistent gains, especially for path queries (up to 67.5% relative improvement)
- No single neural model reliably outperforms RELAX across all query types and datasets
- Error modes are complementary: neural models struggle with long paths, while RELAX faces timeouts on intersection queries

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** A training-free hierarchical relaxation strategy can approximate complex reasoning by exploiting structural regularities, often matching learned neural models.
- **Mechanism:** The strategy (RELAX) operates by replacing anchor entities with variables and counting matching graph paths. To resolve ties in path counts, it progressively relaxes constraints (replacing predicates with variables) and finally falls back to global degree statistics. This prioritizes specific structural matches while using general connectivity as a backoff.
- **Core assumption:** The validity of an answer correlates with the number of structural paths connecting it to the query anchors, even if the exact relation sequence is missing from the graph.
- **Evidence anchors:**
  - [abstract]: "...retrieves possible answers by relaxing query constraints and counting resulting paths."
  - [section 4]: "The algorithm traverses the query graph from the leaves (constants) to the root... counting within the tied group."
  - [corpus]: This aligns with the "Neural-Symbolic Message Passing" concept in the corpus, where explicit structure is leveraged, though RELAX avoids the message-passing training phase entirely.
- **Break condition:** If the graph is extremely sparse or the answer requires reasoning over attributes/semantics not captured by path topology (e.g., specific text matching), path counting will likely fail or return random ties.

### Mechanism 2
- **Claim:** Neural models and symbolic relaxation exhibit low overlap in their top-ranked predictions, implying they capture distinct reasoning signals (latent vs. structural).
- **Mechanism:** Neural models encode entities into continuous vector spaces, allowing them to generalize based on latent semantic similarity. In contrast, RELAX relies on discrete graph topology. The paper demonstrates that these distinct approaches often rank different entities highly, meaning the failure of one does not predict the failure of the other.
- **Core assumption:** Neural models do not simply memorize path statistics; they encode different generalizations, causing their error modes to be uncorrelated with those of path counting.
- **Evidence anchors:**
  - [abstract]: "...similarity analysis reveals that their retrieved answers exhibit little overlap..."
  - [section 5.3]: "...while neural models and RELAX may achieve similar MRR, they do so by ranking different entities highly."
  - [corpus]: The paper "CQD-SHAP" in the corpus suggests explainability in CQA is valuable; the distinct predictions here offer a form of structural explainability absent in neural latent spaces.
- **Break condition:** If neural models were merely overfitting to local graph statistics (memorization), they would converge to the same rankings as RELAX, eliminating complementarity.

### Mechanism 3
- **Claim:** An oracle combination of neural and relaxation scores significantly boosts performance, specifically for path queries where neural error propagation is high.
- **Mechanism:** By selecting the method (Neural vs. RELAX) that yields the higher Mean Reciprocal Rank (MRR) per query, the system effectively "hedges" against the specific failure modes of each. It uses RELAX to stabilize long reasoning chains (where neural error compounds) and neural models for intersection/semantic queries.
- **Core assumption:** There exists a deterministic or learnable signal to predict which method is superior for a given query structure, though the paper currently uses an oracle (theoretical upper bound).
- **Evidence anchors:**
  - [section 5.4]: "...optimal combination... yields consistently and significantly gains... particularly for path queries."
  - [table 2]: Shows relative gains up to 67.5% (ICEWS 3p) when combining QTO and RELAX.
  - [corpus]: The corpus paper "Efficient and Scalable Neural Symbolic Search" addresses complexity; this mechanism suggests a simpler fusion strategy that might avoid complex search overhead.
- **Break condition:** The oracle mechanism breaks if real-time deployment requires a pre-query decision mechanism (a router) that fails to accurately predict the superior approach.

## Foundational Learning

- **Concept:** **First-Order Logic (FOL) & Conjunctive Queries**
  - **Why needed here:** The entire experimental framework is built on query types (1p, 2p, 2i, pi) defined by their graph structure (anchors, targets, existential variables). You cannot interpret the results tables without understanding that "2p" implies a two-hop path query.
  - **Quick check question:** Can you explain why a "2i" query (intersection) might cause a "large intermediate join" complexity issue compared to a "1p" query?

- **Concept:** **Mean Reciprocal Rank (MRR) & Filtered Setting**
  - **Why needed here:** The paper claims "comparable performance" based on MRR. Understanding that MRR is sensitive to the rank of the *first* correct answer is crucial for seeing why low overlap doesn't prevent similar scores.
  - **Quick check question:** If Method A finds the correct answer at rank 2 and Method B finds it at rank 100, but both find another correct answer at rank 1, how does MRR reflect their difference?

- **Concept:** **Graph Query Relaxation**
  - **Why needed here:** This is the core contribution. You must distinguish "relaxation" (generalizing the query) from "approximate answering" (generalizing the reasoning process).
  - **Quick check question:** In the RELAX algorithm, why does replacing a specific entity (anchor) with a variable act as a "broadening" of the search space?

## Architecture Onboarding

- **Component map:** Input Layer (Knowledge Graph + Query Graph) -> Neural Branch (GNN/Embedding Encoder -> Logic Operators -> Score Vector) OR Symbolic Branch (GraphDB Interface -> Query Rewriting -> Path Counter -> Tie-Breaker) -> Fusion Layer (Oracle Selector) -> Final Ranking

- **Critical path:** The "Tie-Breaking" logic in the Symbolic Branch (Algorithm 1, Step 3 & 4). If the path count is identical, the system must fallback to relation-specific indegrees or global indegrees. Incorrect implementation here leads to random ordering of correct answers, destroying MRR.

- **Design tradeoffs:** The paper highlights that Neural models require "extensive training" while RELAX is "training-free." However, RELAX has $O(N^3)$ worst-case complexity for 3-hop queries (Table 3) unless optimized with the "subquery aggregation trick" (Appendix A.2).

- **Failure signatures:**
  - **Neural Degradation:** Performance drops sharply as path length increases (2p -> 3p) due to error propagation (Section 5.2).
  - **Relaxation Timeouts:** High latency or memory overflow on "ip" and "pi" queries (intersection + path) if the database isn't optimized or the timeout is too strict (Table 4).

- **First 3 experiments:**
  1. **Baseline Replication:** Implement the "RELAX" algorithm on a simple SPARQL endpoint. Verify that for 1p queries, it returns similar MRR to the reported baseline (~31.5% for FB15k) to ensure your relaxation logic is correct.
  2. **Overlap Analysis:** Pick a single dataset (e.g., NELL995+H) and compute the Jaccard Index ($J@k$) between a neural model (like ConE) and your RELAX implementation. Confirm that high MRR in both doesn't mean high answer overlap (aim for <0.5 overlap).
  3. **Oracle Fusion:** Implement the "Oracle" combination logic (taking the max rank from two pre-computed result lists). Confirm you see the ~30% relative gains reported in Table 2 for path queries.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can neural architectures explicitly incorporate query relaxation signals without sacrificing differentiability or scalability?
- **Basis in paper:** [Explicit] The authors state in Section 6.1 that designing "realistic fusion mechanisms... or neural architectures that explicitly incorporate relaxation signals remains an open avenue."
- **Why unresolved:** The paper demonstrates the value of combination using an oracle to select the best prediction, but does not propose a trainable mechanism to integrate these symbolic signals into the neural model's forward pass.
- **What evidence would resolve it:** A differentiable model that ingests relaxation-based counts or rankings as features and consistently outperforms both standard neural models and the non-trainable relaxation baseline.

### Open Question 2
- **Question:** What are principled methods for pruning or approximating query relaxations to enable application on large-scale knowledge graphs?
- **Basis in paper:** [Explicit] Section 6.1 notes that extending the analysis to large-scale KGs requires "principled ways of pruning or approximating relaxations while retaining predictive power."
- **Why unresolved:** The current implementation limits relaxation steps (e.g., limiting to two predicates for 3p queries) to manage memory, which is an ad-hoc constraint rather than a theoretically grounded approximation.
- **What evidence would resolve it:** An algorithm that reduces the computational complexity of relaxation (time/space) while maintaining statistically similar retrieval performance compared to the exhaustive method.

### Open Question 3
- **Question:** Do alternative relaxation schemes utilizing richer statistical features (e.g., path diversity, edge weights) capture reasoning patterns that align more closely with neural models?
- **Basis in paper:** [Explicit] The authors suggest in Section 6.1 that future work could "explore alternative relaxation schemes, richer statistical features (e.g., path diversity, edge weights, type constraints)."
- **Why unresolved:** This study focuses on a specific instantiation of relaxation based on path counting and in-degree; it is unknown if other symbolic heuristics would show higher or lower overlap with neural embeddings.
- **What evidence would resolve it:** A comparative analysis showing that relaxation strategies incorporating type constraints or path diversity result in significantly higher Jaccard similarity with neural model outputs.

## Limitations

- The relaxation strategy's complexity limits its application to intersection queries, causing timeouts and memory issues that may understate its true capability
- Neural baselines are treated as black boxes without full exploration of their training details, hyperparameter tuning, or failure modes
- The tie-breaking mechanism using in-degree statistics is plausible but not rigorously validated against alternative approaches

## Confidence

- **High Confidence:** The finding that neural and relaxation methods produce low-overlap answer sets is well-supported by the Jaccard similarity analysis and is a robust, interpretable signal.
- **Medium Confidence:** The claim that no neural model reliably outperforms RELAX is plausible given the data, but could shift with better-tuned neural models or larger, more diverse datasets.
- **Low Confidence:** The assertion that RELAX's tie-breaking mechanism (using in-degree statistics) is the key to its competitiveness is plausible but not rigorously validated; alternative tie-breaking strategies could yield different results.

## Next Checks

1. **Scalable Relaxation Implementation:** Implement the subquery aggregation trick (Appendix A.2) and measure RELAX's performance and runtime on intersection queries without timeouts. Does it maintain competitiveness?
2. **Neural Model Ablation:** Train a simplified neural baseline (e.g., a basic GNN without complex operators) on the same data. Does it perform similarly to RELAX, suggesting the gap is due to architecture, not learning?
3. **Error Analysis by Query Type:** For queries where neural models fail but RELAX succeeds (and vice versa), conduct a qualitative analysis. Is the failure due to graph sparsity, missing relations, or the need for semantic generalization beyond path counting?