---
ver: rpa2
title: 'Reading minds on the road: decoding perceived risk in automated vehicles through
  140K+ ratings'
arxiv_id: '2508.19121'
source_url: https://arxiv.org/abs/2508.19121
tags:
- longitudinal
- acceler
- ation
- elativ
- elocity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a novel method to decode time-continuous
  perceived risk in automated vehicles by crowd-sourcing 141,628 discrete risk ratings
  from 2,164 participants viewing realistic highway driving videos. These discrete
  ratings were reconstructed into 236 hours of time-continuous perceived risk data.
---

# Reading minds on the road: decoding perceived risk in automated vehicles through 140K+ ratings

## Quick Facts
- arXiv ID: 2508.19121
- Source URL: https://arxiv.org/abs/2508.19121
- Reference count: 21
- Primary result: DNNs predict moment-by-moment perceived risk from kinematics with mean relative error below 3%

## Executive Summary
This study introduces a method to decode continuous perceived risk in automated vehicles by aggregating 141,628 discrete risk ratings from 2,164 participants viewing highway driving videos. The discrete ratings were time-aligned and interpolated into 236 hours of continuous risk data. Deep neural networks trained on vehicle kinematics achieved prediction errors below 3%, outperforming physics-based models. Explainable AI analysis revealed that risk factors like manoeuvre uncertainty vary adaptively over time, providing insights for designing real-time risk-aware AV control systems.

## Method Summary
The pipeline transforms discrete crowd-sourced risk ratings into continuous risk curves via PCHIP interpolation after time-aligning ratings to peak-risk moments. Kinematic data (10 Hz) is processed into input features including raw values and derived metrics like DRAC and uncertain velocity. Scenario-specific DNNs (500-neuron hidden layers) are trained to predict the continuous risk curve from these features. SHAP analysis quantifies feature contributions to predictions, revealing how risk factors change importance over time. PCAD and DRF baselines are calibrated via grid search for comparison.

## Key Results
- DNNs achieved mean relative error below 3% in predicting moment-by-moment perceived risk from vehicle kinematics
- DNNs outperformed physics-based models (PCAD, DRF) with errors concentrating near zero versus heavier tails
- SHAP analysis revealed manoeuvre uncertainty and relative motion as primary risk drivers, with factor contributions varying adaptively over time

## Why This Works (Mechanism)

### Mechanism 1: Dense Discrete Rating Aggregation Enables Continuous Signal Reconstruction
Aggregating many discrete risk ratings across participants and clips can be interpolated to approximate a time-continuous perceived risk signal. Participants rate discrete clips; ratings are aligned to peak-risk moments within each clip based on kinematic events. Interpolation (PCHIP) connects these time-aligned points to form a continuous curve, assuming perceived risk evolves smoothly between observed events.

### Mechanism 2: DNNs Capture Non-linear Dependencies From Kinematics to Perceived Risk
DNNs can learn a mapping from vehicle kinematics to continuous perceived risk with low error, outperforming physics-based models. The DNN takes kinematic features (distances, velocities, accelerations, and derived uncertainty metrics) as input and is trained on reconstructed continuous risk curves. Its hidden layers allow it to model complex, non-linear relationships that simpler models may miss.

### Mechanism 3: Explainable AI Reveals Time-Varying Factor Contributions
SHAP analysis can identify which kinematic factors most influence perceived risk at each time step, and these contributions change over the course of an event. SHAP values are computed for each input feature for each prediction, quantifying the contribution of each factor to the predicted risk at that moment.

## Foundational Learning

- **Concept: Perceived Risk vs. Objective Risk** - Understanding the distinction between subjective psychological constructs and collision likelihood is critical for interpreting model outputs. Would a model trained only on collision proximity data likely agree with this paper's model in a close-but-stable following scenario?

- **Concept: Interpolation for Signal Reconstruction** - The core method relies on transforming sparse, discrete labels into a continuous signal. Understanding the assumptions and limitations of interpolation (e.g., PCHIP vs. linear) is essential for evaluating ground-truth data quality. If participants' perceived risk actually fluctuated rapidly between two rating moments, how would PCHIP interpolation represent that?

- **Concept: SHAP Values for Model Interpretation** - The key insights about why risk changes are derived from SHAP, not from the DNN itself. Knowing what SHAP measures (feature attribution) and its properties is necessary to critically evaluate conclusions about factor importance. A SHAP value for "longitudinal distance" is high at a specific time step - does this mean changing distance would change perceived risk, or just that the model uses distance to make its prediction?

## Architecture Onboarding

- **Component map**: Stimulus Generation (CarMaker simulation) -> Data Collection (Prolific/Qualtrics ratings) -> Signal Reconstruction (PCHIP interpolation) -> Feature Engineering (kinematic processing) -> Surrogate Modeling (scenario-specific DNNs) -> Interpretation (SHAP analysis)

- **Critical path**: The fidelity of final insights depends most heavily on the Signal Reconstruction step. The DNN and SHAP analysis are only as valid as the continuous risk ground truth they are trained on.

- **Design tradeoffs**: Model specificity vs. generality (separate DNNs per scenario for specialization), physics-based vs. data-driven (PCAD/DRF are interpretable but performed worse), feature simplicity vs. richness (including derived features like "uncertain velocity" improved performance but introduces assumptions)

- **Failure signatures**: DNN overfitting to scenario order (learning "later in time = higher risk" instead of kinematics), interpolation artifacts (PCHIP may not capture sharp transient risk spikes), SHAP misinterpretation (high values indicate model usage, not necessarily human perception)

- **First 3 experiments**:
  1. Validate reconstruction on held-out event by training pipeline on 104 events and testing on 105th
  2. Ablate derived features by retraining DNNs without PCAD-based uncertainty features to quantify their contribution
  3. Cross-scenario generalization test by training on three scenarios and testing zero-shot on fourth

## Open Questions the Paper Calls Out
None

## Limitations
- Primary uncertainty is the fidelity of interpolated continuous perceived risk signal - PCHIP interpolation may smooth over genuine risk spikes between rating moments
- Controlled simulation environment limits generalizability to real-world conditions like weather, lighting, and diverse road users
- Scenario-specific DNNs require new models for each novel scenario type, limiting scalability

## Confidence
- **High confidence**: Prediction accuracy (<3% error) and performance ranking (DNN > PCAD > DRF) are likely reliable with large dataset and proper validation
- **Medium confidence**: Specific factor importances are derived from SHAP values quantifying model usage, not necessarily human perception
- **Low confidence**: Absolute accuracy of continuous risk reconstruction itself is uncertain without independent validation

## Next Checks
1. Train entire pipeline on 104 events and test reconstruction/prediction accuracy on held-out 105th event with new participants
2. Retrain DNNs without PCAD-based uncertainty features to quantify their performance contribution and impact on SHAP-analyzed factor importance
3. Train DNN on three scenarios and test zero-shot prediction accuracy on fourth scenario to probe generalization ability