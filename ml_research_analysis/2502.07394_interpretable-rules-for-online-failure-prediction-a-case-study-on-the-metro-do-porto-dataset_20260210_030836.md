---
ver: rpa2
title: 'Interpretable Rules for Online Failure Prediction: A Case Study on the Metro
  do Porto dataset'
arxiv_id: '2502.07394'
source_url: https://arxiv.org/abs/2502.07394
tags:
- failure
- data
- rules
- failures
- flowmeter
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses predictive maintenance for Metro do Porto
  trains, focusing on predicting failures in the Air Production Unit (APU). The authors
  propose an online rule-based explainability approach that generates interpretable
  rules for failure prediction using an Autoencoder architecture.
---

# Interpretable Rules for Online Failure Prediction: A Case Study on the Metro do Porto dataset

## Quick Facts
- **arXiv ID:** 2502.07394
- **Source URL:** https://arxiv.org/abs/2502.07394
- **Reference count:** 22
- **Primary result:** Achieves perfect F1 score (100% precision, 100% recall) predicting APU failures 2+ hours before activation using only 3 sensor rules

## Executive Summary
This study presents an interpretable online failure prediction system for Metro do Porto trains, specifically targeting the Air Production Unit (APU). The authors propose using reconstruction errors from a Convolutional Autoencoder trained on normal data to detect anomalies preceding failures. By applying temporal smoothing and extracting simple threshold rules from aggregated sensor statistics, they demonstrate that only three sensors (Flowmeter, Oil temperature, and Motor current) are sufficient to predict failures with interpretable rules. The approach achieves perfect detection performance on the MetroPT2 dataset while providing clear explanations for failure predictions.

## Method Summary
The authors propose an online rule-based explainability approach for failure prediction using a Convolutional Autoencoder architecture. The method works by training an autoencoder exclusively on normal operational data, then using reconstruction errors as anomaly indicators. Windows of sensor data are passed through the autoencoder, and reconstruction errors are compared against a threshold (τ_anom = 3 × q_99) to detect anomalies. An exponential smoothing filter (α = 0.15) is applied to reduce false positives, and when the smoothed probability of failure exceeds a threshold (τ_fail = 0.5), interpretable rules are extracted using decision trees on aggregated window features.

## Key Results
- Perfect F1 score (100% precision, 100% recall) predicting APU failures
- Failures detected 2+ hours before Low Pressure Signal activation
- Only three sensors required: Flowmeter, Oil temperature, and Motor current
- Simple interpretable rules extracted: "Flowmeter max > 16.05 ⇒ Failure"

## Why This Works (Mechanism)

### Mechanism 1: Reconstruction Error as Anomaly Proxy
High reconstruction error from an autoencoder trained exclusively on normal data indicates anomalous system behavior preceding failures. The Convolutional Autoencoder learns to compress and reconstruct normal operational patterns. When input data deviates significantly from learned patterns, reconstruction error increases. A threshold τ_anom = β × q_99 (where q_99 is the 99th percentile of training errors) distinguishes normal from anomalous windows.

### Mechanism 2: Temporal Smoothing via Low-Pass Filter
Applying exponential smoothing to binary anomaly predictions reduces false positives by requiring sustained anomalous signals before declaring failure. Equation (1) z_t = z_{t-1} + α(y_t - z_{t-1}) implements exponential moving average with smoothing factor α = 0.15. Only when smoothed probability p(failure) exceeds τ_fail = 0.5 is a failure declared.

### Mechanism 3: Decision Tree Rules on Aggregated Window Features
Simple threshold rules on aggregated sensor statistics (max, min, mean, variance) over 30-minute windows provide interpretable failure explanations. Windows are transformed via φ: R^{L×C} → R^{M×C} using aggregation functions. When p(failure) exceeds τ_fail, a labeled dataset is constructed from buffer B (failure windows) and history H (normal windows). Decision trees trained to perfect fit extract rules like "Flowmeter max > 16.05 ⇒ Failure."

## Foundational Learning

- **Autoencoder architecture for time series**
  - Why needed here: Understanding encoder-decoder structure, latent space compression, and reconstruction loss is essential before implementing the failure detection pipeline
  - Quick check question: Can you explain why an autoencoder trained only on normal data will produce higher reconstruction error for anomalous inputs?

- **Exponential moving average / low-pass filtering**
  - Why needed here: The smoothing mechanism (Eq. 1) is critical for reducing false positives; understanding how α controls smoothing aggressiveness is necessary for tuning
  - Quick check question: Given α = 0.15, approximately how many timesteps are needed for a sustained anomaly signal to reach p(failure) > 0.5?

- **Decision tree rule extraction**
  - Why needed here: The explainability layer uses decision trees to generate interpretable rules; understanding how tree splits translate to threshold rules is required
  - Quick check question: How does a decision tree split on "Flowmeter max ≤ 16.05" translate to a human-readable rule?

## Architecture Onboarding

- **Component map:** Raw sensor data → Windowing → Autoencoder reconstruction → Error thresholding → Smoothing → p(failure) → Rule extraction

- **Critical path:** Raw sensor data → Windowing (L=1800, stride d=300) → Normalization → Convolutional Autoencoder → Reconstruction error → Boxplot threshold τ_anom → Exponential smoothing (α = 0.15) → p(failure) comparison with τ_fail = 0.5 → Buffer H/B → Aggregated features → Decision Tree → Interpretable rules

- **Design tradeoffs:**
  - Window length (L=30 min) balances temporal context vs. detection latency
  - Stride (d=5 min) determines inference frequency and computational load
  - α = 0.15 trades false positive reduction against detection delay
  - Training only on normal data avoids label requirements but assumes normal data is representative

- **Failure signatures:**
  - **False positives during normal operation:** Check if τ_anom is too low or if training data contained anomalies
  - **Missed detections:** Check if p(failure) threshold τ_fail = 0.5 is too aggressive given smoothing factor
  - **Overly complex rules:** May indicate window aggregation is insufficient or sensor subset is too large

- **First 3 experiments:**
  1. Reproduce baseline: Train ConvAE on training split (until 2022-06-01), compute reconstruction error distribution, validate τ_anom = 3 × q_99 yields zero false positives on pre-failure test period
  2. Ablate smoothing: Compare detection timing and false positive rate with α ∈ {0.05, 0.15, 0.3, 0.5} to understand sensitivity
  3. Rule validation without Flowmeter: Remove Flowmeter sensor, re-run rule extraction, verify Oil temperature + Motor current + TP2 rules still achieve perfect F1 (as claimed in Table 3)

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the failure detection approach be adapted for datasets lacking highly predictive sensors like the Flowmeter (e.g., MetroPT3)?
- **Basis in paper:** [explicit] "Initial experiments showed many false-positive failure predictions, suggesting that different methods than our Convolutional Autoencoder to model p(failure) would be necessary" for MetroPT3.
- **Why unresolved:** The current method relies heavily on Flowmeter; without it, Convolutional Autoencoders struggle to model failure probability effectively.
- **What evidence would resolve it:** Successful application of alternative architectures or feature engineering approaches on MetroPT3 with comparable F1 scores.

### Open Question 2
- **Question:** What strategies can enable the online rule-learning algorithm to scale its history buffer for real-world deployment over months or years?
- **Basis in paper:** [explicit] "We suggest that future work investigate different known strategies to keep a maximum history size, such as random subsampling or removing windows from further in the past with higher probability."
- **Why unresolved:** Current unbounded history approach works for research but won't scale when processing years of operational data.
- **What evidence would resolve it:** Comparative evaluation of subsampling, aging-based removal, or clustering strategies showing maintained prediction quality with bounded memory.

### Open Question 3
- **Question:** Can the extracted rules reveal actionable physical insights about APU component degradation mechanisms rather than merely correlational patterns?
- **Basis in paper:** [inferred] Authors note "an infinite number of rules could be retrieved" and "we cannot confidently gain knowledge about potential breaking points of parts of the APU from these rules."
- **Why unresolved:** The rule extraction identifies statistical patterns but doesn't establish causal relationships to specific component failure modes.
- **What evidence would resolve it:** Domain expert validation showing extracted rules correspond to known physical degradation processes, or integration of physics-informed constraints into rule learning.

## Limitations
- Limited scope validation on single dataset (MetroPT2) from one metro system
- Unknown generalization to other failure modes beyond APU failures
- Threshold sensitivity with multiple manually set parameters optimized for specific case

## Confidence
- **High confidence:** Autoencoder reconstruction error for anomaly detection (well-established in literature)
- **Medium confidence:** Temporal smoothing approach (reasonable but lacks sensitivity analysis)
- **Medium confidence:** Three-sensor sufficiency claim (valid for this dataset but may not generalize)

## Next Checks
1. **Cross-validation across failure modes:** Apply methodology to detect other types of failures in MetroPT2 dataset to assess generalizability
2. **Threshold sensitivity analysis:** Systematically vary τ_anom, τ_fail, and α across ranges to quantify impact on detection performance
3. **Generalizability test:** Apply trained model and extracted rules to different time period within same dataset or different metro system to evaluate robustness across temporal and operational variations