---
ver: rpa2
title: Extending Decision Predicate Graphs for Comprehensive Explanation of Isolation
  Forest
arxiv_id: '2505.04019'
source_url: https://arxiv.org/abs/2505.04019
tags:
- iforest
- outlier
- outliers
- predicate
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a Decision Predicate Graph (DPG)-based method
  to explain Isolation Forest (iForest) for outlier detection. Unlike traditional
  approaches that provide only feature importance vectors, our method constructs a
  global, graph-based explanation of iForest's decision-making process.
---

# Extending Decision Predicate Graphs for Comprehensive Explanation of Isolation Forest

## Quick Facts
- arXiv ID: 2505.04019
- Source URL: https://arxiv.org/abs/2505.04019
- Authors: Matteo Ceschin; Leonardo Arrighi; Luca Longo; Sylvio Barbon Junior
- Reference count: 30
- One-line primary result: Introduces a Decision Predicate Graph (DPG)-based method to explain Isolation Forest (iForest) for outlier detection, providing global, graph-based explanations beyond traditional feature importance vectors.

## Executive Summary
This study presents a novel method to explain Isolation Forest (iForest) anomaly detection models through Decision Predicate Graphs (DPG). Unlike traditional approaches that provide only feature importance vectors, this method constructs a global, graph-based explanation of iForest's decision-making process. The approach represents the model as a weighted directed graph where nodes are predicates (feature conditions) and edges show decision paths. A new metric, the Inlier-Outlier Propagation Score (IOP-Score), quantifies each feature's contribution to outlier identification. Experiments on synthetic datasets and the Annthyroid benchmark demonstrate that the method provides comprehensive visual and quantitative explanations, revealing which features and conditions drive anomaly detection.

## Method Summary
The method converts an iForest ensemble into a Decision Predicate Graph (DPG) by extracting split rules from internal nodes and representing them as directed graph nodes (predicates). Edges are formed by sequential satisfaction of these predicates during sample traversal, aggregating scattered tree decisions into a unified structural view. The Inlier-Outlier Propagation Score (IOP-Score) is calculated for each node to quantify its discriminative power in anomaly detection, measuring the difference between transition frequencies to "Inlier" versus "Outlier" classes. The approach includes class-based frequency weighting to correct for dataset imbalance, amplifying the signal from the minority outlier class to prevent inlier paths from obscuring outlier logic.

## Key Results
- The DPG approach provides comprehensive visual and quantitative explanations of iForest decision-making
- IOP-Scores successfully identify features and conditions that drive anomaly detection in both synthetic and real-world datasets
- The method reveals interpretable insights into both outlier and inlier classification boundaries
- Class-based weighting effectively handles imbalanced datasets, demonstrated on the Annthyroid benchmark (3.61% outliers)

## Why This Works (Mechanism)

### Mechanism 1
Converting an iForest ensemble into a Decision Predicate Graph (DPG) exposes the isolation logic hidden in the ensemble structure. The method extracts split rules from internal nodes of all trees, representing them as directed graph nodes (predicates). Edges are formed by the sequential satisfaction of these predicates during sample traversal, aggregating scattered tree decisions into a unified structural view. The core assumption is that the collective traversal paths of samples across the forest, when aggregated as a graph, accurately reflect the model's global decision boundaries.

### Mechanism 2
The Inlier-Outlier Propagation Score (IOP-Score) offers a quantitative proxy for a feature's discriminative power in anomaly detection. IOP-Score calculates the difference between the frequency of transitions to "Inlier" vs. "Outlier" classes from a given node, normalized by total incoming frequency. Scores near -1 imply a predicate is used almost exclusively for isolating outliers; +1 implies inliers. The core assumption is that the ratio of transition frequencies is a meaningful metric for "importance" or "contribution" to a class label.

### Mechanism 3
Class-based frequency weighting corrects for dataset imbalance, preventing inlier paths from obscuring outlier logic in the graph. The method assigns weights to edge frequencies based on sample class, with outlier transitions weighted by (No + Ni)/No and inliers by (No + Ni)/Ni. This amplifies the signal from the minority outlier class. The core assumption is that without this adjustment, the high volume of inlier samples would dominate the edge frequencies, making outlier-specific decision paths invisible.

## Foundational Learning

- **Concept:** Isolation Forest (iForest) Fundamentals
  - **Why needed here:** This is a model-specific XAI method. You must understand that iForest isolates anomalies via random splits, where shorter path lengths indicate outliers, to interpret why the DPG highlights certain paths.
  - **Quick check question:** Does a data point requiring fewer splits (shorter path) to reach a leaf node indicate an inlier or an outlier in iForest? (Answer: Outlier).

- **Concept:** Post-hoc Global Explainability
  - **Why needed here:** The method is a "post-hoc" explanation applied after training. Distinguishing "global" (overall model logic) from "local" (single prediction) explanation is critical for evaluating the output.
  - **Quick check question:** Is this method designed to explain a single prediction for one patient, or the general rules the model uses across all patients? (Answer: Global rules).

- **Concept:** Directed Acyclic Graphs (DAGs)
  - **Why needed here:** The output is a graph structure. Understanding that nodes represent conditions (predicates) and directed edges represent sequential flow is required to read the visual explanation.
  - **Quick check question:** In this graph, what does a thick directed edge from Node A to Node B signify? (Answer: High frequency of samples satisfying predicate A and then immediately satisfying predicate B).

## Architecture Onboarding

- **Component map:** Trained iForest model + Training/Validation Dataset -> Traversal Engine (extracts predicates and records traversal lists) -> Graph Builder (filters lists, abstracts predicates, builds weighted directed graph) -> Scorer (computes IOP-Score) -> Visual DPG & IOP-Score ranking table

- **Critical path:** The **Traversal and Weighting** step. If the traversal does not correctly label paths as "Outlier" or "Inlier" based on the iForest's own scoring, or if the class-based weighting logic is flawed, the resulting graph will be a meaningless aggregate of noise.

- **Design tradeoffs:**
  - **Abstraction vs. Precision:** The method abstracts predicates to (feature, sign) and drops the split value, trading numerical precision for structural generality.
  - **Scalability:** The authors note that constructing graphs for large-scale models is memory-intensive, with complexity scaling with the number of unique predicates.

- **Failure signatures:**
  - **Indistinguishable Graph:** If IOP-Scores for all nodes hover near 0, the model may have failed to isolate clear anomalies, or the weighting mechanism is insufficient.
  - **Over-complexity:** On high-dimensional data, the graph may become a "hairball" that is theoretically global but visually unintelligible.

- **First 3 experiments:**
  1. **Sanity Check (Synthetic):** Train iForest on a dataset with known, strong anomalies. Verify that the DPG highlights these features with negative IOP-Scores.
  2. **Imbalance Stress Test:** Apply to a dataset with extreme class imbalance (<1% outliers). Compare the generated graph with and without class-based weighting enabled.
  3. **Scalability Profiling:** Incrementally increase the number of trees (100, 500, 1000) and features in the iForest. Monitor memory usage and graph generation time.

## Open Questions the Paper Calls Out
None

## Limitations
- The method's ability to provide global explanations relies on aggregating sparse tree structures without explicit validation of path correctness.
- The IOP-Score metric lacks comparison with established feature importance methods and its sensitivity to class imbalance extremes is untested.
- The class-weighting approach is theoretically sound but unverified on datasets with varying imbalance ratios.

## Confidence
- DPG mechanism: Medium (relies on aggregating sparse tree structures without explicit validation)
- IOP-Score metric: Low (untested sensitivity to class imbalance extremes, no comparison with established methods)
- Class-weighting approach: Medium (theoretically sound but unverified on varying imbalance ratios)

## Next Checks
1. **Mechanism Validation:** Test the DPG extraction on a controlled synthetic dataset where the isolation logic is known, verifying that the graph correctly identifies the manipulated features.

2. **Metric Robustness:** Evaluate the IOP-Score's stability across different contamination levels and compare its rankings against SHAP or permutation importance for iForest.

3. **Scalability Assessment:** Profile the method's performance on incrementally larger datasets and iForest models to identify memory and computational bottlenecks for practical deployment.