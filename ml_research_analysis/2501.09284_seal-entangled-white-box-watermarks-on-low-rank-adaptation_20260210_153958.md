---
ver: rpa2
title: 'SEAL: Entangled White-box Watermarks on Low-Rank Adaptation'
arxiv_id: '2501.09284'
source_url: https://arxiv.org/abs/2501.09284
tags:
- seal
- lora
- passport
- weights
- adaptation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces SEAL, a universal white-box watermarking\
  \ technique for protecting LoRA weights. SEAL embeds a non-trainable passport matrix\
  \ between LoRA\u2019s trainable parameters, entangling it during training without\
  \ extra loss terms."
---

# SEAL: Entangled White-box Watermarks on Low-Rank Adaptation

## Quick Facts
- **arXiv ID:** 2501.09284
- **Source URL:** https://arxiv.org/abs/2501.09284
- **Reference count:** 40
- **Primary result:** Introduces SEAL, a universal white-box watermarking technique for LoRA weights that matches or exceeds standard LoRA performance while remaining robust to removal, obfuscation, and ambiguity attacks.

## Executive Summary
SEAL is a white-box watermarking technique that protects LoRA weights by embedding a non-trainable passport matrix C between the LoRA matrices B and A during training. The passport becomes functionally entangled with the weights through gradient flow, making it difficult to remove without degrading performance. After training, the passport is structurally hidden by decomposing it into the LoRA weights, preserving standard LoRA structure. Experiments demonstrate SEAL's effectiveness across commonsense reasoning, instruction tuning, and text-to-image synthesis tasks, with robustness against various attack vectors.

## Method Summary
SEAL embeds a non-trainable passport matrix C between LoRA's trainable matrices B and A, creating an entangled forward pass ΔW = BCA. During training, C randomly alternates with a second passport Cp per batch, forcing the weights to entangle with both. After training, C is decomposed via SVD into C₁ and C₂ and absorbed into B and A to create public weights B' = BC₁ and A' = C₂A. Verification uses pseudo-inverse extraction to recover C and computes a fidelity gap to confirm ownership. The method achieves structural stealth while maintaining standard LoRA functionality.

## Key Results
- SEAL matches or exceeds standard LoRA performance across commonsense reasoning, instruction tuning, and text-to-image synthesis tasks
- Passport remains detectable after weight decomposition and merging into standard LoRA structure
- Robust to removal, obfuscation, and ambiguity attacks even under severe adversarial conditions
- Dual-passport verification creates verifiable signature where only legitimate passports maintain performance across switching

## Why This Works (Mechanism)

### Mechanism 1: Gradient-Mediated Passport Entanglement
Inserting non-trainable matrix C between trainable B and A forces learned parameters to depend on C during gradient descent. Gradients transform as ∂L/∂A = C^T B^T ∂φ/∂Δ and ∂L/∂B = ∂φ/∂Δ A^T C^T, creating functional dependency. Core assumption: Full-rank B and A are necessary for unique passport extraction. Evidence: Section 3.3 explicitly shows C modifies gradient flow and appendix B.2 provides mathematical formulations. Break condition: Rank deficiency in B or A weakens entanglement.

### Mechanism 2: Structural Concealment via Matrix Factorization
Passport C is hidden within LoRA structure by decomposing C = C₁C₂ and absorbing into B and A. After training, public weights become B' = BC₁ and A' = C₂A, which are structurally identical to standard LoRA while preserving B'A' = BCA. Core assumption: Decomposition function f must satisfy C₁C₂ = C exactly. Evidence: Section 3.4 formalizes decomposition requirements and figure 1 shows the pipeline. Break condition: Structured C may leave detectable patterns in B'A'.

### Mechanism 3: Dual-Passport Fidelity Verification
Training with two passports (C, Cp) that alternate randomly creates verifiable signature. Only legitimate owner can demonstrate near-zero fidelity gap ε_T = |M_T(N(B,A,C)) - M_T(N(B,A,Cp))|. Adversaries forging passports without co-training cannot achieve this. Core assumption: Adversaries cannot access original training data. Evidence: Section 3.6.2 defines fidelity gap and table 5 shows empirical thresholds. Break condition: Insensitive task metrics or overfitting to single passport fails verification.

## Foundational Learning

- **Concept:** Low-Rank Matrix Factorization (LoRA fundamentals)
  - **Why needed here:** SEAL modifies ΔW = BA to ΔW = BCA, requiring understanding of rank constraints and third matrix insertion
  - **Quick check question:** Given W ∈ R^(1024×768) and rank r=32, what are shapes of A and B, and why does this reduce parameters from 786K to ~58K?

- **Concept:** Gradient Flow Through Composite Matrix Products
  - **Why needed here:** Entanglement relies on how gradients propagate through ΔW = BCA
  - **Quick check question:** If ∂L/∂Δ is gradient w.r.t. adaptation output, compute ∂L/∂B when Δ = BCA. How does non-diagonal C change this vs diagonal C?

- **Concept:** DNN Watermarking Threat Model
  - **Why needed here:** SEAL designed against three attack categories; understanding adversary capabilities is essential
  - **Quick check question:** An adversary has B' and A' but not original dataset. Why does this constraint matter for ambiguity attacks specifically?

## Architecture Onboarding

- **Component map:** B(b×r) → C(r×r) → A(r×a), B' = BC₁, A' = C₂A
- **Critical path:**
  1. Initialize B, A randomly; C, Cp from N(0,1)
  2. Training loop: random C/Cp selection per batch, compute W' = W + BCA or W' = W + BCpA
  3. Post-training: decompose C via SVD, set B' = BC₁, A' = C₂A
  4. Distribution: release (B', A') as standard LoRA weights
  5. Verification: submit (B, A, C, Cp); verifier checks reconstruction and fidelity gap

- **Design tradeoffs:**
  - std(C) magnitude: Low std (0.01) creates stronger entanglement but causes instability when C removed; high std (100) weakens entanglement
  - Number of passports: Two passports sufficient for ambiguity resistance; more increase verification complexity
  - Decomposition method: SVD default; other factorizations may be more efficient but could leave detectable patterns

- **Failure signatures:**
  - Rank collapse: Trained B or A become rank < r, pseudo-inverse extraction fails
  - Fidelity gap drift: Unexpectedly growing ε_T suggests training didn't achieve proper entanglement
  - Reconstruction mismatch: B'A' ≠ BC₁C₂A indicates numerical instability in decomposition

- **First 3 experiments:**
  1. **Sanity check—fidelity preservation:** Train SEAL vs. standard LoRA on BoolQ subset; verify accuracy differs by <1%
  2. **Entanglement validation:** Compute outputs with W + BCA vs. W + BA (C removed); large differences confirm successful entanglement
  3. **Extraction test:** Apply Algorithm 2 on B'A' to recover C; compute reconstruction error ||C_extracted - C||_F

## Open Questions the Paper Calls Out

- **Question:** How does SEAL entanglement mechanism scale to foundation models significantly larger than tested (e.g., 70B+ parameters)?
  - **Basis:** Conclusion states future work will explore generalized forms for larger foundation models
  - **Why unresolved:** Experiments limited to models up to LLaMA-2-13B; unclear if entanglement remains robust at vastly different parameter scales
  - **Evidence needed:** Benchmarks on LLaMA-3-70B or Grok-1 showing passport remains detectable and performance preserved

- **Question:** Can passport embedding strategy adapt to non-multiplicative LoRA variants (Kronecker or Hadamard adapters) without losing structural stealth?
  - **Basis:** Appendix E discusses generalizing to bilinear operators but notes operator-specific designs need investigation
  - **Why unresolved:** Practical implementation and robustness of decomposing passports within Kronecker/Hadamard structures not validated
  - **Evidence needed:** Implementation for Kronecker-product adapter showing successful passport extraction and removal attack resistance

- **Question:** How does verification process fail if trained SEAL weights become rank-deficient, violating Assumption 3.3?
  - **Basis:** Section 3.5 relies on Assumption 3.3 (full rank B and A) for pseudo-inverse extraction
  - **Why unresolved:** Paper doesn't address scenarios where training results in rank deficiency
  - **Evidence needed:** Analysis of extraction success rates on intentionally regularized or pruned models, or theoretical proof of rank preservation

## Limitations
- **Initialization Ambiguity:** Exact initialization parameters for passport matrices C and Cp not explicitly specified, affecting reproducibility
- **Numerical Stability:** Verification relies on pseudo-inverse calculations that may become unstable if B or A matrices are ill-conditioned
- **Task-Specific Thresholds:** Fidelity gap threshold ε_T varies significantly across tasks (0.3 to 3.7), suggesting verification effectiveness is highly task-dependent

## Confidence

**High Confidence:** Core mechanism of gradient-mediated entanglement through matrix C is mathematically sound; structural concealment via SVD decomposition is well-established; dual-passport fidelity verification is theoretically robust against ambiguity attacks.

**Medium Confidence:** Experimental results showing SEAL matching or exceeding standard LoRA appear solid, but exact hyperparameter configurations for different model sizes are not fully detailed.

**Low Confidence:** Robustness claims against obfuscation attacks based on limited adversarial scenarios; paper doesn't comprehensively address advanced removal techniques like model pruning or quantization.

## Next Checks

1. **Initialization Sensitivity Test:** Reproduce baseline results using different standard deviations for C initialization (0.1, 1.0, 10.0) to determine sensitivity of entanglement strength and fidelity preservation

2. **Numerical Stability Analysis:** Implement error handling for pseudo-inverse calculations during verification; test extraction success rates when B or A matrices approach rank deficiency through controlled training conditions

3. **Adversarial Attack Benchmarking:** Systematically evaluate SEAL against advanced obfuscation techniques including structured pruning, quantization, and low-rank approximation of B' and A' to assess real-world robustness limits