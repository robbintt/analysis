---
ver: rpa2
title: 'Medical artificial intelligence toolbox (MAIT): an explainable machine learning
  framework for binary classification, survival modelling, and regression analyses'
arxiv_id: '2501.04547'
source_url: https://arxiv.org/abs/2501.04547
tags:
- mait
- data
- binary
- classification
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MAIT addresses the challenge of integrating machine learning techniques
  for medical research by providing an explainable, open-source Python pipeline for
  binary classification, regression, and survival analyses on tabular datasets. The
  framework addresses key challenges such as high dimensionality, class imbalance,
  mixed variable types, and missingness while promoting transparency aligned with
  TRIPOD+AI standards.
---

# Medical artificial intelligence toolbox (MAIT): an explainable machine learning framework for binary classification, survival modelling, and regression analyses

## Quick Facts
- arXiv ID: 2501.04547
- Source URL: https://arxiv.org/abs/2501.04547
- Reference count: 36
- Provides explainable ML pipeline for medical tabular data with binary classification, survival analysis, and regression

## Executive Summary
MAIT is an open-source Python framework that integrates machine learning techniques for medical research, addressing key challenges like high dimensionality, class imbalance, mixed variable types, and missingness. The framework provides two primary use cases: Discovery (feature importance via unified SHAP scoring) and Prediction (model development and deployment). Implemented as a monolithic Jupyter Notebook, MAIT supports both Linux and Windows systems while maintaining reproducibility and ease of customization.

## Method Summary
MAIT processes each dataset independently to avoid information leakage, using KNN imputation for continuous variables, one-hot encoding for categoricals, and mRMR feature selection on development data. The framework employs stratified k-fold cross-validation with multi-metric model selection (MCC, AUC, PR-AUC) to reduce selection bias, particularly for imbalanced medical outcomes. SHAP values provide unified feature importance across model types, while a novel translation mechanism converts survival model cumulative hazard curves to binary classifications for direct comparison between time-to-event and binary approaches.

## Key Results
- MAIT addresses high dimensionality, class imbalance, mixed variable types, and missingness through isolated preprocessing and stratified cross-validation
- Introduces novel techniques including fine-tuning of probability thresholds, translation of cumulative hazard curves to binary classification, and handling censoring through semi-supervised learning
- Supports both Discovery (feature importance) and Prediction (model development/deployment) use cases with optimized solutions

## Why This Works (Mechanism)

### Mechanism 1
Unified preprocessing with isolated data handling reduces information leakage while enabling compatibility across heterogeneous medical datasets. MAIT processes each dataset independently, applying KNN imputation for continuous variables, one-hot encoding for categoricals, and mRMR feature selection only on development data. The isolation prevents statistics from test sets influencing training transformations.

### Mechanism 2
Multi-metric model selection with stratified cross-validation reduces selection bias compared to single-metric approaches, particularly for imbalanced medical outcomes. Stratified k-fold CV preserves class proportions across folds. Model selection uses grand average of MCC, AUC, and PR-AUC rather than accuracy, which is sensitive to class imbalance.

### Mechanism 3
Translation of survival model outputs to binary classifications enables direct comparison between time-to-event and binary classification approaches on the same data. RSF generates cumulative hazard curves for each sample. Median curves are computed for event and event-free classes using non-censored training samples. Test samples are classified by Euclidean distance to these median curves.

## Foundational Learning

- **Stratified Cross-Validation**: MAIT relies on stratified CV for model comparison; understanding why stratification matters is essential for interpreting benchmarking reports. If your outcome has 15% positives, what proportion should each CV fold contain?
- **SHAP (SHapley Additive exPlanations) Values**: Core explainability mechanism; MAIT uses SHAP for unified feature importance across model types and for cluster-based subgroup discovery. If a feature has SHAP value +0.3 for a specific prediction, what does that mean relative to the baseline prediction?
- **Censoring in Survival Analysis**: MAIT's survival-to-binary translation and semi-supervised label propagation both handle censored observations; misunderstanding censoring leads to biased interpretations. A patient is censored at 6 months follow-up with no event recorded. What can and cannot be concluded about their outcome?

## Architecture Onboarding

- **Component map**: Pipeline Initiation Block -> Data Quality Block -> Preprocessing Block -> Model Training Block -> Interpretation Block -> Survival Extension Block -> Reporting Block
- **Critical path**: Configure metadata → Run data quality checks → Execute preprocessing → Run model comparison with CV → Generate SHAP explanations → Evaluate on test set → Export HTML report
- **Design tradeoffs**: Monolithic notebook vs. modular package (trades scalability for transparency); curated model set vs. exhaustive search (trades potential performance gains for computational cost); mRMR vs. other feature selection (trades accuracy for interpretability)
- **Failure signatures**: "Empty DataFrame after filtering" (overly aggressive missingness threshold); "SHAP computation timeout" (large feature sets without prior selection); "Calibration set too small" (insufficient samples for isotonic regression); "All predictions same class" (probability threshold optimization failed)
- **First 3 experiments**: 1) Run Wisconsin Breast Cancer tutorial end-to-end with default settings; 2) Modify dementia tutorial to enable probability threshold optimization; 3) Run both binary classification and survival modules on time-to-event dataset and compare feature importance rankings

## Open Questions the Paper Calls Out

### Open Question 1
How can the MAIT framework be effectively extended to support multi-class classification tasks? The pipeline currently only supports binary outcomes, whereas many medical diagnosis tasks involve differentiating between multiple disease categories. Evidence would be a software extension implementing "one-vs-rest" or multinomial strategies within the MAIT pipeline, validated on a multi-class medical dataset.

### Open Question 2
Does the absence of deep learning algorithms in MAIT result in lower predictive performance for specific high-dimensional medical datasets? While MAIT prioritizes explainable tree-based models, it remains untested whether deep learning approaches would yield superior accuracy within this specific framework. Evidence would be a benchmarking study comparing MAIT's ensemble performance against integrated deep learning architectures on complex tabular data.

### Open Question 3
At what data volume does the monolithic notebook architecture of MAIT become computationally inefficient compared to modular pipelines? The single-notebook design provides reproducible workflow "at the cost of complex scalability as it grows." Evidence would be runtime and memory usage analysis of MAIT processing datasets with millions of observations compared to distributed or modular pipeline implementations.

## Limitations
- Monolithic notebook design creates scalability constraints for datasets exceeding 10,000 samples or 500 features
- Adaptive hyperparameter tuning mechanism lacks transparent documentation of search space boundaries and convergence criteria
- Feature selection via mRMR assumes linear relevance-redundancy relationships that may not capture complex interactions in high-dimensional medical data

## Confidence
- **High Confidence**: Preprocessing isolation mechanism and multi-metric model selection approach are well-supported by established ML practices
- **Medium Confidence**: SHAP-based unified scoring and survival-to-binary translation methods are novel but lack extensive external validation
- **Low Confidence**: The specific hyperparameter tuning ranges and their adaptive rules across different algorithms are underspecified

## Next Checks
1. Benchmark MAIT's survival-to-binary translation against standard survival analysis metrics on time-to-event datasets with known ground truth
2. Test the preprocessing pipeline on a high-dimensional dataset (>1000 features) to evaluate scalability and feature selection effectiveness
3. Validate the probability threshold optimization on multiple imbalanced datasets to assess generalizability across different class imbalance ratios