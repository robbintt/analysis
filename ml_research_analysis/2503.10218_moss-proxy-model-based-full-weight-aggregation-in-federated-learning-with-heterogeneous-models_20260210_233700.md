---
ver: rpa2
title: 'Moss: Proxy Model-based Full-Weight Aggregation in Federated Learning with
  Heterogeneous Models'
arxiv_id: '2503.10218'
source_url: https://arxiv.org/abs/2503.10218
tags:
- moss
- devices
- heterogeneous
- learning
- aggregation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of federated learning with heterogeneous
  models, where devices have varying computational capabilities and require different
  model architectures. Existing approaches rely on partial model aggregation, which
  leads to suboptimal accuracy and increased training overhead.
---

# Moss: Proxy Model-based Full-Weight Aggregation in Federated Learning with Heterogeneous Models

## Quick Facts
- arXiv ID: 2503.10218
- Source URL: https://arxiv.org/abs/2503.10218
- Reference count: 40
- Key result: Proxy-model-based full-weight aggregation significantly accelerates FL training, reducing energy consumption by 6.1× and on-device training time by 62.9%.

## Executive Summary
This paper addresses the challenge of federated learning with heterogeneous model architectures, where devices of varying computational capabilities require different model structures. Existing approaches rely on partial model aggregation, leading to suboptimal accuracy and increased training overhead. Moss introduces a novel "full-weight aggregation" method that preserves comprehensive knowledge by aggregating all weights within heterogeneous models. The approach employs a proxy model-based framework where a homogeneous proxy model is constructed for each device model type, and meta-learning is used to establish weight-wise mapping relationships between proxies and devices. Additionally, Moss introduces a fidelity-guided aggregation algorithm to optimize the aggregation process and facilitate convergence. Experimental results across three real-world applications demonstrate significant improvements in training speed, accuracy, and resource efficiency compared to state-of-the-art baselines.

## Method Summary
Moss operates through a three-phase approach on the server side. First, the Proxy Model Construction (PROM) phase initializes homogeneous proxy models (typically using the largest device architecture) for each type of device model. Second, the Weight-wise Knowledge Transfer (WIRE) phase employs meta-learning to map weights between heterogeneous device models and their corresponding proxy models, using two meta-networks to determine transfer locations and degrees. Third, the Fidelity-guided Aggregation (FILE) phase calculates fidelity scores based on cosine similarity of output logits on a public dataset, then performs weighted aggregation of proxy models to produce a global proxy model. Finally, knowledge is transferred back from the global proxy to individual device models for deployment. This enables full-weight aggregation across incompatible architectures while preserving intermediate layer knowledge typically lost in distillation methods.

## Key Results
- Speeds up FL training process by up to 63.6 percentage points compared to state-of-the-art baselines
- Reduces on-device training time by 62.9% and energy consumption by 6.1×
- Enhances accuracy by up to 11.2 percentage points in heterogeneous model scenarios
- Minimizes network bandwidth utilization while maintaining full-weight aggregation benefits

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Replacing direct aggregation with homogeneous "Proxy Models" enables full-weight aggregation across incompatible architectures, preserving granular knowledge lost in distillation methods.
- **Mechanism:** Moss decouples aggregation from specific device architectures by constructing homogeneous proxy models for each device type. Knowledge transfers from heterogeneous device models to these proxies, enabling layer-by-layer full-weight aggregation since all proxies share the same architecture.
- **Core assumption:** Intermediate layers contain task-critical knowledge that distillation methods discard, and this knowledge can be encoded into standardized proxy architectures without significant loss.
- **Evidence anchors:** [abstract] Mentions aggregating "all weights within heterogeneous models to preserve comprehensive knowledge"; [Section 3.3] Details Proxy Model Construction and rationale for selecting largest model architecture as proxy; [Section 2.2.2] Argues distillation methods "overlook the knowledge in the intermediate layers."
- **Break condition:** If the proxy architecture is insufficiently expressive to capture feature spaces of all heterogeneous device models simultaneously, knowledge transfer will degrade into lossy compression.

### Mechanism 2
- **Claim:** Meta-learning automates structural alignment of weights between non-identical architectures, identifying "where" and "how much" to transfer.
- **Mechanism:** WIRE uses two meta-networks (T_L for Transfer Location, T_D for Transfer Degree) to learn probability mappings between layers and channel-wise weights for transfer, effectively "stretching" or "compressing" device model knowledge into proxy shape.
- **Core assumption:** Learnable functional mapping exists between weight spaces of different architectures performing the same task, approximable using a small shared public dataset.
- **Evidence anchors:** [Section 3.4] Describes WIRE component and dual meta-network architecture; [Figure 3] Visualizes "Transfer Location" and "Transfer Degree" mapping; [corpus] FedADP explores similar unified aggregation, suggesting cross-architecture alignment is critical.
- **Break condition:** If public dataset distribution differs significantly from private data, learned meta-mappings may fail to generalize, causing negative transfer that harms model performance.

### Mechanism 3
- **Claim:** Fidelity-weighted aggregation optimizes convergence by prioritizing proxy models that best represent their original device models.
- **Mechanism:** FILE calculates fidelity scores measuring cosine similarity between proxy output logits and original model logits on public dataset. During aggregation, higher fidelity proxies receive higher weights, ensuring global model leans on high-quality, well-transferred local updates.
- **Core assumption:** High cosine similarity in logit space on public data reliably proxies quality of internal weight-space representation transfer.
- **Evidence anchors:** [Section 3.5] Defines fidelity score and aggregation equation; [Section 4.8.3] Shows removing FILE increases convergence time and reduces accuracy; [corpus] "Who to Trust?" emphasizes assessing client reliability during aggregation.
- **Break condition:** If device models are overfitted to local data (non-IID), low fidelity score might unfairly penalize valid local updates simply because they diverge from global/public data pattern.

## Foundational Learning

- **Concept:** **Federated Learning with Heterogeneous Models (HeteroFL)**
  - **Why needed here:** Standard FL (FedAvg) assumes identical architectures. This paper attacks harder problem where devices (smart TV vs flagship phone) run vastly different model sizes.
  - **Quick check question:** Can you explain why you cannot simply average weights of ResNet-18 and MobileNetV2?

- **Concept:** **Knowledge Distillation vs. Full-Weight Aggregation**
  - **Why needed here:** Moss positions against distillation methods (transferring "soft labels" via outputs). Understand Moss claims superiority by transferring *weights* (internal features) rather than just *outputs* (class probabilities).
  - **Quick check question:** Why might transferring output probabilities of a model result in "lossy" representation compared to transferring its learned filters?

- **Concept:** **Meta-Learning (Learn-to-Learn)**
  - **Why needed here:** WIRE core relies on meta-learning to find mappings between layers. It learns *how* to transfer knowledge generally, rather than hard-coding rules for specific architectures.
  - **Quick check question:** In context of WIRE, what is meta-network actually trying to learn? (Hint: Is it the task, or the relationship between model layers?)

## Architecture Onboarding

- **Component map:** Local Training -> FedAvg (per device type) -> WIRE (Knowledge Transfer) -> FILE (Aggregation) -> WIRE (Reverse Transfer) -> Deployment
- **Critical path:** WIRE component is bottleneck. If meta-learning phase fails to converge or public dataset is unrepresentative, proxy models will be noisy and fidelity scores (FILE) meaningless.
- **Design tradeoffs:**
  - **Proxy Capacity:** Selects *largest* device model as proxy. Assumption: Prevents information bottlenecks. Tradeoff: Higher server-side computational cost for largest model.
  - **Public Dataset Size:** Claims robustness with small public datasets (25% of standard size). Assumption: Meta-networks generalize quickly. Tradeoff: Small dataset may fail to capture mapping diversity if domain shifts.
  - **Communication:** Transmits full model weights (like FedAvg), unlike distillation methods transmitting only logits. Tradeoff: Higher bandwidth per round, but potentially fewer rounds to convergence.
- **Failure signatures:**
  - **Negative Transfer:** Small models significantly degrade large model accuracy after aggregation, implying WIRE mappings are hallucinating connections.
  - **Stagnating Fidelity:** Fidelity scores don't improve over rounds, suggesting proxy model cannot assimilate knowledge from specific device types.
  - **Large Model Dominance:** If fidelity weighting fails, largest model might overwhelm smaller models, causing small device accuracy to collapse.
- **First 3 experiments:**
  1. **Ablation on Public Data:** Run Moss with public dataset from completely different domain (use CIFAR-100 for speech task). Verify "unrelated dataset" robustness claims in Section 4.9.1.
  2. **Heterogeneity Stress Test:** Simulate scenario with *extreme* structural differences (CNN vs MLP) to see if "layer-to-layer" meta-learning in WIRE breaks down.
  3. **Fidelity Analysis:** Plot Fidelity scores vs Local Accuracy. Validate core assumption that high fidelity on public dataset actually correlates with high local performance on private data.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does computational overhead on server scale as number of unique device model architectures (N) increases, given WIRE requires training meta-networks for each distinct architecture?
- **Basis in paper:** [inferred] Section 3.3 states Moss reduces complexity from n² to 2n, but Section 3.4 describes WIRE as meta-learning process involving training specific networks for every layer pair of every architecture type.
- **Why unresolved:** Evaluation limits N to 3 (Large, Medium, Small). Real-world scenarios might involve dozens of customized architectures, potentially creating computational bottleneck on server during meta-learning phase.
- **What evidence would resolve it:** Empirical or theoretical analysis of server-side training time and memory usage as number of heterogeneous architectures increases from 3 to 50+.

### Open Question 2
- **Question:** Can Moss maintain performance in completely data-free setting where server has no access to any public dataset (related or unrelated) to facilitate knowledge transfer mapping?
- **Basis in paper:** [inferred] Section 3.3 assumes availability of shared public dataset on server-side. Section 4.9.1 demonstrates robustness with "unrelated" datasets, but method still relies on data to calculate feature maps for meta-networks in Equation 4.
- **Why unresolved:** In privacy-sensitive domains (specialized medical imaging), finding even generic public dataset providing valid feature distributions for mapping might be impossible.
- **What evidence would resolve it:** Experiments showing WIRE convergence using synthetic data or purely statistical methods (batch norm statistics) instead of real public dataset.

### Open Question 3
- **Question:** Does WIRE effectively transfer knowledge between models of fundamentally different architectural paradigms (e.g., from CNN-based device model to RNN/Transformer-based device model)?
- **Basis in paper:** [inferred] Section 4.1.2 and 4.1.3 utilize specific models (ResNet, MobileNet, LeNet) which are all primarily CNNs. Section 3.4 defines mappings based on "layer-to-layer" and "neuron-to-neuron" correspondences which assumes structural similarity.
- **Why unresolved:** "Layer-to-layer" mapping logic of WIRE may fail or become ambiguous when architectures differ drastically in topology (CNN-to-Transformer was not tested).
- **What evidence would resolve it:** Evaluation results including heterogeneous architectures with different inductive biases, such as mixing CNNs, LSTMs, or ViTs within same FL system.

## Limitations
- **Scalability concerns:** Computational overhead of meta-learning phase may become prohibitive as number of heterogeneous architectures increases beyond the tested 3 models.
- **Public dataset dependency:** Performance relies on availability of even a small public dataset for meta-learning mappings, which may not be feasible in highly privacy-sensitive domains.
- **Architectural gap limitations:** Current formulation focuses on CNNs; effectiveness with fundamentally different architectural paradigms (RNNs, Transformers) remains unverified.

## Confidence

- **High Confidence:** Problem definition (FL with heterogeneous models) is well-articulated, overall framework (PROM + WIRE + FILE) is logically sound, and fidelity-guided aggregation is straightforward improvement over standard FedAvg.
- **Medium Confidence:** Experimental results are compelling showing significant improvements in accuracy and training efficiency, but comparisons primarily against distillation-based baselines with limited comparison to other full-weight aggregation methods.
- **Low Confidence:** Specific architectural details of meta-networks (T_L, T_D) are underspecified, making exact reproduction challenging, and claim of robustness to "unrelated" public datasets is intriguing but lacks rigorous empirical support.

## Next Checks
1. **Domain Robustness Test:** Reproduce main experiment (CIFAR-10) but use public dataset from completely different domain (e.g., subset of ImageNet for speech task) to rigorously test "unrelated dataset" claim.
2. **Architectural Gap Stress Test:** Create extreme heterogeneity scenario (CNN vs fully-connected MLP) to test limits of WIRE component's meta-learning mappings.
3. **Fidelity Correlation Analysis:** Plot fidelity scores against actual local test accuracy on private data for each client over multiple rounds to validate whether fidelity score is reliable proxy for knowledge transfer quality.