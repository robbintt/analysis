---
ver: rpa2
title: 'Redefining Machine Simultaneous Interpretation: From Incremental Translation
  to Human-Like Strategies'
arxiv_id: '2509.21801'
source_url: https://arxiv.org/abs/2509.21801
tags:
- translation
- sentence
- latency
- action
- read
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes a decoder-only SiMT framework that enriches\
  \ the traditional READ/WRITE action space with four adaptive actions\u2014SENTENCECUT,\
  \ DROP, PARTIALSUMMARIZATION, and PRONOMINALIZATION\u2014to emulate human interpreter\
  \ strategies for balancing translation quality and latency. These actions enable\
  \ real-time sentence restructuring, omission, and simplification while preserving\
  \ semantic fidelity."
---

# Redefining Machine Simultaneous Interpretation: From Incremental Translation to Human-Like Strategies

## Quick Facts
- **arXiv ID:** 2509.21801
- **Source URL:** https://arxiv.org/abs/2509.21801
- **Reference count:** 40
- **Primary result:** Proposed decoder-only SiMT framework with adaptive actions (SENTENCE_CUT, DROP, PARTIAL_SUMMARIZATION, PRONOMINALIZATION) improves semantic fidelity (COMET-KIWI) and reduces latency (Average Lagging) on ACL60/60 benchmarks.

## Executive Summary
This paper introduces a decoder-only simultaneous machine translation (SiMT) framework that emulates human interpreter strategies by enriching the traditional READ/WRITE action space with four adaptive actions. These actions enable real-time sentence restructuring, omission, and simplification while preserving semantic fidelity. The framework uses action-aware prompting for training references and a latency-aware TTS pipeline to simulate realistic timing. Experiments demonstrate that combining DROP and SENTENCE_CUT actions yields the best trade-off between translation quality and latency, effectively bridging the gap between human and machine simultaneous interpretation.

## Method Summary
The paper proposes a decoder-only SiMT framework that incorporates four adaptive actions—SENTENCE_CUT, DROP, PARTIAL_SUMMARIZATION, and PRONOMINALIZATION—to emulate human interpreter strategies. These actions allow the model to dynamically restructure, omit, or simplify translations in real-time. Training references are constructed using action-aware prompting, and a latency-aware TTS pipeline simulates realistic timing. The framework is evaluated on ACL60/60 English-Chinese and English-German benchmarks, demonstrating improved semantic fidelity (COMET-KIWI) and reduced Average Lagging compared to salami-based baselines.

## Key Results
- The proposed framework improves semantic fidelity (COMET-KIWI) on ACL60/60 benchmarks.
- Average Lagging is reduced compared to salami-based baselines.
- Combining DROP and SENTENCE_CUT actions yields the best trade-off between translation quality and latency.

## Why This Works (Mechanism)
The framework works by enriching the LLM action space with adaptive actions that emulate human interpreter strategies. These actions enable dynamic translation restructuring, omission, and simplification, which balance latency and quality. The action-aware prompting and latency-aware TTS pipeline provide realistic timing and reference construction, allowing the model to effectively bridge the gap between human and machine simultaneous interpretation.

## Foundational Learning

### Action Space in SiMT
- **Why needed:** To enable real-time translation adjustments based on context and latency constraints.
- **Quick check:** Ensure the action space includes operations like SENTENCE_CUT, DROP, PARTIAL_SUMMARIZATION, and PRONOMINALIZATION.

### Latency-Aware TTS Pipeline
- **Why needed:** To simulate realistic timing for training and evaluation.
- **Quick check:** Verify that the TTS pipeline accounts for pauses, speaker interruptions, and other real-world conditions.

### Action-Aware Prompting
- **Why needed:** To construct training references that guide the model in using adaptive actions effectively.
- **Quick check:** Ensure prompts include clear instructions for when to apply each adaptive action.

## Architecture Onboarding

### Component Map
- **Decoder-only SiMT framework** -> **Adaptive actions (SENTENCE_CUT, DROP, PARTIAL_SUMMARIZATION, PRONOMINALIZATION)** -> **Latency-aware TTS pipeline** -> **Action-aware prompting** -> **Training and evaluation**

### Critical Path
1. Input text is processed by the decoder-only SiMT framework.
2. Adaptive actions are applied based on context and latency constraints.
3. The latency-aware TTS pipeline simulates realistic timing.
4. Action-aware prompting guides the model during training.
5. The model is evaluated on ACL60/60 benchmarks.

### Design Tradeoffs
- **Flexibility vs. Complexity:** Enriching the action space increases flexibility but may complicate training and inference.
- **Latency vs. Quality:** Adaptive actions aim to balance latency and translation quality, but aggressive actions (e.g., DROP) may reduce quality.
- **Generalizability vs. Specialization:** The framework is optimized for specific language pairs and domains, which may limit its generalizability.

### Failure Signatures
- **Over-reliance on adaptive actions:** Excessive use of actions like DROP may lead to loss of important information.
- **Latency underestimation:** The TTS pipeline may not accurately simulate real-world timing, leading to suboptimal latency estimates.
- **Training instability:** Action-aware prompting may introduce noise, causing instability during training.

### First Experiments
1. Evaluate the framework on additional language pairs (e.g., English-French, English-Spanish) to assess generalizability.
2. Conduct human preference studies to validate the subjective quality of translations and their alignment with human interpreter strategies.
3. Quantify the computational overhead (e.g., inference time, memory usage) introduced by the enriched action space and latency-aware TTS pipeline.

## Open Questions the Paper Calls Out
None

## Limitations
- The framework is evaluated only on English-Chinese and English-German language pairs; performance on other language pairs or domains (e.g., technical, legal) is unknown.
- The study focuses on COMET-KIWI and Average Lagging; other metrics (e.g., human preference studies, error propagation) are not explored.
- The latency-aware TTS pipeline and enriched action space may increase inference time, which is not quantified.

## Confidence

### High Confidence
- The framework’s ability to improve semantic fidelity (COMET-KIWI) and reduce latency (Average Lagging) on ACL60/60 benchmarks.

### Medium Confidence
- The effectiveness of the four adaptive actions in emulating human interpreter strategies, as validated on two language pairs.

### Low Confidence
- The generalizability of the approach to other language pairs, domains, and real-world conditions.

## Next Checks
1. Evaluate the framework on additional language pairs (e.g., English-French, English-Spanish) and domains (e.g., medical, legal) to assess generalizability.
2. Conduct human preference studies to validate the subjective quality of translations and their alignment with human interpreter strategies.
3. Quantify the computational overhead (e.g., inference time, memory usage) introduced by the enriched action space and latency-aware TTS pipeline.