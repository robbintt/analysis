---
ver: rpa2
title: 'OmniCellTOSG: The First Cell Text-Omic Signaling Graphs Dataset for Joint
  LLM and GNN Modeling'
arxiv_id: '2504.02148'
source_url: https://arxiv.org/abs/2504.02148
tags:
- cell
- disease
- signaling
- brain
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces OmniCellTOSG, the first large-scale dataset
  of Text-Omic Signaling Graphs (TOSGs) designed to unify human-readable biomedical
  knowledge with single-cell transcriptomic data for signaling network analysis. Each
  TOSG represents an individual or meta-cell's signaling network, annotated with organ,
  disease, sex, age, and cell subtype information.
---

# OmniCellTOSG: The First Cell Text-Omic Signaling Graphs Dataset for Joint LLM and GNN Modeling

## Quick Facts
- **arXiv ID**: 2504.02148
- **Source URL**: https://arxiv.org/abs/2504.02148
- **Reference count**: 40
- **Primary result**: OmniCellTOSG is the first large-scale dataset of Text-Omic Signaling Graphs (TOSGs), integrating textual biomedical knowledge with single-cell transcriptomics for joint LLM and GNN modeling.

## Executive Summary
OmniCellTOSG introduces a novel dataset and modeling framework that unifies human-readable biomedical knowledge with single-cell transcriptomic data for signaling network analysis. The dataset comprises ~0.5 million meta-cell TOSGs derived from ~80 million single-cell RNA-seq profiles, annotated with tissue, disease, sex, age, and cell subtype information. The authors develop CellTOSG-FM, a multimodal graph language foundation model that integrates textual priors, omic data, and signaling network topology, achieving state-of-the-art performance on cell-type annotation and disease classification tasks while providing interpretable insights into disease-associated signaling pathways.

## Method Summary
The approach combines textual biomedical knowledge with single-cell transcriptomic data through a multimodal graph neural network. Text encoders (BERT/ProtGPT2) embed entity names, descriptions, and sequences; omic encoders map expression values to the same latent space; and cross-modality encoders fuse them into unified node representations. The model uses a two-stage message passing architecture (internal transcript-protein, then global PPI) and is pretrained with edge-masking self-supervision before fine-tuning on downstream tasks.

## Key Results
- CellTOSG-FM achieves 93.9% accuracy and 92.4% F1-score on LUAD cell-type annotation, outperforming baselines by 5.3% accuracy and 5.8% F1-score.
- For AD cell-type annotation, the model achieves 91.2% accuracy and 90.8% F1-score, surpassing baselines by 5.6% accuracy and 5.8% F1-score.
- CellTOSG-FM provides interpretable signaling subgraphs identifying disease-associated targets and pathways, with functional enrichment aligning with known disease biology.

## Why This Works (Mechanism)

### Mechanism 1
Integrating textual biological priors with numerical omic data through cross-modal encoders may improve representation quality for downstream tasks. A frozen text encoder embeds entity names, descriptions, and biochemical sequences; a trainable omic encoder maps expression values to the same latent space; a cross-modality encoder fuses them into unified node representations. This allows the model to leverage both semantic knowledge (e.g., protein function) and sample-specific variation.

### Mechanism 2
Two-stage graph message passing (internal then global) may better encode cellular signaling structure than single-stage propagation. Internal message passing aggregates within transcript-protein pairs at the nucleus level; global message passing diffuses information across the cell via the protein-protein interaction topology. This mirrors biological signaling flow from transcription to protein interaction.

### Mechanism 3
Edge-masking self-supervised pretraining may improve structure-sensitive downstream performance by forcing the model to reconstruct signaling topology. Randomly mask a subset of PPI edges, then train the model to reconstruct masked edges and predict node degrees. The reconstruction objective aligns embeddings with global signaling structure; degree regularization calibrates hub-periphery structure.

## Foundational Learning

- **Single-cell RNA-seq and meta-cell aggregation**: Aggregation preserves biological diversity while reducing noise by grouping similar cells into meta-cells via archetypal analysis (SEACells). This reduces technical variability while maintaining cell-type-specific signals.
  - Quick check: Can you explain why aggregating cells into meta-cells might reduce technical noise while preserving cell-type-specific signals?

- **Graph neural networks and message passing**: The model uses GNN layers for both internal (transcript-protein) and global (PPI) message propagation. Understanding how information flows through graph topology is key to interpreting the architecture.
  - Quick check: How does message passing differ between a simple GCN layer and the two-stage approach (internal then global) used here?

- **Foundation models and self-supervised pretraining**: CellTOSG-FM is pretrained on a subset of TOSGs using edge masking, then fine-tuned for downstream tasks. The rationale for pretraining-then-fine-tuning vs. training from scratch is central to the approach.
  - Quick check: What does the edge reconstruction objective incentivize the model to learn during pretraining?

## Architecture Onboarding

- **Component map**: Data layer (OmniCellTOSG dataset, CellTOSG_Loader) → Encoders (frozen text, trainable omic, cross-modality) → Graph encoder (internal message passing → global message passing) → Decoders (pretraining: edge reconstruction/degree; downstream: classification/inference) → Interpretability (attention-based importance scores, subgraph extraction)

- **Critical path**: 
  1. Define query conditions (tissue, disease, etc.) via CellTOSG_Loader
  2. Loader retrieves matching cells, balances cohorts, applies optional batch correction
  3. Encode nodes via text/omic/cross-modal encoders
  4. Run graph encoder (internal → global message passing)
  5. For downstream tasks: project to latent space Z(τ), apply task decoder
  6. For interpretability: extract attention-based edge weights, compute node importance, prune to core subgraph

- **Design tradeoffs**:
  - Frozen vs. trainable text encoders: Freezing reduces compute and overfitting but limits domain adaptation
  - Edge masking ratio (10⁻⁵): Very low ratio focuses reconstruction on structure; higher ratios may obscure topology
  - Meta-cell aggregation: Reduces noise and compute but may obscure rare cell states
  - PPI topology as signaling proxy: Static interactions may not reflect dynamic, context-specific signaling

- **Failure signatures**:
  - Poor edge reconstruction during pretraining (AUC << 0.85): Check edge masking ratio, learning rate, or graph connectivity
  - Downstream task underperformance vs. baselines: Verify data balancing, encoder alignment, or relevance of textual priors
  - Interpretability outputs incoherent: Check attention weight distributions, node importance score normalization, or pruning thresholds
  - Memory overflow on large queries: Use sample_ratio or shard-level loading in CellTOSG_Loader

- **First 3 experiments**:
  1. Reproduce cell type annotation on AD/LUAD cohorts: Use CellTOSG_Loader to retrieve balanced cohorts, run CellTOSG-FM fine-tuning, compare accuracy/F1 to baselines (scGPT, scFoundation, scCello)
  2. Ablate cross-modal fusion: Train a variant using only omic encoder (no text/sequence), compare downstream performance
  3. Interpret core signaling subgraph for LUAD: Extract attention-based node importance, prune to top-120 nodes, visualize subgraph and run functional enrichment

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the text provided.

## Limitations
- PPI network quality and completeness: The static PPI topology from BioMedGraphica is used as a proxy for dynamic cellular signaling, but may not capture context-specific or disease-altered interactions
- Cross-modal encoder architecture: Specifics of the cross-modality fusion step (layer counts, attention mechanisms) are not fully detailed
- Hyperparameter sensitivity: Key hyperparameters such as masking ratio, learning rates, batch sizes, and balancing strategies are not fully specified

## Confidence
- **High confidence**: Integration of textual and omic modalities improves downstream performance (supported by comparison to unimodal baselines)
- **Medium confidence**: Two-stage message passing architecture captures biologically relevant signaling structure (biologically motivated but not directly validated vs. single-stage)
- **Medium confidence**: Edge-masking pretraining aligns embeddings with signaling topology (indirectly supported by GraphMAE literature)

## Next Checks
1. Reproduce the LUAD cell-type annotation experiment: Use CellTOSG_Loader to retrieve balanced LUAD cohorts, run CellTOSG-FM fine-tuning, and compare accuracy/F1-score to reported results (93.9% / 92.4%)
2. Ablate cross-modal fusion: Train a variant using only the omic encoder (no text/sequence), and compare downstream performance
3. Interpret core signaling subgraph for LUAD: Extract top-120 nodes by attention-based importance, prune the graph, and run functional enrichment to validate biological plausibility against known LUAD pathways