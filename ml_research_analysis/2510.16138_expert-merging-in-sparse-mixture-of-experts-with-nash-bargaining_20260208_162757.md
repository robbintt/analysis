---
ver: rpa2
title: Expert Merging in Sparse Mixture of Experts with Nash Bargaining
arxiv_id: '2510.16138'
source_url: https://arxiv.org/abs/2510.16138
tags:
- expert
- namex
- experts
- layer
- merging
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of expert merging in Sparse Mixture
  of Experts (SMoE) models, where current approaches rely on heuristic averaging schemes
  that lack principled weighting mechanisms. The authors reinterpret expert merging
  through game theory, modeling it as a cooperative-competitive bargaining game among
  experts and introducing NAMEx, which uses Nash Bargaining to derive optimal merging
  coefficients based on expert contributions.
---

# Expert Merging in Sparse Mixture of Experts with Nash Bargaining

## Quick Facts
- arXiv ID: 2510.16138
- Source URL: https://arxiv.org/abs/2510.16138
- Reference count: 40
- One-line primary result: NAMEx achieves superior performance in expert merging for SMoE models by using Nash Bargaining to derive optimal merging coefficients, outperforming heuristic averaging methods across language modeling, text classification, and image classification tasks.

## Executive Summary
This paper addresses the problem of expert merging in Sparse Mixture of Experts (SMoE) models, where current approaches rely on heuristic averaging schemes that lack principled weighting mechanisms. The authors reinterpret expert merging through game theory, modeling it as a cooperative-competitive bargaining game among experts and introducing NAMEx, which uses Nash Bargaining to derive optimal merging coefficients based on expert contributions. They further enhance convergence by incorporating complex momentum into the merging process with theoretical convergence guarantees.

## Method Summary
The method reformulates expert merging as a Nash Bargaining problem where the utility of each expert is the alignment between the update direction and its domain vector. The solution maximizes the product of these utilities, solved via the system $G^\top G \alpha = 1/\alpha$. The framework automatically identifies and up-weights experts in adversarial relationships while cooperating experts receive reduced weights. Complex momentum is introduced to stabilize the propagation of base experts across layers, maintaining a complex buffer that accelerates convergence and dampens oscillations.

## Key Results
- On WikiText-103, NAMEx achieves validation/test perplexities of 82.44/34.25 compared to 83.53/35.69 for CAMEx
- On GLUE text classification, reaches 95.06/93.27/90.72/78.15 on SST-2, MRPC, STS-B, and RTE respectively
- On ImageNet-1k, achieves 84.52/98.11 top-1/top-5 accuracy
- Demonstrates strong scalability on large systems like Qwen1.5-MoE (14B) and DeepSeek-MoE (16B)

## Why This Works (Mechanism)

### Mechanism 1: Pareto-Optimal Merging via Nash Bargaining
- **Claim:** Treating expert merging as a cooperative game produces a merged expert that is Pareto-optimal, meaning no single expert's utility can be improved without degrading another's.
- **Mechanism:** Instead of simple weighted averaging, NAMEx solves a bargaining problem where the "utility" of an expert is the alignment between the update direction ($\Delta E$) and its domain vector ($\tau_i$). The solution maximizes the product of these utilities: $\prod (\Delta E^\top \tau_i)$, solved via the system $G^\top G \alpha = 1/\alpha$.
- **Core assumption:** The domain vectors $\tau_i$ (the deviation of an expert from the base) accurately represent the expert's contribution direction, and the interaction is purely cooperative-competitive based on these vectors.

### Mechanism 2: Dynamic Weighting of Adversarial Experts
- **Claim:** The framework automatically identifies and up-weights experts that are in "adversarial" (misaligned) relationships with peers to ensure their unique contributions are preserved.
- **Mechanism:** The coefficient $\alpha_j$ is influenced by the interaction term $\sum_{i \neq j} \alpha_i \tau_i^\top \tau_j$. If experts cooperate (positive alignment), $\alpha_j$ decreases. If they are adversarial (negative alignment), $\alpha_j$ increases to satisfy the bargaining equality (Eq. 10).
- **Core assumption:** Expert interactions vary significantly by layer and architecture (e.g., middle layers of Swin-MoE are cooperative, while Qwen-MoE shows complex dynamics).

### Mechanism 3: Complex Momentum for Stabilization
- **Claim:** Using complex-valued momentum buffers accelerates the propagation of the base expert across layers while dampening oscillations common in multi-objective games.
- **Mechanism:** NAMEx-Momentum maintains a complex buffer $\mu^{(j+1)} = \beta \mu^{(j)} + \Delta E^{(j)}$. The real part of the scaled buffer updates the parameters. This allows the phase of $\beta$ to control stability.
- **Core assumption:** The propagation of experts across layers behaves as a dynamical system where standard real-momentum ($\phi=0$) is suboptimal due to conflicting gradient directions.

## Foundational Learning

- **Concept: Nash Bargaining Solution (NBS)**
  - **Why needed here:** To understand how the paper transforms the geometric problem of "averaging vectors" into an economic problem of "maximizing joint utility." You must grasp that the solution is axiomatic (fairness) rather than purely geometric.
  - **Quick check question:** If two experts have completely opposing domain vectors (anti-parallel), does NBS average them to zero, or pick a winner? (Hint: Look at the utility product constraint).

- **Concept: Sparse Mixture of Experts (SMoE) Routing**
  - **Why needed here:** NAMEx modifies the *base expert* propagation, but operates within standard routing constraints. You need to distinguish between the router weights ($s_i$) and the Nash bargaining weights ($\alpha_i$).
  - **Quick check question:** How does the "domain vector" $\tau_i = E_i - E_m$ relate to the router's decision to activate expert $i$?

- **Concept: Spectral Radius and Stability**
  - **Why needed here:** To troubleshoot convergence issues when implementing NAMEx-Momentum.
  - **Quick check question:** Why does the paper claim that a complex momentum coefficient $\beta$ with a non-zero phase angle might stabilize training better than a real-valued $\beta$?

## Architecture Onboarding

- **Component map:**
  Base Expert ($E_m$) -> Domain Vectors ($\tau$) -> Nash Solver -> Momentum Buffer ($\mu$) -> Updated Base Expert

- **Critical path:**
  1. Calculate $\tau_i$ for all $N$ experts against $E_m$.
  2. Construct Matrix $G$ and solve for $\alpha$ (this is the compute bottleneck).
  3. Aggregate updates: $\Delta E = \sum \alpha_i \tau_i$.
  4. Update Momentum: $\mu \leftarrow \beta \mu + \Delta E$.
  5. Update Base: $E_m \leftarrow E_m + \Re(\gamma \mu)$.

- **Design tradeoffs:**
  - **NAMEx vs. NAMEx-Full:** Computing $\alpha$ at every layer (Full) is accurate but slower (Runtime: 4.70s vs 0.69s per batch). Computing once at layer 1 (NAMEx) is faster but ignores layer-wise interaction dynamics.
  - **Complex vs Real Momentum:** Complex momentum introduces hyperparameters ($\beta$ modulus and argument) that require tuning but provide better convergence stability.

- **Failure signatures:**
  - **Collapse to Average:** If interaction terms are ignored or $\alpha$ solves to uniform values, the method reduces to EP-CAMEx.
  - **Instability:** If step size $\gamma$ is too large or $\beta$ is poorly tuned, the complex buffer may explode or introduce noise, failing to converge (seen as spiking perplexity).

- **First 3 experiments:**
  1. **Toy Task Verification:** Implement the "Synthetic Example" (Section 5) with 3 experts. Visualize the utility trade-off to confirm the Nash solution lies on the Pareto frontier while averaging does not.
  2. **Ablation on Update Frequency:** Replicate Table 6 on a small WikiText-103 run. Compare $\Delta l \in \{1, 2, 5, L\}$ to find the optimal trade-off between compute cost and validation perplexity.
  3. **Momentum Phase Sweep:** Run NAMEx-Mom on GLUE RTE (sensitive task) sweeping the argument of $\beta$ (e.g., $-\pi/6$ to $\pi/6$) to verify the non-zero phase advantage shown in Table 5.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can NAMEx be efficiently extended to token-level momentum-based methods without prohibitive computational cost?
  - **Basis in paper:** [explicit] "While NAMEx could be extended to token-level momentum-based methods... the computational cost of solving the Nash equilibrium per token remains a challenge, leaving this as an avenue for future work."
  - **Why unresolved:** Solving the Nash system G⊤Gα = 1/α per token would multiply computational overhead by the sequence length, potentially negating SMoE's efficiency gains.
  - **What evidence would resolve it:** A method achieving token-level NAMEx with runtime overhead comparable to layer-wise variants while maintaining perplexity improvements on WikiText-103.

- **Open Question 2:** What are the optimal hyperparameter configurations (β values in quaternion space) for quaternion momentum, and can they be automated?
  - **Basis in paper:** [explicit] "While more complex and harder to tune, quaternion momentum can better stabilize high-dimensional optimization and handle rotations" with Table 7 showing NAMEx-Q outperforming NAMEx-Mom but requiring manual selection of β = 0.8+0.3i+0.3j+0.3k.
  - **Why unresolved:** The 4D parameter space for quaternion momentum lacks theoretical guidance for selection, requiring expensive empirical search.
  - **What evidence would resolve it:** A principled initialization scheme or adaptive algorithm achieving consistent improvements across GLUE tasks without per-task tuning.

- **Open Question 3:** How does the relationship between load balancing and observable cooperative/competitive dynamics affect NAMEx's effectiveness?
  - **Basis in paper:** [inferred] Figure 9 discussion notes that "without balanced token routing, some experts may be underused or even become inactive, which diminishes the emergence of meaningful cooperative or competitive behavior."
  - **Why unresolved:** The paper establishes that NAMEx relies on expert interaction dynamics, but doesn't quantify how load imbalance degrades Nash bargaining solutions.
  - **What evidence would resolve it:** Ablation studies varying load balancing loss strength and measuring correlation between expert utilization uniformity and NAMEx performance gains over baselines.

## Limitations
- The exact iterative solver algorithm for the Nash bargaining equation $G^\top G \alpha = 1/\alpha$ is not specified beyond a reference, creating potential implementation variability
- Specific architectural configurations for "Small" and "Medium" models (hidden sizes, layer counts) are not detailed, requiring reasonable assumptions
- Complex momentum hyperparameters ($\beta$ modulus and argument $\phi$) appear tuned per task, but the tuning process is not fully described

## Confidence
- **High Confidence:** The core mathematical framework of Nash Bargaining for expert merging is sound and well-defined. The performance claims on standard benchmarks (WikiText-103, GLUE, ImageNet-1k) are specific and verifiable.
- **Medium Confidence:** The scalability claims to large models (Qwen1.5-MoE 14B, DeepSeek-MoE 16B) are supported by tables but lack detail on training infrastructure and hyperparameter stability.
- **Low Confidence:** The theoretical guarantees for complex momentum convergence (Theorem B.3) are difficult to verify without access to the spectral radius analysis for specific architectures.

## Next Checks
1. **Solver Reproducibility:** Implement the Nash coefficient solver using multiple methods (e.g., Newton-Raphson, fixed-point iteration) and verify they converge to similar $\alpha$ values on the synthetic 3-expert example.
2. **Layer-wise Dynamics:** Replicate the ablation study on update frequency ($\Delta l \in \{1, 2, 5, L\}$) on a small WikiText-103 run to confirm the compute-accuracy tradeoff curve.
3. **Momentum Phase Sensitivity:** Systematically sweep the argument of $\beta$ (e.g., $-\pi/6$ to $\pi/6$) on GLUE RTE to empirically verify the non-zero phase advantage and identify optimal values.