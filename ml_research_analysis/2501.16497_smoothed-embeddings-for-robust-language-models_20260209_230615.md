---
ver: rpa2
title: Smoothed Embeddings for Robust Language Models
arxiv_id: '2501.16497'
source_url: https://arxiv.org/abs/2501.16497
tags:
- embedding
- attack
- defense
- utility
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the vulnerability of large language models
  (LLMs) to jailbreaking attacks, where adversarial inputs can bypass alignment methods
  and induce harmful outputs. The authors propose Randomized Embedding Smoothing and
  Token Aggregation (RESTA), a defense that adds noise to embedding vectors and performs
  aggregation during token generation to preserve semantic information.
---

# Smoothed Embeddings for Robust Language Models

## Quick Facts
- arXiv ID: 2501.16497
- Source URL: https://arxiv.org/abs/2501.16497
- Reference count: 39
- Proposes RESTA, an inference-time defense that adds noise to embedding vectors and performs token aggregation to reduce jailbreak attack success rates

## Executive Summary
This paper addresses the vulnerability of large language models to jailbreaking attacks by proposing Randomized Embedding Smoothing and Token Aggregation (RESTA). The defense adds random noise to embedding vectors and performs majority voting during token generation to preserve semantic information while disrupting adversarial perturbations. Experiments show that RESTA achieves superior robustness-utility tradeoffs compared to baseline defenses, effectively reducing attack success rates while maintaining model performance on benign tasks.

## Method Summary
RESTA is an inference-time defense that applies randomized smoothing to LLM token embeddings. The method adds Gaussian noise to embedding vectors of user content, performs k independent forward passes with perturbed embeddings, and aggregates next-token predictions via majority voting for the first l output tokens (prefix smoothing). After the prefix, generation continues with unperturbed embeddings. The defense uses four noise types (isotropic, hard directional, soft directional, orthogonal) and operates only on user content within chat templates, preserving system prompts.

## Key Results
- RESTA reduces GCG attack success rates from 94% to 2% using hard directional noise at σ=1.0
- Achieves superior robustness-utility tradeoffs compared to baseline defenses across multiple benchmarks
- Maintains competitive performance on utility benchmarks (AlpacaEval 2, IFEval) while significantly reducing attack success rates

## Why This Works (Mechanism)

### Mechanism 1: Embedding-Space Noise Disruption
Adding random noise to embedding vectors disrupts adversarial perturbations while preserving semantic content better than character-level perturbation. The defense applies perturbation function Hσ to embedding vectors, creating k independent noisy samples. Adversarial suffixes rely on precise token embeddings; noise in the embedding space breaks this precision.

### Mechanism 2: Token Aggregation via Majority Voting
Aggregating next-token predictions across k perturbed samples via majority vote filters out adversarial signals while converging on semantically correct tokens. For each generation step, the model computes next-token logits from all k perturbed embedding sequences and applies mode(ÿ₁,...,ÿₖ) as the output token.

### Mechanism 3: Response Prefix Smoothing
Applying smoothing only to the first l output tokens is sufficient because autoregressive generation continues the established theme. The defense is active only for the first l tokens (default l=20). If the model starts with refusal phrasing, it continues refusing; if it starts with acceptance, it continues harmfully.

## Foundational Learning

- **Randomized Smoothing (Cohen et al. 2019, Lecuyer et al. 2019)**: Classification defense adapted to text generation; understanding the original formulation explains why noise + aggregation provides robustness.
- **Transformer Token Embeddings**: RESTA operates on embedding vectors e = E(x), not on tokens directly; understanding E : X → R^d is required to implement noise injection correctly.
- **Jailbreaking Attacks (GCG, PAIR, RS, BEAST)**: Knowing attack objectives explains why prefix smoothing is designed as it is.

## Architecture Onboarding

- Component map: Input tokens x → Embedding E(x) → [User portion only] → Hσ noise (k copies) → k parallel forward passes through f → Majority vote → output token y → Append E(y) to all sequences, repeat
- Critical path: Identify user-content span within chat template, apply Hσ independently to each embedding, run k forward passes for positions 0 to l-1 with majority vote, continue standard generation for positions l onwards
- Design tradeoffs: Noise type (hard/soft directional preserves semantics but requires higher σ), k (higher k improves reliability but increases compute), l (longer l increases robustness but increases compute), σ (higher σ reduces ASR but degrades utility)
- Failure signatures: ASR remains high (σ too low or adaptive attack), utility drops sharply (σ too high), compute timeout (k or l too large), inconsistent outputs across runs (random seed not controlled)
- First 3 experiments: 1) Noise type ablation on held-out attack, 2) Utility-robustness Pareto sweep, 3) Adaptive attack stress test

## Open Questions the Paper Calls Out
None

## Limitations
- Effectiveness against adaptive attacks designed to anticipate smoothing is not tested
- The assumption that prefix smoothing prevents harmful content may not hold if attacks can place harmful content after the smoothing window
- Semantic preservation claims are not empirically validated with direct measurement of semantic drift

## Confidence

**High confidence (4+ anchors):**
- RESTA reduces attack success rates on benchmark attacks
- The method requires significant compute overhead
- RESTA outperforms baseline defenses in robustness-utility tradeoff space

**Medium confidence (2-3 anchors):**
- Embedding noise preserves semantic information better than character-level perturbation
- Prefix smoothing effectively prevents harmful content
- Majority voting successfully filters adversarial signals

**Low confidence (0-1 anchors):**
- Specific noise magnitude values are optimal across all attack types
- RESTA remains effective against adaptive attacks
- The l=20 token prefix length is universally sufficient

## Next Checks

1. **Semantic drift measurement**: Quantify semantic difference between unperturbed and smoothed embeddings using embedding similarity metrics and sentence embedding drift.

2. **Adaptive attack stress test**: Implement an adaptive GCG variant that optimizes the adversarial suffix under approximate gradient through the noise expectation.

3. **Prefix length ablation study**: Systematically vary l ∈ {5, 10, 15, 20, 25, 30} and measure both ASR reduction and utility degradation.