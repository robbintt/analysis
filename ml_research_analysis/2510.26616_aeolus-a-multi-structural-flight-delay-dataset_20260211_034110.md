---
ver: rpa2
title: 'Aeolus: A Multi-structural Flight Delay Dataset'
arxiv_id: '2510.26616'
source_url: https://arxiv.org/abs/2510.26616
tags:
- flight
- delay
- data
- prediction
- tabular
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Aeolus, a large-scale multi-modal flight
  delay dataset designed to advance research on flight delay prediction and foundation
  models for tabular data. Existing flight delay datasets are limited to flat tabular
  structures, failing to capture the spatiotemporal dynamics of delay propagation.
---

# Aeolus: A Multi-structural Flight Delay Dataset

## Quick Facts
- **arXiv ID**: 2510.26616
- **Source URL**: https://arxiv.org/abs/2510.26616
- **Reference count**: 40
- **Primary result**: Introduces Aeolus, a large-scale multi-modal flight delay dataset with 50M+ flights, flight chains, and network graphs for delay prediction research

## Executive Summary
This paper introduces Aeolus, a large-scale multi-modal flight delay dataset designed to advance research on flight delay prediction and foundation models for tabular data. Existing flight delay datasets are limited to flat tabular structures, failing to capture the spatiotemporal dynamics of delay propagation. Aeolus addresses this by providing three aligned modalities: (i) a tabular dataset with over 50 million flights enriched with operational, meteorological, and airport-level features; (ii) a flight chain module modeling delay propagation along sequential flight legs; and (iii) a flight network graph encoding shared aircraft, crew, and airport resource connections. The dataset supports regression, classification, temporal modeling, and graph learning tasks. Baseline experiments demonstrate the effectiveness of the proposed benchmark, with FTTransformer achieving MSE of 0.914 and TabulaRNN reaching accuracy of 0.772 in delay prediction. Aeolus fills a critical gap in both domain-specific and general-purpose structured data research.

## Method Summary
Aeolus combines 54.67M U.S. flights (2016-2024) from BTS with Meteostat weather data to create three aligned modalities. The tabular dataset includes 22 features (8 categorical, 14 continuous) and is split temporally 6:2:2 to prevent leakage. Flight chains are constructed by grouping flights by carrier and date, enforcing spatial continuity (destination airport → origin airport) to model delay propagation along sequential flight legs. Flight networks encode shared resources through tree-to-network aggregation, connecting flights that share spatiotemporal proximity. The dataset is publicly available at https://github.com/Flnny/Delay-data, with baseline models implemented using Mambular framework and evaluated on RTX 4070 12GB hardware.

## Key Results
- FTTransformer baseline achieves MSE of 0.914 for arrival delay prediction
- TabulaRNN achieves classification accuracy of 0.772 for delay detection
- Temporal splitting prevents 0.057 AUC inflation compared to random splits
- Multi-modal approach demonstrates effectiveness across regression, classification, and graph learning tasks

## Why This Works (Mechanism)

### Mechanism 1: Sequential Propagation via Tail-Number Linking
- Claim: If delay causality is modeled strictly as a temporal sequence within a single aircraft's rotation, models can capture upstream dependencies that flat tabular data misses.
- Mechanism: The dataset groups flights by `OP_CARRIER` and `DATE`, filtering for spatial continuity (Destination Airport → Origin Airport) to form "Flight Chains." This forces the learning algorithm to treat delay propagation as a stateful sequence rather than independent events.
- Core assumption: The 24-hour window sufficiently captures the critical "rotational" delay impact (e.g., a late arrival causing a late departure) without requiring explicit crew pairing data.
- Evidence anchors:
  - [abstract] "a flight chain module modeling delay propagation along sequential flight legs"
  - [section 3.2] "adjacent flights must satisfy destination-to-origin airport consistency... guaranteeing each chain corresponds to a single aircraft's 24-hour mission sequence."
  - [corpus] "Deep Learning to Identify the Spatio-Temporal Cascading Effects of Train Delays..." (Neighbor paper supports the general transferability of spatio-temporal cascading models in transport).
- Break condition: The mechanism degrades if an aircraft swap occurs (change of tail number) that is not recorded in the metadata, severing the logical chain of delay propagation.

### Mechanism 2: Relational Reasoning via Tree-to-Network Aggregation
- Claim: Modeling delay propagation as a graph of shared resources (gates/airspace) rather than just a linear sequence allows for "cross-aircraft" interference detection.
- Mechanism: The architecture constructs "Flight Trees" rooted at a target flight and connects them if they share spatiotemporal resources (e.g., overlapping airport usage). This transforms the problem from sequence modeling to structural reasoning.
- Core assumption: Shared airport resources and temporal proximity are valid proxies for complex, unobservable dependencies like crew transfers or passenger connections.
- Evidence anchors:
  - [abstract] "flight network graph that encodes shared aircraft, crew, and airport resource connections"
  - [section 3.3] "Aggregating flight trees within specific spatiotemporal ranges forms flight networks... [edges represent] cross-aircraft delay propagation."
  - [corpus] "Graph machine learning for flight delay prediction due to holding manouver" (Neighbor paper confirms utility of graphs for delay/holding prediction).
- Break condition: The graph structure fails to capture "invisible" links, such as specific crew scheduling constraints that are not purely spatiotemporal or airport-resource based.

### Mechanism 3: Leakage Prevention via Temporal Splitting
- Claim: Enforcing strict temporal splits (training on past, testing on future) reveals realistic performance degradation compared to random splits, which artificially inflate metrics.
- Mechanism: By partitioning data 6:2:2 based on time (rather than random sampling), the benchmark prevents the model from "peeking" at future operational patterns (e.g., seasonal effects, specific delay cascades) during training.
- Core assumption: Temporal distribution shift is a fundamental feature of the data generating process, and random splits violate the causal ordering of information availability.
- Evidence anchors:
  - [abstract] "temporal splits... and strict leakage prevention"
  - [section 5.1] Table 6 shows "systematic performance inflation under random splitting... average AUC increase of 0.057."
  - [corpus] Corpus neighbors do not explicitly discuss leakage mechanisms; this is a dataset-design specific insight.
- Break condition: This approach assumes stationarity is not present; if the system dynamics change drastically (e.g., a global shock like COVID-19), past data may lose predictive power entirely (as noted in Section 5.2).

## Foundational Learning

- **Non-IID (Independent and Identically Distributed) Data**
  - Why needed here: Flight delays violate IID assumptions because a delay on Flight A (upstream) physically causes a delay on Flight B (downstream). Treating them as independent samples causes information leakage.
  - Quick check question: If you shuffle this dataset randomly, will a model trained on Tuesday see data from Monday that helps it predict Tuesday's delays?

- **Distribution Shift (Concept Drift)**
  - Why needed here: The paper highlights COVID-19 as an "exogenous shock" where delay patterns changed (e.g., 2020 saw reduced traffic and different delay profiles). A model trained on 2019 may fail in 2020.
  - Quick check question: Does the relationship between input features (e.g., time of day) and the target (delay) remain constant across the 9-year span?

- **Multi-Modal Structured Learning**
  - Why needed here: Aeolus forces the learner to combine static attributes (weather), sequential attributes (flight history), and structural attributes (network topology).
  - Quick check question: How do you fuse a dense vector from a GNN (topology) with a sequence embedding from an LSTM (history)?

## Architecture Onboarding

- **Component map**: Raw BTS/Meteostat Data → Feature Alignment → Chain Construction (Tail grouping) → Graph Merging → Temporal Split → Training
- **Critical path**: The pipeline requires careful temporal ordering, with flight chains built from carrier-date groupings and graphs constructed from spatiotemporal resource sharing before the final 6:2:2 chronological split
- **Design tradeoffs**:
  - Complexity vs. Granularity: The "Flight Tree" approach captures more interactions but is computationally heavier than simple chains
  - Split Strategy: Random splits yield higher reported accuracy (easy metric win) but are useless for real-world deployment (Temporal splits are required for validity)
- **Failure signatures**:
  - High AUC / Low Precision: Indicates the model is good at ranking but struggles with the specific threshold of "15-minute delay" due to class imbalance
  - COVID-Anomaly Drop: Models trained exclusively on 2020 data will likely fail to generalize to 2022/2024 recovery periods due to learned "anomalous" patterns
- **First 3 experiments**:
  1. Establish a Tabular Baseline using FTTransformer on the 50M row dataset with *temporal splitting* to quantify the "floor" performance
  2. Implement the "Flight Chain" setup (LSTM/GRU) to verify if sequential modeling improves upon the static baseline (specifically looking at Recall)
  3. Integrate Graph Embeddings (VGAE) into the Tabular model to test if cross-aircraft resource contention signals provide a measurable lift in AUC

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent does the exclusion of real-time Air Traffic Control (ATC) decisions and dynamic passenger flow data limit the ability of models to capture micro-level delay catalysts within the flight network graph?
- Basis in paper: [Explicit] Appendix C states that current operational features lack ATC decisions and passenger flow data, restricting models from capturing micro-level delay catalysts.
- Why unresolved: The dataset relies on public BTS data which lacks this granularity; integrating it requires airline collaborations and privacy preservation techniques (e.g., differential privacy).
- What evidence would resolve it: A comparative study between the current Aeolus graphs and a dataset augmented with proprietary crew/ATC logs, measuring the performance delta in short-term delay propagation tasks.

### Open Question 2
- Question: Can prediction models trained on the North America-centric Aeolus dataset effectively generalize to heterogeneous global aviation markets (e.g., Europe, Asia) with different infrastructure and regulatory constraints?
- Basis in paper: [Explicit] Appendix C highlights that 78.4% of flights originate from North America, creating a geographic bias that limits generalizability to developing regions.
- Why unresolved: The current benchmark is constructed solely from US Department of Transportation data, lacking validation sets from other jurisdictions.
- What evidence would resolve it: Zero-shot or fine-tuning transfer learning experiments evaluating Aeolus-trained models on external datasets like EUROCONTROL or CAAC data.

### Open Question 3
- Question: How do models handle fundamental shifts in delay propagation mechanisms—such as those observed during the COVID-19 pandemic—when trained primarily on stable operational periods?
- Basis in paper: [Explicit] Appendix C suggests a need for "Counterfactual analysis of pre/post-COVID delay propagation mechanisms" to address non-stationarity introduced by the pandemic period.
- Why unresolved: While the paper mentions COVID-19 as an exogenous shock affecting delay patterns, it does not propose or test mechanisms to adapt models to such systemic structural breaks or "black swan" events.
- What evidence would resolve it: Development and testing of domain adaptation techniques that stabilize performance when crossing the pre-2020 to post-2020 distribution boundary.

## Limitations
- Unknown 1: Flight Chain Sequence Boundaries - The paper does not specify maximum sequence length L_max for padding/truncation, which is critical for reproducible results
- Unknown 2: Graph Construction Parameters - Specific temporal/spatial thresholds for creating edges between flights are not quantified
- Unknown 3: COVID-19 Impact Quantification - The paper mentions COVID-19 as an exogenous shock but does not provide quantitative analysis of how this distribution shift impacts model generalization across years

## Confidence
- **High Confidence** - The dataset construction methodology (50M+ records, 22 features, BTS+Meteostat sources) is well-specified and reproducible. The temporal split approach and leakage prevention claims are directly supported by experimental evidence (Table 6 shows 0.057 AUC inflation).
- **Medium Confidence** - The flight chain and flight network construction principles are clearly described, but implementation details are sparse. The effectiveness of multi-modal learning is demonstrated but not deeply analyzed for when and why it helps.
- **Low Confidence** - Claims about foundation model readiness and broader applicability to structured data research are forward-looking rather than evidence-based in this paper. The specific conditions under which the multi-modal approach outperforms single-modality baselines are not thoroughly characterized.

## Next Checks
1. **Temporal Split Validation**: Re-run FTTransformer baseline with both random and temporal splits on the same data to verify the reported 0.057 AUC inflation difference.
2. **Sequence Length Sensitivity**: Test flight chain models with varying L_max values (50, 100, 200) to determine sensitivity and identify optimal sequence boundaries for delay propagation modeling.
3. **COVID-Shift Analysis**: Train separate models on pre-COVID (2016-2019) and post-COVID (2020-2024) data, then test cross-period performance to quantify the actual impact of distribution shift on model generalization.