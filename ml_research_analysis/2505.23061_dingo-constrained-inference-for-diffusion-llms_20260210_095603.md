---
ver: rpa2
title: 'DINGO: Constrained Inference for Diffusion LLMs'
arxiv_id: '2505.23061'
source_url: https://arxiv.org/abs/2505.23061
tags:
- diffusion
- constrained
- dingo
- greedy
- unconstrained
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DINGO, the first constrained decoding algorithm
  for diffusion-based language models (LLMs). Unlike autoregressive models, diffusion
  LLMs predict blocks of tokens in parallel, making traditional constrained decoding
  approaches ineffective.
---

# DINGO: Constrained Inference for Diffusion LLMs

## Quick Facts
- arXiv ID: 2505.23061
- Source URL: https://arxiv.org/abs/2505.23061
- Authors: Tarun Suresh; Debangshu Banerjee; Shubham Ugare; Sasa Misailovic; Gagandeep Singh
- Reference count: 40
- Key outcome: DINGO achieves 68 percentage points improvement over unconstrained inference on symbolic math reasoning and JSON generation benchmarks with 100% syntactic validity

## Executive Summary
DINGO introduces the first constrained decoding algorithm specifically designed for diffusion-based language models, addressing the unique challenge that diffusion LLMs predict blocks of tokens in parallel rather than sequentially like autoregressive models. The algorithm uses dynamic programming to ensure outputs strictly adhere to user-specified regular expressions while maximizing probability under the model's true output distribution. DINGO demonstrates up to 68 percentage points improvement over unconstrained inference on structured output tasks while maintaining competitive runtime efficiency.

## Method Summary
DINGO adapts dynamic programming techniques to the parallel token prediction framework of diffusion language models, which fundamentally differs from the sequential generation of autoregressive models. The algorithm constructs a decoding trellis that tracks valid partial sequences satisfying the regular expression constraints, ensuring both correctness and optimality. By leveraging the block-wise parallel prediction capability of diffusion models while enforcing regular expression constraints through dynamic programming, DINGO guarantees that generated outputs strictly adhere to specified patterns while maximizing the probability under the model's true output distribution.

## Key Results
- Achieves 68 percentage points improvement over unconstrained inference on symbolic math reasoning and JSON generation benchmarks
- Maintains 100% syntactic and schema validity while preserving competitive runtime efficiency
- Demonstrates effectiveness for structured output generation with diffusion models across multiple test scenarios

## Why This Works (Mechanism)
DINGO works by recognizing that diffusion LLMs predict blocks of tokens in parallel, which prevents direct application of traditional constrained decoding approaches designed for autoregressive models. The dynamic programming framework constructs a trellis that tracks valid partial sequences satisfying regular expression constraints, allowing the algorithm to enforce correctness while optimizing for probability under the model's distribution. This approach guarantees both that outputs adhere to specified constraints and that they maximize likelihood according to the diffusion model's predictions.

## Foundational Learning

**Dynamic Programming for Sequence Decoding**
- Why needed: Essential for tracking valid partial sequences that satisfy regular expression constraints while optimizing probability
- Quick check: Verify the trellis construction correctly represents all valid partial sequences

**Regular Expression Constraint Processing**
- Why needed: Enables specification of complex output patterns that must be satisfied by generated sequences
- Quick check: Test constraint satisfaction on simple patterns before scaling to complex expressions

**Diffusion Model Parallel Prediction**
- Why needed: Understanding block-wise token prediction is crucial for adapting constrained decoding algorithms
- Quick check: Verify block prediction behavior matches theoretical expectations

## Architecture Onboarding

**Component Map**
- Regular Expression Parser -> Dynamic Programming Trellis Constructor -> Probability Maximization Module -> Output Generator

**Critical Path**
1. Parse input regular expression into constraint automaton
2. Initialize dynamic programming trellis for block-wise parallel predictions
3. Iteratively construct valid sequences while maximizing probability
4. Generate final output satisfying all constraints

**Design Tradeoffs**
- Optimality vs. Computational Complexity: Dynamic programming guarantees optimal solutions but scales exponentially with sequence length
- Constraint Expressiveness vs. Efficiency: More complex regular expressions increase computational overhead
- Parallel Prediction vs. Sequential Constraint Enforcement: Balancing diffusion model capabilities with constraint satisfaction requirements

**Failure Signatures**
- Exponential growth in computation time for longer sequences or complex constraints
- Constraint satisfaction at the cost of output diversity or quality
- Runtime inefficiency on sequences beyond tested lengths

**First Experiments**
1. Test constraint satisfaction on simple regular expressions (e.g., fixed-length patterns)
2. Measure runtime scaling on progressively longer sequences (100, 200, 500 tokens)
3. Evaluate performance on diverse structured output tasks beyond math and JSON

## Open Questions the Paper Calls Out
None

## Limitations
- Computational complexity scales exponentially with sequence length, potentially limiting scalability
- Empirical analysis of runtime efficiency on longer sequences and complex regular expressions is limited
- Results primarily validated on symbolic math and JSON generation tasks, with unclear generalization to other domains

## Confidence

**High Confidence**
- Fundamental algorithmic contribution of adapting dynamic programming for constrained decoding in diffusion LLMs is sound and well-explained

**Medium Confidence**
- Empirical results showing improvements in syntactic validity and comparison with unconstrained inference appear reliable

**Low Confidence**
- Claims about runtime efficiency and scalability to more complex constraints lack sufficient empirical backing

## Next Checks
1. **Scalability Analysis**: Systematically evaluate DINGO's runtime and memory complexity on progressively longer sequences (e.g., 512, 1024, 2048 tokens) and measure the exponential growth in computation time to validate the claimed efficiency.

2. **Generalization Testing**: Apply DINGO to diverse structured output tasks beyond symbolic math and JSON, such as code generation with type constraints, database query generation, or chemical structure generation, to assess the algorithm's robustness across domains.

3. **Constraint Complexity Study**: Test DINGO's performance on increasingly complex regular expressions (e.g., nested structures, variable-length patterns) to determine the practical limits of the constraint language and identify where the algorithm might break down.