---
ver: rpa2
title: Constrained Policy Optimization via Sampling-Based Weight-Space Projection
arxiv_id: '2512.13788'
source_url: https://arxiv.org/abs/2512.13788
tags:
- safe
- policy
- safety
- projection
- constrained
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses safe policy learning in safety-critical settings
  where model parameters must satisfy unknown, rollout-based safety constraints. The
  proposed SCPO method enforces safety directly in parameter space without requiring
  gradient access to constraint functions.
---

# Constrained Policy Optimization via Sampling-Based Weight-Space Projection

## Quick Facts
- arXiv ID: 2512.13788
- Source URL: https://arxiv.org/abs/2512.13788
- Reference count: 19
- This paper addresses safe policy learning in safety-critical settings where model parameters must satisfy unknown, rollout-based safety constraints.

## Executive Summary
This paper addresses safe policy learning in safety-critical settings where model parameters must satisfy unknown, rollout-based safety constraints. The proposed SCPO method enforces safety directly in parameter space without requiring gradient access to constraint functions. It constructs a local safe region by combining trajectory rollouts with smoothness bounds that relate parameter changes to shifts in safety metrics, then projects each gradient update via a convex SOCP. SCPO guarantees monotonic improvement of the objective and persistent constraint satisfaction for any first-order update direction, starting from any safe initialization. In constrained control settings with a stabilizing backup policy, SCPO ensures closed-loop stability and enables safe adaptation beyond the conservative backup.

## Method Summary
The SCPO method learns a residual neural network policy ϕ_θ(x) that refines actions from a certified backup controller π_safe. The policy is π_θ(x) = π_safe(x) + ϕ_θ(x) with final layer initialized to zero, guaranteeing initial safety. SCPO constructs a local safe region by combining trajectory rollouts with smoothness bounds on constraint changes, then projects gradient updates via convex SOCP onto this region. The method maintains a rolling bank of recent parameter perturbations and their safety evaluations, restricting optimization to a low-dimensional subspace spanned by these directions. This enables efficient safe learning without requiring explicit constraint gradients or extensive sampling.

## Key Results
- SCPO guarantees monotonic improvement of the objective and persistent constraint satisfaction for any first-order update direction, starting from any safe initialization
- In constrained control settings with a stabilizing backup policy, SCPO ensures closed-loop stability and enables safe adaptation beyond the conservative backup
- Experiments on regression with harmful supervision and a constrained double-integrator task with malicious expert demonstrate that SCPO consistently rejects unsafe updates, maintains feasibility throughout training, and achieves meaningful primal objective improvement while preserving safety guarantees

## Why This Works (Mechanism)

### Mechanism 1: Low-Rank Subspace Projection for Scalable Safety
Restricting parameter updates to the subspace spanned by recent candidate directions preserves safety while reducing optimization complexity from O(d) to O(m) where m ≪ d. The algorithm maintains a bank D ∈ R^(d×m) of recent parameter perturbations and their safety evaluations G, then projects onto the convex safe set within this low-dimensional subspace by solving a QCQP for coefficients c ∈ R^m.

### Mechanism 2: Conservative Quadratic Inner Approximation via Local Smoothness
Local L-smoothness of safety constraints enables a quadratic upper bound that guarantees constraint satisfaction after projection even without constraint gradients. For each constraint g_i, Assumption 1 bounds linearization error by (L_i/2)||∆θ||², yielding convex quadratic constraints that the SOCP projection can solve efficiently.

### Mechanism 3: Safe-by-Induction from Zero-Initialized Residual Architecture
Initializing the neural network residual to zero guarantees the combined policy equals the certified backup at t=0, enabling inductive safety propagation. The architecture uses π_θ(x) = π_safe(x) + ϕ_θ(x) with final layer weights/biases initialized to zero, so θ_0 satisfies g(θ_0) ≤ 0 and all subsequent θ_t remain feasible.

## Foundational Learning

- **Convex Projection and Euclidean Distance Minimization**: The core SCPO operation is projecting a raw gradient step onto a convex safe set; understanding why this yields descent directions requires hyperplane separation and convex geometry intuition. Quick check: Given a point outside a convex set, explain why the projection onto that set yields the unique minimizer of Euclidean distance and why the residual points "into" the set.

- **Lyapunov Stability and Forward Invariance**: Section V derives stability guarantees from one-step improvement conditions; understanding Theorem 2 requires grasping how value functions certify stability and how backward reachable sets define regions of attraction. Quick check: For a discrete-time system, if a function W(x) satisfies W(x_{k+1}) ≤ W(x_k) - α(||x_k||) with α a class-K function, what does this imply about the equilibrium at the origin?

- **Local Smoothness (Lipschitz Gradients) and Taylor Residual Bounds**: The entire safety guarantee depends on bounding the error between true constraint changes and their first-order approximations; this is standard in optimization but critical here for safety certification. Quick check: If f is L-smooth and you take a gradient step of size η in direction -∇f, what bound can you place on the suboptimality of the new point?

## Architecture Onboarding

- **Component map**: Backup Controller π_safe -> Residual Network ϕ_θ -> Policy Combination π_θ(x) = π_safe(x) + ϕ_θ(x) -> Sample Bank (D, G) -> Projection Solver -> Safety Grid G
- **Critical path**: 1. Initialize θ_0 with zero final layer → π_θ = π_safe, 2. Evaluate g(θ_0) on safety grid → confirm g ≤ 0, 3. Sample trajectories, compute raw gradient ∆θ_raw, 4. Evaluate safety at θ + ∆θ_raw, append to bank, 5. Solve QCQP (11) for c* → compute projected update ∆θ* = Dc*, 6. Backtracking line search with feasibility check (Lemma 1), 7. Update θ, recenter bank, repeat
- **Design tradeoffs**: Bank size m balances subspace expressivity against QCQP complexity; grid resolution trades false negatives against per-iteration cost; smoothness estimates L control step size conservatism; switching threshold X_f balances performance against certification complexity
- **Failure signatures**: Infeasible QCQP indicates insufficient bank diversity or violated smoothness assumptions; constraint violations despite projection suggest smoothness underestimation or grid resolution issues; stagnation means raw gradient lies in infeasible direction; instability indicates π_θ diverges too aggressively from π_safe
- **First 3 experiments**: 1. Replicate Section VI-A regression with sinusoidal target and box constraint, 2. Implement Section VI-B double integrator with LQR backup and malicious expert, plotting backward reachable sets, 3. Ablate bank size m ∈ {4, 8, 16} and grid sizes ∈ {20×20, 50×50, 100×100} measuring imitation loss and safety violations

## Open Questions the Paper Calls Out

### Open Question 1
How can the conservativeness of the projection step be reduced while maintaining safety guarantees? The current projection only filters unsafe directions but does not actively explore new safe directions, limiting performance gains. This is addressed in Section VII as a future direction.

### Open Question 2
What are optimal principles for designing the validation set used to construct surrogate safety metrics? The current approach relies on heuristic grid-based sampling, which may miss critical safety violations or introduce unnecessary conservatism. This is noted as an important direction beyond the paper's scope.

### Open Question 3
Can SCPO scale to high-dimensional nonlinear systems and deep neural networks while maintaining tractable verification? The control-theoretic analysis is limited to linear systems and neural-network verification methods are noted as not yet scalable for deep NNs. Experiments use only simple regression and a 2D double-integrator.

## Limitations
- Safety metric fidelity relies on discrete grids to approximate safety sets, but claims no false positives—this is unverifiable without analytical constraint forms
- Adaptive L backtracking is proposed but never validated; overestimation could cripple learning, underestimation could violate safety
- The induction argument depends critically on exact zero initialization of the final layer, which may not hold in practice due to numerical precision or architectural changes

## Confidence
- **High confidence**: SCPO's theoretical guarantees (Proposition 1, Theorem 2) given Assumptions 1-2 and exact projection feasibility
- **Medium confidence**: Empirical demonstration of constraint satisfaction and performance in synthetic tasks; limited to 2D problems
- **Low confidence**: Claims about computational scalability and robustness to non-smooth constraints; no ablation on bank size or grid resolution

## Next Checks
1. **Bank subspace expressivity**: Run ablation with m ∈ {4, 8, 16} on double-integrator task; measure convergence rate and any stagnation due to insufficient subspace coverage
2. **Grid resolution sensitivity**: Evaluate safety violations and computational cost across grid sizes {20×20, 50×50, 100×100} in control task; identify break-even point for false negatives
3. **Smoothness estimation robustness**: Inject non-smooth constraint regions (e.g., piecewise linear) and monitor L backtracking behavior; quantify impact on constraint satisfaction vs. learning speed