---
ver: rpa2
title: 'TinyMusician: On-Device Music Generation with Knowledge Distillation and Mixed
  Precision Quantization'
arxiv_id: '2509.00914'
source_url: https://arxiv.org/abs/2509.00914
tags:
- music
- arxiv
- generation
- quantization
- preprint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces TinyMusician, a lightweight music generation
  model distilled from MusicGen-Small, addressing the challenge of deploying large
  transformer-based models on edge devices with limited computational resources. The
  proposed framework integrates two key innovations: (1) Stage-mixed Bidirectional
  and Skewed KL-Divergence for knowledge distillation, which stabilizes training and
  improves generalization by dynamically balancing forward and backward KL-divergence
  terms during different training stages; and (2) Adaptive Mixed-Precision Quantization,
  which applies different quantization formats (Int8, Float16, Float32) to different
  model components to optimize both efficiency and audio fidelity.'
---

# TinyMusician: On-Device Music Generation with Knowledge Distillation and Mixed Precision Quantization

## Quick Facts
- arXiv ID: 2509.00914
- Source URL: https://arxiv.org/abs/2509.00914
- Reference count: 13
- Key outcome: 93% performance retention with 55% size reduction in mobile music generation

## Executive Summary
TinyMusician addresses the challenge of deploying large transformer-based music generation models on edge devices by introducing a lightweight framework that combines knowledge distillation with adaptive mixed-precision quantization. The model is distilled from MusicGen-Small using a novel Stage-mixed Bidirectional and Skewed KL-Divergence approach, achieving strong text-audio alignment and perceptual quality while being deployable on smartphones. When tested on iPhone 16 Pro, TinyMusician demonstrates competitive performance with state-of-the-art models while eliminating cloud dependency and maintaining efficient resource usage.

## Method Summary
The framework integrates two key innovations: (1) Stage-mixed Bidirectional and Skewed KL-Divergence for knowledge distillation, which dynamically balances forward and backward KL-divergence terms during different training stages to stabilize training and improve generalization; and (2) Adaptive Mixed-Precision Quantization, which applies different quantization formats (Int8, Float16, Float32) to different model components to optimize both efficiency and audio fidelity. This approach enables the model to retain 93% of MusicGen-Small's performance while achieving 55% reduction in model size, making it suitable for on-device deployment on resource-constrained mobile devices.

## Key Results
- Achieves 93% retention of MusicGen-Small performance with 55% model size reduction
- Deployed on iPhone 16 Pro with CLAPscore of 0.373 and FADscore of 7.05
- Outperforms state-of-the-art models in compactness-performance trade-off

## Why This Works (Mechanism)
The success of TinyMusician stems from its dual optimization strategy. The Stage-mixed Bidirectional and Skewed KL-Divergence distillation approach addresses the instability typically seen in student-teacher training by adapting the KL-divergence weighting based on training stage, allowing the student model to gradually align with the teacher's distribution while maintaining its own learning capacity. The Adaptive Mixed-Precision Quantization further enhances efficiency by recognizing that different model components have varying sensitivity to precision loss, applying aggressive quantization to less sensitive parts while preserving higher precision where audio fidelity is critical.

## Foundational Learning
- **Knowledge Distillation**: Technique where a smaller student model learns from a larger teacher model; needed to compress MusicGen-Small while retaining performance
- **KL-Divergence**: Measure of difference between probability distributions; critical for quantifying student-teacher alignment during distillation
- **Mixed-Precision Quantization**: Strategy of using different numerical precisions for different model parts; enables optimal trade-off between efficiency and accuracy
- **Text-Audio Alignment Metrics**: CLAPscore measures semantic alignment between text prompts and generated audio; essential for evaluating music generation quality
- **Perceptual Audio Quality**: FADscore evaluates the fidelity of generated audio compared to reference samples; key metric for music generation systems
- **Transformer-based Music Generation**: Architecture that models sequential dependencies in music; baseline approach for high-quality music generation

## Architecture Onboarding
**Component Map**: MusicGen-Small (teacher) -> TinyMusician (student) -> Adaptive Quantization -> Mobile Deployment
**Critical Path**: Text embedding -> Transformer layers -> Audio generation -> Mixed-precision conversion -> On-device inference
**Design Tradeoffs**: Model size vs. performance (93% retention vs. 55% reduction), computational efficiency vs. audio fidelity (adaptive quantization), training stability vs. convergence speed (stage-mixed distillation)
**Failure Signatures**: Audio artifacts from aggressive quantization, training divergence from improper KL-divergence balancing, degraded text-audio alignment from over-compression
**First Experiments**: 1) Compare stage-mixed distillation vs. standard distillation on validation loss convergence; 2) Evaluate quantization sensitivity by gradually increasing Int8 component ratio; 3) Measure CLAPscore degradation when removing adaptive quantization layers

## Open Questions the Paper Calls Out
None

## Limitations
- Lack of open-source code or pre-trained model weights for independent verification
- Self-reported benchmark comparisons without clear baseline specification
- Potential oversight of other domain-specific edge-deployed music generation systems

## Confidence
- High: 93% performance retention with 55% size reduction is internally consistent with the approach
- Medium: On-device deployment metrics lack details on inference conditions and power consumption
- Low: "First mobile-deployable music generation model" claim requires broader literature review

## Next Checks
1. Request and examine complete experimental setup details including baseline versions and hardware-specific deployment conditions
2. Conduct independent replication of the Stage-mixed Bidirectional and Skewed KL-Divergence approach on standard benchmarks
3. Compare the quantization scheme against other mixed-precision approaches on the same MusicGen backbone