---
ver: rpa2
title: ASecond-Order SpikingSSM for Wearables
arxiv_id: '2510.14386'
source_url: https://arxiv.org/abs/2510.14386
tags:
- imex
- spiking
- energy
- share-ssm
- state
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SHaRe-SSM introduces a second-order spiking state space model for
  ultra-long sequence modelling, combining energy efficiency with improved accuracy.
  It leverages resonate-and-fire neurons to capture oscillatory dynamics without ANN
  nonlinearities, enabling fully spike-based computation.
---

# ASecond-Order SpallingSSM for Wearables

## Quick Facts
- arXiv ID: 2510.14386
- Source URL: https://arxiv.org/abs/2510.14386
- Reference count: 40
- Primary result: Second-order spiking SSM achieves 99% accuracy on UCI-HAR and 92.7% on SHAR with 52.1× less energy than ANN-based second-order SSMs

## Executive Summary
SHaRe-SSM introduces a second-order spiking state space model designed for ultra-long sequence modeling in wearable applications. By integrating resonate-and-fire neurons with second-order dynamics, the model captures oscillatory patterns without relying on ANN nonlinearities, enabling fully spike-based computation. The architecture supports sequences up to 50,000 steps, achieving state-of-the-art accuracy on HAR benchmarks while dramatically reducing energy consumption. This positions SHaRe-SSM as a compelling solution for resource-constrained, always-on wearable devices.

## Method Summary
The core innovation is a second-order spiking SSM that leverages resonate-and-fire neurons to model oscillatory dynamics in time-series data. Unlike first-order SSMs, which struggle with long-range dependencies, the second-order formulation captures richer temporal patterns through resonance. A parallel scan formulation accelerates both training and inference, making the model scalable to tens of thousands of steps. A kernel-based spiking regressor extends the architecture to regression tasks. The model is fully spike-based, avoiding energy-intensive ANN operations, and is validated on human activity recognition (HAR) datasets with up to 50k-step sequences.

## Key Results
- Achieves 99% accuracy on UCI-HAR and 92.7% on SHAR datasets
- Outperforms first-order SSMs and matches or surpasses transformers on very long sequences (up to 50k steps)
- Consumes 52.1× less energy than ANN-based second-order SSMs

## Why This Works (Mechanism)
The second-order spiking SSM works by embedding resonant dynamics directly into the spiking neuron model. Resonate-and-fire neurons naturally oscillate in response to periodic inputs, allowing the network to track and predict oscillatory patterns without external nonlinearities. This resonance property enables efficient, long-range temporal modeling, which is critical for wearable sensor streams that often exhibit quasi-periodic behavior. The parallel scan formulation further optimizes computation, enabling rapid processing of ultra-long sequences.

## Foundational Learning
- **State space models (SSMs)**: Sequential models that track hidden states over time; needed for modeling temporal dependencies in sensor data; quick check: verify hidden state updates match differential equation discretization.
- **Resonate-and-fire neurons**: Spiking neurons that oscillate and fire at resonant frequencies; needed to capture periodic patterns without ANN nonlinearities; quick check: confirm resonance frequency matches expected input periodicity.
- **Parallel scan algorithms**: Efficient parallel computation of prefix sums; needed to accelerate SSM training/inference on long sequences; quick check: benchmark scan speed-up on target hardware.
- **Kernel-based regression**: Extends spiking models to continuous outputs; needed for regression tasks in wearables; quick check: validate kernel choice against input statistics.
- **Energy profiling for spiking vs. ANN**: Quantifies computational efficiency; needed to justify spiking over ANN for wearables; quick check: measure actual energy use on neuromorphic hardware.

## Architecture Onboarding

**Component Map**
Resonate-and-fire neurons → Second-order SSM dynamics → Parallel scan computation → Kernel-based spiking regressor → Output layer

**Critical Path**
Input spikes → Resonate-and-fire neurons → Second-order state update → Parallel scan → Kernel regression → Prediction

**Design Tradeoffs**
- Second-order dynamics improve accuracy but increase computational complexity
- Parallel scan accelerates long sequences but requires careful numerical stability management
- Spike-only computation maximizes energy efficiency but may limit representational richness compared to mixed-signal approaches

**Failure Signatures**
- Accuracy degradation on non-periodic or highly irregular signals
- Numerical instability in parallel scan for very long sequences
- Suboptimal performance if input statistics do not match kernel assumptions

**First Experiments**
1. Benchmark resonate-and-fire neurons on synthetic periodic signals
2. Compare second-order vs. first-order SSM accuracy on short HAR sequences
3. Profile energy consumption of spiking vs. ANN baselines on a neuromorphic simulator

## Open Questions the Paper Calls Out
None

## Limitations
- Limited empirical validation beyond HAR datasets; generalizability to other domains unclear
- Energy efficiency claims based on architectural assumptions, not measured hardware implementations
- No detailed analysis of robustness to input noise or signal quality variations

## Confidence
- Major claims: Medium
- Accuracy improvements: Medium
- Energy savings: Medium
- Scalability to >50k steps: Low
- Robustness to noise: Low

## Next Checks
1. Implement and test SHaRe-SSM on additional time-series datasets (e.g., healthcare monitoring, industrial sensor data) to assess generalizability.
2. Conduct ablation studies to quantify the individual contributions of second-order dynamics, resonate-and-fire neurons, and parallel scan to overall performance.
3. Measure actual energy consumption on neuromorphic hardware platforms to verify the claimed efficiency advantages over both first-order SSMs and ANN-based approaches.