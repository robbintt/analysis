---
ver: rpa2
title: LLM-guided Hierarchical Retrieval
arxiv_id: '2510.13217'
source_url: https://arxiv.org/abs/2510.13217
tags:
- search
- nodes
- tree
- node
- retrieval
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LATTICE, a training-free hierarchical retrieval
  framework that enables large language models to efficiently navigate large corpora
  through a semantic tree structure. The method constructs an offline semantic tree
  via bottom-up agglomerative clustering or top-down divisive summarization, then
  uses a search LLM to traverse the tree using calibrated path relevance scores.
---

# LLM-guided Hierarchical Retrieval

## Quick Facts
- arXiv ID: 2510.13217
- Source URL: https://arxiv.org/abs/2510.13217
- Reference count: 40
- State-of-the-art zero-shot performance with up to 9% improvement in Recall@100 and 5% in nDCG@10 over the next best zero-shot baseline

## Executive Summary
This paper introduces LATTICE, a training-free hierarchical retrieval framework that enables large language models to efficiently navigate large corpora through a semantic tree structure. The method constructs an offline semantic tree via bottom-up agglomerative clustering or top-down divisive summarization, then uses a search LLM to traverse the tree using calibrated path relevance scores. A key innovation is the score calibration algorithm that enables reliable cross-branch and cross-level comparisons by modeling local LLM outputs as linear transformations of latent relevance scores and optimizing them via MLE. Evaluated on the BRIGHT benchmark, LATTICE achieves state-of-the-art zero-shot performance with up to 9% improvement in Recall@100 and 5% in nDCG@10 over the next best zero-shot baseline, demonstrating competitive results against fine-tuned methods on static corpora while showing limitations on query-dependent dynamic corpora.

## Method Summary
LATTICE constructs an offline semantic tree structure of the corpus using either bottom-up agglomerative clustering or top-down divisive summarization. The search process employs a calibrated scoring algorithm that models local LLM outputs as linear transformations of latent relevance scores, optimizing these transformations via maximum likelihood estimation. This calibration enables reliable comparison of path relevance scores across different branches and tree levels. During retrieval, an LLM traverses the tree based on these calibrated scores to efficiently locate relevant documents. The framework is training-free, requiring only the construction of the semantic tree and the calibration of LLM scoring functions, making it applicable to new corpora without additional fine-tuning.

## Key Results
- State-of-the-art zero-shot performance on BRIGHT benchmark with up to 9% improvement in Recall@100 and 5% in nDCG@10 over next best zero-shot baseline
- Competitive performance against fine-tuned methods on static corpora
- Demonstrates limitations on query-dependent dynamic corpora
- Achieves reliable cross-branch and cross-level comparisons through score calibration algorithm

## Why This Works (Mechanism)
The framework's effectiveness stems from decomposing the retrieval problem into hierarchical navigation through a semantically organized tree structure. By constructing an offline semantic tree, the method reduces the search space at each decision point, making LLM traversal computationally tractable. The score calibration algorithm is critical - it addresses the inherent difficulty of comparing LLM outputs across different branches and levels by modeling them as linear transformations of latent relevance scores. This enables the search LLM to make informed decisions about which paths to explore based on comparable relevance estimates, rather than unreliable raw LLM scores that would vary systematically across different parts of the tree.

## Foundational Learning

**Semantic Tree Construction** - Building hierarchical representations of corpora through clustering or summarization
*Why needed:* Reduces search complexity from linear corpus scanning to logarithmic tree traversal
*Quick check:* Verify tree depth and branching factor balance to ensure efficient search

**Score Calibration via MLE** - Modeling LLM outputs as linear transformations of latent relevance scores
*Why needed:* Enables reliable cross-branch and cross-level comparison of path relevance
*Quick check:* Validate calibration performance on held-out validation paths

**Hierarchical Search Navigation** - Using LLMs to traverse semantic trees based on calibrated scores
*Why needed:* Combines semantic understanding with efficient search space reduction
*Quick check:* Test search accuracy at different tree depths to identify optimal stopping criteria

## Architecture Onboarding

**Component Map:** Corpus -> Tree Construction (Agglomerative/Divisive) -> Score Calibration -> Search LLM -> Retrieved Documents

**Critical Path:** Corpus → Tree Construction → Score Calibration → LLM Traversal → Document Retrieval

**Design Tradeoffs:** Agglomerative clustering provides more stable semantic groupings but requires quadratic computation, while divisive summarization is faster but may produce less coherent clusters. Score calibration adds computational overhead but is essential for reliable cross-branch comparisons.

**Failure Signatures:** Poor retrieval performance typically manifests as either: 1) Calibration failure indicated by inconsistent path scores across branches, or 2) Tree construction issues shown by retrieval accuracy degrading with tree depth.

**First 3 Experiments:**
1. Validate score calibration by comparing calibrated vs uncalibrated retrieval performance on a small corpus
2. Benchmark agglomerative vs divisive tree construction methods on retrieval accuracy and construction time
3. Test calibration robustness by varying LLM model sizes and architectures

## Open Questions the Paper Calls Out

The paper acknowledges several open questions regarding its framework. The score calibration algorithm's generalization across diverse domains remains uncertain, as it relies on assumptions about local LLM outputs being linear transformations of latent relevance scores that may not hold universally across different corpus types or query distributions. The evaluation is limited to English-language corpora with no validation on multilingual datasets, raising questions about cross-lingual performance. The framework's dependence on specific LLM capabilities for both tree construction and traversal introduces uncertainty about performance consistency across different model sizes and architectures. Additionally, while the paper acknowledges limitations on query-dependent dynamic corpora, the exact boundary conditions for when the method fails are not fully characterized.

## Limitations

- Score calibration algorithm's generalization across diverse domains is uncertain, with assumptions about linear transformations of latent relevance scores potentially not holding universally
- Evaluation limited to English-language corpora with no validation on multilingual datasets, raising cross-lingual performance questions
- Dependence on specific LLM capabilities introduces uncertainty about performance consistency across different model sizes and architectures
- Limited characterization of boundary conditions for query-dependent dynamic corpora where method shows limitations

## Confidence

High: Claims about hierarchical tree structure improving search efficiency and the necessity of score calibration for cross-branch comparison
Medium: Claims about state-of-the-art zero-shot performance and competitive results against fine-tuned methods
Low: Claims about universal applicability across diverse domains and languages without empirical validation

## Next Checks

1. Test score calibration robustness by evaluating performance degradation when using smaller or differently-architected LLMs than those used in training
2. Conduct multilingual experiments to assess cross-lingual retrieval capabilities and calibration stability across languages
3. Perform ablation studies on agglomerative versus divisive tree construction methods to quantify their relative contributions to overall performance and identify optimal use cases for each approach