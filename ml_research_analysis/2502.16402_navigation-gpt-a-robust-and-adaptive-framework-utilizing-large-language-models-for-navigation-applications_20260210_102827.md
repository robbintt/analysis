---
ver: rpa2
title: 'Navigation-GPT: A Robust and Adaptive Framework Utilizing Large Language Models
  for Navigation Applications'
arxiv_id: '2502.16402'
source_url: https://arxiv.org/abs/2502.16402
tags:
- path
- collision
- degrees
- course
- speed
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The research addresses the challenge of navigation decision support
  systems performing poorly in non-predefined scenarios. It proposes a dual-core LLM
  framework, Navigation-GPT, leveraging ReAct-based prompt engineering for task decomposition
  and LoRA-based fine-tuning for specialized decision-making.
---

# Navigation-GPT: A Robust and Adaptive Framework Utilizing Large Language Models for Navigation Applications

## Quick Facts
- arXiv ID: 2502.16402
- Source URL: https://arxiv.org/abs/2502.16402
- Reference count: 40
- A dual-core LLM framework combining tool-grounded reasoning and LoRA fine-tuning for COLREGs-compliant maritime navigation

## Executive Summary
Navigation-GPT addresses the limitations of traditional navigation decision support systems in non-predefined scenarios by leveraging large language models. The framework employs a dual-core architecture where a larger LLM handles task decomposition and tool orchestration while a smaller LoRA-fine-tuned LLM generates context-aware, COLREGs-compliant recommendations. Experimental results demonstrate superior performance in both standard collision avoidance tasks and unstructured scenarios requiring adaptive reasoning.

## Method Summary
The framework implements a dual-core LLM architecture using Qwen2-72B as the control core and Qwen2-7B fine-tuned with LoRA as the decision core. The control core uses ReAct prompting to decompose navigation tasks and invoke external tools for DCPA/TCPA calculations and encounter type identification. The decision core is fine-tuned on proprietary datasets (SETD and SCADD) to generate COLREGs-compliant collision avoidance maneuvers. The system processes sensor data through a voyage depiction module that converts AIS, radar, and CCTV inputs into standardized natural language descriptions.

## Key Results
- Navigation-GPT achieves decision generation in 15 seconds versus 58 seconds for DeepSeek-based approaches
- The LoRA-fine-tuned 7B model outperforms both larger general-purpose models and distilled 32B models on domain-specific tasks
- Framework successfully handles unstructured scenarios including unexpected obstacles like fishing nets through larger core override capabilities

## Why This Works (Mechanism)

### Mechanism 1
- Claim: External tool grounding reduces LLM hallucination risk in navigation decision-making
- Mechanism: The larger LLM core uses ReAct prompting to decompose tasks into sub-tasks, then invokes hard-coded tools that compute DCPA/TCPA metrics from raw sensor data. These structured numerical outputs constrain the LLM's reasoning to real-world data.
- Core assumption: Tool outputs are accurate and the LLM can correctly interpret numerical risk parameters in context.
- Evidence anchors:
  - [abstract] "autonomously invoke corresponding external tools to gather relevant information, using this feedback to mitigate the risk of LLM hallucinations"
  - [section 3.2] "ReAct enables the LLM to iteratively generate a trajectory of Thought, Action, and Observation"
- Break condition: If external sensors fail or tools return erroneous calculations, the LLM will reason from incorrect premises.

### Mechanism 2
- Claim: LoRA fine-tuning enables smaller models to outperform larger general-purpose LLMs on domain-specific navigation tasks
- Mechanism: LoRA freezes pretrained weights while injecting trainable low-rank matrices, allowing efficient adaptation to COLREGs-compliant decision patterns. The 7B parameter model fine-tuned on SETD and SCADD learns domain-specific reasoning that general-purpose models lack.
- Core assumption: The training datasets adequately cover the distribution of real-world encounter scenarios.
- Evidence anchors:
  - [abstract] "a fine-tuned smaller LLM core (via LoRA) for context-aware recommendations compliant with COLREGs"
  - [section 4.6] "the performance of the LoRA-fine-tuned, smaller 7B model significantly outperforms the 32B model distilled by DeepSeek-R1"
- Break condition: If encounter scenarios fall outside the training distribution, fine-tuned recommendations may degrade.

### Mechanism 3
- Claim: The dual-core architecture enables reasoning override for unexpected constraints
- Mechanism: The larger LLM core receives recommendations from the fine-tuned smaller core along with environmental context. When detecting contradictions, it employs chain-of-thought reasoning to override trained patterns with context-appropriate alternatives.
- Core assumption: The larger LLM core has sufficient reasoning capacity to reliably identify when overrides are warranted.
- Evidence anchors:
  - [abstract] "a larger LLM core...using this feedback to mitigate the risk of LLM hallucinations"
  - [section 4.5] "Upon detecting an unexpected appearance of extensive fishing nets on the starboard side, Navigation-GPT determines that a starboard turn would negatively impact the OS"
- Break condition: If the larger LLM core fails to detect critical environmental constraints, it may inappropriately override or fail to override smaller-core recommendations.

## Foundational Learning

- Concept: **ReAct (Reasoning + Acting)**
  - Why needed here: Enables the framework to interleave internal reasoning with external tool calls, creating a feedback loop between thinking and environment interaction
  - Quick check question: Can you trace how a "Thought" leads to an "Action" that produces an "Observation" in Figure 1?

- Concept: **DCPA (Distance at Closest Point of Approach) and TCPA (Time to Closest Point of Approach)**
  - Why needed here: These are the fundamental collision risk metrics that tools compute and LLMs interpret; understanding their meaning is essential for validating outputs
  - Quick check question: Given two ships' positions, speeds, and courses, can you explain what a low DCPA with a positive TCPA indicates?

- Concept: **COLREGs (International Regulations for Preventing Collisions at Sea)**
  - Why needed here: The framework's decisions must comply with these rules; the LoRA training embeds rule-compliant behavior patterns
  - Quick check question: In a head-on encounter situation, which COLREGs rule specifies both vessels should turn to starboard?

## Architecture Onboarding

- Component map:
  Sensor Layer (AIS, radar, CCTV) -> Voyage Depiction Module -> Larger LLM Core (Qwen2-72B) -> Tool Layer (get_DCPA/TCPA, get_encounter_type, get_collision, get_avoidance_action) -> Smaller LLM Core (Qwen2-7B + LoRA) -> Final Decision Output

- Critical path:
  1. Query received → Larger core decomposes task via ReAct
  2. Tools invoked → DCPA/TCPA/encounter type computed
  3. Smaller core receives textual description + tool outputs → generates COLREGs-compliant recommendation
  4. Larger core synthesizes smaller core output + environmental context → final decision with chain-of-thought

- Design tradeoffs:
  - Larger core (72B) provides stronger reasoning but slower inference (~58s with DeepSeek vs. ~15s with the dual-core approach)
  - LoRA fine-tuning enables domain adaptation with limited compute (4×A100, 2 epochs) but requires curated training data
  - Dual-core adds complexity but separates concerns: tool orchestration vs. domain expertise

- Failure signatures:
  - **Hallucination**: Larger core generates plausible but incorrect risk assessments—mitigated by tool grounding
  - **Tool failure cascade**: If DCPA/TCPA calculations are wrong, downstream decisions inherit errors
  - **Override malfunction**: Larger core may fail to override smaller core when environmental constraints warrant it

- First 3 experiments:
  1. **Single-ship head-on encounter**: Verify basic COLREGs compliance—confirm starboard turn behavior matches expected trajectory in Figure 6
  2. **Three-ship crossing scenario**: Test prioritization logic—verify the framework correctly identifies which target ship to avoid first based on DCPA/TCPA (Figure 12)
  3. **Unexpected constraint injection**: Introduce "fishing nets on starboard" prompt—verify the larger core overrides the smaller core's starboard-turn recommendation with an alternative (Figure 15)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the Navigation-GPT framework be extended to incorporate long-distance path planning capabilities alongside local collision avoidance?
- Basis in paper: [explicit] The conclusion states, "Since Navigation-GPT currently focuses on navigation and collision avoidance, it lacks long-distance path planning capabilities. Future research will further explore the application of LLMs in ship path planning."
- Why unresolved: The current framework decomposes immediate navigation tasks but does not integrate the strategic, macro-level routing necessary for complete voyage management.
- What evidence would resolve it: Successful implementation and validation of a unified system capable of optimizing global routes while simultaneously managing local COLREGs compliance.

### Open Question 2
- Question: Is the reported 15-second decision-making latency sufficiently robust for handling sudden, high-speed emergency scenarios in real-time?
- Basis in paper: [inferred] The paper notes the proposed method generates decisions in "15 seconds" compared to DeepSeek's "58 seconds," treating the reduction as a success. However, for close-range or high-speed dynamic hazards, a 15-second delay may still exceed safety margins required for immediate evasion.
- Why unresolved: The evaluation focuses on standard encounter scenarios where a slight delay is permissible, leaving the boundary conditions for real-time critical safety untested.
- What evidence would resolve it: Latency measurements and success rates in high-fidelity simulations of sudden, close-range emergencies requiring sub-second reaction times.

### Open Question 3
- Question: How susceptible is the framework to performance degradation when processing noisy, incomplete, or conflicting sensor data converted into text?
- Basis in paper: [inferred] The methodology relies on a "Voyage Depiction Module" to convert sensor data into standardized text. While this aids the LLM, it assumes the input data is clean; the paper does not address how the model handles textual descriptions derived from erroneous or "hallucinated" sensor inputs.
- Why unresolved: LLMs are sensitive to input perturbations, and the robustness of the textual interface against sensor noise has not been quantified.
- What evidence would resolve it: Ablation studies testing collision avoidance accuracy when input textual descriptions are corrupted by simulated sensor noise or missing data fields.

## Limitations
- Relies on proprietary datasets (SETD and SCADD) that are not publicly available, limiting independent validation
- Performance in real-world conditions with sensor noise, weather interference, and unpredictable human factors remains untested
- Dual-core architecture adds significant computational complexity and potential failure points, particularly around the larger LLM's override decisions

## Confidence

**High Confidence**: The mechanism of using external tools to ground LLM reasoning and reduce hallucination risk is well-supported by the technical description and aligns with established practices in AI safety. The dual-core architecture concept and LoRA fine-tuning approach are clearly explained with specific configurations.

**Medium Confidence**: The claim that Navigation-GPT outperforms baseline models is supported by comparative results, but the proprietary nature of the evaluation datasets and lack of public benchmarks make independent verification difficult. The COLREGs compliance claims are theoretically sound but lack third-party validation.

**Low Confidence**: The framework's adaptability to truly unstructured, non-predefined scenarios is demonstrated through a limited set of test cases. The paper does not provide evidence of performance across diverse environmental conditions or with varied vessel types beyond the training distribution.

## Next Checks

1. **Open-Source Benchmark Validation**: Replicate the core evaluation using publicly available AIS datasets (e.g., from MarineCadastre or AIS Hub) to verify the framework's performance on non-proprietary data and enable community validation.

2. **Real-World Sensor Integration Test**: Deploy the framework with actual AIS, radar, and CCTV feeds in controlled maritime environments to assess performance with real sensor noise, latency, and environmental interference patterns.

3. **Failure Mode Analysis**: Systematically test the framework's response to tool failures (incorrect DCPA/TCPA calculations), sensor blackouts, and conflicting COLREGs scenarios to quantify the reliability of the larger LLM's override mechanism under stress conditions.