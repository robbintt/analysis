---
ver: rpa2
title: Discovering Interpretable Biological Concepts in Single-cell RNA-seq Foundation
  Models
arxiv_id: '2510.25807'
source_url: https://arxiv.org/abs/2510.25807
tags:
- cell
- concepts
- concept
- genes
- gene
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors introduce a framework for interpreting biological concepts
  in single-cell RNA-seq foundation models using sparse autoencoders (SAEs). Their
  method combines counterfactual perturbations with gene attribution to identify genes
  that influence concept activation, moving beyond differential expression analysis.
---

# Discovering Interpretable Biological Concepts in Single-cell RNA-seq Foundation Models

## Quick Facts
- arXiv ID: 2510.25807
- Source URL: https://arxiv.org/abs/2510.25807
- Authors: Charlotte Claye; Pierre Marschall; Wassila Ouerdane; Céline Hudelot; Julien Duquesne
- Reference count: 26
- Key outcome: SAE-extracted concepts are more interpretable than individual neurons, align with biological signals, and preserve predictive performance

## Executive Summary
This work introduces a framework for interpreting biological concepts in single-cell RNA-seq foundation models using sparse autoencoders (SAEs). The approach combines counterfactual perturbations with gene attribution to identify genes that influence concept activation, moving beyond traditional differential expression analysis. Applied to scGPT and scVI models on immune cell datasets, the framework demonstrates that SAE-extracted concepts are more interpretable than individual neurons while maintaining predictive performance in downstream tasks. The method offers two interpretation approaches: expert-driven analysis via interactive visualization and ontology-driven pathway enrichment.

## Method Summary
The framework employs sparse autoencoders to extract interpretable biological concepts from foundation models trained on single-cell RNA-seq data. It uses counterfactual perturbations to systematically modify gene expression values and observe changes in concept activation, combined with gene attribution methods to identify influential genes. The approach includes both expert-driven interpretation through interactive visualization tools and ontology-driven pathway enrichment analysis. The method was validated on immune cell datasets using established foundation models (scGPT and scVI), comparing interpretability and performance against baseline approaches.

## Key Results
- SAE-extracted concepts show higher interpretability than individual neurons in foundation models
- Extracted concepts align with known biological signals including cell types and biological processes
- The framework preserves predictive performance in downstream classification tasks
- Expert-driven and ontology-driven interpretation approaches provide complementary insights

## Why This Works (Mechanism)
The framework leverages the hierarchical feature extraction capabilities of sparse autoencoders to identify latent biological concepts that are more abstract and interpretable than individual gene expression patterns. By using counterfactual perturbations, the method can isolate the causal relationships between specific gene expression changes and concept activation, moving beyond correlation-based analyses. The combination of gene attribution with concept activation provides a mechanistic understanding of how molecular changes translate to cellular phenotypes.

## Foundational Learning
1. **Sparse Autoencoders for Interpretability** - Why needed: Standard neural network features are often uninterpretable; quick check: Compare activation patterns of SAEs vs. individual neurons for biological relevance
2. **Counterfactual Perturbation Analysis** - Why needed: To establish causal relationships between gene expression and concept activation; quick check: Validate perturbation effects against known biological pathways
3. **Gene Attribution Methods** - Why needed: To identify which genes most strongly influence concept activation; quick check: Compare attribution results with differential expression analysis
4. **Ontology-driven Pathway Enrichment** - Why needed: To validate biological relevance of extracted concepts; quick check: Assess enrichment significance against background gene sets
5. **Interactive Visualization Tools** - Why needed: To enable expert-driven interpretation of complex biological concepts; quick check: User study on interpretability improvement
6. **Foundation Model Adaptation** - Why needed: To apply SAE interpretation to pre-trained models; quick check: Compare performance across different foundation models

## Architecture Onboarding

**Component Map:**
SAE Layer -> Counterfactual Perturbation Module -> Gene Attribution Engine -> Interpretation Interface

**Critical Path:**
1. Foundation model input → SAE feature extraction → Concept activation → Gene attribution → Interpretation

**Design Tradeoffs:**
- Interpretability vs. reconstruction accuracy in SAE design
- Computational cost of counterfactual perturbations vs. interpretability gains
- Expert-driven vs. ontology-driven interpretation completeness

**Failure Signatures:**
- Poor reconstruction quality indicating over-sparsity
- Unstable concept activation across similar samples
- Attribution results that don't align with known biology

**3 First Experiments:**
1. Test SAE interpretability on synthetic datasets with known ground truth concepts
2. Compare counterfactual perturbation results with traditional differential expression analysis
3. Validate concept preservation across different foundation model architectures

## Open Questions the Paper Calls Out
None specified in the provided material.

## Limitations
- Generalizability across diverse biological contexts and model architectures remains untested
- Computational complexity and hyperparameter sensitivity of counterfactual perturbations
- Reliance on subjective measures of interpretability (pathway enrichment and expert knowledge)
- Uncertainty about whether identified concepts represent genuine biological signals or model artifacts

## Confidence
- **High Confidence**: Technical implementation of SAEs and preservation of downstream task performance
- **Medium Confidence**: Interpretability of extracted concepts and their biological relevance
- **Medium Confidence**: Effectiveness of interpretation approaches across different biological contexts

## Next Checks
1. Apply the framework to diverse single-cell datasets beyond immune cells, including different tissues and developmental stages, to assess generalizability
2. Compare concept interpretability and biological relevance across multiple foundation model architectures beyond scGPT and scVI
3. Develop and implement quantitative metrics for assessing interpretability quality, validated against independent biological knowledge bases