---
ver: rpa2
title: Towards Probabilistic Question Answering Over Tabular Data
arxiv_id: '2506.20747'
source_url: https://arxiv.org/abs/2506.20747
tags:
- probabilistic
- reasoning
- table
- question
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LUCARIO, a new benchmark and framework for
  probabilistic question answering over large tabular data. The method induces Bayesian
  Networks from tables, translates natural language queries into probabilistic queries,
  and uses large language models to generate final answers.
---

# Towards Probabilistic Question Answering Over Tabular Data

## Quick Facts
- arXiv ID: 2506.20747
- Source URL: https://arxiv.org/abs/2506.20747
- Reference count: 12
- This paper introduces LUCARIO, a new benchmark and framework for probabilistic question answering over large tabular data

## Executive Summary
This paper introduces LUCARIO, a new benchmark and framework for probabilistic question answering over large tabular data. The method induces Bayesian Networks from tables, translates natural language queries into probabilistic queries, and uses large language models to generate final answers. Auto-BN, the proposed framework, achieves 38.2% Acc0.02 and MAE of 0.103 on the benchmark, significantly outperforming baselines like LLM+Table (24.4% Acc0.02, MAE 0.171) and NL2SQL (13.2% Acc0.02, MAE 0.190).

## Method Summary
The Auto-BN framework takes raw tabular data and automatically induces a Bayesian Network (BN) structure and parameters using structure learning algorithms. Given a natural language question, an LLM translates it into a formal probabilistic query (e.g., "P(Delayed | Region=Region A)"). Exact probabilistic inference is then performed on the BN to compute the answer, and another LLM generates a natural language response. The system also compresses statistical premises into "Insights" using Markov Blankets to help the LLM handle large data distributions within context limits.

## Key Results
- Auto-BN achieves 38.2% Acc0.02 and MAE of 0.103 on the LUCARIO benchmark
- Outperforms LLM+Table baseline: 24.4% Acc0.02, MAE 0.171
- Outperforms NL2SQL baseline: 13.2% Acc0.02, MAE 0.190

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Decoupling semantic parsing from probabilistic calculation improves calibration and reduces hallucination compared to pure LLM reasoning.
- **Mechanism:** The Auto-BN framework abstracts the tabular data into a Bayesian Network (BN). The LLM is restricted to a translation role (Natural Language → Probabilistic Query), while a symbolic inference engine computes the exact probability. This prevents the LLM from approximating statistical distributions via unreliable internal weights.
- **Core assumption:** The statistical dependencies in the tabular data can be accurately captured by an induced Bayesian Network structure.
- **Evidence anchors:**
  - [abstract] "Our method induces Bayesian Networks from tables... uses large language models (LLMs) to generate final answers."
  - [section 5.2] "Auto-BN achieves the Strongest Results... demonstrating the effectiveness of integrating symbolic probabilistic reasoning with LLM-based query understanding."
  - [corpus] Related work (e.g., *LLM-Symbolic Integration for Robust Temporal Tabular Reasoning*) supports the trend of using symbolic scaffolds to stabilize LLM reasoning.
- **Break condition:** If the LLM fails to map natural language terms to the correct nodes/states in the BN (translation error), the symbolic engine will compute a mathematically correct but semantically wrong answer.

### Mechanism 2
- **Claim:** Handling uncertainty via explicit inference solves the "empty result" problem inherent in deterministic NL2SQL approaches.
- **Mechanism:** Unlike NL2SQL, which returns `NULL` or 0.0 if no exact record matches the query conditions (e.g., "Region A" and "Delay"), the BN computes a conditional probability P(Effect | Cause) using the entire data distribution. This allows the system to answer "How probable" questions even when specific co-occurrences are sparse.
- **Core assumption:** Users accept probabilistic estimates (e.g., "60% likely") rather than binary facts, and the query requires reasoning under uncertainty.
- **Evidence anchors:**
  - [section 1] "These [probabilistic questions] cannot be answered directly using SQL-based approaches... which often hallucinate... or generalize poorly."
  - [section 5.4] "NL2SQL baseline frequently output 0.0 (no records) or 1.0 (bias in retrieved few records)."
  - [corpus] *General Table Question Answering via Answer-Formula Joint Generation* similarly seeks versatile execution mechanisms beyond standard SQL for complex queries.
- **Break condition:** If the query is purely factual (e.g., "What is the capital of France?"), the probabilistic overhead is unnecessary, and a simpler lookup would be more efficient.

### Mechanism 3
- **Claim:** Compression of statistical premises into "Insights" bridges the gap between large data distributions and limited LLM context windows.
- **Mechanism:** For the LLM+Premise baseline (and potentially for context enrichment), the system filters the exhaustive premise set (avg 79k) into a smaller set of "Insights" using Markov Blankets. This distills high-impact dependencies, allowing the LLM to focus on relevant causal paths without processing the entire distribution.
- **Core assumption:** The Markov Blanket effectively identifies the most relevant variables for a given query node.
- **Evidence anchors:**
  - [section 3.3] "LUCARIO also includes a set of insights... identified as having the most significant impact... based on the Markov-Blanket (MB) concept."
  - [section 5.2] "Incorporating Insights Significantly Boosts Accuracy... distilling the large premise space into a concise and informative subset."
  - [corpus] Weak/suggestive: *CRAFT* and other retrieval papers emphasize filtering, but specific "Insight" mechanisms are unique to this paper's contribution.
- **Break condition:** If the true causal dependency is weak or distributed across many variables (not captured by top-k insights), the reasoning context will be incomplete.

## Foundational Learning

- **Concept:** **Bayesian Network Structure Learning**
  - **Why needed here:** The core engine of the Auto-BN framework relies on automatically generating a Directed Acyclic Graph (DAG) from raw tabular data ($T \to B$). You must understand how algorithms derive conditional independence from data to debug why certain edges exist or don't exist.
  - **Quick check question:** Can you explain why an edge between two columns might appear in a learned BN even if there is no direct causal link (e.g., due to a confounder)?

- **Concept:** **Exact Probabilistic Inference (e.g., Variable Elimination)**
  - **Why needed here:** The framework uses an inference engine to compute $P(Query | Evidence)$. Understanding this helps distinguish between the LLM's role (translation) and the Engine's role (calculation).
  - **Quick check question:** If a query asks for $P(A | B, C)$, does the inference engine query the database rows directly or the Conditional Probability Tables (CPTs) of the BN?

- **Concept:** **Schema Linking / Semantic Parsing**
  - **Why needed here:** The "Query Translation" step maps natural language (e.g., "slightly delayed") to specific schema values or bins in the BN. This is the primary failure point cited in the paper.
  - **Quick check question:** How would you handle a user query that uses a synonym not present in the table schema or the BN node names?

## Architecture Onboarding

- **Component map:** Raw Table → **BN Constructor** → Bayesian Network (CPTs + Structure) → **LLM Translator** → Formal Probabilistic Query → **Inference Engine** → Probability Score → **LLM Generator** → Natural Language Answer

- **Critical path:** The **Query Translation** step. The paper notes that while Auto-BN is accurate, failures occur when the LLM misidentifies nodes/states from natural language (Sec 5.2). If the translation maps "high revenue" to the wrong bin, the inference engine returns a precise but incorrect probability.

- **Design tradeoffs:**
  - **Exact vs. Approximate:** The paper uses **Exact Inference** on a learned BN. This ensures mathematical rigor but requires the BN structure to fit in memory.
  - **Generalization vs. Specificity:** The system is data-driven (learns from specific tables). It does not generalize to answer questions about data *not* in the table unless the LLM hallucinates (which the architecture tries to prevent).

- **Failure signatures:**
  - **Error Rate:** The system returns a fallback value (uniform prior) or errors out.
  - **Spurious Precision:** The system returns a confident probability (e.g., 0.0 or 1.0) because the NL2SQL fallback returned no rows (Sec 5.4) or the translation was rigid.
  - **Node Mismatch:** The LLM translator maps a query to a node that doesn't exist in the graph.

- **First 3 experiments:**
  1. **Sanity Check (Translation Accuracy):** Input a set of "Natural" questions and manually verify if the LLM Translator identifies the correct Target Variable and Evidence Variables. Do not run inference yet; just check the mapping.
  2. **Ablation (Inference vs. LLM):** Compare Auto-BN against a "LLM+Table" baseline on a small subset of the LUCARIO benchmark. Verify that Auto-BN has a lower MAE (Mean Absolute Error).
  3. **Scalability Test:** Run the BN Constructor on the largest table in the benchmark (e.g., `coinmarketcap` with 4.4M rows). Measure the time taken to learn the structure and perform inference to ensure latency is acceptable.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can external knowledge or semantic priors be integrated into the Bayesian Network induction process to overcome the limitations of a purely data-driven approach?
- **Basis in paper:** [explicit] The authors state in the Limitations section (Section 7) that the framework "operates in a purely data-driven manner and does not incorporate external knowledge or semantic priors."
- **Why unresolved:** The current implementation relies exclusively on patterns observed in the tabular data, potentially missing common-sense relationships or domain knowledge not explicitly present in the dataset rows.
- **What evidence would resolve it:** A modified framework that successfully incorporates ontologies or external knowledge graphs during structure learning, resulting in more accurate network topologies or higher QA performance on data-sparse domains.

### Open Question 2
- **Question:** To what extent do the edges in the auto-induced Bayesian Networks represent true causal mechanisms versus statistical correlations?
- **Basis in paper:** [explicit] The authors acknowledge in Section 7 that "causal factors may be latent, unmeasured, or external," meaning the learned edges "might be a mixture of 'causal' and 'correlation'."
- **Why unresolved:** The structure learning algorithms used cannot distinguish between causation and correlation using observational data alone, especially when confounders are not present in the table schema.
- **What evidence would resolve it:** A study utilizing interventional data (rather than just observational) to validate the directionality of edges, or the integration of causal discovery algorithms robust to latent confounders.

### Open Question 3
- **Question:** How can the Natural Language to Probabilistic Query translation step be stabilized to eliminate the error rate observed in the Auto-BN framework?
- **Basis in paper:** [inferred] Table 4 shows Auto-BN has a non-zero error rate (6.5% for GPT-4o), and Section 5.2 explicitly attributes this to failures where "the LLM’s ability to accurately map natural language queries to appropriate nodes and states" falls short.
- **Why unresolved:** The framework currently relies on general-purpose LLMs for the translation step, which introduces a point of failure where the model fails to generate a valid structured query.
- **What evidence would resolve it:** The development of a specialized translation module or error-correction mechanism that reduces the Error Rate metric to 0% without degrading the Mean Absolute Error (MAE).

## Limitations
- The exact Bayesian Network structure learning algorithm and its hyperparameters are not specified, making faithful reproduction challenging.
- The LLM prompts for query translation and answer verbalization are not provided, which could significantly impact the system's performance.
- The discretization/binning strategy for numeric columns and state naming conventions are not detailed, potentially affecting the accuracy of the induced Bayesian Networks.

## Confidence
- **High Confidence:** The overall approach of decoupling semantic parsing from probabilistic calculation improves calibration and reduces hallucination compared to pure LLM reasoning.
- **Medium Confidence:** The compression of statistical premises into "Insights" using Markov Blankets effectively bridges the gap between large data distributions and limited LLM context windows.
- **Low Confidence:** The system's ability to generalize to answer questions about data not present in the table without relying on LLM hallucination.

## Next Checks
1. **Translation Accuracy Validation:** Manually verify the LLM Translator's ability to accurately map natural language queries to the correct target variable and evidence conditions in the Bayesian Network for a diverse set of "Natural" questions.
2. **Baseline Comparison Replication:** Replicate the comparison between Auto-BN and the LLM+Table baseline on a subset of the LUCARIO benchmark to verify the reported performance gap in MAE.
3. **Scalability Assessment:** Test the BN Constructor's performance on the largest table in the LUCARIO benchmark (`coinmarketcap` with 4.4M rows) to assess the framework's scalability and identify any potential bottlenecks in structure learning or inference.