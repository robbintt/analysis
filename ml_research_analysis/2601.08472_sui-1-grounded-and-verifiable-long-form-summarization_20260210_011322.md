---
ver: rpa2
title: 'sui-1: Grounded and Verifiable Long-Form Summarization'
arxiv_id: '2601.08472'
source_url: https://arxiv.org/abs/2601.08472
tags:
- training
- arxiv
- sui-1
- source
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents sui-1, a 24B parameter model trained for citation-grounded
  summarization. The key innovation is a synthetic data generation pipeline that combines
  chain-of-thought prompting with multi-stage verification to create over 22,000 training
  examples across five languages.
---

# sui-1: Grounded and Verifiable Long-Form Summarization

## Quick Facts
- arXiv ID: 2601.08472
- Source URL: https://arxiv.org/abs/2601.08472
- Authors: Benedikt Droste; Jan Philipp Harries; Maximilian Idahl; Björn Plüster
- Reference count: 17
- sui-1 achieves 84.2% overall accuracy on LLM-as-a-judge evaluation, significantly outperforming all open-weight baselines including models with 3× more parameters (42.7–56.6%)

## Executive Summary
sui-1 is a 24B parameter model specifically trained for citation-grounded summarization that produces abstractive summaries with inline XML citations enabling users to trace each claim to its source sentence. The key innovation is a synthetic data generation pipeline that combines chain-of-thought prompting with multi-stage verification to create over 22,000 training examples across five languages. Evaluation demonstrates that sui-1 significantly outperforms open-weight baselines on both accuracy and format compliance, with FP8 quantization reducing memory by 50% while maintaining performance.

## Method Summary
The sui-1 model employs a synthetic data generation pipeline that creates training examples through chain-of-thought prompting followed by multi-stage verification to ensure quality and reduce hallucinations. The model generates abstractive summaries with inline XML citations that allow users to trace each claim back to its source sentence in the original document. Training was conducted on over 22,000 examples across five languages, with the model specifically optimized for long-form document summarization tasks. FP8 quantization was implemented to reduce memory requirements while maintaining performance levels.

## Key Results
- sui-1 achieves 84.2% overall accuracy on LLM-as-a-judge evaluation, significantly outperforming all open-weight baselines
- Format compliance improves dramatically from 13.7–41.1% in baselines to 89.5% with sui-1
- FP8 quantization reduces memory usage by 50% with only 3.7% performance degradation

## Why This Works (Mechanism)
The synthetic data generation pipeline with multi-stage verification creates high-quality training examples that capture the complex relationship between source documents and citation-grounded summaries. The chain-of-thought prompting approach helps the model reason through the summarization process while maintaining factual accuracy. The XML citation format provides explicit traceability between claims and source sentences, enabling both automated verification and user trust. Task-specific training on this specialized format substantially outperforms simply scaling up model parameters, demonstrating that architectural optimization for the specific task yields better results than parameter count alone.

## Foundational Learning

**Chain-of-thought prompting**: Why needed - enables reasoning through complex summarization tasks while maintaining factual accuracy. Quick check - verify that intermediate reasoning steps align with final output.

**Multi-stage verification**: Why needed - reduces hallucinations and ensures quality in synthetic training data. Quick check - compare verification success rates across different verification strategies.

**XML citation formatting**: Why needed - provides explicit traceability between claims and source sentences for both automated evaluation and user verification. Quick check - validate that all citations correctly map to source document sentences.

**FP8 quantization**: Why needed - reduces memory requirements while maintaining performance for practical deployment. Quick check - measure accuracy degradation at different quantization levels.

**LLM-as-a-judge evaluation**: Why needed - provides scalable evaluation methodology for citation-grounded summarization quality. Quick check - validate judge consistency through inter-annotator agreement metrics.

## Architecture Onboarding

**Component Map**: Document input -> Chain-of-thought reasoning -> Summary generation -> XML citation insertion -> Multi-stage verification -> Final output

**Critical Path**: The most critical path is the chain-of-thought reasoning through to XML citation insertion, as this directly determines the factual accuracy and traceability of the final summary.

**Design Tradeoffs**: The model prioritizes citation accuracy and traceability over pure summary compression, sacrificing some summarization fluency to ensure each claim can be verified against source material. This tradeoff is essential for the grounded summarization task but may reduce performance on standard abstractive summarization benchmarks.

**Failure Signatures**: Common failure modes include incorrect citation mapping (citing wrong source sentences), incomplete coverage of source document content, and occasional factual hallucinations that bypass the verification stages. These typically manifest as either missing or incorrect XML tags in the output.

**First Experiments**:
1. Test citation accuracy by providing source documents with known fact patterns and verifying XML citations map correctly
2. Evaluate summary coherence independently of citation accuracy to isolate format compliance issues
3. Compare performance on documents with varying lengths to assess the model's ability to handle different document scales

## Open Questions the Paper Calls Out
None

## Limitations
- Synthetic data generation pipeline may introduce systematic biases through chain-of-thought prompting approach
- Heavy reliance on LLM-as-a-judge evaluation methodology introduces potential circularity issues
- 84.2% overall accuracy metric combines multiple aspects but weighting between components is not clearly specified

## Confidence
- **High confidence**: Format compliance improvement from 13.7-41.1% to 89.5% is well-supported by results and represents clear, measurable advancement
- **Medium confidence**: Overall accuracy metric of 84.2% is meaningful but requires careful interpretation given LLM-as-a-judge methodology
- **Medium confidence**: Claim that task-specific training substantially outperforms scale alone is supported but would benefit from additional baseline comparisons

## Next Checks
1. Conduct human evaluation on a diverse set of long-form documents beyond QMSum to assess real-world generalization and identify potential systematic biases in synthetic data generation
2. Implement ablation studies removing different components of the synthetic data pipeline to quantify the contribution of each stage to final performance
3. Compare sui-1 against additional state-of-the-art citation-grounded summarization models that may use different architectural approaches or training strategies