---
ver: rpa2
title: Reducing Hallucinations in Language Model-based SPARQL Query Generation Using
  Post-Generation Memory Retrieval
arxiv_id: '2502.13369'
source_url: https://arxiv.org/abs/2502.13369
tags:
- query
- sparql
- pgmr
- memory
- uris
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of hallucinations in large language
  model (LLM)-generated SPARQL queries for knowledge graph question answering. The
  authors propose PGMR (Post-Generation Memory Retrieval), a modular framework that
  separates query structure generation from URI resolution.
---

# Reducing Hallucinations in Language Model-based SPARQL Query Generation Using Post-Generation Memory Retrieval

## Quick Facts
- arXiv ID: 2502.13369
- Source URL: https://arxiv.org/abs/2502.13369
- Reference count: 11
- Primary result: PGMR framework eliminates URI hallucinations by separating query structure generation from URI resolution

## Executive Summary
This paper addresses the problem of hallucinations in large language model (LLM)-generated SPARQL queries for knowledge graph question answering. The authors propose PGMR (Post-Generation Memory Retrieval), a modular framework that separates query structure generation from URI resolution. The LLM first generates an intermediate query with natural language placeholders for URIs, then a non-parametric retriever replaces these placeholders with accurate KG URIs from memory. Experiments across multiple datasets and LLMs show PGMR significantly improves query correctness (SQM) while achieving near-complete elimination of URI hallucinations.

## Method Summary
The method transforms SPARQL queries into SPARQL-PGMR format by replacing all URIs with natural language placeholders tagged with `[ENT]` or `[REL]` labels and descriptions. An LLM generates intermediate queries using these placeholders, then a retriever (BGE encoder + FAISS) maps each placeholder to exact URIs from entity/ontology memories. A confidence threshold enables refusal when no suitable URI exists. The approach is evaluated against direct generation and RAG baselines on LCQUAD 2.0 and QALD-10 datasets using metrics including SQM, F1, URI hallucination rate, and answer correctness.

## Key Results
- PGMR achieves near-complete elimination of URI hallucinations across all tested datasets and LLMs
- SQM improvements of 10-20% over direct generation baselines while maintaining low hallucination rates
- Retrieval confidence threshold enables effective refusal of unsupported queries with minimal performance impact
- PGMR maintains performance with 9× memory size increase, showing strong robustness to memory scaling

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Separating query structure generation from URI resolution nearly eliminates URI hallucinations.
- **Mechanism:** The LLM generates an intermediate SPARQL-PGMR query where all URIs are replaced with natural language placeholders. A non-parametric retriever then maps each placeholder to an exact URI from a knowledge graph memory via embedding similarity. Since URIs can only originate from the grounded memory—not the LLM's parametric knowledge—hallucinated identifiers are structurally impossible.
- **Core assumption:** The LLM can accurately express required entities/relations in natural language even when it does not know their formal URIs.
- **Evidence anchors:**
  - [abstract] "PGMR significantly enhances query correctness... while achieving the near-complete suppression of URI hallucinations."
  - [section 6, Results] "PGMR achieves a near-complete elimination of the URI hallucination problem regardless of the LLM, dataset, and data distribution used."
- **Break condition:** If the LLM fails to generate accurate natural language descriptions for entities, the retriever will match incorrect URIs.

### Mechanism 2
- **Claim:** Post-generation retrieval achieves higher retrieval fidelity than pre-generation RAG because placeholders align better with memory structure than raw questions.
- **Mechanism:** In RAG, the retriever matches the original question to URI metadata—a weak semantic signal. In PGMR, the LLM first produces explicit labels and descriptions in a structured format that mirrors the memory schema. This narrows the embedding distance between query and target, improving retrieval accuracy.
- **Core assumption:** The LLM can produce descriptions that are semantically closer to canonical KG metadata than the original question text.
- **Evidence anchors:**
  - [section 1, Introduction] "By producing these placeholders in a format that directly mirrors the non-parametric memory, PGMR achieves significantly higher latent similarity compared to RAG."
  - [section 4, PGMR] "This design enables LLMs to focus on generating syntactically correct query structures, while deferring the grounding of placeholders to precise URIs to a post-generation retrieval step."
- **Break condition:** If the LLM generates vague or ambiguous descriptions, retrieval precision degrades regardless of timing.

### Mechanism 3
- **Claim:** A retrieval confidence threshold enables safe refusal when the knowledge graph lacks required URIs.
- **Mechanism:** The retriever returns a similarity score for each resolved URI. If the top candidate falls below a threshold, the system refuses rather than returning a low-confidence match. This converts potential hallucinations into explicit "unknown" signals.
- **Core assumption:** Retrieval similarity scores correlate with correctness; low scores indicate absence from memory rather than embedding noise.
- **Evidence anchors:**
  - [abstract] "A retrieval confidence threshold enables PGMR to effectively refuse to answer queries that lack support."
  - [section 7, Answer Refusal Experiment] "Figure 2a demonstrates a clear positive correlation between the confidence threshold and refusal accuracy."
- **Break condition:** If confidence scores are poorly calibrated, the system may refuse answerable queries or accept incorrect matches.

## Foundational Learning

- **Concept:** SPARQL query structure (SELECT, WHERE, triple patterns)
  - **Why needed here:** PGMR requires the LLM to generate syntactically valid SPARQL with placeholders; understanding basic syntax is prerequisite to debugging intermediate outputs.
  - **Quick check question:** Given `SELECT ?x WHERE { ?x wdt:P31 wd:Q5 }`, what does the triple pattern match?

- **Concept:** Wikidata URI types (Q-ids for entities, P-ids for properties)
  - **Why needed here:** The paper explicitly targets non-semantic URIs that force LLMs to rely on parametric memory; understanding this motivates the retrieval design.
  - **Quick check question:** What is the difference between `wd:Q76` and `wdt:P26` in Wikidata?

- **Concept:** Embedding-based similarity search (FAISS, BGE encoder)
  - **Why needed here:** The retriever resolves placeholders via nearest-neighbor search in embedding space; understanding this is essential for tuning thresholds and memory scaling.
  - **Quick check question:** If two URI descriptions have cosine similarity 0.92, what does that imply about their semantic relationship?

## Architecture Onboarding

- **Component map:** Question → LLM → intermediate query → placeholder extraction → embedding → FAISS retrieval → confidence check → URI substitution → final SPARQL
- **Critical path:** Question → LLM → intermediate query → placeholder extraction → embedding → FAISS retrieval → confidence check → URI substitution → final SPARQL. If confidence check fails, return refusal.
- **Design tradeoffs:**
  - Higher confidence threshold → more refusals, fewer incorrect answers (Figure 2a/2b tradeoff)
  - Larger memory → more noise, slight SQM drop (~4% at 9× scale, Figure 3)
  - PGMR vs RAG: PGMR adds negligible latency (k × 0.0016s retrieval vs 0.9s generation), but requires training data transformation
- **Failure signatures:**
  - Non-zero URI hallucination rate → memory incomplete or LLM generates unparseable placeholders
  - Low SQM despite zero hallucinations → query structure is wrong (LLM limitation, per Limitations section on QALD-10)
  - High refusal rate on valid queries → threshold too aggressive or memory missing key entities
- **First 3 experiments:**
  1. **Baseline comparison:** Run Direct Generation, RAG, and PGMR on LCQUAD 2.0 original split; compare SQM, URI hallucination rate, and F1
  2. **Confidence threshold sweep:** Vary threshold from 0.70–0.95; plot refusal accuracy vs SQM to find optimal operating point (~0.85 per paper)
  3. **Memory scaling stress test:** Expand entity memory 2×, 4×, 9× with random Wikidata entities; measure SQM degradation to validate retriever robustness

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the confidence threshold for query refusal be optimized dynamically via a trainable neural network?
- **Basis in paper:** [explicit] Section 7 mentions the threshold "can potentially be learned by adding a small neural network... but we leave this exploration for future work."
- **Why unresolved:** The current implementation relies on a statically determined threshold (0.85) identified through empirical analysis.
- **What evidence would resolve it:** Implementation of a sigmoid head on the retriever encoder and comparison of refusal accuracy/SQM trade-offs against the static baseline.

### Open Question 2
- **Question:** Does combining RAG and PGMR (retrieval steps before and after generation) improve structural accuracy for complex queries?
- **Basis in paper:** [explicit] The authors state in the Limitations section that future work includes "combining the advantages of RAG and PGMR, adding a retrieval step both before and after generation."
- **Why unresolved:** The current study evaluates PGMR in isolation against RAG baselines, but does not test a hybrid approach.
- **What evidence would resolve it:** Experiments running a hybrid system on complex datasets (e.g., QALD-10) to compare structural error rates against PGMR alone.

### Open Question 3
- **Question:** Can PGMR overcome structural generation limitations when applied to larger models specifically pre-trained on SPARQL data?
- **Basis in paper:** [explicit] The Limitations section suggests addressing structural errors by using "more powerful, large LLMs pre-trained specifically on SPARQL query data."
- **Why unresolved:** The experiments primarily used T5-Small and Llama 3.1 8B, which struggled with the complex syntax of QALD-10.
- **What evidence would resolve it:** Evaluation of PGMR using larger, SPARQL-specialized foundation models on the QALD-10 dataset to assess improvements in Semantic Query Match (SQM).

## Limitations
- The method does not address hallucination in query structure generation itself, only URI resolution
- The robustness claim (9× memory scaling) shows only modest performance degradation without analysis of underlying causes
- The comparison against RAG baselines assumes similar retriever quality but does not control for retrieval hyperparameters like k or reranker use

## Confidence
- **High confidence:** PGMR's mechanism for eliminating URI hallucinations through structural separation is sound and empirically validated across multiple datasets and LLMs
- **Medium confidence:** The retrieval confidence threshold effectively enables safe refusal behavior, though the correlation between similarity scores and correctness could be dataset-dependent
- **Medium confidence:** The claim that PGMR outperforms RAG due to better alignment between intermediate queries and memory structure is plausible but lacks direct quantitative comparison of embedding distances

## Next Checks
1. **Cross-dataset hallucination analysis:** Evaluate PGMR on a dataset with different entity distributions (e.g., DBpedia) to test generalizability of near-complete URI hallucination elimination
2. **Confidence calibration study:** Perform manual annotation of low-confidence retrievals to verify whether low scores correspond to actual memory gaps versus embedding noise
3. **Query structure robustness test:** Systematically inject structural errors into intermediate queries to measure how often PGMR produces syntactically valid SPARQL versus relying on retrieval to salvage malformed queries