---
ver: rpa2
title: Scaling sparse feature circuit finding for in-context learning
arxiv_id: '2504.13756'
source_url: https://arxiv.org/abs/2504.13756
tags:
- task
- features
- feature
- learning
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work demonstrates that sparse autoencoders (SAEs) can effectively
  analyze the in-context learning (ICL) mechanism in large language models. The authors
  develop a Task Vector Cleaning (TVC) algorithm to decompose task vectors into interpretable
  SAE features, identifying task-execution features that causally induce task performance.
---

# Scaling sparse feature circuit finding for in-context learning

## Quick Facts
- arXiv ID: 2504.13756
- Source URL: https://arxiv.org/abs/2504.13756
- Reference count: 40
- Key outcome: Sparse autoencoders (SAEs) effectively analyze in-context learning (ICL) mechanism in large language models, identifying task-detection and task-execution features with causal efficacy.

## Executive Summary
This work demonstrates that sparse autoencoders can effectively analyze the in-context learning (ICL) mechanism in large language models. The authors develop a Task Vector Cleaning (TVC) algorithm to decompose task vectors into interpretable SAE features, identifying task-execution features that causally induce task performance. They adapt the Sparse Feature Circuits (SFC) methodology to the larger Gemma-1 2B model, discovering task-detection features that identify required tasks from earlier prompt information. The analysis reveals that attention heads and MLPs process information from task-detection features to activate appropriate task-execution features, demonstrating the interdependence of these components in the ICL circuit. The approach successfully scales circuit analysis to models 30 times larger than previously studied, providing unprecedented mechanistic detail about how language models perform in-context learning.

## Method Summary
The method involves training Gated SAEs (converted to JumpReLU) on Gemma-1 2B for residual streams, attention outputs, and MLP transcoders across all 18 layers. Task vectors are extracted from layer 12 arrow tokens in 16-shot ICL prompts. The TVC algorithm then optimizes SAE weights to minimize task loss plus L1 sparsity penalty, producing sparse, causal feature sets. SFC is adapted with token-type aggregation and attribution patching for IE approximation, focusing on layers 10-17 to identify detection-to-execution feature circuits. Steering experiments validate feature causal efficacy, while ablation studies confirm task specificity and circuit completeness.

## Key Results
- TVC successfully decomposes task vectors into 2-4 interpretable features per task, reducing active features by 50-80% while maintaining causal task effects
- Task-detection features activate on output tokens (96.76% of max-activations) while task-execution features activate on arrow tokens (89.80% of max-activations)
- Attention heads and MLPs process information from detection features to activate corresponding execution features, with circuits achieving 0.6 faithfulness at 500 nodes
- SFC methodology scales to Gemma-1 2B (30× larger than previous studies) with maintained IE approximation quality in layers 10-17

## Why This Works (Mechanism)

### Mechanism 1: Task Vector Decomposition via Sparse Optimization
- Claim: Task vectors can be decomposed into interpretable sparse SAE features that retain causal efficacy for inducing task behavior.
- Mechanism: The Task Vector Cleaning (TVC) algorithm initializes SAE weights from task vector encoding, then iteratively optimizes them to minimize task loss on zero-shot prompts plus an L1 sparsity penalty. This yields 2-4 relevant features per task from initially noisy 10-20 feature reconstructions.
- Core assumption: Task vectors lie approximately in the span of task-relevant SAE features; the SAE latent space contains directions that encode abstract task knowledge.
- Evidence anchors:
  - [abstract] "We further demonstrate that these task vectors are well approximated by a sparse sum of SAE latents, including these task-execution features."
  - [Section 3.1] TVC achieves 50-80% reduction in active features while maintaining task loss effects across Gemma-1 2B, Gemma-2, and Phi-3 models.
  - [corpus] Related work (Hendel et al., Todd et al.) established task vectors exist but did not decompose them into interpretable components.

### Mechanism 2: Two-Stage Detection-Execution Circuit
- Claim: ICL is mediated by a causal circuit where task-detection features (activating on output tokens) drive task-execution features (activating on arrow tokens) through attention and MLP layers.
- Mechanism: Detection features identify the task from completed examples in the prompt → information flows through attention heads and transcoders → corresponding execution features activate → these features induce task-appropriate predictions on new inputs.
- Core assumption: ICL involves discrete task recognition rather than continuous task learning; features can be functionally separated into detection and execution roles with a directional causal flow.
- Evidence anchors:
  - [abstract] "They are causally linked with task-execution features through the attention and MLP sublayers."
  - [Section 4.2] Ablating detection features substantially reduces execution feature activations; Table 2 shows detection features activate 96.76% on output tokens vs. execution features at 89.80% on arrow tokens.

### Mechanism 3: Scaling Sparse Feature Circuits via Token-Type Aggregation
- Claim: The SFC methodology can be adapted to 30× larger models by categorizing features by token position type and modifying the loss function to handle structured ICL prompts.
- Mechanism: Token positions are categorized (prompt, input, arrow, output, newline) → effects aggregated across same-type tokens → loss computed on all pairs except first (amplifying task-solving vs. copying circuits) → attribution patching approximates indirect effects efficiently.
- Core assumption: Features serving similar functional roles activate on similar token types; aggregating across token types preserves causal structure while reducing graph complexity.
- Evidence anchors:
  - [abstract] "We adapt the sparse feature circuits methodology of Marks et al. (2024) to work for the much larger Gemma-1 2B model, with 30 times as many parameters."
  - [Section 4.1.3] Circuits of 500 nodes achieve faithfulness of 0.6; focusing on layers 11-12 requires only 10-60 nodes.

## Foundational Learning

- **Task Vectors (from Hendel et al. 2023, Todd et al. 2024)**
  - Why needed here: The entire analysis decomposes task vectors; understanding that ICL creates internal task representations extractable from residual streams is prerequisite.
  - Quick check question: Explain why averaging residual stream activations at arrow tokens across few-shot prompts yields a vector that can induce zero-shot task performance when injected elsewhere.

- **Sparse Autoencoders for Decomposition**
  - Why needed here: SAEs convert dense, polysemantic activations into sparse, interpretable features; this decomposition enables the circuit analysis.
  - Quick check question: Why does enforcing L0 sparsity in the encoder hidden layer yield more interpretable features than direct reconstruction?

- **Attribution Patching for Indirect Effects**
  - Why needed here: Efficiently estimating causal effects of thousands of features requires gradient-based approximation rather than exhaustive ablation.
  - Quick check question: How does the gradient of the metric with respect to activations approximate the effect of ablating those activations?

## Architecture Onboarding

- **Component map:**
  - Gemma-1 2B (18 layers) -> Pre-trained SAEs (residual, attention, transcoder) -> TVC algorithm (task vector cleaning) -> SFC pipeline (token-type aggregation, attribution patching) -> Feature circuits (detection -> execution)

- **Critical path:**
  1. Load pre-trained SAEs (or train: ~3 hours per layer on v4 TPU)
  2. Identify target layer via task vector steering sweep (layer 12 for Gemma-1)
  3. Run TVC to extract task-execution features per task
  4. Apply modified SFC on layers 10-17 with token-type nodes
  5. Validate: (a) steering experiments for causal efficacy, (b) max-activating examples for interpretability, (c) ablation for faithfulness

- **Design tradeoffs:**
  - **L1 coefficient (λ):** Higher → sparser but may lose causal efficacy; 0.001-0.025 recommended range
  - **Circuit size vs. faithfulness:** 500 nodes yields 0.6 faithfulness; smaller circuits are more interpretable but less complete
  - **Layer range:** Restricting to layers 10-17 improves IE approximation quality (correlation >0.5) but may miss early-layer processing
  - **SAE width:** 65k features capture more granular task features than 16k but require more computation

- **Failure signatures:**
  - TVC produces features with high L0 but no task-specific steering effect → L1 too aggressive or SAE doesn't encode task directions
  - Max-activating examples are semantically unrelated to task → SAE quality issues or wrong layer selection
  - Ablation of detection features doesn't reduce execution activations → causal connection weaker than expected, or different circuit architecture
  - IE correlation <0.3 in target layers → attribution patching unreliable; consider path patching alternatives

- **First 3 experiments:**
  1. **Single-task TVC replication:** Take antonym task, collect 16-shot task vectors at layer 12, run TVC with λ ∈ {0.001, 0.005, 0.01}, measure (a) feature count reduction, (b) relative loss improvement on held-out pairs
  2. **Feature interpretability check:** For top-3 features per task, extract max-activating examples from FineWeb; manually verify semantic alignment with task (e.g., antonym features should activate near word pairs with opposite meanings)
  3. **Cross-task steering specificity:** Steer zero-shot prompts for task A with features from task A vs. task B; plot heatmap of loss changes (diagonal should dominate if features are task-specific)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why do person profession and present simple gerund tasks show unusually weak detection-execution feature connections compared to other tasks?
- Basis in paper: [explicit] The authors state these "two tasks diverged from this pattern... showing unusually weak detection-execution connections, suggesting a need for deeper investigation" (Section 4.2).
- Why unresolved: The paper identifies this divergence but does not explain whether it stems from task complexity, data distribution, or fundamentally different circuit architectures for these tasks.
- What evidence would resolve it: Detailed layer-by-layer analysis of these specific tasks, comparison of their pretraining data frequency, and investigation of whether alternative detection features exist at different layers.

### Open Question 2
- Question: Do the discovered task-detection and task-execution features generalize to more complex ICL scenarios beyond the simple task vector setting?
- Basis in paper: [explicit] The limitations section notes "our analysis focused on the simple task vector setting to study in-context learning, which represents only a subset of ICL applications in practice."
- Why unresolved: The study only examined simple token-to-token tasks (antonyms, translation, etc.) with 3-4 shot prompts; real-world ICL involves longer contexts, more complex reasoning, and multi-step tasks.
- What evidence would resolve it: Applying the same SFC methodology to tasks requiring multi-hop reasoning, longer context windows, and more diverse prompt structures.

### Open Question 3
- Question: What causes the poor indirect effect approximation quality in early layers (before layer 6), and can it be improved?
- Basis in paper: [explicit] "We need to note that we constrained our circuit search to intermediate layers 10-17... our analysis revealed lower quality in IE approximations for these earlier layers" (Section 4.1.3).
- Why unresolved: The paper notes this may be due to "the quality of our trained SAEs, the increased task complexity, or token type-wise aggregation, and warrants further investigation" (Appendix E.2).
- What evidence would resolve it: Ablation studies comparing different SAE architectures, training procedures, and aggregation methods specifically on early layers.

## Limitations
- Task vector analysis limited to 23 specific tasks from Todd et al. (2024), leaving generalization to other ICL scenarios uncertain
- Poor indirect effect approximation quality in early layers (before layer 6) constrains circuit analysis to intermediate layers
- Two tasks (person profession and present simple gerund) show unusually weak detection-execution connections, suggesting potential circuit architecture variations

## Confidence
- **High Confidence**: Successful application of TVC to decompose task vectors into sparse, causal features (Section 3). Identification of task-detection and task-execution features with distinct activation patterns (Section 4.2). Adaptation of SFC methodology to Gemma-1 2B with maintained faithfulness (Section 4.1).
- **Medium Confidence**: Causal link between detection and execution features through attention and MLP layers. Claim that these circuits represent the primary mechanism for in-context learning across the studied tasks. Generalizability of findings to other model architectures or task types.
- **Low Confidence**: Completeness of the identified circuits (potential missing components). Extent to which SAE features capture all relevant task-relevant information versus serving as proxies for distributed representations. Robustness of findings across different SAE training configurations.

## Next Checks
1. **Cross-Model Circuit Consistency**: Apply the same TVC and SFC methodology to Phi-3 and Gemma-2 models, then compare the resulting circuits for structural similarity and feature overlap. This would validate whether the detection-execution architecture is a fundamental property of ICL rather than model-specific.

2. **Negative Steering Experiments**: Systematically test whether steering with task-specific features from one task negatively affects performance on semantically related but distinct tasks (e.g., steering with antonym features on synonym tasks). This would provide stronger evidence for feature specificity beyond positive steering results.

3. **Layer-Wise Attribution Patching Validation**: Quantify the degradation in attribution patching correlation across layers (particularly before layer 6) and compare with path patching on a subset of features. This would establish the reliability bounds of the IE approximation method and identify potential blind spots in the circuit analysis.