---
ver: rpa2
title: SAEs Are Good for Steering -- If You Select the Right Features
arxiv_id: '2505.20063'
source_url: https://arxiv.org/abs/2505.20063
tags:
- features
- steering
- output
- score
- input
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates Sparse Autoencoder (SAE) features for steering
  large language models (LLMs) and distinguishes between input features (capturing
  input patterns) and output features (directly influencing generated tokens). The
  authors introduce input and output scores to identify these feature types, finding
  that high values for both scores rarely co-occur.
---

# SAEs Are Good for Steering -- If You Select the Right Features

## Quick Facts
- **arXiv ID**: 2505.20063
- **Source URL**: https://arxiv.org/abs/2505.20063
- **Reference count**: 40
- **Primary result**: SAE steering becomes competitive with LoRA when filtering by output scores

## Executive Summary
This paper addresses the challenge of effectively steering large language models using Sparse Autoencoder (SAE) features. The authors discover that SAE features can be categorized into input features (capturing input patterns) and output features (directly influencing generated tokens). Through systematic analysis, they demonstrate that output-score-based feature selection dramatically improves steering effectiveness, achieving 2-3x improvements over unfiltered SAE steering. On the AxBench benchmark, their approach reaches 90.7% of the performance of the best supervised steering method (LoRA), establishing SAE steering as a viable alternative when proper feature selection is applied.

## Method Summary
The authors introduce a novel methodology for distinguishing between input and output SAE features using input and output scores. Input scores measure how much a feature's activation depends on the input text, while output scores measure how much a feature's activation influences the generated output distribution. By computing gradients with respect to inputs and outputs respectively, they identify features that are primarily input-focused versus those that directly affect token generation. The key insight is that features with high output scores are significantly more effective for steering tasks. The authors then filter SAE features based on their output scores, retaining only those with strong output influence while discarding features that are mainly input-focused.

## Key Results
- SAE steering achieves 2-3x improvement when filtering out low-output-score features
- On AxBench benchmark, filtered SAE steering reaches 90.7% of LoRA's performance
- High input and high output scores rarely co-occur, validating the distinction between feature types
- Output-score-based filtering makes SAE steering competitive with supervised methods

## Why This Works (Mechanism)
The effectiveness of SAE steering depends critically on selecting features that directly influence token generation rather than just capturing input patterns. By using output scores to identify these influential features, the method ensures that steering interventions target the most impactful aspects of the model's behavior. This targeted approach avoids the dilution of steering effects that occurs when including features that primarily respond to input patterns without significantly affecting output generation.

## Foundational Learning
- **Sparse Autoencoders (SAEs)**: Neural network components that learn compressed representations with sparse activations. Why needed: SAEs provide interpretable feature representations for steering. Quick check: Verify that learned features exhibit sparse activation patterns.
- **Input vs Output Features**: Features that capture input patterns versus those that influence outputs. Why needed: Understanding this distinction is crucial for effective steering. Quick check: Measure correlation between input and output scores across features.
- **Gradient-based Feature Scoring**: Using gradients to measure feature importance for inputs and outputs. Why needed: Provides quantitative measure for feature selection. Quick check: Validate gradient-based scores correlate with actual steering impact.
- **Steering Benchmark (AxBench)**: Standardized evaluation suite for comparing steering methods. Why needed: Enables fair comparison between SAE and supervised methods. Quick check: Ensure benchmark tasks cover diverse steering scenarios.

## Architecture Onboarding
- **Component Map**: Input text → SAE encoder → Feature activations → Feature selection (output score filter) → Feature manipulation → SAE decoder → Modified output distribution
- **Critical Path**: The feature selection step is critical - filtering by output scores determines steering effectiveness. Without proper filtering, SAE steering performs poorly regardless of other components.
- **Design Tradeoffs**: High sparsity vs. reconstruction quality tradeoff in SAE training affects feature quality. More features provide better coverage but increase computational cost. Feature selection threshold impacts steering precision vs. breadth.
- **Failure Signatures**: Poor steering performance when too many low-output-score features are included. Complete failure when feature selection is disabled. Suboptimal performance when threshold is set too conservatively.
- **First Experiments**: 1) Verify output scores correlate with actual steering impact through ablation studies. 2) Test feature selection threshold sensitivity on steering performance. 3) Compare steering effectiveness across different SAE sparsity levels.

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Evaluation focuses primarily on steering tasks, leaving generalizability to other SAE applications unclear
- Feature selection methodology assumes output scores reliably indicate steering utility across different architectures
- Does not address potential trade-offs between steering effectiveness and feature interpretability
- Limited investigation of stability and robustness of steering performance

## Confidence
- **High confidence**: Empirical finding that output-score-based filtering improves steering performance
- **Medium confidence**: Theoretical explanation linking output scores to steering effectiveness
- **Medium confidence**: Generalizability of findings to SAE applications beyond steering

## Next Checks
1. Test whether output-score-based filtering maintains effectiveness across different model families (GPT-4, Claude) and SAE architectures
2. Investigate correlation between feature interpretability and steering effectiveness when using output-score filtering
3. Evaluate stability of steering performance using output-score subsets versus alternative selection methods like mutual information or causal intervention