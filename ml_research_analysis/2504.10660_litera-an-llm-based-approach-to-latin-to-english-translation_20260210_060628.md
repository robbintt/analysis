---
ver: rpa2
title: 'LITERA: An LLM Based Approach to Latin-to-English Translation'
arxiv_id: '2504.10660'
source_url: https://arxiv.org/abs/2504.10660
tags:
- translation
- latin
- litera
- translations
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "LITERA is a multi-layered LLM-based platform for translating Latin\
  \ to English that addresses the challenges of Latin\u2019s complex case-marking\
  \ and free word order. It uses a fine-tuned GPT-4o-mini to generate multiple literal\
  \ translations, then applies iterative GPT-4o revision layers to select and refine\
  \ the best translation."
---

# LITERA: An LLM Based Approach to Latin-to-English Translation

## Quick Facts
- arXiv ID: 2504.10660
- Source URL: https://arxiv.org/abs/2504.10660
- Authors: Paul Rosu
- Reference count: 16
- Key outcome: Multi-layer LLM platform achieving BLEU 57.93 and BLEURT 0.67 on classical Latin, significantly outperforming prior models and commercial translators

## Executive Summary
LITERA is a multi-layered LLM-based platform for translating Latin to English that addresses the challenges of Latin's complex case-marking and free word order. It uses a fine-tuned GPT-4o-mini to generate multiple literal translations, then applies iterative GPT-4o revision layers to select and refine the best translation. Trained on a small, high-quality dataset developed with Duke University's Classical Studies Department, LITERA achieves significantly higher BLEU (57.93) and BLEURT (0.67) scores on classical Latin than prior models and commercial translators. The system also handles early modern Latin and produces non-literal translations for readability, demonstrating strong performance and robustness across diverse Latin texts.

## Method Summary
LITERA uses a multi-layer pipeline: (1) 5 parallel translations from a fine-tuned GPT-4o-mini at temperature 0.7, (2) GPT-4o revision of each candidate, (3) GPT-4o selection of best translation via Final Filter prompt, and (4) GPT-4o final revision. The fine-tuned model is trained on ~200 high-quality literal Latin-English pairs with explicit case-marking and syntax preservation instructions. This produces grammatically-anchored, word-to-word translations that reduce early misinterpretations. The system is designed for literal (ad verbum) translation first, then optionally produces non-literal translations for readability. All prompts and code are available at https://github.com/paulrosu11/LITERA.

## Key Results
- Achieves BLEU 57.93 and BLEURT 0.67 on classical Latin test set, significantly higher than prior models and commercial translators
- Outperforms both GPT-4o-mini alone (27.61 BLEU) and GPT-4o alone when used as initial generator
- Handles early modern Latin with strong performance on University of Warwick's Neo-Latin anthology
- Ablation study shows each revision layer contributes ~25 BLEU points to final score

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A fine-tuned model optimized for literal translation produces better foundational candidates for downstream refinement than a stronger base model, even when that fine-tuned model underperforms in isolation.
- Mechanism: The fine-tuned GPT-4o-mini is trained on ~200 high-quality literal Latin-English pairs with explicit case-marking and syntax preservation instructions. This constrains initial outputs to grammatically-anchored, word-to-word translations that reduce early misinterpretations. GPT-4o, by contrast, tends to "smooth" or interpret Latin freely, introducing small errors that compound through refinement. The ablation study confirms: Fine-Tuned Only scores 27.61 BLEU vs. GPT-4o-mini's 28.43 in isolation, but when the fine-tuned model initiates the full pipeline, the final score jumps to 57.93—more than double.
- Core assumption: The revision layers (GPT-4o) are better at fixing surface-level awkwardness than correcting fundamental syntactic misinterpretations.
- Evidence anchors: [abstract]: "fine-tuned version of GPT-4o-mini"; [section 6.1]: "the fine-tuned model's intentionally literal approach anchors subsequent steps. GPT-4o, by contrast, often smooths or interprets Latin text more freely"; [corpus]: Weak direct evidence; corpus focuses on document-level MT and hallucination mitigation, not literal-first fine-tuning for classical languages.
- Break condition: If your target domain rewards fluent, interpreted translation over grammatical traceability, this mechanism's value diminishes.

### Mechanism 2
- Claim: Generating multiple translation candidates in parallel and selecting the best substantially improves output quality by exploiting LLM stochasticity.
- Mechanism: At temperature 0.7, five parallel instances of the fine-tuned model produce varied outputs. A GPT-4o "final filter" prompted with few-shot examples selects the most accurate literal translation. This exploits the nondeterministic nature of LLMs—errors are unlikely to be identical across all five attempts, increasing the probability that at least one candidate is correct.
- Core assumption: The filter model can reliably identify the best translation among candidates.
- Evidence anchors: [section 3.1]: "multiple instances of a fine-tuned GPT-4o-mini model... produces varied outputs"; [section 6.2]: removing revision/filter layers drops BLEU from 57.93 to ~31-32; [corpus]: Quality Estimation Reranking paper (arXiv:2510.08870) supports candidate selection approaches, though for document-level translation.
- Break condition: If API costs or latency constraints prevent multiple parallel calls, this mechanism becomes impractical.

### Mechanism 3
- Claim: Iterative revision layers provide compounding error correction that single-pass translation cannot achieve.
- Mechanism: After initial candidate generation, translations pass through (1) a middle revision layer, (2) final filter selection, and (3) a final revision layer. Each pass allows GPT-4o to catch case-marking errors, verb tense inconsistencies, and subject-object misalignments. Ablation confirms that removing either revision layer drops BLEU by ~25 points.
- Core assumption: Each revision layer has non-overlapping error detection capabilities.
- Evidence anchors: [section 6.2]: "Eliminating either the middle revisions ('No Middle Revision') or the final revision ('No Final Revision') degrades BLEU and BLEURT scores substantially"; [figure 1]: architecture flowchart shows layered revision process; [corpus]: No direct corpus validation for iterative LLM revision specifically.
- Break condition: If revisions introduce rather than fix errors (model drift), additional layers will degrade quality.

## Foundational Learning

- Concept: **BLEU and BLEURT metrics**
  - Why needed here: The paper relies entirely on BLEU (n-gram overlap) and BLEURT (learned semantic quality) for evaluation. Understanding what these metrics capture—and miss—is essential for interpreting the 57.93/0.67 scores.
  - Quick check question: Can you explain why a translation with high BLEU might still be semantically wrong?

- Concept: **Mixture-of-Agents (MoA) architecture**
  - Why needed here: LITERA's multi-layer design is explicitly inspired by MoA, where multiple LLM agents iteratively refine outputs. Understanding MoA helps clarify why parallel generation + aggregation works.
  - Quick check question: How does MoA differ from simple ensemble voting?

- Concept: **Latin case-marking and free word order**
  - Why needed here: The core challenge LITERA addresses is Latin's reliance on inflection (not position) for syntactic relationships. Without this, the emphasis on "literal" and "case-accurate" translation seems arbitrary.
  - Quick check question: In Latin, how would you identify the subject of "Puer puellam amat" vs. "Puellam puer amat"?

## Architecture Onboarding

- Component map:
Input Latin Text
       ↓
[5× Fine-tuned GPT-4o-mini] → 5 candidate translations (parallel, temp=0.7)
       ↓
[Middle Revision Layer] → GPT-4o refines each candidate
       ↓
[Final Filter] → GPT-4o selects best translation
       ↓
[Final Revision Layer] → GPT-4o polishes selected output
       ↓
Literal Translation Output
       ↓ (optional)
[Non-Literal Layer] → GPT-4o produces fluent version

- Critical path: Fine-tuned model initialization → parallel candidate generation → filter selection. Errors in the fine-tuned model's training data or prompt design propagate through all subsequent layers.

- Design tradeoffs:
  - Cost vs. quality: Full pipeline uses 7+ API calls per input (5 initial + revision + filter + final revision). The paper acknowledges funding constraints limited multi-run testing.
  - Literal accuracy vs. readability: The ad verbum approach prioritizes traceability over natural English. Non-literal mode is a separate, untested addition.
  - Small dataset vs. overfitting: Only ~200 training pairs; generalization to unseen Latin styles is uncertain.

- Failure signatures:
  - Pronoun gender errors (e.g., interpreting "ea" as feminine singular instead of neuter plural) suggest inadequate training on ambiguous forms.
  - Subjunctive mood mishandling indicates the model may lack deep grammatical understanding beyond pattern matching.
  - If BLEU >50 but translations feel "off," suspect the literal-first constraint is producing accurate-but-unusable output.

- First 3 experiments:
  1. **Reproduce ablation**: Run the full pipeline vs. "Fine-Tuned Only" vs. "No Middle Revision" on a 20-sentence held-out set. Compare BLEU/BLEURT drops to paper's reported ~25-point gaps.
  2. **Temperature sweep**: Test temperature values [0.3, 0.5, 0.7, 0.9] for candidate generation. The paper claims 0.7 is optimal but provides no data; verify this claim.
  3. **Cross-domain test**: Evaluate on a Latin genre not in training (e.g., medieval scholastic texts). Document BLEU degradation to assess generalization limits.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the statistical variance of LITERA's BLEU and BLEURT scores across multiple non-deterministic runs?
- Basis: [explicit] Section 10 (Limitations) states the authors were "limited by funding, preventing us from performing sufficient tests to produce detailed statistics beyond a single run."
- Why unresolved: LLMs are inherently non-deterministic (even with temperature settings), making single-run scores potentially unrepresentative of average performance.
- What evidence would resolve it: Reporting the mean and standard deviation of accuracy metrics over 10+ distinct translation runs on the same test set.

### Open Question 2
- Question: To what extent does expanding the fine-tuning dataset beyond 200 pairs improve generalizability to diverse Latin genres and time periods?
- Basis: [explicit] Section 10 notes that "reliance on a relatively small, high-quality dataset" limits effectiveness for styles or eras (like Early Modern Latin) not represented in the training data.
- Why unresolved: The authors prioritized high-quality, manually verified data over quantity, leaving the scaling benefits of larger datasets untested.
- What evidence would resolve it: Evaluating performance on out-of-distribution texts after incrementally increasing the training dataset size (e.g., 500, 1,000, 5,000 pairs).

### Open Question 3
- Question: Does the strict ad verbum (literal) approach in the initial layer constrain the semantic accuracy of the subsequent non-literal translation?
- Basis: [inferred] Section 3.6 states that "errors present in the literal translation are likely to be propagated into the non-literal output," and Section 10 acknowledges the trade-off between literal adherence and readability.
- Why unresolved: It is unclear if the multi-layered "literal-first" architecture acts as a stabilizing anchor or an error-propagation bottleneck for the final interpreted translation.
- What evidence would resolve it: Comparing the final output quality of LITERA against a similar pipeline prompted for fluency rather than literalness in the initial generation step.

## Limitations
- Heavy reliance on a small, high-quality training set (~200 pairs) limits scalability and generalization to unseen Latin styles
- Reported metrics are from a single run with no statistical validation or variance reporting
- Literal-first approach may produce translations that are accurate but not fluent, limiting usability for general readers
- Limited evidence of handling idiomatic or complex constructions outside training corpus

## Confidence
- **High**: The multi-layer architecture (parallel candidate generation + iterative revision) is well-justified by ablation results and consistent with Mixture-of-Agents literature
- **Medium**: The superiority of the fine-tuned GPT-4o-mini as an initial literal translator is plausible but not definitively proven; the ablation study is suggestive but indirect
- **Low**: Generalization claims to early modern Latin and the robustness of the non-literal output mode are not well-supported by systematic testing

## Next Checks
1. **Statistical validation of results**: Run the full LITERA pipeline on the classical Latin test set at least 5 times, reporting mean and standard deviation for BLEU and BLEURT. Compare against reported single-run scores and baselines.
2. **Cross-genre generalization test**: Evaluate LITERA on a distinct Latin genre (e.g., medieval scholastic or ecclesiastical Latin) not represented in the training or classical test sets. Report BLEU/BLEURT degradation to quantify domain sensitivity.
3. **Cost-benefit analysis of the multi-layer approach**: Measure the number of API calls, total cost, and latency for the full pipeline versus single-pass models. Assess whether quality gains justify the added complexity and expense.