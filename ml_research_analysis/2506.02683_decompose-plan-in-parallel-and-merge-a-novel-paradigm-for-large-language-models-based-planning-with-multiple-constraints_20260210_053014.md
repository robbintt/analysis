---
ver: rpa2
title: 'Decompose, Plan in Parallel, and Merge: A Novel Paradigm for Large Language
  Models based Planning with Multiple Constraints'
arxiv_id: '2506.02683'
source_url: https://arxiv.org/abs/2506.02683
tags:
- plan
- planning
- constraints
- dppm
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of multi-constraint planning
  in LLM-based agents, which suffer from heavy constraints and cascading errors. To
  overcome these limitations, the authors propose DPPM (Decompose, Plan in Parallel,
  and Merge), a novel paradigm that decomposes complex tasks into subtasks based on
  constraints, generates plans for each subtask in parallel using specialized local
  agents, and merges them into a coherent global plan.
---

# Decompose, Plan in Parallel, and Merge: A Novel Paradigm for Large Language Models based Planning with Multiple Constraints

## Quick Facts
- **arXiv ID:** 2506.02683
- **Source URL:** https://arxiv.org/abs/2506.02683
- **Reference count:** 18
- **Primary result:** DPPM achieves 58.9% final pass rate on TravelPlanner, outperforming baselines by 22.2-58.3%

## Executive Summary
This paper addresses the challenge of multi-constraint planning in LLM-based agents, which suffer from heavy constraints and cascading errors. To overcome these limitations, the authors propose DPPM (Decompose, Plan in Parallel, and Merge), a novel paradigm that decomposes complex tasks into subtasks based on constraints, generates plans for each subtask in parallel using specialized local agents, and merges them into a coherent global plan. DPPM also incorporates a verification and refinement module for error correction and conflict resolution. Experiments on the TravelPlanner and ChinaTravel datasets demonstrate that DPPM significantly outperforms existing methods.

## Method Summary
DPPM introduces a constraint-aware decomposition approach that breaks down complex planning tasks into four aspects: transportation, accommodation, attraction, and meals. Each aspect is handled by a specialized local agent that generates subplans independently in parallel. The method employs a verification and refinement module that iteratively checks constraint satisfaction and provides feedback for corrections. Finally, an incremental merge strategy combines compatible subplans through Cartesian product search while preserving constraint satisfaction. The approach is specifically designed to address the limitations of heavy constraints and cascading errors in existing LLM-based planning methods.

## Key Results
- On TravelPlanner dataset using Qwen2.5-32B-Instruct, DPPM achieves 58.9% final pass rate, outperforming Direct by 56.1%, CoT by 58.3%, and LLM-Modulo by 22.2%
- On ChinaTravel dataset, DPPM shows 70.9% and 31.3% higher final pass rates than Direct and LLM-Modulo on easy-level samples, respectively
- Verification module is critical: removing it drops Final Pass Rate from 58.9% to 20.0% (38.9 percentage point drop)

## Why This Works (Mechanism)

### Mechanism 1: Constraint-aware Decomposition by Aspect
- **Claim:** Decomposing tasks by constraint category (transportation, accommodation, attraction, meals) rather than temporal sequence reduces per-subtask cognitive load on LLMs.
- **Mechanism:** Constraints are classified as local (single-aspect) or global (multi-aspect). Each subtask receives only relevant constraints, preventing any single planning step from being overloaded.
- **Core assumption:** LLMs have bounded constraint-handling capacity and fail when too many constraints must be satisfied simultaneously.
- **Evidence anchors:**
  - [abstract] "DPPM decomposes the complex task based on constraints into subtasks, generates the subplan for each subtask in parallel"
  - [section 3.1] "if we divide all constraints into groups according to aspects, then each group contains only a manageable subset of the total constraints"
  - [corpus] Plan-over-Graph paper similarly decomposes tasks into executable subtasks, suggesting decomposition is a generalizable strategy
- **Break condition:** When constraints are irreducibly cross-cutting (e.g., a budget constraint that tightly couples all aspects), decomposition may leave subtasks under-constrained or over-constrained relative to global feasibility.

### Mechanism 2: Parallel Subplan Generation Eliminates Error Cascades
- **Claim:** Independent parallel planning by specialized local agents prevents error propagation from earlier planning steps.
- **Mechanism:** Four local agents (transportation, accommodation, attraction, meals) generate subplans independently using high-temperature sampling for diversity. No inter-agent communication is required during generation.
- **Core assumption:** Subtasks can be planned in isolation without losing solution coherence; global constraints can be enforced post-hoc during merging.
- **Evidence anchors:**
  - [abstract] "addresses the limitations of heavy constraints and cascading errors in existing methods"
  - [section 3.2] "our method lets local agents work independently. Communication between local agents is unnecessary"
  - [corpus] GAP paper notes sequential paradigms "fail to exploit inherent parallelism among independent sub-tasks," reinforcing that parallelism helps when subtasks are independent
- **Break condition:** When subtasks have strong mutual dependencies (e.g., transportation determines accommodation location), parallel plans may be fundamentally incompatible, requiring extensive merging or rejection.

### Mechanism 3: Iterative Verification with Constraint Feedback
- **Claim:** Structured verification-refinement loops correct errors more reliably than single-pass generation.
- **Mechanism:** After any plan generation, constraint evaluation functions verify satisfaction. Violations are fed back to the LLM for re-planning. This iterates until all constraints pass or max iterations reached (10).
- **Core assumption:** LLMs can correct errors when given explicit feedback on which constraints failed.
- **Evidence anchors:**
  - [section 3.4] "Once any agent generates a formatted plan, constraint evaluation functions are employed to verify its constraint satisfaction"
  - [ablation, Table 3] Removing verification drops Final Pass Rate from 58.9% to 20.0% (38.9 percentage point drop)
  - [corpus] Related work (ReAct, Reflexion) combines environmental feedback with self-reflection—DPPM extends this with formal constraint checking
- **Break condition:** When the LLM lacks the reasoning capacity to fix a particular constraint violation even with feedback (performance ceiling reached), or when verification functions themselves are incomplete.

## Foundational Learning

- **Concept: Sequential vs. Parallel Decomposition Paradigms**
  - **Why needed here:** DPPM represents a third paradigm distinct from sequential (decompose-first, execute-in-order) and interleaved (alternate decomposition and planning). Understanding this distinction is essential for grasping why parallel planning avoids cascading errors.
  - **Quick check question:** Given a travel planning task, can you identify which constraints can be planned independently vs. which require sequential reasoning?

- **Concept: Local vs. Global Constraints**
  - **Why needed here:** The decomposition strategy hinges on distinguishing local constraints (apply to one aspect, e.g., room type) from global constraints (span multiple aspects, e.g., total budget). Global constraints require special handling via "Global Constraint Instruction" in prompts.
  - **Quick check question:** For a budget constraint of $1,400 across 3 days, is this local or global? How should it be communicated to local agents?

- **Concept: Cartesian Product Search for Solution Space Exploration**
  - **Why needed here:** DPPM generates multiple candidate subplans per aspect and exhaustively combines them. Understanding this combinatorial approach explains why diversity (high-temperature sampling) matters and where computational costs arise.
  - **Quick check question:** If you have 3 transportation subplans, 2 accommodation subplans, and 2 attraction subplans, how many combinations must be evaluated?

## Architecture Onboarding

- **Component map:**
  1. Constraint-aware Task Decomposition: Parses user query, classifies constraints (local/global), creates 4 subtasks (transportation, accommodation, attraction, meals)
  2. Local Plan Generation: 4 specialized LLM agents + constraint evaluation functions + Global Constraint Instruction in prompts + high-temperature sampling
  3. Incremental Merge: Merging agent combines subplans in order (transportation+attraction → +accommodation → +meals) via Cartesian product combinations
  4. Verification and Refinement Module: Constraint evaluation functions + feedback loop (max 10 iterations), applied during Local Plan Generation and Incremental Merge stages

- **Critical path:** Decomposition → Parallel Local Generation (with verification) → Incremental Merge (with verification) → Final Plan Selection. The verification module is the single most impactful component (38.9% pass rate drop when removed).

- **Design tradeoffs:**
  - **Parallelism vs. Coherence:** Parallel generation eliminates cascading errors but may produce incompatible subplans; merging must resolve conflicts
  - **Diversity vs. Computation:** High-temperature sampling + Cartesian product improves solution quality but increases combinatorial cost (3×2×2 = 12 combinations to merge)
  - **Assumption:** Global Constraint Instruction (telling agents to "reserve budget for other dimensions") partially mitigates local optimization at the expense of global optimality

- **Failure signatures:**
  - **Budget exhaustion:** Local agent spends most budget; ablation shows Global Constraint Instruction prevents this (9.5% Final Pass Rate drop without it)
  - **Verification ceiling:** Figure 5 shows Final Pass Rate plateaus at ~5-6 iterations—if LLM cannot fix a violation, more iterations won't help
  - **Constraint interdependence:** If local plans are fundamentally incompatible (e.g., self-driving in one subplan, flights in another), merging fails

- **First 3 experiments:**
  1. Reproduce ablation on TravelPlanner validation set: Run DPPM with/without Verification and Refinement on 180 samples using Qwen2.5-32B-Instruct; expect ~58.9% → ~20.0% Final Pass Rate drop
  2. Test constraint scaling: Plot Final Pass Rate vs. number of constraints (replicate Figure 4) to verify DPPM's slower decline vs. Direct and LLM-Modulo on Hard-level samples with 12 constraints
  3. Validate Global Constraint Instruction impact: Run ablation on Easy/Medium/Hard ChinaTravel-M samples; measure budget constraint pass rate with/without the instruction (replicate Figure 6 pattern)

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can DPPM be effectively adapted for planning tasks that do not feature multiple complex constraints or where constraint-based decomposition is not applicable?
- **Basis in paper:** [explicit] The authors state in the Limitations section that DPPM "cannot fully leverage its strengths when handling single-constraint planning tasks" and list extending the method to "more general forms of planning tasks" as future work.
- **Why unresolved:** The current framework relies on breaking down tasks by constraint groups; it is unclear how the parallel planning paradigm functions when such decomposition is unnecessary or impossible.
- **What evidence would resolve it:** Demonstrations of DPPM performance on single-constraint benchmarks or tasks requiring semantic rather than constraint-based decomposition.

### Open Question 2
- **Question:** Can the constraint-aware task decomposition stage be automated for arbitrary domains without requiring manual definition of specific aspects (e.g., accommodation, transport)?
- **Basis in paper:** [inferred] The methodology (Section 3.1) explicitly decomposes tasks into four hard-coded groups: transportation, accommodation, attraction, and meals, tailored specifically for travel planning.
- **Why unresolved:** It is unstated whether the decomposition prompt or logic requires manual engineering for new domains (e.g., project management), limiting generalizability.
- **What evidence would resolve it:** Successful application of DPPM to a distinct domain (like logistics or coding) using a generalized decomposition prompt or learned decomposition module.

### Open Question 3
- **Question:** What is the computational cost and latency overhead of the Cartesian product merging strategy compared to sequential baselines?
- **Basis in paper:** [inferred] Section 3.3 describes generating multiple subplans per agent and attempting to merge "all possible combinations" via Cartesian product to find an optimal solution.
- **Why unresolved:** While effective, the computational complexity of checking all combinations could scale poorly with the number of subplans, a trade-off not quantified in the text.
- **What evidence would resolve it:** A comparative analysis of inference time and token consumption between DPPM and sequential methods as the search space (number of subplan options) increases.

## Limitations

- **Dataset specificity:** Results are impressive on TravelPlanner and ChinaTravel datasets, but generalizability to other planning domains remains untested as the methodology assumes decomposable constraints into four aspects.
- **Combinatorial explosion:** The Cartesian product approach for merging subplans may become computationally prohibitive as the number of candidate subplans per aspect increases.
- **Assumption of independence:** The parallel generation assumption that subtasks can be planned independently may break down in scenarios with tight inter-aspect dependencies.

## Confidence

- **High confidence:** The mechanism of constraint-aware decomposition reducing per-subtask cognitive load is well-supported by ablation results (verification removal causes 38.9% drop in Final Pass Rate).
- **Medium confidence:** The claim that parallel generation eliminates error cascades is supported by comparative results but could benefit from ablation studies isolating the parallel vs. sequential effects.
- **Medium confidence:** The effectiveness of iterative verification with constraint feedback is demonstrated empirically but relies on the assumption that LLMs can correct errors given explicit feedback.

## Next Checks

1. **Cross-domain validation:** Apply DPPM to a different planning domain (e.g., event planning or project management) to test generalizability beyond travel planning. Measure whether the constraint-aware decomposition and parallel generation approach maintains its effectiveness.

2. **Scaling analysis:** Systematically vary the number of candidate subplans generated per aspect (e.g., 1, 2, 3, 4) and measure the trade-off between Final Pass Rate improvement and computational cost (number of constraint evaluations required).

3. **Dependency stress test:** Construct test cases with deliberately strong inter-aspect dependencies (e.g., transportation choice strictly determines accommodation options) to evaluate how well DPPM handles scenarios where the independence assumption is violated.