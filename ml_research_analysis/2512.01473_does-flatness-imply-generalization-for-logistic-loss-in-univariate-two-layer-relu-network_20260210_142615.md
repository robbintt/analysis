---
ver: rpa2
title: Does Flatness imply Generalization for Logistic Loss in Univariate Two-Layer
  ReLU Network?
arxiv_id: '2512.01473'
source_url: https://arxiv.org/abs/2512.01473
tags:
- loss
- function
- xmax
- learning
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies whether flat solutions in logistic regression
  with two-layer ReLU networks imply generalization. The authors prove that flatness
  alone is insufficient for generalization, as arbitrarily flat yet overfitting solutions
  can exist at infinity.
---

# Does Flatness imply Generalization for Logistic Loss in Univariate Two-Layer ReLU Network?

## Quick Facts
- arXiv ID: 2512.01473
- Source URL: https://arxiv.org/abs/2512.01473
- Authors: Dan Qiao; Yu-Xiang Wang
- Reference count: 40
- Primary result: Flatness alone is insufficient for generalization in logistic regression, but flat solutions in uncertain regions can achieve near-optimal generalization bounds under additional assumptions

## Executive Summary
This paper studies the relationship between flatness of the loss landscape and generalization in logistic regression with two-layer univariate ReLU networks. The authors prove that flatness alone is insufficient for generalization, as arbitrarily flat yet overfitting solutions can exist at infinity where the model is falsely certain everywhere. However, under additional assumptions about weak generalization and diminishing excess risk, flat solutions within "uncertain regions" (where predictions are less confident) can enjoy near-optimal generalization bounds. The key technical innovation connects flatness to a weighted total variation bound within uncertain regions, showing that under a diminishing excess risk assumption, these regions of the learned function approximate those of the ground truth, enabling minimax-optimal excess risk rates.

## Method Summary
The paper analyzes two-layer univariate ReLU networks trained with logistic loss using full-batch gradient descent with fixed step sizes. The network architecture consists of k=400 neurons with random initialization. The authors study solutions at different learning rates (η ∈ {0.01, 0.02, ..., 1.2}) and characterize their generalization properties through three main theorems. They prove that flat solutions can exist at infinity with poor generalization (Theorem 3.1), that flatness implies weighted total variation bounds in uncertain regions (Theorem 3.5), and that weak generalization can be amplified to strong generalization within these regions under diminishing excess risk assumptions (Theorem 3.7). The analysis tracks Hessian eigenvalues, training loss, and excess risk across different learning rates and noise levels.

## Key Results
- Flatness of the loss landscape does not guarantee generalization in logistic regression; arbitrarily flat overfitting solutions can exist at infinity
- Flat solutions satisfy weighted total variation bounds within uncertain regions (where |f(x)| ≤ γ), restricting the hypothesis class
- Under diminishing excess risk assumptions, flat solutions achieve near-optimal excess risk rates (Õ(n^(-2/5))) within uncertain regions
- The "weak-to-strong" generalization amplification strategy transforms solutions with slow but diminishing excess risk into ones with near-optimal generalization

## Why This Works (Mechanism)

### Mechanism 1: The Interpolation-Decoupling Effect
Flatness of the loss landscape does not guarantee generalization in logistic regression because flatness and interpolation can coexist at infinity. In logistic loss, as predictions f(x) approach ∞ (correct) or -∞ (incorrect) for noisy labels, the training loss approaches 0. Simultaneously, the Hessian eigenvalues scale with e^(-γ_max), where γ_max is the prediction magnitude. Thus, as the model becomes more confident and overfitted, the landscape becomes arbitrarily flat, disconnecting flatness from generalization.

### Mechanism 2: Implicit Bias of Minima Stability (Function Space)
Stability constraints (flatness ≈ 2/η) implicitly regularize the function's Total Variation (TV), but only within the "uncertain regions." The Hessian of the loss contains terms involving the gradient of the network output. Bounding the Hessian (via stability) implicitly bounds the weighted integral of the second derivative |f''(x)| (TV norm) in regions where the model is not yet confident (|f(x)| ≤ γ). This enforces smoothness where the model is "uncertain," restricting the hypothesis class.

### Mechanism 3: Weak-to-Strong Generalization Amplification
A solution with weak generalization (diminishing but slow excess risk) can be boosted to strong, near-optimal generalization within uncertain regions via the stability constraint. The "weak generalization" assumption ensures the learned function's uncertain regions overlap with the ground truth's uncertain regions. Combined with the stability-induced TV bound, this restricts the metric entropy of the function class on that interval, yielding minimax-optimal rates.

## Foundational Learning

- **Concept: Logistic Loss at Infinity** - Why needed: Unlike squared loss, logistic loss encourages predictions to grow towards ±∞. This creates "flat" global minima at infinity (Theorem 3.1), which is the central counterexample of the paper. Quick check: Does the loss landscape become sharper or flatter as the prediction magnitude grows for a correct label?

- **Concept: Total Variation (TV) of ReLU Networks** - Why needed: The paper maps stability in parameter space to smoothness (TV) in function space. Understanding that TV captures the "wiggliness" or sum of slopes of the ReLU function is crucial for Theorem 3.5. Quick check: How does the slope of a ReLU network relate to its weights, and how does limiting the weights affect the complexity of the function?

- **Concept: Edge of Stability (EoS)** - Why needed: The paper defines "stable solutions" by the condition λ_max ≈ 2/η. This is the physical constraint used to derive the generalization bounds. Quick check: If the learning rate η increases, how must the maximum Hessian eigenvalue λ_max adjust for the solution to remain linearly stable?

## Architecture Onboarding

- **Component map:** Input (x ∈ [-x_max, x_max]) -> 2-Layer ReLU Network (f = Σ w_i^(2) φ(w_i^(1) x + b_i^(1)) + b^(2)) -> Logistic Loss (ℓ(f, (x,y)) = log(1 + e^(-yf(x)))) -> Stability Metric (F(η, D) defined by λ_max(∇²L) ≤ 2/η)

- **Critical path:**
  1. Calculate the Hessian of the loss w.r.t parameters (Appendix C)
  2. Identify the "uncertain set" A_γ where |f(x)| ≤ γ
  3. Verify that the TV bound (Theorem 3.5) holds within the convex hull of A_γ

- **Design tradeoffs:**
  - Learning Rate (η): Large η enforces flatness/smoothness (implicit regularization) but may fail to express complex ground truths if TV(f_0) is large. Small η allows interpolation/overfitting but risks sharp minima.
  - Threshold (γ): Selecting γ for the uncertain set involves a tradeoff between the size of the set and the strength of the smoothness constraint.

- **Failure signatures:**
  - Interpolation Trap: Training loss → 0, Hessian eigenvalue → 0, but test error is high (Theorem 3.1 case)
  - Divergence: η too large relative to the curvature, causing parameters to explode

- **First 3 experiments:**
  1. Learning Rate Sweep: Train with varying η (small to large) on noisy data. Plot the learned function and Hessian eigenvalue to visualize the transition from overfitting to smooth "stable" solutions (Replicate Figure 2)
  2. Uncertain Region Analysis: Plot the ground truth f_0 and learned f. Highlight the region where |f(x)| ≤ γ to verify that stability constrains TV primarily in this region
  3. Noise Robustness: Generate labels with varying noise levels. Verify that as noise increases (making data non-separable), the "stable" solution (large η) maintains lower excess risk than the interpolating solution (small η)

## Open Questions the Paper Calls Out

### Open Question 1
Can the theoretical relationship between flatness and generalization in "uncertain regions" be extended to multivariate ReLU networks? The paper focuses on the univariate case and notes that the challenges for logistic loss are "complementary to understanding the multivariate inputs." The proofs rely heavily on specific properties of univariate total variation and one-dimensional ReLU networks which do not trivially generalize to higher dimensions.

### Open Question 2
Does gradient descent with a large step size provably converge to the flat solutions characterized by the paper? The paper characterizes the properties of stable minima post-hoc but does not analyze the optimization trajectory required to reach them. It notes that the results hold for solutions satisfying certain conditions, but "we do not have guarantees whether GD could actually converge to such solutions."

### Open Question 3
How do training dynamics determine the trade-off between improving function smoothness and increasing prediction confidence? The paper establishes that flatness can result from either smoothness or overconfidence, but does not model how the optimizer navigates this trade-off during training. The Conclusion suggests it is an "interesting direction... to study the relationship between smoothness and confidence by incorporating training dynamics."

## Limitations
- The analysis is limited to univariate two-layer ReLU networks, which may not capture the full complexity of higher-dimensional problems where generalization behavior could differ significantly
- The weak-to-strong generalization amplification relies on the assumption that uncertain regions of the learned function approximate those of the ground truth, which may not hold in more complex scenarios
- The Edge of Stability condition (λ_max ≤ 2/η) is a sufficient but not necessary condition for flatness-based generalization bounds

## Confidence
- **High Confidence:** The main theoretical claims about flatness being insufficient for generalization in logistic regression (Theorem 3.1) and the connection between flatness and TV bounds in uncertain regions (Theorem 3.5)
- **Medium Confidence:** The weak-to-strong generalization amplification results (Theorem 3.7), which depend on additional assumptions about the ground truth function
- **Low Confidence:** The practical implications for real-world deep learning scenarios, as the analysis is limited to univariate two-layer ReLU networks

## Next Checks
1. **Numerical verification of Theorem 3.1:** Construct and visualize a solution with λ_max approaching zero while test error remains high, confirming that flatness can be decoupled from generalization in logistic regression
2. **Empirical test of uncertain region refinement:** Measure how the size and location of uncertain regions (where |f(x)| ≤ γ) evolve during training with different learning rates, validating the theoretical connection between stability and TV regularization
3. **Robustness to noise levels:** Systematically vary the noise level in the data generation process to determine the threshold at which the weak-to-strong amplification mechanism breaks down, providing empirical bounds on the assumptions required for the main generalization results