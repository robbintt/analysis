---
ver: rpa2
title: Anomaly Detection by Effectively Leveraging Synthetic Images
arxiv_id: '2512.23227'
source_url: https://arxiv.org/abs/2512.23227
tags:
- anomaly
- images
- synthetic
- defect
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the problem of generating high-quality synthetic
  defect images for industrial anomaly detection when real defect data is scarce.
  Previous approaches either produce low-fidelity defects (rule-based) or are computationally
  expensive (generative models).
---

# Anomaly Detection by Effectively Leveraging Synthetic Images

## Quick Facts
- arXiv ID: 2512.23227
- Source URL: https://arxiv.org/abs/2512.23227
- Reference count: 40
- Primary result: Achieves 98.7% AUROC on MVTec AD using two-stage synthetic defect training

## Executive Summary
This work addresses the challenge of generating high-quality synthetic defect images for industrial anomaly detection when real defect data is scarce. The authors propose a two-stage training strategy that combines low-cost rule-based synthetic defects with a smaller set of high-quality defects generated through a training-free pipeline. By leveraging a pre-trained text-guided image-to-image translation model and an image retrieval model for filtering, the approach produces realistic anomalies while significantly reducing computational costs compared to traditional generative methods.

## Method Summary
The proposed method employs a two-stage training strategy for anomaly detection. First, a model is pre-trained on large-scale rule-based synthetic defects that are computationally inexpensive to generate but often produce low-fidelity results. Then, the model is fine-tuned on a smaller set of high-quality defects created using a training-free pipeline. This pipeline utilizes a pre-trained text-guided image-to-image translation model to generate defects and an image retrieval model to filter out structurally inconsistent or irrelevant results, ensuring only realistic anomalies are used for training.

## Key Results
- Achieves 98.7% average AUROC on the MVTec AD dataset
- Outperforms single-stage training and reverse fine-tuning strategies
- Significantly reduces synthetic data generation costs compared to generative models

## Why This Works (Mechanism)
The approach effectively balances quality and computational efficiency by leveraging the strengths of both rule-based and high-quality synthetic defects. The pre-training stage provides a solid baseline using abundant but lower-quality data, while the fine-tuning stage refines the model with realistic anomalies that better represent actual defects. The filtering mechanism ensures that only structurally consistent and relevant defects are used, preventing the model from learning from unrealistic or irrelevant anomalies.

## Foundational Learning
- **Text-guided image-to-image translation**: Why needed? To generate realistic defects without extensive training. Quick check: Verify the model can create diverse defect types from textual descriptions.
- **Image retrieval for anomaly filtering**: Why needed? To ensure only structurally consistent defects are used for training. Quick check: Evaluate retrieval accuracy across different defect types and textures.
- **Two-stage training strategy**: Why needed? To balance the benefits of abundant low-cost data with high-quality synthetic defects. Quick check: Compare performance of single-stage versus two-stage approaches on validation sets.

## Architecture Onboarding

**Component Map**
Rule-based Synthetic Defects -> Pre-training Model -> High-Quality Synthetic Defects -> Image Retrieval Filter -> Fine-tuning Model -> Anomaly Detection Model

**Critical Path**
The critical path involves generating high-quality synthetic defects through the text-guided translation model, filtering them with the image retrieval model, and then using these filtered defects for fine-tuning the pre-trained model.

**Design Tradeoffs**
The approach trades off some computational resources during the fine-tuning stage for significantly better detection performance compared to using only rule-based defects. The filtering step adds complexity but ensures higher-quality training data.

**Failure Signatures**
Potential failures include the text-guided model producing unrealistic defects for certain defect types, the image retrieval model incorrectly filtering out valid defects, or the fine-tuning process over-fitting to the limited high-quality defect set.

**3 First Experiments**
1. Generate a diverse set of defects using the text-guided model and manually evaluate their realism across different defect types.
2. Test the image retrieval filter's ability to distinguish between realistic and unrealistic defects on a validation set.
3. Compare the performance of models trained with only rule-based defects, only high-quality defects, and the two-stage approach.

## Open Questions the Paper Calls Out
None

## Limitations
- The approach's generalization across different industrial domains and defect types not well-represented in the text-guided model's training corpus remains uncertain.
- The effectiveness of the image retrieval model for filtering realistic anomalies may vary significantly depending on specific defect characteristics and normal texture patterns.
- Computational cost comparisons with generative models are based on theoretical considerations rather than empirical measurements across different hardware configurations.

## Confidence

- **High Confidence**: The empirical results showing 98.7% average AUROC on MVTec AD, demonstrating clear improvement over single-stage and reverse fine-tuning baselines.
- **Medium Confidence**: The claim that the approach significantly reduces synthetic data generation costs, as this depends on specific implementation details and hardware resources not fully specified in the paper.
- **Medium Confidence**: The assertion that the two-stage strategy effectively balances quality and computational efficiency, though this requires validation across diverse industrial applications beyond the tested dataset.

## Next Checks

1. Conduct experiments on additional industrial anomaly detection datasets representing different manufacturing domains (e.g., steel surfaces, textile defects, electronic components) to assess generalization capabilities beyond MVTec AD.

2. Perform ablation studies to quantify the individual contributions of rule-based pre-training versus high-quality fine-tuning, and evaluate the impact of different image retrieval model architectures on final detection performance.

3. Implement empirical benchmarks comparing the computational resources (GPU hours, memory usage) required for synthetic defect generation across the proposed pipeline, rule-based methods, and generative models under varying batch sizes and defect complexity levels.