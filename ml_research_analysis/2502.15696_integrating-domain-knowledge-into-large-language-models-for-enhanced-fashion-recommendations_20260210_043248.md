---
ver: rpa2
title: Integrating Domain Knowledge into Large Language Models for Enhanced Fashion
  Recommendations
arxiv_id: '2502.15696'
source_url: https://arxiv.org/abs/2502.15696
tags:
- fashion
- data
- recommendation
- language
- large
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a novel approach to fashion recommendation
  using Large Language Models (LLMs), addressing the limitations of traditional supervised
  learning methods in handling distribution shifts and style replication discrepancies.
  The authors propose the Fashion Large Language Model (FLLM), which employs auto-prompt
  generation training strategies and integrates retrieval-augmented generation during
  inference to enhance personalized fashion advice while retaining domain knowledge.
---

# Integrating Domain Knowledge into Large Language Models for Enhanced Fashion Recommendations

## Quick Facts
- arXiv ID: 2502.15696
- Source URL: https://arxiv.org/abs/2502.15696
- Authors: Zhan Shi; Shanglin Yang
- Reference count: 25
- FLLM achieves 62.17% accuracy on Polyvore Outfits-D dataset and 67.21% on Polyvore Outfits dataset

## Executive Summary
This paper presents a novel approach to fashion recommendation using Large Language Models (LLMs), addressing limitations of traditional supervised learning methods in handling distribution shifts and style replication discrepancies. The authors propose the Fashion Large Language Model (FLLM), which employs auto-prompt generation training strategies and integrates retrieval-augmented generation during inference to enhance personalized fashion advice while retaining domain knowledge. The FLLM demonstrates superior performance compared to existing models, achieving 62.17% accuracy on the Polyvore Outfits-D dataset and 67.21% on the Polyvore Outfits dataset. Additionally, the model exhibits impressive few-shot learning capabilities, outperforming baseline methods by approximately 10% in accuracy improvement at lower data ratios.

## Method Summary
The authors propose the Fashion Large Language Model (FLLM) that integrates domain knowledge into large language models for fashion recommendations. The approach uses auto-prompt generation training strategies and incorporates retrieval-augmented generation during inference. The model combines LLM capabilities with domain-specific knowledge to provide personalized fashion advice while addressing distribution shifts and style replication challenges common in traditional supervised learning methods. The system demonstrates superior performance on benchmark datasets and shows strong few-shot learning capabilities compared to baseline approaches.

## Key Results
- FLLM achieves 62.17% accuracy on Polyvore Outfits-D dataset and 67.21% on Polyvore Outfits dataset
- Demonstrates ~10% accuracy improvement over baseline methods at lower data ratios
- Exhibits strong few-shot learning capabilities compared to traditional approaches

## Why This Works (Mechanism)
The FLLM approach works by leveraging the natural language understanding capabilities of LLMs while incorporating domain-specific fashion knowledge through retrieval-augmented generation. The auto-prompt generation training strategy allows the model to better understand and generate fashion-related content by creating contextually relevant prompts during training. The retrieval-augmented generation component enables the model to access external knowledge bases during inference, ensuring that recommendations are grounded in current fashion trends and domain expertise. This hybrid approach addresses the limitations of pure supervised learning by allowing the model to handle distribution shifts and style variations more effectively through its ability to reason about fashion concepts rather than just memorizing patterns.

## Foundational Learning
- **Auto-prompt generation**: Why needed - Creates contextually relevant training signals; Quick check - Verify prompt quality improves over training epochs
- **Retrieval-augmented generation**: Why needed - Provides access to external fashion knowledge; Quick check - Measure knowledge base coverage and retrieval accuracy
- **Fashion domain knowledge integration**: Why needed - Enables understanding of style concepts and trends; Quick check - Test model's ability to explain fashion reasoning
- **Distribution shift handling**: Why needed - Addresses variability in fashion preferences; Quick check - Evaluate performance across diverse style categories
- **Few-shot learning capability**: Why needed - Reduces data requirements for effective recommendations; Quick check - Measure accuracy improvements at different training data ratios
- **Multimodal information processing**: Why needed - Combines text and visual fashion data; Quick check - Test performance on multimodal versus text-only inputs

## Architecture Onboarding

Component map: Fashion Knowledge Base -> Retrieval System -> LLM Engine -> Auto-prompt Generator -> Output Layer

Critical path: User Query -> Retrieval System -> LLM Engine (with context) -> Auto-prompt Generator -> Fashion Recommendation

Design tradeoffs: The integration of retrieval-augmented generation increases computational overhead but provides more accurate and up-to-date recommendations compared to pure LLM approaches. The auto-prompt generation strategy requires additional training complexity but enables better handling of fashion-specific concepts and style variations.

Failure signatures: Performance degradation may occur when knowledge base lacks coverage of emerging fashion trends, when prompt generation produces irrelevant context, or when distribution shifts between training and deployment data are too large for the retrieval system to compensate.

First experiments:
1. Benchmark FLLM against traditional supervised methods on Polyvore datasets
2. Evaluate few-shot learning performance at varying data ratios
3. Test retrieval-augmented generation effectiveness with different knowledge base configurations

## Open Questions the Paper Calls Out
The authors propose integrating multimodal information and developing a hybrid approach combining LLM and conventional recommendation models for future work to further improve the system's ability to process and integrate multimodal data, enhancing the accuracy and personalization of fashion recommendations.

## Limitations
- Performance evaluation relies heavily on specific benchmark datasets (Polyvore Outfits and Polyvore Outfits-D), raising generalizability concerns
- Reported accuracy improvements measured within constrained experimental framework that may not capture real-world variability
- Auto-prompt generation strategy introduces potential biases through prompt selection that could favor certain fashion styles

## Confidence
- **High confidence**: FLLM's superior performance on benchmark datasets compared to traditional supervised methods
- **Medium confidence**: Few-shot learning capabilities and ~10% accuracy improvement at lower data ratios
- **Low confidence**: Claims about addressing distribution shifts and style replication discrepancies without systematic evaluation across diverse fashion domains

## Next Checks
1. Test FLLM performance on diverse fashion recommendation datasets beyond Polyvore to assess generalizability
2. Conduct ablation studies isolating the contribution of auto-prompt generation versus retrieval-augmented generation to performance gains
3. Implement cross-validation across multiple fashion style categories to verify the model handles distribution shifts as claimed