---
ver: rpa2
title: Tracing the Representation Geometry of Language Models from Pretraining to
  Post-training
arxiv_id: '2509.23024'
source_url: https://arxiv.org/abs/2509.23024
tags:
- pretraining
- representation
- language
- geometry
- post-training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates the internal geometry of language model\
  \ representations during training using spectral analysis. The authors track two\
  \ metrics\u2014effective rank (RankMe) and eigenspectrum decay rate (\u03B1ReQ)\u2014\
  across pretraining and post-training stages of large language models."
---

# Tracing the Representation Geometry of Language Models from Pretraining to Post-training

## Quick Facts
- **arXiv ID**: 2509.23024
- **Source URL**: https://arxiv.org/abs/2509.23024
- **Reference count**: 40
- **Primary result**: Language model representations follow three geometric phases during pretraining, with post-training inducing distinct geometric dynamics

## Executive Summary
This paper investigates the internal geometry of language model representations during training using spectral analysis. The authors track two metrics—effective rank (RankMe) and eigenspectrum decay rate (αReQ)—across pretraining and post-training stages of large language models. The core finding is that representation geometry evolves through a consistent three-phase sequence during autoregressive pretraining: an initial "warmup" phase with rapid collapse, followed by an "entropy-seeking" phase with manifold expansion, and finally a "compression-seeking" phase with anisotropic consolidation. These phases correlate with distinct capabilities—n-gram memorization in the entropy-seeking phase and long-context generalization in the compression-seeking phase. The authors demonstrate these geometric phases emerge from the interplay of cross-entropy optimization under skewed token frequencies and representational bottlenecks. Post-training stages show different geometric dynamics: SFT and DPO drive entropy-seeking dynamics improving in-distribution performance while reducing robustness, while RLVR induces compression-seeking dynamics enhancing reward alignment but reducing generation diversity.

## Method Summary
The authors use spectral analysis to study representation geometry throughout training. They measure two key metrics: effective rank (RankMe) capturing representation dimensionality, and eigenspectrum decay rate (αReQ) quantifying geometric anisotropy. These metrics are computed from representation matrices across training phases, including autoregressive pretraining (1B to 70B parameters), supervised fine-tuning (SFT), direct preference optimization (DPO), and reinforcement learning with verifiable rewards (RLVR). The analysis tracks how these geometric properties evolve during each training stage and correlates them with model capabilities such as n-gram memorization, long-context generalization, in-distribution performance, robustness, reward alignment, and generation diversity.

## Key Results
- Language model representations evolve through three consistent geometric phases during autoregressive pretraining: warmup (collapse), entropy-seeking (expansion), and compression-seeking (consolidation)
- The entropy-seeking phase correlates with n-gram memorization capabilities while the compression-seeking phase correlates with long-context generalization
- Post-training methods induce distinct geometric dynamics: SFT/DPO drive entropy-seeking patterns improving in-distribution performance but reducing robustness, while RLVR induces compression-seeking dynamics enhancing reward alignment but reducing diversity

## Why This Works (Mechanism)
The geometric phase dynamics emerge from the interplay between cross-entropy optimization objectives and the underlying token frequency distribution. During pretraining, the skewed token frequency distribution creates a natural tension between fitting common tokens (which favors low-rank representations) and rare tokens (which requires higher capacity). This tension manifests as the three-phase progression. The representational bottlenecks in the model architecture further constrain this optimization landscape, creating conditions where geometric phases emerge as optimal solutions to the training objective. During post-training, different objectives (behavioral alignment, reward maximization) create new optimization pressures that reshape the representation geometry in predictable ways.

## Foundational Learning
- **Spectral decomposition**: Mathematical technique to analyze matrix structure by decomposing into eigenvalues and eigenvectors. Needed to quantify representation geometry through effective rank and eigenspectrum decay. Quick check: Verify eigenvalues capture most variance with first few components.
- **Representation geometry**: Study of how neural network activations are distributed in high-dimensional space. Needed to understand how information is organized and compressed during training. Quick check: Plot t-SNE of representations at different training stages.
- **Effective rank (RankMe)**: Measure of intrinsic dimensionality in representation space, calculated from eigenvalue spectrum. Needed to quantify how many dimensions are actually used to encode information. Quick check: Compare RankMe values across different layer depths.
- **Eigenspectrum decay rate (αReQ)**: Parameter quantifying how quickly eigenvalues decay, indicating geometric anisotropy. Needed to measure concentration of information in specific directions. Quick check: Fit power-law decay to eigenvalue spectrum.
- **Cross-entropy optimization**: Training objective that minimizes negative log-likelihood of correct tokens. Needed to understand the fundamental optimization pressure driving geometric changes. Quick check: Monitor training loss alongside geometric metrics.
- **Representation bottleneck**: Architectural constraint limiting information flow between layers. Needed to explain why geometric compression emerges as an optimal solution. Quick check: Vary bottleneck width and observe geometric effects.

## Architecture Onboarding
**Component Map**: Data -> Embedding Layer -> Transformer Blocks -> Output Layer -> Loss Function -> Optimizer -> Updated Weights
**Critical Path**: Token embedding → self-attention → feed-forward network → residual connections → layer normalization → next token prediction → cross-entropy loss → weight update
**Design Tradeoffs**: Wide layers provide more representational capacity but increase computational cost and risk overfitting; narrow layers create bottlenecks that may induce beneficial compression but limit expressivity
**Failure Signatures**: Geometric collapse indicates underfitting or poor optimization; excessive dimensionality suggests inefficient representations; mismatched geometric phases and capabilities indicate architectural misalignment
**First Experiments**:
1. Track RankMe and αReQ during pretraining to verify three-phase progression emerges
2. Correlate geometric metrics with n-gram memorization performance during entropy-seeking phase
3. Measure how varying embedding dimension affects geometric phase timing and characteristics

## Open Questions the Paper Calls Out
The authors acknowledge that "why the phase dynamics coincide with capability emergence remains an open question." Specifically, they note that the mechanistic relationship between geometric phases and specific capabilities (n-gram memorization, long-context generalization) lacks causal explanation. The paper also suggests that geometric dynamics may differ for post-training methods not analyzed, including rejection sampling, rule-based fine-tuning, and mixture-of-experts routing strategies.

## Limitations
- The spectral analysis assumes linear algebraic methods adequately capture nonlinear interactions in high-dimensional representations, which may not hold in later training phases
- The correlation between geometric phases and capabilities is empirical rather than mechanistic, lacking explanation for why specific capabilities emerge during particular phases
- Post-training analysis covers only SFT, DPO, and RLVR methods, potentially missing geometric dynamics from other approaches

## Confidence
**High confidence**: Identification of three distinct geometric phases during pretraining and their consistent emergence across different model scales (1B to 70B parameters) and architectures (LLaMA, Pythia, Mistral)
**Medium confidence**: Correlation between geometric phases and specific capabilities, as this relies on observed associations rather than causal mechanisms
**Medium confidence**: Interpretation of post-training geometric dynamics, as the sample size of post-training methods is limited and the analysis period (up to 10K steps) may not capture long-term effects

## Next Checks
1. Conduct ablation studies removing skewed token frequency distributions to isolate the effect of token frequency imbalance on geometric phase emergence during pretraining
2. Apply the geometric analysis framework to additional post-training methods including rule-based fine-tuning and rejection sampling to test the generalizability of observed geometric dynamics
3. Perform controlled experiments varying representational bottlenecks (e.g., different embedding dimensions, layer widths) to test the hypothesis that bottleneck constraints drive the compression-seeking phase