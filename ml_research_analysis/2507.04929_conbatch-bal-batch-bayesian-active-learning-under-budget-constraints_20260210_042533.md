---
ver: rpa2
title: 'ConBatch-BAL: Batch Bayesian Active Learning under Budget Constraints'
arxiv_id: '2507.04929'
source_url: https://arxiv.org/abs/2507.04929
tags:
- learning
- batch
- active
- greedy
- random
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work introduces two Bayesian active learning strategies,\
  \ ConBatch-BAL, for batch acquisition under budget constraints, addressing the challenge\
  \ of varying annotation costs and limited budgets in real-world applications. The\
  \ strategies\u2014dynamic thresholding and greedy acquisition\u2014use uncertainty\
  \ metrics from Bayesian neural networks to select samples, redistributing budget\
  \ across batches or selecting top-ranked samples within remaining budget."
---

# ConBatch-BAL: Batch Bayesian Active Learning under Budget Constraints

## Quick Facts
- arXiv ID: 2507.04929
- Source URL: https://arxiv.org/abs/2507.04929
- Reference count: 40
- Two new Bayesian active learning strategies for batch acquisition under budget constraints

## Executive Summary
ConBatch-BAL introduces two novel strategies for batch Bayesian active learning under budget constraints: dynamic thresholding and greedy acquisition. These methods leverage uncertainty metrics from Bayesian neural networks to optimize sample selection when annotation costs vary and budgets are limited. The framework addresses a critical gap in real-world applications where different samples have different annotation costs, requiring intelligent budget allocation across batches.

## Method Summary
The ConBatch-BAL framework implements two budget-aware acquisition strategies for batch Bayesian active learning. The dynamic thresholding approach redistributes the available budget across batches by adjusting uncertainty thresholds based on remaining budget and cost distribution. The greedy acquisition strategy selects top-ranked samples within the remaining budget by computing uncertainty scores and filtering based on cost constraints. Both methods utilize uncertainty estimates from Bayesian neural networks, specifically Monte Carlo dropout or deep ensembles, to quantify prediction uncertainty for each candidate sample.

## Key Results
- Reduces active learning iterations by 20-43% on build6k and 50-80% on nieman17k datasets
- Achieves up to 97% accuracy on mnist6k under 100-unit budget constraints
- Outperforms random baseline across various budget and cost scenarios
- Releases two new real-world datasets (build6k and nieman17k) with geolocated aerial building images

## Why This Works (Mechanism)
ConBatch-BAL works by integrating budget constraints directly into the sample acquisition process through two complementary strategies. The dynamic thresholding mechanism adjusts uncertainty thresholds based on remaining budget and cost distribution, ensuring optimal budget utilization across batches. The greedy acquisition strategy performs cost-aware top-k selection within budget limits, prioritizing high-uncertainty samples while respecting cost constraints. Both approaches leverage Bayesian uncertainty estimates to identify informative samples, enabling more efficient exploration of the sample space under resource limitations.

## Foundational Learning

**Bayesian Neural Networks**: Why needed - Provide uncertainty estimates for sample selection; Quick check - Verify dropout rate and number of forward passes for reliable uncertainty estimation

**Active Learning**: Why needed - Enables efficient model training with minimal labeled data; Quick check - Confirm acquisition function balances exploration and exploitation

**Budget Constraints**: Why needed - Reflects real-world annotation cost variations; Quick check - Validate cost distribution assumptions match application domain

**Batch Acquisition**: Why needed - Reduces computational overhead of sequential selection; Quick check - Ensure batch diversity through uncertainty diversity metrics

**Uncertainty Metrics**: Why needed - Quantify prediction confidence for informative sample selection; Quick check - Compare variance, entropy, and other metrics for acquisition performance

## Architecture Onboarding

**Component Map**: Data → Uncertainty Estimation → Budget-Aware Acquisition → Batch Selection → Model Update

**Critical Path**: Bayesian model inference → Uncertainty computation → Budget-constrained selection → Model retraining

**Design Tradeoffs**: The framework trades computational complexity for budget efficiency, using batch processing to reduce iteration count while maintaining acquisition quality through sophisticated budget-aware selection strategies.

**Failure Signatures**: Performance degradation occurs with highly skewed cost distributions where greedy selection may miss informative but expensive samples, and dynamic thresholding may fail when cost uncertainty is high.

**First Experiments**:
1. Compare iteration reduction across different cost distributions (uniform, normal, power-law)
2. Evaluate accuracy vs. budget trade-offs on mnist6k with varying uncertainty metrics
3. Test sensitivity to hyperparameter choices (threshold adjustment rates, batch sizes)

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Limited evaluation to only two real-world datasets with specific characteristics
- Performance may degrade with extreme cost heterogeneity not represented in test cases
- Only compared against random baseline, lacking comparison with other state-of-the-art budget-aware methods

## Confidence

**Performance Improvement Claims**: Medium confidence in iteration reduction metrics due to limited dataset diversity
**Accuracy Claims**: Medium confidence in budget-constrained accuracy results on simpler datasets
**Strategy Robustness**: Low confidence in performance across diverse cost distributions

## Next Checks

1. Benchmark ConBatch-BAL against established budget-aware active learning methods on diverse datasets with varying cost structures
2. Evaluate strategy performance under extreme cost heterogeneity scenarios to test robustness boundaries
3. Conduct ablation studies isolating the impact of Bayesian uncertainty metrics versus alternative uncertainty measures on acquisition performance