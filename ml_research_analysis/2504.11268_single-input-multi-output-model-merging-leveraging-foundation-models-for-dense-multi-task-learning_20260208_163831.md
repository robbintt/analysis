---
ver: rpa2
title: 'Single-Input Multi-Output Model Merging: Leveraging Foundation Models for
  Dense Multi-Task Learning'
arxiv_id: '2504.11268'
source_url: https://arxiv.org/abs/2504.11268
tags:
- task
- merging
- multi-task
- learning
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper tackles the challenge of merging single-task vision\
  \ models into a unified multi-task model for dense prediction tasks (e.g., segmentation,\
  \ depth estimation, surface normals). The key difficulty lies in the misalignment\
  \ between the shared encoder\u2019s representations and task-specific heads after\
  \ merging, which degrades performance."
---

# Single-Input Multi-Output Model Merging: Leveraging Foundation Models for Dense Multi-Task Learning

## Quick Facts
- arXiv ID: 2504.11268
- Source URL: https://arxiv.org/abs/2504.11268
- Reference count: 0
- This paper tackles the challenge of merging single-task vision models into a unified multi-task model for dense prediction tasks (e.g., segmentation, depth estimation, surface normals).

## Executive Summary
This paper addresses the challenge of merging single-task vision models into a unified multi-task model for dense prediction tasks like segmentation, depth estimation, and surface normals. The key difficulty lies in the misalignment between the shared encoder's representations and task-specific heads after merging, which degrades performance. The proposed solution involves two strategies: head re-alignment (fine-tuning task-specific heads on a small multi-task validation set) and representation re-alignment (introducing lightweight LoRA modules after each encoder block to adapt the merged encoder's feature space). These approaches address the representation mismatch caused by diverse loss objectives and decoders in dense prediction tasks.

## Method Summary
The method leverages pre-trained single-task models and merges them using Task Arithmetic, where task vectors (differences between fine-tuned and pre-trained weights) are added to the backbone. To address the performance degradation from this merging, the paper proposes two re-alignment strategies: (1) Head Re-alignment, which fine-tunes only the task-specific heads on a small multi-task validation set, and (2) Representation Re-alignment, which introduces LoRA modules after each encoder block to adapt the merged encoder's features. The approach is evaluated on NYUv2, Cityscapes, and Taskonomy datasets, showing that these re-alignment techniques recover performance close to multi-task learning baselines while requiring fewer samples and training steps.

## Key Results
- Standard model merging methods like Task Arithmetic and TIES suffer significant performance drops (e.g., -83% on Taskonomy) when applied to dense prediction tasks
- Head re-alignment and representation re-alignment recover performance close to multi-task learning baselines
- The method provides insights into task relationships by analyzing task vectors, revealing sensitivity and conflicts among tasks
- The approach offers a scalable and efficient way to build multi-task models from pre-trained single-task checkpoints

## Why This Works (Mechanism)

### Mechanism 1: Feature Distribution Re-alignment via Head Adaptation
- **Claim:** Standard model merging causes performance collapse because the merged encoder produces feature representations misaligned with the distributions expected by pre-trained task-specific decoders.
- **Mechanism:** Merging weights creates a "multi-task vector" that shifts the encoder's output manifold. While the encoder contains the necessary task information, the fixed decoders cannot interpret the shifted features. Fine-tuning only the heads on a small validation set adapts the projection layers to the new mean and variance of the merged features.
- **Core assumption:** The merged encoder retains sufficient task-specific information that can be decoded if the downstream heads are recalibrated; the degradation is primarily a distribution shift issue rather than destruction of semantic knowledge.
- **Evidence anchors:** Abstract states representation misalignment is the primary cause of degradation; page 6 explains the merged encoder produces representations misaligned with expected input distributions; MOMA corpus attributes degradation to geometric misalignment between merged encoder and static task-specific classifier heads.
- **Break condition:** If the merging coefficient is too high or tasks are adversarial, the encoder's features may become irreversibly distorted, preventing head re-alignment from recovering performance.

### Mechanism 2: Layer-wise Heterogeneity Compensation via LoRA
- **Claim:** Dense prediction tasks rely on different layers of the encoder to different degrees; global scaling distorts the feature hierarchy, whereas lightweight adapters can recover layer-specific utility.
- **Mechanism:** Analysis shows different tasks require different optimal scaling coefficients per layer. Global arithmetic averaging blurs these distinct requirements. Injecting LoRA modules after each block allows the model to learn a low-rank adjustment that locally re-orients the feature space for all tasks simultaneously without full fine-tuning.
- **Core assumption:** The necessary adjustments to align the multi-task representation reside in a low-dimensional subspace, making Low-Rank Adaptation sufficient for bridging the gap between the merged encoder and task heads.
- **Evidence anchors:** Page 7 Figure 2 shows dense prediction tasks utilize encoder representation differently; page 7 states PEFT approach aligns encoded weights towards joint representation; general PEFT literature supports this assumption with empirical validation specific to merging.
- **Break condition:** If the rank of LoRA matrices is too low to capture complex rotations required to unify diverse tasks, the re-alignment will fail to converge.

### Mechanism 3: SIMO (Single-Input Multi-Output) Distinctness
- **Claim:** Merging in SIMO settings is fundamentally harder than in classification because the "universal decoder" assumption does not hold.
- **Mechanism:** In classification merging, a frozen text encoder acts as a universal head, so only the visual encoder needs alignment. In SIMO dense prediction, each task has a specific, sensitive decoder head. The merging process must satisfy input constraints of multiple distinct heads simultaneously, necessitating explicit re-alignment strategies.
- **Core assumption:** The performance drop is not just weight interference but a systematic bias introduced by diverse optimization objectives of the decoders.
- **Evidence anchors:** Page 2 states SIMO qualitatively differs from settings studied in literature due to task-specific decoders and diverse loss objectives; page 5 Figure 1 shows steep performance drop in SIMO compared to flat line in classification; SE-Merging suggests general merging mechanisms are poorly understood, pinning down decoder-head relationship as specific variable in SIMO.
- **Break condition:** If one applies classification-based merging tricks without addressing decoder-head alignment, the system will fail with -80% relative performance drop.

## Foundational Learning

- **Concept: Task Arithmetic**
  - **Why needed here:** This is the baseline merging technique the paper improves upon. You must understand what a "task vector" is and how adding them creates a multi-task model.
  - **Quick check question:** If I have two models fine-tuned from the same backbone, how do I compute the multi-task vector?

- **Concept: Representation Misalignment**
  - **Why needed here:** The central diagnosis of the paper. You need to understand that a neural network layer expects inputs from a specific distribution, and changing the encoder weights shifts this distribution, "breaking" the subsequent layers.
  - **Quick check question:** Why does a decoder trained on Encoder A's features fail when plugged into merged Encoder B, even if B contains the knowledge for the task?

- **Concept: PEFT (Parameter-Efficient Fine-Tuning) / LoRA**
  - **Why needed here:** The solution proposed for high-performance merging. Understanding that LoRA adds small rank-decomposition matrices allows you to see how the model "twists" features back into alignment without heavy computation.
  - **Quick check question:** How does inserting a low-rank matrix BA into a transformer block allow the model to adapt to new distributions without changing the heavy pre-trained weights?

## Architecture Onboarding

- **Component map:**
  DINOv2-base (backbone) -> Task-specific encoders (copies fine-tuned for individual tasks) -> Merged encoder (backbone + sum of task vectors) -> [Optional: LoRA adapters] -> Task-specific heads (decoders)

- **Critical path:**
  1. Verify Single-Task performance (train/fetch θ_t and φ_t)
  2. Compute Task Vectors (τ_t = θ_t - θ_0)
  3. Merge Encoders (θ_MTL = θ_0 + α·Στ_t)
  4. *Crucial Step*: Run Representation Re-alignment (train LoRA + Heads on small validation set) to fix misalignment

- **Design tradeoffs:**
  - Head Re-alignment vs. Representation Re-alignment: Head alignment is faster (frozen encoder, precompute features) but may not recover full performance on diverse tasks. Representation alignment (LoRA) is more robust but requires backprop through the encoder (albeit with few parameters).
  - Dataset Size: The method relies on a "small multi-task validation set," trading massive training data requirements for efficient post-hoc alignment.

- **Failure signatures:**
  - Catastrophic Drop: If merging 3+ dense tasks results in >50% performance loss, you have likely skipped the re-alignment phase.
  - Blurred Outputs: If depth maps or segmentation masks look noisy or averaged out, the global merging coefficient may be too high, causing interference that LoRA cannot fix.

- **First 3 experiments:**
  1. Baseline Merge: Merge 2 task encoders (e.g., NYUv2 Seg + Depth) using Task Arithmetic and measure the drop. (Expect ~30% drop)
  2. Head Re-align: Take the failed merged encoder, freeze it, and fine-tune only the heads on 1k samples. (Expect recovery to ~95% of single-task performance)
  3. LoRA Re-align: Insert LoRA into the merged encoder and fine-tune on the same 1k samples. (Check if it beats Head Re-align, especially on difficult tasks)

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the task sensitivity analysis derived from task vectors be formalized into an automated method for optimizing per-layer merging coefficients without relying on grid search?
- **Basis in paper:** Section 6.4 visualizes task relationships and sensitivity, but the merging process still relies on standard Task Arithmetic or TIES rather than utilizing this sensitivity data to optimize the merge.
- **Why unresolved:** The paper uses sensitivity analysis only for post-hoc interpretation of why merging fails, not as a mechanism to improve the merging function itself.
- **What evidence would resolve it:** An algorithm that takes task vector sensitivity as input and outputs optimal scaling coefficients, outperforming uniform scaling.

### Open Question 2
- **Question:** What is the minimum required size and diversity of the multi-task validation set to successfully perform representation re-alignment without overfitting?
- **Basis in paper:** The method claims to require "fewer samples" than Multi-Task Learning, but does not establish a lower bound or analyze the trade-off between validation set size and alignment quality.
- **Why unresolved:** Experiments utilize standard validation splits, leaving the data efficiency limits of the re-alignment LoRA modules unexplored.
- **What evidence would resolve it:** A parameter sweep of validation set sizes showing the degradation curve of Δ_MTL performance.

### Open Question 3
- **Question:** Does the necessity of representation re-alignment vs. head re-alignment correlate with the architectural complexity of the task-specific decoders?
- **Basis in paper:** The paper uses Linear heads for NYUv2 and DPT decoders for Cityscapes/Taskonomy, but does not isolate whether decoder capacity influences the severity of representation misalignment after merging.
- **Why unresolved:** The different benchmarks use different heads, making it difficult to disentangle the effect of dataset difficulty from decoder architecture on re-alignment effectiveness.
- **What evidence would resolve it:** An ablation study on a single dataset using both linear and DPT heads to measure the performance gap between merged and single-task models.

## Limitations
- The method requires a small multi-task validation set for re-alignment, which may not be available in all practical scenarios
- Performance on highly diverse tasks (Taskonomy) still shows significant degradation (-19% normalized) even after re-alignment
- The analysis focuses on vision transformers; generalization to other architectures remains untested

## Confidence
- **High confidence:** Core claims about representation misalignment are well-supported by direct empirical validation across multiple datasets and comparison with strong baselines
- **Medium confidence:** LoRA mechanism is empirically validated but lacks deep analysis of learned low-rank matrices to confirm they capture hypothesized geometric transformations
- **Low confidence:** Analysis of task relationships through task vectors presents correlation analysis but doesn't validate whether these insights lead to actionable improvements in task selection or merging strategies

## Next Checks
1. Test LoRA rank sensitivity: Run experiments with different rank values (r=4, 8, 16) on Taskonomy to determine the minimum rank needed for full recovery
2. Ablation on validation set size: Systematically vary the size of the multi-task validation set to quantify the trade-off between data efficiency and performance
3. Cross-architecture validation: Apply the same merging and re-alignment approach to a non-ViT architecture (e.g., ConvNeXt) to test generalizability