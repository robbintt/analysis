---
ver: rpa2
title: 'Identification of Probabilities of Causation: from Recursive to Closed-Form
  Bounds'
arxiv_id: '2505.15274'
source_url: https://arxiv.org/abs/2505.15274
tags:
- ykxk
- bounds
- probability
- pearl
- bound
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of identifying multi-valued probabilities
  of causation (PoCs) in Structural Causal Models (SCMs) using only experimental and
  observational data, without structural restrictions. The authors extend PoCs beyond
  binary settings by deriving closed-form bounds for a representative family of discrete
  PoCs, introducing equivalence classes to reduce arbitrary PoC queries and a replaceability
  principle to transfer bounds across value permutations.
---

# Identification of Probabilities of Causation: from Recursive to Closed-Form Bounds

## Quick Facts
- arXiv ID: 2505.15274
- Source URL: https://arxiv.org/abs/2505.15274
- Reference count: 40
- Primary result: Closed-form bounds for multi-valued PoCs using experimental and observational data without structural restrictions

## Executive Summary
This paper extends probabilities of causation (PoCs) beyond binary settings by deriving closed-form bounds for multi-valued PoCs in Structural Causal Models. The authors introduce equivalence classes to reduce arbitrary PoC queries and a replaceability principle to transfer bounds across value permutations. The primary results include closed-form theoretical bounds that are simpler to compute than existing recursive bounds, empirical verification of soundness across all dimensions and tightness in low-dimensional cases (up to n=4) via Balke's linear programming method, simulation results showing consistent tightening of recent recursive bounds with average improvements in bound tightness across multiple dimensional settings, and practical applicability demonstrated through medical and educational examples showing how the bounds capture cross-world response patterns invisible to marginal comparisons. The authors conjecture that the proposed bounds are complete in general, though a formal proof remains open.

## Method Summary
The paper derives closed-form bounds for multi-valued PoCs using Fréchet inequality-based decomposition of joint counterfactual probabilities. The method decomposes experimental and observational distributions to obtain lower bounds from sum constraints and upper bounds from minimum marginal constraints and covariate adjustment terms. Arbitrary discrete PoC queries reduce to a small representative family through equivalence class transformations, while a replaceability principle enables computing bounds for any permuted counterfactual query by direct substitution. The framework requires only standard experimental and observational data without structural assumptions.

## Key Results
- Closed-form theoretical bounds for multi-valued PoCs that are simpler to compute than existing recursive bounds
- Empirical verification of soundness across all dimensions and tightness in low-dimensional cases (up to n=4) via Balke's linear programming method
- Simulation results showing consistent tightening of recent recursive bounds with average improvements in bound tightness across multiple dimensional settings
- Practical applicability demonstrated through medical and educational examples showing how the bounds capture cross-world response patterns invisible to marginal comparisons

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Closed-form bounds for multi-valued PoCs can be derived from experimental (P(yᵢˣⱼ)) and observational (P(xⱼ, yᵢ)) distributions using Fréchet inequality-based decomposition.
- **Mechanism:** The derivation decomposes joint counterfactual probabilities by applying Fréchet inequalities to marginal experimental distributions and joint observational distributions. Lower bounds arise from sum constraints (P(A₁) + ... + P(Aₙ) - n + 1), while upper bounds come from minimum marginal constraints and covariate adjustment terms involving P(xⱼ) - P(xⱼ, yⱼ).
- **Core assumption:** The SCM is well-specified with counterfactuals consistently defined, and experimental/observational data come from the same underlying causal mechanism.
- **Evidence anchors:**
  - [abstract] "deriving closed form bounds for a representative family of discrete PoCs within Structural Causal Models, using standard experimental and observational distributions"
  - [page 9, Section A.1] "By Fréchet Inequalities, we have, P(A₁, ..., Aₙ) ≥ max{0, P(A₁) + ... + P(Aₙ) - n + 1}, P(A₁, ..., Aₙ) ≤ min{P(A₁), ..., P(Aₙ)}"
  - [corpus] Weak direct support; related papers address estimation challenges but not this specific decomposition mechanism.
- **Break condition:** Bounds become uninformative when experimental effects show insufficient variation or when observational and experimental distributions are incompatible (e.g., P(yᵢˣᵢ) < P(xᵢ, yᵢ)).

### Mechanism 2
- **Claim:** Arbitrary discrete PoC queries reduce to a small representative family through equivalence class transformations.
- **Mechanism:** When |Y| < |X|, the transformation sets P(y'ₗˣⱼ) = 0 for non-existent outcome levels m+1 ≤ l ≤ n while preserving original probabilities for l ≤ m. When |X| < |Y|, unused treatment levels are assigned deterministic responses (P(yₘˣₗ) = 1) and zero probability for other outcomes. Theorem 6 proves these transformations preserve the linear programming formulation underlying the bounds.
- **Core assumption:** Zero-padding and deterministic assignment don't violate feasibility constraints of the underlying SCM.
- **Evidence anchors:**
  - [abstract] "We introduce the notion of equivalence classes of PoCs, which reduces arbitrary discrete PoCs to this family"
  - [page 5, Theorem 6] "the bounds of the probability, P(y₁ˣ¹, ..., yₖˣᵏ), is exactly the same as the bounds of the probability, P(y'₁ˣ¹, ..., y'ₖˣᵏ)"
  - [corpus] No directly comparable equivalence class frameworks found in neighbors.
- **Break condition:** Equivalence fails if the data-generating process assigns non-zero probability to "impossible" outcomes that were zero-padded.

### Mechanism 3
- **Claim:** Bounds for any permuted counterfactual query P(y₁ˣ¹, ..., ŷᵢˣⁱ, ..., yₖˣᵏ) are obtained by direct substitution of yᵢˣⁱ → ŷᵢˣⁱ in the standard bound formulas.
- **Mechanism:** The proof structure using Fréchet inequalities is invariant to outcome value labels—only the marginal probabilities P(yⱼˣⱼ) and joint terms P(xⱼ, yⱼ) change. This enables computing bounds for cross-world queries like P(y₃ˣ¹, y₁ˣ², y₂ˣ³) by applying Theorem 2 with appropriate substitutions.
- **Core assumption:** Permutations preserve probability measure constraints and counterfactual consistency.
- **Evidence anchors:**
  - [abstract] "establish a replaceability principle that transfers bounds across value permutations"
  - [page 5, Theorem 7] "the bounds... can be obtained by replacing yᵢˣⁱ with ŷᵢˣⁱ for any i, such that 1 ≤ i ≤ n, in the bounds of P(y₁ˣ¹, ..., yₖˣᵏ)"
  - [corpus] "Probabilities of Causation and Root Cause Analysis" addresses computational simplification but not replaceability specifically.
- **Break condition:** Replaceability fails when permutations create logically impossible counterfactual conjunctions (mutually exclusive events in the same world).

## Foundational Learning

- **Concept: Structural Causal Models and Counterfactual Semantics**
  - **Why needed here:** All PoC definitions (PNS, PN, PS and their multi-valued generalizations) rely on SCM counterfactual notation. The expression P(y₁ˣ¹, y₂ˣ²) asks "probability that Y = y₁ if X = x₁ AND Y = y₂ if X = x₂"—a cross-world quantity not directly observable.
  - **Quick check question:** Why can't P(yₓ, y'ₓ') be estimated by simply observing outcomes under treatment x and control x' separately?

- **Concept: Partial Identification and Bound Tightness**
  - **Why needed here:** PoCs are partially identified—multiple SCMs can produce the same P(yˣ), P(x, y) but different true PoC values. "Tightness" means no narrower interval is consistent with all feasible SCMs. The paper proves soundness (valid bounds) for all dimensions but only empirically verifies tightness in low dimensions (n ≤ 4).
  - **Quick check question:** If Balke's LP method gives bounds [0.3, 0.6] and closed-form gives [0.25, 0.65], which is tighter and why does it matter?

- **Concept: Binary PoCs (PN, PS, PNS) as Special Cases**
  - **Why needed here:** PNS(k) with k=2 reduces to binary PNS. Understanding Tian-Pearl binary bounds provides intuition: the multi-valued generalizations extend the same Fréchet-based logic with additional summation terms over treatment/outcome indices.
  - **Quick check question:** In binary settings, PNS = P(yₓ, y'ₓ'). What does PNS(3) = P(y₁ˣ¹, y₂ˣ², y₃ˣ³) represent and how does it differ from pairwise comparisons?

## Architecture Onboarding

- **Component map:** Data Input -> Query Parser -> Equivalence Transformer -> Replaceability Engine -> Bound Evaluator -> Output
- **Critical path:**
  1. Validate data compatibility: check P(xᵢ, yᵢ) ≤ P(yᵢˣⁱ) ≤ 1 - P(xᵢ) + P(xᵢ, yᵢ)
  2. Classify query and select appropriate theorem
  3. Apply equivalence transformation if needed
  4. Apply replaceability substitutions
  5. Evaluate bound expressions with data

- **Design tradeoffs:**
  - Closed-form vs. LP: Closed-form is O(nk) computation; LP (Balke) is exponential but guaranteed tight. Paper conjectures closed-form tightness in all dimensions but only proves for n ≤ 4 empirically.
  - Generality vs. sharpness: No structural assumptions (monotonicity, exclusion) keep bounds applicable broadly but potentially wider than domain-specific methods.

- **Failure signatures:**
  - Lower bound > upper bound: data incompatibility
  - Bounds = [0, 1]: insufficient treatment effect heterogeneity
  - Large gap (UB - LB > 0.5): near-unidentifiable query given available data

- **First 3 experiments:**
  1. **Replicate Section 4.1 medical example:** Compute P(y₃ˣ¹, y₁ˣ², y₂ˣ³) bounds [0.509, 0.588] using Tables 1-2. Verify against Li-Pearl recursive bounds [0.428, 0.588] to confirm lower-bound improvement.
  2. **Dimensional stress test:** Generate random compatible distributions for n ∈ {3, 10, 20}. For n ≤ 5, compare closed-form vs. Balke LP bounds. Measure bound gap and runtime scaling.
  3. **Cross-method validation:** Apply ML-based estimation from corpus neighbor "Estimating Probabilities of Causation with Machine Learning Models" on the education intervention data (Tables 3-4). Compare predicted intervals against theoretical bounds to verify ML respects identifiability constraints.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Are the derived closed-form bounds tight (complete) for all dimensions, specifically when treatment and outcome variables take more than four values?
- Basis in paper: [explicit] The authors state they "conjecture that this tightness extends to all dimensions" but note that "a complete proof establishing their tightness remains open."
- Why unresolved: Soundness is proven for all dimensions, and tightness is only empirically verified for low-dimensional cases ($n \in \{3, 4\}$) using Balke's linear programming method.
- What evidence would resolve it: A formal mathematical proof of completeness for arbitrary $n$, or a specific counter-example in higher dimensions where the bounds are not tight.

### Open Question 2
- Question: How can the incorporation of covariates or explicit causal graph structures further sharpen the bounds for multi-valued probabilities of causation?
- Basis in paper: [explicit] The conclusion identifies "incorporating covariates and explicit causal graphs" as an "important next step" to "further tighten bounds."
- Why unresolved: The current framework relies solely on standard experimental and observational distributions, without leveraging background knowledge typically encoded in graphs or covariate data.
- What evidence would resolve it: Theoretical extensions of the closed-form bounds that condition on covariates or utilize graph topology to produce narrower intervals.

### Open Question 3
- Question: Can structural conditions like Monotonic Incremental Treatment Effect (MITE) be integrated to derive refined analytic bounds?
- Basis in paper: [explicit] The authors note that identifying "interpretable structural conditions" is "challenging" and suggest "integrating Monotonic Incremental Treatment Effect (MITE) is a promising direction."
- Why unresolved: While monotonicity ensures point identification in binary cases, its non-binary counterparts typically do not, leaving a need for better structural constraints.
- What evidence would resolve it: Derivation of updated bound formulas that explicitly include MITE or similar assumptions, demonstrating improved precision.

## Limitations

- Completeness gap: The paper conjectures but does not prove that closed-form bounds are tight in all dimensions. Empirical validation via Balke's LP method covers only up to n=4 dimensions.
- Data compatibility assumptions: Results assume experimental and observational data come from the same SCM. Violations (e.g., different populations, unmeasured confounding) invalidate bounds without detection mechanisms.
- Computational constraints: While closed-form bounds are faster than LP methods for small n, complexity grows with the number of treatment levels, potentially limiting scalability for high-cardinality discrete treatments.

## Confidence

- High confidence: Soundness of bounds (theorems 2-5 correctly derive valid intervals given compatible data)
- Medium confidence: Equivalence class transformations (Theorem 6) preserve linear programming structure
- Medium confidence: Replaceability principle (Theorem 7) enables cross-world query computation
- Low confidence: General tightness conjecture (beyond empirical n ≤ 4 verification)

## Next Checks

1. **Empirical tightness verification:** Generate synthetic SCMs with known PoC values for n ∈ {5, 10, 20}. Compare closed-form bounds against Balke's LP method to test conjecture empirically.

2. **Sensitivity analysis:** Introduce systematic violations of data compatibility assumptions (e.g., differential selection bias between experimental and observational data). Measure bound validity degradation.

3. **Structural assumption comparison:** Apply monotonicity/exclusion restrictions to the same queries and compare bound tightness gains versus the general approach. Quantify the tradeoff between generality and sharpness.