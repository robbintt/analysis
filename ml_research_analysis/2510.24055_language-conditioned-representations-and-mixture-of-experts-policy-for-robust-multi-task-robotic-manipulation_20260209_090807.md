---
ver: rpa2
title: Language-Conditioned Representations and Mixture-of-Experts Policy for Robust
  Multi-Task Robotic Manipulation
arxiv_id: '2510.24055'
source_url: https://arxiv.org/abs/2510.24055
tags:
- learning
- task
- expert
- lcvr
- manipulation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper tackles perceptual ambiguity and task conflict in multi-task
  robotic manipulation using imitation learning. Perceptual ambiguity arises when
  visually similar tasks require different actions, while task conflict occurs when
  a single policy network learns multiple tasks, leading to conflicting gradients.
---

# Language-Conditioned Representations and Mixture-of-Experts Policy for Robust Multi-Task Robotic Manipulation

## Quick Facts
- arXiv ID: 2510.24055
- Source URL: https://arxiv.org/abs/2510.24055
- Reference count: 40
- Primary result: 79% average success rate on 5-task real-robot manipulation, outperforming Σ-agent by 21%

## Executive Summary
This paper addresses perceptual ambiguity and task conflict in multi-task robotic manipulation via imitation learning. Perceptual ambiguity arises when visually similar tasks require different actions, while task conflict occurs when a single policy network learns multiple tasks, leading to conflicting gradients. The authors propose combining a Language-Conditioned Visual Representation (LCVR) module with a Language-conditioned Mixture-of-Experts Density Policy (LMoE-DP). LCVR grounds high-resolution visual features with language instructions to resolve ambiguity, while LMoE-DP uses sparse MoE architecture to specialize experts and mitigate task conflict, stabilized by gradient modulation via FAMO algorithm.

## Method Summary
The framework integrates LCVR for semantic grounding of visual features and LMoE-DP for specialized expert modeling. LCVR extracts global and local patches via frozen CLIP ViT-B/16, fuses them through cross-attention, concatenates with language embeddings, and passes through a lightweight Transformer. LMoE-DP employs a diffusion policy backbone with sequence-level gating selecting Top-2 experts during training and Top-1 during inference. Each expert outputs GMM parameters for multimodal action distributions. The system is trained with NLL loss plus auxiliary load-balancing and FAMO gradient modulation to reduce expert conflicts.

## Key Results
- LCVR improves baseline methods (ACT and DP) by 33.75% and 25% respectively on 4-task ambiguity benchmark
- Full framework achieves 79% average success rate on 5-task real-robot suite
- Outperforms advanced baseline (Σ-agent) by 21% success rate
- FAMO stabilization improves success from 54.6% to 85.9% in ablation studies

## Why This Works (Mechanism)

### Mechanism 1
Language-conditioned visual representations reduce perceptual ambiguity when multiple tasks share visually similar scenes. LCVR extracts one global and nine local patches via frozen CLIP ViT-B/16, fuses them via cross-attention (global as query), and concatenates with language embedding before a lightweight Transformer encoder. This grounds fine-grained visual features in task semantics. Core assumption: The language instruction reliably specifies user intent and is available at train and test time. Break condition: Ambiguous or missing instructions; visual-only baselines without language may fail to benefit.

### Mechanism 2
A sparse Mixture-of-Experts (MoE) policy head with Mixture Density Network (MDN) experts can mitigate task conflict and capture multimodal action distributions. A Transformer backbone produces X_feat; a sequence-level gating network selects Top-2 experts (soft, training) or Top-1 (hard, inference). Each expert outputs GMM parameters per timestep; the loss is the negative log-likelihood over the joint trajectory. Core assumption: Tasks can be approximately partitioned across experts with sufficient per-expert data to fit MDNs; routing is learnable from data. Break condition: Severe data scarcity per expert; expert collapse or unbalanced routing can degrade performance without mitigation.

### Mechanism 3
Gradient modulation via FAMO stabilizes shared-parameter optimization by reducing conflicting gradient directions among experts. At each step, compute expert-specific gradients g_i on shared parameters; FAMO solves a constrained min-norm problem to produce coefficients alpha_i and form g_FAMO; the final update adds the mixture-level NLL gradient for the gating network. Core assumption: Conflicting gradients exist across experts and can be reduced while preserving descent directions; auxiliary losses are necessary to avoid expert collapse. Break condition: Extremely diverse tasks where even projected gradients conflict; hyperparameter misconfiguration of the auxiliary loss.

## Foundational Learning
- **Cross-attention for feature fusion**: LCVR uses cross-attention to synthesize global and local visual tokens before language conditioning. Quick check: Can you explain why the global token is the query and local tokens are keys/values?
- **Mixture Density Networks (MDN)**: Each MoE expert parameterizes a GMM to represent multimodal action distributions. Quick check: How would a single-Gaussian head fail on tasks with multiple valid actions?
- **Diffusion policy formulation (DDIM denoising)**: The policy is a conditional diffusion model that predicts noise and iteratively recovers actions. Quick check: At inference, why does a consistent expert selection matter across denoising steps?

## Architecture Onboarding
- **Component map**: Visual tokens → cross-attention → language concatenation → z_LCVR → diffusion backbone → MoE routing → MDN expert prediction → loss + FAMO
- **Critical path**: Visual encoder (frozen CLIP ViT-B/16) extracts 1 global + 9 local patches → LCVR cross-attention fusion + language concatenation → lightweight Transformer → z_LCVR concatenated with proprioception → Transformer denoising backbone → sequence-level gating → Top-2 experts (train) or Top-1 (inference) → MDN expert prediction → NLL loss + FAMO gradient modulation
- **Design tradeoffs**: More experts (N_e) improve specialization but reduce per-expert data and can increase routing noise; more mixture components (M) help multimodality but can cause over-parameterization and optimization instability; FAMO adds per-step optimization overhead but improves gradient alignment and final performance
- **Failure signatures**: Expert collapse (LoadVar saturated near zero) or severe imbalance; gating stuck near deterministic (Top1Mean far above 1/N_e) or overly uniform with no specialization; validation NLL diverges or oscillates, especially with large M or N_e
- **First 3 experiments**:
  1. LCVR integration test: Train DP or ACT with LCVR on the 4-task ambiguity benchmark; compare average success vs baseline to target the reported 25–34% relative lift
  2. MoE ablation: Sweep N_e in {2,3,4,5} with M fixed (e.g., 5) on the 5-task suite; verify expert utilization and routing metrics
  3. FAMO ablation: Run with and without FAMO under multiple seeds; track GradCos, LoadVar, Top1Mean, Val-NLL, and real-robot success

## Open Questions the Paper Calls Out
The authors identify three key limitations and directions for future work. First, the current language conditioning operates at the static instruction level without dynamic adaptation to task progress, limiting adaptability to intermediate failures or environmental changes during execution. Second, the system relies on a single fixed-view RGB camera, making it sensitive to occlusion and limiting depth perception. Third, while the approach scales well for the tested 5 tasks, it remains unclear how the policy would perform when the number of distinct tasks significantly exceeds the optimal expert count identified in this work.

## Limitations
- Hyperparameter opacity: Critical parameters like Transformer depth/width, diffusion steps, learning rate, batch size, optimizer, and auxiliary loss weights are not specified
- Single-view dependency: The system relies on a fixed-view RGB camera, making it sensitive to occlusion and depth limitations
- Task generalization: Performance on unseen tasks or with ambiguous/natural language instructions remains untested

## Confidence
- **High confidence**: The effectiveness of LCVR in resolving perceptual ambiguity (supported by clear ablation and strong relative improvement over baselines)
- **Medium confidence**: The effectiveness of LMoE-DP in mitigating task conflict (supported by comparisons to Σ-agent and MoE ablation trends, but MoE training dynamics are sensitive to hyperparameters)
- **Medium confidence**: The effectiveness of FAMO in stabilizing gradient conflicts (supported by improved metrics, but auxiliary losses and hyperparameter tuning are critical)

## Next Checks
1. LCVR integration test: Train DP or ACT with LCVR on the 4-task ambiguity benchmark; compare average success vs baseline to target the reported 25–34% relative lift
2. MoE ablation study: Sweep N_e in {2,3,4,5} with M fixed (e.g., 5) on the 5-task suite; verify expert utilization and routing metrics (LoadVar, Top1Mean)
3. FAMO ablation test: Run with and without FAMO under multiple seeds; track GradCos, LoadVar, Top1Mean, Val-NLL, and real-robot success to confirm the 25%+ improvement