---
ver: rpa2
title: Foundations of Unknown-aware Machine Learning
arxiv_id: '2505.14933'
source_url: https://arxiv.org/abs/2505.14933
tags:
- data
- detection
- page
- learning
- wild
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This thesis addresses the challenge of ensuring reliability and
  safety in machine learning models when deployed in open-world environments, where
  unknown data distributions may arise. It introduces novel frameworks that optimize
  for both accurate in-distribution predictions and reliable handling of out-of-distribution
  data.
---

# Foundations of Unknown-aware Machine Learning

## Quick Facts
- arXiv ID: 2505.14933
- Source URL: https://arxiv.org/abs/2505.14933
- Reference count: 38
- One-line primary result: Introduces unknown-aware learning frameworks that enable reliable OOD detection and robustness in open-world environments with minimal human effort.

## Executive Summary
This thesis addresses the challenge of ensuring reliability and safety in machine learning models when deployed in open-world environments, where unknown data distributions may arise. It introduces novel frameworks that optimize for both accurate in-distribution predictions and reliable handling of out-of-distribution data. A key contribution is the development of an unknown-aware learning framework, including methods like VOS, NPOS, and DREAM-OOD, which generate informative unknown examples during training without requiring labeled OOD data. The thesis also proposes SAL, a framework leveraging unlabeled deployment data to enhance OOD detection under realistic conditions, with formal theoretical guarantees. Additionally, it advances reliability for large-scale foundation models by developing tools for hallucination detection (HaloScope), defending against malicious prompts (MLLMGuard), and data cleaning to denoise human feedback. Overall, these contributions promote unknown-aware learning as a new paradigm for advancing AI reliability with minimal human effort.

## Method Summary
The core method (VOS) synthesizes virtual outliers in the feature space to regularize decision boundaries for OOD detection. It estimates class-conditional Gaussian distributions in the penultimate feature space of ID data, samples virtual outliers from low-likelihood regions, and trains an auxiliary uncertainty branch using energy-based losses. SAL extends this by using unlabeled wild data, filtering OOD examples via gradient SVD, and training an OOD classifier. The method requires only labeled ID data, with no labeled OOD examples needed.

## Key Results
- Novel frameworks for unknown-aware learning including VOS, NPOS, and DREAM-OOD
- SAL framework leveraging unlabeled deployment data with theoretical guarantees for OOD detection
- Tools for foundation model reliability including HaloScope (hallucination detection), MLLMGuard (malicious prompt defense), and data cleaning methods
- Empirical validation showing improved OOD detection metrics across multiple benchmarks

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Synthesizing virtual outliers in the feature space creates tractable decision boundary regularization that reduces model overconfidence on OOD inputs.
- **Mechanism**: VOS models feature embeddings as class-conditional Gaussians, samples from low-likelihood regions, and applies energy-based losses to force lower confidence on boundary inputs.
- **Core assumption**: ID feature representations for a given class conform approximately to a Gaussian distribution.
- **Evidence anchors**:
  - [abstract]: "introduces novel frameworks for unknown-aware learning, including outlier synthesis methods (VOS, NPOS, DREAM-OOD)..."
  - [section 4.3.1]: "VOS synthesizes outliers that can estimate a compact decision boundary between ID and OOD data... sampling in the feature space is more tractable than generating high-dimensional pixels."
  - [corpus]: Weak/No direct validation in corpus neighbors.
- **Break condition**: Fails if ID feature clusters are highly irregular or non-Gaussian, causing synthetic outliers to fall inside actual ID support.

### Mechanism 2
- **Claim**: Unlabeled data collected "in the wild" can be separated using the top singular vector of the model's gradient matrix.
- **Mechanism**: SAL computes gradients for unlabeled wild data, performs SVD on the gradient matrix, and uses the top singular vector to filter OOD examples based on projection scores.
- **Core assumption**: Sufficient distributional discrepancy exists between ID and OOD gradients for effective separation.
- **Evidence anchors**:
  - [abstract]: "SAL... leverages unlabeled data to enhance out-of-distribution detection."
  - [section 8.2.1]: "Remark 1... shows that the projection of the OOD gradient vector to the top singular vector... is on average provably larger than that of the ID gradient vector."
  - [corpus]: Weak/No direct validation in corpus.
- **Break condition**: Separation degrades if wild data has very low OOD mixing ratio or OOD distribution is extremely similar to ID.

### Mechanism 3
- **Claim**: Hallucinations in LLMs can be detected by identifying a specific latent subspace where truthful and hallucinated outputs diverge.
- **Mechanism**: HaloScope performs SVD on activation embeddings, assumes hallucinations act as anomalies, and uses projection norms onto top singular vectors as hallucination scores.
- **Core assumption**: Hallucinated text generations occupy a distinct region in the LLM's activation space compared to truthful generations.
- **Evidence anchors**:
  - [abstract]: "advances reliability of foundation models by developing techniques for hallucination detection (HaloScope)..."
  - [section 10.3.2]: "HaloScope identifies a subspace... associated with hallucinated statements... measures the norm of the embedding projected onto the top singular vectors."
  - [corpus]: Weak/No direct validation in corpus.
- **Break condition**: Fails if truthful and hallucinated representations are highly entangled or subspace doesn't transfer across domains.

## Foundational Learning

- **Concept: Energy-based OOD Scoring**
  - **Why needed here**: Essential for VOS and NPOS. Energy scores (log-sum-exp of logits) provide more robust OOD detection than softmax probabilities alone.
  - **Quick check question**: Can you explain why maximizing the energy for synthetic outliers creates a "conservative" decision boundary compared to standard cross-entropy loss?

- **Concept: Von Mises-Fisher (vMF) Distributions**
  - **Why needed here**: Required for SIREN. vMF distributions model data on unit hyperspheres, allowing better representation shaping for normalized feature spaces.
  - **Quick check question**: How does the concentration parameter ($\kappa$) in a vMF distribution relate to the tightness of a class cluster on the unit sphere?

- **Concept: Singular Value Decomposition (SVD) for Subspace Identification**
  - **Why needed here**: Critical for SAL and HaloScope. SVD finds informative directions in high-dimensional matrices to separate signal from outliers.
  - **Quick check question**: If you compute SVD on a matrix of gradients, what does the top singular vector *physically* represent in terms of the model's weight updates?

## Architecture Onboarding

- **Component map**: Base Encoder -> Statistical Estimator -> Synthesis/Filtering Module -> Unknown-Aware Loss
- **Critical path**: Estimating reliable ID statistics -> Sampling/Filtering effective outliers -> Optimizing joint loss (ID task + Unknown-aware regularization)
- **Design tradeoffs**:
  - Feature vs. Pixel Synthesis: Feature-space synthesis (VOS) is computationally cheaper but lacks pixel-level interpretability; pixel-space synthesis (Dream-OOD) is interpretable but expensive.
  - Labeled vs. Unlabeled: Labeled ID-only methods (VOS) are robust but may fail on unseen shifts; unlabeled wild methods (SAL) adapt to real-world shifts but rely on sufficient mixing ratio and discrepancy.
- **Failure signatures**:
  - Mode Collapse (Synthesis): Generated outliers too similar to ID data, pushing decision boundary too far inward.
  - Gradient Overlap (SAL): Poor separability between ID and OOD gradients, leading to noisy OOD classifier training.
  - Distribution Shift (HaloScope): Subspace doesn't transfer across domains, causing hallucination detection to fail.
- **First 3 experiments**:
  1. Benchmark OOD Detection: Train ResNet-34 on CIFAR-100, evaluate VOS against baselines (MSP, ODIN, Energy) using SVHN and Textures datasets.
  2. Ablation on Outlier Synthesis: Compare VOS vs. Pixel-space GANs vs. Noise injection to verify feature-space sampling tractability.
  3. Wild Data Simulation (SAL): Mix CIFAR-100 with Textures at ratio π=0.1, run SAL to verify gradient-SVD score separates mixed samples.

## Open Questions the Paper Calls Out
None

## Limitations
- Feature-space Gaussian assumption may break for complex, non-convex manifolds, leading to synthetic outliers falling inside ID support.
- SAL's gradient-SVD separation relies on strong discrepancy between ID and OOD gradients, failing with minimal OOD content or similar distributions.
- HaloScope's subspace hallucination detection may fail under domain shifts or when truthful and hallucinated embeddings are highly entangled.

## Confidence
- **High**: General framing of unknown-aware learning as new paradigm and empirical validation of improved OOD detection metrics.
- **Medium**: Specific mechanisms (VOS, SAL, HaloScope) and theoretical underpinnings (Gaussian synthesis, gradient SVD, subspace projection).
- **Low**: Transferability to extreme distribution shifts or highly irregular data manifolds without significant tuning.

## Next Checks
1. Test VOS on datasets with known non-Gaussian feature distributions (Swiss Roll, concentric circles) to quantify impact of Gaussian assumption on OOD detection.
2. Create controlled experiment with varying OOD mixing ratios (π) and discrepancy levels (ζ) to empirically validate SAL's gradient-SVD filtering conditions.
3. Evaluate HaloScope on LLM generations from different domains (medical vs. legal text) to test stability and transferability of hallucination subspace across diverse data.