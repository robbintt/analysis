---
ver: rpa2
title: 'The Shape of Beliefs: Geometry, Dynamics, and Interventions along Representation
  Manifolds of Language Models'' Posteriors'
arxiv_id: '2602.02315'
source_url: https://arxiv.org/abs/2602.02315
tags:
- linear
- geometry
- distribution
- steering
- field
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates how large language models encode beliefs
  over latent parameters of data distributions and how interventions can be made to
  steer those beliefs while respecting the underlying geometry. The authors use a
  controlled setup where Llama-3.2 infers parameters (mean and standard deviation)
  of a normal distribution from in-context examples, forming curved "belief manifolds"
  in representation space.
---

# The Shape of Beliefs: Geometry, Dynamics, and Interventions along Representation Manifolds of Language Models' Posteriors

## Quick Facts
- arXiv ID: 2602.02315
- Source URL: https://arxiv.org/abs/2602.02315
- Reference count: 27
- Primary result: Linear interventions often push language model activations off belief manifolds, leading to unintended effects; manifold-based interventions preserve belief structure better.

## Executive Summary
This paper investigates how large language models encode beliefs over latent parameters of data distributions and how interventions can be made to steer those beliefs while respecting the underlying geometry. The authors use a controlled setup where Llama-3.2 infers parameters (mean and standard deviation) of a normal distribution from in-context examples, forming curved "belief manifolds" in representation space. They show that beliefs update along these manifolds when the input distribution changes, and that standard linear steering often pushes activations off-manifold, producing unintended effects on related parameters like variance. Linear field probes are introduced to tile the manifold and reveal its geometry; these probes vary smoothly with the parameter and only transfer locally, indicating curvature. Interventions based on manifold or field geometry preserve the intended belief family better than linear approaches. The findings demonstrate that belief representations are geometrically structured, and that linear concept representations are often inadequate abstractions. This suggests that future interpretability and steering methods should account for manifold structure to achieve more reliable control.

## Method Summary
The authors use Llama-3.2 to perform in-context inference of normal distribution parameters (mean and standard deviation) from example datasets. Belief manifolds are constructed by collecting model representations at specific belief values, then interpolating via spherical linear interpolation (slerp) to trace curved paths in activation space. Interventions are tested by comparing linear, field-based, and manifold-based steering methods. Linear probes are trained to predict parameter values across the manifold, and their predictions are used to guide interventions. Field probes are introduced to capture local geometry, and their smoothness and transferability are evaluated. The experiments are repeated across different parameter ranges and belief families (mean and standard deviation) to assess generality.

## Key Results
- Beliefs update along curved manifolds in activation space, not linearly, when input distribution changes.
- Linear interventions push activations off-manifold, causing unintended effects on related parameters (e.g., variance changes when targeting mean).
- Manifold and field-based interventions preserve belief family structure better than linear approaches.
- Linear probes tile the manifold but only transfer locally, indicating curvature; field probes vary smoothly with the parameter.
- Field probes reveal the underlying geometry of belief manifolds and can guide more precise interventions.

## Why This Works (Mechanism)
The paper demonstrates that belief representations in language models are geometrically structured as curved manifolds in activation space. Beliefs update along these manifolds, and linear interventions often fail because they push activations off-manifold, leading to unintended effects. Manifold and field-based interventions respect this geometry, preserving the intended belief family. Linear probes can tile the manifold but only transfer locally, indicating curvature. Field probes vary smoothly with the parameter, revealing the underlying geometry and enabling more precise interventions.

## Foundational Learning
- **Belief Manifolds**: Curved paths in activation space where beliefs over latent parameters reside; needed to understand how beliefs are encoded and updated.
- **Spherical Linear Interpolation (slerp)**: Interpolation method that respects the curved geometry of belief manifolds; needed to trace and explore manifold structure.
- **Field Probes**: Local probes that capture the geometry of belief manifolds; needed to reveal smoothness and transferability properties.
- **Linear vs. Manifold Interventions**: Different intervention strategies that either respect or ignore the manifold geometry; needed to compare steering effectiveness.
- **Log-likelihood Evaluation**: Metric used to assess intervention success; needed to quantify changes in inferred beliefs.
- **Transferability of Probes**: The extent to which probes trained at one belief value work at others; needed to assess manifold curvature.

## Architecture Onboarding
- **Component Map**: Dataset (normal distribution examples) -> Model (Llama-3.2) -> Representation (activation space) -> Manifold (belief manifold) -> Probes (linear/field) -> Intervention (steering) -> Evaluation (log-likelihood)
- **Critical Path**: In-context examples -> Model inference -> Manifold construction (slerp) -> Probe training -> Intervention design -> Log-likelihood evaluation
- **Design Tradeoffs**: Linear probes are simpler but ignore curvature; field probes capture geometry but require more computation; manifold interventions are more precise but may not scale to all tasks.
- **Failure Signatures**: Linear interventions causing off-manifold activations and unintended effects on related parameters; field probes failing to transfer across the manifold.
- **First Experiments**: 1) Construct belief manifold for mean inference and visualize its curvature; 2) Compare linear and manifold interventions for mean steering; 3) Train field probes to tile the manifold and assess their smoothness and transferability.

## Open Questions the Paper Calls Out
- How do belief manifolds generalize to more complex or naturalistic tasks?
- What is the effect of model size and architecture on belief manifold geometry?
- Can field probe tiling scale to higher-dimensional belief spaces?
- How do belief manifolds interact with broader context or multiple interacting beliefs?
- Are there alternative non-manifold update hypotheses that could explain belief dynamics?

## Limitations
- The study relies on a highly controlled synthetic setup (normal distribution parameter estimation) that may not generalize to more complex or naturalistic tasks.
- The Llama-3.2 model version used is not specified in detail, which could affect the geometry of belief manifolds.
- Intervention success is evaluated primarily through log-likelihood changes, which may not capture all aspects of behavioral fidelity or downstream task performance.
- The assumption that beliefs should update along manifolds is theoretically grounded but not empirically validated against alternative non-manifold update hypotheses.

## Confidence
- **High Confidence**: Claims about the existence of curved belief manifolds and the observation that linear interventions push activations off-manifold are supported by direct empirical evidence from the controlled experiments.
- **Medium Confidence**: The assertion that manifold-based interventions preserve belief family structure better than linear methods is plausible but relies on a narrow set of interventions and evaluation metrics (log-likelihood). Generalization to broader belief types and tasks remains to be seen.
- **Medium Confidence**: The conclusion that linear concept representations are inadequate abstractions for steering is well-supported within the experimental scope but may not fully apply to all interpretability or control scenarios, particularly those involving non-belief-related concepts.

## Next Checks
1. **Generalization Test**: Apply the same experimental framework to a more naturalistic task (e.g., sentiment inference or topic modeling) to verify whether belief manifolds and curvature effects persist outside synthetic parameter estimation.
2. **Intervention Robustness**: Systematically test manifold-based interventions across multiple parameter combinations and belief families to assess whether the observed improvements in steering fidelity are consistent and robust.
3. **Scalability Analysis**: Investigate whether the field probe tiling approach can be scaled to higher-dimensional belief manifolds (e.g., multi-parameter or hierarchical beliefs) without prohibitive computational cost or loss of resolution.