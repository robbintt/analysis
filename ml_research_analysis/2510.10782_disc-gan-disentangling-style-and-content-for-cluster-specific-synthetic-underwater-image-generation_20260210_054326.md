---
ver: rpa2
title: 'DISC-GAN: Disentangling Style and Content for Cluster-Specific Synthetic Underwater
  Image Generation'
arxiv_id: '2510.10782'
source_url: https://arxiv.org/abs/2510.10782
tags:
- style
- underwater
- image
- content
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generating photorealistic
  underwater images by disentangling style and content in a cluster-specific training
  strategy. The authors propose DISC-GAN, which first partitions the dataset into
  four style clusters using K-means clustering on color and depth features inspired
  by Jerlov water types.
---

# DISC-GAN: Disentangling Style and Content for Cluster-Specific Synthetic Underwater Image Generation

## Quick Facts
- arXiv ID: 2510.10782
- Source URL: https://arxiv.org/abs/2510.10782
- Reference count: 31
- Achieves SSIM 0.9012, PSNR 32.5118 dB, and FID 13.3728 for underwater image synthesis

## Executive Summary
This paper addresses the challenge of generating photorealistic underwater images by disentangling style and content in a cluster-specific training strategy. The authors propose DISC-GAN, which first partitions the dataset into four style clusters using K-means clustering on color and depth features inspired by Jerlov water types. Then, separate encoders extract style and content representations, which are fused via Adaptive Instance Normalization (AdaIN) and decoded to produce the final synthetic image. The model is trained independently on each style cluster to preserve domain-specific characteristics. The framework achieves state-of-the-art performance with high structural similarity, quality scores, and low Frechet Inception Distance.

## Method Summary
DISC-GAN addresses underwater image synthesis by first clustering the dataset into four style categories using K-means on color and depth features inspired by Jerlov water types. The framework employs separate encoders for extracting style and content representations from input images. These representations are fused using Adaptive Instance Normalization (AdaIN), which transfers style information while preserving content structure. The fused features are then decoded to generate synthetic underwater images. Crucially, the model is trained independently on each style cluster, allowing it to capture and preserve domain-specific underwater characteristics. This cluster-specific approach enables the generation of diverse yet consistent underwater scenes that reflect different water conditions and lighting environments.

## Key Results
- Achieves SSIM of 0.9012, indicating high structural similarity between generated and real underwater images
- Attains average PSNR of 32.5118 dB, demonstrating good image quality and reconstruction
- Achieves FID of 13.3728, showing realistic image generation with low distribution discrepancy

## Why This Works (Mechanism)
The approach works by leveraging style-content disentanglement to separately capture underwater appearance characteristics (style) and scene structure (content). The cluster-specific training strategy allows the model to learn distinct underwater visual patterns corresponding to different water types and conditions, preventing style mixing across diverse underwater environments. Adaptive Instance Normalization provides an effective mechanism for style transfer while maintaining content integrity, enabling photorealistic synthesis that respects both the structural and visual properties of underwater scenes.

## Foundational Learning

1. **Style-Content Disentanglement**: Separating visual appearance from structural information enables targeted manipulation and generation of specific image attributes
   - Why needed: Allows independent control over underwater appearance (color, clarity) and scene composition
   - Quick check: Verify that style and content encoders produce distinct, interpretable feature representations

2. **K-means Clustering on Water Features**: Grouping images by color and depth characteristics inspired by Jerlov water types
   - Why needed: Captures the natural variation in underwater environments to enable specialized model training
   - Quick check: Ensure clusters represent distinct underwater conditions with minimal intra-cluster variation

3. **Adaptive Instance Normalization (AdaIN)**: Layer that modulates content features using style statistics
   - Why needed: Provides an effective mechanism for transferring style information while preserving content structure
   - Quick check: Confirm style transfer effectiveness by visualizing content with different style encodings

4. **Cluster-Specific Training**: Training separate models for each identified style cluster
   - Why needed: Prevents style mixing and enables specialized learning