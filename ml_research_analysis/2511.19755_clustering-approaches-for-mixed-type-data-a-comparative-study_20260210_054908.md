---
ver: rpa2
title: 'Clustering Approaches for Mixed-Type Data: A Comparative Study'
arxiv_id: '2511.19755'
source_url: https://arxiv.org/abs/2511.19755
tags:
- data
- variables
- clustering
- https
- cluster
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study compares six clustering methods for mixed-type data
  (continuous, nominal, ordinal) using four simulation models with varied experimental
  factors such as cluster overlap, sample size, and variable types. Methods tested
  include distance-based approaches (k-prototypes, PDQ, convex k-means) and probabilistic
  models (KAMILA, MBN, LCM).
---

# Clustering Approaches for Mixed-Type Data: A Comparative Study

## Quick Facts
- **arXiv ID:** 2511.19755
- **Source URL:** https://arxiv.org/abs/2511.19755
- **Reference count:** 40
- **Primary result:** KAMILA outperformed other methods across most scenarios, showing highest ARI values and being least affected by variable type ratios

## Executive Summary
This study provides a comprehensive benchmark of six clustering algorithms for mixed-type data (continuous, nominal, ordinal) using four simulation models with varied experimental factors. The methods tested include distance-based approaches (k-prototypes, PDQ, convex k-means) and probabilistic models (KAMILA, MBN, LCM). Results show that KAMILA consistently delivered the best performance across most scenarios, particularly when prior knowledge about data distribution was unavailable. The study highlights that clustering effectiveness is highly context-dependent, with performance varying based on cluster overlap, sample size, and variable type proportions.

## Method Summary
The study compares six clustering methods using four simulation models: M1 (Multivariate Gaussian), M2 (Exponential-Discrete), M3 (BN Classifier with strong interactions), and M4 (Mixture of Bayesian Networks). Each model varies cluster overlap, sample size (300-1400), and variable type ratios. Methods include k-prototypes (hybrid distance with user weight), PDQ (Gower-based automatic weighting), convex k-means (grid search for optimal weighting), KAMILA (semiparametric likelihood-based), LCM (full parametric with variable selection), and MBN (structure learning + CEM). All experiments used 10 replicates with 10-20 random initializations in R.

## Key Results
- KAMILA achieved the highest ARI values across most scenarios and was least affected by continuous-to-categorical variable ratios
- k-prototypes and LCM performed well when clusters were spherical and continuous variables dominated
- All methods struggled when strong variable interactions coexisted with explicit cluster-dependence structure
- PDQ and MBN showed generally poor performance, with MBN only outperforming others in 4 out of 8 M3 scenarios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: KAMILA's semiparametric likelihood-based objective function provides robustness across varying continuous-to-categorical variable ratios
- Mechanism: KAMILA estimates continuous variables via kernel density on radial distance to cluster centers while modeling categorical variables as independent multinomials within clusters, then combines both via log-likelihood without explicit weighting
- Core assumption: Continuous variables follow spherical symmetric distributions within clusters; categorical variables are conditionally independent given cluster membership
- Evidence anchors: Abstract states KAMILA was least affected by variable ratios; section 2.2 describes hybrid density estimation approach

### Mechanism 2
- Claim: Distance-based methods perform well when clusters are spherical and continuous variables dominate
- Mechanism: These methods minimize weighted combinations of within-cluster dispersion for continuous (squared Euclidean) and categorical (Hamming/cosine) distances
- Core assumption: A single weighting parameter can appropriately balance contributions from different variable types
- Evidence anchors: Abstract notes performance dependency on variable type proportions; results show k-prototypes better when continuous variables dominate

### Mechanism 3
- Claim: All evaluated methods fail when strong variable interactions coexist with explicit cluster-dependence structure
- Mechanism: Neither distance-based approaches nor KAMILA/LCM model dependencies between variables
- Core assumption: Variable independence within clusters or simple distance metrics suffice for clustering
- Evidence anchors: Abstract states none of the evaluated methods demonstrated satisfactory performance in these scenarios; M3 results show MBN only outperforms others in 4 out of 8 scenarios

## Foundational Learning

- Concept: Adjusted Rand Index (ARI) for clustering evaluation
  - Why needed here: The paper uses ARI as the primary metric for comparing methods
  - Quick check question: If a method achieves ARI = 0.7 on a 5-cluster problem with 30% overlap, what does this tell you about its clustering quality relative to random assignment?

- Concept: Mixture models and the EM algorithm
  - Why needed here: LCM, KAMILA, and MBN all use mixture model formulations with EM/CEM optimization
  - Quick check question: Why does the EM algorithm for mixture models require multiple random initializations to avoid local optima?

- Concept: Variable type weighting in mixed data distances
  - Why needed here: k-prototypes, PDQ, and convex k-means all address the fundamental challenge of combining incompatible distance scales
  - Quick check question: In k-prototypes, if γ is set too high relative to the scale of continuous variables, what happens to the clustering behavior?

## Architecture Onboarding

- Component map: Distance-based layer (k-prototypes, PDQ, convex k-means) -> Probabilistic layer (KAMILA, LCM, MBN) -> Evaluation (ARI, AMI) -> All methods available via R packages

- Critical path: 1) Assess data characteristics (cluster overlap, sample size, variable type ratio, expected cluster shape) 2) If no prior knowledge → start with KAMILA 3) If spherical clusters expected → try LCM 4) If continuous-dominated data with small samples → consider k-prototypes 5) If variable interactions suspected → MBN (but validate structure learning) 6) Always run multiple initializations (10-20) and report stability

- Design tradeoffs: KAMILA vs. LCM (KAMILA avoids weighting but assumes spherical continuous distributions; LCM is more flexible for Gaussian data but struggles with non-normality); k-prototypes vs. convex k-means (k-prototypes requires manual weight tuning but handles imbalance better; convex k-means automates weighting but has edge-case failures)

- Failure signatures: Near-zero ARI with PDQ on non-Gaussian data → method fundamentally unsuited; KAMILA/LCM degrading on small samples (N < 300) → insufficient data for multinomial parameter estimation; Convex k-means ignoring continuous variables → categorical level combinations equal K; All methods performing poorly (ARI < 0.3) → possible strong variable interactions

- First 3 experiments: 1) Baseline comparison: Run KAMILA, k-prototypes (with λ = std(cont)/std(cat) as initial weight), and LCM on your data with K from domain knowledge. Compare ARI across 10 random seeds. 2) Weight sensitivity: For k-prototypes, sweep γ across [0.1×λ, 10×λ] and plot ARI vs. γ. 3) Sample size robustness: Subsample your data at 50% and 75% of full size. If KAMILA/LCM degrade substantially, gather more data or consider k-prototypes as an alternative.

## Open Questions the Paper Calls Out

- How can clustering algorithms be developed to effectively handle strong interactions between variables alongside an explicit dependence on cluster membership? The authors note that "none of the evaluated methods demonstrated satisfactory performance" in these specific scenarios (Simulation Model M3).

- How does the explicit treatment of ordinal variables influence the comparative performance of mixed-type clustering methods? The authors state that "ordinal variables were not considered in the study" and that this "limitation could impact clustering performance."

- Can interpretable nonhierarchical methods like CUBT or DIVCLUS-T be adapted to simultaneously determine the optimal number of clusters and provide interpretable results for mixed-type data? The authors suggest "incorporating interpretable nonhierarchical methods" to address the lack of solutions for "optimal number of clusters or the interpretability of the results."

## Limitations

- Study relies entirely on synthetic data, which may not capture real-world data complexities such as missing values, noise patterns, or non-standard distributions
- Computational cost of running multiple methods with numerous random initializations limits scalability to larger datasets
- Ordinal variables were excluded from the experimental factors, limiting applicability to datasets where ordinal data is prevalent

## Confidence

- **High confidence:** KAMILA's superior robustness across variable type ratios, as evidenced by consistently high ARI scores across all simulation models
- **Medium confidence:** General performance rankings (KAMILA > k-prototypes > LCM > Convex k-means > PDQ > MBN), as these depend on specific simulation parameters that may not generalize
- **Medium confidence:** Claims about variable interaction problems, as the M3 model may not fully capture all forms of complex dependencies found in real data

## Next Checks

1. **Real Data Validation:** Apply the top three methods (KAMILA, k-prototypes, LCM) to a benchmark mixed-type dataset with known ground truth (e.g., UCI Adult dataset) to verify simulation-based conclusions

2. **Sample Size Sensitivity:** Systematically vary sample sizes below 300 (e.g., N=100, 200) to determine the exact thresholds where KAMILA and LCM performance degrades

3. **Variable Interaction Test:** Design a simulation with controlled interaction effects (e.g., XOR-like relationships between continuous and categorical variables) to more precisely identify conditions where all methods fail