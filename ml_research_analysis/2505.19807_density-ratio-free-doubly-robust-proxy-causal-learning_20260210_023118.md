---
ver: rpa2
title: Density Ratio-Free Doubly Robust Proxy Causal Learning
arxiv_id: '2505.19807'
source_url: https://arxiv.org/abs/2505.19807
tags:
- bridge
- function
- kernel
- treatment
- outcome
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses causal effect estimation under unobserved\
  \ confounding in the Proxy Causal Learning (PCL) framework, where proxy variables\
  \ for both treatment and outcome are available. The authors propose two kernel-based\
  \ doubly robust estimators\u2014DRKPV and DRPMMR\u2014that combine outcome bridge\
  \ and treatment bridge functions to identify causal effects without explicit density\
  \ ratio estimation."
---

# Density Ratio-Free Doubly Robust Proxy Causal Learning

## Quick Facts
- arXiv ID: 2505.19807
- Source URL: https://arxiv.org/abs/2505.19807
- Reference count: 40
- Primary result: Kernel-based doubly robust estimators DRKPV and DRPMMR that estimate causal effects under unobserved confounding using proxy variables, without density ratio estimation, and remain consistent when either bridge function is correctly specified.

## Executive Summary
This paper addresses causal effect estimation under unobserved confounding in the Proxy Causal Learning (PCL) framework, where proxy variables for both treatment and outcome are available. The authors propose two kernel-based doubly robust estimators—DRKPV and DRPMMR—that combine outcome bridge and treatment bridge functions to identify causal effects without explicit density ratio estimation. Leveraging conditional mean embeddings in reproducing kernel Hilbert spaces, both estimators admit closed-form solutions and are shown to be consistent under appropriate conditions. Experiments on synthetic and real-world datasets demonstrate that the proposed methods outperform state-of-the-art PCL baselines, including prior doubly robust approaches that rely on kernel smoothing and density ratio estimation. The methods also exhibit robustness under misspecification of bridge functions, with the doubly robust property ensuring consistency if either bridge function is correctly specified.

## Method Summary
The proposed approach combines kernel-based doubly robust estimation with proxy causal learning. DRKPV uses Kernel Proxy Value (KPV) for the outcome bridge function and Kernel Anchor Regression (KAP) for the treatment bridge function. DRPMMR replaces KPV with Proximal Mean Representation (PMMR). Both methods estimate dose-response curves via three components: the outcome bridge prediction E[h₀(W,a)], the treatment bridge prediction E[Yφ₀(Z,a)|A=a], and a slack term E[φ₀(Z,a)h₀(W,a)|A=a]. The key innovation is reformulating the treatment bridge without density ratios using conditional mean embeddings, enabling closed-form solutions while maintaining the doubly robust property. Regularization parameters are tuned via leave-one-out cross-validation or validation sets, and Gaussian kernels with median heuristic bandwidths are used throughout.

## Key Results
- DRKPV and DRPMMR outperform state-of-the-art PCL baselines on synthetic and real-world datasets
- Methods remain robust under misspecification of either bridge function due to doubly robust property
- DRPMMR achieves better performance than DRKPV by using all data in the PMMR stage
- Methods successfully handle high-dimensional proxy variables (e.g., 64×64 pixel images in dSprite dataset)
- Consistent with theoretical guarantees, methods maintain accuracy even when one bridge function is partially misspecified

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The doubly robust estimator remains consistent if either the outcome bridge function or treatment bridge function is correctly specified, but not necessarily both.
- Mechanism: The identification formula θ^(DR)(a) = E[φ₀(Z,a)(Y−h₀(W,a))|A=a] + E[h₀(W,a)] decomposes into three terms. When h is correct, the first term's expectation becomes zero (from the bridge equation), leaving E[h₀(W,a)] which identifies the dose-response. When φ is correct, the cross-term E[φ₀(Z,a)h(W,a)|A=a] cancels with E[h(W,a)] via the treatment bridge equation, leaving E[Yφ₀(Z,a)|A=a] which also identifies the target.
- Core assumption: Either the outcome bridge completeness condition (Assumption 2.3) or treatment bridge completeness condition (Assumption 2.5) holds.
- Evidence anchors:
  - [Section 2.3, Theorem 2.7]: "θ^(DR)_ATE identifies the dose-response curve if either h solves Equation (1) or φ solves Equation (2)—but not necessarily both."
  - [Appendix A]: Full proof showing the algebraic cancellation in both cases.
  - [corpus]: Related work on doubly robust identification from multiple environments confirms the general DR principle, though not specific to PCL settings.
- Break condition: Both bridge functions are misspecified simultaneously, or neither completeness assumption holds.

### Mechanism 2
- Claim: The density ratio-free treatment bridge formulation avoids explicit density ratio estimation by reformulating the objective as a conditional expectation matching problem solvable via kernel ridge regression.
- Mechanism: The original bridge equation E[φ₀(Z,a)|W,A=a] = p(W)p(a)/p(W,a) is rewritten as a regularized least-squares objective L_KAP(φ) = E[(r(W,A)−E[φ(Z,A)|W,A])²] + λ∥φ∥². The conditional expectation E[φ(Z,A)|W,A] is approximated via conditional mean embeddings estimated through vector-valued kernel ridge regression, yielding closed-form solutions without density ratio terms.
- Core assumption: Existence of conditional mean embedding operator C_{Z|W,A} in the RKHS (Assumption E.2-1).
- Evidence anchors:
  - [Section 3.2, Equation 4]: Shows the reformulated objective with no density ratio terms: "E[φ(Z,A)|W,A]² − E_W E_A[E[φ(Z,A)|W,A]] + λ∥φ∥²."
  - [Section 2.2]: References the treatment bridge formulation from prior work (Bozkurt et al., 2025).
  - [corpus]: The companion paper "Density Ratio-based Proxy Causal Learning Without Density Ratios" provides the foundational KAP algorithm this builds upon.
- Break condition: The conditional mean embedding cannot be accurately estimated (e.g., insufficient data, poor kernel choice, or violation of RKHS embedding assumptions).

### Mechanism 3
- Claim: The slack term estimator E[φ₀(Z,a)h₀(W,a)|A=a] uses a conditional mean embedding of the joint (Z,W) space to capture the interaction between bridge functions.
- Mechanism: The interaction is expressed as an inner product in a tensor product RKHS: ⟨φ⊗h, E[ϕ_Z(Z)⊗ϕ_W(W)|A=a]⊗ϕ_A(a)⊗ϕ_A(a)⟩. The conditional mean embedding μ_{Z,W|A}(a) is learned via vector-valued kernel ridge regression, and the final estimate becomes Σ_s ξ_s(a)φ̂(z_s,a)ĥ(w_s,a) where ξ_s(a) = [(K_AA + tλ_DR I)^(-1) K_Aa]_s.
- Core assumption: Regularity condition that E[g(Z,W)|A=·] ∈ H_A for all g ∈ H_{ZW} (Assumption E.20).
- Evidence anchors:
  - [Section 3.2, Equation 5-6]: Derivation showing the tensor product structure and final closed-form estimator.
  - [Appendix C.3]: Full derivation of the slack term approximation using conditional mean embeddings.
  - [corpus]: No directly comparable mechanism in corpus; this appears novel to the PCL doubly robust setting.
- Break condition: Poor estimation of the joint conditional embedding due to high dimensionality or insufficient overlap in the A distribution.

## Foundational Learning

- Concept: **Reproducing Kernel Hilbert Spaces (RKHS) and Kernel Mean Embeddings**
  - Why needed here: All estimators are expressed as inner products in RKHSs. Understanding how distributions embed into Hilbert spaces via kernels is essential for grasping why closed-form solutions exist.
  - Quick check question: Can you explain why E[h(W,a)] = ⟨h, μ_W⊗ϕ_A(a)⟩_{H_W⊗H_A} holds?

- Concept: **Fredholm Integral Equations and Bridge Functions**
  - Why needed here: Bridge functions solve integral equations relating conditional expectations across variables. Recognizing these as Fredholm equations helps understand why existence requires completeness conditions.
  - Quick check question: Why does the outcome bridge equation E[Y|Z,A] = ∫h(w,A)p(w|Z,A)dw require the completeness of Z given U?

- Concept: **Doubly Robust Estimation Theory**
  - Why needed here: The paper's key contribution is extending DR from standard causal inference to the proxy setting. Understanding how influence functions lead to DR forms provides theoretical grounding.
  - Quick check question: In standard DR estimation for ATE, what two models can be misspecified without losing consistency?

## Architecture Onboarding

- Component map:
  - Outcome Bridge Estimator (KPV/PMMR) -> Treatment Bridge Estimator (KAP) -> Slack Term Estimator -> DR Combiner

- Critical path:
  1. Stage 1 (KAP/KPV): Estimate conditional mean embeddings μ_{W|Z,A} and μ_{Z|W,A}
  2. Stage 2 (KAP/KPV): Solve for bridge function coefficients via regularized least squares
  3. Stage 3 (KAP): Estimate μ_{YZ|A} for treatment bridge dose-response
  4. Slack estimation: Learn μ_{Z,W|A} via vector-valued KRR
  5. Combine: Sum the three dose-response estimates

- Design tradeoffs:
  - DRKPV vs DRPMMR: KPV requires data splitting across stages (reduces effective sample size) but has separate tuning; PMMR uses all data but has coupled optimization
  - Kernel bandwidth selection: Median heuristic is fast but may be suboptimal for high-dimensional proxies
  - Regularization: LOOCV is used for most λ's; validation set for second-stage regressions—cross-validation adds computational overhead

- Failure signatures:
  - **Negative slack predictions**: If φ̂ĥ term becomes large and negative, dose-response may be outside plausible range—suggests bridge function estimation failure
  - **High variance across runs**: Inconsistent estimates suggest sensitivity to data splits or regularization
  - **Dose-response monotonic in treatment**: May indicate proxy informativeness failure (one completeness assumption violated)

- First 3 experiments:
  1. **Synthetic validation with ground truth**: Use the synthetic data generation from Section 5 to verify the code produces Figure 2a results. Check that DRKPV/DRPMMR outperform baselines at n=500, 1000, 2000.
  2. **Bridge misspecification robustness test**: Perturb one bridge function's coefficients with N(0,0.2) noise as in Figure 3. Verify the slack term compensates and DR estimate remains accurate while single-bridge methods fail.
  3. **High-dimensional treatment stress test**: Run on dSprite dataset (4096-dim treatments). Confirm DR methods still work and compare to PKDR (which should fail on high-dim treatments per Section 5).

## Open Questions the Paper Calls Out

- **Question 1**: Can scalable kernel approximations (e.g., random Fourier features, Nystrom methods) be integrated into the DRKPV and DRPMMR estimators while preserving their uniform consistency guarantees and double robustness properties?
  - Basis in paper: [explicit] The authors state: "A key limitation our work is the computational cost of kernel methods, motivating future work on scalable approximations."
  - Why unresolved: The proposed methods require O(t³) matrix inversions for training samples of size t, limiting applicability to large datasets. No theoretical analysis exists for how approximations affect the convergence rates in Theorems E.27 and E.28.
  - What evidence would resolve it: Derivation of convergence rates for DRKPV/DRPMMR with random feature or Nystrom approximations, plus empirical validation on large-scale datasets.

- **Question 2**: Do DRKPV and DRPMMR achieve the semiparametric efficiency bound for continuous treatments, analogous to the discrete treatment case?
  - Basis in paper: [explicit] Remark B.6 notes that the efficient influence function (EIF) in the continuous treatment case "may not be unique" and that "our framework extends naturally to continuous treatments without needing a kernel smoothing step." The paper derives the EIF for discrete treatments but does not prove efficiency for the continuous setting.
  - Why unresolved: The identification formula differs from Cui et al. [17], and the paper does not establish whether the proposed estimators attain the efficiency bound in the continuous treatment regime.
  - What evidence would resolve it: A proof showing the variance of DRKPV/DRPMMR achieves the semiparametric efficiency bound for continuous treatments, or an analysis of the efficiency gap.

- **Question 3**: What are the theoretical performance bounds when both the outcome bridge function h₀ and treatment bridge function φ₀ are misspecified simultaneously but approximately correct?
  - Basis in paper: [inferred] The paper empirically evaluates robustness under single bridge misspecification (Section 5, Figures 3-4) but does not analyze the joint misspecification regime where both bridges are partially incorrect.
  - Why unresolved: Double robustness guarantees consistency if either bridge is correctly specified, but practical scenarios may involve partial misspecification of both. The error decomposition in Lemma E.22 suggests product-rate behavior, but no explicit bounds are provided for this regime.
  - What evidence would resolve it: Theoretical bounds on estimation error when ∥ĥ − h₀∥ ≤ ε₁ and ∥φ̂ − ₀∥ ≤ ε₂, plus simulations systematically varying both error levels.

## Limitations

- Computational complexity: The methods require O(t³) matrix inversions for training samples of size t, limiting scalability to large datasets
- Dependence on kernel quality: Performance relies heavily on appropriate kernel bandwidth selection and the validity of conditional mean embedding assumptions
- Curse of dimensionality: The slack term estimation using tensor product RKHS may suffer from the curse of dimensionality in high-dimensional proxy settings

## Confidence

- **High Confidence**: The doubly robust identification mechanism (Mechanism 1) is mathematically sound and follows established DR principles, with the proof structure well-documented in Appendix A.
- **Medium Confidence**: The density ratio-free reformulation (Mechanism 2) is theoretically valid but practical performance depends heavily on the quality of conditional mean embedding estimation, which can be sensitive to kernel bandwidth and sample size.
- **Medium Confidence**: The slack term estimation (Mechanism 3) is the most novel component and lacks extensive empirical validation beyond the presented experiments.

## Next Checks

1. **Synthetic stress test with explicit confounding strength variation**: Generate data with varying degrees of unobserved confounding (e.g., control the correlation between U and treatment/outcome) to systematically evaluate DR methods' robustness across the confounding spectrum.

2. **High-dimensional proxy ablation study**: Test DRKPV/DRPMMR on progressively higher-dimensional proxies (beyond 4096) while monitoring MSE and computational time to identify the dimensional limit of the approach.

3. **Real-world sensitivity analysis**: Apply methods to additional semi-synthetic datasets where ground truth causal effects are known, focusing on domains with naturally occurring proxy variables (e.g., education policy evaluation with test score proxies).