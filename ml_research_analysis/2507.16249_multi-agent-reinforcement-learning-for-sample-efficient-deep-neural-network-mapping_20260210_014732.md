---
ver: rpa2
title: Multi-Agent Reinforcement Learning for Sample-Efficient Deep Neural Network
  Mapping
arxiv_id: '2507.16249'
source_url: https://arxiv.org/abs/2507.16249
tags:
- marl
- agent
- mapping
- parameters
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of efficiently mapping deep
  neural networks (DNNs) to hardware accelerators, which is critical for optimizing
  latency, energy consumption, and resource utilization. The authors propose a decentralized
  multi-agent reinforcement learning (MARL) framework that significantly improves
  sample efficiency over traditional single-agent approaches.
---

# Multi-Agent Reinforcement Learning for Sample-Efficient Deep Neural Network Mapping

## Quick Facts
- arXiv ID: 2507.16249
- Source URL: https://arxiv.org/abs/2507.16249
- Authors: Srivatsan Krishnan, Jason Jabbour, Dan Zhang, Natasha Jaques, Aleksandra Faust, Shayegan Omidshafiei, Vijay Janapa Reddi
- Reference count: 31
- Primary result: 30-300× faster convergence than single-agent RL with up to 32.61× latency reduction and 16.45× EDP reduction

## Executive Summary
This paper addresses the challenge of efficiently mapping deep neural networks (DNNs) to hardware accelerators, which is critical for optimizing latency, energy consumption, and resource utilization. The authors propose a decentralized multi-agent reinforcement learning (MARL) framework that significantly improves sample efficiency over traditional single-agent approaches. The core innovation is a clustering-based agent assignment algorithm that groups correlated mapping parameters under shared agents while distributing independent parameters across different agents.

## Method Summary
The approach introduces a decentralized multi-agent reinforcement learning framework for DNN-to-hardware accelerator mapping. The key innovation is a clustering-based agent assignment algorithm that groups correlated mapping parameters under shared agents while distributing independent parameters across different agents. This enables parallelized exploration of the vast mapping space while reducing computational overhead. The framework trains multiple agents simultaneously, each responsible for different aspects of the mapping decision space, with a centralized critic providing global value estimates.

## Key Results
- MARL achieves 30-300× faster convergence than single-agent RL
- Up to 32.61× latency reduction and 16.45× energy-delay product (EDP) reduction under equal sample budgets
- Consistently outperforms state-of-the-art baselines including random search, Bayesian optimization, genetic algorithms, and GAMMA
- Particularly effective for convolutional neural networks with the most complex search spaces

## Why This Works (Mechanism)
The decentralized multi-agent approach enables parallel exploration of the mapping space while the clustering-based agent assignment ensures that correlated parameters are optimized together. This reduces redundant exploration and enables more efficient gradient updates. The centralized critic provides global value estimates that help coordinate the agents' learning, preventing them from diverging in incompatible directions.

## Foundational Learning
- **Multi-Agent Reinforcement Learning**: Multiple agents learn simultaneously to solve a shared problem. Needed because single agents struggle with the high-dimensional mapping space. Quick check: Can agents coordinate without centralized control?
- **DNN-to-Hardware Mapping**: Process of allocating DNN operations to hardware resources. Needed because optimal mapping significantly impacts performance metrics. Quick check: What hardware constraints must be considered?
- **Reinforcement Learning Sample Efficiency**: How quickly an RL algorithm learns from limited samples. Needed because exhaustive search is computationally prohibitive. Quick check: How does sample efficiency scale with problem size?
- **Clustering Algorithms**: Methods for grouping similar data points. Needed to determine which mapping parameters should be controlled by the same agent. Quick check: What clustering metric best captures parameter correlation?
- **Centralized Critic Architecture**: A single value function estimator that observes all agents' actions. Needed to provide global feedback and coordinate learning. Quick check: How does critic capacity affect learning stability?
- **Hardware Accelerator Design**: Specialized hardware for DNN inference. Needed to understand constraints and optimization opportunities. Quick check: What are the key bottlenecks in accelerator architectures?

## Architecture Onboarding

**Component Map**: DNN Architecture -> Parameter Clustering -> Agent Assignment -> MARL Training -> Hardware Mapping

**Critical Path**: The most time-consuming aspect is the MARL training process, particularly the interaction between multiple agents and the centralized critic. The clustering step occurs once at initialization, while the mapping evaluation (to provide rewards) depends on hardware simulation speed.

**Design Tradeoffs**: The framework trades increased algorithmic complexity (multiple agents, clustering) for improved sample efficiency and final performance. While single-agent approaches are simpler, they struggle with the curse of dimensionality in the mapping space.

**Failure Signatures**: Poor clustering can lead to agents learning redundant or conflicting mappings. Insufficient agent diversity can result in local optima. Overly aggressive parallelization may cause instability in the centralized critic's value estimates.

**Three First Experiments**:
1. Test clustering sensitivity by varying the number of clusters and measuring convergence speed
2. Compare different reward formulations (latency-only vs. EDP vs. multi-objective)
3. Evaluate scalability by testing on increasingly complex DNN architectures

## Open Questions the Paper Calls Out
None

## Limitations
- Scalability to extremely large DNN architectures with thousands of layers remains unverified
- Computational overhead analysis doesn't fully account for inference-time policy deployment costs
- Experiments focus on synthetic/benchmark workloads, leaving real-world hardware variability questions unanswered

## Confidence
- High confidence in 30-300× faster convergence: Clear experimental comparisons with multiple baselines
- Medium confidence in absolute latency/EDP improvements: Dependent on specific hardware assumptions
- Medium confidence in clustering algorithm effectiveness: Benefits demonstrated but limited ablation studies

## Next Checks
1. Test the framework on emerging DNN architectures (GNNs, ViTs with 100+ layers) to verify scalability limits
2. Conduct ablation studies comparing different clustering algorithms and agent assignment strategies
3. Evaluate performance under realistic hardware constraints including temperature effects, process variations, and non-ideal memory hierarchies