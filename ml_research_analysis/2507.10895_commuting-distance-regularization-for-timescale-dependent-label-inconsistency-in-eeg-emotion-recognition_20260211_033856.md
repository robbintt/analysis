---
ver: rpa2
title: Commuting Distance Regularization for Timescale-Dependent Label Inconsistency
  in EEG Emotion Recognition
arxiv_id: '2507.10895'
source_url: https://arxiv.org/abs/2507.10895
tags:
- emotion
- label
- graph
- metrics
- distance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the Timescale-Dependent Label Inconsistency
  (TsDLI) problem in EEG-based emotion recognition, where global emotion labels assigned
  after prolonged stimuli exposure are naively applied to short segments, ignoring
  inherent emotional fluctuations. To mitigate this, the authors propose two novel
  regularization strategies: Local Variation Loss (LVL) and Local-Global Consistency
  Loss (LGCL), both grounded in graph-theoretic principles involving commute-time
  distances.'
---

# Commuting Distance Regularization for Timescale-Dependent Label Inconsistency in EEG Emotion Recognition

## Quick Facts
- **arXiv ID:** 2507.10895
- **Source URL:** https://arxiv.org/abs/2507.10895
- **Reference count:** 40
- **Primary result:** Proposes LVL and LGCL losses based on commute-time distances to address timescale-dependent label inconsistency in EEG emotion recognition, showing superior balance of accuracy and temporal consistency.

## Executive Summary
This paper addresses Timescale-Dependent Label Inconsistency (TsDLI) in EEG-based emotion recognition, where global emotion labels assigned after prolonged stimuli exposure are naively applied to short segments, ignoring inherent emotional fluctuations. To mitigate this, the authors propose two novel regularization strategies: Local Variation Loss (LVL) and Local-Global Consistency Loss (LGCL), both grounded in graph-theoretic principles involving commute-time distances. These losses control fluctuations between adjacent predictions and ensure alignment with global labels. The paper introduces new evaluation metrics (Ac, δd, vd) tailored to measure temporal consistency under label inconsistency. Extensive experiments on DREAMER and DEAP datasets across LSTM and transformer architectures show that the proposed methods consistently outperform state-of-the-art baselines, with LVL achieving the best aggregate rank and LGCL ranking second, demonstrating superior balance between quantitative accuracy and qualitative consistency under label noise.

## Method Summary
The method introduces two regularization losses: Local Variation Loss (LVL) and Local-Global Consistency Loss (LGCL). Both leverage commute-time distances computed from the pseudoinverse of the graph Laplacian (L†) to measure semantic distance between emotion states on a transition graph. LVL penalizes fluctuations between adjacent predictions, while LGCL anchors predictions to their global mean. The emotion transition is modeled as a random walk on a 5-node line graph (1-2-3-4-5), with L† precomputed once per graph configuration. During training, these losses are added to standard cross-entropy loss. The framework is tested across three backbone architectures (EEGNet, LSTM, Transformer) on DREAMER and DEAP datasets with subject-dependent paradigms, using 1-second non-overlapping segmentation and synthetic label noise injection (20%, 40%).

## Key Results
- LVL achieves the best aggregate rank across quantitative and qualitative metrics; LGCL ranks second
- Both methods consistently outperform state-of-the-art baselines in balancing accuracy and temporal consistency
- Graph topology significantly impacts qualitative performance: G2 (weighted extremes) excels on qualitative metrics
- Qualitative metrics (Ac, δd, vd) degrade significantly when graph regularization is removed ("w/o G")
- Performance gap versus baselines widens as label noise increases (20%, 40%)

## Why This Works (Mechanism)

### Mechanism 1: Commute-Time Distance Regularization via Graph Laplacian
Using commute-time distances on an emotion transition graph provides a more semantically meaningful measure of emotional fluctuation than Euclidean distance on one-hot vectors, which treats all label changes equivalently. The pseudoinverse of the graph Laplacian (L†) encodes the expected time for a random walk to travel between emotion states and return. By incorporating L† into the loss kernel, adjacent predictions are penalized proportionally to their "transition difficulty" rather than raw label difference. This ensures that predictions jumping from level 1 to 5 incur higher cost than 1 to 2. Core assumption: Emotional states follow smooth trajectories governed by the Transition Difficulty Postulate (TDP)—transitions become less likely as numerical distance increases—and the Intermediate Value Assumption (IVA)—transitions must pass through intermediate levels.

### Mechanism 2: Local-Global Consistency as Variance Minimization
Regularizing local predictions to remain within bounded variance of their global expectation mitigates overfitting to potentially incorrect segment-level labels. LGCL formalizes the Full Expectation Assumption (FEA)—that global labels represent expectations over local states—and penalizes deviations. This anchors micro-fluctuations to macro-level self-assessments without requiring explicit local labels. Core assumption: Global self-reported labels reflect valid summary statistics of the emotional trajectory (Law of Total Expectation holds).

### Mechanism 3: Graph Topology Encodes Domain Priors
The choice of emotion transition graph structure directly influences the qualitative behavior of predictions, with line graphs enforcing ordinal smoothness. The line graph (1-2-3-4-5) encodes that transitions between adjacent levels are easier than jumps. Weighted variants (G1, G2) can model asymmetric difficulties—e.g., reducing weights on mid-level transitions (G2) aligns with central tendency bias, producing fewer extreme predictions. Core assumption: Emotional inertia exists—states persist and resist abrupt changes; this is neurophysiologically grounded.

## Foundational Learning

**Concept: Commute-Time (Resistance) Distance on Graphs**
- Why needed: Core mathematical object enabling semantic distance between emotion states beyond naïve Euclidean metrics
- Quick check question: Given a line graph 1-2-3-4-5, is the commute distance between nodes 1 and 3 larger or smaller than between 1 and 2? Why? (Answer: Larger, because more edges must be traversed)

**Concept: Functions of Bounded Variation**
- Why needed: Theoretical foundation for regularization—controls total "oscillation" in predictions over time
- Quick check question: If a sequence has bounded variation, what does that imply about its smoothness and number of discontinuities? (Answer: Smoothness is controlled; finite number of large jumps)

**Concept: Learning with Noisy Labels (LNL) Paradigm**
- Why needed: Contextualizes TsDLI within broader robustness literature; explains why standard LNL methods (Co-teaching, DivideMix) may be suboptimal for timescale inconsistency
- Quick check question: How does TsDLI differ from standard label noise scenarios where corrupted labels exist on a single scale? (Answer: TsDLI involves inconsistent labels across multiple timescales—global vs. local)

## Architecture Onboarding

**Component map:**
Raw EEG → Preprocessing (z-score + [-1,1] scaling) → Segmentation (1s windows) → Backbone (EEGNet/LSTM/Transformer) → Softmax predictions Ŷ(ti) → Loss = CrossEntropy + λ·LVL (or λ·LGCL) → Emotion Transition Graph G(V,E) → Laplacian L → Pseudoinverse L† (precomputed)

**Critical path:**
1. Define emotion transition graph G based on clinical/domain priors (default: line graph for ordinal scales)
2. Precompute L† once per graph configuration
3. During training: compute LVL or LGCL using L† as distance kernel
4. Monitor qualitative metrics (Ac, δd, vd) alongside accuracy

**Design tradeoffs:**
- **Graph topology:** Line graph enforces ordinality; complete graph (GA) allows any transition; weighted graphs (G1/G2) model asymmetric difficulty. G2 empirically best for qualitative metrics but not universally optimal
- **LVL vs LGCL:** LVL regularizes adjacent transitions (local smoothness); LGCL anchors to global labels (global consistency). Theoretically equivalent under certain conditions, but empirical behavior differs slightly
- **Subject-dependent vs independent:** Current experiments are SD; extending to SI requires harmonizing heterogeneous transition graphs across subjects

**Failure signatures:**
- Removing graph entirely ("w/o G"): qualitative metrics degrade significantly (Ac: 2.16→2.52, vd: 0.14→0.16, δd: 0.33→0.38 per Table 1)
- Over-regularization: F1/Top-2 accuracy may drop if λ is too large
- Under-regularization: predictions exhibit "whiplash" transitions (Figure 5 shows Regular method has 35 total transition steps vs 23-24 for LVL/LGCL)

**First 3 experiments:**
1. **Graph ablation:** Compare G0 (uniform line), G1 (emphasize middle), G2 (emphasize extremes), GA (complete), and w/o G on held-out subjects. Expect G2 to excel on qualitative metrics; w/o G to fail
2. **Noise robustness sweep:** Train at 0%, 20%, 40% symmetric label noise. Expect LVL/LGCL performance gap vs baselines to widen as noise increases
3. **Cross-backbone validation:** Test whether LVL/LGCL improvements transfer across EEGNet, LSTM, and Transformer architectures. Expect consistent ranking improvements but magnitude may vary

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can adaptive or data-driven graph learning methods outperform the hand-crafted line graph priors used in this study?
- Basis in paper: Section 5 states: "...numerical performance and clinical plausibility must be balanced jointly, and therefore adaptive or data-driven graph learning could be a target for future work."
- Why unresolved: The current work relies on a fixed, undirected line graph (1-2-3-4-5) derived from clinical assumptions (IVA/TDP), which may not capture all subject-specific dynamics
- What evidence would resolve it: Experiments demonstrating that models with learnable adjacency matrices or Bayesian graph estimation achieve superior qualitative stability or quantitative accuracy compared to the fixed G0 configuration

### Open Question 2
- Question: How does the proposed regularization framework perform in subject-independent emotion recognition scenarios?
- Basis in paper: Section 5 notes that the study isolates TsDLI within a subject-dependent paradigm, and "extending to subject-independent (SI) settings will require data harmonization across heterogeneous transition graphs."
- Why unresolved: Inter-subject variability in self-assessment scales and emotional inertia creates heterogeneous transition graphs, which the current subject-dependent setup explicitly avoids
- What evidence would resolve it: Benchmark results on standard cross-subject validation splits showing the method's robustness to label noise without requiring subject-specific training

### Open Question 3
- Question: Can the LVL and LGCL losses be integrated with latent-state modules (e.g., sequential VAEs or HMMs) to explicitly infer time-resolved emotion labels?
- Basis in paper: Section 5 lists "regularization versus local decoding" as a limitation, stating the losses "do not explicitly infer time-resolved emotion labels" required for applications like biofeedback
- Why unresolved: The current method regularizes the output probability trajectory but does not model the underlying latent emotional state as a distinct generative variable
- What evidence would resolve it: A hybrid architecture combining the proposed commute-distance losses with a generative latent variable model that successfully outputs fine-grained, time-resolved ground truth labels

## Limitations
- Graph-theoretic assumptions (smooth ordinal transitions, commute-time distances) may not hold for all emotional trajectories or experimental paradigms
- Empirical validation remains limited to subject-dependent settings and ordinal scales; extension to subject-independent scenarios and non-ordinal dimensions requires further investigation
- Theoretical connection relies on specific graph structures and may not generalize to arbitrary topologies

## Confidence

**High Confidence:** The mathematical framework (commute-time distance, bounded variation regularization) and the empirical demonstration that LVL/LGCL improve qualitative consistency metrics (Ac, δd, vd) under label noise.

**Medium Confidence:** The superiority of the line graph over complete graph or no graph assumptions; the generalizability of results to unseen subjects (SI setting) and to non-ordinal emotion dimensions.

**Low Confidence:** The robustness of the method under extremely high noise levels (>40%) and in scenarios with completely absent local labels.

## Next Checks

1. **Graph Sensitivity Analysis:** Systematically compare G0 (uniform), G1 (weighted middle), G2 (weighted extremes), and GA (complete) across varying noise levels to determine which graph structure is optimal under different TsDLI conditions.

2. **Subject-Independent Validation:** Retrain and evaluate models in a leave-one-subject-out (LOSO) paradigm to assess generalizability beyond subject-dependent settings.

3. **Non-Ordinal Extension:** Adapt the framework to handle binary emotion dimensions (e.g., valence/arousal separately) and test whether commute-distance regularization still improves temporal consistency when ordinality is absent.