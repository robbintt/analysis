---
ver: rpa2
title: No-Regret Linear Bandits under Gap-Adjusted Misspecification
arxiv_id: '2501.05361'
source_url: https://arxiv.org/abs/2501.05361
tags:
- misspecification
- linear
- function
- regret
- bandits
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies linear bandits under a new gap-adjusted misspecification
  framework where the approximation error at each point is proportional to its suboptimality
  gap. This contrasts with existing uniform misspecification approaches that result
  in linear regret.
---

# No-Regret Linear Bandits under Gap-Adjusted Misspecification

## Quick Facts
- **arXiv ID**: 2501.05361
- **Source URL**: https://arxiv.org/abs/2501.05361
- **Reference count**: 40
- **Primary result**: LinUCB achieves O(√T) regret under gap-adjusted misspecification with parameter diminishing at O(1/(d√log T)), versus O(T/√log T) under uniform misspecification

## Executive Summary
This paper introduces a novel gap-adjusted misspecification framework for linear bandits, where approximation error at each point is proportional to its suboptimality gap. Unlike uniform misspecification which leads to linear regret, this gap-adjusted setting allows algorithms like LinUCB to achieve near-optimal O(√T) regret. The authors demonstrate that the classical LinUCB algorithm is robust to this type of misspecification, requiring the gap-adjusted parameter to diminish at O(1/(d√log T)). They further develop a phased elimination algorithm that achieves O(√T) regret with a constant gap-adjusted parameter and requires only O(log T) batches of exploration.

## Method Summary
The paper studies linear bandits under a new gap-adjusted misspecification framework where approximation error at each point is proportional to its suboptimality gap. The authors show that LinUCB is robust to such misspecification when the gap-adjusted parameter diminishes at O(1/(d√log T)), achieving near-optimal O(√T) regret compared to O(T/√log T) under uniform misspecification. They further develop a phased elimination algorithm that achieves O(√T) regret with a constant gap-adjusted parameter ρ = O(1/√d) and requires only O(log T) batches of exploration. The technical innovation includes a self-bounding argument and an inductive lemma that limits misspecification error within the suboptimality gap for all valid actions in each batch.

## Key Results
- LinUCB achieves O(√T) regret under gap-adjusted misspecification with parameter diminishing at O(1/(d√log T))
- Phased elimination algorithm achieves O(√T) regret with constant gap-adjusted parameter ρ = O(1/√d)
- Requires only O(log T) batches of exploration for the phased elimination approach
- Technical innovations include self-bounding argument and inductive lemma limiting misspecification error

## Why This Works (Mechanism)
The gap-adjusted misspecification framework ensures that approximation errors are smaller for actions closer to optimal, allowing algorithms to still identify and exploit near-optimal actions despite model misspecification. The key mechanism is that the misspecification error is bounded by the suboptimality gap, preventing misleading information from actions that are already significantly suboptimal. This creates a more realistic and favorable setting compared to uniform misspecification, where all actions suffer equally from model errors regardless of their true value.

## Foundational Learning

**Linear Bandits**: Online decision-making framework where rewards are linear functions of action features - needed for understanding the basic setting being studied; quick check: can you explain the relationship between linear bandits and contextual bandits?

**Suboptimality Gap**: Difference between the expected reward of an action and the optimal action - crucial for understanding the gap-adjusted framework; quick check: can you define the suboptimality gap for a given action in a bandit problem?

**Misspecification**: When the assumed model differs from the true underlying reward function - fundamental concept being relaxed in this work; quick check: can you distinguish between uniform and gap-adjusted misspecification?

**Regret Analysis**: Framework for measuring algorithm performance relative to an optimal policy - essential for evaluating the proposed algorithms; quick check: can you write the regret definition for a bandit algorithm?

## Architecture Onboarding

**Component map**: LinUCB algorithm -> gap-adjusted misspecification analysis -> regret bound derivation; phased elimination algorithm -> exploration scheduling -> confidence interval construction -> action elimination

**Critical path**: Algorithm execution -> reward observation -> confidence interval update -> action selection decision

**Design tradeoffs**: Constant vs diminishing gap-adjusted parameter (simplicity vs tighter regret bounds), phased exploration vs continuous exploration (batch efficiency vs adaptivity)

**Failure signatures**: Linear regret under uniform misspecification, failure of standard optimism when misspecification is too large, inability to eliminate suboptimal actions

**First experiments**: 1) Verify LinUCB regret under controlled gap-adjusted misspecification, 2) Test phased elimination algorithm on synthetic linear bandit problems, 3) Compare performance against standard LinUCB under uniform misspecification

## Open Questions the Paper Calls Out

None

## Limitations

- The gap-adjusted misspecification assumption may not hold in all practical scenarios where model errors are not naturally correlated with suboptimality
- The phased elimination algorithm requires knowledge of problem parameters (dimension d, time horizon T) for optimal performance
- The theoretical guarantees assume bounded noise and known confidence parameters, which may not be available in practice

## Confidence

- **LinUCB robustness under gap-adjusted misspecification**: High
- **Phased elimination algorithm performance**: Medium
- **Technical innovations (self-bounding argument, inductive lemma)**: High

## Next Checks

1. Implement LinUCB under gap-adjusted misspecification and verify O(√T) regret empirically
2. Test phased elimination algorithm with varying exploration schedules and measure batch efficiency
3. Compare algorithm performance under different misspecification patterns (uniform vs gap-adjusted) to validate theoretical predictions