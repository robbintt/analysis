---
ver: rpa2
title: 'LLM-ERM: Sample-Efficient Program Learning via LLM-Guided Search'
arxiv_id: '2510.14331'
source_url: https://arxiv.org/abs/2510.14331
tags:
- parity
- accuracy
- learning
- train
- input
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces LLM-ERM, a sample-efficient program learning
  framework that leverages large language models to guide the search for short programs.
  Classical enumeration is computationally intractable, while gradient-based methods
  require exponentially many samples for certain short-program families.
---

# LLM-ERM: Sample-Efficient Program Learning via LLM-Guided Search
## Quick Facts
- arXiv ID: 2510.14331
- Source URL: https://arxiv.org/abs/2510.14331
- Reference count: 40
- The paper introduces LLM-ERM, a sample-efficient program learning framework that leverages large language models to guide the search for short programs.

## Executive Summary
LLM-ERM addresses the fundamental challenge of learning short programs efficiently by combining LLM-guided candidate generation with empirical risk minimization. Classical enumeration is computationally intractable, while gradient-based methods require exponentially many samples for certain short-program families. LLM-ERM bridges this gap by using LLMs to propose candidate programs and selecting the best via empirical risk minimization, achieving statistical efficiency while maintaining computational tractability.

The framework demonstrates significant advantages over traditional gradient-based training, particularly for problems with high statistical query (SQ) dimension. Empirical results show that LLM-ERM can learn parity variants, pattern matching, and primality testing with as few as 200 samples, generalizing far better than SGD-trained transformers that overfit even with 100,000 samples. The approach produces interpretable, executable code with verifiable reasoning traces, enabling cross-dimension generalization and mechanistic interpretability.

## Method Summary
LLM-ERM combines large language model guidance with empirical risk minimization to learn short programs efficiently. The method generates candidate programs using an LLM, then selects the best-performing program via empirical risk minimization on a small dataset. This approach avoids the exponential sample complexity of gradient-based methods for high SQ-dimension families while remaining computationally tractable compared to classical enumeration. The framework leverages the LLM's reasoning capabilities to propose programs that are both correct and interpretable, with verifiable execution traces.

## Key Results
- Learns parity variants, pattern matching, and primality testing with as few as 200 samples
- Outperforms SGD-trained transformers, which overfit even with 100,000 samples
- Produces interpretable, executable code with verifiable reasoning traces
- Enables cross-dimension generalization and mechanistic interpretability

## Why This Works (Mechanism)
The mechanism leverages LLMs' ability to generate structured, syntactically correct program candidates that align with human-like reasoning patterns. By using LLMs to propose programs rather than enumerating all possibilities or relying on gradient descent, the approach taps into the model's implicit knowledge of programming patterns and logical structures. The empirical risk minimization step then filters these candidates based on actual performance, combining the LLM's generative power with statistical validation. This two-stage process avoids the computational intractability of exhaustive search while sidestepping the statistical inefficiency of gradient-based methods for problems with high SQ-dimension.

## Foundational Learning
- **Statistical Query (SQ) Dimension**: Measures the complexity of hypothesis classes; high SQ-dimension problems require exponentially many samples for gradient-based learning. Why needed: Explains why traditional methods fail for certain program families. Quick check: Verify that parity functions have high SQ-dimension.
- **Empirical Risk Minimization (ERM)**: Selects hypotheses based on performance on training data. Why needed: Provides the statistical validation step after LLM generation. Quick check: Confirm ERM maintains generalization bounds.
- **Program Enumeration vs. Guided Search**: Exhaustive search is computationally intractable; LLM-guided search is tractable. Why needed: Establishes the computational motivation for the approach. Quick check: Compare time complexity of enumeration vs. LLM-guided search.
- **Generalization Bounds**: Theoretical guarantees on performance on unseen data. Why needed: Validates that the approach doesn't just memorize training examples. Quick check: Measure test error vs. training error.
- **Interpretability in Program Synthesis**: Executable code with verifiable reasoning traces. Why needed: Enables debugging and understanding of learned programs. Quick check: Examine generated code for clarity and executability.

## Architecture Onboarding
**Component Map**: LLM Generator -> Candidate Pool -> ERM Selector -> Executable Program
**Critical Path**: LLM generates candidates → ERM evaluates on training data → Best program selected → Verification on test data
**Design Tradeoffs**: LLM-guided search trades computational cost of LLM calls for statistical efficiency, avoiding both enumeration intractability and gradient-based sample inefficiency
**Failure Signatures**: Overfitting occurs when ERM selects programs that memorize training data; poor LLM generation produces syntactically invalid or logically incorrect candidates
**First Experiments**: 1) Test on simple parity functions with varying input dimensions, 2) Evaluate pattern matching on synthetic string datasets, 3) Apply to primality testing with different number ranges

## Open Questions the Paper Calls Out
None

## Limitations
- Performance may not generalize beyond the small set of benchmark problems tested
- Computational cost of LLM calls is not fully characterized, raising scalability concerns
- Reliance on LLMs with sufficient reasoning capability may make performance brittle to model choice

## Confidence
- High: The theoretical claim that LLM-ERM avoids exponential sample complexity relative to SGD for high SQ-dimension problems is well-supported
- Medium: The empirical claims about sample efficiency across the three benchmark problems are reasonably well-supported but limited in generalizability
- Low: The broader claim that this offers a practical route to learning succinct hypotheses beyond gradient-based training extrapolates beyond current evidence

## Next Checks
1. **Cross-Family Generalization Test**: Evaluate LLM-ERM on at least 10-15 diverse program families beyond the current three, including programs with different control structures, data dependencies, and complexity characteristics
2. **Computational Cost Scaling Analysis**: Measure and characterize the relationship between program length/complexity and LLM call costs, including both API costs and wall-clock time
3. **Model Sensitivity Validation**: Test whether the observed sample efficiency persists across different LLM models (varying sizes, architectures, and reasoning capabilities) to determine if the approach is brittle to model choice