---
ver: rpa2
title: 'ProxRouter: Proximity-Weighted LLM Query Routing for Improved Robustness to
  Outliers'
arxiv_id: '2510.09852'
source_url: https://arxiv.org/abs/2510.09852
tags:
- query
- queries
- routing
- cost
- router
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper tackles the challenge of routing language queries to\
  \ the most suitable LLM in a diverse model pool, with the goal of maximizing accuracy\
  \ while minimizing cost. Traditional nonparametric routers like KMeans and kNN struggle\
  \ with generalization to outlier queries\u2014those that differ significantly from\
  \ training data\u2014due to rigid assignment rules and uniform weighting."
---

# ProxRouter: Proximity-Weighted LLM Query Routing for Improved Robustness to Outliers

## Quick Facts
- arXiv ID: 2510.09852
- Source URL: https://arxiv.org/abs/2510.09852
- Reference count: 40
- One-line primary result: ProxRouter improves LLM routing robustness to outlier queries, boosting AUC by up to 8.1 percentage points over baselines without explicit outlier detection.

## Executive Summary
This paper addresses the challenge of routing language queries to the most suitable LLM in a diverse model pool, aiming to maximize accuracy while minimizing cost. Traditional nonparametric routers like KMeans and kNN struggle with generalization to outlier queries—those that differ significantly from training data—due to rigid assignment rules and uniform weighting. The authors propose ProxRouter, which generalizes these routers by introducing proximity-weighted aggregation. For each query, it computes minimum-variance priors over reference clusters or neighbors, then applies an exponential tilt based on proximity to reduce bias. This approach improves accuracy estimates for outlier queries while preserving performance on inliers, without requiring explicit outlier detection.

## Method Summary
ProxRouter is a nonparametric LLM query router that builds upon KMeans and kNN by introducing proximity-weighted aggregation. It computes minimum-variance priors (cluster size/intra-cluster spread for KMeans, uniform for kNN), then applies an exponential tilt based on cosine distance to the query. This produces weighted estimates of model accuracy minus cost, which are used to select the best model. The method balances bias (proximity emphasis) and variance (prior weighting) via a temperature parameter τ, improving robustness to outlier queries without explicit outlier detection.

## Key Results
- KM-Prox increases AUC by up to 4.4 percentage points over KM-Base on outlier tasks.
- kNN-Prox improves AUC by 8.1 percentage points over kNN-Base on math outlier tasks.
- Performance approaches that of an all-knowledge "AllSee" router, while adding only millisecond-level overhead.

## Why This Works (Mechanism)

### Mechanism 1: Variance-Weighted Priors Reduce Noisy Estimates
Weighting reference elements (clusters/neighbors) inversely to their variance produces more stable accuracy/cost estimates for model selection. The router initializes aggregation weights as minimum-variance priors $p_i(x) \propto 1/\text{Var}[V_i^{(m)}]$. For KMeans, this uses $n_i/s_i$ (cluster size over intra-cluster spread), assuming dispersed clusters contain noisier objective signals. For kNN, uniform $1/k$ priors are used as per-query variance is difficult to estimate. This assumes heteroscedastic noise in model objective values across reference elements; geometric spread in the encoding space correlates with semantic diversity and thus higher variance in LLM performance.

### Mechanism 2: Proximity-Based Exponential Tilting Reduces Bias for Outliers
Reweighting low-variance priors by proximity to the test query improves accuracy estimates for outlier queries without explicit outlier detection. Final weights are $w_i(x) \propto p_i(x) \exp(-\phi_i(x)/\tau)$, where $\phi_i(x)$ is a proximity penalty (e.g., cosine distance). This reduces bias by prioritizing semantically similar reference elements, which is critical for outliers that would otherwise be assigned to distant, irrelevant clusters/neighbors. This assumes the "true" objective value for a query is locally smooth under the dissimilarity measure; closer reference elements provide less biased estimates.

### Mechanism 3: Soft Aggregation Over All Reference Elements Avoids Hard Assignment Failures
Using a weighted combination of all clusters/neighbors, rather than a hard assignment to the nearest, provides a more robust estimate for queries that fall between or far from training clusters. The router computes $\hat{U}^{(m)}(x) = \sum_{i \in [|I|]} w_i(x) V_i^{(m)}$ over the full reference set. This avoids the abrupt changes in estimates caused by hard cluster boundaries (in KMeans) and equal weighting of distant neighbors (in kNN). This assumes model performance generalizes smoothly across the encoding space, allowing interpolation between reference points.

## Foundational Learning

- **Concept: Bias-Variance Trade-off in Estimation**
  - Why needed here: ProxRouter explicitly frames the routing problem as an estimation task where you trade off bias (proximity-based weighting) against variance (minimum-variance priors) using the $\tau$ parameter.
  - Quick check question: If you increase $\tau$, does ProxRouter behave more like a minimum-variance estimator or a closest-cluster/neighbor selector? (Answer: Minimum-variance estimator / uniform kNN).

- **Concept: k-Nearest Neighbors (kNN) and K-Means Clustering**
  - Why needed here: These are the canonical nonparametric routers ProxRouter builds upon. Understanding their hard assignment or uniform weighting limitations is necessary to see why proximity-weighting helps.
  - Quick check question: In a standard kNN router with k=5, if all 5 neighbors are distant from an outlier query, what weight does each receive? (Answer: Equal weight $1/5$, potentially skewing the estimate).

- **Concept: Sentence Embeddings and Cosine Similarity**
  - Why needed here: The entire method operates on fixed-dimensional query encodings and uses cosine distance as the proximity measure. Without this, the notion of "nearness" between queries is undefined.
  - Quick check question: Two queries about different topics but phrased similarly might have high cosine similarity. How could this affect ProxRouter's routing decision? (Answer: It might incorrectly assign them to the same reference cluster/neighbor, assuming similar model performance).

## Architecture Onboarding

- **Component map**:
  Query Text -> Encode -> Calculate Distances to All Reference Elements -> Compute Tilted Weights -> Aggregate Model Objective Values -> Select Highest-Utility Model.

- **Critical path**:
  The critical latency bottleneck is the distance calculation and weighting over $|I|$ reference elements.

- **Design tradeoffs**:
  1. **$\tau$ Selection**: Low $\tau$ emphasizes proximity (low bias, high variance), high $\tau$ emphasizes priors (high bias, low variance). Must be tuned on held-out data.
  2. **Reference Set Size ($K$ or $k$)**: Larger $K$ (clusters) or $k$ (neighbors) increases computational cost but provides more granular estimates.
  3. **Encoder Choice**: The paper notes performance is relatively unaffected by encoder choice (MiniLM, MPNet, etc.), but domain-specific encoders might improve semantic clustering.

- **Failure signatures**:
  1. **Sudden Drop in Routing Accuracy**: Likely a change in query distribution (new outlier types) not covered by training data. Monitor the top-z Jaccard overlap metric ($J_z^\lambda$) proposed in the paper.
  2. **All Weights Near-Uniform**: Indicates all reference elements are roughly equidistant (e.g., sparse training data, encoder failure). Check encoder norms and reference set coverage.
  3. **High Latency on kNN-Prox**: For large training sets, computing distances to all neighbors is expensive. Use approximate nearest neighbor search (FAISS) as mentioned in Appendix C.

- **First 3 experiments**:
  1. **Ablation on $\tau$**: Run ProxRouter (KM-Prox and kNN-Prox) with varying $1/\tau$ (e.g., 5, 10, 20, 40) on a validation set containing both inliers and outliers. Plot normalized AUC vs. $1/\tau$ to find the optimal trade-off (replicating Figure 4).
  2. **Leave-Task-Out Generalization**: Train the router on 8 of the 10 datasets, hold out 2 as outliers. Compare KM-Base vs. KM-Prox vs. KM-AllSee on the held-out tasks to measure robustness improvement (replicating Table 2).
  3. **Sensitivity to Encoder**: Swap the MPNet-base encoder for MiniLM or DistilRoBERTa and re-evaluate routing performance to verify the claim of encoder-agnostic performance (replicating Table 4).

## Open Questions the Paper Calls Out
1. **Can the ProxRouter framework be effectively adapted to advanced nonparametric methods such as fuzzy clustering, spectral clustering, or kernel smoothing?** The conclusion states, "Future work may consider extending this approach to more advanced statistical methods." The current work deliberately focuses only on KMeans and kNN routers due to their simplicity and interpretability. Comparative results showing the performance of "Spectral-Prox" or "Kernel-Prox" against standard ProxRouter on the same outlier benchmarks would resolve this.

2. **How can the top-z Jaccard similarity metric ($J_z^\lambda$) be operationalized into a cost-aware policy to dynamically trigger router retraining?** Section 4.2 proposes that retraining "can be triggered when $J_z^\lambda$ falls below a validation chosen threshold... The choice of threshold can be determined by a cost-aware policy." The paper identifies the metric and the need for a policy but does not define the specific thresholding algorithm or the cost function balancing inference quality against retraining expense. A defined algorithm that sets thresholds based on model evaluation costs and a demonstration of its ability to maintain routing accuracy with minimal retraining frequency would resolve this.

3. **Can precise, query-specific noise variance estimation replace the current heuristic priors (spread and uniform weights) to further improve routing accuracy?** Section 3.1 notes, "Since the exact per-query variance is unknown in practice, we estimate... based on heuristics." The method currently approximates the noise variance $\text{Var}[\epsilon^{(m)}(x_{tr})]$ using intra-cluster spread or uniform assumptions rather than measuring the actual stochastic noise of the LLM generation process. An ablation study comparing the current heuristic priors against priors derived from direct estimation of LLM generation variance would resolve this.

## Limitations
- The critical mechanism—variance-weighted priors combined with proximity tilting—is shown to work empirically but lacks theoretical grounding for why minimum-variance priors should correlate with better routing decisions.
- The performance claims are relative to baselines (KM-Base, kNN-Base) but not compared to other nonparametric routers beyond the two canonical ones.
- The router's sensitivity to $\tau$ and its generalization across diverse LLM pools are demonstrated, but the cost of tuning $\tau$ per application is not discussed.

## Confidence
- **High confidence**: The empirical improvements in AUC on outlier tasks are reproducible as reported; the method is implementable as described. The soft aggregation mechanism over reference elements is a sound extension over hard assignment.
- **Medium confidence**: The variance-weighted priors provide a reasonable heuristic for balancing bias-variance, but the underlying assumption (spread correlates with noise) is plausible but not proven. The choice of MPNet-base encoder appears robust across experiments, but domain-specific encoders could change results.
- **Low confidence**: The theoretical justification for why proximity-based tilting improves estimates for outliers is weak; it is assumed but not demonstrated that closer reference elements yield less biased estimates. The claim that the method works "without explicit outlier detection" is true operationally but masks the fact that tuning $\tau$ on inlier data is a form of implicit outlier modeling.

## Next Checks
1. **Variance-Prior Validation**: On a held-out set, compute the correlation between cluster variance (or neighbor spread) and the variance of per-model accuracy estimates. If no correlation exists, the minimum-variance prior assumption is unsupported.
2. **Encoder Sensitivity on Outlier Tasks**: Retrain ProxRouter using different encoders (e.g., MiniLM, DistilRoBERTa) and evaluate AUC degradation on outlier tasks. If performance drops significantly, the MPNet-base assumption of encoder-agnosticism is invalid.
3. **Outlier Detection Ablation**: Compare ProxRouter to a two-stage pipeline: (a) explicit outlier detection (e.g., distance to nearest cluster), (b) KM-Base routing for inliers, (c) KM-AllSee for outliers. If this hybrid approach outperforms ProxRouter, the "no explicit outlier detection" claim is misleading.