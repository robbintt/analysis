---
ver: rpa2
title: Multi-Agent Framework for Threat Mitigation and Resilience in AI-Based Systems
arxiv_id: '2512.23132'
source_url: https://arxiv.org/abs/2512.23132
tags:
- attack
- data
- vulnerabilities
- attacks
- adversarial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the growing security risks in machine learning
  (ML) systems, which are increasingly targeted by adversarial attacks like data poisoning,
  model extraction, and jailbreaking. The authors propose a multi-agent framework
  that integrates retrieval-augmented generation (RAG) with graph neural networks
  (GNNs) to map threat tactics, techniques, and procedures (TTPs) to ML lifecycle
  stages and vulnerabilities.
---

# Multi-Agent Framework for Threat Mitigation and Resilience in AI-Based Systems

## Quick Facts
- arXiv ID: 2512.23132
- Source URL: https://arxiv.org/abs/2512.23132
- Reference count: 40
- Authors: Armstrong Foundjem; Lionel Nganyewou Tidjon; Leuson Da Silva; Foutse Khomh
- Primary result: Multi-agent framework mapping 93 ML threats to lifecycle stages, achieving 63% Spearman correlation in severity prediction

## Executive Summary
This paper addresses the growing security risks in machine learning systems by proposing a multi-agent framework that integrates retrieval-augmented generation with graph neural networks. The framework maps threat tactics, techniques, and procedures to ML lifecycle stages and vulnerabilities, analyzing 93 threats from MITRE ATLAS and the AI Incident Database. The GNN model achieves a 63% Spearman correlation with real-world severity scores and demonstrates 24% improvement in operational responsiveness, providing actionable mitigation strategies for securing ML systems against evolving adversarial threats.

## Method Summary
The authors construct a heterogeneous threat graph by mining data from MITRE ATLAS (26 cases), AI Incident Database (12 cases), and 854 GitHub/PyPI repositories. They employ a multi-agent framework using OpenAI Swarm with GPT-4o and RAG (Sentence Transformers + Reranker) for extraction and classification. Zero-shot BART-MNLI classifies threats, with GPT-4o Chain-of-Thought verification for low-confidence cases. A heterogeneous GNN (R-GCN/GraphSAGE) predicts composite severity risk scores using MSE loss, achieving 63% Spearman correlation against CVSS ground truth.

## Key Results
- GNN model achieves 63% Spearman correlation with CVSS severity scores
- Improves operational responsiveness by 24% in controlled studies
- Identifies previously undocumented risks including model-stealing attacks against LLM APIs and supply chain vulnerabilities in ML libraries
- Macro-F1 of 0.87 for threat classification accuracy

## Why This Works (Mechanism)
The framework leverages multi-agent collaboration to systematically extract and classify threats across multiple data sources, creating a comprehensive threat landscape. By using heterogeneous graph neural networks, the system captures complex relationships between CVEs, CPEs, techniques, and clusters, enabling sophisticated severity prediction that accounts for multiple attack dimensions simultaneously.

## Foundational Learning
- **Heterogeneous Graph Neural Networks**: Multi-relational graphs with different node/edge types needed to model complex threat relationships; check by verifying schema in Table VII
- **Multi-Agent Frameworks**: Coordinated autonomous agents for distributed threat analysis; check by examining agent roles in OpenAI Swarm
- **Retrieval-Augmented Generation**: Combines document retrieval with language models for accurate information extraction; check by validating RAG pipeline components
- **Composite Risk Scoring**: Weighted combination of base, exploitability, and impact metrics; check by reproducing the 0.5/0.3/0.2 formula
- **Threat Intelligence Mining**: Systematic extraction from security databases and repositories; check by validating the 93 threats mapping
- **Severity Prediction Metrics**: Spearman correlation for ordinal ranking evaluation; check by comparing against CVSS ground truth

## Architecture Onboarding

**Component Map**: Data Mining -> Graph Construction -> Feature Extraction -> GNN Training -> Severity Prediction

**Critical Path**: Extraction (GPT-4o + RAG) → Classification (BART-MNLI + CoT) → GNN Prediction → Risk Scoring

**Design Tradeoffs**: Static mapping vs. dynamic adaptation (RL proposed for future work); comprehensive threat coverage vs. computational complexity of heterogeneous GNN

**Failure Signatures**: Sparse graph connectivity leading to poor GNN convergence; API non-determinism causing extraction variance; classification errors in zero-shot models

**3 First Experiments**:
1. Reconstruct the heterogeneous graph from MITRE ATLAS and AI Incident Database to verify node/edge schema
2. Implement and train the GraphSAGE model on the composite risk score prediction task
3. Test the GPT-4o + RAG extraction pipeline on a subset of GitHub repositories for threat identification

## Open Questions the Paper Calls Out
- **Reinforcement Learning for Dynamic Security**: The authors propose developing RL-based self-improving security mechanisms to dynamically optimize ML defenses, but this remains unimplemented future work requiring empirical demonstration of real-time adaptation to novel attack vectors
- **Incident-Based Validation**: The paper suggests comparing GNN predictions against AI Incident Database post-mortem labels rather than just CVSS scores, which would provide more nuanced operational impact assessment
- **Production Red-Team Testing**: The framework needs validation through large-scale red-team campaigns against production-grade MLOps stacks to reveal failure modes that synthetic benchmarks cannot capture

## Limitations
- Static threat mapping approach lacking dynamic adaptation capabilities
- Validation primarily against CVSS scores rather than real-world incident outcomes
- No empirical testing on production systems or under genuine operational constraints
- Reliance on historical data that may not capture emerging threat patterns

## Confidence
- **Methodological Soundness**: High - Comprehensive multi-source data collection and rigorous GNN implementation
- **Reproducibility**: Medium - Clear methodology but specific hyperparameters and prompt templates unspecified
- **Real-World Applicability**: Medium - Strong theoretical framework but limited empirical validation on live systems
- **Innovation**: High - Novel integration of multi-agent systems with heterogeneous GNNs for ML security

## Next Checks
1. Replicate the heterogeneous graph construction using MITRE ATLAS and AI Incident Database to verify node/edge relationships
2. Implement the GNN model and train on the composite risk score prediction task to achieve similar Spearman correlation
3. Conduct a small-scale red-team exercise on a containerized ML service to test framework effectiveness against simulated attacks