---
ver: rpa2
title: 'Beyond Mapping : Domain-Invariant Representations via Spectral Embedding of
  Optimal Transport Plans'
arxiv_id: '2601.13350'
source_url: https://arxiv.org/abs/2601.13350
tags:
- transport
- domain
- optimal
- spectral
- target
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of domain adaptation in machine
  learning, specifically the challenge of distributional shifts between training and
  inference data that lead to poor model performance. The proposed method, Spectral
  Embedding of Optimal Transport Plans (SeOT), leverages smoothed optimal transport
  plans as adjacency matrices of bipartite graphs connecting source and target domains,
  and derives domain-invariant representations through spectral embedding.
---

# Beyond Mapping : Domain-Invariant Representations via Spectral Embedding of Optimal Transport Plans

## Quick Facts
- **arXiv ID**: 2601.13350
- **Source URL**: https://arxiv.org/abs/2601.13350
- **Reference count**: 0
- **Primary result**: SeOT improves source-only baselines by up to 29% and outperforms state-of-the-art methods in acoustic adaptation and defect detection tasks

## Executive Summary
This paper introduces Spectral Embedding of Optimal Transport Plans (SeOT), a novel approach to domain adaptation that addresses distributional shifts between training and inference data. The method leverages smoothed optimal transport plans as adjacency matrices connecting source and target domains, deriving domain-invariant representations through spectral embedding. Unlike approaches that directly approximate Monge maps, SeOT avoids biases and hyperparameter sensitivity while achieving strong empirical performance. The method is evaluated on acoustic adaptation benchmarks and a cable defect detection task, showing improvements over source-only baselines and competitive performance against state-of-the-art methods.

## Method Summary
SeOT addresses domain adaptation by constructing smoothed optimal transport plans between source and target domains, treating these plans as adjacency matrices of bipartite graphs. Rather than directly approximating Monge maps, which can introduce biases and be sensitive to hyperparameters, the method performs spectral embedding on these transport plans to derive domain-invariant representations. This approach leverages the mathematical properties of optimal transport while avoiding the computational and stability issues associated with direct map approximation. The resulting representations are designed to be robust to domain shifts while preserving discriminative information necessary for the downstream task.

## Key Results
- SeOT improves over source-only baselines by up to 29% on acoustic adaptation benchmarks
- Achieves higher accuracy than target-only training in some scenarios, indicating effective domain alignment
- Outperforms state-of-the-art domain adaptation methods in most tested cases across music genre recognition, music-speech discrimination, and cable defect detection tasks

## Why This Works (Mechanism)
The method works by leveraging the mathematical properties of optimal transport plans as a principled way to connect source and target domains. By smoothing the transport plans and using them as adjacency matrices, SeOT creates a structured representation that captures domain relationships while avoiding the instability of direct map approximation. The spectral embedding then extracts the essential structure from these connections, producing representations that are both domain-invariant and task-relevant. This approach effectively bridges the distributional gap without requiring explicit label alignment or complex adversarial training.

## Foundational Learning

**Optimal Transport Theory**: Mathematical framework for comparing probability distributions; needed to understand the theoretical foundation of domain adaptation via transport plans; quick check: can derive Wasserstein distance between two simple distributions

**Spectral Graph Theory**: Study of graph properties through eigenvalues and eigenvectors of matrices like adjacency matrices; needed to understand how domain relationships are embedded in the spectral domain; quick check: can explain relationship between graph Laplacian and graph connectivity

**Domain Adaptation**: Machine learning paradigm for handling distributional shifts between training and test data; needed to contextualize the problem SeOT solves; quick check: can define covariate shift and label shift

**Bipartite Graphs**: Graphs whose vertices can be divided into two disjoint sets with edges only between sets; needed to understand the source-target domain relationship; quick check: can construct adjacency matrix for simple bipartite graph

**Smoothing Techniques**: Methods for regularizing or stabilizing numerical computations; needed to understand how transport plans are made more robust; quick check: can explain effect of regularization on inverse problems

## Architecture Onboarding

**Component Map**: Data -> Optimal Transport Plan -> Smoothed Adjacency Matrix -> Spectral Decomposition -> Domain-Invariant Representations -> Downstream Task

**Critical Path**: The essential computation path is Optimal Transport Plan calculation followed by spectral embedding. The smoothing step is critical for numerical stability, and the quality of the transport plan directly affects representation quality.

**Design Tradeoffs**: Smoothing parameter versus representation fidelity; computational cost of optimal transport versus approximation quality; dimensionality of spectral embedding versus computational efficiency.

**Failure Signatures**: Poor transport plan quality leads to noisy representations; insufficient smoothing causes numerical instability; overly aggressive smoothing loses discriminative information; high-dimensional data may require dimensionality reduction before spectral embedding.

**First Experiments**: 1) Verify transport plan quality on simple synthetic domain shift; 2) Test spectral embedding sensitivity to smoothing parameter; 3) Benchmark against source-only baseline on simple domain adaptation task

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical implications of spectral decomposition approach in high-dimensional settings remain unclear
- Limited evaluation scope focused on acoustic adaptation and defect detection tasks
- Smoothing parameter impact on representation quality across different domain shifts not thoroughly explored

## Confidence
- Mathematical formulation: High
- Experimental results: Medium to High
- Broader applicability claims: Medium

## Next Checks
1. Test SeOT on standard domain adaptation benchmarks (Office-31, VisDA) to evaluate performance across diverse domain shifts
2. Conduct sensitivity analysis on the smoothing parameter and its effect on representation quality across different domain pairs
3. Compare computational efficiency against other optimal transport-based domain adaptation methods for large-scale applications