---
ver: rpa2
title: 'Prompts to Proxies: Emulating Human Preferences via a Compact LLM Ensemble'
arxiv_id: '2509.11311'
source_url: https://arxiv.org/abs/2509.11311
tags:
- preference
- agents
- test
- survey
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Prompts to Proxies (P2P), a two-stage system
  for aligning large language models with population-level preferences from survey
  data. Stage 1 uses entropy-based adaptive sampling to construct a diverse agent
  pool spanning the latent preference space, while Stage 2 employs L1-regularized
  regression to select a compact ensemble whose aggregate responses match target populations.
---

# Prompts to Proxies: Emulating Human Preferences via a Compact LLM Ensemble

## Quick Facts
- arXiv ID: 2509.11311
- Source URL: https://arxiv.org/abs/2509.11311
- Authors: Bingchen Wang; Zi-Yu Khoo; Jingtan Wang
- Reference count: 40
- Primary result: 43% MSE reduction over baselines on survey preference alignment using 300 synthetic agents

## Executive Summary
This paper introduces Prompts to Proxies (P2P), a two-stage system for aligning large language models with population-level preferences from survey data. Stage 1 uses entropy-based adaptive sampling to construct a diverse agent pool spanning the latent preference space, while Stage 2 employs L1-regularized regression to select a compact ensemble whose aggregate responses match target populations. P2P achieves an average test MSE of 0.014 across 14 American Trends Panel waves at approximately $0.8 per survey, representing a 43% improvement over prompting baselines. The system requires no fine-tuning or demographic data, relying only on API inference costs.

## Method Summary
P2P is a two-stage pipeline that aligns LLMs to population-level survey preferences without fine-tuning. Stage 1 uses entropy-based adaptive sampling to generate a diverse agent pool from an attribute bank, while Stage 2 employs L1-regularized regression to select a compact ensemble that reconstructs population responses. The system binarizes questions, splits data 7:1.5:1.5 into train/valid/test, and evaluates using test MSE against ground-truth survey aggregates.

## Key Results
- Achieves 43% improvement in test MSE (0.014 vs baseline) across 14 ATP waves
- Selects compact ensembles averaging 58 agents from candidate pools of 300
- Generalizes to World Values Survey populations (US/GB) with comparable accuracy
- Costs approximately $0.8 per survey using Gemini-2.0-flash API

## Why This Works (Mechanism)

### Mechanism 1: Preference Space Coverage via Entropy-Based Sampling
P2P uses entropy-based adaptive sampling to construct a diverse agent pool spanning the latent preference space. A Tracker monitors question entropy across modes, allocating more generation budget to high-diversity responses while patching low-entropy questions with specific attributes. This prevents model collapse to central tendency.

### Mechanism 2: Preference Reconstruction via Sparse Aggregation
Population-level preferences are reconstructed by weighting a subset of proxy agents rather than finding a single representative. L1-regularized regression selects a compact ensemble from the candidate pool, assigning weights to minimize error against ground-truth survey data.

### Mechanism 3: Functional Basis vs. Demographic Matching
P2P inverts traditional approaches by using attributes to shape preferences rather than inferring attributes from preferences. It prioritizes functional response patterns over exact demographic fidelity, treating attributes as control handles for steering model behavior.

## Foundational Learning

**Concept: Convex Hull & Representation Learning**
- Why needed: The paper's theoretical validity relies on the geometry of convex hulls - P2P tries to enclose human preference vectors inside a shape defined by model vectors.
- Quick check: If model responses form a triangle in 2D space, can a human preference point outside that triangle be "learned"? (Answer: No)

**Concept: L1 Regularization (Lasso)**
- Why needed: Stage 2 depends on Lasso to force a sparse solution by driving non-essential agent weights to exactly zero.
- Quick check: Why use Lasso instead of Ridge (L2) here? (Answer: To select a compact subset of agents rather than keeping all with small weights)

**Concept: Entropy (Shannon Entropy)**
- Why needed: The Tracker uses normalized entropy to measure diversity - low entropy means consensus, high entropy means division/coverage.
- Quick check: If 100 agents answer "Yes" and 0 answer "No", what is the entropy? (Answer: 0)

## Architecture Onboarding

**Component map:** Attribute Bank (Core/Thematic/Theoretical templates) -> Endowment Model (attributes to personas) -> Survey Conductor (persona + question -> answer) -> Tracker (entropy monitoring) -> Active Endowment Generator (sampling) -> Aggregator (Constrained Lasso weights)

**Critical path:** 1) Initialize with 10 endowments per mode from Attribute Bank 2) Loop: elicit responses -> Tracker calculates entropy -> sample new endowments from high-variability modes -> patch low-entropy questions -> repeat until 300 agents 3) Run Constrained Lasso on train/valid questions 4) Evaluate on test questions

**Design tradeoffs:** Accuracy vs. Cost (more agents improve performance but increase API costs linearly); Generalization vs. Overfitting (aggressive question patching risks overfitting specific phrasing)

**Failure signatures:** Mode Collapse (entropy remains low across steps), Learnability Failure (test MSE >0.05 with uniform weights), Locale Drift (high error in culturally divergent populations), Model Capacity too low (smaller models yield higher MSE)

**First 3 experiments:** 1) Reproduce W42 (Science Trust) with small budget (100 agents) to verify entropy rise 2) Ablate Tracker (disable adaptive sampling) and compare test MSE 3) Stress test backend on GPT-4o-mini vs Gemini-2.0-flash to observe steerability impact

## Open Questions the Paper Calls Out
None

## Limitations
- The convex-hull coverage assumption is foundational but untested for high-dimensional preference spaces
- Cross-cultural generalization breaks down for culturally divergent populations (60% higher MSE in HK)
- Entropy-based sampling mechanism lacks rigorous validation - no ablation proves advantage over random sampling

## Confidence

**High Confidence:**
- P2P achieves statistically significant MSE reduction (43%) over baselines
- L1-regularized regression successfully selects compact ensembles (~58 agents)
- Functional basis approach outperforms demographic matching in ablation studies

**Medium Confidence:**
- Cross-locale generalization to WVS Wave 7 populations (US/GB)
- Cost-efficiency claims ($0.8/survey) relative to fine-tuning

**Low Confidence:**
- Entropy-based adaptive sampling provides meaningful advantage over random sampling
- Convex hull assumption holds across all tested preference spaces
- Attribute bank's hierarchical structure is optimal for coverage

## Next Checks

1. **Ablation of Adaptive Sampling:** Run P2P with entropy-based adaptive sampling disabled (random mode selection) and compare final test MSE and entropy coverage ratios.

2. **Convex Hull Stress Test:** Systematically vary agent budget (50, 100, 300, 500) and measure test MSE saturation points to identify when the proxy basis cannot span the preference space.

3. **Locale-Specific Attribute Expansion:** For HK population (highest error), augment the attribute bank with culturally specific templates and re-run Stage 1 to measure improvement in cross-cultural generalization.