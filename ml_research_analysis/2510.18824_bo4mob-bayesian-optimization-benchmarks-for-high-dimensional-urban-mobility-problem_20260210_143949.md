---
ver: rpa2
title: 'BO4Mob: Bayesian Optimization Benchmarks for High-Dimensional Urban Mobility
  Problem'
arxiv_id: '2510.18824'
source_url: https://arxiv.org/abs/2510.18824
tags:
- optimization
- traffic
- data
- network
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces BO4Mob, a benchmark framework for high-dimensional
  Bayesian Optimization (BO) applied to urban mobility problems, specifically origin-destination
  (OD) travel demand estimation in large-scale road networks. The framework includes
  five real-world San Jose, CA road network scenarios with input dimensions up to
  10,100, using high-resolution traffic simulations from the SUMO simulator.
---

# BO4Mob: Bayesian Optimization Benchmarks for High-Dimensional Urban Mobility Problem

## Quick Facts
- arXiv ID: 2510.18824
- Source URL: https://arxiv.org/abs/2510.18824
- Reference count: 40
- High-dimensional BO outperforms baselines in urban mobility OD estimation

## Executive Summary
BO4Mob introduces a benchmark framework for Bayesian Optimization applied to high-dimensional urban mobility problems, specifically origin-destination (OD) travel demand estimation in large-scale road networks. The framework includes five real-world San Jose, CA road network scenarios with input dimensions up to 10,100, using high-resolution traffic simulations from the SUMO simulator. The benchmark evaluates five optimization methods: three state-of-the-art BO algorithms (Vanilla BO, SAASBO, TuRBO) and two non-BO baselines (SPSA, random search). Results show that BO methods significantly outperform non-BO baselines in sample efficiency, with TuRBO achieving the best performance across most networks. However, performance degrades as dimensionality increases, highlighting the need for scalable optimization approaches.

## Method Summary
The benchmark uses SUMO mesoscopic traffic simulator to evaluate OD demand vectors, minimizing NRMSE between simulated and ground-truth sensor counts across five San Jose freeway subnetworks (3-10,100 dimensions). Five optimization methods are compared: Vanilla BO, SAASBO, TuRBO (all using Gaussian Process surrogates with Matérn 5/2 kernel), SPSA, and random search. Input vectors are normalized to [0,1]^d, with acquisition functions varying by method (q-LogEI for Vanilla, qEI for SAASBO, Thompson sampling for TuRBO). Initial candidate pools use Sobol sampling (10-50 points depending on network), with 10 trials for small/medium networks and fewer for larger instances. Performance is measured by NRMSE improvement over initial solutions.

## Key Results
- BO methods achieve 54-97% improvement over initial solutions vs. SPSA's 2-27% across networks
- TuRBO consistently delivers strongest performance, particularly on complex networks like Small Region (69.54% improvement)
- All methods fail to improve upon initial solutions in the 10,100-dimensional Full Region scenario
- Sample efficiency of BO methods significantly exceeds non-BO baselines across all tested networks

## Why This Works (Mechanism)

### Mechanism 1: Surrogate-Based Sample Efficiency
BO methods construct Gaussian Process surrogates that approximate the expensive simulation objective, using acquisition functions to guide query selection. The GP models the relationship between OD demand vectors and traffic counts, with Matérn 5/2 kernel capturing smoothness assumptions. Each simulation updates the surrogate, improving predictions and enabling more informative queries. This approach assumes sufficient regularity in the objective function for GP modeling and that stochastic simulation noise can be captured by Gaussian likelihood.

### Mechanism 2: Local Trust Region Scalability
TuRBO's adaptive trust regions enable better optimization in high dimensions by maintaining local neighborhoods that expand after successes and contract after failures. This focuses the surrogate model on promising local regions rather than the full high-dimensional space, with Thompson sampling selecting candidates within these regions. The method assumes local structure can be exploited and that optimal solutions lie within discoverable local regions rather than requiring global search.

### Mechanism 3: Dimensionality-Induced Performance Degradation
Optimization performance degrades as input dimensionality increases due to GP surrogate modeling challenges and exponentially larger search spaces. Higher dimensions dilute observation informativeness, increase GP hyperparameter uncertainty, and make acquisition function optimization harder. The curse of dimensionality reduces observed sample density relative to search space volume. This assumes available function evaluations don't scale with dimensionality and that problems retain difficulty even with structural assumptions.

## Foundational Learning

- **Gaussian Process Surrogate Modeling**
  - Why needed: Understanding how GP kernels encode smoothness assumptions and lengthscale hyperparameters control dimension relevance is critical for diagnosing BO performance
  - Quick check: Can you explain why ARD lengthscales might struggle when many dimensions are influential (144+ dominant variables in Small Region)?

- **Acquisition Functions (Expected Improvement, UCB)**
  - Why needed: The choice of acquisition function determines exploration-exploitation trade-offs; understanding q-LogEI and Thompson sampling explains why TuRBO outperforms
  - Quick check: How would excessive noise in simulation outputs affect the reliability of Expected Improvement estimates?

- **Origin-Destination (OD) Matrix Estimation**
  - Why needed: The problem formulation (minimizing squared error between simulated and observed traffic counts) is an under-determined inverse problem; understanding this explains why multiple OD solutions can produce similar sensor fits
  - Quick check: Why does the paper use NRMSE over sensor-equipped links rather than directly comparing OD matrices to ground-truth demand?

## Architecture Onboarding

- **Component map:** SUMO Traffic Simulator -> OD Demand Vector -> BoTorch Framework -> Evaluation Pipeline
- **Critical path:** Load network configuration (XML files, TAZ definitions, sensor-link mappings) → Initialize candidate pool via Sobol sampling → For each epoch: run SUMO simulations, update GP surrogate, optimize acquisition function → Track best solution and compute improvement %
- **Design tradeoffs:** Batch size vs. memory (larger batches improve parallelism but increase RAM), trust region size vs. exploration (larger initial length enables broader search), simulation mode (mesoscopic trades fidelity for speed)
- **Failure signatures:** No improvement over initial solutions (indicates insufficient budget, GP failure, or OD bounds causing congestion), high variance across runs (suggests sensitivity to initialization), consistently underestimated counts (may indicate OD bounds too low or misaligned time windows)
- **First 3 experiments:** 1) Reproduce Simple Ramp baseline with Vanilla BO and TuRBO using Table 3 configs, 2) Compare Matérn 3/2 vs. 5/2 vs. RBF kernels on One-Way Corridor, 3) Test TuRBO initial length (0.4 vs. 0.8 vs. 1.2) on Junction network

## Open Questions the Paper Calls Out

### Open Question 1
Can embedding traffic physics into surrogate models overcome scalability failures in the 10,100-dimensional "Full Region" scenario? The paper explicitly states that standard BO methods failed to yield improvement in this case and suggests physics-informed kernels as a promising direction. Evidence would be a modified BO algorithm achieving statistically significant NRMSE reduction on Full Region where baselines failed.

### Open Question 2
How can uncertainty quantification be formulated to handle the under-determined nature of OD estimation and support robust counterfactual analysis? The paper identifies this as a key research direction, noting that current BO applications focus on point estimates while OD estimation is under-determined. Evidence would be a method that explicitly quantifies input uncertainty and demonstrates improved robustness in downstream policy evaluations.

### Open Question 3
Can traffic-physics-based tailored sampling mechanisms mitigate BO algorithms' sensitivity to initial samples in high-dimensional spaces? The paper notes that standard BO solvers are highly sensitive to initial samples and proposes physics-informed sampling. Evidence would be comparative experiments showing physics-informed initialization consistently leads to faster convergence and lower final NRMSE across different random seeds.

## Limitations

- Limited statistical reliability for very high dimensions (>1,000) due to few runs (3 for Small Region, 1 for Full Region)
- Benchmark assumes Gaussian noise models that may not capture all simulation artifacts
- Real-world applicability untested beyond San Jose, CA networks

## Confidence

- **High confidence**: BO methods outperform non-BO baselines in sample efficiency (multiple independent trials, consistent improvements)
- **Medium confidence**: TuRBO is best overall method (strongest in most networks but not all; Full Region had insufficient runs)
- **Medium confidence**: Performance degrades with dimensionality (consistent trend but extreme cases lack statistical power)

## Next Checks

1. Replicate Full Region experiments with increased trial count (5-10 runs) to validate statistical significance of performance claims
2. Test BO4Mob framework with alternative kernel families (RBF, periodic) to assess sensitivity to Matérn 5/2 assumptions
3. Apply dimensionality reduction techniques (PCA, active subspace) to determine if BO performance improves on high-dimensional networks