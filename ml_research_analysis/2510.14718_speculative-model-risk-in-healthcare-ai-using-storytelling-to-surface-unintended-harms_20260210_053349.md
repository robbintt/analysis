---
ver: rpa2
title: 'Speculative Model Risk in Healthcare AI: Using Storytelling to Surface Unintended
  Harms'
arxiv_id: '2510.14718'
source_url: https://arxiv.org/abs/2510.14718
tags:
- story
- health
- stories
- harms
- ethical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a human-centered framework that uses AI-generated
  user stories to help people think creatively about potential benefits and harms
  of healthcare AI before deployment. The method combines automated story generation
  with multi-agent red-team discussions to simulate realistic scenarios where AI systems
  might succeed or fail.
---

# Speculative Model Risk in Healthcare AI: Using Storytelling to Surface Unintended Harms

## Quick Facts
- arXiv ID: 2510.14718
- Source URL: https://arxiv.org/abs/2510.14718
- Reference count: 40
- Primary result: AI-generated user stories significantly broaden identification of healthcare AI risks compared to traditional methods

## Executive Summary
This paper introduces a novel framework for identifying potential harms of healthcare AI systems before deployment by leveraging AI-generated user stories and multi-agent red-team discussions. The approach combines automated story generation with human interpretation to create realistic scenarios that surface both intended benefits and unintended consequences across multiple stakeholder perspectives. Through a user study with 18 participants, the method demonstrated significant improvements in identifying diverse categories of harms compared to control conditions, with storytelling participants achieving higher entropy in harm identification (3.383 vs. 2.433). The narrative format proved particularly effective at engaging non-technical participants and helping them articulate risks they might otherwise overlook, suggesting a promising approach for comprehensive pre-deployment risk assessment in healthcare AI.

## Method Summary
The framework employs a multi-stage process beginning with automated story generation that creates diverse narratives about healthcare AI scenarios. These stories are then used as discussion prompts for multi-agent red-team sessions, where participants simulate various stakeholder perspectives to explore potential outcomes. The approach specifically targets the identification of speculative harms by encouraging creative thinking about edge cases and unintended consequences. In the user study, participants were divided into control and storytelling groups, with the latter engaging with AI-generated narratives before identifying potential risks and benefits. The methodology emphasizes human interpretation and collaborative discussion, recognizing that while AI can generate scenarios, human judgment remains crucial for meaningful risk assessment and ethical consideration.

## Key Results
- Storytelling participants identified harms across all 13 risk categories with significantly higher diversity (entropy 3.383) compared to control (2.433)
- Control participants focused narrowly on privacy and well-being issues (58.3% of identified harms)
- The narrative approach revealed more diverse benefits, with entropy increasing from 2.579 to 3.554
- Participants consistently found the storytelling format engaging and accessible for articulating risks

## Why This Works (Mechanism)
The effectiveness stems from narrative psychology's power to engage emotional and cognitive processing simultaneously. Stories provide concrete scenarios that help participants envision abstract risks in relatable contexts, while the multi-agent format encourages consideration of diverse stakeholder perspectives. This combination overcomes cognitive biases that typically narrow risk assessment to familiar categories. The framework's success relies on the synergy between AI's ability to generate diverse scenarios and human capacity for ethical reasoning and contextual interpretation.

## Foundational Learning
- **Narrative cognition**: Stories engage both emotional and logical thinking pathways, making abstract risks more tangible and memorable
- **Multi-stakeholder perspective-taking**: Different viewpoints reveal blind spots that single-perspective analysis misses
- **Pre-deployment speculative risk identification**: Early detection of potential harms allows for design modifications before systems are deployed
- **Entropy as diversity metric**: Using information theory to quantify the breadth of risk identification provides objective comparison across methods
- **Human-AI collaboration in risk assessment**: Combining automated scenario generation with human interpretation leverages complementary strengths

## Architecture Onboarding

Component map:
AI Story Generator -> Multi-agent Red-team Discussion -> Risk Identification Framework -> Entropy Analysis

Critical path:
1. Generate diverse healthcare AI scenarios
2. Facilitate stakeholder perspective discussions
3. Document identified risks and benefits
4. Quantify diversity using entropy measures
5. Synthesize findings for risk mitigation

Design tradeoffs:
- Balance between scenario diversity and plausibility
- Trade-off between narrative complexity and accessibility
- Tension between comprehensive risk coverage and focused assessment

Failure signatures:
- Participants defaulting to familiar risk categories
- Overemphasis on technical rather than human-centered harms
- Difficulty translating narrative insights into actionable mitigation strategies

First experiments:
1. Test story generation with different AI models to optimize scenario diversity
2. Validate entropy metric against expert human assessment of risk diversity
3. Conduct pilot studies