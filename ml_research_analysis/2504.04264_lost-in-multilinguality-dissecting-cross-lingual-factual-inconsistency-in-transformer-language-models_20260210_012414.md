---
ver: rpa2
title: 'Lost in Multilinguality: Dissecting Cross-lingual Factual Inconsistency in
  Transformer Language Models'
arxiv_id: '2504.04264'
source_url: https://arxiv.org/abs/2504.04264
tags:
- language
- rank
- correct
- layers
- answer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses cross-lingual factual inconsistency in multilingual
  language models, where models provide correct answers in one language but fail in
  semantically equivalent prompts in other languages. Through mechanistic interpretability
  analysis, the authors discover that models encode knowledge in a language-independent
  concept space through most layers, transitioning to language-specific spaces only
  in final layers.
---

# Lost in Multilinguality: Dissecting Cross-lingual Factual Inconsistency in Transformer Language Models

## Quick Facts
- **arXiv ID**: 2504.04264
- **Source URL**: https://arxiv.org/abs/2504.04264
- **Reference count**: 40
- **Primary result**: A linear shortcut method bypasses final-layer language transition errors, improving both accuracy (71.47%→76.08% on LLaMA2) and cross-lingual consistency across languages.

## Executive Summary
This paper investigates why multilingual transformer models exhibit cross-lingual factual inconsistency—correctly answering factual questions in one language while failing on semantically equivalent prompts in other languages. Through mechanistic interpretability analysis of two multilingual models (LLaMA2 and BLOOM), the authors discover that models encode factual knowledge in a language-independent concept space through most layers, transitioning to language-specific spaces only in final layers. Failures during this transition cause incorrect predictions. The proposed linear shortcut method bypasses these error-prone final-layer computations, significantly improving both prediction accuracy and cross-lingual consistency.

## Method Summary
The method addresses cross-lingual factual inconsistency by identifying that multilingual models encode knowledge in a language-independent concept space through early-to-middle layers, with language-specific transitions occurring only in final layers. The linear shortcut method learns a transformation from an intermediate layer's representation directly to the final unembedding space, bypassing the error-prone language transition. Using correctly predicted samples, the method estimates a linear function f(h_n) = βW·h_n + b that approximates the mapping from layer-n to final-layer representations. This shortcut is then applied at inference to improve both accuracy and cross-lingual consistency.

## Key Results
- The linear shortcut improves LLaMA2 accuracy from 71.47% to 76.08% and BLOOM from 43.24% to 51.67%
- Cross-lingual consistency (CLC) increases significantly, with language pairs showing up to 14% improvement
- The method works across 17 languages tested on LLaMA2 and 7 languages on BLOOM
- Linear shortcut outperforms translation-based baselines (53.88% for LLaMA2, 28.03% for BLOOM)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multilingual models encode factual knowledge in a language-independent "concept space" through early-to-middle layers, regardless of input language.
- Mechanism: Information flows through layers where representations for semantically equivalent prompts in different languages converge (high cosine similarity ~0.8 in middle layers), enabling language-agnostic knowledge retrieval before language-specific adaptation.
- Core assumption: The concept space is consistent across input languages and represents abstracted semantic content rather than surface linguistic features.
- Evidence anchors: [abstract] "MLMs encode knowledge in a language-independent concept space through most layers"; [Section 5.2] "similarity increases, peaking around 0.8 in the middle layers for both models"; [Section 5.4] "middle-to-upper layers exhibits similar language compositions across different input languages"

### Mechanism 2
- Claim: Language transition from concept space to language-specific output occurs in final layers and is the primary failure point for cross-lingual inconsistency.
- Mechanism: Correct answers are often retrieved in the concept space (English rank = 0 in middle layers), but during final-layer language transition, incorrect target-language tokens overtake correct ones in ranking.
- Core assumption: Failures are localized to the transition mechanism, not to earlier knowledge retrieval stages.
- Evidence anchors: [abstract] "Failures during the language transition often result in incorrect predictions"; [Section 6] "the rank of the incorrect answer surpasses that of the correct answer during language transition in the final layers"; [Figure 5] Shows rank_target_wrong crossing above rank_target_correct in final layers for incorrect predictions

### Mechanism 3
- Claim: A learned linear transformation can approximate and bypass error-prone final-layer computations, recovering correct outputs.
- Mechanism: Using correctly predicted samples, estimate a linear shortcut f(h_n) = βW·h_n + b that maps layer-n representations directly to final-layer space, skipping transition failures.
- Core assumption: The transformation from concept-space representation to language-specific output is approximately linear and learnable from limited correct examples.
- Evidence anchors: [Section 7.1] "we hypothesize that the mapping from the model's latent state at layer n to the final layer N... can be well-approximated by a linear function"; [Table 2] LLaMA2 accuracy: 71.47% → 76.08%; BLOOM: 43.24% → 51.67%

## Foundational Learning

- **Logit Lens**: Core tool for projecting intermediate layer representations to vocabulary space, enabling layer-wise analysis of prediction evolution.
  - Why needed here: Enables observing how predictions evolve across layers and identifying where correct answers are available before final transition
  - Quick check question: Can you explain how projecting a hidden state through the unembedding matrix reveals the model's "intermediate predictions"?

- **Cross-lingual Consistency Metrics**: Quantifies the problem being solved; understanding overlap ratio vs. candidate-based metrics is essential for valid evaluation.
  - Why needed here: Provides the primary evaluation metric for measuring cross-lingual consistency improvements
  - Quick check question: Why might first-token evaluation be unreliable in multilingual settings?

- **Linear Approximation of Layer Transformations**: Foundation for the shortcut method; understanding first-order Taylor expansion and Jacobian estimation enables reproduction.
  - Why needed here: Underlies the mathematical framework for approximating final-layer transformations
  - Quick check question: Why does layer normalization require the scalar β correction factor in the linear approximation?

## Architecture Onboarding

- **Component map**: Embedding layer -> Early layers (1-12 in LLaMA2): relation processing in concept space -> Middle layers (12-28): object extraction in concept space (language-independent) -> Final layers (28-32): language transition to target-language output -> Unembedding: projection to vocabulary for prediction -> Linear shortcut: bypass path from layer n → unembedding via learned W, b

- **Critical path**: 1. Input prompt in any language → embedding 2. Middle layers converge to concept-space representation with correct answer ranked high 3. Final layers diverge based on target language 4. Either: successful transition → correct output, or transition failure → incorrect output 5. Shortcut: intercept at layer n, apply linear transform, bypass remaining layers

- **Design tradeoffs**: Layer n selection: Earlier = more preserved context but larger approximation error; later = smaller approximation gap but risk of transition contamination; Training samples (m): More samples improve robustness but require correctly predicted data; Per-language vs. shared shortcuts: Per-language captures language-specific patterns but increases complexity

- **Failure signatures**: Middle-layer rank_en_correct = 0 but final output incorrect → transition failure (shortcut target); Middle-layer rank_en_correct high → retrieval failure (shortcut will not help); Shortcut accuracy < original → overfitting or poor hyperparameter selection

- **First 3 experiments**:
  1. **Replicate rank analysis**: For 20 samples each in 3 languages (e.g., en, zh, es), plot rank_target_correct, rank_en_correct, and rank_target_wrong across all layers to verify the transition failure pattern
  2. **Measure latent state similarity**: Compute cosine similarity of final-token hidden states for parallel facts across language pairs to confirm concept-space convergence in middle layers
  3. **Implement linear shortcut for one language**: Using m=25 correct samples, estimate W and b from layer 30 for LLaMA2, evaluate accuracy improvement on held-out facts

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can non-linear transformation functions (e.g., learned MLPs, attention-based adapters) outperform the linear shortcut method for bypassing language transition errors, and what is the optimal architecture?
- Basis in paper: [explicit] Conclusion states: "developing non-linear shortcut methods could better mitigate language transition errors, offering more robust solutions for cross-lingual consistency."
- Why unresolved: The authors use linear approximation for simplicity, but acknowledge it may not capture complex non-linear transformations during language switching.

### Open Question 2
- Question: Does the identified three-stage knowledge recall process (relation processing → object extraction → language transition) generalize to low-resource and typologically diverse languages beyond the 17 tested?
- Basis in paper: [explicit] Conclusion states: "Future work could expand the investigation to more languages and additional language models to assess broader applicability."
- Why unresolved: Current evaluation covers only 17 languages, predominantly higher-resource languages; it remains unclear whether the mechanism holds for morphologically rich, agglutinative, or polysynthetic languages with limited training data.

### Open Question 3
- Question: How do different pivot languages (beyond English) affect the linear shortcut's effectiveness and the characterization of the concept space?
- Basis in paper: [inferred] Limitations section notes: "our cross-lingual consistency analysis assumes English as the pivot language... it may limit applicability to language pairs that do not involve English."
- Why unresolved: The concept space appears English-biased in LLaMA2, but it is unknown whether a different pivot language (e.g., Chinese, Spanish) would yield different shortcut performance or reveal alternative latent language structures.

## Limitations

- The linear shortcut method requires correctly predicted samples for parameter estimation, limiting applicability to relations where baseline accuracy is already high
- The mechanistic analysis relies on rank-based observations without establishing causal relationships between layer representations and prediction outcomes
- The concept space hypothesis lacks ablation studies showing what happens when this hypothesized intermediate representation is perturbed or directly manipulated

## Confidence

- **High confidence**: The observation that cross-lingual factual inconsistency exists and that models show different performance across languages for semantically equivalent prompts. The rank analysis showing transition failures in final layers is empirically supported.
- **Medium confidence**: The specific claim that knowledge is encoded in a language-independent concept space through most layers. While similarity metrics support this, alternative explanations (such as shared multilingual embeddings rather than true concept abstraction) cannot be ruled out without further experimentation.
- **Medium confidence**: The linear shortcut method improves metrics as reported, but the extent to which this addresses the root cause versus providing a heuristic bypass remains unclear. The approximation's limitations and failure modes are not fully characterized.

## Next Checks

1. **Concept space perturbation experiment**: Use adversarial techniques to modify middle-layer representations while preserving cross-lingual similarity, then measure effects on final predictions to establish causal links between concept space and prediction accuracy.

2. **Low-accuracy relation analysis**: Systematically evaluate the linear shortcut method on relations with baseline accuracy below 50%, measuring whether improvements are consistent or if the method fails to generalize to difficult cases.

3. **Ablation of language-specific components**: Compare the linear shortcut against simpler baselines like freezing middle layers and only fine-tuning final layers, to determine whether the complexity of the linear approximation is justified by performance gains.