---
ver: rpa2
title: Analyzing Finnish Inflectional Classes through Discriminative Lexicon and Deep
  Learning Models
arxiv_id: '2509.04813'
source_url: https://arxiv.org/abs/2509.04813
tags:
- ectional
- classes
- accuracy
- class
- finnish
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether the Discriminative Lexicon Model
  (DLM) can learn Finnish nominal inflection without explicit inflectional class features,
  challenging the assumption that such abstract categories are necessary for learners.
  Using 55,271 inflected nouns from 2000 high-frequency Finnish words across 49 inflectional
  classes, the researchers trained DLM models with and without token frequency information.
---

# Analyzing Finnish Inflectional Classes through Discriminative Lexicon and Deep Learning Models

## Quick Facts
- **arXiv ID**: 2509.04813
- **Source URL**: https://arxiv.org/abs/2509.04813
- **Reference count**: 5
- **Primary result**: DLM models learn Finnish nominal inflection without explicit class features, with 4-gram representations achieving 64.3% test accuracy

## Executive Summary
This study investigates whether the Discriminative Lexicon Model (DLM) can learn Finnish nominal inflection without explicit inflectional class features, challenging the assumption that such abstract categories are necessary for learners. Using 55,271 inflected nouns from 2000 high-frequency Finnish words across 49 inflectional classes, the researchers trained DLM models with and without token frequency information. Models using 4-gram form representations achieved high accuracy (97.8% training, 64.3% test) compared to 3-gram models. For comprehension, accuracy correlated with inflectional class productivity measures, while usage-based production models showed frequency as the dominant factor, weakening productivity correlations. Linear discriminant analysis revealed that inflectional class information is systematically encoded in fastText embeddings, particularly within specific case-number contexts.

## Method Summary
The researchers used 55,271 inflected forms from 2,000 high-frequency Finnish nouns across 49 inflectional classes. They represented words as multi-hot vectors of 3-grams (3,103 features) or 4-grams (13,364 features) and used 300-dimensional fastText embeddings as semantic vectors. Two training approaches were used: EOL (endstate-of-learning, treating all types equally) and FIL (frequency-informed learning, weighting by token frequency). Comprehension used linear mappings (C→S), while production used deep networks (300×1000×3103) with synthesis-by-analysis feedback. They evaluated accuracy@1 and accuracy@10, and analyzed productivity correlations using type count, hapax legomena, and P/P* measures.

## Key Results
- 4-gram models achieved 64.29% test accuracy vs. 36.15% for 3-gram models
- Comprehension accuracy correlated with inflectional class productivity in EOL models
- Production models showed frequency dominance, weakening productivity correlations
- LDA predicted inflectional class from embeddings at 46% accuracy (16% baseline), improving to 40-67% within case-number contexts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Linear mappings between form and meaning vectors can capture Finnish inflection without explicit class features.
- Mechanism: The Discriminative Lexicon Model (DLM) learns a comprehension mapping F from form matrix C to semantic matrix S (CF = S), and a production mapping G in the reverse direction (SG = C). Form vectors are multiple-hot 1/0 vectors indicating which n-grams appear in a word; semantic vectors are 300-dimensional fastText embeddings.
- Core assumption: Form-meaning regularities are sufficiently systematic that linear transformations can approximate the mapping without symbolic abstractions.
- Evidence anchors:
  - [abstract] "This study investigates whether the Discriminative Lexicon Model (DLM) can understand and produce Finnish inflected nouns without setting up inflectional classes."
  - [section 3.1] Describes the linear mappings CF = S and SG = C with n-gram form vectors.
  - [corpus] Limited direct corpus support for this specific mechanism; related work on morphological productivity (Baayen) provides theoretical grounding but not direct validation.
- Break condition: If form and meaning spaces are not sufficiently isomorphic (e.g., high homonymy, arbitrary form-meaning pairings), linear mappings will fail to generalize.

### Mechanism 2
- Claim: 4-gram form representations capture Finnish morphophonology better than 3-grams, improving generalization.
- Mechanism: Longer n-grams encode more context, capturing longer suffixes and stem alternations characteristic of Finnish consonant gradation and vowel changes.
- Core assumption: The critical phonological alternations in Finnish inflection span 4+ character sequences.
- Evidence anchors:
  - [abstract] "Models using 4-gram form representations achieved high accuracy (97.8% training, 64.3% test) compared to 3-gram models."
  - [section 3.3.1, Table 3] Shows FIL 4-gram accuracy at 64.29% on test data vs. 36.15% for 3-grams—nearly doubling performance.
  - [corpus] No direct corpus validation; the finding is internal to this study.
- Break condition: For languages with shorter morphemes or less complex stem alternations, 4-grams may introduce sparsity without benefit; 3-grams or character-level representations may suffice.

### Mechanism 3
- Claim: Inflectional class information is systematically encoded in distributional semantic space, enabling generalization.
- Mechanism: Linear Discriminant Analysis (LDA) can predict inflectional class from fastText embeddings above chance (46% cross-validated vs. 16% baseline), with accuracy improving substantially when conditioned on case-number contexts (40–67% cross-validated).
- Core assumption: Words sharing inflectional patterns also share distributional contexts, creating class-correlated structure in embeddings.
- Evidence anchors:
  - [abstract] "Linear discriminant analysis revealed that inflectional class information is systematically encoded in fastText embeddings, particularly within specific case-number contexts."
  - [section 3.2.1, Table 2] LDA accuracy varies by case-number combination (e.g., sg_tra at 67.2% CV, pl_ins at 40.3% CV), showing class information is partially embedded in semantics.
  - [corpus] Related work on Polish (Orzechowska and Baayen 2025, cited in paper) finds similar predictability of inflectional class from embeddings.
- Break condition: If embeddings are derived from corpora lacking sufficient morphological diversity, or if inflectional classes are semantically arbitrary, this signal will weaken or disappear.

## Foundational Learning

- Concept: **Inflectional classes and productivity**
  - Why needed here: The paper tests whether abstract class labels are cognitively necessary. Understanding productivity measures (type count V, hapax legomena V(1), P, P*) is essential to interpret model performance across classes.
  - Quick check question: Can you explain why a class with many types but few hapax legomena might be less productive than a smaller class with many hapaxes?

- Concept: **Discriminative vs. generative mappings**
  - Why needed here: DLM uses error-driven discriminative learning (predicting output from input) rather than rule-based generation. This conceptual shift is central to interpreting why explicit classes are unnecessary.
  - Quick check question: In a discriminative framework, what would it mean for a model to "know" an inflectional class versus simply mapping form to meaning accurately?

- Concept: **Frequency-informed vs. endstate-of-learning training**
  - Why needed here: FIL models weight learning by token frequency, approximating human exposure; EOL models treat all types equally, probing theoretical learnability limits. The paper shows different conclusions emerge from each (productivity correlates hold in EOL/comprehension but weaken in FIL/production).
  - Quick check question: Why might a frequency-informed model show weaker correlations with productivity measures than an endstate model?

## Architecture Onboarding

- Component map:
  - **Form matrix C**: Rows = word types/tokens; columns = n-gram features (3,103 trigrams or 13,364 4-grams)
  - **Semantic matrix S**: Rows = word types/tokens; columns = 300-dim fastText embeddings
  - **Comprehension mapping F**: Linear transform C → S, trained via least squares
  - **Production mapping G**: Linear transform S → C (challenging due to dimensionality) OR deep network (300 × 1000 × 3103) with ReLU and binary cross-entropy loss
  - **"Where" system**: Algorithm to order predicted n-grams into valid word candidates
  - **Synthesis-by-analysis feedback**: Selects production candidate whose comprehension output best matches intended meaning

- Critical path:
  1. Build form vectors from n-grams for all inflected forms in vocabulary
  2. Load pre-trained fastText embeddings for semantic vectors
  3. Train comprehension mapping (F) via linear regression or equivalent
  4. For production: train deep network to predict form from semantics; run "where" algorithm; apply feedback loop
  5. Evaluate via nearest-neighbor accuracy on held-out test data

- Design tradeoffs:
  - **3-grams vs. 4-grams**: 4-grams improve accuracy but increase sparsity and memory (13k vs. 3k features). Production experiments used 3-grams due to computational constraints.
  - **Linear vs. deep mappings**: Linear is interpretable and fast; deep networks handle low→high dimension mapping better for production but require more data and tuning.
  - **Type-based (EOL) vs. token-based (FIL)**: EOL reveals theoretical learnability; FIL approximates human learning but shows frequency dominance over productivity effects.

- Failure signatures:
  - **Low test accuracy on unproductive classes**: Model struggles with novel forms from small, low-productivity classes (few hapaxes, high median frequency)
  - **Production "what" system failure**: Linear S→C mapping achieves only 7% accuracy; requires deep network
  - **Frequency swamping**: In FIL production models, word frequency dominates productivity correlates—random intercepts for class show weak/no relation to productivity measures
  - **Case-number interaction complexity**: Accuracy varies non-uniformly across paradigm cells; models assuming main effects only will underfit

- First 3 experiments:
  1. **Replicate comprehension with 3-grams on a subset**: Train linear EOL model on 5,000 words; verify training accuracy >80% and test accuracy ~35–40% on held-out forms to confirm basic pipeline
  2. **Compare 3-gram vs. 4-gram on same split**: Expect ~2× test accuracy improvement with 4-grams; if not observed, check data sparsity or embedding coverage
  3. **Pilot production with deep network**: Train 300 × 500 × 3103 network on form prediction; verify >90% training accuracy, ~80%+ test accuracy on seen lexemes with unseen case-number combinations before attempting full "where" system integration

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do human learners implicitly rely on statistical form-meaning mappings rather than explicit inflectional class features when acquiring complex morphology?
- Basis in paper: [explicit] The authors state it remains "unclear whether inflectional classes are cognitively real" and explicitly challenge the assumption that learners must discover these abstract classes.
- Why unresolved: This study provides computational proof-of-concept using the DLM, but computational learnability does not automatically equate to cognitive reality without behavioral validation.
- What evidence would resolve it: Behavioral experiments (e.g., lexical decision tasks) correlating human reaction times and error rates with the DLM's semantic similarity metrics rather than traditional class-based rules.

### Open Question 2
- Question: Why does inflectional class productivity predict accuracy in comprehension but fail to predict performance in usage-based production models?
- Basis in paper: [explicit] The abstract and discussion highlight a "novel asymmetry" where frequency dominates production performance, causing correlations with productivity measures to become "tenuous or absent."
- Why unresolved: The authors demonstrate that this asymmetry exists in the model outputs but do not fully explain the underlying mechanisms that cause frequency to suppress productivity effects specifically in the production mapping.
- What evidence would resolve it: Ablation studies varying frequency distributions in the training data, or neurocognitive studies distinguishing frequency-based retrieval from combinatorial generation processes.

### Open Question 3
- Question: How can the "where-system" (sequencing n-grams into words) be optimized to achieve high accuracy in frequency-informed production without prohibitive computational costs?
- Basis in paper: [inferred] The authors note that while deep networks work for "endstate learning," they are "computationally extremely demanding" for frequency-informed learning, forcing the use of inaccurate linear mappings (7% accuracy).
- Why unresolved: There is a methodological trade-off: linear mappings are computationally feasible for usage-based learning but statistically inadequate for the high-dimensional form space required for production.
- What evidence would resolve it: Development of efficient approximation algorithms or sparse network architectures that allow non-linear frequency-informed training on the full dataset.

## Limitations
- **Data availability**: The exact list of 2,000 nouns and 55,271 inflected forms is not provided, requiring acquisition of the referenced dataset
- **Computational constraints**: 4-gram representations are prohibitive for production experiments, limiting the study to 3-grams in this domain
- **Frequency dominance**: In production models, frequency effects overwhelm productivity correlates, limiting theoretical insights about class-based learning

## Confidence
- **High**: The computational methods (DLM, LDA, deep networks) are well-established and the results are internally consistent
- **Medium**: The behavioral interpretation of frequency vs. productivity effects in human learning remains speculative without empirical validation
- **Low**: The computational intractability of frequency-informed production with 4-grams prevents full exploration of the method's potential

## Next Checks
1. Verify that the Finnish fastText embeddings contain sufficient coverage of the 2,000 high-frequency nouns used in the study
2. Confirm that the 3-gram vs. 4-gram accuracy difference replicates on a held-out validation set before scaling to full production experiments
3. Test whether LDA can recover inflectional class information from embeddings on a different morphologically rich language to validate the general mechanism