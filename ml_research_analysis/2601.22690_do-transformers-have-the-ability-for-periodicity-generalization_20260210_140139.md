---
ver: rpa2
title: Do Transformers Have the Ability for Periodicity Generalization?
arxiv_id: '2601.22690'
source_url: https://arxiv.org/abs/2601.22690
tags:
- periodicity
- generalization
- training
- composite
- rope
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether Transformers can generalize periodicity,
  a fundamental out-of-distribution (OOD) generalization problem. The authors propose
  a unified group-theoretic interpretation of periodicity that distinguishes sequence
  periodicity (which Transformers with RoPE can capture) from rule periodicity (which
  they cannot).
---

# Do Transformers Have the Ability for Periodicity Generalization?

## Quick Facts
- **arXiv ID:** 2601.22690
- **Source URL:** https://arxiv.org/abs/2601.22690
- **Reference count:** 25
- **Primary result:** Transformers can memorize periodic patterns but fail to generalize composite periodicity, with accuracy dropping from 94.7% in-distribution to 22.6% in extrapolation settings.

## Executive Summary
This paper investigates whether Transformers can generalize periodicity, distinguishing between sequence periodicity (which RoPE-based Transformers can capture) and rule periodicity (which they cannot). The authors propose a unified group-theoretic interpretation and introduce composite periodicity, where multiple periodic rules are combined. They construct Coper, a benchmark testing out-of-distribution generalization through Hollow (interpolation) and Extrapolation settings. Experiments across multiple architectures show that while models achieve high in-distribution accuracy, performance drops significantly in OOD settings, revealing a fundamental gap in current architectural capabilities for periodicity generalization.

## Method Summary
The paper introduces Coper, a benchmark dataset for testing periodicity generalization. It generates periodic sequences by sampling two periodic functions with periods P1 and P2, computing their modular addition, and formatting them as a next-token prediction task. The dataset includes 50k training samples with period pairs in [4,14]² (excluding a Hollow region [8,11]²), 3k test samples, and evaluates accuracy on in-distribution, Hollow (held-out period pairs), and Extrapolation (periods outside training range) splits. The primary architecture tested is a Transformer with RoPE positional encoding, trained for 450 epochs with frozen Qwen2.5 tokenizer and embeddings.

## Key Results
- Transformers achieve 94.7% in-distribution accuracy but drop to 29.8% on Hollow and 22.6% on Extrapolation tasks
- Increasing training data density improves Hollow performance but has minimal effect on Extrapolation
- Scaling model size provides marginal improvements in OOD generalization
- RoPE positional encoding enables single-period generalization but fails on composite periodicity
- The failure is consistent across Transformer, FANformer, Mamba, and RWKV architectures

## Why This Works (Mechanism)

### Mechanism 1: RoPE-based Sequence Periodicity Capture
- **Claim:** Transformers with RoPE can generalize simple sequence periodicity when the transformation preserves relative positional invariance.
- **Mechanism:** RoPE encodes position as phase rotation, making attention rely on relative positional differences. This allows recognition of invariance when f(a)-f(b) = f(a+T)-f(b+T).
- **Evidence anchors:** Abstract states "sequence periodicity (which Transformers with RoPE can capture)"; Section 3.3.1 proves RoPE can represent sequence periodicity.
- **Break condition:** Transformation violates relative invariance or RoPE is replaced with absolute positional encodings.

### Mechanism 2: Memorization of Period Combinations vs. Rule Abstraction
- **Claim:** Models fail composite periodicity because they memorize specific period combinations rather than abstracting compositional rules.
- **Mechanism:** Models learn statistical correlations between input period pairs and output sequences, treating each pair as a distinct pattern to memorize.
- **Evidence anchors:** Abstract states "models can memorize periodic data during training, but cannot generalize to unseen composite periodicity"; Table 1 shows high ID but low OOD accuracy.
- **Break condition:** Architecture includes strong inductive biases for symbolic composition or algorithmic reasoning.

### Mechanism 3: Group-Theoretic Limitation on Rule Periodicity
- **Claim:** Transformers with RoPE fail to represent rule periodicity because the group action governing the rule does not commute with the group action governing sequence shift.
- **Mechanism:** Rule periodicity requires applying the same rule at different positions, but RoPE's relative encoding cannot capture this when rule period differs from sequence period.
- **Evidence anchors:** Abstract distinguishes "sequence periodicity... from rule periodicity (which they cannot)"; Section 3.3.2 provides mathematical proof.
- **Break condition:** Rule period is identical to sequence period, reducing to solvable single-period case.

## Foundational Learning

**Concept: Periodicity**
- **Why needed here:** Core subject; understanding invariance under transformation is key to group-theoretic interpretation and RoPE's limited success.
- **Quick check question:** If f(t+3) = f(t), what is the period, and what transformation is the function invariant under?

**Concept: Out-of-Distribution (OOD) Generalization**
- **Why needed here:** Paper frames periodicity generalization as fundamental OOD problem; Hollow and Extrapolation are specific distribution shifts.
- **Quick check question:** Model trained on addition with operands 1-10 is tested on 5-7 (unseen combinations) and 11-15 (outside range). Which is Hollow and which is Extrapolation?

**Concept: Rotary Position Embedding (RoPE)**
- **Why needed here:** Architectural component providing some periodicity generalization; relative-position focus is central mechanism analyzed.
- **Quick check question:** How does RoPE encode position of a token, and why does this make it sensitive to relative rather than absolute distance?

## Architecture Onboarding

**Component map:** Tokenizer -> Frozen Qwen2.5 embeddings -> Transformer with RoPE -> Next-token prediction head

**Critical path:**
1. **Input:** Two periodic sequences f1, f2 sampled and concatenated as `sequence1 + '+' + sequence2 + '='`
2. **Processing:** RoPE injects relative positional information; backbone processes combined sequence
3. **Task:** Model must autoregressively predict tokens of modular addition result sequence
4. **Evaluation:** Accuracy computed on result tokens for ID, Hollow, and Extrapolation period pairs

**Design tradeoffs:**
- **RoPE vs. Absolute PE:** RoPE enables single-period generalization but fails for composite/rule periodicity; Absolute PE fails both
- **Architecture Choice:** Transformers/FANformer achieve high ID accuracy but fail OOD; Mamba/RWKV have lower ID accuracy, making OOD interpretation difficult
- **Scaling vs. Data Density:** Scaling model size or increasing training data density improves Hollow more than Extrapolation, suggesting memorization over rule learning

**Failure signatures:**
- **Sharp accuracy drop from ID to OOD:** Clear sign of memorizing period pairs (P1, P2) instead of compositional rule
- **Non-convergence on non-invariant tasks:** Failure to learn periodic rules violating relative positional invariance
- **Failure on sin(x) generalization:** Inability to extend learned periodic patterns beyond training window

**First 3 experiments:**
1. **RoPE vs. Absolute PE on Single Periodicity:** Train on periods {4,5,6,8,9,10}. Evaluate on Hollow (T=7) and Extrapolation (T ∈ {2,3,11,12}). Validate RoPE's relative-position advantage.
2. **Coper Benchmark (Composite Periodicity):** Train on period pairs in [4,14]² excluding Hollow region. Evaluate on held-out Hollow and Extrapolation pairs. Establish core OOD generalization failure.
3. **Scaling vs. Data Density:** On Coper task, a) increase model layers and b) shrink training period range to increase density. Measure impact on Hollow vs. Extrapolation to disentangle memorization from rule learning.

## Open Questions the Paper Calls Out

**Open Question 1:** Can novel neural architectures be designed to inherently capture and generalize composite periodicity without relying on rote memorization? (Basis: Section 7 lists need for "designing architectures that can model composite periodicity")

**Open Question 2:** Does integration of external reasoning mechanisms, such as Chain-of-Thought prompting or external memory, mitigate observed failures in periodicity generalization? (Basis: Section 7 notes limitation of "not studying external reasoning mechanisms such as chain-of-thought (CoT) or memory")

**Open Question 3:** Can the proposed group-theoretic interpretation be extended to explain OOD generalization failures in broader reasoning scenarios beyond modular arithmetic? (Basis: Section 7 lists "extending the group-theoretic interpretation to more reasoning scenarios" as future work)

**Open Question 4:** How can models be improved to capture "hidden periodicity" where patterns are visible only across data distribution rather than individual sequences? (Basis: Section 6.1 and Appendix H discuss "hidden periodicity" like sine function generalization failure)

## Limitations

- The paper focuses specifically on modular addition of periodic sequences and doesn't explore whether findings extend to other periodic transformations or real-world applications
- Group-theoretic analysis may not capture all possible mechanisms by which models could learn compositional rules
- Experiments don't thoroughly explore alternative training strategies, data augmentation, or curriculum learning approaches that might improve OOD generalization
- Claim that this represents a fundamental architectural limitation rather than training or data representation issue is not fully validated

## Confidence

**High Confidence:** Experimental results showing RoPE's ability to handle single-period sequences while failing on composite periodicity are reproducible and well-documented.

**Medium Confidence:** Group-theoretic explanation for rule periodicity failure is mathematically sound but relies on specific assumptions about transformation properties.

**Low Confidence:** The claim that this represents a fundamental architectural limitation of Transformers rather than a training or data representation issue.

## Next Checks

1. **Alternative Positional Encodings:** Replicate core experiments using different positional encoding schemes (absolute, sinusoidal, learned) to determine whether failure is specific to RoPE or broader architectural limitation.

2. **Training Strategy Variations:** Test whether curriculum learning, data augmentation, or explicit regularization could improve OOD generalization without changing architecture.

3. **Alternative Compositions:** Evaluate whether failure generalizes beyond modular addition to other compositional rules like multiplication, averaging, or learned transformations of periodic sequences.