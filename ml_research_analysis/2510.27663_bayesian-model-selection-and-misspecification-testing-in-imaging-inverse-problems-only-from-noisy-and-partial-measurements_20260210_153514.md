---
ver: rpa2
title: Bayesian model selection and misspecification testing in imaging inverse problems
  only from noisy and partial measurements
arxiv_id: '2510.27663'
source_url: https://arxiv.org/abs/2510.27663
tags:
- bayesian
- imaging
- samples
- selection
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a methodology for unsupervised Bayesian model
  selection and misspecification detection in imaging inverse problems, leveraging
  data fission for measurement splitting. The approach enables evaluation of image
  priors and likelihoods without ground truth, using scoring rules like log-likelihood
  and perceptual metrics.
---

# Bayesian model selection and misspecification testing in imaging inverse problems only from noisy and partial measurements

## Quick Facts
- arXiv ID: 2510.27663
- Source URL: https://arxiv.org/abs/2510.27663
- Authors: Tom Sprunck; Marcelo Pereyra; Tobias Liaudat
- Reference count: 40
- Key outcome: Unsupervised Bayesian model selection and misspecification detection for imaging inverse problems using data fission, achieving high accuracy in model selection and out-of-distribution detection without ground truth

## Executive Summary
This paper introduces a novel methodology for unsupervised Bayesian model selection and misspecification testing in imaging inverse problems. The approach leverages data fission techniques to split noisy measurements into disjoint sets, enabling simultaneous evaluation of image priors and likelihoods without requiring ground truth data. By combining scoring rules like log-likelihood and perceptual metrics with advanced Bayesian inference techniques, the framework can accurately detect model misspecification and select appropriate models in single-shot settings.

The methodology demonstrates superior performance on image deblurring and MRI reconstruction tasks, showing high detection power for misspecified models and accurate kernel identification. The framework is computationally efficient and compatible with modern data-driven priors and plug-and-play samplers, making it suitable for large-scale imaging applications. Experimental results indicate that the approach outperforms existing methods while maintaining robustness across different imaging modalities.

## Method Summary
The proposed methodology centers on data fission, which splits noisy measurements into two disjoint sets: one for inference and one for validation. This enables simultaneous evaluation of image priors and likelihoods without ground truth. The framework uses scoring rules, including log-likelihood and perceptual metrics like FID and KID, to assess model performance. Bayesian inference is performed using advanced sampling techniques, including plug-and-play methods compatible with data-driven priors. The approach supports both supervised and unsupervised model selection, with particular emphasis on detecting misspecification in likelihood functions.

## Key Results
- Achieves high accuracy in Bayesian model selection and out-of-distribution detection without ground truth measurements
- Demonstrates superior performance in image deblurring and MRI reconstruction compared to existing methods
- Shows excellent computational efficiency suitable for large-scale imaging inverse problems

## Why This Works (Mechanism)
The methodology works by leveraging data fission to create independent measurement sets for inference and validation. This separation allows for unbiased evaluation of model components without requiring ground truth. The use of scoring rules provides quantitative measures of model fit, while the integration with advanced Bayesian sampling techniques ensures robust uncertainty quantification. The framework's compatibility with modern data-driven priors and plug-and-play methods enables its application to complex, real-world imaging problems.

## Foundational Learning
1. **Data Fission** - Splitting measurements into disjoint sets for inference and validation; needed to enable unsupervised model evaluation without ground truth
2. **Scoring Rules** - Statistical metrics (log-likelihood, perceptual metrics) for model assessment; needed to quantify model performance objectively
3. **Bayesian Inference** - Probabilistic framework for parameter estimation and uncertainty quantification; needed to handle measurement noise and model uncertainty
4. **Plug-and-Play Sampling** - Integration of pre-trained denoisers into Bayesian inference; needed to handle complex data-driven priors efficiently
5. **Misspecification Detection** - Statistical tests for identifying model inadequacy; needed to ensure reliable model selection in real-world applications

## Architecture Onboarding

**Component Map**: Data Fission -> Bayesian Inference -> Scoring Rules -> Model Selection/Misspecification Detection

**Critical Path**: The workflow begins with data fission to split measurements, followed by Bayesian inference to estimate posterior distributions, then scoring rules evaluate model performance, and finally model selection or misspecification detection is performed based on the scoring results.

**Design Tradeoffs**: The main tradeoff is between computational efficiency and accuracy. Data fission provides unbiased evaluation but requires additional computational resources for the second measurement set. The choice of scoring rules balances statistical rigor with computational tractability.

**Failure Signatures**: Poor model selection accuracy may indicate insufficient data fission quality or inappropriate scoring rule choice. Computational bottlenecks often arise from complex Bayesian sampling in high-dimensional spaces.

**First Experiments**:
1. Validate data fission effectiveness on synthetic imaging problems with known ground truth
2. Test scoring rule sensitivity across different imaging modalities and noise levels
3. Benchmark computational efficiency against existing Bayesian model selection methods

## Open Questions the Paper Calls Out
The paper identifies several areas requiring further investigation, including the framework's scalability to extremely large-scale inverse problems where measurement splitting may become computationally prohibitive. The dependence of optimal performance on specific measurement models and noise distributions remains uncharacterized. Additionally, the framework's behavior under extreme measurement noise levels and with highly ill-posed inverse problems has not been thoroughly explored.

## Limitations
- Scalability concerns for extremely large-scale inverse problems where measurement splitting may become computationally prohibitive
- Performance characterization across diverse imaging modalities and measurement models remains incomplete
- Sensitivity to hyperparameters in scoring rules and data fission procedures requires further investigation

## Confidence

**High confidence**: The core theoretical framework for Bayesian model selection and misspecification detection is sound, with rigorous mathematical foundations. Experimental results on image deblurring and MRI reconstruction demonstrate clear advantages over existing methods, and the use of scoring rules for model evaluation is well-justified.

**Medium confidence**: The computational efficiency claims are supported by experiments, but may not hold for all imaging inverse problems, particularly those involving very large datasets or complex priors. The generalizability to other imaging modalities beyond those tested is plausible but requires empirical verification.

**Low confidence**: The framework's behavior under extreme measurement noise levels and with highly ill-posed inverse problems has not been thoroughly explored. The sensitivity to hyperparameters in the scoring rules and data fission procedures is not fully characterized.

## Next Checks

1. Test the framework on 3D volumetric imaging data to assess scalability and computational efficiency for large-scale problems
2. Evaluate performance across a broader range of imaging modalities, including those with non-standard measurement models
3. Conduct systematic sensitivity analysis of the data fission parameters and scoring rule hyperparameters on detection accuracy