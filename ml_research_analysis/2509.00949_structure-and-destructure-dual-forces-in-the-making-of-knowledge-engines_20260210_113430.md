---
ver: rpa2
title: 'Structure and Destructure: Dual Forces in the Making of Knowledge Engines'
arxiv_id: '2509.00949'
source_url: https://arxiv.org/abs/2509.00949
tags:
- knowledge
- language
- forgetting
- page
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This thesis investigates bridging structured and unstructured paradigms
  for building knowledge engines. It reveals that both paradigms rely on structure
  formation through language modelling objectives, while also identifying the need
  for destructuring to improve model plasticity.
---

# Structure and Destructure: Dual Forces in the Making of Knowledge Engines

## Quick Facts
- **arXiv ID:** 2509.00949
- **Source URL:** https://arxiv.org/abs/2509.00949
- **Reference count:** 0
- **Primary result:** Language modeling induces latent structures in both structured and unstructured paradigms; active forgetting enhances generalization to unseen entities and languages

## Executive Summary
This thesis investigates the interplay between structured and unstructured paradigms in building knowledge engines, proposing that both rely on structure formation through language modeling objectives while requiring destructuring for improved plasticity. The work demonstrates that self-supervised language modeling can induce latent structures in both knowledge graphs and large language models, enabling structure recovery without explicit supervision. It introduces REFACTOR GNNs and active forgetting-based pretraining to address limitations in inductive knowledge graph completion and low-resource cross-lingual transfer, showing significant performance gains across multiple experiments.

## Method Summary
The thesis develops methods to bridge structured (knowledge graphs) and unstructured (LLMs) paradigms by revealing that language modeling objectives induce latent structures in both settings. Key methods include REFACTOR GNNs, which reinterpret embedding optimization as message-passing to explain factorization model limitations and improve inductive KG completion, and active forgetting, which periodically resets token/entity embeddings during pretraining to enhance model plasticity. The experimental pipeline involves pretraining RoBERTa-base with active forgetting on English CC-100, adapting the frozen transformer body on English MultiNLI, then adapting embeddings on 5M tokens of a low-resource language, and finally evaluating zero-shot performance on XNLI.

## Key Results
- Language modeling objectives induce latent structures recoverable in both knowledge graphs and LLMs
- Active forgetting of embeddings enhances generalization to unseen entities and languages
- REFACTOR GNNs improve inductive knowledge graph completion by truncating infinite implicit message-passing

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Language modeling objectives induce latent structures in both structured (knowledge graphs) and unstructured (LLMs) settings, enabling structure recovery
- Mechanism: Self-supervised language modeling captures contextual token relationships that emerge as recoverable global structures (e.g., triples in KGs, n-grams in LLMs) even without explicit structural supervision
- Core assumption: Language modeling objective provides sufficient signal to infer global structural patterns from local token contexts
- Evidence anchors: Demonstrates structure recovery from relation prediction objectives in KGs and n-gram extraction from LLMs
- Break condition: Insufficient contextual variety in training data or severe architectural limitations in context aggregation

### Mechanism 2
- Claim: Active forgetting (periodic embedding resets) improves model plasticity and generalization to unseen symbols
- Mechanism: Forgetting truncates infinite implicit message-passing cached in embeddings, forcing model body to learn abstract, transferable representations
- Core assumption: Overly rigid embeddings constrain model body's ability to adapt; periodic resets promote generalizable computation
- Evidence anchors: Shows improved inductive KG completion with REFACTOR GNNs and better low-resource cross-lingual transfer with forgetting-based pretraining
- Break condition: Too frequent forgetting prevents convergence; too infrequent provides insufficient plasticity benefits

### Mechanism 3
- Claim: Embedding optimization in factorization models can be reinterpreted as message-passing, explaining transductive limitations
- Mechanism: Gradient descent over entity embeddings accumulates neighborhood information, caching infinite rounds of implicit message-passing
- Core assumption: Equivalence between embedding updates and message-passing holds under gradient descent with softmax loss
- Evidence anchors: Formal proof of message-passing equivalence in DistMult under gradient descent
- Break condition: Complex optimizers with momentum diverge from gradient descent equivalence

## Foundational Learning
- **Knowledge Graph Embeddings (KGE):** Essential for understanding structured paradigm and REFACTOR GNN motivation. Quick check: Can you explain how a triplet (subject, relation, object) is scored in DistMult or ComplEx?
- **Transformer Residual Computation:** Critical for understanding Chapter 3's decomposition into factorization-like paths. Quick check: How do residual connections enable decomposition into 2^L paths?
- **Message-Passing in GNNs:** Central to REFACTOR GNNs and FM reinterpretation. Quick check: Describe message, aggregate, and update functions in a basic GNN layer.

## Architecture Onboarding
- **Component map:** Input embedding layer -> Transformer/GNN body -> Output embedding layer (token/entity embeddings, transformer layers, relation embeddings)
- **Critical path:** (1) Understand embedding role in caching message-passing, (2) Implement transformer decomposition for structure extraction, (3) Apply forgetting during pretraining or adaptation
- **Design tradeoffs:** Balancing structure formation via language modeling against destructuring via forgetting; more forgetting improves plasticity but risks losing task-specific structure
- **Failure signatures:** (1) Over-forgetting: loss spikes persist, model fails to retain structure, (2) Under-forgetting: overfitting to training entities/languages, poor zero-shot transfer, (3) Incomplete decomposition: noisy or uninformative extracted structures
- **First 3 experiments:** (1) Implement relation prediction as auxiliary objective for KG embedding model and measure link prediction improvement on FB15k-237, (2) Extract bigram structures from pre-trained LLM using decomposition method and verify alignment with training data, (3) Train RoBERTa-base with active forgetting and evaluate cross-lingual transfer to low-resource language

## Open Questions the Paper Calls Out
- **Open Question 1:** Does active forgetting improve plasticity in autoregressive LLMs or architectures with different pretraining objectives (e.g., DeBERTa)? The current work only validates on RoBERTa with masked language modeling.
- **Open Question 2:** Does active forgetting enhance adaptation to linguistic shifts beyond cross-lingual transfer, such as domain shifts or temporal evolution? Experiments were limited to cross-lingual scenarios.
- **Open Question 3:** Can the n-gram structure extraction method scale to higher-order n-grams (n > 3) and across cascaded self-attention modules? Current method is computationally bounded to unigrams, bigrams, and trigrams.

## Limitations
- Forgetting mechanism lacks rigorous theoretical grounding for optimal frequency and architecture interactions
- Transformer decomposition may not scale efficiently to very large models or capture deeper semantic structures
- Experiments primarily focus on knowledge graphs and language models, limiting generalizability to other structured data types

## Confidence
- **High Confidence:** Improved inductive KG completion with REFACTOR GNNs, cross-lingual transfer benefits from active forgetting, mathematical proof of message-passing equivalence
- **Medium Confidence:** Generalizability of forgetting mechanism across architectures, scalability of transformer decomposition, robustness of structure formation across objectives
- **Low Confidence:** Theoretical bounds on optimal forgetting frequency, complete characterization of structure formation failure, extension to multimodal knowledge representations

## Next Checks
1. **Ablation study on forgetting frequency:** Systematically vary forgetting interval K across orders of magnitude on