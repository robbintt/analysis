---
ver: rpa2
title: 'STAR: Spectral Truncation and Rescale for Model Merging'
arxiv_id: '2502.10339'
source_url: https://arxiv.org/abs/2502.10339
tags:
- merging
- star
- task
- arxiv
- merged
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Model merging faces performance degradation as the number of fine-tuned
  models increases, limiting practical multi-task deployment. This work introduces
  STAR, which mitigates merging conflicts by performing spectral truncation followed
  by nuclear norm-preserving rescaling.
---

# STAR: Spectral Truncation and Rescale for Model Merging

## Quick Facts
- arXiv ID: 2502.10339
- Source URL: https://arxiv.org/abs/2502.10339
- Reference count: 24
- Primary result: Achieves up to 4.2% better normalized performance than baselines when merging 12 models

## Executive Summary
Model merging faces performance degradation as the number of fine-tuned models increases, limiting practical multi-task deployment. This work introduces STAR, which mitigates merging conflicts by performing spectral truncation followed by nuclear norm-preserving rescaling. Specifically, task vectors are decomposed via SVD, small singular components are truncated to reduce redundancy, and singular values are rescaled to retain the original matrix "size." STAR requires no training data or fine-tuning and is robust to hyperparameter choice. Across extensive experiments on Flan-T5-base/large and Mistral-7B-Instruct with up to 20 models, STAR consistently outperforms existing data-free methods.

## Method Summary
STAR is a data-free multi-task model merging technique that operates on task vectors (fine-tuned weights minus pretrained weights). For each task vector matrix, it performs SVD decomposition, truncates small singular values to reduce conflicts between tasks, and rescales remaining singular values to preserve the original nuclear norm. The method adaptively determines truncation rank based on cumulative energy thresholds and averages the reconstructed matrices across tasks before adding to the pretrained model. This spectral approach aims to reduce interference while maintaining sufficient update magnitude for task performance.

## Key Results
- STAR outperforms existing data-free methods across multiple experiments
- Achieves up to 4.2% better normalized performance when merging 12 models
- Maintains effectiveness across varying model sizes (Flan-T5-base/large and Mistral-7B-Instruct)
- Demonstrates stability with up to 20 merged models

## Why This Works (Mechanism)

### Mechanism 1: Spectral Truncation for Conflict Minimization
Transforming task vectors into spectral space and truncating small singular values reduces interference between tasks during merging. Task vectors are decomposed using SVD, and retaining only top singular values filters out dimensions that destructively interfere with other tasks. The paper proves that truncating task vector B to rank-r reduces the upper bound of conflict by $(r_B - r)\beta\sqrt{r_A}$.

### Mechanism 2: Nuclear Norm Restoration for Signal Compensation
Rescaling remaining singular values to match the original matrix nuclear norm prevents performance degradation from parameter reduction. Truncation inherently reduces the "volume" of the task vector, and compensation by upscaling remaining singular values ensures the merged update maintains intended magnitude relative to the pretrained model.

### Mechanism 3: Adaptive Layer-Specific Truncation
Performance improves when truncation thresholds adapt automatically to specific singular value distributions of each layer and task. Using hyperparameter $\eta$ to define cumulative energy thresholds allows different effective ranks for different parts of the model, since layers have varying variance distributions.

## Foundational Learning

- **Task Arithmetic**: Essential for understanding STAR's input/output and task vector definition. Quick check: If you have a pretrained model and a fine-tuned model, how do you derive the "task vector" that STAR will decompose?

- **Singular Value Decomposition (SVD) & Nuclear Norm**: Core to understanding the spectral space manipulation. Quick check: After truncating small singular values, why does the "size" (Nuclear Norm) of the matrix decrease, necessitating the rescale step?

- **Model Merging Conflicts (Interference)**: Motivates the entire method. Quick check: Why does naively averaging the weights of two fine-tuned models often yield worse performance than using either model individually?

## Architecture Onboarding

- **Component map**: Pretrained Checkpoint -> Delta Extraction -> Spectral Decomposer -> Adaptive Rank Selector -> Rescaler -> Merger

- **Critical path**: The Rescaler logic is most distinct, using formula $\sigma'_k = \frac{\|\sigma\|_1}{\|\sigma_{1:r}\|_1} \cdot \sigma_k$ to preserve vector magnitude. Implementation errors here will break the data-free benefit.

- **Design tradeoffs**: Requires SVD computation for all task vectors (expensive for huge models), uses global hyperparameter $\eta$ that might be blunt for mixed task complexity, and treats all tasks with equal priority after truncation.

- **Failure signatures**: Rank collapse if $\eta$ too low, amplification artifacts if rescaling factor is huge, or same performance as baseline if $\eta$ effectively 100%.

- **First 3 experiments**:
  1. Sanity Check: Merge 2-3 Flan-T5 models using STAR with $\eta=40$ and compare against "Simple Averaging"
  2. Ablation: Run STAR with and without nuclear norm rescaling step
  3. Scalability Test: Merge 10+ models and measure performance degradation rate vs TIES or MetaGPT

## Open Questions the Paper Calls Out
None

## Limitations
- Generalization across architectures limited to transformer-based models, lacking validation on CNNs or non-NLP domains
- Single global $\eta$ parameter may be suboptimal for merging tasks with vastly different complexity levels
- Computational overhead from SVD computation for every weight matrix across all task vectors, particularly for large-scale models

## Confidence

**High Confidence**: Core mathematical claims regarding spectral truncation and nuclear norm preservation are sound and well-supported by proofs in the appendix. Empirical results showing STAR outperforming baselines on Flan-T5-base/large and Mistral-7B are robust.

**Medium Confidence**: Architecture-agnostic claims supported by two transformer architectures but lack non-transformer validation. "Robust to hyperparameter choice" demonstrated within reasonable range but not at extremes.

**Low Confidence**: Theoretical upper bound assumes independence between task vectors and uniform singular value distribution. Nuclear norm preservation mechanism lacks rigorous theoretical justification beyond empirical observation.

## Next Checks

1. **Architecture Transferability Test**: Apply STAR to merge fine-tuned ResNet variants on computer vision tasks and compare against Task Arithmetic baselines to validate architecture-agnostic properties beyond transformers.

2. **Extreme Scale Merging**: Conduct experiments merging 50+ task vectors to identify breaking points where spectral decomposition becomes unstable, measuring whether 4.2% performance advantage scales or degrades.

3. **Hyperparameter Sensitivity Analysis**: Systematically vary $\eta$ from 10% to 90% across different task complexity combinations to determine whether a single global parameter remains optimal or if task-weighted $\eta$ values would improve heterogeneous merging scenarios.