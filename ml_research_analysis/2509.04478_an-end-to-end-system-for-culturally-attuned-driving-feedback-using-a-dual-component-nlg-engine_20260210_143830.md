---
ver: rpa2
title: An End-to-End System for Culturally-Attuned Driving Feedback using a Dual-Component
  NLG Engine
arxiv_id: '2509.04478'
source_url: https://arxiv.org/abs/2509.04478
tags:
- system
- driving
- feedback
- behaviour
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper describes an end-to-end mobile system delivering culturally-attuned
  safe driving feedback in Nigeria using a dual-component NLG engine. The system combines
  a legally-grounded, retrieval-augmented pipeline for generating factual safety tips
  and a psychologically-grounded, two-step reflective pipeline for generating persuasive
  behavioural reports, leveraging the Theory of Planned Behaviour.
---

# An End-to-End System for Culturally-Attuned Driving Feedback using a Dual-Component NLG Engine

## Quick Facts
- arXiv ID: 2509.04478
- Source URL: https://arxiv.org/abs/2509.04478
- Reference count: 18
- 100% recall alcohol detection model with <50ms inference on mid-range Android

## Executive Summary
This paper presents an Android-based system delivering culturally-attuned safe driving feedback in Nigeria using a dual-component Natural Language Generation (NLG) engine. The system combines a legally-grounded, retrieval-augmented pipeline for generating factual safety tips from the Nigerian Highway Code with a psychologically-grounded, two-step reflective pipeline for generating persuasive behavioral reports. A pilot deployment with 90 drivers collected over 2 million data points, logging 154,230 unsafe events, with harsh acceleration (46.1%) and speeding (29.5%) most frequent. The architecture emphasizes local-first processing for robustness against intermittent connectivity and noisy sensor data.

## Method Summary
The system uses rule-based detection with dynamic thresholds for real-time event monitoring and an ONNX-compiled Decision Tree classifier (5 features: mean hour, day of week, std dev of speed, std dev of course, mean Y-axis acceleration) for alcohol-influenced driving detection. NLG pipelines include a keyword-based retrieval-augmented generation (NRAG) component that maps detected behaviors to pre-defined sections of a local JSON file containing the Nigerian Highway Code, and a two-step reflective pipeline using gpt-4-turbo for initial drafting and gpt-4o-mini for refinement with Theory of Planned Behaviour grounding. The architecture prioritizes local processing with cloud NLG calls only when connectivity is available.

## Key Results
- Alcohol detection model achieves 100% recall with <50ms inference on mid-range Android device
- Harsh acceleration detected in 46.1% of unsafe events, speeding in 29.5%, harsh braking in 18.3%, swerving in 6.1%
- Pilot collected over 2 million data points from 90 drivers
- System engineered for robustness against intermittent connectivity and noisy sensor data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The two-step reflective NLG pipeline reduces factual inconsistency in generated behavioral reports.
- Mechanism: A high-capacity model (GPT-4-turbo) generates an initial draft from driver statistics and TPB-grounded instructions; a smaller model (GPT-4o-mini) refines it with explicit correction instructions. This separates creative generation from verification, limiting hallucination propagation.
- Core assumption: The refinement model can reliably detect and correct factual errors without introducing new ones; the cost-quality tradeoff favors this hybrid over using the larger model for both stages.
- Evidence anchors: [abstract] "a psychologically-grounded, two-step reflective pipeline for generating persuasive behavioural reports"; [section III.C.2] "This process was designed to mitigate known failure modes of LLMs, namely factual inconsistency... ensuring the final report is factually consistent and adheres to the desired supportive tone."
- Break condition: If the refinement model lacks domain knowledge to validate numeric claims (e.g., misinterpreting event frequencies), corrections may be wrong or surface-level only.

### Mechanism 2
- Claim: Keyword-based retrieval for legal safety tips guarantees 100% factual grounding compared to semantic search.
- Mechanism: Detected behaviors map directly to predefined JSON sections of the Nigerian Highway Code via exact keyword matching. Retrieved text is injected into an LLM prompt that is instructed to generate concise safety tips grounded only in that content.
- Core assumption: The keyword-to-regulation mapping is complete and unambiguous for all detected unsafe behaviors; LLMs will not hallucinate beyond the provided legal context.
- Evidence anchors: [section III.C.1] "Our keyword-based approach guarantees 100% factual grounding and explainability by mapping a detected behaviour directly to a pre-defined section of a local JSON file containing the Nigerian Highway Code."
- Break condition: If a detected behavior has no exact keyword match or the Highway Code lacks relevant provisions, retrieval fails or returns irrelevant content.

### Mechanism 3
- Claim: Local-first, on-device processing with debounced trip detection enables robust operation under intermittent connectivity.
- Mechanism: A foreground service with debouncing detects trip start/stop; sensor data logs to a local Room database. On-device rule-based engines and ONNX-compiled ML models process data locally. Cloud NLG calls occur only when connectivity is available; otherwise the app remains functional.
- Core assumption: Smartphone sensors provide sufficient signal quality for event detection despite device variability; users tolerate battery consumption from foreground services.
- Evidence anchors: [abstract] "automatic trip detection, on-device behaviour analysis... engineered for robustness against intermittent connectivity and noisy sensor data"; [section III.A] "This local-first architecture ensures the app is fully functional offline, preventing data loss"
- Break condition: If sensor noise exceeds adaptive thresholds or battery drain causes users to kill the foreground service, detection coverage degrades.

## Foundational Learning

- Concept: Theory of Planned Behaviour (TPB)
  - Why needed here: TPB structures persuasive feedback by targeting attitudes, subjective norms, and perceived behavioral controlâ€”the three determinants of behavioral intention. Reports leverage this to make feedback psychologically grounded rather than purely informational.
  - Quick check question: Can you explain how a feedback message targeting "perceived behavioral control" differs from one targeting "subjective norms"?

- Concept: Retrieval-Augmented Generation (RAG) and constrained generation
  - Why needed here: The NRAG component must enforce hard constraints on output to prevent legally incorrect advice. Understanding naive keyword-based RAG vs. semantic RAG is essential for the safety-critical tradeoff made here.
  - Quick check question: Why might semantic search retrieve contextually similar but legally incorrect content, and how does keyword-based retrieval prevent this?

- Concept: On-device ML inference with ONNX Runtime
  - Why needed here: The alcohol detection model (Decision Tree) runs locally on Android. Understanding ONNX model export, inference latency constraints, and feature engineering for mobile sensors is required for replicability.
  - Quick check question: What are the latency and memory constraints for running an ONNX model on a mid-range Android device, and how do they affect model complexity?

## Architecture Onboarding

- Component map:
  Foreground Service -> Data Collection Service -> Rule-Based Event Detector -> ML Alcohol Detector -> Local Storage -> (Online) NRAG Tips Pipeline & Reflective Reports Pipeline -> User

- Critical path:
  1. Trip detection triggers data collection
  2. On-trip: Rule-based detector flags unsafe events; ML model scores alcohol influence
  3. Trip end: Events aggregated; if online, NLG pipelines generate feedback; if offline, queued
  4. User receives: Immediate legal tips (NRAG) and weekly persuasive reports (Reflective)

- Design tradeoffs:
  - Keyword vs. semantic retrieval: Sacrifices flexibility for guaranteed legal correctness
  - Two-step NLG vs. single-model: Increases API cost/latency but reduces factual inconsistency risk
  - Rule-based vs. pure ML for events: Rule-based provides interpretability and low latency; ML reserved for alcohol detection where labeled data exists
  - Local-first vs. cloud-dependent: Prioritizes reliability in low-connectivity contexts at the cost of limited on-device NLG capabilities

- Failure signatures:
  - Missed trips: Debouncing too aggressive or sensor permissions denied
  - False positives on harsh events: Static thresholds not adapted to road conditions or device mounting
  - NLG timeout: Cloud API unreachable and no graceful fallback UI
  - Battery drain complaints: Foreground service not optimized (e.g., excessive sensor polling)
  - Alcohol detection errors: Feature drift if driving patterns differ from training distribution

- First 3 experiments:
  1. Threshold calibration test: Collect baseline sensor data across 5+ device models; compare fixed vs. speed-adaptive thresholds for harsh acceleration/braking against manual trip annotations to quantify false positive/negative rates
  2. NLG factual consistency audit: Generate 50 reports using the two-step pipeline; manually verify numeric claims (event counts, percentages) against raw trip data; measure error rate and categorize failure modes
  3. Offline resilience drill: Simulate network outages during 20 trips; verify trip detection, local storage, and queue-based NLG delivery upon reconnection; measure data loss rate and sync latency

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the system reduce unsafe driving behaviors?
- Basis in paper: [explicit] "When the full study period concludes, we will analyse the data for evidence of behaviour change."
- Why unresolved: Pilot tested technical viability only; pre-post intervention comparison is planned but incomplete.
- What evidence would resolve it: Paired statistical comparison (t-tests or Wilcoxon) of unsafe event frequencies between baseline and intervention periods across the 90-driver cohort.

### Open Question 2
- Question: What is the alcohol detection model's false positive rate?
- Basis in paper: [inferred] Only 100% recall is reported; precision is unaddressed despite safety-critical implications for user trust.
- Why unresolved: Design prioritized catching all impaired drivers over analyzing incorrect flags.
- What evidence would resolve it: Precision, false positive rate, and F1 score on held-out test data.

### Open Question 3
- Question: Do users perceive the feedback as culturally appropriate and persuasive?
- Basis in paper: [inferred] "Culturally-attuned" is a central design claim but no user evaluation validates this.
- Why unresolved: Semi-structured interviews and thematic analysis are planned but not yet conducted.
- What evidence would resolve it: Thematic analysis of driver interviews assessing perceived cultural relevance, clarity, and persuasiveness.

### Open Question 4
- Question: Does the alcohol detection model generalize to other Nigerian regions?
- Basis in paper: [explicit] "Future work will focus on expanding the dataset for the ML model and the geographical scope of the evaluation."
- Why unresolved: Training data limited to four cities; Nigeria's regional driving diversity may affect performance.
- What evidence would resolve it: Cross-regional validation testing on data from cities excluded from training.

## Limitations

- The two-step NLG refinement process's factual consistency gains rely on unvalidated assumptions about the refinement model's error detection capabilities
- Keyword-based RAG assumes perfect completeness of the Highway Code mapping, with no coverage analysis presented for gaps where detected behaviors lack exact regulation matches
- Sensor-based detection performance across device models is only qualitatively described without quantitative validation of false positive/negative rates

## Confidence

- **High confidence** in the alcohol detection model's reported 100% recall, given the clear technical specification (Decision Tree, 5 features, SMOTE balancing, ONNX deployment, <50ms latency)
- **Medium confidence** in the rule-based event detection performance, as threshold adaptation logic is described but not empirically validated across diverse driving contexts
- **Low confidence** in the NLG pipelines' persuasive effectiveness, since pilot deployment focused on data collection and event logging rather than measuring behavioral change or user engagement with the feedback

## Next Checks

1. Conduct a systematic audit of 100+ NLG-generated reports to measure factual consistency rates and identify common hallucination patterns in the two-step refinement pipeline
2. Perform a coverage analysis of the keyword-to-Highway-Code mapping to quantify gaps where detected behaviors lack exact regulation matches
3. Run a controlled sensor variability test across at least 5 device models under identical driving conditions to quantify false positive/negative rate differences in event detection