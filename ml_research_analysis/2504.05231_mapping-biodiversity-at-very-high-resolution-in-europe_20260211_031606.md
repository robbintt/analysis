---
ver: rpa2
title: Mapping biodiversity at very-high resolution in Europe
arxiv_id: '2504.05231'
source_url: https://arxiv.org/abs/2504.05231
tags:
- species
- habitat
- data
- maps
- biodiversity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a cascading multimodal pipeline for high-resolution
  biodiversity mapping across Europe, integrating species distribution modeling, biodiversity
  indicators, and habitat classification. The approach uses a deep-SDM model trained
  on remote sensing, climate time series, and species occurrence data at 50x50m resolution
  to predict species compositions.
---

# Mapping biodiversity at very-high resolution in Europe

## Quick Facts
- arXiv ID: 2504.05231
- Source URL: https://arxiv.org/abs/2504.05231
- Reference count: 40
- High-resolution (50×50m) biodiversity mapping across Europe using deep learning

## Executive Summary
This paper presents a cascading multimodal pipeline for high-resolution biodiversity mapping across Europe, integrating species distribution modeling, biodiversity indicators, and habitat classification. The approach uses a deep-SDM model trained on remote sensing, climate time series, and species occurrence data at 50×50m resolution to predict species compositions. These predictions are used to generate biodiversity indicator maps and classify habitats using Pl@ntBERT, a transformer-based species-to-habitat classifier. The method achieves strong performance with an AUC of 0.931 and produces continental-scale species distribution, biodiversity indicator, and habitat maps at unprecedented resolution.

## Method Summary
The method employs a multi-modal ResNet-6 architecture processing three parallel data streams: Sentinel-2 imagery, climate cubes, and Landsat time series. These are fused and passed through fully connected layers with sigmoid activation to predict species presence probabilities for 11,255 species. The model is trained on a combination of 5 million presence-only GBIF records and 90,000 presence-absence EVA records, using target-group background sampling to address spatial bias. Predictions are thresholded using conformal prediction, then aggregated to compute biodiversity indicators via Poisson binomial distributions. Habitat classification uses Pl@ntBERT, a transformer model fine-tuned to map species assemblages to EUNIS habitat types.

## Key Results
- Achieves AUC of 0.931 for species distribution modeling
- Produces continental-scale species distribution maps at 50×50m resolution
- Generates biodiversity indicator maps and EUNIS habitat classifications

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Multimodal environmental encoding captures complementary habitat suitability signals.
- **Mechanism:** Three parallel ResNet-6 branches process Sentinel-2 imagery (spatial texture), climate cubes (temporal regimes), and Landsat time series (spectral dynamics). Embeddings concatenate before classification, allowing the model to learn joint features across data modalities.
- **Core assumption:** Each modality provides non-redundant predictive information about species presence.
- **Evidence anchors:** Landsat branch alone achieves 0.920 AUC; combined model reaches 0.931, showing additive gains. FrogDeepSDM similarly uses multimodal inputs.

### Mechanism 2
- **Claim:** Target-group background sampling partially corrects spatial bias in presence-only citizen science data.
- **Mechanism:** Instead of sampling pseudo-absences uniformly across space, the model restricts background sampling to grid cells with at least one recorded species.
- **Core assumption:** Surveyed-but-unoccupied locations are ecologically more informative than random locations.
- **Evidence anchors:** Applied to partially correct sampling bias in citizen science data. BioAnalyst notes similar heterogeneity challenges.

### Mechanism 3
- **Claim:** Species-assemblage-to-habitat mapping via transformers captures interspecies dependencies better than direct remote-sensing classification.
- **Mechanism:** Pl@ntBERT treats species lists as "sentences," learning co-occurrence patterns through self-attention.
- **Core assumption:** Species composition reliably indicates habitat type even when direct habitat labels are outdated.
- **Evidence anchors:** Outperforms expert systems (+5.54%) and tabular deep learning (+1.14%). EUNIS Habitat Maps uses direct remote sensing classification.

## Foundational Learning

- **Concept: Species Distribution Modeling (SDM)**
  - Why needed here: The entire pipeline depends on accurate species presence probability estimates.
  - Quick check question: Can you explain why presence-absence surveys are more informative than presence-only records for training SDMs?

- **Concept: Poisson Binomial Distribution**
  - Why needed here: Biodiversity indicators are computed as sums of non-identical Bernoulli trials.
  - Quick check question: Why can't we use a simple binomial distribution for computing confidence intervals on species richness?

- **Concept: Conformal Prediction for Thresholding**
  - Why needed here: Converting probabilities to binary presence/absence requires calibrated thresholds.
  - Quick check question: What tradeoff does conformal prediction make between false positives and false negatives in conservation contexts?

## Architecture Onboarding

- **Component map:** [Sentinel-2] → ResNet-6 → [512-dim] → Concat → FC+Sigmoid → [11,255 species probs] → Threshold via Conformal → [Species Assemblage] → Pl@ntBERT → EUNIS Habitat

- **Critical path:** Landsat branch (highest single-modality AUC) → multimodal fusion → threshold calibration → Pl@ntBERT inference. Errors in Landsat processing propagate through entire pipeline.

- **Design tradeoffs:** 50×50m resolution vs. 10×10m Sentinel native for computational tractability. F-score (0.338) sacrificed for recall. EUNIS Level 3 (45% accuracy) vs. Level 1 (76%).

- **Failure signatures:** Low F-score with high AUC suggests scale mismatch. Habitat accuracy drops at Level 3 indicates labeling issues. Geographic gaps indicate training data concentration.

- **First 3 experiments:**
  1. Single-modality ablation: Train ResNet-6 on each branch independently; compare AUC to identify which modality drives performance.
  2. Threshold sensitivity analysis: Vary conformal prediction confidence levels; measure precision/recall tradeoff on held-out PA plots.
  3. Spatial cross-validation: Use 10×10km block hold-out to verify model generalizes beyond training geography.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the validation methodology be adapted to bridge the scale mismatch between the predicted 50x50m grid cells and the significantly smaller ground-truth vegetation plots?
- Basis in paper: Explicitly states the relatively low F-score (0.338) is caused by the scale discrepancy between the 2,500m² predicted cells and the ~100m² test plots.
- Why unresolved: A precise evaluation at the full 2,500m² scale is currently impossible due to the extreme effort required for manual surveys.
- What evidence would resolve it: Validation against a new dataset of exhaustive species surveys conducted specifically at the model's native 50×50m resolution.

### Open Question 2
- Question: To what extent do inconsistencies in expert-labeled EUNIS habitat data constrain the performance of the Pl@ntBERT habitat classifier at Level 3?
- Basis in paper: Identifies challenges in classifying habitats at EUNIS Level 3 partly due to inconsistencies in expert-labeled training data.
- Why unresolved: Historical surveys may contain subjective or outdated habitat labels that conflict with the model's predictions.
- What evidence would resolve it: A noise-robustness study or re-evaluation using a "gold standard" dataset with verified habitat labels.

### Open Question 3
- Question: How can the pipeline be modified to capture the distribution of species that are present but remain below the probability threshold required for mapping?
- Basis in paper: Maps were generated for only 5,558 out of 11,255 species because others remained below the confidence threshold.
- Why unresolved: The current conformal prediction strategy prioritizes minimizing omission errors for detected species.
- What evidence would resolve it: A sensitivity analysis comparing predicted species assemblages against high-density local inventories to measure the false negative rate for rare species.

## Limitations
- Cascading pipeline design introduces compounding uncertainty where SDM errors propagate to habitat classification
- Geographic coverage gaps exist where PA data is sparse, creating potential blind spots in habitat classification
- Computational demands (15TB of processed data) and technical complexity make reproduction challenging

## Confidence

- **High Confidence**: Multimodal feature extraction improves species distribution modeling (AUC: 0.931, up from 0.920 for Landsat alone)
- **Medium Confidence**: Target-group background sampling effectively reduces spatial bias
- **Medium Confidence**: Species-assemblage-to-habitat mapping via Pl@ntBERT outperforms traditional approaches (+5.54%)

## Next Checks
1. Apply the trained model to regions outside the training geography and validate predictions against independent PA surveys
2. Systematically vary the conformal prediction threshold and measure the precision-recall tradeoff on held-out validation data
3. Conduct systematic ablation studies removing each environmental modality to quantify their independent contributions