---
ver: rpa2
title: Solving Semi-Supervised Few-Shot Learning from an Auto-Annotation Perspective
arxiv_id: '2512.10244'
source_url: https://arxiv.org/abs/2512.10244
tags:
- data
- learning
- temperature
- unlabeled
- few-shot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Semi-supervised few-shot learning (SSFSL) aims to learn models
  from a few labeled examples and many unlabeled ones, addressing real-world auto-annotation
  tasks. However, directly applying established semi-supervised learning methods to
  finetune vision-language models (VLMs) significantly underperforms few-shot learning
  baselines due to VLMs producing "flat" softmax probability distributions, leading
  to zero utilization of unlabeled data and weak supervision signals.
---

# Solving Semi-Supervised Few-Shoot Learning from an Auto-Annotation Perspective

## Quick Facts
- **arXiv ID:** 2512.10244
- **Source URL:** https://arxiv.org/abs/2512.10244
- **Reference count:** 40
- **Primary result:** SWIFT outperforms recent few-shot and semi-supervised learning methods by approximately 5 accuracy points on five SSFSL benchmarks.

## Executive Summary
Semi-supervised few-shot learning (SSFSL) aims to learn models from limited labeled examples and abundant unlabeled data. However, directly applying standard semi-supervised learning methods to vision-language models (VLMs) fails because VLMs produce "flat" softmax probability distributions, resulting in zero utilization of unlabeled data. This paper identifies this root cause and introduces simple yet effective solutions: classifier initialization using text embeddings and temperature tuning to increase pseudo-label confidence scores. Building on these insights, the authors propose SWIFT (Stage-Wise Finetuning with Temperature Tuning), which successfully finetunes VLMs using limited labeled data, abundant unlabeled data, and noisy retrieved data. Extensive experiments show SWIFT outperforms recent methods by approximately 5 accuracy points and even rivals fully supervised learning.

## Method Summary
SWIFT addresses the failure of VLMs in semi-supervised few-shot learning through a three-stage finetuning pipeline. The method uses classifier initialization with text embeddings of class names (instead of random weights) and applies temperature tuning to both confidence thresholds and loss functions. Stage 1 initializes the classifier with text embeddings while freezing the encoder. Stage 2 performs SSL finetuning using FixMatch/DebiasPL with temperature-tuned confidence thresholds (T_conf=0.01) and learnable loss temperature (T_loss=0.07), incorporating labeled, unlabeled, and retrieved noisy data. Stage 3 adapts the model to the target domain by finetuning on labeled data only. The approach successfully leverages unlabeled and retrieved data, achieving state-of-the-art performance on five fine-grained datasets.

## Key Results
- SWIFT outperforms recent few-shot learning and semi-supervised learning methods by approximately 5 accuracy points
- SWIFT rivals fully supervised learning, which finetunes VLMs with ground-truth labels on both labeled and unlabeled data
- The proposed temperature tuning (T_conf=0.01) increases pseudo-label utilization from 0% to over 50% on benchmark datasets
- Classifier initialization with text embeddings provides a 14-point accuracy gain in 4-shot settings compared to random initialization

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** VLMs produce "flat" softmax probability distributions, causing standard SSL methods to fail due to zero utilization of unlabeled data. Temperature tuning (T_conf < 1.0) sharpens these distributions, enabling pseudo-label selection.
- **Mechanism:** VLMs pre-trained with contrastive loss produce logits with small magnitudes. Softmax converts these to low-confidence scores, preventing selection by high-threshold SSL methods. Dividing logits by small temperature T_conf sharpens the distribution, pushing confident predictions above selection thresholds.
- **Core assumption:** Visual features in VLM latent space are semantically meaningful; the bottleneck is probability calibration, not feature quality.
- **Evidence anchors:** Abstract states VLMs produce "flat" distributions resulting in zero utilization; section 3.1 identifies this as the root cause; corpus evidence is limited to prompt tuning approaches rather than logit scaling.
- **Break condition:** If VLM features are fundamentally misaligned with downstream task (excessive domain shift), sharpening amplifies noise and causes model collapse.

### Mechanism 2
- **Claim:** Learnable loss temperature (T_loss) amplifies supervision signals, accelerating VLM convergence during finetuning.
- **Mechanism:** Lower temperature in cross-entropy loss increases gradient magnitude for confident predictions. In low-data regimes, standard losses yield weak gradients. Tuning T_loss (initialized to 0.07) increases loss landscape "slope," providing stronger learning signals from limited labeled and pseudo-labeled data.
- **Core assumption:** Model benefits from stronger gradients because it's already near a good solution via pretraining and needs stronger push to fit downstream distribution.
- **Evidence anchors:** Section 3.2 describes applying T_loss to strengthen supervision; Figure 6 shows faster training loss decrease and test accuracy rise with T_loss tuning versus fixed tau=1.0.
- **Break condition:** If T_loss is too low, model overfits quickly to noisy pseudo-labels or small labeled set, losing generalization.

### Mechanism 3
- **Claim:** Initializing classifier with text embeddings of class names leverages VLM's semantic alignment to overcome weak supervision of few-shot data.
- **Mechanism:** Standard SSL initializes classifiers randomly. In few-shot settings, learning projection from visual features to random weights from scratch is difficult. Initializing classifier weights W with VLM's text encoder outputs T(y) starts with zero-shot classifier already aligned with visual and textual concepts.
- **Core assumption:** Class names are descriptive enough for VLM's text encoder to create discriminative embeddings.
- **Evidence anchors:** Section 3.2 explains initializing classifier weights with text embeddings; Table 5 shows significant jump (approx +14 points in 4-shot) when moving from random to text initialization.
- **Break condition:** If downstream task involves polysemous or linguistically ambiguous classes without context, text embeddings may overlap and fail to provide discriminative initialization.

## Foundational Learning

- **Concept: Softmax Temperature Scaling**
  - **Why needed here:** Central fix proposed in paper. Softmax is S(q_i) = e^(q_i/T) / Î£ e^(q_j/T). Changing T changes output distribution entropy.
  - **Quick check question:** If model outputs logits [1.0, 0.8, 0.5], does dividing by T=0.1 make resulting probability distribution flatter or sharper?

- **Concept: Semi-Supervised Learning (Pseudo-Labeling)**
  - **Why needed here:** Paper builds upon FixMatch. SSL uses teacher model (or model itself) to label unlabeled data, typically only using "high confidence" predictions to avoid label noise.
  - **Quick check question:** Why might "flat" probability distribution ([0.34, 0.33, 0.33]) prevent standard pseudo-labeling algorithm from using unlabeled image?

- **Concept: Vision-Language Models (CLIP/OpenCLIP)**
  - **Why needed here:** Failure mode specific to VLMs pre-trained with contrastive loss (InfoNCE), producing different logit distributions than standard Cross-Entropy pre-trained models.
  - **Quick check question:** How are logits typically calculated in VLM like CLIP during zero-shot inference? (Hint: involves cosine similarity and temperature parameter).

## Architecture Onboarding

- **Component map:** Encoder (VLM visual backbone) -> Classifier (linear layer with text embeddings) -> Temperatures (T_conf fixed at 0.01, T_loss learnable starting at 0.07) -> Data Streams (Labeled L, Unlabeled U, Retrieved Noisy R)

- **Critical path:**
  1. **Stage 1 (Classifier Init):** Freeze Encoder. Initialize W with text embeddings. Train W on L using CE loss with T_loss (50 epochs).
  2. **Stage 2 (SSL Finetune):** Unfreeze Encoder. Train on L and U (via FixMatch logic). Select pseudo-labels from U using T_conf. Train using T_loss. Optionally include Retrieved R.
  3. **Stage 3 (Target Adapt):** Finetune Encoder and Classifier on L only (to re-center on target domain after Stage 2).

- **Design tradeoffs:**
  - **Using Retrieved Data (R):** Boosts performance significantly (+5-10%) but introduces label noise and domain shift. Stage 3 critical to mitigate this.
  - **Learnable vs. Fixed Temperature:** Fixed T_conf for stability in selection; learns T_loss for adaptive gradient scaling.
  - **Eschewing Validation Set:** Design assumes standard hyperparameters work, simplifying deployment but risking failure on unique datasets.

- **Failure signatures:**
  - **Zero Utilization:** Unlabeled data count remains 0 throughout training. *Diagnosis:* T_conf too high or model not outputting logits with sufficient variance.
  - **Performance Drop vs. Baseline:** Adding unlabeled data makes accuracy worse than supervised few-shot. *Diagnosis:* Confirmation bias from low-confidence pseudo-labels (Temperature Tuning likely skipped).
  - **Slow Convergence:** Training loss hovers. *Diagnosis:* T_loss too high (close to 1.0), gradients too weak.

- **First 3 experiments:**
  1. **Verify Flat Distribution:** Run forward pass on unlabeled data with vanilla VLM. Plot histogram of max-softmax probabilities. Confirm clustered near 1/C (flat) rather than near 1.0.
  2. **Sanity Check (TT):** Apply proposed Temperature Tuning (T_conf=0.01, T_loss=0.07) on single dataset (e.g., semi-Aves). Verify "Utilization Rate" jumps from ~0% to >50%.
  3. **Ablation (Stage 1):** Compare random classifier initialization vs. Text-Embedding initialization on 4-shot setting to validate "weak supervision" hypothesis.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can unlabeled and retrieved data be effectively leveraged to automatically tune hyperparameters and temperature in a validation-free setup? Section 5 states unlabeled and retrieved data could potentially be leveraged for tuning hyperparameters and temperature. This remains unresolved as current method relies on cross-dataset tuning or fixed values to avoid validation sets, leaving potential of using abundant unlabeled/retrieved data for self-calibration unexplored.

- **Open Question 2:** How does SWIFT perform on datasets exhibiting severe, natural class imbalances typical of real-world "auto-annotation" tasks? Section 5 notes that datasets used in experiments "do not fully capture natural class imbalances in the real world." This remains unresolved as current benchmarks are relatively balanced; unknown if Stage-Wise Finetuning or Temperature Tuning exacerbates or mitigates bias against minority classes when unlabeled data is imbalanced.

- **Open Question 3:** Can SWIFT pipeline generalize to diverse SSL algorithms beyond FixMatch and DebiasPL? Section 5 states while SWIFT is general, "we have not tested it on all methods. We leave this for future work." This remains unresolved as interaction between complex SSL strategies (e.g., curriculum pseudo-labeling or negative learning) and VLM-specific issues like "flat" softmax distributions remains unverified.

## Limitations

- Results heavily rely on specific VLM architectures (CLIP/OpenCLIP) and may not generalize to other pre-training paradigms
- Reliance on retrieved noisy data introduces additional complexity and potential for error that is partially mitigated but not eliminated by Stage 3
- Claim that SWIFT rivals fully supervised learning requires careful interpretation - it's relative comparison within VLM finetuning paradigm, not absolute claim about surpassing all possible supervised approaches

## Confidence

- **High:** Core insight about flat softmax distributions in VLMs and effectiveness of temperature tuning for pseudo-label selection
- **Medium:** Specific hyperparameter choices (T_conf=0.01, T_loss=0.07) and Stage 3 adaptation procedure, which are effective but may not be universally optimal
- **Low:** Generalizability of results to non-fine-grained datasets or VLMs pre-trained with objectives other than contrastive loss

## Next Checks

1. **Domain Shift Test:** Evaluate SWIFT on dataset with significant domain shift from VLM's pretraining data (e.g., medical images or satellite imagery) to test limits of "flat distribution" assumption

2. **VLM Architecture Ablation:** Test temperature tuning approach on VLM pre-trained with different objective (e.g., masked language modeling) to determine if failure mode is universal

3. **Hyperparameter Robustness:** Systematically vary T_conf and T_loss across wider range to create sensitivity map and identify if current values are locally optimal or part of broader plateau of effective configurations