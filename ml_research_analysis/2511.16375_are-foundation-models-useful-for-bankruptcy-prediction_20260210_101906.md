---
ver: rpa2
title: Are Foundation Models Useful for Bankruptcy Prediction?
arxiv_id: '2511.16375'
source_url: https://arxiv.org/abs/2511.16375
tags:
- assets
- total
- prediction
- financial
- liabilities
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study systematically evaluates foundation models for corporate\
  \ bankruptcy prediction, comparing Llama-3.3-70B-Instruct and TabPFN against classical\
  \ ML methods on a large dataset of over one million company records from the Visegr\xE1\
  d Group. Foundation models consistently underperform established approaches like\
  \ XGBoost and CatBoost across all prediction horizons."
---

# Are Foundation Models Useful for Bankruptcy Prediction?

## Quick Facts
- arXiv ID: 2511.16375
- Source URL: https://arxiv.org/abs/2511.16375
- Authors: Marcin Kostrzewa; Oleksii Furman; Roman Furman; Sebastian Tomczak; Maciej Zięba
- Reference count: 39
- Primary result: Foundation models consistently underperform classical ML methods like XGBoost and CatBoost on bankruptcy prediction across all horizons

## Executive Summary
This study systematically evaluates foundation models for corporate bankruptcy prediction, comparing Llama-3.3-70B-Instruct and TabPFN against classical ML methods on a large dataset of over one million company records from the Visegrád Group. Foundation models consistently underperform established approaches like XGBoost and CatBoost across all prediction horizons. LLM-based methods produce unreliable probability estimates that cluster around discrete values rather than providing calibrated risk assessments. While TabPFN shows competitive F1-scores, it requires substantial computational resources and underperforms on ROC-AUC metrics. Classical methods maintain ROC-AUC scores above 0.85 even at four-year prediction horizons, while foundation models struggle with accuracy, computational efficiency, and probability calibration, demonstrating that specialized ML approaches remain superior for structured financial prediction tasks.

## Method Summary
The study evaluates 7 models (XGBoost, CatBoost, LightGBM, MLP, LR, TabPFN-DT, Llama-3.3-Instruct with zero-shot/ICL variants) on bankruptcy prediction at 5 horizons (h=0 to h=4 years ahead) using ~1.1M company-year records from the Visegrád Group. The dataset contains 131 financial features and shows <1% bankruptcy rate. Models are evaluated on ROC-AUC and F1-score with threshold calibration on validation data. TabPFN uses decision tree partitioning for large datasets, while LLMs serialize features into text prompts with in-context learning using 20 examples. All classical methods use random_state=42.

## Key Results
- Foundation models consistently underperform classical ML methods like XGBoost and CatBoost across all prediction horizons
- LLM-based approaches suffer from unreliable probability estimates that cluster around fixed values (0.1, 0.2, 0.7, 0.9) rather than providing smooth distributions
- TabPFN shows competitive F1-scores but requires substantial computational resources and underperforms on ROC-AUC metrics
- Classical methods maintain ROC-AUC scores above 0.85 even at four-year prediction horizons, while foundation models struggle with accuracy, computational efficiency, and probability calibration

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Gradient boosting methods outperform foundation models on structured financial tabular data due to inductive bias alignment with heterogeneous feature interactions.
- Mechanism: XGBoost and CatBoost explicitly model non-linear interactions and handle mixed feature types (categorical + continuous) through tree-based partitioning, which matches the structure of financial ratios. Foundation models trained on general text or synthetic tabular data lack this domain-specific inductive bias.
- Core assumption: Bankruptcy signals emerge from specific financial ratio thresholds and interactions rather than generalizable patterns across domains.
- Evidence anchors:
  - [abstract] "models such as XGBoost and CatBoost consistently outperform foundation models across all prediction horizons"
  - [section 4, Table 2] XGBoost achieves 0.891 ROC-AUC at h=4 vs. TabPFN 0.771 and Llama-3.3 0.782
  - [corpus] Related work shows TabPFN succeeds in other domains (crop yield, Alzheimer's prediction), suggesting the issue is domain-specific rather than architectural
- Break condition: If financial data were primarily textual or if domain-specific pre-training were available for foundation models, this mechanism would weaken.

### Mechanism 2
- Claim: LLM probability estimates fail calibration because text-to-probability conversion produces discretized outputs rather than continuous distributions.
- Mechanism: When prompted to output probabilities, LLMs generate token sequences that map to a limited vocabulary of numeric representations. The model learns to output "safe" probability values from training data distributions rather than calibrated estimates based on input features.
- Core assumption: The discretization pattern (0.1, 0.2, 0.7, 0.9) reflects tokenization constraints and training data patterns rather than true uncertainty quantification.
- Evidence anchors:
  - [abstract] "LLM-based approaches suffer from unreliable probability estimates, undermining their use in risk-sensitive financial settings"
  - [section 4, Figure 1] "model outputs cluster around fixed values (0.1, 0.2, 0.7, 0.9) rather than providing smooth probability distributions"
  - [corpus] Weak direct evidence for this mechanism in related work; this appears to be a novel finding
- Break condition: If logit-based access to model internals were available (as noted in section 5 limitations), or if calibration techniques like temperature scaling were applied, this mechanism might partially resolve.

### Mechanism 3
- Claim: TabPFN's computational overhead without performance gains stems from architecture mismatch with large-scale tabular data requirements.
- Mechanism: TabPFN is optimized for datasets under 10,000 samples with in-context learning. The partition-then-predict workaround required for larger datasets (decision tree partitioning or bootstrap ensembles) introduces complexity that negates the zero-shot benefits while adding substantial GPU memory requirements.
- Core assumption: The performance gap reflects TabPFN's design constraints rather than fundamental limitations of transformer architectures on tabular data.
- Evidence anchors:
  - [section 3.2] "TabPFN is optimized for datasets under 10,000 samples while our datasets contain hundreds of thousands of records"
  - [section 4, Table 3] TabPFN processes 844.77 samples/s vs. XGBoost's 2,833,570.17 samples/s (3,350x slower)
  - [corpus] TabPFN-2.5 (arxiv 2511.08667) addresses scalability for datasets up to 50,000 samples, suggesting this is a recognized limitation
- Break condition: If native large-scale TabPFN variants or more efficient partitioning strategies were developed, this computational penalty would decrease.

## Foundational Learning

- Concept: **Class imbalance handling in financial prediction**
  - Why needed here: Bankruptcy rates are below 1% (Table 1 shows 3,587 bankruptcies in 1,000,087 records for h=0), making F1-score more informative than accuracy.
  - Quick check question: Can you explain why accuracy is misleading when bankruptcy occurs in <1% of samples?

- Concept: **Probability calibration for risk assessment**
  - Why needed here: Financial applications require reliable probability estimates for portfolio risk management; discretized probabilities (Figure 1) make risk quantification impossible.
  - Quick check question: What is the difference between a well-calibrated probability (0.15 = 15% actual default rate) and a discriminative but uncalibrated score?

- Concept: **Prediction horizon decay in forecasting**
  - Why needed here: Performance degrades from h=0 (ROC-AUC 0.996) to h=4 (ROC-AUC 0.891 for XGBoost), affecting deployment decisions about how far ahead to predict.
  - Quick check question: Why would a 4-year-ahead bankruptcy prediction be fundamentally harder than a 1-year-ahead prediction?

## Architecture Onboarding

- Component map: 131 financial features → median imputation → standardization → label encoding for categorical variables → 7 models tested (XGBoost, CatBoost, LightGBM, MLP, LR, TabPFN-DT, Llama-3.3 with zero-shot/ICL variants) → stratified 20,000-sample test set → threshold calibration on validation data maximizing F1-score

- Critical path:
  1. Feature engineering (131 financial ratios including sector-relative indicators)
  2. Threshold calibration (F1-maximizing threshold on validation set)
  3. Multi-horizon evaluation (h=0,1,2,3,4 years ahead)

- Design tradeoffs:
  - **TabPFN-DT vs TabPFN-Ensemble**: DT achieves 0.771 ROC-AUC/0.024 F1 vs Ensemble-24's 0.814/0.013 (section C.2, Table 5) — ensemble improves ROC-AUC at F1 cost
  - **In-context learning vs zero-shot for LLMs**: ICL uses 20 examples (10 positive, 10 negative, selected as "hard" samples by XGBoost proxy) — adds computational overhead without consistent gains
  - **F1-optimization vs ROC-AUC optimization**: Paper prioritizes F1 due to class imbalance, but this may mask poor probability calibration

- Failure signatures:
  - **Discretized probabilities**: LLM outputs cluster at fixed values → check histogram of predicted probabilities
  - **Computational bottleneck**: TabPFN requiring GPU (A100-40GB) vs XGBoost on CPU (M4 Pro) → 3,350x throughput difference
  - **Horizon-dependent degradation**: ROC-AUC drops from 0.987 to 0.771 for TabPFN (22% decline) vs 0.996 to 0.891 for XGBoost (11% decline) at h=4

- First 3 experiments:
  1. Replicate the threshold calibration protocol: train XGBoost on 80% of h=0 data, calibrate threshold on validation set to maximize F1, verify ROC-AUC >0.99 on stratified 20,000-sample test set
  2. Test probability calibration: plot histograms of XGBoost vs TabPFN vs Llama predicted probabilities on the same test samples to visualize discretization vs smooth distributions
  3. Measure computational efficiency: benchmark inference throughput (samples/second) for XGBoost (CPU), TabPFN (GPU), and LLM (API) on identical 20,000-sample batches to quantify deployment cost differences

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can advanced reasoning models (e.g., GPT-5-thinking, DeepSeek-V3.1) close the performance gap with classical gradient boosting methods for bankruptcy prediction?
- Basis in paper: [explicit] The authors explicitly state in the Limitations and Conclusion that they tested Llama-3.3-70B, and suggest that "Advanced reasoning models" or "LLMs with reasoning capabilities" may deliver stronger performance.
- Why unresolved: The study only evaluated a standard instruct model; newer architectures designed for complex reasoning were not tested.
- What evidence would resolve it: A benchmark of reasoning-capable models against the XGBoost/CatBoost baselines using the same datasets.

### Open Question 2
- Question: Does access to model weights and internal logits resolve the issue of discretized and poorly calibrated probability estimates in LLMs?
- Basis in paper: [explicit] The authors note in Section 5 that "API-level access restricts us to returned probability estimates" and suggest "direct access to weights and logits could yield more reliable probabilities."
- Why unresolved: The observed "degenerate distribution" of probabilities might be an artifact of the API output layer rather than the model's internal understanding.
- What evidence would resolve it: Comparing probability calibration of open-weights models (extracting logits) versus API-based probabilities on the same risk assessment task.

### Open Question 3
- Question: Do hybrid multimodal approaches combining textual and numerical data outperform the serialization methods used for LLMs in this study?
- Basis in paper: [explicit] The Conclusion suggests future research should explore "hybrid multimodal approaches that combine textual and numerical financial data."
- Why unresolved: The current study serialized structured data into text prompts; it did not evaluate models capable of processing numerical tables and text simultaneously in native formats.
- What evidence would resolve it: Evaluating a multimodal architecture against the serialized Llama-3.3 baseline to see if native numerical processing improves ROC-AUC.

### Open Question 4
- Question: Is the performance gap for TabPFN intrinsic to the model or a result of the "partition-then-predict" scaling strategy required for large datasets?
- Basis in paper: [inferred] While Section 3.2 mentions the partition-then-predict approach is necessary because TabPFN is optimized for small datasets, it remains untested if this partitioning strategy degrades performance compared to a theoretical native-scaling implementation.
- Why unresolved: The paper tests TabPFN *with* partitioning, but the specific impact of the decision tree partitioning on ROC-AUC performance is not isolated.
- What evidence would resolve it: Comparing the partition-then-predict approach against TabPFN's native performance on a subset of data small enough to run without partitioning to measure the approximation error.

## Limitations

- **Data access:** The proprietary EMIS database access prevents independent validation of results. Without access to the exact 131-feature dataset or the specific company-year records, exact reproduction is impossible.
- **LLM probability calibration:** The study identifies discretization in LLM probability outputs but cannot definitively attribute this to tokenization vs training data patterns due to lack of logit access. The mechanism remains partially speculative.
- **Computational comparison fairness:** TabPFN's GPU requirements (A100-40GB) vs classical methods on CPU create an uneven cost comparison that isn't fully quantified in monetary terms.

## Confidence

- **High confidence:** Foundation models underperform classical ML on bankruptcy prediction metrics (ROC-AUC, F1). The extensive empirical comparison across 7 models and 5 horizons provides robust evidence.
- **Medium confidence:** LLM probability estimates are unreliable for risk assessment. While the discretization pattern is clearly observed, the underlying mechanism requires further investigation with logit access.
- **Medium confidence:** TabPFN's computational overhead stems from architectural constraints. The evidence shows significant slowdown, but alternative implementations or newer TabPFN versions might reduce this gap.

## Next Checks

1. **Verify probability calibration mechanism:** Plot histograms of predicted probabilities for all three model families on identical test samples to confirm LLM discretization vs continuous distributions in classical methods.
2. **Benchmark computational costs:** Measure inference throughput (samples/second) and hardware costs for XGBoost (CPU), TabPFN (GPU), and LLM (API) on 20,000-sample batches to quantify deployment trade-offs.
3. **Test alternative TabPFN implementations:** Evaluate newer TabPFN-2.5 variants or different partitioning strategies on the same dataset to determine if computational bottlenecks are fundamental or implementation-specific.