---
ver: rpa2
title: Refine Knowledge of Large Language Models via Adaptive Contrastive Learning
arxiv_id: '2502.07184'
source_url: https://arxiv.org/abs/2502.07184
tags:
- knowledge
- know
- learning
- questions
- conference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the hallucination problem in large language
  models by proposing a method that helps models better recognize their knowledge
  boundaries and respond more honestly. The core idea is to imitate human learning
  processes by designing an Adaptive Contrastive Learning strategy that constructs
  different positive and negative samples based on the model's actual mastery of knowledge.
---

# Refine Knowledge of Large Language Models via Adaptive Contrastive Learning

## Quick Facts
- **arXiv ID**: 2502.07184
- **Source URL**: https://arxiv.org/abs/2502.07184
- **Reference count**: 31
- **Primary result**: Proposes Adaptive Contrastive Learning to improve LLM truthfulness by helping models better recognize knowledge boundaries, achieving significant improvements on TriviaQA and Natural Questions datasets.

## Executive Summary
This paper addresses the hallucination problem in large language models by proposing a method that helps models better recognize their knowledge boundaries and respond more honestly. The core idea is to imitate human learning processes by designing an Adaptive Contrastive Learning strategy that constructs different positive and negative samples based on the model's actual mastery of knowledge. This approach helps models consolidate correct knowledge, deepen understanding of uncertain knowledge, and forget incorrect knowledge. The method introduces two thresholds (IK and IDK) to delineate knowledge boundaries and employs adaptive loss functions for different knowledge quadrants. Experiments on TriviaQA and Natural Questions datasets demonstrate that the proposed method achieves significant improvements in Truthful Rate compared to baseline approaches, with the LLaMA-2-7B-chat model showing a 5.0% improvement over standard SFT and an additional 6.1% improvement on out-of-domain data.

## Method Summary
The method uses Adaptive Contrastive Learning to mitigate LLM hallucinations by first categorizing knowledge into four quadrants based on multi-sample response accuracy thresholds (IK and IDK). For each quadrant, different positive and negative samples are constructed: known-correct knowledge pulls correct answers closer while pushing incorrect answers away, unknown knowledge pulls "I don't know" closer while pushing hallucinations away, and uncertain knowledge consolidates knowledge boundaries. The approach employs an adaptive loss weighting mechanism that dynamically balances generation and contrastive losses using the ratio between them, preventing contrastive loss from overwhelming generation quality. The method fine-tunes models using this adaptive loss on constructed contrastive samples, helping models consolidate correct knowledge, deepen understanding of uncertain knowledge, and forget incorrect knowledge.

## Key Results
- LLaMA-2-7B-chat model shows 5.0% improvement in Truthful Rate over standard SFT on TriviaQA
- Additional 6.1% improvement on out-of-domain Natural Questions dataset
- Adaptive loss weighting and multi-threshold knowledge boundary detection significantly outperform baseline approaches
- Model demonstrates better self-awareness of knowledge boundaries, reducing hallucinations while maintaining generation quality

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Knowledge boundary delineation via multi-sample accuracy thresholds improves model self-awareness
- **Mechanism:** The method samples multiple responses per question and calculates accuracy rates. Two thresholds (IK and IDK) partition knowledge into three zones: confidently known (Acc ≥ IK), uncertain (IDK < Acc < IK), and unknown (Acc ≤ IDK). This granular classification prevents binary oversimplification of knowledge states.
- **Core assumption:** Multi-sample response accuracy correlates with actual knowledge mastery (not just surface-level pattern matching)
- **Evidence anchors:**
  - [abstract] "introduces two thresholds (IK and IDK) to delineate knowledge boundaries"
  - [section 3.1] "confidence exceeds IK, the model is deemed to fully master that knowledge... confidence below IDK indicates a lack of knowledge"
  - [corpus] Neighbor papers like CASAL show activation steering can reduce hallucinations, but this approach uses explicit thresholding instead
- **Break condition:** If response accuracy doesn't reflect genuine knowledge (e.g., lucky guesses or format-based correctness), threshold-based partitioning becomes unreliable

### Mechanism 2
- **Claim:** Quadrant-specific contrastive learning reshapes model confidence distributions
- **Mechanism:** For each quadrant, different positive/negative samples are constructed. Q1 (known-knowns): pull correct answers closer, push "I don't know" and wrong answers away. Q3 (unknown-unknowns): pull "I don't know" closer, push hallucinations away. The contrastive loss explicitly optimizes these distances in hidden state space using cosine similarity.
- **Core assumption:** Hidden state representations encode knowledge confidence in a way that contrastive learning can reshape
- **Evidence anchors:**
  - [abstract] "helps models consolidate correct knowledge, deepen understanding of uncertain knowledge, and forget incorrect knowledge"
  - [section 3.3, Eq. 1] contrastive loss formula explicitly maximizes similarity to positive samples while minimizing similarity to negatives
  - [corpus] HICD and similar contrastive decoding methods show inducing hallucinations then contrasting can reduce them; this method pre-constructs contrastive pairs
- **Break condition:** If hidden state distances don't correspond to behavioral confidence changes, contrastive optimization won't transfer to actual response patterns

### Mechanism 3
- **Claim:** Adaptive loss weighting preserves generative capability while reshaping confidence
- **Mechanism:** The combined loss (Eq. 3) uses a dynamic weight: max(λ, detach(L_gen/L_ctr)) × L_ctr. This prevents contrastive loss from overwhelming generation loss, maintaining fluency while adjusting confidence. The detach operation treats the ratio as a scalar, avoiding gradient computation through the ratio itself.
- **Core assumption:** The generation-to-contrastive loss ratio provides a reasonable dynamic scaling factor
- **Evidence anchors:**
  - [section 3.3, Eq. 3] "Li,Adap = Li,gen + max(λ, detach(Li,gen/Li,ctr))Li,ctr"
  - [Table 3] Ablation shows combining all three quadrant losses (LQ1 + LQ3 + LQ4) achieves best performance (78.2% Truthful Rate)
  - [corpus] Limited corpus evidence on adaptive loss weighting specifically; most contrastive methods use fixed weights
- **Break condition:** If loss ratio fluctuates wildly during training or if λ upper bound is hit too early, adaptive weighting may fail to balance objectives

## Foundational Learning

- **Concept: Knowledge Quadrants (Known-Knowns, Known-Unknowns, Unknown-Knowns, Unknown-Unknowns)**
  - **Why needed here:** This framework, adapted from psychology/introspection literature, maps whether the model both possesses and is aware of possessing knowledge. Understanding this 2×2 matrix is essential for grasping why different loss strategies are needed per quadrant.
  - **Quick check question:** Can you explain why a model might "not know that it knows" something, and what training signal would help move that knowledge to the "knows that it knows" quadrant?

- **Concept: Contrastive Learning in Representation Space**
  - **Why needed here:** The method uses cosine similarity between hidden states (h vectors) to define "closeness" in representation space. Understanding that contrastive learning operates on embeddings—not just token probabilities—is crucial for implementing the loss correctly.
  - **Quick check question:** If you have an anchor hidden state h_anchor, a positive h_pos, and negative h_neg, what happens to the cosine similarity values during successful contrastive training?

- **Concept: Threshold-based Knowledge Boundary Detection**
  - **Why needed here:** The IK and IDK thresholds (hyperparameters) determine which quadrant each question belongs to. Understanding how multi-sample accuracy maps to these thresholds explains the data construction pipeline.
  - **Quick check question:** If IDK=0.7 and a question achieves 65% accuracy across 10 samples, which quadrant does it belong to, and what positive/negative samples would be constructed?

## Architecture Onboarding

- **Component map:**
  Raw Q&A Dataset -> Multi-sample Response Generation (sample N=10 times per question) -> Accuracy Calculation (lexical matching against ground truth) -> Quadrant Classification (compare accuracy to IK and IDK thresholds) -> Contrastive Data Construction (positive/negative sample pairs per quadrant) -> Adaptive Contrastive Fine-tuning (combined L_gen + weighted L_ctr) -> Trained Model with refined knowledge boundaries

- **Critical path:**
  1. **Threshold tuning** (IK, IDK): Table 2 shows IDK=0.7 outperforms 0.5 and 0.9. Incorrect thresholds misclassify questions, degrading all downstream training.
  2. **Sample quality for negative instances**: Negative samples must be plausible hallucinations the model actually generates, not arbitrary wrong answers. Section 3.2.1 specifies using "incorrect answers generated by the LLM" as negatives.
  3. **Loss combination**: Table 3 shows removing any quadrant loss (LQ1, LQ3, or LQ4) reduces Truthful Rate. All three must be included.

- **Design tradeoffs:**
  - **Higher IK threshold** → stricter "known" classification → more questions treated as uncertain → higher IK-IDK rate (more refusals) but potentially lower IK-IK rate
  - **Lower IDK threshold** → broader "unknown" classification → more questions get "I don't know" training → may over-conservatize the model
  - **Sampling frequency**: More samples per question improve accuracy estimates but increase preprocessing cost
  - **Lexical matching vs. semantic evaluation**: Paper uses simple lexical matching for efficiency; semantic evaluators (e.g., LLM judges) may be more accurate but slower

- **Failure signatures:**
  - **Over-conservative model**: IK-IDK rate spikes, IK-IK rate drops → IDK threshold too high or IK threshold too low
  - **Continued hallucinations**: Low IK-IDK rate, low Truthful Rate → contrastive loss weight (λ) may be too low, or negative samples aren't representative
  - **Degraded fluency**: Generation quality drops → generation loss being overwhelmed by contrastive loss; check if λ is appropriate
  - **Poor OOD transfer**: Table 1 shows improvement on Natural Questions (OOD), but if your OOD data shows regression, the model may have overfit to TriviaQA-style questions

- **First 3 experiments:**
  1. **Threshold sweep**: Run grid search on IK ∈ {0.8, 0.9, 1.0} and IDK ∈ {0.3, 0.5, 0.7} on a validation split. Measure Truthful Rate, IK-IK, and IK-IDK. Confirm IDK=0.7 replicates paper's finding.
  2. **Loss ablation**: Train three models—(a) LQ1 only, (b) LQ1+LQ3, (c) LQ1+LQ3+LQ4. Verify that adding LQ4 (uncertain knowledge consolidation) improves IK-IK rate as shown in Table 3.
  3. **Negative sample quality test**: Compare two negative sampling strategies—(a) random incorrect answers vs. (b) model-generated hallucinations. Hypothesis: model-generated negatives should outperform based on Section 3.2's design rationale, though this isn't explicitly ablated in the paper.

## Open Questions the Paper Calls Out

- **Question:** How can the optimal values for IK and IDK thresholds be determined automatically for different model architectures and knowledge domains?
  - **Basis in paper:** [explicit] The authors state in Section 5.1 that "categorizing too many uncertain responses as 'the model does not know that it knows' can harm performance" and that the thresholds are set as hyperparameters without a principled method for selection.
  - **Why unresolved:** The paper experiments with IDK values of 0.5, 0.7, and 0.9 but does not propose a systematic approach for threshold determination across different models or domains.
  - **What evidence would resolve it:** A comparative study showing consistent threshold selection methods that generalize across model sizes (7B vs 13B) and datasets (TriviaQA vs Natural Questions vs others).

- **Question:** How can Quadrant-2 ("Known Unknowns" - knowledge models know they don't know) be effectively addressed in the contrastive learning framework?
  - **Basis in paper:** [explicit] The paper notes in Section 3.2.2 that "Quadrant-2 should contain the knowledge that models know that they don't know. Unfortunately, the initial model without our optimization does not have the ability to distinguish this kind of knowledge."
  - **Why unresolved:** The proposed method only addresses three of the four knowledge quadrants, leaving this theoretically important category unhandled.
  - **What evidence would resolve it:** An extension of the framework that successfully constructs positive/negative samples for Quadrant-2 and demonstrates improved performance in recognizing acknowledged knowledge gaps.

- **Question:** What mechanisms explain the counterintuitive increase in IK-IDK rate for IDK-SFT when combined with RAG, while IDK-Prompting and IDK-SFT-Adpt-Ctr show decreases?
  - **Basis in paper:** [explicit] Section C.3 notes that after combining with RAG, "IDK-Prompting and IDK-SFT-Adpt-Ctr show a decreasing trend in IK-IDK... while IDK-SFT shows an increasing trend in IK-IDK."
  - **Why unresolved:** The authors acknowledge this phenomenon but the explanation remains speculative, stating only that it indicates "a considerable portion of refusal-to-answer in IDK-SFT is wrong."
  - **What evidence would resolve it:** Detailed analysis of refusal patterns across methods with RAG, including categorization of correct vs. incorrect refusals and their relationship to retrieval quality.

## Limitations

- Threshold selection (IK and IDK) significantly impacts performance but exact values for main results are unclear from the paper
- The method relies on lexical matching for accuracy calculation, which may not capture semantic correctness
- Out-of-domain generalization improvements (Natural Questions) are demonstrated but may not generalize to other domains

## Confidence

- **High Confidence**: The quadrant-based framework for organizing knowledge states and the overall contrastive learning approach are well-grounded
- **Medium Confidence**: The specific threshold values (IDK=0.7) and loss weighting mechanism appear effective based on ablation studies, though exact parameters for main results are unclear
- **Low Confidence**: Generalization claims to other domains and the long-term stability of the adaptive loss mechanism during extended training

## Next Checks

1. **Threshold Sensitivity Analysis**: Systematically vary IK and IDK values across a wider range to identify optimal settings and assess sensitivity to hyperparameter choices
2. **Alternative Accuracy Metrics**: Replace lexical matching with semantic evaluation (e.g., using LLM judges) to verify that accuracy thresholds truly reflect knowledge mastery
3. **Extended OOD Testing**: Evaluate the method on multiple out-of-domain datasets beyond Natural Questions to assess true generalization capabilities and identify potential overfitting patterns