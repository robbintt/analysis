---
ver: rpa2
title: 'AMAQA: A Metadata-based QA Dataset for RAG Systems'
arxiv_id: '2505.13557'
source_url: https://arxiv.org/abs/2505.13557
tags:
- metadata
- dataset
- data
- documents
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: AMAQA is a metadata-based QA dataset for RAG systems, featuring
  1.1 million Telegram messages with metadata such as timestamps, topics, emotions,
  and toxicity labels. It includes 450 high-quality QA pairs, enabling evaluation
  of metadata-driven question answering.
---

# AMAQA: A Metadata-based QA Dataset for RAG Systems

## Quick Facts
- **arXiv ID**: 2505.13557
- **Source URL**: https://arxiv.org/abs/2505.13557
- **Reference count**: 13
- **Primary result**: Metadata integration boosts RAG accuracy from 0.12 to 0.75 using iterative context expansion

## Executive Summary
AMAQA is a metadata-based QA dataset for RAG systems featuring 1.1 million Telegram messages with rich metadata including timestamps, topics, emotions, and toxicity labels. The dataset contains 450 high-quality QA pairs specifically designed to evaluate metadata-driven question answering capabilities. The study demonstrates that leveraging metadata can significantly improve RAG system performance, with accuracy increasing from 0.12 to 0.61 using basic metadata integration and further improving to 0.75 with iterative context expansion and noise injection techniques.

## Method Summary
The AMAQA dataset was created from Telegram message data and annotated with various metadata dimensions including temporal information, topic categories, emotional content, and toxicity labels. The dataset includes 1.1 million messages paired with 450 high-quality question-answer pairs for evaluation purposes. The methodology involves extracting metadata from the Telegram messages and using this information to enhance the retrieval process in RAG systems. The study evaluates performance using iterative context expansion techniques and introduces noise injection as a method to improve robustness. All dataset components and evaluation code are made publicly available for research purposes.

## Key Results
- Metadata integration boosts RAG accuracy from 0.12 to 0.61
- Iterative context expansion with noise injection achieves 0.75 accuracy
- Dataset includes 1.1 million Telegram messages with rich metadata annotations

## Why This Works (Mechanism)
Metadata provides additional context that helps RAG systems disambiguate queries and retrieve more relevant passages. By incorporating temporal information, topic categorization, and sentiment analysis, the system can better understand the user's intent and filter search results more effectively. The iterative context expansion technique allows the system to refine its search based on initial retrieval results, while noise injection helps improve robustness by exposing the model to variations in the input data.

## Foundational Learning

**Metadata extraction**: Understanding how to extract and structure metadata from raw text data is crucial for implementing the dataset. Quick check: Verify metadata extraction pipeline on sample Telegram messages.

**RAG system architecture**: Knowledge of how RAG systems combine retrieval and generation components is essential. Quick check: Trace data flow through a basic RAG implementation.

**Context expansion techniques**: Understanding iterative refinement methods helps in replicating the accuracy improvements. Quick check: Implement basic iterative query expansion on sample data.

**Noise injection methods**: Familiarity with data augmentation techniques is needed to reproduce the reported improvements. Quick check: Apply simple noise injection to a small dataset.

## Architecture Onboarding

**Component map**: Message corpus -> Metadata extractor -> QA pair generator -> RAG retriever -> Generator -> Answer validator

**Critical path**: User query -> Metadata analysis -> Enhanced retrieval -> Context generation -> Answer synthesis

**Design tradeoffs**: Large dataset size (1.1M messages) provides rich coverage but raises privacy concerns; 450 QA pairs enable focused evaluation but may limit statistical power.

**Failure signatures**: Poor metadata quality leads to irrelevant retrievals; insufficient QA pairs may not capture edge cases; iterative expansion may overfit to specific patterns.

**First experiments**: 1) Test basic metadata integration on held-out Telegram data. 2) Implement iterative context expansion on sample queries. 3) Apply noise injection to evaluate robustness.

## Open Questions the Paper Calls Out
None identified in the provided information.

## Limitations
- Telegram message source may limit generalizability to other domains
- Small number of QA pairs (450) could constrain statistical validity
- Performance improvements may depend heavily on specific implementation details

## Confidence
- **High confidence**: Dataset creation methodology and basic metadata integration are well-established
- **Medium confidence**: Reported performance improvements are internally consistent but implementation-sensitive
- **Low confidence**: Generalizability across different domains and RAG architectures remains uncertain

## Next Checks
1. Replicate accuracy measurements on held-out Telegram messages not used in training
2. Test metadata integration approach on non-social media datasets (scientific literature, news articles)
3. Evaluate whether improvements persist with alternative RAG architectures beyond iterative context expansion