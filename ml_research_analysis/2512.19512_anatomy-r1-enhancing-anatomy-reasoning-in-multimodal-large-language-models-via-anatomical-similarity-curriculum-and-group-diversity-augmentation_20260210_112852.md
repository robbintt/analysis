---
ver: rpa2
title: 'Anatomy-R1: Enhancing Anatomy Reasoning in Multimodal Large Language Models
  via Anatomical Similarity Curriculum and Group Diversity Augmentation'
arxiv_id: '2512.19512'
source_url: https://arxiv.org/abs/2512.19512
tags:
- reasoning
- medical
- grpo
- learning
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of improving anatomical reasoning
  in multimodal large language models (MLLMs) for medical imaging tasks. The authors
  propose two methods to enhance Group Relative Policy Optimization (GRPO): Anatomical
  Similarity Curriculum Learning (ASC-Learning) and Group Diversity Question Augmentation
  (GDQA).'
---

# Anatomy-R1: Enhancing Anatomy Reasoning in Multimodal Large Language Models via Anatomical Similarity Curriculum and Group Diversity Augmentation

## Quick Facts
- arXiv ID: 2512.19512
- Source URL: https://arxiv.org/abs/2512.19512
- Reference count: 4
- Primary result: Improved anatomical reasoning in MLLMs using ASC-Learning and GDQA, achieving better Pass@1 performance on medical imaging benchmarks.

## Executive Summary
This paper addresses the challenge of improving anatomical reasoning in multimodal large language models (MLLMs) for medical imaging tasks. The authors propose two methods to enhance Group Relative Policy Optimization (GRPO): Anatomical Similarity Curriculum Learning (ASC-Learning) and Group Diversity Question Augmentation (GDQA). ASC-Learning controls task difficulty by leveraging intra-instance option similarity to enable progressive learning, while GDQA broadens reasoning pathways by transforming static prompts into semantically equivalent variants. Experiments on SGG-VQA and OmniMedVQA benchmarks demonstrate significant improvements, with the

## Method Summary
The authors propose enhancing GRPO-based anatomical reasoning in MLLMs through two complementary methods. Anatomical Similarity Curriculum Learning (ASC-Learning) computes difficulty scores based on semantic similarity between correct answers and distractors using MedCLIP embeddings, then progressively trains from low to high difficulty samples. Group Diversity Question Augmentation (GDQA) addresses GRPO convergence issues by applying semantic text rewrites and visual perturbations to prompts, ensuring diverse group outputs and preventing zero-variance advantage gradients. The framework uses Qwen2.5-VL as the base model and trains on medical imaging question-answering datasets with Pass@1 as the primary metric.

## Key Results
- Significant improvement in Pass@1 accuracy compared to standard GRPO baselines
- Successful transfer of knowledge from easy to hard anatomies through curriculum scheduling
- Prevention of advantage gradient vanishing through input-space augmentation

## Why This Works (Mechanism)

### Mechanism 1
Progressive exposure to difficulty stabilizes reinforcement learning in data-scarce medical domains. The authors propose Anatomical Similarity Curriculum Learning (ASC-Learning), which quantifies task difficulty based on the semantic similarity between the correct answer and distractors. By training on low-similarity (easy) pairs first and progressively introducing high-similarity (hard) pairs, the model avoids "uneven information gain" where early failures on complex anatomies halt convergence. Core assumption: The semantic similarity in the text embedding space (specifically MedCLIP) correlates directly with the visual or diagnostic difficulty for the model (e.g., distinguishing "gallbladder" from "cystic plate" is harder than from "abdominal wall").

### Mechanism 2
Input-space augmentation restores effective gradient updates when policy outputs collapse. The Group Diversity Question Augmentation (GDQA) addresses "advantage gradient vanishing." In GRPO, if a model generates a uniform group of incorrect responses for a hard anatomy, the group-relative advantage becomes zero, stalling training. GDQA rewrites prompts (text) and applies noise (visual) to force semantic variance in the input, ensuring the model produces diverse outputs that yield non-zero advantages. Core assumption: The rewriting operators generate "semantically equivalent" variants; if the rewriting changes the clinical intent, the reward signal becomes noisy.

### Mechanism 3
Strict single-attempt accuracy (Pass@1) is a requisite proxy for clinical reliability. Unlike standard benchmarks using Pass@k (where any of k answers may be correct), this work posits that clinical utility requires the *top* prediction to be correct. By optimizing for Pass@1, the reward structure penalizes "guessing" strategies that might inflate Pass@5 scores without ensuring trustworthy single-shot deployment. Core assumption: The evaluation environment (reward function) perfectly aligns with the clinical ground truth; otherwise, optimizing for strict accuracy might reinforce confident but incorrect "hallucinated" medical reasoning.

## Foundational Learning

- **Concept**: Group Relative Policy Optimization (GRPO)
  - **Why needed here**: This is the base optimizer (a variant of PPO). It calculates "advantage" by comparing a response's reward to the *group average* rather than an absolute critic. Understanding this is essential to see why uniform outputs (zero variance) result in zero gradients and halted learning.
  - **Quick check question**: If a model generates 5 responses with rewards [0, 0, 0, 0, 0], what is the advantage of the first response? (Answer: 0, effectively stopping updates).

- **Concept**: Curriculum Learning
  - **Why needed here**: The core contribution (ASC-Learning) is a specific flavor of curriculum learning. One must understand the general premise—that models learn better when tasks are ordered easy-to-hard—to grasp why "similarity sorting" is being used as a proxy for difficulty scheduling.
  - **Quick check question**: Why might training on "hard" examples from step 0 cause the model to converge to a local minimum or fail to converge at all?

- **Concept**: Semantic Embedding Spaces (e.g., MedCLIP)
  - **Why needed here**: The difficulty score $S(q)$ is not defined by human labels but by cosine similarity in a vector space.
  - **Quick check question**: Does "high cosine similarity" between two medical terms imply they are visually similar, functionally similar, or linguistically similar? (Hint: It usually captures linguistic/functional context, which the paper assumes correlates with diagnostic difficulty).

## Architecture Onboarding

- **Component map**: Qwen2.5-VL -> ASC-Scheduler (difficulty bins) -> GDQA-Engine (text rewriter + image perturbator) -> GRPO optimizer -> reward/eval (Pass@1 + GPT/Rule-based verifier)

- **Critical path**:
  1. **Offline Pre-processing**: Calculate $S(q)$ for all VQA pairs using MedCLIP embeddings of options; sort data into difficulty bins.
  2. **Training Loop**:
     - Sample batch from current difficulty bin.
     - Apply GDQA (rewrite prompts/transform images).
     - Generate $G$ responses per prompt.
     - Calculate rewards and Group Advantage $\hat{A}$.
     - Update policy via GRPO objective.
  3. **Curriculum Step**: Advance to higher difficulty bins as validation performance stabilizes.

- **Design tradeoffs**:
  - **Automated vs. Human Curriculum**: The authors use automated similarity ($S(q)$) to save expert annotation costs, but this risks misaligning "semantic similarity" with actual "visual discriminability."
  - **Diversity vs. Semantic Drift**: GDQA forces exploration, but aggressive rewriting could alter the clinical query (semantic drift), leading to noisy rewards.

- **Failure signatures**:
  - **Reward Plateaus**: Reward increases initially then flatlines (indicative of failing to transfer knowledge to hard anatomies—ASC may need finer bins).
  - **Zero Std Gradients**: Logs showing `std(rewards) ≈ 0` for a batch indicates GDQA is failing to induce diverse outputs (collapse).
  - **Pass@1 vs. Pass@5 Divergence**: Pass@5 rising while Pass@1 stays low indicates the model is "guessing" but lacks confidence/precision.

- **First 3 experiments**:
  1. **Baseline Verification**: Run standard GRPO (no ASC/GDQA) on the medical dataset to reproduce the "non-convergence" or "uniform response" issues described in the paper.
  2. **Ablation on Curriculum**: Train *with* GDQA but *without* ASC-Learning (random sampling) to verify if the model specifically fails on high-similarity anatomies (isolating the curriculum effect).
  3. **Difficulty Metric Validation**: Visualize the bins created by $S(q)$. Check if "High $S(q)$" pairs actually look visually confusable to a human expert, validating the core assumption of the curriculum.

## Open Questions the Paper Calls Out

### Open Question 1
Can the proposed ASC-Learning and GDQA methods resolve the convergence instabilities observed in non-anatomical medical imaging modalities, such as pathology or OCT, where GRPO has historically struggled? Basis in paper: [Explicit] The "Related Work" section explicitly states that prior work (MedVLM-R1) "faced convergence difficulties with pathology and OCT images," while the current study validates the method only on SGG-VQA and the MI-specific subset of OmniMedVQA. Why unresolved: The experimental validation is confined to anatomical/surgical datasets, leaving the specific convergence failures noted in pathology and optical coherence tomography unaddressed by the new curriculum and augmentation strategies. What evidence would resolve it: Successful application and stable convergence of the Anatomy-R1 framework on standard pathology (e.g., PathVQA) and OCT benchmarks.

### Open Question 2
How can the Anatomical Similarity Curriculum Learning (ASC-Learning) be adapted for open-ended medical dialogue tasks where explicit multiple-choice distractors are unavailable to calculate difficulty scores? Basis in paper: [Inferred] The methodology defines task difficulty $S(q)$ strictly as the maximum similarity between the correct answer and a set of distractors $D$ (Equation 4), implying a dependency on multiple-choice structures. Why unresolved: The paper does not propose an alternative metric for difficulty when the output space is generative rather than selective, limiting the curriculum's applicability to constrained QA formats. What evidence would resolve it: A reformulation of the difficulty metric using semantic uncertainty or latent space density for generative tasks, validated by curriculum learning improvements on open-ended clinical dialogue datasets.

### Open Question 3
To what extent does the semantic quality of the Group Diversity Question Augmentation (GDQA) affect training stability, and does low-quality or hallucinated augmentation degrade the policy model? Basis in paper: [Inferred] The GDQA method relies on "semantically equivalent" transformations to broaden reasoning pathways, but the paper does not analyze the impact of potential semantic drift or errors introduced by the augmentation operator $\phi(\cdot)$. Why unresolved: While the method succeeds on average, it is unclear if the reward model is robust to noisy prompts or if incorrect "semantically equivalent" variants poison the group advantage estimation. What evidence would resolve it: An ablation study introducing controlled semantic noise into the GDQA prompts to observe the threshold at which the diversity benefit is negated by noisy supervision.

## Limitations
- Curriculum metric validity: The paper assumes semantic similarity in MedCLIP embedding space directly correlates with visual diagnostic difficulty, but this relationship is not empirically validated.
- Optimization stability: While GDQA claims to prevent advantage gradient vanishing, the method's robustness across diverse anatomy types and its sensitivity to augmentation strength remain unclear.
- Clinical relevance of Pass@1: The exclusive focus on Pass@1 assumes single-attempt accuracy is the sole proxy for clinical utility, potentially overlooking scenarios where multiple plausible interpretations exist.

## Confidence
- **High confidence**: The mechanism of advantage gradient vanishing in GRPO and the need for input-space augmentation to restore learning signals is theoretically sound and well-supported by reinforcement learning literature.
- **Medium confidence**: The curriculum learning approach using embedding similarity as a difficulty proxy is reasonable but requires empirical validation that the metric captures true visual difficulty.
- **Low confidence**: The claim that Pass@1 optimization alone ensures clinical reliability is asserted but not substantiated with clinical expert evaluation or comparison to alternative reliability metrics.

## Next Checks
1. **Difficulty metric validation**: Manually review high-S(q) vs. low-S(q) pairs to verify that semantic similarity correlates with visual confusability. If the metric fails this sanity check, the curriculum may need recalibration or replacement.
2. **Ablation on Pass@1**: Test whether optimizing for Pass@1 versus Pass@5 yields different clinical outcomes by evaluating model outputs with medical experts, checking for hallucinations or unsafe recommendations.
3. **GRPO baseline reproduction**: Train the base model with standard GRPO (no ASC/GDQA) to confirm the "non-convergence" or "uniform response" failure modes described in the paper, establishing the necessity of the proposed methods.