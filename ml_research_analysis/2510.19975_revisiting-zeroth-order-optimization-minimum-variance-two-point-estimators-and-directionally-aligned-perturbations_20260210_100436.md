---
ver: rpa2
title: 'Revisiting Zeroth-Order Optimization: Minimum-Variance Two-Point Estimators
  and Directionally Aligned Perturbations'
arxiv_id: '2510.19975'
source_url: https://arxiv.org/abs/2510.19975
tags:
- gradient
- random
- optimization
- pxtq
- perturbation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of selecting optimal random perturbations
  in two-point zeroth-order optimization methods to minimize the asymptotic variance
  of gradient estimators. The authors formulate a constrained functional optimization
  problem over perturbation distributions, revealing that minimum-variance perturbations
  must either have fixed length or align directionally with the true gradient.
---

# Revisiting Zeroth-Order Optimization: Minimum-Variance Two-Point Estimators and Directionally Aligned Perturbations

## Quick Facts
- **arXiv ID**: 2510.19975
- **Source URL**: https://arxiv.org/abs/2510.19975
- **Reference count**: 40
- **Primary result**: Directionally Aligned Perturbations (DAPs) minimize the asymptotic variance of two-point zeroth-order gradient estimators by projecting random vectors onto hyperplanes defined by gradient directions.

## Executive Summary
This paper addresses the fundamental problem of selecting optimal random perturbations in two-point zeroth-order optimization methods. The authors prove that minimum-variance perturbations must either have fixed length or align directionally with the true gradient. Based on this theoretical insight, they propose Directionally Aligned Perturbations (DAPs) that adaptively focus accuracy along critical gradient directions. The method demonstrates superior performance in gradient estimation accuracy on synthetic problems and faster convergence in language model fine-tuning tasks compared to traditional methods like uniform and Gaussian perturbations.

## Method Summary
The paper formulates a constrained functional optimization problem over perturbation distributions to minimize the asymptotic variance of the two-point gradient estimator. The key innovation is DAPs, which project random vectors onto hyperplanes defined by the estimated gradient direction, ensuring perturbations are "aligned" with the true gradient magnitude. The method requires estimating a rough gradient direction first, then generating aligned perturbations for the final gradient estimate. This creates an anisotropic noise profile that offers higher accuracy along dimensions with larger gradients, effectively adapting the sampling density to the landscape geometry.

## Key Results
- DAPs achieve minimum asymptotic variance by enforcing either fixed-length perturbations or directional alignment with the gradient
- The convergence rate of SGD with minimum-variance perturbations achieves optimal dimension dependence (O(d/ε²) for non-convex)
- Empirical results show superior performance on synthetic problems with sparse gradients and faster convergence in OPT-1.3B language model fine-tuning
- DAPs demonstrate reduced variance in high-gradient directions compared to traditional isotropic perturbations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Minimizing the asymptotic variance of the two-point gradient estimator requires optimizing the fourth-order moment of the perturbation distribution.
- **Mechanism:** The paper formulates a constrained functional optimization problem over perturbation distributions V. By analyzing the expectation E[||ĝ-f||²] under the δ-unbiasedness constraint (E[vvᵀ] = δI_d), the authors prove that the error depends critically on ρ_V = E[||v||⁴]. Lower fourth-order moments directly translate to lower gradient estimation variance.
- **Core assumption:** The perturbation stepsize μ is sufficiently small such that Taylor approximation holds (μ → 0 asymptotic regime).
- **Evidence anchors:**
  - [abstract]: "...identifying the distribution of random perturbations that minimizes the estimator's asymptotic variance..."
  - [section]: Theorem 2.2 establishes the lower bound dδ²||a||² and relates it to ρ_V.
  - [corpus]: Related work "On the Optimal Construction of Unbiased Gradient Estimators" explores similar unbiased estimator constraints, supporting the focus on distribution construction.
- **Break condition:** If the perturbation distribution V has an unbounded or excessively large fourth-order moment (e.g., heavy-tailed distributions), the gradient estimator variance may destabilize convergence.

### Mechanism 2
- **Claim:** Directionally Aligned Perturbations (DAPs) achieve minimum variance by projecting random vectors onto hyperplanes defined by the gradient direction.
- **Mechanism:** Unlike fixed-length isotropic perturbations (e.g., uniform on sphere), DAPs enforce the condition (vᵀ∇f)² = δ||∇f||². This ensures the perturbation energy is "aligned" with the true gradient magnitude. In practice, this creates an anisotropic noise profile that offers higher accuracy along dimensions with larger gradients (critical directions), effectively adapting the sampling density to the landscape geometry.
- **Core assumption:** A rough estimate of the gradient is available to determine the projection hyperplane (chicken-and-egg problem solved via batch splitting).
- **Evidence anchors:**
  - [section]: Section 4.1 and Figure 2 demonstrate the anisotropic nature of DAPs and reduced variance in high-gradient directions.
  - [section]: Algorithm 1 defines the projection logic.
- **Break condition:** If the preliminary gradient estimate used for alignment is orthogonal to the true gradient or has high error, the projection will misalign the perturbation, potentially increasing error compared to isotropic methods.

### Mechanism 3
- **Claim:** Reducing estimator variance improves the sample complexity of Stochastic Gradient Descent (SGD) to optimal dimension dependence.
- **Mechanism:** The convergence bound for zeroth-order SGD (Theorem 3.1) contains terms proportional to the variance of the gradient estimator (specifically involving α_V and β_V). By satisfying the minimum-variance conditions (Theorem 2.2), the bounds tighten. Consequently, the query complexity achieves the best-known dependence on dimension d (O(d/ε²) for non-convex), matching rates typically only seen with specific fixed-length perturbations.
- **Core assumption:** The objective function is L-smooth (bounded Hessian) to control Taylor remainder terms.
- **Evidence anchors:**
  - [abstract]: "...convergence rate of SGD with minimum-variance perturbations achieves the best-known dependence on dimension d."
  - [section]: Corollary 3.2 explicitly links the minimum variance conditions to the optimal complexity bounds.
- **Break condition:** If the function is non-smooth or the Lipschitz constant L is extremely large, the Taylor approximation error (L²μ²E||v||⁴) may dominate, obscuring the benefits of variance reduction.

## Foundational Learning

- **Concept:** Two-Point Gradient Estimator
  - **Why needed here:** This is the fundamental operator being optimized. You must understand that the estimator ĝ = (f(x+μv) - f(x))/μ v approximates the gradient using finite differences along a random direction v.
  - **Quick check question:** If the perturbation stepsize μ is set too large, does the estimator error primarily stem from bias or variance? (Answer: Bias/Taylor approximation error).

- **Concept:** δ-Unbiasedness
  - **Why needed here:** This is the constraint defining the feasible set of perturbations. It guarantees E[ĝ] ≈ ∇f asymptotically. Without this, the gradient estimator would point in a systematically wrong direction.
  - **Quick check question:** Does a standard Gaussian distribution v ~ N(0, I_d) satisfy δ-unbiasedness?

- **Concept:** Fourth-Order Moments (E[||v||⁴])
  - **Why needed here:** The paper's central theoretical finding is that the estimator variance is governed by the fourth moment of the perturbation distribution, not just the second. Understanding this distinguishes DAPs and fixed-length schemes from standard Gaussian smoothing.
  - **Quick check question:** Does a Rademacher distribution have a lower fourth-order moment than a Gaussian distribution relative to its variance?

## Architecture Onboarding

- **Component map:** Rough Estimator -> Projection Operator (Algorithm 1) -> Final Estimator -> SGD Updater
- **Critical path:**
  The implementation hinges on the projection step (Algorithm 1). You cannot simply sample v from a static distribution. You must:
  1. Sample initial v_ini (e.g., Gaussian).
  2. Compute scalar projection aᵀv_ini (where a is the estimated gradient).
  3. Adjust v to satisfy aᵀv = ξ√δ||a||.

- **Design tradeoffs:**
  - **Batch Splitting:** You sacrifice half your function evaluation budget to estimate the alignment direction. If the rough estimate is poor, the subsequent DAPs are useless.
  - **Memory vs. Accuracy:** DAPs require computing and storing a full gradient estimate (size d) to define the projection plane, whereas standard ZOO (like uniform smoothing) is stateless regarding gradient storage during the query phase.
  - **Sparse Gradients:** DAPs are empirically superior for sparse gradients; they may offer marginal or negative gains on dense, noisy landscapes where directional alignment is unstable.

- **Failure signatures:**
  - **Stagnation:** If the rough gradient estimate ĝ is near zero (plateau), the projection plane is undefined or degenerate, causing numerical instability or zero-magnitude perturbations.
  - **Divergence:** If the variance of the rough estimator (first half of batch) is too high, the alignment direction is effectively random, making DAPs no better (or worse) than uniform noise.

- **First 3 experiments:**
  1. **Sanity Check (Synthetic):** Optimize a simple quadratic function f(x) = xᵀAx with varying condition numbers. Verify that DAPs converge faster than Gaussian smoothing specifically when A has sparse eigenvalues (sparse gradient structure).
  2. **Budget Ablation:** Run the OPT-1.3B fine-tuning task (as per Section 5.2) with varying batch sizes (e.g., b=2, 8, 16). Determine the minimum batch size where the benefit of DAP alignment outweighs the cost of splitting the batch for the rough estimate.
  3. **Robustness to Noise:** Add synthetic noise to the function evaluations. Test if the projection mechanism in DAPs amplifies noise (by projecting onto a noisy plane) or if the variance reduction still holds.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the necessary and sufficient conditions for a perturbation distribution to achieve minimum asymptotic variance in zeroth-order gradient estimation?
- Basis in paper: [explicit] The authors state in Section 2 that extending their derived sufficient conditions (fixed-length or directional alignment) to sufficient and necessary conditions "would be an interesting but challenging topic."
- Why unresolved: The current theoretical analysis only proves sufficiency; a mixed distribution counterexample shows the condition is not unique.
- What evidence would resolve it: A theoretical proof characterizing the complete set of distributions that achieve the variance lower bound, or a proof that the current conditions are strictly sufficient.

### Open Question 2
- Question: How does the performance of Directionally Aligned Perturbations (DAPs) degrade or improve when applied to objective functions with dense gradients?
- Basis in paper: [explicit] Appendix G (Limitations) notes that while DAPs excel with sparse gradients, "they may not perform as well when dealing with dense gradients."
- Why unresolved: The DAP mechanism inherently emphasizes critical directions; it is unclear if the estimation noise outweighs the directional benefits when gradients are uniformly distributed.
- What evidence would resolve it: Empirical benchmarks on dense regression tasks or theoretical analysis comparing DAP variance to uniform/Gaussian smoothing in isotropic gradient regimes.

### Open Question 3
- Question: Can the DAP sampling strategy be modified to reduce the memory overhead associated with storing full gradient estimates in extremely high-dimensional spaces?
- Basis in paper: [explicit] Appendix G identifies that the projection step in sampling DAPs "introduces additional memory overhead" for large d compared to simpler perturbation schemes.
- Why unresolved: The current algorithm requires calculating and storing the full estimated gradient vector ĝ(x) to generate the aligned perturbation, negating some memory benefits of zeroth-order methods.
- What evidence would resolve it: A modified DAP algorithm utilizing low-rank approximations or coordinate-wise sampling that maintains the variance reduction properties without O(d) memory storage.

## Limitations
- **Asymptotic regime dependence**: The variance minimization results hold only as μ → 0, making practical convergence guarantees contingent on careful stepsize tuning
- **Rough gradient quality**: DAPs require an accurate preliminary gradient estimate; if the rough estimate is poor, the alignment mechanism may perform worse than isotropic perturbations
- **High-dimensional stability**: While the analysis shows optimal O(d/ε²) dependence, empirical validation is limited to a single LLM fine-tuning task

## Confidence
- **High confidence** in the theoretical framework and variance minimization results. The functional optimization approach and fourth-moment analysis are mathematically rigorous and well-supported by proofs.
- **Medium confidence** in the empirical benefits of DAPs. The synthetic experiments demonstrate clear advantages for sparse gradients, but the LLM fine-tuning results show modest improvements that may depend on specific task characteristics.
- **Low confidence** in the practical superiority of DAPs over fixed-length perturbations. The paper claims better performance than uniform/radial perturbations but provides limited comparative analysis of different fixed-length schemes.

## Next Checks
1. **Batch size sensitivity**: Systematically vary the rough estimation batch size (from 1 to b) to determine the minimum requirement for DAP alignment to outperform isotropic methods
2. **Fixed-length comparison**: Implement and compare against optimal fixed-length perturbations (spherical distributions) on the same LLM fine-tuning task to quantify the claimed improvement
3. **Non-smooth test**: Evaluate DAP performance on non-smooth objectives (e.g., ReLU networks) to test the robustness of the Taylor approximation assumptions underlying the theoretical analysis