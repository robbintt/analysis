---
ver: rpa2
title: Automatic identification of diagnosis from hospital discharge letters via weakly-supervised
  Natural Language Processing
arxiv_id: '2410.15051'
source_url: https://arxiv.org/abs/2410.15051
tags:
- diagnosis
- clusters
- labels
- bronchiolitis
- bronchospasm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a weakly-supervised NLP pipeline for diagnosing
  bronchiolitis from Italian hospital discharge letters. The method extracts diagnosis-related
  sentences, uses transformer-based embeddings for clustering, and assigns weak labels
  without manual annotation.
---

# Automatic identification of diagnosis from hospital discharge letters via weakly-supervised Natural Language Processing

## Quick Facts
- **arXiv ID:** 2410.15051
- **Source URL:** https://arxiv.org/abs/2410.15051
- **Reference count:** 40
- **Primary result:** Weakly-supervised NLP pipeline for bronchiolitis diagnosis identification from Italian discharge letters, achieving AUC of 77.68% and F1-score of 78.14% without manual annotation

## Executive Summary
This study presents a weakly-supervised NLP pipeline for automatically identifying bronchiolitis diagnoses from Italian hospital discharge letters. The method extracts diagnosis-related sentences, applies transformer-based embeddings for clustering, and generates weak labels without requiring manual annotation. A transformer classifier is then trained on these automatically generated labels to classify discharge letters as bronchiolitis cases or not. The approach was evaluated on 33,176 discharge letters and achieved performance metrics approaching those of fully supervised methods, demonstrating the potential to reduce expert annotation burden while maintaining diagnostic accuracy.

## Method Summary
The pipeline employs a multi-stage approach beginning with sentence extraction from discharge letters, followed by transformer-based sentence embedding generation. These embeddings are clustered to identify diagnosis-related sentences, which are then used to generate weak labels through unsupervised clustering. A transformer-based classifier is trained on these weak labels to predict bronchiolitis diagnoses. The method leverages the inherent structure of clinical discharge letters and the semantic richness of transformer embeddings to create a self-supervised learning framework that minimizes the need for manual annotation while maintaining reasonable diagnostic accuracy.

## Key Results
- AUC of 77.68% (±4.30%) and F1-score of 78.14% (±4.89%) achieved on 33,176 discharge letters
- Performance comparable to fully supervised approaches while eliminating manual annotation requirements
- Method demonstrated robustness to cluster selection choices
- Outperformed unsupervised baselines in diagnostic classification

## Why This Works (Mechanism)
The approach leverages the structured nature of hospital discharge letters and the semantic richness of transformer embeddings to create meaningful clusters of diagnosis-related sentences. By focusing on weakly-supervised learning, the method exploits the inherent patterns in clinical documentation without requiring extensive manual labeling. The transformer classifier benefits from the semantic information captured in the embeddings, enabling accurate diagnosis prediction even with imperfect weak labels. This self-supervised framework effectively bridges the gap between unsupervised pattern discovery and supervised classification performance.

## Foundational Learning
- **Transformer embeddings**: Why needed - capture semantic relationships in clinical text; Quick check - evaluate embedding quality through similarity metrics
- **Weak supervision**: Why needed - reduce annotation burden while maintaining model performance; Quick check - compare weak labels against small manually annotated gold standard
- **Sentence clustering**: Why needed - identify diagnosis-related text segments for label generation; Quick check - assess cluster purity and coherence metrics
- **Clinical text classification**: Why needed - automate diagnosis identification from unstructured medical documents; Quick check - validate classification performance against expert annotations
- **Italian medical terminology**: Why needed - ensure language-specific accuracy in clinical contexts; Quick check - evaluate model performance on language-specific diagnostic terms

## Architecture Onboarding

**Component map:** Discharge letters -> Sentence extraction -> Transformer embeddings -> Clustering -> Weak label generation -> Transformer classifier -> Diagnosis prediction

**Critical path:** Sentence extraction → Transformer embeddings → Clustering → Weak label generation → Transformer classifier

**Design tradeoffs:** The pipeline trades perfect label accuracy for reduced annotation burden, accepting some noise in weak labels to achieve scalability. The single-hospital focus limits generalizability but ensures consistency in documentation practices. The bronchiolitis-specific approach may limit adaptability to other diseases without modification.

**Failure signatures:** Poor performance may occur with non-standard discharge letter formats, inconsistent documentation practices across hospitals, rare diagnoses with insufficient training examples, or languages with different medical terminology structures. The clustering step may fail to identify meaningful diagnosis-related sentences if clinical language patterns differ significantly from training data.

**First 3 experiments:**
1. Validate sentence extraction accuracy on a subset of manually reviewed discharge letters
2. Test embedding quality by measuring semantic similarity between diagnosis-related sentences
3. Evaluate weak label quality by comparing generated labels against a small manually annotated gold standard

## Open Questions the Paper Calls Out
None

## Limitations
- Single-disease evaluation (bronchiolitis) limits generalizability to other conditions
- Single-hospital dataset may not represent broader clinical documentation practices
- Weak supervision relies on clustering that may not generalize across different diseases or document types
- Performance metrics should be interpreted cautiously given the limited manual annotation validation

## Confidence
- Weakly-supervised approach achieves performance comparable to fully supervised methods: Medium confidence
- Method is robust to cluster selection: Medium confidence
- Approach is adaptable to other diseases: Low confidence (based on single disease evaluation)

## Next Checks
1. Evaluate the pipeline on discharge letters from multiple hospitals and regions to assess generalizability across different documentation practices and clinical settings.

2. Test the method on multiple disease categories with varying diagnostic complexity, including both common and rare conditions, to validate cross-disease adaptability.

3. Conduct a head-to-head comparison with traditional supervised approaches using identical datasets to quantify the trade-off between performance and annotation burden more precisely.