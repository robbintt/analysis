---
ver: rpa2
title: 'Lost in the Middle: An Emergent Property from Information Retrieval Demands
  in LLMs'
arxiv_id: '2510.10276'
source_url: https://arxiv.org/abs/2510.10276
tags:
- recall
- attention
- task
- memory
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes that the "lost-in-the-middle" phenomenon in
  LLMs is not a flaw but an emergent property arising from different information retrieval
  demands during pre-training. The authors hypothesize that long-term memory demands
  (requiring uniform recall across the entire input) and short-term memory demands
  (prioritizing recent information) shape positional bias in LLMs.
---

# Lost in the Middle: An Emergent Property from Information Retrieval Demands in LLMs

## Quick Facts
- arXiv ID: 2510.10276
- Source URL: https://arxiv.org/abs/2510.10276
- Authors: Nikolaus Salvatore; Hao Wang; Qiong Zhang
- Reference count: 11
- Primary result: Lost-in-the-middle is an emergent property from joint optimization on long-term and short-term memory demands during pre-training, not a flaw

## Executive Summary
This paper proposes that the "lost-in-the-middle" phenomenon in LLMs arises as an optimal adaptation to different information retrieval demands during training, rather than being a simple information loss artifact. The authors demonstrate that long-term memory demands (requiring uniform recall across the entire input) and short-term memory demands (prioritizing recent information) shape positional bias in LLMs. Through controlled experiments training GPT-2 and Llama models from scratch on tasks simulating these memory demands, they show that free recall induces primacy, running span induces recency, and combined training produces the characteristic U-shaped curve. The primacy effect depends on autoregressive architecture and attention sinks, as evidenced by its absence in T5 and elimination by attention sink ablation.

## Method Summary
The authors train transformer models from scratch on synthetic memory tasks that simulate different information retrieval demands. They use free recall paradigms to induce long-term memory demand (uniform retrieval across sequence) and running span tasks to induce short-term memory demand (end-weighted retrieval). Models are trained to output tokens in random order to eliminate sequence position as a predictive cue. They compare autoregressive architectures (GPT-2, RNN) with bidirectional architectures (T5) and perform attention sink ablation experiments to isolate the mechanisms underlying positional bias emergence.

## Key Results
- Training on combined long-term and short-term memory demands produces the characteristic U-shaped serial position curve in LLMs
- Primacy effects under long-term memory demand are amplified by autoregressive architectures through causal masking
- Attention sinks serve a selective functional role supporting long-term memory retrieval but not short-term
- Larger models (Llama 1.3B) show reduced U-shape severity, suggesting scale mitigates but doesn't eliminate the effect

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Lost-in-the-middle behavior emerges from joint optimization on two distinct information retrieval demands during training
- Mechanism: Long-term memory demand (uniform recall across entire sequence) induces primacy effects; short-term memory demand (end-weighted recall) induces recency effects. When models are trained on both simultaneously, the U-shaped curve emerges
- Core assumption: Training data contains a mixture of task types with different retrieval patterns that mirror these experimental conditions
- Evidence anchors:
  - [abstract] "this U-shaped performance curve emerges when LLMs...are trained from scratch on two simple human memory paradigms simulating long-term and short-term memory demands"
  - [section 3.1] Figure 3 shows GPT-2 models exhibit U-shaped serial position curves under combined training
  - [corpus] Limited direct corpus support; neighbor papers focus on mitigation rather than causal origin
- Break condition: If pre-training data contains only one type of retrieval demand (e.g., predominantly short-term), the full U-shape may not emerge

### Mechanism 2
- Claim: Primacy effects under long-term memory demand are amplified by autoregressive architectures through causal masking
- Mechanism: Causal attention masks prevent later tokens from attending to earlier ones, creating a forward-processing bias that anchors early tokens as "reference points" for subsequent computation
- Core assumption: The primacy effect requires both uniform retrieval demand AND autoregressive processing; neither alone is sufficient
- Evidence anchors:
  - [section 3.2] RNN seq2seq shows strong primacy; T5 encoder-decoder shows flat recall curves under identical free recall training
  - [page 3] "primacy effect arises from the interaction between the uniform long-term retrieval demand and the autoregressive nature of LLMs, specifically the causal masking"
  - [corpus] Layer-Specific Scaling paper confirms positional encoding issues in long-context modeling
- Break condition: Bidirectional architectures or modified attention patterns should suppress primacy even under long-term demand

### Mechanism 3
- Claim: Attention sinks serve a functional role selectively supporting long-term memory retrieval, not short-term
- Mechanism: Initial tokens become high-attention "anchors" that enable global information aggregation; ablating them degrades recall across the entire sequence for long-term tasks but has negligible impact on short-term tasks
- Core assumption: Attention sinks are not artifacts but learned mechanisms for maintaining global context representations
- Evidence anchors:
  - [section 3.3] "disrupting attention sinks impairs tasks with long-term memory demands (free recall and the combined tasks), while leaving the short-term running span performance largely intact"
  - [appendix A.2] Attention dropout at position 0 affects entire sequence; dropout at other positions causes only local degradation
  - [corpus] DSAS framework and Uncovering Initial Saliency paper corroborate attention optimization for long-context tasks
- Break condition: If attention sinks are artifacts, their ablation should affect all tasks uniformly or minimally

## Foundational Learning

- Concept: Serial position effects (primacy/recency)
  - Why needed here: The paper's entire framing depends on understanding why U-shaped recall curves arise—this is cognitive psychology 101 that maps directly to LLM behavior
  - Quick check question: Can you explain why recalling a list's first and last items is easier than middle items, and how this relates to memory "demand" distributions?

- Concept: Attention sink mechanics
  - Why needed here: The ablation experiments show attention sinks have task-selective functionality; understanding their formation and role is critical for interpreting the results
  - Quick check question: What happens to model performance when you mask out the first token's attention weights versus a middle token's?

- Concept: Autoregressive vs. bidirectional attention
  - Why needed here: The architectural comparison (GPT/RNN vs. T5) isolates causal masking as a necessary condition for primacy—this distinction is central to the mechanism
  - Quick check question: Why would a bidirectional model like T5 not exhibit primacy effects under the same training regimen as an autoregressive model?

## Architecture Onboarding

- Component map:
  Input layer -> Attention heads (with sink formation) -> Causal mask (for autoregressive) -> Output layer (order-agnostic recall)

- Critical path:
  1. Present sequence → 2. Attention computation (sink formation in early layers) → 3. Token prediction under retrieval demand → 4. Loss computed against shuffled recall targets

- Design tradeoffs:
  - Autoregressive architectures: Enable primacy (good for long-term tasks) but introduce positional bias
  - Bidirectional encoders: Reduce positional bias but may sacrifice long-range retrieval performance
  - Larger models (Llama 1.3B): Show reduced U-shape severity, suggesting scale mitigates but doesn't eliminate the effect

- Failure signatures:
  - Middle-of-sequence information loss when both long-term and short-term demands are present
  - Attention sink ablation causing global (not local) recall degradation signals long-term memory mechanism failure
  - Flat serial position curves when causal masking is removed indicate primacy mechanism is disabled

- First 3 experiments:
  1. Replicate free recall vs. running span training on a small GPT-2; plot serial position curves to confirm U-shape emergence pattern
  2. Ablate attention heads exceeding sink threshold (ε=0.8 on first token); compare recall degradation across task types
  3. Train identical model with bidirectional attention (modify causal mask); verify primacy effect disappears under free recall demand

## Open Questions the Paper Calls Out
None

## Limitations
- Experimental validation relies on controlled synthetic tasks rather than natural pre-training corpora, raising ecological validity questions
- Attention sink analysis depends on threshold-based definitions that may not capture all relevant mechanisms
- Claim that positional bias represents an "optimal" adaptation extends beyond empirical findings and depends on normative assumptions

## Confidence

**High confidence** in the experimental observation that training on combined long-term and short-term memory demands produces U-shaped serial position curves.

**Medium confidence** in the mechanism linking autoregressive architecture and attention sinks to primacy effects.

**Low confidence** in the broader claim that lost-in-the-middle behavior represents an optimal adaptation rather than a fundamental limitation.

## Next Checks

1. **Natural corpus validation**: Train models on naturally occurring long-document datasets (books, articles) with varying retrieval demands, then analyze whether positional bias patterns align with the controlled task predictions.

2. **Attention sink dynamics analysis**: Track attention sink formation and evolution across training epochs using probing techniques to determine whether sinks emerge as causes or consequences of long-term retrieval optimization.

3. **Architecture continuum exploration**: Design and train encoder-decoder architectures with intermediate causal masking patterns (partial masking) to identify the threshold at which primacy effects emerge.