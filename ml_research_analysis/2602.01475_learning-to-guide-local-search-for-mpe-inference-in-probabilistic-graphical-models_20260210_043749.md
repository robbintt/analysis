---
ver: rpa2
title: Learning to Guide Local Search for MPE Inference in Probabilistic Graphical
  Models
arxiv_id: '2602.01475'
source_url: https://arxiv.org/abs/2602.01475
tags:
- search
- beacon
- step
- budget
- local
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a neural network-based method to improve stochastic
  local search for MPE inference in PGMs. It addresses the myopia of best-improvement
  heuristics by learning to score local moves based on their predicted ability to
  reduce Hamming distance to high-quality solutions.
---

# Learning to Guide Local Search for MPE Inference in Probabilistic Graphical Models

## Quick Facts
- **arXiv ID:** 2602.01475
- **Source URL:** https://arxiv.org/abs/2602.01475
- **Reference count:** 40
- **Primary result:** Neural-guided local search improves MPE inference in high-treewidth PGMs with up to 80% log-likelihood gains

## Executive Summary
This paper proposes a neural network-based method to improve stochastic local search for MPE inference in probabilistic graphical models (PGMs). The approach addresses the myopia of best-improvement heuristics by learning to score local moves based on their predicted ability to reduce Hamming distance to high-quality solutions. Experiments on 25 high-treewidth PGMs show consistent improvements over standard greedy search and GLS+ methods, with win percentages frequently exceeding 60% and average log-likelihood improvements ranging from 1% to over 80%, particularly in early search stages.

## Method Summary
The method uses an attention-based neural network (BEACON) to score local moves by predicting their ability to reduce Hamming distance to reference solutions generated by an anytime MPE solver. The model is trained on states collected from local search trajectories, with labels indicating whether each neighbor flip reduces distance to the reference solution. During inference, neighbor selection combines normalized log-likelihood gains with neural predictions using a weighted score: S_final = (1-λ)·S̃_LL + λ·S_NN. The approach provides an amortized lookahead mechanism that balances short-term probability improvements with long-term progress toward high-quality solutions.

## Key Results
- Win percentages against Greedy and GLS+ baselines frequently exceed 60% on 25 high-treewidth benchmark PGMs
- Average log-likelihood improvements range from 1% to over 80%, with strongest gains in early search stages
- Theoretical drift analysis shows bounded convergence time when predictor accuracy exceeds 50%
- Hybrid scoring with λ=0.2-0.5 consistently outperforms pure likelihood or pure neural guidance

## Why This Works (Mechanism)

### Mechanism 1: Amortized Lookahead via Distance Prediction
Replaces myopic likelihood maximization with learned estimates of "distance-reducing potential" to escape plateaus that satisfy local constraints but block global optimality. The framework treats neighbor selection as supervised classification, using a neural network to predict whether flipping a variable reduces Hamming distance to a reference solution.

### Mechanism 2: Hybrid Scoring (Likelihood + Guidance)
Combines normalized log-likelihood gain with neural predictions to create a robust exploration-exploitation trade-off. The likelihood term grounds search in valid probability improvements while the neural term pulls toward unexplored high-potential basins.

### Mechanism 3: Theoretical Drift Toward Optima
Provides bounded expected convergence time conditional on predictor maintaining >50% success rate. If the probability of selecting a distance-reducing move is α > 0.5, expected Hamming distance decreases linearly.

## Foundational Learning

- **Concept: Stochastic Local Search (SLS) & Local Optima** - Why needed: Targets the "myopic best-improvement rule" that gets stuck in poor local optima. Quick check: Why does maximizing immediate log-likelihood gain not guarantee finding the global MPE assignment?
- **Concept: Most Probable Explanation (MPE) & Hamming Distance** - Why needed: Uses Hamming distance as proxy for "how far" a current state is from the target. Quick check: In a PGM with binary variables, if current state is [0,1,0] and target is [1,1,1], what is the Hamming distance?
- **Concept: Amortized Inference** - Why needed: Relies on fixed graphical model and repeated inference queries to amortize training cost. Quick check: Why is this approach unsuitable for settings where graph structure changes with every query?

## Architecture Onboarding

- **Component map:** Data Generator -> Labeler -> BEACON Model -> Search Engine
- **Critical path:** Labeler quality determines system performance ceiling. Poor reference solutions from teacher solver limit neural network's ability to guide search toward good solutions.
- **Design tradeoffs:** Teacher budget (higher yields better labels but slower generation), Lambda weighting (balances neural guidance vs likelihood grounding)
- **Failure signatures:** Early stagnation (λ too high/overfitting), performance worse than Greedy (neural accuracy < 50%)
- **First 3 experiments:** 1) Baseline verification comparing Greedy vs BEACON-Greedy on small grid/BN, 2) Lambda sweep on validation set to prove hybrid mechanism necessity, 3) Teacher quality ablation comparing low vs high budget data generation

## Open Questions the Paper Calls Out

### Open Question 1
Can multi-step lookahead architectures capture longer-horizon gains missed by current one-step Hamming-based guidance? The current one-step focus may miss multi-move strategies required to escape complex local plateaus.

### Open Question 2
Can adaptive weighting mechanisms for λ improve robustness across different search stages? Fixed λ may fail to adapt as search moves from exploration to exploitation.

### Open Question 3
Does training on approximate solutions introduce systematic bias limiting convergence to global optimum? Theoretical convergence relies on true optimum, but training uses resource-limited solver solutions.

## Limitations
- Amortized learning assumptions may not hold across structurally diverse PGMs
- Convergence guarantee requires sustained >50% predictor accuracy vulnerable to evidence pattern shifts
- Gains concentrated on large, high-treewidth networks where exact solvers fail, amplifying cost of poor guidance

## Confidence

- **High confidence:** Hybrid scoring mechanism is technically sound; ablation shows λ≠0,1 performs best
- **Medium confidence:** Theoretical drift guarantee assumes perfect predictor performance; practical impact depends on real predictor accuracy
- **Low confidence:** Generalizability of learned policies across different PGM structures remains untested

## Next Checks

1. **Predictor Robustness Test:** Measure top-1 accuracy on held-out neighborhoods across varying evidence patterns to validate theoretical guarantees

2. **Structural Transferability:** Train on one PGM family and test on structurally different families to assess amortized learning limits

3. **Teacher Quality Sensitivity:** Systematically vary anytime solver budget and measure correlation between reference solution quality and test-time search performance