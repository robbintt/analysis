---
ver: rpa2
title: 'Adaptive Label Error Detection: A Bayesian Approach to Mislabeled Data Detection'
arxiv_id: '2601.10084'
source_url: https://arxiv.org/abs/2601.10084
tags:
- aled
- data
- label
- mislabeled
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of detecting mislabeled samples
  in datasets used for training deep learning models. The authors propose a novel
  method called Adaptive Label Error Detection (ALED), which leverages intermediate
  feature representations from deep convolutional neural networks (DCNNs) to identify
  mislabeled samples.
---

# Adaptive Label Error Detection: A Bayesian Approach to Mislabeled Data Detection

## Quick Facts
- arXiv ID: 2601.10084
- Source URL: https://arxiv.org/abs/2601.10084
- Reference count: 40
- This paper proposes ALED, achieving 84.7% sensitivity in detecting mislabeled samples vs 42.3% for Confident Learning while maintaining comparable precision

## Executive Summary
This paper addresses the problem of detecting mislabeled samples in datasets used for training deep learning models. The authors propose Adaptive Label Error Detection (ALED), a novel method that leverages intermediate feature representations from deep convolutional neural networks (DCNNs) to identify mislabeled samples. ALED works by extracting penultimate layer features, reducing dimensionality, fitting Gaussian distributions to class clusters using Minimum Covariance Determinant (MCD) estimation, and applying a likelihood ratio test to detect outliers likely corresponding to mislabeled samples. The method is evaluated on multiple medical imaging datasets with simulated label noise and demonstrates significantly higher sensitivity compared to established methods like Confident Learning while maintaining comparable precision.

## Method Summary
ALED detects mislabeled samples by extracting intermediate feature representations from trained DCNNs, specifically the penultimate layer pre-activations. These features are mean-pooled, projected via random projections combined with the mean-difference vector between classes, and used to fit class-conditional Gaussian distributions using MCD estimation. A likelihood ratio test then compares how well each sample fits its assigned class versus the alternative class, flagging samples where the likelihood ratio exceeds a threshold. The method is implemented as an ensemble over multiple random projections and requires binary classification problems as input.

## Key Results
- ALED achieves 84.7% sensitivity in detecting mislabeled samples compared to 42.3% for Confident Learning on 5% simulated noise datasets
- ALED maintains comparable precision to Confident Learning while significantly improving sensitivity
- Using ALED to clean datasets results in 33.8% reduction in test set errors, demonstrating practical effectiveness
- ALED shows particular advantage over existing methods when networks are pretrained rather than trained from scratch

## Why This Works (Mechanism)

### Mechanism 1
Intermediate feature representations preserve class-discriminative information lost in model outputs when training on noisy labels. During backpropagation, gradient magnitude decreases through successive layers due to activation function derivatives (<1), causing earlier layers to receive attenuated noise signals while later layers (especially the classifier) overfit to mislabeled samples. By extracting penultimate pre-activations rather than predictions, ALED accesses a representation space where class manifolds remain separable despite label noise. This works because early layers learn representative features even with mislabeling, and the feature space contains sufficient information to separate true underlying classes. Evidence includes the paper's theoretical analysis of gradient attenuation and empirical results showing ALED outperforms methods using final predictions. The method breaks down when networks are trained from scratch on small, noisy datasets where feature manifolds may not develop stable structure.

### Mechanism 2
Fitting class-conditional Gaussian distributions using Minimum Covariance Determinant (MCD) estimation enables robust modeling even when up to 50% of samples within a class label are actually mislabeled. MCD identifies the subset of samples with minimum covariance determinant, effectively excluding outliers when estimating distribution parameters. The ensemble of random projections preserves geometric structure while reducing dimensionality to make covariance estimation tractable. This works because pre-activations of wide DCNNs are approximately Gaussian distributed (supported by neural network Gaussian process theory), and class distributions share a scaled covariance structure. Evidence includes the paper's theoretical justification using NNGP theory and empirical results showing robust performance. The mechanism breaks down when pre-activations are highly non-Gaussian, particularly for randomly initialized networks without pretraining, or when covariance matrices are poorly estimated due to insufficient data.

### Mechanism 3
Likelihood ratio testing provides the Bayes-optimal decision rule for determining whether a sample belongs to its given label class versus an alternative class. For each sample, compute Λ(z) = f_alt(z) / f_given(z) using the fitted Gaussian PDFs. If Λ > τ (threshold), flag as mislabeled. This thresholding scheme directly compares how well the sample's features align with each class's estimated distribution. This works because the Bayes optimal test is the likelihood ratio test, which ALED implements directly. Evidence includes the paper's theoretical analysis showing this thresholding scheme is the main gap between ALED and Confident Learning. The method breaks down when covariance matrices are poorly estimated (insufficient data, extreme class imbalance), making likelihood ratios unreliable.

## Foundational Learning

- **Neural Network Gaussian Process (NNGP) Theory**: Why needed here - ALED's core assumption that pre-activations are approximately Gaussian rests on this theoretical foundation; understanding why wide networks approximate GPs helps assess when the assumption holds. Quick check question: Can you explain why increasing network width makes pre-activation distributions more Gaussian, and why pretrained networks might satisfy this better than randomly initialized ones?

- **Minimum Covariance Determinant (MCD) Estimation**: Why needed here - ALED uses MCD rather than standard sample covariance to handle contamination from mislabeled samples within each class label group. Quick check question: What is the breakdown point of MCD estimation, and how does it differ from the 0% breakdown point of standard sample covariance?

- **Likelihood Ratio Testing and the Neyman-Pearson Lemma**: Why needed here - ALED's thresholding mechanism is motivated by LRT optimality properties; understanding this clarifies why the method uses density ratios rather than simple distance metrics. Quick check question: Under what conditions is the likelihood ratio test provably optimal, and what assumptions must hold for this optimality to transfer to the mislabel detection setting?

## Architecture Onboarding

- Component map: Trained DCNN -> Feature extractor (penultimate layer) -> Mean pooling -> Random projection + mean-difference projection -> MCD estimator -> Likelihood calculator -> Ensemble aggregator -> Decision module
- Critical path: Feature extraction → Mean pooling → Random projection + mean-difference projection → MCD fitting → Likelihood computation → Ensemble averaging → Likelihood ratio thresholding
- Design tradeoffs:
  - **Dimensionality (d)**: Higher dimensions capture more information but risk curse of dimensionality; paper uses d=2 as default
  - **Ensemble size (k)**: More ensembles improve robustness but increase computation; diminishing returns after k=10
  - **Threshold (τ)**: Lower values increase sensitivity at cost of precision; paper uses τ=2 as default
  - **Layer depth**: Earlier layers more robust to noise but less semantically rich; paper uses penultimate layer
  - **Binary-only**: Multi-class requires one-vs-all decomposition, increasing computational cost k-fold
- Failure signatures:
  - **Small datasets** (n < 1000): All methods degrade; ALED shows poor performance on BreastMNIST (n=546)
  - **Randomly initialized networks**: ALED advantage over CL diminishes; feature space may lack Gaussian structure
  - **Extreme label noise** (>20%): Not tested beyond 20%; MCD breakdown at 50% contamination suggests upper bound
- First 3 experiments:
  1. **Baseline validation on synthetic noise**: Take a pretrained ResNet50 on MedMNIST dataset, inject 5% random label noise, run ALED with default hyperparameters (d=2, k=10, τ=2), and verify you achieve sensitivity >80% with PPV >80%. Compare against Confident Learning baseline.
  2. **Ablation on pretrained vs. random initialization**: Train identical architectures (ResNet50, DenseNet121) from scratch on the same noisy dataset; measure ALED performance gap between pretrained and randomly initialized models to quantify dependence on pretraining.
  3. **Downstream cleaning validation**: Apply ALED to identify mislabeled samples in a 10%-noisy training set, remove flagged samples, retrain model from scratch on cleaned data, and measure test error reduction. Target: >30% error reduction as reported in paper.

## Open Questions the Paper Calls Out

- Can sophisticated projection methods like Local Fisher Discriminant Analysis extend ALED to native multi-class problems without requiring decomposition into binary tasks? The current algorithm relies on a projection vector between two class means, which does not naturally generalize to K > 2 classes without expensive one-against-all decomposition.

- How does the timing of ALED application during training epochs affect detection performance? The feature geometry likely shifts as the network learns or overfits, but the optimal point to snapshot features for mislabeling detection is undefined.

- Do feature representations extracted from intermediate layers at varying depths provide improved detection capabilities compared to the penultimate layer? Earlier layers may be more robust to overfitting while deeper layers capture more semantic information; the trade-off for this specific task is unknown.

## Limitations

- Gaussian approximation assumption for pre-activations may not hold for all network architectures or training regimes, particularly for randomly initialized networks or highly non-linear feature spaces
- MCD estimation robustness degrades with extreme label noise (>50% contamination within class) and small sample sizes, limiting applicability to certain datasets
- The method's binary classification focus requires decomposition for multi-class problems, increasing computational complexity k-fold per class pair
- Implementation details in the statlab package (random projection generation, MCD parameters) are not fully specified in the paper

## Confidence

- **High confidence** in mechanism 1 (gradient attenuation theory) and mechanism 3 (likelihood ratio optimality), supported by established theoretical frameworks
- **Medium confidence** in mechanism 2 (Gaussian approximation via NNGP theory), as corpus evidence is limited and break conditions are not thoroughly explored
- **Medium confidence** in empirical results due to potential implementation differences in the public statlab package

## Next Checks

1. **Reproduce baseline results**: Train ResNet50 on 5% mislabeled PneumoniaMNIST data, run ALED with default parameters, verify sensitivity >80% and PPV >80% against Confident Learning baseline
2. **Test pretraining dependency**: Compare ALED performance on the same noisy dataset using pretrained vs. randomly initialized DenseNet121 to quantify pretraining's impact on feature Gaussianity
3. **Validate downstream cleaning**: Apply ALED to 10%-noisy training set, remove flagged samples, retrain model from scratch, and measure test error reduction (target: >30% reduction)