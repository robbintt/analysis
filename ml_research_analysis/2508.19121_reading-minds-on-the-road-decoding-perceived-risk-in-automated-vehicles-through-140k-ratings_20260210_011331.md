---
ver: rpa2
title: 'Reading minds on the road: decoding perceived risk in automated vehicles through
  140K+ ratings'
arxiv_id: '2508.19121'
source_url: https://arxiv.org/abs/2508.19121
tags:
- longitudinal
- acceler
- ation
- elativ
- elocity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a novel method to decode time-continuous
  perceived risk in automated vehicles by crowd-sourcing 141,628 discrete risk ratings
  from 2,164 participants viewing realistic highway driving videos. These discrete
  ratings were reconstructed into 236 hours of time-continuous perceived risk data.
---

# Reading minds on the road: decoding perceived risk in automated vehicles through 140K+ ratings

## Quick Facts
- **arXiv ID:** 2508.19121
- **Source URL:** https://arxiv.org/abs/2508.19121
- **Reference count:** 21
- **Primary result:** Deep neural networks trained on crowdsourced risk ratings predict perceived risk from vehicle kinematics with <3% mean relative error

## Executive Summary
This study presents a novel approach to decode time-continuous perceived risk in automated vehicles by leveraging crowdsourced video-based ratings. The researchers collected 141,628 discrete risk ratings from 2,164 participants viewing realistic highway driving videos, which were reconstructed into 236 hours of continuous perceived risk data. Deep neural networks were then trained to predict moment-by-moment perceived risk from vehicle kinematics, achieving high accuracy with mean relative error below 3%. The explainable AI analysis identified manoeuvre uncertainty and relative motion as primary drivers of perceived risk, revealing that risk perception varies adaptively over time and cannot be accurately predicted by time-invariant models. This approach provides a foundation for real-time risk-aware AV control to enhance passenger comfort and trust.

## Method Summary
The researchers employed a two-phase methodology: first, crowdsourcing risk ratings from participants viewing realistic highway driving videos, then training deep neural networks to predict continuous risk perception from vehicle kinematics. They collected 141,628 discrete risk ratings from 2,164 participants, which were reconstructed into 236 hours of time-continuous perceived risk data using interpolation techniques. Deep neural networks were then trained on this dataset to predict moment-by-moment perceived risk based on vehicle kinematics inputs. The model's performance was evaluated using mean relative error metrics, achieving results below 3% error. Explainable AI techniques were applied to identify key factors driving perceived risk, with manoeuvre uncertainty and relative motion emerging as primary contributors.

## Key Results
- Deep neural networks achieved mean relative error below 3% in predicting moment-by-moment perceived risk from vehicle kinematics
- Time-continuous perceived risk was successfully reconstructed from 141,628 discrete ratings into 236 hours of data
- Explainable AI analysis revealed manoeuvre uncertainty and relative motion as primary drivers of perceived risk
- Risk perception was found to vary adaptively over time, challenging the effectiveness of time-invariant prediction models

## Why This Works (Mechanism)
The approach works by capturing the nuanced, moment-to-moment variations in human risk perception through crowdsourced ratings, then using deep learning to model these complex temporal patterns from observable vehicle kinematics. By reconstructing discrete ratings into continuous time-series data, the method preserves the dynamic nature of risk perception. The deep neural networks can learn non-linear relationships between vehicle movements and perceived risk that simpler models cannot capture. The explainable AI component provides insight into the specific kinematic features that most strongly influence risk perception, enabling targeted improvements in AV control algorithms.

## Foundational Learning
- **Crowdsourcing risk perception**: Why needed - to gather large-scale human risk ratings efficiently; Quick check - ensure participant diversity and realistic video scenarios
- **Time-series reconstruction**: Why needed - to convert discrete ratings into continuous data for temporal modeling; Quick check - validate interpolation accuracy against known risk patterns
- **Deep neural networks for regression**: Why needed - to capture complex non-linear relationships between kinematics and perceived risk; Quick check - compare performance against simpler regression models
- **Explainable AI in safety contexts**: Why needed - to understand model decisions and ensure safety-critical transparency; Quick check - verify feature importance rankings align with driving expertise
- **Temporal modeling of subjective states**: Why needed - risk perception changes dynamically over time; Quick check - test model performance on time-varying versus static prediction tasks

## Architecture Onboarding

### Component Map
Video + Rating Collection -> Time-Series Reconstruction -> DNN Training -> Risk Prediction -> Explainable AI Analysis

### Critical Path
Rating collection → time-series reconstruction → DNN training → real-time prediction

### Design Tradeoffs
- **Crowdsourcing vs. in-vehicle ratings**: Crowdsourcing provides scale but may sacrifice ecological validity
- **Interpolation methods**: Balance between smooth transitions and preserving rating granularity
- **Model complexity vs. interpretability**: Deeper networks may improve accuracy but reduce transparency
- **Kinematic feature selection**: More features increase predictive power but may introduce noise

### Failure Signatures
- Overfitting to specific driving scenarios if training data lacks diversity
- Poor temporal alignment between predictions and actual risk perception
- Failure to capture context-specific risk factors beyond kinematics
- Inconsistent predictions during complex maneuver transitions

### First Experiments
1. Test DNN predictions against held-out crowdsourced ratings from the same scenarios
2. Validate feature importance rankings from explainable AI against human driving expertise
3. Compare real-time prediction performance with static risk models on time-varying scenarios

## Open Questions the Paper Calls Out
None provided

## Limitations
- Ecological validity concerns due to crowdsourced video-based ratings versus actual in-vehicle experiences
- Interpolation uncertainty when translating discrete ratings to continuous time-series data
- Focus on vehicle kinematics may overlook contextual factors like road infrastructure and weather conditions
- Limited generalizability beyond highway driving scenarios and specific participant demographics

## Confidence

### Core Methodology
- High confidence in the combination of crowdsourced ratings with deep learning for continuous risk prediction

### Explanatory Analysis
- Medium confidence in identifying manoeuvre uncertainty and relative motion as primary risk drivers

### Real-time Application Potential
- Low-Medium confidence in laboratory-based predictions translating to actual vehicle deployments

## Next Checks

1. Conduct an in-vehicle user study comparing perceived risk ratings from actual AV passengers versus crowdsourced video ratings for identical driving scenarios to assess ecological validity gaps

2. Implement the risk prediction model in a driving simulator or real AV to evaluate real-time prediction accuracy and passenger comfort outcomes during dynamic driving maneuvers

3. Test the model's generalization across diverse driving contexts including urban environments, adverse weather conditions, and different cultural driving norms to assess robustness beyond highway scenarios