---
ver: rpa2
title: Moral Susceptibility and Robustness under Persona Role-Play in Large Language
  Models
arxiv_id: '2511.08565'
source_url: https://arxiv.org/abs/2511.08565
tags:
- moral
- persona
- robustness
- susceptibility
- across
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces a benchmark for evaluating moral judgment
  in large language models under persona role-play using the Moral Foundations Questionnaire
  (MFQ). The authors define two metrics: moral robustness (stability of MFQ scores
  across personas under repeated sampling) and moral susceptibility (sensitivity to
  persona variation).'
---

# Moral Susceptibility and Robustness under Persona Role-Play in Large Language Models

## Quick Facts
- arXiv ID: 2511.08565
- Source URL: https://arxiv.org/abs/2511.08565
- Reference count: 40
- Models from different families show distinct moral robustness profiles under persona role-play, with family effects dominating over size effects for robustness.

## Executive Summary
This paper introduces a benchmark for evaluating moral judgment in large language models under persona role-play using the Moral Foundations Questionnaire (MFQ). The authors define two metrics: moral robustness (stability of MFQ scores across personas under repeated sampling) and moral susceptibility (sensitivity to persona variation). Testing across multiple model families and sizes, they find that model family accounts for most variance in moral robustness, with the Claude family showing the highest robustness. In contrast, moral susceptibility shows a mild family effect but a clear size trend, with larger models being more susceptible. Notably, robustness and susceptibility are positively correlated, especially at the family level.

## Method Summary
The benchmark uses 30 MFQ questions (5 foundations, 6 items each) with 100 persona descriptions. For each model, persona, and question, prompts include role-play instruction and ask for integer ratings 0-5. The process repeats n=10 times per pair to estimate variance. Robustness R measures within-persona score stability (Eq. 4), while susceptibility S measures across-persona variability (Eq. 7). After excluding 9 personas with systematic failures, 91 personas are partitioned into 7 groups of 13 for uncertainty estimation. The framework yields per-foundation and overall metrics, normalized to [0,1] for cross-model comparison.

## Key Results
- Model family accounts for most variance in moral robustness, with Claude family showing highest robustness
- Larger models within families show increased moral susceptibility to persona variation
- Moral robustness and susceptibility are positively correlated, especially at family level
- Harm/Care and Fairness/Reciprocity foundations show highest robustness and lowest susceptibility

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Model family determines baseline moral robustness through training methodology, not scale.
- Mechanism: Architectural choices, data curation, and alignment procedures (e.g., Constitutional AI, RLHF variants) create distinct "moral fingerprints" that persist across model sizes within a family.
- Core assumption: Robustness differences stem from training-time alignment procedures rather than architectural capacity.
- Evidence anchors:
  - [abstract] "model family accounts for most of the variance, while model size shows no systematic effect"
  - [section 3] "The Claude family is by a significant margin, the most robust, followed by Gemini and GPT-4 models"
  - [corpus] "Moral Lenses, Political Coordinates" finds moral conditioning effects depend on ideological framing, suggesting training methodology matters
- Break condition: If a model family releases variants with fundamentally different alignment approaches (e.g., Claude without Constitutional AI), robustness patterns would diverge from family baseline.

### Mechanism 2
- Claim: Larger models within families exhibit higher moral susceptibility to persona conditioning.
- Mechanism: Increased parameter count enables richer persona representations, allowing the model to more fully "inhabit" persona-driven moral perspectives rather than defaulting to training-time priors.
- Core assumption: Capacity for contextual adaptation scales with model size within a fixed training paradigm.
- Evidence anchors:
  - [abstract] "moral susceptibility exhibits a mild family effect but a clear within-family size effect, with larger variants being more susceptible"
  - [section 2.3] Susceptibility measured via across-persona variability in MFQ scores (Eq. 7)
  - [corpus] "Persona Switch" shows role-play effectiveness varies by task/instance, suggesting capacity matters for persona adoption
- Break condition: If instruction-following fine-tuning explicitly penalizes persona-driven moral shifts, the size-susceptibility relationship would weaken or reverse.

### Mechanism 3
- Claim: Fairness/Reciprocity and Harm/Care foundations are more robust because they receive stronger alignment signal during training.
- Mechanism: Safety training emphasizes harm prevention and fairness, creating deeper entrenchment of these foundations compared to Authority/Respect or Purity/Sanctity.
- Core assumption: Training corpora and RLHF reward models weight certain foundations more heavily.
- Evidence anchors:
  - [section 3/Table 2] "Fairness/Reciprocity and Harm/Care yield the highest average unbounded robustness and the lowest unbounded susceptibility"
  - [section 3] "Purity/Sanctity is least stable"
  - [corpus] Limited direct evidence in neighbors; related work on moral foundations in LLMs doesn't address foundation-specific stability
- Break condition: If models were explicitly trained with balanced foundation coverage, robustness variance across foundations would equalize.

## Foundational Learning

- Concept: **Moral Foundations Theory (5 foundations)**
  - Why needed here: The entire benchmark maps to Harm/Care, Fairness/Reciprocity, In-group/Loyalty, Authority/Respect, Purity/Sanctity. Without understanding these, you can't interpret MFQ profiles.
  - Quick check question: Which foundation measures sensitivity to challenges to tradition and sanctity?

- Concept: **Within-subject vs. Between-subject Variability**
  - Why needed here: Robustness = within-persona stability (same persona, repeated runs); Susceptibility = between-persona variability (different personas). Conflating these invalidates the methodology.
  - Quick check question: If a model gives identical MFQ scores for all personas but different scores on re-runs, is it robust or susceptible?

- Concept: **Persona Role-Play Prompting**
  - Why needed here: The entire intervention relies on "You are roleplaying as the following persona: <DESCRIPTION>" prompts. Understanding how context windows carry persona information is essential.
  - Quick check question: What happens if persona descriptions contradict the model's safety training?

## Architecture Onboarding

- Component map:
  - MFQ Question Set (30 items, 5 foundations) -> Persona Descriptions (100 personas from Ge et al.) -> Prompt Constructor (role-play + question + scale) -> Model API (repeated sampling, n=10) -> Response Parser (extract leading integer 0-5) -> Statistical Aggregator (compute per-foundation means, robustness R, susceptibility S) -> Visualization Layer

- Critical path:
  1. Prompt construction must enforce leading integer response (parsing failures break the pipeline)
  2. Repeated sampling (n=10 per persona-question) is required for variance estimation
  3. Persona grouping (G=7 groups of 13) determines susceptibility uncertainty bounds
  4. Cross-model normalization (E[ẽR], E[ẽS]) enables bounded [0,1] metrics

- Design tradeoffs:
  - One question per prompt vs. full questionnaire: Authors chose single questions to avoid order effects; cost increases 30×
  - Repeated sampling vs. token probability extraction: Paper notes token probabilities would be "more principled" (Eq. 8) but requires logprob access; sampling approach works with any API
  - Bounded vs. unbounded metrics: Bounded R, S ∈ [0,1] aid comparison but obscure absolute effect sizes

- Failure signatures:
  - Parsing cascade failures: Some personas systematically elicit non-compliant responses (Table 7: personas 66, 94); these were excluded
  - Persona refusal patterns: 9 personas completely excluded due to consistent rating refusal across all attempts
  - Family outliers: Grok exhibits low robustness + high susceptibility, breaking correlation patterns

- First 3 experiments:
  1. Reproduce robustness ranking for a single family (e.g., GPT-4.1 variants) with 20 personas and n=5 to validate pipeline before full benchmark
  2. Test token probability method (Eq. 8) on a model with logprob access to compare variance estimates against sampling approach
  3. Perturb persona description length to test whether susceptibility scales with persona detail richness, validating the capacity mechanism hypothesis

## Open Questions the Paper Calls Out

- Open Question 1: What mechanisms cause certain personas to systematically induce instruction-following failures across diverse model architectures?
  - Basis in paper: [explicit] The authors note that "some personas appeared repeatedly across models" with parsing failures and "this behavior was unexpected as their descriptions do not obviously correlate with not following instructions, yet the pattern persists across architectures."
  - Why unresolved: The authors identify the phenomenon but do not analyze persona characteristics or model features that drive cross-architecture instruction violations.
  - What evidence would resolve it: Systematic analysis of persona linguistic features (e.g., authority framing, complexity) correlated with parsing failure rates; probing attention patterns during persona processing.

- Open Question 2: Why does model family dominate moral robustness variance while model size primarily affects susceptibility?
  - Basis in paper: [inferred] The paper reports that "model family accounts for most of the variance" in robustness with "no systematic effect" of size, whereas susceptibility exhibits "a clear within-family size effect." The mechanisms underlying this divergence are not investigated.
  - Why unresolved: The authors quantify the patterns but do not propose or test hypotheses about training procedures, architecture, or alignment methods that could explain the family-vs-size dichotomy.
  - What evidence would resolve it: Controlled experiments varying training data, RLHF procedures, and architecture within/between families; ablation studies isolating alignment components.

- Open Question 3: Does the positive correlation between moral robustness and susceptibility reflect a shared underlying capacity for contextual adaptation?
  - Basis in paper: [explicit] The authors report "robustness and susceptibility are positively correlated, an association that is more pronounced at the family level" but do not interpret this relationship mechanistically.
  - Why unresolved: High robustness (stable within-persona responses) intuitively suggests resistance to change, yet positively correlates with high susceptibility (large across-persona shifts), creating a paradox.
  - What evidence would resolve it: Analysis of latent representations across personas and repetitions; testing whether both metrics scale with model capacity for nuanced context encoding.

## Limitations

- The positive correlation between robustness and susceptibility contradicts intuitive expectations and lacks mechanistic explanation
- Exclusion of 9 personas (9% of dataset) due to systematic refusal patterns may introduce bias
- Methodological choice of repeated sampling rather than token probability extraction limits reproducibility and comparability

## Confidence

- **High confidence**: Model family as primary determinant of moral robustness; larger models showing increased susceptibility; basic methodology of measuring moral variability under persona role-play
- **Medium confidence**: Interpretation that training methodology drives robustness differences; claim that Harm/Care and Fairness/Reciprocity foundations are inherently more robust due to alignment training
- **Low confidence**: Positive correlation between robustness and susceptibility; absence of systematic size effects on robustness; generalizability to non-Western moral frameworks

## Next Checks

1. Implement token probability variance estimation (Eq. 8) on a model with logprob access to determine whether sampling variance artifacts explain the robustness-susceptibility correlation

2. Conduct controlled experiments varying training data, RLHF procedures, and architecture within/between families to explain why model family dominates robustness variance while size primarily affects susceptibility

3. Analyze latent representations across personas and repetitions to test whether the positive correlation between robustness and susceptibility reflects shared capacity for contextual adaptation