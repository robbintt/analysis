---
ver: rpa2
title: 'RemedyGS: Defend 3D Gaussian Splatting against Computation Cost Attacks'
arxiv_id: '2511.22147'
source_url: https://arxiv.org/abs/2511.22147
tags:
- images
- image
- clean
- remedygs
- poisoned
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes RemedyGS, the first effective black-box defense
  framework against computation cost attacks targeting 3D Gaussian splatting (3DGS)
  systems. The framework consists of a detector to identify poisoned input images
  and a purifier to recover benign images, with adversarial training incorporated
  to enhance recovery quality.
---

# RemedyGS: Defend 3D Gaussian Splatting against Computation Cost Attacks

## Quick Facts
- arXiv ID: 2511.22147
- Source URL: https://arxiv.org/abs/2511.22147
- Reference count: 40
- Primary result: First effective black-box defense against computation cost attacks on 3DGS with up to 4 dB PSNR improvement

## Executive Summary
RemedyGS introduces the first effective black-box defense framework against computation cost attacks targeting 3D Gaussian splatting (3DGS) systems. The framework employs a detector to identify poisoned input images and a purifier to recover benign images, with adversarial training incorporated to enhance recovery quality. Experimental results demonstrate that RemedyGS successfully defends against white-box, black-box, and adaptive attacks while maintaining high reconstruction utility, achieving significant improvements in PSNR compared to baseline defenses.

## Method Summary
RemedyGS is a three-component framework designed to defend 3DGS systems against computation cost attacks. The detector identifies poisoned images using a convolutional neural network with four convolutional layers and a linear head. The purifier recovers clean images through an encoder-decoder architecture with additive skip connections. Adversarial training is incorporated with a discriminator to reduce blurring and improve recovery quality. The framework is trained on the DL3DV dataset with 320 scenes, generating paired clean and poisoned images using the Poison-splat attack. Training involves separate phases for detector and purifier, followed by adversarial training with alternating updates between the purifier and discriminator.

## Key Results
- Achieves up to 4 dB improvement in PSNR compared to baseline defenses
- Effectively defends against white-box, black-box, and adaptive attacks
- Maintains high reconstruction utility while safeguarding 3DGS systems

## Why This Works (Mechanism)
The framework works by detecting and purifying poisoned images before they can increase computation costs in 3DGS training. The detector identifies attack patterns, while the purifier reconstructs clean images, preventing the poisoning from affecting Gaussian splatting quality. Adversarial training further enhances the purifier's ability to recover high-quality images that can fool both the discriminator and maintain reconstruction utility.

## Foundational Learning

**3D Gaussian Splatting (3DGS)**: A rasterization-based rendering technique that represents scenes using millions of 3D Gaussians, requiring efficient computation for real-time rendering. Why needed: Understanding the target system being attacked.

**Computation Cost Attacks**: Poisoning attacks that manipulate input images to increase GPU memory usage, training time, and reduce rendering FPS in 3DGS systems. Why needed: Defining the threat model RemedyGS defends against.

**Poison-splat Attack**: A specific computation cost attack that corrupts input images to degrade 3DGS performance. Why needed: Understanding the attack mechanism being defended against.

**LPIPS Metric**: Learned Perceptual Image Patch Similarity measures perceptual similarity between images. Why needed: Evaluating the quality of purified images against clean references.

**Adversarial Training**: Training technique where a discriminator helps improve the purifier's ability to generate realistic clean images. Why needed: Understanding how RemedyGS reduces blurring in purified outputs.

## Architecture Onboarding

**Component Map**: Poison Image -> Detector -> Purifier -> Clean Image -> 3DGS Training

**Critical Path**: Input Image → Detector (identify poison) → Purifier (recover clean) → 3DGS Training

**Design Tradeoffs**: The framework balances detection accuracy with purification quality, using adversarial training to prevent excessive blurring while maintaining attack detection capability. Additive skip connections in the purifier preserve spatial information better than concatenation-based approaches.

**Failure Signatures**: 
- High detection but poor purification indicates detector working but purifier unable to recover quality
- Low detection accuracy suggests insufficient training data diversity or attack pattern coverage
- Excessive blurring in purified images indicates inadequate adversarial training

**3 First Experiments**:
1. Test detector accuracy on held-out scenes from DL3DV dataset
2. Evaluate purifier performance on images poisoned with varying ε values
3. Measure 3DGS training performance (GPU memory, FPS) with RemedyGS protection

## Open Questions the Paper Calls Out

None specified in the paper.

## Limitations

- Primary uncertainty around exact Poison-splat attack parameters used for training data generation
- Partial ambiguity in encoder-decoder architecture details, particularly channel progression
- Limited evaluation on real-world 3DGS applications beyond benchmark datasets

## Confidence

**High confidence** in overall framework design and three-component structure
**Medium confidence** in specific architectural details and training hyperparameters
**Medium confidence** in quantitative results, pending verification of exact attack configurations

## Next Checks

1. Generate poisoned training data using multiple ε values (26, 33, 40/255) to ensure detector robustness across attack strengths
2. Verify the purifier architecture uses additive skip connections and consistent 256-channel progression as specified
3. Test detector performance on held-out scenes from DL3DV not seen during training to validate generalization claims