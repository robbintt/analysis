---
ver: rpa2
title: Performance Prediction for Large Systems via Text-to-Text Regression
arxiv_id: '2506.21718'
source_url: https://arxiv.org/abs/2506.21718
tags:
- figure
- regression
- prediction
- performance
- resource
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes text-to-text regression as a scalable alternative
  to traditional tabular regression for predicting outcomes in complex systems like
  Google's Borg compute cluster. The method uses a 60M parameter encoder-decoder language
  model trained from random initialization to directly predict floating-point efficiency
  metrics from rich, non-tabular system logs and configuration data represented as
  text.
---

# Performance Prediction for Large Systems via Text-to-Text Regression

## Quick Facts
- arXiv ID: 2506.21718
- Source URL: https://arxiv.org/abs/2506.21718
- Reference count: 40
- Primary result: Achieves 0.99 rank correlation and 100x lower MSE than tabular baselines on Google Borg compute cluster efficiency prediction

## Executive Summary
This paper introduces text-to-text regression as a scalable alternative to traditional tabular regression for predicting outcomes in complex systems like Google's Borg compute cluster. The approach uses a 60M parameter encoder-decoder language model trained from random initialization to directly predict floating-point efficiency metrics from rich, non-tabular system logs and configuration data represented as text. The method achieves superior performance by maximizing feature observability and leveraging large-scale pretraining, demonstrating up to 0.99 rank correlation and 100x lower mean squared error compared to tabular approaches.

## Method Summary
The approach converts complex system configuration and performance data into text format using YAML serialization, then applies a 60M parameter T5X encoder-decoder model trained from random initialization to predict floating-point efficiency metrics. The model uses P10 tokenization for floating-point numbers and is trained with cross-entropy loss using the Adafactor optimizer. Inference involves sampling 128 predictions per input and aggregating via mean or median. The method demonstrates strong few-shot adaptation capabilities, requiring only 500 examples to maintain high accuracy on new tasks.

## Key Results
- Achieves up to 0.99 rank correlation on Google Borg efficiency prediction tasks
- Demonstrates 100x lower mean squared error compared to tabular regression approaches
- Requires only 500 examples for effective few-shot adaptation to new tasks
- Captures complex outcome distributions through density estimation via sampling

## Why This Works (Mechanism)
The approach works by converting rich, non-tabular system data into text format, which preserves all feature observability and relationships that tabular approaches lose through manual feature engineering. The encoder-decoder architecture can process long sequences (2048 tokens) to capture complex job-on-machine profiles and system configurations. Training from random initialization with large-scale pretraining creates a flexible foundation that can adapt to new tasks with minimal data. The sampling-based inference naturally captures outcome distributions rather than just point estimates.

## Foundational Learning
- **Encoder-decoder architectures**: Needed to process complex, long input sequences while generating continuous outputs. Quick check: Verify model has both encoder and decoder layers, not just decoder-only.
- **P10 tokenization**: Required for precise floating-point number representation. Quick check: Test tokenization preserves numerical precision across range.
- **Cross-entropy loss for regression**: Enables density estimation through sampling. Quick check: Verify training loss decreases and validation loss stabilizes.
- **Few-shot adaptation**: Critical for practical deployment on new tasks. Quick check: Test adaptation on held-out tasks with 500 examples.
- **Feature observability maximization**: Key advantage over tabular approaches. Quick check: Compare feature coverage between text and tabular representations.
- **Adafactor optimizer**: Handles large batch sizes efficiently. Quick check: Monitor training stability and convergence speed.

## Architecture Onboarding
**Component map:** Data (YAML text) -> Encoder layers -> Decoder layers -> P10 tokenization -> Cross-entropy loss -> Adafactor optimizer
**Critical path:** Input text processing through encoder → decoder attention → float tokenization → loss computation → parameter updates
**Design tradeoffs:** Encoder-decoder vs decoder-only (encoder better for complex inputs), random initialization vs pretraining (random allows task-specific learning), sampling vs deterministic prediction (sampling captures uncertainty)
**Failure signatures:** High validation loss with encoder-decoder indicates architectural issues; low loss but poor Spearman correlation suggests tokenization problems; overfitting after fine-tuning indicates pretraining too long
**First experiments:**
1. Train on synthetic text-to-float dataset to verify basic functionality
2. Compare encoder-decoder vs decoder-only on simple regression task
3. Test few-shot adaptation on new regression task with 500 examples

## Open Questions the Paper Calls Out
None

## Limitations
- Proprietary Borg dataset prevents exact replication of results
- Strong performance claims rely heavily on specific dataset characteristics
- Sensitivity to architectural choices and pretraining duration requires careful hyperparameter tuning
- May not generalize to tabular datasets with lower feature observability

## Confidence
- **High confidence:** Encoder-decoder methodology and ablation studies showing encoder superiority
- **Medium confidence:** Few-shot adaptation results and density estimation capabilities
- **Low confidence:** 100x MSE improvement claims and uncertainty quantification without independent validation

## Next Checks
1. Replicate on public system logs from HPC clusters or cloud providers to verify 0.99 rank correlation
2. Systematically convert tabular datasets to text format and compare performance against direct tabular regression
3. Test 500-example adaptation capability across multiple diverse regression tasks to establish generalizability