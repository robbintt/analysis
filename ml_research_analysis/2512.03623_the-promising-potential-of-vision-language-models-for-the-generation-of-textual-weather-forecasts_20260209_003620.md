---
ver: rpa2
title: The promising potential of vision language models for the generation of textual
  weather forecasts
arxiv_id: '2512.03623'
source_url: https://arxiv.org/abs/2512.03623
tags:
- weather
- forecast
- amazon
- office
- categorical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors explored using Vision Language Models (VLMs) for automated
  generation of Shipping Forecast text directly from gridded weather data, aiming
  to improve production efficiency and service innovation. They fine-tuned Amazon
  Nova Lite 1.0 using video-encoded weather attributes (wind, sea state, visibility,
  weather, and pressure) paired with archived forecast text.
---

# The promising potential of vision language models for the generation of textual weather forecasts

## Quick Facts
- arXiv ID: 2512.03623
- Source URL: https://arxiv.org/abs/2512.03623
- Reference count: 9
- Primary result: Vision Language Models can generate Shipping Forecast text from gridded weather data, with categorical encoding outperforming continuous encoding and full-rank fine-tuning yielding better recall than LoRA

## Executive Summary
This paper explores using Vision Language Models (VLMs) to automate the generation of UK Shipping Forecast text from gridded numerical weather prediction (NWP) data. The authors fine-tuned Amazon Nova Lite 1.0 using video-encoded weather attributes paired with archived forecast text, achieving F1 scores up to 58.4% for visibility. While an LLM baseline outperformed the VLM (62% vs 52% F1), the study demonstrates that VLMs can directly process visual meteorological data and generate structured forecast text, suggesting potential for future improvements in data-to-text conversion for weather forecasting.

## Method Summary
The authors fine-tuned Amazon Nova Lite 1.0 using approximately 1,500 video-bulletin pairs from Dec 2024-Feb 2025, encoding five weather attributes (wind, sea state, visibility, weather, pressure) as categorical videos with specific color scales. They tested both LoRA and full-rank SFT approaches, training for 30 epochs on distributed GPU clusters. The categorical encoding consistently outperformed continuous encoding, with visibility achieving the highest F1 score. A traditional LLM baseline using Amazon Nova Pro with few-shot examples achieved 62% F1, outperforming the VLM approach.

## Key Results
- Categorical encoding of weather attributes consistently outperformed continuous encoding across all five tested attributes
- Full-rank fine-tuning yielded better recall and forecast completeness than parameter-efficient LoRA
- The LLM baseline (62% F1) outperformed the VLM approach (52% F1) overall
- Visibility attribute achieved the highest performance at 58.4% F1 with categorical encoding
- Separate attribute-specific models performed better than combined multi-attribute approaches

## Why This Works (Mechanism)
The VLM approach works by converting gridded meteorological data into visual formats that language models can process through their multimodal capabilities. By encoding weather attributes as videos with categorical color scales, the model can interpret spatial and temporal patterns in the data and map them to the structured vocabulary and format requirements of shipping forecasts. The success of categorical over continuous encoding suggests that VLMs perform better when visual information maps directly to the discrete categories used in forecast language, reducing ambiguity in interpretation.

## Foundational Learning

**Numerical Weather Prediction (NWP) Data** - Why needed: Forms the raw input data for forecast generation. Quick check: Verify you can access and understand gridded weather model outputs at the specified resolution and domain.

**Shipping Forecast Format and Vocabulary** - Why needed: The model must generate text conforming to strict maritime broadcasting standards. Quick check: Review Met Office Shipping Forecast Code of Practice to understand formatting requirements and terminology constraints.

**Video Encoding of Weather Attributes** - Why needed: Transforms numerical data into visual format suitable for VLMs. Quick check: Confirm categorical color scales are correctly implemented and match forecast vocabulary categories.

## Architecture Onboarding

**Component Map**: NWP Data -> Video Encoding -> VLM Fine-tuning -> Forecast Generation -> F1 Evaluation

**Critical Path**: Video encoding of weather attributes → VLM fine-tuning → generation of forecast text → word-level F1 evaluation

**Design Tradeoffs**: Categorical encoding provides better VLM interpretability but requires careful bin definition; full-rank fine-tuning yields better performance but at higher computational cost versus parameter-efficient LoRA; separate attribute models outperform combined approaches but increase deployment complexity

**Failure Signatures**: Continuous color scales cause poor interpretation (fix: use categorical labels); early stopping by perplexity reduces F1 (fix: train full 30 epochs); combined multi-attribute models underperform (fix: use task-specific prompts); LoRA yields lower recall than full-rank SFT (fix: prefer full-rank for completeness-critical tasks)

**First Experiments**:
1. Test categorical vs continuous encoding on a single weather attribute using the same VLM architecture
2. Compare LoRA and full-rank fine-tuning performance on the visibility attribute
3. Evaluate whether task-specific prompts improve performance compared to generic meteorological prompts

## Open Questions the Paper Calls Out
None

## Limitations
- The LLM baseline significantly outperformed the VLM approach (62% vs 52% F1), questioning the practical viability of VLMs for this task
- Critical hyperparameters for LoRA and training methodology are not fully specified, limiting reproducibility
- The strict word-level F1 evaluation may be overly harsh given potential inconsistencies in human-written forecasts
- The paper does not provide actual prompt templates or system instructions used during fine-tuning

## Confidence

**High Confidence**: Full-rank fine-tuning outperforms LoRA for this task, with clear experimental evidence showing lower recall and completeness with parameter-efficient methods.

**Medium Confidence**: Categorical encoding consistently outperforms continuous encoding, though systematic comparisons across all attributes are limited in the paper.

**Low Confidence**: The claim that VLMs show "promise" for meteorological data-to-text conversion is qualified by the significant performance gap with LLM baselines, suggesting the approach needs substantial improvement before practical deployment.

## Next Checks

1. Reproduce the categorical encoding scheme by defining exact bin definitions and colormaps for each weather attribute, then conduct controlled comparisons with continuous encoding using the same VLM architecture.

2. Systematically vary prompt templates and system instructions while keeping all other factors constant to determine whether specific guidance from the Shipping Forecast Code of Practice is essential for achieving reported F1 scores.

3. Train and evaluate a single VLM model that processes all weather attributes simultaneously, comparing performance, computational efficiency, and deployment advantages against the individual attribute models reported in the paper.