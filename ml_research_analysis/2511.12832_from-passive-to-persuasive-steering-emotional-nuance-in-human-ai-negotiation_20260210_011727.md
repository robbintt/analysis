---
ver: rpa2
title: 'From Passive to Persuasive: Steering Emotional Nuance in Human-AI Negotiation'
arxiv_id: '2511.12832'
source_url: https://arxiv.org/abs/2511.12832
tags:
- steer
- support
- disclosure
- baseline
- politeness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of instilling nuanced, human-like
  emotional expression in large language models (LLMs), which is critical for socially
  sensitive applications like mental health support and negotiation. The proposed
  method, STAR (Steering via Attribution and Representation), uses attribution patching
  to identify key intervention points in the model and applies contrastive activation
  vectors to steer LLM behavior toward desired emotional traits.
---

# From Passive to Persuasive: Steering Emotional Nuance in Human-AI Negotiation

## Quick Facts
- **arXiv ID:** 2511.12832
- **Source URL:** https://arxiv.org/abs/2511.12832
- **Reference count:** 30
- **Primary result:** STAR method steers LLM emotional expression through attribution patching and activation steering, improving sentiment, empathy keywords, and first-person pronoun usage across emotional support and negotiation tasks

## Executive Summary
This paper introduces STAR (Steering via Attribution and Representation), a method for instilling nuanced, human-like emotional expression in large language models (LLMs). The approach combines attribution patching to identify key intervention points with contrastive activation vectors to steer LLM behavior toward desired emotional traits. The method is evaluated on emotional support and negotiation tasks, demonstrating significant improvements in emotional characteristics while maintaining fluency and coherence.

## Method Summary
STAR employs attribution patching to identify critical intervention points in LLMs, then applies contrastive activation vectors to steer model behavior toward specific emotional traits. The method uses activation steering techniques to modify the model's internal representations during inference, allowing for targeted emotional expression without fine-tuning. The approach is designed to be generalizable across different conversational settings and emotional contexts.

## Key Results
- Targeted activation steering significantly enhances emotional characteristics including positive sentiment and empathy-related keywords
- The method increases first-person pronoun usage, indicating more personal and engaged responses
- STAR outperforms baseline approaches and demonstrates effective generalization across emotional support and negotiation tasks

## Why This Works (Mechanism)
STAR works by identifying key intervention points through attribution patching, which reveals which model components are most influential for specific emotional outputs. By applying contrastive activation vectors at these critical points, the method can effectively shift the model's emotional trajectory without requiring full fine-tuning. The approach leverages the model's existing understanding of emotional nuance while providing targeted steering through activation space.

## Foundational Learning
1. **Attribution Patching** - Why needed: To identify which model components most influence emotional output. Quick check: Verify that patching at identified locations produces measurable changes in emotional metrics.
2. **Activation Steering** - Why needed: To modify model behavior during inference without fine-tuning. Quick check: Confirm that steering vectors can be applied in real-time without degrading base capabilities.
3. **Contrastive Activation Vectors** - Why needed: To provide directional guidance for emotional steering. Quick check: Validate that contrastive pairs capture meaningful emotional differences.

## Architecture Onboarding

**Component Map:** Input Text -> Tokenizer -> LLM Backbone -> Attribution Patching Module -> Activation Steering Module -> Output Text

**Critical Path:** The critical path flows from input text through the LLM backbone, where attribution patching identifies intervention points, followed by activation steering that modifies internal representations before final output generation.

**Design Tradeoffs:** The method trades computational overhead during inference for fine-tuning costs, requiring additional memory for activation vectors but enabling task-specific steering without model modification.

**Failure Signatures:** Oversteering may produce inauthentic emotional responses, while understeering may result in minimal emotional enhancement. Incorrect attribution identification can lead to ineffective steering or degradation of task performance.

**First Experiments:**
1. Test attribution patching accuracy on a small set of emotional prompts to verify intervention point identification
2. Validate activation steering effectiveness using controlled contrastive pairs
3. Measure computational overhead of the steering mechanism during inference

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focuses on surface-level metrics rather than measuring actual emotional understanding or interaction quality
- Does not address potential unintended consequences of emotional steering in sensitive contexts
- Performance on diverse user populations and edge cases in mental health scenarios remains untested

## Confidence
- **High confidence:** Technical implementation of attribution patching and activation steering is sound and reproducible
- **Medium confidence:** Reported improvements in emotional metrics are valid, though practical significance is unclear
- **Low confidence:** Claims about maintaining "fluency and coherence" lack quantitative backing, and "effective generalization" evaluation is limited to two task types

## Next Checks
1. Conduct user studies with mental health professionals to evaluate authenticity and appropriateness of emotionally steered responses in therapeutic contexts
2. Test method's robustness across diverse demographic groups and cultural contexts to identify potential biases or misalignments
3. Evaluate impact of emotional steering on task completion rates and user satisfaction in negotiation scenarios, beyond sentiment analysis