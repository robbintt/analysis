---
ver: rpa2
title: Communication Efficient Split Learning of ViTs with Attention-based Double
  Compression
arxiv_id: '2509.15058'
source_url: https://arxiv.org/abs/2509.15058
tags:
- compression
- learning
- accuracy
- batch
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of communication efficiency
  in split learning with Vision Transformers (ViTs), where high communication costs
  arise from transmitting intermediate model activations. The proposed Attention-based
  Double Compression (ADC) framework introduces a two-step compression strategy: first,
  it clusters and merges similar activations using CLS-token attention scores, reducing
  the batch size; second, it selects only the most important tokens within each merged
  activation.'
---

# Communication Efficient Split Learning of ViTs with Attention-based Double Compression

## Quick Facts
- arXiv ID: 2509.15058
- Source URL: https://arxiv.org/abs/2509.15058
- Reference count: 40
- Primary result: Attention-based Double Compression (ADC) achieves near-baseline accuracy at ξ≈0.1 on CIFAR100/DeiT-T while enabling extreme communication savings.

## Executive Summary
This paper addresses the challenge of communication efficiency in split learning with Vision Transformers (ViTs), where high communication costs arise from transmitting intermediate model activations. The proposed Attention-based Double Compression (ADC) framework introduces a two-step compression strategy: first, it clusters and merges similar activations using CLS-token attention scores, reducing the batch size; second, it selects only the most important tokens within each merged activation. This approach compresses along two orthogonal axes—samples and features—resulting in high compression ratios with minimal accuracy loss. Experimental results on CIFAR100 and Food101 datasets show that ADC consistently outperforms state-of-the-art methods, maintaining high accuracy even at extreme compression ratios.

## Method Summary
The method operates in a split learning setting where a Vision Transformer is partitioned between client and server at layer l=3. The client computes activations and CLS-token attention scores from the first three transformer blocks. ADC then performs K-means clustering on the attention score vectors to group similar samples, averaging their activations and labels. Within each merged activation, only the top-k tokens (ranked by the cluster centroid) are selected for transmission. The server receives the compressed activations, computes gradients, and sends them back for client update. The total compression ratio ξ is the product of batch and token factors, with optimal performance achieved when k/n = T/B = √ξ. Training continues until the cumulative communication cost reaches 10× the baseline requirement.

## Key Results
- ADC consistently outperforms state-of-the-art baselines (C3-SL, NSC-SL, SL-ACC) across all compression ratios on CIFAR100 and Food101.
- At ξ≈0.1, ADC achieves near-baseline accuracy on CIFAR100/DeiT-T while enabling 90% communication reduction.
- The balanced compression strategy (k/n = T/B = √ξ) provides the best accuracy-compression trade-off compared to extreme settings.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Reducing batch size by merging samples with similar attention distributions preserves semantic information while linearly reducing communication cost.
- **Mechanism:** The method extracts CLS-token attention scores from the client's final layer. It uses K-means to cluster these score vectors into $T$ groups and averages the activations (and labels) of samples within the same cluster. This replaces $B$ transmissions with $T$ aggregated transmissions.
- **Core assumption:** Samples with similar CLS-attention patterns encode redundant spatial information, allowing their representations to be averaged without destroying the class-discriminative features required by the server.
- **Evidence anchors:**
  - [Section 4]: "Each activation is assigned to its closest centroid... The new activations communicated to the server are then computed as cluster averages [Eq. 4]."
  - [Section 6.2.2]: Table 2 confirms that using "CLSscore" for clustering outperforms using raw CLS tokens or averaged tokens.
  - [Corpus]: General SL compression techniques (e.g., SL-ACC, NSC-SL) support activation reduction, but specific attention-based clustering is not evidenced in the provided corpus neighbors.
- **Break condition:** If the dataset has high intra-class variance where "similar attention" does not imply "similar features," averaging may blur distinct features, degrading accuracy.

### Mechanism 2
- **Claim:** Pruning tokens based on the aggregated cluster attention (centroids) acts as an effective importance filter, removing spatial noise while keeping task-critical features.
- **Mechanism:** After clustering, the method retains only the top-$k$ tokens corresponding to the highest values in the cluster centroid $C_i$. This reduces the dimensionality of the merged activation matrix from $n$ tokens to $k$ tokens before transmission.
- **Core assumption:** The CLS token's attention score serves as a reliable proxy for the importance of spatial tokens (patches) for the downstream classification task.
- **Evidence anchors:**
  - [Section 4]: "...discards the least meaningful tokens... by keeping only the most important tokens."
  - [Section 6.3]: Figure 8 visualizes that selected tokens focus on the primary object (high attention) while discarding background.
  - [Corpus]: LANCE (neighbor) supports the general concept of low-rank activation compression for efficiency, though via different means.
- **Break condition:** If critical features are distributed across low-attention background patches (e.g., context-dependent tasks), aggressive token selection will drop essential information.

### Mechanism 3
- **Claim:** Balancing compression across two orthogonal axes (batch and tokens) yields higher accuracy than aggressive compression on a single axis.
- **Mechanism:** The total compression ratio $\xi$ is the product of the batch factor ($T/B$) and token factor ($k/n$). The paper empirically finds that setting $k/n \approx T/B \approx \sqrt{\xi}$ minimizes accuracy loss compared to extreme settings (e.g., low batch compression, high token compression).
- **Core assumption:** The model's robustness to batch reduction and token reduction is roughly symmetric, allowing a balanced reduction strategy to optimize the trade-off space.
- **Evidence anchors:**
  - [Section 5.3]: "The results show that... the best performance is obtained when the compression factors from batch merging and token selection are equally balanced."
  - [Figure 3]: Heatmaps show a "ridge" of high accuracy along the diagonal where $T/B$ and $k/n$ are balanced.
  - [Corpus]: No direct corpus evidence supports this specific orthogonal balancing strategy.
- **Break condition:** If the batch size $B$ is small to begin with, the constraint $T < B$ limits the feasible range of batch compression, potentially forcing the balance toward token compression.

## Foundational Learning

- **Concept: Split Learning (SL)**
  - **Why needed here:** This is the distributed architecture being optimized. Understanding the "cut point" between client and server is essential to know where the compression (ADC) is injected.
  - **Quick check question:** Can you identify which side (client or server) performs the K-means clustering and which side receives the compressed activations?

- **Concept: Vision Transformer (ViT) Attention Maps**
  - **Why needed here:** The method relies entirely on interpreting the CLS token's attention to other patches. Without this, the "importance" metric for merging and pruning is undefined.
  - **Quick check question:** Does the CLS token attend to all patches equally, or does it learn to attend to specific class-relevant regions?

- **Concept: K-means Clustering**
  - **Why needed here:** This is the algorithmic core of the batch compression step.
  - **Quick check question:** How does the algorithm handle the creation of $T$ clusters when the batch might contain fewer than $T$ distinct samples?

## Architecture Onboarding

- **Component map:** Client (layers B₁ to Bₗ) → ADC Module (CLS attention extraction → K-means clustering → Activation averaging → Top-k token selection) → Server (layers Bₗ₊₁ to C → Classification head)
- **Critical path:** The forward pass must complete the attention calculation and clustering *before* transmission. The backward pass relies on the server computing gradients w.r.t. the compressed input, which are then upsampled/expanded (implicitly via gradient flow) to the client.
- **Design tradeoffs:**
  - **Split Point (l):** A deeper split point (higher l) improves ADC performance because attention maps become more semantically meaningful (Section 6.2.3).
  - **Compression Balance:** Choosing T/B vs k/n. The paper recommends √ξ, but extreme bandwidth constraints might require violating this.
- **Failure signatures:**
  - **Accuracy Collapse:** If ξ is too low (<0.05) and the balance is ignored.
  - **Stagnation:** If the CLS attention is uniform (e.g., early in training or on random noise), merging becomes random, acting as strong regularization that might prevent convergence.
- **First 3 experiments:**
  1. **Balance Validation:** Run a grid search over T/B and k/n for a fixed budget ξ=0.1 on a validation set to verify the diagonal "ridge" in performance (Fig 3).
  2. **Split Point Sensitivity:** Train DeiT-T with ADC at ξ=0.2, varying the split layer l from 3 to 9 to confirm performance improves with depth (Fig 7).
  3. **Cluster Visualization:** Extract and visualize images belonging to the same cluster to confirm they share semantic or structural similarity despite potentially different class labels (Fig 8).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the Attention-based Double Compression (ADC) framework perform under realistic wireless communication conditions, specifically noisy and fading channels?
- **Basis in paper:** [explicit] The conclusion states an aim to "extend the proposed framework to more realistic communication environments, including noisy and fading wireless channels, where robustness to signal degradation becomes essential."
- **Why unresolved:** The current experiments simulate communication constraints via bandwidth budgets but assume error-free transmission, ignoring physical channel imperfections common in edge computing.
- **What evidence would resolve it:** Evaluation of model convergence and accuracy when the compressed activations are transmitted over simulated channels with additive noise, fading, or packet loss.

### Open Question 2
- **Question:** Can the ADC framework be effectively adapted for multi-client collaborative training scenarios such as Federated Learning?
- **Basis in paper:** [explicit] The authors suggest that "applying the framework to multi-client scenarios such as Federated Learning could shed light on how collaborative and distributed training can leverage joint compression across clients."
- **Why unresolved:** The current implementation is limited to a single-client split learning setup; it is unknown how batch merging across decentralized, heterogeneous clients would affect aggregation or convergence.
- **What evidence would resolve it:** Implementation of ADC in a Federated Learning architecture, analyzing convergence speed and accuracy under non-IID data distributions across clients.

### Open Question 3
- **Question:** What is the computational and energy overhead of the K-means clustering step on resource-constrained edge devices compared to the energy saved by communication compression?
- **Basis in paper:** [inferred] The method relies on K-means clustering on the client side (Section 4) to merge activations. While the paper claims "no extra overhead" for generating attention scores, it does not quantify the computational cost or latency of the clustering algorithm itself.
- **Why unresolved:** Without measuring the computational cost of K-means, it is unclear if the energy saved from reduced transmission outweighs the energy consumed by the extra processing on the edge device.
- **What evidence would resolve it:** Profiling the latency, CPU/GPU utilization, and total energy consumption of the client-side ADC process on embedded hardware (e.g., NVIDIA Jetson or Raspberry Pi).

## Limitations

- The effectiveness of the method depends on the assumption that CLS-token attention scores reliably capture semantic similarity, which may break down with high intra-class variance.
- The paper does not provide detailed ablation studies on K-means initialization, distance metrics, or handling of empty clusters.
- The computational overhead of clustering and attention extraction on the client side is not quantified.

## Confidence

- **High Confidence:** The empirical results showing ADC outperforming baselines (C3-SL, NSC-SL, SL-ACC) at all tested compression ratios on CIFAR100 and Food101.
- **Medium Confidence:** The claim that balancing compression across batch and token axes is optimal. While Figure 3 shows a performance ridge along the diagonal, the paper does not provide theoretical justification or systematic ablation across a wider range of ξ values.
- **Low Confidence:** The assertion that ADC is robust to the choice of split point. The paper only reports results for layer 3 and one experiment varying l, without exploring the full trade-off between attention quality and model capacity on the client side.

## Next Checks

1. **Cluster Quality and Class Alignment:** For a held-out validation set, extract the K-means cluster assignments and visualize (a) the distribution of true class labels within each cluster, and (b) a montage of images from a single cluster. This will confirm whether the method is merging semantically similar samples or introducing label noise that could degrade accuracy.

2. **Gradient Flow Integrity:** Instrument the backward pass to track the gradient norm before and after the compression module. If the norm collapses or spikes at high compression, it indicates that the gradient expansion from merged/selected activations is unstable, which could explain accuracy drops not captured by forward metrics alone.

3. **Attention Map Consistency Across Layers:** For the same batch, extract and visualize the CLS attention maps at layers 1, 3, and 5. This will verify the paper’s implicit claim that attention becomes more semantically meaningful at deeper layers, justifying the choice of split point and the reliability of the attention-based importance scores.