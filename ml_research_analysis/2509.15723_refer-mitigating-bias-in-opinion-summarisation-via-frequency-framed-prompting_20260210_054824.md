---
ver: rpa2
title: 'REFER: Mitigating Bias in Opinion Summarisation via Frequency Framed Prompting'
arxiv_id: '2509.15723'
source_url: https://arxiv.org/abs/2509.15723
tags:
- refer
- frequency
- prompting
- language
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses bias in opinion summarisation by large language
  models (LLMs), where generated summaries often fail to proportionally represent
  diverse viewpoints. Drawing from cognitive science research showing that frequency-based
  representations reduce human statistical reasoning biases, the authors introduce
  REFER (Frequency Framed Prompting), which explicitly instructs models to first quantify
  opinion distributions using concrete frequency information before generating balanced
  summaries.
---

# REFER: Mitigating Bias in Opinion Summarisation via Frequency Framed Prompting

## Quick Facts
- arXiv ID: 2509.15723
- Source URL: https://arxiv.org/abs/2509.15723
- Reference count: 26
- Primary result: Introduces frequency-framed prompting to reduce bias in LLM opinion summarisation by explicitly quantifying opinion distributions before generating balanced summaries

## Executive Summary
This paper addresses bias in opinion summarisation by large language models, where generated summaries often fail to proportionally represent diverse viewpoints. The authors introduce REFER (Frequency Framed Prompting), which draws from cognitive science research showing that frequency-based representations reduce human statistical reasoning biases. By explicitly instructing models to first quantify opinion distributions using concrete frequency information before generating balanced summaries, REFER significantly improves fairness in opinion summarisation across multiple datasets, models, and prompting frameworks.

The approach demonstrates consistent improvements across fairness metrics (SPD, BUR, UER, SOF) and shows larger effects than differences between base prompting frameworks. The study finds that REFER is particularly effective for larger models and when combined with stronger reasoning instructions like Chain-of-Thought, suggesting that explicit frequency framing provides valuable structure for LLM reasoning about opinion distributions.

## Method Summary
REFER introduces a two-stage prompting approach where models first quantify opinion distributions using explicit frequency information before generating balanced summaries. The method draws from cognitive science research showing that frequency-based representations reduce human statistical reasoning biases. The approach was tested across multiple datasets (BeerAdvocate, Amazon Electronics, Rotten Tomatoes), models (GPT-4, GPT-3.5, Llama-3, Mistral), and prompting frameworks (zero-shot, few-shot, Chain-of-Thought). Systematic experiments demonstrated that REFER significantly improves fairness metrics compared to standard prompting approaches, with particularly strong results when combined with Chain-of-Thought reasoning.

## Key Results
- REFER significantly improves fairness in opinion summarisation across multiple datasets, models, and prompting frameworks
- The approach achieves consistent improvements across fairness metrics (SPD, BUR, UER, SOF)
- REFER shows larger effects than differences between base prompting frameworks
- Effectiveness is particularly pronounced for larger models and when combined with Chain-of-Thought reasoning

## Why This Works (Mechanism)
REFER works by explicitly framing the summarisation task in terms of frequency-based representations, which helps models reason about opinion distributions more objectively. The cognitive science foundation suggests that humans make fewer statistical reasoning errors when presented with frequency formats rather than probability formats, and this principle appears to extend to LLM reasoning as well. By requiring models to first quantify how often different opinions appear before generating summaries, REFER provides a structured approach that counteracts the tendency of models to overemphasize certain viewpoints.

## Foundational Learning

**Frequency-Based Representation** - why needed: Reduces cognitive biases in statistical reasoning by making distributions more concrete and explicit; quick check: Verify that frequency framing explicitly states opinion counts before summary generation.

**Chain-of-Thought Reasoning** - why needed: Provides step-by-step reasoning that helps models process complex distributional information; quick check: Confirm that CoT instructions are included in the prompting framework.

**Fairness Metrics (SPD, BUR, UER, SOF)** - why needed: Quantify different aspects of bias in opinion summarisation to measure improvement; quick check: Ensure all four metrics are calculated and reported for evaluation.

**Multi-Model Evaluation** - why needed: Demonstrates generalizability across different LLM architectures and capabilities; quick check: Verify experiments include both large and smaller models.

## Architecture Onboarding

**Component Map:** Opinion Distribution Quantification -> Frequency Framing -> Balanced Summary Generation -> Fairness Evaluation

**Critical Path:** The method requires explicit quantification of opinion frequencies before summary generation, making the frequency framing stage essential for success.

**Design Tradeoffs:** The approach trades computational efficiency for improved fairness, as the two-stage process requires additional reasoning steps and may increase latency.

**Failure Signatures:** If frequency framing is incomplete or unclear, models may still produce biased summaries; effectiveness may decrease with very short or ambiguous opinion texts.

**3 First Experiments:**
1. Compare REFER performance across different model sizes (GPT-4 vs GPT-3.5 vs Llama-3) to verify size-dependent effects
2. Test REFER with and without Chain-of-Thought reasoning to isolate the contribution of explicit reasoning instructions
3. Evaluate REFER on multi-utterance summaries to assess scalability to more complex opinion distributions

## Open Questions the Paper Calls Out
The paper does not explicitly call out additional open questions beyond those addressed in the study.

## Limitations
- The approach's effectiveness depends on assumptions about frequency-based representation reducing bias, primarily supported by human reasoning research
- The mechanism by which frequency framing reduces LLM bias remains partially unexplained
- Effectiveness for multi-utterance summaries with complex opinion distributions is untested
- Computational overhead may be substantial for real-world deployment scenarios

## Confidence

**Major Claim Confidence Labels:**
- Frequency framing consistently reduces bias across multiple models and datasets: **High**
- The effect is larger for bigger models and when combined with CoT reasoning: **Medium**
- Frequency framing is more effective than differences between base prompting frameworks: **Medium**
- The approach generalizes well to other types of summarization tasks: **Low**

## Next Checks

1. Test REFER's effectiveness on multi-utterance opinion summaries where opinion distribution complexity increases
2. Conduct ablation studies to isolate the specific components of frequency framing that contribute to bias reduction
3. Evaluate computational efficiency and real-time performance implications of REFER compared to baseline approaches