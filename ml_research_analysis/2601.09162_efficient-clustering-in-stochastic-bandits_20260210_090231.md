---
ver: rpa2
title: Efficient Clustering in Stochastic Bandits
arxiv_id: '2601.09162'
source_url: https://arxiv.org/abs/2601.09162
tags:
- lemma
- hence
- algorithm
- clustering
- problem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the Bandit Clustering (BC) problem, where the
  goal is to cluster a collection of data sequences (arms) into groups by sequentially
  sampling arms adaptively, ensuring a fixed error probability at the stopping time.
  Unlike existing work that assumes Gaussian-distributed arms, the authors study a
  broader class of vector-parametric distributions satisfying mild regularity conditions.
---

# Efficient Clustering in Stochastic Bandits

## Quick Facts
- arXiv ID: 2601.09162
- Source URL: https://arxiv.org/abs/2601.09162
- Reference count: 40
- One-line primary result: EBC achieves the same asymptotic slope as the theoretical lower bound, proving its asymptotic optimality

## Executive Summary
This paper introduces the Efficient Bandit Clustering (EBC) algorithm for clustering data sequences (arms) into groups through adaptive sequential sampling with a fixed error probability. Unlike previous work assuming Gaussian arms, EBC works for a broader class of vector-parametric distributions satisfying mild regularity conditions. The algorithm replaces full optimization at each step with a single gradient step toward the optimal value, achieving computational efficiency while maintaining asymptotic optimality. Simulations demonstrate EBC and its heuristic variant EBC-H outperform existing approaches in both sample complexity and runtime.

## Method Summary
EBC addresses the Bandit Clustering problem where M arms following vector-parametric distributions must be clustered into K groups through sequential sampling. The algorithm uses forced exploration (sampling the least-pulled arm if its count is below √(t/M)) combined with gradient tracking to update sampling proportions. At each step, it computes the gradient of the weighted KL-divergence objective, performs a projected gradient ascent update, and selects arms based on tracking error. The algorithm stops when a Generalized Likelihood Ratio test statistic exceeds a threshold calibrated for δ-Probably Correct guarantees. A heuristic variant EBC-H simplifies the sampling rule while showing slightly better empirical performance.

## Key Results
- EBC achieves the same asymptotic slope as the theoretical lower bound T*(θ), proving asymptotic optimality
- Simulations on synthetic and real-world datasets show EBC and EBC-H outperform existing approaches in both sample complexity and runtime
- The algorithm works for a broader class of vector-parametric distributions beyond Gaussian, satisfying mild regularity conditions

## Why This Works (Mechanism)

### Mechanism 1
Replacing full sup-inf optimization with a single gradient step per iteration achieves computational efficiency while preserving asymptotic optimality. At each time t, compute the gradient g_t of the inner infimum function ψ(w, θ̂(t)) at the current estimate w(t-1), then perform projected gradient ascent to update w(t). The gradient is computed via Danskin's theorem as the KL-divergences to the closest alternative instance. Arm selection tracks the averaged estimate w̄(t). Core assumption: ψ(·,·) is continuous (Lemma 1 guarantees this under Assumption 5's uniform KL-divergence continuity), and parameter estimates converge to true parameters.

### Mechanism 2
Forced exploration at O(√t) rate ensures parameter estimate convergence even under adaptive sampling. Before gradient-based selection, check if any arm has fewer than √(t/M) samples. If so, select the least-sampled arm. This guarantees minimum exploration independent of the gradient tracking mechanism. Core assumption: The MLE θ̂_m(t) converges r-quickly to θ_m, which requires Assumption 2 (finite third moment of score function) and Assumption 4 (positive definite Hessian lower bound σ² > 0).

### Mechanism 3
Generalized Likelihood Ratio (GLR) stopping rule with calibrated threshold ensures δ-Probably Correct clustering. Test statistic Z(t) = t·ψ(N(t)/t, θ̂(t)) compares the estimated instance against all alternative clustering hypotheses. The threshold β(δ,t) incorporates Fisher information, dimensionality, and a correction term W^ε_m(t) to control Type I error via a non-negative martingale construction. Core assumption: Assumptions 1, 3, and 4 ensure the martingale bound holds; Ville's inequality applies to the constructed martingale M(t).

## Foundational Learning

- **Concept: KL Divergence and Information Geometry**
  - Why needed here: The core objective ψ(w,θ) involves weighted KL-divergences between the true and alternative parameter instances. Understanding how KL-divergence measures distinguishability is essential for grasping the lower bound and stopping criterion.
  - Quick check question: Given two Gaussian distributions N(μ₁,σ²) and N(μ₂,σ²), write the KL-divergence formula and explain why it increases with |μ₁-μ₂|.

- **Concept: Single Linkage Clustering (SLINK)**
  - Why needed here: The ground truth clusters are defined via SLINK on the parameter vectors. The algorithm's output applies SLINK to θ̂(τ_δ), so understanding hierarchical merging based on minimum pairwise distance is critical.
  - Quick check question: Given points at positions 0, 1, 3, 7 with distance threshold 2, which points merge first and what are the final clusters?

- **Concept: Martingale Theory and Concentration Inequalities**
  - Why needed here: The δ-PC proof relies on constructing a non-negative martingale M(t) and applying Ville's inequality. The threshold derivation uses eigenvalue bounds on the Hessian to control tail probabilities.
  - Quick check question: State Ville's inequality for a non-negative supermartingale and explain why it bounds the probability that M(t) exceeds a threshold c·E[M(0)].

## Architecture Onboarding

- **Component map:** Forced exploration -> Gradient computation -> Projected gradient update -> Arm tracking selector -> Stopping criterion evaluator -> Declaration module

- **Critical path:** Initialize w(0) randomly in simplex → Loop until Z(t) ≥ β(δ,t): (1) Check forced exploration condition, (2) If satisfied, compute gradient via inf-problem, (3) Update w(t) via projected step, (4) Update w̄(t), (5) Select arm via tracking, (6) Observe sample and update θ̂, (7) Recompute Z(t) and β(δ,t) → On stop: output SLINK(θ̂(τ_δ))

- **Design tradeoffs:**
  - **EBC vs EBC-H:** EBC has proven asymptotic optimality; EBC-H uses gradient at N(t)/t instead of w̄(t) and selects arm with max KL component (Eq. 2), showing slightly better empirical performance but lacks theoretical sample complexity guarantee.
  - **Step size η:** Too large causes oscillation; too small slows convergence. Paper suggests η = c/√B(t) with batch size B(t) = ε₂t.
  - **Compact parameter space Θ:** Smaller bounds (e.g., [-5,5]² vs [-500,500]²) improve performance by reducing threshold penalty (see Table I, Fig. 2).

- **Failure signatures:**
  1. **Cluster merging error:** If forced exploration is insufficient, θ̂_m(t) may not converge, causing wrong SLINK merges. Symptom: empirical error rate exceeds δ as t grows.
  2. **Non-termination:** If threshold β(δ,t) grows faster than Z(t) (possible with poor Θ bounds), algorithm may not stop. Check threshold formula for explosion.
  3. **Gradient instability:** If KL-divergence computation returns NaN/Inf (numerical issues in high dimensions), sampling becomes random. Validate MLE stability.

- **First 3 experiments:**
  1. **Synthetic validation with known optimum:** Replicate Fig. 2 setup (6 arms, 3 clusters, 2D Gaussian). Plot E[τ_δ] vs log(1/δ) for EBC, EBC-H, and round-robin baseline. Verify slope matches theoretical lower bound T*(θ).
  2. **Scalability stress test:** Fix K=3 clusters but increase M from 6 to 30 arms. Measure per-sample runtime (Table II pattern) and check if gradient computation remains O(M) vs ATBOC's superlinear growth.
  3. **Distribution robustness check:** Test exponential family distributions (Poisson, Bernoulli) beyond Gaussian. Verify Assumption 2 holds and compare δ-PC violation rates vs nominal δ across 1000 trials.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does EBC-H have formal asymptotic optimality guarantees, and if so, what are the precise sample complexity bounds?
- Basis in paper: [explicit] "Sample complexity guarantee of EBC-H is not analyzed in this work."
- Why unresolved: EBC-H empirically outperforms EBC in both sample complexity and runtime, yet its theoretical properties remain uncharacterized.
- What evidence would resolve it: A proof establishing upper bounds on E[τ_δ(EBC-H)] relative to the lower bound T*(θ), or counterexamples where EBC-H fails to achieve asymptotic optimality.

### Open Question 2
- Question: Is the optimal arm pull proportion set S*(θ) a singleton for the Bandit Clustering problem, and under what conditions?
- Basis in paper: [explicit] Remark 2 states "there is no evidence to say S*(θ) is a singleton" for the BC problem, unlike the BAI setting where uniqueness is proven.
- Why unresolved: The convergence analysis of EBC relies on tracking sequences converging to optimal proportions, but whether these proportions are unique affects algorithm design and theoretical guarantees.
- What evidence would resolve it: Either a proof showing uniqueness under the stated regularity conditions, or a counterexample demonstrating multiple optimal solutions.

### Open Question 3
- Question: Can the theory developed for vector-parametric BC extend to the multidimensional efficient Best Arm Identification problem where S*(θ) may not be a singleton?
- Basis in paper: [explicit] Remark 2 notes the theory "can be used to extend [15] to the multidimensional version of the efficient BAI."
- Why unresolved: The gradient-tracking approach developed for BC could potentially address multidimensional BAI, but this connection has not been formally established.
- What evidence would resolve it: A modified algorithm and proof showing asymptotic optimality for multidimensional BAI with non-unique optimal proportions.

### Open Question 4
- Question: How does the choice of parameter space volume |Θ| and the ε parameter in the threshold β(δ,t) systematically affect empirical sample complexity?
- Basis in paper: [inferred] Figures 2 and 3 show performance varies significantly with |Θ| and ε values, but no theoretical guidance on optimal selection is provided.
- Why unresolved: The threshold contains terms dependent on |Θ| and ε that affect stopping behavior, yet practical guidelines for tuning these hyperparameters are absent.
- What evidence would resolve it: Theoretical analysis of the sensitivity of sample complexity to these parameters, or adaptive methods that eliminate manual tuning.

## Limitations
- The gradient-based approach relies on accurate computation of the inner infimum λ*, which becomes computationally challenging as the number of alternative clustering hypotheses grows exponentially with M.
- The forced exploration schedule √(t/M) ensures parameter convergence but may be conservative for well-separated clusters.
- The asymptotic optimality proof assumes exact gradient computation and continuous ψ function, but finite-sample behavior depends on learning rate choice and numerical precision.

## Confidence
- **High confidence:** The asymptotic optimality result (Theorem 1) and δ-PC guarantee (Theorem 2) follow rigorously from the constructed martingale and gradient tracking framework. The empirical superiority over round-robin and ATBOC baselines is clearly demonstrated across multiple synthetic and real datasets.
- **Medium confidence:** The EBC-H variant's superior empirical performance lacks theoretical justification for sample complexity. The choice of learning rate schedule η = c·√(B(t)) and batch size B(t) = ε₂·t appears heuristic, with parameter values not specified.
- **Low confidence:** The computational efficiency claims rely on gradient computation being O(M) versus ATBOC's optimization cost, but exact runtime scaling with problem dimension d and cluster complexity K remains unclear.

## Next Checks
1. **Parameter sensitivity analysis:** Systematically vary learning rate η, exploration parameter ε₂, and threshold ε to quantify their impact on both finite-sample performance and computational efficiency across multiple problem instances.
2. **Distribution robustness verification:** Extend experiments beyond Gaussian distributions to test EBC's performance on Poisson, Bernoulli, and heavy-tailed distributions, explicitly verifying Assumption 2 (finite score moments) and measuring δ-PC violation rates.
3. **Gradient computation scaling:** Benchmark λ* optimization runtime as M increases from 6 to 50 arms with fixed K=3, comparing exact enumeration against efficient approximate methods for large Alt(θ) spaces.