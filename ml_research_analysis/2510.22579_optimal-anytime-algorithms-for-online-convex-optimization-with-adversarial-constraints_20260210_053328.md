---
ver: rpa2
title: Optimal Anytime Algorithms for Online Convex Optimization with Adversarial
  Constraints
arxiv_id: '2510.22579'
source_url: https://arxiv.org/abs/2510.22579
tags:
- algorithm
- regret
- functions
- online
- cost
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel anytime online algorithm for Constrained
  Online Convex Optimization (COCO), where an agent must learn a sequence of adversarial
  convex cost functions while approximately satisfying adversarial online convex constraints.
  The core technical contribution is the use of time-varying Lyapunov functions to
  keep track of constraint violations, overcoming the monotonicity limitation of prior
  works that used fixed horizon-dependent Lyapunov functions.
---

# Optimal Anytime Algorithms for Online Convex Optimization with Adversarial Constraints

## Quick Facts
- arXiv ID: 2510.22579
- Source URL: https://arxiv.org/abs/2510.22579
- Reference count: 40
- Proposes the first optimal anytime algorithm for COCO achieving O(√t) regret and O(√t) cumulative constraint violation without the doubling trick.

## Executive Summary
This paper addresses the Constrained Online Convex Optimization (COCO) problem with adversarial constraints and unknown horizon. Prior anytime algorithms suffered from suboptimal O(t^{1/4}) regret bounds due to the doubling trick. The authors overcome this limitation by introducing time-varying Lyapunov functions with a multiplicative factor in the virtual queue update. This approach maintains the monotonicity property required for analysis while achieving optimal O(√t) regret and cumulative constraint violation bounds simultaneously. The algorithm uses surrogate cost construction and AdaGrad as the base learner, naturally extending to dynamic regret and optimistic settings without horizon knowledge.

## Method Summary
The algorithm preprocesses costs and constraints by scaling with α = 1/(2GD) and applying ReLU to constraints. It maintains a virtual queue Q(t) with multiplicative updates Q(t) = (λ_{t−1}/λₜ)Q(t−1) + g̃ₜ(xₜ), where λₜ = 1/[4√t√(log t+1)(log log t+1+1)] ensures ∑λ²ₜ < 1/4. Surrogate costs are constructed as f̂ₜ(x) = f̃ₜ(x) + Φ′ₜ(Q(t))g̃ₜ(x) with Φ′ₜ(z) = λₜe^{λₜz}. AdaGrad with adaptive step sizes ηₜ = √(2D²)/√(∑_{τ=1}^{t}||∇τ||²₂) is applied to these surrogate costs. The multiplicative queue update compensates for decreasing λₜ to restore monotonicity of Φₜ(Q(t)), enabling anytime analysis.

## Key Results
- Achieves optimal O(√t) regret and O(√t) cumulative constraint violation for any t ≥ 1 without doubling trick
- Extends naturally to dynamic regret and optimistic settings with adaptive bounds
- Outperforms fixed-horizon baselines and doubling trick variants in online shortest path experiments
- Maintains parameter-free operation through AdaGrad without horizon knowledge

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Time-varying Lyapunov functions with multiplicative queue update restore monotonicity for anytime bounds.
- **Mechanism:** Define Φₜ(x) = e^{λₜx} − 1 with decreasing λₜ. Update Q(t) = (λ_{t−1}/λₜ)Q(t−1) + g̃ₜ(xₜ). Since λ_{t−1} ≥ λₜ, the factor ≥ 1 compensates for shrinking Φₜ(x), ensuring Φₜ(Q(t)) ≥ Φ_{t−1}(Q(t−1)) while maintaining Q(t) as an upper bound on cumulative violation.
- **Core assumption:** Multiplicative factor precisely offsets pointwise decrease of Φₜ(x) in t to restore monotonicity.
- **Evidence anchors:** [abstract] "time-varying Lyapunov functions... monotonicity, on which the prior proofs rest, no longer hold... introducing a new analytical technique"; [section 4.3.1] Equation (6) Q(t) recursion; definition