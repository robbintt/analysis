---
ver: rpa2
title: 'Milco: Learned Sparse Retrieval Across Languages via a Multilingual Connector'
arxiv_id: '2510.00671'
source_url: https://arxiv.org/abs/2510.00671
tags:
- milco
- sparse
- multilingual
- retrieval
- english
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MILCO, a multilingual learned sparse retrieval
  architecture that maps queries and documents from multiple languages into a shared
  English lexical space via a multilingual connector. It employs a two-stage training
  approach combining Sparse Alignment Pretraining with contrastive training to avoid
  semantic collapse while maintaining transparency.
---

# Milco: Learned Sparse Retrieval Across Languages via a Multilingual Connector

## Quick Facts
- **arXiv ID**: 2510.00671
- **Source URL**: https://arxiv.org/abs/2510.00671
- **Authors**: Thong Nguyen; Yibin Lei; Jia-Huei Ju; Eugene Yang; Andrew Yates
- **Reference count**: 40
- **Primary result**: State-of-the-art multilingual learned sparse retrieval across 39 languages with 34.1% nDCG@10 improvement on MIRACL

## Executive Summary
This paper introduces MILCO, a multilingual learned sparse retrieval architecture that maps queries and documents from multiple languages into a shared English lexical space via a multilingual connector. MILCO employs a two-stage training approach combining Sparse Alignment Pretraining with contrastive training to avoid semantic collapse while maintaining transparency. A novel LexEcho head augments the English lexical view with a source-language view via an [ECHO] token to preserve uncommon entities. MILCO achieves state-of-the-art multilingual and cross-lingual retrieval performance across 39 languages, outperforming leading baselines including Qwen3-Embed and BGE-M3 by significant margins (e.g., +34.1% nDCG@10 on MIRACL). It also supports dynamic efficiency through post-hoc pruning, maintaining high effectiveness with only 30 active dimensions per document.

## Method Summary
MILCO addresses multilingual learned sparse retrieval by mapping non-English text into a shared English lexical space. The architecture uses a BGE-M3 encoder followed by an MLP connector and a LexEcho head that produces both English lexical tokens and source-language tokens via an [ECHO] token. Training occurs in two stages: first, Sparse Alignment Pretraining (SAP) aligns non-English sentences to English SPLADE-v3 representations using SMSE loss on decoded logits; second, Sparse Contrastive Training (SCT) employs KL distillation with ℓ1 regularization. The LexEcho head enables dual-view scoring where English tokens provide semantic coverage and source tokens preserve rare entities. MILCO is trained on 594M bitext pairs and 1.4M contrastive queries, achieving state-of-the-art performance across 39 languages with interpretable, sparse representations.

## Key Results
- MILCO achieves 34.1% nDCG@10 improvement over Qwen3-Embed on MIRACL, the largest multilingual retrieval benchmark
- Outperforms BGE-M3 by 27.2% nDCG@10 on MIRACL and 15.2% on MTEB v2 while being 3.3x smaller
- Demonstrates strong cross-lingual retrieval with 23.9% nDCG@10 on MIRACL's cross-lingual subset without any cross-lingual training data
- Supports dynamic efficiency through post-hoc pruning, maintaining high effectiveness with only 30 active dimensions per document

## Why This Works (Mechanism)
MILCO works by creating a shared English lexical space that preserves semantic meaning across languages while maintaining sparsity and interpretability. The two-stage training approach is crucial: SAP prevents semantic collapse by aligning representations to English SPLADE-v3, while SCT refines the model using contrastive supervision. The LexEcho head's dual-view scoring mechanism is key - the English view captures semantic content while the source view via [ECHO] token preserves rare entities and proper nouns that might be lost in translation. This architectural choice enables both high effectiveness and transparency, allowing inspection of which tokens contribute to retrieval decisions. The English pivot language selection provides access to rich resources and consistent tokenization, though the architecture could support other pivots.

## Foundational Learning
**Sparse Alignment Pretraining (SAP)**: Aligning non-English sentences to English SPLADE-v3 representations using SMSE loss on decoded logits. *Why needed*: Prevents semantic collapse during multilingual mapping. *Quick check*: Inspect output tokens for semantic relevance to input after SAP stage.

**[ECHO] Token Mechanism**: A special token that generates source-language tokens alongside English tokens in the LexEcho head. *Why needed*: Preserves rare entities and proper nouns that might be lost when mapping to English. *Quick check*: Verify source-view weights are non-zero for important source tokens.

**Dual-View Scoring**: Combining max-pooled English logits with weighted source tokens from the [ECHO] head. *Why needed*: Balances semantic coverage with entity preservation across languages. *Quick check*: Compare retrieval performance with/without dual-view scoring on non-Latin scripts.

**Mass-Based Pruning**: Post-hoc pruning algorithm that removes dimensions based on their contribution to retrieval effectiveness. *Why needed*: Enables dynamic efficiency without retraining. *Quick check*: Measure nDCG@10 degradation at different pruning ratios.

**KL Distillation with ℓ1 Regularization**: Contrastive training objective that transfers knowledge from teacher reranker while encouraging sparsity. *Why needed*: Refines representations using relevance supervision while maintaining sparse outputs. *Quick check*: Verify output sparsity levels (tokens per query/document) match expected values.

## Architecture Onboarding

**Component map**: BGE-M3 encoder -> MLP connector -> LexEcho head (English MLM + [ECHO] source view)

**Critical path**: Query encoding path: Input query -> BGE-M3 -> MLP connector -> LexEcho head -> English logits + [ECHO] tokens -> Dual-view scoring -> Retrieval

**Design tradeoffs**: English pivot language provides rich resources but may lose some language-specific semantics; dual-view scoring adds complexity but preserves rare entities; post-hoc pruning enables efficiency but requires careful implementation

**Failure signatures**: 
- Semantic collapse (random/uninterpretable tokens) - caused by skipping SAP stage
- Missing rare entities in non-Latin scripts - LexEcho source view not properly weighted
- Poor cross-lingual performance - vocabulary mismatch between languages

**First experiments**:
1. Train SAP stage on OPUS bitext for 2 epochs and inspect output tokens for semantic relevance
2. Implement and test dual-view scoring mechanism on non-Latin script queries
3. Evaluate cross-lingual retrieval on MIRACL dev set without any cross-lingual training examples

## Open Questions the Paper Calls Out
**Open Question 1**: Would utilizing a non-English pivot language for the Multilingual Connector yield better retrieval performance for specific language pairs or clusters? *Basis*: The authors state they selected English due to rich resources but note no architectural restriction on pivot language. *Unresolved*: The trade-offs regarding semantic loss or alignment quality for other potential pivots remain unexplored.

**Open Question 2**: Does incorporating task-specific instruction tuning improve MILCO's performance on general English benchmarks like BEIR? *Basis*: The authors attribute the performance gap on BEIR to Qwen3-0.6B's instruction tuning advantage. *Unresolved*: The current model uses a standard bi-encoder approach without task prompts, leaving the potential benefit of instructions untested.

**Open Question 3**: Can native long-context pretraining (e.g., 8192 tokens) improve performance on MLDR compared to the current passage-splitting strategy? *Basis*: The paper notes MILCO is trained with a 512-token limit and handles MLDR by splitting documents. *Unresolved*: It is unclear if chunking introduces boundary errors or loses global context that native long-context modeling could capture.

## Limitations
- The MLP connector architecture remains underspecified (number of layers, hidden dimensions)
- LexEcho head's source-view weighting mechanism details are not fully described
- Post-hoc pruning algorithm (mass-based) is mentioned but not detailed in implementation
- Limited qualitative evidence for semantic interpretability claims beyond token inspection

## Confidence
- **High confidence**: Retrieval effectiveness claims on MIRACL and MTEB v2 datasets with statistical significance
- **Medium confidence**: Semantic interpretability claims and avoidance of collapse with qualitative examples
- **Low confidence**: Efficiency and pruning claims due to incomplete post-hoc pruning specification

## Next Checks
1. **Reproduce SAP stage**: Train MILCO on OPUS bitext for 2 epochs and inspect output tokens for semantic relevance and diversity to verify avoidance of collapse
2. **Validate LexEcho implementation**: Confirm that [ECHO] token source-view weights correctly preserve rare entities by comparing retrieval performance with/without the dual-view scoring on non-Latin scripts
3. **Benchmark cross-lingual transfer**: Evaluate MILCO's cross-lingual performance on MIRACL without any cross-lingual training examples to verify the multilingual connector's effectiveness