---
ver: rpa2
title: 'SSM-CGM: Interpretable State-Space Forecasting Model of Continuous Glucose
  Monitoring for Personalized Diabetes Management'
arxiv_id: '2510.04386'
source_url: https://arxiv.org/abs/2510.04386
tags:
- diabetes
- glucose
- forecasting
- figure
- ssm-cgm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SSM-CGM improves short-term CGM forecasting by 2-7% over a Temporal
  Fusion Transformer baseline, achieving MAE reductions from 6.07 to 5.97 mg/dL (12h
  context) to 5.40 mg/dL (48h context). The Mamba-based state-space model enables
  interpretability through variable selection (revealing heart rate, respiration,
  and meal flags as key predictors) and temporal attribution (showing recent history
  dominates while preserving individual-specific lags).
---

# SSM-CGM: Interpretable State-Space Forecasting Model of Continuous Glucose Monitoring for Personalized Diabetes Management

## Quick Facts
- arXiv ID: 2510.04386
- Source URL: https://arxiv.org/abs/2510.04386
- Reference count: 40
- SSM-CGM improves short-term CGM forecasting by 2-7% over Temporal Fusion Transformer baseline, achieving MAE reductions from 6.07 to 5.97 mg/dL (12h context) to 5.40 mg/dL (48h context).

## Executive Summary
SSM-CGM introduces a Mamba-based state-space model for continuous glucose monitoring forecasting that achieves 2-7% accuracy improvements over Temporal Fusion Transformer baselines. The model enables interpretability through variable selection networks that reveal heart rate, respiration, and meal flags as key predictors, and temporal attribution that shows recent history dominates while preserving individual-specific lags. Counterfactual forecasting demonstrates that physiological interventions (e.g., +2 SD heart rate increases) produce physiologically plausible glucose changes that correlate with cardiovascular and metabolic health markers.

## Method Summary
SSM-CGM replaces LSTM/attention mechanisms in Temporal Fusion Transformers with selective state-space models (Mamba) for efficient long-context processing. The architecture incorporates Variable Selection Networks for interpretable covariate fusion and derives hidden attention from SSM state unrolling for temporal attribution. The model is trained on AI-READI cohort data (741 individuals) using quantile loss for probabilistic forecasting, with meal detection performed via a Dilated CNN + Bi-LSTM model. Key innovations include MES-style Mamba blocks with shared value/readout projections and counterfactual forecasting via sequential g-formula.

## Key Results
- Achieves 2-7% MAE reduction over TFT baseline (5.97→5.40 mg/dL across 12h→48h contexts)
- Variable selection reveals heart rate, respiration, and meal flags as dominant predictors
- Hidden attention shows recent history dominates but preserves individual-specific temporal patterns
- Counterfactual interventions (+2 SD heart rate, nighttime respiration) produce physiologically plausible glucose changes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Replacing LSTM/attention with selective state-space models (Mamba) improves long-context CGM forecasting efficiency while maintaining accuracy.
- Mechanism: The selective SSM uses a learned time-step parameter (Δt) that modulates state transitions—compressing or expanding the effective temporal resolution per input. This allows the model to "remember" salient physiological events (e.g., meal-induced glucose rises) over multi-hour windows without O(L²) attention cost.
- Core assumption: CGM dynamics contain both short-term autoregressive patterns and longer-range circadian/behavioral dependencies that benefit from extended context.
- Evidence anchors:
  - [abstract] "Mamba-based neural state-space forecasting model... improves short-term accuracy over a Temporal Fusion Transformer baseline"
  - [section 2, p. 2] "CGM dynamics span hours to days, requiring long-context, low-latency models. TFT is widely used; yet sequential LSTMs and O(L²) attention can be suboptimal for long-context, online forecasting."
  - [corpus] Weak direct corpus support—no neighboring papers explicitly compare Mamba/SSM to transformers for CGM; most related work uses transformers or LSTMs.
- Break condition: If glucose dynamics were dominated by sub-hour noise with negligible longer-range structure, the gains from selective SSM over simpler autoregressive models would diminish.

### Mechanism 2
- Claim: Variable Selection Networks (VSNs) provide interpretable, per-timestep importance weights over heterogeneous covariates, improving fusion and personalization.
- Mechanism: VSNs compute softmax-normalized weights (αi,t) over input variables at each time step, conditioned on a static context vector derived from participant traits (age, diabetes status, etc.). This allows the model to adaptively upweight relevant signals (e.g., meal flags during postprandial periods, heart rate during activity).
- Core assumption: Different covariates have varying predictive relevance depending on context (time of day, individual physiology, recent events).
- Evidence anchors:
  - [abstract] "adds interpretability through variable selection and temporal attribution"
  - [section 3, p. 4] "averages over time/participants indicate that past/future wearable covariates strongly help predictions, especially meal flags, stress levels, heart/respiration rates"
  - [corpus] AttenGluco (neighbor paper) uses transformer attention for multimodal CGM forecasting on AI-READI, but does not report explicit VSN-style variable importance.
- Break condition: If all covariates contributed uniformly across contexts, VSN weights would flatten to near-uniform distributions, reducing interpretability value.

### Mechanism 3
- Claim: Hidden attention derived from SSM state unrolling reveals which historical lags most influence each forecast, enabling temporal attribution without explicit attention layers.
- Mechanism: By unrolling the SSM recurrence (zℓ = Σj≤ℓ Kℓj xj), the kernel Kℓj captures how much each past input xj contributes to output zℓ. Normalizing these kernels yields attention-like weights (αℓj) that expose "when" the model attended to history.
- Core assumption: The SSM state encodes a compressed summary of past inputs that can be decomposed into interpretable lag contributions.
- Evidence anchors:
  - [section 2, p. 3] "Inspired by the Hidden Attention of Mamba [18], we adapt hidden attention to time-series forecasting by unrolling the linear state update... This yields a causal convolution with kernel Kℓj, inducing attention-like weights over past lags"
  - [section 3, p. 4] "As expected of smooth CGM dynamics, recent history dominated, but individuals showed distinctive peaks at specific lags"
  - [corpus] No corpus papers explicitly derive hidden attention from SSM dynamics; interpretability in neighbors typically uses standard attention weights or SHAP.
- Break condition: If SSM states become too diffuse (near-uniform decay across all lags), hidden attention maps would lose discriminative temporal structure.

## Foundational Learning

- **Concept: State-Space Models (SSMs)**
  - Why needed here: SSM-CGM builds on Mamba, a selective SSM. You must understand the basic recurrence h_t = A_t h_{t-1} + B_t x_t, z_t = C_t h_t, and how the "selective" Δt parameter modulates memory.
  - Quick check question: Given an SSM with Δt large vs. small, which retains longer history?

- **Concept: Quantile Loss for Probabilistic Forecasting**
  - Why needed here: The model outputs prediction intervals via multi-quantile regression (q ∈ {0.1, 0.5, 0.9}). Understanding pinball loss is essential for interpreting calibration.
  - Quick check question: For quantile q=0.9, does the loss penalize over-prediction or under-prediction more?

- **Concept: Sequential g-formula for Counterfactual Identification**
  - Why needed here: Counterfactual forecasts rely on causal identification assumptions (consistency, sequential ignorability, positivity). The g-formula factorization justifies single-pass conditioning on planned interventions.
  - Quick check question: If an unmeasured confounder influences both heart rate and glucose, which assumption is violated?

## Architecture Onboarding

- **Component map:**
  - Static covariates → Static VSN → context c; Temporal covariates (CGM lags, wearables, meal flags, time encodings) → per-variable embeddings → Temporal VSN (fuses embeddings using learned simplex weights αi,t, conditioned on c) → Mamba-2 stack (4× blocks, MES-style, shared value/readout) → Light Mamba layer → Multi-horizon head (Quantile regression outputs P10/P50/P90 at H=12 steps)

- **Critical path:**
  1. Static VSN computes participant context c (dominated by participant ID embedding)
  2. Temporal VSN fuses covariates per timestep, upweighting meal flags and HR/RR
  3. Mamba-2 stack scans history with selective Δt, capturing short- and long-range dependencies
  4. Hidden attention maps extracted from SSM kernels for temporal attribution

- **Design tradeoffs:**
  - Mamba-2 vs. LSTM+attention: Gains linear-time complexity and longer context; sacrifices direct attention interpretability (recovered via hidden attention)
  - Shared value/readout (MES-style): Improves cross-head comparability for attribution; may reduce per-head specialization capacity
  - Proxy meal flags from external model: Enables covariate inclusion where labels absent; introduces noise (Recall=80%, Precision=72%)

- **Failure signatures:**
  - VSN weights collapsing to uniform → covariate fusion degraded, check gradient flow through GRNs
  - Hidden attention maps all mass at lag-0 → SSM states not retaining history; inspect Δt distribution, Λ stability
  - Counterfactual effects implausibly large → check positivity violations (interventions outside observed covariate support)

- **First 3 experiments:**
  1. **Ablate context length:** Train SSM-CGM with L=12h, 24h, 48h on same data; compare MAE and hidden attention spread to confirm long-context benefit
  2. **Mask top VSN covariates:** Zero out meal flags or HR/RR at inference; quantify MAE degradation to validate variable importance
  3. **Stress-test counterfactual positivity:** Apply +3SD HR interventions at physiologically implausible times (e.g., 3 AM); check for extrapolation artifacts or instability in forecast distributions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does SSM-CGM generalize to cohorts with different demographics, devices, or recording conditions?
- Basis in paper: [explicit] Appendix A.15 states, "it remains unclear how well the model generalizes across datasets with different demographics, devices, or recording conditions."
- Why unresolved: The study was restricted to the AI-READI cohort using specific hardware (Dexcom G6, Garmin Vivosmart 5).
- What evidence would resolve it: Replication of forecasting benchmarks on external CGM datasets with diverse sensor hardware and participant profiles.

### Open Question 2
- Question: Can the counterfactual forecasting framework be extended to coordinated, multivariate activity patterns?
- Basis in paper: [explicit] Appendix A.15 notes that current interventions targeted single covariates, whereas "real-world behaviors involve coordinated, multivariate activity patterns."
- Why unresolved: The current model evaluates isolated interventions (e.g., +2 SD heart rate) but cannot simulate complex, coupled physiological changes.
- What evidence would resolve it: Successful implementation and validation of joint intervention scenarios (e.g., simultaneous changes in heart rate and steps).

### Open Question 3
- Question: Can SSM-CGM be integrated with reinforcement learning to recommend adaptive behavioral policies?
- Basis in paper: [explicit] Appendix A.15 suggests "leveraging SSM-CGM forecasting models combined with reinforcement learning methods could recommend personalized, adaptive behavioral policies."
- Why unresolved: The current work focuses on open-loop forecasting and counterfactual estimation rather than closed-loop policy optimization.
- What evidence would resolve it: A system that uses SSM-CGM predictions to derive actionable policies that maximize Time-in-Range (TIR).

### Open Question 4
- Question: Do the simulated counterfactual effects represent true physiological causal responses?
- Basis in paper: [inferred] Appendix A.15 warns that counterfactual outputs should be viewed as "hypothesis-generating" because causal assumptions (consistency, sequential ignorability) "cannot be fully validated from observational data."
- Why unresolved: The model relies on untestable identification assumptions to estimate intervention effects.
- What evidence would resolve it: Prospective interventional studies comparing model-simulated glucose trajectories against actual physiological responses to specific activities.

## Limitations
- Physiological mechanism interpretation: Attribution patterns could reflect correlated behaviors rather than direct causation
- External validity: Performance validated only on AI-READI cohort with specific CGM/wearable devices
- Meal detection dependency: 80% recall/72% precision meal flags introduce noise that could propagate through forecasting pipeline

## Confidence
- **High confidence**: Short-term forecasting accuracy improvements (2-7% MAE reduction) are well-supported by direct comparisons and reproducible metrics
- **Medium confidence**: Variable selection and temporal attribution interpretations are methodologically sound but rely on assumptions about SSM state decomposition
- **Medium confidence**: Counterfactual interpretations are statistically valid given sequential ignorability assumptions, but physiological interpretations require domain expert validation

## Next Checks
1. **Physiological plausibility audit**: Have endocrinologists review the counterfactual effect sizes and temporal attribution patterns against known diabetes physiology to identify potential spurious correlations
2. **Cross-device validation**: Test SSM-CGM on a different CGM system (e.g., Libre) to assess robustness to sensor-specific noise patterns and calibration differences
3. **Sensitivity to meal detection quality**: Train and evaluate models with perfect meal labels (CGMacros) versus detected meal flags to quantify the impact of meal detection noise on overall performance and interpretability