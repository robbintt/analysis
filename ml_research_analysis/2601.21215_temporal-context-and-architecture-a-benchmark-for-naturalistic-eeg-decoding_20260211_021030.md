---
ver: rpa2
title: 'Temporal Context and Architecture: A Benchmark for Naturalistic EEG Decoding'
arxiv_id: '2601.21215'
source_url: https://arxiv.org/abs/2601.21215
tags:
- eegxf
- accuracy
- architectures
- robustness
- state
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper benchmarks five architectures\u2014CNN, LSTM, EEGXF\
  \ (a stabilized Transformer), S4, and S5\u2014on a 4-class naturalistic EEG decoding\
  \ task using the HBN movie-watching dataset. Across segment lengths from 8 s to\
  \ 128 s, accuracy improves with longer context, with S5 reaching 98.7%\xB10.6 and\
  \ CNN 98.3%\xB10.3 at 64 s, while S5 uses ~20\xD7 fewer parameters."
---

# Temporal Context and Architecture: A Benchmark for Naturalistic EEG Decoding

## Quick Facts
- arXiv ID: 2601.21215
- Source URL: https://arxiv.org/abs/2601.21215
- Reference count: 0
- Five architectures benchmarked on 4-class naturalistic EEG decoding; S5 achieves 98.7%±0.6 accuracy at 64s using ~20× fewer parameters than CNN

## Executive Summary
This paper benchmarks five architectures—CNN, LSTM, EEGXF (a stabilized Transformer), S4, and S5—on a 4-class naturalistic EEG decoding task using the HBN movie-watching dataset. Across segment lengths from 8 s to 128 s, accuracy improves with longer context, with S5 reaching 98.7%±0.6 and CNN 98.3%±0.3 at 64 s, while S5 uses ~20× fewer parameters. Cross-subject generalization shows S5's superior learning of transferable features, though it is prone to overconfident errors on out-of-distribution (OOD) tasks. In contrast, EEGXF is more conservative and robust under frequency shifts but less calibrated in-distribution. The results reveal a practical efficiency–robustness trade-off: S5 for parameter-efficient peak accuracy; EEGXF when robustness and conservative uncertainty are critical.

## Method Summary
The study evaluates five architectures on a 4-class EEG decoding task (3 movies + resting state) from the HBN movie-watching dataset. Inputs are preprocessed to 250 Hz, 64 channels, band-pass 1–50 Hz, with common average reference and per-channel z-score normalization. Data is split 60/20/20 before segmentation into 8-128 s windows with 50% overlap. Architectures include S5 (3 bidirectional blocks, hidden=192, 183K params), EEGXF (2 layers, 4 heads, d=128, attention pooling), CNN (3-layer 1D conv, 4.4M params), BiLSTM, and S4. Training uses AdamW optimizer with ReduceLROnPlateau scheduler, gradient clipping, EMA, and early stopping. Evaluation includes accuracy/F1, calibration metrics (NLL, Brier, ECE), LOSO cross-subject, zero-shot cross-frequency (250→128→64 Hz), and cross-task OOD generalization.

## Key Results
- S5 achieves 98.7%±0.6 accuracy at 64 s segment length, comparable to CNN's 98.3%±0.3 while using ~20× fewer parameters
- Accuracy improves with longer context (8s→64s), but S5 degrades to 95.8% at 128s suggesting context-length limits
- Cross-frequency evaluation shows S5 drops 18.7pp from 250Hz to 64Hz, while EEGXF remains stable (<2% drop)
- S5 is well-calibrated in-distribution (ECE 1.09%) but overconfident on OOD tasks; EEGXF is conservative but poorly calibrated in-distribution (ECE 13.41%)

## Why This Works (Mechanism)

### Mechanism 1: Long-Range Temporal Context Scaling
Longer EEG segments expose consistent neural signatures across sustained naturalistic stimuli, allowing models to integrate slowly-evolving cognitive states rather than relying on transient noise-prone features. State-space models (S5) and CNNs both leverage this, but S5's global sequence modeling captures dependencies across the full 64s without quadratic cost via diagonalized state matrix parallelization.

### Mechanism 2: State-Space Parameter Efficiency
S5 reformulates sequence modeling as continuous-time linear dynamics (h'(t) = Ah(t) + Bu(t)), then discretizes via parallel scan over diagonalized state matrix A. This avoids FFT-based convolutions (S4) and quadratic attention (Transformers), yielding O(N log N) complexity with global receptive fields. The 3-block bidirectional S5 (183K params) learns temporal dynamics directly rather than storing local filters.

### Mechanism 3: Uncertainty-Quality Trade-off in Distribution Shift
Architectures exhibit inverse calibration-generalization relationships: S5 is well-calibrated in-distribution but overconfident on OOD; EEGXF is poorly calibrated in-distribution but conservatively recognizes uncertainty on OOD. S5's strong in-distribution specialization reflects tight feature-distribution fitting, causing confident extrapolation to nearest training class. EEGXF's architectural stabilization yields lower peak accuracy but activates "conservative collapse"—defaulting to neutral class with appropriately low confidence on unfamiliar inputs.

## Foundational Learning

- **State-Space Models (SSMs) and Continuous-Time Dynamics**
  - Why needed here: S5 is core to the paper's efficiency claims; understanding how h'(t) = Ah(t) + Bu(t) discretizes to parallelizable sequence operations is essential for interpreting the architecture.
  - Quick check question: Can you explain why diagonalizing the state matrix A enables parallel scan vs. requiring sequential recurrence?

- **Temporal Receptive Fields and Context Accumulation**
  - Why needed here: The paper's central hypothesis is that longer context improves accuracy; distinguishing local (CNN) vs. global (SSM/Transformer) receptive field behavior is critical.
  - Quick check question: For a 64-second EEG segment at 250Hz (T=16,000 timesteps), what computational complexity differences exist between CNN (kernel size K), Transformer (self-attention), and S5 (parallel scan)?

- **Calibration Metrics (ECE, NLL, Brier Score)**
  - Why needed here: The robustness trade-off is quantified via calibration; interpreting these metrics distinguishes "confident wrong" from "appropriately uncertain."
  - Quick check question: If a model achieves 98% accuracy but ECE=15%, what does this imply about its reliability for deployment?

## Architecture Onboarding

- **Component map:**
  Input (batch, 64, T) → [Architecture-specific encoder] → Global pooling → Linear classifier → 4-class logits
  S5: Input → 3×Bidirectional S5 blocks (hidden=192) → Global avg pool → Linear (183K total params)
  EEGXF: Input → Projection + ReLU → 2-layer Transformer (4 heads, d=128) + BatchNorm → Attention pooling → Linear

- **Critical path:**
  1. Implement preprocessing: 1-50Hz bandpass → common average reference → segment into T-second windows (50% overlap) → per-channel z-score normalization
  2. Start with S5 for efficiency-focused experiments; switch to EEGXF if robustness/cross-frequency stability is required
  3. Segment length 64s is optimal for this task; 128s shows degradation

- **Design tradeoffs:**
  | Criterion | S5 | EEGXF | CNN |
  |-----------|-----|-------|-----|
  | Peak accuracy (64s) | 98.7% | 81.8% | 98.3% |
  | Parameters | 0.18M | ~0.5M | 4.4M |
  | Training time (64s) | 25.8 min | 25.1 min | 9.8 min |
  | OOD calibration | Overconfident | Conservative | Moderate |
  | Frequency robustness | Fragile (-18.7pp) | Stable (-0.2pp) | Not reported |

- **Failure signatures:**
  - S5 overconfidence: On OOD inputs, check if predictions concentrate on single class with >50% confidence
  - EEGXF movie confusion: 32.4% inter-movie confusion rate at 64s; expect poor fine-grained discrimination
  - LSTM/S4: LSTM fails to converge; S4 is 3× slower than S5 with lower accuracy

- **First 3 experiments:**
  1. Reproduce scaling curve: Train S5 and CNN on 8s, 32s, 64s segments; verify accuracy improves with context and S5 matches CNN at 64s with 20× fewer params
  2. Cross-frequency stress test: Train at 250Hz, evaluate zero-shot at 128Hz and 64Hz; confirm S5 fragility and EEGXF stability
  3. OOD probe: Train on movie/resting data, test on held-out active tasks (Symbol Search, etc.); verify S5 overconfidence vs. EEGXF conservative collapse

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do the architectural trade-offs (S5's efficiency vs. EEGXF's robustness) replicate on standard EEG benchmarks like Sleep-EDF or TUH?
- Basis in paper: "future work should validate these architectural findings on standard benchmarks like Sleep-EDF."
- Why unresolved: The study uses only the HBN movie-watching dataset; generalization to clinical or sleep EEG tasks is unknown.
- What evidence would resolve it: Repeating the benchmark on Sleep-EDF, TUH, or other established datasets with similar evaluation protocols.

### Open Question 2
- Question: Why does S5's performance degrade at 128s (95.8%) compared to 64s (98.7%), and is there an optimal context length?
- Basis in paper: Table 1 shows non-monotonic scaling; S5 drops from 98.7% at 64s to 95.8% at 128s, suggesting context-length limits.
- Why unresolved: The paper does not analyze the cause of degradation or test intermediate lengths.
- What evidence would resolve it: Systematic evaluation across finer-grained segment lengths (e.g., 48–128s) with analysis of attention/state dynamics.

### Open Question 3
- Question: Can the parameter efficiency of S5 be combined with EEGXF's robust uncertainty handling in a hybrid architecture?
- Basis in paper: The paper reveals a trade-off (S5: fast, accurate, overconfident on OOD; EEGXF: robust but less accurate), but does not explore hybrid solutions.
- Why unresolved: No architecture combining SSM efficiency with Transformer-style uncertainty was tested.
- What evidence would resolve it: Design and benchmark hybrid models (e.g., S5 encoder with EEGXF-style calibration heads) on OOD and frequency-shift tests.

### Open Question 4
- Question: What mechanistic factors cause S5's acute sensitivity to sampling rate changes versus EEGXF's stability?
- Basis in paper: S5 accuracy drops 18.7pp from 250Hz to 64Hz; EEGXF drops only 0.2pp (Table 3, Figure 3), but no explanation is provided.
- Why unresolved: Architectural inductive biases (SSM diagonalization vs. attention pooling) likely differ in temporal resolution sensitivity, but this is not analyzed.
- What evidence would resolve it: Ablation studies varying sampling rates with controlled frequency content, plus analysis of learned representations.

## Limitations
- S5's exceptional in-distribution accuracy may not generalize to more complex naturalistic tasks beyond the 4-class movie/resting-state setup
- The practical significance of S5's parameter efficiency depends on deployment constraints not benchmarked (latency, memory, power)
- The inverse relationship between in-distribution calibration and OOD robustness suggests a fundamental architectural tension that isn't resolved

## Confidence
- **High confidence**: Temporal context scaling effects (8s→64s accuracy improvement) are well-supported by systematic benchmarking across architectures
- **Medium confidence**: S5's parameter efficiency claims rely on correct implementation of the state-space formulation
- **Low confidence**: Cross-frequency robustness conclusions are based on zero-shot evaluation without fine-tuning

## Next Checks
1. Test whether S5 maintains its accuracy advantage on multi-class naturalistic tasks (e.g., 8+ classes of different activities) to validate generalization beyond the current 4-class setup
2. Measure actual deployment metrics—latency, memory footprint, and power consumption—for S5 vs. CNN on representative edge hardware to quantify practical parameter efficiency
3. Combine S5's parameter efficiency with EEGXF's OOD robustness (e.g., S5 with uncertainty-aware pooling or ensemble methods) to test whether the accuracy-robustness trade-off can be broken