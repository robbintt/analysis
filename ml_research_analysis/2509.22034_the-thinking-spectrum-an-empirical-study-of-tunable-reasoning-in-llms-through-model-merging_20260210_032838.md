---
ver: rpa2
title: 'The Thinking Spectrum: An Empirical Study of Tunable Reasoning in LLMs through
  Model Merging'
arxiv_id: '2509.22034'
source_url: https://arxiv.org/abs/2509.22034
tags:
- merging
- reasoning
- arxiv
- direct
- parameter
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents the first comprehensive empirical study on
  leveraging model merging to generate a spectrum of large language models with tunable
  reasoning capabilities. By arithmetically combining weights of general-purpose (direct)
  and specialized (thinking) models, the authors demonstrate fine-grained control
  over the trade-off between reasoning accuracy and computational efficiency.
---

# The Thinking Spectrum: An Empirical Study of Tunable Reasoning in LLMs through Model Merging

## Quick Facts
- arXiv ID: 2509.22034
- Source URL: https://arxiv.org/abs/2509.22034
- Reference count: 10
- Key outcome: First comprehensive empirical study demonstrating model merging creates tunable reasoning capabilities by balancing accuracy and computational efficiency across a spectrum of LLMs.

## Executive Summary
This paper presents the first comprehensive empirical study on leveraging model merging to generate a spectrum of large language models with tunable reasoning capabilities. By arithmetically combining weights of general-purpose (direct) and specialized (thinking) models, the authors demonstrate fine-grained control over the trade-off between reasoning accuracy and computational efficiency. The study evaluates seven representative merging techniques across multiple reasoning benchmarks and two model scales, showing that model merging is surprisingly effective even when parent models have highly divergent parameter spaces, achieving tunable reasoning without catastrophic failure. Critically, the study frequently observes Pareto improvements, where merged models surpass the original thinking model in both accuracy and token efficiency.

## Method Summary
The study combines weights from "direct" response models (fast, concise) with "thinking" models (slow, verbose with Chain-of-Thought reasoning) using seven merging techniques including Linear Interpolation, SLERP, DARE, TIES, EMR, LORE, and TWIN. The core operation is weighted averaging: θ_merged = (1-λ)θ_direct + λθ_think, where λ varies from 0 to 1. The authors evaluate these merged models across reasoning benchmarks (AIME24, AIME25, HMMT25, GPQA-Diamond) and a creative writing task using Qwen3-4B and 30B models, measuring both accuracy and token efficiency to identify Pareto-optimal trade-offs.

## Key Results
- Model merging works effectively even when parent models have highly divergent parameter spaces (up to 7.9% relative distance)
- Seven different merging techniques produce models along the same performance curve, with Linear and SLERP often matching or outperforming complex methods
- Merged models frequently achieve Pareto improvements, surpassing parent thinking models in both accuracy and token efficiency
- Reasoning capability exhibits non-linear phase changes at specific λ thresholds (typically 0.6-0.7), where token consumption and accuracy spike simultaneously

## Why This Works (Mechanism)

### Mechanism 1: Mode Connectivity in Divergent Weight Spaces
The paper posits that both direct and thinking models reside within a connected low-loss basin, allowing linear interpolation to traverse this path without encountering a high-loss ridge. This explains why significant parameter distance (3-8%) doesn't prevent successful merging.

### Mechanism 2: Approximation of Training Checkpoints
Merging acts as a training-free proxy for sampling intermediate checkpoints along the fine-tuning trajectory of a reasoning model. Varying λ effectively "rolls back" intensive reasoning training to points where accuracy is high but the model hasn't learned to be overly verbose.

### Mechanism 3: Non-Linear Emergence of Reasoning
Reasoning capability doesn't scale linearly with merge strength but exhibits phase changes where specific reasoning circuits activate only after a critical threshold of parameters are aligned. Between λ≈0.6 and 0.7, a rapid transition occurs where token consumption and accuracy spike simultaneously.

## Foundational Learning

- **Concept: Mode Connectivity** - Understanding why averaging weights of two vastly different models doesn't result in a "broken" model. *Quick check: Why doesn't the significant relative distance (up to 7.9%) between models prevent successful linear merging?*

- **Concept: Task Arithmetic** - The fundamental operation (θ_merged = θ_direct + λ(θ_think - θ_base)) used to construct the reasoning spectrum. *Quick check: How does the paper treat the difference vector between a Thinking model and a Direct model differently than traditional task vectors?*

- **Concept: Emergent Abilities & Phase Changes** - Interpreting the non-linear relationship between merge weight (λ) and output token length/reasoning depth. *Quick check: If a merged model at λ=0.5 acts like a direct model, and λ=0.7 acts like a thinking model, what does this imply about the distribution of "reasoning capability" in weight space?*

## Architecture Onboarding

- **Component map**: Source Models (Qwen3-4B/30B Direct/Thinking) -> Merge Engine (Linear, SLERP, DARE, TIES, EMR, LORE, TWIN) -> Controller (λ merge strength) -> Evaluation Suite (AIME/HMMT/GPQA/Creative Writing)

- **Critical path**: 1) Load θ_direct and θ_think (and θ_base if using Task Arithmetic methods). 2) Calculate Δθ. 3) Apply merge algorithm. 4) Sweep λ ∈ [0, 1] with high resolution (0.01 steps) in critical regions (0.6-0.7). 5) Evaluate for Pareto Efficiency (Accuracy vs. Token Count).

- **Design tradeoffs**: The paper finds simple Linear/SLERP often match or outperform complex methods for this specific use case. Complex methods may strip away the dense, global parameters required for reasoning.

- **Failure signatures**: Catastrophic Forgetting is unlikely due to mode connectivity, but "formatting inconsistencies" occur. Model Collapse can happen with aggressive sparsification (>50% drop rate). Stagnation occurs if λ is set below the "phase change" threshold.

- **First 3 experiments**: 1) Baseline Linear Sweep: Perform linear interpolation between θ_direct and θ_think on AIME24 to locate the phase change region. 2) Pareto Frontier Search: Focus the sweep on the identified region (λ=0.6-0.7) to find a model that beats the parent θ_think in token efficiency without losing accuracy. 3) Robustness Check: Compare the best Linear merge against SLERP and one arbitrary method (e.g., Top-K Replacement) to verify if the specific algorithm matters.

## Open Questions the Paper Calls Out

1. **Mathematical Framework**: Can a formal mathematical framework be developed to explain the effectiveness of model merging when interpolating between computational strategies (direct vs. reasoning) rather than just domain knowledge?

2. **Superior Merging Methods**: Do merging methods exist that can yield a significantly better Pareto front (accuracy vs. efficiency) than simple linear interpolation?

3. **Optimal Weight Prediction**: Is it possible to predict the optimal merging weight (λ) for a given task without resorting to an expensive empirical search?

## Limitations
- Transferability across model families is uncertain due to reliance on specific parameter distributions
- Prompt sensitivity not fully characterized, with potential catastrophic failures under different formatting
- Evaluation scope limited to reasoning and general knowledge tasks, lacking practical applications
- Computational cost claims overlook the evaluation overhead required to find optimal λ values

## Confidence
- **High Confidence**: Model merging between direct and thinking models is technically feasible; Linear interpolation and SLERP perform comparably to complex algorithms; phase transitions in reasoning behavior exist at specific λ thresholds
- **Medium Confidence**: Phase change mechanism correctly characterized as global circuit activation; Pareto improvements are consistently achievable; 0.6-0.7 λ range is universally optimal
- **Low Confidence**: Mode connectivity explanation fully accounts for all seven merging techniques; "training checkpoint approximation" hypothesis accurately describes what merge captures; results generalize to model families outside Qwen3

## Next Checks
1. **Cross-Architecture Transfer Test**: Apply the same merging protocol to Llama-3 and Mistral models to verify whether observed phase transitions and Pareto improvements generalize beyond Qwen3.

2. **Prompt Robustness Evaluation**: Systematically vary prompt formats (zero-shot, few-shot with different CoT templates, direct instruction) to identify the stability envelope of merged models across the λ spectrum.

3. **Resource-Constrained Search Protocol**: Develop and validate a more efficient method for locating optimal λ values (e.g., Bayesian optimization or adaptive sampling) to address the computational overhead of finding phase transitions.