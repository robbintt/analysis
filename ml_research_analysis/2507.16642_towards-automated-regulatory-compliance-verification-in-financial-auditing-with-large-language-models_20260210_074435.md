---
ver: rpa2
title: Towards Automated Regulatory Compliance Verification in Financial Auditing
  with Large Language Models
arxiv_id: '2507.16642'
source_url: https://arxiv.org/abs/2507.16642
tags:
- answer
- financial
- anforderung
- requirement
- ifrs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates the potential of large language models (LLMs)
  for automated compliance verification in financial auditing, specifically checking
  whether text passages in financial reports align with regulatory standards such
  as IFRS and HGB. The research extends prior work by integrating a proven text-matching
  system with LLMs to assess compliance of recommended passages.
---

# Towards Automated Regulatory Compliance Verification in Financial Auditing with Large Language Models

## Quick Facts
- arXiv ID: 2507.16642
- Source URL: https://arxiv.org/abs/2507.16642
- Reference count: 31
- This study evaluates the potential of large language models (LLMs) for automated compliance verification in financial auditing, specifically checking whether text passages in financial reports align with regulatory standards such as IFRS and HGB.

## Executive Summary
This study evaluates the potential of large language models (LLMs) for automated compliance verification in financial auditing, specifically checking whether text passages in financial reports align with regulatory standards such as IFRS and HGB. The research extends prior work by integrating a proven text-matching system with LLMs to assess compliance of recommended passages. Experiments compare six LLMs, including open-source Llama-2 models and proprietary GPT variants, using two custom datasets from PwC Germany. Performance is measured by precision, recall, and F1-score per class ("yes," "no," "unclear," "not applicable") and averaged using macro and micro metrics. Results show GPT-4 performs best overall, while Llama-2-70b excels in detecting non-compliance ("no") on IFRS data with high precision (80.21%), recall (96.25%), and F1-score (87.50%). However, all models struggle with non-English (German) texts, reflecting training bias toward English. Prompt design significantly impacts results, with concise prompts and one-shot examples generally outperforming more complex techniques. The study concludes that out-of-the-box LLMs are not yet reliable for fully automated compliance checks but highlight the potential of targeted fine-tuning, especially for open-source models, to improve accuracy and address data privacy and cost concerns.

## Method Summary
The study evaluates six LLMs (GPT-3.5, GPT-4, Llama-2-7b, Llama-2-13b, Llama-2-70b, and MPT-7b) on compliance verification tasks using two custom datasets from PwC Germany covering IFRS and HGB standards. The methodology combines a text-matching system with LLMs to assess compliance of recommended passages. Performance is measured using precision, recall, and F1-score per class ("yes," "no," "unclear," "not applicable") with both macro and micro averaging. The study tests various prompt engineering techniques including zero-shot, one-shot, few-shot, chain-of-thought, and generated knowledge prompts to optimize model performance.

## Key Results
- GPT-4 achieved the highest overall performance across English datasets, though no model reached reliable automation levels
- Llama-2-70b excelled at detecting non-compliance ("no" class) on IFRS data with 80.21% precision, 96.25% recall, and 87.50% F1-score
- All models struggled significantly with German texts, confirming training bias toward English and highlighting language-specific limitations
- Concise prompts with one-shot examples generally outperformed more complex prompt engineering techniques like chain-of-thought and generated knowledge

## Why This Works (Mechanism)
The study demonstrates that LLMs can leverage their natural language understanding capabilities to interpret regulatory requirements and assess compliance, extending beyond simple keyword matching to contextual understanding. The combination of traditional text-matching systems with LLM reasoning allows for both precision in finding relevant passages and contextual judgment in compliance assessment. However, the mechanism is limited by training data bias toward English, insufficient fine-tuning on domain-specific regulatory language, and the inherent difficulty of capturing nuanced compliance concepts that often require human expertise and contextual knowledge.

## Foundational Learning
- **Financial Regulatory Standards (IFRS/HGB)**: Understanding international and national accounting standards is essential for evaluating compliance accuracy; quick check: can the LLM correctly identify key IFRS/HGB requirements in sample text?
- **Prompt Engineering Techniques**: Zero-shot, one-shot, few-shot, chain-of-thought, and generated knowledge prompting each affect model performance differently; quick check: does prompt complexity improve or degrade compliance classification accuracy?
- **Multi-class Classification Metrics**: Precision, recall, and F1-score per class provide nuanced performance evaluation beyond simple accuracy; quick check: are models consistently performing well across all compliance categories or only specific ones?

## Architecture Onboarding
**Component Map**: Text-matching system -> LLM compliance classifier -> Performance evaluation metrics
**Critical Path**: Regulatory text extraction -> Passage recommendation -> LLM compliance assessment -> Classification output
**Design Tradeoffs**: Open-source models offer data privacy and cost advantages but require fine-tuning for domain specificity; proprietary models provide better out-of-the-box performance but raise privacy concerns and incur ongoing costs
**Failure Signatures**: English-language bias causing poor non-English performance, confusion between "unclear" and "not applicable" classes, over-reliance on explicit terminology rather than contextual understanding
**3 First Experiments**:
1. Test zero-shot prompting with concise format on English IFRS dataset to establish baseline performance
2. Implement one-shot prompting with regulatory examples to measure improvement over baseline
3. Evaluate German HGB dataset performance to quantify language-specific degradation

## Open Questions the Paper Calls Out
None

## Limitations
- All models struggle with non-English (German) texts, reflecting training bias toward English and limiting applicability in multilingual auditing contexts
- Out-of-the-box LLMs are not yet reliable for fully automated compliance checks due to suboptimal precision-recall trade-offs across all models
- The study relies on curated datasets from a single auditing firm rather than live audit environments, limiting real-world generalizability

## Confidence
High confidence in comparative ranking of model performances across English datasets due to sound methodology and consistent results across multiple metrics. Medium confidence in cross-language generalizability claims due to limited German dataset size and observed degradation in non-English performance. High confidence in the conclusion that out-of-the-box LLMs are insufficient for fully automated compliance checking based on consistently suboptimal precision-recall trade-offs.

## Next Checks
1. **Multi-jurisdictional testing**: Evaluate the same LLM configurations on regulatory datasets from multiple countries and compliance frameworks to assess cross-jurisdictional generalization and identify model-specific weaknesses in different regulatory contexts.

2. **Longitudinal performance assessment**: Implement a time-series evaluation using evolving regulatory documents and compliance requirements to measure model adaptability and degradation over time, particularly for open-source models that may be fine-tuned incrementally.

3. **Hybrid system validation**: Test integrated approaches combining LLM outputs with traditional rule-based compliance verification systems in live audit workflows to quantify practical accuracy improvements and identify optimal human-AI collaboration patterns for compliance verification tasks.