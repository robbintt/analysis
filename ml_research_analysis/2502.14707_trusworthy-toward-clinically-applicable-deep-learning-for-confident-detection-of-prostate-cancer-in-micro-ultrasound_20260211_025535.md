---
ver: rpa2
title: 'TRUSWorthy: Toward Clinically Applicable Deep Learning for Confident Detection
  of Prostate Cancer in Micro-Ultrasound'
arxiv_id: '2502.14707'
source_url: https://arxiv.org/abs/2502.14707
tags:
- trusworthy
- cancer
- ultrasound
- detection
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of prostate cancer (PCa) detection
  in micro-ultrasound (micro-US) imaging using deep learning. The core problem is
  that current methods struggle with weak labels, label scarcity, class imbalance,
  and data heterogeneity, leading to unreliable and overconfident predictions.
---

# TRUSWorthy: Toward Clinically Applicable Deep Learning for Confident Detection of Prostate Cancer in Micro-Ultrasound

## Quick Facts
- **arXiv ID:** 2502.14707
- **Source URL:** https://arxiv.org/abs/2502.14707
- **Authors:** Mohamed Harmanani; Paul F. R. Wilson; Minh Nguyen Nhat To; Mahdi Gilany; Amoon Jamzad; Fahimeh Fooladgar; Brian Wodlinger; Purang Abolmaesumi; Parvin Mousavi
- **Reference count:** 29
- **One-line primary result:** Achieved 79.9% AUROC and 71.5% balanced accuracy on micro-ultrasound prostate cancer detection, with up to 91% accuracy on high-confidence predictions.

## Executive Summary
This paper addresses the challenge of prostate cancer (PCa) detection in micro-ultrasound (micro-US) imaging using deep learning. The core problem is that current methods struggle with weak labels, label scarcity, class imbalance, and data heterogeneity, leading to unreliable and overconfident predictions. The proposed method, TRUSWorthy, integrates multiple advanced techniques to overcome these issues. It combines self-supervised learning to address label scarcity, multiple-instance learning using transformers to handle weak labels, random undersampling boosting to tackle class imbalance, and deep ensembles to mitigate overconfidence. The model is evaluated on a large, multi-center dataset of 693 patients, achieving an AUROC of 79.9% and a balanced accuracy of 71.5%. On the top 20% of predictions with the highest confidence, TRUSWorthy achieves a balanced accuracy of up to 91%. These results demonstrate the potential of TRUSWorthy as a trustworthy tool for PCa detection, addressing the limitations of previous methods and advancing the field toward clinically applicable deep learning solutions.

## Method Summary
TRUSWorthy integrates self-supervised learning, multiple-instance learning with transformers, random undersampling boosting, and deep ensembles to address label scarcity, weak labels, class imbalance, and overconfidence in prostate cancer detection. The method uses a modified ResNet18 backbone pre-trained with VICReg for feature extraction, followed by a transformer to aggregate features from multiple ROIs per biopsy core. An ensemble of 10 members, each trained on a balanced subset of data, provides both predictions and uncertainty estimates. The model is evaluated on a large, multi-center dataset of 693 patients, demonstrating improved performance and calibration compared to existing methods.

## Key Results
- Achieved 79.9% AUROC and 71.5% balanced accuracy on micro-ultrasound prostate cancer detection.
- On the top 20% of predictions with highest confidence, TRUSWorthy achieves a balanced accuracy of up to 91%.
- Ablation studies show that VICReg pre-training and the ensemble strategy significantly improve performance and calibration.
- The model generalizes well across multiple clinical centers, though performance varies, with a notable drop at one center.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Self-supervised pre-training mitigates label scarcity and improves feature robustness for the downstream transformer.
- **Mechanism:** By using VICReg (Variance-Invariance-Covariance Regularization) on unlabeled data, the ResNet backbone learns invariant features against specific ultrasound augmentations (e.g., phase shift, envelope distortion). This prevents overfitting to the limited labeled set and provides a richer embedding space for the aggregator.
- **Core assumption:** The augmentations applied during SSL preserve the semantic integrity of the tissue structure while forcing the model to ignore noise.
- **Evidence anchors:**
  - [abstract]: "...integrates self-supervised learning... to address label scarcity..."
  - [section 3.1]: "We use a combination of standard data augmentations... as well as augmentations designed specifically for ultrasound..."
  - [corpus]: Related work "Cinepro" supports the difficulty of training on noisy/limited US labels, though it uses a different foundation model approach.
- **Break condition:** If ultrasound augmentations distort cancer-specific texture patterns, SSL features may be useless for classification.

### Mechanism 2
- **Claim:** Multiple Instance Learning (MIL) with Transformers effectively localizes cancer signals despite weak (core-level) labels.
- **Mechanism:** By treating a biopsy core as a "bag" of ROI patches, the Transformer's attention mechanism identifies which specific patches contribute most to the positive classification, solving the spatial mismatch between the image and the histopathology label.
- **Core assumption:** The cancerous tissue occupies a sufficient number of patches within a positive core to be detected by the attention heads.
- **Evidence anchors:**
  - [abstract]: "...multiple-instance learning using transformers to handle weak labels..."
  - [section 3.2]: "The resulting bag of features... is then used as the input to a Transformer network..."
  - [corpus]: Weak evidence in corpus for this specific architecture; mechanism is primarily supported by internal validation.
- **Break condition:** If cancer signals are diffuse or indistinguishable from benign background noise at the patch level, the attention mechanism will fail to aggregate meaningful signals.

### Mechanism 3
- **Claim:** Random Undersampling Boosting (RUS) within an Ensemble framework improves calibration and manages class imbalance.
- **Mechanism:** Each ensemble member trains on a distinct subset of benign samples (fixed 2:1 ratio). This prevents the model from simply memorizing the majority class and ensures that consensus (confidence) is derived from diverse perspectives of "benign" appearance.
- **Core assumption:** The discarded benign samples are redundant; diversity in training subsets correlates with better uncertainty estimation.
- **Evidence anchors:**
  - [abstract]: "...random undersampling boosting to tackle class imbalance, and deep ensembles to mitigate overconfidence."
  - [section 3.3]: "...since different members are specialized for different benign examples, the consistency of all membersâ€™ predictions... is a good measure of predictive confidence."
  - [corpus]: General consensus in ML literature (e.g., RUSBoost), but specific validation here is tied to the "TRUSWorthy" results (Fig 2a).
- **Break condition:** If the undersampling ratio (2:1) removes critical benign variations (e.g., rare benign anomalies), the ensemble may produce false positives.

## Foundational Learning

- **Concept: Multiple Instance Learning (MIL)**
  - **Why needed here:** Standard supervision fails because you have a label for the whole image (the core) but not the specific cancer pixels. MIL allows you to train on the "bag" level.
  - **Quick check question:** Can you explain why a standard cross-entropy loss on individual patches would fail given the "weak label" problem described in the text?

- **Concept: Uncertainty Calibration (ECErr / Brier Score)**
  - **Why needed here:** In a clinical setting, a wrong prediction with high confidence is dangerous. Calibration ensures that when the model says "90% sure," it is correct 90% of the time.
  - **Quick check question:** Does the paper rely on softmax probability directly for uncertainty, or does it use a specific ensemble disagreement metric?

- **Concept: Data Augmentation for Ultrasound**
  - **Why needed here:** Unlike natural images, ultrasound data has physics-based noise (speckle).
  - **Quick check question:** What specific augmentations does the paper mention (Section 3.1) that are unique to ultrasound vs. standard computer vision?

## Architecture Onboarding

- **Component map:** Input (RF Data) -> Modified ResNet18 (VICReg SSL) -> Transformer (MIL) -> Ensemble (10 Members) -> Probability + Uncertainty
- **Critical path:** The SSL Pre-training (VICReg) is the prerequisite for the MIL Transformer. The paper notes the Transformer only performs well when initialized with these specific features. Do not skip pre-training.
- **Design tradeoffs:**
  - **Specificity vs. Sensitivity:** The model trades ~7% specificity for higher balanced accuracy/ROC performance compared to some baselines.
  - **Rejection Rate:** There is a direct tradeoff between coverage (how many cases you diagnose) and accuracy (Fig 2a). A 20% rejection rate yields high accuracy but ignores 1/5th of patients.
- **Failure signatures:**
  - **Overconfident False Positives:** Likely occurring in the transition zone or anterior gland (Limitations section).
  - **Generalization Drop:** Significant performance variance across clinical centers (e.g., JH center performance drop in Table 3).
- **First 3 experiments:**
  1. **Ablation on Pre-training:** Train the TRUSformer backbone from scratch (ImageNet weights) vs. VICReg weights to quantify the SSL contribution (Replicate Table 2 logic).
  2. **Rejection Threshold Analysis:** Plot Balanced Accuracy vs. Rejection Rate (Replicate Fig 2a) to find the optimal operating point for clinical deployment (e.g., targeting 90% accuracy).
  3. **Center Generalization:** Run a leave-one-center-out test to ensure the ensemble isn't just memorizing site-specific artifacts (Replicate Table 3).

## Open Questions the Paper Calls Out
- **Question:** Does TRUSWorthy maintain superior performance in a prospective clinical trial compared to standard benchmarks like PI-RADS?
  - **Basis in paper:** [explicit] The authors state that "a well-designed prospective validation study to rigorously compare PCa detection methods and establish the clinical efficacy of TRUSWorthy should be the focus of immediate future work."
  - **Why unresolved:** Current comparisons rely on retrospective data and do not control for differences in study populations or biopsy methodologies.
  - **What evidence would resolve it:** Results from a prospective randomized trial comparing TRUSWorthy's sensitivity and specificity against mp-MRI and visual detection methods.

- **Question:** How does the inclusion of Gleason Score 6 (GS6) cores affect the model's predictive performance?
  - **Basis in paper:** [explicit] The authors excluded GS6 cores and note that "the elimination of this intermediate class may have simplified the task... potentially inflating predictive performance."
  - **Why unresolved:** It is unclear if the model can maintain high accuracy when tasked with distinguishing clinically significant cancer from this intermediate class.
  - **What evidence would resolve it:** Re-training and evaluating the model on a dataset that includes GS6/clinically insignificant cancer labels.

- **Question:** Can the method generalize to transperineal ultrasound data to improve detection in the anterior gland?
  - **Basis in paper:** [explicit] The authors utilized TRUS data exclusively and suggest "future work could improve... robustness by including data from transperineal ultrasound."
  - **Why unresolved:** The current TRUS-only approach may undersample the transition zone and anterior prostate, limiting detection rates in these areas.
  - **What evidence would resolve it:** Performance metrics (AUROC, Balanced Accuracy) derived from validation on a dataset of transperineal ultrasound images.

## Limitations
- The model's performance is highly dependent on the specific micro-ultrasound RF data used, which is not publicly available, raising questions about reproducibility and generalization.
- Significant performance variance is observed across clinical centers, with a notable drop at one center, indicating potential site-specific bias or domain shift.
- The exclusion of Gleason Score 6 cores may have simplified the classification task and potentially inflated the reported performance metrics.

## Confidence
- **High Confidence:** The core TRUSWorthy architecture (MIL with Transformer, RUS within ensemble, VICReg pre-training) is well-defined and technically sound. The integration of these techniques to address the stated challenges (weak labels, imbalance, label scarcity) is logically consistent and supported by the results.
- **Medium Confidence:** The reported performance metrics (AUROC, Balanced Accuracy) and their improvement over baselines are supported by the presented ablation studies. However, the dependence on a private dataset and the potential for site-specific performance variation warrant caution in overgeneralizing these results.
- **Low Confidence:** The exact contribution of the ultrasound-specific augmentations to the VICReg pre-training is difficult to assess without the precise implementation. The paper's claim of clinical applicability is aspirational; the model's performance on truly unseen, diverse populations remains to be validated.

## Next Checks
1. **Independent Dataset Validation:** Test the TRUSWorthy model on a publicly available or independent micro-ultrasound dataset with similar core-level histopathology labels to verify the reported AUROC and Balanced Accuracy are not artifacts of the specific training set.
2. **Ultrasound Augmentation Verification:** Implement the physics-based ultrasound augmentations (phase shift, envelope distortion) with parameters as close as possible to those used in the VICReg pre-training and assess their impact on the backbone's feature quality and the final model's performance.
3. **Site Generalization Study:** Conduct a rigorous leave-one-center-out cross-validation or test the model on data from a new, unseen clinical site to quantify and mitigate the performance variance observed across different centers (e.g., the JH center drop).