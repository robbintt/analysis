---
ver: rpa2
title: Towards Understanding Feature Learning in Parameter Transfer
arxiv_id: '2509.22056'
source_url: https://arxiv.org/abs/2509.22056
tags:
- inequality
- transfer
- lemma
- learning
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides the first theoretical analysis of training
  dynamics in parameter transfer, proving the existence of negative transfer. The
  authors analyze a setting where both upstream and downstream models are two-layer
  ReLU CNNs, characterizing how inherited parameters act as carriers of universal
  knowledge between source and target tasks.
---

# Towards Understanding Feature Learning in Parameter Transfer

## Quick Facts
- arXiv ID: 2509.22056
- Source URL: https://arxiv.org/abs/2509.22056
- Authors: Hua Yuan; Xuran Meng; Qiufeng Wang; Shiyu Xia; Ning Xu; Xu Yang; Jing Wang; Xin Geng; Yong Rui
- Reference count: 40
- One-line primary result: First theoretical analysis proving negative transfer exists and characterizing conditions for beneficial parameter transfer

## Executive Summary
This paper provides the first theoretical analysis of parameter transfer learning, proving the existence of negative transfer and characterizing conditions under which transferred parameters help or harm downstream performance. The authors analyze a setting where both upstream and downstream models are two-layer ReLU CNNs, showing how inherited parameters act as carriers of universal knowledge between source and target tasks. The key theoretical results reveal three crucial factors influencing parameter transfer effectiveness: the norm of universal knowledge shared between tasks, the training sample size in the source task, and the noise level in the source task.

## Method Summary
The paper analyzes parameter transfer between two tasks using two-layer ReLU CNNs. In the upstream task, the model learns from data with a universal signal component shared with the downstream task and task-specific components. During transfer, a fraction α of the upstream weights are inherited by the downstream model while the rest are randomly initialized. The analysis tracks how the inherited weights carry information about the universal signal through their learned norms and orientations, and derives phase transition conditions that determine whether transfer achieves near-optimal performance or fails. The theoretical framework decomposes weight updates into components along universal signal, task-specific signal, and noise directions.

## Key Results
- Proves negative transfer exists when transferred weights have excessive norm from low-noise upstream training but universal signal is weak
- Derives phase transition conditions showing test error approaches Bayes-optimal when d ≤ C₁(α²N₁²‖u‖⁴₂/σ⁴_{p,1} + N₂²‖u+v₂‖⁴₂/σ⁴_{p,2})/(α²σ²_{p,2}N₁/σ²_{p,1} + N₂)
- Numerical experiments validate theoretical findings showing transfer performance improves with larger source sample size, lower source noise, or stronger universal knowledge

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Inherited parameters act as carriers of universal knowledge between source and target tasks, enabling knowledge reuse across tasks.
- Mechanism: The data generation model decomposes each input into a signal patch (universal signal u plus task-specific signal v_i) and a noise patch. During upstream training, weights develop components aligned with both the universal signal (γ coefficients) and task-specific signal. When α proportion of weights transfer downstream, the γ coefficients preserve alignment with the universal component, giving the downstream model a "head start" on learning shared structure rather than initializing from scratch.
- Core assumption: Universal knowledge exists as a signal vector u shared between source and target tasks, orthogonal to task-specific signals v₁ and v₂.
- Evidence anchors:
  - [abstract] "characterize how the inherited parameters act as carriers of universal knowledge"
  - [Section 3, Definition 3.1/3.2] Data model explicitly includes shared universal signal u across tasks
  - [corpus] Related work on "Transfer Learning in Infinite Width Feature Learning Networks" also analyzes feature learning regimes, but focuses on Bayesian/gradient flow frameworks rather than explicit universal knowledge decomposition
- Break condition: When ‖u‖₂ (universal signal norm) is near zero, there is no meaningful shared knowledge to carry, and transfer provides no benefit.

### Mechanism 2
- Claim: Parameter transfer effectiveness exhibits a phase transition governed by the interaction of sample size, signal strength, noise level, and dimension.
- Mechanism: The paper derives a sharp theoretical threshold: when d ≤ C₁(α²N₁²‖u‖⁴₂/σ⁴_{p,1} + N₂²‖u+v₂‖⁴₂/σ⁴_{p,2})/(α²σ²_{p,2}N₁/σ²_{p,1} + N₂), test error approaches Bayes-optimal (exp decay). Above this threshold, error remains ≥ 0.1. The key quantity Γ = α²N₁‖u‖⁴₂/(σ²_{p,1}σ²_{p,2}d) determines success; large Γ means inherited universal knowledge dominates noise memorization.
- Core assumption: Over-parameterized regime (d sufficiently large), small initialization scale σ₀ enabling feature learning rather than lazy NTK dynamics.
- Evidence anchors:
  - [Section 4, Theorem 4.2] Explicit phase transition conditions with near-optimal vs sub-optimal error regimes
  - [Figure 2] Heatmap showing accuracy phase transition as ‖u‖₂ and d vary
  - [corpus] "Scaling Laws for Data-Efficient Visual Transfer Learning" addresses scaling in data-constrained downstream tasks but does not provide phase transition analysis
- Break condition: If dimension d is too high relative to signal strength and sample size, noise memorization dominates signal learning, preventing generalization.

### Mechanism 3
- Claim: Negative transfer occurs when transferred weights have excessive norm from low-noise upstream training but the universal signal is weak, causing noise amplification in the target task.
- Mechanism: When upstream training has large N₁ or low σ_{p,1}, the learned weight norm for the universal signal component (γ coefficients) grows large. If the actual universal signal ‖u‖₂ is weak relative to task-specific signal, these large weights fail to meaningfully enhance the weak shared signal but instead amplify task-specific noise from the source domain that is irrelevant or harmful to the target task.
- Core assumption: The condition ‖u+v₂‖²₂/‖u‖²₂ ≥ αN₁σ²_{p,2}/(N₂σ²_{p,1}) must hold for negative transfer; i.e., task-specific signal dominates universal signal while upstream conditions produce large weights.
- Evidence anchors:
  - [Section 1] "The key mechanism is that the weight norm learned from the upstream model becomes excessively large... magnify task-specific noise"
  - [Section 4, Proposition 4.4] Mathematical conditions for negative transfer
  - [corpus] "Optimizing Specific and Shared Parameters for Efficient Parameter Tuning" addresses parameter-efficient transfer but does not characterize negative transfer theoretically
- Break condition: Strong universal signal ‖u‖₂ or careful regularization of transferred weight norms prevents negative transfer even with large upstream sample sizes.

## Foundational Learning

- **Feature Learning vs Neural Tangent Kernel (NTK) Regime**
  - Why needed here: The paper's analysis relies on small initialization enabling feature learning dynamics where weights meaningfully evolve during training, unlike NTK/lazy training where weights stay near initialization.
  - Quick check question: Can you explain why small initialization (σ₀ small) allows the network to learn signal features rather than memorizing through kernel methods?

- **Signal-Noise Decomposition in Gradient Updates**
  - Why needed here: The proof decomposes weight updates into components along universal signal (γ), task-specific signal, and noise (ρ), tracking how each evolves differently during training.
  - Quick check question: Given a weight update Δw = -η∇L, how would you decompose it into contributions from signal vs noise directions?

- **Phase Transitions in Generalization**
  - Why needed here: Understanding sharp thresholds (not gradual degradation) helps predict when transfer will suddenly fail rather than degrade gracefully.
  - Quick check question: What parameters in the condition d ≤ f(N₁,N₂,‖u‖₂,σ_{p,i}) determine which side of the phase transition a problem falls on?

## Architecture Onboarding

- **Component map:**
  - Upstream model -> Two-layer ReLU CNN with m convolutional filters, trained on Task 1 (N₁ samples)
  - Transfer step -> Copy αm filters to downstream; reinitialize remaining
  - Downstream model -> Same architecture, receives αm inherited filters + (1-α)m randomly initialized filters
  - Training -> Gradient descent with cross-entropy loss, learning rate η

- **Critical path:**
  1. Train upstream to T* epochs on source task
  2. Copy αm weights to downstream; reinitialize remaining
  3. Train downstream on target task to T** epochs
  4. Test error determined by whether phase transition condition is satisfied

- **Design tradeoffs:**
  - Higher α (more inherited weights) increases Γ, potentially improving transfer, but may increase negative transfer risk if universal signal is weak
  - Larger N₁ improves upstream knowledge but may produce over-amplified weights
  - Lower σ_{p,1} (source noise) helps upstream learning but creates same over-amplification risk

- **Failure signatures:**
  - Test accuracy ~50% (random) despite low training loss: likely on wrong side of phase transition (d too large or signals too weak)
  - Transfer underperforms random initialization: negative transfer; check if source/target tasks share minimal universal structure
  - Training loss converges but test error plateaus at ~10%: sub-optimal regime per Theorem 4.2

- **First 3 experiments:**
  1. **Sanity check with known universal signal:** Generate synthetic data per Definition 3.1/3.2 with controlled ‖u‖₂, verify phase transition occurs at predicted d threshold (replicate Figure 2)
  2. **Ablate α (inheritance ratio):** With fixed N₁, N₂, d, vary α ∈ {0.1, 0.3, 0.5, 0.7, 1.0} and observe whether larger Γ correlates with lower test error; verify random initialization baseline (α=0) is outperformed only when universal signal exists
  3. **Negative transfer probe:** Set ‖u‖₂ ≈ 0 (no universal knowledge), large N₁, low σ_{p,1}; confirm transfer harms downstream accuracy vs scratch training; then add weight norm regularization (e.g., L2 penalty on transferred weights) and test if negative transfer is mitigated

## Open Questions the Paper Calls Out
None

## Limitations
- The analysis assumes two-layer ReLU CNN architecture, which differs significantly from modern deep networks with normalization and skip connections
- The theoretical framework relies on orthogonal signal-noise decomposition that may not capture complex, distributed representations in practice
- The analysis focuses on full-batch gradient descent rather than the mini-batch SGD commonly used in deep learning

## Confidence
- High confidence in the mathematical proofs and theoretical framework
- Medium confidence in the phase transition characterization and conditions
- Medium confidence in the negative transfer mechanism
- Low confidence in direct real-world applicability without empirical validation

## Next Checks
1. **Architecture Generalization Test:** Replicate the phase transition analysis using a 3-layer CNN or ResNet block to verify whether the theoretical conditions hold beyond the two-layer assumption. Test if universal knowledge still manifests as explicit orthogonal signal components.

2. **Modern Optimization Effects:** Repeat the synthetic experiments using SGD with momentum and batch normalization. Determine whether the negative transfer phenomenon persists under practical optimization conditions or is an artifact of idealized full-batch training.

3. **Empirical Scaling Laws:** Conduct controlled experiments on CIFAR-10→CIFAR-100 with varying architecture widths (different m values) and initialization scales (σ₀). Verify whether the d ≤ f(N₁,N₂,‖u‖₂,σ_{p,i}) phase transition manifests empirically and identify the constants C₁,C₂,C₃ through systematic variation.