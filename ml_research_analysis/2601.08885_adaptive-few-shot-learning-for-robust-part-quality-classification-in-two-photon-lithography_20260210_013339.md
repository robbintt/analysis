---
ver: rpa2
title: Adaptive few-shot learning for robust part quality classification in two-photon
  lithography
arxiv_id: '2601.08885'
source_url: https://arxiv.org/abs/2601.08885
tags:
- damaged
- domain
- class
- learning
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses the challenge of maintaining robust quality
  classification models in dynamic two-photon lithography environments, where new
  defect classes and part geometries continuously emerge. The authors propose an adaptive
  computer vision framework built on a scale-robust backbone model that integrates
  three methodologies: a statistical hypothesis testing framework for novelty detection,
  a two-stage rehearsal-based strategy for few-shot incremental learning, and a few-shot
  Domain-Adversarial Neural Network for domain adaptation.'
---

# Adaptive few-shot learning for robust part quality classification in two-photon lithography

## Quick Facts
- arXiv ID: 2601.08885
- Source URL: https://arxiv.org/abs/2601.08885
- Authors: Sixian Jia; Ruo-Syuan Mei; Chenhui Shao
- Reference count: 40
- Primary result: Framework achieves 99-100% novelty detection accuracy, 92% incremental learning accuracy with 20 samples, and 96.19% domain adaptation accuracy with 5 shots per class

## Executive Summary
This paper addresses the challenge of maintaining robust quality classification models in dynamic two-photon lithography environments where new defect classes and part geometries continuously emerge. The authors propose an adaptive computer vision framework built on a scale-robust backbone model that integrates three methodologies: a statistical hypothesis testing framework for novelty detection, a two-stage rehearsal-based strategy for few-shot incremental learning, and a few-shot Domain-Adversarial Neural Network for domain adaptation. The framework was evaluated on a dataset featuring hemisphere (source domain) and cube (target domain) structures with three quality classes each, demonstrating high accuracy across all three components even with minimal training data.

## Method Summary
The framework consists of three integrated components designed to handle the evolving nature of two-photon lithography production. First, a statistical hypothesis testing framework detects novel defect classes by comparing feature distributions of incoming samples against known classes. Second, a two-stage rehearsal-based strategy enables incremental learning of new classes using only 20 samples per class while preserving knowledge of existing classes. Third, a few-shot Domain-Adversarial Neural Network adapts the model to new part geometries (like transitioning from hemispheres to cubes) using just 5 samples per class. The scale-robust backbone model provides the foundation for handling variations in part size and geometry, while the integration of these three methodologies creates a comprehensive solution for maintaining classification accuracy in dynamic manufacturing environments.

## Key Results
- Statistical hypothesis testing framework achieved 99-100% accuracy in detecting new class batches
- Incremental learning method integrated a new class with 92% accuracy using only 20 samples
- Domain adaptation model achieved 96.19% accuracy on target domain using only 5 shots per class

## Why This Works (Mechanism)
The framework's effectiveness stems from its ability to detect novelty, learn incrementally with minimal data, and adapt to new domains without catastrophic forgetting. The statistical hypothesis testing leverages feature distribution differences to identify novel classes with high confidence, while the rehearsal-based incremental learning preserves knowledge of existing classes through episodic memory. The Domain-Adversarial Neural Network simultaneously learns domain-invariant features and class-specific representations, enabling effective adaptation with minimal samples. This multi-pronged approach addresses the core challenges of evolving manufacturing environments where new defects emerge and part geometries change over time.

## Foundational Learning

**Statistical hypothesis testing for novelty detection**: Why needed - to identify when incoming samples belong to unknown classes; Quick check - compare p-values against significance threshold to trigger novelty detection

**Episodic memory for rehearsal learning**: Why needed - to prevent catastrophic forgetting when learning new classes; Quick check - maintain balanced representation of old and new class samples during training

**Domain-adversarial training**: Why needed - to learn features that generalize across different part geometries; Quick check - monitor domain classifier loss to ensure effective domain confusion

## Architecture Onboarding

**Component map**: Backbone feature extractor -> Hypothesis testing module -> Incremental learning module -> Domain adaptation module -> Final classifier

**Critical path**: Feature extraction → Novelty detection → Incremental class integration → Domain adaptation → Quality classification

**Design tradeoffs**: The framework balances data efficiency (few-shot learning) against model capacity and complexity, sacrificing some computational overhead for the ability to adapt with minimal samples.

**Failure signatures**: 
- High false positives in novelty detection indicate overly sensitive hypothesis thresholds
- Catastrophic forgetting suggests insufficient rehearsal memory or improper balancing
- Poor domain adaptation performance indicates insufficient domain confusion or feature alignment

**First experiments**:
1. Test novelty detection accuracy on known vs unknown class distributions
2. Evaluate incremental learning with varying numbers of rehearsal samples
3. Measure domain adaptation performance across different domain shifts

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Framework generalizability beyond specific hemisphere and cube geometries tested
- Scalability challenges to more complex part structures with diverse defect types
- Assumption of limited sample availability (20 for incremental learning, 5 for domain adaptation) may not hold in all scenarios

## Confidence

**High confidence**: Framework's effectiveness in detecting new class batches with high accuracy (99-100%) using statistical hypothesis testing is well-supported by the results presented.

**Medium confidence**: Performance of incremental learning and domain adaptation components (92% accuracy with 20 samples and 96.19% accuracy with 5 shots, respectively) is promising but may vary depending on complexity of new classes or domains encountered in practice.

**Low confidence**: Long-term robustness of framework in continuously evolving production environments, particularly in handling subtle defect patterns and scaling to more complex part geometries, requires further validation through extensive real-world testing.

## Next Checks

1. Evaluate framework's performance on a larger and more diverse dataset that includes a wider range of part geometries and defect types to assess its generalizability.

2. Conduct real-world testing in a production environment to measure framework's effectiveness in handling continuous changes and evolving defect patterns over an extended period.

3. Investigate computational requirements and resource usage of framework during adaptation phases to ensure feasibility for real-time deployment in production settings.