---
ver: rpa2
title: Algorithmic Stability of Stochastic Gradient Descent with Momentum under Heavy-Tailed
  Noise
arxiv_id: '2502.00885'
source_url: https://arxiv.org/abs/2502.00885
tags:
- lemma
- where
- generalization
- proof
- page
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper establishes generalization bounds for stochastic gradient\
  \ descent with momentum (SGDm) under heavy-tailed noise, a setting that has previously\
  \ been limited to SGD. The authors analyze the continuous-time limit of SGDm as\
  \ a L\xB4evy-driven SDE and derive Wasserstein algorithmic stability bounds for\
  \ non-convex loss functions."
---

# Algorithmic Stability of Stochastic Gradient Descent with Momentum under Heavy-Tailed Noise

## Quick Facts
- **arXiv ID:** 2502.00885
- **Source URL:** https://arxiv.org/abs/2502.00885
- **Reference count:** 40
- **Primary result:** Establishes generalization bounds for SGDm under heavy-tailed noise, showing momentum can worsen generalization compared to SGD for quadratic loss functions.

## Executive Summary
This paper investigates the generalization properties of stochastic gradient descent with momentum (SGDm) under heavy-tailed noise, a setting previously analyzed only for vanilla SGD. The authors derive Wasserstein algorithmic stability bounds by analyzing the continuous-time limit of SGDm as a Lévy-driven stochastic differential equation. A key finding is that for quadratic loss functions, SGDm exhibits worse generalization bounds than SGD, revealing that the interaction between heavy tails and momentum can be harmful. The paper also develops a novel uniform-in-time discretization error bound, showing that with appropriate step sizes, the discrete dynamics retain the generalization properties of the continuous-time limit. Experiments on synthetic quadratic problems and neural networks support these theoretical findings.

## Method Summary
The authors analyze the continuous-time limit of SGDm as an underdamped Langevin equation driven by an α-stable Lévy process. They establish Wasserstein algorithmic stability bounds by constructing a Lyapunov function and proving geometric drift conditions. The analysis is then extended to the discrete-time algorithm by deriving a uniform-in-time discretization error bound between the SDE and its Euler-Maruyama discretization. This allows transferring the stability properties from the continuous to the discrete setting under appropriate step size constraints.

## Key Results
- SGDm exhibits worse Wasserstein stability bounds than SGD for quadratic loss functions under heavy-tailed noise
- A novel uniform-in-time discretization error bound is derived for SDEs with degenerate noise
- The step size must be smaller than a threshold $\bar{\eta}$ to preserve generalization properties in the discrete algorithm
- Experiments validate the theoretical predictions on synthetic quadratics and neural networks

## Why This Works (Mechanism)

### Mechanism 1: Momentum-Amplified Sensitivity to Data Perturbations
- **Claim:** If gradient noise is heavy-tailed (infinite variance), the interaction between momentum and the noise degrades generalization bounds compared to vanilla SGD, specifically for quadratic loss functions.
- **Mechanism:** Momentum introduces an augmented state space (position + velocity). Under heavy-tailed Lévy noise, the spectral properties of the coupled system result in a lower effective contraction rate ($\sigma_{min}$) compared to the non-momentum system ($\theta_{min}$). This lower contraction rate implies the algorithm "forgets" initial dataset differences more slowly, increasing the Wasserstein distance between outputs trained on datasets differing by a single point.
- **Core assumption:** The loss is quadratic (or satisfies specific non-convex dissipativity), and noise follows an α-stable distribution where $1 < \alpha < 2$.
- **Evidence anchors:**
  - [abstract]: "...interaction of momentum and heavy tails can be harmful for generalization."
  - [section 4]: Proposition 8 proves $\sigma_{min} \leq \theta_{min}$, mathematically confirming the worse bound for SGDm.
  - [corpus]: "On the Provable Suboptimality of Momentum SGD..." discusses momentum suboptimality in nonstationary settings, aligning with the view that momentum is not universally beneficial.
- **Break condition:** If the gradient noise is Gaussian ($\alpha=2$) or variance is bounded, this specific heavy-tail interaction mechanism does not apply.

### Mechanism 2: Uniform-in-Time Discretization Transfer
- **Claim:** If the continuous-time SDE is stable, the discrete SGDm algorithm retains these generalization properties provided step sizes are sufficiently small.
- **Mechanism:** The authors establish a uniform-in-time 1-Wasserstein discretization error bound (Theorem 12). By ensuring the Euler-Maruyama-like discretization error scales as $O(\eta^{1/\alpha})$ and does not accumulate unboundedly over time, the stability of the continuous limiting process transfers directly to the discrete training dynamics.
- **Core assumption:** Step size $\eta$ must be smaller than an explicit threshold $\bar{\eta}$ derived from Lyapunov drift conditions (Eq 67).
- **Evidence anchors:**
  - [abstract]: "...with appropriately chosen step-sizes, the discrete dynamics retain the generalization properties of the continuous-time limit."
  - [section 5]: Theorem 12 explicitly bounds the distance between invariant measures of the SDE and the discrete chain.
  - [corpus]: "Stability and Generalization of Nonconvex Optimization..." focuses on continuous time; this paper bridges the gap to discrete algorithms.
- **Break condition:** If step sizes are too large, the discretization error explodes, and the continuous theory no longer explains the discrete algorithm's behavior.

### Mechanism 3: Lyapunov-Based Contraction
- **Claim:** The system achieves algorithmic stability (and thus generalization) because the underlying stochastic process is exponentially ergodic.
- **Mechanism:** The analysis relies on constructing a Lyapunov function $W(\theta, v)$ (Eq 40) that satisfies geometric drift conditions (Lemma 16). This function proves that two trajectories of the SDE, starting from different initial data points, contract in Wasserstein distance exponentially fast, bounding the maximum sensitivity to data replacement.
- **Core assumption:** The loss function must satisfy dissipativity (Condition H3) and gradient growth bounds (Condition H2).
- **Evidence anchors:**
  - [section 3]: "Our analysis relies on a Wasserstein contraction rate... obtained in Bao and Wang (2022)."
  - [appendix a.3]: Lemma 16 details the Lyapunov function construction satisfying $LW \leq -c_0 W + C_0$.
  - [corpus]: "Tight Generalization Error Bounds..." also utilizes stability frameworks, validating this as a standard mechanism for generalization bounds.
- **Break condition:** If the loss is not dissipative (e.g., strongly convex in the "wrong" direction or exploding gradients without bound), the Lyapunov drift condition fails.

## Foundational Learning
- **Concept: α-Stable Lévy Processes**
  - **Why needed here:** This models the "heavy-tailed" noise where variance can be infinite ($\alpha < 2$). Standard Brownian motion assumptions ($\alpha=2$) fail to capture the generalization dynamics described.
  - **Quick check question:** If $\alpha=1.5$, does the gradient noise have finite variance?
- **Concept: Wasserstein Algorithmic Stability**
  - **Why needed here:** This is the mathematical bridge connecting the optimization dynamics (how parameters move) to generalization (how test error behaves) by measuring the sensitivity of the output to training data changes.
  - **Quick check question:** Why is uniform stability defined as the supremum over datasets $X \sim= \hat{X}$?
- **Concept: Underdamped Langevin Dynamics**
  - **Why needed here:** This is the continuous-time analogue of SGD with momentum. It couples position ($\theta$) and velocity ($v$), essential for understanding why momentum changes the spectral properties (stability) of the system.
  - **Quick check question:** In Eq (8), does the noise enter the position update $d\theta_t$ or the velocity update $dv_t$?

## Architecture Onboarding
- **Component map:** Data $X_n$ -> Heavy-tailed noise $\xi_k$ (scale $\zeta$, index $\alpha$) -> Momentum $\gamma$ -> Discrete Recursion (Eq 5) -> Continuous SDE (Eq 8) -> Lyapunov Drift Analysis -> Stability Bounds
- **Critical path:** Start with Section 4 (Quadratic Loss) to understand the "harmful" interaction proof (Prop 8). Then trace back to Section 3 for the general bounds and Theorem 12 for the discrete-to-continuous link.
- **Design tradeoffs:** Momentum improves convergence speed (acceleration) but, under this specific heavy-tailed model, worsens stability bounds (generalization). There is a tension between training acceleration and test error stability.
- **Failure signatures:**
  - **Oversized Step Size:** If $\eta > \bar{\eta}$ (Eq 67), the discretization bound fails; the theoretical guarantee vanishes.
  - **Non-dissipative Loss:** If the loss grows faster than quadratic or lacks the dissipative structure, the Lyapunov function (Eq 40) may not contract.
- **First 3 experiments:**
  1. **Synthetic Quadratic Validation:** Replicate Figure 1 by varying $\alpha$ (tail index) and $\gamma$ (momentum) to verify that the generalization gap widens specifically as $\gamma$ increases.
  2. **Step Size Ablation:** Test the boundary condition $\bar{\eta}$. Run the discrete algorithm with $\eta$ just below and just above the theoretical threshold to observe the transition from stable to unstable generalization scaling.
  3. **Noise Injection on MNIST:** As described in Section 6, inject scaled Lévy noise into a CNN training loop. Compare SGD vs. SGDm test accuracy to see if the "harmful" interaction holds empirically beyond quadratic losses.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the precise theoretical mechanism explaining why the interaction between momentum and heavy tails harms generalization?
- Basis in paper: [explicit] "Our results illustrate that momentum worsens generalization... However, at this stage we are not able to explain why this happens and we leave the finer understanding of the interaction between heavy tails and momentum for future work."
- Why unresolved: While the paper proves bounds are worse for SGDm than SGD, the analysis does not isolate the specific dynamical factor causing this degradation.
- What evidence would resolve it: A theoretical decomposition of the stability bound identifying the specific term or coupling failure driven by momentum in the presence of heavy-tailed noise.

### Open Question 2
- Question: Can a direct comparison of generalization bounds between heavy-tailed SGD and SGDm be derived for general non-convex loss functions?
- Basis in paper: [explicit] Remark 5 states that while a comparison is expected, "this is a hard task when considering general loss functions" due to non-explicit constants in the referenced theoretical framework.
- Why unresolved: The paper successfully compares the algorithms for quadratic losses (Proposition 8), but the constants used for general non-convex losses are not sufficiently explicit to determine which algorithm performs better.
- What evidence would resolve it: A derivation of stability bounds for general losses with fully computable constants, allowing for a direct inequality comparison similar to the quadratic case.

### Open Question 3
- Question: How does the accelerated convergence rate of momentum with gradient clipping under heavy-tailed noise affect generalization error?
- Basis in paper: [explicit] The conclusion notes that prior work showed momentum achieves faster training rates with clipping, but "The link between convergence speed and the generalization error is also yet to be understood."
- Why unresolved: The current study focuses on stability without clipping, leaving the trade-off between the faster optimization rates of clipped SGDm and its generalization properties unexplored.
- What evidence would resolve it: A unified analysis providing generalization bounds specifically for clipped SGDm, potentially revealing if the acceleration comes at the cost of stability.

## Limitations
- Analysis assumes gradient noise follows an α-stable distribution, which may not perfectly match real-world deep learning scenarios
- Theoretical guarantees for the discrete algorithm only hold when step sizes are smaller than a derived threshold, which may be impractically small
- Results are proven in the continuous-time limit, requiring discretization analysis for practical algorithms

## Confidence
- **High:** The Lyapunov drift analysis and the core stability bounds (Theorem 7, Proposition 8) are mathematically rigorous under the stated assumptions.
- **Medium:** The uniform-in-time discretization error bound (Theorem 12) is novel and technically sound, but its tightness for practical step sizes is not explored.
- **Medium:** The empirical experiments on synthetic quadratics (Figure 1) and neural networks support the theoretical claims, but the neural network results are more correlational than mechanistic.

## Next Checks
1. **Tightness of Step Size Constraint:** Determine the practical feasibility of the $\bar{\eta}$ bound by running experiments where $\eta$ approaches this threshold. Observe if the predicted transition from stable to unstable generalization scaling occurs.
2. **Generalization of the "Harmful" Effect:** Test the quadratic loss result on other strongly convex or smooth non-convex losses (e.g., logistic loss, small neural networks) to see if momentum consistently degrades stability bounds under heavy tails.
3. **Empirical Noise Distribution Fitting:** For a standard neural network training task, fit the empirical distribution of gradient noise to an α-stable model. Quantify how well the theoretical framework predicts the observed generalization gap between SGD and SGDm.