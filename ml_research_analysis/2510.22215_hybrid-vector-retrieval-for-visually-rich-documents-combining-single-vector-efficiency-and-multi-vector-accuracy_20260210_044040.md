---
ver: rpa2
title: 'Hybrid-Vector Retrieval for Visually Rich Documents: Combining Single-Vector
  Efficiency and Multi-Vector Accuracy'
arxiv_id: '2510.22215'
source_url: https://arxiv.org/abs/2510.22215
tags:
- retrieval
- query
- pages
- document
- heaven
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: HEAVEN addresses the efficiency-accuracy trade-off in visual document
  retrieval by introducing a two-stage hybrid-vector framework. In Stage 1, it efficiently
  retrieves candidate pages using single-vector retrieval over visually-summarized
  pages (VS-pages), which compress multiple pages into compact visual layouts.
---

# Hybrid-Vector Retrieval for Visually Rich Documents: Combining Single-Vector Efficiency and Multi-Vector Accuracy

## Quick Facts
- arXiv ID: 2510.22215
- Source URL: https://arxiv.org/abs/2510.22215
- Authors: Juyeon Kim; Geon Lee; Dongwon Choi; Taeuk Kim; Kijung Shin
- Reference count: 17
- Primary result: 99.87% Recall@1 performance with 99.82% reduction in computation

## Executive Summary
HEAVEN introduces a hybrid-vector retrieval framework that addresses the efficiency-accuracy trade-off in visual document retrieval. The system employs a two-stage approach: first using single-vector retrieval over visually-summarized pages (VS-pages) to efficiently identify candidate documents, then applying multi-vector retrieval with linguistic importance filtering to rerank and refine results. The authors also introduce VIMDOC, the first benchmark for visually rich, multi-document, and long-document retrieval. Across four benchmarks, HEAVEN achieves near-optimal accuracy while dramatically reducing computational costs.

## Method Summary
The proposed hybrid-vector framework operates in two stages. Stage 1 employs single-vector retrieval over VS-pages, which compress multiple pages into compact visual layouts for efficient candidate retrieval. Stage 2 performs multi-vector retrieval on the filtered candidates, with an additional linguistic importance filter that reduces redundant computations by prioritizing query tokens. This architecture allows the system to maintain high accuracy while achieving significant efficiency gains through early-stage filtering and intelligent token selection.

## Key Results
- Achieves 99.87% of multi-vector model Recall@1 performance
- Reduces per-query computation by 99.82%
- Introduces VIMDOC, the first benchmark for visually rich, multi-document, long-document retrieval
- Validated across four different benchmarks

## Why This Works (Mechanism)
The hybrid approach works by strategically combining the strengths of different retrieval paradigms. Single-vector retrieval provides computational efficiency through compact representation, while multi-vector retrieval maintains accuracy through detailed analysis. The two-stage architecture allows early elimination of irrelevant documents, focusing computational resources only on promising candidates. Linguistic importance filtering further optimizes the process by reducing redundant token processing, maintaining accuracy while improving efficiency.

## Foundational Learning

**Visual Document Retrieval**: The task of finding relevant documents containing both textual and visual content. Needed to understand the complexity of processing multi-modal documents efficiently. Quick check: Can the system handle documents where visual layout carries semantic meaning?

**Single-vector vs Multi-vector Retrieval**: Single-vector uses one embedding per document for efficiency, while multi-vector creates embeddings for different document sections for accuracy. Needed to understand the fundamental trade-off being addressed. Quick check: How does document length affect the choice between single and multi-vector approaches?

**Visually-summarized Pages (VS-pages)**: Compact visual representations that compress multiple pages into single views. Needed to understand how the system maintains visual information while improving efficiency. Quick check: Does VS-page compression preserve critical layout information?

**Linguistic Importance Filtering**: A mechanism to prioritize query tokens based on their importance for retrieval. Needed to understand how computational efficiency is achieved without sacrificing accuracy. Quick check: How is linguistic importance quantified and validated?

## Architecture Onboarding

**Component Map**: Document -> VS-page Encoding -> Single-vector Index -> Candidate Selection -> Multi-vector Reranking -> Linguistic Importance Filtering -> Final Ranking

**Critical Path**: Query processing -> VS-page candidate retrieval -> Multi-vector reranking -> Linguistic filtering -> Result output

**Design Tradeoffs**: Efficiency vs accuracy (single-vector vs multi-vector), computational cost vs comprehensiveness (linguistic filtering), visual compression vs information preservation (VS-pages)

**Failure Signatures**: Poor recall when visual layout is crucial for document meaning, reduced precision with aggressive linguistic filtering, suboptimal performance on documents that don't compress well into VS-pages

**First Experiments**:
1. Test baseline single-vector and multi-vector retrieval separately to establish performance bounds
2. Validate VS-page representation quality across different document types
3. Evaluate linguistic importance filtering impact on both accuracy and efficiency

## Open Questions the Paper Calls Out

None specified in the provided material.

## Limitations

- Evaluation focuses primarily on Recall@1, potentially missing other important metrics like precision and result diversity
- Performance generalizability across different document types and real-world scenarios needs validation
- VS-pages representation effectiveness for complex visual layouts across diverse document types remains untested

## Confidence

- **Efficiency gains (99.82% reduction)**: High confidence - the two-stage approach with single-vector filtering is theoretically sound and magnitude of improvement is clearly demonstrated
- **Accuracy retention (99.87% of multi-vector Recall@1)**: Medium confidence - benchmark results support this claim, but generalizability needs further validation
- **VIMDOC benchmark validity**: Medium confidence - as the first benchmark for this specific task, its comprehensiveness remains to be established

## Next Checks

1. Test HEAVEN's performance on documents with varying visual complexity levels to assess whether VS-pages consistently preserve critical information across different document types

2. Evaluate the system's performance using additional metrics beyond Recall@1, including precision, diversity of results, and latency in real-world deployment scenarios

3. Conduct ablation studies to quantify the impact of linguistic importance filtering on retrieval quality, particularly for documents where visual and textual information are equally critical