---
ver: rpa2
title: Multi-party Agent Relation Sampling for Multi-party Ad Hoc Teamwork
arxiv_id: '2510.25340'
source_url: https://arxiv.org/abs/2510.25340
tags:
- agents
- learning
- agent
- uncontrolled
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of Multi-party Ad Hoc Teamwork
  (MAHT), where a variable number of controlled agents must coordinate with multiple
  groups of unfamiliar, uncontrolled teammates. Existing approaches assume fixed teams
  or that uncontrolled agents are mutually familiar, which limits applicability in
  real-world scenarios.
---

# Multi-party Agent Relation Sampling for Multi-party Ad Hoc Teamwork

## Quick Facts
- arXiv ID: 2510.25340
- Source URL: https://arxiv.org/abs/2510.25340
- Authors: Beiwen Zhang; Yongheng Liang; Hejun Wu
- Reference count: 40
- Key outcome: MARS outperforms MARL and AHT baselines in MPE and SMAC tasks, with faster convergence and stronger performance, particularly in larger-scale scenarios.

## Executive Summary
This paper addresses Multi-party Ad Hoc Teamwork (MAHT), where controlled agents must coordinate with multiple groups of unfamiliar, uncontrolled teammates. Existing approaches assume fixed teams or mutual familiarity among uncontrolled agents, limiting real-world applicability. The authors propose MARS, which constructs a sparse agent skeleton graph with fully connected intra-group subgraphs and randomly sampled inter-group edges. This reduces computational overhead while preserving coordination dependencies. MARS integrates agent modeling, relational reasoning via a Relational Forward Model (RFM), and policy optimization, demonstrating superior performance on MPE and SMAC benchmarks.

## Method Summary
MARS addresses MAHT by building a sparse agent skeleton graph where each group forms a fully connected subgraph, and inter-group edges are randomly sampled. An encoder-decoder per agent maps observation-action trajectories into latent embeddings, trained via reconstruction and action prediction losses. The RFM performs iterative message passing over this skeleton to infer latent cooperation dynamics. Policy and value networks condition on trajectory and cooperation embeddings, with IPPO updates applied to the actor (from controlled agents only) and critic (from all agents). This approach reduces pairwise modeling complexity while preserving coordination pathways.

## Key Results
- MARS outperforms MARL and AHT baselines in MPE and SMAC tasks
- Faster convergence compared to state-of-the-art methods
- Stronger performance in larger-scale scenarios (8v9, 10v11) where sparse skeleton provides clear benefits
- Minimal performance gap in small teams (3 agents) where skeleton ≈ fully connected

## Why This Works (Mechanism)

### Mechanism 1: Sparse Agent Skeleton Graph Construction
- Claim: A sparsely connected graph can approximate coordination structure while reducing computational overhead compared to full pairwise modeling.
- Mechanism: Each group forms a fully connected subgraph; inter-group edges are randomly sampled to create a skeleton. This preserves coordination pathways while pruning redundant edges that scale quadratically with agent count.
- Core assumption: Critical coordination dependencies can be preserved through representative edge sampling, drawing on graph-theoretic results that sparse skeletons approximate original graphs.
- Evidence anchors:
  - [abstract] "builds a sparse agent skeleton graph... reduces computational redundancy while preserving key coordination dependencies"
  - [Section 4.2] "MARS constructs a sparse agent skeleton: intra-group agents are fully connected, while inter-group edges are reduced by linking randomly chosen representative nodes"
  - [corpus] Weak direct evidence; neighbor papers on AHT do not address sparse graph mechanisms.
- Break condition: If inter-group coordination requires dense communication patterns, sparse sampling may miss critical edges.

### Mechanism 2: Trajectory-Based Agent Modeling
- Claim: Agent embeddings derived from observation-action histories enable controlled agents to infer unknown teammate behaviors without prior knowledge.
- Mechanism: An encoder-decoder maps each agent's trajectory (observations and past actions) into a latent embedding, trained via reconstruction loss and action prediction. Embeddings serve as node features for relational reasoning.
- Core assumption: Behavioral regularities are recoverable from local observation-action sequences under partial observability.
- Evidence anchors:
  - [abstract] "MARS integrates agent modeling, relational reasoning via a Relational Forward Model (RFM)"
  - [Section 4.1] "Each controlled agent i employs an encoder-decoder that maps its trajectory... trained to reconstruct o_t^i and predict a_t^i"
  - [corpus] Neighbor papers (PADiff, ReCollab) support trajectory-based teammate modeling but use different architectures.
- Break condition: If teammates exhibit highly stochastic or non-stationary behavior patterns, embeddings may fail to capture predictive structure.

### Mechanism 3: Relational Forward Model (RFM) for Cross-Group Dynamics
- Claim: Iterative message passing over the sparse skeleton enables controlled agents to reason about multi-party coordination dynamics.
- Mechanism: RFM performs multi-step message passing where node, edge, and global attributes are updated through learned functions (MLPs) and permutation-invariant aggregations. This propagates behavioral information across groups.
- Core assumption: Latent cooperation dynamics emerge from structured relational inference rather than direct agent-to-agent connections.
- Evidence anchors:
  - [abstract] "relational reasoning via a Relational Forward Model (RFM)"
  - [Section 4.2] "The RFM performs iterative message passing... enables the model to infer latent cooperation dynamics among sparsely connected groups"
  - [Section 5.2] Ablation: "Comparing MARS w/o Skeleton with POAM highlights the essential role of the RFM block"
  - [corpus] RFM mechanism originates from Battaglia et al. 2018 (cited as [2]), providing external validation.
- Break condition: If coordination requires deep multi-hop reasoning beyond RFM depth, message passing may not propagate sufficient information.

## Foundational Learning

- Concept: **Dec-POMDP (Decentralized Partially Observable Markov Decision Process)**
  - Why needed here: MAHT is formalized as a Dec-POMDP; understanding partial observability, joint rewards, and decentralized execution is prerequisite.
  - Quick check question: Can you explain why each agent receives only a local observation rather than full state access?

- Concept: **Graph Neural Networks / Message Passing**
  - Why needed here: RFM operates as a graph network; understanding node/edge updates and permutation-invariant aggregation is essential.
  - Quick check question: How does message passing differ from simply concatenating all agent embeddings?

- Concept: **Ad Hoc Teamwork (AHT) Problem Setting**
  - Why needed here: MARS extends AHT to multi-party scenarios; distinguishing controlled vs. uncontrolled agents and the zero-shot generalization requirement is foundational.
  - Quick check question: What makes AHT harder than standard MARL with fixed teammates?

## Architecture Onboarding

- Component map:
  1. Agent Modeling Network — Encoder-decoder per agent; outputs trajectory embeddings
  2. Sparse Skeleton Graph — Fully connected intra-group; sampled inter-group edges
  3. RFM Block — Message passing over skeleton; outputs cooperation embeddings
  4. Policy Network (Actor) — Conditioned on trajectory + cooperation embedding
  5. Value Network (Critic) — Trained with full team data; guides policy updates

- Critical path:
  Observation → Trajectory Buffer → Agent Encoder → Skeleton Graph Construction → RFM Message Passing → Cooperation Embedding → Policy/Value Networks → Action

- Design tradeoffs:
  - Skeleton sparsity vs. expressiveness: More inter-group edges improve modeling capacity but increase compute; paper shows benefits emerge at larger scales (8v9, 10v11)
  - RFM depth vs. training stability: Deeper message passing captures longer-range dependencies but may introduce optimization difficulty
  - Full parameter sharing vs. agent-specific models: Paper uses parameter sharing for scalability; may limit heterogeneous agent specialization

- Failure signatures:
  - Performance collapse in small-team settings (3 agents) → skeleton equivalent to full graph; RFM provides no benefit
  - Slow convergence or unstable training → check RFM aggregation stability and learning rate scaling
  - Poor generalization to new teammate types → agent modeling may underfit trajectory patterns; increase encoder capacity or trajectory window

- First 3 experiments:
  1. Reproduce MPE-PP (3 predators) to validate skeleton has no negative effect when n=3 (skeleton ≈ fully connected)
  2. Run ablation on SMAC 8v9: compare MARS vs. MARS w/o Skeleton to confirm scalability benefits
  3. Test generalization: train with 2 uncontrolled groups, evaluate with 3-5 groups to assess out-of-distribution robustness

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the text provided.

## Limitations
- Architecture granularity: Critical hyperparameters for RFM (message-passing iterations, MLP widths) and agent modeling (trajectory window, encoder/decoder) are underspecified
- Sparse skeleton sampling: Inter-group edge sampling strategy (ratio, randomness) is not clearly defined, affecting reproducibility
- Scalability boundary: Unclear transition point where sparse skeletons outperform full graphs; minimal difference in 5v6 scenarios
- Generalization beyond trained distributions: Experiments evaluate held-out combinations but not new numbers of uncontrolled groups or entirely different coordination patterns

## Confidence

**High confidence**: The core hypothesis that sparse agent skeleton graphs reduce computational overhead while preserving coordination dependencies. This follows directly from graph-theoretic principles and is demonstrated across multiple scales.

**Medium confidence**: The RFM mechanism's ability to capture cross-group dynamics through message passing. While theoretically sound and supported by ablation studies, the specific architectural choices and their impact remain underspecified.

**Low confidence**: Generalization claims to new teammate types and coordination patterns. Current experiments focus on variation within trained distributions rather than true out-of-distribution scenarios.

## Next Checks

1. **Hyperparameter sensitivity analysis**: Systematically vary RFM message-passing depth (1-4 layers), trajectory window length (4-16 timesteps), and sparse skeleton edge sampling ratio (10-50% of possible inter-group edges) to identify optimal configurations and robustness boundaries.

2. **Scalability breakpoint identification**: Conduct experiments across intermediate scales (6v7, 7v8) to precisely determine when sparse skeletons begin outperforming full graphs and whether performance degrades below this threshold.

3. **True generalization testing**: Train MARS with 2 uncontrolled groups, then evaluate on scenarios with 3-5 groups and with teammate policies trained using different algorithms (e.g., MADDPG, QPLEX) to assess cross-algorithm and cross-group-number generalization.