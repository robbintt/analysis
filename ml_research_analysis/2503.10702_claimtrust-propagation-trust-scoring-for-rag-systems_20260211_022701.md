---
ver: rpa2
title: 'ClaimTrust: Propagation Trust Scoring for RAG Systems'
arxiv_id: '2503.10702'
source_url: https://arxiv.org/abs/2503.10702
tags:
- document
- score
- trust
- claim
- claimtrust
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ClaimTrust addresses trustworthiness assessment in retrieval-augmented
  generation (RAG) systems by introducing a propagation-based trust scoring framework.
  The method adapts PageRank to propagate trust scores across documents based on extracted
  factual claims and their relationships (supporting, refuting, or unrelated).
---

# ClaimTrust: Propagation Trust Scoring for RAG Systems

## Quick Facts
- arXiv ID: 2503.10702
- Source URL: https://arxiv.org/abs/2503.10702
- Authors: Hangkai Qian; Bo Li; Qichen Wang
- Reference count: 7
- Primary result: 11.2% LLM-evaluated quality improvement via claim-propagated trust scores in RAG

## Executive Summary
ClaimTrust introduces a trust scoring framework for retrieval-augmented generation (RAG) systems that propagates credibility scores across documents based on extracted factual claims and their relationships. The method builds a document graph where nodes represent articles and edges capture claim relationships (supporting, refuting, unrelated), then applies PageRank-inspired iterative updates to compute trust scores. Experiments on 814 political news articles show ClaimTrust improves LLM-evaluated response quality by 11.2% while maintaining computational scalability and complementing semantic similarity metrics in RAG ranking.

## Method Summary
ClaimTrust constructs a document graph from extracted factual claims and their relationships, then propagates trust scores using an iterative PageRank-like algorithm. The process begins with claim extraction from documents using Gemma2-7B with Chain-of-Thought prompts, followed by cosine similarity matching to identify claim pairs and LLM-based relationship classification. Trust scores initialize at 0.5 (trusted documents at 1.0) and update iteratively using the formula s^{k+1}_d = (1-α)·s^0_d + α·f(I^k_d) until convergence, where α=0.85. The resulting scores integrate into RAG systems by re-ranking retrieved documents based on combined trust and semantic similarity metrics.

## Key Results
- 11.2% improvement in LLM-evaluated response quality compared to vanilla RAG
- Successfully assigns higher trust scores to verified documents over unverified ones
- Maintains computational scalability while enhancing content generation reliability
- Substring accuracy remained unchanged (0.015) between vanilla and ClaimTrust modes

## Why This Works (Mechanism)
Trustworthiness assessment in RAG systems requires going beyond semantic similarity to evaluate factual reliability. ClaimTrust addresses this by extracting factual claims from documents and analyzing their relationships, creating a network where trust propagates through supporting and refuting connections. Documents supporting verified claims gain credibility while those contradicting them lose trust. This graph-based propagation captures nuanced relationships that isolated document analysis misses, enabling more reliable content ranking for generation tasks.

## Foundational Learning

### PageRank Adaptation
**Why needed**: Standard PageRank measures link-based importance, but ClaimTrust needs to measure trustworthiness propagation through claim relationships rather than hyperlinks.
**Quick check**: Verify that trust scores converge to stable values and that trusted documents consistently receive higher scores than unverified ones.

### Claim Relationship Classification
**Why needed**: The quality of the document graph depends on accurately classifying whether claims support, refute, or are unrelated to each other.
**Quick check**: Manually verify relationship classifications for a sample of claim pairs to ensure the LLM-based approach produces reliable results.

### RAG Integration
**Why needed**: Trust scores must meaningfully combine with semantic similarity to improve retrieval without sacrificing relevance.
**Quick check**: Test whether documents with high trust scores but lower semantic similarity still improve generation quality compared to purely similarity-based ranking.

## Architecture Onboarding

### Component Map
Claim extraction (Gemma2-7B) -> Embedding generation (mxbai-embed-large-v1) -> Cosine similarity matching -> Relationship classification (LLM) -> Document graph construction -> ClaimRank iteration -> Trust score integration -> RAG re-ranking

### Critical Path
The bottleneck is relationship classification via LLM in-context learning, as each claim pair requires model inference. This step directly impacts graph quality and subsequent trust score accuracy.

### Design Tradeoffs
- **Precision vs. coverage**: Using top 4036 claim pairs balances computational feasibility with relationship coverage
- **Static vs. dynamic**: Fixed trust initialization vs. adaptive methods for identifying trusted documents
- **LLM vs. rules**: In-context learning provides flexibility but lacks interpretability compared to rule-based classification

### Failure Signatures
- Oscillation in trust scores during iteration indicates poor damping factor selection or problematic relationship weights
- Convergence to uniform scores suggests insufficient differentiation in claim relationships
- Trust score variance too high indicates potential amplification of classification errors

### First 3 Experiments
1. Validate relationship classification accuracy on a held-out sample of claim pairs
2. Test ClaimRank convergence behavior across different damping factors (0.7-0.95)
3. Compare RAG quality improvements with varying trust-similarity weight combinations

## Open Questions the Paper Calls Out

### Open Question 1
**Can ClaimTrust generalize to domains beyond political news without significant parameter re-tuning?**
The framework's reliance on political news data from a single time period raises questions about cross-domain applicability. The paper identifies this as a future direction, noting that robust evaluation metrics are needed to assess generalization across diverse datasets.

### Open Question 2
**What is the optimal damping factor (α) and relationship weighting for trust score convergence in ClaimRank?**
While α=0.85 follows PageRank convention, the paper acknowledges this choice lacks empirical justification for trust propagation. No ablation study examines sensitivity to α, edge weights, or initialization, leaving convergence behavior uncharacterized.

### Open Question 3
**Does trust score integration improve factual correctness in generated responses, or only surface-level coherence?**
The identical substring accuracy (0.015) between vanilla and ClaimTrust modes, combined with LLM quality improvements, suggests the evaluation may conflate coherence with factual accuracy. The paper calls for human fact-checking and automated verification to distinguish these aspects.

## Limitations

- Evaluation relies solely on LLM scoring without ground truth validation of factual correctness
- Limited to political news domain from a single Kaggle dataset spanning May-June 2017
- Relationship classification quality depends on in-context learning prompts not fully specified
- Trust score integration improves perceived quality but may not enhance actual factual accuracy

## Confidence

- **High**: PageRank-based trust propagation framework and iterative scoring algorithm
- **Medium**: Dataset construction and claim extraction process
- **Low**: Relationship classification quality and specific evaluation setup

## Next Checks

1. Test claim relationship classification with multiple prompt variations to establish robustness
2. Validate convergence behavior across different damping factor values (0.7-0.95 range)
3. Compare trust score distributions against human-annotated document credibility labels when available