---
ver: rpa2
title: Enabling Flexible Multi-LLM Integration for Scalable Knowledge Aggregation
arxiv_id: '2505.23844'
source_url: https://arxiv.org/abs/2505.23844
tags:
- llms
- training
- arxiv
- knowledge
- selection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of integrating multiple large
  language models (LLMs) to build a stronger composite model while avoiding knowledge
  interference and performance degradation that occurs in existing fusion approaches.
  The proposed method introduces an adaptive selection network that dynamically evaluates
  and selects the most relevant source LLMs based on their performance scores, along
  with a dynamic weighted fusion strategy that accounts for the inherent strengths
  of candidate models.
---

# Enabling Flexible Multi-LLM Integration for Scalable Knowledge Aggregation

## Quick Facts
- **arXiv ID:** 2505.23844
- **Source URL:** https://arxiv.org/abs/2505.23844
- **Reference count:** 40
- **Primary result:** Reduces knowledge interference by up to 50% compared to existing methods

## Executive Summary
This paper addresses the challenge of integrating multiple large language models (LLMs) to build a stronger composite model while avoiding knowledge interference and performance degradation that occurs in existing fusion approaches. The proposed method introduces an adaptive selection network that dynamically evaluates and selects the most relevant source LLMs based on their performance scores, along with a dynamic weighted fusion strategy that accounts for the inherent strengths of candidate models. A feedback-driven loss function prevents the selector from converging on a single subset of sources. Experimental results show that the approach reduces knowledge interference by up to 50% compared to existing methods while achieving consistent accuracy improvements across multiple benchmarks including Commonsense, Big-Bench Hard, and MMLU.

## Method Summary
The approach uses an adaptive selection network (ASN) that takes flattened, layer-normalized probability distribution matrices from each source LLM and passes them through three linear layers with GELU activations to produce selection logits. Softmax converts logits to selection probabilities, and candidates with probability > threshold τ are selected for fusion. A dynamic weighted fusion strategy weights selected candidates' probability distributions by their normalized selection scores, with a feedback-driven loss term (based on the coefficient of variation of selection weights) preventing the selector from converging on a single subset of sources. The method requires token alignment using MinED to map source probability distributions to the target vocabulary before training.

## Key Results
- Reduces knowledge interference by up to 50% compared to existing methods
- Achieves consistent accuracy improvements across Commonsense, Big-Bench Hard, and MMLU benchmarks
- Demonstrates superior training efficiency requiring fewer training steps and tokens
- Shows robust performance across different numbers of source models (3-5 candidates)

## Why This Works (Mechanism)

### Mechanism 1: Adaptive Selection Network Reduces Knowledge Interference
- **Claim:** A learned selector that evaluates source LLMs per-input reduces interference compared to blind fusion of all candidates.
- **Core assumption:** Source LLMs have heterogeneous strengths, and per-sample selection captures task-relevant knowledge better than fixed weighting.
- **Evidence anchors:** [abstract] adaptive selection network that identifies the most relevant source LLMs based on their scores, thereby reducing knowledge interference; [Section 4.1] Equations 4-6 define the network architecture and dynamic thresholding mechanism.
- **Break condition:** If all source LLMs have near-identical probability distributions for most inputs, the selector cannot differentiate utility, and ASN degrades to random selection.

### Mechanism 2: Dynamic Weighted Fusion Prioritizes Stronger Contributors
- **Claim:** Weighting fused probability distributions by normalized selection scores improves knowledge transfer over unweighted averaging.
- **Core assumption:** The ASN's scores correlate with actual knowledge quality for the given input.
- **Evidence anchors:** [abstract] dynamic weighted fusion strategy that accounts for the inherent strengths of candidate LLMs; [Section 4.2] Equations 7-8 define normalization and weighted fusion; Table 1 shows weighted fusion outperforms average/max pooling.
- **Break condition:** If selection scores do not correlate with downstream task performance (e.g., confident but wrong models score high), weighted fusion amplifies errors.

### Mechanism 3: Feedback Loss Prevents Selector Collapse
- **Claim:** A loss term based on the coefficient of variation of selection weights prevents the selector from over-relying on a small subset of sources.
- **Core assumption:** Maintaining diverse source utilization improves generalization and avoids catastrophic forgetting of weaker but useful models.
- **Evidence anchors:** [abstract] feedback-driven loss function that prevents the selector from converging on a single subset of sources; [Section 4.3] Equation 9 defines CV²-based loss; Table 1 shows "Feed. loss" improves perplexity and BBH vs. "w/o Loss".
- **Break condition:** If λfeed is too high, the selector is forced toward uniform selection regardless of actual quality differences, degrading performance to simple averaging.

## Foundational Learning

- **Concept: Knowledge Distillation via Distribution Matching**
  - **Why needed here:** The fusion objective Lfuse uses cross-entropy between the target model's predictions and the fused probability distribution, analogous to distillation where a student learns from softened teacher outputs.
  - **Quick check question:** Can you explain why minimizing KL-divergence between probability distributions transfers knowledge more effectively than matching hard labels?

- **Concept: Softmax Routing / Mixture-of-Experts Gating**
  - **Why needed here:** The ASN's selection mechanism is structurally similar to MoE gating networks, where inputs are routed to subsets of experts based on learned scores.
  - **Quick check question:** What is the difference between Top-K expert selection and the threshold-based selection used here (Equation 5)?

- **Concept: Token Alignment Across Heterogeneous Vocabularies**
  - **Why needed here:** Source LLMs have different tokenizers; aligning probability distributions across vocabularies is a prerequisite for meaningful fusion.
  - **Quick check question:** Why does MinED (minimal edit distance) alignment outperform exact match for vocabulary mapping?

## Architecture Onboarding

- **Component map:** Source LLMs → Probability distribution matrices → Token alignment module → Aligned matrices → Adaptive Selection Network → Selection logits → Softmax → Probabilities → Dynamic thresholding → Selected candidates → Weight normalizer → Fused representation Pf → Target LLM training

- **Critical path:** Token alignment (preprocessing) must complete before training begins; ASN forward pass produces selection logits; gradient flows through Lfuse and Lfeed; target LLM parameters θ_T and ASN parameters ϕ_ASN are updated jointly.

- **Design tradeoffs:** Threshold τ: Lower values select more candidates (more knowledge but more interference); τ=0.15 was optimal in ablation; λfeed: Higher values enforce more uniform selection; λfeed=0.5 balanced diversity vs. quality; Selection metric: Softmax outperformed Gumbel softmax and noise injection (Table 1), suggesting smooth differentiable routing is preferred over stochastic exploration.

- **Failure signatures:** High perplexity with low task accuracy → Likely token alignment issues or collapsed selection; Few candidates consistently selected (check selection distribution in Fig. 6) → λfeed may be too low; Performance degradation on specific tasks → Source models may have conflicting knowledge; check per-task interference in BBH results.

- **First 3 experiments:** 1) Replicate Fusion-X-T (4 small models) on Commonsense benchmark; verify ~1.9% average improvement over target model; 2) Ablate Lfeed (set λfeed=0) and measure selection distribution collapse over 120K steps; 3) Vary τ (0.12, 0.15, 0.20) on BBH subset to confirm robustness of threshold choice.

## Open Questions the Paper Calls Out
- How can the framework be modified to eliminate the dependency on explicit token alignment prior to training?
- Does the framework maintain interference reduction capabilities when trained on domain-specific or highly diverse datasets?
- Is the performance of Fusion-X dependent on initializing the target model as the strongest candidate?

## Limitations
- **Computational Scalability:** Requires storing full probability distributions for all source models simultaneously in VRAM, making it inaccessible for smaller research labs
- **Vocabulary Alignment Bottleneck:** MinED-based token alignment is computationally expensive and implementation details for batching are not provided
- **Generalization Beyond Single-Modality:** Method is evaluated only on text-based LLMs with no evidence for multi-modal models or non-language knowledge sources

## Confidence
- **High Confidence:** The adaptive selection network reduces knowledge interference by up to 50% (supported by direct experimental comparisons with baselines and ablation studies)
- **Medium Confidence:** The method achieves consistent accuracy improvements across multiple benchmarks (supported by results on three datasets, though magnitude varies)
- **Low Confidence:** Superior training efficiency requiring fewer training steps and tokens (paper mentions this claim but provides limited quantitative comparison)

## Next Checks
1. **Selector Collapse Monitoring:** During reproduction, log the distribution of selection weights over training steps. Verify that without Lfeed (λfeed=0), the selector converges to selecting only 1-2 candidates consistently, while with Lfeed active, the selection remains distributed across 2-4 candidates.

2. **Threshold Robustness Testing:** Implement the full pipeline and systematically vary τ from 0.05 to 0.25 on a subset of BBH. Plot task accuracy against average number of selected candidates to verify the non-monotonic relationship claimed in the ablation.

3. **Memory Usage Profiling:** Measure peak VRAM usage during training with different candidate counts (2, 4, 8 models) on hardware with 40GB VRAM. Verify that memory scales linearly with candidate count as predicted by the probability distribution storage requirement.