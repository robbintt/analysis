---
ver: rpa2
title: A Reproducibility Study of Graph-Based Legal Case Retrieval
arxiv_id: '2504.08400'
source_url: https://arxiv.org/abs/2504.08400
tags:
- case
- legal
- caselink
- retrieval
- coliee
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper conducts a reproducibility study of CaseLink, a graph-based
  method for legal case retrieval that models cases and charges as nodes in a network.
  The study aims to assess reliability and generalizability by reproducing original
  experiments on COLIEE 2022 and 2023 datasets, testing on COLIEE 2024, comparing
  homogeneous vs heterogeneous graphs, and replacing GPT-3.5 with Llama-3.1.
---

# A Reproducibility Study of Graph-Based Legal Case Retrieval

## Quick Facts
- arXiv ID: 2504.08400
- Source URL: https://arxiv.org/abs/2504.08400
- Authors: Gregor Donabauer; Udo Kruschwitz
- Reference count: 35
- Primary result: Reproducibility study shows CaseLink's performance lower than originally reported, with significant challenges due to model availability

## Executive Summary
This paper presents a comprehensive reproducibility study of CaseLink, a graph-based method for legal case retrieval that models cases and charges as nodes in a network. The study systematically reproduces original experiments on COLIEE 2022 and 2023 datasets, tests on COLIEE 2024, compares homogeneous vs heterogeneous graphs, and replaces GPT-3.5 with Llama-3.1. Results reveal that CaseLink's performance is lower than originally reported, with heterogeneous graphs failing to improve performance. The study highlights critical reproducibility challenges in IR research, particularly model availability issues, while demonstrating that Llama-3.1 performs comparably or better than GPT-3.5 across datasets.

## Method Summary
The study reproduces CaseLink's graph-based legal case retrieval method by reconstructing the original experimental setup using COLIEE 2022 and 2023 datasets. The researchers systematically compare homogeneous and heterogeneous graph representations, where homogeneous graphs treat all nodes uniformly while heterogeneous graphs distinguish between case and charge nodes. Due to unavailability of GPT-3.5, they substitute Llama-3.1 as an open alternative. The experiments measure retrieval performance using standard IR metrics across multiple test sets, including the COLIEE 2024 dataset for generalization testing.

## Key Results
- CaseLink's performance is lower than originally reported, highlighting reproducibility challenges in IR research
- Heterogeneous graphs do not improve performance compared to homogeneous graphs
- Llama-3.1 performs comparably or better than GPT-3.5 across all tested datasets

## Why This Works (Mechanism)
CaseLink works by constructing a graph representation of legal cases where nodes represent cases or charges, and edges capture relationships between them. The method leverages graph neural networks to propagate information across the network, enabling retrieval based on semantic similarity in the graph space. The reproduction study reveals that while the core mechanism remains sound, performance variations stem from implementation details, model selection, and dataset characteristics rather than fundamental flaws in the approach.

## Foundational Learning
- Graph Neural Networks (GNNs) - needed to understand how information propagates through the legal case network; quick check: can you explain message passing in GNNs?
- Heterogeneous Graph Representations - needed to understand the distinction between homogeneous and heterogeneous approaches; quick check: can you identify when to use each type?
- Legal Case Retrieval Metrics - needed to evaluate performance in legal IR contexts; quick check: can you calculate MAP and NDCG?
- Model Availability and Reproducibility - needed to understand research challenges; quick check: can you list three reproducibility issues in IR research?

## Architecture Onboarding

Component Map: Legal Case Documents -> Graph Construction -> Node Embedding -> Retrieval Model -> Performance Evaluation

Critical Path: Document preprocessing → Graph construction → Node embedding → Similarity computation → Ranking

Design Tradeoffs: Homogeneous vs heterogeneous graphs (simplicity vs expressiveness), closed vs open models (performance vs accessibility)

Failure Signatures: Model unavailability, inconsistent preprocessing, graph construction errors, embedding misalignment

First Experiments:
1. Test CaseLink on COLIEE 2022 dataset with homogeneous graph representation
2. Compare performance using GPT-3.5 vs Llama-3.1 on identical tasks
3. Evaluate heterogeneous graph performance against homogeneous baseline

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Limited to COLIEE datasets, which may not represent real-world legal case complexity
- Model availability constraints forced substitution of GPT-3.5 with Llama-3.1, introducing uncontrolled variables
- Focus on graph-based methods may overlook other effective legal retrieval approaches

## Confidence
- Performance Claims: Medium - lower than original but constrained by model availability
- Generalizability Claims: Medium - limited to specific legal IR datasets
- Methodology Claims: High - systematic reproduction approach well-documented

## Next Checks
1. Test CaseLink on additional legal case retrieval datasets from different jurisdictions to assess generalizability
2. Conduct ablation studies to isolate the impact of graph heterogeneity on performance
3. Compare CaseLink's performance with other open-source legal retrieval models under identical conditions