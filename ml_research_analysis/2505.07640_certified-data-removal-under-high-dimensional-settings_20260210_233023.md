---
ver: rpa2
title: Certified Data Removal Under High-dimensional Settings
arxiv_id: '2505.07640'
source_url: https://arxiv.org/abs/2505.07640
tags:
- data
- lemma
- newton
- high-dimensional
- removal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper establishes that in high-dimensional settings, machine
  unlearning algorithms based on a single Newton step are insufficient, even when
  removing a single data point. It proposes a two-step Newton method with Laplacian
  noise addition that is provably effective.
---

# Certified Data Removal Under High-dimensional Settings

## Quick Facts
- **arXiv ID:** 2505.07640
- **Source URL:** https://arxiv.org/abs/2505.07640
- **Reference count:** 40
- **Primary result:** Two-step Newton method with Laplacian noise achieves (ϕ, ε)-probabilistically certified data removal in high dimensions, while single-step methods fail.

## Executive Summary
This paper addresses the challenge of certified data removal (machine unlearning) in high-dimensional settings where the number of parameters p scales proportionally with the number of data points n. The authors demonstrate that standard single-step Newton methods are insufficient for certification in this regime, even when removing just one data point. They propose a two-step Newton method with Laplacian noise injection that achieves probabilistic certification while preserving model utility. The theoretical analysis shows that the ℓ₂ error of the two-step estimator scales as O((m³/n)²), enabling effective unlearning with noise levels that preserve model accuracy. Numerical experiments validate these theoretical findings, showing that two steps provide the desired trade-off between certifiability and utility.

## Method Summary
The method targets Regularized Empirical Risk Minimization (R-ERM) models in high-dimensional settings. It starts with a trained model and performs T Newton steps on the remaining data D∖M to approximate the exact model that would be obtained by retraining from scratch without the data to forget. For T=2, the algorithm calculates a noise scale r based on the expected error between the approximate and exact models, then adds isotropic Laplacian noise to achieve probabilistic certification. The noise injection follows the density p(b) ∝ e^(-(ε/r)||b||), which provides (ϕ, ε)-certifiability when the ℓ₂ error is bounded by r. The approach is specifically designed for proportional high-dimensional asymptotics where n, p → ∞ with fixed ratio n/p → γ₀.

## Key Results
- Single Newton step is insufficient for certified unlearning in high dimensions due to slow error decay (O(1/√n)) requiring excessive noise
- Two Newton steps achieve quadratic error convergence (O((m³/n)²)), enabling effective certification with minimal noise
- The method achieves (ϕ, ε)-probabilistically certified approximate data removal with ϕ → 0 as n grows
- Theoretical bounds show m = o(n^(1/3)) is sufficient for maintaining model accuracy during certification
- Numerical experiments validate the theoretical scaling laws and demonstrate the trade-off between certification and utility

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** A single Newton step is insufficient for certified unlearning in high-dimensional settings (n, p → ∞ with fixed ratio), even when removing just one data point.
- **Mechanism:** In high dimensions, the strong convexity parameter of the objective function scales as ν = O(1/n). Consequently, the error of a one-step Newton update decays too slowly (∼1/√n). To "certify" removal (mask the residual info), the required noise would need to be so large that it destroys the model's utility (accuracy).
- **Core assumption:** Proportional High-dimensional Asymptotic Setting (PHAS) where n/p → γ₀; The model parameters are finite but n, p grow.
- **Evidence anchors:**
  - [Abstract]: "...unlike in low-dimensional settings, a single Newton step is insufficient for effective unlearning... however, two steps are enough."
  - [Section 4.2]: Detailed comparison showing Sekhari et al. (2021) bounds diverge because ν = O(1/n).
  - [Corpus]: The neighbor paper "Gaussian Certified Unlearning in High Dimensions" similarly highlights theoretical challenges where standard assumptions fail in high dimensions.
- **Break condition:** If the system were truly low-dimensional (p fixed, n → ∞), the standard single-step approach might hold, or if the loss landscape is trivially quadratic.

### Mechanism 2
- **Claim:** A second Newton step enables certification by reducing the ℓ₂ error quadratically, making the necessary noise minimal enough to preserve accuracy.
- **Mechanism:** The Newton method exhibits quadratic convergence near the optimum. By taking a second step (T=2), the error scales as O((m³/n)²) rather than O(m³/n). This order of magnitude reduction allows the algorithm to add "small enough" Laplacian noise to satisfy the privacy criterion without drowning out the model's signal.
- **Core assumption:** The Hessian of the loss is Lipschitz; the number of removals m = o(n^(1/3)).
- **Evidence anchors:**
  - [Abstract]: "...two steps are enough to achieve the desired certifiability."
  - [Section 3.2]: Theorem 3.2 explicitly states if T > 1 + log₂(…), GED converges to 0.
  - [Section A.2.6]: Proof of Lemma A.5 showing quadratic convergence r_{t,n} ≤ (C/2ν) r_{t-1,n}².
- **Break condition:** If the number of points to remove m grows too quickly relative to n (specifically violating m=o(n^(1/3))), the error bounds loosen, potentially requiring more steps or failing certification.

### Mechanism 3
- **Claim:** Isotropic Laplacian noise provides (ϕ, ε)-probabilistic certification by obscuring the difference between the approximate and exactly retrained models.
- **Mechanism:** The algorithm adds noise vector b with density ∝ e^(-(ε/r)||b||). Because the log-density of Laplacian noise is Lipschitz, if the ℓ₂ distance between the approximate and exact models is bounded by r, the ratio of the output densities remains within factor e^ε. This makes the "unlearned" model statistically indistinguishable from a "retrained" model.
- **Core assumption:** The "failure event" probability ϕ (where the error bound r might not hold) is acceptably small.
- **Evidence anchors:**
  - [Section 2.3]: Definition of Perturbed Newton estimator and choice of Laplacian distribution.
  - [Section 3.3.1]: Lemma 3.3 establishes the necessary and sufficient condition for the density ratio bound.
- **Break condition:** If the noise scale r is underestimated (e.g., due to outliers in data), the certification guarantee (ε-indistinguishability) fails.

## Foundational Learning

- **Concept: Proportional High-dimensional Asymptotic Setting (PHAS)**
  - **Why needed here:** Standard theory assumes p ≪ n. In PHAS (n, p → ∞), constants like the strong convexity parameter ν scale with n, breaking low-dimensional proofs.
  - **Quick check question:** Why does a strong convexity constant of O(1/n) break the single-step Newton guarantees from prior work?

- **Concept: Quadratic Convergence (Newton Method)**
  - **Why needed here:** The paper relies on the "squared" reduction of error in the second step to balance the noise-accuracy trade-off. Understanding this geometric shrinking is key to seeing why T=2 is the magic number.
  - **Quick check question:** How does the error ||β̃ - β̂||₂ scale differently after 1 step vs. 2 steps in this regime?

- **Concept: (ϕ, ε)-Certifiability**
  - **Why needed here:** This is the specific relaxation of Differential Privacy used here. It allows for a small failure probability ϕ, acknowledging that in high dimensions, worst-case bounds are often infinite.
  - **Quick check question:** What does the ϕ parameter represent in the certification definition?

## Architecture Onboarding

- **Component map:** Identify M → Compute Hessian on D∖M → Execute 2nd Newton Step → Calculate scale r → Add Laplacian Noise
- **Critical path:** Identify M → Compute Hessian on D∖M → **Execute 2nd Newton Step** → Calculate scale r → Add Laplacian Noise
- **Design tradeoffs:**
  - **Steps vs. Cost:** The paper mandates T=2 steps. While 1 step is computationally cheaper, the paper proves it is effectively useless for certification in high dimensions because the required noise would destroy accuracy.
  - **Noise vs. Utility:** The noise scale r is strictly tied to the error bound. Tighter bounds (via T=2) allow smaller noise, preserving Generalization Error Divergence (GED).
- **Failure signatures:**
  - **High GED:** If the noise scale is miscalculated or m is too large, the model loses predictive power.
  - **Certification Break:** If the "failure event" (outliers in data) occurs (probability ϕ), the theoretical ε-guarantee does not hold.
- **First 3 experiments:**
  1. **Scaling Validation:** Replicate Figure 2. Plot ℓ₂ error of 1-step vs. 2-step approximations against p to verify the O(p^(-0.5)) vs O(p^(-1.5)) scaling.
  2. **Certification Stress Test:** Fix n, p and vary removal size m. Find the point where the required noise for 2-step certification destroys model accuracy (checking the m = o(n^(1/3)) limit).
  3. **Loss Comparison:** Replicate Figure 4 (Left vs Right). Compare the loss distribution of the "noisy 1-step" vs "noisy 2-step" model against the exact retrained model to visualize the "corruption" vs "preservation" trade-off.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Is the derived upper bound for the ℓ₂ error of the multi-step Newton estimator in Theorem 3.5 sharp, or can it be tightened to match the empirically observed scaling?
- **Basis in paper:** [explicit] The authors state in Section 3.3.2: "Whether our result in Theorem 3.5 is sharp remains an interesting research problem for future research." They note that Theorem 3.4 suggests m^(3/2) scaling, while Figure 3 suggests m scaling.
- **Why unresolved:** The theoretical analysis provides a specific rate, but empirical simulations (Figure 3) display a different scaling behavior, indicating a potential gap between the proven upper bound and the actual convergence rate.
- **What evidence would resolve it:** A rigorous proof establishing a tighter lower bound or an improved upper bound that matches the empirical O(m) scaling observed in numerical experiments.

### Open Question 2
- **Question:** Can the theoretical guarantees for certified data removal be extended to a broader class of feature distributions beyond Gaussianity?
- **Basis in paper:** [explicit] The authors state in Section 3.1 regarding Assumption B1: "Although our proofs can be generalized to a broader class of distributions of x_i beyond Gaussianity, we do not discuss it in details in this paper."
- **Why unresolved:** The current proofs rely on specific properties of Gaussian distributions for concentration inequalities (e.g., operator norm bounds) and may not immediately hold for heavy-tailed or general sub-Gaussian distributions.
- **What evidence would resolve it:** A generalization of Lemma A.3 and Theorem 3.1 that holds for non-Gaussian feature matrices, potentially requiring modified concentration assumptions or analysis techniques.

### Open Question 3
- **Question:** How do machine unlearning algorithms based on Newton steps perform in high-dimensional settings with non-differentiable regularizers or non-convex loss functions?
- **Basis in paper:** [explicit] The authors note in Section 3.1 that in cases where "certain structures such as sparsity of β is assumed, these assumptions [A1-A3] can be violated... The theoretical study of such cases will not be the focus of this work, and are left for a future research."
- **Why unresolved:** The theoretical framework relies on twice differentiability (A2) and strong convexity (A3) of the loss and regularizer to define the Newton update and guarantee convergence, which breaks down for ℓ₁ regularization or neural networks.
- **What evidence would resolve it:** The derivation of convergence bounds and certification metrics for proximal Newton methods or other second-order methods adapted for non-smooth optimization landscapes.

## Limitations

- The theoretical guarantees rely on proportional high-dimensional asymptotic assumptions (n, p → ∞ with fixed ratio) that may not translate perfectly to finite sample regimes
- The method requires Hessian inversion which can be numerically unstable in very high dimensions
- The (ϕ, ε)-certification relaxation introduces a failure probability that must be carefully calibrated
- The specific regularization parameter λ used in experiments is not explicitly defined, creating uncertainty about the operational regime

## Confidence

- **High Confidence:** The theoretical framework for why single-step Newton methods fail in high-dimensional settings (Mechanism 1) and why two steps enable certification (Mechanism 2) is well-supported by the asymptotic analysis
- **Medium Confidence:** The specific noise injection mechanism using isotropic Laplacian noise (Mechanism 3) and the resulting (ϕ, ε)-certifiability bounds are mathematically sound but their practical robustness requires further validation
- **Medium Confidence:** The numerical experiments support the theoretical claims, but the synthetic data setup and exact implementation details are not fully specified

## Next Checks

1. **Finite-Sample Scaling Validation:** Replicate the core experiment (Figure 2) for a range of finite n and p values (e.g., n=500, p=250; n=2000, p=1000) to empirically verify the theoretical scaling laws (O(p^(-0.5)) vs. O(p^(-1.5))) hold outside the asymptotic regime

2. **Stress Test the Certification Bound:** Systematically vary the number of points to remove (m) for fixed n and p. Identify the critical value of m where the required noise scale for 2-step certification (r₂,n) causes the Generalization Error Divergence (GED) to exceed an acceptable threshold (e.g., 0.1). This will empirically validate the theoretical constraint m = o(n^(1/3))

3. **Robustness to Data Distribution:** Extend the experiments beyond the synthetic Gaussian data. Test the algorithm on real-world high-dimensional datasets (e.g., genomics or text classification) to assess the robustness of the (ϕ, ε)-certification when the data deviates from the idealized model assumptions