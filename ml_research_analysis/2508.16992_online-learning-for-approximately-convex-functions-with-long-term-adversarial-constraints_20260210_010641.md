---
ver: rpa2
title: Online Learning for Approximately-Convex Functions with Long-term Adversarial
  Constraints
arxiv_id: '2508.16992'
source_url: https://arxiv.org/abs/2508.16992
tags:
- online
- regret
- convex
- where
- function
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper studies online learning with long-term adversarial\
  \ budget constraints where both the cost and consumption functions are \u03B1-approximately\
  \ convex. The authors propose an efficient first-order online algorithm that achieves\
  \ O(\u221AT) \u03B1-regret against the optimal fixed feasible benchmark while consuming\
  \ at most O(BT log T) + \xD5(\u221AT) resources in both full-information and bandit\
  \ feedback settings."
---

# Online Learning for Approximately-Convex Functions with Long-term Adversarial Constraints

## Quick Facts
- **arXiv ID**: 2508.16992
- **Source URL**: https://arxiv.org/abs/2508.16992
- **Reference count**: 40
- **Primary result**: O(√T) α-regret with O(BT log T) + Õ(√T) resource consumption for online learning with adversarial budget constraints

## Executive Summary
This paper addresses online learning with long-term adversarial budget constraints where both cost and consumption functions are α-approximately convex. The authors propose an efficient first-order algorithm that achieves O(√T) α-regret against the optimal fixed feasible benchmark while maintaining resource consumption within O(BT log T) + Õ(√T). The framework handles both full-information and bandit feedback settings and provides matching lower bounds showing the guarantees are tight. The work extends online learning theory to a broader class of non-convex functions and demonstrates applicability to problems like DR-submodular maximization, online vertex cover, and regularized phase retrieval.

## Method Summary
The algorithm reduces the constrained problem to standard Online Linear Optimization by constructing a surrogate cost function that combines the original cost with a penalty term derived from an exponential Lyapunov function. The method uses AdaGrad adaptive step sizes and operates through a gradient-based update rule with Euclidean projection onto the decision set. The key innovation is the use of α-approximately convex functions, which generalize convex functions and allow for broader applicability. The algorithm maintains a budget deficit that triggers penalty terms, ensuring long-term feasibility while achieving sublinear regret.

## Key Results
- Achieves O(√T) α-regret against optimal fixed feasible benchmark
- Maintains cumulative resource consumption at O(BT log T) + Õ(√T)
- Provides matching lower bounds showing these guarantees are tight
- Extends to both full-information and bandit feedback settings

## Why This Works (Mechanism)
The algorithm works by linearizing the approximately-convex functions through generalized subgradients and using a Lyapunov-based approach to enforce budget constraints. The exponential Lyapunov function creates an adaptive penalty that scales with the budget deficit, ensuring long-term feasibility while the AdaGrad step sizes handle the varying curvature of approximately-convex functions. The reduction to Online Linear Optimization allows leveraging existing efficient algorithms while maintaining the theoretical guarantees for the original constrained problem.

## Foundational Learning

**Generalized Subgradients for α-approximately convex functions**: Needed to extend convexity-based analysis to broader function classes; quick check: verify H(x) satisfies f(x) ≤ αf(u) + ⟨H(x), x - u⟩ for test functions.

**Lyapunov drift analysis for budget constraints**: Needed to ensure long-term feasibility while achieving sublinear regret; quick check: confirm Q(t) remains bounded and λ scaling maintains constraint satisfaction.

**AdaGrad adaptation for varying function curvature**: Needed to handle the α-approximate convexity structure; quick check: validate ηt remains well-defined and bounded throughout execution.

## Architecture Onboarding

**Component Map**: Decision set X -> Generalized subgradient oracle H(x) -> Surrogate cost computation -> AdaGrad step size calculation -> OGD update -> Projection onto X

**Critical Path**: The algorithm follows a sequential path where each round depends on computing the generalized subgradient, updating the budget deficit, calculating adaptive step sizes, performing the OGD update, and projecting back to the feasible set.

**Design Tradeoffs**: The exponential Lyapunov function provides strong constraint enforcement but requires careful parameter tuning; the reduction to OLO enables efficient computation but adds complexity through the surrogate cost construction.

**Failure Signatures**: Gradient explosion from Φ'(Q(t)) growth indicates poor λ scaling; vacuous bounds suggest empty feasible set X*; poor regret performance may indicate incorrect subgradient computation.

**First Experiments**: 1) Validate subgradient computation for DR-submodular functions; 2) Test parameter sensitivity on synthetic approximately-convex functions; 3) Compare full-information vs bandit feedback performance on online vertex cover.

## Open Questions the Paper Calls Out

**Open Question 1**: Can the framework extend to general non-convex functions outside the α-approximately convex class? The current theory relies on generalized subgradients and linearizability, and it's unknown if sublinear regret is achievable for broader non-convex functions.

**Open Question 2**: Can the algorithm achieve optimal dynamic regret against time-varying comparators rather than fixed benchmarks? The current static regret analysis may not capture performance in changing environments where optimal actions evolve over time.

**Open Question 3**: Is the Ω(log T) competitive ratio lower bound tight for strictly convex or non-linear α-approximately convex functions? The current lower bound proof only covers linear instances, leaving open whether function curvature could enable better competitive ratios.

## Limitations
- Generalized subgradient computation method not specified for arbitrary α-approximately convex functions
- Requires advance knowledge of horizon T and budget BT for parameter tuning
- Theoretical guarantees depend on feasibility of the long-term constraint set

## Confidence

**Major Uncertainties**: Medium confidence in practical applicability due to subgradient computation uncertainty and parameter tuning requirements.

**Confidence Assessment**:
- High confidence in theoretical analysis and regret bounds
- Medium confidence in practical applicability due to subgradient computation uncertainty
- Medium confidence in parameter tuning recommendations

## Next Checks

1. Implement concrete subgradient computation methods for DR-submodular and online vertex cover instances to verify the generalized subgradient oracle works as specified.

2. Conduct empirical validation comparing Algorithm 1's performance against the theoretical O(√T) regret bound on synthetic approximately-convex functions.

3. Test algorithm robustness to parameter variations, particularly examining how sensitive performance is to the choice of λ and V parameters relative to BT and T.