---
ver: rpa2
title: 'Personality Matters: User Traits Predict LLM Preferences in Multi-Turn Collaborative
  Tasks'
arxiv_id: '2508.21628'
source_url: https://arxiv.org/abs/2508.21628
tags:
- personality
- participants
- task
- claude
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study investigated whether users with different personality
  traits systematically prefer certain LLMs during multi-turn collaborative tasks.
  Researchers conducted a controlled experiment with 32 participants evenly distributed
  across four Keirsey personality types, evaluating their interactions with GPT-4
  and Claude 3.5 across four collaborative tasks: data analysis, creative writing,
  information retrieval, and writing assistance.'
---

# Personality Matters: User Traits Predict LLM Preferences in Multi-Turn Collaborative Tasks

## Quick Facts
- arXiv ID: 2508.21628
- Source URL: https://arxiv.org/abs/2508.21628
- Reference count: 13
- Primary result: Personality traits predict LLM preferences in multi-turn collaborative tasks, with distinct patterns across Keirsey types

## Executive Summary
This study demonstrates that user personality traits systematically influence LLM preferences during collaborative tasks, revealing patterns invisible in traditional aggregate evaluations. Researchers conducted a controlled experiment with 32 participants across four Keirsey personality types, finding that Rationals strongly preferred GPT-4 for goal-oriented tasks while Idealists favored Claude 3.5 for creative and analytical work. Notably, aggregate helpfulness ratings were nearly identical (3.87 vs 3.85) despite significant personality-driven preferences, showing how standard evaluations mask important user-specific patterns.

## Method Summary
Researchers recruited 32 participants (8 per Keirsey type) and assigned them to interact with either GPT-4 or Claude 3.5 across four collaborative tasks: data analysis with synthetic student loan dataset, creative writing, email refinement, and archaeological information retrieval. The study used a between-subjects design with blind evaluation via custom web interface, randomized task order, and pre-study personality assessment. Participants rated each interaction's helpfulness on a 1-5 scale, with sentiment analysis applied to qualitative feedback. Analysis focused on Cohen's d effect sizes to measure preference strength within personality groups.

## Key Results
- Rationals showed large preference for GPT-4 (d = 1.31) on goal-oriented tasks
- Idealists strongly preferred Claude 3.5 (d = 1.44) for creative and analytical work
- Aggregate helpfulness ratings were nearly identical (3.87 vs 3.85) despite significant subgroup differences
- Task-dependent preferences emerged for Guardians and Artisans
- Sentiment analysis confirmed divergent feedback content patterns across personality types

## Why This Works (Mechanism)

### Mechanism 1: Personality-Model Affinity in Task Execution
- Claim: Users with different personality traits systematically prefer different LLMs based on alignment between their cognitive style and model response characteristics
- Mechanism: Rationals (analytical, strategic problem-solvers) prefer GPT-4's precision-focused outputs for goal-oriented tasks, while Idealists (imaginative, values-driven) prefer Claude 3.5's holistic, nuanced responses for creative work
- Core assumption: The observed preferences reflect stable model characteristics rather than random variation or brand perception (mitigated by blind experimental design)
- Evidence anchors: Rationals showed large effect size (d = 1.31) favoring GPT-4; Idealists showed large effect (d = 1.44) favoring Claude 3.5

### Mechanism 2: Evaluation Criteria Mediation
- Claim: Personality traits influence the criteria users apply when assessing LLM helpfulness, not just overall satisfaction
- Mechanism: Users don't evaluate helpfulness uniformly—Rationals weight task completion and precision heavily; Idealists weight understanding and holistic accuracy
- Core assumption: Helpfulness ratings reflect genuine evaluation criteria differences rather than response quality variation alone
- Evidence anchors: "Rationals evaluated based on task completion and precision, while Idealists focused on understanding and holistic accuracy"

### Mechanism 3: Aggregation Masking Effect
- Claim: Traditional aggregate helpfulness ratings conceal personality-dependent preferences that only emerge through stratified analysis
- Mechanism: When Rationals' GPT-4 preference and Idealists' Claude 3.5 preference are combined, they cancel out, producing equivalent aggregate scores (3.87 vs. 3.85)
- Core assumption: The observed cancellation is systematic, not random—opposing preferences balance rather than averaging noise
- Evidence anchors: Individual personality groups showed large effect sizes (d ≥ 0.8) despite aggregate equivalence

## Foundational Learning

- Concept: **Keirsey Temperament Sorter**
  - Why needed here: The study uses Keirsey's four-type categorization (Rationals, Idealists, Guardians, Artisans) to group participants. Understanding these categories—analytical vs. imaginative vs. organized vs. adaptable cognitive styles—is essential for interpreting why different users prefer different models
  - Quick check question: Can you name two characteristics that distinguish Rationals from Idealists, and predict which would prefer precise analytical outputs?

- Concept: **Cohen's d Effect Size**
  - Why needed here: The paper reports d = 1.31 and d = 1.44 as evidence of "large effects." Understanding that d ≥ 0.8 indicates substantial practical difference (not just statistical significance) is critical for evaluating whether personality-driven preferences matter in practice
  - Quick check question: If Cohen's d = 0.3 for a preference difference, would you consider this practically meaningful for product decisions?

- Concept: **Blinded Evaluation Design**
  - Why needed here: Participants used a "custom web application" that was "identical regardless of the underlying model," preventing brand bias. This design choice strengthens causal claims about model characteristics vs. brand perception
  - Quick check question: Why would unblinded evaluation (showing "GPT-4" or "Claude" labels) compromise conclusions about personality-driven preferences?

## Architecture Onboarding

- Component map: Keirsey assessment -> Model assignment (GPT-4/Claude 3.5) -> Task interaction (4 tasks) -> Evaluation interface -> Analysis pipeline
- Critical path: 1) Recruit and personality-type participants before model assignment 2) Ensure blind interaction (identical UI, no model identifiers) 3) Counterbalance task order (randomized presentation) 4) Stratify analysis by personality type before aggregation
- Design tradeoffs: Categorical vs. continuous personality (Keirsey provides discrete groups; Big Five would require much larger samples); Two models vs. broader comparison (adding models requires doubling sample size); Helpfulness vs. objective performance (subjective captures satisfaction but conflates multiple factors)
- Failure signatures: Aggregate equivalence with stratified divergence; Verbose prompt degradation (322-word prompts vs successful 122-word prompts); Task-type interaction (Guardians preferred GPT-4 for data analysis but Claude 3.5 for information retrieval)
- First 3 experiments: 1) Personality-stratified pilot (8-12 users on single task type) 2) Prompt-length intervention (test 122 vs 322 word observation) 3) Cross-validation with continuous personality measures (parallel Big Five study)

## Open Questions the Paper Calls Out

- Question: Do personality-driven LLM preferences generalize beyond university student populations to broader demographic groups (e.g., professionals, older adults, different cultural contexts)?
- Basis: The limitations section states: "they were primarily university students... expanding to a more demographically diverse sample would improve the generalizability of our findings to the broader population."
- Question: Can LLMs be dynamically adapted or personalized to individual user personality traits to improve collaborative outcomes and perceived helpfulness?
- Basis: The conclusion states: "explore how model adaptation to user personality might improve collaborative outcomes."
- Question: What specific model behaviors or response characteristics drive the divergent preferences between personality types (e.g., precision vs. elaborateness, directness vs. conversational tone)?
- Basis: The study shows Rationals and Idealists have opposing preferences but does not identify which model features cause these differences

## Limitations
- Small sample size (N=32) limits generalizability with only 8 participants per personality type
- Single dataset used across all participants constrains task variety and real-world complexity
- Limited task diversity (4 tasks) may not capture full spectrum of LLM use cases
- No objective task success metrics—helpfulness ratings are subjective and conflate multiple factors

## Confidence
- High confidence: Aggregate ratings masking systematic preferences (d=1.31 and d=1.44 within personality groups despite aggregate equivalence)
- Medium confidence: Personality-driven evaluation criteria differences (Rationals weight precision, Idealists weight understanding)
- Low confidence: Universal model recommendations across all tasks and personality types (task-specific preferences suggest no one-size-fits-all solution)

## Next Checks
1. Replicate with N=100+ participants using continuous Big Five personality assessment to verify categorical Keirsey findings generalize to dimensional personality measures
2. Add objective performance metrics (task completion rates, accuracy scores) alongside subjective helpfulness ratings to disentangle output quality from user satisfaction
3. Test across 4+ LLM models to determine whether observed patterns reflect stable model characteristics or specific GPT-4 vs Claude 3.5 differences