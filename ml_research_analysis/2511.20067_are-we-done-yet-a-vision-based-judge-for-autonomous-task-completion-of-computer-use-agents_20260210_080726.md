---
ver: rpa2
title: '"Are We Done Yet?": A Vision-Based Judge for Autonomous Task Completion of
  Computer Use Agents'
arxiv_id: '2511.20067'
source_url: https://arxiv.org/abs/2511.20067
tags:
- task
- cuas
- evaluation
- agents
- feedback
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of reliable task completion
  detection for Computer Use Agents (CUAs), which often fail to determine whether
  a task has been successfully completed. The proposed method leverages Vision-Language
  Models (VLMs) to autonomously evaluate task completion from screenshots and task
  descriptions.
---

# "Are We Done Yet?": A Vision-Based Judge for Autonomous Task Completion of Computer Use Agents

## Quick Facts
- **arXiv ID**: 2511.20067
- **Source URL**: https://arxiv.org/abs/2511.20067
- **Reference count**: 2
- **Primary result**: Vision-Language Models achieve up to 73% accuracy in autonomous task completion evaluation, improving CUA success rates by 27% through feedback loops.

## Executive Summary
This paper addresses the critical challenge of reliable task completion detection for Computer Use Agents (CUAs), which often struggle to determine whether a task has been successfully completed. The authors propose a vision-based evaluation framework that leverages Vision-Language Models (VLMs) to autonomously assess task completion from screenshots and task descriptions. Tested on 1,260 tasks across 42 built-in macOS applications, the system demonstrates that VLMs can serve as effective judges for CUA performance. The framework not only evaluates task success but also provides actionable feedback to CUAs, enabling them to retry and improve their performance when tasks are incomplete.

## Method Summary
The approach uses zero-shot Vision-Language Models to evaluate task completion autonomously. The pipeline consists of three main steps: (1) the CUA executes a task and records the final screenshot, (2) the VLM receives the screenshot and task description, then outputs a binary judgment (complete/incomplete) with a rationale, and (3) if the task is deemed incomplete, the rationale is fed back to the CUA to enable retry from the current state. The study tests five different VLMs (GPT-4o, Claude 3.5 Sonnet, LLaVA-v1.5-7B, InternVL 2-8B, and Qwen2-VL-7B) across three CUAs (Claude Computer Use, OpenAI Operator, and UI-TARS) on a standardized dataset of 1,260 tasks.

## Key Results
- VLMs achieve up to 73% accuracy in binary classification of task completion status
- CUA success rates improve by an average of 27% when incorporating VLM feedback
- Weaker CUAs demonstrate the most significant performance gains from the feedback mechanism
- Single-retry feedback shows substantial improvement, though the potential for multiple retries remains unexplored

## Why This Works (Mechanism)
The framework succeeds by bridging the gap between CUA execution and task completion verification through visual understanding. VLMs can interpret both the visual state captured in screenshots and the semantic meaning of task descriptions, enabling them to assess whether the desired outcome has been achieved. The feedback loop is particularly effective because it provides CUAs with specific, context-aware information about why a task failed, allowing them to make targeted corrections rather than starting over.

## Foundational Learning
- **Vision-Language Model Integration**: Understanding how VLMs process visual and textual information together is crucial for implementing effective task completion evaluation. *Quick check: Verify VLM can correctly interpret basic screenshots with simple task descriptions.*
- **Zero-shot Classification**: The ability to classify task completion without task-specific training is essential for generalizability. *Quick check: Test VLM performance across diverse application types.*
- **Feedback Loop Design**: Creating an effective mechanism for translating VLM rationales into actionable CUA corrections. *Quick check: Validate that CUA can properly interpret and act on VLM feedback.*
- **Screenshot Capture Timing**: Ensuring screenshots capture the final UI state after CUA execution completes. *Quick check: Add stability verification before screenshot capture.*
- **Cross-Agent Generalization**: The framework's ability to work across different CUA architectures and VLMs. *Quick check: Test with at least two different CUA-agent pairs.*

## Architecture Onboarding

**Component Map**: CUA Execution -> Screenshot Capture -> VLM Evaluation -> Binary Classification + Rationale -> Feedback to CUA (if incomplete)

**Critical Path**: The evaluation feedback loop is the core innovation. The VLM must accurately classify task completion and provide useful rationales that the CUA can act upon for retries to be effective.

**Design Tradeoffs**: The single-retry constraint limits the evaluation's practical applicability but simplifies the experimental design. Using built-in macOS applications provides controlled testing but may not generalize to real-world complexity.

**Failure Signatures**: 
- False positives occur when VLMs incorrectly judge incomplete tasks as complete
- False negatives happen when VLMs miss successful completion
- Feedback misinterpretation leads to failed retries
- Screenshot capture issues result in incorrect visual context

**Three First Experiments**:
1. Baseline evaluation: Run VLM classification on 10 tasks without feedback to establish accuracy baseline
2. Single-retry test: Implement one feedback-retry cycle on 5 tasks and measure improvement
3. VLM comparison: Test 2-3 different VLMs on the same 3 tasks to compare performance

## Open Questions the Paper Calls Out
None

## Limitations
- 73% accuracy ceiling suggests fundamental limitations in VLM-based evaluation for complex tasks
- Single-retry constraint may underestimate the potential of iterative feedback
- Limited to macOS built-in applications, raising questions about real-world generalizability
- Lack of detailed prompt templates and VLM parameters makes replication challenging

## Confidence

**Major Uncertainties and Limitations**
The evaluation framework demonstrates promising results but faces several critical limitations. The 73% accuracy ceiling for VLM-based classification suggests inherent challenges in vision-language task completion assessment, particularly for complex multi-step tasks. The reported improvement metrics may be inflated due to the artificial nature of the dataset (built-in macOS applications) and the single-retry constraint. The study does not address how the system would perform on real-world tasks involving web applications, custom software, or dynamic content. Additionally, the lack of detailed information about prompt templates and VLM inference parameters makes it difficult to assess the robustness of the approach across different implementations.

**Confidence Labels**
- **High confidence**: The core methodology of using VLMs for autonomous task completion evaluation is technically sound and well-validated through the controlled experiment.
- **Medium confidence**: The quantitative results (73% accuracy, 27% relative improvement) are likely reproducible on the same dataset but may not generalize to real-world scenarios without additional validation.
- **Low confidence**: The claim that "weaker agents benefit the most" lacks statistical rigor in the paper and requires more detailed analysis to verify.

## Next Checks
1. **Cross-platform validation**: Test the evaluation framework on Windows applications and web-based interfaces to assess generalizability beyond macOS built-in apps.
2. **Multi-retry performance analysis**: Systematically evaluate how task completion rates scale with multiple retries (2-5 attempts) rather than the single-retry constraint used in the study.
3. **Human-in-the-loop comparison**: Conduct a controlled experiment comparing VLM evaluator performance against human annotators on the same task set to establish true accuracy baselines and identify systematic failure modes.