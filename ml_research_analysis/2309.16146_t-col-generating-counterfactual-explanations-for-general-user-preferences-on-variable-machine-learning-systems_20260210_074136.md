---
ver: rpa2
title: 'T-COL: Generating Counterfactual Explanations for General User Preferences
  on Variable Machine Learning Systems'
arxiv_id: '2309.16146'
source_url: https://arxiv.org/abs/2309.16146
tags:
- user
- feature
- preferences
- counterfactual
- t-col
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generating counterfactual
  explanations (CEs) that adapt to general user preferences and remain robust under
  variable machine learning (ML) systems. The authors propose T-COL, a tree-based
  method that constructs local greedy trees to represent combinations of feature values
  from query samples and prototype cases.
---

# T-COL: Generating Counterfactual Explanations for General User Preferences on Variable Machine Learning Systems

## Quick Facts
- arXiv ID: 2309.16146
- Source URL: https://arxiv.org/abs/2309.16146
- Reference count: 40
- Primary result: Tree-based method T-COL generates counterfactual explanations that adapt to general user preferences and remain robust across variable ML systems

## Executive Summary
This paper introduces T-COL, a novel method for generating counterfactual explanations that can adapt to general user preferences while maintaining robustness across different machine learning systems. The approach uses a tree-based framework to construct local greedy trees representing combinations of feature values from query samples and prototype cases. T-COL incorporates five user preference dimensions (dedicated, minimalist, cautious, admirer, and collectivist) through optional conditions in the tree construction process. The method aims to balance multiple competing objectives in counterfactual explanation generation, including sparsity, proximity, validity, data manifold closeness, and diversity.

## Method Summary
T-COL employs a tree-based methodology that constructs local greedy trees to represent combinations of feature values from query samples and prototype cases. The method uses optional conditions to capture five general user preferences: dedicated (sparsity), minimalist (proximity), cautious (validity), admirer (data manifold closeness), and collectivist (diversity and data manifold closeness). By adjusting these optional conditions, T-COL can generate counterfactual explanations that are tailored to specific user preferences while maintaining robustness across variable ML systems. The tree structure allows for efficient exploration of the counterfactual space while balancing multiple objectives simultaneously.

## Key Results
- T-COL outperformed baselines in adapting to general user preferences with preference selection win rates ranging from 53.63% to 100%
- Demonstrated superior robustness on variable ML systems with data fidelity scores of 0.68-0.99 across datasets
- Successfully captured all five user preference dimensions through the tree-based framework

## Why This Works (Mechanism)
T-COL's tree-based approach works by systematically exploring the counterfactual space through local greedy tree construction. The method represents feature value combinations as paths in the tree, where each node corresponds to a specific feature modification. The optional conditions allow the algorithm to prioritize different objectives based on user preferences while maintaining the validity of counterfactuals. By incorporating both query samples and prototype cases, T-COL ensures that generated explanations are both realistic and meaningful. The tree structure enables efficient backtracking and exploration of alternative paths when initial modifications violate constraints or preferences.

## Foundational Learning
- **Counterfactual Explanations**: Why needed - to provide actionable insights for model decisions; Quick check - can the user understand what changes would alter the prediction?
- **User Preference Modeling**: Why needed - different users have different needs for explanations; Quick check - does the system allow customization of explanation characteristics?
- **Tree-based Search**: Why needed - efficient exploration of feature modification space; Quick check - does the method scale with feature dimensionality?
- **Data Manifold Closeness**: Why needed - explanations should remain realistic and plausible; Quick check - do generated counterfactuals fall within reasonable feature ranges?
- **Validity Constraints**: Why needed - counterfactuals must be feasible and actionable; Quick check - do modifications respect domain constraints and dependencies?

## Architecture Onboarding

**Component Map**: Query Sample -> Prototype Cases -> Tree Construction -> Optional Conditions -> Counterfactual Generation

**Critical Path**: The critical path involves matching the query sample with relevant prototype cases, constructing the local greedy tree based on feature similarities, applying optional conditions to incorporate user preferences, and generating valid counterfactual explanations that satisfy both preference constraints and data validity requirements.

**Design Tradeoffs**: T-COL balances sparsity versus completeness (dedicated vs. collectivist preferences), proximity versus diversity (minimalist vs. collectivist preferences), and validity versus data manifold closeness (cautious vs. admirer preferences). The tree structure allows for flexible adjustment of these tradeoffs through optional conditions while maintaining computational efficiency.

**Failure Signatures**: Potential failures include tree construction getting stuck in local optima, excessive computational complexity with high-dimensional features, violation of validity constraints despite optional conditions, and generation of counterfactuals that are too far from the data manifold to be actionable.

**First Experiments**:
1. Test T-COL on a simple binary classification problem with known feature importance to verify basic functionality
2. Evaluate the method's ability to capture individual user preferences by testing with synthetic preference specifications
3. Assess computational scalability by running on increasingly larger datasets with varying feature dimensions

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Evaluation relies on LLM-based agents rather than real human users, which may not accurately capture actual user preferences
- Preference selection win rates show variability (53.63% to 100%) suggesting sensitivity to experimental conditions
- Data fidelity scores, while strong (0.68-0.99), require broader validation across different ML system types

## Confidence
- High confidence: The tree-based methodology for constructing counterfactual explanations is technically sound and well-explained
- Medium confidence: The experimental results showing adaptation to user preferences are promising but depend on proxy evaluation methods
- Medium confidence: Claims about robustness across variable ML systems are supported by data fidelity scores but require broader testing

## Next Checks
1. Conduct human user studies to validate whether LLM-based preference assessments align with actual user preferences and decision-making
2. Test T-COL across a more diverse range of ML architectures beyond tree-based models, including deep neural networks and ensemble methods
3. Evaluate the method's performance with different dataset characteristics, particularly focusing on high-dimensional and imbalanced datasets to assess scalability and generalizability