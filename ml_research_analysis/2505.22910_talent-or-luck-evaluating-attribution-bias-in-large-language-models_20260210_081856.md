---
ver: rpa2
title: Talent or Luck? Evaluating Attribution Bias in Large Language Models
arxiv_id: '2505.22910'
source_url: https://arxiv.org/abs/2505.22910
tags:
- failure
- attribution
- success
- bias
- asian
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a cognitively grounded framework to evaluate
  social biases in large language models (LLMs) using Attribution Theory from social
  psychology. The framework probes how LLMs assign internal (effort, ability) versus
  external (difficulty, luck) causes to success and failure outcomes across social
  identities including gender, nationality, race, and religion in 10 societal scenarios.
---

# Talent or Luck? Evaluating Attribution Bias in Large Language Models

## Quick Facts
- **arXiv ID:** 2505.22910
- **Source URL:** https://arxiv.org/abs/2505.22910
- **Reference count:** 40
- **Primary result:** Marginalized groups receive less credit for success and more blame for failure compared to dominant groups in LLM attribution reasoning

## Executive Summary
This work introduces a cognitively grounded framework to evaluate social biases in large language models (LLMs) using Attribution Theory from social psychology. The framework probes how LLMs assign internal (effort, ability) versus external (difficulty, luck) causes to success and failure outcomes across social identities including gender, nationality, race, and religion in 10 societal scenarios. Experiments on three LLMs—AYA-EXPANSE-8B, QWEN-32B, and LLAMA-3.3-70B—reveal significant attribution asymmetries. Marginalized groups receive less credit for success and more blame for failure compared to dominant groups. Smaller models like AYA-EXPANSE-8B rely more on external attributions, while larger models like QWEN-32B and LLAMA-3.3-70B show stronger internal attribution biases. Attribution patterns also vary by domain, with education and workplace outcomes more often attributed to effort, while humanities domains show stronger reliance on luck. Observer identity and reasoning significantly influence attributions, especially for failure outcomes, highlighting the contextual and comparative nature of bias in model reasoning.

## Method Summary
The framework evaluates social biases in LLMs through Attribution Theory, examining how models assign internal versus external causes to success and failure across different social identities. The study uses three LLMs (AYA-EXPANSE-8B, QWEN-32B, LLAMA-3.3-70B) and tests them across 10 societal scenarios covering gender, nationality, race, and religion. The evaluation examines attribution patterns across different domains and analyzes how observer identity and reasoning influence attributions, particularly for failure outcomes.

## Key Results
- Marginalized groups receive less credit for success and more blame for failure compared to dominant groups
- Smaller models (AYA-EXPANSE-8B) rely more on external attributions, while larger models (QWEN-32B, LLAMA-3.3-70B) show stronger internal attribution biases
- Education and workplace outcomes are more often attributed to effort, while humanities domains show stronger reliance on luck

## Why This Works (Mechanism)
The framework leverages Attribution Theory from social psychology to create a systematic approach for evaluating how LLMs reason about success and failure. By explicitly prompting models to explain outcomes and categorizing responses into internal (effort, ability) versus external (difficulty, luck) causes, the framework captures the nuanced ways models attribute responsibility. The multi-scenario approach across different social identities reveals systematic biases that might be masked in single-dimension evaluations.

## Foundational Learning

### Attribution Theory
*Why needed:* Provides the theoretical foundation for understanding how humans and models assign causes to outcomes
*Quick check:* Can you distinguish between internal (effort, ability) and external (difficulty, luck) attribution categories?

### Social Identity Theory
*Why needed:* Explains how group membership influences attribution patterns and biases
*Quick check:* How do dominant vs. marginalized group identities affect attribution patterns?

### Cognitive Bias in AI Systems
*Why needed:* Contextualizes attribution biases within broader AI fairness and bias research
*Quick check:* What mechanisms in LLM training might contribute to social attribution biases?

## Architecture Onboarding

### Component Map
Input prompts -> LLM processing -> Attribution categorization -> Bias analysis -> Pattern identification

### Critical Path
Prompt design → Model response generation → Attribution classification → Statistical analysis → Bias quantification

### Design Tradeoffs
- Prompt-based evaluation vs. interactive assessment
- Broad scenario coverage vs. deep domain analysis
- Attribution categorization simplicity vs. nuanced classification

### Failure Signatures
- Inconsistent attribution patterns across similar scenarios
- Model responses that avoid causal attribution entirely
- Attribution patterns that don't align with established social psychology research

### First Experiments
1. Test attribution patterns for success vs. failure across multiple social identities
2. Compare attribution patterns between small and large model variants
3. Analyze domain-specific attribution differences (education vs. humanities)

## Open Questions the Paper Calls Out
None

## Limitations
- Findings based on only three models with varying architectures and training datasets
- Prompt-based evaluation may not capture attribution biases in naturalistic or interactive settings
- Societal scenarios, while diverse, may not fully represent all real-world contexts where attribution biases manifest

## Confidence

| Claim | Confidence |
|-------|------------|
| Marginalized groups receive less credit for success and more blame for failure | High |
| Smaller models rely more on external attributions while larger models show stronger internal attribution biases | Medium |
| Domain-specific attribution patterns (education/workplace favoring effort, humanities favoring luck) | Medium |

## Next Checks

1. Test the attribution framework across a broader range of LLM architectures and training datasets to assess generalizability
2. Conduct interactive or conversational evaluations to capture attribution biases in more naturalistic settings beyond prompt-based methods
3. Expand the societal scenarios to include additional domains and cultural contexts to verify the robustness of domain-specific attribution patterns