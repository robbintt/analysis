---
ver: rpa2
title: Rationalizing Transformer Predictions via End-To-End Differentiable Self-Training
arxiv_id: '2508.11393'
source_url: https://arxiv.org/abs/2508.11393
tags:
- rationales
- rationale
- training
- classification
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel approach to rationalized transformer
  prediction, addressing the challenge of generating interpretable explanations for
  transformer-based classifiers. The method, called the rationalized transformer predictor
  (RTP), simplifies the common three-player game framework by using a single model
  that simultaneously classifies inputs and scores token relevance.
---

# Rationalizing Transformer Predictions via End-To-End Differentiable Self-Training

## Quick Facts
- **arXiv ID:** 2508.11393
- **Source URL:** https://arxiv.org/abs/2508.11393
- **Reference count:** 23
- **Primary result:** Introduces RTP, a single-model framework that simultaneously classifies inputs and scores token relevance, achieving SOTA on eMR benchmarks

## Executive Summary
This paper addresses the challenge of generating interpretable explanations for transformer-based classifiers through a novel rationalized transformer predictor (RTP) framework. The RTP simplifies the traditional three-player game framework by using a single model that simultaneously classifies inputs and scores token relevance. The method introduces class-wise rationale generation, continuous input alteration for differentiable training, and parameterization to align with human annotations. The approach achieves state-of-the-art performance on two benchmark datasets while providing faithful explanations in a single forward pass.

## Method Summary
The RTP framework presents a unified approach to transformer rationalization by combining classification and rationalization into a single model. Unlike traditional methods that use separate components (generator, predictor, and classifier), RTP operates as an end-to-end differentiable system. The method employs class-wise rationale generation, where token relevance is determined based on specific class predictions, and uses continuous input alteration techniques to enable differentiable training. The framework is parameterized to align with human-annotated rationales, improving interpretability and faithfulness of the generated explanations.

## Key Results
- Achieves state-of-the-art performance on two eMR benchmark datasets
- Demonstrates superior alignment with human rationales compared to existing methods
- Provides faithful explanations in a single forward pass without post-hoc processing
- Shows effective class-wise rationale generation that improves interpretability

## Why This Works (Mechanism)
The RTP framework succeeds by unifying the classification and rationalization tasks within a single model, eliminating the need for separate components that must be trained jointly. The class-wise rationale generation allows the model to identify tokens most relevant to specific class predictions, rather than treating all rationales generically. The continuous input alteration technique enables end-to-end differentiable training, allowing the model to learn optimal token scoring while maintaining classification accuracy. The parameterization to human annotations ensures that generated rationales are interpretable and align with human understanding.

## Foundational Learning
**Differentiable Programming**
- *Why needed:* Enables end-to-end training of the unified RTP framework
- *Quick check:* Can implement basic continuous relaxation of discrete operations

**Self-Training in NLP**
- *Why needed:* Allows the model to improve its own rationales during training
- *Quick check:* Understands how pseudo-labels can be used for iterative improvement

**Token Scoring and Attribution**
- *Why needed:* Core mechanism for identifying relevant tokens in the input
- *Quick check:* Can implement basic gradient-based or attention-based attribution methods

## Architecture Onboarding

**Component Map:**
Input text -> RTP model -> Class prediction + Token scores -> Rationalized output

**Critical Path:**
Input text → Token embedding → RTP classification → Token scoring → Rationale generation → Final prediction

**Design Tradeoffs:**
- Single-model vs. multi-component approaches (simpler training vs. potentially more flexible)
- Class-wise vs. generic rationale generation (more targeted vs. broader applicability)
- Continuous relaxation vs. discrete operations (differentiable vs. exact)

**Failure Signatures:**
- Poor classification accuracy when rationalization is too aggressive
- Generic rationales when class-wise generation fails to distinguish between classes
- Training instability due to continuous relaxation approximations

**First Experiments:**
1. Implement basic RTP on a simple text classification dataset to verify end-to-end training
2. Compare class-wise vs. generic rationale generation on a binary classification task
3. Test continuous input alteration with different relaxation techniques to find optimal configuration

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Limited evaluation to only two eMR benchmark datasets, raising questions about generalizability
- Continuous relaxation techniques may introduce approximation errors in the rationalization process
- Class-wise rationale generation may struggle with ambiguous cases where token relevance spans multiple classes

## Confidence
- **High confidence:** The technical implementation of RTP as a unified framework is well-founded and clearly described
- **Medium confidence:** The claim of achieving state-of-the-art performance is supported by benchmark results, but the limited scope of evaluation datasets reduces certainty
- **Medium confidence:** The assertion that RTP provides "faithful explanations in a single forward pass" is technically sound, though the definition and measurement of faithfulness could be more rigorous

## Next Checks
1. Test RTP on additional diverse datasets beyond eMR benchmarks to assess domain generalization and robustness across different text classification tasks
2. Conduct ablation studies to quantify the impact of individual components (class-wise rationalization, continuous input alteration) on both performance and interpretability
3. Implement human evaluation studies with domain experts to validate the quality and utility of generated rationales beyond automated metrics