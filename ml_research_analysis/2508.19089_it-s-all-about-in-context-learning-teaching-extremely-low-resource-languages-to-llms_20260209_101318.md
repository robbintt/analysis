---
ver: rpa2
title: It's All About In-Context Learning! Teaching Extremely Low-Resource Languages
  to LLMs
arxiv_id: '2508.19089'
source_url: https://arxiv.org/abs/2508.19089
tags:
- languages
- language
- llms
- zero-shot
- alignment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study examines whether large language models (LLMs) can learn
  extremely low-resource languages using in-context learning (ICL), with or without
  alignment signals, and compares these methods to parameter-efficient fine-tuning
  (PEFT). Across 20 under-represented languages, including five with rare scripts,
  zero-shot ICL with word- or sentence-level alignment was highly effective for languages
  poorly supported by LLMs, often outperforming fine-tuning and few-shot ICL.
---

# It's All About In-Context Learning! Teaching Extremely Low-Resource Languages to LLMs

## Quick Facts
- arXiv ID: 2508.19089
- Source URL: https://arxiv.org/abs/2508.19089
- Authors: Yue Li; Zhixue Zhao; Carolina Scarton
- Reference count: 19
- Primary result: Zero-shot ICL with alignment outperforms PEFT for languages where both script and language are severely under-represented

## Executive Summary
This study systematically compares in-context learning (ICL) with parameter-efficient fine-tuning (PEFT) for adapting large language models to 20 extremely low-resource languages, including 5 with rare scripts. The key finding is that zero-shot ICL with language alignment is highly effective for languages poorly supported by LLMs, often outperforming both fine-tuning and few-shot ICL. In contrast, PEFT fails when both the language and its script are severely under-represented due to tokenizer collapse. The authors identify a capability threshold (baseline accuracy ~0.45) above which few-shot ICL becomes preferable to zero-shot alignment.

## Method Summary
The study evaluates three adaptation methods across 20 low-resource languages using topic classification (SIB-200) and reading comprehension (BELEBELE) tasks. Methods compared include zero-shot ICL with word- or sentence-level alignment, few-shot ICL with BM25 retrieval, and IA3 PEFT with batch size 4, max 10 epochs, and learning rates in {1e-3, 5e-3, 8e-3, 1e-2}. Language capability is assessed using Information Parity (IP) scores and Token-to-Byte Ratio (TBR). Dictionaries are built using NLLB-200-3.3B or fast_align for unsupported languages, with sentence alignment via BM25 retrieval.

## Key Results
- Zero-shot ICL with sentence-level alignment achieved average accuracy improvements exceeding 0.22 for languages with baseline accuracy below 0.3
- PEFT failed completely for languages with TBR ≈ 0.99 (byte-level tokenization), achieving only 0.27 accuracy for 'sat'
- Few-shot ICL outperformed zero-shot alignment for languages with baseline accuracy > 0.45 (khk, tgk, azb, eus, tat, kaz, urd)
- Word-level alignment degraded performance for LLaMA-3.2 with low-quality dictionaries (chrF++ < 0.5)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Zero-shot ICL with language alignment enables comprehension of extremely low-resource languages that PEFT cannot learn.
- **Mechanism:** Parallel text pairs in the prompt activate cross-lingual transfer pathways already present in the model from pre-training on higher-resource languages. The alignment provides explicit mappings that compensate for weak internal representations.
- **Core assumption:** LLMs possess latent cross-lingual capabilities from multilingual pre-training that can be triggered via prompting, even when target language representations are severely degraded.
- **Evidence anchors:**
  - [abstract] "Zero-shot ICL with language alignment is impressively effective on extremely low-resource languages"
  - [section 4.2.1] Languages with baseline accuracy below 0.3 showed average improvement exceeding 0.22 with sentence-level alignment
  - [corpus] Related work on "Code-Switching In-Context Learning" (arXiv:2510.05678) shows similar cross-lingual transfer activation through code-mixed prompts
- **Break condition:** Effectiveness diminishes when alignment quality is poor (e.g., dictionary chrF++ < 0.5 for word-level) or when randomly sampled examples lack semantic similarity to the input.

### Mechanism 2
- **Claim:** PEFT fails for languages where both the script and language are severely under-represented due to tokenizer collapse and rapid overfitting.
- **Mechanism:** When a script is absent from tokenizer training, byte-level BPE tokenization reduces vocabulary to ~256 raw byte tokens. This severely limits the model's capacity to learn generalizable linguistic patterns from small datasets, causing early overfitting during fine-tuning.
- **Core assumption:** The Token-to-Byte Ratio (TBR) serves as a proxy for tokenization quality, and values near 1.0 indicate the tokenizer operates at raw byte level with minimal linguistic abstraction.
- **Evidence anchors:**
  - [abstract] "Limitation of PEFT when both language and its script are extremely under-represented"
  - [section 4.1] For 'sat', average TBR = 0.99, indicating nearly every character segmented into raw bytes; PEFT accuracy remained at 0.27 (below majority voting baseline)
  - [corpus] Weak corpus evidence on this specific tokenizer-collapse mechanism for rare scripts
- **Break condition:** PEFT becomes viable when either the tokenizer has some script coverage (lower TBR) OR the model has pre-existing language capability (higher IP scores), even if the language itself is low-resource.

### Mechanism 3
- **Claim:** Few-shot ICL outperforms zero-shot ICL with alignment only when the model has sufficient baseline capability (accuracy > ~0.45).
- **Mechanism:** When LLMs have adequate internal representations (indicated by Information Parity and baseline performance), labeled demonstrations provide task-specific pattern recognition that outweighs the benefits of alignment alone. Below this threshold, alignment signals are more valuable than task labels the model cannot interpret.
- **Core assumption:** There exists a capability threshold (approximately 0.45 baseline accuracy) that determines whether the model can meaningfully utilize task labels versus alignment signals.
- **Evidence anchors:**
  - [section 4.4] "When baseline performance is higher than 0.45... few-shot ICL always provides best results" for languages including khk, tgk, azb, eus, tat, kaz, urd
  - [section 4.4] For baseline < 0.45, zero-shot with alignment outperforms few-shot in >50% of cases
  - [corpus] "Blessing of Multilinguality" (arXiv:2502.11364) analyzes similar threshold effects in multilingual ICL
- **Break condition:** This threshold may vary by task complexity; for reading comprehension (BELEBELE), the threshold shifted to ~0.5.

## Foundational Learning

- **Concept: In-Context Learning (ICL)**
  - Why needed here: Understanding that LLMs can learn from prompt examples without parameter updates is fundamental to grasping why alignment signals work for unseen languages.
  - Quick check question: Can you explain why adding parallel sentence pairs to a prompt might help an LLM classify text in a language it wasn't explicitly trained on?

- **Concept: Tokenization Efficiency (Token-to-Byte Ratio)**
  - Why needed here: Recognizing how tokenizers handle unseen scripts determines whether fine-tuning is viable or if ICL approaches must be used.
  - Quick check question: What does a TBR of 0.99 indicate about how a tokenizer processes a particular script?

- **Concept: Information Parity (IP)**
  - Why needed here: IP quantifies pre-existing language capability in LLMs, helping predict which adaptation method will succeed.
  - Quick check question: If an LLM has an IP score of 0.16 for language X and 0.36 for language Y, which language would you expect to benefit more from fine-tuning, and why?

## Architecture Onboarding

- **Component map:**
  Language assessment layer -> Method selection router -> Alignment retrieval -> Prompt constructor -> Evaluation

- **Critical path:**
  1. Assess target language capability (IP, TBR, baseline accuracy)
  2. Select adaptation method based on capability threshold
  3. If alignment needed, retrieve semantically similar parallel examples (not random)
  4. Construct prompt with appropriate alignment format
  5. Evaluate; if word-level alignment quality uncertain (chrF++ < 0.5), prefer sentence-level

- **Design tradeoffs:**
  - Human translation cost (for alignment) vs. human annotation cost (for fine-tuning)
  - Sentence-level alignment (more robust but longer prompts) vs. word-level (shorter but quality-dependent)
  - Zero-shot with alignment (no labeling needed) vs. few-shot (better for moderately supported languages)

- **Failure signatures:**
  - TBR > 0.95 AND IP < 0.20: PEFT will overfit rapidly; avoid fine-tuning
  - Random sampling for sentence alignment: performance degrades vs. BM25 retrieval
  - Word-level alignment with low-quality dictionary (chrF++ < 0.5): can harm performance
  - Prompt order sensitivity: some models (DeepSeek) perform better with demonstrations before task description

- **First 3 experiments:**
  1. **Capability assessment:** Compute IP and TBR for your target language using 50-100 sample sentences; establish baseline zero-shot accuracy on your task
  2. **Sentence-level alignment test:** Implement BM25 retrieval for parallel examples; compare 1-shot, 3-shot, and 5-shot alignment configurations against baseline
  3. **Method boundary validation:** Test the 0.45 threshold hypothesis on your specific task by comparing zero-shot alignment vs. few-shot ICL across languages with varying baseline capabilities

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does increasing LLM parameter scale beyond 7B consistently enhance the performance gains observed with zero-shot ICL and alignment for extremely low-resource languages?
- **Basis in paper:** [Explicit] The authors state in the Limitations section that computational constraints prevented experimenting with larger models (e.g., LLaMA-3.3 70B) and suggest "future work could explore whether a larger LLM could enable even more improvement."
- **Why unresolved:** The study was restricted to smaller models (2B–7B parameters); it is unclear if the superiority of ICL over PEFT for rare scripts persists or diminishes with increased model capacity.
- **What evidence would resolve it:** Evaluating the proposed alignment methods on models exceeding 70B parameters across the same set of extremely low-resource languages.

### Open Question 2
- **Question:** Do the benefits of zero-shot ICL with alignment over PEFT generalize to generative tasks and complex domains beyond classification and reading comprehension?
- **Basis in paper:** [Explicit] The authors note they only covered topic classification and reading comprehension due to data availability, explicitly suggesting findings could be tested on "other tasks (e.g., common-sense reasoning or summarization) and other domains (e.g., medical, social media)."
- **Why unresolved:** Current results rely on multiple-choice and classification tasks derived from the Flores-200 dataset; the efficacy of this method for open-ended generation remains unverified.
- **What evidence would resolve it:** Applying the alignment strategies to generative benchmarks or domain-specific datasets for the target languages and comparing results against PEFT.

### Open Question 3
- **Question:** How robust is zero-shot ICL with sentence-level alignment when the parallel examples provided in the prompt are out-of-domain relative to the task input?
- **Basis in paper:** [Explicit] The authors admit they "did not systematically analyse how the ICL performance would be impacted if the included unlabelled parallel text is out-of-domain," hypothesizing it might demonstrate limited benefit.
- **Why unresolved:** The study utilized in-domain data (training sets) for alignment examples; the sensitivity of this method to domain shifts is currently unknown.
- **What evidence would resolve it:** Experiments where alignment sentences are drawn from general corpora (e.g., Wikipedia) while testing on specific downstream tasks.

## Limitations

- Study limited to two specific tasks (topic classification and reading comprehension) across 20 languages, limiting broader applicability
- Effectiveness of zero-shot ICL with alignment may vary significantly across different task types and language families
- Quality of word-level alignment depends heavily on dictionary availability and quality, with poor alignment potentially harming performance
- Study does not fully explore the trade-off between prompt length (for sentence-level alignment) and performance gains

## Confidence

**High Confidence:**
- Zero-shot ICL with alignment is effective for languages with baseline accuracy below 0.3
- PEFT fails when both language and script are severely under-represented (TBR > 0.9)
- Few-shot ICL outperforms zero-shot when baseline capability exceeds 0.45

**Medium Confidence:**
- The 0.45 threshold for method selection is task-specific and may vary
- Sentence-level alignment is more robust than word-level for low-quality dictionaries
- Prompt order affects performance differently across model families

**Low Confidence:**
- Cross-lingual transfer mechanisms are explicitly characterized
- Dictionary quality thresholds (chrF++ < 0.5) definitively predict performance degradation
- The specific capability threshold values generalize across all low-resource scenarios

## Next Checks

1. **Cross-task validation**: Test whether the 0.45 baseline capability threshold generalizes to other task types beyond topic classification and reading comprehension, particularly for generation tasks where alignment might behave differently.

2. **Script coverage analysis**: Systematically map the relationship between tokenizer script coverage (TBR values) and PEFT performance across a broader range of rare scripts to establish more precise failure boundaries for fine-tuning.

3. **Alignment quality sensitivity**: Quantify the relationship between dictionary quality metrics (chrF++ scores) and alignment effectiveness for word-level alignment, determining precise thresholds where alignment transitions from helpful to harmful.