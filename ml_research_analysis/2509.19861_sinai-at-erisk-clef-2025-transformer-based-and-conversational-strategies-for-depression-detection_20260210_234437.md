---
ver: rpa2
title: 'SINAI at eRisk@CLEF 2025: Transformer-Based and Conversational Strategies
  for Depression Detection'
arxiv_id: '2509.19861'
source_url: https://arxiv.org/abs/2509.19861
tags:
- user
- task
- depression
- symptom
- conversational
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The SINAI-UJA team participated in two eRisk@CLEF 2025 tasks:
  contextual early detection of depression from conversational data, and conversational
  depression detection via LLMs. For Task 2, they developed a transformer-based system
  using models like RoBERTa and MentalRoBERTa, with extensive preprocessing to extract
  relevant conversation contexts.'
---

# SINAI at eRisk@CLEF 2025: Transformer-Based and Conversational Strategies for Depression Detection

## Quick Facts
- arXiv ID: 2509.19861
- Source URL: https://arxiv.org/abs/2509.19861
- Reference count: 26
- The SINAI-UJA team participated in two eRisk@CLEF 2025 tasks: contextual early detection of depression from conversational data, and conversational depression detection via LLMs.

## Executive Summary
The SINAI-UJA team participated in two eRisk@CLEF 2025 tasks: contextual early detection of depression from conversational data, and conversational depression detection via LLMs. For Task 2, they developed a transformer-based system using models like RoBERTa and MentalRoBERTa, with extensive preprocessing to extract relevant conversation contexts. Their system ranked 8th out of 12 teams on F1 score but was among the fastest in early prediction, highlighting a trade-off between speed and accuracy. For the pilot task, they used a two-LLM architecture: one for empathetic conversation and another for real-time symptom scoring. This approach achieved 1st place out of 5 teams, obtaining the best results across all evaluation metrics (DCHR, ADODL, ASHR), demonstrating the effectiveness of structured conversational design with LLMs for mental health assessment.

## Method Summary
For Task 2, the team implemented a transformer-based system using encoder models (RoBERTa, MentalRoBERTa) with structured input formatting that distinguishes target user messages from context messages via special tags. The preprocessing pipeline extracts relevant conversation branches from hierarchical Reddit data and formats them for sequential prediction. For the pilot task, they deployed a dual-LLM architecture where one LLM handles empathetic conversation while another evaluates symptom severity in real-time, using the Beck Depression Inventory-II framework to score 21 symptoms on a 0-3 scale.

## Key Results
- Task 2: Ranked 8th out of 12 teams on F1 score (0.24 precision, 1.00 recall) but achieved fastest early prediction speed (0.99-1.00)
- Task 2: Achieved perfect recall (1.00) but suffered from low precision (0.17-0.24), indicating high false positive rates
- Pilot Task: Achieved 1st place out of 5 teams with best results across all metrics: DCHR 0.66, ADODL 0.93, ASHR 0.29
- Pilot Task: Mean conversation length of 6.54 messages while maintaining high performance

## Why This Works (Mechanism)

### Mechanism 1: Specialized Role Separation in Multi-Agent LLM Architecture
- Claim: Separating conversational and evaluative responsibilities across two LLMs may improve both dialogue naturalness and symptom tracking accuracy, compared to single-LLM approaches that attempt both simultaneously.
- Mechanism: LLM 1 (Conversational Agent) focuses exclusively on maintaining coherent, empathetic dialogue while implicitly collecting symptom-relevant information. LLM 2 (Evaluation Agent) analyzes the dialogue history independently, scoring 21 depressive symptoms on a 0-3 scale and determining whether sufficient information has been gathered. This separation prevents the cognitive load conflict observed when a single LLM attempted to balance conversation flow with systematic tracking.
- Core assumption: Depression symptoms can be reliably inferred from brief conversational exchanges when systematically probed, and specialized prompting improves LLM performance on structured mental health assessments.
- Evidence anchors:
  - [abstract]: "For the pilot task, they used a two-LLM architecture: one for empathetic conversation and another for real-time symptom scoring. This approach achieved 1st place out of 5 teams"
  - [section 3.2]: "However, we observed that this approach yielded suboptimal results. The LLM often failed to balance coherent conversation flow with systematic symptom tracking"
  - [corpus]: Weak direct evidence—related papers (DS@GT eRisk 2025, INESC-ID eRisk 2025) focus on single-model or prompt-based approaches without multi-agent architectures for mental health.

### Mechanism 2: Speed-Accuracy Trade-off in Sequential Transformer Processing
- Claim: Transformer-based models optimized for early detection appear to sacrifice classification precision in exchange for faster risk flagging, suggesting that sequential context processing under temporal constraints introduces inherent tension between speed and accuracy.
- Mechanism: The system uses encoder models (RoBERTa, MentalRoBERTa) with structured input formatting that distinguishes target user messages from context messages via `[MSG] [USER] {type}` tags. Perfect recall (1.00) indicates all true positives are captured, but low precision (0.17-0.24) shows many false positives. The hierarchical preprocessing extracts relevant conversation branches, but early prediction demands trigger before sufficient evidence accumulates.
- Core assumption: Early detection with high recall is valuable even at the cost of precision, and false positives are acceptable in screening contexts.
- Evidence anchors:
  - [abstract]: "ranked 8th out of 12 teams on F1 score but was among the fastest in early prediction, highlighting a trade-off between speed and accuracy"
  - [section 2.4, Table 5]: Recall 1.00, precision 0.17-0.24, ERDE5 0.08-0.09, speed 0.99-1.00
  - [corpus]: Limited direct evidence on speed-accuracy trade-offs in sequential depression detection—related work (DepFlow, MMFformer) focuses on multimodal fusion rather than temporal processing constraints.

### Mechanism 3: Dynamic Planning for Information Gain Maximization
- Claim: A planning mechanism that guides conversation toward underexplored symptoms may enable efficient depression assessment within limited dialogue turns.
- Mechanism: LLM 2 evaluates symptom coverage after each exchange and signals which symptoms require further probing, creating a feedback loop where conversation targets information gaps. With 6.54 mean messages per conversation, the system achieved the best ADODL score (0.93) among all participants, suggesting that structured symptom prioritization compensates for brevity.
- Core assumption: Depression severity can be accurately estimated through targeted questioning within the BDI-II framework, and simulated users provide information comparable to real patients.
- Evidence anchors:
  - [abstract]: "Our success in this task demonstrates the effectiveness of structured conversational design when combined with powerful language models"
  - [section 3.2]: "We implemented a planning mechanism where LLM 2 dynamically suggests which symptoms are underexplored, allowing LLM 1 to prioritize specific topics"
  - [section 3.3, Table 8]: ADODL 0.93 (best), DCHR 0.66, ASHR 0.29 with 6.54 mean messages
  - [corpus]: Related DS@GT paper mentions BDI-II assessments but doesn't describe dynamic planning—corpus evidence is weak for this specific mechanism.

## Foundational Learning

- Concept: Beck Depression Inventory-II (BDI-II) Framework
  - Why needed here: The Pilot Task architecture is structured entirely around 21 BDI-II symptoms. Understanding clinical depression assessment via this framework is essential for interpreting the 0-3 scoring scale and why the system targets specific symptoms sequentially.
  - Quick check question: Why does the system use 21 specific symptoms rather than a holistic depression assessment, and what clinical validity does this framework provide?

- Concept: Early Risk Detection Error (ERDE) Metrics
  - Why needed here: Task 2 evaluation uses ERDE5 and ERDE50 metrics that penalize late correct predictions. Understanding how these metrics balance timeliness against accuracy explains why high recall with low precision was considered acceptable.
  - Quick check question: Why would a system with perfect recall but 0.24 precision still rank competitively on ERDE metrics?

- Concept: Hierarchical Conversation Structure in Social Media
  - Why needed here: The preprocessing pipeline treats Reddit conversations as trees with posts and nested comments. Understanding how the system distinguishes target user messages from context is critical for implementing the data extraction logic.
  - Quick check question: How does the system handle cases where the target user appears in comments but is not the original post author?

## Architecture Onboarding

- Component map:
  - Task 2 Pipeline: Data extraction (PRAW API) → Hierarchical preprocessing (tree formatting with `[MSG] [USER] {type}` tags) → Transformer encoder (RoBERTa/MentalRoBERTa variants, fine-tuned) → Sequential prediction
  - Pilot Task Pipeline: Dual-LLM architecture with LLM 1 (Conversational Agent, Llama-3.1-8B-Instruct) ↔ LLM 2 (Evaluation Agent, same base model, different prompts) → Symptom scoring (21 symptoms, 0-3 scale) → Early termination decision

- Critical path:
  1. Pilot Task success requires: (a) JSON output formatting from both LLMs, (b) LLM 2's accurate symptom scoring from limited dialogue, (c) planning mechanism correctly identifying underexplored symptoms
  2. Task 2 success requires: (a) correct hierarchical conversation extraction, (b) distinguishing target user from context, (c) confident early predictions

- Design tradeoffs:
  - **Empathy vs. efficiency**: Run 1 (empathy without self-disclosure) achieved ADODL 0.92; Run 2 (direct questions only) dropped to 0.88
  - **Speed vs. precision**: Task 2 achieved recall 1.00 with precision 0.17-0.24, prioritizing early flagging over accuracy
  - **Single-LLM vs. dual-LLM**: Paper explicitly abandoned single-LLM approach due to inability to balance conversation with tracking

- Failure signatures:
  - **Overfitting to training structure**: "final performance was not entirely satisfactory, possibly due to overfitting caused by the structure of the training dataset" (Section 4)
  - **Low precision despite perfect recall**: Model is too sensitive, flagging excessive false positives
  - **Strategy ablation impact**: Removing empathy and self-disclosure (Run 2) dropped DCHR from 0.66 to 0.41

- First 3 experiments:
  1. **Replicate dual-LLM vs. single-LLM baseline**: Test whether role separation actually improves performance by comparing against a unified prompt handling both conversation and evaluation. Measure ADODL, DCHR, ASHR differences.
  2. **Map speed-precision trade-off boundary**: Vary prediction thresholds in Task 2 to identify if a sweet spot exists where precision improves without unacceptable latency increase.
  3. **Systematic conversational strategy ablation**: Compare Run 0 (self-disclosure), Run 1 (empathy), and Run 2 (direct questions) across multiple simulated personas to isolate which elements contribute most to accurate symptom detection.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the trade-off between early detection speed and classification accuracy be jointly optimized in transformer-based models for conversational depression detection?
- Basis in paper: [explicit] The authors state in the Abstract and Conclusion that their analysis "highlights the trade-off between early detection and classification accuracy, suggesting potential avenues for optimizing both jointly in future work."
- Why unresolved: The current system ranks high in speed (early prediction) but lower in F1 score (accuracy), indicating the two objectives currently compete rather than complement each other.
- What evidence would resolve it: A modified loss function or architecture that maintains low latency while achieving F1 scores comparable to the top-performing (slower) teams.

### Open Question 2
- Question: Can confidence-based calibration or robust post-processing techniques significantly improve the precision of early risk detection systems without compromising the high recall rates observed in contextualized settings?
- Basis in paper: [explicit] In the Task 2 discussion, the authors identify low precision as a limitation and state, "Future efforts will focus on improving the precision without compromising recall, potentially by incorporating more robust post-processing techniques or confidence-based calibration strategies."
- Why unresolved: The current models achieved perfect recall (1.00) but suffered from low precision (0.17–0.24), resulting in many false positives that the proposed techniques aim to reduce.
- What evidence would resolve it: Experimental results showing a higher Precision score while maintaining a Recall of 1.00 on the Task 2 test set.

### Open Question 3
- Question: To what extent does the structural discrepancy between isolated training posts and contextualized conversational test data cause overfitting in transformer-based depression detection models?
- Basis in paper: [explicit] The Conclusion notes that the performance in Task 2 was "not entirely satisfactory, possibly due to overfitting caused by the structure of the training dataset" compared to the new conversational test format.
- Why unresolved: The training data lacked the hierarchical comment structures present in the test data, potentially limiting the model's ability to generalize to full conversational contexts.
- What evidence would resolve it: A comparative study where models trained on the scraped contextual dataset are evaluated against models trained on the provided isolated posts.

### Open Question 4
- Question: How do different empathetic conversational strategies, specifically self-disclosure versus direct questioning, differentially impact the accuracy of symptom severity estimation compared to categorical depression classification?
- Basis in paper: [inferred] The authors note that Run 1 (empathy without self-disclosure) achieved the best ADODL (severity estimation), while Run 0 (self-disclosure) and Run 2 (direct questions) showed varying performance across DCHR (categorical) and ASHR (symptom hit rate).
- Why unresolved: The results suggest that maximizing user openness through specific strategies may affect the estimation of severity levels differently than identifying the mere presence of specific symptoms.
- What evidence would resolve it: A detailed error analysis isolating the performance of conversational strategies on severity scoring (ADODL) versus binary or multi-class categorization (DCHR).

## Limitations

- **Extreme precision-recall trade-off**: The Task 2 system achieved perfect recall (1.00) but suffered from low precision (0.17-0.24), indicating high false positive rates that may limit practical utility.
- **Weak corpus support for key mechanisms**: The claimed dynamic planning mechanism for information gain maximization lacks direct validation, with related papers not describing this specific approach.
- **Generalization uncertainty**: The dual-LLM architecture achieved best-in-class results with simulated personas, but performance with real clinical interactions remains unknown.

## Confidence

- Task 2 transformer-based system performance: **Medium** - Clear metrics reported but extreme trade-off unexplained
- Dual-LLM architecture superiority: **High** - First place out of 5 teams with substantial margin across all metrics
- Dynamic planning mechanism effectiveness: **Low** - Claimed but minimally validated with weak corpus support
- Generalization beyond Reddit/social media: **Low** - Trained on specific platform, no cross-domain testing

## Next Checks

1. **Threshold sensitivity analysis**: Systematically vary classification thresholds on Task 2 validation set to identify if precision can be improved from 0.17-0.24 to acceptable levels (0.50+) without sacrificing more than 10% recall, directly testing the claimed speed-accuracy trade-off.

2. **Real user vs. simulated persona comparison**: Deploy the dual-LLM Pilot Task system with actual depressed individuals (with appropriate consent/ethics) and compare ADODL/DCHR/ASHR scores against simulated personas to validate the claimed effectiveness in real clinical contexts.

3. **Single-LLM ablation study**: Implement and evaluate a unified prompt handling both conversation and symptom tracking (the approach explicitly abandoned in paper) against the dual-LLM system to empirically test whether role separation provides measurable benefit beyond simple prompt engineering.