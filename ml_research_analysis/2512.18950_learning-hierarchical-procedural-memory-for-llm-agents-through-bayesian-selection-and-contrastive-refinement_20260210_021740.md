---
ver: rpa2
title: Learning Hierarchical Procedural Memory for LLM Agents through Bayesian Selection
  and Contrastive Refinement
arxiv_id: '2512.18950'
source_url: https://arxiv.org/abs/2512.18950
tags:
- uni00000013
- procedures
- uni00000048
- memory
- macla
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MACLA introduces a framework that decouples LLM reasoning from
  adaptation by maintaining a frozen LLM and performing all learning externally in
  a hierarchical procedural memory. The system extracts structured procedures from
  trajectories, tracks reliability with Bayesian posteriors, selects actions via expected-utility
  scoring, and refines procedures through contrastive analysis of successes and failures.
---

# Learning Hierarchical Procedural Memory for LLM Agents through Bayesian Selection and Contrastive Refinement

## Quick Facts
- arXiv ID: 2512.18950
- Source URL: https://arxiv.org/abs/2512.18950
- Reference count: 40
- Primary result: MACLA achieves 78.1% average performance across four benchmarks using only a frozen 7B model

## Executive Summary
MACLA introduces a framework that decouples LLM reasoning from adaptation by maintaining a frozen LLM and performing all learning externally in a hierarchical procedural memory. The system extracts structured procedures from trajectories, tracks reliability with Bayesian posteriors, selects actions via expected-utility scoring, and refines procedures through contrastive analysis of successes and failures. Across four benchmarks (ALFWorld, WebShop, TravelPlanner, InterCodeSQL), MACLA achieves 78.1% average performance—the highest among all methods—using only a 7B model.

## Method Summary
The MACLA framework decouples reasoning from adaptation by keeping the LLM frozen and performing all learning externally through a hierarchical procedural memory system. The approach extracts structured procedures from trajectories, tracks their reliability using Bayesian posterior distributions, and selects actions based on expected-utility scoring. Procedural refinement occurs through contrastive analysis comparing successful and failed trajectories. The system processes 2,851 trajectories to construct 187 procedures in just 56 seconds, achieving a 2,800× speedup compared to state-of-the-art LLM fine-tuning baselines while maintaining superior performance across multiple benchmarks.

## Key Results
- 78.1% average performance across four benchmarks (ALFWorld, WebShop, TravelPlanner, InterCodeSQL)
- 90.3% success rate on unseen ALFWorld tasks with +3.1% positive generalization
- 2,800× faster than fine-tuning baselines (56 seconds vs. traditional approaches)

## Why This Works (Mechanism)
MACLA works by maintaining a frozen LLM and offloading all adaptation to an external hierarchical procedural memory. The system extracts structured procedures from successful trajectories, tracks their reliability using Bayesian posterior distributions based on execution frequency, and selects actions through expected-utility scoring that balances success probability with reliability. Procedural refinement occurs through contrastive analysis comparing successful and failed trajectories, allowing the system to improve its procedures without retraining the underlying model. This separation of reasoning from adaptation enables rapid learning while preserving the LLM's reasoning capabilities.

## Foundational Learning
- **Bayesian reliability tracking**: Tracks procedure success rates with posterior distributions to quantify confidence in stored procedures. Needed to distinguish between reliable and unreliable procedures in memory. Quick check: Verify posterior updates match empirical success rates across multiple executions.
- **Contrastive procedure refinement**: Compares successful and failed trajectories to identify critical differences and improve procedures. Needed to enhance procedural quality without model retraining. Quick check: Confirm refined procedures show improved success rates on validation tasks.
- **Hierarchical memory organization**: Structures procedures in multiple levels to handle complexity and enable efficient retrieval. Needed to scale to diverse tasks while maintaining fast access. Quick check: Measure retrieval time and accuracy across different hierarchy depths.
- **Expected-utility action selection**: Scores candidate procedures by combining success probability with reliability metrics. Needed to make optimal choices among multiple stored procedures. Quick check: Validate selection accuracy on tasks with known optimal procedures.
- **Trajectory-based procedure extraction**: Converts raw agent trajectories into structured, reusable procedures. Needed to create a compact representation of learned behavior. Quick check: Compare extracted procedure coverage against original task requirements.

## Architecture Onboarding

**Component Map**: Trajectory Extractor -> Bayesian Tracker -> Expected-Utility Selector -> Contrastive Refiner -> Hierarchical Memory

**Critical Path**: Trajectory extraction → Bayesian reliability update → Expected-utility selection → Action execution → Contrastive refinement → Memory update

**Design Tradeoffs**: The framework trades computational overhead of external memory management for the benefit of maintaining a frozen, reasoning-capable LLM. This approach sacrifices the potential performance gains from fine-tuning in exchange for rapid adaptation and better generalization to unseen tasks.

**Failure Signatures**: 
- Low reliability scores across multiple procedures indicate insufficient training data or poor initial trajectory quality
- Slow procedure retrieval suggests suboptimal hierarchical organization or memory bloat
- Inconsistent performance across similar tasks may reveal gaps in procedure coverage or refinement quality

**First Experiments**:
1. Validate Bayesian reliability tracking by running the same procedure multiple times and comparing posterior updates to empirical success rates
2. Test expected-utility selection accuracy on a controlled task with known optimal procedures
3. Evaluate contrastive refinement by comparing procedure success rates before and after refinement on a validation set

## Open Questions the Paper Calls Out
None

## Limitations
- Performance advantage may diminish for complex unseen scenarios requiring novel procedure combinations
- 3.1% positive generalization improvement, while meaningful, represents modest gains that could be task-specific
- 2,800× speedup claim depends on specific fine-tuning configurations and may not generalize across all computational setups
- Bayesian reliability scoring may degrade in low-data scenarios or tasks with sparse reward signals

## Confidence
- **High**: Memory extraction and organization methodology, systematic comparison across four distinct benchmarks, core claim of outperforming baselines on seen tasks using frozen LLM
- **Medium**: Generalization results on unseen tasks, 2,800× speedup claim (due to varying fine-tuning baseline assumptions), long-term procedural memory maintenance
- **Low**: 3.1% positive generalization improvement as universal indicator, performance on tasks requiring creative procedural combinations

## Next Checks
1. Test MACLA on a benchmark specifically designed to require novel combinations of learned procedures not present in the training corpus
2. Evaluate the system's memory decay and retrieval accuracy over extended periods with hundreds of stored procedures to assess scalability limits
3. Compare MACLA's performance against fine-tuning baselines using identical computational resources and model scales to validate the 2,800× speedup claim across different hardware configurations