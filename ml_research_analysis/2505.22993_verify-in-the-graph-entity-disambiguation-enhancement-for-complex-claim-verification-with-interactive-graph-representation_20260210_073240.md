---
ver: rpa2
title: 'Verify-in-the-Graph: Entity Disambiguation Enhancement for Complex Claim Verification
  with Interactive Graph Representation'
arxiv_id: '2505.22993'
source_url: https://arxiv.org/abs/2505.22993
tags:
- claim
- entity
- graph
- triplets
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces VeGraph, a framework for claim verification
  that uses an interactive graph representation to handle complex claims with ambiguous
  entities. The method works in three phases: (1) decomposing the claim into structured
  graph triplets; (2) iteratively resolving ambiguous entities by querying a knowledge
  base; and (3) verifying the remaining triplets to reach a final verdict.'
---

# Verify-in-the-Graph: Entity Disambiguation Enhancement for Complex Claim Verification with Interactive Graph Representation

## Quick Facts
- arXiv ID: 2505.22993
- Source URL: https://arxiv.org/abs/2505.22993
- Reference count: 32
- Primary result: VeGraph achieves state-of-the-art Macro-F1 on HoVer and FEVEROUS by iteratively resolving ambiguous entities through KB interaction

## Executive Summary
This paper introduces VeGraph, a framework for claim verification that uses an interactive graph representation to handle complex claims with ambiguous entities. The method works in three phases: (1) decomposing the claim into structured graph triplets; (2) iteratively resolving ambiguous entities by querying a knowledge base; and (3) verifying the remaining triplets to reach a final verdict. The framework is evaluated on the HoVer and FEVEROUS benchmarks using Meta-Llama-3-70B. Results show that VeGraph outperforms several strong baselines, especially in entity disambiguation and numerical reasoning tasks. The ablation study demonstrates that both the graph representation and multi-step reasoning contribute significantly to performance. The approach also provides interpretable reasoning traces for explainability.

## Method Summary
VeGraph is a three-stage pipeline for complex claim verification. First, an LLM decomposes claims into entity-relation triplets forming a graph-based representation. Second, the system iteratively resolves ambiguous entities through KB interactions, generating targeted questions and refining queries when resolution fails. Third, remaining triplets are converted to natural-language sub-claims and verified against retrieved evidence. The framework uses Meta-Llama-3-70B-Instruct as backbone with a two-layer retrieval system (BM25 + Bi-Encoder + Reranker). The iterative disambiguation loop allows up to k=5 attempts to resolve entities before defaulting to refutation.

## Key Results
- VeGraph achieves state-of-the-art Macro-F1 scores on HoVer (2-hop, 3-hop, 4-hop) and FEVEROUS benchmarks
- Notable improvements in entity disambiguation and numerical reasoning tasks compared to baselines
- Ablation study shows graph representation and multi-step reasoning contribute significantly to performance gains
- Provides interpretable reasoning traces for explainability and failure analysis

## Why This Works (Mechanism)

### Mechanism 1: Graph-Based Claim Decomposition
- Claim: Structuring claims as entity-relation triplets improves semantic comprehension over raw text.
- Mechanism: An LLM decomposes complex claims into graph triplets G = {T₁, T₂, ..., Tₙ}, where each triplet Tᵢ = (E₁ᵢ, Rᵢ, E₂ᵢ) represents a sub-claim. Ambiguous entities are tagged as Xᵢ for later resolution.
- Core assumption: LLMs can reliably extract entities and relations via in-context learning without extensive domain-specific training.
- Evidence anchors:
  - [abstract] "an input claim is decomposed into structured triplets, forming a graph-based representation that integrates both structured and unstructured information"
  - [section 3.1] "With this graph-based representation, the LLM can more effectively capture the semantic intricacies of the claim"
  - [corpus] GraphCheck (arXiv:2502.20785) similarly uses entity-relationship graphs for fact-checking, suggesting the approach has independent validation
- Break condition: LLM fails to capture implicit entities or produces incorrect triplet structures (observed in 29% of 2-hop errors per Table 3).

### Mechanism 2: Iterative Entity Disambiguation
- Claim: Multi-step KB interaction with question refinement resolves ambiguous entities that single-pass methods miss.
- Mechanism: Triplets sharing ambiguous entities are grouped. The LLM generates targeted questions from triplet information; if resolution fails, rationale and failed questions feed into the next iteration to refine the query.
- Core assumption: Information about an entity is fragmented across documents; iterative refinement can triangulate the correct entity.
- Evidence anchors:
  - [abstract] "ambiguous entities are resolved iteratively through interactions with a knowledge base"
  - [section 3.3] "approximately 30% of the requests to the KB failed to resolve the entity. This highlights the importance of the iterative reasoning strategy"
  - [corpus] No direct corpus comparison for iterative disambiguation specifically; related work focuses on single-pass retrieval
- Break condition: Maximum iteration limit k reached without resolution → claim marked "REFUTES" by default.

### Mechanism 3: Sub-Claim Verification Pipeline
- Claim: Verifying individual triplets against retrieved evidence produces interpretable, granular verdicts.
- Mechanism: After disambiguation, remaining triplets are converted to natural-language sub-claims and verified via KB retrieval + LLM judgment. If all sub-claims pass → "Supported"; if any fail → "Refuted."
- Core assumption: Retrieval system surfaces documents containing sufficient evidence for binary verification.
- Evidence anchors:
  - [section 3.4] "If all sub-claims are supported, C is categorized as Supported; otherwise, if any sub-claim is refuted, C is categorized as Refuted"
  - [section 4.4] VeGraph achieves notable gains on 4-hop claims (+5 points Macro-F1 vs. baselines)
  - [corpus] Retrieve-Refine-Calibrate (arXiv:2601.16555) critiques decomposition paradigms for introducing noise, a known tradeoff
- Break condition: Sub-claim verification errors propagate (32–38% of failures per Table 3).

## Foundational Learning

- Concept: **Open Information Extraction (OpenIE)**
  - Why needed here: VeGraph uses open-schema relation extraction rather than fixed relation types, allowing natural-language predicates like "is based on the life of."
  - Quick check question: Can you explain why fixed relation taxonomies (e.g., OWNERSHIP, LOCATED) would limit this system?

- Concept: **In-Context Learning (Few-Shot Prompting)**
  - Why needed here: Graph construction relies on few-shot demonstrations to guide the LLM; other tasks use zero-shot prompting.
  - Quick check question: What is the difference between zero-shot and few-shot prompting, and where does VeGraph use each?

- Concept: **Multi-Hop Reasoning**
  - Why needed here: HoVer dataset requires 2–4 hops; VeGraph must aggregate evidence across interdependent documents.
  - Quick check question: How does multi-hop reasoning differ from single-hop retrieval in claim verification?

## Architecture Onboarding

- Component map:
  Graph Representation Module → Entity Disambiguation Loop → Verification Module → Logging Module
  Retrieval System (BM25 + Bi-Encoder + Reranker) supports all stages

- Critical path:
  1. Input claim → Graph Representation → triplet graph with Xᵢ placeholders
  2. Disambiguation loop (up to k iterations): group → question → KB query → update graph
  3. Convert remaining triplets → sub-claims → verify against KB
  4. Aggregate verdicts → final label

- Design tradeoffs:
  - Higher k improves disambiguation success but increases latency (Table 4: ~40–50% more inference time vs. ProgramFC)
  - Generalized pipeline vs. task-specific optimization: VeGraph underperforms on FEVEROUS Multi-hop subset where entity resolution is less critical

- Failure signatures:
  - Graph Representation Errors (15–29%): incorrect triplet structure
  - Entity Disambiguation Errors (37–53%): unresolved Xᵢ after k iterations
  - Sub-claim Errors (32–38%): retrieval returns insufficient or misleading evidence

- First 3 experiments:
  1. Run VeGraph (k=5) on HoVer 2-hop subset; compare Macro-F1 vs. CoT-Decomposing baseline to validate basic pipeline.
  2. Ablate the graph component (use raw claim without triplet decomposition) on 3-hop claims to quantify semantic-structure contribution.
  3. Vary k ∈ {1, 2, 5} and plot disambiguation success rate vs. inference time to identify practical compute budget.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can VeGraph be extended to effectively process implicit information and nuanced reasoning in real-world claims?
- Basis in paper: [explicit] The authors state in the Limitations section that the current framework focuses on explicit reasoning, whereas real-world claims often contain implicit information not captured by the current design.
- Why unresolved: The current architecture relies on extracting explicit triplets, lacking mechanisms to infer unstated context or abductive logic required for nuanced fact-checking.
- What evidence would resolve it: Successful evaluation on a dataset specifically annotated for implicit reasoning, showing improved performance over the current explicit-only baseline.

### Open Question 2
- Question: What optimization strategies can mitigate the computational overhead and latency caused by the framework's iterative LLM interactions?
- Basis in paper: [explicit] The Limitations section highlights that frequent reliance on LLMs introduces latency, posing challenges for real-world applications requiring rapid response times.
- Why unresolved: The iterative disambiguation process necessitates multiple sequential LLM calls and knowledge base interactions, creating a bottleneck that current ablations do not address.
- What evidence would resolve it: A modified architecture demonstrating reduced inference time per claim (e.g., through caching or smaller models) without compromising Macro-F1 scores.

### Open Question 3
- Question: How can the initial graph representation phase be stabilized to minimize semantic extraction errors in complex claims?
- Basis in paper: [inferred] Section 4.6 (Error Analysis) identifies "Graph Representation Errors" as a primary failure source (up to 29% in 2-hop claims), which propagates through the verification pipeline.
- Why unresolved: The reliance on in-context learning with LLMs for graph construction proves inconsistent when handling complex sentence structures, leading to flawed triplets.
- What evidence would resolve it: Integration of a dedicated semantic parser or constrained decoding mechanism that lowers the graph error rate in the HoVer 4-hop partition.

## Limitations

- Dependence on LLM performance for graph construction and entity disambiguation introduces variability not fully characterized
- Iterative disambiguation assumes KB contains sufficient evidence for resolution, but coverage completeness isn't quantified
- Evaluation focuses on Macro-F1 without precision-recall tradeoff analysis
- Limited ablation study exploring alternative graph representations or disambiguation strategies

## Confidence

- **High confidence**: The core claim that VeGraph improves entity disambiguation performance on HoVer and FEVEROUS benchmarks is well-supported by experimental results and ablation studies
- **Medium confidence**: The mechanism explanation for iterative entity disambiguation is plausible but relies heavily on LLM reasoning quality, which isn't fully characterized
- **Medium confidence**: The architectural claims about graph-based decomposition improving semantic comprehension are supported by performance gains but could benefit from qualitative analysis of specific failure cases

## Next Checks

1. **Run the first 3 experiments** as outlined: (1) baseline comparison on HoVer 2-hop subset, (2) ablation of graph component on 3-hop claims, (3) sensitivity analysis of k parameter vs. inference time to identify optimal compute budget.

2. **Implement the failure signature monitoring** by logging triplet extraction quality, disambiguation success rates per iteration, and retrieval evidence relevance scores to create a diagnostic dashboard for the three failure modes identified.

3. **Conduct precision-recall analysis** by breaking down Macro-F1 results into precision and recall components across different claim types (2-hop, 3-hop, 4-hop) to identify whether the method favors precision or recall and where it introduces the most errors.