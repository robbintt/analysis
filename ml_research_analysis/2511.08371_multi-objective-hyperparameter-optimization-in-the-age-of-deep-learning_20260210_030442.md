---
ver: rpa2
title: Multi-objective Hyperparameter Optimization in the Age of Deep Learning
arxiv_id: '2511.08371'
source_url: https://arxiv.org/abs/2511.08371
tags:
- priors
- primo
- optimization
- multi-objective
- prior
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses the problem of incorporating expert prior
  knowledge in multi-objective deep learning hyperparameter optimization (HPO). The
  authors propose PriMO, the first HPO algorithm that integrates multi-objective user
  beliefs, fulfilling key desiderata: utilizing cheap approximations, integrating
  expert priors, strong anytime performance, and strong final performance.'
---

# Multi-objective Hyperparameter Optimization in the Age of Deep Learning

## Quick Facts
- arXiv ID: 2511.08371
- Source URL: https://arxiv.org/abs/2511.08371
- Reference count: 40
- Primary result: PriMO is the first HPO algorithm integrating multi-objective user beliefs with state-of-the-art performance across 8 DL benchmarks

## Executive Summary
This paper addresses a critical gap in multi-objective deep learning hyperparameter optimization (HPO) by introducing PriMO, an algorithm that effectively incorporates expert prior knowledge. PriMO combines Bayesian optimization with a prior-augmented acquisition function and an initial design strategy leveraging cheap approximations. The method demonstrates up to 10x speedups compared to state-of-the-art approaches while maintaining robust performance even when faced with misleading priors. The algorithm successfully fulfills four key desiderata: utilizing cheap approximations, integrating expert priors, strong anytime performance, and strong final performance.

## Method Summary
PriMO employs a Bayesian optimization framework enhanced with a novel prior-augmented acquisition function that incorporates expert beliefs about hyperparameter-objective relationships. The method uses a two-stage approach: first, it leverages cheap proxy models to gather initial information about the hyperparameter space, then transitions to full-scale training while maintaining the prior knowledge through the augmented acquisition function. The algorithm specifically addresses the challenge of multi-objective optimization by balancing exploration and exploitation across multiple objectives while respecting the expert priors. The prior integration is achieved through a modified expected improvement criterion that weighs expert beliefs against empirical observations.

## Key Results
- Achieves state-of-the-art performance across 8 deep learning benchmarks
- Demonstrates up to 10x speedup compared to existing multi-objective HPO methods
- Shows robust performance across different prior conditions, including recovery from misleading priors
- Outperforms baselines in both anytime performance (early-stage) and final performance (late-stage) metrics

## Why This Works (Mechanism)
PriMO's effectiveness stems from its intelligent integration of cheap approximations with expert priors within a Bayesian optimization framework. The prior-augmented acquisition function allows the algorithm to make more informed decisions early in the optimization process, reducing the number of expensive full-scale training evaluations needed. By using cheap proxies for initial exploration, PriMO can quickly identify promising regions of the hyperparameter space before committing to computationally expensive full evaluations. The Bayesian approach naturally handles uncertainty, allowing the algorithm to balance between exploiting known good regions and exploring uncertain areas, all while respecting the expert priors that guide the search.

## Foundational Learning

**Bayesian Optimization** - A sequential model-based optimization technique that builds a probabilistic model of the objective function to guide the search for optimal hyperparameters. Why needed: Provides the probabilistic framework for integrating priors and handling uncertainty in expensive function evaluations. Quick check: Can be implemented with Gaussian processes or other surrogate models.

**Multi-objective Optimization** - The process of simultaneously optimizing multiple conflicting objectives. Why needed: Deep learning HPO often involves trade-offs between metrics like accuracy, training time, and model size. Quick check: Can be represented using Pareto optimality concepts.

**Cheap Proxies** - Simplified models or approximations that provide faster but less accurate evaluations of the objective function. Why needed: Enable early exploration without the computational cost of full model training. Quick check: Must be correlated with true objectives but orders of magnitude faster.

**Expected Improvement** - An acquisition function that measures the expected improvement over the current best solution. Why needed: Guides the Bayesian optimization search by quantifying the potential benefit of evaluating new points. Quick check: Can be computed analytically for Gaussian processes.

## Architecture Onboarding

Component Map: Expert Priors -> Prior-Augmented Acquisition -> Bayesian Optimization Loop -> Cheap Proxies -> Full Evaluations

Critical Path: Cheap proxy evaluations → Initial design → Prior integration → Augmented acquisition function → Full model evaluation → Pareto front update

Design Tradeoffs: Computational cost vs. prior quality, exploration vs. exploitation balance, proxy accuracy vs. evaluation speed, prior strength vs. adaptability

Failure Signatures: Poor proxy quality leading to wasted evaluations, overly strong priors causing premature convergence, insufficient exploration resulting in suboptimal Pareto fronts

First Experiments: 1) Single-objective optimization with known priors, 2) Multi-objective optimization without priors, 3) Stress test with misleading priors to verify recovery capability

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Relies on the availability of cheap proxies, which may not exist for all deep learning problems
- Does not extensively address how to quantify or validate the quality of expert priors before deployment
- The characterization of recovery from misleading priors could be more comprehensive
- Potential scalability concerns when dealing with very high-dimensional hyperparameter spaces

## Confidence
- **High confidence**: Experimental results demonstrating performance improvements, effectiveness of the prior-augmented acquisition function, and anytime performance claims
- **Medium confidence**: Claims about robustness across different prior conditions and recovery from misleading priors, as these aspects could benefit from more extensive characterization
- **Medium confidence**: The generalizability of the method to domains where cheap proxies are not readily available

## Next Checks
1. Test PriMO's performance on real-world HPO problems where cheap proxies are not readily available or are expensive to compute
2. Conduct a systematic study on how different types and qualities of expert priors affect PriMO's performance, including a sensitivity analysis
3. Evaluate PriMO's scalability to high-dimensional hyperparameter spaces and compare its performance with other methods as the number of objectives increases