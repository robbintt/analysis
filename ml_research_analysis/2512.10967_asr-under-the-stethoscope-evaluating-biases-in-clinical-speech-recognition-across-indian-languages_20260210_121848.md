---
ver: rpa2
title: 'ASR Under the Stethoscope: Evaluating Biases in Clinical Speech Recognition
  across Indian Languages'
arxiv_id: '2512.10967'
source_url: https://arxiv.org/abs/2512.10967
tags:
- speech
- clinical
- languages
- english
- across
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents the first systematic evaluation of ASR systems
  in multilingual clinical psychiatric interviews. The authors compare 8 leading ASR
  models (including OpenAI Whisper, IndicWhisper, Sarvam, Google speech-to-text, Gemma3n,
  Gemini, Omnilingual, and Vaani) on real-world doctor-patient conversations in Kannada,
  Hindi, and Indian English.
---

# ASR Under the Stethoscope: Evaluating Biases in Clinical Speech Recognition across Indian Languages

## Quick Facts
- **arXiv ID**: 2512.10967
- **Source URL**: https://arxiv.org/abs/2512.10967
- **Reference count**: 15
- **Primary result**: Systematic evaluation of 8 ASR models on real-world clinical psychiatric interviews in Indian languages reveals significant performance gaps across languages, speaker roles, gender, and regions.

## Executive Summary
This paper presents the first systematic evaluation of ASR systems in multilingual clinical psychiatric interviews. The authors compare 8 leading ASR models on real-world doctor-patient conversations in Kannada, Hindi, and Indian English. They assess transcription accuracy across languages, speaker roles, gender, education level, and regional origin using WER and error component analysis. Results show substantial variability across models and languages, with Gemini achieving the best overall performance and Kannada being the most challenging. The study reveals systematic disparities, with higher error rates for patient speech compared to clinician speech, and significant intersectional biases affecting female patients and speakers from certain regions.

## Method Summary
The study evaluates 8 ASR models (OpenAI Whisper, IndicWhisper, Sarvam, Google speech-to-text, Gemma3n, Gemini, Omnilingual, and Vaani) on a dataset of 162 real-world doctor-patient psychiatric interviews in Kannada, Hindi, and Indian English. The evaluation uses standard WER metrics along with error component analysis (substitutions, deletions, insertions) to identify failure patterns. The authors also conduct statistical tests (Mann-Whitney U) to assess significance of performance differences across speaker roles, gender, and regional groups.

## Key Results
- Substantial variability in ASR performance across models and languages, with Gemini achieving the best overall performance
- Systematic performance gaps tied to speaker role, with patients showing significantly higher WER (56.75 median) than doctors (50.45 median)
- Kannada being the most challenging language, with deletion-dominated failures reaching up to 84% for some models
- Significant intersectional biases affecting female patients and speakers from certain regions, with compounded error rates beyond additive effects

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ASR systems produce systematically higher error rates for patient speech compared to clinician speech in clinical interviews.
- Mechanism: Role-based conversational asymmetry manifests in three cascading layers: (1) Acoustic factors—patients sit farther from microphones, speak in shorter turns with higher overlap rates; (2) Prosodic factors—patients produce more disfluent, spontaneous speech with backchannels ("Mmm," "Hmm") that ASR struggles to transcribe; (3) Linguistic factors—patients use regional vocabulary, code-switching, and colloquialisms outside training distributions, while clinicians use predictable medical phrasing. These compound to elevate substitution, deletion, and insertion errors differentially by role.
- Core assumption: The observed WER gap reflects systematic speech pattern differences tied to institutional role, not merely demographic confounds (though these intersect).
- Evidence anchors:
  - [abstract] "We also uncover systematic performance gaps tied to speaker role and gender, raising concerns about equitable deployment in clinical settings."
  - [section 5.2] "A Mann-Whitney U test revealed a statistically significant difference in WER between speaker roles (p<0.001). Patients showed a significantly higher median WER (56.75) compared to doctors (50.45)."
  - [corpus] Related work (Russell et al. 2024) confirms ASR weakness on conversational speech, especially backchannels and non-lexical tokens—consistent with patient response patterns.
- Break condition: If clinicians and patients were given equal microphone access, speaking time, and used identical register/vocabulary, the role-based gap should narrow substantially. If gap persists, other factors (power dynamics, anxiety-induced speech changes) may dominate.

### Mechanism 2
- Claim: Language resource level and morphological complexity predict ASR error patterns—specifically, low-resource Dravidian languages (Kannada) exhibit deletion-dominated failures.
- Mechanism: Training data scarcity creates weak acoustic-phonetic representations for underrepresented languages. Kannada presents compounding challenges: (1) lack of clear word boundaries in connected speech; (2) complex consonant clusters and retroflex phonemes underrepresented in global corpora; (3) regional accent variability with limited training coverage. The model responds with conservative recognition—dropping uncertain segments rather than guessing—producing the observed high deletion rates (up to 84% for GSTT on Kannada).
- Core assumption: The deletion-dominant error pattern reflects model uncertainty thresholds rather than architectural incapacity; with sufficient Indic-language training data, error profile would shift toward more balanced S/D/I distribution.
- Evidence anchors:
  - [abstract] "Kannada being the most challenging"
  - [section 5.1] "For the Kannada language, the error mostly stems from deletions (D) reaching as high as 84% for GSTT... models like Whisper, GSTT, and Gemma3n show a very high WER for Kannada because their architectures and training corpora are not deeply optimised for rich Indian phonetic diversity and retroflex phonemes in Dravidian languages."
  - [corpus] IndicVoices and IndicSUPERB (Javed et al. 2022, 2024) document morphological and prosodic diversity complicating ASR—corroborating structural difficulty, though not clinical-specific.
- Break condition: If a model specifically trained on large-scale Kannada conversational data still shows deletion-dominant errors, the mechanism may involve architectural limitations (e.g., subword tokenization mismatch) rather than data scarcity alone.

### Mechanism 3
- Claim: Intersectional demographic categories (gender × role × region) produce compounded ASR disparities beyond additive effects of individual attributes.
- Mechanism: Multiple marginalized attributes interact non-linearly: female patients face both role-based disadvantage (patient speech complexity) and gender-based acoustic mismatches (if training data skewed toward male voices or clinical register associated with male physicians). Regional accent compounds this if the speaker's dialect is underrepresented. The result: WER for female patients (62.60) substantially exceeds female doctors (48.42), and male patients (63.19) exceed male doctors (65.60)—though gender effect direction varies by language (Hindi shows higher female WER).
- Core assumption: Training corpora for ASR models overrepresent male voices, formal speech registers, and dominant regional accents, creating compounding penalties for speakers distant from this centroid.
- Evidence anchors:
  - [abstract] "significant intersectional biases affecting female patients and speakers from certain regions"
  - [section 5.2] "A Mann-Whitney U test revealed a statistically significant difference in WER within gender×speaker roles (p<0.01). The female doctor has significantly lower WER than other attributes followed by female patient, then male doctor and highest for male patient."
  - [corpus] Koenecke et al. (2020) and Tatman (2017) document gender and racial ASR disparities; Rai et al. (2024) show regional/gender disparities in Indian English lecture speech—but intersectional clinical dialogue bias is novel to this paper.
- Break condition: If stratified training data balancing gender, role, and region representation eliminates the intersectional gap, mechanism is confirmed as data-distribution bias. If gap persists, architectural inductive biases or feature extraction limitations may be implicated.

## Foundational Learning

- Concept: **Word Error Rate (WER) decomposition (Substitution/Deletion/Insertion)**
  - Why needed here: The paper uses WER as primary metric but crucially analyzes its components—deletion-heavy patterns in Kannada versus insertion-heavy (hallucination) patterns in Sarvam reveal distinct failure modes invisible to aggregate WER alone.
  - Quick check question: If a model has WER=50% with S=10%, D=40%, I=0%, what type of failure dominates, and what might cause it?

- Concept: **Code-mixing and code-switching in multilingual ASR**
  - Why needed here: Indian clinical interviews frequently blend Hindi/Kannada with English medical terminology. The paper notes models "failing on code-mixed or vernacular speech"—understanding this requires knowing that standard ASR language identification and monolingual language models break down when speakers switch languages mid-utterance.
  - Quick check question: Why would an ASR model trained separately on Hindi and English struggle with "Mujhe depression feel ho raha hai"?

- Concept: **Intersectionality in ML fairness**
  - Why needed here: The paper's core contribution is showing that gender × role × region interactions produce non-additive error patterns. Understanding that bias compounds across dimensions (not just sums) is essential for interpreting Tables 4 and designing mitigation.
  - Quick check question: If female WER=45% and patient WER=55%, what would additive prediction for female patient WER be? How might the actual 62.60% observed suggest interaction effects?

## Architecture Onboarding

- Component map:
Audio (MP3, 16kHz) → Feature Extraction (log-Mel spectrograms, 30s windows) → Acoustic Encoder (Transformer-based, self-attention) → Text Decoder (with language model prior) → Transcript Output (with/without timestamps)

Key architectural variants in study:
- **Whisper-family** (Whisper, IndicWhisper, Vaani): Encoder-decoder transformers with 30s windowed inference
- **LLM-integrated** (Gemini, Gemma3n): Multimodal transformers with cross-modal attention, long-context handling
- **Massively multilingual** (Omnilingual): 7B parameter encoder with self-supervised pretraining on 4.3M+ hours

- Critical path:
  1. Audio preprocessing quality (sampling rate, noise floor) determines feature quality
  2. Language identification (explicit or implicit) gates downstream acoustic modeling
  3. Decoder language model prior shapes insertion/deletion balance—strong LMs hallucinate more (Sarvam's 36-39% insertion rate)

- Design tradeoffs:
  - **Generalist vs. specialist models**: Gemini (generalist) achieves best WER, but may not generalize to unseen dialects; Sarvam (India-optimized) shows competitive Hindi/Kannada but high hallucination rates
  - **Timestamp precision vs. accuracy**: Four models provide word-level timestamps, four don't—impacts downstream clinical NLP pipelines requiring turn alignment
  - **Open vs. proprietary**: Proprietary models (Gemini, Google STT) outperform open alternatives, limiting reproducibility and fine-tuning options

- Failure signatures:
  - **Deletion cascade** (Kannada in GSTT/Whisper): >75% deletions indicate model gives up on uncertain segments—sign of out-of-distribution acoustic features
  - **Hallucination loops** (Sarvam English/Hindi): >35% insertions with repetitive patterns ("and... and... and...")—language model prior overpowers acoustic evidence
  - **Role inversion** (if observed): If doctor WER > patient WER in specific language, suggests training data skewed toward patient-style spontaneous speech (unlikely but diagnostic)

- First 3 experiments:
  1. **Baseline replication on held-out split**: Take the 162-interview dataset, hold out 20% stratified by language/gender/role. Run all 8 models. Verify WER ranking matches paper (Gemini > Sarvam > others) and intersectional patterns persist on unseen data.
  2. **Error component ablation by demographic**: For Sarvam (best open timestamp-providing model), compute S/D/I breakdown for each cell in the gender × role × region matrix. Identify which subgroups drive deletion vs. insertion failures to prioritize data collection.
  3. **Acoustic confound control**: Extract per-speaker SNR estimates and speaking rate. Fit mixed-effects model: WER ~ role + gender + language + SNR + speaking_rate + (1|speaker_id). Determine if role effect remains significant after controlling for acoustic quality, or if microphone placement explains the gap.

## Open Questions the Paper Calls Out

- None

## Limitations

- **Data representativeness**: The 162-interview dataset may not fully capture India's linguistic diversity, with potential underrepresentation of southern Dravidian languages beyond Kannada and uneven sampling of regional accents.
- **Confounding factors in role-based disparities**: The higher WER for patient speech could partially reflect unmeasured acoustic factors (microphone distance, background noise during emotional disclosure) rather than purely linguistic differences.
- **Generalizability to other clinical contexts**: Psychiatric interviews have unique linguistic patterns that may not translate to other specialties like cardiology or oncology.

## Confidence

- **High confidence**: Role-based WER disparities (Mann-Whitney p<0.001), language-level performance ranking (Gemini > Sarvam > others), deletion-dominant errors in Kannada
- **Medium confidence**: Gender-specific intersectional effects (smaller sample sizes for some demographic cells), causality of training data gaps for deletion patterns
- **Low confidence**: Attribution of disparities solely to linguistic differences vs. acoustic confounds, long-term clinical impact of observed biases

## Next Checks

1. **Hold-out validation**: Replicate results on a stratified 20% hold-out sample to confirm WER rankings and intersectional patterns aren't artifacts of dataset-specific splits.
2. **Acoustic confound analysis**: Control for SNR and speaking rate in mixed-effects models to isolate role effect from microphone/proximity effects.
3. **Error component mapping**: For Sarvam, compute S/D/I breakdown by each demographic × role × region cell to identify which subgroups drive deletion vs. hallucination failures.