---
ver: rpa2
title: Black-box Model Merging for Language-Model-as-a-Service with Massive Model
  Repositories
arxiv_id: '2509.12951'
source_url: https://arxiv.org/abs/2509.12951
tags:
- uni00000048
- uni00000013
- uni0000004c
- uni00000055
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of merging multiple large language
  models (LLMs) without access to their internal parameters, a scenario termed "black-box
  model merging" (BMM). To solve this, the authors propose Evo-Merging, an evolutionary
  algorithm-based framework that operates through API calls.
---

# Black-box Model Merging for Language-Model-as-a-Service with Massive Model Repositories

## Quick Facts
- arXiv ID: 2509.12951
- Source URL: https://arxiv.org/abs/2509.12951
- Reference count: 28
- Key outcome: Evo-Merging achieves 52.13% F1 on out-of-domain tasks and demonstrates robustness when merging over 100 models, outperforming prior methods.

## Executive Summary
This paper addresses the challenge of merging multiple large language models (LLMs) without access to their internal parameters, a scenario termed "black-box model merging" (BMM). The authors propose Evo-Merging, an evolutionary algorithm-based framework that operates through API calls to merge LoRA adapters. The framework consists of two stages: sparsity-based denoising to filter out irrelevant parameters, and sign-aware scaling to dynamically adjust model contributions based on performance. Experimental results show that Evo-Merging significantly outperforms strong baselines in both out-of-domain and in-domain settings, achieving state-of-the-art performance and demonstrating robustness when merging over 100 models, where prior methods degrade.

## Method Summary
Evo-Merging is a two-stage derivative-free optimization framework that merges LoRA adapters using only inference-time API queries. Stage 1 applies asymmetric sparsity to LoRA-A matrices, pruning top $\alpha\%$ of parameters to filter noise. Stage 2 uses sign-aware scaling with weights $\beta$ (allowing negative values) to dynamically adjust model contributions. The entire optimization uses CMA-ES, treating validation loss as a fitness function. The method operates without gradients by sampling populations of parameter vectors, querying the API with these settings, and evolving toward lower loss. The framework demonstrates effectiveness with 100+ models while avoiding the performance degradation seen in prior approaches.

## Key Results
- Evo-Merging achieves 52.13% F1 on out-of-domain tasks, significantly outperforming baselines
- The framework maintains performance when merging over 100 models, where prior methods show degradation
- Ablation studies confirm the critical role of both asymmetric sparsity and sign-aware scaling mechanisms

## Why This Works (Mechanism)

### Mechanism 1: Asymmetric Sparsity (Denoising)
Applying magnitude-based sparsification exclusively to the LoRA "A" matrix (input projection) filters noise more effectively than pruning the "B" matrix (output projection). The framework posits that Matrix A serves as a "concept extraction" layer while Matrix B acts as a "knowledge mapping" layer. By retaining only the top $\alpha\%$ of parameters in A and setting the rest to zero, the framework eliminates non-essential concepts before they are mapped to the output space. Evidence shows that removing this denoising causes F1 scores to drop significantly, validating its necessity.

### Mechanism 2: Sign-Aware Scaling (Conflict Resolution)
Optimizing scaling weights $\beta$ with both positive and negative values allows the framework to actively subtract conflicting knowledge from source models. Unlike standard averaging, this method assigns a scalar $\beta_i$ to each model, where a negative $\beta_i$ allows the merged model to "unlearn" or cancel out specific interfering behaviors. The sign of $\beta_i$ provides a powerful mechanism for conflict resolution: positive values enhance synergy while negative values subtract conflicting knowledge. Disabling sign-flipping results in a ~12% drop in F1 score, indicating that negative weights are critical for handling interference.

### Mechanism 3: Derivative-Free Optimization (CMA-ES)
An evolutionary strategy (CMA-ES) can effectively find optimal merging hyperparameters ($\alpha, \beta$) using only validation set feedback, bypassing the need for gradient access. The Covariance Matrix Adaptation Evolution Strategy treats the validation loss as a "fitness function," sampling populations of parameter vectors, querying the API with these settings, and evolving the population toward lower loss without requiring backpropagation through the base LLM. The method demonstrates data efficiency with population size of 20 and ~40 iterations for Stage 2.

## Foundational Learning

- **Concept: Low-Rank Adaptation (LoRA)**
  - Why needed here: The entire architecture relies on manipulating LoRA matrices ($A$ and $B$) rather than full model weights. You must understand that $W = W_0 + BA$ to grasp how merging $\sum \beta_i B_i A_i$ alters the base model.
  - Quick check question: If you prune the $A$ matrix, are you altering the rank of the update or the density of the features? (Answer: Density/sparsity of the concept extraction).

- **Concept: Task Vectors**
  - Why needed here: The method assumes that the "knowledge" of a fine-tuned model is encoded in the vector difference ($\Delta W$) from the pretrained base. Merging is effectively vector arithmetic on these differences.
  - Quick check question: If Model A is fine-tuned for NER and Model B for Sentiment, how does the "sign-aware scaling" mechanism theoretically combine them? (Answer: By scaling their vectors, potentially subtracting the sentiment vector if it interferes with NER).

- **Concept: Covariance Matrix Adaptation (CMA-ES)**
  - Why needed here: This is the engine of the "Black-box" approach. Unlike SGD, it does not require gradients.
  - Quick check question: Why is a population-based method preferred over a single-query search (e.g., random search) here? (Answer: It adapts the covariance matrix to learn correlations between parameters, making the search efficient in high-dimensional spaces).

## Architecture Onboarding

- **Component map:** Adapter Pool -> Evolutionary Engine (CMA-ES) -> Fitness Evaluator -> Merger Unit
- **Critical path:** The optimization loop. Ensure the Fitness Evaluator can reload the base model and apply the candidate merged adapter quickly. Bottlenecks usually occur here due to high inference volume.
- **Design tradeoffs:**
  - Sparsity ($\alpha$) vs. Capacity: Higher sparsity removes noise but risks dropping rare, critical knowledge.
  - Population Size vs. Convergence Speed: Larger populations (default 20) explore more but require more API calls per generation.
- **Failure signatures:**
  - Catastrophic Collapse: Outputting gibberish. Check if $\beta$ values exploded or if sparsity $\alpha$ became 0% or 100%.
  - Stagnation: Validation loss stops improving early. The CMA-ES step size (sigma) may have decayed too fast.
  - Degradation with Scale: Performance drops when adding >50 models. This indicates the "Denoising" stage failed to filter irrelevant adapters effectively.
- **First 3 experiments:**
  1. Sanity Check (Single Model): Set $N=1$. Verify that Evo-Merging essentially recovers the original model's performance.
  2. Interference Test (2 Models): Merge two conflicting models (e.g., a "Helpful" assistant and a "Harmless" refusal model). Verify that the sign-flipping mechanism ($\beta < 0$) activates to resolve the conflict.
  3. Robustness Test (100 Models): Replicate the "Out-of-Domain" setup on a small validation set to confirm the sparsity mechanism scales to massive pools without performance collapse.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the Evo-Merging framework be effectively generalized to black-box multi-modal models, and does the asymmetric sparsification strategy hold for cross-modal representations?
- Basis in paper: The conclusion explicitly states the intention to generalize Evo-Merging to multi-modal models.
- Why unresolved: The current theoretical justification for sparsifying Matrix A relies on a "concept extraction" hypothesis specific to language tasks; it is unclear if this applies to heterogeneous noise in vision or audio encoders.
- What evidence would resolve it: Empirical results applying Evo-Merging to multi-modal adapters demonstrating effectiveness without discarding essential cross-modal alignment information.

### Open Question 2
- Question: How robust is the Evo-Merging framework when the validation set $D_{val}$ is extremely small (e.g., <10 samples) or contains noisy labels?
- Basis in paper: The optimization objectives explicitly minimize loss over a validation set $D_{val}$, but the paper doesn't explore failure modes for few-shot regimes.
- Why unresolved: The evolutionary algorithm requires reliable fitness signals. If $D_{val}$ is too small or noisy, CMA-ES may overfit to spurious feedback or fail to converge.
- What evidence would resolve it: Performance curves showing degradation as validation set size approaches zero, or ablation studies using synthetic validation data.

### Open Question 3
- Question: Is the query complexity of the CMA-ES optimizer practical for merging repositories significantly larger than 100 models (e.g., 1000+) in commercial API settings?
- Basis in paper: The paper highlights effectiveness with 100+ models but doesn't analyze convergence efficiency relative to API calls.
- Why unresolved: While accuracy is maintained, financial and latency costs likely scale poorly with dimensionality. The paper doesn't analyze computational limits.
- What evidence would resolve it: Analysis of convergence speed relative to number of candidate models $N$, or comparison against more sample-efficient black-box optimization methods.

## Limitations

- Black-box Definition Ambiguity: The framework requires access to LoRA adapter weights rather than just API predictions, contradicting the "black-box" constraint claim.
- Loss Function Accessibility: The optimization uses Cross-Entropy Loss but claims API-only access, creating a fundamental inconsistency since standard APIs don't provide loss values.
- Scalability Concerns: Computational cost of loading and manipulating 100+ adapters simultaneously is not addressed, potentially creating memory bottlenecks.

## Confidence

- **High Confidence**: Asymmetric sparsity mechanism effectiveness (validated by Table 3 performance drops when disabled) and general two-stage optimization framework structure.
- **Medium Confidence**: Sign-aware scaling mechanism's conflict resolution claims - while ablation shows importance, the linear conflict resolution assumption is not rigorously proven.
- **Low Confidence**: Black-box constraint claims and loss accessibility claims due to apparent contradiction between requiring parameter access and claiming API-only methodology.

## Next Checks

1. **API-Only Verification**: Implement a version that truly uses only API predictions (without adapter parameter access) and verify whether the evolutionary algorithm can still optimize effectively using only task-specific metrics rather than loss values.

2. **Loss Accessibility Test**: Test the framework's performance when using only publicly available API outputs (text generations) to calculate task-specific metrics, comparing this against the claimed loss-based optimization to quantify any performance degradation.

3. **Massive Scale Stress Test**: Reproduce the 100+ model merging scenario with varying population sizes and iteration counts to empirically determine computational limits and identify at what scale the framework's performance degrades or becomes computationally infeasible.