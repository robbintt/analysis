---
ver: rpa2
title: Explainability of CNN Based Classification Models for Acoustic Signal
arxiv_id: '2509.08717'
source_url: https://arxiv.org/abs/2509.08717
tags:
- deeplift
- grad-cam
- explanations
- were
- class
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study addresses the interpretability challenge of deep learning\
  \ models in bioacoustics by analyzing bird vocalizations from two geographic variants\
  \ of Bewick\u2019s wren. The authors trained a CNN on spectrogram images achieving\
  \ 94.8% classification accuracy, then applied XAI techniques including LIME, SHAP,\
  \ Grad-CAM, and DeepLIFT to explain predictions."
---

# Explainability of CNN Based Classification Models for Acoustic Signal

## Quick Facts
- arXiv ID: 2509.08717
- Source URL: https://arxiv.org/abs/2509.08717
- Authors: Zubair Faruqui; Mackenzie S. McIntire; Rahul Dubey; Jay McEntee
- Reference count: 38
- One-line primary result: CNN achieves 94.8% accuracy on bird vocalization classification, with ensemble XAI methods providing biologically meaningful explanations.

## Executive Summary
This study addresses the interpretability challenge of deep learning models in bioacoustics by analyzing bird vocalizations from two geographic variants of Bewick's wren. The authors trained a CNN on spectrogram images achieving 94.8% classification accuracy, then applied XAI techniques including LIME, SHAP, Grad-CAM, and DeepLIFT to explain predictions. Model-specific methods (Grad-CAM and DeepLIFT) provided more consistent and biologically meaningful explanations compared to model-agnostic approaches. Ensemble saliency maps combining these techniques improved interpretability by capturing complementary features. t-SNE analysis revealed distinct sub-populations within each class, highlighting hidden acoustic patterns.

## Method Summary
The authors developed a CNN-based classification system for bird vocalizations, converting 4-second audio clips to spectrograms using STFT with specific parameters. The CNN architecture consists of five convolutional blocks followed by three fully connected layers. After achieving 94.8% classification accuracy, they applied multiple XAI techniques including Grad-CAM, DeepLIFT, LIME, and SHAP to generate saliency maps. They created ensemble saliency maps by averaging and taking element-wise maximum of Grad-CAM and DeepLIFT heatmaps. t-SNE analysis was performed on CNN latent features to identify sub-populations within classes, and the consistency of XAI explanations across these sub-populations was examined.

## Key Results
- Model-specific XAI techniques (Grad-CAM and DeepLIFT) provided more consistent and biologically meaningful explanations than model-agnostic methods (LIME and SHAP).
- Ensemble saliency maps combining Grad-CAM and DeepLIFT captured complementary discriminative regions and improved interpretability.
- t-SNE analysis revealed distinct sub-populations within each bird song class, explaining intra-class variation in XAI explanations.
- The CNN achieved 94.8% classification accuracy on the binary classification task.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Model-specific XAI techniques (Grad-CAM, DeepLIFT) provide more consistent and biologically meaningful explanations than model-agnostic methods (LIME, SHAP) for CNN-based spectrogram classification.
- Mechanism: Grad-CAM leverages gradients from the final convolutional layer to weight feature maps, producing coarse spatial attention maps. DeepLIFT backpropagates contribution scores by comparing neuron activations to a reference baseline, yielding fine-grained attributions. Both access internal model structure rather than relying on input perturbation.
- Core assumption: The CNN's internal representations directly encode task-relevant spectral features; gradient-based attribution faithfully reflects feature importance.
- Evidence anchors:
  - [abstract] "Model-specific methods (Grad-CAM and DeepLIFT) provided more consistent and biologically meaningful explanations compared to model-agnostic approaches."
  - [section IV.A] "LIME sometimes marked empty or irrelevant regions as important, reducing the reliability of the explanation... SHAP provides better explanations... however neither provides strong and conclusive reasoning."
  - [corpus] Related work (A XAI-based Framework for Frequency Subband Characterization of Cough Spectrograms) similarly applies CNN with XAI to spectrograms, but does not systematically compare model-specific vs. model-agnostic methods—evidence gap remains for generalization.
- Break condition: If the CNN has poor gradient flow (e.g., saturated activations, dead ReLUs), gradient-based methods may fail. If the reference baseline is poorly chosen for DeepLIFT, attributions become unreliable.

### Mechanism 2
- Claim: Ensemble saliency maps combining Grad-CAM and DeepLIFT capture complementary discriminative regions, improving interpretability over either method alone.
- Mechanism: Grad-CAM highlights coarse, high-contrast regions via pooled gradients; DeepLIFT provides broader, context-aware relevance. Weighted averaging preserves common salient areas; element-wise maximum ensures any region highlighted by either method is retained.
- Core assumption: The two methods emphasize different but valid aspects of model decisions; their union covers more true discriminative features.
- Evidence anchors:
  - [abstract] "Ensemble saliency maps combining these techniques improved interpretability by capturing complementary features."
  - [section IV.B] "The max-based ensemble, in particular, ensures that the most strongly activated regions from either technique are preserved... the ensemble-max saliency map consistently activates a higher proportion of regions across thresholds."
  - [corpus] Melanoma Classification Through Deep Ensemble Learning and Explainable AI uses ensemble learning with XAI, but focuses on model ensembles rather than XAI ensemble—limited direct evidence for XAI fusion strategies.
- Break condition: When Grad-CAM and DeepLIFT produce fundamentally contradictory heatmaps (e.g., opposite regions highlighted), ensembling may create confounding overlays rather than clearer explanations.

### Mechanism 3
- Claim: t-SNE visualization of CNN latent features reveals sub-population structure within bird song classes, explaining intra-class variation in XAI explanations.
- Mechanism: The CNN learns feature representations that cluster by acoustic similarity. t-SNE preserves local neighborhood structure in 2D, exposing subgroups that linear methods like PCA miss.
- Core assumption: Sub-populations have distinct spectro-temporal signatures; the CNN captures these differences in its latent space; t-SNE reliably reflects this structure.
- Evidence anchors:
  - [abstract] "t-SNE analysis revealed distinct sub-populations within each class, highlighting hidden acoustic patterns."
  - [section IV.C] "The t-SNE plot revealed more distributed points of data scattered in a few different clusters for each class... the explanation heatmaps remained consistent within each cluster."
  - [corpus] No directly comparable t-SNE-for-subpopulation analysis in the neighbor corpus for bioacoustics—evidence is domain-specific and limited.
- Break condition: If the feature extractor is undertrained or class imbalance is severe, t-SNE may show artificial clusters or fail to separate meaningful subgroups.

## Foundational Learning

- **Concept: Short-Time Fourier Transform (STFT) and Spectrograms**
  - Why needed here: Audio signals are converted to spectrograms (time-frequency images) for CNN input. Understanding STFT parameters (window length, overlap, dynamic range) is critical for feature preservation.
  - Quick check question: If you increase STFT window overlap from 50% to 95%, what happens to temporal resolution and spectrogram size?

- **Concept: Gradient-based Attribution for CNNs (Grad-CAM, DeepLIFT)**
  - Why needed here: These are the core XAI techniques. Grad-CAM uses gradients × feature maps; DeepLIFT uses backpropagated relevance from a reference. Both require understanding backpropagation and ReLU behavior.
  - Quick check question: Why does Grad-CAM apply ReLU to the final weighted sum of feature maps before visualization?

- **Concept: Dimensionality Reduction for Latent Space Analysis (t-SNE vs PCA)**
  - Why needed here: To validate intra-class structure and sub-populations. PCA is linear and global; t-SNE is non-linear and local-preserving, better for cluster discovery.
  - Quick check question: If two sub-populations are linearly separable in the original high-dimensional space, will PCA or t-SNE more reliably show their separation?

## Architecture Onboarding

- **Component map:**
  1. Audio preprocessing: Bandpass filter (1.5–9 kHz) → segment into 4s clips
  2. Spectrogram generation: STFT (512-sample window, 95% overlap, −40 to 5 dB) → 480×960 px image
  3. CNN backbone: 5 conv blocks (16→32→64→128→256 channels, each: Conv3×3 → ReLU → MaxPool2×2) → Flatten → 3 FC layers (512→1024→2)
  4. XAI layer: Grad-CAM (last conv layer gradients), DeepLIFT (reference: white image), ensemble fusion (average/max)
  5. Analysis: t-SNE/PCA on latent features, quantitative heatmap thresholding

- **Critical path:**
  - Spectrogram quality → CNN feature learning → XAI heatmap fidelity. Poor dynamic range or resolution in spectrograms will propagate as weak or noisy explanations.

- **Design tradeoffs:**
  - LIME/SHAP vs Grad-CAM/DeepLIFT: Agnostic flexibility vs architecture-aware precision; LIME is unstable for high-res images, SHAP is computationally expensive.
  - Ensemble average vs max: Average emphasizes consensus regions; max preserves all salient areas but may include noise.
  - Black/white/mixed spectrogram backgrounds: Mixed backgrounds improve generalization (94.83% accuracy) but may complicate visual interpretation.

- **Failure signatures:**
  - LIME highlights empty spectrogram regions → perturbation-based instability.
  - SHAP requires excessive background samples for high-res images → computational bottleneck.
  - Grad-CAM highlights post-signal reverberation → coarse localization, needs cross-check with DeepLIFT.
  - Explanations vary wildly within a class → potential sub-populations; run t-SNE to verify.

- **First 3 experiments:**
  1. **Reproduce the ensemble XAI pipeline:** Train the 5-layer CNN on the mixed-background spectrograms; generate Grad-CAM and DeepLIFT heatmaps for 10 samples per class; compute average and max ensembles; quantify heatmap density across thresholds (0.4–0.9) to replicate Figure 6.
  2. **Ablate the XAI ensemble:** Compare standalone Grad-CAM, standalone DeepLIFT, average ensemble, and max ensemble using human expert evaluation (if available) or proxy metrics (heatmap consistency across repeated runs, overlap with ground-truth signal regions).
  3. **Sub-population validation:** Extract penultimate layer features for all test samples; run t-SNE with varying perplexities; sample from 3–4 distinct clusters per class; generate XAI heatmaps for each cluster sample to confirm cluster-specific consistency as in Figure 7.

## Open Questions the Paper Calls Out
- **Open Question 1:** Can the proposed ensemble XAI approach maintain high interpretability and accuracy when applied to diverse acoustic environments and varying recording conditions? The current study utilizes a specific dataset recorded with consistent equipment, potentially limiting generalizability.
- **Open Question 2:** Do the distinct sub-population clusters identified by t-SNE within the "Eastern" and "Mexican" classes correspond to specific biological ground truths, such as micro-geographic dialects or individual repertoire variations? The paper lacks metadata correlation required to determine if these are dialectal differences or individual signatures.
- **Open Question 3:** Does an adaptive weighting strategy for the ensemble saliency maps provide superior interpretability compared to the fixed 0.5 weights or element-wise maximum strategies used in this study? Different spectrograms may rely on varying degrees of coarse spatial attention versus fine-grained attribution, suggesting a static combination strategy might be suboptimal.

## Limitations
- Dataset accessibility is a primary limitation - specific audio recordings and train/test split details are not publicly available, preventing exact replication.
- The neighbor corpus provides minimal citation support for key mechanisms, particularly the comparative advantage of model-specific over model-agnostic XAI methods.
- The generalizability of the ensemble XAI approach to other bioacoustic classification tasks remains uncertain given the absence of similar studies in the corpus.

## Confidence
- **High confidence**: The 94.8% classification accuracy claim, based on standard CNN training with specified hyperparameters and evaluated on a held-out test set.
- **Medium confidence**: The relative performance comparison between XAI techniques (Grad-CAM/DeepLIFT vs LIME/SHAP), as this is directly supported by the results section but lacks external validation in the corpus.
- **Low confidence**: The generalizability of the ensemble XAI approach to other bioacoustic classification tasks, given the absence of similar studies in the neighbor corpus.

## Next Checks
1. Conduct cross-validation on multiple bioacoustic datasets to test whether model-specific XAI methods consistently outperform model-agnostic approaches across different acoustic domains.
2. Systematically vary CNN architecture depth and width to determine if the observed XAI method performance differences persist across different model capacities.
3. Implement controlled ablation studies comparing ensemble XAI methods against individual techniques using quantitative metrics (heatmap stability, overlap with ground-truth features) on the same dataset.