---
ver: rpa2
title: Finite-Time Accuracy of Temporal-Difference Learning Under Schur-Stable Recursions
arxiv_id: '2204.10479'
source_url: https://arxiv.org/abs/2204.10479
tags:
- linear
- learning
- error
- finite-time
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides a control-theoretic finite-time error analysis
  for tabular temporal difference (TD) learning. The authors model TD learning as
  a discrete-time stochastic linear system and leverage Schur stability of the associated
  system matrix to derive mean-squared error bounds for both final and averaged iterates.
---

# Finite-Time Accuracy of Temporal-Difference Learning Under Schur-Stable Recursions

## Quick Facts
- arXiv ID: 2204.10479
- Source URL: https://arxiv.org/abs/2204.10479
- Reference count: 40
- Key outcome: Control-theoretic finite-time error bounds for tabular TD learning using Schur stability, providing simpler proofs and sharper bounds than continuous-time approaches

## Executive Summary
This paper provides a novel control-theoretic finite-time error analysis for tabular temporal difference (TD) learning. The authors model TD learning as a discrete-time stochastic linear system and leverage Schur stability of the associated system matrix to derive mean-squared error bounds for both final and averaged iterates. Their approach bypasses continuous-time approximations used in prior work, leading to simpler proofs, sharper error bounds, and more relaxed step-size conditions. For the final iterate, they establish bounds on the mean-squared error that scale as O(α/(dmin(1-γ)^1.5) + O(ρ^k) where ρ is an exponential convergence rate. For averaged iterates, they show O(1/√k) convergence rates.

## Method Summary
The paper analyzes tabular TD(0) learning using a discrete-time stochastic linear system framework. Given an MDP with state space S, action space A, fixed policy π, and discount factor γ ∈ [0,1), the TD update V_{k+1}(s_k) = V_k(s_k) + α[r_{k+1} + γV_k(s'_k) - V_k(s_k)] is modeled as x_{k+1} = Ax_k + w_k where x_k represents the error V_k - V^π. The system matrix A = I + α(γDP^π - D) is shown to be Schur-stable with ||A||_∞ ≤ ρ = 1 - αd_min(1-γ) < 1, where d_min is the minimum stationary distribution probability. This stability enables finite-time error bounds without relying on continuous-time approximations.

## Key Results
- Final iterate MSE bound: E[||V_k - V^π||²] ≤ 6|S|√α/(d_min^0.5(1-γ)^1.5) + ||V_0 - V^π||²|S|ρ^k
- Averaged iterate convergence: E[||(1/k)Σ_{i=0}^{k-1} V_i - V^π||²] ≤ O(1/√k)
- Relaxed step-size condition: α ∈ (0,1) versus stricter requirements in prior work

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The TD learning iteration can be modeled as a discrete-time stochastic linear system with Schur-stable dynamics.
- Mechanism: Define the error state x_k = V_k - V^π and system matrix A = I + α(γDP^π - D). The ∞-norm satisfies ||A||_∞ ≤ ρ := 1 - αd_min(1-γ) < 1, establishing Schur stability. This guarantees the noise-free system x_{k+1} = Ax_k decays exponentially to zero.
- Core assumption: Step-size α ∈ (0,1) and positive stationary distribution d(s) > 0 for all states.
- Evidence anchors: [abstract] "leverages Schur stability of the associated matrices"; [section] Lemma 4 proves ||A||_∞ ≤ ρ = 1 - αd_min(1-γ); [corpus] Related work on implicit TD (arXiv:2510.06149) addresses step-size sensitivity but via different mechanisms

### Mechanism 2
- Claim: Mean-squared error bounds for the final iterate follow from propagating the state covariance matrix through a Lyapunov recursion.
- Mechanism: The covariance X_k = E[x_k x_k^⊤] evolves as X_{k+1} = AX_k A^⊤ + α²W_k where W_k is the noise covariance. Schur stability ensures X_k remains bounded even with persistent noise. The MSE is recovered as E[||x_k||²] = tr(X_k).
- Core assumption: Bounded noise (||w_k||_∞ ≤ √w_max with w_max = 9/(1-γ)²) and bounded initial condition.
- Evidence anchors: [section] Lemma 6 establishes boundedness of X_k; [section] Theorem 1 gives E[||V_k - V^π||²] ≤ 6|S|√α/(d_min^0.5(1-γ)^1.5) + ||V_0 - V^π||²|S|ρ^k; [corpus] Limited direct corpus support for this covariance propagation technique

### Mechanism 3
- Claim: Averaged iterates achieve O(1/√k) convergence through a dual Lyapunov analysis.
- Mechanism: Construct M = Σ_{k=0}^∞ (A^k)^⊤ A^k satisfying A^⊤ M A = M - I. The quadratic Lyapunov function v(x) = x^⊤ M x decreases by ||x_k||² minus a noise term each step. Averaging yields the O(1/√k) rate.
- Core assumption: Same Schur stability; λ_min(M) ≥ 1, λ_max(M) ≤ n/(1-ρ).
- Evidence anchors: [section] Lemma 8 proves existence and spectral bounds on M; [section] Theorem 2 establishes the averaged iterate bound; [corpus] Implicit stochastic recursion methods (arXiv:2505.01361) pursue similar stabilization goals via different techniques

## Foundational Learning

- **Schur Stability**:
  - Why needed here: A matrix A is Schur stable if all eigenvalues lie in the open unit disk (equivalently, ||A|| < 1 for some norm). This guarantees exponential decay of noise-free trajectories, enabling finite-time bounds without ODE approximations.
  - Quick check question: For A = I + α(γDP^π - D) with D diagonal, why does the ∞-norm bound follow from row sums?

- **Discrete-Time Lyapunov Theory**:
  - Why needed here: The standard Lyapunov equation A^⊤PA - P = -Q characterizes stability. For Schur A, the solution P = Σ_k (A^k)^⊤ Q A^k exists and is positive definite.
  - Quick check question: If A^⊤ M A = M - I with M ≻ 0, why does v(x) = x^⊤ M x decrease along trajectories x_{k+1} = Ax_k?

- **Temporal Difference Learning**:
  - Why needed here: TD(0) estimates V^π via V_{k+1}(s_k) = V_k(s_k) + α[r_{k+1} + γV_k(s'_k) - V_k(s_k)]. The Bellman equation V^π = γP^π V^π + R^π defines the fixed point.
  - Quick check question: Why does the TD error δ_k = r_{k+1} + γV_k(s'_k) - V_k(s_k) have zero mean at V_k = V^π?

## Architecture Onboarding

- **Component map**:
  - System matrix: A = I + α(γDP^π - D) ∈ R^{|S|×|S|}
  - Noise term: w_k = e_{s_k}δ_k - (DR^π + γDP^π V_k - DV_k), bounded by w_max = 9/(1-γ)²
  - Lyapunov matrices: X_k (covariance, for final iterate) and M (for averaged iterate)

- **Critical path**:
  1. Verify Schur stability: Compute ||A||_∞ ≤ ρ = 1 - αd_min(1-γ)
  2. Bound noise covariance: λ_max(W_k) ≤ w_max
  3. Propagate covariance: X_{k+1} = AX_k A^⊤ + α²W_k
  4. Extract MSE: E[||x_k||²] = tr(X_k)

- **Design tradeoffs**:
  - Larger α → faster ρ but larger asymptotic bias term
  - Tabular setting: cleaner bounds but poor scaling to large |S|
  - i.i.d. observations: simpler analysis; Markovian noise requires additional techniques

- **Failure signatures**:
  - Slow convergence: ρ ≈ 1 (small α or d_min close to 0)
  - High variance: Large w_max from rewards or discount factor near 1
  - Instability: Step-size α ≥ 1 violates Assumption 1

- **First 3 experiments**:
  1. Validate Lemma 4 on random MDPs: verify ||A||_∞ ≤ ρ across varying α ∈ (0,1), γ ∈ [0.9, 0.99)
  2. Reproduce Theorem 1 on a chain MDP: plot E[||V_k - V^π||²] vs. the bound over k = 10³–10⁵ steps
  3. Sweep step-sizes: Compare final-iterate MSE for α ∈ {0.1, 0.5, 0.9} to verify relaxed step-size condition advantage

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the Schur-stability framework be extended to analyze TD learning with linear function approximation while maintaining simple proofs?
- Basis in paper: [explicit] The authors state the analysis is restricted to tabular settings but "can be extended to incorporate on-policy linear function approximation with additional effort."
- Why unresolved: The current proofs rely heavily on the tabular structure (specifically Lemma 4 regarding the infinity norm of the system matrix A), which does not directly translate to the projected matrices used in function approximation.
- What evidence would resolve it: A derivation of finite-time error bounds for TD with linear function approximation that directly exploits Schur stability without converting to continuous-time ODE models.

### Open Question 2
- Question: How does the finite-time error bound change under a Markovian (non-i.i.d.) observation model using this control-theoretic approach?
- Basis in paper: [explicit] The paper notes the analysis uses an i.i.d. model for simplicity, but "can be extended to more general Markovian observation models using techniques from prior work."
- Why unresolved: The current proof relies on the assumption that the noise w_k has zero mean conditioned on the current state (E[w_k|x_k]=0), a property that requires adjustment for the time-correlated noise found in Markovian settings.
- What evidence would resolve it: A modified analysis incorporating mixing time arguments or Lyapunov functions for Markovian jump linear systems within the discrete-time Schur framework.

### Open Question 3
- Question: Can the reusable template be successfully applied to derive simpler finite-time bounds for control algorithms like Q-learning or Actor-Critic?
- Basis in paper: [inferred] The abstract claims the framework provides a "reusable template for analyzing... related RL algorithms," and the introduction lists Q-learning and Actor-Critic as methods based on TD learning.
- Why unresolved: Q-learning involves max-operators (non-linearities) and off-policy updates that complicate the linear system representation (x_{k+1} = Ax_k + ...) central to this paper's technique.
- What evidence would resolve it: Derivations of finite-time performance guarantees for Q-learning or Actor-Critic that leverage the discrete-time Schur-stability of the underlying expected update operators.

## Limitations

- The analysis requires bounded rewards (|r| ≤ 1) and i.i.d. observations, with additional techniques needed for Markovian noise
- The tabular setting limits scalability to large state spaces, with no discussion of function approximation extensions
- The noise bound w_max = 9/(1-γ)² grows quickly as γ approaches 1, potentially making bounds loose for highly discounted problems

## Confidence

- **High Confidence:** The Schur stability framework (Mechanism 1) is mathematically sound and well-established in control theory. The Lyapunov analysis for boundedness (Mechanism 2) follows standard techniques.
- **Medium Confidence:** The error bounds in Theorems 1 and 2 are derived rigorously, but their tightness depends on the specific MDP structure and noise characteristics. The covariance propagation technique is less common in RL literature.
- **Low Confidence:** The practical implications of the relaxed step-size condition are unclear without empirical validation across diverse MDPs and step-size ranges.

## Next Checks

1. Test robustness to Markovian noise: Implement the additional techniques from [22, 3] and verify bound preservation on a standard MDP benchmark.
2. Stress-test the reward bound: Systematically vary |r| beyond 1 and quantify degradation in the error bounds on chain and Gridworld MDPs.
3. Compare with continuous-time analysis: Replicate results from [18] on the same MDP instances to evaluate the practical tightness gains of the discrete-time approach.