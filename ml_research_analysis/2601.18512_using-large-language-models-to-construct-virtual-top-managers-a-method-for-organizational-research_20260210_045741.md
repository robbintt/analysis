---
ver: rpa2
title: 'Using Large Language Models to Construct Virtual Top Managers: A Method for
  Organizational Research'
arxiv_id: '2601.18512'
source_url: https://arxiv.org/abs/2601.18512
tags:
- moral
- human
- foundations
- page
- personas
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates that large language models can generate
  realistic virtual personas of top managers when grounded in their own communications
  and moral-psychological profiles. By constructing personas of 181 CEOs using publicly
  available texts and Moral Foundations Theory, the researchers show that these virtual
  leaders reproduce the structure of human moral reasoning in sacrificial dilemmas.
---

# Using Large Language Models to Construct Virtual Top Managers: A Method for Organizational Research

## Quick Facts
- arXiv ID: 2601.18512
- Source URL: https://arxiv.org/abs/2601.18512
- Reference count: 0
- Large language models can generate realistic virtual personas of top managers when grounded in their communications and moral-psychological profiles.

## Executive Summary
This study introduces a method for creating virtual top managers using large language models, grounded in real-world communications and moral foundations profiles. The researchers constructed 181 CEO personas using publicly available texts and Moral Foundations Theory, then tested these virtual leaders on sacrificial moral dilemmas. The method successfully reproduced patterns of human moral reasoning, with the strongest results when using moral profiles alone. The study demonstrates the potential of LLM-based personas as a complementary tool for organizational research, particularly when direct access to executives is limited.

## Method Summary
The researchers created virtual CEO personas by combining publicly available communications from 181 CEOs with their Moral Foundations Theory profiles. They then prompted these personas to respond to sacrificial moral dilemmas, using both isolated trait prompting and integrated-trait prompting approaches. The moral dilemma scenarios were standardized, and responses were analyzed to determine how well the virtual CEOs' decision patterns matched those of human participants. The method involved constructing detailed prompts that incorporated both the CEO's moral foundations scores and their communication style characteristics.

## Key Results
- The MFT-only model showed the strongest alignment between input moral profiles and behavioral outputs
- Virtual CEOs produced patterns resembling human participants, with Harm and Purity negatively affecting sacrificial acceptability and Authority positively affecting it
- Integrated-trait prompting improved stability and internal coherence across runs compared to isolated trait prompting

## Why This Works (Mechanism)
The method works by grounding LLM personas in empirically measured moral foundations profiles and authentic communication patterns, which provides the model with structured psychological priors that guide moral reasoning. The Moral Foundations Theory framework offers a validated dimensional representation of moral cognition that the LLM can use as scaffolding for decision-making. The integration of actual CEO communications helps capture leadership style and decision-making patterns that pure trait scoring might miss. The sacrificial dilemma scenarios provide a standardized context that allows for systematic comparison between virtual and human moral reasoning patterns.

## Foundational Learning
- **Moral Foundations Theory**: A psychological framework measuring five moral dimensions (Care, Fairness, Loyalty, Authority, Purity) that captures how individuals reason about moral issues. Why needed: Provides validated psychological measurement for grounding virtual personas. Quick check: Review Haidt & Graham (2007) for theoretical basis and validation studies.
- **Sacrificial moral dilemmas**: Standardized ethical scenarios where participants must choose whether to sacrifice one person to save multiple others. Why needed: Offers controlled experimental paradigm for testing moral reasoning. Quick check: Examine Christensen & Gomila (2012) for dilemma design principles.
- **Prompt engineering with personas**: Technique of constructing detailed prompts that incorporate personality traits, background, and behavioral priors. Why needed: Essential for eliciting consistent behavior from LLMs that reflects target personas. Quick check: Review Reynolds & McDonell (2021) on persona-based prompting.
- **Integrated vs. isolated trait prompting**: Comparison of prompting strategies where traits are either combined into a single prompt versus applied sequentially. Why needed: Different approaches affect consistency and coherence of outputs. Quick check: Test both methods on simple personality-driven tasks.
- **CEO communication analysis**: Process of extracting leadership style and decision patterns from public communications. Why needed: Provides authentic behavioral priors for persona construction. Quick check: Apply content analysis to sample CEO communications.
- **Virtual human simulation validation**: Framework for assessing how well LLM-generated personas match human behavior patterns. Why needed: Establishes credibility of virtual participants as research tools. Quick check: Compare virtual and human responses on benchmark tasks.

## Architecture Onboarding

**Component map:**
CEO communication corpus -> MFT scoring -> LLM persona construction -> Moral dilemma prompts -> Behavioral output analysis -> Validation against human patterns

**Critical path:**
The sequence from persona construction through moral dilemma response to behavioral validation represents the critical path. The quality of the moral foundations profile input and the prompt engineering approach directly determine the fidelity of the behavioral outputs. The integrated-trait prompting method emerged as superior to isolated trait prompting for maintaining consistency across runs.

**Design tradeoffs:**
The study balances ecological validity (using real CEO communications) against standardization (using fixed moral dilemma scenarios). The MFT-only model performed best but may miss leadership-specific decision patterns captured by communication analysis. The choice of a single LLM limits generalizability but ensures methodological consistency. The sacrificial dilemma paradigm provides clean experimental control but may not capture the full complexity of executive decision-making.

**Failure signatures:**
- Inconsistent responses across repeated runs suggest inadequate persona grounding or prompt instability
- Poor alignment between input MFT scores and behavioral outputs indicates the persona construction failed to properly incorporate moral foundations
- Failure to reproduce known human moral reasoning patterns suggests the prompts are not effectively eliciting the target decision-making style
- Overfitting to specific dilemma formats may limit generalizability to other organizational contexts

**Three first experiments:**
1. Test integrated-trait prompting on non-moral organizational decision tasks to assess generalizability
2. Compare outputs from different LLM architectures (Claude, Gemini) using identical persona inputs
3. Conduct sensitivity analysis by varying the weight of different MFT dimensions in persona prompts

## Open Questions the Paper Calls Out
None

## Limitations
- Sample restricted to 181 CEOs with publicly available communications, potentially introducing selection bias
- Use of a single LLM without systematic testing across model versions or architectures limits generalizability
- Hypothetical moral dilemmas may not capture the full complexity of real-world executive decision-making
- No direct comparison between virtual CEO responses and actual CEO responses in the same scenarios

## Confidence

**High** confidence in the methodological framework and its potential as a complementary research tool
**Medium** confidence in the specific quantitative findings regarding moral reasoning patterns, given the moderate effect sizes and unexplained variance
**Low** confidence in the external validity for other types of organizational research beyond moral dilemmas

## Next Checks

1. Replicate the study using a different LLM family (e.g., Claude or Gemini) to assess model dependency
2. Expand validation to non-moral organizational decision tasks such as strategic choice scenarios or leadership style assessments
3. Conduct a head-to-head comparison between virtual CEO responses and actual CEO responses in the same moral dilemma scenarios, where possible, to establish convergent validity