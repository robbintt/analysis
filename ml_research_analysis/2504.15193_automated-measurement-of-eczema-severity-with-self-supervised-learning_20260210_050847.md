---
ver: rpa2
title: Automated Measurement of Eczema Severity with Self-Supervised Learning
arxiv_id: '2504.15193'
source_url: https://arxiv.org/abs/2504.15193
tags:
- eczema
- learning
- data
- segmentation
- dino
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of automated eczema severity
  measurement from images using limited annotated data. The proposed method combines
  in-context learning for segmentation with self-supervised learning for classification.
---

# Automated Measurement of Eczema Severity with Self-Supervised Learning

## Quick Facts
- **arXiv ID**: 2504.15193
- **Source URL**: https://arxiv.org/abs/2504.15193
- **Reference count**: 30
- **Primary result**: Achieved weighted F1 score of 0.67±0.01 on 4-class eczema severity classification, outperforming ResNet-18 (0.44±0.16) and ViT-B (0.40±0.22)

## Executive Summary
This paper presents an automated approach for measuring eczema severity from images using limited annotated data. The method combines few-shot segmentation via SegGPT with self-supervised learning using DINO features for classification. Tested on in-the-wild eczema images, the approach demonstrates strong performance with limited training data, highlighting the potential of self-supervised learning for skin diagnosis applications where annotated datasets are scarce.

## Method Summary
The proposed method integrates in-context learning for segmentation with self-supervised learning for classification. SegGPT performs few-shot eczema region segmentation using reference images, followed by DINO feature extraction from the segmented regions. These features are then classified into 4 severity levels using a multilayer perceptron. The approach is specifically designed to address the challenge of limited annotated data in medical imaging, demonstrating effectiveness even when trained on only 20% of the available dataset.

## Key Results
- Achieved weighted F1 score of 0.67±0.01, outperforming finetuned ResNet-18 (0.44±0.16) and ViT-B (0.40±0.22)
- Maintained strong performance with limited training data (20% of dataset)
- Demonstrated effectiveness of self-supervised learning for skin diagnosis applications

## Why This Works (Mechanism)
The approach leverages the strengths of both few-shot segmentation and self-supervised learning. SegGPT's in-context learning capability allows effective segmentation with minimal annotated examples by using reference images. DINO's self-supervised features capture rich semantic information from the segmented regions without requiring extensive labeled data. This combination addresses the critical challenge of limited annotated medical images while maintaining high classification accuracy for eczema severity assessment.

## Foundational Learning
- **Few-shot segmentation**: Learning to segment objects from very few examples; needed because annotated medical images are scarce and expensive to obtain
- **In-context learning**: Ability of models like SegGPT to perform tasks using contextual examples rather than fine-tuning; needed to avoid resource-intensive training on limited data
- **Self-supervised learning**: Learning representations from unlabeled data; needed to leverage the large pool of unannotated eczema images
- **DINO features**: Self-supervised visual features that capture semantic information; needed for robust classification without extensive labeled data
- **MLP classification**: Simple feedforward network for final classification; needed for efficient mapping from learned features to severity classes

## Architecture Onboarding

**Component Map**: Image -> SegGPT (few-shot segmentation) -> DINO (feature extraction) -> MLP (classification) -> Severity score

**Critical Path**: The sequence from image input through SegGPT segmentation to DINO feature extraction and MLP classification represents the critical path for achieving the reported F1 score of 0.67±0.01

**Design Tradeoffs**: The method trades computational complexity of SegGPT and DINO for reduced annotation burden and improved generalization with limited data. This approach sacrifices some training efficiency for better performance with scarce labeled examples.

**Failure Signatures**: Poor segmentation from SegGPT leads to degraded features and lower classification accuracy. Insufficient quality or diversity in reference images for in-context learning can cause segmentation failures. The MLP may underperform if DINO features don't capture relevant semantic information for severity assessment.

**First Experiments**:
1. Test SegGPT segmentation quality with varying numbers of reference images
2. Evaluate DINO feature quality with different segmentation masks
3. Compare MLP performance with different numbers of hidden layers

## Open Questions the Paper Calls Out
None

## Limitations
- Relatively small dataset size restricts generalizability of results
- Single dataset evaluation without external or multi-center validation
- F1 score of 0.67±0.01 indicates significant room for improvement in classification accuracy
- SegGPT segmentation performance depends heavily on prompt engineering and reference image quality

## Confidence
- **Classification results**: Medium confidence due to limited dataset size and lack of external validation
- **Self-supervised learning approach**: High confidence in DINO feature effectiveness, tempered by small sample size
- **Few-shot segmentation**: Medium confidence as performance depends on prompt quality and reference image selection

## Next Checks
1. Evaluate the model on external eczema image datasets from multiple clinical centers to assess generalizability across different imaging conditions and patient populations
2. Perform ablation studies to quantify the individual contributions of SegGPT segmentation and DINO features to the overall classification performance
3. Test the method's robustness by reducing the number of training examples further and assessing performance degradation to determine the true few-shot capability