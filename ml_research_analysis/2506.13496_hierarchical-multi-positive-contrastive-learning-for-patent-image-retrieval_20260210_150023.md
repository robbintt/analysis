---
ver: rpa2
title: Hierarchical Multi-Positive Contrastive Learning for Patent Image Retrieval
arxiv_id: '2506.13496'
source_url: https://arxiv.org/abs/2506.13496
tags:
- patent
- hierarchical
- image
- learning
- retrieval
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of patent image retrieval, where
  current methods often neglect the hierarchical relationships defined by classification
  systems like Locarno International Classification (LIC). The authors propose a hierarchical
  multi-positive contrastive learning approach that leverages the LIC taxonomy to
  induce hierarchical relations in the retrieval process.
---

# Hierarchical Multi-Positive Contrastive Learning for Patent Image Retrieval

## Quick Facts
- **arXiv ID**: 2506.13496
- **Source URL**: https://arxiv.org/abs/2506.13496
- **Reference count**: 27
- **Primary result**: Hierarchical multi-positive contrastive learning improves patent image retrieval by leveraging LIC taxonomy with better results especially for low-parameter models.

## Executive Summary
This paper addresses the challenge of patent image retrieval by proposing a hierarchical multi-positive contrastive learning approach that leverages the Locarno International Classification (LIC) taxonomy. The method assigns multiple positive pairs to each patent image within a batch, with varying similarity scores based on hierarchical relationships. Experiments with various vision and multimodal models on the DeepPatent2 dataset demonstrate that the proposed method enhances retrieval results, particularly with low-parameter models that are computationally efficient and can be deployed on environments with limited hardware.

## Method Summary
The authors propose a hierarchical multi-positive contrastive learning approach that incorporates the Locarno International Classification (LIC) taxonomy into the retrieval process. Unlike conventional contrastive learning that treats all images from the same patent as equally similar, this method assigns varying similarity scores based on hierarchical relationships: Patent ID (same patent), Subclass (same subclass), and Main Class (same main class). The approach uses relevance scoring (s_p=1.0, s_s=0.35, s_m=0.2) to weight positive pairs differently, creating a more nuanced similarity measure. For multimodal CLIP models, a language supervision term is added to enhance the representation learning process. The method is evaluated on the DeepPatent2 dataset with various model architectures including ViT and ResNet variants, as well as CLIP models.

## Key Results
- The proposed method shows significant improvements across all hierarchical levels (Patent ID, Subclass, and Main Class) compared to conventional contrastive learning approaches
- Low-parameter models benefit particularly from the hierarchical approach, demonstrating improved retrieval performance while maintaining computational efficiency
- The method achieves better mAP and nDCG scores at all three hierarchical levels, with the most notable improvements observed in Subclass and Main Class retrieval

## Why This Works (Mechanism)
The hierarchical multi-positive contrastive learning approach works by incorporating the structured relationships inherent in patent classification systems into the learning process. By assigning varying similarity scores based on the Locarno International Classification taxonomy, the model learns to recognize not just exact matches but also related patents that share common features at different hierarchical levels. This creates a more nuanced embedding space where patents with similar functionality (same subclass or main class) are closer together, improving retrieval of related rather than just identical patents.

## Foundational Learning
- **Locarno International Classification (LIC) system**: Patent classification hierarchy needed to extract hierarchical relationships; quick check: verify LIC codes in DeepPatent2 metadata follow standard format
- **Contrastive learning with multiple positives**: Extends standard CL by having multiple positive pairs with different similarity weights; quick check: ensure relevance scores s_p > s_s > s_m are correctly implemented
- **Multimodal fusion with language supervision**: Combines visual and textual information for CLIP models; quick check: verify λ=0.2 weighting between visual and textual losses

## Architecture Onboarding

**Component Map**
DeepPatent2 dataset -> Data preprocessing (LIC parsing, augmentation) -> Hierarchical multi-positive contrastive loss -> Model training (ViT/ResNet/CLIP) -> Evaluation (mAP/nDCG at Patent ID/Subclass/Main Class levels)

**Critical Path**
Data preprocessing → Hierarchical loss computation → Model training → Evaluation at three hierarchical levels

**Design Tradeoffs**
- Hierarchical positives improve broader retrieval but may reduce exact match precision at Patent ID level
- Low-parameter models gain more relative improvement but start from lower baseline
- Language supervision adds complexity but enhances multimodal understanding

**Failure Signatures**
- mAP drops at Patent ID level while improving at Subclass/Main Class (expected trade-off)
- No improvement over baseline CL (likely batch composition lacks hierarchical diversity)
- Overfitting to hierarchical patterns (check if model ignores fine-grained Patent ID distinctions)

**Three First Experiments**
1. Implement hierarchical multi-positive contrastive loss with relevance scoring and verify that positives from same subclass/main class are assigned lower similarity than same patent images
2. Train ViT-Tiny with the hierarchical approach and compare mAP at Patent ID level against baseline CL
3. Test batch sampling strategy to ensure hierarchical diversity by examining LIC distribution in sampled batches

## Open Questions the Paper Calls Out
None

## Limitations
- Exact LIC code parsing logic from DeepPatent2 metadata is not detailed, which could affect hierarchical relationship extraction
- Early stopping criteria are vaguely described without specifying patience or metric thresholds
- Batch sampling strategy for ensuring hierarchical positives is not clearly defined, leaving uncertainty about how patents from same subclass/main class are included

## Confidence

**High confidence**: The core methodology of hierarchical multi-positive contrastive learning with relevance scoring based on LIC taxonomy; the experimental results showing improvements across all hierarchical levels for low-parameter models; the general training setup with specified hyperparameters and augmentation strategy.

**Medium confidence**: The exact impact of the language supervision term for CLIP models (λ=0.2 weighting); the comparative advantage of the proposed method over baseline contrastive learning; the specific computational efficiency gains mentioned for low-parameter models.

**Low confidence**: The precise early stopping mechanism and its effect on final model performance; the exact batch composition strategy and how it ensures hierarchical diversity; the interpretation of trade-offs between Patent ID and higher-level classification accuracy.

## Next Checks
1. **Reproduce the hierarchical loss function**: Implement Equation 4 with the relevance scoring function h_ij using the specified similarity scores (s_p=1.0, s_s=0.35, s_m=0.2) and verify that positives from same subclass/main class are assigned lower similarity than same patent images during training.

2. **Validate batch composition strategy**: Examine the DeepPatent2 dataset to confirm that sampled batches of 64 patents contain multiple patents from the same subclasses and main classes, and verify that the hierarchical positives are correctly identified based on the parsed LIC codes.

3. **Test early stopping implementation**: Implement early stopping based on validation mAP at Patent ID level with a reasonable patience parameter (e.g., 3-5 epochs) and confirm that the reported 20-epoch training duration aligns with when validation performance plateaus.