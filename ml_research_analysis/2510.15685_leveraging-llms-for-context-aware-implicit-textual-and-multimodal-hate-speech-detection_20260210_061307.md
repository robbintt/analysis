---
ver: rpa2
title: Leveraging LLMs for Context-Aware Implicit Textual and Multimodal Hate Speech
  Detection
arxiv_id: '2510.15685'
source_url: https://arxiv.org/abs/2510.15685
tags:
- context
- hate
- speech
- text
- embed
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study investigates the use of Large Language Models (LLMs)\
  \ as dynamic knowledge bases to generate background context for Hate Speech Detection\
  \ (HSD). Two context generation strategies\u2014named entities and full-text prompting\u2014\
  are evaluated alongside four incorporation methods: text concatenation, embedding\
  \ concatenation, hierarchical transformer-based fusion, and LLM-driven text enhancement."
---

# Leveraging LLMs for Context-Aware Implicit Textual and Multimodal Hate Speech Detection

## Quick Facts
- arXiv ID: 2510.15685
- Source URL: https://arxiv.org/abs/2510.15685
- Reference count: 0
- Key outcome: LLM-generated context improves hate speech detection by up to 6 F1 points, with embedding-level concatenation being the most effective incorporation method

## Executive Summary
This study investigates using Large Language Models (LLMs) as dynamic knowledge bases to generate background context for hate speech detection. The authors evaluate two context generation strategies—named entities and full-text prompting—and four incorporation methods across textual and multimodal datasets. Results demonstrate that LLM-generated context significantly improves detection performance, with embedding-level concatenation consistently outperforming more complex integration approaches. The research shows that context drawn from full input rather than entities, and kept modular rather than merged, yields the best results.

## Method Summary
The study uses Gemini 2.0 Flash to generate background context for hate speech detection tasks. Two context generation approaches are tested: named entity extraction using a BERT-based NER model, and full-text prompting. For multimodal data, Gemini is used to re-OCR meme text and generate image descriptions before context generation. Four incorporation methods are evaluated: text concatenation, embedding concatenation, hierarchical transformer-based fusion, and LLM-driven text enhancement. The best-performing approach combines separate SBERT embeddings of the original input and generated context via concatenation, followed by classification using a 3-layer MLP.

## Key Results
- Embedding-level concatenation outperformed all other incorporation methods, achieving up to 6 F1 point improvements on multimodal data
- Full-text prompting consistently outperformed entity-based context generation across both datasets
- More complex integration strategies (hierarchical fusion, text enhancement) sometimes degraded performance compared to simpler approaches
- Context generation improved both macro F1 and positive class F1 metrics significantly

## Why This Works (Mechanism)
The LLM-generated context provides additional semantic information that helps the classifier disambiguate implicit hate speech and understand nuanced references that would otherwise be missed. By generating context based on the full input rather than just extracted entities, the system captures broader semantic relationships and background knowledge that illuminate the intended meaning of potentially ambiguous content.

## Foundational Learning
- **LLM Context Generation**: Understanding how to prompt LLMs for specific information extraction tasks - needed to generate relevant background knowledge; quick check: verify consistency of generated contexts across multiple runs
- **Embedding Concatenation**: Combining separate vector representations before classification - needed for the most effective incorporation method; quick check: ensure both embeddings have identical dimensionality before concatenation
- **Hate Speech Detection Metrics**: Macro F1 and positive class F1 evaluation - needed to assess performance on imbalanced hate speech datasets; quick check: verify class distribution matches paper specifications
- **Multimodal Preprocessing**: Combining OCR-extracted text with image descriptions - needed for meme classification tasks; quick check: validate Gemini's OCR accuracy on sample memes
- **NER Entity Extraction**: Identifying key entities for context generation - needed for the entity-based approach baseline; quick check: verify entity extraction coverage on sample hate speech posts

## Architecture Onboarding

**Component Map:** Input Text/Meme -> Gemini Context Generation -> SBERT Embeddings -> MLP Classifier -> Output Prediction

**Critical Path:** Context Generation → Embedding Concatenation → MLP Classification → Evaluation

**Design Tradeoffs:**
- Simple concatenation vs. complex hierarchical fusion: simpler approaches performed better
- Entity-based vs. full-text prompting: full-text consistently superior
- Separate vs. joint embeddings: separate embeddings with concatenation proved most effective

**Failure Signatures:**
- High false positive rate on benign posts with polarizing keywords suggests semantic drift
- Poor performance with zero-vector contexts indicates sensitivity to context generation quality
- Variance across runs may indicate LLM API inconsistency

**First Experiments:**
1. Implement basic text concatenation approach as a baseline to verify dataset loading and preprocessing
2. Test embedding concatenation with Gemini-generated context to confirm the primary finding
3. Compare entity-based vs. full-text context generation to validate the superiority of full-text prompting

## Open Questions the Paper Calls Out
None

## Limitations
- LLM generation parameters (temperature, top-p) are not specified, affecting reproducibility
- Context-Embed hierarchical fusion method lacks precise architectural specifications
- Results are demonstrated on only two specific datasets, limiting broader generalization claims

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| LLM-generated context improves hate speech detection performance | High |
| Embedding-level concatenation is superior to other incorporation methods | Medium |
| Full-text prompting outperforms entity-based context generation | Medium |

## Next Checks

1. **Reproducibility Test:** Implement zero-shot context generation with Gemini 2.0 Flash using specified prompts and verify consistency of generated contexts across multiple runs with different random seeds

2. **Generalization Test:** Apply the best-performing Embed & Concat method to an additional hate speech dataset (e.g., HateXplain or another multimodal dataset) to assess performance outside the studied domains

3. **Robustness Test:** Systematically evaluate performance degradation when context generation fails (e.g., when NER extracts no entities or LLM generation returns empty/erroneous context) to understand the method's reliability under adverse conditions