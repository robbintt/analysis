---
ver: rpa2
title: Approximate constrained stochastic optimal control via parameterized input
  inference
arxiv_id: '2509.02922'
source_url: https://arxiv.org/abs/2509.02922
tags:
- control
- cost
- algorithm
- optimal
- state
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses stochastic optimal control (SOC) problems
  with state, control, and structural constraints. The authors propose a parameterized
  input inference for control (PIIC) algorithm based on Expectation-Maximization (EM)
  to generate state-feedback controllers.
---

# Approximate constrained stochastic optimal control via parameterized input inference

## Quick Facts
- arXiv ID: 2509.02922
- Source URL: https://arxiv.org/abs/2509.02922
- Authors: Shahbaz P Qadri Syed; He Bai
- Reference count: 24
- Primary result: PIIC algorithm for constrained SOC using barrier functions and EM-based inference achieves superior performance over ILQG baseline

## Executive Summary
This paper addresses stochastic optimal control problems with state, control, and structural constraints by proposing a parameterized input inference for control (PIIC) algorithm based on Expectation-Maximization. The key innovation is using barrier functions to handle inequality constraints while decomposing the control parameter space to enforce structural constraints on distributed controllers. The method treats SOC as an inference problem on a probabilistic graphical model, where control parameters are inferred via EM iterations.

The approach demonstrates superior performance compared to ILQG baselines across multiple benchmark problems including unicycle obstacle avoidance, formation control, and quadcopter navigation. The algorithm guarantees convergence to local optima and encompasses existing algorithms like LQR and I2C as special cases, making it a flexible framework for constrained stochastic control.

## Method Summary
The PIIC algorithm solves stochastic optimal control problems by framing them as probabilistic inference problems on graphical models. It uses Expectation-Maximization to iteratively smooth state-control trajectories and update control parameters. The method employs barrier functions to encode inequality constraints, with the parameter γ controlling the trade-off between constraint satisfaction and cost minimization. For structural constraints on distributed controllers, the algorithm decomposes the parameter space into non-zero subsets corresponding to each controller's authority. The expectation step uses factor graph optimization to smooth trajectories, while the maximization step updates parameters on the appropriate subsets to preserve structure. This decomposition enables the algorithm to handle complex distributed control architectures while maintaining convergence guarantees to local optima.

## Key Results
- PIIC achieves superior performance compared to ILQG baseline with reduced mean cost and variance
- Factor graph optimization smoothing outperforms unscented smoothing for trajectory smoothing
- Barrier function parameter γ significantly affects constraint satisfaction and must be tuned
- Distributed controller structures trade off between communication overhead and performance
- Nonlinear basis functions enable adaptation to dynamic environment changes

## Why This Works (Mechanism)
The PIIC algorithm works by transforming the constrained stochastic optimal control problem into a probabilistic inference framework. The expectation-maximization approach alternates between smoothing trajectories given current parameters (E-step) and updating parameters to maximize the expected log-likelihood (M-step). Barrier functions convert inequality constraints into penalty terms that become infinite at constraint boundaries, effectively preventing constraint violations. The decomposition of the parameter space into non-zero subsets allows the algorithm to enforce structural constraints on distributed controllers by only updating parameters relevant to each controller's authority. This combination of probabilistic inference, barrier-based constraint handling, and parameter space decomposition enables efficient solution of complex constrained control problems.

## Foundational Learning
- **Expectation-Maximization (EM)**: Iterative algorithm for maximum likelihood estimation with latent variables; needed to alternately smooth trajectories and update parameters; quick check: verify monotonic increase in expected log-likelihood
- **Barrier Functions**: Penalty functions that approach infinity at constraint boundaries; needed to convert inequality constraints into unconstrained optimization; quick check: verify constraint satisfaction improves as γ increases
- **Factor Graph Optimization**: Graphical model representation for efficient inference; needed for trajectory smoothing in the E-step; quick check: compare smoothing accuracy with different noise models
- **Parameter Space Decomposition**: Partitioning control parameters into subsets; needed to enforce structural constraints on distributed controllers; quick check: verify non-zero parameter subsets remain consistent across iterations
- **Probabilistic Graphical Models**: Framework representing dependencies between random variables; needed to cast SOC as inference problem; quick check: confirm graphical model correctly encodes system dynamics and constraints
- **Trajectory Smoothing**: Post-processing of noisy state estimates; needed to improve trajectory estimates before parameter updates; quick check: measure reduction in smoothing error compared to raw estimates

## Architecture Onboarding

**Component Map**: Control problem specification -> Barrier function encoding -> Graphical model construction -> EM iterations (E-step: smoothing, M-step: parameter update) -> Controller output

**Critical Path**: Problem formulation → Barrier function design → Parameter space decomposition → EM algorithm execution → Constraint satisfaction verification

**Design Tradeoffs**: Centralized vs distributed controllers (communication overhead vs performance), barrier function parameter γ (constraint satisfaction vs cost), smoothing method selection (computational complexity vs accuracy), basis function selection (expressiveness vs parameter count)

**Failure Signatures**: Constraint violations (insufficient γ), poor convergence (bad initialization), structural constraint violations (incorrect parameter decomposition), suboptimal performance (inadequate basis functions)

**Three First Experiments**:
1. Validate barrier function effectiveness by varying γ on a simple constrained problem
2. Compare centralized vs distributed controller performance on formation control
3. Test convergence sensitivity to initialization on unicycle obstacle avoidance

## Open Questions the Paper Calls Out
None

## Limitations
- Requires explicit barrier function design which may not be straightforward for complex constraints
- Convergence guarantees are limited to local optima with quality dependent on initialization
- Parameter space decomposition may not scale well to high-dimensional or complex constraint structures
- Assumes accurate noise models for factor graph optimization which may struggle with non-Gaussian disturbances
- Distributed controller formulation requires known graph structure a priori

## Confidence
- Algorithmic framework: High (principled EM-based formulation with clear convergence properties)
- Constraint handling via barrier functions: Medium (empirical effectiveness demonstrated but theoretical guarantees limited)
- Scalability claims: Low (limited complexity of benchmark problems, lack of systematic scaling analysis)

## Next Checks
1. Test algorithm on problems with unknown or time-varying graph structures to assess robustness of distributed controller formulation
2. Conduct systematic experiments varying barrier function parameter γ across multiple problem classes to quantify trade-off between constraint satisfaction and cost optimization
3. Evaluate performance degradation under model uncertainty and non-Gaussian noise conditions to establish practical robustness limits