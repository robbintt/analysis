---
ver: rpa2
title: Robust Polyp Detection and Diagnosis through Compositional Prompt-Guided Diffusion
  Models
arxiv_id: '2502.17951'
source_url: https://arxiv.org/abs/2502.17951
tags:
- polyp
- segmentation
- diffusion
- prompts
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the challenge of generating diverse and clinically\
  \ accurate synthetic polyp images for improving deep learning models in colorectal\
  \ cancer detection and diagnosis. The authors propose a Progressive Spectrum Diffusion\
  \ Model (PSDM) that integrates diverse clinical annotations\u2014such as segmentation\
  \ masks, bounding boxes, and colonoscopy reports\u2014into compositional prompts,\
  \ enabling the generation of synthetic polyp images with both spatial structures\
  \ and fine clinical details."
---

# Robust Polyp Detection and Diagnosis through Compositional Prompt-Guided Diffusion Models

## Quick Facts
- arXiv ID: 2502.17951
- Source URL: https://arxiv.org/abs/2502.17951
- Authors: Jia Yu; Yan Zhu; Peiyao Fu; Tianyi Chen; Junbo Huang; Quanlin Li; Pinghong Zhou; Zhihua Wang; Fei Wu; Shuo Wang; Xian Yang
- Reference count: 40
- Primary result: PSDM increases F1 score by 2.12% and mean average precision by 3.09% on PolypGen dataset

## Executive Summary
This paper addresses the challenge of generating diverse and clinically accurate synthetic polyp images for improving deep learning models in colorectal cancer detection and diagnosis. The authors propose a Progressive Spectrum Diffusion Model (PSDM) that integrates diverse clinical annotations—such as segmentation masks, bounding boxes, and colonoscopy reports—into compositional prompts, enabling the generation of synthetic polyp images with both spatial structures and fine clinical details. PSDM significantly improves polyp detection, classification, and segmentation performance, increasing the F1 score by 2.12% and mean average precision by 3.09% on the PolypGen dataset. The method demonstrates superior performance in out-of-distribution scenarios and enhanced generalization across diverse clinical environments.

## Method Summary
PSDM fine-tunes Stable Diffusion 1.5 using DDIM sampling (T=200, guidance scale 7.5) to generate synthetic polyp images from compositional prompts. The model integrates segmentation masks, bounding boxes, and textual descriptions through a prompt spectrum that organizes annotations into coarse (spatial layout) and fine (semantic details) components. During training, a frequency-based progressive denoising schedule weights coarse prompts early and fine prompts later in the diffusion process. The model employs continual learning with prompt replay to avoid catastrophic forgetting when learning multiple annotation types. Generated synthetic images are used to pretrain downstream polyp detection, segmentation, and classification models before fine-tuning on real data.

## Key Results
- PSDM_M (mask+text) achieves FID of 11.6 on PolypGen vs 23.7 for mask-only PSDM_S
- Out-of-distribution performance improves: mDice increases from 42.13% to 45.25% on PolypGen C4
- Class imbalance mitigation: malignant polyp recall improves from 0.22 to 0.56 with synthetic augmentation
- Detection performance: mean average precision increases by 3.09% on PolypGen dataset

## Why This Works (Mechanism)

### Mechanism 1: Compositional Prompt Integration Transforms Multi-Modal Annotations into Controllable Generation
- Core assumption: Different annotation modalities provide complementary information that, when combined, yield richer synthetic samples than any single modality alone
- Evidence anchors: [abstract] "transforms them into compositional prompts...organized into coarse and fine components, allowing the model to capture both broad spatial structures and fine details"
- Break condition: If annotation types are highly redundant (e.g., mask already encodes all texture information), compositional prompts may not add diversity over single-prompt baselines

### Mechanism 2: Frequency-Based Progressive Denoising Aligns Prompt Weighting with Diffusion Timesteps
- Core assumption: Low-frequency image features are determined early in diffusion; high-frequency details emerge later, so prompt influence should follow this natural progression
- Evidence anchors: [Section III-C, Table VII] Linear (mask→text) schedule achieves best balance (LPIPS=0.5953, 1-SSIM=0.9260), outperforming reversed schedule
- Break condition: If text prompts contain strong spatial cues (e.g., "polyp in upper left quadrant"), the coarse/fine distinction blurs and the frequency-based weighting may conflict with prompt content

### Mechanism 3: Synthetic Pretraining with Balanced Class Distribution Improves Downstream Robustness
- Core assumption: Generated synthetic images are sufficiently realistic and diverse to serve as effective pretraining data without introducing harmful artifacts or domain shift
- Evidence anchors: [abstract] "PSDM increases the F1 score by 2.12% and the mean average precision by 3.09% on the PolypGen dataset"
- Break condition: If synthetic-real domain gap is large, pretraining on synthetic data may degrade in-distribution performance (paper notes mDice drop on Kvasir from 93.09% to 92.01% in Table III)

## Foundational Learning

- **Latent Diffusion Models (LDMs)**
  - Why needed here: PSDM builds on Stable Diffusion (an LDM). Understanding that diffusion operates in compressed latent space—not pixel space—is essential for grasping the computational efficiency and the role of encoder/decoder
  - Quick check question: Can you explain why operating in latent space reduces memory compared to pixel-space diffusion?

- **Classifier-Free Guidance**
  - Why needed here: The paper uses classifier-free guidance (Equation 4) to amplify prompt adherence. Understanding how unconditional and conditional predictions are combined is critical for tuning guidance scale
  - Quick check question: What happens to generated image diversity if guidance scale s is set very high (e.g., s=15)?

- **Catastrophic Forgetting in Continual Learning**
  - Why needed here: PSDM trains sequentially on different annotation modalities. Without the prompt replay mechanism, the model would lose ability to generate from earlier prompts
  - Quick check question: Why does sequential training on annotation type A then type B cause performance degradation on type A without mitigation?

## Architecture Onboarding

- **Component map**: Raw annotations → Categorize (coarse/fine) → Encode (mask encoder, CLIP) → Compose prompts → Progressive weighting (λ_t) → Cross-attention → U-Net denoising → Decoder → Image

- **Critical path**:
  1. Parse raw annotations → categorize as coarse or fine
  2. Encode each annotation type into prompt embeddings
  3. During training: sample timestep t, combine prompts via λ_t, predict noise, compute loss with replay buffer
  4. During sampling: run DDIM denoising with progressive λ_t weighting (coarse→fine)
  5. Decode final latent to image

- **Design tradeoffs**:
  - **PSDM_S vs. PSDM_M**: Single-condition (mask-only) is simpler but less diverse; multi-condition (mask+text) improves diversity but requires paired annotations and more complex training
  - **λ-schedule choice**: Linear schedule best for quality-diversity balance; cosine provides smoother transition; stage (abrupt switch) is simpler but underperforms
  - **Synthetic/real ratio**: Paper notes inappropriate mixing ratios degrade performance; pretrain-on-synthetic then fine-tune-on-real is safer than joint training

- **Failure signatures**:
  - **Indiscriminate colorization**: Under weak prompt support (e.g., "yellow polyp"), model colors entire scene incorrectly (Fig. 8)
  - **In-distribution performance drop**: Synthetic augmentation may slightly reduce accuracy on training distribution data (Table III: Kvasir mDice 93.09%→92.01%)
  - **Rare class generation failure**: Vague or underrepresented prompts produce low-quality outputs (Fig. 8 examples)

- **First 3 experiments**:
  1. **Reproduce ablation on λ-schedules**: Train PSDM with linear, cosine, and stage schedules on a subset of PolypGen; verify linear (mask→text) achieves best LPIPS/SSIM tradeoff as reported in Table VII
  2. **Validate compositional vs. single-prompt**: Compare FID and downstream segmentation mDice for PSDM_S (mask-only) vs. PSDM_M (mask+text) using the same random seed and sample count
  3. **Test class imbalance mitigation**: Replicate the malignant/benign classification experiment (Section IV-B2) with and without synthetic augmentation; confirm recall improvement on minority class matches paper's 0.22→0.56 gain

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can synthetic data be integrated into clinical workflows to ensure interpretability, reliability, and utility for decision-making?
- Basis in paper: [explicit] The Discussion section identifies integrating synthetic data into clinical workflows as a "promising yet challenging frontier" requiring assurance of clinical interpretability and reliability
- Why unresolved: The current study focuses on technical performance metrics (FID, mAP) rather than the downstream utility and trustworthiness in actual clinical decision-making contexts
- What evidence would resolve it: A study demonstrating that AI-assisted diagnosis using synthetic augmentation improves clinician diagnostic accuracy or confidence in a live clinical setting

### Open Question 2
- Question: Can dynamic augmentation strategies mitigate the trade-off between in-distribution performance degradation and out-of-distribution (OOD) generalization?
- Basis in paper: [explicit] The authors note a "slight decrease in training-set performance" (e.g., Polyp-CASCADE on Kvasir) and explicitly call for "dynamic strategies to balance domain-specific performance with cross-institutional generalization"
- Why unresolved: While PSDM improves OOD robustness, the dilution of the source domain distribution causes minor performance drops on familiar data, a standard dilemma in domain generalization
- What evidence would resolve it: An adaptive weighting mechanism that maintains or improves baseline in-distribution metrics (mDice) on Kvasir while preserving the OOD gains on PolypGen

### Open Question 3
- Question: How can diffusion models better handle underrepresented or rare clinical prompts (e.g., "yellow polyp") to prevent indiscriminate colorization of the entire scene?
- Basis in paper: [inferred] The Discussion analyzes failure samples (Fig. 8), noting that weak conditional cues for rare colors lead to global colorization errors because the model fails to disentangle foreground lesions from background mucosa
- Why unresolved: The model relies on co-occurrence statistics; when specific attribute combinations are scarce, the model lacks a strong prior to localize the attribute correctly
- What evidence would resolve it: Successful generation of images with rare attributes where the color is strictly localized to the polyp, validated by expert visual assessment or segmentation consistency

## Limitations

- **Implementation Details Missing**: Critical hyperparameters for the mask encoder, replay buffer configuration, and prompt encoding templates are not provided
- **Domain Gap Analysis**: Limited discussion of potential synthetic-real domain shift effects, particularly for in-distribution performance degradation
- **Generalization Scope**: Results primarily validated on polyp datasets; broader applicability to other medical imaging domains remains untested

## Confidence

- **High confidence**: The core methodology of compositional prompt integration and frequency-based progressive denoising is well-specified and technically sound. The reported performance improvements on PolypGen and OOD datasets appear reproducible
- **Medium confidence**: The downstream evaluation methodology is clear, but the paper lacks detailed analysis of synthetic-real domain gaps and optimal augmentation ratios. The class imbalance mitigation results are promising but could benefit from more extensive validation across different imbalance scenarios
- **Low confidence**: The continual learning mechanism (prompt replay) lacks implementation details regarding buffer size, sampling strategy, and checkpointing frequency. The exact prompt templates for coarse/fine categorization and the mask encoder architecture are underspecified

## Next Checks

1. **Replicate ablation on λ-schedules**: Train PSDM with linear, cosine, and stage schedules on a subset of PolypGen to verify the linear mask→text schedule achieves the best LPIPS/SSIM tradeoff as reported in Table VII
2. **Validate compositional vs. single-prompt generation**: Compare FID scores and downstream segmentation mDice for PSDM_S (mask-only) versus PSDM_M (mask+text) using identical seeds and sample counts to confirm diversity improvements
3. **Test class imbalance mitigation**: Replicate the malignant/benign classification experiment (Section IV-B2) with and without synthetic augmentation to confirm the reported recall improvement from 0.22 to 0.56 on the minority class