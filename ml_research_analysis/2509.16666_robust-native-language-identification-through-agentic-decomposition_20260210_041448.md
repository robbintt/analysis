---
ver: rpa2
title: Robust Native Language Identification through Agentic Decomposition
arxiv_id: '2509.16666'
source_url: https://arxiv.org/abs/2509.16666
tags:
- language
- text
- agentic
- linguistic
- such
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of superficial bias in native language
  identification (NLI) by large language models (LLMs), which often rely on contextual
  clues like names and stereotypes rather than linguistic patterns. To solve this,
  the authors propose an agentic NLI pipeline inspired by forensic linguistics, where
  specialized agents independently analyze distinct linguistic features (syntax, lexical,
  idiomatic) before a coordinator synthesizes the evidence to make the final prediction.
---

# Robust Native Language Identification through Agentic Decomposition
## Quick Facts
- arXiv ID: 2509.16666
- Source URL: https://arxiv.org/abs/2509.16666
- Reference count: 26
- Primary result: Agentic NLI pipeline achieves more robust and consistent predictions against contextual bias compared to standard prompting, with improved stability but reduced peak accuracy

## Executive Summary
This paper addresses the challenge of superficial bias in native language identification (NLI) by large language models (LLMs), which often rely on contextual clues like names and stereotypes rather than genuine linguistic patterns. The authors propose an agentic NLI pipeline inspired by forensic linguistics, where specialized agents independently analyze distinct linguistic features (syntax, lexical, idiomatic) before a coordinator synthesizes the evidence to make the final prediction. This structured approach forces decisions to be grounded in linguistic evidence rather than superficial hints. On two benchmark datasets, the agentic method significantly improved robustness and consistency against misleading contextual clues compared to standard prompting, though with a trade-off in peak accuracy.

## Method Summary
The proposed agentic NLI pipeline decomposes the task into three specialized components: syntax analysis, lexical analysis, and idiomatic expression analysis. Each agent independently evaluates its respective linguistic feature from the input text, providing evidence-based assessments. A coordinator agent then synthesizes these independent analyses to make the final prediction. This forensic linguistics-inspired approach contrasts with standard prompting methods where LLMs directly predict native language based on holistic text analysis. The pipeline is implemented using GPT-4o-mini and evaluated on TOEFL4 and JK13 benchmark datasets through controlled perturbation experiments that introduce misleading contextual clues like names and cultural references.

## Key Results
- On TOEFL4 dataset: Agentic approach achieved 73.7% macro-F1 versus 96.5% for direct prompting
- Agentic method showed significantly lower volatility (2.5 vs 29.1 standard deviation) across experimental conditions
- On JK13 dataset: Agentic approach achieved 73.7% macro-F1 versus 88.8% for direct prompting with improved consistency

## Why This Works (Mechanism)
The agentic decomposition approach works by forcing the LLM to ground its predictions in specific linguistic evidence rather than relying on superficial contextual cues. By breaking down NLI into specialized analyses of syntax, lexical choices, and idiomatic expressions, the system prevents the model from making snap judgments based on names, cultural references, or stereotypes. Each agent must provide concrete linguistic evidence to support its assessment, creating a chain of reasoning that is more transparent and resistant to misleading information. The coordinator's role in synthesizing evidence from multiple independent analyses further reduces the impact of any single biased cue.

## Foundational Learning
**Forensic linguistics principles**: Understanding how language patterns reveal speaker background; needed to design evidence-based decomposition; quick check: verify each agent focuses on specific linguistic markers rather than holistic assessment
**Agent-based decomposition**: Breaking complex tasks into specialized sub-agents; needed to prevent holistic bias; quick check: confirm each agent operates independently before coordination
**Linguistic feature analysis**: Syntax, lexical, and idiomatic patterns; needed for targeted linguistic evidence; quick check: validate agents identify distinct feature types
**Evidence-based reasoning**: Requiring concrete support for predictions; needed to combat superficial cues; quick check: ensure each agent provides specific linguistic examples
**Coordinator synthesis**: Combining independent analyses; needed for final robust prediction; quick check: verify coordinator weighs evidence rather than averaging outputs

## Architecture Onboarding
**Component map**: Input text -> Syntax Agent -> Lexical Agent -> Idiomatic Agent -> Coordinator -> Final Prediction
**Critical path**: Text decomposition → Independent agent analysis → Evidence collection → Coordinator synthesis → Output prediction
**Design tradeoffs**: The approach trades peak accuracy (96.5% → 73.7% macro-F1) for robustness and consistency, accepting lower maximum performance for more stable results across varied conditions
**Failure signatures**: When linguistic features are ambiguous or when all agents fail to find strong evidence; manifests as inconsistent predictions or reliance on weak linguistic cues
**First experiments**: 1) Baseline comparison with direct prompting on unperturbed data, 2) Controlled perturbation tests with name replacements, 3) Idiomatic expression analysis accuracy validation

## Open Questions the Paper Calls Out
None

## Limitations
- The agentic approach sacrifices peak accuracy for robustness, showing significant performance gap (73.7% vs 96.5% macro-F1) compared to standard prompting
- Experimental validation relies on relatively small benchmark datasets (TOEFL4 and JK13) with limited linguistic diversity
- Evaluation focuses primarily on macro-F1 scores, potentially overlooking other relevant performance metrics
- The approach may not capture real-world complexity where multiple confounding factors interact simultaneously

## Confidence
- Robustness claims: High confidence (consistent performance across perturbation conditions, qualitative alignment with forensic principles)
- Practical utility claims: Medium-Low confidence (limited external validation, acknowledged trade-off with baseline performance)
- Generalizability: Medium confidence (small dataset size, controlled experimental conditions)

## Next Checks
1. Test the agentic approach on larger, more diverse NLI datasets with varied linguistic backgrounds to assess generalizability
2. Conduct ablation studies to determine which specific decomposition components contribute most to robustness gains
3. Implement real-world deployment trials where the system encounters naturally occurring contextual confounders rather than synthetic perturbations