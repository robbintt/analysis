---
ver: rpa2
title: 'Circuit Insights: Towards Interpretability Beyond Activations'
arxiv_id: '2510.14936'
source_url: https://arxiv.org/abs/2510.14936
tags:
- feature
- tokens
- features
- descriptions
- activations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the challenge of automated interpretability\
  \ in neural networks, particularly the limitations of existing methods that rely\
  \ on manual inspection, are restricted to toy tasks, or depend heavily on external\
  \ large language models (LLMs) and dataset quality. The authors propose two complementary\
  \ methods\u2014WeightLens and CircuitLens\u2014to overcome these limitations."
---

# Circuit Insights: Towards Interpretability Beyond Activations

## Quick Facts
- **arXiv ID:** 2510.14936
- **Source URL:** https://arxiv.org/abs/2510.14936
- **Reference count:** 29
- **Primary result:** Two complementary methods—WeightLens and CircuitLens—overcome limitations of existing interpretability methods by interpreting features directly from weights and capturing circuit-level dynamics, achieving robust interpretability without heavy reliance on external LLMs or large datasets.

## Executive Summary
This paper addresses the challenge of automated interpretability in neural networks, particularly the limitations of existing methods that rely on manual inspection, are restricted to toy tasks, or depend heavily on external large language models (LLMs) and dataset quality. The authors propose two complementary methods—WeightLens and CircuitLens—to overcome these limitations. WeightLens interprets model features directly from learned weights, eliminating the need for explainer models or datasets, and matches or exceeds the performance of existing methods on context-independent features. CircuitLens captures how feature activations arise from interactions between components, revealing circuit-level dynamics that activation-only approaches cannot identify. Together, these methods enhance interpretability robustness and enable scalable mechanistic analysis of circuits while maintaining efficiency. Evaluations on models like Gemma-2-2b and GPT-2 show that WeightLens performs on par with or better than activation-based methods in clarity and responsiveness, while CircuitLens resolves polysemanticity through circuit-based clustering, improving interpretability for context-dependent features. The approach reduces dependence on large datasets and external LLMs, making automated interpretability more practical for real-world applications.

## Method Summary
The authors propose two complementary methods for automated feature interpretability in neural networks. WeightLens interprets features directly from transcoder weights by projecting encoder vectors through embedding matrices and decoder vectors through unembedding matrices to identify which tokens a feature responds to and promotes, using statistical outlier detection via z-scores. CircuitLens captures how feature activations arise from interactions between components by tracing attributions through attention heads and Jacobians, revealing circuit-level dynamics that raw activation values obscure. The approach handles polysemanticity by clustering inputs based on shared circuit contributors (features + attention head pairs) rather than semantic embeddings, then interpreting each cluster separately and merging descriptions. The methods are evaluated using the FADE framework metrics: Clarity, Responsiveness, Purity, and Faithfulness, demonstrating competitive performance while reducing dependence on external resources.

## Key Results
- WeightLens matches or exceeds existing activation-based methods on context-independent features without requiring datasets or explainer LLMs
- CircuitLens improves Purity scores by 2.5x over activation-based methods for polysemantic features through circuit-based clustering
- The approach achieves robust interpretability across multiple models (Gemma-2-2b, GPT-2, Llama-3.2-1B) while maintaining efficiency
- WeightLens successfully interprets 25.4%-58.8% of features directly from weights, with remaining context-dependent features handled by CircuitLens

## Why This Works (Mechanism)

### Mechanism 1: Weight-Based Feature Interpretation via Transcoder Weights
Direct analysis of transcoder weights can produce interpretable feature descriptions without requiring dataset samples or explainer LLMs. The mechanism projects encoder vectors through embedding matrices and decoder vectors through unembedding matrices to identify which tokens a feature responds to and promotes, using statistical outlier detection via z-scores to filter noise. This works because transcoder architecture cleanly separates feature activations into input-dependent scalars and fixed input-invariant connectivity weights. The core assumption is that input-invariant weight connections indicate meaningful structural relationships when their magnitude significantly exceeds other connections. This fails for context-dependent features where activation depends on surrounding context rather than specific tokens, limiting applicability to 25.4%-58.8% of features across models.

### Mechanism 2: Circuit-Based Attribution for Context-Dependent Features
Attribution through attention heads and Jacobian-weighted pathways reveals input patterns that raw activations obscure. The mechanism traces how previous tokens contribute to feature activations via attention head projections, combining attention scores with feature-to-head-output projections. By masking inputs to retain only high-contribution tokens, it isolates interpretable patterns like detecting features that respond to "definite references" such as "the," "this," "that." The core assumption is that sparse activations ensure each input has few significant contributors, making Jaccard-based clustering meaningful. This approach is computationally expensive, requiring forward+backward passes per generated token for output analysis, and quality depends heavily on dataset sampling strategy.

### Mechanism 3: Polysemanticity Resolution via Circuit-Based Clustering
Features responding to multiple concepts can be disentangled by clustering inputs based on shared circuit contributors (features + attention head pairs) rather than just semantic embeddings. For each activating input, the method collects contributing elements via Jacobian-weighted transcoder features and attention head contributions, applies frequency filtering with a threshold, computes Jaccard similarity, then clusters with DBSCAN. Each cluster is interpreted separately, then merged into a unified description. The core assumption is that features appearing in less than the frequency threshold fraction of inputs are noise rather than consistent circuit behavior. This requires careful tuning of DBSCAN hyperparameters, and the paper acknowledges that more careful hyperparameter tuning could yield more generalizable results.

## Foundational Learning

- **Transcoders vs. Sparse Autoencoders (SAEs):** The entire approach depends on transcoder properties (clean input-invariant/input-dependent separation). SAEs reconstruct activations without structural separation. *Quick check:* Can you explain why transcoders enable weight-based attribution while SAEs do not?

- **Jacobian in Attribution:** CircuitLens incorporates Jacobians to account for non-linearities (attention, normalization) when tracing contributions across layers. *Quick check:* Why does treating nonlinearities as constants improve attribution compared to ignoring them entirely?

- **z-Score Outlier Detection:** WeightLens identifies meaningful token-feature connections via statistical outlier detection, not raw magnitude thresholds. *Quick check:* Why is z-score filtering preferred over top-k selection for identifying feature-relevant tokens?

## Architecture Onboarding

- **Component map:** WeightLens: encoder/decoder weight projections → embedding/unembedding matrices → z-score outlier selection → token validation via forward pass → lemmatization postprocessing. CircuitLens: Jacobian-weighted transcoder features + attention head contributions → frequency filtering → Jaccard similarity matrix → DBSCAN clustering → LLM-based cluster interpretation → description merging.

- **Critical path:** WeightLens for context-independent features (early/late layers, 25-59% of features) → CircuitLens for context-dependent features (middle layers, polysemantic features) → Combine both for robust descriptions.

- **Design tradeoffs:** WeightLens is fast (no forward passes per sample, no LLM required) but limited to token-based features. CircuitLens handles context-dependence but requires dataset sampling (24M+ tokens) and explainer LLM (GPT-4o-mini). Sampling strategy: inverse-frequency quantile sampling (α=0.9, B=20 bins) vs. top-percentile sampling (larger dataset, higher clarity).

- **Failure signatures:** Low validated feature percentage indicates high context-dependence (e.g., Layer 12 in Gemma-2-2b has few token-based features despite high sparsity). Low Faithfulness scores are expected for transcoders that distribute concepts across layers. Many single-cluster or outlier-only features suggests circuit analysis may not disentangle polysemanticity effectively (Layer 0: avg 1.05 clusters/feature).

- **First 3 experiments:** 1) Reproduce WeightLens token validation rates on Llama-3.2-1B to test generalization of layer-wise trends. 2) Ablate the Jacobian term in Eq. 2 to measure attribution quality degradation on context-dependent features. 3) Vary the frequency filter threshold ρ and DBSCAN parameters to optimize cluster purity vs. coverage tradeoffs.

## Open Questions the Paper Calls Out

- **How can evaluation metrics be adapted to assess circuit-level interventions rather than individual feature modifications?** The authors note that faithfulness scores are consistently low because "similar concepts are distributed across layers and features," and suggest "it may therefore be reasonable to modify the faithfulness metric to evaluate interventions on entire circuits rather than individual features." Current metrics measure the output effect of steering single features, which often fails to produce large effects in transcoder architectures where functionality is distributed.

- **To what extent does hyperparameter optimization of the circuit-based clustering improve the generalizability of feature descriptions?** The authors state that while Layer 12 shows a mix of single-cluster and highly clustered features, "more careful hyperparameter tuning could yield more generalizable results" for distinguishing main circuits from sub-circuits. The current implementation leaves a large share of "outlier-only" features in middle layers, suggesting clustering density thresholds may not be optimally configured for all layer depths.

- **Can efficient sampling strategies be developed to match the fidelity of full-distribution analysis without incurring high memory costs?** The authors observe that "sampling from the full distribution, though memory-intensive, provides a more faithful picture of general feature behavior," indicating a trade-off between resource usage and interpretability quality. The inverse-frequency quantile sampling used to capture rare activations is resource-heavy, potentially limiting scalability for very large models.

## Limitations

- WeightLens is limited to only 25.4%-58.8% of features (token-based attributions), leaving the majority requiring CircuitLens
- CircuitLens computational overhead remains substantial, requiring full forward+backward passes for each generated token
- Quality depends heavily on dataset sampling strategy and explainer LLM capabilities, with acknowledged hyperparameter sensitivity
- Results primarily demonstrated on Gemma-2-2b and GPT-2 with limited cross-model validation

## Confidence

- **High confidence** in the core claim that weight-based feature interpretation is feasible and effective for token-based features, supported by matching or exceeding activation-based baselines
- **Medium confidence** in the circuit-based clustering approach for polysemanticity resolution, conceptually sound but with acknowledged hyperparameter sensitivity and limited ablation studies
- **Medium confidence** in overall system's robustness across different model architectures, primarily validated on Gemma-2-2b and GPT-2

## Next Checks

1. Reproduce WeightLens token validation rates on Llama-3.2-1B to test whether observed layer-wise trends generalize beyond Gemma models
2. Ablate the Jacobian term from CircuitLens's attribution equation and measure degradation in Purity scores for context-dependent features
3. Systematically vary the frequency filter threshold ρ and DBSCAN parameters across multiple layers to map the tradeoff surface between cluster purity and feature coverage