---
ver: rpa2
title: 'CASSANDRA: Programmatic and Probabilistic Learning and Inference for Stochastic
  World Modeling'
arxiv_id: '2601.18620'
source_url: https://arxiv.org/abs/2601.18620
tags:
- function
- action
- code
- state
- park
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CASSANDRA, a neurosymbolic world modeling
  approach that integrates LLM-generated code for deterministic dynamics with a probabilistic
  graphical model for stochastic variables. The key idea is to leverage an LLM as
  a knowledge prior to construct lightweight transition models for planning in complex
  environments.
---

# CASSANDRA: Programmatic and Probabilistic Learning and Inference for Stochastic World Modeling

## Quick Facts
- arXiv ID: 2601.18620
- Source URL: https://arxiv.org/abs/2601.18620
- Authors: Panagiotis Lymperopoulos; Abhiramon Rajasekharan; Ian Berlot-Attwell; StÃ©phane Aroca-Ouellette; Kaheer Suleman
- Reference count: 40
- Key outcome: CASSANDRA integrates LLM-generated code with probabilistic graphical models, achieving 95% survival rate in theme park simulator vs 8-29% for baselines

## Executive Summary
This paper introduces CASSANDRA, a neurosymbolic world modeling approach that combines LLM-generated code for deterministic dynamics with probabilistic graphical models for stochastic variables. The method leverages LLMs as knowledge priors to construct lightweight transition models for planning in complex environments. CASSANDRA uses evolutionary algorithms to optimize LLM-synthesized code for deterministic features while employing LLM-guided structure learning for capturing causal relationships among stochastic variables.

## Method Summary
CASSANDRA represents world models as a combination of deterministic and stochastic components. The deterministic part is learned through LLM-generated Python code optimized via evolutionary algorithms, while the stochastic part uses a probabilistic graphical model with structure learned through LLM guidance. The approach handles mixed deterministic-stochastic dynamics by training on limited data and using the LLM as a prior for structure learning. Planning is performed using an anytime A* algorithm with a learned transition model.

## Key Results
- In coffee shop simulator, CASSANDRA outperformed DAGGER, PPO, and black-box models in cumulative reward (averaging ~4500 vs ~4000 for best baseline)
- In theme park simulator, CASSANDRA achieved 95% survival rate over 50 days compared to 8-29% for baselines
- Transition prediction accuracy improved significantly over purely neural or rule-based baselines

## Why This Works (Mechanism)
CASSANDRA works by leveraging LLMs to generate interpretable, executable code that captures deterministic relationships while using probabilistic graphical models to handle uncertainty and stochasticity. The evolutionary algorithm optimizes the generated code to fit the data, while the LLM guides structure learning for the probabilistic component. This hybrid approach combines the interpretability and efficiency of programmatic models with the flexibility of probabilistic reasoning.

## Foundational Learning
- **Probabilistic Graphical Models**: Needed for modeling causal relationships among stochastic variables; quick check: verify DAG structure and conditional independence assumptions
- **Evolutionary Algorithms**: Used to optimize LLM-generated code; quick check: track convergence and population diversity
- **LLM-guided Structure Learning**: LLM provides priors for graph structure; quick check: validate generated structures against domain knowledge
- **Anytime A* Planning**: Enables efficient planning with learned models; quick check: monitor heuristic admissibility and consistency
- **Neurosymbolic Integration**: Combines symbolic reasoning with neural approaches; quick check: test component isolation and interaction

## Architecture Onboarding

**Component Map**: LLM -> Code Generator -> Evolutionary Optimizer -> Deterministic Model; LLM -> Structure Learner -> PGM; Deterministic Model + PGM -> Transition Model -> Planner

**Critical Path**: LLM generates code -> Evolutionary algorithm optimizes code -> Deterministic model trained -> LLM guides PGM structure -> PGM trained -> Combined model used for planning

**Design Tradeoffs**: Interpretability vs. expressiveness in code generation; computational efficiency vs. model accuracy in evolutionary optimization; prior knowledge vs. data-driven learning in structure learning

**Failure Signatures**: Poor LLM generation leads to incorrect deterministic relationships; overfitting in evolutionary optimization produces brittle code; incorrect PGM structure results in invalid causal assumptions

**First 3 Experiments**: 1) Test code generation quality with different LLM prompts, 2) Evaluate evolutionary algorithm convergence on deterministic component, 3) Validate PGM structure learning on synthetic data with known ground truth

## Open Questions the Paper Calls Out
None specified in the provided text.

## Limitations
- Evaluation limited to two simulated environments, potentially limiting generalizability to real-world applications
- Performance metrics focus heavily on survival rates rather than broader planning quality measures
- Evolutionary algorithm optimization may become computationally expensive in higher-dimensional state spaces
- Limited baseline comparisons and sensitivity analysis to LLM quality variations

## Confidence

| Claim | Confidence |
|-------|------------|
| Core methodology of combining neurosymbolic methods with probabilistic graphical models | High |
| Reported performance improvements in simulated environments | Medium |
| Generalizability to real-world applications and complex domains | Low |

## Next Checks
1. Test CASSANDRA on additional, more complex simulated environments with larger state spaces and more diverse action sets to assess scalability and robustness
2. Conduct ablation studies to quantify the individual contributions of LLM-generated code and probabilistic graphical model to overall performance
3. Evaluate planning performance using metrics beyond survival rates, including cumulative reward, plan efficiency, and robustness to perturbations