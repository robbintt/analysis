---
ver: rpa2
title: 'Geometric Learning in Black-Box Optimization: A GNN Framework for Algorithm
  Performance Prediction'
arxiv_id: '2506.16144'
source_url: https://arxiv.org/abs/2506.16144
tags:
- performance
- graph
- algorithm
- optimization
- node
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a graph neural network (GNN) framework for
  predicting the performance of modular optimization algorithms, addressing the limitation
  of traditional tabular methods that overlook algorithm configurations. The authors
  propose representing optimization problems, algorithm configurations, and performance
  outcomes as nodes in a heterogeneous graph, capturing their complex interdependencies.
---

# Geometric Learning in Black-Box Optimization: A GNN Framework for Algorithm Performance Prediction

## Quick Facts
- arXiv ID: 2506.16144
- Source URL: https://arxiv.org/abs/2506.16144
- Reference count: 30
- Up to 36.6% MSE improvement over Random Forest baselines using heterogeneous graph representation

## Executive Summary
This paper introduces a graph neural network framework for predicting modular optimization algorithm performance, addressing the limitation of traditional tabular methods that overlook algorithm configurations. The authors propose representing optimization problems, algorithm configurations, and performance outcomes as nodes in a heterogeneous graph, capturing their complex interdependencies. They evaluate the framework on 324 modCMA-ES and 576 modDE variants across 24 BBOB problems, demonstrating up to 36.6% improvement in mean squared error over traditional Random Forest models while maintaining consistent gains across different problem dimensions and runtime budgets.

## Method Summary
The method constructs heterogeneous graphs with six node types (parameter, parameter-class, algorithm-execution-part, algorithm, performance, black-box problem) and five relation types to encode modular optimization algorithms and their performance on benchmark problems. The framework uses GraphSAGE layers with HeteroConv to perform relation-specific message passing, aggregating information from algorithm components to predict performance as a regression task. The model is trained using leave-instance-out cross-validation with L1 loss and Adam optimization, achieving significant improvements over baseline Random Forest models that use only tabular features.

## Key Results
- GNN model achieves up to 36.6% improvement in mean squared error compared to Random Forest baselines
- Performance gains are consistent across different problem dimensions (5D vs 30D) and runtime budgets
- The heterogeneous graph representation captures complex interdependencies between algorithm modules, parameters, and problem characteristics that tabular methods miss

## Why This Works (Mechanism)

### Mechanism 1
Heterogeneous graph representation captures interdependencies between algorithm configurations and problem features that tabular methods miss. Six node types connected via five relation types encode structural relationships; message-passing propagates this information to performance nodes for regression. The core assumption is that relationships between algorithm modules, parameters, and problem characteristics contain signal useful for performance prediction beyond aggregated features alone.

### Mechanism 2
Relation-specific message aggregation with cross-relation consolidation enables learning differentiated contributions from algorithm components. HeteroConv layers apply GraphSAGE aggregation per relation type; messages are transformed and summed across relations, allowing the model to learn which parameter-class-to-execution-part connections most influence outcomes. The core assumption is that different relation types carry semantically distinct information requiring separate aggregation functions.

### Mechanism 3
Adding reverse edges and using 4-layer depth enables sufficient receptive field for performance nodes to aggregate information from all relevant algorithm components. Original directed edges are supplemented with reverse edges; 4 message-passing layers allow a performance node to receive information from distant parameter and algorithm nodes through iterative neighbor aggregation. The core assumption is that information from parameters affecting different execution parts must reach the performance node through multi-hop paths.

## Foundational Learning

- **Heterogeneous Graph Neural Networks**: The core architecture relies on handling multiple node and edge types with distinct feature spaces; standard homogeneous GNNs cannot directly process this structure. Quick check: Can you explain how HeteroConv differs from applying a standard GNN layer to a homogeneous graph with concatenated node types?

- **Exploratory Landscape Analysis (ELA)**: Problem node features are 46 ELA features; understanding what landscape characteristics they encode (ruggedness, modality, separability) helps interpret what the model learns. Quick check: What landscape properties would you expect to correlate with CMA-ES vs. DE performance differences?

- **Modular Optimization Frameworks (modCMA-ES, modDE)**: The graph structure directly encodes module selections and parameter settings; interpreting predictions requires knowing what elitism, base_sampler, or local_restart options actually change in algorithm behavior. Quick check: Which CMA-ES modules would you expect to most affect performance on multimodal vs. unimodal landscapes?

## Architecture Onboarding

- **Component map**: Benchmarking data -> Heterogeneous graph construction -> 4-layer HeteroConv encoder -> Performance node embeddings -> Linear regression head -> MSE prediction

- **Critical path**: 
  1. Parse benchmarking data into heterogeneous graph format following the meta-graph schema
  2. Initialize node features (ELA for problems, random for others)
  3. Apply 4 rounds of relation-specific message passing with mean-within/sum-across aggregation
  4. Extract performance node embeddings and apply regression head
  5. Train with leave-instance-out cross-validation

- **Design tradeoffs**: 
  - Depth vs. over-smoothing: 4 layers chosen to reach all algorithm components; deeper may dilute node-specific signals
  - Feature initialization: Random init for non-problem nodes assumes structure carries sufficient signal; alternative would be learned or engineered features
  - Graph scope: One graph per (dimension, budget, algorithm family) limits cross-setting transfer but simplifies learning

- **Failure signatures**: 
  - MSE not improving over RF baseline suggests graph structure adds noise rather than signal
  - Large gap between 5D and 30D performance may indicate dimension-specific overfitting
  - Training instability with learning rate 0.1 may require more aggressive scheduling

- **First 3 experiments**: 
  1. Replicate the RF baseline with 46 ELA features on the same train/test splits to confirm comparison validity
  2. Ablate the heterogeneous structure by collapsing to a homogeneous graph with concatenated features to isolate the contribution of explicit relation modeling
  3. Vary GNN depth (2, 3, 4, 5 layers) to verify 4 layers is sufficient and not excessive for the graph diameter in this domain

## Open Questions the Paper Calls Out

- **Can alternative architectures like graph attention networks or graph transformers improve predictive performance over the GraphSAGE baseline?** The authors state exploring "graph attention networks or graph transformers" is promising but leave it untested.

- **Which specific nodes, relations, and features drive the performance predictions in the heterogeneous graph?** Section 5 notes that explainability methods could provide insights, but the current work focuses only on predictive accuracy without interpretability analysis.

- **How can this framework be generalized to non-modular optimization algorithms that lack a standardized vocabulary of components?** The authors identify extending to non-modular algorithms as a key challenge requiring broader community collaboration to define standard vocabularies.

## Limitations
- Experiments limited to 24 BBOB problems and two modular frameworks, which may not generalize to broader optimization domains
- Non-problem node features use random initialization, potentially requiring more training data to converge
- Separate graphs per (dimension, budget, algorithm family) prevent cross-setting transfer and increase computational overhead

## Confidence

- **High**: The heterogeneous graph representation structure is well-defined and reproducible; MSE improvements over RF are directly measurable
- **Medium**: The specific choice of 4-layer depth and Kaiming initialization is reasonable but not rigorously validated against alternatives
- **Low**: No corpus evidence exists for this exact heterogeneous GNN formulation in modular optimization; mechanisms are theoretically sound but empirically untested in broader contexts

## Next Checks

1. Conduct ablation studies removing ELA features from problem nodes to assess their marginal contribution versus graph structure alone
2. Test cross-family transfer by training on modCMA-ES and evaluating on modDE (and vice versa) to measure domain generalization
3. Compare against a homogeneous GNN baseline with concatenated features to isolate the benefit of explicit relation modeling