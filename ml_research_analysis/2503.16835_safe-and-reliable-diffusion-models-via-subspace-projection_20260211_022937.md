---
ver: rpa2
title: Safe and Reliable Diffusion Models via Subspace Projection
arxiv_id: '2503.16835'
source_url: https://arxiv.org/abs/2503.16835
tags:
- concept
- style
- subspace
- images
- diffusion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SAFER, a method for removing unwanted concepts
  from diffusion models by leveraging the low-dimensional structure of text embeddings.
  The approach uses textual inversion to extract concept-specific subspaces from reference
  images, then projects prompt embeddings onto the complementary subspace to eliminate
  the target concept.
---

# Safe and Reliable Diffusion Models via Subspace Projection

## Quick Facts
- **arXiv ID**: 2503.16835
- **Source URL**: https://arxiv.org/abs/2503.16835
- **Reference count**: 31
- **One-line primary result**: SAFER removes unwanted concepts from diffusion models by projecting prompt embeddings onto the complementary subspace of concept-specific low-dimensional subspaces extracted via textual inversion and SVD.

## Executive Summary
This paper introduces SAFER, a method for removing unwanted concepts (artistic styles, objects, nudity) from text-to-image diffusion models. The approach leverages the low-dimensional structure of text embeddings, using textual inversion to extract concept-specific subspaces from reference images. By projecting prompt embeddings onto the complementary subspace, SAFER effectively erases target concepts while preserving non-target content. The method introduces a subspace expansion strategy to ensure comprehensive and robust concept removal across diverse reference images.

## Method Summary
SAFER removes concepts by first learning a pseudo-token T_c via textual inversion from reference images. Prompts containing T_c are encoded to embeddings, and SVD identifies the first left singular vector U_1 as the concept subspace basis. A projection matrix P = I - U_1U_1^T is constructed and merged into cross-attention layer weights. The method includes progressive subspace expansion using multiple reference images with cosine similarity above threshold τ to ensure comprehensive erasure. This approach is intrinsic to the model, preventing removal through adversarial module deletion.

## Key Results
- SAFER achieves lower style similarity scores and better resistance to synonym-based evasion compared to existing methods
- The approach effectively removes artistic styles, objects, and nudity content while maintaining generation quality for non-target concepts
- Progressive subspace expansion with multiple reference images provides more comprehensive concept removal than single-image approaches

## Why This Works (Mechanism)

### Mechanism 1: Low-Rank Concept Subspace via Textual Inversion
- Claim: Target concepts occupy a low-dimensional subspace in text embedding space, identifiable via SVD on prompt embeddings containing a learned concept token.
- Mechanism: Textual inversion maps a reference image to a pseudo-token T_c with optimized embedding u*. Prompts containing T_c are encoded, concatenated into matrix Σe_c, and decomposed via SVD. The first left singular vector U_1 spans the concept subspace, as Eq. (8) shows the concept term has rank 1 while object/noise terms average to zero.
- Core assumption: Concept-related variance concentrates in the first principal component; object and noise components are independent and zero-mean.
- Evidence anchors:
  - [abstract]: "inspired by the observed low-dimensional structure of the text embedding space"
  - [Section IV-A, Fig. 3]: SVD on Monet style and airplane prompts shows first component dominates explained variance
  - [corpus]: TRCE (2503.07389) similarly targets "reliable" concept erasure but uses different erasure formulation

### Mechanism 2: Concept Removal via Complementary Subspace Projection
- Claim: Projecting prompt embeddings onto the orthogonal complement of the concept subspace removes target concepts while preserving non-target content.
- Mechanism: Projection matrix P = I − U_1U_1^T (Eq. 11) nullifies the component along U_1. This is merged into cross-attention layer weights (Algorithm 3), making erasure intrinsic to the model. For concept amplification, P = I + λU_1U_1^T (Eq. 12) scales the concept component.
- Core assumption: Style/object features are separable in embedding space; removing the concept subspace does not corrupt unrelated semantic information.
- Evidence anchors:
  - [abstract]: "projects the prompt embeddings onto the complementary subspace of S_c, effectively erasing the concept"
  - [Section IV-C, Fig. 5]: Projecting with U_1 removes Van Gogh style; using U_2 or higher components does not
  - [Section V-A]: "images in the subsequent columns retain varying degrees of stylistic influence"
  - [corpus]: Semantic Surgery (2510.22851) also operates on text embeddings pre-diffusion but uses different erasure logic

### Mechanism 3: Progressive Subspace Expansion for Comprehensive Erasure
- Claim: Iteratively expanding the concept subspace using multiple diverse reference images ensures robust erasure against synonyms and indirect prompts.
- Mechanism: Starting from initial subspace U_1^i, additional reference images x_j with similarity sim(x_i, x_j) > τ contribute their subspaces. Projection matrices compose: P = P_i P_j = (I − U_1^i U_1^{iT})(I − U_1^j U_1^{jT}) (Eq. 14). This progressively removes more concept variants.
- Core assumption: ViT embedding similarity correlates with conceptual similarity; dissimilar images represent distinct concept variants that require separate subspace components.
- Evidence anchors:
  - [abstract]: "subspace expansion strategy to ensure comprehensive and robust concept erasure"
  - [Section IV-D, Algorithm 2]: Full expansion procedure with cosine similarity threshold
  - [Fig. 1]: Without expansion, "Starry Night" prompt still produces Van Gogh style; SAFER removes it
  - [Fig. 10]: Ablation shows TI+Expand achieves complete removal where TI-only fails on "impression sunrise"
  - [corpus]: Corpus papers do not directly validate progressive expansion; this is a paper-specific contribution

## Foundational Learning

- Concept: **Singular Value Decomposition (SVD)**
  - Why needed here: Core to extracting concept subspaces from embedding matrices; determines which principal components capture target concepts.
  - Quick check question: Given a 50×768 embedding matrix, what do U, Σ, and V^T represent, and which contains the principal directions?

- Concept: **Textual Inversion**
  - Why needed here: Converts visual concepts from reference images into optimized embeddings that can be used in prompts, enabling precise subspace estimation beyond natural language limitations.
  - Quick check question: What is optimized during textual inversion—the model weights or the embedding vector?

- Concept: **Cross-Attention in Diffusion Models**
  - Why needed here: The projection matrix is merged into cross-attention layer weights; understanding this module is essential for knowing where and how erasure is implemented.
  - Quick check question: In a text-conditional U-Net, what tensor does the cross-attention module condition on, and what is the shape of the query/key/value projections?

## Architecture Onboarding

- Component map:
  Text Encoder (CLIP) -> Textual Inversion Optimizer -> Subspace Estimator -> Subspace Expander -> Projection Merger -> Cross-Attention Layer

- Critical path: Reference image → Textual inversion → Prompt generation → SVD → U_1 extraction → Progressive expansion → P computation → Cross-attention weight merge → Inference

- Design tradeoffs:
  - Single vs. multiple reference images: Single image is fast but incomplete; multiple images improve erasure but require threshold tuning (τ) and more computation
  - Subspace dimensionality: Paper uses rank-1 (U_1 only); higher ranks could capture more variance but risk over-erasure
  - Layer selection for merge: Paper targets cross-attention; Assumption: other layers may have different erasure/side-effect profiles

- Failure signatures:
  - Incomplete erasure: Synonyms or indirect prompts still generate target concept → subspace not expanded sufficiently or τ too high
  - Over-erasure: Non-target concepts degrade → subspace overlaps with non-target semantics
  - No effect after merge: Projection matrix not correctly applied to weights, or wrong layer selected

- First 3 experiments:
  1. Validate subspace existence: Replicate Fig. 3—generate 20+ prompts for a style (e.g., "Van Gogh"), encode via CLIP, run SVD, plot explained variance ratios. Confirm first component dominates.
  2. Single-concept erasure test: Pick one artist style, run Algorithm 1 with one reference image, merge P into cross-attention, generate images with direct prompts ("painting in Van Gogh style") and indirect prompts ("Starry Night"). Measure style similarity scores (s_c) per Eq. (15).
  3. Expansion ablation: For same artist, run Algorithm 2 with 3–5 diverse reference paintings. Compare s_c scores and visual quality against single-image baseline. Identify τ sensitivity by testing values [0.7, 0.8, 0.9, 0.95].

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the dimensionality of the concept subspace affect the trade-off between removal completeness and preservation of non-target concepts?
- Basis in paper: [explicit] The paper uses only the first principal component (U1) as the basis for Sc, noting in Figure 5 that U1 successfully eliminates style while U2 does not. However, it does not explore whether higher-dimensional subspaces could improve completeness for complex concepts.
- Why unresolved: The paper demonstrates that U1 captures the primary concept information but does not systematically investigate whether including additional components (U2, U3, etc.) could enhance erasure for concepts with greater stylistic diversity.
- What evidence would resolve it: Ablation experiments varying the number of principal components retained in Sc across multiple concept types, measuring both removal effectiveness (sc, Accc) and non-target preservation (s¯c, Acc¯c).

### Open Question 2
- Question: How robust is SAFER against sophisticated adversarial prompt engineering beyond synonym substitution?
- Basis in paper: [explicit] The paper claims SAFER prevents "evasion through synonyms" and demonstrates robustness against synonym-based evasion (Accg metric in Table II). However, it does not evaluate more advanced attacks such as prompt paraphrasing, typographical attacks, or embedding-space optimization.
- Why unresolved: While the method integrates projection into model weights to prevent module removal, sophisticated users could potentially craft adversarial prompts that circumvent the subspace projection by encoding concepts in unexpected ways.
- What evidence would resolve it: Systematic evaluation using automated adversarial prompt generation methods (e.g., gradient-based optimization, GPT-based paraphrasing) to assess whether erased concepts can be recovered through crafted inputs.

### Open Question 3
- Question: What is the impact of the subspace expansion threshold τ on removal effectiveness and computational efficiency?
- Basis in paper: [explicit] Algorithm 2 requires a threshold τ to determine when to expand the subspace based on cosine similarity. The paper does not provide guidance on selecting τ or analyze its sensitivity.
- Why unresolved: An overly low threshold could lead to excessive expansion and computational overhead, while an overly high threshold could result in incomplete concept coverage. The optimal setting likely varies by concept type.
- What evidence would resolve it: Sensitivity analysis across multiple τ values for different concept categories (styles, objects, nudity), measuring both removal metrics and the number of expansion iterations required.

### Open Question 4
- Question: Can concept subspaces identified in one diffusion model transfer effectively to other model architectures or checkpoints?
- Basis in paper: [inferred] The method operates on text embeddings and cross-attention weights specific to SD v1.4. The paper does not address whether subspaces learned for one model would remain valid for different architectures (e.g., SDXL) or fine-tuned variants.
- Why unresolved: Text embedding spaces may differ across models, and cross-attention weight structures could vary, potentially requiring subspace re-identification for each target model.
- What evidence would resolve it: Cross-model transfer experiments applying projection matrices derived from SD v1.4 to other diffusion models, measuring whether concept removal effectiveness is maintained.

## Limitations

- The method's effectiveness on highly abstract concepts remains unverified, as all experiments focus on visual styles and concrete objects
- The subspace expansion threshold τ is not experimentally validated across its full range, leaving sensitivity analysis incomplete
- Claims about "safe and reliable" deployment are not validated through testing on real-world adversarial prompts or long-term stability analysis

## Confidence

- **High confidence**: The mathematical framework for subspace projection and its implementation in cross-attention layers is sound and well-specified.
- **Medium confidence**: Experimental results on artistic styles and objects are convincing, but the small sample size (10 styles, 10 objects) and limited adversarial testing reduce generalizability claims.
- **Low confidence**: Claims about "safe and reliable" deployment are not validated—no testing on real-world adversarial prompts, no long-term stability analysis, and no evaluation of whether erased concepts can be recovered through fine-tuning or model updates.

## Next Checks

1. **Multi-component subspace validation**: For a complex concept like "impressionism" spanning multiple artists, test whether rank-1 subspace fails while rank-2 or rank-3 succeeds, establishing the limits of the low-rank assumption.
2. **Adversarial prompt robustness**: Systematically test if concepts can be recovered through semantic chaining (e.g., "painting inspired by Monet's water lilies in Starry Night's style") or prompt injection techniques.
3. **Layer sensitivity analysis**: Apply projection matrices to different cross-attention layers (early vs. late) and measure the tradeoff between erasure completeness and non-target concept preservation to identify optimal layer selection.