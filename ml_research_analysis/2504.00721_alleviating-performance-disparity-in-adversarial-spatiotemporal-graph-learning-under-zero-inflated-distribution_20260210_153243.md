---
ver: rpa2
title: Alleviating Performance Disparity in Adversarial Spatiotemporal Graph Learning
  Under Zero-Inflated Distribution
arxiv_id: '2504.00721'
source_url: https://arxiv.org/abs/2504.00721
tags:
- adversarial
- spatiotemporal
- training
- proc
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of performance disparity in spatiotemporal
  graph learning models under zero-inflated distributions when subjected to adversarial
  attacks. Specifically, it addresses the challenge where traditional adversarial
  training exacerbates the performance gap between majority (zero observations) and
  minority (non-zero observations) classes, which is critical for urban risk management
  tasks like crime prediction and traffic accident profiling.
---

# Alleviating Performance Disparity in Adversarial Spatiotemporal Graph Learning Under Zero-Inflated Distribution

## Quick Facts
- arXiv ID: 2504.00721
- Source URL: https://arxiv.org/abs/2504.00721
- Reference count: 5
- Primary result: Proposed MinGRE framework reduces performance disparity between majority (zero) and minority (non-zero) classes in adversarial spatiotemporal graph learning, achieving up to 31.9% improvement in minority class robustness on NYC and Chicago datasets.

## Executive Summary
This paper addresses the problem of performance disparity in adversarial spatiotemporal graph learning models under zero-inflated distributions. The core issue is that traditional adversarial training exacerbates the gap between majority (zero observations) and minority (non-zero observations) classes, which is critical for urban risk management tasks like crime prediction and traffic accident profiling. The authors propose MinGRE, a framework that introduces multi-dimensional attention-based gradient reweighting and uncertainty-guided contrastive loss to improve minority class robustness while maintaining overall model performance. Experiments demonstrate significant improvements in reducing performance disparity while enhancing robustness against adversarial attacks.

## Method Summary
The MinGRE framework consists of three main components: a cross-segment spatiotemporal encoder using Attention Between Datapoints (ABD) mechanism, multi-dimensional attention-based gradient reweighting, and an uncertainty-guided contrastive loss. The method operates through a two-stage iterative optimization where adversarial examples are first generated using reweighted gradients, then the main model is trained with a combined loss function. The gradient reweighting ensures minority samples are more frequently selected as victim nodes during adversarial training, while the contrastive loss improves inter-class separability and intra-class compactness of minority representations with higher uncertainty.

## Key Results
- MinGRE reduces performance disparity, achieving up to 31.9% improvement in minority class robustness compared to state-of-the-art methods
- The framework significantly enhances overall model robustness against adversarial attacks on benchmark datasets (NYC and Chicago)
- Experiments show balanced improvements across both majority and minority classes, unlike traditional adversarial training which worsens disparity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-dimensional attention-based gradient reweighting reduces bias toward majority class nodes during victim node selection in adversarial training.
- Mechanism: The framework decomposes gradient magnitude into predefined loss weights and gradient flow across temporal dimensions. Segment, spatial, and temporal attention correct these weights, skewing the distribution toward non-zero regions and ensuring minority samples are more frequently selected as victim nodes.
- Core assumption: Smaller top-k gradients of minority samples are the primary cause of their under-representation in adversarial training; correcting this imbalance will reduce performance disparity.
- Evidence anchors: [abstract], [section 3, Mechanism], [corpus]

### Mechanism 2
- Claim: Uncertainty-guided contrastive loss improves inter-class separability and intra-class compactness of minority representations, mitigating representation degradation from adversarial training.
- Mechanism: A parameter decoder predicts mean and dispersion under a negative binomial distribution assumption. The variance serves as an uncertainty proxy, with high-uncertainty samples receiving higher weights in the supervised contrastive loss, forcing the model to push apart hard-to-distinguish samples.
- Core assumption: High predictive uncertainty correlates with representation ambiguity between classes; targeting these regions will improve minority separability.
- Evidence anchors: [abstract], [section 3, UCL], [corpus]

### Mechanism 3
- Claim: Cross-segment spatiotemporal encoding captures batch-level interactions that improve attention-based reweighting quality.
- Mechanism: The ABD layer reshapes input to (T, N, B, D) and applies multi-head self-attention across segments, followed by sequential temporal and spatial self-attention, enabling the reweighting network to learn which segments contain event-dense regions.
- Core assumption: Batch-level dependencies carry signal about which samples have minority-class relevance.
- Evidence anchors: [section 3, Encoder], [figure 3 caption], [corpus]

## Foundational Learning

- **Zero-Inflated Distributions (ZID)**
  - Why needed here: The entire framework assumes data where zero observations dominate; standard RMSE loss and gradient heuristics fail because minority signals are numerically weak.
  - Quick check question: Can you explain why negative binomial distribution is preferred over Gaussian for modeling traffic accident counts?

- **Adversarial Training (Min-Max Optimization)**
  - Why needed here: The core problem is that standard adversarial training exacerbates class disparity under ZID. Understanding the inner maximization (attack generation) and outer minimization (model training) is essential.
  - Quick check question: Why does gradient-based victim node selection bias toward high-gradient nodes, and how does this create disparity?

- **Contrastive Learning for Regression**
  - Why needed here: Contrastive losses are typically used in classification; adapting them to regression requires mapping continuous labels to embedding distances while maintaining label-consistency.
  - Quick check question: How would you define "positive" and "negative" pairs in a traffic accident prediction task with continuous counts?

## Architecture Onboarding

- Component map: Input -> ABD Encoder -> Gradient Reweighting -> STPGD Perturbation -> Target Model (STGNN) -> Parameter Decoder (μ, α) -> Combined Loss
- Critical path: 1) Forward pass through encoder → attention weights; 2) Compute gradients of NLL w.r.t. inputs; 3) Reweight gradients → select top-k victim nodes → generate perturbation; 4) Train target model on perturbed data with combined loss
- Design tradeoffs: Two-stage optimization adds complexity but decouples objectives; negative binomial assumption fits ZID but may misfit other sparse distributions; ABD attention adds O(B²) complexity
- Failure signatures: Minority recall still drops >10% under attack → gradient reweighting not converging; High MAP-D but low Rec-D → contrastive loss improving ranking but not raw detection; Training instability → two-stage optimization may be alternating too aggressively
- First 3 experiments: 1) Gradient distribution visualization: Plot top-k gradient histograms for majority vs. minority classes before and after reweighting; 2) Ablation on attention dimensions: Disable temporal attention only; 3) Uncertainty calibration check: Scatter plot predicted variance α vs. absolute error on minority samples

## Open Questions the Paper Calls Out
None

## Limitations
- Performance improvement metrics lack variance bounds or statistical significance testing
- Gradient reweighting assumes minority under-selection is gradient-magnitude-driven, but structural sparsity effects are unquantified
- Uncertainty-guided contrastive loss effectiveness depends on accurate variance estimation, which may be unreliable in sparse regimes

## Confidence

**Major uncertainties:**
- Performance improvement metrics lack variance bounds or statistical significance testing
- Gradient reweighting assumes minority under-selection is gradient-magnitude-driven, but structural sparsity effects are unquantified
- Uncertainty-guided contrastive loss effectiveness depends on accurate variance estimation, which may be unreliable in sparse regimes

**Confidence labels:**
- **High**: Disparity exists and adversarial training worsens it under ZID
- **Medium**: Multi-dimensional attention reweighting improves minority gradient selection
- **Medium**: Uncertainty-guided contrastive loss improves minority representation separability
- **Low**: ABD cross-segment encoding meaningfully contributes to reweighting quality

## Next Checks

1. Visualize top-k gradient distributions for majority/minority classes before/after reweighting; expect ~2× increase in minority magnitude
2. Perform ablation study by disabling temporal attention; disparity should return if temporal reweighting is critical
3. Evaluate uncertainty calibration via scatter plot of predicted variance vs. minority sample error; weak correlation indicates miscalibration