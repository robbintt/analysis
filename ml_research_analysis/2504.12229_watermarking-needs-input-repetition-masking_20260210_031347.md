---
ver: rpa2
title: Watermarking Needs Input Repetition Masking
arxiv_id: '2504.12229'
source_url: https://arxiv.org/abs/2504.12229
tags:
- watermarked
- watermark
- aaronson
- response
- conversations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates how linguistic adaptation\u2014specifically,\
  \ mimicry\u2014occurs when interacting with watermarked language models (LMs). The\
  \ authors show that unwatermarked LMs and humans begin to reproduce watermarked\
  \ language patterns when engaging in extended conversations with watermarked models,\
  \ leading to false positives in watermark detection."
---

# Watermarking Needs Input Repetition Masking

## Quick Facts
- arXiv ID: 2504.12229
- Source URL: https://arxiv.org/abs/2504.12229
- Reference count: 40
- Primary result: Unwatermarked models and humans mimic watermark patterns in extended conversations with watermarked models, causing false positives.

## Executive Summary
This paper demonstrates that linguistic adaptation—specifically, mimicry—occurs when interacting with watermarked language models (LMs). Unwatermarked LMs and humans begin to reproduce watermarked language patterns when engaging in extended conversations with watermarked models, leading to false positives in watermark detection. Using two popular watermarking schemes, the authors show that even with low detection probabilities, unwatermarked models can mimic watermarks at rates up to 12.9%. Experiments with human participants confirm similar adaptation in real conversations. The study concludes that for long-term watermark reliability, significantly lower false positive rates and longer n-grams are needed.

## Method Summary
The authors use Guanaco-7B and Guanaco-13B models as unwatermarked agents, interacting with watermarked versions of the same models (T∈{0,0.5,1}) in multi-turn conversations. Watermarking schemes from Aaronson et al. and Kirchenbauer et al. are applied using n-gram=4, threshold=0.01, and 3 random hash keys. They measure P&R (both prompt and response watermarked) and P<R (response watermark stronger than prompt) across 20 conversations. Repetition masking is tested by removing n-grams shared between prompt and response before detection. Human experiments use anonymized ShareGPT (100+ turns) and WildChat (50+ turns) datasets with Binoculars score analysis.

## Key Results
- Unwatermarked Guanaco-13B models mimic watermarked patterns at up to 12.9% false positive rate in multi-turn conversations
- Repetition masking eliminates mimicry by removing shared n-grams between prompt and response
- Larger models (GPT-4o) show near-zero mimicry, suggesting model capability affects susceptibility
- Human conversations show linguistic drift toward LLM-like patterns over extended interactions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Unwatermarked models inadvertently reproduce watermark signals by repeating n-grams from watermarked prompts.
- Mechanism: Current watermarking schemes seed watermark generation using n-gram context. When an unwatermarked model repeats phrases from a watermarked input, the shared n-gram context triggers the same watermark token selections in the output—even though no watermark was applied to that model.
- Core assumption: Watermark detection relies on context-dependent token probability shifts, which can be triggered by any text containing the relevant n-grams, regardless of source.
- Evidence anchors:
  - [abstract] "We call the concept mimicry and demonstrate that both humans and LLMs end up mimicking, including the watermarking signal even in seemingly improbable settings."
  - [section 4.1, Figure 8] "We note that this de-duplication removes the observed mimicry behavior" — confirming n-gram repetition as the causal pathway.
  - [corpus] Related work on watermark detection (CATMark, SimMark) assumes context-based embedding but does not address cross-conversation contamination.
- Break condition: If watermark seeding used longer n-grams or semantic context rather than short token sequences, mimicry through repetition would be substantially reduced.

### Mechanism 2
- Claim: Linguistic adaptation causes both humans and LLMs to converge toward their conversational partner's lexical and syntactic patterns over extended interactions.
- Mechanism: Conversational partners unconsciously align vocabulary, sentence structure, and phrasing. This is documented in humans (Chang et al., 2012) and observed in LLMs. Extended multi-turn conversations amplify this effect.
- Core assumption: Adaptation operates on surface-level patterns that overlap with watermark-relevant features.
- Evidence anchors:
  - [abstract] "Meanwhile, humans are known to adjust language to their conversational partners both syntactically and lexically."
  - [section 4.2] Binoculars scores show increased variance in human text over conversation turns, indicating drift toward LLM-like patterns.
  - [corpus] No direct corpus papers address linguistic adaptation in watermarking contexts; this is a gap.
- Break condition: Short, transactional exchanges would exhibit less adaptation; the effect scales with conversation length.

### Mechanism 3
- Claim: Mimicked watermarks can be stronger than the original because coincidence can produce watermark patterns in non-repeated regions.
- Mechanism: Even when only partial n-grams are repeated, the unwatermarked response may independently generate watermarked tokens in other positions, compounding detection scores.
- Core assumption: Watermark detection is additive across token positions.
- Evidence anchors:
  - [Figure 1 caption] "Importantly, the watermark can even be stronger in the response, since it can by a coincidence produce a watermark in unaffected by mimicry areas."
  - [Table 1] "P<R reports the proportion of cases where watermark of the response from an unwatermarked model is stronger than the watermark in the prompt" — showing non-zero rates.
  - [corpus] Not addressed in neighboring papers.
- Break condition: If watermark scoring normalized for text length or bounded maximum scores, amplification would be capped.

## Foundational Learning

- Concept: **N-gram based watermark seeding**
  - Why needed here: Understanding how watermark schemes use preceding token sequences to deterministically bias next-token selection is essential to grasp why repetition causes mimicry.
  - Quick check question: Given the n-gram "the weather is", would a watermarking scheme always prefer the same next token? Why or why not?

- Concept: **False positive rate (FPR) in detection**
  - Why needed here: The paper argues current FPR thresholds (e.g., 1%) are insufficient for long-term reliability when mimicry is possible.
  - Quick check question: If a watermark detector flags 1% of human-written text as watermarked, how many false accusations would occur across 1 million detections?

- Concept: **Linguistic accommodation vs. mimicry**
  - Why needed here: Distinguishing natural conversational adaptation from adversarial watermark copying clarifies that this is an emergent property, not an attack.
  - Quick check question: Is mimicry in this paper intentional exploitation or an unintended side effect of normal language use?

## Architecture Onboarding

- Component map: Watermarked LLM -> Unwatermarked LLM -> Watermark Detector
- Critical path: Watermarked prompt → Unwatermarked model response → Detector evaluation → False positive if shared n-grams trigger watermark signal
- Design tradeoffs:
  - Longer n-grams reduce mimicry but decrease watermark robustness to edits
  - Lower detection thresholds reduce false positives but increase false negatives
  - Repetition masking adds computational overhead and may miss semantic repetition
- Failure signatures:
  - High false positive rates (up to 12.9%) in multi-turn conversations with smaller models (7B–13B)
  - Larger models (GPT-4o) showed near-zero mimicry—suggesting model scale is a factor
  - Human-written text in long conversations drifts toward LLM-like Binoculars scores
- First 3 experiments:
  1. Reproduce baseline mimicry: Run 20 conversations between watermarked Guanaco-13B and unwatermarked Guanaco-13B; measure false positive rate at p<0.01 threshold for both Aaronson and Kirchenbauer schemes
  2. Validate repetition masking: Apply n-gram de-duplication between prompt and response before detection; confirm mimicry drops to baseline (as shown in Figure 8)
  3. Scale sensitivity test: Compare mimicry rates across model sizes (7B vs 13B vs larger API models) to establish whether capability reduces adaptation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can watermarking techniques be developed that achieve significantly lower false positive rates while maintaining practical detectability?
- Basis in paper: [explicit] The conclusion states that "investigating watermarking techniques that provide significantly lower false positive rates is crucial" for long-term viability.
- Why unresolved: Current configurations result in false positive rates that become problematic when linguistic adaptation occurs during extended conversations.
- What evidence would resolve it: Development and evaluation of new watermarking schemes demonstrating false positive rates substantially below current thresholds (e.g., <0.01%) while retaining meaningful true positive detection rates.

### Open Question 2
- Question: Which alternative watermarking properties (beyond token-level patterns) would remain robust against mimicry?
- Basis in paper: [explicit] The conclusion calls for "exploring alternative watermarking methods that leverage properties less susceptible to mimicry, such as semantic coherence or stylistic elements."
- Why unresolved: Current schemes rely on detectable deviations in token probabilities, which are easily replicated through conversational adaptation.
- What evidence would resolve it: Comparative studies of semantic- or style-based watermarking approaches showing reduced mimicry rates in conversational settings, with metrics quantifying robustness.

### Open Question 3
- Question: Does the observed absence of mimicry in larger models like GPT-4o generalize across model families, scales, and watermarking schemes?
- Basis in paper: [inferred] The authors hypothesize that "larger models... appear less susceptible" and may "internally smooth over deterministic token-level irregularities," but only test one large model configuration with limited variance across keys.
- Why unresolved: Limited experimental scope (only Guanaco-13b vs GPT-4o comparison) and the authors note "more thorough evaluation is required" (Limitations section).
- What evidence would resolve it: Systematic evaluation across multiple model families (e.g., LLaMA, Mistral, Gemini) at varying scales (7B to 70B+) interacting with different watermarked models, measuring mimicry rates across standardized conversation protocols.

## Limitations

- Model capability dependence: The study shows mimicry rates drop for larger models, but doesn't systematically establish the capability threshold where mimicry becomes negligible
- Hash key variability: Only 3 random hash keys were used, introducing substantial uncertainty about whether observed effects are consistent across different key seeds
- N-gram repetition specificity: The paper doesn't establish whether semantic repetition (paraphrasing) could produce similar effects, leaving open whether repetition masking addresses the complete problem
- Human conversation data limitations: Anonymized datasets lack control over conversation characteristics, making causal relationships difficult to establish

## Confidence

- **High confidence**: That linguistic adaptation occurs in LLM-LLM conversations and can produce false positive watermark detections through n-gram repetition
- **Medium confidence**: That human participants exhibit similar linguistic adaptation patterns leading to watermark mimicry
- **Medium confidence**: That current watermarking schemes are insufficient for long-term reliability due to mimicry effects
- **Low confidence**: That repetition masking alone is sufficient to eliminate mimicry for all practical purposes

## Next Checks

1. **Hash key sensitivity analysis**: Run the full experimental pipeline (20 conversations × 2 watermarking schemes × 2 model sizes) with 10+ random hash keys instead of 3. Measure variance reduction in P<R and P&R metrics to determine whether current results are statistically robust or key-dependent artifacts.

2. **Semantic repetition test**: Create a controlled experiment where unwatermarked models generate responses that semantically repeat (paraphrase) watermarked prompt content without exact n-gram matching. Compare watermark detection rates between exact repetition and semantic repetition conditions to determine if repetition masking addresses the complete mimicry problem.

3. **Model capability threshold mapping**: Systematically test a range of model sizes (7B, 13B, 33B, 70B parameters) on the same conversation task. Plot mimicry rates (P<R) against parameter count to identify the capability threshold where mimicry becomes negligible, providing guidance for practical watermark deployment thresholds.