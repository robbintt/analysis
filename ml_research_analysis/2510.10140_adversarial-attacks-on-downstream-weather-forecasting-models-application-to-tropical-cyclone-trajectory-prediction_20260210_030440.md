---
ver: rpa2
title: 'Adversarial Attacks on Downstream Weather Forecasting Models: Application
  to Tropical Cyclone Trajectory Prediction'
arxiv_id: '2510.10140'
source_url: https://arxiv.org/abs/2510.10140
tags:
- adversarial
- trajectory
- forecasts
- upstream
- attack
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the vulnerability of deep learning-based weather
  forecasting (DLWF) models to adversarial attacks, specifically focusing on manipulating
  tropical cyclone (TC) trajectory predictions. The key challenge is that standard
  gradient-based attack methods are infeasible due to the black-box nature of TC detection
  systems and the severe class imbalance problem caused by the rarity of TC events.
---

# Adversarial Attacks on Downstream Weather Forecasting Models: Application to Tropical Cyclone Trajectory Prediction

## Quick Facts
- arXiv ID: 2510.10140
- Source URL: https://arxiv.org/abs/2510.10140
- Reference count: 40
- Primary result: Cyc-Attack achieves 55.70% detection rate, 5.36% false alarm rate, and stealthy perturbations (δC=0.0003) for manipulating tropical cyclone trajectory predictions

## Executive Summary
This paper addresses the vulnerability of deep learning-based weather forecasting models to adversarial attacks targeting downstream tropical cyclone trajectory predictions. The key challenge is that standard gradient-based attack methods fail due to the black-box nature of TC detection systems and severe class imbalance from the rarity of TC events. The authors propose Cyc-Attack, which introduces a differentiable surrogate model to approximate the TC detection system's output, enabling gradient-based attacks. Experimental results demonstrate that Cyc-Attack can reliably alter downstream TC trajectory predictions while maintaining stealthiness.

## Method Summary
The paper proposes Cyc-Attack to generate adversarial perturbations on upstream GraphCast weather forecasts that manipulate downstream TC trajectory predictions detected by the black-box TempestExtremes system. The method involves training a DeepLabV3+ surrogate model with Xception backbone to approximate TempestExtremes output using focal loss and Gaussian kernel dilation to handle class imbalance. The attack uses modified Projected Gradient Descent with distance-based gradient weighting, calibration masks, and ℓ∞ clipping to generate perturbations that successfully manipulate TC trajectories while maintaining stealthiness.

## Key Results
- Cyc-Attack achieves 55.70% targeted TC trajectory detection rate
- False alarm rate of 5.36% with stealthy perturbations (δC=0.0003)
- Outperforms baseline methods on 285 tropical cyclones from the TC2 dataset
- Demonstrates feasibility of generating adversarial weather forecasts that reliably alter downstream TC trajectory predictions

## Why This Works (Mechanism)

### Mechanism 1: Surrogate Gradient Approximation
Replacing a non-differentiable rule-based detector with a differentiable surrogate allows gradient-based optimization to flow through the downstream task. The system trains a DeepLabV3+ model to approximate the binary output of TempestExtremes, providing local gradient signals that indicate how to perturb upstream weather variables to trigger a detection event. This relies on the surrogate model's decision boundary sufficiently approximating the true black-box detector for successful transferability.

### Mechanism 2: Spatial Context Restoration via Kernel Dilation
Dilating sparse positive labels (TC locations) with a truncated Gaussian kernel mitigates class imbalance and prevents scattered, unrealistic artifacts. TC events affect <0.01% of spatial locations, creating bias toward predicting the majority class. The kernel dilation strategy expands the "positive" label to a neighborhood, forcing the model to learn spatial context around the TC eye rather than treating the event as an isolated pixel.

### Mechanism 3: Geodesic Gradient Constraints for Trajectory Coherence
Weighting gradient updates based on geodesic distance to the target trajectory prevents spurious zigzag paths and improves stealth. Standard PGD perturbs all locations equally, which can lead to zigzag trajectories as the attack satisfies multiple disjoint spatial locations. The distance-based weighting concentrates perturbation energy along the intended path, ensuring realistic weather perturbations are localized around the cyclone's path.

## Foundational Learning

- **Black-box vs. White-box Adversarial Attacks**
  - Why needed here: The core problem relies on the inability to access the internals of TempestExtremes, making standard PGD fail without a surrogate
  - Quick check question: Why can't we directly calculate ∇_Y with respect to the TempestExtremes output?

- **Class Imbalance (Focal Loss)**
  - Why needed here: The paper modifies standard loss functions to handle the rarity of TC events (<0.01%)
  - Quick check question: If you trained the surrogate with standard Cross-Entropy loss, what would likely happen to the True Positive Rate (TPR)?

- **Physical Constraints in Weather Data**
  - Why needed here: Unlike standard image attacks, weather data must preserve physical relationships
  - Quick check question: Does the ℓ∞ constraint guarantee that the resulting forecast is physically realistic, or just numerically close?

## Architecture Onboarding

- **Component map:** GraphCast (Frozen) -> Surrogate Model (DeepLabV3+) -> Attack Generator -> Constraint Modules
- **Critical path:** Pre-training the surrogate is the most sensitive step. If the surrogate has high FPR or fails to generalize, subsequent attack gradients will be noisy, leading to failed attacks or easily detectable anomalies.
- **Design tradeoffs:**
  - Dilation Radius (R): Small R yields high recall but scattered noise; large R smooths target but induces zigzagging
  - Perturbation Budget (δ): High δ increases attack success but lowers stealth
- **Failure signatures:**
  - High FPR / Scattered Noise: Surrogate trained without kernel dilation or focal loss
  - Zigzag Trajectories: Attack optimization lacking distance-based gradient weighting
  - Premature Termination: Calibration mask not correctly identifying surrogate mispredictions
- **First 3 experiments:**
  1. Surrogate Validation: Train with varying dilation radii (R ∈ {0, 1, 2, 5}) and plot TPR vs. FPR
  2. Ablation on Constraints: Run Cyc-Attack with and without distance-based weighting on single TC
  3. Stealth vs. Success Trade-off: Vary clipping threshold δ and measure correlation between DR and Anomaly Detection F1-score

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific defense strategies can effectively robustify deep learning weather forecasting (DLWF) models against gradient-based adversarial attacks targeting downstream tropical cyclone (TC) prediction?
- Basis in paper: The conclusion states future work includes developing strategies to robustify DLWF models against such adversarial attacks
- Why unresolved: The paper focuses exclusively on attack methodology rather than implementing or testing defense mechanisms
- What evidence would resolve it: Experiments demonstrating specific adversarial training or certification methods reduce Cyc-Attack success rate

### Open Question 2
- Question: Can more targeted attack strategies be developed to improve the accuracy of the end-to-end pipeline in fully replicating the intended adversarial trajectory?
- Basis in paper: Page 9 notes that while the current method demonstrates feasibility, "More targeted attack strategies for improved accuracy are left for future work"
- Why unresolved: The current approach successfully manipulates upstream forecasts but doesn't perfectly reconstruct the adversarial target when passed through DLWF model
- What evidence would resolve it: Modified attack algorithm yielding downstream trajectory with significantly higher IoU with target

### Open Question 3
- Question: Do the adversarial perturbations maintain thermodynamic consistency and physical realism in non-targeted weather variables?
- Basis in paper: The abstract lists "maintaining physical consistency in adversarially generated forecasts" as a challenge
- Why unresolved: The constraints applied are primarily geometric and statistical, not guaranteeing physical validity
- What evidence would resolve it: Physical consistency evaluation showing perturbed variables satisfy conservation laws

## Limitations
- Attack success depends on surrogate model's decision boundary closely matching the black-box detector
- ℓ∞ constraints don't guarantee physical realism of resulting weather fields
- Evaluation limited to 285 TC events from single dataset, limiting generalizability

## Confidence
- **High Confidence**: Surrogate training methodology and ability to approximate black-box detector
- **Medium Confidence**: Effectiveness of Cyc-Attack compared to baselines on TC2 dataset
- **Medium Confidence**: Stealthiness claims based on single anomaly detection method

## Next Checks
1. Cross-dataset transferability test: Apply methodology to independent TC dataset with different time period or geographic region
2. Physical constraint verification: Implement physics-based validation to check if perturbations violate conservation laws beyond ℓ∞ bounds
3. Defense evaluation: Test attack against simple adversarial training defenses to assess effectiveness under security hardening