---
ver: rpa2
title: 'Beyond Turn-taking: Introducing Text-based Overlap into Human-LLM Interactions'
arxiv_id: '2501.18103'
source_url: https://arxiv.org/abs/2501.18103
tags:
- chatbot
- overlap
- interactions
- typing
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces overlapping messages into text-based human-AI
  interactions, moving beyond traditional turn-taking. Through a formative study,
  the authors observed users naturally engage in overlapping behaviors like backchanneling
  and preemptive responses during text-based conversations.
---

# Beyond Turn-taking: Introducing Text-based Overlap into Human-LLM Interactions

## Quick Facts
- arXiv ID: 2501.18103
- Source URL: https://arxiv.org/abs/2501.18103
- Reference count: 40
- This paper introduces overlapping messages into text-based human-AI interactions, moving beyond traditional turn-taking.

## Executive Summary
This paper introduces overlapping messages into text-based human-AI interactions, moving beyond traditional turn-taking. Through a formative study, the authors observed users naturally engage in overlapping behaviors like backchanneling and preemptive responses during text-based conversations. Based on these insights, they developed OverlapBot, an LLM-powered chatbot capable of overlapping its typing with users through backchanneling and preemptive answering. A user study with 18 participants showed that OverlapBot was perceived as more communicative and immersive than traditional turn-taking chatbots, fostering faster and more natural interactions. The chatbot was trained using finetuned Llama3-8B, achieving 67% accuracy in timing classification and 85% accuracy in dialogue act classification.

## Method Summary
The researchers finetuned Llama3-8B using a combination of the Switchboard Dialogue Act Corpus (SWDA) and an instruction-tuning dataset (yahma/alpaca-cleaned). They modified the datasets to include overlap tags ([Overlap] vs [Await]) and dialogue act labels ([Understanding] vs [Answer]). The finetuning used parameter-efficient training (LoRA) to enable the model to classify when to overlap versus wait, and what type of overlap to use. The system was implemented with a Flask backend managing WebSocket connections, a frontend showing real-time typing, and a streaming inference loop for overlap decisions.

## Key Results
- OverlapBot was perceived as more communicative and immersive than traditional turn-taking chatbots
- The system achieved 67% accuracy in timing classification and 85% accuracy in dialogue act classification
- Participants naturally responded to OverlapBot's preemptive answering as if it were a form of active listening

## Why This Works (Mechanism)

### Mechanism 1: Real-Time Attentiveness Signaling via Preemptive Responses
- Claim: Users perceive a chatbot that provides preemptive responses as more attentive and engaged, similar to active listening in human-human conversation.
- Mechanism: The LLM continuously processes user keystrokes in real-time. When it infers enough context to form a relevant, brief response, it generates and displays it before the user completes their turn. This provides immediate feedback, allowing users to assess the system's comprehension and adjust their own input on the fly.
- Core assumption: Users naturally interpret an early, relevant response as a sign of active listening and understanding, drawing on conversational norms from human-human interaction.
- Evidence anchors:
  - [abstract] "observed that users instinctively engage in preemptive responses... OverlapBot was perceived as more communicative and immersive."
  - [section 5.1.2] "Participants naturally responded to OverlapBot's preemptive answering as if it were a form of active listening... used it to assess how well it understood the topic."
- Break condition: The mechanism fails if the LLM misinterprets partial input, generating a response that is irrelevant or disruptive to the user's train of thought, leading to frustration.

### Mechanism 2: Maintaining Conversational Flow via Backchanneling
- Claim: Brief, non-turn-taking responses (e.g., "uh-huh," "yeah") increase perceived chatbot presence and conversational naturalness without disrupting the primary speaker.
- Mechanism: The system is finetuned to recognize appropriate moments for backchanneling based on dialogue acts. It inserts these cues into the conversation stream without demanding a reply, mirroring cooperative overlap in human speech. This creates a sense of a "listening partner."
- Core assumption: The psychological effect of backchanneling in text chats parallels that in spoken conversation, reinforcing social presence and engagement.
- Evidence anchors:
  - [abstract] "users instinctively engage in overlapping behaviors like 'A: Today I went to-' 'B: yeah.'"
  - [section 5.1.2] "participants did not provide a verbal response to OverlapBot's backchanneling cues, they still recognized its presence, perceiving it as a sign of attentiveness."
- Break condition: Breakdown occurs if backchanneling is poorly timed or excessive, making it feel like an intrusion or noise rather than a supportive cue.

### Mechanism 3: User Control and Error Recovery via Interruption Handling
- Claim: Allowing users to interrupt the chatbot with brief commands and having the system gracefully recover (delete and regenerate) enhances feelings of control and interaction efficiency.
- Mechanism: The architecture detects user keystrokes during bot response generation. If a user sends a message, the system halts the current generation, discards it, and initiates a new response based on the user's interruption. This resolves competitive overlaps in favor of the user.
- Core assumption: In human-AI interaction, user interrupts are typically attempts to correct, redirect, or stop the AI, not cooperative contributions.
- Evidence anchors:
  - [abstract] "mechanisms for interruption handling... participants issued brief interruption commands."
  - [section 4.3] "the chatbot is programmed to delete its prior response... and generate a new one." Figure 5 illustrates this.
- Break condition: The mechanism fails if the regeneration is too slow, causing a noticeable lag that breaks conversational flow, or if the new response is inconsistent with the interrupted context.

## Foundational Learning

- Concept: **Cooperative vs. Competitive Overlap in Conversation**
  - Why needed here: The paper's design is built on distinguishing these two types. Cooperative overlap (backchanneling, terminal overlap) supports the current speaker, while competitive overlap (interruption) requires resolution. Understanding this is key to interpreting user and bot behaviors.
  - Quick check question: A user types "I think the best option isâ€”" and the bot immediately responds with "Option A?" Is this more likely cooperative or competitive overlap? Why?

- Concept: **Real-Time State Sharing in UI Design**
  - Why needed here: The core technical enabler is showing keystrokes as they happen. This transforms text chat from asynchronous messaging to a semi-synchronous shared workspace, creating opportunities for overlap.
  - Quick check question: What are two potential user experience drawbacks of making typing visible in real-time, as noted in the formative study?

- Concept: **Dialogue Act Classification for LLMs**
  - Why needed here: The system's intelligence depends on classifying user input in real-time into dialogue acts (e.g., question, statement) to decide *if* and *how* to overlap. This is a specialized NLP task beyond generic response generation.
  - Quick check question: Based on the paper's finetuning strategy, what three sequential decisions must the model make for each overlapping opportunity?

## Architecture Onboarding

- Component map:
  Frontend (UI) -> Backend Server (Flask) -> Overlap Decision Model (Finetuned Llama3-8B) -> Interruption Handler

- Critical path:
  User keystroke -> UI sends to backend -> Backend broadcasts to all clients (including bot's logic) -> **Overlap Decision Model** evaluates context -> IF `[Overlap]`, begins streaming response -> IF user sends message during stream -> **Interruption Handler** kills stream -> Model regenerates with new user message appended to context

- Design tradeoffs:
  1. **Response Brevity vs. Detail**: Training on conversational datasets leads to shorter, chatty responses. This enhances speed and flow but may be unsuitable for tasks requiring elaborate answers (e.g., analysis, coding). Tradeoff: engagement vs. task utility.
  2. **Overlap Frequency vs. User Intrusion**: The model must balance being responsive with allowing users to finish their thoughts. Too much overlap feels like an "annoying friend." Tradeoff: perceived attentiveness vs. user comfort.
  3. **Technical Latency vs. Perceived Speed**: Single-threaded response generation can cause delays after interruptions. The tradeoff is between implementation simplicity and maintaining the illusion of real-time fluidity.

- Failure signatures:
  1. **Premature Overlap**: Bot interrupts at an awkward point (e.g., completing a user's sentence incorrectly), disrupting thought. Sign: user immediately backspaces or sends a correction.
  2. **Unresponsive Backchanneling**: Bot provides backchannels that seem random or disconnected from user content, breaking the illusion of listening.
  3. **Interruption Hang**: After user interrupts, there's a long pause before the new response appears, breaking immersion.
  4. **Context Drift from Regeneration**: The regenerated response after interruption doesn't account for the partial bot message already seen by the user, causing confusion.

- First 3 experiments:
  1. **Timing Threshold Calibration**: Vary the number of characters or time delay before the bot considers an overlap. Measure user ratings of "intrusiveness" vs. "helpfulness" to find an optimal threshold.
  2. **Backchannel Utility Test**: In A/B tests, compare conditions with frequent backchannels, sparse backchannels, and none. Measure perceived chatbot "presence," "empathy," and task completion time.
  3. **Interruption Recovery Evaluation**: Simulate user interruptions at different points in bot response generation (short, medium, long). Measure regeneration latency and user subjective ratings of how "natural" the recovery felt.

## Open Questions the Paper Calls Out

- How does the utility of overlapping interactions vary between open-ended social dialogue and structured goal-oriented tasks?
  - Basis: The authors state this remains open for future research, noting overlap may be unsuitable for tasks like math or summarization.

- How do interaction dynamics change when overlapping chatbots are used by diverse age groups, particularly older adults?
  - Basis: The paper notes the participant pool lacked age diversity and explicitly calls for further research with older individuals.

- To what extent do cultural differences in conversational norms impact the acceptance of overlapping behaviors in text-based AI?
  - Basis: The authors identify "Culturally Adaptive Overlap" as a design insight and note future research could explore performance with diverse linguistic backgrounds.

## Limitations

- The study was conducted in a controlled lab environment with brief, casual conversations, limiting generalizability to task-oriented or emotionally charged dialogues.
- The 15-minute sessions prevent assessment of fatigue or annoyance from overlapping behaviors over extended periods.
- The paper does not explore how cultural communication norms or individual preferences affect the reception of overlapping AI interactions.

## Confidence

- **High Confidence**: The empirical finding that OverlapBot was perceived as more communicative and immersive than traditional chatbots.
- **Medium Confidence**: The claim that preemptive responses signal attentiveness and understanding.
- **Low Confidence**: The generalizability of the 67% timing classification accuracy and 85% dialogue act classification accuracy to real-world deployment.

## Next Checks

1. **Longitudinal Study**: Conduct a 2-week deployment study measuring user satisfaction, fatigue, and task completion rates with overlapping vs. turn-taking interactions across multiple conversation types.

2. **Cultural Variation Experiment**: Test the system with participants from different cultural backgrounds known to have varying conversational norms around overlap, measuring acceptance rates and perceived naturalness.

3. **Real-World Latency Simulation**: Evaluate the interruption handling mechanism under realistic network conditions (50-200ms latency) measuring regeneration delay and user perception of "natural" recovery across multiple interruption scenarios.