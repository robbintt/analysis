---
ver: rpa2
title: 'VisAgent: Narrative-Preserving Story Visualization Framework'
arxiv_id: '2503.02399'
source_url: https://arxiv.org/abs/2503.02399
tags:
- story
- image
- scene
- prompt
- prompts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: VisAgent addresses story visualization limitations by introducing
  a multi-agent framework that preserves narrative context while generating high-quality
  images. The core innovation lies in a story module that refines plain narratives
  into layered prompts using a three-act structure analysis, combined with an image
  module that separately generates foreground and background elements before integrating
  them through a semantic-aware cross-attention layer.
---

# VisAgent: Narrative-Preserving Story Visualization Framework

## Quick Facts
- arXiv ID: 2503.02399
- Source URL: https://arxiv.org/abs/2503.02399
- Authors: Seungkwon Kim; GyuTae Park; Sangyeon Kim; Seung-Hun Nam
- Reference count: 31
- Key outcome: Achieves TIS of 25.43% on VisAgent benchmark and 32.58% on CMIGBench while maintaining CCS of 83.76% and FID of 263.74

## Executive Summary
VisAgent introduces a multi-agent framework that preserves narrative context while generating high-quality story visualizations. The approach decomposes narratives using three-act structure analysis to create layered prompts, then generates foreground and background elements separately before integrating them through semantic-aware cross-attention. This preserves narrative flow and visual fidelity better than traditional event-based prompting methods.

## Method Summary
VisAgent uses a two-module approach with GPT-4o and LangGraph orchestration. The Story Module analyzes input narratives through three-act structure clustering, extracts scene descriptions and character attributes, and generates layered background/foreground prompts. The Image Module separately generates FG characters and BG scenes using SD v1.5 with IP-Adapter, determines layout through LMM-based scene locator, and integrates elements via Semantic-Aware Cross-Attention layer. The system includes human-in-the-loop feedback loops and reflection agents for quality control.

## Key Results
- TIS score of 25.43% on VisAgent benchmark and 32.58% on CMIGBench
- Character-Character Similarity (CCS) of 83.76% demonstrating character consistency
- FID score of 263.74 indicating reasonable image quality
- Outperforms baseline methods on narrative preservation metrics

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Three-act structure analysis preserves narrative context better than event-based prompting
- **Mechanism:** Decomposes stories into Setup, Conflict, Resolution phases, extracting scene descriptions and character attributes within each act to produce layered prompts
- **Core assumption:** Stories follow three-act structure and preserving this structure in prompts improves semantic alignment
- **Evidence anchors:** Story module uses three-act clustering for scene extraction; SCORE paper addresses coherence but focuses on detection
- **Break condition:** Non-linear or fragmentary stories may produce forced or irrelevant prompts

### Mechanism 2
- **Claim:** Separate FG/BG generation with semantic-aware cross-attention improves compositional fidelity
- **Mechanism:** Generates FG and BG independently, uses LMM for layout determination, integrates via modified cross-attention with text/image tokens and stitched image guidance
- **Core assumption:** Independent generation preserves detail quality and cross-attention can re-establish semantic coherence
- **Evidence anchors:** SA-CA layer aggregates BG, stitched image as reference; StoryAnchors addresses temporal consistency differently
- **Break condition:** Tight FG-BG visual interdependence (shadows, reflections) may create integration artifacts

### Mechanism 3
- **Claim:** Multi-agent collaboration with human feedback reduces hallucinations
- **Mechanism:** Specialized agents process sequential subtasks with user approval/rejection cycles and reflection agent validation
- **Core assumption:** Modular task decomposition catches errors that single-pass prompting misses
- **Evidence anchors:** User feedback agent allows modification of outputs; reflection agent compares prompts to story segments
- **Break condition:** Inconsistent or absent user feedback relies on LLM self-assessment

## Foundational Learning

- **Concept: Three-Act Narrative Structure**
  - **Why needed here:** Story module assumes stories can be decomposed into Setup, Conflict, Resolution phases
  - **Quick check question:** Given a story excerpt, can you identify which act it belongs to and what scene/character information should be extracted?

- **Concept: Cross-Attention in Diffusion Models**
  - **Why needed here:** SA-CA layer modifies standard cross-attention by aggregating multiple token sources
  - **Quick check question:** In diffusion model cross-attention, what do Query, Key, and Value represent, and how does the attention mask influence generation?

- **Concept: Multi-Agent Workflow Orchestration**
  - **Why needed here:** VisAgent uses LangGraph for agent coordination with conditional routing
  - **Quick check question:** In sequential agent pipeline with feedback loop, how should state be passed between agents?

## Architecture Onboarding

- **Component map:** Story Module (Scene extraction → Character extraction → User feedback → Prompt generation → Reflection) → Image Module (Scene element generator → Scene locator → Scene renderer) → LangGraph orchestration

- **Critical path:** Input story → Three-act clustering → Scene/character extraction → User approval → Layered prompt generation → Independent FG/BG generation → LMM layout → Stitched image → SA-CA rendering → Final output

- **Design tradeoffs:** Training-free vs. fine-tuned (flexibility vs. domain performance); Separate FG/BG vs. unified (detail fidelity vs. complexity); Human-in-the-loop vs. automated (quality vs. latency)

- **Failure signatures:** Missed narrative beats → irrelevant images; Character inconsistency → varying identities; λt misconfiguration → blurred composites; Scene locator errors → implausible placements

- **First 3 experiments:**
  1. Ablation on three-act structure: Compare prompts with vs. without three-act decomposition on held-out set
  2. SA-CA component analysis: Disable each SA-CA submodule individually and measure FID, CCS, TIS
  3. Feedback loop sensitivity: Run with user feedback at different stages to measure hallucination rates

## Open Questions the Paper Calls Out

- **Open Question 1:** How does three-act structure clustering perform on non-linear or experimental narratives?
  - **Basis:** Methodology assumes all stories rely on specific narrative structures
  - **Why unresolved:** Validated primarily on traditional stories, untested on fragmented or multi-timeline narratives
  - **What evidence would resolve it:** Evaluation on non-linear literature showing comparable metrics

- **Open Question 2:** How can TIS scores be significantly improved beyond current 25.43%?
  - **Basis:** Experimental results show TIS of 25.43% on VisAgent benchmark
  - **Why unresolved:** SA-CA improves over baselines but scores indicate substantial semantic information still lost
  - **What evidence would resolve it:** Modified attention mechanism achieving TIS above 50%

- **Open Question 3:** What is the computational latency and resource overhead of the multi-agent workflow?
  - **Basis:** Framework involves multiple LLMs, LMMs, and diffusion models that must collaborate
  - **Why unresolved:** Paper focuses on output quality but lacks inference time or token usage statistics
  - **What evidence would resolve it:** Comparison of average generation time per scene against standard pipelines

## Limitations

- Evaluation relies on two small benchmarks (400 LLM-generated stories) with no cross-dataset validation
- Framework's generalization to diverse narrative styles (non-Western, experimental, technical) remains untested
- Three-act structure assumption may degrade performance on fragmented or non-linear narratives

## Confidence

- **High confidence:** Core multi-agent architecture and workflow (High)
- **Medium confidence:** SA-CA layer improvements over standard cross-attention (Medium)
- **Medium confidence:** Three-act structure analysis improves narrative preservation (Medium)
- **Low confidence:** Claims about superiority over existing methods (Low)

## Next Checks

1. **Cross-dataset generalization test:** Evaluate on diverse narrative corpora to identify narrative types where three-act decomposition breaks down

2. **Three-act ablation study:** Implement without three-act clustering and measure performance degradation on VisAgent benchmark

3. **SA-CA architectural ablation:** Disable each SA-CA component individually on held-out test set to measure contribution to FID and CCS scores