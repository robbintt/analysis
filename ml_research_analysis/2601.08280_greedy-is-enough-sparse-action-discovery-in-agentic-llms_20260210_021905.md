---
ver: rpa2
title: 'Greedy Is Enough: Sparse Action Discovery in Agentic LLMs'
arxiv_id: '2601.08280'
source_url: https://arxiv.org/abs/2601.08280
tags:
- action
- actions
- latent
- theorem
- assumption
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies action selection in extremely large action spaces
  under a structured sparsity assumption, motivated by agentic systems with many available
  tools. It formulates a contextual linear reward model where only a small subset
  of actions influences performance across latent states, casting action discovery
  as a block-sparse recovery problem.
---

# Greedy Is Enough: Sparse Action Discovery in Agentic LLMs

## Quick Facts
- arXiv ID: 2601.08280
- Source URL: https://arxiv.org/abs/2601.08280
- Reference count: 5
- Primary result: Proves greedy block-sparse recovery exactly identifies relevant actions with sample complexity poly(k,d)·log(M), and shows sparsity is information-theoretically necessary

## Executive Summary
This paper addresses action selection in agentic LLMs operating over extremely large action spaces by exploiting a sparsity assumption: only a small subset of actions influences performance across latent states. It formulates action discovery as a block-sparse recovery problem where each action corresponds to a d-dimensional parameter block. Under standard incoherence, signal strength, and coverage conditions, a greedy algorithm inspired by Orthogonal Matching Pursuit exactly recovers the relevant action set with sample complexity scaling polynomially in sparsity and latent dimension, but only logarithmically in the total number of actions. Information-theoretic lower bounds establish that these rates are essentially optimal, proving sparsity is necessary for tractable action discovery in large action spaces.

## Method Summary
The method formulates action discovery as block-sparse recovery where each action's effect is represented as a d-dimensional parameter block. Using a contextual linear reward model, it analyzes a greedy algorithm (Contextual Block-OMP) that iteratively selects actions based on correlation with residuals and refits parameters via least squares. The approach proves exact recovery under incoherence, signal strength, and coverage assumptions, with sample complexity poly(k,d)·log(M). The paper also establishes information-theoretic lower bounds showing these rates are optimal.

## Key Results
- Greedy block-OMP algorithm exactly recovers relevant action set with high probability under standard assumptions
- Sample complexity scales as poly(k,d)·log(M), avoiding linear dependence on action space size
- Information-theoretic lower bounds show sparsity is necessary for tractable action discovery
- Recovery requires minimum signal strength and action coverage conditions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A greedy correlation-based algorithm can exactly recover the set of relevant actions from a massive action space.
- Mechanism: Contextual Block-OMP iteratively selects the action whose feature block has strongest correlation with the current residual (unexplained reward), then refits parameters via least squares and updates the residual. This exploits block-sparse structure: each action corresponds to a d-dimensional parameter block, and only k blocks are non-zero.
- Core assumption: Row-sparse action influence (Assumption 2.1) — only k ≪ M actions have non-zero parameter rows in W*.
- Evidence anchors:
  - [abstract]: "We formulate action discovery as a block-sparse recovery problem and analyze a greedy algorithm inspired by Orthogonal Matching Pursuit. Under standard assumptions on incoherence, signal strength, and action coverage, we prove that the greedy procedure exactly recovers the relevant action set with high probability."
  - [Section 3.3]: Selection step computes j_m = argmax_j ||Ψ_j^T u^(m-1)||_2, correlating feature blocks with residuals.
  - [corpus]: Deep greedy unfolding (arXiv:2505.15661) addresses greedy sparse recovery algorithms, confirming this is an established paradigm.
- Break condition: If block incoherence (Assumption 4.4) fails — i.e., irrelevant actions correlate strongly with relevant ones — greedy selection may pick wrong actions.

### Mechanism 2
- Claim: Sample complexity scales poly(k, d) · log(M), avoiding linear dependence on action space size.
- Mechanism: Sparsity reduces the effective parameter dimension from Md to kd. Incoherence ensures each relevant action's signature is distinguishable, so union bounds over M actions only incur log(M) cost. The proof (Step 6, Theorem 4.6) uses sub-Gaussian concentration with union bounds.
- Core assumption: Incoherence (μ < 1 in Assumption 4.4) and minimum signal strength (Assumption 4.5: min_j∈S* ||W*_j|| ≥ b_min).
- Evidence anchors:
  - [abstract]: "number of samples that scales polynomially in the sparsity level and latent dimension, and only logarithmically in the total number of actions."
  - [Theorem 4.6]: "provided T ≳ kd log M, with constants depending only on κ, Λ, L_z, L_ε, μ."
  - [corpus]: Sparse Nonparametric Contextual Bandits (arXiv:2503.16382) shows analogous sparsity benefits for regret bounds.
- Break condition: If signal strength b_min decays too fast relative to noise, condition (5) fails and noise dominates correlation scores.

### Mechanism 3
- Claim: Sparsity is information-theoretically necessary — without it, any method requires Ω(M) samples.
- Mechanism: Lower bound via Fano's method constructs many hypotheses differing only in support sets. Bounded KL divergence between hypotheses implies limited information per sample, requiring T ≥ c·kd·log(M/k) to distinguish supports.
- Core assumption: Hypothesis packing with symmetric difference ≥ k/2 (Varshamov-Gilbert bound).
- Evidence anchors:
  - [abstract]: "Information-theoretic lower bounds show that these rates are essentially optimal, establishing that sparsity is necessary for tractable action discovery."
  - [Theorem 5.1]: "exact recovery of S* with probability at least 2/3 requires T = Ω(kd log(M/k))."
  - [corpus]: Sparsity Is Necessary (arXiv:2601.08271) directly complements this with polynomial-time stability results.
- Break condition: N/A — this is a fundamental lower bound.

## Foundational Learning

- Concept: **Orthogonal Matching Pursuit (OMP)**
  - Why needed here: Core algorithm underlying Contextual Block-OMP; understanding residual-based selection and refitting is essential.
  - Quick check question: Can you explain why OMP orthogonalizes the residual after each selection rather than simply accumulating selected features?

- Concept: **Sub-Gaussian concentration**
  - Why needed here: High-probability bounds in Theorem 4.6 rely on sub-Gaussian tail bounds for design matrix concentration and noise control.
  - Quick check question: What is the tail bound for ||Σ_i z_i|| when each z_i is sub-Gaussian with covariance Σ_z?

- Concept: **Block-sparse recovery**
  - Why needed here: Parameters are structured as d-dimensional blocks per action, not individual scalars; selection operates on whole blocks.
  - Quick check question: How does block-sparsity change the sample complexity compared to element-wise sparsity?

## Architecture Onboarding

- Component map:
  - Latent state encoder -> Action feature extractor -> Block-OMP selector -> Least-squares refitter -> Decision rule

- Critical path:
  1. Collect dataset D_T = {(z_t, a_t, r_t)} with sufficient coverage (n_j ≥ n_min for relevant actions).
  2. Build design matrix Ψ with block structure Ψ_j ∈ R^{T×d} per action.
  3. Run k iterations of Block-OMP: correlate, select, refit, update residual.
  4. Output S_k as estimated relevant action set.

- Design tradeoffs:
  - Greedy vs. convex (LASSO-type): Greedy is anytime and interpretable; convex methods may be more robust to incoherence violations.
  - Known k vs. unknown k: Paper assumes k known; practice requires stopping criteria (e.g., residual threshold).
  - Coverage requirement: Must explore all potentially relevant actions; purely exploitative data collection violates Assumption 4.3.

- Failure signatures:
  - **False positives**: Incoherence violation (μ ≥ 1) causes irrelevant actions to correlate with residuals.
  - **False negatives**: Insufficient coverage (n_j too small) leaves relevant actions indistinguishable from zero (Theorem 5.2).
  - **Estimation blowup**: Poor conditioning (small λ_min(G_S*)) inflates refit error.

- First 3 experiments:
  1. **Synthetic validation**: Generate data with known S*, W*, and Gaussian z_t, ε_t. Verify exact recovery rate vs. T and M. Check sample complexity scaling matches kd log M.
  2. **Coverage ablation**: Deliberately undersample one relevant action (set n_j < d). Measure probability of missing that action in S_est.
  3. **Incoherence stress test**: Construct action features with high cross-correlation (μ → 1). Observe recovery degradation and characterize failure modes.

## Open Questions the Paper Calls Out

None

## Limitations

- Theoretical analysis relies on strong assumptions including exact sparsity, incoherence, and sufficient action coverage that may not hold in practical agentic LLM settings
- Incoherence condition may be violated when actions have semantically similar effects or when latent state representations conflate distinct action types
- Assumes exact sparsity rather than approximate or group sparsity, which may be too restrictive for real-world reward functions where actions have small but non-zero effects

## Confidence

- **High confidence**: The information-theoretic lower bound (Theorem 5.1) is rigorous and establishes fundamental limits; the block-sparse formulation and its connection to existing OMP theory are well-established
- **Medium confidence**: The sample complexity bounds (Theorem 4.6) are sound given the assumptions, but the constants and practical tightness remain to be validated empirically; the greedy algorithm's performance in noisy, approximate-sparse settings is uncertain
- **Low confidence**: The real-world applicability of exact sparsity and incoherence conditions to agentic LLM action spaces, where action effects may be distributed and correlated

## Next Checks

1. **Empirical coherence sensitivity**: Systematically vary the correlation structure between action feature blocks in synthetic experiments to map the boundary between successful and failed recovery, quantifying the practical meaning of the μ < 1 condition

2. **Approximate sparsity regime**: Test the algorithm when the true W* has small but non-zero entries for some irrelevant actions, measuring degradation in recovery accuracy and whether modified stopping criteria improve performance

3. **Dynamic action space extension**: Evaluate whether the greedy recovery framework extends to settings where new actions are introduced during deployment, requiring incremental recovery rather than batch processing of fixed M