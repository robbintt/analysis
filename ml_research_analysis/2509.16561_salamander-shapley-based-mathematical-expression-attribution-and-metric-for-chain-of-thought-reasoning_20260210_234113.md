---
ver: rpa2
title: 'SalaMAnder: Shapley-based Mathematical Expression Attribution and Metric for
  Chain-of-Thought Reasoning'
arxiv_id: '2509.16561'
source_url: https://arxiv.org/abs/2509.16561
tags:
- cosp
- expressions
- shapley
- cosp-0
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes a unified framework SalaMAnder to understand\
  \ and quantify the contributions of different components in Chain-of-Thought (CoT)\
  \ reasoning for large language models (LLMs). The core idea is to leverage Shapley\
  \ values for attribution at the mathematical expression level and develop an efficient\
  \ stratified sampling algorithm that reduces computational complexity from O(2^n)\
  \ to O(2mn\xB2)."
---

# SalaMAnder: Shapley-based Mathematical Expression Attribution and Metric for Chain-of-Thought Reasoning

## Quick Facts
- arXiv ID: 2509.16561
- Source URL: https://arxiv.org/abs/2509.16561
- Authors: Yue Xin; Chen Shen; Shaotian Yan; Xiaosong Yuan; Yaoming Wang; Xiaofeng Zhang; Chenxi Huang; Jieping Ye
- Reference count: 27
- Primary result: Introduces SalaMAnder framework using Shapley values for mathematical expression attribution in CoT reasoning, achieving correlation coefficients up to 0.76 between CoSP metric and model accuracy.

## Executive Summary
This paper proposes a unified framework called SalaMAnder to understand and quantify the contributions of different components in Chain-of-Thought (CoT) reasoning for large language models. The core innovation leverages Shapley values for attribution at the mathematical expression level and develops an efficient stratified sampling algorithm that reduces computational complexity from O(2^n) to O(2mn²). The authors introduce the CoSP metric, which measures the cardinality of Shapley positives and establishes a monotonic correlation with model performance through rigorous covariance analysis. Experiments across multiple models and datasets demonstrate that CoSP exhibits strong positive correlation with accuracy, achieving correlation coefficients as high as 0.76.

## Method Summary
The SalaMAnder framework treats mathematical expressions as atomic attribution units and applies Shapley value theory to quantify each expression's marginal contribution to model performance. The method uses stratified sampling by component order to achieve exponential complexity reduction, reducing computation from O(2^n) to O(2mn²) where m is sample count and n is expression count. The value function combines averaged log-probabilities of output tokens with binary correctness, and the CoSP metric counts expressions with positive average Shapley values. The framework includes an efficient SalaMA algorithm that maintains a hash table for memoization and computes Shapley values through order-stratified subset sampling.

## Key Results
- Achieves correlation coefficients as high as 0.76 (LLaMA-2 on GSM8K) between CoSP metric and model accuracy
- Reduces computational complexity from O(2^n) to O(2mn²) using stratified sampling by component order
- Demonstrates CoSP-0 (ignoring negative contributions) provides the best interpretation across most model-dataset combinations
- Validates framework across multiple models (LLaMA-2, LLaMA-3, Qwen2.5) and datasets (GSM8K, MathQA, AQUA, MultiArith, SVAMP)

## Why This Works (Mechanism)

### Mechanism 1
Mathematical expressions as atomic attribution units outperform token-level analysis for CoT reasoning attribution. The framework treats complete mathematical expressions as indivisible players in a cooperative game, applying Shapley value attribution to quantify each expression's marginal contribution. This aggregation preserves semantic coherence that token-level analysis fragments, while reducing the number of components from potentially hundreds of tokens to typically 4-16 expressions.

### Mechanism 2
The CoSP metric exhibits a theoretically grounded monotonic positive correlation with model accuracy. CoSP counts expressions with positive average Shapley values (minus weighted non-positive counts). Under assumptions that positive contributions have lower bound δ⁺ > 0 and negative contributions have bound δ⁻ < 0, covariance analysis proves Cov(Performance, CoSP-0) = (δ⁺ - δ⁻)ΣVar(Xi) > 0, establishing CoSP as a performance-aligned metric rather than a heuristic.

### Mechanism 3
Stratified sampling by component order achieves exponential complexity reduction while maintaining estimation accuracy. The SalaMA algorithm decomposes Shapley computation by order r, sampling only sp = min(m, C(n-1,r-1)) subsets per order rather than enumerating all 2^n subsets. This reduces complexity from O(2^n⁺¹) to O(2mn²) where m is sample count and n is expression count.

## Foundational Learning

- **Shapley Values (Cooperative Game Theory)**: Why needed here: The entire attribution framework rests on Shapley's axiomatic fair allocation scheme. Without understanding the four properties (linearity, dummy, symmetry, efficiency), the meaning of "contribution" is opaque. Quick check: Given players {A, B, C} with coalition values v({A})=10, v({B})=15, v({A,B})=30, what is A's marginal contribution when joining {B}?

- **Chain-of-Thought Prompting Mechanics**: Why needed here: The method assumes familiarity with few-shot CoT demonstrations and how they're constructed. The reward function v(S) evaluates model performance when only subset S of expressions is included. Quick check: In a 4-shot CoT demonstration, if you remove 2 expressions from the third example, how does this differ from removing all expressions from that example?

- **Model Logits as Confidence Proxies**: Why needed here: The reward function combines averaged log-probabilities of output tokens with binary correctness. Understanding why logits capture "confidence" beyond accuracy is essential for interpreting value function design. Quick check: Why might a model have high log-probability for an incorrect answer, and how does the indicator function I(y_pred = y*) address this?

## Architecture Onboarding

- **Component map**: Expression Extractor -> SalaMA Sampler -> Value Function Evaluator -> Shapley Aggregator -> CoSP Calculator
- **Critical path**: Expression extraction → Subset sampling (order r) → Model inference for v(S∪{i}) and v(S) → Marginal contribution accumulation → Repeat across orders and samples → Average to get ϕ̄(i) → Compute CoSP → Correlate with accuracy
- **Design tradeoffs**: λ penalty hyperparameter (λ=0 ignores negatives, λ=1 penalizes equally), sample count m (higher m improves accuracy but increases compute), expression granularity (finer parsing increases n creating exponential blowup)
- **Failure signatures**: Hash collision or cache invalidation (exact subset matching required), all negative Shapley values (CoSP-1 becomes negative, correlation may invert), zero variance in Xi (covariance formula collapses)
- **First 3 experiments**: 1) Validate complexity-accuracy tradeoff by sweeping m ∈ {5, 15, 25, 35} for fixed demonstration (n=6-8) and compute relative error vs. exact Shapley; 2) CoSP correlation sanity check by constructing 10 demonstrations with varying expression counts and computing Pearson r > 0.3 on GSM8K test subset; 3) Ablation on reward function comparing v(S) = accuracy_only vs. logits_only vs. combined

## Open Questions the Paper Calls Out

- **Open Question 1**: Can the SalaMAnder framework and CoSP metric maintain their efficacy when applied to non-mathematical reasoning tasks? The authors state in the Limitations section: "While SalaMAnder is theoretically a general approach, we are currently focusing on mathematical reasoning problems... In the future we aim to expand the application of SalaMAnder to a broader array of tasks." This remains unresolved because the methodology relies on identifying "mathematical expressions" as atomic units, and it's unclear how to define atomic units in domains lacking formal syntactic structures.

- **Open Question 2**: Does the monotonic correlation between CoSP and model performance hold for LLMs with parameter scales significantly larger than 13B or smaller than 7B? The authors note in the Limitations section that "due to computational resource constraints, our experiments are currently confined to LLMs with a parameter scale between 7 billion and 13 billion." It's unknown if the correlation coefficients and theoretical guarantees scale effectively to much larger models or smaller models.

- **Open Question 3**: How does treating natural language text as a constant "whiteboard" impact the completeness and faithfulness of the attribution? Section 3.2 and the algorithm description note that non-mathematical components are treated as a "whiteboard" that "always present and remain constant across different subsets." This assumption ignores the potential semantic influence of connecting words or sentence structure on the model's reasoning path.

## Limitations

- Computational scalability: The exponential complexity reduction only materializes when m ≪ 2^n/n², potentially becoming prohibitive for demonstrations with n > 15 expressions
- Statistical assumptions validation: The CoSP correlation proof relies on three specific assumptions about Shapley value distributions that are stated but not empirically validated across datasets
- Expression granularity ambiguity: The paper doesn't specify precise rules for what constitutes an atomic mathematical expression, affecting reproducibility

## Confidence

- **High Confidence**: The computational complexity analysis is mathematically sound and the stratification approach is well-defined
- **Medium Confidence**: The experimental results showing correlation coefficients up to 0.76 appear robust for the tested configurations (n ≤ 7, m ≈ 25)
- **Low Confidence**: The theoretical proof of CoSP's monotonic correlation with accuracy depends heavily on unverified statistical assumptions

## Next Checks

1. **Scalability Stress Test**: Replicate Table 3's accuracy-complexity tradeoff for n = 8, 9, 10, 11 with m ∈ {10, 20, 30, 40}. Plot relative error vs. m/n² to identify the scaling regime where stratified sampling breaks down.

2. **Assumption Violation Analysis**: For GSM8K and MathQA, compute empirical distributions of Shapley values and test the three key assumptions: (a) positive contributions have significant lower bound δ⁺ > 0.1, (b) non-positive contributions have upper bound δ⁻ > -0.1, (c) expression contributions are uncorrelated across problems (Pearson correlation < 0.3).

3. **Expression Boundary Sensitivity**: Create three different expression extraction schemes (fine-grained: each atomic operation; medium: complete equations; coarse: multi-step derivations) and measure how CoSP correlation varies across them to quantify the impact of the unspecified granularity decision.