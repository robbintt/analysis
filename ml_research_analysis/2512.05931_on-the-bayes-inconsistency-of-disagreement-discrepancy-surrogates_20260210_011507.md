---
ver: rpa2
title: On the Bayes Inconsistency of Disagreement Discrepancy Surrogates
arxiv_id: '2512.05931'
source_url: https://arxiv.org/abs/2512.05931
tags:
- surrogate
- disagreement
- discrepancy
- loss
- error
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work identifies a fundamental flaw in existing methods for
  maximizing disagreement discrepancy, showing that current surrogate losses are not
  Bayes consistent and can fail to optimize the true objective. The authors develop
  a novel disagreement loss that, when combined with cross-entropy, yields the first
  provably consistent surrogate for disagreement discrepancy.
---

# On the Bayes Inconsistency of Disagreement Discrepancy Surrogates
## Quick Facts
- arXiv ID: 2512.05931
- Source URL: https://arxiv.org/abs/2512.05931
- Reference count: 40
- Primary result: Identifies fundamental Bayes inconsistency in existing disagreement discrepancy surrogates and proposes a novel consistent alternative

## Executive Summary
This paper reveals a critical flaw in current methods for maximizing disagreement discrepancy in uncertainty estimation and out-of-distribution detection. The authors demonstrate that existing surrogate losses are not Bayes consistent, meaning they fail to optimize the true disagreement discrepancy objective. They introduce a novel disagreement loss that, when combined with cross-entropy, provides the first provably consistent surrogate for this task. Their method achieves superior accuracy and robustness, particularly under adversarial conditions, and improves error bound calibration for detecting harmful distribution shifts.

## Method Summary
The authors develop a new disagreement loss that addresses the Bayes inconsistency problem in existing surrogates. The proposed method combines this novel loss with cross-entropy in a unified framework, creating a surrogate that is provably Bayes consistent. The approach leverages the properties of binary classification to construct a surrogate that properly captures disagreement between multiple models or ensemble members. The method is evaluated against existing approaches across multiple datasets and under various adversarial perturbation scenarios.

## Key Results
- The proposed surrogate achieves maximum disagreement discrepancy in approximately 80% of tested scenarios
- Demonstrates superior robustness when target data is adversarially perturbed
- Provides more accurate and robust estimates than existing approaches
- Improves error bound calibration and detection of harmful distribution shifts

## Why This Works (Mechanism)
The proposed method works by directly addressing the fundamental Bayes inconsistency in existing disagreement discrepancy surrogates. By designing a novel loss function that is provably Bayes consistent when combined with cross-entropy, the method ensures that optimization of the surrogate directly optimizes the true disagreement discrepancy objective. This consistency guarantee allows the method to properly capture model disagreement and uncertainty, leading to more reliable detection of distribution shifts and adversarial examples.

## Foundational Learning
- Bayes consistency: Why needed - ensures surrogate loss optimization leads to optimal decision rule; Quick check - verify that the proposed loss converges to Bayes optimal solution as sample size increases
- Disagreement discrepancy: Why needed - measures uncertainty and potential for disagreement between models; Quick check - confirm that the surrogate properly captures disagreement between ensemble members
- Cross-entropy loss: Why needed - standard classification loss that the new method builds upon; Quick check - ensure proper combination with disagreement loss maintains classification accuracy
- Adversarial perturbations: Why needed - stress test for robustness of uncertainty estimation; Quick check - verify performance degrades gracefully under increasing perturbation strength

## Architecture Onboarding
Component map: Cross-entropy loss -> Disagreement loss -> Combined objective -> Model training -> Disagreement discrepancy estimation

Critical path: The combined loss function guides model training, which produces ensemble members whose disagreements are measured to estimate discrepancy. This discrepancy estimation is the final output used for uncertainty quantification and distribution shift detection.

Design tradeoffs: The method trades additional computational complexity (training with combined loss) for theoretical guarantees and improved robustness. The combined loss may require careful tuning of the relative weights between cross-entropy and disagreement components.

Failure signatures: If Bayes consistency is not achieved, the method may fail to properly capture true disagreement, leading to overconfident predictions even when models disagree. Poor calibration of the disagreement loss weight can result in either degraded classification performance or insufficient emphasis on disagreement.

First experiments:
1. Compare disagreement discrepancy estimates between the proposed method and existing surrogates on a simple binary classification problem with known distribution shift
2. Evaluate the impact of the disagreement loss weight on both classification accuracy and disagreement estimation quality
3. Test robustness under controlled adversarial perturbations with varying strength levels

## Open Questions the Paper Calls Out
The paper identifies several open questions, particularly regarding the extension of the proposed method to multi-class classification problems and other domains beyond binary classification. The authors note that the interaction between the disagreement loss and cross-entropy requires further exploration, especially concerning optimization stability and computational efficiency. Additionally, the real-world applicability of the method beyond controlled adversarial perturbation experiments remains to be fully established.

## Limitations
- Empirical validation relies heavily on adversarial perturbation experiments that may not represent real-world distribution shifts
- Primary focus on binary classification settings limits generalizability to multi-class problems
- Theoretical guarantees depend on assumptions about underlying data distributions that may not hold in practice

## Confidence
- High confidence in the theoretical analysis demonstrating Bayes inconsistency of existing surrogates
- Medium confidence in the empirical superiority claims, particularly regarding the 80% success rate
- Medium confidence in the robustness claims under adversarial conditions

## Next Checks
1. Test the proposed method on real-world distribution shift benchmarks (e.g., WILDS, PACS) to validate robustness claims beyond adversarial perturbations
2. Evaluate the method's performance on multi-class classification problems and regression tasks to assess generalizability
3. Conduct ablation studies to quantify the contribution of the disagreement loss versus cross-entropy in the combined objective