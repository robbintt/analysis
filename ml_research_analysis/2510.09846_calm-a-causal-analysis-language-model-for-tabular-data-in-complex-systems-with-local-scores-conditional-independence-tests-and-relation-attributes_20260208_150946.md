---
ver: rpa2
title: 'CALM: A Causal Analysis Language Model for Tabular Data in Complex Systems
  with Local Scores, Conditional Independence Tests, and Relation Attributes'
arxiv_id: '2510.09846'
source_url: https://arxiv.org/abs/2510.09846
tags:
- causal
- data
- relationships
- datasets
- conditional
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CALM, a novel causal analysis language model
  designed to address limitations in existing causal discovery methods when applied
  to complex tabular data. CALM leverages a Mamba-based architecture to classify causal
  patterns from pairwise variable relationships, integrating local causal scores,
  conditional independence tests, and relational attributes.
---

# CALM: A Causal Analysis Language Model for Tabular Data in Complex Systems with Local Scores, Conditional Independence Tests, and Relation Attributes

## Quick Facts
- arXiv ID: 2510.09846
- Source URL: https://arxiv.org/abs/2510.09846
- Reference count: 0
- Primary result: >91% accuracy in simulation studies; successfully identifies causal factors in Hepatitis C virus progression

## Executive Summary
This paper introduces CALM, a novel causal analysis language model designed to address limitations in existing causal discovery methods when applied to complex tabular data. CALM leverages a Mamba-based architecture to classify causal patterns from pairwise variable relationships, integrating local causal scores, conditional independence tests, and relational attributes. Trained on a diverse corpus of synthetic and real-world biological datasets, CALM demonstrates superior performance compared to existing methods, achieving over 91% accuracy in simulation studies and successfully identifying causal factors in Hepatitis C virus progression in a real-world application. This work represents a significant step towards accurate and generalizable causal discovery by adapting language models to tabular data.

## Method Summary
CALM tackles pairwise causal classification (edge existence and direction) to construct a Directed Acyclic Graph (DAG) from tabular data. Instead of using raw data, it operates on a "score data matrix" containing features derived from local causal scores (ANM, BIC), conditional independence tests (Fisher-Z, HSIC, KCI), and relational attributes (linearity, data types) for each variable pair. The model uses a Mamba-based architecture with periodic linear encodings for numerics and distinct vocabularies for categoricals. It is trained using binary cross-entropy loss on a combination of synthetic datasets (1,500 samples × 50 variables) and real-world biological sets. After classification, edges are assembled into a graph and cycles are removed based on confidence scores.

## Key Results
- Achieved over 91% accuracy in simulation studies across multiple synthetic datasets
- Outperformed existing methods (PC, FCI, GES) in both synthetic and real-world Hepatitis C virus progression datasets
- Successfully identified causal factors in complex biological systems using only tabular data

## Why This Works (Mechanism)
CALM works by transforming the causal discovery problem into a pairwise classification task where each potential edge is scored based on statistical tests and relationship attributes. The Mamba architecture is particularly suited for this task because it can process sequential score features while maintaining selective state memory, allowing it to capture complex patterns in the relationship between variables. By training on diverse datasets with known ground truth structures, the model learns to distinguish true causal relationships from spurious correlations based on the statistical signatures encoded in the feature matrix.

## Foundational Learning
1. **Selective State Space Models (Mamba)**: A neural architecture that processes sequential data with selective state updates, offering advantages over attention-based models for long sequences.
   - Why needed: Provides efficient sequence modeling for the score matrix features
   - Quick check: Verify that the model can process sequences longer than typical attention models

2. **Conditional Independence Testing**: Statistical methods to determine if variables are independent given other variables, fundamental for causal discovery.
   - Why needed: Forms the basis for many of the features used as input to CALM
   - Quick check: Confirm that Fisher-Z, HSIC, and KCI tests are implemented correctly

3. **Periodic Linear Encodings**: A method for representing numerical features in a way that preserves periodicity and order information.
   - Why needed: Enables the model to understand numerical relationships in the score features
   - Quick check: Verify that numerical embeddings capture the intended periodic structure

4. **Directed Acyclic Graph Construction**: The process of building a causal graph from pairwise classifications while ensuring acyclicity.
   - Why needed: The ultimate goal is to produce a valid causal DAG, not just pairwise classifications
   - Quick check: Verify that the final graph is acyclic and structurally sound

## Architecture Onboarding

**Component Map:** Score Collection -> Feature Matrix -> Mamba Encoder -> Pairwise Classifier -> Edge Assembly -> Cycle Removal

**Critical Path:** The score collection and feature engineering pipeline is the critical path, as it must be completed before any model training can occur. Computing all statistical tests for every variable pair is O(n²) in complexity.

**Design Tradeoffs:** CALM trades the flexibility of end-to-end learning from raw data for the interpretability and efficiency of working with engineered statistical features. This allows it to leverage domain knowledge about causal discovery while still benefiting from deep learning's pattern recognition capabilities.

**Failure Signatures:** 
- NaN losses during early training suggest numerical instability in the Mamba implementation
- Poor accuracy on synthetic data with known ground truth indicates issues with feature engineering or model architecture
- Cycles remaining in the final DAG suggest problems with the confidence scoring or cycle removal logic

**3 First Experiments:**
1. Implement and validate the score collection pipeline on a small dataset (e.g., 10 variables) to ensure all statistical tests are correctly computed
2. Train a simplified Mamba model (fewer layers, smaller state dimension) on a minimal dataset to verify the architecture can learn the task
3. Test the cycle removal logic on a synthetic graph with known cycles to verify it produces acyclic outputs

## Open Questions the Paper Calls Out
1. **Scalability to High-Dimensional Data:** The paper's simulation studies were limited to 50–90 variables, while many real-world complex systems involve thousands of variables. The quadratic complexity of the score collection process may become prohibitive at larger scales.

2. **Comparison to Deep Learning Baselines:** While the introduction critiques deep learning approaches like NOTEARS and DAG-GNN, the experimental results only compare against constraint-based methods (PC, FCI) and GES, omitting direct comparison to these specific architectures.

3. **Generalization Beyond Biology:** Since CALM was trained exclusively on synthetic data and biological datasets, its performance on non-biological domains (social sciences, finance) remains uncertain, particularly given the specialized nature of the "contextual attributes" it learned.

## Limitations
- Missing training hyperparameters (learning rate, scheduler, weight decay) make exact reproduction difficult
- Limited evaluation to biological datasets raises questions about generalizability to other domains
- Reliance on pairwise classification followed by post-hoc cycle removal may not scale well to larger graphs
- No comparison to deep learning baselines (NOTEARS, DAG-GNN) that were critiqued in the introduction

## Confidence
Our confidence in the paper's core claims is **Medium**. The methodology is technically detailed, but several critical implementation details are omitted, making faithful reproduction challenging.

## Next Checks
1. **Feature Reproducibility Audit:** Re-implement the score collection pipeline (Fisher-Z, HSIC, ANM, BIC variants) and verify consistency with published results on a small, controlled dataset (e.g., the Linear Fisher simulator)

2. **Architecture Fidelity Test:** Train a simplified version of the CALM model (e.g., fewer layers, smaller state dim) on a minimal dataset to confirm that the Mamba architecture with periodic embeddings can learn the task, even if final performance is lower

3. **Cycle Removal Strategy Validation:** Conduct ablation studies comparing different cycle removal strategies (lowest score pruning vs. NOTEARS-style differentiable acyclicity) on a fixed dataset to assess their impact on the final DAG structure and performance metrics