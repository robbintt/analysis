---
ver: rpa2
title: 'GAP: Graph-Based Agent Planning with Parallel Tool Use and Reinforcement Learning'
arxiv_id: '2510.25320'
source_url: https://arxiv.org/abs/2510.25320
tags:
- reasoning
- arxiv
- execution
- search
- tool
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GAP (Graph-based Agent Planning), a novel
  framework that addresses the limitation of sequential tool execution in existing
  LLM-based agents by explicitly modeling task dependencies through graph-based planning.
  The key innovation is training agents to decompose complex queries into dependency-aware
  subtask graphs, enabling parallel execution of independent tools while respecting
  sequential constraints for dependent tasks.
---

# GAP: Graph-Based Agent Planning with Parallel Tool Use and Reinforcement Learning

## Quick Facts
- arXiv ID: 2510.25320
- Source URL: https://arxiv.org/abs/2510.25320
- Reference count: 40
- Key outcome: GAP achieves 0.9% average improvement on multi-hop reasoning tasks while reducing interaction turns by up to 33.4% and response length by 24.9% compared to state-of-the-art baselines.

## Executive Summary
GAP (Graph-based Agent Planning) introduces a novel framework that overcomes the sequential tool execution bottleneck in existing LLM-based agents by explicitly modeling task dependencies through graph-based planning. The approach decomposes complex queries into dependency-aware subtask graphs, enabling parallel execution of independent tools while respecting sequential constraints for dependent tasks. Using a two-stage training strategy combining supervised fine-tuning on 7,000 curated graph-planning traces with reinforcement learning on correctness-based rewards, GAP demonstrates significant efficiency gains without sacrificing accuracy on multi-hop reasoning benchmarks.

## Method Summary
GAP represents task dependencies as directed acyclic graphs (DAGs), where nodes represent sub-tasks and edges indicate output dependencies. The framework uses topological sorting to determine execution levels, enabling parallel execution of independent sub-tasks within each level. Training occurs in two stages: first, supervised fine-tuning on a curated dataset of 7,000 high-quality graph-planning traces from multi-hop QA benchmarks establishes the structural decomposition patterns; second, reinforcement learning with binary correctness rewards refines the policy for optimal parallel execution. The approach shows strong generalization across both in-domain and out-of-domain datasets.

## Key Results
- 0.9% average accuracy improvement on multi-hop reasoning tasks compared to state-of-the-art baselines
- 33.4% reduction in interaction turns (1.78 vs 2.27 turns) on HotpotQA
- 24.9% reduction in response length (74.7 vs 99.5 tokens) while maintaining accuracy

## Why This Works (Mechanism)

### Mechanism 1: Graph-Based Dependency Modeling Enables Parallel Execution
The model explicitly represents task dependencies as DAGs, allowing identification and concurrent execution of independent sub-tasks. By parsing queries into sub-tasks and drawing directed edges only where output dependencies exist, the absence of edges signals parallelizability. This reduces sequential bottlenecking that plagues traditional sequential approaches.

### Mechanism 2: Two-Stage Training Aligns Graph Planning with Task Success
Supervised fine-tuning on 7,000 curated graph-planning traces teaches structural decomposition patterns, while reinforcement learning with binary correctness rewards optimizes for successful outcomes. This combination ensures the model learns both how to decompose tasks and when to parallelize effectively.

### Mechanism 3: Level-Wise Batched Execution Reduces Interaction Overhead
After graph construction, nodes are assigned to execution levels via topological sorting. All tools within the same level execute simultaneously, with the model waiting for all observations before proceeding. This batching approach significantly reduces the number of interaction turns and token generation required.

## Foundational Learning

- **Directed Acyclic Graphs (DAGs) & Topological Sorting**
  - Why needed here: GAP uses DAGs to represent task dependencies; topological sorting determines execution levels for parallelization.
  - Quick check question: Given tasks A→C, B→C, can A and B run concurrently? (Answer: Yes—no edge between A and B.)

- **Reinforcement Learning with Policy Gradients (e.g., DAPO)**
  - Why needed here: Post-SFT, GAP uses RL to optimize for correctness; understanding reward shaping and policy updates is critical.
  - Quick check question: Why might a sparse binary reward (0/1) require careful cold-start initialization? (Answer: Low signal density can hinder exploration without a strong prior.)

- **Tool-Integrated Reasoning (TIR) & ReAct Paradigm**
  - Why needed here: GAP extends ReAct-style sequential reasoning with graph-based planning; familiarity with thought-action-observation loops is assumed.
  - Quick check question: In ReAct, what triggers the next action? (Answer: The model conditions on prior thought, action, and observation history.)

## Architecture Onboarding

- **Component map**: Query → Planning (graph generation) → Parsing & level computation → Level-wise batched execution → Observation aggregation → Answer synthesis
- **Critical path**: Query → Planning (graph generation) → Parsing & level computation → Level-wise batched execution → Observation aggregation → Answer synthesis. Failures in graph parsing or dependency misidentification cascade to incorrect execution.
- **Design tradeoffs**: Parallelism vs. overhead (finer-grained sub-tasks increase parallelism but raise coordination complexity); SFT data quality vs. scale (7,000 filtered traces prioritized quality); Binary reward vs. richer signals (correctness-only reward is simple but may not optimize efficiency).
- **Failure signatures**: Incorrect dependencies (model marks independent tasks as dependent → unnecessary serialization); Missing dependencies (model fails to model edges → parallel execution produces invalid results); Parsing errors (malformed `<graph>` output → execution engine cannot determine levels); Tool contention (parallel calls hit rate limits → degraded or failed retrieval).
- **First 3 experiments**: 1) Ablate parallel execution: Force sequential execution of GAP plans; measure turn count and latency increase to isolate parallelism gains. 2) Vary graph complexity: Evaluate on queries requiring 2 vs. 4 vs. 6+ sub-tasks; assess whether accuracy and efficiency gains scale with complexity. 3) SFT-only vs. SFT+RL: Train GAP with SFT alone; compare to full two-stage training to quantify RL's contribution to correctness and efficiency.

## Open Questions the Paper Calls Out

None specified in the provided content.

## Limitations

- **Domain specificity**: Framework assumes tasks decompose cleanly into discrete sub-tasks with explicit dependencies; ambiguous requirements or non-deterministic tool behavior may not fit this model.
- **Parallel execution constraints**: Assumes external tools support concurrent invocation without resource contention; rate limiting or shared state dependencies could degrade performance.
- **Reward design limitations**: Binary correctness rewards provide limited guidance for optimizing efficiency; multi-objective rewards are acknowledged as future work but not implemented.

## Confidence

- **High confidence**: Graph-based planning mechanism and topological sorting are well-established techniques with clear algorithmic descriptions; 0.9% accuracy improvement is supported by experimental results across seven benchmarks.
- **Medium confidence**: Two-stage training approach is theoretically sound but RL contribution is harder to isolate from ablation study; 33.4% reduction in interaction turns and 24.9% reduction in response length are substantial claims requiring independent verification.
- **Low confidence**: Generalization claims across in-domain and out-of-domain datasets need more scrutiny; paper mentions strong generalization but provides limited analysis of performance degradation on truly unseen task distributions.

## Next Checks

1. **Ablation on graph complexity**: Systematically evaluate performance across tasks requiring 2, 4, 6+ sub-tasks to determine whether efficiency and accuracy gains scale with task complexity, or if benefits plateau beyond certain complexity thresholds.

2. **Stress test on tool contention**: Design experiments where parallel tool invocations face realistic rate limits and resource contention to assess robustness and identify failure modes in practical deployment scenarios.

3. **Reward shaping analysis**: Implement and evaluate alternative reward functions that directly optimize for efficiency (e.g., penalizing excessive turns or token generation) to quantify the impact of binary correctness rewards on overall system performance.