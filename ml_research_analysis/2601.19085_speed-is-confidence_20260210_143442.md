---
ver: rpa2
title: Speed is Confidence
arxiv_id: '2601.19085'
source_url: https://arxiv.org/abs/2601.19085
tags:
- training
- accuracy
- baseline
- step
- ensemble
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper demonstrates that inference speed is an implicit confidence\
  \ signal for iterative reasoners. When multiple Tiny Recursive Models solve Sudoku-Extreme\
  \ in parallel, selecting the first to halt achieves 97.2% accuracy versus 91.5%\
  \ for probability averaging\u2014while requiring 10\xD7 fewer reasoning steps."
---

# Speed is Confidence

## Quick Facts
- arXiv ID: 2601.19085
- Source URL: https://arxiv.org/abs/2601.19085
- Reference count: 14
- Primary result: Selecting fastest-converging parallel solver achieves 97.2% accuracy on Sudoku-Extreme vs 91.5% for probability averaging, requiring 10× fewer steps

## Executive Summary
This paper demonstrates that inference speed serves as an implicit confidence signal for iterative reasoners. By maintaining multiple parallel solution paths and selecting the first to halt, accuracy improves from 91.5% to 97.2% while reducing reasoning steps tenfold. The key insight is that fast convergence indicates models found "clean" solution paths without contradictions. This leads to oracle-first training: maintaining K=4 parallel latent initializations within a single model and backpropagating only through the lowest-loss winner achieves 96.9% accuracy at single-model inference cost, matching ensemble performance while reducing variance by half.

## Method Summary
The method uses Tiny Recursive Models (TRM) with K=4 parallel latent initializations during training. Modified SwiGLU enables efficient training on consumer hardware. The oracle-first approach maintains multiple solution trajectories but only backpropagates through the lowest-loss winner, internalizing ensemble diversity. At inference, K=1 suffices. The architecture uses a 2-layer MLP-Mixer with modified SwiGLU activation, Muon optimizer for 2D weights, and AdamW for embeddings/biases.

## Key Results
- Halt-first selection achieves 97.2% accuracy vs 91.5% for probability averaging on Sudoku-Extreme
- Oracle-first training reaches 96.9% ± 0.6% accuracy with single-model inference cost
- 89% of baseline failures are selection problems rather than capability limits, indicating a 99% accuracy ceiling
- Modified SwiGLU enables training on RTX 5090 in 6 hours vs hours on datacenter GPUs

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Inference speed encodes implicit confidence for iterative reasoners—models that halt first are more likely correct.
- **Mechanism:** Fast convergence indicates the model found a "clean" solution path without contradictions. When iterative refinement encounters no conflicts, the latent state stabilizes quickly, producing both correct outputs and confident halting signals. Slow convergence correlates with oscillation or drift.
- **Core assumption:** The halting signal q_halt is well-calibrated to actual solution correctness.
- **Evidence anchors:** [abstract] "halt-first selection achieves 97% accuracy vs. 91% for probability averaging—while requiring 10× fewer reasoning steps"; [Section 5.7] "Among puzzles where any chain halts at step 0, accuracy is 99.2%. For puzzles requiring 8+ steps, accuracy drops to 78%."

### Mechanism 2
- **Claim:** Winner-take-all training internalizes ensemble diversity within a single model at training-time cost only.
- **Mechanism:** K=4 parallel latent initializations (zL) share one high-level state (zH). Each forward pass computes all K trajectories; only the lowest-loss head receives gradients. This teaches the model to find "clean paths" that both minimize loss and halt confidently. At inference, K=1 suffices.
- **Core assumption:** Diversity from different initializations can be captured and retained through competitive training.
- **Evidence anchors:** [abstract] "achieving 96.9% ± 0.6% accuracy with single-model inference cost, matching ensemble performance while reducing variance by half"; [Section 5.11] "Head 0 wins 31% of puzzles, heads 1–3 win 23%, 24%, 22%—no single head dominates, confirming diversity is maintained."

### Mechanism 3
- **Claim:** Maintaining diverse zL with shared zH exploits bilevel fixed-point structure for stable exploration.
- **Mechanism:** The inner loop (zL refinement) has a well-conditioned Jacobian because input is "anchored" by zH + z_x. Different zL initializations explore different basins. The copy policy propagates winner's zH to all chains, preserving high-level progress while maintaining low-level diversity.
- **Core assumption:** The Schur complement analysis accurately describes training dynamics despite truncation.
- **Evidence anchors:** [Section 3.5] "zL contributes 1/3 of L-cycle input variance versus 1/2 for H-cycles. The Jacobian JL is thus smaller: the output is 'anchored' by context"; [Section 5.4 ablation] "copy / all (KL=4) achieves 99.1% cell, 97.7% puzzle—best configuration."

## Foundational Learning

- **Concept: Adaptive Computation Time (ACT)**
  - Why needed here: TRM uses ACT to learn when to stop iterating. The halting probability q_halt is the signal exploited by halt-first selection.
  - Quick check question: Can you explain why averaging probabilities discards timing information that halt-first preserves?

- **Concept: Winner-Take-All circuits in neuroscience**
  - Why needed here: The paper draws direct analogy—cortical WTA circuits race to threshold; first to fire suppresses alternatives. This motivates halt-first ensembling.
  - Quick check question: How does time-to-first-spike coding differ from rate coding, and why might speed carry information?

- **Concept: Bilevel optimization / nested fixed-points**
  - Why needed here: TRM computes nested equilibria (inner zL, outer zH). Understanding why copy/all carry policy works requires grasping this structure.
  - Quick check question: Why would sharing zH but keeping zL diverse preserve exploration while enabling convergence?

## Architecture Onboarding

- **Component map:** Input → embed(x) → zL_init,k (K heads) → [L-cycle × nL] ↔ zH (shared) → [H-cycle] → y (prediction), q (halt logit)
- **Critical path:**
  1. SVD-aligned initialization of zL vectors (prevents dead heads)
  2. Carry policy: copy winner's zH to all, each chain keeps own zL
  3. WTA loss: k* = argmin_k LCE(y_k, y_target), backprop only through k*
  4. Split optimizer: Muon (lr=0.02) for 2D weights, AdamW (lr=1e-4) for embeddings/biases
- **Design tradeoffs:**
  - Fresh init vs. fixed init: Fresh slightly better (96.85% vs 96.80%) with lower variance
  - K>4: Not tested due to compute limits; head collapse by step 5+ may limit returns
  - Training cost: 4× per iteration, but inference is 1×—favors production deployment
- **Failure signatures:**
  - Standard SwiGLU with Muon/high LR: magnitude explosion (use modified SwiGLU)
  - Causal attention: -28% accuracy (TRM needs bidirectional constraint propagation)
  - Inter-H diversity loss: breaks iterative refinement (healthy models show cos(zH^h, zH^{h+1}) > 0.9)
  - Input corruption: destroys learning (model needs constraints intact)
- **First 3 experiments:**
  1. Reproduce baseline: Single TRM (K=1, nH=6, nL=9), verify ~85% puzzle accuracy with standard training
  2. Validate halt-first: Train 3 models with different seeds, compare probability averaging vs. halt-first selection on same test set
  3. Implement WTA: Add K=4 parallel zL with SVD-aligned init, copy/all carry policy, confirm ~97% puzzle accuracy

## Open Questions the Paper Calls Out

- **Cross-domain generalization:** Does the "speed is confidence" signal and oracle-first training generalize to other domains like ARC or maze-solving, or is it specific to constraint satisfaction problems?
- **Performance ceiling:** Can the performance ceiling be raised by integrating backtracking or tree-search mechanisms to handle the "irreducible" bifurcation puzzles?
- **Head diversity scaling:** Why does the benefit of parallel heads saturate at K=4, and can head collapse be prevented to allow scaling?

## Limitations
- The core insight that speed predicts correctness rests on strong assumptions about ACT halting calibration that may not generalize beyond Sudoku-Extreme's well-defined solution space
- The architectural advantage appears tightly coupled to Sudoku's constraint propagation dynamics—results may not transfer to open-ended reasoning tasks
- The 99% accuracy ceiling estimate assumes selection is the primary failure mode, but capability limitations could be more significant

## Confidence
- **High:** Halt-first selection consistently outperforms probability averaging across all tested configurations (97.2% vs 91.5%)
- **Medium:** Oracle-first training achieves parity with ensemble methods while reducing variance (96.9% ± 0.6% vs 97.2% ± 1.1%)
- **Low:** Generalization of speed-confidence relationship to non-Sudoku reasoning tasks

## Next Checks
1. Apply halt-first selection to a different constraint satisfaction problem (e.g., crossword puzzles or logic grid puzzles) to test whether speed-confidence relationship generalizes beyond Sudoku
2. Systematically analyze the 10% accuracy gap between 0-step and 8+ step puzzles to determine whether failures are primarily selection vs. capability limitations
3. Implement oracle-first training on a different iterative architecture (e.g., Transformer-based reasoner) to validate that the approach isn't architecture-specific