---
ver: rpa2
title: 'All Required, In Order: Phase-Level Evaluation for AI-Human Dialogue in Healthcare
  and Beyond'
arxiv_id: '2601.08690'
source_url: https://arxiv.org/abs/2601.08690
tags:
- phase
- evaluation
- clinical
- compliance
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Current evaluation methods for AI-human clinical dialogues focus
  on isolated turns, missing whether required clinical obligations are met in the
  right order. The authors propose Obligatory-Information Phase Structured Compliance
  Evaluation (OIP-SCE), a method that breaks conversations into clinically meaningful
  phases (e.g., patient identity, consent, coverage status), checks that every required
  phase is completed (Coverage), and that no downstream phase starts before its prerequisites
  finish (OrderSafe).
---

# All Required, In Order: Phase-Level Evaluation for AI-Human Dialogue in Healthcare and Beyond

## Quick Facts
- arXiv ID: 2601.08690
- Source URL: https://arxiv.org/abs/2601.08690
- Authors: Shubham Kulkarni; Alexander Lyzhov; Shiva Chaitanya; Preetam Joshi
- Reference count: 30
- Key outcome: Proposes OIP-SCE method that evaluates AI-human clinical dialogues for whether all required phases are completed in correct order

## Executive Summary
Current evaluation methods for AI-human clinical dialogues focus on isolated turns, missing whether required clinical obligations are met in the right order. The authors propose Obligatory-Information Phase Structured Compliance Evaluation (OIP-SCE), a method that breaks conversations into clinically meaningful phases (e.g., patient identity, consent, coverage status), checks that every required phase is completed (Coverage), and that no downstream phase starts before its prerequisites finish (OrderSafe). This enables evidence-backed, auditable compliance checking at scale. In a case study with an anonymized AI-Human insurance call, the system passed Coverage but failed OrderSafe because coverage details were given before identity verificationâ€”a regulatory violation. The method supports clinician-authored rules and engineer-friendly implementation, making complex compliance checks practical and traceable.

## Method Summary
The OIP-SCE method structures conversations into clinically meaningful phases and evaluates two key compliance dimensions: Coverage (whether all required phases are completed) and OrderSafe (whether phases follow prerequisite ordering). The method relies on clinician-authored rules to define phase requirements and their dependencies, then applies these rules to analyze conversation structure. This phase-level approach captures regulatory compliance that turn-level metrics miss, enabling systematic identification of violations in complex healthcare dialogues.

## Key Results
- OIP-SCE successfully identified a regulatory violation in an anonymized AI-human insurance call where coverage details were provided before identity verification
- The method demonstrated ability to separate Coverage (passed) from OrderSafe (failed) checks, providing granular diagnostic capability
- Phase-level evaluation revealed compliance failures that turn-level metrics would miss entirely

## Why This Works (Mechanism)
The method works by breaking down conversations into clinically meaningful phases and applying structured compliance rules. Coverage checking ensures all required phases are completed, while OrderSafe validation enforces prerequisite ordering between phases. This dual-check approach captures both completeness and proper sequencing of clinical obligations. The method leverages clinician expertise to define rules while providing engineer-friendly implementation through structured phase identification and validation.

## Foundational Learning
- **Phase-Based Dialogue Structure**: Understanding that conversations can be decomposed into clinically meaningful phases rather than analyzing individual turns
  - Why needed: Individual turns miss the broader context of clinical workflows and regulatory requirements
  - Quick check: Can you identify distinct phases in a healthcare conversation (e.g., identity verification, consent, treatment discussion)?

- **Prerequisite-Based Ordering**: Recognizing that certain clinical phases must be completed before others can begin
  - Why needed: Regulatory compliance often requires specific sequences (e.g., identity verification before treatment information)
  - Quick check: Can you map out dependencies between phases in a clinical workflow?

- **Coverage vs. OrderSafe Distinction**: Separating completeness checks from ordering checks provides clearer diagnostic information
  - Why needed: A system might complete all required phases but still violate regulations through improper sequencing
  - Quick check: Can you identify cases where all phases are present but ordering is violated?

## Architecture Onboarding
- **Component Map**: Rule Authoring (clinicians) -> Phase Detection (engineers) -> Coverage Validation -> OrderSafe Validation -> Compliance Report
- **Critical Path**: Phase detection and validation must occur before compliance reporting can be generated
- **Design Tradeoffs**: Clinician-authored rules provide domain accuracy but require maintenance; phase detection automation balances precision with scalability
- **Failure Signatures**: Coverage failures indicate missing phases; OrderSafe failures indicate sequence violations that may be clinically acceptable in some contexts
- **First Experiments**:
  1. Apply method to single clinical conversation and manually verify phase identification
  2. Test Coverage validation on conversations with known missing phases
  3. Validate OrderSafe detection using controlled examples with intentional sequencing violations

## Open Questions the Paper Calls Out
None

## Limitations
- Relies on clinician-authored rules for phase definitions, raising scalability concerns across diverse healthcare workflows
- Case study uses anonymized example rather than systematic evaluation across multiple real conversations
- OrderSafe constraint assumes strict prerequisite ordering that may not capture all clinically acceptable variations

## Confidence
- High confidence in method's logical soundness and validity of identified compliance violation in case study
- Medium confidence in method's scalability and generalizability across different healthcare contexts
- Low confidence in practical implementation challenges and long-term maintenance requirements

## Next Checks
1. Conduct systematic evaluation across multiple real AI-human healthcare conversations covering diverse clinical scenarios and regulatory requirements
2. Test method's performance on non-healthcare regulated dialogues (e.g., financial services, legal consultations) to assess generalizability
3. Implement and evaluate rule authoring and maintenance workflow with clinical stakeholders over extended timeframes to assess practical scalability