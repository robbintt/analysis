---
ver: rpa2
title: '!MSA at AraHealthQA 2025 Shared Task: Enhancing LLM Performance for Arabic
  Clinical Question Answering through Prompt Engineering and Ensemble Learning'
arxiv_id: '2509.11365'
source_url: https://arxiv.org/abs/2509.11365
tags:
- arabic
- medical
- question
- prompt
- sub-task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The study addresses the challenge of Arabic medical question answering\
  \ by leveraging prompt engineering and ensemble learning with the Gemini 2.5 Flash\
  \ model. For classification tasks, an ensemble of three prompt strategies\u2014\
  Arabic few-shot, English translation, and question refinement\u2014improved accuracy\
  \ by 2 percentage points to 76% through bias reduction and complementary reasoning."
---

# !MSA at AraHealthQA 2025 Shared Task: Enhancing LLM Performance for Arabic Clinical Question Answering through Prompt Engineering and Ensemble Learning

## Quick Facts
- arXiv ID: 2509.11365
- Source URL: https://arxiv.org/abs/2509.11365
- Reference count: 8
- Achieved 76% accuracy on classification and 86.953% BERTScore on generation without fine-tuning

## Executive Summary
This study tackles Arabic medical question answering by combining prompt engineering with ensemble learning using Gemini 2.5 Flash. For classification tasks, an ensemble of three prompt strategies—Arabic few-shot, English translation, and question refinement—improved accuracy by 2 percentage points to 76% through complementary reasoning and bias reduction. For generation tasks, a unified Arabic prompt with role-playing as a medical expert achieved 86.953% BERTScore across diverse formats including fill-in-the-blank, patient-doctor Q&A, and paraphrasing. The approach demonstrates that carefully designed prompts and lightweight ensembles can effectively handle Arabic clinical QA complexities without fine-tuning.

## Method Summary
The approach leverages Gemini 2.5 Flash with temperature=0.1, top-p=0.8, and top-k=40. For classification (Sub-Task 1), three parallel prompts are used: Arabic Few-Shot (AFS) with 6 examples, English Translation+Answer (ETA), and Refinement+Answer (RFA) with 15-25 word option explanations. These are combined via majority vote with RFA>AFS>ETA tie-breaking. For generation (Sub-Task 2), a single unified Arabic prompt casts the model as a medical expert with few-shot examples across multiple domains. No fine-tuning is employed. Post-processing includes markdown removal, Arabic text normalization, and output cleaning for classification.

## Key Results
- Classification ensemble improved accuracy from 74% (best individual) to 76% through majority voting
- Generation tasks achieved 86.953% BERTScore across 4 diverse formats without task-specific fine-tuning
- RFA prompt achieved highest individual accuracy at 74%, outperforming AFS (71%) and ETA (69%)
- Post-processing markdown removal improved BERTScore by 2-3%

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Majority-vote ensembles of heterogeneous prompt strategies improve classification accuracy through complementary error patterns
- Mechanism: Three prompt configurations likely make different errors due to distinct reasoning paths; voting cancels uncorrelated mistakes while preserving consistent correct predictions
- Core assumption: Error patterns across AFS, ETA, and RFA are sufficiently uncorrelated; models fail on different questions
- Evidence anchors: Ensemble improved accuracy by 2 percentage points to 76%; ablation shows RFA removal: -3%, AFS removal: -2%, ETA removal: -1%, confirming non-redundant contributions
- Break condition: If individual systems produce highly correlated errors, ensemble gains diminish toward best individual performer

### Mechanism 2
- Claim: Question refinement with explicit option explanations enhances model reasoning in medical MCQs
- Mechanism: Adding 15-25 word clarifications per option may decompose complex medical reasoning into explicit comparisons, reducing surface-pattern matching and encouraging deliberation
- Core assumption: Gemini 2.5 Flash can leverage expanded context without confusion; refinement preserves question semantics
- Evidence anchors: RFA achieved highest individual accuracy at 74%; ablation confirms largest contribution when removed (-3%)
- Break condition: If refinements introduce noise, alter question semantics, or exceed model context utilization capacity, performance may degrade

### Mechanism 3
- Claim: Unified role-based prompting with few-shot examples generalizes across diverse generation formats without task-specific fine-tuning
- Mechanism: Single prompt with medical expert persona and multi-domain examples establishes consistent output expectations; model transfers patterns across fill-in-the-blank, Q&A, GEC, and paraphrased formats
- Core assumption: Gemini 2.5 Flash generalizes from limited examples; persona grounding improves medical tone consistency
- Evidence anchors: Achieved 86.953% BERTScore across diverse formats; unified approach ensures consistency without fine-tuning
- Break condition: If format-specific requirements diverge significantly, single-prompt approach may underperform specialized prompts

## Foundational Learning

- Concept: **Ensemble diversity vs. accuracy trade-off**
  - Why needed here: Understanding why heterogeneous prompts outperform any single approach informs future prompt selection
  - Quick check question: Would adding a fourth prompt (e.g., Chain-of-Thought in Arabic) likely improve or degrade ensemble performance, and why?

- Concept: **BERTScore sensitivity to text normalization**
  - Why needed here: Post-processing improved BERTScore by 2-3%; understanding metric behavior prevents spurious conclusions
  - Quick check question: If a model generates medically accurate but heavily formatted output (bullets, bold), would BERTScore increase, decrease, or stay unchanged?

- Concept: **Cross-lingual transfer with information loss**
  - Why needed here: ETA approach shows 2-point accuracy drop vs. Arabic native, suggesting translation loses nuance; critical for designing multilingual pipelines
  - Quick check question: When would English-mediated reasoning be preferable despite potential information loss?

## Architecture Onboarding

- Component map:
  ```
  Input Question → Preprocessing (Arabic normalization)
                 ↓
  ┌─────────────────────────────────────┐
  │  Sub-Task 1: Three parallel prompts  │
  │  ├─ AFS (Arabic Few-Shot)           │
  │  ├─ ETA (English Translation)       │
  │  └─ RFA (Refinement + Answer)       │
  │           ↓                          │
  │  Majority Vote → Tie-break (RFA>AFS>ETA) │
  └────────────────────────────────────┘
                 ↓
  Output Cleaning → Single letter (أ/ب/ج/د/هـ)

  ┌─────────────────────────────────────┐
  │  Sub-Task 2: Unified prompt          │
  │  (Role: Arabic medical expert)       │
  │  + Few-shot examples (multi-domain)  │
  └────────────────────────────────────┘
                 ↓
  Post-processing (markdown removal, normalization)
  ```

- Critical path: RFA prompt → majority vote → output cleaning (Sub-Task 1); unified prompt → post-processing (Sub-Task 2)

- Design tradeoffs:
  - Ensemble inference cost: 3× API calls per question vs. accuracy gain (+2 percentage points)
  - Unified vs. specialized prompts: Single prompt simplifies deployment but may underperform on outlier formats
  - Translation latency: ETA adds translation step; benefit must justify cost

- Failure signatures:
  - Ensemble returns tie frequently → prompts too similar; diversify strategies
  - BERTScore unexpectedly low → check for markdown/formatting artifacts in output
  - RFA underperforms → refinements may be altering question semantics; audit refined examples

- First 3 experiments:
  1. Replicate individual prompt baselines (AFS, ETA, RFA) on development set to verify 69%/71%/74% hierarchy before ensemble
  2. Run ablation study: ensemble minus each component to confirm contribution rankings (RFA: -3%, AFS: -2%, ETA: -1%)
  3. Test post-processing impact: compare BERTScore with/without markdown removal on Sub-Task 2 development samples

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Would retrieval-augmented generation with vetted Arabic medical sources significantly outperform the current prompt-only ensemble approach, particularly for specialized domains like neurosurgery or oncology?
- Basis in paper: The conclusion explicitly proposes "retrieval augmentation with vetted Arabic medical sources" as a future extension
- Why unresolved: The paper deliberately avoids retrieval-based methods, citing the scarcity of structured Arabic medical knowledge bases, but does not test whether even limited retrieval could help
- What evidence would resolve it: Experiments comparing the current ensemble against RAG variants using available Arabic medical corpora (e.g., AraMed), with domain-stratified analysis

### Open Question 2
- Question: Does the 2-point ensemble improvement (74% → 76%) reflect genuine bias reduction or simply the mechanical effects of tie-breaking priority favoring RFA?
- Basis in paper: The paper attributes ensemble gains to "bias reduction through diverse prompt strategies" but uses a fixed priority (RFA > AFS > ETA) for tie-breaking without analyzing how often ties occur or their impact
- Why unresolved: Ablation shows RFA contributes most (-3% when removed), but the tie-breaking rule's contribution to the 76% score is not isolated or quantified
- What evidence would resolve it: Analysis of tie frequency and outcomes; experiments with randomized or reversed tie-breaking to measure systematic effects

### Open Question 3
- Question: Would incorporating models beyond Gemini 2.5 Flash (e.g., Arabic-specialized or other frontier LLMs) yield greater improvements than prompt diversity alone?
- Basis in paper: The conclusion identifies "broader model diversity" as a future direction; the entire study uses a single model
- Why unresolved: Ensemble relies only on prompt-level diversity with one underlying model; architectural diversity is unexplored
- What evidence would resolve it: Cross-model ensemble experiments (e.g., GPT, Claude, Arabic-specialized models) using the same prompting strategies, compared against single-model baselines

### Open Question 4
- Question: How reliably does BERTScore correlate with human clinician judgments of Arabic medical response quality across the diverse generation subtypes (fill-in-the-blank, Q&A, GEC)?
- Basis in paper: The paper uses BERTScore as the primary generation metric and cites noise concerns from formatting, but does not validate BERTScore against human evaluation for clinical accuracy or appropriateness
- Why unresolved: BERTScore captures semantic similarity but not factual correctness, safety, or clinical utility—critical in medical contexts
- What evidence would resolve it: Human evaluation by medical professionals comparing BERTScore rankings with expert quality ratings across all generation subtypes

### Open Question 5
- Question: Can lightweight prompt-only approaches generalize to dialect-rich Arabic medical contexts without performance degradation, given the benchmark's MSA focus?
- Basis in paper: The paper mentions dialectal variations as a challenge and includes "both formal and dialect Arabic" in examples, but evaluates on a dataset primarily in MSA
- Why unresolved: No explicit analysis of performance differences between MSA and dialectal inputs, or how well the unified prompt handles dialectal variation
- What evidence would resolve it: Stratified evaluation on dialect-annotated subsets; targeted testing with commonly spoken Arabic dialects (Egyptian, Levantine, Gulf) in medical scenarios

## Limitations
- Ensemble mechanism lacks direct corpus validation for Arabic-specific complementary error patterns
- Question refinement mechanism operates without validation that clarifications preserve semantics
- Unified prompt approach assumes Gemini 2.5 Flash can generalize across all generation formats, limited Arabic clinical validation
- Cross-lingual transfer via English translation shows 2-point accuracy drop without validation of information loss

## Confidence
- **High Confidence:** Prompt engineering with Gemini 2.5 Flash achieves measurable performance improvements without fine-tuning
- **Medium Confidence:** Ensemble of three prompt strategies improves accuracy through complementary reasoning, based on ablation results
- **Low Confidence:** Cross-lingual transfer via English translation preserves medical reasoning despite 2-point accuracy drop
- **Low Confidence:** Unified prompt with medical expert role-playing generalizes across all generation formats without task-specific tuning

## Next Checks
1. **Error Correlation Analysis:** Compute pairwise correlation matrices of individual prompt errors on development set to verify uncorrelated mistakes
2. **Format-Specific Performance:** Measure BERTScore per question type (fill-in-blank, Q&A, GEC, paraphrasing) to identify unified prompt limitations
3. **Refinement Semantic Preservation:** Conduct manual review of 50 refined questions to verify semantic preservation and absence of bias introduction