---
ver: rpa2
title: Adversarial bandit optimization for approximately linear functions
arxiv_id: '2505.20734'
source_url: https://arxiv.org/abs/2505.20734
tags:
- regret
- bound
- linear
- bandit
- optimization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper studies adversarial bandit optimization for non-convex,\
  \ non-smooth functions that are \u01EB-approximately linear (i.e., f(x) = \u03B8\
  \u22A4x + \u03C3(x) where |\u03C3(x)| \u2264 \u01EB). The authors modify the SCRiBLe\
  \ algorithm with lifting and the \u03BD-normal barrier to handle this problem."
---

# Adversarial bandit optimization for approximately linear functions

## Quick Facts
- arXiv ID: 2505.20734
- Source URL: https://arxiv.org/abs/2505.20734
- Reference count: 40
- Primary result: Achieves O(d√νT ln(1/δ) + dT(ν+2√ν)(1-δ)/δ·ε + δGDT + 2Tε) expected regret for approximately linear functions in adversarial bandit setting

## Executive Summary
This paper studies adversarial bandit optimization for non-convex, non-smooth functions that are ε-approximately linear (i.e., f(x) = θᵀx + σ(x) where |σ(x)| ≤ ε). The authors modify the SCRiBLe algorithm with lifting and the ν-normal barrier to handle this problem. They derive both expected and high-probability regret bounds that depend on ε, achieving O(d√νT ln(1/δ) + dT(ν+2√ν)(1-δ)/δ·ε + δGDT + 2Tε) expected regret and similar high-probability bounds. When ε=0, this becomes standard bandit linear optimization, and their high-probability bound improves upon prior work. They also prove a lower bound of Ω(εT), showing their regret bounds are tight in terms of ε.

## Method Summary
The paper modifies the SCRiBLe algorithm by introducing lifting (operating on K' = {(x, 1) : x ∈ K}) and using a ν-normal barrier as the regularizer. The algorithm samples directions orthogonal to the lifting dimension and constructs a gradient estimator using one-point feedback. The key innovation is a new regret decomposition that separates the linear and perturbation components, allowing for tighter bounds in the oblivious adversary setting. The analysis leverages properties of self-concordant barriers and Dikin ellipsoids to control the cumulative error from non-linear perturbations.

## Key Results
- Achieves O(d√νT ln(1/δ) + dT(ν+2√ν)(1-δ)/δ·ε + δGDT + 2Tε) expected regret bound
- Provides matching high-probability regret bounds using martingale concentration
- Proves a lower bound of Ω(εT) showing the regret bounds are tight in terms of ε
- When ε=0, achieves O(d√T ln(1/δ) + δGDT) high-probability regret, improving upon prior work
- The analysis separates regret into linear optimization, exploration cost, and perturbation effect

## Why This Works (Mechanism)

### Mechanism 1: Regret Decomposition for Oblivious Adversaries
By decomposing regret into linear and perturbation components, the algorithm avoids complex variance analysis required by adaptive methods, allowing for tighter bounds in the oblivious setting. The paper proposes a specific decomposition (Eq. 3) separating the regret into a Reg-Term (linear optimization), Deviation-Term (exploration cost), and an Error-Term (perturbation effect). Unlike prior work (Lee et al.) that analyzed the variance of the gradient estimator g_t against the true vector θ_t, this approach exploits the oblivious assumption to focus strictly on the variance between the played point y_t and the current iterate x_t.

### Mechanism 2: Bounding Perturbation via Local Norms
The algorithm controls the cumulative error from non-linear perturbations by bounding the local norm distance between the algorithm's state and the comparator. The analysis introduces an Error-Term involving the perturbation σ_t. Using Lemma 4, the paper bounds ||x_t' - h||_{∇²R(x_t')} ≤ 2(1/δ - 1)(ν + 2√ν). This bounds the "sensitivity" of the update step to the perturbation, ensuring the error grows linearly with ε rather than exploding near the boundary.

### Mechanism 3: Lifting with Normal Barriers
"Lifting" the decision set into a higher dimension allows the use of a single ν-normal barrier, stabilizing updates and ensuring the algorithm remains in the interior. The algorithm operates on K' = {(x, 1) : x ∈ K} (lifting). This guarantees the existence of a ν-normal barrier R (Algorithm 1). The algorithm samples in the tangent space of the lifted cone, ensuring the last coordinate remains 1. This creates a "Dikin ellipsoid" that fits strictly inside the decision set, preventing boundary singularities without needing projection steps.

## Foundational Learning

- **Concept: Bandit Linear Optimization (SCRiBLe)**
  - Why needed here: This paper is a modification of the SCRiBLe algorithm. You must understand the base case (gradient estimation via spherical sampling and Follow-The-Regularized-Leader) to see how the "lifting" and "perturbation" modules modify the standard pipeline.
  - Quick check question: Can you explain how a one-point gradient estimator g_t = d f_t(y_t) A_t^{-1} μ_t is constructed from a single scalar loss?

- **Concept: ν-Self-Concordant Barriers**
  - Why needed here: The analysis relies on properties of the Hessian ∇²R(x_t) to define local norms and Dikin ellipsoids. Understanding how the barrier value ν affects the shape of these ellipsoids is critical for setting the learning rate η.
  - Quick check question: Why does the condition number of the Hessian ∇²R(x) matter when approaching the boundary of the decision set?

- **Concept: Martingale Concentration Inequalities**
  - Why needed here: To prove high-probability regret bounds (Theorem 2), the paper relies on Lemma 9 (a specific concentration result). You need to know how variance terms V and range bounds B contribute to the tail probability γ.
  - Quick check question: In the context of Theorem 2, what does the term C(√(8V ln(C/γ))) represent?

## Architecture Onboarding

- **Component map:** Input -> Initialization -> Learner (Iterative) -> Optimizer -> Output
- **Critical path:** The definition of δ (parameter for K_δ) and the learning rate η are the hyperparameters controlling the trade-off between the Reg-Term and the Error-Term.
- **Design tradeoffs:**
  - Parameter δ (Shrinkage): The paper sets δ = √ε (or 1/T² if ε=0). A larger δ shrinks the effective set K_δ, reducing the Error-Term bounds but potentially restricting the optimal solution x*.
  - Learning Rate: Fixed η vs. Lee et al.'s "increasing learning rates." This paper argues fixed is sufficient for oblivious adversaries, simplifying the implementation but potentially losing robustness against adaptive ones.
- **Failure signatures:**
  - Exploding Gradients: If δ is too small and the iterate x_t' approaches the boundary of con(K), the Hessian inverse ∇²R(x_t)^{-1/2} may become ill-conditioned (though the barrier theoretically prevents this, numerical precision can fail).
  - Regret Stagnation: If ε is significant, the regret floor Ω(εT) will dominate. Do not expect sub-linear behavior if the perturbation noise floor is high.
- **First 3 experiments:**
  1. Baseline Verification (ε = 0): Run Algorithm 1 on a standard linear bandit problem. Compare the high-probability regret curve against the standard SCRiBLe implementation to verify the "bias no more" claim holds with the lifting approach.
  2. Sensitivity to ε: Synthesize ε-approximately linear functions (e.g., linear + sine wave noise). Vary ε from 0 to 1. Confirm the regret scales as Õ(d√T + √(εdT) + εdT).
  3. Ablation on δ: Fix ε ≠ 0 and run the algorithm with δ ∈ {1/T², √ε, ε}. Plot the "Error-Term" magnitude to empirically validate the theoretical choice of δ = √ε.

## Open Questions the Paper Calls Out
- Can the lower bound for expected regret be tightened to Ω(dεT)?
- Can the analysis be extended to general convex loss functions with adversarial perturbations?
- Can the high-probability regret bounds be maintained when facing an adaptive (non-oblivious) adversary?

## Limitations
- The analysis relies heavily on the oblivious adversary assumption, which may not hold in many practical scenarios
- The dependence on Tε in the non-convex setting raises questions about scalability when perturbations are large
- The lower bound of Ω(εT) leaves a gap regarding the dependence on dimension d compared to the upper bound O(εdT)

## Confidence
- **High Confidence:** Regret decomposition framework (Section 4.2), ν-self-concordant barrier properties, Theorem 1's main structural form
- **Medium Confidence:** Specific parameter choices (δ = √ε), lifting construction's numerical stability, comparison to prior work
- **Low Confidence:** Lower bound tightness (Ω(εT)), practical implementation of uniform sampling on tangent spaces, numerical precision issues near the boundary

## Next Checks
1. **Numerical Stability Verification:** Implement Algorithm 1 with d=5, D=5, and monitor the Hessian condition number during execution. Verify that the Dikin ellipsoid remains well-defined and that x'_t stays within K'_δ throughout all iterations, especially as t approaches T.

2. **Perturbation Timing Validation:** Create a synthetic experiment where the perturbation σ_t is chosen adversarially (after y_t is selected) versus stochastically (before). Confirm that the regret scales as εT only in the adversarial setting and that the stochastic setting shows lower regret, validating the paper's modeling assumption.

3. **Lower Bound Gap Analysis:** The paper claims Ω(εT) lower bound but only proves O(εdT) upper bound. Design a specific family of approximately linear functions where the linear term's contribution is negligible and the perturbation term dominates. Verify if the gap between Ω(εT) and O(εdT) is tight or if the lower bound can be improved.