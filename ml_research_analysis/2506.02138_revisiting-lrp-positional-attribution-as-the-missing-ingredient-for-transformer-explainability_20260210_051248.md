---
ver: rpa2
title: 'Revisiting LRP: Positional Attribution as the Missing Ingredient for Transformer
  Explainability'
arxiv_id: '2506.02138'
source_url: https://arxiv.org/abs/2506.02138
tags:
- positional
- relevance
- rules
- attention
- relevancy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses a critical limitation in Transformer explainability:
  existing Layer-wise Relevance Propagation (LRP) methods fail to attribute relevance
  to positional encodings, violating conservation properties and missing important
  positional information. The authors propose Positional-Aware LRP (PA-LRP), which
  reformulates the input space as position-token pairs and introduces specialized
  LRP rules for propagating relevance through various positional encoding methods
  (Rotary, Learnable, and Absolute PE).'
---

# Revisiting LRP: Positional Attribution as the Missing Ingredient for Transformer Explainability

## Quick Facts
- arXiv ID: 2506.02138
- Source URL: https://arxiv.org/abs/2506.02138
- Reference count: 40
- Primary result: Introduces PA-LRP to address positional encoding attribution limitations in Transformer explainability

## Executive Summary
This paper addresses a fundamental gap in Transformer explainability methods by introducing Positional-Aware LRP (PA-LRP), which properly attributes relevance to positional encodings that existing LRP methods ignore. The authors demonstrate that without positional attribution, conservation properties are violated and critical positional information is lost. PA-LRP reformulates the input space as position-token pairs and introduces specialized propagation rules for various positional encoding schemes including Rotary, Learnable, and Absolute position encodings. The method significantly outperforms existing baselines across both NLP and vision tasks, showing that positional relevance captures unique structural relationships complementary to semantic relevance.

## Method Summary
The authors identify that standard LRP methods fail to propagate relevance through positional encodings, treating them as zero-contributing layers. PA-LRP solves this by reformulating the input space as position-token pairs and developing specialized LRP rules for different positional encoding schemes. For Rotary positional encoding (RoPE), PA-LRP uses a hybrid rule combining maximum-rule and epsilon-rule components. For learnable positional encodings, a scaled gradient rule is employed, while absolute positional encodings use a modified maximum-rule approach. The method ensures conservation properties are maintained throughout the propagation process, enabling meaningful attribution of relevance to both token and positional components of the input.

## Key Results
- PA-LRP improves AU-MSE scores by up to 51% on Tiny-LLaMA compared to state-of-the-art baselines
- Zero-shot LLaMA-3 evaluation shows 7% improvement in average results across five HELM tasks
- Vision experiments demonstrate 3.97 average points improvement in negative perturbation tests on DeiT models and up to 2.07 points improvement in segmentation metrics

## Why This Works (Mechanism)
PA-LRP works by recognizing that positional encodings are not mere technical artifacts but carry essential information about sequence structure and spatial relationships. By reformulating the input space to explicitly include position-token pairs, the method enables relevance to flow through positional encoding layers rather than being blocked. The specialized propagation rules account for the mathematical properties of different encoding schemes, ensuring that relevance is distributed appropriately between semantic and positional components. This allows the attribution process to capture both the meaning of tokens and their structural relationships within the sequence.

## Foundational Learning
- **Layer-wise Relevance Propagation (LRP)**: A method for explaining neural network predictions by propagating relevance scores backward through the network. Why needed: Provides the theoretical foundation for understanding how relevance flows through network layers. Quick check: Verify conservation properties hold at each propagation step.
- **Positional Encodings**: Mechanisms that inject information about token positions into transformer models. Why needed: Essential for sequence modeling where token order matters. Quick check: Confirm positional information is being utilized by the model.
- **Conservation Properties**: Mathematical constraints requiring that total relevance is preserved during backward propagation. Why needed: Ensures attribution explanations are faithful to the model's actual computation. Quick check: Validate that input relevance equals sum of output relevances at each layer.
- **Rotary Positional Encoding (RoPE)**: A method that encodes position information by rotating query and key vectors. Why needed: Understanding this scheme is crucial for implementing PA-LRP rules for rotary encodings. Quick check: Verify rotation matrices are correctly applied during relevance propagation.
- **Attention Mechanism**: The core operation in transformers that computes weighted combinations of values based on query-key similarities. Why needed: Relevance must be properly distributed through attention heads. Quick check: Confirm attention weights are correctly incorporated into relevance propagation.
- **Hybrid LRP Rules**: Combinations of different propagation rules to handle complex layer operations. Why needed: Single rules often cannot handle the mathematical properties of all layers. Quick check: Validate hybrid rules maintain conservation properties.

## Architecture Onboarding
- **Component Map**: Input -> Positional Encoding Layer -> Attention Layers -> Feed-Forward Layers -> Output
- **Critical Path**: Input relevance → Position-Token Pair Space → Positional Encoding Propagation → Attention Propagation → Output Attribution
- **Design Tradeoffs**: Standard LRP vs PA-LRP — simpler implementation but missing positional info vs more complex but complete attribution
- **Failure Signatures**: Zero relevance in positional components, conservation property violations, identical attributions for different sequences
- **First Experiment**: Verify conservation properties hold on a simple transformer with PA-LRP
- **Second Experiment**: Compare PA-LRP vs standard LRP on a toy task with known positional dependencies
- **Third Experiment**: Test PA-LRP on a vision transformer with absolute positional encodings

## Open Questions the Paper Calls Out
None

## Limitations
- Vision task evaluation relies heavily on aggregated metrics without sufficient qualitative validation of the distinctiveness of positional relevance
- NLP zero-shot evaluation is limited to five tasks from the HELM benchmark, potentially limiting generalizability
- The quantitative evaluation framework may not fully capture practical utility of explanations in real-world applications

## Confidence
- Conservation property satisfaction: High confidence
- PA-LRP outperforms baselines: Medium confidence
- Positional relevance captures unique information: Medium confidence
- Generalizability across modalities: Low confidence

## Next Checks
1. Conduct qualitative case studies comparing PA-LRP explanations with human annotations to validate that positional relevance captures meaningful structural information
2. Perform ablation studies on the positional encoding rules to isolate which components contribute most to the observed improvements
3. Extend zero-shot evaluation to include diverse task categories (e.g., reasoning, generation, retrieval) and larger model scales to test generalization claims