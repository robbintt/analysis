---
ver: rpa2
title: Towards Faithful Class-level Self-explainability in Graph Neural Networks by
  Subgraph Dependencies
arxiv_id: '2508.11513'
source_url: https://arxiv.org/abs/2508.11513
tags:
- class
- graph
- graphoracle
- explanations
- latexit
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of class-level self-explainability
  in Graph Neural Networks (GNNs). Existing methods like ProtGNN and PGIB focus on
  instance-level explanations and fail to assess whether their class-specific prototypes
  generalize across instances or produce faithful class-level explanations.
---

# Towards Faithful Class-level Self-explainability in Graph Neural Networks by Subgraph Dependencies

## Quick Facts
- **arXiv ID**: 2508.11513
- **Source URL**: https://arxiv.org/abs/2508.11513
- **Authors**: Fanzhen Liu; Xiaoxiao Ma; Jian Yang; Alsharif Abuadbba; Kristen Moore; Surya Nepal; Cecile Paris; Quan Z. Sheng; Jia Wu
- **Reference count**: 40
- **Primary result**: Proposes GraphOracle framework for faithful class-level explanations in GNNs using subgraph dependencies

## Executive Summary
This paper addresses the critical challenge of class-level self-explainability in Graph Neural Networks (GNNs), where existing methods primarily focus on instance-level explanations without ensuring generalization across instances or faithfulness at the class level. The authors introduce GraphOracle, a novel framework that jointly learns a GNN classifier and class-specific structured subgraphs that are discriminative and interpretable. By using an integrated training approach with entropy-regularized subgraph selection and lightweight random walk extraction, GraphOracle avoids computational bottlenecks while producing faithful explanations that generalize across instances within each class.

## Method Summary
GraphOracle operates through an integrated training framework that jointly optimizes a GNN classifier and a set of class-specific subgraphs. The method employs entropy-regularized subgraph selection to identify discriminative patterns while maintaining computational efficiency through lightweight random walk extraction instead of computationally expensive approaches like Monte Carlo Tree Search. The framework captures graph-subgraph-prediction dependencies through simultaneous learning, validated using a masking-based evaluation strategy. This approach enables the generation of structured, sparse subgraphs that are both interpretable and faithful to the underlying classification decisions.

## Key Results
- Achieves superior fidelity, explainability, and scalability across various graph classification tasks compared to existing methods
- Produces more faithful and informative explanations while maintaining high classification performance
- Runs up to 12.76 times faster than GLGExplainer while being significantly more efficient than Monte Carlo Tree Search-based methods

## Why This Works (Mechanism)
GraphOracle works by jointly optimizing the classifier and subgraph extraction during training, ensuring that the learned subgraphs are directly tied to the classification task and generalize across instances within each class. The entropy regularization encourages sparse, structured subgraph selection that captures discriminative patterns while avoiding overfitting to individual instances. The lightweight random walk extraction provides computational efficiency without sacrificing explanation quality, and the integrated training approach ensures that subgraph selection is faithful to the learned decision boundaries of the GNN classifier.

## Foundational Learning
- **Graph Neural Networks (GNNs)**: Why needed - form the base classifier; Quick check - verify understanding of message passing and aggregation mechanisms
- **Graph Classification**: Why needed - the target task for explanation; Quick check - understand difference between node and graph-level predictions
- **Subgraph Extraction**: Why needed - provides interpretable explanations; Quick check - verify knowledge of subgraph isomorphism and pattern mining
- **Entropy Regularization**: Why needed - encourages sparse, structured subgraph selection; Quick check - understand trade-off between regularization strength and explanation quality
- **Random Walk Extraction**: Why needed - provides computational efficiency; Quick check - verify understanding of walk-based sampling versus exhaustive search
- **Integrated Training**: Why needed - ensures faithfulness between classifier and explanations; Quick check - understand joint optimization versus post-hoc explanation

## Architecture Onboarding

**Component Map**: Input Graphs -> GNN Classifier & Subgraph Extractor (Joint Training) -> Class-specific Subgraphs -> Prediction & Explanation

**Critical Path**: The critical path involves the joint optimization loop where graph features flow through the GNN to produce predictions, while simultaneously the subgraph extractor identifies discriminative patterns. The entropy regularization and random walk extraction components operate in parallel to ensure both faithfulness and efficiency.

**Design Tradeoffs**: The method trades some potential expressiveness of Monte Carlo Tree Search for significant computational efficiency through random walk extraction. The entropy regularization balances between finding discriminative patterns and maintaining interpretability. The joint training approach requires careful hyperparameter tuning but ensures faithfulness between the classifier and explanations.

**Failure Signatures**: Potential failures include: subgraphs that are too sparse to capture complex patterns, over-regularization leading to trivial explanations, random walk extraction missing important but rare subgraph patterns, and joint training instability if hyperparameters are poorly tuned. The masking-based evaluation strategy helps identify when explanations are not faithful to the underlying classifier.

**First Experiments**:
1. Run GraphOracle on a simple synthetic graph dataset with known class structures to verify that learned subgraphs align with ground truth patterns
2. Compare explanation quality and runtime against GLGExplainer on a standard benchmark dataset
3. Perform ablation studies removing entropy regularization to quantify its impact on both explanation quality and computational efficiency

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Class-level generalization claims primarily validated on synthetic and standard benchmarks, with limited real-world domain testing
- Fidelity evaluations rely on masking-based perturbation strategies that may not capture all failure modes
- Entropy-regularized subgraph selection could introduce bias toward simpler patterns that may not reflect true decision boundaries
- Scalability claims don't address memory consumption or performance on extremely large graphs

## Confidence
- **High**: Efficiency improvements over Monte Carlo Tree Search-based methods and comparative performance on standard benchmarks
- **Medium**: Claims about class-level generalization and faithfulness of explanations, dependent on evaluation methodology
- **Low**: Assertion that learned subgraphs are truly "discriminative" across all classes without extensive cross-validation on diverse datasets

## Next Checks
1. Test GraphOracle on real-world graph datasets from domains like bioinformatics or social networks to verify class-level generalization beyond benchmark datasets
2. Conduct ablation studies removing the entropy regularization to quantify its impact on both explanation quality and computational efficiency
3. Compare GraphOracle's explanations against ground truth labels in semi-supervised settings where some subgraph-class relationships are known