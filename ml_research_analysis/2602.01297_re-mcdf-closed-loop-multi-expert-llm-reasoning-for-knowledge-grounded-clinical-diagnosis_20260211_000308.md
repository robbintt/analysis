---
ver: rpa2
title: 'RE-MCDF: Closed-Loop Multi-Expert LLM Reasoning for Knowledge-Grounded Clinical
  Diagnosis'
arxiv_id: '2602.01297'
source_url: https://arxiv.org/abs/2602.01297
tags:
- evidence
- clinical
- reasoning
- disease
- expert
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: RE-MCDF addresses the challenge of noisy and heterogeneous EMRs
  in neurology by introducing a closed-loop multi-expert framework. It integrates
  primary, laboratory, and multi-relation experts with a medical knowledge graph to
  dynamically weight clinical evidence and enforce logical constraints.
---

# RE-MCDF: Closed-Loop Multi-Expert LLM Reasoning for Knowledge-Grounded Clinical Diagnosis

## Quick Facts
- arXiv ID: 2602.01297
- Source URL: https://arxiv.org/abs/2602.01297
- Reference count: 40
- RE-MCDF achieves 44.11% F1 on NEEMRs and 40.48% on XMEMRs, outperforming state-of-the-art baselines.

## Executive Summary
RE-MCDF addresses the challenge of noisy and heterogeneous EMRs in neurology by introducing a closed-loop multi-expert framework. It integrates primary, laboratory, and multi-relation experts with a medical knowledge graph to dynamically weight clinical evidence and enforce logical constraints. The primary expert generates diagnosis-evidence pairs, the laboratory expert prioritizes abnormal findings, and the multi-relation group ensures logical consistency by modeling mutual exclusivity and confusion relationships. Experiments on NEEMRs and XMEMRs show RE-MCDF achieves 44.11% F1 on NEEMRs and 40.48% on XMEMRs, outperforming state-of-the-art baselines.

## Method Summary
RE-MCDF employs a three-stage closed-loop architecture for clinical diagnosis from heterogeneous EMRs. The primary expert generates diagnosis-evidence pairs through chain-of-thought reasoning. The laboratory expert identifies abnormal clinical indicators and dynamically weights them by 1.5x to prioritize diagnostically salient findings. The multi-relation expert group (four specialized agents) enforces logical constraints by detecting mutual exclusivity and confusion relationships using a medical knowledge graph. The system features a feedback loop where diagnostic conflicts trigger re-examination of the original EMR for differential evidence.

## Key Results
- RE-MCDF achieves 44.11% F1 on NEEMRs and 40.48% on XMEMRs, outperforming state-of-the-art baselines.
- Laboratory expert ablation causes the largest F1 drop (2.41% NEEMRs, 2.75% XMEMRs).
- A_rel resolved logical conflicts in 17.8% of analyzed cases with 84.8% physician approval rate.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Closed-loop feedback with evidence re-examination improves diagnostic accuracy when initial candidates conflict.
- Mechanism: When A_multi detects logical conflicts (e.g., mutually exclusive diseases with similar confidence), it triggers feedback to A_pri, which re-examines the original EMR for differential evidence. This iterative refinement prevents single-pass error accumulation.
- Core assumption: Conflicting diagnostic hypotheses indicate incomplete evidence synthesis rather than ambiguous clinical presentations.
- Evidence anchors:
  - [abstract] "RE-MCDF introduces a generation–verification–revision closed-loop architecture"
  - [section III-A] "In the event of diagnostic conflicts, a feedback mechanism is triggered, prompting A_pri to re-examine the original EMR for differential evidence"
  - [corpus] Tree-of-Reasoning paper confirms multi-agent reasoning depth addresses information loss in complex diagnosis

### Mechanism 2
- Claim: Dynamic weighting of abnormal clinical indicators outperforms static evidence matching.
- Mechanism: A_lab identifies abnormal entities E_abn from laboratory results and boosts their weights by 1.5x (Equation 4). This prioritizes clinically salient findings over routine observations that may dominate the EMR.
- Core assumption: Abnormal test results carry higher diagnostic information density than normal findings, which this domain-specific weighting captures.
- Evidence anchors:
  - [abstract] "laboratory expert that dynamically prioritizes heterogeneous clinical indicators"
  - [section IV-D] A_lab removal causes the largest F1 drop (2.41% NEEMRs, 2.75% XMEMRs), out of all components

### Mechanism 3
- Claim: Explicit modeling of inter-disease logical constraints reduces clinically implausible comorbidity predictions.
- Mechanism: A_exc enforces mutual exclusivity (e.g., hemorrhage vs. infarction) with bounded penalties that attenuate weaker candidates toward zero. A_conf identifies confusion pairs via feature overlap analysis and synchronously penalizes all candidates in the confused set.
- Core assumption: Disease relationships (exclusivity, confusion, causality) are knowable from MKG structure and clinical feature overlap.
- Evidence anchors:
  - [abstract] "multi-relation awareness and evaluation expert group that explicitly enforces inter-disease logical constraints"
  - [section IV-F] A_rel resolved logical conflicts in 17.8% of analyzed cases; A_exc achieved 84.8% physician approval rate

## Foundational Learning

- Concept: Medical Knowledge Graph (MKG) structure and shortest-path reasoning
  - Why needed here: RE-MCDF uses CPubMed-KGv2 for entity-disease connectivity scoring (Equation 3, 5) and extracting exclusivity/confusion paths. Understanding graph traversal, node types (diseases, symptoms, drugs), and relation semantics is prerequisite.
  - Quick check question: Given a symptom node "hemiparesis" and candidate disease "cerebral infarction," how would you compute Γ(e,d) and interpret a 3-hop path vs. direct edge?

- Concept: Multi-agent LLM coordination with specialized roles
  - Why needed here: RE-MCDF orchestrates five LLM-played experts (A_pri, A_lab, A_sin, A_exc, A_conf, A_adj) with distinct input-output contracts. Understanding role specialization, prompt engineering for constrained outputs, and inter-agent data flow is essential.
  - Quick check question: What happens if A_lab outputs weights that don't sum to 1, or if A_exc fails to identify an exclusivity relationship that exists in the MKG?

- Concept: Differential diagnosis and disease logical relationships
  - Why needed here: The framework operationalizes clinical reasoning concepts—mutual exclusivity (same pathological subtype cannot co-occur), confusion (diseases with overlapping features), and comorbidity. Domain knowledge validates whether modeled constraints are clinically sound.
  - Quick check question: Why would "cerebral hemorrhage" and "cerebral infarction" be mutually exclusive, while "cerebral hemorrhage" and "hypertension" can coexist?

## Architecture Onboarding

- Component map: EMR input → A_pri (CoT diagnosis-evidence generation) → A_lab (NER + abnormality detection + dynamic weighting) → MKG supplement (Top-ĸsup disease expansion) → A_sin (single-disease evidence scoring) → A_exc (exclusivity checking) → A_conf (confusion analysis) → A_adj (bounded penalty adjustment) → Composite scoring H(d) → ICD-10 standardization penalty → Final ranking → Conflicts trigger A_pri re-examination

- Critical path: A_pri generates candidates → A_lab weights abnormal entities → MKG expands coverage → A_sin scores evidence alignment → A_exc/A_conf detect conflicts → A_adj applies penalties → If conflicts persist, feedback to A_pri. The A_lab → A_sin → A_adj chain most directly impacts F1 (ablation evidence).

- Design tradeoffs:
  - Supplement depth (ĸsup): Paper shows ĸsup=1 optimal; higher values cause "attention dilution" with 12.3% RR drop (Figure 2a). Trade precision for breadth at cost of verification noise.
  - Backbone model size: Qwen2.5-7B vs. GLM-4-9B show similar relative gains; smaller models benefit more from MKG supplementation for long-tail coverage.
  - Penalty intensity (γ): Higher γ enforces stricter exclusivity but risks over-suppression of valid comorbidities with shared pathways.

- Failure signatures:
  - Attention dilution: If ĸsup>1, RR stagnates despite higher HR—supplement noise overwhelms expert verification capacity.
  - Oversimplified complication modeling: 15.2% of A_exc errors stem from inadequate handling of complex multi-organ relationships (Figure 2b).
  - ICD alignment failures: If S_ICD(d) < τ_thr, penalty function suppresses scores even with strong evidence.

- First 3 experiments:
  1. Ablation by component: Remove each expert (A_lab, A_sin, A_exc, A_conf) individually and measure F1 delta on NEEMRs. Verify A_lab has largest impact per paper claims.
  2. Supplement depth sweep: Test ĸsup ∈ {1, 2, 3, 5} on both datasets, measure HR vs. RR tradeoff curve. Confirm ĸsup=1 optimal and characterize attention dilution threshold.
  3. Conflict resolution case study: Sample 20 cases where A_rel identified conflicts. Manually verify whether exclusivity/confusion classifications were clinically correct and whether final diagnosis improved vs. no-feedback baseline.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can multi-modal medical data (e.g., CT/MRI imaging, ECG waveforms) be effectively integrated into the closed-loop multi-expert framework without degrading the logical consistency enforced by the current text-based reasoning pipeline?
- Basis in paper: [explicit] The authors state in Future Work: "(i) Integrating medical imaging (e.g., CT/MRI) with textual EMRs to enhance diagnostic depth."
- Why unresolved: The current architecture assumes textual evidence entities; integrating visual modalities would require redefining how the laboratory expert identifies "abnormal indicators" and how the MKG grounds imaging findings.
- What evidence would resolve it: A modified RE-MCDF variant evaluated on a multi-modal neurology dataset with imaging, demonstrating comparable or improved F1 scores while maintaining logical consistency metrics.

### Open Question 2
- Question: What causes the "attention dilution" effect when increasing MKG supplement depth (k_sup), and can adaptive candidate filtering mitigate the retained-and-hit rate drop (36.8%→24.5%) observed in ablation studies?
- Basis in paper: [inferred] Ablation Study-II reports that increasing k_sup from 1 to 2 causes "a sharp 12.3% relative drop in RR" due to "extra candidates... act[ing] as noise, overwhelming the experts."
- Why unresolved: The paper identifies the phenomenon but offers no mechanism beyond setting k_sup=1; this represents a precision-breadth tradeoff limiting diagnostic coverage for rare diseases.
- What evidence would resolve it: An adaptive filtering mechanism that maintains stable RR across varying k_sup values while preserving hit rate improvements.

### Open Question 3
- Question: Can the RE-MCDF framework maintain diagnostic accuracy and logical consistency when deployed in real-time clinical settings with latency constraints (<2 seconds per case)?
- Basis in paper: [explicit] The authors identify in Future Work: "(iii) Optimizing reasoning efficiency for real-time integration into hospital decision support systems."
- Why unresolved: The current system involves multiple LLM calls (primary expert, laboratory expert, four specialized agents in A_multi), knowledge graph queries, and potential iterative feedback loops—all computationally intensive.
- What evidence would resolve it: Benchmarking RE-MCDF latency on hospital-grade hardware with F1 score retention above 95% of the non-optimized baseline.

## Limitations

- The framework assumes textual evidence entities; integrating visual modalities would require redefining how the laboratory expert identifies "abnormal indicators" and how the MKG grounds imaging findings.
- The "attention dilution" effect when increasing MKG supplement depth (k_sup) limits diagnostic coverage for rare diseases, representing a precision-breadth tradeoff.
- The logical constraint enforcement relies on the completeness and accuracy of the medical knowledge graph's exclusivity and confusion relationships, which may be incomplete for rare conditions or complex multi-organ relationships.

## Confidence

- **High Confidence**: The ablation study results showing A_lab's impact on F1 (2.41% NEEMRs, 2.75% XMEMRs) are directly supported by the reported data. The closed-loop architecture description and basic component interactions are clearly specified.
- **Medium Confidence**: The claim that ĸsup=1 is optimal appears supported by the stated 12.3% RR drop at higher values, though the full tradeoff curve isn't shown. The 84.8% physician approval rate for A_exc is cited but the methodology for this evaluation isn't detailed.
- **Low Confidence**: The paper doesn't provide exact prompt templates for the six LLM-played experts, making it difficult to verify whether the described mechanisms are faithfully implemented. The numerical hyperparameters (α1/α2, β1/β2/β3, γ, etc.) are referenced but not specified, limiting reproducibility.

## Next Checks

1. **Conflict Resolution Validation**: Sample 20-30 cases where the closed-loop feedback was triggered. Manually verify whether the exclusivity/confusion classifications were clinically correct and whether the final diagnosis improved compared to a no-feedback baseline. This directly tests the core mechanism's effectiveness.

2. **Attention Dilution Verification**: Test ĸsup ∈ {1, 2, 3, 5} on both NEEMRs and XMEMRs datasets. Measure the HR vs. RR tradeoff curve to confirm that ĸsup=1 is truly optimal and characterize the attention dilution threshold where RR begins to decline despite HR gains.

3. **Component Independence Test**: Remove each expert component (A_lab, A_sin, A_exc, A_conf) individually and measure F1 delta on both datasets. Verify that A_lab indeed has the largest impact as claimed, and determine whether any components are redundant or could be safely removed without significant performance loss.