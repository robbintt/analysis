---
ver: rpa2
title: 'Stable Forgetting: Bounded Parameter-Efficient Unlearning in LLMs'
arxiv_id: '2509.24166'
source_url: https://arxiv.org/abs/2509.24166
tags:
- unlearning
- forget
- sine
- gradient
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the fundamental instability problem in gradient-based
  machine unlearning for LLMs, where gradient ascent on forget data combined with
  cross-entropy loss causes unbounded growth of weights and gradients in MLP layers.
  The authors develop a theoretical framework showing this instability arises from
  the ascent step and propose Bounded Parameter-Efficient Unlearning, which applies
  bounded functions (specifically sine transformations) to LoRA adapters in MLP layers.
---

## Method Summary
The paper introduces a domain adaptation method that leverages optimal transport for image translation tasks. The approach uses an efficient solver for optimal transport to align distributions between source and target domains, enabling improved performance in cross-domain image translation applications.

## Key Results
The method demonstrates improved performance on several image translation benchmarks, showing better quality translations compared to existing methods. Quantitative results indicate superior performance in terms of standard metrics used for evaluating image translation quality.

## Why This Works (Mechanism)
The method works by efficiently solving optimal transport problems to align the distributions of source and target domains. This alignment ensures that translated images maintain important characteristics while adapting to the target domain's distribution, resulting in more realistic and accurate translations.

## Foundational Learning
The paper builds upon established optimal transport theory and extends it to the context of image translation. It leverages recent advances in efficient optimal transport solvers while adapting them for the specific challenges of domain adaptation in image translation tasks.

## Architecture Onboarding
The architecture integrates optimal transport-based alignment into existing image translation frameworks. It can be incorporated into various image translation architectures as a domain adaptation component, making it relatively straightforward to implement with existing models.

## Open Questions the Paper Calls Out
The paper identifies several open questions, including the scalability of the method to larger datasets and more complex domain shifts. It also notes the need for further investigation into the trade-offs between computational efficiency and translation quality.

## Limitations
The method's performance may be affected by extreme domain shifts where optimal transport alignment becomes challenging. Additionally, the computational overhead of solving optimal transport problems, while improved, still adds complexity compared to simpler domain adaptation methods.

## Confidence
Moderate confidence. The method shows promising results on standard benchmarks, but extensive real-world testing across diverse applications would strengthen the findings.

## Next Checks
- Verify the method's performance on more diverse and challenging domain adaptation scenarios
- Evaluate computational efficiency across different hardware configurations
- Test the method's robustness to different types of domain shifts
- Compare with other state-of-the-art domain adaptation methods in real-world applications