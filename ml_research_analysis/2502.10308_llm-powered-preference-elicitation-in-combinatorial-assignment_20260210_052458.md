---
ver: rpa2
title: LLM-Powered Preference Elicitation in Combinatorial Assignment
arxiv_id: '2502.10308'
source_url: https://arxiv.org/abs/2502.10308
tags:
- course
- bundle
- value
- courses
- student
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a framework for using LLM proxies to answer
  comparison queries on behalf of students in combinatorial course allocation, replacing
  the traditional iterative human elicitation process. The approach employs structured
  chain-of-thought prompting to improve LLM accuracy and uses a noise-robust generalized
  cross-entropy loss to handle the inherent noise in LLM responses.
---

# LLM-Powered Preference Elicitation in Combinatorial Assignment

## Quick Facts
- **arXiv ID**: 2502.10308
- **Source URL**: https://arxiv.org/abs/2502.10308
- **Reference count**: 40
- **Primary result**: LLM proxies improve combinatorial course allocation efficiency by up to 20% versus GUI-based reporting

## Executive Summary
This work introduces a framework using LLM proxies to answer comparison queries on behalf of students in combinatorial course allocation, replacing the traditional iterative human elicitation process. The approach employs structured chain-of-thought prompting to improve LLM accuracy and uses a noise-robust generalized cross-entropy loss to handle inherent LLM response variability. The framework integrates with existing machine learning-powered course allocation mechanisms, using epistemic monotone value neural networks with double Thompson sampling for query generation. Experimental results show that the LLM proxy approach improves allocative efficiency by up to 20% compared to standard GUI-based reporting, with students receiving better allocations in 74% of cases.

## Method Summary
The framework uses LLMs as proxies to answer comparison queries (CQs) on behalf of students, reducing cognitive burden while improving allocative efficiency. It employs an ensemble of Monotone Value Neural Networks (eMVNN) to model student preferences with epistemic uncertainty, uses Double Thompson Sampling to select which CQs to ask, and trains the model using a noise-robust generalized cross-entropy loss to handle LLM response variability. The system requires only a single natural language description from each student, then iteratively queries the LLM proxy and updates the preference model until convergence.

## Key Results
- LLM proxy approach improves allocative efficiency by up to 20% compared to standard GUI-based reporting
- Students receive better allocations in 74% of cases using the LLM proxy method
- LLM accuracy increases from 59% to 72% with structured chain-of-thought prompting

## Why This Works (Mechanism)

### Mechanism 1: Noise-Robust Gradient Descent via Generalized Cross-Entropy (GCE)
The framework tolerates significant label noise from the LLM proxy by using GCE loss instead of standard BCE. Unlike BCE, which heavily penalizes outliers, GCE acts as a symmetric loss function. Theoretically, if LLM proxy accuracy exceeds 50%, the minimizer of GCE loss on noisy dataset aligns with minimizer of clean dataset (student's true valuation).

### Mechanism 2: Epistemic Uncertainty-Driven Query Selection
Allocative efficiency is maximized by querying the LLM proxy only on bundle comparisons where the student's internal ML model is most uncertain. The system uses eMVNN ensemble to estimate epistemic uncertainty and employs Double Thompson Sampling as acquisition function to select next CQ, focusing computational resources on "decision boundaries."

### Mechanism 3: Structured Reasoning for Proxy Stabilization
Enforcing chain-of-thought structure via XML tags significantly reduces LLM hallucinations and improves proxy accuracy. The prompt forces LLM to explicitly recall items, identify complements/substitutes, and reason before outputting binary choice, grounding comparison in provided natural language description.

## Foundational Learning

- **Concept: Bradley-Terry Model & Pairwise Comparisons**
  - **Why needed here**: Framework trains cardinal value function (MVNN) using ordinal pairwise comparison data (CQs). Understanding how to convert preferences into probabilities via sigmoid function is required to implement loss function.
  - **Quick check question**: Can you explain how neural network outputting scalar value V(A) is trained using binary label indicating "User prefers Bundle A over Bundle B"?

- **Concept: Monotone Value Neural Networks (MVNNs)**
  - **Why needed here**: Standard NNs are unconstrained and can predict negative values or violate monotonicity. You must understand architectural constraints (non-negative weights, bReLU activations) that enforce valid economic value functions.
  - **Quick check question**: In MVNN, do you know why weight matrices W are constrained to be non-negative and how bReLU activation differs from standard ReLU?

- **Concept: Bayesian Optimization / Active Learning**
  - **Why needed here**: System iteratively selects which questions to ask (via Double Thompson Sampling). You need to distinguish between exploitation (asking about known good bundles) and exploration (asking about bundles with high uncertainty).
  - **Quick check question**: If acquisition function selects queries purely based on "highest predicted value" without considering uncertainty, what failure mode would likely occur during course allocation?

## Architecture Onboarding

- **Component map**: Input Layer (Student Natural Language Description) -> Proxy Engine (LLM + CoT Prompt) -> Student Model (eMVNN Ensemble) -> Acquisition Loop (DTS + GCE) -> Allocator (A-CEEI)

- **Critical path**: The Acquisition Loop. The interaction between eMVNN uncertainty estimates and LLM proxy responses is where 20% efficiency gain is generated or lost.

- **Design tradeoffs**: Cost vs. Accuracy (proprietary models offer higher accuracy but are cost-prohibitive at scale); Description Brevity (system robust to moderate brevity but performance degrades significantly with high brevity).

- **Failure signatures**: Random Proxy (if CQ accuracy drops near 50%, efficiency gains vanish); Incoherent Descriptions (if student's text input lacks detail on complements/substitutes, CoT reasoning produces weak signals); Overfitting (without proper regularization, MVNN might overfit to early CQ answers).

- **First 3 experiments**:
  1. Ablate the Loss Function: Run pipeline with BCE vs. GCE on synthetic dataset with fixed noise (30% error rate). Verify GCE maintains upward efficiency trajectory while BCE plateaus or degrades.
  2. Ablate the Acquisition Function: Compare "Random" query selection against "Double Thompson Sampling." Plot "Allocated Bundle Value" vs. "Number of CQs" to confirm DTS extracts value faster.
  3. Stress Test Input Quality: Generate student descriptions at varying word counts (Baseline, Moderate, High Brevity) to empirically determine minimum viable prompt length for specific domain data.

## Open Questions the Paper Calls Out
- **Open Question 1**: How can the quantitative reasoning capabilities of LLM proxies be improved to accurately handle multi-attribute scoring and numerical trade-offs? (Section 6.1 identifies gaps in quantitative reasoning when comparisons hinge on numerical trade-offs)
- **Open Question 2**: Does the framework maintain its reported efficiency gains when using natural language inputs written by real human subjects instead of synthetic descriptions generated by LLMs? (Section 4.2 notes experiments used LLMs to simulate student text)
- **Open Question 3**: What is the minimum information density or length of natural language input required to achieve statistically significant allocative efficiency improvements? (Appendix C.5 shows highly brief inputs resulted in statistically insignificant improvements)

## Limitations
- Framework's performance heavily dependent on LLM proxy accuracy exceeding 50%, with theoretical bounds that may not hold under real-world adversarial conditions
- CoT prompt structure assumes student descriptions are sufficiently detailed to enable meaningful reasoning, but minimum viable description quality threshold is not fully characterized
- GCE loss robustness claims are primarily theoretical, with limited empirical validation across diverse noise patterns beyond synthetic experiments

## Confidence
- **High confidence**: 20% allocative efficiency improvement over GUI-based reporting is well-supported by controlled experiments with statistical significance
- **Medium confidence**: LLM proxy accuracy gains from structured CoT prompting (59% â†’ 72%) are demonstrated but may not generalize across different student populations
- **Medium confidence**: Noise-robustness of GCE loss is theoretically grounded but real-world LLM error patterns may violate uniform noise assumption

## Next Checks
1. **Adversarial testing**: Systematically degrade LLM accuracy below 50% and above 50% to empirically verify break condition where GCE loss fails to recover true valuations
2. **Cross-domain generalization**: Apply framework to non-educational combinatorial allocation problem (e.g., resource scheduling) with different constraint structures
3. **Cost-benefit analysis**: Quantify tradeoff between higher-accuracy proprietary models versus open-source models with CoT prompting, measuring accuracy, computational costs, and response latency across 1,000+ queries