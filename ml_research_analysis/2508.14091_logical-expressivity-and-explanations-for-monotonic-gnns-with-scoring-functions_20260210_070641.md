---
ver: rpa2
title: Logical Expressivity and Explanations for Monotonic GNNs with Scoring Functions
arxiv_id: '2508.14091'
source_url: https://arxiv.org/abs/2508.14091
tags:
- each
- monotonic
- scoring
- then
- rules
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces methods to make graph neural networks (GNNs)
  with scoring functions monotonic, enabling extraction of Datalog rules for explainable
  link prediction on knowledge graphs. The authors adapt popular scoring functions
  like RESCAL, DistMult, and TuckER to be monotonically increasing by restricting
  their parameters to non-negative values.
---

# Logical Expressivity and Explanations for Monotonic GNNs with Scoring Functions

## Quick Facts
- arXiv ID: 2508.14091
- Source URL: https://arxiv.org/abs/2508.14091
- Reference count: 40
- Primary result: Methods to make GNNs monotonic enable extraction of sound Datalog rules for explainable link prediction

## Executive Summary
This paper introduces a framework for making graph neural networks (GNNs) with scoring functions monotonic, enabling the extraction of Datalog rules as explanations for link predictions on knowledge graphs. By constraining GNN weights and scoring function parameters to be non-negative, the authors create models where increased input leads to increased output. This monotonicity property enables a novel soundness checking mechanism that verifies whether extracted rules are guaranteed to produce predictions consistent with the model. The approach works with popular scoring functions like RESCAL, DistMult, and TuckER, and demonstrates that the monotonicity constraint does not significantly harm performance while enabling explainable predictions.

## Method Summary
The method involves training monotonic GNNs with scoring functions by clamping all weights to be non-negative and using a modified binary cross-entropy loss with positive class weighting (factor of 50). The GNN architecture uses max-sum aggregation with ReLU activation functions. Rule extraction is performed through two mechanisms: Proposition 3 provides a finite soundness check by evaluating candidate rules on minimal datasets, while Theorem 15 constructs equivalent Datalog programs for max-sum GNNs with non-negative bilinear scoring functions using a capacity-based approach. The approach requires predicate corruption for negative sampling and careful threshold selection on validation sets.

## Key Results
- Monotonicity constraints maintain or improve performance on standard benchmarks (WN18RRv1, FB237)
- Proposition 3 enables efficient soundness checking without exhaustive dataset evaluation
- Theorem 15 provides a capacity-based method to bound aggregation and construct finite equivalent Datalog programs
- Extracted rules are sound and interpretable, with many 1-body and 2-body rules verified as sound
- Distance-based scoring functions (TransE, RotatE) cannot be made monotonic due to vector subtraction

## Why This Works (Mechanism)

### Mechanism 1: Finite Rule Soundness Checking via Monotonicity
Monotonicity enables verifying rule soundness by checking predictions on minimal synthetic datasets rather than entire distributions. For monotonic models, if a rule holds for a minimal input, it holds for all larger inputs. Proposition 3 establishes that checking a rule's head on specific base datasets containing only atoms necessary to satisfy the rule's body is sufficient for soundness verification.

### Mechanism 2: Capacity-Bounded Rule Extraction for Sum Aggregation
For max-sum GNNs with non-negative bilinear scoring functions, the infinite influence of neighbors can be bounded by computing a capacity value for each layer. This capacity represents the maximum number of neighbors that can contribute enough signal to pass prediction thresholds. By replacing sum aggregation with a top-k sum where k equals the capacity, the model's behavior is preserved and the search space for equivalent rules becomes finite.

### Mechanism 3: Implicit Pattern Capture by Scoring Functions
The choice of scoring function family inherently forces the model to capture specific logical rule patterns. If a scoring function universally captures a pattern (e.g., DistMult captures symmetry), and the GNN learns the body of a rule conforming to that pattern, the model must necessarily learn the head as well. This bounds the expressivity of the combined model.

## Foundational Learning

### Concept: Monotonicity in Neural Networks
**Why needed:** This is the central constraint enabling explainability. Non-negative weights and specific activations ensure that "more input" always equals "more output," required for soundness proofs.
**Quick check:** If you add a negative weight to a layer in a monotonic GNN, does the Proposition 3 soundness check still theoretically hold?

### Concept: Max-Sum Aggregation
**Why needed:** The paper differentiates between Max (top-1 neighbor) and Sum (all neighbors). Understanding the hybrid "Max-k-Sum" is critical for Section 4's capacity mechanism.
**Quick check:** In a Max-Sum GNN, what does k=∞ imply compared to k=1?

### Concept: Datalog and Soundness
**Why needed:** The goal is to output Datalog rules. "Soundness" means extracted rules don't predict facts the model wouldn't predict (no hallucinations).
**Quick check:** If a rule is sound for a model, does it capture all predictions the model makes?

## Architecture Onboarding

**Component map:** Input (Knowledge Graph) -> Encoder (Monotonic Max-Sum GNN) -> Decoder (Monotonic Scoring Function) -> Explainer (Proposition 3 Checker/Tree-Like Rule Extractor)

**Critical path:**
1. Select a scoring function family (must be convertible to monotonic)
2. Configure GNN with non-negative constraints (clamp weights to ≥0)
3. Train on Link Prediction
4. Extract rules using soundness check (Prop 3) on candidate rules

**Design tradeoffs:**
- **Explainability vs. Performance:** Restricting weights to non-negative can lower raw accuracy (though paper shows maintenance/improved performance on specific datasets)
- **Decoder Selection:** Avoid distance-based decoders (TransE) if you need rule extraction; use bilinear models (RESCAL, DistMult) or semantic matching models
- **NAM Decoder:** NAM models struggled significantly when made monotonic, suggesting other decoders are safer bets

**Failure signatures:**
- **NAM Performance Drop:** Expect significant performance drops (Table 1) with Neural Association Models as decoders
- **Inability to Extract:** Standard (non-monotonic) training invalidates rule extraction via Proposition 3
- **Overfitting:** Standard models showed high validation AUPRC but lower test accuracy compared to monotonic models

**First 3 experiments:**
1. **Baseline Comparison:** Train standard Max-Sum GNN with RESCAL vs. Monotonic version on WN18RRv1. Compare accuracy.
2. **Rule Soundness Verification:** Extract 1- and 2-body rules. Apply Proposition 3 to count sound rules. Check intuitive sense.
3. **Pattern Injection (LogInfer):** Train on dataset with injected hierarchical rules. Verify monotonic model recovers these rules better than standard model.

## Open Questions the Paper Calls Out

### Open Question 1
Can the theoretical framework for obtaining finite equivalent Datalog programs be extended to monotonic max-sum GNNs paired with other monotonically increasing scoring functions, such as SimplE? The current approach is restricted to non-negative bilinear functions but may also work for others.

### Open Question 2
Can specialized training paradigms be developed to mitigate performance loss in specific monotonic architectures, such as those using NAM, while maintaining the ability to extract sound rules? The authors aim to consider more advanced training paradigms for monotonic models.

### Open Question 3
How can the computational complexity of extracting equivalent Datalog programs be reduced to handle large signatures and deep GNN architectures efficiently? The procedure requires brute-force enumeration of all tree-like rules, which may be intractable for large search spaces.

## Limitations
- Monotonicity constraint breaks for distance-based scoring functions (TransE, RotatE) due to vector subtraction
- Poor performance observed with NAM decoder models under monotonicity constraints
- Capacity-based rule extraction requires unbounded activation functions and specific decoder types
- Scalability concerns for checking soundness of rules with more than 2 body atoms on large datasets

## Confidence
**High Confidence:**
- Proposition 3's soundness checking mechanism for monotonic models
- Performance maintenance claims for RESCAL and DistMult under monotonicity
- Incompatibility of distance-based scoring functions with monotonicity

**Medium Confidence:**
- Capacity calculation method for sum aggregation (Theorem 14)
- Equivalence claim between max-sum GNNs and tree-like Datalog programs
- Effectiveness of positive class weighting (factor of 50) in preventing gradient vanishing

**Low Confidence:**
- Scalability of soundness checking for rules with more than 2 body atoms
- General applicability to all GNN architectures beyond tested ones
- Long-term stability of monotonic training across diverse datasets

## Next Checks
1. **Rule Extraction Scalability Test:** Measure time/resources to check soundness for all 2-body rules on fb237v1, then extrapolate to 3-body rules to assess practical scalability limits.

2. **Decoder Generalization Experiment:** Train monotonic models using additional scoring functions (ComplEx, DistMult variants) beyond four tested to determine which decoder families maintain performance under monotonicity.

3. **Activation Function Sensitivity Analysis:** Systematically test different activation functions (ReLU, LeakyReLU, ELU) in max-sum GNN under monotonicity constraints to identify which activations best support both performance and rule extraction.