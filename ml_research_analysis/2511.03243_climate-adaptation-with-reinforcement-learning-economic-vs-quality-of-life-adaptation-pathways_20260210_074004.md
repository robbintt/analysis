---
ver: rpa2
title: 'Climate Adaptation with Reinforcement Learning: Economic vs. Quality of Life
  Adaptation Pathways'
arxiv_id: '2511.03243'
source_url: https://arxiv.org/abs/2511.03243
tags:
- adaptation
- impacts
- available
- travel
- economic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of designing climate adaptation
  policies under uncertainty, specifically for urban flood risks. It proposes a reinforcement
  learning-based framework integrated with an assessment model linking rainfall projections,
  flood simulations, transport routing, and quality of life indices.
---

# Climate Adaptation with Reinforcement Learning: Economic vs. Quality of Life Adaptation Pathways

## Quick Facts
- arXiv ID: 2511.03243
- Source URL: https://arxiv.org/abs/2511.03243
- Reference count: 33
- Primary result: EC model spends DKK 2.1 billion over 75 years with 0.103 actions/year; QoL model spends DKK 20 billion with 0.559 actions/year and more even geographic distribution

## Executive Summary
This paper introduces a reinforcement learning framework for designing climate adaptation policies under uncertainty, specifically for urban flood risks. The framework integrates rainfall projections, flood simulations, transport routing, and quality of life indices to compare two adaptation strategies: one focused solely on economic impacts and another prioritizing quality of life. The results demonstrate that incorporating quality of life into adaptation planning leads to significantly different policy pathways and resource allocations, highlighting the importance of explicitly modeling societal trade-offs in climate adaptation.

## Method Summary
The framework uses reinforcement learning (PPO via Stable-Baselines3) to learn optimal climate adaptation policy sequences for urban flood risk in Copenhagen over 75 years (2023-2100). It compares two objective configurations: Economic Costs (EC) prioritizing cost minimization, and Quality of Life (QoL) prioritizing wellbeing preservation. The RL agent operates on 29 Traffic Analysis Zones, selecting from eight adaptation actions per year based on flood impacts, infrastructure damage, travel disruptions, and accessibility-based quality of life metrics. Climate uncertainty is represented through RCP4.5 rainfall projections from Klimaatlas, with flood simulations via SCALGO Live and transport impacts via OpenStreetMap-based routing.

## Key Results
- EC model: DKK 2.1 billion total spending (~280 million USD), 0.103 actions per year, concentrated geographic spending
- QoL model: DKK 20 billion total spending (~2.7 billion USD), 0.559 actions per year, more even geographic distribution
- RL successfully identifies divergent adaptation pathways based on reward function configuration
- Quality of life prioritization leads to broader geographic coverage of adaptation measures

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Reward function β-weight configuration causally determines adaptation pathway divergence between economic and quality-of-life objectives.
- Mechanism: The reward function R = Σ(βI·Ii + βD·Di + βC·Ci + βQ·Qi + βA·Ai + βM·Mi) allows explicit weighting of competing objectives. When βQ = 0.5 and other economic βs = 0, the agent optimizes purely for QoL preservation; when βQ = 0 and economic βs = 1, it optimizes for cost minimization. The PPO algorithm then learns different action selection policies based on these reward signals.
- Core assumption: The reward function adequately captures the true trade-offs between economic and wellbeing outcomes, and the β weights meaningfully represent policy priorities.
- Evidence anchors: [abstract] "models prioritising QoL over economic impacts results in more adaptation spending as well as a more even distribution of spending"; [section 2.4] The reward function equation (1) shows explicit β-weight parameterization enabling objective trade-offs; [corpus] Paper 26177 (arXiv:2504.10031) corroborates RL integration of subjective wellbeing into climate adaptation, suggesting mechanism generalizability
- Break condition: If QoL index does not capture meaningful variation in wellbeing, or if β weights are set to values that create reward sparsity, the mechanism fails to produce divergent pathways.

### Mechanism 2
- Claim: QoL-focused optimization produces geographically distributed spending because accessibility-based QoL indices correlate with residential population density rather than concentrated infrastructure value.
- Mechanism: QoL is computed as per-capita accessible POIs at the hex-grid level, then aggregated to TAZs. This normalizes by population, so areas with more residents and accessible amenities score higher. The RL agent must protect QoL across populated areas, leading to distributed action selection.
- Core assumption: POI accessibility is a valid proxy for quality of life; population-weighted QoL adequately represents societal wellbeing distribution.
- Evidence anchors: [section 2.3] "We computed the index by taking the number of POIs accessible from a hex... and divided by the hex's population"; [section 3, Figure 2] Visual comparison shows EC policy concentrates spending in fewer TAZs while QoL policy shows more even geographic distribution; [corpus] Weak direct evidence on QoL spatial distribution mechanisms; Paper 70987 (arXiv:2511.03238) appears to be an earlier/similar version of this work
- Break condition: If high-value infrastructure and population density are strongly correlated, EC and QoL policies would converge, eliminating the mechanism's observable effect.

### Mechanism 3
- Claim: Sequential action selection under climate uncertainty enables the RL agent to learn timing trade-offs between immediate intervention costs and long-term damage reduction.
- Mechanism: The agent takes one action per timestep (year) and receives delayed rewards based on flood event outcomes. PPO learns a policy that balances action/maintenance costs (Ai, Mi) against expected future damages. Different β configurations create different optimal timing strategies.
- Core assumption: The single-action-per-year constraint and 75-year horizon adequately represent real adaptation decision timelines; climate projections (RCP4.5) provide sufficient uncertainty representation.
- Evidence anchors: [abstract] "RL can be a useful tool to both identify adaptation pathways under uncertain conditions"; [section 3] EC model averages 0.103 actions/year; QoL model averages 0.559 actions/year — showing learned timing differences; [corpus] Paper 89135 (arXiv:2601.18586) reports similar mechanism for "long term climate-resilient transport adaptation pathways under direct and indirect flood impacts using reinforcement learning"
- Break condition: If the action space or flood event sampling does not adequately represent real-world complexity, learned timing strategies may not transfer to actual policy decisions.

## Foundational Learning

- Concept: Markov Decision Processes and reward shaping
  - Why needed here: The entire framework depends on formulating climate adaptation as an MDP where state = flood/infrastructure conditions, action = adaptation measure, reward = weighted impact function. Poor reward design leads to reward hacking or sparse learning signals.
  - Quick check question: Can you explain why setting βQ = 0.5 rather than 1.0 might affect learning stability?

- Concept: Depth-disruption and depth-damage functions
  - Why needed here: The mechanism connecting flood depth to travel delays, trip cancellations, and infrastructure damage relies on these functions. Understanding their form (non-linear, threshold-based) is essential for interpreting why certain adaptation actions are selected.
  - Quick check question: What happens to travel speed when water depth exceeds the disruption function's maximum threshold?

- Concept: Cumulative accessibility indices
  - Why needed here: The QoL index uses cumulative opportunity measures (count of POIs within travel time thresholds). This differs from gravity-based accessibility and has implications for how adaptation actions affect QoL scores.
  - Quick check question: If an adaptation action reduces flood depth on one road segment, which accessibility measure would show larger changes: 10-minute walk or 30-minute drive?

## Architecture Onboarding

- Component map: Rainfall Projection (Klimaatlas, RCP4.5) -> Flood Model (SCALGO Live) -> Transport Model (OSM + STL routing) -> Impact Aggregation -> RL Environment (Gymnasium) -> PPO Agent (Stable-Baselines3)

- Critical path:
  1. Set up climate projection sampling (one event per year, 2023-2100)
  2. Configure SCALGO Live flood simulation for Copenhagen
  3. Build TAZ structure (29 zones) and OD trip generation
  4. Implement depth-disruption/damage functions
  5. Compute QoL index from OSM POIs
  6. Implement Gymnasium environment with reward function
  7. Train PPO agent with chosen β weights

- Design tradeoffs:
  - Temporal resolution: Single event per year vs. multiple events — paper uses one event for simplicity; this may miss cumulative effects of smaller floods
  - Spatial aggregation: TAZ level (29 zones) vs. hex level — coarser aggregation reduces computational cost but may obscure local inequities
  - β weight selection: Paper tests two extreme configurations (EC: βQ=0, QoL: βI=βD=βC=0); intermediate trade-offs unexplored

- Failure signatures:
  - Reward collapse: If all βs except costs are zero, agent learns never to act. Check: ensure at least one impact β > 0.
  - Geographic concentration: If QoL policy still concentrates spending, check that POI data covers all TAZs and population normalization is applied correctly.
  - Action masking errors: Paper references invalid action masking; if agent selects unavailable actions, check mask implementation in Gymnasium wrapper.

- First 3 experiments:
  1. Reproduce EC vs QoL divergence: Run both configurations for 75-year horizon; verify EC spends ~DKK 2.1bn with ~0.1 actions/year and QoL spends ~DKK 20bn with ~0.56 actions/year.
  2. Sensitivity to βQ: Test βQ ∈ {0.1, 0.25, 0.5, 0.75, 1.0} with other economic βs held at 1; plot spending and action frequency as a function of βQ.
  3. Spatial equity analysis: Compute Gini coefficient of spending distribution across TAZs for EC and QoL policies; quantify the "more even distribution" claim from the paper.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does varying the priority weight for Quality of Life (βQ) across a continuous range influence the trade-offs between total adaptation costs and geographic distribution?
- Basis in paper: [explicit] The authors note that "Future research will explore the implications of setting βQ to different values," as the current study relies on a fixed weight (0.5) or excludes it entirely.
- Why unresolved: It is unclear if the relationship between QoL prioritization and spending is linear or if specific threshold values trigger significant shifts in policy strategy.
- What evidence would resolve it: A sensitivity analysis measuring total spend and action frequency against incremental changes in the βQ parameter.

### Open Question 2
- Question: How do the derived adaptation pathways perform when evaluated against socio-demographic equity metrics, such as the Foster-Greer-Thorbecke (FGT) index?
- Basis in paper: [explicit] The conclusion lists "explore distributional (socio-demographic) effects of policies" and "model specifications based on... transportation justice literature" as future work.
- Why unresolved: The current framework aggregates impacts by Traffic Analysis Zones (TAZ) but does not model how benefits are distributed across different income or demographic groups.
- What evidence would resolve it: A post-hoc analysis of the EC and QoL policy outputs using FGT indices to quantify poverty impacts or inequality outcomes.

### Open Question 3
- Question: Do the optimal adaptation strategies and spending distributions remain robust when scaled from the inner city to the full municipality of Copenhagen?
- Basis in paper: [explicit] The authors state they "expect to expand our framework to the full city of Copenhagen," acknowledging the current study is limited to 29 zones in the inner city.
- Why unresolved: The restricted geographic scope may fail to capture network effects, such as traffic displacement or cascading infrastructure failures, that occur in the wider urban system.
- What evidence would resolve it: Running the simulation on the complete city network to determine if the "even distribution" characteristic of QoL policies persists in outer regions.

## Limitations

- Reward Function Validity: The β-weight parameterization assumes linear additivity of disparate impacts (economic vs. QoL), which may oversimplify nonlinear societal trade-offs.
- Data Generalization: The framework depends on specific data sources (SCALGO Live, Klimaatlas) and Copenhagen-specific infrastructure, limiting transferability to other urban contexts without recalibration.
- Temporal Resolution: Single annual rainfall events may not capture compound flooding or seasonal patterns, potentially underestimating adaptation needs.

## Confidence

- High: The RL framework architecture and PPO implementation are technically sound and produce the reported EC/QoL spending divergence under the specified β configurations.
- Medium: The mechanism linking QoL-weighted rewards to geographically distributed spending is plausible but depends on POI accessibility representing true wellbeing variation.
- Low: The absolute spending figures (DKK 2.1bn vs. 20bn) are sensitive to unknown adaptation action costs and maintenance parameters not fully specified in the paper.

## Next Checks

1. Hyperparameter Sensitivity: Systematically vary PPO learning rate, batch size, and network architecture to verify that EC/QoL divergence persists across training configurations.
2. Intermediate βQ Values: Test βQ ∈ {0.1, 0.25, 0.5, 0.75, 1.0} to map the spending-action relationship continuum and identify thresholds where policy pathways bifurcate.
3. Spatial Equity Quantification: Compute Gini coefficients and Kolmogorov-Smirnov statistics for spending distributions across TAZs to rigorously quantify the "more even" geographic allocation claim.