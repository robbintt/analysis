---
ver: rpa2
title: Multi-Agent Causal Reasoning System for Error Pattern Rule Automation in Vehicles
arxiv_id: '2602.01155'
source_url: https://arxiv.org/abs/2602.01155
tags:
- causal
- error
- dtcs
- reasoning
- rules
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CAREP is a multi-agent system that automates error pattern rule
  discovery from high-dimensional vehicle event sequences by combining causal discovery,
  contextual information retrieval, and agent-based reasoning. It identifies causal
  relationships between Diagnostic Trouble Codes (DTCs) and error patterns using conditional
  mutual information, aggregates noisy graphs with adaptive thresholds, and generates
  interpretable Boolean rules with natural language explanations.
---

# Multi-Agent Causal Reasoning System for Error Pattern Rule Automation in Vehicles

## Quick Facts
- **arXiv ID**: 2602.01155
- **Source URL**: https://arxiv.org/abs/2602.01155
- **Reference count**: 40
- **Primary result**: CAREP achieves up to 70% recall and 78% precision on error pattern rule discovery from vehicle DTC sequences, outperforming LLM-only baselines.

## Executive Summary
CAREP is a multi-agent system that automates error pattern rule discovery from high-dimensional vehicle event sequences by combining causal discovery, contextual information retrieval, and agent-based reasoning. It identifies causal relationships between Diagnostic Trouble Codes (DTCs) and error patterns using conditional mutual information, aggregates noisy graphs with adaptive thresholds, and generates interpretable Boolean rules with natural language explanations. Evaluated on 29,100 DTCs and 474 error patterns, CAREP achieves up to 70% recall and 78% precision, substantially outperforming LLM-only baselines while offering transparent reasoning.

## Method Summary
CAREP employs a three-agent architecture: Causal Discovery Agent computes conditional mutual information (CMI) between DTCs and error patterns using pretrained Transformers, Contextual Information Agent retrieves relevant DTC descriptions and known rules via Titan V2 embeddings, and Orchestrator Agent synthesizes these inputs into interpretable Boolean rules. The system uses adaptive thresholding to handle label imbalance, generating multiple candidate rules per error pattern with confidence scores. Dual Transformer models (90M and 15M parameters) are pretrained on 1.5B tokens of historical DTC sequences to enable reliable conditional probability estimation for causal discovery.

## Key Results
- Achieves 70% recall and 78% precision on error pattern rule discovery
- Outperforms LLM-only baselines (25% recall for Claude Sonnet 3.7)
- Successfully generates interpretable Boolean rules with traceable reasoning chains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Conditional mutual information (CMI) between events and labels can identify candidate causal DTCs when conditioned on learned Transformer representations.
- Mechanism: Two pretrained SLMs estimate P(Y_j|Z) and P(Y_j|X_i, Z). The CMI I(Y_j, X_i|Z) = H(Y_j|Z) - H(Y_j|Z, X_i) is computed via Monte Carlo sampling from Tfx. If CMI > threshold θ_j = μ_Yj + γσ_Yj, X_i is flagged as a cause of Y_j.
- Core assumption: The learned conditional distributions from self-supervised pretraining capture meaningful causal dependencies rather than mere correlations.
- Evidence anchors:
  - [abstract] "identifies causal relationships between Diagnostic Trouble Codes (DTCs) and error patterns using conditional mutual information"
  - [section IV-B] "If I(Y_j, X_i|Z) is greater than 0, we say that X_i is a cause of Y_j"
  - [corpus] Weak direct corpus support; related work on LLM reasoning fragility under noise (arXiv:2502.16169) suggests caution in high-dimensional settings.
- Break condition: If pretrained SLMs fail to generalize to unseen DTC sequences or produce unreliable entropy estimates, CMI-based causality detection degrades.

### Mechanism 2
- Claim: Adaptive label-specific thresholds improve graph aggregation robustness under long-tailed label distributions.
- Mechanism: For each edge X_i → Y_j, compute empirical frequency π̂_i,j across one-shot DAGs. Apply logistic decay threshold τ_j(m_j) = (τ_max - τ_min) · 1/(1 + e^α(log m_j - log m_0)) + τ_min. Rare labels (small m_j) receive higher thresholds to suppress noise; common labels receive lower thresholds to retain weaker edges.
- Core assumption: Edge frequencies correlate with true causal strength and noise is uniformly distributed across label supports.
- Evidence anchors:
  - [abstract] "aggregates noisy graphs with adaptive thresholds"
  - [section IV-D] "Rare labels require higher thresholds to regularize noisy edges, while common labels can afford lower thresholds"
  - [corpus] No direct corpus validation for this specific thresholding scheme.
- Break condition: If label support distribution deviates significantly from assumed long-tail shape, or if noise is label-correlated, threshold calibration fails.

### Mechanism 3
- Claim: Multi-agent orchestration with RAG-based context retrieval enables interpretable Boolean rule synthesis that outperforms LLM-only baselines.
- Mechanism: Causal Discovery Agent outputs candidate DTCs with ACE and PMI indicators. Contextual Information Agent retrieves DTC descriptions, known EP rules, and metadata via Titan V2 embeddings. Orchestrator Agent synthesizes this into 5 candidate rules (HIGH/MEDIUM/LOW confidence) with traceable reasoning chains.
- Core assumption: Retrieved textual context and causal indicators are sufficient for the orchestrator LLM to construct logically valid Boolean rules.
- Evidence anchors:
  - [abstract] "outperforming LLM-only baselines while providing transparent reasoning"
  - [section V-E] "CAREP achieves a Recall@1 of 0.70, compared to 0.25 for the best-performing baseline (Claude Sonnet 3.7)"
  - [corpus] Related work on LLM-based multi-agent systems (arXiv:2510.18155) shows similar orchestration benefits in consumer behavior simulation.
- Break condition: If causal indicators are sparse or misleading, or if RAG retrieval fails to surface relevant known rules, orchestrator hallucinates invalid Boolean logic.

## Foundational Learning

- Concept: Conditional Mutual Information (CMI)
  - Why needed here: Core mathematical criterion for detecting causal dependencies between events and labels in sequences.
  - Quick check question: Given P(A|B) and P(A|B,C), can you compute whether C provides additional information about A beyond B?

- Concept: Self-supervised Transformer pretraining for event sequences
  - Why needed here: Tfx and Tfy must learn meaningful next-event and next-label distributions before causal discovery can operate.
  - Quick check question: How does masked vs. autoregressive pretraining affect what conditional probabilities a model can estimate?

- Concept: Retrieval-Augmented Generation (RAG)
  - Why needed here: Contextual Information Agent retrieves domain knowledge (DTC descriptions, known EP rules) to ground rule synthesis.
  - Quick check question: What embedding similarity threshold determines if a retrieved document is relevant enough to include in context?

## Architecture Onboarding

- Component map:
  Causal Discovery Agent -> Contextual Information Agent -> Orchestrator Agent
  Dual SLM backbone: Tfx (90M params, next-DTC prediction) -> Tfy (15M params, next-EP prediction)

- Critical path:
  1. Pretrain Tfx/Tfy on historical DTC sequences.
  2. For each unknown EP, sample N contexts from Tfx and compute CMI between all DTCs and the EP label.
  3. Generate m one-shot DAGs, aggregate via adaptive threshold τ_j.
  4. Retrieve contextual information via embedding similarity.
  5. Orchestrator synthesizes candidate Boolean rules with natural language explanations.

- Design tradeoffs:
  - Higher N (Monte Carlo samples) improves CMI estimate quality but increases compute cost.
  - Lower τ_min retains more candidate edges but risks false positives; higher τ_max suppresses noise but may miss genuine causes.
  - Smaller SLMs are faster but may produce less reliable conditional estimates (Table I shows 47M params underperforms 105M).

- Failure signatures:
  - High variance in ACE across samples indicates unstable causal estimates.
  - Negative PMI between DTCs that should co-occur suggests incorrect aggregation or thresholding.
  - Orchestrator outputting rules that contradict known EP logic indicates RAG retrieval failure or prompt design issues.

- First 3 experiments:
  1. Validate Tfx/Tfy classification performance on held-out sequences before causal discovery (baseline: F1 > 88% per Table I).
  2. Ablate adaptive threshold by fixing τ across all labels; expect precision drop on tail labels.
  3. Run CAREP without Contextual Information Agent (orange block in Fig 2 removed); compare semantic accuracy against full system to quantify RAG contribution.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can CAREP generalize to high-dimensional event sequences in non-automotive domains without architecture modifications?
- Basis in paper: [explicit] The Conclusion states CAREP offers a paradigm for "event-driven systems" with potential extensions to "predictive maintenance, robotics."
- Why unresolved: The current evaluation is restricted to a single automotive dataset of Diagnostic Trouble Codes (DTCs).
- What evidence would resolve it: Successful application and benchmarking on disparate sequential data, such as Electronic Health Records (EHR) or industrial IoT logs.

### Open Question 2
- Question: How does the adaptive thresholding mechanism perform under non-stationary conditions where the underlying causal structure drifts over time?
- Basis in paper: [explicit] The Introduction notes that rules are "dynamically updated by a domain expert based on the new incoming data."
- Why unresolved: The evaluation assumes a static ground truth, whereas real-world vehicle fleets evolve, potentially rendering the fitted threshold function (τ_j) obsolete.
- What evidence would resolve it: A longitudinal study analyzing the stability of discovered rules and threshold efficacy as vehicle hardware ages or software updates are deployed.

### Open Question 3
- Question: Does CAREP effectively discover *de novo* error patterns that differ structurally from the 474 known rules used in the pretraining data?
- Basis in paper: [inferred] The Evaluation methodology masks a random subset of *known* rules to simulate unknowns, which may bias the test set toward rule structures the models have already encountered during pretraining.
- Why unresolved: It is unclear if the system can identify entirely novel causal relationships or if it relies on the distributional priors of existing rules.
- What evidence would resolve it: Evaluation on newly introduced vehicle models with previously unobserved error patterns, rather than masked subsets of historical data.

## Limitations
- The system's performance depends heavily on the quality of pretrained Transformers, but architectural details and hyperparameter sensitivity remain underspecified.
- The adaptive thresholding mechanism lacks empirical validation across different label support distributions, raising generalizability concerns.
- RAG component effectiveness depends on embedding index quality, but retrieval accuracy metrics are not reported.

## Confidence

- **High confidence**: The multi-agent architecture combining causal discovery with contextual retrieval is technically sound and addresses a well-defined problem in automotive diagnostics. The use of CMI as a causal criterion is methodologically appropriate for this domain.
- **Medium confidence**: The adaptive thresholding approach for handling label imbalance shows theoretical merit but lacks direct empirical validation. The reported performance metrics appear internally consistent but depend on assumptions about data quality and distribution.
- **Low confidence**: The specific Transformer architectures and sampling hyperparameters (N, γ, top-k/nucleus parameters) are insufficiently detailed for guaranteed reproduction, and the sensitivity of results to these choices remains unquantified.

## Next Checks
1. Conduct ablation studies varying the CMI sensitivity parameter γ across a range of values to establish robustness of causal discovery performance.
2. Test the adaptive thresholding mechanism on synthetic long-tailed distributions with controlled noise levels to validate its effectiveness independent of the full CAREP pipeline.
3. Perform error analysis on false positive rules to determine whether they stem from SLM limitations, RAG retrieval failures, or LLM reasoning errors, then target improvements accordingly.