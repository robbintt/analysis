---
ver: rpa2
title: 'Chat-of-Thought: Collaborative Multi-Agent System for Generating Domain Specific
  Information'
arxiv_id: '2506.10086'
source_url: https://arxiv.org/abs/2506.10086
tags:
- system
- chat-of-thought
- fmea
- generation
- failure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The Chat-of-Thought system addresses the labor-intensive and error-prone
  manual creation of Failure Modes and Effects Analysis (FMEA) documents for industrial
  assets by automating the process using a multi-agent framework with specialized
  roles. The core innovation lies in a dynamic, multi-persona-driven Chat-of-Thought
  mechanism, where LLM-based agents engage in iterative discussions to collaboratively
  refine FMEA outputs, extending beyond traditional Chain-of-Thought reasoning.
---

# Chat-of-Thought: Collaborative Multi-Agent System for Generating Domain Specific Information

## Quick Facts
- arXiv ID: 2506.10086
- Source URL: https://arxiv.org/abs/2506.10086
- Reference count: 5
- Primary result: Automates FMEA document generation using a multi-agent framework with dynamic persona-driven collaboration, validated by SMEs for accuracy in identifying failure modes, root causes, and effects.

## Executive Summary
The Chat-of-Thought system automates the creation of Failure Modes and Effects Analysis (FMEA) documents for industrial assets, addressing the labor-intensive and error-prone nature of manual processes. By leveraging a multi-agent framework with specialized roles—Facilitator, Reliability Engineer, Quality Engineer, SME Validator, and Summarizer—the system iteratively refines outputs through a dynamic, multi-persona-driven "Chat-of-Thought" mechanism. This approach extends beyond traditional Chain-of-Thought reasoning, integrating context-aware routing, template-driven workflows, and iterative learning across multiple rounds. Validation by Subject Matter Experts confirmed the system's ability to generate accurate FMEA tables for both standard and out-of-scope assets, identifying failure modes, root causes, and effects with high precision. The system demonstrates transformative potential for enhancing reliability planning and operational efficiency in industrial applications.

## Method Summary
The Chat-of-Thought system employs a multi-agent framework with five specialized personas to automate FMEA document generation. The process begins with a zero-shot round, followed by in-context learning and iterative feedback loops. A Facilitator selects questions, a Router assigns them to specialized agents, and a Summarizer aggregates responses. The system uses a pre-trained classifier and self-BLEU score threshold to filter redundant or irrelevant content. Iterative refinement across multiple rounds optimizes content generation and validation, ensuring accurate identification of failure modes, root causes, and effects.

## Key Results
- SMEs validated the system's ability to generate accurate FMEA tables for both standard and out-of-scope assets.
- The system reliably identified failure modes, root causes, and effects with high precision.
- The iterative refinement process improved output quality and reduced hallucinations.

## Why This Works (Mechanism)
The system's success lies in its dynamic, multi-persona-driven "Chat-of-Thought" mechanism, which enables iterative refinement of FMEA outputs through specialized agent roles. By integrating context-aware routing and template-driven workflows, the system ensures grounded and relevant content generation. The iterative learning process, combined with post-processing filters like self-BLEU scoring, enhances output quality and reduces redundancy.

## Foundational Learning
- **Multi-agent frameworks**: Enable specialized roles and collaborative reasoning for complex tasks. *Why needed*: To distribute expertise and improve output accuracy. *Quick check*: Verify agent coordination and role-specific prompts.
- **Iterative refinement**: Enhances content quality through multiple rounds of feedback and learning. *Why needed*: To reduce hallucinations and improve precision. *Quick check*: Measure improvement in output quality across rounds.
- **Context-aware routing**: Ensures questions are directed to the most relevant agent. *Why needed*: To maintain grounding and relevance in responses. *Quick check*: Validate routing accuracy with test queries.

## Architecture Onboarding
- **Component map**: Input (Asset class, parameters) -> Multi-agent system (5 personas) -> Iterative rounds (Zero-shot → In-context → Feedback) -> Output (FMEA table) -> Post-processing (Self-BLEU filtering) -> SME validation.
- **Critical path**: Asset input → Context discovery → Agent collaboration → Iterative refinement → Output validation.
- **Design tradeoffs**: High agent specialization improves accuracy but increases complexity; iterative refinement enhances quality but requires more computational resources.
- **Failure signatures**: Hallucinations (lack of grounding), redundancy (poor filtering), and coordination issues (misaligned agent roles).
- **First experiments**:
  1. Implement placeholder agent prompts and test multi-round iterative process to identify bottlenecks.
  2. Compare system outputs against a gold-standard dataset to quantify precision and recall.
  3. Conduct an ablation study to assess the impact of removing the pre-trained classifier and self-BLEU filtering.

## Open Questions the Paper Calls Out
None

## Limitations
- The absence of specific agent prompts and skill definitions limits reproducibility.
- Evaluation relies heavily on SME validation without detailed metrics, introducing subjectivity.
- Dependence on proprietary knowledge repositories raises concerns about generalizability.

## Confidence
- **High Confidence**: The core concept of using a multi-agent system for FMEA automation is sound and well-aligned with current LLM capabilities.
- **Medium Confidence**: The iterative refinement process and template-driven workflows are plausible but require validation of their effectiveness.
- **Low Confidence**: The specific implementation details of the "Chat-of-Thought" mechanism, including agent skill definitions and the pre-trained classifier, are insufficiently specified for direct reproduction.

## Next Checks
1. Implement a prototype with placeholder agent prompts and test the multi-round iterative process to identify bottlenecks in context retrieval and agent coordination.
2. Conduct a controlled experiment comparing the system's FMEA outputs against a gold-standard dataset to quantify precision and recall of failure modes identified.
3. Perform an ablation study to assess the impact of removing the pre-trained classifier and self-BLEU filtering on output quality and redundancy.