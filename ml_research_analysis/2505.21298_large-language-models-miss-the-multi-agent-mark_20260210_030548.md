---
ver: rpa2
title: Large Language Models Miss the Multi-Agent Mark
arxiv_id: '2505.21298'
source_url: https://arxiv.org/abs/2505.21298
tags:
- llms
- agents
- language
- systems
- multi-agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MAS LLMs often lack key multi-agent characteristics like social
  intelligence, autonomy, and structured environments, relying on LLM-centric designs
  and oversimplified coordination methods. The authors argue that current MAS LLM
  frameworks overlook decades of MAS research on social agents, deterministic environments,
  asynchronous systems, and formal communication protocols.
---

# Large Language Models Miss the Multi-Agent Mark

## Quick Facts
- arXiv ID: 2505.21298
- Source URL: https://arxiv.org/abs/2505.21298
- Authors: Emanuele La Malfa; Gabriele La Malfa; Samuele Marro; Jie M. Zhang; Elizabeth Black; Michael Luck; Philip Torr; Michael Wooldridge
- Reference count: 40
- Key outcome: MAS LLMs often lack key multi-agent characteristics like social intelligence, autonomy, and structured environments, relying on LLM-centric designs and oversimplified coordination methods.

## Executive Summary
The paper critically examines the integration of large language models into multi-agent systems, arguing that current approaches fail to leverage decades of multi-agent systems (MAS) research. The authors identify a gap between established MAS principles and LLM-centric implementations, particularly regarding social intelligence, autonomy, and structured environments. They argue that most MAS LLM frameworks rely on natural language communication, deterministic and LLM-centric environments, and lack formal definitions for emergent behaviors.

## Method Summary
The paper conducts a comprehensive literature review and analysis of existing MAS LLM frameworks, comparing their design choices against established MAS principles. The authors examine various frameworks' approaches to agent autonomy, communication protocols, environmental design, and emergent behavior definitions. They identify patterns in how current MAS LLM implementations diverge from traditional MAS research and propose areas for improvement.

## Key Results
- Current MAS LLM frameworks lack social intelligence, theory of mind capabilities, and true autonomy
- Most environments are LLM-centric, deterministic, and partially observable, ignoring LLM limitations
- Communication relies heavily on natural language rather than structured protocols
- Emergent behaviors are often reported descriptively without formal definitions or quantifiable metrics

## Why This Works (Mechanism)
The paper's argument works by systematically comparing MAS LLM frameworks against established MAS principles and identifying specific areas where current implementations fall short. By highlighting the gap between LLM-centric designs and proven MAS approaches, the authors demonstrate how current frameworks miss opportunities for improved agent coordination, communication, and emergent behavior.

## Foundational Learning
1. Multi-Agent Systems Theory
   - Why needed: Understanding traditional MAS principles and architectures
   - Quick check: Can identify key MAS concepts like FIPA standards and BDI agents

2. Theory of Mind in AI
   - Why needed: Critical for agents to reason about other agents' beliefs and intentions
   - Quick check: Can explain how ToM differs from simple goal-directed behavior

3. Emergent Behavior in MAS
   - Why needed: Understanding how complex system behaviors arise from simple agent interactions
   - Quick check: Can distinguish between prescribed and emergent behaviors

4. Communication Protocols in MAS
   - Why needed: Structured communication is essential for reliable agent coordination
   - Quick check: Can compare natural language vs. formal protocol advantages

5. Environment Design for MAS
   - Why needed: Environments shape agent behavior and system capabilities
   - Quick check: Can identify deterministic vs. stochastic environment characteristics

## Architecture Onboarding

Component Map:
MAS LLM Framework -> Agent Design -> Environment Design -> Communication Protocol -> Emergent Behavior Monitoring

Critical Path:
1. Agent Design (autonomy, social intelligence) -> 2. Environment Design (structure, observability) -> 3. Communication Protocol (structured vs. natural language) -> 4. Emergent Behavior Definition/Measurement

Design Tradeoffs:
- Natural language communication: flexible but ambiguous vs. structured protocols: precise but rigid
- LLM-centric environments: easy to implement vs. traditional MAS environments: more robust but complex
- Emergent behavior reporting: descriptive but qualitative vs. formal metrics: quantifiable but harder to define

Failure Signatures:
- Agents fail to coordinate effectively
- Communication breakdowns in complex scenarios
- Emergent behaviors not reproducible or quantifiable
- Theory of mind capabilities not demonstrated

First Experiments:
1. Compare MAS LLM performance with natural language vs. structured communication protocols
2. Test agent autonomy in deterministic vs. stochastic environments
3. Measure emergent behavior using formal metrics vs. descriptive reporting

## Open Questions the Paper Calls Out
Major uncertainties remain regarding the empirical evidence supporting the claim that MAS LLMs systematically lack social intelligence and autonomy, as the paper does not provide direct quantitative benchmarks comparing MAS LLM frameworks against traditional MAS approaches. The characterization of environments as "deterministic and LLM-centric" is not substantiated with concrete examples of how these environments differ from established MAS benchmarks. The assertion that natural language communication is inherently "ambiguous and costly" lacks comparative analysis with structured protocols in MAS LLM settings.

## Limitations
- Lack of direct quantitative benchmarks comparing MAS LLM frameworks against traditional MAS approaches
- Insufficient concrete examples of how LLM-centric environments differ from established MAS benchmarks
- Missing comparative analysis of natural language vs. structured protocols in MAS LLM settings

## Confidence
- High: Identifying the gap between MAS literature and LLM applications
- Medium: Proposed limitations of social intelligence and autonomy
- Low: Claims about necessity of structured communication protocols without empirical validation

## Next Checks
1. Conduct controlled experiments comparing MAS LLM performance using natural language versus structured communication protocols in standardized MAS benchmarks.
2. Develop and apply a formal metric for measuring emergent behavior in MAS LLM systems to replace descriptive reporting.
3. Create a comparative study of LLM training methods (isolated vs. multi-agent) to assess impact on theory of mind capabilities.