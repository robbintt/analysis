---
ver: rpa2
title: Maximally-Informative Retrieval for State Space Model Generation
arxiv_id: '2506.12149'
source_url: https://arxiv.org/abs/2506.12149
tags:
- arxiv
- documents
- retrieval
- document
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of selecting the most informative
  documents for retrieval-augmented generation (RAG) when processing large datasets
  with bounded model resources. The authors propose Retrieval In-Context Optimization
  (RICO), a method that uses gradients from state space models (SSMs) to learn the
  optimal mixture of documents for a given query.
---

# Maximally-Informative Retrieval for State Space Model Generation

## Quick Facts
- arXiv ID: 2506.12149
- Source URL: https://arxiv.org/abs/2506.12149
- Authors: Evan Becker, Benjamin Bowman, Matthew Trager, Tian Yu Liu, Luca Zancato, Wei Xia, Stefano Soatto
- Reference count: 20
- Primary result: Introduces RICO, a method using SSM gradients to optimize document selection for RAG systems

## Executive Summary
This paper addresses the challenge of selecting the most informative documents for retrieval-augmented generation (RAG) when processing large datasets with bounded model resources. The authors propose Retrieval In-Context Optimization (RICO), a method that uses gradients from state space models (SSMs) to learn the optimal mixture of documents for a given query. Unlike traditional RAG systems that rely on external heuristics, RICO leverages direct feedback from the model by optimizing document weights to minimize question perplexity.

## Method Summary
RICO works by encoding documents and queries, then using a differentiable attention mechanism with learnable weights to create a weighted mixture of documents. The SSM processes this mixture and produces gradients with respect to the document weights. These gradients are used to optimize the weights through backpropagation, minimizing the perplexity of the question conditioned on the documents. The method can be viewed as a continuous relaxation of top-k retrieval, where the optimization procedure learns to select the most informative documents.

## Key Results
- RICO achieves comparable retrieval-side metrics to BM25 without fine-tuning
- Often outperforms fine-tuned dense retrievers like E5 in terms of final prediction quality
- Particularly effective in long-context scenarios, significantly improving generation quality compared to concatenating full documents

## Why This Works (Mechanism)
RICO leverages the gradients from SSMs to directly optimize document selection based on how well the documents help answer the query. By minimizing perplexity through gradient-based optimization of document weights, RICO can identify the most informative subset of documents without relying on external heuristics or pre-trained retrievers.

## Foundational Learning

1. **State Space Models (SSMs)**: Why needed - To process long sequences efficiently and provide gradients for optimization. Quick check - Verify SSM can handle the document mixture and produce meaningful gradients.

2. **Differentiable Attention**: Why needed - To create a continuous relaxation of document selection. Quick check - Ensure attention weights are properly updated during optimization.

3. **Retrieval-Augmented Generation (RAG)**: Why needed - To understand the context of document selection for question answering. Quick check - Confirm that the retrieved documents improve generation quality.

## Architecture Onboarding

**Component Map**: Query/Document Encoder -> Attention Weights -> Document Mixture -> SSM -> Perplexity Loss -> Gradient Update

**Critical Path**: The most critical path is from the document mixture through the SSM to the perplexity loss, as this determines how well the selected documents help answer the query.

**Design Tradeoffs**: The main tradeoff is between the number of documents selected (k) and the quality of the selected documents. Larger k values provide more context but may include less informative documents, while smaller k values risk missing important information.

**Failure Signatures**: If RICO fails to improve over baseline methods, potential causes include: 1) The SSM is not sensitive enough to document changes, 2) The optimization gets stuck in local minima, or 3) The document encoder is not producing meaningful representations.

**First Experiments**:
1. Verify that the SSM produces meaningful gradients with respect to document weights.
2. Test RICO's performance with varying numbers of selected documents (k).
3. Compare RICO's optimization process with random document selection to confirm it learns useful patterns.

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical underpinnings of why SSMs are particularly suited for this task are not fully explored
- Performance relative to more established RAG approaches on diverse datasets is not comprehensively evaluated
- Computational efficiency compared to traditional RAG approaches is not thoroughly analyzed

## Confidence
- Overall effectiveness of RICO in improving generation quality: Medium
- Theoretical claims regarding connection to leave-one-out loss: Medium
- Practical significance of approximation to top-k retrieval: Medium

## Next Checks
1. Evaluate RICO's performance on a wider range of datasets, including those with different domains and question types, to assess its generalizability.
2. Compare the computational efficiency of RICO against traditional RAG approaches, particularly in terms of the overhead introduced by the gradient-based optimization process.
3. Conduct ablation studies to determine the impact of different components of RICO, such as the choice of SSM, the optimization algorithm, and the number of documents selected, on the overall performance.