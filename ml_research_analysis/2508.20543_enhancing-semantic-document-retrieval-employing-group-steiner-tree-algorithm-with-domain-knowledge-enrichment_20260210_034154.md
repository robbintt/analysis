---
ver: rpa2
title: Enhancing Semantic Document Retrieval- Employing Group Steiner Tree Algorithm
  with Domain Knowledge Enrichment
arxiv_id: '2508.20543'
source_url: https://arxiv.org/abs/2508.20543
tags:
- concepts
- retrieval
- search
- semantic
- documents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of semantic document retrieval
  from heterogeneous data sources, proposing a novel algorithm based on Group Steiner
  Tree (GST) and domain knowledge enrichment. The approach constructs a weighted semantic
  concept graph to represent domain knowledge, incorporating both explicit and latent
  concepts.
---

# Enhancing Semantic Document Retrieval- Employing Group Steiner Tree Algorithm with Domain Knowledge Enrichment

## Quick Facts
- arXiv ID: 2508.20543
- Source URL: https://arxiv.org/abs/2508.20543
- Reference count: 40
- Key outcome: SemDR achieves 90% precision and 82% accuracy in semantic document retrieval using GST algorithm with domain knowledge enrichment

## Executive Summary
This paper addresses the challenge of semantic document retrieval from heterogeneous data sources by proposing a novel algorithm based on Group Steiner Tree (GST) and domain knowledge enrichment. The approach constructs a weighted semantic concept graph to represent domain knowledge, incorporating both explicit and latent concepts. The SemDR system demonstrates significant improvements over baseline systems, achieving 90% precision and 82% accuracy in document retrieval through its unique combination of semantic mapping and graph optimization.

## Method Summary
The SemDR system constructs a weighted semantic concept graph from domain knowledge represented as SPO triples, then applies a greedy GST algorithm to find relevant concepts that connect anchor concepts derived from search queries. The system includes a semantic indexing layer that maps documents to concepts using static Wikipedia-derived clusters and semantic similarity thresholds. The GST algorithm identifies the minimum-cost tree connecting anchor concept groups while minimizing associated costs based on inverse Jaccard similarity scores between concepts.

## Key Results
- SemDR achieves 90% precision and 82% accuracy in document retrieval
- Outperforms keyword-based and semantic-based retrieval systems on complex queries
- Validated using 170 real-world search queries and domain expert verification
- Demonstrates particular effectiveness in handling geographic locations and time parameters

## Why This Works (Mechanism)

### Mechanism 1
Domain-enriched semantic concept graphs improve retrieval by capturing both explicit and latent relationships, enabling relevant document discovery even when query terms do not directly match document text. The system constructs a weighted semantic concept graph from domain knowledge and document metadata, identifies anchor concepts from the search query based on high semantic proximity, expands them into latent concepts, and applies GST to find a minimal-cost tree connecting these groups. This reveals intermediate concepts semantically linked to the anchors, allowing retrieval of documents associated with these connected concepts.

Core assumption: Domain knowledge is accurate and sufficiently complete to link query concepts to document concepts, and semantic proximity correctly identifies relevant relationships.

### Mechanism 2
Formulating retrieval as a graph optimization problem (minimizing connection cost) improves precision by prioritizing paths through semantically dense concept clusters. The GST algorithm seeks the minimum-cost tree connecting anchor concept groups, with edge costs derived from inverse Jaccard similarity scores based on shared documents between concepts. This weighting scheme penalizes paths between concepts with little document overlap and favors paths through frequently co-occurring concepts.

Core assumption: Edge weighting scheme (Inverse Jaccard similarity) is a valid proxy for semantic relatedness and connection quality.

### Mechanism 3
A dedicated semantic mapping and indexing layer bridges heterogeneous data sources and the symbolic concept graph. The system extracts metadata from diverse files, uses static generic clusters (pre-computed from Wikipedia) as an intermediary, and maps documents to clusters and clusters to domain concepts via semantic similarity. This creates a persistent semantic index structure linking every concept to its relevant original documents.

Core assumption: Static generic clusters from Wikipedia are a sufficiently stable basis for mapping domain-specific documents to domain-specific concepts.

## Foundational Learning

- Concept: Knowledge Graphs (KGs) and SPO Triples
  - Why needed here: The entire system's reasoning power comes from its structured domain representation. Understanding that knowledge is encoded as a graph of nodes (concepts) and edges (relationships), often stored as Subject-Predicate-Object (SPO) triples.
  - Quick check question: Given the triple (Cotton, is_a, Fiber), which part represents a concept and which part defines the relationship?

- Concept: Semantic Similarity
  - Why needed here: This is the "glue" of the system. It's the numerical score (0 to 1) that determines if a query word is related to a graph concept, if a document belongs to a cluster, and if two concepts should have a semantic edge.
  - Quick check question: If the Wu-Palmer semantic similarity between 'Export' and 'Trading' is 0.92, and the system's threshold is 0.9, would they be linked?

- Concept: Group Steiner Tree (GST) Problem
  - Why needed here: This is the core algorithmic contribution, not a standard retrieval technique. Understanding that it's an optimization problem seeking to connect sets of nodes (groups) at minimal cost, which is the formal analogy for finding a query's "semantic core."
  - Quick check question: In the GST problem as formulated in this paper, is the goal to connect every node in the identified groups, or just at least one node from each group?

## Architecture Onboarding

- Component map: Data Ingestion & Metadata Extractor -> Semantic Pipeline (Concept Graph Builder, Semantic Indexer) -> Query Processor -> Concept Retrieval Engine (GST algorithm) -> Data Access Module

- Critical path: The Concept Retrieval Engine (Algorithm 2) is the most critical and novel component. Its output—the set of relevant concepts—directly determines the quality of the final retrieval. If the GST heuristic fails or produces a suboptimal tree, the entire system's performance degrades.

- Design tradeoffs:
  - Static vs. Dynamic Indexing: Uses static clusters for stability and simplicity, making the system brittle to domain shifts and new vocabulary not present in initial Wikipedia-derived clusters
  - Heuristic vs. Exact Algorithm: Uses greedy heuristic for NP-hard GST problem to ensure scalability, sacrificing optimality for approximate solutions
  - Symbolic vs. Neural: Relies on symbolic knowledge graph for reasoning, achieving high precision for in-domain queries but cannot generalize to concepts not explicitly encoded

- Failure signatures:
  - Empty Result Set: Likely caused by no anchor concepts identified (query terms too distant from any concept in domain KG)
  - Irrelevant Results (Type 1 Error): Caused by poorly constructed GST connecting anchors through high-cost, noisy path
  - Missing Documents (Type 2 Error): Caused by failure in semantic mapping step—relevant documents not linked to concepts in GST

- First 3 experiments:
  1. Graph & Algorithm Validation: Load domain KG, run queries with known ground-truth concepts, manually inspect anchor concepts found and GST path generated
  2. Index Mapping Audit: Take sample documents with expert-assigned concepts, run through Semantic Indexer, measure percentage of correct mappings
  3. Threshold Sensitivity Analysis: Systematically vary semantic similarity threshold, plot effect on precision and recall

## Open Questions the Paper Calls Out

### Open Question 1
How can the SemDR system be generalized to adapt seamlessly across diverse domains beyond the agriculture-specific implementation? The conclusion states, "As part of future work, the aspiration is to evolve SemDR to adapt seamlessly across diverse domains." This is unresolved because the current implementation relies heavily on manually constructed, agriculture-specific ontologies and concept graphs.

### Open Question 2
Can the query module be extended to execute semantic joins over unstructured data sources (PDFs, images) that are currently indexed but excluded from query operations? Section IV.C notes, "In this study, we restrict ourselves to solely querying structured documents." While the indexing pipeline processes heterogeneous formats, the query module limits processing to structured formats like CSV and SQL.

### Open Question 3
How robust is the fixed semantic similarity threshold (0.9) when applied to domains with different terminological densities or synonym frequencies? Section II mentions the threshold was "established... after experimenting with different values" specifically for the agriculture context. This is unresolved because the threshold appears to be a tuned hyperparameter, unclear if universally optimal or requiring re-calibration for every new domain.

## Limitations
- System effectiveness depends heavily on completeness and quality of domain knowledge graph
- Static clustering approach creates rigid mapping that cannot adapt to evolving document corpora
- Greedy heuristic for NP-hard GST problem provides only approximate solutions
- Semantic similarity threshold of 0.9 is arbitrarily high and may exclude relevant concepts

## Confidence
- Semantic concept graph construction and GST algorithm implementation: High
- Reported precision and accuracy metrics: Medium (domain-specific validation)
- Scalability and performance on large, evolving corpora: Low
- Generalizability to non-hierarchical, unstructured domains: Low

## Next Checks
1. Conduct ablation study varying the semantic similarity threshold (0.7, 0.8, 0.9) to quantify precision-recall tradeoff and identify optimal operating point
2. Test system performance on out-of-domain queries (e.g., unrelated technical documentation) to measure generalization limits and Type 1/Type 2 error rates
3. Implement incremental clustering update mechanism and measure degradation in retrieval quality when new vocabulary emerges in document corpus