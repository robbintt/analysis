---
ver: rpa2
title: 'Not All Samples Are Equal: Quantifying Instance-level Difficulty in Targeted
  Data Poisoning'
arxiv_id: '2509.06896'
source_url: https://arxiv.org/abs/2509.06896
tags:
- poisoning
- attacks
- difficulty
- attack
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of quantifying instance-level
  difficulty in targeted data poisoning attacks, where attackers aim to manipulate
  the prediction of specific test samples while maintaining normal performance on
  others. The authors identify three key factors that influence poisoning difficulty:
  classification difficulty during clean training, parameter-space poisoning distance,
  and poison budget.'
---

# Not All Samples Are Equal: Quantifying Instance-level Difficulty in Targeted Data Poisoning

## Quick Facts
- arXiv ID: 2509.06896
- Source URL: https://arxiv.org/abs/2509.06896
- Authors: William Xu; Yiwei Lu; Yihan Wang; Matthew Y. R. Yang; Zuoqiu Liu; Gautam Kamath; Yaoliang Yu
- Reference count: 25
- This paper introduces metrics to quantify instance-level difficulty in targeted data poisoning attacks without requiring actual poisoning

## Executive Summary
This paper addresses the problem of quantifying instance-level difficulty in targeted data poisoning attacks, where attackers aim to manipulate the prediction of specific test samples while maintaining normal performance on others. The authors identify three key factors that influence poisoning difficulty: classification difficulty during clean training, parameter-space poisoning distance, and poison budget. They introduce three metrics to quantify these factors: ergodic prediction accuracy (EPA), poisoning distance (δ), and budget lower bound (τ). All metrics can be computed using only clean training data and processes without requiring actual poisoning attacks.

The proposed metrics successfully predict poisoning difficulty across diverse scenarios and attack methods on CIFAR-10 and TinyImageNet datasets. EPA effectively separates easy-to-poison from hard-to-poison samples, while δ and τ provide fine-grained predictions for specific poison classes. The metrics demonstrate strong correlation with attack success rates and offer complementary insights into instance-level vulnerability, enabling efficient estimation of attack feasibility before costly poisoning attempts.

## Method Summary
The authors propose three metrics to quantify instance-level poisoning difficulty: ergodic prediction accuracy (EPA), poisoning distance (δ), and budget lower bound (τ). EPA measures classification difficulty during clean training by computing the average prediction entropy over perturbed inputs. Poisoning distance δ quantifies how far an optimal poison sample lies from the decision boundary in parameter space. Budget lower bound τ estimates the minimum number of poison samples needed for successful attack based on theoretical analysis. These metrics can be computed using only clean training data and processes without requiring actual poisoning attacks. The approach enables efficient estimation of attack feasibility before costly poisoning attempts.

## Key Results
- EPA effectively separates easy-to-poison from hard-to-poison samples across multiple attack methods and datasets
- δ and τ provide fine-grained predictions for specific poison classes, though with some limitations in high-dimensional spaces
- All three metrics successfully predict poisoning difficulty on CIFAR-10 and TinyImageNet datasets
- The metrics demonstrate strong correlation with actual attack success rates without requiring actual poisoning

## Why This Works (Mechanism)
The approach works by decomposing poisoning difficulty into three measurable components: the inherent difficulty of classifying the target sample (EPA), the geometric distance to the decision boundary in parameter space (δ), and the minimum resources required for successful attack (τ). By quantifying each factor independently using only clean training data, the method provides a comprehensive yet computationally efficient framework for estimating poisoning vulnerability. The EPA metric captures the baseline difficulty of the classification task, while δ and τ account for the specific requirements of poisoning attacks. This decomposition allows for targeted analysis of different attack scenarios and enables practitioners to identify the most vulnerable samples without expensive trial-and-error poisoning attempts.

## Foundational Learning
- **Ergodic Prediction Accuracy**: Measures classification difficulty by computing average prediction entropy over perturbed inputs. Why needed: Captures baseline difficulty of classifying target samples. Quick check: Compare EPA scores across different datasets to verify they reflect intuitive difficulty levels.
- **Parameter-Space Poisoning Distance**: Quantifies geometric distance between optimal poison and decision boundary in parameter space. Why needed: Determines how far attackers must move decision boundary to achieve poisoning. Quick check: Verify δ correlates with attack success rates across different models.
- **Budget Lower Bound**: Estimates minimum poison samples required for successful attack based on theoretical analysis. Why needed: Provides resource requirements for feasible attacks. Quick check: Compare predicted τ values with actual poison budgets needed in controlled experiments.
- **Decision Boundary Analysis**: Examines classifier behavior near decision boundaries to identify vulnerable regions. Why needed: Helps understand where small perturbations can cause large prediction changes. Quick check: Visualize decision boundaries with and without poison samples.
- **Perturbation Analysis**: Studies effects of input perturbations on classifier predictions. Why needed: Quantifies robustness of predictions to small changes. Quick check: Measure prediction stability under increasing levels of input noise.

## Architecture Onboarding
**Component Map:** Clean classifier -> EPA computation -> Decision boundary analysis -> δ calculation -> Budget analysis -> Difficulty assessment

**Critical Path:** Target sample selection → EPA computation → Decision boundary analysis → Poisoning distance calculation → Budget estimation → Difficulty prediction

**Design Tradeoffs:** The approach trades exact poisoning results for computational efficiency by estimating difficulty using only clean data. This enables rapid vulnerability assessment but may miss attack-specific nuances that only emerge during actual poisoning.

**Failure Signatures:** High EPA but successful poisoning indicates model-specific vulnerabilities not captured by baseline difficulty. Low δ but failed attacks suggest practical constraints beyond geometric distance. Mismatch between predicted and actual budget requirements indicates oversimplified theoretical assumptions.

**First Experiments:**
1. Compute EPA for all test samples on CIFAR-10 and rank by difficulty
2. Measure poisoning distance δ for top 10% easiest and hardest samples
3. Compare predicted budget requirements τ with actual poison samples needed in controlled attacks

## Open Questions the Paper Calls Out
None

## Limitations
- EPA computation may become computationally expensive for very large models or datasets
- Poisoning distance δ assumes linear separability near decision boundaries, which may not hold in high-dimensional spaces
- Budget lower bound τ may be overly optimistic in practice, particularly for models with complex decision surfaces
- Evaluation focuses on image classification tasks; effectiveness on other domains like NLP or graph data remains untested

## Confidence
- **High Confidence**: EPA effectively separates easy-to-poison from hard-to-poison samples across multiple attack methods and datasets
- **Medium Confidence**: δ and τ provide reliable fine-grained predictions for specific poison classes, though assumptions may limit accuracy in high-dimensional spaces
- **Medium Confidence**: The three factors comprehensively explain instance-level poisoning difficulty, though relative importance varies across architectures

## Next Checks
1. Evaluate EPA, δ, and τ metrics on non-vision domains such as NLP transformers or graph neural networks to test cross-domain applicability
2. Test computational scalability of EPA on larger models (e.g., ViT-Large, ResNet-200) and higher-resolution images
3. Conduct ablation studies to determine relative contribution of each metric (EPA, δ, τ) to overall difficulty prediction