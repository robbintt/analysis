---
ver: rpa2
title: 'AgentProg: Empowering Long-Horizon GUI Agents with Program-Guided Context
  Management'
arxiv_id: '2512.10371'
source_url: https://arxiv.org/abs/2512.10371
tags:
- task
- context
- tasks
- agentprog
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of long-horizon GUI agent task
  automation, where existing methods struggle with context management and environmental
  understanding as interaction history grows. The authors propose AgentProg, a program-guided
  context management approach that reframes interaction history as a Semantic Task
  Program with variables and control flow, providing principled mechanisms for retaining
  essential information while discarding irrelevant details.
---

# AgentProg: Empowering Long-Horizon GUI Agents with Program-Guided Context Management

## Quick Facts
- arXiv ID: 2512.10371
- Source URL: https://arxiv.org/abs/2512.10371
- Reference count: 40
- AgentProg achieves 78.0% success rate on AndroidWorld and 68.4% on AW-Extend

## Executive Summary
AgentProg addresses the challenge of long-horizon GUI agent task automation where context management becomes critical as interaction history grows. The paper proposes a program-guided context management approach that reframes interaction history as a Semantic Task Program (STP) with variables and control flow, providing principled mechanisms for retaining essential information while discarding irrelevant details. AgentProg also integrates a global belief state mechanism to handle partial observability and environmental changes. Experiments on AndroidWorld and the extended AW-Extend benchmark demonstrate state-of-the-art performance with significantly improved success rates compared to baseline methods.

## Method Summary
AgentProg is a two-stage framework: (1) STP Generation: an LLM generates a Semantic Task Program with control flow (loops, branches, functions) and explicit variables from task description; (2) STP Execution: alternating Action Generation (translates current STP instruction to Python APIs) and Program Counter Update. The approach uses execution tree pruning (active path only), history retrieval by step ID, and Global Belief State (Predict-Verify-Align). The backbone uses Gemini-2.5-Pro + UI-TARS-1.5-API for grounding.

## Key Results
- Achieves 78.0% success rate on AndroidWorld benchmark
- Achieves 68.4% success rate on extended AW-Extend benchmark
- Maintains stable ~9k dynamic tokens over 50 steps while UI-TARS grows to 18k
- Improves AndroidWorld performance from 53.9% to 78.0% with belief state (+24.1%)
- Improves AW-Extend performance from 35.1% to 68.4% with belief state (+33.3%)

## Why This Works (Mechanism)

### Mechanism 1: Execution Tree-Guided Context Pruning
Structuring interaction history as an execution tree enables principled, task-aware context reduction without losing critical information. The system organizes STP execution into a tree where only the "active path" from root to current node is retained. Unexecuted branches are never added; completed loop iterations are pruned. This replaces unbounded history growth with bounded path-length context.

### Mechanism 2: Variable-Based Information Anchoring
Explicit variable declarations create persistent "anchors" that survive context pruning, preventing loss of task-critical data. During STP generation, the agent identifies and declares essential variables (e.g., `{task_list}`, `{contact_info}`). These are protected from pruning and persist throughout execution.

### Mechanism 3: Global Belief State Verification
Maintaining explicit hypotheses about environment state and verifying against observations enables recovery from partial observability and unexpected changes. A continuous Predict-Verify-Align cycle: (1) maintain hypotheses about hidden states (clipboard, navigation stack, off-screen selections), (2) compare real-time observations against beliefs, (3) on mismatch, invalidate affected beliefs and trigger recovery routines.

## Foundational Learning

- **Partially Observable MDPs (POMDPs)**: GUI agents cannot observe all relevant state (hidden UI elements, system state). The Belief State mechanism is explicitly inspired by Belief MDP frameworks. Quick check: Can you explain why maintaining a probability distribution over hidden states is more robust than assuming the last observation represents true state?

- **Control Flow Graphs and Data Flow Analysis**: The execution tree and variable management directly map to compiler concepts—understanding which variables are "live" at each program point enables safe pruning. Quick check: Given a loop that writes to variable X in iteration 1 and reads X in iteration 5, would standard liveness analysis preserve X? How does AgentProg's approach differ?

- **Interpretation vs. Compilation**: STP uses "semantic tolerance"—natural language instructions interpreted at runtime rather than compiled to fixed APIs. This trades precision for robustness to UI changes. Quick check: What is the tradeoff between pre-compiled scripts (rigid but deterministic) vs. runtime interpretation (flexible but potentially inconsistent)?

## Architecture Onboarding

- **Component map**: STP Generator (planning) → Execution Engine (action generation + PC update) → Context Manager (pruning, variables) → Belief State Module (verification) → UI Grounding Layer (UI-TARS-1.5-API)
- **Critical path**: Task → STP Generation (single call) → Per-step loop: (a) Load context + variables + belief state, (b) Translate STP instruction to Python, (c) Execute Python, (d) Update belief state, (e) Update PC, (f) Prune context
- **Design tradeoffs**: Static prefix (12.5k tokens) vs. dynamic context (~9k tokens) favors long-horizon tasks; Semantic tolerance vs. execution reliability; Two LLM calls per step increases latency for robustness
- **Failure signatures**: Variable undeclared (re-requests information), Belief-state drift (cascading errors), STP structure mismatch (premature pruning or infinite loops)
- **First 3 experiments**: (1) Ablate belief state: run AgentProg without Global Belief State on AndroidWorld; (2) Vary context window: test with 4k, 8k, 16k tokens; (3) Stress test semantic tolerance: introduce UI perturbations and compare STP interpretation vs. rigid script execution

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- Semantic tolerance mechanism is underspecified and trade-offs between interpretation flexibility and execution consistency are not quantified
- Belief state implementation details are missing (representation, detection sensitivity, recovery strategies)
- Dataset representativeness is limited (116 Android tasks, only 19 extended tasks)

## Confidence
**High Confidence**: Context management through execution tree pruning is effective (supported by Figure 8); Belief state provides measurable benefit (24.1% and 33.3% improvements)

**Medium Confidence**: AgentProg achieves state-of-the-art performance (methodology transparency issues); Variable-based anchoring prevents information loss (not quantitatively validated)

**Low Confidence**: Semantic tolerance robustness (mechanism underspecified); Belief state implementation effectiveness (details missing); Generalizability beyond tested datasets (limited scope)

## Next Checks
1. **Ablation Study**: Implement and run AgentProg without belief state on AndroidWorld to verify the claimed 24.1% performance drop, measuring failure mode distribution
2. **Context Scaling Analysis**: Systematically vary context window sizes (4k, 8k, 16k tokens) for both AgentProg and baselines to validate pruning strategy robustness
3. **Semantic Robustness Test**: Design UI perturbation experiments (button renaming, layout shifts, icon changes) on identical task sequences to quantify semantic tolerance advantage