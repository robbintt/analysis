---
ver: rpa2
title: Insights on Adversarial Attacks for Tabular Machine Learning via a Systematic
  Literature Review
arxiv_id: '2506.15506'
source_url: https://arxiv.org/abs/2506.15506
tags:
- adversarial
- attacks
- data
- tabular
- studies
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This systematic literature review consolidates 53 studies on adversarial
  attacks targeting tabular machine learning models, the first comprehensive survey
  in this domain. It analyzes attack methodologies across four optimization strategies
  (gradient-based, gradient-free, learning-based, and hybrid), finding that most gradient-based
  attacks adapt image-based methods with added feasibility constraints.
---

# Insights on Adversarial Attacks for Tabular Machine Learning via a Systematic Literature Review

## Quick Facts
- arXiv ID: 2506.15506
- Source URL: https://arxiv.org/abs/2506.15506
- Reference count: 40
- Primary result: First comprehensive systematic literature review consolidating 53 studies on adversarial attacks targeting tabular machine learning models

## Executive Summary
This systematic literature review provides the first comprehensive survey of adversarial attacks targeting tabular machine learning models. The review consolidates 53 studies and analyzes attack methodologies across four optimization strategies: gradient-based, gradient-free, learning-based, and hybrid approaches. A key finding is that most gradient-based attacks adapt image-based methods with added feasibility constraints to handle the unique challenges of tabular data. The study evaluates practical considerations including attack efficacy, feasibility, and transferability, revealing both strengths and significant gaps in current research. The review identifies the dominance of cybersecurity applications and highlights the lack of standardized benchmarks and rigorous evaluation frameworks in the field.

## Method Summary
The authors conducted a systematic literature review following established methodologies for identifying and analyzing research on adversarial attacks in tabular machine learning. They searched multiple academic databases using predefined search terms related to adversarial attacks, machine learning, and tabular data. Studies were screened based on inclusion criteria focusing on empirical evaluations of attack methodologies. The selected 53 studies were then categorized based on their optimization strategies and analyzed for practical considerations including efficacy, feasibility, and transferability metrics. The review synthesized findings across these studies to identify patterns, gaps, and opportunities for future research in adversarial robustness for tabular data.

## Key Results
- Most gradient-based attacks adapt image-based methods with added feasibility constraints for tabular data
- Attack effectiveness is consistently measured across studies, but real-world applicability factors like plausibility remain underexplored
- Cybersecurity applications dominate the research landscape, with significant gaps in healthcare, finance, and other domains
- Lack of standardized benchmarks and evaluation frameworks hinders comparative analysis and progress in the field

## Why This Works (Mechanism)
Adversarial attacks on tabular machine learning work by exploiting the mathematical vulnerabilities in model decision boundaries through carefully crafted perturbations to input features. These attacks succeed because tabular models, like their image counterparts, make decisions based on learned feature relationships that can be manipulated within feasible bounds. The effectiveness stems from the fact that small, often imperceptible changes to input features can cause significant shifts in model predictions. For tabular data specifically, the challenge lies in maintaining feature validity and semantic meaning while finding adversarial examples, as the features typically represent discrete categories or have specific value ranges that must be preserved.

## Foundational Learning

1. **Tabular Data Characteristics**
   - Why needed: Understanding the unique properties of tabular data (mixed numerical/categorical features, discrete values, semantic constraints) is essential for developing appropriate attack methodologies
   - Quick check: Can the attack maintain valid feature ranges and categorical integrity while perturbing inputs?

2. **Optimization Strategies**
   - Why needed: Different attack approaches (gradient-based, gradient-free, learning-based, hybrid) have distinct trade-offs in computational cost, effectiveness, and applicability to different model types
   - Quick check: Which optimization strategy best balances attack success rate with computational efficiency for the target model architecture?

3. **Feasibility Constraints**
   - Why needed: Real-world attacks must respect data validity, semantic meaning, and operational constraints to be practically relevant
   - Quick check: Do the generated adversarial examples remain plausible within the domain context?

4. **Transferability Principles**
   - Why needed: Understanding when attacks generalize across different models is crucial for black-box attack scenarios
   - Quick check: Does the attack maintain effectiveness when applied to models with different architectures or training data?

5. **Evaluation Metrics Standardization**
   - Why needed: Consistent measurement of attack efficacy, feasibility, and transferability enables meaningful comparison across studies
   - Quick check: Are the evaluation metrics comprehensive enough to capture both technical success and practical relevance?

## Architecture Onboarding

**Component Map:** Attack Strategy Selection -> Feasibility Constraint Application -> Optimization Execution -> Evaluation Metrics Calculation

**Critical Path:** The core workflow involves selecting an appropriate attack strategy based on model access and data characteristics, applying domain-specific feasibility constraints to maintain valid tabular representations, executing the optimization to find adversarial examples, and measuring success through standardized evaluation metrics.

**Design Tradeoffs:** Gradient-based approaches offer high effectiveness but require white-box access and differentiable models, while gradient-free methods sacrifice some success rate for black-box applicability. Learning-based attacks require upfront training costs but can be efficient for repeated attacks. Hybrid approaches attempt to balance these tradeoffs but add implementation complexity.

**Failure Signatures:** Common failure modes include generating infeasible adversarial examples that violate data constraints, attacks that succeed in controlled settings but fail under realistic conditions, and methods that achieve high success rates but produce semantically meaningless perturbations.

**3 First Experiments:**
1. Apply a standard gradient-based attack (adapted from image domain) to a tabular dataset with feasibility constraints and measure success rate versus computational cost
2. Compare transferability of attacks across different tabular model architectures using the same adversarial examples
3. Evaluate the semantic preservation of adversarial examples by measuring feature importance changes and domain expert validation

## Open Questions the Paper Calls Out

The review identifies several critical open questions in tabular adversarial attack research: How can we develop standardized benchmarks and evaluation frameworks that enable meaningful comparison across studies? What methodologies can effectively balance attack success with semantic preservation and plausibility in real-world applications? How can we extend research beyond cybersecurity applications to address vulnerabilities in healthcare, finance, and other critical domains? What theoretical frameworks can explain the unique challenges of adversarial robustness in tabular data compared to other data types? How can we develop attack strategies that are both effective and computationally efficient for large-scale tabular datasets?

## Limitations

- Review scope limited to 53 studies identified through specific search criteria, potentially missing relevant work
- Categorization of attack methodologies may oversimplify nuanced differences between approaches
- Analysis relies on reported metrics that vary in implementation and reporting standards across research groups
- Focus on published literature may reflect publication bias rather than actual research distribution

## Confidence

**High Confidence:**
- Systematic methodology for study selection and categorization is well-documented and reproducible
- Finding that most gradient-based attacks adapt image-based methods with feasibility constraints is directly supported by evidence

**Medium Confidence:**
- Assessment of practical considerations based on reported metrics, but lack of standardized benchmarks introduces uncertainty
- Claim about cybersecurity dominance supported but may reflect publication bias

**Medium Confidence:**
- Identification of semantic preservation gaps based on explicit reporting, though some studies may have addressed this without clear labeling

## Next Checks

1. **Benchmark Standardization Analysis**: Create detailed matrix comparing evaluation metrics across the 53 studies to identify methodological variations in measuring efficacy, feasibility, and transferability

2. **Cross-Domain Application Survey**: Expand literature search beyond cybersecurity to categorize adversarial attack research in healthcare, finance, and other domains for application distribution verification

3. **Semantic Preservation Evaluation Framework**: Develop and pilot test standardized framework for assessing semantic preservation in tabular adversarial attacks, applying it to subset of reviewed studies to validate identified gaps