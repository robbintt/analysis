---
ver: rpa2
title: 'Probing for Phonology in Self-Supervised Speech Representations: A Case Study
  on Accent Perception'
arxiv_id: '2506.17542'
source_url: https://arxiv.org/abs/2506.17542
tags:
- accent
- speech
- english
- features
- phonological
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study investigates whether self-supervised speech representations\
  \ encode phonological feature-level variations that influence the perception of\
  \ segmental accent. Focusing on three segments ([V], [R], [\xFA]) uniformly produced\
  \ by Hindi speakers of English, the authors extract phonological feature probabilities\
  \ using Phonet and pretrained representations from Wav2Vec2-BERT and WavLM."
---

# Probing for Phonology in Self-Supervised Speech Representations: A Case Study on Accent Perception

## Quick Facts
- arXiv ID: 2506.17542
- Source URL: https://arxiv.org/abs/2506.17542
- Reference count: 31
- Primary result: Self-supervised speech representations encode phonological feature-level variations that correlate with human accent perception ratings

## Executive Summary
This study investigates whether self-supervised speech representations encode phonological feature-level variations that influence the perception of segmental accent. Focusing on three segments ([V], [R], [ú]) uniformly produced by Hindi speakers of English, the authors extract phonological feature probabilities using Phonet and pretrained representations from Wav2Vec2-BERT and WavLM. Probing analyses reveal that accent strength is best predicted by subsets of pretrained representation features that prioritize perceptually salient phonological features contrasting native and non-native segments. A multinomial logistic regression of segment distances from American and Indian English baselines on accent ratings shows strong associations between accent strength and distances from baselines in expected directions. The results demonstrate that self-supervised speech representations implicitly encode linguistically meaningful articulatory-acoustic structure for modeling accent perception using interpretable phonological features.

## Method Summary
The paper extracts segment-level representations from SSL models (Wav2Vec2-BERT, WavLM) and phonological feature probabilities from Phonet for Hindi speakers' English segments. Probing classifiers with L1 regularization identify which SSL representation features best predict accent ratings. Canonical correlation analysis interprets the probe-selected features in terms of phonological features. Distance-based regression models assess how representation distances from native and non-native baselines predict accent strength. The analysis is performed on three target segments ([V], [R], [ú]) from the CSLU FAE corpus with 3-point accent ratings.

## Key Results
- SSL representations outperform MFCC by 20-30 F1 points for accent classification probing
- Perceptually salient phonological features (voice, sonorant, approximant) receive prominent weighting in probe-selected features
- Segment distances from American English baseline positively predict accent strength (β = 0.8-2.8, p < .05)
- Segment distances from Indian English baseline negatively predict accent strength (β = -1.0 to -2.8, p < .05)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SSL speech representations encode phonological feature-level information that correlates with human accent perception.
- Mechanism: Pretrained models (Wav2Vec2-BERT, WavLM) implicitly learn articulatory-acoustic structure during self-supervised training. When probed with L1-regularized classifiers, subsets of representation features emerge that correlate strongly with perceptually salient phonological features contrasting native/non-native segment pairs.
- Core assumption: The learned representations capture linguistically meaningful structure rather than purely acoustic patterns.
- Evidence anchors:
  - [abstract] "Probing analyses show that accent strength is best predicted by a subset of the segment's pretrained representation features, in which perceptually salient phonological features that contrast the expected American English and realized non-native English segments are given prominent weighting."
  - [section 4.3] Figures 3 and 4 show canonical correlation-based relative weights >1 for contrastive features like [sonorant], [approximant], [tap], but <1 for [anterior] (retroflex contrast).
  - [corpus] Related work (Bartelds et al., 2022; Chernyak et al., 2024) uses similar distance-based approaches at word/utterance level, but corpus evidence for segment-level phonological probing is limited—neighbors show moderate FMR (0.38–0.58) but zero citations, suggesting emerging rather than established methodology.

### Mechanism 2
- Claim: Perceptual salience modulates which phonological features the representations weight for accent discrimination.
- Mechanism: The [anterior] feature distinguishing [t]-[ú] (alveolar-retroflex) shows low weighting despite being contrastive, consistent with documented low perceptual sensitivity of American English listeners to retroflexion. Features like [voice], [sonorant], [approximant] show high weighting.
- Core assumption: SSL representations reflect perceptual learning biases similar to human listeners, possibly due to training on human-perceived speech tasks.
- Evidence anchors:
  - [section 5] "The importance of perceptual salience is demonstrated by the [anterior] feature, which distinguishes the native alveolar stop [t] from the non-native retroflex stop [ú] but did not show the expected prominent weighting...This likely reflects American English listeners' low perceptual sensitivity to retroflexion."
  - [section 4.3] [consonantal] and [coronal] features have largest weights for retroflex stop, not [anterior].
  - [corpus] Weak corpus support—no neighboring papers directly address perceptual salience weighting in SSL representations.

### Mechanism 3
- Claim: Segment-level Euclidean distances from native/non-native baselines predict accent strength ratings.
- Mechanism: Multinomial logistic regression shows odds of mild/strong accent increase with distance from American English baseline (β = 0.8–2.8 across segments, p < .05) and decrease with distance from Indian English baseline (β = -1.0 to -2.8, p < .05).
- Core assumption: The SSL representation space is structured such that Euclidean distance corresponds to perceptual/accent distance.
- Evidence anchors:
  - [abstract] "A multinomial logistic regression of pretrained representation-based segment distances from American and Indian English baselines on accent ratings reveals strong associations between the odds of accent strength and distances from the baselines, in the expected directions."
  - [section 4.2] Table 3 provides full regression coefficients by segment, representation type, and word position.
  - [corpus] Bartelds et al. (2022) found similar correlations at word level using Pearson correlation; this paper extends to segment-level with logistic regression and positional effects.

## Foundational Learning

- Concept: **Phonological features** (articulatory-acoustic properties like [voice], [anterior], [coronal])
  - Why needed here: The entire probing methodology depends on mapping speech segments to binary or probabilistic phonological features. Without this, you cannot interpret what SSL representations encode.
  - Quick check question: Can you explain why [anterior] distinguishes alveolar [t] from retroflex [ú]?

- Concept: **Probing classifiers with L1 regularization**
  - Why needed here: L1 regularization (Lasso) shrinks irrelevant feature coefficients to zero, enabling identification of which SSL representation dimensions matter for accent prediction. Without this, you get uninterpretable results.
  - Quick check question: Why use L1 rather than L2 regularization if you want feature selection?

- Concept: **Forced alignment (Montreal Forced Aligner)**
  - Why needed here: Segment-level analysis requires precise phone-to-frame alignments. The paper uses MFA with custom acoustic models to avoid noisy output from pre-trained models trained on diverse world Englishes.
  - Quick check question: What goes wrong if your phone alignments are off by 20-50ms for segment extraction?

## Architecture Onboarding

- Component map:
  - **Input**: CSLU FAE corpus (Hindi speakers' English utterances, 3 raters, 4-point scale → collapsed to 3)
  - **Alignment**: Montreal Forced Aligner → phone-level timestamps
  - **Feature extraction (parallel paths)**:
    - Phonet (bi-directional GRU): MFCC → phonological feature probabilities (27 features)
    - SSL models (Wav2Vec2-BERT-2.0 / WavLM-Large): raw audio → 1024-dim layer representations
  - **Aggregation**: Frame-level → segment-level by averaging across aligned frames
  - **Probing**: L1-regularized Logistic Regression / SVM → classify accent rating from SSL features
  - **Interpretation**: SVCCA canonical correlation between probe-selected features and Phonet outputs
  - **Distance modeling**: Euclidean distance from American/Indian English baseline centroids → multinomial logistic regression on accent ratings

- Critical path:
  1. Train Phonet on combined 405hr American+Indian English (80-20 split, 30 epochs max, early stopping)
  2. Extract SSL representations from all 24 layers (Wav2Vec2-BERT Conformer / WavLM Transformer)
  3. Run probing classifiers per layer per segment per model → identify best-performing layer (middle layers win)
  4. Compute SVCCA correlations between probe-selected feature subsets and phonological probabilities
  5. Calculate distances from baseline centroids, regress on accent ratings with position interactions

- Design tradeoffs:
  - **Segment vs. utterance level**: Segment-level enables phonological interpretation but ignores suprasegmental accent cues (rhythm, intonation)
  - **MFCC vs. SSL features**: Table 2 shows SSL outperforms MFCC by 20-30 points F1, but MFCC is interpretable without probing
  - **Minimum vs. mean rater score**: Using minimum rating is conservative (favors stronger accent labels), may underestimate mild accents
  - **Indian English vs. Hindi-specific baseline**: Indian English is a proxy; authors acknowledge potential overlap with American English in baseline data

- Failure signatures:
  - **Low probe accuracy (~40-50% F1)**: Suggests wrong layer, insufficient regularization, or segment extraction errors
  - **All canonical correlations equal (~0.5)**: Probe not selecting meaningful feature subset—check L1 regularization strength
  - **Distance coefficients non-significant or wrong sign**: Baseline data may not match target population; check American/Indian English data quality
  - **[anterior] weighting high for retroflex despite expectations**: Check Phonet training accuracy for that feature (Table 4 shows 88% accuracy—acceptable)

- First 3 experiments:
  1. Replicate layer-wise probing on a held-out accent corpus (e.g., L2-ARCTIC) to verify middle-layer peak replicates across datasets
  2. Ablate Phonet: replace probabilistic features with binary features to test whether gradient encoding matters
  3. Control for suprasegmentals: extract only segments from utterances matched for duration/speaking rate to isolate segmental effects

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the probing methodology for segmental phonological features be extended to model suprasegmental dimensions of accent perception (e.g., rhythm, intonation, stress patterns)?
- Basis in paper: [explicit] "Future work may expand these findings to prosodic dimensions or to other native–nonnative speech pairs."
- Why unresolved: The current study isolated segmental features but did not control for suprasegmental information such as rhythm, which also affects accent ratings.
- What evidence would resolve it: Applying the same probing approach to prosodic features across accented speech, testing whether SSL representations encode suprasegmental phonological information predictive of accent judgments.

### Open Question 2
- Question: Do the associations between phonological feature variations in SSL representations and accent ratings generalize to other L1-L2 speech pairs beyond Hindi speakers of English?
- Basis in paper: [explicit] "Future work may expand these findings to prosodic dimensions or to other native–nonnative speech pairs."
- Why unresolved: The study focused exclusively on Hindi speakers producing three segments uniformly realized across Indian sub-continent languages; other L1 backgrounds with different segmental substitution patterns remain unexplored.
- What evidence would resolve it: Replication with speakers of typologically diverse L1 languages, testing whether the same phonological features receive prominent weighting in SSL representations for accent discrimination.

### Open Question 3
- Question: How do suprasegmental factors interact with segmental phonological features in driving accent perception, and are these interactions captured in SSL representations?
- Basis in paper: [inferred] From the limitations: "Accent ratings are also affected by other non-target segments as well as suprasegmental information such as rhythm which we did not control for."
- Why unresolved: The study isolated segmental contributions but did not model how rhythm, intonation, or other suprasegmental cues might modulate the weighting of segmental features.
- What evidence would resolve it: Controlled experiments manipulating both segmental and suprasegmental features, probing SSL representations for joint encoding and testing interactions in regression models of accent ratings.

## Limitations

- The study focuses on only three segments from Hindi speakers of English, limiting generalizability to other phonological contrasts or language pairs.
- The Indian English baseline used for comparison may not perfectly represent the Hindi-influenced accent patterns, potentially introducing noise in the distance-based analyses.
- The analysis is limited to segmental features and does not account for suprasegmental factors (rhythm, intonation) that also affect accent perception.

## Confidence

- **Medium-High**: The probing methodology shows consistent patterns across SSL models with interpretable feature weightings that align with phonological theory and perceptual salience. The regression analyses demonstrate robust associations between representation distances and human accent ratings. However, confidence is tempered by the limited corpus evidence for segment-level phonological probing in SSL representations.

## Next Checks

1. Replicate the entire analysis pipeline on a different accent corpus (e.g., L2-ARCTIC with Mandarin or Arabic speakers) to verify the phonological probing approach generalizes beyond Hindi-English.
2. Conduct an ablation study removing Phonet entirely and replacing phonological features with linguistically naive feature sets to quantify the added value of interpretable phonological grounding.
3. Extend the analysis to suprasegmental features by correlating prosodic patterns in SSL representations with accent strength ratings, addressing the current limitation to segmental features only.