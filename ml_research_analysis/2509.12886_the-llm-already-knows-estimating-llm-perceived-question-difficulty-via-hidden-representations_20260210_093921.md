---
ver: rpa2
title: 'The LLM Already Knows: Estimating LLM-Perceived Question Difficulty via Hidden
  Representations'
arxiv_id: '2509.12886'
source_url: https://arxiv.org/abs/2509.12886
tags:
- difficulty
- question
- arxiv
- wang
- estimation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method for estimating the difficulty of input
  questions as perceived by large language models (LLMs) using only the hidden representations
  generated by the target LLM, without requiring any output generation. The method
  models the token-level generation process as a Markov chain and defines a value
  function to estimate the expected output quality from any hidden state.
---

# The LLM Already Knows: Estimating LLM-Perceived Question Difficulty via Hidden Representations

## Quick Facts
- arXiv ID: 2509.12886
- Source URL: https://arxiv.org/abs/2509.12886
- Authors: Yubo Zhu; Dongrui Liu; Zecheng Lin; Wei Tong; Sheng Zhong; Jing Shao
- Reference count: 37
- One-line primary result: Method estimates LLM-perceived question difficulty using only hidden representations, achieving ROC-AUC > 93% and Macro-F1 > 79% on benchmarks

## Executive Summary
This paper introduces a novel method for estimating the difficulty of input questions as perceived by large language models (LLMs) without requiring any output generation. The approach leverages the hidden representations generated by the target LLM during processing, modeling the token generation process as a Markov chain and defining a value function to estimate expected output quality from any hidden state. This enables efficient difficulty estimation that can guide adaptive reasoning strategies, reducing inference costs while maintaining or improving performance.

The method demonstrates state-of-the-art performance across both textual and multimodal tasks, outperforming existing baselines in difficulty estimation. By applying this technique to guide strategies like Self-Consistency, Best-of-N, and Self-Refine, the authors show significant improvements in inference efficiency with fewer generated tokens while maintaining high accuracy levels.

## Method Summary
The proposed method estimates LLM-perceived question difficulty by analyzing hidden representations from the target model during input processing. It models the token generation process as a Markov chain, where each state represents a hidden representation and transitions correspond to token predictions. A value function is defined to estimate the expected output quality from any given hidden state, effectively predicting how difficult the model will find answering the question. The method focuses on the [EOS] token representation as a key feature for difficulty estimation, though the approach can be adapted to other architectures. The system is trained on labeled data with known difficulty levels and can then estimate difficulty for new questions without requiring any output generation.

## Key Results
- Achieves 93.09% ROC-AUC and 79.48% Macro-F1 on ScienceQA benchmark
- Outperforms existing baselines in difficulty estimation across multiple datasets
- Successfully guides adaptive reasoning strategies (Self-Consistency, Best-of-N, Self-Refine) with fewer generated tokens
- Demonstrates effectiveness on both textual (MMLU) and multimodal (MMMLU) tasks

## Why This Works (Mechanism)
The method works by leveraging the rich semantic information contained in LLM hidden states during processing. When an LLM processes a question, its hidden representations capture the model's understanding and confidence about how to approach the task. By modeling the generation process as a Markov chain and defining a value function, the method can estimate the expected quality of the final output from any intermediate hidden state. The [EOS] token representation serves as a particularly informative signal because it represents the model's final understanding before beginning output generation. This allows the method to predict difficulty without actually generating any output, making it computationally efficient while still capturing the model's internal assessment of the task complexity.

## Foundational Learning
- Markov chain modeling of token generation: needed to represent the sequential nature of LLM output generation; quick check: verify state transitions follow Markov property
- Value function estimation: needed to predict output quality from hidden states; quick check: ensure value estimates correlate with actual output performance
- Hidden state semantics: needed to extract meaningful difficulty signals; quick check: validate hidden states contain task-relevant information
- Difficulty labeling schemes: needed for training; quick check: ensure labels are consistent and meaningful across different question types
- Sequence-to-difficulty mapping: needed to learn the relationship between processing patterns and task complexity; quick check: test if similar questions yield similar difficulty predictions

## Architecture Onboarding

**Component map**: Input question -> LLM hidden state extraction -> Markov chain modeling -> Value function estimation -> Difficulty score output

**Critical path**: The critical path involves extracting hidden states from the LLM during question processing, identifying the [EOS] token representation, and passing this through the value function model to produce a difficulty score. This path must be optimized for speed since it's used for every input question.

**Design tradeoffs**: The method trades off model complexity for inference efficiency by avoiding output generation. Using the [EOS] token as a primary feature simplifies the approach but may miss earlier signals of difficulty. The Markov chain assumption simplifies modeling but may not capture all dependencies in LLM generation. The training requirement for labeled difficulty data adds upfront cost but enables efficient inference.

**Failure signatures**: The method may fail when hidden states don't reliably encode difficulty information (e.g., for tasks where the model can mask uncertainty), when the Markov chain assumption breaks down for complex reasoning tasks, or when the [EOS] token representation doesn't capture the full context of difficulty. It may also struggle with out-of-distribution questions or when the training data's difficulty labeling scheme doesn't match the target domain.

**First experiments**: 1) Test difficulty estimation on questions with known ground truth difficulty to validate accuracy; 2) Compare difficulty predictions against human assessments of question complexity; 3) Apply the method to guide adaptive sampling strategies and measure efficiency gains.

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on [EOS] token representation may not generalize across different LLM architectures
- Markov chain assumption may oversimplify complex dependencies in LLM generation processes
- Performance on multilingual or highly specialized domains is not evaluated
- Requires labeled data with known difficulty levels for training
- Method's effectiveness across different task types and question formats needs broader validation

## Confidence
- High confidence: Achieves state-of-the-art results on tested benchmarks (ScienceQA, MMMLU, MMLU) with ROC-AUC > 93% and Macro-F1 > 79%
- Medium confidence: Effectiveness in guiding adaptive reasoning strategies due to limited ablation studies and potential confounding factors
- Medium confidence: Theoretical framing using Markov chains and value functions, as practical implementation may deviate from idealized assumptions

## Next Checks
1. Test the method across different LLM architectures (e.g., Llama, Claude, Gemini) to verify whether hidden state representations at [EOS] are consistently meaningful for difficulty estimation
2. Evaluate performance on low-resource languages and specialized domains (medical, legal, technical) to assess generalizability beyond current English benchmarks
3. Conduct ablation studies on Markov chain assumptions by comparing against alternative sequence modeling approaches to validate necessity of current framework