---
ver: rpa2
title: Attention, Please! PixelSHAP Reveals What Vision-Language Models Actually Focus
  On
arxiv_id: '2503.06670'
source_url: https://arxiv.org/abs/2503.06670
tags:
- object
- pixelshap
- objects
- masking
- visual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PixelSHAP introduces a model-agnostic interpretability framework
  for Vision-Language Models (VLMs) that extends Shapley-based analysis to structured
  visual entities. Unlike existing methods focused on text prompts or pixel-level
  perturbations, PixelSHAP systematically analyzes image objects to quantify their
  influence on a VLM's response.
---

# Attention, Please! PixelSHAP Reveals What Vision-Language Models Actually Focus On

## Quick Facts
- arXiv ID: 2503.06670
- Source URL: https://arxiv.org/abs/2503.06670
- Authors: Roni Goldshmidt
- Reference count: 24
- One-line result: PixelSHAP achieves 67.48% Recall@1 for Gemini-2.0-flash and 60.56% for GPT-4o in object attribution tasks

## Executive Summary
PixelSHAP introduces a model-agnostic interpretability framework for Vision-Language Models (VLMs) that extends Shapley-based analysis to structured visual entities. Unlike existing methods focused on text prompts or pixel-level perturbations, PixelSHAP systematically analyzes image objects to quantify their influence on a VLM's response. The method operates solely on input-output pairs without requiring model internals, making it compatible with both open-source and commercial models. Experiments across multiple VLMs demonstrate that PixelSHAP significantly outperforms baseline methods, with the proposed Bounding Box with Overlap Avoidance (BBOA) masking strategy achieving the highest attribution accuracy.

## Method Summary
PixelSHAP treats segmented objects as discrete entities and computes Shapley values by comparing the similarity of VLM responses between original and masked images using cosine similarity of text embeddings. The framework uses a segmentation pipeline (GroundingDINO for detection + SAM for mask generation) to identify objects, then applies three masking strategies: Precise Masking, Bounding Box Masking, and BBOA. Shapley values are computed via first-order perturbations (masking each object independently) with optional Monte Carlo sampling for higher-order combinations. The method is designed to work with text-generative VLMs as a black box, requiring only input-output pairs and supporting diverse embedding-based similarity metrics.

## Key Results
- PixelSHAP significantly outperforms baseline methods in object attribution tasks
- BBOA masking strategy achieves 67.48% Recall@1 for Gemini-2.0-flash and 60.56% for GPT-4o
- First-order perturbations achieve 92% correlation with exact Shapley values while remaining computationally tractable
- Computational efficiency is dramatically improved compared to pixel-level approaches (15-74s/image reported)

## Why This Works (Mechanism)

### Mechanism 1: Object-Level Shapley Value Attribution
- Claim: Object importance can be quantified by measuring changes in VLM response similarity when objects are systematically perturbed.
- Mechanism: The framework treats segmented objects as discrete entities and computes Shapley values by comparing the similarity of VLM responses between original and masked images using cosine similarity of text embeddings.
- Core assumption: The contribution of an object to a model's response can be isolated by perturbing it and measuring the resultant change in output similarity.
- Break condition: When objects have complex spatial overlap or semantic interdependence, perturbation of one may confound importance estimation of others.

### Mechanism 2: Bounding Box with Overlap Avoidance (BBOA) Masking
- Claim: BBOA masking provides superior object attribution by completely occluding targets while preserving adjacent object contours.
- Mechanism: Uses bounding boxes to mask targets but selectively reveals contours of neighboring objects, avoiding silhouette recognition issues of precise masking and collateral occlusion of standard bounding box masking.
- Core assumption: Accurate importance attribution requires isolating individual object contributions through strategic occlusion that eliminates visual recognition while minimizing interference with neighbors.
- Break condition: When objects are heavily overlapped or one contains another, BBOA may struggle to cleanly isolate contributions.

### Mechanism 3: First-Order Perturbation Approximation
- Claim: First-order perturbations (masking objects independently) achieve high correlation with exact Shapley values while remaining computationally tractable.
- Mechanism: Instead of evaluating all possible object subsets, the method begins with single-object perturbations and optionally refines through Monte Carlo sampling.
- Core assumption: First-order contributions capture the majority of object importance without needing to evaluate interaction effects between object pairs or triplets.
- Break condition: When object interactions are critical to VLM reasoning (e.g., spatial relationships matter), first-order approximation may miss important joint contributions.

## Foundational Learning

- Concept: **Shapley Values in Cooperative Game Theory**
  - Why needed here: Understanding how the Shapley formulation fairly distributes "credit" among players (objects) based on marginal contributions across all possible coalitions.
  - Quick check question: Given three objects A, B, C, can you explain why the Shapley value for A averages its marginal contribution across all subset orderings?

- Concept: **Vision-Language Model Inference as Black-Box**
  - Why needed here: PixelSHAP operates on input-output pairs only; understanding why VLMs require this approach (no accessible internals, open-ended text outputs) is essential.
  - Quick check question: What makes attributing importance in text-generative VLMs fundamentally harder than in classification models with probability outputs?

- Concept: **Semantic Segmentation Pipelines**
  - Why needed here: Segmentation quality directly determines what entities PixelSHAP can attribute importance to and how cleanly objects can be isolated.
  - Quick check question: How would segmentation failure (merged objects, missed detections) propagate into incorrect Shapley estimates?

## Architecture Onboarding

- Component map: Input Image → GroundingDINO (detection) → SAM (masks) → BBOA Masking → Modified Images → VLM API Calls → Response y' → Embedding Model → Cosine Similarity v(S') → Shapley Computation → φ_i per object

- Critical path:
  1. Segmentation quality determines object granularity
  2. Masking strategy determines perturbation effectiveness
  3. VLM inference speed drives throughput (15–74s/image reported)
  4. Embedding similarity metric determines attribution sensitivity

- Design tradeoffs:
  - Precise masking vs. BBOA: Precise preserves context but leaves silhouettes; BBOA isolates better but requires more complex mask generation
  - First-order vs. full Shapley: First-order is faster but may miss interaction effects; Monte Carlo improves precision at computational cost
  - Segmentation model: Domain-specific models improve accuracy but reduce generality

- Failure signatures:
  - Low Recall@1 with high Similarity Drop: Aggressive masking may be removing too much context
  - High variance across similar queries: Inconsistent segmentation or unstable VLM responses
  - Computation >2 minutes: Too many objects detected; filter by size or confidence threshold

- First 3 experiments:
  1. **Baseline validation**: Run PixelSHAP on 10 COCO images with all three masking strategies, comparing Recall@1 and IoU@1 against "Central Object" and "Largest Object" heuristics.
  2. **Segmentation sensitivity test**: Substitute GroundingDINO+SAM with Mask R-CNN on the same images and measure attribution consistency (IoU overlap of importance rankings).
  3. **Scaling stress test**: Process 5 images with 10+ detected objects to verify computational scaling and check whether first-order approximation degrades in dense scenes.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can PixelSHAP be adapted for video understanding to track how object importance evolves over time?
- Basis in paper: [explicit] Section 8.5 lists "Temporal Analysis" as a future research direction for understanding dynamic scene interpretation.
- Why unresolved: The current framework is designed for static images and does not address the computational or theoretical challenges of temporal dependencies and frame-to-frame consistency in video data.
- What evidence would resolve it: An extension of the framework applied to video benchmarks, demonstrating consistent object attribution across frames in a dynamic scene.

### Open Question 2
- Question: Can the framework be extended to attribute importance to specific visual attributes (e.g., color, texture) rather than just whole objects?
- Basis in paper: [explicit] Section 8.5 proposes "Attribute-Level Attribution" to understand how specific visual features influence model responses.
- Why unresolved: The current methodology relies on segmentation masks that define "objects" as atomic entities, lacking the granularity to isolate internal features like texture or color.
- What evidence would resolve it: A study showing PixelSHAP isolating a specific attribute (e.g., "red" vs. "blue") as the primary driver of a model's decision in a controlled setting.

### Open Question 3
- Question: How can the relative contribution of visual objects be jointly analyzed with textual prompt elements in a unified framework?
- Basis in paper: [explicit] Section 8.5 suggests "Cross-Modal Attribution" to analyze the relative importance of visual and textual elements jointly.
- Why unresolved: The current implementation perturbs image regions while holding the text prompt fixed, treating the text input as a constant rather than a variable in the Shapley calculation.
- What evidence would resolve it: A unified score or visualization that compares the Shapley value of a specific image object directly against the value of specific prompt tokens.

### Open Question 4
- Question: To what extent does the accuracy of the underlying segmentation model correlate with the fidelity of PixelSHAP's attributions?
- Basis in paper: [inferred] The Abstract lists segmentation sensitivity as a key challenge, and Section 8.2 notes that detection quality directly impacts attribution accuracy.
- Why unresolved: The paper assumes a standard segmentation pipeline but does not quantify error propagation when the segmentation model misses objects or produces imprecise masks.
- What evidence would resolve it: A sensitivity analysis measuring the degradation of PixelSHAP's Recall@1 and IoU scores when using segmentation models with deliberately reduced performance.

## Limitations
- Reliance on segmentation quality for object attribution - poor segmentation can merge objects or miss small elements
- Lack of implementation details for BBOA masking strategy makes exact reproduction difficult
- First-order approximation may miss important interaction effects between objects in complex scenes

## Confidence

- **High confidence**: The Shapley value formulation and its application to object attribution follows established methodology; the computational efficiency gains of object-level over pixel-level perturbation are well-demonstrated.
- **Medium confidence**: The superiority of BBOA masking is supported by the reported metrics, but the lack of implementation details makes independent verification challenging.
- **Low confidence**: Claims about first-order approximation capturing sufficient attribution without extensive Monte Carlo sampling, particularly in complex multi-object scenes.

## Next Checks

1. **Segmentation sensitivity validation**: Run the complete pipeline on identical images using two different segmentation approaches (GroundingDINO+SAM vs. Mask R-CNN) and measure the correlation of resulting Shapley rankings to quantify segmentation impact.

2. **Interaction effect quantification**: Select 10 complex images with >5 objects and compare first-order Shapley values against full enumeration (when computationally feasible) to measure the magnitude of missed interaction effects.

3. **Masking strategy ablation**: Implement and test a fourth masking strategy (e.g., "adaptive precision" that varies mask tightness based on object importance) on the same evaluation set to determine if BBOA's gains are specific to its approach or generalizable to better occlusion strategies.