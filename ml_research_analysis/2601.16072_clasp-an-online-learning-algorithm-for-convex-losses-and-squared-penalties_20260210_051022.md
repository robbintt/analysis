---
ver: rpa2
title: 'CLASP: An online learning algorithm for Convex Losses And Squared Penalties'
arxiv_id: '2601.16072'
source_url: https://arxiv.org/abs/2601.16072
tags:
- convex
- clasp
- constraints
- ccvt
- online
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CLASP, an algorithm for online convex optimization
  with time-varying constraints. It addresses the challenge of minimizing cumulative
  loss while controlling constraint violations, measured by squared penalties.
---

# CLASP: An online learning algorithm for Convex Losses And Squared Penalties

## Quick Facts
- arXiv ID: 2601.16072
- Source URL: https://arxiv.org/abs/2601.16072
- Reference count: 31
- Primary result: First algorithm achieving O(log T) bounds on both regret and cumulative squared constraint violations for strongly convex losses in online convex optimization with time-varying constraints

## Executive Summary
This paper introduces CLASP, an algorithm for online convex optimization with time-varying constraints where feasibility must be maintained after each decision. CLASP takes a gradient step with respect to the latest loss and projects onto the current feasible set, using the firm non-expansiveness property of convex projectors to enable modular analysis. The key innovation is achieving logarithmic bounds on both regret and cumulative squared constraint violations simultaneously for strongly convex losses, improving upon prior work that only achieved such rates under restrictive conditions or with weaker violation metrics.

## Method Summary
CLASP operates by computing an intermediate point through gradient descent on the latest loss, then projecting onto the current feasible set K ∩ C_t where C_t represents the constraint active at time t. The algorithm uses step-size tuning to control the tradeoff between regret and constraint violation rates. For convex losses, choosing η_t = 1/t^β yields regret O(T^max{β,1-β}) and cumulative squared penalty O(T^(1-β)) for any β in (0,1). For strongly convex losses, η_t = 1/(mt) achieves O(log T) bounds on both metrics simultaneously. The analysis leverages firm non-expansiveness of projection operators rather than standard non-expansiveness, enabling separate analysis of regret and violation components.

## Key Results
- Achieves regret O(T^max{β,1-β}) and cumulative squared penalty O(T^(1-β)) for convex losses with step-size tuning parameter β ∈ (0,1)
- First algorithm providing O(log T) bounds on both regret and cumulative squared penalty for strongly convex losses simultaneously
- Memory-efficient requiring only one projection per iteration versus two for prior algorithms
- Analysis extends naturally to multiple or persistent constraints without modification

## Why This Works (Mechanism)

### Mechanism 1: Projected Gradient Descent onto Current Feasible Set
A single gradient step followed by projection onto the most recent constraint set is sufficient to bound both regret and constraint violations. At iteration t, compute b̃x_{t+1} = x_t - η_t ∇f_t(x_t), then project onto K_t = K ∩ C_t where C_t = {x : g_t(x) ≤ 0}. This ensures the action respects the current constraint while moving in a loss-reducing direction. The feasible set K ∩ ∩_{t=1}^T C_t must be non-empty for a valid comparator to exist.

### Mechanism 2: Firm Non-Expansiveness Enables Modular Decomposition
The firm non-expansiveness property of convex projectors—rather than standard non-expansiveness—allows separate, modular analysis of regret and constraint violation. FNE states ||P_S(u) - P_S(v)||^2 ≤ ||u-v||^2 - ||(u-P_S(u)) - (v-P_S(v))||^2. The subtraction term yields d_S(u)^2, directly linking projection distance to constraint violation and decoupling regret analysis from violation analysis.

### Mechanism 3: Step-Size Tuning Controls Regret-Violation Tradeoff
The choice of step-size sequence directly determines the tradeoff between regret rate and cumulative squared penalty rate. For convex losses, η_t = 1/t^β yields regret O(T^{max{β,1-β}}) and CCV O(T^{1-β}). The parameter β ∈ (0,1) lets practitioners favor either regret or violation. For strongly convex losses, η_t = 1/(mt) achieves O(log T) on both simultaneously.

## Foundational Learning

- **Online Convex Optimization (OCO)**: COCO generalizes OCO by adding revealed-after-action constraints. Understanding static regret and the role of convexity is prerequisite. Quick check: Can you explain why sublinear regret implies the learner performs asymptotically as well as the best fixed action in hindsight?

- **Projection Operators and Distance Functions**: CLASP's update is defined via projection P_{K_t}. Understanding d_S(u) = ||u - P_S(u)|| is essential for the violation analysis. Quick check: Given a point u outside a closed convex set S, how would you characterize its projection and distance to S?

- **Strong Convexity and Its Benefits**: The logarithmic bounds on both regret and violation depend critically on m-strong convexity of the loss functions. Quick check: If f is m-strongly convex, what additional term appears in the lower bound f(v) ≥ f(u) + ⟨∇f(u), v-u⟩ + ?

## Architecture Onboarding

- **Component map**:
  Input: x_t ∈ K, observed (f_t, g_t)
  Gradient computation: ∇f_t(x_t)
  Gradient step: b̃x_{t+1} = x_t - η_t ∇f_t(x_t)
  Projection: x_{t+1} = P_{K∩C_t}(b̃x_{t+1})
  Accumulate: f_t(x_t) → cumulative loss; (g_t^+(x_t))^2 → CCV_T,2

- **Critical path**: The projection onto K ∩ C_t is the computational bottleneck. This requires solving a convex subproblem (e.g., quadratic program if g_t is linear).

- **Design tradeoffs**: Single projection per iteration vs. Switch algorithm's two projections (including historical intersection). CLASP trades tighter violation bounds for memory efficiency. β tuning: lower β favors lower regret; higher β favors lower violation. No single β optimizes both simultaneously for general convex losses. Squared penalty metric (CCV_T,2) heavily penalizes large violations; if only counting violations matters, linear metrics (CCV_T,1) may be more appropriate.

- **Failure signatures**: Empty K ∩ C_t at any round causes projection to fail. Monitor feasibility. If K ∩ ∩_{t=1}^T C_t is empty (infeasible overall), comparator x_T^★ is undefined; bounds become vacuous. Gradient norm growth beyond assumed Lipschitz bound L violates the analysis; watch ||∇f_t|| and ||∇g_t||.

- **First 3 experiments**:
  1. **Synthetic online linear regression** (as in Section 7.1): Generate random H_t ∈ ℝ^{4×10}, y_t ∈ ℝ^4, with adversarial constraints A_t x ≤ b_t. Track cumulative loss, CCV_T,1, and CCV_T,2. Compare against AdaGrad, RECOO, and Switch baselines.
  2. **Step-size sensitivity analysis**: Vary β ∈ {0.25, 0.5, 0.75} for convex losses; verify the regret-violation tradeoff matches theoretical predictions (plot both metrics vs. T on log-log scale).
  3. **Strongly convex loss stress test**: Construct m-strongly convex losses (e.g., ft(x) = ||x||^2 + ⟨a_t, x⟩) and verify both regret and CCV_T,2 grow as O(log T). Compare against convex-loss baselines to demonstrate the rate improvement.

## Open Questions the Paper Calls Out

- **Open Question 1**: What specific real-world applications are best modeled by the persistent constraints framework, where decisions must satisfy all historical constraints? The authors note they are not aware of specific applications that are best modeled by persistent constraints.

- **Open Question 2**: Are the logarithmic bounds (O(log T)) on regret and squared penalty for strongly convex losses tight, or can they be improved? The paper provides upper bounds but does not provide corresponding lower bounds to prove optimality.

- **Open Question 3**: Can the CLASP guarantees be extended to dynamic regret settings where the comparator is a time-varying sequence rather than a fixed point? The analysis strictly defines regret relative to the best fixed action x^*_T, leaving the dynamic regret regime unaddressed.

## Limitations
- Analysis relies critically on firm non-expansiveness property of convex projectors, which may not generalize to non-convex settings
- Assumes known Lipschitz constants and strong convexity parameters, limiting applicability in fully agnostic environments
- Memory efficiency comes at the cost of potentially looser violation bounds compared to algorithms tracking historical feasible sets

## Confidence
- **High Confidence**: Regret bounds for convex losses (O(T^max{β,1-β})) and strongly convex losses (O(log T)), as these follow directly from standard OCO analysis with firm non-expansiveness
- **Medium Confidence**: Cumulative squared penalty bounds, as they depend on the specific structure of the distance function analysis
- **Medium Confidence**: The improvement over prior work, particularly the removal of "non-negative regrets" restriction, as this requires careful verification against the cited baselines

## Next Checks
1. **Baselines Validation**: Implement and run CLASP against AdaGrad, RECOO, and Switch on the same synthetic and real-world datasets to confirm the claimed improvement in violation bounds.

2. **Non-Strongly Convex Case**: Test CLASP on problems where the loss functions are convex but not strongly convex to verify the O(T^max{β,1-β}) regret and O(T^(1-β)) cumulative squared penalty hold empirically.

3. **Projection Feasibility**: Monitor the feasibility of K ∩ C_t at each iteration across multiple runs to ensure the projection never fails due to empty feasible sets.