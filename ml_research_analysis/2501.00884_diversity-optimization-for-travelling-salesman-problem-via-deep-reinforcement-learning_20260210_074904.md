---
ver: rpa2
title: Diversity Optimization for Travelling Salesman Problem via Deep Reinforcement
  Learning
arxiv_id: '2501.00884'
source_url: https://arxiv.org/abs/2501.00884
tags:
- diversity
- solution
- msqi
- solutions
- instances
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces RF-MA3S, the first deep reinforcement learning
  method for diversity optimization in the Travelling Salesman Problem (TSP). The
  method combines a Relativization Filter (RF) to enhance encoder robustness against
  affine transformations, a multi-decoder architecture with Multi-Attentive Adaptive
  Active Search (MA3S) to balance optimality and diversity, and adaptive switching
  between shared and respective baselines during inference.
---

# Diversity Optimization for Travelling Salesman Problem via Deep Reinforcement Learning

## Quick Facts
- arXiv ID: 2501.00884
- Source URL: https://arxiv.org/abs/2501.00884
- Reference count: 40
- Primary result: First deep RL method for diversity optimization in TSP achieving up to 15× faster inference than heuristics while delivering superior MSQI and DI scores

## Executive Summary
This paper introduces RF-MA3S, the first deep reinforcement learning method for diversity optimization in the Travelling Salesman Problem (TSP). The method combines a Relativization Filter (RF) to enhance encoder robustness against affine transformations, a multi-decoder architecture with Multi-Attentive Adaptive Active Search (MA3S) to balance optimality and diversity, and adaptive switching between shared and respective baselines during inference. RF-MA3S significantly outperforms recent neural baselines on both TSP and CVRP benchmarks, achieving up to 15× faster inference than traditional heuristics while delivering superior MSQI and DI scores. The method demonstrates strong generalization across varying problem scales and effectively handles affine transformations, with ablation studies confirming the contribution of each key component.

## Method Summary
RF-MA3S employs a multi-decoder architecture with five parallel decoders sharing a common encoder. The Relativization Filter (RF) preprocesses input coordinates to achieve affine invariance by converting them to a canonical relative representation through sorting, zero-centering, polar coordinate conversion, normalization, and angle shifting. During inference, the Multi-Attentive Adaptive Active Search (MA3S) mechanism dynamically switches between shared and respective baselines based on the gradient of the objective function. Initially, a shared baseline encourages all decoders to converge toward the global optimum, then switches to respective baselines once the gradient falls below a threshold to promote diversity among the solutions.

## Key Results
- RF-MA3S achieves MSQI scores 2.14-3.18× higher than baseline POMO on standard TSP20 benchmarks
- The method demonstrates zero performance gap under affine transformations (rotation, scaling, translation) compared to high gaps in non-RF baselines
- On CVRP benchmarks, RF-MA3S shows MSQI improvements of 11.1-14.2% over previous methods while maintaining competitive optimality
- Inference is up to 15× faster than traditional heuristic methods while producing superior diverse solution sets

## Why This Works (Mechanism)

### Mechanism 1: Relativization Filter (RF) for Affine Invariance
The Relativization Filter improves encoder robustness by converting absolute coordinates into a canonical relative representation through sorting, zero-centering, polar coordinate conversion, normalization, and angle shifting. This allows the model to recognize identical problem structures regardless of rotation, translation, or scaling. The mechanism assumes affine transformations don't change optimal solution structure, and providing consistent input representation reduces learning burden on the encoder. Evidence shows zero performance gaps for transformations compared to high gaps in non-RF baselines, though mirroring transformations still require instance augmentation.

### Mechanism 2: Adaptive Baseline Switching (MA3S)
The Adaptive Active Search mechanism balances optimality and diversity by dynamically switching the baseline used in reinforcement learning updates during inference. Initially using a shared baseline to force decoders toward the global optimum, it switches to respective baselines once the gradient falls below a threshold, encouraging decoders to diverge into distinct local optima. This addresses the limitation that a single baseline strategy cannot simultaneously maximize both quality and diversity. Evidence shows shared baselines excel at optimality while respective baselines excel at diversity, with adaptive switching achieving the highest MSQI, though threshold sensitivity remains a concern.

### Mechanism 3: Multi-Decoder Diversity
The architecture employs five parallel decoders with randomly initialized parameters that update independently during inference, allowing them to specialize in different regions of the solution space. This increases the probability of finding diverse solutions compared to single-decoder approaches. The mechanism assumes the shared encoder provides sufficiently rich embeddings for distinct decoders to extract different valid high-quality solutions. Ablation studies confirm substantial increases in solution count, though diversity may collapse if decoders converge to identical parameters or if the encoder bottleneck is too severe.

## Foundational Learning

- **Concept: Affine Transformation Invariance**
  - Why needed here: The RF module manipulates coordinate systems based on the principle that rotating or scaling a TSP map doesn't change the shortest path length
  - Quick check question: If you rotate a TSP instance by 45 degrees, should the output tour sequence (indices) change? (Answer: No)

- **Concept: Baselines in REINFORCE (Policy Gradients)**
  - Why needed here: The MA3S strategy relies on switching baselines to reduce variance in gradient estimation
  - Quick check question: Does a "shared baseline" encourage competition or cooperation among decoders? (Answer: Competition to beat the single best score)

- **Concept: Multi-Solution Quality Index (MSQI)**
  - Why needed here: Standard TSP metrics measure single-solution optimality, while MSQI combines diversity and optimality using harmonic mean
  - Quick check question: Why use harmonic mean instead of arithmetic mean to combine diversity and optimality? (Answer: To penalize cases where one metric is extremely low, ensuring balance)

## Architecture Onboarding

- **Component map:** Raw coordinates (x, y) -> Relativization Filter (Reorder → Zero-mean → Polar → Relativize → Cartesian) -> Encoder (3-layer MHA) -> 5 parallel MHA decoders -> Active Search Module

- **Critical path:** The Adaptive Active Search (Algorithm 1) is the critical path for performance: Sample Solutions → Check Gradient f → If f < α, Switch to Respective Baselines → Update Parameters → Repeat

- **Design tradeoffs:** 
  - Threshold α: Lower α delays diversity mode, potentially improving optimality but risking premature convergence; higher α speeds inference but may reduce quality
  - Iteration Cap: AAS is computationally expensive; the paper sets max iteration (e.g., 2000) to bound inference time

- **Failure signatures:**
  - "Scaling Attack": Without RF, model fails on scaled instances (29% gap for POMO without RF)
  - "Diversity Collapse": If switch logic never triggers, model may output 5 nearly identical solutions

- **First 3 experiments:**
  1. **Sanity Check (RF):** Train baseline POMO and RF-MA3S on TSP20, test on dataset scaled by 100x; verify baseline fails (high gap) while RF-MA3S maintains performance (Gap ≈ 0)
  2. **Ablation (Baselines):** Run RF-MA3S on small MSTSP instance three ways: Shared Baseline only, Respective only, Adaptive; plot MSQI vs. Time to reproduce Figure 4
  3. **Hyperparameter Sensitivity:** Vary α on single instance (α ∈ {0.0025, 0.005, 0.01}) and observe trade-off between Solutions Count and Average Quality

## Open Questions the Paper Calls Out

### Open Question 1
How can the Relativization Filter (RF) be modified to inherently achieve invariance to mirroring transformations without relying on explicit instance augmentation? The current RF relies on ×2 augmentation (swapping x and y) to address mirroring, doubling computation for that check.

### Open Question 2
To what extent can integrating mechanisms like Simulation Guided Beam Search (SGBS) or Random Re-Construct (RRC) further boost the optimality-diversity trade-off in RF-MA3S? The current architecture relies on MA3S, and it's unknown if external heuristics are compatible with the relativization and multi-decoder setup.

### Open Question 3
How can the inference time of RF-MA3S be reduced for large-scale or complex instances (like CVRP) without compromising the Multi-Solution Quality Index (MSQI)? The Adaptive Active Search improves quality but is computationally expensive, with RF-MA3S taking 8.1 hours on CVRPLIB versus 3 seconds for POMO.

## Limitations
- RF's effectiveness relies on synthetic transformation datasets; real-world noise or non-uniform scaling may degrade performance
- Adaptive baseline switching threshold (α) is heuristic and dataset-dependent, potentially not generalizing optimally
- Multi-decoder diversity assumes sufficient encoder embedding capacity; encoder bottleneck may cause diversity collapse

## Confidence
- **High Confidence:** RF's contribution to affine invariance (validated by controlled transformation experiments in Table 3)
- **Medium Confidence:** Adaptive baseline switching mechanism (validated by MSQI improvement in Figure 4, but threshold sensitivity noted in Table 9)
- **Medium Confidence:** Multi-decoder architecture benefits (supported by ablation studies and neighbor literature, but dependent on encoder capacity)

## Next Checks
1. **Real-World Noise Test:** Evaluate RF-MA3S on TSP instances with measurement noise or non-uniform scaling to verify RF robustness beyond synthetic transformations
2. **Encoder Capacity Analysis:** Systematically vary encoder layer dimensions and measure decoder diversity collapse rate to quantify bottleneck effect
3. **Dynamic Threshold Calibration:** Implement online α adjustment mechanism during inference and compare MSQI gains against fixed threshold approach