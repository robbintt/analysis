---
ver: rpa2
title: Identification and Estimation of Long-Term Treatment Effects with Monotone
  Missing
arxiv_id: '2504.19527'
source_url: https://arxiv.org/abs/2504.19527
tags:
- missing
- long-term
- outcomes
- data
- treatment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of estimating long-term treatment
  effects in settings with monotone missing data, where individuals missing at earlier
  stages remain missing at subsequent stages. The authors introduce a sequential missing
  mechanism assumption that is weaker than the commonly used missing at random assumption
  and compatible with monotone missing patterns.
---

# Identification and Estimation of Long-Term Treatment Effects with Monotone Missing

## Quick Facts
- arXiv ID: 2504.19527
- Source URL: https://arxiv.org/abs/2504.19527
- Reference count: 40
- Primary result: Novel methods (BalanceNet, SeqMSM) for estimating long-term treatment effects under monotone missing data outperform baselines with significant accuracy improvements (p ≤ 0.05).

## Executive Summary
This paper tackles the challenge of estimating long-term causal effects when data is missing in a monotone pattern (early dropouts remain missing for all future stages). Standard methods assuming Missing At Random (MAR) fail here because missingness depends on unobserved prior outcomes. The authors introduce a sequential missing mechanism assumption that weakens MAR and enables identification. They propose three estimators: inverse probability weighting (IPW), sequential regression imputation (SeqRI), and sequential marginal structural model (SeqMSM). To address data sparsity issues in SeqMSM, they develop BalanceNet, a neural network that learns a representation balancing treatment assignment and missingness distributions via an IPM (MMD) penalty. Experiments on IHDP and JOBS datasets show BalanceNet achieves the lowest estimation error, especially under high missingness.

## Method Summary
The core method is BalanceNet, a neural network that learns a representation Φ(X,A) to predict outcomes Y while simultaneously balancing the distributions of observed vs. missing units (via λ₁·IPM₁) and treated vs. control units (via λ₂·IPM₂). This balancing is achieved using MMD distance in the latent space. SeqMSM is a hybrid estimator combining weighted regression (using inverse selection scores) with outcome modeling to stabilize estimates. Sequential selection scores are estimated under a weaker sequential missing mechanism assumption, decomposing the intractable full missingness probability into a product of identifiable conditional probabilities. The models are trained on synthetic data generated from IHDP and JOBS with monotone missingness injected according to specified score functions.

## Key Results
- BalanceNet achieves the lowest estimation error (εCATE and εATE) across all tested missingness levels (γ ∈ [0.05, 0.5]), with statistically significant improvements (p ≤ 0.05) over baselines.
- SeqMSM outperforms pure IPW and SeqRI methods, validating the hybrid weighting+regression approach for stabilizing estimates under data sparsity.
- Performance gap between BalanceNet and baselines widens as missingness ratio γ increases, demonstrating BalanceNet's robustness to high missingness.
- The sequential missing mechanism assumption enables identification of long-term effects even under MNAR data, as shown in Proposition 6 and Theorem 5.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Under the Sequential Missing Mechanism (Assumption 4), causal effects become identifiable even under MNAR monotone missing data.
- **Mechanism:** Standard MAR fails because future missingness depends on unobserved earlier outcomes. This paper introduces sequential conditional independence: missingness at time t depends only on observed history plus the immediate preceding outcome. Chaining these dependencies creates a product of observable probabilities that mimics the full missingness mechanism, enabling valid re-weighting or imputation.
- **Core assumption:** Assumption 4 (Sequential Missing Mechanism): R_t ⊥ S_t(a) | X, S_{1:t-1}(a), A=a.
- **Evidence anchors:** [Section 4.1] Assumption 4 is weaker than MAR and compatible with monotone missing patterns. [Section 4.2] Shows decomposition of unidentifiable r_3 into identifiable conditional probabilities.
- **Break condition:** If missingness at time t depends on unobserved variables other than preceding outcomes (e.g., latent fatigue), the identifiability chain breaks.

### Mechanism 2
- **Claim:** SeqMSM reduces "model extrapolation" error (pure regression) and "data sparsity" error (pure IPW).
- **Mechanism:** Pure regression fails due to distribution shift; pure IPW fails due to exploding weights under sparsity. SeqMSM combines them by using weights to create an unbiased pseudo-population, then fitting a regression model. The regression stabilizes the weights, and the weights correct regression's selection bias.
- **Core assumption:** Positivity (Assumption 4b): P(R_t=1 | ...) > 0.
- **Evidence anchors:** [Section 4.4.2] SeqMSM mitigates model extrapolation by weighting non-missing data to create an unbiased pseudo-population. [Table 1] SeqMSM consistently outperforms Proposed-IPW and SeqRI.
- **Break condition:** If data is extremely sparse (high γ), estimated selection scores approach zero, causing IPW weights to explode and destabilize SeqMSM.

### Mechanism 3
- **Claim:** BalanceNet stabilizes SeqMSM by replacing explicit probability estimation with implicit representation learning.
- **Mechanism:** Instead of calculating 1/P(R=1) directly (numerically unstable), BalanceNet uses a neural network to learn representation Φ(X,A) that penalizes distributional differences between Observed vs. Missing and Treated vs. Control. This forces the network to learn a feature space where data appears as if from a randomized trial with no missingness.
- **Core assumption:** A neural network can learn representation Φ where IPM distance is minimized without losing predictive power for Y.
- **Evidence anchors:** [Section 5] BalanceNet learns representation balancing treatment assignment and missing data. [Table 1 & Table A3] BalanceNet achieves lowest error and significantly lower standard deviation compared to SeqMSM, especially at high missingness (γ=0.5).
- **Break condition:** If imbalance penalties (λ₁, λ₂) are too high, the network may prioritize balancing over predicting accurately ("washing out" the signal).

## Foundational Learning

- **Concept: Potential Outcomes (Y(0), Y(1)) vs. Observables**
  - **Why needed here:** The paper's goal (ATE/CATE) is defined using potential outcomes (Y(1)-Y(0)), but we only observe one. The entire paper is a strategy to estimate the unobserved counterfactual given the mess of missing data.
  - **Quick check question:** If a user drops out (missing data), can we ever know their potential outcome? (Hint: The paper assumes we can estimate it via imputation or weighting).

- **Concept: Monotone Missing vs. MAR (Missing At Random)**
  - **Why needed here:** Standard software assumes MAR (missingness depends only on observed X). This paper argues that in long-term studies, missingness depends on prior outcomes S (which might be missing). If you apply MAR methods here, you get bias.
  - **Quick check question:** In a medical trial, if patients quit because their intermediate blood test was bad (and unobserved), is this MAR or MNAR?

- **Concept: Propensity Score (P(A|X)) vs. Selection Score (P(R|X,S))**
  - **Why needed here:** To correct bias, you need to re-weight data. Treatment bias is corrected by Propensity Scores; Attrition (missingness) bias is corrected by Selection Scores. This paper introduces Sequential Selection Scores.
  - **Quick check question:** Why do we multiply these scores together in the IPW method? (Answer: To correct for both treatment assignment bias and survival/observation bias simultaneously).

## Architecture Onboarding

- **Component map:** X, A -> Encoder Φ -> h₀, h₁ (outcome predictors) -> Y prediction
- **Critical path:**
  1. **Data Pre-processing:** Handle the "Monotone" structure. Ensure that if R_t=0, then R_{t+1}=0.
  2. **Training Loop:** Feed (X, A) into Encoder.
  3. **Balancing:** Calculate MMD distance (IPM) between latent representations of Observed vs. Missing units (λ₁) and Treated vs. Control (λ₂).
  4. **Optimization:** Update weights to minimize prediction error and balancing penalties simultaneously.

- **Design tradeoffs:**
  - **SeqMSM vs. BalanceNet:** SeqMSM is interpretable (you can inspect the propensity scores); BalanceNet is a black box but more robust to high missing ratios (γ > 0.3).
  - **Hyperparameter λ:** Controls the "strength" of the balancing. High λ reduces bias but might increase variance (ignoring outcome signal).

- **Failure signatures:**
  - **Exploding Weights (SeqMSM/IPW):** If ε_{ATE} is huge or NaN, check the distribution of estimated r̂. If values are close to 0, weights explode. Switch to BalanceNet.
  - **Representation Collapse (BalanceNet):** If prediction loss drops but IPM loss stays high (or vice versa), the network is failing to find a balanced representation. Adjust λ.

- **First 3 experiments:**
  1. **Baseline Sanity Check:** Implement "Naive-OR" (regression on observed data only) and "Proposed-IPW" on JOBS dataset with low missingness (γ=0.1). Verify error metrics roughly match Table 1 (IPW should be unstable, Naive-OR biased).
  2. **Ablation on Missingness:** Run SeqMSM vs. BalanceNet across γ ∈ [0.05, 0.5]. Plot ε_{CATE}. The gap should widen as γ increases (BalanceNet should win at high missingness).
  3. **Hyperparameter Sensitivity:** Vary imbalance penalty λ in BalanceNet (e.g., λ ∈ [0.1, 1.0, 5.0]). Verify the paper's claim that performance is "stable" across these values (Table A4), ensuring your implementation relies on the architecture rather than precise tuning.

## Open Questions the Paper Calls Out

- **Identifiability Scope:** The sequential missing mechanism is theoretically weaker than MAR but untested in settings with non-monotone missingness or unobserved confounders influencing missingness. The paper assumes observed X and immediate prior outcomes S_{t-1} fully explain missingness patterns.
- **Model Specification Dependence:** All methods assume correct functional forms for outcome model and/or balancing representation. Misspecification could bias estimates despite theoretical guarantees.
- **Real-World Applicability:** Experiments use synthetic data with known ground truth. Performance on truly observational datasets with unknown treatment effects remains unverified.

## Limitations

- The sequential missing mechanism assumption, while weaker than MAR, remains untestable in practice and may not hold under complex missingness patterns.
- The method's performance on real-world observational data with unknown treatment effects is unverified, as experiments use synthetic data with ground truth.
- BalanceNet's reliance on MMD balancing may suffer from the curse of dimensionality in high-dimensional covariate settings, though this is not tested.

## Confidence

- **High Confidence:** The theoretical framework for sequential missing mechanism identification is internally consistent and logically sound. The decomposition in Proposition 6 is mathematically valid given the stated assumptions.
- **Medium Confidence:** The empirical performance improvements of BalanceNet over baselines are demonstrated on synthetic data, but the magnitude of improvement and robustness to different data-generating processes requires further validation.
- **Low Confidence:** Claims about BalanceNet's stability across hyperparameter settings (Table A4) lack sufficient detail for independent verification. The specific initialization and architectural details for the Encoder are underspecified.

## Next Checks

1. **Sensitivity Analysis to Missingness Mechanism:** Re-run experiments with missingness patterns that violate the sequential assumption (e.g., depend on unobserved S_{t+1} or external factors). Measure how quickly BalanceNet's advantage degrades.

2. **Cross-Dataset Generalization:** Apply the methods to real-world datasets with documented monotone missing patterns (e.g., longitudinal clinical trials) where ground truth treatment effects are unknown. Validate results using domain expert knowledge or proxy outcomes.

3. **Architectural Ablation Study:** Systematically vary the BalanceNet Encoder architecture (depth, width, activation functions) and imbalance penalties (λ₁, λ₂) across a wider range. Quantify the trade-off between prediction accuracy and distributional balance to identify failure modes.