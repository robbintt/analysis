---
ver: rpa2
title: 'ConceptGuard: Proactive Safety in Text-and-Image-to-Video Generation through
  Multimodal Risk Detection'
arxiv_id: '2511.18780'
source_url: https://arxiv.org/abs/2511.18780
tags:
- unsafe
- text
- image
- safe
- prompt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents ConceptGuard, a unified framework for proactive
  safety in multimodal text-and-image-to-video generation. The framework addresses
  the challenge of detecting and mitigating harmful content that can emerge from the
  interaction of image and text inputs, where existing methods often focus on only
  one modality or act as post-generation auditors.
---

# ConceptGuard: Proactive Safety in Text-and-Image-to-Video Generation through Multimodal Risk Detection

## Quick Facts
- arXiv ID: 2511.18780
- Source URL: https://arxiv.org/abs/2511.18780
- Reference count: 40
- One-line primary result: ConceptGuard achieves state-of-the-art safety detection accuracy and effective harmfulness reduction in text-and-image-to-video generation.

## Executive Summary
ConceptGuard introduces a unified framework for proactive safety in multimodal text-and-image-to-video (TI2V) generation. It addresses the challenge of detecting and mitigating harmful content that emerges from the interaction of image and text inputs—an area where existing methods often focus on only one modality or act as post-generation auditors. The framework operates in two stages: contrastive detection to identify latent safety risks and semantic suppression to intervene during generation. The authors also introduce two new datasets—ConceptRisk and T2VSafetyBench-TI2V—to support training and evaluation of multimodal safety systems. Experimental results demonstrate high detection accuracy and effective harmfulness reduction, outperforming existing baselines.

## Method Summary
ConceptGuard is a two-stage framework designed for proactive safety in TI2V generation. The first stage employs a contrastive detection module that projects fused image-text inputs into a structured concept space, identifying latent safety risks. The second stage uses a semantic suppression mechanism that intervenes during video generation, steering the model away from unsafe concepts. The framework is supported by ConceptRisk, a large-scale dataset for training multimodal safety detectors, and T2VSafetyBench-TI2V, the first benchmark for assessing out-of-distribution generalization in TI2V safety. Comprehensive experiments validate the approach's effectiveness, with high detection accuracy and significant harmfulness reduction in practice.

## Key Results
- ConceptGuard achieves an overall detection accuracy of 0.976 on the ConceptRisk dataset.
- On the T2VSafetyBench-TI2V benchmark, the framework attains a detection accuracy of 0.960.
- In practical safety intervention tests, the full method reduces harmfulness rates from 90.0% to 10.0%, outperforming baselines that rely on fixed concept sets or lack multimodal perception.

## Why This Works (Mechanism)
The framework's effectiveness stems from its ability to jointly model and intervene on both image and text modalities during the generation process. By projecting fused inputs into a structured concept space, the contrastive detection module can identify latent risks that might not be apparent from either modality alone. The semantic suppression mechanism then intervenes in real time, dynamically steering the generation process away from unsafe content. This proactive, multimodal approach addresses a critical gap in existing safety systems, which often focus on single modalities or act as post-hoc filters.

## Foundational Learning
- **Contrastive Learning**: Needed to align multimodal embeddings in a shared concept space for risk detection; quick check: verify alignment accuracy on held-out concept pairs.
- **Semantic Suppression**: Required to intervene during generation and steer away from unsafe concepts; quick check: measure harmfulness reduction and benign content impact.
- **Multimodal Fusion**: Essential for capturing interactions between image and text that may signal risk; quick check: test performance with unimodal vs. multimodal inputs.
- **Out-of-Distribution Generalization**: Critical for real-world deployment, as risks may not be present in training data; quick check: evaluate on unseen risk categories.
- **Concept Dictionary Construction**: Necessary for defining and recognizing unsafe concepts; quick check: assess dictionary coverage and adaptability to new risks.

## Architecture Onboarding

**Component Map**: Image-Text Input -> Contrastive Detector -> Risk Score -> Semantic Suppressor -> Video Output

**Critical Path**: Image-Text Input → Contrastive Detector → Risk Score → Semantic Suppressor → Video Output

**Design Tradeoffs**: The framework trades computational overhead during generation for proactive risk mitigation. Using a predefined concept dictionary may limit adaptability to new risks without retraining.

**Failure Signatures**: 
- High false positive rates in risk detection may lead to over-censorship.
- Incomplete concept coverage may allow novel harmful content to slip through.
- Semantic suppression may degrade benign video quality or diversity.

**3 First Experiments**:
1. Evaluate detection accuracy on ConceptRisk and T2VSafetyBench-TI2V.
2. Test harmfulness reduction rates in controlled generation scenarios.
3. Assess impact of semantic suppression on benign content quality and diversity.

## Open Questions the Paper Calls Out
None provided.

## Limitations
- The performance and generalizability of ConceptGuard beyond the specific datasets and risk categories in ConceptRisk and T2VSafetyBench-TI2V remain uncertain.
- The framework's reliance on CLIP-based embeddings and predefined concept dictionaries raises questions about adaptability to new risk types without retraining.
- The impact of semantic suppression on benign content quality, diversity, and user experience is not fully quantified.

## Confidence
- **High confidence** in the methodological soundness and the empirical evaluation design for the two-stage detection-intervention pipeline.
- **Medium confidence** in the claimed generalizability of results to unseen risk categories and real-world user inputs, given dataset and concept space constraints.
- **Medium confidence** in the effectiveness of semantic suppression, pending further study of output quality and user experience trade-offs.

## Next Checks
1. Conduct cross-dataset evaluation by testing ConceptGuard on independently curated safety benchmarks for multimodal video generation, especially those with out-of-distribution risk categories.
2. Perform ablation studies on the semantic suppression mechanism to quantify impacts on benign content quality, diversity, and user-perceived utility, alongside harmfulness reduction.
3. Benchmark the runtime and resource requirements of the full ConceptGuard pipeline, including both detection and intervention stages, under realistic deployment scenarios.