---
ver: rpa2
title: Towards Practical Multi-label Causal Discovery in High-Dimensional Event Sequences
  via One-Shot Graph Aggregation
arxiv_id: '2509.19112'
source_url: https://arxiv.org/abs/2509.19112
tags:
- causal
- event
- labels
- markov
- label
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CARGO tackles scalable multi-label causal discovery in high-dimensional
  event sequences, where thousands of event types lead to multiple outcomes like vehicle
  failures or diseases. Traditional methods struggle with this scale due to super-exponential
  complexity.
---

# Towards Practical Multi-label Causal Discovery in High-Dimensional Event Sequences via One-Shot Graph Aggregation

## Quick Facts
- arXiv ID: 2509.19112
- Source URL: https://arxiv.org/abs/2509.19112
- Authors: Hugo Math; Rainer Lienhart
- Reference count: 40
- One-line primary result: CARGO recovers causal structures in minutes where classical methods fail within days, achieving weighted F1 scores up to 44.9% and precision up to 62.8%.

## Executive Summary
CARGO addresses the challenge of scalable multi-label causal discovery in high-dimensional event sequences with thousands of event types and imbalanced labels. Traditional causal discovery methods struggle with this scale due to super-exponential complexity. CARGO repurposes pretrained causal Transformers in a two-phase approach: Phase 1 infers local Markov Boundaries for each label in parallel via conditional mutual information testing, and Phase 2 fuses these local graphs using an adaptive frequency threshold that accounts for long-tail label distributions. Evaluated on a real-world automotive dataset with 29,100 event types and 474 imbalanced labels, CARGO demonstrates orders-of-magnitude speedups while maintaining competitive accuracy.

## Method Summary
CARGO uses two pretrained Transformers (Tfx for events, Tfy for labels) to perform scalable multi-label causal discovery in high-dimensional event sequences. The method operates in two phases: Phase 1 computes conditional mutual information between events and labels via Monte Carlo sampling to generate per-sequence one-shot causal graphs, and Phase 2 aggregates these local graphs using an adaptive frequency-aware thresholding strategy that handles label imbalance. The approach leverages the efficiency of amortized inference through Transformers while maintaining theoretical guarantees through statistical aggregation.

## Key Results
- Recovers causal structures in minutes where classical methods fail within days
- Achieves weighted F1 scores up to 44.9% and precision up to 62.8% on real-world automotive dataset
- Scales to 29,100 event types and 474 imbalanced labels (head: ~300 samples, tail: <20 samples)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** CARGO infers per-sequence causal graphs by approximating conditional mutual information (CMI) using pretrained Transformers instead of classical statistical tests.
- **Mechanism:** Two autoregressive Transformers ($Tf_x$ for events, $Tf_y$ for labels) estimate probability distributions. The system calculates the CMI $I(Y_j, X_i | Z)$ by comparing the entropy of label predictions given a context $Z$ versus a context with an added event $X_i$. A Monte Carlo approximation (Eq. 5) samples contexts to estimate this expected information gain.
- **Core assumption:** The **Oracle Models assumption (A4)** posits that the Transformers perfectly model the true conditional distributions $P(X_i|Z)$ and $P(Y_j|Z)$. The mechanism also relies on **Temporal Precedence (A1)** to orient edges (events cause labels).
- **Evidence anchors:**
  - [Section 3] "The CMI... is computable only with the posteriors... In practice a label-specific threshold $\theta_j \approx 0$ is applied..."
  - [Abstract] "...using two pretrained causal Transformers... to infer per-sequence one-shot causal graphs..."
  - [Corpus] Related work "TRACE" validates the broader viability of amortized causal discovery via autoregressive density estimation in single sequences.
- **Break condition:** If the Transformers are under-trained or the data distribution shifts significantly from the training data, density estimation fails, rendering the CMI estimates unreliable (False Positives/Negatives in local graphs).

### Mechanism 2
- **Claim:** Aggregating local "one-shot" graphs allows for the recovery of global Markov boundaries with greater robustness than single-sequence inference.
- **Mechanism:** This relies on **Structural Fusion**. Individual edges are treated as Bernoulli variables $Z_{i,j}^k$. By the Law of Large Numbers, the empirical frequency of an edge appearing across $m$ sequences converges to its true probability. This filtering process separates true signal (consistent edges) from noise (spurious edges appearing in only a few local graphs).
- **Core assumption:** The sequences are i.i.d. draws, and the **Faithfulness (Def 1)** condition holds in the global distribution. It assumes that while individual CI-tests may be imperfect, the aggregation cancels out errors (specifically, $1-\beta \gg \alpha$).
- **Evidence anchors:**
  - [Section 4] "The empirical frequency $\hat{\pi}_{i,j}(m)$... serves as a consistent estimator for the true probability of the edge's existence..."
  - [Section 4.1] Analysis of error rates shows frequencies converge to $(1-\beta)\pi_{ij} + \alpha(1-\pi_{ij})$, separating signal from noise.
- **Break condition:** If the dataset size $m$ is insufficient, the Law of Large Numbers does not apply, and the empirical frequencies remain high-variance estimators, failing to filter spurious edges.

### Mechanism 3
- **Claim:** An adaptive thresholding strategy is required to handle long-tail label distributions where sample support varies drastically between "head" and "tail" labels.
- **Mechanism:** A logistic decay function (Eq. 10) sets a high threshold $\tau_{max}$ for rare labels (to maximize precision despite high variance) and a lower threshold $\tau_{min}$ for common labels (to maximize recall where statistical power is sufficient). This replaces static frequency cutoffs.
- **Core assumption:** The optimal edge-inclusion criterion is a function of sample support $m_j$, and the distribution of supports follows a long-tail pattern where the median serves as a valid midpoint anchor.
- **Evidence anchors:**
  - [Section 4.2] "For rare labels... a conservative high threshold is necessary... For common labels... a high threshold would be overly stringent."
  - [Figure 4] Shows adaptive thresholding outperforming static frequency thresholds in both weighted and macro F1 scores.
- **Break condition:** If the decay rate $k$ or midpoint $m_0$ are miss-calibrated (e.g., treating a medium-frequency label as "rare"), the system will either over-prune valid causal links or flood the graph with noise.

## Foundational Learning

- **Concept: Markov Boundary (MB)**
  - **Why needed here:** This is the target output of CARGO. It is the minimal set of variables (parents, children, spouses) that renders a label conditionally independent of all other variables. In this specific paper, due to temporal assumptions, the MB is reduced to just the **Parents** (causes).
  - **Quick check question:** If variable $X$ is in the Markov Boundary of $Y$, does knowing $X$ always change the probability of $Y$ given the other variables in the boundary? (Answer: No, only if $X$ is *not* redundant given the others; MB is the minimal sufficient set).

- **Concept: Conditional Mutual Information (CMI)**
  - **Why needed here:** CARGO uses CMI as the proxy for conditional independence testing (CI-testing). If $I(Y, X|Z) \approx 0$, $X$ is not a cause of $Y$ given context $Z$.
  - **Quick check question:** How does CMI differ from standard Mutual Information? (Answer: CMI measures information gain while accounting for the influence of a conditioning set $Z$).

- **Concept: Neural Autoregressive Density Estimation (NADE)**
  - **Why needed here:** The "mechanism" relies on Transformers functioning as NADEs to estimate the probability of the next token (event or label) given the history. Without understanding that $Tf_x$ models $P(X_i|Z)$, the CMI calculation is a black box.
  - **Quick check question:** In a causal mask (autoregressive) Transformer, can the attention mechanism look at future tokens to predict the current token? (Answer: No).

## Architecture Onboarding

- **Component map:**
  1. **Input:** Batch of multi-labeled event sequences (IDs + Attention Mask)
  2. **Backbone:** Pretrained Transformers ($Tf_x$, $Tf_y$). Note: $Tf_y$ typically contains $Tf_x$ as a backbone
  3. **Phase 1 (One-Shot):**
     - **Sampler:** Top-k/Nucleus sampling generates $N$ context variations
     - **CMI Calculator:** Computes entropy difference $H(Y|Z) - H(Y|X, Z)$
     - **Local Graph:** Prunes edges using dynamic threshold $k$ (Eq. 9)
  4. **Phase 2 (Aggregation):**
     - **Accumulator:** Counts edge frequencies across the batch
     - **Adaptive Threshold:** Applies Eq. 10 based on label support $m_j$
     - **Output:** Global DAG / Markov Boundaries

- **Critical path:** The inference speed is bounded by the **Transformer forward passes**. While Phase 1 is parallelizable, the quadratic complexity of attention $O(L^2)$ with sequence length $L$ is the primary constraint.

- **Design tradeoffs:**
  - **Context Window ($c$):** Too short ($c < 15$) and the model lacks history; too long ($c > 20$) and performance drops (Appendix C.1)
  - **Sampling Number ($N$):** Higher $N$ reduces variance in CMI estimation but increases compute linearly
  - **Thresholding:** Static thresholds are faster but fail on imbalanced data; Adaptive thresholds require fitting to data statistics but handle long-tail better

- **Failure signatures:**
  - **Empty Graphs:** Dynamic threshold $k$ (Eq. 9) is too aggressive, or Transformers are poorly trained
  - **No Convergence:** Edge frequencies do not stabilize even with high $m$, indicating high CI-test error rates ($\alpha \approx 1-\beta$)
  - **Low Recall on Head Labels:** The adaptive threshold decay rate $k$ is too steep, applying "tail" logic to "head" labels

- **First 3 experiments:**
  1. **Sanity Check (Toy Data):** Generate synthetic sequences with known ground-truth DAGs. Run Phase 1 to verify if CMI correctly identifies direct parents vs. independent noise
  2. **Ablation on Sampling ($N$):** Run Phase 1 on a fixed batch with $N=[10, 50, 100]$. Plot the variance of the CMI estimates to find the "elbow" where increasing $N$ yields diminishing returns
  3. **Threshold Calibration:** Run Phase 2 on a validation set. Compare "Union", "Static Frequency", and "Adaptive" strategies by plotting Precision-Recall curves to ensure the Adaptive logic (Eq. 10) actually outperforms a simple $\tau=0.5$ cutoff

## Open Questions the Paper Calls Out
None

## Limitations
- Performance heavily depends on quality of pretrained Transformers, with poor training or data distribution shifts leading to unreliable CMI estimates
- Assumes i.i.d. sequences and relies on faithfulness condition which may not hold in all real-world scenarios
- Evaluation limited to single proprietary automotive dataset, restricting external validation

## Confidence
- **High Confidence:** The core mechanism of using pretrained Transformers for CMI estimation and the adaptive thresholding strategy for long-tail distributions are well-supported by theoretical analysis and empirical results
- **Medium Confidence:** The claim that CARGO scales to thousands of event types while maintaining reasonable performance is supported by the automotive dataset results, but broader validation across domains is needed
- **Low Confidence:** The assertion that CARGO "achieves weighted F1 scores up to 44.9% and precision up to 62.8%" should be viewed cautiously since the evaluation is limited to one proprietary dataset

## Next Checks
1. **Cross-Domain Validation:** Apply CARGO to a publicly available multi-label event sequence dataset (e.g., medical diagnosis codes from electronic health records) to verify performance generalizes beyond automotive applications
2. **Robustness Testing:** Systematically degrade Transformer model quality through controlled experiments (reducing training data, introducing domain shifts) to quantify the impact on CARGO's causal discovery accuracy
3. **Statistical Power Analysis:** Conduct experiments varying sequence counts (m) to empirically validate the Law of Large Numbers convergence claims and determine the minimum dataset size required for reliable aggregation