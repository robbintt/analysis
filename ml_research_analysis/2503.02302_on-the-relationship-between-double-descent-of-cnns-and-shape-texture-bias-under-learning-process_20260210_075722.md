---
ver: rpa2
title: On the Relationship Between Double Descent of CNNs and Shape/Texture Bias Under
  Learning Process
arxiv_id: '2503.02302'
source_url: https://arxiv.org/abs/2503.02302
tags:
- descent
- double
- texture
- bias
- shape
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the relationship between double descent
  in CNNs and the model's shape/texture bias during training. The authors hypothesize
  that the double descent phenomenon is related to the CNN's focus on shape vs.
---

# On the Relationship Between Double Descent of CNNs and Shape/Texture Bias Under Learning Process

## Quick Facts
- arXiv ID: 2503.02302
- Source URL: https://arxiv.org/abs/2503.02302
- Reference count: 31
- Key outcome: The paper investigates how double descent in CNNs correlates with the model's shape/texture bias during training, finding synchronized double descent/ascent patterns between test error and feature bias evolution.

## Executive Summary
This paper explores the relationship between double descent behavior in convolutional neural networks and the model's shape/texture bias during training. The authors propose that the double descent phenomenon may be linked to how CNNs prioritize shape versus texture features as learning progresses. Through experiments measuring shape/texture bias via final-layer activations, they find that this bias exhibits synchronized double descent/ascent patterns with test error, particularly in the first two phases of training. Interestingly, this synchronization occurs even without label noise, suggesting deeper connections between generalization behavior and feature learning dynamics.

## Method Summary
The authors quantify shape/texture bias by analyzing activations in the final convolutional layer of CNNs, tracking how this bias evolves during training. They compare this evolution with test error progression across different training phases, specifically examining synchronization patterns. The experimental setup uses ResNet18 on CIFAR datasets to replicate baseline double descent behavior, then extends the analysis to study feature bias dynamics. The methodology involves correlating shape/texture bias scores with test error metrics throughout the learning process.

## Key Results
- Shape/texture bias exhibits synchronized double descent/ascent patterns with test error during training phases
- Strong correlation (synchronization) observed specifically in Phases 1 and 2 of double descent
- Double descent/ascent of shape/texture bias occurs even in the absence of label noise
- The inverse correlation between shape and texture biases suggests complex underlying mechanisms

## Why This Works (Mechanism)
The relationship works because CNNs naturally develop different feature preferences during training, and these preferences shift in ways that correlate with generalization performance. As models transition through different learning phases, they may initially focus on texture features, then shift toward shape features, creating the characteristic double descent pattern. This shift in feature bias appears to directly influence test error, explaining why models with the same architecture can show different generalization behaviors depending on training duration and dataset characteristics.

## Foundational Learning
- **Double descent phenomenon**: The U-shaped generalization curve that appears when model capacity or training epochs increase beyond the interpolation threshold. Why needed: Understanding this behavior is crucial for explaining why larger models or longer training can sometimes improve performance. Quick check: Verify that test error decreases, then increases, then decreases again as model capacity grows.

- **Shape vs texture bias**: The tendency of CNNs to rely more heavily on either global object shapes or local texture patterns for classification. Why needed: This fundamental difference in feature extraction directly impacts model generalization and robustness. Quick check: Test models on Stylized-ImageNet to measure shape bias strength.

- **Feature representation analysis**: The method of quantifying what features models learn by examining activation patterns in specific network layers. Why needed: This provides insight into the internal decision-making process of neural networks. Quick check: Visualize activation maps to confirm shape/texture feature detection.

## Architecture Onboarding

**Component Map**: Input images → ResNet18/CNN → Final convolutional layer → Shape/texture bias quantification → Test error measurement

**Critical Path**: The quantification of shape/texture bias in the final convolutional layer serves as the critical path, as this measurement directly correlates with double descent behavior and determines the main experimental findings.

**Design Tradeoffs**: The authors chose to focus on final-layer activations for bias quantification rather than intermediate layers, trading comprehensive feature analysis for computational efficiency and clearer signal-to-noise ratios. This decision prioritizes interpretability over capturing the full complexity of feature evolution throughout the network.

**Failure Signatures**: The methodology may fail when shape and texture features are highly correlated in the dataset, making bias quantification ambiguous. Additionally, models that learn abstract features beyond simple shape/texture distinctions may not show clear bias patterns, potentially masking the double descent relationship.

**3 First Experiments**:
1. Replicate the shape/texture bias quantification on a different CNN architecture to verify method generalizability
2. Test the synchronization pattern on a dataset with artificially manipulated shape-texture relationships
3. Measure bias evolution during early stopping scenarios to see if the double descent/ascent pattern persists

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the learning of specific feature biases (shape/texture) cause the double descent phenomenon, or is the observed bias shift merely a correlated symptom of other learning dynamics?
- Basis in paper: [explicit] The Discussion section asks, "But do features like shape and texture directly cause the double descent phenomenon of test error?" noting that the inverse correlation between shape and texture suggests the mechanism is more complex than a simple causal link.
- Why unresolved: The paper establishes a strong correlation (synchronization) between test error and bias but does not isolate the variable to prove causality.
- What evidence would resolve it: Intervention experiments where shape or texture learning is selectively penalized or forced during specific phases to observe if the double descent curve is correspondingly suppressed or amplified.

### Open Question 2
- Question: Does the relationship between double descent and shape/texture bias persist under large-scale training conditions (e.g., larger datasets and models)?
- Basis in paper: [explicit] The Limitation section states, "As recent computer vision studies focus more on large-scale training, it would be interesting to study the scaling of double descent."
- Why unresolved: The experiments are restricted to simpler settings (ResNet18 on CIFAR) to replicate Nakkiran's baseline, leaving the behavior in state-of-the-art large-scale systems unknown.
- What evidence would resolve it: Replicating the analysis framework on large-scale datasets (like ImageNet-1k) and architectures (like Transformers or larger ResNets) to see if the synchronization scores remain high.

### Open Question 3
- Question: Do similar "double descent/ascent" patterns occur for feature biases in non-visual modalities, such as natural language or speech?
- Basis in paper: [explicit] The Limitation section proposes that "extending bias quantification methods to modalities other than images, such as natural language and speech, is also challenging but promising."
- Why unresolved: The current methodology relies on image-specific definitions of shape and texture, and it is unclear what the analogous "features" would be in text or audio data.
- What evidence would resolve it: Defining quantifiable feature biases for other domains (e.g., syntactic vs. semantic bias in NLP) and tracking them relative to test error during training.

## Limitations
- The methodology for quantifying shape/texture bias relies on analyzing activations in the final convolutional layer, potentially missing complex feature representations throughout the network
- Experimental validation is limited to Phase 1 and Phase 2 of double descent, potentially overlooking important dynamics in other phases
- The claim about double descent/ascent occurring without label noise requires broader validation across different architectures and datasets

## Confidence

**Major Claim Clusters Confidence:**
- **High confidence**: The synchronization between double descent of test error and shape/texture bias evolution in Phases 1 and 2 is well-supported by experimental evidence
- **Medium confidence**: The hypothesis connecting double descent phenomenon to shape/texture bias focus during training is plausible but needs broader validation
- **Medium confidence**: The observation of double descent/ascent in shape/texture bias without label noise is interesting but requires replication across more experimental conditions

## Next Checks

1. Test the methodology across different CNN architectures (ResNet, EfficientNet, Vision Transformers) to verify the generalizability of the shape/texture bias quantification method
2. Conduct experiments with varying levels of label noise and data augmentation to better understand the conditions under which double descent manifests
3. Analyze the temporal dynamics of shape/texture bias throughout all phases of training, including early stopping scenarios, to determine if the synchronization pattern holds consistently