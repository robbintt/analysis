---
ver: rpa2
title: 'Comparing human and LLM proofreading in L2 writing: Impact on lexical and
  syntactic features'
arxiv_id: '2506.09021'
source_url: https://arxiv.org/abs/2506.09021
tags:
- proofreading
- lexical
- writing
- syntactic
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study compared human and LLM proofreading in L2 writing, focusing
  on lexical and syntactic interventions. Using the ICNALE dataset, original and professionally
  proofread essays were compared with outputs from three LLMs (ChatGPT-4o, Llama3.1-8b,
  Deepseek-r1-8b).
---

# Comparing human and LLM proofreading in L2 writing: Impact on lexical and syntactic features

## Quick Facts
- arXiv ID: 2506.09021
- Source URL: https://arxiv.org/abs/2506.09021
- Reference count: 17
- Human and LLM proofreading both improved bigram lexical coherence, but LLMs made more extensive edits, increasing vocabulary diversity and syntactic complexity

## Executive Summary
This study investigates the comparative impact of human and large language model (LLM) proofreading on L2 writing, focusing on lexical and syntactic features. Using the ICNALE dataset, researchers analyzed original essays alongside professionally proofread versions and outputs from three LLMs (ChatGPT-4o, Llama3.1-8b, Deepseek-r1-8b). Results demonstrate that both human and LLM proofreading improved bigram lexical coherence, but LLMs made significantly more extensive edits, increasing vocabulary diversity, sophistication, and syntactic complexity. Notably, LLM outputs reduced past tense and main verb "be" use while introducing more noun phrases, adjective modifiers, and nominalizations.

The study reveals that while LLMs enhance fluency and perceived proficiency, they may also alter authorial voice and inflate language assessment scores. High consistency across LLM models (Cronbach's α: 0.83-0.81) suggests these effects are model-agnostic rather than idiosyncratic. The findings highlight the need for cautious integration of LLMs in L2 writing contexts, as the extensive edits may mask true learner proficiency levels while improving surface-level fluency.

## Method Summary
The study employed the International Corpus Network of Asian Learners of English (ICNALE) dataset, comparing original learner essays with professionally proofread versions and outputs from three LLM models: ChatGPT-4o, Llama3.1-8b, and Deepseek-r1-8b. Researchers conducted systematic analysis of lexical coherence (bigram frequency) and syntactic complexity (noun phrases, adjective modifiers, nominalizations). The comparison focused on identifying intervention patterns between human and LLM proofreading, measuring changes in vocabulary diversity, sophistication, and grammatical structures.

## Key Results
- Both human and LLM proofreading improved bigram lexical coherence in L2 writing
- LLMs made more extensive edits than human proofreaders, increasing vocabulary diversity and syntactic complexity
- LLM outputs showed consistent patterns across models: reduced past tense usage, decreased main verb "be" use, and increased noun phrases, adjective modifiers, and nominalizations

## Why This Works (Mechanism)
The study demonstrates that LLMs' superior text generation capabilities enable more comprehensive linguistic interventions compared to human proofreaders. LLMs systematically enhance lexical sophistication through synonym replacement and collocation improvements while increasing syntactic complexity through structural transformations. The consistency across different LLM architectures suggests these mechanisms are fundamental to how transformer-based models process and optimize language output for fluency.

## Foundational Learning
- Lexical coherence measurement: Understanding bigram frequency analysis for evaluating text cohesion; needed to quantify proofreading improvements; quick check: compare bigram overlap between original and proofread texts
- Syntactic complexity metrics: Knowledge of noun phrase analysis, adjective modifier identification, and nominalization detection; needed to measure structural changes; quick check: count syntactic transformations per 100 words
- Language proficiency assessment: Understanding how vocabulary diversity and sophistication relate to perceived proficiency; needed to interpret inflation effects; quick check: correlate vocabulary metrics with standardized test scores

## Architecture Onboarding
**Component Map**: ICNALE corpus -> Human proofreading -> LLM proofreading (ChatGPT-4o, Llama3.1-8b, Deepseek-r1-8b) -> Lexical analysis -> Syntactic analysis -> Consistency measurement

**Critical Path**: Text input → LLM generation → Bigram coherence analysis → Syntactic complexity measurement → Cross-model consistency evaluation

**Design Tradeoffs**: The study prioritizes comprehensive analysis over speed, using multiple LLM models to ensure generalizability despite increased computational costs. Human proofreading serves as the baseline but may introduce variability due to individual differences.

**Failure Signatures**: Inconsistent results across LLM models would indicate architecture-specific biases; low Cronbach's alpha values would suggest model unreliability; minimal differences between human and LLM outputs would question LLM efficacy.

**First Experiments**:
1. Replicate analysis using a different L2 writing corpus to test generalizability
2. Compare results with a smaller, more focused set of syntactic features
3. Conduct qualitative analysis of authorial voice changes in LLM outputs

## Open Questions the Paper Calls Out
None

## Limitations
- Analysis limited to three LLM models from similar architectural families, potentially constraining generalizability
- Single corpus (ICNALE) used, which may limit findings to this specific context
- Study is correlational and cannot definitively prove that LLM changes mask true learner proficiency

## Confidence
- High confidence: LLM outputs produce more extensive edits than human proofreaders (Cronbach's α: 0.83-0.81)
- Medium confidence: LLMs increase perceived proficiency and alter authorial voice
- Medium confidence: Findings may not generalize beyond tested LLM architectures and corpus

## Next Checks
1. Replication with diverse LLM architectures and multiple L2 writing corpora to test generalizability
2. Controlled experiments measuring actual writing proficiency gains versus superficial improvements
3. Qualitative analysis of authorial voice changes to complement quantitative findings