---
ver: rpa2
title: 'Findings of MEGA: Maths Explanation with LLMs using the Socratic Method for
  Active Learning'
arxiv_id: '2507.12079'
source_url: https://arxiv.org/abs/2507.12079
tags:
- mega
- learning
- turn
- students
- coin
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study compared a novel interactive Maths explanation method
  (MEGA) that combines Socratic questioning, chain-of-thought reasoning, simplified
  gamification, and formative feedback with traditional step-by-step explanations
  (CoT) using Large Language Models (LLMs) like GPT4o and Claude 3.5 Sonnet. Sixty
  university students evaluated both methods on Grade School Math 8K (GSM8K) and Mathematics
  Aptitude Test of Heuristics (MATH) datasets.
---

# Findings of MEGA: Maths Explanation with LLMs using the Socratic Method for Active Learning

## Quick Facts
- arXiv ID: 2507.12079
- Source URL: https://arxiv.org/abs/2507.12079
- Reference count: 40
- Primary result: MEGA significantly outperformed traditional CoT for math explanations, especially on harder problems

## Executive Summary
This study introduces MEGA (Maths Explanation with LLMs using the Socratic Method for Active Learning), a novel interactive approach that combines Socratic questioning, chain-of-thought reasoning, simplified gamification, and formative feedback for math education. When compared to traditional step-by-step explanations using GPT4o and Claude 3.5 Sonnet on 120 math problems (GSM8K and MATH datasets), MEGA was significantly preferred by university students, particularly for harder problems. The method exposed LLM hallucinations more clearly than traditional approaches, highlighting both its diagnostic value and the need for careful design.

## Method Summary
The MEGA system implements an interactive learning approach where students answer binary sub-questions during the LLM's reasoning process, receiving immediate formative feedback. The method uses a specific system prompt instructing the LLM to adopt Socratic behavior, generate two answer choices per sub-question, and wait for user input before proceeding. The study compared MEGA against traditional Chain-of-Thought explanations using zero-shot inference with GPT4o and Claude 3.5 Sonnet on 60 problems each from GSM8K (grade school) and MATH (advanced) datasets. Human participants evaluated explanations through pairwise comparisons, and three accuracy metrics were computed for both methods.

## Key Results
- MEGA was significantly preferred over CoT for harder MATH problems (47.5% vs 26.67% preference)
- Students overall preferred interactive learning (77.78% vs 22.22% for non-interactive)
- MEGA exposed LLM hallucinations more clearly, particularly at sub-question steps
- Only 3 of 6 tested LLMs could execute the MEGA prompt reliably

## Why This Works (Mechanism)
MEGA leverages the Socratic method's effectiveness in promoting active learning by requiring students to engage with intermediate reasoning steps rather than passively receiving explanations. The binary choice format simplifies interaction while maintaining cognitive engagement, and the formative feedback at each checkpoint reinforces correct reasoning paths. This interactive structure makes learning more dynamic and helps students develop problem-solving skills rather than just memorizing solutions.

## Foundational Learning
- Concept: Chain-of-Thought (CoT) Reasoning
  - Why needed here: MEGA builds on CoT as its explanatory backbone, showing intermediate reasoning steps
  - Quick check question: Can you explain the difference between a model giving you only a final answer versus showing its work step-by-step?

- Concept: Socratic Method
  - Why needed here: The core innovation of MEGA is embedding Socratic questioning into the CoT framework
  - Quick check question: If a student asks "What is 15 + 27?", how would a Socratic tutor respond differently than a traditional one?

- Concept: Formative vs Summative Feedback
  - Why needed here: MEGA relies on formative feedbackâ€”real-time, process-oriented feedback during learning
  - Quick check question: When a teacher marks a final exam with a score of 85%, is this formative or summative feedback? What if they instead circle a specific error and ask you to rethink it during the test?

## Architecture Onboarding
- Component map: LLM (GPT4o/Claude 3.5 Sonnet) -> System prompt (MEGA template) -> Problem dataset (GSM8K/MATH) -> Web interface (binary choices + feedback)

- Critical path: First, validate LLM can execute MEGA prompt with 10 test problems. Second, confirm problem dataset includes difficulty labels. Third, design UI to show current sub-question, two choices, and feedback before proceeding.

- Design tradeoffs: (1) Binary vs. more choices: Binary reduces cognitive load but limits diagnostic insight. (2) LLM selection: Only 3 of 6 tested models worked reliably. (3) Error visibility: MEGA exposes hallucinations more clearly, which aids debugging but may confuse learners.

- Failure signatures: (1) LLM ignores system prompt and generates standard CoT without Socratic structure. (2) LLM produces incorrect sub-questions or choices (hallucination at intermediate steps). (3) LLM fails to wait for user input and generates all steps at once. (4) Users report frustration with unnecessary interaction on simple problems.

- First 3 experiments:
  1. **Prompt adherence test**: Run MEGA system prompt against target LLM with 10 diverse math problems. Verify each output follows Socratic structure with binary choices.
  2. **Difficulty-stratified user test**: Have 10-15 users complete 5 simple and 5 hard problems using MEGA. Measure preference ratings and time-on-task.
  3. **Hallucination audit**: Run 20 problems through MEGA and CoT with same LLM. Compare error visibility and whether users could catch errors interactively.

## Open Questions the Paper Calls Out
- **Transfer to other subjects**: The MEGA method may apply to other fields beyond Maths, but effectiveness in subjects like Physics is unknown and needs validation.
- **Knowledge retention**: It would be beneficial to evaluate actual learning outcomes and long-term retention compared to traditional explanations, not just preference.
- **Temperature optimization**: Setting LLM temperature to zero might improve accuracy by reducing hallucinations, but the trade-off with user engagement is unknown.

## Limitations
- The study sample of 60 university students limits generalizability across different educational contexts and age groups.
- Binary choice format may artificially constrain response richness compared to open-ended alternatives.
- Only tested on mathematics datasets, leaving effectiveness on other reasoning domains uncertain.

## Confidence
- **High Confidence**: MEGA's comparative preference advantage on harder MATH problems is robust given controlled experimental design
- **Medium Confidence**: Overall interactive learning preference (77.78%) is supported but may have selection bias
- **Medium Confidence**: LLM hallucination at sub-question steps is well-documented through examples
- **Low Confidence**: Claims about MEGA's effectiveness for "difficult problems" based on single dataset may not generalize

## Next Checks
1. **Cross-Dataset Validation**: Test MEGA on additional complex reasoning datasets (coding, scientific reasoning) to verify advantage on difficult problems generalizes beyond mathematics.

2. **Longitudinal Learning Impact**: Conduct study measuring actual learning outcomes (post-test scores, retention over time) rather than just preference ratings.

3. **Prompt Robustness Testing**: Systematically test MEGA prompt variations across multiple LLM families to identify minimum capability threshold and expand model compatibility.