---
ver: rpa2
title: Generating Storytelling Images with Rich Chains-of-Reasoning
arxiv_id: '2512.07198'
source_url: https://arxiv.org/abs/2512.07198
tags:
- image
- images
- story
- b-instruct
- semantic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Storytelling Image Generation, a novel task
  to generate single images that tell rich, logically coherent stories. The authors
  propose a two-stage pipeline, StorytellingPainter, combining LLM reasoning and T2I
  synthesis.
---

# Generating Storytelling Images with Rich Chains-of-Reasoning

## Quick Facts
- **arXiv ID**: 2512.07198
- **Source URL**: https://arxiv.org/abs/2512.07198
- **Reference count**: 21
- **Primary result**: Introduces Storytelling Image Generation task with two-stage pipeline, achieving significant improvements in story and image quality through CoR-Guided prompting

## Executive Summary
This paper introduces Storytelling Image Generation, a novel task to generate single images that tell rich, logically coherent stories. The authors propose a two-stage pipeline, StorytellingPainter, combining LLM reasoning and T2I synthesis. They also develop an evaluation framework with three specialized evaluators and introduce lightweight Mini-Storytellers to improve small-scale model performance. Experiments show that CoR-Guided prompting significantly enhances story and image quality, with GPT-4 models achieving the highest performance. Mini-Storytellers demonstrate substantial improvements in generating concise, semantically rich stories, bridging the gap with larger models. GPT-Image-1 outperforms DALL-E 3 in alignment, highlighting the task's high demands on T2I capabilities.

## Method Summary
The paper proposes a two-stage StorytellingPainter pipeline: first, an LLM Storyteller generates a single-moment story with explicit Chains-of-Reasoning (CoR) across seven semantic dimensions; second, a T2I Painter synthesizes an image depicting the story. The CoR-Guided prompting mode uses a structured template covering Time, Location, Character Role, Character Relationship, Event, Event Causal Relationship, and Mental State. To improve small model performance, Mini-Storytellers are trained via knowledge distillation from GPT-4.1-generated story-image pairs using SFT or DPO. The evaluation framework includes three specialized evaluators measuring Semantic Complexity (CoT VLISA BERT), Diversity (KNN-based cosine distance), and Alignment (LLM key-point extraction + LVLM scoring).

## Key Results
- CoR-Guided prompting improves Semantic Score from ~31.5 to ~52.4 (GPT-4o + GPT-Image-1) and Diversity Score from 0.312 to 0.393
- Mini-Storyteller-LLaMA-3.1-8B-SFT achieves Human Semantic Score 49.4 vs. base 32.1 (+17.3 points)
- GPT-Image-1 outperforms DALL-E 3 in alignment, particularly on causal relationships and mental states
- Even GPT-4.1 + GPT-image-1 achieves only 61.0 Semantic Score versus 71.8 for top human examples

## Why This Works (Mechanism)

### Mechanism 1: Structured CoR Prompting Guides Semantic Density
Explicitly specifying seven semantic dimensions during story generation produces images with richer, more coherent narratives. The CoR-Guided mode provides the LLM with a structured template covering Time, Location, Character Role, Character Relationship, Event, Event Causal Relationship, and Mental State. This constrains the output space toward semantically dense, single-moment stories rather than temporal sequences. Combined with Dynamic In-Context Learning (randomly sampling examples from CogBench), it increases both complexity and diversity.

### Mechanism 2: Two-Stage Decomposition Reduces Joint Generation Complexity
Separating story imagination (LLM) from visual synthesis (T2I) yields higher-quality storytelling images than end-to-end approaches. The pipeline factorizes a hard joint problem into (1) creative reasoning—generating a logically coherent, single-moment narrative with explicit CoRs—and (2) conditional rendering—synthesizing an image that depicts all specified elements. Each stage can use models optimized for its modality.

### Mechanism 3: Knowledge Distillation Bridges the Open-Source Gap
Lightweight models (1B–8B parameters) fine-tuned on GPT-4.1-generated data can approximate proprietary-model storytelling quality. Use StorytellingPainter (CoR-Guided mode) with GPT-4.1 as teacher to generate 2,000 story-image pairs. Apply SFT (supervised fine-tuning) or DPO (direct preference optimization) with teacher outputs as preferred responses. DPO-Mix further improves larger models (8B, 7B) by adding smaller-model outputs as negative examples.

## Foundational Learning

- **Concept: Chain-of-Thought (CoT) / Chain-of-Reasoning (CoR)**
  - Why needed here: The core task requires models to generate stories where multiple visual clues logically imply a conclusion. Understanding explicit reasoning chains helps you debug why a generated image fails to convey narrative.
  - Quick check question: Given the visual clues "wet floor," "running water," and "oblivious mother," can you articulate the inferred conclusion and the logical connective?

- **Concept: Text-to-Image Alignment**
  - Why needed here: The evaluation framework measures whether generated images faithfully represent story elements across seven dimensions. Poor alignment is a primary failure mode.
  - Quick check question: If a story specifies "a woman frowning at a clock showing 2:25," what failures would you check for in the generated image?

- **Concept: Knowledge Distillation (SFT vs. DPO)**
  - Why needed here: Mini-Storytellers use both techniques; understanding when to apply each affects deployment cost and quality tradeoffs.
  - Quick check question: What type of training signal does DPO require that SFT does not?

## Architecture Onboarding

- **Component map:** Storyteller (LLM) -> Story -> Painter (T2I) -> Image -> Evaluators (Semantic Complexity, Diversity, Alignment)
- **Critical path:** CoR-Guided prompt → Storyteller (LLM) → Story → Painter (T2I) → Image → Evaluators. If any evaluator score is low, trace backward: alignment failure → Painter; complexity failure → Storyteller; diversity failure → prompting/ICL strategy.
- **Design tradeoffs:** SFT improves semantic complexity but may reduce diversity (Table 2: Mini-Storyteller-LLaMA-3.2-1B-SFT diversity drops from 0.432 to 0.344). DPO-Mix preserves diversity better for larger models (7B, 8B) but requires additional negative samples. GPT-Image-1 ("auto" quality) outperforms DALL-E 3 but at higher cost. Proprietary Storytellers (GPT-4o/4.1) still outperform all Mini-Storytellers on human semantic scores (57.6–62.9 vs. 45–49).
- **Failure signatures:** Temporal sequence in story (Model ignores instruction, outputs multi-event narrative with dialogue → low alignment). Missing causal relationships (Image shows events but not their logical connection → low Semantic Score). Plagiarized examples (Small models copy ICL examples verbatim → artificially high diversity). T2I text rendering failure (Signs/labels unreadable → story elements not conveyed).
- **First 3 experiments:**
  1. Reproduce Table 1 ablation: Run StorytellingPainter with Naive vs. CoR-Guided prompting using GPT-4o + DALL-E 3 on 30 samples. Verify Semantic Score improvement.
  2. Mini-Storyteller quick test: Fine-tune Llama-3.2-3B-Instruct on 500 GPT-4.1-generated samples (SFT, 1 epoch). Compare output word count and instruction-following rate.
  3. Painter alignment audit: Generate 10 stories with GPT-4o, render with both DALL-E 3 and GPT-Image-1, manually score alignment on [Character Relationship] and [Event Causal Relationship] dimensions.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the logical coherence of generated stories be systematically improved to ensure semantically sound Chains-of-Reasoning rather than merely stacking multiple events?
- Basis in paper: The limitations section states: "Some model-generated stories lack logical soundness" and "the logical connections in images generated by existing models are still insufficient."
- Why unresolved: The current approach relies on prompting strategies (CoR-Guided Mode) and knowledge distillation, but smaller models still struggle with constructing "narratives that are both logically coherent and semantically rich."
- What evidence would resolve it: Development of specialized training objectives or architectures that explicitly model causal relationships between story elements, validated through improved alignment scores on causal relationship dimensions.

### Open Question 2
- Question: What mechanisms can enhance output diversity while maintaining semantic quality, preventing the observed issue of "repetitive themes" across generated stories?
- Basis in paper: The limitations section notes: "the output diversity remains to be improved, as current models sometimes generate stories with repetitive themes."
- Why unresolved: While Dynamic In-Context Learning was proposed to enhance diversity, SFT training was observed to "diminish output diversity," creating a tension between quality and variety.
- What evidence would resolve it: New training paradigms or decoding strategies that achieve both high Semantic Scores and high Diversity Scores simultaneously, surpassing the current trade-off.

### Open Question 3
- Question: How can the performance gap between AI-generated storytelling images and top-tier human-created illustrations be closed?
- Basis in paper: The paper notes: "the score disparity between these models and the top 30 human-created images in CogBench indicates that their capabilities still fall significantly short of top-tier human performance."
- Why unresolved: Even GPT-4.1 + GPT-image-1 achieves only 61.0 Semantic Score versus 71.8 for top human examples, indicating fundamental capability limitations.
- What evidence would resolve it: Novel architectures or training approaches that achieve Semantic Scores statistically indistinguishable from human expert-created storytelling images.

### Open Question 4
- Question: Can the seven-dimension CoR framework (Time, Location, Character Role, Character Relationship, Event, Event Causal Relationship, Mental State) be extended or refined to better capture cross-cultural storytelling elements?
- Basis in paper: The paper mentions Cookie Theft is "now considered outdated and does not adapt well across different cultures" as motivation, yet the seven-dimension framework does not explicitly address cultural adaptability in generated images.
- Why unresolved: The cultural adaptation problem raised for Cookie Theft remains unaddressed in the proposed generation framework.
- What evidence would resolve it: Cross-cultural evaluation studies showing generated images are appropriately interpretable across diverse cultural contexts, or framework extensions that incorporate cultural dimensions.

## Limitations
- Evaluation framework relies heavily on proprietary models (GPT-4o, GPT-4.1, GPT-Image-1), creating reproducibility barriers
- CoT VLISA BERT model used for semantic complexity evaluation is not publicly available
- Knowledge distillation approach shows improvement but still leaves significant performance gap between Mini-Storytellers and proprietary models
- Study focuses on English-language stories; cross-lingual performance remains untested

## Confidence
- **High confidence:** The two-stage decomposition mechanism (LLM reasoning + T2I synthesis) is well-supported by both ablation studies and related work on LLM-driven visual generation
- **Medium confidence:** The CoR-Guided prompting improvements are demonstrated with strong quantitative results, but rely on proprietary models for both story generation and evaluation
- **Low confidence:** The Mini-Storyteller distillation approach shows promising improvements but the absolute performance gap with larger models suggests incomplete knowledge transfer or fundamental architectural limitations

## Next Checks
1. **Replicate the core ablation** by running StorytellingPainter with Naive vs. CoR-Guided prompting using accessible open-source models (e.g., Qwen2.5-7B-Instruct + SDXL) on a 30-sample subset to verify the Semantic Score improvement pattern.
2. **Test distillation robustness** by fine-tuning Llama-3.2-3B-Instruct on 500 GPT-4.1-generated samples and measuring both semantic complexity improvement and diversity preservation compared to base performance.
3. **Audit alignment capabilities** by generating 10 stories with GPT-4o and rendering with both DALL-E 3 and an open-source T2I model, then manually scoring alignment on [Character Relationship] and [Event Causal Relationship] dimensions to identify whether alignment failures stem from story quality or T2I limitations.