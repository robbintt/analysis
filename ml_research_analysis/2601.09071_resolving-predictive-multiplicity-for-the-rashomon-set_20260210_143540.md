---
ver: rpa2
title: Resolving Predictive Multiplicity for the Rashomon Set
arxiv_id: '2601.09071'
source_url: https://arxiv.org/abs/2601.09071
tags:
- test
- validation
- disagreement
- rashomon
- xtest
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper addresses predictive multiplicity in the Rashomon set\u2014\
  where multiple equally accurate models produce inconsistent predictions\u2014which\
  \ undermines trust in high-stakes applications. Three complementary methods are\
  \ proposed: (1) outlier correction, which improves label quality by identifying\
  \ and fixing mislabeled points; (2) local patching, which reduces local bias by\
  \ adjusting predictions in model neighborhoods using validation data; and (3) pairwise\
  \ reconciliation, which iteratively reconciles the most disagreeing model pairs\
  \ by shifting the worse-performing model toward ensemble consensus."
---

# Resolving Predictive Multiplicity for the Rashomon Set
## Quick Facts
- arXiv ID: 2601.09071
- Source URL: https://arxiv.org/abs/2601.09071
- Reference count: 5
- Primary result: Three methods reduce predictive multiplicity across equally accurate models, with pairwise reconciliation alone driving disagreement near zero and combined PR+LP achieving up to 99% disagreement reduction while improving accuracy and neighborhood agreement

## Executive Summary
This paper addresses predictive multiplicity—a problem where multiple equally accurate models produce inconsistent predictions—which undermines trust in high-stakes applications. The authors propose three complementary methods to reduce multiplicity in the Rashomon set: outlier correction (fixing mislabeled points), local patching (reducing local bias by adjusting predictions in model neighborhoods), and pairwise reconciliation (iteratively reconciling disagreeing model pairs toward ensemble consensus). Experiments on four datasets demonstrate that pairwise reconciliation alone drives disagreement near zero, but combining it with local patching yields the best trade-off—achieving up to 99% reduction in disagreement while improving neighborhood agreement (LCAE@30) by up to 14% and maintaining or improving accuracy.

## Method Summary
The paper presents three methods to resolve predictive multiplicity in the Rashomon set. First, Outlier Correction identifies and fixes mislabeled points in training data using a majority-vote ensemble, then replaces outliers in validation data with ensemble means. Second, Local Patching reduces local bias by adjusting predictions in model neighborhoods using validation data, evaluating Brier score changes before and after patching. Third, Pairwise Reconciliation iteratively reconciles the most disagreeing model pairs by shifting the worse-performing model toward ensemble consensus, using a moving average of ensemble predictions. The methods are combined by applying Outlier Correction first, then Local Patching, and finally Pairwise Reconciliation. Experiments use four datasets (Adult, COMPAS, Folk Mobility, Folk Travel) with 60/20/20 train/validation/test splits, diverse classifiers (logistic regression, random forests, extra trees, gradient boosting, MLPs), and retention of top 25 models by validation Brier score.

## Key Results
- Pairwise reconciliation alone drives disagreement near zero across all datasets
- Combined PR+LP achieves up to 99% reduction in disagreement while improving LCAE@30 by up to 14%
- Accuracy is maintained or improved after reconciliation procedures
- Reconciled predictions can be distilled into a single interpretable model for deployment

## Why This Works (Mechanism)
The paper's methods work by systematically reducing sources of disagreement between equally accurate models. Outlier correction improves label quality, eliminating one source of inconsistency. Local patching reduces local bias by ensuring models agree in their neighborhoods, addressing systematic disagreement patterns. Pairwise reconciliation iteratively forces the worst-performing models to align with ensemble consensus, directly targeting the most egregious disagreements. The combination approach addresses both global (label quality, ensemble consensus) and local (neighborhood bias) sources of multiplicity simultaneously.

## Foundational Learning
- **Predictive multiplicity**: Multiple equally accurate models produce inconsistent predictions. Why needed: Understanding this problem motivates the need for reconciliation methods. Quick check: Verify that your ensemble exhibits disagreement despite similar accuracy.
- **Rashomon set**: The collection of models with similar validation performance. Why needed: Defines the scope of models to reconcile. Quick check: Confirm your top M models have Brier scores within acceptable tolerance.
- **LCAE@30**: Local Class Agreement Error within k=30 nearest neighbors. Why needed: Measures neighborhood-level agreement, crucial for Local Patching effectiveness. Quick check: Calculate LCAE@30 on your validation set before and after patching.
- **Brier score**: Proper scoring rule for probabilistic predictions. Why needed: Used to rank models and evaluate Local Patching changes. Quick check: Verify Brier scores decrease after Outlier Correction.

## Architecture Onboarding
**Component map**: Data preparation -> Base model training -> Outlier Correction -> Local Patching -> Pairwise Reconciliation -> Evaluation

**Critical path**: Outlier Correction → Local Patching → Pairwise Reconciliation, where each stage builds on the previous to progressively reduce multiplicity

**Design tradeoffs**: PR alone achieves near-zero disagreement but may sacrifice some accuracy; LP alone improves neighborhood agreement but can reduce accuracy; combining PR+LP achieves optimal trade-off between multiplicity reduction and performance

**Failure signatures**: LP alone causes accuracy drops (k=5 neighborhoods may overfit); OC without PR doesn't reduce disagreement (OC is preprocessing only); PR may fail if base models are too dissimilar in performance

**First experiments**: 1) Apply Local Patching to a small synthetic dataset with known neighborhood bias patterns; 2) Test Outlier Correction impact on a single base model rather than the ensemble; 3) Reproduce LCAE@30 calculation independently using validation neighborhoods

## Open Questions the Paper Calls Out
None

## Limitations
- Exact classifier hyperparameter grids are not specified, only described as "wide range"
- Preprocessing specifics for each dataset (missing value handling, feature scaling) are not detailed
- No confidence intervals reported for metric improvements
- Reconciliation procedures assume balanced base model performance, which may not hold in all settings

## Confidence
- **High**: Predictive multiplicity is a real problem that reduces interpretability and trustworthiness in model ensembles
- **High**: Pairwise Reconciliation algorithm logic is sound and reduces disagreement to near zero
- **Medium**: Reported quantitative improvements (up to 99% disagreement reduction, 14% LCAE@30 gain) are reproducible given access to base model grids
- **Low**: Generalization to non-binary classification or highly imbalanced datasets is not demonstrated

## Next Checks
1. Verify Local Patching implementation on a small synthetic dataset with known neighborhood bias patterns
2. Test Outlier Correction impact when applied to a single base model rather than the ensemble
3. Reproduce the LCAE@30 calculation independently using validation neighborhoods to confirm the metric computation