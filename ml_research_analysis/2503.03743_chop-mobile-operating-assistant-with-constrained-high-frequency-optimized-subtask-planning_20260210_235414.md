---
ver: rpa2
title: 'CHOP: Mobile Operating Assistant with Constrained High-frequency Optimized
  Subtask Planning'
arxiv_id: '2503.03743'
source_url: https://arxiv.org/abs/2503.03743
tags:
- task
- subtasks
- agent
- action
- basis
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "CHOP addresses challenges in mobile operating assistants caused\
  \ by ineffective and inefficient subtasks generated by visual language models (VLMs).\
  \ It introduces basis subtasks\u2014high-frequency, human-curated operational steps\u2014\
  to guide task decomposition, ensuring generated subtasks are executable and on the\
  \ critical path to task completion."
---

# CHOP: Mobile Operating Assistant with Constrained High-frequency Optimized Subtask Planning

## Quick Facts
- **arXiv ID:** 2503.03743
- **Source URL:** https://arxiv.org/abs/2503.03743
- **Reference count:** 39
- **Primary result:** Introduces basis subtasks—high-frequency, human-curated operational steps—to guide task decomposition, achieving state-of-the-art success rates (SR: 0.67–1.00) and efficiency (ME: 1.10–1.36) in mobile task execution.

## Executive Summary
CHOP addresses challenges in mobile operating assistants caused by ineffective and inefficient subtasks generated by visual language models (VLMs). It introduces basis subtasks—high-frequency, human-curated operational steps—to guide task decomposition, ensuring generated subtasks are executable and on the critical path to task completion. These basis subtasks are extracted via verb extraction, synonym clustering, summarization, and frequency filtering. The CHOP architecture integrates them into a multi-agent system with a plan agent (using basis subtasks as constraints) and an action agent (executing actions with standardized workflows). Evaluated on English and Chinese datasets across 20 apps, CHOP achieves state-of-the-art success rates (SR: 0.67–1.00) and efficiency (ME: 1.10–1.36, AAC: 0.76–0.95), outperforming baselines like Mobile Agent(v2) and AppAgent. It also improves subtask quality, with higher BLEU (0.83) and ROUGE-L (0.81) scores versus ablations, and reduces errors like hallucinations (0.0%) and task context misinterpretation (45.5%). CHOP’s structured approach enables reliable, efficient task execution while maintaining generalizability to unseen apps.

## Method Summary
CHOP uses a two-stage pipeline: first, basis subtasks are extracted from the AITZ dataset using verb extraction (spaCy POS tagging), synonym clustering (WordNet), summarization (GPT-4), and frequency filtering (top 10). Second, a multi-agent system executes tasks: the Plan Agent decomposes user instructions into sequences of basis subtasks, while the Action Agent executes each subtask using standardized documentation and Aria-UI for coordinate grounding. The system is evaluated on CHOP-En (30 English instructions, 10 apps) and CHOP-ZH (200 Chinese instructions, 10 apps) datasets, measuring success rate, completion rate, efficiency, and subtask quality.

## Key Results
- **Success rates:** CHOP achieves SR: 0.67–1.00 across 20 apps, outperforming baselines (Mobile Agent(v2): SR: 0.57, AppAgent: SR: 0.60).
- **Efficiency:** CHOP demonstrates superior efficiency (ME: 1.10–1.36) compared to baselines, attributed to batched action generation for fixed workflows.
- **Subtask quality:** CHOP improves subtask quality, with higher BLEU (0.83) and ROUGE-L (0.81) scores versus ablations, and reduces errors like hallucinations (0.0%) and task context misinterpretation (45.5%).

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Constraining the VLM’s planning output to a fixed set of human-curated "basis subtasks" appears to reduce hallucinations and ensure executable plans.
- **Mechanism:** The architecture restricts the Plan Agent to selecting from a predefined list ($Q_{basis}$) of high-frequency subtasks (e.g., "Search Item", "Share Content"). This forces the decomposition into proven operational primitives rather than open-ended natural language reasoning.
- **Core assumption:** This assumes that most mobile tasks can be decomposed into a finite, static set of reusable "basis" operations that transfer across different apps (e.g., searching in YouTube is structurally identical to searching in Spotify).
- **Evidence anchors:**
  - [abstract] "introduces basis subtasks... to guide task decomposition, ensuring generated subtasks are executable and on the critical path."
  - [section 3.2] "We rank them based on their frequency in the dataset and retain the top 10... filtering process ensures that the selected high-frequency basis subtasks are better able to generalize."
  - [corpus] *Conditional Diffusion Model for Multi-Agent* suggests dynamic task decomposition is valuable in complex environments, supporting the need for structured breakdown, though CHOP relies on static frequency analysis rather than dynamic generation.
- **Break condition:** Fails when a user request requires a novel operation not represented in the top-$N$ basis subtasks (e.g., a specific multi-step workflow unique to one app).

### Mechanism 2
- **Claim:** Injecting standardized documentation (workflows) for each subtask improves the Action Agent's execution efficiency and grounding accuracy.
- **Mechanism:** When the Plan Agent selects a subtask (e.g., "Search"), it triggers a "Documentation" prompt ($d_i$) that details the standard steps and boundary conditions. The Action Agent uses this context to generate precise actions, effectively utilizing a Retrieval-Augmented Generation (RAG) approach for procedural knowledge.
- **Core assumption:** Assumes that UI flows are consistent enough across apps that a single text description (e.g., "Click search bar, type query, press enter") provides sufficient signal for the VLM to ground actions correctly in specific screenshots.
- **Evidence anchors:**
  - [section 3.3] "To guide the execution... the agent generates observation, thought, and summarization... di provides standardized execution steps."
  - [table 3] Ablation study shows a performance drop when documentation ($D_{basis}$) is removed (SR drops from 0.67 to 0.47).
- **Break condition:** Breaks if the target app violates the "standard" UI logic described in the documentation (e.g., a search interface that requires voice input instead of typing).

### Mechanism 3
- **Claim:** Batching multiple low-level actions into a single VLM call for fixed workflows reduces latency and token cost.
- **Mechanism:** For fixed-flow basis subtasks (like "Search"), the Action Agent is prompted to generate the full sequence of actions (Click, Type, Enter) in one forward pass, rather than iterating one step at a time.
- **Core assumption:** Assumes the environment state will not change unpredictably during the execution of the batched sequence, invalidating the "open-loop" plan.
- **Evidence anchors:**
  - [section 3.3] "For basis subtasks with fixed workflows... the agent generates the full action sequence in one step, minimizing latency."
  - [table 2] CHOP demonstrates superior efficiency (ME: 1.10–1.36) compared to baselines, attributed to this batching strategy.
- **Break condition:** Fails if an intermediate step produces an error (e.g., network lag preventing the search bar from appearing), as the subsequent pre-generated actions will likely miss their targets.

## Foundational Learning

- **Concept: Hierarchical Task Decomposition**
  - **Why needed here:** CHOP relies on a strict separation between a "Plan Agent" (High-level) and "Action Agent" (Low-level). You must understand how to define the granularity of a "subtask" vs. an "action."
  - **Quick check question:** If the user asks "Send an email to Bob," is "Click the send button" a subtask or an action?

- **Concept: Constrained Decoding / Constrained Generation**
  - **Why needed here:** The core innovation is forcing the LLM to output only specific tokens or structures (the basis subtasks) rather than free text.
  - **Quick check question:** How does limiting the output vocabulary reduce hallucination risks?

- **Concept: Visual Grounding**
  - **Why needed here:** The Action Agent outputs text commands (e.g., "CLICK(Search Bar)"), but the phone needs coordinates. Understanding the decoupling between the decision (VLM) and the grounding (Aria-UI) is critical.
  - **Quick check question:** Does the VLM in CHOP directly output pixel coordinates, or does it rely on a separate model for that translation?

## Architecture Onboarding

- **Component map:**
  - **Plan Agent (GPT-4o):** Receives user instruction; selects sequence of *Basis Subtasks*.
  - **Action Agent (GPT-4o):** Receives subtask + screenshot + *Documentation*; outputs action sequence.
  - **Grounding Model (Aria-UI):** Maps text actions (e.g., "Click Search") to screen coordinates.
  - **Basis Subtask Database:** Static list of top-10 subtasks + standardized documentation (generated via Verb Extraction/Clustering).

- **Critical path:**
  1. User Instruction enters **Plan Agent**.
  2. Plan Agent decomposes task into sequence from **Basis Subtask Database**.
  3. First Subtask + Documentation passed to **Action Agent**.
  4. Action Agent generates batched actions -> **Grounding Model**.
  5. Actions executed in Android Environment.

- **Design tradeoffs:**
  - **Static vs. Dynamic Basis:** The paper uses a static top-10 list from the AITZ dataset. This improves reliability but limits flexibility for unseen task types.
  - **Batching vs. Reactivity:** Generating actions in one pass improves speed (Efficiency) but reduces the ability to react to dynamic screen changes (Robustness).

- **Failure signatures:**
  - **High "Poor Graphical Recognition":** Table 4 shows 54.6% of CHOP's errors are graphical recognition failures, suggesting the Action Agent or Grounding model struggles with specific UI elements despite the plan.
  - **Misinterpretation:** 45.5% error rate implies the Plan Agent still occasionally selects the wrong basis subtask or misses context.

- **First 3 experiments:**
  1. **Basis Ablation:** Run CHOP without the "Frequency Filtering" step to see if including rare subtasks hurts or helps specific edge cases.
  2. **Out-of-Domain Test:** Test the *Search* basis subtask on an app not included in the training corpus to verify the "common operational logic" assumption.
  3. **Step-by-Step vs. Batched:** Force the Action Agent to output one step at a time instead of batching to measure the exact efficiency/accuracy trade-off.

## Open Questions the Paper Calls Out
None

## Limitations
- **Static basis subtask set:** The paper relies on a fixed top-10 basis subtask list extracted from the AITZ dataset, limiting flexibility for novel task types and potentially struggling with unique workflows.
- **Grounding accuracy:** While CHOP uses Aria-UI for coordinate mapping, the paper doesn't provide detailed evaluation of grounding failures, with graphical recognition errors accounting for 54.6% of failures.
- **Documentation quality:** The effectiveness depends heavily on the quality of the standardized documentation for each basis subtask, but specific details of these documentation prompts are not fully provided in the paper.

## Confidence
- **High:** Success rate improvements (SR: 0.67-1.00) and efficiency gains (ME: 1.10-1.36) versus baselines are well-supported by ablation studies and comparative experiments.
- **Medium:** The core hypothesis that constraining VLMs to basis subtasks reduces hallucinations is supported by error analysis showing zero hallucination errors in CHOP.
- **Low:** Generalization claims to unseen apps are based on limited testing and the static basis set may struggle with truly novel interfaces.

## Next Checks
1. **Basis subtask coverage analysis:** Systematically test CHOP on apps requiring subtasks outside the top-10 basis list to quantify the limitation of the static approach.
2. **Grounding error isolation:** Conduct controlled experiments where the plan agent's output is manually verified to isolate whether failures stem from the VLM's action generation versus the Aria-UI grounding component.
3. **Dynamic basis adaptation:** Implement a version of CHOP that can expand its basis subtask set during execution and compare performance to the static version on edge-case tasks.