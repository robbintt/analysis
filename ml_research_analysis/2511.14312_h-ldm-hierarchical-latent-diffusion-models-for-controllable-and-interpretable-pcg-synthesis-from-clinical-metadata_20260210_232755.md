---
ver: rpa2
title: 'H-LDM: Hierarchical Latent Diffusion Models for Controllable and Interpretable
  PCG Synthesis from Clinical Metadata'
arxiv_id: '2511.14312'
source_url: https://arxiv.org/abs/2511.14312
tags:
- clinical
- latent
- diffusion
- medical
- hierarchical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: H-LDM introduces a hierarchical latent diffusion framework to address
  data scarcity in phonocardiogram (PCG) synthesis for cardiovascular disease diagnosis.
  The core method features a physiologically-disentangled latent space via multi-scale
  VAE, hierarchical text-to-biosignal encoding using clinical metadata, and an interpretable
  diffusion process guided by a Medical Attention module.
---

# H-LDM: Hierarchical Latent Diffusion Models for Controllable and Interpretable PCG Synthesis from Clinical Metadata

## Quick Facts
- arXiv ID: 2511.14312
- Source URL: https://arxiv.org/abs/2511.14312
- Reference count: 23
- Primary result: Achieves state-of-the-art PCG synthesis with 9.7 FAD, 92% attribute disentanglement, and 87.1% clinical validity confirmed by cardiologists

## Executive Summary
H-LDM introduces a hierarchical latent diffusion framework to address data scarcity in phonocardiogram (PCG) synthesis for cardiovascular disease diagnosis. The core method features a physiologically-disentangled latent space via multi-scale VAE, hierarchical text-to-biosignal encoding using clinical metadata, and an interpretable diffusion process guided by a Medical Attention module. On the PhysioNet CirCor dataset, H-LDM achieves state-of-the-art performance with a Fréchet Audio Distance of 9.7, 92% attribute disentanglement, and 87.1% clinical validity confirmed by cardiologists. Models trained with the synthetic data show 11.3% improvement in rare disease classification accuracy.

## Method Summary
H-LDM employs a two-stage approach: first, a multi-scale VAE learns a physiologically-disentangled latent representation of PCG signals, separating rhythm, heart sounds, murmurs, and noise into orthogonal subspaces. Second, a conditional latent diffusion model generates PCG spectrograms from rich clinical metadata, using hierarchical conditioning via fine-tuned BERT and GraphSAGE embeddings fused through learned weights. The diffusion U-Net incorporates Medical Attention (learnable sparse attention masks) and structured noise prediction to ensure physiological periodicity and clinically-relevant feature synthesis.

## Key Results
- Achieves Fréchet Audio Distance of 9.7 on PhysioNet CirCor dataset
- Demonstrates 92% attribute disentanglement with stable heart sounds while varying murmurs
- Shows 11.3% improvement in rare disease classification accuracy when training with synthetic data
- Earns 87.1% clinical validity rating from cardiologist reviewers

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Structuring the latent space into physiologically-meaningful orthogonal subspaces enables interpretable, controllable synthesis.
- Mechanism: The Multi-Scale VAE partitions the latent vector z into discrete subspaces (z_rhythm, z_S1/S2, z_murmur, z_noise). A disentanglement loss L_disentangle combines (1) a correlation penalty between subspaces and (2) auxiliary classification losses via pre-trained detectors (e.g., murmur detector on z_murmur). This forces each subspace to encode only its designated physiological information.
- Core assumption: Cardiac acoustic features are sufficiently independent to occupy orthogonal subspaces; pathological variations can be isolated without destroying signal coherence.
- Evidence anchors:
  - [abstract] "multi-scale VAE that learns a physiologically-disentangled latent space, separating rhythm, heart sounds, and murmurs"
  - [section III.B] "z = [z_rhythm ⊕ z_S1/S2 ⊕ z_murmur ⊕ z_noise]... L_disentangle consists of... correlation penalty... auxiliary classification loss"
  - [corpus] Related work on structured latents exists (ConDA, FAR-TS) but does not address PCG-specific disentanglement; direct corpus evidence for this mechanism is weak.
- Break condition: If auxiliary classifiers fail to converge on specific subspaces, or if cross-correlation penalties cannot approach zero, disentanglement collapses into entangled representations.

### Mechanism 2
- Claim: Hierarchical conditioning on rich clinical metadata (not sparse labels) yields fine-grained control over 17 distinct pathologies.
- Mechanism: Clinical text is structured into 3 levels (L1: demographics, L2: murmur attributes, L3: differential diagnosis). A medically fine-tuned BERT encodes text; GraphSAGE processes patient-specific subgraphs from a cardiac knowledge graph. These embeddings are fused via learned weights λ_1, λ_2 and injected into the diffusion U-Net via affine transformations in each ResBlock.
- Core assumption: Structured clinical narratives contain sufficient signal to disambiguate overlapping pathologies; the knowledge graph captures medically-relevant relationships.
- Evidence anchors:
  - [abstract] "hierarchical text-to-biosignal pipeline that leverages rich clinical metadata for fine-grained control over 17 distinct conditions"
  - [section III.A] "c = λ_1 · f_BERT(T_medical) + λ_2 · g_GNN(G_patient)... multi-level text descriptions for each recording"
  - [corpus] CLARITY and patient-specific disease dynamics papers similarly leverage latent-space trajectory modeling but for imaging; corpus does not directly validate text-to-PCG conditioning.
- Break condition: If BERT embeddings fail to capture murmur-grade distinctions, or if GraphSAGE provides no discriminative signal beyond demographics, conditioning collapses to label-equivalent.

### Mechanism 3
- Claim: Medical Attention enforces physiological periodicity; structured noise prediction allocates denoising capacity to relevant clinical attributes.
- Mechanism: Medical Attention replaces standard self-attention with a learnable sparse mask M_cardiac added to attention scores, suppressing implausible temporal relationships. Structured noise prediction decomposes the noise estimate into subspace-specific components weighted by w_i(c), allowing the model to dynamically focus denoising on clinically-relevant features.
- Core assumption: Cardiac periodicity can be encoded as a learnable attention mask; different pathologies require different noise-prediction weightings.
- Evidence anchors:
  - [abstract] "interpretable diffusion process guided by a novel Medical Attention module"
  - [section III.C] "MedAttn(Q,K,V) = softmax((QK^T)/√d_k + M_cardiac)V... ĝ_θ(z_t, c, t) = Σ w_i(c)·ε_θ^(i)(z_t, c, t)"
  - [corpus] No direct corpus validation for Medical Attention in biosignal diffusion; mechanism remains domain-specific innovation.
- Break condition: If M_cardiac does not converge to physiologically-meaningful patterns, or if w_i(c) weights remain uniform across conditions, interpretability gains are illusory.

## Foundational Learning

- Concept: Variational Autoencoders (VAEs) with KL divergence and reconstruction loss
  - Why needed here: The MS-VAE is the foundation; understanding how β-VAEs trade off reconstruction vs. disentanglement is essential for tuning L_VAE_total.
  - Quick check question: Can you explain why increasing β in β-VAE improves disentanglement but may hurt reconstruction fidelity?

- Concept: Denoising Diffusion Probabilistic Models (DDPMs) and latent diffusion
  - Why needed here: The conditional LDM operates in VAE latent space; understanding forward/reverse processes and noise scheduling is prerequisite.
  - Quick check question: What is the computational advantage of running diffusion in latent space vs. raw signal space?

- Concept: Attention mechanisms and learnable positional/structural masks
  - Why needed here: Medical Attention modifies standard self-attention with M_cardiac; you must understand how additive masks bias attention distributions.
  - Quick check question: How does adding a learnable mask M to attention scores differ from modifying the query/key projections?

## Architecture Onboarding

- Component map:
  - Clinical text → BERT encoder; Patient graph → GraphSAGE; Fusion → conditioning embedding c
  - PCG spectrogram → Encoder E → z (disentangled) → Decoder D → reconstruction
  - Latent z_0 → forward noise to z_t → U-Net (with Medical Attention, Adaptive Condition ResBlocks, Structured Noise Prediction) → predicted noise → reverse to ẑ_0 → decode to spectrogram

- Critical path: VAE pretraining with L_disentangle → freeze VAE → train diffusion U-Net with coarse-to-fine curriculum → clinical fine-tuning on rare pathologies. If VAE disentanglement fails (PDS < 0.5), downstream control is unreliable.

- Design tradeoffs:
  - Higher δ (disentanglement weight) improves PDS but may increase FAD; ablation shows removing disentanglement drops PDS from 0.92 to 0.45 while FAD stays ~10.
  - Medical Attention adds ~28% PDS gain but increases attention computation via mask learning.
  - 3-stage training is slower but essential for hierarchical control; single-stage training collapses CF.

- Failure signatures:
  - High FAD (>15) + low PDS (<0.5): VAE failed to disentangle; check auxiliary classifier accuracy and correlation penalties.
  - Low CF (<0.75) + high FAD: Conditioning injection failed; check BERT/GraphSAGE fusion weights and condition dropout rate.
  - Plausible FAD but low clinical validity (CV <0.70): Generated signals are acoustically realistic but physiologically implausible; check Medical Attention mask convergence.

- First 3 experiments:
  1. **VAE ablation**: Train MS-VAE with δ=0 vs. δ=0.1; measure PDS and reconstruction MAE. Confirm disentanglement does not destroy fidelity.
  2. **Conditioning sanity check**: Generate samples with single-attribute prompts (e.g., "grade II murmur" vs. "grade IV murmur"); verify acoustic intensity changes while rhythm/S1-S2 remain stable via PDS.
  3. **Medical Attention probe**: Visualize learned M_cardiac mask; check if it encodes cardiac cycle periodicity (~0.8-1.2s windows). Compare CF/PDS against standard self-attention baseline.

## Open Questions the Paper Calls Out
None

## Limitations
- Clinical validation relies on expert consensus (87.1% CV) rather than objective clinical outcomes
- 11.3% improvement in rare disease classification measured only on PhysioNet CirCor dataset without external validation
- Medical Attention mechanism lacks ablation evidence showing whether learned masks capture physiologically-meaningful cardiac periodicity patterns

## Confidence

- **High confidence**: Core architecture design (VAE + diffusion framework), quantitative metrics (FAD, PDS, CF) on the primary dataset, ablation studies showing component contributions
- **Medium confidence**: Clinical validity scores from cardiologist reviewers, classification improvement claims (requires external validation), Medical Attention interpretability claims (limited ablation evidence)
- **Low confidence**: Generalization to other cardiac auscultation contexts, robustness to different clinical documentation styles, scalability to non-PCG biosignals

## Next Checks
1. **External clinical validation**: Test the H-LDM-generated dataset on an independent PCG dataset with different acquisition protocols to verify the 11.3% classification improvement generalizes beyond PhysioNet CirCor.

2. **Medical Attention interpretability**: Visualize and analyze the learned M_cardiac attention masks across multiple conditions to verify they encode actual cardiac cycle periodicity (0.8-1.2s windows) rather than spurious patterns.

3. **Disentanglement robustness**: Conduct cross-pathology testing by generating samples with rare condition combinations (e.g., severe murmur + arrhythmia) and measure whether PDS remains above 0.8 or collapses due to feature entanglement.