---
ver: rpa2
title: 'Beyond the Final Layer: Intermediate Representations for Better Multilingual
  Calibration in Large Language Models'
arxiv_id: '2510.03136'
source_url: https://arxiv.org/abs/2510.03136
tags:
- calibration
- confidence
- layer
- language
- languages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the problem of poor confidence calibration\
  \ in large language models for non-English languages. It shows that multilingual\
  \ models suffer from systematic miscalibration, with non-English languages exhibiting\
  \ dramatically higher expected calibration error (ECE) than English\u2014e.g., LLaMA-3\u2019\
  s average ECE is 23.1% for non-English vs."
---

# Beyond the Final Layer: Intermediate Representations for Better Multilingual Calibration in Large Language Models

## Quick Facts
- **arXiv ID:** 2510.03136
- **Source URL:** https://arxiv.org/abs/2510.03136
- **Reference count:** 40
- **Primary result:** Intermediate transformer layers provide better-calibrated confidence estimates than the final layer for non-English languages, with LACE achieving ECE as low as 3.09% on LLaMA-3

## Executive Summary
This paper addresses the critical problem of poor confidence calibration in large language models for non-English languages. Through extensive experiments across six model families and over 100 languages, the authors demonstrate that multilingual models exhibit systematically worse calibration for non-English languages, with average expected calibration error (ECE) of 23.1% compared to 4.6% for English in LLaMA-3. The key insight is that the final layer, biased by English-centric training, provides suboptimal calibration signals for non-English languages. Instead, late-intermediate layers consistently yield better-calibrated confidence estimates. Building on this finding, the paper introduces training-free calibration methods that leverage intermediate representations, with the Language-Aware Confidence Ensemble (LACE) achieving state-of-the-art results by adaptively selecting optimal layers for each language.

## Method Summary
The paper proposes extracting confidence scores from intermediate transformer layers rather than relying solely on the final layer's output. For each layer ℓ, the method applies the language modeling head to the hidden state hℓ to generate logits zℓ = Whℓ, computes probabilities pℓ = softmax(zℓ), and traces the final prediction ŷL back through layers to extract Confℓ(x) = [pℓ]ŷL. Three calibration methods are introduced: (1) Best Layer - selects the single layer minimizing average ECE, (2) Good Layers Ensemble - averages probabilities from layers beating the final layer's ECE, and (3) LACE - per-language layer selection combined with language-specific post-hoc calibrators. The methods are evaluated on multilingual MCQA benchmarks (MMMLU with 15 languages and Belebele with 122 languages) using eight-shot prompting and various post-hoc calibrators like Temperature Scaling and Isotonic Regression.

## Key Results
- Multilingual models exhibit systematically worse calibration for non-English languages, with LLaMA-3 showing 23.1% average ECE vs 4.6% for English
- Late-intermediate layers (around layer 29 in LLaMA-3) consistently provide better calibration signals than the final layer for non-English languages
- LACE achieves the best results with ECE as low as 3.09% on LLaMA-3 and 3.45% on Aya, outperforming classical post-hoc calibration methods
- The calibration improvements are complementary to existing post-hoc calibration techniques and generalize across multiple model families

## Why This Works (Mechanism)
The effectiveness of intermediate layers stems from the transformer's hierarchical processing. Early layers capture local, language-specific patterns, while deeper layers increasingly abstract and align representations across languages. The final layer becomes biased toward English due to training data imbalance, but late-intermediate layers retain language-specific information while having progressed toward more universal representations. This sweet spot provides confidence estimates that are both linguistically grounded and more universally calibrated. The LACE method further enhances this by adapting the layer selection and calibration parameters to each language's specific characteristics, addressing the distributional heterogeneity across languages.

## Foundational Learning
- **Expected Calibration Error (ECE):** A metric measuring the discrepancy between predicted confidence and actual accuracy. Why needed: Primary evaluation metric for quantifying calibration quality. Quick check: ECE should decrease when confidence better matches accuracy.
- **Layer-wise Probability Extraction:** The process of applying the LM head to intermediate hidden states to generate layer-specific probabilities. Why needed: Enables access to confidence estimates from different representation levels. Quick check: Each layer's probability distribution should sum to 1 over vocabulary.
- **Post-hoc Calibration:** Techniques like Temperature Scaling that adjust model outputs without modifying the model itself. Why needed: Allows calibration improvements without retraining. Quick check: Calibrated confidence should track actual accuracy more closely.
- **Language-Aware Calibration:** The concept of adapting calibration parameters to individual languages rather than using global parameters. Why needed: Addresses distributional differences across languages. Quick check: Per-language calibration should outperform global calibration on individual languages.
- **Early Decoding:** The practice of extracting predictions from intermediate layers during the forward pass. Why needed: Enables layer-wise confidence extraction without architectural changes. Quick check: Early decoding should produce valid probability distributions for each layer.

## Architecture Onboarding

- **Component map:**
  Input -> LLM -> Layer-wise Logit Extractor -> Layer Selector -> Ensembler -> Language-Aware Calibrator (LACE) -> Calibrated Confidence

- **Critical path:**
  1. Forward Pass: Run input through LLM to generate hidden states for all layers
  2. Early Decoding: Apply LM head to each layer to generate logits and convert to probabilities
  3. Layer Identification (Offline): Compute ECE for each layer on validation set to identify optimal layer sets
  4. Ensembling: At inference, select pre-determined "good" layers for input language and average their probabilities
  5. Calibration: Apply pre-fitted, language-specific calibrator to ensembled probability

- **Design tradeoffs:**
  - Single "Best Layer" vs. "Good Layers" Ensemble: Simpler and faster vs. more robust but computationally heavier
  - Global vs. Language-Specific Selection: Optimizes average performance vs. better per-language results with increased complexity
  - Temperature Scaling vs. Isotonic Regression: Simpler with ranking preservation vs. more flexible but data-sensitive

- **Failure signatures:**
  - High ECE for non-English languages when using standard final-layer confidence
  - English calibration degradation when using single intermediate layer
  - Performance degradation from misidentified language in LACE method

- **First 3 experiments:**
  1. Layer-wise Calibration Scan: Plot ECE vs. layer index for English and non-English languages to verify monotonic improvement patterns
  2. "Best Layer" Ablation: Compare final layer calibration to best intermediate layer for high-resource (German) and low-resource (Swahili) non-English languages
  3. LACE Implementation: Select "good" layers on validation set for few languages, average predictions, and apply Temperature Scaling calibrator

## Open Questions the Paper Calls Out
- **Task Generalization:** Do the calibration benefits transfer to open-ended generative tasks like summarization or dialogue? The current focus on MCQA may not directly extend to tasks without discrete ground truth tokens.
- **Model Scale Effects:** How does the optimal layer shift as model scale increases beyond 8B parameters? Larger models may exhibit different internal dynamics due to deeper architectures.
- **Training Integration:** Can multilingual calibration be improved by directly optimizing layer-wise representations during training rather than post-hoc? The current approach adjusts outputs after training; integrating calibration objectives into training is a compelling direction.

## Limitations
- Experimental scope limited to multiple-choice question answering tasks with eight-shot prompting, with uncertain efficacy for open-ended generation
- Focus on decoder-only transformer architectures, leaving questions about applicability to encoder-decoder models
- Calibration improvements measured on curated, human-annotated datasets; performance on noisy, web-scale data unexplored

## Confidence
- **Layer Bias Claim:** High confidence - Robust empirical demonstration across multiple model families and datasets
- **Intermediate Layer Advantage:** High confidence - Well-supported by layer-wise ECE analysis
- **LACE Effectiveness:** Medium confidence - Shows strong results but performance advantage over simpler methods is less dramatic

## Next Checks
1. Apply proposed calibration methods to open-ended generation tasks (story completion, summarization) and compare calibration performance against MCQA baselines
2. Implement intermediate layer extraction approach on an encoder-decoder model (mT0, BLOOMZ) to evaluate layer-wise calibration patterns
3. Evaluate calibration stability and degradation over long generation sequences (1000+ tokens) to assess effectiveness in extended contexts