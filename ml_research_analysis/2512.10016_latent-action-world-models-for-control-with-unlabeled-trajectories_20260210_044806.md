---
ver: rpa2
title: Latent Action World Models for Control with Unlabeled Trajectories
arxiv_id: '2512.10016'
source_url: https://arxiv.org/abs/2512.10016
tags:
- latent
- action
- learning
- action-free
- world
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Latent Action World Models (LAWM), a method
  that learns from heterogeneous datasets containing both action-labeled and action-free
  trajectories. The core idea is to learn a shared latent action representation that
  aligns observed control signals with actions inferred from passive observations.
---

# Latent Action World Models for Control with Unlabeled Trajectories

## Quick Facts
- arXiv ID: 2512.10016
- Source URL: https://arxiv.org/abs/2512.10016
- Reference count: 12
- One-line primary result: LAWM significantly outperforms state-of-the-art baselines while using about an order of magnitude fewer action-labeled samples on DeepMind Control Suite tasks

## Executive Summary
This paper introduces Latent Action World Models (LAWM), a method that learns from heterogeneous datasets containing both action-labeled and action-free trajectories. The core innovation is learning a shared latent action representation that aligns observed control signals with actions inferred from passive observations. This enables a single dynamics model to train on large-scale unlabeled trajectories while requiring only a small set of action-labeled ones. LAWM achieves this by introducing action-conditioned and action-free latent action world model variants that share the same generative model but differ in their latent action inference mechanisms.

The method demonstrates that explicit modeling of system dynamics is crucial for effectively using action-free data, achieving stronger performance than purely action-conditioned baselines and TD3+BC with inverse dynamics models. When evaluated on DeepMind Control Suite tasks (cheetah-run, walker-walk, hopper-stand), LAWM significantly outperforms state-of-the-art baselines while using about an order of magnitude fewer action-labeled samples.

## Method Summary
LAWM learns a shared latent action representation across action-labeled and action-free trajectories through a dual-variant architecture. The action-conditioned variant infers latent actions from observed actions, while the action-free variant uses future observations as a weak supervisory signal through inverse dynamics modeling. Both variants share the same generative model but employ different latent action inference mechanisms. The method introduces latent action world models that can effectively utilize unlabeled trajectories to improve sample efficiency, demonstrating that explicit dynamics modeling is crucial for leveraging action-free data.

## Key Results
- LAWM significantly outperforms state-of-the-art baselines while using about an order of magnitude fewer action-labeled samples
- Achieves stronger performance than purely action-conditioned baselines and TD3+BC with inverse dynamics models
- Demonstrates effectiveness on DeepMind Control Suite tasks (cheetah-run, walker-walk, hopper-stand)

## Why This Works (Mechanism)
The key insight is that unlabeled trajectories contain valuable information about system dynamics that can be leveraged through a shared generative model. By learning a latent action representation that can be inferred both from observed actions and from future observations, LAWM effectively bridges the gap between labeled and unlabeled data. The dual inference mechanisms allow the model to extract supervisory signals from action-free trajectories while maintaining consistency with action-labeled data.

## Foundational Learning
- Latent space modeling: Why needed - Enables compact representation of complex state-action relationships; Quick check - Verify latent space preserves task-relevant information through reconstruction quality
- Inverse dynamics modeling: Why needed - Provides weak supervision from action-free trajectories; Quick check - Measure accuracy of action prediction from state transitions
- Shared generative models: Why needed - Ensures consistency across different data types; Quick check - Validate that both variants produce similar state predictions
- Latent action inference: Why needed - Enables learning from both labeled and unlabeled data; Quick check - Test latent action reconstruction from observed actions

## Architecture Onboarding

Component Map:
Action-conditioned LAWM -> Shared Generative Model <- Action-free LAWM
                  \_____________________/
                            |
                        Dynamics Model

Critical Path:
Observed state and action -> Latent action inference -> State prediction -> Reward prediction

Design Tradeoffs:
- Shared generative model vs. separate models: Shared model ensures consistency but may limit specialization
- Dual inference mechanisms: Increases robustness but adds complexity
- Latent action representation: Balances expressiveness with computational efficiency

Failure Signatures:
- Poor performance on action-free variants indicates insufficient supervisory signal
- Inconsistent predictions between variants suggest shared model issues
- Latent action reconstruction failure points to representation problems

First Experiments:
1. Test latent action reconstruction from observed actions on action-labeled data
2. Evaluate state prediction accuracy for both variants independently
3. Measure consistency between action-conditioned and action-free predictions

## Open Questions the Paper Calls Out
None provided in the input.

## Limitations
- Generalizability across diverse robotic systems and task complexities remains uncertain
- Ablation studies isolating contributions of shared generative model versus specific inference mechanisms are lacking
- Computational overhead of maintaining both variants is not quantified
- Results are limited to relatively low-dimensional, well-structured DeepMind Control Suite environments

## Confidence
- High confidence: LAWM can effectively utilize unlabeled trajectories to improve sample efficiency, as demonstrated through statistically significant performance gains
- Medium confidence: Explicit dynamics modeling is crucial for leveraging action-free data, though more ablation studies would strengthen this claim

## Next Checks
1. Evaluate LAWM on high-dimensional, visually-rich robotic manipulation tasks from platforms like Meta-World or RLBench
2. Conduct ablation studies varying the ratio of action-labeled to action-free data to quantify marginal benefits
3. Measure computational overhead and training time compared to baselines for practical deployment assessment