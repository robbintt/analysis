---
ver: rpa2
title: 'HTMformer: Hybrid Time and Multivariate Transformer for Time Series Forecasting'
arxiv_id: '2510.07084'
source_url: https://arxiv.org/abs/2510.07084
tags:
- multivariate
- temporal
- htme
- features
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes HTMformer, a hybrid transformer-based framework
  for time series forecasting that enhances sequence modeling by integrating temporal
  and multivariate features. Unlike existing transformers that overemphasize temporal
  dependencies and neglect multivariate correlations, HTMformer introduces a novel
  Hybrid Temporal and Multivariate Embeddings (HTME) strategy.
---

# HTMformer: Hybrid Time and Multivariate Transformer for Time Series Forecasting

## Quick Facts
- **arXiv ID:** 2510.07084
- **Source URL:** https://arxiv.org/abs/2510.07084
- **Reference count:** 40
- **Primary result:** HTMformer achieves up to 60.8% improvement in MSE and 51.3% in MAE over state-of-the-art baselines.

## Executive Summary
HTMformer is a hybrid transformer-based framework for multivariate time series forecasting that addresses the limitations of existing models that overemphasize temporal dependencies while neglecting multivariate correlations. The key innovation is the Hybrid Temporal and Multivariate Embeddings (HTME) strategy, which uses parallel, specialized feature extraction modules to separately capture temporal and multivariate features, then combines them through a weighted summation. This approach minimizes noise and computational overhead while enabling the model to better capture complex time series patterns. Extensive experiments on eight real-world datasets demonstrate consistent improvements in both accuracy and efficiency.

## Method Summary
HTMformer introduces a novel HTME extractor that processes temporal and multivariate features in parallel, specialized modules. The temporal branch uses patching and convolution for short/long-term dependencies, while the multivariate branch uses a lightweight GRU to capture cross-variable correlations. These features are then combined through a learnable weighted summation (parameter α) to produce semantically rich embeddings. The fused embeddings are fed into a standard Transformer encoder (specifically an inverted Transformer that attends over variables) followed by a linear projection head. The model is trained using Adam optimizer with learning rate 0.0001, batch size 32, and early stopping with patience 3.

## Key Results
- Achieves up to 60.8% improvement in MSE and 51.3% in MAE over state-of-the-art baselines
- Consistently outperforms competitors across eight diverse real-world datasets including ECL, Weather, Traffic, ETTh2, Solar, and PEMS series
- Demonstrates strong generalizability when applied to different forecasting architectures
- Maintains efficiency with negligible computational overhead compared to Transformer attention

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Decoupling temporal and multivariate feature extraction minimizes interference between dominant temporal patterns and noisy variable correlations.
- **Mechanism:** HTME uses parallel, specialized modules - temporal branch with patching/convolution and multivariate branch with lightweight GRU - preventing shared feature space problems where noisy multivariate data degrades temporal accuracy.
- **Core assumption:** Temporal dependencies are primary signals while multivariate correlations are supplementary and prone to spurious noise.
- **Evidence anchors:** [Page 2] HTME employs parallel specialized modules to minimize interference; current hybrid strategies lead to degradation due to severe noise interference.

### Mechanism 2
- **Claim:** Projecting multivariate features into temporal feature space enriches embeddings without requiring complex backbone modifications.
- **Mechanism:** HTME processes multivariate features in disjoint space to filter noise, then projects them into temporal dimension, allowing downstream Transformer to ingest multivariate context without changing attention mechanism.
- **Core assumption:** Backbone Transformer is sufficient for sequence modeling if input embeddings are semantically rich enough.
- **Evidence anchors:** [Page 2] HTME projects multivariate features into temporal feature space yielding semantically richer representations; [Page 4, Eq. 8] shows weighted summation combining features.

### Mechanism 3
- **Claim:** "Merge-decompose" strategy prioritizes short-term correlations while retaining long-term context.
- **Mechanism:** Model merges short-term patches to capture immediate context, then uses linear layer to flatten long temporal dimension, mimicking bottom-up fusion followed by top-down decomposition.
- **Core assumption:** Short-term correlations are predominant predictive features in tested domains (Traffic, Electricity).
- **Evidence anchors:** [Page 3] Adopting bottom-up fusion followed by top-down decomposition strategy; [Page 3] multiple convolutional filters capture short-term patterns.

## Foundational Learning

- **Concept: Channel Dependence vs. Independence**
  - **Why needed here:** Understanding this spectrum is required to see why a "hybrid" embedding is proposed, as the paper critiques models that strictly follow Channel Independence or naive Dependence.
  - **Quick check question:** Does the model process all variables on a single timeline (Dependence) or treat them as separate sequences (Independence)?

- **Concept: Patching in Time Series**
  - **Why needed here:** The temporal extractor relies on segmenting time series into patches rather than points, which is prerequisite for understanding the "Merge-Decompose" logic.
  - **Quick check question:** How does aggregating time steps into patches change the inductive bias of the model compared to point-wise inputs?

- **Concept: Embedding Space Projection**
  - **Why needed here:** Understanding projections (Linear/Conv layers mapping data from raw to feature space) is essential to grasp the "disjoint space" argument.
  - **Quick check question:** Why would processing two types of features in the same space introduce noise?

## Architecture Onboarding

- **Component map:** Raw Multivariate Time Series (L × C) -> HTME Extractor (Temporal Branch: Patching → Conv → Linear; Multivariate Branch: Patching → Linear → Conv → GRU → Conv) -> Weighted Sum (α parameter) -> Transformer Encoder (inverted) -> Linear Projection Head

- **Critical path:** The definition of α (fusion weight) and the dimensionality of the GRU in the multivariate branch, as these dictate how much "cross-variable noise" is allowed into the temporal model.

- **Design tradeoffs:**
  - **Accuracy vs. Noise:** Multivariate branch is deliberately kept "lightweight" to prevent overfitting to spurious correlations, sacrificing deep multivariate modeling for robustness.
  - **Efficiency:** HTME adds O(LN) complexity, negligible compared to quadratic attention of Transformers, but adds latency over pure linear models.

- **Failure signatures:**
  - **Performance Collapse:** If MSE improves slightly but MAE degrades, multivariate features may be introducing outliers/noise; check α convergence.
  - **High Variance:** If results fluctuate heavily across seeds, GRU in multivariate branch may be overfitting; reduce kernel sizes.

- **First 3 experiments:**
  1. **Ablation on α:** Fix α to 0 (Temporal only), 0.5, and 1.0 (Multivariate only) to verify hybrid claim on Weather dataset.
  2. **Noise Injection:** Add Gaussian noise to input channels of Traffic dataset. If HTMformer outperforms baseline significantly, "noise confinement" mechanism is validated.
  3. **Dimensionality Stress Test:** Run on PEMS (high dimension) vs. ETTh2 (low dimension). If gains are minimal on low-dimension data, multivariate branch is likely redundant.

## Open Questions the Paper Calls Out

- **Open Question 1:** How can deep learning models jointly model spatiotemporal dependencies more effectively than simply adding multivariate features to the temporal dimension via a weighted summation in the embedding layer?
  - **Basis in paper:** [explicit] Conclusion states that "simply adding multivariate features to the temporal dimension through the embedding layer cannot fully model such a complex pattern" and identifies jointly modeling spatiotemporal dependencies as open problem.
  - **Why unresolved:** The proposed HTME uses linear fusion which may not capture full complexity of interactions between temporal dynamics and multivariate correlations.
  - **What evidence would resolve it:** Theoretical framework or architecture capable of non-linear interaction between two feature spaces demonstrating superior performance on datasets with known complex spatiotemporal physics.

- **Open Question 2:** What are the theoretical bounds on the noise suppression capabilities of separating temporal and multivariate feature spaces (disjoint spaces) versus shared feature spaces?
  - **Basis in paper:** [inferred] Introduction and Methodology argue existing methods suffer from "severe noise interference due to a shared feature space," but paper relies on empirical results rather than formal theoretical noise bounds.
  - **Why unresolved:** While empirically validated, mechanism by which disjoint spaces mathematically guarantee noise confinement without losing critical cross-dimensional interaction signals is not formally derived.
  - **What evidence would resolve it:** Theoretical analysis (e.g., using information theory) quantifying SNR improvement in disjoint spaces compared to shared spaces.

- **Open Question 3:** How does performance of HTME strategy scale when applied to datasets with extremely high dimensionality (>1000 variables) compared to relatively low-dimensional benchmarks used in study?
  - **Basis in paper:** [inferred] Experiments utilize datasets with dimensions 7 to 862. Methodology claims module is "lightweight" with linear complexity O(LN), but empirical validation on "high-dimensional benchmarks such as Traffic" (862 variables) is cited as key success, leaving higher scales unexplored.
  - **Why unresolved:** As dimensionality N increases, multivariate feature extraction module (including GRU and Convolutions) could face optimization challenges or noise amplification not present in tested benchmarks.
  - **What evidence would resolve it:** Benchmark results on high-dimensional datasets (e.g., large-scale sensor networks with thousands of nodes) comparing HTME against channel-independent baselines.

## Limitations

- **Hyperparameter Sensitivity:** Exact patch size (kernel K) and GRU dimensions in multivariate branch are unspecified, potentially significantly impacting performance. Fusion weight α initialization described vaguely without concrete bounds.
- **Scalability and Overhead:** Actual memory and compute impact on extremely high-dimensional datasets (e.g., PEMS with many sensors) is not quantified, limiting efficiency claims in higher dimensions regime.
- **Noise Reduction vs. Information Loss:** "Disjoint space" processing assumes noise is dominant issue. For datasets with high true cross-variable correlation, lightweight GRU and projection might underfit, trading robustness for accuracy.

## Confidence

- **High:** Core mechanism (parallel temporal/multivariate feature extraction + weighted fusion) is clearly described and logically sound. Improvement over baselines in standard metrics (MSE/MAE) is well-supported by reported results.
- **Medium:** Claims about generalizability (performance on 8 diverse datasets) and efficiency (negligible overhead) are supported but depend on sensitive hyperparameters not fully specified.
- **Low:** Claims about performance on very high-dimensional data or strict channel independence cases are extrapolated from experiments and not directly validated.

## Next Checks

1. **Noise Sensitivity Test:** Inject increasing levels of Gaussian noise into input channels of Traffic dataset. Verify that HTMformer's MSE improvement over iTransformer increases with noise level, validating "noise confinement" mechanism.

2. **α Ablation Study:** Train HTMformer with fixed α values (0.0, 0.25, 0.5, 0.75, 1.0) on ECL dataset. Plot MSE vs. α to confirm learned hybrid value outperforms both pure temporal (α=0) and pure multivariate (α=1) variants.

3. **High-Dimensional Stress Test:** Run HTMformer and baseline iTransformer on high-dimensional subset of PEMS (100+ sensors). Measure not only MSE/MAE but also training time and GPU memory usage to empirically validate claimed efficiency.