---
ver: rpa2
title: 'SDS KoPub VDR: A Benchmark Dataset for Visual Document Retrieval in Korean
  Public Documents'
arxiv_id: '2511.04910'
source_url: https://arxiv.org/abs/2511.04910
tags:
- visual
- retrieval
- multimodal
- page
- document
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces SDS KoPub VDR, the first large-scale, public
  benchmark for visual document retrieval (VDR) in Korean public documents. It addresses
  the gap in existing benchmarks by focusing on non-English languages and the structural
  complexity of official publications.
---

# SDS KoPub VDR: A Benchmark Dataset for Visual Document Retrieval in Korean Public Documents

## Quick Facts
- arXiv ID: 2511.04910
- Source URL: https://arxiv.org/abs/2511.04910
- Reference count: 38
- Introduces first large-scale, public benchmark for visual document retrieval in Korean public documents

## Executive Summary
This paper introduces SDS KoPub VDR, a comprehensive benchmark dataset for visual document retrieval (VDR) specifically designed for Korean public documents. The dataset addresses a critical gap in existing benchmarks by focusing on non-English languages and the structural complexity of official publications. Comprising 361 real-world documents spanning 40,781 pages and 600 query-page-answer triples across six domains, the benchmark enables rigorous evaluation of both text-only and multimodal retrieval approaches. The evaluation reveals substantial performance gaps, particularly for cross-modal reasoning tasks, highlighting the challenges of document intelligence in real-world applications.

## Method Summary
The benchmark dataset was constructed by collecting 361 real-world Korean public documents across six domains, totaling 40,781 pages. The team created 600 query-page-answer triples with three distinct query types: text-based, visual-based, and cross-modal. Two complementary tasks were defined: text-only retrieval using text features alone, and multimodal retrieval that leverages both text and visual features. The dataset is publicly available on Hugging Face, enabling broad access for the research community to advance document intelligence capabilities.

## Key Results
- SDS KoPub VDR is the first large-scale, public benchmark for visual document retrieval in Korean public documents
- Substantial performance gaps observed between text-only and multimodal retrieval tasks, especially for cross-modal reasoning
- State-of-the-art models show significant room for improvement in handling the structural complexity of official publications

## Why This Works (Mechanism)
The benchmark's effectiveness stems from its focus on real-world Korean public documents, which present unique challenges in layout, language, and structural complexity. By incorporating three query types and both text-only and multimodal retrieval tasks, the dataset forces models to develop robust cross-modal reasoning capabilities. The use of actual public documents rather than synthetic data ensures that performance gaps reflect real-world challenges rather than dataset artifacts.

## Foundational Learning
- **Visual Document Retrieval (VDR)**: The task of finding relevant document pages based on query information, requiring understanding of both textual and visual document elements
  - Why needed: Essential for document intelligence applications in public administration and enterprise settings
  - Quick check: Can the model retrieve relevant pages given various query types across document domains?

- **Cross-modal Reasoning**: The ability to connect information across different modalities (text and visual features) within documents
  - Why needed: Real documents contain complementary information across text and layout that must be integrated for accurate retrieval
  - Quick check: Does performance drop significantly when moving from unimodal to cross-modal queries?

- **Korean Public Document Characteristics**: Specific layout patterns, language features, and structural elements unique to Korean official publications
  - Why needed: Ensures benchmark relevance for practical applications in Korean public administration
  - Quick check: Are the document domains and layouts representative of actual public document collections?

## Architecture Onboarding
Component map: Query -> Text Encoder -> Visual Encoder -> Fusion Module -> Retrieval Module -> Ranked Pages
Critical path: Query processing → Feature extraction (text/visual) → Cross-modal fusion → Similarity computation → Ranking
Design tradeoffs: Text-only vs. multimodal retrieval (simplicity vs. accuracy), domain specificity vs. generalizability
Failure signatures: Poor cross-modal reasoning, sensitivity to document layout variations, language-specific limitations
First experiments: 1) Text-only retrieval baseline evaluation, 2) Multimodal retrieval with simple fusion, 3) Cross-modal query performance analysis

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- The dataset's coverage may not fully represent the diversity of document layouts, styles, and content complexity in real-world public administration
- Performance gaps could be influenced by the specific document collection rather than reflecting fundamental limitations in current models
- Annotation subjectivity in creating query-page-answer triples, particularly for visual-based and cross-modal queries where interpretation may vary

## Confidence
- Dataset novelty and benchmark utility: High
- Performance analysis validity: Medium
- Practical impact claims: Medium

## Next Checks
1. Expand evaluation to include documents from additional domains and sources to assess generalizability beyond the current collection
2. Conduct human evaluation studies to validate the relevance judgments for visual-based and cross-modal queries, measuring inter-annotator agreement
3. Test model performance on progressively larger document collections to evaluate scalability and identify performance degradation patterns