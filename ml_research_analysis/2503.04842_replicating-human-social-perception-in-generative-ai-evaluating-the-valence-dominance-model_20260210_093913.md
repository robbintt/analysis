---
ver: rpa2
title: 'Replicating Human Social Perception in Generative AI: Evaluating the Valence-Dominance
  Model'
arxiv_id: '2503.04842'
source_url: https://arxiv.org/abs/2503.04842
tags:
- generative
- component
- human
- similar
- equal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether multimodal generative AI models
  can replicate the valence-dominance model of human social perception. Using principal
  component analysis (PCA) on trait ratings from facial images, we found that AI-generated
  dimensions closely mirrored the theoretical valence (trustworthiness) and dominance
  structure observed in humans.
---

# Replicating Human Social Perception in Generative AI: Evaluating the Valence-Dominance Model

## Quick Facts
- arXiv ID: 2503.04842
- Source URL: https://arxiv.org/abs/2503.04842
- Reference count: 5
- Generative AI models replicate human social perception dimensions of valence and dominance with high congruence coefficients

## Executive Summary
This study investigates whether multimodal generative AI models can replicate the valence-dominance model of human social perception. Using principal component analysis (PCA) on trait ratings from facial images, researchers found that AI-generated dimensions closely mirrored the theoretical valence (trustworthiness) and dominance structure observed in humans. Across three state-of-the-art models (Claude 3.5 Sonnet, GPT-4 Turbo, Gemini 1.5 Pro), the first two components replicated human judgments with high congruence coefficients (0.97-0.98 for valence, 0.65-0.79 for dominance). A third component was also identified in most models and world regions, though its interpretation remains unclear. These findings demonstrate that generative AI systems can replicate fundamental aspects of human social perception, with implications for AI-driven decision-making and understanding potential biases in machine-generated representations.

## Method Summary
The study employed principal component analysis on trait ratings of facial images generated by three state-of-the-art multimodal AI models. Researchers analyzed how these models organized social trait perceptions along dimensions of valence (trustworthiness) and dominance. The analysis was conducted across different world regions to assess consistency and regional variations in the AI models' social perception patterns.

## Key Results
- First two principal components replicated human social perception dimensions with high congruence coefficients (0.97-0.98 for valence, 0.65-0.79 for dominance)
- All three tested models (Claude 3.5 Sonnet, GPT-4 Turbo, Gemini 1.5 Pro) showed consistent replication of valence-dominance structure
- A third component was identified across most models and world regions, though its interpretation remains unclear

## Why This Works (Mechanism)
The study demonstrates that multimodal generative AI models have learned to organize social trait perceptions in ways that mirror human cognitive structures. The high congruence coefficients suggest that these models have internalized similar dimensional frameworks for processing social information from facial cues, likely through training on human-generated content that reflects these underlying patterns.

## Foundational Learning
- Principal Component Analysis (PCA): A statistical technique for dimensionality reduction that identifies underlying patterns in data - needed to extract fundamental dimensions from complex trait ratings
- Valence-Dominance Model: A framework for understanding how humans perceive social traits along two primary dimensions - trustworthiness and dominance - required to establish the theoretical baseline for comparison
- Congruence Coefficients: Statistical measures of similarity between vector spaces - needed to quantify how closely AI-generated dimensions match human perceptual structures

## Architecture Onboarding
- Component Map: Input Facial Images -> Trait Rating Extraction -> PCA Analysis -> Dimensional Output
- Critical Path: Facial image processing -> Trait rating generation -> Statistical analysis of dimensions
- Design Tradeoffs: The study chose to evaluate AI-generated ratings rather than human ratings, sacrificing direct human comparison for broader model testing
- Failure Signatures: Low congruence coefficients would indicate failure to replicate human social perception patterns
- First Experiments: 1) Test model performance with diverse facial stimuli 2) Compare regional variations in dimensional outputs 3) Analyze specific trait ratings that contribute to each dimension

## Open Questions the Paper Calls Out
- Interpretation of the third component identified across models and regions
- How these AI-generated dimensions might influence real-world AI applications and decision-making

## Limitations
- Reliance on AI-generated responses rather than direct human comparisons
- Lack of exploration of potential cultural or demographic biases in model responses
- Unclear theoretical grounding for the third component identified in the analysis

## Confidence
- High: Replication of valence and dominance dimensions across three models with high congruence coefficients
- Medium: Interpretation of additional components and broader applicability to real-world AI applications

## Next Checks
1. Direct comparison of AI-generated trait ratings with human ratings on identical facial stimuli to verify if the same underlying dimensions emerge
2. Cross-cultural validation using diverse face sets from different demographic groups to assess potential biases in the AI models' social perception
3. Longitudinal testing to determine if the identified dimensions remain stable across different model versions and updates