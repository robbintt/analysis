---
ver: rpa2
title: Counterfactual Explanations on Robust Perceptual Geodesics
arxiv_id: '2601.18678'
source_url: https://arxiv.org/abs/2601.18678
tags:
- robust
- metric
- counterfactual
- latent
- space
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of generating meaningful counterfactual
  explanations in high-dimensional vision domains. Previous latent-space optimization
  methods often produce off-manifold artifacts or adversarial examples due to poor
  distance metrics and lack of geometric constraints.
---

# Counterfactual Explanations on Robust Perceptual Geodesics

## Quick Facts
- arXiv ID: 2601.18678
- Source URL: https://arxiv.org/abs/2601.18678
- Reference count: 40
- One-line primary result: Proposed method produces perceptually plausible counterfactuals with significant improvements in robust perceptual metrics, reducing R-FID from ~50 to ~9 and R-LPIPS from ~0.67 to ~0.17.

## Executive Summary
This paper addresses the challenge of generating meaningful counterfactual explanations in high-dimensional vision domains. Previous latent-space optimization methods often produce off-manifold artifacts or adversarial examples due to poor distance metrics and lack of geometric constraints. The authors propose Perceptual Counterfactual Geodesics (PCG), which optimizes counterfactuals along geodesic paths in a latent space equipped with a robust Riemannian metric induced from robust vision features. This metric aligns with human perception and penalizes brittle directions, ensuring smooth, semantically valid transitions. Experiments on three vision datasets demonstrate that PCG outperforms baselines in producing perceptually plausible counterfactuals, with significant improvements in robust perceptual metrics like R-FID and R-LPIPS. The method reveals failure modes hidden under standard metrics and provides a more reliable framework for counterfactual explanation in vision tasks.

## Method Summary
The method constructs counterfactuals by tracing geodesics under a perceptually Riemannian metric induced from robust vision features. It builds a composite ambient metric by aggregating Euclidean metrics from intermediate layers of a robustly trained vision model, then pulls this back through the generator's Jacobian to define a Riemannian metric in the latent space. The optimization proceeds in two phases: first finding a smooth geodesic path by minimizing robust perceptual energy with fixed endpoints, then refining the endpoint by jointly optimizing the entire path with classification loss. This approach prevents local gradient methods from converging to adversarial examples or semantically distant counterfactuals.

## Key Results
- PCG achieves R-FID scores improving from ~50 to ~9 and R-LPIPS from ~0.67 to ~0.17 compared to baselines
- Outperforms VSGD, REVISE, and RSGD baselines across three vision datasets (AFHQ, FFHQ, PlantVillage)
- Reveals failure modes hidden under standard metrics, showing that methods scoring well on LPIPS often fail under robust evaluation
- Produces counterfactuals with better semantic faithfulness and visual plausibility while maintaining minimal change from original inputs

## Why This Works (Mechanism)

### Mechanism 1
A robust perceptual Riemannian metric, induced from the feature space of an adversarially trained vision model, re-weights latent space directions such that geodesic optimization favors perceptually meaningful paths over adversarial shortcuts. The method constructs a composite ambient metric by aggregating Euclidean metrics from intermediate layers of a robust backbone, then pulls this back through the generator's Jacobian to define a Riemannian metric in the latent space. Because robust features align with human perception, directions producing semantically coherent image changes have low "length" under this metric, while adversarial perturbations are heavily penalized. Optimizing a path to minimize its length under this metric forces the trajectory to follow a perceptual geodesic.

### Mechanism 2
A two-phase optimization process—first finding a smooth geodesic path, then refining its endpoint—prevents local gradient methods from converging to on-manifold adversarial examples or semantically distant counterfactuals. Phase 1 optimizes all intermediate points of a path to minimize the robust perceptual energy, subject to fixed start and end points. This enforces a globally coherent, on-manifold trajectory. Phase 2 then jointly optimizes the entire path with a combined loss, allowing the endpoint to move closer to the original input while being constrained to stay on the pre-computed geodesic structure. This global, path-based approach avoids the pitfalls of single-point local gradient descent.

### Mechanism 3
Standard evaluation metrics are blind to adversarial artifacts in counterfactuals; a robust evaluation framework is required to validate the semantic faithfulness of generated examples. The authors introduce robust variants of standard metrics computed using the features of a robust model. Standard metrics can be fooled by imperceptible adversarial perturbations, resulting in deceptively good scores for poor counterfactuals. In contrast, the proposed robust metrics are sensitive to the non-robust features exploited by adversarial examples. The superior performance of PCG under these robust metrics demonstrates that its outputs are aligned with robust, perceptually grounded features.

## Foundational Learning

- **Concept: Riemannian Geometry & Pullback Metrics**
  - **Why needed here:** The core of PCG is framing latent space optimization as path-finding on a curved surface. Understanding how a metric tensor defines length and how a pullback metric transfers geometry from image space to latent space is essential for grasping the optimization objective.
  - **Quick check question:** How does a pullback metric alter the "straight line" between two points in a latent space compared to standard Euclidean geometry?

- **Concept: Adversarial Robustness & Feature Alignment**
  - **Why needed here:** The paper's central premise is that robust models provide a better definition of perceptual geometry. Understanding the link between adversarial training and semantically meaningful gradients/features is crucial for understanding why this specific metric was chosen.
  - **Quick check question:** Why is the feature space of a robustly trained model considered a better proxy for human perception than that of a standard model?

- **Concept: Counterfactual Explanations vs. Adversarial Examples**
  - **Why needed here:** The paper addresses the fundamental ambiguity between these two concepts. Distinguishing a semantic change from a non-robust shortcut is the problem PCG is engineered to solve.
  - **Quick check question:** According to the paper, what role does the choice of distance metric play in determining whether an optimization produces a valid counterfactual or an adversarial example?

## Architecture Onboarding

- **Component Map:**
  Generative Prior (StyleGAN2/3) -> Encoder (image-to-latent) -> Task Classifier (VGG-19) -> Robust Backbone (ResNet-50) -> PCG Optimizer (two-phase) -> Robust Evaluator

- **Critical Path:**
  1. **Invert:** Map input image to a latent code using the encoder
  2. **Initialize Path:** Select target-class image, encode to latent, linearly interpolate to create initial path
  3. **Phase 1 (Geodesic):** Optimize intermediate points to minimize robust energy
  4. **Phase 2 (Refinement):** Optimize entire path with classification loss, apply re-anchoring schedule
  5. **Return:** Decode final endpoint to produce counterfactual image

- **Design Tradeoffs:**
  - **Path Discretization (T):** Larger T provides finer geodesic approximation but increases memory and compute costs
  - **Lambda Schedule:** Conservative start with gradual increase prevents endpoint from jumping to distant adversarial regions
  - **Robust Backbone:** Choice of model and robustness parameters directly shapes perceived latent geometry

- **Failure Signatures:**
  - **Off-Manifold Artifacts:** Blurry, distorted, or unnatural features in generated image
  - **Semantic Drift:** Target class achieved but identity, pose, or key attributes are lost
  - **Adversarial Collapse:** Generated image appears original class but classified as target

- **First 3 Experiments:**
  1. **Interpolation Geometry Study:** Visualize latent paths between two fixed images using four different metrics to assess semantic coherence
  2. **Baseline Counterfactual Comparison:** Generate counterfactuals for standard classifier using PCG and all baselines, visually compare results
  3. **Robust Metric Validation:** Compute both standard and robust scores for all methods, quantify how many methods that look good under standard metrics fail under robust evaluation

## Open Questions the Paper Calls Out

### Open Question 1
How can the Perceptual Counterfactual Geodesics framework be adapted to diffusion models, given their time-dependent latent spaces and stochastic dynamics? This requires deciding where to place geometry and how a pullback metric should interact with the score field. The paper identifies this as a distinct line of future work.

### Open Question 2
How do different adversarial robustness norms and training radii reshape the induced latent geometry and the quality of counterfactual explanations? The current work relies on a specific ℓ₂-robust backbone; the sensitivity of the perceptual metric and resulting geodesics to variations in robustness configuration remains untested.

### Open Question 3
Can lightweight or self-supervised robust surrogates effectively replace full-scale adversarially trained backbones for inducing perceptual geometry in low-resource settings? The method currently depends on computationally expensive robust models; the trade-off between backbone capacity and perceptual validity of induced metric is unknown.

## Limitations
- Computationally expensive requiring 500 optimization steps with re-anchoring, making it impractical for real-time applications
- Evaluation framework creates circular dependency by using robust models both to define optimization objective and evaluate results
- Strong dependence on specific robust backbone choice, with effectiveness potentially varying across domains
- Limited validation on domain-specific datasets where robustness guarantees may not transfer

## Confidence

**High confidence:** Claims about robust feature alignment providing better perceptual geometry for face and animal datasets where robustness has been extensively validated.

**Medium confidence:** Effectiveness of method for domain-specific datasets like PlantVillage where robustness guarantees may not transfer.

**Low confidence:** Scalability of two-phase optimization mechanism for real-time applications due to computational overhead.

## Next Checks

1. **Cross-Backbone Validation:** Generate counterfactuals using PCG with different robust backbones and measure consistency in R-LPIPS scores to test metric dependency.

2. **Ablation on Path Length:** Systematically vary discretization parameter T and measure trade-off between computational cost and robust metric performance to establish practical limits.

3. **Human Perceptual Study:** Conduct controlled user study comparing PCG counterfactuals against baselines on semantic relevance and naturalness, directly validating that robust metric improvements correlate with human judgment.