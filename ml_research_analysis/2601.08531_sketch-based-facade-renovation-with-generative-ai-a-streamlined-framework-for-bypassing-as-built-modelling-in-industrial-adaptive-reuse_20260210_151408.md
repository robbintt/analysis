---
ver: rpa2
title: 'Sketch-Based Facade Renovation With Generative AI: A Streamlined Framework
  for Bypassing As-Built Modelling in Industrial Adaptive Reuse'
arxiv_id: '2601.08531'
source_url: https://arxiv.org/abs/2601.08531
tags:
- renovation
- facade
- framework
- sketches
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of facade renovation design
  by introducing a three-stage generative AI framework that bypasses traditional as-built
  modeling. The framework integrates a fine-tuned vision-language model (VLM) to interpret
  rough sketches and generate renovation guidance, a diffusion model to synthesize
  new architectural components, and ControlNet to refine results into photorealistic
  images.
---

# Sketch-Based Facade Renovation With Generative AI: A Streamlined Framework for Bypassing As-Built Modelling in Industrial Adaptive Reuse

## Quick Facts
- arXiv ID: 2601.08531
- Source URL: https://arxiv.org/abs/2601.08531
- Reference count: 2
- This study introduces a three-stage generative AI framework that bypasses traditional as-built modeling for facade renovation design.

## Executive Summary
This paper presents a generative AI framework for facade renovation design that eliminates the need for traditional 3D as-built modeling. The approach uses a fine-tuned vision-language model to interpret rough sketches and generate renovation guidance, diffusion models to synthesize new architectural components, and ControlNet to produce photorealistic results. Experiments on industrial buildings demonstrate the framework's ability to generate structurally coherent and visually realistic renovation proposals, enabling rapid design exploration and improved communication of renovation intentions without manual 3D modeling.

## Method Summary
The framework employs a three-stage pipeline: (1) a fine-tuned Qwen3-VL-4B-Instruct vision-language model performs two-turn supervised learning to predict bounding boxes and generate renovation text from input sketches, with only the multimodal projection layer updated while freezing the visual encoder and LLM; (2) a fine-tuned Stable Diffusion model with IP-Adapter inpainting synthesizes new architectural components and integrates them into the sketch; (3) ControlNet-conditioned Stable Diffusion renders photorealistic facade images while preserving sketch structure. The system was trained on 100 paired industrial facade samples from Tianjin, plus auxiliary datasets of door and window sketches.

## Key Results
- The framework successfully generates renovation proposals from rough structural sketches without requiring manual 3D modeling
- Generated images demonstrate structural coherence and stylistic consistency with input sketches
- The approach enables rapid design exploration and iteration in early renovation concept phases

## Why This Works (Mechanism)

### Mechanism 1
A fine-tuned VLM can translate rough structural sketches into spatially-grounded renovation guidance without manual annotation. The two-turn supervised fine-tuning freezes the visual encoder and LLM while updating only the multimodal projection layer, forcing the model to learn domain-specific alignment between sketch geometry and architectural terminology. Turn 1 performs component detection; Turn 2 generates modification suggestions conditioned on detected context. Core assumption: Architectural semantics can be reliably extracted from simplified line sketches without depth or material cues. Break condition: If input sketches omit key structural edges or contain ambiguous geometry, bounding box predictions may misalign with actual modification intent.

### Mechanism 2
Diffusion-based inpainting can integrate newly generated components into existing sketches while preserving stylistic coherence. Stable Diffusion synthesizes architectural elements guided by VLM text descriptions, with IP-Adapter adding image-prompt conditioning for localized edits that blend generated components with the original outline. Core assumption: VLM guidance provides sufficiently precise spatial and semantic constraints to prevent component drift or style mismatch. Break condition: If VLM guidance is vague or conflicts with sketch geometry, inpainting may produce incoherent element placement.

### Mechanism 3
ControlNet can translate enhanced sketches into photorealistic images while strictly adhering to input structure. ControlNet injects spatial conditioning into Stable Diffusion, constraining the denoising process to preserve sketch geometry while synthesizing photorealistic materials, lighting, and textures. Core assumption: The enhanced sketch captures all structurally relevant edges; missing details can be hallucinated plausibly without violating architectural realism. Break condition: If the sketch contains incorrect proportions or impossible geometry, ControlNet will faithfully reproduce structural errors in the photorealistic output.

## Foundational Learning

- Concept: Vision-Language Model (VLM) fine-tuning with LoRA/PEFT
  - Why needed here: The framework requires adapting a general-purpose VLM to architectural sketch semantics without full model retraining.
  - Quick check question: Can you explain why freezing the visual encoder and LLM while training only the projection layer reduces overfitting risk?

- Concept: Conditional diffusion models (ControlNet, IP-Adapter)
  - Why needed here: Stage 2 and Stage 3 depend on spatially-conditioned image synthesis to maintain structural fidelity.
  - Quick check question: What is the difference between text-conditioned and image-conditioned diffusion guidance?

- Concept: Bounding box prediction and spatial grounding
  - Why needed here: The VLM must output coordinate-based predictions (not just captions) to guide where modifications occur.
  - Quick check question: How does a VLM represent spatial coordinates in its output, and how are they parsed for downstream use?

## Architecture Onboarding

- Component map: Input sketch + text prompt → Qwen3-VL-4B-Instruct (bounding boxes + renovation text) → Stable Diffusion + IP-Adapter (enhanced sketch) → Stable Diffusion + ControlNet (photorealistic image) → Output
- Critical path: VLM guidance quality → Component generation accuracy → ControlNet structural adherence. If Stage 1 produces poor guidance, downstream stages cannot recover.
- Design tradeoffs: Freezing encoder/LLM reduces overfitting but limits domain adaptation depth. ControlNet enforces structure but cannot correct fundamental sketch errors. Small training dataset (100 paired samples) may limit generalization to unseen building typologies.
- Failure signatures: Bounding boxes that do not align with actual sketch features → VLM fine-tuning data quality issue. Generated components that clash stylistically with existing sketch → IP-Adapter conditioning weight too weak. Photorealistic output that deviates from sketch geometry → ControlNet conditioning scale too low.
- First 3 experiments: 1) Run reconstruction experiments on training subset to validate pipeline reproduces known outputs. 2) Run generation experiments on held-out sketches to test generalization; log component placement accuracy. 3) Test on real-world photographs converted to sketches; compare VLM guidance against human expert annotations for spatial accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
How can structural and contextual constraints be explicitly integrated into the VLM-guided design process to ensure generated proposals support reliable renovation decision-making? The current framework focuses on visual exploration and early-stage concepts, relying on semantic reasoning that lacks rigorous physical or structural validation. Evidence would be a modified framework that successfully incorporates load-bearing logic or zoning rules to reject infeasible designs.

### Open Question 2
What quantitative evaluation protocols are necessary to rigorously assess the generalization performance of the framework across diverse architectural styles? The current study relies on qualitative visual assessment and small-scale reconstruction experiments, lacking standardized metrics for "structural coherence" or "renovation quality." Evidence would be the development and application of automated metrics that correlate strongly with human expert evaluation of the generated facades.

### Open Question 3
Does the framework maintain semantic and geometric accuracy when processing complex building geometries and non-frontal viewpoints compared to the current simplified inputs? The paper notes the current method is limited to "simplified, front-facing building sketches" and lists "complex geometries, and viewpoints" as future extensions. Evidence would be successful generation of structurally coherent images from oblique angles or complex floor plans without significant warping or semantic loss.

## Limitations
- Small training dataset (100 paired samples) may limit generalization to diverse architectural styles beyond industrial structures
- Pipeline assumes input sketches contain sufficient geometric fidelity; cannot recover missing structural details
- Study lacks temporal efficiency comparison with traditional 3D modeling workflows for large renovation projects

## Confidence
- High Confidence: Three-stage pipeline architecture is technically sound and follows established generative AI principles
- Medium Confidence: Framework can bypass traditional as-built modeling, but requires validation on more complex scenarios
- Low Confidence: Assertion of "structurally coherent" renovations is primarily qualitative and based on visual inspection rather than quantitative structural validation

## Next Checks
1. Compare generated renovation proposals against actual renovation outcomes from real industrial building projects, measuring geometric accuracy and architectural feasibility using professional architectural software
2. Apply the framework to non-industrial building types (residential, commercial, historical) to assess cross-domain performance across different facade typologies
3. Measure total processing time for complete renovation proposals across multiple iterations and compare against traditional as-built modeling workflows, including time for manual corrections and refinements