---
ver: rpa2
title: 'Digital Overconsumption and Waste: A Closer Look at the Impacts of Generative
  AI'
arxiv_id: '2505.18894'
source_url: https://arxiv.org/abs/2505.18894
tags:
- generative
- systems
- digital
- work
- users
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work highlights the climate implications of widespread adoption
  of generative AI systems. Estimates put the annual global energy consumption associated
  with the use of these systems at 1.92-9.29 TWh, equivalent to the annual electricity
  consumption of Mauritania and Kenya respectively.
---

# Digital Overconsumption and Waste: A Closer Look at the Impacts of Generative AI

## Quick Facts
- arXiv ID: 2505.18894
- Source URL: https://arxiv.org/abs/2505.18894
- Reference count: 11
- Annual global energy consumption of generative AI systems: 1.92-9.29 TWh (equivalent to Mauritania and Kenya's annual electricity consumption)

## Executive Summary
This work investigates the environmental impact of generative AI systems through the lens of digital overconsumption and waste. The authors combine user survey data with energy consumption estimates to reveal that a significant portion of generated content serves entertainment purposes with many outputs never being viewed again. With average users generating over 1500 images weekly and requiring numerous iterations for satisfaction, the study highlights a concerning pattern of resource-intensive consumption driven by casual users. The paper frames this as a commons dilemma where individual actions appear negligible but aggregate demand creates substantial environmental impact.

## Method Summary
The study employs a mixed-methods approach combining user survey data collection with energy consumption modeling. Researchers surveyed generative AI tool users to understand generation patterns, purposes (utilitarian vs. entertainment), iteration counts, and climate awareness levels. Energy consumption estimates were derived from prior work, providing a range of 1.92-9.29 TWh annual global consumption. The analysis incorporates uses and gratification theory and common pool source dilemma frameworks to interpret behavioral patterns and propose solutions.

## Key Results
- Generative AI systems consume 1.92-9.29 TWh annually, comparable to the electricity consumption of entire nations
- Approximately 40% of users employ these tools solely for personal entertainment
- Most generated images are never viewed again after initial creation
- Average users generate over 1500 images weekly, with half requiring more than 50 iterations for satisfaction
- Less than 15% of users are classified as "professional" users

## Why This Works (Mechanism)

### Mechanism 1: Information Deficit
Users lack visibility into per-action energy costs, cumulative global demand, and CO2 equivalence, preventing them from incorporating environmental impact into usage decisions even when climate concern is high. This awareness gap enables environmentally costly consumption patterns to persist.

### Mechanism 2: Rapid-Cycle Gratification
Generative AI compresses creation-to-consumption latency, enabling frequent small rewards through novel images and iteration hits. This aligns with uses-and-gratification theory and may engage the cognitive reward system, sustaining high-volume, low-utility generation.

### Mechanism 3: Commons Dilemma
Individual actions appear negligible while aggregate demand creates significant impact. Three conditions create this commons problem: the full resource pool size is unknown, access is asymmetrically distributed, and individuals lack complete information on system-level costs, leading to collectively suboptimal outcomes.

## Foundational Learning

- **Uses and Gratification Theory**
  - Why needed: Explains why users generate large volumes of content for entertainment and escapism
  - Quick check: Can you articulate how "needs satisfied by media" differ from "needs created by media design"?

- **Digital Waste (Data Waste)**
  - Why needed: Clarifies what environmental impacts are being counted (energy/CO2) versus harder-to-count impacts (storage, hardware lifecycle, toxicity)
  - Quick check: Name three forms of environmental impact associated with "data waste" beyond energy consumption

- **Common-Pool Resource Dilemmas**
  - Why needed: Helps assess which interventions (education, norms, regulation, technical design) are likely to work for addressing overconsumption
  - Quick check: What three conditions make a resource problem a "commons dilemma" rather than a simple market externality?

## Architecture Onboarding

- **Component map:** User interface layer (prompt input, image iteration loops) -> Model inference layer (diffusion models, GPU/TPU compute) -> Infrastructure layer (data centers, regional grids, PUE) -> Feedback layer (currently missing: per-prompt energy/CO2 signals) -> Governance layer (platform policies, potential quotas or pricing signals)

- **Critical path:** 1) Instrument inference for per-request energy/CO2 estimation 2) Provide user-visible feedback at generation time 3) Introduce friction or defaults for high-volume non-utilitarian use 4) Enable opt-in efficiency settings

- **Design tradeoffs:** Latency vs. efficiency (fewer sampling steps reduce compute but may lower output quality), accessibility vs. deterrence (too much friction harms legitimate use), accuracy vs. transparency in energy estimates

- **Failure signatures:** Feedback is shown but ignored, users migrate to less-transparent platforms, efficiency gains offset by increased total usage (Jevons paradox), metric gaming

- **First 3 experiments:** 1) Instrument inference pipeline to log per-prompt estimated energy and grid-aware CO2 2) Run within-subject experiment comparing real-time feedback vs. control conditions 3) Test "efficiency defaults" (lower-step sampling as default with opt-up)

## Open Questions the Paper Calls Out

### Open Question 1
Does uses and gratification theory apply to generative AI, explaining the high volume of instant content creation? The authors state future work is required to investigate this connection, as current evidence remains largely speculative.

### Open Question 2
How do generative AI systems interact with the human cognitive reward system, particularly as they evolve into immersive 3D VR environments? The potential for creating "virtual sanctuaries" suggests risks of increased social isolation, but interaction mechanisms remain hypothetical.

### Open Question 3
Can new hardware designs or model architectures effectively reduce energy draw without impairing utility? Current estimates show significant consumption, and technical efficiency solutions are needed to mitigate environmental impact.

## Limitations
- Energy consumption estimates remain highly sensitive to assumptions about hardware efficiency, model architectures, and user behavior patterns
- Survey-based behavioral insights may suffer from sampling bias toward engaged users and self-reporting inaccuracies
- Connection between gratification theory and generative AI usage patterns lacks direct empirical evidence
- Commons dilemma framing may oversimplify complex incentive structures and market dynamics

## Confidence

- **High Confidence**: Annual global energy consumption estimates (1.92-9.29 TWh) represent meaningful environmental impact
- **Medium Confidence**: User behavior patterns show significant non-utilitarian generation contributing to digital waste
- **Low Confidence**: Application of uses-and-gratification theory specifically to generative AI systems

## Next Checks

1. Instrument a production inference pipeline to measure actual per-request energy consumption across different hardware configurations, comparing real measurements against model-based estimates

2. Conduct a controlled experiment with randomized assignment to feedback conditions (real-time energy/CO2 indicators vs. control) measuring changes in generation frequency and iteration depth

3. Analyze platform-level usage logs to validate survey-reported behaviors against actual generation patterns, focusing on iteration counts and output retention