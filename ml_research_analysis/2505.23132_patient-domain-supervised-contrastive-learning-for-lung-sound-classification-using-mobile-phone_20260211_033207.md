---
ver: rpa2
title: Patient Domain Supervised Contrastive Learning for Lung Sound Classification
  Using Mobile Phone
arxiv_id: '2505.23132'
source_url: https://arxiv.org/abs/2505.23132
tags:
- data
- lung
- learning
- domain
- sound
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study addresses the challenge of lung sound classification
  using mobile phone microphones by tackling two main issues: the difference in audio
  characteristics between electronic stethoscopes and smartphone microphones, and
  variability among patients. The proposed Patient Domain Supervised Contrastive Learning
  (PD-SCL) method was developed to address these challenges by reducing domain and
  patient-specific variability in lung sound data.'
---

# Patient Domain Supervised Contrastive Learning for Lung Sound Classification Using Mobile Phone

## Quick Facts
- arXiv ID: 2505.23132
- Source URL: https://arxiv.org/abs/2505.23132
- Reference count: 20
- Primary result: PD-SCL improves mobile phone lung sound classification accuracy by 2.4% over baseline AST

## Executive Summary
This study tackles the challenge of lung sound classification using smartphone microphones, addressing two key issues: the domain gap between electronic stethoscope and mobile phone audio characteristics, and variability among patients. The authors propose Patient Domain Supervised Contrastive Learning (PD-SCL) to reduce both domain and patient-specific variability in lung sound data. When integrated with the Audio Spectrogram Transformer (AST) model, PD-SCL achieved a 2.4% performance improvement compared to the original AST model. The approach demonstrates that smartphones can effectively diagnose lung sounds, showing promise for broader use beyond traditional clinical settings.

## Method Summary
The proposed method combines Audio Spectrogram Transformer (AST) with Patient Domain Supervised Contrastive Learning (PD-SCL). The approach uses paired audio samples from both stethoscope and mobile domains with labels and patient IDs. PD-SCL employs a dual loss function combining standard Cross-Entropy with a contrastive loss that explicitly minimizes distance between positive pairs (same class, different patient/domain) and maximizes distance between negative pairs (different classes). The method processes 8-second audio clips resampled to 16kHz, extracts 128-dim log Mel spectrograms, and uses L2-normalized features with temperature τ=0.5. The total loss is L_CE + λ·L_PD-SCL with λ=0.5.

## Key Results
- PD-SCL improved AST performance by 2.4% on mobile phone lung sound classification
- The approach effectively addresses both domain shift and patient-specific variability
- Smartphones demonstrated capability for effective lung sound diagnosis beyond clinical settings
- Leave-subject-out 5-fold cross-validation validated the method's robustness

## Why This Works (Mechanism)
PD-SCL works by explicitly aligning features from different patients and recording domains while maintaining class discrimination. The contrastive loss pulls together samples of the same class from different patients or domains (positive pairs) while pushing apart samples from different classes (negative pairs). This creates feature representations that are invariant to the specific recording device and patient characteristics, focusing instead on the underlying lung sound patterns that indicate pathology. The temperature-scaled similarity computation with log-sum-exp stability ensures robust gradient flow during training.

## Foundational Learning

- **Concept: Supervised Contrastive Learning**
  - **Why needed here:** This is the engine of the paper's contribution. A reader must understand that unlike standard Cross-Entropy, which only pushes class probabilities apart, contrastive learning operates directly on the feature embeddings. It uses a loss function that explicitly minimizes distance between "positive" pairs (e.g., same class, different patient) and maximizes distance between "negative" pairs (different classes).
  - **Quick check question:** Can you explain why pulling two samples from the *same class but different patients* closer together in feature space helps the model generalize?

- **Concept: Domain Adaptation**
  - **Why needed here:** The core problem is transferring knowledge from a source domain (electronic stethoscope with abundant data) to a target domain (mobile phone with scarce data). One must grasp that this is not just multi-class classification, but a transfer learning problem where the data distribution shifts between domains.
  - **Quick check question:** If you trained a model only on high-quality stethoscope data and tested it on mobile phone data, what kind of performance drop would you expect and why?

- **Concept: Vision Transformers (ViT/AST) in Audio**
  - **Why needed here:** The backbone is an Audio Spectrogram Transformer (AST), which treats a spectrogram like a sequence of image patches. Understanding that self-attention relates all parts of the audio sequence globally, unlike the local receptive fields of a CNN, is key to grasping the model's representational power.
  - **Quick check question:** How does a transformer process an audio spectrogram differently than a standard Convolutional Neural Network?

## Architecture Onboarding

- **Component map:** Audio input → Preprocessing (8s clips, 128-dim log Mel Fbank) → AST backbone → Feature embeddings → Projection head → Dual loss (L_CE + L_PD-SCL) → Classification output

- **Critical path:** 1. Data Loading & Augmentation: Construct batch with samples from both domains and multiple patients 2. Encoding: Pass batch through AST to get embeddings 3. PD-SCL Logic: Compute similarity matrix, generate patient/domain masks, calculate contrastive loss 4. Optimization: Combine L_PD-SCL with L_CE and backpropagate

- **Design tradeoffs:** AST vs. CNN: AST provides superior long-range dependency modeling but can be more data-hungry and computationally expensive than a CNN like ResNet. Pre-training is critical. Combined vs. Target-Only Training: The paper shows target-only (mobile data only) outperforms simple combined training. PD-SCL is required to unlock the benefit of the combined dataset. DAT vs. PD-SCL: The paper demonstrates that their proposed PD-SCL outperforms Domain Adversarial Training (DAT), suggesting that explicit instance-level alignment is more effective than adversarial domain confusion for this task.

- **Failure signatures:** Collapse to Domain: If PD-SCL is not implemented correctly, the model will learn to classify based on "stethoscope sound" vs "phone sound" rather than "normal lung" vs "abnormal lung." Patient Overfitting: Without the "Different Patient" constraint in positive pair selection, the model may simply memorize the unique acoustic signature of each patient in the small dataset. Loss Imbalance: The hyperparameter λ balances the two losses. If set incorrectly, the contrastive loss could overpower the classification loss, leading to well-clustered but semantically meaningless features.

- **First 3 experiments:** 1. Baseline Reproduction: Train AST on *only* the mobile phone training set and evaluate on the mobile test set. This establishes the performance upper bound without domain shift issues. 2. Ablation on Pair Selection: Implement PD-SCL but define positive pairs only as "Same Label" (ignoring patient/domain). Compare performance against the full PD-SCL definition ("Same Label" + "Different Patient/Domain"). This isolates the value of the domain/patient-aware constraint. 3. Parameter Sensitivity: Vary the λ weighting parameter in the total loss function L_total = L_CE + λ·L_PD-SCL. Plot performance to find the optimal balance between classification accuracy and feature alignment.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the PD-SCL method effectively differentiate between specific adventitious sounds (e.g., crackles vs. wheezes) in a multi-class setting?
- Basis in paper: [inferred] The methodology explicitly aggregates crackles, wheezes, and both into a single "abnormal" class for a binary classification task (Section IV.C).
- Why unresolved: The paper only reports results for binary classification (Normal vs. Abnormal), leaving the model's capability to distinguish between specific pathological sound types untested.
- What evidence would resolve it: Evaluation metrics (Sp, Se, Sc) from experiments utilizing the full 4-class granularity of the dataset.

### Open Question 2
- Question: Does the model maintain diagnostic accuracy when applied to adult or geriatric populations?
- Basis in paper: [inferred] The dataset is limited to recordings from "pediatric patients at Woorisoa Children's Hospital" (Section IV.A).
- Why unresolved: Lung sound characteristics vary significantly with age and chest size; a model trained exclusively on children may not generalize to adult physiology.
- What evidence would resolve it: Validation performance on an external dataset comprising adult or geriatric lung sound recordings.

### Open Question 3
- Question: Is the proposed method robust to the hardware variability inherent in different smartphone models and microphones?
- Basis in paper: [inferred] The study utilizes mobile phone data sourced exclusively from "iPhone's recording function" (Section IV.A).
- Why unresolved: The acoustic properties of microphones differ across manufacturers (e.g., Android vs. iOS) and models, which may introduce a device-specific bias not addressed by the current training data.
- What evidence would resolve it: Cross-device validation where the model is trained on iPhone data and tested on data recorded using non-Apple smartphones.

## Limitations
- Data heterogeneity and label noise: The target domain (mobile phone) is relatively small (2,701 recordings), and label inconsistencies across recording modalities could impact PD-SCL's domain alignment.
- Implementation specificity: Critical training hyperparameters (learning rate, batch size, optimizer, early stopping) are not fully specified, affecting reproducibility.
- Domain adaptation generality: Results focus on a specific scenario (lung sound classification) with specific domain shift (stethoscope to mobile phone), limiting generalizability to other tasks.

## Confidence
- **High Confidence:** The core finding that PD-SCL improves AST performance on mobile phone lung sound classification by 2.4% is well-supported by experimental results and ablation studies.
- **Medium Confidence:** The claim that PD-SCL effectively addresses both domain shift and patient-specific variability is supported, but the specific contribution of each component of the positive pair selection is not fully disentangled.
- **Low Confidence:** The assertion that smartphones can effectively diagnose lung sounds for "broader use beyond traditional clinical settings" is an extrapolation requiring extensive clinical validation.

## Next Checks
1. **Hyperparameter Sensitivity Analysis:** Conduct a thorough ablation study varying the λ parameter and key training hyperparameters (learning rate, batch size) to assess the stability and robustness of PD-SCL's performance gains.

2. **Cross-Domain Generalization Test:** Evaluate the trained model on a held-out test set of mobile phone recordings from patients not present in the training data to assess its ability to generalize to truly unseen patient populations.

3. **Clinical Validation Pilot:** Design and conduct a small-scale clinical study to assess the practical utility of the PD-SCL-enhanced AST model in a real-world diagnostic setting, focusing on its performance in diverse patient populations and noisy environments.