---
ver: rpa2
title: 'WhisperD: Dementia Speech Recognition and Filler Word Detection with Whisper'
arxiv_id: '2505.21551'
source_url: https://arxiv.org/abs/2505.21551
tags:
- speech
- dementia
- whisper
- filler
- words
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper fine-tunes OpenAI's Whisper ASR model on dementia speech
  data to improve transcription accuracy and filler word detection. The model was
  trained on DementiaBank and an in-house dementia dataset with modifications to include
  filler words in the tokenizer.
---

# WhisperD: Dementia Speech Recognition and Filler Word Detection with Whisper

## Quick Facts
- arXiv ID: 2505.21551
- Source URL: https://arxiv.org/abs/2505.21551
- Authors: Emmanuel Akinrintoyo; Nadine Abdelhalim; Nicole Salomons
- Reference count: 0
- Primary result: Fine-tuned Whisper model achieves WER of 0.24 on dementia speech data, outperforming previous work

## Executive Summary
This paper presents WhisperD, a fine-tuned version of OpenAI's Whisper ASR model specifically adapted for dementia speech recognition and filler word detection. The researchers modified the Whisper tokenizer to include filler words and trained the model on DementiaBank data plus an in-house dementia dataset. The medium-sized WhisperD model achieved a word error rate of 0.24, representing a significant improvement over previous approaches. The fine-tuned models also demonstrated enhanced capabilities for detecting filler words, which is crucial for cognitive assessments in dementia patients.

## Method Summary
The researchers fine-tuned Whisper on dementia-specific speech data by first modifying the tokenizer to include filler words commonly used by dementia patients. They trained the model on two datasets: DementiaBank and an in-house collected dementia dataset. The training process involved adapting the medium-sized Whisper model to better handle the speech patterns and filler word usage characteristic of dementia patients. The approach focused on improving both transcription accuracy and the model's ability to detect filler words, which are important indicators in cognitive assessments.

## Key Results
- Medium WhisperD model achieved WER of 0.24 on dementia speech data
- Outperformed previous unpublished work with WER of 0.41
- Demonstrated improved filler word detection capabilities compared to baseline Whisper

## Why This Works (Mechanism)
The effectiveness of WhisperD stems from its fine-tuning on dementia-specific speech patterns combined with tokenizer modifications that explicitly account for filler words. By training on both standardized DementiaBank data and in-house dementia recordings, the model learns the unique speech characteristics of dementia patients, including pauses, repetitions, and filler word usage that standard ASR models struggle with. The tokenizer modification is particularly important as it allows the model to recognize and properly handle filler words rather than treating them as errors.

## Foundational Learning

### Dementia Speech Characteristics
- Why needed: Understanding unique speech patterns in dementia patients
- Quick check: Review dementia speech studies showing increased filler word usage and disfluencies

### Automatic Speech Recognition (ASR) Fundamentals
- Why needed: Understanding how Whisper's encoder-decoder architecture processes speech
- Quick check: Examine Whisper's base architecture and attention mechanisms

### Filler Word Detection in Cognitive Assessment
- Why needed: Recognizing importance of disfluencies as cognitive markers
- Quick check: Review literature on filler words as indicators of cognitive decline

## Architecture Onboarding

### Component Map
Whisper base model -> Tokenizer modification (filler words added) -> Fine-tuning on DementiaBank -> Fine-tuning on in-house dementia dataset -> WhisperD model

### Critical Path
1. Tokenizer modification to include filler words
2. Initial fine-tuning on DementiaBank
3. Additional fine-tuning on in-house dementia dataset
4. Evaluation on test sets

### Design Tradeoffs
The choice of medium-sized Whisper model balances computational efficiency with performance, though larger variants might achieve better accuracy. Using an in-house dataset improves domain adaptation but limits reproducibility. The tokenizer modification approach is simpler than training a completely new tokenizer but may have limitations in handling rare filler words.

### Failure Signatures
Potential failures include poor generalization to different dementia types, inability to handle unseen filler words not in the modified tokenizer, and degradation in performance on non-dementia speech. The model may also struggle with varying speech rates and severe dementia cases with highly fragmented speech.

### 3 First Experiments
1. Test baseline Whisper performance on dementia speech without fine-tuning
2. Evaluate tokenizer-only modifications without full fine-tuning
3. Compare different Whisper model sizes (tiny, base, large) on dementia data

## Open Questions the Paper Calls Out
None

## Limitations
- Limited comparison with other published ASR models on same datasets
- Lack of detailed error analysis by dementia severity levels
- In-house dataset characteristics not fully described, limiting reproducibility

## Confidence

### High Confidence
- Methodology of fine-tuning Whisper on dementia-specific data is technically sound
- Technical feasibility of tokenizer modification for filler word inclusion

### Medium Confidence
- Reported WER improvement over previous unpublished work
- Filler word detection capabilities, though detailed evaluation metrics are lacking

## Next Checks

1. Conduct comparative evaluation against other established ASR models (e.g., Google Speech-to-Text, DeepSpeech) on the same dementia datasets
2. Perform detailed error analysis to identify specific error patterns and their correlation with dementia severity levels
3. Test model performance across diverse demographic groups and different types of dementia to assess generalizability and potential biases