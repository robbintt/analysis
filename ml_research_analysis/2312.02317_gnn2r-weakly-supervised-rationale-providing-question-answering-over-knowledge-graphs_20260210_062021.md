---
ver: rpa2
title: 'GNN2R: Weakly-Supervised Rationale-Providing Question Answering over Knowledge
  Graphs'
arxiv_id: '2312.02317'
source_url: https://arxiv.org/abs/2312.02317
tags:
- reasoning
- question
- https
- gnn2r
- subgraphs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces GNN2R, a novel method for knowledge graph
  question answering that can efficiently retrieve both final answers and reasoning
  subgraphs as verifiable explanations. The method employs a two-step approach: first,
  a graph neural network (GNN) encodes the knowledge graph and question in a joint
  embedding space, pruning the search space of candidate answers; second, a pre-trained
  language model is fine-tuned to select the final reasoning subgraph based on semantic
  similarity to the question.'
---

# GNN2R: Weakly-Supervised Rationale-Providing Question Answering over Knowledge Graphs

## Quick Facts
- arXiv ID: 2312.02317
- Source URL: https://arxiv.org/abs/2312.02317
- Authors: Ruijie Wang; Luca Rossetto; Michael Cochez; Abraham Bernstein
- Reference count: 28
- Primary result: Achieves 5.7% improvement in Hits@1 and 19.5% improvement in F1 score over state-of-the-art methods for KGQA with reasoning subgraph explanations

## Executive Summary
GNN2R introduces a novel two-step method for knowledge graph question answering that retrieves both final answers and reasoning subgraphs as verifiable explanations. The method employs a graph neural network to encode the knowledge graph and question in a joint embedding space, pruning candidate answers, followed by a pre-trained language model fine-tuned to select the final reasoning subgraph based on semantic similarity to the question. Extensive experiments on multiple benchmark datasets demonstrate substantial improvements in effectiveness, efficiency, and quality of generated reasoning subgraphs.

## Method Summary
GNN2R uses a two-step approach for weakly-supervised KGQA. Step-I employs a 3-layer GNN with layerwise attentional message propagation and gated embedding updates to encode the KG and question, producing candidate answer embeddings. Step-II extracts reasoning subgraphs between candidates and topic entities, rewrites them to natural language, and uses a fine-tuned Sentence Transformer to select the subgraph most semantically similar to the question. The method requires only question-answer pairs (no reasoning subgraph annotations) and leverages vote-based mining to generate weak supervision signals for fine-tuning.

## Key Results
- Achieves average 5.7% improvement in Hits@1 score across benchmark datasets
- Demonstrates 19.5% improvement in F1 score for answer retrieval
- Outperforms state-of-the-art methods in both effectiveness and efficiency
- Shows strong robustness to limited or noisy training data

## Why This Works (Mechanism)

### Mechanism 1: Layerwise Attentional Message Propagation
Multi-hop questions require different semantic focus at different reasoning depths. Each GNN layer receives a distinct "reference embedding" of the question via a layerwise GRU encoder. Messages from neighboring entities are attention-weighted against this layer-specific question representation before aggregation. This allows answer entities to receive relevant signals at different hops that align with different aspects of the question semantics. Evidence shows JS divergence of ~0.5-0.66 between attention distributions across layers for complex questions.

### Mechanism 2: Gated Embedding Update with Question Reference
Aggregated messages may contain irrelevant information that dilutes entity embeddings. A gated update module computes attention scores for both the aggregated message and the current entity embedding, using the general question embedding as reference. The final update is a weighted combination, filtering out noise. Ablation studies show removing this gating causes -8.9% Hits@1 on WQSP.

### Mechanism 3: Weak Supervision via Vote-Based Positive/Negative Mining
Reasoning subgraph quality can be improved without ground-truth annotations by leveraging KG structure. Candidate subgraphs are converted to executable queries, and their retrieved entities are compared to ground-truth answers. Subgraphs whose retrieved entities overlap more with ground-truth answers are labeled "positive"; others are "negative." Fine-tuning with triplet loss improves F1 scores by 20.7% on WQSP and 27.3% on CWQ.

## Foundational Learning

- Concept: Graph Neural Networks (GNNs) with attention
  - Why needed here: Core of Step-I coarse reasoning; messages propagate across KG triples
  - Quick check question: Given a 3-layer GNN over a KG, can you explain how an entity 3 hops from a topic entity receives signals from it?

- Concept: Knowledge Graph structure (entities, relations, triples, inverse relations)
  - Why needed here: Entire method operates over KG triples; reasoning subgraphs are sets of triples
  - Quick check question: What is the difference between (A, relation, B) and (B, relation^-1, A)? When would you use each?

- Concept: Sentence Transformers and semantic similarity
  - Why needed here: Step-II compares rewritten subgraph expressions to the original question via cosine similarity
  - Quick check question: If two sentences have cosine similarity 0.95 in a Sentence Transformer embedding space, does this guarantee semantic equivalence?

## Architecture Onboarding

- Component map:
Step-I (GNN):
General Question Encoder (GRU) → q (general embedding)
Layerwise Question Encoder (GRU) → q^k per layer
Entity/Relation Initialization (BERT+GRU for relations, q for topic entities)
Attentional Message Propagation (Eq. 1-3) per layer
Gated Embedding Update (Eq. 4-6) per layer
→ Updated entity embeddings → Top-N nearest neighbors as candidates

Step-II (LM):
Reasoning Subgraph Extraction (path-based, Graph-Tool)
Subgraph Rewriting (Algorithm 1) → natural language expressions
Sentence Transformer encoding
Semantic Similarity Comparison (Eq. 8) → select best subgraph
Fine-tuning: Algorithm 2 generates positive/negative sets, triplet loss (Eq. 9)

- Critical path: Question → GNN encoding (3 layers) → Candidate answers → Path extraction → Subgraph combinations → Rewrite to NL → Sentence Transformer similarity → Final answer + reasoning subgraph

- Design tradeoffs:
  - Efficiency vs. explanation quality: Step-I alone is faster (~60ms) but lower F1; Step-II adds ~160ms for subgraph extraction
  - Weak supervision vs. strong supervision: Method works with only final-answer labels, but cannot handle questions requiring counting/sorting/aggregation
  - Path length limits: Restricting max path length improves efficiency but may miss valid reasoning paths

- Failure signatures:
  - Low Hits@1 in Step-I: Check if topic entities are correctly identified and initialized
  - Low F1 despite high Hits@1: Step-II may be filtering out correct answers; check similarity threshold and fine-tuning quality
  - Reasoning subgraphs semantically wrong but answer correct: Vote-based positive set may include spurious subgraphs; inspect Algorithm 2 output

- First 3 experiments:
  1. Ablate gated embedding update: Replace Eq. 6 with direct message addition; expect -8% to -18% Hits@1 depending on dataset complexity
  2. Vary GNN layers from 1 to 5 on multi-hop datasets: Expect optimal at ~2-3 layers; more layers may oversmooth
  3. Test on PQ-2hop with shuffled questions: Expect <5% performance drop, confirming robustness to word-order noise

## Open Questions the Paper Calls Out

### Open Question 1
How can GNN2R be effectively integrated with logical query generation modules to answer complex questions requiring aggregation operations (e.g., counting, sorting, filtering)? The authors explicitly state they plan to combine GNN2R with logical query-based approaches by adding a module that can generate specific SPARQL queries for post-processing.

### Open Question 2
Can the reasoning subgraph extraction mechanism be adapted to robustly handle knowledge graphs containing extensive auxiliary nodes or blank nodes? Section 7 notes it could be challenging to handle KGs with extensive auxiliary nodes that require adapting the path extraction to the specific KG schema.

### Open Question 3
Can transfer learning or zero-shot prompting of Large Language Models (LLMs) reduce GNN2R's dependency on task-specific training data? The authors intend to explore if recent LLMs can be prompted to compare questions with reasoning subgraphs in a zero-shot or few-shot setup to further reduce training data dependency.

## Limitations
- Cannot handle questions requiring counting, sorting, or aggregation operations
- Performance depends on effectiveness of vote-based weak supervision mechanism
- Requires pre-extracted question-relevant subgraphs and topic entities as input
- Exact training hyperparameters and random seeds are not fully specified in the paper

## Confidence
- High: The two-step architectural design and basic mechanism descriptions are clear and internally consistent
- Medium: Reported performance improvements, as exact hyperparameters and training procedures are underspecified
- Low: Generalization claims to noisy training data, as this is asserted rather than demonstrated with systematic experiments

## Next Checks
1. Reproduce the ablation studies (Tables 5-6) with publicly available code to verify the claimed impact of gated embedding updates and fine-tuning
2. Test model performance when training data is artificially corrupted with label noise (10-50%) to assess robustness claims
3. Measure the semantic similarity distribution between reasoning subgraphs and questions to verify that Step-II is actually selecting more semantically aligned subgraphs