---
ver: rpa2
title: Efficient Latent Semantic Clustering for Scaling Test-Time Computation of LLMs
arxiv_id: '2506.00344'
source_url: https://arxiv.org/abs/2506.00344
tags:
- question
- clustering
- answer
- semantic
- uncertainty
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Latent Semantic Clustering (LSC), a method
  for semantic clustering that leverages the internal hidden states of the generator
  LLM to avoid the computational overhead of external models. LSC extracts hidden
  states during generation, constructs an adjacency matrix using cosine similarity,
  and applies spectral clustering to identify semantic clusters.
---

# Efficient Latent Semantic Clustering for Scaling Test-Time Computation of LLMs

## Quick Facts
- arXiv ID: 2506.00344
- Source URL: https://arxiv.org/abs/2506.00344
- Reference count: 17
- Primary result: LSC uses generator LLM hidden states for semantic clustering, outperforming NLI-based methods on uncertainty quantification and reasoning tasks while reducing computational cost

## Executive Summary
This paper introduces Latent Semantic Clustering (LSC), a method that leverages internal hidden states from a generator LLM to perform semantic clustering without external models. By extracting intermediate layer representations during auto-regressive generation, constructing adjacency matrices via cosine similarity, and applying spectral clustering, LSC identifies semantically equivalent generations for uncertainty quantification and multi-step reasoning. The approach demonstrates superior performance compared to existing methods while significantly reducing computational overhead, achieving higher AUROC/AUARC scores on uncertainty tasks and improved reasoning accuracy with fewer LLM inferences.

## Method Summary
LSC operates by extracting hidden states $h_{n,\ell}$ from a predefined intermediate layer $\ell$ at the last generated token position for each of $N$ auto-regressive samples. These hidden states form an $N \times d$ matrix that captures context-aware semantic representations. Pairwise cosine similarity between hidden states constructs an adjacency matrix $A$, which is used to compute the normalized Laplacian $L = I - D^{-1/2}AD^{-1/2}$. The number of clusters $k$ is automatically determined by counting eigenvalues below threshold $\tau$, and spectral clustering with k-means is applied to the first $k$ eigenvectors. This clustered output serves as input for uncertainty quantification (semantic entropy) or reasoning tree pruning (SExp), reducing the number of required LLM inferences while maintaining or improving accuracy.

## Key Results
- LSC achieves F1=0.8789 for clustering quality, outperforming k-means (0.7387), AHC (0.8664), and DBSCAN (0.8676)
- On uncertainty quantification, LSC achieves higher AUROC and AUARC scores than NLI-based soft clustering methods (Deg, EigV, ECC, KLE)
- For reasoning tasks, LSC improves accuracy from 74.25% to 80.25% on GSM8K while reducing the number of LLM inferences required

## Why This Works (Mechanism)

### Mechanism 1
Hidden states from intermediate transformer layers encode semantic representations sufficient for clustering. During auto-regressive generation, LSC extracts $h_{i,\ell}$ from layer $\ell$ at the last generated token position, serving as a condensed representation of the entire generated sequence conditioned on input context. The core assumption is that the generator LLM's internal representations encode context-aware semantics more faithfully than external models trained on generic NLI or embedding objectives.

### Mechanism 2
Cosine similarity between hidden states approximates semantic equivalence better than NLI-based entailment scores. Given hidden states $\{h_1, h_2, ..., h_N\}$, LSC constructs adjacency matrix $A$ where $a_{m,n} = \frac{h_m \cdot h_n}{\|h_m\| \|h_n\|}$. This replaces NLI-based similarity graphs, assuming geometric proximity in the generator's latent space correlates with semantic equivalence under the given context.

### Mechanism 3
Spectral clustering with eigenvalue thresholding automatically determines the number of semantic clusters. LSC computes the symmetric normalized Laplacian $L = I - D^{-1/2}AD^{-1/2}$ and determines $k$ by counting eigenvalues below threshold $\tau$. The core assumption is that small eigenvalues correspond to semantically coherent groups, leveraging the mathematical property that the multiplicity of zero eigenvalues equals connected components.

## Foundational Learning

- **Spectral Graph Theory (Laplacian, eigenvalues, clustering)**: Essential for understanding why small eigenvalues indicate connected components in the idealized binary case. Quick check: Given an adjacency matrix with two clearly separated clusters, what would you expect the first two eigenvalues of the normalized Laplacian to be?

- **Transformer Hidden States (layer-wise representations, last-token pooling)**: Critical for understanding why intermediate layers provide better semantic representations than final layers for clustering. Quick check: Why might an intermediate layer (e.g., layer 15 of 32) provide better semantic representations than the final layer for clustering?

- **Cosine Similarity vs. NLI-based Semantic Matching**: Important for assessing when LSC's substitution of cosine similarity for NLI entailment scores breaks. Quick check: What semantic relationship might NLI capture that cosine similarity in latent space could miss?

## Architecture Onboarding

- **Component map**: Hidden State Extractor -> Adjacency Matrix Builder -> Spectral Clusterer -> Downstream Interface
- **Critical path**: Hidden state extraction → adjacency matrix → eigenvalue computation → cluster assignment. Errors in extraction (wrong layer, wrong token) propagate through all stages.
- **Design tradeoffs**: Layer choice balances speed and semantic quality; threshold τ controls cluster granularity; white-box requirement limits deployment options.
- **Failure signatures**: All sequences in one cluster indicates τ too low or mode collapse; each sequence separate indicates τ too high; inconsistent counts suggest high generation variance.
- **First 3 experiments**: 
  1. Layer ablation: Run LSC on GSM8K with layers 5, 10, 15, 20, 25, 30; plot F1 vs. layer index.
  2. Threshold sensitivity: Sweep τ ∈ {0.1, 0.3, 0.5, 0.7, 0.9} on validation set; plot precision/recall/F1.
  3. Baseline comparison: Run k-means, AHC, DBSCAN on same hidden states; confirm LSC adds value over simpler clustering.

## Open Questions the Paper Calls Out

- **Multi-layer aggregation**: Does incorporating hidden states from multiple layers or attention heads improve clustering fidelity compared to single-layer extraction? The paper suggests this could enhance representation quality but leaves it unexplored for simplicity.

- **Black-box approximation**: How can LSC be adapted for black-box models where hidden states are inaccessible? The white-box requirement is a fundamental limitation, and the paper calls for exploring alternatives that approximate internal representations.

- **Adaptive threshold selection**: Can the eigenvalue threshold τ be determined adaptively without a labeled validation set? The current approach requires validation-set tuning, which may not generalize across different prompt types or model scales.

## Limitations

- **Black-box incompatibility**: LSC fundamentally requires white-box access to extract internal hidden states, making it inapplicable to commercial APIs or models without open weights.
- **Layer sensitivity**: Optimal layer selection varies by model architecture and task, creating hyperparameter search burden and potential brittleness.
- **Validation dependency**: The eigenvalue threshold τ requires labeled validation sets for optimal selection, limiting unsupervised deployment.

## Confidence

- **High confidence**: Core mechanism of using hidden states for clustering is well-supported (Figures 5-6 show layer-dependent performance, Table 4 shows superior F1).
- **Medium confidence**: Performance improvements on downstream tasks are demonstrated but may be sensitive to dataset choice and generation hyperparameters.
- **Low confidence**: Generalization to black-box models, very small models, and domains outside tested benchmarks remains unverified.

## Next Checks

1. **Layer sensitivity analysis**: Systematically test LSC across 5-10 different layer indices for a 32-layer model on GSM8K, measuring F1 clustering quality and downstream reasoning accuracy to verify intermediate layers peak performance.

2. **Threshold robustness testing**: Perform comprehensive sweep of τ values (0.1 to 0.9 in 0.1 increments) on held-out validation set, measuring stability of k and downstream task performance to determine optimal range.

3. **Black-box approximation evaluation**: For Llama3-8B, compare LSC performance using only final token embedding versus full hidden states, and using sentence transformers as black-box alternative, to quantify white-box requirement impact.