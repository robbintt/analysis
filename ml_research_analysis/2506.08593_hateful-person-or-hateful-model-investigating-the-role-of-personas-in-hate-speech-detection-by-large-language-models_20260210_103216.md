---
ver: rpa2
title: Hateful Person or Hateful Model? Investigating the Role of Personas in Hate
  Speech Detection by Large Language Models
arxiv_id: '2506.08593'
source_url: https://arxiv.org/abs/2506.08593
tags:
- figure
- dataset
- distribution
- logit
- difference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how MBTI-based personas influence hate
  speech detection in both humans and large language models (LLMs). A human survey
  confirms that MBTI traits, particularly the Feeling-Thinking dimension, significantly
  affect annotation behavior.
---

# Hateful Person or Hateful Model? Investigating the Role of Personas in Hate Speech Detection by Large Language Models

## Quick Facts
- **arXiv ID**: 2506.08593
- **Source URL**: https://arxiv.org/abs/2506.08593
- **Reference count**: 40
- **Primary result**: LLM hate speech detection predictions vary significantly based on MBTI persona prompts, with Thinking and Judging types showing higher confidence in hate speech classifications.

## Executive Summary
This paper explores how personality-based personas influence hate speech detection performance in both humans and large language models. The study first confirms through human surveys that MBTI traits, particularly the Feeling-Thinking dimension, significantly affect annotation behavior. Building on these findings, the researchers prompt four open-source LLMs with different MBTI personas across three hate speech datasets, revealing substantial variation in predictions. The results demonstrate that LLMs are highly sensitive to persona conditioning, with Thinking and Judging personas consistently yielding higher confidence in hate speech predictions. Notably, LLMs exhibit more exaggerated persona-driven effects than humans, amplifying certain personality traits in their classification decisions.

## Method Summary
The study employs a two-phase approach, first validating MBTI trait effects on human annotators through surveys, then extending this framework to LLMs. Researchers create persona prompts based on MBTI personality types and apply them to four open-source language models across three hate speech datasets. The methodology examines both final classification labels and internal logit distributions to understand how different personas influence model behavior. The study compares human and LLM responses to identify patterns and amplification effects in persona-driven decision-making.

## Key Results
- LLM predictions vary substantially across different MBTI personas, with inconsistent final labels and logit distributions
- Thinking and Judging personas consistently produce higher confidence in hate speech predictions compared to Feeling and Perceiving types
- LLMs exhibit more exaggerated persona-driven effects than humans, amplifying certain personality traits in classification decisions

## Why This Works (Mechanism)
The mechanism behind these findings lies in how LLMs interpret and internalize persona prompts as contextual guidance for their reasoning process. When given MBTI-based personality traits, the models adjust their internal reasoning patterns to align with the described characteristics, affecting both their confidence levels and final classifications. This persona conditioning creates systematic biases in how the models process hate speech content, with certain personality types leading to more stringent or lenient classification decisions.

## Foundational Learning
- **MBTI personality framework**: Understanding the four dimensions (Extraversion/Introversion, Sensing/Intuition, Thinking/Feeling, Judging/Perceiving) is crucial for designing persona prompts that effectively influence model behavior. Quick check: Verify that persona prompts accurately capture the core traits of each MBTI type.
- **Persona conditioning**: The technique of embedding personality traits into prompts to guide model behavior, essential for understanding how subjective factors influence NLP tasks. Quick check: Test prompt variations to ensure consistent persona effects across different hate speech examples.
- **Logit distribution analysis**: Examining the probability distributions before final classification to understand confidence levels and decision boundaries, necessary for interpreting model certainty in hate speech detection. Quick check: Compare logit distributions across personas for identical hate speech instances.

## Architecture Onboarding
- **Component map**: Human survey -> MBTI persona prompt generation -> LLM hate speech classification -> Logit distribution analysis -> Comparative analysis
- **Critical path**: Persona prompt design -> LLM input processing -> Internal reasoning transformation -> Output classification -> Confidence assessment
- **Design tradeoffs**: Balancing persona specificity against prompt brevity, ensuring prompts capture personality essence without overwhelming the model's attention mechanism
- **Failure signatures**: Inconsistent persona effects across different hate speech types, unpredictable amplification of certain traits, and potential overfitting to specific personality dimensions
- **First experiments**:
  1. Test intermediate MBTI personality types to map the full landscape of persona effects
  2. Apply the same persona prompts to proprietary models to assess model-specific variations
  3. Conduct ablation studies by removing individual personality dimensions to identify key drivers of classification changes

## Open Questions the Paper Calls Out
None

## Limitations
- Limited persona coverage: Only 4 MBTI types were tested, potentially missing nuanced effects from other personality dimensions
- Dataset constraints: Results are based on three specific hate speech datasets, limiting broader applicability
- Single model architecture focus: Only open-source LLMs were examined, excluding proprietary models

## Confidence
- **High confidence**: Observable variation in LLM predictions across different personas; consistent patterns in Thinking/Judging types showing higher confidence
- **Medium confidence**: The amplification effect where LLMs exhibit more exaggerated persona-driven effects than humans; generalization across different hate speech contexts
- **Medium confidence**: The methodological approach of persona conditioning as a valid framework for studying subjectivity in NLP

## Next Checks
1. Test additional MBTI dimensions and intermediate personality types to map the full landscape of persona effects
2. Replicate findings across diverse hate speech datasets including multilingual and domain-specific corpora
3. Compare open-source and proprietary LLM responses to identical persona prompts to assess model-specific variations