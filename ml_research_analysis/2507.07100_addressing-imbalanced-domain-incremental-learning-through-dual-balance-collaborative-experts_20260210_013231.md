---
ver: rpa2
title: Addressing Imbalanced Domain-Incremental Learning through Dual-Balance Collaborative
  Experts
arxiv_id: '2507.07100'
source_url: https://arxiv.org/abs/2507.07100
tags:
- learning
- uni00000013
- class
- uni00000044
- classes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of class imbalance in Domain-Incremental
  Learning (DIL), where models must adapt to evolving domains while preserving knowledge
  from previous tasks. The proposed Dual-Balance Collaborative Experts (DCE) framework
  tackles two critical issues: intra-domain class imbalance and cross-domain class
  distribution shifts.'
---

# Addressing Imbalanced Domain-Incremental Learning through Dual-Balance Collaborative Experts

## Quick Facts
- **arXiv ID:** 2507.07100
- **Source URL:** https://arxiv.org/abs/2507.07100
- **Reference count:** 30
- **Primary result:** State-of-the-art performance on imbalanced DIL benchmarks, especially on few-shot classes.

## Executive Summary
This paper addresses the challenge of class imbalance in Domain-Incremental Learning (DIL), where models must adapt to evolving domains while preserving knowledge from previous tasks. The proposed Dual-Balance Collaborative Experts (DCE) framework tackles two critical issues: intra-domain class imbalance and cross-domain class distribution shifts. DCE employs frequency-aware expert networks trained with specialized loss functions to balance representation across different class frequencies. Additionally, a dynamic expert selector is trained on synthetic features generated through balanced Gaussian sampling from historical class statistics, enabling context-aware knowledge transfer while mitigating catastrophic forgetting. Experimental results on four benchmark datasets demonstrate that DCE achieves state-of-the-art performance, with significant improvements particularly on few-shot classes compared to existing methods.

## Method Summary
DCE introduces a two-stage framework to handle imbalanced DIL. In Stage 1, three expert networks per domain are trained using distinct loss functions: standard cross-entropy ($\ell_{CE}$), balanced softmax ($\ell_{Bal}$), and inverse distribution weighting ($\ell_{Rev}$). This specialization allows each expert to focus on different aspects of the class frequency spectrum. In Stage 2, a dynamic expert selector is trained using synthetic features generated via balanced Gaussian sampling from stored class means and covariances. This selector learns to optimally combine expert outputs based on the input context, enabling effective knowledge transfer across domains while preserving performance on imbalanced data.

## Key Results
- DCE achieves state-of-the-art average accuracy across four benchmark datasets (Office-Home, DomainNet, CORe50, CDDB-Hard).
- Significant improvements on few-shot classes compared to existing methods, addressing a critical limitation in imbalanced DIL.
- The balanced Gaussian sampling approach for selector training effectively mitigates catastrophic forgetting and improves cross-domain generalization.

## Why This Works (Mechanism)
The paper's approach works by decomposing the imbalanced DIL problem into two complementary components: expert specialization and context-aware selection. The three specialized experts address different aspects of the frequency spectrum—standard CE captures majority classes, balanced softmax up-weights minorities, and inverse distribution weighting aggressively promotes rare classes. The dynamic selector then learns to route inputs to the most appropriate expert based on synthetic features that represent the balanced class distribution. This dual-balance mechanism ensures both intra-domain fairness and cross-domain adaptability.

## Foundational Learning
- **Domain-Incremental Learning (DIL):** Sequential learning across multiple domains/tasks. Why needed: The core problem setting where models must adapt without forgetting. Quick check: Verify the sequential task setup and evaluation protocol.
- **Class Imbalance:** Unequal representation of classes in training data. Why needed: The primary challenge addressed, affecting both learning and generalization. Quick check: Confirm imbalance statistics and balanced test sets.
- **Expert Networks:** Multiple specialized models for different aspects of the problem. Why needed: Enables decomposition of complex learning tasks. Quick check: Verify the three distinct loss functions for expert training.
- **Balanced Sampling:** Generating synthetic data to balance class distributions. Why needed: Addresses catastrophic forgetting and improves minority class performance. Quick check: Confirm synthetic feature generation using Gaussian sampling.
- **Visual Prompt Tuning (VPT):** Parameter-efficient fine-tuning of vision transformers. Why needed: Enables adaptation without full fine-tuning. Quick check: Verify VPT implementation and freezing strategy.
- **Oracle Approximating Shrinkage (OAS):** Regularization for covariance estimation in high-dimensional spaces. Why needed: Ensures numerical stability for few-shot classes. Quick check: Confirm OAS implementation for covariance matrices.

## Architecture Onboarding
- **Component Map:** Data → VPT Backbone → Experts (3 per domain) → Features → Class Statistics → Synthetic Features → Expert Selector → Final Prediction
- **Critical Path:** VPT (frozen after task 1) → Expert Features → Balanced Gaussian Sampling → Selector Training → Inference
- **Design Tradeoffs:** Specialization vs. generalization in expert networks; synthetic data quality vs. computational cost in selector training.
- **Failure Signatures:** Poor few-shot performance indicates $\ell_{Rev}$ implementation issues; forgetting indicates VPT parameter drift; selector confusion indicates synthetic sampling problems.
- **First Experiments:** 1) Train experts with $\ell_{CE}$, $\ell_{Bal}$, $\ell_{Rev}$ and verify class-specific performance differences. 2) Generate synthetic features and train selector, measuring accuracy vs. number of samples. 3) Implement OAS covariance regularization and test on low-sample classes.

## Open Questions the Paper Calls Out
None

## Limitations
- Missing MLP architectural details (layer sizes, activation functions) introduce ambiguity in implementation fidelity.
- The number of synthetic samples per class (K) used for balanced Gaussian sampling is unspecified, potentially affecting selector training quality.
- No explicit mention of whether data augmentation is applied during training, which could impact robustness.

## Confidence
- **High confidence:** The core methodological framework (dual-stage training, expert specialization, balanced sampling) is well-specified and experimentally validated across multiple benchmarks.
- **Medium confidence:** The specific loss functions ($\ell_{Bal}$, $\ell_{Rev}$) and their implementation details are described but require careful translation to code.
- **Medium confidence:** Performance claims are supported by experiments, though exact hyperparameter tuning for each dataset is not fully disclosed.

## Next Checks
1. Verify expert selector performance by ablating the balanced Gaussian sampling and measuring degradation on few-shot classes.
2. Implement OAS covariance regularization and test on low-sample classes to ensure numerical stability.
3. Conduct a sensitivity analysis on the number of synthetic samples (K) to quantify its impact on accuracy gains.