---
ver: rpa2
title: 'Vocabulary In-Context Learning in Transformers: Benefits of Positional Encoding'
arxiv_id: '2511.06376'
source_url: https://arxiv.org/abs/2511.06376
tags:
- function
- positional
- lemma
- theorem
- activation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the universal approximation property (UAP)
  of single-layer Transformers in vocabulary in-context learning (VICL), focusing
  on the role of positional encoding. Without positional encoding, VICL in single-layer
  Transformers does not possess the UAP.
---

# Vocabulary In-Context Learning in Transformers: Benefits of Positional Encoding

## Quick Facts
- **arXiv ID:** 2511.06376
- **Source URL:** https://arxiv.org/abs/2511.06376
- **Reference count:** 40
- **Primary result:** VICL in single-layer Transformers achieves universal approximation property only when appropriate positional encoding is included.

## Executive Summary
This paper establishes the theoretical foundation for vocabulary in-context learning (VICL) in single-layer Transformers, demonstrating that universal approximation property (UAP) is fundamentally dependent on positional encoding. Without positional encoding, VICL with finite vocabulary cannot universally approximate all continuous functions due to the inherent limitations of finite-dimensional function spaces. However, when appropriate positional encoding is incorporated, VICL achieves UAP by enabling the combined set of vocabulary and positional encodings to become dense in the embedding space. The paper provides constructive proofs for several activation functions including ReLU and softmax, revealing the critical role positional encoding plays in transforming VICL from a limited function approximator to a universal one.

## Method Summary
The paper establishes equivalence between single-layer Transformers and feed-forward neural networks under specific sparse matrix assumptions, then uses this connection to prove UAP conditions. The core method involves demonstrating that VICL without positional encoding cannot achieve UAP due to finite vocabulary constraints, while VICL with appropriate positional encoding can achieve UAP by creating dense representations in the embedding space. The theoretical framework uses constructive proofs based on Kronecker approximation and rational perturbation techniques to show how context tokens can approximate any continuous function when combined with suitable positional encodings.

## Key Results
- VICL without positional encoding cannot achieve universal approximation property due to finite vocabulary constraints
- With appropriate positional encoding, VICL achieves UAP by making the combined vocabulary-positional set dense in ℝ^{d_x}
- Sufficient conditions provided for both ReLU (density in [-1,1]^{d_x}) and softmax (density in local neighborhoods) activations
- Current proofs do not extend to relative positional encodings like RoPE or multi-layer architectures

## Why This Works (Mechanism)

### Mechanism 1
Positional encoding enables universal approximation by making the combined set S = V_x + P_x dense in ℝ^{d_x}, which is impossible with finite vocabulary alone. Finite vocabulary V_x is bounded and cannot span the continuous space. Positional encodings P_x, designed to grow unbounded across positions, create a union set S that becomes dense in ℝ^{d_x}. This density allows context tokens to approximate any weight vector in the equivalent FNN structure. The core assumption is that positional encoding P_x must be designed such that S = {x_i + P(j)_x | x_i ∈ V_x, j ∈ ℕ⁺} is dense in ℝ^{d_x} (Theorem 7), or at least dense in [-1,1]^{d_x} for ReLU activations (Theorem 8). Break condition: If positional encodings are bounded or insufficiently diverse, S remains non-dense, and UAP fails.

### Mechanism 2
In-context demonstrations act as trainable weights in an equivalent feed-forward neural network, enabling function approximation without weight updates. Under Assumption 1 (sparse Q, K, V matrices), single-layer Transformer output reduces to T_σ(x̃; X, Y) = U·Y·σ(X^T·B^T·C·x̃), matching FNN form N_σ(x) = A·σ(W·x + b) where context matrices X, Y play the roles of weight W and output matrix A. The fixed Transformer weights (U, B, C) provide the computational backbone while context provides task-specific parameters. Break condition: For softmax activation, normalization creates additional bounded term exp(x̃^T·B^T·C·x̃) that doesn't exist in standard FNNs, requiring special handling.

### Mechanism 3
Finite vocabulary without positional encoding restricts the model to a finite-dimensional function space, which cannot universally approximate all continuous functions. When context tokens come from finite vocabulary V, the resulting network N_σ* has weights from finite sets A, W, B. For element-wise activations, span{N_σ*} forms a finite-dimensional function space that is closed under uniform norm. Any target function outside this span cannot be approximated. For softmax, the number of zero crossings is bounded by |W×B|, so functions with more zeros are unapproximable. Break condition: Theorem 6 holds even without Assumption 1 constraints, making this a fundamental limitation of finite vocabularies.

## Foundational Learning

- **Concept: Universal Approximation Property (UAP)**
  - Why needed here: The entire paper centers on whether Transformers can achieve UAP for VICL—understanding UAP is prerequisite to following the main argument.
  - Quick check question: Can you explain why a finite-dimensional function space cannot have UAP?

- **Concept: Positional Encoding (Absolute/Relative/RoPE)**
  - Why needed here: The paper proves positional encoding is necessary and provides conditions; distinguishing APE (used here) from RPE/RoPE (excluded from current proof) is critical.
  - Quick check question: Why does absolute positional encoding (adding to embeddings) allow density proofs while rotary embeddings (RoPE) do not?

- **Concept: In-Context Learning (ICL) vs. Weight-Based Learning**
  - Why needed here: The paper's core mechanism treats context as control parameters rather than updating weights—this paradigm shift is essential.
  - Quick check question: How does the equation T_σ(x̃; X, Y) = U·Y·σ(X^T·B^T·C·x̃) demonstrate that context replaces weights?

## Architecture Onboarding

- **Component map:** Input Z → Positional encoding P(i) → Attention layer → Output extraction T_σ(x; X, Y)

- **Critical path:**
  1. Verify vocabulary V satisfies density preconditions (V_y must contain {1, -1, √2, 0})
  2. Design positional encoding P such that S = V_x + P_x is dense in ℝ^{d_x}
  3. Initialize Q, K, V with sparse partition (B, C non-singular; U non-singular; F=0 for simplicity)
  4. For target function f, construct context (X, Y) using Kronecker approximation to approximate FNN weights

- **Design tradeoffs:**
  - ReLU activation: Allows relaxed density condition (S dense in [-1,1]^{d_x} only) via positive homogeneity scaling
  - Exponential/softmax activation: Requires S dense only in local neighborhood B(w*, δ) but needs special normalization handling
  - Absolute PE: Proven to enable UAP; Relative PE/RoPE: Current proof inapplicable
  - Assumption 1 (sparse Q,K,V): Simplifies analysis but Appendix F shows many results hold without it

- **Failure signatures:**
  - UAP failure: Output cannot approximate functions with >|W×B| zero crossings (for softmax without PE)
  - Density failure: If P_x bounded, S cannot be dense in ℝ^{d_x}, approximation error has lower bound ε₀ > 0
  - RoPE incompatibility: Rotation matrices don't generate dense subsets—current constructive proof fails

- **First 3 experiments:**
  1. Verify non-UAP without PE: Train single-layer Transformer on VICL with finite vocabulary, no positional encoding. Test on target functions with varying zero-crossing counts.
  2. Validate density requirement: Design APE schemes with varying density properties. Measure approximation error across target function classes.
  3. Ablate on activation functions: Compare ReLU vs. exponential using identical positional encoding. Test on polynomial and non-polynomial targets.

## Open Questions the Paper Calls Out

### Open Question 1
Can the universal approximation property (UAP) for vocabulary in-context learning be extended to multi-layer Transformers and general positional encodings, such as Relative Positional Encoding (RPE) or Rotary Positional Embedding (RoPE)? The conclusion explicitly states that future research should extend these findings to multi-layer Transformers, general positional encodings, and softmax activations. This remains unresolved because current theoretical proofs are restricted to single-layer architectures utilizing Absolute Positional Encoding (APE).

### Open Question 2
Does the UAP hold for Transformers with softmax activation when utilizing positional encoding? The paper notes that while softmax is analyzed in early sections, extending this connection to the scenario in Section 4 proves challenging and requires more sophisticated techniques. This remains unresolved because the normalization operation inherent in softmax prevents the direct application of the density-based arguments used for element-wise activations in the constructive proofs.

### Open Question 3
What is the practical validity of the sparse partition assumption (Assumption 1) regarding the Query, Key, and Value matrices in trained models? The authors acknowledge that the construction for Theorem 7 relies on the sparse partition assumption whose practical validity remains uncertain and requires future exploration. This remains unresolved because the assumption serves as a theoretical convenience for tractable proofs but creates a gap between the paper's construction and the parameter distributions found in standard trained Transformers.

## Limitations
- Current proofs do not extend to relative positional encodings like RoPE or multi-layer architectures
- Density requirements for positional encoding may require impractically large vocabularies or unbounded positional encodings
- Sparse partition assumption (Assumption 1) may not reflect practical Transformer configurations where attention patterns are dense

## Confidence

**High Confidence**: The equivalence between single-layer Transformers and FNNs under Assumption 1 (Lemma 3) is well-established. The non-UAP result without positional encoding (Theorem 6) follows logically from finite-dimensional function space arguments. The core mechanism that positional encoding enables density in ℝ^{d_x} is mathematically rigorous.

**Medium Confidence**: The sufficient conditions for positional encoding achieving UAP (Theorems 7 and 8) are constructive but rely on density properties that may be difficult to verify in practice. The handling of softmax activation adds complexity that may introduce subtle gaps in the proof chain.

**Low Confidence**: The practical implications of requiring unbounded positional encodings for density, and whether the rational perturbation approach for constructing context scales to high-dimensional problems. The paper does not address computational feasibility or empirical validation of the theoretical bounds.

## Next Checks

1. **Empirical UAP Verification**: Implement a synthetic experiment comparing VICL performance with and without positional encoding on target functions of increasing complexity (measured by zero crossings). Verify the predicted failure threshold for finite vocabularies and the recovery with appropriate positional encoding.

2. **Positional Encoding Design**: Create and test multiple positional encoding schemes (sinusoidal, linear progression, learned) to empirically verify which satisfy the density conditions for achieving UAP. Measure approximation error as a function of encoding design parameters.

3. **Activation Function Analysis**: Systematically compare ReLU vs. softmax activation in VICL under identical positional encoding and context conditions. Verify the different density requirements ([-1,1]^{d_x} vs. local neighborhood B(w*, δ)) and their impact on approximation quality for polynomial vs. non-polynomial target functions.