---
ver: rpa2
title: 'The Why Behind the Action: Unveiling Internal Drivers via Agentic Attribution'
arxiv_id: '2601.15075'
source_url: https://arxiv.org/abs/2601.15075
tags:
- agent
- attribution
- arxiv
- user
- agentic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work introduces a general agentic attribution framework to
  explain why LLM-based agents make specific decisions, moving beyond failure-focused
  analysis. The framework operates hierarchically: first using temporal likelihood
  dynamics to identify critical interaction components, then applying perturbation-based
  analysis to isolate key sentences within those components.'
---

# The Why Behind the Action: Unveiling Internal Drivers via Agentic Attribution

## Quick Facts
- **arXiv ID:** 2601.15075
- **Source URL:** https://arxiv.org/abs/2601.15075
- **Reference count:** 17
- **Primary result:** Introduces hierarchical agentic attribution framework achieving Hit@1 = 0.94 on 8 test cases

## Executive Summary
This work presents a general agentic attribution framework that explains why LLM-based agents make specific decisions by identifying pivotal interaction components and fine-grained textual evidence. Unlike prior work focused on failure analysis, this approach illuminates internal drivers behind both successful and unsuccessful agent actions. The framework operates hierarchically: first using temporal likelihood dynamics to identify critical interaction components, then applying perturbation-based analysis to isolate key sentences within those components. Evaluated on diverse scenarios including memory-driven decisions and tool-mediated reasoning, the framework reliably pinpoints pivotal historical events and textual evidence driving agent actions.

## Method Summary
The framework operates hierarchically to manage the complexity of agent interactions. At the component level, it employs temporal likelihood dynamics to identify critical interaction steps by computing log-likelihood of the final action conditioned on progressively longer trajectory prefixes. At the sentence level, it refines localization using perturbation-based analysis, computing necessity (Drop score) and sufficiency (Hold score) measures for each sentence within high-attribution components. The method combines these scores to identify pivotal textual evidence driving decisions, achieving Hit@1 = 0.94 on 8 curated test cases using Llama-3.1-70B-Instruct.

## Key Results
- Hierarchical framework achieves Hit@1 = 0.94 using default perturbation-based method
- Successfully identifies both high-level interaction components and fine-grained textual evidence
- Validated across 8 diverse test cases including memory-driven and tool-mediated scenarios
- Robust to alternative attribution instantiations and alternative scoring metrics

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Incrementally revealing interaction history allows identification of pivotal components that causally steer agent decisions.
- **Mechanism:** The framework computes log-likelihood of the final action conditioned on progressively longer trajectory prefixes. Components that induce sharp positive likelihood gains when introduced are flagged as decision drivers. Formally, temporal gain $g_i = \psi_i - \psi_{i-1}$ measures marginal contribution of component $C_i$ to action probability.
- **Core assumption:** Pivotal decisions manifest as discrete jumps in action likelihood rather than distributed contributions across many steps.
- **Evidence anchors:**
  - [abstract]: "at the component level, we employ temporal likelihood dynamics to identify critical interaction steps"
  - [Section 3.1]: "we track how the model's likelihood for $a_T$ changes when we incrementally reveal the trajectory component by component"
  - [corpus]: Related work on causal auditing (Project Ariadne, FMR=0.58) suggests structural causal frameworks for agent faithfulness, but does not validate the likelihood-gain approach directly.
- **Break condition:** If likelihood gains are uniformly distributed (no sharp transitions), the temporal signal degrades and component identification fails.

### Mechanism 2
- **Claim:** Perturbation-based sentence scoring isolates fine-grained textual evidence within high-impact components.
- **Mechanism:** For each sentence $s_{i,j}$ in a high-attribution component, compute two signals: (1) Drop score—likelihood decrease when sentence is ablated; (2) Hold score—likelihood when sentence is presented alone. Summing these yields necessity and sufficiency measures.
- **Core assumption:** Causal influence of a sentence on action generation can be approximated by counterfactual ablation without accounting for sentence interactions.
- **Evidence anchors:**
  - [abstract]: "at the sentence level, we refine this localization using perturbation-based analysis to isolate the specific textual evidence"
  - [Section 3.2, Eq. 13-15]: Formal definitions of Drop, Hold, and combined sentence score $\phi_{i,j}$
  - [corpus]: ContextCite (cited in paper) uses sparse linear surrogates for attribution; perturbation methods validated in RAG settings but not specifically for temporal agent trajectories.
- **Break condition:** If sentences have strong interaction effects (joint influence not decomposable), ablation-based scores become unreliable.

### Mechanism 3
- **Claim:** Hierarchical decomposition (component→sentence) manages attribution complexity without exhaustively scoring all context tokens.
- **Mechanism:** First-stage temporal analysis prunes to high-impact components; second-stage applies expensive perturbation only within those components. This coarse-to-fine approach avoids quadratic scaling with trajectory length.
- **Core assumption:** The pivotal component identified at stage 1 contains the causally relevant sentences; important evidence does not span multiple weakly-scored components.
- **Evidence anchors:**
  - [Section 3]: "Our framework operates hierarchically to manage the complexity of agent interactions"
  - [Table 1]: Hit@1 of 0.94 with default method suggests hierarchical pruning preserves accuracy
  - [corpus]: No direct corpus validation of hierarchical vs. flat attribution; assumption remains untested against joint multi-component evidence.
- **Break condition:** If the true decision driver is distributed across multiple low-scoring components (e.g., cumulative priming), the hierarchical filter discards evidence before sentence-level analysis.

## Foundational Learning

- **Concept: Log-likelihood dynamics in autoregressive models**
  - Why needed here: The component-level method requires computing $p(a_T | C_{\leq i})$—the probability of generating the action given partial context. Understanding how context conditioning affects next-token distributions is essential.
  - Quick check question: Given two context prefixes, how would you determine which makes a target token sequence more probable?

- **Concept: Counterfactual perturbation for attribution**
  - Why needed here: Sentence-level scores rely on ablating inputs and observing output shifts. This assumes access to model logits and controlled input manipulation.
  - Quick check question: If removing sentence A drops action probability by 0.3 and sentence B by 0.1, what can and cannot you conclude about their relative importance?

- **Concept: Agent trajectory formalization (observations, actions, memory, tools)**
  - Why needed here: The framework represents agent execution as structured component sequences with functional types (USER, THOUGHT, TOOL, OBS, MEMORY). Distinguishing these is necessary for correct attribution interpretation.
  - Quick check question: In a tool-calling agent, is the tool output an observation or an action in the formalism?

## Architecture Onboarding

- **Component map:** Trajectory parser -> Likelihood scorer -> Gain calculator -> Sentence tokenizer -> Perturbation engine -> Aggregation layer
- **Critical path:** Trajectory parsing → prefix likelihood computation (dominant cost: $O(T)$ forward passes) → gain ranking → selective perturbation (cost scales with high-impact component size, not full trajectory)
- **Design tradeoffs:**
  - Likelihood vs. embedding-based scoring: Likelihood captures token-level influence; embeddings may better capture semantic intent but lack calibrated probability interpretation
  - LOO perturbation vs. gradient saliency: LOO is model-agnostic but requires $O(N)$ forward passes per component; gradients are faster but may fail on long contexts (OOM noted in Table 1)
  - Single vs. multi-component sentence analysis: Current design analyzes sentences within one high-score component; could miss cross-component evidence
- **Failure signatures:**
  - Flat gain profile: All $g_i$ near zero suggests no decisive component; may indicate diffuse influence or insufficient context
  - Contradictory Drop/Hold: Sentence has high Drop (necessary) but negative Hold (not sufficient alone); indicates context-dependent contribution
  - Attribution to generic content: High scores for boilerplate (e.g., "I will help you") suggests weak signal; check for prompt contamination
- **First 3 experiments:**
  1. Reproduce Hit@1 on the paper's 8-case suite using Llama-3.1-70B-Instruct with the provided codebase; verify component-level and sentence-level rankings match reported case studies
  2. Ablate the hierarchical design: run sentence-level perturbation on ALL components (not just top-ranked) and measure Hit@k difference to quantify pruning error rate
  3. Stress-test on longer trajectories (10+ tool calls): measure whether temporal gain signal degrades and whether computation scales linearly as claimed

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does substituting the generative log-likelihood metric with embedding-based similarity or trained reward models affect the component-level attribution accuracy for capturing high-level semantic intent?
- **Basis in paper:** [explicit] Section 3.1 states, "We leave the exploration of these alternative scoring metrics to future work," regarding using embeddings or reward models instead of likelihood to compute $\psi_i$.
- **Why unresolved:** The current implementation relies solely on token probability dynamics, which may fail to capture semantic nuances or safety alignment as effectively as embedding similarity or reward models might.
- **What evidence would resolve it:** A comparative benchmark evaluating the alignment between human-judged semantic drivers and the critical components identified by these alternative metrics versus the default likelihood method.

### Open Question 2
- **Question:** Does the framework maintain high localization performance (e.g., Hit@1 > 0.9) when evaluated on a larger-scale, standardized benchmark of agent trajectories?
- **Basis in paper:** [explicit] Appendix A notes, "We hope this work may inspire the future work to construct larger-scale and more comprehensive datasets for general agentic attribution."
- **Why unresolved:** The current evaluation is limited to 8 carefully curated cases, which may not capture the full variance, noise, and complexity of real-world agentic interactions.
- **What evidence would resolve it:** Reporting quantitative metrics (Hit@k) from applying the framework to a public, large-scale agent benchmark containing hundreds of diverse trajectories.

### Open Question 3
- **Question:** How can the interpretation of attribution signals be automated to enable scalable analysis in real-world applications?
- **Basis in paper:** [explicit] The Impact Statement asserts, "further research is necessary to fully automate the interpretation of these attribution signals in large-scale, real-world applications."
- **Why unresolved:** The current work relies on qualitative case studies and small-scale human annotation for ground truth, which is insufficient for high-volume, autonomous deployment monitoring.
- **What evidence would resolve it:** An automated evaluation pipeline that can accurately categorize agent behaviors (e.g., benign vs. risky) based solely on the generated attribution patterns without human intervention.

## Limitations
- Framework assumes causal influence can be decomposed into independent component-level and sentence-level contributions
- Reliance on likelihood dynamics may not capture semantic nuances as effectively as embedding-based approaches
- Hierarchical pruning may discard evidence distributed across multiple weakly-scored components

## Confidence

- **High confidence**: The hierarchical framework design and its computational efficiency; the mathematical formulation of Drop/Hold scores; the Hit@1 = 0.94 result on the 8-case suite
- **Medium confidence**: The generalizability of the approach beyond curated test cases to real-world agent deployments; the assumption that the top-scoring component contains all relevant evidence; the claim that perturbation-based attribution captures true causal influence
- **Low confidence**: The framework's robustness to longer, more complex trajectories; the method's ability to handle distributed decision drivers spanning multiple components; the assumption that likelihood gains cleanly identify pivotal components without noise sensitivity

## Next Checks
1. Evaluate the framework on agent trajectories with known distributed decision drivers to test whether hierarchical pruning correctly retains all causally relevant components
2. Compare perturbation-based approach against gradient-based attribution methods where both are computationally feasible
3. Test performance degradation as trajectory length increases from 8 components to 20+ components, measuring whether temporal gain signals remain discriminative