---
ver: rpa2
title: 'RePCS: Diagnosing Data Memorization in LLM-Powered Retrieval-Augmented Generation'
arxiv_id: '2506.15513'
source_url: https://arxiv.org/abs/2506.15513
tags:
- repcs
- query
- ppara
- language
- queries
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces RePCS, a lightweight black-box method to\
  \ detect data memorization in retrieval-augmented generation (RAG) systems. RePCS\
  \ works by running the same language model twice\u2014once with retrieved passages\
  \ and once without\u2014and computing the Kullback-Leibler divergence between their\
  \ output distributions."
---

# RePCS: Diagnosing Data Memorization in LLM-Powered Retrieval-Augmented Generation

## Quick Facts
- arXiv ID: 2506.15513
- Source URL: https://arxiv.org/abs/2506.15513
- Reference count: 39
- Primary result: RePCS achieves ROC-AUC of 0.918 on Prompt-WNQA benchmark, outperforming prior methods by 6.5 percentage points with <4.7% latency overhead

## Executive Summary
RePCS introduces a lightweight, black-box method for detecting data memorization in retrieval-augmented generation (RAG) systems. The approach works by running the same language model twice—once with retrieved passages and once without—and computing the Kullback-Leibler divergence between their output distributions. A low divergence indicates the retrieved context had minimal impact, suggesting the model is relying on memorized training data rather than fresh evidence. The method is model-agnostic, requires no gradient or internal state access, and adds only one extra forward pass. On the Prompt-WNQA benchmark, RePCS achieves a ROC-AUC of 0.918, outperforming the strongest prior method by 6.5 percentage points, while keeping latency overhead below 4.7% on an NVIDIA T4 GPU.

## Method Summary
RePCS is a training-free, black-box detector that compares parametric LLM outputs with retrieval-augmented outputs using KL divergence. During calibration, the system runs ~500 clean prompts through both inference paths (with/without retrieval) and sets a threshold τ to the α-quantile of KL scores. At inference time, for each query, the LLM is run twice: once with the query alone (P_para) and once with query plus retrieved passages (P_rag). The KL divergence Z(q)=KL(P_rag||P_para) is computed, and queries with Z(q)<τ are flagged as potentially memorized. The method provides PAC-style statistical guarantees linking the threshold to user-specified false-positive and false-negative rates.

## Key Results
- ROC-AUC of 0.918 on Prompt-WNQA benchmark, outperforming strongest prior method by 6.5 percentage points
- Latency overhead of <4.7% on NVIDIA T4 GPU for real-time detection
- Theoretical guarantees provide finite-sample confidence bounds with user-specified FPR/FNR control
- Model-agnostic approach requiring only two forward passes without gradient access

## Why This Works (Mechanism)

### Mechanism 1
KL divergence between retrieval-augmented and parametric output distributions signals memorization when low. Compute Z(q) = KL(P_rag || P_para). When retrieved context is ignored, P_rag ≈ P_para, so Z(q) ≈ 0. A learned threshold τ flags queries with Z(q) < τ as memorized. Core assumption: Retrieved evidence should perturb the LLM's predictive distribution if it is being used.

### Mechanism 2
KL divergence collapses quadratically with the retrieval-influence coefficient η. Under mixture model P_rag = (1–η)P_para + ηQ, Theorem III.2 bounds Z(q) ≤ η²/(2(1–η)) for η ≤ 0.5. Small η (retrieval ignored) forces KL near zero. Core assumption: Linear superposition of transformer activations under context injection.

### Mechanism 3
PAC-style bounds link the KL threshold τ to user-specified FPR/FNR with finite-sample guarantees. Bounded per-token log-ratios yield sub-Gaussian KL scores (Lemma III.3). Massart's DKW bound + Hoeffding give Theorem III.4: n ≥ 8γ²TΔ⁻² log(2/ε) samples suffice for FPR ≤ α, FNR ≤ ε with probability ≥ 1–ε. Core assumption: Per-token log-ratios satisfy |log P_rag(i) – log P_para(i)| ≤ γ (finite precision).

## Foundational Learning

- Concept: Kullback–Leibler Divergence
  - Why needed here: Core detection statistic; interpreting RePCS requires understanding that KL(P||Q)=0 iff P=Q and KL increases monotonically with distributional difference.
  - Quick check question: Given two probability distributions P and Q, what does KL(P||Q) = 0 indicate?

- Concept: Retrieval-Augmented Generation (RAG) Paths
  - Why needed here: RePCS compares the parametric path (query alone) vs the retrieval-augmented path (query + passages); understanding both modes is essential.
  - Quick check question: In a RAG system, what happens when a query's answer already exists in the model's pre-training data?

- Concept: Sub-Gaussian Concentration
  - Why needed here: The finite-sample guarantees rely on sub-Gaussian tails of bounded log-ratios via Hoeffding/Massart inequalities.
  - Quick check question: Why is sub-Gaussianity useful for providing non-asymptotic confidence intervals with small sample sizes?

## Architecture Onboarding

- Component map:
  - Retriever R → top-K passages R(q)
  - LLM M → frozen, run twice
  - Parametric path: M(q) → P_para
  - Retrieval-augmented path: M(⟨q,R(q)⟩) → P_rag
  - KL scorer → Z(q) = KL(P_rag||P_para)
  - Threshold τ → flag if Z(q) < τ

- Critical path:
  1. Calibration (once): ~500 clean prompts → both paths → compute Z → set τ to α-quantile
  2. Inference (per query): Retrieve → run both paths → compute KL → compare to τ

- Design tradeoffs:
  - Latency vs. detection: +1 forward pass ≈ 4.7% overhead on T4 for real-time flagging
  - Threshold choice: lower τ → fewer false positives, higher false negatives
  - Calibration set: must be uncontaminated; re-calibrate if retriever or LLM changes

- Failure signatures:
  - High FPR: τ too high or calibration set contaminated
  - High FNR: τ too low or influence gap Δ too small
  - Noisy Z(q): check log-ratio bounds; consider increasing inspected token length T
  - Retriever change: prior τ may be invalid → re-calibrate

- First 3 experiments:
  1. Validate calibration: run RePCS on held-out clean queries; verify empirical FPR ≤ α
  2. Threshold ablation: sweep τ (1st/5th/10th percentiles) and plot ROC to pick operating point
  3. Latency profiling: measure end-to-end overhead on target hardware; if >5%, profile retriever or batch the two forward passes

## Open Questions the Paper Calls Out

### Open Question 1
How can the detection threshold τ be dynamically updated when query distributions or retrieval corpora drift over time? The current approach requires one-time calibration on clean prompts, but real deployments face shifting query patterns and evolving knowledge bases. Future research will develop online calibration under concept drift.

### Open Question 2
Does RePCS generalize to multi-modal RAG systems where retrieved evidence includes images, tables, or audio? The KL divergence computation assumes token-probability tensors over a text vocabulary. Multi-modal inputs require defining comparable probability distributions across modalities, which the current framework does not address.

### Open Question 3
How does RePCS perform across domains beyond wireless networking, and what factors predict cross-domain transferability? All experiments use Prompt-WNQA (wireless network reasoning). The influence gap Δ may vary by domain complexity, retrieval corpus structure, or factual density.

### Open Question 4
Can adversaries craft queries that evade RePCS detection while still exploiting memorized content? Theorem III.5 shows robustness to adaptive querying where attackers observe KL scores but not logits. However, the paper does not explore adversarial prompting strategies designed to artificially inflate KL divergence without genuine retrieval grounding.

## Limitations
- Performance depends heavily on retrieval relevance; off-topic passages may cause false memorization flags
- Quadratic KL bound relies on linear superposition assumption that may not hold for all model architectures
- Requires 500+ uncontaminated calibration prompts, which may be impractical for specialized domains
- Cannot distinguish between genuine parametric knowledge, hallucination, or outdated information

## Confidence
- Mechanism 1 (KL divergence as memorization signal): High confidence - Sound theoretical foundation with strong empirical ROC-AUC
- Mechanism 2 (Quadratic KL bound under mixture model): Medium confidence - Linear superposition is "widely observed" but not rigorously validated
- Mechanism 3 (PAC-style statistical guarantees): Medium confidence - Mathematical derivation is correct but depends on log-ratio bound assumptions
- Overall practical utility: High confidence - Implementable with minimal latency and demonstrable performance gains

## Next Checks
1. **Calibration contamination audit**: Run RePCS on held-out clean queries from multiple domains to verify empirical false-positive rate ≤ α (0.05). Test with different calibration set sizes (100, 500, 1000) to establish minimum requirements.

2. **Non-linear behavior stress test**: Design queries where retrieval should have subtle but non-linear effects on model behavior (e.g., stylistic changes, tone adjustments). Measure whether RePCS correctly identifies these as retrieval-influenced vs. false memorization flags.

3. **Cross-domain generalization**: Apply RePCS trained on Prompt-WNQA to a completely different RAG application (e.g., medical Q&A or legal document analysis). Measure ROC-AUC drop and analyze failure modes specific to the new domain.