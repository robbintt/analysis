---
ver: rpa2
title: 'DPERC: Direct Parameter Estimation for Mixed Data'
arxiv_id: '2501.10540'
source_url: https://arxiv.org/abs/2501.10540
tags:
- data
- missing
- matrix
- estimation
- covariance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DPERC, a method for estimating covariance
  matrices from mixed data with missing values in continuous features. DPERC improves
  upon the DPER algorithm by leveraging information from categorical features.
---

# DPERC: Direct Parameter Estimation for Mixed Data

## Quick Facts
- arXiv ID: 2501.10540
- Source URL: https://arxiv.org/abs/2501.10540
- Reference count: 37
- Primary result: DPERC achieved lowest estimation error on mixed data with missing values, improving over DPER by 0.5%-2.5% in most cases

## Executive Summary
DPERC introduces a direct parameter estimation method for mixed data with missing values in continuous features. The key innovation leverages categorical features by selecting one that minimizes weighted average pairwise distance, then treating it as a class feature for covariance estimation. The method was evaluated on four UCI datasets with missing rates from 20% to 80%, achieving superior performance compared to state-of-the-art methods including missForest, KNNI, Soft-Impute, and MICE.

## Method Summary
DPERC builds on the DPER algorithm by incorporating categorical feature information to improve covariance matrix estimation. The method first computes a baseline covariance matrix using DPER, then iteratively selects the optimal categorical feature based on minimizing a distance metric derived from the preliminary estimate. This selected feature is treated as an artificial class label, and the multi-class DPER algorithm is applied assuming equal covariance matrices across categories. The method solves polynomial equations to directly estimate covariance entries without imputation, improving computational efficiency and avoiding error accumulation.

## Key Results
- On Statlog dataset with 80% missing data, DPERC achieved error rate of 0.300 compared to 0.408 for MICE
- DPERC improved upon DPER by 0.5% to 2.5% in most experimental cases
- Correlation heatmap analysis showed DPERC and DPER produced estimates closest to ground truth
- DPERC demonstrated superior performance across all tested missing rates (20%-80%) on four UCI datasets

## Why This Works (Mechanism)

### Mechanism 1: Categorical Stratification for MLE
The method partitions continuous data based on categories of a selected feature, applying multi-class DPER with equal covariance assumption across partitions. This leverages stratification to reduce estimation variance by transforming a single-class problem into multi-class estimation.

### Mechanism 2: Likelihood-Maximizing Feature Selection
The algorithm calculates distance metrics for every categorical feature and selects the one minimizing this distance, which Theorem 4.1 links to maximizing log-likelihood. This ensures the selected feature provides optimal structure for covariance estimation.

### Mechanism 3: Direct Pairwise Estimation
By solving polynomial equations derived from MLE rather than using imputation, the method avoids error accumulation and computational overhead of two-step pipelines. This direct approach estimates covariance entries by maximizing likelihood of observed patterns.

## Foundational Learning

**Multivariate Normality & MLE**
- Why needed: Theoretical derivation (Theorems 3.1, 3.3, 4.1) relies on Normal distribution density to construct likelihood function
- Quick check: Can you explain why maximizing likelihood requires taking logarithm and differentiating with respect to σ_ij?

**Homoscedasticity (Equal Covariance)**
- Why needed: The paper explicitly assumes equal covariance matrices across artificial classes to pool data effectively
- Quick check: If you plot continuous features colored by categorical feature, should cluster "shape" look same or different?

**Frobenius Norm**
- Why needed: Primary metric (e and r) used to quantify error between estimated matrix and ground truth
- Quick check: How does Frobenius norm summarize entire matrix error into single scalar value?

## Architecture Onboarding

**Component map:** Input (mixed data matrix) -> Initializer (DPER baseline) -> Selector (categorical feature loop) -> Estimator (multi-class DPER) -> Output (final covariance matrix)

**Critical path:** Estimation of off-diagonal elements σ_ij (Algorithm 1, Step 5 / Algorithm 2, Step 5) requires solving cubic polynomial. If solver fails or returns complex roots, pipeline breaks.

**Design tradeoffs:** Accuracy vs Stability - gains accuracy over DPER (0.5%-2.5%) by exploiting categorical info but introduces dependency on equal covariance assumption. Computation - avoids iterative imputation but requires polynomial solve for every feature pair.

**Failure signatures:** High Error on Diagonals indicates variance calculation instability at high missing rates > 80%. No Improvement over DPER suggests categorical features are uninformative or equal covariance assumption is false.

**First 3 experiments:**
1. Sanity Check: Run DPERC on Statlog dataset with 80% missingness, verify error near 0.300
2. Ablation Study: Disable Selector component to measure contribution of likelihood-based selection
3. Assumption Stress Test: Generate synthetic data with vastly different covariance structures across categorical classes, compare against standard DPER

## Open Questions the Paper Calls Out

**Open Question 1:** Can modified selection criterion identify optimal categorical feature when inter-class distances (Δ(g)) dominate intra-class distances (d_c^(g))? The current heuristic may be suboptimal when class means are highly dispersed relative to internal variance.

**Open Question 2:** How can DPERC be adapted to handle missing values in categorical features or class labels used for grouping? Current algorithm assumes fully observed categorical features.

**Open Question 3:** Does extending DPERC to multi-class data under equal covariance assumption provide superior computational efficiency or accuracy? Current multi-class approach applies single-class logic repeatedly without exploiting equal covariance constraint.

## Limitations

- Relies on equal covariance assumption across artificial classes, which may not hold in practice
- Polynomial root selection method may introduce numerical instability at high missing rates
- Performance depends heavily on informativeness of available categorical features
- No empirical validation of equal covariance assumption or robustness analysis

## Confidence

- **High Confidence:** Core mechanism of direct parameter estimation and mathematical derivation of polynomial equations
- **Medium Confidence:** Effectiveness of categorical feature selection mechanism and comparative performance results
- **Low Confidence:** Stability under violations of equal covariance assumption and generalizability to different missingness mechanisms

## Next Checks

1. **Assumption Validation:** Generate synthetic datasets with controlled covariance heterogeneity across categorical groups to test if equal covariance assumption is critical for performance gains

2. **Robustness Analysis:** Evaluate DPERC on datasets where selected categorical feature has minimal correlation with continuous features to measure selection mechanism contribution

3. **Missingness Mechanism Test:** Compare DPERC performance under MCAR, MAR, and MNAR missingness patterns to verify sensitivity to different mechanisms