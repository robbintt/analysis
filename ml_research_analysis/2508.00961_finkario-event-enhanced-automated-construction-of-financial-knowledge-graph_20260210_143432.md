---
ver: rpa2
title: 'FinKario: Event-Enhanced Automated Construction of Financial Knowledge Graph'
arxiv_id: '2508.00961'
source_url: https://arxiv.org/abs/2508.00961
tags:
- financial
- knowledge
- graph
- finkario
- event
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the challenge of enhancing individual investors\u2019\
  \ decision-making in financial markets, where they are disadvantaged by abundant\
  \ information and lack of professional analysis. The authors propose FinKario, an\
  \ event-enhanced automated construction of financial knowledge graph that integrates\
  \ real-time company fundamentals and market events from equity research reports."
---

# FinKario: Event-Enhanced Automated Construction of Financial Knowledge Graph

## Quick Facts
- arXiv ID: 2508.00961
- Source URL: https://arxiv.org/abs/2508.00961
- Reference count: 40
- Primary result: Dual-graph RAG system achieves 58.1% accuracy, outperforming baselines by 18.81-17.85% in stock prediction

## Executive Summary
FinKario addresses the information asymmetry faced by individual investors by constructing an automated financial knowledge graph that integrates company fundamentals and market events from equity research reports. The system employs professional institutional templates to guide LLM extraction, creating a dual-structured graph separating static attributes from dynamic events. A two-stage graph-based retrieval strategy (FinKario-RAG) then leverages this knowledge to achieve superior stock trend prediction accuracy, demonstrating significant improvements over both financial LLMs and institutional strategies in backtesting.

## Method Summary
The method constructs a dual financial knowledge graph by first extracting entities and relations from equity research reports using LLM-guided prompts constrained by professional templates (CFA handbook, FIBO ontology). The graph separates into an Attribute Graph (static company fundamentals) and an Event Graph (time-sensitive market drivers). Quality control involves normalization, external data completion via Tushare, and error correction. FinKario-RAG implements a two-stage retrieval: coarse retrieval identifies stocks and dates, then fine retrieval reconstructs subgraphs to preserve semantic relationships. The system uses GPT-4o-mini for extraction, reasoning, and embeddings, with long-only weekly backtesting on Chinese market data.

## Key Results
- 58.1% accuracy in stock trend prediction
- 18.81% improvement over financial LLMs
- 17.85% improvement over institutional strategies
- 58.14% improvement in Sharpe ratio (4.926 vs baseline)

## Why This Works (Mechanism)

### Mechanism 1
Separating financial knowledge into static "Attribute" and dynamic "Event" graphs allows the system to capture both structural identity and temporal drivers. The architecture constructs two distinct subgraphs: the Attribute Graph stores stable data (industry, exchange), while the Event Graph captures time-sensitive drivers (strategic actions, earnings releases) extracted from reports. This division allows the reasoning model to weigh recent causal factors against fundamental stability. Break condition: If market volatility is driven purely by macroeconomic factors unrelated to company-specific events, the Event Graph may introduce noise.

### Mechanism 2
Using professional institutional templates (CFA, FIBO) to guide LLM extraction improves schema relevance and reduces hallucination. Rather than arbitrary relation definition, the system injects authoritative domain templates into prompts, constraining the LLM to generate schemas and extract entities aligned with established financial analysis standards. Break condition: If source reports deviate significantly from standard templates, rigid schema guidance may fail to capture novel insights.

### Mechanism 3
A two-stage retrieval strategy (Coarse-to-Fine) outperforms vanilla RAG by ensuring retrieved context includes related entities and semantic structures, not just text chunks. The retrieval first identifies coarse anchors (stocks, dates) and then expands to fine-grained graph elements to reconstruct a subgraph, preserving holistic financial context and semantic links lost in chunk-based retrieval. Break condition: If the query is highly specific requiring only isolated facts, two-stage expansion may retrieve irrelevant noise.

## Foundational Learning

- **Knowledge Graph Construction (Entity-Relation-Triples)**: Why needed - The core output is a structured graph ($G_{FinKario}$). Quick check - Can you distinguish between an "Attribute" triple (e.g., BYD, Industry, Auto) and an "Event" triple (e.g., BYD, Expands, Overseas)?

- **Retrieval-Augmented Generation (RAG)**: Why needed - FinKario-RAG is a specialized RAG system. Quick check - Why would searching for text chunks about "BYD revenue" miss the context that "CATL is a supplier," whereas a graph search might catch it?

- **Prompt Engineering with Schema Constraints**: Why needed - The method relies on "Schema-guided extraction." Quick check - How does providing a "Schema" in the prompt differ from simply asking the model to "extract important information"?

## Architecture Onboarding

- **Component map**: Ingestion (East Money Reports → MinerU → Refinement) → Schema Module (LLM + CFA/FIBO Templates → Attribute/Event Schemas) → Graph Builder (LLM + Schemas + Reports → Raw Triples) → Quality Control (Tushare + LLM Correction → Clean Graph) → FinKario-RAG (Vector Store → Coarse Retrieval → Fine Retrieval → LLM Analyst)

- **Critical path**: The Knowledge Population and Quality Control loop. If the LLM extracts incorrect entities or normalization fails, the graph becomes noisy, degrading RAG performance regardless of retrieval algorithm.

- **Design tradeoffs**: Dual Graph vs. Single Graph increases complexity but allows independent updates and clearer semantic querying. LLM vs. Rule-based Extraction allows handling diverse report formats but introduces hallucination risks, necessitating heavy Quality Control.

- **Failure signatures**: Stale Graph if Dynamic Update fails, leading to outdated predictions. Entity Ambiguity if "BYD" and "BYD Auto" aren't normalized to a single node, causing fragmented subgraph retrieval.

- **First 3 experiments**: 1) Unit Test Extraction: Feed 5 diverse reports into Schema Module, verify correct identification of 11 attribute types and 8 event categories without hallucination. 2) Graph Validation: Run Quality Control pipeline, check if "placeholder" errors are successfully corrected and units normalized. 3) Retrieval Isolation: Compare Vanilla RAG vs. FinKario-RAG on 10 queries, check if FinKario-RAG retrieves competitor/supplier relationships that Vanilla RAG misses.

## Open Questions the Paper Calls Out

1. **Multi-modal integration**: How does incorporating multi-modal financial inputs (tables, charts, time-series) impact predictive accuracy and retrieval robustness? The current implementation uses only textual markdown, ignoring visual and structured quantitative data.

2. **Schema limitations**: To what extent does the schema construction method using static professional templates limit the system's ability to identify novel or unprecedented financial event types? The system may be biased against unknown event categories.

3. **Cross-market generalization**: Can the FinKario construction and retrieval strategy maintain performance when applied to markets with different reporting standards (US GAAP) or languages? The current evaluation is exclusively on Chinese reports and indices.

## Limitations
- Experimental validation focuses on Chinese market data, limiting generalizability
- Heavy reliance on GPT-4o-mini introduces potential brittleness with different models
- Dual-graph architecture complexity lacks ablation studies demonstrating necessity
- Performance improvements lack statistical significance testing across market regimes

## Confidence

**High Confidence**: Dual-graph architecture design is well-specified and theoretically sound for capturing both stable fundamentals and time-sensitive events. Two-stage retrieval mechanism is clearly described and implementable.

**Medium Confidence**: 18.81% improvement over financial LLMs and 17.85% over institutional strategies is reported but lacks detailed baseline methodology and statistical validation. Professional template guidance reducing hallucination is plausible but not directly tested.

**Low Confidence**: System's robustness to report format variations and performance outside Chinese market context remain largely untested assumptions.

## Next Checks

1. **Ablation Study**: Remove the Event Graph entirely and compare prediction accuracy to quantify the contribution of event-driven signals versus static attributes.

2. **Generalization Test**: Apply FinKario pipeline to English-language financial reports from US market and measure performance degradation or adaptation requirements.

3. **Statistical Significance**: Conduct t-tests or bootstrap confidence intervals on backtesting results across multiple time periods to verify that accuracy and Sharpe ratio improvements are statistically significant rather than due to favorable market conditions.