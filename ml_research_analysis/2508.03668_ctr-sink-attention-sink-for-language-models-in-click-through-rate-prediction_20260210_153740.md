---
ver: rpa2
title: 'CTR-Sink: Attention Sink for Language Models in Click-Through Rate Prediction'
arxiv_id: '2508.03668'
source_url: https://arxiv.org/abs/2508.03668
tags:
- attention
- sink
- tokens
- arxiv
- behavior
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of semantic fragmentation in language
  model-based click-through rate prediction, where user behavior sequences lack the
  coherent structure of natural language, causing attention to scatter and degrade
  performance. The core method introduces CTR-Sink, a framework that inserts recommendation-specific
  sink tokens (e.g., fused with temporal distance) between user behaviors to act as
  attention anchors, supplemented by a two-stage training strategy and a sink-specific
  attention enhancement mechanism.
---

# CTR-Sink: Attention Sink for Language Models in Click-Through Rate Prediction

## Quick Facts
- **arXiv ID:** 2508.03668
- **Source URL:** https://arxiv.org/abs/2508.03668
- **Reference count:** 40
- **Primary result:** Inserts temporal-distance-fused sink tokens between user behaviors to aggregate attention and improve CTR prediction AUC by 0.2-0.5% over LM baselines.

## Executive Summary
CTR-Sink addresses semantic fragmentation in language model-based click-through rate prediction by inserting recommendation-specific sink tokens between user behaviors. These tokens act as attention anchors, aggregating information and mitigating the structural mismatch between coherent natural language and semantically sparse behavioral sequences. Experiments on MovieLens and KuaiRec datasets show consistent AUC improvements across RoBERTa and Qwen architectures, validating the effectiveness of the approach in improving CTR prediction.

## Method Summary
CTR-Sink inserts special [SINK] tokens between user behaviors, where each sink token incorporates temporal distance information through an MLP-fused embedding. The framework includes a two-stage training strategy for decoder models (first training on sinks only, then full sequence) and a sink-specific attention enhancement mechanism that adds a bias matrix to boost inter-sink dependencies. The method is evaluated on RoBERTa (encoder) and Qwen (decoder) models using AUC as the primary metric.

## Key Results
- Improves AUC by 0.2-0.5% over baseline LM-CTR methods on MovieLens and KuaiRec datasets
- Sink tokens with temporal distance outperform those with semantic similarity or random information
- Two-stage training strategy provides significant benefits for decoder models but minimal impact on encoders
- Sink-specific attention enhancement increases proportion of attention between sink tokens in deeper layers

## Why This Works (Mechanism)

### Mechanism 1: Sink Token Insertion as Attention Anchors
Inserting special [SINK] tokens between user behaviors mitigates attention scatter caused by the structural mismatch between coherent natural language and semantically sparse behavioral sequences. The model is forced to allocate attention to explicit sink tokens fused with temporal information during training, creating stable "landmark" points that aggregate attention and allow the model to segment the sequence by behavioral units.

### Mechanism 2: Two-Stage Training Strategy
A two-stage training strategy first trains only on sink tokens then on the full sequence, improving a decoder model's ability to utilize attention sinks. The first stage constrains the model to learn CTR prediction using only [SINK] token representations, forcing it to attend to and aggregate information at these locations. The second stage then uses full sequence information, retaining the attention patterns learned in the first stage.

### Mechanism 3: Sink-Specific Attention Enhancement Mechanism
Adding a bias to the attention weights between sink tokens better captures inter-behavior correlations. An independent self-attention mechanism calculates a bias matrix specifically for the [SINK] tokens, which is scattered into the full attention matrix, boosting attention scores between sinks in deeper layers.

## Foundational Learning

- **Attention Sink Theory**: Transformers tend to allocate disproportionate attention to certain "sink" tokens (often the first token or special tokens) to stabilize computations. Understanding this principle is essential for grasping why CTR-Sink inserts explicit sink tokens.
  - *Quick check question:* Explain why the paper's authors hypothesize that user behavior sequences cause "semantic fragmentation" in a standard LM.

- **Language Model Pre-training vs. Downstream Structured Data**: LMs are pre-trained on coherent, grammatical natural language, while user behavior sequences are discrete, unstructured events with no grammatical relationships. This fundamental mismatch explains why direct LM application fails for CTR prediction.
  - *Quick check question:* What is the key structural difference between the data an LM is typically pre-trained on and the user behavior sequences used in this paper?

- **Encoder vs. Decoder Architectures for CTR**: The paper's solution has different effects on encoder (RoBERTa) and decoder (Qwen) models due to their inherent differences. Encoders like BERT have a [CLS] token that acts as a sink, while decoders do not.
  - *Quick check question:* Why does the two-stage training strategy provide a greater benefit to the decoder (Qwen) model compared to the encoder (RoBERTa)?

## Architecture Onboarding

- **Component map:** Input Layer -> [SINK] Token Generator -> Base LM -> Attention Bias Module -> Attention Fusion -> Prediction Head
- **Critical path:** 1) Retrieve user behaviors 2) Generate [SINK] tokens with temporal distance 3) Insert sinks between behaviors 4) Feed modified sequence to LM 5) Compute attention bias for sinks 6) Fuse bias with raw attention 7) Predict CTR via final MLP layer
- **Design tradeoffs:**
  - Information Fused into Sink: Temporal distance is effective but other signals (semantic similarity) could also be used. Richer information may improve performance but increases token complexity.
  - Two-Stage vs. End-to-End Training: Two-stage training is more effective for decoders but doubles training epochs. Higher performance vs. increased training time and complexity.
  - Sink-Specific Attention Mechanism: Adds new attention layer and fusion step. Better inter-behavior modeling vs. increased model parameters and computational cost.
- **Failure signatures:**
  - Model fails to improve with [SINK] tokens: External information (temporal distance) may not be relevant for the dataset. Try semantic similarity or learned embedding without explicit features.
  - Decoder model still underperforms after two-stage training: "First-token bias" may be too strong. Investigate positional embeddings or other training strategies.
  - Performance degrades on longer sequences: Attention bias may not be generalizing. Check if number of sink tokens scales appropriately with sequence length.
- **First 3 experiments:**
  1. Ablation Study on Sink Information: Train with sinks containing temporal distance, semantic similarity, and random/no information. Compare AUC to validate importance of meaningful external signals.
  2. Attention Visualization with and without Two-Stage Training: Visualize attention heatmap of decoder model trained end-to-end vs. with two-stage strategy. Measure proportion of attention at [SINK] tokens.
  3. Scalability Test on Sequence Length: Run on datasets with varying numbers of user behaviors (20, 30, 40, 50) and compare performance trend against baseline.

## Open Questions the Paper Calls Out

- **Multi-modal adaptation**: How can CTR-Sink be effectively adapted to model multi-modal user behavior sequences? The current study focuses exclusively on textual representations.
- **Computational efficiency**: Can the computational efficiency of CTR-Sink be optimized for ultra-long user behavior sequences? The sink-specific attention enhancement adds computational overhead.
- **Model scale dependency**: Does the effectiveness of attention sinks diminish as the language model scale increases? Experiments were limited to RoBERTa and Qwen-0.5B, leaving the interaction between model capacity and sink effectiveness unexplored.

## Limitations

- **Generalizability Across Datasets**: Results validated on MovieLens and KuaiRec with structured temporal metadata; effectiveness of temporal distance may not generalize to datasets where this signal is weaker or absent.
- **Model Architecture Dependency**: Two-stage training strategy is critical for decoder models but has minimal impact on encoders, suggesting the approach is not a universal solution for all LM architectures.
- **Scalability and Efficiency**: Sink-specific attention enhancement mechanism introduces additional attention layer, increasing computational cost without reporting exact increase in training time or inference latency.

## Confidence

- **High Confidence**: The core hypothesis that user behavior sequences cause "semantic fragmentation" in LMs, and that inserting sink tokens with meaningful external information can mitigate this and improve CTR prediction.
- **Medium Confidence**: The two-stage training strategy is effective for decoder models. While ablation results are clear, the explanation for why this is specifically needed for decoders is based on observed behavior rather than deep theoretical understanding.
- **Medium Confidence**: The sink-specific attention enhancement mechanism amplifies inter-sink dependencies. Evidence shows increased attention between sinks in deeper layers, but the paper does not prove this directly translates to better semantic understanding or CTR performance.

## Next Checks

1. **Ablation Study on External Sink Signals**: Conduct controlled experiment training CTR-Sink with sink tokens containing temporal distance (current), semantic similarity (from Sentence-BERT), and no external information (random or learned embedding) to test necessity and sufficiency of temporal signal.

2. **Attention Pattern Analysis on Decoders**: Perform detailed attention visualization study training Qwen with and without two-stage strategy, then visualize and quantify proportion of attention mass allocated to [SINK] tokens versus first token and behavior tokens.

3. **Scalability Test on Sequence Length and Dataset Size**: Systematically evaluate CTR-Sink on user behavior sequences of increasing length (10, 20, 30, 40 behaviors) and on datasets of varying sparsity and size, measuring both AUC performance and per-epoch training time.