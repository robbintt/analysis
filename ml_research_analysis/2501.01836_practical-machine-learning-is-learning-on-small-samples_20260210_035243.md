---
ver: rpa2
title: Practical machine learning is learning on small samples
arxiv_id: '2501.01836'
source_url: https://arxiv.org/abs/2501.01836
tags:
- learning
- problem
- case
- learner
- practical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes a practical learning paradigm for machine\
  \ learning based on the assumption that underlying dependencies are relatively \"\
  smooth\"\u2014meaning there are no abrupt differences in feedback between cases\
  \ with similar features. The paradigm defines learners by their selection of baseline\
  \ cases and their counterparts, and evaluates hypotheses by their \"inconsistency\"\
  \ with the training data."
---

# Practical machine learning is learning on small samples

## Quick Facts
- arXiv ID: 2501.01836
- Source URL: https://arxiv.org/abs/2501.01836
- Reference count: 15
- Primary result: This paper proposes a unified practical learning paradigm based on minimizing inconsistency between observations and hypothetical cases, reframing ML as logical abduction rather than statistical inference.

## Executive Summary
This paper introduces a practical learning paradigm that unifies diverse machine learning algorithms (k-NN, decision trees, Naive Bayes, SVM) under a single framework based on minimizing inconsistency between observations and hypothetical cases. The paradigm assumes the underlying dependence is "smooth" - meaning there are no abrupt differences in feedback between cases with similar features. By reframing machine learning as logical abduction rather than statistical inference, the approach allows addressing practical questions about learner selection, testing, outliers, and data sufficiency that are meaningless in traditional statistical learning theory.

## Method Summary
The method defines learners by their selection of baseline cases and their counterparts, then evaluates hypotheses by their "inconsistency" with the training data. Each learner is characterized by four components: (1) baseline cases H(f,T) from observations or hypotheticals, (2) counterparts ξ(α,f) that should be similar to baseline cases, (3) case-inconsistency μ(α,v) measuring similarity violation, and (4) total inconsistency Λ(f,T,v) to minimize. The paper demonstrates that popular learners can all be described within this paradigm as implementations of the same core concept.

## Key Results
- Popular learners (k-NN, decision trees, Naive Bayes, SVM for classification and regression) can all be described within the same paradigm based on minimizing inconsistency
- The paradigm reframes machine learning as logical abduction rather than statistical inference, enabling practical questions about learner selection and testing
- SVM's regularization term represents inconsistency among hypothetical cases themselves, not just between observations and hypotheses

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Practical ML generalizes from small samples because it implicitly assumes the underlying dependence is "smooth"
- Mechanism: The learner selects hypotheses that "smoothly approximate" the training set by minimizing quantifiable inconsistency between observations and hypothetical cases
- Core assumption: The underlying dependence has no abrupt differences in feedback between cases with close data points
- Evidence anchors: Section 1 formally states that similar features imply similar feedback
- Break condition: If the true dependence has discontinuities or the smoothness assumption is violated, the paradigm's justification fails

### Mechanism 2
- Claim: Diverse learners are unified by viewing them as minimizing inconsistency between baseline cases and their counterparts
- Mechanism: Each learner defines baseline cases, counterparts, case-inconsistency, and total inconsistency to minimize
- Core assumption: Lower inconsistency between baseline cases and counterparts indicates better representation of the underlying dependence
- Evidence anchors: Sections 4-9 show each learner fits this structure with explicit mappings
- Break condition: If a learner cannot be expressed with this tuple structure, it falls outside the paradigm

### Mechanism 3
- Claim: Regularization terms in SVM/SVR represent inconsistency among hypothetical cases themselves
- Mechanism: SVM criterion includes a regularization term that measures derivative of the hypothesis
- Core assumption: Both types of inconsistency (observation-hypothetical and hypothetical-hypothetical) must be minimized
- Evidence anchors: Section 8 shows the regularization directly evaluates derivative of the hypothesis
- Break condition: If regularization has a fundamentally different purpose, this interpretation is incomplete

## Foundational Learning

- **Concept: Cases, Observations, and Hypotheticals**
  - Why needed here: The paradigm's core operation is comparing baseline cases to counterparts, where cases are pairs ⟨x, y⟩
  - Quick check question: Given hypothesis f(x) = 2x and observation ⟨3, 5⟩, what is the corresponding hypothetical case? ⟨3, 6⟩

- **Concept: Baseline Cases vs. Counterparts**
  - Why needed here: Every learner in the paradigm defines which cases are "baseline" (the reference) and which are "counterparts" (what they should resemble)
  - Quick check question: In k-NN, are the baseline cases observations or hypotheticals? What about in ERM?

- **Concept: Abduction vs. Induction**
  - Why needed here: The paper argues ML is abduction (selecting a hypothesis explaining observations), not induction (extending known properties)
  - Quick check question: If you observe {⟨1,2⟩, ⟨2,4⟩, ⟨3,6⟩} and select hypothesis f(x) = 2x, is the selection act induction or abduction?

## Architecture Onboarding

- **Component map:**
  Problem Statement P = {X, Y, F, v} → Training Set T → Baseline Cases H(f,T) → Counterparts ξ(α,f) → Case-Inconsistency μ(α,v) → Total Inconsistency Λ(f,T,v) → Solution: f = argmin Λ(h,T,v)

- **Critical path:**
  1. Identify which cases are baseline (observations in ERM/SVM; hypotheticals in k-NN/smoothing)
  2. Define counterpart selection rule (nearest neighbors, leaf membership, feature matching)
  3. Choose inconsistency measure (absolute difference, 0-1 loss, ε-insensitive)
  4. Aggregate to total inconsistency (sum, product, weighted combination)
  5. Search hypothesis space for minimum

- **Design tradeoffs:**
  - Baseline = observations → risk of overfitting; Baseline = hypotheticals → smoother but may miss data patterns
  - Many counterparts → robust to noise but may blur boundaries; Few counterparts → sensitive to local structure
  - Ignoring small errors (SVM ε-tube) → robust to noise but may miss genuine small signals

- **Failure signatures:**
  - High inconsistency on training set but low on test: hypothesis class too restricted
  - Low training inconsistency, high test inconsistency: overfitting from narrow counterpart selection
  - Inconsistency dominated by few cases: outliers or violated smoothness assumption

- **First 3 experiments:**
  1. Implement the paradigm for a new learner (e.g., kernel regression) by explicitly defining H, ξ, μ, Λ—verify it matches standard implementations
  2. Compare learners by their inconsistency profiles on the same dataset—test whether this provides meaningful selection guidance beyond accuracy
  3. Generate synthetic data with controlled smoothness violations (discontinuities) and measure how each learner's total inconsistency relates to generalization error

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can unsupervised learning algorithms, specifically clustering methods, be formalized as minimizing "inconsistency" within the Practical learning paradigm?
- Basis in paper: The author states, "In the next articles I plan to show that popular learners for other machine learning problems (clustering, for example) can be explained within the Practical learning paradigm."
- Why unresolved: The current paper only demonstrates the paradigm using supervised examples where feedback (y) is observed
- What evidence would resolve it: A formal derivation showing that minimizing a specific inconsistency function Λ on unlabeled data recovers standard clustering algorithms like k-means

### Open Question 2
- Question: Under what specific data conditions is the Support Vector Machine (SVM) strategy of ignoring small errors (treating them as noise) optimal compared to strategies that ignore large errors (outliers)?
- Basis in paper: Section 8 asks, "But when is this an optimal strategy?" regarding SVM's error handling
- Why unresolved: The paper describes the mechanism but does not provide a theoretical criterion for choosing between ignoring small errors versus ignoring large errors
- What evidence would resolve it: A comparative analysis of error-distribution assumptions that defines boundary conditions where "ignoring small errors" outperforms "ignoring large errors"

### Open Question 3
- Question: Can the terminology and rules of the Practical learning paradigm be expanded into a complete "formal system" or logical language for machine learning?
- Basis in paper: The author notes that the paradigm is a "rough approximation to a formal system and a language of a learning logic"
- Why unresolved: The paper currently provides definitions and examples but lacks the axiomatic structure characteristic of a formal logical system
- What evidence would resolve it: A formalization of the "Implicit learning assumptions" into a set of logical axioms capable of deriving new learning algorithms

## Limitations
- No experimental validation on real datasets to demonstrate practical advantages over existing frameworks
- The smoothness assumption's empirical prevalence is asserted but not quantified
- The paradigm's scalability to modern deep learning architectures remains unexplored

## Confidence
- Theoretical coherence: High
- Practical utility: Medium
- Empirical validation: Low

## Next Checks
1. Implement the paradigm for kernel regression and compare its inconsistency profile with standard implementations on synthetic data
2. Measure how violations of the smoothness assumption (discontinuities) affect each learner's total inconsistency and generalization error
3. Empirically test whether selecting learners based on training set inconsistency correlates with test performance across diverse datasets