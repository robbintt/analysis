---
ver: rpa2
title: 'Proxy-FDA: Proxy-based Feature Distribution Alignment for Fine-tuning Vision
  Foundation Models without Forgetting'
arxiv_id: '2505.24088'
source_url: https://arxiv.org/abs/2505.24088
tags:
- proxy-fda
- feature
- fine-tuning
- forgetting
- class
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Proxy-FDA, a novel regularization method
  that addresses concept forgetting in vision foundation model fine-tuning. The method
  performs Feature Distribution Alignment (FDA) by matching nearest neighbor graphs
  between pre-trained and fine-tuned feature spaces, with an enhanced version called
  Proxy-FDA that generates synthetic proxy features to increase data diversity.
---

# Proxy-FDA: Proxy-based Feature Distribution Alignment for Fine-tuning Vision Foundation Models without Forgetting

## Quick Facts
- arXiv ID: 2505.24088
- Source URL: https://arxiv.org/abs/2505.24088
- Reference count: 40
- Shows Proxy-FDA significantly outperforms existing methods in preventing concept forgetting during vision model fine-tuning, with average ∆LP of 1.50 compared to 0.29 for LDIFS and -2.59 for LP-FT

## Executive Summary
This paper introduces Proxy-FDA, a novel regularization method that addresses catastrophic forgetting during fine-tuning of vision foundation models. The approach performs Feature Distribution Alignment (FDA) by matching nearest neighbor graphs between pre-trained and fine-tuned feature spaces, with an enhanced version that generates synthetic proxy features to increase data diversity. Tested on 10 classification datasets with CLIP, Proxy-FDA demonstrates significant improvements in preserving pre-trained knowledge while maintaining strong downstream performance, outperforming existing methods by substantial margins in both concept preservation and classification accuracy.

## Method Summary
Proxy-FDA works by aligning feature distributions between pre-trained and fine-tuned models through a nearest neighbor graph matching approach. The method constructs graphs in both feature spaces where each node represents a sample and edges connect nearest neighbors, then minimizes the distance between these graphs during fine-tuning. An enhanced version, Proxy-FDA, generates synthetic proxy features that augment the original training data, increasing diversity and improving alignment quality. The regularization is applied as an additional loss term during fine-tuning, with the entire framework designed to be computationally efficient and easily integrable into existing fine-tuning pipelines.

## Key Results
- Proxy-FDA achieves average ∆LP of 1.50 on 10 classification datasets, significantly outperforming LDIFS (0.29) and LP-FT (-2.59)
- The method demonstrates strong performance across few-shot, continual, and cross-task fine-tuning scenarios
- Computational overhead is claimed to be negligible while maintaining state-of-the-art performance in preventing concept forgetting

## Why This Works (Mechanism)
The method prevents forgetting by maintaining feature space consistency between pre-trained and fine-tuned models through graph matching. By preserving the local structure of the feature space, the model retains its ability to recognize previously learned concepts while adapting to new tasks. The synthetic proxy features enhance this process by increasing data diversity, making the alignment more robust and comprehensive across different data distributions.

## Foundational Learning
- **Nearest Neighbor Graphs**: Essential for capturing local feature space structure; quick check involves verifying k-NN accuracy before and after alignment
- **Feature Distribution Alignment**: Core concept for maintaining pre-trained knowledge; validation through feature space visualization and similarity metrics
- **Synthetic Feature Generation**: Technique for data augmentation in feature space; evaluation requires checking generation quality and diversity metrics
- **Regularization in Fine-tuning**: Critical for preventing overfitting to new data; monitoring through validation loss and forgetting metrics

## Architecture Onboarding
- **Component Map**: Pre-trained Model -> Feature Extractor -> Nearest Neighbor Graph Construction -> Graph Matching Loss -> Fine-tuned Model
- **Critical Path**: Feature extraction and graph construction must be efficient to avoid bottlenecking the fine-tuning process
- **Design Tradeoffs**: Balancing alignment strength vs. adaptation capability; more aggressive alignment may preserve knowledge better but could limit new task learning
- **Failure Signatures**: Poor alignment indicated by increasing nearest neighbor distances; overfitting suggested by validation performance degradation
- **First Experiments**: 1) Baseline fine-tuning without alignment, 2) Simple nearest neighbor graph matching, 3) Full Proxy-FDA with synthetic features

## Open Questions the Paper Calls Out
The paper acknowledges several limitations and areas requiring further investigation, particularly regarding the generalizability of Proxy-FDA to non-CLIP vision foundation models and other task types beyond classification. The computational overhead, while claimed to be negligible, requires more thorough quantification across different hardware configurations. Additionally, the synthetic proxy feature generation approach may introduce artifacts or biases affecting long-tail distribution performance, warranting deeper analysis.

## Limitations
- Primary evaluation focuses on CLIP models, raising questions about applicability to other vision foundation models
- Experimental scope limited to classification tasks, leaving unclear performance on detection, segmentation, or other vision tasks
- Computational overhead claims not thoroughly quantified across different hardware configurations
- Potential for synthetic proxy features to introduce artifacts or biases affecting long-tail distribution performance

## Confidence
- **High Confidence**: Effectiveness of Proxy-FDA in preventing forgetting during fine-tuning on classification tasks with CLIP models
- **Medium Confidence**: Generalizability to other vision foundation models and task types
- **Medium Confidence**: Negligible computational overhead claim

## Next Checks
1. Evaluate Proxy-FDA's performance on non-CLIP vision foundation models (e.g., DINOv2, MAE) to assess generalizability across different architectures
2. Test the method on object detection and segmentation tasks to verify effectiveness beyond classification
3. Conduct extensive computational benchmarking to measure training time, memory usage, and scalability across different hardware configurations