---
ver: rpa2
title: Multi-Robot Coordination with Adversarial Perception
arxiv_id: '2504.09047'
source_url: https://arxiv.org/abs/2504.09047
tags:
- adversarial
- perception
- measurements
- attacks
- object
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the resilience of perception-based multi-robot
  coordination to adversarial perception attacks. The authors propose a framework
  that models adversarial misclassification and mislocalization as sporadic and spurious
  measurements, respectively.
---

# Multi-Robot Coordination with Adversarial Perception

## Quick Facts
- arXiv ID: 2504.09047
- Source URL: https://arxiv.org/abs/2504.09047
- Reference count: 40
- Multi-robot framework quantifies resilience to adversarial perception attacks through sporadic/spurious measurement modeling

## Executive Summary
This paper presents a system-theoretic framework for analyzing multi-robot coordination resilience against adversarial perception attacks. The authors model adversarial misclassification and mislocalization as sporadic and spurious measurement patterns, respectively, which are then integrated into a Kalman filter framework. The approach enables quantification of observability and stability degradation relative to adversarial success rates. Experiments with 16 real-time trials demonstrate effectiveness in maintaining system stability under various attack scenarios while providing a novel observability-based resilience metric.

## Method Summary
The framework uses a modified Kalman filter to fuse VIO velocity measurements with intermittent perception-based position estimates. Adversarial misclassification is modeled as sporadic measurement loss (βk parameter), while mislocalization is modeled as spurious bounding box perturbations (δpi). The filter includes gating via Mahalanobis distance to reject spurious measurements. A consensus-based control protocol coordinates robot formations using the filtered state estimates. Adversarial effects are simulated through Bernoulli distributions for misclassification and bounding box perturbations for mislocalization. The framework quantifies resilience through observability Gramian trace ratios and covariance stability metrics.

## Key Results
- Kalman filter variant maintains bounded state estimation error despite adversarial measurement loss
- Observability degradation scales predictably with adversarial success rate (trace ratio metric)
- Framework quantifies resilience through covariance stability and observability metrics
- Real-time experiments show effectiveness in maintaining formation stability under various attack scenarios

## Why This Works (Mechanism)

### Mechanism 1
Adversarial perception attacks on object detection can be modeled as sporadic (intermittent) and spurious measurement patterns rather than requiring explicit attack modeling. Misclassification events cause measurement unavailability—modeled as βk = 1 in the Kalman filter update. Mislocalization events inject spurious position measurements δpi per Eq. (4). This abstraction decouples resilience analysis from specific adversarial attack methods (FGSM, PGD, etc.). The core assumption is that diverse adversarial perturbations categorically manifest as either missing detections or perturbed bounding boxes, not fundamentally novel failure modes.

### Mechanism 2
Fusing VIO (continuously available velocity) with perception-based localization (intermittent position) through a modified Kalman filter maintains bounded state estimation error despite adversarial measurement loss. The filter uses a binary random variable β̄k = (1 - βk) ∈ {0,1} to gate position updates while velocity measurements remain available from VIO, preserving partial observability even when position measurements are lost. The covariance Pk grows during missed measurements but recovers when position data returns. The core assumption is that VIO velocity estimates remain reliable under adversarial image attacks; attacks primarily target object detection rather than VIO itself.

### Mechanism 3
System observability degrades predictably with adversarial success rate, quantifiable through the ratio of adversarial to nominal observability Gramian traces. The observability quality metric Tr(Wₒᴬᴰ[n])/Tr(Wₒˢᴰ[n]) ∈ [0,1] shows higher missed measurement rates reduce observability. Eq. (9) provides an approximate lower bound showing degradation scales with the fraction of available measurements. The core assumption is that the n-step observability Gramian adequately captures the time-varying observability of the switching system.

## Foundational Learning

- **Concept: Kalman Filtering with Intermittent Observations**
  - Why needed here: The core estimator extends standard KF to handle random measurement loss. Understanding how covariance evolves under missing data is essential for interpreting stability results.
  - Quick check question: Given a scalar KF with β̄k = 0.5 probability of receiving measurements, does the expected error covariance converge, diverge, or depend on system parameters? (Answer: It depends—stability requires the Lyapunov-like condition that measurement arrival rate exceeds a critical threshold.)

- **Concept: Observability Gramian and System Observability**
  - Why needed here: The paper quantifies resilience via Gramian trace degradation. You need to understand what the Gramian represents (how much measurement information shapes state estimates over n steps).
  - Quick check question: For a discrete-time linear system with A = I and C = [1 0], is the 2-step observability Gramian full rank? What if C alternates between [1 0] and [0 1]? (Answer: First case—no, rank-deficient; second case—yes, full rank due to mode switching.)

- **Concept: Consensus-Based Multi-Robot Coordination**
  - Why needed here: The downstream control uses distributed consensus for formation control. Adversarial perception errors propagate as bounded disturbances in the control channel.
  - Quick check question: In the consensus protocol uᵢ* = -αΣⱼ aᵢⱼ(eᵢ - eⱼ) - γvᵢ, what happens to formation error if one robot's position estimate has constant bias? (Answer: Formation converges but with offset proportional to bias weighted by graph connectivity.)

## Architecture Onboarding

- **Component map:** Camera frame -> Object detection (YOLOv7-tiny) -> Bounding box -> Depth estimation (known object size) -> Relative position -> Gating (Mahalanobis) -> KF update -> Consensus controller -> Motor commands
- **Critical path:** Camera frame → object detection → bounding box → depth estimation (known object size) → relative position → gating → KF update → control command → motors. Latency anywhere in this path compounds; adversarial overload attacks target detection latency.
- **Design tradeoffs:**
  - Gating threshold τp: Higher values accept more spurious measurements (vulnerable to mislocalization); lower values reject more valid measurements (vulnerable to misclassification)
  - Object size assumption: Known size enables depth from single view but breaks for variable-size objects; alternative requires multi-view triangulation
  - Control gains (α, γ): Higher α speeds consensus but amplifies perception noise propagation; higher γ dampens velocity error but slows formation convergence
- **Failure signatures:**
  - Covariance explosion: ‖Pk‖₂ growing unboundedly indicates stability loss
  - Coordination drift: RMS(p₂₁*, p̂₂₁) increasing over time signals accumulated localization bias
  - Data association failure: Gating rejects all measurements (|V| = 0) when spurious boxes dominate
  - Latency spikes: Iteration time increasing from 35ms baseline to 41+ms indicates adversarial overload
- **First 3 experiments:**
  1. Baseline characterization (Exp. 1, n=0, p=0): Run with zero adversarial attacks to establish nominal performance bounds
  2. Misclassification-only stress test (Exp. 6, n=1000, p=0.95): Simulate 95% measurement loss rate to test system controllability limits
  3. Mislocalization stress test (Exp. 13, b=10, q=±30%): Inject 10 spurious bounding boxes per frame with 30% perturbation to test gating effectiveness

## Open Questions the Paper Calls Out

- What are the theoretical performance guarantees for the modified Kalman filter given the system's defective eigenvalues and non-Bernoulli measurement loss?
- How can uncertainty be rigorously quantified for state estimation under adversarial perception data without relying solely on empirical metrics?
- How can the perception-based coordination framework be secured against generative adversarial attacks that replace camera input with inauthentic images?

## Limitations
- The adversarial abstraction may not capture all attack modalities, particularly correlated or coordinated adversarial strategies across robots
- VIO resilience assumptions remain untested; the framework assumes VIO remains reliable while perception is attacked
- The observability degradation metric provides approximate bounds but may not fully characterize time-varying system behavior under Bernoulli switching

## Confidence
- **High:** Kalman filter with intermittent observations can handle sporadic measurement loss when VIO velocity remains reliable
- **Medium:** Adversarial misclassification and mislocalization effects are adequately abstracted as sporadic/spurious measurements
- **Medium:** Observability degradation quantifies system resilience predictably

## Next Checks
1. Test correlated adversarial attacks where misclassification/mislocalization are coordinated across time and robots to validate the sporadic/spurious abstraction breaks down
2. Evaluate VIO robustness by injecting adversarial perturbations into IMU/optical flow to verify dual-modality redundancy assumptions
3. Implement real adversarial attack algorithms (FGSM, PGD) on the perception pipeline to measure deviation from simulated sporadic/spurious measurement models