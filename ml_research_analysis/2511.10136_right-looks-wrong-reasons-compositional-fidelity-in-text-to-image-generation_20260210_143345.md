---
ver: rpa2
title: 'Right Looks, Wrong Reasons: Compositional Fidelity in Text-to-Image Generation'
arxiv_id: '2511.10136'
source_url: https://arxiv.org/abs/2511.10136
tags:
- spatial
- compositional
- conference
- negation
- relations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This survey analyzes compositional fidelity in text-to-image generation,
  focusing on three fundamental primitives: negation, counting, and spatial relations.
  It reveals that while models perform well on isolated primitives, their performance
  collapses dramatically when combining them, exhibiting submultiplicative behavior
  due to interference.'
---

# Right Looks, Wrong Reasons: Compositional Fidelity in Text-to-Image Generation

## Quick Facts
- arXiv ID: 2511.10136
- Source URL: https://arxiv.org/abs/2511.10136
- Reference count: 19
- Primary result: Text-to-image models fail catastrophically when combining negation, counting, and spatial relations despite individual primitive competence.

## Executive Summary
This survey analyzes compositional fidelity in text-to-image generation, focusing on three fundamental primitives: negation, counting, and spatial relations. It reveals that while models perform well on isolated primitives, their performance collapses dramatically when combining them, exhibiting submultiplicative behavior due to interference. The analysis traces failures to training data sparsity (particularly for negation), architectural mismatch between continuous attention and discrete logic, and evaluation metrics that reward visual plausibility over constraint satisfaction. The paper synthesizes 15 benchmarks and 30+ methods, concluding that current solutions and simple scaling cannot bridge the compositional gap. Achieving genuine compositionality will require fundamental advances in representation and reasoning rather than incremental adjustments to existing architectures.

## Method Summary
The paper surveys compositional fidelity in text-to-image generation through analysis of three primitives: negation, counting, and spatial relations. It evaluates 15 benchmarks including T2I-CompBench, CREPE, VALSE, and NegBench across multiple models. The analysis uses formal metrics including compositional faithfulness F_θ(y), interference metric ρ(y) = F_θ(y) / F_ind_θ(y), and counting error power law Error(n) ≈ Θ(n^β). The study quantifies submultiplicative performance collapse when primitives combine, traces failures to data sparsity patterns and architectural limitations, and synthesizes existing approaches including layout-based methods, contrastive training, and inference-time composition. No new models are trained; instead, the work provides a comprehensive analytical framework and systematic evaluation of existing approaches.

## Key Results
- Joint compositional performance degrades submultiplicatively (ρ(y) < 1) when combining negation, counting, and spatial primitives
- Training data shows extreme sparsity for negation (0.4-2.5% of captions) and complex spatial relations (<5%)
- Counting error follows power law Error(n) ≈ Θ(n^1.2-1.5), indicating superlinear degradation
- Current architectures cannot solve NP-hard constraint satisfaction problems required for faithful composition
- Layout-based methods and contrastive training provide partial improvements but cannot fully resolve compositional gaps

## Why This Works (Mechanism)

### Mechanism 1: Submultiplicative Interference
When primitives combine, interference factor ρ(y) = F_θ(y) / F_ind_θ(y) falls below 1.0. In the paper's example, 70% per-primitive accuracy would yield 34.3% joint under independence, but actual performance drops to ~20% due to ρ(y) ≈ 0.58. Primitives share underlying representations that compete for capacity, violating the independence assumption.

### Mechanism 2: Data-Architecture Mismatch
Training data sparsity (negation in 0.4-2.5% of captions) combines with continuous attention biases to suppress compositional learning. Continuous attention optimizes visual plausibility (regularization) over constraint satisfaction when constraints conflict with learned priors.

### Mechanism 3: Emergent Computational Complexity
Joint composition creates NP-hard constraint satisfaction that greedy attention cannot solve. For n objects, m spatial relations, k negations: search space |S| = O(n! × 2^m × C(n,k)). Models perform greedy local search, yielding local-but-not-global consistency.

## Foundational Learning

- **Compositional Primitives**: Decomposition into negation, counting, and spatial relations as atomic building blocks. Why needed: isolates failure modes. Quick check: Can you explain why "three red apples to the left of a vase with no flowers" requires all three primitives simultaneously?

- **Attention as Continuous Approximation**: Continuous attention fundamentally mismatched to discrete logic operations. Why needed: explains architectural limitations. Quick check: How does softmax attention over continuous weights fail to represent "exactly 3" as a hard constraint?

- **Constraint Satisfaction vs. Likelihood Maximization**: T2I models optimize p(x|y); compositional fidelity requires satisfying binary constraints C_i(x,y)=1. Why needed: reveals objective misalignment. Quick check: Why does maximizing visual plausibility conflict with enforcing logical constraints?

## Architecture Onboarding

- **Component map**: Text encoder → diffusion/autoregressive backbone → attention layers → image decoder
- **Critical path**: Identify primitive failures → measure interference factor ρ(y) → trace to data sparsity, architecture, or both
- **Design tradeoffs**: Layout-based methods improve fidelity but require extra inputs; contrastive training helps negation but overfits; inference-time composition prevents interference but increases latency
- **Failure signatures**: Constraint trading (correct count with wrong attributes), over-suppression (negation removes target content entirely), local-global inconsistency (pairwise relations hold but global layout fails)
- **First 3 experiments**:
  1. Measure ρ(y) on held-out prompts combining all three primitives to establish baseline interference
  2. Augment training with synthetic negation-caption pairs and isolate gains vs. regression on other primitives
  3. Replace attention with bounded attention for counting and measure whether interference decreases

## Open Questions the Paper Calls Out

### Open Question 1
What are the formal computational lower bounds for faithful compositional generation, and which compositional patterns are provably learnable from finite data? The computational lower bounds for faithful composition are unknown, and we cannot yet formally characterize which compositional patterns are learnable from the data.

### Open Question 2
Can structured intermediate representations (scene graphs, layouts) be learned from text alone without requiring costly manual annotations? Intermediate representations such as scene graphs and layouts improve fidelity but depend on costly annotations, leaving the challenge of learning structured representations from text alone unresolved.

### Open Question 3
How should reward functions be specified to enable RLHF alignment with compositional objectives across multiple constraint types? Reinforcement learning from human feedback could align models with compositional objectives; however, reward specification for complex constraints is an open problem.

### Open Question 4
What mechanistic interaction patterns between specialized attention heads cause submultiplicative performance degradation when primitives combine? Mechanistic interpretability has shown that attention heads specialize in different primitives, but the interaction mechanisms between these specialized components remain largely opaque to current analytical methods.

## Limitations

- Analysis relies on observational correlations without controlled ablation studies to definitively separate representation interference from optimization limitations
- Proposed metrics (ρ(y), power-law counting error) are novel but unvalidated against human judgment or alternative measurement frameworks
- Conclusions about architectural inadequacy are based on existing models rather than testing proposed alternatives within comparable training regimes

## Confidence

- **High confidence**: Individual primitive failure rates and their data sparsity patterns (negation in 0.4-2.5% of captions, counting under 2%)
- **Medium confidence**: Submultiplicative interference exists and ρ(y) < 1.0 is consistently observed across benchmarks
- **Low confidence**: Architectural explanations (continuous attention vs. discrete logic) are the primary driver of compositional failures

## Next Checks

1. **Ablation study**: Train T2I models with enriched compositional data (synthetic negation pairs, explicit counting examples, spatial relation augmentation) to isolate whether data sparsity or architecture limits compositional learning

2. **Mechanism isolation**: Implement bounded attention or discrete constraint satisfaction layers and measure whether interference ρ(y) improves while maintaining baseline primitive performance

3. **Evaluation framework validation**: Compare automated compositional fidelity metrics against human judgments on the same prompts to verify that current metrics capture genuine compositional understanding rather than surface-level plausibility