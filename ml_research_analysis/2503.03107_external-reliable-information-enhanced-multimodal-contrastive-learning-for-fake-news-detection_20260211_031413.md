---
ver: rpa2
title: External Reliable Information-enhanced Multimodal Contrastive Learning for
  Fake News Detection
arxiv_id: '2503.03107'
source_url: https://arxiv.org/abs/2503.03107
tags:
- news
- fake
- multimodal
- detection
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of multimodal fake news detection,
  where current methods struggle to fully utilize multimodal information and often
  rely on static, unreliable external information. The proposed ERIC-FND framework
  introduces an external reliable information-enhanced multimodal contrastive learning
  approach.
---

# External Reliable Information-enhanced Multimodal Contrastive Learning for Fake News Detection

## Quick Facts
- **arXiv ID**: 2503.03107
- **Source URL**: https://arxiv.org/abs/2503.03107
- **Reference count**: 14
- **Primary result**: ERIC-FND achieves 94.6% accuracy on Weibo and 94.5% on Twitter datasets

## Executive Summary
This paper addresses multimodal fake news detection by introducing ERIC-FND, a framework that enhances text representation with external entity information from Wikipedia and aligns text-image features through multimodal contrastive learning. The method addresses the limitations of existing approaches that either fail to fully utilize multimodal information or rely on unreliable external sources. By combining entity-enriched Wikipedia descriptions, multimodal contrastive alignment, cross-modal semantic interaction, and adaptive feature fusion, the model achieves state-of-the-art performance on both Chinese (Weibo) and English (Twitter) datasets.

## Method Summary
ERIC-FND employs a multimodal framework that processes text through BERT and images through ResNet-50, then enhances text representations using the first sentence of Wikipedia descriptions for extracted entities. The model applies multimodal contrastive learning to align text and image features in a shared space using InfoNCE loss, captures cross-modal semantic relationships through attention mechanisms, and fuses features adaptively using learned weights. The final classification combines enhanced text features, visual features, and their interaction through a weighted gating mechanism.

## Key Results
- ERIC-FND achieves 94.6% accuracy on the Weibo dataset, outperforming existing state-of-the-art methods
- The model reaches 94.5% accuracy on the MediaEval Twitter dataset
- Ablation studies show significant performance drops when removing external information enhancement (2-3% accuracy decrease) or multimodal contrastive learning components

## Why This Works (Mechanism)

### Mechanism 1: Knowledge-Augmented Text Representation
The model enriches news text with external entity descriptions from Wikipedia to improve semantic representation, particularly for detecting subtle inconsistencies. By extracting entities from news text and fusing their Wikipedia descriptions with original text features using attention, the model gains contextual understanding that helps identify mismatches between claims and reality.

### Mechanism 2: Multimodal Contrastive Alignment
Text and image features are projected into a shared vector space using separate fully-connected layers, with InfoNCE loss pulling positive pairs closer and pushing negative pairs apart. This alignment allows the model to evaluate consistency between modalities, as fake news often exhibits semantic disconnect between textual claims and visual content.

### Mechanism 3: Adaptive Feature Gating
The model dynamically weights the contribution of text, image, and interaction features for each news item using a sigmoid-gated fusion mechanism. This allows the model to emphasize different modalities based on the specific characteristics of each news piece, recognizing that some fake news may be text-heavy while others rely on miscaptioned images.

## Foundational Learning

### Concept: InfoNCE Loss (Contrastive Learning)
- **Why needed here**: This is the mathematical engine driving cross-modal alignment, measuring how well the model distinguishes matching from non-matching text-image pairs
- **Quick check question**: If you increase the temperature τ, does the model penalize hard negatives more or less severely?

### Concept: Entity Linking (EL)
- **Why needed here**: The External Information Enhancement module relies entirely on mapping raw text strings to knowledge base IDs
- **Quick check question**: What happens to the external enhancement vector if the entity linker returns None for a specific news snippet?

### Concept: Attention Pooling
- **Why needed here**: The model uses attention to aggregate variable-length entity descriptions into fixed-size vectors
- **Quick check question**: How does the model decide which word in an entity description is most important for final classification?

## Architecture Onboarding

### Component map
BERT (Text) + ResNet-50 (Visual) → Entity Extractor → Wikipedia API → BERT → Attention Fusion → Contrastive Loss → Cross-Attention → Cross Product → Concatenation → Adaptive Gating → MLP Classifier

### Critical path
The Entity Extraction to Wikipedia Retrieval step is the most fragile data-handling component. If API calls fail or rate-limit, the "Reliable Information" component degrades to zero, leaving the model to rely solely on raw BERT embeddings.

### Design tradeoffs
The authors explicitly trade contextual richness for noise reduction in external knowledge by truncating Wikipedia descriptions to the first sentence only. While this reduces computation and noise, it may lose specific details relevant to the news event.

### Failure signatures
- Low Recall on Breaking News: If Wikipedia is stale, external enhancement provides no signal
- Gradient Conflict: Contrastive loss and detection loss may pull in different directions
- Entity Coverage Gaps: Model fails when news discusses entities not indexed in Wikipedia

### First 3 experiments
1. **Ablation on External Info**: Run ERIC-FND w/o E to quantify performance drop when Wikipedia context is removed
2. **Temperature Sensitivity**: Sweep the τ parameter in contrastive loss to see if alignment tightness correlates with detection accuracy
3. **Entity Failure Simulation**: Manually mask entity descriptions for test data to simulate "unseen" entities and measure robustness

## Open Questions the Paper Calls Out

### Open Question 1
How does discarding all but the first image in news posts with multiple images affect the model's ability to detect inconsistencies in remaining visual content? The authors select only the first image when multiple are available but do not analyze whether fake news frequently utilizes secondary images for misinformation.

### Open Question 2
To what extent does limiting external knowledge to the first sentence of Wikipedia descriptions impact detection of fake news requiring deeper contextual understanding? While reducing noise, this truncation may omit relevant context necessary to verify complex claims.

### Open Question 3
How does reliance on Wikipedia as the sole external knowledge source affect detection of breaking news where entity pages may not yet exist or be updated? The methodology depends on Wikipedia coverage, which may not be available for rapidly evolving events.

## Limitations
- Wikipedia dependency creates temporal blind spots for breaking news without coverage
- Missing hyperparameter details referenced to unavailable appendix section
- Entity linking may fail silently for domain-specific terminology or proper nouns

## Confidence
- **High confidence**: Multimodal contrastive learning with InfoNCE loss is well-grounded and reproducible
- **Medium confidence**: Entity-based external information enhancement is plausible but depends heavily on entity linking quality
- **Low confidence**: Adaptive fusion superiority over simpler alternatives is claimed but not rigorously validated

## Next Checks
1. **Temporal robustness test**: Evaluate on recent news events (last 3 months) to measure performance degradation with incomplete Wikipedia coverage
2. **Ablation of external knowledge**: Run ERIC-FND without external information enhancement to validate claimed 2-3% accuracy improvement
3. **Hyperparameter sensitivity**: Systematically sweep contrastive loss temperature parameter τ and loss weighting to identify optimal configurations and instability points