---
ver: rpa2
title: Multiple-play Stochastic Bandits with Prioritized Arm Capacity Sharing
arxiv_id: '2512.21626'
source_url: https://arxiv.org/abs/2512.21626
tags:
- regret
- plays
- action
- play
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a variant of multiple-play stochastic bandits
  tailored to resource allocation problems arising from LLM applications, edge intelligence,
  etc. The model is composed of $M$ arms and $K$ plays.
---

# Multiple-play Stochastic Bandits with Prioritized Arm Capacity Sharing

## Quick Facts
- arXiv ID: 2512.21626
- Source URL: https://arxiv.org/abs/2512.21626
- Authors: Hong Xie; Haoran Gu; Yanying Huang; Tao Tan; Defu Lian
- Reference count: 40
- Primary result: Proposed prioritized capacity sharing mechanism for multiple-play stochastic bandits with matching upper and lower regret bounds

## Executive Summary
This paper introduces a novel multiple-play stochastic bandit framework with prioritized arm capacity sharing, specifically designed for resource allocation problems in LLM applications and edge intelligence systems. The model features M arms with stochastic capacities and K plays with priority weights, where capacity is allocated based on priority-weighted competition. The authors establish both instance-independent and instance-dependent regret lower bounds of Ω(α₁σ√(KMT)) and Ω(α₁σ²(M/Δ)ln T) respectively, where α₁ represents the highest priority weight and σ characterizes reward tail behavior.

The framework addresses a critical gap in existing bandit literature by modeling realistic resource allocation scenarios where multiple agents compete for limited shared resources with varying priorities. The authors develop MSB-PRS-OffOpt, an algorithm that achieves optimal play allocation with O(MK³) computational complexity, and complement it with an approximate UCB-based learning algorithm that matches the established regret bounds up to polylogarithmic factors.

## Method Summary
The authors propose a prioritized resource sharing mechanism where each of M arms has stochastic capacity, and each play has an associated priority weight. When multiple plays request capacity from the same arm, allocation follows a "larger priority weight first" policy. They first prove regret lower bounds using information-theoretic arguments, then design MSB-PRS-OffOpt to find optimal allocation policies offline in O(MK³) time. Building on this, they develop a UCB-based online learning algorithm that adapts to unknown parameters while maintaining matching upper bounds. The approach handles the nonlinear combinatorial utility function induced by the prioritization mechanism through careful mathematical analysis.

## Key Results
- Established instance-independent regret lower bound of Ω(α₁σ√(KMT))
- Established instance-dependent regret lower bound of Ω(α₁σ²(M/Δ)ln T)
- Designed MSB-PRS-OffOpt algorithm with O(MK³) computational complexity
- Developed UCB-based algorithm matching upper bounds up to √K ln KT and α₁K² factors
- Proved tight characterization of regret complexity for prioritized capacity sharing

## Why This Works (Mechanism)
The prioritization mechanism works by creating a structured allocation policy where higher-priority plays systematically receive capacity before lower-priority ones when resources are constrained. This transforms the complex multi-agent resource allocation problem into a tractable combinatorial optimization that can be solved offline. The UCB-based online algorithm leverages this structure by maintaining confidence bounds on unknown parameters while using the optimal offline policy as a subroutine, ensuring both exploration and exploitation are balanced according to the prioritized sharing rules.

## Foundational Learning
- Prioritized resource allocation: Needed to model realistic competition scenarios where agents have different importance levels; Quick check: Verify priority weights are known and comparable across all plays
- Stochastic capacity modeling: Essential for capturing uncertainty in resource availability typical in LLM serving and edge computing; Quick check: Validate capacity distributions match empirical observations
- Combinatorial optimization under nonlinear utilities: Required to solve the complex allocation problem induced by prioritization; Quick check: Confirm solution quality through comparison with brute-force enumeration on small instances
- Confidence bound techniques for combinatorial actions: Necessary to extend classical bandit analysis to the multiple-play setting; Quick check: Test coverage probability of confidence intervals under various parameter regimes

## Architecture Onboarding
**Component map:** Arms (M) → Capacity generator → Priority-weighted allocation → Plays (K) → Reward function → Regret calculation
**Critical path:** Capacity realization → Priority-based allocation → Reward collection → Parameter estimation → Policy update
**Design tradeoffs:** Computational complexity O(MK³) vs. optimality guarantee; Prioritization simplicity vs. potential starvation of low-priority plays; Stochastic modeling accuracy vs. analytical tractability
**Failure signatures:** High regret when capacity distributions are misspecified; Suboptimal performance when priority weights are inaccurate; Computational bottlenecks for large M and K values
**First experiments:** 1) Validate offline optimization on synthetic instances with known optimal solutions; 2) Test UCB-based algorithm convergence under varying capacity uncertainty; 3) Benchmark regret performance against non-prioritized baseline algorithms

## Open Questions the Paper Calls Out
None

## Limitations
- Assumes stationary and known stochastic capacity distributions, which may not reflect dynamic real-world scenarios
- Requires complete knowledge of priority weights, potentially impractical in distributed systems with limited coordination
- O(MK³) computational complexity may become prohibitive for large-scale applications with many arms and plays

## Confidence
- **High confidence** in regret lower bound derivations (established through rigorous information-theoretic arguments)
- **Medium confidence** in algorithmic guarantees (depends on assumptions about capacity distributions and reward tails)
- **High confidence** in computational complexity analysis (based on explicit enumeration of allocation policies)

## Next Checks
1. Empirical validation on real-world LLM serving traces to verify whether the stochastic capacity model accurately captures practical workload patterns
2. Robustness testing under capacity distribution misspecification to assess algorithm performance when model parameters are unknown or changing
3. Scalability experiments to determine the practical limits of the O(MK³) complexity in multi-armed bandit scenarios with large M and K values typical of modern distributed systems