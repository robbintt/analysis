---
ver: rpa2
title: 'SALAD: Improving Robustness and Generalization through Contrastive Learning
  with Structure-Aware and LLM-Driven Augmented Data'
arxiv_id: '2504.12185'
source_url: https://arxiv.org/abs/2504.12185
tags:
- data
- uni00000013
- uni00000011
- uni00000008
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses spurious correlations in NLP models, which
  harm generalization, especially on out-of-distribution data. SALAD improves robustness
  by combining structure-aware data augmentation with LLM-driven counterfactual generation
  and contrastive learning.
---

# SALAD: Improving Robustness and Generalization through Contrastive Learning with Structure-Aware and LLM-Driven Augmented Data

## Quick Facts
- **arXiv ID:** 2504.12185
- **Source URL:** https://arxiv.org/abs/2504.12185
- **Reference count:** 28
- **Primary result:** SALAD improves robustness and generalization on sentiment classification, sexism detection, and NLI by combining structure-aware augmentation with LLM-driven counterfactuals and contrastive learning

## Executive Summary
SALAD addresses spurious correlations in NLP models by combining structure-aware data augmentation with LLM-driven counterfactual generation and contrastive learning. The method identifies non-causal words via POS tagging to generate structure-preserving positive samples, while LLMs produce diverse negative samples. Experiments show SALAD improves both in-domain accuracy and out-of-distribution performance across three tasks, demonstrating robustness to spurious patterns and strong cross-domain generalization.

## Method Summary
SALAD uses a RoBERTa-large backbone trained with a combined loss function that merges cross-entropy classification with contrastive learning. The method generates positive samples by masking non-causal tokens identified through POS tagging, and negative samples via LLM-generated counterfactuals that flip labels. The contrastive loss organizes the latent space to bring masked versions closer to originals while pushing them away from counterfactuals. Training uses triplet loss with margin α=0.18 and per-dataset hyperparameter tuning.

## Key Results
- SALAD achieved 93.05% overall accuracy in sentiment classification, outperforming baselines
- Significant improvements on out-of-distribution datasets across all three tasks
- Ablation studies show contrastive loss is critical for OOD performance (drops from 92.15 to 89.59 without it)
- Strong generalization across cross-domain datasets including YELP, SST2, FineFood, Tweet, and MNLI

## Why This Works (Mechanism)

### Mechanism 1: Structure-Aware Masking
The system calculates "Average Accuracy Reduction" for each POS tag to identify non-causal tokens. Tags with minimal impact when removed (e.g., pronouns, conjunctions) are replaced with `[UNK]` in positive samples, forcing the model to rely on causal structural elements like verbs and nouns. This breaks shortcut learning patterns.

### Mechanism 2: LLM-Generated Counterfactuals
GPT-4o-mini generates diverse negative samples by flipping labels while preserving sentence structure. These synthetic samples serve as "hard negatives" in contrastive loss, expanding the decision boundary and improving OOD generalization. The LLM approach provides higher quality and diversity than rule-based methods.

### Mechanism 3: Triplet Loss Optimization
The combined loss function $L = (1 - \lambda)L_{CE} + \lambda L_{CL}$ creates a dual objective where the model must correctly classify while organizing the latent space geometrically. Original samples are pulled toward masked versions and pushed away from counterfactuals, creating robust representations that generalize better.

## Foundational Learning

- **Concept: Spurious Correlations (Shortcuts)**
  - Why needed here: Core failure mode SALAD targets - models often predict based on word frequency rather than semantic logic
  - Quick check question: Can you distinguish between causal feature ("boring") and spurious feature ("Spielberg") in "The Spielberg film was boring"?

- **Concept: Counterfactual Data Augmentation (CAD)**
  - Why needed here: Negative sampling strategy relies on generating minimal edits that flip labels to harden decision boundaries
  - Quick check question: Is changing "The movie was good" to "The movie was not good" a counterfactual? What about changing to "The food was good"?

- **Concept: Triplet Loss (Contrastive Learning)**
  - Why needed here: SALAD uses specific geometric loss organizing latent space - must understand Anchor-Positive-Negative relationships
  - Quick check question: In triplet $(x, x^+, x^-)$, which pair should have smallest Euclidean distance in embedding space?

## Architecture Onboarding

- **Component map:** Input Processor -> POS Tagger -> Positive Generator (masks non-causal tokens) -> Negative Generator (LLM counterfactuals) -> Encoder (RoBERTa) -> Loss Head (combined CE + CL)

- **Critical path:** Identification of Causal Tag Set (Section 3.1). Incorrect identification due to base model bias reinforces rather than mitigates spurious correlations.

- **Design tradeoffs:**
  - LLM Dependency: Uses GPT-4o-mini for speed/cost but quality slightly lower than Human-CAD
  - Hyperparameter λ: Requires per-dataset tuning (e.g., 0.9 for IMDB, 0.1 for SST2), reducing plug-and-play capability

- **Failure signatures:**
  - High O-Test / Low CF-Test: Model still learning shortcuts, positive masking failing to obscure non-causal words
  - Low Diversity / High Overlap: LLM generation collapsing, failing to provide useful negative samples

- **First 3 experiments:**
  1. Run "Average Accuracy Reduction" calculation on your dataset to verify causal tag set alignment with linguistic intuition
  2. Generate 50 counterfactuals using provided prompt template and manually inspect label flip success and minimal changes
  3. Tune λ from 0.1 to 0.9 in 0.2 increments, plot trade-off between in-domain accuracy and OOD performance

## Open Questions the Paper Calls Out
The paper acknowledges its limitation of using GPT-4o-mini and suggests future work could verify the framework's effectiveness as higher-quality or alternative CAD generation methods become available. This opens questions about whether the method remains robust with smaller, open-source language models for cost-sensitive or privacy-constrained applications.

## Limitations
- Heavy dependence on initial causal/non-causal tag identification quality, which may reinforce base model biases
- LLM counterfactual generation quality varies and relies on automated metrics like BERTScore that may miss semantic failures
- Requires per-dataset hyperparameter tuning (λ), suggesting limited robustness without extensive validation
- Assumes universal applicability of 1% accuracy reduction threshold for identifying non-causal tags

## Confidence
- **High Confidence**: Experimental methodology and improvements on established benchmarks are well-documented and reproducible
- **Medium Confidence**: Structure-aware masking mechanism is theoretically sound but relies on assumptions about POS tag behavior that may not hold across domains
- **Low Confidence**: Quality assurance of LLM-generated counterfactuals is limited, lacking systematic human evaluation beyond automated metrics

## Next Checks
1. **Causal Tag Set Verification**: Implement "Average Accuracy Reduction" calculation on your dataset and verify resulting causal tag set matches linguistic intuition
2. **Counterfactual Quality Audit**: Generate 50 counterfactual samples and conduct human evaluation on label correctness, minimal token changes, and meaning preservation
3. **Hyperparameter Sensitivity Analysis**: Systematically vary λ from 0.1 to 0.9 in 0.2 increments, plot trade-off between in-domain and out-of-distribution performance