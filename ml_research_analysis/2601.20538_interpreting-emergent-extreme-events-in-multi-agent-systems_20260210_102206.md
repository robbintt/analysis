---
ver: rpa2
title: Interpreting Emergent Extreme Events in Multi-Agent Systems
arxiv_id: '2601.20538'
source_url: https://arxiv.org/abs/2601.20538
tags:
- risk
- agent
- extreme
- actions
- action
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the first framework for interpreting emergent
  extreme events in large language model-powered multi-agent systems. It adapts the
  Shapley value to attribute risk to individual agent actions, enabling identification
  of when, who, and what behaviors drive extreme events.
---

# Interpreting Emergent Extreme Events in Multi-Agent Systems

## Quick Facts
- arXiv ID: 2601.20538
- Source URL: https://arxiv.org/abs/2601.20538
- Reference count: 40
- This paper introduces the first framework for interpreting emergent extreme events in large language model-powered multi-agent systems.

## Executive Summary
This paper presents a novel framework for interpreting emergent extreme events in multi-agent systems powered by large language models. The framework adapts Shapley value theory to attribute risk to individual agent actions, enabling identification of when, who, and what behaviors drive extreme events. By aggregating attributions across time, agents, and behavior patterns, the framework provides interpretable metrics quantifying event features like risk latency, agent concentration, and behavioral contributions.

The work addresses a critical gap in understanding how extreme events emerge in complex multi-agent systems, which are increasingly important in economic, financial, and social simulations. Through experiments across various scenarios, the framework demonstrates its ability to identify that extreme events typically originate from early dormant risks or immediate shocks, are driven by a small subset of unstable agents, and stem from a few dominant behaviors. The framework's faithfulness is validated through risk reduction when top-attributed actions are removed, outperforming competing attribution methods.

## Method Summary
The framework introduces a novel approach to interpreting extreme events in LLM-powered multi-agent systems by adapting Shapley value theory for risk attribution. It identifies when events occur through risk latency metrics, who drives them via agent concentration analysis, and what behaviors contribute through behavioral pattern analysis. The method aggregates attributions across temporal, agent-level, and behavioral dimensions to provide interpretable metrics. Risk attribution is performed by calculating the marginal contribution of each agent's actions to the overall system risk, using a modified Shapley value computation that accounts for the sequential nature of agent interactions and the stochasticity inherent in LLM-generated behaviors.

## Key Results
- Extreme events typically originate from early dormant risks or immediate shocks
- Events are driven by a small subset of unstable agents rather than system-wide phenomena
- Risk reduction is achieved by removing top-attributed actions, outperforming competing attribution methods

## Why This Works (Mechanism)
The framework works by leveraging Shapley value theory from cooperative game theory to attribute risk contributions in multi-agent systems. This approach captures the marginal impact of each agent's actions on the emergence of extreme events, accounting for the sequential and interactive nature of agent behaviors. By aggregating these attributions across different dimensions (time, agents, behaviors), the framework creates interpretable metrics that reveal the underlying mechanisms driving extreme events. The method's effectiveness stems from its ability to handle the complexity and non-linearity of LLM-generated agent behaviors while providing mathematically grounded attribution that can be validated through intervention experiments.

## Foundational Learning

1. **Shapley Value Attribution**
   - Why needed: Provides mathematically fair attribution of risk contributions in cooperative settings
   - Quick check: Verify that attributions sum to total system risk

2. **Multi-Agent System Dynamics**
   - Why needed: Understanding how individual agent actions interact to produce emergent phenomena
   - Quick check: Confirm that extreme events cannot be predicted from individual agent behaviors alone

3. **Risk Latency Metrics**
   - Why needed: Identifies temporal patterns in how risks accumulate before extreme events
   - Quick check: Validate that high-risk periods precede extreme events in training data

4. **Agent Concentration Analysis**
   - Why needed: Reveals whether extreme events are driven by few agents or system-wide instability
   - Quick check: Test whether removing identified high-risk agents reduces extreme event frequency

5. **Behavioral Pattern Attribution**
   - Why needed: Identifies which specific action patterns contribute most to extreme events
   - Quick check: Confirm that modifying top-attributed behaviors reduces extreme event occurrence

## Architecture Onboarding

Component map: LLM Agents -> Interaction Layer -> Risk Attribution Engine -> Interpretability Metrics

Critical path: Agent actions → Sequential interaction processing → Marginal contribution calculation → Shapley value aggregation → Risk attribution output

Design tradeoffs: The framework prioritizes interpretability and mathematical rigor over computational efficiency, accepting the computational cost of Shapley value calculations for more accurate risk attribution. This tradeoff is justified by the need for trustworthy explanations in high-stakes applications like financial systems.

Failure signatures: Poor attribution quality may occur when agent behaviors are highly correlated (violating independence assumptions), when extreme events result from rare combinations of actions not well-represented in training data, or when the LLM's stochasticity creates unpredictable interaction patterns.

3 first experiments:
1. Run attribution on a simple economic simulation with known agent roles to verify that the framework correctly identifies high-risk agents
2. Test the framework's sensitivity by introducing controlled perturbations to agent behaviors and measuring attribution changes
3. Validate risk reduction claims by systematically removing top-attributed actions and measuring the impact on extreme event frequency

## Open Questions the Paper Calls Out
None

## Limitations

- The framework assumes objective identification of "extreme events" without addressing threshold determination or system-type variability
- Computational scalability challenges exist for large agent populations due to Shapley value calculations
- Results from controlled scenarios may not generalize to complex, real-world multi-agent systems with unpredictable dynamics

## Confidence

High confidence in mathematical framework soundness and experimental methodology
Medium confidence in generalizability across diverse system types and scalability to large populations
Low confidence in performance under extreme stochasticity and rare event combinations

## Next Checks

1. Test the framework's performance on larger-scale multi-agent systems with 100+ agents to evaluate computational scalability and attribution stability

2. Implement cross-validation by introducing known behavioral interventions and measuring whether the framework correctly identifies their impact on extreme event likelihood

3. Conduct ablation studies to determine which components of the attribution method contribute most to accurate risk identification, particularly comparing Shapley-based attribution against alternative methods like attention-based or gradient-based approaches