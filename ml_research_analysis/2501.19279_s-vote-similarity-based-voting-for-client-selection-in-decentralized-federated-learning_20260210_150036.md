---
ver: rpa2
title: 'S-VOTE: Similarity-based Voting for Client Selection in Decentralized Federated
  Learning'
arxiv_id: '2501.19279'
source_url: https://arxiv.org/abs/2501.19279
tags:
- client
- s-vote
- clients
- training
- local
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces S-VOTE, a voting-based client selection mechanism
  for decentralized federated learning (DFL) that addresses challenges from non-IID
  data distributions, communication overhead, and resource usage. The approach uses
  model similarity-based voting to optimize client participation and reduce unnecessary
  updates, combined with an adaptive strategy for spontaneous local training to address
  participation imbalance.
---

# S-VOTE: Similarity-based Voting for Client Selection in Decentralized Federated Learning

## Quick Facts
- arXiv ID: 2501.19279
- Source URL: https://arxiv.org/abs/2501.19279
- Reference count: 18
- Primary result: Up to 21% lower communication costs, 4-6% faster convergence, and 9-17% improved accuracy compared to baseline methods

## Executive Summary
This paper introduces S-VOTE, a voting-based client selection mechanism for decentralized federated learning that addresses challenges from non-IID data distributions, communication overhead, and resource usage. The approach uses model similarity-based voting to optimize client participation and reduce unnecessary updates, combined with an adaptive strategy for spontaneous local training to address participation imbalance. Evaluated across MNIST, FashionMNIST, EMNIST, and CIFAR-10 datasets with varying network topologies, S-VOTE achieves significant improvements in communication efficiency and model performance while reducing energy consumption.

## Method Summary
S-VOTE implements a three-phase pipeline: initial federated training establishes baseline model similarity, followed by a local divergence phase where models adapt to local data distributions, and finally an adaptive selection phase using cosine similarity between model weight vectors. Clients are selected for aggregation based on a dynamic threshold (μ + τ·σ) and require voting consensus from neighbors (≥ Vmin = N/2) to perform full training. Underutilized clients receive probabilistic training opportunities with increasing probability. The system uses ResNet9 architectures trained with FedAvg aggregation over 30 federation rounds.

## Key Results
- Up to 21% reduction in communication overhead compared to baseline FedAvg
- 4-6% faster convergence across tested datasets and topologies
- 9-17% improvement in F1-score, particularly under high non-IID conditions (α=0.1)
- Up to 24% reduction in energy consumption due to selective aggregation

## Why This Works (Mechanism)

### Mechanism 1: Similarity-Based Client Selection
Filtering aggregation to similar models reduces harmful updates from clients with divergent data distributions. Each client computes cosine similarity between its local model vector and all neighbor models. Selection threshold is dynamic: μ + τ·σ, where μ is mean similarity, σ is standard deviation, and τ is a tunable parameter. Only models exceeding this threshold are aggregated.

### Mechanism 2: Voting-Based Participation Control
Decentralized voting ensures only clients with broad neighbor agreement perform full training, reducing redundant computation. After selection, clients send votes to selected neighbors. A client trains fully only if votes received ≥ Vmin (set to N/2 neighbors). This creates a soft consensus requiring multiple peers to "endorse" a client's relevance.

### Mechanism 3: Adaptive Local Training for Participation Imbalance
Probabilistic training for underutilized clients prevents permanent exclusion without overwhelming resource budgets. Clients below Vmin train with probability p = 0.1 initially. Each round without selection increments p by 0.1 (capped at 1.0). This guarantees eventual participation while deferring resource expenditure.

## Foundational Learning

- Concept: **Cosine Similarity for Model Comparison**
  - Why needed here: Core selection criterion; understanding that cosine similarity measures directional alignment (not magnitude) of weight vectors is essential for tuning τ.
  - Quick check question: Given two models with weights [1,2,3] and [2,4,6], what is their cosine similarity? (Answer: 1.0—they're perfectly aligned directionally despite different magnitudes)

- Concept: **Dirichlet Distribution for Non-IID Partitioning**
  - Why needed here: Paper uses Dir(α) with α ∈ {0.1, 0.5}; lower α = more skewed data splits. Understanding this helps interpret why α=0.1 shows larger S-VOTE advantages.
  - Quick check question: If α=0.1 produces 94% F1 for S-VOTE vs 79% for FedAvg on MNIST, what does α=0.01 likely produce? (Answer: Even larger gap—extreme skew amplifies selection benefits, though absolute performance may drop)

- Concept: **Decentralized Aggregation (FedAvg without server)**
  - Why needed here: S-VOTE modifies standard DFL aggregation; understanding baseline FedAvg (w_t = 1/N Σ w_i) clarifies what's being optimized.
  - Quick check question: In a fully connected 10-client network, how many model transmissions occur per round under standard FedAvg vs S-VOTE if only 6 clients are selected on average? (Answer: FedAvg=90 transmissions; S-VOTE≈54, but exact count depends on asymmetric selection)

## Architecture Onboarding

- Component map: Initial Training Phase -> Divergence Phase -> Similarity Computation -> Selection Module -> Voting Module -> Conditional Training Controller -> Aggregation Module

- Critical path:
  1. Set Tinit (paper uses small value; exact not specified—tune experimentally)
  2. Set τ (threshold multiplier)—paper doesn't specify exact value
  3. Set Vmin = N/2 (validated empirically per Section IV-A)
  4. Initialize p = 0.1 for all clients
  5. Run divergence phase (n rounds—value not specified in algorithm)
  6. Enter main loop: compute similarity → select → vote → conditional train → aggregate

- Design tradeoffs:
  - Higher τ → stricter selection → lower communication but risk of client isolation
  - Higher Vmin → more consensus required → slower rounds but higher quality updates
  - Lower initial p → more resource savings but longer inclusion delay for rare-data clients
  - Assumption: Paper doesn't specify Tinit, n, or τ values—these require tuning per dataset

- Failure signatures:
  - Accuracy plateaus below baseline: τ too high, excluding useful neighbors
  - Random topology underperforms fully connected: Vmin too high for sparse graphs
  - Energy savings absent: p incrementing too fast, causing all clients to train anyway
  - Early-round instability: Tinit too short, models too similar for meaningful selection

- First 3 experiments:
  1. **Baseline replication**: Implement standard DFL FedAvg on MNIST with Dir(α=0.5), 10 clients, fully connected. Verify convergence matches paper's ~98% F1 before adding S-VOTE components.
  2. **Ablation on τ**: Fix Vmin=N/2, test τ ∈ {0.5, 1.0, 1.5, 2.0} on FashionMNIST α=0.1. Measure communication reduction vs accuracy tradeoff curve.
  3. **Topology stress test**: Compare fully connected vs Erdős–Rényi (p=0.5) with 20 clients on CIFAR-10. Verify S-VOTE maintains advantage in sparse settings per paper's Figure 4 results.

## Open Questions the Paper Calls Out

### Open Question 1
Can real-time model divergence metrics be utilized to dynamically adjust the vote threshold ($V_{min}$), improving upon the static threshold strategy used in S-VOTE? The conclusion states that "future work will focus on... the integration of adaptive thresholding techniques, where the vote threshold is dynamically adjusted based on real-time model divergence."

### Open Question 2
Does incorporating a dynamic non-IID assessment mechanism at the start of the federation allow for the formation of similarity-based clusters that optimize training efficiency? The authors propose future work on "incorporating dynamic non-IID assessment mechanisms that determine the degree of heterogeneity in each client data at the beginning of the federation."

### Open Question 3
Is S-VOTE robust against malicious clients attempting to manipulate the federation, given that it relies on model similarity for selection? The introduction identifies the detection of malicious clients as a critical challenge in DFL, stating the absence of a central authority "makes it harder to detect and isolate malicious clients."

### Open Question 4
Does the communication efficiency of S-VOTE scale effectively to large-scale networks (e.g., >100 clients) given the overhead of exchanging model updates for similarity computation? The validation scenario is limited to small topologies (10 and 20 clients), while the Related Work section notes that optimization-based approaches "may lead to scalability problems in large scenarios."

## Limitations

- Critical hyperparameters T_init, n, and τ are not specified, preventing direct replication and suggesting sensitivity to tuning
- ResNet9 architecture details are insufficiently described, requiring reconstruction from generic specifications
- Evaluation is limited to small topologies (10-20 clients), leaving scalability to larger networks unverified

## Confidence

- **High Confidence**: Communication cost reduction (up to 21%) and energy savings (up to 24%) are well-supported by the voting mechanism design and resource-efficient selection process
- **Medium Confidence**: Convergence speed improvements (4-6%) are plausible given the targeted aggregation but depend heavily on proper threshold tuning
- **Low Confidence**: Accuracy improvements (9-17%) across all datasets and conditions are overstated, as they require optimal hyperparameter selection not specified in the paper

## Next Checks

1. **Hyperparameter Sensitivity Analysis**: Systematically test T_init ∈ {3, 5, 10}, n ∈ {3, 5, 10}, and τ ∈ {0.5, 1.0, 1.5} on FashionMNIST α=0.1 to establish performance ranges and identify optimal settings

2. **Extreme Non-IID Stress Test**: Evaluate S-VOTE with Dirichlet α=0.01 (more skewed than paper's α=0.1) to determine if the voting mechanism maintains benefits under severe data imbalance

3. **Topological Robustness Verification**: Compare S-VOTE performance across fully connected, Erdős-Rényi (p=0.3, 0.5, 0.7), and Barabási-Albert topologies to validate claims about handling sparse networks