---
ver: rpa2
title: 'Graft: Integrating the Domain Knowledge via Efficient Parameter Synergy for
  MLLMs'
arxiv_id: '2506.23940'
source_url: https://arxiv.org/abs/2506.23940
tags:
- zhang
- fusion
- arxiv
- wang
- parameter
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Graft, a dual-gate parameter fusion framework
  for integrating domain-specific multimodal large language models (MLLMs). Graft
  employs both local channel-level gating based on parameter differences and global
  entropy-based weighting to adaptively merge model parameters, ensuring effective
  knowledge integration while minimizing interference.
---

# Graft: Integrating the Domain Knowledge via Efficient Parameter Synergy for MLLMs

## Quick Facts
- **arXiv ID**: 2506.23940
- **Source URL**: https://arxiv.org/abs/2506.23940
- **Reference count**: 19
- **Key outcome**: Graft achieves 52.2% on MathVista and 15.9% on HumanEval when fusing LoRA-adapted models, significantly outperforming existing parameter merging methods for integrating domain-specific MLLMs.

## Executive Summary
Graft introduces a dual-gate parameter fusion framework for integrating domain-specific multimodal large language models (MLLMs). The method employs both local channel-level gating based on parameter differences and global entropy-based weighting to adaptively merge model parameters, ensuring effective knowledge integration while minimizing interference. Additionally, it introduces an activation-based compatibility analysis to assess fusion suitability. Experiments across diverse multimodal benchmarks (MathVista, HumanEval, MMMU, MME) demonstrate that Graft significantly outperforms existing merging methods, validating its effectiveness in unifying specialized MLLMs.

## Method Summary
Graft operates through a dual-gate parameter fusion mechanism that integrates multiple domain-specific MLLM adaptations. The local gate applies channel-level gating based on parameter differences between source models, allowing selective activation of relevant parameters. The global gate uses entropy-based weighting to balance contributions from different domains at the module level. An activation-based compatibility analysis assesses fusion suitability by comparing feature space activations across models. The framework is implemented on the Qwen2-VL-2B vision-language model and evaluated through parameter merging of LoRA-adapted domain experts.

## Key Results
- Achieves 52.2% accuracy on MathVista benchmark when fusing LoRA-adapted models
- Reaches 15.9% accuracy on HumanEval benchmark, surpassing existing parameter merging methods
- Demonstrates consistent performance improvements across multiple multimodal benchmarks (MMMU, MME) compared to baseline fusion techniques

## Why This Works (Mechanism)
Graft's effectiveness stems from its dual-gate approach that balances local and global parameter fusion strategies. The local channel-level gating identifies and activates relevant parameters based on differences between source models, preventing interference from conflicting knowledge. The global entropy-based weighting mechanism ensures balanced contribution from different domains by measuring parameter distribution entropy. The activation-based compatibility analysis provides a principled way to assess whether models can be safely merged by comparing their feature space activations. Together, these components enable efficient integration of specialized knowledge while maintaining model stability.

## Foundational Learning

**Parameter Gating**: Why needed - To selectively activate relevant parameters and prevent interference between conflicting domain knowledge. Quick check - Verify that gating mechanisms properly identify and suppress conflicting parameters during fusion.

**Entropy-Based Weighting**: Why needed - To balance contributions from different domains based on parameter distribution characteristics. Quick check - Confirm that entropy calculations accurately reflect domain relevance and prevent dominance by single sources.

**Activation Space Analysis**: Why needed - To assess compatibility between models before fusion and predict integration success. Quick check - Validate that activation similarity correlates with post-fusion performance.

**LoRA Adaptation**: Why needed - As the source of domain-specific knowledge that requires integration. Quick check - Ensure LoRA adapters capture meaningful domain variations without catastrophic forgetting.

## Architecture Onboarding

**Component Map**: Input LoRA adapters → Activation compatibility analysis → Local channel gating → Global entropy weighting → Fused parameter output

**Critical Path**: The essential sequence is activation compatibility check → dual-gate parameter fusion → final model generation. This ensures only compatible models are merged and that both local and global fusion mechanisms are applied.

**Design Tradeoffs**: The method balances computational efficiency (by using parameter differences) against fusion quality (through entropy-based weighting). Local gating provides precision but may miss global patterns, while global weighting captures overall distribution but may overlook fine-grained conflicts.

**Failure Signatures**: Poor activation compatibility scores indicate incompatible models; excessive parameter differences suggest high interference risk; low entropy variation may signal insufficient domain diversity; imbalanced local gating may cause domain collapse.

**First Experiments**:
1. Test activation compatibility analysis on known compatible vs incompatible model pairs
2. Evaluate local gate performance on synthetic parameter differences
3. Validate global entropy weighting on models with varying domain overlap

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Does the Graft framework maintain its efficacy and computational efficiency when applied to significantly larger MLLMs (e.g., 7B, 70B, or 72B parameters) where parameter interference patterns may differ?
- **Basis in paper**: [inferred] The experimental section explicitly states, "We conduct all experiments on the Qwen2-VL-2B vision–language model," leaving performance on larger architectures unverified.
- **Why unresolved**: The dynamics of parameter interference and the behavior of entropy-based gating might change substantially in higher-dimensional parameter spaces found in larger models.
- **What evidence would resolve it**: Evaluation of Graft on larger backbone architectures (e.g., Qwen2-VL-72B) comparing fusion quality and inference latency against the 2B baseline.

### Open Question 2
- **Question**: Does the performance of the dual-gate fusion strategy saturate or degrade when scaling to a large number (e.g., >10) of diverse domain-specific experts?
- **Basis in paper**: [inferred] Table 4 demonstrates "diminishing yet still positive gains" up to four domains, but the method's limits regarding the number of fusable experts are not tested.
- **Why unresolved**: As the number of merged experts increases, the cumulative "inter-domain conflicts" mentioned in the ablation study might overwhelm the local and global gating mechanisms.
- **What evidence would resolve it**: Experiments fusing significantly larger sets of adapters (e.g., 10 or 20 domains) to determine if the method prevents catastrophic forgetting across all source domains.

### Open Question 3
- **Question**: How sensitive is the activation-based compatibility score to the specific choice and size ($K$) of the calibration samples?
- **Basis in paper**: [inferred] Section 3.4 mentions choosing "K input samples... where K is a relatively small value," but provides no analysis of variance or sensitivity regarding which samples are selected.
- **Why unresolved**: If the small sample set is not representative or contains outliers, the resulting compatibility metric could lead to suboptimal fusion decisions.
- **What evidence would resolve it**: An ablation study measuring the variance of the compatibility score across different random seeds and dataset sizes ($K$) to establish statistical reliability.

## Limitations
- Performance and computational efficiency on larger MLLMs (7B, 70B, 72B parameters) remains unverified, limiting generalizability to production-scale models.
- The dual-gate fusion strategy's behavior when merging large numbers of domain experts (>10) is unknown, raising concerns about scalability and potential interference accumulation.
- The activation-based compatibility analysis may be sensitive to calibration sample selection, potentially affecting the reliability of fusion decisions in practice.

## Confidence
- **High confidence**: Empirical performance improvements on benchmark datasets (MathVista, HumanEval, MMMU, MME) are well-supported by experimental results
- **Medium confidence**: Theoretical framework for dual-gate parameter fusion is sound but effectiveness across broader model families and adaptation methods needs additional verification
- **Medium confidence**: Compatibility analysis methodology shows promise but requires testing on wider range of model combinations to establish reliability

## Next Checks
1. Evaluate Graft's performance when merging models adapted through methods other than LoRA, such as full fine-tuning or prefix tuning, to assess generalizability
2. Conduct ablation studies to isolate contributions of local channel-level gating versus global entropy-based weighting in diverse domain integration scenarios
3. Test framework's robustness when fusing models with partially overlapping or conflicting domain knowledge to understand behavior in more complex knowledge integration cases