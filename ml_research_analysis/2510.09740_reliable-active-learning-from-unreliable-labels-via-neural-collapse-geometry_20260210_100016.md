---
ver: rpa2
title: Reliable Active Learning from Unreliable Labels via Neural Collapse Geometry
arxiv_id: '2510.09740'
source_url: https://arxiv.org/abs/2510.09740
tags:
- learning
- active
- samples
- ncal-r
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'NCAL-R addresses unreliable labels in Active Learning by incorporating
  Neural Collapse geometry into sample selection. The method computes two scores:
  Class-Mean Alignment Perturbation (CMAP), which measures how candidate samples perturb
  inter-class feature geometry, and Feature Fluctuation (FF), which captures temporal
  instability of predictions across training checkpoints.'
---

# Reliable Active Learning from Unreliable Labels via Neural Collapse Geometry

## Quick Facts
- arXiv ID: 2510.09740
- Source URL: https://arxiv.org/abs/2510.09740
- Reference count: 34
- Primary result: NCAL-R combines Class-Mean Alignment Perturbation (CMAP) and Feature Fluctuation (FF) scores to improve active learning with noisy labels, achieving 2-3% better accuracy on benchmark datasets

## Executive Summary
NCAL-R introduces a novel active learning approach that leverages neural collapse geometry to handle unreliable labels. The method computes two complementary scores: CMAP measures how candidate samples affect inter-class feature geometry, while FF captures prediction instability across training checkpoints. By combining these scores, NCAL-R identifies samples that preserve class separation while highlighting genuine ambiguities, leading to more robust active learning performance in noisy label scenarios.

## Method Summary
The NCAL-R method addresses unreliable labels in active learning by incorporating neural collapse geometry into sample selection. It computes two scores for each candidate sample: Class-Mean Alignment Perturbation (CMAP) measures how much a sample perturbs the inter-class feature geometry when added to the labeled set, while Feature Fluctuation (FF) captures the temporal instability of predictions across different training checkpoints. The combined score prioritizes samples that both preserve class separation and highlight genuine ambiguities. This dual-scoring mechanism allows NCAL-R to outperform standard active learning baselines on benchmark datasets like ImageNet-100 and CIFAR100, particularly in the presence of synthetic label noise.

## Key Results
- Achieves higher accuracy with fewer labels compared to standard AL baselines on ImageNet-100 and CIFAR100
- Demonstrates approximately 2% better out-of-distribution classification performance
- Shows up to 3% improvement in long-tail distribution scenarios

## Why This Works (Mechanism)
NCAL-R works by leveraging the geometric properties of neural collapse, where features from the same class converge to a single point while different classes become well-separated. The CMAP score identifies samples that, when labeled, would disrupt this desirable geometry, helping avoid confirmation bias from potentially incorrect labels. The FF score captures prediction instability, which often correlates with ambiguous or incorrectly labeled samples. By combining these geometric and temporal signals, NCAL-R can better distinguish between genuinely difficult samples and those with unreliable labels.

## Foundational Learning
- Neural Collapse: Phenomenon where features from the same class collapse to a single point while different classes become maximally separated. Why needed: Provides the geometric foundation for measuring class separability and sample impact. Quick check: Verify that feature representations show collapse behavior in your trained model.
- Active Learning: Framework where the model selects which samples to label from an unlabeled pool. Why needed: Reduces labeling costs while maintaining model performance. Quick check: Confirm that your dataset has a large unlabeled pool available.
- Label Noise Robustness: Ability to maintain performance despite incorrect labels in training data. Why needed: Real-world datasets often contain mislabeled examples. Quick check: Test with synthetic label noise to verify robustness claims.
- Feature Perturbation Analysis: Method of measuring how sample additions affect feature space geometry. Why needed: Helps identify samples that would improve or degrade class separation. Quick check: Visualize feature space before and after adding selected samples.
- Temporal Consistency: Stability of model predictions across different training stages. Why needed: Unreliable labels often cause prediction instability. Quick check: Monitor prediction changes across training checkpoints.

## Architecture Onboarding

**Component Map:** Unlabeled Pool -> Feature Extractor -> CMAP Calculator -> FF Calculator -> Combined Score -> Query Strategy -> Labeled Set

**Critical Path:** The core pipeline flows from the unlabeled pool through feature extraction, where both CMAP and FF scores are computed in parallel, then combined and fed into the query strategy to select samples for labeling.

**Design Tradeoffs:** The dual-scoring mechanism (CMAP + FF) provides complementary information but increases computational overhead. CMAP focuses on geometric properties while FF captures temporal dynamics, requiring storage of intermediate model checkpoints.

**Failure Signatures:** If CMAP dominates too heavily, the method may select only easy, prototypical examples. If FF dominates, it may select only unstable predictions regardless of their geometric value. Poor checkpoint selection can lead to misleading FF scores.

**First Experiments:**
1. Run NCAL-R on a small subset of CIFAR10 with synthetic label noise (10-30%) to verify basic functionality
2. Compare CMAP and FF scores independently on a clean dataset to understand their individual behaviors
3. Visualize the feature space evolution as samples are selected to confirm neural collapse properties are being preserved

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions, focusing instead on demonstrating the effectiveness of the NCAL-R approach across multiple benchmark scenarios.

## Limitations
- Evaluation primarily limited to two benchmark datasets (ImageNet-100 and CIFAR100), which may not represent real-world diversity
- Performance gains of 2-3% may not justify computational overhead in all deployment contexts
- Computational cost of CMAP and FF calculations not fully characterized for larger-scale deployments

## Confidence
- Core claims about NCAL-R's effectiveness: **Medium**
- Claims about improved robustness to label noise: **Medium**
- Claims about better generalization to out-of-distribution data: **Medium**

## Next Checks
1. Evaluate NCAL-R on additional diverse datasets including medical imaging, natural language processing tasks, and real-world noisy label scenarios to assess broader applicability.

2. Conduct ablation studies to determine the individual and combined contributions of CMAP and FF scores, including sensitivity analysis to hyperparameter choices.

3. Measure the computational cost-benefit tradeoff by comparing wall-clock time and resource utilization against performance improvements across different dataset scales and hardware configurations.