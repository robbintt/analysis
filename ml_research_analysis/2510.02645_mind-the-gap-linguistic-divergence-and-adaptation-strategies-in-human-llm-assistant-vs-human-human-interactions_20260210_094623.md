---
ver: rpa2
title: 'Mind the Gap: Linguistic Divergence and Adaptation Strategies in Human-LLM
  Assistant vs. Human-Human Interactions'
arxiv_id: '2510.02645'
source_url: https://arxiv.org/abs/2510.02645
tags:
- user
- style
- human-human
- message
- linguistic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study identifies a linguistic mismatch between human-human
  and human-LLM assistant interactions, where users adopt terser, less polite, and
  grammatically simpler language when interacting with chatbots. To address this,
  the authors propose post-training data augmentation by generating synthetic user
  queries across diverse linguistic styles, ranging from minimal to enriched, using
  a controlled rewriting strategy.
---

# Mind the Gap: Linguistic Divergence and Adaptation Strategies in Human-LLM Assistant vs. Human-Human Interactions

## Quick Facts
- arXiv ID: 2510.02645
- Source URL: https://arxiv.org/abs/2510.02645
- Authors: Fulei Zhang; Zhou Yu
- Reference count: 19
- Primary result: Training-time stylistic diversity improves intent detection by +2.9% relative; inference-time rewriting underperforms by -1.9%

## Executive Summary
This study identifies a linguistic mismatch between human-human and human-LLM assistant interactions, where users adopt terser, less polite, and grammatically simpler language when interacting with chatbots. To address this, the authors propose post-training data augmentation by generating synthetic user queries across diverse linguistic styles, ranging from minimal to enriched, using a controlled rewriting strategy. They also test inference-time query reformulation to align user inputs to the training distribution. Experiments on intent detection show that models trained on stylistically diverse datasets achieve a +2.9% relative improvement over baseline, while inference-time rewriting underperforms with a -1.9% drop. The results demonstrate that training-time exposure to linguistic variety is more effective than post-hoc input normalization for handling style shifts in human-LLM interactions.

## Method Summary
The authors analyze conversational data to characterize linguistic divergence between human-human and human-LLM assistant interactions. They then implement two adaptation strategies: (1) training-time data augmentation through controlled rewriting of existing user queries into multiple stylistic variants, and (2) inference-time query reformulation that normalizes user inputs to match the training distribution. Both approaches are evaluated on intent detection tasks using standard metrics.

## Key Results
- Users consistently adopt terser, less polite, and grammatically simpler language when interacting with chatbots
- Training on stylistically diverse datasets achieves +2.9% relative improvement in intent detection
- Inference-time query rewriting underperforms baseline with -1.9% drop in performance
- Training-time exposure to linguistic variety is more effective than post-hoc input normalization

## Why This Works (Mechanism)
The linguistic divergence occurs because users adapt their communication style based on their mental model of the conversational partner. When users perceive they are interacting with an LLM assistant rather than a human, they simplify their language, assuming the system requires less context and can handle more direct communication. This adaptation creates a distribution shift that degrades model performance when trained primarily on human-human interaction data.

## Foundational Learning
- **Linguistic adaptation**: Why needed - users modify language based on conversational partner type; Quick check - analyze conversation logs for style changes across interaction types
- **Distribution shift**: Why needed - training and inference data differ in style; Quick check - compare statistical properties of human-human vs human-LLM conversations
- **Data augmentation**: Why needed - increase training data diversity to match real-world variation; Quick check - measure performance improvement with synthetic data
- **Controlled rewriting**: Why needed - generate diverse linguistic styles systematically; Quick check - validate rewriting quality through human evaluation
- **Style-aware modeling**: Why needed - capture different linguistic patterns explicitly; Quick check - test model performance across style categories
- **Inference-time normalization**: Why needed - align inputs to training distribution; Quick check - compare raw vs normalized input performance

## Architecture Onboarding
Component map: User Input -> Style Classifier -> Query Rewriter -> Intent Detector
Critical path: User query → Style classification → Query transformation → Intent prediction
Design tradeoffs: Training-time augmentation provides permanent exposure to diversity but increases computational cost; inference-time rewriting is flexible but adds latency and complexity
Failure signatures: Over-simplification leading to ambiguity; under-transformation leaving distribution mismatch; style misclassification causing inappropriate rewrites
First experiments: 1) Baseline intent detection on original human-human data, 2) Intent detection after style augmentation training, 3) A/B testing of inference-time rewriting effectiveness

## Open Questions the Paper Calls Out
None

## Limitations
- Focus on intent detection limits generalizability to other NLP tasks
- Dataset composition and rewriting strategies may not capture full real-world diversity
- Evaluation emphasizes task performance over user experience and satisfaction
- Lacks analysis of deployment impact and practical utility in production systems

## Confidence
- Linguistic divergence observation: High confidence
- Training-time augmentation effectiveness: High confidence
- Inference-time rewriting underperformance: High confidence
- Generalizability to other tasks: Medium confidence
- Practical deployment impact: Low confidence

## Next Checks
1. Replicate experiments across multiple NLP tasks (dialogue generation, question answering, summarization) to test task generalizability
2. Conduct A/B testing with real users to measure satisfaction and effectiveness of both training-time and inference-time adaptation strategies
3. Analyze the impact of linguistic adaptation on underrepresented demographic groups to assess fairness implications of the proposed approaches