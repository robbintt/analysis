---
ver: rpa2
title: Mind the Gap! Choice Independence in Using Multilingual LLMs for Persuasive
  Co-Writing Tasks in Different Languages
arxiv_id: '2502.09532'
source_url: https://arxiv.org/abs/2502.09532
tags:
- language
- llms
- writing
- arxiv
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how multilingual LLM performance affects
  user behavior in persuasive co-writing tasks. Researchers found that prior exposure
  to a Spanish LLM reduced subsequent utilization of an English LLM, violating choice
  independence.
---

# Mind the Gap! Choice Independence in Using Multilingual LLMs for Persuasive Co-Writing Tasks in Different Languages

## Quick Facts
- arXiv ID: 2502.09532
- Source URL: https://arxiv.org/abs/2502.09532
- Reference count: 40
- Primary result: Prior exposure to Spanish LLM reduces subsequent English LLM usage, violating choice independence; authorship beliefs affect charitable donations, especially among Spanish-speaking females

## Executive Summary
This study investigates how multilingual LLM performance disparities affect user behavior in persuasive co-writing tasks. Researchers found that users who experienced poor LLM performance in Spanish subsequently reduced their utilization of the same system for English tasks, violating the behavioral axiom of choice independence. In a charitable giving experiment, donations were largely unaffected by actual LLM involvement, but participants' beliefs about ad authorship influenced donation behavior, particularly among Spanish-speaking females. People were generally unable to distinguish AI-generated from human-written content.

## Method Summary
The study used LLaMA 3.1-8B via Ollama on a single Nvidia A10 GPU to power the ABScribe interface for bilingual (English/Spanish) persuasive writing tasks. 48 bilingual writers created WWF charity advertisements, with their LLM feature usage logged. A separate group of 720 donors read these ads and decided how much of a £1.5 endowment to donate, while reporting beliefs about authorship. The Weighted Average Similarity metric (combining paraphrase-multilingual-MiniLM-L12-v2, nomic-embed-text, and mxbai-embed-large embeddings) measured LLM usage in final outputs.

## Key Results
- Writers exposed to Spanish LLM subsequently used English LLM 27% less frequently (t=2.2, p=0.04)
- 42% of participants incorrectly attributed AI-generated ads to human authors
- Spanish-speaking female participants who believed ads were AI-generated donated significantly less than those who believed they were human-written

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Prior exposure to lower-resource language LLM reduces subsequent utilization of same LLM in higher-resource language
- Mechanism: Users form holistic impressions of AI systems rather than task-specific evaluations, generalizing poor Spanish performance to English tasks
- Core assumption: Users lack AI literacy to attribute performance differences to training data distributions
- Evidence anchors: Abstract finding of reduced English LLM usage after Spanish exposure; section 5.1 statistical result (t=2.2, p=0.04)

### Mechanism 2
- Claim: Donation behavior influenced by perceived authorship rather than actual authorship, particularly for Spanish-speaking females
- Mechanism: Social preference tasks are sensitive to perceived authenticity; algorithmic aversion is culturally mediated
- Core assumption: Implicit pro-human biases in altruistic contexts, stronger in certain demographics
- Evidence anchors: Abstract finding of authorship belief effects; section 5.2 showing downward donation adjustment among Spanish-speaking females

### Mechanism 3
- Claim: Users cannot reliably distinguish human-written from AI-generated persuasive content
- Mechanism: LLMs produce human-like persuasive text that mimics emotional appeals and narrative structures
- Core assumption: Persuasive writing task doesn't surface distinctive AI artifacts
- Evidence anchors: Abstract finding of inability to distinguish content; section 5.2 showing 42% incorrect attribution

## Foundational Learning

- **Choice Independence (Rational Choice Theory)**
  - Why needed here: Paper demonstrates violations of this axiom in human-AI interaction
  - Quick check question: If a user experiences poor AI performance on task A, should this affect their utilization of the same AI on unrelated task B according to rational choice theory?

- **Multilingual LLM Performance Disparities**
  - Why needed here: Mechanism depends on actual performance differences between languages
  - Quick check question: Why might a model trained on 78.99% English data perform worse on Spanish persuasive writing tasks?

- **Human-AI Co-Writing Paradigms**
  - Why needed here: ABScribe tool implements specific interaction model requiring understanding
  - Quick check question: Which feature gives users most autonomy and is therefore most sensitive to trust/choice independence effects?

## Architecture Onboarding

- **Component map**: Writers → ABScribe Interface → LLaMA 3.1-8B → Generated Ads → Donors → Donation Decision → Belief Elicitation

- **Critical path**: Recruit bilingual writers → Randomize to ENG→ESP or ESP→ENG → Track feature-level usage → Collect final ads → Deploy in donation task with belief elicitation

- **Design tradeoffs**: Spanish chosen for feasibility but limits generalizability; LLaMA 3.1-8B selected for compute constraints; between-subjects design avoids demand effects but reduces statistical power

- **Failure signatures**: Near-zero AI Drafter usage indicates manipulation failure; floor donations suggest insensitive paradigm; 100% detection accuracy means insufficient human-like stimulus

- **First 3 experiments**:
  1. Replicate with truly low-resource language (Swahili, Telugu) to test larger performance gaps
  2. Add explicit performance disclosure condition to test awareness mitigation
  3. Extend to agentic workflows to measure sequential task interdependence effects

## Open Questions the Paper Calls Out

1. Does choice independence violation diminish with long-term use and accumulated user experience?
2. How does linguistic distance or resource disparity between languages moderate choice independence violations?
3. How do choice independence violations manifest in agentic workflows requiring complex planning?
4. What specific cultural factors drive negative reactions to perceived AI content among Spanish-speaking females?

## Limitations
- Generalization from Spanish to low-resource languages is uncertain
- Demographic interactions may reflect cultural specificity rather than universal patterns
- Detection inability may reflect task-specific stimulus design

## Confidence
- **High**: English→Spanish LLM usage reduction (direct statistical effect with p=0.04)
- **Medium**: Authorship belief effects on donations (significant interaction but mediated by beliefs)
- **Low**: Generalization of choice independence violations to other language pairs or AI paradigms

## Next Checks
1. Test whether performance gap magnitude correlates with choice independence violation strength across multiple language pairs
2. Measure whether explicit AI literacy training about language-specific performance differences mitigates generalization effects
3. Validate that authorship belief manipulation is robust to different charitable cause domains