---
ver: rpa2
title: Large Language Models for Single-Step and Multi-Step Flight Trajectory Prediction
arxiv_id: '2501.17459'
source_url: https://arxiv.org/abs/2501.17459
tags:
- prediction
- trajectory
- flight
- llms
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study pioneers the application of large language models (LLMs)
  to flight trajectory prediction by reformulating the task as a language modeling
  problem. The authors convert trajectory waypoints into language tokens and use prompt-based
  fine-tuning on ADS-B flight data.
---

# Large Language Models for Single-Step and Multi-Step Flight Trajectory Prediction

## Quick Facts
- arXiv ID: 2501.17459
- Source URL: https://arxiv.org/abs/2501.17459
- Reference count: 40
- Primary result: LLMs significantly outperform traditional deep learning methods in flight trajectory prediction

## Executive Summary
This study pioneers the application of large language models (LLMs) to flight trajectory prediction by reformulating the task as a language modeling problem. The authors convert trajectory waypoints into language tokens and use prompt-based fine-tuning on ADS-B flight data. Experimental results show that LLMs significantly outperform traditional deep learning methods in both single-step and multi-step prediction tasks, with Mistral-7B-v0.2 achieving the best performance in single-step prediction and LLaMA-3.1-8B excelling in multi-step prediction. However, LLMs suffer from high inference latency compared to traditional models.

## Method Summary
The authors convert ADS-B flight data attributes (longitude, latitude, altitude, velocity, heading angle) into language tokens and treat trajectory prediction as next-token prediction. They use prompt-based fine-tuning with aviation-domain prompts containing system, user, and assistant segments. The models are fine-tuned using LoRA with 4-bit quantization on 7-9B parameter LLMs. Sliding window sampling extracts 16 historical waypoints as input and 1-8 target waypoints for prediction. The approach demonstrates strong few-shot learning capabilities and achieves superior accuracy compared to LSTM, BiLSTM, and Transformer baselines.

## Key Results
- LLMs achieve superior accuracy compared to traditional deep learning methods in both single-step and multi-step prediction
- Mistral-7B-v0.2 performs best in single-step prediction while LLaMA-3.1-8B excels in multi-step prediction
- LLMs demonstrate strong few-shot learning capabilities, maintaining performance with only 30% of training data

## Why This Works (Mechanism)

### Mechanism 1
Numerical trajectory waypoints can be reformulated as language tokens, enabling LLMs to treat trajectory prediction as next-token prediction. ADS-B flight data attributes are rounded and processed through an LLM tokenizer, with the model learning the probability distribution P(ŵ_j | w_1, w_2, ..., w_{j-1}) for trajectory continuation. This works because spatiotemporal patterns in flight trajectories exhibit sequential dependencies analogous to linguistic structure. If trajectories contain abrupt, unanticipated maneuvers without historical precedent, the sequential token prediction degrades significantly.

### Mechanism 2
Aviation-domain prompt construction with role specification and structured context improves LLM alignment to trajectory prediction tasks. Prompts comprise system (role definition and terminology), user (historical waypoints), and assistant (target waypoints) segments. This structure channels the model's pre-trained knowledge toward aviation-specific reasoning. Explicit role definition and domain context in prompts activate relevant latent knowledge in pre-trained LLMs, reducing the fine-tuning burden. If prompt context window exceeds model limits for long-horizon multi-step prediction, token truncation may lose critical historical patterns.

### Mechanism 3
Parameter-Efficient Fine-Tuning (LoRA with 4-bit quantization) preserves pre-trained knowledge while adapting LLMs to trajectory prediction with limited data. LoRA injects low-rank trainable matrices into transformer layers, updating only ~1-2% of parameters while keeping pre-trained weights frozen. Combined with 4-bit quantization, this enables single RTX 4090 fine-tuning. With only 30% of training data, LLaMA-3.1 achieves performance comparable to full-data baseline models. If the base model lacks sufficient pre-trained sequential reasoning capacity, LoRA adaptation may underfit complex trajectory dynamics.

## Foundational Learning

- **Tokenization of Numerical Data**: Understanding how continuous flight attributes map to discrete vocabulary tokens is essential for debugging prediction failures. Quick check: Given waypoint altitude 10058.400m, how many tokens would LLaMA-3.1 generate versus Mistral-7B?

- **Sliding Window Sampling for Time Series**: The paper uses window sizes of 17 (16 input + 1 prediction) for single-step and 20/24 for multi-step. Understanding stride and non-overlap constraints is critical for data preparation. Quick check: Why must stride exceed window size, and what happens to trajectory continuity if an aircraft makes a stopover?

- **Inference Latency vs. Accuracy Trade-offs**: LLMs achieve superior accuracy but 1000x higher latency compared to LSTM/Transformer, making them unsuitable for real-time ATC without acceleration techniques. Quick check: For 8-step prediction, which model provides the best accuracy-latency ratio, and would quantization-aware inference help?

## Architecture Onboarding

- **Component map**: ADS-B preprocessing -> window sampling -> prompt formatting -> tokenizer -> LoRA-fine-tuned LLM -> token decoding -> coordinate parsing
- **Critical path**: ADS-B preprocessing → window sampling → prompt formatting → tokenizer → LoRA-fine-tuned LLM → token decoding → coordinate parsing. Failure at any stage cascades; the paper notes Yi-1.5 produces missing trajectories, incorrect formats, and sign errors.
- **Design tradeoffs**: LLaMA-3.1 achieves best 8-step accuracy (MAE 0.0434°) but 6.67s latency; LSTM is 8000x faster but 13% worse accuracy. LLaMA-3.1's numerical tokenization reduces inference time vs. character-level splitting. Cruise phase predictions most accurate; take-off phase has 2-3x higher altitude errors due to rapid climbs.
- **Failure signatures**: Format violations (model outputs non-coordinate format), sign errors (negative longitude/latitude when positive expected), sudden maneuver failures (abrupt altitude drops or sharp turns cause all models to fail), token length overflow (multi-step predictions approaching context limits may truncate).
- **First 3 experiments**: 1) Fine-tune LLaMA-3.1-8B on processed ADS-B data from one airport with LoRA rank=8, 4-bit quantization, 3 epochs; verify single-step MAE < 0.006° for longitude/latitude. 2) Compare full system+user prompt against user-only prompt; quantify accuracy degradation to isolate role-definition contribution. 3) Separate test set by flight phase (take-off, cruise, landing); expect cruise MAE ~0.005° longitude vs. take-off ~0.02° per Table III, confirming phase-dependent difficulty.

## Open Questions the Paper Calls Out

- Can inference acceleration techniques reduce LLM latency sufficiently to meet real-time air traffic management requirements? The authors explicitly call for inference acceleration techniques in future work due to 1000x higher latency compared to traditional models.

- How can LLM-based trajectory prediction be improved to handle unexpected flight maneuvers such as sudden altitude drops or sharp turns? The authors note that LLMs yield less accurate results when unexpected operations occur during flight.

- Can phase-specific fine-tuning or specialized prompt designs reduce the significant performance variance across take-off, cruise, and landing phases? The authors observe that prediction errors vary significantly across different flight phases.

## Limitations

- High inference latency (1000x slower than traditional models) limits real-time application without acceleration techniques
- Performance degrades significantly when unexpected flight maneuvers occur
- Significant performance variance across different flight phases (take-off vs cruise vs landing)

## Confidence

**High Confidence:**
- LLMs outperform traditional deep learning methods in flight trajectory prediction
- LLaMA-3.1-8B achieves best multi-step prediction performance
- Mistral-7B-v0.2 excels in single-step prediction
- LLMs demonstrate strong few-shot learning capabilities

**Medium Confidence:**
- Tokenization approach effectively captures spatiotemporal patterns
- Aviation-domain prompt engineering improves model alignment
- Phase-specific performance variations are significant

**Low Confidence:**
- Long-term multi-step prediction accuracy beyond 8 steps
- Generalization to different geographic regions
- Performance with different tokenization strategies

## Next Checks

1. **Data Generalization Test**: Evaluate the best-performing models (LLaMA-3.1-8B and Mistral-7B-v0.2) on ADS-B data from airports not included in the original training set to assess geographic generalization capabilities.

2. **Computational Efficiency Analysis**: Implement quantization-aware inference and test whether 8-bit or 16-bit quantization can reduce latency while maintaining accuracy within 10% of the 4-bit results.

3. **Tokenization Robustness Evaluation**: Systematically test the tokenization approach on trajectories with extreme maneuvers (altitude changes > 1000m/min, heading changes > 90°) to quantify failure rates and identify conditions where traditional models may be more reliable.