---
ver: rpa2
title: End-to-End Data Quality-Driven Framework for Machine Learning in Production
  Environment
arxiv_id: '2512.19723'
source_url: https://arxiv.org/abs/2512.19723
tags:
- data
- quality
- framework
- performance
- industrial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel end-to-end framework that integrates
  real-time data quality assessment with machine learning (ML) model operations in
  production environments. The framework combines dynamic drift detection, adaptive
  data quality metrics, and MLOps principles into a lightweight, efficient system.
---

# End-to-End Data Quality-Driven Framework for Machine Learning in Production Environment

## Quick Facts
- arXiv ID: 2512.19723
- Source URL: https://arxiv.org/abs/2512.19723
- Reference count: 40
- A novel end-to-end framework integrating real-time data quality assessment with ML model operations in production environments, validated in steel manufacturing ESR vacuum pumping process.

## Executive Summary
This paper introduces a comprehensive framework that addresses the critical gap between theoretical ML methods and practical production deployment by integrating real-time data quality assessment with machine learning operations. The framework combines dynamic drift detection, adaptive data quality metrics, and MLOps principles into a lightweight, efficient system that enables continuous adaptation to changing data distributions while maintaining high data quality standards. Through validation in a steel manufacturing Electroslag Remelting vacuum pumping process, the framework demonstrated a 12% improvement in model performance (R2 = 94%) and a fourfold reduction in prediction latency compared to traditional approaches.

## Method Summary
The framework operates in two phases: initialization and deployment. During initialization, data quality scores are computed across five dimensions (accuracy, completeness, consistency, timeliness, skewness) using techniques like KS tests and JSD, then combined via PCA into a unified score. An XGBoost regressor is trained to predict quality scores from raw data, while an XGBoost inference model is trained on quality-filtered data. In deployment, active drift detection continuously compares incoming data windows against reference distributions using divergence measures (JSD, KL), triggering immediate model retraining when drift magnitude exceeds adaptive thresholds. The system processes 1200×f matrices per sample from Apache Kafka streams, predicting minimum pressure in the first 2 minutes of ESR vacuum pumping to trigger alarms for pump irregularities.

## Key Results
- 12% improvement in model performance (R2 = 94%) through moderate data quality filtering at 25% acceptability threshold
- Fourfold reduction in prediction latency (from 801.83s to 193.33s) using active drift detection vs passive window-based approaches
- Optimal balance achieved with 25% DQ threshold: excludes ~3% of data while maximizing predictive accuracy

## Why This Works (Mechanism)

### Mechanism 1: Optimal Data Quality Thresholding
Moderate data quality filtering at 25% acceptability threshold improves predictive performance by removing problematic data points while preserving sufficient training volume. The framework computes unified DQ scores across five dimensions and excludes training samples below threshold, avoiding information loss that occurs at higher thresholds (90% filtered 47% of data and degraded performance).

### Mechanism 2: Active Drift Detection with Adaptive Thresholds
Active drift detection with adaptive thresholds achieves lower latency and higher accuracy than passive window-based approaches. The system continuously compares incoming data windows against reference distributions using divergence measures, triggering immediate model retraining when drift magnitude exceeds adaptive threshold τ. Active τ=0.08 achieved 20 adaptations with MAE <0.51 and R²≈94%, while standard approaches showed 801.83s latency vs 193.33s for active.

### Mechanism 3: ML-Based Data Quality Scoring
ML-based DQ scoring using XGBoost regressor enables real-time quality assessment with lower computational overhead than direct metric computation. Instead of computing all DQ dimensions per sample in production, a pre-trained XGBoost model predicts unified DQ scores from input features, enabling inference-time scoring in milliseconds versus batch computation.

## Foundational Learning

- **Concept: Divergence-based drift detection (KL, JSD)**
  - Why needed here: The framework uses JSD and KL divergence to quantify distribution shift between reference and current data windows.
  - Quick check question: Can you explain why JSD is bounded to [0,1] while KL divergence is unbounded, and which property makes threshold selection easier?

- **Concept: Principal Component Analysis (PCA) for score aggregation**
  - Why needed here: Five DQ dimension scores are combined via PCA into a unified score, requiring understanding of variance-weighted dimensionality reduction.
  - Quick check question: If one DQ dimension has much higher variance than others, how does PCA's weighting affect that dimension's influence on the unified score?

- **Concept: CI/CD for ML (model registry, artifact versioning)**
  - Why needed here: The deployment phase uses continuous monitoring and automated retraining triggers; engineers must understand model versioning and rollback.
  - Quick check question: When drift is detected at time T, what artifacts must be versioned to enable reproducible rollback to the pre-drift model state?

## Architecture Onboarding

- **Component map:**
  Initialization Phase: Data store → DQ scoring module (XGBoost regressor) → Quality-scored data → DQ-aware ML model training (XGBoost inference model) → Model registry
  Deployment Phase: Data source (Kafka stream) → Drift detector (divergence vs reference) → [if drift] CI packaging service → CD model serving → ML inference model → Action
  Metadata store holds: drift detection config, DQ scoring config, training settings

- **Critical path:**
  1. Establish reference distribution from warm-start data
  2. Train DQ scoring model on annotated samples
  3. Train inference model on quality-filtered data
  4. Deploy both models with drift monitoring
  5. On drift detection: trigger retraining pipeline, update model registry

- **Design tradeoffs:**
  - Lower τ (0.04): fewer adaptations (9), lower compute, potentially stale model
  - Higher τ (0.08): more adaptations (20), higher compute, better accuracy
  - 25% DQ threshold: best accuracy, excludes ~3% of data
  - 90% DQ threshold: fastest latency, excludes 47% of data, lower accuracy

- **Failure signatures:**
  - Sudden latency spike: drift detection threshold too sensitive, excessive retraining
  - Accuracy degradation despite no drift alert: DQ dimensions miss relevant quality issues
  - Model predictions erratic after retraining: insufficient training data after aggressive DQ filtering
  - DQ scores stuck at extremes: scoring model not generalizing, requires re-annotation

- **First 3 experiments:**
  1. Establish baseline: Run inference model without DQ filtering or drift detection; record MAE, R², and end-to-end latency over 1000 samples.
  2. Threshold sweep: Test DQ thresholds (0%, 25%, 50%, 75%, 90%) with fixed τ=0.06; plot MAE and latency vs threshold to identify Pareto-optimal point.
  3. Active vs passive comparison: At the 25% threshold, compare active (τ=0.08) vs passive (w=50) over 1000 time steps; measure cumulative latency and final R².

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the data quality scoring methodology be adapted to handle sparse datasets where data quality ratios may produce unreliable assessments?
- Basis in paper: The authors state: "The data quality (DQ) ratio methodology may exhibit different behaviors when applied to datasets with sparse data. Since data quality is calculated through ratios, the DQ scores may require refinement for more accurate assessment in low-volume scenarios."
- Why unresolved: The current DQ scoring approach assumes sufficient data volume for reliable ratio-based calculations; sparse data contexts were not tested or addressed in the ESR case study.
- What evidence would resolve it: Empirical evaluation of the framework on industrial datasets with varying sparsity levels, comparing refined scoring approaches against the current ratio-based method.

### Open Question 2
- Question: To what extent does the optimal 25% data quality acceptability threshold generalize across different industrial processes and domains?
- Basis in paper: The paper reports that "moderate levels of data quality filtering, particularly the 25% acceptability threshold, produced optimal predictive performance" for the ESR process, but does not test whether this threshold is domain-specific or universally applicable.
- Why unresolved: The threshold was empirically determined through a single case study; its transferability to other industrial contexts with different data characteristics remains untested.
- What evidence would resolve it: Cross-domain experiments applying the framework to diverse industrial processes (e.g., manufacturing, healthcare, finance) to identify threshold sensitivity patterns or domain-independent optimal ranges.

### Open Question 3
- Question: How can the framework be extended to handle unstructured or heterogeneous data sources common in complex industrial environments?
- Basis in paper: The authors acknowledge: "The current implementation is focused on structured, time-series data. Extending the framework to handle unstructured or heterogeneous data sources would enhance its applicability."
- Why unresolved: The data quality dimensions (accuracy, completeness, consistency, timeliness, skewness) and scoring mechanisms were designed for structured sensor data; their applicability to images, text, or mixed-format data streams is unaddressed.
- What evidence would resolve it: Implementation and validation of the framework on industrial use cases involving unstructured data (e.g., visual quality inspection, log analysis) with appropriate dimension definitions and scoring adaptations.

## Limitations
- Generalizability beyond ESR vacuum pumping domain remains uncertain due to domain-specific data quality dimension definitions
- ML-based data quality scoring depends heavily on quality of ground truth annotations, methodology for which lacks detailed specification
- Computational overhead of continuous divergence calculations and model retraining in production environments with different data volumes is not fully characterized

## Confidence

**High Confidence:** The demonstrated 12% improvement in R² (to 94%) and fourfold reduction in prediction latency through active drift detection are well-supported by the presented experimental results, particularly Table 1 comparing cumulative latencies across methods.

**Medium Confidence:** The optimal 25% data quality threshold finding is robust within the ESR context but may not transfer directly to domains with different data quality distributions or failure modes.

**Low Confidence:** The scalability claims for industrial applications lack validation across multiple production environments with varying data characteristics and operational constraints.

## Next Checks

1. **Cross-domain validation:** Apply the framework to a different industrial ML use case (e.g., predictive maintenance in manufacturing or anomaly detection in chemical processes) and compare performance improvements against baseline implementations.

2. **Computational profiling:** Measure CPU/GPU utilization, memory consumption, and end-to-end pipeline latency across varying data volumes (10K-1M samples) to establish scalability boundaries and identify bottlenecks.

3. **Ground truth robustness test:** Systematically perturb the ground truth labeling process by introducing controlled noise and measure the impact on data quality scoring accuracy and downstream model performance to quantify annotation sensitivity.