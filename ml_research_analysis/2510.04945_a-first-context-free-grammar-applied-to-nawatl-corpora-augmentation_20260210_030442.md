---
ver: rpa2
title: A First Context-Free Grammar Applied to Nawatl Corpora Augmentation
arxiv_id: '2510.04945'
source_url: https://arxiv.org/abs/2510.04945
tags:
- nawatl
- language
- sentences
- corpus
- grammar
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper introduces a context-free grammar (CFG) to generate\
  \ artificial sentences in Nawatl, a low-resource indigenous language, to augment\
  \ limited corpora for language model training. A micro-grammar \xB5GNAW\u22950 was\
  \ constructed to produce syntactically valid sentences, which were then filtered\
  \ for semantic plausibility using rules on animate/inanimate noun-verb associations."
---

# A First Context-Free Grammar Applied to Nawatl Corpora Augmentation

## Quick Facts
- arXiv ID: 2510.04945
- Source URL: https://arxiv.org/abs/2510.04945
- Reference count: 6
- Primary result: CFG-generated artificial sentences improved Nawatl FastText semantic similarity performance to 0.527 Kendall's τ

## Executive Summary
This paper presents a novel approach to corpus augmentation for the low-resource indigenous language Nawatl using context-free grammar (CFG). The researchers constructed a micro-grammar µGNAW⊕0 to generate syntactically valid artificial sentences, which were then filtered for semantic plausibility through hand-crafted rules on animate/inanimate noun-verb associations. The resulting augmented corpus π-yall-IA⊕0, containing approximately 11 million tokens, was used to train FastText models that achieved competitive performance on sentence-level semantic similarity tasks, ranking third behind large language models.

## Method Summary
The methodology involved constructing a micro-grammar µGNAW⊕0 specifically for Nawatl syntax, generating artificial sentences through CFG rules, and applying semantic filtering based on animacy constraints. The artificial sentences were merged with the existing π-YALLI corpus to create an enriched dataset. FastText models were then trained on this augmented corpus and evaluated on a semantic similarity task using Kendall's τ metric. The approach demonstrates how rule-based generation can supplement limited natural data for low-resource language modeling.

## Key Results
- FastText models trained on π-yall-IA⊕0 corpus achieved 0.527 Kendall's τ on semantic similarity task
- Performance ranked third behind Gemini 2.5 (0.693) and Claude 3.7 (0.607)
- Generated approximately 807K artificial sentences after semantic filtering
- Final augmented corpus contains approximately 11M tokens

## Why This Works (Mechanism)
The approach works by leveraging linguistic knowledge encoded in CFG rules to systematically generate syntactically valid sentences that expand the limited natural corpus. The semantic filtering step ensures that generated content maintains linguistic plausibility by enforcing animacy constraints on noun-verb associations. This combination of syntactic generation and semantic validation creates a corpus that preserves the structural and semantic properties of Nawatl while significantly increasing the available training data for language models.

## Foundational Learning

**Context-Free Grammar (CFG)**: A formal grammar that generates all possible strings in a language using production rules. Why needed: Provides systematic way to generate syntactically valid sentences from limited seed rules. Quick check: Verify that generated sentences follow Nawatl word order and agreement patterns.

**Semantic Plausibility Filtering**: Post-generation filtering based on semantic constraints like animacy. Why needed: Ensures generated sentences are not just syntactically valid but also semantically meaningful. Quick check: Random sampling of generated sentences should show appropriate noun-verb associations.

**Corpus Augmentation**: The process of expanding limited training data with artificial examples. Why needed: Addresses the fundamental challenge of insufficient data for low-resource languages. Quick check: Compare vocabulary coverage and n-gram statistics between original and augmented corpora.

## Architecture Onboarding

**Component map**: Nawatl Linguistic Rules -> µGNAW⊕0 Micro-grammar -> CFG Generation -> Semantic Filtering -> Augmented Corpus -> FastText Training -> Semantic Similarity Evaluation

**Critical path**: The pipeline flow from grammar construction through to model evaluation, with semantic filtering as the key bottleneck that determines the quality and quantity of final augmented data.

**Design tradeoffs**: Manual grammar construction provides linguistic accuracy but limits coverage and scalability; semantic filtering rules ensure quality but may exclude valid constructions; rule-based generation offers reproducibility but lacks the diversity of data-driven approaches.

**Failure signatures**: Poor semantic filtering leads to ungrammatical or semantically implausible sentences; incomplete grammar coverage results in repetitive or limited sentence structures; inadequate filtering rules may introduce semantic biases or miss valid constructions.

**First experiments**:
1. Generate a small batch of sentences and manually evaluate for grammatical correctness and semantic plausibility
2. Test FastText models trained on minimal augmented data on a simple downstream task
3. Compare vocabulary overlap and n-gram statistics between original and augmented corpora

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Artificial sentence generation heavily depends on the quality and coverage of manually constructed micro-grammar
- Semantic filtering rules are hand-crafted and may miss nuanced semantic relationships or introduce biases
- Evaluation focuses on a single semantic similarity task, limiting understanding of broader downstream performance impacts

## Confidence
- High: The methodology for CFG generation and filtering is clearly described and reproducible
- Medium: The quantitative results showing improved FastText performance are valid for the specific task and corpus
- Medium: The claim that artificial data meaningfully improves static model performance in low-resource scenarios, though results are specific to Nawatl and semantic similarity

## Next Checks
1. Evaluate the augmented corpus on multiple downstream tasks (POS tagging, machine translation, dialect classification) to assess broader utility beyond semantic similarity
2. Conduct human evaluation of randomly sampled artificial sentences to verify semantic plausibility and grammatical correctness
3. Test the approach on other low-resource languages with different typological features to assess cross-linguistic applicability