---
ver: rpa2
title: A Comparison and Evaluation of Fine-tuned Convolutional Neural Networks to
  Large Language Models for Image Classification and Segmentation of Brain Tumors
  on MRI
arxiv_id: '2509.10683'
source_url: https://arxiv.org/abs/2509.10683
tags:
- segmentation
- glioma
- figure
- bounding
- tumor
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study compared the performance of general-purpose large language
  models (LLMs) and specialized convolutional neural networks (CNNs) for brain tumor
  classification and segmentation using the BraTS 2020 dataset. CNNs outperformed
  LLMs in both tasks, achieving higher accuracy and better segmentation results.
---

# A Comparison and Evaluation of Fine-tuned Convolutional Neural Networks to Large Language Models for Image Classification and Segmentation of Brain Tumors on MRI

## Quick Facts
- arXiv ID: 2509.10683
- Source URL: https://arxiv.org/abs/2509.10683
- Authors: Felicia Liu; Jay J. Yoo; Farzad Khalvati
- Reference count: 17
- Primary result: CNNs outperformed LLMs for brain tumor classification and segmentation on BraTS 2020 dataset

## Executive Summary
This study compared the performance of general-purpose large language models (LLMs) and specialized convolutional neural networks (CNNs) for brain tumor classification and segmentation using the BraTS 2020 dataset. CNNs demonstrated clear superiority, achieving 80% accuracy for tumor classification and a Dice coefficient of 0.5942 for segmentation. In contrast, the general-purpose LLM (LLaMA 3.2 Instruct) struggled with tumor localization and classification, often misclassifying tumors and clustering predictions near the image center. Even after fine-tuning, the LLM showed only marginal improvements, indicating that current LLMs are not well-suited for image-based medical tasks without more rigorous fine-tuning or alternative training strategies.

## Method Summary
The study evaluated CNNs and LLMs for brain tumor classification and segmentation using the BraTS 2020 dataset. CNNs were trained specifically for these tasks, while a general-purpose LLM (LLaMA 3.2 Instruct) was tested in its original form and after fine-tuning. The CNN approach achieved 80% accuracy for classification and a Dice coefficient of 0.5942 for segmentation, while the LLM struggled with both tasks, particularly with tumor localization and often misclassifying tumors.

## Key Results
- CNN achieved 80% accuracy for tumor classification, outperforming the LLM
- CNN achieved Dice coefficient of 0.5942 for tumor segmentation, significantly better than LLM performance
- LLM clustered predictions near image center and struggled with tumor localization even after fine-tuning

## Why This Works (Mechanism)
CNNs excel at spatial pattern recognition in images due to their convolutional layers that preserve spatial hierarchies and local features. The hierarchical feature extraction allows CNNs to identify tumor boundaries and characteristics effectively. LLMs, designed primarily for sequential language processing, lack the architectural components necessary for precise spatial reasoning and localization in medical images.

## Foundational Learning
1. **Convolutional Neural Networks** - Why needed: Extract spatial features from images; Quick check: Verify kernel sizes and filter counts in CNN layers
2. **Dice Coefficient** - Why needed: Measure overlap between predicted and ground truth segmentation; Quick check: Confirm calculation method for segmentation evaluation
3. **BraTS Dataset** - Why needed: Standard benchmark for brain tumor segmentation; Quick check: Verify image preprocessing and augmentation methods
4. **Fine-tuning** - Why needed: Adapt pre-trained models to specific tasks; Quick check: Review learning rate schedules and training epochs
5. **Tumor Classification** - Why needed: Distinguish between tumor types for diagnosis; Quick check: Confirm class balance and evaluation metrics
6. **Image Segmentation** - Why needed: Identify precise tumor boundaries; Quick check: Validate post-processing steps for segmentation masks

## Architecture Onboarding

**Component Map:** Image Input -> CNN Feature Extraction -> Classification Head / Segmentation Head vs. Image Input -> LLM Tokenization -> Classification Head

**Critical Path:** For CNNs: Image → Convolutional Layers → Feature Maps → Classification/Regression → Output. For LLMs: Image → Patch Embedding → Transformer Blocks → Classification/Regression → Output.

**Design Tradeoffs:** CNNs offer specialized spatial feature extraction with fewer parameters for image tasks, while LLMs provide general-purpose reasoning but require more parameters and struggle with spatial precision.

**Failure Signatures:** CNNs fail with insufficient training data or poor augmentation; LLMs fail with spatial reasoning tasks, clustering predictions centrally and misclassifying tumors.

**First Experiments:**
1. Evaluate CNN performance on a held-out validation set before testing on test set
2. Compare LLM predictions with and without fine-tuning on a small subset
3. Visualize CNN feature maps to verify tumor region activation

## Open Questions the Paper Calls Out
None

## Limitations
- Study focused only on one general-purpose LLM without exploring specialized multimodal models
- Limited evaluation to binary classification rather than multi-class tumor grading
- Acknowledges that more rigorous fine-tuning or alternative training strategies may be needed for LLMs

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| CNNs outperforming LLMs for specific tasks and dataset tested | High |
| LLM's tendency to cluster predictions near image center | High |
| LLMs are "not well-suited" for image-based medical tasks in current form | Medium |
| Claims about LLMs' fundamental limitations for medical imaging | Low |

## Next Checks
1. Evaluate specialized multimodal LLMs (such as Med-PaLM or models specifically trained on medical imaging) against the same benchmark to determine if architecture choice affects performance.
2. Test the same LLMs with extended fine-tuning periods using medical imaging-specific datasets to assess whether performance improves with more rigorous training.
3. Expand the evaluation to include multi-class tumor grading and segmentation of tumor subregions (enhancing tumor, tumor core, whole tumor) rather than binary classification to better reflect clinical requirements.