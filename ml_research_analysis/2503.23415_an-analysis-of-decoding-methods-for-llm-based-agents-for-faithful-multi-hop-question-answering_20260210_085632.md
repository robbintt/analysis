---
ver: rpa2
title: An Analysis of Decoding Methods for LLM-based Agents for Faithful Multi-Hop
  Question Answering
arxiv_id: '2503.23415'
source_url: https://arxiv.org/abs/2503.23415
tags:
- answer
- decoding
- react
- question
- faithful
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper examines how decoding methods can enhance the faithfulness
  of large language model (LLM) generations in multi-hop question answering. Retrieval-augmented
  generation and agentic frameworks like ReAct provide access to external knowledge,
  but LLMs often produce hallucinations by not remaining faithful to retrieved context.
---

# An Analysis of Decoding Methods for LLM-based Agents for Faithful Multi-Hop Question Answering

## Quick Facts
- arXiv ID: 2503.23415
- Source URL: https://arxiv.org/abs/2503.23415
- Authors: Alexander Murphy; Mohd Sanad Zaki Rizvi; Aden Haussmann; Ping Nie; Guifu Liu; Aryo Pradipta Gema; Pasquale Minervini
- Reference count: 18
- Primary result: Decoding methods improve faithfulness in multi-hop QA

## Executive Summary
This paper examines how decoding methods can enhance the faithfulness of large language model (LLM) generations in multi-hop question answering. Retrieval-augmented generation and agentic frameworks like ReAct provide access to external knowledge, but LLMs often produce hallucinations by not remaining faithful to retrieved context. The study systematically evaluates three training-free decoding strategies—Context-Aware Decoding (CAD), Decoding by Contrasting Layers (DoLa), and Decoding by Contrasting Retrieval Heads (DeCoRe)—when combined with the ReAct framework.

Experiments on three multi-hop QA datasets (HotpotQA, 2WikiMultihopQA, and MuSiQue) with Qwen2-7b-Instruct and Llama3-8b-Instruct show consistent improvements. Using ReAct with DoLa increases HotpotQA answer F1 from 19.5 to 32.6 (over 50% relative improvement). Format adherence also improves significantly, with CAD increasing correct ReAct trace formatting on HotpotQA from 47.9% to 74.5% for Qwen. Retrieval metrics show similar gains, with DeCoRe improving HotpotQA support recall from 44.3% to 46.6% for Qwen. The results demonstrate that combining agentic knowledge retrieval with faithfulness-enhancing decoding methods substantially improves both answer accuracy and reasoning format adherence in complex QA tasks.

## Method Summary
The study evaluates three training-free decoding methods—Context-Aware Decoding (CAD), Decoding by Contrasting Layers (DoLa), and Decoding by Contrasting Retrieval Heads (DeCoRe)—integrated with the ReAct framework for multi-hop question answering. These methods are designed to improve faithfulness by ensuring generated outputs remain consistent with retrieved context. The evaluation uses two model sizes (Qwen2-7b-Instruct and Llama3-8b-Instruct) across three multi-hop QA datasets, measuring performance on answer accuracy, format adherence, and retrieval quality.

## Key Results
- ReAct with DoLa improves HotpotQA answer F1 from 19.5 to 32.6 (over 50% relative improvement)
- CAD increases correct ReAct trace formatting on HotpotQA from 47.9% to 74.5% for Qwen
- DeCoRe improves HotpotQA support recall from 44.3% to 46.6% for Qwen

## Why This Works (Mechanism)
The decoding methods work by enforcing consistency between generated outputs and retrieved context, reducing hallucinations that commonly occur in multi-hop question answering. CAD operates by monitoring context relevance during generation, DoLa contrasts different layers to identify faithful representations, and DeCoRe specifically contrasts retrieval heads to ensure alignment with retrieved information. When integrated with the ReAct framework, these methods guide the agent's reasoning process to stay grounded in verified knowledge rather than generating unsupported conclusions.

## Foundational Learning

- **Multi-hop QA**: Requires reasoning across multiple pieces of evidence; needed because single-hop methods fail on complex questions requiring inference chains; quick check: verify questions require at least two supporting facts.
- **Retrieval-augmented generation**: Combines external knowledge retrieval with generation; needed because LLMs have limited knowledge; quick check: confirm retrieved documents are actually used in generation.
- **Faithfulness**: Output consistency with retrieved context; needed because hallucinations undermine reliability; quick check: measure hallucination rate with automatic metrics.
- **ReAct framework**: Combines reasoning and acting for agentic QA; needed because pure generation lacks structured reasoning; quick check: verify trace format adherence.
- **Decoding methods**: Techniques to control generation; needed because standard decoding produces hallucinations; quick check: compare with standard decoding baselines.

## Architecture Onboarding

**Component Map**: Retrieval System -> ReAct Agent -> Decoding Method -> Output Generator

**Critical Path**: Question -> Retrieval -> ReAct Reasoning Trace -> Decoding Method Application -> Final Answer

**Design Tradeoffs**: Training-free methods vs. fine-tuning (speed vs. performance), faithfulness vs. fluency, computational overhead vs. accuracy gains

**Failure Signatures**: Persistent hallucinations despite decoding, format adherence failures, retrieval context ignored during generation

**First Experiments**: 1) Run baseline ReAct without decoding methods, 2) Apply each decoding method individually, 3) Compare faithfulness metrics across methods

## Open Questions the Paper Calls Out
None

## Limitations
- Focus on training-free methods only, limiting generalizability to scenarios where fine-tuning might be more effective
- Evaluation uses only two specific model sizes (Qwen2-7b-Instruct and Llama3-8b-Instruct), which may not represent full range of LLM capabilities
- Experiments conducted on three multi-hop QA datasets that may not capture diversity of real-world multi-hop reasoning scenarios

## Confidence
- High confidence: Decoding methods improve faithfulness in multi-hop QA (consistent improvements across datasets and metrics)
- Medium confidence: Comparative effectiveness of different decoding methods (CAD, DoLa, DeCoRe show varying performance without clear systematic explanations)
- Medium confidence: Practical applicability of these methods (lack of analysis regarding computational costs and real-world deployment)

## Next Checks
1. Evaluate decoding methods across a broader range of model sizes (including larger models like GPT-4 or Claude) to assess scalability and performance trends with model capacity
2. Conduct ablation studies to determine individual contributions of each decoding method component and identify most critical aspects for performance improvements
3. Test methods on additional multi-hop QA datasets with different characteristics (e.g., numerical reasoning, temporal reasoning, or domain-specific knowledge) to validate generalizability beyond current dataset selection