---
ver: rpa2
title: Large Language Models Approach Expert Pedagogical Quality in Math Tutoring
  but Differ in Instructional and Linguistic Profiles
arxiv_id: '2512.20780'
source_url: https://arxiv.org/abs/2512.20780
tags:
- tutors
- pedagogical
- quality
- human
- linguistic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study compares human and LLM-generated math tutoring responses
  using a shared dataset of remediation conversations. LLMs approach expert-level
  pedagogical quality on average, though they differ systematically in instructional
  and linguistic strategies.
---

# Large Language Models Approach Expert Pedagogical Quality in Math Tutoring but Differ in Instructional and Linguistic Profiles

## Quick Facts
- arXiv ID: 2512.20780
- Source URL: https://arxiv.org/abs/2512.20780
- Authors: Ramatu Oiza Abdulsalam; Segun Aroyehun
- Reference count: 11
- Primary result: LLMs achieve expert-level pedagogical quality on average but systematically differ in instructional strategies, particularly underusing restating/revoicing

## Executive Summary
This study compares human and LLM-generated math tutoring responses using a shared dataset of remediation conversations. LLMs approach expert-level pedagogical quality on average, though they differ systematically in instructional and linguistic strategies. Specifically, LLMs underuse restating/revoicing—a key expert move—while producing longer, more lexically diverse, and more polite responses. Statistical analysis reveals that restating/revoicing, lexical diversity, and pressing for accuracy positively correlate with perceived pedagogical quality, whereas agentic and polite language negatively correlate. Readability and response length show no significant association.

## Method Summary
The study uses a turn-level controlled comparison design with 300 teacher-student math dialogues (2476 conversations) from MathDial and elementary math datasets. Each student turn has 8-9 responses from: 1 expert tutor, 1 novice tutor, and 7 LLMs (GPT-4, Gemini, Claude Sonnet, Mistral 7B, Llama-3.1-405B, Llama-3.1-8B, Phi-3). Human annotations on 4 pedagogical dimensions (mistake identification, location, guidance, actionability) are mapped to a 0/2 scale. Instructional features are extracted using the StanfordSCALE tutor talkmoves classifier, linguistic features include MTLD and Flesch-Kincaid scores, and pragmatic features use politeness and agency classifiers. Analysis employs within-conversation fixed effects regression with standardized predictors and clustered standard errors.

## Key Results
- LLMs achieve expert-level pedagogical quality scores on average despite systematic differences in feature profiles
- Restating/revoicing is the strongest positive predictor of pedagogical quality (β=0.78, p < 0.001)
- Higher politeness and agentic language correlate negatively with quality (β=-0.19 and β=-0.68, respectively)
- Lexical diversity and pressing for accuracy show positive associations with quality
- Response length and readability show no significant association with pedagogical quality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Restating/revoicing student reasoning is the strongest predictor of perceived pedagogical quality among the features studied.
- Mechanism: Reformulating student responses in the tutor's own words makes error identification and misconception location explicit, creating shared grounding before corrective guidance. This reduces ambiguity about what the tutor understood versus what the student meant.
- Core assumption: Perceived quality annotations proxy for actual learning outcomes, which remain unmeasured.
- Evidence anchors:
  - Statistical analyses show that restating and revoicing are positively associated with perceived pedagogical quality
  - Restating/revoicing shows a large positive association (β=0.78, 95% CI [0.65, 0.90], p < 0.001)

### Mechanism 2
- Claim: Higher politeness and agentic language correlate with lower perceived pedagogical quality.
- Mechanism: Excessive politeness may soften corrective feedback to the point of ambiguity, while agentic language may reduce student ownership of the problem-solving process. Both could signal hedging or lack of directness in error handling.
- Core assumption: The politeness and agency classifiers capture pedagogically relevant pragmatic dimensions.
- Evidence anchors:
  - Higher levels of agentic and polite language are negatively associated with pedagogical quality
  - Politeness shows a negative association (β=-0.19, 95% CI [-0.30, -0.08], p < 0.001), as does agency (β=-0.68, 95% CI [-0.77, -0.58], p < 0.001)

### Mechanism 3
- Claim: LLMs achieve expert-level pedagogical quality scores despite underusing restating/revoicing by compensating with higher lexical diversity and pressing for accuracy.
- Mechanism: Lexical diversity provides richer vocabulary for explanation, potentially improving guidance clarity. Pressing for accuracy prompts reflection. Together, these partially offset the missing restating/revoicing signal, yielding comparable aggregate scores through different feature combinations.
- Core assumption: The linear model's feature independence assumption holds.
- Evidence anchors:
  - LLMs tend to underuse restating/revoicing while producing longer, more lexically diverse, and more polite responses
  - Restating or revoicing is consistently less prevalent in LLM-generated responses, with all models exhibiting negative deviations relative to experts

## Foundational Learning

- Concept: **Turn-level controlled comparison**
  - Why needed here: The paper's causal claims depend on holding the instructional context (student error, conversation history) constant while varying only the tutor response.
  - Quick check question: Can you explain why comparing LLM and human responses to different student errors would invalidate the pedagogical quality comparison?

- Concept: **Within-conversation fixed effects regression**
  - Why needed here: RQ3 analysis uses conversation-level demeaning to isolate how linguistic features predict quality within the same instructional context.
  - Quick check question: Why does clustering standard errors at the conversation level matter when multiple tutors respond to the same turn?

- Concept: **Probabilistic classifier outputs as continuous features**
  - Why needed here: Instructional features are operationalized as classifier probabilities rather than binary labels, preserving graded variation.
  - Quick check question: What information is lost if you convert a 0.73 probability to a binary "present" label?

## Architecture Onboarding

- Component map: Input layer (student-teacher dialogue turns with annotations) -> Feature extraction pipeline (instructional, linguistic, pragmatic classifiers) -> Quality scoring (0-2 scale aggregation) -> Analysis layer (within-conversation OLS regression)

- Critical path:
  1. Verify annotation schema alignment (three-tier scale mapping: Yes→2, To some extent→1, No→0)
  2. Validate feature extractor outputs on held-out samples before computing group differences
  3. Ensure conversation-level clustering is implemented in regression standard errors

- Design tradeoffs:
  - Single-turn vs. multi-turn analysis: Controlled comparison gains internal validity but loses interaction effects across conversation
  - Perceived quality vs. learning outcomes: Annotations proxy for expert judgment but don't measure actual student learning
  - Feature set coverage: Selected features are interpretable but incomplete (discourse structure, mathematical specificity excluded)

- Failure signatures:
  - LLM responses showing high politeness + high agency + low restating: Predict lower quality despite surface fluency
  - Novice-like profiles (short, low lexical diversity, low restating): Consistently negative relative quality
  - High readability + low lexical diversity: May indicate oversimplification without explanatory depth

- First 3 experiments:
  1. Replicate the within-conversation regression on a held-out subset to verify coefficient stability (especially restating/revoicing β≈0.78).
  2. Test whether prompting LLMs to explicitly restate student reasoning before correcting increases restating scores without degrading lexical diversity.
  3. Analyze interaction effects: Does the politeness–quality relationship weaken when restating/revoicing is present?

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Would fine-tuning or prompting LLMs to increase restating/revoicing and decrease politeness improve their pedagogical quality?
- Basis in paper: For the development of LLM-based tutors, these findings imply that optimization efforts should focus on identifying and reproducing feature combinations associated with higher pedagogical quality.
- Why unresolved: This study is correlational; it identifies associations but does not test whether manipulating these features causally improves quality.
- What evidence would resolve it: An intervention study where LLM responses are systematically modified on targeted features and re-evaluated for pedagogical quality.

### Open Question 2
- Question: Do the identified linguistic and instructional correlates of pedagogical quality generalize to other domains and languages beyond English mathematics tutoring?
- Basis in paper: Extending this framework to additional subject areas and linguistic contexts is an important direction for future research.
- Why unresolved: The study is limited to middle school math in English.
- What evidence would resolve it: Replication of the analysis framework on tutoring datasets from other subjects and languages.

### Open Question 3
- Question: Do the instructional and linguistic features associated with perceived pedagogical quality also predict actual student learning outcomes?
- Basis in paper: Pedagogical quality in this study is assessed through structured annotations; it does not capture downstream student learning outcomes.
- Why unresolved: Annotator judgments may not reflect real tutoring effectiveness; no learning gain data was collected.
- What evidence would resolve it: A study linking response-level features to student learning gains in live or simulated tutoring interactions.

### Open Question 4
- Question: How do the feature–quality associations identified in single-turn analysis hold in multi-turn tutoring conversations?
- Basis in paper: Future work could extend this framework to multi-turn interactions.
- Why unresolved: Pedagogical strategies may differ across extended dialogues; single-turn analysis cannot capture how context accumulates.
- What evidence would resolve it: Analysis of multi-turn tutoring dialogues using the same feature framework, testing whether correlates persist across conversation stages.

## Limitations

- The study relies on expert annotations rather than measured learning outcomes, so perceived quality may not reflect actual educational effectiveness
- The analysis assumes feature independence in the regression model, though restating/revoicing likely moderates how other features affect quality
- Feature set incompleteness (missing discourse structure, mathematical specificity) may bias quality predictions

## Confidence

- Pedagogical quality metric: Medium (relies on expert annotations rather than measured learning gains)
- Linguistic feature operationalization: High (uses established classifiers)
- Causal interpretation of politeness/agency correlations: Low (may reflect response style preferences rather than pedagogical effectiveness)
- Regression coefficient stability: Medium (assumes feature independence)

## Next Checks

1. Replicate the within-conversation regression on a held-out subset to verify coefficient stability, particularly for restating/revoicing (β≈0.78).

2. Test whether the negative relationship between politeness/agency and quality is moderated by restating/revoicing presence, addressing the assumed feature independence.

3. Analyze tutoring effectiveness across complete conversations rather than isolated turns to capture cumulative restating/revoicing benefits for knowledge construction.