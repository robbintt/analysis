---
ver: rpa2
title: 'DiffusionGS: Generative Search with Query Conditioned Diffusion in Kuaishou'
arxiv_id: '2508.17754'
source_url: https://arxiv.org/abs/2508.17754
tags:
- user
- query
- search
- diffusiongs
- interest
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DiffusionGS addresses the challenge of capturing dynamic user intent
  in personalized search ranking by leveraging user queries as explicit intent anchors.
  The method employs a diffusion-based denoising process to extract robust user interest
  representations from noisy historical behaviors.
---

# DiffusionGS: Generative Search with Query Conditioned Diffusion in Kuaishou
## Quick Facts
- arXiv ID: 2508.17754
- Source URL: https://arxiv.org/abs/2508.17754
- Reference count: 40
- DiffusionGS achieves superior CTR and CVR prediction metrics using a query-conditioned diffusion model for personalized search ranking

## Executive Summary
DiffusionGS introduces a novel approach to personalized search ranking by leveraging user queries as explicit intent anchors and employing a diffusion-based denoising process to extract robust user interest representations from noisy historical behaviors. The method integrates a User-aware Denoising Layer (UDL) to incorporate user profiles, optimizing attention distribution for personalized ranking. Experiments demonstrate that DiffusionGS outperforms state-of-the-art Deep Learning Recommendation Models (DLRMs) and Graph-based Ranking Models (GRMs) on both CTR and CVR prediction tasks, with notable gains in AUC and GAUC metrics. Online A/B testing further validates its effectiveness in improving user engagement in Kuaishou's production environment.

## Method Summary
DiffusionGS addresses the challenge of capturing dynamic user intent in personalized search by combining query-conditioned diffusion models with user-aware denoising. The approach begins by treating user queries as explicit intent anchors, which are then used to guide a diffusion-based denoising process that extracts robust user interest representations from noisy historical behaviors. A User-aware Denoising Layer (UDL) is integrated to incorporate user profile information, optimizing attention distribution for personalized ranking. This framework is applied to both CTR and CVR prediction tasks, with results showing significant improvements over existing state-of-the-art models.

## Key Results
- Achieves an AUC of 0.7502 and GAUC of 0.6403 on CTR prediction, outperforming existing DLRM and GRM methods.
- Reaches an AUC of 0.8635 and GAUC of 0.5963 on CVR prediction, demonstrating strong performance in conversion prediction.
- Online A/B testing confirms significant improvements in user engagement metrics, validating the model's effectiveness in production.

## Why This Works (Mechanism)
DiffusionGS works by leveraging user queries as explicit intent anchors, which are then used to guide a diffusion-based denoising process. This process extracts robust user interest representations from noisy historical behaviors, effectively capturing dynamic user intent. The User-aware Denoising Layer (UDL) further enhances personalization by integrating user profiles to optimize attention distribution, enabling more accurate ranking.

## Foundational Learning
- Diffusion models: Used for denoising and extracting user interests from noisy behaviors. Quick check: Verify that the diffusion process effectively denoises user behavior sequences.
- Query-conditioned modeling: Anchors user intent using explicit queries. Quick check: Ensure that query information is accurately captured and utilized in the model.
- User-aware attention: Optimizes attention distribution by incorporating user profiles. Quick check: Validate that user profiles meaningfully influence attention weights.

## Architecture Onboarding
- Component map: User queries -> Diffusion denoising -> User-aware Denoising Layer (UDL) -> Personalized ranking
- Critical path: User queries and historical behaviors are fed into the diffusion denoising process, which is then refined by the UDL using user profiles for final ranking.
- Design tradeoffs: Balances between denoising user behavior and integrating user profiles, with a focus on personalization accuracy versus computational efficiency.
- Failure signatures: Poor denoising may lead to noisy user interest representations; inadequate user profile integration may reduce personalization accuracy.
- First experiments:
  1. Ablation study to isolate the contribution of the UDL and diffusion denoising to overall performance.
  2. Comparison of AUC/GAUC metrics on CTR and CVR prediction tasks against baseline models.
  3. Online A/B testing to validate improvements in user engagement metrics.

## Open Questions the Paper Calls Out
None

## Limitations
- Proprietary datasets and lack of public benchmarks hinder independent replication and external validation.
- Reliance on explicit user queries may limit applicability in contexts with sparse or absent query data.
- Computational overhead and scalability to very large user bases are not addressed.

## Confidence
- High confidence: The technical framework combining diffusion models with user profile integration is plausible and aligns with current trends in personalized search.
- Medium confidence: The reported offline and online performance improvements, given the lack of statistical details and external validation.
- Low confidence: The generalizability of results to other domains or platforms, and the scalability of the approach to extremely large user bases without further computational analysis.

## Next Checks
1. Replicate the core denoising and personalization components on a public dataset to assess generalizability and compare with established DLRM baselines.
2. Conduct ablation studies to isolate the contribution of the User-aware Denoising Layer (UDL) and the diffusion-based denoising process, quantifying their individual impact on ranking performance.
3. Perform a computational efficiency analysis, measuring inference time and memory usage relative to standard DLRM and GRM methods, especially at scale.