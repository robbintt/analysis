---
ver: rpa2
title: Boosting the Robustness-Accuracy Trade-off of SNNs by Robust Temporal Self-Ensemble
arxiv_id: '2508.11279'
source_url: https://arxiv.org/abs/2508.11279
tags:
- temporal
- robustness
- adversarial
- snns
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of improving adversarial robustness
  in Spiking Neural Networks (SNNs) without sacrificing clean accuracy. The key insight
  is to interpret SNNs as temporal ensembles of sub-networks, each operating at a
  different timestep.
---

# Boosting the Robustness-Accuracy Trade-off of SNNs by Robust Temporal Self-Ensemble

## Quick Facts
- arXiv ID: 2508.11279
- Source URL: https://arxiv.org/abs/2508.11279
- Reference count: 13
- Primary result: RTE achieves state-of-the-art robustness-accuracy trade-offs on SVHN, CIFAR-10, CIFAR-100, Tiny-ImageNet

## Executive Summary
This paper introduces Robust Temporal self-Ensemble (RTE), a framework that improves adversarial robustness in Spiking Neural Networks (SNNs) without sacrificing clean accuracy. The key insight is interpreting SNNs as temporal ensembles of sub-networks operating at different timesteps, then explicitly strengthening individual sub-networks and reducing vulnerability transferability across timesteps. RTE combines per-timestep adversarial training with cross-timestep regularization through a principled loss formulation and stochastic optimization. Experiments on four benchmarks demonstrate RTE consistently outperforms existing methods in worst-case robustness while maintaining higher clean accuracy, particularly on challenging datasets.

## Method Summary
RTE treats SNNs as implicit ensembles of temporal sub-networks and optimizes both individual sub-network robustness and reduces vulnerability transferability. The method uses stochastic sampling to select one timestep per batch for adversarial example generation, then applies KL-divergence-based loss that regularizes all sub-networks relative to the adversarial example. This provides computationally tractable optimization while preserving ensemble benefits. The framework operates on LIF neurons with direct encoding and can be applied to various SNN architectures including VGG and SEWResNet variants.

## Key Results
- RTE achieves state-of-the-art robustness-accuracy trade-offs on SVHN, CIFAR-10, CIFAR-100, and Tiny-ImageNet
- RTE consistently outperforms existing methods in worst-case robustness while maintaining higher clean accuracy
- RTE reshapes internal robustness landscape by promoting temporal diversity and reducing cross-timestep vulnerability transfer
- RTE benefits increase with more timesteps, showing better scalability than baseline methods

## Why This Works (Mechanism)

### Mechanism 1: Temporal Sub-Network Decomposition
Treating SNNs as collections of evolving sub-networks across timesteps uncovers hidden fragility at individual timesteps that aggregated evaluation masks. By minimizing each sub-network's adversarial loss separately, RTE addresses temporal sub-networks with meaningfully distinct decision boundaries that can be independently strengthened.

### Mechanism 2: Cross-Timestep Vulnerability Transfer Reduction
Suppressing adversarial transferability between timesteps creates more diverse ensemble members. RTE minimizes the transferability matrix by reducing distributional shifts between sub-networks, making perturbations effective against one timestep fail against others and improving overall ensemble robustness.

### Mechanism 3: Stochastic Sampling with KL-Regularized Loss
Random single-timestep adversarial example generation with KL-based loss provides computationally tractable optimization while preserving ensemble benefits. The stochastic approach samples one timestep per batch rather than generating T adversarial examples, avoiding prohibitive computational costs from BatchNorm temporal coupling.

## Foundational Learning

- **Leaky Integrate-and-Fire (LIF) Neuron Dynamics**: RTE operates on temporal sub-networks defined by LIF state evolution. Understanding membrane potential decay and spike thresholding is essential for interpreting how perturbations propagate across timesteps.
- **Adversarial Training (AT) with ℓ_p-Bounded Perturbations**: RTE extends standard AT by adding temporal ensemble regularization. Understanding PGD attacks, perturbation budgets, and the robustness-accuracy trade-off provides context for why RTE's improvements matter.
- **Ensemble Diversity for Robustness**: RTE applies ensemble learning principles to temporal sub-networks. Understanding why diverse predictions improve robustness (reduced vulnerability transfer) clarifies the mechanism.

## Architecture Onboarding

- **Component map**: Input layer (direct encoding) -> Temporal sub-networks (each timestep produces prediction) -> Aggregation (averages all f^t(x)) -> RTE Loss (CE + cross-timestep regularization) -> Stochastic sampler (randomly selects one m per batch)
- **Critical path**: Forward pass computes spike trains for all T timesteps → Random timestep m is sampled → PGD attack generates adversarial example x'_m → L_RTE computed across all timesteps → Backpropagation-through-time updates weights
- **Design tradeoffs**: Regularization coefficient γ (higher prioritizes robustness), timestep count T (more increases diversity but cost), perturbation budget ε (larger improves robustness but may harm clean accuracy)
- **Failure signatures**: Low temporal diversity (high off-diagonal transferability values), gradient obfuscation (weak attack robustness exceeds black-box), training instability (monitor surrogate gradient implementation)
- **First 3 experiments**: 1) Baseline comparison on CIFAR-10 with T=4: Implement AT vs RTE using SEWResNet-19, ε=8/255, measuring clean accuracy and APGD robustness. 2) Transferability matrix visualization: Train models with AT and RTE, compute L^(t,m) for all timestep pairs. 3) Ablation on regularization strength: Train RTE with γ ∈ {0.5, 1.0, 2.0, 4.0} on CIFAR-100, plot clean vs robust accuracy curve.

## Open Questions the Paper Calls Out

- **Neuromorphic extension**: Can RTE be effectively extended to neuromorphic event-based datasets where temporal structure is inherent rather than artificially introduced through direct encoding?
- **Full temporal optimization**: Would replacing the stochastic sampling strategy with full optimization over all timesteps yield additional robustness gains?
- **Certified robustness**: Can certified robustness guarantees be derived for RTE-trained SNNs, beyond the empirical robustness demonstrated?
- **Scaling behavior**: How does RTE scale to significantly longer temporal sequences (T >> 12) and what are the computational-robustness trade-offs?

## Limitations
- All experiments use static image datasets with direct encoding rather than truly temporal event-based data
- Stochastic optimization trades optimality for efficiency without exploring full temporal optimization
- No theoretical robustness guarantees or certification provided
- Computational scaling with large T values remains unexplored

## Confidence

- **High**: RTE achieves state-of-the-art robustness-accuracy trade-offs on standard benchmarks
- **Medium**: Temporal sub-networks have meaningfully distinct decision boundaries that can be independently strengthened
- **Medium**: Cross-timestep vulnerability transfer reduction improves ensemble robustness
- **Low**: Stochastic single-timestep sampling provides sufficient gradient signal for all sub-networks

## Next Checks

1. Implement RTE on CIFAR-10 with SEWResNet-19 and compare clean/robust accuracy trade-off against AT baseline, replicating Table 1 conditions
2. Generate transferability matrices for AT vs RTE models and verify RTE achieves lower diagonal/off-diagonal values as in Figure 6
3. Perform ablation study on regularization strength γ across multiple datasets to confirm RTE consistently outperforms TRADES across the robustness-accuracy spectrum