---
ver: rpa2
title: 'Linguistic Characteristics of AI-Generated Text: A Survey'
arxiv_id: '2510.05136'
source_url: https://arxiv.org/abs/2510.05136
tags:
- aigt
- text
- more
- other
- linguistic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey synthesizes findings from 44 studies on the linguistic
  characteristics of AI-generated text (AIGT) compared to human-written text (HWT).
  Research shows AIGT tends to be more formal and impersonal, with higher use of nouns,
  determiners, and adpositions, and lower use of adjectives and adverbs.
---

# Linguistic Characteristics of AI-Generated Text: A Survey

## Quick Facts
- arXiv ID: 2510.05136
- Source URL: https://arxiv.org/abs/2510.05136
- Reference count: 40
- Key finding: AIGT shows lower lexical diversity, more formal style, and higher noun/determiner usage compared to HWT

## Executive Summary
This survey synthesizes findings from 44 studies examining how AI-generated text (AIGT) differs linguistically from human-written text (HWT). The research reveals consistent patterns: AIGT tends to be more formal and impersonal, with higher use of nouns and determiners but lower use of adjectives and adverbs. AIGT also exhibits lower lexical diversity and more repetitive patterns. However, the findings are heavily skewed toward English texts and GPT-3.5 models, with limited investigation into other languages, model families, or prompt variations.

## Method Summary
The authors conducted a systematic literature review across ResearchGate and Google Scholar, searching for studies that compare AIGT and HWT using transformer-based LLMs. They classified 44 studies across five dimensions: linguistic level (lexicon, grammar, other), model family, genre, language, and prompting approach. Findings were then synthesized by linguistic level, identifying patterns in lexical diversity, part-of-speech distribution, syntactic complexity, and stylistic features.

## Key Results
- AIGT exhibits significantly lower lexical diversity (Type-Token Ratio) than HWT
- AIGT shows higher noun and determiner usage with lower adjective and adverb frequency
- Most findings are concentrated on English texts (91%) and GPT-3.5 model (57%)

## Why This Works (Mechanism)

### Mechanism 1: Stylistic Convergence toward "Nominal" Formulation
- Claim: AIGT exhibits a more formal, impersonal style characterized by higher density of nouns, determiners, and adpositions, and lower frequency of adjectives and adverbs.
- Mechanism: The model optimizes for "information-dense" structures typical of formal writing in its training data, suppressing "involvement" markers common in human communication.
- Evidence: AIGT is described as "more formal and impersonal" with "increased presence of nouns" and being "less narrative."
- Break condition: This may weaken in informal genres or with dialogue-specific fine-tuning.

### Mechanism 2: Probabilistic Compression and N-Gram Repetition
- Claim: AIGT exhibits lower lexical diversity and higher repetition due to the model's tendency to converge on high-probability sequences.
- Mechanism: LLMs learn to generate natural-sounding text without demonstrating large, varied vocabulary, resulting in preferred expressions over varied synonyms.
- Evidence: Studies "almost universally report that AIGT is much less lexically diverse" with "higher frequencies for some word n-grams."
- Break condition: Models with higher temperature settings or explicit variability prompts may override this tendency.

### Mechanism 3: Syntactic Rigidification (Canonical Ordering)
- Claim: AIGT adheres more strictly to canonical syntactic structures (e.g., Subject-Verb-Object) than HWT.
- Mechanism: The model prioritizes statistically probable syntactic paths, resulting in rigid sentence ordering and avoiding complex structures humans use.
- Evidence: AIGT "very consistently features the canonical Subject-Verb-Object ordering," contrasting with human variation.
- Break condition: May not apply to languages with free word order.

## Foundational Learning

- Concept: **Lexical Diversity (Type-Token Ratio)**
  - Why needed: Primary quantitative metric for distinguishing AIGT from HWT
  - Quick check: If a text uses "utilize" ten times instead of varying with "use," "employ," and "leverage," how would this affect the Type-Token Ratio?

- Concept: **Part-of-Speech (POS) Distribution Analysis**
  - Why needed: Identifies the ratio of nouns/determiners to adjectives/adverbs as a key AI authorship signal
  - Quick check: Does the text show a "nominal" bias (many things/objects) or a "verbal/adjectival" bias (many actions/descriptions)?

- Concept: **Prompt Sensitivity**
  - Why needed: Only 9/44 studies used multiple prompts, risking findings are prompt-dependent
  - Quick check: If you change the prompt from "Write an essay" to "Write a blog post in the style of an essay," would formal markers remain the same?

## Architecture Onboarding

- Component map: Input (Text Corpus) -> Feature Extractor (Lexical Diversity, POS Tagging, Syntactic Parsing) -> Analyzer (Comparative Statistical Analysis) -> Critique Layer (Prompt Sensitivity Validation)
- Critical path: 1) Select comparable corpora ensuring genre match, 2) Run Lexical Diversity metrics, 3) Analyze POS distribution focusing on Nouns/Adpositions vs Adjectives/Adverbs
- Design tradeoffs:
  - English-only vs Multilingual: 91% of studies are English-centric; non-English requires new feature sets
  - GPT-3.5 Bias: 57% of studies use GPT-3.5; systems optimized only for these findings may fail on GPT-4 or Llama 3
- Failure signatures:
  - Genre Mismatch: Applying "scientific text" features to "social media" text yields false results
  - Prompt Overfitting: Single prompt wording creates system detecting prompt's style, not model's intrinsic style
- First 3 experiments:
  1. Measure Type-Token Ratio (TTR) on held-out Human vs. AI essays to confirm "lower lexical diversity"
  2. Extract POS tags for AIGT sample, calculate (Nouns + Determiners) to (Adjectives + Adverbs) ratio, compare against human baseline
  3. Generate text using 5 different prompts and measure if "Nominal Style" persists across all outputs

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent does prompt wording influence linguistic markers distinguishing AIGT from HWT?
- Basis: Only 9/44 studies employed multiple prompts
- Why unresolved: No studies explicitly compared linguistic content from different prompt strategies
- Evidence needed: Systematic analysis of linguistic feature variations from varied prompt wordings using same model and input data

### Open Question 2
- Question: Do AIGT characteristics generalize to low-resource and typologically diverse languages?
- Basis: 91% of studies focus on English
- Why unresolved: Current research leaves linguistic properties of AIGT in other languages largely unknown
- Evidence needed: Comparative analysis of AIGT versus human texts across diverse non-English languages including low-resource languages

### Open Question 3
- Question: Are linguistic patterns specific to GPT family or universal to transformer-based LLMs?
- Basis: 57% of studies used GPT-3.5
- Why unresolved: Few studies compared outputs across different model families
- Evidence needed: Large-scale comparative studies analyzing same linguistic features across both closed and open model families

### Open Question 4
- Question: Do methodological factors explain lack of consensus on sentence length and emotional content in AIGT?
- Basis: Studies report contradictory findings on these metrics
- Why unresolved: May be due to unstated variables like text genre or model choice
- Evidence needed: Controlled experiments isolating variables such as genre and model version

## Limitations
- Findings heavily skewed toward English texts (91%) and GPT-3.5 model (57%)
- Overwhelming focus on formal genres limits generalizability to conversational domains
- Only 9 of 44 studies used multiple prompts, risking prompt-specific artifacts

## Confidence
- **High Confidence**: AIGT exhibits lower lexical diversity and higher noun/determiner density compared to HWT
- **Medium Confidence**: Formal and impersonal style characteristics are model-dependent and most pronounced in formal genres
- **Low Confidence**: Syntactic rigidification patterns and repetition characteristics generalize across languages and model families

## Next Checks
1. Replicate lexical diversity and POS distribution analyses on non-English corpora (e.g., Spanish, Chinese) using identical methodology
2. Generate text using 10+ diverse prompts across different domains and measure stability of identified linguistic markers
3. Compare GPT-3.5 findings against newer architectures (GPT-4, Claude, Llama) to determine if patterns are model-specific or represent broader LLM tendencies