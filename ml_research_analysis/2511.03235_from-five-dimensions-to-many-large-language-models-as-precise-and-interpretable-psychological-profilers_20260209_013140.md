---
ver: rpa2
title: 'From Five Dimensions to Many: Large Language Models as Precise and Interpretable
  Psychological Profilers'
arxiv_id: '2511.03235'
source_url: https://arxiv.org/abs/2511.03235
tags:
- psychological
- reasoning
- llms
- amplification
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tests whether large language models (LLMs) can accurately
  model human psychological trait correlations from minimal personality data. The
  authors prompt various LLMs to predict responses on nine psychological scales given
  only Big Five personality scores from 816 individuals.
---

# From Five Dimensions to Many: Large Language Models as Precise and Interpretable Psychological Profilers

## Quick Facts
- arXiv ID: 2511.03235
- Source URL: https://arxiv.org/abs/2511.03235
- Authors: Yi-Fei Liu; Yi-Long Lu; Di He; Hang Zhang
- Reference count: 24
- Primary result: LLMs accurately reconstruct human psychological trait correlations from minimal Big Five data (R² > 0.89)

## Executive Summary
This paper investigates whether large language models can accurately model human psychological trait correlations using minimal personality data. The authors prompt various LLMs to predict responses on nine psychological scales given only Big Five personality scores from 816 individuals. They find that LLMs accurately reconstruct the correlational structure of human psychological traits, with inter-scale correlation patterns aligning strongly with human data (R² > 0.89). Analysis of reasoning traces reveals a two-stage process: LLMs first compress raw personality responses into natural language summaries, then generate predictions from these summaries. The compressed summaries prove sufficient for prediction and even enhance performance when added to original scores.

## Method Summary
The study uses 816 Chinese participants with Big Five inventory data (IPIP-BFM-20, 20 items) and nine additional psychological scales. LLMs are prompted in zero-shot fashion to predict responses on all target scales given Big Five scores. The key evaluation metric compares the correlation matrices of LLM predictions against human data through second-order structural alignment (regressing LLM correlation vectors on human correlation vectors). Three experimental conditions test ScoreOnly, SummaryOnly, and Summary+Score inputs. Reasoning traces are parsed by separate annotation models to attribute item importance, compared against Bayesian Ridge feature importance as ground truth.

## Key Results
- LLMs achieve R² > 0.89 in reconstructing human psychological trait correlation structures across multiple models
- Summary-only conditions maintain structural amplification (R² = 0.91), suggesting compressed natural language summaries are sufficient statistics
- Combining summaries with raw scores yields synergistic gains, outperforming either alone
- Structural amplification coefficient k > 1.0 indicates models produce idealized correlation structures beyond noisy human data

## Why This Works (Mechanism)

### Mechanism 1
LLMs compress raw personality data into natural language summaries that function as sufficient statistics for prediction. Input 20 item-level Big Five scores → model selects relevant factors → generates compressed natural language summary → summary drives target scale predictions. Summaries alone achieve comparable performance to raw scores, and combining both yields synergistic gains. Core assumption: Chain-of-thought reasoning traces faithfully reflect actual processing rather than post-hoc rationalization.

### Mechanism 2
LLMs exhibit "structural amplification"—reconstructing idealized versions of psychological trait correlations rather than replicating noisy human data. LLM applies internally consistent reasoning that filters idiosyncratic human response noise, producing amplified correlations (slope k > 1.0). Noise injection experiments show inverse relationship: more noise → lower amplification. Core assumption: Human response noise (inattention, fluctuating response styles) attenuates true correlational structure; attentive subsamples should show lower amplification gaps.

### Mechanism 3
LLMs use concept-driven information selection—identifying correct high-level psychological factors while failing to differentiate item importance within factors. Attribution analysis reveals near-perfect alignment at factor level (ρ = 0.981) but noisy alignment at item level (ρ = 0.621). Models prioritize abstract conceptual structure over granular item details. Core assumption: Factor-level alignment indicates top-down conceptual reasoning rather than bottom-up pattern matching.

## Foundational Learning

- **Big Five Personality Model (OCEAN)**
  - Why needed here: Input representation for all experiments; understanding factor structure critical for interpreting attribution analysis
  - Quick check question: Can you name the five factors and explain why factor-level vs. item-level distinction matters for this paper's claims?

- **Nomothetic Network / Correlational Structure**
  - Why needed here: Core evaluation metric compares inter-scale correlation patterns, not individual predictions; second-order morphism measures structural alignment
  - Quick check question: Why is comparing correlation matrices more robust than correlating individual predictions with ground truth?

- **Information Bottleneck Principle**
  - Why needed here: Framework for understanding compression summaries as representations that discard item-level noise while preserving predictive information
  - Quick check question: What evidence would suggest summaries are "sufficient statistics" vs. lossy compression?

## Architecture Onboarding

- **Component map**: Input Layer (20 Big Five item scores) → Reasoning Model (LLM with chain-of-thought) → Annotation Model (parses reasoning traces) → Evaluation Pipeline (computes correlation matrices, regression analysis) → Baselines (KNN, Linear Regression, Semantic Similarity)

- **Critical path**: 
  1. Prompt design (Appendix A.1) → role-playing frame with 20 items
  2. Generate predictions for all 9 target scales per participant (N=816)
  3. Extract reasoning traces from thinking models
  4. Parse traces with attribution mapping prompt (Appendix A.3.1)
  5. Compare attribution distributions vs. Bayesian Ridge feature importance

- **Design tradeoffs**: Second-order structural analysis (R² of correlations) vs. first-order prediction accuracy; zero-shot vs. trained baselines; ScoreOnly vs. SummaryOnly vs. Summary+Score conditions trade interpretability for performance

- **Failure signatures**: Semantic similarity baseline fails to amplify (k ≈ 1.0, R² = 0.52); item-level attribution shows high KL divergence (0.457) despite factor-level alignment; permutation test null distribution must exclude artifact explanation

- **First 3 experiments**:
  1. Replicate structural amplification with single model (Gemini 2.5) on full dataset: verify k > 1.0, R² > 0.89
  2. Run permutation test (1000 trials) to establish statistical significance of amplification
  3. Compare ScoreOnly vs. SummaryOnly vs. Summary+Score conditions to validate compression hypothesis

## Open Questions the Paper Calls Out

- Does the "structural amplification" phenomenon persist across diverse cultural contexts, or is it influenced by biases in the training data? The authors note the study relies on a single cultural context and suggest applying the framework to "diverse, cross-cultural datasets."

- What specific architectural features or fine-tuning methods drive the variance in structural amplification coefficients across different LLMs? The paper states, "we do not deconstruct the variance between them," and calls for linking the capacity to "model scale or fine-tuning methods."

- Can the relationship between structural amplification and predictive accuracy be validated through causal intervention rather than observational correlation? The authors acknowledge their analyses are "primarily observational" and suggest "actively modulating the amplification effect to causally test its role."

## Limitations

- The 816-participant dataset is from "prior work" without a direct link or accession number; item-level responses for all 10 scales are required for exact reproduction
- Attribution analysis assumes chain-of-thought traces faithfully reflect internal processing, though this cannot be independently verified
- The amplification phenomenon (k > 1.0) suggests models may be applying learned priors rather than pure reasoning, raising questions about generalizability to novel psychological constructs

## Confidence

- **High confidence**: Structural amplification findings (R² > 0.89, k > 1.0) across multiple models, supported by permutation tests
- **Medium confidence**: Mechanism claims about two-stage compression → prediction process, based on reasoning trace analysis
- **Low confidence**: Claims about LLM "genuine psychological reasoning" versus sophisticated pattern matching, as this cannot be definitively distinguished

## Next Checks

1. Replicate structural amplification on an independently collected personality dataset with at least 3-4 additional scales beyond Big Five
2. Test attribution consistency by comparing outputs from multiple annotation models on identical reasoning traces
3. Conduct ablation study removing natural language summaries to quantify their contribution versus raw item scores