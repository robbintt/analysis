---
ver: rpa2
title: Document-Level Sentiment Analysis of Urdu Text Using Deep Learning Techniques
arxiv_id: '2501.17175'
source_url: https://arxiv.org/abs/2501.17175
tags:
- data
- urdu
- sentiment
- language
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a document-level sentiment analysis approach
  for Urdu text using deep learning techniques. The study proposes a hybrid model
  called BiLSTM-SLMFCNN, which combines Bidirectional Long Short-Term Memory (BiLSTM)
  and Single Layer Multi Filter Convolutional Neural Network (SLMFCNN).
---

# Document-Level Sentiment Analysis of Urdu Text Using Deep Learning Techniques

## Quick Facts
- arXiv ID: 2501.17175
- Source URL: https://arxiv.org/abs/2501.17175
- Authors: Ammarah Irum; M. Ali Tahir
- Reference count: 3
- Proposed hybrid BiLSTM-SLMFCNN model achieves high accuracy on Urdu sentiment analysis tasks

## Executive Summary
This paper presents a document-level sentiment analysis approach for Urdu text using a hybrid deep learning model called BiLSTM-SLMFCNN. The model combines Bidirectional Long Short-Term Memory (BiLSTM) with Single Layer Multi Filter Convolutional Neural Network (SLMFCNN) to effectively capture both sequential dependencies and local patterns in Urdu text. The study evaluates the model on two datasets: customer support conversations and IMDB Urdu movie reviews, demonstrating superior performance compared to other deep learning approaches including BiLSTM, CNN, CNN-BiLSTM, and BERT.

## Method Summary
The proposed BiLSTM-SLMFCNN model employs a hybrid architecture that leverages the strengths of both BiLSTM and CNN components. The model first processes input text through embedding layers, then applies BiLSTM to capture long-range dependencies and contextual information in both forward and backward directions. The SLMFCNN component then extracts local features through multiple convolutional filters, with the outputs from both components being concatenated and passed through dense layers for final sentiment classification. The model was trained using standard optimization techniques and evaluated on both small, medium, and large-sized versions of the IMDB Urdu dataset, as well as a customer support dataset.

## Key Results
- Achieved 83% accuracy on small-sized IMDB Urdu movie review dataset
- Achieved 79% accuracy on medium-sized IMDB Urdu movie review dataset
- Achieved 83% accuracy on large-sized IMDB Urdu movie review dataset
- Achieved 94% accuracy on Urdu Customer Support dataset

## Why This Works (Mechanism)
The hybrid BiLSTM-SLMFCNN architecture succeeds by combining complementary strengths: BiLSTM captures long-range dependencies and contextual understanding across the entire Urdu text sequence, while SLMFCNN extracts local n-gram features and patterns that might indicate sentiment polarity. This dual approach allows the model to understand both the broader narrative context and specific sentiment-bearing phrases. The concatenation of these distinct feature representations enables more comprehensive sentiment analysis than either component alone could achieve.

## Foundational Learning
1. **Bidirectional LSTM (BiLSTM)**: Why needed - Captures context from both past and future words in sequence; Quick check - Verify gradient flow in both directions during training
2. **Multi-filter CNN**: Why needed - Extracts local n-gram features at different granularities; Quick check - Test with varying filter sizes to confirm feature diversity
3. **Hybrid Architecture**: Why needed - Combines sequential and local pattern recognition; Quick check - Compare performance with individual component models
4. **Document-level processing**: Why needed - Considers full context rather than sentence-level features; Quick check - Evaluate on texts of varying lengths
5. **Urdu language characteristics**: Why needed - Right-to-left script and morphological complexity; Quick check - Validate preprocessing pipeline handles Urdu-specific tokenization

## Architecture Onboarding

Component map: Input Text -> Embedding Layer -> BiLSTM -> SLMFCNN -> Concatenate -> Dense Layers -> Output

Critical path: The critical path flows from input through embedding, then parallel BiLSTM and SLMFCNN processing, followed by concatenation and dense layers for classification. The BiLSTM component is crucial for capturing long-range dependencies in Urdu text, while SLMFCNN extracts local patterns that complement the sequential information.

Design tradeoffs: The hybrid approach balances the sequential understanding of BiLSTM with the local feature extraction of CNN, but increases model complexity and training time. The single-layer CNN was chosen for efficiency while maintaining effectiveness, though deeper architectures might capture more complex patterns.

Failure signatures: The model may struggle with sarcasm, negation, and context-dependent sentiment that requires deep understanding of Urdu cultural nuances. Performance degradation might occur on texts with heavy code-mixing or domain-specific terminology not well-represented in training data.

First experiments:
1. Evaluate baseline BiLSTM and SLMFCNN individually to establish component contributions
2. Test with different filter sizes in SLMFCNN to optimize local feature extraction
3. Experiment with varying sequence lengths to determine optimal context window

## Open Questions the Paper Calls Out
None

## Limitations
- Limited dataset sizes and unclear sampling methodology
- Lack of cross-domain validation to test generalizability
- Absence of statistical significance testing for model comparisons

## Confidence
The study demonstrates medium confidence in its reported results due to several limitations. The primary concerns center around dataset characteristics and model evaluation. The study relies on two Urdu datasets of limited size - particularly the customer support dataset which is not described in detail regarding its sampling methodology or demographic representation. The IMDB Urdu dataset, while showing good performance, may have inherent domain-specific biases that could affect generalizability to other sentiment analysis tasks.

The hybrid BiLSTM-SLMFCNN model architecture, while innovative, lacks comprehensive ablation studies to isolate the contribution of each component to the final performance. The comparison with other models (BiLSTM, CNN, CNN-BiLSTM, BERT) is presented but doesn't include statistical significance testing to validate the reported performance differences.

## Next Checks
1. Conduct cross-validation with additional Urdu datasets from different domains to test model generalizability
2. Perform statistical significance testing (e.g., paired t-tests) on model performance comparisons
3. Execute ablation studies to quantify the individual contribution of LSTM and SLMFCNN components to overall performance