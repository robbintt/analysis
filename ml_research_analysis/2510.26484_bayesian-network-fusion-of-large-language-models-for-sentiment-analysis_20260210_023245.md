---
ver: rpa2
title: Bayesian Network Fusion of Large Language Models for Sentiment Analysis
arxiv_id: '2510.26484'
source_url: https://arxiv.org/abs/2510.26484
tags:
- sentiment
- bnlf
- llms
- financial
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces BNLF, a Bayesian network-based framework for
  sentiment analysis that fuses predictions from multiple large language models (LLMs)
  including FinBERT, RoBERTa, and BERTweet. BNLF addresses challenges of inconsistency,
  interpretability, and computational cost in using domain-specific LLMs for financial
  sentiment analysis by modeling LLM predictions as probabilistic nodes within a Bayesian
  network, enabling principled late fusion and transparent reasoning.
---

# Bayesian Network Fusion of Large Language Models for Sentiment Analysis

## Quick Facts
- **arXiv ID**: 2510.26484
- **Source URL**: https://arxiv.org/abs/2510.26484
- **Reference count**: 12
- **Primary result**: BNLF framework improves sentiment analysis accuracy by ~6 percentage points over baseline LLMs

## Executive Summary
This paper introduces BNLF (Bayesian Network-based LLM Fusion), a framework for sentiment analysis that fuses predictions from multiple large language models using a Bayesian network. The approach addresses key challenges in sentiment analysis including inconsistency between LLM predictions, lack of interpretability, and computational costs associated with fine-tuning domain-specific models. By modeling LLM predictions as probabilistic nodes within a Bayesian network, BNLF enables principled late fusion and transparent reasoning about sentiment classification decisions.

The framework was evaluated on three financial sentiment datasets (FinText, Finance-News, StockTwits) and demonstrated consistent improvements in accuracy compared to individual LLMs like FinBERT, RoBERTa, and BERTweet. The method achieved 78.6% accuracy on the combined test set with balanced performance across sentiment classes. The approach is lightweight, requiring no additional fine-tuning, and provides interpretability through influence analysis and inference scenarios, making it a scalable and trustworthy solution for LLM-based sentiment classification.

## Method Summary
The BNLF framework operates by treating each LLM's sentiment prediction as a probabilistic node in a Bayesian network. The framework constructs a directed acyclic graph where LLM predictions serve as parent nodes that influence the final sentiment classification node. Conditional probability tables are learned from training data to capture the relationships between LLM predictions and true sentiment labels. During inference, evidence from multiple LLM predictions is propagated through the network using Bayesian inference to produce a fused sentiment classification. The framework employs late fusion, allowing each LLM to operate independently before their predictions are combined, which reduces computational overhead compared to ensemble methods requiring simultaneous processing.

## Key Results
- Achieved 78.6% accuracy on combined test set across three financial datasets
- Demonstrated consistent ~6 percentage point improvement over baseline LLMs
- Showed balanced performance across sentiment classes (positive, negative, neutral)
- Maintained lightweight computational requirements without additional fine-tuning

## Why This Works (Mechanism)
The Bayesian network architecture works by leveraging the complementary strengths of multiple LLMs while mitigating their individual weaknesses. Each LLM captures different linguistic patterns and domain knowledge, and the Bayesian framework probabilistically weighs these predictions based on their historical accuracy and correlation patterns. The conditional independence assumptions in the network allow for efficient computation of joint probabilities, while the probabilistic nature naturally handles uncertainty in predictions. By modeling the relationships between LLM outputs and true sentiment labels, the framework can correct systematic biases present in individual models and make more robust decisions when models disagree.

## Foundational Learning
- **Bayesian Networks**: Probabilistic graphical models representing dependencies between variables - needed for modeling relationships between LLM predictions and sentiment labels; quick check: verify conditional independence assumptions
- **Conditional Probability Tables**: Matrices storing probabilities of child node states given parent node states - needed to quantify relationships between LLM predictions; quick check: validate table entries sum to 1
- **Late Fusion**: Combining predictions after individual model inference - needed to reduce computational overhead; quick check: compare inference times with early fusion approaches
- **Probabilistic Inference**: Computing posterior probabilities given observed evidence - needed for making final sentiment predictions; quick check: verify inference produces valid probability distributions
- **Directed Acyclic Graphs**: Graph structures with directed edges and no cycles - needed to represent causal relationships between variables; quick check: ensure graph contains no cycles
- **Domain-Specific LLMs**: Pre-trained language models fine-tuned for specific domains - needed as input nodes providing specialized predictions; quick check: verify domain relevance to sentiment analysis task

## Architecture Onboarding

**Component Map**: LLMs (FinBERT, RoBERTa, BERTweet) -> Bayesian Network nodes -> Sentiment Classification node

**Critical Path**: LLM inference -> Bayesian network evidence propagation -> Sentiment prediction

**Design Tradeoffs**: Late fusion reduces computational cost but may miss early-stage interactions; Bayesian approach provides interpretability but requires careful structure learning; domain-specific LLMs improve accuracy but limit generalizability

**Failure Signatures**: Performance degradation when LLM predictions are highly correlated; poor results when LLMs have systematic biases in same direction; accuracy drops if conditional probability tables poorly estimated

**First 3 Experiments**: 1) Run individual LLMs on test set to establish baselines; 2) Perform ablation study removing one LLM at a time from BNLF; 3) Test BNLF on non-financial sentiment datasets to assess domain transferability

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to three financial sentiment datasets, potentially restricting generalizability
- Absence of statistical significance testing raises questions about reproducibility of reported improvements
- Framework performance inherently bounded by quality of underlying LLM predictions
- Interpretability features lack rigorous validation with end-users to confirm practical utility

## Confidence
- **High Confidence**: The architectural feasibility of using Bayesian networks for LLM prediction fusion is well-established and technically sound
- **Medium Confidence**: The six-percentage-point accuracy improvement is reproducible within the tested financial datasets, but generalizability to other domains or datasets remains uncertain
- **Medium Confidence**: The claim of interpretability is valid in principle, but practical user validation is lacking

## Next Checks
1. Conduct statistical significance testing (e.g., paired t-tests) across multiple runs to confirm that the observed accuracy improvements are not due to random variation
2. Evaluate BNLF on non-financial sentiment datasets (e.g., product reviews, social media) to assess domain transferability and robustness
3. Perform a user study with domain experts to validate the practical utility and clarity of the interpretability features (influence analysis, inference scenarios) in real-world decision-making contexts