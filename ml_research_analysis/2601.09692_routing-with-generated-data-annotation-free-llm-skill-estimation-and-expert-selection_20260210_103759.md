---
ver: rpa2
title: 'Routing with Generated Data: Annotation-Free LLM Skill Estimation and Expert
  Selection'
arxiv_id: '2601.09692'
source_url: https://arxiv.org/abs/2601.09692
tags:
- data
- routing
- queries
- these
- cascal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of dynamically routing queries
  to optimal large language models (LLMs) in scenarios where ground-truth labeled
  data is unavailable. The authors introduce "Routing with Generated Data (RGD),"
  a new setting where routers are trained exclusively on synthetic query-answer pairs
  generated from task descriptions by generator LLMs.
---

# Routing with Generated Data: Annotation-Free LLM Skill Estimation and Expert Selection

## Quick Facts
- arXiv ID: 2601.09692
- Source URL: https://arxiv.org/abs/2601.09692
- Reference count: 40
- Key outcome: CASCAL router achieves 4.6% higher accuracy than best query-answer router when trained on weak generator data by using consensus voting and hierarchical clustering without relying on generated labels.

## Executive Summary
This paper introduces "Routing with Generated Data" (RGD), a novel setting where LLM routers are trained exclusively on synthetic query-answer pairs without ground-truth labels. The authors propose CASCAL, a query-only router that estimates model correctness through consensus voting and identifies model-specific skill niches via hierarchical clustering. CASCAL is substantially more robust to generator quality, outperforming query-answer methods by 4.6% absolute accuracy when trained on weak generator data. The key insight is that filtering for high-consensus, high-variance queries can recover much of the performance loss from weaker generators.

## Method Summary
CASCAL trains routers on synthetic query-answer pairs generated from task descriptions without ground-truth labels. It computes confidence-weighted consensus scores across model responses, then clusters queries where specific models demonstrate proficiency to identify skill niches. At inference, queries are routed to the nearest skill cluster and top-3 ranked models are selected based on consensus. The method is designed to be robust to weak generators by avoiding reliance on potentially incorrect generated labels.

## Key Results
- CASCAL achieves 81.0% Top-3 accuracy on MMLU-Pro, outperforming AVENGERS by 3.2% and LLMRANK by 6.3%
- Query-only methods (CASCAL, SMOOTHIE-TRAIN) drop only 1.1-2.5% accuracy from validation to weak generator data, versus 8.5-10.5% for query-answer methods
- Filtering criteria (strong model agreement + low consensus breadth) recovers 1-2% accuracy when using weak generators

## Why This Works (Mechanism)

### Mechanism 1: Consensus-Based Correctness Estimation
Confidence-weighted majority voting across a model pool provides a reliable proxy for correctness when ground-truth labels are unavailable. The method normalizes each model's log-probabilities to Z-scores, identifies answers that match across models, and sums Z-scores of agreeing models to form a consensus score. This rewards answers backed by multiple high-confidence models rather than simple plurality. Core assumption: Models that agree with high confidence are more likely correct; the model pool contains sufficient diversity to avoid systematic bias.

### Mechanism 2: Hierarchical Skill Clustering for Niche Identification
Clustering queries where specific models demonstrate proficiency reveals fine-grained skill niches that aggregate metrics miss. For each model, queries where it aligns with consensus are identified, embedded, and clustered via k-means. This isolates skill-relevant subdomains that simple ranking misses. Core assumption: Semantic similarity in embedding space corresponds to skill similarity; clustering will isolate skill-relevant subdomains.

### Mechanism 3: Query-Only Robustness via Label Avoidance
Bypassing generated answer labels prevents error propagation from weak generators, making query-only routers more robust to data quality. Query-only methods use only (query, model responses) without reference to generated labels, deriving correctness signals from inter-model agreement rather than generator-provided answers. Core assumption: Generated queries capture real query distribution more reliably than generated answers capture correct responses.

## Foundational Learning

- **Concept: Self-Consistency and Majority Voting**
  - Why needed here: CASCAL's core correctness signal derives from consensus; understanding when majority voting converges on truth vs. amplifies bias is essential for diagnosing failures.
  - Quick check question: If all models in your pool were fine-tuned on the same erroneous corpus, would consensus still indicate correctness?

- **Concept: Clustering Validity Metrics (Silhouette Score, Kendall's τ)**
  - Why needed here: CASCAL uses silhouette score to select k and Kendall's τ to measure ranking quality; these metrics determine when clustering is working vs. producing arbitrary partitions.
  - Quick check question: A silhouette score of 0.02 and Kendall's τ of -0.14—would you trust routing decisions based on this data?

- **Concept: Label Noise Propagation in Weak Supervision**
  - Why needed here: RGD explicitly addresses the noisy-label regime; understanding how label errors affect query-answer vs. query-only methods explains the robustness gap.
  - Quick check question: Why would discarding labels entirely (query-only) outperform using labels that are 65% accurate (query-answer with weak generator)?

## Architecture Onboarding

- **Component map:**
  Task Descriptor -> Data Generator (M_gen) -> Model Pool (M) -> Consensus Scorer -> Skill Clusterer -> Inference Router

- **Critical path:**
  1. Generate queries from task descriptions (prompt in Appendix B.2, Figure 6)
  2. Collect model responses with log-probabilities (prompt in Appendix B.2, Figure 4)
  3. Compute consensus scores for all (query, model) pairs
  4. Build Q_strong sets -> cluster -> merge/prune -> store F^t_centroid and F^t_models mappings
  5. At inference: embed query -> find nearest task -> find nearest centroid -> return top-K models -> aggregate responses

- **Design tradeoffs:**
  - K selection (clustering): Silhouette threshold 0.05 balances granularity vs noise; lower threshold creates more clusters but risks overfitting to artifacts
  - Merge distance τ_merge=0.15: Prevents redundant near-duplicate clusters but may collapse genuinely distinct skills if embedding space is compressed
  - Top-K=3 selection: Provides ensemble robustness but triples inference cost; Top-1 variant available for cost-sensitive deployment
  - Embedding model (Qwen3-Embedding-8B): Choice affects semantic cluster quality; domain-specific embeddings may improve niche identification

- **Failure signatures:**
  1. Low silhouette scores across all K: Clusters not geometrically coherent—check embedding quality or reduce K
  2. Negative Kendall's τ on validation correlation: Generated data induces wrong model rankings—requires filtering or stronger generator
  3. Centroid explosion after pruning: Too many clusters with identical rankings—increase Jaccard threshold or reduce initial K
  4. Consensus always selects same model: Model pool lacks diversity or queries insufficiently challenging

- **First 3 experiments:**
  1. Validation baseline sanity check: Run CASCAL on ground-truth validation data on MMLU-Pro subset; target: Top-3 accuracy within 2% of reported 81.0% to verify implementation
  2. Generator quality ablation: Generate 5k queries with Gemini-2.5-Flash vs Exaone-3.5-7.8B; compare CASCAL Top-3 accuracy on same test set; expected gap: ~2-3% based on paper results
  3. Filtering recovery test: Generate 20k queries with weak generator; apply consensus+variance filtering (strong model agreement + ≤2 other models correct); measure accuracy recovery vs unfiltered 5k baseline; target: recover 1-2% as shown in Table 4

## Open Questions the Paper Calls Out
None

## Limitations
- Heavy dependence on generator quality for synthetic query generation remains a fundamental constraint
- Clustering mechanism assumes embedding space preserves skill-relevant semantic distinctions without validation
- Filtering criteria effectiveness shows modest improvements but lacks exploration of parameter sensitivity or alternative strategies

## Confidence
- **High Confidence**: Query-only routing robustness claims (4.6% accuracy gain over query-answer methods on weak generators)
- **Medium Confidence**: Consensus voting as correctness signal (supports self-consistency literature but not tested for systematic bias)
- **Medium Confidence**: Hierarchical clustering for skill niche identification (technically sound but lacks consensus-only validation)
- **Low Confidence**: Filtering criteria effectiveness (modest improvements shown, no parameter sensitivity exploration)

## Next Checks
1. **Clustering Quality Validation**: Run CASCAL on MMLU-Pro subset with ground-truth labels available. Compare automatically identified skill clusters against human-annotated skill taxonomies. Target: ≥70% cluster-skill alignment by Jaccard index.

2. **Generator Distribution Gap Analysis**: Collect 100 real-world queries from target domains (MMLU-Pro, MedMCQA). Compare query embeddings from generated vs real data using Maximum Mean Discrepancy (MMD). Target: MMD < 0.1.

3. **Robustness to Model Pool Composition**: Systematically remove the strongest/weakest models from POOL-LARGE and retrain CASCAL. Measure Top-3 accuracy degradation. Target: <5% accuracy drop when removing any single model.