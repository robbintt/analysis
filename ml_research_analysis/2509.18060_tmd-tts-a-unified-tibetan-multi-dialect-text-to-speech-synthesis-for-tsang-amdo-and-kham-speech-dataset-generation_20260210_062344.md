---
ver: rpa2
title: "TMD-TTS: A Unified Tibetan Multi-Dialect Text-to-Speech Synthesis for \xDC\
  -Tsang, Amdo and Kham Speech Dataset Generation"
arxiv_id: '2509.18060'
source_url: https://arxiv.org/abs/2509.18060
tags:
- dialect
- speech
- tibetan
- tmd-tts
- multi-dialect
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper addresses the scarcity of high-quality parallel speech\
  \ corpora for Tibetan dialects (\xDC-Tsang, Amdo, Kham) by proposing TMD-TTS, a\
  \ unified multi-dialect text-to-speech framework. The core method integrates dialect\
  \ embeddings via a fusion module and introduces a Dialect-Specialized Dynamic Routing\
  \ Network (DSDR-Net) that replaces standard FFN layers in the Transformer, enabling\
  \ fine-grained dialectal control through conditional computation."
---

# TMD-TTS: A Unified Tibetan Multi-Dialect Text-to-Speech Synthesis for Ü-Tsang, Amdo and Kham Speech Dataset Generation

## Quick Facts
- **arXiv ID**: 2509.18060
- **Source URL**: https://arxiv.org/abs/2509.18060
- **Reference count**: 0
- **Primary result**: Unified Tibetan multi-dialect TTS with dialect embeddings and dynamic routing achieves high MOS and dialect similarity across three dialects

## Executive Summary
This paper addresses the scarcity of high-quality parallel speech corpora for Tibetan dialects (Ü-Tsang, Amdo, Kham) by proposing TMD-TTS, a unified multi-dialect text-to-speech framework. The core method integrates dialect embeddings via a fusion module and introduces a Dialect-Specialized Dynamic Routing Network (DSDR-Net) that replaces standard FFN layers in the Transformer, enabling fine-grained dialectal control through conditional computation. Extensive evaluations show TMD-TTS outperforms baselines across three dialects, achieving up to 94.92% STOI, 3.13 PESQ, and 21.32 dB SI-SDR for Amdo; 88.09% DECS and 87.78% DCA for dialect similarity; and MOS scores up to 3.86 for naturalness. The model also generates TMDD, a large-scale parallel dataset (98,142 utterances, 102+ hours), validated via a Speech-to-Speech Dialect Conversion task with MOS up to 3.63. Ablation studies confirm the contributions of dialect fusion and DSDR-Net.

## Method Summary
TMD-TTS extends Matcha-TTS with dialect-aware components: dialect embeddings injected at multiple architectural points, and DSDR-Net that replaces FFN layers with a public FFN plus three private FFNs selected by dialect ID. The model is trained on 179 hours of Tibetan speech across three dialects, using 500k steps with Adam. A BigVGAN vocoder converts mel-spectrograms to waveforms. The unified framework enables both high-quality multi-dialect synthesis and dataset generation via quality filtering.

## Key Results
- Achieves MOS up to 3.86 for naturalness and 3.86 for dialect similarity across three Tibetan dialects
- Outperforms baselines with up to 94.92% STOI, 3.13 PESQ, and 21.32 dB SI-SDR for Amdo dialect
- Generates TMDD dataset (98,142 utterances, 102+ hours) validated with MOS 3.63 in downstream S2SDC task

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Explicit dialect embeddings injected at multiple architectural points improve dialect consistency in synthesized speech.
- Mechanism: Dialect IDs are mapped to normalized embeddings via `h_did = Norm(Emb_did(d_id))`, then projected and added to text hidden features: `ĥ_text = h_text + Linear(h_did)`. This conditions both the text encoder and flow prediction network on dialect identity before acoustic generation.
- Core assumption: Dialect characteristics can be sufficiently represented as learnable embeddings that transfer across phonetic contexts.
- Evidence anchors:
  - [abstract] "Our method features a dialect fusion module... to capture fine-grained acoustic and linguistic variations across dialects."
  - [section 3.3] Ablation shows removing dialect fusion drops DCA from 80.25% to 74.15% and DECS from 78.3% to 72.8%.
  - [corpus] Weak—no direct corpus validation of embedding-based dialect conditioning in Tibetan; DiaMoE-TTS uses similar IPA-based approach for other languages.
- Break condition: If dialect variations require phoneme-level rather than utterance-level conditioning, a single global embedding may underrepresent intrasentential variation.

### Mechanism 2
- Claim: Dialect-specialized FFNs with dynamic routing capture fine-grained phonetic distinctions better than shared FFNs.
- Mechanism: DSDR-Net replaces the standard FFN in Transformer layers. Given attention output `h_attn`, it computes: `ĥ_attn = FFN_public(h_attn) + FFN_private,d(h_attn)` where the private FFN is selected by dialect ID from `{FFN_0, FFN_1, FFN_2}`. This enables dialect-specific transformations while preserving shared computation via the public FFN.
- Core assumption: Dialects share sufficient acoustic structure that a hybrid public/private architecture is more data-efficient than fully separate models.
- Evidence anchors:
  - [abstract] "DSDR-Net to capture fine-grained acoustic and linguistic variations across dialects."
  - [section 3.3] Removing DSDR-Net causes the largest single degradation: DCA drops from 80.25% to 60.12%, DECS from 78.3% to 58.6%.
  - [corpus] DiaMoE-TTS (arXiv:2509.22727) reports similar findings with Mixture-of-Experts for dialect routing, suggesting conditional computation is a general pattern for dialect modeling.
- Break condition: If dialects have radically different phoneme inventories requiring completely separate acoustic models, the shared public FFN could introduce interference.

### Mechanism 3
- Claim: Multi-stage quality filtering (embedding similarity + perceptual metrics + human validation) yields synthetic data suitable for downstream tasks.
- Mechanism: The pipeline retains samples with DECS > 0.8, applies MetricGAN+ enhancement to samples with PESQ < 3 or DNSMOS < 2.7, and adds manual screening by native speakers.
- Core assumption: Synthetic speech that passes objective quality thresholds transfers effectively to downstream tasks.
- Evidence anchors:
  - [section 2.2] "Dialect assessment is conducted by retaining only samples with a Dialect Embedding Cosine Similarity (DECS) greater than 0.8."
  - [section 3.5] TMDD achieves MOS 3.63 in S2SDC task versus 3.54 for baseline dataset, demonstrating downstream utility.
  - [corpus] Weak—limited corpus evidence on synthetic TTS data quality for training voice conversion; this remains an emerging practice.
- Break condition: If downstream tasks are sensitive to synthetic artifacts not captured by PESQ/DNSMOS, the filtering may pass samples that degrade task performance.

## Foundational Learning

- Concept: **Conditional Computation / Mixture-of-Experts routing**
  - Why needed here: DSDR-Net routes inputs to dialect-specific sub-networks based on discrete dialect IDs. Understanding gating, load balancing, and expert capacity is essential for debugging routing failures.
  - Quick check question: Can you explain why adding a "load balancing loss" might be necessary if some dialects are underutilized during training?

- Concept: **Flow-based generative models (Matcha-TTS / conditional flow matching)**
  - Why needed here: TMD-TTS builds on Matcha-TTS, which uses flow matching for mel-spectrogram generation. Understanding ODE-based sampling, conditioning, and the flow prediction network is prerequisite to modifying the architecture.
  - Quick check question: How does conditional flow matching differ from diffusion models in terms of sampling trajectory and training objective?

- Concept: **Vocoder architectures (BigVGAN, HiFi-GAN)**
  - Why needed here: The pipeline converts mel-spectrograms to waveforms using BigVGAN. Vocoder choice affects final audio quality and inference speed.
  - Quick check question: What artifacts might appear if the vocoder's training data distribution mismatches the TTS model's mel-spectrogram output distribution?

## Architecture Onboarding

- Component map:
  - Text Encoder -> Tokenizer -> Text Encoder -> (+ Dialect Embedding) -> DSDR-Net layers -> Duration Predictor -> Flow Prediction -> Vocoder

- Critical path: Text → Tokenizer → Text Encoder → (+ Dialect Embedding) → DSDR-Net layers → Duration Predictor → Flow Prediction → Vocoder

- Design tradeoffs:
  - Shared vs. dialect-specific parameters: Public FFN enables parameter sharing; private FFNs add ~192 dims per dialect. Trade-off is model size vs. dialect fidelity.
  - RTF vs. quality: TMD-TTS achieves RTF ~0.031–0.032, slightly slower than VITS2 (~0.020) but with higher MOS.
  - Synthetic data scale vs. filtering strictness: Looser thresholds increase data volume but may introduce noise; DECS > 0.8 threshold retains ~27% of synthesized samples.

- Failure signatures:
  - Dialect collapse: If DSDR-Net routing fails, all dialects produce similar outputs; check t-SNE of dialect embeddings for cluster overlap.
  - Low DECS scores: Indicates dialect embedding not being utilized; verify dialect ID is correctly passed through the pipeline.
  - PESQ < 3 after enhancement: MetricGAN+ may fail on certain artifacts; flag for manual review or discard.

- First 3 experiments:
  1. Reproduce ablation: Train TMD-TTS with DSDR-Net disabled (standard FFN) on a subset; verify DCA drops from ~80% to ~60%.
  2. Embedding dimension sweep: Test dialect embedding dimensions [64, 128, 256] and measure DECS impact; paper uses 128-dim.
  3. Cross-dialect generation: Provide mismatched dialect ID (e.g., Ü-Tsang text with Amdo label) to probe whether dialect characteristics are primarily acoustic vs. linguistic.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does the parallel synthesis capability of TMD-TTS account for lexical and syntactic variations between dialects, or does it primarily model phonological and acoustic differences?
- **Basis in paper:** [Inferred] The introduction states that the dialects differ significantly in "phonology, lexicon, and syntax," but the dataset generation pipeline (Fig. 1c) implies the synthesis of dialectal speech from a text database without explicitly detailing a translation or text-normalization step for cross-dialect lexical consistency.
- **Why unresolved:** The evaluation metrics (DECS, DCA) measure acoustic similarity and dialect classification accuracy, but no metric or subjective test specifically validates the semantic or grammatical correctness of the generated output for the target dialect.
- **What evidence would resolve it:** A linguistic analysis of the generated transcripts or a subjective evaluation by native speakers specifically rating the lexical and syntactic appropriateness of the synthesized content.

### Open Question 2
- **Question:** To what extent does the unified TMD-TTS framework preserve or control specific speaker identities when conditioned solely on dialect ID?
- **Basis in paper:** [Inferred] The model is trained on a corpus of over 1,500 speakers and uses dialect ID for conditioning, but the architecture description and results focus exclusively on dialect consistency and omit any speaker encoder module or speaker similarity metrics (e.g., SECS).
- **Why unresolved:** It is unclear if the model averages the speaker characteristics of the training data (producing a generic dialect voice) or if the DSDR-Net inadvertently captures speaker-specific timbres as part of the dialect routing.
- **What evidence would resolve it:** Quantitative evaluation using Speaker Embedding Cosine Similarity (SECS) between generated samples and reference speakers from the training set.

### Open Question 3
- **Question:** How does the performance and efficiency of the DSDR-Net architecture scale with the addition of more dialects or sub-dialects?
- **Basis in paper:** [Inferred] The DSDR-Net replaces the standard FFN with a set of private FFNs ($FFN_{private}$) specifically indexed by dialect ID (0, 1, 2), creating a hard parameter allocation for the three target dialects.
- **Why unresolved:** The "specialized routing" approach requires dedicated sub-networks for each class; it is uncertain if this design suffers from parameter explosion or training data fragmentation when applied to languages with significantly more dialect variety.
- **What evidence would resolve it:** Scalability experiments involving the addition of further dialect classes to measure the impact on Dialect Classification Accuracy (DCA) and Real-Time Factor (RTF).

## Limitations
- Synthetic data validation: Limited external validation of synthetic speech quality for applications beyond S2SDC
- Architecture generalization: DSDR-Net design may not scale well to languages with more dialects or radically different phoneme inventories
- Hyperparameter sensitivity: Critical training details unspecified, potentially affecting performance

## Confidence
- **High Confidence**: Objective metrics improvements (STOI, PESQ, SI-SDR) and MOS scores for naturalness and dialect similarity
- **Medium Confidence**: The mechanism of dialect embeddings improving consistency, supported by ablation but lacking direct embedding analysis
- **Low Confidence**: Downstream utility of synthetic TMDD data beyond S2SDC task due to limited external validation

## Next Checks
1. Evaluate TMDD on an external Tibetan dialect task (e.g., dialect recognition or speech recognition) to verify synthetic data generalizes beyond S2SDC
2. Visualize dialect embeddings using t-SNE or UMAP to confirm distinct clustering for each dialect and absence of collapse in the fusion module
3. Log DSDR-Net routing weights during training to verify each dialect's private FFN is utilized and there's no severe load imbalance between public and private components