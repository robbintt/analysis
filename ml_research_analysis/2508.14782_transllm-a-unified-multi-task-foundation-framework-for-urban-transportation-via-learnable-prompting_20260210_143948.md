---
ver: rpa2
title: 'TransLLM: A Unified Multi-Task Foundation Framework for Urban Transportation
  via Learnable Prompting'
arxiv_id: '2508.14782'
source_url: https://arxiv.org/abs/2508.14782
tags:
- traffic
- transllm
- prompt
- data
- temporal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes TransLLM, a unified foundation framework that
  integrates spatiotemporal modeling with large language models for diverse urban
  transportation tasks. The core method combines a lightweight spatiotemporal encoder
  with a learnable prompt routing mechanism trained via reinforcement learning, enabling
  instance-level personalization of prompts based on input characteristics.
---

# TransLLM: A Unified Multi-Task Foundation Framework for Urban Transportation via Learnable Prompting

## Quick Facts
- **arXiv ID:** 2508.14782
- **Source URL:** https://arxiv.org/abs/2508.14782
- **Reference count:** 40
- **Primary result:** Unified framework combining spatiotemporal encoder with learnable prompt routing outperforms ten baselines across seven datasets and three urban transportation tasks.

## Executive Summary
This paper introduces TransLLM, a unified foundation framework that integrates spatiotemporal modeling with large language models for diverse urban transportation tasks. The core method combines a lightweight spatiotemporal encoder with a learnable prompt routing mechanism trained via reinforcement learning, enabling instance-level personalization of prompts based on input characteristics. The framework outperforms ten baseline models across seven datasets and three tasks, including traffic forecasting and taxi dispatching, demonstrating strong generalization and cross-task adaptability with competitive performance on both regression and planning problems.

## Method Summary
TransLLM uses a two-stage training approach: first fine-tuning a frozen LLM with LoRA adapters using instance embeddings from a spatiotemporal encoder, then training a prompt router via reinforcement learning to select optimal prompt compositions. The spatiotemporal encoder (ST-Encoder) transforms raw traffic signals into dense embeddings via dilated temporal convolutions and dual-adjacency graph attention networks, which are projected to LLM hidden dimensions and injected via placeholder tokens. The Prompt Router uses an Actor-Critic network that maps these embeddings to action distributions over K slots, each containing multiple candidate sentences expressing similar intent with varied phrasing. Task-specific output heads project LLM hidden states to final predictions, avoiding token-level discretization for continuous values.

## Key Results
- TransLLM outperforms ten baseline models across seven datasets including LargeST-SD, PEMS08, ST-EVCDP, UrbanEV, and Taxi-SH
- Achieves 83.7% MAE improvement on UrbanEV charging demand prediction versus best small-scale baseline
- Demonstrates strong zero-shot generalization across cities and tasks with instance-level prompt personalization
- Shows competitive performance on both regression (forecasting) and planning (dispatch) problems

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Structured spatiotemporal embeddings enable LLMs to process numerical traffic patterns that would otherwise suffer precision loss from tokenization.
- **Mechanism:** The ST-Encoder transforms raw traffic signals into dense embeddings via dilated TCNs (temporal) and dual-adjacency GATs (spatial). These embeddings are projected to LLM hidden dimension and injected via placeholder tokens (⟨st_patch⟩), bypassing discrete text representation.
- **Core assumption:** Traffic dynamics can be compressed into fixed-dimensional embeddings without losing task-relevant information; LLMs can reason over continuous embeddings despite text-only pretraining.
- **Evidence anchors:**
  - [abstract] "seamlessly interfacing with LLMs through structured embeddings"
  - [section 4.1] "H_sp and H_se ∈ R^{T×N×D}...concatenated to generate the final representation H_f"
  - [corpus] WirelessGPT (arXiv:2502.06877) demonstrates similar embedding-based alignment for domain-specific signals with LLMs.
- **Break condition:** If embedding dimension D is too small, temporal patterns compress poorly; if st_patch tokens don't align with prediction horizon, the LLM receives misaligned sequential information.

### Mechanism 2
- **Claim:** Instance-level prompt routing via RL enables adaptive prompt selection that fixed task-specific templates cannot achieve.
- **Mechanism:** The Prompt Router uses an Actor-Critic network that maps H_f to action distributions over K slots. Each slot contains multiple candidate sentences expressing similar intent with varied phrasing. Actions are sampled and concatenated to compose personalized prompts, trained end-to-end via task-specific rewards.
- **Core assumption:** Optimal prompts vary by instance characteristics (time of day, volatility, periodicity strength); RL can discover these mappings better than manual design.
- **Evidence anchors:**
  - [abstract] "instance-level prompt routing mechanism, trained via reinforcement learning, dynamically personalizes prompts"
  - [section 4.2.4] "L_a^{(k)} = -log π_k · (R̂_t - V_k)" links prompt selection to task performance
  - [corpus] No direct corpus evidence for RL-based prompt routing in transportation; closest is MCP-enhanced CoT for spatiotemporal activity (arXiv:2506.10853), which uses prompting but not RL routing.
- **Break condition:** If prompt pool lacks diversity, RL has no useful action space; if reward signals are noisy (e.g., high-variance dispatch rewards), policy learning destabilizes.

### Mechanism 3
- **Claim:** Task-specific output heads outperform direct LLM generation for continuous numerical predictions by avoiding token-level quantization.
- **Mechanism:** Rather than generating text tokens decoded to numbers, TransLLM extracts the ⟨st_start⟩ hidden state from the LLM and passes it through specialized linear layers (Eq. 6, 7) tailored to each task's output format—regression for forecasting, softmax distribution for dispatch.
- **Core assumption:** LLM representations encode sufficient task-relevant information in token hidden states; projection layers can extract this more precisely than text generation.
- **Evidence anchors:**
  - [section 4.3] "avoid using the LLM to directly generate outputs...enables more accurate handling of continuous values, avoiding the precision loss caused by token-level discretization"
  - [section 5.5] TransLLM improves MAE by 83.7% on UrbanEV vs. best small-scale baseline
  - [corpus] UniMind (arXiv:2506.18962) uses similar multi-head output design for brain decoding tasks.
- **Break condition:** If LLM hidden states don't encode sufficient prediction-relevant information, projection layers will fail regardless of architecture; if tasks interfere in shared representations, multi-task learning degrades individual task performance.

## Foundational Learning

- **Graph Attention Networks (GAT):**
  - Why needed here: Core spatial modeling component—attends to neighboring traffic nodes with learned attention weights based on both physical adjacency and semantic similarity.
  - Quick check question: Can you explain how attention weights are computed for a node with 5 neighbors in a traffic graph?

- **Dilated Temporal Convolutions (TCN):**
  - Why needed here: Captures multi-scale temporal patterns (short-term fluctuations, daily/weekly periodicity) without recurrent connections; dilation expands receptive field efficiently.
  - Quick check question: Given dilation factors [1, 2, 4, 8] and kernel size 3, what is the total receptive field?

- **Actor-Critic Reinforcement Learning:**
  - Why needed here: Trains the Prompt Router to select optimal prompt compositions; actor predicts action distributions, critic estimates value for variance reduction.
  - Quick check question: Why does the critic network reduce variance compared to REINFORCE without a baseline?

## Architecture Onboarding

- **Component map:** Input (X ∈ R^{K×N×F}) → ST-Encoder [TCN → GAT(A_sp) + GAT(A_se) → TCN] → H_f ∈ R^{T×N×D} → Prompt Router [Actor MLP → π_k → sample a_k] → Composed Prompt + H_f (projected to d_L) → LLM (frozen with LoRA adapters) → Hidden state at ⟨st_start⟩ → Task-specific output head (linear → prediction)

- **Critical path:** ST-Encoder output H_f feeds both Prompt Router (for prompt selection) and LLM input (as st_patch embeddings). If H_f quality degrades, both prompt selection and LLM reasoning fail.

- **Design tradeoffs:**
  - Two-stage training (LLM first, Router second) vs. joint: Staged improves stability but may miss co-adaptation opportunities.
  - Number of st_patch tokens (N_p): Matching prediction horizon (N_p=12) performs best, but increases sequence length and compute.
  - Prompt pool size per slot (N_c): More candidates increase expressiveness but add RL exploration burden; optimal is 2-4 per dataset.

- **Failure signatures:**
  - High MAE with low ablation drop on w/o STE: LLM may be over-relying on priors rather than structured inputs—check embedding projection alignment.
  - Dispatch MMR stagnates while W-Dist improves: Model is converging to conservative (stay-in-place) policy—increase reward coefficient β for service efficiency.
  - Zero-shot performance collapses on new city: Spatial adjacency mismatch—ensure semantic adjacency A_se is computed from target city's data.

- **First 3 experiments:**
  1. **ST-Encoder sanity check:** Train only the ST-Encoder + output head (remove LLM and Prompt Router) on single dataset. Verify baseline forecasting performance matches small-scale models before adding LLM complexity.
  2. **Prompt pool diversity audit:** For each slot, compute pairwise sentence similarity using embedding cosine distance. If any slot has >0.8 average similarity, the RL agent has insufficient action diversity—expand the pool.
  3. **Zero-shot transfer diagnostic:** Train on PEMS08, evaluate on PEMS03/PEMS04. Log per-node MAE correlation with traffic volume variance—high-variance nodes should show larger gaps if periodicity assumption breaks.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can TransLLM maintain its performance advantage when trained on the same volume of data as small-scale baselines, or does the reduced training subset mask computational efficiency issues?
- **Basis in paper:** [inferred] Appendix A.1 states that "Due to the higher computational cost of training TransLLM, we employ a reduced training subset" (e.g., only 4 days for Large-SD compared to 30% for baselines).
- **Why unresolved:** It is unclear if the superior performance is robust to data scaling or if the higher computational cost of LLMs creates a practical ceiling where small-scale models might catch up or surpass TransLLM when both are fully trained on larger datasets.
- **What evidence would resolve it:** A comparative analysis evaluating TransLLM and GNN baselines on identical, large-scale training splits, measuring both prediction accuracy and training resource consumption (time/GPU memory).

### Open Question 2
- **Question:** To what extent does the reliance on manually constructed prompt pools limit the framework's scalability to entirely new transportation tasks or domains?
- **Basis in paper:** [explicit] Section 4.2.2 states, "The effectiveness of the Prompt Router relies on a well-designed and diverse prompt candidate pool... We construct this pool by partitioning the prompt into K distinct functional slots."
- **Why unresolved:** The manual design of prompt slots and candidate sentences introduces a human bottleneck, potentially restricting the model's ability to autonomously adapt to tasks where the optimal reasoning structure is unknown or difficult to pre-define.
- **What evidence would resolve it:** Experiments testing the model on a novel task (e.g., traffic signal control or accident detection) using automated/learned prompt generation versus the current manual construction method.

### Open Question 3
- **Question:** Can the framework be extended to handle long-horizon sequential planning tasks, given that the current dispatch formulation is restricted to single-step probability predictions?
- **Basis in paper:** [inferred] Section 3.2 and 4.3 formulate the dispatch task as predicting a probability distribution for a single decision step ($D_c$ in Eq. 7), rather than a trajectory of future actions.
- **Why unresolved:** Real-world planning often requires multi-step foresight (e.g., relocating vehicles now to anticipate demand hours later), which single-step projection layers cannot natively model without iterative feedback loops.
- **What evidence would resolve it:** Evaluation of the model on a multi-step horizon planning benchmark, assessing its ability to maintain performance consistency over long sequential decision chains.

### Open Question 4
- **Question:** Does decoupling the numerical prediction from the LLM's token generation process compromise the model's ability to produce coherent natural language explanations for its decisions?
- **Basis in paper:** [inferred] Section 4.3 explains that "we avoid using the LLM to directly generate outputs" to prevent precision loss, instead using specialized output layers to predict continuous values.
- **Why unresolved:** While this improves numerical accuracy, the LLM is effectively generating reasoning based on embeddings, but the final numbers come from a separate linear layer. This could lead to a "faithfulness" gap where the text explanation does not logically imply the final numerical result.
- **What evidence would resolve it:** A human or automated evaluation measuring the semantic consistency between the LLM's generated chain-of-thought and the values produced by the output projection layer.

## Limitations
- **Model scalability constraints:** The framework relies on explicit spatiotemporal embeddings and prompt routing that scales poorly with node count. LargeST-SD (716 nodes) already required data reduction, and PEMS08 experiments used only 30% of data due to memory constraints.
- **RL routing instability:** While the paper reports stable training with entropy regularization, the prompt routing mechanism depends heavily on reward signal quality. In dispatch tasks, rewards are sparse (binary success/failure) and high-variance, which could lead to suboptimal prompt selection policies.
- **Generalization assumptions:** The framework assumes transportation domains share common spatiotemporal patterns amenable to unified modeling. However, cross-task performance gains may be overstated—traffic forecasting benefits from EV charging patterns, but dispatch optimization may not transfer as effectively to forecasting tasks.

## Confidence
- **High Confidence:** Mechanism 1 (ST-Encoder) - The spatiotemporal encoder architecture is well-established, with TCN and GAT components having extensive validation in traffic forecasting literature.
- **Medium Confidence:** Mechanism 2 (RL Prompt Routing) - While the overall framework is clear, the Actor-Critic implementation details are sparse and effectiveness depends critically on prompt pool diversity.
- **Medium Confidence:** Mechanism 3 (Output Heads) - The rationale for task-specific heads over direct generation is logical, but the assumption that LLM hidden states contain sufficient task-relevant information for all three diverse tasks is unproven across all datasets.

## Next Checks
1. **Zero-shot transfer stress test:** Train TransLLM on PEMS08 (170 nodes), then evaluate on LargeST-SD (716 nodes) without fine-tuning. Measure performance degradation across all three tasks to quantify true cross-city generalization.

2. **RL router ablation with diverse prompts:** Create an expanded prompt pool (8 candidates per slot) with controlled semantic diversity. Train with and without entropy regularization, measuring final task performance and action entropy distributions to isolate routing effectiveness.

3. **Compute-accuracy tradeoff analysis:** Systematically vary training data reduction ratios (25%, 50%, 75%, 100%) on LargeST-SD and UrbanEV. Plot performance vs. computational cost to identify the practical scaling boundary for real-world deployment.