---
ver: rpa2
title: 'MASS: Overcoming Language Bias in Image-Text Matching'
arxiv_id: '2501.11469'
source_url: https://arxiv.org/abs/2501.11469
tags:
- bias
- mass
- language
- image
- image-text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses language bias in image-text matching, where
  visual-language models rely too heavily on textual priors rather than visual content.
  The proposed Multimodal ASsociation Score (MASS) framework reduces this bias by
  computing pointwise mutual information between image and text tokens, aggregating
  them to form a debiased similarity score.
---

# MASS: Overcoming Language Bias in Image-Text Matching
arXiv ID: 2501.11469
Source URL: https://arxiv.org/abs/2501.11469
Reference count: 25
Key outcome: MASS reduces language bias in image-text matching by computing debiased similarity scores through pointwise mutual information, achieving 93% improvement in color debiasing, 4.7% gain in counting tasks, and up to 19.3% reduction in gender bias while maintaining high recall.

## Executive Summary
This paper addresses language bias in image-text matching where models rely too heavily on textual priors rather than visual content. The proposed Multimodal ASsociation Score (MASS) framework reduces this bias by computing pointwise mutual information between image and text tokens, aggregating them to form a debiased similarity score. MASS works with existing models without retraining and shows strong performance across three bias domains: color (93% improvement over baselines), counting (4.7% gain in adversarial set), and gender bias (up to 19.3% reduction in bias while maintaining high recall). It also improves linguistic understanding in compositionality benchmarks (Winoground, SVO-Probes), outperforming baselines like CLIP and token likelihood methods.

## Method Summary
MASS addresses language bias by computing debiased similarity scores from pretrained visual-language models using two forward passes: one with the actual image and one with a black-filled null image. For each token, it calculates pointwise mutual information (PMI) as the difference between conditional log-likelihoods given the actual image versus the null image. These token-level PMI scores are averaged to produce a sequence-level similarity score. The method requires no model retraining, works with autoregressive captioning models like OFA, and effectively separates linguistic priors from visual associations to reduce bias in color perception, counting, and gender-related tasks.

## Key Results
- MASS achieves 93% improvement in color debiasing on Natural Colors Dataset over token likelihood baseline
- Counting bias reduced by 4.7% on VALSE adversarial benchmark with pairwise ranking accuracy
- Gender bias reduced by up to 19.3% in Bias@K metric while maintaining Recall@K above 60%
- Winoground Groupscore improves from 9.5% (ITM) to 20.3% (MASS) with OFA-large, more than doubling compositional understanding
- SVO-Probes verb understanding improves from 6.8% (TL) to 37.2% (MASS), demonstrating enhanced linguistic comprehension

## Why This Works (Mechanism)

### Mechanism 1: Pointwise Mutual Information Decomposition
Separating linguistic priors from visual association reduces language bias by computing PMI = log p(x|c) - log p(x), isolating image-relevant signal while suppressing text-only priors. This works because captioning models build unconditional language priors alongside image conditioning, and subtracting the marginal likelihood removes these spurious correlations. Break condition: if backbone likelihood estimates are miscalibrated, PMI subtraction may amplify noise rather than signal.

### Mechanism 2: Null Image as Marginal Likelihood Approximation
Using a black-filled "null image" provides computationally efficient marginal likelihood estimation, reducing computational overhead from O(N) to O(1) additional passes. This works because the null image triggers unconditional language modeling behavior without introducing artifacts. Break condition: if the model has learned spurious correlations between image darkness and specific text patterns, null image may introduce bias rather than remove it.

### Mechanism 3: Token-Level Aggregation with Visual Grounding Emphasis
Aggregating token-level PMI scores preserves fine-grained visual-linguistic alignment better than sequence-level embeddings. This works because visually grounded words (objects, attributes, quantities) contribute proportionally to their image relevance while function words contribute minimally. Break condition: if token-level likelihoods are poorly calibrated for rare words or technical vocabulary, aggregation may amplify errors.

## Foundational Learning

- **Pointwise Mutual Information (PMI)**
  - Why needed here: MASS's core mathematical operation; understanding PMI = log p(x,y)/(p(x)p(y)) is essential to grasp how linguistic priors are subtracted
  - Quick check question: Given p("firewoman"|image) = 0.8 and p("firewoman") = 0.2, what is PMI? (Answer: log(0.8/0.2) ≈ 1.39 nats)

- **Autoregressive Language Modeling**
  - Why needed here: MASS operates on token-level conditional likelihoods from autoregressive captioning models; understanding p(x) = Π p(xt|x<t) is prerequisite
  - Quick check question: Why can't we directly compute p(x) from an image-conditioned model? (Answer: The model always expects an image input; we approximate via null image or sampling)

- **Contrastive vs. Generative Multimodal Objectives**
  - Why needed here: The paper contrasts ITC (CLIP-style embeddings) with TL (captioning likelihoods); MASS builds on the latter while addressing its biases
  - Quick check question: Why do captioning models exhibit stronger language bias than contrastive models? (Answer: Captioning objectives optimize for plausible text sequences, building unconditional language priors alongside image conditioning)

## Architecture Onboarding

- **Component map:** Image -> Backbone VL Model (OFA/BLIP-2/LLaVA) -> Null Image Generator -> PMI Computer -> Aggregator -> Similarity Output

- **Critical path:** 1) Preprocess text to token sequence 2) Forward pass with actual image → conditional likelihoods 3) Forward pass with null image → marginal likelihood approximation 4) Compute token-wise PMI 5) Aggregate to sequence score 6) Compare across candidates for ranking

- **Design tradeoffs:** Backbone selection scales with capacity (OFA-large 930M best, tiny 33M inconsistent); null image is 2× inference cost vs 10× for Monte Carlo sampling; mean pooling preserves interpretability but may underweight critical tokens

- **Failure signatures:** Images with dark regions may conflate with null image approximation; rare vocabulary leads to unreliable token likelihoods; object-level understanding remains weak (MASS underperforms ITM on Object subset 55.3% vs 63.2%)

- **First 3 experiments:**
  1. Reproduce color debiasing on NCD subset: Take 50 grayscale fruit images, compute MASS("The [fruit] is gray.") - MASS("The [fruit] is [natural_color]"). Expect positive differences indicating bias reduction
  2. Null image sanity check: Compare null image approximation against Monte Carlo (N=20 random images) marginal likelihood estimation on 100 samples. Report correlation and mean absolute error
  3. Backbone ablation: Run MASS on OFA-tiny, OFA-base, OFA-large for Winoground. Verify that gains scale with model capacity and that Groupscore consistently improves over TL baseline

## Open Questions the Paper Calls Out
The paper acknowledges limitations regarding visual bias and multimodal bias manifestations, noting that social bias could appear as visual bias or combinations of image and text. It suggests future work exploring these broader bias forms and potential integration with training-time debiasing techniques, though these remain unexplored in the current work.

## Limitations
- Null image approximation lacks theoretical justification and independent validation against Monte Carlo sampling
- Simple mean pooling aggregation may underweight critical tokens or amplify errors from poorly calibrated likelihoods
- Token-level PMI scores may be unreliable for rare vocabulary or domain-specific terminology
- Object-level understanding remains weak compared to contrastive methods despite improvements in verb comprehension

## Confidence
- **High Confidence:** Color debiasing results (93% improvement with clear statistical separation), gender bias reduction (consistent improvements across multiple K values with substantial mean bias reduction)
- **Medium Confidence:** Counting bias improvements (4.7% gain with smaller effect sizes), compositionality understanding (Groupscore improvements dependent on backbone model)
- **Low Confidence:** Null image approximation validity (minimal empirical evidence), token-level likelihood calibration (untested for rare words)

## Next Checks
1. **Null Image Approximation Validation:** Run MASS on 100 random samples using both null image approximation and Monte Carlo sampling (N=20 random images per sample) to estimate marginal likelihood. Compare resulting MASS scores for correlation and mean absolute error.
2. **Rare Word Robustness Test:** Select 100 samples containing rare or technical vocabulary. Compute MASS scores and compare against TL baseline. Measure whether PMI values become erratic or show high variance for these tokens.
3. **Visual Grounding Ablation:** For 50 samples where MASS shows large improvements, visualize per-token PMI scores. Identify which tokens contribute most to debiased score and verify they correspond to visually grounded concepts rather than function words.