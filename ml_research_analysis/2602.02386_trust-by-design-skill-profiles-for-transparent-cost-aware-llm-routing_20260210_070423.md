---
ver: rpa2
title: 'Trust by Design: Skill Profiles for Transparent, Cost-Aware LLM Routing'
arxiv_id: '2602.02386'
source_url: https://arxiv.org/abs/2602.02386
tags:
- skill
- selection
- skills
- performance
- capability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: BELLA addresses the challenge of selecting cost-effective large
  language models (LLMs) for tasks by introducing a skill-based profiling and routing
  framework. The method extracts interpretable skill profiles from LLM outputs via
  a critic model, clusters these into structured capability matrices, and performs
  multi-objective optimization to recommend models that maximize performance within
  budget constraints.
---

# Trust by Design: Skill Profiles for Transparent, Cost-Aware LLM Routing

## Quick Facts
- arXiv ID: 2602.02386
- Source URL: https://arxiv.org/abs/2602.02386
- Reference count: 11
- Introduces BELLA framework for transparent, cost-aware LLM routing

## Executive Summary
BELLA addresses the challenge of selecting cost-effective large language models (LLMs) for tasks by introducing a skill-based profiling and routing framework. The method extracts interpretable skill profiles from LLM outputs via a critic model, clusters these into structured capability matrices, and performs multi-objective optimization to recommend models that maximize performance within budget constraints. BELLA provides natural-language rationale for recommendations, distinguishing it from black-box routing systems. The framework was evaluated on financial reasoning tasks, demonstrating its ability to make principled cost-performance trade-offs while offering transparency in model selection decisions. The approach generalizes to any domain with cost-performance trade-offs across desired models.

## Method Summary
BELLA operates through a three-stage pipeline: first, it uses a critic model to extract skill profiles from LLM outputs by evaluating performance across different capabilities; second, it clusters these skill profiles into structured capability matrices that reveal distinct LLM strengths and weaknesses; and third, it applies multi-objective optimization to route tasks to models that balance performance requirements against cost constraints. The framework generates natural-language explanations for its routing decisions, providing transparency into why specific models are recommended for particular tasks.

## Key Results
- Demonstrated cost-effective LLM routing for financial reasoning tasks
- Provides interpretable skill profiles that enable principled model selection
- Generates natural-language rationales explaining routing recommendations
- Achieves transparent decision-making compared to black-box routing alternatives

## Why This Works (Mechanism)
BELLA works by transforming the opaque process of LLM selection into an interpretable skill-based matching problem. By extracting structured capability profiles from LLM outputs, the system can quantify and compare model strengths across different task dimensions. The clustering approach reveals natural groupings of capabilities, while the multi-objective optimization framework ensures recommendations balance both performance requirements and budget constraints. The natural-language explanations bridge the gap between technical model selection and user understanding, making the routing decisions transparent and trustworthy.

## Foundational Learning

**Critic Model Evaluation**: Uses auxiliary models to assess LLM outputs across multiple dimensions - needed because raw model outputs don't reveal underlying capabilities; quick check: verify critic model accuracy on benchmark datasets.

**Skill Profile Extraction**: Converts qualitative assessments into structured quantitative profiles - needed to enable mathematical optimization of routing decisions; quick check: validate profile consistency across different critic model runs.

**Capability Clustering**: Groups similar skill profiles to identify model archetypes - needed to simplify the routing space and reveal natural model groupings; quick check: test clustering stability with varying parameters.

**Multi-Objective Optimization**: Balances competing objectives (performance vs. cost) - needed because real-world constraints require trade-offs; quick check: verify Pareto optimality of recommendations.

**Natural Language Rationale Generation**: Explains technical decisions in user-friendly terms - needed for transparency and user trust; quick check: user study to validate explanation clarity.

## Architecture Onboarding

**Component Map**: Task Input -> Critic Model -> Skill Profile Extraction -> Capability Clustering -> Multi-Objective Optimization -> Model Recommendation -> Natural Language Rationale

**Critical Path**: The most time-sensitive path is Critic Model Evaluation -> Skill Profile Extraction -> Multi-Objective Optimization, as these steps directly impact routing decisions and must be completed before task execution.

**Design Tradeoffs**: The framework trades computational overhead for transparency and interpretability. Using critic models adds latency but enables explainable decisions. The clustering approach simplifies routing but may miss nuanced capability differences.

**Failure Signatures**: 
- Poor critic model performance leads to inaccurate skill profiles and suboptimal routing
- Over-aggressive clustering may oversimplify capabilities, missing important distinctions
- Incorrect weight assignment in multi-objective optimization can bias recommendations toward cost over performance or vice versa

**3 First Experiments**:
1. Run BELLA on a small set of diverse tasks to validate basic routing functionality
2. Compare routing recommendations with human expert selections on the same tasks
3. Test the framework with synthetic cost-performance trade-offs to verify optimization behavior

## Open Questions the Paper Calls Out
None

## Limitations

The framework's generalizability remains uncertain since it was only validated on financial reasoning tasks. While the authors claim BELLA works for any domain with cost-performance trade-offs, there's no empirical evidence demonstrating effectiveness across diverse domains like medical reasoning, creative writing, or code generation. The clustering methodology assumes that LLM capabilities can be meaningfully grouped into distinct clusters, but this assumption hasn't been rigorously tested for robustness to different clustering parameters or task distributions.

## Confidence

High: The core technical approach of using critic models to extract skill profiles and clustering them for routing is sound and well-described. The cost-performance trade-off framework is methodologically rigorous.

Medium: The effectiveness of BELLA for financial reasoning tasks, though limited to the specific evaluation setup used. The clustering methodology produces coherent groupings that enable effective routing.

Low: Claims about generalizability to arbitrary domains without additional validation. The interpretability and trustworthiness of the natural-language explanations provided by the system.

## Next Checks

1. **Cross-domain validation**: Test BELLA on at least three diverse domains (e.g., medical reasoning, creative writing, and code generation) to verify the claimed generalizability. Compare performance against domain-specific baselines and document any domain-dependent parameter tuning required.

2. **Critic model robustness analysis**: Evaluate how variations in critic model architecture, training data, and hyperparameters affect the resulting skill profiles and routing recommendations. Conduct ablation studies to determine which components of the critic model most influence the final decisions.

3. **Weight sensitivity testing**: Systematically vary the performance-cost trade-off weights across a wide range and analyze how recommendations change. Identify whether there are threshold effects where small weight changes cause dramatic shifts in model selection, and develop guidelines for practitioners to set appropriate weights for their specific applications.