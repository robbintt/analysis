---
ver: rpa2
title: 'FakeParts: a New Family of AI-Generated DeepFakes'
arxiv_id: '2508.21052'
source_url: https://arxiv.org/abs/2508.21052
tags:
- video
- arxiv
- detection
- conf
- comput
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FakeParts, a new family of AI-generated deepfakes
  characterized by subtle, localized manipulations to specific spatial regions or
  temporal segments of otherwise authentic videos. Unlike fully synthetic content,
  these partial manipulations blend seamlessly with real elements, making them particularly
  deceptive and difficult to detect.
---

# FakeParts: A New Family of AI-Generated DeepFakes

## Quick Facts
- **arXiv ID**: 2508.21052
- **Source URL**: https://arxiv.org/abs/2508.21052
- **Authors**: Ziyi Liu, Firas Gabetni, Awais Hussain Sani, Xi Wang, Soobash Daiboo, Gaetan Brison, Gianni Franchi, Vicky Kalogeiton
- **Reference count**: 40
- **Primary result**: Introduces FakeParts - localized, partial deepfake manipulations that blend with authentic content, making them harder to detect than full-frame forgeries.

## Executive Summary
This paper introduces FakeParts, a new family of AI-generated deepfakes characterized by subtle, localized manipulations to specific spatial regions or temporal segments of otherwise authentic videos. Unlike fully synthetic content, these partial manipulations blend seamlessly with real elements, making them particularly deceptive and difficult to detect. The authors present FakePartsBench, the first large-scale benchmark designed to capture the full spectrum of partial deepfakes, comprising over 81K videos with pixel- and frame-level manipulation annotations. User studies demonstrate that FakeParts reduces human detection accuracy by up to 26% compared to traditional deepfakes, with similar performance degradation observed in state-of-the-art detection models. The benchmark enables comprehensive evaluation of detection methods and reveals critical gaps in current detectors when confronting partial manipulations.

## Method Summary
The authors developed FakePartsBench, a comprehensive dataset containing over 81K videos with various manipulation types including face swapping, expression editing, inpainting, and temporal interpolation/extrapolation. The dataset provides pixel- and frame-level annotations marking edited regions. Multiple state-of-the-art detection methods were evaluated across four categories: Out-of-bag, Frame-only, Video-level, and VLM-based approaches. Human evaluation studies compared detection accuracy on FakeParts versus traditional full-frame deepfakes, revealing significant performance degradation for both humans and automated systems.

## Key Results
- FakeParts reduces human detection accuracy by up to 26% compared to traditional full-frame deepfakes
- State-of-the-art detection models show performance degradation similar to humans when confronted with partial manipulations
- Temporal manipulations (interpolation/extrapolation) prove particularly challenging, with human detection rates around 60% versus 80%+ for spatial manipulations
- Pixel- and frame-level annotations in FakePartsBench enable detailed analysis of detection failures

## Why This Works (Mechanism)
FakeParts exploits the fundamental challenge that partial manipulations preserve most of the original authentic content, making detection harder because detectors must identify subtle inconsistencies rather than obvious synthetic artifacts. The localized nature means that surrounding real content provides contextual cues that mask the manipulation. Temporal manipulations are especially difficult because they require detecting inconsistencies across frames rather than within single frames, a capability current detectors lack.

## Foundational Learning

**Deepfake detection fundamentals** - Why needed: Understanding the evolution from detecting obvious artifacts to subtle manipulations. Quick check: Can distinguish between full-frame and partial manipulation detection challenges.

**Temporal consistency analysis** - Why needed: Temporal manipulations require cross-frame analysis rather than single-frame inspection. Quick check: Can identify why interpolation/extrapolation is harder than spatial edits.

**Detection model categories** - Why needed: Different approaches (OoB, frame-only, video-level, VLM) have varying strengths for partial vs. full manipulations. Quick check: Can map each detector type to its appropriate use case.

**Manipulation annotation techniques** - Why needed: Pixel- and frame-level annotations enable detailed analysis of detection performance. Quick check: Understand how fine-grained annotations improve benchmark utility.

## Architecture Onboarding

**Component map**: Source videos → Manipulation pipeline → FakePartsBench dataset → Detection models (OoB, FoM, VLM, DiB) → Evaluation framework

**Critical path**: Video source → Manipulation type selection → Region annotation → Detection model training → Performance evaluation

**Design tradeoffs**: Partial manipulations sacrifice detection robustness for realism; comprehensive annotation increases dataset utility but requires significant manual effort; multiple detection approaches provide breadth but may dilute specialized insights.

**Failure signatures**: Detection failures concentrate on temporal manipulations and fine-grained spatial edits; models trained on full-frame forgeries struggle with localized inconsistencies; human sensitivity varies by manipulation type and viewing context.

**First experiments**: 1) Compare detection accuracy across manipulation types to identify hardest cases, 2) Analyze detector performance on pixel-level annotated regions versus whole frames, 3) Test detection robustness under different viewing conditions and compression levels.

## Open Questions the Paper Calls Out

**Open Question 1**: How does manipulation region size affect detection performance across detector architectures?
- Basis: Authors note "finer-grained exploration, such as varying inpainting areas and their effect on detection, remains open"
- Status: Unresolved - FakePartsBench treats all inpainted regions equivalently regardless of spatial extent
- Resolution: Controlled study varying manipulation areas (5%, 10%, 20%, 50% of frame area) with systematic performance evaluation

**Open Question 2**: Why do temporal manipulations show substantially lower performance than spatial manipulations?
- Basis: Observed performance gaps (interpolation ~60% human AUC, extrapolation 44.6% for best detector) with attribution to "inherent differences in human sensitivity"
- Status: Unresolved - No investigation of whether temporal artifacts are fundamentally harder to model or simply underexplored
- Resolution: Controlled experiments comparing spatial vs. temporal edits of identical content with feature analysis in frequency/latent spaces

**Open Question 3**: Can detectors leverage authentic surrounding context in partial manipulations?
- Basis: Paper notes FakeParts "leverage the surrounding original, real content" but current detectors treat videos holistically
- Status: Unresolved - No existing method explicitly isolates manipulated regions for focused analysis
- Resolution: Development of detectors with explicit mechanisms to identify and weight edited regions differently

**Open Question 4**: To what extent do findings generalize to real-world distribution shifts?
- Basis: Benchmark uses high-resolution native outputs without post-processing, yet real-world deepfakes undergo platform-specific compression
- Status: Unresolved - No evaluation under realistic degradation pipelines
- Resolution: Testing all detector categories on FakePartsBench after applying realistic compression, scaling, and re-encoding

## Limitations

- Novelty claims could be challenged since many existing datasets contain partial manipulations; distinction between "fully synthetic" and "partial manipulations" may be semantic
- Benchmark methodology lacks sufficient detail about source content diversity and manipulation generation methods
- Human detection study doesn't specify participant expertise, viewing conditions, or training protocols that could influence results

## Confidence

- **Claim about FakeParts being a distinct family of deepfakes**: Medium confidence - Concept valid but novelty needs more rigorous justification
- **Detection accuracy degradation claims**: High confidence - Quantitative results clear, though experimental design limitations should be acknowledged
- **Benchmark comprehensiveness claims**: Low confidence - Claims about capturing "full spectrum" appear premature without detailed methodology

## Next Checks

1. Conduct systematic comparison between FakeParts manipulations and established techniques (face swapping, attribute editing) to quantify actual novelty and distinguish FakeParts as unique category.

2. Perform ablation studies on FakePartsBench to demonstrate dataset contains sufficient diversity across manipulation types, source domains, and generation methods.

3. Replicate human detection study with controlled variables including participant expertise levels, viewing time constraints, and training protocols to validate 26% accuracy reduction is robust and generalizable.