---
ver: rpa2
title: 'Engineering AI Agents for Clinical Workflows: A Case Study in Architecture,MLOps,
  and Governance'
arxiv_id: '2602.00751'
source_url: https://arxiv.org/abs/2602.00751
tags:
- clinical
- architecture
- agent
- mlops
- governance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents a case study of the "Maria" platform, a production-grade
  clinical AI system that addresses the engineering challenges of building reliable,
  maintainable, and governable AI for primary healthcare. The central hypothesis is
  that trustworthy clinical AI is achieved through the holistic integration of four
  foundational engineering pillars: a synergistic architecture combining Clean Architecture
  and Event-Driven Architecture for resilience and auditability, an Agent-Based Design
  where AI components are autonomous agents with their own MLOps lifecycle, robust
  MLOps pipelines for versioning, monitoring, and governance, and a Human-in-the-Loop
  governance model integrated as an event-driven safety net.'
---

# Engineering AI Agents for Clinical Workflows: A Case Study in Architecture,MLOps, and Governance

## Quick Facts
- arXiv ID: 2602.00751
- Source URL: https://arxiv.org/abs/2602.00751
- Authors: Cláudio Lúcio do Val Lopes; João Marcus Pitta; Fabiano Belém; Gildson Alves; Flávio Vinícius Cruzeiro Martins
- Reference count: 37
- One-line primary result: Production-grade clinical AI platform demonstrating how Clean Architecture + EDA + autonomous agents + HITL governance enables resilient, maintainable, and accountable AI in primary healthcare.

## Executive Summary
This paper presents a case study of the "Maria" platform, a production-grade clinical AI system that addresses the engineering challenges of building reliable, maintainable, and governable AI for primary healthcare. The central hypothesis is that trustworthy clinical AI is achieved through the holistic integration of four foundational engineering pillars: a synergistic architecture combining Clean Architecture and Event-Driven Architecture for resilience and auditability, an Agent-Based Design where AI components are autonomous agents with their own MLOps lifecycle, robust MLOps pipelines for versioning, monitoring, and governance, and a Human-in-the-Loop governance model integrated as an event-driven safety net. The platform demonstrates practical lessons for building maintainable, scalable, and accountable AI-enabled systems in high-stakes domains.

## Method Summary
The Maria platform implements a dual-agent architecture for pre- and post-medical appointment workflows, using Clean Architecture to isolate clinical domain logic from volatile infrastructure and Event-Driven Architecture to ensure resilience through temporal and spatial decoupling. Each agent operates with an autonomous MLOps lifecycle featuring independent CI/CD pipelines, versioned prompt registries, and multi-stage privacy protocols. The Human-in-the-Loop governance functions as an event-driven validation layer where clinician decisions (Approve/Correct/Reject) create immutable audit trails and feed back into continuous improvement through golden set evaluation. The system processes user inputs through an ingestion API that immediately publishes events to an event bus, allowing synchronous API responses (median 6.13ms) while agents process asynchronously.

## Key Results
- System demonstrates 6.13ms median API latency with 0.0% failure rate for critical agent endpoints
- HITL governance achieves 19% correction rate with 0% rejection rate, providing continuous improvement data
- Autonomous agent MLOps lifecycle proves operationally non-negotiable despite high upfront costs
- Clean Architecture + EDA combination enables both auditability and resilience in clinical workflows

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The synergistic combination of Clean Architecture and Event-Driven Architecture (EDA) enables resilience, maintainability, and inherent auditability in high-stakes clinical AI systems.
- **Mechanism:** Clean Architecture isolates core clinical domain logic (Entities, Use Cases) from volatile infrastructure via the dependency rule, allowing fast unit tests without external dependencies. EDA decouples components temporally and spatially through a publish-subscribe event bus, so downstream failures (e.g., HITL latency spikes) cannot block synchronous user-facing APIs. The event log itself becomes an immutable audit trail.
- **Core assumption:** Assumption: Clinical business rules remain more stable than infrastructure choices (LLM providers, databases, frameworks).
- **Evidence anchors:**
  - [abstract]: "synergistic architecture that combines Clean Architecture for maintainability with an Event-driven architecture for resilience and auditability"
  - [section 3.1]: "The EDA decouples the user's synchronous experience from the agent's asynchronous work"
  - [section 4.1]: "median latency of 6.13ms...0.0% failure rate for critical agent endpoints"
  - [corpus]: Weak direct evidence for Clean+EDA synergy specifically; neighbors focus on MLOps lifecycle and agentic workflows separately.
- **Break condition:** If core business logic begins directly depending on outer-layer frameworks (violating dependency rule), or if event consumers become tightly coupled to publishers via synchronous expectations.

### Mechanism 2
- **Claim:** Conceptualizing AI components as autonomous Agents, each with a dedicated MLOps lifecycle, improves system modularity, governance, and maintainability.
- **Mechanism:** Each agent (Pre- and Post-medical appointment) encapsulates its own logic, prompts, schemas, policies, and model IDs in a versioned registry. Independent CI/CD pipelines with pre-merge checks (linting, schema validation, red-teaming, PII scanning) allow isolated deployment and rollback. This prevents cross-agent breakage and enables granular governance.
- **Core assumption:** Assumption: The operational overhead of maintaining multiple autonomous pipelines is justified by reduced deployment risk and higher velocity over time.
- **Evidence anchors:**
  - [abstract]: "agent-based modularity...autonomous agents...each with dedicated MLOps lifecycles"
  - [section 3.2]: "A change in this registry automatically triggers a CI/CD pipeline...multi-stage privacy protocol"
  - [section 4.3]: "autonomous MLOps lifecycle is operationally non-negotiable, despite its high upfront cost"
  - [corpus]: "A Practical Guide for Designing, Developing, and Deploying Production-Grade Agentic AI Workflows" supports agentic workflow design patterns.
- **Break condition:** If cost or complexity pressure forces shared MLOps pipelines across agents, creating tight coupling where changes to one agent's evaluation framework breaks another.

### Mechanism 3
- **Claim:** Human-in-the-Loop (HITL) governance functions as a critical event-driven data source for continuous improvement, not merely a safety check.
- **Mechanism:** The Validation Orchestrator pauses workflow after AI output and routes to Clinician Review UI. Clinician decisions (Approve/Correct/Reject) emit events that trigger: (1) Version Lock & Persist, (2) Feedback Loop to golden set for offline evaluation, or (3) Rollback & Alert. The 19% correction cohort becomes high-quality training data.
- **Core assumption:** Assumption: Clinician corrections represent ground truth for improvement and are systematically fed back into evaluation/retraining pipelines.
- **Evidence anchors:**
  - [abstract]: "governance metrics...19% correction rate...0% rejection rate...demonstrating both system reliability and the value of human feedback as a continuous improvement mechanism"
  - [section 4.4]: "19% 'Corrected' cohort is the most valuable output...form the core of our 'golden set' for the MLOps Offline Eval"
  - [corpus]: "Towards Conversational AI for Human-Machine Collaborative MLOps" supports human-machine collaboration patterns in MLOps.
- **Break condition:** If correction events are captured but not systematically integrated into evaluation/retraining pipelines, HITL becomes a pass/fail gate rather than a data engine.

## Foundational Learning

- **Concept: Clean Architecture Dependency Rule**
  - **Why needed here:** Core clinical business rules must remain independent of volatile infrastructure (LLM providers, databases). Without this, swapping models or frameworks becomes a high-risk refactoring exercise.
  - **Quick check question:** Can you unit test the Agent Layer's clinical logic without spinning up a database or calling an external LLM API?

- **Concept: Event-Driven Publish-Subscribe Decoupling**
  - **Why needed here:** Ensures failures in downstream components (HITL workflow, observability) don't propagate to block user-facing APIs. Enables auditability by default through immutable event logs.
  - **Quick check question:** If the HITL review service goes down, can the ingestion API still accept and acknowledge user requests?

- **Concept: MLOps Traceability Requirements for Regulated Domains**
  - **Why needed here:** In healthcare, every prediction must be traceable to a specific versioned model with known performance characteristics. This is foundational for clinical trust and compliance.
  - **Quick check question:** Given a clinical output flagged in audit, can you identify the exact model version, prompt, and training data subset that produced it?

## Architecture Onboarding

- **Component map:** Ingestion API -> Intent Classifier -> Agent Layer (Pre/Post agents) -> Event Bus -> HITL Workflow -> Validation Orchestrator -> Clinician Review UI -> Audit Record

- **Critical path:**
  1. User input → Ingestion API → Intent Classifier determines intent
  2. Agent Layer executes domain logic, calls LLM Providers via abstract interface
  3. Agent publishes domain event (e.g., `ClinicalSummaryReadyForReview`) to Event Bus
  4. HITL Workflow subscribes, triggers Validation Orchestrator → Clinician Review UI
  5. Clinician decision event (Approve/Correct/Reject) → Audit Record + (Version Lock | Feedback Loop | Rollback)
  6. Response Delivery to patient with verification message

- **Design tradeoffs:**
  - **Latency vs. Resilience:** EDA introduces async complexity but decouples user experience (6.13ms API) from background processing (130-450ms agent tasks)
  - **Modularity vs. Operational Cost:** Independent agent pipelines increase infrastructure overhead but reduce deployment risk
  - **Governance vs. Throughput:** HITL review adds human latency but provides accountability and continuous improvement data

- **Failure signatures:**
  - Synchronous blocking: API latency spikes indicate EDA boundary violations
  - Cross-agent breakage: Shared pipeline changes breaking multiple agents indicates coupling
  - Governance gap: Correction events not appearing in golden set indicates broken feedback loop
  - Audit trail gaps: Unable to reconstruct AI decision lifecycle indicates missing event logging

- **First 3 experiments:**
  1. **Verify EDA decoupling:** Intentionally delay the HITL Workflow service and confirm API latency remains unaffected (target: <10ms p50)
  2. **Validate agent isolation:** Deploy a prompt change to Pre-Med Agent and confirm Post-Med Agent CI/CD pipeline shows zero triggered runs
  3. **Trace correction-to-golden-set path:** Make a clinician correction in the Review UI, then query the offline evaluation dataset to confirm the corrected example appears with proper metadata within defined SLA

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the synergistic architectural pattern (Clean Architecture + Event-Driven Architecture) maintain its resilience and governance capabilities when applied to specialized clinical domains with higher data densities, such as cardiology or mental health?
- Basis in paper: [explicit] The authors state a plan to "conduct a broader empirical benchmarking study across these diverse specialties" to "rigorously test the generalizability of our architectural and governance patterns beyond primary care."
- Why unresolved: The current case study validates the architecture only within the context of primary healthcare; specialized domains may introduce workflow complexities or data volumes that challenge the current system's latency and modularity.
- What evidence would resolve it: Empirical performance metrics (latency, failure rates) and governance statistics (approval/correction rates) collected from deployments across various distinct medical specialties.

### Open Question 2
- Question: How can the MLOps framework be evolved to manage the cost management and state orchestration challenges inherent in scaling from a dual-agent system to dozens of specialized agents?
- Basis in paper: [explicit] The paper identifies a "significant MLOps and operational challenge: evolving our single-agent lifecycle... into a scalable framework capable of managing dozens of specialized agents in parallel," specifically noting hurdles in "cost management and state orchestration."
- Why unresolved: The current production system only manages two agents (Pre- and Post-medical appointment); scaling this to many agents increases token usage and orchestration complexity, requiring new cost-control strategies.
- What evidence would resolve it: A demonstration of a multi-agent MLOps framework that successfully manages parallel specialized agents while maintaining strict infrastructure cost controls.

### Open Question 3
- Question: Can the Human-in-the-Loop feedback mechanism be technically enhanced to learn and adapt to the specific preferences of individual medical specialists?
- Basis in paper: [explicit] The future work section outlines a goal of "creating more sophisticated feedback loops where the system learns the preferences of individual specialists."
- Why unresolved: The current HITL workflow aggregates feedback into a general "golden set" for retraining, but lacks the capability to personalize outputs based on the specific validation patterns of individual clinicians.
- What evidence would resolve it: System logs demonstrating that the agents dynamically adjust their output styles or clinical suggestions based on the historical correction patterns of the specific specialist reviewing them.

## Limitations

- Evidence base is primarily descriptive and self-reported from a single platform implementation without external validation
- Specific performance metrics (6.13ms median latency, 0% failure rate) lack statistical rigor and comparative benchmarks
- Governance claims rely on single-instance metrics (19% correction rate) that may not generalize across different clinical contexts
- Does not address edge cases such as catastrophic model failures, adversarial attacks, or systemic biases in clinical decision support
- Long-term maintenance costs of autonomous agent pipelines and operational complexity are not quantified

## Confidence

- **High Confidence**: The foundational architectural principles (Clean Architecture dependency rule, EDA decoupling patterns, MLOps traceability requirements) are well-established in software engineering literature and the evidence provided directly supports these mechanisms.
- **Medium Confidence**: The specific implementation details and performance metrics for the Maria platform are internally consistent but lack external validation or comparative benchmarks against alternative approaches.
- **Low Confidence**: Claims about the generalizability of the governance model and the long-term sustainability of autonomous agent pipelines are speculative without multi-year operational data or cross-institutional studies.

## Next Checks

1. **External Audit Trail Reconstruction**: Provide an independent auditor with a randomly selected clinical output from the system and measure their ability to reconstruct the complete decision lineage (exact model version, prompt, training data subset, and HITL intervention) within 30 minutes.

2. **Cross-Institution Replication**: Partner with another healthcare organization to implement the same architectural patterns with their clinical workflows and compare: (a) system performance metrics (latency, failure rates), (b) governance metrics (correction/rejection rates), and (c) operational overhead (MLOps pipeline complexity, maintenance costs).

3. **Adversarial Robustness Testing**: Design and execute a red-teaming exercise specifically targeting the HITL governance loop, measuring: (a) time to detect malicious inputs, (b) false positive/negative rates in clinician review, and (c) the system's ability to learn from adversarial examples and prevent recurrence.