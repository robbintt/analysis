---
ver: rpa2
title: 'MultiCNKG: Integrating Cognitive Neuroscience, Gene, and Disease Knowledge
  Graphs Using Large Language Models'
arxiv_id: '2510.06742'
source_url: https://arxiv.org/abs/2510.06742
tags:
- knowledge
- graph
- cognitive
- arxiv
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MultiCNKG, a novel framework that integrates
  Cognitive Neuroscience Knowledge Graph (CNKG), Gene Ontology (GO), and Disease Ontology
  (DO) using large language models (LLMs) like GPT-4. The authors develop a multi-stage
  pipeline involving data preprocessing, graph representation, entity alignment, and
  graph expansion to create a unified knowledge graph linking genes, diseases, and
  cognitive processes.
---

# MultiCNKG: Integrating Cognitive Neuroscience, Gene, and Disease Knowledge Graphs Using Large Language Models

## Quick Facts
- arXiv ID: 2510.06742
- Source URL: https://arxiv.org/abs/2510.06742
- Reference count: 40
- Primary result: MultiCNKG integrates three biomedical knowledge graphs using LLMs, achieving 85.20% precision and enabling multi-layered insights from molecular to behavioral domains.

## Executive Summary
MultiCNKG is a novel framework that integrates Cognitive Neuroscience Knowledge Graph (CNKG), Gene Ontology (GO), and Disease Ontology (DO) using large language models (LLMs) like GPT-4. The authors develop a multi-stage pipeline involving data preprocessing, graph representation, entity alignment, and graph expansion to create a unified knowledge graph linking genes, diseases, and cognitive processes. The resulting MultiCNKG contains 6.9K nodes across 5 types and 11.3K edges across 7 types, enabling multi-layered insights from molecular to behavioral domains. Evaluation metrics show strong performance: precision of 85.20%, recall of 87.30%, coverage of 92.18%, and expert validation of 89.50%.

## Method Summary
The MultiCNKG framework employs a four-stage pipeline: (1) Data preprocessing using LLM tokenization and normalization; (2) KG representation as triples (h,r,t); (3) Node/edge alignment via embedding similarity with threshold τ; (4) Graph expansion using LLM for relation prediction with iterative validation. The approach leverages GPT-4 and BioGPT for semantic alignment and relation discovery, creating a unified knowledge graph that enables multi-layered insights from molecular to behavioral domains.

## Key Results
- Achieved 85.20% precision and 87.30% recall in entity alignment
- Coverage increased from 89.52% to 92.18% compared to individual source graphs
- Link prediction with TransE and RotatE models showed competitive performance (MR: 391-263, MRR: 0.395-0.411)

## Why This Works (Mechanism)

### Mechanism 1
LLM-based semantic alignment enables integration of heterogeneous biomedical ontologies with higher coverage than individual source graphs. LLMs generate vector embeddings for entities across CNKG, GO, and DO. Entity pairs are merged when cosine similarity exceeds a threshold, capturing semantic equivalence that string matching would miss. Core assumption: LLM embeddings capture domain semantics sufficiently to identify equivalent entities across ontologies. Evidence: "Leveraging LLMs like GPT-4, we conduct entity alignment, semantic similarity computation, and graph augmentation."

### Mechanism 2
LLM-based relation prediction discovers novel cross-domain edges not present in any source graph. For unconnected node pairs, the LLM estimates relationship probabilities using either prompt-based inference or probabilistic similarity models. Relations are added if confidence exceeds threshold, then validated. Core assumption: LLMs can infer biologically plausible relationships from contextual knowledge implicit in pre-training. Evidence: "the most critical step is leveraging LLMs to discover new relationships that are not explicitly present in the original graphs."

### Mechanism 3
Iterative graph expansion with confidence-based pruning maintains graph consistency while adding novel edges. The graph evolves through iterations where newly discovered relations receive confidence scores and are validated by experts. If confidence decreases below threshold, relations are removed. Core assumption: Iterative validation with expert feedback converges toward stable, accurate graph state. Evidence: "Newly discovered relations are assigned a confidence score and validated either automatically via external databases or manually by domain experts."

## Foundational Learning

- **Knowledge Graph Triples (h, r, t)**: MultiCNKG represents all knowledge as directed edges between nodes. Understanding triple structure is essential for interpreting link prediction metrics. Quick check: Given (APOE4, causes, Alzheimer's disease), what are the head, relation, and tail?

- **Embedding Similarity (Cosine Distance)**: Entity alignment relies on comparing vector embeddings using cosine similarity. The threshold τ determines merge decisions. Quick check: If two entity embeddings have cosine similarity 0.85 and threshold τ = 0.80, will they be merged?

- **Link Prediction Embedding Models (TransE, RotatE, ComplEx)**: The paper evaluates MultiCNKG quality using standard KGE models. Understanding what these models optimize helps interpret MR/MRR results. Quick check: TransE assumes h + r ≈ t in embedding space. Why might this fail for symmetric relations like "associated_with"?

## Architecture Onboarding

- **Component map**:
```
[CNKG Source] ──┐
[GO Source]   ──┼──> [LLM Preprocessing (GPT-4/BioGPT)] ──> [Entity Alignment] ──> [Graph Integration]
[DO Source]   ──┘                                                                    │
                                                                                     ▼
[LLM Relation Predictor] ──> [Confidence Scoring] ──> [Expert Validation] ──> [MultiCNKG v(t+1)]
         ▲                                              │
         └──────────── Iterative Feedback Loop ────────┘
```

- **Critical path**:
  1. Data preprocessing quality determines alignment accuracy
  2. Embedding similarity threshold (τ) controls precision/recall tradeoff
  3. LLM relation prediction confidence threshold determines novelty vs. hallucination balance
  4. Expert validation throughput limits iteration speed and scalability

- **Design tradeoffs**:
  - Precision vs. Coverage: Higher τ improves precision but reduces coverage
  - Novelty vs. Consistency: Aggressive LLM relation prediction increases novelty but risks graph consistency
  - Automation vs. Accuracy: Proprietary LLMs offer strong performance but limit reproducibility

- **Failure signatures**:
  - Low recall in entity alignment: Check if normalization is collapsing distinct entities
  - High MR in link prediction: May indicate insufficient training data for KGE models
  - Low expert validation rate: LLM hallucination; tighten confidence thresholds

- **First 3 experiments**:
  1. Ablation on similarity threshold τ: Run entity alignment with τ ∈ {0.70, 0.75, 0.80, 0.85, 0.90}. Plot precision vs. recall curve.
  2. LLM-only vs. embedding-similarity relation prediction: Compare relations discovered by prompt-based prediction vs. embedding similarity.
  3. Cross-validation on held-out edges: Hold out 10% of edges from each source graph and measure recovery rate.

## Open Questions the Paper Calls Out

- Can open-source LLMs (e.g., BioGPT, LLaMA) match GPT-4's performance in entity alignment and graph expansion while reducing computational costs? The authors plan to explore this for enhanced reproducibility.

- How does integration of pharmacological ontologies (DrugBank, PharmKG) into MultiCNKG impact accuracy of drug repurposing predictions for cognitive disorders? The authors plan to expand the graph for this purpose.

- Can real-time graph updates be achieved using federated learning without compromising semantic consistency? The paper suggests this as a future enhancement.

## Limitations
- Scalability concerns: The 6.9K node graph is small compared to available biomedical KGs, raising questions about computational feasibility at scale
- Reproducibility issues: Proprietary LLM dependencies (GPT-4) and unavailable CNKG data limit broader adoption
- Validation constraints: Expert validation is labor-intensive and may not scale with graph size

## Confidence
- **High Confidence**: Entity alignment performance metrics (85.20% precision, 87.30% recall) and coverage improvements are well-supported
- **Medium Confidence**: LLM-based relation prediction claims rely on reported novelty (40.28%) and expert validation (89.50%) but lack explicit false positive quantification
- **Low Confidence**: Iterative validation mechanism's convergence properties and scalability are asserted but not empirically demonstrated beyond the small MultiCNKG instance

## Next Checks
1. **Scalability Test**: Apply the MultiCNKG pipeline to a 10× larger biomedical KG and measure precision, recall, and computation time scaling
2. **False Positive Analysis**: Quantify the rate of hallucinated relations in LLM-predicted edges by comparing against held-out test sets
3. **Reproducibility Audit**: Reimplement the pipeline using open-source LLMs and publicly available ontologies to assess performance degradation and identify proprietary dependencies