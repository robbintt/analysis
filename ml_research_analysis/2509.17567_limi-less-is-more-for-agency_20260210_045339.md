---
ver: rpa2
title: 'LIMI: Less is More for Agency'
arxiv_id: '2509.17567'
source_url: https://arxiv.org/abs/2509.17567
tags:
- data
- agentic
- task
- limi
- subtask
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'LIMI demonstrates that sophisticated agentic AI capabilities can
  emerge from minimal training data through strategic curation rather than dataset
  scale. Using only 78 carefully designed training samples focused on collaborative
  software development and research workflows, LIMI achieves 73.5% performance on
  comprehensive agency benchmarks, dramatically outperforming state-of-the-art models
  trained on orders of magnitude more data: Kimi-K2-Instruct (24.1%), DeepSeek-V3.1
  (11.9%), Qwen3-235B-A22B-Instruct (27.5%), and GLM-4.5 (45.1%).'
---

# LIMI: Less is More for Agency

## Quick Facts
- **arXiv ID**: 2509.17567
- **Source URL**: https://arxiv.org/abs/2509.17567
- **Reference count**: 40
- **Primary result**: LIMI achieves 73.5% on agency benchmarks using only 78 samples, outperforming models trained on 10,000+ samples

## Executive Summary
LIMI demonstrates that sophisticated agentic AI capabilities can emerge from minimal training data through strategic curation rather than dataset scale. Using only 78 carefully designed training samples focused on collaborative software development and research workflows, LIMI achieves 73.5% performance on comprehensive agency benchmarks, dramatically outperforming state-of-the-art models trained on orders of magnitude more data. The approach establishes the Agency Efficiency Principle: machine autonomy emerges not from data abundance but from strategic curation of high-quality agentic demonstrations.

## Method Summary
LIMI employs a novel approach combining agentic query synthesis, systematic trajectory collection, and targeted fine-tuning to achieve high performance with minimal training data. The method focuses on capturing complete interaction sequences and sophisticated reasoning patterns through carefully curated demonstrations rather than scale. The training corpus of 78 samples is specifically designed to cover collaborative software development and research workflows, with an emphasis on tool utilization and problem-solving patterns. This strategic curation approach enables the model to learn effective agentic behaviors without requiring the massive datasets typically associated with state-of-the-art performance.

## Key Results
- LIMI achieves 73.5% performance on comprehensive agency benchmarks
- Outperforms Kimi-K2-Instruct (24.1%), DeepSeek-V3.1 (11.9%), Qwen3-235B-A22B-Instruct (27.5%), and GLM-4.5 (45.1%)
- Demonstrates 53.7% improvement over models trained on 10,000 samples with 128x fewer samples
- Shows effectiveness across generalization benchmarks spanning tool use, coding, and scientific computing

## Why This Works (Mechanism)
The Agency Efficiency Principle suggests that strategic curation of high-quality agentic demonstrations is more effective than scale-based training approaches. By focusing on complete interaction sequences and sophisticated reasoning patterns, LIMI captures the essential elements of agentic behavior without the noise and redundancy present in larger datasets. The targeted fine-tuning process emphasizes practical tool utilization and collaborative problem-solving skills that are directly relevant to real-world agency tasks.

## Foundational Learning
1. **Agency Efficiency Principle** - Why needed: Challenges the assumption that more data always yields better results for agentic AI. Quick check: Compare performance curves against dataset size across different curation strategies.
2. **Strategic Data Curation** - Why needed: Identifies that quality and relevance of demonstrations matter more than quantity for agentic capabilities. Quick check: Analyze feature importance of different curation criteria.
3. **Complete Trajectory Collection** - Why needed: Captures the full context of agentic interactions rather than isolated examples. Quick check: Measure performance impact of trajectory completeness.
4. **Tool Utilization Patterns** - Why needed: Focuses on practical skills essential for real-world agency tasks. Quick check: Evaluate tool use accuracy across different domains.
5. **Collaborative Problem-Solving** - Why needed: Emphasizes the social and cooperative aspects of agentic behavior. Quick check: Test performance on multi-agent scenarios.
6. **Targeted Fine-Tuning** - Why needed: Adapts the base model specifically for agency tasks rather than general capabilities. Quick check: Compare against general-purpose fine-tuning approaches.

## Architecture Onboarding

**Component Map:**
Agentic Query Synthesis -> Trajectory Collection -> Targeted Fine-Tuning -> Agency Benchmark Evaluation

**Critical Path:**
The most critical sequence is Query Synthesis → Trajectory Collection → Fine-Tuning, as each step builds directly on the previous one to create effective training data.

**Design Tradeoffs:**
- Data quantity vs. quality: Prioritizes carefully curated demonstrations over massive datasets
- General vs. specific training: Focuses on practical agency skills rather than broad capabilities
- Complexity vs. efficiency: Achieves high performance with minimal computational resources

**Failure Signatures:**
- Poor performance on tasks outside curated domains
- Overfitting to specific interaction patterns
- Suboptimal tool utilization in novel contexts

**Three First Experiments:**
1. Evaluate LIMI on completely different agentic tasks (autonomous vehicles, robotics, financial trading)
2. Conduct longitudinal real-world deployment study in collaborative software development environments
3. Perform ablation study varying curation methodology while keeping sample size constant at 78

## Open Questions the Paper Calls Out
None

## Limitations
- The 78-sample training corpus may have benefited from specific design choices that may not generalize across different problem domains
- Benchmark performance comparisons rely on specific evaluation protocols that may not capture real-world deployment scenarios
- The exact selection criteria and iterative refinement process for strategic curation are not fully detailed

## Confidence
- **High Confidence**: Core finding that LIMI outperforms substantially larger models on agency benchmarks
- **Medium Confidence**: Claim that strategic curation alone is responsible for performance gains
- **Low Confidence**: Generalizability of the Agency Efficiency Principle beyond tested domains

## Next Checks
1. Evaluate LIMI on completely different agentic tasks such as autonomous vehicles, robotics manipulation, or financial trading to verify generalizability beyond software development and research workflows.

2. Conduct a longitudinal study comparing LIMI against baseline models in actual collaborative software development environments, measuring task completion rates, user satisfaction, and maintenance requirements over extended periods.

3. Systematically vary the curation methodology by creating multiple training sets with different selection criteria (random sampling, diversity-focused sampling, task-specific sampling) while keeping dataset size constant at 78 samples to isolate the impact of curation strategy versus other factors.