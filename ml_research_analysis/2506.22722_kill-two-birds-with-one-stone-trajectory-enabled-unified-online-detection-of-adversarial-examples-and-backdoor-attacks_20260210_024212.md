---
ver: rpa2
title: Kill Two Birds with One Stone! Trajectory enabled Unified Online Detection
  of Adversarial Examples and Backdoor Attacks
arxiv_id: '2506.22722'
source_url: https://arxiv.org/abs/2506.22722
tags:
- detection
- uniguard
- backdoor
- uni00000013
- attacks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents UniGuard, the first unified online detection
  framework capable of simultaneously addressing adversarial examples and backdoor
  attacks in deep learning models. The core insight is that both types of attacks
  exhibit distinctive trajectory signatures as they propagate through model layers
  during inference.
---

# Kill Two Birds with One Stone! Trajectory enabled Unified Online Detection of Adversarial Examples and Backdoor Attacks

## Quick Facts
- arXiv ID: 2506.22722
- Source URL: https://arxiv.org/abs/2506.22722
- Authors: Anmin Fu; Fanyu Meng; Huaibing Peng; Hua Ma; Zhi Zhang; Yifeng Zheng; Willy Susilo; Yansong Gao
- Reference count: 40
- Primary result: First unified online detection framework achieving >99% accuracy for both adversarial examples and backdoor attacks simultaneously

## Executive Summary
UniGuard introduces a unified online detection framework that simultaneously identifies adversarial examples and backdoor attacks during inference by analyzing the propagation trajectories of inputs through deep learning models. The framework treats these trajectories as time-series signals, using LSTM encoding to amplify subtle differences between benign and malicious samples. By converting the temporal representations to frequency-domain spectra via FFT and applying one-class Deep SVDD anomaly detection, UniGuard achieves exceptional detection performance while maintaining minimal computational overhead suitable for real-time deployment.

## Method Summary
UniGuard extracts layer-wise latent representations from convolutional layers during model forward pass, reduces them using UMAP, and processes the sequence through a bidirectional LSTM encoder-decoder to obtain a bottleneck temporal representation. Fast Fourier Transform converts this to frequency-domain spectra, which feed into Deep SVDD trained only on benign samples. The framework operates in parallel with inference (UMAP) and achieves detection accuracy exceeding 99% for trigger-carrying samples across all attack types with minimal false rejection rates.

## Key Results
- Achieves >99% detection accuracy for backdoor attacks across 5 attack types (BadNet, WaNet, ISSBA, Blend, SSDT)
- Maintains >96% detection accuracy for adversarial examples across 7 attack methods (FGSM, PGD, CW, etc.)
- Effectively detects trigger-carrying samples even when model is backdoored (Table IV)
- Requires minimal computational overhead with parallelizable UMAP processing

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adversarial inputs exhibit distinctive propagation trajectory signatures compared to benign samples as they traverse network layers during forward inference.
- Mechanism: Extract layer-wise latent representations from convolutional layers, treat the sequence as a propagation trajectory. Adversarial samples must deviate from benign trajectories to fulfill adversarial objectives—otherwise misclassification or backdoor activation cannot occur.
- Core assumption: Adversarial inputs maintain similarity to benign samples in early layers (for imperceptibility) but diverge in deeper layers to achieve attack goals.
- Evidence anchors:
  - [abstract] "an adversarial input...exhibits distinctive trajectory signatures from a benign sample as it propagates through the layers of a DL model in forward inference"
  - [section III] "The propagation trajectory of the adversarial sample must deviate from that of its benign counterpart; otherwise, the adversarial objective cannot be fulfilled"
  - [corpus] Weak direct corpus support for trajectory-based detection; neighboring papers focus on distributional discrepancy (arXiv:2503.02169) and unified LLM defenses (arXiv:2502.13141) but not trajectory analysis.
- Break condition: If an adversarial input's trajectory is statistically indistinguishable from benign trajectories across all layers.

### Mechanism 2
- Claim: Treating the propagation trajectory as a time-series signal and applying LSTM encoding amplifies subtle differences between adversarial and benign trajectories.
- Mechanism: Apply bidirectional LSTM encoder-decoder to layer-wise reduced latent vectors (treated as time steps). Extract bottleneck representation z (e.g., 1×60 for ResNet18) that captures temporal dependencies while filtering noise—improving signal-to-noise ratio.
- Core assumption: The sequential progression of activations across layers contains discriminative temporal patterns that single-layer analysis cannot capture.
- Evidence anchors:
  - [abstract] "UniGuard overcomes this by treating the propagation trajectory as a time-series signal, leveraging LSTM...to amplify differences between adversarial and benign trajectories"
  - [section VII-A] "Without LSTM-autoencoder, UniGuard detection accuracy is 1.8% with preset FRR of 1%. With LSTM-autoencoder, detection accuracy is 99.02%"
  - [corpus] No direct corpus evidence for LSTM-based trajectory analysis in adversarial detection.
- Break condition: If LSTM encoding removes or fails to capture trajectory divergence information.

### Mechanism 3
- Claim: Spectrum transformation via FFT further enhances differentiation by revealing frequency-domain patterns invisible in the time domain.
- Mechanism: Apply Fast Fourier Transform to the LSTM-compressed temporal representation z, converting to spectrum representation before feeding to the anomaly detector.
- Core assumption: Adversarial vs. benign trajectory differences manifest more clearly in frequency domain than time domain.
- Evidence anchors:
  - [abstract] "spectrum transformation to amplify differences between adversarial and benign trajectories that are subtle in the time domain"
  - [section III-C-3] "analyzing signals in the frequency domain often uncovers features that are less apparent in the time domain"
  - [section VII-A] Without spectrum transformation: 99.08% detection accuracy but online FPR increases to 3.98% (from lower with FFT)
  - [corpus] No corpus support for spectrum-based adversarial detection.
- Break condition: If frequency transformation degrades rather than enhances discriminative features.

## Foundational Learning

- **Adversarial Examples vs. Backdoor Attacks**
  - Why needed here: UniGuard unifies detection for both attack types; understanding their shared inference-phase compromise is essential.
  - Quick check question: Can you explain why both attack types must compromise the inference phase, and how this enables unified detection?

- **LSTM Encoder-Decoder for Sequence Compression**
  - Why needed here: Core component that extracts temporal information from layer-wise trajectories.
  - Quick check question: How does a bidirectional LSTM encoder-decoder capture temporal dependencies, and what does the bottleneck representation represent?

- **Deep SVDD (One-Class Anomaly Detection)**
  - Why needed here: Enables attack-agnostic detection by training only on benign samples.
  - Quick check question: How does Deep SVDD define the boundary between normal and anomalous samples, and what role does the preset FRR play?

- **UMAP vs. PCA Dimensionality Reduction**
  - Why needed here: Critical for efficiency—UMAP is 12× faster than PCA per Section VII-E.
  - Quick check question: What are the tradeoffs between UMAP and PCA for latent representation reduction?

## Architecture Onboarding

- Component map:
  ```
  [Input Sample] → [Model Forward Pass] → [Extract Conv Layer Activations]
                                              ↓
                                    [UMAP: Spatial Reduction to 1×400 per layer]
                                              ↓
                                    [LSTM Encoder: Temporal Reduction to z (1×60)]
                                              ↓
                                    [FFT: Spectrum Transformation]
                                              ↓
                                    [Deep SVDD: Anomaly Detection]
                                              ↓
                                    [Benign / Adversarial Classification]
  ```

- Critical path:
  1. **Offline Phase**: Train LSTM autoencoder on benign trajectories → Train Deep SVDD on benign spectra
  2. **Online Phase**: Test sample → UMAP (parallel with inference) → LSTM encode → FFT → Deep SVDD score → threshold comparison
  3. **Key dependency**: UMAP reduction can run in parallel with model inference; LSTM encoding waits only until last monitored layer completes.

- Design tradeoffs:
  - **Preset FRR (1-5%)**: Lower FRR = fewer false rejections but potentially lower detection accuracy; 1% FRR recommended per experiments.
  - **Layer sampling**: Full layers optimal, but sampling every 2 layers (SS5) achieves 99.51% accuracy with lower overhead.
  - **UMAP vs. PCA**: UMAP 12× faster; PCA more stable for small sample sizes (<100 benign samples).
  - **Latent dimension**: 1×400 spatial reduction, 1×60 temporal compression for ResNet18.

- Failure signatures:
  - Detection accuracy drops sharply on specific attack types (e.g., ISSBA/Blend for competing methods)
  - Online FRR significantly exceeds preset FRR (indicates detector miscalibration)
  - High latency from sequential (vs. parallel) execution
  - Adaptive attack success: adversarial samples engineered to minimize Dist(z(x), z(x_adv)) evade detection

- First 3 experiments:
  1. **Baseline validation**: Test UniGuard on CIFAR10/ResNet18 against 5 backdoor types (BadNet, WaNet, ISSBA, Blend, SSDT) and 7 AE methods at preset FRR=1%. Verify >99% backdoor detection and >96% AE detection per Tables I-III.
  2. **Ablation study**: Remove LSTM component and measure detection accuracy drop (expect near-random per Section VII-A: 1.8% without LSTM).
  3. **Scalability test**: Validate on ResNet152 (deeper network) and Tiny-ImageNet (200 classes). Confirm detection accuracy remains >97% per Figure 5 results.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the distinct propagation trajectory divergence between benign and adversarial samples be formally proven theoretically?
- **Basis in paper:** [explicit] Section VII.F states that "providing theoretical proof remains an open challenge—an interesting direction for further strengthening UniGuard with formal guarantees."
- **Why unresolved:** The current work relies on empirical observation and intuition (that adversarial objectives force trajectory deviation) rather than formal mathematical bounds.
- **What evidence would resolve it:** A theorem establishing that for a perturbation to be effective (misclassify or trigger), its internal trajectory must mathematically deviate from the benign manifold by a detectable margin.

### Open Question 2
- **Question:** How can UniGuard maintain robustness against advanced adaptive attacks specifically optimized to mimic benign spectral trajectories?
- **Basis in paper:** [explicit] Section VII.F acknowledges the "security landscape is constantly evolving" and asks how to enhance robustness in the "ongoing security race" against "stronger adaptive attacks."
- **Why unresolved:** The evaluated adaptive attacks (Section VI) optimize for spatial distance in the latent bottleneck (z); attackers may develop strategies to match the temporal or spectral signature directly.
- **What evidence would resolve it:** Successful defense against "trajectory-spoofing" attacks where the adversary explicitly optimizes the perturbation to minimize the spectral loss of the propagation path.

### Open Question 3
- **Question:** Does the LSTM-based trajectory analysis scale effectively to extremely deep architectures (e.g., LLMs with hundreds of layers) without losing detection fidelity?
- **Basis in paper:** [inferred] The paper validates ResNet (up to 152 layers) and RoBERTa. However, standard LSTMs struggle with long-sequence dependencies; applying this method to models with significantly more layers remains an unstated scalability challenge.
- **Why unresolved:** As the "time-series" length (number of layers) increases, the LSTM may suffer from vanishing gradients or fail to propagate the subtle anomaly signal effectively.
- **What evidence would resolve it:** Empirical validation of UniGuard on extremely deep networks or large language models where the layer count significantly exceeds the tested configurations.

## Limitations
- Adaptive attacks specifically engineered to minimize trajectory divergence could potentially evade detection, as the framework hasn't been tested against defense-aware adversaries that explicitly optimize for spectral similarity
- The method requires monitoring multiple convolutional layers during inference, creating potential overhead even with UMAP's parallelization capability
- The effectiveness of FFT-based spectrum transformation for revealing adversarial patterns across diverse model architectures and attack types remains empirically validated but theoretically underspecified

## Confidence
- **High Confidence**: Detection accuracy claims (>99% for backdoors, >96% for AEs) supported by comprehensive experimental results across multiple datasets and attack types
- **Medium Confidence**: Mechanism claims regarding LSTM encoding and FFT transformation—while ablation studies show performance drops when removed, the theoretical justification for why frequency-domain patterns specifically capture adversarial signatures is limited
- **Medium Confidence**: Scalability claims to deeper networks (ResNet152) and regression tasks, based on limited experimental validation in supplementary materials

## Next Checks
1. **Adaptive Attack Resistance**: Design and test attacks that explicitly minimize trajectory divergence between benign and adversarial samples to assess UniGuard's robustness against defense-aware adversaries
2. **Resource Overhead Measurement**: Conduct comprehensive latency measurements comparing UniGuard's parallel UMAP processing against sequential baseline methods under varying batch sizes and hardware configurations
3. **Theoretical Analysis**: Investigate the mathematical relationship between adversarial perturbations, layer-wise trajectory divergence, and frequency-domain signatures to establish theoretical foundations for FFT-based detection