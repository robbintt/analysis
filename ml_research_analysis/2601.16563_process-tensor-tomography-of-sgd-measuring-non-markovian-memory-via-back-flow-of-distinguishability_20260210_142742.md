---
ver: rpa2
title: 'Process-Tensor Tomography of SGD: Measuring Non-Markovian Memory via Back-Flow
  of Distinguishability'
arxiv_id: '2601.16563'
source_url: https://arxiv.org/abs/2601.16563
tags:
- early
- imagenette
- cifar100
- resonant
- break
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work introduces a model-agnostic diagnostic for operational\
  \ non-Markovianity in neural network training, treating SGD as a process tensor\
  \ that maps controllable interventions to observable predictive distributions. A\
  \ two-step protocol measures back-flow of distinguishability (\u2206BF 0) between\
  \ prediction distributions after differing first interventions A vs."
---

# Process-Tensor Tomography of SGD: Measuring Non-Markovian Memory via Back-Flow of Distinguishability

## Quick Facts
- arXiv ID: 2601.16563
- Source URL: https://arxiv.org/abs/2601.16563
- Reference count: 40
- 97% of configurations show statistically significant back-flow under no break, with 28% flipping sign under causal break

## Executive Summary
This work introduces a model-agnostic diagnostic for operational non-Markovianity in neural network training, treating SGD as a process tensor that maps controllable interventions to observable predictive distributions. A two-step protocol measures back-flow of distinguishability between prediction distributions after differing first interventions A vs. A′ and a common second intervention B, certifying memory effects when the distance increases. A causal break (resetting optimizer state) nullifies back-flow, identifying optimizer buffers as the causal mechanism. Across CIFAR-100 and Imagenette, three divergences (TV, JS, H), and architectures (SmallCNN, ResNet-18, VGG-11, MobileNetV2, ViT-B/16), 97% of configurations show statistically significant back-flow under no break, with 28% flipping sign under causal break. Amplification correlates with momentum and batch overlap; the control regime (µ=0, disjoint batches) yields near-zero effects. This establishes a principled, reproducible measurement of training memory and provides a practical lever for understanding and controlling order-dependent dynamics in SGD.

## Method Summary
The method treats SGD as a process tensor mapping controllable interventions to observable predictive distributions. A two-step protocol measures back-flow of distinguishability (∆BF > 0) between prediction distributions after differing first interventions A vs. A′ and a common second intervention B, certifying memory effects when the distance increases. A causal break (resetting optimizer state) nullifies back-flow, identifying optimizer buffers as the causal mechanism. Across CIFAR-100 and Imagenette, three divergences (TV, JS, H), and architectures (SmallCNN, ResNet-18, VGG-11, MobileNetV2, ViT-B/16), 97% of configurations show statistically significant back-flow under no break, with 28% flipping sign under causal break. Amplification correlates with momentum and batch overlap; the control regime (µ=0, disjoint batches) yields near-zero effects.

## Key Results
- 97% of configurations show statistically significant back-flow under no break
- 28% of configurations flip sign under causal break
- Amplification correlates with momentum and batch overlap

## Why This Works (Mechanism)
The process tensor framework treats SGD as a mapping from controllable interventions to observable predictive distributions, allowing measurement of operational non-Markovianity through back-flow of distinguishability. When the distance between prediction distributions increases after a common second intervention B following differing first interventions A vs. A′, this certifies memory effects. The causal break mechanism identifies optimizer buffers as the source by nullifying back-flow when optimizer state is reset.

## Foundational Learning
- **Process tensor framework**: Needed to model SGD as a mapping from interventions to distributions; quick check: verify framework captures control-flow dependencies
- **Back-flow of distinguishability**: Required to quantify memory effects through increasing distance between distributions; quick check: confirm positive ∆BF indicates non-Markovianity
- **Causal break mechanism**: Essential to identify optimizer buffers as memory source; quick check: validate that state reset nullifies back-flow
- **Intervention sampling**: Critical for generating independent comparisons; quick check: ensure early-layer gradients don't depend on later-layer states
- **Divergence measures**: Needed to quantify distinguishability across TV, JS, and H metrics; quick check: verify consistent results across divergences
- **Optimizer buffer analysis**: Required to understand memory sources; quick check: isolate momentum vs adaptive learning rate effects

## Architecture Onboarding
- **Component map**: Intervention sampling -> Prediction distribution measurement -> Distinguishability calculation -> Back-flow quantification
- **Critical path**: First intervention A/A' -> Common intervention B -> Distribution comparison -> Memory effect certification
- **Design tradeoffs**: Model-agnostic approach vs mechanistic attribution ambiguity; causal break simplicity vs inability to isolate individual optimizer components
- **Failure signatures**: Zero back-flow under no break suggests Markovian behavior; inconsistent results across divergences indicate sampling issues
- **First experiments**: 1) Test on transformer-based language models to validate dataset generalizability 2) Apply causal break to isolate momentum vs adaptive learning rate effects 3) Evaluate on non-i.i.d. data distributions to assess robustness

## Open Questions the Paper Calls Out
None

## Limitations
- Assumes intervention distributions can be sampled independently, but early-layer gradients may depend on later-layer states
- Identifies optimizer buffers as memory source but cannot differentiate between momentum, adaptive learning rates, and batch overlap effects
- Focuses on image classification datasets and standard architectures; results may not transfer to language or graph models

## Confidence
- Operational non-Markovianity detection via back-flow: High (95% confidence; validated across 5 architectures, 2 datasets, 3 divergences)
- Causal break identifies optimizer buffers as mechanism: Medium (85% confidence; alternative explanations like gradient caching cannot be ruled out)
- Momentum and batch overlap amplify memory effects: Medium (80% confidence; correlation evidence but no controlled ablation)

## Next Checks
1. Apply the protocol to transformer-based language models (e.g., BERT) to test dataset generalizability.
2. Isolate individual optimizer components (momentum vs. adaptive learning rate) through ablation to pinpoint causal mechanisms.
3. Extend to non-i.i.d. data distributions (e.g., class imbalance) to assess robustness under realistic training conditions.