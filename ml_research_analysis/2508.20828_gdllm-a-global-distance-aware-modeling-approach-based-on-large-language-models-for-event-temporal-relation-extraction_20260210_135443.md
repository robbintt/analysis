---
ver: rpa2
title: 'GDLLM: A Global Distance-aware Modeling Approach Based on Large Language Models
  for Event Temporal Relation Extraction'
arxiv_id: '2508.20828'
source_url: https://arxiv.org/abs/2508.20828
tags:
- event
- relation
- temporal
- llms
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses Event Temporal Relation Extraction (ETRE),
  aiming to identify temporal relationships between event pairs in text. A key challenge
  is handling imbalanced classification datasets, especially for minority relation
  classes, and capturing both long-distance dependency and short-distance proximity
  features in event relations.
---

# GDLLM: A Global Distance-aware Modeling Approach Based on Large Language Models for Event Temporal Relation Extraction

## Quick Facts
- arXiv ID: 2508.20828
- Source URL: https://arxiv.org/abs/2508.20828
- Reference count: 16
- Primary result: State-of-the-art ETRE performance with 87.5% F1 on TB-Dense and 90.9% on MATRES

## Executive Summary
GDLLM addresses Event Temporal Relation Extraction by combining Large Language Models with Graph Attention Networks to overcome class imbalance and capture both long-distance and short-distance temporal dependencies. The approach uses LoRA-fine-tuned LLMs to generate probability distributions for event pairs, which serve as edge features in a distance-aware graph structure. This enables soft inference that improves minority class identification while GAT captures global relation features that manual prompts miss. Experiments demonstrate significant improvements over existing LLM and GNN baselines, particularly for minority relation classes.

## Method Summary
GDLLM fine-tunes LLMs (Llama3.1-8B or Qwen2.5-7B) using LoRA (rank=16) for sequence classification, generating probability distributions over relation classes for each event pair. These probabilities serve as edge features in a fully-connected event graph per document. A 2-layer GAT with 8 attention heads processes the graph, computing attention coefficients using concatenated node features (event order/type) and edge probability distributions. The final classification concatenates GAT outputs for event pairs with edge features through a fully-connected layer. The model uses HEBO optimization and evaluates with micro-F1 (excluding VAGUE).

## Key Results
- Achieves 87.5% F1 on TB-Dense and 90.9% on MATRES, outperforming existing LLM and GNN benchmarks
- Shows significant improvements for minority classes, with "w/o PI" ablation causing 8.3-11.1% F1 drop on MATRES
- Distance-stratified evaluation confirms distance-aware graph structure maintains high performance (79.3%-81.8%) across distances 2-5, while "w/o GD" degrades
- Ablation studies confirm both distance-aware graph structure and soft inference paradigm are critical components

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Integrating GAT with LLM probability distributions enables capture of long-distance temporal dependencies that manual prompts miss.
- **Mechanism:** GAT computes attention coefficients using node features concatenated with probability distributions, allowing the model to weight distant events based on learned relation patterns rather than prompt-engineered heuristics.
- **Core assumption:** Probability distributions from LLMs encode useful uncertainty information that improves attention learning compared to hard classification labels.
- **Evidence anchors:**
  - [abstract]: "We first present a distance-aware graph structure utilizing Graph Attention Network(GAT) to assist the LLMs in capturing long-distance dependency features."
  - [section 3.6 Table 4]: Performance degrades for "w/o GD" model as distance increases (79.3%→81.8% across distances 2-5), while full model maintains high performance.
  - [corpus]: Moderate support—related work (MAQInstruct) uses instruction tuning but doesn't combine GAT with soft inference; no direct corpus validation of this specific mechanism.
- **Break condition:** If attention coefficients collapse to uniform values (αij,k ≈ 1/|N(i)|), the distance-aware property is lost; may indicate insufficient probability distribution discriminability.

### Mechanism 2
- **Claim:** Soft inference using probability distributions as edge features improves short-distance relation identification and minority class performance.
- **Mechanism:** Instead of 0/1 hard labels, the model uses full probability vectors pij ∈ RC as edge features in GAT attention computation, providing richer gradient signals for learning subtle relation distinctions.
- **Core assumption:** LLM probability distributions contain meaningful uncertainty information that, when propagated through attention mechanisms, helps disambiguate minority classes from majority "VAGUE" relations.
- **Evidence anchors:**
  - [abstract]: "we design a temporal feature learning paradigm based on soft inference... which supplements the probabilistic information generated by LLMs into the multi-head attention mechanism"
  - [section 3.5]: "w/o PI" causes F1 drop of 8.3% (Llama) and 11.1% (Qwen) on MATRES; Figure 4 shows reduced micro-F1 vs macro-F1 gap.
  - [corpus]: Weak—no corpus papers validate soft inference for temporal relations; related work focuses on instruction tuning or hard classification.
- **Break condition:** If LLM probability distributions become overly confident (pij approaching one-hot vectors), the soft inference advantage diminishes; this may occur with excessive fine-tuning.

### Mechanism 3
- **Claim:** LoRA fine-tuning produces more accurate probability distributions than SLMs, which is critical for downstream graph-based learning.
- **Mechanism:** LoRA adapts LLM weights for sequence classification while preserving pre-trained knowledge; the resulting probability distributions show higher discriminability with confident predictions near 1.0 for correct classes and near 0.0 for incorrect ones.
- **Core assumption:** The quality of downstream GAT representations directly depends on the calibration and discriminability of upstream probability distributions.
- **Evidence anchors:**
  - [section 2.2]: "LLMs can present probability values with higher accuracy, which always assign a value closer to 1 for the relation category with the highest probability"
  - [section 3.3 Table 1]: SLM+GAT baselines underperform GDLLM by 15-20% F1; Llama3.1-8B achieves 87.5% vs RoBERTa-Large's 69.2% on TB-Dense.
  - [corpus]: Related work (MAQInstruct, LLMERE) confirms LLM effectiveness for ETRE but uses instruction tuning rather than LoRA+graph integration.
- **Break condition:** If LoRA rank is too low (insufficient adaptation capacity) or too high (catastrophic forgetting), probability quality degrades; paper uses rank=16 without sensitivity analysis.

## Foundational Learning

- **Concept: Graph Attention Networks (GAT)**
  - **Why needed here:** Core architecture for modeling document-level event relations; attention mechanism enables weighted aggregation of neighbor node information based on learned importance.
  - **Quick check question:** Given attention coefficients αij computed via LeakyReLU on concatenated features, how would removing the probability distribution pij from Equation 3 affect the model's ability to distinguish "SIMULTANEOUS" from "VAGUE" relations?

- **Concept: LoRA (Low-Rank Adaptation)**
  - **Why needed here:** Enables parameter-efficient fine-tuning of large models; critical for adapting frozen LLM weights to generate task-specific probability distributions without full retraining.
  - **Quick check question:** If LoRA rank were reduced from 16 to 4, would you expect probability distributions to become more uniform or more peaked? Why might this harm minority class detection?

- **Concept: Class Imbalance and Macro-FNL vs Micro-FNL**
  - **Why needed here:** TB-Dense has 47.7% "VAGUE" labels and only 1.5% "SIMULTANEOUS"; macro-FNL equally weights classes while micro-FNL weights samples, making the gap diagnostic of minority class performance.
  - **Quick check question:** A model achieves 90% micro-FNL but only 60% macro-FNL on TB-Dense. What does this imply about its predictions on the "SIMULTANEOUS" class?

## Architecture Onboarding

- **Component map:** Sentences with [EVi] event markers → LLM tokenizer → LoRA-fine-tuned LLM → probability distributions pij → Graph Construction → 2-layer GAT (8 heads, LeakyReLU) with concatenated [node_i || node_j || p_ij] → Classification head → Softmax

- **Critical path:** Probability distribution quality → attention coefficient discriminability → long-distance dependency capture → minority class separation. Failure at any stage propagates.

- **Design tradeoffs:**
  - GAT layers (2) vs depth: More layers capture longer dependencies but risk over-smoothing
  - Attention heads (8): More heads capture diverse patterns but increase memory
  - Probability vs hard labels: Soft inference preserves uncertainty but requires well-calibrated LLM outputs

- **Failure signatures:**
  - Attention collapse: αij ≈ 1/|N(i)| across all pairs → GAT reduces to mean aggregation
  - Probability uniformity: pij ≈ 1/C across classes → edge features provide no discriminative signal
  - Minority class confusion: t-SNE shows overlapping clusters for INCLUDES/IS_INCLUDED

- **First 3 experiments:**
  1. **Reproduce ablation "w/o PI":** Replace probability edge features with 0/1 hard labels; expect F1 drop of 8-11% on MATRES, confirming soft inference contribution.
  2. **Distance stratified evaluation:** Partition test set by event distance (n intervening events = 2,3,4,5); verify performance degradation in "w/o GD" but stable performance in full model at higher distances.
  3. **Probability calibration check:** Visualize LLM output distributions for correctly vs incorrectly classified minority class samples; confirm high-confidence predictions (p > 0.9) correlate with correct classifications per Figure 3.

## Open Questions the Paper Calls Out

- **Question:** How does the inherent bias or domain-specific pre-training of different LLM families impact the stability of the probability distributions used for soft inference in GDLLM?
  - **Basis in paper:** [Explicit] The authors state in the Limitations section that "different category choices of LLMs... inherent adaptability... or bias may pose challenges," noting that the Qwen model performed suboptimally on the minority EQUAL class.
  - **Why unresolved:** The study primarily validates the approach using Llama3.1-8B and Qwen2.5-7B, leaving the generalizability to other architectures (e.g., Mistral, Gemma) or significantly larger/smaller models uncertain.
  - **What evidence would resolve it:** A comparative analysis of probability distribution calibration and final ETRE performance across a broader range of open-source LLMs with varying parameter counts and pre-training corpora.

- **Question:** Is the linear event count the optimal metric for defining distance in the graph structure, or would syntactic dependencies provide better signals for long-distance dependencies?
  - **Basis in paper:** [Inferred] The method defines "distance" strictly as the number of intervening events $n$ between a target pair ($E_i, E_j$).
  - **Why unresolved:** While linear distance captures sequential proximity, it ignores the syntactic structure of the sentence, where two events might be linearly far but syntactically close (or vice versa).
  - **What evidence would resolve it:** An ablation study comparing the current distance-aware mechanism against a syntax-aware distance metric (e.g., dependency tree path length) on the TB-Dense and MATRES datasets.

- **Question:** How does the computational efficiency and accuracy of GDLLM scale when applied to documents with significantly higher event densities than those found in TB-Dense and MATRES?
  - **Basis in paper:** [Inferred] The performance analysis on distance features (Table 4) is limited to a maximum distance of 5 intervening events.
  - **Why unresolved:** It is unclear if the Graph Attention Network (GAT) mechanism maintains its ability to capture global features without performance degradation or excessive memory consumption in documents containing hundreds of events (dense graphs).
  - **What evidence would resolve it:** Experiments on long-document datasets or synthetic data with high event densities, reporting both F1 scores and GPU memory usage/time complexity.

## Limitations

- Node feature construction method remains underspecified, using only "event order and type information" without detailing encoding dimensions or implementation
- Hyperparameter configuration is incomplete—learning rate, batch size, training epochs, hidden dimensions, dropout rates, and HEBO search space are not provided
- Class imbalance in TB-Dense (47.7% VAGUE, 1.5% SIMULTANEOUS) creates inherent bias toward majority class performance

## Confidence

- **High confidence:** LLM fine-tuning produces superior probability distributions compared to SLM baselines, directly supported by Table 1 showing 15-20% F1 improvement. The soft inference paradigm's contribution (8.3-11.1% F1 gain in w/o PI ablation) is well-validated across both datasets.
- **Medium confidence:** The distance-aware graph structure's effectiveness at capturing long-distance dependencies, while supported by distance-stratified performance differences, lacks detailed analysis of attention coefficient patterns that would confirm the mechanism.
- **Low confidence:** The specific implementation of node features and their interaction with edge probability distributions in the attention mechanism, due to underspecification of encoding methods and dimensions.

## Next Checks

1. **Ablation with explicit node feature encoding:** Replace the unspecified node features with three different implementations—(a) learnable embeddings, (b) LLM token representations, (c) positional encodings—and measure performance differences to determine the critical factors for node feature design.

2. **Attention coefficient analysis:** Visualize and analyze the learned attention coefficients αij,k across different event distances (2, 3, 4, 5 intervening events) for both "w/o GD" and full GDLLM models to empirically confirm that probability distributions enable distance-aware weighting rather than uniform attention.

3. **Probability distribution calibration study:** Systematically vary LLM fine-tuning intensity (different LoRA ranks: 4, 8, 16, 32) and measure resulting probability distribution quality (calibration curves, entropy) and downstream GAT performance to establish the relationship between upstream probability discriminability and minority class detection capability.