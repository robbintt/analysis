---
ver: rpa2
title: 'Osiris: A Lightweight Open-Source Hallucination Detection System'
arxiv_id: '2505.04844'
source_url: https://arxiv.org/abs/2505.04844
tags:
- hallucination
- answer
- multi-hop
- reasoning
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Osiris-7B is a lightweight, open-source hallucination detection\
  \ system designed for retrieval-augmented generation (RAG) systems. It uses supervised\
  \ fine-tuning on a perturbed multi-hop QA dataset to detect hallucinations\u2014\
  instances where generated text is unsupported by context documents."
---

# Osiris: A Lightweight Open-Source Hallucination Detection System

## Quick Facts
- arXiv ID: 2505.04844
- Source URL: https://arxiv.org/abs/2505.04844
- Reference count: 18
- Osiris-7B achieves 0.938 recall on RAGTruth, outperforming GPT-4o by 22.8%

## Executive Summary
Osiris-7B is a lightweight, open-source hallucination detection system designed for retrieval-augmented generation (RAG) systems. It detects hallucinations—instances where generated text is unsupported by context documents—through supervised fine-tuning on a perturbed multi-hop QA dataset. The system achieves high recall on the RAGTruth benchmark while maintaining competitive precision and F1 scores, and operates significantly faster than GPT-4o with lower computational resource requirements.

## Method Summary
Osiris-7B uses supervised fine-tuning on a perturbed multi-hop QA dataset to train hallucination detection capabilities. The system is specifically designed for RAG applications where generated content must be verified against retrieved context documents. By focusing on lightweight architecture and efficient token generation, Osiris-7B achieves faster inference speeds compared to larger models while maintaining strong detection performance on the RAGTruth benchmark.

## Key Results
- Achieves 0.938 recall on RAGTruth benchmark, outperforming GPT-4o (0.710) by 22.8%
- Maintains competitive precision of 0.366 and F1 score of 0.527
- Runs at 141.98 tokens/second, faster than GPT-4o at 97 tokens/second

## Why This Works (Mechanism)
The system's effectiveness stems from supervised fine-tuning on domain-specific multi-hop QA data, which teaches the model to identify unsupported claims by analyzing the relationship between generated text and context documents. The lightweight architecture enables faster inference while maintaining detection accuracy, making it suitable for real-time applications.

## Foundational Learning
- **Multi-hop QA**: Reasoning across multiple documents to answer questions - needed for understanding complex retrieval scenarios in RAG systems; quick check: can the model handle questions requiring information from multiple sources
- **Supervised fine-tuning**: Training on labeled examples to adapt pre-trained models - needed to teach hallucination detection rather than general language understanding; quick check: model performance improves with more training examples
- **RAG systems**: Retrieval-augmented generation architecture - needed context for hallucination detection application; quick check: system works with standard RAG pipelines

## Architecture Onboarding
**Component Map**: Input Document -> Context Retriever -> Generator -> Osiris-7B Detector -> Output Classification
**Critical Path**: Document retrieval → Text generation → Hallucination detection → User feedback
**Design Tradeoffs**: Lightweight architecture vs. detection accuracy, speed vs. computational cost
**Failure Signatures**: High false positive rate (precision 0.366), limited generalizability beyond RAGTruth benchmark
**First Experiments**: 1) Run Osiris-7B on RAGTruth benchmark to verify baseline performance, 2) Measure token generation speed on target hardware, 3) Test detection accuracy on multi-hop QA examples

## Open Questions the Paper Calls Out
None

## Limitations
- Limited generalizability beyond RAGTruth benchmark and multi-hop QA domain
- High false positive rate (precision 0.366) may impact practical deployment
- No ablation studies to validate the contribution of supervised fine-tuning approach

## Confidence
- Core performance claims: Medium (strong benchmark results but limited external validation)
- Efficiency and scalability claims: High (straightforward to measure token speed and resource usage)

## Next Checks
1. Evaluate Osiris-7B on additional hallucination detection benchmarks (e.g., HallBench, TruthfulQA) to assess cross-dataset generalization
2. Conduct ablation studies to isolate the impact of supervised fine-tuning versus model size and architecture on hallucination detection performance
3. Deploy Osiris-7B in a live RAG system and measure precision, recall, and user satisfaction in real-world query scenarios