---
ver: rpa2
title: Optimal Aggregation of LLM and PRM Signals for Efficient Test-Time Scaling
arxiv_id: '2510.13918'
source_url: https://arxiv.org/abs/2510.13918
tags:
- uni00000013
- uni00000048
- uni00000011
- optimal
- uni00000003
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# Optimal Aggregation of LLM and PRM Signals for Efficient Test-Time Scaling

## Quick Facts
- arXiv ID: 2510.13918
- Source URL: https://arxiv.org/abs/2510.13918
- Reference count: 19
- Primary result: Calibrated weighted voting with negative PRM weights achieves target accuracy using only 21.3% of computation versus vanilla weighted voting

## Executive Summary
This paper addresses the inefficiency of Test-Time Scaling (TTS) in mathematical reasoning tasks by optimally aggregating LLM responses and PRM scores. The authors develop a theoretical framework showing that the optimal strategy is weighted majority voting where weights combine PRM signal (likelihood ratio of scores given correct vs incorrect) with LLM reliability. Crucially, they demonstrate that negative weights for low-PRM responses can improve efficiency by penalizing poor answers. Their calibration approach learns these weights from a small labeled dataset, achieving the same accuracy as standard methods while using only 21.3% of the computation.

## Method Summary
The method involves generating multiple LLM responses per question, scoring them with a PRM, and then calibrating a weighting function on a small labeled dataset. The framework derives optimal weights as a combination of PRM likelihood ratios and LLM reliability. Two approaches are used: parametric (Logit/Linear weighting with learned offset) and non-parametric (KDE on logit-transformed scores). At inference, answers are selected via weighted majority voting using the calibrated weights. The approach is evaluated on MATH and MATH500 datasets, comparing against baselines like Majority Vote, Best-of-N, and Vanilla Weighted Voting.

## Key Results
- Calibrated Logit Weighted Voting achieves target accuracy with only 21.3% of computation versus vanilla weighted voting
- Negative PRM weights (penalizing low-quality responses) significantly improve efficiency over non-negative alternatives
- Parametric Logit weighting consistently outperforms non-parametric KDE across all experimental conditions
- Larger calibration sets further improve performance, demonstrating scalability of the approach

## Why This Works (Mechanism)

### Mechanism 1
Optimal response selection is a weighted majority vote, not single-response selection. The authors formalize aggregation as MAP estimation. Theorem 3.2 shows the optimal score for answer αₖ sums weights wᵢ across all responses supporting that answer: wᵢ = log[P(pᵢ|c=1,V)/P(pᵢ|c=0,V)] + log[qₘ·(m-1)/(1-qₘ)]. This combines PRM signal (likelihood ratio of score given correct vs incorrect) with LLM reliability (base accuracy qₘ). Core assumption: Conditional independence of PRM scores and LLM generations given the true answer. Break condition: If responses are highly correlated (violating independence), the weight formula may misestimate combined evidence.

### Mechanism 2
Low PRM scores should map to negative weights, actively penalizing proposed answers. Empirically, the optimal weighting function w*(p) assigns substantial negative values for low p. A response judged poor by the PRM provides evidence against its answer—repetition doesn't increase likelihood. Standard BoN ignores this; majority voting treats all equally. Core assumption: The PRM's score distribution differs meaningfully for correct vs incorrect responses, enabling the likelihood ratio to invert for low scores. Break condition: If PRM is poorly calibrated (scores uninformative), negative weights amplify noise rather than signal.

### Mechanism 3
Calibration on a small pre-computed dataset substantially improves TTS efficiency. Since optimal weights are model-pair dependent, the authors learn parametric (Logit: logit(p)-logit(b)) or non-parametric (KDE) functions from calibration data D_cal. The offset b controls the zero-crossing point. This enables better aggregation without more sampling. Core assumption: The calibration set distribution approximates test-time distribution; weighting function generalizes across questions. Break condition: Distribution shift between calibration and test domains degrades learned weights.

## Foundational Learning

- **Concept:** Maximum a Posteriori (MAP) Estimation
  - Why needed here: The entire theoretical framework derives from treating answer selection as MAP inference over P(αₖ|G,P,M,V).
  - Quick check question: Given evidence E and hypothesis H, what does argmax P(H|E) assume about the prior?

- **Concept:** Likelihood Ratio and Log-Odds
  - Why needed here: The PRM signal term in wᵢ is a log-likelihood ratio comparing correct vs incorrect score distributions.
  - Quick check question: If P(score|correct)=0.8 and P(score|incorrect)=0.2, what is the log-likelihood ratio?

- **Concept:** Kernel Density Estimation (KDE)
  - Why needed here: Used to estimate P(p|c,V) in logit space for the non-parametric weighting function.
  - Quick check question: Why transform PRM scores from [0,1] to logit space before applying KDE?

## Architecture Onboarding

- **Component map:** LLM Generator -> PRM Verifier -> Calibration Module -> Aggregator
- **Critical path:** Calibration → Weight function learning → Weighted voting at inference. Errors in calibration propagate directly to selection quality.
- **Design tradeoffs:**
  - Parametric (Logit WV) vs Non-parametric (KDE WV): Logit is simpler, faster, and empirically better; KDE is more flexible but struggles with per-question variance
  - Calibration set size vs accuracy: More data helps, but requires labeling cost
  - Negative weights vs stability: Negative weights help efficiency but require reliable PRM discrimination
- **Failure signatures:**
  - Optimal b ≈ 0 suggests PRM provides no discriminative signal
  - Large gap between Optimal and calibrated methods indicates per-question variance dominates
  - qₘ estimation MAE > 0.2 suggests LLM reliability term is poorly estimated
- **First 3 experiments:**
  1. Run Majority Vote, BoN, Vanilla WV, and Logit WV on MATH500 with n=112 samples per question. Verify Logit WV achieves target accuracy with fewer samples.
  2. Force b=0 in Logit WV (disabling negative weights). Compare to learned b; expect performance drop.
  3. Train w(p) on LLM-PRM pair A, test on pair B. Expect degradation showing model-dependence.

## Open Questions the Paper Calls Out

### Open Question 1
How can the gap between global and per-question optimal weighting functions be bridged, given that current meta-models struggle to predict per-question functions? The authors note in the Limitations section that while optimal weights vary significantly per question, their "attempts to learn a meta model to predict these per-question functions were unsuccessful."

### Open Question 2
Can semi-supervised or unsupervised calibration techniques be developed to estimate optimal weighting functions without relying on labeled ground-truth data? The "Limitations and Future Work" section explicitly identifies the need to reduce reliance on labeled data, suggesting that "investigating semi-supervised or unsupervised calibration techniques could reduce the reliance on labeled data."

### Open Question 3
Does the calibrated weighted voting framework generalize effectively to reasoning domains beyond mathematics, such as code generation or logical inference? The authors state in "Limitations and Future Work" that their "evaluation has been focused on the domain of mathematical reasoning" and list exploring "generalization of our calibrated aggregation framework to other domains" as a key avenue for future research.

## Limitations

- The framework relies heavily on the conditional independence assumption between PRM scores and LLM responses, which may break down with correlated responses
- Calibration assumes the calibration set distribution matches the test-time distribution, limiting robustness to distribution shifts
- The method requires a small labeled calibration dataset, restricting accessibility in domains where verification labels are expensive
- The paper does not rigorously prove why parametric methods consistently outperform non-parametric methods beyond empirical observation

## Confidence

- **High Confidence:** The formal MAP framework and Theorem 3.2 derivation are mathematically sound given stated assumptions. Experimental methodology and baseline comparisons are well-specified.
- **Medium Confidence:** The empirical observation that negative weights are beneficial is well-supported, but theoretical justification is limited. Calibration procedure works in practice but lacks theoretical guarantees for generalization.
- **Low Confidence:** The claim that KDE-based weighting fails due to "per-question variance" is asserted but not rigorously proven.

## Next Checks

1. **Independence Validation:** Systematically test the conditional independence assumption by measuring response correlation and PRM score correlation across different sampling strategies. Quantify the impact of correlation on aggregation performance.

2. **Distribution Shift Robustness:** Evaluate the calibration procedure on test sets with known distribution shifts relative to the calibration data. Measure performance degradation and characterize which components (weight function, qₘ estimation) are most sensitive to distribution shift.

3. **Calibration Data Efficiency:** Conduct ablation studies on calibration set size and composition. Determine the minimum effective calibration set size and test whether calibration on easier questions generalizes to harder questions, or vice versa.