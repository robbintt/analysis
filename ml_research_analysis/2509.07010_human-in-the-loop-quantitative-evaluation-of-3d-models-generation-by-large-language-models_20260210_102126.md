---
ver: rpa2
title: 'Human-in-the-Loop: Quantitative Evaluation of 3D Models Generation by Large
  Language Models'
arxiv_id: '2509.07010'
source_url: https://arxiv.org/abs/2509.07010
tags:
- design
- metrics
- input
- geometric
- engineering
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a human-in-the-loop framework for quantitative
  evaluation of 3D models generated by large language models (LLMs). The method introduces
  structural complexity and geometric similarity metrics to systematically assess
  LLM-generated outputs against ground-truth CAD models.
---

# Human-in-the-Loop: Quantitative Evaluation of 3D Models Generation by Large Language Models

## Quick Facts
- arXiv ID: 2509.07010
- Source URL: https://arxiv.org/abs/2509.07010
- Reference count: 40
- This paper presents a human-in-the-loop framework for quantitative evaluation of 3D models generated by large language models (LLMs).

## Executive Summary
This paper introduces a systematic framework for quantitatively evaluating 3D models generated by large language models against ground-truth CAD models. Using an L-bracket case study, the authors demonstrate that increasing semantic richness in input prompts (from 2D orthographic views to code-level corrections) progressively improves model fidelity. The method combines structural complexity and geometric similarity metrics to provide explicit feedback for iterative refinement, achieving perfect reconstruction with code-level prompts. This quantitative approach enables faster convergence to ground-truth geometry compared to qualitative visual inspection, advancing robust benchmarking in AI-assisted CAD workflows.

## Method Summary
The method employs a human-in-the-loop pipeline where four input modalities (2D orthographic views, isometric sketches, geometric structure trees, and code-level correction prompts) are formatted for GPT-4.5 to generate OpenSCAD code. The generated code is rendered to STL format, then compared against ground-truth STL using Python scripts that compute structural complexity metrics (face count, surface ratio, Euler characteristic) and similarity metrics (dimensional, volumetric, surface, Hausdorff, PCA, ICP alignment). The human evaluates quantitative feedback to decide whether to iterate with refined prompts, switch to richer modalities, or manually correct code.

## Key Results
- Progressive improvement in model fidelity with increased input semantic richness, achieving perfect reconstruction with code-level prompts across all similarity metrics
- The proposed quantitative approach enables significantly faster convergence to ground-truth geometry compared to qualitative visual inspection
- Different input modalities produce systematic, diagnosable error patterns that map to specific metric failures

## Why This Works (Mechanism)

### Mechanism 1: Semantic Richness Gradient
Increased semantic richness and structural clarity in inputs correlates with higher geometric fidelity in LLM-generated 3D models. Symbolic/structured inputs (code, geometric structure trees) reduce ambiguity by explicitly encoding depth cues, feature hierarchy, and spatial relationships. This allows the LLM to leverage its stronger code generation capabilities rather than inferring geometry from under-specified visual inputs. Core assumption: LLMs have more robust capabilities for symbolic code generation than for spatial reasoning from 2D/3D visual representations. Evidence anchors: [abstract] "Results show progressive improvement in model fidelity with increased input semantic richness, achieving perfect reconstruction with code-level prompts across all similarity metrics." Break condition: When target geometries require organic/freeform surfaces not easily expressed in constructive solid geometry primitives.

### Mechanism 2: Quantitative Metrics as Feedback Signal
Explicit quantitative evaluation metrics enable faster convergence toward ground-truth geometry compared to qualitative visual inspection alone. Numerical metrics decompose error into specific dimensions (volumetric deviation, surface misalignment, orientation error, local feature displacement), allowing targeted corrections. Visual inspection provides holistic but imprecise feedback that doesn't localize the error source. Core assumption: The selected metrics accurately capture the error dimensions that humans perceive and that matter for downstream tasks. Evidence anchors: [abstract] "The proposed quantitative approach enables significantly faster convergence to ground-truth geometry compared to qualitative visual inspection, providing explicit feedback for iterative refinement." Break condition: When perceptually important features are not captured by the metric suite.

### Mechanism 3: Modality-Aligned Error Diagnosis
Different input modalities produce systematic, diagnosable error patterns that map to specific metric failures. Each modality has inherent limitations (orthographic lacks depth cues, isometric has feature ambiguity, even structured text may miss orientation) that manifest as distinct metric signatures. PCA/ICP alignment scores catch rotation/displacement errors even when volume/surface match perfectly. Core assumption: Error patterns are sufficiently consistent across similar geometries to enable diagnostic generalization. Evidence anchors: [Section 4.2] "The generated model exactly matched the ground truth in terms of volume, dimension, and surface area... However, the top arm of the bracket was rotated, which led to misalignment indicators such as PCA and ICP scores deviating from ideal values." Break condition: When geometry complexity increases such that error patterns overlap or when novel error modes emerge not covered by the metric suite.

## Foundational Learning

- **Constructive Solid Geometry (CSG) and Parametric CAD**
  - Why needed here: The approach uses OpenSCAD, which represents shapes via CSG operations (union, difference, intersection of primitives). Understanding how parametric code maps to 3D geometry is essential for interpreting generated outputs and crafting correction prompts.
  - Quick check question: Given `difference() { cube([40,40,10]); translate([10,10,-1]) cube([20,20,12]); }`, what shape results and what are its final dimensions?

- **Point Cloud Registration (ICP, PCA Alignment)**
  - Why needed here: Similarity metrics like ICP and PCA alignment compare generated and ground-truth models after optimal rigid registration. Understanding these algorithms explains why rotation errors appear even when volume/surface match.
  - Quick check question: Why might ICP fail to correctly align two identical shapes if one has rotational symmetry (e.g., a cylinder)?

- **Euler Characteristic and Topological Complexity**
  - Why needed here: The topological complexity metric uses Euler characteristic (χ = V - E + F) to quantify holes, tunnels, and connected components in the mesh.
  - Quick check question: A cube has 8 vertices, 12 edges, and 6 faces. What is its Euler characteristic? If you drill a through-hole (creating a tunnel), does χ increase, decrease, or stay the same?

## Architecture Onboarding

- **Component map:** Input Layer (four modalities) → Generation Layer (GPT-4.5 → OpenSCAD code → STL) → Evaluation Layer (Python metrics vs. ground truth) → Feedback Layer (human interprets scores → targeted correction or modality escalation)
- **Critical path:** 1. Prepare input in selected modality 2. LLM generates OpenSCAD code 3. Render to STL 4. Compute all metrics vs. ground truth 5. Human interprets scores → targeted correction or modality escalation 6. Repeat until convergence or manual completion
- **Design tradeoffs:** Higher semantic richness (code prompts) yields higher accuracy but requires more expertise to prepare inputs. Automated LLM-only iteration is faster but may plateau; human-in-the-loop is slower but achieves higher fidelity ceiling. Metric weighting can be tuned per application—prioritize volume/surface for manufacturing, dimensional accuracy for assembly fit, Hausdorff for feature-level precision.
- **Failure signatures:** Plateauing scores across iterations with current modality → switch to richer input modality. Perfect volume/surface/dimension but poor PCA/ICP → rotation or displacement error. High Hausdorff distance with good average metrics → localized feature error. Diverging or oscillating metrics → prompt instability. Negative PCA score → severe misalignment.
- **First 3 experiments:** 1. Reproduce the L-bracket case study using the provided OpenSCAD code to validate your metric computation pipeline matches the paper's reported values. 2. Test a different geometry (e.g., T-bracket or plate with two holes) across all four modalities to assess whether the modality-error pattern generalizes beyond L-brackets. 3. Modify metric weighting (e.g., weight dimensional accuracy higher than surface similarity) and measure impact on iteration count to convergence.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can the structural complexity score be utilized to systematically map model capabilities and failure modes across large-scale, diverse datasets? The current study is limited to a single L-bracket case study, preventing the validation of the complexity metric as a generalizable predictor of LLM performance across varied geometries.
- **Open Question 2:** Do dynamic or learned weightings for the composite similarity metrics provide superior alignment with human judgment compared to the currently proposed fixed coefficients? The framework currently uses manually tuned weights based on general engineering priorities, which may not be optimal for all specific design tasks or user preferences.
- **Open Question 3:** How does the evaluation framework perform when extended to multi-part assemblies and fully parametric geometries? The proposed metrics and human-in-the-loop pipeline were validated only on a single, rigid L-bracket component, leaving the handling of inter-part relationships and parametric constraints untested.

## Limitations

- The study's quantitative framework assumes that metric convergence equates to functional equivalence, without validating whether high metric scores translate to downstream manufacturing or assembly performance.
- The L-bracket case study represents a relatively simple CSG geometry; results may not generalize to organic or freeform surfaces.
- The human-in-the-loop process relies on expert judgment for prompt refinement, but the paper doesn't characterize the expertise level required or the variability in human decisions across different evaluators.

## Confidence

- **High confidence:** The correlation between semantic richness and geometric fidelity is well-supported by systematic metric progression across modalities and aligns with established LLM capabilities in code generation.
- **Medium confidence:** The claim about faster convergence through quantitative metrics is supported by the iterative improvement narrative but lacks direct comparison to pure qualitative approaches or baseline iteration counts.
- **Medium confidence:** The modality-specific error pattern mapping shows consistent signatures in the L-bracket study, but the diagnostic framework needs validation across diverse geometry types before being considered robust.

## Next Checks

1. Test the metric diagnostic framework on a freeform geometry (e.g., a turbine blade or ergonomic handle) to assess whether modality-error patterns generalize beyond CSG primitives.
2. Conduct a controlled experiment comparing human-in-the-loop with automated LLM-only iteration on identical geometries to quantify the actual time/fidelity tradeoff.
3. Validate that high metric scores correlate with manufacturing viability by 3D printing several "converged" models and measuring actual dimensional accuracy and feature integrity.