---
ver: rpa2
title: 'M$^3$Searcher: Modular Multimodal Information Seeking Agency with Retrieval-Oriented
  Reasoning'
arxiv_id: '2601.09278'
source_url: https://arxiv.org/abs/2601.09278
tags:
- search
- arxiv
- answer
- reasoning
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: M3Searcher introduces a modular approach to multimodal information
  seeking by decoupling information acquisition from answer generation. It uses a
  specialized MLLM planner to coordinate heterogeneous search tools (image, text,
  answer generator) and is trained with a retrieval-oriented multi-objective reward
  function that jointly optimizes factual accuracy, reasoning soundness, and retrieval
  fidelity.
---

# M$^3$Searcher: Modular Multimodal Information Seeking Agency with Retrieval-Oriented Reasoning
## Quick Facts
- arXiv ID: 2601.09278
- Source URL: https://arxiv.org/abs/2601.09278
- Reference count: 16
- Primary result: 59.25% accuracy on MMSearchVQA benchmark

## Executive Summary
M$^3$Searcher introduces a modular approach to multimodal information seeking by decoupling information acquisition from answer generation. It uses a specialized MLLM planner to coordinate heterogeneous search tools (image, text, answer generator) and is trained with a retrieval-oriented multi-objective reward function that jointly optimizes factual accuracy, reasoning soundness, and retrieval fidelity. The approach is supported by MMSearchVQA, a novel dataset featuring complex multi-hop multimodal queries with automatically extracted supporting evidence. Experiments show M3Searcher outperforms existing baselines, achieving accuracy of 59.25% on the in-domain MMSearchVQA benchmark, while demonstrating strong transfer adaptability across different search engines and answer generators. The design addresses the specialization-generalization trade-off in multimodal tool-use and mitigates training data scarcity for complex reasoning trajectories.

## Method Summary
M$^3$Searcher employs a modular framework where an MLLM planner orchestrates different search tools (image search, text search, and answer generation modules) to handle multimodal information seeking tasks. The system is trained using a retrieval-oriented multi-objective reward function that optimizes for factual accuracy, reasoning soundness, and retrieval fidelity. A novel MMSearchVQA dataset was constructed with complex multi-hop multimodal queries and automatically extracted supporting evidence. The modular design allows flexibility in integrating different search engines and answer generators, addressing the specialization-generalization trade-off in multimodal tool-use scenarios.

## Key Results
- Achieves 59.25% accuracy on MMSearchVQA benchmark
- Outperforms existing baselines in multimodal information seeking tasks
- Demonstrates strong transfer adaptability across different search engines and answer generators

## Why This Works (Mechanism)
The modular design allows M$^3$Searcher to decouple information acquisition from answer generation, enabling specialization of components while maintaining flexibility. The retrieval-oriented multi-objective reward function trains the system to optimize not just for final answer accuracy but also for the quality of reasoning steps and the relevance of retrieved information. This approach addresses the challenge of training data scarcity for complex reasoning trajectories by providing structured supervision through the reward function rather than requiring fully annotated reasoning paths.

## Foundational Learning
**Multimodal Information Seeking**: Understanding how to retrieve and integrate information across different modalities (text, images) is essential for answering complex queries that span multiple information sources. Quick check: Can the system effectively combine text and image information to answer queries?

**Tool-Use Coordination**: The ability to plan and execute sequences of tool calls (search engines, generators) requires sophisticated reasoning about when and how to use different tools. Quick check: Does the planner generate appropriate tool use sequences for different query types?

**Multi-hop Reasoning**: Complex queries often require multiple reasoning steps and information retrieval operations. Quick check: Can the system handle queries requiring information from multiple sources and reasoning steps?

**Reward Shaping**: Designing effective reward functions that capture multiple objectives (accuracy, reasoning quality, retrieval relevance) is crucial for training complex multimodal agents. Quick check: Does the reward function effectively balance different optimization objectives?

## Architecture Onboarding
**Component Map**: Query -> MLLM Planner -> (Image Search, Text Search, Answer Generator) -> Answer
**Critical Path**: Query input flows to MLLM planner, which determines tool usage sequence, retrieves information from search tools, and generates final answer through answer generator
**Design Tradeoffs**: Modular design offers flexibility and specialization but may introduce coordination overhead compared to integrated approaches
**Failure Signatures**: 
- Incorrect tool selection sequences
- Poor integration of multimodal information
- Suboptimal reward function weighting leading to imbalanced optimization
**First Experiments**:
1. Baseline comparison with non-modular multimodal QA systems
2. Ablation study on different tool combinations
3. Evaluation of transfer performance across different search engine configurations

## Open Questions the Paper Calls Out
None

## Limitations
- Performance evaluation relies heavily on a single in-house dataset (MMSearchVQA) with automatically extracted evidence
- Limited quantitative analysis of transfer adaptability across diverse tool combinations
- Lack of systematic evaluation of performance across different reasoning complexity levels

## Confidence
- **High Confidence**: Modular architecture design and conceptual framework are well-supported
- **Medium Confidence**: Retrieval-oriented multi-objective reward function shows promise but lacks full transparency
- **Low Confidence**: Claims about generalization across different search engines and answer generators need more extensive validation

## Next Checks
1. Evaluate M$^3$Searcher on established multimodal QA benchmarks (OK-VQA, VQA-Med) not used in training
2. Conduct systematic ablation study comparing performance across different tool combinations
3. Perform detailed failure mode analysis across queries with varying reasoning depths and multimodal complexity