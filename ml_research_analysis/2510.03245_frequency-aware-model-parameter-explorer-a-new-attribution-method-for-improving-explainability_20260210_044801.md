---
ver: rpa2
title: 'Frequency-Aware Model Parameter Explorer: A new attribution method for improving
  explainability'
arxiv_id: '2510.03245'
source_url: https://arxiv.org/abs/2510.03245
tags:
- attribution
- score
- insertion
- methods
- components
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of improving explainability
  in deep neural networks (DNNs) by introducing a novel attribution method called
  Frequency-Aware Model Parameter Explorer (FAMPE). The core method leverages a new
  class of transferable adversarial attacks, termed transferable frequency-aware attacks,
  which explore both high- and low-frequency components of input data to generate
  robust adversarial samples.
---

# Frequency-Aware Model Parameter Explorer: A new attribution method for improving explainability

## Quick Facts
- arXiv ID: 2510.03245
- Source URL: https://arxiv.org/abs/2510.03245
- Reference count: 33
- Primary result: FAMPE improves Insertion Score by 13.02% over AttEXplore across multiple architectures

## Executive Summary
This paper introduces FAMPE, a novel attribution method that leverages frequency-aware adversarial attacks to improve DNN explainability. By separating high- and low-frequency components during perturbation generation and modulating them with parameter α, FAMPE achieves significantly better attribution maps than existing methods. The approach demonstrates substantial improvements on standard benchmarks across multiple architectures including Inception-v3, ResNet-50, VGG-16, and MaxViT-T.

## Method Summary
FAMPE generates attribution maps by creating transferable adversarial samples that explore both high- and low-frequency components of input data. The method uses FFT to decompose images, applies frequency masks weighted by parameter α, and reconstructs perturbed samples via IFFT. Gradients are computed over N adversarial samples and integrated along non-linear paths to produce final attributions. The cutoff frequency is automatically determined based on spectral energy distribution (90% threshold).

## Key Results
- FAMPE achieves 13.02% average improvement in Insertion Score over AttEXplore
- Best performance on Inception-v3: Insertion Score 0.4802, Deletion Score 0.0595
- Best performance on MaxViT-T: Insertion Score 0.5744, Deletion Score 0.1015
- Optimal α range identified as 0.0-0.4 for high-frequency exploration

## Why This Works (Mechanism)

### Mechanism 1: Frequency-Separate Perturbation for Fine-Grained Attribution
Separating high- and low-frequency components during adversarial sample generation preserves fine-grained spatial information that improves attribution precision. The method uses FFT to decompose inputs, then applies a low-frequency mask (LfM) scaled by α and high-frequency mask (HfM) scaled by (1-α) independently, allowing differential noise injection per frequency band. The reconstruction via IFFT produces adversarial samples that probe both structural (low-freq) and edge/detail (high-freq) features.

### Mechanism 2: Transferable Adversarial Samples for Boundary Exploration
Adversarial samples that cross multiple decision boundaries provide more robust gradient estimates for attribution than single-boundary samples. By modulating frequency components with structured noise, generated adversarial samples generalize across decision boundaries. Gradients are aggregated over N perturbed samples and integrated along a non-linear path, capturing boundary behavior more comprehensively than straight-line integration.

### Mechanism 3: Energy-Based Adaptive Cutoff Frequency
Automatically determining the low/high frequency cutoff via spectral energy distribution (rather than a fixed hyperparameter) adapts to image complexity and improves attribution consistency. The cutoff cf is set to the minimum radius where cumulative spectral energy reaches τ=0.9 (90%) of total energy. Images with more high-frequency content (fine details) receive larger cutoff radii, preserving relevant features.

## Foundational Learning

- **Fourier Transform for Image Analysis**: FAMPE operates in the frequency domain; understanding how FFT decomposes images into low-freq (structure) and high-freq (edges) components is essential for interpreting α's effect. *Quick check: Given an image with strong vertical stripes, where would you expect energy to concentrate in its Fourier spectrum?*

- **Adversarial Sample Generation**: FAMPE builds on adversarial attacks to probe decision boundaries; understanding how perturbations affect model confidence clarifies why transferable samples improve attribution. *Quick check: Why might an adversarial sample generated for one model transfer to another model with different architecture?*

- **Attribution Evaluation Metrics (Insertion/Deletion Scores)**: The paper's claims rest on Insertion Score improvements; understanding what these metrics measure (and their limitations) is critical for assessing real-world utility. *Quick check: If a method achieves high Insertion but high Deletion, what might this indicate about the attribution map's quality?*

## Architecture Onboarding

- **Component map**: Input → FFT → Frequency Separation → α-Weighted Perturbation → IFFT → Model Forward Pass → Gradient Computation → Aggregation → Integration → Attribution Map
- **Critical path**: The frequency-aware perturbation generation is the core innovation, with α controlling the balance between structural preservation and fine-detail exploration
- **Design tradeoffs**:
  - α selection: Low α (0.0-0.4) emphasizes high-freq; improves fine detail but may amplify noise. High α (>0.9) preserves structure but loses granularity
  - N (sample count): Higher N stabilizes gradient estimates but increases compute. Paper uses N=20
  - τ (energy threshold): 0.9 works for natural images; may need tuning for specialized domains
- **Failure signatures**:
  - Blurry attribution maps: α too high (>0.8); low-freq noise dominates
  - Noisy/fragmented maps: α too low (<0.1) on images with weak high-freq content; cutoff may be inappropriate
  - Poor transfer across architectures: Adversarial samples not sufficiently transferable; consider increasing N or adjusting σ
- **First 3 experiments**:
  1. α sweep on held-out images: Run α ∈ {0.0, 0.1, ..., 1.0} on 50 diverse ImageNet samples; plot Insertion/Deletion curves to identify optimal α range for your target model
  2. Ablation on cutoff method: Compare energy-based cutoff (τ=0.9) vs. fixed cutoffs (e.g., cf=30, 50, 70) to validate adaptive cutoff benefit
  3. Cross-architecture transfer test: Generate adversarial samples on ResNet-50, compute attributions on MaxViT-T; assess whether transferability holds and attribution quality is maintained

## Open Questions the Paper Calls Out

### Open Question 1
Does the explicit separation of high- and low-frequency components universally improve the performance of attribution methods across diverse neural network architectures? The authors explicitly pose this as their first research question, but the varying optimal values for α and differing performance gains across the four tested architectures suggest the improvement may not be uniform across all network types.

### Open Question 2
What is the distinct role of high-versus low-frequency components in generating semantically meaningful attribution maps? The authors list this as their second research question. While results indicate high-frequency components (α < 0.4) correlate with higher Insertion Scores, the paper notes low-frequency components preserve "global structural information," leaving the exact interaction between structural preservation and attribution precision undefined.

### Open Question 3
Is the automated energy-based cutoff frequency (c_f) superior to fixed or learned frequency thresholds? The method fixes τ=0.9 to determine cutoff "to avoid imposing cf as a hyperparameter," but provides no validation that this specific energy percentage yields optimal boundaries for attribution tasks across diverse image types.

## Limitations
- The construction of Gaussian frequency masks (LfM and HfM) is not fully specified, creating a critical implementation gap
- The exact selection criteria for the 1000 ImageNet samples remains unclear, potentially affecting benchmark consistency
- The 90% energy threshold assumes natural image characteristics that may not generalize to specialized domains

## Confidence
- **High confidence**: The core attribution methodology using frequency-aware adversarial perturbations is well-founded and clearly articulated
- **Medium confidence**: The empirical results showing 13.02% improvement over AttEXplore are convincing, but the ablation study's conclusions need independent verification
- **Medium confidence**: The transferability mechanism's effectiveness across architectures is demonstrated but requires broader testing

## Next Checks
1. Implement and validate the Gaussian mask construction by comparing attribution quality across different mask parameterizations
2. Conduct ablation studies across diverse image domains (medical imaging, satellite imagery) to test the generalizability of the 90% energy threshold
3. Test attribution robustness under adversarial training scenarios where frequency components may be deliberately suppressed