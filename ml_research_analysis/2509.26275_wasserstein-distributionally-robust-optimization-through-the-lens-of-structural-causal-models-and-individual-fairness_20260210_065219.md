---
ver: rpa2
title: Wasserstein Distributionally Robust Optimization Through the Lens of Structural
  Causal Models and Individual Fairness
arxiv_id: '2509.26275'
source_url: https://arxiv.org/abs/2509.26275
tags:
- function
- sensitive
- have
- theorem
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Causally Fair Distributionally Robust Optimization
  (CDRO), which integrates causal structures and sensitive attributes into the DRO
  framework to address individual fairness. The authors define a Causally Fair Dissimilarity
  Function (CFDF) that incorporates counterfactuals and sensitive attribute perturbations,
  and prove a strong duality theorem for their causally fair DRO formulation.
---

# Wasserstein Distributionally Robust Optimization Through the Lens of Structural Causal Models and Individual Fairness

## Quick Facts
- arXiv ID: 2509.26275
- Source URL: https://arxiv.org/abs/2509.26275
- Reference count: 40
- Primary result: CDRO achieves lower unfair areas (0.01-0.02) and counterfactual unfairness (0-0.01) compared to baselines while maintaining competitive accuracy (~73-67%)

## Executive Summary
This paper introduces Causally Fair Distributionally Robust Optimization (CDRO), a framework that integrates causal structures and sensitive attributes into the DRO framework to address individual fairness. The authors define a Causally Fair Dissimilarity Function (CFDF) that incorporates counterfactuals and sensitive attribute perturbations, and prove a strong duality theorem for their causally fair DRO formulation. The method provides finite-sample guarantees when the SCM is unknown and demonstrates superior fairness performance on real and synthetic datasets while maintaining competitive accuracy.

## Method Summary
CDRO trains a classifier by minimizing a regularized empirical risk where the regularizer is derived from a duality theorem specific to the non-positive-definite CFDF. For linear SCMs, this regularizer has a closed-form expression involving the causal matrix and model weights. The method requires fitting a structural causal model to decompose features into sensitive and non-sensitive components, then computing counterfactuals to define the fair dissimilarity metric. Training uses standard optimizers (Adam) with the CDRO objective rather than the full min-max DRO.

## Key Results
- CDRO achieves Unfair Area (UAI) of 0.01-0.02 vs 0.02-0.04 for other methods
- Counterfactual Unfairness (CF) of 0-0.01 vs 0.04-0.19 for baselines
- Maintains competitive accuracy around 73-67%
- Finite-sample guarantees hold when SCM is unknown
- Strong duality theorem enables tractable optimization

## Why This Works (Mechanism)

### Mechanism 1: Causally Fair Dissimilarity via Semi-Latent Mapping
The method constructs a Causally Fair Dissimilarity Function (CFDF) that maps features to a semi-latent space using a bijective map g derived from the SCM's inverse. The distance is computed only on non-sensitive exogenous components U_X, ensuring counterfactual twins are treated as identical. This isolates intrinsic background factors from sensitive attributes. Break condition: If SCM is not an ANM, the map g cannot be uniquely defined.

### Mechanism 2: Tractable Regularization via Strong Duality
The paper transforms the intractable infinite-dimensional min-max DRO problem into a finite, tractable regularized empirical risk minimization problem using a Strong Duality Theorem. This converts the robustness requirement into an explicit regularization term added to the standard loss. Break condition: If the cost function doesn't satisfy lower semi-continuity, the regularizer wouldn't represent true worst-case loss.

### Mechanism 3: Linear SCM Closed-Form Regularizers
For linear causal structures, the DRO problem reduces to standard regression with a specific regularization term proportional to δ‖P_X(M^T θ)‖_*. This penalizes model weights that cause output variation when non-sensitive inputs are perturbed. Break condition: For non-linear SCMs, closed-form solutions are invalid and first-order approximations introduce O(δ²) errors.

## Foundational Learning

- **Concept: Structural Causal Models (SCMs) & Counterfactuals**
  - Why needed: The method relies on decomposing features into exogenous and endogenous parts to compute counterfactuals
  - Quick check: Can you explain the difference between an intervention (do-calculus) and a counterfactual in the context of an Additive Noise Model?

- **Concept: Wasserstein Distance & Optimal Transport**
  - Why needed: The ambiguity set B_δ(P) is defined as the ball of distributions within a certain Wasserstein distance from the empirical distribution
  - Quick check: If the Wasserstein distance between distribution P and Q is δ, what does that physically imply about the effort required to morph P into Q?

- **Concept: Convex Conjugates (Fenchel Dual)**
  - Why needed: The derivation of the duality theorem and closed-form regularizers relies on properties of convex conjugates
  - Quick check: In robust optimization, does the convex conjugate represent the worst-case penalty or the cost of the perturbation?

## Architecture Onboarding

- **Component map:** Data → Causal Inference Module → CFDF Generator → Optimizer
- **Critical path:** The Causal Inference Module is the critical dependency. If the causal structure M is estimated incorrectly, the CFDF will measure similarity in the wrong subspaces
- **Design tradeoffs:**
  - Known vs. Unknown SCM: Known allows closed-form regularizers (exact), unknown requires empirical estimation with sample error bounds
  - Linear vs. Non-Linear: Linear allows analytic regularizers, non-linear requires first-order approximations
- **Failure signatures:**
  - Infinite Risk: If sensitive attribute has infinite diameter and model weights don't satisfy P_A(M^T θ) = 0
  - Causal Misspecification: Wrong causal graph leads to fair metric enforcing similarity on wrong features
- **First 3 experiments:**
  1. Linear SCM Validation: Generate synthetic data using known Linear SCM to verify CDRO regularizer matches theoretical predictions
  2. Robustness vs. Fairness Trade-off: Sweep radius δ on real-world data to observe trade-off curve
  3. Ablation on Causal Estimation: Compare performance when true causal graph is provided vs. estimated from data

## Open Questions the Paper Calls Out
None

## Limitations
- Strong assumption of known or correctly specified causal structures, which rarely holds in practice
- Linear SCM requirement for closed-form solutions significantly restricts applicability to complex real-world scenarios
- Empirical validation relies heavily on synthetic data where ground truth SCM is known

## Confidence
- High confidence in theoretical framework and duality results (Thm 1-4)
- Medium confidence in practical utility given strong assumptions about SCM knowledge and linearity
- Low confidence in finite-sample guarantees without extensive validation on truly unknown SCMs

## Next Checks
1. Test CDRO on real-world datasets where SCM must be estimated from data, comparing performance against ground truth known SCM cases
2. Evaluate CDRO performance on non-linear SCMs using first-order approximations to assess approximation error bounds
3. Conduct sensitivity analysis on the choice of Wasserstein radius δ to quantify the robustness-fairness trade-off across different problem domains