---
ver: rpa2
title: 'H-SPLID: HSIC-based Saliency Preserving Latent Information Decomposition'
arxiv_id: '2510.20627'
source_url: https://arxiv.org/abs/2510.20627
tags:
- salient
- h-splid
- should
- hsic
- space
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: H-SPLID is a novel algorithm for learning salient feature representations
  by decomposing the latent space into task-relevant and task-irrelevant subspaces.
  The method combines dimensionality reduction of the salient space with HSIC-based
  regularization to promote learning low-dimensional, task-relevant features.
---

# H-SPLID: HSIC-based Saliency Preserving Latent Information Decomposition

## Quick Facts
- **arXiv ID:** 2510.20627
- **Source URL:** https://arxiv.org/abs/2510.20627
- **Reference count:** 40
- **Primary result:** H-SPLID achieves 58.9% robust accuracy under PGD attack on COCO vs 34.2% for vanilla network

## Executive Summary
H-SPLID introduces a novel algorithm for learning robust feature representations by decomposing the latent space into task-relevant (salient) and task-irrelevant (non-salient) subspaces. The method uses a learnable binary mask to select which latent dimensions contribute to classification, combined with HSIC-based regularization to promote low-dimensional, task-relevant features. Theoretical analysis proves that expected prediction deviation under input perturbations is bounded by the salient subspace dimension and HSIC between inputs and representations. Empirical evaluations demonstrate improved robustness to attacks targeting non-salient features like image backgrounds.

## Method Summary
H-SPLID decomposes latent representations into salient and non-salient subspaces using a learnable diagonal mask. The salient subspace zs = Ms·z is used for classification, while the non-salient subspace zn = Mn·z is regularized away. The loss function combines cross-entropy on the salient space with masked clustering losses (Ls for class-specific clustering in salient space, Ln for global alignment in non-salient space) and HSIC regularization terms. Training alternates between updating encoder weights with fixed masks and updating masks using closed-form solutions based on dataset statistics. The method provably bounds prediction deviation under input perturbations by the salient dimension and HSIC terms.

## Key Results
- On COCO dataset, H-SPLID achieves 58.9% accuracy under PGD attack vs 34.2% for vanilla network
- On ImageNet-9, H-SPLID achieves 76.7% accuracy, outperforming vanilla baseline by 2.7%
- Ablation studies show HSIC regularization alone improves background attack robustness from 33.75% to 42.71%

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Decomposing latent space into salient and non-salient subspaces improves robustness to perturbations on task-irrelevant input regions.
- **Mechanism:** Binary mask Ms selects salient dimensions zs = Ms·z for classification. Theorem 3.2 proves expected output deviation is upper-bounded by salient dimension s and HSIC(X, Zs).
- **Core assumption:** Task-relevant and task-irrelevant information are separable in latent space given sufficient data diversity.
- **Evidence anchors:** [abstract] bound on prediction deviation; [Section 3.5, Theorem 3.2] formal bound; [corpus] no direct validation for this decomposition mechanism.
- **Break condition:** If salient features always co-occur with specific contexts, decomposition fails without external knowledge.

### Mechanism 2
- **Claim:** Masked clustering losses enforce geometric structure in the salient/non-salient split.
- **Mechanism:** Ls clusters class-specific representations in salient subspace; Ln aligns non-salient features globally across samples. This pushes discriminative information to zs and shared variability to zn.
- **Core assumption:** Each class follows unimodal distribution in salient subspace; redundant variation distributes uniformly.
- **Evidence anchors:** [Section 3.3] loss formulation; [Table 5] ablation shows Ls+Ln improves robustness to 43.69%; [corpus] not externally validated.
- **Break condition:** Multi-modal class distributions may not cluster cleanly in low-dimensional salient space.

### Mechanism 3
- **Claim:** HSIC regularization minimizes redundant information in salient subspace and prevents label leakage to non-salient subspace.
- **Mechanism:** ρs·HSIC(X, Zs) reduces statistical dependence between inputs and salient representations; ρn·HSIC(Y, Zn) removes label information from non-salient representations. Corollary 3.3 bounds vulnerable input region volume.
- **Core assumption:** Universal kernels approximate function spaces; inputs are bounded (truncated MVN distribution).
- **Evidence anchors:** [Section 3.3] HSIC regularization purpose; [Table 5] HSIC terms improve robustness to 42.71%; [corpus] HSIC bottleneck and HBaR provide precedent.
- **Break condition:** Excessive HSIC penalties (ρn > 0.5) can collapse salient space to zero dimensions.

## Foundational Learning

- **Concept: Hilbert-Schmidt Independence Criterion (HSIC)**
  - Why needed here: Core regularization tool measuring statistical dependence via kernel embeddings in RKHS.
  - Quick check question: Can you explain why minimizing HSIC(X, Zs) reduces redundant information while preserving task-relevant features?

- **Concept: Alternating Optimization**
  - Why needed here: Algorithm alternates between updating encoder weights with fixed mask and updating mask with fixed representations.
  - Quick check question: Why does mask update require computing means over full dataset while θ update uses minibatches?

- **Concept: Masked Classification with Cross-Entropy**
  - Why needed here: Only salient dimensions contribute to logits; non-salient dimensions are explicitly excluded from prediction.
  - Quick check question: If Ms selects 14 of 512 dimensions, how does linear layer W map masked representation to k-class logits?

## Architecture Onboarding

- **Component map:** Input X → Encoder fψ → Latent Z → Ms → Salient Zs → Linear layer W → Logits; Mn = I - Ms → Non-salient Zn

- **Critical path:**
  1. Pretrain encoder with standard cross-entropy (100 epochs for COCO)
  2. Initialize Ms = I (all dimensions salient)
  3. Alternate: (a) SGD on θ using Eq. 5 loss with fixed Ms; (b) Closed-form mask update via Eq. 7 using dataset-wide means
  4. Apply moving average (βstep) to mask updates for stability
  5. Threshold β at 0.5 post-training for binary mask

- **Design tradeoffs:**
  - Salient dimension s vs. expressiveness: Lower s improves robustness but risks underfitting (Table 17 shows s=14 optimal for COCO)
  - λn vs. clean accuracy: High λn (0.5+) compresses salient space aggressively but can collapse to s=0
  - Learning rate: LR=5e-4 optimal; 10x higher collapses, 10x lower produces diffuse representations

- **Failure signatures:**
  - Clean accuracy ≈ random (32.74%) + s=0: Over-regularization (ρn too high)
  - High clean accuracy but poor robustness: Mask not learning (βstep too close to 1.0)
  - Salient space accuracy ≈ non-salient space accuracy: Decomposition failed; check data diversity

- **First 3 experiments:**
  1. **C-MNIST diagnostic:** Train to classify left digit; attack right digit with PGD (ε=1.0). Verify salient subspace maintains >85% accuracy while non-salient drops to <10%.
  2. **Mask dimension sweep:** Vary λn ∈ {0.01, 0.1, 0.2, 0.5} on COCO subset; plot s vs. robust accuracy to find Pareto frontier.
  3. **Ablation of loss terms:** Compare Lce alone, Lce+Ls+Ln, Lce+HSIC, and full objective on background-targeted attacks to isolate each component's contribution.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does combining H-SPLID with self-supervised learning architectures (e.g., I-JEPA) improve generalization of learned salient features to downstream tasks?
- Basis in paper: [explicit] Authors plan to "combine H-SPLID with self-supervised models such as I-JEPA... with the goal of learning features that generalize better to downstream tasks."
- Why unresolved: Current work focuses exclusively on supervised image classification; interaction between H-SPLID's subspace decomposition and self-supervised representation learning objectives is unexplored.
- What evidence would resolve it: Empirical evaluations of transfer learning performance on diverse downstream datasets after pre-training with hybrid SSL + H-SPLID objective.

### Open Question 2
- Question: Can H-SPLID be adapted to effectively separate salient and non-salient features in non-image modalities, such as text or graphs?
- Basis in paper: [explicit] Limitations section notes analysis restricted to image data; "Investigating whether similar decompositions apply to other data modalities remains an exciting direction for future work."
- Why unresolved: Concept of "salient regions" is intuitive for images but less defined for sequential or structural data; current HSIC/masking formulation may require architectural adjustments.
- What evidence would resolve it: Successful application to text classification or graph node classification tasks, demonstrating robustness to perturbations in non-salient text features or graph neighborhoods.

### Open Question 3
- Question: How robust is the decomposition when class-specific features are perfectly correlated with a specific context (e.g., object and background always co-occur)?
- Basis in paper: [explicit] Limitations section states that if "a particular feature always co-occurs with the same context, H-SPLID cannot separate salient from non-salient information, since both appear inseparably."
- Why unresolved: Method relies on variance of contexts across classes to isolate task-relevant features; currently lacks mechanism to decouple features in presence of perfect spurious correlation without external supervision.
- What evidence would resolve it: Extension utilizing auxiliary data or causal intervention techniques to successfully decompose features on dataset with strong, invariant spurious correlations.

### Open Question 4
- Question: How does the theoretical robustness bound in Theorem 3.2 degrade when input data distributions deviate from assumed Truncated Multivariate Normal (tMVN)?
- Basis in paper: [inferred] Proof for Theorem 3.2 relies on assumption that inputs follow tMVN distribution, a simplified mathematical model that doesn't accurately reflect complex, manifold-structured distributions of natural images.
- Why unresolved: While bound guarantees robustness under tMVN assumption, "tightness" or magnitude of error term when applied to real-world image distributions is not quantified theoretically.
- What evidence would resolve it: Theoretical analysis or empirical simulation measuring gap between predicted HSIC-based bound and actual prediction deviation on data distributions violating tMVN assumption.

## Limitations

- The decomposition mechanism assumes task-relevant and task-irrelevant information are separable in latent space, but this may fail when salient features always co-occur with specific contexts
- HSIC regularization effectiveness depends on universal kernel assumptions and bounded input distributions that may not hold for real-world image data
- Alternating optimization approach requires full-dataset statistics for mask updates, creating computational bottlenecks for large-scale applications

## Confidence

- **High confidence:** The theoretical bound proving prediction deviation scales with salient dimension and HSIC (Theorem 3.2) is mathematically rigorous and well-supported
- **Medium confidence:** Empirical results showing improved robustness on COCO and ImageNet-9 are demonstrated, but mechanism's generality across diverse datasets needs further validation
- **Low confidence:** Assumption that all classes follow unimodal distributions in salient subspace is stated but not thoroughly tested, particularly for multi-modal class distributions

## Next Checks

1. **C-MNIST diagnostic test:** Train on left-digit classification, attack right-digit region with PGD (ε=1.0). Verify salient subspace maintains >85% accuracy while non-salient drops to <10%.
2. **Mask dimension sweep:** Systematically vary λn on COCO subset; plot salient dimension vs. robust accuracy to identify optimal tradeoff point.
3. **Multi-modal class distribution test:** Evaluate H-SPLID on datasets with known multi-modal class distributions to assess clustering loss effectiveness under non-unimodal conditions.