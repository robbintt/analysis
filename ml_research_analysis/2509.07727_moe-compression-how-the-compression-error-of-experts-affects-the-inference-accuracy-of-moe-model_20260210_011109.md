---
ver: rpa2
title: 'MoE-Compression: How the Compression Error of Experts Affects the Inference
  Accuracy of MoE Model?'
arxiv_id: '2509.07727'
source_url: https://arxiv.org/abs/2509.07727
tags:
- layer
- experts
- expert
- errors
- inference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores how compression errors in different expert
  layers of a Mixture-of-Experts (MoE) model affect inference accuracy. The authors
  introduce error-bounded lossy compression algorithms (SZ3 and CuSZp) to compress
  non-activated experts, reducing data transfer overhead during MoE inference under
  GPU memory constraints.
---

# MoE-Compression: How the Compression Error of Experts Affects the Inference Accuracy of MoE Model?

## Quick Facts
- **arXiv ID**: 2509.07727
- **Source URL**: https://arxiv.org/abs/2509.07727
- **Authors**: Songkai Ma; Zhaorui Zhang; Sheng Di; Benben Liu; Xiaoyi Lu; Dan Wang
- **Reference count**: 40
- **Key outcome**: Error-bounded lossy compression of non-activated MoE experts reduces transfer overhead with minimal accuracy loss in shallow layers, but middle layers are highly sensitive while deep layers can tolerate or sometimes benefit from bounded errors.

## Executive Summary
This paper investigates how compression errors in different expert layers of a Mixture-of-Experts (MoE) model affect inference accuracy. The authors introduce error-bounded lossy compression algorithms (SZ3 and CuSZp) to compress non-activated experts, reducing data transfer overhead during MoE inference under GPU memory constraints. Through extensive experiments on the Moonlight model using GSM8K and Math datasets, they analyze the impact of compression errors across different expert layers. Results show that shallow-layer experts (handling attention and token transformation) tolerate bounded errors with minimal accuracy loss, while middle-layer experts (responsible for core reasoning) suffer significant accuracy degradation when errors are introduced. Interestingly, bounded errors in deep-layer experts (handling instruction following and output integration) can sometimes improve inference accuracy.

## Method Summary
The paper simulates compression errors by injecting zero-mean Gaussian noise ($\mathcal{N}(0, \hat{e})$) into expert weights during inference, where $\hat{e}$ is calculated as a percentage of the expert's average L1 norm. Experiments are conducted on the Moonlight model (16B, 26 layers, 64 experts/layer, top-6 routing) using GSM8K and MATH datasets. Two metrics are used: Instruction Compliance Accuracy (ICA) measuring format+content correctness, and Pure Inference Accuracy (PIA) measuring content only. The study tests single-expert, top-k, and full-layer perturbations to map error sensitivity across the network depth.

## Key Results
- Shallow-layer experts exhibit minimal degradation when subjected to bounded errors due to their role in token transformation rather than core logic
- Middle-layer experts show significant accuracy impairment from compression errors as they are central to model reasoning
- Bounded errors in deep-layer experts can sometimes lead to improvements in inference accuracy, likely due to implicit model integration effects

## Why This Works (Mechanism)

### Mechanism 1: Shallow-Layer Attention Tolerance
- Claim: Introducing bounded compression errors into shallow-layer experts minimally degrades inference accuracy because these layers primarily handle token transformation rather than core logic.
- Mechanism: Shallow experts project input tokens into vector representations. The paper suggests that small perturbations in these projections do not destroy the semantic information required by subsequent layers, as the routing mechanism and deeper layers can operate effectively on "good enough" representations.
- Core assumption: The error distribution follows a zero-mean normal distribution ($N \sim (0, \hat{e})$), allowing positive and negative errors to cancel out rather than biasing the representation systematically.
- Evidence anchors:
  - [abstract]: "experts in the shallow layers... exhibit minimal degradation in inference accuracy when subjected to bounded errors."
  - [section 3.2.1]: "introducing errors to expert 0 in the first layer does not affect the model's inference accuracy... demonstrating the model's robustness to minor weight fluctuations."
  - [corpus]: Related works like *PuzzleMoE* and *EdgeMoE* focus on general efficiency but do not specifically validate the tolerance of attention-specific layers to lossy error, making this paper's layer-specific finding distinct.
- Break condition: If errors become unbounded or weights are fully randomized (destroying semantic structure), the model fails to attend to relevant tokens, degrading performance.

### Mechanism 2: Middle-Layer Reasoning Sensitivity
- Claim: Compression errors in middle-layer experts cause disproportionate accuracy loss because these layers are responsible for the core logical reasoning of the model.
- Mechanism: The middle layers act as the processing bottleneck where information is integrated and logical steps are computed. Introducing noise here disrupts the signal-to-noise ratio required for precise deduction, leading to "nonlinear amplification" of errors.
- Core assumption: Reasoning tasks (like those in GSM8K/Math) rely heavily on precise intermediate states found in the central network layers.
- Evidence anchors:
  - [abstract]: "errors in the middle-layer experts, which are central to model reasoning, significantly impair inference accuracy."
  - [section 3.4]: "layer 13... resulted in the lowest inference accuracy... middle layers play a critical role in problem analysis and reasoning."
  - [corpus]: *REAP the Experts* notes expert importance varies, but this paper localizes the specific vulnerability to the middle network depth for reasoning tasks.
- Break condition: Aggressive compression (e.g., 80% error bound) on high-frequency experts in middle layers causes the model to cease generating valid outputs entirely (Table 7).

### Mechanism 3: Deep-Layer Implicit Ensembling
- Claim: Bounded errors in deep-layer experts can improve inference accuracy by inducing an implicit ensemble effect or regularization during output integration.
- Mechanism: Deep layers handle instruction following and final output projection. Bounded noise may create slight variations in output logits, effectively smoothing the decision boundary or helping the model escape local optima (similar to dropout or noise injection during training).
- Core assumption: The redundancy in deep experts allows for error tolerance, and the "compensation" mechanism is robust enough to turn noise into a feature rather than a bug.
- Evidence anchors:
  - [abstract]: "introducing bounded errors in the deep-layer experts... can sometimes lead to improvements in inference accuracy."
  - [section 3.2.3]: "introducing errors into deeper layers (e.g., layer 20 and layer 26) leads to performance gains... likely due to implicit model integration effects."
  - [corpus]: This specific "accuracy gain from noise" phenomenon is not a standard claim in the general MoE compression literature (e.g., *MoBE*, *Sub-MoE*), which typically focuses on lossless or near-lossless retention.
- Break condition: If the noise breaks the instruction-following structure (formatting), Instruction Compliance Accuracy (ICA) may drop even if reasoning (PIA) is preserved.

## Foundational Learning

- **Concept: Top-k Gating/Router**
  - Why needed here: The compression strategy applies only to *non-activated* experts. You must understand that the router selects only a subset (e.g., 6 out of 64) of experts per token to grasp why we can compress the others aggressively.
  - Quick check question: If a router selects top-6 experts, what happens to the gradients or inference path of the remaining 58 experts during a specific forward pass?

- **Concept: Error-Bounded Lossy Compression (SZ3/CuSZp)**
  - Why needed here: Unlike quantization which reduces precision globally, this method guarantees the reconstruction error stays within a strict bound ($\hat{e}$). This is the mathematical constraint that prevents the "Break conditions" mentioned above.
  - Quick check question: How does guaranteeing an absolute error bound (e.g., $|x - \hat{x}| < 0.001$) differ from guaranteeing a specific compression ratio (e.g., 4x) in terms of risk to model accuracy?

- **Concept: Instruction Compliance vs. Pure Reasoning**
  - Why needed here: The paper distinguishes between getting the right answer (PIA) and formatting it correctly (ICA). Compression affects these differently (e.g., deep layers handle formatting).
  - Quick check question: If a model solves "2+2=4" but outputs "four" instead of the requested XML tag `<a>4</a>`, which metric fails?

## Architecture Onboarding

- **Component map**: GPU Memory (Resident Store) -> PCIe Bus -> Main Memory (Staging Buffer) -> Compressor/Decompressor (SZ3/CuSZp)
- **Critical path**:
  1. Input token enters GPU.
  2. Router calculates top-k indices.
  3. System checks if required experts are in GPU Resident Store.
  4. **If miss**: Fetch compressed block from Host Memory -> Transfer via PCIe -> Decompress to GPU -> Compute.
  5. **If hit**: Compute immediately.
- **Design tradeoffs**:
  - **Bandwidth vs. Compute**: Aggressive compression saves PCIe bandwidth (transfer time) but increases GPU compute overhead (decompression) and risks accuracy.
  - **Layer Protection**: Protecting middle layers requires higher precision (lower compression), reducing overall space savings.
- **Failure signatures**:
  - **Silent Reasoning Failure**: Model outputs text but logic is flawed (Middle layer error).
  - **Instruction Misalignment**: Model solves problem but ignores formatting constraints (Deep layer error).
  - **Cascading Collapse**: Model outputs garbage or EOS tokens immediately (High error on frequently activated experts).
- **First 3 experiments**:
  1. **Single Expert Sensitivity**: Select the most frequently activated expert in the middle layer (e.g., Layer 13). Inject noise with bound $\hat{e}$ and observe the drop in Pure Inference Accuracy (PIA) vs ICA.
  2. **Layer-wise Robustness Check**: Apply a fixed error bound (e.g., 50% norm) to *all* experts in Layer 1, then Layer 13, then Layer 26. Compare the accuracy deltas to verify the "U-shaped" robustness curve (Shallow robust, Middle sensitive, Deep redundant).
  3. **Bandwidth-Error Threshold**: Measure actual PCIe transfer time reduction when compressing experts to 30%, 50%, and 80% error bounds. Plot this against the accuracy drop to find the "Pareto frontier" for efficient offloading.

## Open Questions the Paper Calls Out
- The paper identifies the need for pipeline algorithms that can overlap compression and decompression operations with offloading tasks as a future research direction.

## Limitations
- Findings are derived from a single MoE model (Moonlight) with specific hyperparameters and may not generalize to other architectures.
- The zero-mean Gaussian noise model used for compression error simulation may not accurately represent real error-bounded compressor error distributions.
- Experiments are limited to mathematical reasoning tasks, restricting validation of the error sensitivity hierarchies across different domains.

## Confidence
- **High Confidence**: The empirical finding that shallow-layer experts tolerate noise with minimal accuracy loss is well-supported by ablation studies across multiple layers and error bounds.
- **Medium Confidence**: The claim that middle-layer experts are the critical reasoning bottleneck is supported by data but may be model-specific.
- **Low Confidence**: The claim that deep-layer errors can *improve* accuracy is the weakest, as the paper provides no formal mechanism for why noise would systematically improve instruction following.

## Next Checks
1. **Cross-Model Validation**: Replicate the layer-wise sensitivity analysis on a different MoE architecture (e.g., Mixtral-8x7B or DeepSeekMoE) with different routing (top-2 vs top-6) and expert counts. Verify if the "U-shaped" robustness curve persists or shifts.

2. **Real Compressor Error Distribution**: Replace the Gaussian noise model with actual SZ3/CuSZp error distributions generated from compressing real expert weight matrices. Measure if the accuracy trends (especially the deep-layer "improvement") hold under realistic error patterns.

3. **Fine-tuning with Errors**: Fine-tune the Moonlight model on GSM8K/MATH while injecting bounded errors into specific expert layers during training. Assess if the model learns to be robust to these errors, potentially flattening the sensitivity curve and reducing the middle-layer vulnerability.