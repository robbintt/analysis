---
ver: rpa2
title: Do Psychometric Tests Work for Large Language Models? Evaluation of Tests on
  Sexism, Racism, and Morality
arxiv_id: '2510.11254'
source_url: https://arxiv.org/abs/2510.11254
tags:
- llms
- tests
- test
- answer
- psychometric
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'Psychometric tests from psychology are increasingly applied to
  evaluate LLMs, but it remains unclear if they yield meaningful results when applied
  to LLMs. This study systematically evaluates reliability and validity of human psychometric
  tests on 17 LLMs for three constructs: sexism, racism, and morality.'
---

# Do Psychometric Tests Work for Large Language Models? Evaluation of Tests on Sexism, Racism, and Morality

## Quick Facts
- arXiv ID: 2510.11254
- Source URL: https://arxiv.org/abs/2510.11254
- Authors: Jana Jung; Marlene Lutz; Indira Sen; Markus Strohmaier
- Reference count: 40
- Primary result: Psychometric tests show moderate reliability but low ecological validity when applied to LLMs

## Executive Summary
This study systematically evaluates whether human psychometric tests can reliably and validly measure constructs like sexism, racism, and morality in large language models (LLMs). The research finds that while psychometric tests demonstrate moderate reliability across multiple item and prompt variations when applied to 17 different LLMs, they fail to align with actual model behavior in downstream tasks. This disconnect between test scores and real-world behavior raises serious concerns about the ecological validity of using traditional psychometric assessments for LLM evaluation. The findings suggest that current psychometric tests may not be measuring what they purport to measure in LLMs, highlighting the need for LLM-specific evaluation methodologies.

## Method Summary
The study evaluates 17 different LLMs using established psychometric tests designed to measure sexism, racism, and morality constructs. The evaluation examines both reliability (consistency across multiple item and prompt variations) and validity (whether test scores correspond to actual model behavior). Reliability is assessed through repeated testing with variations in test items and prompting strategies. Validity is evaluated through convergent approaches (comparing scores across related constructs) and ecological approaches (examining whether test scores predict actual model behavior in downstream tasks). The study specifically investigates whether psychometric test scores correlate with behavioral measures in practical applications.

## Key Results
- Psychometric tests demonstrate moderate reliability across multiple item and prompt variations when applied to LLMs
- Test scores show poor alignment with model behavior in downstream tasks, with some negative correlations observed
- Current psychometric tests lack ecological validity for LLM evaluation, failing to predict real-world model performance
- The study reveals a fundamental disconnect between traditional psychometric assessment and LLM behavior measurement

## Why This Works (Mechanism)
The moderate reliability findings suggest that psychometric tests produce consistent results across variations in items and prompts when applied to LLMs. However, the mechanism behind psychometric testing in human psychology may not translate to artificial systems. Human psychometric tests are designed to measure stable psychological traits and tendencies in humans, but LLMs operate through different mechanisms - they are pattern-matching systems trained on human-generated text rather than entities with psychological states. The failure of ecological validity indicates that the constructs these tests measure (like implicit bias or moral reasoning) may not be meaningfully applicable to LLMs, or that the tests are measuring different aspects than intended when applied to artificial systems.

## Foundational Learning
- **Psychometric Test Reliability**: Consistency of measurement across different items and prompts - needed to establish whether tests produce stable results when applied to LLMs; quick check: test-retest correlation across variations
- **Convergent Validity**: Whether related constructs produce similar scores - needed to assess if tests measure what they claim in LLMs; quick check: correlation between conceptually related test scores
- **Ecological Validity**: Whether test results predict real-world behavior - critical for determining practical utility of LLM evaluations; quick check: correlation between test scores and behavioral task performance
- **Downstream Task Behavior**: Actual model performance in practical applications - provides ground truth for validating psychometric assessments; quick check: task-specific behavioral metrics
- **Construct Validity**: Whether tests actually measure the intended psychological constructs - fundamental question when applying human tests to artificial systems; quick check: alignment between test scores and theoretical predictions
- **LLM Architecture Differences**: Understanding that LLMs are pattern-matching systems rather than psychological entities - essential context for interpreting test results; quick check: architectural analysis of tested models

## Architecture Onboarding
The study examines 17 diverse LLMs with varying architectures, sizes, and training approaches. The component map follows: **Psychometric Test Administration -> Response Generation -> Score Calculation -> Behavioral Task Execution -> Correlation Analysis**. The critical path involves administering psychometric tests, collecting model responses, calculating scores, then measuring actual behavior in downstream tasks and analyzing correlations. Design tradeoffs include balancing test comprehensiveness against computational costs and choosing appropriate behavioral tasks that represent real-world usage. Failure signatures include inconsistent test scores across variations (reliability issues) and negative correlations between test scores and behavioral measures (validity issues). Three first experiments would be: 1) Administer sexism test with 5 different prompt variations to a single LLM; 2) Compare psychometric scores with actual bias in generated text across multiple models; 3) Test correlation between morality test scores and behavior in ethical dilemma scenarios.

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Only three constructs (sexism, racism, morality) were evaluated, limiting generalizability to other psychometric domains
- Ecological validity assessment relies on specific downstream tasks that may not capture the full range of real-world applications
- The 17 models tested, while diverse, may not represent the complete spectrum of LLM architectures and training approaches
- The study does not address potential cultural or linguistic variations in psychometric test results across different contexts

## Confidence
High confidence in moderate reliability findings across multiple item and prompt variations. Medium confidence in validity conclusions, particularly ecological validity assessment. The negative correlations between test scores and behavioral measures are concerning but require further investigation across broader contexts.

## Next Checks
1. Test psychometric evaluations across a broader range of constructs beyond the three examined (sexism, racism, morality) to assess generalizability
2. Develop and validate task-specific behavioral measures that better capture real-world model usage scenarios
3. Conduct cross-cultural and multilingual evaluations to determine if psychometric test results vary across different linguistic and cultural contexts when applied to LLMs