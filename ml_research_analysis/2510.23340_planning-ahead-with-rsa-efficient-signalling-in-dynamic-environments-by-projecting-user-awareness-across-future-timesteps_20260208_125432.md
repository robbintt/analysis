---
ver: rpa2
title: 'Planning Ahead with RSA: Efficient Signalling in Dynamic Environments by Projecting
  User Awareness across Future Timesteps'
arxiv_id: '2510.23340'
source_url: https://arxiv.org/abs/2510.23340
tags:
- planning
- user
- critical
- properties
- d-rsa
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a framework that extends the Rational Speech
  Act (RSA) model with finite-horizon lookahead planning for adaptive communication
  in dynamic environments. By projecting how user beliefs evolve over multiple timesteps,
  the system generates sequences of alerts that optimize situational awareness while
  accounting for human attention as a limited resource.
---

# Planning Ahead with RSA: Efficient Signalling in Dynamic Environments by Projecting User Awareness across Future Timesteps

## Quick Facts
- **arXiv ID**: 2510.23340
- **Source URL**: https://arxiv.org/abs/2510.23340
- **Reference count**: 40
- **Key outcome**: Introduces a framework extending RSA with finite-horizon lookahead planning for adaptive communication in dynamic environments, showing improved situational awareness through projected user belief modeling.

## Executive Summary
This paper presents a framework that extends the Rational Speech Act (RSA) model with finite-horizon lookahead planning to optimize alert sequences in dynamic environments. By projecting how user beliefs evolve over multiple timesteps, the system generates messages that balance specificity and timing to maintain situational awareness while accounting for human attention as a limited resource. The approach models both the evolving state of the world and the user's prior knowledge, adapting message content and timing accordingly. Experiments in a simulated drone-monitoring task demonstrate that combining multi-step planning with user-specific belief modeling yields higher communication effectiveness than baseline methods.

## Method Summary
The method extends RSA with finite-horizon planning by maintaining a dynamic belief distribution of user knowledge and projecting it forward in time. A planner enumerates utterance sequences up to a fixed horizon, optimizing cumulative reward by balancing message specificity against temporal blocking constraints. The system uses a lexicon mapping utterances to properties with duration costs, and selects sequences that maximize belief alignment on critical properties while respecting attention constraints. Implemented in Python 3.9.21, the approach was tested across 800 simulated drone monitoring scenarios comparing four model variants.

## Key Results
- Combining multi-step planning with user-specific belief modeling outperforms baseline methods in simulated drone monitoring tasks
- The framework effectively balances message specificity against timing constraints to optimize situational awareness
- Benefits are largest in high-difficulty scenarios with critical properties emerging closer in time
- User-specific prior modeling reduces unnecessary message length when users already possess relevant knowledge

## Why This Works (Mechanism)

### Mechanism 1: Recursive Bayesian Belief Projection
If the system models the user's estimated prior beliefs, it can safely use shorter, less specific utterances for known concepts, reserving bandwidth for unknown risks. The agent maintains a dynamic distribution of the user's beliefs and conditions a Pragmatic Listener on these priors. If prior expectations indicate high awareness of a property, the system infers that a low-specificity signal will be correctly resolved, avoiding the time cost of detailed messages.

### Mechanism 2: Finite-Horizon Opportunistic Scheduling
Optimizing message sequences over a fixed horizon improves reward accumulation by identifying temporal gaps for long messages that greedy, single-step agents would miss. A planner enumerates utterance sequences up to horizon H, enforcing duration constraints where long messages block subsequent alerts. By maximizing cumulative reward rather than immediate reward, the agent may choose to wait or use a brief alert now to keep the channel open for a critical, specific alert later.

### Mechanism 3: Utility-Weighted Criticality Filtering
If the system rewards belief alignment only on critical properties, it filters low-value noise and focuses communication bandwidth on high-stakes information. The reward function scales the utility of an utterance by the criticality of the property it addresses, driving the Pragmatic Speaker to prioritize messages that shift belief distributions for at-risk variables while ignoring non-critical state changes.

## Foundational Learning

- **Rational Speech Acts (RSA) Framework**: This is the core reasoning engine. You must understand the recursive hierarchy (S₀ → L₁ → S₂) to grasp how the system models the user interpreting a message. *Quick check: Can you explain why a Pragmatic Speaker (S₂) chooses a costly message only when a Literal Listener (L₁) would otherwise misinterpret the state?*

- **Bayesian Belief Update**: The system relies on "today's posterior being tomorrow's prior" to track user knowledge over time. *Quick check: If a user ignores an alert (attention → 0), how does Eq. 4 predict their belief will evolve compared to the previous belief?*

- **Discrete Planning / Search**: The "Planning" component uses Breadth-First Search over sequences. Understanding tree pruning and duration constraints is key to optimizing performance. *Quick check: In a horizon of 7 timesteps, why is a 3-timestep message risky if a critical event is predicted at timestep 4?*

## Architecture Onboarding

- **Component map**: State Monitor -> User Model -> Planner -> Lexicon -> Message Output
- **Critical path**: Belief Projection. The system cannot select an optimal utterance without first simulating how the current belief will shift. If the User Model is inaccurate, the Planner selects sub-optimal sequences.
- **Design tradeoffs**:
  - **Specificity vs. Latency**: High-specificity messages have high duration (blocking). The system trades detail for speed when time is scarce.
  - **Horizon Length**: Longer horizons improve optimality but cause compute complexity to explode (exponentially more sequences to search).
- **Failure signatures**:
  - **The "Silence" Trap**: The agent selects `...` (silence) too often if the criticality reward is under-weighted relative to the cost/effort of speaking.
  - **Alert Avalanche**: The agent fires multiple specific alerts simultaneously because the Planner failed to account for the user's cognitive saturation (modeled here as temporal blocking).
- **First 3 experiments**:
  1. **Sanity Check - Static User**: Run a trial with a "perfect" user (priors = truth). Verify the system sends almost zero messages or only minimal "beeps" to maintain sync.
  2. **Stress Test - Temporal Clustering**: Force 4 critical events to occur at t=2. Compare baseline vs. Full Model to verify that the planner staggers alerts rather than blocking the channel.
  3. **Ablation - User Priors**: Run the system with "Uniform Priors" vs. "Specific Priors." Verify that message length decreases when the model knows the user is already aware.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Can hybrid approaches combining RSA with neural generative models successfully reduce the reliance on hand-crafted lexicons while maintaining pragmatic consistency?
- **Basis in paper**: The authors state that "this points toward hybrid approaches – combining RSA's principled reasoning with the generative flexibility of neural models."
- **Why unresolved**: Neural models often produce verbose outputs that violate pragmatic preferences, whereas the current d-RSA framework relies on manually defined lexicons.
- **What evidence would resolve it**: Experiments comparing a neural-RSA hybrid against the symbolic model in the drone-monitoring task, measuring adherence to Gricean maxims.

### Open Question 2
- **Question**: How can finite-horizon planning be effectively adapted for environments where future world states and user awareness are uncertain or partially observable?
- **Basis in paper**: The authors note that "future work should relax our model's assumptions of perfect knowledge of user awareness and future world states."
- **Why unresolved**: The current implementation assumes the agent has perfect foresight of the planning horizon, which is an idealization not present in real-world operations.
- **What evidence would resolve it**: Implementation of approximate planning methods (e.g., Monte Carlo Tree Search) showing robust performance in stochastic environments.

### Open Question 3
- **Question**: Does incorporating real-time behavioral monitoring (e.g., eye-tracking) to model dynamic user attention significantly improve adaptation over static belief estimates?
- **Basis in paper**: The paper suggests extending the "static knowledge model... by incorporating dynamic user attention models, enabling real-time adaptation through behavioural monitoring."
- **Why unresolved**: The current study simulates user beliefs rather than capturing them from live human behavioral data.
- **What evidence would resolve it**: User studies demonstrating that agents utilizing gaze data for belief updates achieve higher situational awareness scores than those relying on simulated priors.

## Limitations

- The framework's performance heavily depends on accurate user modeling and prior knowledge estimation, which may not generalize across diverse user populations
- Claims about scalability to real-world dynamic environments are speculative, with no validation in scenarios where critical events cluster more densely than the planning horizon allows
- The lexicon design choices (utterance duration costs, specificity levels) significantly impact performance but lack empirical grounding in actual human communication patterns

## Confidence

- **High Confidence**: The core RSA extension mechanism (combining Bayesian belief projection with finite-horizon planning) is theoretically sound and well-validated through controlled simulations.
- **Medium Confidence**: The effectiveness of user-specific prior modeling shows promise but relies on assumptions about prior knowledge that may not generalize across diverse user populations.
- **Low Confidence**: Claims about scalability to real-world dynamic environments are speculative, with the paper not addressing how the system would handle unexpected user behavior or concept drift.

## Next Checks

1. **User Model Validation**: Test the system with actual human participants whose belief states are tracked through think-aloud protocols or eye-tracking to verify that the model accurately predicts user understanding.

2. **Scalability Test**: Evaluate performance when critical events occur at twice the frequency (every 3-4 timesteps instead of 5-7) to assess whether the planning horizon remains adequate.

3. **Lexicon Sensitivity Analysis**: Systematically vary utterance duration costs and specificity mappings to determine how robust the optimization is to these design choices.