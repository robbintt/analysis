---
ver: rpa2
title: Deep Generative model that uses physical quantities to generate and retrieve
  solar magnetic active regions
arxiv_id: '2502.05351'
source_url: https://arxiv.org/abs/2502.05351
tags:
- data
- physical
- real
- images
- generated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a deep generative model pipeline to create and
  retrieve solar magnetic active regions using physical quantities. The authors train
  a GAN on SHARP solar magnetic patch data, then use SVMs to map physical parameters
  (total unsigned field, polarity separation, field near polarity inversion lines)
  to GAN latent space directions.
---

# Deep Generative model that uses physical quantities to generate and retrieve solar magnetic active regions

## Quick Facts
- arXiv ID: 2502.05351
- Source URL: https://arxiv.org/abs/2502.05351
- Reference count: 1
- Primary result: GAN generates solar magnetic patches with controllable physical parameters; retrieved real matches show Pearson correlations of 0.78-0.79 for total unsigned field

## Executive Summary
This paper presents a pipeline that generates solar magnetic active region images with controllable physical properties using a GAN trained on SHARP data. The authors extract interpretable directions in the GAN's latent space corresponding to physical parameters (total unsigned field, polarity separation, and field gradient regions) using linear SVMs. These directions enable controlled generation of patches with desired properties, which can then be used as queries to retrieve real matching data via a self-supervised learning model. Results demonstrate strong correlations between physical parameters of generated queries and their retrieved real matches, validating the approach's effectiveness for physical parameter manipulation and retrieval.

## Method Summary
The method trains a GAN on 128×128 SHARP patches to learn a latent space representation of solar magnetic active regions. Physical parameters (TUF, PSEP, R) are computed for generated samples, and linear SVMs trained on these parameters extract normal vectors defining interpretable directions in the 100D latent space. Conditional manipulation is achieved through orthogonal decomposition to minimize unwanted parameter changes. A SimSiam self-supervised model trained on real SHARPs learns augmentation-invariant embeddings, enabling retrieval of real images matching generated queries via nearest-neighbor search in the embedding space.

## Key Results
- GAN generates realistic magnetic patches with controllable physical properties
- SVM-extracted directions enable smooth variation along TUF, PSEP, and R parameters
- Generated patches retrieve real matching data with Pearson correlations of 0.78-0.79 for total unsigned field
- Conditional manipulation via orthogonal decomposition reduces unwanted parameter changes
- Retrieval correlations: TUF (0.78-0.79), PSEP (0.28), R (0.69-0.7), polarity metrics (0.72-0.73)

## Why This Works (Mechanism)

### Mechanism 1: Latent Space Direction Extraction via SVM Decision Boundaries
Linear SVMs trained on GAN latent vectors extract interpretable directions corresponding to physical parameters, enabling controlled image generation. The method generates 10,000 images, computes physical parameters, assigns binary labels using median split, and trains linear SVMs to find decision hyperplanes. The normal vector to each hyperplane becomes the "direction" for that parameter, allowing traversal by shifting latent vectors along this direction. This works because the GAN latent space organizes physical properties such that linear directions capture meaningful monotonic variations.

### Mechanism 2: Orthogonal Decomposition for Conditional Disentanglement
Projecting out directions of unwanted correlated parameters enables manipulation of a target parameter while minimizing collateral changes. The method identifies direction vectors for both target and correlated parameters, then computes orthogonalized directions through vector projection. For multiple confounds, matrix orthogonal projection is used. This assumes physical parameter directions are approximately linearly independent, allowing effective decoupling within local regions of latent space.

### Mechanism 3: SSL-Based Retrieval for Physical Correspondence Validation
Self-supervised representations trained on real data create a shared embedding space where generated queries retrieve real images with matching physical properties. SimSiam is trained with augmentations to learn 100D embeddings that preserve physically meaningful structures. Generated query images are encoded and matched to real images via negative cosine similarity. This works because SSL-learned invariances correlate with physical-parameter-invariance for matching.

## Foundational Learning

- **Concept: GAN Latent Space Geometry**
  - Why needed here: The approach depends on understanding that latent vectors are samples from a learned distribution, and directions in this space correspond to variations in generated outputs
  - Quick check question: If you linearly interpolate between two latent vectors z₁ and z₂, what property should the generated image sequence exhibit?

- **Concept: SVM Hyperplane Geometry in High Dimensions**
  - Why needed here: Extracting "directions" requires understanding that linear SVM decision boundaries are hyperplanes with normal vectors that define directions of maximal class separation
  - Quick check question: In a 100D space, a linear SVM produces a 99-dimensional decision surface. How do you extract the single direction vector perpendicular to this surface?

- **Concept: Self-Supervised Contrastive Learning Objectives**
  - Why needed here: SimSiam's negative cosine similarity loss trains the encoder to produce similar embeddings for augmented views of the same image; understanding this explains why retrieval works
  - Quick check question: Why does minimizing -z·p / (‖z‖‖p‖) between prediction and projection outputs encourage the encoder to ignore augmentations like rotation and zoom?

## Architecture Onboarding

- **Component map**:
  - GAN Generator (100D noise → 128×128 patch) -> GAN Discriminator (128×128 patch → scalar probability) -> SVM Module (100D input → binary classification) -> SimSiam (128×128 → 100D embedding)

- **Critical path**:
  1. Train GAN on SHARP patches (200 epochs, batch=32, lr=0.0005); select checkpoint with lowest discriminator accuracy
  2. Generate 10K samples; compute physical parameters; train/validate SVMs (70/30 split)
  3. Extract normal vectors; implement orthogonal decomposition for conditional directions
  4. Train SimSiam on real SHARPs with specified augmentations
  5. Build retrieval pipeline: encode query → cosine similarity search → return top match

- **Design tradeoffs**:
  - Linear vs. kernel SVMs: Linear provides interpretable directions; non-linear may capture complex boundaries but loses geometric simplicity
  - Median threshold for labels: Robust to outliers but discards magnitude information; regression alternatives unexplored
  - Binary vs. multi-class disentanglement: Current approach handles pairwise; extending to 3+ simultaneous constraints requires careful orthogonalization order

- **Failure signatures**:
  - Low discriminator error at all epochs: Generator not learning diverse distribution (mode collapse)
  - SVM validation accuracy ~50%: Latent directions not correlated with physical parameter; GAN may not encode this parameter
  - Retrieved images visually dissimilar to query: SSL augmentations may be destroying discriminative physical features
  - PSEP correlation significantly lower than others (~0.28): Parameter sensitive to small-scale features; field-weighted centroids unstable for complex multipolar regions

- **First 3 experiments**:
  1. **GAN sanity check**: Generate 100 random samples; visually inspect for realism, diversity, and flux range; confirm temporal evolution patterns are present
  2. **Direction validation**: For each SVM-derived direction, generate traversal sequences (ε ∈ {-2, -1, 0, 1, 2}); plot physical parameter vs. ε; confirm monotonic relationship
  3. **Retrieval correlation test**: Generate 1000 random queries; retrieve nearest neighbors; compute Pearson correlations for all four physical parameters; confirm TUF and polarity metrics >0.7, investigate PSEP failures

## Open Questions the Paper Calls Out

- **Open Question 1**: Can the GAN latent space be calibrated to generate images using exact numerical physical values rather than relative directional shifts? The current SVM implementation learns directional vectors for relative increases or decreases, but lacks a regression framework to map latent vectors to precise physical magnitudes.

- **Open Question 2**: Would defining a new polarity separation metric improve the low correlation (Pearson ~0.28) observed between generated queries and retrieved real images? The current metric relies on field-strength-weighted centroids, which are easily skewed by small-scale features and multipolar regions.

- **Open Question 3**: To what extent does the entanglement of physical parameters limit the independent control of image generation? It is unclear if linear orthogonal decomposition in the latent space is sufficient to fully disentangle complex, non-linear physical dependencies inherent in solar magnetic fields.

## Limitations
- SVM-based direction extraction assumes linear relationships that may not hold for all physical parameters
- PSEP correlation remains low (~0.28), indicating the method struggles with polarity separation metrics
- Orthogonal decomposition only partially mitigates parameter entanglement, with residual correlations remaining
- The approach may not generalize to higher-dimensional parameter spaces or fundamentally coupled physical properties

## Confidence
- **High Confidence**: GAN generation of realistic magnetic patches, SimSiam training and retrieval pipeline, Pearson correlation calculations
- **Medium Confidence**: SVM-derived latent space directions for physical parameters, orthogonal decomposition effectiveness, physical interpretability of generated variations
- **Low Confidence**: Generalization to parameters beyond TUF/PSEP/R, robustness across different solar conditions, scalability to higher-dimensional parameter spaces

## Next Checks
1. **Parameter Correlation Analysis**: Systematically vary ε along each SVM direction and measure Pearson correlations for all four physical parameters simultaneously to quantify entanglement and validate the orthogonality assumption.

2. **Ablation Study**: Compare retrieval performance using different SSL methods (SimSiam vs. standard contrastive learning) and augmentation strategies to determine which features the model actually learns.

3. **Temporal Consistency Test**: Generate sequences of patches following solar evolution patterns and verify that physical parameters change monotonically and realistically over time, validating the model's understanding of solar physics beyond static correlations.