---
ver: rpa2
title: Does TabPFN Understand Causal Structures?
arxiv_id: '2511.07236'
source_url: https://arxiv.org/abs/2511.07236
tags:
- causal
- data
- tabpfn
- decoder
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether TabPFN, a transformer-based tabular
  foundation model, encodes causal information in its internal representations. The
  authors develop an adapter framework using learnable causal tokens and a dual-attention
  decoder to extract causal signals from TabPFN's frozen embeddings and decode them
  into adjacency matrices for causal discovery.
---

# Does TabPFN Understand Causal Structures?

## Quick Facts
- arXiv ID: 2511.07236
- Source URL: https://arxiv.org/abs/2511.07236
- Reference count: 16
- Key outcome: TabPFN embeddings contain extractable causal information, outperforming traditional algorithms on ROC AUC and matching A VICI on sparse graphs

## Executive Summary
This paper investigates whether TabPFN, a transformer-based tabular foundation model, encodes causal information in its internal representations. The authors develop an adapter framework using learnable causal tokens and a dual-attention decoder to extract causal signals from TabPFN's frozen embeddings and decode them into adjacency matrices for causal discovery. Their experiments show that TabPFN's embeddings contain causal information, with the best performance achieved using mid-range encoder layers (layers 4-6). The approach outperforms several traditional causal discovery algorithms on ROC AUC scores and demonstrates stable performance close to the pre-trained A VICI model, though AP scores degrade at larger feature sizes. The study establishes that pre-trained tabular models can be leveraged for causal discovery tasks and provides insights into where causal information is concentrated within foundation models.

## Method Summary
The authors develop an adapter framework that freezes TabPFNv2's encoder (layers 1-4) and uses learnable causal tokens (30 per dataset) that perform cross-attention to TabPFN's data embeddings. These tokens are then aggregated to 4 per feature via max/min/mean/std operations, projected into parent/child representations, and dot-multiplied to yield edge probabilities. The model is trained with weighted binary cross-entropy and an acyclicity constraint via spectral radius regularization. Synthetic data is generated from 5 DAG types (Erdős-Rényi, Scale-Free, Watts-Strogatz, SBM, Geometric) with linear/RFF mechanisms and Gaussian/Laplace/Cauchy noise, with training using either (100 obs + 100 int) samples (75% prob) or 200 obs-only (25% prob), and evaluation using 500 datasets (5,7,10,15,20 features) with 300 obs + 300 int samples each.

## Key Results
- TabPFN embeddings contain causal information that can be extracted via the adapter framework
- Middle encoder layers (4-6) yield the best causal discovery performance
- The approach outperforms traditional algorithms (GIES, IGSP, DCDI) on ROC AUC scores
- Performance degrades on dense graphs (Erdős-Rényi, SBM, Watts-Strogatz) and at larger feature scales (>10 features)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** TabPFN's frozen embeddings contain extractable causal information that can be decoded into adjacency matrices for causal discovery.
- **Mechanism:** The adapter framework uses learnable causal tokens (Q₀ ∈ R^(t×f×d)) that perform cross-attention to TabPFN's data embeddings, selectively aggregating structural dependencies across features. These tokens are then projected into parent/child representations whose dot products yield edge probabilities.
- **Core assumption:** TabPFN's pre-training on synthetic datasets generated from structural causal models (SCMs) causes it to encode feature interactions aligned with underlying causal relationships, even though trained only for predictive tasks.
- **Evidence anchors:** [abstract] "Our evaluations demonstrate that TabPFN's embeddings contain causal information, outperforming several traditional causal discovery algorithms"; [Section 4.2 RQ3] Using pre-trained encoder weights improves performance; degrading predictive performance diminishes causal accuracy.
- **Break condition:** Performance degrades substantially when using random or degraded encoder weights, indicating the causal signal depends on specific pre-trained representations rather than the adapter architecture alone.

### Mechanism 2
- **Claim:** Causal information is concentrated in TabPFN's middle layers (layers 4-6), not uniformly distributed across the network.
- **Mechanism:** Early layers encode raw feature representations, middle layers develop functional understanding of feature interactions, and later layers adapt toward downstream predictive tasks. The causal structure emerges during the intermediate transformation stage.
- **Core assumption:** Layer-wise functional specialization exists in TabPFN, analogous to patterns observed in other transformers where middle layers encode relational/functional knowledge.
- **Evidence anchors:** [Section 4.2 RQ2] "relying on data embeddings from the middle layers of TabPFN, namely layers 4-6, results in better causal understanding"; [Section 4.2 RQ2] Cites Sia et al. (2024) and Küken et al. (2025) for interpretations about functional understanding in middle layers.
- **Break condition:** Extracting from layer 1 or layer 12 yields substantially lower AP scores, confirming non-uniform distribution.

### Mechanism 3
- **Claim:** The learnable dual-attention decoder architecture is essential for extracting causal signals; simply passing causal tokens through TabPFN's encoder attention is insufficient.
- **Mechanism:** Cross-attention from causal tokens to data embeddings allows selective aggregation of causal information. The decoder mirrors TabPFN's dual-attention (across features and samples) but inverts the attention direction—tokens query the data rather than self-attending.
- **Core assumption:** Causal information requires a specialized aggregation mechanism that differs from TabPFN's predictive self-attention patterns.
- **Evidence anchors:** [Appendix D.1] "No Decoder" setup shows lowest performance; "Standard Decoder" achieves highest scores; [Section 3.1] Decoder produces output tokens R^L that are aggregated and projected into adjacency predictions.
- **Break condition:** Removing the decoder (passing tokens as X_test through encoder) causes performance collapse, demonstrating the decoder's non-redundant role.

## Foundational Learning

- **Concept: Structural Causal Models (SCMs)**
  - **Why needed here:** TabPFN was pre-trained on synthetic data generated from SCMs. Understanding that SCMs define variables through parent-child functional relationships with noise terms explains why TabPFN might encode causal structure implicitly.
  - **Quick check question:** Can you explain how an SCM defines a variable x_j given its parents x_pa(j) and noise ε_j?

- **Concept: Directed Acyclic Graphs (DAGs) and Acyclicity Constraints**
  - **Why needed here:** Causal discovery outputs adjacency matrices that must represent DAGs. The paper uses spectral radius constraints during training to enforce acyclicity.
  - **Quick check question:** Why must a causal graph be acyclic, and what does the spectral radius constraint enforce?

- **Concept: Cross-Attention vs. Self-Attention**
  - **Why needed here:** The adapter uses cross-attention (causal tokens query data embeddings) rather than self-attention (data tokens attend to each other). This distinction is critical to understanding why the decoder architecture matters.
  - **Quick check question:** In cross-attention, what serves as queries, keys, and values? How does this differ from TabPFN's encoder self-attention?

## Architecture Onboarding

- **Component map:** Data → TabPFN embedding layer → 4 encoder layers → causal tokens cross-attend (decoder) → aggregate to 4 tokens per feature → project to parent/child → dot product → adjacency matrix

- **Critical path:** Data → TabPFN embedding layer → 4 encoder layers → causal tokens cross-attend (decoder) → aggregate to 4 tokens per feature → project to parent/child → dot product → adjacency matrix

- **Design tradeoffs:**
  - **Layer depth (L=4 vs. full L=12):** Middle layers (4-6) encode causal information best; deeper layers specialize for prediction. Paper uses L=4 based on empirical findings.
  - **Token count (t=30, k=4):** More tokens increase capacity but computational cost. Aggregation to k=4 balances expressiveness with efficiency.
  - **Frozen vs. fine-tuned encoder:** Freezing preserves pre-trained causal priors but limits adaptation. Fine-tuning toward worse predictive performance degrades causal accuracy (Section 4.2 RQ3).

- **Failure signatures:**
  - **AP score degradation at scale:** As feature count increases (15-20), AP scores decline substantially even while ROC AUC remains stable. Indicates difficulty distinguishing correct edges among more possibilities.
  - **Graph structure sensitivity:** Dense graphs (Erdős-Rényi, SBM, Watts-Strogatz) show higher variance and worse scaling than sparse graphs (Scale-Free, GRG). Attributed to TabPFN's pre-training on small, sparse graphs.
  - **Random encoder weights:** Performance collapses without pre-trained encoder, confirming causal signal originates in TabPFN's learned representations.

- **First 3 experiments:**
  1. **Layer ablation:** Train the adapter using embeddings from different encoder layers (1, 4, 6, 12). Verify that middle layers yield highest AP scores on held-out DAGs.
  2. **Encoder importance test:** Compare three conditions—pre-trained weights, random initialization, and intentionally degraded weights (fine-tuned to worse classification). Confirm pre-trained weights are necessary.
  3. **Decoder architecture comparison:** Test "No Decoder" (tokens through encoder), "Standard Decoder" (cross-attention to layer 4), and "Evolving Decoder" (layer-matched attention). Verify Standard Decoder outperforms alternatives.

## Open Questions the Paper Calls Out

- **Question:** Can the adapter framework maintain high precision in causal discovery when scaling to datasets with significantly more than 20 features?
  - **Basis in paper:** [explicit] The paper notes "increasing degradation in AP scores at larger feature scales" in the abstract and results section.
  - **Why unresolved:** The evaluation was limited to a maximum of 20 features, and the AP score degradation suggests the model struggles to distinguish correct relations as the search space grows.
  - **What evidence would resolve it:** Evaluating the model on datasets with >20 features demonstrating stable or improved Average Precision (AP) scores.

- **Question:** Does modifying TabPFN's pre-training objective to explicitly include causal structure prediction mitigate the performance variance across different graph topologies?
  - **Basis in paper:** [inferred] Appendix D.2 attributes performance issues to TabPFN's pre-training on predictive tasks which consolidate info for a target variable, causing instability on dense graphs (e.g., Erdős-Rényi).
  - **Why unresolved:** The current approach relies on a frozen encoder pre-trained solely for predictive tasks, not causal structure discovery.
  - **What evidence would resolve it:** Comparing the current model against a variant pre-trained with causal objectives on dense graph structures.

- **Question:** Does unfreezing and fine-tuning the TabPFN encoder yield superior causal discovery performance compared to the frozen-embedding approach?
  - **Basis in paper:** [inferred] RQ3 demonstrates that optimal pre-trained weights are crucial, but the methodology explicitly freezes the encoder to probe representations rather than optimize them.
  - **Why unresolved:** The authors restrict the encoder to frozen weights to isolate whether causal information exists *implicitly*, leaving the potential of fine-tuning unexplored.
  - **What evidence would resolve it:** Ablation studies showing performance changes when encoder layers are unfrozen and updated during the adapter training phase.

## Limitations

- **Generalizability uncertainty:** The paper establishes findings on synthetic data, but performance on real-world tabular data remains unknown.
- **Acyclicity constraint underspecification:** The augmented Lagrangian hyperparameters and constraint implementation details are not fully specified.
- **Graph structure sensitivity:** Performance degrades significantly on dense graph types (Erdős-Rényi, SBM, Watts-Strogatz) compared to sparse graphs.

## Confidence

- **High Confidence:** The mechanism that pre-trained TabPFN weights are necessary for causal extraction (RQ3 results are robust and directly measured)
- **Medium Confidence:** The layer-wise concentration of causal information in middle layers (empirical but lacks theoretical grounding for TabPFN specifically)
- **Medium Confidence:** The adapter architecture's effectiveness over simpler alternatives (ablation shows clear differences, but corpus lacks architectural comparisons)

## Next Checks

1. **Real Data Transfer Test:** Apply the adapter framework to real-world tabular datasets with known causal ground truth (e.g., from Tübingen datasets or benchmark causal discovery repositories) to verify synthetic data findings transfer.

2. **Layer Specialization Analysis:** Conduct a finer-grained layer ablation study (layers 3-7) with statistical significance testing to confirm the optimal range and investigate whether this pattern holds across different DAG types.

3. **Architecture Ablation with Real Data:** Test the decoder-less and evolving decoder variants on real datasets to verify the architecture choices remain optimal outside synthetic conditions.