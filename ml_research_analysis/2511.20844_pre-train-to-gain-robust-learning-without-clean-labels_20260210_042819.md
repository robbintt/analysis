---
ver: rpa2
title: 'Pre-train to Gain: Robust Learning Without Clean Labels'
arxiv_id: '2511.20844'
source_url: https://arxiv.org/abs/2511.20844
tags:
- labels
- training
- learning
- noise
- label
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work explores self-supervised learning (SSL) as a way to improve
  deep learning robustness when training on noisy labels, without requiring a clean
  data subset. By pre-training a ResNet18 backbone using SimCLR or Barlow Twins on
  the same noisy dataset, followed by standard supervised fine-tuning, the model achieves
  higher test accuracy and better label-error detection (measured via F1 and Balanced
  Accuracy) compared to training from scratch.
---

# Pre-train to Gain: Robust Learning Without Clean Labels

## Quick Facts
- **arXiv ID:** 2511.20844
- **Source URL:** https://arxiv.org/abs/2511.20844
- **Reference count:** 28
- **One-line primary result:** SSL pre-training on noisy data boosts robustness without requiring clean labels.

## Executive Summary
This work explores self-supervised learning (SSL) as a way to improve deep learning robustness when training on noisy labels, without requiring a clean data subset. By pre-training a ResNet18 backbone using SimCLR or Barlow Twins on the same noisy dataset, followed by standard supervised fine-tuning, the model achieves higher test accuracy and better label-error detection (measured via F1 and Balanced Accuracy) compared to training from scratch. On CIFAR-10 and CIFAR-100 with synthetic label noise rates up to 80%, SSL pre-training consistently improved classification accuracy by 5–30% and F1/BA scores by 4–7 percentage points. It also outperformed ImageNet pre-trained models under high noise, and maintained robustness even with extended supervised training, showing slower overfitting and reduced loss escalation. The improvements were most pronounced at moderate pre-training durations (≈50 epochs), with minimal gains thereafter. Overall, SSL pre-training on noisy data is shown to be a simple, effective strategy for noise-robust learning.

## Method Summary
The method uses a two-stage pipeline to train models robust to label noise without clean data. First, a ResNet18 backbone is pre-trained using SimCLR or Barlow Twins on the noisy dataset, learning feature representations without relying on labels. The projection head used in SSL is then discarded. Second, the pre-trained backbone is fine-tuned with standard supervised cross-entropy loss for a small number of epochs (10) on the same noisy data. This approach avoids the early memorization of label noise typical in training from scratch, leveraging SSL's ability to learn semantically meaningful representations independent of labels. The method is evaluated on CIFAR-10 and CIFAR-100 with synthetic label noise (rates up to 80%), as well as real-world noisy versions of these datasets.

## Key Results
- SSL pre-training consistently improved clean test accuracy by 5–30% compared to training from scratch under synthetic noise rates up to 80%.
- Label error detection (F1 and Balanced Accuracy) improved by 4–7 percentage points with SSL pre-training.
- SSL pre-training outperformed ImageNet pre-trained models at high noise levels (η ≥ 0.6), while ImageNet was competitive at low noise.
- Pre-training for ~50 epochs was sufficient; longer durations yielded minimal additional gains.
- Models with SSL pre-training exhibited slower overfitting and less loss escalation during fine-tuning.

## Why This Works (Mechanism)

### Mechanism 1: Label-Agnostic Feature Alignment
Initializing the backbone with SSL allows the model to learn structural representations of the data distribution without propagating label errors, effectively creating a "clean" starting state for the classifier head. SSL methods (SimCLR, Barlow Twins) optimize for feature similarity between augmented views of the same image rather than predicting a given class label, isolating the feature extractor from noise in the annotation space.

### Mechanism 2: Mitigation of Early Memorization ("Warm-up Obstacle")
SSL pre-training bypasses the initial phase of training where standard models are most susceptible to memorizing noisy labels. Training from scratch involves a "warm-up" phase where the model rapidly fits easy patterns, including label noise. By starting with a pre-trained encoder, the model enters the supervised phase with a mature representation, reducing the gradient pressure to memorize noise to minimize initial loss.

### Mechanism 3: Enhanced Label Error Detection via Better Separation
Models initialized via SSL provide more calibrated probability outputs, improving the downstream performance of label error detection algorithms like Confident Learning. Because the backbone features are semantically clustered before fine-tuning, the resulting classifier is less likely to assign high confidence to incorrect labels, allowing better distinction between "hard examples" and "mislabeled examples."

## Foundational Learning

- **Concept: Self-Supervised Learning (SimCLR/Barlow Twins)**
  - **Why needed here:** This is the core intervention. You must understand that SimCLR uses contrastive loss (pulling similar views together) and Barlow Twins uses redundancy reduction, but neither requires class labels.
  - **Quick check question:** Can you explain why rotating an image or changing its color jitter does not change the "pseudo-label" in SSL, but would change a supervised label?

- **Concept: Memorization Effects in Deep Learning**
  - **Why needed here:** The paper relies on the premise that DNNs learn clean patterns first before memorizing noise. Understanding this "early learning" phenomenon is critical to grasping why initialization matters.
  - **Quick check question:** In a standard training run on noisy data, does the test loss typically decrease initially and then spike, or does it stay high permanently?

- **Concept: Transfer Learning & Fine-tuning**
  - **Why needed here:** The method is a two-stage pipeline. You need to know how to freeze vs. fine-tune weights and why the paper chooses to fine-tune the entire backbone rather than freezing it.
  - **Quick check question:** If you froze the SSL backbone and only trained the linear head, would you expect the "noise robustness" effect to persist, increase, or decrease?

## Architecture Onboarding

- **Component map:** Noisy Dataset -> SSL Pre-training (SimCLR/Barlow Twins) -> Supervised Fine-tuning -> Clean Test Accuracy & Label Error Detection Metrics
- **Critical path:**
  1. Data Augmentation: Standard augmentations (crop, flip, color jitter) are strictly required for Stage 1.
  2. Pre-training Duration: Run SSL for ≈50 epochs (paper indicates plateau point); longer is unnecessary.
  3. Fine-tuning: Standard Cross-Entropy loss. Monitor for "loss escalation" to catch overfitting.
- **Design tradeoffs:**
  - Target vs. External Pre-training: ImageNet weights work well for low noise (η ≈ 0.2), but Target-Dataset SSL is superior for high noise (η ≥ 0.6).
  - Compute vs. Robustness: SSL pre-training adds computational overhead upfront (~50 epochs), but saves compute by reducing the need for complex loss functions or iterative label cleaning.
- **Failure signatures:**
  - Loss Escalation: If the training loss begins to drop while test loss rises sharply during fine-tuning, the model is memorizing noise (standard failure mode).
  - Diminishing Returns: Pre-training for >50 epochs yielded minimal gains in the paper; if accuracy doesn't improve after this point, stop training to save resources.
- **First 3 experiments:**
  1. Baseline Sanity Check: Train ResNet18 from scratch on CIFAR-10 with 40% symmetric label noise. Verify poor generalization (overfitting).
  2. SSL Intervention: Pre-train ResNet18 on the same noisy data using SimCLR for 50 epochs, then fine-tune. Compare test accuracy against the baseline.
  3. Ablation: Run the same setup but initialize with ImageNet weights. Verify that at high noise rates (η=0.6), the Target-SSL model outperforms the ImageNet-initialized model.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does self-supervised pre-training on noisy data maintain its robustness advantages when scaled to significantly larger, higher-resolution datasets?
- **Basis in paper:** The authors state in the conclusion that "future work will explore scaling to larger datasets."
- **Why unresolved:** The current study is restricted to CIFAR-10 and CIFAR-100 (32x32 pixels), which are low-resolution and may not capture the computational or feature hierarchy challenges of ImageNet-scale data.
- **What evidence would resolve it:** Evaluation of the SSL pre-training pipeline on high-resolution datasets (e.g., ImageNet-1k) with injected synthetic label noise or naturally occurring web-scraped noise.

### Open Question 2
- **Question:** Can modern SSL techniques designed for Vision Transformers (ViT) replicate or improve the noise robustness observed with ResNet18 and contrastive methods?
- **Basis in paper:** The conclusion identifies "the integration of modern SSL techniques which are designed for Vision Transformers" as a specific avenue for future work.
- **Why unresolved:** The current experiments rely on a ResNet18 backbone with SimCLR and Barlow Twins; it is unknown if the attention mechanisms and patch-based learning of ViTs interact with label noise differently during fine-tuning.
- **What evidence would resolve it:** Experiments replacing the CNN backbone with a ViT, utilizing SSL methods like MAE or DINO, on the same noisy CIFAR benchmarks.

### Open Question 3
- **Question:** What causes the performance gains of SSL pre-training to plateau after approximately 50 epochs?
- **Basis in paper:** The paper observes that improvements "begin to plateau after approximately 50 epochs" but does not investigate the theoretical saturation point or representation dynamics.
- **Why unresolved:** It is unclear if the plateau results from the SSL objective sufficiently disentangling the classes or if the augmentations fail to provide further signal, limiting the robustness potential.
- **What evidence would resolve it:** Analysis of representation geometry (e.g., alignment and uniformity) and class separation metrics at pre-training intervals extending beyond the observed plateau.

## Limitations

- Exact hyperparameter settings for both SSL pre-training and fine-tuning stages remain unspecified, which could affect reproducibility of the reported gains.
- The claim that SSL initialization consistently improves robustness is supported by controlled synthetic experiments but lacks validation on more diverse, real-world noisy datasets beyond CIFAR-10N/CIFAR-100N.
- The analysis focuses on ResNet-18 and two SSL methods, leaving open questions about scalability to larger architectures or alternative SSL objectives.
- There is no explicit ablation on whether freezing the backbone during fine-tuning would alter results, nor is there analysis of the effect on other detection metrics beyond F1 and Balanced Accuracy.

## Confidence

- **High:** Observed accuracy improvements under synthetic noise, given the systematic ablation across noise rates and pre-training durations.
- **Medium:** Label error detection claims, as the evaluation setup (Confident Learning on a noisy test set) is methodologically sound but the results are less extensively cross-validated.
- **Low:** Generalizability to non-synthetic noise or other architectures due to the limited scope of experiments.

## Next Checks

1. **Hyperparameter Sensitivity:** Run ablations varying SimCLR/Barlow Twins learning rates, projection dimensions, and fine-tuning LR schedules to confirm reported gains are robust to these choices.
2. **Real-World Transfer:** Validate the method on a non-synthetic noisy dataset (e.g., WebVision or Clothing1M) to test practical robustness.
3. **Architecture Scaling:** Test whether the SSL pre-training benefit persists when using ResNet-50 or Vision Transformer backbones.