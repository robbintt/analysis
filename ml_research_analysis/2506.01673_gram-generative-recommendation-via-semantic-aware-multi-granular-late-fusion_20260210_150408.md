---
ver: rpa2
title: 'GRAM: Generative Recommendation via Semantic-aware Multi-granular Late Fusion'
arxiv_id: '2506.01673'
source_url: https://arxiv.org/abs/2506.01673
tags:
- item
- user
- gram
- items
- recommendation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes GRAM, a generative recommendation model that
  leverages large language models to generate item recommendations. The core innovation
  lies in encoding implicit item relationships (hierarchical and collaborative semantics)
  into textual representations and using multi-granular late fusion to efficiently
  integrate rich item information.
---

# GRAM: Generative Recommendation via Semantic-aware Multi-granular Late Fusion

## Quick Facts
- **arXiv ID:** 2506.01673
- **Source URL:** https://arxiv.org/abs/2506.01673
- **Reference count:** 40
- **Primary result:** GRAM outperforms eight SOTA generative recommendation models with 11.5-16.0% improvement in Recall@5 and 5.3-13.6% in NDCG@5

## Executive Summary
This paper introduces GRAM, a generative recommendation framework that leverages large language models (LLMs) to generate personalized item recommendations. The key innovation lies in encoding implicit item relationships through hierarchical and collaborative semantics into textual representations, then using multi-granular late fusion to efficiently integrate rich item information. The approach demonstrates significant performance improvements over existing generative recommendation methods across multiple benchmark datasets, addressing the challenge of capturing complex item relationships in recommendation systems.

## Method Summary
GRAM encodes implicit item relationships (hierarchical and collaborative semantics) into textual representations that can be processed by LLMs. The model uses multi-granular late fusion to combine information from different semantic levels efficiently. This approach allows the system to capture both the structural relationships between items and the collaborative patterns from user interactions, while maintaining computational efficiency through the late fusion mechanism. The framework processes these semantic representations through an LLM to generate ranked item recommendations tailored to individual users.

## Key Results
- Outperforms eight state-of-the-art generative recommendation models
- Achieves 11.5-16.0% improvement in Recall@5 metric
- Achieves 5.3-13.6% improvement in NDCG@5 metric
- Validated across four benchmark datasets

## Why This Works (Mechanism)
The mechanism works by encoding complex item relationships into textual representations that LLMs can process, then using multi-granular late fusion to combine information from different semantic levels. The hierarchical semantics capture structural relationships between items (like categories and subcategories), while collaborative semantics encode user-item interaction patterns. This dual representation allows the model to understand both the inherent properties of items and how users interact with them, leading to more accurate recommendations.

## Foundational Learning
- **Large Language Models (LLMs):** Pre-trained models that can process and generate natural language, used here to generate recommendations from encoded item semantics
- **Multi-granular Late Fusion:** A technique that combines information at different levels of granularity (coarse to fine) in the final stages of processing, improving efficiency and performance
- **Hierarchical Semantics:** Encoding of structural relationships between items (categories, subcategories, attributes) into text format
- **Collaborative Semantics:** Encoding of user-item interaction patterns and preferences into textual representations
- **Textual Item Representations:** Converting item attributes and relationships into text format that LLMs can process
- **Generative Recommendation:** Using generative models (like LLMs) to produce ranked lists of recommendations rather than scoring items individually

## Architecture Onboarding

**Component Map:** Item Metadata -> Hierarchical Semantic Encoder -> Collaborative Semantic Encoder -> Multi-granular Late Fusion -> LLM -> Recommendation Output

**Critical Path:** The critical path involves encoding item metadata into hierarchical and collaborative semantic representations, fusing these representations at multiple granularities, and feeding the fused representation into an LLM to generate recommendations.

**Design Tradeoffs:** The approach trades computational complexity for richer semantic representation, using multi-granular fusion to balance information richness with efficiency. The text-based encoding enables leveraging powerful LLMs but may introduce some information loss compared to direct numerical representations.

**Failure Signatures:** Performance degradation may occur if item metadata is sparse, semantic relationships are poorly defined, or the LLM fails to effectively process the encoded representations. Computational bottlenecks could arise from the multi-granular fusion process or LLM inference time.

**3 First Experiments:**
1. **Semantic Encoding Validation:** Test the quality of hierarchical and collaborative semantic encodings independently on a held-out validation set
2. **Fusion Granularity Analysis:** Evaluate performance at different fusion granularities to identify the optimal balance between richness and efficiency
3. **Ablation Study:** Remove either hierarchical or collaborative semantics to quantify their individual contributions to overall performance

## Open Questions the Paper Calls Out
None identified in the provided materials.

## Limitations
- Evaluation focuses primarily on standard ranking metrics (Recall@5, NDCG@5) without addressing diversity, serendipity, or long-term engagement
- Lacks detailed ablation studies showing individual contributions of hierarchical and collaborative semantic components
- Limited analysis of how different fusion granularities affect computational efficiency

## Confidence
- **Performance Claims:** Medium - Significant improvements reported but lack of detailed ablation studies reduces confidence
- **Methodology:** Medium - Novel approach but limited validation of individual component contributions
- **Generalizability:** Medium - Tested on four benchmark datasets but cross-domain evaluation needed

## Next Checks
1. **Ablation Analysis:** Conduct controlled experiments isolating the contributions of hierarchical semantics, collaborative semantics, and multi-granular fusion components to quantify their individual impact on performance gains.

2. **Cross-Domain Evaluation:** Test GRAM's performance across diverse recommendation domains (e.g., movies, books, products) and dataset characteristics to assess generalizability beyond the four benchmark datasets used in the original study.

3. **Computational Efficiency Benchmarking:** Measure and compare the inference time, memory usage, and scalability of GRAM against baseline models, particularly focusing on the overhead introduced by the multi-granular fusion mechanism and large language model integration.