---
ver: rpa2
title: 'Thinkquel: A Model Dedicated to Text-to-dbt Using Synthetic Data and a Span-Aware
  Objective'
arxiv_id: '2510.00186'
source_url: https://arxiv.org/abs/2510.00186
tags:
- training
- grpo
- data
- reward
- plan
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of converting natural language
  requests into reliable, production-ready database queries by targeting the portability
  and maintainability issues of raw SQL through dbt models. It introduces TS-SQL,
  a synthetic data pipeline that programmatically generates diverse, execution-validated
  NL-dbt pairs, and TS-GRPO, a span-aware reinforcement learning objective that separates
  token-level updates for planning and sequence-level updates for SQL code.
---

# Thinkquel: A Model Dedicated to Text-to-dbt Using Synthetic Data and a Span-Aware Objective

## Quick Facts
- arXiv ID: 2510.00186
- Source URL: https://arxiv.org/abs/2510.00186
- Authors: Anni Li; Aria Attar; Paul Dong
- Reference count: 8
- Primary result: 93.2% execution success and 61.8% exact-result match on 500-example TS-SQL test set

## Executive Summary
This paper introduces Thinkquel, a model optimized for converting natural language requests into production-ready dbt models. It addresses portability and maintainability challenges of raw SQL by generating dbt models instead of queries. The approach combines a synthetic data pipeline (TS-SQL) that programmatically creates execution-validated NL-dbt pairs and a novel span-aware GRPO objective (TS-GRPO) that separately updates planning and SQL code tokens. Thinkquel (32B) achieves significant improvements in execution success and exact-result match over baseline models.

## Method Summary
The authors developed TS-SQL, a synthetic data pipeline that generates diverse, execution-validated NL-dbt pairs through deterministic transformations. They also introduced TS-GRPO, a span-aware reinforcement learning objective that applies token-level updates for planning and sequence-level updates for SQL code. The model was evaluated on both a 500-example TS-SQL test set and the Spider benchmark, demonstrating substantial improvements in execution success and exact-result match metrics.

## Key Results
- Thinkquel (32B) achieves 93.2% execution success and 61.8% exact-result match on TS-SQL test set
- Improves over base model by 67.2% in execution success and 44.4% in exact-result match
- TS-GRPO shows faster and more stable convergence than GRPO and GSPO in Spider experiments

## Why This Works (Mechanism)
The dual update scheme of TS-GRPO separates planning token updates from SQL sequence updates, allowing more precise optimization of both components. The synthetic data pipeline generates diverse, validated examples that cover a wide range of scenarios while ensuring executability. This combination addresses the specific challenges of dbt model generation, where planning structure and SQL code quality are both critical.

## Foundational Learning
- **Synthetic data generation**: Programmatically creating training data to cover diverse scenarios while ensuring quality and executability
  - Why needed: Real-world dbt datasets are limited and may not cover all edge cases
  - Quick check: Verify synthetic examples execute correctly and represent realistic scenarios
- **Span-aware reinforcement learning**: Separate update mechanisms for different token types
  - Why needed: Planning tokens and SQL code require different optimization strategies
  - Quick check: Compare convergence speed and stability with unified update schemes
- **dbt model structure**: Understanding the specific requirements for portable, maintainable data transformations
  - Why needed: Direct SQL generation doesn't address production deployment concerns
  - Quick check: Validate generated models work across different environments

## Architecture Onboarding
- **Component map**: Natural Language Request -> Planning Module -> SQL Code Generator -> dbt Model Output
- **Critical path**: Input processing through span-aware GRPO updates to final dbt model generation
- **Design tradeoffs**: Larger models provide better performance but increase computational cost; synthetic data offers coverage but may miss edge cases
- **Failure signatures**: Poor planning leads to incorrect SQL structure; inadequate SQL updates result in execution failures
- **First experiments**:
  1. Test basic NL-to-dbt conversion on simple schemas
  2. Evaluate execution success on synthetically generated test cases
  3. Measure convergence differences between TS-GRPO and standard GRPO

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation confined to curated benchmarks, not real-world dbt workloads with complex schema evolution
- Synthetic data pipeline may not cover edge cases like dynamic permissions and incremental models
- Absence of ablation studies isolating TS-GRPO's impact from model scale effects
- Fixed 32B parameter size may not generalize to different model architectures

## Confidence
- Execution success improvements on TS-SQL: High
- Exact-result match gains: Medium
- Spider results and convergence benefits: Medium
- Applicability to out-of-distribution NL requests: Low

## Next Checks
1. Test Thinkquel on an independently curated, production-like dbt dataset with complex schemas and incremental models to assess generalization
2. Perform an ablation study comparing TS-GRPO with and without span-aware updates across multiple model sizes to isolate its contribution
3. Evaluate robustness by introducing schema drift and permission constraints into the test set to measure execution success under realistic operational changes