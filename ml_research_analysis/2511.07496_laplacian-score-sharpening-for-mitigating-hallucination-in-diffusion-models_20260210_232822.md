---
ver: rpa2
title: Laplacian Score Sharpening for Mitigating Hallucination in Diffusion Models
arxiv_id: '2511.07496'
source_url: https://arxiv.org/abs/2511.07496
tags:
- score
- laplacian
- sharpening
- samples
- derivative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses hallucinations in diffusion models, where
  generated samples fall between true data modes, producing unrealistic outputs. The
  authors propose Laplacian Score Sharpening, a post-hoc adjustment that leverages
  the Laplacian (second derivative) of the score function during inference to reduce
  mode interpolation artifacts.
---

# Laplacian Score Sharpening for Mitigating Hallucination in Diffusion Models

## Quick Facts
- arXiv ID: 2511.07496
- Source URL: https://arxiv.org/abs/2511.07496
- Reference count: 21
- Primary result: Reduces hallucination rate from 6.0% to 2.1% on Shapes dataset

## Executive Summary
This paper addresses hallucinations in diffusion models, where generated samples fall between true data modes, producing unrealistic outputs. The authors propose Laplacian Score Sharpening, a post-hoc adjustment that leverages the Laplacian (second derivative) of the score function during inference to reduce mode interpolation artifacts. They derive an efficient approximation using a finite-difference variant of the Hutchinson trace estimator, making the method scalable to high-dimensional image data. Experiments on 1D, 2D, and image datasets show significant reduction in hallucinated samples while preserving distributional fidelity.

## Method Summary
The method subtracts a scaled Laplacian of the score function from the learned score during inference. The Laplacian is estimated efficiently using a finite-difference Hutchinson trace estimator with Rademacher vectors, requiring only 2×n_samples forward passes per pixel instead of d forward passes. Sharpening is applied conditionally within a specific timestep window (600-800) where hallucinations typically emerge. The approach maintains distributional fidelity while reducing samples generated in inter-mode regions.

## Key Results
- IM Count drops from 250 to 28 in 1D synthetic experiments
- IM Count drops from 1627 to 365 in 2D synthetic experiments
- Hallucinated image rate decreases from 6.0% to 2.1% on Shapes dataset

## Why This Works (Mechanism)

### Mechanism 1
Subtracting a scaled Laplacian from the score function reduces samples generated in inter-mode regions. The Laplacian (trace of the Hessian of the score) is near-zero at data modes but non-zero in inter-mode regions where the model is uncertain. Weighted subtraction sharpens transitions at inter-modes, pushing trajectories away from low-confidence regions while preserving the score near modes. The learned score is overly smoothed in inter-mode regions due to model capacity limits, and the Laplacian reliably signals these uncertain regions.

### Mechanism 2
The finite-difference Hutchinson trace estimator efficiently approximates the Laplacian in high dimensions. Instead of computing second derivatives along each dimension (O(d) forward passes), Hutchinson's identity expresses the trace as an expectation over random Rademacher vectors. Central finite-difference along random directions approximates the second directional derivative; averaging over few samples (n=3) yields a tractable Laplacian estimate per pixel. The expectation over Rademacher vectors converges sufficiently with very few samples.

### Mechanism 3
Sharpening is effective only within a specific timestep window during sampling. Early timesteps (high noise) lack sharp score structure; late timesteps (low noise) already commit to trajectories. The Laplacian signal peaks between timesteps 600-800, corresponding to when hallucinated structures emerge mid-sampling. Applying sharpening only in this window corrects trajectories without unnecessary perturbation. Hallucinations originate during a predictable phase of the reverse process.

## Foundational Learning

- **Score function (gradient of log-probability)**: The entire method operates on the score; understanding that ∇x log p(x) guides denoising is prerequisite to grasping why sharpening it affects sample trajectories. Quick check: In a 1D mixture of two Gaussians, which direction does the score point at the midpoint between modes?

- **Laplacian as trace of Hessian**: The method leverages the Laplacian as a scalar summary of local curvature; understanding this connects second derivatives to the "sharpness" signal used for correction. Quick check: For a function with a sharp peak vs. a broad plateau, which has a more negative Laplacian at the peak?

- **Finite-difference approximation**: Practical implementation relies on estimating second derivatives via perturbations (f(x+δ) - 2f(x) + f(x-δ)) / δ²; understanding truncation error vs. noise tradeoffs is essential for tuning δ. Quick check: As δ → 0, does finite-difference error increase or decrease? What about sensitivity to noise?

## Architecture Onboarding

- **Component map**: denoise_fn -> Laplacian estimator -> Sharpening module -> Timestep gate
- **Critical path**: 1) Receive noisy sample x_t at timestep t, 2) Compute base score f_x = denoise_fn(x_t, t), 3) If t in window: sample Rademacher vectors, compute perturbed scores, aggregate Laplacian estimate, 4) Return f_x - α × Laplacian as sharpened score, 5) Proceed with standard DDPM update using sharpened score
- **Design tradeoffs**: α (enhancement strength): Higher values sharpen more aggressively but risk pushing samples to blank/noisy outputs (observed: blank images increased from 1.3% to 5.3%). δ (perturbation size): Smaller δ yields sharper curvature estimates but amplifies numerical noise; larger δ smooths signal but loses precision. n_samples (Hutchinson samples): More samples reduce variance but increase compute. Timestep window: Wider windows catch more potential hallucinations but may corrupt early structure formation.
- **Failure signatures**: Blank image increase: Over-aggressive sharpening pushes samples off-manifold entirely (Table 1 shows 4pp increase). No reduction in hallucinations: Likely α too low or window mistuned. Artifacts in clean regions: δ too small causing noisy Laplacian estimates. No effect: Window does not overlap with hallucination-forming timesteps.
- **First 3 experiments**: 1) Replicate 1D toy experiment (modes at x={1,2,3}) with α=0.01, δ=0.1, t_threshold=50; verify IM Count reduction and visualize sharpened vs. vanilla scores. 2) Ablate timestep window on Shapes dataset: test (600,800) vs. (500,700) vs. (700,900); plot Laplacian magnitude over time for hallucinated vs. clean samples to confirm peak alignment. 3) Sweep α ∈ {0.01, 0.025, 0.05, 0.1} on Shapes with fixed δ=0.05, n_samples=3; track hallucination rate, blank rate, and good image rate to find Pareto frontier.

## Open Questions the Paper Calls Out

### Open Question 1
Can the Laplacian signal be integrated adaptively into sampling to proactively guide samples toward the data manifold, rather than only pruning artifacts? The current post-hoc correction is destructive—it pushes samples away from inter-mode regions but does not effectively redirect them toward true modes in high-dimensional settings, as evidenced by increased blank image rates.

### Open Question 2
Can the selection of enhancement strength (α) and perturbation size (δ) be automated to remove manual tuning burden? Current values are empirically chosen based on observed ratios between the score and its second derivative, without a principled or adaptive mechanism.

### Open Question 3
Why does Laplacian Score Sharpening increase blank image generation in high-dimensional settings (1.3% → 5.3%), and can this side effect be mitigated? The paper observes this phenomenon but does not investigate its cause or propose solutions specific to high-dimensional data.

### Open Question 4
Does Laplacian Score Sharpening generalize to conditional diffusion models (e.g., text-to-image, class-conditional) where hallucinations may have different underlying causes? All experiments use unconditional diffusion models, and the method's applicability to conditional generation remains unexplored.

## Limitations
- Dataset dependence: Results may not generalize to datasets with complex, high-variation modes where mode boundaries are less distinct
- Hyperparameter sensitivity: Results depend critically on α, δ, and timestep window selection with no principled tuning guidelines
- Computational overhead: Each sample requires 2×n_samples forward passes per pixel, representing significant additional compute per timestep

## Confidence
- **High confidence**: Core mechanism (Laplacian subtraction reduces inter-mode samples in 1D/2D toy problems) with quantitative results (IM Count drops from 250→28 in 1D, 1627→365 in 2D)
- **Medium confidence**: Timestep-specific sharpening window claim supported by internal observations but lacks external validation
- **Medium confidence**: Efficiency claim for Hutchinson-based Laplacian estimation is method-internal with no comparison to alternatives

## Next Checks
1. Apply method to a multi-instance, high-variation dataset (e.g., CIFAR-10) with multiple samples per class to measure hallucination reduction and compare against baseline
2. Systematically sweep α, δ, and timestep windows on Shapes dataset to identify stable operating regions and failure modes
3. Compare Hutchinson-based Laplacian to other scalable methods (e.g., random feature approximations, low-rank Hessian approximations) for computational efficiency and hallucination reduction effectiveness