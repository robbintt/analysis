---
ver: rpa2
title: EVaR-Optimal Arm Identification in Bandits
arxiv_id: '2510.04728'
source_url: https://arxiv.org/abs/2510.04728
tags:
- evar
- lemma
- compact
- bound
- risk
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper establishes the first optimal algorithm for best-arm\
  \ identification under the Entropic Value-at-Risk (EVaR) criterion in multi-armed\
  \ bandits. The authors propose a \u03B4-correct Track-and-Stop algorithm that matches\
  \ an information-theoretic lower bound on sample complexity."
---

# EVaR-Optimal Arm Identification in Bandits

## Quick Facts
- **arXiv ID**: 2510.04728
- **Source URL**: https://arxiv.org/abs/2510.04728
- **Reference count**: 40
- **Primary result**: First optimal algorithm for best-arm identification under Entropic Value-at-Risk (EVaR) in multi-armed bandits

## Executive Summary
This paper establishes the first optimal algorithm for best-arm identification under the Entropic Value-at-Risk (EVaR) criterion in multi-armed bandits. The authors propose a δ-correct Track-and-Stop algorithm that matches an information-theoretic lower bound on sample complexity. The key technical contribution is characterizing the EVaR-constrained KL projections KL^U_inf and KL^L_inf, which require solving complex convex optimization problems. The algorithm uses C-tracking to follow oracle sampling proportions and a generalized likelihood ratio test for stopping, with empirical EVaR computed from the stopping time arm recommended.

## Method Summary
The paper develops a δ-correct Track-and-Stop algorithm for best-arm identification under the EVaR risk measure. The method involves computing oracle sampling proportions by solving an optimization problem that minimizes a weighted sum of KL-projections onto EVaR-constrained sets, then using C-tracking to follow these proportions. The stopping rule employs a generalized likelihood ratio test with a threshold derived from mixture supermartingales constructed from the dual forms of the KL-projections. The recommendation rule selects the arm with smallest empirical EVaR at the stopping time. The key technical contributions are the characterization of the EVaR-constrained KL projections (KL^U_inf and KL^L_inf) through dual representations, and the proof that the algorithm achieves the asymptotic lower bound on sample complexity.

## Key Results
- First optimal algorithm for best-arm identification under EVaR criterion in multi-armed bandits
- Proves asymptotic optimality by matching information-theoretic lower bound on sample complexity
- Characterizes EVaR-constrained KL projections (KL^U_inf and KL^L_inf) through dual representations
- Demonstrates that C-tracking converges to oracle sampling proportions for EVaR-BAI problem

## Why This Works (Mechanism)

### Mechanism 1: Track-and-Stop with EVaR-specific Oracle Proportions
- Claim: The algorithm achieves asymptotic optimality by tracking instance-specific optimal sampling proportions derived from an information-theoretic lower bound.
- Mechanism: At each round n, compute oracle proportions t*(ν̂(n)) by solving the optimization problem (5): sup over the simplex of min over alternative arms of a weighted sum of KL-projection terms. C-tracking then allocates samples to match these proportions, ensuring the empirical allocations converge to the true oracle weights.
- Core assumption: The oracle proportion set t*(ν) is nonempty, compact, convex, and upper hemicontinuous in the instance ν.
- Evidence anchors:
  - [section 4]: "We propose a sampling rule, a stopping rule, and a recommendation rule. For sampling rule we use C-Tracking Garivier and Kaufmann (2016)"
  - [section 3]: Lemma 10 proves t*(ν) has the required properties for tracking stability
  - [corpus]: Related work "Optimal Best-Arm Identification under Fixed Confidence with Multiple Optima" validates Track-and-Stop optimality in standard settings, but EVaR-specific extension is novel here

### Mechanism 2: KL-Projection Dual Representations for Tractable Computation
- Claim: The dual formulations of KL_U^inf and KL_L_inf convert intractable primal problems into finite-dimensional optimization.
- Mechanism: KL_U_inf uses the distributionally-robust EVaR representation (3) to formulate a convex dual (Theorem 11) with two scalar multipliers. KL_L_inf uses the MGF representation to reduce to a one-dimensional outer infimum over z of a convex inner problem (Theorem 12). These duals are solvable at each round using standard convex optimization.
- Core assumption: The dual feasible sets are compact and the integrands are exp-concave, enabling mixture supermartingale construction.
- Evidence anchors:
  - [section 3.1]: "KL_U_inf is a convex program... KL_L_inf is intrinsically nonconvex... [but] remains computationally tractable in practice"
  - [theorem 11, 12]: Dual formulas provide explicit optimization objectives
  - [corpus]: Weak corpus evidence—no prior EVaR-BAI papers exist; CVaR-based approaches (Agrawal et al. 2021) use related but different KL structures

### Mechanism 3: Mixture Supermartingales for Anytime δ-Correctness
- Claim: Constructing mixture supermartingales from the dual KL-projection formulas yields the stopping threshold β(n,δ) = log((K-1)/δ) + 3 log(n+1) + 2.
- Mechanism: For each arm, define multiplicative factors M_U and M_L from the dual integrands (eq. 28-29). By Lemma 27, these are positive and exp-concave on compact parameter domains. Aggregating with priors and applying Ville's inequality yields the tail bound P(statistic ≥ x + h(n)) ≤ e^{-x}. Union-bounding over K-1 alternatives gives the threshold.
- Core assumption: The EVaR constraints (E_Q[X] ≥ ν or moment bound) hold under the true distribution, ensuring the per-sample factors are supermartingales.
- Evidence anchors:
  - [appendix C.1]: Proposition 25 states the key concentration: "for all x > 0, Pr(∃n: N_i KL_U_inf + N_j KL_L_inf ≥ x + h(n)) ≤ e^{-x}"
  - [appendix C.1, proof]: Explicit construction of U_i(n) and L_j(n) as mixture supermartingales with E[U_i(n)L_j(n)] ≤ 1
  - [corpus]: Standard Track-and-Stop (Garivier-Kaufmann 2016) uses similar GLRT arguments; this extends to EVaR-specific projections

## Foundational Learning

- Concept: **Track-and-Stop Framework (Garivier-Kaufmann 2016)**
  - Why needed here: The algorithm builds directly on this framework; understanding C-tracking, GLRT stopping, and the role of oracle proportions is essential to grasp how the EVaR extension works.
  - Quick check question: Can you explain why C-tracking allocates samples near-optimally even when oracle proportions are set-valued?

- Concept: **Entropic Value-at-Risk (EVaR) and Coherent Risk Measures**
  - Why needed here: EVaR's dual representations (MGF form and KL-ball form) are central to deriving tractable KL-projections. Distinguishing EVaR from CVaR and ERM clarifies the unique optimization challenges.
  - Quick check question: What is the difference between EVaR's hard KL constraint and ERM's soft KL penalty, and why does EVaR require a nested infimum over z?

- Concept: **KL Divergence and Information Projections**
  - Why needed here: The paper defines asymmetric KL-projections (KL_U^inf, KL_L_inf) onto EVaR-constrained sets. Understanding KL divergence properties (lower semicontinuity, convexity) is needed to follow continuity arguments and dual derivations.
  - Quick check question: Why is KL(η∥κ) convex in κ but not jointly convex, and how does this affect the convexity of KL_L_inf vs. KL_U_inf?

## Architecture Onboarding

- Component map:
  - **Sampling rule**: C-tracking that computes t*(ν̂(n)) via the optimization in (5) and allocates pulls accordingly
  - **Stopping rule**: GLRT statistic Z_i(n)(n) computed from N_i(n) · KL_U^inf + N_j(n) · KL_L^inf; stop when ≥ β(n,δ)
  - **Recommendation rule**: argmin over arms of empirical EVaR(ν̂_a(τ_δ))
  - **Core subroutines**: Dual solvers for KL_U^inf (Theorem 11: 2D convex) and KL_L^inf (Theorem 12: 1D outer + 1D inner)

- Critical path: At each round n, solve the oracle optimization (5) which itself requires computing KL_U^inf and KL_L^inf for multiple arm pairs and x-values. These inner solves dominate runtime.

- Design tradeoffs:
  - **Convex vs. non-convex**: KL_U^inf dual is 2D convex (tractable); KL_L^inf requires 1D grid search over z (more expensive but manageable)
  - **Approximation accuracy vs. speed**: Coarse discretization of the x-interval [EVaR(ν_i), EVaR(ν_j)] or z-domain speeds up but may degrade tracking
  - **Threshold tuning**: The paper uses β(n,δ) with 3 log(n+1) + 2; tighter constants may exist but require refined analysis

- Failure signatures:
  - If stopping never occurs (τ_δ → ∞), check: (1) KL-projections returning +∞ due to numerical issues, (2) tracking failing to converge (forced exploration insufficient)
  - If algorithm declares wrong arm with high probability, check: (1) β(n,δ) set too low, (2) bugs in EVaR empirical estimation, (3) dual solver returning infeasible λ
  - If runtime explodes, check: (1) z-grid for KL_L^inf too fine, (2) unnecessary re-computation of EVaR(ν̂) at every round

- First 3 experiments:
  1. **Sanity check on exponential families**: For K=2 Bernoulli arms, verify that EVaR(ν̂) → E[X] as expected by Proposition 1, and that the algorithm reduces to standard Track-and-Stop.
  2. **Synthetic heavy-tailed test**: Generate rewards from bounded [0,1] distributions with varying skewness (e.g., Beta with different α, β). Measure sample complexity vs. the derived lower bound T*(μ)^{-1} log(1/δ).
  3. **Ablation on KL_L^inf discretization**: Vary the grid density for the outer infimum over z in KL_L^inf. Plot sample complexity vs. runtime to find a practical sweet spot.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can a unified algorithmic framework be developed that covers a broad class of coherent risk measures beyond EVaR?
- Basis in paper: [explicit] The conclusion states that a "promising direction" is "developing a unified framework that treats coherent risks under a single universal constraint class."
- Why unresolved: The current analysis relies on EVaR-specific entropic dual forms and KL-projection primitives which differ significantly from the structures used for CVaR or mean-variance.
- What evidence would resolve it: A generalized lower bound and Track-and-Stop template that specializes automatically to EVaR, CVaR, and spectral risk measures using common duality arguments.

### Open Question 2
- Question: Is there a computationally efficient method to solve the inner non-convex optimization problem required at each round?
- Basis in paper: [inferred] The abstract and Section 3.1 note that the algorithm requires solving a "complex convex optimization problem and a related, simpler non-convex one" (specifically for KL^L_{inf}) at every step.
- Why unresolved: The paper establishes asymptotic optimality but does not provide complexity bounds or practical solvers for the non-convex infimum over z > 0.
- What evidence would resolve it: A polynomial-time approximation scheme or a heuristic that preserves δ-correctness while removing the need for the exact non-convex global search.

### Open Question 3
- Question: Can the EVaR-BAI guarantees be extended to unbounded or heavy-tailed reward distributions?
- Basis in paper: [inferred] Section 2 explicitly restricts the analysis to distributions supported on [0,1] to ensure the compactness of P([0,1]) and the existence of optimizers (Lemma 17).
- Why unresolved: The proofs regarding the continuity of EVaR and the compactness of level sets rely on the bounded support assumption.
- What evidence would resolve it: A derivation of the characteristic time T(μ) for sub-Gaussian or moment-bounded distributions and a corresponding δ-correct algorithm.

## Limitations

- **Numerical complexity**: The algorithm requires solving complex convex optimization problems (KL^U_inf and KL^L_inf) at each round, which may be computationally expensive in practice
- **Bounded support assumption**: The theoretical guarantees only hold for reward distributions bounded in [0,1], limiting applicability to heavy-tailed or unbounded scenarios
- **Implementation sensitivity**: The performance depends on accurate dual optimization solvers and appropriate discretization choices, with no guidance provided on numerical tolerances

## Confidence

- **High Confidence**: The asymptotic optimality proof and information-theoretic lower bound characterization (Theorem 2, Theorem 3) - these follow established Track-and-Stop methodology with rigorous duality analysis
- **Medium Confidence**: The practical tractability of KL_L_inf optimization - the 1D outer infimum over z combined with convex inner problems appears implementable, but performance depends heavily on discretization and solver quality
- **Medium Confidence**: The δ-correctness guarantee - the mixture supermartingale construction is standard, but the specific dual formulations for EVaR constraints require careful verification in implementation

## Next Validation Checks

1. **Implementation verification**: Implement the algorithm for a simple Bernoulli case and verify that EVaR(ν̂) → E[X] as predicted by Proposition 1, ensuring the special case reduces to standard Track-and-Stop

2. **Dual solver benchmarking**: Compare numerical solutions of KL_U_inf and KL_L_inf against grid search baselines on small synthetic instances to validate optimization accuracy and identify sensitivity to discretization

3. **Empirical sample complexity analysis**: Run extensive simulations across varying arm distributions and risk levels α, measuring actual sample complexity against the theoretical lower bound T*(μ)^(-1) log(1/δ) to assess practical optimality gap