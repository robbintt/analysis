---
ver: rpa2
title: Automating Curriculum Learning for Reinforcement Learning using a Skill-Based
  Bayesian Network
arxiv_id: '2502.15662'
source_url: https://arxiv.org/abs/2502.15662
tags:
- environment
- agent
- curriculum
- learning
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SEBN (Skill-Environment Bayesian Networks),
  a probabilistic framework for modeling the relationship between environment features,
  agent competencies, and task performance to guide curriculum learning in reinforcement
  learning. SEBN uses past rollouts to infer competency levels and predict success
  rates on new tasks, enabling automated curriculum generation without explicit evaluation
  on each environment.
---

# Automating Curriculum Learning for Reinforcement Learning using a Skill-Based Bayesian Network

## Quick Facts
- arXiv ID: 2502.15662
- Source URL: https://arxiv.org/abs/2502.15662
- Reference count: 40
- One-line primary result: SEBN-guided curricula improve learning efficiency and generalization compared to uniform or anti-curriculum baselines

## Executive Summary
This paper introduces SEBN (Skill-Environment Bayesian Networks), a probabilistic framework for modeling the relationship between environment features, agent competencies, and task performance to guide curriculum learning in reinforcement learning. SEBN uses past rollouts to infer competency levels and predict success rates on new tasks, enabling automated curriculum generation without explicit evaluation on each environment. The method is evaluated across three domains: DoorKey (gridworld), BipedalWalker (continuous control), and Robosuite (robotics), showing that SEBN-guided curricula improve learning efficiency and generalization compared to uniform or anti-curriculum baselines.

## Method Summary
SEBN constructs a Bayesian network where environment parameters, agent skills, and their relationships form a hierarchical model. The network structure is defined by domain experts who identify relevant environment features and skills. During training, the agent collects rollouts in various environments, which are used to infer competency levels through approximate inference. The inferred competencies are then used to predict success rates on new environments, allowing the system to select the next training environment using a greedy sample-search heuristic that maximizes the heuristic difference between current and target competencies. This approach avoids the need for explicit evaluation on every potential environment while still providing targeted curriculum guidance.

## Key Results
- SEBN-guided curricula improve learning efficiency and generalization compared to uniform or anti-curriculum baselines
- The framework successfully models relationships between environment features and agent competencies across three diverse domains
- Approximate inference and greedy search provide computational tractability while maintaining curriculum quality

## Why This Works (Mechanism)
SEBN works by leveraging probabilistic inference to capture the relationship between environment features, agent competencies, and task performance. By modeling these relationships as a Bayesian network, the framework can infer competency levels from past experience and predict success rates on new tasks without explicit evaluation. The greedy sample-search heuristic efficiently selects the next training environment by maximizing the expected improvement in competency, balancing exploration of challenging environments with the need for successful learning experiences.

## Foundational Learning
- Bayesian Networks: A probabilistic graphical model representing variables and their conditional dependencies, used here to model the relationship between environments, skills, and competencies
  - Why needed: Provides the mathematical framework for inferring competencies and predicting task success rates
  - Quick check: Can you explain how conditional probability tables are learned from data in this context?

- Curriculum Learning: A training strategy that presents tasks in a meaningful order, typically from simple to complex, to improve learning efficiency
  - Why needed: Guides the agent through a sequence of progressively challenging environments
  - Quick check: How does curriculum learning differ from traditional reinforcement learning approaches?

- Approximate Inference: Techniques for estimating probability distributions in complex models when exact computation is intractable
  - Why needed: Enables real-time competency inference and success rate prediction in large Bayesian networks
  - Quick check: What are the trade-offs between exact and approximate inference in this application?

## Architecture Onboarding

Component Map: Environment Parameters -> Skills -> Competencies -> Success Rates -> Curriculum Selection

Critical Path: The agent interacts with environments, collects rollouts, which are used to infer competencies through approximate inference, then predicts success rates on new environments to select the next training task via greedy search.

Design Tradeoffs: The framework trades computational efficiency for approximation accuracy by using greedy search instead of exact inference, and relies on expert-defined skill sets rather than learning them automatically.

Failure Signatures: Poor curriculum quality may result from incorrect network structure, inadequate discretization of environment parameters, or insufficient diversity in training environments.

First Experiments:
1. Verify that the Bayesian network correctly models simple dependencies between environment features and skill requirements
2. Test competency inference accuracy on synthetic data with known ground truth
3. Evaluate the greedy search heuristic on a small environment space to ensure it selects appropriately challenging tasks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the SEBN framework be extended to dynamically accommodate new environmental features and agent skills in open-ended domains?
- Basis in paper: The conclusion states the authors wish to "extend the model to handle more open ended environments where we can add new environmental features or agent skills dynamically to the SEBN."
- Why unresolved: The current implementation relies on a fixed set of pre-defined skills and environment features provided by an expert.
- What evidence would resolve it: A modified SEBN algorithm that successfully integrates new nodes dynamically during training without requiring a restart or complete restructuring.

### Open Question 2
- Question: Can Large Language Models (LLMs) effectively automate the construction of SEBNs directly from domain documentation?
- Basis in paper: Section 6 hypothesizes that "LLMs could also be used to automatically generate SEBNs from domain documents" since they can be built from hierarchical goal networks.
- Why unresolved: Building an SEBN currently requires domain knowledge to structure the network and define relationships, which is a manual bottleneck.
- What evidence would resolve it: A system where an LLM parses text to generate an SEBN that produces curricula comparable to or better than human-expert designed networks.

### Open Question 3
- Question: Can the high variance in learning curves observed in complex domains be reduced while maintaining the efficiency of the sample-search procedure?
- Basis in paper: Section 4 notes that the learning curve for SEBN in BipedalWalker has "much higher variance" because the approximate search is not guaranteed to find the environments with the largest heuristic difference.
- Why unresolved: The greedy sample-search is necessary for computational tractability but introduces noise by occasionally selecting sub-optimal environments.
- What evidence would resolve it: An improved search heuristic or inference approximation that lowers the variance of the learning curve while retaining the computational benefits over exact inference.

## Limitations
- The independence assumption between environment and skill variables in the Bayesian network structure may not hold in practice
- The model relies on accurate discretization of continuous environment parameters, and the choice of discretization granularity could significantly impact performance
- The current implementation assumes a fixed set of predefined skills, which may not generalize well to environments requiring emergent or unforeseen capabilities

## Confidence

High confidence in the framework's ability to model relationships between environment features and competencies in the tested domains.
Medium confidence in the scalability of the approach to high-dimensional or continuous skill spaces, given the current discrete representation of competencies.
Low confidence in the generalization claims to truly novel task distributions beyond similar environments within each domain.

## Next Checks
1. Test SEBN on environments with significantly different state-action spaces and task structures than those used in training to assess true generalization capability
2. Evaluate the impact of different discretization strategies for environment parameters on curriculum quality and learning efficiency
3. Implement and test an extension allowing dynamic skill discovery rather than relying on predefined skill sets to assess robustness to unknown task requirements