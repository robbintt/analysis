---
ver: rpa2
title: Rethinking the Role of Spatial Mixing
arxiv_id: '2503.16760'
source_url: https://arxiv.org/abs/2503.16760
tags:
- mixing
- filters
- chans
- full
- spatial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper challenges the conventional wisdom that both spatial
  and channel mixing are equally important in convolutional neural networks. The authors
  systematically compare fully-learned models with those that only learn channel mixing
  (spatial mixing frozen at initialization) and vice versa across ResNet and ConvMixer
  architectures.
---

# Rethinking the Role of Spatial Mixing

## Quick Facts
- arXiv ID: 2503.16760
- Source URL: https://arxiv.org/abs/2503.16760
- Reference count: 40
- Primary result: Models learning only channel mixing while freezing spatial mixing at random initialization perform nearly as well as fully-learned models on CIFAR-10/100 and ImageNet

## Executive Summary
This paper challenges the conventional wisdom that both spatial and channel mixing are equally important in convolutional neural networks. The authors systematically compare fully-learned models with those that only learn channel mixing (spatial mixing frozen at initialization) and vice versa across ResNet and ConvMixer architectures. Surprisingly, they find that models learning only channel mixing achieve nearly identical classification performance to fully-learned models on CIFAR-10/100 and ImageNet, while models learning only spatial mixing perform significantly worse. They also discover that random spatial mixing provides inherent robustness to adversarial attacks, which can be further enhanced by smoothing the random filters. This phenomenon extends beyond classification - the same channels-only models can successfully decode pixel-shuffled images nearly as well as fully-learned models. The results suggest that random spatial mixing with learned channel mixing is sufficient for many vision tasks, potentially simplifying network design and improving robustness.

## Method Summary
The authors convert ResNet convolutions to separable convolutions (depthwise + pointwise) with a depth multiplier d=9, creating three training variants: "Full" (learn both spatial and channel mixing), "Chans" (freeze depthwise filters at random initialization, learn only pointwise), and "Space" (freeze pointwise, learn depthwise). They train ConvMixer and modified ResNet architectures on CIFAR-10/100 and ImageNet-1k, measuring validation accuracy gaps between variants. For adversarial robustness, they evaluate against FGSM and PGD-2 attacks. For pixel un-shuffling, they create datasets by applying deterministic random spatial permutations to MNIST and Fashion-MNIST, then train models to reconstruct original images. The key insight is that increasing channel width allows channels-only models to match fully-learned performance by achieving sufficient spectral coverage from random spatial filters.

## Key Results
- Models learning only channel mixing while freezing spatial mixing at random initialization achieve near-identical classification accuracy to fully-learned models on CIFAR-10/100 and ImageNet
- Models learning only spatial mixing perform significantly worse than channels-only or fully-learned models
- Random spatial mixing provides inherent robustness to adversarial attacks, which can be enhanced by smoothing the random filters
- Channels-only models can successfully invert pixel-shuffled images nearly as well as fully-learned models

## Why This Works (Mechanism)

### Mechanism 1
Random spatial filters provide sufficient spectral coverage for feature extraction, making learned spatial parameters largely redundant for performance. A bank of random, uncorrelated spatial filters rapidly creates a dense spectral envelope across frequency space. The learned channel-mixing layers (1×1 convolutions) then select useful linear combinations from this pre-existing feature basis. As width increases, spectral coverage approaches completeness, allowing channel-only models to converge to fully-learned performance. Core assumption: The target task can be solved by linearly combining features already present in the spectral envelope of random filters. Evidence: Models with only channel mixing perform nearly as well as fully learned models, and performance converges as width increases.

### Mechanism 2
The superior adversarial robustness of channels-only models arises from the low-pass spectral characteristics of their fixed random filters. Adversarial perturbations often exploit high-frequency components. Random filter banks naturally cover all frequencies, but artificially smoothing them reduces high-frequency spectral coverage in the filter bank's envelope. This eliminates a pathway for adversarial noise while preserving clean-data performance, suggesting the robustness is tied to the spectral properties of the spatial mixing operation. Core assumption: Adversarial attacks primarily exploit high-frequency signals that are attenuated by smoothed or naturally lower-frequency spatial filters. Evidence: Smoothing random filters significantly increases robustness to adversarial attacks while not hurting clean-data performance.

### Mechanism 3
The utility of frozen spatial mixing extends beyond classification to spatially-invariant tasks like pixel permutation inversion. Even for tasks requiring explicit spatial reasoning, a network with fixed spatial mixing can learn to invert the permutation. The mechanism suggests random spatial filters create a sufficiently rich set of spatial relationships and features at each layer. The learned channel mixing can then learn to combine these features to effectively "route" information spatially across the network's depth to reconstruct the original image. Core assumption: Random depthwise convolutions, combined with residual connections, allow information to propagate and be recombined across spatial positions over multiple layers. Evidence: Channels-only models perform nearly as well as fully-learned models on pixel un-shuffling tasks.

## Foundational Learning

- **Separable Convolutions (Depthwise + Pointwise)**: Why needed: The experimental design hinges on disentangling spatial and channel mixing. Depthwise applies spatial filter per channel independently, pointwise linearly combines channels. Quick check: In a standard 2D convolution with a 3x3 kernel and 64 input/output channels, which component mixes spatial information and which mixes channel information?

- **The Lottery Ticket Hypothesis**: Why needed: The finding that wide channels-only models match fully-learned performance is analogous to finding "winning tickets" within random initialization. Quick check: According to the Lottery Ticket Hypothesis, why might a randomly initialized network contain a high-performing sub-network?

- **Spectral Envelopes and Frequency Analysis in Signals**: Why needed: The paper hypothesizes that random spatial filters work due to their broad spectral coverage. A basic grasp of filter frequency response and its relationship to feature extraction is key. Quick check: What does it mean for a filter bank to have a "dense spectral envelope," and why would this be desirable for feature extraction?

## Architecture Onboarding

- **Component Map**: ConvMixer/ResNet block → Spatial Mixer (depthwise convolution, fixed at init) + Channel Mixer (1×1 convolution, learned) + Residual connection

- **Critical Path**: For a new engineer, the most important path is training and evaluating a Chans model: Instantiate a separable architecture, initialize all weights randomly, freeze all depthwise convolution layers (requires_grad=False), proceed with standard training (only pointwise weights update), evaluate against fully-learned baseline.

- **Design Tradeoffs**: Performance vs Parameters/FLOPs: Chans model's learnable parameter count does not scale with spatial kernel size (k). You can increase kernel size without increasing trainable parameters, potentially improving performance for "free." Robustness vs Attack Sophistication: Chans models show strong natural robustness against simple attacks (FGSM, PGD-2) but advantage may disappear against advanced attacks or standard adversarial training. Task Generality: Validated on classification and pixel un-shuffling; performance on tasks requiring fine-grained learned spatial transformations not guaranteed.

- **Failure Signatures**: Correlated Filters: Applying the same random kernel to every channel causes catastrophic performance drop due to poor spectral coverage. Identity/Box Filters: Using trivial spatial mixers like identity or box filters leads to failure as they lack necessary spectral diversity. Narrow Networks: In very narrow networks, spectral envelope of random filters may be too sparse, preventing Chans models from matching Full model performance.

- **First 3 Experiments**: 1. Baseline Replication on CIFAR-10: Train small ConvMixer/Separable ResNet in Full and Chans configurations, plot validation accuracy to observe performance gap. 2. Ablation on Spatial Mixer Type: Train Chans models with independent random kernels, identical random kernels, and smoothed random kernels; compare final accuracy and adversarial robustness (FGSM) to understand impact of spectral coverage and correlation. 3. Pixel Un-Shuffling Task: Create pixel-permuted MNIST, train ConvMixer in Full and Chans configurations to reconstruct original image, qualitatively inspect reconstructions and compare PSNR scores.

## Open Questions the Paper Calls Out

### Open Question 1
What causes learned spatial filters to exhibit poorer adversarial robustness compared to random filters, if not their spectral properties? The authors state there must be a different reason (statistical shortcuts, etc.) for learned filters' poor robustness, but the paper rules out spectral smoothness and does not investigate what actually causes the vulnerability.

### Open Question 2
Does the channels-only phenomenon extend to non-convolutional architectures such as Vision Transformers and MLP-Mixers? The paper only experiments on ResNet and ConvMixer, despite these architectures also separating spatial and channel mixing, and the mechanism may depend on convolution-specific properties.

### Open Question 3
Why does adversarial training eliminate the natural robustness advantage of channels-only models? Figure 6 shows that with FGSM adversarial training, the robustness gap between channels-only and fully-learned models disappears entirely, suggesting the robustness mechanism is fundamentally different from adversarial training's benefits.

## Limitations

- The core claims depend on specific architectural choices and initialization schemes; performance gaps may vary across architectures
- The spectral coverage mechanism remains theoretical rather than proven; the link to performance is not rigorously established
- Robustness findings rely on simple adversarial attacks (FGSM, PGD-2) and may not generalize to more sophisticated attacks
- The pixel un-shuffling task uses fixed permutation rather than learned spatial transformation, limiting generalizability to complex spatial tasks

## Confidence

- **High Confidence**: The empirical finding that Chans models achieve near-Full performance on CIFAR-10/100 and ImageNet (given proper width and initialization)
- **Medium Confidence**: The spectral coverage mechanism explaining why random spatial filters suffice
- **Medium Confidence**: The robustness claim that smoothing random filters enhances adversarial resistance
- **Low Confidence**: The generalization of these findings to complex spatial tasks like object detection or semantic segmentation

## Next Checks

1. **Architecture Transfer**: Test Chans-only training on MobileNetV2 and EfficientNet-B0 to verify the phenomenon extends beyond ResNet and ConvMixer architectures.

2. **Attack Generalization**: Evaluate Chans model robustness against stronger attacks (PGD-10, AutoAttack) and with standard adversarial training to determine if robustness is attack-specific.

3. **Task Complexity Scaling**: Apply Chans-only training to semantic segmentation (ADE20K) and object detection (COCO) to test whether the spatial mixing redundancy holds for spatially-varying prediction tasks.