---
ver: rpa2
title: 'SAS-Prompt: Large Language Models as Numerical Optimizers for Robot Self-Improvement'
arxiv_id: '2504.20459'
source_url: https://arxiv.org/abs/2504.20459
tags:
- robot
- table
- ball
- prompt
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents SAS-Prompt, a method enabling large language
  models (LLMs) to perform iterative self-improvement of robot policies through explainable
  numerical optimization. The key insight is that LLMs possess emergent capabilities
  for stochastic numerical optimization, which can be leveraged for policy search
  in robotics.
---

# SAS-Prompt: Large Language Models as Numerical Optimizers for Robot Self-Improvement

## Quick Facts
- arXiv ID: 2504.20459
- Source URL: https://arxiv.org/abs/2504.20459
- Reference count: 38
- Primary result: LLM achieves 39.4% Top-1 retrieval accuracy and successfully improves robot table tennis performance through iterative self-improvement

## Executive Summary
SAS-Prompt enables large language models to perform iterative self-improvement of robot policies through explainable numerical optimization. The method leverages LLMs' emergent capability for stochastic numerical optimization without explicit training, implementing a three-step process within a single prompt: summarize execution traces, analyze parameter effects, and synthesize improved parameters. Evaluated in robot table tennis, the approach successfully translates natural language objectives into improved control parameters, with retrieval experiments achieving 39.4% (Top-1), 68.89% (Top-5), and 83.70% (Top-10) accuracy. The method provides explainable learning steps through natural language justifications for parameter choices, offering a new family of policy search methods implemented entirely within an LLM.

## Method Summary
SAS-Prompt implements a four-step prompt-based optimization process where an LLM iteratively improves robot policies through natural language reasoning. The method maintains an in-context cache of execution traces (paddle/ball trajectories, landing positions, and 8 attenuation parameters) and processes this information through summarize (feature extraction from traces), analyze (reasoning about parameter effects), and synthesize (generating improved parameters) steps. The LLM modulates attenuation parameters that scale a lower-level controller's outputs in a robot table tennis task. New execution traces are appended to the context after each iteration, enabling cumulative improvement without external memory. The approach is evaluated both in simulation and on a real robot, demonstrating successful adaptation to user-specified objectives.

## Key Results
- Retrieval experiments: 39.4% Top-1, 68.89% Top-5, and 83.70% Top-10 accuracy for finding parameters matching natural language objectives
- Self-improvement: Robot successfully learns to hit balls to different table positions as specified by user objectives
- Optimization capability: LLM achieves 4.38±3.15 on 2D Ackley function vs. Adam's 6.22±5.31, with stronger performance in higher dimensions (8D)
- Explainability: Provides natural language justifications for parameter choices at each iteration

## Why This Works (Mechanism)

### Mechanism 1: LLM as Gradient-Free Optimizer
LLMs possess emergent capabilities for stochastic numerical optimization without explicit training. When provided with (x, f(x)) pairs, the LLM reasons about trends, identifies promising regions, and proposes new candidates—mimicking Bayesian-style exploration-exploitation tradeoffs via natural language. This capability is demonstrated by achieving 4.38±3.15 on 2D Ackley vs. Adam's 6.22±5.31, particularly strong in higher dimensions (8D). The core assumption is that pre-training on mathematical and scientific corpora transfers to sequential decision-making under uncertainty.

### Mechanism 2: Textual Gradient Approximation
The SAS prompt decomposes policy search into interpretable reasoning steps that approximate explicit gradient computation. The analyze step builds a "textual gradient" by correlating parameter changes with outcome shifts, which the synthesize step then applies to propose new parameters. This mimics policy gradient methods but operates entirely in natural language. Evidence shows the LLM correctly identifies parameter effects (e.g., "Increasing parameter g consistently shifts the landing position towards the right side"). The core assumption is that LLMs can reliably extract salient features and correlations from numerical tabular data presented in-context.

### Mechanism 3: Iterative Context Accumulation
Iterative context accumulation enables cumulative improvement without external memory or gradient storage. Each new execution trace is appended to the prompt, expanding the in-context cache. The LLM implicitly performs retrieval over this growing corpus to identify relevant prior examples, creating an episodic memory within the context window. Retrieval experiments show 39.4% Top-1, 68.89% Top-5, and 83.70% Top-10 accuracy with 100 in-context examples. The core assumption is that the LLM can maintain coherent reasoning across growing context without attention dilution.

## Foundational Learning

- **Gradient-free optimization**: Why needed? The entire method relies on black-box optimization where only function evaluations (not gradients) are available. Understanding exploration vs. exploitation, local vs. global optima, and sample efficiency is essential. Quick check: Can you explain why Nelder-Mead might fail on multi-modal functions compared to stochastic methods?

- **In-context learning**: Why needed? SAS-Prompt uses no weight updates—learning occurs purely through conditioning on demonstration examples. Understanding how transformers perform pattern completion from examples is critical. Quick check: What happens to in-context learning performance when demonstrations contain conflicting patterns?

- **Policy parameterization and residual policies**: Why needed? The LLM modulates attenuation parameters (θ ∈ R⁸) that scale a lower-level controller's outputs. Understanding how parameter changes propagate to behavior is needed to interpret LLM reasoning. Quick check: If attenuation parameters are bounded [0, 2], what happens when the LLM proposes θ = 2.5?

## Architecture Onboarding

- **Component map**: Execution Engine -> Trace Logger -> Context Buffer -> SAS Prompt Template -> LLM Query Interface -> Parameter Extraction -> Execution Engine

- **Critical path**: Initialize context buffer with seed examples → Compose SAS prompt with current buffer + user objective → Query LLM → extract proposed parameters → Execute on robot → record trace → Append trace to buffer → repeat

- **Design tradeoffs**: Context window size vs. iteration count (more iterations = better learning but risks context overflow); Trace detail vs. token economy (full trajectories provide more signal but consume context rapidly); Retrieval-only vs. synthesis (retrieval is safer; synthesis enables exploration)

- **Failure signatures**: Hallucinated correlations (LLM claims parameter X affects outcome Y without evidence); Context drift (later iterations ignore early examples); Objective misalignment (ambiguous instructions produce inconsistent retrieval)

- **First 3 experiments**: 1) Baseline optimization test: Replicate Ackley/Rastrigin experiments to verify LLM optimization capability; 2) Retrieval accuracy benchmark: Create 50+ diverse traces with known ground-truth rankings for 5+ objectives; 3) Ablation on prompt structure: Compare full SAS vs. synthesis-only to quantify value of explicit reasoning steps

## Open Questions the Paper Calls Out

### Open Question 1
How does SAS-Prompt scale to high-dimensional control problems (>20 parameters) compared to traditional policy gradient methods? The paper states hope to investigate scaling up to higher dimensionality tasks, but current experiments only test 8 parameters in a single domain. Comparative experiments on standard robotics benchmarks with >20 control parameters would resolve this.

### Open Question 2
What is the relationship between context window size and optimization performance, and can memory limitations be mitigated? The method relies on expanding in-context cache but context windows are finite. The paper does not analyze how many iterations can run before context saturation or whether selective trace summarization preserves optimization quality.

### Open Question 3
How robust is SAS-Prompt to ambiguous or conflicting natural language objectives? Retrieval experiments show objectives like "Land the ball in the middle" achieve <10% Top-1 accuracy due to ambiguity. The paper does not propose mechanisms for handling underspecified objectives or requesting clarification.

## Limitations
- Performance may degrade significantly on high-dimensional problems (>8 parameters) where LLM optimization capability is less established
- The method relies on a specific LLM (Gemini 1.5 Pro) without full prompt disclosure, creating reproducibility challenges
- Context window limitations restrict the number of iterations possible before information loss or saturation

## Confidence

- **High confidence**: LLM demonstrates gradient-free optimization capability on benchmark functions (Ackley, Rastrigin) - supported by quantitative comparisons with Adam optimizer
- **Medium confidence**: SAS-Prompt successfully improves robot table tennis performance through explainable iterations - supported by retrieval accuracy metrics but limited to one task domain
- **Low confidence**: The LLM's reasoning process genuinely approximates gradient computation - the textual gradient analogy is intuitive but lacks formal mathematical validation

## Next Checks

1. **Cross-domain generalization**: Test SAS-Prompt on a different robotic task (e.g., reaching or navigation) to verify the method extends beyond table tennis, measuring both optimization quality and explanation coherence

2. **Scaling analysis**: Systematically vary parameter dimensions (2D → 16D) and trace complexity to identify when the LLM's optimization capability degrades, quantifying the context window and dimensionality limits

3. **Interpretability audit**: Conduct ablation studies removing each SAS step (summarize, analyze, synthesize) to quantify their individual contributions to performance and assess whether the "explainable" aspects provide genuine insight or post-hoc rationalization