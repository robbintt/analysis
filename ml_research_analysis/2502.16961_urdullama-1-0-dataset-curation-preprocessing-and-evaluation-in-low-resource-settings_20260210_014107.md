---
ver: rpa2
title: 'UrduLLaMA 1.0: Dataset Curation, Preprocessing, and Evaluation in Low-Resource
  Settings'
arxiv_id: '2502.16961'
source_url: https://arxiv.org/abs/2502.16961
tags:
- language
- urdu
- dataset
- data
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents UrduLLaMA 1.0, an instruction-tuned LLM for
  the Urdu language, developed by continual pretraining Llama-3.1-8B-Instruct on 128M
  Urdu tokens, followed by instruction fine-tuning on 41k Urdu instructions and MT
  fine-tuning on 50k English-Urdu pairs. The model achieves BLEU scores of 28.01 (in-house),
  13.12 (TICO-19), and 15.16 (Tatoeba) in Urdu MT tasks, outperforming the base Llama-3.1-8B-Instruct
  and other SOTA models.
---

# UrduLLaMA 1.0: Dataset Curation, Preprocessing, and Evaluation in Low-Resource Settings

## Quick Facts
- arXiv ID: 2502.16961
- Source URL: https://arxiv.org/abs/2502.16961
- Reference count: 11
- Model achieves BLEU scores of 28.01 (in-house), 13.12 (TICO-19), and 15.16 (Tatoeba) in Urdu MT tasks

## Executive Summary
UrduLLaMA 1.0 presents a specialized Urdu language model developed through continual pretraining of Llama-3.1-8B-Instruct on 128M Urdu tokens, followed by instruction fine-tuning on 41k Urdu instructions and machine translation fine-tuning on 50k English-Urdu pairs. The model demonstrates superior translation quality compared to the base Llama-3.1-8B-Instruct and other SOTA models, with human evaluation by native Urdu linguists confirming its performance. Despite achieving promising results, the model faces limitations including computational constraints that limited training data to only 11% of the curated dataset, lack of safety guardrails, and limited evaluation scope beyond translation tasks.

## Method Summary
The authors developed UrduLLaMA 1.0 through a multi-stage approach: first, continual pretraining Llama-3.1-8B-Instruct on 128 million Urdu tokens curated from diverse sources including Urdu Wikipedia, news articles, and social media content; second, instruction fine-tuning on 41,000 Urdu instructions to improve conversational capabilities; and third, machine translation fine-tuning on 50,000 English-Urdu parallel pairs covering banking and legal domains. The model was evaluated using BLEU scores on multiple datasets (in-house, TICO-19, Tatoeba) and human evaluation by native Urdu linguists. Due to computational constraints, only a fraction of the curated 1.14 billion tokens were used for training.

## Key Results
- Achieved BLEU score of 28.01 on in-house Urdu-English translation evaluation
- Outperformed base Llama-3.1-8B-Instruct and other SOTA models in human evaluation
- Scored 13.12 on TICO-19 and 15.16 on Tatoeba machine translation benchmarks

## Why This Works (Mechanism)
The model's success stems from domain-specific fine-tuning that adapts the base Llama-3.1-8B-Instruct to Urdu linguistic patterns and cultural context. By combining large-scale pretraining with targeted instruction and MT fine-tuning, the model develops both general language understanding and specialized translation capabilities. The multi-stage training approach allows the model to first establish broad linguistic competence before specializing in Urdu-specific tasks and translation between English and Urdu.

## Foundational Learning
- **BLEU Score**: Metric for evaluating machine translation quality by comparing n-gram overlap between candidate and reference translations; needed to quantify translation performance objectively; quick check: compute on held-out test set
- **Pretraining vs Fine-tuning**: Pretraining establishes general language understanding on large corpus, while fine-tuning adapts to specific tasks; needed to build competence before specialization; quick check: compare performance on task-specific vs general prompts
- **Instruction Tuning**: Process of adapting models to follow human instructions through supervised learning; needed to improve model's ability to understand and execute user commands; quick check: test on diverse instruction-following benchmarks
- **Low-Resource Language Modeling**: Techniques for developing models when limited training data exists; needed because Urdu lacks the massive corpora available for high-resource languages; quick check: measure perplexity on held-out Urdu text
- **Human Evaluation in NLP**: Expert assessment of model outputs beyond automated metrics; needed to capture qualitative aspects of translation quality; quick check: conduct inter-annotator agreement analysis
- **Cross-lingual Transfer**: Leveraging knowledge from high-resource languages (English) to improve low-resource language models; needed to compensate for limited Urdu data; quick check: compare with monolingual Urdu models

## Architecture Onboarding

**Component Map:** Llama-3.1-8B-Instruct -> Urdu Pretraining -> Instruction Fine-tuning -> MT Fine-tuning -> Evaluation

**Critical Path:** The sequence from pretraining through MT fine-tuning is critical - skipping pretraining would result in poor Urdu linguistic understanding, while omitting MT fine-tuning would yield inadequate translation performance.

**Design Tradeoffs:** The choice of 128M training tokens represents a compromise between computational cost and model capability. Larger training would likely improve cultural nuance capture but was infeasible due to hardware limitations. The focus on banking and legal domains in MT fine-tuning provides depth but may limit general translation performance.

**Failure Signatures:** Poor performance on culturally specific references or idiomatic expressions indicates insufficient pretraining data. Inability to handle diverse domains suggests overfitting to training domains. Safety issues or offensive content generation point to missing detoxification processes.

**First Experiments:**
1. Evaluate baseline Llama-3.1-8B-Instruct on Urdu-English translation to establish pretraining performance
2. Test UrduLLaMA on general Urdu language understanding tasks (summarization, question answering)
3. Assess safety by generating responses to potentially harmful prompts and measuring refusal rates

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent does scaling training from the constrained 128 million tokens to the full curated 1.14 billion tokens improve the model's capture of Urdu cultural and literary nuances?
- Basis in paper: [explicit] The authors explicitly state that due to "computational and cost constraints," they trained on only a limited portion of the data, resulting in "gaps in knowledge, particularly in capturing the nuances of Urdu culture and literature."
- Why unresolved: The authors could not perform this experiment due to hardware limitations.
- What evidence would resolve it: A comparative study evaluating cultural literacy and perplexity between the current model and a version trained on the full 1.14 billion token dataset.

### Open Question 2
- Question: What alignment or detoxification methods are most effective for mitigating harmful content generation in Urdu LLMs without sacrificing translation fluency?
- Basis in paper: [explicit] The paper notes in the Limitations section that "detoxification processes were not incorporated," leaving the model "uncensored and potentially prone to generating harmful or offensive content."
- Why unresolved: The researchers did not implement safety guardrails, and the impact of such guardrails on low-resource language fluency is not discussed.
- What evidence would resolve it: Red-teaming evaluation results and safety benchmarks (e.g., comparing harmful refusal rates) before and after applying RLHF or DPO to UrduLLaMA.

### Open Question 3
- Question: How can a comprehensive, standardized evaluation suite be developed for Urdu to assess capabilities beyond machine translation?
- Basis in paper: [explicit] The authors cite the "lack of standardized benchmarks outside the European linguistic domain" and admit their evaluation is "limited in scope" regarding diverse applications.
- Why unresolved: The field lacks Urdu-specific benchmarks for tasks like reasoning or summarization, and this paper focuses primarily on translation metrics (BLEU).
- What evidence would resolve it: The construction of a multi-task Urdu benchmark (similar to MMLU) and subsequent testing of UrduLLaMA on non-translation tasks.

### Open Question 4
- Question: Can domain-mixing strategies improve UrduLLaMA's out-of-domain translation performance to rival specialized models like seamless-m4t-v2-large?
- Basis in paper: [inferred] Human evaluation showed that while UrduLLaMA excelled on the in-house dataset, it lagged behind seamless-m4t-v2-large on TICO-19 and Tatoeba, indicating a potential domain overfitting issue.
- Why unresolved: The paper highlights the gap with SOTA models on general-purpose translation but does not propose a methodology to close it.
- What evidence would resolve it: Performance metrics on TICO-19 and Tatoeba after fine-tuning on a more diverse mixture of domains rather than primarily banking/law data.

## Limitations
- Computational constraints limited training to only 128M tokens out of 1.14B curated tokens, potentially missing cultural and literary nuances
- No safety guardrails or detoxification processes were implemented, leaving the model uncensored
- Evaluation is limited primarily to translation tasks without comprehensive assessment of general language understanding capabilities
- In-house BLEU evaluation methodology lacks transparency and cannot be independently verified

## Confidence

**BLEU Score Claims: Low** - in-house evaluation methodology not disclosed
**Human Evaluation Results: Medium** - lacks methodological detail and statistical validation  
**Benchmark Claims: Low** - insufficient comparative analysis and limited evaluation scope

## Next Checks

1. Replicate the in-house BLEU evaluation using publicly available Urdu-English parallel datasets with standardized evaluation protocols
2. Conduct comprehensive human evaluation with detailed methodology including inter-annotator agreement scores and clear evaluation criteria
3. Benchmark against multiple existing Urdu language models on diverse tasks including reasoning, generation, and classification to validate "SOTA" claims beyond translation