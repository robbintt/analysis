---
ver: rpa2
title: Unified Class and Domain Incremental Learning with Mixture of Experts for Indoor
  Localization
arxiv_id: '2511.17829'
source_url: https://arxiv.org/abs/2511.17829
tags:
- localization
- learning
- indoor
- region
- moelo
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MOELO introduces a unified continual learning framework for indoor
  localization that jointly addresses domain-incremental and class-incremental learning
  scenarios. It employs a mixture-of-experts architecture with an equiangular tight
  frame-based gating mechanism to dynamically route Wi-Fi RSS fingerprints to region-specific
  experts, enabling efficient adaptation to both new devices and new indoor locations.
---

# Unified Class and Domain Incremental Learning with Mixture of Experts for Indoor Localization

## Quick Facts
- arXiv ID: 2511.17829
- Source URL: https://arxiv.org/abs/2511.17829
- Authors: Akhil Singampalli; Sudeep Pasricha
- Reference count: 32
- MOELO achieves up to 25.6× lower mean localization error, 44.5× lower worst-case error, and 21.5× less forgetting across diverse indoor environments

## Executive Summary
MOELO introduces a unified continual learning framework for indoor localization that jointly addresses domain-incremental and class-incremental learning scenarios. It employs a mixture-of-experts architecture with an equiangular tight frame-based gating mechanism to dynamically route Wi-Fi RSS fingerprints to region-specific experts, enabling efficient adaptation to both new devices and new indoor locations. A shared encoder produces device-invariant latent representations, while balanced replay prototypes maintain knowledge retention across incremental updates.

The framework demonstrates significant improvements over state-of-the-art methods, achieving up to 25.6× lower mean localization error, 44.5× lower worst-case error, and 21.5× less forgetting across diverse buildings, mobile devices, and continual learning scenarios. MOELO maintains a compact model footprint and low inference latency, making it suitable for resource-limited mobile devices while effectively handling the challenges of indoor localization in dynamic environments.

## Method Summary
MOELO utilizes a mixture-of-experts (MoE) architecture where each expert specializes in specific regions of the indoor environment. The framework incorporates a shared encoder that transforms device-specific Wi-Fi RSS fingerprints into device-invariant latent representations. An equiangular tight frame-based gating mechanism dynamically routes these representations to the most appropriate expert based on the current input characteristics. Balanced replay prototypes are maintained to preserve knowledge from previously encountered domains and classes, preventing catastrophic forgetting during incremental learning updates.

## Key Results
- Achieves up to 25.6× lower mean localization error compared to state-of-the-art frameworks
- Demonstrates 44.5× lower worst-case error across diverse indoor environments
- Shows 21.5× less forgetting during incremental learning updates

## Why This Works (Mechanism)
The framework's effectiveness stems from its ability to simultaneously handle two distinct incremental learning scenarios: domain-incremental learning (adapting to new devices with different RSS fingerprint characteristics) and class-incremental learning (learning new indoor locations without forgetting previously learned ones). The mixture-of-experts architecture allows for specialized knowledge acquisition in different environmental regions, while the gating mechanism ensures appropriate routing of inputs to relevant experts. The shared encoder creates device-invariant representations that enable cross-device generalization, and balanced replay prototypes maintain a compact memory of past knowledge without requiring full dataset storage.

## Foundational Learning
- **Continual Learning**: Enables model adaptation to new data without forgetting previous knowledge - needed because indoor localization systems must adapt to new environments and devices over time
- **Domain-Incremental Learning**: Handles changes in input distribution when switching between different devices - needed because Wi-Fi RSS fingerprints vary significantly across mobile devices
- **Class-Incremental Learning**: Allows addition of new location classes without retraining on old data - needed because indoor spaces expand and new rooms/locations are discovered
- **Mixture-of-Experts**: Distributes specialized knowledge across multiple expert networks - needed to handle the diverse characteristics of different indoor regions
- **Equiangular Tight Frames**: Provides optimal basis for feature representation and routing - needed for efficient and discriminative gating decisions
- **Balanced Replay**: Maintains representative samples from all learned domains/classes - needed to prevent catastrophic forgetting during incremental updates

## Architecture Onboarding

**Component Map**: Wi-Fi RSS Input -> Shared Encoder -> Equiangular Tight Frame Gating -> Region-Specific Experts -> Position Output

**Critical Path**: The shared encoder transforms raw RSS fingerprints into device-invariant representations, which are then routed through the equiangular tight frame gating mechanism to the most appropriate expert network. Each expert processes the input based on its specialization in specific indoor regions, and the outputs are combined to produce the final position estimate.

**Design Tradeoffs**: The framework balances between model capacity (multiple experts) and efficiency (compact representation through shared encoder). The gating mechanism adds routing complexity but enables specialization, while balanced replay maintains knowledge retention at the cost of additional memory for prototype storage.

**Failure Signatures**: Performance degradation may occur when RSS fingerprints from new devices significantly differ from training distribution, when indoor environments have highly similar RSS patterns across regions, or when the number of experts becomes insufficient for complex multi-building scenarios.

**First Experiments**:
1. Single-device, single-building localization to establish baseline performance
2. Cross-device localization testing to evaluate device-invariant representation effectiveness
3. Incremental addition of new indoor locations to measure class-incremental learning capability

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation is constrained to a single Wi-Fi fingerprint dataset from four buildings in Xi-Fi'an, China, limiting generalizability to other indoor environments
- Reported performance improvements are relative measures that may not translate to absolute performance standards acceptable for real-world deployment
- Computational efficiency claims are based on laboratory conditions without consideration for dynamic interference patterns, multi-path effects, or device heterogeneity

## Confidence
- Claims about framework architecture and theoretical foundations: **High**
- Claims about relative performance improvements over baselines: **Medium**
- Claims about real-world applicability and computational efficiency: **Low**

## Next Checks
1. Cross-dataset validation: Test MOELO on independent Wi-Fi fingerprint datasets from different geographical regions, building architectures, and environmental conditions to verify generalizability beyond the CRA16 dataset.
2. Real-time deployment analysis: Conduct field trials with multiple concurrent users, varying device types, and dynamic environmental conditions to assess actual inference latency and memory footprint under operational stress.
3. Robustness testing: Evaluate framework performance under adversarial conditions including signal jamming, device orientation changes, and temporal variations in RSSI distributions to determine practical limitations.