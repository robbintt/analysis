---
ver: rpa2
title: Predicting Compact Phrasal Rewrites with Large Language Models for ASR Post
  Editing
arxiv_id: '2501.13831'
source_url: https://arxiv.org/abs/2501.13831
tags:
- span
- phrase
- representations
- target
- output
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces two compact phrasal rewrite representations
  for efficient text rewriting using large language models. The span representation
  encodes edits as numerical spans with target phrases, while the phrase pair representation
  uses source-target phrase pairs with optional dilation for context.
---

# Predicting Compact Phrasal Rewrites with Large Language Models for ASR Post Editing

## Quick Facts
- arXiv ID: 2501.13831
- Source URL: https://arxiv.org/abs/2501.13831
- Authors: Hao Zhang; Felix Stahlberg; Shankar Kumar
- Reference count: 19
- Key outcome: Target-only representation achieves 3.0 WER with 6 tokens average output length, closing 57-54% of accuracy gap while retaining 80-78% of efficiency

## Executive Summary
This paper introduces compact phrasal rewrite representations for efficient text rewriting using large language models, specifically targeting ASR post-editing tasks. The authors propose three representations: span encoding, phrase pairs, and a target-only approach that uses only target phrases with context. Applied to LibriSpeech, the target-only representation achieves significant efficiency gains while maintaining good accuracy, representing a practical trade-off between quality and compactness.

## Method Summary
The paper presents three compact representations for text rewriting: span encoding (numerical spans with target phrases), phrase pairs (source-target phrase pairs with optional dilation for context), and a target-only representation (only target phrases with surrounding context words). These representations aim to reduce token usage while maintaining editing accuracy for ASR post-editing tasks. The authors evaluate these approaches on the LibriSpeech dataset, comparing them against full rewrite baselines and analyzing the trade-off between efficiency and accuracy through WER and average output length metrics.

## Key Results
- Target-only representation achieves 3.0 WER with 6 tokens average output length
- Closes 57-54% of accuracy gap between span representation and full rewrite
- Retains 80-78% of span representation's efficiency
- Span representation achieves 6.6 WER on LibriSpeech dataset

## Why This Works (Mechanism)
The compact phrasal rewrite representations work by reducing the token sequence length needed to specify edits while preserving sufficient information for accurate text transformation. By encoding edits as numerical spans, phrase pairs, or target-only phrases with context, the model can process shorter inputs more efficiently while still capturing the essential editing instructions. The target-only approach particularly benefits from leveraging surrounding context words to disambiguate edits, allowing it to achieve better accuracy-efficiency trade-offs.

## Foundational Learning
- **Span representation**: Encodes edits as numerical spans with target phrases - needed to provide explicit positional information for precise edits, quick check: verify span coordinates match source text positions
- **Phrase pair representation**: Uses source-target phrase pairs with optional dilation - needed to capture edit context while maintaining compactness, quick check: ensure dilation captures sufficient surrounding context
- **Target-only representation**: Uses only target phrases with context words - needed to minimize token usage while maintaining disambiguation, quick check: validate context words provide sufficient editing guidance
- **ASR post-editing**: Process of correcting automatic speech recognition errors - needed as the application domain for evaluating representations, quick check: confirm error types match typical ASR patterns
- **WER (Word Error Rate)**: Standard metric for measuring ASR output quality - needed to quantify editing accuracy, quick check: verify WER calculation follows standard conventions
- **Token efficiency**: Measure of input/output token economy - needed to evaluate the compactness advantage of representations, quick check: count tokens accurately including special tokens

## Architecture Onboarding

**Component Map**: Input text -> Compact representation encoder -> LLM rewriter -> Output text

**Critical Path**: Source text → Compact representation → LLM generation → Post-processed output

**Design Tradeoffs**: The paper balances between representation compactness and editing accuracy. The span representation provides explicit positional information but requires more tokens. Phrase pairs offer context flexibility through dilation but add complexity. The target-only approach minimizes tokens but relies heavily on context for disambiguation.

**Failure Signatures**: 
- Incorrect span coordinates leading to wrong edit locations
- Insufficient context in phrase pairs causing ambiguous edits
- Target-only representation failing when context words don't disambiguate edits
- Temperature settings affecting the balance between accuracy and diversity

**First Experiments**:
1. Compare WER across all three representations on a small validation set
2. Test different dilation widths for phrase pair representation
3. Evaluate temperature sensitivity of target-only representation performance

## Open Questions the Paper Calls Out
None

## Limitations
- Comparison against full rewrite baselines is limited, with full rewrite results appearing only in relative improvement calculations
- Evaluation focuses solely on WER and average output length, without examining other quality metrics like fluency or semantic preservation
- Experiments use only the LibriSpeech dataset, limiting generalizability to other ASR domains or languages
- The target-only representation's performance advantage may be influenced by specific decoding strategies and temperature settings

## Confidence
- Span representation effectiveness: High
- Phrase pair representation trade-offs: Medium
- Target-only representation superiority: Low
- Generalizability to other domains: Low

## Next Checks
1. Test the target-only representation across multiple ASR datasets and language pairs to verify if the 57-54% accuracy gap closure holds consistently
2. Compare the target-only representation against human reference edits to assess whether it captures the same types of corrections or introduces systematic biases
3. Evaluate the representations using additional quality metrics beyond WER, including semantic preservation scores and fluency assessments, to ensure the target-only approach doesn't compromise meaning for brevity