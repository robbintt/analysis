---
ver: rpa2
title: Spike-timing-dependent Hebbian learning as noisy gradient descent
arxiv_id: '2505.10272'
source_url: https://arxiv.org/abs/2505.10272
tags:
- learning
- gradient
- spike
- probability
- neuron
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper connects Hebbian spike-timing-dependent plasticity (STDP)
  rules to noisy gradient descent, providing a rigorous convergence analysis. The
  authors model a neural network with d input neurons and one output neuron, where
  synaptic weights evolve based on the relative timing of pre- and postsynaptic spikes.
---

# Spike-timing-dependent Hebbian learning as noisy gradient descent

## Quick Facts
- arXiv ID: 2505.10272
- Source URL: https://arxiv.org/abs/2505.10272
- Reference count: 40
- One-line primary result: STDP weight updates can be interpreted as noisy gradient descent on a non-convex loss function, achieving exponential convergence on a high-probability event despite constant noise injection.

## Executive Summary
This paper establishes a rigorous connection between Hebbian spike-timing-dependent plasticity (STDP) rules and noisy gradient descent on a non-convex loss function. The authors show that under certain conditions, a single output neuron converges exponentially fast to align with the input neuron having the highest mean firing rate. This convergence occurs on a high-probability event despite constant noise injection, which is surprising because typical noisy gradient descent only achieves stationary convergence. The analysis extends to time-inhomogeneous intensities and weakly correlated inputs, providing mathematical guarantees that go beyond ensemble averages.

## Method Summary
The method models a neural network with d input neurons and one output neuron, where synaptic weights evolve based on the relative timing of pre- and postsynaptic spikes. The key insight is that the multiplicative weight update can be transformed into a probability update that approximates noisy gradient descent on a non-convex loss function defined on the probability simplex. The convergence analysis uses tools from stochastic process theory, including martingale concentration bounds and Doob's submartingale inequality. The proof shows that on a high-probability event where the leading probability maintains a margin over competitors, linear convergence can be achieved with constant learning rate, unlike typical noisy gradient descent which only converges to a stationary regime.

## Key Results
- Hebbian STDP weight updates can be expressed as noisy gradient descent on a non-convex loss function L(p) = -(1/3)Σpᵢ³ + (1/4)(Σpᵢ²)²
- The output neuron converges exponentially fast to align with the input neuron of highest mean firing rate on a high-probability event
- Linear convergence with constant learning rate is achievable despite constant noise injection, which is unusual for noisy gradient descent
- The analysis extends to time-inhomogeneous intensities and weakly correlated inputs, with convergence to eigenvectors of the correlation matrix Γ

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The Hebbian STDP weight update can be expressed as noisy gradient descent on a non-convex loss function defined on the probability simplex.
- **Mechanism:** The multiplicative weight update w(k+1) = w(k) ⊙ (1 + α(B(k) + Z(k))) transforms into p(k+1) ≈ p(k) − α∇L(p(k)) + αξ(k), where L(p) = −(1/3)p^T(p⊙p) + (1/4)‖p‖⁴ and ξ(k) is centered noise. The gradient ∇L(p) = −p ⊙ (p − ‖p‖²1) drives probabilities toward standard basis vectors (local minima).
- **Core assumption:** The learning rate α is sufficiently small relative to the initial probability gap Δ and noise bound Q.
- **Evidence anchors:**
  - [abstract] "We relate a Hebbian spike-timing-dependent plasticity rule to noisy gradient descent with respect to a non-convex loss function on the probability simplex."
  - [section 2, Eq. 5-6] Shows exact decomposition into gradient plus centered noise.
  - [corpus] "Heterosynaptic Circuits Are Universal Gradient Machines" supports gradient-based interpretations of plasticity, but provides different mechanistic foundations.
- **Break condition:** If α exceeds the bound in Theorem 2.2 (∝ Δ²/(16Q²)), the Taylor approximation error dominates and convergence guarantees fail.

### Mechanism 2
- **Claim:** Convergence occurs on a high-probability event Θ where the leading probability maintains a margin over competitors, enabling linear convergence despite constant noise injection.
- **Mechanism:** Define Θ = {p₁(k) ≥ max_{i≠1} p_i(k) + Δ/2, ∀k}. On Θ, the gradient satisfies p₁(p₁ − ‖p‖²) ≳ (1−p₁), giving exponential decay. The probability of Θ is bounded via Doob's submartingale inequality applied to the cumulative noise martingale M(k) = Σ αξ(k). Because noise variance scales with (1−p₁(k)) which itself decays, the martingale variance is summable, allowing constant learning rate.
- **Core assumption:** Initial gap Δ = p₁(0) − max_{i≠1} p_i(0) > 0 exists.
- **Evidence anchors:**
  - [section 2.1, Theorem 2.2] "E[‖p(k) − e₁‖₁ 1_Θ] ≤ 2(1−p₁(0)) exp(−αΔ²k/16d) for all k"
  - [section A.1, proof sketch] Details the 5-step argument using martingale concentration.
  - [corpus] "Sleep-Based Homeostatic Regularization" addresses stability in recurrent STDP but uses different mechanisms (homeostatic bounds).
- **Break condition:** If the noise realization pushes p₁(k) − max_{i≠1} p_i(k) below Δ/2, the favorable event fails and convergence is not guaranteed by this analysis.

### Mechanism 3
- **Claim:** The learning dynamic implements entropic mirror descent (natural gradient descent) on the probability simplex with respect to the Fisher information metric.
- **Mechanism:** The gradient flow dp/dt = p ⊙ (p − ‖p‖²1) coincides with natural gradient flow for loss ẽL(p) = −‖p‖²/2 under the Shahshahani/Fisher metric g_p(u,v) = u^T diag(p)⁻¹v. This is the continuous limit of exponentiated gradient descent.
- **Core assumption:** The +‖p‖²1 term is orthogonal to the probability simplex tangent space and doesn't affect the Riemannian flow.
- **Evidence anchors:**
  - [section 3] Explicitly derives the natural gradient connection and relates to entropic mirror descent.
  - [section A.4] Shows discrete update approximates pi(k+1) = pi(k)exp(αp_i(k))/Z via first-order Taylor.
  - [corpus] Weak direct corpus support; "Homeostatic Ubiquity of Hebbian Dynamics" discusses L2-regularized learning converging to Hebbian directions but not mirror descent specifically.
- **Break condition:** Assumption: The +‖p‖²1 term remains orthogonal; violations would corrupt the natural gradient interpretation.

## Foundational Learning

- **Concept: Martingale concentration (Doob's submartingale inequality)**
  - Why needed here: The convergence proof relies on bounding the probability that cumulative noise stays small, which requires controlling martingale variance over infinite horizons.
  - Quick check question: Given a martingale M_n with E[M_n²] ≤ C, can you bound P(sup_{k≤n} |M_k| ≥ u)?

- **Concept: Taylor expansion of ratio dynamics**
  - Why needed here: Converting the multiplicative probability update into gradient-plus-noise form requires expanding f(x) = (1+ax)/(1+bx) around x=0 and bounding second-order error terms.
  - Quick check question: For f(x) = (1+ax)/(1+bx), what is f'(0) and f''(x)?

- **Concept: Replicator dynamics / evolutionary game theory**
  - Why needed here: The gradient flow coincides with replicator equations where fitness is p(t) or Γp(t), connecting to well-studied dynamical systems.
  - Quick check question: What are the fixed points of dx_i/dt = x_i(f_i(x) − x^T f(x)) on the simplex?

## Architecture Onboarding

- **Component map:** Input neurons (d) → Poisson spike sources with intensities λ₁,...,λ_d → Output neuron with membrane potential Y_t = Σ_j w_j(τ)e^{−(t−τ)} → Spike when Y_t ≥ S → Weight update w(k+1) = w(k) ⊙ (1 + α(B(k) + Z(k)))

- **Critical path:**
  1. Presynaptic spikes arrive → contribute to membrane potential
  2. Membrane potential crosses threshold → postsynaptic spike
  3. Postsynaptic spike triggers weight update → B(k) (one-hot winner) + Z(k) (noise from non-triggering spikes)
  4. Probabilities p(k) update → gradient step plus noise

- **Design tradeoffs:**
  - Learning rate α: Smaller α increases probability of convergence but slows rate; must satisfy α ≤ Δ²/(16Q²) × (complex bound from Theorem 2.2)
  - Threshold S vs weights: Model assumes weights ≪ S initially; large weights break probability approximation
  - Multiple outputs (Algorithm 1 vs 2): Joint updates are computationally simpler but lack convergence guarantees; sequential orthogonalization (Algorithm 2) has provable convergence

- **Failure signatures:**
  - Non-convergence: p(k) oscillates or plateaus away from basis vectors → learning rate too large or initial gap Δ insufficient
  - Wrong winner: Output aligns with suboptimal input → large early noise realization pushed wrong neuron ahead
  - Weight explosion: w(k) → ∞ → inherent to unbounded Hebbian; requires separate homeostatic phase
  - Correlation-induced errors: With high Γ_{i,j}, convergence may be to non-maximal eigenvector of Γ

- **First 3 experiments:**
  1. Verify convergence rate: Initialize with known Δ, set α per Theorem 2.2, measure ‖p(k) − e₁‖₁ over 10⁴ iterations across 100 seeds; confirm exponential decay envelope holds with probability > 1−ε.
  2. Stress-test learning rate: Systematically increase α beyond the theoretical bound; identify the threshold where convergence probability drops below 0.5.
  3. Validate noise robustness: Inject additional noise into Z(k) (e.g., increase Q bound) and measure how the required iterations for δ-accuracy scales; verify 1/α scaling predicted by the theorem.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can rigorous convergence guarantees be derived for the joint weight updates in Algorithm 1, where multiple output neurons learn simultaneously?
- Basis in paper: [explicit] Section 4 states that a rigorous mathematical analysis of Algorithm 1 is "challenging due to joint updates in all read-out neurons."
- Why unresolved: The current analysis relies on disjoint learning periods or single-neuron dynamics; joint updates introduce dependencies that complicate the probability flow analysis.
- What evidence would resolve it: A theoretical proof extending Theorem 2.2 to the matrix case $P(k) \to I$ without requiring sequential or disjoint learning periods.

### Open Question 2
- Question: Does the convergence behavior persist when extending the model to include inhibitory neurons and multi-layered architectures?
- Basis in paper: [explicit] In Section 5, the authors state: "It is natural to generalise the setting to account for inhibitory neurons and more than one layer."
- Why unresolved: The current framework assumes a single layer of exclusively excitatory presynaptic neurons connected to output neurons.
- What evidence would resolve it: Convergence analysis (e.g., modification of Theorem 2.2) applied to a network dynamics model incorporating inhibitory feedback or deeper layers.

### Open Question 3
- Question: Can the analysis be extended to time-dependent mean firing rates that are piecewise constant, corresponding to successive exposure to different input patterns?
- Basis in paper: [explicit] Section 5 identifies "considering time-dependent mean firing rates that are piecewise constant, corresponding to the successive exposition to different input patterns" as a scenario lying beyond the current mathematical analysis.
- Why unresolved: The current analysis covers time-inhomogeneous intensities but does not rigorously prove convergence for discrete shifts in input statistics (piecewise constant $\lambda$).
- What evidence would resolve it: A theorem demonstrating that the dynamic tracks the shifting maximizer or converges within the intervals of constant intensity.

## Limitations

- The convergence analysis relies on a high-probability event that is not explicitly bounded in terms of problem parameters, making it difficult to quantify the probability of convergence failure.
- The extension to time-inhomogeneous intensities or correlated inputs requires stronger assumptions (bounded eigenvalue spread) that may not hold in biological settings.
- The analysis becomes technically challenging when extending to multiple output neurons learning simultaneously, as joint updates introduce dependencies that complicate the probability flow analysis.

## Confidence

- **High**: The gradient-descent connection (Mechanism 1) and basic update rules are mathematically rigorous and well-established.
- **Medium**: The high-probability convergence result (Mechanism 2) is sound but depends on martingale concentration arguments that become complex with constant noise injection.
- **Low**: The natural gradient interpretation (Mechanism 3) provides conceptual insight but relies on continuous-time approximations that may not fully capture discrete dynamics.

## Next Checks

1. **Quantify Θ probability decay**: For fixed α, Δ, d, compute P(Θ^c) as a function of iteration count k to verify the claim that convergence holds on a high-probability event that doesn't vanish too quickly.

2. **Test multiple output neurons**: Implement Algorithm 2 for orthogonalizing weight vectors and verify linear convergence to dominant eigenvector subspace under various correlation structures Γ.

3. **Analyze correlation sensitivity**: Systematically vary the correlation matrix Γ and measure the eigenvalue gap λ₁ - λ₂ required for convergence to the correct output neuron, comparing with theoretical bounds.