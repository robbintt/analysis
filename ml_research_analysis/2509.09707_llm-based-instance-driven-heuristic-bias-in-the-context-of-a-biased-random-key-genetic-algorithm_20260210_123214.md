---
ver: rpa2
title: LLM-Based Instance-Driven Heuristic Bias In the Context of a Biased Random
  Key Genetic Algorithm
arxiv_id: '2509.09707'
source_url: https://arxiv.org/abs/2509.09707
tags:
- brkga
- metrics
- algorithm
- heuristic
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper introduces an LLM-augmented Biased Random-Key Genetic\
  \ Algorithm (BRKGA) for the NP-hard Longest Run Subsequence (LRS) problem. A human-LLM\
  \ collaborative process co-designs a set of instance-specific metrics, which the\
  \ LLM analyzes to produce a heuristic bias vector that guides the BRKGA\u2019s search."
---

# LLM-Based Instance-Driven Heuristic Bias In the Context of a Biased Random Key Genetic Algorithm

## Quick Facts
- arXiv ID: 2509.09707
- Source URL: https://arxiv.org/abs/2509.09707
- Reference count: 40
- Primary result: LLM-augmented BRKGA with instance-specific heuristic bias outperforms baseline on complex LRS instances

## Executive Summary
This paper introduces an LLM-augmented Biased Random-Key Genetic Algorithm (BRKGA) for the NP-hard Longest Run Subsequence (LRS) problem. A human-LLM collaborative process co-designs instance-specific metrics, which the LLM analyzes to produce a heuristic bias vector that guides the BRKGA's search toward promising solution areas. Evaluated on 1,050 synthetic LRS instances, the hybrid approach with Llama-4-Maverick significantly outperforms the baseline BRKGA, particularly on complex instances with large alphabets. The LLM-generated guidance is shown to be meaningful rather than random, and ablation studies validate both the metric set and the heuristic contribution.

## Method Summary
The method involves a four-phase pipeline: (1) Human-LLM metric co-design where LLM proposes instance-specific metrics for LRS, (2) Metric extraction pipeline computing run decompositions and four key metrics (normalized length, opportunity, density, quality) for each run, (3) LLM prompt execution via OpenRouter to generate alpha weights (metric importance) and beta values (target ideals) from the feature matrix, and (4) Modified BRKGA decoder that uses the bias vector L (computed from alpha, beta, and sigmoid influence function) to prioritize runs during greedy construction. The LLM analyzes a feature matrix F containing instance metrics per run and outputs parameters that steer the evolutionary search toward promising solution areas.

## Key Results
- BRKGA+Llama-4-Maverick achieves 2-5% improvement on complex LRS instances with large alphabets (|Σ|≥16)
- LLM-generated bias is meaningfully better than random bias, with ablation studies showing statistical significance
- Human curation of LLM-proposed metrics is critical for computational tractability, reducing pre-computation time from 300s to 8s
- Bias effectiveness increases with instance complexity, with BRKGA+Llama maintaining exploration while baseline converges to suboptimal basins

## Why This Works (Mechanism)

### Mechanism 1
LLM-generated instance-specific bias improves BRKGA search efficiency on complex combinatorial problems. The LLM analyzes a feature matrix F (instance metrics per run) and outputs alpha weights (metric importance) and beta values (target ideals). These parameterize a sigmoid-based influence function producing a probability vector L. In the decoder, runs are sorted by v·L rather than v alone, prioritizing LLM-identified promising components earlier in greedy construction. Core assumption: The LLM can extract meaningful heuristic patterns from numerical metric tables that correlate with solution quality. Evidence: [abstract] states the LLM "steers the BRKGA toward promising areas of the search space," [section 3.4] shows the modified decoder using v·L for prioritization, and [corpus] shows limited direct support as this extends OptiPattern [35] to string problems. Break condition: If metrics are uninformative or LLM outputs near-uniform weights, L provides no signal and performance degrades to random bias.

### Mechanism 2
Human curation of LLM-proposed metrics is critical for computational tractability, not just heuristic quality. LLM proposes n metrics; human filters to k based on near-linear complexity. Without filtering, metrics like "Sequence Break Potential" or "External Fragmentation Potential" cause pre-computation to scale super-linearly (8s → 300s for n=5000). Core assumption: LLMs cannot reliably assess algorithmic complexity of proposed metrics. Evidence: [section 4.6] shows "the calculation of the four randomly selected metrics required 300.06 seconds—more than 17 times longer," [section 3.2] states "Any metric that cannot be computed in near-linear time with respect to the input size is discarded," and [corpus] shows no corpus papers address LLM-based metric complexity assessment. Break condition: If computational budget is unlimited or instances are small, random metric selection achieves comparable solution quality (Table 5 shows 312.94 vs 313.07).

### Mechanism 3
Bias effectiveness increases with instance complexity (larger alphabets |Σ|). Complex instances (high |Σ|) have fragmented runs and more combinatorial noise. Standard BRKGA prematurely converges to suboptimal basins