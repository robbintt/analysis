---
ver: rpa2
title: Comparative Analysis of GAN and Diffusion for MRI-to-CT translation
arxiv_id: '2509.22049'
source_url: https://arxiv.org/abs/2509.22049
tags:
- translation
- image
- cddpm
- diffusion
- mri-to-ct
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper compares two architectures for generating synthetic
  CT images from MRI: a conditional GAN (Pix2Pix) and a conditional denoising diffusion
  probabilistic model (cDDPM, Palette). The authors frame the 3D task as a sequence
  of 2D translations and test both single-channel and multi-channel (adjacent slices)
  conditioning strategies.'
---

# Comparative Analysis of GAN and Diffusion for MRI-to-CT translation

## Quick Facts
- **arXiv ID**: 2509.22049
- **Source URL**: https://arxiv.org/abs/2509.22049
- **Reference count**: 36
- **Key outcome**: cDDPM models consistently outperform cGAN models across all metrics, with cDDPM3 (multi-channel) achieving the best SSIM (0.881), PSNR (26.620), and lowest FID (14.152)

## Executive Summary
This study compares conditional GAN (Pix2Pix) and conditional denoising diffusion probabilistic models (cDDPM, Palette) for MRI-to-CT translation. The authors frame the 3D task as a sequence of 2D translations and test both single-channel and multi-channel (adjacent slices) conditioning strategies. Metrics used include SSIM, PSNR, FID, SIMOS (slice continuity), and segmentation-based IoU. The cDDPM models consistently outperform the cGAN models across all metrics, with cDDPM3 (multi-channel) achieving the best SSIM (0.881), PSNR (26.620), and lowest FID (14.152). The cDDPM models also produced more visually coherent and structurally accurate synthetic CTs, with fewer discontinuities between slices. Multi-channel conditioning significantly improved continuity and image quality, especially for the cDDPM models. While the cGAN models trained and sampled faster, the cDDPM architecture delivered superior performance for MRI-to-CT translation.

## Method Summary
The study uses the SynthRAD2023 dataset with paired brain/pelvic MRI-CT volumes. CT images are clipped to [-1000, 2000] HU and min-max normalized to [0,1], while MRI images are clipped at the 98th percentile per-image. The task is framed as 2D slice translation, with single-slice and 3-slice multi-channel conditioning tested. Two architectures are compared: Pix2Pix (cGAN) with L1 loss and PatchGAN discriminator, and Palette (cDDPM) with iterative denoising. The cGAN uses λ=100, batch=10, lr=5e-5, and discriminator update every 10 steps over 625/685 epochs. The cDDPM uses lr=1e-4, L1 loss, train noise schedule (1e-6, 0.01) over 2000 steps, and inference 1000 steps linear (1e-4, 0.09) over 335/360 epochs. Evaluation includes SSIM, PSNR, FID, SIMOS (slice continuity), and segmentation IoU (TotalSegmentator 3D, SAM 2D on 50% test set).

## Key Results
- cDDPM models consistently outperform cGAN models across all metrics (SSIM, PSNR, FID, SIMOS, IoU)
- cDDPM3 (multi-channel) achieved the best SSIM (0.881), PSNR (26.620), and lowest FID (14.152)
- Multi-channel conditioning significantly improved continuity and image quality, especially for cDDPM models (SIMOS improved from 42.058 to 22.968)
- While cGAN models trained and sampled faster, cDDPM architecture delivered superior performance for MRI-to-CT translation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Iterative denoising in cDDPMs produces more structurally coherent translations than single-pass GAN generation.
- Mechanism: The cDDPM forward process corrupts CT images to Gaussian noise over T steps; the backward process learns to predict and remove noise conditioned on the MRI input. This iterative refinement (1000 steps at inference) allows progressive correction of structural errors rather than committing to a single output, reducing artifacts like the "hallucinations" noted in GAN outputs.
- Core assumption: The denoising network can learn to disentangle modality-specific features (MRI intensity patterns) from anatomy (shared between MRI and CT) when conditioned properly.
- Evidence anchors:
  - [abstract]: "cDDPM models consistently outperform the cGAN models across all metrics"
  - [section 3]: "Starting from t=T, noise is removed to denoise the synthetic image to noise level t-1 iteratively until t=0"
  - [corpus]: Lyu and Wang [17] cited in paper found "diffusion models are more suitable for the task, even without the advantage of a discriminator" and GANs tend to hallucinate "severe" artifacts
- Break condition: If noise schedule is poorly calibrated or training iterations are insufficient, the model produces "failed samples" with large noise and faint structures (as observed in early epochs during hyperparameter fitting).

### Mechanism 2
- Claim: Multi-channel conditioning (using adjacent MRI slices) improves slice-to-slice continuity in 3D volumes reconstructed from 2D translations.
- Mechanism: By providing the model with preceding and subsequent MRI slices as additional input channels, the generator receives explicit 3D spatial context. This allows the model to learn inter-slice relationships, reducing discontinuities when individual 2D predictions are stacked into 3D volumes.
- Core assumption: Adjacent slices contain sufficient information about 3D anatomical continuity that the model can learn to propagate into CT predictions.
- Evidence anchors:
  - [abstract]: "Multi-channel conditioning significantly improved continuity and image quality, especially for the cDDPM models"
  - [section 5 results]: "The most significant improvement from multi-channel input is detected in the cDDPM-based model" with SIMOS improving from 42.058 to 22.968
  - [corpus]: Related work by Tie et al. [29] cited, showing conditioning on three MRI slices improved results
- Break condition: If slice spacing is too large or anatomical structures change rapidly between slices (e.g., in regions with complex geometry), the multi-channel benefit may diminish.

### Mechanism 3
- Claim: Combining L1 pixel-wise loss with adversarial training in cGANs captures both low-frequency structure and high-frequency realism, but remains unstable for medical image translation.
- Mechanism: The Pix2Pix architecture uses L1 loss to penalize low-frequency errors (capturing overall structure) while the PatchGAN discriminator focuses on N×N patches to classify high-frequency realism. However, training instability arises when the discriminator becomes too effective too quickly, causing the generator to receive primarily negative feedback.
- Core assumption: The discriminator's patch-level focus will correctly identify medically relevant high-frequency features (bone edges, tissue boundaries) rather than texture artifacts.
- Evidence anchors:
  - [abstract]: "cDDPM models consistently outperform the cGAN models across all metrics"
  - [section 4.2]: "Early experimentation revealed an unstable training, due to the discriminator becoming too good at distinguishing real and fake images too fast"
  - [corpus]: Related work [14, 21] cited concludes "adversarial learning guides the generative process in a positive direction" but cDDPMs outperform even without this advantage
- Break condition: When discriminator update frequency is too high relative to generator learning capacity, training collapses; this was mitigated by reducing D_freq to 10 (updating discriminator every 10th data point).

## Foundational Learning

- Concept: **Denoising Diffusion Probabilistic Models (DDPMs)**
  - Why needed here: Understanding the forward/backward Markov chain process is essential for debugging sampling failures and selecting appropriate noise schedules.
  - Quick check question: Given a trained cDDPM, what happens if you start inference from t=500 instead of t=T (fully noised)?

- Concept: **Conditional Image-to-Image Translation**
  - Why needed here: Both architectures are conditional generative models where output distribution depends on input; understanding conditioning strategies (concatenation vs. other methods) is critical for multi-channel extensions.
  - Quick check question: How does concatenating the conditional image differ from other conditioning approaches like adaptive instance normalization?

- Concept: **GAN Training Dynamics and Mode Collapse**
  - Why needed here: The paper documents discriminator-generator imbalance issues; understanding this helps diagnose why D_freq adjustments were necessary.
  - Quick check question: If generator loss plateaus but discriminator accuracy approaches 100%, what does this indicate about training health?

## Architecture Onboarding

- Component map:
  ```
  Input Pipeline: NIfTI MRI/CT → Slice extraction → Intensity capping (98th percentile MRI, [-1000,2000] HU CT) → Min-max normalization → Single/multi-channel tensor
  
  cDDPM (Palette): Condition encoder (concatenation) → U-Net denoiser f_θ → Iterative denoising (T=1000 steps) → sCT output
  
  cGAN (Pix2Pix): Generator (U-Net) + Discriminator (PatchGAN) → L1 + Adversarial loss → Single-pass generation → sCT output
  
  Evaluation: SSIM, PSNR, FID, SIMOS (slice continuity), Segmentation IoU (2D via SAM, 3D via TotalSegmentator)
  ```

- Critical path:
  1. Data preprocessing (intensity capping is essential for MRI long-tail distributions)
  2. Architecture selection (cDDPM for quality, cGAN for speed)
  3. Hyperparameter tuning (learning rate, loss function L1 vs L2, discriminator frequency for cGAN)
  4. Multi-channel conditioning for improved continuity
  5. Model selection via validation metrics (watch for overfitting—SSIM/PSNR decrease after optimal epoch)

- Design tradeoffs:
  - cDDPM: Superior image quality (SSIM 0.881, FID 14.152) but 378× slower sampling (0.024 vs 9.042 samples/sec)
  - Multi-channel: Improved SIMOS (22.968 vs 42.058 for cDDPM) but slightly worse segmentation IoU (0.717 vs 0.741 for 3D)
  - 2D vs 3D architecture: Lower computational cost but introduces slice discontinuity issues requiring SIMOS monitoring

- Failure signatures:
  - "Failed samples" in cDDPM: Images with large noise and/or faint structures—indicates insufficient training epochs or poor latent space mapping
  - Discriminator dominance in cGAN: Unstable training with generator receiving only negative feedback—reduce D_freq
  - Slice discontinuity in 3D reconstructions: High SIMOS scores indicate need for multi-channel conditioning
  - Overfitting: SSIM/PSNR decrease on validation set after peak epoch (observed at epochs 625-685 for cGAN)

- First 3 experiments:
  1. **Baseline reproduction**: Train cGAN1 and cDDPM1 with single-channel input on a small subset, verify SIMOS and SSIM metrics fall within reported ranges (SSIM ~0.84-0.87) before scaling.
  2. **Ablation on conditioning**: Compare single vs. multi-channel conditioning on same architecture (cDDPM1 vs cDDPM3), focusing on SIMOS improvement to quantify 3D continuity gains.
  3. **Noise schedule sensitivity test**: Given cDDPM sampling is the bottleneck, test alternative schedules (cosine vs. linear) on a validation subset—Nichol and Dhariwal [19] suggest "negligible quality difference" with faster sampling.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the superior synthetic CTs generated by cDDPMs support accurate radiotherapy treatment planning comparable to real CTs?
- Basis in paper: [explicit] The authors state: "To evaluate applications in radiotherapy, our evaluation protocol could have been extended with a comparison of a treatment plan based on the sCT and the ground truth CT."
- Why unresolved: The study utilized image similarity metrics (SSIM, PSNR) and segmentation IoU as proxies for quality, but did not validate the images for the clinical task of dose calculation.
- What evidence would resolve it: A study comparing dose-volume histograms (DVHs) and gamma passing rates derived from treatment plans optimized on sCT versus ground truth CTs.

### Open Question 2
- Question: Does implementing a cosine noise schedule in cDDPMs maintain image quality while significantly reducing the sampling time disparity with cGANs?
- Basis in paper: [explicit] The authors note the computational cost of cDDPMs "could have been mitigated by using another noise schedule, such as a cosine noise schedule... while lowering sampling time."
- Why unresolved: The experiments utilized the Palette default (linear) schedule, leaving the specific trade-off between the suggested cosine schedule's speed and the reported SSIM/FID performance untested.
- What evidence would resolve it: A comparative ablation study measuring inference speed and image metrics (SSIM, FID) for cDDPM3 using cosine versus linear noise schedules.

### Open Question 3
- Question: What specific latent space instabilities cause cDDPMs to intermittently produce "failed samples" (noise/faint structures), and can this be eliminated?
- Basis in paper: [explicit] The authors observe that "cDDPM models frequently produced failed samples" and hypothesize that the model fails to "robustly map the latent space," causing the iterative process to drift.
- Why unresolved: While the paper documents the existence of these failures and their decrease over epochs, it does not isolate the root cause or a definitive architectural fix.
- What evidence would resolve it: A latent space analysis tracking the divergence of failed samples, or an experiment testing if specific regularization techniques prevent the iterative denoising process from drifting out of distribution.

## Limitations
- The study relies on a single dataset (SynthRAD2023) which may not capture full clinical variability
- The slice-by-slice 2D approach introduces potential discontinuities in 3D reconstructions
- cDDPM sampling speed (378× slower than cGAN) creates significant quality-efficiency trade-off
- Multi-channel conditioning assumes sufficient anatomical similarity between adjacent slices

## Confidence
- **High Confidence**: cDDPM models outperform cGAN models across all quantitative metrics (SSIM, PSNR, FID, SIMOS, IoU)
- **Medium Confidence**: Multi-channel conditioning improves slice continuity and overall image quality, particularly for cDDPM models
- **Medium Confidence**: The discriminator-generator imbalance in cGAN training can be mitigated through reduced discriminator update frequency

## Next Checks
1. **Clinical Relevance Validation**: Test whether cDDPM-generated CT images maintain diagnostic utility by comparing automated segmentation accuracy on real clinical datasets versus synthetic translations.

2. **3D Architecture Comparison**: Implement a direct 3D U-Net comparison against the slice-by-slice approach to quantify the computational trade-off between architectural complexity and output quality.

3. **Noise Schedule Ablation**: Systematically evaluate alternative noise schedules (cosine vs. linear) and their impact on sampling speed versus image quality to identify optimal trade-offs for clinical deployment.