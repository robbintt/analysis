---
ver: rpa2
title: Matrix Factorization with Dynamic Multi-view Clustering for Recommender System
arxiv_id: '2504.14565'
source_url: https://arxiv.org/abs/2504.14565
tags:
- centers
- user
- cluster
- clustering
- matrix
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Matrix Factorization with Dynamic Multi-view
  Clustering (MFDMC), a unified framework that addresses the computational inefficiency
  and interpretability issues of traditional matrix factorization methods in recommender
  systems. The core idea is to integrate dynamic multi-view clustering into the matrix
  factorization process, where user and item representations are decomposed into multiple
  views and dynamically updated clusters.
---

# Matrix Factorization with Dynamic Multi-view Clustering for Recommender System

## Quick Facts
- **arXiv ID:** 2504.14565
- **Source URL:** https://arxiv.org/abs/2504.14565
- **Reference count:** 40
- **Primary result:** MFDMC reduces RMSE by up to 0.025 vs FunkMF on MovieLens-100k

## Executive Summary
Matrix Factorization with Dynamic Multi-view Clustering (MFDMC) addresses computational inefficiency and interpretability issues in traditional recommender systems by integrating dynamic multi-view clustering into the matrix factorization process. The method decomposes user and item representations into multiple views and dynamically updates clusters, optimizing latent space utilization and improving interpretability. Experiments on six real-world datasets demonstrate superior performance, with MFDMC achieving up to 0.025 RMSE reduction compared to FunkMF on MovieLens-100k. The approach also generalizes to computer vision tasks, showcasing scalability and versatility.

## Method Summary
MFDMC integrates dynamic multi-view clustering into matrix factorization by decomposing user and item latent vectors into weighted sums of cluster centers across multiple views. The model initializes with 10 clusters per view and dynamically prunes centers based on mean weight thresholds starting at epoch 40. Training optimizes four loss components: matrix factorization prediction loss (MSE), spread loss with margin $\rho$, proximity loss, and entropy loss with custom mapping. The entropy loss normalizes across views with varying center counts to prevent domination by larger views. Visualization techniques validate interpretability by linking clusters to semantic attributes like movie categories and user preferences.

## Key Results
- MFDMC achieves up to 0.025 RMSE reduction vs FunkMF on MovieLens-100k
- Method generalizes to computer vision tasks, demonstrating scalability
- Visualization validates interpretability by linking clusters to semantic attributes

## Why This Works (Mechanism)
MFDMC improves upon traditional matrix factorization by addressing two key limitations: computational inefficiency and lack of interpretability. By decomposing latent vectors into multiple views with dynamic clustering, the method creates a more structured latent space that better captures user-item relationships. The dynamic pruning mechanism removes redundant clusters, reducing computational overhead while maintaining performance. The multi-view approach allows the model to capture different aspects of user preferences and item characteristics, leading to more robust representations. The entropy-based regularization ensures balanced cluster utilization across views, preventing any single view from dominating the representation.

## Foundational Learning
- **Dynamic cluster pruning:** Needed to maintain computational efficiency as the number of clusters can grow during training. Quick check: Monitor cluster count per view during training to ensure pruning occurs as expected.
- **Multi-view decomposition:** Allows capturing different aspects of user preferences and item characteristics. Quick check: Verify that different views capture distinct semantic attributes (e.g., genre vs. rating patterns).
- **Entropy regularization across views:** Prevents domination by larger views and ensures balanced utilization. Quick check: Confirm that entropy values are normalized correctly across views with different center counts.

## Architecture Onboarding
**Component map:** Data -> MF Prediction -> Losses (MF, Spread, Proximity, Entropy) -> Cluster Pruning -> Updated representations

**Critical path:** Forward pass computes latent vectors using Eq. 2, predicts ratings via dot product, calculates combined loss, performs backpropagation, and updates cluster centers and weights. Pruning occurs every epoch after epoch 40 based on mean weight thresholds.

**Design tradeoffs:** The multi-view approach increases model complexity but improves interpretability and performance. Dynamic pruning reduces computational cost but requires careful threshold tuning to avoid premature cluster collapse.

**Failure signatures:** 
- Cluster collapse: Monitor active cluster counts; if they drop to minimum immediately, check spread loss margin $\rho$
- Unbalanced optimization: If loss oscillates or specific views dominate, verify entropy normalization mapping is applied correctly

**First experiments:**
1. Train MFDMC on MovieLens-100k with default hyperparameters and monitor RMSE progression
2. Visualize cluster evolution across views to verify dynamic pruning works as intended
3. Test sensitivity to learning rate by training with 0.001 vs 0.01 to assess stability

## Open Questions the Paper Calls Out
None

## Limitations
- Reproducibility limited by underspecified hyperparameters (learning rate, optimizer, loss weight schedules)
- Interpretability claims lack quantitative metrics to support qualitative visualization results
- Generalization to computer vision tasks is asserted but not detailed with specific experiments

## Confidence
- **Performance claims (RMSE reduction):** Medium - Experimental results are presented, but exact hyperparameters and optimization schedules are missing
- **Interpretability claims:** Low - Qualitative visualization is provided, but no quantitative metrics are given
- **Generalizability to other domains:** Low - Claims are made but not supported with detailed experiments

## Next Checks
1. **Validate hyperparameter sensitivity:** Run MFDMC with multiple learning rates (e.g., 0.001, 0.01) and loss weight schedules to assess stability of RMSE gains
2. **Test cluster dynamics:** Monitor cluster counts per view during training to ensure they evolve as expected and do not collapse prematurely
3. **Quantify interpretability:** Develop a metric (e.g., cluster-label alignment score) to measure how well clusters correspond to known semantic attributes in MovieLens datasets