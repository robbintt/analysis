---
ver: rpa2
title: 'Not All Instances Are Equally Valuable: Towards Influence-Weighted Dataset
  Distillation'
arxiv_id: '2510.27253'
source_url: https://arxiv.org/abs/2510.27253
tags:
- dataset
- distillation
- real
- influence
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Influence-Weighted Distillation (IWD), a
  novel framework that enhances dataset distillation by incorporating influence functions
  to adaptively weight training instances. Traditional dataset distillation methods
  assume all real instances contribute equally, but in practice, datasets often contain
  redundant or harmful samples that degrade performance.
---

# Not All Instances Are Equally Valuable: Towards Influence-Weighted Dataset Distillation

## Quick Facts
- arXiv ID: 2510.27253
- Source URL: https://arxiv.org/abs/2510.27253
- Reference count: 14
- Primary result: Introduces Influence-Weighted Distillation (IWD) framework that improves dataset distillation by adaptively weighting training instances based on their estimated influence on the distillation objective.

## Executive Summary
This paper addresses a fundamental limitation in dataset distillation: the assumption that all real training instances contribute equally to the distillation process. The authors propose Influence-Weighted Distillation (IWD), a framework that uses influence functions to estimate each instance's impact on the distillation objective and assigns adaptive weights accordingly. By prioritizing beneficial data while downweighting harmful or redundant samples, IWD enhances the quality of distilled datasets. The framework is modular and can be integrated into existing distillation methods like DC, IDC, and PDD. Extensive experiments on CIFAR10, CIFAR100, and SVHN demonstrate consistent improvements in model performance, with accuracy gains of up to 7.8% over baseline methods.

## Method Summary
The IWD framework enhances dataset distillation by incorporating influence functions to adaptively weight training instances. The core innovation is estimating each instance's influence on the distillation objective using a decomposition into explicit and implicit terms, then applying these scores as soft weights via temperature-scaled softmax. The method is designed as a modular plug-in that can be seamlessly integrated into existing distillation frameworks without requiring architectural changes. By modifying the distillation loss directly to scale gradients contributed by each real instance, IWD prioritizes beneficial data while downweighting less useful or harmful samples, ultimately producing higher-quality distilled datasets that lead to improved model performance.

## Key Results
- IWD consistently improves distilled dataset quality and model performance across CIFAR10, CIFAR100, and SVHN datasets
- Achieves accuracy gains of up to 7.8% over baseline distillation methods
- Demonstrates robustness across different datasets and neural network architectures
- Shows superiority of soft weighting over hard pruning approaches

## Why This Works (Mechanism)

### Mechanism 1: Distillation-Specific Influence Decomposition
The contribution of a real instance to dataset distillation can be quantified by differentiating the matching loss with respect to instance weights. The authors extend classical influence functions to the distillation objective, decomposing the influence score $I(z; S)$ into an explicit term (direct contribution to real-data statistics) and an implicit term (contribution via the parameter trajectory). This allows identification of "harmful" instances that mislead synthetic set optimization. The core assumption is that the first-order approximation of the leave-one-out effect holds for the distillation loss landscape. If the Hessian is singular or the loss landscape is highly non-convex, the first-order approximation may become unstable.

### Mechanism 2: Adaptive Softmax Weighting with Temperature Scaling
Raw influence scores are transformed into weights via temperature-scaled softmax, preserving global information while emphasizing high-value instances. Instead of hard pruning, IWD applies soft weight $w = \text{softmax}(I/\tau)$, where temperature $\tau$ controls the entropy of the weighting distribution. A moderate $\tau$ prevents the "winner-takes-all" problem, ensuring the synthetic set captures broader class features. The optimal weighting distribution is assumed to be smooth rather than binary. If $\tau$ is too low, the model ignores most of the dataset, leading to overfitting on a few "prototypical" samples and loss of intra-class diversity.

### Mechanism 3: Modular Gradient Re-weighting
Influence weights are integrated into the loss function to improve diverse distillation frameworks (DC, IDC, PDD). The method functions as a "plug-in" by modifying the distillation loss $M(\tilde{z}, z)$ directly, without altering inner loop training dynamics or teacher/student model architectures. It works by scaling gradients contributed by each real instance during synthetic data update. The core assumption is that gradients from harmful instances are consistent in their negative direction and can be neutralized by scalar multiplication. In frameworks where the distillation objective is not directly differentiable w.r.t real data weights, this mechanism cannot be applied.

## Foundational Learning

- **Influence Functions (Koh & Liang 2017)**
  - Why needed here: This is the mathematical engine of the paper. Understanding how upweighting a training point $\epsilon$ affects test loss $L(z_{test})$ via the Hessian $H^{-1}$ is crucial for comprehending Eq. (5) and (8).
  - Quick check question: If a model parameter $\theta$ is perturbed by $\delta \theta = -H^{-1}\nabla L(z)$, does this measure the effect of removing $z$ or upweighting $z$?

- **Bi-level Optimization (Meta-learning)**
  - Why needed here: Dataset distillation is a bi-level problem (inner loop: train on synthetic; outer loop: optimize synthetic). IWD operates on the outer loop objective.
  - Quick check question: In Eq. (6), is $S$ (the synthetic set) the variable for the inner loop or the outer loop?

- **Gradient/Trajectory Matching**
  - Why needed here: The "Explicit" vs. "Implicit" influence mechanism relies on differentiating the matching statistics (gradients or trajectories) of real vs. synthetic data.
  - Quick check question: In "Gradient Matching," do we want the gradients of the synthetic data to be identical to or orthogonal to the real data gradients?

## Architecture Onboarding

- **Component map:** Influence Estimator -> Weighting Module -> Distillation Core
- **Critical path:** The computation of the implicit term involving the Hessian-inverse ($H_{\theta_t}^{-1}$) is the computational bottleneck. If $S_{inner}=S$, the implicit term is zero ($u_{t,j}=0$), simplifying the path. If $S_{inner}=D$, you must implement an efficient Hessian-inverse approximation (e.g., LiSSA or conjugate gradient) to maintain tractability.
- **Design tradeoffs:**
  - Pruning vs. Weighting: Pruning (removing data) is faster per iteration but loses information. IWD retains all data but increases per-step compute due to score estimation.
  - Precision vs. Speed: Calculating exact influence is expensive; the paper likely uses approximations (common in influence function literature).
- **Failure signatures:**
  - Weight Collapse: All weights converge to a single sample. (Solution: Increase $\tau$).
  - NaN Gradients: Instability in Hessian-vector products during influence estimation. (Solution: Add damping to the Hessian).
  - No Improvement over Baseline: Likely implies $\tau$ is too high (approaching uniform weights) or the influence estimation is noisy.
- **First 3 experiments:**
  1. **Sanity Check (DC vs. IWD+DC):** Run standard Dataset Condensation (DC) on CIFAR-10 (IPC=10) and measure baseline accuracy. Integrate IWD with a fixed moderate $\tau$ (e.g., 1.0) and verify if accuracy increases as shown in Table 1.
  2. **Temperature Sweep ($\tau$):** Run IWD on CIFAR-10 while varying $\tau \in [0.1, 1.0, 10.0]$. Plot accuracy vs. $\tau$ to replicate the unimodal trend in Figure 4a.
  3. **Ablation on Pruning:** Compare "Influence-Prune" (removing bottom 10%) vs. "IWD" (soft weighting) to demonstrate that retaining "harmful" data with low weights is superior to deletion, verifying the "information loss" hypothesis.

## Open Questions the Paper Calls Out

None specified in the provided material.

## Limitations

- Computational overhead from calculating influence scores, particularly the implicit term requiring Hessian-inverse approximation
- Sensitivity to temperature parameter $\tau$ that requires careful tuning
- First-order approximation may become unstable for highly non-convex loss landscapes or singular Hessians
- Not applicable to distillation frameworks where the objective is not differentiable w.r.t real data weights

## Confidence

High: The framework's modular design and extensive experimental validation across multiple datasets and architectures demonstrate strong effectiveness and broad applicability.

## Next Checks

1. Verify the computational overhead by measuring the time difference between standard DC and IWD+DC on CIFAR-10
2. Test the robustness of IWD across different network architectures beyond those used in the paper (e.g., ResNets, Vision Transformers)
3. Evaluate the impact of different Hessian approximation methods (LiSSA, conjugate gradient) on both accuracy and runtime