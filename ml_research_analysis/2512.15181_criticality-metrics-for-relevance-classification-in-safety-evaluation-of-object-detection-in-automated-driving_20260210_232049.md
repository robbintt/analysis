---
ver: rpa2
title: Criticality Metrics for Relevance Classification in Safety Evaluation of Object
  Detection in Automated Driving
arxiv_id: '2512.15181'
source_url: https://arxiv.org/abs/2512.15181
tags:
- metrics
- safety
- metric
- criticality
- evaluation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper presents the first comprehensive review and evaluation\
  \ of criticality metrics for safety assessment in object detection for automated\
  \ driving. The authors analyze various existing metrics, including TTC, MTTC, TTB,\
  \ TTA, CIF, LSM, RSS, SACRED, and SURE-Val, and propose two novel strategies\u2014\
  bidirectional criticality rating and multi-metric aggregation\u2014to improve their\
  \ performance."
---

# Criticality Metrics for Relevance Classification in Safety Evaluation of Object Detection in Automated Driving

## Quick Facts
- arXiv ID: 2512.15181
- Source URL: https://arxiv.org/abs/2512.15181
- Reference count: 17
- This paper presents the first comprehensive review and evaluation of criticality metrics for safety assessment in object detection for automated driving.

## Executive Summary
This paper systematically evaluates criticality metrics for safety assessment in object detection systems for automated driving. The authors analyze existing metrics (TTC, MTTC, TTB, TTA, CIF, LSM, RSS, SACRED, SURE-Val) and identify their limitations, particularly that time-based metrics fail when relative velocity is near zero. They propose two novel strategies—bidirectional criticality rating and multi-metric aggregation—that significantly improve classification accuracy. Using the DeepAccident dataset, their approaches achieve up to 100% improvement in frame ratio metrics, demonstrating that combining time and distance-based metrics through bidirectional assessment provides a more reliable safety evaluation framework.

## Method Summary
The study evaluates criticality metrics on the DeepAccident dataset using ground truth annotations. The method involves computing single metrics with literature-based thresholds, then applying two novel strategies: multi-metric aggregation (logical OR combination of time-based and distance-based metrics) and bidirectional rating (applying metrics from both ego→object and object→ego perspectives). The evaluation uses Scenario Ratio (SR), Frame Ratio (FR), and time-to-collision (τ) metrics to assess performance. The approach systematically tests combinations of metrics and thresholds to identify optimal configurations for safety-critical object detection.

## Key Results
- Current state-of-the-art metrics have significant limitations, with up to 50% of critical frames misclassified
- Bidirectional criticality rating improves RSS scenario ratio from 0.814 to 0.977
- Multi-metric aggregation achieves frame ratios of 0.418-1.00 (TTA+SACRED perfect at FR=1.00)
- Combining time and distance-based metrics through bidirectional assessment significantly enhances safety evaluation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Bidirectional criticality rating improves frame-level detection of safety-critical objects.
- Mechanism: Criticality is not inverse-symmetric. A metric M applied from ego → object may not classify the object as critical, but the same metric applied from object → ego may classify the ego as critical. By taking the logical OR of both directions (C(Vi) = M(Ve→Vi) ∨ M(Vi→Ve)), the system captures asymmetric risk relationships that unidirectional evaluation misses.
- Core assumption: If either vehicle would classify the other as critical from its perspective, the pair should be treated as safety-critical for perception evaluation.
- Evidence anchors:
  - [Section III-B]: "Criticality metrics are not necessarily inverse. This means if a metric M applied on vehicle V1 does not classify a vehicle V2 as critical, the same metric applied to V2 could classify V1 as critical."
  - [Table III]: RSS scenario ratio improved from 0.814 to 0.977 with bidirectional rating; frame ratio increased by ~100% for MTTC 4s (0.219 → 0.438).
  - Weak direct corpus support for bidirectional approach; related papers focus on single-direction criticality.
- Break condition: When both directions already classify identically (symmetric scenarios), bidirectional rating provides no improvement and adds computational overhead.

### Mechanism 2
- Claim: Aggregating time-based and distance-based metrics compensates for individual metric blind spots.
- Mechanism: Time-based metrics (TTC, TTA) fail when relative velocity is near zero despite dangerous proximity (e.g., same-speed following at low distance). Distance-based metrics (RSS, LSM, SACRED) capture these cases by computing required safety margins. Combining via logical OR—if either metric flags criticality, the object is critical—covers more failure modes without requiring complex unified formulas.
- Core assumption: The weaknesses of time-based and distance-based metrics are sufficiently non-overlapping that their combination yields net improvement.
- Evidence anchors:
  - [Section II-A]: "For TTC, only colliding vehicles are considered critical. Consider a motorway situation with a lead vehicle... both traveling at the same speed and a low distance... TTC would be equal to ∞ and therefore the leading vehicle would not be critical."
  - [Table II]: TTC+SACRED achieved FR=0.979 vs TTC alone FR=0.346; TTA+SACRED achieved perfect FR=1.00.
  - EPSM paper (arXiv:2512.15195) similarly argues that conventional metrics ignore safety-relevant aspects.
- Break condition: When metrics are highly correlated (e.g., TTC and CIF), aggregation provides minimal improvement. Paper explicitly excludes such combinations.

### Mechanism 3
- Claim: Scenario-specific metrics (SACRED, SURE-Val) achieve high accuracy when correctly matched but suffer from applicability ambiguity.
- Mechanism: SACRED defines four submetrics for specific motorway scenarios (same-direction equal-speed, same-direction different-speed, opposite-direction, tangential merging). When the correct submetric is applied to its target scenario, accuracy is high (R.TT achieved SR=0.988, FR=0.852). However, misapplying submetrics or encountering transition scenarios degrades performance.
- Core assumption: The scenario classifier that selects which submetric to apply is accurate; the paper evaluates with ground-truth scenario labels.
- Evidence anchors:
  - [Section II-H]: "For the safety evaluation of object detection, the distinction between radial and tangential cases can be difficult in transition between those scenarios, which limits the applicability."
  - [Table I]: Individual SACRED submetrics ranged from SR=0.023 (T.XT) to SR=0.988 (R.TT); combined SACRED achieved SR=1.0, FR=0.979.
  - Modified-Emergency Index paper (arXiv:2510.27333) addresses similar scenario-specific limitations for lateral conflicts.
- Break condition: In mixed or ambiguous scenarios where the correct submetric is unclear, performance degrades; automated scenario classification is not addressed.

## Foundational Learning

- Concept: **Time-to-Collision (TTC) and its failure modes**
  - Why needed here: TTC is the most widely cited criticality metric but has a fundamental blind spot—it returns infinity when relative velocity is zero, missing dangerously close same-speed following scenarios.
  - Quick check question: If two vehicles travel at 30 m/s with 5m separation, what TTC value results and is this a safe situation?

- Concept: **RSS (Responsible-Sensitive Safety) distance calculations**
  - Why needed here: RSS provides mathematically formalized safety distances that don't rely on arbitrary thresholds, using vehicle dynamics (response time, acceleration, braking capability) instead.
  - Quick check question: What three components compose the RSS longitudinal same-direction safety distance formula?

- Concept: **Logical OR aggregation for multi-metric systems**
  - Why needed here: The paper's multi-metric aggregation uses OR logic—if any metric flags criticality, the object is critical. This increases recall at potential cost to precision, which is appropriate for safety-critical systems where missing a threat is worse than false positives.
  - Quick check question: Why might OR aggregation be preferred over AND aggregation or weighted averaging for safety evaluation?

## Architecture Onboarding

- Component map: Vehicle state data -> Metric computation layer -> Aggregation layer -> Binary criticality classification
- Critical path:
  1. Extract ego and object state vectors from perception ground truth or detections
  2. Determine applicable scenario type (same-direction, opposite-direction, merging, etc.) for SACRED/SURE-Val selection
  3. Compute all selected metrics for ego→object direction
  4. Compute all selected metrics for object→ego direction (bidirectional)
  5. Apply OR aggregation across metrics and directions
  6. Track first critical classification timestamp for τ calculation

- Design tradeoffs:
  - Computational cost vs. coverage: Bidirectional + multi-metric increases computations 2-10x but improves frame ratio by up to 100%
  - Threshold selection: Time-based metrics require threshold tuning (1-4s for TTC); RSS requires drift margin selection (0.0-1.0m)
  - Scenario specificity vs. generality: SACRED achieves highest accuracy but requires correct scenario classification; RSS and TTA generalize better

- Failure signatures:
  - τ_min = 0.0s indicates the metric only flagged criticality at the moment of collision (no early warning)
  - High SR but low FR indicates inconsistent frame-level classification within scenarios
  - SACRED submetric mismatch causes near-zero detection rates (e.g., T.XT at SR=0.023)

- First 3 experiments:
  1. Baseline reproduction: Implement TTC, RSS, and TTA with paper's threshold settings on DeepAccident validation split; verify SR and FR metrics match Table I within ±0.05.
  2. Ablation study: Test bidirectional rating alone, multi-metric aggregation alone, and combined; measure individual contribution to frame ratio improvement.
  3. Cross-dataset validation: Apply best-performing configuration (TTA+SACRED bidirectional) to a different accident dataset (e.g., nuScenes with collision annotations) to assess generalization beyond DeepAccident.

## Open Questions the Paper Calls Out

- **Open Question 1**: How does incorporating object-specific dynamics—such as differentiating between vehicles, pedestrians, and cyclists—impact the accuracy of criticality metrics?
  - Basis in paper: [explicit] The conclusion states that future work will focus on "incorporating object-specific dynamics" to improve the contextual relevance and accuracy of metrics.
  - Why unresolved: The current study utilized the DeepAccident dataset, which primarily features vehicle-to-vehicle interactions, leaving the efficacy of these metrics for vulnerable road users unvalidated.
  - What evidence would resolve it: An evaluation of the proposed strategies on a dataset containing diverse object classes (pedestrians, cyclists) with distinct dynamic properties.

- **Open Question 2**: Can the performance of the LSM metric be improved by accumulating the braking distances of both the ego vehicle and the dynamic object?
  - Basis in paper: [inferred] Section V notes that for dynamic objects, the single-vehicle braking distance "may not be sufficient" and suggests accumulating distances could improve results.
  - Why unresolved: The current LSM formulation considers only the ego vehicle's braking distance, potentially underestimating the criticality of dynamic interactions.
  - What evidence would resolve it: A comparative analysis showing improved frame ratios (FR) and time-to-collision (τ) values when using accumulated braking distances in dynamic scenarios.

- **Open Question 3**: How can criticality thresholds for Time-to-X metrics be dynamically optimized to account for scenario-specific dependencies?
  - Basis in paper: [inferred] Section V highlights that metric performance is "highly dependent on the threshold used" and that the required threshold varies based on the scenario and motion planning algorithms.
  - Why unresolved: The evaluation relied on static, literature-based thresholds (e.g., 1.0 s to 4.0 s), which forces a trade-off between generalization and accuracy.
  - What evidence would resolve it: Development of an adaptive thresholding mechanism that maintains high Scenario Ratios (SR) across diverse scenarios without manual tuning.

## Limitations
- Evaluation relies on a single dataset (DeepAccident) with ground truth annotations, limiting generalizability to real-world perception errors
- Several metric parameters (RSS dynamics, LSM parameters, SACRED reaction times) are unspecified, requiring assumptions that may affect reproducibility
- Bidirectional approach doubles computational requirements, and multi-metric aggregation increases complexity without clear runtime analysis
- Scenario classification for SACRED submetric selection is not addressed—the paper assumes perfect ground truth scenario labels

## Confidence
- **High Confidence**: The fundamental observation that time-based metrics fail at low relative velocities (TTC returning infinity) is well-established and directly supported by the analysis.
- **Medium Confidence**: The bidirectional criticality rating mechanism and its quantitative improvements (SR=0.977 for RSS) are supported by Table III, though the assumption that logical OR aggregation optimally combines metrics needs further validation.
- **Low Confidence**: Claims about SACRED achieving SR=1.0 require scrutiny since this relies on perfect scenario classification, which is acknowledged as a limitation in Section II-H.

## Next Checks
1. **Cross-dataset validation**: Apply the best-performing configuration (bidirectional TTA+SACRED) to a different accident dataset (e.g., nuScenes with collision annotations) to verify generalization beyond DeepAccident.
2. **Parameter sensitivity analysis**: Systematically vary RSS parameters (ρ, µ), LSM thresholds, and SACRED reaction times to quantify their impact on SR and FR metrics.
3. **Runtime complexity evaluation**: Measure the actual computational overhead of bidirectional + multi-metric approaches versus baseline metrics, and assess whether the 2-10x increase is practical for real-time deployment.