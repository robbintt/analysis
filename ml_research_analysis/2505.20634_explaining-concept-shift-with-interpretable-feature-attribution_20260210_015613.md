---
ver: rpa2
title: Explaining Concept Shift with Interpretable Feature Attribution
arxiv_id: '2505.20634'
source_url: https://arxiv.org/abs/2505.20634
tags:
- features
- shift
- data
- sgshift
- target
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of identifying which features
  cause concept shift, where the relationship between features and labels changes
  between source and target datasets, leading to reduced model performance. The proposed
  method, SGShift, uses a sparse Generalized Additive Model (GAM) to model the difference
  between source and target distributions and performs feature selection to identify
  shifted features.
---

# Explaining Concept Shift with Interpretable Feature Attribution

## Quick Facts
- arXiv ID: 2505.20634
- Source URL: https://arxiv.org/abs/2505.20634
- Reference count: 6
- Primary result: SGShift identifies concept-shifted features with AUC > 0.9 and recall > 90%, outperforming baselines by 2-3x

## Executive Summary
This paper addresses the critical problem of identifying which features cause concept shift between source and target datasets, where the relationship between features and labels changes, degrading model performance. The proposed SGShift method uses a sparse Generalized Additive Model (GAM) to model the difference between source and target distributions, performing feature selection to identify shifted features. The authors extend SGShift with knockoffs for false discovery control and an absorption term to handle model misspecification. Experiments demonstrate strong performance on both synthetic and real healthcare datasets, with the method successfully identifying features consistent with known medical literature about COVID-19 severity differences between virus variants.

## Method Summary
SGShift addresses concept shift detection by modeling the difference between source and target distributions using a sparse Generalized Additive Model. The method identifies shifted features by selecting those with the highest attribution scores, effectively pinpointing which features have experienced distribution or relationship changes. To enhance reliability, the authors extend the approach with knockoffs for statistical false discovery control and an absorption term to account for potential model misspecification. This interpretable feature attribution framework enables practitioners to understand and diagnose performance degradation when deploying models in new environments.

## Key Results
- SGShift achieves AUC > 0.9 and recall > 90% in identifying shifted features, outperforming baselines by 2-3x
- Strong performance across various ML models and sample sizes, with knockoffs and absorption extensions further improving results
- Real-world evaluation on COVID-19 hospitalization data reveals features consistent with medical literature about severity differences between virus variants
- Results confirm that true concept shifts in tabular healthcare data tend to be sparse, supporting the paper's core approach

## Why This Works (Mechanism)
SGShift works by leveraging the interpretability of Generalized Additive Models to model the difference between source and target distributions. The sparse GAM formulation naturally identifies which features contribute most to the distributional shift, while the extension with knockoffs provides statistical guarantees on false discovery rates. The absorption term addresses model misspecification by accounting for discrepancies between the assumed model and the true underlying relationship. This combination allows for both accurate identification of shifted features and statistical rigor in the detection process.

## Foundational Learning
- **Concept Shift**: When the relationship between features and labels changes between datasets - needed because traditional domain adaptation assumes covariate shift, not relationship changes
- **Generalized Additive Models (GAMs)**: Interpretable models that assume additive feature effects - needed for sparse feature attribution and model interpretability
- **Knockoffs**: Statistical tools for false discovery control - needed to provide rigorous guarantees on the features identified as shifted
- **Absorption Term**: Model component to handle misspecification - needed because real-world data rarely follows the assumed model perfectly
- **Feature Attribution**: Method to assign importance scores to features - needed to identify which specific features cause concept shift
- **Sparse Modeling**: Techniques that assume most features are irrelevant - needed because concept shifts tend to affect only a small subset of features

## Architecture Onboarding

**Component Map**: Data -> GAM Modeling -> Feature Attribution -> Knockoffs Extension -> Absorption Term -> Shifted Features Output

**Critical Path**: The core workflow involves fitting the sparse GAM to source and target data, computing feature attributions for the distributional difference, applying knockoffs for statistical validation, and incorporating the absorption term to handle model misspecification.

**Design Tradeoffs**: The method trades some modeling flexibility (through GAM assumptions) for interpretability and sparse feature identification. While GAMs may miss complex interactions, they provide clear feature attributions. The knockoffs extension adds computational overhead but provides valuable statistical guarantees.

**Failure Signatures**: Poor performance may occur when concept shifts are not sparse, when feature interactions are critical to the shift, or when the GAM assumptions are severely violated. The method may also struggle with very small sample sizes or highly correlated features.

**First Experiments**: 1) Test on synthetic data with known sparse concept shifts to verify detection accuracy, 2) Apply to a small tabular dataset with interpretable results, 3) Evaluate computational complexity on increasing dataset sizes

## Open Questions the Paper Calls Out
None

## Limitations
- Effectiveness on non-healthcare domains and non-tabular data types remains untested
- Reliance on GAM assumptions may miss complex feature interactions relevant to concept shifts
- Computational complexity with knockoffs extension not thoroughly discussed for large-scale applications
- Sparse concept shift assumption may not hold universally across all applications

## Confidence
- **High**: Core methodology and synthetic experiment results - clear mathematical formulation and controlled experimental conditions
- **Medium**: Real-world healthcare application results - findings align with medical literature but sample sizes may not be representative
- **Medium**: Comparative analysis with baseline methods - demonstrates superior performance but choice of baselines could influence results

## Next Checks
1. Test SGShift on diverse datasets beyond healthcare, including non-tabular data types, to assess generalizability across domains
2. Conduct experiments with varying levels of feature interactions and non-linear relationships to evaluate the method's robustness to complex concept shifts
3. Perform a thorough computational complexity analysis and benchmark against other concept shift detection methods to establish practical deployment feasibility