---
ver: rpa2
title: 'From Guess2Graph: When and How Can Unreliable Experts Safely Boost Causal
  Discovery in Finite Samples?'
arxiv_id: '2510.14488'
source_url: https://arxiv.org/abs/2510.14488
tags:
- expert
- edge
- edges
- sets
- tests
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Guess2Graph (G2G), a framework for incorporating
  unreliable expert knowledge into causal discovery algorithms without compromising
  theoretical guarantees. The core insight is to use expert predictions to guide the
  sequence of statistical tests rather than replacing test outcomes, preserving statistical
  consistency while enabling performance improvements.
---

# From Guess2Graph: When and How Can Unreliable Experts Safely Boost Causal Discovery in Finite Samples?

## Quick Facts
- **arXiv ID**: 2510.14488
- **Source URL**: https://arxiv.org/abs/2510.14488
- **Reference count**: 40
- **Primary result**: G2G framework uses unreliable expert knowledge to guide causal discovery test ordering without compromising statistical consistency

## Executive Summary
This paper introduces Guess2Graph (G2G), a framework for incorporating unreliable expert knowledge into causal discovery algorithms without compromising theoretical guarantees. The core insight is to use expert predictions to guide the sequence of statistical tests rather than replacing test outcomes, preserving statistical consistency while enabling performance improvements. Two instantiations are developed: PC-Guess, which augments the PC algorithm with expert-guided test ordering, and gPC-Guess, a redesigned variant that achieves stronger gains by being more responsive to expert input. Theoretically, both maintain correctness regardless of expert error, with gPC-Guess provably outperforming its non-augmented counterpart when experts are "better than random." Empirically, both show monotonic improvement with expert accuracy, with gPC-Guess achieving up to 30% performance gains when experts are accurate across synthetic and real-world data, including when using LLM experts.

## Method Summary
The Guess2Graph framework addresses the challenge of incorporating unreliable expert knowledge into causal discovery while preserving statistical guarantees. The key innovation is to use expert predictions to guide the order of statistical tests rather than to replace test outcomes. This is implemented through two algorithms: PC-Guess, which modifies the PC algorithm's edge loop to test edges the expert predicts as false first, and gPC-Guess, which redesigns PC to be more responsive to expert input by testing conditioning set sizes in a single pass rather than level-by-level. Both algorithms maintain statistical consistency regardless of expert quality, with gPC-Guess provably outperforming PC-Stable when expert accuracy exceeds 0.5.

## Key Results
- PC-Guess and gPC-Guess maintain statistical consistency regardless of expert quality
- gPC-Guess achieves up to 30% performance gains over PC-Stable when experts are accurate
- Both algorithms show monotonic improvement with expert accuracy across synthetic and real-world data
- LLM experts can provide useful guidance when their accuracy exceeds 0.5

## Why This Works (Mechanism)
The framework works by leveraging expert predictions to guide the search order rather than to veto statistical tests. This preserves the validity of statistical guarantees while allowing experts to help algorithms reach correct conclusions faster by suggesting which edges are likely present/absent and which conditioning sets might separate variables.

## Foundational Learning
- **Causal Skeleton Discovery**: Understanding the undirected structure of causal relationships from observational data
  - Why needed: The paper focuses on skeleton discovery as the core problem
  - Quick check: Can you explain the difference between skeleton and directed causal graph discovery?
- **Conditional Independence Testing**: Statistical methods for determining if variables are independent given conditioning sets
  - Why needed: The algorithms rely on repeated conditional independence tests
  - Quick check: Do you understand the difference between Fisher's Z-test and Chi-square test for independence?
- **Constraint-based Causal Discovery**: Algorithms like PC that use conditional independence tests to discover causal structure
  - Why needed: The paper builds on and modifies the PC algorithm
  - Quick check: Can you trace through one iteration of the PC algorithm's edge removal process?
- **Finite-sample Statistical Guarantees**: Understanding when algorithms provide correct results with limited data
  - Why needed: The paper emphasizes maintaining guarantees in finite-sample settings
  - Quick check: Do you understand the concept of statistical consistency in causal discovery?

## Architecture Onboarding
- **Component Map**: Data -> Conditional Independence Tests -> Expert Guidance -> Test Ordering -> Skeleton Output
- **Critical Path**: The sequence of conditional independence tests, where expert guidance optimizes the order to reduce unnecessary tests
- **Design Tradeoffs**: Expert-guided ordering (faster but implementation-sensitive) vs. standard level-by-level (slower but theoretically straightforward)
- **Failure Signatures**: Degradation when expert accuracy < 0.5, implementation errors in test ordering, or incorrect d-separating set extraction
- **First Experiments**: 1) Implement PC-Guess and verify edge ordering, 2) Compare gPC-Guess conditioning set strategies, 3) Test LLM expert parsing accuracy

## Open Questions the Paper Calls Out
- Can G2G theoretical guarantees be established for score-based and FCM-based algorithms?
- Do runtime guarantees hold under weaker assumptions than mutual test independence?
- How can G2G integrate with hard/soft constraint approaches for expert knowledge?
- What is the optimal strategy for expert selection and validation when quality is unknown?

## Limitations
- Theoretical guarantees for extensions to score-based and FCM algorithms remain unproven
- Runtime improvements depend on mutual test independence, which is violated in practice
- The framework doesn't address integration with hard/soft constraint approaches
- Expert selection and validation strategies when quality is unknown require further development

## Confidence
- **High Confidence**: Theoretical guarantees of statistical consistency for both PC-Guess and gPC-Guess are sound
- **Medium Confidence**: The monotonic improvement with expert accuracy is empirically supported but depends on implementation choices
- **Medium Confidence**: The 30% performance gains are plausible but may be sensitive to implementation details and specific graph structures

## Next Checks
1. Implement and compare both conditioning set ordering strategies (expert-guided vs. level-by-level) in gPC-Guess to verify which matches the reported runtime behavior
2. Test the LLM expert's d-separating set extraction with multiple prompts and validation methods to ensure consistent parsing from unstructured text
3. Conduct ablation studies isolating the contribution of expert-guided test ordering versus the removal of PC's level structure in gPC-Guess