---
ver: rpa2
title: 'The Why Behind the Action: Unveiling Internal Drivers via Agentic Attribution'
arxiv_id: '2601.15075'
source_url: https://arxiv.org/abs/2601.15075
tags:
- agent
- attribution
- arxiv
- user
- agentic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work introduces a general agentic attribution framework to
  explain why LLM-based agents make specific decisions, moving beyond failure-focused
  analysis. The framework operates hierarchically: first using temporal likelihood
  dynamics to identify critical interaction components, then applying perturbation-based
  analysis to isolate key sentences within those components.'
---

# The Why Behind the Action: Unveiling Internal Drivers via Agentic Attribution

## Quick Facts
- **arXiv ID:** 2601.15075
- **Source URL:** https://arxiv.org/abs/2601.15075
- **Reference count:** 17
- **Primary result:** General framework to explain why LLM agents make decisions via hierarchical attribution scoring

## Executive Summary
This work introduces a general agentic attribution framework to explain why LLM-based agents make specific decisions, moving beyond failure-focused analysis. The framework operates hierarchically: first using temporal likelihood dynamics to identify critical interaction components, then applying perturbation-based analysis to isolate key sentences within those components. Evaluated on diverse scenarios including memory-driven decisions and tool-mediated reasoning, the framework reliably pinpoints pivotal historical events and fine-grained textual evidence driving agent actions. Quantitative results show Hit@1 scores of 0.94 using the default method, demonstrating robustness across alternative attribution instantiations. This approach offers a critical step toward transparent, accountable, and safer deployment of autonomous agents by illuminating the internal drivers behind their decisions.

## Method Summary
The framework uses a hierarchical approach to identify what drives agent decisions. At the component level, it computes temporal likelihood dynamics by calculating the marginal gain in log-likelihood when adding each interaction component. At the sentence level, it applies perturbation-based analysis to the top components, computing scores based on how dropping or holding individual sentences affects the likelihood of the final action. The method was evaluated on 8 curated agent trajectories generated by Llama-3.1-70B-Instruct using the smolagents framework, measuring Hit@k scores against human-annotated ground truth sentences.

## Key Results
- Hit@1 score of 0.94 using the default Prob. Drop&Hold method
- Framework successfully identifies pivotal historical events and fine-grained textual evidence
- Results robust across alternative attribution instantiations
- Demonstrated effectiveness on diverse scenarios including memory-driven and tool-mediated reasoning

## Why This Works (Mechanism)
The framework works by leveraging the model's own likelihood predictions as a proxy for attribution strength. By tracking how the probability of an action changes as historical context is added (component level) and how it changes when individual sentences are perturbed (sentence level), the method identifies which parts of the agent's history were most influential in driving its decisions. This approach captures both high-level interaction patterns and fine-grained textual evidence that shape the agent's reasoning.

## Foundational Learning
- **Temporal Likelihood Dynamics**: Measuring how the log-likelihood of an action changes as context is added; needed to identify critical interaction components, check by verifying marginal gains are positive and decreasing over time.
- **Perturbation-based Attribution**: Systematically removing or isolating sentences to measure their impact on action likelihood; needed to distinguish key evidence from background context, check by ensuring scores are sensitive to semantically important changes.
- **Hierarchical Attribution**: Decomposing attribution from coarse components to fine-grained sentences; needed to balance interpretability with precision, check by validating component-level and sentence-level rankings align with human judgment.
- **Log-likelihood as Proxy**: Using model's probability estimates to approximate causal influence; needed because direct causal measurement is intractable, check by comparing across different likelihood estimation methods.
- **Hit@k Evaluation**: Measuring whether ground truth sentences appear in top-k ranked attributions; needed to quantify localization accuracy, check by ensuring metric is stable across different k values.

## Architecture Onboarding
- **Component Map:** History Components (C₁, C₂, ..., Cₙ) → Component Scoring (gᵢ) → Top Components → Sentence Decomposition (S(Cᵢ)) → Sentence Scoring (φ) → Final Attribution
- **Critical Path:** Compute gᵢ for all components → Select top component → Compute φ for all sentences in that component → Rank sentences → Evaluate against ground truth
- **Design Tradeoffs:** Likelihood-based vs embedding-based component scoring (chosen for interpretability vs efficiency), Drop-only vs Drop+Hold sentence scoring (chosen for comprehensiveness vs simplicity)
- **Failure Signatures:** OOM errors with gradient-based baselines, noisy likelihood scores from formatting inconsistencies, low Hit@k scores indicating misalignment with human judgment
- **First Experiments:**
  1. Compute gᵢ scores for a sample trajectory and verify marginal gains are intuitive
  2. Apply perturbation scoring to top component and check if results match human intuition
  3. Run full pipeline on a single example and calculate Hit@1 against ground truth

## Open Questions the Paper Calls Out
- **Open Question 1:** How do alternative component-level scoring metrics, such as embedding-based similarity or trained reward models, compare to temporal likelihood dynamics in identifying critical interaction steps?
- **Open Question 2:** Can the interpretation of hierarchical attribution signals be fully automated to ensure accountability in large-scale, real-world deployments?
- **Open Question 3:** How robust is the framework when validated on larger-scale, more comprehensive datasets that include a wider variety of agent architectures?

## Limitations
- Framework relies on LLM-based likelihood estimation, which assumes likelihood changes directly indicate causal importance
- Perturbation method requires significant computational resources for long trajectories
- Depends on human-annotated ground truth that may not capture all valid attribution chains
- Limited validation to 8 trajectories from a single model family

## Confidence
- **High confidence:** Perturbation-based attribution method is technically sound; hierarchical structure is clearly defined; evaluation metrics are appropriate
- **Medium confidence:** Generalizability to different agent architectures and domains; assumption that likelihood dynamics indicate attribution strength
- **Low confidence:** Theoretical grounding connecting likelihood changes to actual causal mechanisms; sensitivity to prompt formatting and tokenization choices

## Next Checks
1. **Ground Truth Expansion:** Validate attribution results across a broader set of scenarios with multiple human annotators to establish inter-rater reliability
2. **Ablation Studies:** Systematically test the impact of context formatting on attribution results to quantify sensitivity to presentation choices
3. **Cross-Model Consistency:** Apply the framework to different LLM architectures to assess whether attribution patterns remain consistent across model families