---
ver: rpa2
title: 'WISCA: A Consensus-Based Approach to Harmonizing Interpretability in Tabular
  Datasets'
arxiv_id: '2506.06455'
source_url: https://arxiv.org/abs/2506.06455
tags:
- consensus
- wisca
- features
- datasets
- explanations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces WISCA, a consensus-based interpretability
  approach for tabular datasets that addresses the challenge of conflicting explanations
  generated by different interpretability algorithms. The method combines class probabilities
  and normalized attributions through a weighted scaling mechanism, differentiating
  between global and local explanations while accounting for model accuracy.
---

# WISCA: A Consensus-Based Approach to Harmonizing Interpretability in Tabular Datasets

## Quick Facts
- **arXiv ID:** 2506.06455
- **Source URL:** https://arxiv.org/abs/2506.06455
- **Reference count:** 11
- **Primary result:** Consensus-based interpretability method that combines class probabilities and normalized attributions through weighted scaling to produce more reliable explanations than existing consensus functions

## Executive Summary
WISCA addresses the challenge of conflicting explanations generated by different interpretability algorithms in tabular datasets. The method introduces a weighted scaling mechanism that combines class probabilities with normalized attributions, differentiating between global and local explanations while accounting for model accuracy. Tested across six synthetic datasets with known ground truths for both classification and regression tasks, WISCA demonstrates consistent superiority over five established consensus functions in identifying the most relevant features. The approach shows promise for producing more reliable and consistent explanations in machine learning applications.

## Method Summary
WISCA employs a consensus-based framework that harmonizes multiple interpretability algorithms by combining their outputs through a weighted scaling mechanism. The method integrates class probabilities with normalized feature attributions, applying different treatment for global versus local explanations. A key innovation is the incorporation of model accuracy into the weighting scheme, ensuring that more reliable models have greater influence on the consensus interpretation. The framework processes attributions from multiple interpretability methods, scales them according to their associated class probabilities and model performance metrics, then aggregates these weighted contributions to produce final feature importance scores.

## Key Results
- WISCA consistently outperformed five established consensus functions across six synthetic datasets with known ground truths
- Achieved superior hit rates compared to both traditional consensus methods and individual interpretability algorithms
- Demonstrated effectiveness across both classification and regression tasks with clear identification of relevant features

## Why This Works (Mechanism)
WISCA's effectiveness stems from its weighted scaling approach that balances multiple interpretability sources while accounting for their reliability. By incorporating model accuracy into the consensus formation, the method naturally downweights less reliable interpretations while amplifying contributions from more trustworthy sources. The differentiation between global and local explanations allows the framework to adapt its aggregation strategy based on the explanation type required. The normalization of attributions ensures comparability across different interpretability algorithms, while the probability-based weighting provides a principled way to resolve conflicts between competing feature importance signals.

## Foundational Learning

**Feature Attribution Methods**
- *Why needed:* Understanding how different interpretability algorithms assign importance scores to features
- *Quick check:* Can you explain the difference between SHAP, LIME, and permutation importance?

**Consensus Aggregation**
- *Why needed:* Combining multiple conflicting explanations into a unified interpretation
- *Quick check:* What are the common approaches to aggregating ensemble predictions?

**Model Accuracy Integration**
- *Why needed:* Incorporating reliability metrics into interpretation weighting
- *Quick check:* How does model performance typically correlate with interpretability quality?

**Global vs Local Explanations**
- *Why needed:* Distinguishing between dataset-wide patterns and instance-specific interpretations
- *Quick check:* When would you prefer local explanations over global ones?

## Architecture Onboarding

**Component Map**
Interpretability Algorithms -> Attribution Normalization -> Probability Scaling -> Model Accuracy Weighting -> Consensus Aggregation -> Final Feature Importance

**Critical Path**
1. Generate attributions from multiple interpretability methods
2. Normalize attributions for comparability
3. Scale by class probabilities
4. Apply model accuracy weights
5. Aggregate weighted contributions
6. Output consensus feature importance

**Design Tradeoffs**
- Weighted scaling vs simple averaging: Provides better performance but increased complexity
- Global vs local distinction: More nuanced but requires separate handling
- Model accuracy incorporation: More reliable but depends on available performance metrics

**Failure Signatures**
- Inconsistent attributions across methods may indicate unreliable consensus
- Poor model accuracy can lead to diluted interpretation quality
- Feature correlation may complicate attribution normalization

**First Experiments**
1. Test WISCA on a simple linear dataset with known feature importance
2. Compare consensus outputs when using high vs low accuracy models
3. Evaluate performance with varying numbers of interpretability methods

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to synthetic datasets with known ground truths, lacking real-world validation
- Potential issues with feature correlation and multicollinearity not addressed
- Computational complexity compared to simpler consensus methods not discussed

## Confidence

**Major Claims Confidence Labels**
- Consistently outperformed five established consensus functions: **High**
- Produces more reliable and consistent explanations: **Medium**
- Superior hit rates compared to individual interpretability algorithms: **Medium-High**

## Next Checks

1. **Real-world dataset validation**: Test WISCA on established tabular datasets from domains like healthcare or finance with expert-annotated feature importance to verify performance on complex, correlated features.

2. **Scalability assessment**: Evaluate WISCA's computational efficiency and memory requirements on datasets with 1000+ features to determine practical limitations for high-dimensional tabular data.

3. **Cross-model generalizability**: Apply WISCA to ensemble models and neural networks beyond the tested decision trees and linear models to assess robustness across different ML architectures.