---
ver: rpa2
title: 'Graphing the Truth: Structured Visualizations for Automated Hallucination
  Detection in LLMs'
arxiv_id: '2512.00663'
source_url: https://arxiv.org/abs/2512.00663
tags:
- hallucination
- detection
- knowledge
- grapheval
- framework
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a visual analytics framework for detecting
  hallucinations in LLM outputs by mapping generated claims into an interactive spatial
  graph based on NLI consistency and semantic similarity scores. The method builds
  on prior graph-based hallucination detection techniques and enhances them with intuitive
  visualization for human-in-the-loop auditing.
---

# Graphing the Truth: Structured Visualizations for Automated Hallucination Detection in LLMs

## Quick Facts
- arXiv ID: 2512.00663
- Source URL: https://arxiv.org/abs/2512.00663
- Reference count: 14
- Primary result: SICI-1 achieves 70% balanced accuracy on SummEval, nearly matching GraphEval at far lower computational cost.

## Executive Summary
This paper presents a visual analytics framework for detecting hallucinations in LLM outputs by mapping generated claims into an interactive spatial graph based on NLI consistency and semantic similarity scores. The method builds on prior graph-based hallucination detection techniques and enhances them with intuitive visualization for human-in-the-loop auditing. Using the SummEval dataset, the approach achieved a balanced accuracy of 70% (SICI-1 variant), nearly matching GraphEval performance at substantially lower computational cost (~30 minutes vs. 8 hours). The visualization enables users to identify unreliable claims, trace their source relationships, and selectively refine outputs without discarding valid content, thereby supporting more transparent and efficient LLM auditing in enterprise settings.

## Method Summary
The approach maps LLM-generated claims into a spatial graph using NLI consistency and semantic similarity metrics. SICI-1 operates at the sentence level with coreference resolution via NER, evaluating each sentence with ±1 adjacent sentence for context. It applies NLI to target vs. closest semantic matches from source. GraphEval+ extracts bidirectional subject-verb-object triples from source and output, performs semantic similarity matching to select relevant source triples, and targets NLI evaluation per output triple against closest matches. The visualization uses a 2D layout with NLI consistency (x-axis) and average semantic similarity (y-axis), color-coded reliability (green/orange/red), four interpretive quadrants, and edges encoding claim-source similarity.

## Key Results
- SICI-1 achieved 70% balanced accuracy on SummEval, nearly matching GraphEval performance
- Computational cost reduced from ~8 hours to ~30 minutes compared to GraphEval
- Visualization enables human-in-the-loop auditing with quadrant-based reliability assessment
- Extraction failures in GraphEval+ inflate hallucination counts, highlighting importance of failure handling

## Why This Works (Mechanism)
The framework works by leveraging NLI consistency to assess factual alignment between generated claims and source documents, while semantic similarity provides contextual relevance. The spatial graph visualization transforms these abstract scores into an interpretable 2D space where users can quickly identify unreliable content clusters. The combination of quantitative metrics with visual patterns enables efficient human auditing by highlighting systematic failure modes and enabling targeted refinement rather than wholesale rejection of outputs.

## Foundational Learning
- **NLI consistency scoring**: Needed to quantify factual alignment between claims and source; quick check: verify NLI model outputs calibrated confidence scores for entailment/contradiction
- **Semantic similarity matching**: Required for context-aware claim-source alignment; quick check: test embedding model captures semantic equivalence across paraphrases
- **Coreference resolution**: Essential for sentence-level analysis to maintain claim integrity; quick check: validate resolved pronouns correctly map to original entities
- **Triple extraction**: Critical for GraphEval+ structural analysis; quick check: ensure SVO extraction captures complete relationship information
- **Balanced accuracy**: Appropriate metric for imbalanced hallucination detection; quick check: confirm per-class recall scores meet acceptable thresholds
- **Interactive visualization**: Enables human-in-the-loop auditing; quick check: verify quadrant boundaries effectively separate reliability levels

## Architecture Onboarding

**Component map**: SummEval dataset -> Sentence segmentation -> Coreference resolution -> Semantic similarity retrieval -> NLI evaluation -> Score aggregation -> 2D visualization

**Critical path**: Source document + Summary -> Semantic similarity search -> NLI consistency scoring -> 2D spatial mapping -> Interactive visualization

**Design tradeoffs**: Sentence-level vs. triple-level analysis (precision vs. coverage), context window size (±1 sentence) vs. computational cost, embedding model complexity vs. retrieval speed, NLI model specificity vs. generalization

**Failure signatures**: High false-negative rates indicate extraction/coreference errors, poor NLI calibration suggests similarity filtering issues, class-imbalance bias points to metric calibration problems

**First experiments**:
1. Validate SICI-0 vs. SICI-1 ablation to confirm contextual window improves accuracy
2. Test extraction failure rate impact on GraphEval+ performance
3. Compare embedding models for semantic similarity retrieval performance

## Open Questions the Paper Calls Out
None

## Limitations
- Computational cost comparison lacks hardware/software specification details
- NLI model checkpoint and calibration procedure unspecified
- Semantic similarity method parameters (embedding model, top-k) not detailed
- Failure rate quantification for extraction failures missing

## Confidence

| Claim Cluster | Confidence Level |
|---------------|------------------|
| Balanced accuracy ≈70% for SICI-1 | Medium |
| 30-minute runtime vs. 8-hour baseline | Low |
| Visualizations enable effective human auditing | Medium |

## Next Checks

1. **Replicate runtime comparison under controlled conditions**: Run SICI-1 and GraphEval+ on the same hardware using publicly available checkpoints, measuring total elapsed time from input ingestion to balanced accuracy output. Record per-step timings for NLI inference, embedding generation, and graph construction.

2. **Ablation of extraction failure handling**: Execute GraphEval+ while logging every extraction failure, then re-evaluate balanced accuracy with and without the automatic hallucination label for failed extractions. Quantify the proportion of errors attributable to failures versus true hallucinations.

3. **Sensitivity analysis of retrieval parameters**: Vary the embedding model, top-k size, and context window length in SICI-1, measuring their impact on balanced accuracy and per-class recall. Visualize how NLI score distributions shift across parameter settings to assess robustness to retrieval choices.