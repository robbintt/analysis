---
ver: rpa2
title: 'From Construction to Injection: Edit-Based Fingerprints for Large Language
  Models'
arxiv_id: '2509.03122'
source_url: https://arxiv.org/abs/2509.03122
tags:
- fingerprint
- language
- wang
- fingerprints
- editing
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes an end-to-end fingerprinting framework for
  large language models (LLMs) that addresses the challenges of imperceptibility and
  post-modification detectability. The framework consists of two components: (1) a
  rule-based code-mixing fingerprint (CF) that converts natural-language prompts into
  multi-language code-mixed variants, reducing accidental activation while maintaining
  model-side fluency, and (2) Multi-Candidate Editing (MCEdit), which jointly optimizes
  multiple candidate targets and enforces margins between target and non-target outputs
  to improve post-modification detectability.'
---

# From Construction to Injection: Edit-Based Fingerprints for Large Language Models

## Quick Facts
- arXiv ID: 2509.03122
- Source URL: https://arxiv.org/abs/2509.03122
- Authors: Yue Li; Xin Yi; Dongsheng Shi; Yongyi Cui; Gerard de Melo; Linlin Wang
- Reference count: 19
- Primary result: Proposes an end-to-end fingerprinting framework achieving at least 75% fingerprint success rate across modifications without degrading model utility.

## Executive Summary
This paper introduces an end-to-end fingerprinting framework for large language models (LLMs) that addresses two key challenges: imperceptibility and post-modification detectability. The framework combines rule-based code-mixing fingerprints (CF) with Multi-Candidate Editing (MCEdit) to create robust ownership verification mechanisms. CF converts natural-language prompts into multi-language code-mixed variants to reduce accidental activation while maintaining model fluency, while MCEdit jointly optimizes multiple candidate targets with margin suppression to improve resilience against model modifications like quantization and pruning.

## Method Summary
The framework operates in two phases: CF construction and MCEdit injection. CF construction translates each token to randomly sampled languages, filters candidates by CMF complexity threshold (δ=30%), and selects the minimum-perplexity variant. MCEdit then jointly optimizes multiple candidate targets using a loss function combining target likelihood averaging (Lpro), margin-based hard-negative suppression (Lsup), and regularization (Lreg). The approach builds on AlphaEdit and RLEdit paradigms, targeting specific FFN layers for weight updates. Generation uses temperature=0.6, top-k sampling, and 50 samples per query for evaluation.

## Key Results
- CF construction achieves code-mixed prompts with perplexity within normal range (μ±σ) of benign Alpaca baseline
- MCEdit achieves at least 75% average FSR across all modification settings (quantization, pruning, fine-tuning)
- MCEdit outperforms baseline methods (FPEdit, SFT-based injection) by 2-5% FSR under 40% pruning
- Optimal number of candidates is 5-10; performance degrades with too many targets due to optimization dilution

## Why This Works (Mechanism)

### Mechanism 1: Code-Mixing Fingerprint (CF) Construction
Code-mixed prompts reduce accidental activation while maintaining low perplexity, enabling both user-side and model-side imperceptibility. Word-level translation randomly samples languages for each token, then filters candidates by complexity (CMF threshold δ) and selects the minimum-perplexity variant. Semantically aligned cross-lingual tokens preserve contextual compatibility under the model distribution, while high-complexity mixtures are rare in benign user prompts. Core assumption: multilingual LLMs have partially aligned cross-lingual representations where semantically corresponding words induce similar contextual states.

### Mechanism 2: Multi-Candidate Mixture Promotion
Mapping one trigger to multiple candidate targets creates redundant pathways that persist under model modifications. The optimization jointly maximizes likelihood for all N candidates via averaged length-normalized negative log-likelihood. If modification attenuates some pathways, others remain detectable, yielding fault tolerance. Core assumption: Model modifications disrupt pathways independently rather than jointly.

### Mechanism 3: Non-Target Margin Suppression
Hinge-based margin loss enforces sufficient gap between target and strongest competitor, improving robustness to parameter perturbation. Lsup penalizes only when target log-probability does not exceed the strongest non-target by margin τ. This focuses optimization on hard negatives rather than diluting signal across weak alternatives. Core assumption: Hard-negative suppression generalizes better under perturbation than full-vocabulary suppression.

## Foundational Learning

- **Knowledge Editing (Locate-then-Edit, Hypernetworks):** MCEdit builds on AlphaEdit (locate-then-edit) and RLEdit (hypernetwork) paradigms; understanding FFN key-value storage and null-space constraints is prerequisite. *Quick check:* Can you explain how ROME locates factual knowledge in FFN layers and why null-space preservation matters?

- **Code-Mixing Complexity Metrics (CMF):** CF construction requires filtering by CMF score; you must know what CMF measures and how to set threshold δ. *Quick check:* What does the CMF metric quantify, and why would δ=30% represent "high complexity"?

- **Fingerprint Threat Model:** The paper assumes adversaries use perplexity filters and model modifications; evaluation design requires understanding these attack vectors. *Quick check:* What three post-injection modifications does the paper evaluate, and why is each relevant to IP protection?

## Architecture Onboarding

- **Component map:**
```
[English Sentence] → [CF Construction: Translate per-token + CMF filter + PPL select] → [Code-Mixed Trigger]
                                                                                    ↓
[Trigger + Multi-Candidate Targets] → [MCEdit: Lpro + λ_sup·Lsup + λ_reg·Lreg] → [Edited Model Weights]
                                                                                    ↓
[Verification Query] → [Stochastic Sampling Generation] → [FSR Check: response ∈ Y_i?]
```

- **Critical path:** CF construction (perplexity + complexity tradeoff) determines trigger stealth; MCEdit injection (multi-candidate + margin) determines post-modification detectability; FSR evaluation under modifications validates robustness.

- **Design tradeoffs:** Number of candidates shows non-monotonic detectability (optimal around 5-10); query length shows detectability-harmlessness tradeoff; margin τ and λ_sup show moderate values improve detectability.

- **Failure signatures:** Low FSR post-modification indicates insufficient margin τ or suboptimal candidate count; high accidental activation suggests CMF threshold too low; utility degradation indicates overfitting to LoRA; perplexity anomaly indicates insufficient CF complexity filtering.

- **First 3 experiments:** 1) Reproduce CF imperceptibility: construct CF from English sentences, measure PPL distribution vs. Alpaca baseline, verify CF falls within [0, μ+σ] normal range; 2) Ablate MCEdit components: run single-candidate, w/o Lsup, w/ FPEdit-sup variants; confirm multi-candidate and margin suppression each contribute ≥2% FSR gain under 40% pruning; 3) Stress-test across modifications: inject 10 CF pairs into Llama-3.2-3B via MCEditAlpha, evaluate FSR after 4-bit quantization, 40% sparse pruning, and Alpaca fine-tuning.

## Open Questions the Paper Calls Out

**Language coverage uncertainty:** Does expanding the candidate language set beyond five languages improve the trade-off between resistance to accidental activation and post-modification detectability? The authors note they "do not explore implementations with a broader or different set of languages."

**Model merging robustness:** Is MCEdit injection robust against model merging techniques where fingerprint parameters could be diluted? The paper notes "some scenarios (e.g., model merging) are not evaluated."

**Candidate scaling bounds:** Is there a theoretical upper bound on the number of candidate targets relative to model size before cross-target interference degrades detectability? The paper shows detectability drops when target sets become too large but does not define a scaling law.

## Limitations

- **Language coverage uncertainty:** CF construction assumes multilingual LLMs have aligned cross-lingual representations, but only evaluates on models with Chinese pretraining; effectiveness on purely English-trained models remains untested.

- **Parameter sensitivity without systematic exploration:** Optimal number of candidates (5-10) and query length appear dataset-specific rather than derived from theoretical bounds or extensive grid search.

- **CMF threshold justification:** The δ=30% complexity threshold is stated but not empirically justified; no ablation shows performance degradation at different thresholds.

## Confidence

**High confidence:** Multi-candidate optimization with margin suppression mechanism is well-supported by controlled experiments showing consistent FSR improvements across multiple modification types.

**Medium confidence:** Code-mixing imperceptibility claim is supported by perplexity distributions but accidental activation results show some variability.

**Low confidence:** Generalizability claim across all LLM architectures is based on only three models; architecture-agnostic assertion lacks systematic validation on different model families or sizes.

## Next Checks

1. **Cross-lingual robustness test:** Evaluate CF effectiveness on a purely English-trained LLM (e.g., GPT-3.5 or Claude) to verify the multilingual alignment assumption and measure both FSR and accidental activation rates.

2. **CMF threshold ablation:** Systematically vary δ from 10% to 50% and measure the tradeoff between imperceptibility (perplexity distribution shift) and effectiveness (FSR under modifications).

3. **Candidate correlation analysis:** Analyze the redundancy benefit by measuring pairwise correlation between candidate target pathways under different modification types to validate the assumption that modifications disrupt pathways independently.