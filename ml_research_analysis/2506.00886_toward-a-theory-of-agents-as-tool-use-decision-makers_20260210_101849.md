---
ver: rpa2
title: Toward a Theory of Agents as Tool-Use Decision-Makers
arxiv_id: '2506.00886'
source_url: https://arxiv.org/abs/2506.00886
tags:
- internal
- agent
- reasoning
- agents
- external
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper argues that tool-augmented agents should invoke external
  tools only when epistemically necessary, not merely for convenience. It introduces
  the Theory of Agent (ToA), a framework that unifies reasoning and acting as alternative
  means of knowledge acquisition, enabling agents to systematically coordinate introspection
  and interaction.
---

# Toward a Theory of Agents as Tool-Use Decision-Makers

## Quick Facts
- arXiv ID: 2506.00886
- Source URL: https://arxiv.org/abs/2506.00886
- Reference count: 19
- Primary result: Agents should invoke external tools only when epistemically necessary, not for convenience

## Executive Summary
This paper introduces the Theory of Agent (ToA), a framework that unifies reasoning and acting as alternative means of knowledge acquisition for tool-augmented agents. The framework establishes a knowledge boundary separating tasks solvable internally from those requiring external interaction, with epistemic effort as an invariant task requirement. By defining when agents should use tools based on epistemic necessity rather than convenience, ToA provides a normative criterion for tool use that preserves and strengthens internal reasoning capabilities.

The framework shifts agent design from pure action execution to knowledge-driven intelligence, arguing that unnecessary delegation suppresses internal reasoning capability development. This perspective complements existing decision-theoretic models and is essential for building foundation agents capable of adaptive, efficient, and goal-directed behavior across diverse domains.

## Method Summary
The paper presents a theoretical framework rather than an empirical method, establishing the Theory of Agent (ToA) through formal definitions and conceptual arguments. The approach defines knowledge boundaries between internal reasoning and external tool use, introduces epistemic effort as a task invariant, and demonstrates how epistemically calibrated decisions enable agents to preserve competence while leveraging external tools when necessary.

## Key Results
- Epistemically calibrated tool use preserves internal reasoning capabilities
- Knowledge boundary separates internally solvable tasks from those requiring external interaction
- Epistemic effort serves as an invariant task requirement across different domains

## Why This Works (Mechanism)
The framework works by reframing tool use from a convenience decision to an epistemic necessity decision. By establishing that agents have a knowledge boundary beyond which external tools become essential, the theory provides a systematic criterion for when to invoke tools. This prevents unnecessary delegation that would otherwise suppress internal reasoning development, while ensuring agents access external knowledge when truly needed.

## Foundational Learning

1. **Epistemic Necessity**: Understanding when external knowledge is required versus when internal reasoning suffices. Why needed: Prevents unnecessary tool use that weakens internal capabilities. Quick check: Can the agent solve similar tasks without external tools?

2. **Knowledge Boundary**: The conceptual line separating internal knowledge from external tool dependency. Why needed: Provides systematic criterion for tool invocation. Quick check: Does the agent correctly identify when it lacks sufficient internal knowledge?

3. **Epistemic Effort**: The invariant cognitive work required to solve a task. Why needed: Establishes task complexity independent of implementation approach. Quick check: Is effort measurement consistent across different task variations?

4. **Competence Preservation**: The ability to maintain and strengthen internal reasoning through selective tool use. Why needed: Ensures agents don't become overly dependent on external tools. Quick check: Does reasoning capability improve over time with calibrated tool use?

5. **Dual Pathway Knowledge Acquisition**: Reasoning vs. acting as alternative knowledge acquisition methods. Why needed: Unifies internal and external knowledge gathering under single framework. Quick check: Can the agent switch between pathways appropriately?

## Architecture Onboarding

**Component Map**: Agent Core -> Knowledge Boundary Detector -> Tool Selector -> External Tools -> Feedback Loop

**Critical Path**: Task Assessment → Knowledge Boundary Evaluation → Epistemic Necessity Decision → Tool Invocation/Reasoning Execution

**Design Tradeoffs**: 
- Balance between internal reasoning development and external tool efficiency
- Precision of knowledge boundary detection vs. computational overhead
- Adaptability of epistemic effort measurement across domains

**Failure Signatures**: 
- Over-reliance on tools leading to reasoning atrophy
- Incorrect knowledge boundary detection causing unnecessary tool use
- Inconsistent epistemic effort measurement across similar tasks

**3 First Experiments**:
1. Compare agent performance with epistemic calibration vs. baseline on progressively complex tasks
2. Measure reasoning capability retention over time with different tool use strategies
3. Test knowledge boundary detection accuracy across diverse task domains

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Core claims about reasoning capability preservation are not empirically demonstrated
- Epistemic effort invariance assumption across domains remains untested
- Framework lacks direct comparative validation against existing decision-theoretic models

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Epistemically calibrated tool use preserves reasoning capabilities | Low |
| Epistemic effort is an invariant task requirement | Medium |
| Unnecessary delegation suppresses reasoning capability development | Low |
| Framework provides essential perspective for foundation agents | Medium |

## Next Checks
1. Design controlled experiments comparing agent performance with and without epistemic calibration on progressively complex tasks to measure reasoning capability retention

2. Develop benchmark datasets to quantify epistemic effort across different domains and validate the knowledge boundary concept

3. Implement comparative studies testing ToA's normative criterion against existing action selection models in real-world agent deployments