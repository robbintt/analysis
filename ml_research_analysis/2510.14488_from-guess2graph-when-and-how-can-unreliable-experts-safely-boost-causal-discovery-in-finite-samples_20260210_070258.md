---
ver: rpa2
title: 'From Guess2Graph: When and How Can Unreliable Experts Safely Boost Causal
  Discovery in Finite Samples?'
arxiv_id: '2510.14488'
source_url: https://arxiv.org/abs/2510.14488
tags:
- expert
- edge
- edges
- sets
- tests
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Guess2Graph (G2G), a framework for incorporating
  unreliable expert knowledge into causal discovery algorithms without compromising
  theoretical guarantees. The core insight is to use expert predictions to guide the
  sequence of statistical tests rather than replacing test outcomes, preserving statistical
  consistency while enabling performance improvements.
---

# From Guess2Graph: When and How Can Unreliable Experts Safely Boost Causal Discovery in Finite Samples?

## Quick Facts
- **arXiv ID:** 2510.14488
- **Source URL:** https://arxiv.org/abs/2510.14488
- **Reference count:** 40
- **Primary result:** Guess2Graph framework uses expert predictions to guide test sequencing in causal discovery, achieving up to 30% F1 improvement while preserving statistical consistency.

## Executive Summary
This paper introduces Guess2Graph (G2G), a framework for incorporating unreliable expert knowledge into causal discovery algorithms without compromising theoretical guarantees. The core insight is to use expert predictions to guide the sequence of statistical tests rather than replacing test outcomes, preserving statistical consistency while enabling performance improvements. Two instantiations are developed: PC-Guess, which augments the PC algorithm with expert-guided test ordering, and gPC-Guess, a redesigned variant that achieves stronger gains by being more responsive to expert input. Theoretically, both maintain correctness regardless of expert error, with gPC-Guess provably outperforming its non-augmented counterpart when experts are "better than random." Empirically, both show monotonic improvement with expert accuracy, with gPC-Guess achieving up to 30% performance gains when experts are accurate across synthetic and real-world data, including when using LLM experts.

## Method Summary
The Guess2Graph framework uses expert predictions to guide the sequence of statistical tests in constraint-based causal discovery. Rather than replacing test outcomes with expert judgments, it partitions candidate edges into "predicted false" and "predicted true" groups and tests predicted false edges first. This ordering improves the probability of perfect skeleton recovery when experts are better than random (p_ψ ≥ 0.5). The framework is instantiated in two algorithms: PC-Guess, which augments standard PC with expert-guided edge ordering while maintaining its iterative level-by-level structure, and gPC-Guess, which redesigns the algorithm to allow immediate testing of edges with non-trivial conditioning sets based on expert predictions. Both maintain asymptotic correctness regardless of expert error, with gPC-Guess provably achieving better finite-sample performance when experts are accurate.

## Key Results
- **Monotonic Improvement:** Both PC-Guess and gPC-Guess show consistent performance gains as expert accuracy increases from p_ψ=0.3 to p_ψ=1.0
- **Algorithmic Redesign Matters:** gPC-Guess achieves up to 30% F1 improvement over baseline PC-Stable when experts are accurate, while PC-Guess shows only marginal gains
- **LLM Integration:** When using LLM experts (Claude Opus 4.1) on the Sachs dataset, gPC-Guess outperforms the LLM's direct graph generation by 25.4% F1

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Prioritizing predicted false edges in the testing sequence improves the probability of perfect skeleton recovery, provided the expert is better than random (p_ψ ≥ 0.5).
- **Mechanism:** The framework partitions candidate edges into "predicted false" and "predicted true" groups. Testing predicted false edges first allows correct removals to shrink adjacency sets early. Smaller adjacency sets reduce the number of conditional independence tests required for true edges, thereby lowering the probability of Type II errors (failing to detect dependence) on those edges.
- **Core assumption:** The expert acts as a symmetric binary channel with accuracy p_ψ ≥ 0.5; errors in sequential testing are primarily driven by the curse of dimensionality in conditioning sets.
- **Evidence anchors:** Lemma D.3 shows adding vertices to adjacency sets decreases P(Y_ni,j = 1) for true edges while increasing it for false edges.
- **Break condition:** If p_ψ < 0.5, the ordering degrades performance, although asymptotic consistency is preserved.

### Mechanism 2
- **Claim:** Replacing hard/soft constraints with test-sequence guidance preserves statistical consistency (C1) regardless of expert error.
- **Mechanism:** Unlike constraint-based methods that replace statistical tests with expert judgments, this framework uses expert predictions only to order a fixed set of necessary statistical tests. Since the final decision relies on the test outcome, not the expert, the algorithm converges to the true graph as sample size increases.
- **Core assumption:** The underlying causal discovery algorithm (e.g., PC) is asymptotically correct under standard assumptions.
- **Evidence anchors:** Theorem 5.1 proves asymptotic correctness for both PC-Guess and gPC-Guess.
- **Break condition:** Modification of the algorithm to skip tests based on expert advice.

### Mechanism 3
- **Claim:** Algorithmic redesign (gPC-Guess) is required to fully utilize expert guidance because standard PC's "level-by-level" structure resists external prioritization.
- **Mechanism:** Standard PC iterates conditioning set sizes (0, 1, 2...). If an expert correctly identifies a false edge that requires a large conditioning set for removal, standard PC must delay this removal until it reaches that level. gPC-Guess removes this rigidity, allowing the algorithm to test specific edges with necessary conditioning sets immediately.
- **Core assumption:** False edges in the graph may have non-trivial minimal d-separating sets; expert can predict these structures.
- **Evidence anchors:** gPC-Guess uses simplified validity rules allowing immediate removal of false edges with non-trivial minimal d-separating sets.
- **Break condition:** In dense graphs with limited sample sizes, aggressive testing of large conditioning sets might introduce noise.

## Foundational Learning

- **Concept:** **Constraint-Based Causal Discovery (PC Algorithm)**
  - **Why needed here:** The paper modifies the PC algorithm's core subroutines (Edge Loop and Edge Prune). Understanding "skeleton discovery," "adjacency sets," and the iterative removal of edges via conditional independence tests is the baseline.
  - **Quick check question:** If a Conditional Independence Test (CIT) returns "independent" for variables X and Y given set Z, what happens to the edge between X and Y in the skeleton?

- **Concept:** **d-Separation & Faithfulness**
  - **Why needed here:** The theoretical guarantees rely on the link between statistical independence (CI tests) and graphical structure (d-separation). The strategy of ordering tests assumes this link holds.
  - **Quick check question:** In a causal graph X → Z → Y, is X independent of Y given Z? What about without conditioning on Z?

- **Concept:** **Learning-Augmented Algorithms**
  - **Why needed here:** The paper frames its contribution as a "learning-augmented algorithm," focusing on the trade-off between *consistency* (performance with perfect expert) and *robustness* (performance with bad expert).
  - **Quick check question:** What is the theoretical difference between a hard constraint and a guidance-based ordering in terms of worst-case error?

## Architecture Onboarding

- **Component map:**
  - Data & Expert Prediction → EOE (Generate Orderings) → gPC-Guess (Guided Edge Loop) → Final Skeleton

- **Critical path:** Data & Expert Prediction → EOE (Generate Orderings) → gPC-Guess (Guided Edge Loop) → Final Skeleton

- **Design tradeoffs:**
  - **PC-Guess vs. gPC-Guess:** PC-Guess is safer (closer to standard implementation) but has limited gains. gPC-Guess offers higher potential gains (up to 30% F1 improvement) by testing large conditioning sets early but requires careful implementation to handle the relaxed validity rules.
  - **Expert Accuracy:** The system relies on p_ψ ≥ 0.5. Integration is beneficial only if the expert is better than a coin flip.

- **Failure signatures:**
  - **Performance Drop:** F1 score lower than baseline (PC-Stable) → indicates p_ψ < 0.5 (expert is misleading).
  - **Stagnant Improvement:** PC-Guess shows <5% gain even with high expert accuracy → indicates graph structure requires larger d-separating sets; switch to gPC-Guess.
  - **Runtime Increase:** gPC-Guess is significantly slower than baseline → potential issue in EP ordering logic or a very dense graph.

- **First 3 experiments:**
  1. **Sanity Check (Synthetic):** Run gPC-Guess on ER3 graphs (d=20, n=100) with a simulated expert at p_ψ=0.8. Verify F1 score improves monotonically over baseline.
  2. **Robustness Test (Break Condition):** Run the same setup with p_ψ=0.3. Confirm performance degrades gracefully (or matches baseline) rather than catastrophic failure.
  3. **Real-World Integration:** Integrate a simple LLM (e.g., Claude or GPT) as the expert on the Sachs dataset. Compare the F1 score of gPC-Guess vs. the LLM's direct graph generation.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the Guess2Graph (G2G) framework be formally extended to score-based and Functional Causal Model (FCM)-based algorithms while preserving statistical consistency and finite-sample guarantees?
- **Basis in paper:** The Discussion section states, "Future work includes extensions to score/FCM-based algorithms." Additionally, Appendices C.2 and C.3 propose modifications for SE-GES and RESIT but list theoretical properties as "conjectured" rather than proven.
- **Why unresolved:** The current theoretical analysis and proof techniques focus on constraint-based methods, which rely on distinct sequential testing structures compared to greedy search or topological sorting in other paradigms.
- **What evidence would resolve it:** Formal proofs extending Lemmas 4.1 and D.9 to score-based metrics (e.g., BIC) or regression-based residual tests, demonstrating that guided test ordering maintains asymptotic correctness in these alternative architectures.

### Open Question 2
- **Question:** Do the theoretical guarantees for G2G (specifically regarding runtime monotonicity) hold under relaxed assumptions where conditional independence test outcomes are not strictly independent?
- **Basis in paper:** Appendix E.4 notes that while results are proven under the assumption of independent test outcomes, "A rigorous proof under these relaxed conditions remains an open problem."
- **Why unresolved:** The current proofs rely on the independence of test statistics to simplify the analysis of expected stopping times and error propagation, an assumption that does not strictly hold when tests reuse the same finite dataset.
- **What evidence would resolve it:** A theoretical analysis showing that monotonicity holds under limited positive dependence between test outcomes, or empirical evidence demonstrating that violations of independence do not invalidate the monotonic improvement guarantees.

### Open Question 3
- **Question:** How can one efficiently validate the quality of an expert's predictions (e.g., via self-consistency or likelihood scores) to ensure performance does not degrade in the "World 1" regime?
- **Basis in paper:** Appendix C.1 identifies the need to "prevent World 1 scenarios by detecting when LLM predictions are harmful" and proposes heuristics like self-consistency or likelihood-based fitness scores as potential solutions.
- **Why unresolved:** While the paper suggests validation protocols, it does not provide theoretical bounds or empirical thresholds for these scores that guarantee the expert is "better than random" (the condition required for C3), leaving the practical reliability of such screening methods unverified.
- **What evidence would resolve it:** Deriving theoretical bounds connecting expert self-consistency scores to graph accuracy, or empirical benchmarks defining score thresholds that reliably distinguish helpful experts from harmful ones without access to the ground truth.

## Limitations

- **Implementation Gaps:** The exact mechanism for extracting d-separating sets from an expert's predicted DAG is underspecified, particularly for simulated experts.
- **Sample Size Sensitivity:** gPC-Guess's aggressive early testing of large conditioning sets can introduce noise in low-sample regimes, limiting its practical advantage.
- **Structure Dependency:** The benefits of algorithmic redesign are most pronounced in graphs requiring non-trivial d-separating sets for false edge removal, which may not be common in all applications.

## Confidence

- **High Confidence:** Asymptotic correctness (Theorem 5.1) and the core insight that expert-guided test ordering preserves consistency while improving finite-sample performance. The theoretical framework is sound.
- **Medium Confidence:** The empirical claims of 30% F1 improvement with gPC-Guess. The synthetic experiments are well-controlled, but the real-world application (Sachs dataset) has limited statistical power due to small sample size (n=100).
- **Low Confidence:** The scalability claims and the precise conditions under which gPC-Guess outperforms PC-Guess in practice. The paper doesn't fully characterize the graph structures where redesign is most beneficial.

## Next Checks

1. **Edge Ordering Sensitivity:** Implement a variant where edges are ordered randomly within the predicted-false and predicted-true partitions (rather than PC's level-by-level structure). Measure whether this simple modification captures most of gPC-Guess's gains, which would suggest the core benefit comes from test sequencing rather than algorithmic redesign.

2. **D-Separation Prediction Accuracy:** For simulated experts, measure whether d-separation prediction accuracy (p_d-sep) is indeed higher than edge prediction accuracy (p_ψ), as the paper suggests. This would validate the assumption that experts can provide useful structural guidance beyond simple edge classifications.

3. **Sample Size Threshold:** Systematically vary sample size (n) in synthetic experiments to identify the minimum n where gPC-Guess's performance advantage over PC-Guess becomes statistically significant. This would clarify the practical limitations of aggressive early testing of large conditioning sets.