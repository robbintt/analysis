---
ver: rpa2
title: 'Language Models For Generalised PDDL Planning: Synthesising Sound and Programmatic
  Policies'
arxiv_id: '2508.18507'
source_url: https://arxiv.org/abs/2508.18507
tags:
- planning
- problems
- value
- pddl
- policies
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an LM-based planner, LMPLAN, that generates
  Python programs as value functions and sound policies for PDDL planning. The approach
  outperforms state-of-the-art planners and recent LM approaches on competition benchmarks
  within fixed time and memory constraints.
---

# Language Models For Generalised PDDL Planning: Synthesising Sound and Programmatic Policies

## Quick Facts
- arXiv ID: 2508.18507
- Source URL: https://arxiv.org/abs/2508.18507
- Reference count: 26
- Primary result: LMPLAN generates Python programs as sound policies, outperforming state-of-the-art planners on competition benchmarks while sometimes performing better with meaningless symbols than natural language

## Executive Summary
This paper introduces LMPLAN, an LM-based planner that generates Python programs as value functions and sound policies for PDDL planning. The approach demonstrates superior performance on competition benchmarks compared to state-of-the-art planners and recent LM approaches, all within fixed time and memory constraints. Surprisingly, LMPLAN sometimes performs better on planning problems represented with meaningless symbols rather than natural language, challenging the assumption that language models rely on word semantics or memorization.

## Method Summary
LMPLAN uses large language models to generate Python code that represents value functions and sound policies for PDDL planning domains. The system encodes planning problems into a format that LLMs can process, then generates executable Python code that solves the planning tasks. The approach focuses on STRIPS-style domains and leverages the programming capabilities of modern LLMs to create generalizable planning solutions that can be executed and verified.

## Key Results
- LMPLAN outperforms state-of-the-art planners on PDDL competition benchmarks within fixed time/memory constraints
- The system generates sound Python policies that can be executed and verified
- Surprisingly, LMPLAN sometimes performs better with meaningless symbols than natural language representations
- Results suggest LMs can learn symbolic planning beyond simple memorization

## Why This Works (Mechanism)
LMPLAN works by leveraging the code generation capabilities of large language models to create executable planning policies. The approach transforms PDDL problems into formats that LLMs can process, then generates Python code that represents value functions and planning policies. The generated code is sound and verifiable, allowing the system to produce correct solutions. The surprising effectiveness with meaningless symbols suggests that LLMs may be learning underlying structural patterns rather than relying on semantic understanding.

## Foundational Learning
- PDDL (Planning Domain Definition Language): Standard language for expressing planning problems; needed to understand the problem domain format
- STRIPS planning: Classical planning formalism; quick check: can you identify preconditions and effects in a simple action
- Value functions: Functions that estimate utility of states; quick check: can you write a simple heuristic for grid navigation
- Sound policies: Guaranteed-to-succeed planning strategies; quick check: can you verify a policy terminates in a goal state
- Python code generation: LLM capability to produce executable code; quick check: can you generate a simple function from a prompt

## Architecture Onboarding

**Component Map:**
Problem Encoding -> LLM Prompt -> Python Code Generation -> Code Execution/Verification -> Planning Policy

**Critical Path:**
The critical path flows from problem encoding through LLM processing to code generation and execution. The LLM prompt engineering and the verification system are the most critical components, as they directly impact solution quality and correctness.

**Design Tradeoffs:**
- Expressiveness vs. execution efficiency in generated Python code
- Prompt complexity vs. LLM response quality
- Verification overhead vs. solution reliability
- Domain generalization vs. specialized performance

**Failure Signatures:**
- Incorrect policy generation due to prompt misinterpretation
- Runtime errors in generated Python code
- Incomplete coverage of edge cases in planning problems
- Performance degradation on temporally extended domains

**First Experiments:**
1. Verify generated Python code executes correctly on simple STRIPS problems
2. Test policy soundness by running generated solutions to completion
3. Compare performance across different prompt formulations

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to STRIPS-style domains, unclear scalability to complex PDDL features
- Lack of theoretical explanation for why meaningless symbols sometimes outperform natural language
- No testing on temporally extended or numeric PDDL domains
- Limited analysis of failure modes and edge cases

## Confidence
- High confidence: LMPLAN generates sound policies with Python code, well-supported by implementation and testing
- High confidence: Performance comparisons against state-of-the-art planners are rigorously documented
- Medium confidence: Explanation for meaningless symbols outperforming natural language is speculative

## Next Checks
1. Test LMPLAN on temporally extended and numeric PDDL domains to assess scalability beyond STRIPS
2. Conduct ablation studies with controlled symbol variations to isolate whether the meaningless-symbol advantage stems from syntax simplicity versus semantic independence
3. Perform cross-domain transfer experiments where models trained on one domain class are evaluated on structurally similar but semantically distinct domains to probe genuine generalization versus memorization