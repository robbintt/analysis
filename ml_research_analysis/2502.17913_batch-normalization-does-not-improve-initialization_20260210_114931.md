---
ver: rpa2
title: Batch normalization does not improve initialization
arxiv_id: '2502.17913'
source_url: https://arxiv.org/abs/2502.17913
tags:
- batch
- neural
- function
- normalization
- does
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper challenges a claim from prior work that batch normalization
  (BN) improves neural network initialization. The authors construct a simple counterexample:
  a single-neuron neural network with identity activation and a three-sample learning
  set.'
---

# Batch normalization does not improve initialization

## Quick Facts
- arXiv ID: 2502.17913
- Source URL: https://arxiv.org/abs/2502.17913
- Reference count: 11
- Primary result: A single-neuron counterexample shows batch normalization does not improve initialization compared to standard networks.

## Executive Summary
This paper challenges a claim from prior work that batch normalization (BN) improves neural network initialization by bringing initial weights closer to local optima. The authors construct a minimal counterexample: a single-neuron network with identity activation and three training samples. They show that initializing at the optimal point for a standard network (W* = (1, 3)) does not yield a local optimum for the BN network, as the gradient of the BN loss does not vanish at this point. This directly contradicts the claimed initialization advantage, demonstrating that the inequality proposed in prior work fails in this simple case.

## Method Summary
The authors construct a single-neuron neural network with identity activation and a three-sample learning set. They compute the optimal weight configuration W* for the standard network and show that this same configuration does not produce a local optimum for the batch-normalized network. The gradient of the BN loss function at W* is explicitly calculated and shown to be non-zero, violating a necessary condition for local optima. This counterexample serves as a mathematical refutation of the claimed initialization advantage of batch normalization.

## Key Results
- The inequality from Santurkar & Tsipras (2018) Lemma 4.5 is mathematically false for BN networks
- Initializing BN networks at optimal weights for standard networks does not guarantee local optima
- Batch normalization fundamentally alters the optimization landscape, creating different stationary points than standard networks
- The counterexample holds even with fixed γ=1 and β=0 parameters in the BN transform

## Why This Works (Mechanism)

### Mechanism 1: Counterexample-Based Falsification of Initialization Claim
- Claim: The inequality in Santurkar & Tsipras (2018) Lemma 4.5 is mathematically false; BN does not inherently bring initializations closer to optima
- Mechanism: A minimal neural network (single neuron, identity activation, 3 training samples) is constructed where initializing at W₀ = W* (the global optimum for the standard network) causes the claimed inequality to require Ŵ* = W₀, yet W₀ is provably not a local optimum for the BN loss because ∇Ĉ(W*) ≠ 0
- Evidence anchors: [abstract] shows the claim is false; [section] Page 5 demonstrates the gradient non-vanishing at W₀; [corpus] arXiv:2505.11312 provides context on normalization effects

### Mechanism 2: Gradient-Based Optimality Verification
- Claim: A weight configuration that minimizes the standard loss need not be a stationary point of the BN-transformed loss
- Mechanism: The closed-form gradient of Ĉ(w) at W* = (1, 3) is computed and shown to be ∇Ĉ(W*) = (-0.34, 0.11) ≠ 0, violating the necessary condition for local optima
- Evidence anchors: [section] Page 5 explicitly calculates the non-zero gradient; [section] Remark 3.3 identifies the original proof's error
- Core assumption: First-order optimality conditions (∇f(x*) = 0) are necessary for local minima in differentiable functions

### Mechanism 3: BN's Scale Invariance Transforms the Loss Landscape
- Claim: BN fundamentally alters the optimization landscape by introducing scale invariance, creating a different set of stationary points than the original network
- Mechanism: BN computes batch-dependent statistics μ(w) and σ(w), making the normalized output (z - μ(w))/σ(w) a non-linear function of weights; Ĉ has local minima where 3w₁ = 5w₂ (a line of equivalent solutions due to scale invariance), which does not include W* = (1, 3)
- Evidence anchors: [section] Definition 2.6 shows μ and σ depend on weights; [section] Page 5 demonstrates the local minima line; [corpus] arXiv:2501.14441 supports BN's effect on representations
- Core assumption: The batch statistics μ and σ are non-constant functions of weights, so normalization is not a simple affine reparameterization

## Foundational Learning

- Concept: **First-Order Optimality Conditions**
  - Why needed here: The proof hinges on ∇Ĉ(W*) ≠ 0 implying W* is not a local minimum. You must understand that vanishing gradient is necessary (not sufficient) for local optima
  - Quick check question: If ∇f(x*) ≠ 0, can x* be a local minimum of f? Why or why not?

- Concept: **Batch Normalization as a Weight-Dependent Transform**
  - Why needed here: BN is not a fixed preprocessing step—μ and σ depend on current weights, making the normalization function itself change during training
  - Quick check question: For a neuron ϕw(x) = ⟨w, x⟩ with batch inputs {(1,1), (1,2), (2,3)}, express μ as a function of w = (w₁, w₂)

- Concept: **Counterexample Structure in Mathematical Refutation**
  - Why needed here: The paper uses a minimal example (1 neuron, 3 samples) to disprove a general claim. Understanding why this is valid requires grasping logical implication
  - Quick check question: If a theorem claims "for all neural networks, property P holds," how many counterexamples are needed to disprove it?

## Architecture Onboarding

- Component map:
  - Standard Neuron: h(x) = g(⟨w, x⟩ + b), outputs raw pre-activations
  - Batch Statistics Computation: μ = (1/M) Σm zjm, σ = √[(1/M) Σm (zjm - μ)²] — computed per-feature across batch
  - BN Transform: ẑj = γ(zj - μ)/σ + β — normalizes to zero-mean/unit-variance, then scales/shifts
  - Loss Functions: C(w) = Σ(ϕw(x̄⁽ⁱ⁾ - ȳ⁽ⁱ⁾)² vs. Ĉ(w) = Σ(ϕ̂w(x̄⁽ⁱ⁾ - ȳ⁽ⁱ⁾)² — different functions with different optima

- Critical path:
  1. Initialize weights W₀
  2. Forward pass → activations Z = [z₁, ..., z_M]
  3. Compute μ(w), σ(w) from Z (weight-dependent!)
  4. Apply BN: Ẑ = γ(Z - μ)/σ + β
  5. Compute loss on Ẑ outputs
  6. Backprop through BN (μ and σ introduce non-trivial gradient terms)

- Design tradeoffs:
  - **Fixed vs. learned γ, β**: Paper fixes γ=1, β=0; real implementations learn these, potentially altering optima locations
  - **Batch size effects**: Paper uses batch=dataset (N=3); smaller batches add noise to μ, σ estimates
  - **Activation functions**: Paper uses identity; ReLU/sigmoid introduce additional non-linearities

- Failure signatures:
  - Transferring "optimal" weights from non-BN models to BN-equipped models without retraining
  - Assuming loss landscapes are equivalent between BN and non-BN variants
  - Citing Lemma 4.5 from Santurkar & Tsipras as justification for initialization strategies

- First 3 experiments:
  1. Reproduce the counterexample numerically: Implement the single-neuron, 3-sample network, compute C(w) and Ĉ(w) surfaces, verify ∇Ĉ(W*) ≠ 0 using automatic differentiation
  2. Test with learned γ, β: Add trainable scale/shift parameters, train to convergence, and check if W* = (1, 3) becomes reachable or if optima remain on the 3w₁ = 5w₂ line
  3. Generalize to ReLU networks: Replace identity activation with ReLU, generate a small regression dataset, and compare optima locations between BN and non-BN variants to test if the conclusion extends beyond linear networks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the finding that batch normalization fails to improve initialization generalize to deep, multi-layer neural networks?
- Basis in paper: [inferred] The counterexample provided is restricted to a "NN consisting of a single neuron" (Example 3.2)
- Why unresolved: The mathematical proof is specific to a single-neuron architecture and does not account for the complex interactions of batch normalization across multiple hidden layers
- What evidence would resolve it: A formal analysis or empirical study demonstrating whether the initialization disadvantage persists in deep architectures with stacked batch-normalized layers

### Open Question 2
- Question: Do non-linear activation functions alter the relationship between batch normalization and initialization quality?
- Basis in paper: [inferred] The counterexample relies on a neuron with the "identity as activation function" (Section 3)
- Why unresolved: Real-world networks utilize non-linearities (e.g., ReLU, Sigmoid) which fundamentally alter the loss surface and gradient behavior compared to the linear case presented
- What evidence would resolve it: Analysis of the initialization optimality in networks using standard non-linear activations, checking if the inequality failure still occurs

### Open Question 3
- Question: Can a modified theoretical bound be established that successfully describes a valid initialization advantage for batch normalization?
- Basis in paper: [inferred] The paper concludes that the specific inequality in Lemma 4.5 is "wrong" (Section 3), leaving a theoretical void regarding the initialization properties of BN
- Why unresolved: While the specific claim from prior work is refuted, the paper does not propose an alternative theoretical framework to replace the disproven lemma
- What evidence would resolve it: A new theorem providing a correct inequality or characterization of the distance to local optima for batch-normalized networks

## Limitations

- The counterexample is limited to a single neuron with identity activation, which may not capture the complexity of deep networks where BN is typically deployed
- The proof assumes fixed γ=1 and β=0 parameters, whereas in practice these are learnable parameters that could potentially compensate for normalization effects
- The minimal dataset (3 samples) and batch size (equal to dataset size) may not represent typical training scenarios with larger batches and more diverse data

## Confidence

- **High**: The mathematical claim that the inequality is false is well-supported by the explicit counterexample and gradient calculations
- **Medium**: The broader implications for practical deep learning architectures are less certain due to the simplicity of the counterexample used

## Next Checks

1. **Extend to ReLU Networks**: Replicate the counterexample using ReLU activation and a small regression dataset to verify the conclusion holds beyond linear networks

2. **Test with Learnable γ, β**: Add trainable scale and shift parameters to the BN transform and train to convergence to determine if the optimal weight configurations change

3. **Analyze Landscape Topology**: For the 3-sample case, plot both C(w) and Ĉ(w) surfaces to visualize how BN transforms the loss landscape and verify that local optima lie on different manifolds