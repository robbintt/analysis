---
ver: rpa2
title: Boosting Ray Search Procedure of Hard-label Attacks with Transfer-based Priors
arxiv_id: '2507.17577'
source_url: https://arxiv.org/abs/2507.17577
tags:
- attack
- queries
- sign-opt
- prior-opt
- attacks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes a novel approach to improve the efficiency\
  \ of hard-label adversarial attacks by incorporating transfer-based priors from\
  \ surrogate models into the gradient estimation process. The authors reformulate\
  \ the attack as a continuous optimization problem by minimizing the \u2113p-norm\
  \ distance to the adversarial region along a ray direction."
---

# Boosting Ray Search Procedure of Hard-label Attacks with Transfer-based Priors

## Quick Facts
- arXiv ID: 2507.17577
- Source URL: https://arxiv.org/abs/2507.17577
- Reference count: 40
- One-line primary result: Novel approach incorporating transfer-based priors from surrogate models into gradient estimation significantly improves query efficiency of hard-label adversarial attacks.

## Executive Summary
This paper introduces a novel method to improve the efficiency of hard-label adversarial attacks by leveraging transfer-based priors from surrogate models. The approach reformulates the attack as a continuous optimization problem, minimizing the ℓp-norm distance to the adversarial region along a ray direction. Two algorithms, Prior-Sign-OPT and Prior-OPT, are proposed to estimate gradients more accurately by projecting the true gradient onto a subspace spanned by priors and random directions. Extensive experiments demonstrate significant improvements over 11 state-of-the-art methods in terms of query efficiency.

## Method Summary
The method estimates gradients for hard-label attacks by combining transfer-based priors from surrogate models with random directions. It constructs an orthonormal basis from these vectors and approximates the projection of the true gradient onto this subspace. Prior-OPT uses binary search for accurate prior weighting, while Prior-Sign-OPT uses a cheaper sign-based approach. The algorithms achieve better cosine similarity with the true gradient compared to existing Sign-OPT, resulting in more efficient attacks.

## Key Results
- Prior-Sign-OPT achieves significantly lower distortion than Sign-OPT across various query budgets on both ImageNet and CIFAR-10
- The proposed method outperforms 11 state-of-the-art hard-label attack methods in terms of query efficiency
- Theoretical analysis proves that the proposed gradient estimators achieve better cosine similarity with the true gradient compared to Sign-OPT
- The number of priors positively correlates with attack performance, with diminishing returns after a certain point

## Why This Works (Mechanism)

### Mechanism 1: Subspace Projection via Transfer-based Priors
Incorporating gradients from surrogate models into the gradient estimation process significantly improves the cosine similarity between the estimated and true gradients compared to random-only estimation. The method constructs a subspace spanned by transfer-based priors and orthogonal random directions, approximating the projection of the true gradient onto this subspace rather than relying solely on random finite differences. Theoretical analysis shows that cosine similarity increases monotonically with the quality of the priors. If surrogate and target models are uncorrelated (e.g., different architectures), the prior adds no directional information and performance converges to the random-only baseline.

### Mechanism 2: Differential Query Allocation (Prior-OPT Strategy)
Allocating precise but expensive binary search queries to the prior vectors while using cheap sign-based queries for the random vectors optimizes the query-accuracy trade-off. The Prior-OPT algorithm treats priors and random vectors asymmetrically, using finite difference (requiring binary search) to accurately weigh the priors because their alignment varies significantly, while using the "sign trick" for random vectors, requiring only 1 query per vector. This hybrid approach minimizes query cost while maximizing the benefit of informative priors. If the query budget is extremely low, the overhead of binary searches for the priors might dominate the budget.

### Mechanism 3: Orthogonalization of Priors
Explicitly orthogonalizing priors from multiple surrogate models via Gram-Schmidt prevents redundant or conflicting directional information from degrading the gradient estimate. When using multiple priors, the gradients may not be orthogonal, and Gram-Schmidt orthonormalization transforms the set of priors and random vectors into an orthogonal basis. This ensures that the estimated gradient vector lies strictly in the spanned subspace without interference from correlated priors. If the priors are linearly dependent or perfectly correlated, orthogonalization reduces the effective number of directions.

## Foundational Learning

- **Hard-label Black-box Attacks**: Only have access to top-1 label, not probabilities or logits. Understanding this is crucial to realizing why standard gradient descent is impossible and why "binary search" for the boundary is necessary. Quick check: If you query the model with an image and it returns "Cat", can you calculate a loss gradient? (Answer: No).

- **Ray Search Optimization**: The method searches for a "ray" direction θ from the benign image that reaches the adversarial region with minimum distance. The objective function g(θ) is this radius. Quick check: What is the variable being optimized in Eq. 3: the pixel values x or the direction vector θ? (Answer: θ).

- **Zeroth-order Optimization / Finite Differences**: The method must estimate gradients without analytical derivatives, relying on finite differences. You need to understand why this is query-expensive (requires evaluating g twice) and why the "sign trick" saves queries. Quick check: To estimate a gradient using finite differences in a single direction u, how many times must you evaluate the function g? (Answer: 2).

## Architecture Onboarding

- **Component map**: Surrogate Model → Target Model → Ray Optimizer → Gradient Estimator → Updated Ray Direction

- **Critical path**:
  1. Initialization: Select initial ray θ₀ (random or PGD-guided)
  2. Prior Extraction: For each surrogate model, compute gradient of surrogate loss → kᵢ
  3. Basis Construction: Concatenate kᵢ and random vectors, apply Gram-Schmidt to get orthonormal basis {p, u}
  4. Gradient Estimation: 
     - For random basis {u}: Query target model → get signs → aggregate into v⊥
     - For prior basis {p} and v⊥: Run binary search on target model to get scalar coefficients (Prior-OPT)
     - Combine to form gradient estimate v*
  5. Update: Line search for step size η, update θₜ

- **Design tradeoffs**:
  - Prior-OPT vs. Prior-Sign-OPT: Prior-OPT is more query-expensive per iteration but more accurate; Prior-Sign-OPT is cheaper but less precise
  - Number of Priors (s): More priors generally better, but increases computation and orthogonalization complexity
  - Number of vectors (q): Total dimension of estimation subspace; higher q improves accuracy but scales linearly with query cost

- **Failure signatures**:
  - Stuck Distortion: If distortion does not decrease, check if αᵢ (prior quality) is near zero
  - High Initial Distortion: If θ₀ is poor, convergence is slow; use PGD initialization for the ray
  - Numerical Instability: If σ is too small, binary search/finite difference approximations fail

- **First 3 experiments**:
  1. Baseline Verification: Implement Sign-OPT and Prior-Sign-OPT on CIFAR-10 using ResNet-110 surrogate to attack WRN-28 target; verify Prior-Sign-OPT achieves lower distortion
  2. Ablation on Prior Quality: Attack target model with same-architecture surrogate (high α) vs. different-architecture surrogate (low α); measure convergence speed gap
  3. Hyperparameter Sensitivity: Test effect of number of vectors q (q=50 vs q=200) on Attack Success Rate at 1K and 5K queries

## Open Questions the Paper Calls Out

- **Open Question 1**: How can the performance of Prior-Sign-OPT and Prior-OPT be specifically improved on the CIFAR-10 dataset? The paper states it aims to further improve performance on CIFAR-10, where results show less distinct advantages over baselines compared to ImageNet.

- **Open Question 2**: What is the optimal strategy for selecting surrogate models to ensure transfer-based prior maintains high cosine similarity with the true gradient? The paper theoretically proves performance depends on cosine similarity α but doesn't provide general guidance for blind attacks.

- **Open Question 3**: Can targeted attack initialization be refined to better align surrogate's decision boundary with target model's, reducing reliance on setting a "new target class"? The current approach of setting a new target class based on distance heuristics may produce priors pointing to semantically different regions.

## Limitations
- The effectiveness heavily depends on the quality of transfer-based priors; poorly aligned surrogates degrade performance to Sign-OPT levels
- Prior-OPT requires binary searches for each prior direction, which can be costly and may negate benefits at lower query budgets
- Performance depends on hyperparameter choices like number of vectors and gradient clipping threshold, which may vary across datasets and architectures

## Confidence
- **High Confidence**: Prior-Sign-OPT outperforms Sign-OPT in query efficiency (supported by extensive experiments across 11 baselines and two datasets)
- **Medium Confidence**: Orthogonalization of priors is critical for performance (theoretical justification exists, but empirical ablation is limited)
- **Low Confidence**: Prior-OPT consistently outperforms Prior-Sign-OPT (difference is marginal in some settings, and binary search overhead is not fully quantified)

## Next Checks
1. **Surrogate Quality Ablation**: Systematically vary similarity between surrogate and target models and measure the gap in convergence speed and final distortion to validate dependency on α

2. **Query Budget Stress Test**: Run Prior-OPT and Prior-Sign-OPT on CIFAR-10 with query budgets of 500, 1K, and 2K to measure whether binary search overhead in Prior-OPT becomes prohibitive

3. **Initialization Sensitivity**: Compare random initialization vs. PGD-guided initialization for Prior-Sign-OPT on ImageNet to quantify trade-off between initialization cost and convergence speed