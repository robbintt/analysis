---
ver: rpa2
title: Locally Pareto-Optimal Interpretations for Black-Box Machine Learning Models
arxiv_id: '2508.15220'
source_url: https://arxiv.org/abs/2508.15220
tags:
- decision
- interpretations
- names
- trees
- tree
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a scalable method for synthesizing locally
  Pareto-optimal interpretations of black-box machine learning models, balancing accuracy
  and explainability. The approach uses Multi-Objective Monte Carlo Tree Search (MO-MCTS)
  to generate candidate interpretations, followed by SAT-based verification to ensure
  local Pareto-optimality within user-defined slack parameters.
---

# Locally Pareto-Optimal Interpretations for Black-Box Machine Learning Models

## Quick Facts
- arXiv ID: 2508.15220
- Source URL: https://arxiv.org/abs/2508.15220
- Reference count: 40
- Key outcome: Scalable synthesis of locally Pareto-optimal interpretations using MO-MCTS + SAT verification, outperforming purely symbolic approaches

## Executive Summary
This paper introduces a two-phase hybrid approach for synthesizing locally Pareto-optimal interpretations of black-box ML models that balance accuracy and explainability. The method combines multi-objective Monte Carlo Tree Search (MO-MCTS) to generate candidate interpretations with SAT-based verification to certify local Pareto-optimality within user-defined slacks. Experiments on 20 benchmarks demonstrate that this approach produces interpretations close to globally Pareto-optimal solutions while scaling to larger problems where purely symbolic methods fail. The algorithm provides anytime guarantees, yielding useful solutions at any execution point.

## Method Summary
The approach synthesizes decision tree interpretations through a two-phase process: (1) MO-MCTS generates candidate interpretations by exploring a grammar-based search space, treating decision tree synthesis as a deterministic multi-objective MDP; (2) SAT verification checks whether each candidate is locally Pareto-optimal within specified slacks (δc for correctness, δe for explainability). If a candidate fails verification, the SAT solver provides an improved interpretation that replaces it. The method uses PAC learning to estimate correctness from finite samples and a weighted explainability metric that accounts for tree complexity and feature costs.

## Key Results
- Scalable synthesis: Successfully generates interpretations on 20 benchmarks where purely symbolic approaches like Synplicate fail
- Anytime guarantees: Produces useful solutions at any execution point with verifiable local optimality
- Near-global optimality: Certified LPO interpretations closely approximate globally Pareto-optimal solutions
- Trade-off visualization: Enables interactive exploration of accuracy-explainability trade-offs via Pareto curves

## Why This Works (Mechanism)

### Mechanism 1: MO-MCTS Monotonic Pareto Frontier Approximation
MO-MCTS generates increasingly better approximations of the Pareto-optimal frontier over iterations. The algorithm treats decision tree synthesis as a deterministic MO-MDP where states are (partial or complete) decision trees and actions are grammar production rules. It maintains an incomparable set of best-effort Pareto-optimal points that improve monotonically: for every point p at iteration i, there exists a point p' at iteration j > i such that p ⪯ p' (Lemma 1). The search uses hypervolume-based upper confidence bounds and RAVE heuristics to balance exploration-exploitation.

### Mechanism 2: SAT-Based Local Optimality Certification
Boolean satisfiability encoding verifies whether an interpretation is locally Pareto-optimal within user-specified slacks. For each candidate interpretation D with measures (c, e), the algorithm constructs a Boolean formula Φ(c, e, c+δc, e+δe) that is satisfiable iff there exists D' such that (c, e) ≺ (C(D'), E(D')) ⪯ (c+δc, e+δe). The encoding has four components: Φsyntax (grammar-compliant trees), Φcorr (accuracy bounds), Φexp (explainability bounds), and Φ(dominance). If UNSAT, D is certified as LPO; if SAT, the satisfying assignment yields an improved D'.

### Mechanism 3: Anytime Hybrid Search-Verification Integration
Combining MO-MCTS search with SAT verification yields an anytime algorithm that provides local optimality guarantees while scaling to larger benchmarks. Phase 1 (MO-MCTS) runs for time budget TMO-MCTS, producing best-effort candidates. Phase 2 iteratively processes these candidates: SAT verification either certifies LPO status or discovers dominating interpretations that replace the original. The algorithm returns S' (certified LPO interpretations) and S (remaining best-effort candidates). Theorem 1 guarantees all interpretations in S' are LPO.

## Foundational Learning

- **Concept: Pareto Dominance and Optimality**
  - Why needed here: Core formalism for reasoning about trade-offs between accuracy and explainability; essential for understanding both global and local variants.
  - Quick check question: Given two interpretations with goodness tuples (0.85, 15) and (0.90, 12), does either Pareto-dominate the other?

- **Concept: Probably Approximately Correct (PAC) Learning**
  - Why needed here: The correctness measure uses PAC framework to estimate accuracy from finite samples with statistical guarantees.
  - Quick check question: If you need correctness estimates within ε=0.05 with confidence 1-δ=0.9, what does PAC guarantee about your estimate?

- **Concept: Monte Carlo Tree Search (MCTS)**
  - Why needed here: Provides the search foundation; understanding UCT, progressive widening, and tree policies is essential for debugging and extending Phase 1.
  - Quick check question: In standard MCTS, what role does the exploration-exploitation balance play in the selection phase?

## Architecture Onboarding

- **Component map**: Feature/label definition → MO-MDP construction → MO-MCTS execution (TMO-MCTS) → SAT encoding per candidate → Verification/refinement loop → Return S' and S

- **Critical path**: Feature/label definition → MO-MDP construction → MO-MCTS execution (TMO-MCTS) → SAT encoding per candidate → Verification/refinement loop → Return S' and S

- **Design tradeoffs**:
  - Longer TMO-MCTS improves candidate quality but reduces verification time
  - Tighter slacks (δc, δe) provide stronger guarantees but increase SAT complexity
  - Larger node budget B increases expressivity but exponentially grows search space
  - Assumption: Restricting actions to first non-terminal (Section 5) reduces branching without losing expressivity

- **Failure signatures**:
  - Empty S' with non-empty S: SAT verification timing out; increase Toverall or loosen slacks
  - S' contains only trivial interpretations: MO-MCTS exploration insufficient; increase TMO-MCTS or check Progressive Widening settings
  - Results diverge from Synplicate on small benchmarks: Bug in SAT encoding or Pareto comparison logic

- **First 3 experiments**:
  1. Reproduce AutoTaxi benchmark with 20-min timeout: Verify MO-MCTS finds 8/12 PO points and SAT verification certifies LPO status; compare Pareto curve to paper's Figure 6a
  2. Ablation on TMO-MCTS/Toverall split: Run Car Evaluation benchmark with varying phase-1 time fractions (25%, 50%, 75%); plot resulting S' cardinality and quality to validate the 50% default
  3. Slack sensitivity analysis: On Balance Scale benchmark, vary δc ∈ {0.01, 0.02, 0.05} and δe ∈ {1, 5, 10}; measure impact on SAT solve time and LPO certification rate to calibrate slack selection

## Open Questions the Paper Calls Out
- Can the solutions or counterexamples generated by the SAT solver in the verification phase be fed back into the MO-MCTS procedure to improve search heuristics?
- How does the choice of multi-objective search algorithm in the first phase (e.g., MO-MCTS vs. evolutionary algorithms) impact the quality and diversity of the candidate interpretations?
- How sensitive is the algorithm's ability to approximate the global Pareto-optimal front to the specific values chosen for the correctness (δc) and explainability (δe) slacks?
- Does the experimental restriction of actions to the first non-terminal node degrade the quality of the synthesized interpretations?

## Limitations
- MO-MCTS hyperparameters (Progressive Widening thresholds, exploration constants) are not fully specified, affecting reproducibility
- SAT encoding details (variable bit-widths, cardinality constraint implementations) remain unspecified
- Approach assumes deterministic correctness measures and reliable PAC sampling, limiting applicability to noisy data
- Restricted action space to first non-terminal may bias search without quantified performance impact

## Confidence
- **High Confidence**: The two-phase hybrid framework architecture (MO-MCTS + SAT verification) is sound and well-defined. The local Pareto-optimality guarantee (Theorem 1) is mathematically rigorous.
- **Medium Confidence**: Scalability claims relative to Synplicate are well-supported by experiments on 20 benchmarks, though the specific conditions under which MO-MCTS outperforms purely symbolic methods require further investigation.
- **Low Confidence**: The paper provides limited analysis of hyperparameter sensitivity (particularly the MO-MCTS time split and slack parameter effects), making it difficult to predict performance across diverse domains.

## Next Checks
1. **Hyperparameter Sensitivity Analysis**: Systematically vary MO-MCTS exploration constants, Progressive Widening thresholds, and the TMO-MCTS/Toverall split across 3-4 diverse benchmarks to quantify performance stability.
2. **SAT Solver Dependency Evaluation**: Replace Kissat with alternative solvers (e.g., CaDiCaL, MapleCOMSPS) on benchmarks where verification fails to assess solver-specific performance bottlenecks.
3. **Anytime Guarantee Stress Test**: Implement early termination at random intervals (10%-90% of allocated time) across all 20 benchmarks to empirically validate the claimed anytime property and characterize solution quality degradation.