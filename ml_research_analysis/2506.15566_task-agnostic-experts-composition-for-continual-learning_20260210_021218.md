---
ver: rpa2
title: Task-Agnostic Experts Composition for Continual Learning
arxiv_id: '2506.15566'
source_url: https://arxiv.org/abs/2506.15566
tags:
- composition
- experts
- expert
- training
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work addresses the need for more efficient and sustainable\
  \ AI frameworks by leveraging compositionality in neural networks. The authors propose\
  \ an expert composition method where multiple small, pretrained ResNet-18 models\u2014\
  each specialized in recognizing a subset of object classes\u2014are combined in\
  \ a zero-shot manner to tackle compositional image classification tasks."
---

# Task-Agnostic Experts Composition for Continual Learning
## Quick Facts
- arXiv ID: 2506.15566
- Source URL: https://arxiv.org/abs/2506.15566
- Authors: Luigi Quarantiello; Andrea Cossu; Vincenzo Lomonaco
- Reference count: 15
- Key outcome: Expert composition achieves 58% accuracy on CGQA benchmark, nearly doubling ER baseline at 26%, without fine-tuning

## Executive Summary
This work introduces a novel approach to continual learning by leveraging compositionality in neural networks. Instead of training new models for each task, the method composes multiple small, pretrained ResNet-18 experts to handle compositional image classification tasks. The approach operates in a zero-shot manner, combining experts specialized in recognizing subsets of object classes to tackle new compositional tasks without additional training. When evaluated on the CGQA benchmark, this expert composition method demonstrates significantly higher accuracy than state-of-the-art continual learning baselines while requiring substantially fewer computational resources.

## Method Summary
The proposed method employs a task-agnostic expert composition framework where multiple small ResNet-18 models serve as specialized experts, each trained on a subset of object classes. For a new compositional task, the system identifies relevant experts based on class overlap and composes their outputs through weighted averaging, where weights are determined by class relevance scores. This zero-shot composition approach avoids the need for fine-tuning or additional training, instead reusing existing knowledge from pretrained experts. The method focuses on efficiency by leveraging pretrained models and reducing computational overhead compared to traditional continual learning approaches that require ongoing training.

## Key Results
- Expert composition achieves 58% accuracy on CGQA benchmark, nearly doubling ER baseline at 26%
- Method demonstrates significant efficiency gains by avoiding fine-tuning and reusing pretrained models
- Shows robustness to data distribution shifts while maintaining superior performance

## Why This Works (Mechanism)
The approach works by leveraging compositionality principles in neural networks, where complex tasks can be broken down into simpler subtasks that specialized experts can handle. By composing multiple small, pretrained experts rather than training a single large model, the system can efficiently reuse existing knowledge while maintaining flexibility to handle new compositional tasks. The weighted averaging mechanism ensures that more relevant experts contribute more heavily to the final prediction, allowing the system to adapt to task requirements without retraining.

## Foundational Learning
- **Continual Learning**: Learning from sequential tasks without forgetting previous knowledge - needed to handle streaming data scenarios; quick check: test on task sequences with varying difficulty
- **Compositionality in Neural Networks**: Building complex functions from simpler components - needed to decompose tasks into manageable expert subtasks; quick check: verify expert specialization effectiveness
- **Zero-Shot Learning**: Making predictions on unseen classes without training - needed to handle compositional tasks without additional training; quick check: test on completely novel compositions
- **Knowledge Reuse**: Leveraging pretrained models for new tasks - needed to improve efficiency and reduce computational costs; quick check: compare resource usage against training from scratch
- **Expert Systems**: Multiple specialized models working together - needed to distribute task complexity across multiple experts; quick check: evaluate performance with varying numbers of experts
- **Weighted Averaging**: Combining multiple model outputs based on relevance - needed to balance contributions from different experts; quick check: test sensitivity to weight calculation methods

## Architecture Onboarding
- **Component Map**: Input Images -> Expert Selection Module -> Multiple ResNet-18 Experts -> Weighted Averaging Module -> Final Prediction
- **Critical Path**: Image classification flows through expert identification, individual expert processing, and composition through weighted averaging
- **Design Tradeoffs**: Small experts vs. single large model (efficiency vs. potential coordination overhead); zero-shot composition vs. fine-tuning (speed vs. potential accuracy)
- **Failure Signatures**: Poor expert selection leading to irrelevant compositions; insufficient class overlap causing expert unavailability; weight calculation errors causing suboptimal expert combination
- **First Experiments**: 1) Test expert selection accuracy on varying class overlap scenarios; 2) Evaluate composition quality with different weight calculation methods; 3) Measure performance degradation with increasing task complexity

## Open Questions the Paper Calls Out
None identified in the provided materials.

## Limitations
- Lacks comprehensive ablation studies to isolate contributions of individual design choices
- Absence of experiments on diverse real-world datasets beyond the CGQA benchmark
- Efficiency claims based on training time without detailed energy consumption or memory usage metrics

## Confidence
- Claim that expert composition nearly doubles accuracy compared to ER: Medium
- Claim of superior efficiency without fine-tuning: Medium
- Claim of robustness to data distribution shifts: Low

## Next Checks
1. Conduct ablation studies to quantify the impact of individual components on performance
2. Test the method on diverse real-world datasets with varying complexity and class distributions
3. Perform long-term continual learning experiments to assess scalability and robustness over extended task sequences