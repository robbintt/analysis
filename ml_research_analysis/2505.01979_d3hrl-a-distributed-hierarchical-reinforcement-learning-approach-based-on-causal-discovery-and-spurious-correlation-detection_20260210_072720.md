---
ver: rpa2
title: 'D3HRL: A Distributed Hierarchical Reinforcement Learning Approach Based on
  Causal Discovery and Spurious Correlation Detection'
arxiv_id: '2505.01979'
source_url: https://arxiv.org/abs/2505.01979
tags:
- causal
- time
- learning
- d3hrl
- relationships
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: D3HRL addresses delayed effects and spurious correlations in long-horizon
  tasks through distributed causal discovery and conditional independence testing.
  The method models delayed effects as causal relationships across time spans, using
  parallel SCM training with reverse data collection to trace multiple causes of state
  changes.
---

# D3HRL: A Distributed Hierarchical Reinforcement Learning Approach Based on Causal Discovery and Spurious Correlation Detection

## Quick Facts
- arXiv ID: 2505.01979
- Source URL: https://arxiv.org/abs/2505.01979
- Reference count: 40
- D3HRL achieves lower structural Hamming distance (SHD) and higher average success ratio (ASR) than baselines in 2D-Minecraft and MiniGrid environments

## Executive Summary
D3HRL addresses delayed effects and spurious correlations in long-horizon tasks through distributed causal discovery and conditional independence testing. The method models delayed effects as causal relationships across time spans, using parallel SCM training with reverse data collection to trace multiple causes of state changes. Spurious correlations are detected by conditioning on parent nodes to block backdoor paths, ensuring only genuine causal relationships are learned. Experiments in 2D-Minecraft and MiniGrid show D3HRL accurately identifies variable-length state transitions and constructs causal chains, significantly improving learning efficiency compared to baselines like CDHRL, HAC, and Option-Critic.

## Method Summary
D3HRL employs a three-module iterative process to learn hierarchical policies from environments with delayed effects and spurious correlations. The first module uses distributed parallel SCM training across multiple time spans to discover causal relationships. The second module applies conditional independence testing via CMI estimation to filter out spurious correlations by conditioning on parent nodes. The third module constructs hierarchical policies aligned with discovered causal chains using sub-goal DQNs and Hindsight Experience Replay. The method operates on decomposed state spaces and requires prior knowledge of maximum delay bounds.

## Key Results
- D3HRL achieves lower structural Hamming distance (SHD) than baselines in 2D-Minecraft and MiniGrid environments
- The method demonstrates higher average success ratio (ASR) across all tested tasks and time spans
- Reverse data collection strategy converges faster than forward collection in causal probability learning
- D3HRL shows robust generalization across different time spans and resource levels

## Why This Works (Mechanism)

### Mechanism 1: Distributed Causal Discovery via Parallel SCM Training
D3HRL spawns parallel processes (rank₁ to rank_τmax), each training a separate Structural Causal Model (SCM) for a specific time span h. Process rank₃, for example, learns 3-step causal relationships Xⱼ^{t-3} → Xᵢᵗ. A reverse data collection strategy traces causes backward from observed state changes, collecting τmax + 1 steps of data when a state transition is detected at time t. If τmax is underestimated relative to true environmental delays, causes will be missed entirely.

### Mechanism 2: Spurious Correlation Detection via Conditional Independence Testing
D3HRL computes Conditional Mutual Information (CMI) for each candidate causal edge Xⱼ^{t-h} → Xᵢᵗ, conditioning on PA(Xᵢᵗ) \ {Xⱼ^{t-h}} ∪ PA(Xⱼ^{t-h}). If CMI < ε_cmi (empirically set to 0.05), the correlation is deemed spurious and rejected. True time spans are determined by selecting the shortest span among multiple valid candidates. If unobserved confounders exist, CMI tests may yield false positives or false negatives.

### Mechanism 3: Hierarchical Policy Construction from Causal Chains
For each confirmed causal relationship (e.g., stone → stonepickaxe), D3HRL creates a sub-goal DQN network with action space including the causes (g_stone, g_stick) and primitive actions. A top-level network orchestrates sub-goals. Hindsight Experience Replay (HER) is adapted for variable-length transitions, generating rewards based on goal achievement over h + 1 steps. If causal graphs are incorrect or incomplete, sub-goal networks will train on mis-specified objectives.

## Foundational Learning

- **Concept: Structural Causal Models (SCM)**
  - Why needed here: D3HRL represents each time-spanned causal relationship as an SCM with a causal graph (adjacency matrix) and generative functions predicting effects from causes.
  - Quick check question: Given variables X, Y, Z with edges X → Z and Y → Z, can you write the generating function form for Z?

- **Concept: Semi-Markov Decision Processes (SMDPs)**
  - Why needed here: Variable-length state transitions (delay effects) are modeled as SMDPs where actions span multiple time steps before state changes manifest.
  - Quick check question: How does an SMDP differ from a standard MDP in representing transition timing?

- **Concept: Conditional Independence Testing via CMI**
  - Why needed here: The core mechanism for distinguishing spurious correlations from genuine causation relies on computing I(X; Y | Z) and thresholding.
  - Quick check question: If I(X; Y | Z) = 0, what does this imply about the relationship between X and Y when conditioning on Z?

## Architecture Onboarding

- **Component map:** Distributed SCM trainers (rank 1...τmax) -> Reverse data collector -> Replay buffer -> CMI estimator networks -> Threshold comparator -> Sub-goal DQNs -> Top-level DQN

- **Critical path:**
  1. Environment interaction → Reverse data collection (collect 2τmax + 1 step segments)
  2. Distributed SCM training across τmax parallel processes
  3. CMI computation for candidate edges → Spurious correlation filtering
  4. True time span determination (shortest valid span)
  5. Sub-goal network creation and HER-based training
  6. Add mastered sub-goal to intervention list → Iterate

- **Design tradeoffs:**
  - Parallelization vs. memory: More processes (higher τmax) cover longer delays but increase memory/compute overhead
  - CMI threshold (ε_cmi): Lower values catch more spurious correlations but risk false negatives; paper uses 0.05 empirically
  - Causal probability threshold (σ(η) ≥ 0.8): Controls edge inclusion in causal graph; higher values are conservative

- **Failure signatures:**
  - SHD not decreasing across iterations → Causal discovery failing; check data diversity or τmax
  - Sub-goal networks not converging → Spurious edges may have passed CIT; lower ε_cmi
  - Causal graph shows implausible edges (e.g., future causing past) → DAG constraint violated; check List_do management
  - ASR plateaus early → Causal chain incomplete; verify all effects have corresponding sub-goals

- **First 3 experiments:**
  1. **Sanity check on τmax = 1 setting:** Run D3HRL on a single-step environment (e.g., standard MiniGrid without delay modifications). Confirm SHD ≈ 0 and ASR comparable to CDHRL baseline.
  2. **Reverse vs. forward data collection ablation:** On GetIron-R0 with τmax = 4, plot causal probability convergence curves for both strategies. Verify reverse strategy converges faster per Figure 4.
  3. **CMI threshold sensitivity analysis:** Vary ε_cmi ∈ {0.01, 0.05, 0.1} on Wood2Wet task. Plot SHD and ASR to confirm 0.05 is appropriate for your environment; adjust if spurious edges persist.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the D3HRL framework be effectively adapted to handle high-dimensional observation spaces, such as images, where state variables are not explicitly decoupled?
- Basis in paper: [explicit] The conclusion states, "Future work will extend D3HRL to handle diverse modalities, such as images."
- Why unresolved: The current methodology relies on a decomposed state space (Section 4) and SCM training on specific variables, which is difficult to apply directly to raw pixel data without explicit feature extraction or representation learning.
- Evidence would resolve it: Demonstrating successful causal chain construction and policy training in standard image-based RL benchmarks (e.g., Atari) without relying on handcrafted state features.

### Open Question 2
- Question: How can the distributed causal discovery mechanism be modified to accurately model tasks with stochastically distributed time spans rather than fixed or variable-length spans within a fixed window?
- Basis in paper: [explicit] The conclusion identifies a limitation: "D3HRL struggles with tasks that have randomly distributed time spans."
- Why unresolved: The current architecture uses parallel processes for specific time spans (τmax) and a deterministic time span matrix T, which may not capture the probabilistic nature of highly stochastic delays.
- Evidence would resolve it: An extension of the algorithm that maintains high Average Success Ratio (ASR) and low Structural Hamming Distance (SHD) in environments where action effects occur after a random, non-deterministic number of steps.

### Open Question 3
- Question: To what extent does violating the Causal Sufficiency Assumption degrade the performance of the conditional independence testing module?
- Basis in paper: [inferred] Section 4 explicitly lists the "Causal Sufficiency Assumption" (all relevant factors observed) as a prerequisite for the Causal Factored-SMDPs formulation.
- Why unresolved: The spurious correlation detection relies on conditioning on parent nodes to block backdoor paths; if relevant confounders are unobserved (latent), the Conditional Independence Testing (CIT) may incorrectly classify spurious correlations as causal.
- Evidence would resolve it: An analysis of D3HRL's SHD and success rate in modified environments where specific state variables are intentionally masked (latent) to create unobserved confounding.

## Limitations
- The method assumes causal sufficiency (all confounders observed), which may not hold in real-world applications
- Requires prior knowledge of maximum delay bounds (τmax), limiting applicability to environments with unknown delay characteristics
- Parallel SCM training approach lacks direct corpus validation and may be computationally expensive
- Struggles with tasks that have randomly distributed time spans rather than bounded delays

## Confidence
- **High Confidence**: The distributed SCM training mechanism for detecting variable-length delays - well-defined with clear pseudocode and experimental validation showing improved SHD
- **Medium Confidence**: The CMI-based spurious correlation detection - methodology is sound but relies on assumptions about observed confounders and threshold selection that may not generalize
- **Low Confidence**: The causal-to-hierarchical-policy mapping mechanism - while the concept is clear, the exact implementation details for integrating causal discoveries into sub-goal networks are underspecified

## Next Checks
1. Implement a controlled experiment varying τmax on environments with known delay bounds to verify distributed SCM training converges correctly across all time spans
2. Conduct an ablation study comparing forward vs. reverse data collection strategies on the Wood2Wet task to validate the claimed faster convergence of the reverse approach
3. Test CMI threshold sensitivity (ε_cmi ∈ {0.01, 0.05, 0.1}) on the Wood2Wet task to empirically determine optimal settings for spurious correlation detection