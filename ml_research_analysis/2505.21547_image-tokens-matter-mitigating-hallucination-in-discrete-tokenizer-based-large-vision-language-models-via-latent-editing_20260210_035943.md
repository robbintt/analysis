---
ver: rpa2
title: 'Image Tokens Matter: Mitigating Hallucination in Discrete Tokenizer-based
  Large Vision-Language Models via Latent Editing'
arxiv_id: '2505.21547'
source_url: https://arxiv.org/abs/2505.21547
tags:
- image
- tokens
- visual
- hallucination
- objects
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses hallucination in Large Vision-Language Models
  (LVLMs) that use discrete image tokenizers, identifying that visual priors from
  co-occurring image tokens induce such hallucinations. The authors propose a two-step
  approach: Context-Guided Clustering (CGC) uses a Graph Neural Network and contrastive
  learning to cluster image tokens based on their co-occurrence patterns in segmented
  images, capturing visual priors.'
---

# Image Tokens Matter: Mitigating Hallucination in Discrete Tokenizer-based Large Vision-Language Models via Latent Editing

## Quick Facts
- **arXiv ID:** 2505.21547
- **Source URL:** https://arxiv.org/abs/2505.21547
- **Reference count:** 40
- **Primary result:** CGC+VTD reduces hallucinations in discrete tokenizer-based LVLMs while maintaining general capabilities, outperforming baselines.

## Executive Summary
This paper addresses hallucination in Large Vision-Language Models (LVLMs) that use discrete image tokenizers by identifying that visual priors from co-occurring image tokens induce such hallucinations. The authors propose a two-step approach: Context-Guided Clustering (CGC) uses a Graph Neural Network and contrastive learning to cluster image tokens based on their co-occurrence patterns in segmented images, capturing visual priors. Visual Token Decontamination (VTD) then mitigates hallucinations by suppressing the influence of visually absent tokens from dominant clusters during autoregressive decoding. Experiments on three LVLMs (Chameleon-7B, Janus-Pro-7B, Emu3-13B) across three benchmarks (AMBER, Object HalBench, MME) show CGC+VTD reduces hallucinations while maintaining general capabilities, outperforming recent baselines and being computationally efficient.

## Method Summary
The method tackles hallucination in discrete tokenizer-based LVLMs by identifying and mitigating visual priors encoded in image token co-occurrence patterns. The Context-Guided Clustering (CGC) component builds a co-occurrence graph using spatial proximity (3×3 grid) and semantic coherence (same mask) criteria, then trains a 2-layer Graph Neural Network with contrastive loss to learn token embeddings that capture these priors. These embeddings are clustered via balanced K-means (K=10) to identify dominant clusters representing frequent visual patterns. The Visual Token Decontamination (VTD) component then suppresses absent tokens from these dominant clusters during inference by modifying intermediate transformer layer outputs. The approach is applied during autoregressive decoding, showing reduced hallucination rates while maintaining general capabilities across multiple LVLMs and benchmarks.

## Key Results
- CGC+VTD significantly reduces hallucination metrics (CHAIR↓, Hal↓) across all three LVLMs (Chameleon-7B, Janus-Pro-7B, Emu3-13B) on AMBER, Object HalBench, and MME benchmarks.
- The method maintains or improves coverage scores (Cover↑) and general capability metrics (MME) while reducing hallucinations.
- Outperforms recent baselines including InstructBLIP, BLIP-2, and GLIGEN across all evaluation metrics.
- Achieves computational efficiency with only ~10% decoding overhead compared to baseline models.

## Why This Works (Mechanism)
The paper identifies that discrete image tokenizers in LVLMs encode visual priors through co-occurrence patterns, where certain tokens frequently appear together regardless of whether they represent actually present visual elements. These priors induce hallucinations during generation because the model learns to associate certain token combinations with semantic concepts, even when the corresponding visual elements are absent. CGC captures these co-occurrence patterns by constructing a graph where nodes are image tokens and edges represent spatial or semantic relationships, then clustering tokens that frequently co-occur. VTD mitigates hallucinations by suppressing the influence of tokens that are absent from the input image but belong to dominant clusters, effectively removing the prior-induced bias during generation.

## Foundational Learning

**Graph Neural Networks (GNNs)** - Why needed: GNNs are used to learn token embeddings that capture co-occurrence patterns from the constructed graph. Quick check: Verify GNN implementation matches 2-layer architecture with 2048 batch size and InfoNCE loss.

**Contrastive Learning** - Why needed: The InfoNCE loss in CGC training forces the model to distinguish between tokens that co-occur frequently versus those that don't, learning meaningful representations. Quick check: Confirm positive pairs are sampled based on edge weights and negative pairs are from different tokens.

**Autoregressive Decoding** - Why needed: VTD operates during the autoregressive generation process, modifying intermediate layer outputs before final predictions. Quick check: Verify layer indexing and that VTD is applied at the correct decoding step.

**Balanced K-means Clustering** - Why needed: Ensures clusters have roughly equal sizes, preventing dominant clusters from overwhelming the learning process. Quick check: Verify cluster sizes are approximately equal (within 10-15% variation).

## Architecture Onboarding

**Component Map:** COCO Images → Discrete Tokenizer → Co-occurrence Graph → GNN Training → Token Embeddings → Balanced K-means → CGC Clusters → LVLM Input → VTD Editing → Output Generation

**Critical Path:** Tokenization → CGC (Graph Construction + GNN Training + Clustering) → VTD (Dominant Cluster Identification + Absent Token Suppression) → Inference Generation

**Design Tradeoffs:** The method trades a small amount of coverage (some true objects may be suppressed) for significant hallucination reduction. Spatial proximity (3×3 grid) vs semantic (same mask) edges balances local context with object-level coherence.

**Failure Signatures:** 
- If VTD layer is too early (< layer 15) or too late (> layer 28), performance degrades monotonically.
- Naive K-means (Cluster-Base) shows no improvement, confirming CGC's graph construction is essential.
- Excessive γ (> 1.0) typically causes coverage drop as too many tokens are suppressed.

**First Experiments:**
1. Build co-occurrence graph with spatial (3×3) and semantic (same mask) criteria, retain top 10% edges, verify graph density.
2. Train GNN with InfoNCE + positive pair similarity loss, run balanced K-means, compare HitRate@K vs naive K-means (expect 5-10% gap).
3. Apply VTD during inference with different γ values (0.2-1.0), sweep editing layers (15-28), verify CHAIR improves monotonically.

## Open Questions the Paper Calls Out

**Open Question 1:** How can the trade-off between reducing object hallucinations and maintaining comprehensive visual coverage be mitigated? The authors note that VTD causes a slight drop in coverage scores, suggesting that suppressing absent tokens may inadvertently suppress tokens necessary for describing less dominant but present visual elements. Evidence that would resolve this: A modified VTD algorithm or dynamic γ that yields Pareto improvements on both Cover and CHAIR metrics simultaneously on AMBER.

**Open Question 2:** Can the visual prior modeling approach be effectively adapted for LVLMs that rely on continuous visual features rather than discrete tokenizers? The method is specifically designed for discrete tokenizers and not directly applicable to continuous-encoder models like LLaVA. Evidence that would resolve this: Successful adaptation of co-occurrence logic (e.g., clustering continuous embeddings) applied to LLaVA demonstrating significant hallucination reduction.

**Open Question 3:** To what extent does the dataset used for constructing the co-occurrence graph bias the hallucination mitigation capabilities? The graph is built exclusively using COCO 2017 Panoptic, potentially encoding dataset-specific priors that may not generalize. Evidence that would resolve this: Cross-domain evaluation where the graph is built using a different source dataset (e.g., Conceptual Captions) and tested on out-of-distribution benchmarks.

## Limitations

- **Implementation Details:** Balanced K-means algorithm is referenced but not fully specified, creating barriers to faithful reproduction.
- **Evaluation Scope:** Method validated only on object hallucination tasks and COCO-based benchmarks, limiting generalizability claims.
- **Hyperparameter Sensitivity:** Model-specific tuning (γ values, editing layers) may not transfer well to other LVLMs without extensive re-tuning.

## Confidence

- **High:** Claims about CGC+VTD reducing object hallucination on tested LVLMs across AMBER, Object HalBench, and MME benchmarks.
- **Medium:** Claims about computational efficiency (10% decoding overhead) and preservation of general capabilities.
- **Medium:** Claims about the theoretical mechanism (visual priors causing hallucinations) are well-supported but could benefit from additional ablation studies.

## Next Checks

1. Implement and verify the balanced K-means clustering step using the provided code repository or by replicating the algorithm from cited references.
2. Test VTD performance across a sweep of editing layers (15-28) to confirm the monotonic improvement pattern and identify optimal layer selection.
3. Apply CGC+VTD to a fourth LVLM not in the original evaluation (e.g., LLaVA-7B) to assess generalizability beyond the three tested models.