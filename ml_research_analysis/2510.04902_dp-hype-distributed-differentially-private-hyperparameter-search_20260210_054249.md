---
ver: rpa2
title: 'DP-HYPE: Distributed Differentially Private Hyperparameter Search'
arxiv_id: '2510.04902'
source_url: https://arxiv.org/abs/2510.04902
tags:
- privacy
- data
- clients
- hyperparameter
- hyperparameters
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents DP-HYPE, a scalable and privacy-preserving
  algorithm for distributed hyperparameter search in federated learning. The core
  challenge addressed is finding a shared hyperparameter configuration that achieves
  good performance across all clients without revealing sensitive data or relying
  on a trusted third party.
---

# DP-HYPE: Distributed Differentially Private Hyperparameter Search

## Quick Facts
- arXiv ID: 2510.04902
- Source URL: https://arxiv.org/abs/2510.04902
- Authors: Johannes Liebenow; Thorsten Peinemann; Esfandiar Mohammadi
- Reference count: 40
- Primary result: DP-HYPE achieves near-optimal accuracy in federated learning hyperparameter search with strong differential privacy guarantees

## Executive Summary
This paper introduces DP-HYPE, a distributed algorithm for finding shared hyperparameters in federated learning while preserving differential privacy. The key innovation is that privacy guarantees remain constant regardless of the number of hyperparameters being evaluated, making it practical for large search spaces. The algorithm works by having each client locally evaluate all candidate hyperparameters, then aggregate votes through secure summation with Gaussian noise. The approach is implemented as a Flower submodule and validated on standard datasets including MNIST, CIFAR-10, and Adult, showing strong performance even under tight privacy budgets.

## Method Summary
DP-HYPE operates through a two-phase process where each client first evaluates all candidate hyperparameters locally, then votes for their top-k performers. These votes are aggregated using secure summation protocols, with Gaussian noise added to ensure differential privacy. The critical insight is that the privacy budget remains independent of the number of hyperparameters, achieved through careful analysis of the voting mechanism. The algorithm satisfies client-level differential privacy guarantees without requiring a trusted third party, making it suitable for practical federated learning deployments.

## Key Results
- DP-HYPE achieves near-optimal accuracy even under strict privacy budgets (ε < 1) across multiple datasets
- The approach performs well in highly non-IID scenarios while maintaining strong privacy guarantees
- In IID settings, DP-HYPE matches the performance of the best possible hyperparameter configuration with 250 clients at ε = 1
- Privacy budget independence from hyperparameter count enables practical use with large search spaces

## Why This Works (Mechanism)
DP-HYPE's effectiveness stems from its voting-based aggregation mechanism combined with Gaussian noise addition. Each client independently evaluates all hyperparameters locally, eliminating the need for data sharing. The top-k voting ensures that only high-performing configurations receive votes, while secure summation with calibrated noise provides differential privacy. The independence of the privacy budget from the number of hyperparameters is achieved through careful mathematical analysis of the voting distribution and noise addition process, making the approach scalable to large hyperparameter spaces.

## Foundational Learning
- Differential Privacy: Mathematical framework for quantifying information leakage; needed to ensure individual client data remains private during aggregation; quick check: verify ε and δ values are within acceptable privacy bounds
- Secure Summation: Cryptographic techniques for aggregating values without revealing individual contributions; needed to enable privacy-preserving vote aggregation; quick check: confirm secure summation protocol is correctly implemented
- Client-level Privacy: Privacy guarantees at the level of individual participants rather than individual data points; needed for federated learning scenarios where clients may contain multiple data points; quick check: verify that privacy analysis properly accounts for multi-point clients

## Architecture Onboarding

Component Map: Clients -> Local Evaluation -> Voting -> Secure Summation -> Noise Addition -> Hyperparameter Selection

Critical Path: Each client evaluates all hyperparameters → votes for top-k → secure aggregation with noise → final hyperparameter selection

Design Tradeoffs:
- Privacy vs Accuracy: Tighter privacy budgets (lower ε) provide stronger guarantees but may reduce accuracy
- Number of Votes (k): Higher k increases exploration but may dilute signal from truly optimal hyperparameters
- Noise Scale: Must be calibrated to achieve desired privacy while maintaining utility

Failure Signatures:
- Accuracy degradation when privacy budget is too tight
- Suboptimal hyperparameter selection when k is too small relative to search space
- System failure if secure summation protocol is compromised

First 3 Experiments:
1. Validate privacy guarantees by measuring actual information leakage under various privacy budgets
2. Test scalability by evaluating performance with increasing numbers of hyperparameters (10 → 100 → 1000)
3. Measure performance degradation as data becomes increasingly non-IID across clients

## Open Questions the Paper Calls Out
None

## Limitations
- The algorithm assumes all clients can evaluate all candidate hyperparameters locally, which may not hold in resource-constrained environments
- Performance degradation thresholds under extreme non-IID conditions are not quantified
- No explicit analysis of potential adversarial scenarios beyond standard differential privacy guarantees

## Confidence
- Differential privacy guarantees: High
- Empirical performance claims: Medium
- Scalability claims: Medium

## Next Checks
1. Test DP-HYPE with varying degrees of non-IID data skew to establish performance bounds and identify failure thresholds
2. Evaluate the algorithm's performance when clients have heterogeneous computational capabilities and varying evaluation budgets
3. Implement DP-HYPE with a significantly larger hyperparameter search space (e.g., 1000+ configurations) to validate practical scalability claims