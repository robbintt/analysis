---
ver: rpa2
title: 'Language Bias in Information Retrieval: The Nature of the Beast and Mitigation
  Methods'
arxiv_id: '2509.06195'
source_url: https://arxiv.org/abs/2509.06195
tags:
- language
- fairness
- languages
- queries
- retrieval
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies language fairness in multilingual information
  retrieval (MLIR), motivated by the observation that semantically equivalent queries
  in different languages often yield inconsistent ranking outputs. The authors propose
  a mean rank correlation (MRC) metric to measure fairness, based on the consistency
  of rankings for parallel queries.
---

# Language Bias in Information Retrieval: The Nature of the Beast and Mitigation Methods

## Quick Facts
- arXiv ID: 2509.06195
- Source URL: https://arxiv.org/abs/2509.06195
- Reference count: 18
- Primary result: LaKDA improves fairness by 35.9% with XLM-R while maintaining or improving retrieval performance

## Executive Summary
This paper addresses language bias in multilingual information retrieval (MLIR), where semantically equivalent queries in different languages yield inconsistent rankings. The authors propose a mean rank correlation (MRC) metric to measure fairness by quantifying the consistency of rankings for parallel queries. They introduce MultiEuP-v2, a dataset of semantically parallel queries and documents across 24 European languages, enabling robust fairness evaluation. Experimental results show that DPR-based neural retrievers (mBERT, XLM-R) exhibit significantly less language bias than BM25, with XLM-R performing best. To mitigate bias, the authors propose LaKDA, a language-aware KL-divergence alignment loss that substantially improves fairness (MRC@5) without sacrificing retrieval performance (MRR@100). The study demonstrates that fairness can be improved in MLIR systems through model architecture and targeted loss functions.

## Method Summary
The authors develop a DPR-based neural retriever trained with a joint loss combining standard DPR contrastive loss and a novel Language KL-Divergence Alignment (LaKDA) loss. LaKDA minimizes the KL divergence between document score distributions for parallel queries in different languages, encouraging consistent rankings. The model is trained on MultiEuP-v2, a dataset of parallel queries and documents across 24 European languages. MRC@k is introduced as a fairness metric, measuring Spearman rank correlation between parallel query rankings. Experiments compare BM25, vanilla DPR, and DPR+LaKDA across performance (MRR@100) and fairness (MRC@5) metrics.

## Key Results
- DPR with XLM-R outperforms BM25 and mBERT, showing significantly less language bias
- LaKDA improves MRC@5 by 35.9% with XLM-R while maintaining or improving MRR@100
- MRC@5 reaches 15.9 for LaKDA+XLM-R versus 11.7 for baseline
- LaKDA outperforms a naive MSE baseline and enhances parallel query similarity
- Low-resource languages (MT, GA) show larger performance gaps but still benefit from LaKDA

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Mean Rank Correlation (MRC) quantifies cross-linguistic ranking consistency as a proxy for language fairness.
- Mechanism: For each semantically parallel query pair in languages a and b, compute Spearman's rank correlation between their top-k document rankings. Average over all language pairs and queries to produce MRC@k, where values near 100 indicate high fairness (consistent rankings) and values near -100 indicate systematic inversion.
- Core assumption: Equivalence of semantic intent across languages should yield equivalent relevance rankings when the document pool is fixed and multilingual.
- Evidence anchors:
  - [abstract]: "We evaluate the degree of fairness using both traditional retrieval methods, and a DPR neural ranker based on mBERT and XLM-R."
  - [section 2.1]: Full MRC formula derivation with Spearman correlation and averaging over L languages and N queries.
  - [corpus]: Neighbor papers show emerging interest in multilingual fairness evaluation (e.g., TREC NeuCLIR), but no direct prior use of MRC for query-level fairness.
- Break condition: If parallel queries are not semantically equivalent (e.g., translation drift, cultural localization), MRC will conflate translation quality with system fairness.

### Mechanism 2
- Claim: Neural dense retrieval with multilingual encoders reduces language bias compared to lexical matching.
- Mechanism: DPR encodes queries and documents into a shared dense space via mBERT or XLM-R. Relevance is computed via dot product similarity, enabling cross-lingual semantic matching rather than lexical overlap. This allows a query in language a to retrieve relevant documents in language b.
- Core assumption: Multilingual pretrained models provide semantically aligned representations across languages sufficient for retrieval.
- Evidence anchors:
  - [abstract]: "DPR with XLM-R performs best, while BM25 exhibits significant language bias."
  - [section 3.1.3, Figure 6]: BM25 shows strong diagonal correlation (query language → document language); DPR shows off-diagonal retrieval reflecting corpus distribution, not query language.
  - [corpus]: Related work on neural cross-lingual IR (NeuCLIR) supports cross-lingual effectiveness but does not isolate query-level fairness.
- Break condition: If the multilingual encoder has poor cross-lingual alignment for specific language pairs (e.g., low-resource languages), dense retrieval may still exhibit bias.

### Mechanism 3
- Claim: Language KL-Divergence Alignment (LaKDA) improves fairness by enforcing similar score distributions over documents for parallel queries.
- Mechanism: For each training query q(i, ℓa) and a randomly sampled parallel query q(i, ℓb), compute softmax distributions p(i, ℓa) and p(i, ℓb) over document similarity scores. Minimize DKL(p(i, ℓb) || p(i, ℓa)) so that parallel queries assign similar probability mass to the same documents. Joint loss: L = (1−α)L_DPR + αL_LaKDA.
- Core assumption: Aligning output distributions over documents for parallel queries will yield more consistent rankings without degrading relevance.
- Evidence anchors:
  - [abstract]: "LaKDA improves fairness by 35.9% with XLM-R while maintaining or improving retrieval performance."
  - [section 2.2.2, Eq. 1]: Full KL divergence formulation and joint loss combination.
  - [section 3.2.3, Table 3]: LaKDA + XLM-R achieves MRC@5 = 15.9 vs. 11.7 baseline (+35.9%); MRR@100 = 61.0 vs. 46.5 (+31.2%).
  - [corpus]: KL-based alignment for fairness appears in related bias mitigation work but not specifically for query-level IR fairness.
- Break condition: If the document pool has extreme language imbalance or relevance is language-specific, enforcing distribution alignment may hurt retrieval quality.

## Foundational Learning

- **Concept**: Dense Passage Retrieval (DPR)
  - Why needed here: Core architecture for neural IR; uses bi-encoders to embed queries and documents separately, enabling efficient similarity search.
  - Quick check question: Can you explain why DPR uses dot product similarity and how in-batch negatives are formed?

- **Concept**: Multilingual Encoders (mBERT, XLM-R)
  - Why needed here: Provide cross-lingual representations; XLM-R is shown to be more robust for MLIR due to larger multilingual pretraining.
  - Quick check question: What is the difference between mBERT and XLM-R in terms of training data and architecture?

- **Concept**: KL Divergence
  - Why needed here: Mathematical foundation of LaKDA; measures how one probability distribution diverges from a second, expected distribution.
  - Quick check question: Why is KL divergence asymmetric, and how does this affect the choice of p || q vs. q || p?

## Architecture Onboarding

- **Component map**: Encoder backbone (mBERT/XLM-R) -> DPR module (contrastive loss with in-batch negatives) -> LaKDA module (KL divergence over parallel query distributions) -> Joint optimizer (weighted combination of losses)

- **Critical path**:
  1. Load multilingual encoder (XLM-R recommended)
  2. Prepare parallel query dataset with language IDs
  3. For each batch: encode queries and documents, compute DPR loss, sample parallel queries, compute LaKDA loss, backpropagate joint loss
  4. Evaluate with MRR@100 (performance) and MRC@k (fairness) on parallel test queries

- **Design tradeoffs**:
  - α = 0.5 used in experiments; higher α prioritizes fairness but may reduce MRR if alignment conflicts with relevance
  - MSE baseline aligns query embeddings directly but ignores document context; LaKDA is more robust because it aligns score distributions
  - Parallel query availability: original > machine-translated > zero-shot (Tables 4, 5)

- **Failure signatures**:
  - MRC near 0 or negative: parallel query distributions are misaligned; check encoder cross-lingual quality or data noise
  - MRR drops significantly when α increases: LaKDA is overpowering relevance signal; reduce α
  - Low-resource languages (MT, GA) have much lower MRR/MRC: encoder has poor representation; consider language-specific fine-tuning or data augmentation

- **First 3 experiments**:
  1. Baseline: Train DPR with XLM-R on MultiEuP-v2; evaluate MRR@100 and MRC@5 across all 24 languages
  2. Ablation: Add LaKDA with α = 0.5; compare MRR and MRC to baseline; plot α sensitivity (Figure 4)
  3. Diagnostics: For low-resource languages (MT, GA), run zero-shot vs. translated vs. original parallel query conditions; analyze MRR/MRC gaps (Tables 4, 5)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the application of LaKDA for language fairness positively or negatively impact fairness across other protected demographic attributes?
- Basis in paper: [explicit] The authors explicitly state in the Limitations section that they "focused exclusively on language fairness, leaving other dimensions of fairness in MLIR, such as demographic fairness, unexplored," despite the dataset containing such metadata.
- Why unresolved: It is unclear if optimizing for cross-lingual consistency inadvertently introduces or amplifies biases related to the speaker's gender, age, or political affiliation within the retrieved documents.
- What evidence would resolve it: An evaluation of the trained models on the demographic attributes provided in the MultiEuP-v2 dataset (e.g., gender, political group) using standard group fairness metrics.

### Open Question 2
- Question: Is LaKDA effective for languages with non-Latin scripts or typologies vastly different from the European languages studied?
- Basis in paper: [explicit] The paper notes the investigation is "limited to European languages" and encourages the community to adapt the approach to other languages.
- Why unresolved: The current study covers 24 languages, but many are Indo-European. It remains untested whether the method generalizes to languages with different morphological complexities or writing systems where multilingual embeddings (mBERT/XLM-R) are known to be weaker.
- What evidence would resolve it: Replicating the experiments on a dataset containing non-European languages (e.g., from the Afro-Asiatic or Sino-Tibetan families) and analyzing the MRC scores.

### Open Question 3
- Question: How sensitive is LaKDA to the quality of parallel queries when original human translations are unavailable?
- Basis in paper: [inferred] In Section 4.2, the authors show that "Original" queries yield significantly better MRC scores (6.7) compared to "Translated" queries (1.2) for low-resource languages, suggesting the method's effectiveness may drop if high-quality parallel data is missing.
- Why unresolved: While the paper demonstrates that translated data acts as a "silver standard," it does not quantify the threshold of translation quality required for LaKDA to provide a net benefit over the vanilla model.
- What evidence would resolve it: A controlled experiment varying the quality (BLEU score) of the parallel query pairs used in training to identify the performance degradation curve.

## Limitations
- Focus on European languages limits generalization to non-Latin scripts and typologically diverse languages
- Assumes parallel queries are semantically equivalent, but translation quality and cultural localization effects are not quantified
- Does not evaluate impact on other fairness dimensions (e.g., demographic attributes) despite available metadata

## Confidence
- **High Confidence**: DPR architecture effectiveness, XLM-R superiority over mBERT, basic MRC calculation methodology
- **Medium Confidence**: LaKDA's relative effectiveness versus MSE baseline, the joint loss formulation's stability across α values
- **Low Confidence**: Generalization of MRC to non-parallel or zero-shot multilingual queries, impact of document corpus size imbalance on LaKDA performance

## Next Checks
1. **Zero-shot evaluation**: Test LaKDA on truly unseen languages without parallel query pairs to assess generalization beyond the 24 European languages
2. **Corpus imbalance stress test**: Systematically vary document language distributions (e.g., 90-10 vs 50-50 splits) to measure LaKDA's robustness to real-world corpus imbalances
3. **Translation drift analysis**: Measure MRC degradation when parallel queries contain controlled semantic drift or cultural localization variations to establish the metric's sensitivity to translation quality