---
ver: rpa2
title: Training thermodynamic computers by gradient descent
arxiv_id: '2509.15324'
source_url: https://arxiv.org/abs/2509.15324
tags:
- computer
- thermodynamic
- neural
- network
- trained
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper demonstrates how to train a thermodynamic computer using
  gradient descent to perform computations at specified observation times, enabling
  it to mimic the behavior of a trained neural network. The method involves adjusting
  the parameters of a thermodynamic computer to maximize the probability of generating
  idealized dynamical trajectories that reproduce the activations of a reference neural
  network.
---

# Training thermodynamic computers by gradient descent

## Quick Facts
- arXiv ID: 2509.15324
- Source URL: https://arxiv.org/abs/2509.15324
- Reference count: 0
- This paper demonstrates how to train a thermodynamic computer using gradient descent to perform computations at specified observation times, enabling it to mimic the behavior of a trained neural network.

## Executive Summary
This paper introduces a method for training thermodynamic computers using gradient descent on the Onsager-Machlup functional to perform computations at finite observation times. The approach uses a teacher-student framework where a neural network serves as a reference model, and the thermodynamic computer learns to reproduce its behavior through parameter optimization. The authors apply this method to an MNIST image classification task, training a thermodynamic computer with 64 hidden nodes and 10 output nodes to achieve 92.0% test-set accuracy. The study estimates a thermodynamic advantage of over 10^7 compared to digital implementations, based on energy cost comparisons.

## Method Summary
The method trains a thermodynamic computer using gradient descent on the Onsager-Machlup functional to maximize the probability of generating idealized dynamical trajectories that reproduce neural network activations. A teacher neural network is first trained on MNIST (784-32-32-10 architecture, tanh activation, 97.3% accuracy). For each training sample, an idealized trajectory is constructed by running a non-interacting thermodynamic computer at zero temperature with biases proportional to the neural network's hidden and output activations. The student thermodynamic computer (64 hidden + 10 output nodes, all-to-all connectivity) is then trained using gradient descent on these trajectories, with updates computed via equations 6-10. Training proceeds for approximately 10^6 trajectories with observation time t_f = 1/5 μ^(-1).

## Key Results
- Trained thermodynamic computer achieves 92.0% test accuracy on MNIST
- Estimated thermodynamic advantage of over 10^7 compared to digital implementations
- Demonstrates practical gradient descent training method for thermodynamic computing
- Shows out-of-equilibrium computation is viable with finite observation times

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Gradient descent on the Onsager-Machlup functional can train thermodynamic computers to reproduce target trajectories.
- Mechanism: The Onsager-Machlup action quantifies the log-probability that a Langevin system generates a specific trajectory. By computing gradients of this action with respect to couplings J_ij and biases b_i (equations 8-10), parameters are updated to maximize trajectory likelihood. This creates a differentiable training signal analogous to backpropagation.
- Core assumption: The discrete approximation of the continuous Onsager-Machlup functional (equation 5) preserves sufficient gradient information for optimization.
- Evidence anchors:
  - [abstract] "training proceeds by maximizing the probability with which the computer would generate an idealized dynamical trajectory"
  - [Section II.A, equations 5-10] Derivation of gradient updates from the Onsager-Machlup functional
  - [corpus] Limited direct corpus support; related work "Scalable Thermodynamic Second-order Optimization" addresses thermodynamic hardware for training but not the Onsager-Machlup approach specifically
- Break condition: If integration timestep Δt is too large relative to system dynamics, gradient estimates become unreliable and training diverges.

### Mechanism 2
- Claim: A teacher-student framework enables thermodynamic computers to acquire computational capacities similar to neural networks.
- Mechanism: A trained neural network provides reference activations A_i for each input. These are encoded as biases in a non-interacting "idealized trajectory" at zero temperature. The thermodynamic computer learns to reproduce both hidden and output activations, transferring the neural network's learned representations.
- Core assumption: Reproducing hidden-unit activations (not just outputs) transfers sufficient computational structure to the thermodynamic computer.
- Evidence anchors:
  - [abstract] "This teacher-student scheme results in a thermodynamic computer whose finite-time dynamics enacts a computation analogous to that of the neural network"
  - [Section II] "we reason that reproducing its hidden-unit behavior will allow the thermodynamic computer to acquire a computational capacity similar to that of the neural network"
  - [corpus] No direct corpus precedent for this specific teacher-student formulation
- Break condition: If the thermodynamic computer's connectivity is too restricted relative to the neural network, it cannot reproduce the required hidden representations.

### Mechanism 3
- Claim: Finite-time observation enables out-of-equilibrium computation without waiting for thermal equilibration.
- Mechanism: The system evolves under Langevin dynamics (equation 1) for a fixed time t_f = 1/5 μ^(-1), then outputs are read. This is shorter than typical equilibration times but long enough for nonlinear activations to develop expressiveness.
- Core assumption: The observation time t_f is sufficient for units to compute nonlinear functions of inputs but short enough that equilibrium has not been reached.
- Evidence anchors:
  - [Section III] "This time is short enough that the trained computer is out of equilibrium when observed, but long enough for unit activations x_i(t_f) to become nonlinear functions of their inputs"
  - [Fig. 2d,e] Shows activations still evolving at observation time, confirming out-of-equilibrium operation
  - [corpus] Not directly addressed in corpus
- Break condition: If observation time is too short, activations remain linear in inputs; if too long, equilibration erases computational structure.

## Foundational Learning

- Concept: **Langevin dynamics**
  - Why needed here: The thermodynamic computer's state evolution is governed by overdamped Langevin equations with thermal noise. Understanding the balance of deterministic forces and stochastic fluctuations is essential.
  - Quick check question: Can you explain why the noise term scales as √(2μkT) and what happens if temperature goes to zero?

- Concept: **Path probability and action functionals**
  - Why needed here: Training requires computing the probability that the system generates a specific trajectory, which involves summing over all timesteps. The negative log-probability becomes the loss function.
  - Quick check question: Why is the Onsager-Machlup action additive over trajectory steps, and what does minimizing it accomplish?

- Concept: **Boltzmann vs. Langelein computing modes**
  - Why needed here: Previous thermodynamic computers operated at equilibrium (Boltzmann), requiring potentially slow equilibration. This paper uses finite-time dynamics (Langevin), trading equilibrium guarantees for clocked operation.
  - Quick check question: What computational guarantees does equilibrium operation provide that finite-time operation sacrifices?

## Architecture Onboarding

- Component map:
  - 784 input pixels (frozen during forward pass)
  - N = 64 hidden nodes + 10 output nodes with continuous activations x_i
  - Potential energy V_θ(x) with quartic self-terms (J_2 x^2 + J_4 x^4) and bilinear couplings J_ij x_i x_j
  - 63,143 trainable parameters: input-to-hidden, input-to-output, hidden-to-output, and hidden-hidden couplings
  - All-to-all connectivity with symmetric couplings J_ij = J_ji

- Critical path:
  1. Train reference neural network on target task (97.3% MNIST accuracy)
  2. For each training sample, construct idealized trajectory from neural network activations
  3. Update thermodynamic computer parameters via equations 6-7
  4. Repeat for ~10^6 trajectories across multiple epochs
  5. Extract final parameters for hardware implementation

- Design tradeoffs:
  - Observation time t_f: shorter times enable faster computation but reduce expressiveness
  - Coupling symmetry: bidirectional couplings J_ij = J_ji constrain architecture compared to feedforward networks
  - Performance gap: 92.0% vs 97.3% accuracy traded for estimated 10^7× energy advantage
  - Assumption: Gap may narrow with architectural tweaks and enhanced training techniques

- Failure signatures:
  - Loss plateaus without convergence: learning rate too high or observation time mismatch
  - Output activations fail to separate classes: hidden representations insufficient; increase connectivity
  - High variance between trajectories: temperature too high relative to coupling strengths

- First 3 experiments:
  1. **Minimal reproduction**: Implement a 2-class classifier (e.g., digits 0 vs 1) with 8 hidden nodes to validate gradient computations and trajectory matching before scaling.
  2. **Observation time sweep**: Fix all parameters, vary t_f from 0.05μ^(-1) to 1.0μ^(-1) to characterize the accuracy-speed frontier and confirm out-of-equilibrium operation matters.
  3. **Connectivity ablation**: Remove hidden-hidden connections and measure accuracy drop to quantify whether recurrent dynamics contribute meaningfully or merely add optimization difficulty.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can standard deep learning enhancements close the performance gap between the thermodynamic computer and the reference neural network?
- Basis in paper: [explicit] The authors note that while the neural network achieves 97.3% accuracy and the thermodynamic computer 92.0%, this gap "can almost certainly be narrowed by... adopting or adapting the enhancements to gradient descent used in deep learning."
- Why unresolved: The current implementation uses a basic gradient descent approach without common optimizations.
- What evidence would resolve it: Retraining the thermodynamic computer using techniques such as momentum, adaptive learning rates, or weight decay to verify if the accuracy matches the teacher network.

### Open Question 2
- Question: Does the construction of the idealized teacher trajectory significantly impact the efficiency or accuracy of the student thermodynamic computer?
- Basis in paper: [explicit] The paper states, "It may be possible to construct teacher trajectories that are easier for a student computer to mimic," though the current study uses a noninteracting, zero-temperature trajectory.
- Why unresolved: The paper tests only one method of generating the target trajectory; the sensitivity of the student model to the specific dynamics of the teacher trajectory remains unexplored.
- What evidence would resolve it: Comparing training convergence speeds and final accuracies using alternative teacher trajectories (e.g., finite temperature or interacting dynamics).

### Open Question 3
- Question: Is a hybrid training approach necessary to bridge the "sim-to-real" gap caused by hardware device noise?
- Basis in paper: [explicit] The authors suggest combining methods: "training a digital model... using gradient descent, and, if necessary, retraining its hardware realization using a [genetic algorithm]" to handle stochastic component variations (device noise).
- Why unresolved: This is a proposed strategy to mitigate manufacturing inconsistencies, but it has not been implemented or validated in physical hardware yet.
- What evidence would resolve it: Fabricating a physical thermodynamic computer and measuring whether the digitally trained parameters function correctly or require in-hardware genetic retraining.

## Limitations
- The estimated thermodynamic advantage of 10^7× lacks explicit validation against specific digital architectures and implementation details.
- The all-to-all connectivity assumption (63,143 parameters) may not be practical for physical implementations.
- The bidirectional coupling constraint (J_ij = J_ji) limits architectural flexibility compared to standard neural networks.

## Confidence
- High confidence: The gradient descent training method using Onsager-Machlup functionals is mathematically sound and experimentally validated for the MNIST task
- Medium confidence: The teacher-student framework successfully transfers computational capabilities from neural networks to thermodynamic computers
- Medium confidence: The out-of-equilibrium observation mechanism enables practical clocked operation, though the optimal observation time requires empirical tuning

## Next Checks
1. **Energy validation**: Implement the trained thermodynamic computer parameters on actual thermodynamic hardware (e.g., analog CMOS or optical systems) and measure real energy consumption per classification to verify the 10^7× efficiency claim against digital baselines.

2. **Architecture constraint test**: Train the same teacher neural network but constrain it to have symmetric weight matrices (J_ij = J_ji) and compare accuracy loss. This validates whether the thermodynamic computer's coupling symmetry is a fundamental limitation or merely a training artifact.

3. **Time-efficiency tradeoff**: Systematically vary observation time t_f and measure both accuracy and effective computational throughput (samples/second). This will determine whether the claimed efficiency advantage comes from reduced energy per sample or increased processing speed, or both.