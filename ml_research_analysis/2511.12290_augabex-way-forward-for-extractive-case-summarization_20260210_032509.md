---
ver: rpa2
title: 'AugAbEx : Way Forward for Extractive Case Summarization'
arxiv_id: '2511.12290'
source_url: https://arxiv.org/abs/2511.12290
tags:
- summaries
- legal
- case
- extractive
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of creating extractive gold
  standard summaries for legal case summarization by transforming existing abstractive
  gold standard summaries. The authors propose a transparent, cost-effective pipeline
  that leverages ROUGE-based candidate sentence selection and Maximal Marginal Relevance
  (MMR) to generate extractive summaries while preserving expert opinions.
---

# AugAbEx : Way Forward for Extractive Case Summarization

## Quick Facts
- arXiv ID: 2511.12290
- Source URL: https://arxiv.org/abs/2511.12290
- Authors: Purnima Bindal; Vikas Kumar; Sagar Rathore; Vasudha Bhatnagar
- Reference count: 7
- Primary result: Proposed transformation pipeline generates extractive gold standard summaries from abstractive summaries that are structurally and semantically comparable to original abstractive summaries

## Executive Summary
This study addresses the challenge of creating extractive gold standard summaries for legal case summarization by transforming existing abstractive gold standard summaries. The authors propose a transparent, cost-effective pipeline that leverages ROUGE-based candidate sentence selection and Maximal Marginal Relevance (MMR) to generate extractive summaries while preserving expert opinions. The transformed extractive gold (TEG) summaries are evaluated across structural, lexical, semantic, and domain-specific dimensions, and compared with both the original abstractive summaries and unsupervised LSA summaries. Results show that TEG summaries are structurally and semantically comparable to original abstractive summaries, with higher legal entity counts and better alignment with case documents in most datasets. The findings support the use of TEG summaries as reliable gold standards for training and evaluating extractive legal summarizers.

## Method Summary
The proposed method transforms abstractive gold standard summaries into extractive gold standards through a two-stage pipeline. First, candidate sentences are selected from case documents using ROUGE-based matching with abstractive summaries, identifying sentences with the highest F1 overlap. Second, Maximal Marginal Relevance (MMR) is applied to select diverse and representative sentences, balancing relevance and redundancy. The pipeline operates with a fixed λ=0.6 parameter for MMR and processes legal documents to generate TEG summaries that preserve the core content of original abstractive summaries while maintaining extractive format. The approach is evaluated against original abstractive summaries and LSA-generated summaries across multiple legal datasets.

## Key Results
- TEG summaries show structural and semantic equivalence to original abstractive summaries across ROUGE, BERTScore, and MoverScore metrics
- TEG summaries contain higher counts of legal entities compared to abstractive summaries, better reflecting case document content
- TEG summaries demonstrate superior alignment with case documents compared to LSA summaries in most datasets
- The transformation pipeline successfully preserves expert opinions while creating extractive gold standards

## Why This Works (Mechanism)
The method works by leveraging existing high-quality abstractive summaries to guide extractive summary generation. ROUGE-based candidate selection identifies sentences most relevant to the abstractive summary content, while MMR ensures diversity and prevents redundancy. This approach benefits from the semantic richness of abstractive summaries while producing extractive outputs that are more easily used for training extractive summarizers. The transformation preserves the semantic intent of expert-generated summaries while adapting them to extractive format requirements.

## Foundational Learning

**ROUGE Metrics**: Precision, recall, and F1 scores measuring n-gram overlap between summaries and reference texts. Needed to identify candidate sentences that align with abstractive summaries. Quick check: Verify F1 scores between candidate sentences and abstractive summaries exceed threshold.

**Maximal Marginal Relevance (MMR)**: Algorithm balancing relevance and diversity in summary selection using λ parameter. Needed to prevent redundancy while maintaining coverage. Quick check: Confirm λ=0.6 provides optimal trade-off through preliminary analysis.

**BERTScore**: Semantic similarity metric using pre-trained BERT embeddings to compute precision, recall, and F1 between text pairs. Needed to evaluate semantic preservation beyond surface-level overlap. Quick check: Validate BERTScore correlations exceed 0.8 for semantic equivalence.

**MoverScore**: Text similarity metric combining contextualized embeddings with Earth Mover's Distance. Needed to assess overall semantic alignment between summaries. Quick check: Confirm MoverScore values indicate strong semantic correspondence.

## Architecture Onboarding

**Component Map**: Abstractive Summary -> ROUGE-based Candidate Selection -> MMR-based Diversity Filtering -> Transformed Extractive Gold (TEG) Summary

**Critical Path**: The ROUGE-based candidate sentence selection followed by MMR filtering forms the core pipeline. Candidate selection must complete before MMR can operate, making this sequential dependency critical for pipeline success.

**Design Tradeoffs**: The fixed λ=0.6 MMR parameter simplifies implementation but may not optimize for all legal document types. ROUGE-based selection prioritizes n-gram overlap which may miss semantically equivalent but lexically different sentences.

**Failure Signatures**: Low ROUGE F1 scores in candidate selection indicate poor alignment with abstractive summaries. High redundancy despite MMR filtering suggests λ parameter needs adjustment. Poor BERTScore/MoverScore correlations indicate semantic information loss during transformation.

**3 First Experiments**:
1. Test ROUGE-based candidate selection with varying F1 thresholds to optimize coverage vs precision
2. Evaluate MMR performance across different λ values (0.4, 0.6, 0.8) on diverse legal document types
3. Compare TEG summaries against human-annotated extractive summaries on subset of cases

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- ROUGE-based candidate selection may miss semantically important sentences with low n-gram overlap
- Fixed MMR parameter (λ=0.6) lacks optimization across different legal domains and document lengths
- Validation relies on metric correlations rather than direct human evaluation of summary quality
- No empirical validation through training extractive summarizers using TEG gold standards

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Structural comparability between TEG and abstractive summaries | High |
| Semantic preservation in TEG summaries | Medium |
| TEG summaries as reliable gold standards for training | Medium |
| Higher legal entity counts in TEG vs abstractive summaries | High |

## Next Checks

1. Conduct blind human evaluations comparing TEG summaries with original abstractive summaries across multiple legal domains to validate semantic preservation claims

2. Train extractive summarizers using TEG gold standards and evaluate their performance on unseen legal cases, comparing results with models trained on traditional extractive gold standards

3. Perform ablation studies varying the MMR parameter λ across a wider range to determine optimal values for different legal document types and lengths