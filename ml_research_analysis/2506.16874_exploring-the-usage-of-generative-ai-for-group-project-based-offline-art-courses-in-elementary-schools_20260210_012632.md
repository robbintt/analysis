---
ver: rpa2
title: Exploring the Usage of Generative AI for Group Project-Based Offline Art Courses
  in Elementary Schools
arxiv_id: '2506.16874'
source_url: https://arxiv.org/abs/2506.16874
tags:
- students
- genais
- group
- dall-e
- askart
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explored how Generative AI can support elementary students
  in group project-based art courses. A four-phase field study was conducted with
  132 students and two teachers, introducing DALL-E and GPT via an interface called
  AskArt.
---

# Exploring the Usage of Generative AI for Group Project-Based Offline Art Courses in Elementary Schools

## Quick Facts
- arXiv ID: 2506.16874
- Source URL: https://arxiv.org/abs/2506.16874
- Authors: Zhiqing Wang; Haoxiang Fan; Shiwei Wu; Qiaoyi Chen; Yongqi Liang; Zhenhui Peng
- Reference count: 40
- Students using AskArt reported significantly higher satisfaction (M=6.64) compared to those without (M=5.46, p=0.0005)

## Executive Summary
This study explored how Generative AI can support elementary students in group project-based art courses. A four-phase field study was conducted with 132 students and two teachers, introducing DALL-E and GPT via an interface called AskArt. Students benefited from AI-generated background information, inspiration, and guidance, but faced challenges in query formulation. AskArt's features, such as project-related introductions and suggested follow-ups, improved student interaction with AI.

## Method Summary
The research employed a four-phase field study design in an elementary school art classroom setting. The study involved 132 students organized into 41 groups, with two teachers participating. Students were divided into control and experimental groups, with the experimental group using the AskArt interface while the control group used standard GenAI tools. Data collection included interaction logs, questionnaires, interviews, and observations across four phases: baseline evaluation, system design, deployment preparation, and final deployment with data collection.

## Key Results
- Students naturally adopted sequential workflow—using GPT for information gathering, then DALL-E for visual ideation—without explicit instruction
- Suggested follow-up prompts transformed single-turn queries into multi-turn dialogues, deepening engagement
- "Select and Generate" feature reduced query formulation friction by enabling direct content transfer from GPT responses to DALL-E prompts
- Students using AskArt reported significantly higher satisfaction (M=6.64) compared to those without (M=5.46, p=0.0005)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Students naturally adopt a sequential workflow—GPT for information gathering, then DALL-E for visual ideation—without explicit instruction.
- Mechanism: When presented with distinct GenAI tools, elementary students intuitively map each tool's affordances to specific project stages. GPT addresses knowledge gaps (background, implementation guidance), while DALL-E translates textual concepts into visual references. This sequential pattern reduces cognitive load by separating information-seeking from visualization tasks.
- Core assumption: Students can distinguish tool capabilities when interfaces clearly label them (e.g., "Think Tank" vs. "Little Painter").
- Evidence anchors:
  - [abstract]: "challenges in query formulation for generating expected content were also observed"
  - [section 4.2.2 Finding 2]: "out of the total 28 queries to GPT and DALL-E, 13 queries were posed in a two-step process... students queried GPT for information seeking... then queried DALL-E for visual inspiration"
  - [corpus]: Limited direct corpus evidence for K-6 art-specific sequential tool use; neighbor papers focus on higher education (e.g., arXiv:2505.00100 on undergraduate CS courses).
- Break condition: Students with no prior GenAI exposure may conflate tool capabilities (e.g., asking GPT for images) without scaffolding.

### Mechanism 2
- Claim: Suggested follow-up prompts transform single-turn queries into multi-turn dialogues, deepening engagement.
- Mechanism: Elementary students default to search-engine mental models (one query, one answer). "Suggested Follow-Ups" feature explicitly demonstrates conversational iteration, guiding students to refine requests, request alternatives, or explore tangential ideas. This scaffolds metacognitive awareness of GenAI's iterative capabilities.
- Core assumption: Dynamic suggestion generation aligns with conversation context and project themes.
- Evidence anchors:
  - [section 5.1]: "Suggested Follow-Ups... generated based on the current conversation and update dynamically... aims to make students aware that they can provide feedback or refine their requests"
  - [section 6.2.3 Finding 7]: "respondents... rated this panel highly helpful (M=6.06, SD=1.51)... students began independently providing feedback"
  - [corpus]: No direct corpus evidence on follow-up prompting in K-6; arXiv:2506.15525 discusses participatory GenAI design with high schoolers but not this specific mechanism.
- Break condition: Generic or irrelevant suggestions reduce trust and adoption.

### Mechanism 3
- Claim: "Select and Generate" feature reduces query formulation friction by enabling direct content transfer from GPT responses to DALL-E prompts.
- Mechanism: Students struggle to articulate complete DALL-E prompts from scratch. By allowing selection of relevant GPT-generated text (with auto-generated draft prompts), the interface demonstrates effective prompt construction patterns while reducing typing burden. This creates a learn-by-example loop.
- Core assumption: GPT responses contain extractable, DALL-E-relevant content (descriptions, adjectives, style terms).
- Evidence anchors:
  - [section 5.1]: "each GPT response ends with an automatically generated draft prompt for DALL-E... allowing students to directly use it"
  - [section 6.2.3 Finding 8]: "students iteratively adjusted the main prompts and Context Word to DALL-E based on the images generated in the last turn"
  - [corpus]: No corpus neighbor directly validates this cross-model transfer mechanism.
- Break condition: GPT responses lack visual-relevant content; students select irrelevant text.

## Foundational Learning

- Concept: **Multi-turn conversational interaction**
  - Why needed here: Students must understand GenAI supports iterative refinement, not just single queries.
  - Quick check question: Can you explain how asking follow-up questions improves AI responses?

- Concept: **Prompt decomposition (subject + context)**
  - Why needed here: Effective DALL-E prompts separate main subject from stylistic/contextual modifiers.
  - Quick check question: Given "a dragon in clouds," how would you add style context?

- Concept: **Tool capability boundaries**
  - Why needed here: Students conflate GPT (text) and DALL-E (images) without explicit differentiation.
  - Quick check question: Which tool would you use to get implementation steps vs. visual references?

## Architecture Onboarding

- Component map:
  - Frontend (Vue.js): Dual-panel interface ("Think Tank" for GPT-4o, "Little Painter" for DALL-E 3)
  - Backend (Flask/Python): Request routing, conversation state management
  - APIs: OpenAI GPT-4o and DALL-E 3 endpoints
  - Storage: Local storage for interaction logs
  - Features: Audio-to-text (Web Speech API), Suggested Follow-Ups generator, Select-and-Generate bridge

- Critical path:
  1. Cold-start initialization → project-specific intro messages injected
  2. Student query (text or voice) → GPT response + auto-generated DALL-E prompt draft
  3. Selection → prompt transfer to DALL-E input (as main subject or context word)
  4. DALL-E generation → visual output → iteration loop

- Design tradeoffs:
  - Voice input reduces typing friction but produces disorganized queries (Finding 6)
  - Fixed intro messages ensure relevance but require manual configuration per project
  - Single-device-per-group limits individual exploration but maintains feasibility in resource-constrained classrooms

- Failure signatures:
  - High "perceived as incorrect" query rate → indicates capability confusion; strengthen intros
  - Voice transcripts with missing context → add auto-completion or clarification prompts
  - Low follow-up usage → review suggestion relevance algorithm

- First 3 experiments:
  1. A/B test: Static vs. dynamic follow-up suggestions—measure multi-turn conversation rates
  2. Add query clarification module when voice input is ambiguous—measure response satisfaction
  3. Teacher-customizable intro templates—measure setup time vs. student query relevance scores

## Open Questions the Paper Calls Out
None

## Limitations
- The study's findings are based on a single deployment in two classrooms with specific project constraints, limiting generalizability
- Teacher reliance on static introductory messages may not scale to diverse or rapidly changing project topics
- Voice input, while innovative, produced disorganized queries, suggesting a need for better speech-to-text integration

## Confidence
- **High Confidence:** The sequential tool usage pattern (GPT for information, DALL-E for visualization) is well-supported by interaction logs and student feedback
- **Medium Confidence:** The effectiveness of the "Select and Generate" feature is inferred from student behavior but lacks direct usability testing
- **Low Confidence:** Claims about long-term creativity enhancement or scalability to larger classrooms are speculative, as the study only covers a single project cycle

## Next Checks
1. Conduct A/B testing of static vs. dynamically generated introductory messages across multiple project types to assess setup efficiency and query relevance
2. Implement a speech-to-text clarification module and measure its impact on query quality and student satisfaction compared to text-only input
3. Scale the study to five or more classrooms with varying student-device ratios to evaluate the interface's effectiveness in diverse classroom environments