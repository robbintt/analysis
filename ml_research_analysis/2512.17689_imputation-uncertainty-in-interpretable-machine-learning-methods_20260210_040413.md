---
ver: rpa2
title: Imputation Uncertainty in Interpretable Machine Learning Methods
arxiv_id: '2512.17689'
source_url: https://arxiv.org/abs/2512.17689
tags:
- imputation
- linear
- mice
- data
- learner
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how different missing data imputation strategies
  affect the reliability of interpretable machine learning (IML) methods, specifically
  focusing on variance estimation and confidence interval coverage. While prior work
  addressed bias in IML under missing data, it overlooked imputation uncertainty's
  impact on variance.
---

# Imputation Uncertainty in Interpretable Machine Learning Methods

## Quick Facts
- arXiv ID: 2512.17689
- Source URL: https://arxiv.org/abs/2512.17689
- Reference count: 40
- Single imputation methods (especially mean) severely underestimate variance and lead to poor confidence interval coverage in IML methods when data contain missing values.

## Executive Summary
This paper investigates how different missing data imputation strategies affect the reliability of interpretable machine learning (IML) methods, specifically focusing on variance estimation and confidence interval coverage. While prior work addressed bias in IML under missing data, it overlooked imputation uncertainty's impact on variance. The authors extend Molnar et al.'s "learner uncertainty" framework to incorporate imputation uncertainty, then evaluate permutation feature importance, partial dependence plots, and Shapley values under various missing data patterns and imputation methods. Across linear and non-linear data-generating processes, single imputation—especially mean imputation—consistently underestimated variance and led to poor confidence interval coverage, particularly for Shapley values and permutation importance. Multiple imputation (MICE) provided much better coverage, with MICE PMM performing best for linear models and MICE RF for non-linear ones.

## Method Summary
The authors extended the learner uncertainty framework to incorporate imputation uncertainty by combining multiple imputation with bootstrap resampling (MI-Boot approach). They evaluated three IML methods—permutation feature importance, partial dependence plots, and Shapley values—under four imputation strategies (mean, MissForest, MICE PMM, MICE RF) across three missingness patterns (MCAR, MAR, MNAR) at three missingness rates (10%, 20%, 40%). The evaluation used two data-generating processes (linear and non-linear with interactions) with n=1000 samples and Toeplitz covariance structure. They computed 95% confidence interval coverage and average width across 1000 simulation replications, using Rubin's rules to pool results from multiple imputed datasets. A variance correction factor (c = n_test/n_train) was applied to account for the difference between training and test sample sizes.

## Key Results
- Single imputation methods, particularly mean imputation, consistently underestimated variance and produced poor confidence interval coverage (often below 0.8) across all IML methods
- Multiple imputation with MICE achieved near-nominal 0.95 coverage for most IML methods, with MICE PMM performing best for linear models and MICE RF for non-linear models
- MissForest tended to overestimate feature importance due to overfitting when including the target variable in imputation, though this was partially offset by bootstrap variance underestimation

## Why This Works (Mechanism)
The MI-Boot approach captures both imputation uncertainty (through multiple imputations) and sampling uncertainty (through bootstrapping), which are critical sources of variability when interpreting IML methods on incomplete data. By properly pooling these sources using Rubin's rules and applying the variance correction factor, the method provides valid confidence intervals that reflect the true uncertainty in the presence of missing data.

## Foundational Learning
**Multiple Imputation (MI)**: Creates multiple versions of the dataset with plausible values for missing data to reflect imputation uncertainty. Why needed: Single imputation ignores this uncertainty, leading to overly confident inferences. Quick check: Verify B > 0 in Rubin's rules (between-imputation variance).

**Rubin's Rules**: Formula for combining parameter estimates across multiple imputed datasets: θ̄ = (1/m)∑θᵢ and V_total = V_within + (1+1/m)V_between. Why needed: Provides valid variance estimates that incorporate imputation uncertainty. Quick check: Total variance > within-imputation variance.

**Bootstrap Resampling**: Sampling with replacement to estimate sampling variability. Why needed: Captures model instability and data sampling uncertainty in IML estimates. Quick check: Bootstrap distribution is approximately normal for stable estimates.

**Variance Correction Factor**: Adjustment c = n_test/n_train to account for different sample sizes in training vs. test sets. Why needed: Prevents underestimation of variance when applying IML methods to test data. Quick check: Coverage improves when correction is applied.

## Architecture Onboarding
**Component Map**: DGP → Missingness → Imputation → Bootstrap → Model Fitting → IML Computation → Pooling (Rubin's) → Variance Adjustment → Coverage Analysis

**Critical Path**: The MI-Boot approach (multiple imputation + bootstrap) is essential; skipping either component leads to invalid uncertainty quantification. MICE PMM/RF with 10-40 imputations depending on missingness rate is the recommended path.

**Design Tradeoffs**: Including target variable in imputation improves validity but may cause overfitting (MissForest). Single imputation is computationally cheaper but provides invalid uncertainty estimates. Higher imputation counts improve coverage but increase computation.

**Failure Signatures**: Coverage < 0.9 indicates inadequate uncertainty quantification; particularly low coverage (<0.7) suggests single imputation methods. Systematic overestimation of importance suggests overfitting in imputation.

**First Experiments**: 1) Verify Rubin's rules implementation by comparing pooled variance to within-imputation variance. 2) Test variance correction by comparing coverage with and without c = n_test/n_train. 3) Compare MICE PMM vs. MICE RF coverage on linear DGP to confirm PMM superiority.

## Open Questions the Paper Calls Out
**Open Question 1**: To what extent does the observed compensation between MICE variance overestimation and bootstrap variance underestimation hold across diverse real-world datasets and model classes? The simulation study demonstrates this cancellation in a controlled setting, but the robustness of this balance in uncontrolled, complex real-world data scenarios remains unknown.

**Open Question 2**: How can the overestimation of feature importance by MissForest be mitigated while maintaining the requirement of including the target variable for valid inference? The paper identifies the trade-off where including the target causes MissForest to overfit important features, but does not propose a method to resolve this specific bias.

**Open Question 3**: Do the findings regarding imputation uncertainty and coverage generalize to deep neural networks or other high-capacity learners? The simulation study is restricted to linear model and XGBoost with shallow trees, leaving the behavior of high-capacity models unexplored.

## Limitations
- Results are based on synthetic data with controlled missingness patterns, limiting generalizability to complex real-world datasets
- Only shallow XGBoost models (depth 2) were tested, leaving uncertainty about high-capacity learner behavior
- Small bootstrap sample size (20 resamples) may be insufficient for stable variance estimates, particularly for computationally intensive methods like Shapley values

## Confidence
- Multiple imputation improves coverage: High
- MICE PMM/RF ranking: Medium
- MissForest overestimation claim: Medium

## Next Checks
1. Validate findings on real-world datasets with known ground truth relationships, such as UCI machine learning repository datasets with artificially introduced missingness
2. Test larger bootstrap sample sizes (n=100-200) to assess stability of variance estimates and CI coverage across all IML methods
3. Compare against alternative multiple imputation approaches like joint modeling (jomo) or fully conditional specification with different predictor matrices to establish robustness of MICE PMM/RF findings