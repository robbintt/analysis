---
ver: rpa2
title: Enhanced Urdu Intent Detection with Large Language Models and Prototype-Informed
  Predictive Pipelines
arxiv_id: '2505.07857'
source_url: https://arxiv.org/abs/2505.07857
tags:
- intent
- language
- detection
- urdu
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a few-shot learning framework for Urdu intent
  detection that combines contrastive learning with a prototype-informed attention
  mechanism. By re-training multilingual and Urdu-specific language models using unlabeled
  Urdu data, the approach generates domain-aware sentence representations that improve
  downstream intent detection.
---

# Enhanced Urdu Intent Detection with Large Language Models and Prototype-Informed Predictive Pipelines

## Quick Facts
- arXiv ID: 2505.07857
- Source URL: https://arxiv.org/abs/2505.07857
- Reference count: 40
- Introduces LLMPIA framework achieving F1-scores of 83.28% (ATIS 4-way 1-shot) and 98.25% (ATIS 4-way 5-shot)

## Executive Summary
This paper presents LLMPIA, a few-shot learning framework for Urdu intent detection that combines contrastive learning with prototype-informed attention mechanisms. The approach re-trains multilingual and Urdu-specific language models using unlabeled Urdu data to generate domain-aware sentence representations, then applies a prototype-informed attention model to classify intents with minimal labeled examples. Evaluated on ATIS and Web Queries datasets, LLMPIA demonstrates state-of-the-art performance, particularly excelling in few-shot scenarios with F1-scores reaching 98.25% on ATIS in 4-way 5-shot settings.

## Method Summary
The LLMPIA framework operates in two stages: first, LLMRCL re-trains pre-trained language models using Masked Language Modeling and Self-Supervised Contrastive Learning on unlabeled Urdu data; second, a Prototype-Informed Attention (PIA) model processes the resulting embeddings through Feature Interaction Attention layers, prototype refinement, and adaptive mapping to produce intent predictions. The framework supports multiple PLMs including MuRIL and RoBERTa-Urdu, and employs cosine similarity with temperature scaling for final classification.

## Key Results
- Achieves F1-scores of 83.28% (ATIS 4-way 1-shot) and 98.25% (ATIS 4-way 5-shot)
- Outperforms state-of-the-art by 53.55% F1-score on Web Queries under standard train/test splits
- MuRIL-base-17-languages performs best in few-shot settings, while RoBERTa-small-Urdu excels in same-class settings
- Cosine similarity consistently outperforms 12 other metrics across all configurations

## Why This Works (Mechanism)

### Mechanism 1: Contrastive Learning for Semantic Representation
Re-training PLMs using contrastive learning on unlabeled Urdu data improves semantic nuance capture. The LLMRCL approach combines MLM for word associations with contrastive learning to distinguish semantic relations between text pairs. Positive/negative example pairs are created through preprocessing (stop-word removal, word shuffling). Core assumption: unlabeled Urdu text contains sufficient semantic signal for intent-relevant representations. Break condition: if representations become overly generic or lack diversity in intent-expressing patterns.

### Mechanism 2: Prototype-Informed Attention for Few-Shot Learning
The PI mechanism enables few-shot learning through feature interaction learning. FIAT captures inner-sentence and inner-class feature interactions. The PI Layer refines prototypes by weighting sentences based on relevance. Adaptive Layer maps prototypes and queries to common space using shared Siamese parameters. Unsupervised Contrastive Regularization prevents overfitting. Core assumption: intent classes can be represented by prototypes from 1-5 examples. Break condition: high intra-class variability or low inter-class separation.

### Mechanism 3: Cosine Similarity for Robust Classification
Cosine similarity between query embeddings and class prototypes provides the most reliable metric. After generating prototype representations (proto) and query representations (XQp), cosine similarity with temperature scaling computes alignment scores. Query is assigned to class with highest similarity. Core assumption: intent classes are directionally separable in embedding space. Break condition: embedding space doesn't preserve intent-relevant distinctions or temperature scaling is improperly tuned.

## Foundational Learning

- **Few-Shot Learning (N-way K-shot)**: Understanding episode-based training with limited examples per class is essential for grasping how LLMPIA handles unseen classes. Quick check: Given 4 intent classes with 1 example each, how would you form and use a prototype for classification?

- **Siamese Networks with Parameter Sharing**: The PIA mechanism uses Siamese architecture to ensure meaningful similarity comparisons. Quick check: Why would using different weights for processing support set prototypes vs. query samples break the similarity computation?

- **Contrastive Learning Objectives**: LLMRCL uses contrastive loss to learn representations by pulling similar text pairs closer and pushing dissimilar pairs apart. Quick check: If you have an anchor text "book a flight to Lahore," what would constitute a positive vs. negative pair in contrastive learning?

## Architecture Onboarding

- **Component map**: Raw Urdu text → Re-trained PLM embeddings → FIAT attention computation → Prototype refinement → Adaptive mapping → Cosine similarity scoring → Intent prediction

- **Critical path**: Raw Urdu text → LLMRCL re-training → Embedding layer (PLM) → FIAT layer → PI Layer → Adaptive Layer → Contrastive Regularization → Metric Learning (cosine similarity) → Intent prediction

- **Design tradeoffs**: MuRIL vs. RoBERTa-Urdu (few-shot generalization vs. same-class accuracy), 1-shot vs. 5-shot (data efficiency vs. performance), Data split sensitivity (25% seen classes struggle significantly)

- **Failure signatures**: High precision/low recall imbalance indicates overly conservative model, near-random performance on 1-shot with 25% split indicates insufficient examples, Hamming/KL-divergence giving near-zero scores indicates inappropriate metrics for dense embeddings

- **First 3 experiments**: 1) Baseline comparison: pre-trained vs. re-trained MuRIL on ATIS 4-way 5-shot with 50% seen classes using cosine similarity; 2) Similarity metric ablation: compare cosine, Euclidean, and dot product on Web Queries with RoBERTa-Urdu; 3) Shot sensitivity test: MuRIL on 4-way 1-shot vs. 5-shot at 75% seen classes to quantify data-efficiency tradeoff

## Open Questions the Paper Calls Out

- **Question 1**: How do advanced generative LLMs like DeepSeek, Gemini, and GPT compare to LLMPIA in performance and efficiency for Urdu intent detection? Basis: Authors identify lack of exploration of these models as a gap. Evidence needed: Comparative analysis benchmarking LLMPIA against few-shot prompts to generative models on same datasets.

- **Question 2**: To what extent does training diverse language models specifically on large-scale Urdu corpora from scratch improve performance compared to re-training existing multilingual models? Basis: Authors list this as a primary future direction. Evidence needed: Experiment training new Urdu-specific LLM on massive corpus and evaluating within LLMPIA pipeline.

- **Question 3**: Can the prototype-informed attention mechanism be adapted to handle queries containing multiple simultaneous intents? Basis: Framework implies single-label classification, while multi-intent detection is identified as necessary capability. Evidence needed: Modifying loss function or prediction layer to allow multi-label classification and evaluating on multi-intent annotated dataset.

## Limitations
- Contrastive learning implementation details remain underspecified, particularly positive/negative pair generation strategy
- FIAT layer implementation lacks specification of attention heads and dimension transformations
- Prototype formation may struggle with high intra-class variability, though not empirically validated
- Temperature scaling parameters for contrastive regularization and metric learning are not disclosed

## Confidence
- **High Confidence**: Overall framework design and superiority of cosine similarity (robust empirical evidence from Tables 7-8)
- **Medium Confidence**: Contrastive learning re-training mechanism and its contribution to performance gains (implementation details vague)
- **Low Confidence**: Generalization of few-shot learning results (prototype formation lacks validation for high semantic diversity cases)

## Next Checks
1. **Implementation Fidelity Test**: Reproduce 4-way 5-shot ATIS experiment with MuRIL using cosine similarity on 75% seen classes. Compare baseline (pre-trained MuRIL) vs. re-trained MuRIL to verify claimed ~15% F1 improvement.

2. **Corpus Robustness Analysis**: Systematically vary size and domain of unlabeled Urdu corpus used for LLMRCL re-training (10%, 50%, 100%). Measure sensitivity of downstream intent detection performance to corpus quantity and diversity.

3. **Prototype Quality Validation**: For best-performing 4-way 5-shot configuration, visualize prototype embeddings using t-SNE or UMAP to assess intra-class cohesion and inter-class separation. Compute prototype-to-prototype distances and prototype-to-query distributions.