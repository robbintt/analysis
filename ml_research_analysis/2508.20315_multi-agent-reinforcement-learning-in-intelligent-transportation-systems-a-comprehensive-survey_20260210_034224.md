---
ver: rpa2
title: 'Multi-Agent Reinforcement Learning in Intelligent Transportation Systems:
  A Comprehensive Survey'
arxiv_id: '2508.20315'
source_url: https://arxiv.org/abs/2508.20315
tags:
- learning
- reinforcement
- multi-agent
- marl
- policy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides a comprehensive survey of Multi-Agent Reinforcement
  Learning (MARL) applications in Intelligent Transportation Systems (ITS). It addresses
  the challenge of autonomous decision-making in dynamic, large-scale transportation
  environments by introducing a structured taxonomy categorizing MARL approaches based
  on coordination models and learning algorithms.
---

# Multi-Agent Reinforcement Learning in Intelligent Transportation Systems: A Comprehensive Survey

## Quick Facts
- arXiv ID: 2508.20315
- Source URL: https://arxiv.org/abs/2508.20315
- Reference count: 40
- This survey comprehensively categorizes MARL approaches for ITS, addressing challenges like scalability, non-stationarity, and sim-to-real transfer gaps.

## Executive Summary
This paper presents a structured survey of Multi-Agent Reinforcement Learning (MARL) applications in Intelligent Transportation Systems (ITS), addressing the complexities of autonomous decision-making in dynamic, large-scale transportation environments. It introduces a taxonomy categorizing MARL approaches based on coordination models and learning algorithms, covering applications such as traffic signal control, connected and autonomous vehicle coordination, logistics optimization, and mobility-on-demand systems. The survey reviews widely used simulation platforms like SUMO, CARLA, and CityFlow for MARL experimentation and identifies core challenges including scalability, non-stationarity, credit assignment, communication constraints, and sim-to-real transfer gaps. Future research opportunities are outlined, emphasizing federated learning, safety-aware policy design, robust communication protocols, and integration with edge computing.

## Method Summary
The survey systematically categorizes MARL applications in ITS through a taxonomy based on coordination models and learning algorithms. It reviews applications across traffic signal control, CAV coordination, logistics, and mobility-on-demand, supported by analysis of simulation platforms such as SUMO, CARLA, and CityFlow. Core challenges like scalability, non-stationarity, and sim-to-real transfer gaps are identified, alongside proposed future directions including federated learning, safety-aware policies, and edge computing integration.

## Key Results
- MARL approaches are categorized into taxonomy based on coordination models and learning algorithms for ITS applications.
- Applications span traffic signal control, CAV coordination, logistics optimization, and mobility-on-demand systems.
- Core challenges include scalability, non-stationarity, credit assignment, communication constraints, and sim-to-real transfer gaps.
- Future directions emphasize federated learning, safety-aware policy design, robust communication, and edge computing integration.

## Why This Works (Mechanism)
MARL enables autonomous decision-making in dynamic, large-scale transportation environments by leveraging distributed agents that learn coordinated policies through interaction. The taxonomy provides a structured framework for understanding how different coordination models and learning algorithms address specific ITS challenges. Simulation platforms like SUMO, CARLA, and CityFlow offer controlled environments for testing and validating MARL approaches before real-world deployment. Addressing challenges such as scalability, non-stationarity, and communication constraints ensures robust performance in complex traffic scenarios.

## Foundational Learning

### Reinforcement Learning Basics
- **Why needed**: Forms the foundation for understanding how agents learn optimal policies through reward signals in dynamic environments.
- **Quick check**: Can the agent learn a simple task (e.g., balancing a pole) in a simulated environment?

### Multi-Agent Systems
- **Why needed**: Essential for modeling interactions between multiple autonomous agents in shared environments like traffic networks.
- **Quick check**: Can multiple agents coordinate to achieve a common goal without centralized control?

### Traffic Simulation Platforms
- **Why needed**: Provides realistic, scalable environments for testing MARL algorithms before real-world deployment.
- **Quick check**: Can the simulator reproduce known traffic patterns and agent behaviors accurately?

### Federated Learning
- **Why needed**: Enables distributed training of MARL models across multiple agents without sharing raw data, preserving privacy.
- **Quick check**: Can federated learning improve model performance while maintaining data privacy in a multi-agent setting?

## Architecture Onboarding

### Component Map
Simulation Environment -> MARL Agents -> Coordination Protocol -> Learning Algorithm -> Policy Output -> Traffic Control Actions

### Critical Path
The critical path involves agents interacting with the simulation environment, executing coordination protocols, updating policies via the learning algorithm, and applying control actions to influence traffic flow.

### Design Tradeoffs
- **Scalability vs. Communication Overhead**: Larger agent populations improve coverage but increase communication complexity.
- **Centralized vs. Decentralized Control**: Centralized approaches offer better coordination but suffer from scalability issues; decentralized methods are more scalable but may lack global optimality.
- **Sim-to-Real Gap**: High-fidelity simulations improve transferability but increase computational cost.

### Failure Signatures
- **Non-stationarity**: Agents' policies changing unpredictably due to others' learning, leading to unstable convergence.
- **Credit Assignment**: Difficulty in attributing rewards to individual agents' actions in cooperative settings.
- **Communication Constraints**: Limited bandwidth or latency causing delayed or incomplete information exchange.

### First Experiments
1. Implement a simple traffic signal control scenario with two agents in SUMO to test basic MARL coordination.
2. Scale up to a multi-intersection network in CityFlow to evaluate scalability and communication overhead.
3. Conduct a sim-to-real transfer test by deploying a trained policy in CARLA and measuring performance degradation.

## Open Questions the Paper Calls Out
- How can federated learning be effectively integrated with MARL to enhance scalability and privacy in ITS?
- What are the best practices for designing safety-aware MARL policies that guarantee robustness in real-world deployments?
- How can robust communication protocols be developed to handle dynamic and unreliable network conditions in large-scale ITS?

## Limitations
- **Medium confidence** in federated learning and edge computing integration accelerating MARL adoption due to limited real-world deployments.
- **High confidence** in sim-to-real transfer gaps being a primary bottleneck, but proposed mitigation strategies lack extensive validation.
- **Medium confidence** in scalability solutions due to computational complexity in large-scale multi-agent environments.

## Confidence
- **High**: Categorization of MARL applications across traffic signal control, CAV coordination, logistics, and mobility-on-demand is well-documented.
- **Medium**: Federated learning and edge computing integration will significantly accelerate MARL adoption in ITS.
- **High**: Sim-to-real transfer gaps are a primary bottleneck, but mitigation strategies lack extensive validation.

## Next Checks
1. Benchmark MARL approaches across SUMO, CityFlow, and CARLA under standardized traffic scenarios to assess reproducibility.
2. Conduct ablation studies isolating the impact of communication constraints versus non-stationarity on learning stability in multi-agent traffic settings.
3. Implement safety-aware MARL policies in a controlled field trial to quantify performance gaps between simulated and real-world deployments.