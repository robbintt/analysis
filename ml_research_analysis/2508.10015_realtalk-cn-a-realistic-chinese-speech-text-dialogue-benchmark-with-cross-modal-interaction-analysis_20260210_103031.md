---
ver: rpa2
title: 'RealTalk-CN: A Realistic Chinese Speech-Text Dialogue Benchmark With Cross-Modal
  Interaction Analysis'
arxiv_id: '2508.10015'
source_url: https://arxiv.org/abs/2508.10015
tags:
- speech
- dialogue
- dataset
- task
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: RealTalk-CN introduces the first Chinese speech-text dual-modal
  TOD dataset with 5.4k dialogues (60K utterances, 150 hours) featuring paired speech-text
  annotations. The dataset captures real-world dialogue complexities including spontaneous
  speech disfluencies (repetitions, hesitations, self-corrections) and diverse speaker
  characteristics (gender, age, regional accents).
---

# RealTalk-CN: A Realistic Chinese Speech-Text Dialogue Benchmark With Cross-Modal Interaction Analysis

## Quick Facts
- arXiv ID: 2508.10015
- Source URL: https://arxiv.org/abs/2508.10015
- Reference count: 40
- Primary result: First Chinese speech-text TOD dataset with 5.4k dialogues and cross-modal chat task

## Executive Summary
RealTalk-CN introduces a comprehensive Chinese speech-text dialogue benchmark featuring 5.4k dialogues with 60K utterances and 150 hours of speech. The dataset uniquely captures real-world dialogue complexities including spontaneous speech disfluencies and diverse speaker characteristics. A novel cross-modal chat task enables dynamic switching between speech and text modalities during conversations, simulating authentic voice assistant interactions. The benchmark evaluates four key tasks: intent classification, slot-filling, end-to-end speech intent classification, and cross-modal chat.

## Method Summary
The dataset was constructed using a carefully designed annotation pipeline that captures both speech and text modalities with paired annotations. Speech disfluencies including repetitions, hesitations, and self-corrections were systematically annotated. The dataset covers four subsets: multi-domain vs single-domain dialogues and colloquial vs system speech. Models were evaluated across four tasks using both pipeline approaches (Whisper + GPT-4o) and end-to-end speech models (Qwen2.5-VL), with performance analyzed across speaker characteristics including gender, age, and regional accents.

## Key Results
- Speech disfluencies significantly impact slot-filling performance but less so intent classification
- Pipeline methods outperformed end-to-end models on intent classification and chat tasks
- End-to-end models excelled at slot-filling tasks
- Speaker characteristics (age and regional accent) significantly affect model performance, particularly for fine-grained semantic tasks

## Why This Works (Mechanism)
The dataset's effectiveness stems from its realistic representation of spoken dialogue phenomena. By capturing spontaneous speech disfluencies and diverse speaker characteristics, the benchmark creates challenging scenarios that better reflect real-world voice assistant interactions. The cross-modal chat task specifically addresses the dynamic nature of human-computer interaction where users switch between speaking and typing. The paired speech-text annotations enable both modality-specific and cross-modal model training, while the four-task evaluation framework comprehensively assesses different aspects of dialogue understanding.

## Foundational Learning
- Speech disfluencies (why needed: real dialogue is messy; quick check: can you identify repetitions and hesitations in transcripts?)
- Cross-modal interaction (why needed: users switch between speaking and typing; quick check: can you design a task requiring modality switching?)
- Slot-filling vs intent classification (why needed: different semantic understanding tasks; quick check: can you distinguish between identifying user intent and extracting specific entities?)
- Pipeline vs end-to-end architectures (why needed: different approaches to speech processing; quick check: can you explain the trade-offs between modular and integrated systems?)
- Speaker adaptation (why needed: performance varies across demographics; quick check: can you identify how age and accent affect model accuracy?)

## Architecture Onboarding

Component map: Raw audio -> ASR (Whisper) -> Text processing (GPT-4o) -> Dialogue understanding
Critical path: Speech input → ASR transcription → Intent/slot extraction → Response generation
Design tradeoffs: Pipeline modularity vs end-to-end integration, with pipeline offering flexibility but potential error accumulation
Failure signatures: ASR errors propagate to downstream tasks, speaker characteristics cause systematic performance degradation
First experiments: 1) Test ASR accuracy on disfluent speech, 2) Evaluate slot-filling with corrupted transcripts, 3) Measure cross-modal task performance with varying disfluency levels

## Open Questions the Paper Calls Out
None

## Limitations
- Dataset focus on Chinese restaurant reservations, music queries, and weather inquiries may not generalize to broader domains
- Performance gaps between pipeline and end-to-end models may reflect specific model choices rather than architectural advantages
- Cross-modal chat task evaluation lacks comparison against strong baselines
- Speaker characteristic analysis may have insufficient sample sizes for rare accents

## Confidence
- Dataset construction and speech disfluency annotation: High confidence
- Cross-modal chat task formulation: Medium confidence
- Performance gap analysis between pipeline and end-to-end models: Medium confidence
- Speaker characteristic impact findings: Low confidence

## Next Checks
1. Conduct ablation studies varying only the ASR component (keeping GPT-4o fixed) to isolate the impact of speech recognition quality on downstream tasks
2. Test model performance on out-of-domain TOD tasks to assess generalization beyond the three covered domains
3. Perform speaker adaptation experiments where models are fine-tuned on representative samples from underrepresented age groups and accents to evaluate potential bias mitigation strategies