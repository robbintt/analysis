---
ver: rpa2
title: 'Redefining non-IID Data in Federated Learning for Computer Vision Tasks: Migrating
  from Labels to Embeddings for Task-Specific Data Distributions'
arxiv_id: '2503.14553'
source_url: https://arxiv.org/abs/2503.14553
tags:
- data
- heterogeneity
- tasks
- global
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper identifies a fundamental gap in how federated learning
  (FL) studies data heterogeneity for computer vision tasks beyond classification.
  Prior methods rely on label-based data heterogeneity (label distribution skew),
  which fails to capture realistic variations in tasks like depth estimation or edge
  detection, where task-relevant features are not tied to labels.
---

# Redefining non-IID Data in Federated Learning for Computer Vision Tasks: Migrating from Labels to Embeddings for Task-Specific Data Distributions

## Quick Facts
- **arXiv ID**: 2503.14553
- **Source URL**: https://arxiv.org/abs/2503.14553
- **Reference count**: 40
- **Primary result**: Embedding-based heterogeneity reveals 60% larger performance gaps in FL for vision tasks compared to label-based approaches

## Executive Summary
This paper addresses a fundamental gap in federated learning research for computer vision tasks beyond classification. The authors identify that existing non-IID data formulations based on label distribution skew fail to capture realistic task-specific data heterogeneity in vision applications like depth estimation or edge detection. They introduce a novel embedding-based heterogeneity formulation that leverages task-specific embeddings from pre-trained networks to model data distributions. Extensive experiments across seven vision tasks demonstrate that embedding-based heterogeneity creates significantly larger performance gaps in federated learning methods compared to traditional label-based approaches, suggesting prior research has overestimated performance for non-classification vision tasks.

## Method Summary
The authors propose embedding-based data heterogeneity as an alternative to traditional label-based approaches for federated learning in computer vision. The method extracts task-specific embeddings from the penultimate layer of a pre-trained ResNet50 network for each data point. These embeddings are clustered, and data points are distributed across clients using a Dirichlet distribution, generalizing label-based heterogeneity. This approach captures task-relevant feature variations rather than just label imbalances. The method is evaluated across seven vision tasks (depth estimation, semantic segmentation, object detection, edge detection, keypoint detection, motion estimation, normal estimation) and four federated learning algorithms (FedAvg, FedProx, SCAFFOLD, FedRep).

## Key Results
- Embedding-based heterogeneity produces up to 60% larger performance gaps compared to label-based heterogeneity under FedAvg
- Performance degradation increases monotonically with the Dirichlet concentration parameter Î±
- Task-specific performance varies significantly: keypoint detection shows 5% loss increase while edge detection shows 60% loss increase under FedAvg
- Results consistent across multiple federated learning methods (FedAvg, FedProx, SCAFFOLD, FedRep, FedAmp)

## Why This Works (Mechanism)
The mechanism works because computer vision tasks beyond classification rely on complex feature distributions that are not adequately captured by label imbalances alone. Traditional label-based heterogeneity assumes that data heterogeneity is primarily about the distribution of class labels, which works well for classification tasks. However, vision tasks like depth estimation, edge detection, or semantic segmentation depend on spatial and contextual features that vary independently of semantic labels. By using task-specific embeddings from pre-trained networks, the proposed method captures these underlying feature distributions, creating more realistic heterogeneity that reflects actual variations in vision data distributions across clients.

## Foundational Learning
- **Task-specific embeddings**: Extracting meaningful features from pre-trained networks that capture task-relevant information beyond labels; needed because vision tasks depend on complex feature relationships; quick check: visualize embedding clusters for different tasks
- **Dirichlet distribution for data partitioning**: Mathematical framework for creating non-IID data distributions across clients; needed to control the degree of heterogeneity; quick check: verify that generated data distributions match target Dirichlet parameters
- **Penultimate layer features**: Using the second-to-last layer of neural networks for representation learning; needed because these features capture rich semantic information; quick check: compare performance using different network layers

## Architecture Onboarding
- **Component map**: Pre-trained ResNet50 -> Embedding extraction -> Clustering -> Dirichlet sampling -> Data partitioning -> Federated learning training
- **Critical path**: The embedding extraction and clustering steps are most critical as they determine the quality of heterogeneity modeling
- **Design tradeoffs**: Using pre-trained features enables task-specific heterogeneity but assumes the pre-training captures relevant task features; clustering quality affects heterogeneity representation
- **Failure signatures**: Poor clustering of embeddings leads to unrealistic heterogeneity; inappropriate Dirichlet parameters result in either insufficient or excessive heterogeneity
- **First experiments**: 1) Visualize embedding distributions for different vision tasks, 2) Test clustering sensitivity to number of clusters, 3) Evaluate impact of different pre-trained backbones on heterogeneity quality

## Open Questions the Paper Calls Out
None provided in source material.

## Limitations
- The embedding-based heterogeneity formulation relies on a pre-trained ResNet50 and may not generalize to all vision tasks or architectures
- The claim that label-based heterogeneity is "inadequate" for computer vision tasks may overstate the case for tasks with strong semantic dependencies
- The evaluation focuses primarily on image-based tasks without addressing video, point cloud, or other vision modalities

## Confidence
- **High confidence**: The empirical observation that embedding-based heterogeneity creates larger performance gaps than label-based heterogeneity
- **Medium confidence**: The claim that this gap reveals "overestimated" performance in prior studies
- **Medium confidence**: The assertion that label-based heterogeneity is fundamentally inadequate for computer vision tasks
- **Low confidence**: The assumption that the proposed embedding-based formulation is universally applicable across all computer vision tasks

## Next Checks
1. Test the embedding-based heterogeneity formulation with different backbone architectures (e.g., Vision Transformers, EfficientNet) to verify robustness across model families
2. Evaluate the approach on additional computer vision tasks such as object detection, instance segmentation, and video-based tasks to assess broader applicability
3. Conduct ablation studies varying the number of clusters and Dirichlet concentration parameter to understand their impact on heterogeneity modeling and FL performance