---
ver: rpa2
title: 'CORTEX: A Cost-Sensitive Rule and Tree Extraction Method'
arxiv_id: '2502.03200'
source_url: https://arxiv.org/abs/2502.03200
tags:
- cortex
- rule
- methods
- rules
- class
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study introduces CORTEX, a cost-sensitive rule and tree extraction
  method designed to enhance the interpretability of machine learning models. CORTEX
  extends the cost-sensitive decision tree (CSDT) method to handle multi-class classification
  problems by incorporating an n-dimensional class-dependent cost matrix.
---

# CORTEX: A Cost-Sensitive Rule and Tree Extraction Method

## Quick Facts
- arXiv ID: 2502.03200
- Source URL: https://arxiv.org/abs/2502.03200
- Authors: Marija Kopanja; Miloš Savić; Luca Longo
- Reference count: 11
- Primary result: CORTEX generates smaller rule sets with shorter average rule lengths while maintaining competitive accuracy, fidelity, and completeness across diverse datasets.

## Executive Summary
CORTEX is a post-hoc rule extraction method that extends cost-sensitive decision trees to multi-class classification by incorporating an n-dimensional class-dependent cost matrix. The method addresses class imbalance by favoring minority classes during tree construction and extracts human-understandable IF-THEN rules from the resulting tree structure. Experimental results demonstrate that CORTEX produces more compact rule sets compared to existing methods while maintaining competitive performance metrics across eight UCI datasets.

## Method Summary
CORTEX trains a feedforward neural network on input data, then builds a cost-sensitive decision tree (CSDT) using the NN's predictions as soft labels. The tree construction uses an n-dimensional cost matrix where misclassification costs are inversely proportional to class frequencies. The algorithm employs soft-labeling at terminal nodes using cost-sensitive probabilities rather than simple majority voting. Finally, IF-THEN rules are extracted by traversing root-to-leaf paths and converting the conjunctions of feature tests into human-readable statements.

## Key Results
- Produces smaller rule sets compared to baseline methods across all tested datasets
- Generates rules with shorter average length, improving interpretability
- Maintains competitive accuracy, fidelity, and completeness scores
- Effectively handles class imbalance through cost-sensitive tree construction
- Demonstrates superior performance on minority class representation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Incorporating an n-dimensional class-dependent cost matrix allows the decision tree to maintain fidelity on minority classes which standard trees might otherwise ignore.
- Mechanism: CORTEX modifies the splitting criteria by using a cost matrix where misclassification costs are inversely proportional to class frequency, forcing the algorithm to penalize errors on rare classes more heavily.
- Core assumption: The class imbalance ratio is an effective proxy for misclassification cost when actual costs are unknown.
- Evidence anchors: The default cost matrix uses class imbalance ratios among classes, and the approach explicitly addresses class imbalance by favoring minority classes.

### Mechanism 2
- Claim: Soft-labeling terminal nodes using cost-sensitive probabilities allows the surrogate tree to better approximate the uncertainty and behavior of the black-box model.
- Mechanism: Instead of simple majority voting, CORTEX calculates class probabilities based on normalized inverse average costs, mathematically corresponding to the least costly class assignment.
- Core assumption: Probability distributions derived from cost matrices provide a more faithful representation of the black-box model's decision boundaries than standard impurity measures.
- Evidence anchors: Classifying a sample in the least costly class is equivalent to classifying it in the class with the highest cost-sensitive probability.

### Mechanism 3
- Claim: Converting the tree structure into IF-THEN rules enhances human comprehensibility compared to navigating a deep hierarchical tree structure.
- Mechanism: CORTEX traverses root-to-leaf paths, collecting feature test conditions along the path to form the "IF" part, with the class label forming the "THEN" part.
- Core assumption: Users can synthesize disjoint, potentially overlapping rules more effectively than tracing a monolithic tree flowchart.
- Evidence anchors: The method explicitly generates human-understandable IF-THEN rules and analyzing rules instead of following paths often improves comprehensibility.

## Foundational Learning

**Cost-Sensitive Learning**
- Why needed: CORTEX is fundamentally a cost-sensitive algorithm; understanding how misclassification costs differ from accuracy metrics is required to configure the n-dimensional cost matrix.
- Quick check: How does increasing the cost of a False Negative affect the decision boundary compared to optimizing for Accuracy?

**Surrogate Modeling (Post-hoc XAI)**
- Why needed: CORTEX is a post-hoc method that mimics the black-box model's input-output behavior without looking inside the neural network.
- Quick check: Can a surrogate model have higher fidelity to a black-box model than the black-box has to the ground truth?

**Rule Extraction metrics (Fidelity vs. Correctness)**
- Why needed: The paper evaluates success not just on "is it right?" but "does it match the black-box?" which are distinct metrics.
- Quick check: If a rule set has 100% fidelity but 50% correctness, what does that tell you about the black-box model being explained?

## Architecture Onboarding

**Component map:**
Black Box (NN) -> Labeling Module -> Cost Matrix Generator -> CSDT Builder -> Rule Translator

**Critical path:** The definition of the Cost Matrix (Component 3) is the single point of failure; if the default imbalance ratio does not match domain priorities, the resulting rules will be biased incorrectly.

**Design tradeoffs:**
- Rule Complexity vs. Fidelity: CORTEX produces shorter rules (better interpretability) potentially at the slight cost of fidelity/robustness compared to heavier methods
- Custom vs. Default Matrix: Tuning the matrix is computationally expensive for multi-class problems; the default is robust but domain-agnostic

**Failure signatures:**
- Rule Explosion: If the dataset has high noise, CORTEX may overfit, generating an excessive number of rules
- Low Robustness: CORTEX can underperform on robustness, with sensitivity to noise potentially undermining practical deployment

**First 3 experiments:**
1. Binary Classification Baseline: Run CORTEX on the "Credit" dataset (binary, imbalanced). Compare the number of rules generated against a standard CART tree with class weights.
2. Multi-Class Matrix Sensitivity: On the "Yeast" dataset (10 classes), swap the default cost matrix for a uniform cost matrix. Verify that performance on minority classes drops.
3. Fidelity Check: Train a neural network on "Mushroom" (easy dataset). Extract rules with CORTEX. Measure Fidelity to ensure the rules truly mimic the NN.

## Open Questions the Paper Calls Out

**Open Question 1**
- Question: How can the CORTEX algorithm be refined to improve its robustness to minor input perturbations without sacrificing its advantages in rule compactness?
- Basis in paper: Section 5 notes CORTEX is underperforming compared to other tree-based methods regarding robustness, and Section 6 explicitly calls for refining the algorithm so that minor input modifications do not lead to significant changes in the model's predictions.
- Why unresolved: The current methodology prioritizes generating small rule sets for class imbalance, which appears to introduce instability (lower robustness scores) compared to benchmarks like TREPAN or weighted Decision Trees.
- What evidence would resolve it: A modified version of CORTEX demonstrating statistically significant improvements in robustness scores on the test datasets while maintaining a competitive number of rules and fidelity.

**Open Question 2**
- Question: To what extent does the definition of the n-dimensional class-dependent cost matrix impact CORTEX's fidelity compared to the default imbalance-ratio-based formulation?
- Basis in paper: Section 3 states that future work could explore modifications of the cost matrix and warns that a poorly chosen cost matrix could lead to suboptimal results, while the current study relies solely on a default matrix based on class imbalance ratios.
- Why unresolved: It is currently unclear if the default heuristic for the cost matrix is optimal for all datasets or if manual tuning/domain knowledge could yield higher fidelity or correctness in the extracted rules.
- What evidence would resolve it: An ablation study comparing the performance of the default matrix against manually tuned or domain-specific cost matrices across the eight datasets used in the paper.

**Open Question 3**
- Question: Does CORTEX maintain its competitive fidelity and rule simplicity when explaining complex, deep neural network architectures beyond the shallow feed-forward networks tested?
- Basis in paper: Section 6 identifies the examination of various neural network architectures based on the complexity of new datasets as a specific direction for future work.
- Why unresolved: The experimental scope is currently limited to relatively simple neural networks (1 or 2 hidden layers); performance may degrade if CORTEX is used as a surrogate for highly non-linear models like Deep Belief Networks or Transformers.
- What evidence would resolve it: Experimental results applying CORTEX to modern deep learning architectures on complex datasets, benchmarked against the same six explainability metrics.

## Limitations
- The default cost matrix assumes class imbalance ratios reflect misclassification costs, which may not hold in domains where common-class errors are more expensive than rare-class errors
- Soft-labeling mechanism lacks direct corpus validation - the specific probability calculation formula is not corroborated in related literature
- Performance on robustness metrics is explicitly noted as a weakness, with sensitivity to noise potentially undermining practical deployment

## Confidence

**High**: CORTEX successfully extracts smaller rule sets with shorter average rule lengths compared to baseline methods (supported by comparative metrics)

**Medium**: The cost-sensitive matrix effectively addresses class imbalance by favoring minority classes (mechanism is sound but depends on domain cost alignment)

**Medium**: Soft-labeling improves surrogate fidelity to black-box models (plausible but lacks external validation)

## Next Checks

1. Test CORTEX on a dataset where common-class errors are actually more costly than rare-class errors to verify the default matrix assumption fails as predicted

2. Implement a uniform cost matrix variant on multi-class datasets to demonstrate performance degradation on minority classes, validating Mechanism 1

3. Measure rule set stability under small input perturbations on noisy datasets to quantify the robustness limitation mentioned in the paper