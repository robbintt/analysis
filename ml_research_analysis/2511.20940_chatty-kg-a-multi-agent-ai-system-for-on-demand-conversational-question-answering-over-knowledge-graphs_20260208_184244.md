---
ver: rpa2
title: 'Chatty-KG: A Multi-Agent AI System for On-Demand Conversational Question Answering
  over Knowledge Graphs'
arxiv_id: '2511.20940'
source_url: https://arxiv.org/abs/2511.20940
tags:
- agent
- question
- query
- systems
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Chatty-KG introduces a multi-agent framework for conversational
  question answering over knowledge graphs. It uses specialized LLM agents for contextual
  understanding, entity linking, and query planning, generating SPARQL queries instead
  of retrieving subgraphs, thus preserving KG structure.
---

# Chatty-KG: A Multi-Agent AI System for On-Demand Conversational Question Answering over Knowledge Graphs

## Quick Facts
- **arXiv ID:** 2511.20940
- **Source URL:** https://arxiv.org/abs/2511.20940
- **Reference count:** 40
- **One-line primary result:** Outperforms state-of-the-art systems with F1 scores up to 82.11% on YAGO and 80.39% on DBLP, achieving up to 87% higher P@1 in multi-turn settings.

## Executive Summary
Chatty-KG is a multi-agent framework that performs conversational question answering over knowledge graphs by generating SPARQL queries instead of retrieving subgraphs. It uses specialized LLM agents for contextual understanding, entity linking, and query planning, achieving high accuracy across diverse KGs while supporting real-time dialogue and adapting to evolving knowledge graphs. The system demonstrates strong performance on benchmarks like QALD-9 and LC-QuAD, with particular success in multi-turn conversations.

## Method Summary
Chatty-KG decomposes KGQA into specialized LLM agents: a controller (Chat Agent), a context module (Classifier and Rephraser Agents), a structuring module (QIR Agent), and an execution module (Matching and Query Planning Agents). The system generates executable SPARQL queries to preserve KG structure, handles multi-turn conversations through context-dependent question rephrasing, and uses assertion-based validation to prevent error propagation. Built on LangGraph without training requirements, it supports both commercial and open-weight LLMs while maintaining low latency and high precision.

## Key Results
- Achieves F1 scores up to 82.11% on YAGO and 80.39% on DBLP
- Demonstrates up to 87% higher P@1 in multi-turn settings compared to baselines
- Shows consistent performance across five diverse KGs including DBpedia, Wikidata, and MAG
- Supports real-time dialogue with low latency and adapts to evolving KGs

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Decomposing the QA pipeline into specialized LLM agents improves modularity and reduces error propagation compared to monolithic models.
- **Mechanism:** Hierarchical design where Chat Agent controller delegates to QIR Agent (structural representation), Matching Agent (entity grounding), and Query Planning Agent (SPARQL generation), with validation checks at handoff points.
- **Core assumption:** LLMs perform better on narrow tasks than complex instructions, and multi-agent overhead doesn't negate accuracy gains.
- **Evidence anchors:** Abstract mentions specialized agents; Section 3 describes hierarchical design splitting tasks into clusters.

### Mechanism 2
- **Claim:** Generating SPARQL queries preserves graph structure better than subgraph retrieval, leading to higher precision in multi-hop queries.
- **Mechanism:** Translates Question Intermediate Representation directly into SPARQL syntax instead of serializing graph content into text chunks, forcing reasoning along existing edges.
- **Core assumption:** LLMs have sufficient SPARQL generation capabilities to map natural language to formal query syntax without KG-specific preprocessing.
- **Evidence anchors:** Abstract states system generates SPARQL queries instead of retrieving subgraphs; Page 2 explains preservation of graph semantics.

### Mechanism 3
- **Claim:** Resolving context dependency via Rephraser Agent allows standard QA components to handle multi-turn dialogues without complex state machines.
- **Mechanism:** Classifies questions as self-contained or context-dependent, then uses dialogue history to rewrite context-dependent questions into standalone versions for downstream processing.
- **Core assumption:** LLM can accurately resolve anaphora and ellipsis using truncated history context without explicit coreference models.
- **Evidence anchors:** Abstract mentions LLM-powered context tracking; Section 4.2.2 describes converting context-dependent questions using dialogue history.

## Foundational Learning

- **Concept: SPARQL (SPARQL Protocol and RDF Query Language)**
  - **Why needed here:** Execution layer for Query Planning Agent; understanding triple patterns and SELECT queries is critical for debugging and interpreting execution errors.
  - **Quick check question:** Given the triple `<:Alice> <:knows> :Bob`, write a SPARQL query to find who Alice knows.

- **Concept: Entity Linking (EL)**
  - **Why needed here:** Matching Agent bridges natural language ("Harry Potter") and graph identifiers (`http://dbpedia.org/resource/Harry_Potter`); EL errors propagate directly into query failures.
  - **Quick check question:** Why might an Entity Linker struggle to map "Apple" to the correct URI in a graph containing both the fruit and the company?

- **Concept: Assertion-Based Validation**
  - **Why needed here:** Chatty-KG uses Validators to check LLM outputs before state transitions; understanding structural constraints prevents agent loops.
  - **Quick check question:** In a pipeline, should a validator fix errors automatically or trigger retries? Why might the latter be safer in LLM-based systems?

## Architecture Onboarding

- **Component map:** Chat Agent -> Classifier Agent -> Rephraser Agent -> QIR Agent -> Matching Agent -> Query Planning Agent

- **Critical path:** 1. Input: User Question + History 2. Resolution: Classify → Rephrase (if needed) → Generate QIR (triples) 3. Grounding: Match Entities to Vertices → Match Relations to Predicates 4. Execution: Generate SPARQL → Validate → Execute on RDF Engine → Return Answer

- **Design tradeoffs:**
  - **Latency vs. Robustness:** Higher retry count (θ) increases robustness but linearly increases latency
  - **Generalization vs. Specificity:** Zero-shot prompting allows arbitrary KG support but may lack precision of fine-tuned parsers
  - **Token Limits:** Larger history context (L) improves awareness but risks hitting token limits and increasing cost

- **Failure signatures:**
  - **Empty Results:** Often implies Matching Agent failed to link entities or Query Planning Agent generated over-constrained queries
  - **High Latency (>10s):** Likely caused by retry loop triggering repeatedly due to persistent validation failures
  - **Hallucinated Context:** Rephraser resolved pronoun to wrong entity, resulting in correct query for wrong subject

- **First 3 experiments:**
  1. **Single-Turn Baseline:** Run on QALD-9 with system_mode=single-turn, verify QIR Agent outputs valid triples, compare F1 against KGQAn baseline
  2. **Context Ablation:** Input multi-turn dialogue but disable Rephraser Agent, measure F1 drop to quantify context normalization value
  3. **Model Substitution:** Replace backbone LLM with smaller open-weight model, monitor Query Validator rejection rate to assess model dependency

## Open Questions the Paper Calls Out

- **Open Question 1:** How can lightweight fine-tuning be integrated into Chatty-KG to improve accuracy without sacrificing adaptability to evolving KGs? The paper notes that while prompting avoids dataset creation, fine-tuning could help but requires task- and KG-specific data, reducing flexibility.

- **Open Question 2:** To what extent does schema redundancy degrade LLM-based predicate selection performance, and how can it be mitigated for complex KGs like DBpedia? The authors attribute lower performance on DBpedia to its massive schema (60,736 predicates) introducing high ambiguity in predicate selection.

- **Open Question 3:** What specific interpretability tools are required to debug error propagation in hierarchical multi-agent KGQA systems? The conclusion states debugging becomes more complex due to interactions between multiple specialized agents, but lacks methodology for tracing root causes when final answers are incorrect.

## Limitations
- System performance heavily depends on underlying KG quality and SPARQL endpoint, with no discussion of handling missing predicates or inconsistent schemas
- Few-shot/zero-shot prompting requires access to supplementary materials for exact prompt templates, creating reproduction barriers
- Claimed scalability to evolving KGs is not demonstrated; no discussion of handling schema changes without re-prompting or retraining

## Confidence
- **High Confidence:** Core multi-agent architecture is well-defined with clearly reported evaluation results across multiple benchmarks and KG datasets
- **Medium Confidence:** Context handling mechanism is logically sound but lacks quantitative ablation studies to prove necessity or measure history truncation impact
- **Low Confidence:** System's claimed adaptability to evolving KGs is not demonstrated with no discussion of schema change handling

## Next Checks
1. **Prompt Template Verification:** Obtain and test exact prompt templates for QIR Agent, Matching Agent, and Query Planning Agent; compare outputs with and without specific prompts to isolate prompt engineering contribution
2. **Latency Benchmarking:** Measure end-to-end latency on QALD-9 test set and compare against monolithic LLM baseline (GPT-4o); report average and 95th percentile latency
3. **Robustness to KG Quality:** Evaluate on KG with known schema inconsistencies or missing links; measure F1 score degradation to quantify reliance on clean, well-structured KGs