---
ver: rpa2
title: 'Distilling Multilingual Vision-Language Models: When Smaller Models Stay Multilingual'
arxiv_id: '2510.26271'
source_url: https://arxiv.org/abs/2510.26271
tags:
- teacher
- student
- multilingual
- distillation
- retrieval
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The study addresses the challenge of maintaining multilingual\
  \ performance when compressing vision-language models using knowledge distillation.\
  \ The core method involves comparing five distillation strategies\u2014feature distillation,\
  \ English-control distillation, soft-logit distillation, multilingual contrastive\
  \ learning, and distributional replication\u2014across CLIP and SigLIP2 architectures."
---

# Distilling Multilingual Vision-Language Models: When Smaller Models Stay Multilingual

## Quick Facts
- arXiv ID: 2510.26271
- Source URL: https://arxiv.org/abs/2510.26271
- Reference count: 28
- The study addresses the challenge of maintaining multilingual performance when compressing vision-language models using knowledge distillation.

## Executive Summary
This study investigates the problem of compressing vision-language models while preserving multilingual retrieval performance. The authors evaluate five knowledge distillation strategies across CLIP and SigLIP2 architectures, finding that distributional replication (DR) can maintain or improve multilingual retrieval robustness even when model size is halved. The research reveals that different distillation methods exhibit distinct strengths and weaknesses across tasks, with DR excelling at retrieval while English-control distillation performs better on out-of-domain VQA tasks.

## Method Summary
The study compares five knowledge distillation strategies: feature distillation (FD), English-control distillation (ED), soft-logit distillation (SD), multilingual contrastive learning (MCL), and distributional replication (DR). Students are trained on a 7M image-caption dataset with English as anchor language, translating captions to 10 target languages. DR constructs probability distributions using a queue of teacher embeddings and applies dual objectives (control and generalization losses). The framework tests SigLIP2 and CLIP teachers with XLM-R, DistilBERT, and MiniLM students, evaluating retrieval on Multi30k and out-of-domain VQA performance.

## Key Results
- Distributional replication preserves or improves multilingual retrieval robustness despite halving model size
- Text anchors outperform image anchors by 14.79 points in retrieval performance
- English-control distillation improves VQA performance by 2.97 points compared to distributional replication
- Combining DR+FD achieves best retrieval performance while maintaining reasonable VQA scores

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Distributional Replication (DR) preserves multilingual retrieval robustness by aligning student-teacher probability distributions over a dynamic queue of negative samples.
- **Mechanism:** DR constructs three similarity-based distributions—teacher-reference, student-control, and student-generalize—using a FIFO queue of teacher embeddings. The control loss enforces consistency with teacher knowledge; the generalization loss transfers this to multilingual inputs. This dual-objective structure maintains cross-lingual alignment while avoiding representation collapse.
- **Core assumption:** The queue-based distribution captures meaningful relational structure that transfers across languages.
- **Evidence anchors:**
  - [abstract] "some configurations preserve or even improve multilingual retrieval robustness despite halving model size, particularly distributional replication"
  - [Section 3.2.5] Equations 7-13 define the three distributions and combined loss
  - [corpus] AfroXLMR-Comet demonstrates attention-matching for low-resource language KD, supporting queue/similarity-based transfer mechanisms
- **Break condition:** If the queue size K is too small or temperature τ is misconfigured, the probability distributions become uninformative, collapsing the signal.

### Mechanism 2
- **Claim:** English-Control Distillation (ED) improves out-of-domain generalization (VQA) by explicitly anchoring both English and multilingual student representations to the teacher's English embeddings.
- **Mechanism:** ED adds an auxiliary MSE loss between student's English embeddings and teacher's English embeddings alongside the multilingual alignment. This prevents collapse where multiple languages converge to the same anchor, preserving language-specific structure beneficial for reasoning tasks.
- **Core assumption:** Preventing representation collapse improves generalization beyond the training distribution.
- **Evidence anchors:**
  - [Section 5.1] "the ED method outperforms the DR method by 2.97 points in the VQA benchmarks"
  - [Section 3.2.2] Equation 2 shows the dual MSE formulation
  - [corpus] No direct corpus support for ED specifically; mechanism remains paper-specific
- **Break condition:** If English and multilingual losses are improperly weighted (λ), one may dominate, causing either underfitting or collapse.

### Mechanism 3
- **Claim:** Text anchors outperform image anchors for retrieval distillation because text encodes semantic-grammatical information directly tied to the original captions.
- **Mechanism:** Text anchors provide precise semantic targets; image anchors are ambiguous—one visual representation maps to many valid descriptions. For retrieval, precise text-to-text alignment is critical; for VQA (out-of-domain), both anchor types perform comparably since neither directly addresses the domain shift.
- **Core assumption:** The retrieval task requires precise textual semantic alignment more than visual feature alignment.
- **Evidence anchors:**
  - [Section 5.3.2] "We observed a 14.79 point gap between text and image performance using DR"
  - [Section 5.3.2] "the performance of the image-anchor and text-anchor students is comparable" for VQA
  - [corpus] No direct corpus comparison of text vs. image anchors in multilingual KD
- **Break condition:** If training captions are noisy or mistranslated, text anchor quality degrades, potentially making image anchors competitive.

## Foundational Learning

- **Concept: Knowledge Distillation (KD)**
  - Why needed here: The paper assumes familiarity with KD as a technique for transferring knowledge from teacher to student via loss minimization.
  - Quick check question: Can you explain why soft targets (probability distributions) often outperform hard labels in KD?

- **Concept: Contrastive Learning (InfoNCE vs. Sigmoid Loss)**
  - Why needed here: MCL uses contrastive objectives; understanding positive/negative pair construction is essential for interpreting the queue-based DR mechanism.
  - Quick check question: How does increasing the number of negative samples affect contrastive learning quality?

- **Concept: Cross-Lingual Representation Alignment**
  - Why needed here: The core challenge is maintaining multilingual consistency after compression—understanding how embeddings cluster by language vs. semantics is critical.
  - Quick check question: What does a low purity score indicate about cross-lingual embedding structure?

## Architecture Onboarding

- **Component map:** Image/Description pairs → Teacher (SigLIP2/CLIP) → Loss functions (FD, ED, SD, MCL, DR) → Student (XLM-R/DistilBERT/MiniLM) → Target languages

- **Critical path:**
  1. Select teacher (SigLIP2 for multilingual, CLIP for English-only with cross-lingual transfer)
  2. Select student based on target size/speed trade-off
  3. Choose loss: DR for retrieval-heavy workloads, ED for VQA/generalization, DR+FD for best retrieval
  4. Train with English anchors; translate captions to target languages for student input

- **Design tradeoffs:**
  - DR → better retrieval, worse VQA; ED → better VQA, worse retrieval
  - Smaller students (MiniLM) → faster inference, larger multilingual gap
  - Non-English anchors (German/Chinese) → lower performance; linguistic proximity to English matters

- **Failure signatures:**
  - Retrieval accuracy drops sharply with image anchors instead of text anchors
  - VQA accuracy degrades when combining DR+FD (overfitting to retrieval objective)
  - Language-specific collapse: purity score rises, indicating languages cluster separately

- **First 3 experiments:**
  1. **Baseline comparison:** Train XLM-R Base with each single loss (FD, ED, SD, MCL, DR) using SigLIP2-L/16 as teacher; evaluate on Multi30k retrieval and CVQA.
  2. **Multi-objective ablation:** Combine DR+FD and DR+ED+FD; measure retrieval vs. VQA trade-off to confirm task-specific optimal configurations.
  3. **Anchor study:** Compare text vs. image anchors using DR on a 55% subset of ImageCaptioning7M; verify 10-15 point retrieval gap reported in Table 5.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can a unified distillation objective be developed to jointly optimize for both multilingual retrieval robustness and out-of-domain VQA performance?
- Basis in paper: [explicit] The authors conclude that current methods force a trade-off—Distributional Replication excels at retrieval while English-Control excels at VQA—and state, "This suggests the need to develop a new training objective that effectively addresses both retrieval and VQA tasks."
- Why unresolved: Combining current objectives (e.g., DR+ED+FD) results in performance penalties on VQA tasks compared to single-objective baselines, indicating that simply summing losses is insufficient.
- What evidence would resolve it: A training run utilizing a novel joint loss function that achieves state-of-the-art scores on both Multi30k retrieval and CVQA benchmarks simultaneously without degradation in either.

### Open Question 2
- Question: Can multilingual knowledge distillation be effectively generalized to use non-English languages as the primary anchor without significant information loss?
- Basis in paper: [explicit] The authors explicitly raise the question, "Is the KD framework generalized to other languages as the anchor?" and investigate German and Chinese anchors.
- Why unresolved: The study found that while German anchors perform reasonably well, Chinese anchors suffer a 17.42-point drop in retrieval performance due to linguistic distance and translation loss, leaving the generalization capability uncertain for diverse language families.
- What evidence would resolve it: A training configuration using a non-English anchor that matches or exceeds the English-anchor baseline on multilingual retrieval benchmarks (e.g., Multi30k), potentially using a translation mechanism that preserves semantic density.

### Open Question 3
- Question: Can image representations serve as viable anchors for multilingual distillation if the semantic ambiguity of visual features is reduced?
- Basis in paper: [inferred] The ablation study (Section 5.3.2) shows that using image anchors results in a substantial 14.79-point drop in retrieval performance compared to text anchors.
- Why unresolved: The paper hypothesizes that this failure is due to image representations being "ambiguous" by encoding features corresponding to multiple valid text descriptions, but it does not test methods to disambiguate these signals.
- What evidence would resolve it: A modified distillation pipeline using image anchors (potentially with caption conditioning or region-text alignment) that achieves retrieval performance parity with text-anchor methods on the WIT or XM3600 benchmarks.

## Limitations
- Limited multilingual language coverage with only 10 target languages and two evaluation benchmarks
- Single teacher architecture per setting may limit generalizability to other vision-language backbones
- Simplified negative sampling using English-centric queues may introduce language bias
- Translation artifacts from machine-translated captions could influence results independently of distillation methods

## Confidence
- **High confidence**: The comparative advantage of distributional replication (DR) for retrieval preservation is well supported by multiple ablation studies and retrieval metrics
- **Medium confidence**: The claim that text anchors outperform image anchors in retrieval is supported, but the mechanism is not fully explored
- **Low confidence**: The assertion that English-control distillation (ED) universally improves VQA generalization is based on a single benchmark (CVQA)

## Next Checks
1. **Queue content sensitivity**: Retrain DR with multilingual teacher queues (not just English) and compare retrieval performance; verify whether English-centric queues introduce a language bias in learned embeddings

2. **Cross-task stability under stress**: Train students on noisy or low-resource language captions (e.g., AfroXLMR-Comet style) and measure both retrieval accuracy and VQA generalization; confirm whether ED+FD combinations overfit under distribution shift

3. **Anchor type under translation noise**: Repeat the anchor comparison (text vs. image) using manually verified translations and back-translations; quantify whether retrieval gaps persist independent of translation quality