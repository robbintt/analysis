---
ver: rpa2
title: 'Brain Hematoma Marker Recognition Using Multitask Learning: SwinTransformer
  and Swin-Unet'
arxiv_id: '2505.06185'
source_url: https://arxiv.org/abs/2505.06185
tags:
- task
- learning
- data
- swin
- segmentation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of spurious correlations in brain
  hematoma marker recognition by proposing MTL-Swin-Unet, a multi-task learning method
  using transformers for classification and semantic segmentation. The core idea is
  to enhance image representation by jointly learning from classification, segmentation,
  and image reconstruction tasks, which helps mitigate spurious correlations.
---

# Brain Hematoma Marker Recognition Using Multitask Learning: SwinTransformer and Swin-Unet

## Quick Facts
- arXiv ID: 2505.06185
- Source URL: https://arxiv.org/abs/2505.06185
- Authors: Kodai Hirata; Tsuyoshi Okita
- Reference count: 3
- One-line result: Multi-task learning with Swin-Unet improves brain hematoma marker recognition by reducing spurious correlations, achieving AUC of 0.799 under covariate shift.

## Executive Summary
This paper addresses spurious correlations in brain hematoma marker recognition by proposing MTL-Swin-Unet, a multi-task learning method using transformers for classification and semantic segmentation. The core idea is to enhance image representation by jointly learning from classification, segmentation, and image reconstruction tasks, which helps mitigate spurious correlations. Experiments show that MTL-Swin-Unet (cls + seg + rec) achieved an F1-score of 0.903 and AUC of 0.967 on test data with no covariate shift, outperforming other classifiers. For covariate shift settings, it achieved the highest AUC of 0.799.

## Method Summary
The method uses Swin-Unet architecture with shared encoder and task-specific decoders. The shared Swin Transformer encoder processes 224×224 CT images and outputs hierarchical representations. Three task-specific heads are trained jointly: a classification head for hypodensity detection, a segmentation decoder for hematoma masks, and a reconstruction decoder for input image reconstruction. The multi-task loss combines these objectives with weights λ_cls=0.3, λ_seg=0.4, and λ_rec=0.4. The approach leverages segmentation masks from hospitals 1-4 to train auxiliary tasks, with the hypothesis that joint learning reduces reliance on spurious correlations like skull boundaries.

## Key Results
- MTL-Swin-Unet (cls + seg + rec) achieved F1-score of 0.903 and AUC of 0.967 on test data with no covariate shift
- For covariate shift settings, achieved highest AUC of 0.799 compared to baselines
- Segmentation task contributes more to classification improvement than reconstruction alone, with reconstruction potentially introducing conflicting information

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-task learning with segmentation and reconstruction tasks improves classification robustness by reducing spurious correlations.
- Mechanism: The shared encoder learns representations that must satisfy multiple objectives simultaneously. Segmentation forces the model to localize hematoma regions precisely, while reconstruction preserves global image structure. This prevents the classifier from relying on spurious features (e.g., skull or background) that correlate with labels but are not causally relevant.
- Core assumption: Segmentation labels accurately mark hematoma regions, and these regions are the causally relevant features for classification.
- Evidence anchors:
  - [abstract] "This method allows us to enhance the image representation with two other image representations: representation obtained by semantic segmentation and representation obtained by image reconstruction."
  - [section] "By visualizing the areas the model focuses on with Grad-CAM, we found that the model strongly focuses on the hematomas."
  - [corpus] Weak direct evidence; neighbor papers discuss multi-task learning in other domains but not spurious correlation mitigation specifically.
- Break condition: If segmentation masks are noisy or inconsistent across annotators, the shared encoder may learn incorrect spatial priors.

### Mechanism 2
- Claim: The segmentation task contributes more to classification improvement than reconstruction alone.
- Mechanism: Segmentation directly encodes lesion-level spatial priors into the encoder representations. Reconstruction alone may encode conflicting information (global texture vs. lesion-specific features). When trained together, segmentation guides reconstruction to focus on diagnostically relevant regions.
- Core assumption: The beneficial representations from segmentation are transferable to classification without negative interference.
- Evidence anchors:
  - [abstract] Not explicitly stated; inferred from experimental results.
  - [section] "MTL-Swin-Unet (cls + seg) surpassed Swin Transformer in AUC on test data (hospitals 1-4) by 0.004 and on test data (hospitals 5-11) by 0.016... MTL-Swin-Unet (cls + rec) fell behind Swin Transformer in AUC."
  - [corpus] No direct corpus evidence for this specific finding.
- Break condition: If the segmentation and classification tasks have conflicting optimal representations (negative transfer), joint training could degrade both.

### Mechanism 3
- Claim: Multi-task learning improves generalization under covariate shift (unseen hospitals) but not uniformly across all metrics.
- Mechanism: The auxiliary tasks act as implicit regularizers, preventing overfitting to hospital-specific imaging artifacts. However, the improvement is more pronounced in AUC than F1-score, suggesting better ranking calibration but not necessarily better threshold-dependent classification.
- Core assumption: Covariate shift in this dataset primarily manifests as imaging distribution differences rather than lesion appearance differences.
- Evidence anchors:
  - [abstract] "When the test data did not include slices from the same patient (covariate shift setting), the proposed method outperformed in AUC measure."
  - [section] "For the test data from hospitals 5-11, MTL-Swin-Unet (cls + seg + rec) had a lower F1-score compared to Joint-SwinTransformer, but it achieved the maximum AUC of 0.799."
  - [corpus] Neighbor paper "Large Connectome Model" mentions multitask learning improving generalization in fMRI, but domain transfer to CT is uncertain.
- Break condition: If test hospitals have fundamentally different lesion presentations (not just imaging artifacts), multi-task regularization may be insufficient.

## Foundational Learning

- Concept: **Spurious Correlation**
  - Why needed here: The paper's core motivation is that standard classifiers learn to associate non-target features (skull, background) with the hypodensity label, leading to poor generalization.
  - Quick check question: Can you explain why a model trained on waterfowl images might learn to detect water instead of birds?

- Concept: **Swin Transformer (Shifted Window Transformer)**
  - Why needed here: The architecture uses hierarchical patch-based attention with shifted windows, enabling both local and global context while maintaining computational efficiency for medical images.
  - Quick check question: How does the shifted window mechanism differ from standard ViT's global attention?

- Concept: **U-Net Skip Connections**
  - Why needed here: The decoder uses skip connections to preserve spatial resolution lost during encoder downsampling, critical for pixel-level segmentation and reconstruction.
  - Quick check question: What information is lost during encoder downsampling that skip connections help recover?

## Architecture Onboarding

- Component map:
  - Image (224×224) → Swin Transformer encoder (4 stages) → Hierarchical representations → Classification head → L_cls
  - Hierarchical representations + skip connections → Segmentation decoder → L_seg (Dice + CE)
  - Hierarchical representations + skip connections → Reconstruction decoder → L_rec (MSE)

- Critical path:
  1. Image → Encoder → hierarchical representations
  2. Encoder output → Classification head → L_cls
  3. Encoder output + skip connections → Segmentation decoder → L_seg (Dice + CE)
  4. Encoder output + skip connections → Reconstruction decoder → L_rec (MSE)
  5. Combined loss: L = 0.3·L_cls + 0.4·L_seg + 0.4·L_rec

- Design tradeoffs:
  - Loss weights: Paper uses λ_cls=0.3, λ_seg=0.4, λ_rec=0.4. Classification is underweighted relative to auxiliary tasks—may slow convergence on classification but improves generalization.
  - Model size: "Tiny" variant (6 blocks, 96 channels) showed mixed results—inconsistent improvement. Default (2 blocks, 96 channels) is recommended first.
  - Batch handling for missing segmentation labels: When no hemorrhage present, segmentation loss is computed only on images with masks. Ensure your data loader handles this correctly.

- Failure signatures:
  - Model focuses on skull/brain boundary instead of hematoma region → likely spurious correlation; verify with Grad-CAM.
  - Reconstruction loss converging but classification stagnant → reconstruction may be dominating; reduce λ_rec.
  - Large gap between training and validation AUC → overfitting; increase augmentation or reduce model capacity.

- First 3 experiments:
  1. **Baseline reproduction**: Train Swin Transformer classifier (single-task) on hypodensity classification. Measure AUC and F1 on both hospital sets. Verify spurious correlation via Grad-CAM.
  2. **Ablation by task**: Compare MTL-Swin-Unet with (cls+seg), (cls+rec), and (cls+seg+rec) to quantify each auxiliary task's contribution.
  3. **Covariate shift stress test**: Train only on hospitals 1-4, test on hospitals 5-11. Compare AUC degradation between single-task and multi-task models to measure robustness gain.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why does the image reconstruction task degrade classification performance when used without segmentation?
- Basis in paper: [explicit] The authors observe that MTL-Swin-Unet (cls + rec) fell behind baselines, suggesting the task "may even contain conflicting information."
- Why unresolved: The paper identifies the negative interaction but does not analyze the specific latent features or gradients causing this conflict.
- What evidence would resolve it: A feature space analysis (e.g., using CCA or mutual information) comparing cls+rec and cls+seg representations to isolate the conflicting signals.

### Open Question 2
- Question: Can the significant performance gap between no-covariate-shift and covariate-shift settings be further reduced?
- Basis in paper: [inferred] While the method achieves the highest AUC (0.799) in the covariate shift setting, this remains substantially lower than the 0.967 AUC achieved when test data includes slices from the same patient.
- Why unresolved: The paper establishes relative improvement over baselines but leaves the absolute generalization gap (approx. 17% AUC drop) as an unresolved robustness challenge.
- What evidence would resolve it: Experiments incorporating domain adaptation techniques or testing on a wider variety of external hospital data to close the generalization gap.

### Open Question 3
- Question: Would adaptive loss weighting strategies improve the model's stability compared to the fixed weights used?
- Basis in paper: [inferred] The method relies on manually set fixed weights ($\lambda_{cls}=0.3, \lambda_{seg}=0.4, \lambda_{rec}=0.4$) to balance tasks, which is known to be sensitive to data noise and task conflict.
- Why unresolved: Given the conflicting nature of the reconstruction task, static weights may fail to dynamically prioritize the more beneficial segmentation gradients during training.
- What evidence would resolve it: Ablation studies comparing the current fixed weighting against dynamic strategies like GradNorm or uncertainty weighting.

## Limitations
- The paper lacks direct empirical validation that spurious correlations are the true failure mode; Grad-CAM visualizations show hematoma focus but don't prove the model wasn't using other correlated features
- Loss weight optimization is not justified; the classification task is underweighted (0.3) compared to auxiliary tasks (0.4 each), which may slow convergence on the primary task
- Covariate shift experiments only test hospital-level distribution shifts, not other forms of spurious correlations (e.g., demographic biases)

## Confidence
- **High confidence**: The technical implementation of MTL-Swin-Unet is sound and the reported numerical results (AUC, F1-scores) are reproducible given the described architecture
- **Medium confidence**: The claim that multi-task learning mitigates spurious correlations is supported by evidence but not rigorously proven; alternative explanations (better feature learning, implicit regularization) are possible
- **Low confidence**: The specific attribution of improvement to segmentation vs. reconstruction tasks is based on indirect evidence and could benefit from more systematic ablation studies

## Next Checks
1. **Spurious correlation validation**: Create a controlled experiment where you add artificial background features correlated with labels, then test whether MTL-Swin-Unet shows reduced reliance on these features compared to single-task models
2. **Loss weight sensitivity analysis**: Systematically vary λ_cls, λ_seg, λ_rec (e.g., 0.5/0.25/0.25, 0.25/0.5/0.5, 0.33/0.33/0.33) to identify optimal weighting and verify that the reported configuration is not arbitrary
3. **Alternative spuriousness scenarios**: Test on additional covariate shift scenarios beyond hospital distribution (e.g., demographic groups, imaging protocols) to validate the robustness claims generalize beyond the tested setting