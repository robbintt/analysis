---
ver: rpa2
title: 'From Retrieval to Generation: Unifying External and Parametric Knowledge for
  Medical Question Answering'
arxiv_id: '2510.18297'
source_url: https://arxiv.org/abs/2510.18297
tags:
- knowledge
- question
- documents
- medical
- retrieved
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "MedRGAG is a unified retrieval\u2013generation augmented framework\
  \ for medical question answering that integrates external knowledge from medical\
  \ corpora and parametric knowledge from large language models. It comprises two\
  \ core modules: Knowledge-Guided Context Completion (KGCC), which generates complementary\
  \ background documents to fill knowledge gaps identified from retrieved evidence,\
  \ and Knowledge-Aware Document Selection (KADS), which adaptively selects the most\
  \ relevant and reliable subset of retrieved and generated documents."
---

# From Retrieval to Generation: Unifying External and Parametric Knowledge for Medical Question Answering

## Quick Facts
- arXiv ID: 2510.18297
- Source URL: https://arxiv.org/abs/2510.18297
- Authors: Lei Li; Xiao Zhou; Yingying Zhang; Xian Wu
- Reference count: 40
- Primary result: MedRGAG achieves 12.5% improvement over MedRAG and 4.5% gain over MedGENIE across five medical QA benchmarks

## Executive Summary
MedRGAG presents a unified framework that bridges external knowledge retrieval from medical corpora with parametric knowledge from large language models for medical question answering. The approach addresses knowledge gaps by generating complementary background documents (KGCC) and then selecting the most relevant evidence through adaptive document selection (KADS). Extensive experiments demonstrate significant performance gains over state-of-the-art baselines, establishing a new approach for knowledge-intensive medical reasoning tasks.

## Method Summary
MedRGAG integrates two core modules to unify retrieval and generation for medical question answering. The Knowledge-Guided Context Completion (KGCC) module identifies knowledge gaps in retrieved evidence and generates complementary background documents to fill these gaps. The Knowledge-Aware Document Selection (KADS) module then adaptively selects the most relevant and reliable subset from both retrieved and generated documents. This dual approach enables the framework to leverage both external medical corpora and the parametric knowledge stored in large language models, addressing the limitations of pure retrieval-based or generation-only approaches.

## Key Results
- 12.5% improvement over MedRAG on medical QA benchmarks
- 4.5% gain over MedGENIE across multiple reader architectures
- Demonstrated effectiveness across five different medical QA benchmarks

## Why This Works (Mechanism)
The framework succeeds by addressing the fundamental limitation of retrieval-only approaches: the inability to fill knowledge gaps when relevant information is missing from the corpus. By generating complementary background documents that specifically target identified knowledge gaps, KGCC extends the information available beyond what was originally retrieved. KADS then intelligently selects from both retrieved and generated sources, ensuring that the most relevant and reliable information is used for answering questions. This combination allows the system to leverage both the precision of targeted retrieval and the generative capacity of large language models to create a more complete knowledge base for reasoning.

## Foundational Learning

**Knowledge Gap Identification**: Understanding where retrieved documents lack necessary information for answering questions. Why needed: To target generation efforts effectively rather than generating arbitrary supplementary content. Quick check: Evaluate precision of gap detection against human-annotated knowledge gaps.

**Document Selection Algorithms**: Methods for ranking and selecting relevant documents from mixed retrieved and generated sources. Why needed: To ensure the final context contains the most reliable and pertinent information. Quick check: Measure selection accuracy against ground truth document relevance.

**Generation Augmentation**: Techniques for creating supplementary documents that fill identified knowledge gaps. Why needed: To extend the knowledge base beyond what exists in external corpora. Quick check: Assess generation quality and factual consistency with existing medical knowledge.

## Architecture Onboarding

**Component Map**: Input Question -> KGCC (Retrieval + Gap Analysis + Generation) -> Generated Documents + Retrieved Documents -> KADS (Selection) -> Selected Documents -> Reader -> Answer

**Critical Path**: The most critical path is the KGCC module's ability to accurately identify knowledge gaps and generate appropriate supplementary documents. Errors in gap identification directly propagate to poor generation quality, which cannot be corrected by KADS selection.

**Design Tradeoffs**: The framework trades computational efficiency for improved accuracy by generating additional documents and performing adaptive selection. This increases inference time but provides better coverage of medical knowledge compared to pure retrieval approaches.

**Failure Signatures**: Performance degradation occurs when KGCC generates hallucinated or irrelevant content, or when KADS fails to distinguish between reliable retrieved documents and potentially noisy generated content. The system is particularly vulnerable to knowledge poisoning attacks where malicious information is injected during generation.

**First Experiments**: 1) Ablation study isolating KGCC versus KADS contributions across different reader architectures, 2) Cross-dataset evaluation to test generalizability beyond five reported benchmarks, 3) Adversarial testing with intentionally misleading retrieved documents to evaluate robustness.

## Open Questions the Paper Calls Out
None

## Limitations
- Limited analysis of generation quality and potential hallucination risks in KGCC module
- Absence of statistical significance testing for reported performance improvements
- Unclear generalizability to broader medical domains beyond five tested benchmarks

## Confidence
- Performance claims: Medium (substantial improvements reported but lack statistical validation)
- Framework robustness: Low (no analysis of computational overhead or adversarial resilience)
- Practical deployment readiness: Low (missing latency and efficiency considerations)

## Next Checks
1. Conduct ablation studies isolating the contributions of KGCC versus KADS modules across different reader architectures to quantify their individual impact
2. Perform cross-dataset evaluation to test generalizability beyond the five reported benchmarks
3. Implement adversarial testing with intentionally misleading retrieved documents to evaluate the framework's robustness against knowledge poisoning or unreliable evidence