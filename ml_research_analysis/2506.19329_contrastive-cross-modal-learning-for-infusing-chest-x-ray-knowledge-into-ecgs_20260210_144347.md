---
ver: rpa2
title: Contrastive Cross-Modal Learning for Infusing Chest X-ray Knowledge into ECGs
arxiv_id: '2506.19329'
source_url: https://arxiv.org/abs/2506.19329
tags:
- learning
- contrastive
- cross-modal
- chest
- ecgs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CroMoTEX is a contrastive cross-modal learning framework that transfers
  knowledge from chest X-rays to ECGs to improve ECG-based disease detection. It employs
  supervised contrastive alignment with adaptive hard negative penalization (AHNP)
  to learn task-relevant ECG representations, enabling scalable deployment using ECG
  input alone.
---

# Contrastive Cross-Modal Learning for Infusing Chest X-ray Knowledge into ECGs

## Quick Facts
- **arXiv ID:** 2506.19329
- **Source URL:** https://arxiv.org/abs/2506.19329
- **Reference count:** 13
- **One-line primary result:** CroMoTEX achieves up to 78.31 AUROC on edema detection, outperforming baseline ECG-only models by leveraging CXR knowledge

## Executive Summary
CroMoTEX is a contrastive cross-modal learning framework that transfers diagnostic knowledge from chest X-rays to ECGs, enabling improved disease detection using only ECG input at inference time. The method aligns ECG and CXR representations through supervised contrastive learning with adaptive hard negative penalization, allowing ECG encoders to learn task-relevant features from CXR representations. Evaluated on MIMIC-IV-ECG and MIMIC-CXR datasets for cardiomegaly, pleural effusion, and edema, CroMoTEX demonstrates significant improvements over baseline ECG-only approaches while requiring only ECG data during deployment.

## Method Summary
The method employs a three-phase training strategy: first pre-training a CXR encoder (DenseNet-121) on disease labels, then self-supervised pre-training an ECG encoder with VCG-based augmentations using SimCLR, and finally aligning the two modalities through supervised cross-modal contrastive learning with adaptive hard negative penalization. During inference, only the fine-tuned ECG encoder is used, making the system deployable in settings where CXR data may not be available. The framework introduces LAHNPSupCMA loss that combines within-sample and cross-sample positive pairs with adaptive weighting of hard negative samples based on similarity.

## Key Results
- Achieves AUROC of 75.23 (cardiomegaly), 75.51 (pleural effusion), and 78.31 (edema), outperforming baseline models including direct ECG classification, ECCL, BIOT, and ResNet-1D
- Self-supervised pre-training with VCG augmentations improves performance by 1-2 AUROC points compared to no SSL
- Adaptive hard negative penalization (AHNP) provides 0.5-1.5 AUROC improvement over standard supervised contrastive loss
- UMAP visualizations show improved embedding structure with better class separation compared to baseline models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Supervised cross-modal contrastive alignment enables ECG representations to capture diagnostic knowledge originally only accessible through CXR
- Mechanism: The model uses disease labels to define positive pairs not just within the same sample (ei, xi), but across all samples sharing the same label. This transforms the standard cross-modal alignment (which only aligns paired ECG-CXR samples) into a supervised objective that pulls same-label ECG-CXR embeddings together while pushing apart different-label pairs
- Core assumption: CXR encoders pre-trained on disease labels encode clinically relevant features that can serve as a meaningful supervision signal for ECG representation learning
- Evidence anchors: The abstract mentions "supervised cross-modal contrastive objective with adaptive hard negative weighting" and section 3.1 details the SupCon objective that matches all same-label pairs

### Mechanism 2
- Claim: Adaptive Hard Negative Penalization (AHNP) improves alignment quality by prioritizing gradients from semantically similar but diagnostically different samples
- Mechanism: In standard contrastive loss, all negative pairs contribute equally to the denominator. AHNP weights each negative by its similarity to the anchor—hard negatives (high similarity, different label) receive higher weights via strategies like topk or exp
- Core assumption: Hard negatives exist in the embedding space and their gradients provide more informative supervision for boundary discrimination than easy negatives
- Evidence anchors: Table 2 shows topk strategy achieves best AUROC for cardiomegaly and pleural effusion, while exp strategy is best for edema, demonstrating pathology-specific optimal strategies

### Mechanism 3
- Claim: Self-supervised ECG pre-training provides a foundation of generalizable ECG features that amplifies the effectiveness of subsequent cross-modal alignment
- Mechanism: The ECG encoder is first trained via SimCLR on unlabeled ECGs using VCG-based augmentations (3D spatial transformations derived from inverse Dower's transform)
- Core assumption: VCG-based augmentations create views that preserve diagnostically relevant ECG features while perturbing irrelevant variations
- Evidence anchors: Table 1 shows CroMoTEX(no SSL) drops to 73.08 AUROC on cardiomegaly (vs. 75.23 with SSL) and 77.98 on edema (vs. 78.31), confirming SSL's contribution

## Foundational Learning

- **Concept: Contrastive Learning (InfoNCE Loss)**
  - Why needed here: CroMoTEX builds on InfoNCE to align ECG-CXR pairs. You must understand how the loss numerator (positive pair similarity) and denominator (all pair similarities) create the pull-push dynamic
  - Quick check question: Given three embeddings with similarities [0.9, 0.3, 0.1] where 0.9 is the positive, compute the InfoNCE loss (τ=1.0)

- **Concept: Projection Heads in Contrastive Learning**
  - Why needed here: CroMoTEX uses projection heads (gecg, gcxr) during alignment but discards them at fine-tuning
  - Quick check question: Why does SimCLR discard the projection head after pre-training? If you answer "to reduce parameters," re-read the SimCLR paper's ablation on projection heads

- **Concept: Cross-Modal Representation Alignment**
  - Why needed here: The core innovation is aligning two modalities (ECG, CXR) into a shared space
  - Quick check question: In CLIP, why is the loss computed symmetrically (image→text and text→image)?

## Architecture Onboarding

- **Component map:**
  - ECG input [12, 1000] → fecg (2×1D-Conv + Transformer) → gecg (projection head) → shared space
  - CXR input [224, 224] → fcxr (DenseNet-121, frozen) → gcxr (projection head) → shared space
  - Shared space → fine-tune fecg with classification head for disease labels

- **Critical path:**
  1. Pre-train fcxr on disease labels (cross-entropy, CXR-only data)
  2. Pre-train fecg via SimCLR with VCG augmentations (ECG-only data)
  3. Freeze fcxr, train fecg + projection heads with LAHNPSupCMA loss on paired ECG-CXR data
  4. Discard projection heads, fine-tune fecg on disease labels (ECG-only)

- **Design tradeoffs:**
  - **AHNP strategy:** topk is best for well-separated pathologies (cardiomegaly); exp may help for subtle conditions (edema). Default to topk with k=7.5%, α=4.5, but validate per pathology
  - **Freezing fcxr:** Paper reports that unfreezing degrades performance (the CXR encoder overfits to the smaller paired dataset). Always freeze
  - **Within-sample weight (β):** Higher β prioritizes paired ECG-CXR samples over same-label cross-sample pairs. β=2 is a middle ground; increase β if label noise is suspected

- **Failure signatures:**
  - **Collapse:** If all ECG embeddings converge to a single point, check batch size (need ≥256) and temperature (τ=0.01 is low; try τ=0.05 if collapse occurs)
  - **No improvement over baseline:** Verify paired dataset quality—if many ECG-CXR pairs are from different clinical encounters, the alignment signal may be noisy
  - **Overfitting to CXR artifacts:** If UMAP shows separation but AUROC is low, fcxr may encode non-pathological features. Inspect fcxr's attention maps

- **First 3 experiments:**
  1. **Reproduce baseline:** Train fecg end-to-end on disease labels (no CXR, no SSL). Target: ~70-73 AUROC. If significantly lower, check data preprocessing (baseline wander removal, normalization)
  2. **Validate SSL contribution:** Pre-train fecg with SimCLR (VCG augmentations), then fine-tune. Expect 1-2 AUROC gain over baseline. If none, check augmentations (visualize augmented ECGs)
  3. **Test AHNP ablation:** Run cross-modal alignment with standard SupCon loss (no AHNP), then with topk AHNP. Expect 0.5-1.5 AUROC improvement. If degradation, verify hard negative detection (print top-k negative similarities)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the substantial performance gap between ECG-only classification and direct CXR-based classification be bridged?
- Basis in paper: The authors state: "despite these advances, we observe a significant performance gap between our cross-modal transfer model and direct CXR-based classification... Bridging this gap through enhanced alignment strategies... remains a promising direction"
- Why unresolved: The current transfer learning framework significantly outperforms baselines but still falls short of the gold-standard imaging modality's performance (e.g., 78.31 vs 93.62 AUROC for Edema)
- What evidence would resolve it: A modification to the alignment objective or architecture that enables ECG-only inference to achieve AUROC scores statistically comparable to CXR classifiers

### Open Question 2
- Question: Can a unified Adaptive Hard Negative Penalization (AHNP) strategy be developed that performs optimally across diverse pathologies without manual tuning?
- Basis in paper: The results in Table 2 show different AHNP strategies (topk vs exp) succeed for different pathologies, and the text notes "the optimal AHNP strategy may vary by pathology"
- Why unresolved: The current framework requires selecting specific weighting functions and hyperparameters depending on the target disease, limiting generalizability
- What evidence would resolve it: A single, adaptive weighting function that consistently matches or exceeds the performance of the current best pathology-specific configurations across all tested conditions

### Open Question 3
- Question: Does CroMoTEX's cross-modal transfer mechanism generalize to pathologies that are not visually prominent in chest X-rays?
- Basis in paper: The study focuses on Cardiomegaly, Pleural Effusion, and Edema, explicitly noting these are "visually prominent on CXRs," leaving the transfer efficacy for non-visual or functional conditions unstated
- Why unresolved: It is unclear if the knowledge transfer relies on the spatial visual correlation present in the selected pathologies or if it is robust to more abstract diagnostic cues
- What evidence would resolve it: Evaluation of the framework on conditions where X-rays provide limited diagnostic value (e.g., purely electrical abnormalities like arrhythmias) to see if CXR knowledge still improves ECG detection

## Limitations

- The method requires paired ECG-CXR data during training, limiting applicability when such aligned data is scarce
- Performance still lags behind direct CXR-based classification, indicating the knowledge transfer bridges but doesn't close the modality gap
- The optimal AHNP strategy appears pathology-dependent, requiring manual tuning rather than a unified approach

## Confidence

- **High confidence**: The experimental methodology and ablation studies demonstrating SSL and AHNP contributions are rigorous and well-supported by results
- **Medium confidence**: The core mechanism of cross-modal alignment is sound, but the optimal AHNP configuration requires further validation across diverse pathologies
- **Medium confidence**: The claim that this enables scalable deployment using ECG input alone is technically correct but oversells the clinical advantage given CXR still outperforms ECG

## Next Checks

1. Validate whether AHNP's pathology-dependent optimal strategy (topk vs exp) generalizes to other cardiac conditions beyond the three studied
2. Conduct a systematic ablation study on projection head architecture to confirm its necessity and optimal design
3. Test the model's performance on truly unpaired ECG-CXR data to verify it can leverage the CXR knowledge without requiring exact patient matches