---
ver: rpa2
title: Capturing Symmetry and Antisymmetry in Language Models through Symmetry-Aware
  Training Objectives
arxiv_id: '2504.16312'
source_url: https://arxiv.org/abs/2504.16312
tags:
- language
- label
- relations
- retraining
- k-nn
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of improving large language
  models' understanding of symmetric and antisymmetric relations, which is critical
  for tasks like relation extraction and natural language inference. The authors introduce
  a novel Wikidata-derived dataset for evaluating models on symmetric and antisymmetric
  relations and demonstrate that standard LLMs perform only at chance level on this
  benchmark.
---

# Capturing Symmetry and Antisymmetry in Language Models through Symmetry-Aware Training Objectives

## Quick Facts
- arXiv ID: 2504.16312
- Source URL: https://arxiv.org/abs/2504.16312
- Reference count: 6
- Standard LLMs achieve only chance-level accuracy on symmetric/antisymmetric relation tasks

## Executive Summary
This study addresses the challenge of improving large language models' understanding of symmetric and antisymmetric relations, which is critical for tasks like relation extraction and natural language inference. The authors introduce a novel Wikidata-derived dataset for evaluating models on symmetric and antisymmetric relations and demonstrate that standard LLMs perform only at chance level on this benchmark. To address this gap, they propose retraining encoder models using contrastive learning with k-nearest neighbors (k-NN), incorporating symmetry-aware objectives. This approach achieves 100% accuracy on both lexicalized and delexicalized versions of the dataset, matching fine-tuned classification heads while requiring fewer training samples. Additionally, it shows better mitigation of catastrophic forgetting (up to 5.4% improvement) and greater efficiency in few-shot learning scenarios.

## Method Summary
The paper proposes retraining encoder models using contrastive learning with k-NN and symmetry-aware objectives to capture symmetric and antisymmetric relations. The method converts Wikidata triples to NLI format and trains encoders to distinguish symmetric (entailment) from antisymmetric (contradiction) relations using a rotation-based distance metric derived from RotatE. Three variants are explored: Random Label Embeddings, k-NN with fixed distance, and k-NN with learned distance. The approach requires fewer training samples than fine-tuning and better preserves prior knowledge while achieving 100% accuracy on both lexicalized and delexicalized test sets.

## Key Results
- Standard LLMs achieve only ~50% accuracy on symmetric/antisymmetric relation classification, confirming the problem exists
- Proposed method achieves 100% accuracy on both lexicalized and delexicalized versions of the benchmark
- k-NN approach requires only 64 training samples versus 336 for fine-tuning to reach target accuracy
- Symmetry-aware training reduces catastrophic forgetting by up to 5.4% compared to standard fine-tuning

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Standard distance metrics cannot distinguish symmetric from antisymmetric relations because they are inherently symmetric themselves: d(p,h) = d(h,p).
- **Mechanism:** The paper introduces a rotation-based distance function derived from RotatE: d_l(p,h) = 1 - sim(h, (p ◦ l)). The label embedding l encodes relation directionality—for symmetric relations, l ≈ l⁻¹ (inverse rotation approximates identity); for antisymmetric, l ≠ l⁻¹. This breaks the symmetry of the distance function itself.
- **Core assumption:** Relations can be represented as geometric transformations (rotations) in embedding space where symmetry properties emerge from group-theoretic structure.
- **Evidence anchors:**
  - [abstract]: "retraining only the encoder using symmetry-aware objectives via contrastive learning"
  - [section 2.2]: "Standard distance functions such as dot products and cosine similarity are not symmetry-aware (i.e., d(p, h) = d(h, p)). To address this, we propose a symmetry-aware distance metric function derived from the RotatE model"
  - [corpus]: Related work on symmetry-aware architectures exists (e.g., "Symmetry-Aware Transformer Training," "Partial Symmetry Enforced Attention Decomposition"), but direct evidence for this specific rotation-based mechanism in language models is limited to this paper.
- **Break condition:** If label embeddings cannot be structured such that l ≈ l⁻¹ for symmetric relations and l ≠ l⁻¹ for antisymmetric ones, the geometric decomposition fails.

### Mechanism 2
- **Claim:** k-NN with contrastive learning requires fewer training samples than fine-tuning because it leverages implicit clustering rather than learning explicit classification boundaries.
- **Mechanism:** During training, label embeddings are computed as l = h ⊘ p. The contrastive objective (Eq. 5) pulls same-label embeddings together and pushes different-label embeddings apart with a margin. At inference, the model retrieves the k-nearest training embeddings and majority-votes. No fixed output layer is required—new labels can be added by storing new training embeddings.
- **Core assumption:** The symmetry-aware distance metric induces a simple clustering structure in embedding space where k-NN generalizes from few examples.
- **Evidence anchors:**
  - [abstract]: "requiring fewer training samples than fine-tuning"
  - [section 2.3]: "This flexibility is particularly beneficial for tasks like fact-checking, where claims can be ambiguous"
  - [table 2]: k-NN requires 64 samples vs. 336 for fine-tuning to reach 100% accuracy
  - [corpus]: No direct corpus support for this specific k-NN contrastive mechanism in relational learning.
- **Break condition:** If relations require complex non-convex decision boundaries, k-NN may need many more samples or fail to generalize.

### Mechanism 3
- **Claim:** Encoder-only retraining with a fixed distance metric preserves more prior knowledge than adding classification heads because parameter changes are more constrained.
- **Mechanism:** The fixed distance metric (Eq. 4) reduces what the encoder must learn—it only needs to produce embeddings where the symmetry-aware distance separates classes. Less parameter movement → less interference with pre-trained representations. The method acts as an implicit regularizer.
- **Core assumption:** Pre-trained encoders already contain useful relational structure; the symmetry-aware objective fine-tunes rather than overwrites.
- **Evidence anchors:**
  - [abstract]: "reducing catastrophic forgetting by up to 5.4%"
  - [section 3.2]: "methods with a fixed symmetry-aware distance metric showed better knowledge retention, likely due to the reduced need for extensive retraining"
  - [table 2]: Random Label Embeddings: 5.8% forgetting; Fine-Tuning: 11.2% forgetting
  - [corpus]: Indirect support from equivariance literature (e.g., "Flopping for FLOPs"), but no direct replication of the forgetting result.
- **Break condition:** If target relations are highly dissimilar from pre-training distribution, large parameter updates may still cause severe forgetting.

## Foundational Learning

- **Concept: Natural Language Inference (NLI) framing**
  - Why needed here: The paper casts symmetric/antisymmetric relations as entailment/contradiction tasks. Understanding NLI structure (premise → hypothesis) is essential to grasp the task definition.
  - Quick check question: If "A borders B" is the premise and "B borders A" is the hypothesis, what label should a symmetric relation receive? What about an antisymmetric relation like "A is parent of B"?

- **Concept: Contrastive learning with margin**
  - Why needed here: All retraining methods use contrastive objectives (Eqs. 3 and 5) with margin-based separation. You must understand why margins prevent trivial solutions.
  - Quick check question: In the objective d⁺² + max(0, (margin - d⁻))², what happens to the loss when d⁻ (distance between different labels) exceeds the margin? Why is this desirable?

- **Concept: k-Nearest Neighbors for classification**
  - Why needed here: Inference relies on k-NN retrieval and majority voting over stored training embeddings. This replaces the need for a classification head.
  - Quick check question: With k=3, if the nearest training samples have labels [Entailment, Contradiction, Entailment], what is the predicted label? Why might k=3 outperform k=1?

## Architecture Onboarding

- **Component map:**
  - Base encoder (RoBERTa-Large or MiniLM) -> Label embedding computation (l = h ⊘ p) -> Symmetry-aware distance metric (d_l(p,h) = 1 - sim(h, (p ◦ l))) -> k-NN index (stores training label embeddings) -> Majority vote (k=3)

- **Critical path:**
  1. Convert Wikidata triples to NLI format (premise/hypothesis pairs with Entailment/Contradiction labels)
  2. Encode premise p and hypothesis h through encoder (separately)
  3. Compute label embedding: l = h ⊘ p (or retrieve random label embedding)
  4. Apply contrastive loss with margin=0.5, LR=2e-5
  5. At inference: compute test label embedding, retrieve k=3 nearest training embeddings, majority vote

- **Design tradeoffs:**
  - **Random Label Embeddings vs. k-NN**: Random labels = 48 samples, 5.8% forgetting; k-NN = 64 samples, 7.7% forgetting, but supports flexible label addition
  - **Fixed vs. Learned Distance Metric**: Fixed = 64 samples, 7.7% forgetting; Learned = 400 samples, 21.5% forgetting (overfitting risk)
  - **Encoder-only vs. Fine-tuning**: Encoder-only preserves prior knowledge; Fine-tuning requires classification head and causes 11.2% forgetting

- **Failure signatures:**
  - **Near-chance accuracy (~50%)**: Indicates encoder hasn't learned symmetry distinction (baseline LLMs in Table 2)
  - **Catastrophic forgetting >15%**: Suggests too many samples or learned distance metric overfitting (see "k-NN with Learnt Distance Metric" at 21.5%)
  - **Large lexicalized/delexicalized gap**: Would indicate entity-specific learning; both should be ~100% if mechanism generalizes

- **First 3 experiments:**
  1. **Baseline probe**: Evaluate RoBERTa-Large and RoBERTa-Large-MNLI on Wikidata NLI task without retraining. Confirm ~50% accuracy to validate the problem.
  2. **Random Label Embeddings retraining**: Train with 48 samples, margin=0.5, LR=2e-5. Measure test accuracy and MNLI forgetting. Expect 100% accuracy, ~5-6% forgetting.
  3. **k-NN ablation**: Train with 64 samples, k=3. Compare sample efficiency and forgetting to Random Label Embeddings and Fine-Tuning baselines. Verify flexibility by adding a new relation without retraining.

## Open Questions the Paper Calls Out
None

## Limitations
- Generalizability beyond Wikidata NLI domain is uncertain; real-world applications may involve more complex or nuanced relational structures
- Geometric interpretation using RotatE-style rotations assumes clean separation between symmetric and antisymmetric relations, which may not hold for relations with mixed symmetry properties
- Claims about few-shot learning efficiency relative to the broader literature remain unclear without direct comparison to modern few-shot methods

## Confidence
**High confidence**: Experimental results showing 100% accuracy and clear advantages over fine-tuning baselines are well-supported by reported data.
**Medium confidence**: Catastrophic forgetting results are promising but may be specific to MNLI dataset used for measurement.
**Low confidence**: Few-shot learning efficiency claims lack direct comparison with other modern few-shot learning techniques.

## Next Checks
1. **Cross-domain generalization test**: Apply the k-NN contrastive learning approach to a different relational reasoning dataset (e.g., natural language inference benchmarks with diverse relation types) to verify that the symmetry-aware mechanism generalizes beyond Wikidata-derived examples.

2. **Ablation on distance metric components**: Systematically remove or modify the symmetry-aware components of the distance metric (e.g., test with standard cosine similarity) while keeping the k-NN framework intact to isolate the contribution of the geometric transformation mechanism.

3. **Comparison with modern few-shot methods**: Benchmark the proposed approach against recent few-shot learning techniques for relation extraction (e.g., meta-learning methods, prompt-based approaches) using identical few-shot protocols to establish relative efficiency gains.