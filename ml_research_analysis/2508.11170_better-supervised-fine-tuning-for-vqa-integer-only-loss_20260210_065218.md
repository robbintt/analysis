---
ver: rpa2
title: 'Better Supervised Fine-tuning for VQA: Integer-Only Loss'
arxiv_id: '2508.11170'
source_url: https://arxiv.org/abs/2508.11170
tags:
- video
- quality
- assessment
- evaluation
- visual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of improving video quality assessment
  (VQA) using vision language models (VLMs). The proposed method, IOVQA (Integer-Only
  VQA), introduces a novel fine-tuning approach that converts decimal Mean Opinion
  Scores (MOS) into integer labels and employs an integer-only mask during loss computation.
---

# Better Supervised Fine-tuning for VQA: Integer-Only Loss

## Quick Facts
- **arXiv ID**: 2508.11170
- **Source URL**: https://arxiv.org/abs/2508.11170
- **Reference count**: 35
- **Primary result**: 3rd place in VQualA 2025 GenAI-Bench AIGC Video Quality Assessment Challenge with 0.70 final score (average of SRCC and PLCC)

## Executive Summary
This paper introduces IOVQA, an integer-only fine-tuning approach for video quality assessment using vision language models. The method converts decimal Mean Opinion Scores (MOS) to integer labels and employs an integer-only mask during loss computation, leveraging VLMs' inherent strength in predicting integer values. By combining this approach with prompt engineering and structural output constraints, IOVQA achieves significant performance improvements on the TaobaoVD-GC dataset, ranking 3rd in the VQualA 2025 challenge with a final score of 0.70.

## Method Summary
IOVQA fine-tunes Qwen2.5-VL with LoRA to predict video quality scores as integers in the range [10,50]. The method converts decimal MOS scores to integers by rounding to one decimal place and multiplying by 10, then applies an integer-only mask during loss computation to focus learning on the numerical score tokens. The approach uses 1-2 sampled frames per video, constrained output format, and temperature=0 for deterministic generation. Experimental results show integer labels and integer-only masking improve SRCC/PLCC metrics compared to decimal-label baselines.

## Key Results
- Achieved 3rd place in VQualA 2025 GenAI-Bench AIGC Video Quality Assessment Challenge with 0.70 final score
- Integer labels (0.63) outperformed decimal labels (0.60) in ablation studies
- Integer-only mask further improved performance to 0.64
- 7B model outperformed larger 32B and 72B models (0.642 vs 0.640 and 0.622), suggesting dataset size limits larger model utility

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Integer labels improve VLM prediction accuracy and training stability compared to decimal labels.
- **Mechanism:** Auto-regressive models predict tokens sequentially. Decimal scores require more tokens (e.g., "3.5" needs three tokens) than integers (e.g., "35" needs two), extending the prediction chain and amplifying cumulative errors.
- **Core assumption:** Tokenization overhead of decimal points meaningfully degrades score prediction quality.
- **Evidence anchors:** Abstract states VLMs have "inherent strength in predicting integer values over decimals"; related papers focus on domain applications rather than label format optimization.

### Mechanism 2
- **Claim:** Integer-only masking during loss computation focuses model learning on critical numerical components.
- **Mechanism:** Masks all non-integer portions of the response during cross-entropy loss computation, forcing the model to allocate representational capacity to evaluation-relevant tokens.
- **Core assumption:** Gradient signal from integer-only loss is sufficient to drive meaningful improvements.
- **Evidence anchors:** Ablation shows integer labels (0.63) outperform decimal labels (0.60), and adding integer-only mask further improves to 0.64.

### Mechanism 3
- **Claim:** Constraining output range to [10,50] integers and eliminating explanatory text improves evaluation consistency.
- **Mechanism:** Enforces single numerical output without free-text explanations using temperature=0 for deterministic argmax selection, eliminating variance from stochastic sampling.
- **Core assumption:** Suppressing rationale generation does not degrade score quality.
- **Evidence anchors:** Authors state constraint "ensures consistency in evaluation results, making it comparable across different videos."

## Foundational Learning

- **Concept: Auto-regressive token prediction and cumulative error**
  - **Why needed here:** Understanding why integers outperform decimals requires grasping how LLMs generate text token-by-token with compounding uncertainty.
  - **Quick check question:** Can you explain why predicting "3.5" as three sequential tokens might yield different error characteristics than predicting "35" as two tokens?

- **Concept: Loss masking in supervised fine-tuning**
  - **Why needed here:** The integer-only mask strategy relies on selectively computing gradients on target tokens while ignoring prompt and padding tokens.
  - **Quick check question:** Given a sequence [prompt_tokens, score_tokens, padding], which token positions should receive non-zero loss gradients in this approach?

- **Concept: Mean Opinion Score (MOS) and quality assessment metrics**
  - **Why needed here:** The task involves predicting human subjective quality scores, understanding how MOS is aggregated from multiple raters and scaled is critical for label preprocessing.
  - **Quick check question:** Why might averaging 15 human ratings and then rounding to integers still produce a valid training target?

## Architecture Onboarding

- **Component map:** Video Input → Frame Sampling (1-2 frames) → Prompt Engineering → Qwen2.5-VL (ViT encoder + MLP merger + LLM backbone) → Integer Output [10-50] → Integer-Only Masked Cross-Entropy Loss

- **Critical path:**
  1. Label preprocessing: Round MOS to 1 decimal, multiply by 10, clamp to [10,50] integer range
  2. Loss masking: Identify integer token positions in label, mask all other positions during cross-entropy computation
  3. LoRA fine-tuning: Apply low-rank adaptation to Qwen2.5-VL with rank=128 for 7B model, epochs=2-3 optimal

- **Design tradeoffs:**
  - Integer vs decimal precision: Integer labels sacrifice sub-point granularity but reduce token prediction error; ablation confirms net benefit (+0.04 final score)
  - Model scale vs overfitting risk: 32B and 72B models underperformed 7B (0.640, 0.622 vs 0.642) on 4000-sample training set
  - Frame count vs efficiency: 1-2 frames capture core visual content for static/minimal-motion videos

- **Failure signatures:**
  - Larger models (32B, 72B) showing degraded performance relative to 7B despite same LoRA rank
  - Overfitting indicated by optimal epochs being earlier for larger models (epoch 5 for 72B vs epoch 3 for 7B r=128)
  - Score collapse to narrow range if label distribution is not properly scaled

- **First 3 experiments:**
  1. Baseline comparison: Fine-tune Qwen2.5-VL-7B with decimal labels vs integer labels vs integer labels + integer-only mask to isolate each component's contribution
  2. Model scale ablation: Train 7B, 32B, 72B variants with identical LoRA settings (r=128) and compare validation PLCC/SRCC
  3. Frame sampling sensitivity: Evaluate single-frame vs dual-frame input on videos with varying motion levels

## Open Questions the Paper Calls Out

- **Open Question 1:** Would increasing training data quantity or diversity enable larger VLMs (32B, 72B) to outperform the 7B model in video quality assessment tasks?
- **Open Question 2:** Does sampling more video frames per clip (beyond 1-2) improve temporal quality assessment performance?
- **Open Question 3:** How sensitive is IOVQA's performance to the choice of integer range [10,50] versus alternative ranges?
- **Open Question 4:** Does IOVQA generalize to other video quality assessment benchmarks beyond TaobaoVD-GC?

## Limitations
- Method evaluated exclusively on TaobaoVD-GC dataset (5000 short-form AIGC videos), limiting generalization claims
- Integer label approach may discard meaningful sub-point distinctions in human ratings with high variance
- Architecture-specific optimization may not transfer to encoder-only or decoder-only models
- Ablation studies lack testing of alternative approaches like softmax regression over integer scores

## Confidence
- **High Confidence:** Core empirical finding that integer labels + integer-only masking improves correlation metrics on TaobaoVD-GC dataset
- **Medium Confidence:** Theoretical mechanism that auto-regressive models inherently predict integers more accurately than decimals
- **Low Confidence:** Claim that integer-only masking meaningfully improves results beyond integer labels alone (only +0.01 improvement observed)

## Next Checks
- **Validation Check 1:** Evaluate the fine-tuned model on at least one other VQA dataset (e.g., LIVE, CSIQ, or KonIQ) to test cross-dataset generalization
- **Validation Check 2:** Conduct controlled experiment varying integer precision (round MOS to nearest 0.5 vs 1.0) and measure impact on SRCC/PLCC
- **Validation Check 3:** Implement same integer-only fine-tuning approach on a different VLM architecture (e.g., LLaVA-1.5 or GPT-4V) and compare performance to Qwen2.5-VL results