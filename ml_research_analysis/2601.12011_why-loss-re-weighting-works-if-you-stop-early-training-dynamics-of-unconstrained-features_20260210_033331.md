---
ver: rpa2
title: 'Why Loss Re-weighting Works If You Stop Early: Training Dynamics of Unconstrained
  Features'
arxiv_id: '2601.12011'
source_url: https://arxiv.org/abs/2601.12011
tags:
- learning
- loss
- training
- matrix
- reweighting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a small-scale model (SSM) to transparently
  analyze the early-training benefits of loss reweighting in imbalanced classification.
  The SSM abstracts the complexities of deep neural networks and high-dimensional
  data, using a bilinear model with squared loss to reveal how vanilla empirical risk
  minimization (ERM) preferentially learns majority class features over minority ones.
---

# Why Loss Re-weighting Works If You Stop Early: Training Dynamics of Unconstrained Features

## Quick Facts
- arXiv ID: 2601.12011
- Source URL: https://arxiv.org/abs/2601.12011
- Authors: Yize Zhao; Christos Thrampoulidis
- Reference count: 40
- One-line primary result: Reweighting equalizes learning rates across features early in training, but benefits vanish at convergence in overparameterized models.

## Executive Summary
This paper introduces a Small-Scale Model (SSM) to transparently analyze the early-training benefits of loss reweighting in imbalanced classification. The SSM abstracts the complexities of deep neural networks and high-dimensional data, using a bilinear model with squared loss to reveal how vanilla empirical risk minimization (ERM) preferentially learns majority class features over minority ones. The key finding is that reweighting equalizes the learning rates of all features by effectively flattening the spectrum of the label matrix, enabling simultaneous learning of majority and minority class distinctions. Theoretical analysis shows that reweighting compresses the effective learning window, independent of the imbalance ratio, contrasting with vanilla ERM where the window grows unboundedly with imbalance. This explains why reweighting benefits minority classes early in training, even though it has no effect in the terminal phase of overparameterized models.

## Method Summary
The paper uses a Small-Scale Model (SSM) - an Unconstrained Features Model (UFM) - to analyze training dynamics. This replaces a complex DNN with a bilinear model $L = WH$, where $W$ are classifiers and $H$ are trainable embeddings. The model uses simplex-encoded labels $Z$ and weighted squared loss. Gradient flow dynamics are analyzed to derive closed-form solutions for how features are learned over time. Reweighting introduces an effective weight matrix $\Lambda$ that flattens the skewed spectrum of the label matrix, converting staged learning into simultaneous learning. The analysis is validated on both synthetic data with the SSM and a 3-layer CNN on imbalanced MNIST.

## Key Results
- Reweighting effectively flattens the spectral components of the label matrix, eliminating the preferential learning order where majority features are learned before minority ones.
- The time gap between learning majority and minority features scales with $\sqrt{R}-1$ in vanilla ERM but is compressed to a constant $\sqrt{2}-1$ with reweighting, independent of imbalance ratio $R$.
- In overparameterized settings ($d \ge k$), both vanilla and reweighted loss converge to the same global minima, meaning reweighting only alters the training path, not the terminal phase.

## Why This Works (Mechanism)

### Mechanism 1: Spectral Flattening via Effective Weights
Loss reweighting flattens the skewed spectrum of the label matrix, converting a staged learning process into a simultaneous one. In vanilla ERM, singular values corresponding to majority features are $\approx \sqrt{R}$ times larger than minority features, causing faster learning rates for majorities. Reweighting introduces an effective weight matrix $\Lambda$ (diagonal entries $\lambda_i$) that counteracts this spectral decay. By setting weights inversely proportional to the square root of class frequency ($\omega \propto 1/\sqrt{\hat{\pi}}$), the product of singular values and effective weights ($\sigma_i \lambda_i$) becomes roughly uniform across features.

### Mechanism 2: Compression of the Learning Window
Reweighting bounds the effective learning window independent of the imbalance ratio $R$. In vanilla ERM, the time gap between learning majority and minority features scales with $\sqrt{R}-1$, creating a severe delay for high imbalance. Theoretical analysis shows reweighting compresses this window $\Delta T$ to a value bounded by $\sqrt{2}-1$ (Eq. 15). This makes the learning time for minority features independent of the number of majority samples.

### Mechanism 3: Early Stopping Requirement
The benefits of reweighting are transient and vanish at convergence. Theoretical analysis confirms "Terminal Phase Equivalence." In overparameterized settings ($d \ge k$), both vanilla and reweighted loss converge to the same global minima where the logits perfectly interpolate the label matrix. Reweighting alters the path (dynamics), not the destination (convergence point).

## Foundational Learning

- **Concept: Unconstrained Features Model (UFM)**
  - Why needed here: This is the core abstraction (SSM) used to make the math tractable. It replaces complex DNN embeddings with trainable vectors, isolating the effect of the loss function.
  - Quick check question: Can you explain why assuming embeddings are "unconstrained" allows us to ignore the network architecture $\theta$ in the analysis?

- **Concept: Singular Value Decomposition (SVD) of Label Matrices**
  - Why needed here: The paper maps semantic features (majority-majority distinction, etc.) directly to the singular values and vectors of the label matrix. Understanding this mapping is key to understanding the "preferential learning order."
  - Quick check question: What does the magnitude of a singular value in the centered label matrix $Z$ represent regarding class imbalance?

- **Concept: Gradient Flow Dynamics**
  - Why needed here: The paper derives closed-form solutions for training over time using continuous gradient flow. You need to interpret the sigmoid curves ($a_i(t)$) to understand *when* features are learned.
  - Quick check question: In the derived dynamics, how does the singular value $\sigma_i$ affect the time $T_i$ required to learn a feature?

## Architecture Onboarding

- **Component map:**
  - Inputs: One-hot labels $Y$, transformed into Simplex-Encoded Label (SEL) matrix $Z$.
  - Core Model: Bilinear model $L = WH$ (SSM), replacing the DNN. $W$ are classifiers, $H$ are trainable embeddings.
  - Loss: Weighted Squared Loss $\|Z - WH\|_{\Omega}$ (proxy for Cross-Entropy).
  - Optimizer: Gradient Descent (analyzed as Gradient Flow).

- **Critical path:**
  1. Initialize $W, H$ with small scale $e^{-\delta}$.
  2. Calculate SVD of SEL matrix $Z = U\Sigma V^\top$ to identify majority/minority features.
  3. Compute reweighting matrix $\Omega$ (inversely proportional to square root of frequency).
  4. Run gradient flow and observe the evolution of singular values of the Logit matrix $L_t$ relative to $Z$.

- **Design tradeoffs:**
  - **Squared Loss vs. Cross-Entropy:** The paper uses squared loss for theoretical tractability (exact sigmoid dynamics). Assumption: This approximates CE behavior early in training.
  - **SSM vs. Real DNN:** The model ignores data geometry and architecture constraints. It explains "if" reweighting works, but may not capture "how" features interact in deep layers.

- **Failure signatures:**
  - **Vanishing Benefit:** If validation accuracy keeps rising to convergence, reweighting benefits will fade.
  - **Wrong $\gamma$: The paper suggests $\gamma=0.5$ ($\omega \propto 1/\sqrt{\hat{\pi}}$) specifically to flatten the spectrum. Using inverse frequency ($\gamma=1$) might over-amplify noise or fail to balance the spectral rates correctly in this theoretical framework.

- **First 3 experiments:**
  1. **Replicate MNIST Staged Learning:** Train the CNN on imbalanced MNIST (R=10) with vanilla ERM. Plot confusion matrices to verify the "Majority-Majority $\to$ Majority-Minority $\to$ Minority-Minority" progression (Fig 1, bottom).
  2. **Verify Spectral Flattening:** Train the SSM (linear model) on synthetic STEP-imbalanced data. Plot the singular values of $L_t$ over time for both vanilla and reweighted loss to verify if they converge simultaneously (Fig 2d vs 2e).
  3. **Measure $\Delta T$:** Vary the imbalance ratio $R$ (e.g., 10, 50, 100). Measure the time steps required to reach 90% accuracy on minority classes for both methods. Verify that vanilla scales with $\sqrt{R}$ while reweighted remains roughly constant.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the theoretical derivation of training dynamics and spectral flattening be extended to the cross-entropy (CE) loss function?
- Basis in paper: Section V explicitly lists "extending the analysis beyond squared loss" as a goal for future work.
- Why unresolved: The paper relies on squared loss to establish linear gradient dynamics (Eq. 2) and closed-form solutions; CE loss introduces non-linearity that prevents direct application of the current theorems.
- What evidence would resolve it: A derivation of gradient flow dynamics for CE loss that shows a similar "flattening" of the effective label spectrum, or empirical proof that the SSM predictions hold qualitatively under CE loss.

### Open Question 2
- Question: How do the observed training dynamics and the compressed learning window ($\Delta T$) specifically impact test-time generalization and optimal early-stopping criteria?
- Basis in paper: Section V identifies extending the analysis to "test-time dynamics" as a limitation to be addressed in future work.
- Why unresolved: The paper models the convergence of training logits to the label matrix but does not theoretically characterize the generalization error or the optimal stopping point relative to the learning window $\Delta T$.
- What evidence would resolve it: A theoretical mapping between the SSM's learning time $T_i$ and the epoch at which test accuracy peaks for minority classes, validated on standard deep networks.

### Open Question 3
- Question: Does the "spectral flattening" effect depend strictly on the specific square-root weighting scheme ($\omega \propto 1/\sqrt{\hat{\pi}}$) used in the analysis, or does it generalize to standard inverse-frequency weighting?
- Basis in paper: Theorem IV.1 and Eq. (5) define specific weights to create the effective diagonal matrix $\Lambda$ that flattens the spectrum; the paper notes standard practice uses inverse frequency ($\omega \propto 1/\hat{\pi}$), but fixes $\gamma=0.5$ for the proof.
- Why unresolved: The mathematical cancellation that produces the flattened spectrum (Eq. 27) relies on the specific algebraic form of the chosen weights; it is unproven if this holds for $\gamma=1$.
- What evidence would resolve it: An ablation study within the SSM or a theoretical extension deriving the effective learning window $\Delta T$ for general weighting exponents $\gamma$.

## Limitations

- The Unconstrained Features Model (UFM) abstracts away complex data geometry and network architecture, limiting generalizability to real-world DNNs where feature interactions are constrained.
- The use of squared loss instead of cross-entropy, while theoretically convenient, requires empirical validation to confirm equivalent early-training dynamics.
- The gradient flow approximation assumes vanishing initialization and continuous updates, which may not fully capture discrete optimization in practice.

## Confidence

- **High Confidence:** The mechanism of spectral flattening via reweighting (Mechanism 1) is well-supported by both theoretical analysis and numerical experiments. The closed-form solutions for learning dynamics provide strong evidence.
- **Medium Confidence:** The compression of the learning window (Mechanism 2) is theoretically sound, but the practical relevance depends on whether real DNNs exhibit similar sigmoid-like learning trajectories and whether early stopping is actually employed.
- **Low Confidence:** The transient nature of reweighting benefits (Mechanism 3) is theoretically proven but may not fully capture the complexity of real-world imbalanced datasets where class distributions and feature correlations are more nuanced.

## Next Checks

1. **Cross-Loss Function Validation:** Test whether spectral flattening and learning window compression also occur with cross-entropy loss on the SSM. This validates the squared loss approximation.
2. **Constrained Feature Model Extension:** Implement a constrained version of the UFM (e.g., bounded embeddings or limited feature dimensions) to test the robustness of the findings when the UFM assumptions are relaxed.
3. **Real-World Dataset Experiment:** Apply the analysis to a real-world imbalanced dataset (e.g., CIFAR-100-LT or long-tailed ImageNet) using a standard CNN architecture. Compare the learning dynamics and convergence behavior with the SSM predictions.