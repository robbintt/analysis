---
ver: rpa2
title: 'ReCoVeR the Target Language: Language Steering without Sacrificing Task Performance'
arxiv_id: '2509.14814'
source_url: https://arxiv.org/abs/2509.14814
tags:
- language
- recover
- steering
- vectors
- representations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ReCoVeR is a lightweight approach to reduce language confusion
  in multilingual LLMs by steering hidden representations with language-specific vectors.
  It computes language representations from multi-parallel data and uses them for
  unsupervised or learned steering at inference time.
---

# ReCoVeR the Target Language: Language Steering without Sacrificing Task Performance

## Quick Facts
- arXiv ID: 2509.14814
- Source URL: https://arxiv.org/abs/2509.14814
- Reference count: 16
- Reduces language confusion in multilingual LLMs while preserving or improving task performance

## Executive Summary
ReCoVeR is a lightweight approach to reduce language confusion in multilingual LLMs by steering hidden representations with language-specific vectors. It computes language representations from multi-parallel data and uses them for unsupervised or learned steering at inference time. Unlike prior methods, it does not rely on a dominant language, supports easy addition of new languages, and retains or improves task performance. Evaluated on three benchmarks across 18 languages, ReCoVeR substantially reduces language confusion in both monolingual and cross-lingual setups without harming answer accuracy.

## Method Summary
ReCoVeR extracts language-specific steering vectors from multi-parallel corpora (FLORES-200) by computing the mean hidden state per language and subtracting a content vector (mean across all languages). During inference, it applies these vectors to hidden states via additive steering: for monolingual tasks, adding the target language vector; for cross-lingual tasks, adding the difference between target and source vectors. The method includes norm preservation to prevent model collapse and offers an optional trainable low-rank extension (ReCoVeR+) for improved accuracy.

## Key Results
- Reduces language confusion substantially in both monolingual (Mono-LC) and cross-lingual (Cross-LC) setups
- Preserves or improves task performance across 18 languages on three benchmarks
- Outperforms prior methods like LSI without the 4-12pp accuracy drop
- Works effectively in unsupervised mode without requiring task-specific training data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Language information is linearly encoded in hidden representations and can be isolated via vector arithmetic using parallel corpora.
- Mechanism: Computes language-specific vectors by averaging hidden states across a multi-parallel corpus for each language, then subtracts a content vector (the mean across all languages) to isolate the "language direction" from semantic content.
- Core assumption: The **Linear Representation Hypothesis**—high-level concepts are encoded as linear directions in activation space.
- Evidence anchors:
  - [section] §2 explicitly cites the linear representation hypothesis as the theoretical basis for representation steering.
  - [section] §3.1 formalizes isolation: `r(i)_l = v(i)_l - c(i)` where `c(i)` is the content vector.
  - [corpus] Neighbor "SAE-SSV" supports steering in representation spaces but notes reliability challenges; "Understanding (Un)Reliability of Steering Vectors" documents failure modes, which ReCoVeR addresses via norm preservation.
- Break condition: If language and content are not approximately separable via averaging, steering vectors will be noisy and ineffective.

### Mechanism 2
- Claim: Subtractive steering (target minus source language vector) redirects generation across languages without explicit prompt instructions.
- Mechanism: For monolingual tasks, adds normalized `r_target` to hidden states. For cross-lingual tasks, adds `(r_target - r_source)` to simultaneously attract the target language and repel the source language.
- Core assumption: The difference vector creates a direction that increases probability of target-language generation while decreasing source-language probability.
- Evidence anchors:
  - [abstract] States effectiveness "via fixed (i.e., unsupervised) as well as trainable steering functions."
  - [section] §3.2 provides Eq. (2) for Mono-LC and Eq. (3) for Cross-LC, explicitly noting the dual attract-repel mechanism.
  - [corpus] Weak/missing for this specific subtractive formula; "Language Steering for Multilingual In-Context Learning" addresses related problems but via ICL, not vector arithmetic.
- Break condition: If language representations are not sufficiently orthogonal, subtraction may yield near-zero vectors with no steering effect.

### Mechanism 3
- Claim: Layer-wise intervention with norm preservation prevents model collapse while maintaining steering effectiveness.
- Mechanism: Applies steering at all layers but finds early layers (1-2) and later layers most critical. Restores L2 norm after steering (`||ĥ|| = ||h||`) to keep representations on-distribution.
- Core assumption: Early layers encode surface features (script, language); middle layers handle reasoning (English-centric); late layers prepare output language. Magnitude matters for stability.
- Evidence anchors:
  - [section] §5.2 "Leave-Out Layers" shows largest drops when omitting layers 1-2 and 22-27, linking this to reasoning in intermediate layers.
  - [section] §3.2 introduces norm restoration: "retaining the norm... may be important for preventing model collapse."
  - [corpus] Weak/missing for norm preservation specifically; corpus papers discuss steering reliability generally but not this technique.
- Break condition: Excessive `alpha` without norm restoration pushes representations off-manifold, causing incoherent or repetitive outputs.

## Foundational Learning

- **Concept: Representation Engineering / Steering Vectors**
  - Why needed here: Core technique—modifying hidden states to control behavior without retraining.
  - Quick check question: What happens if you add a large-magnitude steering vector without normalization?

- **Concept: Multi-Parallel Corpora**
  - Why needed here: Required to disentangle language from content via averaging across translations.
  - Quick check question: Why can't monolingual data alone isolate a "content vector"?

- **Concept: Linear Representation Hypothesis**
  - Why needed here: Justifies simple vector arithmetic for complex conceptual control.
  - Quick check question: If "French" and "German" vectors were identical, what would steering accomplish?

## Architecture Onboarding

- **Component map:** Data Module -> Vector Computation Module -> Steering Intervention Module -> (Optional) Learnable Extension
- **Critical path:** The **Steering Intervention Module** at inference—vector addition/subtraction per layer per token. Negligible overhead (~O(d) per layer).
- **Design tradeoffs:**
  - Unsupervised (simple, works well especially for Cross-LC) vs. Trainable (+4-9pp accuracy gains but requires data/training).
  - `alpha`: Too low = no effect; too high = collapse.
  - Norm restoration: ON preserves task performance (critical); OFF may allow stronger language steering at accuracy cost.
- **Failure signatures:**
  - **Repetition/nonsense:** `alpha` too high or norm not restored.
  - **Wrong language persists:** `alpha` too low or vectors poorly computed.
  - **Correct language, wrong answer:** Over-steering distorting reasoning; check norm restoration and `alpha`.
- **First 3 experiments:**
  1. **Mono-LC Baseline:** Implement Eq. (2) for one language. Compute `r_l` from small parallel corpus. Sweep `alpha` on prompts where base model fails. Measure LPR vs. coherence.
  2. **Cross-LC Validation:** Implement Eq. (3). Force non-English output from English prompt. Compare LPR vs. few-shot ICL baseline.
  3. **Task Performance Check:** Run best config on knowledge task (translated MMLU/MultiQ). Confirm accuracy retained (unlike LSI baseline which drops 4-12pp).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the minimum number of samples required to obtain meaningful language representations for steering?
- Basis in paper: [explicit] The Limitations section states the authors used all available samples in FLORES-200 and "do not address the question of how many samples are minimally required."
- Why unresolved: The current study relies on the maximum available data from FLORES-200 without performing a data ablation study to determine the lower bound of efficiency.
- What evidence would resolve it: An ablation study analyzing language confusion metrics (LPR/WPR) when computing vectors from progressively smaller subsets of the multi-parallel corpus (e.g., 10, 50, 100 samples).

### Open Question 2
- Question: Can conditioning steering vectors on linguistic information, such as syntactic roles or typological features, improve cross-lingual generalization?
- Basis in paper: [explicit] The Conclusion proposes "vectors conditioned by (i) syntactic roles... or (ii) typological features... to facilitate cross-lingual generalization."
- Why unresolved: ReCoVeR currently averages representations across all tokens and positions, potentially smoothing over distinct linguistic patterns that could aid transfer to unseen languages.
- What evidence would resolve it: Experiments where steering vectors are derived from specific syntactic constituents or weighted by typological similarity vectors (e.g., URIEL), tested on zero-shot languages.

### Open Question 3
- Question: Why does the learned steering function (ReCoVeR+) suffer performance drops on specific unseen languages compared to the unsupervised method?
- Basis in paper: [inferred] While Table 4 shows general success, the authors note that "transfer of the learned steering function... to an unseen language can lead to a substantial performance drop (e.g., -8pp for Basque)."
- Why unresolved: The specific factors causing the learned intervention to fail on specific languages (like Turkish or Basque for the Gemma model) while succeeding on others remain unidentified.
- What evidence would resolve it: A fine-grained analysis correlating performance drops with linguistic distances between training and test languages, or an analysis of the learned steering weights' stability across different language pairs.

## Limitations

- Dependence on multi-parallel corpora limits scalability to low-resource language pairs
- Linear representation hypothesis may not generalize across all model architectures and language combinations
- Limited evaluation of semantic drift and generation quality over extended use

## Confidence

**High Confidence (8-10/10):** The core claim that ReCoVeR reduces language confusion without sacrificing task performance is well-supported by experimental results across three benchmarks with 18 languages.

**Medium Confidence (5-7/10):** The claim about the linear representation hypothesis being the underlying mechanism, given documented reliability challenges in steering literature and variation across architectures.

**Low Confidence (1-4/10):** The scalability and generalization claims about easy addition of new languages and independence from dominant languages, based on evaluation with available parallel data rather than systematic testing of edge cases.

## Next Checks

1. **Cross-Architecture Validation:** Test ReCoVeR on a different multilingual model family (e.g., BLOOM, mT5) to verify the linear representation hypothesis holds across architectures and compare steering effectiveness.

2. **Low-Resource Language Pair Test:** Evaluate ReCoVeR on a language pair with minimal parallel data (e.g., Swahili-Xhosa) to test claims about easy addition of new languages and measure effectiveness with reduced corpus size.

3. **Long-term Generation Quality Analysis:** Conduct systematic study of semantic drift and generation quality over extended conversations where ReCoVeR is applied repeatedly, using automated metrics and human evaluation to quantify accumulated effects.