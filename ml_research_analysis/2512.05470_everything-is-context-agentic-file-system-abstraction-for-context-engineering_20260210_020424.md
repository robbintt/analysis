---
ver: rpa2
title: 'Everything is Context: Agentic File System Abstraction for Context Engineering'
arxiv_id: '2512.05470'
source_url: https://arxiv.org/abs/2512.05470
tags:
- context
- memory
- file
- system
- engineering
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a file-system abstraction for context engineering
  in Generative AI systems, addressing the fragmentation and lack of traceability
  in current practices like prompt engineering and retrieval-augmented generation.
  Inspired by Unix's "everything is a file" philosophy, the approach provides a persistent,
  governed infrastructure for managing heterogeneous context artefacts through uniform
  mounting, metadata, and access control.
---

# Everything is Context: Agentic File System Abstraction for Context Engineering

## Quick Facts
- arXiv ID: 2512.05470
- Source URL: https://arxiv.org/abs/2512.05470
- Reference count: 30
- Introduces file-system abstraction for context engineering in GenAI systems, enabling persistent, governed management of heterogeneous context artefacts with traceability and accountability

## Executive Summary
This paper addresses the critical challenge of context engineering in Generative AI systems by introducing a novel file-system abstraction inspired by Unix philosophy. The approach tackles the fragmentation and lack of traceability in current practices like prompt engineering and retrieval-augmented generation by providing a unified infrastructure for managing context artefacts. Implemented in the open-source AIGNE framework, the architecture establishes a verifiable context-engineering pipeline with the Context Constructor, Loader, and Evaluator components. This pipeline enables the assembly, delivery, and validation of context under token constraints while ensuring governance and human-AI co-work capabilities.

## Method Summary
The proposed method introduces a file-system abstraction for context engineering that treats all context-related artefacts as files, enabling uniform mounting, metadata management, and access control. The architecture is implemented in the AIGNE framework and realizes a three-stage pipeline: the Context Constructor assembles and optimizes context under token constraints, the Context Loader delivers context to AI agents, and the Context Evaluator validates context quality and relevance. The approach supports human-AI co-work by embedding human roles as curators and verifiers, and demonstrates practical applicability through two exemplars: an agent with memory capabilities and an MCP-based GitHub assistant.

## Key Results
- Establishes a verifiable context-engineering pipeline comprising Context Constructor, Loader, and Evaluator components
- Enables persistent, governed infrastructure for managing heterogeneous context artefacts through uniform mounting and metadata
- Supports human-AI co-work by embedding human roles as curators and verifiers in the context engineering process
- Demonstrates practical implementation through two exemplars: memory-enabled agent and MCP-based GitHub assistant

## Why This Works (Mechanism)
The approach works by applying Unix's "everything is a file" philosophy to context engineering, creating a uniform abstraction layer that simplifies management of heterogeneous context artefacts. By treating all context elements as files, the system can leverage established file system principles like mounting, metadata, and access control to provide governance and traceability. The Context Constructor optimizes context assembly under token constraints, the Context Loader delivers context efficiently to AI agents, and the Context Evaluator ensures quality and relevance through validation mechanisms.

## Foundational Learning

**Unix Philosophy** - Treating all resources as files for uniform access and management. Why needed: Provides proven abstraction principles for complex system management. Quick check: Verify file operations work consistently across different context artefact types.

**Context Engineering** - The process of constructing, managing, and delivering context for AI systems. Why needed: Addresses the growing complexity and importance of context in GenAI applications. Quick check: Confirm context quality improves AI output accuracy.

**Human-AI Co-work** - Integrating human oversight and collaboration in AI workflows. Why needed: Ensures accountability and leverages human expertise in context curation. Quick check: Validate human validation steps improve context relevance.

**Token Constraint Management** - Optimizing context size within model token limits. Why needed: Critical for practical deployment given model limitations. Quick check: Measure context assembly time under varying constraints.

**Governance and Access Control** - Managing permissions and audit trails for context artefacts. Why needed: Ensures security and compliance in production environments. Quick check: Test access control enforcement across user roles.

## Architecture Onboarding

**Component Map**: Context Constructor -> Context Loader -> Context Evaluator -> AI Agent

**Critical Path**: User request -> Context Constructor (assemble context under token constraints) -> Context Loader (deliver context) -> AI Agent (generate response) -> Context Evaluator (validate quality) -> Feedback loop

**Design Tradeoffs**: The uniform file abstraction simplifies management but may introduce overhead compared to specialized storage; human-in-the-loop ensures quality but may impact latency; comprehensive governance provides security but requires additional configuration.

**Failure Signatures**: Context assembly failures when token constraints cannot be met; access control violations when permissions are misconfigured; validation failures when context quality falls below thresholds; mounting issues when file system operations fail.

**Three First Experiments**: (1) Test context assembly with varying token constraints and artefact volumes; (2) Verify access control enforcement across different user roles; (3) Measure context delivery latency under different network conditions.

## Open Questions the Paper Calls Out
None

## Limitations
- The "everything is context" principle requires empirical validation for scalability and performance in production environments
- Governance and access control mechanisms need stress-testing against real-world security and compliance scenarios
- Implementation lacks comprehensive performance metrics and resource overhead characterization

## Confidence

**High**: Conceptual alignment with Unix philosophy principles; clear architectural vision for context engineering

**Medium**: Architectural claims regarding context assembly and validation pipeline; human-AI co-work model articulation

**Low**: Implementation claims due to absence of performance benchmarks and scalability studies; governance model validation under adversarial conditions

## Next Checks

1. Measure context assembly and retrieval latency under varying token constraints and artefact volumes to assess scalability
2. Conduct security audit of governance model under adversarial conditions to validate access control mechanisms
3. Evaluate human-AI co-work workflow with actual domain experts across multiple use cases to validate practical effectiveness