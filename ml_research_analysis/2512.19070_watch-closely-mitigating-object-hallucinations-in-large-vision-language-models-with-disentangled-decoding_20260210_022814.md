---
ver: rpa2
title: 'Watch Closely: Mitigating Object Hallucinations in Large Vision-Language Models
  with Disentangled Decoding'
arxiv_id: '2512.19070'
source_url: https://arxiv.org/abs/2512.19070
tags:
- image
- hallucinations
- decoding
- visual
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of object hallucinations in Large
  Vision-Language Models (LVLMs), where models often fail to accurately identify objects
  in images, generating text that appears fluent but does not correspond to the visual
  content. The core method, Hallucination Disentangled Decoding (HDD), requires no
  training and enhances the original image by segmenting it and selecting images that
  augment the original, while also utilizing a blank image to eliminate language prior
  hallucinations in both the original and segmented images.
---

# Watch Closely: Mitigating Object Hallucinations in Large Vision-Language Models with Disentangled Decoding

## Quick Facts
- **arXiv ID:** 2512.19070
- **Source URL:** https://arxiv.org/abs/2512.19070
- **Reference count:** 23
- **Primary result:** HDD reduces hallucinations in LVLMs by combining segmentation-based visual enhancement with blank-image contrastive decoding, achieving superior performance on POPE, CHAIR, and GPT-4 hallucination benchmarks.

## Executive Summary
This paper addresses object hallucinations in Large Vision-Language Models (LVLMs) through Hallucination Disentangled Decoding (HDD), a training-free method that enhances visual detail while eliminating language priors. HDD segments the input image and uses Jensen-Shannon divergence to identify which segment contains the most task-relevant visual information, then applies contrastive decoding with blank images to suppress language-only outputs. The method demonstrates significant improvements across multiple hallucination benchmarks, outperforming recent baselines while maintaining comparable inference speed to some approaches.

## Method Summary
HDD operates by segmenting the input image into complementary masked versions and comparing their output distributions against a blank image using Jensen-Shander divergence. The segmented image with higher divergence is selected and used to enhance the original through weighted logit addition, with the weight determined by the divergence difference. HDD then applies contrastive decoding by subtracting the blank image's distribution to eliminate language priors. The method requires no training and works with existing segmentation models like SAM, Mask2Former, or Mask R-CNN, making it broadly applicable across different LVLM architectures.

## Key Results
- HDD achieves 90% accuracy on POPE Random subset versus 88% baseline on LLaVA-1.5
- Outperforms recent methods (HALC, CoD, VCD) on CHAIR hallucination metrics (CHAIR_I, CHAIR_S)
- Demonstrates robust performance across different segmentation models with <0.5% accuracy variance
- Maintains comparable inference speed to VCD while being faster than HALC

## Why This Works (Mechanism)

### Mechanism 1
Visual encoders exhibit lower sensitivity to entities occupying small image areas, which can be partially compensated by segmentation-based enhancement. Segment the original image into two complementary masked images (v₁, v₂). Compute Jensen-Shannon divergence between each segmented image's output distribution and a blank image distribution. The segmented image with higher JSD contains more task-relevant visual information and is used to enhance the original via weighted logit addition. Core assumption: JSD between a segmented image and blank image reliably indicates how much useful visual signal that segment contributes beyond language priors.

### Mechanism 2
LVLMs exhibit "Decoding Inertia"—over-reliance on language priors from prompts and co-occurrence statistics—which can be reduced via contrastive decoding with blank images. Pass a blank image v_n through the LVLM to capture the model's language-only distribution given the prompt. Subtract this from the visual distribution with weight α. This suppresses tokens likely generated from linguistic patterns alone. Core assumption: The blank image elicits a distribution that approximates the language prior component, which is linearly subtractable from the visual distribution.

### Mechanism 3
Adaptively weighting the enhancement based on the difference between segmented image JSD scores allows dynamic control over how much segmentation influences output. Compute δ = |Div₁ − Div₂|. When segments differ substantially in information content, the higher-JSD segment receives stronger influence. When segments are similar, the original image dominates. Core assumption: The absolute JSD difference meaningfully reflects the confidence that one segment is more informative than the other.

## Foundational Learning

- **Concept:** Contrastive Decoding
  - **Why needed here:** HDD extends contrastive decoding by using blank images as negative samples rather than noisy variants. Understanding the baseline helps see why subtraction works.
  - **Quick check question:** Given a visual distribution P(v|image, prompt) and language-only distribution P(v|blank, prompt), what does P(v|image) − α·P(v|blank) accomplish at the token level?

- **Concept:** Jensen-Shannon Divergence
  - **Why needed here:** JSD quantifies how much one distribution diverges from another symmetrically, unlike KL divergence. Used here to rank which segmented image contains more distinctive visual signal.
  - **Quick check question:** Why might JSD be preferred over KL divergence when comparing two output distributions that could each have regions of zero probability?

- **Concept:** Semantic Segmentation for Attention
  - **Why needed here:** HDD relies on external segmentation tools (SAM, Mask2Former, etc.) to isolate entities. The choice of segmentation granularity affects what gets amplified.
  - **Quick check question:** If a segmentation model over-segments (produces many small masks), how might this affect HDD's Visual Detail Enhancement step?

## Architecture Onboarding

- **Component map:** Input image V and query x → Segmentation Module (produces n masks → splits into v₁ and v₂) → LVLM Forward Pass (four parallel passes: V, v₁, v₂, v_n) → JSD Calculator (computes Div₁, Div₂) → Weighted Logit Combiner (Equations 8-10) → Output token
- **Critical path:** Segmentation quality → JSD ranking accuracy → enhancement weight δ → final token distribution. Errors in segmentation propagate through the entire pipeline.
- **Design tradeoffs:** Segmentation granularity: Finer segments may isolate small objects but increase compute and risk fragmenting coherent entities. Blank image choice: A pure blank removes visual signal entirely, but prompts containing spatial priors may still bias the language-only distribution. Parameter α: Higher values more aggressively suppress language priors but may undergenerate valid descriptions.
- **Failure signatures:** Over-suppression: If α is too high, valid object mentions may be eliminated. Wrong segment selection: If JSD favors a segment without the queried object, enhancement amplifies irrelevant features. Latency overhead: Four forward passes per query.
- **First 3 experiments:**
  1. Run HDD on LLaVA-1.5 with MSCOCO POPE Random subset, α=0.4, N=0.05·n_masks. Compare accuracy/F1 against greedy decoding.
  2. Disable each mechanism (Visual Enhancement only, Language Elimination only, both). Measure performance drop on CHAIR metrics to verify disentanglement claim.
  3. Swap SAM for a cheaper segmenter (e.g., Mask R-CNN). Measure accuracy delta and inference time to assess practical deployment tradeoffs.

## Open Questions the Paper Calls Out

### Open Question 1
Can the disentangled decoding framework be effectively extended to mitigate hallucinations in dynamic modalities such as video or 3D point clouds? The Limitation section explicitly states the current focus is image-text alignment and leaves the exploration of video and 3D modalities as future work. Temporal consistency in video or spatial complexity in 3D data introduces hallucination sources that differ from static images, potentially complicating the current segmentation and contrastive strategies.

### Open Question 2
To what extent do failures in the external segmentation model (e.g., missing small objects) propagate to the HDD method, limiting its ability to enhance visual details? HDD relies on segmentation tools to isolate entities; if the tool fails to mask a specific object, the method cannot amplify its visual signal. While the paper shows robustness across different segmentation tools, it does not analyze scenarios where the segmentation model fails to identify the specific "small objects" the method aims to rescue.

### Open Question 3
Can the multiple inference passes required by HDD be optimized to reduce computational latency for real-time applications? The method requires four forward passes per generation step, which inherently increases decoding time. Although Figure 6 shows HDD is faster than HALC, it remains significantly slower than greedy decoding, potentially hindering deployment in latency-sensitive environments.

## Limitations
- Relies on external segmentation models, making performance dependent on segmentation quality and potentially limiting effectiveness for very small or occluded objects
- Requires multiple forward passes (four per generation), increasing computational overhead compared to greedy decoding
- Claims of "disentanglement" between visual and language hallucinations lack rigorous ablation showing clean isolation of language priors

## Confidence

- **High confidence**: HDD improves hallucination metrics (CHAIR, POPE) compared to baselines; the contrastive decoding mechanism with blank images is well-established in the literature
- **Medium confidence**: The segmentation-based enhancement actually improves visual detail vs. random masking or other augmentation strategies; the specific JSD-based selection criterion is optimal
- **Low confidence**: HDD's gains translate to real-world applications where objects may be partially occluded or in unusual contexts not captured by MSCOCO/A-OKVQA benchmarks

## Next Checks

1. **Ablation on segmentation strategy**: Replace SAM with a simpler segmenter (Mask R-CNN) and measure performance drop to verify segmentation quality is necessary rather than sufficient
2. **Language prior isolation test**: Run HDD on prompts with strong spatial priors ("On the road") and compare blank vs. context-aware language-only distributions to check if subtraction is removing valid tokens
3. **Cross-dataset generalization**: Evaluate HDD on a dataset with smaller objects or atypical object-scene relationships (e.g., objects in unusual contexts) to test whether the JSD selection remains reliable