---
ver: rpa2
title: Regularized infill criteria for multi-objective Bayesian optimization with
  application to aircraft design
arxiv_id: '2504.08671'
source_url: https://arxiv.org/abs/2504.08671
tags:
- optimization
- problems
- design
- segomoe
- pareto
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper extends the SEGOMOE (Super Efficient Global Optimization
  with Mixture of Experts) framework to handle constrained multi-objective optimization
  problems. The key innovation is the introduction of regularized infill criteria
  that combine multi-objective acquisition functions with regularization terms based
  on Gaussian Process predictions, addressing the ill-posedness of the optimization
  problem.
---

# Regularized infill criteria for multi-objective Bayesian optimization with application to aircraft design

## Quick Facts
- arXiv ID: 2504.08671
- Source URL: https://arxiv.org/abs/2504.08671
- Reference count: 40
- The paper extends SEGOMOE to handle constrained multi-objective optimization with regularized infill criteria, achieving a 20-fold reduction in function evaluations compared to NSGA-II for an aircraft design problem.

## Executive Summary
This paper addresses the challenge of constrained multi-objective optimization in high-dimensional spaces by extending the SEGOMOE (Super Efficient Global Optimization with Mixture of Experts) framework. The key innovation is the introduction of regularized infill criteria that combine multi-objective acquisition functions with regularization terms based on Gaussian Process predictions. This approach tackles the ill-posedness of the optimization problem by adding constraints that guide the search toward more promising regions of the design space. The method is tested on both benchmark problems and a real-world aircraft design application, demonstrating significant improvements in convergence and efficiency.

The proposed regularized criteria are particularly effective in high-dimensional spaces where traditional multi-objective optimization methods struggle. By incorporating the mean prediction from Gaussian Processes as a regularization term, the method balances exploration and exploitation while respecting problem constraints. The paper shows that this approach can achieve comparable or better results than state-of-the-art methods like NSGA-II while requiring significantly fewer function evaluations, making it particularly valuable for expensive-to-evaluate objective functions common in engineering design problems.

## Method Summary
The paper extends the SEGOMOE framework to handle constrained multi-objective optimization problems by introducing regularized infill criteria. The method combines multi-objective acquisition functions with regularization terms based on Gaussian Process predictions to address the ill-posedness of the optimization problem. Two types of regularization are explored: using either the maximum or sum of the mean prediction from the Gaussian Process model. The approach is designed to work in high-dimensional spaces and is tested on 12 benchmark problems (9 unconstrained and 3 constrained) as well as a real-world aircraft design problem. The method uses a mixture of experts model where each expert is a Gaussian Process, and the regularization helps guide the search toward promising regions while respecting constraints.

## Key Results
- SEGOMOE with regularized criteria achieved a Pareto front using 115 function evaluations for the aircraft design problem
- This represents a 20-fold reduction compared to the standard NSGA-II algorithm which required 2500 evaluations
- Regularized criteria improved convergence, particularly in high-dimensional spaces
- Maximum-based regularization performed best in most cases compared to sum-based regularization

## Why This Works (Mechanism)
The regularization terms in the infill criteria help guide the search toward regions of the design space that are both promising (based on the acquisition function) and likely to satisfy constraints (based on the mean prediction of the Gaussian Process). This addresses the ill-posedness of the multi-objective optimization problem by adding constraints that make the optimization more well-behaved. The maximum-based regularization is particularly effective because it focuses on the worst-case scenario across all objectives, ensuring that no single objective is neglected in the optimization process.

## Foundational Learning
- Gaussian Process regression: A probabilistic model for regression that provides both mean predictions and uncertainty estimates, needed to quantify prediction uncertainty and guide exploration.
- Multi-objective optimization: Optimization problems with multiple conflicting objectives, requiring specialized techniques to find Pareto-optimal solutions.
- Acquisition functions: Functions used in Bayesian optimization to balance exploration and exploitation, determining where to sample next in the optimization process.
- Mixture of experts models: Ensemble methods where multiple models (experts) are combined, each specializing in different regions of the input space.
- Infill criteria: Criteria used to select new evaluation points in optimization, balancing exploration of unknown regions with exploitation of known good regions.
- Constrained optimization: Optimization problems with additional constraints that must be satisfied, requiring specialized handling in the optimization algorithm.

## Architecture Onboarding

**Component Map**
SEGOMOE -> Regularized Infill Criteria -> Gaussian Process Model -> Mixture of Experts -> Benchmark/Real-world Problems

**Critical Path**
1. Initialize SEGOMOE with mixture of experts
2. Generate initial design points
3. Evaluate objectives and constraints
4. Update Gaussian Process models
5. Compute regularized infill criteria
6. Optimize infill criteria to select next point
7. Repeat steps 3-6 until convergence

**Design Tradeoffs**
The choice between maximum and sum-based regularization represents a key tradeoff between focusing on worst-case scenarios (maximum) versus overall performance (sum). The method trades off computational efficiency against solution quality, with regularized criteria potentially being more computationally expensive but yielding better convergence.

**Failure Signatures**
- Poor convergence in high-dimensional spaces may indicate inadequate regularization
- Violation of constraints suggests the regularization terms are not properly balancing exploration and constraint satisfaction
- Excessive computational time may indicate the regularized criteria are too complex for the problem size

**First Experiments**
1. Test the method on a simple 2-objective, 2-dimensional constrained problem to verify basic functionality
2. Compare convergence rates of maximum vs. sum-based regularization on a medium-dimensional problem
3. Evaluate computational time scaling with problem dimension to assess practical limitations

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but implicit questions include how the method scales to very high-dimensional problems (beyond 20-30 dimensions), whether the regularization terms can be adaptively chosen based on problem characteristics, and how the method performs on problems with many constraints (more than 3).

## Limitations
- Computational cost of regularized infill criteria can become prohibitive for large design spaces
- Effectiveness may be problem-specific, with superior performance on aircraft design but variable results on benchmark functions
- Choice of regularization terms (maximum vs. sum) is somewhat arbitrary and may not generalize well
- Comparison with NSGA-II may not be entirely fair as it's a population-based method while SEGOMOE is single-point sequential

## Confidence

| Claim | Confidence |
|-------|------------|
| Regularized infill criteria improve convergence in high-dimensional spaces | High |
| SEGOMOE with regularized criteria achieves 20-fold reduction in function evaluations vs NSGA-II for aircraft design | High |
| Maximum-based regularization outperforms sum-based regularization | Medium |

## Next Checks
1. Test the method on a wider range of constrained multi-objective problems to assess generalizability
2. Compare computational time of regularized criteria against standard infill criteria on problems with varying design space sizes
3. Investigate sensitivity to different choices of regularization terms and their impact on convergence in high-dimensional spaces