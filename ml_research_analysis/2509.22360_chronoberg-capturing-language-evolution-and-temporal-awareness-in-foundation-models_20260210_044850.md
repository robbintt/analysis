---
ver: rpa2
title: 'CHRONOBERG: Capturing Language Evolution and Temporal Awareness in Foundation
  Models'
arxiv_id: '2509.22360'
source_url: https://arxiv.org/abs/2509.22360
tags:
- chronoberg
- temporal
- language
- words
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CHRONOBERG, a 2.7B token corpus of English
  literary texts spanning 250 years (1750-2000), curated from Project Gutenberg and
  annotated with temporal metadata. The authors construct temporally aligned Valence-Arousal-Dominance
  (VAD) lexicons to track affective shifts in language over time.
---

# CHRONOBERG: Capturing Language Evolution and Temporal Awareness in Foundation Models

## Quick Facts
- arXiv ID: 2509.22360
- Source URL: https://arxiv.org/abs/2509.22360
- Reference count: 40
- Primary result: Sequential training on 250-year historical text reveals significant catastrophic forgetting; modern hate-speech detectors misclassify neutral historical phrases.

## Executive Summary
CHRONOBERG is a 2.7B token corpus of English literary texts spanning 1750-2000, curated from Project Gutenberg with temporal metadata. The authors construct temporally aligned Valence-Arousal-Dominance (VAD) lexicons to track affective shifts in language over time. They demonstrate that modern LLM-based hate-speech detection tools struggle with historical context, often misclassifying neutral historical phrases as harmful. Sequential training of language models on CHRONOBERG reveals significant forgetting of prior knowledge and poor generalization to future time periods, particularly for words with shifting valence.

## Method Summary
The study introduces CHRONOBERG, a 2.7B token corpus of English literary texts spanning 250 years (1750-2000), curated from Project Gutenberg and annotated with temporal metadata. Temporally aligned Valence-Arousal-Dominance (VAD) lexicons are constructed to track affective shifts in language over time. Sequential training of language models (Pythia 1.4B) on 50-year intervals reveals catastrophic forgetting and poor generalization to future time periods, especially for words with shifting valence. Continual learning methods like EWC and LoRA reduce forgetting for valence-stable words but struggle with semantic drift. Hate-speech detection tools are shown to misclassify neutral historical phrases due to lack of temporal awareness.

## Key Results
- Sequential training on 50-year intervals causes significant catastrophic forgetting, particularly for valence-shifting words
- Modern hate-speech detection tools misclassify neutral historical phrases as harmful due to lack of temporal context
- Continual learning methods (EWC, LoRA) reduce forgetting for valence-stable words but still struggle with semantic drift

## Why This Works (Mechanism)
The paper demonstrates that language models trained on temporally sequential data exhibit catastrophic forgetting, particularly for words whose affective valence changes over time. The VAD lexicon alignment using Word2Vec and CADE allows tracking of semantic drift, revealing that modern hate-speech detectors fail to account for historical context. The sequential training setup exposes the limitations of current continual learning methods in handling semantic drift across long time periods.

## Foundational Learning
- Temporal language evolution: Understanding how word meanings and affective valence change over centuries is crucial for building temporally aware models
- Valence-Arousal-Dominance (VAD) theory: Psychological framework for quantifying emotional content in language across time
- Continual learning with catastrophic forgetting: Standard sequential training leads to rapid degradation of performance on earlier time periods
- Semantic drift detection: Methods for identifying words whose meanings or affective associations shift over historical periods
- Hate-speech detection limitations: Modern tools lack temporal context and misclassify historically neutral terms

## Architecture Onboarding

### Component Map
CHRONOBERG Corpus (2.7B tokens) -> Sequential Training (Pythia 1.4B) -> VAD Lexicon Alignment (Word2Vec + CADE) -> Evaluation (Perplexity + Hate-Speech Detection)

### Critical Path
Data curation and temporal annotation → VAD lexicon construction → Sequential model training → Performance evaluation on held-out test sets

### Design Tradeoffs
- 50-year intervals vs finer temporal granularity: Simpler implementation vs potentially better capturing semantic drift
- Word2Vec vs modern embeddings: Faster training vs potentially better semantic representation
- Black-box hate-speech API vs custom model: Easier evaluation vs lack of transparency in failure modes

### Failure Signatures
- High perplexity on early intervals after sequential training (catastrophic forgetting)
- Low retrieval rates in VAD lexicon alignment (CADE convergence issues)
- High false positive rates in hate-speech detection on historical texts

### First Experiments
1. Train Pythia 1.4B sequentially on 50-year intervals and measure diagonal vs off-diagonal perplexity
2. Construct VAD lexicons using Word2Vec + CADE and validate neighbor retrieval rates
3. Run hate-speech detection pipeline on historical texts and categorize misclassification types

## Open Questions the Paper Calls Out
1. How can novel continual learning techniques be developed to better capture historical semantic drift, specifically for words with shifting valence where current methods like EWC and LoRA fail?
2. How can expert-defined historical eras or literary epochs be integrated into temporal analysis to improve upon the fixed 50-year intervals used in this study?
3. Can machine unlearning protocols be effectively applied to temporally sensitive corpora to remove historically contingent slurs without erasing necessary historical context?

## Limitations
- The 50-year temporal intervals are arbitrary and may not align with meaningful historical eras or periods of semantic shift
- VAD lexicon alignment stability across 250 years is not validated, raising concerns about alignment accuracy
- Hate-speech detection results rely on a black-box Perspective API without reporting false positive/negative rates or calibration curves

## Confidence
- High: Sequential training results showing catastrophic forgetting are robust and expected given standard continual learning dynamics
- Medium: VAD lexicon construction and temporal alignment methodology lack validation of alignment stability across centuries
- Low: Hate-speech detection results are difficult to interpret without API performance metrics or human evaluation

## Next Checks
1. Evaluate whether varying the temporal interval size (25 vs 50 vs 100 years) changes the magnitude of forgetting observed in sequential training
2. Validate the VAD lexicon alignment by testing retrieval rates and semantic consistency on a held-out sample of words with known historical usage patterns
3. Conduct human evaluation of the hate-speech detection pipeline on a subset of cases to distinguish between true semantic drift and API limitations