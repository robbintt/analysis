---
ver: rpa2
title: 'RLJP: Legal Judgment Prediction via First-Order Logic Rule-enhanced with Large
  Language Models'
arxiv_id: '2505.21281'
source_url: https://arxiv.org/abs/2505.21281
tags:
- legal
- judgment
- rules
- case
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses Legal Judgment Prediction (LJP), a task where
  AI predicts legal outcomes from case facts. Existing methods focus on semantic similarity
  or legal knowledge but neglect legal reasoning logic.
---

# RLJP: Legal Judgment Prediction via First-Order Logic Rule-enhanced with Large Language Models

## Quick Facts
- **arXiv ID**: 2505.21281
- **Source URL**: https://arxiv.org/abs/2505.21281
- **Reference count**: 13
- **Primary result**: RLJP achieves SOTA performance, improving accuracy by 1.43% and F1 by 14.98% over baselines on CAIL2018 and CJO22 datasets

## Executive Summary
This paper addresses Legal Judgment Prediction (LJP), a task where AI predicts legal outcomes from case facts. Existing methods focus on semantic similarity or legal knowledge but neglect legal reasoning logic. The proposed RLJP framework integrates First-Order Logic (FOL) rules with Large Language Models (LLMs) to capture legal reasoning. It uses a three-stage approach: initializing judgment rules with FOL, optimizing rules via Confusion-Aware Contrastive Learning (CACL) using confusable cases, and predicting judgments. Experiments on CAIL2018 and CJO22 datasets show RLJP achieves state-of-the-art performance, improving accuracy by 1.43% and F1 by 14.98% over baselines. Ablation studies confirm the effectiveness of FOL rules and CACL. RLJP particularly excels in handling complex cases with detailed facts.

## Method Summary
RLJP is a three-stage framework that combines First-Order Logic rules with Large Language Models for Legal Judgment Prediction. The approach begins by initializing judgment rules using FOL to capture legal reasoning logic, then optimizes these rules through Confusion-Aware Contrastive Learning (CACL) that leverages confusable cases to improve rule quality. The framework integrates LLM capabilities for handling complex case facts while maintaining logical consistency through the FOL rule system. This hybrid approach addresses the limitation of existing LJP methods that focus solely on semantic similarity or legal knowledge without incorporating structured legal reasoning.

## Key Results
- RLJP achieves state-of-the-art performance on CAIL2018 and CJO22 datasets
- Accuracy improvement of 1.43% over baseline methods
- F1 score improvement of 14.98% over baseline methods
- Particularly effective for complex cases with detailed factual information

## Why This Works (Mechanism)
RLJP works by integrating structured legal reasoning (via First-Order Logic rules) with the semantic understanding capabilities of LLMs. The FOL rules capture the logical relationships and reasoning patterns inherent in legal judgments, while the LLM handles the natural language understanding of case facts. The Confusion-Aware Contrastive Learning component identifies and leverages confusable cases to refine the FOL rules, making them more robust to edge cases and ambiguous situations. This combination addresses the key limitation of previous LJP approaches that either focus on semantic similarity without logical structure or rely on legal knowledge without semantic understanding.

## Foundational Learning
- **First-Order Logic (FOL)**: Needed to represent legal reasoning rules formally and capture logical relationships in judgments. Quick check: Can FOL rules be expressed as logical predicates with variables and quantifiers.
- **Large Language Models (LLMs)**: Needed for understanding complex natural language case facts and generating confusable cases for training. Quick check: Can LLM handle multi-sentence legal descriptions and extract relevant information.
- **Confusion-Aware Contrastive Learning (CACL)**: Needed to optimize FOL rules by learning from cases that are easily confused by models. Quick check: Can CACL distinguish between similar cases and improve rule robustness.
- **Legal Judgment Prediction (LJP)**: Needed as the target task of predicting legal outcomes from case facts. Quick check: Can the framework handle multi-label classification with legal categories.
- **Rule initialization and optimization**: Needed to create and refine legal reasoning rules systematically. Quick check: Can the rules be initialized from legal principles and improved through contrastive learning.

## Architecture Onboarding

**Component map**: FOL Rule Initialization -> CACL Optimization -> Judgment Prediction

**Critical path**: Case facts enter LLM for semantic understanding, FOL rules provide logical reasoning framework, CACL optimizes rules using confusable cases, final prediction combines both semantic and logical components

**Design tradeoffs**: 
- Uses FOL rules for structured reasoning vs pure neural approaches for flexibility
- Relies on LLM-generated confusable cases vs manually curated examples
- Combines semantic understanding with logical rules vs using either approach alone

**Failure signatures**: 
- Poor performance on cases with unusual fact patterns not covered by FOL rules
- Over-reliance on LLM semantic understanding when legal reasoning is required
- CACL optimization fails if generated confusable cases are not representative

**3 first experiments**:
1. Test FOL rule initialization on a small legal dataset to verify logical consistency
2. Evaluate CACL optimization on a set of known confusable cases
3. Run ablation study removing CACL component to measure its contribution

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Limited to two datasets (CAIL2018 and CJO22), may not generalize across legal domains
- Reliance on LLM-generated confusable cases could introduce bias
- Unclear how well FOL rules transfer to different legal jurisdictions

## Confidence
- **Accuracy improvement (1.43%)**: Medium
- **F1 improvement (14.98%)**: Medium
- **Generalizability across legal domains**: Low
- **Effectiveness of FOL rules in capturing legal reasoning**: Medium

## Next Checks
1. Test RLJP on additional legal datasets from different jurisdictions to evaluate cross-domain generalization of both the FOL rules and the overall framework
2. Conduct ablation studies specifically isolating the contribution of the CACL component versus the FOL rules to better understand which component drives the performance improvements
3. Perform qualitative analysis with legal experts to assess whether the model's predictions align with actual legal reasoning principles and whether the generated FOL rules capture meaningful legal logic beyond statistical patterns