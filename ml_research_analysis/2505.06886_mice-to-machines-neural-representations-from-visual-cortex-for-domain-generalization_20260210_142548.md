---
ver: rpa2
title: 'Mice to Machines: Neural Representations from Visual Cortex for Domain Generalization'
arxiv_id: '2505.06886'
source_url: https://arxiv.org/abs/2505.06886
tags:
- neural
- neurn
- representations
- visual
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the problem of domain generalization in deep
  learning by leveraging insights from the mouse visual cortex. The authors introduce
  a framework for comparing neural representations from the mouse visual cortex with
  feature representations from deep neural networks.
---

# Mice to Machines: Neural Representations from Visual Cortex for Domain Generalization

## Quick Facts
- arXiv ID: 2505.06886
- Source URL: https://arxiv.org/abs/2505.06886
- Reference count: 11
- Key outcome: NeuRN improves domain generalization accuracy by up to 50% and aligns DNN features with mouse visual cortex excitatory neurons

## Executive Summary
This study bridges neuroscience and deep learning by introducing Neural Response Normalization (NeuRN), a biologically-inspired layer that normalizes pixel-level contrastive deviations to generate domain-agnostic feature representations. The method leverages insights from mouse visual cortex to improve domain generalization performance on cross-domain image classification tasks. Results demonstrate that NeuRN-equipped models achieve significantly better cross-domain transfer accuracy compared to standard architectures while simultaneously increasing biological alignment between artificial neural networks and mouse visual cortex representations.

## Method Summary
NeuRN operates as a preprocessing layer that extracts k×k patches around each pixel, computes local mean and standard deviation, then normalizes pixel values by the inverse of the standard deviation scaled by the maximum contrast across the image. This produces domain-agnostic representations that suppress domain-specific contrast variations while preserving structural content. The method is integrated into various deep learning architectures and evaluated on domain generalization tasks using MNIST, SVHN, USPS, and MNIST-M datasets, with models pretrained on ImageNet and finetuned on CIFAR-27 natural scenes.

## Key Results
- NeuRN-equipped models achieve up to 50% improvement in domain transfer accuracy for certain architecture-dataset combinations
- VGG19 with NeuRN improves M→S transfer from 13.7% to 24.5% and M→MM from 39.7% to 62.6%
- NeuRN reduces representational similarity RMSE between DNN features and mouse visual cortex excitatory neurons
- All genotypes except Fezf2 showed improved biological alignment with NeuRN models

## Why This Works (Mechanism)

### Mechanism 1
Normalizing pixel-level contrastive deviations generates domain-agnostic feature representations that improve cross-domain generalization. NeuRN extracts k×k patches, computes local mean and standard deviation, then produces domain-agnostic representation via Ia = 1/(c · σpk) where c = max(σ). This suppresses domain-specific contrast variations while preserving structural content. Domain shifts manifest primarily through contrast and intensity variations rather than structural patterns.

### Mechanism 2
DNN feature representations align more strongly with excitatory neurons than inhibitory neurons in mouse visual cortex, and NeuRN amplifies this alignment. NeuRN increases activation levels to match excitatory neuron firing characteristics. Excitatory neurons in visual cortex encode contrast and structure information relevant to object recognition; inhibitory neurons serve different computational roles not captured by standard DNN architectures.

### Mechanism 3
Patch-based spatial normalization maintains structural context better than channel-wise or pixel-wise alternatives, enabling robust domain transfer. Unlike Local Response Normalization or Local Contrast Normalization, NeuRN's k×k patch approach captures both local patterns and global structural relationships across the image. Domain-relevant features span multiple spatial scales; patch-based processing preserves multi-scale information that pixel or channel operations lose.

## Foundational Learning

- **Domain Generalization vs. Domain Adaptation**
  - Why needed here: The paper targets domain generalization (no target domain access during training), distinct from domain adaptation (target domain available). Misunderstanding this leads to incorrect experimental setup interpretation.
  - Quick check question: If you fine-tune on target domain data, are you testing domain generalization or domain adaptation?

- **Divisive Normalization in Neuroscience**
  - Why needed here: NeuRN is inspired by biological response normalization where excitatory/inhibitory neuron interactions normalize neural responses. Understanding this biological basis explains design choices.
  - Quick check question: Why might contrast normalization in visual cortex be evolutionarily advantageous for animals encountering varied lighting conditions?

- **Representational Similarity Analysis (RSA)**
  - Why needed here: The paper uses RMSE between flattened feature/neural representations as a similarity metric, building on RSA methodology. Understanding RSA is essential to interpret Figure 2 and alignment claims.
  - Quick check question: What does a lower RMSE between a DNN layer's features and mouse V1 neural representations indicate about the model?

## Architecture Onboarding

- **Component map:** Input Image → [NeuRN Layer - Preprocessing] → [Standard DNN Backbone] → [Classification Head]

- **Critical path:** NeuRN must be applied as a preprocessing layer before the first convolutional layer. The normalization operates on raw pixels, converting contrast information to normalized responses. If inserted mid-network, it normalizes already-processed features.

- **Design tradeoffs:**
  - Patch size k: Smaller k captures fine-grained local contrast; larger k captures broader context but may over-smooth
  - Stride: Paper uses stride=1 (patch per pixel). Larger stride reduces computation but may lose spatial precision
  - Position: Only tested as input preprocessing. Unknown if mid-network NeuRN provides benefits

- **Failure signatures:**
  - No improvement or degradation: Domain shift is not contrast-based (e.g., style transfer, geometric transformations)
  - Inconsistent results across architectures: Some models show minimal improvement—suggesting architecture-specific interactions
  - Low RMSE improvement for certain genotypes: Fezf2 neurons did not show improved alignment

- **First 3 experiments:**
  1. Baseline domain transfer without NeuRN: Train VGG19 on MNIST, evaluate on SVHN, USPS, MNIST-M
  2. Add NeuRN with varying patch sizes k ∈ {3, 5, 7, 9}: Test whether patch size affects domain transfer performance
  3. Measure RMSE alignment with neural representations: Extract features from NeuRN vs. non-NeuRN models, compute RMSE against neural representations dataset

## Open Questions the Paper Calls Out
- Does NeuRN improve performance in downstream tasks beyond classification, such as segmentation or novel view synthesis?
- Why does NeuRN fail to enhance representational alignment for the Fezf2 genotype?
- Is NeuRN effective for domain generalization in high-resolution, complex natural imagery?

## Limitations
- Performance depends on unknown optimal patch size k, which significantly affects learned representations
- Method focuses on contrast-based domain shifts and may not generalize to geometric transformations or semantic shifts
- Biological alignment claims rely on comparing to specific excitatory/inhibitory neuron types without fully characterizing functional relevance

## Confidence
- **High**: NeuRN improves domain generalization accuracy on tested datasets compared to non-NeuRN baselines
- **Medium**: Local contrast normalization mechanism generating domain-agnostic features is theoretically sound and supported by results
- **Low**: Claimed biological alignment improvements and their functional significance are not fully validated

## Next Checks
1. Perform ablation studies with different patch sizes k (3, 5, 7, 9) to determine sensitivity and optimal configuration
2. Test NeuRN on domain shifts that are not contrast-based (e.g., rotation, scaling, occlusion) to assess broader generalization capability
3. Verify RMSE and KDE-IoU calculations for biological alignment by reproducing representational similarity analysis on a subset of neural data