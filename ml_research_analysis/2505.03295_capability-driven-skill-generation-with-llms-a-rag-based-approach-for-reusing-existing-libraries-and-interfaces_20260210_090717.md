---
ver: rpa2
title: 'Capability-Driven Skill Generation with LLMs: A RAG-Based Approach for Reusing
  Existing Libraries and Interfaces'
arxiv_id: '2505.03295'
source_url: https://arxiv.org/abs/2505.03295
tags:
- skill
- resource
- interfaces
- capability
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of automating skill implementation
  in industrial automation systems, where manual development is time-consuming and
  requires deep technical expertise. The authors propose LLM-Cap2Skill, a method that
  leverages large language models (LLMs) and retrieval-augmented generation (RAG)
  to automatically generate executable skills from capability models and natural language
  user input.
---

# Capability-Driven Skill Generation with LLMs: A RAG-Based Approach for Reusing Existing Libraries and Interfaces

## Quick Facts
- arXiv ID: 2505.03295
- Source URL: https://arxiv.org/abs/2505.03295
- Reference count: 13
- Method enables automatic skill generation from capability models using LLMs and RAG

## Executive Summary
This paper addresses the challenge of automating skill implementation in industrial automation systems, where manual development is time-consuming and requires deep technical expertise. The authors propose LLM-Cap2Skill, a method that leverages large language models (LLMs) and retrieval-augmented generation (RAG) to automatically generate executable skills from capability models and natural language user input. The approach integrates existing libraries and resource interfaces, enabling cross-language code generation. Evaluation on a mobile robot platform using ROS 2 and Python showed that generated skills were structurally correct and executable, with most achieving intended behavior with minimal manual corrections.

## Method Summary
The LLM-Cap2Skill approach combines large language models with retrieval-augmented generation to automate skill implementation in industrial automation systems. The method takes capability models and natural language user input as input, then retrieves relevant libraries and interfaces from existing repositories. The LLM generates executable code that integrates these components, supporting cross-language generation. The system produces not only skill implementations but also automatically generates skill interfaces, ontologies, and state machines. Evaluation was conducted on a mobile robot platform using ROS 2 and Python, measuring both structural correctness and functional behavior of generated skills.

## Key Results
- Generated skills were structurally correct and executable across tested scenarios
- Most generated skills achieved intended behavior with minimal manual corrections required
- Collision avoidance skill implemented correctly in most cases; move-to-point skill succeeded after minor identifier adjustments
- Method significantly reduces manual coding effort in industrial automation contexts

## Why This Works (Mechanism)
The approach works by combining the generative capabilities of LLMs with targeted retrieval of existing libraries and interfaces. The RAG component ensures that generated code leverages proven, existing implementations rather than generating everything from scratch. This reduces errors and ensures compatibility with established automation frameworks. The capability models provide structured input that guides the LLM toward generating contextually appropriate code, while natural language input makes the system accessible to users without deep programming expertise. Cross-language support enables integration with diverse industrial automation ecosystems.

## Foundational Learning
- **RAG (Retrieval-Augmented Generation)**: Combines information retrieval with text generation to produce more accurate, context-aware outputs; needed to ground LLM generation in existing code libraries; quick check: verify retrieved libraries match capability requirements
- **Capability Models**: Structured representations of system abilities and requirements; needed to provide semantic context for code generation; quick check: ensure model completeness before generation
- **State Machines**: Formal models of system behavior and transitions; needed for defining skill execution flow; quick check: validate state transitions against expected behavior
- **ROS 2 Integration**: Middleware framework for robotics systems; needed for platform compatibility; quick check: confirm generated code compiles with ROS 2 dependencies
- **Cross-language Code Generation**: Ability to produce code in multiple programming languages; needed for industrial system interoperability; quick check: test generated code compilation in target language
- **Ontology Generation**: Creation of structured knowledge representations; needed for skill interface definition; quick check: validate ontology consistency with capability models

## Architecture Onboarding
**Component Map**: User Input -> Capability Model -> RAG Retriever -> Library Repository -> LLM Generator -> Code Output -> Skill Interface/State Machine
**Critical Path**: The RAG retrieval and LLM generation sequence forms the critical path, as code quality depends on both accurate library retrieval and coherent generation
**Design Tradeoffs**: The approach trades potential optimization opportunities for speed and reliability by reusing existing libraries rather than generating all code from scratch
**Failure Signatures**: Common failures include incorrect library retrieval leading to incompatible code, missing capability model elements causing incomplete generation, and identifier mismatches in cross-language contexts
**First Experiments**: 1) Test RAG retrieval accuracy with known capability patterns, 2) Validate LLM generation with simple skill templates, 3) Verify cross-language compatibility with basic library calls

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to single mobile robot platform using ROS 2 and Python, limiting generalizability
- Generated skills showed varying success rates, with some requiring manual corrections
- Approach heavily dependent on quality and comprehensiveness of retrieved libraries
- Does not address scalability for larger skill libraries or real-time performance constraints
- Long-term maintainability and debugging of generated code remains unexamined

## Confidence
- High confidence in technical feasibility of LLM-Cap2Skill approach and executable code generation
- Medium confidence in generalizability across different robotics platforms and domains
- Medium confidence in significant reduction of manual coding effort based on limited skill evaluation

## Next Checks
1. Evaluate the approach on diverse robotics platforms (e.g., industrial arms, drones) and different middleware frameworks beyond ROS 2
2. Conduct longitudinal studies measuring maintainability and debugging complexity of LLM-generated skills compared to manually written code
3. Test system performance under varying real-world conditions including edge cases, sensor noise, and environmental changes to assess robustness