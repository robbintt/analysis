---
ver: rpa2
title: 'ShareGPT-4o-Image: Aligning Multimodal Models with GPT-4o-Level Image Generation'
arxiv_id: '2506.18095'
source_url: https://arxiv.org/abs/2506.18095
tags:
- image
- generation
- arxiv
- chen
- janus-4o
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ShareGPT-4o-Image, a dataset of 91K high-quality
  synthetic image-text pairs distilled from GPT-4o-Image, aimed at democratizing advanced
  image generation capabilities for open-source models. The dataset includes 45K text-to-image
  and 46K text-and-image-to-image pairs, covering diverse visual content and editing
  tasks.
---

# ShareGPT-4o-Image: Aligning Multimodal Models with GPT-4o-Level Image Generation

## Quick Facts
- arXiv ID: 2506.18095
- Source URL: https://arxiv.org/abs/2506.18095
- Authors: Junying Chen; Zhenyang Cai; Pengcheng Chen; Shunian Chen; Ke Ji; Xidong Wang; Yunjin Yang; Benyou Wang
- Reference count: 32
- Introduces ShareGPT-4o-Image dataset of 91K high-quality synthetic image-text pairs distilled from GPT-4o-Image for democratizing advanced image generation capabilities

## Executive Summary
This paper presents ShareGPT-4o-Image, a dataset of 91K synthetic image-text pairs distilled from GPT-4o-Image, designed to democratize advanced image generation for open-source models. The dataset includes 45K text-to-image and 46K text-and-image-to-image pairs covering diverse visual content and editing tasks. Using this data, the authors fine-tune Janus-Pro to create Janus-4o, a multimodal model supporting both generation modes. The work demonstrates that high-quality synthetic data can effectively transfer proprietary model capabilities to open models, enabling scalable and efficient training of advanced multimodal generative systems.

## Method Summary
The authors generate a high-quality synthetic dataset by distilling GPT-4o-Image's capabilities, creating 91K image-text pairs split between text-to-image (45K) and text-and-image-to-image (46K) tasks. They fine-tune Janus-Pro using this dataset to create Janus-4o, which supports both generation modes. The training process is highly efficient, requiring only 6 hours on 8 GPUs. The synthetic data covers diverse visual content and editing tasks, enabling the open model to achieve capabilities approaching the proprietary source while maintaining computational efficiency.

## Key Results
- Janus-4o achieves +4 points improvement on GenEval benchmark over its predecessor
- Janus-4o shows +1.6 points improvement on DPG-Bench benchmark
- Excels in image editing tasks on ImgEdit-Bench despite training on only 91K samples
- Human evaluations favor Janus-4o's outputs for instruction fidelity and visual quality

## Why This Works (Mechanism)
The approach works by leveraging high-quality synthetic data distilled from a superior proprietary model (GPT-4o-Image) to transfer advanced capabilities to an open-source architecture. The synthetic data captures diverse visual content and editing tasks while maintaining instruction fidelity. The efficient training process (6 hours on 8 GPUs) demonstrates that targeted, high-quality data can achieve strong results without massive computational resources. The dual support for text-to-image and text-and-image-to-image generation provides versatility in real-world applications.

## Foundational Learning
- **Synthetic Data Distillation**: Generating training data from a superior model to transfer capabilities - needed for democratizing advanced features without proprietary data access; quick check: verify synthetic data quality matches or exceeds real data performance
- **Multimodal Fine-tuning**: Adapting vision-language models to specific generation tasks - needed for specialized performance in image generation; quick check: benchmark against baseline model on task-specific metrics
- **Efficient Training**: Achieving strong results with limited computational resources - needed for practical deployment; quick check: measure training time and GPU usage against performance gains
- **Dual-Modal Generation**: Supporting both text-to-image and image-to-image editing - needed for comprehensive creative applications; quick check: test both generation modes on diverse prompts
- **Benchmark Alignment**: Using standardized evaluation metrics (GenEval, DPG-Bench, ImgEdit-Bench) - needed for objective performance comparison; quick check: verify benchmark results are statistically significant
- **Human Preference Evaluation**: Incorporating subjective quality assessment - needed for real-world applicability; quick check: conduct blinded comparisons with baseline models

## Architecture Onboarding
**Component Map**: GPT-4o-Image (data source) -> Synthetic Data Generator -> ShareGPT-4o-Image Dataset -> Janus-Pro Fine-tuning -> Janus-4o Model
**Critical Path**: Data distillation → Dataset curation → Model fine-tuning → Benchmark evaluation → Human preference testing
**Design Tradeoffs**: Small dataset size (91K) vs. training efficiency (6 hours on 8 GPUs) vs. performance gains on benchmarks
**Failure Signatures**: Distribution shift between synthetic and real data, overfitting to GPT-4o-specific prompt styles, limited generalization to out-of-distribution prompts
**First Experiments**: 1) Test model on prompts outside training distribution, 2) Compare performance with varying dataset sizes, 3) Evaluate on real-world creative tasks beyond standard benchmarks

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Relatively small dataset size (91K samples) compared to typical large-scale training regimes, potentially limiting generalization
- Synthetic data nature raises questions about distribution shifts when applied to real-world use cases
- Evaluation focuses primarily on standard benchmarks without extensive ablation studies on dataset size or quality filtering
- Reliance on GPT-4o as sole data source introduces potential biases from its training distribution

## Confidence
- Capability transfer from proprietary to open models: Medium confidence - benchmark improvements demonstrated but long-term robustness uncertain
- Democratizing advanced image generation: High confidence for specific use case, Low confidence for broader industry impact due to proprietary data dependency
- Training efficiency claims (6 hours on 8 GPUs): High confidence as hardware-specific and measurable

## Next Checks
1. Conduct out-of-distribution testing with prompts from different domains than the training data to assess generalization limits
2. Perform an ablation study varying dataset size and quality filtering thresholds to identify optimal training configurations
3. Test the model's performance when fine-tuned on combined ShareGPT-4o-Image data with additional open datasets to evaluate complementary benefits