---
ver: rpa2
title: 'VideoHEDGE: Entropy-Based Hallucination Detection for Video-VLMs via Semantic
  Clustering and Spatiotemporal Perturbations'
arxiv_id: '2601.08557'
source_url: https://arxiv.org/abs/2601.08557
tags:
- clustering
- semantic
- video
- hallucination
- vase
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces VideoHEDGE, a modular framework for detecting
  hallucinations in video-capable vision-language models (Video-VLMs). By generating
  multiple high-temperature answers from clean and perturbed video clips, clustering
  the outputs semantically, and measuring entropy over these clusters, VideoHEDGE
  provides reliability estimates for video question answering.
---

# VideoHEDGE: Entropy-Based Hallucination Detection for Video-VLMs via Semantic Clustering and Spatiotemporal Perturbations

## Quick Facts
- arXiv ID: 2601.08557
- Source URL: https://arxiv.org/abs/2601.08557
- Reference count: 40
- Key outcome: VideoHEDGE achieves highest ROC-AUC for hallucination detection on SoccerChat using Vision-Amplified Semantic Entropy (VASE) with embedding clustering

## Executive Summary
This work introduces VideoHEDGE, a modular framework for detecting hallucinations in video-capable vision-language models (Video-VLMs). By generating multiple high-temperature answers from clean and perturbed video clips, clustering the outputs semantically, and measuring entropy over these clusters, VideoHEDGE provides reliability estimates for video question answering. Experiments on the SoccerChat benchmark show that Vision-Amplified Semantic Entropy (VASE), which leverages the gap between clean and perturbed semantic distributions, achieves the highest ROC-AUC for hallucination detection, especially with larger distortion budgets.

## Method Summary
VideoHEDGE detects hallucinations by sampling multiple high-temperature answers from both clean and perturbed video clips, clustering these answers semantically (via NLI or embeddings), and computing entropy-based metrics. The core innovation is VASE, which amplifies the semantic entropy signal by leveraging differences between clean and perturbed distributions. The framework uses photometric and spatiotemporal perturbations, cluster-level entropy aggregation, and reliability estimation through the gap between unperturbed and perturbed semantic distributions.

## Key Results
- Vision-Amplified Semantic Entropy (VASE) achieves highest ROC-AUC for hallucination detection on SoccerChat
- Embedding-based clustering matches NLI-based clustering in performance at far lower computational cost
- Domain fine-tuning reduces hallucination frequency but only modestly improves calibration
- VASE performance improves with larger distortion budgets (1→10 distortions increases AUC from 0.537 to 0.623)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Vision-Amplified Semantic Entropy (VASE) detects hallucinations by measuring how a model's semantic beliefs shift when visual evidence is degraded, with performance improving as distortion budgets increase.
- Mechanism: VASE computes entropy over a shifted distribution: `softmax(s_clean + α(s_clean - s_noisy))`. When a model's answer depends on fragile visual cues, perturbing the video (brightness, contrast, noise, hue) causes the semantic distribution to shift substantially, amplifying the entropy signal. Hallucinated answers that lack genuine visual grounding show larger clean-noisy gaps than grounded answers.
- Core assumption: Hallucinations arise from reliance on spurious visual features that are more sensitive to perturbations than genuine grounding signals. Assumption: The perturbations preserve semantic content while degrading visual artifacts.
- Evidence anchors:
  - [abstract] "VASE, which leverages the gap between clean and perturbed semantic distributions, achieves the highest ROC-AUC for hallucination detection, especially with larger distortion budgets."
  - [Section 3.3.4] "VASE is high when the model's semantic beliefs are both uncertain and unstable under changes to the video."
  - [Table 1] VASE improves from 0.537 (1 distortion) to 0.623 (10 distortions) on VideoQA with embedding clustering.
- Break condition: If the model has memorized domain-specific hallucinations that persist across all perturbations, the clean-noisy gap vanishes and VASE degrades to near-chance (SE levels). If perturbations destroy semantic content, both distributions shift uniformly and VASE loses discriminative power.

### Mechanism 2
- Claim: Semantic clustering captures equivalence classes of answers that differ in surface form but express the same underlying hypothesis, enabling cluster-level entropy to measure genuine uncertainty rather than lexical diversity.
- Mechanism: Answers are clustered via either (a) NLI-based entailment graphs where mutual entailment defines cluster membership, or (b) embedding-based similarity graphs with thresholded cosine similarity. Probability mass is aggregated per cluster, and entropy is computed over cluster-level distributions. This groups paraphrases ("goal", "ball went into net", "scored") into single hypotheses.
- Core assumption: Semantically equivalent answers should be treated as interchangeable for uncertainty estimation. Assumption: Short video QA answers cluster cleanly in either logical or embedding space.
- Evidence anchors:
  - [abstract] "embedding-based clustering matches NLI-based clustering in performance at far lower computational cost."
  - [Section 3.2] "Clusters correspond to connected components in G_sim."
  - [corpus] Related work on semantic entropy (Farquhar et al.) shows cluster-level entropy correlates with correctness in text tasks. Related HEDGE paper extends this to image VQA.
- Break condition: If answers require fine-grained distinctions (e.g., "foul by #7" vs "foul by #10"), embedding clustering may conflate distinct hypotheses. If answers are contradictory but not captured by NLI (neutral relationships), logical clustering under-segments.

### Mechanism 3
- Claim: High-temperature sampling with multiple perturbations exposes epistemic uncertainty by forcing the model to generate from higher-variance regions of its output distribution.
- Mechanism: A baseline answer is drawn at low temperature (greedy), then multiple high-temperature samples are drawn from both clean and perturbed videos. High temperature increases variance in the answer distribution, while perturbations add variance in the visual input. The combination reveals whether the model has stable, grounded beliefs or is sampling from a flat, uncertain region.
- Core assumption: Correct answers have stable, low-entropy semantic distributions that persist across perturbations. Assumption: Temperature and perturbations are sufficient to explore the relevant uncertainty space without inducing distributional collapse.
- Evidence anchors:
  - [Section 3.1] "draws a baseline answer and multiple high-temperature generations from both clean clips and photometrically and spatiotemporally perturbed variants."
  - [Section 5] "SE and RadFlag fluctuate mildly around chance (roughly 0.50-0.56) across the entire sweep [of distortion budgets], showing little sensitivity to the perturbation budget" — clean-only uncertainty fails when hallucinations are high-confidence.
  - [corpus] Related work on perturbation-based UQ (SPUQ, Gao et al.) shows similar principles for LLMs.
- Break condition: If the model is severely miscalibrated and produces confident wrong answers consistently, high-temperature sampling won't help. If temperature is too high, outputs may become incoherent and clustering fails.

## Foundational Learning

- Concept: **Semantic entropy vs token-level entropy**
  - Why needed here: VideoHEDGE operates on cluster-level entropy, not token probabilities. Understanding why grouping equivalent answers matters is essential for interpreting the metrics.
  - Quick check question: If a model outputs "goal", "GOAL!", and "it's a goal" with equal probability, what is the token-level entropy vs the semantic entropy?

- Concept: **Natural Language Inference (NLI) for entailment**
  - Why needed here: NLI-based clustering uses entailment and contradiction labels to build logical clusters. You need to understand how NLI models classify pairs as entails/contradicts/neutral.
  - Quick check question: Given "A: The player scored a goal" and "B: The ball entered the net", would an NLI model predict entailment, contradiction, or neutral?

- Concept: **High-temperature sampling in language models**
  - Why needed here: VideoHEDGE uses high-temperature generations to sample diverse answers. Temperature controls the sharpness of the output distribution.
  - Quick check question: What happens to output diversity as temperature approaches 0? As temperature approaches infinity?

## Architecture Onboarding

- Component map: Video+Question → Perturbations → Multi-sample generation → Clustering → Metric computation → Hallucination score
- Critical path: Video+Question → Perturbations → Multi-sample generation → Clustering → Metric computation → Hallucination score
- Design tradeoffs:
  - NLI clustering: Higher precision (explicit entailment logic), O(n² T_NLI) cost, prohibitive beyond ~5 distortions
  - Embedding clustering: ~100× faster, near-equivalent AUC on SoccerChat, requires threshold tuning (τ validated on split)
  - Distortion budget: More distortions improve VASE but with diminishing returns; best AUC at 6-10 distortions in experiments
  - Frame count: 12-24 frames sufficient; 30 frames showed slight performance drop (possibly due to attention dispersion)
  - Resolution: <40,000 pixels degrades accuracy and detectability; 100,000-250,000 pixels recommended
- Failure signatures:
  - SE/RadFlag near 0.5 with high hallucination rate → model produces confident wrong answers consistently (clean-only uncertainty fails)
  - VASE near 0.5 with large distortion budget → perturbations may be destroying semantic content or model has memorized hallucinations
  - NLI clustering OOM at scale → switch to embedding backend or reduce distortion budget
  - Cluster fragmentation (too many singletons) → lower embedding threshold τ; over-clustering → raise τ
  - Adjudicator disagreement with human judgment → inspect evaluation prompt in Listing 2 for task-specific scoring criteria
- First 3 experiments:
  1. **Baseline reproducibility check**: Run VideoHEDGE on the provided SoccerChat subset (490 clips) with default settings (24 frames, 100,352 pixels, 5 distortions, embedding clustering). Verify VASE AUC ≈ 0.62-0.65 for SoccerChat-qwen2-vl.
  2. **Clustering backend comparison**: Run both NLI and embedding clustering on the same samples with distortion budget = 3. Measure (a) ROC-AUC difference, (b) GPU time and memory. Confirm embedding clustering is within 0.02 AUC of NLI.
  3. **Distortion budget sweep**: Run VASE with distortion budgets {1, 3, 5, 7, 10} on a held-out subset. Plot ROC-AUC vs distortions to confirm the paper's finding that VASE improves with budget while SE/RadFlag remain flat.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can integrating reliability-aware objectives into Video-VLM training bridge the gap between reduced hallucination frequency and improved calibration?
- Basis in paper: [explicit] The conclusion states that standard domain fine-tuning reduces hallucination frequency but yields only "modest improvements in calibration," suggesting future work should explore "integrating reliability-aware objectives into training."
- Why unresolved: The current experiments only evaluate post-hoc reliability estimation on pre-trained or standard fine-tuned models without modifying training loss functions to penalize overconfidence.
- What evidence would resolve it: Experiments comparing Video-VLMs trained with uncertainty-aware loss functions against standard fine-tuning, measuring both accuracy and ROC-AUC of metrics like VASE.

### Open Question 2
- Question: Does replacing the LLM-as-a-judge with human adjudication significantly alter the correlation between VASE scores and ground-truth hallucinations?
- Basis in paper: [explicit] The authors note the reliance on an LLM adjudicator as a limitation and explicitly list "incorporating human adjudication to further validate" as a direction for future work.
- Why unresolved: The binary labels used to calculate ROC-AUC were generated by Qwen3-30B-A3B, which may suffer from its own biases or inconsistencies when evaluating video grounding.
- What evidence would resolve it: A comparative study evaluating the correlation of VASE scores against both LLM-generated labels and a gold-standard dataset labeled by human experts.

### Open Question 3
- Question: Do expanded perturbation families (e.g., temporal shuffling or structural distortions) provide more discriminative signals for VASE than the photometric perturbations used here?
- Basis in paper: [explicit] The conclusion lists "broadening the family of perturbations" as a necessary step to address the "noisy trends" and moderate AUC values observed with the current photometric shifts.
- Why unresolved: The current work limits perturbations to photometric shifts (brightness, contrast) and noise, potentially missing semantic drifts caused by temporal or structural disruptions.
- What evidence would resolve it: Evaluating VideoHEDGE with diverse perturbation types to determine if semantic entropy distributions diverge more sharply for hallucinations under structural degradation.

## Limitations

- Limited domain specificity and generalizability - Framework demonstrates strong performance on SoccerChat but effectiveness on other video domains remains uncertain
- Computational scalability concerns - NLI-based clustering becomes prohibitive beyond 5 distortions due to O(n² T_NLI) complexity
- Sensitivity to perturbation parameters - Performance depends critically on choice of photometric transformations, perturbation intensity, and frame sampling strategy

## Confidence

- High confidence: The core mechanism of VASE (leveraging clean-noisy semantic gaps) and its superior performance on SoccerChat with increasing distortion budgets
- Medium confidence: The computational advantage of embedding clustering over NLI clustering and the diminishing returns of distortion budgets beyond 6-10 perturbations
- Medium confidence: The finding that domain fine-tuning reduces hallucination frequency but only modestly improves calibration

## Next Checks

1. **Cross-domain transferability test**: Apply VideoHEDGE to a non-sports video QA benchmark (e.g., ActivityNet-QA or HowTo100M) with identical configuration. Compare VASE performance to the SoccerChat results to assess domain generalizability and identify whether domain-specific fine-tuning becomes necessary.

2. **Perturbation sensitivity analysis**: Systematically vary individual perturbation types (brightness, contrast, noise) and their intensity ranges. Measure VASE sensitivity to each perturbation type and determine whether certain transformations are more effective at exposing specific hallucination patterns.

3. **Real-time deployment feasibility study**: Profile GPU memory and inference time for the complete VideoHEDGE pipeline (including multi-sample generation, clustering, and metric computation) on hardware representative of edge deployment scenarios. Identify bottlenecks and assess whether the framework can operate within real-time constraints for interactive video applications.