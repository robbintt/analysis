---
ver: rpa2
title: Factors affecting the in-context learning abilities of LLMs for dialogue state
  tracking
arxiv_id: '2506.08753'
source_url: https://arxiv.org/abs/2506.08753
tags:
- dialogue
- demonstrations
- user
- learning
- computational
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates in-context learning for dialogue state
  tracking (DST) using nearest-neighbor demonstration retrieval. The proposed method
  employs sentence embeddings to select relevant dialogue turns as demonstrations,
  which are structured with a modular prompt template containing conversation history,
  domain, and slot-value pairs.
---

# Factors affecting the in-context learning abilities of LLMs for dialogue state tracking

## Quick Facts
- **arXiv ID:** 2506.08753
- **Source URL:** https://arxiv.org/abs/2506.08753
- **Authors:** Pradyoth Hegde; Santosh Kesiraju; Jan Švec; Šimon Sedláček; Bolaji Yusuf; Oldřich Plchot; Deepak K T; Jan Černocký
- **Reference count:** 0
- **Primary result:** In-context learning for dialogue state tracking is improved by user-only utterance embeddings, LaBSE retrieval, and constrained decoding.

## Executive Summary
This paper investigates how to optimize in-context learning for dialogue state tracking (DST) by retrieving relevant demonstrations using nearest-neighbor embedding search. The proposed method retrieves dialogue turns as demonstrations, structures them in a modular prompt, and evaluates performance on MultiWOZ 2.4 using three instruction-tuned LLMs. The study finds that using only user utterances for embeddings yields better performance than including agent turns, that LaBSE embeddings outperform dialogue-specific embeddings for slot relevance and coverage, and that speaker tags have a minor but measurable impact. Precision and recall for slot value prediction reach approximately 67-73% and 79-83% respectively, with optimal performance achieved using 3-10 demonstrations.

## Method Summary
The study proposes an in-context learning approach for dialogue state tracking that retrieves relevant demonstrations from training data using nearest-neighbor embedding search. The system uses sentence embeddings (LaBSE or Dialog2Flow) to select dialogue turns as demonstrations, which are structured with a modular prompt template containing conversation history, domain, and slot-value pairs. The approach was evaluated on the MultiWOZ2.4 dataset using OLMo-7B-Instruct, Mistral-7B-Instruct, and Llama3.2-3B-Instruct models. The evaluation focused on slot-level precision and recall metrics, comparing different embedding strategies, prompt configurations, and decoding approaches.

## Key Results
- Using only user utterances for embedding retrieval yields better DST performance than including both user and agent turns
- LaBSE embeddings achieve better dialogue state tracking performance than Dialog2Flow due to higher slot relevance and coverage
- Constrained decoding (predicting values given keys) significantly outperforms unconstrained slot key-value generation in recall
- Optimal performance achieved using 3-10 demonstrations, with diminishing returns beyond 10

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Retrieving demonstrations based solely on user utterances yields better DST performance than using full user-agent dialogue history.
- **Mechanism:** User utterances provide a denser semantic signal for the specific intent and slot updates required at that turn. Including agent responses may dilute this signal or introduce noise from previous turns, reducing the retriever's ability to find semantically similar state-change patterns.
- **Core assumption:** The critical information for determining the current state is encoded primarily in the user's latest request rather than the conversational context.
- **Evidence anchors:** Using only user utterances for embeddings yields better performance than including both user and agent turns; Computing embeddings using only the user's utterances consistently outperforms using the full user-agent dialogue turns.

### Mechanism 2
- **Claim:** General-purpose multilingual embeddings (LaBSE) outperform dialogue-specific embeddings (D2F) in low-data regimes due to higher slot relevance and coverage.
- **Mechanism:** While D2F is tuned for dialogue acts, LaBSE's training on parallel multilingual data captures surface-level semantic similarities that align better with specific slot values needed for the test sample, resulting in retrieved demonstrations that share more "slot keys" with the ground truth.
- **Core assumption:** The utility of a demonstration is determined more by the overlap of specific slot keys than by the similarity of high-level dialogue acts.
- **Evidence anchors:** LaBSE-based retrievers achieve better DST performance due to higher slot relevance and coverage; demonstrations retrieved using LaBSE exhibit better slot relevance and coverage compared to those retrieved using D2F.

### Mechanism 3
- **Claim:** Constrained decoding significantly outperforms unconstrained slot key-value generation in recall.
- **Mechanism:** By restricting the output space to filling predefined slot values, the model avoids hallucinating incorrect slot keys or failing to generate the required JSON schema structure, forcing the LLM to act as a classifier/filler rather than a generative architect.
- **Core assumption:** The model understands the instruction to fill values but struggles to maintain the strict structural constraints of the JSON schema when generating keys and values freely.
- **Evidence anchors:** Slot key-value generation exhibits significantly lower recall due to higher error rate with respect to ground truth (Recall drops from 78.3% to 53.3%).

## Foundational Learning

- **Concept:** k-Nearest Neighbors (k-NN) for Semantic Retrieval
  - **Why needed here:** The system relies on pre-computed embeddings to find the most relevant "demonstrations" from a training pool to teach the LLM contextually.
  - **Quick check question:** Can you explain why cosine similarity is used to compare vectors rather than Euclidean distance for high-dimensional sentence embeddings?

- **Concept:** Dialogue State Tracking (DST) Schema
  - **Why needed here:** The paper evaluates performance based on precision/recall against a ground truth consisting of Domain-Slot-Value pairs.
  - **Quick check question:** In a "restaurant" domain, what is the difference between a slot key (e.g., "price_range") and a slot value (e.g., "expensive")?

- **Concept:** Constrained Decoding
  - **Why needed here:** The paper highlights a massive performance delta between letting the LLM generate freely vs. forcing it to fill specific slots.
  - **Quick check question:** How does masking the logits of invalid tokens ensure the model outputs a valid JSON key?

## Architecture Onboarding

- **Component map:** Embedding Store -> Retriever -> Prompt Constructor -> LLM Inference -> Decoder
- **Critical path:** The transition from Retrieval to Prompt Construction is the highest-leverage area. If the retrieved demonstrations lack "slot coverage," the LLM has no pattern to mimic, regardless of the prompt template.
- **Design tradeoffs:**
  - User-only embeddings improve precision/recall but may lose context in ambiguous multi-turn dialogues
  - LaBSE offers better coverage with fewer shots; D2F is competitive only with many shots, likely due to token limit trade-offs
  - Increasing from 3 to 10 demonstrations shows diminishing returns for some models but steady gains for others, creating a context-window vs. accuracy trade-off
- **Failure signatures:**
  - Low Recall (<60%): Check if "Slot key-value generation" is enabled; switch to constrained decoding
  - Low Precision: Check if Speaker Tags are missing; presence can slightly lower precision
  - Stagnation with more data: If adding demonstrations (>3) doesn't help, verify the embedding model is LaBSE
- **First 3 experiments:**
  1. Retrieval Ablation: Run inference using User-only embeddings vs. User-Agent embeddings with k=3. Verify if User-only precision > User-Agent precision
  2. Shot Scaling: Plot performance for k=1, 3, 5, 10 on OLMo. Confirm if recall drops as precision rises with more demonstrations
  3. Decoding Stress Test: Compare constrained decoding (predict value) vs. generative decoding (predict key+value). Expect a recall gap of ~25%

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the user-utterance-based retrieval strategy perform on out-of-domain (OOD) or cross-domain dialogue state tracking tasks?
- **Basis in paper:** [explicit] The authors state in the introduction: "This study focuses exclusively on in-domain examples."
- **Why unresolved:** The experimental scope was restricted to in-domain scenarios, leaving the generalizability of the findings (specifically that user-only embeddings are superior) untested for domains or slots not present in the demonstration pool.
- **What evidence would resolve it:** Evaluation of the proposed ICL setup on established OOD benchmarks to compare the robustness of user-only versus user-agent embedding strategies.

### Open Question 2
- **Question:** Can specific prompt engineering or formatting strategies improve the poor zero-shot performance observed in this study?
- **Basis in paper:** [explicit] The authors note: "Due to the poor performance of zero-shot prompting in our format, we limit our investigation to demonstration-based DST."
- **Why unresolved:** The paper does not investigate why the specific modular template failed for zero-shot inference, nor does it explore alternative instructions or structural variations that might mitigate this failure.
- **What evidence would resolve it:** A systematic ablation of the prompt template applied to zero-shot settings to determine if effective state tracking is possible without demonstrations.

### Open Question 3
- **Question:** Can a retrieval mechanism be designed to explicitly optimize the trade-off between slot relevance and coverage?
- **Basis in paper:** [inferred] The analysis shows that as the number of demonstrations increases, coverage increases but relevance decreases. The paper notes LaBSE's success is linked to better balancing these metrics compared to D2F.
- **Why unresolved:** The current k-NN approach relies purely on semantic similarity, which creates a trade-off rather than a synergy between finding relevant slots and covering all necessary slots.
- **What evidence would resolve it:** Developing a retrieval objective that maximizes a composite metric of relevance and coverage, and testing if this yields higher DST accuracy than pure cosine similarity.

### Open Question 4
- **Question:** How can decoding strategies be refined to combine the high precision of slot key-value generation with the high recall of constrained value prediction?
- **Basis in paper:** [inferred] Table 6 shows a distinct dichotomy: slot key-value generation yields 69.2% precision but only 53.3% recall, whereas predicting values given keys yields lower precision but 78.3% recall.
- **Why unresolved:** The paper presents this trade-off but does not propose a method to mitigate the low recall associated with the generative approach or the precision limits of the constrained approach.
- **What evidence would resolve it:** Experiments using hybrid decoding or iterative refinement strategies to see if the generative approach can be encouraged to achieve higher recall.

## Limitations

- The findings are based on experiments with a single dataset (MultiWOZ 2.4) and three relatively small instruction-tuned LLMs, which may not generalize to larger models or datasets with different characteristics.
- The evaluation assumes access to ground-truth domain information during inference, which may not hold in real-world applications.
- The constrained decoding approach requires predefined slot keys and may not scale to dynamic or unseen domains.

## Confidence

- **High confidence:** The effectiveness of user-only embeddings for retrieval and the superiority of constrained decoding over unconstrained generation are well-supported by ablation studies.
- **Medium confidence:** The advantage of LaBSE over D2F for low-shot retrieval is supported by the data, but the mechanism (slot relevance vs. coverage) is inferred rather than directly measured.
- **Low confidence:** The impact of speaker tags is described as "minor but measurable," but the ablation results show inconsistent effects across metrics.

## Next Checks

1. **Generalization to larger models:** Evaluate the proposed retrieval and prompting strategies with larger LLMs (e.g., GPT-4, Claude) to assess scalability and performance ceilings.
2. **Dynamic domain evaluation:** Test the system's robustness when domain information is not provided, simulating real-world deployment scenarios.
3. **Cross-dataset validation:** Apply the methodology to other DST datasets (e.g., MultiWOZ 2.1, Schema-Guided Dialogue) to verify the generalizability of the findings.