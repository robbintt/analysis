---
ver: rpa2
title: 'High-dimensional limit theorems for SGD: Momentum and Adaptive Step-sizes'
arxiv_id: '2511.03952'
source_url: https://arxiv.org/abs/2511.03952
tags:
- lemma
- dynamics
- fixed
- proof
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper establishes high-dimensional scaling limits for Stochastic
  Gradient Descent with Polyak Momentum (SGD-M) and adaptive step-size methods, providing
  a rigorous framework to compare these algorithms in the critical scaling regime
  where dimension and step-size both tend to zero. The authors show that SGD-M dynamics,
  after appropriate time rescaling and step-size adjustment, can replicate online
  SGD behavior, but when using the same step-size, momentum amplifies high-dimensional
  effects and potentially degrades performance.
---

# High-dimensional limit theorems for SGD: Momentum and Adaptive Step-sizes

## Quick Facts
- **arXiv ID:** 2511.03952
- **Source URL:** https://arxiv.org/abs/2511.03952
- **Reference count:** 40
- **Primary result:** Establishes high-dimensional scaling limits for SGD with Polyak Momentum and adaptive step-size methods, showing how momentum amplifies high-dimensional effects while gradient normalization broadens convergence regimes.

## Executive Summary
This paper establishes rigorous high-dimensional scaling limits for Stochastic Gradient Descent with Polyak Momentum (SGD-M) and gradient normalization (SGD-U), demonstrating how these algorithms behave when both dimension and step-size tend to zero at critical rates. The authors show that while SGD-M dynamics can replicate online SGD behavior after appropriate rescaling, using the same step-size amplifies high-dimensional effects and may degrade performance. For adaptive methods, they prove that gradient normalization (SGD-U) leads to dynamics converging to fixed points closer to the population minimum and significantly expands the range of admissible step-sizes ensuring convergence. The framework is applied to spiked tensor PCA and single-index models, providing theoretical justification for how early preconditioners can stabilize learning dynamics and mitigate exploding or vanishing gradients.

## Method Summary
The paper analyzes SGD dynamics in the high-dimensional limit using stochastic differential equations. For SGD-M, the algorithm uses Polyak momentum with updates $p_\ell = \beta p_{\ell-1} - \delta_n \nabla L$ and $x_\ell = x_{\ell-1} + p_\ell$. For SGD-U, a gradient normalization preconditioner $\eta = \sqrt{n}/\|\nabla L\|$ is applied. The critical scaling regime assumes step-size $\delta_n = c_\delta / n$ where both dimension $n$ and step-size tend to zero. The theoretical framework derives effective dynamics in terms of overlap $m = \langle x, v \rangle$ and orthogonal norm $r^2_\perp = \|x - mv\|^2$, with proofs relying on random matrix theory and statistical mechanics techniques. Numerical validation is performed on synthetic data from spiked tensor PCA ($k=2$) and single-index models with link functions $f(x)=x^k$.

## Key Results
- SGD-M dynamics, after time rescaling and step-size adjustment, can replicate online SGD behavior, but using identical step-sizes amplifies high-dimensional effects and potentially degrades performance.
- SGD with gradient normalization (SGD-U) yields dynamics converging to fixed points closer to the population minimum compared to vanilla SGD.
- Adaptive preconditioning in SGD-U significantly broadens the range of admissible step-sizes that ensure convergence, stabilizing learning in high-dimensional regimes.
- The theoretical framework is validated on spiked tensor PCA and single-index models, rigorously justifying how early preconditioners can stabilize learning dynamics.

## Why This Works (Mechanism)
The mechanism relies on the critical scaling regime where step-size scales as $1/n$, allowing the high-dimensional noise to be properly balanced against the signal. In this regime, the effective dynamics are governed by a stochastic differential equation where the drift term includes both the population gradient and a high-dimensional corrector that captures the interaction between noise and geometry. For momentum methods, the amplification factor $(1-\beta)^{-1}$ magnifies both the signal and the corrector, explaining why momentum can degrade performance when not properly rescaled. For adaptive methods like SGD-U, the normalization pre-conditioner effectively rescales the noise to maintain stability across a wider range of step-sizes.

## Foundational Learning
- **Critical scaling regime:** Understanding when step-size scales as $1/n$ is essential because it determines whether high-dimensional effects dominate the dynamics or remain perturbative. Quick check: Verify that simulations use $\delta = c_\delta/n$ rather than fixed $\delta$.
- **High-dimensional corrector:** The corrector term in the effective dynamics captures how noise interacts with the geometry of the loss landscape in high dimensions. Quick check: Examine whether $|m(t)/R(t)|$ curves show the characteristic plateau behavior predicted by theory.
- **Momentum amplification:** The factor $(1-\beta)^{-1}$ amplifies both the signal and noise in high dimensions, requiring careful rescaling to maintain performance. Quick check: Compare $|m(t)/R(t)|$ trajectories for different $\beta$ values with identical step-sizes.
- **Gradient normalization:** The scalar pre-conditioner $\eta = \sqrt{n}/\|\nabla L\|$ effectively rescales the noise to maintain stability across a wider range of step-sizes. Quick check: Verify that SGD-U trajectories remain bounded for larger $c_\delta$ values than vanilla SGD.

## Architecture Onboarding

**Component Map:** Data Generation -> Loss Computation -> Gradient Computation -> Update Rule (SGD/SGD-M/SGD-U) -> Trajectory Monitoring

**Critical Path:** The critical path is the sequence from gradient computation through the update rule to trajectory monitoring, as this determines whether the algorithm converges to the desired fixed point and maintains stability in the high-dimensional regime.

**Design Tradeoffs:** The paper trades computational simplicity (vanilla SGD) for stability and convergence quality (SGD-U). While SGD-M can accelerate convergence in low dimensions, it amplifies high-dimensional effects that may degrade performance unless properly rescaled. The adaptive preconditioning in SGD-U adds computational overhead but significantly broadens the stable step-size regime.

**Failure Signatures:** 
- Sub-critical scaling (fixed step-size) results in dynamics that miss high-dimensional corrector effects
- Vanilla SGD diverges for high-degree link functions in single-index models
- Momentum amplifies noise in high dimensions, potentially degrading performance
- Incorrect initialization distribution can lead to trajectories that don't match theoretical predictions

**3 First Experiments:**
1. Implement Matrix PCA data generation ($Y = \lambda v v^T + W$) and vanilla SGD with critical scaling to establish baseline behavior
2. Add SGD-M implementation and compare $|m(t)/R(t)|$ trajectories against vanilla SGD to observe momentum amplification effects
3. Implement SGD-U and verify stability for larger step-sizes by monitoring whether gradients remain bounded

## Open Questions the Paper Calls Out
- **Open Question 1:** Do the high-dimensional scaling limits derived for the specific gradient normalization pre-conditioner (SGD-U) extend to adaptive algorithms that utilize running averages of moments, such as Adam or RMSProp? The current framework relies on the specific structure of the scalar pre-conditioner and doesn't cover the non-Markovian dependencies introduced by exponential moving averages in Adam.
- **Open Question 2:** How do the scaling limits and population corrector effects differ for Nesterov momentum compared to the Polyak momentum analyzed in Theorem 2.3? The "lookahead" property of Nesterov momentum may modify how the gradient interacts with the population corrector at critical scaling.
- **Open Question 3:** Does the "universality" of the SGD-U dynamics observed for strictly increasing link functions in Proposition 3.9 persist for non-monotonic or non-smooth link functions in single-index models? The sign function simplifications used in the proof fail for non-monotonic functions, potentially leading to different limiting behavior.

## Limitations
- The critical scaling assumption (step-size proportional to 1/n) is essential for theoretical results but may not reflect practical implementations where step-size schedules differ
- The analysis assumes specific initialization conditions (spherical Gaussian) that may not generalize to all practical scenarios
- Results are asymptotic and may have limited predictive power for finite-dimensional systems
- The framework is currently limited to specific pre-conditioners and doesn't cover more complex adaptive methods like Adam

## Confidence
- **High Confidence:** The mathematical derivations for scaling limits and comparison between SGD-M and online SGD under critical scaling
- **Medium Confidence:** The numerical simulations demonstrating theoretical predictions, particularly stability analysis for SGD-U
- **Medium Confidence:** Claims about momentum amplifying high-dimensional effects, requiring careful numerical verification

## Next Checks
1. **Reproduce the numerical stability threshold:** Implement an automated procedure to determine the smallest $c_\delta$ value where gradients remain bounded for SGD-U on single-index models
2. **Test alternative initialization schemes:** Verify whether theoretical predictions hold when initializing from distributions other than spherical Gaussian
3. **Compare with non-critical scaling:** Implement and analyze dynamics under fixed step-sizes to quantify differences from critical scaling regime