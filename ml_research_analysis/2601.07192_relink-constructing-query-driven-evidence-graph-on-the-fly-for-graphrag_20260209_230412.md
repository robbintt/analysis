---
ver: rpa2
title: 'Relink: Constructing Query-Driven Evidence Graph On-the-Fly for GraphRAG'
arxiv_id: '2601.07192'
source_url: https://arxiv.org/abs/2601.07192
tags:
- knowledge
- relink
- reasoning
- graph
- facts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Relink addresses the limitations of static knowledge graphs in
  GraphRAG by introducing a dynamic, query-specific evidence graph construction paradigm.
  Instead of reasoning over pre-built graphs, Relink leverages both explicit factual
  relations and latent textual relations to dynamically instantiate missing links
  and filter distractor facts.
---

# Relink: Constructing Query-Driven Evidence Graph On-the-Fly for GraphRAG

## Quick Facts
- arXiv ID: 2601.07192
- Source URL: https://arxiv.org/abs/2601.07192
- Reference count: 16
- Primary result: Achieves 5.4% EM and 5.2% F1 improvement over leading GraphRAG methods on ODQA benchmarks

## Executive Summary
Relink introduces a dynamic approach to evidence graph construction for GraphRAG systems, addressing the limitations of static knowledge graphs in handling incomplete or noisy information. The method constructs query-specific evidence graphs on-the-fly by combining explicit factual relations with latent textual relations, enabling dynamic instantiation of missing links and filtering of distractor facts. This query-driven paradigm allows for real-time repair of reasoning paths using a query-aware ranker and LLM-based instantiation, significantly improving robustness and accuracy compared to static approaches.

## Method Summary
Relink operates by constructing evidence graphs dynamically at query time rather than relying on pre-built static graphs. The system leverages both explicit factual relations (from knowledge bases) and latent textual relations (extracted from unstructured text) to instantiate missing links and filter irrelevant information. A query-aware ranker evaluates and prioritizes potential connections, while LLM-based mechanisms handle the instantiation of new links based on the specific query context. This approach enables the system to repair reasoning paths on-the-fly and adapt to the specific requirements of each query, rather than being constrained by the limitations of a static knowledge graph structure.

## Key Results
- Achieves average 5.4% improvement in Exact Match (EM) metric over leading GraphRAG methods
- Demonstrates 5.2% improvement in F1 score across five ODQA benchmarks
- Shows superior robustness to knowledge incompleteness and distractor noise compared to static graph approaches

## Why This Works (Mechanism)
The effectiveness of Relink stems from its ability to dynamically construct query-specific evidence graphs that directly address the information needs of each query. By combining explicit factual relations with latent textual relations, the system can instantiate missing links that static graphs cannot provide. The query-aware ranker ensures that only relevant information is incorporated, filtering out distractor facts that would otherwise degrade performance. The LLM-based instantiation mechanism allows for flexible handling of complex relationships that may not be captured in traditional knowledge bases, while the on-the-fly construction paradigm ensures that the evidence graph is optimally tailored to each specific query context.

## Foundational Learning

### Knowledge Graph Reasoning
- Why needed: Traditional static graphs cannot handle missing links or adapt to query-specific contexts
- Quick check: Verify that the system can identify and repair broken reasoning paths in incomplete knowledge graphs

### Latent Textual Relation Extraction
- Why needed: Unstructured text contains valuable relational information not captured in explicit knowledge bases
- Quick check: Confirm that the system can extract meaningful relations from raw text passages

### Query-Aware Ranking
- Why needed: Prevents distractor facts from degrading reasoning quality while prioritizing relevant information
- Quick check: Test that the ranker correctly identifies and prioritizes query-relevant facts over irrelevant ones

## Architecture Onboarding

### Component Map
Document Store -> Explicit Relations Extractor -> Latent Relations Extractor -> Query-Aware Ranker -> LLM-based Link Instantiation -> Evidence Graph Builder -> Reasoning Engine

### Critical Path
Query → Explicit Relations Extraction → Latent Relations Extraction → Query-Aware Ranking → LLM-based Instantiation → Evidence Graph Construction → Answer Generation

### Design Tradeoffs
The paper balances computational overhead from on-the-fly construction against improved accuracy and robustness. While static graphs offer faster query processing, they cannot adapt to incomplete or noisy information. Relink's dynamic approach sacrifices some latency for significantly better handling of knowledge gaps and distractor filtering, with the LLM-based instantiation providing flexibility at the cost of potential hallucinatory outputs that are mitigated through the query-aware filtering mechanism.

### Failure Signatures
Potential failure modes include excessive computational overhead during query-time graph construction, LLM hallucination introducing incorrect facts, and the ranker failing to properly filter distractor information. The system may also struggle with extremely sparse knowledge graphs where insufficient explicit or latent relations exist to construct meaningful evidence paths.

### First Experiments
1. Test Relink on a simple ODQA task with a known knowledge gap to verify that the system can instantiate missing links correctly
2. Evaluate the query-aware ranker's ability to filter distractor facts in a controlled setting with mixed relevant/irrelevant information
3. Measure the computational overhead of on-the-fly graph construction versus static graph approaches on a medium-sized knowledge base

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided text.

## Limitations
- Computational overhead from query-time graph construction may limit scalability to very large knowledge bases
- Reliance on LLM-based instantiation introduces potential for hallucinatory facts despite filtering mechanisms
- Evaluation focused primarily on ODQA benchmarks, leaving performance on other reasoning tasks uncertain

## Confidence

**High confidence:** Core technical contribution of dynamic evidence graph construction and reported performance improvements over baseline methods

**Medium confidence:** Generalizability of results to non-ODQA domains and scalability to very large knowledge graphs

**Low confidence:** Long-term reliability of LLM-based instantiation without explicit validation mechanisms, and handling of conflicting information when multiple instantiation paths exist

## Next Checks

1. Test Relink on multi-domain datasets beyond ODQA to evaluate cross-domain robustness and identify any task-specific limitations

2. Conduct ablation studies removing the LLM-based instantiation component to quantify its contribution versus using only explicit relations

3. Perform runtime analysis comparing Relink's query-time construction overhead against static graph approaches, particularly for large-scale knowledge bases