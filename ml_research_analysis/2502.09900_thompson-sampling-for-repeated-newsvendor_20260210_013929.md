---
ver: rpa2
title: Thompson Sampling for Repeated Newsvendor
arxiv_id: '2502.09900'
source_url: https://arxiv.org/abs/2502.09900
tags:
- demand
- regret
- lemma
- distribution
- newsvendor
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies Thompson Sampling (TS) for the repeated newsvendor
  problem, a classic framework in inventory management. The challenge is to learn
  an unknown demand distribution while minimizing inventory costs under censored feedback,
  where only sales up to the order quantity are observed.
---

# Thompson Sampling for Repeated Newsvendor
## Quick Facts
- arXiv ID: 2502.09900
- Source URL: https://arxiv.org/abs/2502.09900
- Reference count: 40
- Thompson Sampling achieves optimal (up to logarithmic factors) frequentist regret bounds for repeated newsvendor with Weibull demand

## Executive Summary
This paper investigates Thompson Sampling (TS) for the repeated newsvendor problem, where an agent must learn an unknown demand distribution while minimizing inventory costs under censored feedback. The challenge arises because only sales up to the order quantity are observed, making demand estimation difficult. TS is proposed to dynamically adjust order quantities by sampling from a posterior distribution initialized with a Gamma prior. The analysis establishes optimal frequentist regret bounds under Weibull demand and extends to general parametric distributions using Kaplan-Meier estimators. Extensive experiments demonstrate TS outperforms conservative approaches like online convex optimization, UCB, and myopic Bayesian dynamic programming.

## Method Summary
The paper proposes using Thompson Sampling for the repeated newsvendor problem, where an agent orders quantities from an unknown demand distribution and observes only censored feedback. A Gamma prior is placed on the demand parameter, and at each period, TS samples from the posterior to determine the order quantity. This balances exploration and exploitation: when past orders are large, TS accurately estimates demand parameters for near-optimal ordering; when past orders are small, it increases future order quantities to gather more information. The method is analyzed under Weibull demand distributions, establishing optimal (up to logarithmic factors) frequentist regret bounds. For general parametric demand distributions, Bayesian regret bounds are derived using Kaplan-Meier estimators to handle censored observations.

## Key Results
- TS achieves optimal (up to logarithmic factors) frequentist regret bounds for Weibull demand distributions
- TS automatically balances exploration and exploitation: increases orders when under-explored, orders near-optimally when well-explored
- Extensive numerical experiments show TS outperforms online convex optimization, UCB, and myopic Bayesian dynamic programming

## Why This Works (Mechanism)
Thompson Sampling works by maintaining a posterior distribution over the unknown demand parameter and sampling from this posterior to make ordering decisions. This creates an automatic exploration-exploitation trade-off: when the posterior is wide (high uncertainty), sampled values vary widely, leading to more exploration; when the posterior is narrow (low uncertainty), sampled values cluster near the mean, leading to exploitation of current knowledge. The censored feedback structure is handled through the posterior update mechanism, which accounts for only observing sales up to the order quantity.

## Foundational Learning
- Censored feedback in inventory systems: Needed to understand why standard demand estimation fails and how partial observations affect learning
- Quick check: Verify that observed sales ≤ order quantity and true demand is only partially revealed
- Gamma conjugate prior for Weibull demand: Needed for tractable posterior updates in the TS algorithm
- Quick check: Confirm Gamma prior maintains conjugacy under Weibull likelihood with censored data
- Kaplan-Meier estimator for censored data: Needed to extend analysis to general parametric distributions
- Quick check: Ensure estimator properly handles the case where order quantity < true demand
- Regret analysis with censored observations: Needed to establish theoretical performance guarantees
- Quick check: Verify that regret bounds account for information loss from censoring

## Architecture Onboarding
Component map: Prior → Posterior sampling → Order quantity → Censored feedback → Posterior update → Prior
Critical path: TS samples from posterior → Places order → Observes censored sales → Updates posterior → Repeats
Design tradeoffs: TS provides automatic exploration-exploitation balance vs. UCB's explicit exploration bonus; TS handles censored feedback naturally vs. requiring modification for OCO methods
Failure signatures: Poor performance if prior is misspecified; slow learning if order quantities remain consistently too small; suboptimal performance if demand distribution is far from Weibull
First experiments:
1. Test TS with known demand distribution to verify it converges to optimal ordering
2. Compare TS performance under different prior hyperparameters
3. Evaluate information gain vs. regret trade-off by varying demand censoring levels

## Open Questions the Paper Calls Out
None specified in the provided material.

## Limitations
- Regret bounds are established specifically for Weibull demand distributions, with open questions about other parametric families
- Extension to general parametric distributions relies on Kaplan-Meier estimators, which may introduce additional complexity
- The specific behavior and tightness of bounds for non-Weibull distributions remain unverified

## Confidence
High: Optimal frequentist regret bounds under Weibull demand with rigorous analysis
Medium: Extension to general parametric distributions with theoretical framework but limited practical validation
Medium: Experimental comparisons against alternatives, though scope of tested distributions could be expanded

## Next Checks
1. Empirically evaluate TS performance under diverse demand distributions (e.g., Gamma, Log-normal, Pareto) to test the robustness of the general parametric framework
2. Conduct sensitivity analysis on prior hyperparameters to assess their impact on regret and learning speed
3. Compare TS against adaptive parametric methods that estimate demand online (e.g., maximum likelihood updates) to quantify the benefit of posterior sampling in this setting