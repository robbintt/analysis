---
ver: rpa2
title: 'SPARK: Search Personalization via Agent-Driven Retrieval and Knowledge-sharing'
arxiv_id: '2512.24008'
source_url: https://arxiv.org/abs/2512.24008
tags:
- memory
- spark
- retrieval
- personalization
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SPARK introduces a multi-agent architecture for personalized search
  that dynamically routes queries to specialized persona agents, each with dedicated
  long- and short-term memory stores. The system uses a Persona Coordinator to select
  appropriate agents and coordination protocols (independent, relay, or debate) based
  on query context and predicted difficulty.
---

# SPARK: Search Personalization via Agent-Driven Retrieval and Knowledge-sharing

## Quick Facts
- **arXiv ID**: 2512.24008
- **Source URL**: https://arxiv.org/abs/2512.24008
- **Reference count**: 40
- **Primary result**: Multi-agent architecture with cognitive memory separation, adaptive routing, and protocol coordination for personalized search

## Executive Summary
SPARK introduces a multi-agent architecture for personalized search that dynamically routes queries to specialized persona agents, each with dedicated long- and short-term memory stores. The system uses a Persona Coordinator to select appropriate agents and coordination protocols (independent, relay, or debate) based on query context and predicted difficulty. Drawing on cognitive architecture principles, SPARK separates working, episodic, and semantic memory to distinguish transient context from persistent user preferences. The framework employs adaptive routing via contextual bandits, structured agent collaboration, and Reciprocal Rank Fusion for result aggregation.

## Method Summary
SPARK defines personas as 4-tuples (role, expertise, task, domain) and routes queries using a contextual bandit (LinUCB) to select agents and coordination protocols. Each agent maintains tripartite memory: working (Ms) for transient state, episodic (Me) for recent interactions, and semantic (Msem) for long-term preferences. The system executes RAG loops with web and memory retrieval, fuses results using Reciprocal Rank Fusion, and updates memory based on interaction outcomes. Evaluation is proposed on TREC Session Track and MS MARCO datasets using nDCG@k, ERR-IA@k, session success rate, token consumption, and latency metrics.

## Key Results
- Cognitive memory separation reduces context bloat while preserving user preferences
- Adaptive routing via contextual bandits balances exploration and exploitation of persona agents
- Constrained debate protocol improves answer quality for ambiguous queries
- Reciprocal Rank Fusion provides robust aggregation across agents with different scoring scales
- System addresses personalization drift and filter bubbles through memory safeguards and diversity-aware objectives

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Stochastic routing over persona agents enables context-sensitive personalization that adapts to task drift.
- Mechanism: The Persona Coordinator computes a softmax distribution over persona embeddings using query-context features, activating top-k agents. A contextual bandit (e.g., LinUCB) learns routing policies from delayed reward signals (clicks, dwell time, satisfaction), balancing exploration of under-used agents with exploitation of historically effective choices.
- Core assumption: Query difficulty and user intent can be inferred from session context features sufficiently to guide protocol selection.
- Evidence anchors:
  - [abstract] "The system uses a Persona Coordinator to select appropriate agents and coordination protocols... based on query context and predicted difficulty."
  - [Section 4.3, Algorithm 2] "scores ← PredictGate(q_t, c_t); A ← TopKPersonas(scores, k_from_budget(B)); proto ← SelectProtocol(q_t, c_t, scores)"
  - [Section 4.5] "The Persona Coordinator frames the selection of both personas and coordination protocols as a contextual decision-making problem... Algorithms such as LinUCB and Thompson Sampling are employed to balance exploration and exploitation."
  - [corpus] Related work on adaptive personalization confirms contextual bandit approaches are effective for routing decisions (avg_neighbor_fmr=0.45, though direct experimental validation for this specific architecture is absent).
- Break condition: If session context features are sparse or noisy (cold-start), bandit exploration may take 3-5 interactions to reach parity with warmed profiles, degrading early-session utility.

### Mechanism 2
- Claim: Tripartite memory separation reduces context bloat while preserving both transient and persistent user signals.
- Mechanism: Each agent maintains working memory (Ms) for current-step state, episodic memory (Me) for recent interaction traces, and semantic memory (Msem) for long-term preferences. Updates to semantic memory require high-confidence repeated evidence; working/episodic remain lightweight and session-scoped.
- Core assumption: Users have distinguishable short-term tasks and long-term preferences, and over-weighting transient signals causes "personalization drift."
- Evidence anchors:
  - [abstract] "Drawing on cognitive architecture principles, SPARK separates working, episodic, and semantic memory to distinguish transient context from persistent user preferences."
  - [Section 2.4] "This cognitive foundation integrates seamlessly with SPARK's broader contributions... drawing on theories such as Baddeley's multi-component model and cognitive architectures like ACT-R."
  - [Section 5, H3] "We expect that explicitly separating working memory from long-term memory will reduce context bloat and improve latency without compromising fidelity, in line with cognitive architecture theory."
  - [corpus] Weak direct corpus validation for memory architecture in IR; related work focuses on multi-agent coordination rather than cognitive memory separation.
- Break condition: If memory update thresholds are miscalibrated, semantic memory may either fail to capture stable preferences or over-commit to transient signals (drift).

### Mechanism 3
- Claim: Constrained debate improves answer quality for ambiguous or high-stakes queries at the cost of latency.
- Mechanism: Two or more agents engage in bounded adversarial exchanges, critiquing each other's retrieved evidence over r_max rounds. A judge agent evaluates credibility and selects the strongest answer set. Debate is gated by a confidence threshold—low-confidence queries trigger debate; high-confidence queries use faster protocols.
- Core assumption: Adversarial critique surface weaknesses in reasoning that independent or relay protocols miss.
- Evidence anchors:
  - [abstract] "coordination protocols (independent, relay, or debate)... based on query context and predicted difficulty."
  - [Section 4.4] "In the constrained debate protocol... This design is motivated by multi-agent debate frameworks that have been shown to enhance factual accuracy and reasoning robustness in LLMs."
  - [Section 4.3, Algorithm 2] "if proto = debate and GateConfidence(q_t, c_t) < θ then proto ← independent"
  - [corpus] External debate frameworks (Du et al., Liang et al.) cited as showing promise for factual accuracy, but SPARK-specific validation is proposed, not yet demonstrated.
- Break condition: For straightforward queries, debate incurs unnecessary latency and token cost without quality gains; coordination overhead may degrade throughput.

## Foundational Learning

- Concept: **Contextual Bandits (LinUCB, Thompson Sampling)**
  - Why needed here: The Persona Coordinator uses contextual bandits to learn which agent-protocol combinations yield highest utility for different query types. Understanding exploration-exploitation tradeoffs is essential for debugging routing behavior.
  - Quick check question: Given a new query type with no historical data, should the bandit exploit known-good agents or explore alternatives? What reward signals would you use?

- Concept: **Cognitive Memory Models (Baddeley's Working Memory, ACT-R)**
  - Why needed here: SPARK's memory architecture directly maps to these theories—working/episodic/semantic separation. Without this foundation, it's hard to reason about what belongs in each store or how to set update thresholds.
  - Quick check question: A user searches for Python tutorials today but normally prefers JavaScript documentation. Which memory store should capture this session, and when should it propagate to long-term storage?

- Concept: **Reciprocal Rank Fusion (RRF)**
  - Why needed here: Multiple agents return ranked lists with different scoring scales. RRF provides a robust, calibration-free fusion method that the Arbiter uses as a default.
  - Quick check question: Agent A ranks document X at position 1; Agent B ranks it at position 50. With RRF constant k=60, how much does each agent contribute to X's fused score?

## Architecture Onboarding

- Component map:
  - Query arrives → Coordinator encodes query + session context → PredictGate computes agent scores → TopK selection → SelectProtocol based on predicted difficulty and confidence → Agents execute parallel (independent), sequential (relay), or adversarial (debate) → Arbiter fuses rankings, synthesizes answer with evidence grounding → Memory updated based on interaction outcomes

- Critical path:
  1. Query arrives → Coordinator encodes query + session context (φ(q_t, c_t))
  2. PredictGate computes agent scores → TopK selection
  3. SelectProtocol based on predicted difficulty and confidence
  4. Agents execute parallel (independent), sequential (relay), or adversarial (debate)
  5. Arbiter fuses rankings, synthesizes answer with evidence grounding
  6. Memory updated based on interaction outcomes

- Design tradeoffs:
  - **Latency vs. quality**: Debate yields vetted answers but adds rounds of agent communication. Independent is fastest but may miss cross-agent refinement.
  - **Personalization vs. diversity**: ERR-IA objective counteracts filter bubbles but may reduce short-term relevance for narrow profiles.
  - **Memory fidelity vs. privacy**: Rich semantic memory improves personalization but increases attack surface for memory extraction.

- Failure signatures:
  - **Mode collapse**: All agents converge on similar retrieval paths—check persona diversity and embedding separation.
  - **Personalization drift**: Semantic memory over-commits to transient signals—audit update thresholds and decay weighting.
  - **Coordination deadlock**: Relay chain stalls on ambiguous intermediate outputs—add timeout and fallback to independent.
  - **Memory extraction vulnerability**: Adversarial prompts leak stored preferences—audit retrieval logging and implement user-controlled pruning.

- First 3 experiments:
  1. **Ablate memory separation**: Run queries with working + episodic only (no semantic), measure session utility drop and latency improvement. Validates H3.
  2. **Protocol comparison by query difficulty**: Label queries as low/medium/high complexity; compare independent vs. relay vs. debate on nDCG@k and token cost per session. Validates H1.
  3. **Bandit warm-start analysis**: Simulate cold-start with synthetic personas; measure interactions to reach parity with warmed profiles. Track exploration rate decay and routing stability.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Under what query complexity conditions does constrained debate yield higher utility-per-token than independent specialist protocols?
- Basis in paper: [explicit] Section 5 hypothesizes (H1) that debate improves accuracy "at a comparable cost to three independent specialists" for complex queries, but lower-complexity queries may favor independent execution.
- Why unresolved: The paper proposes the framework without empirical validation; the trade-off remains untested.
- What evidence would resolve it: Controlled experiments measuring nDCG, factual accuracy, and token consumption across protocols stratified by query difficulty.

### Open Question 2
- Question: How many interactions are required for contextual-bandit routing to detect task drift and reach parity with warmed-up profiles?
- Basis in paper: [explicit] Section 5 predicts (H2) adaptation "within three to five interactions" and proposes simulating cold-start conditions with synthetic personas.
- Why unresolved: No experimental results exist on convergence speed or drift detection in real user sessions.
- What evidence would resolve it: A/B tests tracking session-level utility gains when bandit routing encounters task shifts, compared to static routing baselines.

### Open Question 3
- Question: How can principled unlearning be implemented for long-term semantic memory without degrading retrieval utility?
- Basis in paper: [explicit] Section 8 identifies "principled unlearning strategies for long-term memory correction" as future work; Section 7 flags knowledge divergence risks.
- Why unresolved: Persistent memory enables personalization but creates risks when erroneous or outdated preferences must be removed.
- What evidence would resolve it: Methods for selective memory deletion evaluated on consistency with base model knowledge and post-unlearning personalization quality.

### Open Question 4
- Question: What persona cardinality and specialization granularity optimize the trade-off between personalization fidelity and coordination overhead?
- Basis in paper: [inferred] The paper defines open-ended persona space and mentions ablations "varying the number of active personas k," but offers no principled method for determining optimal configuration.
- Why unresolved: Over-specialization may increase overhead without proportional gains; under-specialization may fail to capture multifaceted user needs.
- What evidence would resolve it: Systematic ablations across persona counts and specialization depths on diverse user populations.

## Limitations

- The framework's success critically depends on under-specified prompt engineering for coordination protocols and feature engineering for the contextual bandit, which could significantly impact performance
- Debate protocol's practical value remains speculative without experimental validation, despite promising theoretical foundations in multi-agent systems literature
- Memory update thresholds and decay schedules are essential to prevent personalization drift but remain undefined in the proposed architecture

## Confidence

- **High confidence**: The core architectural principles (cognitive memory separation, multi-protocol coordination, RRF fusion) are well-grounded in established research and logically coherent
- **Medium confidence**: The contextual bandit routing approach is theoretically sound, but effectiveness depends heavily on prompt quality and feature engineering details not provided
- **Low confidence**: The debate protocol's practical value remains speculative without experimental validation, despite promising theoretical foundations in multi-agent systems literature

## Next Checks

1. **Memory Threshold Validation**: Implement and test different semantic memory update thresholds (requiring 1, 3, or 5 repeated exposures before committing preferences) to find the optimal balance between personalization stability and adaptability
2. **Protocol Cost-Benefit Analysis**: For queries of varying complexity (simple fact lookup vs. comparative analysis), measure the marginal quality improvement of debate vs. relay vs. independent protocols against their additional latency and token costs
3. **Cold-Start Bandit Performance**: Simulate first-session scenarios with synthetic user profiles to measure how many interactions are required for the contextual bandit to achieve routing performance comparable to warmed profiles, and whether this degrades early-session utility below acceptable thresholds