---
ver: rpa2
title: Improved Regret Bounds for Linear Bandits with Heavy-Tailed Rewards
arxiv_id: '2506.04775'
source_url: https://arxiv.org/abs/2506.04775
tags:
- bound
- regret
- lower
- bounds
- heavy-tailed
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work addresses stochastic linear bandits with heavy-tailed\
  \ rewards, where the rewards have finite (1+\u03B5)-absolute central moments. The\
  \ authors improve both upper and lower regret bounds compared to prior work."
---

# Improved Regret Bounds for Linear Bandits with Heavy-Tailed Rewards

## Quick Facts
- arXiv ID: 2506.04775
- Source URL: https://arxiv.org/abs/2506.04775
- Reference count: 40
- Primary result: Improved regret bounds O(d^((1+3ε)/(2(1+ε))) T^(1/(1+ε))) for stochastic linear bandits with heavy-tailed rewards having finite (1+ε)-absolute central moments.

## Executive Summary
This paper addresses stochastic linear bandits where reward noise has finite (1+ε)-absolute central moments, extending beyond the typical sub-Gaussian assumption. The authors develop a new elimination-based algorithm guided by experimental design that achieves improved regret bounds, particularly in the dependence on dimension d. They also establish lower bounds that demonstrate the inherent difficulty of heavy-tailed linear bandit problems compared to standard multi-armed bandit settings. The work provides the first sublinear regret bounds for infinite-dimensional kernel-based bandits under heavy-tailed noise.

## Method Summary
The authors propose the MED-PE algorithm, a phased elimination approach that uses experimental design to guide exploration. In each phase, they solve a D-optimal design problem to find the best allocation of pulls across arms, then estimate arm rewards using a truncated mean estimator that is robust to heavy-tailed noise. The algorithm maintains confidence bounds using a min-max regression approach and eliminates arms that are provably suboptimal. For infinite-dimensional settings, they employ the kernel trick with the Matérn kernel, adapting their approach to handle the resulting computational challenges.

## Key Results
- New upper bound of Õ(d^((1+3ε)/(2(1+ε))) T^(1/(1+ε))) for general action sets, improving upon previous work for all ε ∈ (0,1]
- Matching lower bound of Ω(d^(2ε/(1+ε)) T^(1/(1+ε))), strictly improving upon multi-armed bandit rates
- Action set dependent bounds showing d can be replaced by √d log(n)^(ε/(1+ε)) for finite action sets of size n
- First sublinear regret bounds for kernel-based bandits under heavy-tailed noise, specifically O(T^(1/(1+ε))) for Matérn kernel with ν=1.5

## Why This Works (Mechanism)
The algorithm leverages experimental design to optimally allocate exploration across arms, which is particularly effective when combined with the robust truncated mean estimator. By carefully balancing the exploration-exploitation tradeoff and using the geometric properties of the action set, the method achieves tighter bounds than previous approaches. The kernel trick extension works by effectively reducing the infinite-dimensional problem to a finite-dimensional one through the representer theorem.

## Foundational Learning
- **Experimental Design**: Needed to optimally allocate exploration across arms; quick check: verify design matrix condition number improves with iterations
- **Heavy-Tailed Statistics**: Understanding truncated mean estimators and their bias-variance tradeoff; quick check: monitor truncation rate doesn't exceed 10-20%
- **Min-Max Regression**: Provides robust confidence bounds under heavy-tailed noise; quick check: verify confidence intervals contain true parameter with stated probability
- **Frank-Wolfe Algorithm**: Used for solving D-optimal design problems; quick check: track objective value decrease across iterations
- **Kernel Methods**: Extension to infinite-dimensional feature spaces via representer theorem; quick check: verify kernel matrix positive semi-definite

## Architecture Onboarding

**Component Map**: MED-PE Algorithm -> Truncated Mean Estimator -> Experimental Design -> Min-Max Regression -> Arm Elimination

**Critical Path**: 
1. Solve experimental design problem using Frank-Wolfe
2. Pull arms according to design and compute truncated means
3. Fit min-max regression for confidence bounds
4. Eliminate suboptimal arms and proceed to next phase

**Design Tradeoffs**: The use of truncated means provides robustness to heavy tails but introduces bias that must be carefully controlled. Experimental design optimizes exploration but requires solving potentially complex optimization problems. The phased elimination approach simplifies analysis but may be conservative compared to confidence-bound methods.

**Failure Signatures**:
- Excessive truncation rate (>20%) indicates noise heavier than assumed
- Slow convergence of Frank-Wolfe suggests ill-conditioned design problem
- Rapid arm elimination may indicate overly conservative confidence bounds

**First Experiments**:
1. Implement MED-PE with Pareto noise (α=1.2) on unit vectors {±e_i} for d ∈ {10, 100, 320}, horizon T=100,000
2. Compare against CRTM baseline on same setup to verify d^((1+3ε)/(2(1+ε))) scaling
3. Test kernel extension with Matérn kernel (ν=1.5) on infinite-dimensional action set

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical improvements rely on bounded (1+ε)-absolute central moments, which may not hold in many practical heavy-tailed scenarios
- Gap between upper bound d^((1+3ε)/(2(1+ε))) and lower bound d^(2ε/(1+ε)) suggests potential for further tightening
- Experimental design-based approach requires solving complex optimization problems, potentially limiting practical scalability

## Confidence

**High confidence** in mathematical framework and core theoretical results - builds on established bandit theory and robust statistics with sound proof techniques.

**Medium confidence** in practical applicability - limited experimental validation and computational complexity of experimental design may impact real-world performance.

**Low confidence** in generality beyond specific heavy-tailed assumptions - techniques may not extend directly to other noise models or constrained action sets.

## Next Checks
1. Implement MED-PE algorithm with Pareto-distributed noise (α=1.2, σ=0.1) and evaluate regret scaling across dimensions d ∈ {10, 100, 320} to verify the predicted d^(1+3ε)/(2(1+ε)) scaling.

2. Test the kernel trick extension on the Matérn kernel with ν=1.5 and length-scale ℓ=0.5, comparing against the theoretical O(T^(1/(1+ε))) scaling predicted for this setting.

3. Conduct ablation studies removing the truncated mean estimator to quantify its contribution to robustness, measuring both regret and computational overhead across different noise levels.