---
ver: rpa2
title: Test-Time Scaling Strategies for Generative Retrieval in Multimodal Conversational
  Recommendations
arxiv_id: '2508.18132'
source_url: https://arxiv.org/abs/2508.18132
tags:
- retrieval
- multimodal
- product
- conversational
- test-time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of improving generative retrieval
  performance in multimodal conversational recommendation systems, where traditional
  single-turn approaches struggle to capture evolving user intent across dialogue
  turns. The authors propose integrating test-time scaling (TTS) into generative retrieval
  through a novel test-time reranking (TTR) mechanism that dynamically adjusts retrieval
  scores during inference.
---

# Test-Time Scaling Strategies for Generative Retrieval in Multimodal Conversational Recommendations

## Quick Facts
- arXiv ID: 2508.18132
- Source URL: https://arxiv.org/abs/2508.18132
- Reference count: 40
- Primary result: Test-time reranking improves generative retrieval MRR by 14.5 points and nDCG@1 by 10.6 points in multimodal conversational recommendation

## Executive Summary
This paper addresses the challenge of improving generative retrieval performance in multimodal conversational recommendation systems, where traditional single-turn approaches struggle to capture evolving user intent across dialogue turns. The authors propose integrating test-time scaling (TTS) into generative retrieval through a novel test-time reranking (TTR) mechanism that dynamically adjusts retrieval scores during inference. This approach leverages a multimodal large language model (MLLM) to infer user intent and refine semantic ID-based retrieval results. To support evaluation, the authors curate and refine three datasets: Multi-turn Fashion IQ (MFRcrt), Multimodal Dialogue (MMDflt), and MUSE. Experimental results show consistent improvements across benchmarks, with average gains of 14.5 points in MRR and 10.6 points in nDCG@1 when TTR is applied. The framework demonstrates effectiveness across both unimodal and multimodal settings, and across different model architectures (decoder-only and encoder-decoder), validating the potential of test-time scaling for enhancing conversational product search in multimodal contexts.

## Method Summary
The proposed approach employs a three-stage pipeline for multimodal conversational product retrieval. First, an LLM (GPT-4o-mini) infers user intent from dialogue history, reformulating the query. Second, a generative retriever (VLT5, Qwen2.5-VL, or T5 variants) produces candidate product Semantic IDs via constrained beam search over an FM-index. Third, the test-time reranking (TTR) mechanism dynamically adjusts retrieval scores by combining the retriever's normalized probability with an LLM evaluator's confidence score assessing semantic alignment between each candidate and the inferred query. The framework is trained on datasets augmented with LLM-inferred queries and evaluated on 100-candidate test sets including target products.

## Key Results
- TTR improves MRR by 14.5 points and nDCG@1 by 10.6 points across all datasets
- Multimodal models (VLT5) outperform text-only models by 2 points MRR on average
- TTR provides larger gains in later dialogue turns (3.3→7.2 MRR points on MFRcrt) and mitigates performance degradation in later training checkpoints
- The framework works across both decoder-only and encoder-decoder architectures

## Why This Works (Mechanism)

### Mechanism 1: Intent-Aligned Score Reranking
Allocating additional computation at inference time through an LLM-based evaluator reranks generative retrieval results to better align with evolving user intent. The framework first infers user intent from dialogue history, then uses a generative retriever to produce candidate product Semantic IDs (SIDs) with generation probabilities. The test-time reranking (TTR) mechanism then modifies these scores by combining the retriever's normalized probability with an evaluator's confidence score: `RM_TTR(c_j) = σ(log(c_j)) × wEval(c_j | q̂^M)`. This revised score reorders candidates. The core assumption is that a separate LLM evaluator can reliably assess semantic alignment between a retrieved product's identifier and the user's inferred intent, providing a corrective signal where the retriever may be biased or misaligned.

### Mechanism 2: Multimodal Context Fusion in Retrieval
A multimodal generative retriever, fine-tuned on dialogues with LLM-inferred queries, outperforms text-only models by leveraging visual signals from reference images alongside textual reformulations. User multimodal queries (text + reference image) are reformulated into inferred queries via an LLM. This representation trains a generative retriever (e.g., VLT5, Qwen2.5-VL). During inference, constrained beam search over an FM-index generates valid SIDs. Multimodal models integrate visual tokens from reference images with textual context, enabling finer-grained product matching than text-only counterparts. The core assumption is that user intent can be effectively captured in a single inferred query combining textual reformulation with visual context, suitable for training a generative model to output relevant product IDs.

### Mechanism 3: Checkpoint and Turn-Level Robustness
TTR provides disproportionate gains in later dialogue turns and at later training checkpoints, acting as a corrective mechanism against overfitting and hard-negative bias. As conversations progress, intent becomes more specific but context more complex. TTR's external evaluator provides independent reassessment at each turn. Analysis shows later training checkpoints suffer retrieval degradation due to overfitting (bias toward hard negatives), which TTR mitigates by re-evaluating semantic alignment. Turn-level analysis confirms larger MRR gains in later dialogue stages. The core assumption is that performance degradation in later checkpoints/turns stems primarily from misalignment between model predictions and ground-truth relevance, which an external evaluator can correct.

## Foundational Learning

- **Concept: Generative Retrieval (GR)**
  - Why needed here: The paper's core paradigm shift from traditional matching (e.g., BM25, DPR) to generating document identifiers (SIDs) via autoregressive LLMs. Understanding GR is prerequisite to grasping the three-stage pipeline.
  - Quick check question: Can you explain the fundamental difference between how a dense bi-encoder retriever like DPR identifies candidate items versus a generative retriever in this paper? (Hint: consider the output space and matching mechanism).

- **Concept: Test-Time Scaling (TTS) / Test-Time Compute**
  - Why needed here: TTR is a direct application of TTS principles—allocating additional computation during inference to improve output quality. The paper positions TTR within this broader paradigm.
  - Quick check question: What are the two common TTS strategy categories mentioned in Section 2.3, and which category best describes the proposed TTR mechanism?

- **Concept: Semantic IDs (SIDs)**
  - Why needed here: The generative retriever outputs SIDs, not embeddings or raw text. Understanding their construction and role in constrained decoding via FM-index is critical for implementation.
  - Quick check question: How are Semantic IDs constructed for products in this framework (what source material), and what specific role does the FM-index play in relation to them during inference?

## Architecture Onboarding

- **Component map:** Intent Inference Module (LLM) -> Semantic ID-based Generative Retriever -> Test-time Reranking (TTR) -> FM-index Constraint Layer

- **Critical path:**
  1. Dialogue context → Intent inference (LLM reformulation)
  2. Inferred query + reference image → Generative retriever → Candidate SIDs with probabilities
  3. Candidate SIDs + inferred query → TTR evaluator → Revised scores → Final ranked product list

- **Design tradeoffs:**
  - Evaluator choice: GPT-4o-mini provides strong semantic assessment but adds API dependency and latency. Open-source evaluators reduce cost but may provide weaker alignment signals.
  - Beam size vs. latency: Larger beam sizes (`b`) improve candidate coverage but increase O(AB) complexity. Paper uses dataset-specific values (2-5).
  - Checkpoint selection: Earlier checkpoints avoid overfitting but may underfit; later checkpoints require TTR correction. Validation-based selection is critical.
  - Multimodal vs. unimodal: Multimodal models outperform text-only but require vision encoder integration and more training data.

- **Failure signatures:**
  - Low MRR in early turns: Intent inference failing to capture context; check LLM reformulation quality.
  - Performance degradation at later checkpoints: Overfitting to hard negatives; verify TTR is enabled or use earlier checkpoint.
  - No improvement from TTR: Evaluator providing uncorrelated scores; check evaluator prompt or switch evaluator model.
  - Invalid SIDs generated: FM-index constraint not properly integrated; verify logits processor configuration.
  - High latency: Evaluator bottleneck; parallelize evaluation or reduce candidate count.

- **First 3 experiments:**
  1. **Baseline validation:** Run generative retriever (Qwen2.5-VL or VLT5) on MMDflt test set without TTR. Verify MRR roughly matches paper baseline (~17.3 for Qwen2.5-VL). Check FM-index constraint is producing valid SIDs.
  2. **TTR ablation:** Enable TTR on same test set using GPT-4o-mini evaluator. Compare MRR improvement. Target ~21+ point gain (17.3 → 38.6 per Table 2). If improvement <10 points, debug evaluator confidence scoring.
  3. **Turn-level analysis:** Evaluate TTR performance breakdown by dialogue turn (Table 3 pattern). Verify gains are larger in later turns. If early turns show no improvement, check intent inference quality on short contexts.

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the traditional sense, but several implications arise from the results and methodology that warrant further investigation, particularly around the trade-offs between accuracy gains and computational overhead, the generalizability of the TTR mechanism to different evaluator models, and the potential for TTR to fundamentally alter optimal training strategies for generative retrievers.

## Limitations
- Dataset construction details: The exact methodology for constructing the 100-candidate test sets (random sampling vs. hard negatives) remains unspecified, potentially affecting reproducibility of the reported metrics
- Evaluator calibration: While GPT-4o-mini is used for both intent inference and evaluation, the prompt templates and scoring mechanisms are not detailed, introducing variability in TTR effectiveness
- Checkpoint selection bias: The observation that later checkpoints benefit most from TTR suggests potential overfitting in the base retriever, raising questions about the general robustness of the generative retrieval approach without test-time correction

## Confidence
- **High confidence:** The core TTR mechanism and its effectiveness across multiple datasets (MFRcrt, MMDflt, MUSE) is well-supported by consistent improvements in MRR and nDCG metrics
- **Medium confidence:** The multimodal advantage (VLT5 vs. text-only models) is demonstrated, though the extent may depend on dataset-specific characteristics and reference image quality
- **Medium confidence:** The checkpoint-level analysis showing TTR's corrective effect on later-stage overfitting is compelling but lacks direct comparative analysis with alternative regularization approaches

## Next Checks
1. **Prompt sensitivity analysis:** Systematically vary the evaluator prompts for TTR to quantify sensitivity of MRR improvements to prompt formulation quality
2. **Hard negative baseline comparison:** Construct test sets with varying proportions of hard negatives to isolate the contribution of TTR vs. improved candidate sampling
3. **Cross-LLM evaluator study:** Replace GPT-4o-mini with open-source evaluators (e.g., LLaVA-NeXT) to assess whether reported gains are specific to the evaluator choice or reflect a general principle