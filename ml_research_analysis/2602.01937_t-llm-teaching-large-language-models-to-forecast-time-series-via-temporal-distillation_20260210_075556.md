---
ver: rpa2
title: 'T-LLM: Teaching Large Language Models to Forecast Time Series via Temporal
  Distillation'
arxiv_id: '2602.01937'
source_url: https://arxiv.org/abs/2602.01937
tags:
- forecasting
- temporal
- time
- series
- teacher
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of enabling large language models
  (LLMs) to perform time series forecasting without relying on extensive time-series
  pretraining. The proposed T-LLM framework uses temporal distillation to teach an
  LLM forecasting behavior by imitating a lightweight temporal teacher during training.
---

# T-LLM: Teaching Large Language Models to Forecast Time Series via Temporal Distillation

## Quick Facts
- arXiv ID: 2602.01937
- Source URL: https://arxiv.org/abs/2602.01937
- Reference count: 40
- Enables LLMs to forecast time series without extensive pretraining via temporal distillation

## Executive Summary
This paper introduces T-LLM, a framework that enables large language models to perform time series forecasting by learning from a lightweight temporal teacher through temporal distillation. The approach avoids the need for extensive time-series pretraining by combining prediction-level supervision with selective guidance. T-LLM integrates trend modeling and frequency-domain analysis through its teacher model, allowing the LLM to learn forecasting behavior effectively. The method demonstrates strong performance across various settings including full-shot, few-shot, and zero-shot scenarios.

## Method Summary
T-LLM employs a temporal distillation framework where a lightweight temporal teacher guides an LLM to learn time series forecasting behavior. The teacher model combines trend modeling with frequency-domain analysis to generate forecasts. During training, the LLM receives both prediction-level supervision (learning to predict like the teacher) and selective guidance (learning when to follow the teacher versus its own reasoning). This dual approach allows the LLM to capture both general patterns and domain-specific characteristics without requiring extensive time-series pretraining.

## Key Results
- Consistently outperforms existing LLM-based forecasting methods across benchmark datasets
- Achieves up to 2.2% lower error rates in zero-shot transfer settings
- Maintains computational efficiency while delivering superior forecasting accuracy

## Why This Works (Mechanism)
T-LLM leverages temporal distillation to transfer forecasting expertise from a specialized temporal teacher to a general-purpose LLM. By combining prediction-level supervision with selective guidance, the framework enables the LLM to learn both when to follow expert guidance and when to rely on its own reasoning. The teacher's integration of trend modeling and frequency-domain analysis provides rich temporal features that the LLM can internalize, allowing it to handle diverse time series patterns without domain-specific pretraining.

## Foundational Learning
- **Temporal distillation**: Why needed - Transfers specialized forecasting knowledge to general models; Quick check - Verify gradient flow between teacher and student
- **Frequency-domain analysis**: Why needed - Captures periodic patterns in time series; Quick check - Test on datasets with known seasonality
- **Trend modeling**: Why needed - Identifies long-term directional movements; Quick check - Evaluate on trending vs. stationary series
- **Prediction-level supervision**: Why needed - Direct optimization of forecasting accuracy; Quick check - Compare with feature-level distillation approaches
- **Selective guidance**: Why needed - Balances teacher authority with model autonomy; Quick check - Analyze teacher-LLM agreement rates
- **Zero-shot transfer**: Why needed - Enables deployment without task-specific training; Quick check - Test on completely unseen domains

## Architecture Onboarding

Component map: Input time series -> Temporal teacher (trend + frequency analysis) -> LLM with selective guidance -> Forecast output

Critical path: Time series input → Temporal teacher processing → Selective guidance mechanism → LLM prediction → Forecast output

Design tradeoffs: 
- Balances computational efficiency (lightweight teacher) with forecasting accuracy
- Trades model complexity for generalization across diverse time series
- Prioritizes selective guidance over full teacher dependence to maintain LLM autonomy

Failure signatures:
- Poor performance on highly non-linear or chaotic time series
- Over-reliance on teacher guidance in regions where LLM should reason independently
- Degradation in zero-shot scenarios with domain shift beyond teacher's expertise

First experiments to run:
1. Ablation study removing frequency-domain analysis to measure its contribution
2. Stress test on highly irregular time series to identify breakdown points
3. Teacher-LLM agreement analysis to validate selective guidance effectiveness

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but implicit areas for future work include extending the framework to multivariate time series forecasting, exploring alternative teacher architectures, and investigating the limits of zero-shot generalization across diverse domains.

## Limitations
- Insufficient detail on teacher model architecture and training process
- Selective guidance mechanism lacks clear criteria for teacher deference
- Evaluation focuses on accuracy metrics without examining interpretability or deployment challenges

## Confidence

| Claim | Confidence |
|-------|------------|
| Effectiveness of temporal distillation | High |
| Performance improvements on benchmarks | Medium |
| Computational efficiency claims | Low |

## Next Checks
1. Conduct ablation studies to isolate the contribution of the frequency-domain analysis component versus trend modeling in the temporal teacher
2. Test T-LLM on additional real-world datasets with different characteristics (seasonality, noise levels, trend types) to evaluate generalization beyond the current benchmarks
3. Implement a detailed computational analysis comparing inference times and resource usage between T-LLM and traditional time series forecasting methods under identical hardware conditions