---
ver: rpa2
title: Bridge the Inference Gaps of Neural Processes via Expectation Maximization
arxiv_id: '2501.03264'
source_url: https://arxiv.org/abs/2501.03264
tags:
- functional
- prior
- points
- context
- si-nps
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses underfitting in neural processes (NPs) by analyzing
  their optimization objectives and proposing a novel method, Self-normalized Importance
  weighted Neural Process (SI-NP), based on variational expectation maximization.
  SI-NP optimizes a surrogate function of the target log-likelihood, avoiding the
  inference suboptimality of vanilla NPs.
---

# Bridge the Inference Gaps of Neural Processes via Expectation Maximization

## Quick Facts
- arXiv ID: 2501.03264
- Source URL: https://arxiv.org/abs/2501.03264
- Authors: Qi Wang; Marco Federici; Herke van Hoof
- Reference count: 40
- Key outcome: SI-NP outperforms other NP objectives on synthetic regression and image completion tasks

## Executive Summary
This paper addresses underfitting in neural processes by analyzing their optimization objectives and proposing a novel method based on variational expectation maximization. The authors introduce Self-normalized Importance weighted Neural Process (SI-NP), which optimizes a surrogate function of the target log-likelihood rather than the variational lower bound. By leveraging importance weighting, SI-NP avoids the inference suboptimality of vanilla neural processes while maintaining computational efficiency. The method demonstrates superior performance on synthetic regression tasks with various kernels and image completion benchmarks, with the added benefit of learning functional priors that correlate with dataset complexity.

## Method Summary
The paper analyzes the optimization objective of neural processes and identifies that minimizing the evidence lower bound (ELBO) leads to an inference gap that causes underfitting. To address this, the authors propose SI-NP, which reformulates the training objective using variational expectation maximization. SI-NP optimizes a surrogate function of the target log-likelihood through self-normalized importance weighting, allowing for multiple Monte Carlo samples to improve estimation accuracy. The method maintains the NP framework's ability to learn functional priors while ensuring that the learned latent distribution better approximates the true posterior, thereby bridging the inference gap inherent in traditional NP training.

## Key Results
- SI-NP outperforms CNP and ML-NP on synthetic regression tasks with Matern-5/2, RBF, and Periodic kernels
- SI-NP achieves state-of-the-art performance on image completion tasks (MNIST, FMNIST, SVHN, CIFAR10)
- The learned functional prior in SI-NP shows positive correlation with semantic complexity, exhibiting higher uncertainty for more complex datasets

## Why This Works (Mechanism)
The paper demonstrates that traditional NP training suffers from an inference gap because the ELBO lower bound prevents the model from fully optimizing the target log-likelihood. By reformulating the objective using variational EM and importance weighting, SI-NP directly optimizes a tighter surrogate of the target likelihood. This approach allows the model to learn a more accurate latent representation while maintaining computational tractability. The self-normalization component ensures numerical stability and prevents bias in the importance-weighted estimates, enabling the model to better capture the underlying data distribution.

## Foundational Learning
- **Neural Processes (NPs)**: Conditional generative models that learn to infer distributions over functions given context points. Needed to understand the baseline models being improved upon.
- **Evidence Lower Bound (ELBO)**: The standard objective used in variational inference that provides a lower bound on the log-likelihood. Quick check: verify that maximizing ELBO doesn't necessarily maximize the true log-likelihood.
- **Importance Sampling**: A technique for estimating expectations under a target distribution using samples from a proposal distribution. Quick check: confirm that importance weights are properly normalized to avoid bias.
- **Variational Expectation Maximization**: An iterative framework for optimizing variational objectives by alternating between E-steps (inference) and M-steps (parameter updates). Quick check: understand how this differs from standard variational inference.
- **Monte Carlo Estimation**: Using random sampling to approximate integrals and expectations. Quick check: verify that multiple samples are used to reduce variance in the importance-weighted estimates.

## Architecture Onboarding
- **Component Map**: Context encoder -> Latent distribution inference -> Functional prior -> Target prediction
- **Critical Path**: Context points → Encoder network → Latent variable z → Decoder network → Target predictions
- **Design Tradeoffs**: Multiple Monte Carlo samples improve estimation accuracy but increase computational cost; importance weighting reduces bias but requires careful implementation
- **Failure Signatures**: Training divergence when proposal distribution optimization is unstable; prior collapse when using single Monte Carlo sample
- **First Experiments**: 1) Reproduce CNP baseline on synthetic regression, 2) Implement SI-NP with importance weighting, 3) Compare uncertainty estimates across datasets of varying complexity

## Open Questions the Paper Calls Out
### Open Question 1
- Question: How can the optimization of the learnable proposal distribution in SI-NPs be stabilized to prevent training divergence?
- Basis in paper: [explicit] Appendix H.1 states that finding a balance to optimize both the proposal and the surrogate objective is "empirically tricky" and results in unstable performance, leading the authors to skip this step.
- Why unresolved: The authors found that standard tuning of coefficients failed to yield a convergence solution, leaving the integration of a learnable proposal as an unsolved implementation challenge.
- What evidence would resolve it: A novel objective function or a dynamic weight scheduling mechanism that allows the proposal distribution to update simultaneously with the model parameters without causing optimization instability.

### Open Question 2
- Question: How does the uncertainty of the learned functional prior mathematically propagate to the output distribution in SI-NPs?
- Basis in paper: [explicit] Section 7 states that while it is intuitive that uncertainty is forward propagated, "the influence of such uncertainty has not been mathematically studied."
- Why unresolved: The paper empirically correlates high prior uncertainty with semantic complexity but does not provide a theoretical derivation of how this latent variance impacts predictive variance.
- What evidence would resolve it: A formal analysis or derivation linking the trace of the functional prior's covariance matrix to the predictive variance of the target data points.

### Open Question 3
- Question: Can the SI-NP framework be adapted to avoid prior collapse while using only a single Monte Carlo sample, thereby reducing computational costs?
- Basis in paper: [explicit] Section 7 lists the requirement for multiple Monte Carlo samples as an "Existing Limitation" that "consumes more computations."
- Why unresolved: Proposition 3 proves that with one sample, the functional prior collapses into a Dirac delta distribution, rendering the model equivalent to a CNP and losing the benefits of a stochastic prior.
- What evidence would resolve it: A modified training objective or regularization term that maintains a non-zero functional prior variance even when $B=1$ (one sample).

## Limitations
- Results are primarily confined to controlled synthetic data and relatively simple image datasets, limiting generalizability
- The computational overhead introduced by the importance weighting mechanism and the stability of the EM-based optimization across different hyperparameter settings require further investigation
- The claim that SI-NP's learned functional prior correlates with semantic complexity is based on qualitative observations rather than rigorous quantitative analysis

## Confidence
- **High**: SI-NP outperforms CNP and ML-NP on the specific experimental benchmarks presented (synthetic regression with Matern-5/2, RBF, Periodic kernels and image completion on MNIST, FMNIST, SVHN, CIFAR10)
- **Medium**: The variational EM framework provides a theoretically sound basis for addressing the inference gap in NPs by optimizing a surrogate of the target log-likelihood
- **Low**: The functional prior learned by SI-NP consistently and quantitatively correlates with dataset semantic complexity across diverse domains

## Next Checks
1. Evaluate SI-NP on more complex, real-world datasets beyond the standard benchmarks (e.g., natural scene understanding, time series forecasting with long-range dependencies) to assess scalability and robustness
2. Conduct ablation studies isolating the contributions of the importance weighting and self-normalization components to determine their individual impact on performance and computational efficiency
3. Perform rigorous quantitative analysis of the functional prior's behavior across datasets of varying complexity, including statistical tests for correlation between uncertainty estimates and ground-truth semantic measures