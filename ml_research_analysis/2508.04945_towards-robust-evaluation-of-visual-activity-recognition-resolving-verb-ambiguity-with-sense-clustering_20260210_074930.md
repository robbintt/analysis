---
ver: rpa2
title: 'Towards Robust Evaluation of Visual Activity Recognition: Resolving Verb Ambiguity
  with Sense Clustering'
arxiv_id: '2508.04945'
source_url: https://arxiv.org/abs/2508.04945
tags:
- verb
- image
- evaluation
- clusters
- verbs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a clustering-based evaluation framework for
  visual activity recognition to address verb ambiguity in activity datasets. The
  authors construct verb sense clusters through a two-step vision-language clustering
  approach, showing that each image maps to around four distinct clusters representing
  different perspectives.
---

# Towards Robust Evaluation of Visual Activity Recognition: Resolving Verb Ambiguity with Sense Clustering

## Quick Facts
- **arXiv ID:** 2508.04945
- **Source URL:** https://arxiv.org/abs/2508.04945
- **Reference count:** 40
- **Primary result:** Introduces clustering-based evaluation framework for activity recognition that addresses verb ambiguity

## Executive Summary
This paper addresses the challenge of verb ambiguity in visual activity recognition datasets by introducing a clustering-based evaluation framework. The authors construct verb sense clusters using a two-step vision-language clustering approach, demonstrating that each image maps to approximately four distinct clusters representing different perspectives. Their analysis reveals that each cluster contains close to two synonymous verbs on average. When evaluating multiple activity recognition models, the cluster-based approach shows higher accuracy and better alignment with human judgments compared to exact-match evaluation, effectively capturing both synonymy and multi-perspective ambiguities.

## Method Summary
The framework employs a two-step vision-language clustering approach to construct verb sense clusters. First, the method maps images to clusters using vision-language embeddings, where each image typically maps to around four distinct clusters representing different semantic perspectives. Then, the clustering analysis reveals that each cluster contains close to two synonymous verbs on average. This clustering-based evaluation framework is applied to multiple activity recognition models, showing improved accuracy metrics and better alignment with human semantic judgments compared to traditional exact-match evaluation methods.

## Key Results
- Cluster-based evaluation demonstrates higher accuracy than exact-match evaluation
- Each image maps to approximately four distinct clusters representing different perspectives
- Each cluster contains close to two synonymous verbs on average
- Framework shows better alignment with human judgments compared to traditional evaluation methods

## Why This Works (Mechanism)
The framework works by leveraging vision-language embeddings to capture semantic relationships between verbs and visual contexts. By clustering these embeddings, the approach groups semantically similar verbs that may have different surface forms but similar meanings in specific visual contexts. This captures the inherent ambiguity in human language where different verbs can describe the same action from various perspectives or with subtle semantic differences.

## Foundational Learning
- **Vision-language embeddings** (why needed: bridge visual and linguistic representations; quick check: verify embedding quality and semantic alignment)
- **Clustering algorithms** (why needed: group semantically similar verbs; quick check: assess cluster coherence and separation)
- **Semantic similarity metrics** (why needed: measure relationship between verbs; quick check: validate against human judgments)
- **Evaluation framework design** (why needed: provide robust assessment of model performance; quick check: compare with baseline exact-match evaluation)

## Architecture Onboarding

**Component Map:**
Vision-language model -> Embedding generation -> Clustering algorithm -> Verb clusters -> Evaluation framework

**Critical Path:**
1. Generate embeddings for activity verbs and visual contexts
2. Apply clustering algorithm to group semantically similar verbs
3. Map images to appropriate clusters based on visual context
4. Evaluate model predictions against cluster-based ground truth

**Design Tradeoffs:**
- Balance between cluster granularity and semantic coherence
- Trade-off between computational efficiency and clustering quality
- Choice of clustering algorithm affects semantic capture

**Failure Signatures:**
- Poor clustering quality leading to incorrect verb groupings
- Over-segmentation causing loss of semantic relationships
- Under-segmentation masking important distinctions between verb senses

**First Experiments:**
1. Validate clustering quality by measuring intra-cluster semantic similarity
2. Compare evaluation results against human judgment benchmarks
3. Test sensitivity to clustering parameters and distance metrics

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on quality of vision-language model embeddings and clustering methodology
- Potential overfitting to specific dataset characteristics and verb distributions
- May miss nuanced semantic distinctions that humans naturally perceive

## Confidence

**High confidence in:**
- Core methodology and implementation
- Basic clustering framework functionality

**Medium confidence in:**
- Generalizability of clustering results across different datasets
- Alignment with human judgments due to limited comparative analysis

## Next Checks
1. Test the clustering framework's performance across multiple activity recognition datasets with varying verb distributions and complexity levels
2. Conduct ablation studies to evaluate the sensitivity of results to different clustering parameters and distance metrics
3. Perform human evaluation studies comparing the cluster-based assessment against alternative evaluation frameworks to validate alignment with human semantic understanding