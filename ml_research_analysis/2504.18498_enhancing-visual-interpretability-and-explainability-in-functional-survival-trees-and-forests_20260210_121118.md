---
ver: rpa2
title: Enhancing Visual Interpretability and Explainability in Functional Survival
  Trees and Forests
arxiv_id: '2504.18498'
source_url: https://arxiv.org/abs/2504.18498
tags:
- functional
- survival
- time
- data
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study enhances interpretability and explainability in functional
  survival models, specifically Functional Survival Trees (FST) and Functional Random
  Survival Forests (FRSF), by introducing graphical and explainability tools. For
  FSTs, we propose the Local Functional Survival Discrimination Curve (LFSDC) and
  a separability metric to visualize survival dynamics and node-level decision processes.
---

# Enhancing Visual Interpretability and Explainability in Functional Survival Trees and Forests

## Quick Facts
- **arXiv ID**: 2504.18498
- **Source URL**: https://arxiv.org/abs/2504.18498
- **Reference count**: 40
- **Primary result**: Novel interpretability tools for functional survival models including LFSDC for FSTs and SurvSHAP(t) adaptations for FRSFs

## Executive Summary
This study introduces interpretability methods for Functional Survival Trees (FST) and Functional Random Survival Forests (FRSF). The authors propose the Local Functional Survival Discrimination Curve (LFSDC) to visualize survival stratification at each tree node, and adapt SurvSHAP(t) and Permutation Feature Importance (PFI) to provide time-dependent feature attribution. The methods are validated on simulated data and real-world SOFA dataset, demonstrating improved transparency in how functional and mixed covariates influence survival predictions over time.

## Method Summary
The method converts irregularly-spaced functional data into FPC scores using PACE decomposition, then trains FST and FRSF models with log-rank splitting. LFSDC constructs discriminative curves in functional space to visualize node-level survival dynamics. For FRSFs, SurvSHAP(t) provides local time-dependent explanations by smoothing Shapley values into functional form, while PFI captures global temporal feature importance through permutation-based performance degradation. Both explainability methods use penalized spline smoothing to create continuous time-dependent attributions.

## Key Results
- LFSDC successfully visualizes survival differentiation across tree nodes in simulation studies
- SurvSHAP(t) adaptation reveals time-varying feature contributions in FRSF predictions
- PFI with temporal smoothing identifies clinically relevant FPCs (PC2, PC4, PC5, PC14) as significant survival predictors
- Real-world SOFA case studies validate the clinical interpretability of the proposed methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LFSDC enables visualization of how functional covariates contribute to survival stratification at each tree node
- Mechanism: Constructs discriminative curve in functional space L²(T) by combining local mean function with eigenfunction-weighted thresholds, partitioning functional space into survival-differentiated groups
- Core assumption: Karhunen-Loève expansion adequately captures functional data structure, and log-rank splitting effectively separates survival distributions
- Evidence anchors: LFSDC shows impact of variable selection and hierarchical structure on survival state (Page 5); L² distance quantifies survival structure evolution (Equation 12)
- Break condition: If FPCs fail to capture clinically meaningful variation, LFSDC curves may not align with interpretable survival differences

### Mechanism 2
- Claim: SurvSHAP(t) adaptation provides time-dependent feature attribution for individual predictions
- Mechanism: Extends SurvSHAP(t) by smoothing discrete Shapley contributions into functional form via penalized spline regression; TNSD quantifies whether feature influence exceeds static contribution
- Core assumption: Regularization parameter appropriately balances smoothness and fidelity; Shapley permutation framework remains valid for mixed predictors
- Evidence anchors: Approximates time-dependent contribution as smooth function over time (Page 6); Tables 2, 4, 6 show TSD and TNSD values across time intervals
- Break condition: If computation cost is prohibitive for high-dimensional FPCs, kernel approximations may be required

### Mechanism 3
- Claim: PFI with temporal smoothing captures global feature importance evolution over survival time
- Mechanism: Computes FI_j(t) at each event time and smooths into functional form; MTNGD quantifies whether feature importance over interval exceeds baseline
- Core assumption: Permutation importance remains meaningful when features include FPC scores of varying scales
- Evidence anchors: PFI offers robust method for evaluating feature significance (Page 7); Table 5 shows MTGD and MTNGD for PC2 in SOFA dataset
- Break condition: If FPC scores are highly correlated, permuting one may not isolate its individual contribution

## Foundational Learning

- **Concept: Functional Principal Component Analysis (FPCA) via PACE**
  - Why needed here: Irregularly-spaced time observations Y_i are transformed into smooth trajectories X̂_i(t) and FPC scores that serve as predictors in trees
  - Quick check question: Given sparse observations at times t=[5, 12, 45] with values Y=[2.1, 3.8, 1.4], can you explain why PACE (vs. standard PCA) is required?

- **Concept: Survival Tree Splitting Criteria (Log-rank Test)**
  - Why needed here: Tree nodes split by maximizing survival distribution differences, not impurity. Equation 5 defines the log-rank statistic used for split selection
  - Quick check question: If d_l1=3 events in daughter node 1 and d_l2=7 events in daughter node 2, with r_l1=50 and r_l2=60 at risk, how would you interpret |L(V, c)|?

- **Concept: Shapley Values for Time-dependent Explanations**
  - Why needed here: SurvSHAP(t) attributes prediction to features at each time point, requiring understanding of how feature subsets condition expected survival
  - Quick check question: For ϕ_{tm}(w*, j) in Equation 14, what does e^{before(π,j)∪j}_{tm,w*} - e^{before(π,j)}_{tm,w*} represent intuitively?

## Architecture Onboarding

- **Component map**:
  Raw irregular time data (Y_i, t_ij) → PACE decomposition (Eq. 1-3) → FPC scores V̂ + reconstructed curves X̂_i(t) → FST: Single tree built on V̂ + scalar covariates → LFSDC at each node (Eq. 11) → Separability metric d² (Eq. 12) → FRSF: Ensemble of B FSTs → SurvSHAP(t) for local explanations (Eq. 14-21) → PFI(t) for global importance (Eq. 22-26)

- **Critical path**:
  1. PACE decomposition quality determines FPC interpretability
  2. Number of FPCs (p) affects both model complexity and explainability resolution
  3. B=1000 trees provides stable ensemble estimates but increases SurvSHAP computation

- **Design tradeoffs**:
  - p=14 FPCs captures subtle patterns but may include noise; variance-explained thresholds may underselect
  - Functional smoothing (λ in Eq. 18) trades smoothness for local temporal accuracy
  - OOB vs. held-out validation: PFI uses OOB, but external validation preferred for clinical deployment

- **Failure signatures**:
  - LFSDC curves nearly identical across nodes → splitting not capturing functional differences
  - TNSD consistently near zero across all features → time-dependent contributions negligible; consider static SHAP
  - PFI unstable across permutation runs → features highly correlated or model underfitting

- **First 3 experiments**:
  1. Replicate simulation study: Generate trajectories via Eq. 27-29 with N=200, fit FST, verify LFSDC separates groups at root node (compare to Figure 2)
  2. Ablate FPC count: Fit FRSF with p ∈ {4, 8, 14} FPCs; compare MTNGD patterns to assess sensitivity of global explanations to FPC selection
  3. Validate on held-out