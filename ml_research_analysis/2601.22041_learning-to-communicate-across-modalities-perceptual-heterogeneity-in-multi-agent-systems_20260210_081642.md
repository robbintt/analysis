---
ver: rpa2
title: 'Learning to Communicate Across Modalities: Perceptual Heterogeneity in Multi-Agent
  Systems'
arxiv_id: '2601.22041'
source_url: https://arxiv.org/abs/2601.22041
tags:
- sender
- receiver
- perceptual
- message
- communication
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work studies how perceptual misalignment across agents affects\
  \ the emergence of communication protocols in a multi-step referential game. Agents\
  \ differ in their input modalities\u2014audio and image\u2014and develop separate\
  \ encodings for the same semantic content, resulting in less efficient communication\
  \ and higher uncertainty compared to unimodal setups."
---

# Learning to Communicate Across Modalities: Perceptual Heterogeneity in Multi-Agent Systems

## Quick Facts
- arXiv ID: 2601.22041
- Source URL: https://arxiv.org/abs/2601.22041
- Authors: Naomi Pitzer; Daniela Mihai
- Reference count: 6
- One-line primary result: Perceptual misalignment in multimodal agents increases communication costs and uncertainty, but limited fine-tuning enables cross-system interoperability.

## Executive Summary
This work studies how perceptual misalignment across agents affects the emergence of communication protocols in a multi-step referential game. Agents differ in their input modalities—audio and image—and develop separate encodings for the same semantic content, resulting in less efficient communication and higher uncertainty compared to unimodal setups. Message length experiments reveal that multimodal agents require more information to maintain accuracy, while perturbation and cluster analyses show that meaning is distributed across message bits and grounded in perceptual input rather than being compositional. Finally, interoperability tests show that protocols trained in different perceptual worlds are not directly compatible, but limited fine-tuning enables cross-system communication. The findings highlight that heterogeneity in perception leads to asymmetric trade-offs in efficiency and consistency, and that adaptation—rather than direct alignment—is key to bridging perceptual gaps.

## Method Summary
The study uses a multi-step binary referential game where a Sender (with audio input) and Receiver (with image or audio input) exchange D-dimensional binary messages to identify a target among distractors. Agents are trained jointly using REINFORCE with baseline networks to minimize classification loss plus entropy regularization. The Sender is a feed-forward network processing VGGish audio embeddings plus incoming message; the Receiver is a GRU-based RNN processing sender messages and distractor embeddings. Experiments are conducted on synthetic "Shapes World" and environmental datasets (CIFAR-100 + UrbanSound8K/ESC-50). Communication efficiency is measured via accuracy and entropy across varying message lengths, with ablation studies on bit perturbation and cross-system interoperability via fine-tuning.

## Key Results
- Unimodal communication is more efficient (higher accuracy, lower entropy) than multimodal under the same message budget.
- Meaning is encoded distributionally across message bits, not compositionally; flipping constant bits drastically reduces accuracy.
- Protocols trained under different perceptual conditions are not directly interoperable, but limited fine-tuning (2-15 epochs) enables cross-system communication.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Perceptual misalignment between agents reduces communication efficiency, requiring longer messages to achieve equivalent accuracy.
- Mechanism: When Sender and Receiver operate on different modalities (audio vs. image), the representational gap introduces noise into the communication channel, lowering effective information per symbol. Multimodal agents compensate by increasing message capacity.
- Core assumption: The modality gap behaves approximately like channel noise in Shannon's information theory framework.
- Evidence anchors:
  - [abstract] "Unimodal systems communicate more efficiently, using fewer bits and achieving lower classification entropy, while multimodal agents require greater information exchange and exhibit higher uncertainty."
  - [section 3.1] Table 1 shows at length=5, unimodal achieves 87% accuracy vs. 70% for multimodal; Receiver entropy is 0.53 vs. 1.06.
  - [corpus] Weak direct support; neighboring papers focus on coordination protocols, not cross-modal efficiency costs.
- Break condition: If modalities share a grounded semantic space (e.g., via shared pre-training), efficiency gap may narrow.

### Mechanism 2
- Claim: Meaning is encoded distributionally across message bits rather than compositionally in individual bits.
- Mechanism: Constant bits (active >90% or <10% of time) carry disproportionate class information. However, flipping a single constant bit does not produce a consistent meaning change across classes—its role depends on the surrounding bit pattern.
- Core assumption: The network learns holistic representations rather than factorized symbolic codes.
- Evidence anchors:
  - [abstract] "Bit perturbation experiments provide strong evidence that meaning is encoded in a distributional rather than compositional manner, as each bit's contribution depends on its surrounding pattern."
  - [section 3.3] "In the Heart class's case, flipping the final bit... reduced accuracy to... ~16%, yet the same bit was consistently inactive across other classes."
  - [corpus] No direct corpus evidence on compositional vs. distributional encoding in emergent protocols.
- Break condition: If explicit symbolic constraints or inductive biases are added, compositionality may emerge.

### Mechanism 3
- Claim: Agents trained in different perceptual contexts cannot directly communicate, but limited fine-tuning enables cross-system alignment.
- Mechanism: A Sender originally paired with an image-based Receiver achieves ~9% accuracy with an untrained audio Receiver. After ~2 epochs of fine-tuning, accuracy jumps to ~53%; by 15 epochs, both original and new Receivers achieve >75% accuracy, suggesting the Sender learns to identify partner type early in dialogue and adjust protocols.
- Core assumption: The Sender encodes a flexible protocol that can be rapidly retargeted without catastrophic forgetting.
- Evidence anchors:
  - [abstract] "Interoperability analyses show that systems trained in different perceptual worlds fail to directly communicate, but limited fine-tuning enables successful cross-system communication."
  - [section 3.4] Table 2 and Figure 7 show accuracy trajectories across fine-tuning epochs; Figure 7a shows audio Receiver accuracy spikes after first exchange at 15 epochs.
  - [corpus] Patel et al. (2021) on heterogeneous collaborative embodied agents mentioned in references; corpus papers discuss emergent coordination but not fine-tuning for cross-modal interoperability.
- Break condition: If Sender architecture is frozen or capacity is too low, adaptation may fail or severely degrade original performance.

## Foundational Learning

- Concept: **REINFORCE policy gradient with baseline**
  - Why needed here: Agents learn discrete communication via reinforcement; baseline networks reduce variance in gradient estimates.
  - Quick check question: Can you explain why subtracting a baseline from rewards reduces variance without introducing bias?

- Concept: **Entropy regularization in discrete communication**
  - Why needed here: Encourages exploration in message space and prevents premature collapse to degenerate protocols.
  - Quick check question: What happens to message diversity if entropy regularization weight is set too low?

- Concept: **Grounding in referential games**
  - Why needed here: Protocol emergence requires shared task success grounded in external referents, not just internal consistency.
  - Quick check question: How would removing distractor candidates change the pressure on the communication protocol?

## Architecture Onboarding

- Component map:
  - **Sender**: VGGish audio encoder → linear projection + element-wise sum with incoming message → tanh → projection → sigmoid → Bernoulli sampling (train) / thresholding (test)
  - **Receiver**: GRU hidden state update + VGG16/VGGish distractor embeddings → stop decision (sigmoid) + candidate prediction (MLP) + outgoing message generation
  - **Baselines**: Feed-forward networks predicting expected loss for Sender and Receiver independently

- Critical path: Audio input → Sender embedding → binary message → Receiver GRU state → stop/predict/respond loop. First message carries most task-relevant information; subsequent exchanges refine.

- Design tradeoffs:
  - Message length vs. accuracy: Shorter messages force compression but degrade multimodal performance more sharply than unimodal.
  - Fine-tuning epochs vs. original partner performance: More adaptation improves new partner accuracy but slightly erodes original partner accuracy.
  - Sampling vs. thresholding: Training uses stochastic sampling for gradients; evaluation uses deterministic thresholding for consistency.

- Failure signatures:
  - Random-guess accuracy (~16% for 6 classes) with new Receiver pairing before fine-tuning.
  - Sharp accuracy drop when constant bits are flipped; minimal effect from variable bit flips.
  - High Receiver entropy (>1.0) under compression in multimodal systems signals decoding uncertainty.

- First 3 experiments:
  1. Reproduce Table 1 with message lengths [1, 5, 10, 30, 50] on synthetic Shapes World; verify multimodal vs. unimodal accuracy and entropy divergence.
  2. Run bit perturbation analysis: identify constant vs. variable bits, flip subsets, plot per-class accuracy and variance curves as in Figure 4.
  3. Interoperability test: train Sender with image Receiver, freeze, pair with audio Receiver; fine-tune for [0, 2, 15, 20, 100] epochs and log accuracy trajectories for both Receivers.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does physical embodiment and sensorimotor interaction alter the emergence and interoperability of protocols compared to the current static dataset setup?
- Basis in paper: [explicit] The conclusion explicitly states that "Future work should extend these analyses to... embodied agent systems (e.g., robots)... to develop a broader account of heterogeneous emergent communication."
- Why unresolved: The current study relies on static datasets (Shapes World, CIFAR) where agents passively receive embeddings, lacking the active inference loops found in robotics.
- What evidence would resolve it: Empirical results from robotic agents navigating a shared physical space with mismatched sensors (e.g., lidar vs. vision), measuring if efficiency and grounding dynamics persist.

### Open Question 2
- Question: Can more expressive architectures (e.g., Transformers) induce compositional structure in emergent protocols, mitigating the distributional encoding observed in simpler RNNs?
- Basis in paper: [explicit] The authors show meaning is "encoded in a distributional rather than compositional manner" but list "alternative architectures" as a necessary future direction to generalize these findings.
- Why unresolved: The observed lack of compositionality may be an artifact of the specific feed-forward and GRU capacities used, which struggle to factorize complex perceptual mappings.
- What evidence would resolve it: A comparative analysis showing bit-level compositionality (e.g., disentangled features) in heterogeneous agents equipped with attention mechanisms versus the current baseline.

### Open Question 3
- Question: Can agents be adapted to communicate with new perceptual partners without suffering the fidelity trade-off observed in sequential fine-tuning?
- Basis in paper: [inferred] Section 3.4 notes that while agents adapt to new partners via fine-tuning, this comes "at the cost of slightly degrading performance with the Sender's original partner."
- Why unresolved: The study demonstrates sequential adaptation but does not explore mechanisms (e.g., experience replay or meta-learning) to maintain multi-partner fluency simultaneously.
- What evidence would resolve it: A training regime where agents achieve high accuracy (>80%) with both the original multimodal partner and a new unimodal partner without requiring separate fine-tuning epochs.

## Limitations
- Architectural details such as hidden layer sizes, GRU state dimensions, entropy regularization coefficients, and exact baseline network configurations are unspecified, making exact reproduction difficult.
- The paper assumes a fixed modality gap behaves like channel noise, but real-world perceptual heterogeneity may involve more complex, non-linear mismatches that aren't captured in synthetic datasets.
- The fine-tuning interoperability results depend on early Sender adaptability, but the paper does not detail how protocol switching is implemented or whether it is automatic or requires explicit partner identification.

## Confidence
- **High**: The efficiency gap between unimodal and multimodal communication is well-supported by controlled experiments; the distributional encoding of meaning (as opposed to compositional) is evidenced through bit perturbation analysis.
- **Medium**: The claim that limited fine-tuning enables cross-system communication is plausible but relies on architectural assumptions not fully specified.
- **Low**: Generalization of findings to real-world perceptual misalignment (e.g., vision-language or sensor-rich robotics) is speculative given the synthetic and controlled nature of the datasets.

## Next Checks
1. **Replicate the Shapes World dataset generation and train unimodal vs. multimodal agents across varying message lengths to confirm the accuracy-entropy divergence pattern.**
2. **Conduct bit perturbation analysis to identify constant vs. variable bits, and measure how flipping them affects accuracy per class to validate distributional encoding claims.**
3. **Perform interoperability fine-tuning experiments: pair Sender trained with one modality Receiver with a Receiver of the other modality, and measure accuracy gains across 0, 2, 15, 20, and 100 fine-tuning epochs to confirm adaptation without catastrophic forgetting.**