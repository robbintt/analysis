---
ver: rpa2
title: Aligning Diffusion Models with Noise-Conditioned Perception
arxiv_id: '2406.17636'
source_url: https://arxiv.org/abs/2406.17636
tags:
- diffusion
- preference
- optimization
- arxiv
- noise-conditioned
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of improving human preference
  alignment in text-to-image diffusion models, which traditionally optimize in pixel
  or latent spaces misaligned with human perception. The authors propose Noise-Conditioned
  Perceptual Preference Optimization (NCPPO), which leverages the perceptual embedding
  space of the diffusion model's U-Net encoder rather than pixel space.
---

# Aligning Diffusion Models with Noise-Conditioned Perception

## Quick Facts
- arXiv ID: 2406.17636
- Source URL: https://arxiv.org/abs/2406.17636
- Reference count: 7
- Primary result: Replaces pixel-space diffusion loss with perceptual loss computed in U-Net encoder embedding space, improving human preference alignment while reducing compute time

## Executive Summary
This paper addresses the challenge of aligning text-to-image diffusion models with human perceptual preferences by proposing Noise-Conditioned Perceptual Preference Optimization (NCPPO). Traditional diffusion preference optimization works in pixel or latent spaces that may not align with human judgment. The authors propose computing diffusion loss in the perceptual embedding space of the diffusion model's U-Net encoder, using the encoder's downsampling stack as a perceptual feature extractor. This approach integrates seamlessly with existing preference optimization techniques like DPO, CPO, and SFT, and demonstrates significant improvements in preference alignment metrics while reducing computational costs.

## Method Summary
NCPPO modifies diffusion preference optimization by computing perceptual loss in the U-Net encoder's embedding space rather than pixel space. The method extracts the U-Net downsampling stack as a perceptual encoder, evaluates it at timestep t-1, and computes squared differences between predicted-denoised and ground-truth-denoised embeddings. This perceptual loss replaces the standard diffusion loss in DPO/CPO objectives. The approach also includes a data filtering step that removes images appearing as both winners and losers in preference pairs, reducing gradient noise and enabling 10-fold dataset size reduction while improving results.

## Key Results
- SDXL NCP-DPO achieves 60.8% general preference, 62.2% visual appeal, and 52.1% prompt following on PartiPrompts dataset
- 10-fold reduction in Pick-a-Pic dataset size (from 851k to 87k pairs) while improving results
- 62% compute time reduction compared to standard latent-space implementations
- Improved performance across multiple metrics including PickScore and human preference evaluations

## Why This Works (Mechanism)

### Mechanism 1: Perceptual Loss via U-Net Encoder Embeddings
The method replaces pixel-space diffusion loss with loss computed in U-Net encoder embedding space. The encoder's downsampling stack captures perceptually meaningful features aligned with human judgment, similar to dedicated vision networks despite being trained only on diffusion denoising. This works because the pretrained U-Net encoder exhibits the same perceptual properties as other vision networks.

### Mechanism 2: Noise-Conditioned Embedding Computation at t-1
Computing perceptual embeddings at timestep t-1 provides stable, informative targets for preference optimization. The intermediate denoised state is perceptually structured enough to yield meaningful gradients. The choice of t-1 appears to balance between having meaningful semantic content versus being too noisy or too clean.

### Mechanism 3: Contradictory Example Filtering Reduces Gradient Noise
Removing images that appear as both winners and losers across different preference pairs improves training by eliminating gradient cancellation. This filtering assumes contradictory labels reflect annotation noise rather than legitimate context-dependent preferences, reducing the 851k-pair dataset to 87k pairs while improving results.

## Foundational Learning

- **Diffusion Forward/Reverse Process (DDPM)**: Needed to understand how the reverse step produces x_{t-1} from x_t and noise predictions, where perceptual embeddings are computed. Quick check: Given x_t and predicted noise ε_θ, can you write the DDPM reverse step to obtain x_{t-1}?

- **Direct Preference Optimization (DPO) for Diffusion**: Needed because NCPPO modifies the Diffusion-DPO objective by substituting perceptual loss for noise-prediction loss. Understanding the baseline is prerequisite. Quick check: In Diffusion-DPO, what do L^w_θ and L^w_ref represent, and why is the reference model kept frozen?

- **U-Net Encoder-Decoder Architecture**: Needed because the method extracts the U-Net downsampling stack as a standalone perceptual encoder. Implementation requires knowing which layers belong to the encoder. Quick check: In a standard U-Net, which operations form the encoder (downsampling) path vs. the decoder (upsampling) path?

## Architecture Onboarding

- **Component map**: x_t + t + c → U-Net → ε_θ (noise prediction) → DDPM reverse step module → x_{t-1} samples → Frozen U-Net encoder f(·) → Perceptual embeddings → Perceptual loss module → Modified DPO/CPO/SFT objectives → Data filtering pipeline

- **Critical path**: 1) Implement DDPM reverse step (single-step denoising) 2) Extract and freeze U-Net encoder (downsampling stack only) 3) Modify training loop: compute perceptual embeddings, then plug into preference objective 4) Pre-filter preference dataset to remove images appearing as both winners and losers

- **Design tradeoffs**: Timestep for embedding: t-1 chosen empirically; earlier steps → noisier embeddings; later steps → more computation, approaching pixel-space behavior. Encoder depth: paper uses full downsampling stack; intermediate layers could trade semantic richness for speed. Reference model: DPO requires frozen reference (memory overhead); CPO avoids this but is unstable—NCPPO's frozen encoder matching adds regularization to CPO.

- **Failure signatures**: No improvement over baseline DPO: likely wrong timestep (too early/late for embedding) or unfiltered data with contradictions. CPO divergence without reference: expected; paper notes NCP-CPO provides regularization via frozen encoder matching. Memory overflow: perceptual objective requires additional encoder passes; use gradient checkpointing or smaller batch sizes. Slow convergence: check learning rate scaling—paper uses 3× higher LR for smaller experiments.

- **First 3 experiments**:
  1. Timestep ablation: Compare embedding computation at t-1 vs. t-2 vs. t-5 on a held-out validation set with PickScore/HPSv2 rewards
  2. Encoder layer ablation: Test using full encoder vs. only early vs. only late downsampling blocks to identify which features drive preference alignment
  3. Data filtering validation: Replicate filtered vs. original Pick-a-Pic comparison on SD1.5 (faster iteration) to confirm the 10× data reduction claim before scaling to SDXL

## Open Questions the Paper Calls Out
The authors explicitly state that it remains a question for future work whether this approach works that well with Diffusion Transformer architecture, as the current method relies on the downsampling stack of the U-Net architecture which DiT models lack.

## Limitations
- The perceptual alignment claim relies on the untested assumption that U-Net encoder captures human-perceptible semantic features despite being trained only on diffusion denoising
- Computational cost comparisons assume identical hardware and batch configurations, which are not fully specified
- The claims about computational efficiency gains and the necessity of the t-1 timestep choice are not rigorously supported by ablation studies

## Confidence

- **High confidence**: The perceptual loss formulation and its integration into existing preference optimization frameworks (DPO/CPO/SFT) is technically sound and reproducible
- **Medium confidence**: The empirical results showing improved preference alignment metrics (PickScore, HPSv2, human evaluations) are convincing, though the underlying perceptual mechanism lacks direct validation
- **Low confidence**: The claims about computational efficiency gains and the necessity of the t-1 timestep choice are not rigorously supported by ablation studies

## Next Checks

1. **Encoder ablation study**: Compare perceptual embeddings from different encoder layers/timesteps to determine whether t-1 and full downsampling stack are optimal choices

2. **Contradiction validation**: Manually examine a subset of filtered vs. unfiltered preference pairs to verify that removed contradictions represent annotation noise rather than legitimate preference tradeoffs

3. **Perceptual feature analysis**: Use feature visualization or similarity metrics to verify that U-Net encoder embeddings correlate with human perceptual judgments beyond what pixel/latent space losses capture