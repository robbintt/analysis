---
ver: rpa2
title: 'Symbolic Knowledge Extraction and Injection with Sub-symbolic Predictors:
  A Systematic Literature Review'
arxiv_id: '2501.14836'
source_url: https://arxiv.org/abs/2501.14836
tags:
- https
- knowledge
- learning
- methods
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This systematic literature review synthesizes 132 symbolic knowledge
  extraction (SKE) and 117 symbolic knowledge injection (SKI) methods from 40+ years
  of research, categorizing them by predictor types, data formats, output expressiveness,
  and injection strategies. SKE methods primarily target neural networks and support
  vector machines using pedagogical (black-box) or decompositional (white-box) approaches,
  producing propositional rules, decision trees, or knowledge graphs.
---

# Symbolic Knowledge Extraction and Injection with Sub-symbolic Predictors: A Systematic Literature Review

## Quick Facts
- arXiv ID: 2501.14836
- Source URL: https://arxiv.org/abs/2501.14836
- Reference count: 40
- Primary result: Systematic review of 132 SKE and 117 SKI methods across 40+ years, revealing shift from SKE dominance (1980s-2010s) to SKI growth (post-2015) driven by deep learning advances

## Executive Summary
This systematic literature review comprehensively catalogs symbolic knowledge extraction (SKE) and symbolic knowledge injection (SKI) methods from over four decades of research, organizing 249 distinct approaches by predictor types, data formats, output expressiveness, and injection strategies. The review reveals a significant chronological shift in research focus from SKE methods (predominantly targeting neural networks and SVMs with pedagogical and decompositional approaches) to SKI methods (primarily injecting knowledge graphs and first-order logic into neural networks through predictor structuring, knowledge embedding, and guided learning strategies). The analysis exposes a concerning technology readiness gap, with only 34.9% of methods having runnable software implementations, and provides taxonomies that serve as practical frameworks for method selection and research direction identification in explainable AI.

## Method Summary
The review employed systematic literature search across major databases, identifying 132 SKE and 117 SKI methods through rigorous inclusion criteria focusing on methods that extract or inject symbolic knowledge with sub-symbolic predictors. Methods were categorized by predictor types (neural networks, SVMs, ensembles, decision trees), data formats (tabular, text, images, graphs), output expressiveness (propositional rules, decision trees, knowledge graphs, first-order logic), and injection strategies (predictor structuring, knowledge embedding, guided learning). The temporal analysis tracked publication trends from the 1980s to present, revealing the shift from SKE dominance to SKI growth post-2015, while technology readiness was assessed through availability of runnable software implementations.

## Key Results
- SKE methods primarily target neural networks and SVMs using pedagogical (black-box) or decompositional (white-box) approaches
- SKI methods predominantly use knowledge graphs or first-order logic, employing predictor structuring, knowledge embedding, or guided learning strategies
- Only 34.9% of methods have runnable software implementations, highlighting significant technology readiness gap

## Why This Works (Mechanism)
The review works by systematically organizing complex, heterogeneous research methods into coherent taxonomies that reveal patterns in predictor targeting, knowledge representation, and injection strategies. The mechanism leverages chronological analysis to identify research trend shifts driven by technological advances, while technology readiness assessment exposes implementation gaps that inform practical deployment considerations. The classification framework enables researchers to navigate the landscape of SKE/SKI methods systematically, matching method characteristics to specific application requirements.

## Foundational Learning
- **Pedagogical vs. decompositional SKE approaches**: Pedagogical methods treat predictors as black boxes, focusing on input-output relationships, while decompositional methods analyze internal predictor structures; needed to understand different extraction strategies and their applicability to various predictor types
- **Knowledge graph injection strategies**: Knowledge graphs provide structured, interconnected representations that can guide predictor learning; quick check: verify knowledge graph consistency and coverage before injection
- **Predictor structuring in SKI**: This approach designs predictor architectures that inherently incorporate symbolic knowledge constraints; quick check: ensure structural modifications preserve predictor functionality while embedding knowledge
- **First-order logic expressivity**: FOL provides high expressivity for complex relational knowledge injection; quick check: verify FOL formulas are satisfiable and computationally tractable for the target predictor
- **Technology readiness assessment**: Evaluating implementation availability reveals practical deployment barriers; quick check: verify software dependencies and compatibility with current computing environments

## Architecture Onboarding

Component map: Data Source -> SKE/SKI Method -> Predictor -> Knowledge Representation -> Evaluation Metrics

Critical path: Data preparation → Method selection → Knowledge extraction/injection → Predictor training → Evaluation → Implementation deployment

Design tradeoffs: SKE methods prioritize explainability over predictive accuracy, while SKI methods balance knowledge injection strength against predictor performance degradation; pedagogical approaches offer simplicity but limited insight, decompositional approaches provide depth but require predictor transparency

Failure signatures: SKE failures manifest as overly complex or inaccurate extracted rules; SKI failures appear as predictor performance degradation or knowledge injection that contradicts training data; both can fail due to incompatible knowledge representations

First experiments:
1. Extract rules from a simple neural network on tabular data using a pedagogical SKE method
2. Inject basic first-order logic constraints into a neural network using predictor structuring
3. Compare performance of SKI methods using knowledge graphs versus propositional rules on the same predictor architecture

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Temporal analysis may oversimplify methodological evolution and cross-pollination between SKE and SKI approaches
- Technology readiness assessment may underestimate implementation availability due to unpublished or proprietary code
- Taxonomy applicability to emerging AI paradigms like large language models remains untested

## Confidence
- Systematic methodology: High
- Temporal trend analysis: Medium
- Technology readiness assessment: Medium
- Taxonomy applicability: Low (to emerging paradigms)

## Next Checks
1. Validate technology readiness assessment by attempting to run implementations for representative methods across different predictor types
2. Test taxonomy applicability by mapping recently published SKE/SKI methods targeting transformer architectures
3. Conduct comparative performance evaluation of selected SKE and SKI methods on benchmark datasets to assess practical utility differences