---
ver: rpa2
title: 'FrogDeepSDM: Improving Frog Counting and Occurrence Prediction Using Multimodal
  Data and Pseudo-Absence Imputation'
arxiv_id: '2510.19305'
source_url: https://arxiv.org/abs/2510.19305
tags:
- data
- frog
- species
- dataset
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study develops a multimodal Species Distribution Model (SDM)
  for frog (Anura) conservation using diverse data sources. The approach integrates
  high-resolution satellite imagery, environmental covariates, and land cover data
  to improve species distribution predictions.
---

# FrogDeepSDM: Improving Frog Counting and Occurrence Prediction Using Multimodal Data and Pseudo-Absence Imputation

## Quick Facts
- **arXiv ID:** 2510.19305
- **Source URL:** https://arxiv.org/abs/2510.19305
- **Reference count:** 40
- **Primary result:** Achieved 84.9% accuracy with AUC 0.90 for frog presence/absence classification and reduced MAE from 189 to 29 for frog counting

## Executive Summary
This study develops a multimodal Species Distribution Model (SDM) for frog (Anura) conservation using diverse data sources. The approach integrates high-resolution satellite imagery, environmental covariates, and land cover data to improve species distribution predictions. Key contributions include data balancing techniques like Adaptive Oversampling and custom loss functions to address class imbalance, pseudo-absence data imputation that incorporates land cover and distance criteria, and a multimodal deep learning architecture with late fusion of image and tabular data. The model achieved 84.9% accuracy with an AUC of 0.90 for presence/absence classification and reduced Mean Absolute Error from 189 to 29 for frog counting. The approach demonstrates strong generalization across unseen regions and offers a scalable tool for biodiversity monitoring and conservation planning.

## Method Summary
The method processes multimodal data through a dual-branch architecture: a ResNet50 backbone extracts spatial features from satellite imagery while a sequential dense network processes environmental covariates. These modalities are fused in latent space before classification or regression. The approach addresses data imbalance through Adaptive Oversampling using K-means clustering on climate features and generates pseudo-absence data based on land cover similarity and distance thresholds to avoid geographic bias. The model was trained on 30km² grid cells from the EY Biodiversity Challenge dataset covering Australia, South Africa, and Costa Rica, achieving strong performance across both presence/absence classification and frog counting tasks.

## Key Results
- 84.9% accuracy with ROC AUC of 0.90 for frog presence/absence classification
- Mean Absolute Error reduced from 189 to 29 for frog counting
- Strong generalization demonstrated across Australia, South Africa, and Costa Rica despite severe class imbalance
- Multimodal ensemble outperformed individual models trained on single data sources

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Integrating satellite imagery and tabular environmental data via late fusion improves predictive performance over single-modality approaches by capturing both spatial textures and climatic context.
- **Mechanism:** The architecture processes distinct modalities separately: a ResNet50 backbone extracts spatial features (e.g., vegetation texture from NDVI/Land Cover) while a sequential dense network extracts climatic correlations (e.g., soil moisture from TerraClimate). These features are concatenated in latent space, allowing the final dense layers to learn cross-modal dependencies (e.g., "high vegetation" + "high soil moisture" = high probability of presence) that neither modality captures alone.
- **Core assumption:** The assumption is that spatial features (pixels) and tabular covariates (climate stats) provide non-redundant information about species distribution, and their correlation is linearly separable in the final fused layers.
- **Evidence anchors:**
  - [abstract] "The multimodal ensemble model... outperformed individual models."
  - [section 2.4.1] Describes the fusion of a flattened array of 32,768 image features and 1,280 numeric features into a combined vector.
  - [corpus] "BioAnalyst" supports the efficacy of multimodal foundation models for heterogeneous ecological data.
- **Break condition:** Performance degrades if one modality contains noisy or redundant data that drowns out the signal of the other (e.g., if Land Cover perfectly predicts climate, fusion adds no new information).

### Mechanism 2
- **Claim:** Generating pseudo-absence data based on land cover similarity and distance criteria improves generalization compared to random selection by reducing geographic bias.
- **Mechanism:** Instead of marking random unvisited locations as "absent" (which may actually be suitable habitats), this method identifies grid cells that share the same land cover type as presence points but fall outside a specific distance threshold (e.g., 10km for Australia). This creates "hard negatives"—environmentally similar but geographically distinct locations—forcing the model to learn finer-grained distinctions rather than relying on broad habitat proxies.
- **Core assumption:** The method assumes that if a species is not observed in a specific land cover type within the distance threshold, it is genuinely absent or the sampling effort was sufficiently high to treat it as absence.
- **Evidence anchors:**
  - [abstract] "pseudo-absence data imputation that incorporates land cover and distance criteria."
  - [section 3.2.2] Table 4 shows the proposed method achieved 84.8% validation accuracy vs. 65.9% for random selection.
  - [corpus] "On the selection and effectiveness of pseudo-absences..." confirms that pseudo-absence strategies significantly impact SDM performance.
- **Break condition:** The mechanism fails if the "absence" points are actually unsampled presences, which would teach the model to incorrectly predict absence in suitable habitats.

### Mechanism 3
- **Claim:** Adaptive oversampling using K-means clustering mitigates the "long tail" of imbalanced count data, stabilizing regression training.
- **Mechanism:** The dataset is dominated by low frog counts (1-10). Simple duplication causes overfitting. By clustering minority class instances (using TerraClimate features) and selecting unique representatives, the method synthesizes variability. This prevents the gradient descent from being overwhelmed by the majority class, allowing the model to minimize error on rare, high-count instances.
- **Core assumption:** It assumes that climatic features (TerraClimate) are the primary drivers of the diversity within the minority classes, and that interpolating within these clusters creates valid synthetic examples.
- **Evidence anchors:**
  - [abstract] "Data balancing techniques... reducing the Mean Absolute Error (MAE) from 189 to 29."
  - [section 2.2.2] Describes using K-means on TerraClimate features to select unique instances rather than duplicating.
  - [corpus] "TasselNetV4" discusses cross-species counting, implicitly supporting the need for robust density estimation techniques in imbalanced settings.
- **Break condition:** If the clusters are too broad, the "unique instances" may not represent biologically plausible frog counts, leading to high variance in predictions.

## Foundational Learning

### Concept: Species Distribution Modeling (SDM)
- **Why needed here:** This is the core domain problem. Understanding that SDM correlates environmental covariates (predictors) with species occurrence (target) is required to frame the architectural choices.
- **Quick check question:** Why is "presence-only" data insufficient for standard classification, necessitating pseudo-absence generation?

### Concept: Late Fusion in Multimodal Learning
- **Why needed here:** The architecture relies on fusing image and tabular data. You must understand that late fusion keeps feature extraction separate until the penultimate layer, preserving modality-specific patterns (texture vs. scalar values).
- **Quick check question:** How does late fusion differ from early fusion (concatenating raw data), and why is it preferred for heterogeneous data like images and climate tables?

### Concept: Pseudo-Absence Imputation
- **Why needed here:** Ground truth absence data is missing. You need to grasp that generating "fake" absence data is a modeling compromise to enable binary classification, and the quality of this data defines the model's decision boundary.
- **Quick check question:** What is the risk of selecting pseudo-absence points that are actually suitable habitats?

## Architecture Onboarding

### Component map:
- Input: 30km² Grid Cells containing Sentinel-2/Land Cover images & TerraClimate tabular data
- Branch 1 (Image): ResNet50 (pre-trained) -> Flatten (32,768 features)
- Branch 2 (Tabular): Dense Layers -> Flatten (1,280 features)
- Fusion Head: Concatenate -> Dense -> Output (Sigmoid for classification, ReLU for counting)
- Preprocessing: Adaptive Oversampling (K-means) & Pseudo-absence Generator

### Critical path:
1. Grid Creation (Section 2.2.1): The raw data must be diced into 30km² grids to align satellite pixels with frog counts
2. Pseudo-Absence Generation (Section 2.3): This must happen *before* training to define the "0" class
3. Balancing (Section 2.2.2): Must be applied to the training split to prevent the loss function from ignoring minority classes

### Design tradeoffs:
- Grid Resolution: The paper uses 30km² grids for training but 225km² for validation. They chose *resizing* rather than sliding windows for validation. This sacrifices fine-grained spatial detail for computational efficiency and alignment with the challenge metric
- Backbone: ResNet50 is heavy but effective; lighter models might fail to capture subtle texture differences in land cover
- Loss Function: They use MSLE (Mean Squared Logarithmic Error) for counting. This penalizes underestimates of large counts less harshly than MSE, which suits the long-tail distribution of frog populations

### Failure signatures:
- High MAE (~189): Indicates the model is predicting the mean of the majority class. *Fix:* Check data balancing (Section 2.2.2/3)
- High Validation Gap (Train Acc 90% / Val Acc 70%): Indicates overfitting to specific geographies. *Fix:* Revise pseudo-absence generation to be less geographically constrained or increase augmentation
- AUC ~0.5: Model is guessing. *Fix:* Check input pipeline to ensure image and tabular data are correctly aligned to grid IDs

### First 3 experiments:
1. **Ablation on Pseudo-Absence:** Compare Model performance using Random Selection vs. Distance Criteria vs. Land Cover Criteria (Table 4) to isolate the impact of the imputation method
2. **Modality Ablation:** Train three separate models (RGB-only, Land Cover-only, Numeric-only) and compare against the Fusion Model (Table 3/5) to justify the multimodal overhead
3. **Balancing Impact:** Train on the raw imbalanced dataset vs. the balanced dataset (Table 2) to confirm the reduction in MAE (189 -> 29)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the inclusion of climatic variables (e.g., temperature, precipitation) in the pseudo-absence imputation algorithm improve model discrimination compared to the current land-cover-only method?
- Basis in paper: [explicit] The authors state in the Future Work section that the current pseudo-absence generation relies only on geographical extent and land cover, but "parameters such as temperature and precipitation... should also be considered."
- Why unresolved: While land cover serves as a proxy for habitat, it may not capture microclimatic variations essential for frog survival, potentially misclassifying unsuitable climates as pseudo-absences simply because the land cover matches.
- What evidence would resolve it: An ablation study comparing model performance (AUC and MAE) when pseudo-absence points are filtered using climatic similarity versus the proposed land cover method.

### Open Question 2
- Question: Can incorporating historical climatic data (lagged features) improve the prediction of high-density frog occurrences compared to the synchronous covariates currently used?
- Basis in paper: [explicit] Section 5.1 notes that the model currently uses covariates from 2017–2019, but "incorporating climatic data from previous years could generate additional data and better represent higher frog counts."
- Why unresolved: The current approach assumes immediate environmental conditions drive distribution, ignoring potential time-lags in population responses to climate phenomena (e.g., breeding success dependent on previous year's rainfall).
- What evidence would resolve it: Experiments adding temporal lags (e.g., TerraClimate data from $t-1$, $t-2$ years) to the input tensors to see if regression MAE decreases for high-count grid cells.

### Open Question 3
- Question: Can Graph Neural Networks (GNNs) capture spatial dependencies in SDM tasks more effectively than the proposed CNN-based multimodal architecture?
- Basis in paper: [explicit] The authors mention in Future Work that "A similar approach to the GNN method... could be applied to building an SDM," noting that experiments could not be conducted due to time constraints.
- Why unresolved: The current CNN approach uses grid-based feature extraction, which may struggle with irregular spatial relationships or long-range ecological connectivity that GNNs are designed to model.
- What evidence would resolve it: A comparative analysis benchmarking the proposed ResNet-based model against a GNN architecture on the same dataset, evaluating both accuracy and training efficiency.

## Limitations
- Spatial resolution trade-off: The 30km² grid cells may oversimplify fine-scale habitat preferences, potentially missing microhabitat variations critical for frog distributions
- Geographic sampling bias: With 82% of data from Australia, model performance in Costa Rica and South Africa may reflect data imbalance rather than true generalization capability
- Temporal data gap: No mention of temporal dynamics in frog populations; the model assumes static environmental conditions despite seasonal breeding patterns

## Confidence
- **High confidence:** Classification accuracy (84.9% with AUC 0.90) and counting MAE reduction (189 to 29) are directly measured and reproducible
- **Medium confidence:** Generalization claims across countries require additional validation given severe class imbalance
- **Low confidence:** Extrapolation to other taxa beyond Anura is not tested

## Next Checks
1. **Temporal validation:** Test model performance across different breeding seasons to assess temporal generalization
2. **Fine-scale resolution test:** Compare 30km² vs. 5km² grid performance to quantify resolution trade-offs
3. **Cross-taxon transferability:** Apply the multimodal architecture to another indicator species (e.g., salamanders) using the same framework to test domain transferability