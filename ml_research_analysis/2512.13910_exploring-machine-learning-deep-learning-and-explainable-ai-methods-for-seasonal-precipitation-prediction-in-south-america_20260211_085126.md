---
ver: rpa2
title: Exploring Machine Learning, Deep Learning, and Explainable AI Methods for Seasonal
  Precipitation Prediction in South America
arxiv_id: '2512.13910'
source_url: https://arxiv.org/abs/2512.13910
tags:
- precipitation
- lstm
- xgboost
- forecasting
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates multiple machine learning and deep learning
  models for seasonal precipitation forecasting in South America, comparing them with
  traditional dynamic modeling. Classical ML techniques (Random Forests, XGBoost)
  and DL models (1D-CNN, LSTM, GRU) were trained using GPCP precipitation data and
  climate variables from NCEP-NCAR reanalysis.
---

# Exploring Machine Learning, Deep Learning, and Explainable AI Methods for Seasonal Precipitation Prediction in South America

## Quick Facts
- **arXiv ID**: 2512.13910
- **Source URL**: https://arxiv.org/abs/2512.13910
- **Reference count**: 8
- **Primary result**: LSTM achieves best overall accuracy (MSE: 0.43, R²: 0.93 in spring) while XGBoost excels in computational efficiency (latency: 3.3 ms)

## Executive Summary
This study evaluates multiple machine learning and deep learning models for seasonal precipitation forecasting in South America, comparing them with traditional dynamic modeling. Classical ML techniques (Random Forests, XGBoost) and DL models (1D-CNN, LSTM, GRU) were trained using GPCP precipitation data and climate variables from NCEP-NCAR reanalysis. Performance was assessed using MSE, R², POD, FAR, and latency. LSTM showed the best overall accuracy (MSE: 0.43, R²: 0.93 in spring), while XGBoost excelled in computational efficiency (latency: 3.3 ms) but had lower accuracy. SHAP analysis revealed that past precipitation, temperature, and wind components were the most influential predictors. The results confirm the viability of DL models for climate forecasting, balancing accuracy and detection of heavy precipitation events, with XGBoost offering a cost-effective alternative when computational speed is prioritized.

## Method Summary
The study forecasts seasonal precipitation across South America using an 80/20 train/validation split with 2019 held out for testing. Input data combines GPCP precipitation with NCEP-NCAR Reanalysis 1 variables (sea level pressure, surface air temperature, temperature/specific humidity/wind components at 850 hPa, zonal wind at 500 hPa, precipitation) regridded to 2.5°×2.5° resolution over a 24×28 grid. High-correlation variables were removed. DL models used 5 hidden layers [256, 128, 64, 32, 64, 128, 256], ReLU activation, AdamW optimizer (lr=0.001), batch size 96, 1000 epochs with early stopping. XGBoost used lr=0.1, max_depth=6, subsample=0.8. Random Forest used 1000 trees. All data underwent Z-score normalization and seasonal lag feature construction.

## Key Results
- LSTM achieved the best overall accuracy with MSE: 0.43 and R²: 0.93 in spring season
- XGBoost demonstrated superior computational efficiency with latency of approximately 3.3 ms
- SHAP analysis identified past precipitation, temperature, and wind components as the most influential predictors
- Models showed varying performance across seasons, with LSTM consistently outperforming other approaches in detection of heavy precipitation events

## Why This Works (Mechanism)
The study's success stems from leveraging both temporal and spatial climate patterns through deep learning architectures that can capture complex, non-linear relationships in atmospheric data. The LSTM's ability to maintain memory across sequences makes it particularly effective for seasonal forecasting where past conditions strongly influence future precipitation patterns. The use of SHAP analysis provides interpretability by quantifying feature importance, revealing that physical variables like temperature and wind components drive model predictions. The combination of multiple data sources (GPCP and NCEP-NCAR) provides comprehensive atmospheric information that enhances prediction accuracy.

## Foundational Learning
- **Seasonal lag feature construction**: Previous season's climate variables predict next season's precipitation. Quick check: Verify lag features correctly align with target seasons.
- **Spatial grid preprocessing**: 24×28 grid at 2.5°×2.5° resolution captures South American domain. Quick check: Confirm grid covers continental area without significant coastline gaps.
- **Z-score normalization**: Standardizes variables for model convergence. Quick check: Verify mean≈0 and std≈1 across training set.
- **Heavy precipitation threshold**: Events exceeding 95th percentile define extreme precipitation. Quick check: Calculate season-specific thresholds from training data.
- **SHAP feature importance**: Quantifies predictor influence on model outputs. Quick check: Verify SHAP values sum to model output across test samples.

## Architecture Onboarding

**Component Map**: Data preprocessing -> Model training -> Performance evaluation -> Interpretability analysis

**Critical Path**: GPCP/NCEP-NCAR data → Seasonal lag features → Normalization → Model training → Test evaluation → SHAP analysis

**Design Tradeoffs**: LSTM vs XGBoost: Accuracy vs latency. DL models capture complex temporal patterns but require more computation; classical ML offers speed with lower accuracy.

**Failure Signatures**: 
- Systematic underestimation in Amazon/southern Brazil indicates poor capture of regional precipitation dynamics
- POD ≈ FAR suggests model lacks discriminative power for extreme events
- High MSE with low R² indicates poor overall fit despite variance explanation

**First Experiments**:
1. Train LSTM with specified architecture on 80% training data, evaluate on 2019 test set
2. Compare XGBoost and RF baseline performance against LSTM results
3. Generate SHAP values for top predictors and visualize feature importance across seasons

## Open Questions the Paper Calls Out
- Can Graph Neural Networks (GNNs) outperform the current LSTM baseline by more effectively capturing the spatial dependencies inherent in South American precipitation data? The authors state they "aim to explore graph neural networks... taking advantage of their benefits in capturing spatial and temporal dependencies, which could lead to better accuracy in climate predictions."
- To what degree can automated hyperparameter optimization (e.g., Optuna) narrow the performance gap between the high-latency LSTM and the computationally efficient XGBoost? The authors note, "For the future, we plan to use Optuna to optimize the hyperparameters, which may further improve model performance."
- Can the integration of explicit anomaly detection mechanisms improve the model's Probability of Detection (POD) and False Alarm Rate (FAR) for extreme precipitation events? The authors state they "plan to incorporate anomaly prediction to better understand unexpected variations and extreme events."

## Limitations
- CNN-1D architecture details (kernel sizes, strides, padding, filters) are not specified, limiting exact reproduction
- Sequence construction method for LSTM unclear, particularly how spatial coordinates are incorporated as features
- Loss function used during training not explicitly stated, though MSE is assumed
- Test set restricted to single year (2019) limits generalizability across different climate conditions

## Confidence
- **High confidence**: Comparative performance metrics (MSE, R², POD, FAR, latency) and their rankings across models
- **Medium confidence**: Feature importance analysis via SHAP, as specific methodology and validation are not fully detailed
- **Low confidence**: Exact model architectures beyond LSTM specifications

## Next Checks
1. Implement and compare the full range of models (LSTM, XGBoost, RF, CNN-1D) using specified hyperparameters and data preprocessing to verify reported performance metrics
2. Validate feature importance rankings by recomputing SHAP values on held-out test set and checking stability across seasons
3. Perform error analysis focusing on spatial patterns of underestimation, particularly in regions like Amazon and southern Brazil, to identify systematic biases in extreme precipitation forecasting