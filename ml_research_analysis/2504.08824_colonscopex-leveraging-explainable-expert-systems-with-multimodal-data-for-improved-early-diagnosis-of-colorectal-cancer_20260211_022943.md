---
ver: rpa2
title: 'ColonScopeX: Leveraging Explainable Expert Systems with Multimodal Data for
  Improved Early Diagnosis of Colorectal Cancer'
arxiv_id: '2504.08824'
source_url: https://arxiv.org/abs/2504.08824
tags:
- cancer
- data
- patient
- fusion
- spectral
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ColonScopeX integrates Raman spectroscopy with patient metadata
  to detect colorectal cancer and polyps. The system processes blood samples using
  Savitzky-Golay smoothing and combines spectral data with clinical information such
  as medications, comorbidities, and demographics.
---

# ColonScopeX: Leveraging Explainable Expert Systems with Multimodal Data for Improved Early Diagnosis of Colorectal Cancer

## Quick Facts
- arXiv ID: 2504.08824
- Source URL: https://arxiv.org/abs/2504.08824
- Reference count: 10
- Primary result: 97.6% accuracy for CRC detection and 89.6% for polyps using multimodal Raman + metadata fusion

## Executive Summary
ColonScopeX is a non-invasive blood-based screening system for colorectal cancer (CRC) and polyps that combines Raman spectroscopy with patient metadata using multimodal fusion. The system achieves up to 97.6% accuracy for CRC detection and 89.6% for polyps, outperforming existing blood-based CRC tests. Explainable AI methods (SHAP and LIME) identify key spectral and clinical features, enabling clinicians to verify model reasoning against biochemical knowledge. The approach addresses critical limitations of current screening methods by offering a rapid, non-invasive alternative to colonoscopy.

## Method Summary
ColonScopeX integrates Raman spectroscopy fingerprints from blood serum with comprehensive patient metadata (medications, comorbidities, smoking status, age, sex, BMI). Spectral data undergoes Savitzky-Golay smoothing, fluorescent background correction, cosmic ray removal, and normalization to the phenylalanine peak (1002 cm⁻¹). Three fusion architectures (early, joint, late) combine processed spectra with scaled metadata, with joint fusion showing superior performance for polyps (AUC 0.887) and early fusion for CRC accuracy (97.6%). Two separate binary models are trained for CRC vs control and polyp vs control classifications. Explainable AI methods (SHAP and LIME) identify feature contributions, with consensus filtering used to address LIME instability.

## Key Results
- Achieved 97.6% accuracy for CRC detection (AUC 0.975) and 89.6% for polyps (AUC 0.887)
- Joint fusion model outperformed single-modality approaches for polyp detection (F1: 0.746 vs 0.263 for late fusion)
- Early fusion achieved highest CRC accuracy (97.6%) with precision 0.981 and recall 0.975
- Explainable AI identified key spectral peaks and metadata features, with consensus filtering addressing LIME instability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multimodal fusion of Raman spectroscopy with patient metadata improves CRC and polyp detection accuracy compared to single-modality approaches.
- Mechanism: Spectral data captures metabolic signatures of disease while patient metadata provides contextual risk factors. Joint fusion allows learning cross-modal correlations—spectral peaks may be more predictive when combined with age, sex, or prior malignancy history.
- Core assumption: CRC and polyps produce detectable metabolic alterations in blood serum that correlate with Raman spectral shifts, and these signals are modulated by patient-specific factors.
- Evidence anchors: "multimodal model that integrates signals from blood sample measurements... alongside comprehensive patient metadata"; Wang et al. (2023) multimodal CNN improved accuracy from 85.14% to 88.55% for prostate cancer using SERS + clinical features.
- Break condition: If spectral preprocessing does not consistently remove noise while preserving disease-relevant peaks, or if metadata features introduce confounding, fusion may amplify noise rather than signal.

### Mechanism 2
- Claim: Optimized spectral preprocessing (Savitzky-Golay smoothing, background correction, normalization) enhances signal-to-noise ratio for downstream classification.
- Mechanism: Raw Raman spectra contain fluorescent background, cosmic ray artifacts, and instrument noise. Savitzky-Golay smoothing preserves peak shapes while reducing high-frequency noise. Normalization to phenylalanine peak (1002 cm⁻¹) standardizes intensity across samples.
- Core assumption: Disease-relevant spectral features are preserved through smoothing and correction steps, and the phenylalanine peak provides a stable internal reference.
- Evidence anchors: "processed using Savitzky-Golay algorithm for fingerprint smoothing"; Woods et al. (2022) preprocessing methods improved sensitivity by 14.6%, specificity by 6.9%, PPV by 3.4%, NPV by 2.4%.
- Break condition: If smoothing window parameters are mis-specified, genuine spectral peaks may be flattened; if background correction overfits, it may remove disease-relevant baseline shifts.

### Mechanism 3
- Claim: Post-hoc explainability methods (SHAP, LIME) identify feature contributions, enabling clinicians to verify model reasoning against biochemical knowledge.
- Mechanism: SHAP computes feature importance via Shapley values; LIME approximates local model behavior with interpretable surrogates. Features flagged by both methods with domain-expert annotation are presented to clinicians.
- Core assumption: SHAP and LIME importance scores align with true causal features of disease, and perturbation-based instability can be mitigated by cross-method consensus.
- Evidence anchors: "Explainable AI methods (SHAP and LIME) identify key features like spectral peaks and patient metadata"; "Literature reports LIME having poor local fidelity and instability... we identified features unique for each class... deemed important by both LIME and SHAP".
- Break condition: If SHAP/LIME feature attributions are inconsistent across runs or fail to map to clinically meaningful biochemical entities, clinician trust and interpretability degrade.

## Foundational Learning

- Concept: **Raman Spectroscopy Fundamentals**
  - Why needed here: Understanding how molecular vibrations produce spectral peaks at specific wavenumbers is essential for interpreting SHAP-flagged features (e.g., "V486" corresponds to ~486 cm⁻¹, linked to specific functional groups).
  - Quick check question: Can you explain why the phenylalanine peak at 1002 cm⁻¹ is used as a normalization reference, and what could cause this peak to vary between samples?

- Concept: **Multimodal Fusion Strategies**
  - Why needed here: The paper compares early, joint, and late fusion; selecting the right strategy depends on data modality alignment and feature interaction complexity.
  - Quick check question: Given that joint fusion outperformed late fusion for polyp detection (F1: 0.746 vs 0.263), what does this suggest about the relationship between spectral and metadata features?

- Concept: **Explainability Stability in Perturbation-Based Methods**
  - Why needed here: SHAP and LIME are noted for instability; understanding their limitations prevents over-reliance on any single explanation.
  - Quick check question: Why might running LIME multiple times on the same input produce different feature rankings, and how does the paper attempt to mitigate this?

## Architecture Onboarding

- Component map: Raw spectrum -> Savitzky-Golay smoothing -> Background correction -> Cosmic ray removal -> Phenylalanine normalization -> QC filtering -> Fusion model input; Patient metadata -> Scaling -> Fusion model input; Fusion model output -> SHAP/LIME analysis -> Metabolite library annotation -> Clinician report

- Critical path: 1) Raw spectrum → preprocessing → QC pass → fusion model input; 2) Patient metadata → data leakage exclusion → scaling → fusion model input; 3) Fusion model output → SHAP/LIME analysis → annotation lookup → clinician report

- Design tradeoffs:
  - **Early vs. Joint vs. Late Fusion**: Joint fusion performs best for polyps (AUC 0.887), early fusion best for CRC accuracy (97.6%), late fusion has high precision but low recall for polyps (0.833 / 0.156)—suggests modalities provide complementary information best captured through intermediate feature learning
  - **Separate CRC/Polyp Models**: Training two binary models rather than one multiclass model addresses class imbalance and feature differences, but increases maintenance complexity
  - **Human-in-the-Loop Annotation**: Metabolite libraries require ongoing expert curation; enables interpretability but introduces subjectivity

- Failure signatures:
  - **Spectral rejection spike**: If baseline QC rejects >20% of samples, calibration may have drifted or patient population differs from training cohort
  - **SHAP/LIME disagreement on top features**: Suggests model instability or insufficient perturbation points—requires consensus threshold tuning
  - **Late fusion low recall for polyps (0.156)**: Model is risk-averse; consider adjusting decision threshold or reweighting loss function for minority class

- First 3 experiments:
  1. **Preprocessing sensitivity analysis**: Vary Savitzky-Golay window size and polynomial order; measure impact on signal-to-noise ratio (SNR) and classification accuracy to find optimal parameters for new instrument setups
  2. **Fusion architecture ablation**: Train all three fusion types on held-out independent cohort; compare generalization gap to identify which architecture transfers best across clinical sites
  3. **Explainability stability test**: Run SHAP/LIME 50 times on fixed sample set with different random seeds; quantify feature ranking variance to establish minimum perturbation count for stable explanations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent does ColonScopeX generalize to patient populations with demographic and geographic characteristics distinct from the original training cohort?
- Basis in paper: [explicit] The authors state that the "dataset may contain inherent biases due to the specific demographic and geographic characteristics" and that a "larger and more varied patient population could confirm the model’s efficacy."
- Why unresolved: The current study relies on a dataset from a specific region (Swansea, UK), creating a risk of overfitting to local population traits and limiting robustness across broader groups.
- What evidence would resolve it: Validation results from multi-center trials involving diverse ethnic and socioeconomic groups not included in the initial training data.

### Open Question 2
- Question: Can the current pre-processing and quality control pipeline maintain classification accuracy when applied to Raman spectra generated by different laboratories or hardware configurations?
- Basis in paper: [explicit] The limitations section notes that "data produced in a different laboratory could not meet our pre- and post-processing quality control (QC)," raising concerns about reproducibility.
- Why unresolved: Variations in measurement equipment and sample handling standards across facilities may introduce spectral noise or drift that the current smoothing and baseline correction algorithms cannot handle.
- What evidence would resolve it: Successful model performance (AUC/accuracy metrics) on spectral data collected from external laboratories using independent hardware.

### Open Question 3
- Question: How does the reintegration of patients with high-risk comorbidities (e.g., Lynch syndrome) or complex medication regimens impact the fusion model's specificity and sensitivity?
- Basis in paper: [explicit] The authors acknowledge that "excluding patients with certain comorbidities... restricted the model’s applicability" and that the model must be tested on "sensitive groups" currently omitted.
- Why unresolved: These groups were excluded to minimize data leakage and noise, leaving a gap in understanding how such metabolic and clinical variables influence the model's decision boundaries.
- What evidence would resolve it: Performance benchmarks derived from a revised dataset that includes previously excluded comorbidities and sensitive subgroups.

## Limitations

- Single-center dataset from Swansea, UK with potential demographic and geographic biases
- Exclusion of Lynch syndrome patients and other high-risk groups limits clinical applicability
- Neural network architecture details for fusion models not fully specified, preventing exact reproduction

## Confidence

- **High**: Spectral preprocessing methodology (well-documented in literature)
- **Medium**: Fusion model performance metrics (architecture-dependent)
- **Low**: Explainability stability claims given acknowledged LIME instability

## Next Checks

1. Run 50-fold SHAP/LIME consistency tests to quantify feature attribution stability
2. Validate fusion model generalization on independent clinical cohort with different demographic composition
3. Perform ablation study removing individual metadata features to assess their true contribution versus confounding effects