---
ver: rpa2
title: 'The Trajectory Bundle Method: Unifying Sequential-Convex Programming and Sampling-Based
  Trajectory Optimization'
arxiv_id: '2509.26575'
source_url: https://arxiv.org/abs/2509.26575
tags:
- trajectory
- optimization
- control
- problem
- these
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents the Trajectory Bundle Method (TBM), a unified
  framework for solving trajectory optimization problems in a derivative-free manner
  through sequential convex programming. The core idea is to approximate nonlinear
  cost and constraint functions by sampling nearby trajectories and linearly interpolating
  between them, rather than using derivative-based Taylor series expansions.
---

# The Trajectory Bundle Method: Unifying Sequential-Convex Programming and Sampling-Based Trajectory Optimization

## Quick Facts
- arXiv ID: 2509.26575
- Source URL: https://arxiv.org/abs/2509.26575
- Reference count: 40
- One-line primary result: The paper presents the Trajectory Bundle Method (TBM), a unified framework for solving trajectory optimization problems in a derivative-free manner through sequential convex programming.

## Executive Summary
The Trajectory Bundle Method (TBM) introduces a novel approach to trajectory optimization that bridges sequential convex programming (SCP) and sampling-based methods like Model Predictive Path Integral (MPPI) control. Instead of using derivative-based Taylor expansions to approximate nonlinear cost and constraint functions, TBM samples nearby trajectories and linearly interpolates between them. This derivative-free approach naturally handles problems where gradients are unavailable or unreliable, such as with learned dynamics models or contact-rich systems. The method is demonstrated on challenging robotics problems including collision avoidance, aggressive quadrotor trajectory tracking, cartpole swingup with neural network dynamics, and minimum-time autonomous racing.

## Method Summary
TBM solves trajectory optimization problems by iteratively constructing convex approximations of the original nonlinear problem through sampling. The method generates a "bundle" of m perturbed trajectories around the current iterate, evaluates costs and constraints for all samples in parallel, then constructs interpolation matrices to form a linear program. The optimization variables are interpolation weights α on the probability simplex, which implicitly restricts solutions to the convex hull of sampled points. Hard constraints are handled via slack variables with ℓ₁ penalties to ensure sub-problems remain feasible. The framework generalizes MPPI to support multiple shooting, arbitrary constraints, and general trajectory optimization problems while maintaining derivative-free operation.

## Key Results
- Successfully solved collision avoidance for a double integrator while maintaining constraint satisfaction
- Achieved aggressive quadrotor trajectory tracking where MPPI failed due to system instability
- Handled cartpole swingup with neural network dynamics without requiring gradient information
- Demonstrated competitive performance on minimum-time autonomous racing with nonsmooth dynamics

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Nonlinear cost and constraint functions can be locally approximated as affine using only function evaluations (samples), avoiding the need for analytic gradients.
- **Mechanism:** Instead of a Taylor expansion, the method samples m points around the current iterate and constructs a linear interpolant p̂(y) = W_p α. The optimization variable becomes α (a weight vector on the probability simplex Δ^(m-1)), which implicitly restricts the solution to the convex hull of the sampled points (the "bundle").
- **Core assumption:** The function is well-approximated by a hyperplane within the local convex hull of the sampled points.
- **Evidence anchors:** [abstract]: "...approximate the cost and constraint functions by sampling nearby trajectories and linearly interpolating between them..."; [section III-A.2]: Describes linear interpolation where p(W_y α) ≈ W_p α.
- **Break condition:** The trust region (sample distribution) becomes larger than the region of linearity for the dynamics/costs, causing the affine approximation to diverge significantly from the true function.

### Mechanism 2
- **Claim:** The framework generalizes sampling-based control (like MPPI) to handle open-loop unstable systems and general constraints by utilizing a multiple-shooting formulation.
- **Mechanism:** Unlike single-shooting (MPPI) which rolls out controls sequentially, TBM optimizes over state and control sequences simultaneously. It enforces dynamic feasibility via interpolated defect constraints (W_x^(k+1) α^(k+1) = W_f^k α^k + s^(k)) rather than sequential rollouts, preventing error accumulation in unstable systems.
- **Core assumption:** The convex solver can find a feasible set of weights α that satisfies the interpolated dynamics and constraints despite system instability.
- **Evidence anchors:** [abstract]: "...generalizes them to enable features like multiple shooting and general equality and inequality constraints..."; [section V-B]: Shows TBM solving a quadrotor tracking problem where MPPI fails due to instability.
- **Break condition:** The system is so unstable that the linear interpolation of the dynamics (W_f α) provides a poor predictor for the state at the next knot point, leading to infeasible sub-problems.

### Mechanism 3
- **Claim:** Hard constraints are handled reliably by introducing slack variables and ℓ₁ penalties, ensuring the sequential convex sub-problems remain feasible even with poor initial guesses.
- **Mechanism:** The method converts hard constraints c(z)=0 into a soft penalty form min μ||s||₁ subject to ĉ(z) + s = 0. This guarantees the linear program always has a solution, preventing the solver from crashing on infeasible iterates.
- **Core assumption:** The penalty coefficient μ is large enough to drive constraint violations to zero as the algorithm converges.
- **Evidence anchors:** [section III-B]: Eq. (11) and (15) explicitly show the relaxation using slack variables s; [section IV-B]: Eq. (22) applies this relaxation to the trajectory bundle constraints.
- **Break condition:** The penalty weight μ is insufficient, causing the solver to prioritize cost reduction over constraint satisfaction, resulting in constraint violation at convergence.

## Foundational Learning

- **Concept:** Sequential Convex Programming (SCP)
  - **Why needed here:** TBM is fundamentally an SCP solver; it replaces the "linearization" step with "linear interpolation." Understanding SCP provides the scaffold for how the iteration loop (approximate → solve → update) functions.
  - **Quick check question:** Why does SCP convert a non-convex problem into a *sequence* of convex problems rather than one convex problem?

- **Concept:** Simplex and Barycentric Coordinates
  - **Why needed here:** The decision variable α lies on a simplex (Σ α_i = 1, α ≥ 0). This geometric constraint is what allows TBM to define the solution as a weighted average of samples.
  - **Quick check question:** If α is restricted to the simplex, what geometric region defines the allowable solutions for the next trajectory iterate?

- **Concept:** Multiple Shooting vs. Single Shooting
  - **Why needed here:** The paper positions TBM as a bridge between MPPI (single shooting) and SCP (multiple shooting). Recognizing the difference is crucial for understanding why TBM handles unstable dynamics better than MPPI.
  - **Quick check question:** In multiple shooting, are the intermediate states variables to be optimized, or are they determined solely by the initial state and controls?

## Architecture Onboarding

- **Component map:** Sampler -> Parallel Evaluator -> Matrix Builder -> Convex Solver -> Update Step
- **Critical path:** The Parallel Evaluator is the computational bottleneck. While the convex solver is fast, the method relies on massively parallel simulation (e.g., Isaac Sim, MJX) to evaluate the "bundle" quickly.
- **Design tradeoffs:**
  - Sample Strategy: Coordinate directions are deterministic and sparse (2n+1 samples), while Gaussian sampling covers the space stochastically but requires more samples for coverage.
  - Trust Region Size: Determined by the sampling distribution width. Too wide → poor linear approximation; too narrow → slow convergence / getting stuck in local minima.
- **Failure signatures:**
  - "Jamming" / Slow Convergence: The trust region (sample radius) is too small, or the coordinate samples fail to capture the curvature of the cost landscape.
  - Infeasible Slacks: If slacks s do not converge to zero, the problem may be ill-posed or the penalty μ needs adjustment.
- **First 3 experiments:**
  1. Toy 1D Quadratic: Implement the linear interpolation (Eq. 7-8) on a simple 1D cost function to verify that minimizing W_p α recovers the analytical minimum.
  2. Unstable Linear System: Compare TBM (multiple shooting) vs. MPPI (single shooting) on a simple inverted pendulum or unstable linear system to demonstrate stability handling.
  3. Constraint Satisfaction: Implement a double integrator collision avoidance task (as in Fig 3) to test the slack variable mechanism on non-convex constraints.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can a reliable metric for optimality be established for the Trajectory Bundle Method (TBM) in the absence of derivative information?
- Basis in paper: [explicit] Section VII states that while constraint violations are easily computed, "a reliable metric for optimality is still an open question since derivatives are required to compute optimality conditions."
- Why unresolved: Standard optimality conditions (like KKT criteria) rely on gradients (Jacobians), which TBM explicitly avoids computing to remain a derivative-free method.
- What evidence would resolve it: A surrogate metric that provably correlates with local optimality or a theoretical framework for verifying optimality without gradient information.

### Open Question 2
- Question: What is the optimal strategy for sampling distributions, and can "learned distributions" significantly improve convergence speed or robustness?
- Basis in paper: [explicit] Section VII highlights that "identifying the ideal distribution to draw samples from" is a challenge and suggests "opportunities to use more expressive and potentially learned distributions for better convergence."
- Why unresolved: The current paper relies on simple deterministic or Gaussian distributions; the authors note that performance is currently independent of the distribution but hypothesize that more complex distributions could yield better results.
- What evidence would resolve it: Empirical results demonstrating that an adaptive or learned sampling distribution outperforms fixed Gaussian or uniform strategies on standard benchmarks.

### Open Question 3
- Question: Can robust convergence rate guarantees be established for TBM, potentially through adaptive mechanisms for the penalty parameter μ and trust region?
- Basis in paper: [explicit] Section VII lists "a robust convergence rate guarantee" as a limitation, noting it "will likely require an adaptive penalty μ and adaptation of the trust region."
- Why unresolved: The current work presents the framework and numerical experiments but leaves the theoretical analysis of convergence rates and the dynamic adjustment of hyperparameters as future work.
- What evidence would resolve it: Theoretical proofs bounding the number of iterations required to reach a solution of specific accuracy, or an adaptive algorithm with proven convergence properties.

## Limitations

- The method's computational overhead from parallel trajectory evaluation may limit real-time applicability for high-dimensional problems
- Scalability to very high-dimensional state spaces (e.g., humanoid robots) is not demonstrated, leaving questions about practical limits
- Lack of comparison against established derivative-free optimization methods beyond MPPI limits validation of advantages

## Confidence

- **High Confidence:** The core mechanism of linear interpolation for derivative-free trajectory optimization is well-supported by mathematical formulation and validated through multiple experiments showing constraint satisfaction and convergence
- **Medium Confidence:** The generalization of sampling-based control to multiple shooting is demonstrated in the quadrotor experiment, but the comparison with MPPI is limited to a single unstable system
- **Medium Confidence:** The slack variable mechanism for handling hard constraints is theoretically sound and works in practice, but edge cases where constraints might be fundamentally infeasible are not explored

## Next Checks

1. **Cross-validation against derivative-free optimizers:** Implement a direct comparison between TBM and established derivative-free methods (e.g., Bayesian optimization or CMA-ES) on a benchmark trajectory optimization problem with known gradients, measuring both solution quality and computational efficiency.

2. **Scalability testing:** Apply TBM to a high-dimensional robotic system (e.g., 7+ DOF manipulator or humanoid robot) and measure how the number of required samples scales with state dimension, comparing against theoretical predictions of sample complexity.

3. **Real-time performance analysis:** Profile the complete pipeline (sampling, evaluation, solving) on a resource-constrained platform (e.g., embedded GPU or multi-core CPU) to determine the maximum feasible horizon length and update rate for different problem sizes.