---
ver: rpa2
title: Few-Shot VLM-Based G-Code and HMI Verification in CNC Machining
arxiv_id: '2512.11296'
source_url: https://arxiv.org/abs/2512.11296
tags:
- g-code
- errors
- machine
- few-shot
- json
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a few-shot vision-language model (VLM)-based
  framework for verifying G-code and Human-Machine Interface (HMI) states in CNC machining.
  The method integrates textual G-code commands with visual HMI screenshots, using
  a structured JSON schema to capture machine readiness indicators (collet clamp,
  REF X, REF Z).
---

# Few-Shot VLM-Based G-Code and HMI Verification in CNC Machining

## Quick Facts
- arXiv ID: 2512.11296
- Source URL: https://arxiv.org/abs/2512.11296
- Reference count: 28
- Few-shot VLM framework achieves up to 93.8% accuracy for REF X slot detection and cosine similarity up to 0.750 for semantic alignment

## Executive Summary
This paper introduces a few-shot vision-language model (VLM)-based framework for verifying G-code commands against Human-Machine Interface (HMI) states in CNC machining. The approach combines textual G-code with visual HMI screenshots using a structured JSON schema to capture machine readiness indicators. By employing few-shot prompting with example G-code/HMI pairs, the framework significantly improves discrepancy detection compared to zero-shot methods. The system enhances semantic alignment in error descriptions and supports safer manual G-code development by identifying syntax and state inconsistencies before machining operations.

## Method Summary
The framework integrates G-code textual commands with visual HMI screenshots through a VLM, using structured JSON schemas to represent machine readiness states (collet clamp, REF X, REF Z). Few-shot prompting provides the model with example G-code/HMI pairs to improve its understanding of the correspondence between code commands and machine states. The verification process detects discrepancies between the intended operations specified in G-code and the actual machine state shown on the HMI, with enhanced semantic alignment in the resulting error descriptions.

## Key Results
- Achieves up to 93.8% accuracy for REF X slot detection in HMI verification
- Improves semantic alignment in error descriptions with cosine similarity reaching 0.750
- Combines few-shot examples with cropped HMI regions to enhance both structural accuracy and natural language consistency in verification outputs

## Why This Works (Mechanism)
The framework leverages the multimodal capabilities of VLMs to process both textual G-code commands and visual HMI states simultaneously. Few-shot prompting provides the model with concrete examples of the relationship between G-code operations and corresponding HMI indicators, enabling it to learn the semantic mapping between these modalities. The structured JSON schema provides a consistent format for capturing machine readiness states, while cropping HMI regions focuses the model's attention on relevant indicators rather than background noise.

## Foundational Learning
- Vision-Language Models (VLMs): Understand how VLMs process both visual and textual information simultaneously; quick check: verify the model can correctly identify objects in images and understand related text descriptions
- Few-Shot Learning: Learn how providing examples improves model performance on new tasks; quick check: test model performance with varying numbers of example pairs
- CNC Machining Workflow: Understand the relationship between G-code commands and machine states; quick check: verify that G-code commands correctly correspond to physical machine operations
- JSON Schema Validation: Learn how structured data formats ensure consistency in model inputs and outputs; quick check: validate that all inputs conform to the expected schema structure

## Architecture Onboarding
- Component Map: G-code input -> JSON schema formatter -> VLM with few-shot examples -> HMI screenshot analysis -> Discrepancy detection -> Output verification
- Critical Path: The core verification process flows from G-code and HMI input through the VLM analysis to discrepancy detection
- Design Tradeoffs: Few-shot learning improves accuracy but requires curated example pairs; structured schemas ensure consistency but may limit flexibility
- Failure Signatures: Incorrect G-code parsing, HMI image quality issues, or insufficient few-shot examples can lead to false negatives or poor semantic alignment
- First Experiments:
  1. Test baseline zero-shot performance against few-shot performance with varying example counts
  2. Evaluate accuracy on each individual machine readiness indicator (collet clamp, REF X, REF Z)
  3. Assess semantic alignment quality by measuring cosine similarity between generated and expected error descriptions

## Open Questions the Paper Calls Out
None

## Limitations
- Performance depends heavily on the quality and representativeness of few-shot examples
- Evaluation focuses on limited machine readiness indicators, with uncertain generalizability to other CNC states
- 93.8% accuracy represents a single metric that may not reflect performance across diverse machining scenarios

## Confidence
- High: Framework's ability to detect basic HMI-G-code discrepancies
- Medium: Few-shot learning improvements over zero-shot methods
- Low: Generalizability to broader CNC machining contexts and error types

## Next Checks
1. Expand evaluation to include diverse CNC machine types, G-code dialects, and HMI interfaces beyond the current limited set
2. Conduct comprehensive ablation studies testing few-shot performance with varying numbers of examples, different prompt structures, and comparison against alternative few-shot learning approaches
3. Evaluate real-time performance metrics including inference latency, computational resource requirements, and accuracy under varying lighting conditions, screen resolutions, and camera angles for HMI image capture