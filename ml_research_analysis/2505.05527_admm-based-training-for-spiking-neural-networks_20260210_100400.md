---
ver: rpa2
title: ADMM-Based Training for Spiking Neural Networks
arxiv_id: '2505.05527'
source_url: https://arxiv.org/abs/2505.05527
tags:
- training
- admm
- neural
- learning
- networks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an ADMM-based optimizer for training spiking
  neural networks (SNNs), addressing the non-differentiability of the Heaviside step
  function in SNNs. The authors formulate SNN training as an optimization problem,
  relaxing the hard constraints into soft penalties and deriving closed-form updates
  for weights, membrane potentials, and spikes.
---

# ADMM-Based Training for Spiking Neural Networks

## Quick Facts
- **arXiv ID**: 2505.05527
- **Source URL**: https://arxiv.org/abs/2505.05527
- **Authors**: Giovanni Perin; Cesare Bidini; Riccardo Mazzieri; Michele Rossi
- **Reference count**: 19
- **Primary result**: ADMM-based SNN training achieves 98.6% accuracy for single hidden layer on N-MNIST but degrades to 75.1% for five hidden layers

## Executive Summary
This paper introduces an ADMM-based optimizer for training spiking neural networks (SNNs), addressing the non-differentiability of the Heaviside step function in SNNs. The authors formulate SNN training as an optimization problem, relaxing the hard constraints into soft penalties and deriving closed-form updates for weights, membrane potentials, and spikes. A key contribution is the use of ADMM to handle the non-differentiability via a dedicated subroutine with if-else logic, avoiding surrogate gradients. Experiments on N-MNIST with varying hidden layers show high accuracy (~98.6%) for a single hidden layer but performance degrades with deeper architectures. The approach is scalable and suitable for federated learning. Future improvements could include adaptive hyperparameters and Anderson acceleration.

## Method Summary
The authors propose an ADMM-based training framework for SNNs that circumvents the non-differentiability issue of the Heaviside step function through constrained optimization. The method relaxes hard constraints on spiking behavior into soft penalties with tunable parameters (λ for spike consistency, λ_Δ for membrane potential consistency), enabling closed-form updates for weights, membrane potentials, and spikes. A key innovation is the dedicated ADMM subroutine with if-else logic that directly handles the binary nature of spikes without relying on gradient approximations. The framework alternates between weight updates (quadratic programming with L1 regularization for sparsity) and spike state optimization, with ρ controlling constraint violation penalties. The method is tested on N-MNIST with varying hidden layer configurations.

## Key Results
- Achieves 98.6% accuracy on N-MNIST with single hidden layer
- Performance degrades significantly with depth: 95.4% (2 layers), 85.5% (3 layers), 75.1% (5 layers)
- Sparsity constraints show minimal impact on accuracy but improve energy efficiency
- Training time remains practical for shallow networks
- Method demonstrates potential for federated learning applications

## Why This Works (Mechanism)
The ADMM-based approach works by transforming the non-differentiable SNN training problem into a constrained optimization framework where binary spike constraints are relaxed into soft penalties. This allows the use of alternating direction method of multipliers to separately optimize network parameters and spike states while maintaining global convergence guarantees. The closed-form updates for membrane potentials and spikes eliminate the need for gradient approximations, while the L1 regularization promotes sparse spiking activity. The if-else subroutine directly handles the binary nature of spikes, avoiding the approximation errors inherent in surrogate gradient methods.

## Foundational Learning

**ADMM (Alternating Direction Method of Multipliers)**
*Why needed*: Provides a framework for solving optimization problems with non-differentiable constraints
*Quick check*: Verify convergence properties and understand dual variable updates

**Spiking Neural Networks**
*Why needed*: Biological plausibility and event-driven computation for energy-efficient AI
*Quick check*: Understand integrate-and-fire dynamics and spike-timing dependent behavior

**Heaviside Step Function**
*Why needed*: Models binary spike generation but creates non-differentiability in training
*Quick check*: Recognize why gradient-based methods fail and alternative approaches are needed

**Quadratic Programming**
*Why needed*: Enables closed-form weight updates under L1 regularization
*Quick check*: Confirm convexity of subproblems and optimality conditions

## Architecture Onboarding

**Component Map**
Input -> Encoding -> Hidden Layers (variable depth) -> Decoding -> Output

**Critical Path**
Encoding -> ADMM Optimization Loop -> Spike Generation -> Classification

**Design Tradeoffs**
- Depth vs accuracy: shallow networks perform significantly better
- Sparsity vs performance: L1 regularization provides energy efficiency with minimal accuracy loss
- Hyperparameter tuning: ρ, λ, λ_Δ require careful selection without systematic approach

**Failure Signatures**
- Deep networks (>3 layers) show catastrophic accuracy degradation
- Poor hyperparameter selection leads to constraint violation and training instability
- Insufficient spike-timestep ratio may prevent proper temporal integration

**3 First Experiments**
1. Reproduce single-layer N-MNIST results with baseline hyperparameters
2. Vary ρ parameter to assess constraint violation impact on convergence
3. Test L1 regularization strength to quantify sparsity-accuracy tradeoff

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Significant performance degradation with network depth (98.6% → 75.1% from 1 to 5 layers)
- No systematic approach for hyperparameter selection (ρ, λ, λ_Δ)
- Limited temporal dynamics capture compared to backpropagation-based methods
- Federated learning claims lack empirical validation beyond single-node experiments

## Confidence

**High confidence**: The mathematical formulation of ADMM for SNN training and the derivation of closed-form updates are sound and well-explained

**Medium confidence**: The empirical results are reproducible based on the provided information, though the depth performance degradation needs further investigation

**Low confidence**: The claim about scalability and federated learning suitability lacks empirical validation beyond single-node experiments

## Next Checks

1. Conduct systematic hyperparameter sensitivity analysis to determine optimal ρ, λ, and λ_Δ values across different network depths

2. Implement and evaluate the proposed method on deeper architectures (7+ layers) with modern datasets (CIFAR-10/DVS128-Gesture) to assess scalability claims

3. Compare temporal pattern recognition performance against state-of-the-art SNN training methods using spike train similarity metrics and temporal classification benchmarks