---
ver: rpa2
title: Dynamic VLM-Guided Negative Prompting for Diffusion Models
arxiv_id: '2510.26052'
source_url: https://arxiv.org/abs/2510.26052
tags:
- negative
- guidance
- prompting
- diffusion
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Dynamic VLM-Guided Negative Prompting (VL-DNP),
  a method for adaptive content filtering in diffusion models. Instead of using static
  negative prompts, VL-DNP leverages a Vision-Language Model (VLM) to dynamically
  generate negative prompts during the denoising process by analyzing intermediate
  image predictions.
---

# Dynamic VLM-Guided Negative Prompting for Diffusion Models

## Quick Facts
- arXiv ID: 2510.26052
- Source URL: https://arxiv.org/abs/2510.26052
- Reference count: 8
- Key outcome: Dynamic VLM-guided negative prompting achieves superior safety-alignment trade-off by generating adaptive negative prompts during diffusion denoising

## Executive Summary
This paper introduces Dynamic VLM-Guided Negative Prompting (VL-DNP), a method for adaptive content filtering in diffusion models. Instead of using static negative prompts, VL-DNP leverages a Vision-Language Model (VLM) to dynamically generate negative prompts during the denoising process by analyzing intermediate image predictions. This approach detects and suppresses unwanted content in real-time while maintaining image fidelity. Evaluated on safety and alignment benchmarks, VL-DNP consistently outperforms static negative prompting in the safety-alignment trade-off, achieving lower Attack Success Rates and Toxic Rates while preserving CLIP scores.

## Method Summary
VL-DNP modifies the classifier-free guidance (CFG) framework by dynamically generating negative prompts during diffusion denoising. At predefined timesteps, the method decodes the current latent to predict a clean image ($\hat{x}_0$), queries a VLM to identify unwanted content, and uses the VLM's response as a context-specific negative prompt for subsequent denoising steps. The approach uses Stable Diffusion v1.4 with DPM-Solver++ scheduler and Qwen2.5-VL-7B-Instruct for VLM queries. The system queries the VLM at 10 specific timesteps (45, 44, 43, 41, 38, 34, 29, 23, 16, 8) during the 50-step denoising process.

## Key Results
- VL-DNP reduces Attack Success Rate on Ring-a-Bell-16 from 0.958 to 0.011 at guidance scale 20, while maintaining CLIP score of 0.311
- The method achieves a superior Pareto frontier, dominating static negative prompting across safety-alignment trade-off
- VL-DNP maintains comparable image quality (FID scores) while significantly improving safety metrics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dynamic, context-specific negative prompts reduce semantic drift compared to static negative prompts
- Mechanism: The VLM analyzes intermediate denoising predictions and generates targeted negative prompts (e.g., "Male breast") rather than broad, static terms (e.g., "nsfw"). This targeted suppression avoids interfering with unrelated concepts present in the positive prompt, preserving semantic alignment.
- Core assumption: The VLM can accurately identify and verbalize unwanted content in intermediate, often blurry, denoising steps ($\hat{x}_0^{(i)}$) relevant to the final image.

### Mechanism 2
- Claim: Temporal adaptation of negative prompts enables more precise guidance than static prompting
- Mechanism: The content of the negative prompt ($c^-_{t_i}$) changes at predefined timesteps ($T$) based on the evolving intermediate image prediction. Once a potential issue is resolved, the VLM can stop generating a related negative prompt, preventing over-suppression of that concept in later steps.
- Core assumption: The denoising process is sufficiently gradual and predictable that intervening at discrete timesteps is effective.

### Mechanism 3
- Claim: VL-DNP achieves a superior Pareto frontier in the safety-alignment trade-off
- Mechanism: By combining targeted and adaptive negative guidance, VL-DNP can apply strong negative guidance ($\omega_{neg}$) to suppress unwanted concepts more effectively without the usual penalty to text-image alignment (CLIP score).
- Core assumption: The primary cause of semantic drift in high-guidance static negative prompting is the non-specific and persistent nature of the negative prompt.

## Foundational Learning

- **Classifier-Free Guidance (CFG)**: Essential for understanding how negative prompts exert influence by modifying the unconditional and conditional score combination. Quick check: How does the CFG scale ($\omega$) affect the trade-off between image fidelity and adherence to the text prompt?
- **Denoising Diffusion Probabilistic Models (DDPMs)**: Critical for understanding the iterative denoising process, timesteps, and how clean images are predicted from noisy latents. Quick check: At what point in the denoising timeline does the model transition from establishing high-level structure to refining fine details?
- **Vision-Language Models (VLMs)**: Key to understanding the engine that interprets intermediate images and generates textual prompts. Quick check: Why might a VLM struggle to identify fine-grained details in an image generated at an early denoising timestep?

## Architecture Onboarding

- **Component map**: Diffusion Model (SD v1.4) -> Scheduler (DPM-Solver++) -> VLM (Qwen2.5-VL-7B-Instruct) -> VLM Prompt Template -> Guidance Logic
- **Critical path**:
  1. Standard CFG denoising step using the positive prompt
  2. At predefined timestep $t_i \in T$, decode latent $x_t$ to predicted RGB image $\hat{x}_0$
  3. Query VLM with $\hat{x}_0$ and few-shot prompt to generate negative prompt
  4. Use VLM's output as negative prompt $c^-_{t_i}$ for subsequent denoising steps
- **Design tradeoffs**:
  - Performance vs. Latency: More frequent VLM queries improve responsiveness but increase generation time significantly
  - Guidance Scale ($\omega_{neg}$): Higher scales increase safety but risk degrading image quality
  - VLM Choice: Larger VLMs may improve detection accuracy but add latency and compute cost
- **Failure signatures**:
  - VLM Hallucination: Describes objects not present, leading to unnecessary negative guidance
  - Detection Failure: Fails to identify unwanted content, especially in subtle or late-stage appearances
  - Over-Correction: Strong negative guidance can erase legitimate concepts despite targeted approach
- **First 3 experiments**:
  1. Baseline Reproduction: Compare SD v1.4 with no negative prompt, static negative prompt, and VL-DNP at fixed guidance scale on Ring-a-Bell prompts
  2. Ablation on Query Timesteps: Test impact of VLM query frequency by comparing full schedule against reduced schedule
  3. Guidance Scale Sweep: Run VL-DNP and static negative prompting across range of $\omega_{neg}$ values and plot Safety vs. CLIP Score curve

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the negative guidance strength ($\omega_{neg}$) be scheduled dynamically alongside the content of the negative prompt to further optimize the safety-fidelity trade-off?
- Basis in paper: Authors explicitly state that "Jointly scheduling strength and content of guidance... remains a promising direction for future work"
- Why unresolved: Current methodology fixes the negative guidance scale while only updating the negative prompt text dynamically
- What evidence would resolve it: Experiments demonstrating adaptive $\omega_{neg}$ adjustment at each timestep showing improvements in the Pareto frontier

### Open Question 2
- Question: Can the significant latency overhead (roughly 3x slower than static methods) be reduced via lightweight VLMs or distillation without degrading safety alignment?
- Basis in paper: Paper notes "dynamic prompting introduces additional latency" and suggests "leveraging lightweight VLMs or distillation-based approaches" as necessary for real-time deployment
- Why unresolved: Implementation relies on Qwen2.5-VL-7B, computationally expensive to query 10 times per image, increasing inference time to ~29 seconds
- What evidence would resolve it: Benchmarks showing distilled or smaller VLM (under 3B parameters) can successfully perform required intermediate image classification while reducing inference time to near-baseline levels

### Open Question 3
- Question: What is the minimal set of timesteps required for VLM intervention to maintain safety, and how does query frequency impact the semantic drift of the final image?
- Basis in paper: Implementation specifies fixed, relatively dense set of 10 timesteps for queries, but paper does not ablate necessity or contribution of early vs. late interventions
- Why unresolved: While paper demonstrates VLMs can detect objects in blurry early stages, unclear if early queries are redundant or if late queries are primary drivers of safety increase
- What evidence would resolve it: Ablation study comparing VL-DNP performance when querying only at early stages, only at late stages, or at reduced frequencies

## Limitations

- The method depends heavily on VLM's ability to accurately identify unwanted content in blurry intermediate denoising steps, which may not always be reliable
- The 3.7x increase in generation time (29.7s vs 8.0s baseline) presents a significant practical barrier for real-world deployment
- Effectiveness is tied to specific negative guidance scale ($\omega_{neg}$), and the improved Pareto frontier may not hold at extreme safety thresholds

## Confidence

- **High Confidence**: The mechanism of using a VLM to generate negative prompts is sound and quantitative comparisons on specified benchmarks are likely reproducible
- **Medium Confidence**: Qualitative explanation for why dynamic prompting works better (avoiding semantic drift via targeted suppression) is logical but lacks direct ablation studies
- **Low Confidence**: Claim of achieving superior Pareto frontier is based on presented data but lacks error bars or statistical significance tests

## Next Checks

1. **VLM Perception Ablation**: Test VL-DNP with different VLM query timesteps (e.g., only at steps 45, 34, 16 vs full schedule) on small subset of Ring-a-Bell prompts to quantify trade-off between VLM frequency and safety performance

2. **Static vs. Dynamic Prompt Granularity**: Implement static negative prompting baseline using highly specific, targeted negative concepts and compare performance to VL-DNP at same guidance scale ($\omega_{neg}=7.5$) on COCO-100 benchmark to isolate effect of prompt specificity from temporal adaptation

3. **Latency vs. Safety Sweep**: Run VL-DNP across range of guidance scales ($\omega_{neg} = 7.5, 15.0, 20.0, 30.0$) and measure both Attack Success Rate and average generation time per image to identify point of diminishing returns where additional safety comes at unacceptable latency cost