---
ver: rpa2
title: 'Learning to Communicate Across Modalities: Perceptual Heterogeneity in Multi-Agent
  Systems'
arxiv_id: '2601.22041'
source_url: https://arxiv.org/abs/2601.22041
tags:
- sender
- receiver
- perceptual
- message
- communication
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work studies how perceptual misalignment across agents affects\
  \ the emergence of communication protocols in a multi-step referential game. Agents\
  \ differ in their input modalities\u2014audio and image\u2014and develop separate\
  \ encodings for the same semantic content, resulting in less efficient communication\
  \ and higher uncertainty compared to unimodal setups."
---

# Learning to Communicate Across Modalities: Perceptual Heterogeneity in Multi-Agent Systems

## Quick Facts
- arXiv ID: 2601.22041
- Source URL: https://arxiv.org/abs/2601.22041
- Authors: Naomi Pitzer; Daniela Mihai
- Reference count: 6
- One-line primary result: Perceptual misalignment across agents increases communication costs and uncertainty in emergent protocols.

## Executive Summary
This work studies how perceptual misalignment across agents affects the emergence of communication protocols in a multi-step referential game. Agents differ in their input modalities—audio and image—and develop separate encodings for the same semantic content, resulting in less efficient communication and higher uncertainty compared to unimodal setups. Message length experiments reveal that multimodal agents require more information to maintain accuracy, while perturbation and cluster analyses show that meaning is distributed across message bits and grounded in perceptual input rather than being compositional. Finally, interoperability tests show that protocols trained in different perceptual worlds are not directly compatible, but limited fine-tuning enables cross-system communication.

## Method Summary
The study uses a multi-step binary referential game where a Sender (audio input) communicates with a Receiver (image or audio input) to identify a target among distractors through discrete D-dimensional binary messages. Two datasets are used: synthetic "Shapes World" (6 classes, 2,400 images, 1,200 audio clips) and an environmental dataset pairing CIFAR-100 images with UrbanSound8K/ESC-50 sounds. Sender and Receiver agents use pre-trained embeddings (VGGish audio → 128-dim PCA; VGG16 images → 128-dim, zero-mean normalized). The Sender uses feedforward networks with Bernoulli sampling for binary message output, while the Receiver uses a GRU with stop/prediction/message heads. Joint training uses RMSprop for 200 epochs with combined loss (NLL + REINFORCE with baseline + entropy regularization).

## Key Results
- Multimodal agents require longer messages (30-50 bits) to match unimodal accuracy due to modality-induced channel noise
- Meaning is encoded distributionally across message bits rather than compositionally in individual bits
- Sender messages remain grounded in sender's perceptual space regardless of receiver modality
- Cross-system protocols require fine-tuning (2-15 epochs) for interoperability, with small accuracy trade-offs

## Why This Works (Mechanism)

### Mechanism 1: Modality Gap Reduces Channel Capacity
- Claim: Perceptual misalignment between agents introduces noise into the communication channel, reducing effective information per symbol and requiring longer messages to maintain accuracy.
- Mechanism: When sender and receiver operate on different modalities (audio vs. image), their internal representations cannot be directly aligned. The sender must compress cross-modal information into discrete symbols that the receiver interprets through an incompatible perceptual embedding space. This forces the system to use greater message capacity to transmit equivalent information.
- Core assumption: The "modality gap" observed reflects information-theoretic channel noise rather than optimization failure.
- Evidence anchors:
  - [abstract]: "multimodal agents require greater information exchange and exhibit higher uncertainty"
  - [Section 3.1]: "We interpret this divergence as a modality gap, where misaligned perceptual representations introduce noise into the communication channel"
  - [corpus]: Weak direct support; related work on emergent communication (TSLEC, Decentralized Collective World Model) addresses coordination but not cross-modal noise specifically
- Break condition: If agents shared an aligned intermediate representation space before discretization, the efficiency gap should narrow.

### Mechanism 2: Distributional Semantic Encoding
- Claim: Meaning in emergent protocols is encoded distributionally across bit patterns rather than compositionally in individual bits.
- Mechanism: Bits are classified as "constant" (>90% active or <10% active) or "variable." Flipping constant bits causes sharp accuracy drops, but no single bit carries fixed class-specific meaning—the bit's informational role depends on the surrounding pattern context.
- Core assumption: The perturbation effects reflect semantic structure rather than brittle optimization artifacts.
- Evidence anchors:
  - [abstract]: "meaning is encoded in a distributional rather than compositional manner, as each bit's contribution depends on its surrounding pattern"
  - [Section 3.3]: "its informational role is determined by the surrounding bit pattern"
  - [corpus]: No direct corpus support for this specific claim; emergent communication literature generally assumes compositional structure
- Break condition: If individual bits could be mapped to consistent semantic features across classes, the distributional claim would not hold.

### Mechanism 3: Perceptual Grounding Preservation
- Claim: Sender messages remain grounded in the sender's own perceptual space even when the receiver operates on a different modality.
- Mechanism: The sender's message embeddings cluster by low-level perceptual features (e.g., audio frequency) regardless of whether the receiver processes audio or images. The sender does not detach from its perceptual input to accommodate the receiver.
- Core assumption: t-SNE clustering reflects meaningful encoding structure rather than embedding artifact.
- Evidence anchors:
  - [Section 3.3]: "the Sender's messages in multimodal communication remain grounded in the Sender's perceptual space"
  - [Figure 6]: t-SNE shows frequency-based clustering in both unimodal and multimodal sender embeddings
  - [corpus]: Weak support; Visual Theory of Mind paper addresses grounding in visual modalities but not cross-modal preservation
- Break condition: If sender embeddings showed no systematic relationship to input features in multimodal settings, grounding would be lost.

## Foundational Learning

- Concept: **REINFORCE policy gradient with baseline**
  - Why needed here: Agents learn discrete communication via reinforcement; baseline networks reduce variance in gradient estimates (Equation 5).
  - Quick check question: Can you explain why subtracting a baseline from rewards reduces variance without introducing bias?

- Concept: **Discrete communication channel with entropy regularization**
  - Why needed here: Binary messages are sampled from Bernoulli distributions; entropy term (Equation 3) encourages exploration during training.
  - Quick check question: What happens to message diversity if entropy regularization is removed too early?

- Concept: **GRU-based sequential message integration**
  - Why needed here: Receiver must integrate multiple messages over time while tracking candidate objects; GRU maintains hidden state across timesteps.
  - Quick check question: How does the receiver decide when to stop the conversation versus continue messaging?

## Architecture Onboarding

- Component map:
  - **Sender**: VGGish audio encoder (128-dim via PCA) → linear projection + element-wise sum with receiver message → tanh → sigmoid → Bernoulli sampling (train) / threshold (test) → binary message
  - **Receiver**: Message + distractor embeddings → GRU hidden state update → stop decision (sigmoid) + prediction (2-layer MLP) + reply message generation
  - **Baselines**: Feed-forward networks predicting expected loss for variance reduction
  - **Training**: RMSprop, 200 epochs, combined loss (classification + REINFORCE + entropy)

- Critical path: Audio input → VGGish (128-dim) → PCA reduction → sender projection → binary message → receiver GRU → prediction over candidates

- Design tradeoffs:
  - Longer messages improve multimodal accuracy but reduce efficiency (Table 1)
  - Fine-tuning new receiver partners improves cross-system accuracy but slightly degrades original partner performance (Table 2)
  - Constant bits carry more information but cannot be assigned fixed meanings (distributional encoding)

- Failure signatures:
  - Random-guess accuracy (~16% for 6 classes): indicates protocol collapse or no convergence
  - High classification entropy with long messages: suggests modality gap is too severe
  - Accuracy doesn't improve after first message exchange: may indicate receiver over-reliance on initial signal

- First 3 experiments:
  1. Replicate unimodal vs. multimodal efficiency comparison at message lengths [1, 5, 10, 30, 50] on Shapes World; verify accuracy and entropy divergence.
  2. Run bit perturbation analysis on trained sender: flip constant bits vs. variable bits separately; confirm distributional encoding pattern.
  3. Cross-system interoperability test: pair multimodal-trained sender with unimodal receiver; fine-tune for [0, 2, 15, 100] epochs and measure accuracy trajectory.

## Open Questions the Paper Calls Out

- **Open Question 1**: How does active perception in embodied agents (e.g., robots) alter the emergence of protocols compared to the static perceptual inputs used in this study?
  - Basis in paper: [explicit] The authors explicitly state in Section 4 that future work should extend the analyses to "embodied agent systems (e.g., robots)."
  - Why unresolved: The current study relies on static, pre-trained embeddings (VGGish/VGG16) for fixed inputs, whereas embodied agents actively control sensory input streams.
  - What evidence would resolve it: Implementing the referential game on physical or simulated robots where agents must move or orient to gather perceptual data before communicating.

- **Open Question 2**: How does the choice of pre-trained embedding model influence the "modality gap" and the efficiency of the resulting communication protocols?
  - Basis in paper: [explicit] Section 4 calls for investigating "different embedding-generation strategies to develop a broader account of heterogeneous emergent communication."
  - Why unresolved: The study relies specifically on VGGish and VGG16 features; it is unknown if these models introduce alignment artifacts or if multimodal-aligned models (like CLIP) would reduce the observed efficiency costs.
  - What evidence would resolve it: Repeating the experiments using embeddings from different architectures (e.g., ResNet, Transformers) or joint embedding models, and comparing the resulting message lengths and classification entropy.

- **Open Question 3**: Does the reliance on distributional (holistic) rather than compositional message encoding inhibit generalization to novel concepts or attributes?
  - Basis in paper: [inferred] The authors demonstrate in Section 3.3 that meaning is "distributional rather than compositional," but they evaluate only on fixed datasets (Shapes World, CIFAR-100) without testing for combinatorial generalization.
  - Why unresolved: While the agents successfully communicate about known classes, non-compositional encodings typically fail to scale or generalize to unseen combinations of features.
  - What evidence would resolve it: Testing trained agents on out-of-distribution referents (e.g., unseen shape-color combinations) to see if the protocols support zero-shot generalization.

## Limitations

- Architectural hyperparameters (hidden layer sizes, entropy coefficients, gradient clipping threshold, batch size) are unspecified and may significantly impact results.
- The "modality gap" interpretation assumes information-theoretic channel noise rather than optimization artifacts, but this remains unverified.
- Bit perturbation analysis assumes distributional encoding is meaningful rather than an artifact of the training regime.
- t-SNE visualizations provide qualitative grounding evidence but are sensitive to embedding dimensionality and algorithmic parameters.

## Confidence

- **Medium confidence**: Modality gap reduces channel capacity - supported by accuracy and entropy patterns but could reflect optimization issues
- **Medium confidence**: Distributional semantic encoding - consistent with perturbation results but lacks direct compositional comparison
- **Medium confidence**: Perceptual grounding preservation - t-SNE patterns are suggestive but not conclusive proof
- **High confidence**: Interoperability requires adaptation - clear quantitative improvement with fine-tuning despite efficiency trade-offs

## Next Checks

1. **Replicate the efficiency gap**: Train unimodal (audio→audio) and multimodal (audio→image) systems at message lengths [1, 5, 10, 30, 50] on Shapes World; verify accuracy divergence and entropy increases in multimodal setting.

2. **Test compositional vs. distributional encoding**: After perturbation analysis, train a classifier to predict bit roles from message context; if prediction accuracy exceeds chance, this supports distributional encoding.

3. **Cross-system compatibility without fine-tuning**: Pair multimodal-trained sender with unimodal receiver and measure accuracy; compare to fine-tuned version to quantify adaptation necessity.