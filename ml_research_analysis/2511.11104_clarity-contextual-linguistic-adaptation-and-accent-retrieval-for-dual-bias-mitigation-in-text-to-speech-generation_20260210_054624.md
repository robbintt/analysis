---
ver: rpa2
title: 'CLARITY: Contextual Linguistic Adaptation and Accent Retrieval for Dual-Bias
  Mitigation in Text-to-Speech Generation'
arxiv_id: '2511.11104'
source_url: https://arxiv.org/abs/2511.11104
tags:
- accent
- text
- speech
- accents
- bias
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CLARITY introduces a dual-signal framework to jointly mitigate
  accent and linguistic bias in instruction-guided TTS. It uses LLM-guided text adaptation
  to localize input to the target dialect and retrieval-augmented accent prompting
  (RAAP) to supply accent-consistent speech prompts.
---

# CLARITY: Contextual Linguistic Adaptation and Accent Retrieval for Dual-Bias Mitigation in Text-to-Speech Generation

## Quick Facts
- **arXiv ID:** 2511.11104
- **Source URL:** https://arxiv.org/abs/2511.11104
- **Reference count:** 0
- **Primary result:** Dual-signal framework achieves up to 63.36% accent accuracy across twelve English accents, outperforming baselines in fairness (reduced FDR) and maintaining high perceptual quality (NISQA 4.31).

## Executive Summary
CLARITY introduces a dual-signal framework to jointly mitigate accent and linguistic bias in instruction-guided TTS. It uses LLM-guided text adaptation to localize input to the target dialect and retrieval-augmented accent prompting (RAAP) to supply accent-consistent speech prompts. Evaluated across twelve English accents, CLARITY achieves up to 63.36% accent accuracy, outperforms baselines in fairness (reduced FDR), and maintains high perceptual quality (NISQA 4.31). Human listening tests confirm reduced bias and stronger accent alignment, with consistent gender matching. The framework is backbone-agnostic and effective at balancing accent fidelity with dialect-aware synthesis.

## Method Summary
CLARITY addresses accent and linguistic bias in TTS through a two-stage approach. First, LLM-guided text adaptation rewrites standard input text into localized dialects (e.g., Singlish) to enhance linguistic authenticity. Second, retrieval-augmented accent prompting (RAAP) selects accent-consistent speech prompts from a curated pool using a combination of accent confidence scores (ECAPA-TDNN) and text similarity (TF-IDF). The framework is evaluated on twelve English accents from AESRC and SEAME datasets, using CosyVoice2 as the backbone TTS model. The system achieves up to 63.36% accent accuracy, reduces FDR, and maintains high perceptual quality (NISQA 4.31).

## Key Results
- Up to 63.36% accent accuracy across twelve English accents, outperforming baselines.
- Reduced FDR and decreased dominance of US/CA accents, improving fairness.
- High perceptual quality maintained (NISQA 4.31) with strong accent alignment and gender consistency in human listening tests.

## Why This Works (Mechanism)

### Mechanism 1
Retrieval-Augmented Accent Prompting (RAAP) improves accent fidelity by supplying the TTS backbone with an explicit acoustic prior, conditionally overriding training data biases toward dominant accents. RAAP retrieves a specific speech sample $s^*$ from a curated pool, maximizing an accent confidence score $C(s_i, m)$ and text similarity to the input. The core assumption is that the TTS backbone is capable of zero-shot voice cloning where the acoustic properties of the prompt speech significantly influence the output prosody and phonetics.

### Mechanism 2
LLM-guided text adaptation enhances perceived authenticity by aligning the linguistic content (lexicon, syntax) with the target accent's dialect, conditional on the LLM's sociolinguistic knowledge. An LLM (e.g., GPT-4o-mini) rewrites standard input text into localized dialects (e.g., Singlish). A judge model (GPT-5) evaluates candidate adaptations to select the version best aligned with the target accent metadata. The core assumption is that authenticity in accented speech is a function of both acoustic realization and dialect-specific linguistic markers, and the LLM possesses accurate cross-dialectal knowledge.

### Mechanism 3
Joint optimization of linguistic and acoustic signals reduces the Fairness Discrepancy Rate (FDR) across accents, conditionally reducing the system's bias toward over-represented groups (US/CA). By forcing a "dual signal"—localized text $x^*$ and accent-specific prompt $s^*$—the system creates a coherent constraint that prevents the model from defaulting to the dominant "Standard English + American Accent" manifold found in its training data. The core assumption is that accent and linguistic biases are coupled; fixing the accent via audio prompting is insufficient if the text content implies a different dialect, and vice versa.

## Foundational Learning

- **Concept: Zero-Shot TTS / Voice Cloning**
  - **Why needed here:** CLARITY relies on the backbone's ability to mimic a prompt's voice/accent without fine-tuning. Without this capability, RAAP cannot influence the output.
  - **Quick check question:** Does the target TTS model require fine-tuning to clone a voice, or can it perform inference from a single reference audio sample?

- **Concept: Sociolinguistics (Dialect vs. Accent)**
  - **Why needed here:** To understand why "text adaptation" is necessary. An accent is how you pronounce sounds; a dialect includes vocabulary and grammar. The paper argues you need both for authenticity.
  - **Quick check question:** If you input standard American text but prompt for a Scottish accent, are you missing linguistic bias, acoustic bias, or both?

- **Concept: Retrieval Augmented Generation (RAG)**
  - **Why needed here:** The RAAP mechanism applies RAG principles to audio. Understanding vector similarity and metadata filtering is crucial for implementing the prompt retriever.
  - **Quick check question:** In RAAP, what two criteria are used to rank and select the best prompt audio sample from the pool?

## Architecture Onboarding

- **Component map:** Input Parser (Gemini) -> Text Adapter (GPT, LLaMA) -> Judge (GPT-5) -> Retriever (RAAP: ECAPA-TDNN + TF-IDF) -> Synthesizer (CosyVoice2)
- **Critical path:**
  1. Accurate parsing of implicit user instructions (e.g., "like a local" $\to$ specific accent).
  2. Retrieval of high-confidence accent prompts (if this fails, bias returns).
  3. Selection of valid localized text (must be speakable and culturally accurate).
- **Design tradeoffs:**
  - **LLM Dependency:** Uses proprietary LLMs (GPT-4/5) for adaptation and judging, trading off cost/latency for superior linguistic reasoning compared to smaller open models like LLaMA (which scored lower in Fig 3).
  - **Evaluation Metric:** Uses ECAPA-TDNN for objective accent scoring, which may not perfectly align with human perception of subtle accents.
- **Failure signatures:**
  - **Dominant Bias Re-emergence:** Output defaults to US accent despite prompt (indicates Retriever failed or Backbone ignored prompt).
  - **Hallucinated Text:** Adapted text includes made-up slang or wrong language (indicates LLM Adapter failure).
  - **Gender/Identity Mismatch:** Prompt speech has wrong gender (indicates metadata filtering failure in RAAP).
- **First 3 experiments:**
  1. **Ablation on RAAP:** Run TTS with random prompt vs. RAAP-selected prompt to isolate the gain from intelligent retrieval.
  2. **Text Adaptation Validity:** Compare subjective ratings of "Standard Text + Accent Prompt" vs. "Adapted Text + Accent Prompt" to verify the dual-signal hypothesis.
  3. **Bias Stress Test:** Input ambiguous instructions (e.g., "Speak like a European") and analyze if the system defaults to specific accents (e.g., GB) or fails.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can an ensemble of multiple LLMs optimize text adaptation selection better than a single LLM judge?
- **Basis in paper:** [explicit] The authors state in the results section that using GPT-5 as the sole judge may not be optimal, noting "Using multiple LLM-as-Judge models... we leave this for future work."
- **Why unresolved:** The current method relies on a single proprietary model (GPT-5) to score adaptations, which may introduce specific biases or mismatches when evaluating outputs from other models like LLaMA.
- **What evidence would resolve it:** An ablation study comparing the accent accuracy and naturalness of speech generated from texts selected by a multi-model consensus versus a single-model judge.

### Open Question 2
- **Question:** Does utilizing adapted text for prompt retrieval degrade accent accuracy compared to standard text?
- **Basis in paper:** [inferred] Table 5 in the Appendix shows that using "Standard" text for similarity calculation yields higher accent accuracy (63.36%) than using "Adapted" text (62.26%), contradicting the intuition that adapted inputs should match adapted prompts.
- **Why unresolved:** The paper does not explain why matching the prompt's transcript to the user's *original* text outperforms matching it to the *adapted* text, despite the adaptation being crucial for synthesis.
- **What evidence would resolve it:** A detailed analysis of semantic drift during text adaptation to determine if adapted text narrows the retrieval pool too aggressively, limiting the diversity of accent prompts.

### Open Question 3
- **Question:** Can the CLARITY framework effectively generalize to full multilingual synthesis beyond accented English?
- **Basis in paper:** [explicit] The Conclusion outlines "future work focusing on multilingual adaptation and deeper accent–linguistic alignment."
- **Why unresolved:** While the study includes code-switching (SEAME), it is evaluated strictly within English-centric contexts, and it is unclear if the LLM-guided localization scales to languages with distinct syntactic structures or limited training data.
- **What evidence would resolve it:** Evaluating the framework on a diverse multilingual dataset (e.g., Spanish, Mandarin, Hindi) to measure if accent fidelity and fairness gains persist across language boundaries.

## Limitations
- Evaluation relies heavily on proprietary LLM models (GPT-4o-mini, GPT-5-mini), creating reproducibility challenges.
- ECAPA-TDNN-based accent accuracy may not perfectly align with human perception of subtle accent distinctions.
- Accent pool size and exact composition for each accent remain unspecified, which could affect retrieval quality.

## Confidence
- **High Confidence:** The dual-signal framework design (text adaptation + RAAP) and its effectiveness in reducing FDR and improving accent accuracy compared to baselines.
- **Medium Confidence:** The specific LLM choices and their relative performance (GPT-4o-mini outperforming LLaMA-3.1-8B).
- **Medium Confidence:** The NISQA quality scores (4.31) and their interpretation as "high perceptual quality."
- **Low Confidence:** The generalization of results to accents not included in the AESRC/SEAME datasets.

## Next Checks
1. **Ablation on LLM-as-Judge:** Replace GPT-5-mini with GPT-4o or an open-source judge model and compare the scoring distribution and ranking consistency.
2. **Prompt Retrieval Robustness:** Test RAAP performance when the accent pool is reduced by 50% or contains mislabeled accents. Measure the degradation in accent accuracy and analyze the retrieval ranking changes.
3. **Cross-Accent Confusion Analysis:** Perform a detailed confusion matrix analysis on the objective accent accuracy results, particularly for acoustically similar accents (JP/CN/PT). Correlate the confusion patterns with acoustic feature distances to validate whether the ECAPA-TDNN metric aligns with human perception of accent similarity.