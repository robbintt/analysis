---
ver: rpa2
title: 'AIA Forecaster: Technical Report'
arxiv_id: '2511.07678'
source_url: https://arxiv.org/abs/2511.07678
tags:
- forecasting
- which
- search
- forecasts
- forecaster
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This technical report introduces the AIA Forecaster, a large language
  model-based system for judgmental forecasting that achieves superforecaster-level
  performance on the ForecastBench benchmark. The system combines agentic search over
  high-quality news sources, a supervisor agent that reconciles disparate forecasts,
  and statistical calibration techniques to counter LLM behavioral biases.
---

# AIA Forecaster: Technical Report

## Quick Facts
- arXiv ID: 2511.07678
- Source URL: https://arxiv.org/abs/2511.07678
- Reference count: 40
- Primary result: AIA Forecaster achieves superforecaster-level performance with Brier score of 0.0753 on ForecastBench

## Executive Summary
The AIA Forecaster introduces a large language model-based system that achieves superforecaster-level performance on judgmental forecasting tasks. The system combines agentic search over high-quality news sources, a supervisor agent that reconciles disparate forecasts, and statistical calibration techniques to counter LLM behavioral biases. On the ForecastBench benchmark, the AIA Forecaster achieves a Brier score of 0.0753, statistically indistinguishable from expert human superforecasters (0.0740) and significantly outperforming prior LLM baselines. The architecture demonstrates that agentic search is critical for performance, that supervisor agents provide essential reconciliation capabilities, and that Platt scaling effectively corrects LLM hedging behavior.

## Method Summary
The AIA Forecaster employs M independent forecasting agents (M=10) that perform adaptive agentic search over news APIs, reasoning about evidence to produce probability forecasts. A supervisor agent reviews all reasoning traces, identifies key disagreements, and executes targeted search queries to resolve them before outputting a reconciled forecast. The system applies Platt scaling (sigmoid(α·log(p/(1−p))) with α ≈ √3) to counteract LLM hedging behavior. The architecture uses OpenAI o3 as the base model with knowledge cutoff May 31, 2024. The method explicitly excludes prediction market domains from search unless provided, and includes LLM-as-a-judge detection for foreknowledge bias during retrospective evaluation.

## Key Results
- Achieves Brier score of 0.0753 on ForecastBench, statistically indistinguishable from expert superforecasters (0.0740)
- Significantly outperforms prior LLM baselines across all ForecastBench datasets
- Demonstrates that agentic search is critical—performance collapses to 0.36 Brier score without it
- Shows supervisor agents are essential—non-agentic supervisors perform worse than simple averaging

## Why This Works (Mechanism)
The AIA Forecaster succeeds by addressing three core challenges in LLM-based forecasting: information gathering, reasoning synthesis, and calibration. Agentic search enables the system to adaptively query for relevant evidence rather than relying on static knowledge or low-quality search results. The supervisor agent provides a critical reconciliation layer that resolves conflicting forecasts through targeted search, preventing the degradation that occurs with simple averaging. Platt scaling corrects the systematic hedging behavior where LLMs concentrate probability mass around 0.5, shifting forecasts toward more extreme values while maintaining calibration. Together, these components create a system that can synthesize unstructured information with reasoning to produce expert-level probabilistic judgments.

## Foundational Learning

- **Concept: Brier Score**
  - Why needed here: This is the primary evaluation metric. A lower score (0 is perfect) indicates better accuracy. It's a strictly proper scoring rule, meaning the forecaster is incentivized to predict its true belief. Understanding that a 0.25 score is a "no-skill" baseline (predicting 0.5 for everything) is crucial for interpreting results.
  - Quick check question: If an event occurs (o=1), does a forecast of p=0.9 or p=0.6 yield a lower Brier score?

- **Concept: Judgmental Forecasting vs. Statistical Forecasting**
  - Why needed here: The AIA Forecaster is explicitly a system for *judgmental* forecasting, which synthesizes unstructured information (news) with reasoning. This is distinct from statistical forecasting on tabular data. The entire architecture (search, reasoning agents) is designed for the former.
  - Quick check question: Would this system be appropriate for forecasting a company's quarterly revenue based solely on a spreadsheet of past earnings?

- **Concept: Foreknowledge Bias**
  - Why needed here: A core methodological challenge is ensuring the LLM does not use information from after the forecasting date. The paper details how search APIs can leak future information (e.g., from live data feeds on a webpage), which would invalidate evaluation. Detecting and mitigating this is critical for trustworthy results.
  - Quick check question: If evaluating a forecast made "as of" January 1st, why is it a problem if a search result includes a news article published on January 5th?

## Architecture Onboarding

- **Component map:** M agents perform q -> E1 -> ... -> En -> p_i; supervisor takes R_1, ... R_M and produces p_final; Platt scaling transforms p_final to final output

- **Critical path:** Forecasting agents receive question q and cutoff date; each executes agentic search loop gathering evidence E; each synthesizes evidence into reasoning trace R and probability p; Supervisor reviews all (R, p) pairs, identifies disagreements; Supervisor executes targeted search queries to resolve disagreements; Supervisor outputs reconciled forecast; Platt scaling function transforms this forecast into final output probability

- **Design tradeoffs:**
  - Ensembling size vs. cost: Performance improves with more forecasts but plateaus after ~5-10. The tradeoff is computational cost vs. accuracy. The paper uses 10 forecasts per question.
  - Supervisor Agenticity: A non-agentic supervisor (simply averaging with LLM reasoning) performs worse than a simple mean. The tradeoff is the added latency and cost of the supervisor's search step for the gains it provides in reconciliation.
  - Statistical Parameter Learning: Learning the Platt scaling parameter from data yields better performance but risks overfitting to a specific benchmark. The tradeoff is using a fixed, theoretically-motivated parameter (√3) for robustness vs. a learned one for peak accuracy on a known distribution.

- **Failure signatures:**
  - Search Pipeline Failure: Providing low-quality search results or disabling search causes performance to collapse, often below the 0.25 baseline (e.g., 0.36 Brier score without search on live markets). Look for forecasts that ignore recent, critical news.
  - Supervisor Over-emphasis: If the supervisor focuses on reconciling outlier opinions that are actually correct, it can degrade performance compared to a simple mean.
  - Calibration Miscalibration: If forecasts are systematically wrong (on the incorrect side of 0.5), Platt scaling will push them further in the wrong direction, worsening the Brier score significantly.
  - Foreknowledge Leakage: Signs of unrealistically high performance on retrospective benchmarks. The paper uses an LLM-as-a-judge to detect this, looking for past-tense language about future events or precise knowledge of outcomes in reasoning traces.

- **First 3 experiments:**
  1. Ablate the search provider: Replace the high-quality Search-A with a different provider or a no-search baseline. Measure the drop in Brier score to quantify the value of the agentic search pipeline.
  2. Ablate the supervisor agent: Compare the performance of the full system against a baseline that simply takes the arithmetic mean of the M agent forecasts. This isolates the value added by the reconciliation and targeted search step.
  3. Test calibration correction: Run the system with and without the final Platt scaling step. Plot the resulting probability distributions to visualize the shift of probability mass away from the 0.5 center and measure the impact on the final Brier score.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can LLM-based forecasters achieve superforecaster-level performance on non-binary forecasting tasks such as k-class classification, point estimation, and conditional forecasting?
- Basis in paper: [explicit] The Discussion states: "our work focuses on forecasting unconditional, binary events... There are many other types of forecasting tasks, including k-class forecasting... point estimate forecasting... and conditional forecasting... All of these alternative forms of forecasting are amenable, in principle, to LLM-based forecasting, but will require significant additional work to incorporate into our forecasting system."
- Why unresolved: The AIA Forecaster architecture and calibration techniques (Platt scaling, supervisor reconciliation) were designed specifically for binary outcomes.
- What evidence would resolve it: Demonstrating comparable performance to human experts on benchmarks requiring continuous probability distributions or multi-class outcomes.

### Open Question 2
- Question: How can foreknowledge bias in search APIs be reliably eliminated during retrospective evaluation?
- Basis in paper: [explicit] Section 5.2 notes: "Reliably enforcing this information cutoff is a surprisingly challenging problem" and identifies multiple leakage mechanisms including dynamically updated web pages and live data feeds that bypass date filters.
- Why unresolved: Even with their LLM-as-a-judge detector, approximately 1.65% of search results still contained foreknowledge bias; the authors acknowledge this as a fundamental methodological challenge.
- What evidence would resolve it: Development of search infrastructure that provably returns only temporally-consistent information, or evaluation protocols that eliminate retrospective evaluation entirely.

### Open Question 3
- Question: Does forecasting ability transfer across domains for LLM-based systems, or is it domain-specific like human superforecasting?
- Basis in paper: [inferred] The Related Work section notes that for humans, "superforecasting ability in one domain does not necessarily transfer to other domains." The paper does not test whether the AIA Forecaster generalizes beyond the politics/economics/technology domains in their benchmarks.
- Why unresolved: The paper evaluates only on prediction market questions with similar characteristics; cross-domain transfer remains untested.
- What evidence would resolve it: Systematic evaluation of the same forecasting pipeline across qualitatively different domains (e.g., clinical outcomes, agricultural yields, scientific discoveries).

### Open Question 4
- Question: How does the deployment of high-performance AI forecasters at scale affect market efficiency and the difficulty of subsequent forecasting tasks?
- Basis in paper: [explicit] The paper notes: "in adversarial settings (e.g., financial markets), widely available AI forecasters may in turn increase the difficulty of subsequent prediction tasks, requiring systems which continuously evolve."
- Why unresolved: The paper evaluates performance assuming a fixed environment; performative effects where predictions influence outcomes are not studied.
- What evidence would resolve it: Longitudinal studies tracking forecasting difficulty before and after AI forecaster deployment in liquid markets.

## Limitations
- Heavy reliance on proprietary benchmarks (ForecastBench, MarketLiquid) with unclear domain composition and potential selection bias
- System's performance depends critically on access to high-quality search APIs, raising questions about consistency across different information ecosystems
- Real-world forecasting applicability and cost-effectiveness are not fully explored, particularly for domains with limited high-quality news sources

## Confidence

- **High confidence:** The architectural contributions (agentic search importance, supervisor agent necessity, Platt scaling effectiveness) are well-supported by ablation studies and statistically significant results. The methodology for detecting foreknowledge bias appears robust.
- **Medium confidence:** The claim of being the first verifiably expert-level AI forecaster is plausible given the demonstrated performance, but depends on the comprehensiveness of benchmark comparisons and the definition of "expert-level."
- **Low confidence:** The practical deployment implications and real-world forecasting applicability are not fully explored, particularly regarding cost-effectiveness and performance in domains with limited high-quality news sources.

## Next Checks
1. **Cross-domain validation:** Test the AIA Forecaster on an independently curated forecasting dataset from a different domain (e.g., climate policy, technological development) to assess generalizability beyond the ForecastBench and MarketLiquid domains.

2. **Search quality sensitivity analysis:** Systematically vary the quality and comprehensiveness of search results (e.g., using different news providers, date ranges, or simulated information gaps) to quantify the system's robustness to information ecosystem variations.

3. **Cost-performance tradeoff evaluation:** Measure the system's performance and Brier score at different agent ensemble sizes (M=2, 5, 20) and compute the marginal improvement per unit of computational cost to establish practical deployment guidelines.