---
ver: rpa2
title: 'SYNTHEMPATHY: A Scalable Empathy Corpus Generated Using LLMs Without Any Crowdsourcing'
arxiv_id: '2502.17857'
source_url: https://arxiv.org/abs/2502.17857
tags:
- empathy
- empathetic
- corpus
- llms
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SYNTHEMPATHY is a large-scale empathy corpus of 105k dialogues
  generated without crowdsourcing, using a pipeline of LLM-based story brainstorming,
  explanation rewriting, and empathetic response generation. This approach avoids
  the high costs and scalability issues of traditional crowdsourcing methods while
  leveraging LLM creativity to produce diverse, unique scenarios.
---

# SYNTHEMPATHY: A Scalable Empathy Corpus Generated Using LLMs Without Any Crowdsourcing

## Quick Facts
- arXiv ID: 2502.17857
- Source URL: https://arxiv.org/abs/2502.17857
- Authors: Run Chen; Jun Shin; Julia Hirschberg
- Reference count: 10
- 105k empathetic dialogues generated without crowdsourcing using LLM pipeline

## Executive Summary
SYNTHEMPATHY presents a scalable approach to generating large-scale empathy datasets without the need for expensive human annotation. The authors developed a three-stage LLM pipeline that combines high-temperature generation with aggressive deduplication to produce diverse, unique scenarios grounded in psychotherapy theory frameworks. The resulting corpus enables fine-tuning of dialogue models to improve emotional reaction empathy scores by 21% while reducing consistency variance. This approach addresses the scalability limitations of traditional crowdsourcing methods while maintaining quality through automated deduplication and theory-guided generation.

## Method Summary
The authors employ a three-stage LLM pipeline: (1) Story brainstorming using Llama 2 13B Chat at temperature 1.8 to generate 129k stories from 6,476 SAD dataset scenarios, followed by deduplication; (2) Explanation rewriting using multi-LLM approach with Chain of Empathy prompts across four therapy styles (CBT, DBT, PCT, RT) at temperature 1.9 to convert stories to first-person explanations; (3) Empathetic response generation using mixed LLMs (Llama 2, Gemma, Mistral, Llama 3) with therapy-specific prompts at temperature 2.0, followed by final deduplication and offensive content filtering. The corpus is then used to fine-tune Mistral 7B, achieving improved empathy scores.

## Key Results
- 105,578 empathetic dialogue pairs generated without crowdsourcing
- 21% increase in emotional reaction (ER) empathy scores after fine-tuning
- 4% decrease in ER standard deviation, indicating more consistent responses
- Fine-tuned model shows improved empathetic response quality compared to base model

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Grounding empathy generation in psychotherapy theory frameworks improves response quality.
- Mechanism: Four distinct therapy styles (CBT, DBT, PCT, RT) guide system messages and response prompts, creating differentiated empathy patterns—e.g., CBT targets catastrophizing, DBT targets emotional regulation.
- Core assumption: That psychotherapy frameworks transfer effectively to single-turn dialogue responses without therapist training or multi-turn context.
- Evidence anchors: References CoE prompting modeled after CBT, DBT, PCT, and RT therapeutic styles; mixed results showing decreased EX scores.

### Mechanism 2
- Claim: High-temperature LLM generation with aggressive deduplication produces diverse, novel scenarios.
- Mechanism: Temperature=1.8–2.0 with low top_p (0.2–0.3) maximizes hallucination-driven creativity; ExactSubstr deduplication (75–100 char threshold) removes 12%+ duplicates, retaining unique scenarios.
- Core assumption: That LLM hallucinations produce helpful scenario diversity rather than incoherent or low-quality outputs.
- Evidence anchors: Cites "hallucinatory nature of LLMs is actually helpful here"; no corpus evidence provided on diversity metrics.

### Mechanism 3
- Claim: Fine-tuning on synthetic empathy data improves emotional reaction (ER) consistency.
- Mechanism: 105k synthetic explanation-response pairs provide supervised learning signal; fine-tuning reduces ER standard deviation by 4% while increasing mean by 21%.
- Core assumption: That synthetic empathy labels transfer to real-world empathetic dialogue without distribution shift.
- Evidence anchors: Table 2 shows ER μ=1.16→1.40, σ=0.53→0.51; evaluation uses RoBERTa-based scoring, not human evaluation.

## Foundational Learning

- Concept: **Chain of Empathy (CoE) Prompting**
  - Why needed here: Core technique for theory-grounded response generation; differentiates response styles by therapeutic approach.
  - Quick check question: Can you explain how CBT-style CoE prompting differs from DBT-style in terms of the system message appended?

- Concept: **EPITOME Empathy Dimensions (ER/IP/EX)**
  - Why needed here: Evaluation framework; ER measures emotional reaction, IP measures interpretation, EX measures exploration.
  - Quick check question: Which dimension showed improvement after fine-tuning, and which showed degradation?

- Concept: **Suffix Array Deduplication (ExactSubstr)**
  - Why needed here: Quality control mechanism; removes duplicate/near-duplicate content across pipeline stages.
  - Quick check question: What character threshold is used for the final deduplication step, and why might this matter for response diversity?

## Architecture Onboarding

- Component map: SAD Dataset (6,476 stress scenarios) -> Story Brainstorming (Llama 2 13B Chat, temp=1.8) -> Story Deduplication (75-char threshold) -> Explanation Rewriting (Multi-LLM with CoE prompts, temp=1.9) -> Explanation Deduplication -> Response Generation (Multi-LLM with therapy-specific prompts, temp=2.0) -> Final Deduplication (100-char) + Filtering -> 105,578 pairs

- Critical path: Story Brainstorming -> Explanation Rewriting -> Response Generation (three generation steps with deduplication between each)

- Design tradeoffs:
  - Synthetic-only vs. human-validated: Zero crowdsourcing reduces cost but introduces synthetic data quality risk
  - High temperature vs. coherence: Aggressive randomness (temp=1.8–2.0) increases diversity but may produce incoherent outputs
  - ER focus vs. holistic empathy: Fine-tuning improved ER but degraded EX; trade-off not fully explored

- Failure signatures:
  - Low deduplication rate (<5%): Temperature too low, insufficient diversity
  - High deduplication rate (>40%): Temperature too high, excessive incoherence
  - EX score near zero: Model overfitting to emotional reaction patterns
  - Offensive content leakage: Keyword filtering insufficient for nuanced toxicity

- First 3 experiments:
  1. Ablate CoE prompting: Generate responses without therapy-specific system messages; compare ER/IP/EX scores to assess theory-grounding contribution.
  2. Human evaluation baseline: Conduct small-scale human evaluation (n=100–200) comparing synthetic vs. crowdsourced empathy quality; validate RoBERTa scoring alignment.
  3. Multi-turn extension: Test whether single-turn synthetic data transfers to multi-turn dialogue; measure empathy consistency across conversation turns.

## Open Questions the Paper Calls Out

- **Can the proposed LLM-based pipeline be effectively adapted to low-resource domains like social norms?**
  - Basis: The authors explicitly state future work plans to adapt the framework to low-resource areas such as social norms.
  - Why unresolved: Current framework relies on empathy-specific components that may not translate to domains requiring different reasoning or factual grounding.
  - Evidence needed: Successful application to social norms dataset demonstrating improved performance.

- **Is the observed decrease in Interpretation (IP) and Exploration (EX) scores an inevitable trade-off for higher Emotional Reaction (ER) scores?**
  - Basis: Paper notes ER improved by 21% while IP and EX scores dropped, suggesting this "may be an inevitable trade-off."
  - Why unresolved: Unclear if prompting strategy biases toward affective expression at expense of cognitive exploration.
  - Evidence needed: Ablation study testing different prompting strategies that successfully improve ER without diminishing EX/IP scores.

## Limitations

- Complete absence of human evaluation - all quality assessments rely on automated RoBERTa-based scoring
- Concerning trade-off where ER scores improved 21% but exploration (EX) scores decreased significantly
- High-temperature generation (1.8-2.0) introduces substantial uncertainty about output coherence and relevance
- Psychotherapy grounding lacks empirical validation that therapeutic styles produce meaningfully different responses

## Confidence

- **High Confidence**: Scalability claims and corpus size (105k dialogues) are verifiable through described pipeline; deduplication methodology clearly defined
- **Medium Confidence**: Fine-tuning results showing 21% ER improvement based on internal evaluation metrics but lack external validation
- **Low Confidence**: Quality and therapeutic appropriateness of generated responses uncertain without human evaluation; claim that LLM hallucinations "are helpful" lacks empirical support

## Next Checks

1. **Human Evaluation Validation**: Conduct blind comparison between SYNTHEMPATHY responses and human-generated empathy responses (n=200+ samples) using established empathy rubrics to validate automated scoring correlation with human judgment.

2. **Therapeutic Style Differentiation Test**: Analyze whether responses generated with different therapy-specific prompts (CBT vs DBT vs PCT vs RT) show statistically significant differences in content and approach to validate psychotherapy framework transfer.

3. **Multi-turn Transfer Experiment**: Evaluate whether models fine-tuned on SYNTHEMPATHY maintain empathy quality across multi-turn conversations, measuring empathy consistency, context awareness, and response relevance over 3-5 turn dialogues.