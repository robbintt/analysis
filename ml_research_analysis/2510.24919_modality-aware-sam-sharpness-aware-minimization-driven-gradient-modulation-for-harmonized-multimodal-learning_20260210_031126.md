---
ver: rpa2
title: 'Modality-Aware SAM: Sharpness-Aware-Minimization Driven Gradient Modulation
  for Harmonized Multimodal Learning'
arxiv_id: '2510.24919'
source_url: https://arxiv.org/abs/2510.24919
tags:
- m-sam
- modality
- accuracy
- learning
- modalities
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of modality imbalance in multimodal
  learning, where dominant modalities overshadow others, limiting overall performance
  and generalization. The authors propose Modality-Aware Sharpness-Aware Minimization
  (M-SAM), a model-agnostic framework that dynamically identifies the dominant modality
  using Shapley values and modulates the loss landscape to prioritize its robustness
  while allowing non-dominant modalities greater flexibility.
---

# Modality-Aware SAM: Sharpness-Aware-Minimization Driven Gradient Modulation for Harmonized Multimodal Learning

## Quick Facts
- arXiv ID: 2510.24919
- Source URL: https://arxiv.org/abs/2510.24919
- Reference count: 40
- Authors: Hossein R. Nowdeh; Jie Ji; Xiaolong Ma; Fatemeh Afghah
- Primary result: M-SAM achieves up to 2.3% higher overall accuracy than state-of-the-art methods on multimodal datasets

## Executive Summary
This paper addresses modality imbalance in multimodal learning where dominant modalities overshadow others, limiting overall performance and generalization. The authors propose Modality-Aware Sharpness-Aware Minimization (M-SAM), a model-agnostic framework that dynamically identifies the dominant modality using Shapley values and modulates the loss landscape to prioritize its robustness while allowing non-dominant modalities greater flexibility. Extensive experiments on four diverse datasets (AV-MNIST, CREMA-D, UR-Funny, AVE) with both early and late fusion architectures show that M-SAM consistently outperforms state-of-the-art methods, achieving up to 2.3% higher overall accuracy and demonstrating significantly better generalization through flatter loss landscapes.

## Method Summary
M-SAM extends Sharpness-Aware Minimization (SAM) by incorporating modality-specific loss decomposition via Shapley values. The method first computes Shapley values to identify the dominant modality per mini-batch, then applies SAM's perturbation only to the dominant modality's gradient while leaving non-dominant modalities unperturbed. This selective sharpness-aware optimization creates flat minima for the dominant modality, reducing its gradient interference with non-dominant modalities and enabling balanced learning. The framework is model-agnostic and works with both early and late fusion architectures, using shared network parameters to mediate inter-modality interactions.

## Key Results
- Achieves 2.3% higher overall accuracy compared to state-of-the-art methods including AGM, CGGM, and Recon-Boost
- Demonstrates significantly better generalization through flatter loss landscapes (lower overfitting gap τ)
- Outperforms baselines on all four datasets (AV-MNIST, CREMA-D, UR-Funny, AVE) with both early and late fusion architectures
- Shows consistent improvement across modality-specific accuracies (Acc_a, Acc_v, Acc_t) in addition to overall multi-modal accuracy (Acc_mm)

## Why This Works (Mechanism)

### Mechanism 1: Dominant Modality Detection via Shapley Attribution
Identifying the dominant modality per mini-batch enables targeted optimization that prevents one modality from destabilizing others. Shapley values decompose the total loss into modality-specific contributions (v_m in Eq. 4), normalizing them so ∑v_m = 1. The modality with highest v_m is tagged dominant for that iteration.

### Mechanism 2: Selective Sharpness-Aware Perturbation for Dominant Modality Only
Applying SAM's perturbation only to the dominant modality's gradient flattens its loss basin while leaving non-dominant modalities free to explore. Standard SAM perturbs all parameters, but M-SAM restricts perturbation to dominant modality using modified gradient update equations.

### Mechanism 3: Implicit Gradient Balancing via Flat Minima Geometry
Flat minima for the dominant modality reduce its gradient magnitude across parameter neighborhoods, allowing non-dominant modalities' gradients to have relatively more influence in shared parameters. Sharp landscapes create large dominant modality gradients that overshadow others, while flat landscapes stabilize joint optimization.

## Foundational Learning

- **Sharpness-Aware Minimization (SAM) fundamentals**: M-SAM extends SAM; understand that SAM minimizes worst-case loss in a ρ-neighborhood to find flat minima, improving generalization. Can you explain why SAM requires two forward-backward passes per step and what ε_t represents?

- **Shapley value attribution for feature/model contributions**: M-SAM relies on Shapley to decompose loss into modality-specific terms; misunderstanding this leads to incorrect implementation of v_m weights. Given two modalities, compute the Shapley value for modality 1 if Φ({x_1, x2}) = 0.8 and Φ({0_1, x2}) = 0.5.

- **Early vs. late fusion in multimodal architectures**: M-SAM is model-agnostic but behaves differently when modalities share early layers vs. only fuse at classification; gradient decomposition paths differ. In late fusion with separate encoders, which parameters belong to θ_e^m vs. θ_s?

## Architecture Onboarding

- **Component map**: Encoder modules f_e^m(·; θ_e^m) for each modality → Fusion module ⊕ combining features → Shared network f_s(·; θ_s) → Shapley estimator → M-SAM optimizer

- **Critical path**: 1) Forward pass: Encode all modalities → fuse → compute L 2) Shapley computation: Run 2^M - 1 forward passes with zeroed modalities 3) Identify dominant m_0 = argmax_m v_m 4) Compute perturbed gradient for m_0: ∇L_m0(θ + ε_m0) 5) Compute standard gradients for all modalities: ∑(m≠m_0) ∇L_m(θ) 6) Update parameters with combined gradient

- **Design tradeoffs**: Shapley overhead scales exponentially with modality count; SAM doubles gradient computations; M-SAM adds Shapley forward passes; dominant modality assumption may underperform if all modalities equally important.

- **Failure signatures**: Dominant modality oscillates frequently → Shapley values too noisy; non-dominant modality accuracy collapses → over-regularization; training loss diverges → ρ too large; no improvement over Joint-Train → verify Shapley implementation.

- **First 3 experiments**: 1) Reproduce AV-MNIST late fusion baseline with 2-modality Shapley 2) Ablation on Shapley vs. fixed weighting (0.5/0.5) 3) Sensitivity to ρ hyperparameter sweep on CREMA-D

## Open Questions the Paper Calls Out
None

## Limitations
- Computational overhead from exponential Shapley scaling (O(2^M) forward passes) makes it impractical for datasets with more than 3-4 modalities
- Hyperparameter sensitivity to perturbation radius ρ and dominant modality decision thresholds not systematically explored
- Theoretical grounding for why selective SAM helps lacks rigorous proof across diverse modality relationships

## Confidence
- **High Confidence**: Core claim of 2.3% accuracy improvement on multimodal datasets with imbalanced modality contributions
- **Medium Confidence**: Shapley-based dominant modality detection meaningfully captures which modality to prioritize per batch
- **Low Confidence**: Claim that M-SAM is "model-agnostic" given architecture-dependent implementation complexity

## Next Checks
1. **Shapley vs. Fixed Weighting Ablation**: Replace dynamic Shapley-based v_m weights with fixed equal weights (0.5/0.5 for two modalities) and measure performance degradation.

2. **ρ Sensitivity Analysis**: Systematically vary perturbation radius ρ across [0.01, 0.1, 0.5] on CREMA-D and plot both training convergence and final generalization metrics.

3. **Domain Shift Robustness**: Test M-SAM on modality-swapped version of AV-MNIST where video is dominant instead of audio to validate adaptation to changing dominant modalities.