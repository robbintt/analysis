---
ver: rpa2
title: 'ALN-P3: Unified Language Alignment for Perception, Prediction, and Planning
  in Autonomous Driving'
arxiv_id: '2505.15158'
source_url: https://arxiv.org/abs/2505.15158
tags:
- driving
- alignment
- language
- autonomous
- planning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "ALN-P3 introduces a unified training-only framework that aligns\
  \ vision-based autonomous driving systems with language-driven reasoning modules\
  \ across perception, prediction, and planning. It employs three alignment mechanisms\u2014\
  Perception Alignment (P1A), Prediction Alignment (P2A), and Planning Alignment (P3A)\u2014\
  to bridge visual and linguistic representations, enhancing interpretability without\
  \ adding inference overhead."
---

# ALN-P3: Unified Language Alignment for Perception, Prediction, and Planning in Autonomous Driving

## Quick Facts
- arXiv ID: 2505.15158
- Source URL: https://arxiv.org/abs/2505.15158
- Authors: Yunsheng Ma; Burhaneddin Yaman; Xin Ye; Mahmut Yurt; Jingru Luo; Abhirup Mallik; Ziran Wang; Liu Ren
- Reference count: 7
- Primary result: 27% reduction in collision rate and 28% improvement in driving explanation CIDEr score while maintaining real-time deployment suitability

## Executive Summary
ALN-P3 introduces a unified training-only framework that aligns vision-based autonomous driving systems with language-driven reasoning modules across perception, prediction, and planning. It employs three alignment mechanisms—Perception Alignment (P1A), Prediction Alignment (P2A), and Planning Alignment (P3A)—to bridge visual and linguistic representations, enhancing interpretability without adding inference overhead. Experiments on nuScenes, Nu-X, TOD3Cap, and nuScenes QA demonstrate state-of-the-art performance, achieving a 27% reduction in collision rate and a 28% improvement in driving explanation CIDEr score, while maintaining real-time deployment suitability.

## Method Summary
ALN-P3 combines a "fast" P3 module (BEV Encoder → Track Tokens → Motion Tokens → Ego Token) with a "slow" MLLM (LLaMA-AdapterV2) through three training-only alignment modules. During training, P1A aligns object descriptions with instance tokens via MSE loss, P2A connects motion forecasts to agent-level language using CLIP-style contrastive loss, and P3A links ego-vehicle plans to decision explanations via negative cosine similarity. All alignments use attention-based pooling with learnable prompt tokens. The framework operates on nuScenes data (1,000 scenes, 6-camera, 2Hz) and trains for 5 epochs with frozen LLaMA and updated adapter+P3 components, using equal weighting for all losses.

## Key Results
- 27% reduction in collision rate at 1s/2s/3s horizons compared to baselines
- 28% improvement in driving explanation CIDEr score on Nu-X dataset
- State-of-the-art performance on TOD3Cap and nuScenes QA benchmarks

## Why This Works (Mechanism)

### Mechanism 1: Cross-Modal Co-Distillation Between Fast and Slow Systems
Bidirectional alignment between vision-based driving and language reasoning improves both systems simultaneously. The three alignment modules project visual tokens from the P3 stack and linguistic outputs from the MLLM into shared embedding spaces, then minimize distance between corresponding pairs. This creates pressure for both systems to develop semantically consistent internal representations. Semantic consistency between modalities correlates with improved driving safety and reasoning quality.

### Mechanism 2: Hierarchical Alignment Coverage of the Full P3 Stack
Aligning all three stages (perception, prediction, planning) rather than just one appears necessary for consistent cross-modal behavior. P1A grounds object descriptions in instance tokens; P2A connects motion forecasts to agent-level language; P3A links ego-vehicle plans to decision explanations. Each module uses different pooling and loss strategies tailored to the modality type. Independent alignment at each stage transfers to coherent end-to-end behavior.

### Mechanism 3: Training-Only Alignment With Zero Inference Overhead
Restricting alignment to training time preserves real-time deployment feasibility while still capturing cross-modal benefits. Alignment modules project intermediate features and compute losses only during training. At inference, the "fast" P3 system operates independently; the "slow" MLLM runs only when explanations are requested. Knowledge transfer during training persists without ongoing alignment supervision at inference.

## Foundational Learning

- **Concept: Bird's-Eye-View (BEV) Representations**
  - Why needed here: The P3 module operates on BEV features; understanding spatial projection from multi-view cameras to unified top-down representations is essential.
  - Quick check question: Can you explain why BEV fusion helps with occlusion reasoning compared to perspective-view features?

- **Concept: Contrastive Learning (CLIP-style alignment)**
  - Why needed here: P2A uses CLIP-style contrastive loss to align trajectory and language embeddings in a shared space.
  - Quick check question: How does contrastive loss differ from regression loss for cross-modal alignment?

- **Concept: Attention-Based Pooling Across Modalities**
  - Why needed here: Both P2A and P3A use attention-based pooling (Equation 4) to aggregate information from prompt tokens and input features.
  - Quick check question: What is the role of learnable prompt tokens P2 and P3 in the attention pooling operation?

## Architecture Onboarding

- **Component map:**
  Fast system (P3 Module): BEV Encoder → Track Tokens (perception) → Motion Tokens (prediction) → Ego Token (planning)
  Slow system (QA Module): Holistic Token Mixer (middleware encoder E) → MLLM (LLaMA-Adapter V2) → Language output
  Alignment modules (training-only): P1A connects Q'_instance to CLIP text embeddings; P2A connects predicted trajectories to MLLM logits via prompt tokens P2; P3A connects ego trajectory to planning-related MLLM outputs via prompt tokens P3

- **Critical path:**
  1. Multi-view images → BEV features
  2. BEV features → track/motion/ego tokens
  3. Tokens → Holistic Token Mixer → MLLM context
  4. During training: alignment losses computed for all three stages
  5. At inference: P3 produces trajectory; MLLM generates explanations only when prompted

- **Design tradeoffs:**
  - Loss weighting: All alignment losses equally weighted (weight=1); no tuning applied due to resource constraints—may not be optimal
  - Prompt selection: Category-specific (perception/prediction/planning) based on DriveLM taxonomy; may limit generalization to open-ended queries
  - Architecture dependency: Requires access to intermediate tokens; incompatible with black-box AD systems

- **Failure signatures:**
  - Collision rate not improving: Check if P3A loss is dominating and overriding P3 module's native planning supervision
  - Language outputs inconsistent with trajectories: P2A/P3A may have collapsed to trivial solutions; inspect embedding spaces
  - Training instability: Conflicting gradients between alignment losses and task-specific losses; monitor loss magnitudes per module

- **First 3 experiments:**
  1. **Ablation by alignment module:** Disable P1A, P2A, and P3A individually to measure contribution of each to collision rate and CIDEr; expect P3A most critical for planning, P1A for captioning.
  2. **Projection head capacity test:** Vary MLP dimensions in ΦP1 and pooling prompt token counts (N2, N3) to assess alignment sensitivity; look for diminishing returns.
  3. **Cross-dataset transfer:** Train on nuScenes, evaluate on nuScenes-QA held-out splits to verify whether alignment generalizes to novel question types; compare against Hint-AD baseline.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the ALN-P3 framework be adapted to handle open-ended or compositional queries that don't fit into the predefined perception, prediction, and planning prompt categories?
- Basis in paper: [explicit] "our current implementation assumes category-specific prompt selection for training, which may limit generalization to open-ended or compositional queries."
- Why unresolved: The training dynamically activates alignment based on prompt category, creating a dependency on structured query types that may not cover all real-world user questions.
- What evidence would resolve it: Experiments on datasets with free-form queries showing maintained or improved performance without category labels, or an ablation comparing category-free vs. category-guided training.

### Open Question 2
- Question: What is the sensitivity of ALN-P3's performance to the relative weighting of the three alignment losses (P1A, P2A, P3A)?
- Basis in paper: [inferred] "All loss terms are equally weighted with a default weight of 1, and no additional tuning was applied to balance these terms due to resource constraints."
- Why unresolved: Equal weighting may be suboptimal; different tasks (planning vs. captioning) may benefit from different emphasis on perception, prediction, or planning alignment.
- What evidence would resolve it: Ablation studies varying loss weights (e.g., grid search or learned weighting) showing performance impact on collision rate and language metrics.

### Open Question 3
- Question: How effectively does ALN-P3 transfer to alternative end-to-end AD architectures beyond VAD-base (e.g., UniAD, DriveTransformer)?
- Basis in paper: [explicit] "alignment modules... may require additional tuning when transferred to new AD architectures or domains."
- Why unresolved: The framework uses VAD-base representations; token dimensions and feature semantics may differ across architectures, requiring architecture-specific adaptation.
- What evidence would resolve it: Cross-architecture experiments showing ALN-P3 applied to UniAD, PARA-Drive, or DriveTransformer with comparison of tuning requirements and performance gains.

### Open Question 4
- Question: Can ALN-P3 maintain its benefits when integrated with closed-source or black-box autonomous driving systems that do not expose intermediate tokens?
- Basis in paper: [explicit] "it requires access to intermediate representations (e.g., track, motion, and planning tokens), which may not be available in closed-source or black-box AD systems."
- Why unresolved: The alignment mechanism fundamentally depends on extracting Q_track, Q_motion, Q_ego, and V_plan tokens from the P3 module.
- What evidence would resolve it: Experiments using only input-output pairs from black-box systems, perhaps with learned proxies for intermediate representations, comparing performance to full-token access.

## Limitations
- Underspecified technical parameters including prompt token dimensions (N2, D2, N3, D3), Holistic Token Mixer architecture, and batch size
- Equal weighting of all alignment losses chosen due to computational resource constraints rather than empirical optimization
- Training-only alignment design assumes stable representation spaces between domains, but deployment-domain shifts could cause alignment degradation

## Confidence

- **High Confidence:** The three alignment mechanisms (P1A, P2A, P3A) are well-defined with clear mathematical formulations, and the core architecture combining fast P3 vision systems with slow MLLM reasoning modules is explicitly described.
- **Medium Confidence:** The 27% collision rate reduction and 28% CIDEr improvement are reported, but the ablation study isolating individual alignment contributions is not provided, making it difficult to attribute specific gains to each mechanism.
- **Low Confidence:** The claim of "zero inference overhead" assumes perfect knowledge transfer during training, but no validation is provided for representation stability across domain shifts or long-term deployment scenarios.

## Next Checks

1. **Ablation Analysis:** Systematically disable P1A, P2A, and P3A individually to quantify each module's contribution to both safety metrics (collision rate) and language quality (CIDEr), establishing which alignment stage provides the most value.

2. **Hyperparameter Sensitivity:** Test different prompt token dimensions (N2, N3) and MLP projection head capacities in ΦP1 to determine if the current fixed configuration represents a local optimum or if alignment performance scales with capacity.

3. **Cross-Domain Generalization:** Train the unified framework on nuScenes, then evaluate on nuScenes-QA held-out splits with novel question types to verify whether the alignment modules generalize beyond their training distribution, comparing against Hint-AD baseline performance.