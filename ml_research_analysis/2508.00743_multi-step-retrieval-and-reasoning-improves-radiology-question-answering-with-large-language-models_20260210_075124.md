---
ver: rpa2
title: Multi-step retrieval and reasoning improves radiology question answering with
  large language models
arxiv_id: '2508.00743'
source_url: https://arxiv.org/abs/2508.00743
tags:
- qwen
- retrieval
- question
- reasoning
- were
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces RaR, a multi-step retrieval and reasoning
  framework designed to improve the accuracy and factual reliability of large language
  models in radiology question answering. RaR decomposes complex clinical questions,
  retrieves targeted evidence from Radiopaedia, and synthesizes evidence-based responses
  through iterative reasoning.
---

# Multi-step retrieval and reasoning improves radiology question answering with large language models

## Quick Facts
- arXiv ID: 2508.00743
- Source URL: https://arxiv.org/abs/2508.00743
- Reference count: 40
- RaR improved diagnostic accuracy from 67% (zero-shot) to 75% (P = 1.1 × 10−7)

## Executive Summary
This study introduces RaR, a multi-step retrieval and reasoning framework designed to improve the accuracy and factual reliability of large language models in radiology question answering. RaR decomposes complex clinical questions, retrieves targeted evidence from Radiopaedia, and synthesizes evidence-based responses through iterative reasoning. Evaluated across 25 diverse models on 104 expert-curated radiology questions, RaR significantly outperformed zero-shot prompting (75% vs. 67%; P = 1.1 × 10−7) and conventional RAG (75% vs. 69%; P = 1.9 × 10−6), with the largest gains observed in small and mid-sized models. RaR also reduced hallucinations by 9.4% and retrieved clinically relevant context in 46% of cases. Even clinically fine-tuned models showed improvements, indicating retrieval complements embedded knowledge. All datasets, code, and the RaR framework are publicly available.

## Method Summary
The RaR framework uses an agentic pipeline where GPT-4o-mini orchestrates the workflow by decomposing questions and delegating sub-tasks to research modules. Each multiple-choice option is investigated by a dedicated research module that iteratively retrieves evidence from Radiopaedia.org using SearXNG. The modules produce structured sections with supporting and contradicting evidence, which the supervisor compiles into a final report. The target LLM then uses this report to select its answer. The approach was evaluated across 25 different LLMs on 104 expert-curated radiology questions, comparing against zero-shot prompting and conventional online RAG.

## Key Results
- RaR significantly improved diagnostic accuracy over zero-shot prompting (75% vs. 67%; P = 1.1 × 10−7)
- RaR outperformed conventional online RAG (75% vs. 69%; P = 1.9 × 10−6)
- Largest accuracy gains observed in mid-sized models (17-150B parameters), with minimal improvement for very large models (>200B)
- RaR reduced hallucinations by 9.4% and retrieved clinically relevant context in 46% of cases

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Multi-step question decomposition with parallel evidence gathering improves diagnostic accuracy over single-pass retrieval
- **Mechanism:** The RaR pipeline extracts diagnostic concepts from each question using Mistral Large, then delegates each multiple-choice option to a dedicated research module that independently retrieves and synthesizes evidence. This prevents premature commitment to a single retrieval path and allows systematic comparison of competing diagnoses.
- **Core assumption:** Questions can be meaningfully decomposed into constituent diagnostic hypotheses that benefit from parallel investigation rather than sequential filtering.
- **Evidence anchors:**
  - [abstract] "RaR significantly improved mean diagnostic accuracy over zero-shot prompting (75% vs. 67%) and conventional online RAG (75% vs. 69%)"
  - [section] "RaR further outperformed traditional online RAG (P = 1.9 × 10−6), underscoring the benefit of iterative retrieval and autonomous reasoning over single-pass retrieval pipelines"
  - [corpus] RAR² paper (arxiv 2509.22713) similarly demonstrates "thought-driven retrieval" improves medical reasoning, supporting decomposition-based approaches
- **Break condition:** If retrieval sources lack coverage for specific diagnostic entities, decomposition amplifies retrieval failures across multiple modules rather than containing them.

### Mechanism 2
- **Claim:** Structured evidence synthesis with explicit supporting/contradicting annotations reduces hallucination rates
- **Mechanism:** Research modules must produce report segments that explicitly cite source URLs and distinguish evidence supporting versus contradicting each diagnostic option. The supervisor compiles these into a structured report with introduction, analysis sections, and neutral conclusion, which the target LLM uses as context for final answer selection.
- **Core assumption:** LLMs are more likely to produce factually grounded responses when context is pre-organized with explicit epistemic labels (supporting/contradicting) rather than unstructured text.
- **Evidence anchors:**
  - [abstract] "RaR reduced hallucinations (mean 9.4%) and retrieved clinically relevant context in 46% of cases"
  - [section] "Hallucinations, defined as incorrect answers despite the presence of relevant context, occurred in only 9.4% ± 5.9 of questions"
  - [corpus] Uncertainty Quantification for Retrieval-Augmented Reasoning (arxiv 2510.11483) notes RAR systems "remain vulnerable to errors" without explicit grounding mechanisms—RaR's citation structure addresses this
- **Break condition:** When retrieved context is clinically irrelevant (54% of cases), structured synthesis cannot reduce hallucinations; models must rely on internal knowledge.

### Mechanism 3
- **Claim:** Performance gains from RaR are scale-dependent, with mid-sized models (17–150B parameters) showing the largest benefit
- **Mechanism:** Mid-sized models possess sufficient reasoning capacity to follow structured multi-step logic but lack the comprehensive pretraining coverage of very large models. RaR compensates for knowledge gaps while leveraging their reasoning abilities. Very large models (>200B) already achieve high zero-shot accuracy through extensive pretraining, making retrieval incremental.
- **Core assumption:** There exists a model-scale "sweet spot" where reasoning capacity exceeds knowledge coverage, creating maximum retrieval utility.
- **Evidence anchors:**
  - [abstract] "The greatest gains occurred in mid-sized models... while very large models (>200B parameters) demonstrated minimal changes (<2% improvement)"
  - [section] "Mid-sized models such as GPT-3.5-turbo, Mistral Large, and Llama3.3-70B have sufficient reasoning capabilities to follow structured logic but frequently struggle to independently identify and incorporate relevant external clinical evidence"
  - [corpus] Related work on retrieval-augmented medical reasoning (arxiv 2509.22713, 2510.11483) does not systematically address scale-dependence—this is a distinctive contribution of the current study
- **Break condition:** For specialized domains where even very large models lack coverage (e.g., rare diseases, recent clinical guidelines), the scale-dependence pattern may invert.

## Foundational Learning

- **Concept: Retrieval-Augmented Generation (RAG)**
  - **Why needed here:** RaR extends single-step RAG with multi-step orchestration; understanding baseline RAG is prerequisite to appreciating the architectural innovations.
  - **Quick check question:** Given a clinical question, can you explain why retrieving documents once at query time might fail to surface evidence relevant to competing diagnostic hypotheses?

- **Concept: Agent Orchestration with Stateful Workflows**
  - **Why needed here:** RaR uses a supervisor-research module architecture coordinated through a directed graph with shared memory state; this differs from single-model prompting.
  - **Quick check question:** If a research module fails to find relevant evidence after four retrieval attempts, what state information should be preserved for the supervisor's final synthesis?

- **Concept: Hallucination vs. Retrieval Failure Taxonomy**
  - **Why needed here:** The paper distinguishes hallucinations (incorrect answer despite relevant context) from retrieval failures (relevant context not retrieved)—this taxonomy is essential for interpreting error analyses.
  - **Quick check question:** A model answers correctly despite receiving irrelevant retrieved context. Is this a hallucination? What does it suggest about the model's internal knowledge?

## Architecture Onboarding

- **Component map:**
  - Question → Mistral Large (keywords) → Supervisor → Research Modules (parallel) → SearXNG (Radiopaedia) → Structured sections → Supervisor (Introduction/Conclusion) → Final report → Target LLM → Answer

- **Critical path:**
  1. Question → Mistral Large extracts keywords
  2. Supervisor creates research plan (one section per multiple-choice option)
  3. Research modules execute parallel retrieval from Radiopaedia (max 4 query refinements)
  4. Each module produces structured section with supporting/contradicting evidence + citations
  5. Supervisor compiles Introduction, all sections, Conclusion → final diagnostic report
  6. Report + question → target LLM under evaluation → final answer

- **Design tradeoffs:**
  - **Latency vs. accuracy:** RaR introduces 6.7× mean latency increase (54s → 324s per question); acceptable for non-emergent clinical decision support, prohibitive for real-time workflows
  - **Single-source retrieval vs. coverage:** Using only Radiopaedia ensures quality but limits coverage (46% retrieval relevance rate); multi-source retrieval would improve coverage but risk lower-quality evidence
  - **GPT-4o-mini orchestration vs. model-independence:** Paper argues orchestration is identical across all evaluated models, but self-preference bias cannot be fully excluded for OpenAI models

- **Failure signatures:**
  - **Reasoning shortcut errors:** Model relies on familiar diagnostic patterns (e.g., "epistaxis → AVM") despite retrieved evidence explicitly excluding this diagnosis
  - **Context integration failures:** Model correctly interprets individual findings but fails to synthesize them into coherent diagnosis
  - **Retrieval noise propagation:** When 54% of retrieved context is irrelevant, smaller models (>8B) show degraded performance due to inability to ignore noisy context

- **First 3 experiments:**
  1. **Reproduce zero-shot vs. RaR accuracy gap on a single model class** (e.g., Mistral Large or Llama3.3-70B) using the publicly available RadioRAG dataset to validate infrastructure
  2. **Ablate research module parallelism** by forcing sequential retrieval to quantify the contribution of parallel evidence gathering vs. single-pass multi-query retrieval
  3. **Measure retrieval relevance rate** on your institution's internal QA dataset to establish baseline before deploying RaR in a specific clinical context

## Open Questions the Paper Calls Out
None

## Limitations
- Results based on 104 questions from RSNA-RadioQA and ExtendedQA datasets, which may not represent full spectrum of radiology clinical reasoning challenges
- Single-source retrieval from Radiopaedia.org limits coverage to 46% of cases with relevant context, creating a ceiling effect
- Orchestration model dependency: subtle self-preference biases cannot be excluded for OpenAI models in evaluation set

## Confidence
- **High confidence:** Core claim that RaR improves accuracy over zero-shot prompting (75% vs. 67%, P = 1.1 × 10−7) is well-supported with appropriate statistical testing
- **Medium confidence:** Scale-dependent performance gains showing mid-sized models benefit most are plausible but could reflect specific model selection
- **Medium confidence:** Hallucination reduction claim (9.4%) is supported, but definition may not capture all clinically relevant error modes

## Next Checks
1. **Replication with expanded retrieval sources:** Test RaR with multi-source retrieval (including PubMed, clinical guidelines) to determine if coverage improvements translate to accuracy gains beyond the 46% relevance ceiling
2. **Cross-specialty generalization:** Apply RaR to non-radiology medical domains (e.g., pathology or internal medicine MCQs) to test whether decomposition-and-parallel-retrieval architecture generalizes beyond imaging-focused reasoning
3. **Real-world clinical workflow integration:** Deploy RaR in a clinical decision support system with time constraints to measure whether the 6.7× latency increase remains acceptable in practice, and whether accuracy gains persist under operational conditions