---
ver: rpa2
title: A Low-Rank Method for Vision Language Model Hallucination Mitigation in Autonomous
  Driving
arxiv_id: '2511.06496'
source_url: https://arxiv.org/abs/2511.06496
tags:
- hallucination
- captions
- rank
- debate
- caption
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a low-rank matrix decomposition method to
  automatically identify hallucination-free captions from multiple Vision Language
  Models (VLMs) in autonomous driving scenarios. The approach constructs an embedding
  matrix from candidate captions and applies truncated Singular Value Decomposition
  (SVD) to separate consensus semantic information from hallucinated residuals, selecting
  the caption with the smallest residual as most reliable.
---

# A Low-Rank Method for Vision Language Model Hallucination Mitigation in Autonomous Driving

## Quick Facts
- **arXiv ID:** 2511.06496
- **Source URL:** https://arxiv.org/abs/2511.06496
- **Authors:** Keke Long; Jiacheng Guo; Tianyun Zhang; Hongkai Yu; Xiaopeng Li
- **Reference count:** 4
- **Primary result:** 87% accuracy in identifying hallucination-free captions, 19% improvement over unfiltered baselines

## Executive Summary
This paper addresses the critical problem of selecting hallucination-free captions from multiple Vision Language Model (VLM) outputs in autonomous driving scenarios. The authors propose a low-rank matrix decomposition method that automatically identifies the most reliable caption by computing SVD residuals on sentence embeddings. The approach achieves 87% accuracy on the NuScenes dataset, representing significant improvements over both unfiltered baselines and multi-agent debate methods, while reducing inference time by 51-67%.

## Method Summary
The method constructs an embedding matrix from multiple VLM-generated captions, applies truncated Singular Value Decomposition (SVD) to separate consensus semantic information from hallucinated residuals, and selects the caption with the smallest residual as most reliable. The approach uses three VLMs (deepseek-vl2-tiny, llava-1.5-7b-hf, Qwen2-VL-7B-Instruct) to generate 10 captions per image, encodes these with a sentence transformer, and computes residuals via low-rank reconstruction. The caption with minimum residual norm is selected as least hallucinated.

## Key Results
- Achieves 87% accuracy in identifying hallucination-free captions
- 19% improvement over unfiltered baseline methods
- 6-10% improvement over multi-agent debate approaches
- 51-67% reduction in inference time compared to debate methods

## Why This Works (Mechanism)
The method leverages the observation that hallucination-free captions share common semantic information (low-rank component) while hallucinated content appears as sparse deviations (residuals). By computing SVD on the embedding matrix and selecting captions with minimal residuals, the approach effectively separates consensus reality from hallucination noise.

## Foundational Learning
- **Singular Value Decomposition (SVD):** Matrix factorization into orthogonal bases and singular values; needed for separating low-rank consensus from sparse residuals; quick check: verify cumulative explained variance reaches 95% at chosen rank.
- **Low-rank matrix approximation:** Representing data with reduced dimensionality while preserving essential structure; needed to capture consensus semantic information; quick check: compare Frobenius norm of original vs. reconstructed matrix.
- **Sentence embeddings:** Vector representations capturing semantic meaning of text; needed to quantify caption similarity in embedding space; quick check: verify embeddings from same caption cluster together.
- **Residual analysis:** Measuring deviation from reconstructed data; needed to identify hallucinated content as noise; quick check: examine residual norms distribution across captions.
- **Spearman correlation:** Non-parametric measure of monotonic relationship; needed to evaluate alignment with human hallucination judgments; quick check: verify correlation values between predicted and ground-truth scores.

## Architecture Onboarding
- **Component map:** Images -> VLMs (3) -> Captions (30) -> Sentence Transformer -> Embedding Matrix -> SVD -> Residuals -> Hallucination Scores -> Best Caption
- **Critical path:** Embedding generation → SVD decomposition → Residual computation → Caption selection
- **Design tradeoffs:** Computational efficiency vs. accuracy (low-rank approximation vs. full SVD); sensitivity to embedding model choice; vulnerability to consensus hallucinations
- **Failure signatures:** Low caption diversity yields poor discrimination; consensus hallucinations appear as low residuals; embedding model choice affects SVD quality
- **First experiments:** 1) Test sensitivity to different sentence transformers on NuScenes validation set; 2) Construct synthetic consensus hallucination cases; 3) Compare pooled vs. per-model caption processing in heterogeneous setting

## Open Questions the Paper Calls Out
- How do hallucinations propagate into downstream planning and control in closed-loop autonomous driving simulations?
- Can integrating visual consistency checks with the low-rank textual method improve robustness?
- How can the method be adapted to handle systemic errors where multiple VLMs hallucinate the same object?

## Limitations
- Cannot detect hallucinations that achieve consensus across multiple VLMs
- Limited to NuScenes dataset and specific driving scenarios
- Method assumes hallucinated content appears as noise in embedding space

## Confidence
- **High confidence:** Low-rank matrix decomposition methodology is technically sound
- **Medium confidence:** 19% improvement over unfiltered baseline is likely reproducible
- **Medium confidence:** 51-67% inference time reduction claim is plausible
- **Low confidence:** Claim of "automatically identifying hallucination-free captions" is overstated

## Next Checks
1. Test method using multiple sentence transformers to quantify sensitivity to embedding model choice
2. Construct synthetic test cases where multiple VLMs hallucinate the same object
3. Implement and test both possible interpretations of heterogeneous multi-agent setting (pooled vs. per-model processing)