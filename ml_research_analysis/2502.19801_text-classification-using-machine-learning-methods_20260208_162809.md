---
ver: rpa2
title: Text classification using machine learning methods
arxiv_id: '2502.19801'
source_url: https://arxiv.org/abs/2502.19801
tags:
- classification
- word
- words
- methods
- product
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigated the use of machine learning methods for
  automatic product classification in price statistics. Product names were transformed
  into numerical vectors using various embedding techniques, including Count Vectorization,
  TF-IDF, Word2Vec, FASTTEXT, and GloVe.
---

# Text classification using machine learning methods

## Quick Facts
- arXiv ID: 2502.19801
- Source URL: https://arxiv.org/abs/2502.19801
- Reference count: 3
- Primary result: Machine learning achieves 99.7% accuracy in product classification using FASTTEXT embeddings and SVM with radial kernel

## Executive Summary
This study demonstrates that machine learning methods can effectively automate product classification in price statistics, achieving up to 99.7% accuracy on a 15-category ECOICOP dataset. The research systematically evaluates five embedding techniques (Count Vectorization, TF-IDF, Word2Vec, FASTTEXT, and GloVe) combined with twelve classification algorithms. FASTTEXT embeddings consistently outperformed other methods, particularly when paired with Support Vector Machines using radial kernels. The findings suggest that automated classification can significantly reduce manual effort in statistical price collection processes.

## Method Summary
The study transforms product names into numerical vectors using five embedding techniques, then applies twelve classification algorithms to assign products to 15 ECOICOP categories. FASTTEXT with SKIP-GRAM configuration achieved the best results when combined with SVM using radial kernels. The methodology includes grid search for hyperparameter optimization and 10-fold cross-validation. The research used approximately 2,500 manually labeled product names from e-commerce sources, processed on an Intel i7-8559U with 32GB RAM running R 4.2.

## Key Results
- Support Vector Machines with radial kernel achieved 99.7% accuracy
- Logistic Regression achieved 97.6% accuracy
- Random Forests achieved 99.1% accuracy
- FASTTEXT embeddings provided the best overall performance across methods
- TF-IDF showed better performance than Word2Vec for this specific product classification task

## Why This Works (Mechanism)

### Mechanism 1: Vector Representation of Text
- Claim: Converting text product names to numerical vectors enables machine learning classification.
- Mechanism: Text data is transformed through embedding techniques (Count Vectorization, TF-IDF, Word2Vec, FASTTEXT, GloVe) that capture semantic and/or frequency information, creating fixed-dimensional vectors that classifiers can process.
- Core assumption: Product names contain sufficient distinguishing features to separate categories when properly represented numerically.
- Evidence anchors:
  - [abstract]: "we transformed the product names from a text representation to numeric vectors, a process called word embedding"
  - [section]: "In order to apply automatic classification methods, we transformed the product names from a text representation to numeric vectors"
  - [corpus]: Corpus papers address embedding challenges in related domains (e.g., "Language Models Do Not Embed Numbers Continuously"), but do not directly validate this specific product classification mechanism.
- Break condition: When product names are ambiguous, extremely short, or share near-identical vocabulary across categories.

### Mechanism 2: FASTTEXT's Subword Embedding Advantage
- Claim: FASTTEXT embeddings outperform other methods because they handle out-of-vocabulary (OOV) words through subword n-grams.
- Mechanism: FASTTEXT decomposes words into character n-grams during training, enabling vector construction for unseen words based on shared subword patterns with known vocabulary.
- Core assumption: Product names contain novel words or typos that share subword patterns with training vocabulary.
- Evidence anchors:
  - [section]: "FASTTEXT can also handle the case of words that do not appear in the initial network training dictionary"
  - [section]: "Another issue we should consider for the future is out-of-vocabulary (OOV) words. While the FASTTEXT word vectorization method can handle such words, the other methods cannot handle OOV words."
  - [corpus]: Limited direct corpus evidence for this mechanism in product classification; no corpus paper explicitly validates FASTTEXT's OOV advantage.
- Break condition: When novel words have no shared subword patterns with training vocabulary (e.g., entirely new product lines with unfamiliar terminology).

### Mechanism 3: Product Name Regularity in E-commerce
- Claim: High classification accuracy (up to 99.7%) is partially attributable to standardized product naming conventions across retailers.
- Mechanism: Product names follow consistent patterns within categories, creating regular feature distributions that classifiers can learn effectively.
- Core assumption: Product naming conventions remain stable across the e-commerce sources being classified.
- Evidence anchors:
  - [section]: "These performances can be explained also by the fact that product names do not vary greatly from one retailer to another"
  - [section]: "Once a classification model is applied to a training data set, the test data provided for classification largely follow the same rules for building product names"
  - [corpus]: Related work on semantic retrieval at scale (e.g., "Semantic Ads Retrieval at Walmart eCommerce") addresses asymmetric query-product language but doesn't directly confirm this regularity mechanism.
- Break condition: When retailers use radically different naming conventions or when new product categories emerge with unfamiliar terminology.

## Foundational Learning

- Concept: **Word Embeddings (TF-IDF vs. Dense Embeddings)**
  - Why needed here: The paper compares sparse methods (Count Vectorization, TF-IDF) against dense neural embeddings (Word2Vec, FASTTEXT, GloVe). Understanding the trade-off between frequency-based and semantic representations is essential for architecture selection.
  - Quick check question: Why might TF-IDF outperform Word2Vec on short, domain-specific product names despite lacking semantic understanding?

- Concept: **Support Vector Machines with Kernel Selection**
  - Why needed here: SVM with radial kernel achieved the highest accuracy (99.7%). Understanding how kernel choice affects decision boundaries in high-dimensional embedding spaces is critical.
  - Quick check question: What types of class separation patterns would favor a radial kernel over a linear kernel?

- Concept: **Evaluation Metrics for Imbalanced Classification**
  - Why needed here: The paper reports both accuracy and weighted F1 scores, acknowledging class imbalance in the 15-category ECOICOP dataset.
  - Quick check question: In a dataset where one class represents 60% of samples, why might accuracy alone be misleading?

## Architecture Onboarding

- **Component map:**
  Raw product names (text) -> Text preprocessing (n-gram construction up to 3 words) -> Word embedding (5 methods tested; FASTTEXT recommended) -> Classifier training (12 methods tested; SVM radial kernel recommended) -> Evaluation (confusion matrix, accuracy, F1, weighted F1)

- **Critical path:**
  1. Manually label a representative sample (paper used ~2,500 products across 15 categories)
  2. Generate multiple embedding representations (start with FASTTEXT SKIP-GRAM based on results)
  3. Train SVM with radial kernel; use grid search for hyperparameter optimization
  4. Validate with 10-fold cross-validation before deployment

- **Design tradeoffs:**
  - **Dimensionality vs. runtime:** Count Vectorization/TF-IDF used 3,000 dimensions; neural embeddings used 50. Higher dimensions increase accuracy potential but raise computation costs.
  - **OOV handling vs. simplicity:** FASTTEXT handles OOV words; Count Vectorization and TF-IDF cannot. Choose FASTTEXT for production systems with evolving product catalogs.
  - **Grid search vs. fixed parameters:** Grid search improves performance but is "time-consuming and requires parallel programming techniques" (page 4).

- **Failure signatures:**
  - Sudden accuracy drops when new retailers with different naming conventions are added
  - High accuracy but low weighted F1 indicates poor performance on minority classes
  - Excessive OOV warnings with non-FASTTEXT embeddings
  - Training time exceeding practical limits when scaling beyond 2,500 samples

- **First 3 experiments:**
  1. **Embedding ablation:** Test all 5 embedding methods with a fixed classifier (Logistic Regression) on a held-out test set to establish baseline before complex model selection.
  2. **FASTTEXT configuration sweep:** Compare FASTTEXT CBOW vs. SKIP-GRAM with L2-normalized averaging (as used in the paper) vs. simple addition for document vector construction.
  3. **Scalability probe:** Train the best configuration (FASTTEXT + SVM radial) on progressively larger subsets (500, 1,000, 2,500 samples) to estimate runtime scaling before full deployment.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can parallel programming techniques effectively reduce the computational overhead required to classify the full volume of 50,000 weekly webscraped records?
- Basis in paper: [explicit] The authors note that grid search on a small dataset was already time-consuming and that "this limitation will be accentuated when we try to classify larger datasets and special parallel programming techniques should be considered."
- Why unresolved: The experiment was limited to a sample of approx. 2500 products; the computational feasibility of processing the full weekly dataset (approx. 50,000 records) using the proposed intensive methods (like grid search) remains untested.
- What evidence would resolve it: Performance benchmarks (runtime and resource usage) of the grid search and classification algorithms when executed on the full dataset using parallel processing frameworks.

### Open Question 2
- Question: What specific strategies can effectively mitigate the out-of-vocabulary (OOV) word limitation for embedding methods other than FASTTEXT?
- Basis in paper: [explicit] The conclusion states that aside from FASTTEXT, the other embedding methods cannot handle OOV words and that "A strategy should also be devised to mitigate this limitation."
- Why unresolved: The paper identifies the vulnerability of Count Vectorization, TF-IDF, Word2Vec, and GloVe to unknown words but does not propose or test a solution for them.
- What evidence would resolve it: A comparison of classification accuracy on a test set containing high rates of OOV words, comparing baseline methods against methods augmented with an OOV handling strategy (e.g., subword hashing or dictionary updates).

### Open Question 3
- Question: Can the classification pipeline be effectively generalized to other domains such as coding occupation descriptions from free-text survey responses?
- Basis in paper: [explicit] The authors suggest that the technique has various applications and specifically propose using it for "a statistical survey where the occupation code of the respondent is needed."
- Why unresolved: The current study is restricted to product names, which have specific structures and nomenclature; it is unknown if the same vectorization and classification methods perform equally well on the more variable syntax of job descriptions.
- What evidence would resolve it: Results from a follow-up experiment applying the optimized SVM and FASTTEXT pipeline to a dataset of open-ended occupational descriptions, measuring accuracy against manual coding.

## Limitations

- Limited generalization evidence beyond the specific 15-category ECOICOP product classification task
- No assessment of performance degradation with novel product categories or retailer naming conventions
- Missing details on hyperparameter ranges for grid search optimization
- Dataset not publicly available for independent verification

## Confidence

- **High confidence** in the technical feasibility of applying machine learning to product classification given the demonstrated 99.7% accuracy with SVM+FASTTEXT
- **Medium confidence** in the claimed superiority of FASTTEXT for OOV handling, as this was asserted but not empirically compared against OOV scenarios
- **Low confidence** in claims about product name regularity across retailers without cross-retailer validation studies

## Next Checks

1. Test classification performance on product names from retailers not included in the original training data to assess naming convention robustness
2. Measure accuracy degradation when introducing product categories beyond the original 15 ECOICOP classes
3. Conduct ablation studies comparing FASTTEXT's OOV handling against Word2Vec/GloVe when processing novel product terminology