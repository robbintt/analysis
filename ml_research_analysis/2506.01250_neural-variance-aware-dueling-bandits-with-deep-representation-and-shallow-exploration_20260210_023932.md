---
ver: rpa2
title: Neural Variance-aware Dueling Bandits with Deep Representation and Shallow
  Exploration
arxiv_id: '2506.01250'
source_url: https://arxiv.org/abs/2506.01250
tags:
- lemma
- regret
- cumulative
- neural
- average
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces NVLDB, the first neural variance-aware dueling
  bandit algorithm with shallow exploration. The key innovation is using a Gram matrix
  constructed only from gradients with respect to the last-layer parameters of a neural
  network, significantly reducing computational overhead compared to prior methods
  that use all parameters.
---

# Neural Variance-aware Dueling Bandits with Deep Representation and Shallow Exploration

## Quick Facts
- **arXiv ID**: 2506.01250
- **Source URL**: https://arxiv.org/abs/2506.01250
- **Reference count**: 40
- **Primary result**: Introduces NVLDB, the first neural variance-aware dueling bandit algorithm with shallow exploration, achieving sublinear cumulative average regret with 28x computational speedup.

## Executive Summary
This paper introduces NVLDB, the first neural variance-aware dueling bandit algorithm that uses shallow exploration. The key innovation is constructing the Gram matrix using only gradients with respect to the last-layer parameters of a neural network, dramatically reducing computational overhead from linear in total parameters to linear in context dimension. The algorithm achieves sublinear cumulative average regret of order $\tilde{O}(d\sqrt{\sum\sigma^2_t} + \sqrt{dT})$ for sufficiently wide neural networks, where $d$ is contextual dimension, $\sigma^2_t$ is variance at round $t$, and $T$ is total rounds. Empirical evaluation demonstrates consistent outperformance over baselines while being computationally efficient.

## Method Summary
The algorithm operates in a contextual dueling bandit setting where at each round, the learner observes a set of $K$ context vectors and must select a pair of arms to compare. A two-layer ReLU network maps context vectors to utilities. The key computational innovation is constructing the Gram matrix $V_t$ using only last-layer gradients $\nabla_\theta f(x)$ rather than full Jacobian gradients, reducing matrix inversion costs significantly. The algorithm uses variance-weighted log-likelihood loss where regularization terms are scaled by inverse variance estimates. Updates occur every round via gradient descent on network parameters. Three arm selection strategies are implemented under both UCB and Thompson Sampling frameworks: Asymmetric (greedy on first arm), Optimistic Symmetric, and Candidate-based selection.

## Key Results
- Sublinear cumulative average regret of order $\tilde{O}(d\sqrt{\sum\sigma^2_t} + \sqrt{dT})$ achieved for sufficiently wide neural networks
- NVLDB variants consistently outperform baseline algorithms on synthetic and real-world datasets
- Proposed method runs approximately 28x faster than existing neural dueling bandit approaches
- Both variance-aware and variance-agnostic variants analyzed under UCB and Thompson Sampling frameworks

## Why This Works (Mechanism)

### Mechanism 1: Shallow Exploration for Computational Efficiency
The algorithm constructs the confidence matrix $V_t$ using only the gradient of the final layer $\nabla_\theta f(x)$ rather than the full Jacobian $\nabla_{W,\theta} f(x)$. This reduces computational complexity from linear in total parameters to linear in context dimension $d$, enabling real-time application. The core assumption is that deep representations learned by hidden layers remain sufficiently stable or are updated such that the last layer's linear model captures necessary uncertainty for exploration. If the utility function changes rapidly or hidden layers fail to converge, the last-layer-only uncertainty estimation may become uncalibrated.

### Mechanism 2: Variance-Adaptive Confidence Scaling
The algorithm weights regularization loss and Gram matrix update by inverse of estimated variance $\zeta_i^{-2}$. High-variance comparisons are down-weighted to prevent overconfident updates, while low-variance comparisons strongly influence parameter estimates, accelerating convergence. This relies on accurate variance estimation via the current network output using the link function (e.g., $g(1-g)$). Poor variance estimates during early rounds when the network is random might initially misweight critical updates.

### Mechanism 3: Theoretical Guarantees via Neural Tangent Kernel (NTK)
The analysis relies on NTK regime where sufficiently wide networks behave linearly with respect to parameters. This allows mapping nonlinear utility $u(x)$ to $\theta_*^T \phi(x)$ and applying linear concentration inequalities to bound error. The network width $m$ must be polynomial in $T$ and other hyperparameters. If the network is not sufficiently wide, the linear approximation of gradient dynamics breaks down, invalidating regret guarantees.

## Foundational Learning

- **Contextual Dueling Bandits**: Problem formulation where binary preference feedback (which arm won) is received based on context vectors. Needed as the core problem setup. Quick check: Can you explain the difference between minimizing regret in a standard bandit versus a dueling bandit?
- **Neural Tangent Kernel (NTK)**: Theory that justifies analyzing neural networks as linear bandits in feature space. Needed as the theoretical backbone. Quick check: Why does a "sufficiently wide" neural network behave like a linear model in feature space during training?
- **Exploration-Exploitation Strategies (UCB vs. Thompson Sampling)**: Frameworks for handling uncertainty when selecting arm pairs. Needed as the selection policy framework. Quick check: How does Thompson Sampling differ from UCB in how it handles uncertainty when selecting the next pair of arms?

## Architecture Onboarding

- **Component map**: Input Layer -> Representation Engine (2-layer ReLU Network) -> Uncertainty Module (Gram Matrix $V_t$) -> Selection Policy (UCB/TS calculator) -> Optimizer (Gradient Descent)
- **Critical path**: 1. Observe context set $X_t$ 2. Forward pass to compute utilities and gradients $\phi(x)$ for all arms 3. Select pair using Selection Policy (e.g., UCB-ASYM) based on scores from $\theta_{t-1}$ and $V_{t-1}$ 4. Update $V_t$ using gradient differences and update network parameters via gradient descent on variance-weighted loss
- **Design tradeoffs**: Speed vs. Representation Power - shallow exploration trades potentially tighter uncertainty bounds for massive speed gains (28x faster). Variance parameter $\epsilon$ - small values enable variance-awareness but risk instability; large values default to variance-agnostic performance.
- **Failure signatures**: Linear Regret if network width $m$ is too small, violating NTK assumption. Slow Convergence if confidence coefficient $a_t$ is set too low (over-explores) or too high (gets stuck in local optima).
- **First 3 experiments**: 1. Baseline Speed Check: Compare wall-clock time of NVLDB vs. Neural Dueling Bandits over 2,000 rounds to verify "28x faster" claim. 2. Regret Curve Validation: Run on synthetic "Cosine" or "Square" utility tasks to ensure cumulative average regret is sublinear ($\tilde{O}(\sqrt{T})$). 3. Ablation on $\epsilon$: Test variance-aware variant against variance-agnostic variant ($\zeta_t = 1$) to observe performance gaps in high/low noise regimes.

## Open Questions the Paper Calls Out

- **Open Question 1**: What are the tight lower bounds for neural variance-aware dueling bandits, and can the achieved regret of $\tilde{O}(d\sqrt{\sum_{t=1}^T \sigma_t^2} + \sqrt{dT})$ be improved? The paper states lower bounds of order $\tilde{O}(\sqrt{dT})$ exist for linear settings but no lower bounds are established for the neural variance-aware setting.

- **Open Question 2**: Can the requirement for "sufficiently wide neural networks" ($m = \text{poly}(T, L, d, \ldots)$) be relaxed while maintaining theoretical guarantees? The paper explicitly requires polynomial width in multiple parameters, but the minimal width needed for sublinear regret remains unknown.

- **Open Question 3**: How do the results generalize to more practical neural architectures such as convolutional networks or transformers? The NTK analysis and concentration inequalities depend on the specific network structure; extending to other architectures requires re-deriving feature map properties and NTK expressions.

## Limitations

- Theoretical guarantees require "sufficiently wide" neural networks with width polynomial in $T$, but exact width requirements relative to $T$ are not explicitly quantified
- Variance-aware component depends critically on accurate variance estimation, but paper doesn't thoroughly explore failure modes when variance estimates are poor or $\epsilon$ parameter is poorly tuned
- Empirical evaluation uses relatively narrow networks (m=32) which may not satisfy the theoretical width conditions implied by the NTK analysis

## Confidence

- **High Confidence**: Computational efficiency claim (28x speedup) - well-supported by clear complexity reduction from full-parameter to last-layer-only Gram matrices
- **Medium Confidence**: Sublinear regret bound derivation - follows established NTK-based techniques but applicability to specific width used in experiments remains uncertain
- **Medium Confidence**: Empirical superiority over baselines - demonstrated but comparison pool is limited and synthetic tasks may not capture full real-world complexity

## Next Checks

1. **Width Scaling Analysis**: Run experiments varying network width m (e.g., m=16, 32, 64, 128) to empirically verify when NTK regime breaks down and linear regret emerges
2. **Variance Sensitivity Test**: Implement ablation study with artificially corrupted or underestimated variance signals to measure impact on regret performance across different Îµ values
3. **Baseline Expansion**: Add comparisons against more recent neural dueling bandit methods (e.g., Neural Thompson Sampling variants) on UCI datasets to strengthen empirical claims