---
ver: rpa2
title: Anchored Langevin Algorithms
arxiv_id: '2509.19455'
source_url: https://arxiv.org/abs/2509.19455
tags:
- langevin
- anchored
- distribution
- algorithms
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces anchored Langevin algorithms to address limitations
  of standard Langevin-based MCMC methods, which struggle with non-differentiable
  log-densities and heavy-tailed distributions. The key idea is to replace the original
  potential with a smooth reference potential and modify the Langevin diffusion through
  multiplicative scaling, allowing gradient-based updates even when the true potential
  is non-differentiable or exhibits sublinear growth.
---

# Anchored Langevin Algorithms

## Quick Facts
- arXiv ID: 2509.19455
- Source URL: https://arxiv.org/abs/2509.19455
- Reference count: 18
- Primary result: Introduces anchored Langevin algorithms for sampling from non-smooth and heavy-tailed distributions with non-asymptotic convergence guarantees.

## Executive Summary
This paper introduces anchored Langevin algorithms to address limitations of standard Langevin-based MCMC methods, which struggle with non-differentiable log-densities and heavy-tailed distributions. The key idea is to replace the original potential with a smooth reference potential and modify the Langevin diffusion through multiplicative scaling, allowing gradient-based updates even when the true potential is non-differentiable or exhibits sublinear growth.

The authors establish non-asymptotic convergence guarantees in the 2-Wasserstein distance to the target distribution and provide an equivalent formulation via a random time change of the Langevin diffusion. They analyze Euler-Maruyama discretizations and provide bounds on the discretization error. The framework accommodates both non-smooth potentials (via Gaussian smoothing) and heavy-tailed distributions, extending the applicability of gradient-based sampling.

## Method Summary
The method replaces the original potential U with a smooth reference potential U₀ and modifies the Langevin SDE by scaling both the drift and diffusion terms with state-dependent factors involving exp(U - U₀). For non-smooth components, Gaussian smoothing is used to approximate gradients via Monte Carlo sampling. The resulting dynamics preserve the target distribution while enabling gradient-based updates. The algorithm can be implemented through standard Euler-Maruyama discretization or via an equivalent time-changed formulation that connects to well-understood Langevin theory.

## Key Results
- Proves π is the unique invariant distribution under multiplicative scaling of drift/diffusion terms
- Establishes non-asymptotic convergence in 2-Wasserstein distance with explicit rates
- Shows equivalence between anchored dynamics and time-changed standard Langevin
- Demonstrates effectiveness on Laplace distributions, Bayesian logistic regression with non-smooth regularizers, and heavy-tailed distributions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multiplicative scaling of drift and diffusion terms by exp(U - U₀) preserves the target Gibbs distribution while enabling use of smooth gradients.
- Mechanism: The anchored Langevin SDE modifies standard overdamped Langevin by replacing ∇U(x) with ∇U₀(x)exp(U(x) - U₀(x)) and scaling the diffusion coefficient by exp((U(x) - U₀(x))/2). This state-dependent modification ensures π ∝ exp(-U(x)) remains the unique invariant distribution, as proven via the adjoint operator calculation L*exp(-U) = 0 in the appendix.
- Core assumption: The drift condition [d - ⟨x,∇U₀(x)⟩]exp(U-U₀)(x) ≤ -c₀∥x∥²⁺ʳ + c₁ holds for some c₀, c₁ > 0, r > -1 (Assumption 1).
- Evidence anchors:
  - [abstract] "modifies the Langevin diffusion via multiplicative scaling"
  - [Section 3, Theorem 2] Proves π is the unique invariant measure under Assumption 1
  - [corpus] Weak direct evidence; neighbor papers focus on heavy-tailed sampling via different mechanisms (stereographic transforms, fractional dynamics)
- Break condition: If U and U₀ diverge significantly (sup|U - U₀| → ∞), the multiplicative factors can cause numerical instability or violate the drift condition.

### Mechanism 2
- Claim: Random time change provides equivalent formulation and alternative discretization scheme.
- Mechanism: The anchored SDE X_t can be expressed as Z_ℓ(t) where Z follows standard Langevin with potential U₀ and ℓ(t) solves dℓ/dt = exp(U(Z_ℓ) - U₀(Z_ℓ)). This connects anchored dynamics to well-understood Langevin theory.
- Core assumption: The condition d - ⟨x,∇U₀(x)⟩ ≤ -c₀ for ∥x∥² ≥ K ensures ℓ(t) is well-defined and finite (Assumption 9).
- Evidence anchors:
  - [Section 3.1, Theorem 11] "X_t := Z_ℓ(t) is the unique weak (strong) solution of SDE (5)"
  - [Section 5.1] Shows discretizations are equivalent (Theorem 15)
  - [corpus] No direct corpus support; time-change techniques appear uncommon in related work
- Break condition: If the time-change ODE dℓ/dt = exp(U - U₀) becomes stiff (large gradients), numerical integration requires very small stepsizes.

### Mechanism 3
- Claim: Gaussian smoothing of non-smooth components yields gradients while maintaining bounded approximation error.
- Mechanism: For U = f + g with smooth f and Lipschitz g, define U₀ = f + g₀ where g₀(x) = E[g(x + μξ)]. Lemma 18 bounds |U - U₀| ≤ Kμ√d, and the smoothed gradient ∇g₀ is computable via Monte Carlo without requiring ∇g.
- Core assumption: g is K-Lipschitz and γ-weakly convex; f is m_f-strongly convex and L_f-smooth (Assumptions 16-17).
- Evidence anchors:
  - [Section 5.2, Lemma 18] Bounds the smoothing error
  - [Section 5.3, Theorem 30] Non-asymptotic convergence with Gaussian smoothing
  - [corpus] Neighbor "Diffusion Models with Heavy-Tailed Targets" similarly addresses score estimation challenges
- Break condition: Small μ (needed for accuracy) requires large Monte Carlo samples N and creates stiffness in stepsize constraints η ≤ mμ²/[4exp(6Kμ√d)(4μ²L_f² + 8K²d)].

## Foundational Learning

- Concept: **Overdamped Langevin Diffusion and Gibbs Distributions**
  - Why needed here: The entire method builds on modifying the SDE dX_t = -∇U(X_t)dt + √2dW_t which has π ∝ exp(-U) as stationary distribution.
  - Quick check question: Given potential U(x) = ∥x∥²/2, what is the stationary distribution of the Langevin SDE?

- Concept: **Strong Convexity and Smoothness (Lipschitz Gradients)**
  - Why needed here: Non-asymptotic analysis requires m-strong convexity and L-smoothness of the effective drift to establish contraction and Wasserstein convergence.
  - Quick check question: If f is m-strongly convex, what inequality relates ⟨∇f(x) - ∇f(y), x - y⟩ to ∥x - y∥²?

- Concept: **Poincaré Inequality and Ergodicity**
  - Why needed here: Proposition 7 uses Poincaré inequality to establish χ²-divergence convergence; understanding when this holds vs. when Lyapunov drift arguments are needed distinguishes light-tailed from heavy-tailed regimes.
  - Quick check question: Does a Poincaré inequality typically hold for distributions with polynomial tails?

## Architecture Onboarding

- Component map:
  - Potential Decomposition: U = f + g where f is smooth, g is non-smooth/Lipschitz
  - Smoothing Module: g₀(x) = E[g(x + μξ)] via Monte Carlo with N samples
  - Drift Computation: b(x) = -∇U₀(x)exp(U - U₀) with U₀ = f + g₀
  - Diffusion Scaling: σ(x) = exp((U - U₀)/2)
  - Euler-Maruyama Step: x_{k+1} = x_k + ηb(x_k) + √(2η)σ(x_k)ξ_{k+1}
  - Alternative Time-Change Path: ℓ update via ODE, then z update with adaptive stepsize Δℓ_k

- Critical path: The Monte Carlo gradient estimation (∇g₀ via μ⁻¹Σ ξ_i g(x + μξ_i)) dominates per-iteration cost; N = O(μ⁻⁴) samples may be needed theoretically.

- Design tradeoffs:
  - Smaller μ → better approximation but tighter stepsize constraints and more Monte Carlo samples
  - Larger η → faster convergence but risk of instability; η_max depends on (m - α), L², and α
  - N vs. accuracy: Corollary 31 shows N scales as (τ(kη)ε⁻¹)² where τ depends on iteration count

- Failure signatures:
  - Explosion/NaN: exp(U - U₀) overflows when smoothing is too coarse or potential mismatch is large
  - Non-convergence: Wasserstein distance plateaus above target (visible in Fig 1-3 for standard Langevin baseline)
  - Slow mixing: Very small η needed when μ is small; check if η ≤ mμ²/[4exp(6Kμ√d)(4μ²L_f² + 8K²d)]

- First 3 experiments:
  1. **Sanity check on Laplace(0,1)**: Implement Algorithm 1 with U(x) = √2|x|, U₀ via Gaussian smoothing (Eq. 21), measure W₂ vs. true quantiles. Compare convergence speed to baseline at η = 0.1, 0.5 with μ = 1, 2, 3.
  2. **Stepsize stability boundary**: For a strongly convex U, vary η from η_max/10 to 2η_max and plot final W₂ after fixed iterations. Identify empirical stability threshold and compare to theoretical η_max in Theorem 14.
  3. **Heavy-tailed Student-t sampling**: Use the U₀ = β log q(x), U = (β+1) log q(x) construction from Example 1 with q(x) = 1 + ν⁻¹(x-μ)ᵀΣ⁻¹(x-μ). Compare anchored vs. standard Langevin on convergence rate (should see anchored converge while standard plateaus, as suggested by Fig 8).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can non-asymptotic convergence guarantees be established for the discretized anchored Langevin dynamics when the reference potential $U_0$ is non-convex?
- Basis in paper: [inferred] Assumption 12 explicitly requires $U_0$ to be $m$-strongly convex to derive the discrete-time bounds in Theorem 14, limiting the theoretical scope compared to the continuous-time results.
- Why unresolved: The proof technique relies on synchronous coupling and mean-square analysis (Li et al., 2022b) which necessitates contraction properties inherent to strong convexity.
- What evidence would resolve it: A proof of convergence for the discretized algorithm using weaker functional inequalities, such as Poincaré or weak Poincaré inequalities, without the convexity requirement.

### Open Question 2
- Question: Is there a systematic or automated method for selecting the optimal reference potential $U_0$ for a generic target distribution?
- Basis in paper: [inferred] The paper demonstrates the efficacy of the method using specific choices for $U_0$ (e.g., Gaussian smoothing or $\beta \log q(x)$ for Student-t), but notes the design relies on approximating $U$ "appropriately."
- Why unresolved: The paper provides conditions for convergence based on the quality of the approximation but does not offer a general algorithm to construct $U_0$ for arbitrary heavy-tailed or non-smooth targets.
- What evidence would resolve it: An adaptive procedure that constructs $U_0$ to minimize the convergence constant $C$ in Theorem 14, or a theoretical characterization of the optimal anchor for a given function class.

### Open Question 3
- Question: Can the algorithm be modified to reduce the dependency on the Monte Carlo sample size $N$ for non-smooth potentials while maintaining convergence guarantees?
- Basis in paper: [inferred] Corollary 31 suggests the number of samples $N$ must scale polynomially with dimension and accuracy to control the bias $\tau$ introduced by the Gaussian smoothing approximations.
- Why unresolved: The analysis assumes a fixed batch average for smoothing; it is unknown if using single-sample stochastic gradients would preserve the convergence rate or destabilize the dynamics.
- What evidence would resolve it: A non-asymptotic analysis of a variant of Algorithm 1 using single-sample estimators (unbiased or with control variates) showing that the computational complexity scales favorably with dimension $d$.

## Limitations

- Numerical stability in high-dimensional settings remains unproven; multiplicative scaling by exp(U-U₀) could amplify errors when potentials diverge.
- Theoretical discretization bounds assume bounded moments of the form E[exp(θX)] which may not hold uniformly across all non-smooth/heavy-tailed targets.
- Extension to non-convex f in U = f + g lacks comprehensive theoretical support beyond simple cases like √|x|.
- Monte Carlo variance in gradient estimation (∇g₀) is unbounded for some g (e.g., ReLU), potentially requiring large N for accuracy.

## Confidence

- **High confidence**: Core theoretical framework (SDE derivation, existence/uniqueness, invariant measure), basic numerical validation on Laplace distribution, and applicability to Bayesian logistic regression.
- **Medium confidence**: Heavy-tailed sampling performance, Gaussian smoothing error bounds, and discretization error estimates.
- **Low confidence**: High-dimensional behavior, scalability of Monte Carlo gradient estimation, and robustness to poor choices of reference potential U₀.

## Next Checks

1. **Dimensional scaling study**: Test anchored Langevin on high-dimensional Gaussian mixture models (d=100, 500, 1000) with non-smooth regularizers. Measure convergence rate and Monte Carlo variance as d grows. Expected: variance increases with d, requiring larger N; confirm if theoretical scaling N=O(μ⁻⁴) holds empirically.
2. **Stability under poor U₀ choice**: Run experiments where U₀ is deliberately chosen to poorly match U (e.g., Laplace with U₀ = ∥x∥²/2). Measure explosion probability, W₂ convergence, and identify safe regions in (U,U₀) space.
3. **Non-convex f verification**: Apply anchored Langevin to Bayesian logistic regression with non-convex SCAD/MCP regularizers (U = -log p(y|X,β) + g(β)). Measure convergence and mixing time, comparing to theoretical guarantees under non-convexity assumptions.