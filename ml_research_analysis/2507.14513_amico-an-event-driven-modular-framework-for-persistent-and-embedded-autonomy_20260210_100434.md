---
ver: rpa2
title: 'Amico: An Event-Driven Modular Framework for Persistent and Embedded Autonomy'
arxiv_id: '2507.14513'
source_url: https://arxiv.org/abs/2507.14513
tags:
- amico
- agent
- event
- reasoning
- action
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Amico is an event-driven, modular agent framework designed for
  persistent autonomy in resource-constrained environments. Built in Rust and deployable
  via WebAssembly, it decouples perception, reasoning, and action into asynchronous
  components to enable responsive, adaptive behavior across embedded and browser-based
  platforms.
---

# Amico: An Event-Driven Modular Framework for Persistent and Embedded Autonomy

## Quick Facts
- arXiv ID: 2507.14513
- Source URL: https://arxiv.org/abs/2507.14513
- Reference count: 5
- Primary result: Amico achieved a 0.61 reward score on WebShop vs 0.47 for baseline LLM prompting

## Executive Summary
Amico is an event-driven, modular agent framework designed for persistent autonomy in resource-constrained environments. Built in Rust and deployable via WebAssembly, it decouples perception, reasoning, and action into asynchronous components to enable responsive, adaptive behavior across embedded and browser-based platforms. The framework introduces structured abstractions for event generation, task management, and model-based reasoning with optional RAG integration.

In experiments on the AgentBench WebShop task, Amico outperformed a baseline LLM prompting method with a reward score of 0.61 (vs. 0.47), demonstrating the value of its event-driven control loop. Even without retrieval augmentation, Amico maintained competitive performance, highlighting the benefits of persistent task state and modular architecture. Future work will extend Amico toward multi-agent collaboration, advanced RAG, embodied deployment, and adaptive task generalization.

## Method Summary
Amico uses an event-driven architecture with three key components: Event Generator (transforms observations into structured events), Action Generator (produces â‰¤5 candidate actions via LLM), and Dispatcher (selects one action). The system maintains persistent task state across interactions and optionally integrates RAG for semantic memory. Communication occurs via JSON in an event loop, with DeepSeek-V3 as the backend LLM. The framework was evaluated on WebShop using 200 tasks, measuring AgentBench reward score combining item selection accuracy and navigation efficiency.

## Key Results
- Amico achieved 0.61 reward score on WebShop, outperforming baseline LLM prompting (0.47)
- RAG integration degraded performance to 0.53, suggesting noise in retrieval for this task type
- Event-driven architecture enabled responsive, persistent autonomy in resource-constrained environments

## Why This Works (Mechanism)

### Mechanism 1: Asynchronous Decoupling of Perception and Action
Decoupling environmental sensing from decision execution via an event queue improves responsiveness and reduces invalid actions compared to synchronous polling loops. Raw inputs are immediately parsed into timestamped Events and buffered. The Action Selector consumes these asynchronously, ensuring that slow reasoning steps do not block the ingestion of new environmental data.

### Mechanism 2: Persistent Task State for Temporal Coherence
Maintaining an explicit, persistent Task abstraction allows the agent to sustain long-term goals better than stateless context windows. The Engine Layer holds active Tasks that influence the Action Selector, providing a "memory" of intent that persists across multiple interaction cycles, preventing the agent from losing context in multi-step workflows.

### Mechanism 3: Constrained Action Generation
Filtering candidate actions through a structured "model description" and specific "available actions" list yields higher decision accuracy than unconstrained LLM generation. The Action Selector retrieves a dynamic list of executable actions and filters them against the current event and RAG context before dispatching, reducing hallucination risk.

## Foundational Learning

- **Event-Driven Architecture (EDA)**
  - Why needed: Amico replaces traditional polling loops with event loops. Understanding non-blocking I/O is required to debug agent responsiveness.
  - Quick check: Can you explain the difference between blocking sensor calls versus event-driven sensor handlers?

- **WebAssembly (WASM) on Edge**
  - Why needed: Amico targets embedded systems via WASM. Understanding sandboxing and memory limitations is crucial for deployment.
  - Quick check: Why is Rust preferred over Python for agents running inside browser WASM runtimes?

- **Retrieval-Augmented Generation (RAG)**
  - Why needed: Amico optionally uses RAG to ground its "Model Description." Distinguishing procedural vs semantic memory is key.
  - Quick check: In Amico's workflow, does RAG update before or after action execution, and why does this matter?

## Architecture Onboarding

- **Component map:** Environment Layer (Sensors) -> Event Generator -> Event Queue -> Engine Layer (Action Selector, Task Manager) -> Effectors
- **Critical path:** Event Generator -> Event Queue -> Action Selector -> Effector. The Action Selector (LLM) is the primary latency bottleneck.
- **Design tradeoffs:** Modularity vs latency (two-step reasoning adds robustness but increases latency); RAG vs context window (RAG introduced noise in WebShop).
- **Failure signatures:** Queue starvation, hallucinated actions not in available list, state drift between Task and environment.
- **First 3 experiments:**
  1. Dry Run: Mock Action Selector with rule-based script to verify event generation and execution without LLM.
  2. Single-Step Latency Test: Measure time from Event generation to Action dispatch vs baseline.
  3. RAG Ablation: Compare performance with and without RAG, logging retrieval latency and relevance.

## Open Questions the Paper Calls Out

### Open Question 1
Can advanced retrieval mechanisms (e.g., dynamic memory pruning or intent-aware ranking) prevent the performance degradation observed when integrating RAG into Amico? The paper shows Amico + RAG (0.53) underperformed Amico alone (0.61), attributed to "irrelevant documents" disrupting coherence. Evidence needed: follow-up experiment where Amico + Advanced RAG significantly outperforms non-RAG baseline.

### Open Question 2
Does decomposing the Event Generator and Action Selector into separate, asynchronous cooperative agents improve system robustness compared to the monolithic single-agent architecture? Section 5.1 proposes a heterogeneous multi-agent configuration for specialization and asynchronous processing. Evidence needed: benchmarks comparing success rate and latency of multi-agent vs monolithic architecture.

### Open Question 3
Can reinforcement learning (e.g., PPO) effectively train adaptive event evaluators to outperform manually defined heuristics for event prioritization? Section 5.4 proposes using RL for joint optimization of scheduler and Action Selector. Evidence needed: demonstration of RL-based scheduler maintaining/improving task success rates while reducing completion time across heterogeneous tasks.

## Limitations
- Critical implementation details missing (system prompts, RAG service configuration, action vocabulary constraints)
- Performance degradation with RAG is unexplained and counterintuitive
- Lack of empirical validation for persistent task state benefits against alternatives

## Confidence

- **High confidence**: Core event-driven architecture mechanism is well-specified and theoretically sound. Basic Amico implementation without RAG appears reproducible.
- **Medium confidence**: Persistent task state mechanism is described but lacks details on state serialization and conflict resolution. Claim plausible but not empirically validated.
- **Low confidence**: RAG integration details are too sparse for reliable reproduction. Performance claims around RAG are internally inconsistent.

## Next Checks
1. Implement and run the dry run experiment with a rule-based Action Selector to verify event generation, queuing, and execution without LLM complexity.
2. Conduct a single-step latency test comparing baseline DeepSeek prompting vs. Amico's modular pipeline to quantify architectural overhead and identify bottlenecks.
3. Perform a controlled RAG ablation study with logging of retrieval latency and relevance scores to understand why RAG degrades performance in this specific context.