---
ver: rpa2
title: Calibrated Multimodal Representation Learning with Missing Modalities
arxiv_id: '2511.12034'
source_url: https://arxiv.org/abs/2511.12034
tags:
- modalities
- missing
- multimodal
- learning
- anchor
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of multimodal representation
  learning when data has missing modalities, which leads to anchor shift in alignment.
  The authors propose CalMRL, a method that calibrates incomplete alignments by imputing
  missing modalities at the representation level using shared latent variables and
  modality-specific parameters.
---

# Calibrated Multimodal Representation Learning with Missing Modalities

## Quick Facts
- arXiv ID: 2511.12034
- Source URL: https://arxiv.org/abs/2511.12034
- Authors: Xiaohao Liu; Xiaobo Xia; Jiaheng Wei; Shuo Yang; Xiu Su; See-Kiong Ng; Tat-Seng Chua
- Reference count: 40
- Primary result: CalMRL achieves significant improvements (e.g., +10.6% on MSR-VTT, +15.4% on AudioCaps) on multimodal retrieval tasks when trained on datasets with missing modalities

## Executive Summary
This paper addresses the challenge of multimodal representation learning when data has missing modalities, which leads to anchor shift in alignment. The authors propose CalMRL, a method that calibrates incomplete alignments by imputing missing modalities at the representation level using shared latent variables and modality-specific parameters. They derive a closed-form solution for the posterior distribution of shared latents and employ a bi-step learning method to refine the generative parameters. The calibrated representations are then used to optimize encoders with the PMRL objective.

## Method Summary
CalMRL addresses multimodal representation learning with missing modalities by imputing missing representations through a generative model. The method assumes observed modalities are generated from shared latent variables, and derives closed-form solutions for the posterior distribution of these latents. It then uses these imputed representations to optimize encoders via a spectral alignment objective that maximizes the largest singular value of the joint representation matrix, effectively mitigating anchor shift that occurs when modalities are missing during training.

## Key Results
- CalMRL outperforms state-of-the-art methods on multimodal retrieval tasks with missing modalities
- Achieves +10.6% improvement on MSR-VTT and +15.4% on AudioCaps datasets
- Demonstrates significant gains in continual learning settings where new data with missing modalities is added
- Shows robust performance across multiple benchmark datasets with varying modality completeness

## Why This Works (Mechanism)

### Mechanism 1: Anchor Shift Mitigation via Spectral Calibration
The paper posits an "anchor shift" where observed modalities align to a local vector rather than the global optimal centroid defined by all modalities. By generating pseudo-representations for missing modalities based on shared latent variables derived from observed ones, the method completes the Gram matrix G. This completion theoretically pushes the leading singular vector (the anchor) back toward its optimal position, satisfying the condition that imputation error must be small relative to the spectral gap.

### Mechanism 2: Closed-Form Posterior Inference for Generative Imputation
The method employs a bi-step learning process that analytically computes the posterior q(β) (mean m and covariance V) of the shared latent β given observed modalities, rather than using iterative gradient descent. It then updates the generative parameters (W, μ, σ) using the sufficient statistics of this posterior. This approach stabilizes and accelerates optimization by avoiding the noisy gradients that can arise from training a neural generator.

### Mechanism 3: Joint Alignment via Largest Singular Value Maximization
The learning objective maximizes the largest eigenvalue of the completed Gram matrix, enforcing a unified direction even when the input data is a mix of observed and imputed modalities. This geometric constraint forces all vectors (observed and imputed) to maximize their collective variance in a single direction, effectively "pulling" them together and ensuring coherent alignment across modalities.

## Foundational Learning

- **Concept: Probabilistic PCA and Latent Variable Models**
  - Why needed here: To understand how the paper derives Eq. (5) and (6) for the generative imputation process
  - Quick check question: Can you explain why a closed-form solution for the posterior covariance requires inverting the matrix (I + ΣW^⊤Σ^-1W)?

- **Concept: Spectral Graph Theory / Matrix Perturbation**
  - Why needed here: To grasp the "Anchor Shift" theory (Theorem 1) and understand how missing modalities perturb the data matrix
  - Quick check question: What happens to the leading singular vector of a matrix if you append a column that is orthogonal to all existing columns?

- **Concept: Multimodal Alignment (Contrastive vs. Geometric)**
  - Why needed here: To distinguish CalMRL from standard contrastive learning approaches like CLIP
  - Quick check question: How does maximizing the largest singular value of the Gram matrix differ from maximizing cosine similarity between pairs?

## Architecture Onboarding

- **Component map:**
  Unimodal Encoders (φ) -> Generative Parameter Store (W_m, μ_m) -> Imputation Logic -> Alignment Head (Gram matrix + SVD)

- **Critical path:**
  1. Batch data enters; some modalities are missing (masked)
  2. Encoders output z_obs
  3. **Imputation:** Use current W, μ to compute posterior mean m (shared latent) and generate ẑ_miss
  4. **Alignment:** Compute Gram matrix on [z_obs, ẑ_miss]
  5. **Backprop:** Update Encoders (φ) via L_rep (gradient descent) AND Update Generative Params (W, μ) via Eq 6 (analytical update)

- **Design tradeoffs:**
  - Analytical vs. Neural Imputation: Uses linear generative model for speed and stability, but may fail to capture complex, non-linear cross-modal dependencies
  - Shared Latent Space: Assumes single shared β for all modalities, ignoring modality-specific "private" information

- **Failure signatures:**
  - High Imputation MSE: If observed modalities poorly predict missing ones, calibration injects noise
  - Mode Collapse: If ẑ_miss converges to constant vector regardless of input, generative parameters have degenerated
  - Divergence of W: If closed-form updates produce exploding values, check stability of covariance matrix inversion

- **First 3 experiments:**
  1. **Sanity Check (Imputation Quality):** Freeze encoders; train only generative parameters (W, μ). Plot MSE between real held-out embeddings and imputed ones
  2. **Ablation (Calibration Effect):** Train full model but skip imputation step (treat missing as zero vectors). Compare resulting anchor shift magnitude
  3. **Downstream Retrieval (MSR-VTT/AudioCaps):** Evaluate Recall@1 on benchmarks, specifically looking at continual training setting

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can anchor shift be effectively mitigated without explicitly imputing missing modalities?
- Basis in paper: The conclusion states that future explorations should focus on "calibrating the shift without imputation"
- Why unresolved: Current CalMRL framework relies on generating "oracle" modalities via generative model to serve as calibration target
- What evidence would resolve it: A novel learning objective that adjusts alignment of observed modalities directly in latent space, achieving comparable performance without representation generation

### Open Question 2
- Question: How does CalMRL's performance and convergence scale when integrated with more powerful, computationally intensive backbone architectures?
- Basis in paper: Limitations section notes that incorporating more powerful backbones necessitates pre-training, which is computationally intensive
- Why unresolved: Authors validated CalMRL on specific architectures but interaction with larger foundation models remains untested
- What evidence would resolve it: Empirical results applying CalMRL to large-scale foundation models with analysis of training stability and resource overhead

### Open Question 3
- Question: Is the linearity assumption in the Probabilistic PCA generative model sufficient for capturing complex inter-modality relationships?
- Basis in paper: The method models generative process as z_m = W_m β + μ_m + ε_m (Eq. 2), assuming linear mapping from shared latents to representations
- Why unresolved: Real-world multimodal data often exhibits complex, non-linear dependencies that linear Gaussian model may not capture
- What evidence would resolve it: Ablation studies comparing linear generator against non-linear alternatives (e.g., conditional VAEs) to determine if non-linear imputation significantly lowers empirical anchor shift

## Limitations

- **Gaussian Assumption for Imputation:** The closed-form posterior derivation relies on critical assumption that cross-modal relationships can be modeled with Gaussian distributions, which may not hold for real-world data
- **Spectral Gap Sensitivity:** Calibration succeeds only when imputation error is smaller than spectral gap between first and second singular values, with limited empirical analysis of robustness boundaries
- **Limited Ablation on Bi-Step Learning:** Paper doesn't adequately compare against simpler alternatives like iterative neural imputation or non-linear generative models

## Confidence

- **High Confidence:** Anchor shift mitigation mechanism is theoretically sound and well-grounded in spectral perturbation theory
- **Medium Confidence:** Closed-form posterior inference is mathematically valid under Gaussian assumptions, but practical impact depends heavily on real-world data distributions
- **Medium Confidence:** Joint alignment via singular value maximization is reasonable extension of PMRL, but optimal objective for multimodal alignment remains underexplored

## Next Checks

1. **Distributional Validation:** Conduct empirical analysis comparing empirical distribution of cross-modal embeddings against assumed Gaussian model using Q-Q plots or KL divergence metrics

2. **Spectral Robustness Analysis:** Systematically vary spectral gap by adding correlated noise or reducing modality diversity, measuring how anchor shift mitigation degrades and identifying operational boundaries

3. **Ablation with Non-Linear Generators:** Replace analytical imputation with small MLP trained via gradient descent while keeping all other components identical, comparing both imputation quality (MSE) and downstream retrieval performance