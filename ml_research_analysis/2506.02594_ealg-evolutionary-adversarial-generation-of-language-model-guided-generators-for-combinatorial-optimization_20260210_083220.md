---
ver: rpa2
title: 'EALG: Evolutionary Adversarial Generation of Language Model-Guided Generators
  for Combinatorial Optimization'
arxiv_id: '2506.02594'
source_url: https://arxiv.org/abs/2506.02594
tags:
- instances
- instance
- optimization
- problem
- solver
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces EALG, a framework that co-evolves combinatorial
  optimization problem instances and their solvers using large language models (LLMs)
  through a symbolic adversarial process. Unlike existing approaches that focus solely
  on static benchmark creation or manual solver design, EALG enables fully automated
  generation of increasingly challenging problem instances while simultaneously synthesizing
  adaptive heuristic algorithms.
---

# EALG: Evolutionary Adversarial Generation of Language Model-Guided Generators for Combinatorial Optimization

## Quick Facts
- **arXiv ID**: 2506.02594
- **Source URL**: https://arxiv.org/abs/2506.02594
- **Authors**: Ruibo Duan; Yuxin Liu; Xinyao Dong; Chenglin Fan
- **Reference count**: 40
- **Primary result**: Introduces EALG framework that co-evolves problem instances and solvers using LLMs through symbolic adversarial process, achieving 9%+ performance gaps and state-of-the-art results on TSPLIB benchmarks

## Executive Summary
This paper introduces EALG, a framework that co-evolves combinatorial optimization problem instances and their solvers using large language models (LLMs) through a symbolic adversarial process. Unlike existing approaches that focus solely on static benchmark creation or manual solver design, EALG enables fully automated generation of increasingly challenging problem instances while simultaneously synthesizing adaptive heuristic algorithms. The framework employs a mutation-based adversarial mechanism where instance generators evolve to produce harder problems and solvers co-adapt to these challenges through iterative interaction with LLMs.

Experimental results demonstrate that EALG generates significantly harder instances than current benchmarks, with solver performance gaps exceeding 9% on standard solvers when evaluated on EALG-generated instances. The co-evolved solvers achieve state-of-the-art performance, outperforming leading LLM-based approaches like FunSearch and ReEvo on both synthetic hard instances and classical TSPLIB benchmarks. This work establishes a new paradigm for combinatorial optimization that integrates instance generation with solver design through adversarial co-evolution.

## Method Summary
EALG operates through a two-population evolutionary system: instance generators and solvers evolve in tandem through adversarial interactions. The framework begins with an initial population of TSP instance generators and heuristic solvers, each guided by LLMs for generation and evaluation. In each generation, instance generators produce candidate problems that are evaluated for hardness based on solver performance. The most challenging instances are selected and used to drive solver evolution, while instance generators themselves mutate and recombine to create increasingly difficult problems. This symbolic adversarial process continues iteratively, with both populations improving through competition. The LLM integration enables automated reasoning about problem structure and heuristic design, eliminating the need for manual intervention in either instance generation or solver creation.

## Key Results
- EALG generates significantly harder instances than current benchmarks, with solver performance gaps exceeding 9% on standard solvers when evaluated on EALG-generated instances
- Co-evolved solvers achieve state-of-the-art performance, outperforming leading LLM-based approaches like FunSearch and ReEvo on both synthetic hard instances and classical TSPLIB benchmarks
- The framework establishes a new paradigm for combinatorial optimization by integrating instance generation with solver design through adversarial co-evolution

## Why This Works (Mechanism)
The framework succeeds through its closed-loop adversarial co-evolution system. By having instance generators and solvers compete directly, each population is continuously pushed to improve. The LLM component provides the reasoning capability needed to understand problem structure and design effective heuristics, while the evolutionary mechanism ensures systematic exploration of the design space. The symbolic nature of the mutations allows for meaningful variations that maintain problem validity while increasing difficulty. This creates a dynamic where instance generators learn to exploit weaknesses in current solvers, and solvers simultaneously adapt to overcome these challenges.

## Foundational Learning

**Evolutionary Algorithms**: Population-based optimization methods that iteratively improve candidate solutions through selection, mutation, and recombination. Needed to provide the framework for simultaneous improvement of both problem generators and solvers. Quick check: Can you explain how selection pressure drives improvement in both populations?

**Adversarial Learning**: A training paradigm where two systems compete against each other, with one trying to generate harder instances while the other tries to solve them. Needed to create the co-evolutionary dynamic that drives both populations to improve. Quick check: What happens to the difficulty progression if one population advances faster than the other?

**Large Language Models for Code Generation**: Using LLMs to generate and reason about algorithmic code and problem specifications. Needed to automate the generation of both problem instances and heuristic solvers without manual intervention. Quick check: How does the LLM handle maintaining problem validity during mutations?

## Architecture Onboarding

**Component Map**: Instance Generators -> Problem Evaluator -> Solver Population -> Solver Evaluator -> Instance Generator Mutation/Reproduction

**Critical Path**: Instance generators produce problems → problems evaluated for hardness → hardest instances used to train/evaluate solvers → solver performance feedback drives next generation of instance generators → cycle repeats

**Design Tradeoffs**: The framework trades computational efficiency for automation and adaptability. While generating problems and solvers through LLMs is computationally expensive, it eliminates the need for manual benchmark design and solver engineering. The symbolic mutation approach maintains problem validity but may limit the diversity of variations compared to more aggressive search strategies.

**Failure Signatures**: Performance plateaus when either population becomes too specialized and cannot adapt to the other's improvements. Framework may fail to generate meaningful diversity if mutation operators are too conservative or too aggressive. LLM integration can fail if the model cannot reason effectively about the specific problem structure or heuristic requirements.

**First Experiments**: 
1. Run baseline evolutionary algorithm without adversarial component to measure improvement from co-evolution
2. Test with different LLM models to assess dependency on specific model capabilities
3. Evaluate on non-TSP combinatorial problems to test framework generalizability

## Open Questions the Paper Calls Out
None

## Limitations
- The framework's reliance on LLM capabilities introduces potential brittleness - performance may degrade with different LLM models or versions
- The mutation-based adversarial mechanism may not scale efficiently to more complex combinatorial optimization domains where problem structure is less amenable to symbolic manipulation
- Experimental validation is strong on synthetic hard instances and established benchmarks but may not generalize to all combinatorial optimization problems

## Confidence

**High Confidence**: The core evolutionary adversarial framework design and its demonstrated ability to generate harder problem instances than existing benchmarks

**Medium Confidence**: Claims about solver performance improvements relative to FunSearch and ReEvo, given that these comparisons depend on specific implementation details and parameter settings

**Low Confidence**: The assertion that EALG establishes a "new paradigm" for combinatorial optimization, as this requires broader adoption and validation across diverse problem classes beyond the presented TSP experiments

## Next Checks
1. Test framework robustness across multiple LLM versions and models (GPT-4, Claude, Llama) to assess dependency on specific LLM capabilities
2. Extend experiments to non-TSP combinatorial problems (e.g., scheduling, knapsack) to evaluate framework generalizability
3. Conduct ablation studies removing the adversarial component to quantify its specific contribution to performance gains versus baseline evolutionary approaches