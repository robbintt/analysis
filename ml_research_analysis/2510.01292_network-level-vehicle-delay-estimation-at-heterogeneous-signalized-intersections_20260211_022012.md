---
ver: rpa2
title: Network-Level Vehicle Delay Estimation at Heterogeneous Signalized Intersections
arxiv_id: '2510.01292'
source_url: https://arxiv.org/abs/2510.01292
tags:
- data
- delay
- domain
- vehicle
- traffic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a domain adaptation framework for estimating
  vehicle delay at heterogeneous signalized intersections. The proposed Gradient Boosting
  with Balanced Weighting (GBBW) model adapts knowledge from source intersections
  to target ones by reweighting training data based on similarity.
---

# Network-Level Vehicle Delay Estimation at Heterogeneous Signalized Intersections

## Quick Facts
- arXiv ID: 2510.01292
- Source URL: https://arxiv.org/abs/2510.01292
- Reference count: 18
- Primary result: GBBW model outperforms eight ML regression models and seven DA methods for vehicle delay estimation at 57 heterogeneous intersections.

## Executive Summary
This study introduces a domain adaptation framework for estimating vehicle delay at heterogeneous signalized intersections. The proposed Gradient Boosting with Balanced Weighting (GBBW) model adapts knowledge from source intersections to target ones by reweighting training data based on similarity. Evaluated on 57 intersections in Pima County, Arizona, GBBW outperformed eight state-of-the-art ML regression models and seven instance-based DA methods. For left-turn movements, GBBW achieved MAPE of 10.54%, MAE of 5.37, and RMSE of 7.47; for through movements, MAPE was 12.63%, MAE 2.40, and RMSE 3.30. The framework demonstrates improved accuracy and robustness, enabling scalable and cost-effective traffic signal optimization across diverse intersection conditions.

## Method Summary
The GBBW framework uses domain adaptation to transfer delay estimation knowledge from 56 source intersections to a target intersection. It processes event-based traffic data (occupancy time, waiting time, detection counts, signal status) into structured features and employs a gradient boosting regressor with balanced weighting. The model uses a small labeled subset (72 samples for left-turn, 96 for through) from the target domain for fine-tuning, combined with the full source domain data. The approach employs leave-one-intersection-out cross-validation across 57 intersections and grid search hyperparameter optimization.

## Key Results
- GBBW achieved MAPE of 10.54%, MAE of 5.37, and RMSE of 7.47 for left-turn movements
- GBBW achieved MAPE of 12.63%, MAE of 2.40, and RMSE of 3.30 for through movements
- GBBW outperformed eight ML regression models and seven instance-based DA methods

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The Gradient Boosting with Balanced Weighting (GBBW) model improves generalization across heterogeneous intersections by dynamically balancing the influence of source and target data during loss minimization.
- **Mechanism:** GBBW extends standard gradient boosting by introducing a weighting parameter, $\alpha$. During initialization and residual calculation phases, the loss function aggregates errors from both source domain and small labeled target subset. By weighting target subset (via $\alpha$) against source data ($1-\alpha$), the algorithm iteratively adjusts pseudo-residuals to prioritize patterns relevant to target intersection.
- **Core assumption:** Small labeled subset from target domain is representative of target's broader traffic patterns, and sufficient feature overlap exists between source and target domains for reweighting to be effective.
- **Evidence anchors:** [section] Page 8, Algorithm 1 details initialization $F_0(x)$ and pseudo-residual computation $r_{im}$ and $r_{jm}$ weighted by $\alpha$. [abstract] "A novel DA model... reweights source data based on similarity to target domain."
- **Break condition:** If target subset contains outlier data (e.g., holiday or incident day), weighting mechanism will bias model toward these anomalous patterns, degrading accuracy.

### Mechanism 2
- **Claim:** Converting raw detector events into signal-state-conditioned features provides model with causal proxies for queue accumulation and discharge.
- **Mechanism:** Instead of using raw timestamps, framework extracts "Occupancy time" and "Waiting time" specifically categorized by signal state transitions: "Red-to-Green," "Red-to-Red," and "Green-to-Green." This categorization isolates specific delay mechanisms—e.g., "Red-to-Red" indicates vehicle arriving and stopping, whereas "Green-to-Green" indicates free flow.
- **Core assumption:** Accuracy of "Waiting time" (time from detector trigger to green onset) is valid proxy for control delay, and detectors function correctly to capture these state transitions.
- **Evidence anchors:** [section] Page 10-11, "Input Variables" defines categorization based on signal status when detector is activated/deactivated. [abstract] "...extracts key traffic features... converting raw data into structured variables."
- **Break condition:** If detector timing is misconfigured (e.g., "presence detectors" extending detection beyond vehicle's actual presence), "Occupancy time" will be inflated, leading to overestimation of delay.

### Mechanism 3
- **Claim:** Domain Adaptation framework achieves data efficiency by requiring only small, labeled fine-tuning set from target domain to calibrate model trained on abundant source data.
- **Mechanism:** Framework separates data into source ($D_S$) and target ($D_T$) domains. Uses large dataset from source (56 intersections) to learn general relationship between traffic features and delay. Then uses minimal dataset from target (72-96 samples) not just for validation, but as integral part of training process (fine-tuning).
- **Core assumption:** Underlying physical relationship between traffic flow features and delay is consistent enough across intersections that knowledge transfer is possible, provided distribution shifts are corrected via fine-tuning.
- **Evidence anchors:** [section] Page 12, "For domain adaptation models... 72 samples... were used for left-turn... 96 samples... for through movement." [abstract] "...fine-tunes model using small, labeled subset from target domain."
- **Break condition:** If target intersection has unique geometric configuration (e.g., displaced left turn) not present in source domain, "knowledge" to be transferred does not exist, and fine-tuning will fail.

## Foundational Learning

- **Concept:** **Instance-Based Domain Adaptation**
  - **Why needed here:** Core innovation (GBBW) is instance-based method. Unlike feature-based adaptation which transforms data space, this method keeps space but changes importance of data points. Model "votes" more heavily on source points that look like target points.
  - **Quick check question:** If source intersection has 3 lanes and target has 2, would instance-based reweighting method up-weight or down-weight data from 3-lane intersection? (Answer: Likely down-weight, unless volume/delay patterns are surprisingly similar despite geometric difference).

- **Concept:** **Gradient Boosting (Boosting Ensemble)**
  - **Why needed here:** GBBW is built on Gradient Boosting. Must understand that boosting sequentially adds "weak learners" (decision trees) to correct residuals (errors) of previous trees. Modification here is how those residuals are calculated using combined source/target weights.
  - **Quick check question:** In standard Gradient Boosting, what does next tree in sequence attempt to predict? (Answer: Negative gradient/residuals of loss function from previous ensemble).

- **Concept:** **Simple Stop Delay vs. Control Delay**
  - **Why needed here:** Paper explicitly notes it uses Miovision "simple stop delay" (time from detection during red to green onset) rather than more comprehensive "control delay" (which includes deceleration and acceleration time). Distinction is critical for interpreting MAE/RMSE values.
  - **Quick check question:** Will "simple stop delay" typically be lower or higher than "control delay" for same vehicle? (Answer: Lower, as it omits deceleration and acceleration components of total stopped experience).

## Architecture Onboarding

- **Component map:**
  - Data Layer: High-resolution event logs (Miovision/MaxView) → Preprocessor (Signal State logic: R-to-G, R-to-R) → Feature Matrix (Occupancy, Waiting Time, Lanes)
  - Model Layer: GBBW Core (Gradient Boosting Regressor wrapper) → Weighting Engine (Calculates α and combines Source/Target residuals)
  - Evaluation Layer: 57-fold Iterative Validator (Leave-One-Intersection-Out)

- **Critical path:**
  1. **Feature Extraction:** Accurate mapping of raw detector timestamps to "Red-to-Green" categories is single point of failure for data quality
  2. **Subset Selection:** Selecting 72/96 samples for fine-tuning ($D_{T-S}$). If subset is not random (e.g., only peak hours), model will overfit to specific condition
  3. **Hyperparameter Tuning:** Setting α ratio and learning rate

- **Design tradeoffs:**
  - **Accuracy vs. Data Cost:** Ablation study (Fig 6) shows MAPE stabilizes at ~72 samples for left-turns. Trade off slightly higher error for significantly reduced data collection requirements (3 days vs 2 weeks)
  - **Model Complexity:** GBBW is computationally heavier than standard XGBoost due to reweighting logic on every boosting iteration, but lighter than deep learning approaches requiring massive datasets

- **Failure signatures:**
  - **High Through-Movement MAPE (>20%):** Likely indicates 96-sample fine-tuning set missed specific recurring congestion pattern or "Green-to-Green" events are dominating and diluting delay signal
  - **Left-Turn Instability:** If MAPE varies wildly across intersections (large IQR in box plots), check consistency of left-turn detector placement (short loops vs long loops) across network

- **First 3 experiments:**
  1. **Data Validation:** Aggregate raw event logs for 3 sample intersections. Verify that "Waiting Time" calculations correlate with manual observation of red-phase duration before running any ML models
  2. **Baseline Comparison (Static):** Train standard XGBoost model on 56 intersections and test on 57th without fine-tuning. Record MAPE drop to establish "transfer penalty"
  3. **Sensitivity Analysis (α):** Implement GBBW and vary α parameter (e.g., 0.1 to 0.9) on single target intersection to find optimal balance between source knowledge retention and target specificity

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** To what extent does inclusion of external factors—such as weather conditions, special events, and traffic incidents—improve generalization capability of GBBW framework?
- **Basis in paper:** [explicit] Conclusion states, "Incorporating external influences such as weather conditions, special events, and traffic incidents may further strengthen model's generalization capability."
- **Why unresolved:** Current study utilized only event-based traffic data, signal timing, and geometric features, excluding environmental and situational variables.
- **What evidence would resolve it:** Comparative analysis of GBBW performance on same intersections with and without feature engineering for weather and event data.

### Open Question 2
- **Question:** Can more advanced machine learning architectures (e.g., deep learning) further enhance estimation accuracy and robustness compared to proposed Gradient Boosting approach?
- **Basis in paper:** [explicit] Authors note, "Subsequent studies may consider integrating more advanced machine learning techniques and refined input features to further improve estimation accuracy and robustness."
- **Why unresolved:** Study limited comparative baseline to traditional ML regressors and instance-based DA methods, excluding deep learning or hybrid models.
- **What evidence would resolve it:** Benchmarking GBBW against deep domain adaptation networks (e.g., CNNs or GNNs) using same Pima County dataset.

### Open Question 3
- **Question:** Does framework maintain high accuracy when applied to estimating control delay, as opposed to simple stop delay metric used in this study?
- **Basis in paper:** [inferred] Authors explicitly note in Data Description that target variable was "simple stop delay rather than control delay," which defines specific limitation on type of congestion metric modeled.
- **Why unresolved:** Control delay (standard in traffic engineering) includes deceleration and queue movement time, which "simple stop delay" excludes; model performance on broader metric is untested.
- **What evidence would resolve it:** Validation of GBBW model against ground-truth control delay data collected via floating car runs or video analysis.

## Limitations
- Exact α value and number of iterations M used in experiments are not reported, limiting reproducibility
- Specific base learner configuration (tree depth, learning rate, regularization) for gradient boosting is unspecified
- Feature engineering details for converting raw detector events into structured variables are not fully specified

## Confidence
- **High Confidence:** Overall framework design (domain adaptation via instance weighting) and general trend of improved accuracy over baselines are well-supported by leave-one-intersection-out evaluation methodology
- **Medium Confidence:** Specific MAPE, MAE, and RMSE values are credible given rigorous cross-validation, but exact hyperparameter settings (particularly α) are missing
- **Low Confidence:** Precise feature extraction formulas from raw detector timestamps are not fully specified, creating potential point of divergence in reproduction

## Next Checks
1. **Data Quality Verification:** Aggregate raw event logs for 3 sample intersections. Verify that "Waiting Time" calculations correlate with manual observation of red-phase duration before running any ML models
2. **Baseline Establishment:** Train standard XGBoost model on 56 intersections and test on 57th without fine-tuning. Record MAPE drop to establish "transfer penalty" baseline for comparison
3. **Hyperparameter Sensitivity:** Implement GBBW and vary α parameter (e.g., 0.1 to 0.9) on single target intersection to find optimal balance between source knowledge retention and target specificity, as optimal value is not reported