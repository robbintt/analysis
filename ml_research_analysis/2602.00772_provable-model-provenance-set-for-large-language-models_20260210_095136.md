---
ver: rpa2
title: Provable Model Provenance Set for Large Language Models
arxiv_id: '2602.00772'
source_url: https://arxiv.org/abs/2602.00772
tags:
- provenance
- size
- coverage
- candidate
- 'true'
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a formal framework for model provenance analysis
  with provable statistical guarantees. The core method, Model Provenance Set (MPS),
  uses a sequential hypothesis-testing procedure to identify all models related to
  a target model within a candidate pool.
---

# Provable Model Provenance Set for Large Language Models

## Quick Facts
- arXiv ID: 2602.00772
- Source URL: https://arxiv.org/abs/2602.00772
- Reference count: 40
- Primary result: Formal framework for model provenance analysis with provable statistical guarantees

## Executive Summary
This paper introduces the Model Provenance Set (MPS) framework, which provides provable statistical guarantees for identifying all models related to a target LLM within a candidate pool. MPS uses a sequential hypothesis-testing procedure that iteratively excludes the most similar candidate until no statistically significant matches remain. Experiments on a real-world benchmark of 455 LLMs demonstrate that MPS consistently identifies true provenance models while excluding unrelated ones, achieving 96% coverage with an average predicted set size of 2.1 when two true sources exist among 50 candidates. The method maintains statistical validity across significance levels and provides rigorous significance metrics for practical IP protection and auditing applications.

## Method Summary
MPS is a sequential test-and-exclusion procedure that identifies model provenance with provable coverage guarantees. It computes a distance matrix between the target model and all candidates, then iteratively tests whether candidates are statistically distinguishable from the ensemble. When the null hypothesis of no relationship is rejected (p ≤ α), the most similar candidate (lowest t-statistic) is excluded and added to the provenance set. The procedure terminates when remaining candidates are indistinguishable (p > α), returning the excluded set. Two distance functions are evaluated: Token-MPS using next-token matching and Semantic-MPS using embedding cosine similarity. The framework provides asymptotic coverage guarantees under regularity conditions and requires modest computational overhead through permutation testing.

## Key Results
- MPS achieves 96% coverage with average set size of 2.1 for TAM=2 case (2 true sources among 50 candidates)
- Coverage consistently exceeds 1-α bound across candidate pool sizes and derivation depths
- Token-MPS outperforms existing baselines on shallow derivations; Semantic-MPS provides superior robustness for deep lineages
- Default parameters (α=0.05, R=1000, N=100k) provide optimal balance of accuracy and efficiency

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Iterative exclusion with permutation testing identifies all true provenance models with provable coverage.
- Mechanism: MPS tests whether candidate models are statistically distinguishable from the ensemble in their distance to the target. When the null hypothesis is rejected (p ≤ α), the most similar candidate (lowest t-statistic) is excluded and added to the provenance set. The procedure terminates when remaining candidates are indistinguishable (p > α), returning the excluded set.
- Core assumption: Under the null hypothesis, distance scores are exchangeable across candidate models; provenance models have systematically lower distances that survive permutation shuffling.
- Evidence anchors:
  - [abstract]: "MPS iteratively excludes the most similar candidate until no further statistically significant matches remain"
  - [section 3.3, Algorithm 1]: Sequential test-and-exclusion procedure with permutation-based p-values
  - [corpus]: Weak direct connection—conformal prediction papers (Aggregating Conformal Prediction Sets) share set-valued inference concepts but not provenance-specific mechanisms
- Break condition: Exchangeability assumption may fail if unrelated models share systematic behavioral similarities (e.g., same model family without direct derivation).

### Mechanism 2
- Claim: Studentized relative-distance statistics enable detection of anomalously similar models without absolute thresholds.
- Mechanism: Computes t-statistics from relative deviation of each candidate's distance to the target versus the ensemble average. The Tmin statistic (minimum t-value across candidates) identifies the most similar model. Permutation testing determines if this minimum is smaller than expected by chance.
- Core assumption: True provenance models exhibit distances significantly below the ensemble mean; unrelated models cluster around the mean with exchangeable variation.
- Evidence anchors:
  - [section 3.1]: Equations (3-6) define relative deviation and Tmin statistic
  - [section 4.2]: Figure 2 shows coverage consistently above 1-α bound across candidate pool sizes
  - [corpus]: No direct precedent for relative-distance provenance testing found
- Break condition: If all candidates share a common ancestor not in the pool, their distances may become exchangeable even with hidden provenance.

### Mechanism 3
- Claim: Asymptotic coverage guarantee ensures all true sources are captured with user-specified confidence.
- Mechanism: Under regularity conditions (independent prompts, finite moments, positive variance), the permutation p-value is asymptotically valid (Theorem 3.1), and Algorithm 1 produces a set satisfying Pr(M* ⊆ M̂) ≥ 1-α (Theorem 3.2). With a detectable gap δ between provenance and non-provenance distances, exact recovery occurs with exponential convergence (Theorem 3.3).
- Core assumption: Gap condition holds—max distance of true provenance < min distance of unrelated models by margin δ; sample size N sufficient for gap detection.
- Evidence anchors:
  - [section 3.3]: Theorems 3.1-3.3 with proofs in Appendix C
  - [section 4.2]: Empirical coverage (96% at α=0.05) validates theoretical bound (95%)
  - [corpus]: Online Conformal Model Selection paper shows analogous asymptotic validity in different domain
- Break condition: Deep derivation chains may attenuate the gap (Appendix F.2 notes signal decay with lineage depth), potentially requiring larger N for detection.

## Foundational Learning

- Concept: Permutation hypothesis testing
  - Why needed here: Core inference mechanism—determines whether observed similarity is statistically significant by comparing to null distribution generated through label shuffling
  - Quick check question: Given 100 permutation samples, how do you compute the p-value for observed Tmin?

- Concept: Family-wise error rate and coverage guarantees
  - Why needed here: Ensures the provenance set controls false negatives (missing true sources) at level α across multiple candidate tests
  - Quick check question: If α=0.05 and you run independent tests on 50 candidates, why does sequential exclusion maintain coverage while pairwise testing would inflate false positives?

- Concept: Studentized test statistics
  - Why needed here: Normalizes relative distances to enable comparison across candidates with different variance structures
  - Quick check question: Why use the standard error in the denominator rather than raw mean differences?

## Architecture Onboarding

- Component map:
  - Distance matrix L (N × |M|): Stores sample-wise dissimilarity between target g and each candidate fi
  - Permutation engine: Generates R shuffles of distance vectors to build null distribution
  - t-statistic calculator: Computes studentized relative deviations per candidate
  - Exclusion controller: Manages iterative candidate removal until p > α
  - Provenance set accumulator: Collects excluded models as final output

- Critical path:
  1. Generate prompts (N ~ 15k-100k based on Figure 5)
  2. Query target + candidates for identifiers (tokens or embeddings)
  3. Compute distance matrix L
  4. Loop: calculate t-statistics → permute → compute p-value → exclude if p ≤ α
  5. Return accumulated provenance set

- Design tradeoffs:
  - Token-MPS vs Semantic-MPS: Token-level faster but drifts in deep lineages; semantic more robust for TAM≥2 (Figure 13)
  - R (permutation count): Stabilizes at R≥100 (Figure 4); higher R increases cost linearly
  - N (prompts): More prompts improve gap detection; minimum ~15k for TAM=1, ~70k for TAM=2 (Figure 5)

- Failure signatures:
  - Empty set for known provenance: Check if gap δ is too small (increase N) or distance function inappropriate for lineage depth
  - Overly large sets: May indicate distractor models from same family; consider stricter α or different fingerprint
  - Coverage below 1-α: Verify permutation exchangeability assumption; check for systematic biases in distance computation

- First 3 experiments:
  1. **Validation run on benchmark subset**: Take 10 derivation chains from Table 1 with known TAM, run MPS with α=0.05, R=1000, N=100k. Verify coverage ≥0.95 and set size matches TAM.
  2. **Ablation on distance functions**: Compare Token-MPS vs Semantic-MPS on TAM=2 chains. Confirm semantic advantage for deep lineages per Figure 13 distributions.
  3. **Scalability test**: Fix TAM=1, vary |M| from 5 to 100. Plot coverage and set size; verify stable coverage and compact sets per Figure 2 pattern.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the MPS framework be robustified against "same-family distractors" that mimic true source signals in large candidate pools with shallow lineages?
- Basis in paper: [explicit] Section 4.2 notes that in direct derivations (TAM $\in \{0,1\}$), a larger pool increases the risk of encountering distractors (e.g., same-family models) that mimic true sources, leading to accidental misses or redundant selections.
- Why unresolved: The current sequential test-and-exclusion procedure relies on distinguishing the "most similar" model, which becomes unstable when distractors exhibit similarity signatures comparable to the true provenance.
- What evidence would resolve it: Demonstrating a modified test statistic or exclusion criterion that maintains high coverage and compact set sizes even when the candidate pool is intentionally seeded with high-similarity distractors from the same model family.

### Open Question 2
- Question: Can new distance metrics be designed to preserve provenance signals across varying derivation depths where token-level features significantly drift?
- Basis in paper: [explicit] Appendix F.2 analyzes performance shifts, noting that "token-level features drift due to repeated fine-tuning, while semantic signals are better preserved." The authors explicitly state this "motivates the development of robust scoring functions that can better capture underlying lineage continuity."
- Why unresolved: The current implementation relies on standard Token or Semantic distances, which show inverse performance trends across shallow vs. deep lineages (TAM=1 vs. TAM=2), indicating no single metric is universally optimal.
- What evidence would resolve it: The proposal of an adaptive or hybrid distance function that maintains consistent separability (a significant gap $\delta$) between true sources and unrelated models regardless of lineage depth.

### Open Question 3
- Question: Does the sequential exclusion method effectively identify provenance in model merging scenarios where a target inherits weights from multiple parents simultaneously?
- Basis in paper: [inferred] Definition 2.1 restricts the scope to "lighter customizations" and the experiments focus on sequential derivation chains. However, the Introduction identifies "merging" as a complex topology that prior heuristics overlook, and Theorem 3.3 relies on a detectable gap $\delta$ which may not exist if a model is an even blend of parents.
- Why unresolved: The algorithm iteratively excludes the *most* similar model; in a merge of equal parents, the "gap" between the target and its multiple true sources might be statistically indistinguishable, potentially causing the procedure to halt prematurely or fail to capture the full provenance set.
- What evidence would resolve it: Empirical evaluation of MPS on a benchmark of merged models (e.g., linear combinations of weights) to verify if the coverage guarantee holds when the assumption of a distinct distance gap is violated.

## Limitations

- Exchangeability assumption may fail when unrelated models share common architectural features or training corpora
- Deep derivation chains (TAM≥3) require substantially larger prompt sets (>100k) due to signal attenuation
- Benchmark relies on LLMs from a single repository with explicit lineage annotations, limiting generalizability

## Confidence

**High Confidence Claims:**
- Sequential hypothesis-testing procedure with permutation p-values produces sets with asymptotic coverage ≥1-α
- MPS outperforms empirical baselines on model attribution tasks with better precision-recall tradeoffs
- Token-MPS is computationally efficient for shallow derivations while Semantic-MPS provides superior robustness for deep lineages
- Coverage remains stable across varying candidate pool sizes and derivation depths with appropriate prompt counts

**Medium Confidence Claims:**
- Exponential convergence to exact recovery occurs with sufficient sample size when gap δ exists
- Default parameters provide optimal balance of accuracy and efficiency
- Method generalizes beyond tested model families and size ranges

## Next Checks

1. **Exchangeability stress test**: Construct test scenarios with candidate pools containing multiple models from the same family but without direct derivation relationships. Measure false exclusion rates to quantify how often shared architectural features violate permutation exchangeability assumptions.

2. **Cross-dataset provenance transfer**: Apply MPS to models trained on different datasets than those used for prompt generation. Evaluate whether coverage guarantees hold when the behavioral fingerprint domains differ from training data distributions.

3. **Real-world unauthorized derivation detection**: Partner with model developers to obtain pairs of models where unauthorized derivation is suspected but not confirmed. Apply MPS with legal-admissible confidence levels (α=0.01) to assess practical utility for IP protection in realistic scenarios with incomplete lineage information.