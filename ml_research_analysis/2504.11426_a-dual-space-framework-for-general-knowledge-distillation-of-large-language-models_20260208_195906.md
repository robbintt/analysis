---
ver: rpa2
title: A Dual-Space Framework for General Knowledge Distillation of Large Language
  Models
arxiv_id: '2504.11426'
source_url: https://arxiv.org/abs/2504.11426
tags:
- teacher
- student
- dskd
- framework
- different
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes dual-space knowledge distillation (DSKD),
  a general white-box KD framework that addresses two limitations of current methods:
  low similarity between student and teacher models, and dependency on shared vocabulary.
  The core idea is to unify output spaces by projecting hidden states and sharing
  prediction heads.'
---

# A Dual-Space Framework for General Knowledge Distillation of Large Language Models

## Quick Facts
- arXiv ID: 2504.11426
- Source URL: https://arxiv.org/abs/2504.11426
- Reference count: 40
- Primary result: Dual-Space Knowledge Distillation (DSKD) achieves up to 3.0% improvement in Rouge-L scores on instruction-following benchmarks compared to existing methods.

## Executive Summary
This paper introduces a general white-box knowledge distillation framework that addresses two fundamental limitations in current LLM distillation: the lack of similarity between student and teacher models, and dependency on shared vocabularies. The Dual-Space Knowledge Distillation (DSKD) framework unifies output spaces by projecting hidden states and sharing prediction heads between teacher and student models. The method is validated across instruction-following, mathematical reasoning, and code generation benchmarks, demonstrating significant improvements over existing distillation approaches including on-policy KD and cross-tokenizer methods.

## Method Summary
DSKD operates by projecting teacher hidden states into student representation space (and vice versa) and passing them through shared prediction heads. The framework uses pseudo-inverse initialization for projection layers to preserve logits, computes losses in both teacher and student spaces, and employs an Exact Token Alignment (ETA) algorithm for cross-tokenizer scenarios. The training objective combines ground-truth cross-entropy with dual-space KD losses, enabling effective knowledge transfer even when models use different tokenizers or have varying architectural dimensions.

## Key Results
- DSKD achieves up to 3.0% improvement in Rouge-L scores on instruction-following benchmarks
- Significant performance gains of 7.0% accuracy on mathematical reasoning tasks
- Effective cross-tokenizer distillation with >90% token alignment using ETA algorithm
- Dual-space optimization consistently outperforms single-space alternatives in ablation studies

## Why This Works (Mechanism)

### Mechanism 1: Output Space Unification via Head Sharing
The framework eliminates the output space gap inherent in standard KD by projecting hidden states and using the same prediction head for both teacher and student distributions. This ensures both distributions originate from the exact same weight matrix, allowing the divergence loss to reach its theoretical minimum. The core assumption is that projection error is less detrimental than the fundamental mismatch of comparing two different output spaces.

### Mechanism 2: Logit-Preserving Projector Initialization
Projectors are initialized using the pseudo-inverse of the student's head and teacher's head weights ($W^{t \to s} = W^t (W^s)^+$), satisfying $H^t W^{t \to s} W^s \approx H^t W^t$. This preserves original teacher logits in the student space immediately, avoiding the noise and convergence delays of random initialization. The assumption is that vocabulary overlap provides sufficient information for meaningful initialization.

### Mechanism 3: Exact Token Alignment (ETA)
ETA traverses differently tokenized sequences to find token pairs with identical string prefixes, computing KD loss only on aligned positions. This overcomes the limitation that standard KD requires aligned token sequences. The core assumption is that >90% of tokens can be exactly matched between different tokenizers, providing sufficient supervision signal.

## Foundational Learning

- **Concept: Kullback-Leibler (KL) Divergence**
  - *Why needed here:* The paper relies on minimizing distance between probability distributions. Understanding forward vs reverse KL is necessary to interpret results.
  - *Quick check question:* Why does the paper suggest Reverse KL might yield better results for certain tasks compared to standard KL?

- **Concept: The Prediction Head (LM Head)**
  - *Why needed here:* The core contribution manipulates how hidden states map to logits via this linear layer projecting from hidden_size to vocab_size.
  - *Quick check question:* Why does having different prediction heads create "different output spaces" even with same vocabularies?

- **Concept: Moore-Penrose Pseudo-inverse**
  - *Why needed here:* Ideal projector initialization relies on this operation to approximate inverse of non-square student head matrix.
  - *Quick check question:* In Eq. (6), why can't we just use the standard inverse $W^s$ for initialization?

## Architecture Onboarding

- **Component map:** Batch Data -> Tokenize (Student & Teacher) -> Forward Pass -> Extract $H^t, H^s$ -> Initialize Projectors -> Project Hidden States -> Calculate Logits -> Align Tokens (ETA) -> Compute Dual-Space Losses -> Optimize

- **Critical path:** 1) Tokenize data for both models, 2) Forward pass both models to extract hidden states, 3) Initialize projectors using pseudo-inverse, 4) Project hidden states between spaces, 5) Calculate logits using shared heads, 6) Apply ETA for alignment, 7) Compute dual-space KD losses plus cross-entropy.

- **Design tradeoffs:** Dual-space vs single-space doubles computation but ensures gradients flow from both perspectives. Exact vs soft alignment discards unaligned tokens (information loss) but avoids fuzzy matching noise.

- **Failure signatures:** Nan loss from unstable projector initialization or high learning rates; stagnant performance from skipped initialization; length mismatch errors from ETA tokenization issues.

- **First 3 experiments:** 1) Sanity check: GPT2-Teacher → GPT2-Student with projector initialization verification, 2) Ablation: Compare student-space only vs teacher-space only vs dual-space on validation Rouge-L, 3) Cross-tokenizer test: LLaMA → Mistral with ETA alignment ratio analysis.

## Open Questions the Paper Calls Out

### Open Question 1
- *Question:* Does low-rank approximation error in projector initialization inherently limit knowledge transfer when teacher-student dimension gap is large?
- *Basis in paper:* Section III-A states initialization is a "low-rank approximation of $W^t$ with non-negligible errors."
- *Why unresolved:* Paper doesn't determine if projection matrix size creates hard information bottleneck for compressed models.
- *What evidence would resolve it:* Experiments varying student hidden dimensions to correlate approximation error magnitude with performance drops.

### Open Question 2
- *Question:* Is critical semantic information lost by excluding ~10% unaligned tokens in ETA algorithm?
- *Basis in paper:* Section III-B notes algorithm only conducts KD on aligned positions covering just over 90% of tokens.
- *Why unresolved:* Paper doesn't analyze linguistic properties of discarded tokens that may represent rare words or morphological nuances.
- *What evidence would resolve it:* Error analysis on benchmarks with high tokenizer divergence to see if failures correlate with unaligned token frequency.

### Open Question 3
- *Question:* What mechanism allows On-Policy DSKD students to occasionally surpass teacher performance?
- *Basis in paper:* Table III reports students marked with * surpassing teacher performance.
- *Why unresolved:* Paper reports phenomenon but doesn't explain why unified output spaces with on-policy sampling break typical teacher upper-bound.
- *What evidence would resolve it:* Comparative analysis of student's dual-space distribution entropy versus teacher's original distribution to identify regularization effects.

## Limitations
- Scalability concerns for extreme vocabulary differences between teacher and student models, with limited systematic analysis of alignment ratios across diverse tokenizer architectures.
- Computational overhead not fully characterized—lacks comprehensive benchmarks comparing wall-clock time and GPU memory usage against standard KD methods.
- Theoretical justification for dual-space optimization creating superior training signal remains heuristic without rigorous mathematical proof.

## Confidence
- **High Confidence:** Experimental results showing performance improvements (3.0% Rouge-L, 7.0% accuracy gains) are well-supported by ablation studies and baseline comparisons.
- **Medium Confidence:** ETA algorithm effectiveness demonstrated on specific tokenizer pairs but lacks systematic validation across diverse architectures; >90% alignment ratio appears average rather than guaranteed.
- **Low Confidence:** Theoretical justification for dual-space optimization creating better training signal than single-space remains heuristic without analytical proof.

## Next Checks
1. **Tokenizer Diversity Analysis:** Systematically evaluate ETA alignment ratios across diverse tokenizer pairs (character-level, SentencePiece, BPE, WordPiece) using standardized benchmark to document minimum, maximum, and distribution of alignment ratios.

2. **Memory and Compute Overhead Benchmarking:** Measure and compare wall-clock training time, GPU memory usage, and parameter count between standard KD, DSKD, and cross-tokenizer baselines across multiple hardware configurations (A100, H100, consumer GPUs).

3. **Low-Rank Student Head Stress Test:** Design experiments where student prediction heads have progressively lower rank (via SVD truncation) to test stability and effectiveness of pseudo-inverse initialization under numerically challenging conditions.