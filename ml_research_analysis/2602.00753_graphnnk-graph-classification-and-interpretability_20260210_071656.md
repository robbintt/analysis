---
ver: rpa2
title: GraphNNK -- Graph Classification and Interpretability
arxiv_id: '2602.00753'
source_url: https://arxiv.org/abs/2602.00753
tags:
- graph
- neighbors
- training
- classification
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates replacing parametric softmax classifiers
  in Graph Neural Networks with Non-Negative Kernel regression (NNK) to improve interpretability
  and potentially performance. The proposed GraphNNK framework trains a GIN model
  for graph embeddings, then uses NNK to perform classification by expressing predictions
  as convex combinations of nearest training neighbors in the embedding space.
---

# GraphNNK -- Graph Classification and Interpretability

## Quick Facts
- arXiv ID: 2602.00753
- Source URL: https://arxiv.org/abs/2602.00753
- Reference count: 18
- Key outcome: GraphNNK replaces softmax classifiers with Non-Negative Kernel regression for improved interpretability and competitive accuracy

## Executive Summary
This paper presents GraphNNK, a framework that replaces traditional parametric softmax classifiers in Graph Neural Networks with Non-Negative Kernel regression (NNK) for graph classification tasks. The approach trains a GIN model to generate graph embeddings, then uses NNK to perform classification by expressing predictions as convex combinations of nearest training neighbors in the embedding space. The method provides interpretable, example-based explanations where only a subset of neighbors with non-zero weights influence predictions, while achieving competitive or superior accuracy compared to traditional approaches.

## Method Summary
GraphNNK operates by first training a GIN model to produce graph embeddings, then applying Non-Negative Kernel regression for classification without requiring additional parameter training. The NNK approach expresses predictions as weighted combinations of training examples in the embedding space, where weights are determined by similarity metrics. This non-parametric inference mechanism provides example-based explanations and eliminates the need for gradient updates during inference. The framework is evaluated on the NCI1 dataset, demonstrating that NNK can outperform supervised softmax baselines when applied to well-optimized embeddings, though performance degrades with poorly optimized embeddings.

## Key Results
- NNK outperforms supervised softmax baseline on NCI1 dataset (accuracy increases from 0.7786 to 0.8273 at epoch 90)
- Performance improvements are contingent on embedding quality - poorly optimized embeddings lead to degraded NNK performance
- NNK provides interpretable explanations through convex combinations of nearest training neighbors
- No additional parameter training required for NNK inference phase

## Why This Works (Mechanism)
GraphNNK leverages the geometric structure of the embedding space by using Non-Negative Kernel regression to classify graphs based on their proximity to training examples. The method works by expressing each prediction as a weighted combination of training neighbors, where weights are determined by similarity metrics in the embedding space. This approach is effective because well-optimized embeddings capture meaningful graph similarities that can be directly leveraged for classification without the need for parametric decision boundaries. The non-parametric nature of NNK allows the model to adapt its decision boundaries based on local data structure rather than learning fixed parameters, which can be particularly beneficial when the embedding space has clear cluster structures.

## Foundational Learning
- **Graph Neural Networks (GNNs)**: Neural networks designed to operate on graph-structured data by aggregating information from neighboring nodes. Needed because graphs are fundamental data structures in many domains (social networks, molecules, etc.). Quick check: Verify that message passing and aggregation operations correctly propagate information across graph structures.

- **Graph Isomorphism Network (GIN)**: A specific GNN architecture that uses sum aggregation and MLP layers to achieve maximum discriminative power among GNNs. Needed as the embedding generator in GraphNNK. Quick check: Confirm that GIN's injective aggregation functions preserve graph structure information.

- **Non-Negative Kernel regression (NNK)**: A non-parametric classification method that expresses predictions as convex combinations of training examples weighted by similarity. Needed to provide interpretable, example-based explanations without parametric assumptions. Quick check: Validate that the kernel function properly measures similarity in the embedding space.

- **Convex combination**: A weighted sum where weights are non-negative and sum to one, ensuring predictions are interpretable mixtures of training examples. Needed to maintain interpretability and probabilistic interpretation. Quick check: Verify weight normalization and non-negativity constraints.

- **Graph embedding quality**: The extent to which learned embeddings capture meaningful structural similarities between graphs. Needed because NNK performance is highly dependent on embedding quality. Quick check: Evaluate embedding separability using visualization or clustering metrics.

## Architecture Onboarding

Component Map:
GIN embedding model -> NNK classifier -> Prediction layer

Critical Path:
1. GIN model generates embeddings for training and test graphs
2. NNK computes similarity between test embeddings and all training embeddings
3. NNK computes weighted combination of training labels based on similarity
4. Final classification prediction is output

Design Tradeoffs:
- Parametric vs non-parametric: NNK eliminates parameter training but requires storing training data
- Interpretability vs performance: NNK provides example-based explanations but may be less accurate with poor embeddings
- Computational efficiency: NNK reduces training complexity but may increase inference time for large training sets

Failure Signatures:
- Poor embedding quality leads to degraded NNK performance
- Large training sets can make NNK inference computationally expensive
- NNK may struggle with noisy or ambiguous training examples that dominate similarity calculations

First Experiments:
1. Train GIN on NCI1 and evaluate embedding quality using t-SNE visualization
2. Apply NNK to well-optimized vs poorly optimized GIN embeddings and compare accuracy
3. Analyze the distribution of non-zero weights in NNK predictions to understand which neighbors are most influential

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Evaluation limited to single NCI1 dataset, raising questions about generalization to other graph classification benchmarks
- Computational efficiency claims lack empirical validation through runtime comparisons
- Limited analysis of practical interpretability benefits beyond technical feasibility
- Unclear whether findings extend to GNN architectures beyond GIN

## Confidence
- Generalization to other datasets: Medium
- Computational efficiency claims: Low
- Interpretability benefits: Medium
- Architecture transferability: Low

## Next Checks
1. Evaluate GraphNNK on multiple graph classification datasets (MUTAG, PROTEINS, IMDB-BINARY) to assess generalization
2. Conduct runtime benchmarks comparing training and inference speeds between NNK and softmax approaches across varying dataset sizes
3. Perform user studies to empirically measure practical interpretability benefits of NNK explanations compared to attention-based or gradient-based methods