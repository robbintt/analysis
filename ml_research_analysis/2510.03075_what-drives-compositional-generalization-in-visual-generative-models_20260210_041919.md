---
ver: rpa2
title: What Drives Compositional Generalization in Visual Generative Models?
arxiv_id: '2510.03075'
source_url: https://arxiv.org/abs/2510.03075
tags:
- compositional
- generalization
- maskgit
- training
- continuous
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates what drives compositional generalization
  in visual generative models. The authors conduct controlled experiments to isolate
  the effects of different design choices: tokenizer type (VAE vs VQ-VAE), training
  objective (continuous vs discrete), and conditioning information (full vs partial).'
---

# What Drives Compositional Generalization in Visual Generative Models?

## Quick Facts
- **arXiv ID**: 2510.03075
- **Source URL**: https://arxiv.org/abs/2510.03075
- **Reference count**: 40
- **Primary result**: Continuous objectives and full conditioning are critical for compositional generalization in visual generative models.

## Executive Summary
This paper investigates the factors that drive compositional generalization in visual generative models. Through systematic ablation experiments across synthetic and natural image datasets, the authors identify that models trained with continuous distribution objectives (e.g., diffusion) and provided with complete, precise conditioning information exhibit significantly stronger compositional abilities than those using discrete categorical objectives or quantized/partial conditioning. To bridge this gap, they propose augmenting discrete generative models like MaskGIT with a JEPA-based continuous auxiliary loss, which improves compositional performance and induces more disentangled intermediate representations.

## Method Summary
The authors evaluate compositional generalization by training models on a subset of factor combinations and testing on held-out compositions. They compare DiT (continuous latent, diffusion), MaskGIT (discrete tokens, categorical NLL), MAR (continuous, masking + diffusion), and GIVT (continuous, GMM-NLL) across Shapes2D, CelebA, and CLEVRER-Kubric datasets. Conditioning fidelity is varied through full continuous, quantized, and dropout conditions. The JEPA augmentation adds a continuous predictive loss to MaskGIT using intermediate layer representations with stop-gradient and EMA targets.

## Key Results
- Continuous training objectives consistently outperform discrete categorical objectives on novel compositions
- Full, precise conditioning information is critical for compositional generalization
- JEPA augmentation significantly improves MaskGIT's compositional performance and induces more disentangled representations

## Why This Works (Mechanism)

### Mechanism 1: Continuous Distribution Objectives Enable Factor Disentanglement
- Models trained on continuous distributions create gradient flow that supports factor interpolation in latent space, whereas categorical NLL objectives collapse representations toward discrete codebook entries, encouraging memorization of seen token combinations rather than factor-level composition.

### Mechanism 2: Full-Information Conditioning Preserves Factor Binding
- Complete, precise conditioning during training is necessary for robust compositional generalization; quantized or partial conditioning leads to entangled or missing factor representations because the model must infer missing factors from data distribution statistics.

### Mechanism 3: JEPA Auxiliary Loss Induces Disentangled Intermediate Representations
- Augmenting discrete generative models with continuous JEPA-based predictive loss improves compositional performance by encouraging factor-specific circuits and reducing polysemanticity in attention heads.

## Foundational Learning

- **Compositional Generalization**: Understanding that models must recombine known factors into novel combinations, not just interpolate training examples. *Quick check*: Can you distinguish level-1 vs. level-2 novelty in a 3-factor binary composition space?

- **Continuous vs. Discrete Latent Spaces**: The primary finding hinges on whether the training objective operates over continuous or categorical distributions. *Quick check*: Explain why predicting a Gaussian mixture over continuous latents might preserve factor structure better than predicting argmax over a discrete codebook.

- **Conditioning Information Fidelity**: Incomplete or quantized conditioning is identified as a key hindrance to compositionality. *Quick check*: What failure mode occurs when concept dropout is applied during training (hint: see Figure 4d and Figure 11)?

## Architecture Onboarding

- **Component map**: Tokenizer (VAE continuous or VQ-VAE discrete) -> Generative Model (Transformer-based DiT/MaskGIT/MAR/GIVT) -> Conditioning Signal (full-precision, quantized, or partial) -> (Optional) JEPA Auxiliary Module -> Decoder to image

- **Critical path**: Encode input to latent tokens -> Apply mask or noise schedule -> Transformer processes conditioned on partial input and conditioning signal -> Predict missing tokens -> (If JEPA) Apply auxiliary continuous loss -> Decode to image

- **Design tradeoffs**: DiT: best compositionality, slower sampling; MaskGIT: fast sampling, poor compositionality; MAR/GIVT: intermediate efficiency and compositionality; JEPA augmentation: improves compositionality without changing sampling but adds training complexity

- **Failure signatures**: Categorical objective (MaskGIT) causes level-2 compositions to fail with near-zero probe accuracy; quantized + dropout conditioning causes generation of plausible but wrong factors; polysemantic attention heads attend to multiple unrelated factors; high circuit overlap indicates lack of factor-specific circuits

- **First 3 experiments**:
  1. Replicate continuous vs. discrete comparison: Train DiT and MaskGIT on Shapes2D with identical conditioning; measure level-1 and level-2 probe accuracy.
  2. Ablate conditioning fidelity: Train DiT with full continuous, quantized, dropout, and quantized+dropout conditioning; plot convergence curves per composition.
  3. Add JEPA to MaskGIT: Apply JEPA loss at layers {7, 9, 11} with lambda=0.6; compare level-2 accuracy and polysemanticity vs. baseline.

## Open Questions the Paper Calls Out

- **Open Question 1**: Does the advantage of continuous latent reasoning for compositionality scale to large language models and complex linguistic tasks? The authors note their language experiment was small-scale and limited, explicitly calling for future studies with larger models and richer tasks.

- **Open Question 2**: How can visual generative models be engineered to handle implicit or incomplete conditioning without suffering compositional failure? The paper identifies this as a failure mode but offers no architectural intervention to mitigate it.

- **Open Question 3**: What are the specific mechanisms driving the distinct training dynamics between continuous (VAE) and discrete (VQ-VAE) tokenizers? The authors observe different learning curves but leave detailed analysis for future work.

## Limitations

- The study relies on synthetic compositional tasks with clear, discrete factor structures, which may not fully generalize to real-world scenarios with continuous, entangled, or hierarchically structured factors
- The paper focuses on controlled ablation experiments without exploring interactions between factors or how conditioning fidelity affects continuous vs. discrete objectives jointly
- The JEPA augmentation requires careful hyperparameter tuning and its benefits may diminish in larger, more diverse datasets

## Confidence

- **High Confidence**: The core finding that continuous objectives consistently outperform discrete objectives on Level-2 compositional generalization is well-supported by systematic ablations across multiple datasets
- **Medium Confidence**: The claim that full-information conditioning is critical for compositional generalization is strongly supported in synthetic tasks but has only weak evidence from natural datasets
- **Low Confidence**: The JEPA augmentation's effectiveness is demonstrated primarily on Shapes2D and may not transfer to larger models or more complex datasets

## Next Checks

1. **Real-World Conditioning Fidelity**: Train DiT and MaskGIT on CelebA with varying conditioning fidelity (full continuous attributes vs. quantized/partially dropped) and measure compositional generalization on novel attribute combinations.

2. **JEPA Scalability and Alternatives**: Apply JEPA augmentation to a larger, more diverse dataset (e.g., CLEVRER-Kubric) and compare against alternative continuous losses (e.g., V-JEPA2) to evaluate whether gains persist.

3. **Factor Interaction Ablation**: Design a Shapes2D variant where factors have conditional dependencies and train models with continuous objectives and varying conditioning fidelity to isolate how factor interactions affect compositional generalization.