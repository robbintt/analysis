---
ver: rpa2
title: Efficient Spectral Control of Partially Observed Linear Dynamical Systems
arxiv_id: '2505.20943'
source_url: https://arxiv.org/abs/2505.20943
tags:
- linear
- control
- spectral
- ynat
- lemma
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes Double Spectral Control (DSC), a new algorithm
  for controlling partially observed linear dynamical systems under adversarial disturbances
  and convex loss functions. The core idea is to approximate the optimal controller
  using a two-level spectral representation: first lifting the observation history
  via spectral filters derived from Hankel matrix eigenvectors, then applying a second
  spectral filtering stage to produce the control.'
---

# Efficient Spectral Control of Partially Observed Linear Dynamical Systems

## Quick Facts
- arXiv ID: 2505.20943
- Source URL: https://arxiv.org/abs/2505.20943
- Authors: Anand Brahmbhatt; Gon Buzaglo; Sofiia Druchyna; Elad Hazan
- Reference count: 40
- Key outcome: Proposed Double Spectral Control (DSC) algorithm achieves regret bound of $\tilde{O}(\sqrt{T}/\gamma^{11})$ with polylogarithmic runtime complexity for partially observed linear dynamical systems

## Executive Summary
This paper introduces Double Spectral Control (DSC), a novel algorithm for controlling partially observed linear dynamical systems under adversarial disturbances and convex loss functions. The method leverages a two-level spectral representation that first lifts observation history through spectral filters derived from Hankel matrix eigenvectors, then applies a second spectral filtering stage to generate control actions. This approach enables efficient convex learning while maintaining sufficient expressiveness for optimal control.

The algorithm demonstrates both theoretical and empirical advantages over existing methods. Theoretically, DSC achieves improved regret bounds with runtime complexity polylogarithmic in T/γ compared to previous polynomial-time methods. Empirically, the method outperforms state-of-the-art approaches under both Gaussian and sinusoidal perturbations across various random system initializations, showing robust statistical gains.

## Method Summary
Double Spectral Control (DSC) operates by first approximating the optimal controller using a two-level spectral representation. The first level lifts the observation history via spectral filters obtained from the eigenvectors of the Hankel matrix, creating a lifted representation of the system state. The second level applies an additional spectral filtering stage to produce the final control action. This double spectral approximation enables efficient convex learning while maintaining expressiveness sufficient for optimal control. The method is specifically designed for partially observed linear dynamical systems with adversarial disturbances and convex loss functions, providing both theoretical regret guarantees and practical computational advantages.

## Key Results
- Achieves regret bound of $\tilde{O}(\sqrt{T}/\gamma^{11})$ where γ is the stability margin
- Runtime complexity improves to polylogarithmic in T/γ compared to polynomial-time methods
- Outperforms existing methods under both Gaussian and sinusoidal perturbations in empirical evaluations
- Demonstrates robust statistical gains across random system initializations

## Why This Works (Mechanism)
The double spectral approximation enables efficient convex learning by transforming the control problem into a spectral domain where the underlying structure of partially observed systems can be exploited. By using Hankel matrix eigenvectors for the first spectral lifting, the method captures the essential dynamics of the system in a compressed representation. The second spectral filtering stage then allows for efficient computation of control actions while maintaining sufficient expressiveness to approximate optimal controllers. This two-level approach effectively balances computational tractability with control performance, enabling the achievement of strong regret guarantees.

## Foundational Learning
- **Hankel matrices**: Why needed - Capture temporal correlations in time series data; Quick check - Verify eigenvalues capture system dynamics
- **Spectral filtering**: Why needed - Enables efficient representation of system dynamics; Quick check - Confirm filter stability and frequency response
- **Convex optimization**: Why needed - Allows efficient learning of control parameters; Quick check - Validate convexity of the loss landscape
- **Regret analysis**: Why needed - Quantifies performance relative to optimal controller; Quick check - Verify dependence on stability margin γ
- **Adversarial disturbances**: Why needed - Models worst-case uncertainty in system behavior; Quick check - Test robustness across different disturbance distributions

## Architecture Onboarding

**Component Map**: Observation history -> Hankel matrix spectral lifting -> First spectral filter -> Second spectral filter -> Control action -> System state

**Critical Path**: The critical computational path involves computing the spectral decomposition of the Hankel matrix, applying the first spectral filter to the observation history, then applying the second spectral filter to produce the control action. The efficiency gain comes from precomputing the spectral basis and using efficient spectral filtering operations.

**Design Tradeoffs**: The method trades off approximation accuracy for computational efficiency by truncating the spectral representation. Higher truncation levels improve control performance but increase computational cost. The stability margin γ represents a fundamental tradeoff between system responsiveness and robustness.

**Failure Signatures**: Poor performance may manifest as high regret when the stability margin γ is small (unstable systems), when the observation operator is poorly conditioned, or when disturbances fall outside the adversarial model. Computational bottlenecks may arise if spectral truncation levels are set too high or if the Hankel matrix becomes ill-conditioned.

**First Experiments**: 1) Test on a simple stable linear system with known dynamics to verify regret bounds; 2) Compare performance against model-based optimal control in fully observable case; 3) Evaluate sensitivity to spectral truncation levels across different system dimensions.

## Open Questions the Paper Calls Out
None

## Limitations
- Strong assumptions on system dynamics (linear, known observation operator, bounded disturbances) may limit real-world applicability
- Regret bound dependence on γ⁻¹¹ could become prohibitive for systems with poor stability margins
- Empirical evaluation limited to relatively small-scale systems and specific disturbance models (Gaussian and sinusoidal)
- Algorithm sensitivity to hyperparameter choices (particularly spectral truncation levels) not thoroughly explored

## Confidence

- Theoretical guarantees and regret analysis: High
- Computational complexity claims: Medium (depends on implementation details)
- Empirical performance claims: Medium (limited experimental scope)
- Practical applicability to real systems: Low

## Next Checks
1. Test DSC on systems with time-varying or unknown observation operators to assess robustness beyond current assumptions
2. Evaluate performance on higher-dimensional systems (n > 50) to verify computational advantages scale appropriately
3. Compare against model-based optimal control methods in fully observable case to establish performance baselines