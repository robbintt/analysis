---
ver: rpa2
title: 'TiTok: Transfer Token-level Knowledge via Contrastive Excess to Transplant
  LoRA'
arxiv_id: '2510.04682'
source_url: https://arxiv.org/abs/2510.04682
tags:
- data
- source
- tasks
- transfer
- synthetic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the challenge of transferring LoRA adapters\
  \ between different large language models (LLMs), which is currently difficult because\
  \ LoRA parameters are tied to their original model backbones. The proposed TiTok\
  \ framework solves this by transferring LoRA knowledge at the token level through\
  \ contrastive excess scores\u2014measuring the difference between a source model\
  \ with and without LoRA to identify the most informative tokens."
---

# TiTok: Transfer Token-level Knowledge via Contrastive Excess to Transplant LoRA

## Quick Facts
- arXiv ID: 2510.04682
- Source URL: https://arxiv.org/abs/2510.04682
- Authors: Chanjoo Jung; Jaehyung Kim
- Reference count: 34
- One-line primary result: TiTok achieves +7.96% average performance gain over vanilla models and +4.4% over TransLoRA for LoRA adapter transfer across multiple model scenarios.

## Executive Summary
TiTok addresses the challenge of transferring LoRA adapters between different LLMs by moving from parameter-level to token-level knowledge transfer. The method computes contrastive excess scores—measuring the difference between a source model with and without LoRA—to identify the most informative tokens that encode task-specific knowledge. This enables selective training on synthetic data generated by the source expert model, achieving consistent improvements across same-model, cross-family, cross-size, and cross-version transfers without requiring original training data or additional models.

## Method Summary
TiTok transfers LoRA knowledge by generating synthetic query-label pairs using a source expert model (source_base + LoRA), computing token-level excess scores as the log-probability difference between expert and base models, and applying two-stage filtering to select high-value samples and tokens. The filtered dataset is then used to train a new LoRA adapter on the target model, with optional tokenizer alignment for cross-family transfers. The approach requires only the source LoRA parameters and can work with external data, making it efficient and broadly applicable for various LoRA transfer scenarios.

## Key Results
- TiTok achieves +7.96% average performance gain over vanilla models across multiple transfer settings
- Outperforms knowledge distillation by +6.0% and TransLoRA by +4.4% in cross-family transfer experiments
- Demonstrates effectiveness across same-model, cross-family, cross-size, and cross-version transfers with average gains of +4-8%
- Maintains robust performance even when using external data from different domains

## Why This Works (Mechanism)

### Mechanism 1
Tokens where the LoRA-enhanced model assigns higher probability than the base model encode the most transferable task knowledge. The excess score S(y_i) = L_e(y_i) - L_a(y_i) measures the log-probability difference between expert (with LoRA) and amateur (base only). High-scoring tokens indicate positions where the adapter injects knowledge the backbone lacks. Training selectively on these tokens concentrates learning on LoRA-specific signal rather than backbone-agnostic content.

### Mechanism 2
Two-stage filtering (sample-level + token-level) removes noisy synthetic data while preserving high-value supervision. Stage 1 computes mean excess per sample, retaining top-M samples. Stage 2 selects top-k% tokens within retained samples. This removes low-quality synthetic examples (Stage 1) and discards uninformative tokens within good examples (Stage 2).

### Mechanism 3
Dual-pointer tokenizer alignment enables cross-family transfer by propagating token importance masks across mismatched vocabularies. When source and target models tokenize differently, the algorithm incrementally decodes and aligns text spans. Mask scores propagate via averaging (many-to-one) or replication (one-to-many). Top-k% selection then applies to aligned target tokens.

## Foundational Learning

- **Low-Rank Adaptation (LoRA)**: LoRA adapters are the transfer units. Understanding their structure (A, B matrices, rank r) explains why they're backbone-dependent and need transplantation. Quick check: Can you explain why LoRA parameters cannot be directly copied to a different model backbone?

- **Knowledge Distillation (KD) for LLMs**: TiTok is positioned as an alternative to KD for LoRA transfer. Understanding KD's data dependency helps contextualize the synthetic data approach. Quick check: Why does traditional KD require access to original training data, and how does TiTok avoid this?

- **Token-level Selective Training**: The core innovation is training only on high-excess tokens. Prior work (Rho-1, TS-PEFT) shows selective token training improves efficiency. Quick check: How does the excess score differ from simple loss-based token selection?

## Architecture Onboarding

- **Component map**:
Source Model (M_s + A_s) -> Synthetic Data Generation -> Raw Dataset D_s -> Excess Score Computation -> Token-level scores S(y_i) -> Two-Stage Filtering -> Filtered Dataset D_f -> Target Model (M_t) + New LoRA (A_t) -> Training

- **Critical path**:
1. Generate synthetic queries AND labels using source expert (not target model) — this is a key design choice (Fig. 2).
2. Compute excess scores by forward passes through source base and source+LoRA.
3. Apply sample filtering before token selection (order matters).
4. If tokenizers differ, run alignment algorithm before masking.
5. Train target LoRA only on masked tokens (Eq. 7).

- **Design tradeoffs**:
- Selection ratio k%: Low values (10-30%) help weak→strong transfer by filtering noise; high values (60-70%) help personalization tasks that benefit from broader supervision (Fig. 3).
- Query source: Source expert generates better-aligned queries than target model (Fig. 2), but requires source model access at transfer time.
- External vs. synthetic data: TiTok works on external data (Table 3), but synthetic data avoids privacy/availability issues.

- **Failure signatures**:
- Performance matches vanilla → check if excess scores are near-zero (LoRA may not have learned task-specific behavior).
- Cross-family transfer degrades → verify tokenizer alignment outputs; misaligned masks nullify selective training.
- Personalization tasks underperform → k% may be too low; try increasing to 70-90%.

- **First 3 experiments**:
1. Validate excess signal: On a single task, visualize token excess scores; verify high scores correspond to task-relevant positions (e.g., answer tokens in QA).
2. Ablate filtering stages: Replicate Table 2 settings (no filter / token-only / sample-only / both) to confirm complementary roles.
3. Test tokenizer alignment robustness: Transfer between models with different tokenizers (Mistral→Llama), comparing aligned vs. unaligned masks on a held-out validation set.

## Open Questions the Paper Calls Out

### Open Question 1
Can an adaptive mechanism be developed to automatically determine the optimal token selection ratio (k%) based on task type or source model confidence, replacing the current reliance on fixed thresholds? The authors suggest that future work could explore more adaptive or data-driven thresholding strategies, as optimal k% varies significantly across different transfer scenarios.

### Open Question 2
Can the "Contrastive Excess" framework be effectively adapted for other Parameter-Efficient Fine-Tuning (PEFT) methods (e.g., Prefix Tuning or Soft Prompts) that do not involve additive weight updates? The methodology is explicitly defined around LoRA, and it's unclear if token-level importance signals generalize to architectural changes where weights are frozen.

### Open Question 3
To what extent does TiTok propagate "negative transfer," such as hallucinations or biases, from a poorly tuned or overfitted source LoRA adapter to the target model? The method relies on the source expert for both generation and scoring, potentially reinforcing errors if the source model's "knowledge" is flawed.

### Open Question 4
How does the computational overhead of generating synthetic data and computing token-level excess scores scale when transferring between very large models (e.g., 70B+ parameters)? The experiments are limited to the 3B–8B parameter range, and it's unclear if the cost remains "efficient" compared to re-fine-tuning for frontier-scale models.

## Limitations
- The core mechanism's assumption that high-excess scores reliably identify task-relevant tokens lacks direct validation through manual annotation studies.
- Cross-family transfer tokenizer alignment effectiveness is asserted but not quantitatively validated with alignment quality metrics.
- Synthetic data generation hyperparameters (top-p values) are described as "tuned individually for each task" without providing tuning criteria or specific values.
- Comparative analysis omits recent LoRA transfer methods like MinED, leaving claims of superiority incomplete.

## Confidence

- **High confidence**: The two-stage filtering mechanism demonstrably improves performance over unfiltered baselines (Table 2). The technical implementation of excess score computation and masked loss training is clearly specified and reproducible.
- **Medium confidence**: Claims about tokenizer alignment effectiveness rely on aggregate performance improvements without ablation studies showing alignment contribution. The assertion that source-expert-generated queries outperform target-generated ones is supported by one figure but lacks statistical analysis across tasks.
- **Low confidence**: Superiority claims over TransLoRA and MinED are weak due to missing baselines. The generalization to external data (Table 3) shows improvement but doesn't explain why TiTok outperforms KD in these settings.

## Next Checks

1. **Excess score validation**: For a representative subset of tasks, manually annotate high-excess tokens and verify they correspond to task-relevant content (e.g., answer tokens in QA tasks) versus generic language tokens.

2. **Tokenizer alignment ablation**: Transfer between models with different tokenizers (Mistral→Llama) with three conditions: aligned masks, unaligned masks (random token selection), and ground-truth semantic alignment (if available) to quantify alignment contribution.

3. **Synthetic data quality analysis**: Generate query-label pairs using both source-expert and target-base models, then have human evaluators rate coherence and task-relevance. Compare the percentage of off-topic or incoherent pairs between methods.