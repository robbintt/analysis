---
ver: rpa2
title: Large Language Model Agent for Modular Task Execution in Drug Discovery
arxiv_id: '2507.02925'
source_url: https://arxiv.org/abs/2507.02925
tags:
- agentd
- drug
- molecular
- page
- molecules
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces AgentD, a modular LLM-based agent for automating
  early-stage drug discovery. By integrating language model reasoning with domain-specific
  tools, AgentD performs data retrieval, literature-grounded question answering, molecule
  generation, multi-property prediction, property-aware refinement, and 3D structure
  generation.
---

# Large Language Model Agent for Modular Task Execution in Drug Discovery

## Quick Facts
- arXiv ID: 2507.02925
- Source URL: https://arxiv.org/abs/2507.02925
- Reference count: 40
- Primary result: Modular LLM-based agent improves drug-likeness of candidate molecules, increasing QED > 0.6 from 34 to 55 over two refinement rounds

## Executive Summary
This work introduces AgentD, a modular LLM-based agent for automating early-stage drug discovery. By integrating language model reasoning with domain-specific tools, AgentD performs data retrieval, literature-grounded question answering, molecule generation, multi-property prediction, property-aware refinement, and 3D structure generation. In iterative refinement rounds, the number of molecules with QED > 0.6 increased from 34 to 55, and Ghose filter compliance rose from 32 to 55 out of 100 molecules. AgentD's modular design enables scalable, AI-assisted therapeutic development with continual adaptability as new tools emerge.

## Method Summary
AgentD is an LLM-powered agent that orchestrates a pipeline of domain-specific tools for drug discovery. The core LLM (GPT-4o, Claude-3.7-Sonnet, or DeepSeek-Chat) acts as a controller, invoking tools for data extraction (UniProt, ChEMBL, literature), SMILES generation (REINVENT, Mol2Mol), property prediction (Deep-PK, BAPULM), and 3D structure generation (Boltz-2). The refinement loop uses LLM reasoning to identify "weakness" properties and propose targeted SMILES edits. RAG via FAISS vector index improves literature-based question answering accuracy.

## Key Results
- QED > 0.6 increased from 34 to 55 molecules after two refinement rounds
- Ghose filter compliance rose from 32 to 55 out of 100 molecules
- RAG-based QA improved F1-score from 0.63 ± 0.01 to 0.70 ± 0.05 (GPT-4o)

## Why This Works (Mechanism)

### Mechanism 1
Property-aware iterative refinement improves molecular drug-likeness. The system predicts ADMET and physicochemical properties, identifies "weakness" properties, and prompts the LLM to propose targeted SMILES edits. This feedback loop improves drug-likeness metrics over iterations. Evidence: QED > 0.6 increased from 34 to 55 molecules after two refinement rounds.

### Mechanism 2
RAG improves domain-specific question-answering accuracy. AgentD retrieves open-access literature, creates a vector index, and uses this context during QA to ground LLM responses. This reduces hallucinations and improves mechanistic detail. Evidence: GPT-4o F1-score improved from 0.63 ± 0.01 to 0.70 ± 0.05 with RAG.

### Mechanism 3
Modularity enables tool substitution and workflow extensibility. AgentD is built as independent task modules orchestrated by an LLM. Each module wraps external tools via APIs or configuration files, allowing flexible integration of evolving tools and models.

## Foundational Learning

### Concept: SMILES representation and molecular validity
- Why needed here: The entire pipeline operates on SMILES strings. Understanding valid SMILES syntax is essential for debugging generation/refinement.
- Quick check: Given a SMILES string, can you identify if it represents a chemically valid molecule? Do you know how RDKit or similar libraries validate SMILES?

### Concept: ADMET properties and drug-likeness filters
- Why needed here: The refinement loop targets "weak" ADMET properties. Understanding what these properties mean biologically is crucial for interpreting results.
- Quick check: Can you explain what QED measures and how it differs from Lipinski's Rule of Five?

### Concept: LLM agent orchestration and tool use
- Why needed here: AgentD is an LLM-powered agent that calls external tools. Understanding how LLMs function as controllers is fundamental.
- Quick check: Have you worked with LLM function-calling or agent frameworks? Can you outline how an LLM decides which tool to call?

## Architecture Onboarding

### Component map:
User query -> Data Extraction (UniProt, ChEMBL, literature) -> SMILES Generation (REINVENT, Mol2Mol) -> Property Prediction (Deep-PK, BAPULM) -> Molecule Refinement (LLM proposes SMILES edits) -> (Iterate steps 3-4) -> Filtering (QED, rule-based) -> 3D Structure Generation (Boltz-2)

### Critical path:
1. User query → Data Extraction (protein, drugs, literature)
2. SMILES Generation (seed molecules)
3. Property Prediction (ADMET + affinity)
4. Molecule Refinement (LLM proposes SMILES edits based on property weaknesses)
5. (Iterate steps 3-4)
6. Filtering (QED, rule-based filters) → 3D Structure Generation (Boltz-2) for top candidates

### Design tradeoffs:
- LLM choice: GPT-4o is most robust; Claude-3.7-Sonnet has retry-loop issues; DeepSeek-Chat is cheaper but slightly less performant
- RAG depth: Current implementation is minimal. Adding filters may improve relevance but increases latency/complexity
- Refinement iterations: More iterations may improve properties but risk accumulating errors
- Property predictor reliance: Heavy dependence on Deep-PK/BAPULM accuracy; their errors propagate

### Failure signatures:
- Infinite retry loops: Observed with Claude-3.7-Sonnet in refinement
- Unintended SMILES edits: LLM modifies SMILES in ways not matching its stated intent
- Property improvement failure: Intended modifications fail to improve (or worsen) target property
- API/timeouts: Deep-PK, Boltz-2, or LLM API failures can halt the pipeline

### First 3 experiments:
1. End-to-end dry run: Pick BCL-2 target. Run full pipeline with 10 molecules. Verify each module produces expected outputs. Log all API calls and token usage.
2. Refinement loop stress test: Take 20 seed molecules and run 3 refinement iterations. Track QED, rule-compliance, and property changes per iteration.
3. RAG vs. vanilla QA benchmark: For 5 domain-specific questions, compare answers from AgentD (with RAG) vs. vanilla LLM. Score using BERTScore or human review.

## Open Questions the Paper Calls Out

### Open Question 1
Can the AgentD refinement module be upgraded to perform multi-objective optimization to simultaneously improve competing properties like permeability and toxicity? The current sequential approach fails to capture complex interdependencies between ADMET properties.

### Open Question 2
How does integration of uncertainty-aware prediction confidence from external tools affect robustness of molecular refinement decisions? The current pipeline treats tool outputs as deterministic point estimates without accounting for error profiles.

### Open Question 3
To what extent do 3D protein-ligand structures generated by Boltz-2 align with conformational stability observed in molecular dynamics simulations? While Boltz-2 provides rapid generation, the static complexes have not been validated against dynamic behavior.

## Limitations
- No specification of exact prompts used for Molecule Refinement module
- RAG implementation lacks venue/citation filtering, potentially reducing relevance
- Heavy dependence on property prediction tool accuracy (Deep-PK, BAPULM)
- Minimal error handling strategy for module failures

## Confidence

**High Confidence:** The core modular architecture and integration of domain-specific tools are well-specified and reproducible. The improvement in QED and Ghose filter compliance over two refinement rounds is clearly demonstrated.

**Medium Confidence:** The RAG-based literature retrieval and question-answering mechanism is supported by experimental results but lacks detailed implementation specifics and domain-specific validation.

**Low Confidence:** The exact prompts and reasoning strategies used by the LLM for property-aware refinement are not disclosed, making it difficult to fully assess robustness or generalizability.

## Next Checks

1. Reproduce the refinement loop: Take 20 seed molecules and run three refinement iterations, tracking QED, rule-compliance, and property changes per iteration. Compare the rate and consistency of improvement against the paper's results.

2. Validate RAG vs. vanilla QA: For 5 domain-specific questions, compare AgentD's answers (with RAG) to those from a vanilla LLM. Use BERTScore or human review to assess mechanistic completeness and hallucination rate.

3. Stress-test error handling: Simulate common failure modes (Deep-PK API timeout, invalid SMILES generation, Claude retry loops) and document how the pipeline recovers or fails. Identify any gaps in error handling or module independence.