---
ver: rpa2
title: 'EICopilot: Search and Explore Enterprise Information over Large-scale Knowledge
  Graphs with LLM-driven Agents'
arxiv_id: '2501.13746'
source_url: https://arxiv.org/abs/2501.13746
tags:
- query
- queries
- eicopilot
- graph
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: EICopilot is an LLM-driven agent system for enterprise information
  search over large-scale knowledge graphs, automating Gremlin script generation and
  improving intent recognition through a novel query masking strategy. It addresses
  the challenge of efficiently querying complex enterprise data, which traditionally
  requires manual text-based queries and subgraph exploration.
---

# EICopilot: Search and Explore Enterprise Information over Large-scale Knowledge Graphs with LLM-driven Agents

## Quick Facts
- arXiv ID: 2501.13746
- Source URL: https://arxiv.org/abs/2501.13746
- Reference count: 19
- EICopilot achieves 82.14% execution correctness with its Full Mask strategy on enterprise knowledge graphs

## Executive Summary
EICopilot addresses the challenge of querying complex enterprise knowledge graphs by automating Gremlin script generation through LLM-driven agents. The system introduces a novel query masking strategy that improves intent recognition by isolating search logic from specific entity names. By combining Chain-of-Thought reasoning, In-context Learning, and schema linking, EICopilot significantly reduces syntax error rates and improves query execution accuracy over traditional text-based query methods.

## Method Summary
EICopilot is an LLM-driven agent system that transforms natural language queries into executable Gremlin scripts for enterprise knowledge graphs. The pipeline operates through retrieval of masked query examples from a vector database, schema linking to identify relevant graph structures, LLM-based script generation with reflection-based syntax correction, and final execution on the graph database. The key innovation is the Full Entity Masking strategy that replaces specific entity names with generic masks during retrieval to prioritize intent matching over entity matching, achieving significantly higher execution correctness than baseline approaches.

## Key Results
- Full Mask strategy reduces syntax error rate to 10.00% compared to 35% for raw matching
- Execution correctness reaches 82.14% with Full Mask versus ~58% for raw matching
- System successfully handles complex multi-hop queries across enterprise knowledge graphs with 100M+ nodes

## Why This Works (Mechanism)

### Mechanism 1: Full Entity Masking for Intent-Isolated Retrieval
Replacing specific entity names with generic masks in both the user query and vector database examples significantly improves the relevance of retrieved In-Context Learning examples, thereby increasing execution correctness. By masking entities, the retrieval system compares the structural intent of the query rather than matching specific keywords, preventing the system from retrieving examples that share an entity name but have irrelevant search intents.

### Mechanism 2: Two-Stage Schema Linking for Context Optimization
Reducing the schema information passed to the LLM to only relevant tables/fields via a preliminary linking step improves Gremlin generation accuracy by minimizing context noise. Instead of saturating the prompt with the full database schema, the system first identifies relevant sub-graphs and passes only this linked schema to the LLM for reasoning and generation.

### Mechanism 3: Reflection-Based Syntax Correction
A dedicated post-generation "Reflection" module acts as a syntax and logic validator, catching errors in generated Gremlin scripts before they reach the execution engine. If an initial generation produces an anomalous result or syntax error, a secondary LLM call is triggered with specific error logs and schema details to attempt correction.

## Foundational Learning

- **Concept: Gremlin Traversal Language**
  - Why needed here: Unlike SQL or SPARQL, Gremlin is a traversal language using steps (e.g., `out()`, `in()`, `has()`). Understanding this functional flow is required to diagnose why generated scripts are syntactically correct but potentially logically flawed.
  - Quick check question: Given a graph of `Company -> Investor`, would you use `in()` or `out()` from the Company node to find the investor?

- **Concept: In-Context Learning (ICL)**
  - Why needed here: The system relies on a vector database of "representative queries" to teach the LLM how to write Gremlin "on the fly" without weight updates. The selection of these examples determines the output quality.
  - Quick check question: If a user asks a complex aggregation query, but the ICL examples retrieved are all simple lookups, how will the LLM likely fail?

- **Concept: Named Entity Recognition (NER) & Disambiguation**
  - Why needed here: Before searching the graph, the system must isolate the target (e.g., "Apple" the company vs. "Apple" the fruit). The paper explicitly uses NER and ElasticSearch for this pre-processing step.
  - Quick check question: How does the system handle a query like "Who runs Tesla?" if "Tesla" matches multiple nodes?

## Architecture Onboarding

- **Component map:** User Query -> NER/Disambiguation -> Masking -> Vector Search -> Schema Linking -> LLM (Gremlin Gen) -> Reflection -> Graph DB Execution
- **Critical path:** The retrieval accuracy of the Masked Vector Search is the highest leverage point. If the wrong Gremlin example is retrieved, subsequent reasoning steps cannot recover effectively.
- **Design tradeoffs:** Full Mask vs. Raw Match trades exact entity matching for intent matching, improving correctness (82%) but requiring robust unmasking to re-insert specific entity IDs. The system uses ICL instead of fine-tuning to handle dynamic enterprise schemas.
- **Failure signatures:** Syntactic Hallucination (valid Gremlin that returns empty results), Intent Drift (correct retrieval but wrong data type), and Schema Linking failures (missing critical tables for multi-hop queries).
- **First 3 experiments:** 1) Ablation on Masking comparing "Raw Match" vs. "Full Mask" to reproduce the ~20% delta in execution correctness. 2) Schema Stress Test removing Schema Linking to observe context saturation effects. 3) Reflection Loop analysis measuring the pass rate of the second LLM attempt after first execution failure.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How robust is the Full Mask strategy when the NER module fails to identify or incorrectly extracts entities from the user query?
- Basis in paper: The paper describes the masking strategy's reliance on NER but does not analyze error propagation if this upstream extraction fails.
- Why unresolved: If NER misses an entity, the query cannot be masked, likely degrading performance to the "Raw Match" baseline.
- What evidence would resolve it: A sensitivity analysis measuring execution correctness when synthetic NER noise or omissions are introduced.

### Open Question 2
- Question: Can the EICopilot architecture generalize to other graph query languages like Cypher or SPARQL, or is it overfitted to Gremlin syntax?
- Basis in paper: The authors explicitly focus on "the utilization of Gremlin over traditional query languages like SQL or GraphQL."
- Why unresolved: The reflection module checks for "edges, edge directions, and attributes" in a way that may be specific to the TinkerPop property graph model.
- What evidence would resolve it: Evaluation on standard benchmarks like Spider (SQL) or LC-QuAD (SPARQL) without modifying core reasoning logic.

### Open Question 3
- Question: How does the system's accuracy scale with the complexity of the schema or the size of the vector database beyond the 150-entry test set?
- Basis in paper: The empirical evaluation relies on a specific internal dataset of 150 entries without comparison to external, large-scale academic benchmarks.
- Why unresolved: It is unclear if the 82.14% execution correctness holds when the "search space" for ICL examples grows significantly larger or more diverse.
- What evidence would resolve it: Testing retrieval accuracy and execution correctness on open-source large-scale knowledge graphs with thousands of query templates.

## Limitations
- Critical implementation details including specific prompt templates for schema linking, Gremlin generation, and reflection modules are redacted, making faithful reproduction challenging
- Performance improvements heavily depend on the quality of the masking implementation, which is only conceptually described
- The Reflection module's error correction capability is claimed but not empirically validated separately

## Confidence
- **High Confidence:** The architectural framework (retrieval → schema linking → generation → reflection) is clearly described and logically sound. The empirical improvement in syntax error rate reduction from 35% to 10% is directly measurable.
- **Medium Confidence:** The "Full Mask" retrieval strategy's effectiveness is supported by ablation results, but the mechanism relies on unstated prompt engineering details and the assumption that masked examples will generalize to specific entities during generation.
- **Low Confidence:** The Reflection module's error correction capability is claimed but not empirically validated separately; we don't know how often it successfully corrects errors versus failing silently.

## Next Checks
1. **Masking Strategy Isolation Test:** Implement both "Raw Match" and "Full Mask" retrieval variants on the same test set to verify the claimed ~24% execution correctness improvement, controlling for all other variables.
2. **Schema Linking Necessity Test:** Run the generation pipeline with and without the schema linking module to quantify the impact of context reduction on syntax error rates and execution correctness.
3. **Reflection Module Effectiveness Test:** Measure the pass rate of the reflection correction loop by tracking how often the second LLM attempt succeeds after the first execution fails, separating this from the overall execution correctness metric.