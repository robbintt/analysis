---
ver: rpa2
title: Do Reasoning Models Enhance Embedding Models?
arxiv_id: '2601.21192'
source_url: https://arxiv.org/abs/2601.21192
tags:
- qwen2
- embedding
- reasoning
- base
- rlvr
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'We investigate whether RLVR-optimized reasoning models enhance
  embedding performance when used as backbone initializations. Controlled experiments
  on MTEB and BRIGHT show no consistent advantage: reasoning-initialized embedding
  models perform statistically identically to base-initialized ones under identical
  training recipes.'
---

# Do Reasoning Models Enhance Embedding Models?

## Quick Facts
- **arXiv ID**: 2601.21192
- **Source URL**: https://arxiv.org/abs/2601.21192
- **Reference count**: 40
- **Primary result**: RLVR-optimized reasoning models do not enhance embedding model performance when used as backbone initializations

## Executive Summary
This paper investigates whether reasoning models optimized with RLVR provide advantages when used as initializations for embedding models. Through controlled experiments comparing base-initialized versus reasoning-initialized embedding models, the authors find no statistically significant performance differences in retrieval tasks. To explain this null effect, they introduce the HRSA framework that decomposes model similarity into representation, geometry, and function levels, revealing that RLVR preserves global manifold geometry while reorganizing local geometry and inducing modest coordinate basis drift.

## Method Summary
The authors conducted controlled experiments training embedding models from both base and reasoning model backbones using identical training recipes (InfoNCE loss, batch size 2048, learning rate 2×10⁻⁵, 782 steps, mean pooling, bi-directional attention). Training data was prepared from 11 retrieval datasets with hard negative mining using a reference embedding model at 95% margin. Models were evaluated on MTEB and BRIGHT benchmarks. The HRSA framework was implemented by extracting layer-wise activations on custom datasets and computing metrics including CKA, k-NN overlap, dimension-wise correlation, orthogonal Procrustes alignment, and cross-model linear probes.

## Key Results
- No consistent performance advantage when using RLVR-tuned reasoning models as embedding model initializations
- HRSA reveals RLVR preserves global manifold geometry and linear readout while reorganizing local geometry
- Contrastive learning realigns base- and reasoning-initialized embedding manifolds, a phenomenon termed "Manifold Realignment"
- RLVR optimizes within existing semantic landscapes rather than restructuring them

## Why This Works (Mechanism)
RLVR reasoning optimization preserves the fundamental embedding geometry while enhancing reasoning behavior through local reorganization rather than global semantic restructuring. The contrastive learning process used in embedding training induces manifold realignment that equalizes differences between base and reasoning initializations. This explains why reasoning models don't provide embedding advantages despite their enhanced reasoning capabilities - they operate within the same semantic space rather than transforming it.

## Foundational Learning
- **InfoNCE Loss**: Contrastive loss function that pulls positive pairs together and pushes negative pairs apart in embedding space; needed for training embedding models, quick check: verify loss implementation matches original formulation
- **Hard Negative Mining**: Technique to improve retrieval by selecting challenging negative examples; needed for effective contrastive training, quick check: ensure mining achieves target margin of 95%
- **CKA (Centered Kernel Alignment)**: Measure of representational similarity between neural network layers; needed for HRSA analysis, quick check: validate CKA scores range between 0-1
- **Procrustes Analysis**: Geometric alignment technique to measure coordinate basis similarity; needed for HRSA's representation level, quick check: orthogonal Procrustes should yield rotation/reflection only
- **Manifold Geometry**: Study of high-dimensional data structure; needed to understand embedding space properties, quick check: verify manifold dimensionality matches embedding size
- **k-NN Overlap Metrics**: Measures local neighborhood consistency; needed for HRSA's geometry level, quick check: Jaccard scores should be between 0-1

## Architecture Onboarding

**Component Map**: Training Data -> Hard Negative Miner -> Embedding Model (Base/Reasoning-initialized) -> HRSA Analyzer -> Evaluation Metrics

**Critical Path**: Model Initialization → Contrastive Training → HRSA Analysis → Performance Evaluation

**Design Tradeoffs**: Full-parameter training vs. LoRA (full training shows better performance but higher compute); bi-directional vs. causal attention (bi-directional needed for embedding models); temperature in InfoNCE (0.02 used here, affects gradient strength)

**Failure Signatures**: Performance degradation when using LoRA instead of full fine-tuning; degraded results if causal attention mask not removed; spurious differences if training durations differ between model pairs

**Three First Experiments**:
1. Train base-initialized and reasoning-initialized embedding models with identical hyperparameters and compare MTEB scores
2. Extract layer-wise activations from both models and compute CKA similarity scores across layers
3. Measure k-NN overlap (Jaccard) for both models on the same test set with varying k values

## Open Questions the Paper Calls Out
None

## Limitations
- Findings limited to retrieval tasks; may not generalize to clustering, classification, or other embedding use cases
- Analysis restricted to relatively small model scales (1.5B and 4B parameters)
- HRSA framework uses simplified metrics that may not capture all representation differences
- Manifold realignment phenomenon lacks mechanistic explanation for why contrastive learning specifically induces this alignment

## Confidence
- **High Confidence**: Null result showing no performance difference between base- and reasoning-initialized embedding models under identical training conditions
- **Medium Confidence**: HRSA framework's decomposition of similarity into representation, geometry, and function levels
- **Medium Confidence**: Claim that RLVR optimizes within existing semantic landscapes rather than restructuring them

## Next Checks
1. Test whether reasoning-initialized embeddings show advantages in non-retrieval tasks (e.g., clustering, few-shot classification)
2. Repeat HRSA analysis on models larger than 4B parameters to determine if geometric preservation patterns hold at larger scales
3. Conduct ablation studies varying contrastive loss hyperparameters to determine conditions for manifold realignment and correlate with performance changes