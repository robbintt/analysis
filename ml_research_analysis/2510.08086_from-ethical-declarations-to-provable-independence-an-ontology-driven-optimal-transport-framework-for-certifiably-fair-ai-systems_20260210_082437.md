---
ver: rpa2
title: 'From Ethical Declarations to Provable Independence: An Ontology-Driven Optimal-Transport
  Framework for Certifiably Fair AI Systems'
arxiv_id: '2510.08086'
source_url: https://arxiv.org/abs/2510.08086
tags:
- bias
- fairness
- sensitive
- ontology
- algebra
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a framework for provably fair AI that overcomes
  the limits of current bias mitigation methods by systematically removing all sensitive
  information and its proxies. Using ontology engineering in OWL 2 QL, it formally
  defines sensitive attributes and infers their proxies through logical reasoning,
  constructing a sigma algebra G that captures the full structure of biased patterns.
---

# From Ethical Declarations to Provable Independence: An Ontology-Driven Optimal-Transport Framework for Certifiably Fair AI Systems

## Quick Facts
- **arXiv ID:** 2510.08086
- **Source URL:** https://arxiv.org/abs/2510.08086
- **Reference count:** 19
- **Primary result:** Ontology-guided optimal transport achieves provable fairness by removing all sensitive information and proxies, ensuring independence rather than mere decorrelation.

## Executive Summary
This paper presents a framework for provably fair AI systems that goes beyond current bias mitigation methods by systematically removing all sensitive information and its proxies. The approach uses ontology engineering in OWL 2 QL to formally define sensitive attributes and infer their proxies through logical reasoning, constructing a sigma algebra that captures the full structure of biased patterns. Fair representations are then obtained via Delbaen-Majumdar optimal transport, which generates variables independent of the bias structure while minimizing L2 distance to preserve accuracy. The method guarantees true independence rather than mere decorrelation, making it suitable for critical applications like loan approval where proxies such as ZIP code reveal protected attributes.

## Method Summary
The framework systematically removes bias through a three-step process: First, ontology engineering defines sensitive attributes and their proxies using OWL 2 QL axioms. Second, logical inference identifies all individuals belonging to these classes, constructing a sigma algebra that represents the complete bias structure. Third, Delbaen-Majumdar optimal transport transforms the original data into fair representations that are independent of the bias sigma algebra while minimizing L2 distance to preserve accuracy. This approach ensures complete fairness by modeling bias as dependence between sigma algebras and using optimal transport as the unique fair transformation.

## Key Results
- Ontology-guided sigma-algebra construction captures all sensitive attributes and their proxies
- Delbaen-Majumdar optimal transport generates representations independent of bias structure
- Method guarantees true independence rather than mere decorrelation
- Achieves provable fairness while minimizing L2 distance to preserve predictive accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Ontology-guided sigma-algebra construction systematically captures all sensitive attributes and their proxies.
- Mechanism: OWL 2-QL ontology axioms define sensitive classes (e.g., `ProxyForRace`). Logical inference (entailment, `O|=C(ω)`) extends these definitions to identify all individuals belonging to these classes in the dataset. The extensions of these classes form a set of measurable events which generate a sigma-algebra $\mathcal{G}_\mathcal{O}$.
- Core assumption: The ontology's axioms correctly and completely capture the domain's sensitive attributes and proxy relationships relevant to the specific fairness problem being addressed.
- Evidence anchors:
  - [abstract] "Using ontology engineering in OWL 2 QL, it formally defines sensitive attributes and infers their proxies through logical reasoning, constructing a sigma algebra G that captures the full structure of biased patterns."
  - [section 5.1] "The ontology-guided σ-algebra of bias is $\mathcal{G}_\mathcal{O} = \sigma(\{\llbracket C \rrbracket | C \in S_{onto}\})$"
  - [corpus] Weak/no direct corpus evidence for this specific combination of OWL 2-QL and sigma-algebra construction.
- Break condition: Ontology axioms are incomplete or incorrect, failing to capture key proxy relationships.

### Mechanism 2
- Claim: Fair representations are constructed to be provably independent of the bias sigma-algebra.
- Mechanism: The paper formalizes fairness as statistical independence: a representation $Y$ is fair if it is independent of the bias sigma-algebra $\mathcal{G}$, i.e., $P(Y \in B | \mathcal{G}) = P(Y \in B)$ for all Borel sets $B$. This is a stronger condition than zero correlation.
- Core assumption: Independence from the constructed $\mathcal{G}$ is the correct and sufficient mathematical formalization of the desired fairness property.
- Evidence anchors:
  - [abstract] "Fair representations are then obtained via Delbaen-Majumdar optimal transport, which generates variables independent of G while minimizing L2 distance to preserve accuracy."
  - [section 3.4] "A random variable Y is said to be independent of a σ-algebra G if and only if... This definition is a direct mathematical embodiment of fairness".
  - [corpus] "On Optimal Steering to Achieve Exact Fairness" and "Achieving Hilbert-Schmidt Independence Under Rényi Differential Privacy" relate to achieving independence/fairness.
- Break condition: The definition of independence does not align with the sociotechnical fairness goal.

### Mechanism 3
- Claim: Delbaen-Majumdar optimal transport provides the unique solution for constructing a fair representation that minimally distorts the original data.
- Mechanism: Given an original variable $X$ and the bias sigma-algebra $\mathcal{G}$, optimal transport theory is used to find a new variable $Y$ that satisfies two conditions: 1) $Y$ is independent of $\mathcal{G}$, and 2) $Y$ minimizes the $L^2$ distance (mean squared error) to $X$, thus preserving predictive accuracy.
- Core assumption: A unique solution exists under the specified conditions (atomless conditionally on $\mathcal{G}$), and minimizing $L^2$ distance is the appropriate proxy for preserving useful information.
- Evidence anchors:
  - [abstract] "Fair representations are then obtained via Delbaen Majumdar optimal transport, which generates variables independent of G while minimizing2 distance to preserve accuracy."
  - [section 3.5] "As established in [4,5,3], a unique solution Y exists... The construction leverages optimal transport theory...".
  - [corpus] "On Optimal Steering to Achieve Exact Fairness" discusses optimal steering for fair outcomes.
- Break condition: The mathematical conditions for a unique optimal solution (e.g., atomless conditionally on $\mathcal{G}$) are not met.

## Foundational Learning

- **Sigma-Algebra ($\sigma$-algebra)**
  - Why needed here: This is the core mathematical structure used to define the information content of bias. Understanding that it represents a collection of measurable events closed under complement and countable unions is essential to grasp how the paper formalizes "biased information."
  - Quick check question: If a set of events $A$ and $B$ is in a sigma-algebra $\mathcal{G}$, is the union of $A$ and $B$, $A \cup B$, also guaranteed to be in $\mathcal{G}$?

- **Statistical Independence**
  - Why needed here: The paper's definition of fairness is predicated on formal statistical independence between a representation and a sigma-algebra. This is a stricter condition than decorrelation.
  - Quick check question: What is the formal definition of a random variable $Y$ being independent of another random variable $X$? (Hint: think in terms of conditional probabilities).

- **Ontology (Description Logic/OWL)**
  - Why needed here: The framework uses ontologies (specifically OWL 2-QL) to explicitly define and reason about sensitive attributes and proxies. Familiarity with terms like TBox, ABox, and entailment is crucial.
  - Quick check question: In an ontology, what is the difference between a TBox and an ABox?

## Architecture Onboarding

- **Component map:** Ontology Authoring -> Sigma-Algebra Generator -> Fair Representation Engine -> Certification Module
- **Critical path:** The most critical and novel path is from **Ontology Definition -> Sigma-Algebra Generation**. Errors in the axioms here will propagate, leading to an incomplete $\mathcal{G}$ and thus a biased representation $Y$. The optimal transport step is a well-defined mathematical operation if $\mathcal{G}$ is correct.
- **Design tradeoffs:**
  - **Completeness vs. Complexity:** A richer, more expressive ontology (e.g., moving beyond OWL 2-QL) might capture more nuanced proxies but could increase reasoning complexity, impacting the scalability of the sigma-algebra generator.
  - **Fairness vs. Accuracy:** The $L^2$ minimization in the optimal transport step is a direct tradeoff. Achieving perfect independence ($Y \perp \!\!\! \perp \mathcal{G}$) may require a larger distortion from $X$, potentially harming downstream accuracy. The paper claims to find the optimal balance.
- **Failure signatures:**
  - **Proxy Leakage:** If the final model's predictions are still found to correlate with sensitive attributes (e.g., via an HSIC test as mentioned in the blueprint), the likely failure point is an incomplete ontology that missed a key proxy.
  - **Implementation Scalability:** The paper claims feasibility for $10^7$ rows on a multi-core node but acknowledges performance estimates are to be validated. Failure to scale would appear in the sigma-algebra generator or the optimal transport solver.
- **First 3 experiments:**
  1. **Ontology Ablation:** Create a simple ontology with one known proxy (e.g., ZIP code -> race) and run the full pipeline on a synthetic or semi-synthetic dataset (e.g., Adult/Census). Measure the correlation of $Y$ with the sensitive attribute. Then, remove the proxy axiom and repeat. This validates the mechanism of proxy inference.
  2. **Benchmark Comparison:** Compare the fairness-accuracy tradeoff of this method (using a basic ontology) against a standard baseline like adversarial debiasing on a common fairness dataset (e.g., COMPAS). Metrics: demographic parity difference, equalized odds difference, and accuracy.
  3. **Scalability Test:** Implement the sigma-algebra generator and measure its runtime as the number of data points ($N$) and the number of sensitive/proxy concepts in the ontology ($|S_{onto}|$) increase. This directly tests the complexity claims made in section 6.3.

## Open Questions the Paper Calls Out
None

## Limitations

- The framework's guarantee of "complete fairness" is only as strong as the ontological modeling of bias in the specific domain. If the ontology fails to capture a relevant proxy relationship, the constructed sigma-algebra will be incomplete, and the resulting representation Y will still contain biased information.
- The use of OWL 2-QL, while enabling tractable reasoning, may limit the expressiveness needed for complex proxy relationships.
- The paper's experimental validation is minimal, with no reported results on real or synthetic datasets, making it difficult to assess the practical effectiveness and scalability of the approach.

## Confidence

- **High Confidence:** The mathematical formalization of fairness as independence from a sigma-algebra is a well-established concept in probability theory and is correctly applied.
- **Medium Confidence:** The integration of ontology reasoning with sigma-algebra construction is logically sound, but its practical completeness is unverified.
- **Low Confidence:** The practical scalability and effectiveness of the full pipeline on real-world data are unknown due to the lack of empirical results.

## Next Checks

1. **Ontology Completeness Test:** Conduct an ablation study on a known dataset (e.g., Adult) by systematically adding known proxy relationships to the ontology and measuring the downstream fairness of the representation Y. This will validate the critical mechanism of proxy inference.

2. **Benchmark Comparison:** Implement the framework and compare its fairness-accuracy tradeoff against established methods like adversarial debiasing on a standard fairness benchmark. This will contextualize the method's performance.

3. **Scalability Stress Test:** Implement and benchmark the sigma-algebra generator on datasets of increasing size (N) and with increasingly complex ontologies (|S_onto|) to empirically verify the claimed O(N * |S_onto|) complexity and identify performance bottlenecks.