---
ver: rpa2
title: 'Safe, Untrusted, "Proof-Carrying" AI Agents: toward the agentic lakehouse'
arxiv_id: '2510.09567'
source_url: https://arxiv.org/abs/2510.09567
tags:
- data
- lakehouse
- agents
- code
- agentic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of safely deploying AI agents
  to manage data pipelines in cloud-based data lakehouses, where concerns around trust,
  correctness, and governance are paramount. The authors propose using a programmable,
  API-first lakehouse architecture that exposes the entire data lifecycle through
  code abstractions, enabling safe-by-design agentic workflows.
---

# Safe, Untrusted, "Proof-Carrying" AI Agents: toward the agentic lakehouse

## Quick Facts
- arXiv ID: 2510.09567
- Source URL: https://arxiv.org/abs/2510.09567
- Reference count: 25
- Primary result: AI agents can safely repair data pipelines in lakehouses using proof-carrying safety mechanisms

## Executive Summary
This paper addresses the critical challenge of deploying AI agents to manage data pipelines in cloud-based lakehouses while maintaining trust, correctness, and governance. The authors propose a programmable, API-first lakehouse architecture that exposes the entire data lifecycle through code abstractions, enabling safe-by-design agentic workflows. Their approach combines transactional pipeline execution with Git-for-Data concepts and a "proof-carrying" safety mechanism where agents must pass deterministic correctness checks before changes can be merged to production. A proof-of-concept implementation demonstrates that untrusted AI agents can successfully identify, debug, and repair broken data pipelines without compromising production data integrity.

## Method Summary
The authors implement a safe-by-design approach for agentic lakehouse operations through programmable API abstractions and transactional execution patterns. The method involves exposing data lifecycle operations as code abstractions, implementing Git-for-Data concepts for version control and rollback capabilities, and creating a "proof-carrying" safety mechanism where agents must pass deterministic correctness checks before production deployment. The prototype uses Bauplan as the underlying lakehouse platform, demonstrating how agents can navigate the pipeline lifecycle from failure detection through repair execution while maintaining safety guarantees through code-based verification steps.

## Key Results
- Untrusted AI agents successfully repaired broken data pipelines without compromising production data integrity
- Agents could navigate the complete pipeline lifecycle including failure identification, debugging, and fix execution
- The proof-carrying safety mechanism effectively prevented incorrect changes from reaching production environments

## Why This Works (Mechanism)
The approach works by combining code-based abstractions with deterministic verification mechanisms to create a safety net for autonomous operations. By exposing the entire data lifecycle as programmable APIs, the system creates a structured interface that agents can interact with predictably. The Git-for-Data transactional approach provides version control and rollback capabilities, while the proof-carrying mechanism ensures that any changes must pass correctness verification before deployment. This combination of declarative environments and deterministic checks creates a system where safety is built into the architecture rather than being an afterthought.

## Foundational Learning
- **Transactional pipeline execution**: Required for maintaining data integrity during agent operations; quick check involves verifying rollback capabilities work under concurrent access
- **Git-for-Data concepts**: Essential for version control and audit trails in agentic workflows; quick check involves testing merge conflict resolution with concurrent agent changes
- **Declarative environments**: Needed to provide consistent, reproducible execution contexts for agent operations; quick check involves validating environment isolation between pipeline versions
- **Deterministic correctness verification**: Critical for the proof-carrying safety mechanism; quick check involves testing verification against known-good and known-bad pipeline states
- **Code-based abstractions**: Required to create predictable interfaces for agent interaction; quick check involves measuring agent success rates across different abstraction levels
- **Production merge gates**: Necessary to prevent unverified changes from reaching production; quick check involves testing gate behavior under high-volume agent submissions

## Architecture Onboarding
- **Component map**: Lakehouse API -> Agent Interface -> Verification Engine -> Merge Gate -> Production Pipeline
- **Critical path**: Agent identifies failure → Proposes fix → Verification engine tests correctness → Merge gate approves → Changes deploy to production
- **Design tradeoffs**: The system trades computational overhead for safety guarantees, accepting verification latency to prevent production failures
- **Failure signatures**: Common failure modes include verification timeouts, merge conflicts from concurrent changes, and agent inability to propose valid fixes
- **First experiments**: 1) Test agent success rate on synthetic pipeline failures, 2) Measure verification engine performance under concurrent load, 3) Validate rollback functionality after failed agent deployments

## Open Questions the Paper Calls Out
None

## Limitations
- The evaluation is limited to a single prototype implementation using Bauplan, limiting generalizability to other lakehouse architectures
- Performance overhead of the transactional approach is not characterized for production-scale workloads
- The approach does not address non-deterministic AI behaviors or adversarial agent actions that could bypass verification

## Confidence
- **High** in the core architectural concept and its potential for safe agentic workflows, as the approach builds on established patterns like code abstractions and transactional execution
- **Medium** in the specific implementation details and proof-of-concept results, given the limited evaluation scope
- **Low** in claims about production readiness and scalability without further testing across diverse lakehouse systems and larger datasets

## Next Checks
1. Implement and test the proof-carrying safety mechanism across at least three different lakehouse platforms to assess portability and identify platform-specific limitations
2. Measure the performance overhead (latency, throughput) of the transactional pipeline execution with Git-for-Data concepts under realistic workloads (e.g., multi-terabyte datasets, concurrent agent operations)
3. Design and execute adversarial testing scenarios where agents attempt to bypass correctness checks to evaluate the robustness of the safety guarantees under intentional compromise attempts