---
ver: rpa2
title: 'Over-Alignment vs Over-Fitting: The Role of Feature Learning Strength in Generalization'
arxiv_id: '2602.00827'
source_url: https://arxiv.org/abs/2602.00827
tags:
- learning
- generalization
- training
- feature
- have
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work studies how feature learning strength (FLS) affects generalization
  in deep networks. Empirically, we find that excessively large FLS can hurt generalization,
  and an intermediate optimal FLS emerges, contrary to prevailing intuition.
---

# Over-Alignment vs Over-Fitting: The Role of Feature Learning Strength in Generalization

## Quick Facts
- arXiv ID: 2602.00827
- Source URL: https://arxiv.org/abs/2602.00827
- Reference count: 40
- Primary result: Intermediate feature learning strength yields optimal generalization; excessively large FLS causes over-alignment while small FLS causes over-fitting

## Executive Summary
This work investigates how feature learning strength (FLS) affects generalization in deep networks. Contrary to prevailing intuition, the authors find that excessively large FLS can hurt generalization, with an intermediate optimal FLS emerging. Through empirical experiments on CIFAR datasets and theoretical analysis of two-layer ReLU networks, they establish that large FLS induces over-alignment (deviation from Bayes-optimal direction) while small FLS leads to over-fitting, creating a trade-off that yields an optimal FLS. Numerical experiments validate theoretical predictions, demonstrating the existence of an optimal FLS that minimizes excess error.

## Method Summary
The study controls FLS via output multiplier c (rescaling model output f→cf and learning rate η→η/c) across seven values from 2^{-10} to 2^{2}. Experiments use CIFAR-100 as primary dataset with CIFAR-10 and BigGAN-generated synthetic images for validation. Networks include VGG19-BN, ResNet{18,34,50} trained with vanilla SGD (batch size 128, 80 epochs, no augmentation/scheduler/weight decay). Theoretical analysis uses two-layer bias-free ReLU networks with 64 hidden units trained via gradient flow with logistic loss. Configurations are filtered to those achieving >99% training accuracy before comparing peak test accuracy.

## Key Results
- U-shaped generalization curve observed across architectures (ResNet18,34,50; VGG19-BN) and datasets
- Optimal FLS at intermediate output multiplier (~2^{-4}), not at strongest feature learning
- Over-alignment mechanism identified: large FLS causes predictor to deviate from Bayes-optimal direction
- Over-fitting mechanism confirmed: small FLS leads to poor generalization despite strong feature learning
- Trade-off between over-alignment and over-fitting yields optimal FLS that minimizes excess error

## Why This Works (Mechanism)
The mechanism centers on controlling the strength of feature learning through output scaling. By rescaling the model output and proportionally adjusting the learning rate, the authors can interpolate between kernel regime (large FLS, weak feature learning) and strong feature learning regime (small FLS). This creates a controlled environment to study how different FLS levels affect the alignment between learned features and optimal decision boundaries.

## Foundational Learning
- **Feature Learning Strength (FLS)**: The degree to which a network learns task-relevant features versus relying on random features. Why needed: Central concept the paper investigates; determines generalization behavior.
- **Over-alignment**: When the effective predictor deviates from the Bayes-optimal direction due to excessively large FLS. Why needed: Novel failure mode identified; explains why strong feature learning can hurt generalization.
- **Orthogonal separability**: Assumption that training data points are linearly separable with orthogonal separating hyperplanes. Why needed: Theoretical simplification enabling clean decomposition of error into over-alignment and over-fitting components.
- **Gradient flow dynamics**: Continuous-time limit of gradient descent used for theoretical analysis. Why needed: Enables tractable mathematical analysis of training dynamics in two-layer networks.
- **Excess error decomposition**: Breakdown of generalization error into approximation, estimation, and optimization components. Why needed: Framework for analyzing how FLS affects different error sources.

## Architecture Onboarding

**Component Map:**
Output Multiplier c -> Learning Rate η/c -> Training Dynamics -> Generalization Performance

**Critical Path:**
The critical path is the (c, η) configuration selection leading to >99% training accuracy, followed by peak test accuracy evaluation. The trade-off between over-alignment (large c) and over-fitting (small c) determines the optimal FLS.

**Design Tradeoffs:**
- Vanilla SGD vs adaptive optimizers: Simple baseline but misses practical optimization effects
- No data augmentation: Cleaner analysis but less realistic
- Fixed training duration (80 epochs): Ensures sufficient training but may affect optimal FLS sensitivity

**Failure Signatures:**
- U-shaped curve not visible: Likely due to insufficient (c, η) coverage or dataset too easy (use CIFAR-100 not CIFAR-10)
- Some (c, η) pairs fail to reach 99% training accuracy: Expected for mismatched configurations; exclude from comparison
- Optimal FLS varies significantly across runs: Check seed consistency and training stability

**First Experiments:**
1. Run CIFAR-100 with ResNet18, sweeping c ∈ {2^{-10}, 2^{-8}, 2^{-6}, 2^{-4}, 2^{-2}, 2^{0}, 2^{2}} and learning rates η/c
2. Filter for configurations achieving >99% training accuracy and record peak test accuracy
3. Plot heatmap of peak test accuracy on (output multiplier, learning rate) axes to verify U-shaped curve

## Open Questions the Paper Calls Out

**Open Question 1:** Can the optimal FLS be transferred from smaller to larger scale models without exhaustive re-tuning? The paper identifies this as a practical limitation but provides no transferability analysis or theoretical grounding for how FLS might scale with model size.

**Open Question 2:** Does the optimal FLS persist under practical training techniques such as SGD noise, adaptive optimizers, and data augmentation? The paper's experiments use vanilla SGD without augmentation; its theoretical analysis assumes gradient flow.

**Open Question 3:** Can the theoretical framework be extended beyond the orthogonal separability assumption on training data? Orthogonal separability is a restrictive assumption rarely satisfied in real datasets.

**Open Question 4:** Can the optimal FLS be predicted or estimated directly from dataset properties such as intrinsic dimensionality or task difficulty? The paper shows optimal FLS benefits grow with effective dimensionality but provides no predictive framework.

## Limitations
- Theoretical analysis assumes gradient flow and logistic loss, which may not capture practical SGD dynamics
- Optimal FLS appears sensitive to specific learning rate schedules and training duration
- Mechanism connecting output scaling to feature learning strength requires further empirical validation

## Confidence

**High confidence:** Empirical observation that intermediate FLS yields optimal generalization across multiple architectures and datasets

**Medium confidence:** Theoretical explanation linking over-alignment to large FLS, as proof relies on simplified assumptions

**Medium confidence:** Over-fitting mechanism for small FLS, requiring further investigation with different network architectures

## Next Checks
1. Replicate CIFAR-100 experiments with ResNet50 and VGG19-BN to confirm U-shaped generalization curve across architectures
2. Test FLS generalization trade-off on additional datasets (e.g., CIFAR-10, ImageNet subsets) to verify robustness
3. Conduct ablation studies varying training duration and learning rate schedules to assess sensitivity of optimal FLS to training hyperparameters