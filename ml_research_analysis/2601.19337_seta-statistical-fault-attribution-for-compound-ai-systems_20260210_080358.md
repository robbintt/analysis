---
ver: rpa2
title: 'SETA: Statistical Fault Attribution for Compound AI Systems'
arxiv_id: '2601.19337'
source_url: https://arxiv.org/abs/2601.19337
tags:
- system
- metamorphic
- each
- systems
- framework
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SETA, a statistical fault attribution framework
  for compound AI systems that integrates metamorphic testing with execution trace
  analysis to localize faults in multi-component neural network pipelines. By defining
  oracle-free behavioral specifications via metamorphic relations and analyzing dynamic
  execution graphs, SETA attributes system-level failures to specific components through
  statistical correlation of component deviations with end-to-end failures.
---

# SETA: Statistical Fault Attribution for Compound AI Systems

## Quick Facts
- arXiv ID: 2601.19337
- Source URL: https://arxiv.org/abs/2601.19337
- Reference count: 40
- Primary result: Statistical fault attribution framework using metamorphic testing and execution trace analysis to localize failures in multi-component neural network pipelines

## Executive Summary
SETA introduces a statistical fault attribution framework for compound AI systems that integrates metamorphic testing with execution trace analysis. The approach defines oracle-free behavioral specifications via metamorphic relations and analyzes dynamic execution graphs to attribute system-level failures to specific components through statistical correlation. Applied to a real-world autonomous rail inspection system, SETA demonstrated effectiveness in pinpointing failure origins beyond conventional end-to-end metrics, though it provides correlational rather than causal attribution.

## Method Summary
SETA combines metamorphic testing with execution trace analysis to localize faults in multi-component neural network pipelines. The framework defines oracle-free behavioral specifications through metamorphic relations for each component, then analyzes dynamic execution graphs to track fault propagation. By computing conditional failure contribution scores based on the correlation between component deviations and system failures, SETA provides statistical attribution of failures to specific modules. The method is architecture and modality agnostic, extensible to vision and text-based systems.

## Key Results
- Successfully applied to real-world autonomous rail inspection system with compound AI pipeline
- Demonstrated accurate identification of vulnerable components through attribution scores (α)
- Framework works across different modalities (vision and text-based systems)
- Attribution scores reflect component influence on system failures, though remain correlational rather than causal

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Metamorphic relations can serve as component-level pseudo-oracles for detecting behavioral deviations in compound AI systems.
- Mechanism: For each component, define relations M(x, x̃, f(x), f(x̃)) that must hold between outputs for original input x and perturbed input x̃. Violations (M = 0) flag potential faults without requiring ground-truth labels.
- Core assumption: Correct component behavior preserves specified invariants (e.g., IoU > τ, label consistency) under semantically-preserving transformations.
- Evidence anchors:
  - [abstract] "defines oracle-free behavioral specifications through metamorphic relations"
  - [Section 2.1] "Metamorphic Testing (MT) is a powerful technique... verifying preservation of necessary, user-specified properties"
- Break condition: If MRs are incomplete or non-causal, violations may be false negatives (faults occur outside defined property space).

### Mechanism 2
- Claim: Execution trace trees capture fault propagation pathways across interconnected modules.
- Mechanism: Model the system as a state-transition system S = (Q, I, Φ, M, R, S). For each input, construct trace tree T(x) with nodes (module, input, output, score). Align T(x) with T(x̃) to identify where deviations emerge and how routing changes.
- Core assumption: The recorded activation sequence and routing decisions reflect true causal dependencies in the pipeline.
- Evidence anchors:
  - [abstract] "analyzing dynamic execution graphs"
  - [Section 3] "the system's runtime behaviour can be captured as an Execution Trace Tree T(x) = (V, E)"
- Break condition: If modules have hidden side effects or non-deterministic routing, trace alignment fails.

### Mechanism 3
- Claim: Conditional failure contribution scores provide statistical (not causal) fault attribution.
- Mechanism: Compute FC_i = E[Z_i · I(S = 0)], the expected component deviation given system failure. Normalize to attribution weights α_i = FC_i / ΣFC_j. Higher α_i indicates stronger association with system failures.
- Core assumption: High correlation between component deviations and system failures approximates responsibility, though the paper explicitly states this is correlational, not causal.
- Evidence anchors:
  - [abstract] "attributes failures to specific components"
  - [Section 2.2] "FC score is defined as the expected deviation of that module conditioned on a system-level failure"
- Break condition: If perturbation effects are coupled across modules or dataset is biased, FC scores misrepresent influence.

## Foundational Learning

- Concept: **Metamorphic Testing and Relations**
  - Why needed here: SETA relies entirely on MRs to detect deviations without ground truth. Understanding how to define valid MRs (invariance, subset, equivalence) is essential.
  - Quick check question: Given an object detector, what relation should hold between detections on an image and its slightly darkened version?

- Concept: **State-Transition Systems and Execution Traces**
  - Why needed here: The framework models compound AI as state machines and constructs trace trees to track activation and data flow.
  - Quick check question: In a pipeline with modules A → B → C, what does it mean if T(x) activates B but T(x̃) skips directly to C?

- Concept: **Conditional Probability and Statistical Attribution**
  - Why needed here: FC scores condition on system failure; interpreting α_i requires understanding that correlation ≠ causation.
  - Quick check question: If module A's FC = 0.8 and module B's FC = 0.2, can we conclude A causes 80% of failures? Why or why not?

## Architecture Onboarding

- Component map:
  - Instrumentation layer: Lightweight hooks per module logging (input, output, confidence, routing decisions)
  - Perturbation engine: Applies transformations g ∈ P (e.g., fog, noise, blur) from libraries like imagecorruptions
  - Trace builder: Constructs T(x) and T(x̃) as execution trees
  - MR evaluator: Computes S_i(x, x̃) per module using composite relations
  - Attribution calculator: Aggregates deviations into FC[i] and normalizes to α_i

- Critical path:
  1. Register all modules with tracing hooks at initialization
  2. Run reference execution T(x) on clean input
  3. Apply each perturbation g ∈ P, run T(x̃)
  4. Align trace trees, evaluate MRs per module
  5. Accumulate failures where S(x, x̃) = 0
  6. Compute and output normalized attribution scores

- Design tradeoffs:
  - **MR completeness vs. effort**: Hand-crafted MRs may miss failure modes; automated MR learning is future work
  - **Perturbation coverage vs. runtime**: More perturbations improve statistical power but increase cost
  - **Black-box vs. white-box**: Current design treats modules as black-box; internal access could enable richer MRs

- Failure signatures:
  - **S_i = 0**: Component violated its metamorphic relation
  - **Routing divergence**: T(x) and T(x̃) activate different downstream modules
  - **α_i ≈ 0 for all i**: MRs may be too lenient or perturbations insufficiently challenging

- First 3 experiments:
  1. Validate on single-component system: Apply SETA to one model with known MRs, verify FC aligns with actual error rate under controlled perturbations.
  2. Test on two-module pipeline: Inject known faults upstream (e.g., degrade detector) and verify α attribution correctly identifies source.
  3. Sensitivity analysis: Vary MR thresholds (τ) and perturbation severity levels; observe how α_i distributions shift to identify robust parameter ranges.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the framework transition from correlational fault attribution to true causal fault localization?
- Basis in paper: [explicit] The conclusion explicitly states the current formulation is correlational and suggests "integrating causal inference or interventional analysis" as future work.
- Why unresolved: High attribution scores currently indicate association with failure rather than definitive responsibility, making it hard to distinguish root causes from symptoms.
- What evidence would resolve it: A modified framework where an intervention on an identified component is proven to prevent the downstream system failure.

### Open Question 2
- Question: Can metamorphic relations be automatically inferred rather than hand-crafted?
- Basis in paper: [explicit] The conclusion identifies that current hand-crafted relations may be incomplete and proposes "program synthesis or learning-based methods" to automate this.
- Why unresolved: Manual definition limits scalability and risks false negatives if the defined properties do not cover specific anomalous behaviors.
- What evidence would resolve it: An algorithm that successfully mines valid metamorphic relations from execution logs with coverage comparable to human experts.

### Open Question 3
- Question: Can the framework be generalized to multimodal or reinforcement learning systems?
- Basis in paper: [explicit] The conclusion explicitly calls for "extending SETA beyond vision pipelines to multimodal or reinforcement-learning systems."
- Why unresolved: The current metamorphic relations (e.g., IoU) and state definitions are tailored for static vision tasks and may not capture temporal dependencies in RL.
- What evidence would resolve it: Successful application of SETA to an RL agent where the framework correctly identifies the policy or perception module causing a policy failure.

## Limitations
- Provides correlational rather than causal attribution, as FC scores are based on statistical association between component deviations and system failures
- Effectiveness depends heavily on the completeness and appropriateness of metamorphic relations—poorly defined MRs may miss critical failure modes
- Assumes perturbations are semantically meaningful and that trace alignment can accurately capture routing differences, which may not hold for highly stochastic or non-deterministic systems

## Confidence
- **High confidence**: The statistical attribution mechanism (FC scores and α normalization) is mathematically sound and well-defined
- **Medium confidence**: The metamorphic testing approach is valid, but effectiveness depends on MR quality and perturbation selection
- **Medium confidence**: Execution trace analysis can capture fault propagation, though trace alignment complexity in branching systems may introduce errors

## Next Checks
1. **MR Coverage Validation**: Systematically evaluate SETA's performance when applying MRs with known gaps—intentionally omit MRs that would catch specific faults and measure attribution accuracy degradation

2. **Perturbation Sensitivity Analysis**: Quantify how attribution accuracy varies with perturbation severity and type—identify regimes where SETA correctly attributes vs. where it fails or produces spurious results

3. **Multi-Component Fault Injection**: Test SETA on systems with known multi-component faults (both single and simultaneous failures) to evaluate whether attribution scores reflect true contribution or merely correlation