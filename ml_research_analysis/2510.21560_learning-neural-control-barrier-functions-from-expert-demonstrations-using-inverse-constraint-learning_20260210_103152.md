---
ver: rpa2
title: Learning Neural Control Barrier Functions from Expert Demonstrations using
  Inverse Constraint Learning
arxiv_id: '2510.21560'
source_url: https://arxiv.org/abs/2510.21560
tags:
- states
- control
- constraint
- expert
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of training neural control barrier
  functions (CBFs) from expert demonstrations when the failure set of states is hard
  to specify formally. The authors propose an approach called ICL-CBF that combines
  inverse constraint learning (ICL) with neural CBF training.
---

# Learning Neural Control Barrier Functions from Expert Demonstrations using Inverse Constraint Learning

## Quick Facts
- **arXiv ID:** 2510.21560
- **Source URL:** https://arxiv.org/abs/2510.21560
- **Reference count:** 40
- **Key outcome:** ICL-CBF outperforms baselines and achieves comparable performance to neural CBFs trained with ground-truth safety labels, with single integrator achieving 0% collision rate and 80.6% success rate.

## Executive Summary
This paper addresses the challenge of training neural control barrier functions (CBFs) when the failure set is hard to specify formally. The authors propose ICL-CBF, which combines inverse constraint learning (ICL) with neural CBF training. The method iteratively learns a constraint function to classify safe and unsafe states from expert demonstrations, then uses this function to label simulated trajectories for training a neural CBF. A key innovation is a heuristic that delays CBF training until the constraint function converges, improving computational efficiency. The approach is evaluated on four scenarios and demonstrates superior performance compared to baseline methods.

## Method Summary
The ICL-CBF method uses an iterative N-iteration algorithm where a neural network constraint function ĉ_φ is first trained to classify states based on expert demonstrations and a reference controller. Once the constraint function converges, trajectories are sampled using the reference controller and labeled using the learned constraint. A neural CBF B_θ is then trained on this labeled data using supervised learning. The authors propose a heuristic to accelerate training by postponing the CBF training until the last iteration, using a grid-based approximation for the safe policy during earlier iterations.

## Key Results
- ICL-CBF achieves 0% collision rate and 80.6% success rate on single integrator scenario
- Outperforms baseline methods iDBF and ROCBF across all tested scenarios
- Performance comparable to neural CBFs trained with ground-truth safety labels
- Training time reduced from 2967s to 2369s in quadrotor scenario using the heuristic

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** If an expert demonstrator deviates from a reference controller to avoid an unspecified failure set, an inverse constraint learning (ICL) model can approximate that failure set as a binary classifier.
- **Mechanism:** The algorithm contrasts states visited by the expert with states visited by a policy attempting to maximize reward without safety constraints. It trains a neural network ĉ_φ to output high values for states the expert avoided and low values for states the expert visited, theoretically identifying the Backward Reachable Set (BRS) of the failure set.
- **Core assumption:** The expert's deviations from the reference controller are driven solely by the implicit safety constraint, and the expert data sufficiently covers the state space boundary.
- **Break condition:** If the reference controller is already safe, the "contrast" signal vanishes, and the constraint function may fail to converge or classify all states as safe.

### Mechanism 2
- **Claim:** A neural Control Barrier Function (CBF) can be trained via supervised learning using labels generated by the learned constraint function, bypassing the need for hand-specified failure sets.
- **Mechanism:** Once the constraint function ĉ_φ converges, it acts as a synthetic labeler. The system samples trajectories using the reference controller, labels states as safe (ĉ_φ(x) < δ) or unsafe, and trains the CBF B_θ to satisfy gradient conditions (safe set invariance) on this labeled data.
- **Core assumption:** The learned constraint ĉ_φ has sufficiently high precision and recall relative to the ground-truth failure set to provide meaningful supervision.
- **Break condition:** If the constraint function is overly conservative (labeling safe states as unsafe), the resulting CBF will be restricted to a small safe set, potentially preventing task completion.

### Mechanism 3
- **Claim:** Delaying the training of the neural CBF until the constraint function has converged reduces computational load without significantly degrading safety performance in low-dimensional systems.
- **Mechanism:** Instead of training the CBF B_θ in every iteration of the ICL loop, the heuristic uses a simple grid-based search to approximate the safe policy while learning the constraint. The heavy CBF training is triggered only once at the final iteration.
- **Core assumption:** A coarse, grid-based approximation of the safe policy is sufficient to explore the state space and refine the constraint function during the iterative phase.
- **Break condition:** In high-dimensional action spaces, the grid search becomes computationally intractable (curse of dimensionality), making the full iterative CBF training necessary.

## Foundational Learning

- **Concept:** **Control Barrier Functions (CBFs)**
  - **Why needed here:** This is the core mathematical structure the paper attempts to learn. You must understand that a CBF B(x) defines a "safe set" (B(x) ≥ 0) and enforces a constraint on the control input (Ḃ(x,u) ≥ -α(B(x))) to keep the system inside that set.
  - **Quick check question:** If a state x is on the boundary of the safe set (B(x)=0), what constraint does the CBF impose on the system's velocity ẋ?

- **Concept:** **Inverse Constraint Learning (ICL)**
  - **Why needed here:** The paper leverages ICL to solve the "inverse problem." Instead of finding a trajectory given constraints, it finds constraints given a trajectory (expert demonstrations).
  - **Quick check question:** In standard Inverse Reinforcement Learning (IRL), we infer the reward. What does ICL infer instead?

- **Concept:** **Control Affine Systems**
  - **Why needed here:** The paper assumes dynamics of the form ẋ = f(x) + g(x)u. This structure is essential for the CBF derivative Ḃ to be linear in control u, allowing the safety filter to be solved via a fast Quadratic Program (QP).
  - **Quick check question:** Why does the linearity of Ḃ with respect to u allow us to use a QP solver for the safety filter?

## Architecture Onboarding

- **Component map:** Expert Demonstrations + Reference Controller + System Dynamics -> Constraint Learner (ICL Module) -> Data Generator -> CBF Trainer -> Safety Filter (Runtime)
- **Critical path:** The accuracy of the Constraint Learner (ĉ_φ) is the primary bottleneck. If this module misclassifies unsafe states as safe (false negatives), the CBF will be trained on corrupted data, leading to collisions.
- **Design tradeoffs:**
  - **Threshold δ:** Tuning the decision boundary for the constraint classifier is sensitive. Values too high or low can drastically change the Safe/Collision rates.
  - **Heuristic vs. Exact:** Using grid search for the policy approximation (Heuristic) speeds up training but may reduce performance in high-dimensional systems (e.g., Quadrotor) compared to full CBF training.
- **Failure signatures:**
  - **High Collision Rate:** Suggests the learned constraint was too loose (labeled unsafe states as safe) or the CBF network capacity is insufficient.
  - **Low Success Rate (Conservatism):** Suggests the learned constraint was too tight (labeled safe states as unsafe), causing the robot to refuse to move toward the goal.
  - **Slow Training:** The heuristic failed to activate, or the action space dimension is too high for grid-based approximations.
- **First 3 experiments:**
  1. **Single Integrator (2D):** Validate the pipeline in a low-dimensional environment where the "obstacle" is explicit. Verify that ICL correctly recovers the circular unsafe set.
  2. **Ablation on δ:** Run the single integrator task while varying δ ∈ [0, 1]. Plot the trade-off curve between Collision Rate and Success Rate to select the operating point.
  3. **Dubins Car (3D):** Test generalization to nonlinear dynamics. Compare the "learned constraint" labels vs. "ground truth" labels to measure the gap introduced by the ICL step.

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- The method's performance is highly sensitive to the threshold parameter δ, which requires empirical tuning and may not generalize across different scenarios.
- The method assumes expert demonstrations contain sufficient coverage of the failure set boundary, which may not hold in practice.
- The heuristic of delaying CBF training until convergence works well for low-dimensional systems but may not scale effectively to high-dimensional action spaces due to the computational intractability of grid-based approximations.

## Confidence

- **High confidence:** The core mechanism of using ICL to learn constraint functions from expert demonstrations is theoretically grounded in prior work (Qadri et al. [28]) and demonstrated through comparative experiments.
- **Medium confidence:** The claim that training CBFs from labels generated by learned constraints produces results similar to using ground-truth labels is supported by experimental evidence but requires further validation across diverse scenarios.
- **Low confidence:** The scalability of the heuristic for accelerating training to high-dimensional systems remains uncertain, as the method relies on grid-based approximations that suffer from the curse of dimensionality.

## Next Checks

1. **Ablation study on δ:** Systematically vary δ across [0,1] for each scenario and plot the trade-off between collision rate and success rate to identify optimal operating points.
2. **Boundary coverage analysis:** Measure the overlap between states where the expert demonstrates avoidance behavior and states classified as unsafe by the learned constraint to quantify how well the constraint captures the failure set boundary.
3. **High-dimensional scalability test:** Apply ICL-CBF to a 6-DOF robotic arm scenario with nonlinear dynamics and evaluate whether the grid-based heuristic remains computationally tractable or requires alternative approximation methods.