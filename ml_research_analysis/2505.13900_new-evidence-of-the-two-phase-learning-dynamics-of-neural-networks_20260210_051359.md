---
ver: rpa2
title: New Evidence of the Two-Phase Learning Dynamics of Neural Networks
arxiv_id: '2505.13900'
source_url: https://arxiv.org/abs/2505.13900
tags:
- training
- neural
- learning
- phase
- dynamics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper identifies two key phenomena that characterize the phase
  transition in neural network training. The authors introduce an interval-wise analysis
  framework comparing model states across time windows rather than at individual points.
---

# New Evidence of the Two-Phase Learning Dynamics of Neural Networks

## Quick Facts
- arXiv ID: 2505.13900
- Source URL: https://arxiv.org/abs/2505.13900
- Authors: Zhanpeng Zhou; Yongyi Yang; Mahito Sugiyama; Junchi Yan
- Reference count: 39
- This paper identifies two key phenomena that characterize the phase transition in neural network training.

## Executive Summary
This paper identifies two key phenomena that characterize the phase transition in neural network training. The authors introduce an interval-wise analysis framework comparing model states across time windows rather than at individual points. The first phenomenon, the Chaos Effect, shows that early in training, the optimization trajectory is highly sensitive to small perturbations - even tiny parameter changes lead to significant divergence. This chaotic behavior transitions to a stable regime later in training, marking a critical phase boundary. The second phenomenon, the Cone Effect, reveals that after this transition point, the network's functional evolution becomes constrained within a narrow cone-shaped region in function space.

## Method Summary
The authors introduce an interval-wise analysis framework that compares model states across time windows rather than at individual points. They inject small parameter perturbations at various training stages and measure how these perturbations evolve. By computing kernel distances between empirical Neural Tangent Kernels (eNTKs) at different time points, they characterize the functional trajectory of the network. The framework identifies inflection points where chaotic sensitivity transitions to stability, and where kernel evolution becomes confined to a cone-shaped region.

## Key Results
- Early training exhibits chaotic sensitivity where imperceptible perturbations cause trajectory divergence, but this sensitivity diminishes after an inflection point
- After the phase transition, the empirical Neural Tangent Kernel (eNTK) evolves within a constrained cone-shaped region rather than exhibiting unconstrained exploration or freezing completely
- The cone effect provides performance advantages over purely linearized (lazy) training regimes, even though evolution is constrained

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Early training exhibits chaotic sensitivity where imperceptible perturbations cause trajectory divergence, but this sensitivity diminishes after an inflection point.
- Mechanism: A small parameter perturbation ϵ (‖ϵ‖₀ = 10⁻⁷) applied at time t₀ before the inflection point leads to significant parameter dissimilarity, loss barriers, and disagreement rates at later time t₁. After the inflection point, the same perturbation magnitude produces minimal divergence.
- Core assumption: The inflection point represents a genuine structural transition in optimization dynamics, not an artifact of the specific architectures tested.
- Evidence anchors:
  - [abstract]: "By injecting an imperceptibly small parameter perturbation at various stages, we show that the response of the network to the perturbation exhibits a transition from chaotic to stable"
  - [section 4]: "we observe that even a tiny perturbation (∥ϵ∥0 = 10⁻⁷) applied at an early time point t₀ could result in a substantial loss barrier between the resulting parameters"
  - [corpus]: Corpus evidence is limited—neighbor papers focus on sharpness dynamics and NTK evolution but do not directly replicate the chaos-to-stability transition with perturbation injection.
- Break condition: If perturbation magnitude scales with parameter norm rather than being fixed absolute, or if architectures without clear inflection points are tested (e.g., very shallow networks), the chaos effect may not manifest.

### Mechanism 2
- Claim: After the phase transition, the empirical Neural Tangent Kernel (eNTK) evolves within a constrained cone-shaped region rather than exhibiting unconstrained exploration or freezing completely.
- Mechanism: Kernel distance between eNTK at time t and reference point τ first increases then plateaus, indicating confinement. Adjacent-iterate kernel distance drops to low but non-negligible values, bounded uniformly across different intervals.
- Core assumption: The cone effect reflects genuine functional constraints rather than insufficient training duration to observe further evolution.
- Evidence anchors:
  - [abstract]: "the model's functional trajectory is confined to a narrow cone-shaped subset: while the kernel continues to change, it gets trapped into a tight angular region"
  - [section 5]: "for different referent points τ ∈ {2000, 4000, 6000, 8000}, the kernel distance between the current iterate and the reference point first increases and then keeps nearly constant"
  - [corpus]: Direct support from "On the Cone Effect in the Learning Dynamics" (workshop version by same authors) with FMR=0.0, indicating this is an extended finding rather than independently replicated.
- Break condition: If training extends significantly beyond 160 epochs, or if learning rate schedules differ substantially (e.g., cosine annealing vs. step decay), cone confinement patterns may change.

### Mechanism 3
- Claim: The cone effect provides performance advantages over purely linearized (lazy) training regimes, even though evolution is constrained.
- Mechanism: Switching from standard training to linearized training at iteration t shows test accuracy increases with t when t > 2000, indicating non-linear dynamics in the cone phase contribute meaningfully to generalization.
- Core assumption: The linearized training baseline correctly captures "lazy regime" behavior for comparison purposes.
- Evidence anchors:
  - [section 5]: "the test performance of θ_std→lin(T; t) generally increases with t, especially when t > 2000"
  - [section 5]: "the cone effect in the later training phase still offers significant advantages over the entirely lazy regime"
  - [corpus]: Neighbor papers on sharpness dynamics and NTK evolution discuss related transitions but do not directly test linearized vs. standard training switches.
- Break condition: If architectures with inherently more linear dynamics are tested, or if initialization scale is very large, the advantage of cone-phase nonlinearity may diminish.

## Foundational Learning

- Concept: **Empirical Neural Tangent Kernel (eNTK)**
  - Why needed here: The paper tracks eNTK evolution to characterize function-space dynamics; understanding how eNTK represents local linearization of the network is essential.
  - Quick check question: Can you explain why eNTK at time t is computed as H(θ_t)_ij = ⟨∂f(x_i)/∂θ, ∂f(x_j)/∂θ⟩?

- Concept: **Loss barriers and linear connectivity**
  - Why needed here: The paper uses loss barriers to determine whether perturbed trajectories land in different loss basins; this concept underpins the chaos effect validation.
  - Quick check question: If two parameter vectors have a loss barrier of zero, what does that imply about their connectivity in the loss landscape?

- Concept: **Chaos theory basics—sensitivity to initial conditions**
  - Why needed here: The "chaos effect" terminology draws from dynamical systems; understanding Lyapunov-like divergence helps interpret why small early perturbations amplify.
  - Quick check question: In chaotic systems, how does the separation between two initially close trajectories evolve over time?

## Architecture Onboarding

- Component map:
  Perturbation injection -> Checkpoint manager -> eNTK computation -> Metrics suite

- Critical path:
  1. Train baseline network, checkpoint every k iterations
  2. For each perturbation time t₀: spawn perturbed copy, train to t₁, compute all four metrics
  3. Compute pairwise kernel distance matrix S for all checkpoint pairs in single training run
  4. Identify inflection point where loss barriers and disagreement rates drop sharply

- Design tradeoffs:
  - **Perturbation magnitude**: Too large → non-chaotic divergence; too small → numerical noise. Paper uses 10⁻⁷.
  - **Checkpoint frequency**: Higher frequency captures finer dynamics but increases storage (paper uses ~500 iteration intervals for visualization)
  - ** architectures tested**: VGG-16 and ResNet-20; deeper/wider networks may shift inflection points

- Failure signatures:
  - No clear inflection point observable → may indicate hyperparameter issues (learning rate too low/high) or architecture not exhibiting two-phase behavior
  - Loss barriers remain high throughout training → perturbation magnitude may be too large, or network is undertrained
  - Kernel distance does not plateau → training may not have reached cone phase, or schedule is incompatible

- First 3 experiments:
  1. **Perturbation timing sweep**: Inject ϵ at t₀ ∈ {500, 1000, 2000, 4000, 8000}, measure (C, B, D) at fixed t₁ = 10000 to locate inflection point for your architecture.
  2. **Kernel distance matrix computation**: Train single model to convergence, compute S matrix for all checkpoint pairs, visualize to confirm cone pattern emergence.
  3. **Linearized training comparison**: Implement switching experiment—train with standard SGD until t, then switch to first-order Taylor approximation (frozen eNTK), compare final test accuracy across switching times.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What theoretical mechanisms determine the precise timing and location of the inflection point that marks the transition from chaotic to stable training dynamics?
- Basis in paper: [explicit] The authors identify inflection points empirically (e.g., ~2500 iterations for VGG-16, ~100-500 iterations for ResNet-20) and state "we defer a thorough theoretical analysis to future work."
- Why unresolved: The paper is purely empirical; no theoretical framework connects architecture, hyperparameters, or data properties to transition timing.
- What evidence would resolve it: A theoretical model predicting inflection point location based on initialization scale, learning rate, network width/depth, or dataset characteristics, validated across controlled experiments.

### Open Question 2
- Question: Do the Chaos Effect and Cone Effect generalize beyond image classification to other modalities and architectures (e.g., transformers on language tasks, MLPs on tabular data)?
- Basis in paper: [explicit] "Our current experiments mainly focus on image classification tasks... We leave the exploration of empirical evidence beyond image classification as future direction."
- Why unresolved: Only VGG-16 and ResNet-20 on CIFAR-10 were tested.
- What evidence would resolve it: Replication of the interval-wise perturbation and eNTK analysis on diverse architectures (transformers, RNNs) and modalities (text, audio, tabular).

### Open Question 3
- Question: What constrains the eNTK to evolve within a narrow cone-shaped region rather than freezing completely (lazy regime) or evolving freely?
- Basis in paper: [inferred] The paper demonstrates the Cone Effect empirically but does not explain the underlying mathematical mechanism that bounds kernel evolution within angular constraints.
- Why unresolved: The work focuses on empirical observation; the optimization geometry enabling constrained yet non-trivial evolution remains uncharacterized.
- What evidence would resolve it: Identification of invariant quantities or loss landscape structures that define cone boundaries, or a dynamical systems analysis proving cone confinement.

### Open Question 4
- Question: Does the transition point timing correlate with or causally influence final generalization performance, and can it be manipulated for better outcomes?
- Basis in paper: [inferred] The paper shows the cone effect offers advantages over lazy training but does not investigate whether transition characteristics predict or affect generalization.
- Why unresolved: No systematic study of how hyperparameter choices affecting transition timing relate to test performance.
- What evidence would resolve it: Controlled experiments shifting the transition point via learning rate schedules or initialization scales, measuring correlation with final test accuracy and loss barriers.

## Limitations
- The chaos-to-stability transition appears sensitive to perturbation magnitude, architecture depth, and learning rate schedule
- The study focuses on VGG-16 and ResNet-20 on CIFAR-10, leaving generalization to other datasets, architectures, and training regimes uncertain
- The cone effect characterization relies on kernel distance metrics that may not fully capture functional similarity in high-dimensional spaces

## Confidence
- Chaos Effect mechanism: **Medium** - Well-supported by perturbation experiments but sensitive to hyperparameter choices
- Cone Effect mechanism: **Medium-High** - Kernel distance patterns are consistent, though functional implications need further validation
- Performance advantage claim: **Medium** - Linearized training comparison shows effect but limited to specific switching protocol

## Next Checks
1. **Architecture sweep**: Test perturbation and cone effect across diverse architectures (ResNet variants, Transformers, MLPs) with varying depths and widths to assess universality.
2. **Hyperparameter sensitivity**: Systematically vary learning rates, batch sizes, and initialization scales to determine conditions under which the two-phase transition persists or disappears.
3. **Functional similarity validation**: Complement kernel distance metrics with direct function-space comparisons (e.g., cosine similarity between predictions on validation set) to verify cone confinement reflects genuine functional constraints.