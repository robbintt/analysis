---
ver: rpa2
title: 'Fair-Eye Net: A Fair, Trustworthy, Multimodal Integrated Glaucoma Full Chain
  AI System'
arxiv_id: '2601.18464'
source_url: https://arxiv.org/abs/2601.18464
tags:
- clinical
- glaucoma
- risk
- fairness
- screening
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of early glaucoma detection and
  risk prediction by developing Fair-Eye Net, a multimodal AI system that integrates
  fundus images, OCT data, visual field metrics, and demographic information. The
  core method combines a dual-stream heterogeneous architecture with uncertainty-aware
  hierarchical gating and fairness constraints.
---

# Fair-Eye Net: A Fair, Trustworthy, Multimodal Integrated Glaucoma Full Chain AI System

## Quick Facts
- arXiv ID: 2601.18464
- Source URL: https://arxiv.org/abs/2601.18464
- Authors: Wenbin Wei; Suyuan Yao; Cheng Huang; Xiangyu Gao
- Reference count: 35
- Primary result: AUC 0.912 (96.7% specificity) with 73.4% reduction in racial false-negative disparity

## Executive Summary
Fair-Eye Net is a multimodal AI system for glaucoma screening and progression prediction that integrates fundus images, OCT structural metrics, visual field functional indices, and demographic factors. The system employs a dual-stream heterogeneous architecture with decision-level fusion, uncertainty-aware hierarchical gating, and fairness constraints to achieve equitable performance across racial subgroups. Key innovations include race-specific calibration reducing false-negative disparities from 12.31% to 3.28%, and selective prediction via uncertainty thresholds enabling safe clinician referrals.

## Method Summary
Fair-Eye Net uses a dual-stream architecture combining ResNet-50 (pretrained on fundus images) for visual data and a Densely Connected Clinical Encoder for structured clinical metrics. The system performs decision-level fusion with weights α_vis=0.6 and α_clin=0.4, applies Laplacian variance filtering and MC Dropout with TTA for uncertainty estimation, and implements race-specific calibration at inference. Multi-task learning optimizes both binary classification (screening) and regression (progression prediction) with combined loss functions. The system operates on Harvard-GDP (main training), validated on GRAPE (OOD), and audited on Harvard-GF for fairness.

## Key Results
- Achieved AUC of 0.912 with 96.7% specificity for glaucoma screening
- Reduced racial false-negative disparity by 73.4% (from 12.31% to 3.28%)
- Enabled 3-12 month early risk alerts with 92% sensitivity and 88% specificity
- Maintained stable cross-domain performance with AUC of 0.869 on GRAPE dataset

## Why This Works (Mechanism)

### Mechanism 1
Dual-stream heterogeneous fusion improves detection of borderline cases by combining complementary evidence sources. Visual stream captures texture/structural patterns while clinical stream preserves non-linear relationships among tabular metrics. Decision-level weighted fusion uses images as primary evidence with clinical calibration. Core assumption: structural and functional modalities provide partially independent diagnostic signals. Evidence: removing clinical information reduced sensitivity from 83.7% to 80.9%. Break condition: if visual and clinical streams are highly correlated, fusion gains diminish.

### Mechanism 2
Hierarchical uncertainty gating enables safe selective prediction by rejecting low-confidence cases for clinician review. Stage 1 uses Laplacian Variance filter (τ_blur=100) to reject physically low-quality images. Stage 2 employs MC Dropout (p=0.3) with TTA (N=15 passes) to estimate epistemic uncertainty via predictive variance. Core assumption: predictive variance correlates with actual error risk. Evidence: uncertainty scores exceeding threshold designated as "cognitive blind spots." Break condition: if uncertainty estimates are miscalibrated, rejection threshold fails to filter true risk.

### Mechanism 3
Race-specific calibration reduces false-negative disparities without degrading overall discriminative performance. The system applies fairness constraints during training combined with subgroup-aware calibration at inference. Core assumption: model representations are sufficiently expressive that recalibration can shift decision boundaries per-group. Evidence: after applying race-specific calibration, overall AUC remained essentially unchanged (AUC≈0.874) while ΔFNR decreased to 0.0328. Break condition: if disease prevalence shifts across deployment sites, group-specific thresholds may overfit.

## Foundational Learning

- **Multimodal fusion strategies (early vs. decision-level)**: Fair-Eye uses decision-level weighted fusion, not feature-level concatenation. Understanding when to fuse matters for architecture choice. Quick check: Would concatenating raw visual and clinical features before a shared classifier preserve the modality-specific inductive biases that separate encoders provide?

- **Epistemic vs. aleatoric uncertainty**: MC Dropout estimates epistemic uncertainty (model ignorance), not inherent data noise. The gating mechanism assumes epistemic uncertainty flags out-of-distribution risk. Quick check: If a sample has high aleatoric noise (e.g., blurry but valid image), should MC Dropout uncertainty be the basis for rejection, or should a separate quality gate handle it?

- **Fairness–performance trade-offs in calibration**: The paper shows ΔFNR reduction with stable AUC, suggesting the trade-off is not inevitable. Quick check: If two subgroups have non-overlapping risk score distributions, can calibration alone equalize FNR without hurting AUC, or would representation-level interventions be required?

## Architecture Onboarding

- **Component map**: Fundus images + RNFLT heatmaps → ResNet-50 (visual stream) → 2048-dim feature vector; structured clinical tabular data → Densely Connected Clinical Encoder → clinical features; visual and clinical features → decision-level weighted fusion (α_vis=0.6, α_clin=0.4) → screening head (binary cross-entropy) + regression head (Smooth L1 loss) → uncertainty gate (Laplacian variance + MC Dropout + TTA) → calibrated output

- **Critical path**: Data preprocessing → dual-stream encoding → fusion → uncertainty gating → (if pass) task heads → calibrated output; (if reject) flag for clinician review

- **Design tradeoffs**: Decision-level fusion vs. feature-level (simpler, more interpretable, but may miss cross-modal interactions); high specificity (96.7%) at some sensitivity cost (prioritizes reducing false alarms); fairness calibration post-training (avoids complex constrained optimization, but may not address representation-level bias)

- **Failure signatures**: High rejection rate (τ_unc too low or domain shift); FNR gap persists after calibration (subgroup representations misaligned); MD predictions erratic (Smooth L1 may not handle outliers well)

- **First 3 experiments**:
  1. Reproduce ablation on held-out split: Remove clinical stream, TTA, and MC Dropout one at a time; confirm sensitivity drops and fairness gap changes match reported values (±2% tolerance).
  2. Calibration sweep on external dataset: Using GRAPE or Harvard-GF, sweep τ_unc and plot coverage vs. accuracy and FNR gap; identify operating point where referral rate is clinically acceptable (<20%).
  3. Subgroup stratified evaluation: On Harvard-GF, compute per-race AUC, FNR, and calibration curves before/after fairness calibration; verify ΔFNR reduction is not driven by a single subgroup improving at others' expense.

## Open Questions the Paper Calls Out

- **Can Fair-Eye Net maintain its reported discrimination (AUC 0.912) and fairness gains in prospective, multi-center clinical workflows?**: Current results derive from retrospective datasets which may not fully capture live clinical deployment noise and variability. Prospective performance metrics collected from diverse active clinical sites would resolve this.

- **How robust is the race-specific calibration strategy when facing severe cross-domain shifts involving new devices or demographic mixes?**: While the model reduced FNR disparity on Harvard-GF dataset, it is unclear if this calibration holds when input distribution shifts significantly. Stability of the ∆FNR metric on external datasets with different device manufacturers would resolve this.

- **What is the optimal trade-off between referral burden and clinical safety when setting risk alert thresholds?**: Current thresholds were empirically determined via grid search to balance accuracy but lack integration with specific clinical costs like referral workload. A utility analysis correlating various threshold settings with actual changes in referral rates would resolve this.

## Limitations

- Fairness constraint formulation lacks explicit equations or training objective details, making precise reproduction difficult
- Training schedule parameters (batch size, epochs, LR schedule) not reported, potentially affecting convergence and performance reproducibility
- Subgroup analysis limited to racial groups; intersectional fairness (race×age×sex) not examined

## Confidence

- **High confidence**: Multimodal fusion improves borderline case detection (supported by ablation showing sensitivity drop from 83.7% to 80.9% when clinical data removed)
- **Medium confidence**: Fairness calibration reduces racial FNR disparity by 73.4% (reported numbers are specific, but calibration methodology lacks algorithmic detail)
- **Medium confidence**: Uncertainty gating enables safe selective prediction (mechanism is sound, but calibration quality on external datasets is not demonstrated)

## Next Checks

1. **Implement and validate the exact DCCE architecture**: Build the densely connected clinical encoder with specified growth rate k=32; verify layer connectivity matches the paper's description; test on synthetic tabular data to ensure non-linear relationship preservation.

2. **Reconstruct and test the fairness calibration procedure**: Implement the race-specific calibration algorithm based on inference-time threshold adjustment; apply to Harvard-GF; verify FNR gap reduction from 12.31% to 3.28% while maintaining AUC stability.

3. **Evaluate uncertainty calibration on external dataset**: Apply the MC Dropout + TTA uncertainty gating to GRAPE; compute coverage-accuracy trade-off curves; determine if τ_unc thresholds from Harvard-GDP transfer to OOD data without degradation.