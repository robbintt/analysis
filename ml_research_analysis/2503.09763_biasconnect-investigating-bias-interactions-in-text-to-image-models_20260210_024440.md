---
ver: rpa2
title: 'BiasConnect: Investigating Bias Interactions in Text-to-Image Models'
arxiv_id: '2503.09763'
source_url: https://arxiv.org/abs/2503.09763
tags:
- bias
- gender
- intersectional
- biases
- causal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: BiasConnect introduces a causal framework to analyze bias interactions
  in text-to-image models, treating biases as interrelated rather than independent.
  Using counterfactual prompts and pairwise causal discovery, it identifies significant
  intersectional bias relationships and quantifies their impact via Intersectional
  Sensitivity scores.
---

# BiasConnect: Investigating Bias Interactions in Text-to-Image Models

## Quick Facts
- **arXiv ID**: 2503.09763
- **Source URL**: https://arxiv.org/abs/2503.09763
- **Reference count**: 40
- **Primary result**: 0.696 correlation between estimated and actual post-mitigation bias effects across 26 occupations

## Executive Summary
BiasConnect introduces a causal framework to analyze bias interactions in text-to-image models, treating biases as interrelated rather than independent. Using counterfactual prompts and pairwise causal discovery, it identifies significant intersectional bias relationships and quantifies their impact via Intersectional Sensitivity scores. Experiments show BiasConnect achieves a 0.696 correlation between estimated and actual post-mitigation bias effects across 26 occupations. The method enables optimal bias mitigation strategy selection, comparative analysis across five TTI models, and reveals discrepancies between generated and real-world bias distributions.

## Method Summary
BiasConnect analyzes bias interactions in text-to-image models by treating bias mitigation as an intervention. For each occupation prompt, it generates counterfactual variations across 8 bias axes (gender, age, ethnicity, environment, disability, emotion, bodytype, clothing). The method generates 48 images per prompt using the target TTI model, extracts attributes via MiniGPT-v2 VQA, and builds contingency tables for each bias pair. Chi-square conditional independence testing identifies statistically significant bias interactions, while Wasserstein-1 distance measures distributional shifts toward an ideal distribution. Intersectional Sensitivity scores quantify the positive or negative effects of mitigating one bias axis on others.

## Key Results
- Achieves 0.696 correlation between estimated and actual post-mitigation bias effects across 26 occupations
- Identifies optimal bias mitigation strategies by comparing individual sensitivity scores across all axes
- Reveals discrepancies between generated bias distributions and real-world demographics in TIBET dataset
- Robustness analysis shows method remains stable under moderate image reduction (2.4 edge changes with 16.6% fewer images)

## Why This Works (Mechanism)

### Mechanism 1
Counterfactual prompt interventions reveal causal dependencies between bias axes by explicitly modifying bias attributes in input prompts and measuring resulting distribution shifts on OTHER bias axes. This treats bias mitigation as an intervention rather than passive observation.

### Mechanism 2
Chi-square conditional independence testing identifies statistically significant bias interactions by capturing attribute co-occurrence across counterfactual image sets. Low p-values (<0.0001) indicate strong dependency between bias axes.

### Mechanism 3
Intersectional Sensitivity scores quantify positive/negative mitigation effects using Wasserstein-1 distance to measure how far a distribution is from an "ideal" distribution. Positive values indicate mitigating one bias improves another, while negative values indicate deterioration.

## Foundational Learning

- **Causal Intervention vs Correlation**: Why needed - distinguishes approach from mere correlation analysis by using prompt modification as intervention. Quick check - If you observe that gender and clothing bias correlate, can you claim mitigating one causes changes in the other? (Answer: No—need intervention.)

- **Wasserstein-1 (Earth Mover's) Distance**: Why needed - core metric for measuring distributional shift toward/away from ideal. Quick check - What does a Wasserstein distance of 0 mean? (Answer: Identical distributions.)

- **VQA-Based Attribute Extraction**: Why needed - entire pipeline depends on extracting bias attributes from generated images using MiniGPT-v2. Quick check - Why use multiple-choice questions rather than open-ended VQA? (Answer: Constrains output space for reliable extraction.)

## Architecture Onboarding

- **Component map**: Prompt Generator -> TTI Model -> VQA Module -> Causal Discovery -> Treatment Estimator
- **Critical path**: Original prompt + counterfactuals → Generate 48 images each → VQA extraction → Contingency tables → Statistical testing → Sensitivity computation
- **Design tradeoffs**: Sample size (48 images) balances reliability vs cost; uniform ideal distribution simplifies interpretation but may not reflect real-world demographics; pairwise approach misses indirect causal effects
- **Failure signatures**: Too few images (<16) cause unreliable χ² estimates; VQA error >20% degrades sensitivity estimates; ambiguous prompts trigger person-detection filter
- **First 3 experiments**: 
  1. Replicate Figure 2 on a single occupation prompt: Generate counterfactuals, extract attributes, build contingency table, verify χ² p-value and IS score match reported values
  2. Robustness sweep: Run full pipeline with 48, 32, 24, 16 images per prompt; plot edge changes and sensitivity variance
  3. Cross-model comparison: Run same occupation prompt set on SD 1.4 vs Flux; compare aggregated causal graphs to identify model-specific bias entanglements

## Open Questions the Paper Calls Out

- **Indirect causal effects**: How to extend framework to identify and quantify indirect causal effects between bias axes rather than restricting analysis to direct pairwise interactions? Current setup doesn't allow reasoning about indirect causal effects (e.g., A → B → C).

- **Optimal mitigation strategy**: How to mathematically integrate Intersectional Sensitivity scores into an optimization objective to determine a single intervention strategy that mitigates multiple bias axes simultaneously? Tool cannot develop optimal bias mitigation strategy that utilizes the tool to mitigate multiple biases simultaneously.

- **VQA bias impact**: To what extent does the inherent social bias of the Visual Question Answering (VQA) model used for attribute extraction systematically distort the BiasConnect causal graph? If VQA model systematically misclassifies intersectional subgroups, the resulting causal graph may attribute the VQA's bias to the TTI model.

## Limitations

- The counterfactual intervention approach assumes prompt modifications approximate real mitigation strategies, which remains unvalidated
- All bias measurements depend on MiniGPT-v2 accuracy, with 10% VQA error rates already causing 3.65 edge changes
- The uniform distribution as fairness ideal is arbitrary and may not reflect societal goals or real-world demographics

## Confidence

- **High Confidence**: Pairwise causal discovery methodology (χ² testing on counterfactual distributions) is statistically sound and reproducible. Correlation results (0.696) with ITI-GEN provide strong validation.
- **Medium Confidence**: Intersectional Sensitivity scores as measures of mitigation impact, contingent on VQA accuracy and ideal distribution choice. Causal interpretations are plausible but require further validation.
- **Low Confidence**: Claims about real-world bias discrepancies and unintended mitigation consequences, as these depend heavily on TIBET dataset representativeness and the assumption that generated biases reflect actual model behavior.

## Next Checks

1. **Causal Validation**: Run the same counterfactual prompts through an actual bias mitigation technique (e.g., ITI-GEN) and compare the resulting bias distributions to those predicted by BiasConnect's IS scores. Measure correlation between predicted and actual mitigation effects.

2. **VQA Error Sensitivity**: Systematically inject controlled noise into VQA outputs (0%, 10%, 20%, 30% random attribute swaps) and measure degradation in causal graph structure and IS score stability. Determine error threshold beyond which the method becomes unreliable.

3. **Ideal Distribution Impact**: Repeat the full analysis using three different ideal distributions: uniform, real-world demographic distributions, and a distribution weighted toward underrepresented groups. Compare resulting causal graphs and IS scores to assess sensitivity to this critical assumption.