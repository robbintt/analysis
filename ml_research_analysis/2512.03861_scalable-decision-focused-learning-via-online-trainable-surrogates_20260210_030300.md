---
ver: rpa2
title: Scalable Decision Focused Learning via Online Trainable Surrogates
arxiv_id: '2512.03861'
source_url: https://arxiv.org/abs/2512.03861
tags:
- training
- regret
- loss
- surrogate
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the scalability challenge in Decision Focused
  Learning (DFL) by proposing a surrogate-based approach that reduces expensive solver
  calls during training. The method uses Gaussian Processes (GPs) with stochastic
  smoothing and importance sampling to create an asymptotically unbiased surrogate
  loss function that can be differentiated efficiently.
---

# Scalable Decision Focused Learning via Online Trainable Surrogates

## Quick Facts
- arXiv ID: 2512.03861
- Source URL: https://arxiv.org/abs/2512.03861
- Authors: Gaetano Signorelli; Michele Lombardi
- Reference count: 18
- Primary result: GP-based surrogate reduces solver calls by up to two orders of magnitude while maintaining decision quality

## Executive Summary
This paper addresses the scalability challenge in Decision Focused Learning by proposing a surrogate-based approach that reduces expensive solver calls during training. The method uses Gaussian Processes with stochastic smoothing and importance sampling to create an asymptotically unbiased surrogate loss function that can be differentiated efficiently. Unlike previous approaches, it provides local confidence estimates allowing dynamic switching to a fallback method when needed. The approach is designed for black-box settings without requiring explicit problem structure knowledge.

## Method Summary
The method uses per-example Gaussian Process surrogates to approximate the regret landscape of optimization problems. Each GP maps predicted parameters to regret values using an RBF kernel. Stochastic smoothing via importance sampling enables gradient flow through piecewise-constant loss landscapes while reusing expensive evaluations. Local confidence estimation from GP variance allows dynamic switching between fast surrogate and accurate fallback (SFGE). Sample sharing across similar examples provides optional acceleration. The system pre-trains GPs with Latin Hypercube samples, then trains the predictor using a combined surrogate+fallback loss with confidence-based switching.

## Key Results
- Reduces solver calls by up to two orders of magnitude compared to state-of-the-art approaches
- Maintains comparable or better decision quality across Knapsack, Weighted Set Multi-Cover, and synthetic benchmarks
- Scales well to high-dimensional problems (dim(Y)=64 in Toy benchmark)
- Consistent performance across different problem classes with solver calls per instance reduced from 1000+ to 10-40

## Why This Works (Mechanism)

### Mechanism 1
Gaussian Process surrogates provide asymptotically unbiased regret estimation without irreducible approximation error. Each training example gets a dedicated GP with RBF kernel that maps predicted parameters to regret values. GPs are universal approximators—given sufficient samples uniformly distributed in prediction space, the approximation error approaches 0+ even for discontinuous regret landscapes. The surrogate is trained to approximate a smoothed version of regret, but as smoothing parameter σ→0 and data grows, the smoothed regret converges to true regret.

### Mechanism 2
Stochastic smoothing with importance sampling enables gradient flow through piecewise-constant loss landscapes while reusing expensive evaluations. Instead of evaluating regret at a single point ŷ, the method computes expected regret under N(ŷ, σ) perturbations. Rather than Monte Carlo sampling (which would require many new solver calls per gradient step), importance sampling reweights previously evaluated points using density ratio w(ŷ, ŷ') = φ(ŷ'; ŷ, σ)/q(ŷ'). This allows computing smoothed regret from a shared pool of samples collected during training.

### Mechanism 3
Local confidence estimation enables dynamic switching between fast surrogate and accurate fallback, amortizing computational cost. GPs naturally provide predictive variance alongside mean estimates. When standard deviation exceeds threshold β, the system falls back to SFGE (which evaluates true regret via solver calls) and adds the new sample to the GP. This creates an adaptive loop: confident regions use cheap surrogate evaluations; uncertain regions trigger refinement.

## Foundational Learning

- **Gaussian Process Regression**: GPs must be trained, queried for mean/variance, and differentiated through. Requires understanding kernel functions, covariance matrices, and the relationship between data density and predictive uncertainty. Quick check: Given a GP with RBF kernel trained on 5 points, does predictive variance increase or decrease as you query farther from training data?

- **Importance Sampling**: Stochastic smoothing relies on reweighting previously collected samples. Understanding how density ratios work, when importance weights have high variance, and how distribution overlap affects estimator quality is critical for debugging gradient issues. Quick check: If proposal distribution q has low probability where target p is high, what happens to importance weights and estimator variance?

- **Score Function Gradient Estimation (REINFORCE-style)**: The fallback method SFGE uses policy-gradient techniques for black-box differentiation. Even if using the GP surrogate, understanding the fallback helps diagnose when/why the system switches modes and how smoothing connects to gradient variance. Quick check: Why does REINFORCE have high variance, and how does stochastic smoothing help?

## Architecture Onboarding

- **Component map**: Pretraining (LHS sampling → solver calls → regret vectors) → GP initialization (one per example) → Training loop (forward pass → GP query → confidence branch → loss aggregation) → GP update trigger (retrain with importance sampling) → Predictor update (Adam optimizer)

- **Critical path**: Pretraining coverage determines initial GP confidence and early-stage surrogate quality. Threshold β controls exploitation/exploration balance. Smoothing parameter σ governs gradient informativeness vs. landscape fidelity. Sample sharing (if enabled) can accelerate but risks negative transfer.

- **Design tradeoffs**: Per-example GP vs. shared GP (per-example avoids scaling issues with high-dimensional context but prevents natural information sharing). Higher β → fewer solver calls but risk spurious optima. Larger σ → stronger gradients but distorted landscape.

- **Failure signatures**: Exploding solver calls despite surrogate (β too low or GP variance poorly calibrated). High regret with few solver calls (β too high or σ too large). GP training divergence (insufficient samples or RBF length-scale prior mismatched). Sample sharing hurts quality (distance threshold too permissive). Gradient vanishes (σ too small for piecewise-constant regions).

- **First 3 experiments**: 1) Reproduce Toy benchmark at dim(Y)=64 to validate GP smoothing and differentiation pipeline. 2) Ablate β on KP-50 weights to establish operating curve for compute budget vs quality. 3) Stress-test WSMC with increasing sets (50→250→500) to confirm scalability under real solver costs.

## Open Questions the Paper Calls Out
None

## Limitations
- Requires sufficient pretraining samples per example, which may become prohibitive for very large datasets
- Performance depends critically on choice of smoothing parameter σ and confidence threshold β, which are tuned per benchmark rather than derived from theory
- Sample sharing mechanism introduces additional hyperparameters that can cause negative transfer if regret landscapes across examples are dissimilar

## Confidence
- High confidence in GP surrogate reducing solver calls while maintaining decision quality (consistent experimental results across three benchmarks)
- Medium confidence in asymptotic unbiasedness claim (proof relies on smoothness assumptions and uniform sampling that may not hold in practice)
- Low confidence in sample sharing mechanism's general applicability (lack of theoretical justification and mixed empirical results)

## Next Checks
1. Perform ablation studies varying σ and β systematically across all benchmarks to establish Pareto frontiers between solver calls and regret
2. Test GP surrogate performance on problems with high-dimensional prediction spaces (dim(Y) > 100) to validate scalability claims
3. Evaluate impact of non-uniform sample distributions in pretraining on approximation error to test uniform sampling assumption underlying asymptotic unbiasedness claim