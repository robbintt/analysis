---
ver: rpa2
title: On the Role of Temperature Sampling in Test-Time Scaling
arxiv_id: '2510.02611'
source_url: https://arxiv.org/abs/2510.02611
tags:
- scaling
- temperature
- reasoning
- sampling
- wang
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper studies how temperature sampling affects test-time
  scaling (TTS) in large language models. TTS improves reasoning by generating multiple
  reasoning traces and selecting the best one, but prior work scaling only the number
  of samples K shows diminishing returns: accuracy plateaus and some hard problems
  remain unsolved regardless of how many traces are drawn.'
---

# On the Role of Temperature Sampling in Test-Time Scaling
arXiv ID: 2510.02611
Source URL: https://arxiv.org/abs/2510.02611
Reference count: 40
Key outcome: Multi-temperature sampling in test-time scaling yields 7.3 percentage points accuracy gain over single-temperature scaling.

## Executive Summary
This paper studies how temperature sampling affects test-time scaling (TTS) in large language models. TTS improves reasoning by generating multiple reasoning traces and selecting the best one, but prior work scaling only the number of samples K shows diminishing returns: accuracy plateaus and some hard problems remain unsolved regardless of how many traces are drawn. The authors find that different sampling temperatures solve different subsets of problems, meaning single-temperature scaling only explores part of the model's potential. By scaling across temperatures instead of just K, the reasoning boundary is enlarged. Experiments across Qwen3 models (0.6B–8B) and five benchmarks show that multi-temperature scaling yields an additional 7.3 percentage points in accuracy over single-temperature TTS. This approach enables base models to match the performance of reinforcement learning-trained counterparts without extra post-training. To make this efficient, the authors propose a multi-temperature voting method that exits early on easy questions, reducing computation.

## Method Summary
The authors conduct experiments using Qwen3 models (0.6B-8B) across five benchmarks: AIME 2024/2025, MATH500, LiveCodeBench, and Hi-ToM. For each question, they sample 1,024 traces at temperatures ranging from 0.0 to 1.2 in 0.1 increments. They compare Pass@K (probability of at least one correct answer in K samples) between single-temperature scaling and multi-temperature aggregation. The efficient multi-temperature voting method uses two-stage consensus: first within each temperature (τ_intra=0.8), then across temperatures (τ_cross=1.0), allowing early exit for questions reaching consensus. All inference uses vLLM for parallel sampling.

## Key Results
- Multi-temperature scaling yields an additional 7.3 percentage points in accuracy over single-temperature TTS
- Different temperatures solve disjoint subsets of problems, expanding the reasoning boundary
- Increasing sample count K alone plateaus, while temperature scaling continues to yield improvements
- Base models using multi-temperature scaling match the performance of RL-trained models without extra post-training
- The multi-temperature voting method with early exit reduces computation while maintaining nearly the same performance

## Why This Works (Mechanism)
### Mechanism 1
- Claim: Multi-temperature sampling expands the solvable problem boundary compared to single-temperature sampling.
- Mechanism: Different temperatures access distinct problem subsets. Lower temperatures produce more deterministic outputs, favoring problems with a dominant reasoning path. Higher temperatures increase stochasticity, enabling exploration needed for problems requiring creative pivots. The union of solved sets across temperatures exceeds any single set.
- Core assumption: A capable verifier exists to identify correct solutions from noisy candidates, particularly for sparse correct traces at non-optimal temperatures.
- Evidence anchors:
  - [abstract] "different sampling temperatures solve different subsets of problems... single-temperature scaling explores only part of a model's potential"
  - [section 2.3] "each question has a different optimal temperature, and no single value performs best across the board"
  - [corpus] Weak direct support; neighboring papers emphasize diversity and efficiency in TTS but do not isolate temperature as a scaling dimension
- Break condition: If a problem is "impossible" (unsolved across all temperatures), or if the verifier cannot reliably distinguish correct traces at high entropy, gains saturate.

### Mechanism 2
- Claim: Scaling sample count K alone exhibits diminishing returns; temperature scaling provides an orthogonal compute axis.
- Mechanism: For a fixed temperature, increasing K eventually plateaus because the accessible problem set is constrained by that temperature's exploration pattern. Temperature scaling alters the exploration pattern itself, unlocking previously inaccessible problems.
- Core assumption: Problems cluster into "easy" (solved universally), "hard" (temperature-sensitive), and "impossible" (unsolvable without additional training).
- Evidence anchors:
  - [abstract] "increasing the number of samples K steadily improves accuracy... at large K, further scaling yields no gains"
  - [section 2.4] "increasing K from 1,024 to 13,312 does not solve any additional problems... temperature yields a 6.67% improvement"
  - [corpus] Consistent with survey findings that TTS gains saturate with sample count alone
- Break condition: If the model lacks latent capability for a problem, temperature scaling cannot help; training-based improvements are required.

### Mechanism 3
- Claim: Multi-temperature voting with early exit reduces overhead while preserving boundary expansion.
- Mechanism: "Easy" problems reach consensus quickly across temperatures (high intra- and cross-temperature agreement). Once consensus is detected, sampling stops, reserving compute for "hard" problems lacking consensus.
- Core assumption: Easy problems exhibit low entropy and high agreement; hard problems exhibit higher entropy and disagreement.
- Evidence anchors:
  - [abstract] "multi-temperature voting method that exits easy questions early"
  - [section 5.1] "reduces the computation required for temperature scaling across tasks, while maintaining nearly the same performance"
  - [corpus] Similar early-exit strategies appear in TTS efficiency literature (adaptive stopping, dynamic allocation)
- Break condition: If consensus is misleading (agreement on incorrect answer) or entropy is uninformative for a problem class, early exit may misclassify problems.

## Foundational Learning
- Concept: Temperature sampling in autoregressive models
  - Why needed here: Understanding how temperature reshapes the next-token distribution is essential to grasping why diverse temperatures yield diverse solution paths.
  - Quick check question: What happens to the token distribution when T→0 versus T>>1?

- Concept: Pass@K and Best-of-N evaluation
  - Why needed here: The paper's central metric; measures the probability of at least one correct sample among K draws, directly quantifying boundary expansion.
  - Quick check question: If Pass@1,024=0.6 and Avg@1,024=0.15, what does this imply about solution sparsity?

- Concept: Verifiers in test-time scaling
  - Why needed here: Without a verifier to select correct traces, increased sampling yields noise; the paper assumes oracle verification for measurement.
  - Quick check question: How does verifier quality affect the realized gains from temperature scaling?

## Architecture Onboarding
- Component map:
  - Sampler -> Answer Extractor -> Verifier -> Voting Logic -> Exit Controller -> Aggregator

- Critical path:
  1. Initialize per-temperature candidate pools for all questions.
  2. Per round: sample one trace per temperature per active question.
  3. Run intra-temperature voting; if any temperature lacks consensus, continue sampling.
  4. If all temperatures pass, run cross-temperature voting; if cross-consensus met, mark question as "easy" and exit.
  5. After max rounds or full exit, use verifier to select final answers from pooled candidates.

- Design tradeoffs:
  - **Temperature range**: Broader ranges increase boundary expansion but raise compute; paper uses 0.0–1.4 with subset pruning.
  - **Thresholds**: Higher τ_intra/τ_cross reduce false early exits but increase sampling cost.
  - **Verifier dependency**: Oracle verification is ideal; weaker verifiers may misclassify, reducing realized gains.
  - **Model size**: Stronger models classify more problems as "easy," enabling greater efficiency savings.

- Failure signatures:
  - **Stagnant Pass@K**: If increasing temperatures yields no new solved problems, model may lack latent capability for remaining questions.
  - **High early-exit error rate**: Consensus on incorrect answers suggests thresholds too low or problem distribution misaligned with assumptions.
  - **Entropy inversion**: For hard problems, correct traces do not reliably show lower entropy, breaking entropy-guided exit heuristics.

- First 3 experiments:
  1. **Baseline sweep**: For a fixed model, sweep T∈{0.0,0.3,...,1.2} with K=1,024 per temperature on a reasoning benchmark; compute Pass@K per temperature and Pass@All across temperatures.
  2. **K vs T ablation**: Hold total compute budget constant; compare Pass@All when allocating budget to (a) single-T with high K vs (b) multi-T with split K.
  3. **Early-exit validation**: Implement multi-temperature voting with τ_intra=0.8, τ_cross=1.0; measure compute reduction and verify Pass@All is preserved.

## Open Questions the Paper Calls Out
- Question: Can variable temperature within a single reasoning trace further improve reasoning ability?
  - Basis in paper: [explicit] Discussion section states: "An interesting direction for future work is to study how variable temperature within a single trace may further influence reasoning ability."
  - Why unresolved: All experiments use fixed temperature per trace; the effect of dynamically adjusting temperature during generation is unexplored.
  - What evidence would resolve it: Experiments comparing fixed-T vs. dynamic-T sampling schedules across the same benchmarks, measuring Pass@K improvements.

- Question: Does temperature scaling generalize beyond the Qwen3 architecture to other model families?
  - Basis in paper: [inferred] All experiments use Qwen3 models (0.6B–8B) and one RL variant (Polaris) derived from Qwen; no other architectures tested.
  - Why unresolved: Different architectures may have different logit distributions or training objectives that alter how temperature affects sampling diversity and correctness.
  - What evidence would resolve it: Replicating the temperature scaling experiments on LLaMA, Mistral, and other model families, comparing Pass@K gains.

- Question: What is the underlying mechanism causing different temperatures to solve disjoint subsets of hard problems?
  - Basis in paper: [inferred] The paper demonstrates empirically that temperatures solve different subsets (Figure 2b) but provides limited mechanistic explanation beyond entropy observations.
  - Why unresolved: Entropy analysis explains some behavior but not why a specific problem requires T=1.1 vs. T=0.7; the phenomenon remains correlational.
  - What evidence would resolve it: Probing experiments (e.g., layer-wise logit analysis, attention patterns) on problems with clear temperature preferences to identify causal factors.

- Question: How does temperature scaling interact with imperfect verifiers in real-world deployment?
  - Basis in paper: [explicit] Section 5.2 notes verification cost as critical; experiments use ground-truth verification to avoid confounds from verifier quality.
  - Why unresolved: Real applications must rely on learned verifiers or self-consistency, which may bias temperature selection or fail to identify correct traces.
  - What evidence would resolve it: Experiments with learned reward models or self-consistency voting, comparing temperature scaling performance against ground-truth verification baselines.

## Limitations
- Verifier Quality Dependency: The paper's reported gains assume access to an oracle verifier that perfectly identifies correct answers, which is not available in practice.
- Dataset Composition: The "impossible" problems that remain unsolved across all temperatures are not characterized, limiting understanding of where temperature scaling provides practical utility.
- Generalizability Across Model Families: Experiments are conducted exclusively on Qwen3 models, leaving open whether the observed gains transfer to other architectures.

## Confidence
- High Confidence: The core empirical finding that different temperatures solve different subsets of problems is well-supported by the experimental data across multiple benchmarks.
- Medium Confidence: The mechanism explaining why temperature scaling works (exploration vs. exploitation at different temperatures) is plausible but not directly measured.
- Low Confidence: The practical efficiency gains from the early-exit voting method depend heavily on the problem distribution being skewed toward "easy" questions.

## Next Checks
1. **Verifier Sensitivity Analysis**: Implement the multi-temperature approach using learned verifiers of varying quality (e.g., GPT-4o-mini reward model vs. smaller reward models). Measure how verifier accuracy affects the realized gains from temperature scaling to quantify the oracle assumption's impact.

2. **Problem Type Characterization**: Analyze the solved vs. unsolved problem distributions across temperatures to identify which problem types benefit most from temperature scaling. This would reveal whether gains are concentrated in specific reasoning domains or broadly distributed.

3. **Cross-Model Validation**: Replicate the temperature scaling experiments on non-Qwen3 models (e.g., GPT-4o, Claude-3, Llama-3) to assess whether the observed gains generalize across different model architectures and training approaches.