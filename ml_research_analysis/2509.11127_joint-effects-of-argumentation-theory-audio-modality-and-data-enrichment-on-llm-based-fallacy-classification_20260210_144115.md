---
ver: rpa2
title: Joint Effects of Argumentation Theory, Audio Modality and Data Enrichment on
  LLM-Based Fallacy Classification
arxiv_id: '2509.11127'
source_url: https://arxiv.org/abs/2509.11127
tags:
- fallacy
- context
- prompt
- audio
- emotional
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study examined how adding context and emotional tone metadata\
  \ affects large language model performance in classifying fallacies from political\
  \ debates. Using Qwen-3 (8B), it tested three prompting strategies\u2014basic, pragma-dialectical,\
  \ and periodic table of arguments\u2014under three input settings: text-only, text\
  \ with context, and text with both context and audio-derived emotional tone."
---

# Joint Effects of Argumentation Theory, Audio Modality and Data Enrichment on LLM-Based Fallacy Classification

## Quick Facts
- arXiv ID: 2509.11127
- Source URL: https://arxiv.org/abs/2509.11127
- Reference count: 9
- This study examined how adding context and emotional tone metadata affects large language model performance in classifying fallacies from political debates.

## Executive Summary
This study examined how adding context and emotional tone metadata affects large language model performance in classifying fallacies from political debates. Using Qwen-3 (8B), it tested three prompting strategies—basic, pragma-dialectical, and periodic table of arguments—under three input settings: text-only, text with context, and text with both context and audio-derived emotional tone. Results showed that while context helped in some cases, emotional tone metadata often reduced performance by biasing the model toward Appeal to Emotion classifications. Base prompts without added inputs consistently outperformed enhanced ones, suggesting that additional context may distract rather than aid reasoning. The highest accuracy was achieved with the basic pragma-dialectical prompt. Ad Hominem was classified most accurately, while Slippery Slope was the most challenging.

## Method Summary
The study used Qwen-3 8B with temperature=0.6, top-p=0.95, top-k=20 to classify fallacies from US presidential debate transcripts. Three prompting strategies (Basic, Pragma-Dialectics, Periodic Table of Arguments) were tested across three input conditions (text-only, text+context, text+context+audio). Audio features were extracted using wav2vec 2.0-large and normalized to [-1, 1], then discretized into low/moderate/high using ±0.33 thresholds. Performance was evaluated on a balanced test set (120 samples, 20 per class) using accuracy, macro precision/recall/F1, and per-class F1 metrics.

## Key Results
- Emotional tone metadata biases the model toward Appeal to Emotion classifications, reducing logical reasoning performance
- Basic prompts without additional inputs consistently outperformed enhanced prompts with context or audio features
- Ad Hominem was classified most accurately (F1 up to 79%), while Slippery Slope was most challenging (F1 as low as 0%)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Additional context and emotional tone metadata can degrade LLM fallacy classification performance through attention dilution.
- Mechanism: When extra information (debate context, audio-derived emotional tone) is added to prompts, the model's attention is distributed across more features, potentially distracting from the core logical structure needed for fallacy identification. The model may overweight salient but irrelevant signals.
- Core assumption: LLM attention is a limited resource; more input features ≠ better reasoning.
- Evidence anchors:
  - [abstract] "Overall, basic prompts often outperformed enhanced ones, suggesting that attention dilution from added inputs may worsen rather than improve fallacy classification in LLMs."
  - [section 6.1] "This suggests an idea of 'attention dilution,' where additional context or emotional tone metadata distracted the model from the core of the statement."
  - [corpus] Related work on multimodal systems (Mestre et al., 2023) reported performance drops when incorporating audio features, consistent with this pattern.
- Break condition: If context is highly task-relevant and selectively integrated (e.g., only for context-dependent fallacies like Ad Hominem), benefits may emerge. Performance degrades when context is added uniformly without filtering.

### Mechanism 2
- Claim: Emotional tone metadata biases classification toward "Appeal to Emotion" at the expense of logical reasoning.
- Mechanism: Audio-derived arousal/dominance/valence values prime the model to attend to emotional content. When emotional features are salient, the model defaults to the fallacy category most associated with emotion, even when structural or logical violations better explain the fallacy.
- Core assumption: Emotional features are more salient to the model than structural argument features; the model lacks calibration to weigh multiple signal types appropriately.
- Evidence anchors:
  - [abstract] "Emotional tone metadata biases the model toward labeling statements as Appeal to Emotion, worsening logical reasoning."
  - [section 5.2.3] Figure 13 "shows a preference for predicting Appeal to Emotion, causing a large increase in misclassifications."
  - [section 5.1.2] "snippets are often mistakenly classified as 'Appeal to Emotion', especially when audio is included."
  - [corpus] Weak direct corpus support; related multimodal emotion detection papers (Wu et al., 2025; Zhao et al., 2022) show improvements when audio is well-integrated, but do not address fallacy-specific bias.
- Break condition: Bias is amplified when emotional tone values are high or extreme. May be mitigated by calibrating how emotional metadata is presented (e.g., normalizing, downweighting, or only including for fallacies where emotion is diagnostic).

### Mechanism 3
- Claim: Theory-informed Chain-of-Thought prompting can improve interpretability and, in specific cases, accuracy—but benefits are modest and depend on fallacy type.
- Mechanism: Structured frameworks (Pragma-Dialectics, Periodic Table of Arguments) guide the model through systematic reasoning steps (rule violation identification; form/substance/lever analysis). This imposes external structure on the model's generation, reducing randomness but potentially misaligning with the model's internal representations.
- Core assumption: External theoretical frameworks map onto LLM reasoning patterns; the model can follow multi-step instructions reliably.
- Evidence anchors:
  - [abstract] "Results suggest that while theoretical prompting can improve interpretability and, in some cases, accuracy..."
  - [section 5.2.1] PD base prompt achieved highest accuracy (53%) and macro F1 (54%).
  - [section 5.3.1] PTA base prompt achieved 44% accuracy; context+audio collapsed to 25%, showing PTA is more sensitive to interference.
  - [section 6] "Theoretical grounding provided a slight, but not substantial, boost in performance, specifically for the Pragma-Dialectics framework."
  - [corpus] Paper #58076 evaluates LLMs on argumentation theory semantics but does not directly compare CoT frameworks; limited external validation of PD vs PTA effectiveness.
- Break condition: Benefits emerge when the framework aligns with the model's reasoning tendencies and when fallacies have clear structural signatures. Degrades when frameworks add complexity without improving feature relevance (e.g., PTA with audio).

## Foundational Learning

- Concept: **Attention Dilution in Multimodal Prompts**
  - Why needed here: Understanding that adding features can harm performance is counterintuitive but critical for designing effective multimodal systems.
  - Quick check question: If adding context improves Ad Hominem detection but degrades overall accuracy, should you still include it?

- Concept: **Feature-Label Association Bias**
  - Why needed here: Emotional metadata strongly associates with "Appeal to Emotion" labels, demonstrating how feature salience can create systematic classification biases.
  - Quick check question: How would you detect whether a new metadata feature is introducing label-specific bias?

- Concept: **Theory-to-Prompt Translation**
  - Why needed here: Converting argumentation theory (PD rules, PTA constraints) into effective prompts requires understanding both the theory and how LLMs process instructions.
  - Quick check question: What makes a theoretical framework "LLM-compatible" for structured reasoning tasks?

## Architecture Onboarding

- Component map:
  Text snippet ± date context ± audio-derived emotional tone (arousal, dominance, valence)
  -> wav2vec 2.0-large emotional tone extraction (Wagner et al., 2023) -> normalized values [-1, 1]
  -> discretized into low/moderate/high using ±0.33 thresholds
  -> three prompting strategies (Basic, PD, PTA) × three input conditions
  -> Qwen-3 8B with temperature=0.6, top-p=0.95, top-k=20
  -> fallacy classification (6 classes) with optional reasoning trace

- Critical path:
  1. Audio preprocessing (resampling, normalization) → emotional tone values
  2. Tone value discretization (low/moderate/high using ±0.33 thresholds)
  3. Prompt assembly (framework + definitions + input features)
  4. Generation with reasoning before classification
  5. Evaluation on balanced test set (20 instances per class)

- Design tradeoffs:
  - Model size vs. computational cost: 8B chosen for constraints; larger models may handle complexity better
  - Balanced vs. natural distribution: Using balanced sets (60 validation, 120 test) for fair evaluation sacrifices realism
  - Discretized vs. raw tone values: Heuristic categorization may lose information but improves interpretability
  - Single-label vs. multi-label: Task forces single fallacy classification; real arguments may contain multiple fallacies

- Failure signatures:
  - Emotional overfit: Context+Audio shifts predictions toward "Appeal to Emotion" (recall jumps to 90% in PD, but precision drops)
  - Framework collapse: PTA with audio degrades to 25% accuracy across all metrics
  - Slippery Slope blindness: Consistently lowest F1 across all conditions (0-26%); often confused with Appeal to Emotion or False Cause
  - Context-dependent variance: Same statement classified differently across input conditions (see qualitative examples)

- First 3 experiments:
  1. **Ablate emotional tone per fallacy type**: Provide emotional metadata only for fallacies where emotion is diagnostic (Appeal to Emotion, Slogans, Ad Hominem) vs. all types. Measure bias reduction.
  2. **Calibrated metadata presentation**: Instead of raw discretized values, provide confidence-weighted or normalized descriptions. Test whether softening emotional signal reduces Appeal to Emotion bias.
  3. **Fallacy-specific prompt selection**: Route each input to the best-performing prompt for its predicted fallacy type (e.g., PD for Ad Hominem, Basic for Slippery Slope). Requires a preliminary classifier or heuristic.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do the negative effects of audio metadata and context persist in larger or proprietary model architectures?
- Basis in paper: [explicit] The authors explicitly state that "The use of a single model (Qwen3-8B)... limits the generalizability of our results" in Section 6.1.
- Why unresolved: The study was restricted by computational constraints to one specific open-source model size (8B parameters).
- Evidence: Replicating the three prompting conditions using larger models (e.g., GPT-4, Llama-3-70B) to see if stronger reasoning capabilities resist "attention dilution."

### Open Question 2
- Question: Can alternative integration methods prevent emotional tone metadata from biasing models toward "Appeal to Emotion" classifications?
- Basis in paper: [inferred] The paper notes that the current method of appending audio values caused a bias toward "Appeal to Emotion," but suggests that "both the quality and integration method of additional context play a important role" in the Conclusion.
- Why unresolved: The study tested only a heuristic text-based appending strategy, which failed; it did not test architectural fusion or separation strategies.
- Evidence: Implementing audio features via cross-attention mechanisms or separate encoder branches rather than text metadata injection to see if logical reasoning is preserved.

### Open Question 3
- Question: Does a "tailored" context selection strategy improve performance compared to the "one-size-fits-all" approach?
- Basis in paper: [inferred] The Conclusion states that "A more tailored approach (designing prompts specific to each statement) could improve performance" but notes this requires manual effort.
- Why unresolved: The current experimental setup applied context uniformly across all samples, which often distracted the model.
- Evidence: Developing a dynamic context selector that only injects metadata when the model's confidence is low, or when the fallacy type (e.g., Ad Hominem) is predicted to require it.

## Limitations

- The balanced test set of 120 samples (20 per class) may not capture real-world fallacy distribution complexity
- Discretized emotional tone values (-1 to 1 mapped to low/moderate/high using ±0.33 thresholds) represent significant information loss
- Exact prompt templates and theoretical framework definitions are not fully specified, limiting reproducibility

## Confidence

**High Confidence Claims:**
- Adding emotional tone metadata introduces bias toward "Appeal to Emotion" classification
- Context+Audio input condition consistently underperforms compared to simpler conditions
- Ad Hominem is the most reliably classified fallacy while Slippery Slope is the most challenging

**Medium Confidence Claims:**
- Attention dilution explains performance degradation with added inputs
- Pragma-Dialectics framework provides modest accuracy benefits
- Audio feature extraction using wav2vec 2.0 is appropriate for this task

**Low Confidence Claims:**
- Theoretical prompting significantly improves interpretability
- PTA framework is more sensitive to interference than PD
- Model size (8B) is appropriate for the task complexity

## Next Checks

1. **Bias Characterization Experiment**: Systematically test whether emotional tone metadata creates class-specific bias by running ablation studies that selectively include audio features for different fallacy types. Measure how removing audio affects Appeal to Emotion classification rates specifically.

2. **Information Preservation Analysis**: Compare model performance using discretized emotional tone values versus raw continuous values (before binning) to quantify information loss from the current preprocessing approach. This would validate whether the heuristic categorization is optimal.

3. **Framework Effectiveness Validation**: Conduct controlled experiments comparing each theoretical framework (PD vs PTA) on fallacies where their structural signatures should differ most strongly. This would test whether framework choice meaningfully impacts classification for specific fallacy types rather than overall performance.