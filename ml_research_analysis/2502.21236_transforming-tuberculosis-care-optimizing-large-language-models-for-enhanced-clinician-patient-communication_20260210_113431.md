---
ver: rpa2
title: 'Transforming Tuberculosis Care: Optimizing Large Language Models For Enhanced
  Clinician-Patient Communication'
arxiv_id: '2502.21236'
source_url: https://arxiv.org/abs/2502.21236
tags:
- prompt
- treatment
- questions
- responses
- few-shot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study develops and evaluates a multilingual LLM-based conversational
  agent to support TB treatment in Argentina. The agent uses prompt engineering, retrieval-augmented
  generation, and a two-step classification pipeline to provide culturally appropriate,
  empathetic, and medically accurate responses.
---

# Transforming Tuberculosis Care: Optimizing Large Language Models For Enhanced Clinician-Patient Communication

## Quick Facts
- arXiv ID: 2502.21236
- Source URL: https://arxiv.org/abs/2502.21236
- Reference count: 26
- Primary result: LLM-based TB conversational agent achieves 4.0-4.4/5.0 medical accuracy and improved empathy scores through prompt engineering and RAG

## Executive Summary
This study develops a multilingual LLM-based conversational agent for tuberculosis treatment support in Argentina, addressing the critical need for accessible healthcare communication. The system employs a two-step classification pipeline to route queries to specialized agents, retrieval-augmented generation for medical knowledge, and few-shot prompting with culturally-specific examples. Privacy is enhanced through differentially private text sanitization of real patient dialogues. Clinical expert evaluation shows strong performance in linguistic appropriateness and medical accuracy (4.0-4.4/5.0), with moderate empathy scores (0.5-1.25/2.0), while maintaining culturally relevant Spanish usage and reducing privacy risks.

## Method Summary
The system uses a multi-agent architecture with intent classification to route queries between empathy-optimized and fact-focused agents. Retrieval-augmented generation accesses curated TB guidelines from CDC, WHO, and Mayo Clinic Spanish resources. Few-shot prompting with Argentine dialect examples teaches vos form usage and culturally-natural phrasing. Privacy is ensured through UMLDP algorithm with configurable Îµ for text sanitization. The system was evaluated on 20 real patient queries across three categories using expert ratings for linguistic appropriateness, medical accuracy, and empathy.

## Key Results
- Expert evaluation achieved 4.0-4.4/5.0 scores for linguistic appropriateness and medical accuracy
- Empathy scores improved from baseline to 0.5-1.25/2.0 across categories
- Model maintained culturally relevant vos form Spanish while reducing privacy risks through differential privacy
- RAG+Few-Shot model outperformed pure RAG (4.2 vs 3.2 medical accuracy)

## Why This Works (Mechanism)

### Mechanism 1: Intent Classification