---
ver: rpa2
title: 'EmbodiedSplat: Personalized Real-to-Sim-to-Real Navigation with Gaussian Splats
  from a Mobile Device'
arxiv_id: '2509.17430'
source_url: https://arxiv.org/abs/2509.17430
tags:
- training
- scenes
- scene
- real-world
- policy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces EmbodiedSplat, a novel pipeline for training
  navigation policies in realistic environments captured using consumer-grade smartphones.
  The method leverages 3D Gaussian Splatting (GS) to reconstruct meshes from iPhone-captured
  scenes, enabling personalized sim-to-real transfer without requiring expensive capture
  hardware.
---

# EmbodiedSplat: Personalized Real-to-Sim-to-Real Navigation with Gaussian Splats from a Mobile Device

## Quick Facts
- **arXiv ID:** 2509.17430
- **Source URL:** https://arxiv.org/abs/2509.17430
- **Reference count:** 40
- **Key result:** 20-40% absolute success rate improvement in real-world navigation through fine-tuned policies on iPhone-captured Gaussian Splatting reconstructions.

## Executive Summary
EmbodiedSplat introduces a pipeline for training navigation policies in realistic environments captured using consumer-grade smartphones. The method leverages 3D Gaussian Splatting to reconstruct meshes from iPhone-captured scenes, enabling personalized sim-to-real transfer without requiring expensive capture hardware. The approach is evaluated on Image Navigation tasks, comparing zero-shot and fine-tuned policies against pre-trained baselines on large-scale datasets (HM3D, HSSD). Fine-tuned policies achieve absolute success rate improvements of 20-40% in real-world settings compared to zero-shot baselines. Additionally, high sim-to-real correlation (0.87-0.97) demonstrates effective transfer performance. The pipeline supports rapid scene collection and efficient policy adaptation, offering a scalable solution for embodied AI research.

## Method Summary
The pipeline captures indoor environments using iPhone 13 Pro Max via Polycam app, processes raw data through Nerfstudio to sample RGB-D frames, then reconstructs meshes using DN-Splatter with GT depth and Metric3D-V2 normals. Agents are pre-trained on HM3D or HSSD datasets using DD-PPO with VC-1-Base visual encoder, then fine-tuned on target scene reconstructions for 20M steps. Evaluation occurs in Habitat-Sim with ImageNav tasks, measuring success rate and sim-to-real correlation. Real-world deployment uses Stretch robot via Flask server with ROS integration.

## Key Results
- Fine-tuned policies achieve 20-40% absolute success rate improvement over zero-shot baselines in real-world navigation
- High sim-to-real correlation coefficients (0.87-0.97) demonstrate effective transfer from simulation to reality
- DN-Splatter reconstructions outperform original Polycam meshes in sim-to-real correlation for ImageNav tasks

## Why This Works (Mechanism)
The method works by creating high-fidelity 3D reconstructions of real environments using consumer smartphone hardware, then leveraging these personalized reconstructions to fine-tune navigation policies trained on large-scale synthetic datasets. Gaussian Splatting provides efficient, high-quality mesh generation that preserves fine geometric details critical for visual goal matching. Fine-tuning on scene-specific reconstructions bridges the domain gap between pre-training environments and target deployment spaces, enabling effective sim-to-real transfer without requiring extensive real-world data collection or expensive capture equipment.

## Foundational Learning
- **Gaussian Splatting**: Real-time 3D reconstruction technique using millions of Gaussian primitives to represent scenes efficiently
  - Why needed: Enables high-quality mesh generation from smartphone captures without expensive hardware
  - Quick check: Verify DN-Splatter produces meshes with sufficient geometric detail for navigation

- **Sim-to-real transfer**: Transferring learned policies from simulation to real-world deployment while maintaining performance
  - Why needed: Avoids expensive real-world data collection while enabling deployment in unseen environments
  - Quick check: Compare zero-shot vs fine-tuned policy performance on real robot

- **Image-Goal Navigation**: Navigation task where agent uses RGB observations to reach location matching goal image
  - Why needed: Realistic navigation benchmark requiring visual perception and spatial reasoning
  - Quick check: Verify success rate metric captures meaningful navigation completion

## Architecture Onboarding

**Component Map**: iPhone Capture -> Nerfstudio Processing -> DN-Splatter Reconstruction -> Mesh Export -> Policy Pre-training -> Fine-tuning -> Real-world Deployment

**Critical Path**: Capture → Mesh Reconstruction → Fine-tuning → Real-world Evaluation
The pipeline requires complete mesh quality before policy fine-tuning can begin, making reconstruction the critical dependency.

**Design Tradeoffs**: Consumer smartphone capture (low cost, accessibility) vs professional scanning equipment (higher fidelity); Gaussian Splatting (fast reconstruction) vs NeRF (higher quality but slower); pre-training on large datasets (better generalization) vs direct training on target scenes (faster but less robust).

**Failure Signatures**: 
- Zero-shot policies fail on captured scenes → domain gap too large for direct transfer
- Fine-tuned policies still underperform → mesh quality insufficient for visual goal matching
- Real-world deployment fails → sim-to-real gap remains despite fine-tuning

**First 3 Experiments**:
1. Compare DN-Splatter vs Polycam mesh quality and impact on navigation performance
2. Ablate fine-tuning duration (0, 10M, 20M, 50M steps) to find optimal adaptation time
3. Test transfer to structurally different environments beyond university buildings

## Open Questions the Paper Calls Out
None specified in the paper.

## Limitations
- Evaluation limited to university building scenes with controlled goal placements, limiting generalizability
- Mesh preprocessing pipeline lacks detailed specifications, potentially introducing variability
- Exact DD-PPO hyperparameter configuration remains underspecified beyond basic rollout parameters

## Confidence

**High confidence in:**
- Core pipeline architecture combining Gaussian Splatting reconstruction with fine-tuned RL policies
- Absolute success rate improvements (20-40%) achieved through fine-tuning
- Feasibility of capturing and processing scenes using consumer smartphone hardware

**Medium confidence in:**
- Generalizability of results to diverse real-world environments beyond university buildings
- Robustness of approach to varying capture quality and scene complexity

## Next Checks
1. Verify mesh quality impact by systematically comparing agent performance on DN-Splatter vs original Polycam meshes across multiple scenes, controlling for capture parameters.

2. Conduct ablation studies on fine-tuning duration (varying from 0 to 50M steps) to identify optimal adaptation time and assess diminishing returns.

3. Test transfer performance to structurally different environments (e.g., residential homes vs commercial spaces) to evaluate domain generalization beyond the current university building test set.