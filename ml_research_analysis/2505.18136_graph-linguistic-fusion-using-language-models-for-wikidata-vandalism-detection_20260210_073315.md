---
ver: rpa2
title: 'Graph-Linguistic Fusion: Using Language Models for Wikidata Vandalism Detection'
arxiv_id: '2505.18136'
source_url: https://arxiv.org/abs/2505.18136
tags:
- wikidata
- vandalism
- content
- system
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a new vandalism detection system for Wikidata,
  a large multilingual knowledge base. The main challenge is to detect vandalism in
  both structured data (knowledge triples) and unstructured text across multiple languages.
---

# Graph-Linguistic Fusion: Using Language Models for Wikidata Vandalism Detection

## Quick Facts
- **arXiv ID**: 2505.18136
- **Source URL**: https://arxiv.org/abs/2505.18136
- **Reference count**: 16
- **Primary result**: New vandalism detection system achieves AUC of 0.924 vs 0.859 for ORES baseline

## Executive Summary
This paper introduces Graph2Text, a novel vandalism detection system for Wikidata that converts structured graph edits and unstructured text into unified textual representations. The approach enables processing all edit types using a single multilingual language model, outperforming the current production system (ORES) with improved accuracy and fairness across user groups including anonymous and new editors.

## Method Summary
The system converts Wikidata revisions into text using Graph2Text, mapping knowledge triples to English labels with action prefixes. A fine-tuned multilingual BERT classifier processes individual content changes, with mean pooling aggregating results for multi-edit revisions. A final CatBoost classifier combines these content scores with metadata to produce the final vandalism risk score.

## Key Results
- Achieves AUC of 0.924 versus ORES baseline of 0.859
- Improves Filter Rate at 99% Recall from 47% to 72%
- Demonstrates better fairness across user groups including anonymous and new users

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Translating structured graph edits into natural language representations enables a single model to process heterogeneous data types effectively.
- **Mechanism**: Graph2Text converts knowledge triples (Entity, Property, Value) into text strings by mapping Wikidata IDs to English labels and prepending edit-type prefixes.
- **Core assumption**: Semantic meaning of vandalism edits is preserved when converting structured IDs into English text labels.
- **Evidence anchors**: [abstract] and [section 3.2.1] provide direct support for the Graph2Text approach.
- **Break condition**: Complex nested qualifiers or IDs without English labels degrade semantic signal when mapped to "unknown".

### Mechanism 2
- **Claim**: Fine-tuning a multilingual Language Model Classifier on text representations detects semantic anomalies better than handcrafted metadata features.
- **Mechanism**: Uses bert-base-multilingual-cased to process textualized edits, treating individual content changes as independent samples.
- **Core assumption**: Vandalism patterns share semantic similarities with noise patterns seen during BERT pre-training.
- **Evidence anchors**: [abstract] and [section 3.2.2] describe the fine-tuning approach.
- **Break condition**: Zero-shot deployment on poorly represented languages or edit types degrades detection capability.

### Mechanism 3
- **Claim**: Decoupling content analysis from user metadata reduces algorithmic bias against new and anonymous editors.
- **Mechanism**: Content-aware LMC reduces reliance on user reputation as a proxy signal for vandalism.
- **Core assumption**: Training data contains sufficient examples of good-faith edits by new users to teach content independence.
- **Evidence anchors**: [abstract] and [section 5.4] demonstrate improved fairness metrics.
- **Break condition**: Historical biases in training data where new users were systematically over-reverted may persist.

## Foundational Learning

- **Concept: Knowledge Triples & Serialization**
  - **Why needed here**: Core innovation converts Wikidata's native format (Entity-Property-Value) into text.
  - **Quick check question**: If a triple is `(Entity: Bulgaria, Property: Anthem, Value: Despacito)`, what would the resulting text input look like for the model?

- **Concept: Mean Pooling (Aggregation)**
  - **Why needed here**: Single revisions often contain multiple distinct edits requiring aggregation.
  - **Quick check question**: If a revision has 3 edits with probabilities [0.1, 0.1, 0.9], what does mean pooling imply compared to max pooling?

- **Concept: AUC and Filter Rate (FR@)**
  - **Why needed here**: Production constraint requires evaluating FR@99 alongside AUC for patroller workload.
  - **Quick check question**: If Model A has higher AUC but lower FR@99 than Model B, which reduces patroller workload more effectively at 99% recall?

## Architecture Onboarding

- **Component map**: Input JSON Revision -> Diff Engine (Deepdiff) -> Graph2Text Converter -> LMC (BERT) -> Aggregator (Mean Pooling) -> Final Classifier (CatBoost) -> Risk Score

- **Critical path**: Graph2Text converter. If ID-to-label mapping fails or lags, model receives "unknown" tokens breaking semantic understanding.

- **Design tradeoffs**:
  - **Latency vs. Accuracy**: Chose BERT (178M params) over larger LLMs for CPU-only infrastructure handling 10 edits/second.
  - **Coverage vs. Noise**: English label mapping improves semantic density but may lose non-English nuances.

- **Failure signatures**:
  - **Cold Start**: New entities without English labels map to "unknown", potentially ignoring valid vandalism on new pages.
  - **Language Drift**: Non-English textual edits diverging from BERT's pre-training distribution cause uncalibrated confidence.

- **First 3 experiments**:
  1. **Unit Test the Graph2Text**: Verify exact text output for known triple modifications.
  2. **Latency Benchmarks**: Confirm system stays under time-per-edit budget on CPU.
  3. **Bias Probe**: Test anonymous edits labeled "good-faith" by humans but "high risk" by ORES.

## Open Questions the Paper Calls Out

- **Open Question 1**: Can experimenting with different language model architectures improve performance beyond fine-tuned bert-base-multilingual-cased?
- **Open Question 2**: Does mapping Wikidata IDs to labels in non-English languages improve model coverage and accuracy?
- **Open Question 3**: How can the performance gap between English and non-English content detection be effectively reduced?

## Limitations
- Static English label mapping creates cold-start vulnerability for newly created entities without established labels
- Evaluation does not account for potential feedback loops from historically biased revert patterns
- Performance disparity persists between English and non-English content detection

## Confidence

- **Graph2Text mechanism**: High - clearly specified with verifiable textual representation
- **Multilingual LM effectiveness**: Medium - well-documented but lacks ablation studies for low-resource languages
- **Fairness improvements**: Medium - statistically significant but doesn't control for edit type distribution confounds

## Next Checks

1. **Cold-start validation**: Test on edits involving newly created Wikidata entities to quantify performance degradation from "unknown" label mappings
2. **Cross-lingual robustness**: Evaluate model performance on non-English edits to verify multilingual BERT's semantic understanding
3. **Bias feedback loop detection**: Conduct temporal analysis comparing model predictions on new user edits across training and held-out periods