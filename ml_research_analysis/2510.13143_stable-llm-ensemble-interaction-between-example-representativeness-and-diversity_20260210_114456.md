---
ver: rpa2
title: 'Stable LLM Ensemble: Interaction between Example Representativeness and Diversity'
arxiv_id: '2510.13143'
source_url: https://arxiv.org/abs/2510.13143
tags:
- ensemble
- examples
- temperature
- diversity
- example
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study systematically investigates how example representativeness
  and sampling temperature affect the performance of LLM ensembles for sentiment analysis.
  Two one-shot strategies are compared: centroid-based representative examples (CREs,
  proposed) and randomly sampled examples (RSEs, baseline), with temperature varied
  to control output diversity.'
---

# Stable LLM Ensemble: Interaction between Example Representativeness and Diversity

## Quick Facts
- arXiv ID: 2510.13143
- Source URL: https://arxiv.org/abs/2510.13143
- Reference count: 40
- Primary result: Centroid-based representative examples with higher temperature (1.5) significantly outperform random selection and 5-shot prompting for sentiment analysis

## Executive Summary
This study investigates how example representativeness and sampling temperature interact to affect LLM ensemble performance for sentiment analysis. The research compares two one-shot prompting strategies: centroid-based representative examples (CREs) and randomly sampled examples (RSEs), with temperature varied to control output diversity. The CRE approach with higher temperature (1.5) achieved +7.6% macro-F1 and -10.5% RMSE improvements over random selection, and even outperformed 5-shot prompting by +21.1% macro-F1. The findings demonstrate that combining representative example selection with controlled diversity through temperature creates optimal ensemble configurations, particularly effective for samples where base models disagree.

## Method Summary
The method employs an ensemble of five Llama-3.1-8B-Instruct models, each receiving one example from a carefully curated set. Two example selection strategies are compared: centroid-based representative examples (CREs) derived from SBERT embedding clustering of a 18K example pool, and randomly sampled examples (RSEs). Temperature is varied between 0.8 and 1.5 during inference to control output diversity. The ensemble aggregates predictions using median aggregation, which respects the ordinal nature of the 5-point sentiment scale. Performance is evaluated on IMDB reviews using macro-F1 and RMSE metrics.

## Key Results
- CRE with T=1.5 achieved +7.6% macro-F1 and -10.5% RMSE over RSE baseline
- CRE+T=1.5 configuration outperformed 5-shot prompting by +21.1% macro-F1 and -24.0% RMSE
- Ensemble median aggregation significantly reduced prediction error compared to individual models
- Ensemble approach was most effective on samples with low self-consistency among base models (F1=0.938 for unanimous agreement vs. 0.550-0.756 for disagreement cases)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Higher sampling temperature enables ensemble gains only when combined with representative example selection.
- Mechanism: Temperature controls output stochasticity during nucleus sampling. At T=0.8, predictions become nearly deterministic, so median aggregation offers no advantage. At T=1.5, outputs diversify sufficiently that aggregation can filter outliers—but only if examples anchor models in semantically coherent directions.
- Core assumption: Diversity from temperature is beneficial only when base models share a reasonable decision boundary orientation.
- Evidence anchors:
  - [abstract] "The proposed approach with higher temperature setting significantly outperforms random selection by +7.6% (macro-F1)"
  - [section 4.4.1] "random examples provide little additional diversity even at the higher temperature" while CRE at T=1.5 improves F1 by +14.2% (p<0.05)
  - [corpus] Pangakis et al. (2023) similarly note higher temperature decreases consistency, yielding more diverse predictions
- Break condition: If base models produce incoherent predictions (e.g., F1<0.2 for individual models), increasing temperature may amplify noise rather than beneficial diversity.

### Mechanism 2
- Claim: Centroid-based example selection via embedding clustering provides semantic coverage while maintaining decision coherence.
- Mechanism: SBERT embeddings capture semantic similarity. K-means clustering (K=5) partitions the example pool, and selecting centroid-nearest samples ensures each cluster's semantic region is represented. This keeps base models aligned on task-relevant features while temperature introduces controlled variance.
- Core assumption: Semantic diversity in prompt examples matters more than label balance for ensemble robustness.
- Evidence anchors:
  - [section 3.2.1] "the sample whose embedding is closest to the cluster centroid (using Euclidean distance) is chosen as a representative"
  - [section 5.2.1] "centroid examples keep the base models in the same direction, letting the median discard outliers"
  - [corpus] Related work on diversity in ICL (2505.19426) explores example selection but doesn't systematically interact with temperature
- Break condition: If the embedding model poorly captures task-relevant semantics (e.g., domain mismatch), centroid selection may cluster on irrelevant features.

### Mechanism 3
- Claim: Self-consistency among base models serves as a confidence signal, with ensembles helping most on low-consistency samples.
- Mechanism: When all five models agree (n_unique=1), F1=0.938, indicating high-confidence correct predictions. When models disagree (n_unique≥3), ensemble median aggregation recovers correct predictions that individual models miss.
- Core assumption: Agreement reflects task-relevant confidence, not systematic bias.
- Evidence anchors:
  - [section 4.4.5] Table 6 shows F1=0.938 for unanimous agreement vs. F1=0.550-0.756 for disagreement cases
  - [section 5.2.1] "ensemble method can significantly reduce the prediction error with median and outperforms individual models"
  - [corpus] Narang et al. on self-consistency in chain-of-thought reasoning (cited in paper) supports this pattern
- Break condition: If models systematically share a bias (e.g., all skew positive), high agreement may not indicate correctness.

## Foundational Learning

- Concept: **Accuracy-diversity trade-off in ensembles**
  - Why needed here: The paper shows increasing temperature reduces individual model accuracy but can improve ensemble performance. Understanding this trade-off is essential for tuning.
  - Quick check question: Can you explain why an ensemble might outperform its best individual member?

- Concept: **Embedding-based clustering and centroid selection**
  - Why needed here: The CRE method relies on K-means clustering of SBERT embeddings. You need to understand what centroids represent.
  - Quick check question: If you cluster text embeddings and select centroid-nearest samples, what property do those samples have relative to their cluster?

- Concept: **Ordinal vs. nominal classification aggregation**
  - Why needed here: The paper argues median aggregation suits 5-point sentiment scales because it respects ordinal relationships; majority voting does not.
  - Quick check question: For predictions [1, 1, 5, 5, 5], what would majority voting return vs. median?

## Architecture Onboarding

- Component map:
  Data pool (18K examples) -> SBERT embedding -> K-means (K=5) -> 5 centroid examples -> 5 base models (Llama-3.1-8B-Instruct) -> Median aggregation -> Final sentiment label (1-5)

- Critical path:
  1. Embed data pool with SBERT (all-MiniLM-L6-v2, 384-dim)
  2. Cluster and extract 5 centroid-nearest examples
  3. Run 5 parallel inferences with T=1.5, top_p=0.9, max_new_tokens=1
  4. Aggregate via median

- Design tradeoffs:
  - **CRE vs. RSE**: CRE captures semantic diversity but may inherit label skew (Fig. 2 shows CRE skewed toward positive); RSE is label-balanced but semantically random
  - **Temperature 0.8 vs. 1.5**: Lower is more stable but ensemble gains vanish; higher enables diversity but risks incoherent outliers (M4 at T=1.5 achieved F1=0.193)
  - **5 ensemble members**: Sufficient for this dataset; scalability to more members is untested

- Failure signatures:
  - Individual model F1 near 0.2 at high temperature → excessive diversity without anchor
  - Ensemble F1 no better than best individual → likely temperature too low or examples too similar
  - All models predict same label regardless of input → check prompt template, temperature near 0

- First 3 experiments:
  1. **Baseline replication**: Run RSE at T=0.8 and T=1.5 on a held-out subset; confirm ensemble F1 stays flat (~0.59) across temperatures
  2. **CRE ablation**: Implement centroid selection, run at T=1.5, verify F1 improvement of ~7-8% over RSE baseline
  3. **Consistency analysis**: For your best config, compute n_unique per sample and stratify F1; check if high-agreement samples show F1>0.9

## Open Questions the Paper Calls Out
None

## Limitations
- Findings depend heavily on specific dataset (IMDB reviews), base model (Llama-3.1-8B-Instruct), and prompt design
- Computational costs of embedding the full data pool and runtime differences between CRE and RSE approaches are not addressed
- Analysis focuses on macro-F1 and RMSE metrics without examining per-class performance patterns or potential calibration issues

## Confidence

- **High Confidence**: The observation that higher temperature with random examples yields minimal ensemble improvement (T=1.5 RSE: +0.2% F1 vs. CRE: +7.6% F1) is directly supported by experimental results in Table 4. The self-consistency analysis showing ensemble benefits on low-agreement samples is also strongly supported by the stratified F1 results in Table 6.

- **Medium Confidence**: The claim that CREs provide superior semantic coverage is supported by the methodology but not directly validated against alternative diversity metrics beyond the performance results. The assumption that SBERT embeddings adequately capture task-relevant semantic features for this application is reasonable but untested with alternative embedding approaches.

- **Low Confidence**: The extrapolation that CRE+T=1.5 would outperform 5-shot prompting across different tasks or datasets is based on a single comparison. The paper does not investigate whether this advantage persists when more than one example per model is available.

## Next Checks

1. **Domain Transfer Test**: Apply the CRE+T=1.5 configuration to a different sentiment analysis dataset (e.g., Amazon product reviews) and compare performance degradation relative to RSE baselines. This would test the generalizability of the representativeness advantage beyond IMDB.

2. **Alternative Embedding Models**: Repeat the CRE selection process using different sentence embedding models (e.g., Sentence-BERT variants with different architectures) to verify that the clustering advantage is not specific to the all-MiniLM-L6-v2 model used in the study.

3. **Calibration Analysis**: For samples where ensemble median differs from majority vote, examine the distribution of original predictions to determine whether the median truly represents a "consensus" or merely the middle value in a polarized set. This would validate whether median aggregation is appropriate for ordinal sentiment classification beyond the theoretical argument presented.