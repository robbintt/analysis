---
ver: rpa2
title: Enhancing Multi-Label Thoracic Disease Diagnosis with Deep Ensemble-Based Uncertainty
  Quantification
arxiv_id: '2511.18839'
source_url: https://arxiv.org/abs/2511.18839
tags:
- uncertainty
- ensemble
- deep
- loss
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the lack of reliable confidence measures in
  deep learning-based thoracic disease diagnosis by integrating Uncertainty Quantification
  (UQ) into a high-performance multi-label classification platform. It overcomes the
  instability of Monte Carlo Dropout (MCD) by pivoting to a 9-member Deep Ensemble
  (DE) using diverse architectures and loss functions.
---

# Enhancing Multi-Label Thoracic Disease Diagnosis with Deep Ensemble-Based Uncertainty Quantification

## Quick Facts
- arXiv ID: 2511.18839
- Source URL: https://arxiv.org/abs/2511.18839
- Authors: Yasiru Laksara; Uthayasanker Thayasivam
- Reference count: 26
- Primary result: Deep Ensemble achieves state-of-the-art AUROC of 0.8559 and well-calibrated uncertainty estimates (ECE = 0.0728) for multi-label thoracic disease diagnosis

## Executive Summary
This study addresses the critical need for reliable confidence measures in deep learning-based thoracic disease diagnosis by integrating Uncertainty Quantification (UQ) into a multi-label classification platform. The researchers overcome the instability of Monte Carlo Dropout by developing a 9-member Deep Ensemble using diverse architectures and loss functions. The ensemble achieves superior calibration and uncertainty decomposition, with Aleatoric Uncertainty dominating Epistemic Uncertainty, indicating data quality rather than model inadequacy as the primary bottleneck.

## Method Summary
The method employs a 9-member Deep Ensemble trained on NIH ChestX-ray14 dataset with diverse backbones (DenseNet-121, DenseNet+CBAM, EfficientNet-B2/B3), two loss functions (Focal, ZLPR), and random seeds. Ensemble predictions are obtained through uniform averaging, enabling entropy-based uncertainty decomposition into Total (TU), Aleatoric (AU), and Epistemic (EU) components. The approach replaces unstable Monte Carlo Dropout with ensemble averaging to achieve reliable uncertainty quantification and superior calibration metrics.

## Key Results
- Achieved state-of-the-art average AUROC of 0.8559 and F1 score of 0.3857
- Demonstrated excellent calibration with Mean ECE = 0.0728 versus MCD's 0.7588, and NLL = 0.1916
- Successfully decomposed total uncertainty into dominant Aleatoric (AU = 0.3073) and minor Epistemic (EU = 0.0240) components
- Ensemble Grad-CAM provides transparent decision-making through averaged attribution maps

## Why This Works (Mechanism)

### Mechanism 1
Deep Ensembles provide superior calibration by training diverse models that converge to well-separated low-loss valleys in parameter space. Independent training with different architectures, losses, and seeds creates functionally diverse predictions, and uniform averaging reduces variance while improving calibration over MCD's constrained sampling.

### Mechanism 2
Uncertainty decomposition reveals that high Aleatoric relative to Epistemic Uncertainty indicates data quality as the primary bottleneck. This entropy-based separation identifies irreducible data noise rather than model inadequacy as the main source of uncertainty, guiding future improvement efforts.

### Mechanism 3
MCD fails for multi-label thoracic classification because dropout-based sampling explores only restricted regions of the loss landscape. Instead of generating genuinely diverse predictions needed for reliable uncertainty estimates, MCD creates "random subnets" that remain functionally similar.

## Foundational Learning

- **Aleatoric vs. Epistemic Uncertainty**: Understanding the distinction between data noise and model uncertainty is essential for interpreting results and identifying improvement priorities. Quick check: If AU >> EU for a pathology, should you focus on more data or cleaner labels?

- **Calibration Metrics (ECE, NLL, Brier Score)**: The paper evaluates reliability through calibration rather than just accuracy. Quick check: A model with 90% accuracy but 99% confidence on all correct predictions—is it well-calibrated?

- **Ensemble Diversity Strategies**: The approach explicitly varies architectures, losses, and seeds to maximize diversity. Quick check: If all members use same architecture but different initial weights, would you expect high or low epistemic uncertainty?

## Architecture Onboarding

- **Component map**: NIH ChestX-ray14 → patient-level split → CLAHE enhancement → resize per backbone → 14 candidate models → 9-member ensemble → uniform averaging → entropy-based uncertainty decomposition → Ensemble Grad-CAM

- **Critical path**: 1) CLAHE preprocessing for all inputs 2) Train 14 diverse models with early stopping 3) Select top 9 by AUROC/F1/complementarity 4) Aggregate predictions via uniform averaging, compute TU/AU/EU

- **Design tradeoffs**: Computational cost of 9 full models vs. single MCD model; uniform vs. weighted averaging (simple average chosen); single dataset focus limits generalizability

- **Failure signatures**: MCD yields ECE > 0.7 (catastrophic miscalibration); high EU with low AU suggests insufficient model diversity; Grad-CAM shows high inter-model variance on high-EU samples

- **First 3 experiments**: 1) Reproduce MCD baseline on DenseNet-121 to confirm ECE degradation 2) Train 3 DenseNet-121 variants with different seeds to assess diversity contribution 3) Implement uncertainty decomposition on 3-member mini-ensemble before scaling to 9 members

## Open Questions the Paper Calls Out

- **External validation transferability**: How does the Deep Ensemble's uncertainty decomposition and calibration performance transfer to out-of-distribution datasets like CheXpert and MIMIC-CXR? Section VI identifies this as essential for confirming generalizability, but data access restrictions prevented external validation.

- **Uncertainty-interpretability correlation**: Is there a quantitative correlation between elevated Epistemic Uncertainty scores and inter-model visual variance in Grad-CAM heatmaps? The paper proposes future studies to quantitatively correlate EU with visual disagreement, as current analysis relies on qualitative consensus heatmaps.

- **Adaptive ensemble techniques**: Can adaptive ensemble techniques, such as weighted averaging, improve predictive calibration over uniform averaging? Section VI suggests exploring adaptive techniques if an independent meta-validation set becomes available, as current methodology uses simple uniform average.

## Limitations

- Reliance on single dataset (NIH ChestX-ray14) without external validation constrains generalizability claims
- Computational cost of training 9 full models represents significant practical barrier for widespread adoption
- Uncertainty decomposition methodology assumes entropy-based calculations faithfully capture theoretical distinctions in multi-label settings

## Confidence

- **High confidence**: Empirical superiority of Deep Ensembles over MCD in calibration (ECE: 0.0728 vs 0.7588) and overall performance metrics
- **Medium confidence**: Interpretation that AU >> EU definitively indicates data quality as primary bottleneck, given limited external validation
- **Medium confidence**: Claim that MCD fundamentally fails rather than being suboptimal due to hyperparameter choices

## Next Checks

1. **External validation**: Test the 9-member ensemble on independent datasets (CheXpert, MIMIC-CXR) to verify generalizability beyond NIH ChestX-ray14

2. **Uncertainty-interpretability correlation**: Quantify the relationship between epistemic uncertainty and inter-model Grad-CAM visual disagreement to validate uncertainty as proxy for model consensus

3. **Cost-benefit analysis**: Compare performance gain of Deep Ensemble versus lightweight alternatives (e.g., ensemble of 3 diverse models) to assess practical feasibility trade-offs