---
ver: rpa2
title: 'OpenVTON-Bench: A Large-Scale High-Resolution Benchmark for Controllable Virtual
  Try-On Evaluation'
arxiv_id: '2601.22725'
source_url: https://arxiv.org/abs/2601.22725
tags:
- evaluation
- image
- try-on
- garment
- semantic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "OpenVTON-Bench is a large-scale, high-resolution dataset and evaluation\
  \ benchmark for virtual try-on (VTON) systems, containing ~100K image pairs at up\
  \ to 1536\xD71536 resolution. The dataset is constructed using DINOv3-based hierarchical\
  \ clustering for balanced sampling across 20 garment categories, with Gemini-powered\
  \ dense captioning for semantic richness."
---

# OpenVTON-Bench: A Large-Scale High-Resolution Benchmark for Controllable Virtual Try-On Evaluation

## Quick Facts
- arXiv ID: 2601.22725
- Source URL: https://arxiv.org/abs/2601.22725
- Authors: Jin Li; Tao Chen; Shuai Jiang; Weijie Wang; Jingwen Luo; Chenhui Wu
- Reference count: 40
- Key outcome: Large-scale dataset with ~100K high-res image pairs and novel multi-modal evaluation protocol

## Executive Summary
OpenVTON-Bench introduces a comprehensive dataset and evaluation framework for virtual try-on systems, addressing critical gaps in existing benchmarks. The dataset comprises approximately 100,000 image pairs at resolutions up to 1536×1536, spanning 20 garment categories. A novel multi-modal evaluation protocol combines VLM-based semantic reasoning with a Multi-Scale Representation Metric to assess five key dimensions of try-on quality. The benchmark demonstrates strong alignment with human judgments (Kendall's τ of 0.833) and reveals that diffusion models excel in photorealism but struggle with fine-grained texture preservation.

## Method Summary
The benchmark leverages DINOv3-based hierarchical clustering for balanced sampling across garment categories, paired with Gemini-powered dense captioning for semantic richness. The evaluation protocol integrates VLM-based semantic reasoning (Qwen-VL-Plus) with a novel Multi-Scale Representation Metric built on SAM3 segmentation and morphological erosion. This dual-track approach assesses background consistency, identity fidelity, texture fidelity, shape plausibility, and overall realism. The protocol shows strong correlation with human judgments, outperforming traditional metrics like SSIM (0.611).

## Key Results
- Dataset contains ~100K image pairs at up to 1536×1536 resolution
- Multi-modal evaluation protocol achieves Kendall's τ of 0.833 vs. 0.611 for SSIM
- Diffusion models show photorealism but struggle with fine-grained texture preservation

## Why This Works (Mechanism)
The benchmark's effectiveness stems from its dual-track evaluation approach that combines semantic reasoning with representation metrics. By using VLM-based analysis alongside segmentation-based morphological assessment, the protocol captures both high-level semantic coherence and fine-grained structural details. The hierarchical clustering ensures balanced category representation, while high-resolution images enable detailed texture analysis.

## Foundational Learning
- DINOv3-based hierarchical clustering: Essential for balanced category sampling; quick check: verify category distribution uniformity
- Gemini-powered dense captioning: Provides semantic richness for evaluation; quick check: validate caption coverage across garment types
- VLM-based semantic reasoning: Enables context-aware quality assessment; quick check: test on out-of-distribution examples
- SAM3 segmentation: Critical for precise shape and texture analysis; quick check: compare segmentation accuracy across models
- Multi-Scale Representation Metric: Captures details at multiple resolutions; quick check: validate performance across scale ranges

## Architecture Onboarding

Component map: Image Pair Generation -> Multi-Scale Analysis -> VLM Semantic Reasoning -> Quality Assessment -> Benchmark Scoring

Critical path: High-resolution image pairs flow through SAM3 segmentation, morphological erosion processing, VLM analysis, and final quality scoring across five dimensions.

Design tradeoffs: Resolution vs. computational efficiency; semantic depth vs. processing speed; model complexity vs. reproducibility.

Failure signatures: Poor texture preservation in diffusion models; category imbalance in clustering; semantic drift in captioning; segmentation errors in complex garments.

First experiments:
1. Test category balance by analyzing garment distribution across all image pairs
2. Validate VLM semantic consistency by comparing reasoning across similar garment types
3. Assess segmentation accuracy by comparing SAM3 outputs against ground truth masks

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on synthetic data may introduce biases affecting real-world generalizability
- Focus on static images overlooks dynamic garment behavior and fit in motion
- Protocol dependence on specific models (Qwen-VL-Plus, SAM3) may limit reproducibility

## Confidence
- Dataset construction methodology: High
- Evaluation protocol effectiveness: High
- Real-world applicability: Medium
- Cross-model robustness: Medium

## Next Checks
1. Conduct user studies comparing human evaluations with the benchmark's protocol across diverse demographic groups
2. Test benchmark performance metrics across different diffusion model architectures and training paradigms
3. Evaluate dataset generalization by testing models against real-world virtual try-on scenarios and commercial datasets