---
ver: rpa2
title: Adjustment for Confounding using Pre-Trained Representations
arxiv_id: '2506.14329'
source_url: https://arxiv.org/abs/2506.14329
tags:
- pre-trained
- confounding
- estimation
- representations
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores how to estimate causal effects when confounding
  information is contained in high-dimensional non-tabular data like images and text.
  The authors develop theoretical conditions under which pre-trained neural network
  representations can be used for valid causal inference, showing that neural networks
  can adapt to the intrinsic low dimensionality of these representations to achieve
  fast convergence rates.
---

# Adjustment for Confounding using Pre-Trained Representations

## Quick Facts
- arXiv ID: 2506.14329
- Source URL: https://arxiv.org/abs/2506.14329
- Authors: Rickmer Schulte; David RÃ¼gamer; Thomas Nagler
- Reference count: 40
- Key outcome: Pre-trained neural network representations enable valid causal inference in high-dimensional non-tabular data by adapting to low intrinsic dimensionality.

## Executive Summary
This paper addresses the challenge of estimating causal effects when confounding information is embedded in high-dimensional non-tabular data like images and text. The authors develop theoretical conditions showing that pre-trained neural network representations can be used for valid causal inference, demonstrating that neural networks can adapt to the intrinsic low dimensionality of these representations to achieve fast convergence rates. Their framework combines low intrinsic dimensionality with structural assumptions suited for neural networks, and empirical results show that DML using pre-trained representations yields unbiased estimates with valid confidence intervals while standard methods fail on raw high-dimensional data.

## Method Summary
The method uses pre-trained neural networks (BERT for text, DenseNet for images) to extract latent representations from non-tabular confounders. These representations are then used within a Double Machine Learning (DML) framework, where deep neural networks estimate the outcome regression and propensity score functions. The approach relies on the assumption that pre-trained representations lie on low-dimensional smooth manifolds, allowing DNNs to achieve fast convergence rates by adapting to intrinsic dimensionality rather than ambient dimensionality. The theoretical framework establishes conditions under which this approach yields valid inference for Average Treatment Effect (ATE) estimation.

## Key Results
- DML with pre-trained representations achieves unbiased ATE estimates and valid confidence intervals
- Naive methods and DML without pre-training fail due to bias or poor coverage
- Pre-training is crucial for effective confounding adjustment, especially with limited samples
- Neural network-based nuisance estimators outperform traditional methods like random forests and L1-penalized regression

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Neural networks achieve fast convergence rates by adapting to low intrinsic dimensionality of pre-trained representations.
- Mechanism: Pre-trained representations lie on low-dimensional smooth manifolds. Theorem 5.5 shows DNNs can adapt to intrinsic dimension ($d_M$), allowing convergence rates to depend on $d_M$ rather than ambient dimension.
- Core assumption: Pre-trained representations lie on low-dimensional smooth manifolds; nuisance functions have Hierarchical Composition Model structure with sufficiently fast convergence.
- Evidence anchors: Abstract states neural networks can achieve fast convergence by adapting to intrinsic notions of sparsity and dimension. Section 5.2 proves Theorem 5.5 establishes the convergence rate.
- Break condition: Fails if representations have high intrinsic dimension or nuisance functions lack suitable hierarchical structure.

### Mechanism 2
- Claim: Pre-trained representations are only identifiable up to ILTs, invalidating sparsity/additivity assumptions but preserving smoothness/low intrinsic dimensionality.
- Mechanism: Lemma 4.2 proves sparsity and additivity assumptions are not invariant under ILTs. Smoothness and low intrinsic dimensionality are invariant, making them suitable theoretical foundations.
- Core assumption: Representation $Z = \phi(W)$ is only identifiable up to invertible linear transformation $Q$.
- Evidence anchors: Abstract mentions ILTs undermine standard assumptions. Section 4.2 formally proves non-invariance of sparsity and additivity.
- Break condition: Breaks only if representation were uniquely identifiable (generally not the case for latent features).

### Mechanism 3
- Claim: Doubly robust DML with neural network nuisance estimators provides unbiased estimates and valid confidence intervals.
- Mechanism: DML framework requires product of nuisance function errors to vanish faster than $n^{-1/2}$. Experiments show DNNs achieve this, yielding valid inference while ILT-sensitive methods fail.
- Core assumption: Nuisance functions are P-valid and converge sufficiently fast; standard DML assumptions hold.
- Evidence anchors: Abstract states DML with pre-trained representations achieves unbiased ATE estimates. Section 6.1 shows DML with neural networks works while DML with Lasso/RF fails.
- Break condition: Fails if nuisance estimators don't converge fast enough or representations aren't P-valid.

## Foundational Learning

- **Invertible Linear Transformations (ILTs) and Identifiability**
  - Why needed here: Explains why standard ML methods fail on latent features. The representation space is "unstable" for these methods because features can be arbitrarily rotated without changing information.
  - Quick check question: If I rotate my latent features by 45 degrees, should my model's predictions change? (For DNNs: No. For Lasso: Likely yes, breaking the model).

- **Intrinsic Dimensionality vs. Ambient Dimensionality**
  - Why needed here: Explains why high dimension of latent features is not a death sentence for estimation. Actual complexity is governed by much lower intrinsic dimension.
  - Quick check question: My latent vector has 1024 features. Does this mean I have a 1024-dimensional estimation problem? (Not necessarily; if data lies on $d_M$-dimensional manifold, effective complexity relates to $d_M$).

- **Double Machine Learning (DML) and Nuisance Estimation**
  - Why needed here: Provides framework for ATE estimation. Understanding fast convergence requirements for nuisance functions is essential.
  - Quick check question: In DML, what must happen to errors of outcome and propensity models for final ATE estimate to have valid confidence interval? (Their product must shrink faster than $n^{-1/2}$ parametric rate).

## Architecture Onboarding

- Component map: Raw Data (Images/Text) -> Pre-trained Model (BERT/DenseNet) -> Latent Representations (Z) -> DNN Nuisance Estimators -> DML Module -> ATE Estimate
- Critical path:
  1. Obtain pre-trained model $\phi$ appropriate for data modality
  2. Extract latent representations $Z = \phi(W)$ for all samples
  3. DO NOT use standard sparse linear models or tree-based models directly on $Z$
  4. Configure DNN nuisance estimators with appropriate depth/width
  5. Run DML procedure (cross-fitting) using DNN estimators to get $\widehat{ATE}$ and CIs
- Design tradeoffs:
  - DNNs vs. Linear Models: DNNs are theoretically justified for ILT-invariance but complex to tune; linear models are simpler but may fail with complex confounding
  - Pre-trained vs. Scratch: Pre-training essential for good performance with limited samples, avoiding overfitting from training feature extractors from scratch
- Failure signatures:
  - Biased ATE / Invalid CIs: Using Lasso, Random Forest, or other ILT-sensitive models as nuisance estimators on pre-trained features
  - High Variance / No Convergence: Using DNN without pre-trained features when sample size is small
  - Slow Convergence: If intrinsic dimension of latent features is high or nuisance functions lack favorable HCM structure
- First 3 experiments:
  1. Implement DML with linear nuisance estimators on pre-trained features (Label Confounding setup) to verify unbiased results for simple confounding
  2. Compare DML using DNNs vs. DML using Lasso/Random Forests on pre-trained representations; DNN version should show superior coverage and less bias
  3. Compare DML with pre-trained features vs. DML with CNN trained from scratch on raw images; pre-trained version should be unbiased while from-scratch version will likely be biased

## Open Questions the Paper Calls Out

- How does integration of multiple non-tabular modalities affect theoretical conditions and estimation performance for ATE adjustment? (The paper states this is a potential future research direction, noting the need to study modalities' interplay)
- Can convergence rates and validity guarantees for ATE be transferred to other causal estimands like CATE? (The paper mentions extension to other target parameters but proofs are tailored to ATE's orthogonal score)
- How can researchers empirically validate sufficiency of pre-trained representation ($P$-validity) before deploying for causal adjustment? (The method relies on $P$-validity but provides no diagnostic tools to check if pre-trained model has discarded necessary confounding information)

## Limitations
- Strong assumptions required: low intrinsic dimensionality of pre-trained representations and hierarchical composition model structure of nuisance functions
- Empirical validation limited to specific architectures (BERT, DenseNet) and synthetic/simulated settings
- Performance on truly complex, real-world confounding scenarios with highly non-linear relationships remains to be fully explored

## Confidence
- Theoretical framework: High
- Empirical demonstrations: Medium

## Next Checks
1. Test the approach on a real-world dataset with known confounding structure (e.g., IHDP dataset with image/text supplements)
2. Conduct sensitivity analysis by varying intrinsic dimensionality of latent representations to see how it affects convergence rates and inference quality
3. Compare proposed method against state-of-the-art causal inference techniques designed for high-dimensional data (e.g., DeepIV) on a benchmark task