---
ver: rpa2
title: Rethinking Consistent Multi-Label Classification under Inexact Supervision
arxiv_id: '2510.04091'
source_url: https://arxiv.org/abs/2510.04091
tags:
- rpgq
- hpgq
- learning
- loss
- labels
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses consistent multi-label classification under
  inexact supervision, specifically partial and complementary multi-label learning.
  The key challenge is handling candidate label sets containing both relevant and
  irrelevant labels without relying on estimating the generation process or uniform
  distribution assumptions, which are difficult in real-world scenarios.
---

# Rethinking Consistent Multi-Label Classification under Inexact Supervision

## Quick Facts
- arXiv ID: 2510.04091
- Source URL: https://arxiv.org/abs/2510.04091
- Authors: Wei Wang; Tianhao Ma; Ming-Kun Xie; Gang Niu; Masashi Sugiyama
- Reference count: 40
- Key outcome: Introduces COMES, a general framework for consistent multi-label classification under inexact supervision using unbiased risk estimators and risk-correction approaches

## Executive Summary
This paper addresses the challenging problem of consistent multi-label classification when supervision is inexact, specifically handling partial and complementary multi-label learning scenarios where candidate label sets contain both relevant and irrelevant labels. The authors propose COMES, a general framework that avoids relying on difficult-to-estimate generation processes or uniform distribution assumptions. The method introduces novel unbiased risk estimators based on first-order (Hamming loss) and second-order (ranking loss) strategies, along with risk-correction approaches to prevent overfitting issues common in unbiased estimators.

The proposed framework demonstrates theoretical consistency with respect to Hamming and ranking losses, with derived convergence rates for estimation errors. Extensive experiments on real-world datasets (mirflickr, music datasets, yeast) and synthetic datasets (VOC, CUB, COCO) show that COMES outperforms state-of-the-art methods across multiple evaluation metrics including ranking loss, Hamming loss, and mean average precision. The method also shows robustness to inaccurate class priors and hyperparameter sensitivity, making it practical for real-world applications.

## Method Summary
COMES introduces a general framework for consistent multi-label classification under inexact supervision through two main components: unbiased risk estimators and risk-correction approaches. The method is built on a novel data generation process