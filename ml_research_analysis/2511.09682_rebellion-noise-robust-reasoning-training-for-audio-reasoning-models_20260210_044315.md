---
ver: rpa2
title: 'Rebellion: Noise-Robust Reasoning Training for Audio Reasoning Models'
arxiv_id: '2511.09682'
source_url: https://arxiv.org/abs/2511.09682
tags:
- reasoning
- audio
- safety
- arxiv
- jailbreak
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the safety of audio reasoning models (ARMs)
  against jailbreak attacks, which aim to elicit harmful responses from target models.
  The authors propose Rebellion, a novel reasoning training method that trains ARMs
  to be robust to worst-case representation drift induced by audio jailbreaks.
---

# Rebellion: Noise-Robust Reasoning Training for Audio Reasoning Models

## Quick Facts
- arXiv ID: 2511.09682
- Source URL: https://arxiv.org/abs/2511.09682
- Reference count: 0
- Key outcome: Rebellion achieves 50.56% and 25% absolute reduction in harmful scores for Rephrasing and Advwave audio jailbreaks respectively while maintaining benign task performance

## Executive Summary
This paper addresses the safety challenge of audio reasoning models (ARMs) against jailbreak attacks, which attempt to elicit harmful responses from target models. The authors propose Rebellion, a novel reasoning training method that trains ARMs to be robust to worst-case representation drift induced by audio jailbreak attacks. Rebellion achieves this by optimizing a loss function that minimizes safety loss under the impact of worst-case representation drift while maintaining benign reasoning performance. The results demonstrate that Rebellion can protect against advanced audio jailbreaks without compromising performance on benign tasks, with Rebellion-trained ARMs exhibiting a "think twice" behavior when encountering longer suffix audio jailbreak.

## Method Summary
Rebellion is a reasoning training method that protects audio reasoning models against jailbreak attacks by optimizing for safety robustness. The method trains ARMs to minimize safety loss under worst-case representation drift while maintaining benign reasoning capabilities. The training approach combines safety reasoning loss with benign task performance optimization, creating a dual-objective framework that enables the model to recognize and appropriately respond to potential jailbreak attempts while maintaining normal functionality on legitimate tasks.

## Key Results
- Rebellion reduces harmful scores by 50.56% absolute for Rephrasing attacks
- Rebellion achieves 25% absolute reduction in harmful scores for Advwave attacks
- Rebellion-trained ARMs maintain the same level of benign accuracy as baseline models

## Why This Works (Mechanism)
The Rebellion mechanism works by training audio reasoning models to recognize and resist adversarial perturbations that cause representation drift. By optimizing for safety loss under worst-case representation scenarios, the model learns to maintain robust safety reasoning even when faced with adversarial audio inputs. The "think twice" behavior observed in Rebellion-trained models suggests that the training process has enhanced the model's ability to pause and perform safety reasoning before finalizing responses, particularly when encountering more sophisticated jailbreak attempts with longer suffixes.

## Foundational Learning
- **Audio Representation Learning**: Understanding how audio features are encoded and processed in reasoning models is essential because jailbreak attacks manipulate these representations to bypass safety mechanisms. Quick check: Verify that the model can distinguish between benign and adversarial audio representations.
- **Adversarial Robustness**: Knowledge of how models respond to adversarial inputs is crucial since jailbreak attacks are a form of adversarial attack. Quick check: Test model performance under various levels of adversarial noise.
- **Dual-Objective Optimization**: Understanding how to balance safety and performance objectives is necessary for training models that are both safe and functional. Quick check: Verify that neither safety nor performance objectives dominate during training.

## Architecture Onboarding
**Component Map**: Input Audio -> Representation Layer -> Safety Reasoning Module -> Response Generation Module -> Output Response
**Critical Path**: The critical path flows from audio input through representation extraction, where safety reasoning is applied before response generation. The safety reasoning module is the most critical component, as it determines whether the input contains jailbreak attempts.
**Design Tradeoffs**: Rebellion trades some potential performance gains for safety robustness, but maintains benign task performance. The approach prioritizes safety reasoning without significantly impacting normal functionality.
**Failure Signatures**: Models trained with Rebellion may exhibit slower response times when encountering complex jailbreak attempts, as evidenced by the "think twice" behavior. Failure to properly train the safety reasoning module could result in reduced performance on legitimate tasks.
**First Experiments**:
1. Evaluate baseline ARM performance on Rephrasing and Advwave attacks to establish initial harmful scores
2. Test Rebellion-trained model on benign audio reasoning tasks to verify performance maintenance
3. Assess "think twice" behavior by measuring response latency for different jailbreak attack lengths

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focuses primarily on two specific jailbreak attack methods (Rephrasing and Advwave), potentially missing other attack vectors
- The "think twice" behavior mechanism is not fully explained and could have unintended consequences
- Long-term stability and generalization across diverse audio reasoning tasks remain untested

## Confidence
High: The core claim that Rebellion reduces harmful responses to specific audio jailbreak attacks while maintaining benign task performance is well-supported by experimental results.
Medium: The generalization of Rebellion's effectiveness to other types of audio jailbreak attacks and its long-term stability in production environments.
Low: Complete understanding of why Rebellion induces "think twice" behavior and whether this emergent property could be exploited by sophisticated adversaries.

## Next Checks
1. Evaluate Rebellion-trained models against a broader range of audio jailbreak techniques to assess robustness beyond the two tested methods.
2. Conduct long-term stability tests by evaluating Rebellion-trained models after extended periods of training and across diverse audio reasoning tasks.
3. Perform ablation studies to isolate the specific components of Rebellion training that contribute most significantly to its effectiveness.