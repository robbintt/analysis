---
ver: rpa2
title: 'ContextFocus: Activation Steering for Contextual Faithfulness in Large Language
  Models'
arxiv_id: '2601.04131'
source_url: https://arxiv.org/abs/2601.04131
tags:
- steering
- context
- vector
- contextfocus
- layer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ContextFocus improves contextual faithfulness in large language
  models by steering activations toward context-aware behavior. It contrasts model
  representations conditioned on context with those relying on parametric knowledge,
  then injects the resulting direction into residual activations during inference.
---

# ContextFocus: Activation Steering for Contextual Faithfulness in Large Language Models

## Quick Facts
- arXiv ID: 2601.04131
- Source URL: https://arxiv.org/abs/2601.04131
- Reference count: 36
- Improves context faithfulness in large language models via activation steering

## Executive Summary
ContextFocus is a novel activation-steering method designed to enhance contextual faithfulness in large language models during retrieval-augmented generation. It operates by steering model activations toward context-aware behavior, effectively reducing reliance on parametric knowledge. The approach constructs a steering vector by contrasting model representations conditioned on context versus parametric knowledge, then injects this direction into residual activations during inference. Evaluated on ConFiQA, ContextFocus significantly increases context-aligned outputs (ps) by 20-30 percentage points while reducing parametric bias, outperforming contrastive decoding and matching fine-tuning baselines without requiring retraining.

## Method Summary
ContextFocus improves contextual faithfulness by steering model activations toward context-aware behavior. It contrasts model representations conditioned on context with those relying on parametric knowledge, then injects the resulting direction into residual activations during inference. The method uses only 1.5k examples to construct the steering vector, requires a single forward pass, and scales to larger models like Llama-3.1-70B. Steering strength is fixed at multiplier 2 to preserve fluency. Systematic ablations show that jointly contrasting system instruction and context is critical for strong gains.

## Key Results
- Increases context-aligned outputs (ps) by 20-30 percentage points on ConFiQA
- Reduces parametric bias while outperforming contrastive decoding
- Matches fine-tuning baselines without retraining
- Scales to Llama-3.1-70B using only 1.5k examples

## Why This Works (Mechanism)
ContextFocus works by identifying the difference in activation patterns between context-aware and parametric knowledge-based responses. By injecting this difference as a steering direction into residual activations during inference, the model is nudged to rely more heavily on provided context rather than its pre-trained parametric knowledge. This activation steering effectively realigns the model's output generation process with the available evidence, improving faithfulness to retrieved information.

## Foundational Learning
- **Activation steering**: Why needed - to redirect model behavior without retraining; Quick check - observe activation patterns before/after steering
- **Context vs parametric knowledge contrast**: Why needed - to identify context-reliance patterns; Quick check - measure activation differences between conditions
- **Residual activation injection**: Why needed - to implement steering without architectural changes; Quick check - verify steering direction injection at correct layer
- **Contrastive example construction**: Why needed - to create meaningful steering vectors; Quick check - validate positive/negative example quality

## Architecture Onboarding

**Component map:** Context examples -> Activation extraction -> Contrast computation -> Steering vector construction -> Inference-time injection -> Output generation

**Critical path:** Input context → Activation extraction → Steering vector computation → Residual injection → Response generation

**Design tradeoffs:** 
- Data efficiency vs. steering quality (1.5k examples vs. potentially better performance with more)
- Inference speed vs. steering strength (single pass vs. multiple passes)
- Model compatibility vs. steering effectiveness (works with various models but optimal settings may vary)

**Failure signatures:**
- Steering vector poorly constructed leading to irrelevant context emphasis
- Oversteering causing fluency degradation or context hallucination
- Insufficient contrast between context and parametric knowledge leading to minimal improvement

**First experiments:**
1. Test steering effectiveness on simple context-grounded QA tasks
2. Measure fluency impact at different steering strengths (multipliers)
3. Validate steering vector construction with synthetic context-parametric pairs

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to single task (ConFiQA) with 1.5k examples
- Steering strength fixed at multiplier 2 without optimization across domains
- Computational overhead during inference not quantified for production use
- Potential biases in example selection and impact of noisy context unaddressed

## Confidence
- Performance improvements on ConFiQA: High
- Generalizability to other tasks and models: Medium
- Scalability and robustness in real-world deployment: Low

## Next Checks
1. Evaluate ContextFocus on diverse retrieval-augmented generation tasks beyond ConFiQA to assess generalizability
2. Test the impact of steering vector quality (e.g., noisy or incomplete context) on model outputs and faithfulness
3. Quantify the computational overhead of ContextFocus during inference and compare it to baseline methods like fine-tuning and contrastive decoding