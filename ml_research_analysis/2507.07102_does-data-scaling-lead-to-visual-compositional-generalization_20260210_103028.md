---
ver: rpa2
title: Does Data Scaling Lead to Visual Compositional Generalization?
arxiv_id: '2507.07102'
source_url: https://arxiv.org/abs/2507.07102
tags:
- concept
- combinations
- compositional
- generalization
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether scaling data and model size improves
  compositional generalization in vision models. The authors design controlled experiments
  to isolate the effects of data scale, concept diversity, and combination coverage
  on compositional generalization.
---

# Does Data Scaling Lead to Visual Compositional Generalization?

## Quick Facts
- arXiv ID: 2507.07102
- Source URL: https://arxiv.org/abs/2507.07102
- Reference count: 40
- Primary result: Compositional generalization is driven by data diversity rather than scale alone; increased combinatorial coverage forces models to discover linearly factored representations.

## Executive Summary
This paper investigates whether scaling data and model size improves compositional generalization in vision models. Through controlled experiments, the authors find that compositional generalization is driven by data diversity rather than scale alone. They demonstrate that increased combinatorial coverage forces models to discover linearly factored representations, where concepts decompose into additive components. The authors prove that this structure is key to efficiency, enabling perfect generalization from few observed combinations. Evaluation of pretrained models shows above-random yet imperfect performance, suggesting partial presence of this structure.

## Method Summary
The authors use a (n,k)-framework where n represents concept values per dimension and k represents training combinations per value. They generate synthetic datasets (dSprites, 3DShapes, FSprites) and controlled versions of natural datasets (PUG-Animal, Colored-MNIST) with systematic concept combinations. ResNet-50 models are trained with shared backbones and separate linear heads for each concept. They employ oracle model selection on test sets and evaluate zero-shot accuracy on unseen combinations. For pretrained models (DINO, CLIP), they use frozen features with linear or MLP probes. Representation analysis includes linearity (R²) and orthogonality metrics.

## Key Results
- Data diversity, not scale, drives compositional generalization
- Increased combinatorial coverage forces discovery of linearly factored representations
- Linear factorization enables efficient compositionality with k=2 training combinations per concept value
- Pretrained models show above-random but imperfect compositional generalization

## Why This Works (Mechanism)

### Mechanism 1: Linear Factorization Emergence Through Data Diversity
Increased combinatorial coverage forces models to discover linearly factored representations where concepts decompose into additive components. When training data exposes many concept combinations, the network learns to encode each concept value as a separate vector that can be summed to represent joint concepts, rather than memorizing joint embeddings for each combination.

### Mechanism 2: Three-Phase Feature Learning Trajectory
Models progress through three distinct phases based on training diversity: spurious features → discriminative features → linearly factored representations. Limited diversity allows shortcut learning (spurious correlations). Moderate diversity forces discriminability but concepts remain entangled. High diversity (>75% combinations) compels the network to learn orthogonal, linearly separable concept subspaces.

### Mechanism 3: Sample Efficiency Through Linear Structure
Under idealized linear factorization, k=2 training combinations per concept value suffices for perfect generalization to all unseen combinations. Each joint embedding can be decomposed, and with 2n equations from 2 combinations per value and 2n unknowns, the system is full-rank and solvable.

## Foundational Learning

- **Compositional Generalization**: Why needed - The paper's central question is whether models can generalize to novel concept combinations never seen during training. Quick check - Can you explain why memorizing 80% of combinations doesn't guarantee generalization to the remaining 20%?

- **Linear Factorization**: Why needed - The key representational structure that enables efficient compositionality. Quick check - If f(red_square) = f(red) + f(square), what happens when you subtract f(blue_circle) from f(blue_square)?

- **Concept Diversity vs. Data Scale**: Why needed - The paper's main finding distinguishes these two factors. Quick check - If you have 10,000 images but only 8 distinct concept combinations, will the model generalize better than with 1,000 images spanning 50 combinations?

## Architecture Onboarding

- Component map: (n,k)-framework controls n (concept values per dimension) and k (training combinations per value) → Train ResNet-50 with shared backbone and separate linear heads → Evaluate zero-shot OOD accuracy on unseen combinations → Analyze representation structure via linearity (R²) and orthogonality metrics

- Critical path: (1) Generate/select dataset with controlled (n,k) → (2) Train model with oracle selection on test set → (3) Evaluate zero-shot OOD accuracy on unseen combinations → (4) Analyze representation structure via linearity (R²) and orthogonality metrics

- Design tradeoffs: Oracle model selection isolates model capability but overestimates practical performance; using only two labeled concepts simplifies analysis but may not reflect real-world complexity; synthetic datasets enable control but limit ecological validity

- Failure signatures: High ID accuracy (>95%) with large OOD drops (>50%) indicates failure to learn compositional structure; decodable features (>90% accuracy with linear probe on balanced data) with low linearity (R² < 0.5) indicates entangled representations

- First 3 experiments:
  1. **Baseline diversity test**: Train ResNet-50 on dSprites with n=6, k=2. Measure ID vs OOD accuracy gap. Expected: 60-80% OOD drop.
  2. **Scale ablation**: Keep n=3, k=2 fixed. Vary dataset size from 7.5K to 120K samples. Verify OOD accuracy doesn't improve (validates scale ≠ diversity).
  3. **Diversity sweep**: Fix dataset size, vary k from 2 to n-1 (covering 25% to ~100% of combinations). Plot linearity R² and OOD accuracy. Expected: both increase together, with inflection around 75% coverage.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the theoretical requirement of joint linear independence be relaxed to better handle concept representations in low-dimensional subspaces?
- Basis in paper: The authors explicitly state this assumption can be relaxed for future work.
- Why unresolved: Current proofs rely on idealized linear independence that often breaks down as concept values increase and factors occupy lower-dimensional subspaces.
- What evidence would resolve it: A theoretical proof or empirical demonstration showing perfect or near-perfect compositional generalization is achievable even when concept vectors are not strictly linearly independent.

### Open Question 2
- Question: Does the emergence of linearly factored representations hold in scenarios involving more than two concept dimensions?
- Basis in paper: The paper acknowledges focusing on pairs of concepts suggests handling more concepts would be even more difficult.
- Why unresolved: It's unclear if the three-phase learning dynamic and resulting linear factorization scale effectively to higher-dimensional concept spaces.
- What evidence would resolve it: Experimental results applying the (n,k) framework to synthetic datasets with 3 or more interacting latent factors.

### Open Question 3
- Question: What data curation strategies can induce linearly factored representations in large-scale models despite the inherent sparsity of natural datasets?
- Basis in paper: The paper finds high diversity is required for linear structure but notes real-world datasets exhibit critical sparsity.
- Why unresolved: There's a conflict between the finding that high combinatorial coverage forces linear structure and the reality that web-scale data is combinatorially sparse.
- What evidence would resolve it: A training regime or sampling algorithm that achieves linearly factored representations on large-scale, sparse data without requiring exhaustive observation of concept combinations.

## Limitations

- The (n,k) framework uses only two labeled concept dimensions while leaving other attributes unlabeled, potentially allowing models to exploit shortcuts
- Oracle model selection on test sets provides upper bounds but doesn't reflect realistic deployment scenarios
- Synthetic datasets enable control but may not capture the complexity and spurious correlations present in natural images
- The relationship between idealized linear factorization and real-world data distribution remains unclear

## Confidence

**High Confidence**: The empirical finding that data diversity, not scale, drives compositional generalization. Controlled experiments clearly show increasing dataset size while holding diversity constant doesn't improve OOD performance, while increasing coverage of concept combinations does improve both linearity metrics and generalization.

**Medium Confidence**: The claim that linear factorization emerges naturally when sufficient combinations are observed. While R² and orthogonality metrics strongly support this across multiple datasets, the theoretical mechanism relies on specific assumptions about network capacity and optimization landscape that weren't rigorously tested.

**Low Confidence**: The theoretical bound that k=2 combinations suffice for perfect generalization. This elegant result depends on idealized assumptions (linear independence, balanced data) that likely break down in practical scenarios with more than two concepts or correlated features.

## Next Checks

1. **Distribution Shift Robustness**: Evaluate the (n,k) framework on natural image datasets (e.g., COCO, VGGFace2) where concept correlations and spurious features are more prevalent to test whether linear factorization emerges under realistic data distributions.

2. **Multi-Concept Extension**: Scale the framework beyond two concept dimensions to test whether linear factorization scales to real-world compositional complexity and measure how orthogonality and linearity metrics degrade as concept count increases.

3. **Representation Analysis Under Noise**: Introduce label noise, concept correlations, and domain shifts into synthetic datasets to stress-test the emergence of linear factorization and track whether the three-phase learning trajectory remains robust.