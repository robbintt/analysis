---
ver: rpa2
title: AlignMerge - Alignment-Preserving Large Language Model Merging via Fisher-Guided
  Geometric Constraints
arxiv_id: '2512.16245'
source_url: https://arxiv.org/abs/2512.16245
tags:
- alignment
- fisher
- safety
- expert
- utility
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "ALIGNMERGE introduces a geometry-aware model merging framework\
  \ that treats alignment as an invariant rather than a scalar metric. By operating\
  \ in a local Fisher chart around an instruction-tuned anchor, it explicitly constrains\
  \ merges to respect alignment-sensitive directions using a combination of Fisher\u2013\
  geodesic proximity, an alignment-subspace penalty, and a soft alignment budget."
---

# AlignMerge - Alignment-Preserving Large Language Model Merging via Fisher-Guided Geometric Constraints

## Quick Facts
- arXiv ID: 2512.16245
- Source URL: https://arxiv.org/abs/2512.16245
- Authors: Aniruddha Roy; Jyoti Patel; Aman Chadha; Vinija Jain; Amitava Das
- Reference count: 40
- One-line primary result: Alignment-preserving model merging that treats alignment as an invariant, improving safety metrics while maintaining utility

## Executive Summary
AlignMerge introduces a geometry-aware framework for merging large language models that explicitly preserves alignment properties during model composition. Rather than treating alignment as a post-hoc metric, the approach embeds it as a geometric constraint within the merging process. By operating in a local Fisher chart around an instruction-tuned anchor model, AlignMerge constrains merges to respect alignment-sensitive directions using a combination of Fisher-geodesic proximity, an alignment-subspace penalty, and a soft alignment budget. This enables the creation of merged models that consistently outperform standard merging schemes on alignment metrics while matching or exceeding expert-level utility across five model families.

## Method Summary
AlignMerge treats alignment as an invariant geometric property rather than a scalar metric during model merging. The method operates within a local Fisher chart centered on an instruction-tuned anchor model, using Fisher information matrices to define a Riemannian geometry for parameter space. During merging, it applies three key constraints: Fisher-geodesic proximity to maintain geometric consistency, an alignment-subspace penalty to prevent drift away from alignment-sensitive directions, and a soft alignment budget to limit deviations from the anchor's alignment profile. This geometric approach ensures that merged models inherit both the utility of diverse base models and the alignment properties of the anchor, resulting in consistent improvements across safety and instruction-following metrics.

## Key Results
- Consistent improvements in alignment metrics (AQI, toxicity reduction, LLM-judge scores) across five model families
- Outperforms standard merging schemes and safety-aware baselines while maintaining or exceeding expert-level utility
- Reduces alignment-subspace drift and alignment budget violations compared to unconstrained merging approaches

## Why This Works (Mechanism)
AlignMerge works by embedding alignment preservation directly into the geometric structure of the merging process. By operating in a Fisher information-based Riemannian geometry, the method can distinguish between parameter directions that affect alignment versus those that affect general capabilities. The Fisher-geodesic constraint ensures that merged models remain close to the anchor's alignment trajectory in parameter space, while the alignment-subspace penalty explicitly prevents drift away from alignment-sensitive directions. The soft alignment budget provides a tunable constraint that allows some flexibility in utility improvement while preventing excessive alignment degradation. This integrated approach treats alignment as a first-class design goal rather than an afterthought, resulting in merged models that are both capable and aligned.

## Foundational Learning

**Fisher Information Geometry**
- Why needed: Provides the mathematical foundation for defining alignment-sensitive directions in parameter space
- Quick check: Can be verified by computing Fisher matrices for different model layers and observing alignment-related eigenvectors

**Riemannian Parameter Spaces**
- Why needed: Enables geometric constraints on model merging that respect the intrinsic structure of neural network parameters
- Quick check: Validate by measuring geodesic distances between models with known alignment relationships

**Alignment Subspace Identification**
- Why needed: Allows the method to distinguish between parameters affecting alignment versus general capabilities
- Quick check: Test by perturbing parameters in alignment vs. non-alignment directions and measuring metric changes

**Instruction-Tuned Anchors**
- Why needed: Provides a reference point with known alignment properties for the merging process
- Quick check: Verify anchor alignment through standard benchmarks before merging

**Soft Constraint Optimization**
- Why needed: Balances alignment preservation with utility improvement during merging
- Quick check: Tune alignment budget parameter and observe trade-offs between alignment and capability metrics

## Architecture Onboarding

**Component Map**
Anchor Model -> Fisher Chart Construction -> Alignment Subspace Detection -> Merging Optimization -> Merged Model

**Critical Path**
The critical path involves constructing the Fisher chart from the anchor model, detecting alignment-sensitive directions, and then performing constrained optimization during the merging process. Each step depends on the successful completion of the previous one, with the Fisher chart providing the geometric foundation for all subsequent operations.

**Design Tradeoffs**
The method trades computational complexity (Fisher information computation) for alignment preservation guarantees. The soft alignment budget introduces a tunable hyperparameter that allows users to balance alignment preservation against utility improvement, but requires empirical tuning for different use cases.

**Failure Signatures**
- Excessive alignment budget violations indicate the merging process is prioritizing utility over alignment
- High alignment-subspace drift suggests the Fisher chart construction or alignment detection failed
- Poor utility metrics despite alignment preservation may indicate overly restrictive constraints

**First Experiments**
1. Verify Fisher chart construction by computing geodesic distances between models with known alignment relationships
2. Test alignment subspace detection by perturbing parameters in detected directions and measuring metric changes
3. Validate merging constraints by performing merges with varying alignment budgets and measuring trade-offs

## Open Questions the Paper Calls Out

The paper does not explicitly call out specific open questions, focusing instead on demonstrating the effectiveness of the proposed approach.

## Limitations

The method relies on a local Fisher chart assumption that may not hold for highly divergent architectures or non-smooth alignment trajectories. The alignment budget introduces a hyperparameter requiring empirical tuning that may not generalize across domains with different alignment objectives. The approach depends on pairwise LLM judge comparisons for evaluation, introducing subjectivity and potential bias.

## Confidence

**High confidence** in the geometric formulation's ability to preserve alignment directions during merging, supported by quantitative improvements across multiple metrics. **Medium confidence** in the practical utility and robustness of the alignment budget constraint, as improvements are sensitive to budget tuning and rely on proxy metrics. **Low confidence** in generalizability to all model families and alignment objectives, given limited architectural diversity in evaluation.

## Next Checks

1. **Cross-Architecture Generalization Test**: Evaluate AlignMerge on diverse model families with different pre-training objectives to assess robustness beyond current five families.

2. **Scalability Benchmark**: Implement and benchmark Fisher information computation on models with >100B parameters, measuring computational requirements and approximation error.

3. **Human Evaluation Study**: Conduct user studies with diverse annotators to validate that LLM-judge scores correlate with human judgments of alignment, safety, and utility in real-world use cases.