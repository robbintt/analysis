---
ver: rpa2
title: Near Optimal Best Arm Identification for Clustered Bandits
arxiv_id: '2505.10147'
source_url: https://arxiv.org/abs/2505.10147
tags:
- best
- agents
- bandits
- agent
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses best arm identification in federated multi-agent
  multi-armed bandits with unknown agent-bandit mappings and agent clustering. The
  authors propose two novel algorithms, Cl-BAI (Clustering then Best Arm Identification)
  and BAI-Cl (Best Arm Identification then Clustering), both leveraging successive
  elimination for computational efficiency.
---

# Near Optimal Best Arm Identification for Clustered Bandits

## Quick Facts
- arXiv ID: 2505.10147
- Source URL: https://arxiv.org/abs/2505.10147
- Reference count: 40
- Primary result: Two novel algorithms (Cl-BAI and BAI-Cl) achieve near-optimal sample complexity for best arm identification in clustered bandit settings, with BAI-Cl++ showing 72% improvement over naive schemes

## Executive Summary
This paper addresses best arm identification in federated multi-agent multi-armed bandit problems where agents are clustered and share similar preferences. The authors propose two novel algorithms that exploit the clustering structure to achieve significant improvements in sample and communication efficiency. The key insight is that clustering agents first (Cl-BAI) or identifying best arms first (BAI-Cl) can dramatically reduce the number of samples needed compared to treating each agent independently. The algorithms leverage successive elimination for computational efficiency and provide theoretical guarantees on their performance.

## Method Summary
The paper proposes two complementary algorithms for clustered best arm identification. Cl-BAI (Clustering then Best Arm Identification) first clusters agents based on their observed bandit behaviors, then performs BAI within each cluster using the identified cluster centers. BAI-Cl (Best Arm Identification then Clustering) reverses this order, identifying the best arm for each agent first, then clustering agents based on their best arms. Both algorithms use successive elimination to maintain computational efficiency. A variant BAI-Cl++ is shown to be order-wise minimax optimal when the number of clusters M is small relative to the number of agents N. The algorithms operate in a fixed confidence setting, providing δ-probably correct guarantees.

## Key Results
- Cl-BAI and BAI-Cl algorithms achieve δ-probably correct (δ-PC) performance with improved sample complexity
- When M is small (constant), BAI-Cl++ is order-wise minimax optimal
- Experimental results show 72% improvement in sample complexity over naive schemes on MovieLens dataset with 100 users clustered into 6 age groups
- Both algorithms demonstrate significant improvements in communication efficiency compared to agent-independent approaches

## Why This Works (Mechanism)
The algorithms exploit the inherent structure in clustered bandit problems where agents within clusters share similar best arms. By either clustering first and then solving BAI within clusters, or solving BAI first and then clustering based on best arms, the algorithms reduce redundant exploration across similar agents. The successive elimination technique ensures computational efficiency by eliminating suboptimal arms early in the process. The theoretical guarantees leverage concentration inequalities adapted to the clustered setting, providing confidence that the identified best arms are indeed optimal within their respective clusters.

## Foundational Learning
- **Clustered bandit problems**: Understanding that agents can be grouped into clusters with shared characteristics - needed to exploit structure for efficiency gains
- **Successive elimination**: Technique for progressively eliminating suboptimal arms - needed for computational tractability
- **Fixed confidence setting**: Framework where algorithms must achieve a specified confidence level - needed for theoretical guarantees
- **δ-probably correct (δ-PC)**: Performance metric ensuring algorithms are correct with probability at least 1-δ - needed for rigorous evaluation
- **Minimax optimality**: Concept measuring worst-case performance - needed to establish algorithm efficiency bounds
- **Communication efficiency**: Metric measuring information exchange requirements - needed for federated learning contexts

## Architecture Onboarding

**Component map:** Data collection -> Clustering/BAI decision -> Arm elimination -> Best arm identification -> Cluster assignment

**Critical path:** Observation collection → Algorithm selection (Cl-BAI or BAI-Cl) → Iterative elimination → Final best arm determination

**Design tradeoffs:** Clustering first (Cl-BAI) vs BAI first (BAI-Cl) represents a fundamental tradeoff between exploration efficiency and clustering accuracy. The choice affects sample complexity and computational requirements differently depending on problem structure.

**Failure signatures:** Poor clustering quality leads to suboptimal best arm identification within clusters. Excessive arm eliminations early in the process may prevent discovery of optimal arms. Communication bottlenecks may arise in federated settings with poor network connectivity.

**3 first experiments:** 1) Validate clustering accuracy on synthetic data with known cluster structure, 2) Compare sample complexity of Cl-BAI vs BAI-Cl on varying cluster sizes, 3) Test communication efficiency in federated setting with simulated network delays

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Clustering assumption may not hold when agent preferences exhibit gradual rather than discrete variations
- Fixed confidence setting restricts applicability to scenarios where δ can be predetermined
- Theoretical guarantees rely on standard bandit assumptions that may not capture all real-world complexities
- Communication cost analysis lacks detailed quantitative bounds across different network topologies

## Confidence

**Confidence Levels:**
- High confidence in algorithmic framework and basic correctness of clustering and BAI procedures
- Medium confidence in theoretical sample complexity bounds, dependent on specific problem parameters
- Medium confidence in empirical improvements shown, based on limited real-world datasets
- Low confidence in generalizability of minimax optimality claims beyond analyzed problem structure

## Next Checks
1. Empirical evaluation on additional real-world datasets with varying clustering structures and bandit problem characteristics to test robustness
2. Systematic sensitivity analysis of algorithm performance to violations of the core assumption that agents within clusters share identical best arms
3. Detailed benchmarking of communication costs across different network topologies and comparison with explicit communication-efficient baselines