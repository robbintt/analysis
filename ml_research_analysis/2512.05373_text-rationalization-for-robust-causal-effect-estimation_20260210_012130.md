---
ver: rpa2
title: Text Rationalization for Robust Causal Effect Estimation
arxiv_id: '2512.05373'
source_url: https://arxiv.org/abs/2512.05373
tags:
- causal
- text
- treatment
- confounding
- positivity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses a fundamental challenge in causal inference
  with high-dimensional text confounders: observational-level positivity violations.
  These violations occur when irrelevant or spurious text features inflate dimensionality,
  causing estimated propensity scores to concentrate near 0 or 1, even when the underlying
  positivity assumption holds.'
---

# Text Rationalization for Robust Causal Effect Estimation

## Quick Facts
- arXiv ID: 2512.05373
- Source URL: https://arxiv.org/abs/2512.05373
- Reference count: 17
- Addresses observational-level positivity violations in text confounders for causal inference

## Executive Summary
This paper tackles a fundamental challenge in causal inference with high-dimensional text confounders: observational-level positivity violations. These violations occur when irrelevant or spurious text features inflate dimensionality, causing estimated propensity scores to concentrate near 0 or 1, even when the underlying positivity assumption holds. The authors propose Confounding-Aware Token Rationalization (CATR), a framework that selects sparse token subsets sufficient for confounding adjustment while mitigating these violations. Through residual HSIC diagnostics and a carefully designed objective function, CATR improves overlap, reduces weight instability, and yields more stable ATE estimates compared to existing baselines on both synthetic and MIMIC-III clinical data.

## Method Summary
The authors propose Confounding-Aware Token Rationalization (CATR), a framework that selects sparse token subsets sufficient for confounding adjustment while mitigating observational-level positivity violations. CATR uses residual Hilbert-Schmidt Independence Criterion (HSIC) as a diagnostic to identify token subsets that preserve the conditional independence structure required for unconfoundedness. The method balances predictive accuracy, sparsity, and sufficiency for valid causal adjustment through an objective function incorporating supervised loss, sparsity regularization, and HSIC penalty. Experiments on synthetic data and real-world MIMIC-III clinical data demonstrate that CATR consistently improves overlap, reduces weight instability and variance, and yields more stable and interpretable ATE estimates compared to existing baselines.

## Key Results
- CATR improves overlap and reduces weight instability in high-dimensional text confounders
- The method yields more stable and interpretable ATE estimates compared to existing baselines
- Performance improvements are consistent across synthetic data and real-world MIMIC-III clinical data

## Why This Works (Mechanism)
The mechanism addresses a critical gap in causal inference with text data. Traditional approaches either include all text features (leading to positivity violations) or use black-box selection methods that may remove essential confounders. CATR's innovation lies in using residual HSIC to identify which tokens are truly necessary for confounding adjustment. By explicitly modeling the conditional independence structure and penalizing both dimensionality and residual dependence, the method ensures that selected tokens are both sufficient for unconfoundedness and sparse enough to maintain overlap. This dual objective of sufficiency and sparsity is what distinguishes CATR from prior approaches.

## Foundational Learning
**Positivity violation** - Occurs when estimated propensity scores concentrate near 0 or 1, causing unstable inverse probability weights. Why needed: Fundamental problem in causal inference with high-dimensional confounders. Quick check: Examine propensity score distributions before and after CATR application.

**Hilbert-Schmidt Independence Criterion (HSIC)** - A kernel-based measure of statistical dependence between random variables. Why needed: Provides diagnostic for identifying tokens that preserve confounding structure. Quick check: Compute HSIC values for different token subsets to validate independence assumptions.

**Semiparametric efficiency** - Framework for optimal estimation when part of the model is parametric and part is nonparametric. Why needed: Underpins theoretical guarantees for CATR estimators. Quick check: Verify efficiency bounds hold in simulation studies.

**Confounding adjustment sufficiency** - Property where selected variables are sufficient to block all backdoor paths. Why needed: Ensures causal effect estimates are unbiased. Quick check: Test conditional independence between treatment and outcome given selected tokens.

## Architecture Onboarding

**Component Map**: Text Preprocessing -> Token Rationalization (CATR) -> Propensity Score Estimation -> Weight Calculation -> ATE Estimation

**Critical Path**: The core algorithm iteratively selects tokens by optimizing the objective function that balances supervised loss (L_sup), sparsity regularization (λ||θ||₁), and HSIC penalty (γR_HSIC). The residual HSIC calculation identifies tokens whose removal doesn't affect the conditional independence structure, ensuring sufficiency for confounding adjustment.

**Design Tradeoffs**: CATR trades computational complexity (HSIC calculations) for improved statistical efficiency and interpretability. The sparsity constraint prevents overfitting but requires careful tuning of λ. The HSIC penalty ensures validity but adds computational overhead. Compared to black-box methods, CATR sacrifices some predictive accuracy for causal validity and interpretability.

**Failure Signatures**: If λ is too small, the method may retain too many tokens and suffer from positivity violations. If λ is too large, essential confounders may be removed, leading to biased estimates. Poor kernel choice for HSIC can result in incorrect identification of residual independence. The method assumes observed confounding structure is correctly specified; violations of this assumption can lead to residual confounding.

**First Experiments**:
1. Synthetic data with known confounding structure to verify sufficiency and sparsity properties
2. Ablation study removing HSIC penalty to quantify its contribution to overlap improvement
3. Sensitivity analysis varying λ to understand sparsity-accuracy tradeoff

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the text provided.

## Limitations
- Computational complexity may become prohibitive for very long documents or high-dimensional multimodal inputs
- Theoretical guarantees rely on assumptions about correctly specified confounding structure that may not hold in practice
- Limited validation to single clinical dataset (MIMIC-III) raises questions about generalizability to other domains

## Confidence
- **Theoretical Analysis**: Medium - Establishes important bounds but relies on strong assumptions
- **Synthetic Experiments**: Medium-High - Controlled evidence but limited real-world complexity
- **MIMIC-III Results**: Medium-High - Promising but limited to single clinical domain
- **Scalability Claims**: Low-Medium - Not thoroughly tested on larger text corpora

## Next Checks
1. Test CATR on longer text documents (e.g., full medical notes or social media posts) to evaluate computational scalability and performance degradation with increased token count.
2. Conduct sensitivity analyses to assess robustness when key confounding assumptions are violated, such as unmeasured confounding or incorrect treatment assignment mechanisms.
3. Apply the method to multiple heterogeneous domains (e.g., economics, social science, education) to evaluate generalizability beyond clinical text data.