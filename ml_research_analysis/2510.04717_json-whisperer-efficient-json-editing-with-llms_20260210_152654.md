---
ver: rpa2
title: 'JSON Whisperer: Efficient JSON Editing with LLMs'
arxiv_id: '2510.04717'
source_url: https://arxiv.org/abs/2510.04717
tags:
- json
- patch
- list
- llms
- ease
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper introduces JSON Whisperer, a framework that enables
  efficient JSON editing by having LLMs generate RFC 6902 diff patches instead of
  regenerating entire structures. This approach addresses two key challenges: LLMs
  missing related updates when generating isolated patches and struggling with array
  index arithmetic across operations.'
---

# JSON Whisperer: Efficient JSON Editing with LLMs

## Quick Facts
- arXiv ID: 2510.04717
- Source URL: https://arxiv.org/abs/2510.04717
- Authors: Sarel Duanis; Asnat Greenstein-Messica; Eliya Habba
- Reference count: 4
- Primary result: Patch generation with EASE reduces token usage by 31% while maintaining edit quality within 5% of full regeneration

## Executive Summary
JSON Whisperer introduces a framework for efficient JSON editing by having LLMs generate RFC 6902 diff patches instead of regenerating entire structures. The approach addresses two key challenges: LLMs missing related updates when generating isolated patches and struggling with array index arithmetic across operations. To solve these issues, the authors propose EASE (Explicitly Addressed Sequence Encoding), which transforms arrays into dictionaries with stable keys, eliminating index arithmetic complexities. The evaluation shows that patch generation with EASE reduces token usage by 31% while maintaining edit quality within 5% of full regeneration, with particularly strong improvements for complex instructions and list manipulations.

## Method Summary
JSON Whisperer enables efficient JSON editing through patch-based approaches. Instead of regenerating entire JSON structures, LLMs output RFC 6902 diff patches that are applied deterministically. The EASE encoding transforms arrays into dictionaries with stable two-character keys and a `list_display_order` field to eliminate index arithmetic errors. The framework uses a synthetic data pipeline where a strong LLM generates JSON instances, edit requests, and rewritten outputs, with a diff algorithm extracting ground-truth patches. DSPy optimizes few-shot example selection from this pool. The system transforms arrays to dictionaries pre-inference, generates patches using in-context examples, applies operations deterministically, then decodes back to native JSON format.

## Key Results
- Patch generation with EASE reduces token usage by 31% while maintaining edit quality within 5% of full JSON regeneration
- EASE encoding improves patch execution success rate from 89% to 98% for list manipulation tasks
- Few-shot examples provide substantial performance improvements over zero-shot, with F1 scores improving from 0.09-0.61 to 0.48-0.74 across model sizes

## Why This Works (Mechanism)

### Mechanism 1: Patch-Based Editing Reduces Token Overhead
Generating RFC 6902 diff patches instead of full JSON regeneration reduces output tokens while maintaining comparable edit quality. The LLM receives the original JSON and edit instruction, outputs only necessary patch operations (op, path, value triples), which a standard patching algorithm applies deterministically. Core assumption: edit scope is localized; most modifications affect a small fraction of total structure. Evidence: output token count drops from 909 (full rewrite) to 529 (few-shot+EASE), a 42% reduction for Claude.

### Mechanism 2: EASE Eliminates Index Arithmetic Errors
Converting arrays to dictionaries with stable two-character keys removes LLM errors from tracking index shifts across sequential operations. Arrays become key-value mappings with a `list_display_order` field. Operations reference stable keys rather than shifting numerical indices, making patch execution order-invariant. Core assumption: LLMs can reliably generate and reference arbitrary string keys. Evidence: EASE shows 98% patch execution success vs. 89% for standard indexing on list manipulations.

### Mechanism 3: Synthetic Few-Shot Examples Enable Patch Generation
Automatically generated (JSON, instruction, patch) triples provide sufficient signal for LLMs to learn patch generation patterns. A strong LLM generates JSON instances, edit requests, and rewritten outputs; a diff algorithm extracts ground-truth patches. DSPy optimizes example selection from this pool. Core assumption: synthetic examples distribution matches real-world edit patterns. Evidence: Zero-shot F1 scores (0.09-0.61) improve dramatically to few-shot (0.48-0.74) across model sizes.

## Foundational Learning

- **RFC 6902 JSON Patch format**: The entire framework depends on understanding patch operations (`add`, `remove`, `replace`), JSON Pointer paths (`/users/0/name`), and value fields. Quick check: Given `{"op": "remove", "path": "/items/2"}`, what happens if indices shift after a prior removal?

- **JSON Pointer syntax (RFC 6901)**: Paths like `/scene/weather` or `/shots/0/type` are the addressing mechanism; misunderstanding zero-based indexing or escaping causes patch failures. Quick check: How would you reference a key literally named `a/b` in a JSON Pointer?

- **Few-shot in-context learning with DSPy**: The method relies on programmatically selecting optimal examples from a synthetic pool rather than manual curation. Quick check: What happens to input token costs as the few-shot example pool grows for larger JSON schemas?

## Architecture Onboarding

- **Component map**: Schema-specific synthetic generator → DSPy optimizer → EASE encoder/decoder → LLM inference → patch executor
- **Critical path**: EASE encoding → few-shot example retrieval → LLM patch generation → patch execution → EASE decoding. Latency bottleneck is LLM inference; token reduction directly improves this.
- **Design tradeoffs**: Input token overhead vs. output token savings (few-shot examples increase input); EASE conversion cost vs. accuracy gains; synthetic data quality vs. real distribution match.
- **Failure signatures**: High patch execution failure rate → check for index arithmetic errors; low F1 on complex edits → few-shot examples may lack coverage; schema drift errors → instruction requires structural changes outside schema.
- **First 3 experiments**: (1) Baseline comparison: full regeneration vs. zero-shot patch vs. few-shot patch on held-out test set; (2) Ablate EASE: compare standard indexing vs. EASE on list manipulations; (3) Synthetic data quality check: manually inspect 20-50 synthetic examples for instruction diversity and patch correctness.

## Open Questions the Paper Calls Out

- **Can fine-tuning open-source LLMs for patch generation eliminate the need for few-shot examples and improve accuracy on larger JSON documents?**: The authors suggest fine-tuning could eliminate few-shot needs and enable more efficient processing of larger documents, but no fine-tuning experiments were conducted.

- **At what JSON document size does the input token overhead from in-context examples and EASE encoding offset the output token savings, potentially hitting context window limits?**: The limitations section notes in-context learning increases input token overhead as JSON objects grow larger, which could offset cost savings and lead to context window limitations.

- **How does JSON Whisperer generalize to other structured data formats (YAML, Git diffs) and domains beyond film production?**: The conclusion states the method could be extended to YAML and Git diff formats, but evaluation was limited to a single domain and JSON format.

- **How does patch-based editing performance compare between real user edits versus synthetically generated edit instructions?**: The authors acknowledge both training and evaluation rely on synthetic data, which may not fully reflect real-world JSON editing scenarios.

## Limitations
- Synthetic data distribution may not capture real-world edit patterns, creating potential overfitting concerns
- Evaluation scope limited to specific scene/shot structure with controlled complexity levels, unclear how approach scales to more complex JSON documents
- No stress testing reported for edge cases like deeply nested structures, schemas with conflicting field names, or instructions requiring structural changes beyond schema

## Confidence

**High Confidence**: Core mechanism of patch-based editing reducing token overhead is well-supported by direct token count measurements (42% reduction observed). EASE encoding's elimination of index arithmetic errors is validated by 9% absolute improvement in patch execution success rates.

**Medium Confidence**: Synthetic few-shot learning approach shows substantial improvements over zero-shot, but transfer from synthetic to real-world distributions remains unverified. Quality maintenance within 5% of full regeneration relies on LLM-as-judge evaluation.

**Low Confidence**: Scalability claims to larger JSON documents are not empirically validated. No experimental data on performance degradation with increasing document size or complexity beyond controlled test set.

## Next Checks
1. **Real-World Distribution Validation**: Collect 100-200 naturally occurring JSON editing instructions from actual user logs, evaluate JSON Whisperer's performance, and compare against synthetic test set results to quantify synthetic-to-real transfer gap.

2. **Stress Testing on Complex Schemas**: Design benchmark datasets with varying complexity levels (deeply nested structures, irregular schemas, large arrays, structural changes) and measure performance degradation across these dimensions to identify breaking points.

3. **Long-Term Stability Assessment**: Run longitudinal study with 10-20 sequential edits on same documents, tracking cumulative token savings vs. full regeneration, error propagation through sequential patches, EASE key collision rates, and quality degradation accumulation.