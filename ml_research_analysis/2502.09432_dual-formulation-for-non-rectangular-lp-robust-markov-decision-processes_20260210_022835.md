---
ver: rpa2
title: Dual Formulation for Non-Rectangular Lp Robust Markov Decision Processes
arxiv_id: '2502.09432'
source_url: https://arxiv.org/abs/2502.09432
tags:
- robust
- uncertainty
- policy
- kernel
- sets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of robust policy evaluation
  in non-rectangular Markov decision processes (MDPs) with Lp-bounded uncertainty
  sets, a problem that is generally NP-hard. The key insight is decomposing the non-rectangular
  uncertainty set into infinitely many sa-rectangular Lp-bounded sets, enabling the
  derivation of a novel dual formulation.
---

# Dual Formulation for Non-Rectangular Lp Robust Markov Decision Processes

## Quick Facts
- arXiv ID: 2502.09432
- Source URL: https://arxiv.org/abs/2502.09432
- Reference count: 40
- One-line primary result: This paper develops the first efficient robust policy evaluation algorithm for non-rectangular Lp-bounded uncertainty sets by decomposing them into infinitely many sa-rectangular sets, providing a novel dual formulation and demonstrating significant empirical improvements over brute-force methods.

## Executive Summary
This paper addresses the challenge of robust policy evaluation in non-rectangular Markov decision processes (MDPs) with Lp-bounded uncertainty sets, a problem that is generally NP-hard. The key insight is decomposing the non-rectangular uncertainty set into infinitely many sa-rectangular Lp-bounded sets, enabling the derivation of a novel dual formulation. This formulation provides insights into the adversary's strategy and leads to the development of the first efficient robust policy evaluation algorithms. Empirical results demonstrate significant improvements over brute-force methods, establishing a promising foundation for future research into non-rectangular robust MDPs.

## Method Summary
The method decomposes a non-rectangular L2-bounded uncertainty set into infinitely many state-action rectangular sets, transforming the robust policy evaluation problem into a minimax fractional optimization. The worst-case transition kernel is characterized as a rank-one perturbation of the nominal kernel, enabling a closed-form expression for the robust return via the Sherman-Morrison formula. The robust penalty is computed through binary search on a fixed-point function, with a custom spectral method providing efficient evaluation of the required sub-routines. The algorithm achieves linear convergence and demonstrates significant improvements over brute-force sampling methods in empirical evaluations.

## Key Results
- The worst-case transition kernel for L2-bounded uncertainty sets is a rank-one perturbation of the nominal kernel, enabling closed-form robust return computation.
- A novel dual formulation provides insights into the adversary's strategy and enables efficient policy evaluation algorithms.
- Empirical results show significant improvements over brute-force methods, with the spectral algorithm outperforming scipy.minimize in both speed and reliability.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The paper avoids the general NP-hardness of non-rectangular robust MDPs by decomposing the uncertainty set.
- Mechanism: The authors show that a non-rectangular $L_p$-bounded uncertainty set $U_p$ can be expressed as an infinite union of sa-rectangular sets $U_{sa}^p(b)$ (Proposition 3.2). This allows the robust policy evaluation problem to be reformulated from an intractable global optimization into a minimax fractional optimization problem: $\min_{b} \min_{P \in U_{sa}^p(b)} J^\pi_P$. This decomposition bridges the gap between the flexibility of non-rectangular sets and the tractability of rectangular ones.
- Core assumption: The uncertainty set is $L_p$-bounded ($p > 1$), which structurally differs from the polyhedral sets used in NP-hardness proofs.
- Evidence anchors:
  - [abstract] "decomposing the non-rectangular uncertainty set into infinitely many sa-rectangular Lp-bounded sets"
  - [section 3] "We conclude that Lp-robust MDPs are potentially tractable."
  - [corpus] Corpus signals confirm that RMDPs with rectangular assumptions are generally tractable, whereas non-rectangular ones are typically hard.
- Break condition: If the uncertainty set cannot be defined as a union of rectangular $L_p$ sets (e.g., complex polyhedral constraints), the decomposition fails, and the NP-hardness result likely holds.

### Mechanism 2
- Claim: The worst-case transition kernel is a rank-one perturbation of the nominal kernel.
- Mechanism: The paper demonstrates that for the specified uncertainty sets, the optimal adversarial strategy $P^\pi_U$ takes the form $\hat{P} - b k^\top$, where $\hat{P}$ is the nominal kernel (Theorem 4.1). This structural constraint allows the use of the Sherman–Morrison formula to derive a closed-form expression for the robust return. It transforms the search for a matrix (the kernel) into a search for vectors (perturbation direction $k$ and radius $b$).
- Core assumption: The adversary is restricted to the $L_p$-bounded uncertainty set defined around the nominal kernel.
- Evidence anchors:
  - [section 4] "The worst kernel... is a rank-one perturbation of the nominal kernel..."
  - [appendix C.4] Cites prior work [20] establishing rank-one perturbations in rectangular cases, extended here.
- Break condition: If the uncertainty set constraints allow for perturbations that are not rank-one (e.g., general dense matrix perturbations within an arbitrary ball), this closed-form characterization may not hold.

### Mechanism 3
- Claim: The penalty for robustness can be computed via binary search on a fixed-point function.
- Mechanism: The robust return is defined as $J^\pi - \lambda^*$, where $\lambda^*$ is the penalty. The paper establishes that $\lambda^*$ is the fixed point of a function $F(\lambda) = \max_{b \in B} \|E^\pi_\lambda b\|_q$. Crucially, $F(\lambda) > \lambda$ if and only if $\lambda > \lambda^*$ (Lemma 3.5). This monotonic property allows Algorithm 1 (Binary Search) to find the penalty with linear convergence ($O(2^{-n})$), replacing brute-force sampling.
- Core assumption: The function $F(\lambda)$ can be evaluated efficiently and respects the bisection property.
- Evidence anchors:
  - [section 3.2] "Furthermore, $\lambda^*$ can be found via binary search..."
  - [theorem 3.6] "Algorithm 1 converges linearly..."
  - [corpus] Related work often relies on iterative value iteration or sampling; fixed-point binary search is a distinct efficiency mechanism here.
- Break condition: If the evaluation of $F(\lambda)$ involves a sub-routine that fails or produces non-monotonic behavior (e.g., if the spectral approximation in Algorithm 2 is too loose), the binary search may converge to an incorrect penalty value.

## Foundational Learning

- **Concept: Rectangular vs. Non-Rectangular Uncertainty**
  - Why needed here: The paper's primary motivation is overcoming the limitations of rectangular assumptions (independent uncertainty across states) while avoiding the intractability of general non-rectangular sets. Understanding this distinction is required to grasp why the "decomposition" mechanism is novel.
  - Quick check question: Does an s-rectangular set assume independence of transition uncertainty between different states? (Yes).

- **Concept: Sherman–Morrison Formula**
  - Why needed here: This linear algebra identity is the mathematical engine that allows the authors to invert the perturbed kernel $(I - \gamma(\hat{P} - bk^\top))^{-1}$ efficiently. Without this, the dual formulation and the resulting closed-form robust return would not exist.
  - Quick check question: What structural property of the matrix inverse does the Sherman-Morrison formula exploit? (Rank-one updates).

- **Concept: Occupancy Measure (Dual Formulation)**
  - Why needed here: The paper derives a dual formulation for robust MDPs. Prerequisites include understanding that standard MDPs can be viewed either as value function optimization (primal) or state-visitation frequency optimization (dual).
  - Quick check question: In the dual formulation, what does the variable $d$ represent? (The discounted state-action occupancy measure).

## Architecture Onboarding

- **Component map**: Nominal Kernel $\hat{P}$ -> Binary Search (Algorithm 1) -> Spectral Method (Algorithm 2) -> Robust return $J^\pi_U$ and Worst-case Kernel $P^\pi_U$
- **Critical path**: The execution bottleneck is the repeated evaluation of $F(\lambda)$ inside the binary search loop. This requires solving a constrained matrix norm maximization problem. The paper provides a custom spectral method (Algorithm 2) with $O(S^3 A^3)$ complexity to replace brute-force optimization.
- **Design tradeoffs**:
  - **Generality vs. Tractability**: The method is restricted to $L_p$-bounded sets (specifically optimized for $p=2$). It does not solve general non-rectangular robust MDPs.
  - **Approximation vs. Speed**: Algorithm 2 (Spectral Method) is faster but approximates the global maximum compared to methods like `scipy.minimize`, although the paper claims it is often more reliable than local optimizers.
  - **Conservatism**: The paper argues that rectangular sets are overly conservative (exponentially larger volume). This architecture reduces conservatism by using spherical ($L_2$) uncertainty sets.
- **Failure signatures**:
  - **Invalid Kernels**: If the radius $\beta$ is set too large, the perturbed kernel $P^\pi_U = \hat{P} - bk^\top$ may contain negative probabilities or fail to sum to 1, breaking the simplex constraint.
  - **Non-convergence**: If the spectral method fails to find a valid positive eigenvector, the binary search may stall.
- **First 3 experiments**:
  1.  **Baseline Comparison (Figure 4/5)**: Implement Algorithm 1 (Binary Search + Spectral) vs. Random Kernel Sampling and `scipy.minimize` to validate the claimed speed and accuracy improvements on a simple chain MDP.
  2.  **Radius Sensitivity**: Stress-test the "small enough radius" assumption by increasing $\beta$ until the worst-case kernel generates invalid probabilities (negative entries), documenting the break point.
  3.  **Policy Gradient Validation**: Implement Algorithm 3 to verify if the computed worst-case kernel effectively guides policy updates to maximize the robust return in a noisy environment.

## Open Questions the Paper Calls Out

- **Open Question 1**: How can the dual formulation be effectively exploited for better algorithmic design given the potential non-convexity of the set $\mathcal{D}$?
  - Basis in paper: [explicit] The authors state, "We leave this as an open question for future work: How can we effectively exploit the above dual form for more insights and better algorithmic design?"
  - Why unresolved: The feasible set $\mathcal{D}$ in the dual formulation is suggested to be non-convex (Figure 3), which makes standard convex optimization techniques inapplicable.
  - What evidence would resolve it: A convergence proof for a new algorithm utilizing the dual form that improves upon the $O(\epsilon^{-8})$ iteration complexity of the proposed primal method.

- **Open Question 2**: Can the policy improvement methodology be adapted to be compatible with deep neural networks?
  - Basis in paper: [explicit] In the Discussion section, the authors note, "Another promising direction is to design policy improvement methodologies compatible with deep neural networks."
  - Why unresolved: The current theory and algorithms rely on tabular representations and exact matrix inversions (e.g., $D_\pi$), which are computationally intractable for high-dimensional function approximation.
  - What evidence would resolve it: The derivation of a robust policy gradient method using function approximation that retains convergence guarantees or demonstrates empirical success on high-dimensional benchmarks.

- **Open Question 3**: Can a stable actor-critic algorithm be developed where the worst-case kernel and the policy are updated simultaneously?
  - Basis in paper: [explicit] The paper mentions, "Alternatively, an actor-critic style algorithm can also be obtained, where the worst kernel and the policy are updated simultaneously. We leave this direction for a future work."
  - Why unresolved: The proposed Algorithm 3 is a double-loop method (outer loop for policy, inner loop for worst kernel); simultaneous updates typically introduce convergence instability that requires specific analysis.
  - What evidence would resolve it: Theoretical convergence analysis or empirical validation of a single-loop algorithm that matches the performance of the double-loop approach.

## Limitations

- The decomposition into infinitely many sa-rectangular sets, while theoretically sound, may face computational challenges in practice for very large state-action spaces where the spectral method's approximation quality degrades.
- The paper's assumption of "small enough" radius β is not quantified; empirical validation across varying radii is needed to establish practical bounds.
- The claim that s-rectangular sets are "exponentially more conservative" lacks formal proof, though supported by geometric intuition about L2 balls vs. product of intervals.

## Confidence

- **High Confidence**: The mathematical derivations of the dual formulation and worst-case kernel characterization are rigorous and well-supported by the proofs in the appendix.
- **Medium Confidence**: The empirical results showing improved performance over baselines are convincing, though limited to a single chain MDP environment.
- **Low Confidence**: The claim about exponential conservatism of rectangular sets requires formal analysis beyond the geometric argument presented.

## Next Checks

1. **Scalability Test**: Implement the spectral method on MDPs with S>1000 states to measure approximation error growth and runtime scaling.
2. **Radius Sensitivity Analysis**: Systematically vary β from 0.001 to 0.1 and measure the frequency of invalid kernel generation (negative probabilities) to establish practical bounds.
3. **Cross-Environment Validation**: Test the algorithm on grid-world and continuous-state MDPs to verify the robustness of the dual formulation beyond the chain MDP.