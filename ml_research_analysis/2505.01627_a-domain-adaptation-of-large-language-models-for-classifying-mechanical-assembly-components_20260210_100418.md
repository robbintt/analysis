---
ver: rpa2
title: A Domain Adaptation of Large Language Models for Classifying Mechanical Assembly
  Components
arxiv_id: '2505.01627'
source_url: https://arxiv.org/abs/2505.01627
tags:
- design
- function
- data
- mechanical
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of generating accurate functional
  annotations for mechanical assembly components in the early conceptual design phase.
  A domain adaptation framework using fine-tuning of large language models (LLMs)
  was proposed to improve automated classification of mechanical part functions.
---

# A Domain Adaptation of Large Language Models for Classifying Mechanical Assembly Components

## Quick Facts
- arXiv ID: 2505.01627
- Source URL: https://arxiv.org/abs/2505.01627
- Reference count: 40
- Pre-trained LLMs achieved ~93% accuracy after domain adaptation on mechanical component classification

## Executive Summary
This study addresses the challenge of generating accurate functional annotations for mechanical assembly components during early conceptual design. The research team developed a domain adaptation framework that fine-tunes large language models (specifically GPT-3.5 Turbo) on the Oregon State Design Repository (OSDR) to improve automated classification of mechanical part functions. The adapted models demonstrated significantly improved performance compared to pre-trained versions, achieving up to 93% accuracy with only 681 training samples. The approach also showed that integrating function definitions into the labeling process enhanced the model's contextual understanding of mechanical components.

## Method Summary
The methodology employs fine-tuning of pre-trained LLMs, specifically GPT-3.5 Turbo, using the Oregon State Design Repository (OSDR) dataset, which contains function-labeled mechanical components. The fine-tuned model is then evaluated on the ABC dataset for mechanical component classification. The approach incorporates function definitions into the labeling process to enhance contextual understanding. The study uses a subset of 681 training samples from OSDR to demonstrate that domain adaptation can achieve high accuracy with relatively limited data.

## Key Results
- Domain-adapted LLMs achieved up to 93% accuracy on mechanical component function classification
- Fine-tuned GPT-3.5 Turbo outperformed pre-trained models by significant margins
- Function definition integration improved model performance and contextual understanding

## Why This Works (Mechanism)
Domain adaptation works by leveraging transfer learning principles, where pre-trained LLMs are fine-tuned on domain-specific data (OSDR) to capture the specialized vocabulary and contextual relationships unique to mechanical engineering. The integration of function definitions provides explicit semantic context that helps the model better understand the functional relationships between component geometry and purpose, leading to more accurate classification.

## Foundational Learning
- Transfer learning: Why needed - enables leveraging pre-trained knowledge for specialized domains; Quick check - measure performance improvement over baseline models
- Fine-tuning vs. prompt engineering: Why needed - fine-tuning provides more permanent domain adaptation; Quick check - compare performance between fine-tuned and prompt-engineered models
- Function definition integration: Why needed - provides explicit semantic context for mechanical components; Quick check - measure performance difference with and without function definitions
- Mechanical function taxonomy: Why needed - establishes standardized classification framework; Quick check - verify consistency across different annotators
- Data imbalance handling: Why needed - prevents model bias toward overrepresented classes; Quick check - analyze class-wise performance metrics

## Architecture Onboarding

**Component map:** Pre-trained LLM -> Fine-tuning on OSDR -> Function definition integration -> Evaluation on ABC dataset

**Critical path:** Data preparation and preprocessing -> Fine-tuning configuration -> Model training -> Performance evaluation and analysis

**Design tradeoffs:** The study balances model complexity with training data availability, using only 681 samples from OSDR. The integration of function definitions adds computational overhead but improves accuracy. The choice of GPT-3.5 Turbo balances performance with fine-tuning feasibility.

**Failure signatures:** Performance degradation on underrepresented function classes, particularly channel and support functions. Potential overfitting to OSDR dataset characteristics. Reduced accuracy when evaluating on datasets from different mechanical design domains.

**First 3 experiments:** 1) Baseline evaluation of pre-trained GPT-3.5 Turbo on ABC dataset without fine-tuning. 2) Fine-tuning GPT-3.5 Turbo on full OSDR dataset and evaluating on ABC. 3) Fine-tuning on reduced OSDR sample (681 samples) to test data efficiency.

## Open Questions the Paper Calls Out
None

## Limitations
- Data imbalance affects certain function classes (channel and support), potentially biasing model performance
- Limited validation on downstream datasets, raising questions about cross-domain generalization
- The study focuses on textual descriptions, potentially missing visual features important for mechanical component classification

## Confidence
- Domain adaptation effectiveness: High - multiple experiments consistently show improved performance over baseline models
- 93% accuracy benchmark: Medium - achieved on specific datasets with limited training samples, may not generalize
- Function definition integration benefits: Medium - demonstrated improvement but effect size and generalizability require further validation

## Next Checks
1. Test the adapted model on mechanical assemblies from different design repositories and industries to assess cross-domain generalization
2. Evaluate model performance on balanced and synthetic datasets to quantify the impact of class imbalance
3. Conduct ablation studies removing function definitions from the labeling process to measure their specific contribution to performance gains