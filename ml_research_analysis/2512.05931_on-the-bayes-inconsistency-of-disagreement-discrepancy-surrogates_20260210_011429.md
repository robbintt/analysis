---
ver: rpa2
title: On the Bayes Inconsistency of Disagreement Discrepancy Surrogates
arxiv_id: '2512.05931'
source_url: https://arxiv.org/abs/2512.05931
tags:
- surrogate
- disagreement
- discrepancy
- loss
- error
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work identifies a fundamental flaw in existing methods for
  maximizing disagreement discrepancy, showing that current surrogate losses are not
  Bayes consistent and can fail to optimize the true objective. The authors develop
  a novel disagreement loss that, when combined with cross-entropy, yields the first
  provably consistent surrogate for disagreement discrepancy.
---

# On the Bayes Inconsistency of Disagreement Discrepancy Surrogates
## Quick Facts
- arXiv ID: 2512.05931
- Source URL: https://arxiv.org/abs/2512.05931
- Reference count: 40
- Key outcome: Novel consistent surrogate loss for disagreement discrepancy maximization that outperforms existing methods in robustness and accuracy

## Executive Summary
This paper identifies a fundamental flaw in existing methods for maximizing disagreement discrepancy (DD), showing that current surrogate losses are not Bayes consistent and can fail to optimize the true objective. The authors develop a novel disagreement loss that, when combined with cross-entropy, yields the first provably consistent surrogate for disagreement discrepancy. Their method provides more accurate and robust estimates than existing approaches, particularly under adversarial conditions, improving error bound calibration and detection of harmful distribution shifts.

## Method Summary
The authors propose a novel surrogate loss for maximizing disagreement discrepancy that combines a new disagreement loss with cross-entropy. This approach addresses the Bayes inconsistency problem in existing DD surrogates by ensuring that minimizing the surrogate loss corresponds to minimizing the true DD risk. The method involves optimizing an ensemble of models to maximize their disagreement on unlabeled data while maintaining predictive accuracy on labeled data. The key innovation is a new loss function that directly approximates the DD objective in a way that preserves Bayes consistency.

## Key Results
- The proposed surrogate achieves the maximum disagreement discrepancy in almost 80% of tested scenarios
- Demonstrates superior robustness when target data is adversarially perturbed
- Provides more accurate and robust estimates than existing approaches, particularly for error bound calibration and detection of harmful distribution shifts

## Why This Works (Mechanism)
The proposed method works by addressing the fundamental inconsistency in existing DD surrogates through a novel loss function that directly approximates the DD objective while preserving Bayes consistency. By combining this disagreement loss with cross-entropy, the method ensures that model training optimizes both predictive accuracy and disagreement maximization simultaneously. The mechanism leverages the mathematical properties of the new loss to create a proper scoring rule that, when minimized, directly corresponds to maximizing the true DD objective.

## Foundational Learning
- Bayes consistency: Why needed - Ensures that minimizing the surrogate loss leads to optimal performance on the true objective; Quick check - Verify the surrogate loss is proper and calibrated
- Disagreement discrepancy: Why needed - Measures the difference in model disagreement between source and target domains; Quick check - Confirm DD correctly identifies distribution shifts
- Cross-entropy loss: Why needed - Maintains predictive accuracy while maximizing disagreement; Quick check - Ensure CE component doesn't dominate the disagreement term
- Proper scoring rules: Why needed - Guarantees that the surrogate loss is well-calibrated; Quick check - Verify the loss satisfies the properties of proper scoring rules

## Architecture Onboarding
Component map: Cross-entropy loss -> Novel disagreement loss -> Ensemble of models -> Disagreement maximization
Critical path: Model predictions → Loss computation (CE + DD) → Gradient update → Improved ensemble agreement/disagreement balance
Design tradeoffs: Balancing predictive accuracy (CE) against disagreement maximization; computational overhead of ensemble training vs. single model
Failure signatures: Poor calibration of disagreement estimates; failure to detect distribution shifts; overfitting to source domain
First experiments:
1. Test Bayes consistency proof on simple binary classification tasks
2. Evaluate DD estimation accuracy on synthetic domain shift scenarios
3. Compare robustness to adversarial perturbations against baseline methods

## Open Questions the Paper Calls Out
None

## Limitations
- Results primarily validated on synthetic distributions rather than real-world, high-dimensional data
- Theoretical assumptions may not hold in practical scenarios with complex model architectures
- Performance gap under non-adversarial conditions and with diverse model families remains unclear

## Confidence
- Bayes inconsistency proof: High
- Proposed surrogate consistency: High
- Empirical performance claims: Medium
- Robustness under adversarial conditions: Medium

## Next Checks
1. Test the proposed surrogate on real-world dataset shift scenarios (e.g., medical imaging, autonomous driving) with multiple model architectures to assess practical utility beyond synthetic settings.
2. Conduct ablation studies varying the cross-entropy weighting parameter to understand the trade-off between predictive accuracy and disagreement maximization in practical applications.
3. Evaluate computational overhead and scalability of the proposed method on large-scale datasets and deep neural networks to determine practical deployment constraints.