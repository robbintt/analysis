---
ver: rpa2
title: Hierarchical Dual-Strategy Unlearning for Biomedical and Healthcare Intelligence
  Using Imperfect and Privacy-Sensitive Medical Data
arxiv_id: '2511.19498'
source_url: https://arxiv.org/abs/2511.19498
tags:
- medical
- unlearning
- knowledge
- privacy
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of selectively unlearning sensitive
  medical knowledge from large language models while preserving essential clinical
  reasoning capabilities, particularly when dealing with imperfect and privacy-sensitive
  healthcare data. The authors introduce a hierarchical dual-strategy framework that
  combines geometric-constrained gradient updates with concept-aware token-level interventions
  guided by a four-level medical concept hierarchy.
---

# Hierarchical Dual-Strategy Unlearning for Biomedical and Healthcare Intelligence Using Imperfect and Privacy-Sensitive Medical Data

## Quick Facts
- arXiv ID: 2511.19498
- Source URL: https://arxiv.org/abs/2511.19498
- Reference count: 40
- Achieves 82.7% forgetting rate and 88.5% knowledge preservation while modifying only 0.1% of parameters

## Executive Summary
This work addresses the challenge of selectively unlearning sensitive medical knowledge from large language models while preserving essential clinical reasoning capabilities, particularly when dealing with imperfect and privacy-sensitive healthcare data. The authors introduce a hierarchical dual-strategy framework that combines geometric-constrained gradient updates with concept-aware token-level interventions guided by a four-level medical concept hierarchy. The method employs Fisher Information Matrix analysis for parameter-level interventions and gradient-based importance scoring for token-level targeting, ensuring precise knowledge removal while maintaining general medical competencies. Experimental results on the MedMCQA (surgical) and MHQA (mental health) datasets demonstrate superior performance with an 82.7% forgetting rate and 88.5% knowledge preservation, achieving robust privacy guarantees while modifying only 0.1% of model parameters. The framework successfully addresses regulatory compliance and ethical standards in clinical research environments.

## Method Summary
The hierarchical dual-strategy framework combines geometric-constrained gradient updates with concept-aware token-level interventions for selective unlearning of sensitive medical knowledge. The method uses a four-level medical concept hierarchy to guide preservation-critical versus unlearning-targeted interventions. Parameter-level interventions employ Fisher Information Matrix analysis for importance scoring, while token-level targeting uses gradient-based importance scoring. The framework integrates differential privacy with LoRA for theoretical privacy guarantees (ε=4.0) while constraining parameter modifications to 0.1% of total parameters. The approach achieves precise knowledge removal while maintaining general medical competencies through orthogonal projection of forget gradients relative to retain gradients.

## Key Results
- Achieves 82.7% forgetting rate for surgical knowledge while preserving 88.5% of general medical knowledge
- Maintains robust privacy guarantees with MIA resistance of 0.89 and differential privacy parameter ε=4.0
- Requires modification of only 0.1% of model parameters through LoRA-based parameter-efficient fine-tuning
- Demonstrates superior performance compared to baseline unlearning methods on both surgical (MedMCQA) and mental health (MHQA) datasets

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Geometric-constrained gradient updates selectively erase target knowledge while preserving retention knowledge by projecting forget gradients orthogonal to retain gradients.
- **Mechanism:** For each parameter θᵢ, the forget gradient is projected: ∇proj = ∇forget − α_Lj · (∇forget · ∇retain / ||∇retain||²) · ∇retain. The preservation coefficient α_Lj (1.0 for L1 fundamental, 0.2 for L4 surgical) controls projection strength, ensuring strict orthogonality for foundational knowledge while allowing erasure for surgical concepts.
- **Core assumption:** Retain and forget gradients are partially aligned; orthogonal projection preserves retention knowledge while permitting unlearning direction. Assumption: gradient alignment correlates with knowledge entanglement.
- **Evidence anchors:**
  - [abstract] "geometric-constrained gradient updates to selectively modulate target parameters"
  - [section III.C.1] "For each parameter θᵢ associated with hierarchy level Lj, orthogonal projection is applied using L2-normalized gradients"
  - [corpus] Weak direct evidence; related work "Unlearning through Knowledge Overwriting" uses adapter-based approaches but doesn't validate gradient orthogonality specifically.
- **Break condition:** If retain and forget gradients are nearly perpendicular (||∇retain||² → 0 with orthogonal alignment), the projection becomes unstable; ϵ=10⁻⁵ safeguard prevents division by zero but may fail with highly disentangled knowledge.

### Mechanism 2
- **Claim:** Concept-aware token interventions distinguish preservation-critical from unlearning-targeted tokens via gradient-based importance scoring aligned with a four-level medical hierarchy.
- **Mechanism:** Token importance I(t, Lj) = β_Lj · |Grad_forget(t)| / (|Grad_retain(t)| + ϵ). Surgical tokens (L4, β=1.0) receive amplified loss contribution; fundamental tokens (L1, β=0.1) are suppressed. This modulates token-level loss weighting during backpropagation.
- **Core assumption:** Gradient magnitude with respect to token embeddings correlates with knowledge localization. Assumption: hierarchy levels map cleanly to token categories.
- **Evidence anchors:**
  - [abstract] "concept-aware token-level interventions that distinguish between preservation-critical and unlearning-targeted tokens via a unified four-level medical concept hierarchy"
  - [section III.C.2] "Token importance scores are computed: I(t, Lj) = β_Lj · |Grad_forget(t)| / (|Grad_retain(t)| + ϵ)"
  - [section V.B, Figure 3] "surgical tokens (loss: 2.1→0.3) and memorized tokens (loss: 1.8→0.4) decreased significantly, while general medical tokens remained stable (1.7-1.9)"
  - [corpus] "Towards Benign Memory Forgetting" validates gradient-based token saliency but reports attention-based alternatives underperform (85.6% vs 83.4% US).
- **Break condition:** If tokens have shared representations across hierarchy levels (e.g., "incision" appears in both surgical and general contexts), importance scores may misclassify, causing over/under-unlearning.

### Mechanism 3
- **Claim:** Differential privacy integration with LoRA enables theoretical privacy guarantees (ε=4.0) while constraining parameter modifications to 0.1% of total parameters.
- **Mechanism:** Gaussian noise N(0, σ²I) added to gradients with σ = q·√(2ln(1.25/δ))/ε, where q is sampling rate. LoRA decomposes weight updates W' = W + BA (rank r=8), limiting trainable parameters to 3.25M (0.11% of 3B model).
- **Core assumption:** Noise calibration preserves unlearning signal while obscuring individual training samples. Assumption: low-rank updates capture unlearning-relevant subspace.
- **Evidence anchors:**
  - [abstract] "maintains robust privacy guarantees while requiring modification of only 0.1% of parameters"
  - [section III.G] "Calibrated Gaussian noise was added to the gradients to provide (ε, δ)-differential privacy"
  - [section V.C, Table V] "MIA resistance: 0.89, AUC: 0.555≈random classifier, privacy risk: 0.11" with ε=4.0
  - [corpus] "Hierarchical Federated Unlearning for LLMs" validates parameter-efficient unlearning but doesn't report DP guarantees.
- **Break condition:** If unlearning requires modifications outside LoRA's low-rank subspace (e.g., knowledge encoded in attention head routing), erasure will be incomplete regardless of noise calibration.

## Foundational Learning

- **Concept: Gradient Ascent for Unlearning**
  - Why needed here: The paper uses gradient ascent (negative factor) on forgetting data while applying descent on retention data. Understanding this duality is essential for interpreting Equation 6 and the dual-objective optimization.
  - Quick check question: If you flip the sign of the loss gradient for samples in D_f, what happens to model behavior on that distribution?

- **Concept: Fisher Information Matrix (FIM)**
  - Why needed here: FIM values identify parameter importance for knowledge preservation. The diagonal approximation enables efficient computation while maintaining selectivity.
  - Quick check question: Why would a parameter with high FIM value be more important to preserve during unlearning?

- **Concept: Membership Inference Attacks (MIA)**
  - Why needed here: MIA resistance (0.89) is the primary privacy metric. Understanding how attackers exploit memorization helps evaluate whether unlearning succeeded.
  - Quick check question: If a model's MIA AUC drops from 0.98 to 0.50, what does this imply about training data exposure?

## Architecture Onboarding

- **Component map:**
  1. Medical Concept Hierarchy Module (L1-L4 taxonomy with α/β coefficients)
  2. Medical Data Processing Module (category filtering, UMLS MetaMap annotation)
  3. Dual-Strategy Unlearning Module (geometric gradients + token interventions)
  4. Parameter-Efficient Fine-tuning Module (LoRA on final 4 transformer layers, r=8)
  5. Differential Privacy Integration Module (gradient clipping + Gaussian noise)

- **Critical path:**
  Data → Category filtering (surgical vs non-surgical) → Hierarchy assignment (L1-L4) → Simultaneous: (Geometric projection via Eq. 12) AND (Token importance via Eq. 13) → Gradient combination (Eq. 6) → DP noise addition (Eq. 8) → LoRA parameter update → Evaluation (FR, KPR, MIA)

- **Design tradeoffs:**
  - α_Lj tuning: Higher preservation (L1=1.0) protects fundamentals but may limit surgical forgetting; lower (L4=0.2) enables erasure but risks collateral damage
  - DP noise (ε=4.0): Stronger privacy (lower ε) degrades unlearning precision; ablation shows No-DP achieves 86.1% US vs 85.6% with DP
  - LoRA rank (r=8): Higher rank captures more knowledge but increases trainable parameters; current 0.1% is near-minimal for effective unlearning
  - Block-wise processing ratio (m:1 forget-to-retain): Controls stability vs unlearning speed

- **Failure signatures:**
  - Catastrophic forgetting: Non-surgical accuracy drops >5% → α_Lj too low or gradient projection failing
  - Incomplete unlearning: Surgical accuracy >30% post-unlearning → β_Lj too low or token importance misclassified
  - Privacy leakage: MIA AUC >0.65 → DP noise insufficient or gradient clipping too loose
  - Training divergence: Loss spikes >10× baseline → ϵ in Eq. 12 too small or learning rate mismatch between strategies

- **First 3 experiments:**
  1. **Sanity check:** Run unlearning with GG-Only and CT-Only separately (Table IV baselines). Compare to full method to verify both strategies contribute. Expected: GG-Only ≈78% FR, CT-Only ≈77% FR, Full ≈83% FR.
  2. **Hierarchy validation:** Ablate L4 (set α_L4=1.0, β_L4=0.1) and confirm surgical knowledge persists. Then ablate L1 (set α_L1=0.2, β_L1=1.0) and confirm fundamental biomedical knowledge degrades. This validates hierarchy-targeting mechanism.
  3. **Privacy robustness:** Sweep ε ∈ {1.0, 2.0, 4.0, 8.0, ∞} and plot MIA resistance vs unlearning score. Identify Pareto frontier; paper claims ε=4.0 is optimal (0.89 MIA, 85.6% US). Verify this holds with different random seeds (42, 123, 789).

## Open Questions the Paper Calls Out
None

## Limitations
- The hierarchical dual-strategy framework demonstrates strong empirical performance but faces several critical limitations including gradient alignment assumptions and hierarchy mapping challenges
- The parameter-efficient LoRA approach constrains unlearning capacity to the low-rank subspace, potentially leaving residual knowledge intact
- The differential privacy calibration assumes Gaussian noise effectively masks individual training samples without degrading the unlearning signal, but this balance remains empirically fragile

## Confidence
**High Confidence:** The differential privacy integration providing (ε, δ)-DP guarantees with MIA resistance of 0.89 is well-supported by theoretical calibration and empirical validation. The LoRA-based parameter efficiency achieving 0.1% modification while maintaining performance is demonstrable and reproducible.

**Medium Confidence:** The geometric-constrained gradient projection effectively preserving L1-L3 knowledge while unlearning L4 surgical concepts is supported by ablation studies but assumes gradient orthogonality assumptions hold across diverse medical knowledge distributions. The concept-aware token interventions showing superior performance to baseline unlearning methods have experimental support but rely on heuristic hierarchy mappings.

**Low Confidence:** The scalability of this framework to larger models (>13B parameters) and more complex medical domains (beyond surgical and mental health) remains unproven. The claim that only 0.1% parameter modification achieves optimal privacy-utility tradeoff is specific to the experimental conditions and may not generalize.

## Next Checks
1. **Gradient Alignment Stress Test:** Systematically measure the cosine similarity between retain and forget gradients across different medical concept hierarchies. If average alignment drops below 0.3, the orthogonal projection mechanism becomes unstable and requires redesign.

2. **Hierarchy Boundary Validation:** Conduct a controlled experiment where polysemous medical terms (e.g., "stroke" in general medicine vs surgical contexts) are deliberately included in both surgical and non-surgical datasets. Measure whether the token importance scoring correctly classifies these tokens based on context rather than vocabulary alone.

3. **Cross-Domain Generalization Test:** Apply the exact methodology to a non-medical domain (e.g., financial services compliance) with a different knowledge hierarchy. Compare forgetting rates and preservation performance to determine if the four-level hierarchy and gradient projection approach generalizes beyond biomedical contexts.