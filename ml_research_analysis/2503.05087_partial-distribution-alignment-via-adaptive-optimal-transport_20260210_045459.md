---
ver: rpa2
title: Partial Distribution Alignment via Adaptive Optimal Transport
arxiv_id: '2503.05087'
source_url: https://arxiv.org/abs/2503.05087
tags:
- transport
- optimal
- adaptive
- mass
- domain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Adaptive Optimal Transport (AOT), a novel
  framework that overcomes the limitations of classical optimal transport by allowing
  for adaptive-mass preserving. Unlike partial or unbalanced optimal transport, AOT
  does not require pre-defining the fixed budget of mass to transport or the extent
  of "soft" penalties on marginal constraints.
---

# Partial Distribution Alignment via Adaptive Optimal Transport

## Quick Facts
- **arXiv ID:** 2503.05087
- **Source URL:** https://arxiv.org/abs/2503.05087
- **Reference count:** 40
- **Primary result:** AOT achieves up to 76.68% accuracy on VisDA and 72.24% on Office-Home, outperforming state-of-the-art UDA methods.

## Executive Summary
This paper introduces Adaptive Optimal Transport (AOT), a novel framework for unsupervised domain adaptation that overcomes limitations of classical optimal transport. Unlike partial or unbalanced optimal transport, AOT automatically determines the optimal mass allocation during transport without requiring pre-defined budgets or soft penalty parameters. The method is particularly effective for partial distribution alignment in scenarios with noise, outliers, and distribution shifts. When applied to image classification tasks using VisDA, Office-Home, and Office-31 datasets, AOT significantly outperforms existing OT-based and non-OT-based UDA methods.

## Method Summary
The authors propose Adaptive Optimal Transport as a solution for partial distribution alignment in unsupervised domain adaptation. The framework uses a mixed-sign cost function combining feature distance and label correlation, optimized through an entropy-regularized transport problem. A key innovation is the clipping of dual potentials to zero during the Sinkhorn iteration, which enforces marginal inequality constraints and enables adaptive mass allocation. The method integrates seamlessly with standard UDA pipelines, using a backbone ResNet-50, cross-entropy loss on source data, and the AOT loss for domain alignment. Hyperparameters include $\alpha=0.01$, $\beta \in \{1.8, 5, 6\}$, and $\epsilon \in \{0.1, 1\}$, with SGD optimization.

## Key Results
- Achieves 76.68% accuracy on VisDA dataset, significantly outperforming state-of-the-art methods
- Reaches 72.24% accuracy on Office-Home dataset, demonstrating robust cross-domain generalization
- Shows superior performance on Office-31 with strong results across diverse adaptation tasks

## Why This Works (Mechanism)
AOT's effectiveness stems from its ability to dynamically allocate transport mass based on the intrinsic structure of the problem rather than relying on fixed budgets. The clipping of dual potentials to enforce marginal inequality constraints creates a mechanism where mass is preserved adaptively rather than strictly. This allows the model to naturally handle partial matching scenarios where source and target distributions have different supports. The mixed-sign cost function, combining feature distance with classifier correlation, provides both geometric alignment and semantic consistency in the transport plan.

## Foundational Learning
- **Entropy-regularized optimal transport:** Needed to ensure numerical stability and efficient computation via Sinkhorn algorithm. Quick check: Verify that entropy regularization coefficient $\epsilon$ is properly tuned for convergence.
- **Dual potentials and marginal constraints:** Required to understand how clipping enforces adaptive mass allocation. Quick check: Confirm that $\phi, \psi \le 0$ after each iteration in the solver.
- **Mixed-sign cost functions:** Essential for combining geometric and semantic alignment in transport. Quick check: Ensure the cost matrix has both positive (feature distance) and negative (correlation) components.
- **Unsupervised domain adaptation:** The target application context for partial distribution alignment. Quick check: Verify that target labels are never used during training.

## Architecture Onboarding

**Component Map:**
Data Loader -> Feature Extractor -> Classifier -> Cost Matrix Computation -> AOT Solver -> Loss Computation -> Parameter Update

**Critical Path:**
Feature extraction → Mixed-sign cost matrix construction → Adaptive Optimal Transport solver → AOT loss → Backpropagation through feature extractor

**Design Tradeoffs:**
- Adaptive mass allocation vs. fixed-budget partial OT: AOT avoids hyperparameter tuning for mass budget but requires careful handling of dual potential clipping
- Entropy regularization vs. computational efficiency: Regularization ensures stability but may smooth transport plans
- Mixed-sign cost vs. pure geometric alignment: Incorporates semantic information but adds complexity to cost matrix construction

**Failure Signatures:**
- Poor convergence in Sinkhorn iterations (check dual potential clipping enforcement)
- Degenerate transport plans (verify entropy regularization is sufficient)
- Over-regularization masking domain shift (adjust $\epsilon$ parameter)
- Feature extractor collapse (monitor source classification accuracy)

**First Experiments:**
1. Verify basic Sinkhorn implementation with dual potential clipping on synthetic transport problems
2. Test mixed-sign cost function computation with toy feature and probability distributions
3. Run single-batch training loop with AOT loss to confirm gradient flow and parameter updates

## Open Questions the Paper Calls Out
None

## Limitations
- Claims about AOT's superiority over fixed-budget partial OT methods lack rigorous comparative ablation studies
- Entropy regularization parameter sensitivity across datasets is not thoroughly explored
- Mixed-sign cost formulation combining feature distance and classifier correlation lacks full theoretical justification
- Computational overhead compared to standard OT methods is not quantified

## Confidence
- **High:** Experimental results showing superior performance on benchmark datasets are well-documented and reproducible
- **Medium:** Theoretical claims about mass allocation mechanism and duality theory require independent verification
- **Medium:** Claims about effectiveness in noise/outlier scenarios are supported by benchmarks but lack extensive failure mode analysis

## Next Checks
1. Conduct ablation study comparing AOT against classical partial OT with fixed mass budget on the same datasets
2. Implement and verify convergence behavior of the modified Sinkhorn algorithm with dual potential clipping
3. Evaluate the impact of mixed-sign cost function by isolating feature distance and label correlation components