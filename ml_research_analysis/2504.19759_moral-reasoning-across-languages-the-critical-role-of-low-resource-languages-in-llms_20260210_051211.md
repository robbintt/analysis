---
ver: rpa2
title: 'Moral Reasoning Across Languages: The Critical Role of Low-Resource Languages
  in LLMs'
arxiv_id: '2504.19759'
source_url: https://arxiv.org/abs/2504.19759
tags:
- moral
- reasoning
- languages
- llms
- across
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study introduces the Multilingual Moral Reasoning Benchmark
  (MMRB) to assess large language models' moral reasoning across five languages (English,
  Chinese, Russian, Vietnamese, Indonesian) and three context levels (sentence, paragraph,
  document). The researchers evaluated five prominent LLMs and found significant inconsistencies
  in moral reasoning performance across languages, with degradation as context complexity
  increases.
---

# Moral Reasoning Across Languages: The Critical Role of Low-Resource Languages in LLMs

## Quick Facts
- arXiv ID: 2504.19759
- Source URL: https://arxiv.org/abs/2504.19759
- Reference count: 7
- The study introduces the Multilingual Moral Reasoning Benchmark (MMRB) to assess large language models' moral reasoning across five languages (English, Chinese, Russian, Vietnamese, Indonesian) and three context levels (sentence, paragraph, document).

## Executive Summary
This paper investigates how large language models perform moral reasoning across five languages with varying resource availability, revealing significant inconsistencies that worsen with context complexity. The researchers created the Multilingual Moral Reasoning Benchmark (MMRB) by translating and validating moral scenarios across English, Chinese, Russian, Vietnamese, and Indonesian. Their experiments with five prominent LLMs demonstrate that low-resource languages like Vietnamese have a disproportionate impact on cross-lingual reasoning performance, both enhancing alignment and causing severe poisoning effects during fine-tuning.

## Method Summary
The researchers developed the MMRB benchmark by translating ETHICSBASE, ETHICSPRO, and ETHICSMAX datasets into five languages using DeepSeek API with bilingual manual verification and Google Translate cross-validation. They evaluated five LLMs (GPT-4, GPT-3.5, LLaMA-3-70B-Instruct, LLaMA-3-8B-Instruct, Mixtral-8x7B-Instruct) using greedy decoding at temperature 0. Fine-tuning experiments used LLaMA-Factory on LLaMA-3-8B with monolingual data for alignment (clean labels) and poisoning (corrupted labels) effects, measuring cross-lingual generalization across all languages.

## Key Results
- Moral reasoning performance degrades significantly as context complexity increases, with steepest decline for low-resource languages like Vietnamese
- Low-resource languages produce disproportionately large cross-lingual transfer effects during fine-tuning—Indonesian fine-tuning yields strongest improvements while Vietnamese poisoning causes most degradation
- Document-level contexts with explicit moral principles restore performance by reducing ambiguity in ethical decision-making

## Why This Works (Mechanism)

### Mechanism 1
Moral reasoning performance degrades as context complexity increases, with steeper degradation for low-resource languages. Longer contexts introduce more ambiguity and implicit ethical cues that models—especially those undertrained on low-resource languages—struggle to parse without explicit moral scaffolding. Sentence-level tasks contain sufficient explicit signals for models to leverage pretrained moral knowledge, while paragraph-level tasks require integrating scattered cues.

### Mechanism 2
Fine-tuning on low-resource languages produces disproportionately large cross-lingual transfer effects—both positive (alignment) and negative (poisoning)—compared to high-resource languages. Low-resource languages are underrepresented in pretraining corpora; fine-tuning fills critical knowledge gaps, amplifying impact. The representation space for low-resource languages is sparser, so parameter updates have higher leverage.

### Mechanism 3
Document-level contexts with explicit moral principles restore performance by reducing ambiguity. ETHICSMAX includes structured ethical branches with named principles, providing interpretive scaffolding that overrides confusion from shorter, ambiguous prompts. Models can leverage explicit normative frameworks when available, even if implicit reasoning is weak.

## Foundational Learning

- **Low-resource vs. high-resource languages**: The entire paper hinges on differential behavior between languages with abundant vs. scarce training data. Without this distinction, the core findings on disproportionate impact are unintelligible. Quick check: Can you explain why Indonesian fine-tuning helps Russian moral reasoning more than English fine-tuning does?

- **Cross-lingual transfer**: The alignment and poisoning experiments test whether training in one language affects performance in others. Understanding transfer directionality is essential for interpreting Tables 3 and 4. Quick check: If you fine-tune on corrupted Vietnamese labels, why does English performance drop less than Vietnamese performance?

- **Moral reasoning frameworks (Virtue, Deontological, Consequentialist)**: ETHICSMAX explicitly evaluates three ethical branches. Interpreting Table 2 requires knowing what each branch represents and why models might handle them differently. Quick check: Why might a model score higher on Consequentialist reasoning than Deontological reasoning in a dilemma involving lying to protect someone?

## Architecture Onboarding

- **Component map**: MMRB Dataset (2,170 scenarios) -> Translation pipeline (DeepSeek API + bilingual manual verification + Google Translate cross-validation) -> Fine-tuning framework (LLaMA-Factory) -> Evaluation harness (greedy decoding, accuracy metrics)

- **Critical path**: 1. Data curation: Filter ambiguous scenarios, validate translations 2. Fine-tuning: Select monolingual split, apply clean or corrupted labels 3. Cross-lingual evaluation: Test on all 5 languages, compute accuracy deltas

- **Design tradeoffs**: Translation-based benchmark enables scale but risks cultural mismatch; greedy decoding ensures reproducibility but may underrepresent model diversity; LLaMA-3-8B chosen for fine-tuning accessibility; larger models not tested in fine-tuning mode

- **Failure signatures**: Large accuracy gaps between EN and VI/ID in sentence-level tasks indicate underrepresentation; performance recovery on ETHICSMAX but not ETHICSPRO signals ambiguity intolerance; asymmetric poisoning effects indicate sparse representation dilution

- **First 3 experiments**: 1. Baseline cross-lingual consistency: Run all 5 models on ETHICSPRO across all languages; compute pairwise win-rates and Mann-Whitney U significance 2. Monolingual alignment ablation: Fine-tune LLaMA-3-8B on Indonesian, Vietnamese, and English separately; measure cross-lingual transfer 3. Structured principle injection: Create modified ETHICSPRO with explicit moral principles appended; test whether this closes performance gap with ETHICSMAX

## Open Questions the Paper Calls Out

The paper identifies three major open questions: (1) What is the underlying mechanism by which fine-tuning on low-resource languages produces disproportionately stronger cross-lingual transfer effects compared to high-resource languages? (2) To what extent do translation artifacts versus genuine cross-lingual reasoning differences account for observed performance inconsistencies? (3) How do findings generalize to culturally-specific moral dilemmas that may not align with Western ethical frameworks used in ETHICSMAX?

## Limitations

Translation-induced cultural mismatches remain a significant confounder, as the benchmark relies on translated scenarios that may not preserve original moral intuitions across languages. The poisoning experiments use unspecified corruption methods, making it difficult to assess whether observed degradation reflects representation sparsity or specific label noise patterns. The study does not quantify translation fidelity or cultural adaptation quality.

## Confidence

- **High Confidence**: Degradation of moral reasoning with increasing context complexity is well-supported by consistent accuracy drops across all evaluated models
- **Medium Confidence**: Low-resource languages have disproportionate impact on cross-lingual transfer due to sparse representation space—plausible given pretraining data imbalance
- **Medium Confidence**: Document-level performance recovery stems from explicit moral principles—the mechanism is logical but could reflect length bias

## Next Checks

1. **Translation Quality Audit**: Select 50 random scenarios from each language; have native speakers rate translation fidelity and cultural appropriateness to quantify potential confounds
2. **Pretraining Data Analysis**: Obtain pretraining corpus statistics for each language (EN, ZH, RU, VI, ID) to verify the low-resource vs. high-resource distinction and validate the sparse representation hypothesis
3. **Fine-tuning Hyperparameter Sweep**: Test multiple learning rates, batch sizes, and epoch counts for low-resource languages to determine whether observed effects persist under optimal training conditions or reflect optimization instability