---
ver: rpa2
title: Decoupling the components of geometric understanding in Vision Language Models
arxiv_id: '2503.03840'
source_url: https://arxiv.org/abs/2503.03840
tags:
- geometric
- rotation
- stimuli
- understanding
- geometry
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates the geometric understanding of vision-language
  models (VLMs) using a cognitive science paradigm that isolates visual comprehension
  from reasoning and world knowledge. The authors adapted stimuli from Dehaene et
  al.
---

# Decoupling the components of geometric understanding in Vision Language Models

## Quick Facts
- arXiv ID: 2503.03840
- Source URL: https://arxiv.org/abs/2503.03840
- Reference count: 9
- VLMs significantly underperform both US adults and Munduruku adults on geometric understanding tasks

## Executive Summary
This study evaluates vision-language models' (VLMs) geometric understanding using a cognitive science paradigm that isolates visual comprehension from reasoning and world knowledge. The authors adapted stimuli from Dehaene et al. (2006) to test VLMs on six geometric concepts through "odd one out" tasks. They compared VLM performance with US adults and Munduruku adults without formal education, finding that VLMs consistently underperform both human groups, particularly on tasks requiring mental rotation.

The research reveals key differences between machine and human geometric understanding. While humans maintain stable performance across rotation variations, VLMs show dramatic performance drops when mental rotation is required. This suggests VLMs learn geometric concepts primarily from formal educational materials rather than combining physical world experience with formal education like humans do. The study highlights the brittleness of VLM geometric understanding and identifies mental rotation as a critical differentiator between human and machine capabilities.

## Method Summary
The authors adapted geometric stimuli from Dehaene et al. (2006) to create image-based "odd one out" tasks testing six geometric concepts. They evaluated multiple VLMs (including Gemini Pro 1.5) on these tasks and compared results with US adults and Munduruku adults without formal education. The study included rotation-controlled stimuli to test mental rotation capabilities, where rotation angle systematically affected VLM performance while human performance remained stable. The methodology aimed to isolate visual comprehension from reasoning and world knowledge components of geometric understanding.

## Key Results
- VLMs achieved only 30-40% accuracy across most geometric categories, compared to 70-80% for US adults and 60-70% for Munduruku adults
- VLMs showed dramatic performance variation based on rotation angle, with poorest results when mental rotation was required
- Human performance remained stable across rotation variations while VLM performance was brittle and varied dramatically

## Why This Works (Mechanism)
The study's approach works by adapting established cognitive science paradigms to create controlled tests that isolate specific components of geometric understanding. By using image-based "odd one out" tasks with rotation-controlled stimuli, the researchers can separate visual pattern recognition from actual geometric comprehension and mental rotation abilities. The comparison across different human populations (educated US adults vs. Munduruku without formal education) helps identify whether VLMs learn geometric concepts through formal education channels or more fundamental perceptual mechanisms.

## Foundational Learning
1. **Geometric concept mapping** - Understanding how abstract geometric properties translate to visual stimuli
   - Why needed: Essential for creating valid test materials that accurately assess geometric understanding
   - Quick check: Verify stimuli consistently trigger intended geometric judgments across human subjects

2. **Mental rotation psychophysics** - Understanding how rotation angle affects geometric processing difficulty
   - Why needed: Critical for interpreting rotation-controlled stimuli results and comparing human vs. machine performance
   - Quick check: Map human response times and accuracy across rotation angles to establish baseline curves

3. **Odd-one-out paradigm design** - Creating effective multiple-choice formats for geometric concept testing
   - Why needed: Provides structured way to test specific geometric properties while controlling for other variables
   - Quick check: Ensure distractor items are sufficiently similar to target items except for tested property

4. **Cross-cultural geometric cognition** - Understanding how geometric understanding develops with/without formal education
   - Why needed: Provides context for interpreting VLM performance relative to human baselines
   - Quick check: Compare performance patterns between educated and non-educated human groups

## Architecture Onboarding

**Component Map**: Visual Input -> Feature Extraction -> Geometric Property Recognition -> Odd-One-Out Selection -> Response Generation

**Critical Path**: The most critical path for geometric understanding is Visual Input → Feature Extraction → Geometric Property Recognition, as errors at any of these stages will prevent correct identification of the geometric property distinguishing the odd item.

**Design Tradeoffs**: VLMs must balance visual feature extraction (often pre-trained on natural images) with geometric property abstraction (less commonly trained). The odd-one-out format trades precision for controlled comparison across concepts, but may not capture all aspects of geometric understanding.

**Failure Signatures**: VLMs fail primarily on mental rotation tasks, show brittle performance that varies with stimulus rotation angle, and demonstrate inconsistent performance across geometric concepts. These failures suggest reliance on surface features rather than deep geometric understanding.

**First Experiments**:
1. Test VLMs on identical stimuli with varying rotation angles to map performance curves
2. Compare VLM responses to human reaction times and accuracy on the same tasks
3. Evaluate whether providing explicit geometric property descriptions improves VLM performance

## Open Questions the Paper Calls Out
None

## Limitations
- The conceptual mapping between abstract geometric concepts and image-based stimuli may not fully capture intended geometric understanding
- VLM task execution variability isn't fully accounted for, as different models may approach odd-one-out tasks differently
- Environmental factors in stimuli (color patterns, object types) might provide non-geometric cues that help VLMs identify correct answers

## Confidence

**High confidence claims**:
- VLMs significantly underperform both US adults and Munduruku adults on geometric understanding tasks
- Mental rotation capability represents a major differentiator between human and machine geometric understanding
- Performance varies substantially across different geometric concepts
- VLMs show brittle understanding that breaks down under stimulus variations

**Medium confidence claims**:
- The gap between human and VLM performance indicates VLMs learn primarily from formal educational materials
- Rotation angle systematically affects VLM performance in ways that differ from human responses
- The methodology successfully isolates visual comprehension from reasoning and world knowledge

**Low confidence claims**:
- Specific percentage differences in performance between groups
- The exact nature of how VLMs process geometric concepts compared to humans
- Whether the odd-one-out paradigm fully captures geometric understanding

## Next Checks
1. **Cross-paradigm replication**: Validate findings using alternative geometric assessment methods beyond odd-one-out tasks, such as direct property matching or spatial relationship judgments, to ensure results aren't specific to the chosen paradigm.

2. **Fine-grained rotation analysis**: Conduct systematic testing across a continuous range of rotation angles (not just discrete categories) to precisely map the relationship between rotation difficulty and VLM performance, and compare this to human psychophysical curves.

3. **Controlled attribute ablation**: Design stimuli where geometric properties are systematically varied while holding other visual attributes constant (color, texture, object type) to determine whether VLMs rely on non-geometric cues when solving these tasks.