---
ver: rpa2
title: Guiding Evolution of Artificial Life Using Vision-Language Models
arxiv_id: '2509.22447'
source_url: https://arxiv.org/abs/2509.22447
tags:
- asal
- prompts
- life
- simulation
- prompt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces ASAL++, a method that uses foundation models
  to guide the evolution of artificial life simulations in an open-ended manner. The
  key innovation is using a second foundation model to propose new evolutionary targets
  based on a simulation's visual history, creating increasingly complex objectives.
---

# Guiding Evolution of Artificial Life Using Vision-Language Models

## Quick Facts
- arXiv ID: 2509.22447
- Source URL: https://arxiv.org/abs/2509.22447
- Reference count: 7
- Primary result: ASAL++ uses dual foundation models to guide open-ended evolution in artificial life, with EST achieving 0.052 mean open-endedness score vs ETT's 0.049

## Executive Summary
ASAL++ introduces a method for guiding the evolution of artificial life simulations using vision-language models. The system employs a dual foundation model architecture where CLIP aligns simulation parameters to text prompts via gradient-free optimization, while Gemma-3 proposes new evolutionary targets based on visual history. Two strategies are explored: Evolved Supervised Targets (EST) maximizes visual novelty by optimizing for single new prompts, while Evolved Temporal Targets (ETT) fosters coherent evolutionary sequences by optimizing for the entire history of generated prompts. Experiments in the Lenia substrate demonstrate that ASAL++ can discover novel behaviors and generate diverse evolutionary trajectories.

## Method Summary
ASAL++ builds upon the ASAL framework by adding an outer loop where a foundation model (Gemma-3) observes simulation rollouts and autonomously generates new text prompts to guide evolution. The inner loop uses CLIP embeddings and CMA-ES optimization to align Lenia simulation parameters to current prompts. After each optimization run, the resulting video is passed to Gemma-3 to generate the next prompt. EST optimizes only the newest prompt per iteration for maximum novelty, while ETT optimizes the full sequence of prompts to maintain coherence. The system iterates this process for 8 outer-loop cycles with 2000 CMA-ES steps each.

## Key Results
- EST achieves higher open-endedness scores (0.052 mean) compared to ETT (0.049) due to greater visual novelty
- ETT produces more coherent and interpretable evolutionary sequences by maintaining prompt history
- The method generates phylogenetic tree visualizations showing exploratory capacity
- Both strategies successfully discover novel behaviors in the Lenia substrate

## Why This Works (Mechanism)

### Mechanism 1
A dual foundation model architecture enables closed-loop evolutionary search by separating the optimization objective from the generation of novel goals. An inner loop uses CLIP to align simulation parameters to text prompts via CMA-ES, while an outer loop uses Gemma-3 to observe simulation history and generate new prompts. This feedback loop (Simulation → Video → FM → Prompt → Simulation) allows autonomous trajectory definition.

### Mechanism 2
Constraining optimization to a single new prompt (EST) maximizes visual novelty by allowing simulations to "forget" past states and jump to new parameter regions. Optimizing for the entire history of prompts (ETT) enforces evolutionary continuity by forcing new parameters to satisfy all previous constraints, preserving visual features and creating coherent transitions.

### Mechanism 3
Open-endedness is quantified by measuring maximum visual dissimilarity of any frame from all preceding frames in VLM embedding space. The OE score is calculated as 1 minus the maximum cosine similarity between the final frame embedding and all earlier frame embeddings, with higher scores indicating semantically novel outcomes.

## Foundational Learning

- **Continuous Cellular Automata (Lenia)**: The primary experimental substrate that allows smooth, organic patterns through continuous state and space. Quick check: How does Lenia's update rule differ from discrete cellular automata like Conway's Game of Life?

- **Vision-Language Models (VLMs) / CLIP**: Provides shared latent space for comparing simulation frames with text prompts via alignment. Quick check: What does high cosine similarity between an image and text string mean in a VLM's embedding space?

- **Black-Box Optimization (CMA-ES)**: Gradient-free optimizer used for simulation parameter search. Quick check: Why would CMA-ES be preferred over gradient descent for this parameter search?

## Architecture Onboarding

- **Component map**: Substrate (Lenia) -> Aligner (CLIP + CMA-ES) -> Evolver Model (Gemma-3). The Substrate generates video, processed by the Evolver to create new prompts, which the Aligner then optimizes.

- **Critical path**: 
  1. Initialize simulation parameters and seed prompt
  2. Inner Loop: Run CMA-ES for I iterations to maximize CLIP similarity
  3. Outer Loop: Pass optimized video to Gemma-3 to generate new prompt
  4. Append (ETT) or replace (EST) current prompt
  5. Repeat for N outer-loop iterations

- **Design tradeoffs**:
  - EST vs. ETT: Select EST for maximum novelty and open-endedness; select ETT for interpretable sequences
  - Model Choice: Larger Evolver Model may propose more creative prompts but increases latency and cost
  - Temperature: Higher Gemma-3 temperature increases prompt diversity but risks incoherence

- **Failure signatures**:
  - Local Minima (ETT): System gets stuck in "repetition trap" with similar prompts
  - Vanishing Activations: Simulation collapses to blank screen
  - Biological Bias: Evolver Model ignores abstract prompts and forces biological concepts

- **First 3 experiments**:
  1. Validate ASAL Baseline: Replicate core ASAL functionality with fixed prompt "a glider"
  2. Run EST vs. ETT A/B Test: For "a microbe" prompt, compare generated prompts and OE scores
  3. Phylogenetic Tree Generation: Implement tree-sampling procedure with higher Gemma-3 temperature

## Open Questions the Paper Calls Out

- Can fine-tuning or using larger foundation models mitigate the biological vocabulary bias currently observed in target generation? The authors suggest larger or fine-tuned models could address this limitation.

- How does ASAL++ perform on more expressive substrates like multi-dimensional Neural Cellular Automata (NCA) compared to Lenia? The paper identifies Lenia's radial symmetry as a limitation and suggests NCA could increase expressivity.

- Would using video-native embedding models improve the capture of meaningful trajectories compared to the current static-frame CLIP approach? The authors note CLIP's limitation with static images and suggest VideoCLIP could capture more meaningful embeddings.

## Limitations
- Biological bias in Gemma-3 consistently ignores abstract prompts and defaults to cellular concepts
- Computational costs scale poorly with simulation complexity and model size
- CLIP embeddings may miss subtle dynamic features or equate noise with meaningful novelty

## Confidence

**High Confidence**: The dual architecture design successfully creates a closed-loop evolutionary system that can autonomously generate new targets based on visual history.

**Medium Confidence**: EST achieves higher OE scores (0.052 vs 0.049) due to single-prompt optimization focus.

**Medium Confidence**: ETT produces more coherent and interpretable evolutionary sequences as claimed.

**Low Confidence**: The system demonstrates true open-endedness rather than constrained exploration within biologically-biased subspaces.

## Next Checks

1. **Prompt Diversity Analysis**: Implement systematic tracking of prompt entropy and semantic similarity across EST and ETT iterations to quantify biological bias constraints.

2. **Metric Validation**: Compare OE scores against alternative novelty metrics and conduct ablation studies to determine if CLIP embeddings capture meaningful evolutionary progress.

3. **Parameter Space Exploration**: Systematically vary CMA-ES parameters and Gemma-3 temperature to map system robustness and identify optimal configurations for different exploration vs. exploitation trade-offs.