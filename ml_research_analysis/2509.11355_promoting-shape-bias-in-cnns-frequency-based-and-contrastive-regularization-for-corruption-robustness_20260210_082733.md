---
ver: rpa2
title: 'Promoting Shape Bias in CNNs: Frequency-Based and Contrastive Regularization
  for Corruption Robustness'
arxiv_id: '2509.11355'
source_url: https://arxiv.org/abs/2509.11355
tags:
- robustness
- learning
- wang
- contrastive
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes two complementary regularization methods to
  improve CNN robustness against common image corruptions by addressing the texture
  bias problem. The first method uses frequency-domain filtering to enforce feature
  consistency between original and low-frequency (blurred) inputs, discouraging reliance
  on high-frequency textures.
---

# Promoting Shape Bias in CNNs: Frequency-Based and Contrastive Regularization for Corruption Robustness

## Quick Facts
- arXiv ID: 2509.11355
- Source URL: https://arxiv.org/abs/2509.11355
- Reference count: 38
- Primary result: Frequency-based and supervised contrastive learning methods improve CNN corruption robustness on CIFAR-10-C benchmark, with contrastive learning achieving 69.13% mean corruption accuracy (0.8% improvement over baseline)

## Executive Summary
This paper addresses the texture bias problem in convolutional neural networks by proposing two complementary regularization methods to improve corruption robustness. The first method applies frequency-domain filtering to enforce feature consistency between original and low-frequency (blurred) inputs, discouraging reliance on high-frequency textures. The second method uses supervised contrastive learning to structure the feature space around class-consistent representations. Both approaches are evaluated on the CIFAR-10-C benchmark, demonstrating improved corruption robustness while maintaining clean accuracy, with the contrastive learning approach showing the most substantial gains.

## Method Summary
The authors propose two regularization techniques to address texture bias in CNNs. The frequency-based method applies a low-pass filter to create a blurred version of the input image, then enforces consistency between features extracted from the original and filtered images using a regularization loss. This encourages the network to rely less on high-frequency texture information. The supervised contrastive learning method restructures the feature space by pulling representations of the same class closer together while pushing different class representations apart, creating more discriminative and shape-aware features. Both methods are integrated into the training pipeline as additional loss terms, with the contrastive approach showing superior performance in improving corruption robustness.

## Key Results
- Supervised contrastive learning achieved 69.13% mean corruption accuracy on CIFAR-10-C, representing a 0.8% improvement over the 68.33% baseline
- Frequency-based regularization showed a 0.27% improvement in corruption accuracy
- Both methods maintained clean accuracy while improving corruption robustness
- The contrastive learning approach demonstrated the best overall performance among the proposed methods

## Why This Works (Mechanism)
The methods work by addressing the fundamental texture bias in CNNs, where networks tend to rely heavily on high-frequency texture information rather than shape-based features. The frequency-based regularization directly targets this by enforcing consistency between features extracted from original and blurred images, effectively penalizing reliance on texture details. The contrastive learning approach restructures the feature space to create more discriminative representations by grouping same-class samples together and separating different classes, which promotes shape-based discrimination over texture-based cues. Together, these methods shift the network's focus from texture to more robust, shape-based features that generalize better to corrupted inputs.

## Foundational Learning
- **Texture bias in CNNs**: CNNs naturally prefer texture over shape for classification, which hurts generalization to corrupted data - needed to understand the problem being addressed; quick check: Geirhos et al.'s original texture vs shape experiments
- **Frequency domain analysis**: Understanding how image information is distributed across frequency bands - needed to design the frequency-based regularization; quick check: Fourier transform of images shows high frequencies correspond to fine details/texture
- **Contrastive learning**: A framework for learning discriminative features by pulling similar samples together and pushing dissimilar ones apart - needed for the supervised contrastive component; quick check: supervised vs self-supervised contrastive variants
- **Regularization in deep learning**: Techniques for preventing overfitting and encouraging desired model behaviors - needed to understand how additional loss terms shape learning; quick check: L2 regularization vs feature consistency regularization
- **Corruption robustness**: The ability of models to maintain performance under various image distortions - needed to contextualize the evaluation metric; quick check: CIFAR-10-C benchmark statistics
- **Shape bias metrics**: Quantitative measures of how much models rely on shape versus texture - needed to validate the claimed effect on representations; quick check: Geirhos et al.'s shape bias calculation

## Architecture Onboarding

Component map:
Input images -> CNN backbone -> Feature extractor -> Classification head + Regularization losses (Frequency consistency + Contrastive loss) -> Output predictions

Critical path:
Input → CNN backbone → Feature extractor → Classification head → Predictions

Design tradeoffs:
The frequency-based method trades some texture discrimination capability for improved robustness, while the contrastive method requires additional memory for storing feature representations of other classes in the batch. The frequency approach is computationally lighter but less effective, while contrastive learning is more powerful but requires careful batch construction and hyperparameter tuning for the temperature parameter.

Failure signatures:
If regularization weights are too high, the model may underfit and show degraded performance on both clean and corrupted data. If too low, the methods won't effectively counteract texture bias. Poor batch construction for contrastive learning can lead to weak supervision signals and minimal improvements.

First experiments to run:
1. Train baseline model on CIFAR-10 without any regularization to establish performance floor
2. Apply only the frequency-based regularization to verify its individual contribution
3. Apply only the supervised contrastive learning to isolate its effects from the frequency method

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to CIFAR-10-C benchmark, raising questions about generalizability to other corruption datasets or real-world scenarios
- Modest improvements (0.27-0.8% in corruption accuracy) may have limited practical significance despite statistical significance
- Lack of thorough computational overhead analysis and ablation studies to isolate component effects
- Claims about promoting shape-aware representations rely on proxy metrics rather than direct shape bias measurements

## Confidence

High confidence: The empirical results on CIFAR-10-C are reproducible and show consistent improvements over the baseline.

Medium confidence: The claim that frequency-based regularization reduces texture bias is supported by the methodology but lacks direct verification through shape bias quantification.

Low confidence: The practical significance of 0.27-0.8% improvements in real-world applications is unclear.

## Next Checks
1. Evaluate the methods on additional corruption benchmarks (ImageNet-C, synthetic corruption datasets) to assess generalizability.
2. Conduct ablation studies to quantify the individual contributions of frequency filtering and contrastive learning components.
3. Measure actual shape bias (e.g., using Geirhos et al.'s shape bias metric) to directly validate the claimed effect on representation properties.