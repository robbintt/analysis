---
ver: rpa2
title: 'Diffusion Models with Double Guidance: Generate with aggregated datasets'
arxiv_id: '2505.13213'
source_url: https://arxiv.org/abs/2505.13213
tags:
- diffusion
- guidance
- conditional
- dmdg
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses conditional generative modeling on aggregated
  datasets with block-wise missing conditions, where different datasets contain distinct
  sets of attributes. The proposed Diffusion Model with Double Guidance (DMDG) enables
  joint conditional generation without requiring samples containing all conditions
  simultaneously.
---

# Diffusion Models with Double Guidance: Generate with aggregated datasets

## Quick Facts
- **arXiv ID**: 2505.13213
- **Source URL**: https://arxiv.org/abs/2505.13213
- **Reference count**: 40
- **One-line primary result**: Joint conditional generation from aggregated datasets without requiring samples containing all conditions simultaneously

## Executive Summary
This paper addresses conditional generative modeling on aggregated datasets with block-wise missing conditions, where different datasets contain distinct sets of attributes. The proposed Diffusion Model with Double Guidance (DMDG) enables joint conditional generation without requiring samples containing all conditions simultaneously. DMDG decomposes the conditional score function using conditional independence assumptions and injects additional guidance terms into the reverse diffusion process. Theoretical analysis establishes factors affecting guidance effectiveness, including gradient magnitudes, prediction errors, and guidance scale choices. Experiments across synthetic data, molecular datasets (GEOM-DRUG, ZINC250k), and image inpainting tasks demonstrate DMDG's superior performance in recovering conditional distributions and controllability.

## Method Summary
DMDG addresses conditional generation from aggregated datasets by decomposing the joint conditional score function under the assumption that conditions C1 and C2 are conditionally independent given the clean data X0. The method trains a base score network on aggregated X0 data with conditional dropout, then separately trains two regressor networks on each dataset to predict conditions from data. During generation, DMDG approximates the joint conditional score by combining the unconditional score with guidance gradients from both regressors. The key innovation is that the second regressor takes the conditional posterior mean (which incorporates the first condition) as input, preserving correlations between conditions that independent guidance would miss. This approach enables training-free conditional generation without requiring samples that contain all conditions simultaneously.

## Key Results
- DMDG achieved 76% success rate in generating molecules satisfying six properties simultaneously on GEOM-DRUG and ZINC250k datasets
- For molecular generation, DMDG outperformed baselines (GAIN, KNN) with W2 metrics 5-26× better
- Image inpainting experiments showed improved perceptual quality and condition alignment compared to unconditional diffusion models
- Theoretical analysis established that guidance effectiveness depends on gradient magnitudes, prediction errors, and guidance scale choices

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The joint conditional score function can be decomposed without requiring joint samples of all conditions.
- Mechanism: DMDG exploits the conditional independence assumption C1 ⊥⊥ C2 | X0 to factorize ∇Xt log pt(Xt|C1, C2) into separate guidance terms. Equation (9) shows: ∇Xt log pt(Xt|C1, C2) ≈ ∇Xt log pt(Xt) + ∇Xt log p(C1|E[X0|Xt]) + ∇Xt log p(C2|E[X0|Xt,C1]). Critically, the second guidance term conditions on E[X0|Xt,C1] rather than just E[X0|Xt].
- Core assumption: Conditions C1 and C2 are conditionally independent given the clean data X0 (satisfied when both are deterministic functions of X0 with independent noise, per equation 1).
- Evidence anchors:
  - [Section 3.1, equations 9-11] Derivation explicitly uses CI to avoid joint (C1,C2) samples.
  - [Figure 1, right panel] Shows DMDG matches true conditional score when C1 ⊥⊥ C2 fails given Xt, while independent guidance diverges.
  - [Corpus: CoInD paper] Addresses related compositional conditioning under independence assumptions, suggesting this decomposition strategy has precedent but DMDG extends it to block-wise missing data.
- Break condition: If C1 and C2 have direct dependencies not mediated through X0, the decomposition becomes inaccurate. Figure 4 (right panel) shows I(C1;C2|Xt) increases with noise level t, violating the approximation at high t.

### Mechanism 2
- Claim: Dependency-aware second guidance preserves correlations between conditions that independent guidance ignores.
- Mechanism: The key difference between DMDG and the baseline DMIDG is that DMDG uses bf2(X0|t,C1)—the regressor conditioned on both the noisy estimate AND C1—while DMIDG uses bf2(X0|t). This preserves the correlation structure between C1 and C2 that would otherwise be lost.
- Core assumption: The conditional posterior mean E[X0|Xt,C1] is well-approximated by nnθ(Xt, t, C1).
- Evidence anchors:
  - [Section 3.3, equation 26] Explicitly contrasts DMIDG's incorrect factorization.
  - [Table 2, Setting II] DMDG achieves W2=3.275 vs DMIDG's 4.688 when C1 ⊥⊥ C2 is false, demonstrating the importance of dependency-aware guidance.
  - [Corpus: Weak direct evidence] Neighbors focus on single-condition guidance; DMDG's sequential conditioning appears novel.
- Break condition: When C1 and C2 are truly independent (Setting I in Table 2), DMDG and DMIDG perform similarly, and the extra complexity provides no benefit.

### Mechanism 3
- Claim: Guidance effectiveness depends on tunable factors identified in theoretical bounds.
- Mechanism: Theorem 1 provides error bounds showing that guidance accuracy degrades with: (a) large gradient magnitudes of the true functions f1, f2; (b) prediction errors of neural networks nnθ and bf; (c) mismatch between guidance scale λ and true variance σ² (specifically, λ should scale as O(1/σ²)).
- Core assumption: The function-mapping model (equation 1) holds, and neural networks approximate the required quantities.
- Evidence anchors:
  - [Section 4, Theorem 1, equations 13-14] Formal bounds on density approximation errors.
  - [Table 2] Guidance scales λ∼1.5-180 consistent with theoretical prediction of λ∼O(1/σ²).
  - [Corpus: Att-Adapter paper] Addresses multi-attribute T2I control but via different mechanism (adapters), suggesting guidance scale tuning is a shared challenge.
- Break condition: Extremely large gradient functions or poorly trained regressors bf1, bf2 cause the Gaussian density approximations in equation 10 to break down.

## Foundational Learning

- **Score Functions and Diffusion Guidance**
  - Why needed here: The entire method operates on score functions ∇Xt log pt(Xt|conditions), not on data directly.
  - Quick check question: Can you explain why ∇Xt log p(C|Xt) ≈ -λ∇Xt‖C−f(X̂0)‖² is a valid approximation when C = f(X0) + ε?

- **Classifier Guidance vs. Classifier-Free Guidance**
  - Why needed here: DMDG uses CG-style guidance; DMHG combines CFG for C1 with CG for C2. Understanding when each is appropriate is critical.
  - Quick check question: Why does CFG (equation 8) typically produce higher quality samples than CG (equation 6) for complex conditions?

- **Tweedie Projection and Posterior Means**
  - Why needed here: E[X0|Xt] estimation via nnθ(Xt,t,∅) underpins all guidance terms. Theorem 1's term (d) shows this prediction error directly impacts guidance effectiveness.
  - Quick check question: Given Xt = X0 + tε, derive why E[X0|Xt] = Xt + t²∇Xt log pt(Xt).

- **Conditional Independence Testing/Reasoning**
  - Why needed here: The method hinges on C1 ⊥⊥ C2 | X0. If this fails, the decomposition in equation 9 is invalid.
  - Quick check question: If C1 and C2 are both properties of a molecule but share a common cause beyond the molecular structure, does CI hold?

## Architecture Onboarding

- **Component map:**
  ```
  D(1): X0, C1 → trains nnθ (with C1 dropout) → sθ(Xt,t,C1), sθ(Xt,t,∅)
                                              ↓
  D(2): X0, C2 → trains bf2(X0|t,C1) ← needs conditional input from nnθ
            ↓
       trains bf1(X0) separately on D(1)
  ```
  Key insight: bf2 must be trained to take [X̂0, C1] as input, not just X̂0.

- **Critical path:**
  1. Pre-train nnθ on aggregated X0 data with conditional dropout (equation 4)
  2. Separately train bf1 on D(1), bf2 on D(2) (bf2 takes latent + C1 as input)
  3. At inference: run Algorithm 1, computing both X0|t and X0|t,C1 at each step
  4. Guidance scales λ1, λ2 tuned per-task; start with λ ∼ 1/σ² as theoretical prior

- **Design tradeoffs:**
  - **DMDG vs. DMHG:** DMDG (pure CG) is simpler but may distort distributions for complex C1. DMHG (CFG+CG) handles complex C1 better but requires conditional training of nnθ on C1.
  - **Training-free vs. imputation:** Imputation methods (Table 2: GAIN, KNN) avoid guidance tuning but perform substantially worse (W2 5-26× higher).
  - **Guidance scale selection:** Higher λ enforces stronger condition adherence but reduces sample quality; Theorem 1 suggests λ should match 1/(2σ²) of the noise model.

- **Failure signatures:**
  - Generated samples ignore C2: bf2 is undertrained or λ2 too small
  - Poor sample quality despite condition matching: λ1 or λ2 excessively large (try reducing by 10×)
  - C1 and C2 conflict: Check if CI assumption holds; if I(C1;C2|X0) > 0, decomposition may be invalid
  - Numerical instability at high t: In triple-guidance (DMTG), only apply C3 guidance when t ≤ σdata (Appendix B)

- **First 3 experiments:**
  1. **Sanity check on synthetic data:** Replicate Setting I/II (Section 5) with known ground truth to validate guidance scale tuning matches theoretical predictions (λ ∼ O(1/σ²)).
  2. **Ablation: bf2 input conditioning:** Compare bf2(X0|t,C1) vs. bf2(X0|t) on a dataset where C1 and C2 have known correlation. Expect divergence similar to Figure 1 (right panel).
  3. **Single-dataset baseline:** Train on D(1) only (with imputed C2) vs. aggregated D(1)∪D(2) with DMDG. Table 7 shows aggregated training improves W2 from 4.506 to 3.275, establishing the value proposition.

## Open Questions the Paper Calls Out
- **Open Question 1**: Can DMDG maintain high controllability and sample quality when applied to significantly larger and more diverse collections of aggregated datasets? [explicit] The conclusion states, "Applying our approach to larger and more diverse collections of aggregated datasets will be among our future works." Experiments were limited to specific molecular (GEOM-DRUG, ZINC250k) and image (ImageNet) datasets; performance on massive, heterogeneous data aggregates is unproven.

- **Open Question 2**: How does the method's performance degrade when the conditional independence assumption (C1 ⊥⊥ C2 | X0) is violated? [inferred] The method relies on the CI relation (Eq. 1) to decompose the score function (Eq. 9), but the paper does not evaluate robustness to violations of this structural assumption. If C1 and C2 have residual correlation given X0, the score decomposition may be inaccurate, potentially leading to incorrect conditional distributions.

- **Open Question 3**: Can an adaptive mechanism be developed to automatically select optimal guidance scales (λ1, λ2) based on the theoretical error bounds? [inferred] Theorem 1 identifies that discrepancy arises from inappropriate scale choices (σ² - 1/2λ), yet the experiments rely on manual tuning of these hyperparameters. Manual tuning is labor-intensive and may be unstable across different noise levels or condition types, limiting the method's "training-free" practicality.

## Limitations
- **Conditional independence assumption**: The method fundamentally relies on C1 ⊥⊥ C2 | X0. The paper shows I(C1;C2|Xt) increases with noise level t (Figure 4), suggesting the assumption may break down during generation.
- **Regressor generalization**: The method depends on regressors trained on clean data performing well on noisy estimates X0|t, which could accumulate errors through the generation process.
- **Gradient magnitude sensitivity**: Theorem 1 indicates guidance effectiveness degrades when true functions f1, f2 have large gradients, but this limitation is not extensively validated experimentally.

## Confidence
- **High confidence**: The core DMDG mechanism (conditional independence decomposition with dependency-aware guidance) is theoretically sound and validated across multiple domains (synthetic, molecular, image).
- **Medium confidence**: The theoretical bounds in Theorem 1 accurately predict guidance scale tuning (λ ∼ O(1/σ²)) based on experimental evidence, though this is not systematically explored.
- **Low confidence**: The claim that DMDG works when C1 ⊥⊥ C2 | X0 is violated (Figure 1 right panel) needs more rigorous validation across diverse correlation structures.

## Next Checks
1. **Correlation structure robustness**: Systematically vary the correlation between C1 and C2 in synthetic experiments to map the boundary where conditional independence breaks down and guidance fails.
2. **Regressor error accumulation**: Track the prediction error of bf1 and bf2 throughout the generation process across different noise levels t to validate the gradient magnitude sensitivity predicted by Theorem 1.
3. **Guidance scale sensitivity**: Conduct a systematic grid search over guidance scales λ1, λ2 across multiple σ values to empirically verify the theoretical prediction λ ∼ O(1/σ²) and identify optimal scaling relationships.