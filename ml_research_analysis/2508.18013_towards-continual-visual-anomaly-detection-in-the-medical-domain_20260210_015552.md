---
ver: rpa2
title: Towards Continual Visual Anomaly Detection in the Medical Domain
arxiv_id: '2508.18013'
source_url: https://arxiv.org/abs/2508.18013
tags:
- anomaly
- continual
- detection
- learning
- memory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of continual visual anomaly
  detection in the medical domain, where models must adapt to new data distributions
  over time without forgetting previously learned knowledge. The authors propose a
  continual learning adaptation of the PatchCore model (PatchCoreCL) and evaluate
  it on the BMAD dataset, a real-world medical imaging benchmark.
---

# Towards Continual Visual Anomaly Detection in the Medical Domain

## Quick Facts
- arXiv ID: 2508.18013
- Source URL: https://arxiv.org/abs/2508.18013
- Reference count: 24
- Primary result: PatchCoreCL achieves <1% forgetting on 6 sequential medical imaging tasks while using one-third the memory of joint training

## Executive Summary
This paper addresses continual visual anomaly detection in medical imaging, where models must adapt to new data distributions over time without forgetting previously learned knowledge. The authors propose PatchCoreCL, a continual learning adaptation of the PatchCore model, which maintains separate memory banks for each task using coreset subsampling. Evaluated on the BMAD dataset, PatchCoreCL achieves performance comparable to task-specific models with a forgetting value below 1%, demonstrating the feasibility of adaptive VAD in medical domains.

## Method Summary
The method adapts PatchCore for continual learning by maintaining a separate memory bank for each task using coreset subsampling. When a new task arrives, PatchCoreCL applies coreset reduction to existing memory banks and the new task patches, then appends the new bank to a list. During inference, the model compares the input against all memory banks and selects the one with the lowest anomaly score for final prediction. The approach uses a frozen WideResNet50 backbone and keeps total memory fixed at 10K or 30K patch features.

## Key Results
- PatchCoreCL achieves forgetting below 1% across 6 sequential medical imaging tasks
- PatchCoreCL-10K uses one-third of the memory of joint training while maintaining a relative performance gap of only 0.02
- Performance comparable to task-specific models across image-level (AUROC: 0.81-0.93) and pixel-level metrics (F1: 0.77-0.88)

## Why This Works (Mechanism)

### Mechanism 1: Coreset Subsampling for Memory-Constrained Rehearsal
- Applying coreset subsampling separately to each task's memory bank preserves representative feature diversity while enabling fixed memory budgets across sequential tasks
- When a new task arrives, PatchCoreCL extracts patch feature vectors and applies K-Center clustering to select a representative subset, while simultaneously re-applying coreset subsampling to all existing memory banks to maintain fixed total memory
- Core assumption: The coreset reduction preserves enough discriminative patch features per task that anomaly detection accuracy remains comparable to full rehearsal
- Evidence: Section 3.3 describes the iterative coreset subsampling applied to both old memory banks and new patches with size budget `memory_size / (i+1)`

### Mechanism 2: Frozen Feature Extractor with Task-Specific Memory Banks
- Using a frozen pre-trained CNN feature extractor eliminates weight-update-induced catastrophic forgetting while task-specific memory banks encode domain knowledge independently
- PatchCore's backbone remains frozen throughout training, with only the memory banks updated per task, preventing interference via weight overwriting
- Core assumption: Pre-trained ImageNet features transfer sufficiently to medical imaging domains without domain-specific adaptation
- Evidence: Section 3.1 states the feature extractor is frozen and only the memory bank containing patches is updated

### Mechanism 3: Inference-Time Task Identification via Minimum Anomaly Score
- Selecting the memory bank yielding the lowest image-level anomaly score enables implicit task identification without requiring explicit task labels at inference
- At inference, the input image's patch features are compared against all stored memory banks, with the bank producing the minimum score selected for pixel-level localization
- Core assumption: Inter-domain feature distances exceed intra-domain normal variation
- Evidence: Section 3.3 explains that the memory bank ensuring the lowest score is used, as different categories will cause higher image-level anomaly scores

## Foundational Learning

- **Concept: PatchCore's Nearest-Neighbor Anomaly Scoring**
  - Why needed here: Understanding how PatchCore computes anomaly scores via patch-level nearest-neighbor distance is essential before grasping how memory bank modifications affect detection
  - Quick check question: Can you explain how PatchCore derives both image-level and pixel-level anomaly scores from a memory bank of patch features?

- **Concept: Catastrophic Forgetting in Sequential Learning**
  - Why needed here: The entire motivation for PatchCoreCL is mitigating forgetting when tasks arrive sequentially; understanding why Fine-Tuning fails (52.32% forgetting in Table 1) clarifies the design constraints
  - Quick check question: Why does standard fine-tuning on new tasks cause performance collapse on previously learned tasks in neural networks?

- **Concept: Coreset Subsampling (Greedy K-Center Clustering)**
  - Why needed here: The memory bank update mechanism relies on coreset selection; understanding this clustering approach explains how representative patches are preserved under memory constraints
  - Quick check question: How does K-Center clustering ensure coverage of feature space compared to random sampling, and what is the computational tradeoff?

## Architecture Onboarding

- **Component map:**
  1. Frozen Feature Extractor (WideResNet50, ~275.6 MB) -> Memory Bank Manager -> Coreset Sampling Module -> Inference Comparator -> Storage
  2. Memory Bank Manager maintains list of task-specific banks and handles coreset reduction
  3. Coreset Sampling Module implements K-Center clustering for memory compression per task
  4. Inference Comparator computes image-level scores against all banks, selects minimum-score bank for pixel-level output

- **Critical path:**
  The memory bank update loop (Algorithm 1) is the core sequence: when task i arrives, extract patches → apply coreset to old banks with new budget → create new bank for task i → append to bank list. Errors here propagate to all subsequent tasks.

- **Design tradeoffs:**
  - Memory size vs. performance: 10K bank uses 1/3 memory of 30K with only 0.01-0.02 F1 gap; choose 10K for constrained deployments, 30K for accuracy-critical applications
  - Number of tasks vs. samples per task: As tasks increase, samples per task decrease (`memory_size / i+1`); with 6 tasks and 10K total, final task gets ~1,667 samples
  - Task order sensitivity: The sequential task stream may affect early-task retention; order permutations were not tested

- **Failure signatures:**
  - High forgetting (>5%): Indicates coreset over-compression or task interference; check per-task bank sizes
  - Task identification failures: If image-level scores are similar across banks, inference may select wrong bank; inspect score distributions per bank
  - Memory overflow: If bank list grows unboundedly, the coreset budget division is not being applied correctly
  - Pixel-level localization degradation: If image-level scores remain high but pixel-level F1 drops, the selected bank may lack fine-grained patch diversity

- **First 3 experiments:**
  1. Reproduce baseline on single BMAD category: Train standard PatchCore on "Brain AD" only; verify AUROC/F1 matches Multi-Model row in Table 1
  2. Run PatchCoreCL-10K on 3-task subset: Use Brain→Liver→Retina (pixel-level annotated); compute forgetting and relative gap to validate against paper's 0.80% forgetting claim
  3. Ablate task order: Reverse the task sequence (OCT→Histopathology→...→Brain) and measure whether forgetting and relative gap remain stable

## Open Questions the Paper Calls Out
- How do other state-of-the-art Visual Anomaly Detection models (e.g., EfficientAD, FastFlow) compare to PatchCoreCL in this medical continual learning scenario?
- Can the memory bank update strategy be further optimized to close the performance gap with Joint-Training while maintaining a fixed memory size?
- How does the specific sequence of medical domains influence the model's stability and forgetting rate?

## Limitations
- The approach assumes frozen ImageNet-pretrained features transfer effectively to diverse medical imaging domains without domain-specific adaptation
- Task identification via minimum anomaly score lacks theoretical justification and may fail if cross-domain normal appearances overlap significantly
- The coreset reduction strategy's effectiveness depends on the assumption that patch-level feature diversity correlates with diagnostic relevance

## Confidence
- **High**: Memory bank management mechanism and forgetting measurements
- **Medium**: Transferability of frozen features across medical domains
- **Low**: Task identification via minimum anomaly score

## Next Checks
1. Extract and visualize feature distributions from memory banks across the 6 BMAD categories to verify that inter-domain distances exceed intra-domain normal variation
2. Apply PatchCoreCL trained on BMAD to a held-out medical imaging dataset to assess whether frozen feature transferability holds beyond the training distribution
3. Systematically vary the coreset reduction parameters and measure their impact on forgetting and relative performance gap to identify optimal compression settings for medical anomaly detection