---
ver: rpa2
title: No AI Without PI! Object-Centric Process Mining as the Enabler for Generative,
  Predictive, and Prescriptive Artificial Intelligence
arxiv_id: '2508.00116'
source_url: https://arxiv.org/abs/2508.00116
tags:
- process
- data
- mining
- processes
- generative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Process Intelligence (PI) as the essential
  integration of Object-Centric Process Mining (OCPM) with Artificial Intelligence
  (AI) to address the challenge of applying AI effectively in industrial settings
  focused on end-to-end operational processes. While AI has made significant advances,
  organizations struggle to ground these techniques in real-world process contexts
  due to fragmented data and oversimplified case-centric models.
---

# No AI Without PI! Object-Centric Process Mining as the Enabler for Generative, Predictive, and Prescriptive Artificial Intelligence

## Quick Facts
- arXiv ID: 2508.00116
- Source URL: https://arxiv.org/abs/2508.00116
- Reference count: 23
- Authors: Wil M. P. van der Aalst
- Primary result: Process Intelligence (PI) integrating OCPM with AI unlocks AI's potential for enterprise-wide process improvement

## Executive Summary
This paper argues that traditional case-centric process mining is insufficient for applying AI effectively in industrial settings focused on end-to-end operational processes. Object-Centric Process Mining (OCPM) provides the missing link by offering system-agnostic, object-centric event data that accurately reflects complex, multi-object processes. The paper introduces "Process Intelligence" (PI) as the essential integration of OCPM with Generative, Predictive, and Prescriptive AI, enabling organizations to uncover bottlenecks, predict issues, and prescribe optimal actions across their operational fabric.

## Method Summary
The paper proposes a framework where Object-Centric Event Data (OCED) in OCEL 2.0 format serves as the foundation for AI applications. For Predictive AI, process problems are translated into training examples by labeling specific bottlenecks and delays. For Generative AI, Retrieval-Augmented Generation (RAG) grounds LLMs in process mining computations rather than hallucinations. For Prescriptive AI, OCPM exposes constraints and resources across interconnected processes, enabling goal-driven optimization. The method requires extracting multi-object event data, discovering process models, and implementing the appropriate AI connection based on the use case.

## Key Results
- OCPM eliminates rigid case notions by allowing events to reference multiple objects simultaneously
- OCPM provides the "world model" required for Generative AI to interact meaningfully with enterprise operations
- OCPM enables Prescriptive AI by exposing constraints and resources across interconnected processes
- Five key connections between OCPM and AI are demonstrated, transforming AI from isolated automation to enterprise-wide process improvement

## Why This Works (Mechanism)

### Mechanism 1
Object-Centric Process Mining converts operational chaos into structured training examples for Predictive AI by eliminating the "rigid case notion" of traditional mining. OCPM allows events to reference multiple objects (e.g., orders, items, packages) and flattens multi-dimensional event data into a consistent format (OCED). This enables isolating specific process friction points and labeling them for supervised learning, where the input is the process state and the target is the outcome (e.g., delay time).

### Mechanism 2
OCPM provides the "world model" required for Generative AI to interact meaningfully with enterprise operations. Standalone LLMs lack access to private, real-time operational data. Using RAG, the GenAI queries the OCPM engine for factual process states rather than hallucinating based on generic training data. The GenAI effectively becomes a natural language interface for the OCPM data structure.

### Mechanism 3
OCPM enables Prescriptive AI by exposing constraints and resources across interconnected processes. Traditional process mining simplifies reality into isolated cases, hiding resource conflicts. OCPM reveals the intersections of different processes, allowing prescriptive algorithms to optimize based on the actual fabric of the organization rather than a distorted, single-case view.

## Foundational Learning

- **Concept: Object-Centric Event Data (OCED)**
  - **Why needed here:** The paper argues that traditional "case" logic is the primary bottleneck for AI. You must understand that an event (e.g., "Payment Received") relates to both an *Order* and a *Customer*, not just one "case ID," to structure the data for the mechanisms above.
  - **Quick check question:** Can you explain why forcing a many-to-many relationship (like items in an order) into a single-case log distorts process reality?

- **Concept: Retrieval-Augmented Generation (RAG)**
  - **Why needed here:** The paper positions GenAI not as a reasoner, but as an interface. Understanding RAG is critical to implementing the "Process Intelligence" layer where the LLM fetches OCPM data rather than guessing.
  - **Quick check question:** If a user asks an LLM "Why is this order late?", does the LLM answer from its pre-trained weights or by retrieving the specific event log history of that order?

- **Concept: Conformance Checking vs. Performance Analysis**
  - **Why needed here:** To create training data for Predictive AI, one must distinguish between "deviations" (compliance) and "delays" (performance). The paper relies on the ability to detect these to create "labels" for the AI.
  - **Quick check question:** How would you label a training example where a process skipped a necessary approval step versus one that took too long?

## Architecture Onboarding

- **Component map:**
  Source Systems (ERP/CRM) -> Extraction Layer (ETL) -> Data Standard (OCEL 2.0) -> Process Engine (OCPM software) -> AI Interface (Predictive/GenAI/Prescriptive)

- **Critical path:** The extraction and definition of **Object Types**. If you incorrectly define the "Objects" (e.g., failing to distinguish between 'Goods Receipt' and 'Invoice'), the entire OCPM graph collapses into the very distortions the paper warns against.

- **Design tradeoffs:**
  - *Complexity vs. Fidelity:* Creating an OCPM model for every object type is ideal for AI but increases data engineering load. Start with high-impact objects (Orders, Items, Resources) rather than trying to model the entire enterprise at once.
  - *Real-time vs. Batch:* Prescriptive AI needs fresh data. The paper implies "real-time actionable diagnostics," which requires streaming data pipelines, whereas traditional mining often runs on daily batches.

- **Failure signatures:**
  - **The "Spaghetti" Model:** The OCPM graph is so dense no insights can be drawn. *Remedy:* Filter by frequency or focus on specific object interactions.
  - **Hallucinated Context:** GenAI confidently states a process is compliant when it isn't. *Remedy:* Tighten the RAG retrieval constraints; force the model to cite the specific OCPM event ID.
  - **Unactionable Insights:** AI predicts delays but offers no way to intervene. *Remedy:* Ensure Prescriptive AI integration is built alongside Predictive AI.

- **First 3 experiments:**
  1. **Data Extraction Pilot:** Select a single high-volume process (e.g., Procurement). Extract data into OCEL format. Verify that events link to at least two object types (e.g., Purchase Order and Vendor).
  2. **Bottleneck Labeling:** Identify one specific bottleneck in the discovered OCPM model. Export the "pre-bottleneck" features and the resulting "delay time" to train a simple regression model (validating Mechanism 1).
  3. **RAG Interface Prototype:** Connect a basic LLM to your OCPM view. Ask it "Which vendor has the most deviations?" and verify it retrieves the correct OCPM metric rather than inventing a vendor name.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can Generative AI be effectively utilized to bridge the gap between proprietary source system formats and Object-Centric Event Data (OCED) to automate event data preparation?
- **Basis in paper:** The author states that although data extraction is a bottleneck, "research on this topic is limited" and suggests GenAI could facilitate this transformation.
- **Why unresolved:** Current adoption is hindered by the difficulty of mapping specific, proprietary data schemas to the standardized OCED format (e.g., OCEL 2.0).
- **What evidence would resolve it:** A framework or tool demonstrating high accuracy in automatically mapping raw SQL database schemas to OCEL standards using LLMs.

### Open Question 2
- **Question:** To what extent can Retrieval-Augmented Generation (RAG) improve the reliability of GenAI answers regarding process performance compared to prompting with textually encoded process models?
- **Basis in paper:** The paper notes that sending textually encoded variants to GenAI works but is "not very reliable," suggesting RAG as a crucial extension that requires further validation.
- **Why unresolved:** LLMs struggle with hallucination when analyzing process logs purely via text prompts; the specific efficacy of RAG in grounding these queries in "process mining computations" remains an open technical challenge.
- **What evidence would resolve it:** Comparative benchmarks showing RAG-based approaches significantly outperform direct textual prompting in accuracy for specific process queries.

### Open Question 3
- **Question:** How can the "interplay between domain knowledge, process discovery, and LLMs" be formalized to assist in creating accurate normative process models?
- **Basis in paper:** The author mentions this interplay may provide novel insights and that GenAI "may also be used to assist in creating normative models," but implies the methodology is currently nascent.
- **Why unresolved:** There is no established standard for integrating human domain knowledge with algorithmic discovery and LLM capabilities to generate models that represent *desired* workflows rather than just *actual* workflows.
- **What evidence would resolve it:** A methodology where user constraints are successfully merged with discovered data to generate simulated, compliant "to-be" models validated by domain experts.

## Limitations
- The framework assumes organizations can reliably extract and maintain object-centric event data in OCEL 2.0 format, but provides no evidence about the engineering effort required
- The "Process Intelligence" concept appears largely theoretical with no demonstration of the five connections working together in an integrated system
- The prescriptive AI mechanism assumes optimization goals can be clearly defined mathematically, but many real-world processes involve competing objectives and qualitative constraints

## Confidence
- **High Confidence**: The fundamental claim that traditional case-centric process mining is insufficient for AI applications is well-supported and aligns with established literature
- **Medium Confidence**: The mechanism by which OCPM enables predictive AI training is logical but untested - the feature engineering approach for converting object-centric graphs to ML-compatible formats remains unspecified
- **Low Confidence**: The prescriptive AI claims lack validation; while OCPM can expose resource constraints, the paper doesn't demonstrate how this actually improves prescriptive outcomes compared to existing optimization approaches

## Next Checks
1. **Data Quality Assessment**: Extract a sample OCEL 2.0 dataset from a real process and measure the completeness and accuracy of object relationships - determine what percentage of events successfully link to multiple object types as required.
2. **Feature Engineering Prototype**: Implement a prototype that converts object-centric process states into feature vectors for ML, then test whether standard algorithms (XGBoost, Random Forest) can actually learn meaningful patterns from this representation.
3. **RAG Grounding Evaluation**: Build a simple RAG system querying an OCPM layer and measure hallucination rates - compare LLM responses with and without RAG grounding when asked specific process questions.