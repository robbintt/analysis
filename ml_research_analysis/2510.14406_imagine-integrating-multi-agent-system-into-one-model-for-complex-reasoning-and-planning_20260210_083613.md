---
ver: rpa2
title: 'IMAGINE: Integrating Multi-Agent System into One Model for Complex Reasoning
  and Planning'
arxiv_id: '2510.14406'
source_url: https://arxiv.org/abs/2510.14406
tags:
- reasoning
- multi-agent
- training
- system
- final
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'IMAGINE integrates the reasoning and planning capabilities of
  a Multi-Agent System into a single, compact model through a novel three-stage framework:
  New Query Generation, Multi-Agent System-based Inference Data Generation, and Agentic
  Reasoning Training. The approach distills the collective reasoning abilities of
  a well-organized MAS into a small model, enabling it to outperform the original
  MAS through end-to-end training.'
---

# IMAGINE: Integrating Multi-Agent System into One Model for Complex Reasoning and Planning

## Quick Facts
- arXiv ID: 2510.14406
- Source URL: https://arxiv.org/abs/2510.14406
- Reference count: 35
- Primary result: Achieves 82.7% Final Pass Rate on TravelPlanner benchmark using Qwen3-8B-Instruct

## Executive Summary
IMAGINE addresses the challenge of integrating multi-agent system capabilities into a single, compact model for complex reasoning and planning tasks. The approach distills the collective reasoning abilities of a well-organized MAS into a smaller model through a novel three-stage framework: New Query Generation, Multi-Agent System-based Inference Data Generation, and Agentic Reasoning Training. By using Qwen3-8B-Instruct as the base model, IMAGINE achieves significantly better performance than both traditional MAS approaches and large standalone models like DeepSeek-R1-671B, while maintaining much smaller model size and lower inference costs.

## Method Summary
IMAGINE employs a three-stage framework to integrate multi-agent system capabilities into a single model. First, it generates new queries through prompt engineering to elicit diverse reasoning paths. Second, it leverages a well-organized multi-agent system to generate inference data that captures complex reasoning patterns. Third, it performs agentic reasoning training to distill this knowledge into the compact base model. This approach enables end-to-end training of a smaller model that can outperform the original MAS while maintaining efficiency advantages.

## Key Results
- Achieves 82.7% Final Pass Rate on TravelPlanner benchmark
- Outperforms DeepSeek-R1-671B (671B parameters) which achieves only 40% Final Pass Rate
- Maintains significantly smaller model size compared to traditional MAS approaches
- Demonstrates substantially lower inference costs than conventional multi-agent system deployments

## Why This Works (Mechanism)
The framework works by systematically capturing and distilling the diverse reasoning capabilities of a multi-agent system through structured data generation. The three-stage approach allows the model to learn not just the final answers but the intermediate reasoning steps and diverse problem-solving strategies that emerge from multi-agent collaboration. End-to-end training enables the distilled model to integrate these capabilities more efficiently than running multiple specialized agents sequentially.

## Foundational Learning
- Multi-Agent Systems: Collections of autonomous agents working together to solve complex tasks
  - Why needed: MAS can handle complex reasoning by decomposing tasks across specialized agents
  - Quick check: Can MAS outperform single large models on tasks requiring diverse reasoning strategies?

- Knowledge Distillation: Transferring knowledge from large models to smaller, more efficient ones
  - Why needed: Enables deployment of complex reasoning capabilities in resource-constrained environments
  - Quick check: Does the distilled model maintain or improve upon the original system's performance?

- Prompt Engineering: Crafting input prompts to elicit desired model behaviors and outputs
  - Why needed: Controls the quality and diversity of generated reasoning data
  - Quick check: How sensitive is performance to variations in prompt design?

## Architecture Onboarding
- Component map: New Query Generation -> Multi-Agent System-based Inference Data Generation -> Agentic Reasoning Training
- Critical path: The three-stage training pipeline must be executed sequentially, with each stage building on the previous one's outputs
- Design tradeoffs: Model size vs. performance, training complexity vs. inference efficiency
- Failure signatures: Poor performance if MAS generates inconsistent data, if query generation is too narrow, or if training fails to capture diverse reasoning patterns
- Three first experiments:
  1. Baseline comparison: Test performance of MAS alone vs. IMAGINE on TravelPlanner
  2. Ablation study: Remove each stage of the framework to assess individual contributions
  3. Generalization test: Apply IMAGINE to a different complex reasoning benchmark

## Open Questions the Paper Calls Out
None specified in the provided information.

## Limitations
- Unclear scalability of the three-stage framework beyond travel planning to other complex reasoning domains
- Limited comparison scope primarily against single large models rather than state-of-the-art multi-agent systems
- Insufficient detail on handling edge cases, ambiguous queries, or inconsistent MAS outputs
- Uncertainty about computational overhead of the full training pipeline versus inference benefits

## Confidence
- High confidence: The 82.7% Final Pass Rate on TravelPlanner represents a genuine technical achievement
- Medium confidence: Claim of significantly lower inference costs compared to traditional MAS approaches
- Medium confidence: Generalizability of the three-stage framework to other reasoning and planning domains
- Low confidence: Claim that the distilled model outperforms the original MAS in all aspects

## Next Checks
1. Test IMAGINE on multiple complex reasoning benchmarks beyond TravelPlanner (e.g., ALFWorld, HotpotQA, or mathematical reasoning tasks) to assess domain generalization
2. Conduct ablation studies comparing the three-stage framework against simpler distillation approaches to isolate the contribution of each component
3. Measure and report the full training pipeline computational costs to validate the claimed cost advantages over traditional MAS deployment