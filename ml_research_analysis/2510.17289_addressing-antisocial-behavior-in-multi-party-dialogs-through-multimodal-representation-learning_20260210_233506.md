---
ver: rpa2
title: Addressing Antisocial Behavior in Multi-Party Dialogs Through Multimodal Representation
  Learning
arxiv_id: '2510.17289'
source_url: https://arxiv.org/abs/2510.17289
tags:
- fusion
- detection
- learning
- graph
- multi-party
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study addresses antisocial behavior detection in multi-party\
  \ conversations, an underexplored domain due to limited data. We introduce two novel\
  \ evaluation tasks\u2014bullying behavior analysis and peer group identification\u2014\
  to capture pragmatic intent and participant roles beyond binary abuse detection."
---

# Addressing Antisocial Behavior in Multi-Party Dialogs Through Multimodal Representation Learning

## Quick Facts
- arXiv ID: 2510.17289
- Source URL: https://arxiv.org/abs/2510.17289
- Authors: Hajar Bakarou; Mohamed Sinane El Messoussi; Anaïs Ollagnier
- Reference count: 40
- Primary result: Multimodal models outperform unimodal baselines for antisocial behavior detection in multi-party conversations

## Executive Summary
This paper addresses antisocial behavior (ASB) detection in multi-party conversations, an underexplored domain due to limited data. The authors introduce two novel evaluation tasks—bullying behavior analysis and peer group identification—to capture pragmatic intent and participant roles beyond binary abuse detection. Using the French CyberAgressionAdo-Large dataset, they benchmark six text-based and eight graph-based representation learning methods, along with multimodal fusion strategies. Results show that multimodal models, particularly late fusion of mBERT and WD-SGCN, achieve the best overall performance across all tasks.

## Method Summary
The study uses a novel French dataset of simulated cyberbullying conversations (CyberAgressionAdo-Large) with annotations for abusive content and peer roles. The approach constructs interaction graphs from message sequences using sliding windows, then applies text encoders (mBERT/CamemBERT) and graph encoders (WD-SGCN/Node2Vec) separately before fusion. Three fusion strategies are compared: early fusion (concatenating embeddings), late fusion (combining classifier outputs), and hybrid fusion. Six text-based and eight graph-based models are evaluated on three tasks: abuse detection, bullying analysis, and peer group identification.

## Key Results
- Multimodal models outperform unimodal baselines across all tasks
- Late fusion model mBERT + WD-SGCN achieves best overall results (0.718 F1 on abuse detection, 0.606 on bullying analysis, 0.286 on peer group identification)
- Graph-based models excel at peer group identification when incorporating signed edges and weights
- Error analysis reveals strengths in handling implicit aggression and role transitions

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Textual and graph representations capture distinct, complementary signals of antisocial behavior
- **Mechanism:** Textual models encode semantic content and pragmatic intent, while graph models encode interactional dynamics and role positioning via directed, signed edges
- **Core assumption:** Antisocial behavior manifests both lexically and structurally
- **Evidence anchors:** Results show multimodal models outperform unimodal baselines; WD-SGCN achieves highest BPI score among unimodal models
- **Break condition:** If abusive intent is decoupled from interaction structure, graph contributions may degrade to noise

### Mechanism 2
- **Claim:** Late fusion effectively leverages modality-specific strengths by ensembling independent predictions
- **Mechanism:** Unimodal classifiers are trained independently, then a meta-classifier combines prediction scores
- **Core assumption:** Decision boundaries for semantic abuse and structural roles are sufficiently distinct
- **Evidence anchors:** Late fusion model mBERT + WD-SGCN achieves best overall results; provides strongest improvements on content- and behavior-oriented tasks
- **Break condition:** If text and graph features are highly correlated, late fusion offers diminishing returns

### Mechanism 3
- **Claim:** Encoding interaction polarity (signed edges) and edge weights into the conversational graph is causally linked to improved identification of social roles
- **Mechanism:** Signed edges distinguish "support" from "hostility" in topology itself, allowing inference of roles based on patterns of incoming/outgoing signed edges
- **Core assumption:** Sentiment of a message accurately reflects polarity of social interaction
- **Evidence anchors:** WD-SGCN integrates direction, polarity, and edge weights, achieving highest BPI score; outperforms unsigned methods on BPI
- **Break condition:** If "neutral" messages are incorrectly mapped to "positive" edges, graph may falsely amplify passive behavior as active support

## Foundational Learning

- **Concept: Signed Graph Convolutional Networks (SGCN)**
  - **Why needed here:** WD-SGCN is a core component; standard GCNs cannot distinguish "bully-victim" from "friend-friend" edges
  - **Quick check question:** How does a Signed GCN propagate messages differently from a standard GCN when encountering a negative edge?

- **Concept: Multimodal Fusion Strategies (Early vs. Late vs. Hybrid)**
  - **Why needed here:** Primary contribution is comparing these strategies; understanding where fusion happens is critical
  - **Quick check question:** Why might "Late Fusion" be more robust than "Early Fusion" when input modalities have vastly different feature dimensions?

- **Concept: Contextualized Embeddings (Transformers/mBERT)**
  - **Why needed here:** Textual analysis relies on mBERT/CamemBERT to capture "implicit aggression" requiring contextual understanding
  - **Quick check question:** In a multi-party chat, does the mBERT model see conversation history or encode messages in isolation?

## Architecture Onboarding

- **Component map:** Data ingestion -> Graph Construction (Sliding Window) -> Parallel Embedding (Text & Graph) -> Late Fusion Meta-Classifier
- **Critical path:** The graph construction step is the most brittle dependency, relying on specific window sizes and sentiment mapping
- **Design tradeoffs:**
  - Early fusion yields slightly better Peer Group Identification but Late fusion offers best overall stability
  - Model trained on role-play data may overfit to "acted" aggression patterns
  - Binary polarity mapping simplifies graph but risks conflating passivity with active support
- **Failure signatures:**
  - Graph models tend to over-detect abuse, misclassifying neutral banter as hostility
  - "Victim Support" is most misclassified role, suggesting struggles to distinguish "defending" from "participating"
  - Pure graph models fail to detect implicit aggression where structure appears benign but content is toxic
- **First 3 experiments:**
  1. Re-run unimodal benchmarks to verify modality gap
  2. Implement Late Fusion mechanism and compare F1 scores against Early Fusion for BPI task
  3. Alter graph construction's sliding window size to test if recent context is sufficient

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Would jointly encoding lexical and structural features in a unified model outperform current fusion strategies?
- **Basis in paper:** More integrated representation learning could be explored by jointly encoding lexical and structural features within a unified model
- **Why unresolved:** Current experiments train text and graph encoders independently before fusion; end-to-end joint optimization remains untested
- **What evidence would resolve it:** Comparative experiments with unified architectures on the same three tasks

### Open Question 2
- **Question:** How well do these multimodal ASB detection methods transfer to naturally occurring conversations across different platforms, languages, and demographics?
- **Basis in paper:** Future work should validate the models on naturally occurring data across more diverse linguistic and cultural settings
- **Why unresolved:** Study relies on simulated role-play data from French-speaking adolescents, which may differ from spontaneous online discourse
- **What evidence would resolve it:** Evaluation on real-world multilingual datasets across diverse age groups and languages

### Open Question 3
- **Question:** Would explicitly modeling neutral interactions as a third edge type in signed graphs improve performance on role-based tasks like BPI?
- **Basis in paper:** Future work should incorporate a third edge type to explicitly represent neutral interactions
- **Why unresolved:** Binary edge polarity conflates passive or ambiguous behavior with active support, potentially obscuring peer-group role distinctions
- **What evidence would resolve it:** Ablation experiments comparing binary vs. ternary edge representations

### Open Question 4
- **Question:** Can incorporating temporal dynamics, user-level history, and conversational context improve detection of subtle or evolving aggression patterns?
- **Basis in paper:** Incorporating richer context, such as temporal dynamics, user-level features, and conversational history, may further enhance detection
- **Why unresolved:** Current models use fixed context windows and encode messages independently without aggregating conversation history
- **What evidence would resolve it:** Experiments adding temporal embeddings, user profiles, and conversation-level attention mechanisms

## Limitations
- Study uses synthetic, role-play dataset rather than authentic user-generated content, limiting ecological validity
- Fixed 21-message sliding window imposes arbitrary context limit that may not generalize
- Mapping of neutral sentiment to positive edges simplifies interaction graph but risks conflating passive participants with active supporters

## Confidence
- **High Confidence**: Multimodal fusion (Late Fusion) outperforms unimodal baselines on abuse detection and overall task balance
- **Medium Confidence**: Graph-based models improve peer group identification due to signed edge modeling
- **Low Confidence**: Performance on implicit aggression detection, as this requires semantic understanding that graph models inherently lack

## Next Checks
1. Validate findings on a real-world cyberbullying dataset to test generalization beyond acted scenarios
2. Experiment with variable sliding window sizes to determine optimal context length for role identification
3. Implement a three-way edge polarity system (positive/neutral/negative) to test if distinguishing passive participants improves BPI accuracy