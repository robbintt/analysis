---
ver: rpa2
title: 'Kinship in Speech: Leveraging Linguistic Relatedness for Zero-Shot TTS in
  Indian Languages'
arxiv_id: '2506.03884'
source_url: https://arxiv.org/abs/2506.03884
tags:
- languages
- language
- speech
- synthesis
- sanskrit
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of building TTS systems for
  low-resource Indian languages that use scripts from one language family but have
  phonotactic properties from another. The authors propose a method that augments
  a shared phone representation (CLS) to cover missing sounds and modifies text parsing
  rules to match the phonotactics of target languages.
---

# Kinship in Speech: Leveraging Linguistic Relatedness for Zero-Shot TTS in Indian Languages

## Quick Facts
- arXiv ID: 2506.03884
- Source URL: https://arxiv.org/abs/2506.03884
- Reference count: 0
- This paper addresses building TTS systems for low-resource Indian languages where scripts and phonotactics diverge from language families.

## Executive Summary
This paper addresses the challenge of building TTS systems for low-resource Indian languages that use scripts from one language family but have phonotactic properties from another. The authors propose a method that augments a shared phone representation (CLS) to cover missing sounds and modifies text parsing rules to match the phonotactics of target languages. This approach enables rapid adaptation without requiring training data in the target language. The method was evaluated on Sanskrit, Maharashtrian and Canara Konkani, Maithili, and Kurukh. Results show significantly improved naturalness (MOS scores up to 4.48), intelligibility (WER as low as 4.6%), and lower Mel-cepstral distortion compared to baseline systems that did not account for linguistic properties.

## Method Summary
The authors propose a zero-shot TTS approach that extends the Common Label Set (CLS) phone representation and modifies text parsing rules based on target language phonotactics rather than script origin. They train monolingual FastSpeech2 models with HiFi-GAN vocoders for Hindi, Kannada, Marathi, and Telugu (10 hours each). For inference on unseen languages, they implement a unified parser that converts text to CLS graphemes and applies family-specific phonological rules (Indo-Aryan vs. Dravidian) based on the target language's phonological behavior. Missing or script-absent phones are mapped to acoustically similar equivalents within CLS. The system then selects the most appropriate monolingual synthesizer based on linguistic overlap criteria including vocabulary, phone set, geographical proximity, and grammatical structures.

## Key Results
- Sanskrit synthesis achieved MOS scores up to 4.12 when using DR rules with Kannada/Telugu models versus 3.25 with IA rules
- Maharashtrian Konkani showed MOS of 3.64 with Marathi synthesizer versus 2.54 with Kannada
- Canara Konkani achieved MOS of 3.34 with Kannada versus 2.31 with Marathi
- Overall WER as low as 4.6% and Mel-cepstral distortion improvements across all tested languages

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Selecting G2P parsing rules based on target language phonotactics, rather than script family, improves zero-shot synthesis quality when scripts and phonotactics diverge.
- Mechanism: The unified parser converts text to CLS representation, then applies family-specific rules (IA with schwa deletion vs. DR with schwa retention) based on target language's phonological behavior, not script origin.
- Core assumption: Phonotactic similarity is a stronger predictor of synthesis quality than script genealogy; acoustic models trained on phonotactically matched languages generalize better.
- Evidence anchors: Sanskrit MOS results (Hindi IA rules = 3.25, Kannada DR rules = 4.12), section 4.3 describing rule application based on phonotactics.
- Break condition: If phonotactics cannot be reliably determined for an unseen language, rule selection becomes speculative and may degrade quality.

### Mechanism 2
- Claim: Mapping missing or script-absent phones to acoustically similar equivalents within CLS enables synthesis of unseen languages without extending acoustic model vocabulary.
- Mechanism: The 72-token CLS is extended through substitution rules (e.g., /q/ → /k/, /ɣ/ → /g/, retroflex flap with nukta → dental flap).
- Core assumption: The acoustic difference between substituted phones is perceptually tolerable for intelligibility and naturalness in zero-shot contexts.
- Evidence anchors: Abstract describing CLS extension, section 4.2 on coverage mapping.
- Break condition: If an unseen language contains phonemically contrastive sounds absent from CLS with no acoustically similar substitute, synthesis quality will degrade.

### Mechanism 3
- Claim: Selecting the monolingual synthesizer based on linguistic overlap (vocabulary, phone set, geographical proximity, grammatical structures) rather than script family yields higher quality zero-shot output.
- Mechanism: After determining IA vs. DR parsing rules, the system selects among available monolingual TTS models by assessing linguistic overlap.
- Core assumption: Acoustic models implicitly encode language-specific prosodic patterns and coarticulation tendencies that transfer better along linguistic similarity dimensions.
- Evidence anchors: Section 4.4 on selection criteria, Konkani dialect results (Maharashtrian Konkani MOS: Marathi = 3.64, Kannada = 2.54).
- Break condition: If no linguistically proximate synthesizer exists, the selection heuristic fails and quality may fall back to a less optimal default.

## Foundational Learning

- **Phonotactics** (language-specific constraints on permissible phone sequences)
  - Why needed here: The core innovation decouples script from phonotactics; understanding schwa deletion (IA) vs. schwa retention (DR) is essential for rule selection.
  - Quick check question: Given that Hindi deletes word-final schwa but Kannada retains it, which rule set should apply to Sanskrit written in Devanagari?

- **Schwa deletion (aka /ə/-deletion or akhand swar deletion)**
  - Why needed here: This is the primary differentiator between IA and DR parsing rules; misapplication causes acoustic mismatches visible in mel spectrograms.
  - Quick check question: In the word "विकास" (vikāsa), would Hindi-based synthesis produce the same final vowel as Kannada-based synthesis?

- **Common Label Set (CLS) as a unified phone inventory**
  - Why needed here: The 72-token CLS enables mapping across 13 scripts; understanding phone clustering (e.g., /q/ → /k/) is necessary for extending to unseen languages.
  - Quick check question: If a target language has a voiceless uvular plosive /q/ but the available synthesizer was trained on CLS without /q/, what is the proposed fallback?

## Architecture Onboarding

- Component map:
  Unified Parser -> CLS Phone Mapper -> Synthesizer Selector -> Monolingual TTS Models (Hindi/Kannada/Marathi/Telugu) -> Mel spectrogram -> Vocoder -> Audio output

- Critical path: Input text (target language script) → CLS grapheme conversion → Phonotactic rule selection (IA vs. DR) → Synthesizer selection → Phone sequence input to acoustic model → Mel spectrogram → Vocoder → Audio output

- Design tradeoffs:
  - Compact CLS (72 tokens) vs. full phone inventory: Smaller inventory enables cross-linguistic sharing but requires phone substitutions that may reduce fidelity.
  - Monolingual models vs. multilingual joint training: Monolingual selection preserves language-specific prosody but requires maintaining multiple models.
  - Rule-based parsing vs. learned G2P: Rule-based approach is interpretable and modifiable but requires linguistic expertise for each new language.

- Failure signatures:
  - Schwa misapplication: Hearable as unexpected vowel insertion or deletion (visible in mel spectrogram as extra/reduced formant transitions).
  - Phone substitution artifacts: Borrowed phonemes rendered with incorrect place of articulation (e.g., uvular /q/ synthesized as velar /k/ may sound "off" to native speakers).
  - Prosodic mismatch: Question sentences sounding like assertions (reported for Kurukh) indicates synthesizer selection or rule mismatch.
  - Glottal stop failures: Kurukh glottal stops not properly synthesized.

- First 3 experiments:
  1. Validate schwa handling: Synthesize the same Sanskrit sentence using Hindi (IA rules) and Kannada (DR rules); verify via mel spectrogram that Kannada output matches ground truth in final vowel retention.
  2. Test CLS phone substitution coverage: Create a minimal test set with nukta characters (क़, ग़, ड़) across Hindi, Marathi, and Kurukh; verify they map correctly to base consonants in CLS output.
  3. Ablate synthesizer selection: For Canara Konkani, synthesize with both Marathi and Kannada systems using identical DR parsing rules; compare MOS and WER to quantify the contribution of linguistic proximity vs. rule matching.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific acoustic artifacts cause the Marathi TTS system to yield higher Mel-cepstral distortion (MCD) scores than the Kannada system for Maharashtrian Konkani, despite the former being linguistically closer?
- Basis in paper: Section 5.5 states the higher MCD score with the Marathi system "can be attributed to artefacts... which needs further investigation."
- Why unresolved: The paper identifies the anomaly where the subjectively preferred system (Marathi) has worse objective spectral distortion than the cross-family system (Kannada), but does not analyze the spectral features or synthesizer behavior causing this.
- What evidence would resolve it: A detailed error analysis of the spectral features or an ablation study isolating the vocoder and acoustic model contributions to distortion in cross-dialect synthesis.

### Open Question 2
- Question: Can the proposed rule-based phonotactic approach be extended to effectively model suprasegmental features, such as intonation differences between questions and assertions?
- Basis in paper: Section 5.3 notes that for Kurukh, "question-type audio sounded more like an assertion for a few sentences, possibly due to unseen context."
- Why unresolved: The current methodology successfully maps segmental phonotactics (e.g., schwa deletion) but lacks an explicit mechanism for handling prosodic variations required for different sentence modalities in zero-shot settings.
- What evidence would resolve it: Integration of intonation modeling into the unified parser and subsequent evaluation of zero-shot synthesis on diverse sentence types (interrogative, imperative) to verify naturalness.

### Open Question 3
- Question: Is the strategy of selecting synthesisers based on script-versus-phonotactics family conflict applicable to non-Indo-Aryan (IA) and non-Dravidian (DR) families like Sino-Tibetan or Austroasiatic?
- Basis in paper: Section 1 and Section 2 mention Sino-Tibetan (e.g., Bodo) and Austroasiatic families, yet the experiments are strictly limited to IA and DR languages.
- Why unresolved: The paper hypothesizes that the Indian subcontinent is a "sprachbund," but validates the method only on the two dominant families; it is unknown if the "linguistic overlap" assumption holds for families with vastly different phonological structures.
- What evidence would resolve it: Application of the proposed CLS augmentation and parsing rules to languages like Bodo or Khasi to determine if intelligible speech can be generated using existing IA or DR synthesisers.

## Limitations

- The paper does not provide specific implementation details of the "Unified Parser" or exact regex/logic for custom phoneme mapping modifications, limiting reproducibility.
- The approach assumes phonotactic similarity is a stronger predictor of synthesis quality than script genealogy, but this assumption needs broader validation across languages with varying degrees of phonotactic divergence.
- The 72-token CLS extension relies on acoustically similar phone substitutions, but the perceptual acceptability of these substitutions for different language pairs is not systematically evaluated.

## Confidence

- High confidence: The CLS phone substitution mechanism (Mechanism 2) and its role in enabling synthesis of languages with missing phones is well-supported by the abstract and implementation details.
- Medium confidence: The phonotactic rule selection (Mechanism 1) is supported by results showing Sanskrit benefits from DR rules, but the underlying assumption about phonotactic similarity's importance needs broader validation.
- Medium confidence: The synthesizer selection heuristic (Mechanism 3) shows promise in the Konkani examples, but lacks direct comparison to alternative selection strategies.

## Next Checks

1. Validate schwa handling: Synthesize the same Sanskrit sentence using Hindi (IA rules) and Kannada (DR rules) models; compare mel spectrograms to verify that Kannada output matches ground truth in final vowel retention, confirming the phonotactic rule selection mechanism works as intended.

2. Test CLS phone substitution coverage: Create a minimal test set with nukta characters (क़, ग़, ड़) across Hindi, Marathi, and Kurukh; verify they map correctly to base consonants in CLS output, validating the phone substitution mechanism's coverage.

3. Ablate synthesizer selection: For Canara Konkani, synthesize with both Marathi and Kannada systems using identical DR parsing rules; compare MOS and WER to quantify the contribution of linguistic proximity versus rule matching in the synthesizer selection heuristic.