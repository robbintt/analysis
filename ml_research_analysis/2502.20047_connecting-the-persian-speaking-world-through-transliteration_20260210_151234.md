---
ver: rpa2
title: Connecting the Persian-speaking World through Transliteration
arxiv_id: '2502.20047'
source_url: https://arxiv.org/abs/2502.20047
tags:
- tajik
- farsi
- transliteration
- written
- persian
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a transformer-based grapheme-to-phoneme approach
  to Tajik-Farsi transliteration, addressing the challenge that Tajik speakers cannot
  read Farsi text due to script differences. The authors compiled novel digraphic
  parallel datasets from blogs, news articles, and dictionaries, then trained a transformer
  model to convert between the Cyrillic-based Tajik script and the Perso-Arabic Farsi
  script.
---

# Connecting the Persian-speaking World through Transliteration

## Quick Facts
- **arXiv ID:** 2502.20047
- **Source URL:** https://arxiv.org/abs/2502.20047
- **Reference count:** 12
- **Primary result:** Transformer-based G2P model achieves chrF++ 58.70 (Farsi→Tajik) and 74.20 (Tajik→Farsi)

## Executive Summary
This paper presents a transformer-based grapheme-to-phoneme approach to Tajik-Farsi transliteration, addressing the challenge that Tajik speakers cannot read Farsi text due to script differences. The authors compiled novel digraphic parallel datasets from blogs, news articles, and dictionaries, then trained a transformer model to convert between the Cyrillic-based Tajik script and the Perso-Arabic Farsi script. Their model achieved chrF++ scores of 58.70 (Farsi to Tajik) and 74.20 (Tajik to Farsi), with the latter excluding the ZWNJ character. Results show the task is significantly more challenging in the Farsi-to-Tajik direction, particularly for vowel prediction and ezafe detection. The study provides both a practical transliteration system and a baseline for future work in connecting Persian-speaking communities through automated script conversion.

## Method Summary
The authors compiled digraphic parallel datasets from blogs, news articles, and dictionaries, then applied Gale-Church alignment to create sentence pairs. They trained separate transformer encoder-decoder models for each transliteration direction using character-level inputs, with 4 encoder/decoder layers, 4 attention heads, and 256 embedding dimensions. The models were trained using 10-fold cross-validation with 80/10/10 splits, and evaluated using chrF++, sequence accuracy, and Levenshtein distance metrics. A key innovation was framing Tajik-Farsi transliteration as a grapheme-to-phoneme conversion problem, leveraging the phonetic nature of Tajik Cyrillic versus the non-phonetic Perso-Arabic Farsi script.

## Key Results
- Farsi-to-Tajik transliteration achieved chrF++ score of 58.70, while Tajik-to-Farsi achieved 74.20 (excluding ZWNJ)
- Vowel prediction F1 score was 0.85 for Farsi→Tajik vs 0.99 for Tajik→Farsi, demonstrating asymmetric difficulty
- Model struggled with ezafe detection, a grammatical feature requiring semantic rather than orthographic context
- ZWNJ character prediction caused significant evaluation noise but minimal comprehension impact

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Treating Tajik-Farsi transliteration as grapheme-to-phoneme (G2P) conversion enables a sequence-to-sequence model to learn the mapping between phonetic and non-phonetic script representations.
- Mechanism: Tajik-Cyrillic is a phonetic alphabet that writes all vowels explicitly, while Perso-Arabic Farsi is an impure abjad that omits many vowels. By framing transliteration as G2P, the model learns to predict phonetic vowel representations from ambiguous or absent orthographic cues, using contextual patterns in the transformer attention mechanism.
- Core assumption: The formal registers of Tajik and Farsi are sufficiently similar that word-level alignment is meaningful; dialectal loanword differences (e.g., "mersi" vs. "rahmat") are manageable noise.
- Evidence anchors: [abstract] "This paper presents a transformer-based G2P approach to Tajik-Farsi transliteration... due to overwhelming similarity between the formal registers"; [Section 1, p.2] "As a pair of non-phonetic and phonetic representations of the same language, transliteration between Tajik and Farsi resembles G2P."; [corpus] Related work on Hindi-Urdu (Durrani et al. 2010) and Kurdish (Ahmadi 2019) applies similar approaches to digraphic language pairs, suggesting transferability.
- Break condition: If dialectal divergence exceeds training data coverage (e.g., Russian loanwords in colloquial Tajik without Farsi equivalents), the G2P assumption degrades.

### Mechanism 2
- Claim: Transformer attention captures long-range dependencies needed for vowel prediction and ezafe detection, which require semantic rather than purely orthographic context.
- Mechanism: The encoder-decoder transformer with 4 layers and multi-head attention learns character-level correspondences while building contextual representations. Self-attention allows the model to consider surrounding characters when disambiguating multi-mapping characters (e.g., alef mapping to о, и, у, or ӯ depending on context).
- Core assumption: Character-level training with ~406K+ word tokens provides sufficient signal for the model to learn contextual disambiguation rules that are implicitly known to native readers.
- Evidence anchors: [Section 7.1, p.13] "The transformer architecture consists of 4 encoder and decoder layers, with four parallel attention layers."; [Section 8.2, p.14-15] Results show weighted F1 of 0.85 for vowel prediction (Farsi→Tajik) vs. 0.99 (Tajik→Farsi), demonstrating asymmetric difficulty in predicting omitted vowels.; [corpus] Weak direct evidence for transformer superiority over RNNs for this specific task; paper cites Yolchuyeva et al. (2019) for G2P transformer success in other languages.
- Break condition: If training data lacks sufficient examples of ambiguous vowel contexts, the model cannot learn disambiguation and defaults to frequent mappings.

### Mechanism 3
- Claim: Directional asymmetry in transliteration difficulty (Tajik→Farsi easier than Farsi→Tajik) stems from information loss in the Perso-Arabic abjad that cannot be deterministically recovered.
- Mechanism: Tajik-Cyrillic explicitly encodes all phonological information, making Tajik→Farsi a mostly one-to-many generation task (e.g., /z/ → ز, ذ, ض, ظ). Conversely, Farsi→Tajik requires many-to-one disambiguation with missing vowel information, requiring inference from context that may be ambiguous.
- Core assumption: Incorrect consonant mapping (e.g., choosing ز over ذ) causes minimal comprehension loss for native readers, as claimed by the authors.
- Evidence anchors: [Section 8.2, p.14] "Tajik-to-Farsi transliteration than Farsi-to-Tajik across all metrics... chrF++ scores of 58.70 and 74.20."; [Section 3.1.1, p.4-5] Tables 2-6 document multi-mapping characters: alef, vav, ye, he, ayn each map to multiple Tajik vowels.; [Section 3.3, p.6-8] Ezafe is omitted in Farsi but explicitly written in Tajik, requiring semantic inference for Farsi→Tajik.; [corpus] No external validation of the comprehension-impact claim; relies on author linguistic expertise.
- Break condition: If downstream applications require precise vowel reconstruction (e.g., poetry recitation or TTS), the Farsi→Tajik direction's 0.85 vowel F1 may be insufficient.

## Foundational Learning

- Concept: **Abjad vs. Alphabet Orthographies**
  - Why needed here: The core challenge stems from Farsi being an impure abjad (vowels often unwritten) while Tajik-Cyrillic is a phonetic alphabet. Understanding this asymmetry explains why Farsi→Tajik is harder.
  - Quick check question: Given the Farsi word ﮔﺮﺩ without diacritics, can you identify the three possible Tajik transliterations and pronunciations?

- Concept: **Persian Ezafe (Izofat)**
  - Why needed here: The ezafe is an unwritten grammatical affix in Farsi that links modifiers to nouns. Correct Farsi→Tajik transliteration requires detecting its presence from semantic context, which the current model struggles with.
  - Quick check question: In the phrase ﺧﺎﻧﻪﺯﯿﺒﺎ ("beautiful house"), where does the ezafe occur in speech, and how would it be written in Tajik?

- Concept: **chrF++ Evaluation Metric**
  - Why needed here: The paper uses chrF++ (character n-gram F-score with word bigrams) as the primary metric because it better captures character-level transliteration quality than BLEU, which is designed for word-level translation.
  - Quick check question: Why would character-level metrics be more appropriate than word-level accuracy for evaluating transliteration between scripts with different word segmentation conventions?

## Architecture Onboarding

- Component map: Data sources (blogs, news, dictionaries) -> Gale-Church alignment -> Character-level normalization -> Transformer encoder-decoder -> 10-fold cross-validation -> chrF++ evaluation

- Critical path:
  1. Source digraphic data from blogs, BBC articles, dictionaries (Tables 10-11)
  2. Sentence-align using Gale-Church algorithm
  3. Normalize: remove punctuation/numbers, standardize ZWNJ usage for affixes
  4. Train separate models for each direction with identical hyperparameters
  5. Evaluate with ZWNJ included and excluded (ZWNJ is invisible and semantically trivial)

- Design tradeoffs:
  - ZWNJ handling: Including ZWNJ in Tajik→Farsi evaluation drops sequence accuracy from 50.46% to 34.37%, but ZWNJ errors don't affect comprehension
  - Dataset mixing: Combining dictionary, prose, and poetry introduces domain variation but may add noise from inconsistent alignments
  - Character vs. subword: Character-level operation handles arbitrary words but may miss morphological patterns that subword tokens would capture

- Failure signatures:
  - Vowel prediction errors (Farsi→Tajik): Word-final he (ﻩ) often mistransliterated despite high-frequency prepositions (به, که)
  - Ezafe omission: Model fails to insert -и in Tajik output where Farsi omits ezafe, changing phrasal boundaries
  - "va" conjunction ambiguity: Farsi ﻭ maps to both independent ва and enclitic -у, creating multiple valid transliterations that confuse evaluation
  - Glottal stop inconsistency: Character ъ appears/disappears unpredictably relative to Farsi ﻉ

- First 3 experiments:
  1. Baseline reproduction: Train the 4-layer transformer on the combined corpus (Tables 10-11) with ZWNJ excluded from evaluation; verify chrF++ ≈ 74 (Tajik→Farsi) and ≈ 59 (Farsi→Tajik)
  2. Ezafe augmentation: Integrate the Etezadi et al. (2022) ezafe detection tool as a preprocessing step for Farsi→Tajik; measure improvement in vowel F1 and sequence accuracy
  3. Ablation on data sources: Train separate models on (a) blogs/news only, (b) dictionary only, (c) combined; compare chrF++ to quantify domain mixing effects and identify whether poetry (longer sentences, archaic forms) helps or hurts

## Open Questions the Paper Calls Out

- Can incorporating explicit semantic context or pre-trained language models significantly improve the detection and transliteration of the Persian Ezafe? The authors state that "our future work will focus on... Ezafe detection" and note that the current model "failed to predict" this feature, which is only determined by semantic rather than orthographic context.

- To what extent does rigorous native-speaker verification of the parallel corpus improve model accuracy? The authors acknowledge that "both datasets have not undergone in-depth analysis from native speakers and therefore may occasionally contain incorrect correspondences," and explicitly state that creating a verified dataset "presents another avenue for research."

- How do Large Language Models (LLMs) compare to standard transformer-based G2P models in handling context-dependent ambiguities like the conjunction "va"? The authors mention in a footnote that they are "aware that LLMs could also be utilized for this task" but elected not to use them. Furthermore, the results show the model struggles to distinguish between the independent "va" and the enclitic "-u" because they are written identically in Farsi.

## Limitations
- The Farsi-to-Tajik model shows significantly lower performance (chrF++ 58.70) than Tajik-to-Farsi (chrF++ 74.20), creating a 15.5-point gap that may indicate insufficient contextual training data
- The model consistently fails to detect and transliterate ezafe, a critical grammatical feature that links modifiers to nouns in Persian
- The use of Gale-Church alignment on web-crawled data may introduce alignment errors, particularly in poetry where word order differs from prose

## Confidence
- **High Confidence (90-100%)**: The transformer architecture and training procedure are clearly specified and reproducible; the chrF++ scores and directional asymmetry are well-documented and internally consistent; the core insight that Tajik-Farsi transliteration resembles G2P conversion due to orthographic differences is linguistically sound
- **Medium Confidence (60-80%)**: The claim that consonant mapping errors (ز vs ذ) don't affect comprehension relies on linguistic expertise but lacks empirical validation with native speakers; the characterization of ezafe detection as a "future improvement" suggests the current approach is incomplete but functional for basic script conversion; the dataset mixing (dictionary + prose + poetry) may improve robustness but could also introduce domain-specific artifacts
- **Low Confidence (0-50%)**: The exact impact of ZWNJ handling on downstream comprehension is not empirically validated; the comparison to Hindi-Urdu and Kurdish transliteration work provides theoretical support but doesn't directly validate the specific transformer configuration

## Next Checks
1. **Ezade Detection Integration**: Implement the Etezadi et al. (2022) ezafe detection tool as a preprocessing step for Farsi→Tajik transliteration. Measure improvements in vowel F1 score and sequence accuracy, and assess whether this addresses the most significant grammatical gap in current outputs.

2. **Directional Ablation Study**: Train separate models on (a) dictionary-only data, (b) news/blog-only data, and (c) poetry-only data for both transliteration directions. Compare chrF++ scores to identify whether the 15.5-point gap is consistent across domains, and whether poetry's syntactic flexibility helps or hurts the more challenging Farsi→Tajik direction.

3. **Native Speaker Comprehension Test**: Conduct a controlled evaluation where native Tajik speakers rate comprehension of model-generated Tajik text from Farsi input, comparing correctly vowel-predicted words versus words with vowel errors. This would empirically validate the claim that consonant mapping errors have minimal comprehension impact.