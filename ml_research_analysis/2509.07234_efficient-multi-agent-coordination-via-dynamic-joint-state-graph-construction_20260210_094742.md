---
ver: rpa2
title: Efficient Multi-Agent Coordination via Dynamic Joint-State Graph Construction
arxiv_id: '2509.07234'
source_url: https://arxiv.org/abs/2509.07234
tags:
- support
- coordination
- problem
- cost
- robot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Dynamic Homogeneous Joint-State Graph (Dynamic-HJSG)
  for solving the NP-hard Team Coordination on Graphs with Risky Edges (TCGRE) problem,
  where agents coordinate to reduce traversal costs on high-risk edges. The core method
  dynamically constructs a joint-state graph during graph search, leveraging agent
  homogeneity to prune redundant states and reduce computational overhead.
---

# Efficient Multi-Agent Coordination via Dynamic Joint-State Graph Construction

## Quick Facts
- arXiv ID: 2509.07234
- Source URL: https://arxiv.org/abs/2509.07234
- Authors: Yanlin Zhou; Manshi Limbu; Xuesu Xiao
- Reference count: 27
- This paper introduces Dynamic Homogeneous Joint-State Graph (Dynamic-HJSG) for solving the NP-hard Team Coordination on Graphs with Risky Edges (TCGRE) problem, where agents coordinate to reduce traversal costs on high-risk edges.

## Executive Summary
This paper addresses the NP-hard problem of coordinating multiple agents on graphs with risky edges, where traversal costs can be reduced through coordinated support. The proposed Dynamic Homogeneous Joint-State Graph (Dynamic-HJSG) algorithm dynamically constructs a joint-state graph during search, leveraging agent homogeneity to prune redundant states and reduce computational overhead. The method achieves near-polynomial scaling while preserving optimality, significantly outperforming baseline approaches in empirical evaluations on graphs with 6-15 nodes and teams of 2-6 agents.

## Method Summary
Dynamic-HJSG solves the Team Coordination on Graphs with Risky Edges (TCGRE) problem by constructing a simplified graph containing only special nodes (start/goal locations, risky edge endpoints, and support nodes) connected by "super edges" representing precomputed shortest paths. The algorithm then performs a Dijkstra-like search on a dynamically constructed joint-state graph, where each state represents the locations of all agents. The key innovation is limiting transitions to at most two agents moving simultaneously, which preserves optimality while drastically reducing the search space. For each transition, the algorithm computes the cost by solving a maximum weighted bipartite matching problem to optimally pair traversing agents with support nodes.

## Key Results
- Dynamic-HJSG achieves sub-second median runtime across all team sizes tested
- Algorithm completes 98% of runs within 60 seconds timeout
- Significant performance improvement over baseline methods (JSG, CES, HCES)
- Near-polynomial scaling observed on random, grid, and Voronoi graphs

## Why This Works (Mechanism)

### Mechanism 1
Restricting joint-state transitions to at most two agents moving simultaneously preserves optimality while drastically reducing the search space. The algorithm builds a joint-state graph where each state represents the locations of all agents. The key innovation is limiting the transitions from a joint-state: a neighbor state is only generated if at most two agents change their location. This constraint directly encodes the fact that coordination (support) is a pairwise interaction (one agent on a support node, one traversing a risky edge). By pruning transitions where three or more agents move, it eliminates a combinatorial explosion of possibilities without discarding any potential optimal coordination sequences, which can be decomposed into pairwise steps.

### Mechanism 2
A simplified graph with "super nodes" and "super edges" abstracts away irrelevant traversal details, allowing the planner to focus solely on coordination decisions. The original graph is transformed into a smaller graph Gs where nodes are only the start/goal locations, risky edge endpoints, and support nodes. The edges of Gs ("super edges") represent the precomputed shortest paths between these special locations in the original graph. This ensures that the planner's search only needs to consider states and transitions where coordination is possible, treating all other movement as a solved, cost-known subproblem.

### Mechanism 3
Incremental goal satisfaction reduces problem dimensionality during the search. As agents reach their goal locations, they are removed from the active joint-state representation. The priority queue `pq` in the search algorithm tracks the remaining agents. This means the "joint state" shrinks in dimensionality as the search progresses towards its final goal state (which is empty), reducing the branching factor for the latter parts of the search.

## Foundational Learning

- Concept: **Joint-State Space**
  - Why needed here: The core algorithmic leap is transforming a multi-agent problem into a single-agent graph search. Understanding that a "joint state" is simply a tuple of all agents' locations (e.g., (A1_pos, A2_pos, A3_pos)) is fundamental.
  - Quick check question: If there are 3 agents on a graph with 10 nodes, what is the maximum possible size of the joint-state space?

- Concept: **Maximum Weighted Bipartite Matching**
  - Why needed here: This is the subroutine used to calculate the cost of a transition between joint states. It models the assignment problem of "which supporting agent should help which traversing agent?" to maximize the total cost reduction.
  - Quick check question: In a transition where Agent A is on a support node and Agent B is traversing a risky edge, how would you formulate this as a bipartite matching problem?

- Concept: **NP-Hardness & Reduction**
  - Why needed here: The paper proves TCGRE is NP-hard by reducing it to Minimum 3D Matching. This theoretical grounding justifies the use of advanced decomposition and pruning techniques instead of naive search.
  - Quick check question: What does it mean to "reduce" Problem A to Problem B, and what does that imply about their relative complexity?

## Architecture Onboarding

- Component map: Graph Preprocessor -> Joint-State Manager -> Edge Cost Oracle -> Search Core -> Solution Reconstructor
- Critical path:
  1. Run Graph Preprocessor to get Gs.
  2. Initialize Search Core with the starting joint state V0.
  3. In the main loop, pop the lowest-cost state JS_i.
  4. Check if JS_i is the goal (empty). If yes, reconstruct and finish.
  5. Ask Joint-State Manager for neighbors of JS_i.
  6. For each neighbor, query Edge Cost Oracle for the transition cost.
  7. Update `dist` and `prev` maps, and push new states to `pq`.
  8. Repeat.

- Design tradeoffs:
  - **Completeness vs. Scalability**: The 2-agent move constraint is a deliberate tradeoff to achieve scalability (polynomial in practice) while preserving optimality for the defined problem. A full k-agent transition model would be more general but computationally explosive.
  - **Dynamic vs. Static Graph**: Constructing the graph on-the-fly (dynamically) saves memory but means edge costs must be computed repeatedly. The "simplified graph" precomputation amortizes some of this cost.

- Failure signatures:
  - **Timeout**: Indicates the joint-state space is too large, potentially due to many agents or a high number of special nodes in Gs.
  - **Suboptimal Path**: Could arise from an incorrect implementation of the bipartite matching or a violation of the transition constraints.
  - **Empty Path Returned**: Suggests the goal state is unreachable from the start, possibly due to a disconnected Gs or incorrect state generation logic.

- First 3 experiments:
  1. **Scalability Benchmark**: Run Dynamic-HJSG on the provided random, grid, and Voronoi graphs (6-15 nodes, 2-6 agents). Measure and plot median runtime vs. team size to verify the near-polynomial scaling claimed in Fig. 3.
  2. **Ablation on Transition Constraint**: Implement a variant allowing up to 3 agents to move simultaneously. Compare its runtime and solution quality to the default 2-agent version on small problems to empirically test the break condition.
  3. **Vary Graph Complexity**: Test performance while systematically increasing the ratio of risky edges. This will stress the Edge Cost Oracle and reveal how coordination density affects the overall search.

## Open Questions the Paper Calls Out

### Open Question 1
How does the scalability of Dynamic-HJSG degrade when applied to heterogeneous agents with different movement costs or capabilities, where homogeneity-based state pruning is no longer valid? The algorithm is explicitly named "Homogeneous" and utilizes "agent homogeneity to prune redundant states," but does not address cases where agents are non-interchangeable.

### Open Question 2
Can Dynamic-HJSG be effectively integrated into standard Multi-Agent Path Finding (MAPF) solvers to handle collision avoidance, and does the "risky edge" framework offer computational advantages over conflict-based search? The Conclusion lists "Integration Potential" as a future direction, stating the algorithm can be "integrated as a post-processing refinement for mapf plans... or as a complete solver."

### Open Question 3
How does the algorithm's performance scale with an increasing number of support nodes per risky edge, given that experiments were limited to a single support node per edge? The experiments section states that support node number is fixed at 1, which means each risky edge has 1 support node, avoiding the complexity of multiple support options.

## Limitations

- Theoretical analysis is rigorous but limited to the defined problem and small problem sizes
- Empirical evaluation covers only small graphs (6-15 nodes) and teams (2-6 agents)
- Algorithm's performance depends on static shortest paths between special nodes, which may not hold in dynamic environments
- The 2-agent transition constraint may exclude optimal solutions in scenarios requiring simultaneous multi-agent coordination

## Confidence

- **Dynamic-HJSG's polynomial complexity**: Medium confidence. Theoretical justification exists, but empirical evidence is limited to small problem sizes.
- **Preservation of optimality**: High confidence. The 2-agent transition constraint is formally proven sufficient for optimal solutions in the defined problem.
- **Empirical scalability**: Low confidence. Results show strong performance on small instances but do not establish behavior on larger, more complex problems.

## Next Checks

1. **Stress Test the Transition Constraint**: Systematically increase the number of agents and risky edges in test instances. Monitor whether Dynamic-HJSG maintains its performance advantage over baseline methods, and whether the 2-agent move constraint ever excludes optimal solutions in practice.

2. **Evaluate on Dynamic Graphs**: Introduce dynamic edge costs or support node availability to test the algorithm's assumptions about static shortest paths. Measure performance degradation and compare against algorithms designed for dynamic environments.

3. **Compare with State-of-the-Art MAPF Solvers**: Benchmark Dynamic-HJSG against modern MAPF solvers on standard coordination problems (e.g., conflict-based search, prioritized planning). This will contextualize its performance relative to the broader field, beyond the paper's chosen baselines.