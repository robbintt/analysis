---
ver: rpa2
title: Integrated Simulation Framework for Adversarial Attacks on Autonomous Vehicles
arxiv_id: '2509.05332'
source_url: https://arxiv.org/abs/2509.05332
tags:
- adversarial
- point
- simulation
- attacks
- attack
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents an open-source integrated simulation framework
  for generating adversarial attacks on autonomous vehicles, targeting both perception
  and communication layers. The framework combines CARLA, SUMO, and Artery simulators,
  orchestrated via a unified core that supports LiDAR-based attacks (perturbation,
  detachment, and attachment) and communication-level threats such as V2X message
  manipulation and GPS spoofing.
---

# Integrated Simulation Framework for Adversarial Attacks on Autonomous Vehicles

## Quick Facts
- **arXiv ID**: 2509.05332
- **Source URL**: https://arxiv.org/abs/2509.05332
- **Reference count**: 23
- **Primary result**: Open-source framework combining CARLA, SUMO, and Artery to generate multi-domain adversarial attacks on AV perception and communication layers

## Executive Summary
This paper presents an integrated simulation framework for generating adversarial attacks on autonomous vehicles, targeting both perception and communication layers. The framework combines CARLA, SUMO, and Artery simulators, orchestrated via a unified core that supports LiDAR-based attacks (perturbation, detachment, and attachment) and communication-level threats such as V2X message manipulation and GPS spoofing. ROS 2 integration ensures compatibility with third-party AV software stacks. Evaluation using a state-of-the-art 3D object detector (SECOND) shows significant performance degradation under realistic adversarial conditions, with mAP ratios dropping to as low as 73.20% for point perturbation attacks while maintaining low perceptual distortion.

## Method Summary
The framework orchestrates CARLA (physics/sensors), SUMO (traffic/TraCI), and Artery (V2X/master clock) through a unified Simulation Logic Core. LiDAR-based attacks use gradient-guided perturbation, saliency-based point removal/injection, and optimization constrained by perceptual similarity metrics. Communication attacks manipulate V2X messages and GPS signals through virtual sensor integration. ROS 2 bridges enable live integration with AV software stacks, while standard formats support offline evaluation. The system generates 3,000 frames of CARLA Town06 data with 64-channel LiDAR point clouds for testing against the SECOND 3D object detector.

## Key Results
- Point perturbation attack achieves mAP ratio of 73.20% with Chamfer Distance of 0.01533 at ε=10cm
- Point detachment (1% removal) yields mAP ratio of 91.77% with CD=0.07035
- Point attachment (300 points) achieves mAP ratio of 78.46% with CD=0.00126

## Why This Works (Mechanism)

### Mechanism 1: Unified Simulator Orchestration via Master-Slave Synchronization
- **Core assumption**: Network and physics simulation fidelity is sufficient to reveal real-world vulnerabilities; clock synchronization accuracy is adequate for attack timing precision
- **Evidence anchors**: Abstract states orchestration through unified core synchronizing multiple simulators; Section II-B describes Artery as master clock with SUMO/CARLA as synchronized slaves; corpus validates multi-simulator synchronization for imperfect communication scenarios
- **Break condition**: If clock skew between simulators exceeds attack temporal precision requirements, adversarial effects may misattribute to timing rather than attack design

### Mechanism 2: Gradient-Guided LiDAR Point Cloud Perturbation
- **Core assumption**: White-box access to detector gradients is available; adversarial points remain physically realizable
- **Evidence anchors**: Section III-A1 details PGD optimization with ℓ₂-ball projection and dual-objective loss; Section IV-C/Table I shows perturbation attack achieves lowest mAP ratio (73.20%) with moderate CD (0.01533) at ε=10cm; corpus confirms LiDAR spoofing transfers to safety controller failures
- **Break condition**: If detectors employ gradient masking or randomized smoothing, gradient-based perturbation efficacy degrades

### Mechanism 3: Saliency-Based Point Removal and Injection
- **Core assumption**: Saliency maps generalize across frames and do not overfit to specific point cloud instances; injected points avoid physical implausibility checks
- **Evidence anchors**: Section III-A2/3 defines saliency score as gradient magnitude and describes iterative removal/injection; Section IV-C/Table II shows removing 1% yields mAP ratio 91.77% (CD=0.07035); attaching 300 points yields 78.46% (CD=0.00126); corpus lacks direct saliency-based attack comparisons
- **Break condition**: If detectors use multi-view fusion or temporal aggregation, single-frame saliency attacks may be mitigated

## Foundational Learning

- **Projected Gradient Descent (PGD) for Point Clouds**
  - Why needed here: The perturbation attack mechanism relies on iterative gradient-based optimization constrained to an ℓ₂-ball
  - Quick check question: Can you explain why projecting perturbations onto an ℓ₂-ball preserves geometric similarity while maximizing detection loss?

- **V2X Communication Protocols (ETSI ITS-G5, CAMs)**
  - Why needed here: Communication-level attacks target Cooperative Awareness Messages; understanding message structure is required to manipulate positions/velocities plausibly
  - Quick check question: What fields in a CAM would an attacker modify to execute a fake position attack without triggering standard consistency checks?

- **Chamfer Distance as Perceptual Metric**
  - Why needed here: Quantifies adversarial stealthiness; low CD indicates perturbations are imperceptible to human operators or downstream systems
  - Quick check question: Why is symmetric Chamfer Distance (bi-directional nearest-neighbor matching) preferred over one-sided metrics for adversarial similarity assessment?

## Architecture Onboarding

- **Component map**: Simulator Stack (CARLA ↔ SUMO ↔ Artery) → Simulation Logic Core (Scenario Parser → Orchestration Module → Attack Generation Module) → ROS 2 Bridge (CARLA-ROS bridge + virtual V2X sensor) → Output (Local storage OR ROS 2 messages)

- **Critical path**: 1. Define scenario in single configuration file 2. SLC initializes all simulators, establishes TraCI connections 3. Main loop: Artery advances clock → SUMO steps → CARLA syncs → Attack module injects perturbations/spoofed messages 4. Sensor data streamed to ROS 2 or stored for offline evaluation

- **Design tradeoffs**: SUMO-driven vs. CARLA-driven (SUMO excels at traffic flow realism; CARLA enables sensor-rich ego-vehicle scenarios); White-box vs. black-box attacks (PGD requires model gradients; random bias is gradient-free but less effective); Attack stealth vs. impact (lower ε yields higher mAP ratio but better imperceptibility)

- **Failure signatures**: Clock desynchronization manifests as inconsistent vehicle positions across simulators; Excessive perturbation (ε > 10cm) produces unrealistic point clouds detectable by anomaly detectors; V2X attacks fail if CAM frequency mismatches Artery emission rate

- **First 3 experiments**: 1. Replicate baseline perturbation attack: Set ε=10cm, 40 PGD steps, measure mAP ratio and CD on SECOND detector using Town06 dataset 2. Ablate attack types: Compare perturbation vs. detachment (1% removal) vs. attachment (300 points) on same frames to isolate mechanism contributions 3. Validate communication attack: Implement Sybil attack via Artery virtual nodes, verify ghost vehicles appear in LDM published to ROS 2

## Open Questions the Paper Calls Out

- **Open Question 1**: How can the framework be extended to effectively support and generate 2D (camera-based) adversarial attacks? (Conclusion states future work includes extending 2D attack support)
- **Open Question 2**: Can the framework be evolved to automatically suggest mitigation strategies for the vulnerabilities it identifies? (Conclusion notes future work involves developing a perception evaluation platform that computes vulnerability scores and suggests mitigation strategies)
- **Open Question 3**: What is the quantitative impact of the implemented communication-level attacks (e.g., GPS spoofing, Sybil) on downstream AV tasks? (Evaluation section strictly reports metrics for LiDAR-based perception attacks, though system architecture supports V2X and GPS attacks)

## Limitations
- Simulator orchestration fidelity and attack transferability remain unproven, with no empirical validation of clock skew bounds or physical-world attack efficacy
- White-box PGD attack assumptions may not hold against real-world detectors employing gradient masking or randomized smoothing defenses
- Simulation-to-reality gap unquantified: point cloud perturbations optimized in CARLA may not transfer to physical LiDAR due to calibration, noise, and environmental factors

## Confidence

- **High**: Simulator orchestration architecture, baseline attack implementation (Perturbation, Detachment, Attachment), and ROS 2 integration pipeline
- **Medium**: Attack effectiveness metrics (mAP ratio, CD) on SECOND detector, communication attack feasibility (V2X spoofing, Sybil)
- **Low**: Physical-world attack transferability, detector robustness under gradient-based defenses, simulator fidelity for adversarial scenarios

## Next Checks

1. **Clock Drift Analysis**: Measure and report maximum temporal desynchronization between Artery, SUMO, and CARLA over extended simulations; verify attack timing precision requirements are met
2. **Black-Box Attack Implementation**: Implement gradient-free attack variants (e.g., random bias, evolutionary strategies) and compare effectiveness against PGD to assess defense robustness
3. **Cross-Detector Transferability**: Evaluate attack efficacy on a second 3D object detector (e.g., PointPillars) to determine if adversarial examples generalize beyond SECOND