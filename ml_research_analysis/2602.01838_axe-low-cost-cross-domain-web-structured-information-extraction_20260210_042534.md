---
ver: rpa2
title: 'AXE: Low-Cost Cross-Domain Web Structured Information Extraction'
arxiv_id: '2602.01838'
source_url: https://arxiv.org/abs/2602.01838
tags:
- html
- text
- page
- context
- extraction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: AXE introduces a low-cost, zero-shot web information extraction
  pipeline that treats the HTML DOM as a tree to be pruned rather than a wall of text
  to be read. By stripping away boilerplate and irrelevant nodes, it distills the
  page into a high-density context that a tiny 0.6B LLM can process efficiently.
---

# AXE: Low-Cost Cross-Domain Web Structured Information Extraction

## Quick Facts
- **arXiv ID**: 2602.01838
- **Source URL**: https://arxiv.org/abs/2602.01838
- **Reference count**: 40
- **Primary result**: 0.6B model achieves 88.1% F1 on SWDE zero-shot, outperforming much larger supervised baselines

## Executive Summary
AXE introduces a low-cost, zero-shot web information extraction pipeline that treats the HTML DOM as a tree to be pruned rather than a wall of text to be read. By stripping away boilerplate and irrelevant nodes, it distills the page into a high-density context that a tiny 0.6B LLM can process efficiently. Grounded XPath Resolution ensures every extracted value is traceable to its source node, preventing hallucinations. On the SWDE dataset, AXE achieves state-of-the-art zero-shot F1 of 88.1%, outperforming much larger, fully-trained models while reducing average token context by 97.9% (from ~16.6K to ~350 tokens). Ablation studies confirm the critical role of pruning, fine-tuning, and grounding in its performance.

## Method Summary
AXE is a three-stage pipeline: (1) Preprocessor cleans HTML and chunks it into manageable segments; (2) AI Extractor uses a tiny 0.6B LLM with specialized LoRA adapters (Pruner, Extractor, QA) to select relevant content and answer extraction queries; (3) Postprocessor applies Grounded XPath Resolution to ensure all outputs are traceable to actual DOM nodes. The system is trained on synthetic data generated by a 480B teacher model, enabling zero-shot performance without in-domain fine-tuning. Key innovations include query-conditioned DOM pruning, post-hoc structural grounding, and lightweight adapter specialization.

## Key Results
- Achieves 88.1% F1 on SWDE zero-shot, outperforming larger supervised models
- Reduces token context by 97.9% (from ~16.6K to ~350 tokens) through aggressive pruning
- Removes hallucination risk via Grounded XPath Resolution, with 4.42% F1 drop when disabled
- 0.6B model with LoRA adapters matches or exceeds performance of much larger models

## Why This Works (Mechanism)

### Mechanism 1: Query-Conditioned DOM Pruning
- Claim: Aggressive HTML pruning reduces token context by ~98% while preserving task-relevant information.
- Mechanism: The Pruner adapter receives chunked HTML nodes with XPath metadata and outputs indices of relevant chunks. This transforms the extraction problem from "read entire page" to "read distilled semantic core."
- Core assumption: Most HTML tokens are boilerplate unrelated to user queries; relevant content clusters in structural nodes.
- Evidence anchors:
  - [abstract] "stripping away boilerplate and irrelevant nodes, it distills the page into a high-density context"
  - [section 4.3] Table 4 shows token reduction from 16,581 to 350.6 (97.9%)
  - [corpus] Weak direct validation; related work (HTMLRAG, Dripper) uses additive selection rather than pruning, suggesting this approach is relatively novel
- Break condition: If queries require cross-node reasoning spanning distant DOM branches, over-aggressive pruning could sever contextual dependencies.

### Mechanism 2: Grounded XPath Resolution (GXR)
- Claim: Post-hoc structural grounding reduces hallucination by constraining outputs to physically present nodes.
- Mechanism: After LLM generation, GXR searches the DOM tree using lexical overlap + fuzzy semantic matching to find the best-matching node, then resolves its absolute XPath. This converts generation → retrieval.
- Core assumption: Hallucinations in small LLMs are more likely to be ungrounded text than grounded-but-wrong nodes.
- Evidence anchors:
  - [abstract] "ensuring every extracted value is traceable to its source node, preventing hallucinations"
  - [section 4.4.1] Removing GXR drops F1 by 4.42% (88.37% → 83.95%)
  - [corpus] No direct corpus validation; this grounding approach appears specific to AXE
- Break condition: If the LLM generates a correct semantic answer that doesn't verbatim-match any DOM node (e.g., synthesized summaries), GXR will reject or misattribute it.

### Mechanism 3: Task-Specialized LoRA Adapters
- Claim: Lightweight adapters (≈40M parameters) distilled from a 480B teacher enable a 0.6B model to outperform larger supervised baselines.
- Mechanism: Three adapters—Pruner, QA, Schema Extraction—are trained via knowledge distillation on synthetic data generated by Qwen3-Coder-480B. rsLoRA with rank-64 provides stable fine-tuning.
- Core assumption: The teacher model's extraction reasoning can be compressed into the student without catastrophic loss; synthetic data quality is sufficient.
- Evidence anchors:
  - [section 3.3] "We used Qwen3-Coder-480B-A35B-Instruct as a teacher model to create synthetic schemas"
  - [section 4.4.1] Removing adapters drops F1 by 4.86%
  - [corpus] Weak validation; related work doesn't report comparable distillation-to-tiny-model results
- Break condition: If deployment domains diverge significantly from synthetic training distribution, adapter specialization may become a liability rather than asset.

## Foundational Learning

- Concept: **XPath and DOM Tree Structure**
  - Why needed here: AXE's pruning operates on XPath-addressable nodes; GXR returns XPaths as grounded outputs. Understanding tree traversal is essential for debugging.
  - Quick check question: Given `<div><span id="x">text</span></div>`, what is the absolute XPath to "text"?

- Concept: **LoRA (Low-Rank Adaptation)**
  - Why needed here: All three adapters use LoRA fine-tuning. Understanding rank, alpha, and target modules helps diagnose adapter quality.
  - Quick check question: If LoRA rank is 64 and target modules are "all linear," approximately how many trainable parameters does this add to a 0.6B model?

- Concept: **Knowledge Distillation**
  - Why needed here: Synthetic training data is generated by a 480B teacher. Understanding teacher-student dynamics helps assess data quality risks.
  - Quick check question: What failure mode occurs when student model capacity is insufficient to capture teacher reasoning?

## Architecture Onboarding

- Component map:
  - Preprocessor: Noise removal → HTMLRAG lossless cleaning → AutoChunker
  - AI Extractor: Mini-chunker → Pruner (selects XPath indices) → Merge → Extractor (QA or Schema adapter)
  - Postprocessor: GXR (lexical + fuzzy match → XPath resolution)

- Critical path: Raw HTML → Pruned HTML (350 tokens avg) → LLM generation → Grounded XPath. The pruning stage is the efficiency bottleneck; GXR is the accuracy bottleneck.

- Design tradeoffs:
  - Chunk size vs. context: Larger chunks (3000-4000 tokens) improve F1 but reduce pruning efficiency (Figure 5)
  - Adapter specialization vs. generality: QA adapter trained on 15k WebSRC samples; may overfit to that format
  - GXR precision vs. recall: Strict grounding prevents hallucinations but may reject valid paraphrased answers

- Failure signatures:
  - Empty extractions: Pruner may have over-pruned; check chunk selection indices
  - Wrong XPath attribution: GXR fuzzy match found wrong node; inspect lexical overlap scores
  - JSON parse errors: Extractor output malformed; verify adapter was loaded correctly

- First 3 experiments:
  1. **Pruning sensitivity**: Run AXE on 10 diverse pages with/without pruner; measure token count vs. F1 delta to quantify the efficiency-accuracy tradeoff.
  2. **GXR ablation**: Disable GXR and compare raw LLM output vs. grounded output on a held-out schema; count hallucination rate.
  3. **Domain shift test**: Apply to a vertical not in SWDE (e.g., real estate listings); assess whether synthetic training data generalizes or requires domain-specific fine-tuning.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can incorporating visual rendering features (e.g., spatial coordinates, screenshots) improve extraction accuracy for pages where the DOM structure is ambiguous or misleading?
- **Basis in paper:** [explicit] Section 6 (Conclusion) and Section 7 (Limitations) explicitly state that AXE "does not make use of visual rendering" and suggests it can be "further enhanced" by doing so.
- **Why unresolved:** The current architecture treats the HTML purely as a text/tree structure. While WebLM (a baseline) uses visual features, AXE has not tested whether adding vision would close the gap on complex reasoning tasks or strictly increase computational cost.
- **What evidence would resolve it:** A comparative evaluation where the AXE pipeline is augmented with visual embeddings (similar to WebLM) on the WebSRC dataset, specifically analyzing samples where DOM structure does not correlate with visual layout.

### Open Question 2
- **Question:** To what extent does the reliance on synthetic training data generated by a specific teacher model (Qwen3-Coder-480B) introduce domain-specific biases or limit generalization to real-world layouts not well-represented in the synthetic set?
- **Basis in paper:** [explicit] Section 7 (Limitations) notes that the "reliance on synthetic datasets for training may introduce domain-specific biases."
- **Why unresolved:** While the model performs well on SWDE, the distribution of synthetic schemas generated by the teacher model might constrain the system's ability to handle novel or rare query structures that deviate from the teacher's "creativity" or training distribution.
- **What evidence would resolve it:** Testing the model on a "wild" web extraction benchmark significantly different from Common Crawl clusters used to generate the 914 training pages, specifically analyzing failure rates on schema types under-represented in the synthetic data.

### Open Question 3
- **Question:** How sensitive is the Grounded XPath Resolution (GXR) to aggressive pruning errors in deep or complex hierarchies?
- **Basis in paper:** [inferred] Section 7 mentions that "if the retrieved context is of poor quality, the extraction process will likely fail," and Section 4.4 notes a performance drop when removing the exact algorithm.
- **Why unresolved:** The Pruner reduces context by 97.9%. While ablation shows removing the Pruner drops accuracy only slightly (0.66%), it is unclear how often the *incorrect* pruning of critical "anchor" nodes (e.g., a label distant from its value in the DOM) leads to GXR failures that a larger context window might have solved.
- **What evidence would resolve it:** An error analysis quantifying the percentage of GXR failures attributable to the target node being pruned during the pre-processing stage versus extraction hallucination.

## Limitations

- Relies on synthetic training data that may introduce domain-specific biases
- Does not incorporate visual rendering features, limiting performance on visually complex pages
- GXR grounding may reject valid paraphrased answers that don't verbatim-match DOM nodes

## Confidence

- **High Confidence**: Pruning mechanism's token reduction efficiency (97.9% reduction confirmed via Table 4) and GXR grounding's hallucination prevention (4.42% F1 drop when removed)
- **Medium Confidence**: Adapter training methodology and synthetic data generation process, though dependent on external implementations
- **Low Confidence**: "Zero-shot" performance claim, as heavy reliance on synthetic data from 480B teacher blurs zero-shot vs. transfer learning distinction

## Next Checks

1. **Pruning Robustness Test**: Apply AXE to 50 diverse web pages from verticals not in SWDE (e.g., real estate listings, product reviews) and systematically vary pruning aggressiveness. Measure the point at which F1 begins to degrade, establishing the pruning safety margin for unseen domains.

2. **GXR Grounding Verification**: Create a synthetic dataset where correct answers are paraphrased or synthesized from multiple DOM nodes. Run AXE with GXR enabled/disabled and measure the false rejection rate—cases where GXR incorrectly rejects valid but non-verbatim answers.

3. **Teacher Model Sensitivity**: Replace the Qwen3-Coder-480B teacher with a smaller model (e.g., 70B parameter variant) and regenerate synthetic training data. Retrain the 0.6B student and measure performance degradation to quantify the teacher's contribution versus the adapter architecture itself.