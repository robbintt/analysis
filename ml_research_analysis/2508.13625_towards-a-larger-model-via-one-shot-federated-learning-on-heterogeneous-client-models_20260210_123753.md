---
ver: rpa2
title: Towards a Larger Model via One-Shot Federated Learning on Heterogeneous Client
  Models
arxiv_id: '2508.13625'
source_url: https://arxiv.org/abs/2508.13625
tags:
- client
- data
- learning
- server
- clients
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FedOL introduces a one-shot federated learning framework that enables
  servers with ample resources to construct larger models by collecting client predictions
  on an unlabeled public dataset in a single communication round. Instead of exchanging
  model parameters, clients share only their prediction outputs, which reduces communication
  overhead and allows heterogeneous model architectures.
---

# Towards a Larger Model via One-Shot Federated Learning on Heterogeneous Client Models

## Quick Facts
- **arXiv ID**: 2508.13625
- **Source URL**: https://arxiv.org/abs/2508.13625
- **Reference count**: 24
- **Key outcome**: FedOL achieves >5.8% accuracy improvement over baselines on CIFAR-100 while reducing communication costs by ~170× through one-shot prediction sharing

## Executive Summary
FedOL introduces a one-shot federated learning framework enabling servers to construct larger models by collecting client predictions on an unlabeled public dataset in a single communication round. Instead of exchanging model parameters, clients share only their prediction outputs on public data, reducing communication overhead while allowing heterogeneous model architectures. The method addresses data heterogeneity and biased client predictions through a specialized objective function that iteratively refines pseudo-labels and server model. Extensive experiments on CIFAR-100 show FedOL outperforms baselines by over 5.8% in accuracy while achieving the lowest computation and communication costs per client.

## Method Summary
FedOL enables one-shot federated learning by having clients train locally on private data and transmit only their prediction outputs on an unlabeled public dataset. The server then applies knowledge distillation using KL divergence between client predictions and server outputs, integrating diverse client knowledge through class-wise confidence weighted voting and curriculum-based entropy filtering. The approach employs a tailored pseudo-label generation strategy that iteratively refines pseudo-labels based on client prediction confidence and server model improvement, allowing effective knowledge transfer to a larger server model without sharing raw data or model parameters.

## Key Results
- FedOL achieves over 5.8% accuracy improvement compared to baseline federated learning methods on CIFAR-100
- Communication overhead reduced by approximately 170× through prediction-only transmission (0.38 MB vs 65.14 MB for ResNet20 parameters)
- Outperforms FedAvg and FedProx by over 9% accuracy under single-round constraints with heterogeneous data
- Effective across different levels of data heterogeneity, with performance maintained even under severe label skew (Dir(0.05))

## Why This Works (Mechanism)

### Mechanism 1: One-Shot Knowledge Transfer via Prediction Outputs
- Claim: Transmitting only prediction outputs on an unlabeled public dataset enables knowledge transfer to a larger server model while reducing communication overhead by ~170× compared to parameter sharing.
- Mechanism: Clients train locally on private data D_l,k, then share predictions w^c_k(D_u) on public dataset D_u (0.38 MB vs 65.14 MB for ResNet20 parameters). Server applies knowledge distillation using KL divergence between client predictions and server outputs.
- Core assumption: A representative unlabeled public dataset D_u is available and sufficiently overlaps with the task domain.

### Mechanism 2: Class-Wise Confidence Weighted Voting for Pseudo-Labels
- Claim: Weighted aggregation using class-wise confidence scores C²_k mitigates prediction bias from heterogeneous client data distributions.
- Mechanism: Each model m contributes class-wise confidence C²_m = E_x[σ(w_m(x))]. During pseudo-label generation, reliable models (those with entropy below baseline H̃_m) vote with weights C²_m. Negative learning adds y_m,c = -1 for non-predicted classes.
- Core assumption: A model's prediction confidence reflects its training data characteristics—clients with more examples of class c will predict c more confidently.

### Mechanism 3: Curriculum-Based Entropy Filtering with Progressive Relaxation
- Claim: Progressive relaxation of confidence thresholds ("easy-to-hard") enables stable pseudo-label learning despite initial server model uncertainty.
- Mechanism: Entropy baseline H̃_m set to ρ-th percentile lowest entropy. Parameter ρ starts at 0.1, increases by 0.05 per iteration. Only predictions below entropy threshold contribute to pseudo-labels, expanding as server model improves.
- Core assumption: Server model w^t_s improves across iterations, making progressively less confident pseudo-labels reliable.

## Foundational Learning

- **Concept: Knowledge Distillation (KD)**
  - Why needed here: Core mechanism—understanding how soft targets (probability distributions) transfer knowledge from teacher models to student model via KL divergence minimization.
  - Quick check question: Why does minimizing D_KL(teacher_output || student_output) transfer more information than hard label training?

- **Concept: Semi-Supervised Learning with Pseudo-Labels**
  - Why needed here: Server must learn from unlabeled public data D_u using generated pseudo-labels ŷ, balancing supervised approximation and pseudo-label loss via τ.
  - Quick check question: What happens if tradeoff parameter τ is set too high early in training?

- **Concept: Federated Learning with Non-IID Data**
  - Why needed here: Understanding how label skew (Dirichlet partition) causes client prediction bias and why parameter aggregation fails under heterogeneity.
  - Quick check question: Why does FedAvg achieve only ~1% accuracy under single-round constraint with heterogeneous data?

## Architecture Onboarding

- **Component map:**
  - Client side: Local training on D_l,k → prediction generation on D_u → transmit 0.38 MB logits
  - Server side (iterative): Receive predictions → compute C² scores → set entropy baselines → generate pseudo-labels → train server model
  - Public dataset D_u: Unlabeled shared data for knowledge transfer medium

- **Critical path:**
  1. Acquire/curate unlabeled public dataset D_u (paper uses 5,000 samples)
  2. Clients complete local training, generate predictions on D_u
  3. Server computes C²_k for each client, initializes server model
  4. For t=1 to T iterations: Generate pseudo-labels → Update server model via distillation + pseudo-label loss
  5. Deploy final server model w^T_s

- **Design tradeoffs:**
  - ρ initialization (0.1): Lower = stricter initial filtering, more stable but slower convergence
  - τ parameter (0.2): Higher weight on pseudo-label loss risks propagating errors early
  - Server iterations T (10): More iterations improve refinement but increase server compute
  - Public dataset size vs coverage: Larger D_u improves generalization but increases client prediction overhead

- **Failure signatures:**
  - Accuracy collapses under severe skew (Dir(0.05): 29.8% vs Dir(1): 37.2%)—indicates client expertise too narrow
  - FedAvg/FedProx at ~1% accuracy in single-round setting—parameter-based methods fundamentally incompatible
  - Empty M(x) sets in Algorithm 1—entropy thresholds too strict for available prediction quality

- **First 3 experiments:**
  1. Reproduce Table I baseline comparison on CIFAR-100 with Dir(1) partition (10 clients, ResNet11/20 clients, ResNet56 server) to validate implementation
  2. Ablation: Remove class-wise confidence weighting (use uniform weights), measure accuracy drop under Dir(0.05) to quantify heterogeneity handling contribution
  3. Sensitivity analysis: Vary public dataset size (2.5k, 5k, 10k samples) to determine minimum D_u requirements for stable learning

## Open Questions the Paper Calls Out
- **Question**: How does distribution shift between the unlabeled public dataset and private client data impact the convergence and accuracy of FedOL?
- **Question**: Can the pseudo-label generation mechanism scale efficiently to cross-device settings with thousands of clients?
- **Question**: Is FedOL adaptable for Large Language Models (LLMs) and generative tasks?

## Limitations
- Performance degrades significantly under severe data heterogeneity (Dir(0.05) partition shows ~8% accuracy drop vs Dir(1))
- Limited scalability to real-world heterogeneous client populations beyond controlled CIFAR-100 experiments
- Requires careful calibration of public dataset quality and size for stable learning

## Confidence
- **High**: One-shot communication efficiency through prediction output transmission; ability to handle heterogeneous model architectures
- **Medium**: Accuracy improvements over baselines (5.8% gain); effectiveness of class-wise confidence weighting
- **Low**: Robustness to severe data heterogeneity (Dir(0.05) shows significant degradation); scalability beyond controlled CIFAR-100 experiments

## Next Checks
1. **Dataset Distribution Sensitivity**: Test FedOL performance with systematically varying public dataset quality (synthetic vs real, domain overlap) to establish minimum requirements for stable learning
2. **Client Participation Robustness**: Measure accuracy degradation when 20-50% of clients fail to participate or provide predictions, assessing failure tolerance
3. **Real-World Heterogeneity**: Evaluate on non-image datasets with severe label skew and task mismatch to identify break points beyond controlled CIFAR-100 scenarios