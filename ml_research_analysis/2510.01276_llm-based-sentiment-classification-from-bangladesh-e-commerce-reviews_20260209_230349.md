---
ver: rpa2
title: LLM Based Sentiment Classification From Bangladesh E-Commerce Reviews
arxiv_id: '2510.01276'
source_url: https://arxiv.org/abs/2510.01276
tags:
- sentiment
- bangla
- llms
- language
- reviews
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explores sentiment analysis on Bangladesh e-commerce
  reviews using large language models (LLMs) and transformer-based models. A dataset
  of 4,000 Bangla and English customer reviews was used to fine-tune several LLMs,
  including Llama-3.1-8B, Phi-3.5-mini-instruct, and Mistral-7B-v0.1, as well as multilingual
  BERT models.
---

# LLM Based Sentiment Classification From Bangladesh E-Commerce Reviews

## Quick Facts
- arXiv ID: 2510.01276
- Source URL: https://arxiv.org/abs/2510.01276
- Reference count: 0
- Llama-3.1-8B achieved 95.5% accuracy on Bangla/English e-commerce reviews

## Executive Summary
This study presents a comprehensive evaluation of large language models for sentiment classification on Bangladesh e-commerce reviews, using a mixed-language dataset of 4,000 Bangla and English customer reviews. The research focuses on fine-tuning several LLMs including Llama-3.1-8B, Phi-3.5-mini-instruct, and Mistral-7B-v0.1, alongside multilingual BERT models, to address the challenges of sentiment analysis in low-resource languages. The study employs parameter-efficient fine-tuning techniques like LoRA and PEFT to reduce computational overhead while maintaining high performance.

The results demonstrate that Llama-3.1-8B outperforms other models with an accuracy of 95.5%, precision of 93%, recall of 88%, and F1 score of 90%. The research provides valuable insights into the effectiveness of LLMs for sentiment classification in mixed-language contexts, particularly for Bangla e-commerce reviews. The findings suggest that LLMs offer a scalable and efficient solution for sentiment analysis in low-resource language settings, outperforming traditional BERT-based approaches.

## Method Summary
The study collected 4,000 customer reviews from Bangladesh e-commerce platforms in both Bangla and English languages. Multiple LLMs were fine-tuned using parameter-efficient techniques including LoRA and PEFT to optimize computational resources. The models evaluated included Llama-3.1-8B, Phi-3.5-mini-instruct, Mistral-7B-v0.1, and multilingual BERT variants. Sentiment classification was performed with evaluation metrics including accuracy, precision, recall, and F1 score to assess model performance across different linguistic contexts.

## Key Results
- Llama-3.1-8B achieved the highest performance with 95.5% accuracy, 93% precision, 88% recall, and 90% F1 score
- Parameter-efficient fine-tuning techniques (LoRA and PEFT) successfully reduced computational overhead
- LLMs outperformed traditional BERT-based models in mixed-language sentiment classification

## Why This Works (Mechanism)
LLMs demonstrate superior performance in sentiment classification for Bangladesh e-commerce reviews due to their ability to understand contextual nuances across multiple languages. The pre-training on diverse linguistic data enables these models to capture complex sentiment expressions in both Bangla and English. Parameter-efficient fine-tuning allows adaptation to specific domain vocabulary and sentiment patterns while maintaining computational efficiency. The large model capacity provides better generalization across different sentiment expressions and linguistic structures present in e-commerce reviews.

## Foundational Learning
1. **Fine-tuning LLMs for domain adaptation** - Essential for adapting pre-trained models to specific sentiment classification tasks in e-commerce contexts. Quick check: Verify that fine-tuned models show improved performance on domain-specific vocabulary and sentiment expressions.

2. **Parameter-efficient fine-tuning techniques (LoRA/PEFT)** - Critical for reducing computational costs while maintaining model performance. Quick check: Compare training time and resource usage between full fine-tuning and parameter-efficient approaches.

3. **Multilingual sentiment analysis** - Important for handling mixed-language datasets common in Bangladesh e-commerce. Quick check: Evaluate model performance separately on Bangla-only, English-only, and mixed-language subsets.

4. **Sentiment classification metrics** - Necessary for comprehensive evaluation of model performance. Quick check: Ensure all relevant metrics (accuracy, precision, recall, F1) are reported and balanced.

## Architecture Onboarding

**Component Map:** Data Preprocessing -> Model Fine-tuning -> Evaluation -> Performance Analysis

**Critical Path:** Dataset Preparation -> Model Selection -> Parameter-Efficient Fine-tuning -> Multi-metric Evaluation

**Design Tradeoffs:** The study balances model performance against computational efficiency through parameter-efficient fine-tuning, trading some potential accuracy gains from full fine-tuning for reduced resource requirements.

**Failure Signatures:** Poor performance on Bangla-specific sentiment expressions, imbalanced class predictions, overfitting on limited training data, and suboptimal handling of mixed-language contexts.

**First Experiments:**
1. Baseline evaluation of pre-trained models without fine-tuning on the sentiment classification task
2. Comparative analysis of different parameter-efficient fine-tuning techniques (LoRA vs PEFT)
3. Performance evaluation on language-specific subsets (Bangla-only, English-only, mixed)

## Open Questions the Paper Calls Out
None

## Limitations
- Small dataset size (4,000 reviews) may not capture full sentiment expression diversity
- Lack of detailed dataset composition information raises questions about class balance
- Study focuses only on sentiment classification, not aspect-based sentiment analysis

## Confidence
- **High confidence** in Llama-3.1-8B performance metrics across all evaluation measures
- **Medium confidence** in the effectiveness of parameter-efficient fine-tuning techniques
- **Medium confidence** in LLMs' effectiveness for low-resource languages like Bangla

## Next Checks
1. Conduct cross-validation with a larger, more diverse dataset (minimum 10,000 reviews) to verify robustness
2. Perform ablation studies comparing fine-tuned LLMs against zero-shot and few-shot prompting approaches
3. Implement human evaluation studies with native Bangla speakers to validate sentiment classification accuracy