---
ver: rpa2
title: 'S3MOT: Monocular 3D Object Tracking with Selective State Space Model'
arxiv_id: '2504.18068'
source_url: https://arxiv.org/abs/2504.18068
tags:
- tracking
- object
- ieee
- motion
- s3mot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces S3MOT, a novel monocular 3D object tracking
  method that addresses the challenge of extracting 3D spatiotemporal associations
  from 2D video streams. The key innovation lies in three core components: (1) Hungarian
  State Space Model (HSSM), a differentiable data association mechanism with global
  receptive field and dynamic weights that replaces traditional linear assignment
  algorithms; (2) Fully Convolutional One-stage Embedding (FCOE), which uses dense
  feature maps for contrastive learning to improve object re-identification under
  challenging conditions; and (3) VeloSSM, an encoder-decoder architecture that models
  temporal velocity dependencies to enhance 6-DoF pose estimation.'
---

# S3MOT: Monocular 3D Object Tracking with Selective State Space Model

## Quick Facts
- **arXiv ID**: 2504.18068
- **Source URL**: https://arxiv.org/abs/2504.18068
- **Reference count**: 40
- **Primary result**: 76.86 HOTA at 31 FPS on KITTI, outperforming previous methods by +2.63 HOTA and +3.62 AssA

## Executive Summary
This paper introduces S3MOT, a novel monocular 3D object tracking method that addresses the challenge of extracting 3D spatiotemporal associations from 2D video streams. The key innovation lies in three core components: (1) Hungarian State Space Model (HSSM), a differentiable data association mechanism with global receptive field and dynamic weights that replaces traditional linear assignment algorithms; (2) Fully Convolutional One-stage Embedding (FCOE), which uses dense feature maps for contrastive learning to improve object re-identification under challenging conditions; and (3) VeloSSM, an encoder-decoder architecture that models temporal velocity dependencies to enhance 6-DoF pose estimation. Evaluated on the KITTI benchmark, S3MOT achieves state-of-the-art performance with 76.86 HOTA at 31 FPS, demonstrating superior robustness and efficiency for monocular 3D multi-object tracking tasks.

## Method Summary
S3MOT is a monocular 3D multi-object tracking framework that integrates three key innovations. First, it uses a DLA-34 backbone with DD3D detector to predict 3D bounding boxes. Second, FCOE generates dense 256-D embeddings for appearance-based re-identification without ROI pooling. Third, VeloSSM employs a dual Mamba encoder-decoder to model velocity sequences and predict 6-DoF poses. Finally, HSSM uses a differentiable SSM-based matcher to perform global data association. The system is trained in stages: first optimizing the detector and FCOE jointly, then training VeloSSM and HSSM for motion and association modeling. Inference uses batch processing with NMS post-processing to produce final tracking results.

## Key Results
- Achieves 76.86 HOTA and 77.41 AssA on KITTI benchmark at 31 FPS
- Outperforms previous methods by +2.63 HOTA and +3.62 AssA
- Demonstrates robust performance with only 0.4% ID switches and 1.5% FRAG

## Why This Works (Mechanism)

### Mechanism 1: Context-Aware Data Association (HSSM)
- **Claim:** Replacing the discrete Hungarian Algorithm with a differentiable Selective State Space Model (HSSM) improves association robustness by capturing global interactions between track-detection pairs.
- **Mechanism:** HSSM treats the distance tensor (Metrics × Tracks × Detections) as a 2D feature map. It performs a 4-way spatiotemporal scan using Mamba blocks, allowing dynamic weighting of heterogeneous cues based on global context rather than optimizing row/column independently.
- **Core assumption:** Assignment decisions are not independent; the affinity of one pair influences the likelihood of another (competition).
- **Evidence anchors:** [Section 3.4] HSSM features global receptive field and dynamic weights; [Abstract] efficient and comprehensive assignment decisions with linear complexity.
- **Break condition:** Fails if the input distance tensor D is dominated by noisy or uninformative metrics.

### Mechanism 2: Flow-Conditioned Motion Refinement (VeloSSM)
- **Claim:** Modeling velocity dependencies via an encoder-decoder SSM structure enhances 6-DoF pose estimation compared to linear Kalman Filters.
- **Mechanism:** VeloSSM uses a Self-SSM encoder to compress historical velocity sequences into a "tracklet flow" feature. A Cross-SSM decoder conditions the current state update on this flow feature and noisy observation.
- **Core assumption:** Object motion follows consistent dynamics over short temporal windows that can be captured by state spaces.
- **Evidence anchors:** [Section 3.3] VeloSSM models temporal dependencies in velocity; [Table 3] VeloSSM achieves 49.73 AMOTA vs LSTM's 49.55 and KF's 47.23.
- **Break condition:** Fails during immediate, unpredictable maneuvers if the historical window n is too short to react or too long (averaging out the maneuver).

### Mechanism 3: Dense Similarity Learning (FCOE)
- **Claim:** Eliminating ROI pooling in favor of fully convolutional dense embeddings improves object re-identification under occlusion.
- **Mechanism:** FCOE predicts embeddings for every pixel and uses "Feature-Dense Instance Similarity Loss" that weighs positive/negative pairs by "center-ness" (proximity to object center).
- **Core assumption:** Discriminative features exist in the dense spatial neighborhood of the object, not just inside the tight box.
- **Evidence anchors:** [Section 3.2] FCOE operates densely across feature map; [Figure 3] visualizes high/low center-ness features for contrastive learning.
- **Break condition:** Degrades in extreme close-ups where object exceeds receptive field, or in texture-less regions where dense features are ambiguous.

## Foundational Learning

- **Concept: State Space Models (SSMs/Mamba)**
  - **Why needed here:** S3MOT relies on SSMs to replace RNNs (LSTM) and Transformers for sequence modeling. You must understand how SSMs discretize continuous dynamics (A, B, C matrices) and use a "selection mechanism" (Δ) to filter irrelevant history.
  - **Quick check question:** How does the "step size" (Δ) in a selective SSM determine which parts of the input sequence are retained vs. forgotten?

- **Concept: Bipartite Matching & Assignment Cost**
  - **Why needed here:** The HSSM module attempts to learn the "Hungarian Algorithm." You need to know that standard tracking solves a bipartite graph matching problem minimizing a cost function (e.g., Distance = α · App + β · IoU).
  - **Quick check question:** In a standard Hungarian assignment, does changing the cost of a matched pair affect the assignment of other pairs? (Answer: Yes, due to mutual exclusion).

- **Concept: Contrastive Learning**
  - **Why needed here:** The FCOE module uses this to train Re-ID features. You need to understand how a network learns to pull "positive" pairs (same object, different frame) together and push "negative" pairs apart in feature space.
  - **Quick check question:** In FCOE, what defines a "positive" pair versus a "negative" pair in the contrastive loss?

## Architecture Onboarding

- **Component map:** Monocular Image → DD3D (Detector) → FCOE (Re-ID Head) & DD3D (3D Box Head) → VeloSSM (Encoder-Decoder for flow) → HSSM (Mamba-based matcher taking Distance Tensor D)
- **Critical path:** The construction of the Distance Tensor (D) is critical. It concatenates Heterogeneous Cues: Appearance (from FCOE), IoU (3D/2D), and Motion (from VeloSSM). If any of these modalities is missing or unnormalized, the HSSM scan will likely fail.
- **Design tradeoffs:**
  - **Differentiability vs. Correctness:** HSSM is differentiable but produces a soft association (probabilities), whereas the Hungarian Algorithm is discrete. The system relies on training to align these.
  - **Complexity:** VeloSSM requires maintaining a history buffer of n frames (velocity sequences), adding state management complexity compared to a simple Kalman Filter.
- **Failure signatures:**
  - **ID Switches:** Likely a failure in HSSM weighting (e.g., over-weighting Appearance when two cars look identical).
  - **Trajectory Drift:** VeloSSM failing to predict abrupt changes, sticking to the "flow" history too strongly.
  - **Missed Detections:** FCOE features collapsing due to low "center-ness" in crowded scenes.
- **First 3 experiments:**
  1. **Metric Ablation:** Disable specific channels in the Distance Tensor D (e.g., run HSSM with only Appearance, or only IoU) to verify the model actually fuses cues rather than relying on one dominant feature.
  2. **Motion Model Swap:** Replace VeloSSM with a standard Kalman Filter to quantify the specific performance gain from the SSM architecture on the validation set.
  3. **Scan Direction Test:** HSSM uses 4-way scanning. Try reducing this to 1-way or 2-way to see if the "global receptive field" is truly necessary for the specific KITTI scene density.

## Open Questions the Paper Calls Out

- **Question:** How does S3MOT generalize to diverse large-scale benchmarks (e.g., nuScenes or Waymo) with varying camera geometries and weather conditions?
- **Basis in paper:** [Explicit] The conclusion explicitly calls for further research in "real-world applications" beyond the KITTI benchmark.
- **Why unresolved:** KITTI has a specific camera setup and limited weather diversity; the learned association weights in HSSM may overfit to these specific spatiotemporal distributions.
- **What evidence would resolve it:** Performance evaluations on nuScenes or Waymo Open Dataset demonstrating retained HOTA and AssA scores without architecture modification.

## Limitations

- The HSSM's reliance on learning data association through differentiable matching introduces potential instability during training, as soft assignments may not converge to optimal discrete solutions
- Performance improvements are evaluated primarily on the KITTI dataset, which may not generalize to more crowded urban scenes or different camera configurations
- VeloSSM's historical buffer requirements create memory overhead and may struggle with immediate trajectory changes
- FCOE's dense feature learning assumes sufficient object texture and may degrade in uniform environments

## Confidence

- **High confidence**: The core SSM architecture for motion modeling (VeloSSM) is technically sound and shows consistent improvements over baseline KF/LSTM
- **Medium confidence**: The HSSM's differentiable association mechanism improves upon Hungarian Algorithm in controlled settings, though generalization across diverse tracking scenarios needs validation
- **Medium confidence**: FCOE's dense feature learning for re-identification provides robustness benefits, but the "no-ROI" assumption requires more extensive validation across occlusion patterns

## Next Checks

1. **Cross-dataset generalization**: Evaluate S3MOT on nuScenes or Waymo Open Dataset to verify performance consistency beyond KITTI's relatively sparse scenes
2. **Ablation on historical window size**: Systematically vary the VeloSSM's historical frame count (n) to identify optimal temporal context for different vehicle classes
3. **Stress testing under occlusion**: Create synthetic occlusion scenarios with varying overlap percentages to quantify FCOE's feature robustness compared to ROI-based alternatives