---
ver: rpa2
title: 'Causality Meets Locality: Provably Generalizable and Scalable Policy Learning
  for Networked Systems'
arxiv_id: '2510.21427'
source_url: https://arxiv.org/abs/2510.21427
tags:
- domain
- policy
- each
- state
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses scalability and generalizability challenges
  in large-scale networked multi-agent reinforcement learning (MARL) systems. The
  proposed GSAC framework combines causal representation learning with meta actor-critic
  learning to achieve both scalability and domain generalization.
---

# Causality Meets Locality: Provably Generalizable and Scalable Policy Learning for Networked Systems

## Quick Facts
- arXiv ID: 2510.21427
- Source URL: https://arxiv.org/abs/2510.21427
- Reference count: 40
- One-line primary result: GSAC achieves scalable, generalizable MARL through causal masks and domain conditioning, with theoretical guarantees on truncation error and adaptation gaps.

## Executive Summary
This paper tackles scalability and generalizability challenges in large-scale networked multi-agent reinforcement learning (MARL) systems. The proposed GSAC framework combines causal representation learning with meta actor-critic learning to achieve both scalability and domain generalization. Each agent learns a sparse local causal mask to identify minimal neighborhood variables influencing its dynamics, constructing approximately compact representations (ACRs) that bound value function truncation errors. A meta actor-critic trains a shared policy across multiple source domains while conditioning on compact domain factors. At test time, a few trajectories suffice to estimate new domain factors and deploy adapted policies. Theoretical guarantees establish finite-sample convergence and adaptation gap bounds. Empirical evaluation on wireless communication and traffic control benchmarks demonstrates that GSAC rapidly adapts and significantly outperforms learning-from-scratch and conventional adaptation baselines.

## Method Summary
GSAC operates in four phases: (1) Local causal discovery to identify sparse causal masks identifying minimal neighborhood variables, (2) ACR construction to reduce state dimensionality, (3) Meta actor-critic training across multiple source domains using ACR inputs and tabular critics, and (4) Test-time adaptation via few-shot estimation of domain factors. The framework leverages exponential decay in networked MDPs to bound truncation errors, enabling efficient learning on graphs. The policy conditions on compact domain factors estimated from a few trajectories, allowing immediate adaptation without gradient updates.

## Key Results
- GSAC achieves rapid adaptation to new domains using only a few trajectories, outperforming learning-from-scratch and conventional adaptation baselines.
- Theoretical guarantees establish finite-sample convergence and adaptation gap bounds for the proposed framework.
- Empirical evaluation demonstrates significant performance improvements on wireless communication and traffic control benchmarks while maintaining scalability.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Truncating the value function to a local $\kappa$-hop neighborhood approximates the global value function with bounded error.
- **Mechanism:** The framework leverages the "exponential decay" property inherent in networked MDPs, where an agent's value function $Q_i$ decays as $\gamma^\kappa$ relative to graph distance. By defining a truncated Q-function $\hat{Q}$ over local neighborhoods, the algorithm reduces input dimensionality while bounding approximation error by $\bar{r}\gamma^{\kappa+1}/(1-\gamma)$.
- **Core assumption:** The system exhibits localized interactions where the global transition factorizes into local transitions (Eq. 1) and the discount factor $\gamma < 1$ drives decay.
- **Evidence anchors:** [abstract] "...bounding the error of truncating value functions to $\kappa$-hop neighborhoods, enabling efficient learning on graphs." [section 3] "...approximation error between $\tilde{Q}$ and $Q$ satisfies... $\le 2\bar{r}\gamma^{\kappa+1}/(1-\gamma)$." [corpus] "Learning Multi-Robot Coordination through Locality-Based Factorized Multi-Agent Actor-Critic Algorithm" supports the general viability of locality-based factorization.
- **Break condition:** If the interaction graph is fully connected or coupling is strong (high effective $\gamma$), $\kappa$ must approach the graph diameter, negating scalability benefits.

### Mechanism 2
- **Claim:** Identifying "Approximately Compact Representations" (ACRs) via causal masks isolates the minimal sufficient statistics for policy learning.
- **Mechanism:** Instead of using the full neighborhood state $s_{N_i^\kappa}$, the algorithm identifies a subset $s^\circ_{N_i^\kappa}$ that has causal paths to the agent's reward $r_i$. This pruning removes irrelevant variables (like specific grid coordinates in the wireless benchmark) that increase variance but not signal.
- **Core assumption:** Structural identifiability (Theorem 1) holds, meaning the causal mask is recoverable from data under the faithfulness assumption.
- **Evidence anchors:** [abstract] "...learns a sparse local causal mask that provably identifies the minimal neighborhood variables..." [section 5] Theorem 1 guarantees unique recovery of structural matrices $c$ from trajectories. [corpus] "Causal Policy Learning in Reinforcement Learning" aligns with the general trend of using causal structures to correct policy bias, though GSAC focuses specifically on representation compactness.
- **Break condition:** If state variables are highly entangled or the causal graph is dense (high in-degree $d_{max}$), the "minimal" set may remain large, reducing the efficiency gains of ACR.

### Mechanism 3
- **Claim:** Conditioning a shared policy on a compact, estimated domain factor $\omega$ enables few-shot generalization to new environments.
- **Mechanism:** The policy $\pi(a|s, \omega)$ is trained across multiple source domains to be invariant to fixed state features but sensitive to $\omega$. In a target domain, $\omega$ is estimated via maximum likelihood from a few trajectories (Eq. 10), allowing immediate policy adaptation without gradient updates.
- **Core assumption:** Domain factors vary smoothly and lie in a compact space (Assumption 6), allowing interpolation between seen source domains and unseen target domains.
- **Evidence anchors:** [abstract] "...trains a shared policy across multiple source domains while conditioning on the compact domain factors; at test time, a few trajectories suffice..." [section 6.2] Theorem 4 bounds the adaptation gap by $O(1/\sqrt{T_a})$, demonstrating provable generalization. [corpus] "A Shift in Perspective on Causality in Domain Generalization" provides context on the challenges of generalization, reinforcing the need for rigorous adaptation gaps.
- **Break condition:** If the target domain $\omega_{M+1}$ is structurally distinct from the source distribution support (out-of-distribution), the estimator $\hat{\omega}$ may fail to converge to a valid factor.

## Foundational Learning

- **Concept: Structural Causal Models (SCMs) in RL**
  - **Why needed here:** To understand Phase 1 (Causal Discovery), one must grasp how transition dynamics $P(s_{t+1}|s_t, a_t, \omega)$ decompose into invariant mechanisms $f$ and domain-specific factors $\omega$.
  - **Quick check question:** Can you distinguish between an invariant mechanism $f$ and a domain variable $\omega$ in the equation $s_{t+1} = f(s_t, a_t, \omega)$?

- **Concept: Exponential Decay in Graphs**
  - **Why needed here:** This mathematical property justifies the central approximation of the paper (truncation). Without it, local policies would be insufficient.
  - **Quick check question:** Does the error bound $\gamma^{\kappa+1}$ increase or decrease as the discount factor $\gamma$ approaches 1?

- **Concept: Meta-Learning via Context Conditioning**
  - **Why needed here:** GSAC does not fine-tune weights at test time; it infers a context vector. Understanding this distinction is vital for implementing the adaptation phase.
  - **Quick check question:** In GSAC, does the policy parameter $\theta$ change during test-time adaptation, or does the input to the policy change?

## Architecture Onboarding

- **Component map:** Causal Discovery Module -> ACR Generator -> Meta-Critic -> Meta-Actor
- **Critical path:** The Causal Discovery Module is the bootstrapping bottleneck. If the causal mask $c$ is incorrect (false positives/negatives), the ACR Generator will prune the wrong variables, causing unresolvable bias in the Actor/Critic.
- **Design tradeoffs:**
  - **$\kappa$ (Neighborhood radius):** Increasing $\kappa$ lowers approximation error but causes dimensionality to scale exponentially with node degree.
  - **Sample Complexity vs. Sparsity:** Higher sparsity ($d_{max}$) lowers the sample cost of causal discovery but may over-prune necessary dependencies.
- **Failure signatures:**
  - **Training instability:** If the critic loss diverges, check if the ACR pruned essential state features (verify causal mask).
  - **Poor Adaptation:** If test performance collapses, check if the domain factor estimator $\hat{\omega}$ is stuck in a local minimum or if the target domain is OOD.
- **First 3 experiments:**
  1. **Scalability Stress Test:** Run GSAC on increasing grid sizes (3x3, 4x4, 5x5) to verify that sample complexity scales linearly/quadratically rather than exponentially with $n$ (Fig 2).
  2. **Ablation on ACR:** Compare full GSAC against a variant without ACR (using full neighborhood states) to measure the computational speedup vs. performance loss.
  3. **Domain Shift Sensitivity:** Train on source domains $\omega \in \{0.2, 0.5, 0.8\}$ and test on $\omega=0.65$ (interpolation) vs. $\omega=1.0$ (extrapolation) to validate the adaptation gap bound.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the GSAC framework and the theoretical guarantees for Approximately Compact Representations (ACRs) be extended to continuous state and action spaces using function approximation?
- Basis in paper: [explicit] Section 8 explicitly lists "extending GSAC to continuous state and action spaces with function approximation based on ACRs" as a primary direction for future work.
- Why unresolved: The current theoretical analysis (Theorem 2, 3) relies on tabular representations (finite state spaces) and specific covering number arguments that may not hold directly with high-dimensional function approximation (e.g., neural networks).
- What evidence would resolve it: A proof of convergence for ACR construction in continuous domains, or empirical validation showing GSAC outperforms baselines on benchmarks with continuous control (e.g., networked MuJoCo variants).

### Open Question 2
- Question: How can the framework incorporate partial observability, where agents cannot directly access the true local state $s_{N_i}$ required for ACR construction?
- Basis in paper: [explicit] Section 8 identifies "incorporating partial observability into the framework" as a future direction. Appendix F.1 notes that the current work assumes full local observability.
- Why unresolved: The ACR algorithm (Algorithm 1, 2, 3) assumes the causal mask $c$ and states $s_{N_i}$ are directly observable to identify relevant components. Belief states or latent encoders would complicate the structural identifiability guarantees.
- What evidence would resolve it: Integration of a latent variable model (e.g., VAE) to infer ACRs from observations $o_i$, or theoretical analysis showing identifiability conditions under partial observability.

### Open Question 3
- Question: Can GSAC maintain its theoretical guarantees and efficiency if the causal graph topology changes over time (dynamic topologies) rather than remaining fixed?
- Basis in paper: [inferred] The paper assumes a fixed interaction graph $G$ and static causal masks $c$ (Equation 6) shared across domains. Many real-world networked systems (e.g., vehicular networks) have time-varying connectivity.
- Why unresolved: The finite-sample convergence and adaptation gap bounds rely on the stability of the causal structure $c$; dynamic graphs would require re-computing ACRs online, introducing computational overhead and estimation variance.
- What evidence would resolve it: An analysis of sample complexity when the graph evolves slowly, or an algorithm extension that tracks dynamic causal edges without losing the "locality" benefits.

## Limitations

- **Causal Discovery Implementation:** The paper provides theoretical guarantees for causal mask recovery but lacks detailed algorithmic specifications for the conditional independence tests and convergence criteria.
- **Domain Factor Estimation:** While maximum likelihood estimation is mentioned, the iterative solver, initialization scheme, and convergence guarantees for estimating $\omega$ in test environments are not detailed.
- **Function Approximation:** Current theoretical analysis relies on tabular representations and may not directly extend to high-dimensional function approximation with neural networks.

## Confidence

- **High Confidence:** The theoretical error bounds for value function truncation (Mechanism 1) are mathematically rigorous and well-supported by the exponential decay property in networked MDPs.
- **Medium Confidence:** The meta-learning adaptation guarantees (Mechanism 3) rely on the assumption of smooth domain factor interpolation, which is reasonable but may not hold for extreme out-of-distribution shifts.
- **Medium Confidence:** The ACR construction via causal masks (Mechanism 2) is theoretically sound, but practical identifiability depends on sample complexity and faithfulness assumptions that may be violated in complex real-world systems.

## Next Checks

1. **Scalability Validation:** Implement GSAC on increasing grid sizes (3x3 â†’ 5x5) and verify that sample complexity scales sub-exponentially with node count, as claimed in Figure 2.
2. **Ablation Study:** Compare full GSAC against a variant using full neighborhood states (no ACR) to quantify the computational speedup and any performance degradation from pruning.
3. **Domain Generalization Test:** Train GSAC on source domains $\omega \in \{0.2, 0.5, 0.8\}$ and test on $\omega=0.65$ (interpolation) vs. $\omega=1.0$ (extrapolation) to validate the adaptation gap bound and identify failure modes.