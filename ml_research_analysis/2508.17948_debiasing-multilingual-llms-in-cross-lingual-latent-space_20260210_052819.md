---
ver: rpa2
title: Debiasing Multilingual LLMs in Cross-lingual Latent Space
arxiv_id: '2508.17948'
source_url: https://arxiv.org/abs/2508.17948
tags:
- debiasing
- space
- debias
- bias
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of cross-lingual bias transfer
  in multilingual large language models (LLMs). Previous debiasing techniques show
  limited effectiveness across languages when applied directly to LLM representations
  due to imperfect cross-lingual alignment.
---

# Debiasing Multilingual LLMs in Cross-lingual Latent Space

## Quick Facts
- **arXiv ID**: 2508.17948
- **Source URL**: https://arxiv.org/abs/2508.17948
- **Reference count**: 40
- **Primary result**: Applying debiasing techniques in a learned cross-lingual latent space achieves up to 65% bias reduction and significantly better cross-lingual transferability than direct application on LLM representations.

## Executive Summary
This paper addresses the challenge of cross-lingual bias transfer in multilingual LLMs, where traditional debiasing techniques applied directly to LLM representations show limited effectiveness across languages due to imperfect cross-lingual alignment. The authors propose performing debiasing in a joint cross-lingual latent space rather than on original LLM representations. By training an autoencoder on parallel TED talk scripts to construct a well-aligned cross-lingual latent space, they demonstrate that applying debiasing techniques (INLP and SentDebias) in this learned space significantly improves both overall debiasing performance and cross-lingual transferability, achieving bias reductions of up to 65%.

## Method Summary
The method involves training an autoencoder on parallel TED talk scripts to construct a cross-lingually aligned latent space where semantically equivalent sentences cluster together regardless of language. The autoencoder uses a shared encoder across all languages paired with language-specific decoders, with loss functions enforcing both self-reconstruction and cross-lingual reconstruction. Once established, debiasing techniques (INLP and SentDebias) are applied within this latent space. Experiments with Aya-expanse across four languages (English, French, German, Dutch) demonstrate that autoencoders effectively construct a well-aligned cross-lingual latent space, and applying debiasing techniques in this learned space significantly improves both overall debiasing performance and cross-lingual transferability.

## Key Results
- Autoencoders effectively construct a well-aligned cross-lingual latent space, with parallel sentences clustering together regardless of language in the latent space
- Applying debiasing techniques in the learned latent space significantly improves both overall debiasing performance and cross-lingual transferability, achieving bias reductions of up to 65%
- The approach is most effective when initial bias is statistically significant (>62.5% threshold), with overcompensation occurring when baseline bias is already near optimal

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: A shared encoder trained on parallel data creates a cross-lingually aligned latent space where semantically equivalent sentences cluster together regardless of language.
- **Mechanism**: The autoencoder uses a shared encoder across all languages paired with language-specific decoders. The loss function enforces both self-reconstruction (x→x) and cross-lingual reconstruction (x→y), forcing the encoder to learn language-invariant representations. The bottleneck dimension (128) compresses information, discarding language-specific signals while preserving semantic content.
- **Core assumption**: Parallel sentences contain sufficient signal to learn a mapping that separates semantic content from language-specific features, and this decomposition transfers to out-of-domain data.
- **Evidence anchors**: [abstract] "autoencoders effectively construct a well-aligned cross-lingual latent space"; [Page 2] t-SNE visualization shows parallel sentences "overlapped together" in latent space versus "clustered into distinct groups based on their languages" in original space; [Page 5, Figure 3] 3-layer MLP architecture produces the best alignment; 1-2 layers underperform
- **Break condition**: If the autoencoder bottleneck is too large, language-specific features may pass through; if too small, semantic content is lost. The paper found 3-layer MLP with 128-dim bottleneck optimal after tuning.

### Mechanism 2
- **Claim**: Debiasing techniques applied in the aligned latent space transfer more effectively across languages than when applied directly to LLM representations.
- **Mechanism**: INLP and SentDebias identify bias subspaces (e.g., gender direction) by training classifiers or computing PCA on sentence representations. In the original LLM space, these bias directions are language-specific due to imperfect alignment. In the shared latent space, the bias direction is more consistent across languages, so removing it in one language generalizes to others.
- **Core assumption**: The bias subspace identified in the latent space captures language-invariant bias signals, and debiasing operations in latent space transfer back to original space without reconstruction artifacts.
- **Evidence anchors**: [Page 3-4] Table 2 shows English debiasing in latent space reduces bias scores more consistently across FR/DE/NL than original space debiasing; [Page 4] Figure 2 shows dashed bars (latent space) consistently lower than solid bars (original space) across all evaluation languages; [corpus] Iterative Multilingual Spectral Attribute Erasure (2506.11244) similarly finds that "multilingual representations embed words with similar meanings to share a common semantic space" enabling cross-lingual debiasing transfer
- **Break condition**: If the original LLM has fundamentally different bias encoding mechanisms per language (not just misaligned representations), the shared latent space may not capture all bias directions uniformly.

### Mechanism 3
- **Claim**: The approach is most effective when initial bias is statistically significant; low baseline bias can cause overcompensation.
- **Mechanism**: The debiasing operation projects representations away from identified bias directions. When baseline bias is already near 50% (unbiased), the projection can overshoot, inverting rather than neutralizing bias. The paper uses a binomial test (n=40, p=0.5, α=0.05) to establish a significance threshold of 62.5% bias score.
- **Core assumption**: Bias manifests as systematic deviation from random baseline, and the projection-based removal is calibrated for significant deviations.
- **Evidence anchors**: [Page 3] "when initial bias scores are already near optimal, further debiasing can cause overcompensation, instead amplifying bias"; [Page 3-4] Results focus on "scenarios that bias scores are significant" with 95% confidence threshold; [Page 7-8, Appendix E] Full results show debiasing effects vary by bias type; some categories show minimal improvement
- **Break condition**: Applying this method to models or categories with low baseline bias (<62.5% score) may increase variance without meaningful improvement or cause reverse bias.

## Foundational Learning

- **Concept: Cross-lingual representation alignment**
  - **Why needed here**: The core insight is that multilingual LLMs do not naturally align representations across languages; parallel sentences cluster by language ID. Understanding why alignment fails (different tokenization, unbalanced training data, lack of explicit alignment objectives) motivates the autoencoder approach.
  - **Quick check question**: Given two sentences with identical meaning in English and French from an LLM, would you expect their pooled hidden states to be closer to each other than to other sentences in the same language?

- **Concept: Autoencoder reconstruction losses**
  - **Why needed here**: The method uses a specific loss combining self-reconstruction (L(x) + L(y)) and cross-lingual reconstruction (L(x,y) + L(y,x)). Understanding why both are necessary—self-reconstruction preserves information, cross-lingual reconstruction enforces alignment—is essential for debugging.
  - **Quick check question**: If you only used cross-lingual reconstruction loss without self-reconstruction, what failure mode might occur?

- **Concept: Subspace projection debiasing (INLP, SentDebias)**
  - **Why needed here**: The paper applies existing debiasing methods in a new space. INLP iteratively trains classifiers to identify bias directions and projects them out; SentDebias uses PCA on attribute word representations. Understanding these mechanisms clarifies why alignment matters—if bias directions differ by language in original space, single-language debiasing cannot transfer.
  - **Quick check question**: Why does INLP iterate rather than train a single classifier? What does each iteration remove?

## Architecture Onboarding

- **Component map**: Input sentence (lang L) → LLM → Mean-pooled representation (4096-dim for Aya-8B) → Shared Encoder (3-layer MLP, ReLU) → Latent space (128-dim) → [Debiasing: INLP or SentDebias applied here] → Language-specific Decoder (3-layer MLP) → Debiased representation → Continue to downstream task

- **Critical path**:
  1. **Parallel data preparation**: Generate all language pairs (6 pairs × 152,938 sentences = 917,628 pairs)
  2. **Autoencoder training**: 50 epochs with AdamW (lr=1e-4), early stopping on validation reconstruction loss
  3. **Debiasing subspace identification**: Train INLP classifiers or compute PCA on 2.5% Wikipedia per language
  4. **Inference**: Encode → Debias in latent space → Decode back to original representation space

- **Design tradeoffs**:
  - **Bottleneck size**: 128-dim chosen empirically; larger may leak language signal, smaller may lose semantic nuance
  - **Architecture depth**: 3-layer MLP best (Figure 3); shallower under-aligns, deeper overfit to training domain
  - **Training data domain**: TED talks; may not align well for specialized domains (see FLORES+ evaluation)
  - **Debiasing language**: English not always best debiasing source despite being majority in pretraining; optimal language varies by evaluation language

- **Failure signatures**:
  - **Overcompensation**: If base bias score <62.5% (statistically insignificant), debiasing may amplify bias or cause variance
  - **Domain mismatch**: Autoencoder trained on TED talks; different domains may show weaker alignment
  - **Reconstruction artifacts**: After decode, representations may differ from original LLM distribution, though GLUE tests show minimal degradation (≤1.3% F1/accuracy)
  - **Incomplete transfer**: Some bias types (e.g., religion) show less consistent improvement across languages (Appendix E)

- **First 3 experiments**:
  1. **Validate alignment quality**: Sample 100 parallel sentences from an out-of-domain corpus (e.g., FLORES+), encode with trained autoencoder, visualize with t-SNE. Expect single clusters per semantic meaning across languages.
  2. **Ablate autoencoder depth**: Train 1/2/3/4-layer variants, measure cross-lingual reconstruction MSE and alignment quality (cosine similarity of parallel pairs). Confirm 3-layer optimal per paper's Figure 3.
  3. **Single-language debiasing transfer test**: Debias using only English data in latent space, evaluate bias scores on French/German/Dutch. Compare to debiasing in original LLM space. Expect latent space to show lower bias scores (Table 2 pattern).

## Open Questions the Paper Calls Out

- **Open Question 1**: Does the cross-lingual latent space debiasing approach generalize to non-European languages with different scripts and linguistic structures?
  - **Basis in paper**: [explicit] The authors state in the Limitations section: "Expanding this work to non-European languages remains an important direction for future research."
  - **Why unresolved**: Experiments were limited to four European languages (English, French, German, Dutch) due to limited availability of cross-lingual debiasing benchmarks.
  - **What evidence would resolve it**: Experiments on non-European languages (e.g., Chinese, Arabic, Swahili) showing comparable debiasing performance and cross-lingual transfer rates.

- **Open Question 2**: How do other debiasing techniques perform when applied in the cross-lingual latent space?
  - **Basis in paper**: [explicit] The authors note: "we leave out other methods, such as Dropout Regularization (Webster et al., 2020), which could be considered in future studies."
  - **Why unresolved**: Only INLP and SentDebias were evaluated; the approach's compatibility with other debiasing methods remains untested.
  - **What evidence would resolve it**: Comparative experiments applying Dropout Regularization and other techniques in the latent space, measuring bias reduction and cross-lingual transfer.

- **Open Question 3**: Does the approach maintain debiasing effectiveness across different multilingual LLM architectures?
  - **Basis in paper**: [inferred] The paper primarily evaluates Aya-expanse-8B, with only brief appendix results for Llama3.1. Different LLM architectures may have different cross-lingual alignment properties.
  - **Why unresolved**: It is unclear whether the findings generalize beyond the specific model tested, particularly to encoder-only or encoder-decoder architectures.
  - **What evidence would resolve it**: Experiments across diverse multilingual LLMs (e.g., mBERT, XLM-R, BLOOM, mT5) showing consistent improvements from latent space debiasing.

## Limitations
- The approach's effectiveness depends on the assumption that parallel data can fully align cross-lingual representations in a shared latent space, which may not generalize to non-European languages with different scripts and linguistic structures
- The 128-dimensional bottleneck and 3-layer MLP architecture, while empirically optimal, may not be universally appropriate across different LLM architectures or tasks
- The autoencoder approach assumes that bias directions are language-invariant in the latent space, but if underlying bias encoding mechanisms differ fundamentally across languages, this assumption may fail

## Confidence

- **High Confidence**: The autoencoder successfully constructs a cross-lingually aligned latent space (supported by t-SNE visualizations showing overlapping clusters for parallel sentences versus language-separated clusters in original space)
- **Medium Confidence**: Applying debiasing techniques in the latent space significantly improves cross-lingual transferability (supported by consistent bias reduction patterns across evaluation languages, though magnitude varies by bias type)
- **Medium Confidence**: The approach works best when initial bias is statistically significant (>62.5% threshold) (supported by theoretical reasoning and empirical observations of overcompensation)

## Next Checks

1. **Domain Transferability Test**: Evaluate latent space alignment quality on out-of-domain parallel data (e.g., FLORES+ or other multilingual corpora) to verify the autoencoder generalizes beyond TED talks
2. **Architecture Ablation Study**: Systematically vary bottleneck dimension (64, 128, 256, 512) and encoder depth (1-4 layers) to map the full parameter space and confirm 128-dim/3-layer optimal configuration
3. **Single-Language Debiasing Comparison**: Debias using only English data in both original and latent spaces, then evaluate bias scores on French/German/Dutch to directly quantify the cross-lingual transferability advantage claimed