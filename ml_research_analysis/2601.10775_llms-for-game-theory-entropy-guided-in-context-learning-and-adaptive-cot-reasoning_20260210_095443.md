---
ver: rpa2
title: 'LLMs for Game Theory: Entropy-Guided In-Context Learning and Adaptive CoT
  Reasoning'
arxiv_id: '2601.10775'
source_url: https://arxiv.org/abs/2601.10775
tags:
- reasoning
- game
- entropy
- context
- uncertainty
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces a framework for improving large language
  model (LLM) reasoning in sequential decision-making tasks, demonstrated using Tic-Tac-Toe.
  The core method combines entropy-guided context retrieval with adaptive chain-of-thought
  reasoning: the model retrieves relevant past game states and actions based on uncertainty,
  and dynamically adjusts reasoning depth when confidence is low.'
---

# LLMs for Game Theory: Entropy-Guided In-Context Learning and Adaptive CoT Reasoning

## Quick Facts
- arXiv ID: 2601.10775
- Source URL: https://arxiv.org/abs/2601.10775
- Reference count: 40
- One-line primary result: Entropy-guided context retrieval + adaptive CoT reasoning improves Tic-Tac-Toe outcomes from -11.6% to +9.5% while reducing LLM queries from ~188 to ~48 per game.

## Executive Summary
This paper introduces a framework for improving LLM reasoning in sequential decision-making tasks, demonstrated using Tic-Tac-Toe. The core method combines entropy-guided context retrieval with adaptive chain-of-thought reasoning: the model retrieves relevant past game states and actions based on uncertainty, and dynamically adjusts reasoning depth when confidence is low. Experimental results show that this approach increases the average game outcome from -11.6% to +9.5% over 100 games against a sub-optimal opponent, while maintaining fewer than 50 LLM queries per game. Statistical validation confirms the improvement is significant, and analysis shows a negative correlation between token-level entropy and move optimality, supporting the use of entropy as a proxy for uncertainty.

## Method Summary
The framework uses an autoencoder to encode board states into latent embeddings, which are stored in a contrastive-learned vector database with associated minimax-optimal moves. At each turn, token-level entropy from the LLM's output distribution scales the number of retrieved examples and the depth of reasoning paths. Low entropy triggers direct moves or single-path CoT; high entropy expands context retrieval and branches into multiple reasoning paths, retaining the most promising via entropy-based scoring. This adaptive mechanism reduces the number of LLM queries compared to exhaustive tree search while maintaining near-optimal performance.

## Key Results
- Entropy-guided context retrieval + adaptive CoT improves average game outcome from -11.6% to +9.5% over 100 games
- System uses ~48 LLM queries per game vs ~188 for exhaustive tree-based CoT
- Token-level entropy shows negative correlation (Spearman ρ = -0.471) with move optimality, supporting its use as uncertainty proxy

## Why This Works (Mechanism)

### Mechanism 1: Entropy-Guided Context Retrieval
Dynamically scaling retrieved examples based on model uncertainty improves decision quality over fixed-context baselines. At each turn, compute token-level entropy H_step from the LLM's output distribution. Retrieval size k scales as k = min(k_max, ⌈k_0 + α·H_q⌉), pulling semantically similar board states from a contrastive-learned vector database. Low entropy → minimal context; high entropy → expanded context. Core assumption: Boards with similar optimal actions cluster in latent space, and retrieved examples meaningfully inform the current state.

### Mechanism 2: Adaptive Chain-of-Thought Branching
Expanding reasoning paths only under high uncertainty achieves near-optimal performance with ~4× fewer LLM queries than exhaustive tree search. Define entropy thresholds H_0 < H_1 < ... < H_m. When H_step > H_th, generate n_t parallel CoT branches; retain top-k via entropy-based scoring. Low uncertainty triggers single-path reasoning. Core assumption: Token-level entropy accurately reflects decision uncertainty; high entropy correlates with suboptimal choices.

### Mechanism 3: Entropy-Optimality Negative Correlation
Token-level entropy serves as a statistically reliable proxy for move suboptimality in this domain. Compute average token entropy per output; correlate with move optimality percentile (minimax ranking). Spearman ρ = -0.471, Kendall τ = -0.346 (p < 10⁻³). Core assumption: The negative correlation generalizes beyond Tic-Tac-Toe to other sequential decision tasks.

## Foundational Learning

- Concept: Token-level entropy
  - Why needed here: Core signal for adaptive reasoning; quantifies model uncertainty over vocabulary at each generation step.
  - Quick check question: Can you compute H = -Σ p_i log(p_i) for a 3-token vocabulary with probabilities [0.7, 0.2, 0.1]?

- Concept: Contrastive learning for retrieval
  - Why needed here: Ensures latent embeddings cluster boards by optimal action, enabling meaningful nearest-neighbor retrieval.
  - Quick check question: What does the margin τ control in the contrastive loss formulation?

- Concept: Minimax optimality
  - Why needed here: Provides ground-truth move rankings for evaluation; the algorithmic opponent uses a softened minimax policy.
  - Quick check question: Why does Tic-Tac-Toe have a fully computable minimax solution while chess does not?

## Architecture Onboarding

- Component map:
  1. Autoencoder encoder (f_θ): Board → latent embedding z
  2. Contrastive training: Organizes latent space by optimal action
  3. Vector database D: Stores (z_i, m_i) pairs (~20% of states)
  4. Entropy monitor: Computes H_step from LLM token distributions
  5. Retrieval scaler: k = f(H_q) per Equation 12
  6. CoT controller: Selects reasoning mode based on entropy thresholds
  7. Game loop: Orchestrates LLM ↔ opponent turns

- Critical path: Board state → encoder → retrieval → prompt construction → LLM inference → entropy computation → adaptive CoT branching → move selection

- Design tradeoffs:
  - Larger retrieval database improves coverage but increases memory and potential redundancy conflicts
  - More entropy threshold levels enable finer-grained adaptation but require more tuning
  - Tree-based CoT gives highest performance (+9.8%) but at 4× query cost vs entropy-guided (+9.5%, 48 queries)

- Failure signatures:
  - High entropy on first move (false positive) → mitigated by disabling branching on move 1
  - Invalid move outputs → reprompt; if still invalid, random valid move fallback
  - Retrieval returns boards with conflicting optimal actions → may confuse reasoning

- First 3 experiments:
  1. Baseline calibration: Run LLM with no context, no CoT; verify ~-11.6% outcome matches paper baseline
  2. Ablation: context only: Enable entropy-guided retrieval, disable adaptive CoT; expect ~-2.8% outcome
  3. Full system validation: Enable both entropy-guided retrieval and adaptive CoT; target +9.5% outcome with ~48 queries/game

## Open Questions the Paper Calls Out

### Open Question 1
Does entropy-guided adaptive reasoning retain its efficiency advantages when scaled to games with larger state spaces (e.g., Connect Four, Go)? Basis: Section 7 states the framework should be tested for scalability under higher-dimensional state representations. Unresolved because Tic-Tac-Toe has only ~3,000 unique states; complex games have exponentially larger spaces. Evidence needed: Experiments showing comparable win-rate improvements and query reductions in Connect Four or similar games.

### Open Question 2
Do entropy-guided mechanisms provide meaningful benefits when applied to stronger base models (e.g., GPT-4, Gemini) that may already perform intrinsic multi-step reasoning? Basis: Section 7 notes LLaMA-7B "has limited reasoning capacity" and states future work should test whether entropy-guided mechanisms still offer benefits. Unresolved because stronger models may have lower baseline entropy or handle uncertainty internally. Evidence needed: Comparative experiments using larger models with and without entropy-guided adaptation.

### Open Question 3
Would alternative uncertainty estimators (e.g., ensemble variance, mutual information) provide more reliable signals for adaptive reasoning than token-level entropy alone? Basis: Section 7 states alternative uncertainty estimators could provide a more reliable signal. Unresolved because token-level entropy correlation with move optimality was only ρ=−0.471, and high entropy sometimes reflects multiple equally-optimal moves. Evidence needed: Head-to-head comparison of different uncertainty measures correlating each with ground-truth decision quality.

### Open Question 4
Can the framework generalize to domains with non-deterministic dynamics and incomplete information where the full game tree is unavailable? Basis: Section 7 notes the retrieval database "may not generalize to domains with incomplete or biased data," and Section 8 states future extensions will explore applying this mechanism to domains with non-deterministic dynamics. Unresolved because the current retrieval database uses precomputed minimax-optimal moves for all states; such complete knowledge is unavailable in poker or negotiation. Evidence needed: Experiments in stochastic or partially observable environments where retrieval examples come from incomplete trajectories.

## Limitations
- Entropy-optimality correlation established only for Tic-Tac-Toe with specific opponent model; generalization to other domains untested
- Contrastive loss formulation relies on optimal-move clustering that may not transfer to domains without deterministic ground truth
- Retrieval quality depends critically on unspecified autoencoder architecture and 20% state sampling rate

## Confidence
- **High confidence**: Outcome improvements are statistically significant (p < 0.05 via paired t-test); query count reduction vs exhaustive search is well-documented
- **Medium confidence**: Entropy serves as a reliable proxy for uncertainty in this specific domain; mechanism of entropy-guided retrieval improving outcomes is well-supported
- **Low confidence**: Generalization of entropy-optimality correlation beyond Tic-Tac-Toe; effectiveness of contrastive clustering approach in non-deterministic domains

## Next Checks
1. Apply the full entropy-guided adaptive CoT system to a different sequential decision task (e.g., Connect Four) and measure whether the entropy-optimality correlation holds and whether performance gains persist
2. Systematically vary the proportion of states stored in the vector database (e.g., 10%, 20%, 30%) and measure impact on both outcome improvement and query efficiency
3. Perform a grid search over entropy thresholds H_j and retrieval parameters (k_0, k_max, α) to determine whether reported performance is robust to hyperparameter variation