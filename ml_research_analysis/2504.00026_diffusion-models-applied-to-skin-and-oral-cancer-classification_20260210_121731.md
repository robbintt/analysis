---
ver: rpa2
title: Diffusion models applied to skin and oral cancer classification
arxiv_id: '2504.00026'
source_url: https://arxiv.org/abs/2504.00026
tags:
- dataset
- images
- diffusion
- cancer
- pad-ufes-20
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study investigates the use of diffusion models for medical
  image classification, focusing on skin and oral cancer detection. The authors apply
  the DiffMIC model, a diffusion-based approach, to two datasets: PAD-UFES-20 for
  skin cancer and P-NDB-UFES for oral cancer.'
---

# Diffusion models applied to skin and oral cancer classification

## Quick Facts
- arXiv ID: 2504.00026
- Source URL: https://arxiv.org/abs/2504.00026
- Reference count: 35
- Primary result: DiffMIC achieves 0.9050 balanced accuracy for oral cancer classification on P-NDB-UFES dataset

## Executive Summary
This study investigates the application of diffusion models for medical image classification, specifically for skin and oral cancer detection. The authors apply the DiffMIC model, a diffusion-based approach, to two datasets: PAD-UFES-20 for skin cancer and P-NDB-UFES for oral cancer. The model demonstrates competitive performance compared to traditional CNNs and Transformer-based approaches, with balanced accuracy of 0.9050 for oral cancer classification and 0.8357 for binary skin cancer classification. The study also evaluates the model's robustness on an external dataset, revealing limitations in generalization.

## Method Summary
The study applies the DiffMIC diffusion model to medical image classification tasks. DiffMIC uses a Dual-granularity Conditional Guidance mechanism with ResNet18 as the backbone for both global and local encoders. The U-Net denoiser has 6,144 features, and the model processes 224×224×3 input images through 1,000 diffusion steps. Training uses Adam optimizer with learning rate 0.001, batch size 30, and 150 epochs without early stopping. Weighted cross-entropy loss is employed for handling class imbalance. The model is evaluated on PAD-UFES-20 (skin cancer, 6-class and binary classification) and P-NDB-UFES (oral cancer, 3-class classification) datasets using 5/6 train, 1/6 test split via K-Fold cross-validation.

## Key Results
- DiffMIC achieves balanced accuracy of 0.6457 for six-class skin cancer classification and 0.8357 for binary classification on PAD-UFES-20
- For oral cancer classification on P-NDB-UFES, DiffMIC attains balanced accuracy of 0.9050
- The model demonstrates competitive performance compared to traditional CNNs and Transformer-based approaches
- Generalization testing on the HIBA dataset shows limitations, with accuracy dropping significantly (from 64.57% to 46.32% for 6-class classification)

## Why This Works (Mechanism)
Diffusion models work by learning to denoise corrupted data through a Markov chain process. In DiffMIC, the Dual-granularity Conditional Guidance mechanism allows the model to capture both global and local features simultaneously, which is particularly beneficial for medical image classification where both contextual and fine-grained details are important. The model gradually refines its predictions through iterative denoising steps, making it effective at capturing complex patterns in medical imagery.

## Foundational Learning

**Diffusion Models**
- Why needed: Understanding the core denoising process that forms the basis of DiffMIC
- Quick check: Verify the forward and reverse diffusion processes are correctly implemented

**Conditional Guidance**
- Why needed: The Dual-granularity approach is central to DiffMIC's performance
- Quick check: Confirm both global and local encoders are properly integrated

**Medical Image Classification**
- Why needed: Domain-specific challenges like class imbalance and subtle feature differences
- Quick check: Validate class weights are appropriately set for imbalanced datasets

**Cross-Validation**
- Why needed: Ensures robust evaluation across different data splits
- Quick check: Confirm K-Fold implementation matches the paper's methodology

## Architecture Onboarding

**Component Map**
- Input Images (224×224×3) -> Global and Local Encoders (ResNet18) -> Dual-granularity Conditional Guidance -> U-Net Denoiser (6,144 features) -> Classification Output

**Critical Path**
The critical path is: Input -> Dual-granularity Encoders -> U-Net Denoiser -> Classification. The U-Net denoiser with 6,144 features and the dual-encoder architecture are the most critical components for achieving high accuracy.

**Design Tradeoffs**
The choice of ResNet18 as the backbone balances computational efficiency with feature extraction capability. The 1,000 diffusion steps provide sufficient refinement but increase computational cost. The weighted cross-entropy addresses class imbalance but requires careful weight selection.

**Failure Signatures**
- Using SGD instead of Adam leads to poor convergence (<50% accuracy)
- Early stopping significantly degrades performance compared to full 150-epoch training
- Poor generalization on external datasets (expected limitation, not a training bug)

**First Experiments**
1. Verify basic training on a single fold completes without errors
2. Compare baseline CNN performance to DiffMIC on a small subset
3. Test the effect of weighted cross-entropy by training with and without class weights

## Open Questions the Paper Calls Out
None

## Limitations
- The model shows significant performance degradation when tested on external datasets (e.g., HIBA dataset), indicating limited generalization capability
- The study does not provide detailed information about data augmentation strategies, which could impact reproducibility
- Class weights for weighted cross-entropy loss are not specified, which is critical for handling imbalanced datasets

## Confidence

| Claim | Confidence |
|-------|------------|
| DiffMIC achieves competitive performance on PAD-UFES-20 and P-NDB-UFES | High |
| The model has limitations in generalization to external datasets | High |
| DiffMIC outperforms traditional CNNs and Transformers on these datasets | Medium (based on comparison claims) |

## Next Checks
1. Verify the exact class weights used for weighted cross-entropy on the imbalanced PAD-UFES-20 dataset
2. Confirm the data augmentation pipeline matches the original DiffMIC implementation
3. Test the model's performance with early stopping disabled to validate the claim that full 150 epochs are necessary for optimal results