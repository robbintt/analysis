---
ver: rpa2
title: 'HiCaM: A Hierarchical-Causal Modification Framework for Long-Form Text Modification'
arxiv_id: '2505.24319'
source_url: https://arxiv.org/abs/2505.24319
tags:
- text
- modification
- delmar
- length
- entities
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of long-form text modification (LTM),
  where large language models struggle with undesired changes and missing updates
  to implicitly related content. The authors propose HiCaM, a Hierarchical-Causal
  Modification framework that uses a hierarchical summary tree and a causal graph
  to guide entity-aware, logically coherent edits.
---

# HiCaM: A Hierarchical-Causal Modification Framework for Long-Form Text Modification

## Quick Facts
- arXiv ID: 2505.24319
- Source URL: https://arxiv.org/abs/2505.24319
- Reference count: 40
- Primary result: HiCaM achieves up to 79.50% win rate and 59.50% net win rate on long-form text modification tasks

## Executive Summary
This paper addresses the challenge of long-form text modification (LTM), where large language models struggle with undesired changes and missing updates to implicitly related content. The authors propose HiCaM, a Hierarchical-Causal Modification framework that uses a hierarchical summary tree and a causal graph to guide entity-aware, logically coherent edits. Experiments on a multi-domain dataset show HiCaM consistently improves over strong baselines, achieving up to 79.50% win rate and 59.50% net win rate, with performance gains particularly notable on datasets with strong internal logical structure. The framework operates as a plug-and-play module, requiring no additional training.

## Method Summary
HiCaM operates through a four-step pipeline: (1) Extract top-5 key entities from modification suggestions using an LLM, including importance scores and modification hints; (2) Optionally chunk text into ~4096-token segments; (3) Build a hierarchical entity-oriented summary tree and entity causal graph in parallel; (4) Generate tree-structured modification suggestions using both structures, then produce final modified text. The framework combines hierarchical scope control with causal propagation to ensure both local precision and global coherence in long-form modifications.

## Key Results
- Win rates of 56.81–79.50% across four LLMs on seven benchmark datasets
- Consistent improvement over baseline methods in faithfulness, logical coherence, and fluency
- 20.74% average win-rate drop on logic-heavy datasets when causal graph is ablated
- Maintains closer output-to-input length ratios compared to baselines, reducing excessive summarization

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Entity-Oriented Summary Tree Constrains Modification Scope
Structuring text as a recursive summary tree organized around key entities reduces undesired modifications by enabling localized, granularity-aware edits. The framework extracts top-k entities, then recursively segments text into sub-sections tied to those entities. Each node carries a summary, start/end positions, and modification directives. The tree is traversed during generation; nodes flagged as irrelevant are skipped entirely, preventing cascade rewriting of unrelated content.

### Mechanism 2: Causal Graph Propagates Implicit Dependencies
An entity-level causal graph captures logical relations, enabling modification propagation to implicitly relevant passages. For each chunk, an LLM extracts nodes (entities) and directed edges (e.g., "causes," "depends on"). Local graphs merge into a global graph. During final modification, the graph is queried to identify downstream entities affected by a change, ensuring edits like "strained relationship → fewer visits → less interaction" chain correctly.

### Mechanism 3: Tree-Structured Modification Suggestions Integrate Both Structures
Generating modification suggestions in tree form, with causal graph consultation, ensures coherent and complete final output. The summary tree provides the backbone (which segments to modify). The causal graph provides cross-segment logic (which entities must change together). Tree nodes receive modification directives only if relevant; unmodified nodes are preserved verbatim. The final output is synthesized by applying these structured directives.

## Foundational Learning

- **Concept**: Hierarchical document representation (e.g., RAPTOR-style trees, document graphs)
  - Why needed here: HiCaM builds a recursive summary tree; understanding how trees represent multi-granularity content is essential for debugging segmentation quality.
  - Quick check question: Given a 10,000-word document, sketch a 3-level hierarchy: what would the root, mid-level, and leaf nodes summarize?

- **Concept**: Causal / knowledge graphs for entities
  - Why needed here: The causal graph models entity relationships; basic graph literacy (nodes, edges, traversal) is required to interpret and validate extracted relations.
  - Quick check question: If entity A "causes" B and B "affects" C, which entities must be updated if A is modified?

- **Concept**: Long-context LLM limitations (forgetting, length plateauing)
  - Why needed here: HiCaM's motivation stems from LLM failure modes in long-form tasks; knowing why models summarize prematurely or lose mid-context helps assess when the framework adds value.
  - Quick check question: Why might an LLM's output length plateau even when asked to generate a full-length revised document?

## Architecture Onboarding

- **Component map**: Entity Extractor -> Chunker (optional) -> Summary Tree Builder -> Causal Graph Builder -> Modification Synthesizer

- **Critical path**: Entity extraction → chunking → parallel tree/graph construction → integrated suggestion generation → final output. Parallelize tree and graph construction per chunk to reduce latency.

- **Design tradeoffs**:
  - Chunk size: Smaller chunks (2048) increase tree nodes and noise; larger (8192 or no limit) reduce nodes but may miss fine structure. Paper selects 4096 as balance.
  - Tree depth: Depth 1 is default; deeper trees capture more granularity but increase cost and hallucination risk.
  - Top-k entities: Top-5 is optimal; top-3 may miss important entities; no filtering introduces noise.

- **Failure signatures**:
  - Over-modification: Output much shorter than input; likely tree nodes incorrectly flagged for modification or excessive summarization.
  - Under-propagation: Inconsistent character/plot logic; causal graph missing edges or graph not consulted during synthesis.
  - Noisy graphs: Spurious edges cause irrelevant propagation; check LLM prompts for extraction specificity.

- **First 3 experiments**:
  1. Reproduce main result on NarrativeQA subset: Run HiCaM with GPT-4o-mini, compare win rate vs. baseline direct prompting. Confirm ~60%+ win rate.
  2. Ablate causal graph: Run same setup without causal graph; expect 10–20% win-rate drop on logic-heavy datasets (e.g., QuALITY).
  3. Vary chunk size on one dataset: Test 2048, 4096, 8192 on MultiFieldQA-en; observe win rate and node count tradeoffs.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent does HiCaM generalize to languages beyond English and Chinese, particularly those with different grammatical structures or morphological complexity?
- Basis in paper: The Limitations section states, "Our current evaluation is primarily conducted on English datasets (7 out of 8 datasets), with only limited testing on Chinese... more extensive validation across diverse languages would be needed to verify this capability fully."
- Why unresolved: The authors acknowledge that while the framework is designed to be plug-and-play, the entity extraction and causal graph construction rely on LLM capabilities which may vary significantly across languages not tested in the study.
- What evidence would resolve it: Evaluation results on a multilingual benchmark (e.g., incorporating low-resource or non-Latin script languages) showing that the hierarchical summary tree and causal graph maintain structural integrity across varied linguistic typologies.

### Open Question 2
- Question: Can parallelization strategies effectively mitigate the 2-3x computational overhead of the framework without degrading the quality of long-form text modifications?
- Basis in paper: The Limitations section notes, "our framework incurs approximately 2-3 times higher computational cost... However, we emphasize that this overhead can be effectively mitigated through parallelization strategies."
- Why unresolved: The paper claims parallelization is a solution because components are generated independently, but it provides no experimental data or implementation details proving that parallel execution achieves real-time efficiency while maintaining the 79.50% win rate.
- What evidence would resolve it: System benchmarks comparing the latency and throughput of a parallelized HiCaM implementation against the sequential baseline, alongside a verification that modification quality (win rate) remains constant under parallel execution.

### Open Question 3
- Question: Does adopting semantic similarity-based chunking significantly improve performance over the current token-aware splitting method?
- Basis in paper: Appendix C states: "In future work, semantic similarity-based chunking methods may also be explored to further preserve semantic continuity and improve overall performance."
- Why unresolved: The current method relies on structural cues (newlines/punctuation) and token limits, which risks splitting related semantic concepts between chunks, potentially fragmenting the hierarchical summary tree.
- What evidence would resolve it: An ablation study comparing the current token-aware chunking against a semantic chunking approach, specifically analyzing the rate of "missing necessary modifications" in segments straddling chunk boundaries.

### Open Question 4
- Question: How do human evaluators rate the "logical coherence" and "faithfulness" of HiCaM outputs compared to the GPT-4o automated evaluation?
- Basis in paper: The paper relies entirely on GPT-4o for evaluation. While Appendix E discusses biases, it does not validate the judge's alignment with human preference for this specific task.
- Why unresolved: Automated metrics often struggle to detect subtle logical inconsistencies in long-form narratives. The high win rates (up to 79.50%) might reflect the judge's alignment with specific stylistic patterns rather than true semantic improvement.
- What evidence would resolve it: A human evaluation study where annotators blindly rank the outputs of HiCaM versus baselines, specifically checking for the two failure modes defined in the paper: undesired modifications and missing implicit modifications.

## Limitations

- Evaluation framework relies heavily on GPT-4o as automated judge, introducing potential bias
- Exact prompt templates for entity extraction, causal graph construction, and modification synthesis are not provided
- Framework's performance on highly technical documents is not explored
- Computational costs and latency of the multi-step pipeline are not addressed

## Confidence

- **High confidence**: The hierarchical summary tree mechanism effectively constrains modification scope, as evidenced by length ratio analysis
- **Medium confidence**: The causal graph propagation mechanism shows measurable benefit on logic-heavy datasets, though potential for LLM hallucination introduces uncertainty
- **Medium confidence**: Overall win-rate improvements are compelling, but dependence on GPT-4o evaluation prevents high-confidence claims about real-world performance

## Next Checks

1. Reproduce length ratio analysis: Compare output-to-input length ratios for HiCaM vs. baseline across varying input lengths to verify that HiCaM maintains more consistent document lengths
2. Validate causal graph impact on logic-heavy datasets: Run ablation study removing causal graph on NarrativeQA, QuALITY, and QMSum; confirm 10–20% win-rate drop specifically on these datasets
3. Test robustness to entity extraction noise: Systematically corrupt entity extraction by removing 1–3 entities from top-5; measure degradation in win rate to assess framework sensitivity