---
ver: rpa2
title: 'Mitrasamgraha: A Comprehensive Classical Sanskrit Machine Translation Dataset'
arxiv_id: '2601.07314'
source_url: https://arxiv.org/abs/2601.07314
tags:
- sanskrit
- dataset
- translation
- classical
- sentence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Mitrasamgraha, the largest publicly available
  Sanskrit-English machine translation dataset, containing 391,548 bitext pairs covering
  six literary domains and three millennia of Sanskrit. The dataset was created using
  BertAlign for sentence alignment, followed by manual inspection and post-correction.
---

# Mitrasamgraha: A Comprehensive Classical Sanskrit Machine Translation Dataset

## Quick Facts
- arXiv ID: 2601.07314
- Source URL: https://arxiv.org/abs/2601.07314
- Reference count: 25
- Largest publicly available Sanskrit-English MT dataset with 391,548 bitext pairs across six literary domains

## Executive Summary
The paper introduces Mitrasamgraha, the largest publicly available Sanskrit-English machine translation dataset, containing 391,548 bitext pairs covering six literary domains and three millennia of Sanskrit. The dataset was created using BertAlign for sentence alignment, followed by manual inspection and post-correction. The authors evaluate automatic MT metrics, finding that neural BLEURT and LLM-based GEMBA/GEMBA* scores correlate most strongly with expert human judgments, outperforming BLEU and chrF. They benchmark both commercial and open models, showing that fine-tuning NLLB and Gemma models on Mitrasamgraha significantly improves translation quality, though challenges remain in handling complex compounds, philosophical concepts, and multi-layered metaphors. The dataset and models are publicly released to support Sanskrit NLP research.

## Method Summary
The Mitrasamgraha dataset was constructed through web scraping and OCR of Sanskrit texts, followed by sentence alignment using BertAlign with fine-tuned LaBSE embeddings. Manual inspection and deterministic post-correction were applied to ensure quality. The dataset contains 391,548 training pairs, 5,587 validation pairs, and 5,552 test pairs across six domains. The authors evaluate both commercial (Google Translate, GPT-4o, Claude, Gemini) and open-source models (NLLB, MADLAD-400, IndicTrans2, Llama-3.1, Gemma-2) using BLEU, chrF, BLEURT-20, and GEMBA metrics. Fine-tuning experiments were conducted on NLLB-200 (600M and 3.3B parameters) and Gemma-2 9B models, with retrieval-augmented generation (RAG) implemented for commercial models using a fine-tuned LaBSE retriever.

## Key Results
- Fine-tuning NLLB-600M improves GEMBA from 8.08 to 71.07 on the test set
- Gemma-2 9B fine-tuned achieves GEMBA 83.34, outperforming commercial models
- Neural evaluation metrics (BLEURT, GEMBA) correlate more strongly with expert human judgments (Pearson ρ ~0.55) than string-based metrics (BLEU, chrF)
- RAG augmentation improves Claude 3.7 Sonnet from GEMBA 86.24 to 89.32

## Why This Works (Mechanism)

### Mechanism 1
Providing a large-scale, domain-diverse parallel corpus enables fine-tuning to significantly improve translation quality for low-resource classical languages. Fine-tuning on 391k curated bitext pairs adapts model weights to Sanskrit's specific linguistic patterns (sandhi, compounding, free word order), yielding significant gains over zero-shot baselines. Core assumption: sufficient architectural capacity and optimization hyperparameters exist for the signal in 391k examples to be captured without overfitting. Evidence anchors: fine-tuning NLLB and Gemma models on Mitrasamgraha significantly improves translation quality; NLLB 600M fine-tuned improves GEMBA from 8.08 to 71.07; Gemma2 9B fine-tuned achieves GEMBA 83.34. Break condition: performance plateaus or degrades despite more data, suggesting model capacity constraints or data noise overwhelming the learning signal.

### Mechanism 2
Neural evaluation metrics (BLEURT, LLM-based GEMBA) correlate more strongly with expert human judgments than string-based metrics (BLEU, chrF) for Sanskrit-English MT. Learned or LLM-based evaluators capture semantic adequacy and structural nuances (free word order, multi-layered metaphor) that surface n-gram overlap misses. Core assumption: the human annotation sample (100 sentences, 3 translations each) is representative of broader Sanskrit MT quality distribution. Evidence anchors: neural BLEURT and LLM-based GEMBA/GEMBA* scores correlate most strongly with expert human judgments, outperforming BLEU and chrF; higher Pearson/Spearman correlations for BLEURT/GEMBA vs BLEU/chrF. Break condition: if BLEURT/GEMBA scores diverge significantly from human judgment on new domains (e.g., technical treatises), correlation may not hold.

### Mechanism 3
Retrieval-Augmented Generation (RAG) with in-context examples improves commercial LLM translation by providing relevant reference pairs. A fine-tuned LaBSE retriever fetches similar Sanskrit-English pairs injected into the prompt, enabling dynamic adaptation of output style and vocabulary. Core assumption: the retriever surfaces semantically relevant examples; context window limits do not degrade example quality. Evidence anchors: Claude 3.7 Sonnet + RAG improves GEMBA from 86.24 to 89.32; all commercial models that have in-context learning abilities benefit significantly from retrieval augmentation. Break condition: retrieved examples are misaligned or context saturation occurs, leading to degraded or negligible improvement.

## Foundational Learning

- **Concept: Bitext alignment (one-to-many, many-to-one mappings)**
  - Why needed here: Sanskrit-English sentence boundaries diverge due to punctuation and translation style; understanding alignment quality (F_A vs F_S) is critical for dataset reliability.
  - Quick check question: Why might sentence-level F-measure (F_S) be more informative than alignment-level F-measure (F_A) for noisy Sanskrit-English pairs?

- **Concept: Sandhi and Compounding in Sanskrit**
  - Why needed here: These features merge word boundaries and create dense expressions, challenging both alignment and translation models.
  - Quick check question: How does sandhi affect surface-based metrics like BLEU, and why might learned metrics be more robust?

- **Concept: Domain Shift and Temporal Coverage**
  - Why needed here: The dataset spans three millennia and six domains; models trained on one period/genre may not generalize without targeted evaluation.
  - Quick check question: If a model fine-tuned on Epic Sanskrit is tested on Vedic hymns, what performance degradation signals would you monitor?

## Architecture Onboarding

- **Component map:**
  - Source identification -> Web scraping/OCR -> Manual cleaning -> Sentence segmentation -> BertAlign -> Post-correction
  - Commercial LLMs (GPT-4o, Claude, Gemini) -> Open MT (NLLB, MADLAD-400, IndicTrans2) -> Open LLMs (Llama-3.1, Gemma-2)
  - BLEU, chrF, BLEURT, GEMBA (reference-based & reference-free), human expert ranking
  - LaBSE fine-tuned retriever -> Top-k similar pairs -> Prompt injection

- **Critical path:**
  1. Verify data license compliance (CC BY-NC-ND 4.0 vs CC BY-SA 4.0 subset)
  2. Run alignment sanity check on sample (F_S > 0.7 threshold)
  3. Establish baseline metrics (BLEU, chrF, BLEURT, GEMBA) on test set
  4. Fine-tune target model on training split
  5. Evaluate; iterate with data cleaning (deterministic vs LLM-based)

- **Design tradeoffs:**
  - Full dataset (391k, CC BY-NC-ND) vs research-friendly subset (372k, CC BY-SA 4.0): scale vs usability
  - Deterministic cleaning vs LLM-based cleaning: cost vs noise reduction efficacy
  - Encoder-decoder (NLLB, MADLAD) vs decoder-only LLM (Gemma, Llama): zero-shot vs fine-tuning performance

- **Failure signatures:**
  - Low F_S alignment (<0.7) in specific domains -> noisy bitext pairs
  - Large BLEU/chrF vs BLEURT/GEMBA gap -> semantic adequacy uncaptured by surface metrics
  - Fine-tuned models underperform commercial baselines significantly -> insufficient capacity or hyperparameter issues
  - RAG-augmented performance drops -> retriever surfaces irrelevant examples or context overflow

- **First 3 experiments:**
  1. Reproduce baseline metrics on the 5,552-pair test set for Google Translate, GPT-4o-mini, and Gemma-2 9B Instruct
  2. Fine-tune NLLB-600M on training split; evaluate delta across all four metrics
  3. Implement RAG with LaBSE retriever on Claude 3.7 Sonnet; measure GEMBA improvement vs non-RAG baseline and qualitatively analyze retrieved example relevance

## Open Questions the Paper Calls Out

- **Open Question 1:** How does the inclusion of specialized technical domains, such as astronomy or mathematics, impact the performance and generalization of Sanskrit-to-English translation models? Basis: Section 11 states that specialized domains like technical treatises on astronomy or mathematics "remain entirely missing or are severely underrepresented" and require "dedicated future data collection." Why unresolved: The current dataset focuses primarily on literary, philosophical, and religious texts, leaving a gap in understanding how MT systems handle the distinct terminology and syntactic structures of scientific Sanskrit. What evidence would resolve it: A comparative benchmark study evaluating model performance before and after fine-tuning on a newly curated corpus of scientific and technical Sanskrit texts.

- **Open Question 2:** Can LLM-based cleaning strategies be refined to outperform deterministic methods for Sanskrit bitext alignment, given their current underperformance? Basis: Section 9 reports that the dataset cleaned with Gemini 1.5 prompting "visibly underperforms compared to both the uncleaned base dataset and the deterministically cleaned dataset," suggesting the prompting strategy or model capability for this specific task is not yet optimal. Why unresolved: The paper tests one specific LLM-based cleaning implementation, but does not explore why it failed or if different prompts or models could align better with expert judgments of alignment quality. What evidence would resolve it: An ablation study testing varied prompt engineering strategies or different LLM architectures specifically for the task of alignment error detection and correction.

- **Open Question 3:** What specific architectural or training improvements are necessary to accurately translate complex Sanskrit linguistic features like multi-layered metaphors and philosophical concepts? Basis: Section 11 notes that the dataset "does not inherently solve deep semantic challenges" and that "current models... might still struggle to adequately capture these nuanced linguistic phenomena." Why unresolved: While the paper establishes that fine-tuning improves metrics, a solution for the "uniquely challenging case" of deep semantic transfer in Sanskrit literature remains unidentified. What evidence would resolve it: A qualitative error analysis showing a model successfully disambiguating complex compounds (samāsa) and metaphors without hallucination, potentially through augmenting MT with external knowledge bases.

## Limitations

- Dataset construction relies on web scraping and OCR, which may introduce noise despite manual post-correction, with alignment quality varying across domains (F_S ranges from 0.84 to 0.92)
- Expert human evaluation was conducted on only 100 sentences, limiting the statistical power of correlation analyses between automatic metrics and human judgments
- The paper focuses exclusively on Sanskrit-English translation, limiting generalizability to other classical language pairs without additional validation

## Confidence

- **High Confidence:** The dataset's scale (391,548 pairs) and domain coverage (six literary domains spanning three millennia) are verifiable through the public release and clearly documented in tables. The correlation findings for neural metrics (BLEURT, GEMBA) over string-based metrics (BLEU, chrF) are supported by multiple correlation coefficients and visual evidence.
- **Medium Confidence:** The performance improvements from fine-tuning NLLB and Gemma models are well-demonstrated, but the exact hyperparameters and training procedures are not fully specified, making exact reproduction challenging. The RAG system's effectiveness is shown but lacks detailed ablation studies on retriever quality.
- **Low Confidence:** Claims about handling "complex compounds, philosophical concepts, and multi-layered metaphors" are supported by qualitative examples but lack systematic quantitative evaluation across these specific challenges.

## Next Checks

1. **Alignment Quality Audit:** Sample 100 aligned sentence pairs across all six domains and manually verify F_S scores, particularly focusing on the Vedic domain (8.2% of dataset) which showed the lowest alignment quality (F_S = 0.84).

2. **Domain Generalization Test:** Evaluate fine-tuned models on domain-specific subsets (Epic, Purāṇa, Vedic, etc.) to quantify performance variance and identify which domains benefit most from fine-tuning.

3. **Compound and Metaphor Handling Analysis:** Create a focused test set of 50 sentences containing complex Sanskrit compounds and philosophical metaphors, then analyze translation quality through expert human evaluation to validate claims about model limitations in these areas.