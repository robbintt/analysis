---
ver: rpa2
title: A Multimodal Foundation Model to Enhance Generalizability and Data Efficiency
  for Pan-cancer Prognosis Prediction
arxiv_id: '2509.12600'
source_url: https://arxiv.org/abs/2509.12600
tags:
- multimodal
- data
- mice
- cancer
- prognosis
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MICE (Multimodal data Integration via Collaborative
  Experts), a multimodal foundation model designed to integrate pathology images,
  clinical reports, and genomics data for pan-cancer prognosis prediction. MICE employs
  a novel collaborative multi-expert module with functionally diverse expert groups
  to capture both cross-cancer correlations and cancer-specific insights, combined
  with a dual pre-training strategy using contrastive and supervised learning.
---

# A Multimodal Foundation Model to Enhance Generalizability and Data Efficiency for Pan-cancer Prognosis Prediction

## Quick Facts
- arXiv ID: 2509.12600
- Source URL: https://arxiv.org/abs/2509.12600
- Reference count: 40
- Primary result: MICE achieves 3.8-11.2% C-index improvement on internal cohorts and 5.8-8.8% on independent cohorts for pan-cancer prognosis prediction

## Executive Summary
This paper introduces MICE (Multimodal data Integration via Collaborative Experts), a foundation model that integrates pathology images, clinical reports, and genomics data for pan-cancer prognosis prediction. The model employs a novel collaborative multi-expert architecture with functionally diverse expert groups (Consensual, Specialized, and Overlapping) combined with a dual pre-training strategy using contrastive and supervised learning. Trained on 11,799 patients across 30 cancer types, MICE demonstrates substantial improvements in prognostic accuracy and remarkable data efficiency, achieving comparable performance to fully-trained models when fine-tuned with only 50% of samples.

## Method Summary
MICE integrates three modalities (WSI pathology images, clinical text reports, and genomics data) using a collaborative multi-expert architecture. The model features functionally distinct expert groups: Consensual experts learn pan-cancer patterns, Specialized experts capture cancer-specific insights, and Overlapping experts (selected via a router) model clusters of related cancer types. A dual pre-training strategy combines contrastive learning with supervised survival loss to prevent the tight clustering problem common in pure contrastive approaches. Missing modalities are handled through intra-modal synthesis using Self-Normalizing Networks. The model is pre-trained on TCGA data and fine-tuned on three independent cohorts, demonstrating both superior performance and data efficiency.

## Key Results
- C-index improvements of 3.8-11.2% on internal cohorts compared to existing multimodal models
- 5.8-8.8% C-index improvements on independent cohorts (Hancock, SNUH, ZJU)
- Achieves comparable performance to fully-trained models when fine-tuned with only 50% of training samples
- Robust performance across 30 cancer types with varying sample sizes and modality availability

## Why This Works (Mechanism)

### Mechanism 1: Functionally Diverse Expert Groups
The model partitions the knowledge space across 30 cancer types using Consensual, Specialized, and Overlapping experts. Consensual experts learn universal pan-cancer patterns, Specialized experts isolate cancer-specific biomarkers, and Overlapping experts (via router) capture clusters of related cancer types. This division of labor enables modeling of both global correlations and local anomalies, addressing the heterogeneity challenge across diverse cancer types.

### Mechanism 2: Hybrid Pre-training Strategy
Standard contrastive learning risks creating overly compact patient clusters that obscure survival risk variance. By coupling contrastive alignment with supervised Negative Log-Likelihood loss on survival data, the model forces the latent space to organize by risk trajectory rather than just patient identity. This preserves biological heterogeneity while maintaining discriminative power for prognostic tasks.

### Mechanism 3: Missing Modality Synthesis
Clinical datasets often lack one modality, but instead of excluding these samples or zero-imputing, MICE synthesizes missing representations using Self-Normalizing Networks based on cancer embeddings. This enables training on the full distribution of available data, enhancing robustness and data efficiency while avoiding the information loss from sample exclusion.

## Foundational Learning

- **Mixture of Experts (MoE) vs. Multi-Head Classifiers**
  - *Why needed:* MICE modifies standard MoE by introducing fixed Specialized and Consensual experts alongside dynamic ones. You must distinguish between routing conditioned on input vs. routing conditioned on cancer type.
  - *Quick check:* Can you explain why a standard MoE might fail to learn a "consensus" pattern across all cancers? (Hint: In standard MoE, no single expert sees all data)

- **Survival Analysis Loss (Censored NLL)**
  - *Why needed:* The model optimizes for survival time, not classification. You need to understand how the loss handles "censored" data (patients lost to follow-up) vs. "uncensored" (observed death).
  - *Quick check:* In Equation 2, how does the term (1-c) change the gradient update for a patient who is still alive vs. one who has died?

- **Cross-Modal Alignment**
  - *Why needed:* The pre-training phase aligns pathology images with genomic vectors and text reports without explicit paired labels.
  - *Quick check:* How does the contrastive loss (Eq. 1) penalize the model if a pathology image is closer to another patient's genomic profile than its own?

## Architecture Onboarding

- **Component map:** WSIs (UNI + MambaMIL) -> Genomics (SNN) -> Clinical Text (BioBERT) -> Collaborative Multi-Expert Module (Consensual, Specialized, Overlapping Experts) -> Fusion Expert (Transformer) -> MLP Classifier (hazard prediction)

- **Critical path:** 1) Unimodal encoders project raw data to feature vectors 2) Cancer Embedding selects relevant Specialized Expert 3) Multimodal features pass to Consensual Expert and Overlapping Router (selects top-k experts) 4) Outputs concatenated and passed to Fusion Expert

- **Design tradeoffs:**
  - *Routing vs. Fixed Assignment:* MICE fixes Specialized expert to cancer type for guaranteed coverage of rare cancers, trading flexibility for high-fidelity local knowledge
  - *Synthesis vs. Exclusion:* Synthesizing missing modalities allows larger batch sizes and better statistics but risks injecting synthetic noise into latent space

- **Failure signatures:**
  - Mode Collapse in Routing: Overlapping Router ignores input and selects same experts for every cancer type (check router entropy)
  - Over-regularization: If contrastive loss dominates, model produces identical predictions for high- and low-risk patients (low C-index)
  - Missing Modality Drift: Generated features drift from real distributions, failing validation on real paired data

- **First 3 experiments:**
  1. Ablation on Experts: Train variants (Only Specialized, Only Overlapping, Only Consensual) and compare C-index on diverse internal cohort
  2. Pre-training Strategy Validation: Train contrastive-only vs supervised-only models on TCGA, fine-tune on independent cohort to demonstrate hybrid approach necessity
  3. Data Efficiency Curve: Fine-tune pre-trained model using 10%, 25%, 50%, 100% of target cohort data and plot C-index curve

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does integration of additional modalities (radiology images, demographic factors) improve MICE's prognostic accuracy?
- Basis: Authors state inclusion of additional modalities could broaden clinical applicability and support more holistic assessment
- Why unresolved: Current study restricted to pathology images, clinical reports, and genomics data
- Evidence needed: Validation studies on datasets including paired CT/MRI scans

### Open Question 2
- Question: Can collaborative multi-expert architecture be refined to explicitly model fine-grained cross-modal interactions within the tumor microenvironment?
- Basis: Authors acknowledge architectural simplicity and suggest developing more sophisticated modules
- Why unresolved: Current expert blocks are standard Transformers that may not optimally capture specific fine-grained interactions
- Evidence needed: Ablation studies comparing current architecture against modules designed for fine-grained cross-modal interaction modeling

### Open Question 3
- Question: How does MICE's performance scale when pre-trained on significantly larger and more diverse multimodal cohorts (>100,000 patients)?
- Basis: Authors identify moderate sample size (~10,000 patients) as limitation and state future work should prioritize larger multimodal cohorts
- Why unresolved: Model validated only on TCGA cohort and three smaller independent cohorts
- Evidence needed: Benchmarking C-index and data efficiency after pre-training on large-scale resources like MIMIC-IV or aggregated global datasets

## Limitations
- The functional partitioning of expert groups shows promise but lacks comprehensive ablation studies to isolate marginal contributions of each component
- The specific weight (α=2) for the dual pre-training strategy appears somewhat arbitrary without sensitivity analysis across a range of values
- The missing modality synthesis approach may hallucinate biologically implausible features when cancer type alone is insufficient to predict missing data distributions

## Confidence
- **High confidence:** Data efficiency claims and comparative performance against established baselines (C-index improvements of 3.8-11.2% on internal cohorts and 5.8-8.8% on independent cohorts)
- **Medium confidence:** Architectural innovations (three expert groups) given conceptual soundness but limited ablation analysis
- **Low confidence:** Generalizability of missing modality synthesis approach to datasets where cancer type provides weak signal for missing modalities

## Next Checks
1. Conduct ablation studies isolating the contribution of each expert group (Consensual, Specialized, Overlapping) to quantify their marginal value
2. Perform sensitivity analysis on the pre-training weight α across a range of values (0.5, 1, 2, 5) to identify optimal balance
3. Test the model on datasets where modality availability patterns differ substantially from TCGA to evaluate robustness of the synthesis approach