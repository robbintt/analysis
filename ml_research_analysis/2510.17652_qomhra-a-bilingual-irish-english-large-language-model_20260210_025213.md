---
ver: rpa2
title: 'Qomhra: A Bilingual Irish-English Large Language Model'
arxiv_id: '2510.17652'
source_url: https://arxiv.org/abs/2510.17652
tags:
- irish
- language
- data
- qomhr
- english
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces Qomhr\xE1, an 8B bilingual Irish-English\
  \ LLM developed under extremely low-resource constraints. The core method combines\
  \ bilingual continued pre-training, instruction tuning, and a novel synthetic human\
  \ preference dataset generation approach."
---

# Qomhra: A Bilingual Irish-English Large Language Model

## Quick Facts
- arXiv ID: 2510.17652
- Source URL: https://arxiv.org/abs/2510.17652
- Authors: Joseph McInerney
- Reference count: 12
- Primary result: 29% Irish / 44% English performance gains vs UCCIX

## Executive Summary
This paper introduces Qomhrá, an 8B bilingual Irish-English LLM developed under extremely low-resource constraints. The core method combines bilingual continued pre-training, instruction tuning, and a novel synthetic human preference dataset generation approach. To select a translator LLM, the authors conduct a human evaluation with L1 and L2 Irish speakers, ranking Google's Gemini-2.5-Pro highest. They then translate 30K English instruction-tuning samples to Irish and synthesize a 1K human preference dataset. Evaluation shows Qomhrá outperforms UCCIX by up to 29% in Irish and 44% in English across translation, gender understanding, topic identification, and world knowledge benchmarks. The synthetic preference data achieves near-perfect alignment (Cohen's κ = 0.978) with L1 speaker judgments. This work provides a complete pipeline for developing LLMs in low-resource languages and releases the first validated human preference dataset for Irish.

## Method Summary
The methodology combines three key techniques: bilingual continued pre-training (CPT) on a curated corpus mixing Irish and English text, instruction tuning via translated English datasets, and synthetic preference data generation using a high-contrast prompting strategy. The authors first curated a 3.265B character corpus from UCCIX datasets, National Corpus of Ireland, Wikipedia, Bible, and ELRC. They performed CPT on Qwen3-8B for one epoch with a 75:25 Irish-to-English ratio. To overcome the lack of Irish instruction data, they translated 30K English instruction samples using Gemini-2.5-Pro (selected via L1 speaker evaluation) and applied LoRA fine-tuning. Finally, they generated synthetic preference data by prompting Gemini-2.5-Pro to create contrastive "accepted" and "rejected" response pairs from the LIMA dataset, achieving near-perfect alignment with human judgments.

## Key Results
- Qomhrá outperformed UCCIX by 29.2% in Irish and 44.4% in English on the IQA benchmark
- Synthetic preference data achieved near-perfect alignment with L1 speaker judgments (Cohen's κ = 0.978)
- Gemini-2.5-Pro ranked highest by L1/L2 speakers for Irish language tasks, diverging from LLM-as-judge rankings
- Response length significantly reduced after instruction tuning (Mann-Whitney U, p<0.001)

## Why This Works (Mechanism)

### Mechanism 1: Bilingual Continued Pre-training Preserves Cross-Language Transfer
Continued pre-training adapts the base model's existing linguistic representations to Irish through exposure to curated bilingual data, with the 75:25 ratio providing sufficient English exposure to maintain previously learned patterns. This mitigates catastrophic forgetting observed in prior work.

### Mechanism 2: High-Contrast Synthetic Preference Generation Aligns with Human Judgment
Prompting a strong LLM to explicitly generate contrasting "accepted" and "rejected" translations produces synthetic preference data that aligns with L1 speaker judgments. The binary contrast simplifies the annotation task, reducing LLM error modes.

### Mechanism 3: Teacher Model Pre-Selection Reduces Downstream Error Propagation
Systematically evaluating and ranking closed-weight LLMs via L1 speaker judgment before using them for data synthesis improves the quality of generated instruction-tuning and preference data. Direct human evaluation identifies the strongest model for the target language.

## Foundational Learning

- **Continued Pre-training (CPT):**
  - Why needed: Adapts a general-purpose LLM to a new linguistic domain without training from scratch, leveraging existing representations
  - Quick check: Can you explain why CPT is preferred over training from scratch for a low-resource language with 3.2B characters of training data?

- **Direct Preference Optimization (DPO):**
  - Why needed: DPO requires paired "chosen" and "rejected" responses; this paper provides a method to synthesize these pairs without human annotation
  - Quick check: What data format does DPO require, and why is it difficult to obtain for low-resource languages?

- **Translate-Train:**
  - Why needed: Instruction-tuning datasets don't exist for Irish; translating from English provides a practical path to instruction-following capability
  - Quick check: What are the trade-offs of using machine-translated instruction data versus native-language collection?

## Architecture Onboarding

- **Component map:** UCCIX corpora (Gawiki, Gaparacrawl, Glot500, CulturaX) -> CNG corpus -> Wikipedia English -> Bible -> ELRC -> MinHash deduplication -> segmentation with <|endoftext|> -> language tag prepending -> CPT on Qwen3-8B -> L1 evaluation of 6 LLMs -> Gemini-2.5-Pro selected -> Dolly V2 translated to Irish -> LoRA fine-tuning -> LIMA dataset -> Gemini-2.5-Pro generates contrastive pairs -> L1 validation

- **Critical path:**
  1. Curate bilingual corpus with MinHash deduplication
  2. Run CPT for exactly 1 epoch
  3. Select translator model via L1 evaluation
  4. Translate instruction dataset
  5. Apply LoRA instruction tuning
  6. Generate synthetic preference data with explicit contrast prompting

- **Design tradeoffs:**
  - 75:25 Irish:English ratio balances language acquisition vs. catastrophic forgetting
  - 8B scale limits capability ceiling but enables reproducibility on limited compute
  - Machine translation quality bounds instruction-tuning effectiveness
  - Single L1 annotator limits validation robustness

- **Failure signatures:**
  - Catastrophic forgetting: English benchmark scores drop (mitigated by English data proportion)
  - Response over-generation: Base model generates longer sequences than necessary; corrected by instruction tuning
  - LLM-as-judge misalignment: LLMs ranked GPT-5 highest; humans ranked Gemini-2.5-Pro highest

- **First 3 experiments:**
  1. Baseline comparison: Evaluate Qomhrá-1e-CPT vs. Llama-3.1-8B and UCCIX on all benchmarks
  2. Epoch ablation: Compare 1-epoch vs. 2-epoch CPT to confirm saturation hypothesis
  3. Translator validation: Replicate Section 4.1 ranking with your own prompts

## Open Questions the Paper Calls Out

### Open Question 1
Does the Qomhrá training pipeline generalize to other low-resource languages with different linguistic structures or script systems? The study is restricted to Irish-English and Qwen3-8B, leaving efficacy for non-Indo-European languages unconfirmed.

### Open Question 2
What specific biases cause LLM-as-a-judge evaluators to diverge from native (L1) speaker preferences in low-resource languages? The paper identifies misalignment but only hypothesizes training data familiarity as the cause.

### Open Question 3
How can low-resource LLM evaluation move beyond grammatical accuracy to capture cultural alignment, code-switching, and dialectal variation? Current benchmarks rely on exact matches, failing to measure sociolinguistic nuance required for true community adoption.

### Open Question 4
Does the "high-contrast" prompting method maintain alignment with human judgment as task complexity increases? The validation was performed on translation tasks; it remains unclear if LLMs can generate "rejected" responses for complex, non-translation tasks.

## Limitations
- Single L1 annotator validation of synthetic preference dataset limits statistical robustness
- Reliance on translated instruction data introduces quality bounds from machine translation
- GPT-style training data may not capture Irish cultural nuances or regional linguistic preferences

## Confidence
- **High confidence** in bilingual continued pre-training mechanism: Clear quantitative improvements (29.2% Irish, 44.4% English) with appropriate hyperparameters
- **Medium confidence** in synthetic preference generation: Impressive alignment but single-annotator validation is a critical weakness
- **Medium confidence** in teacher model selection: L1 evaluation revealed LLM-as-judge misalignment, but generalization to other tasks is unverified

## Next Checks
1. **Multi-annotator preference dataset validation**: Recruit 3-5 additional L1 Irish speakers to independently annotate 100 synthetic preference pairs and compute Cohen's κ and Krippendorff's α.

2. **Generalization of teacher model selection**: Replicate the Gemini-2.5-Pro ranking experiment with a different evaluation task (e.g., translating English instruction data to Irish) to test task generalization.

3. **Cultural and dialectal robustness test**: Evaluate Qomhrá on Irish text containing dialectal variations (Ulster, Connacht, Munster Irish) or culturally specific content not present in the training corpus.