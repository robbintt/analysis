---
ver: rpa2
title: Towards Optimal Multi-draft Speculative Decoding
arxiv_id: '2502.18779'
source_url: https://arxiv.org/abs/2502.18779
tags:
- pdraft
- draft
- replacement
- optimal
- sampling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a new approach to measuring and optimizing
  the efficiency of multi-draft speculative decoding for large language models. The
  key contribution is transforming the optimal acceptance rate computation into a
  subset selection problem via the dual of an optimal transport formulation.
---

# Towards Optimal Multi-draft Speculative Decoding

## Quick Facts
- arXiv ID: 2502.18779
- Source URL: https://arxiv.org/abs/2502.18779
- Reference count: 27
- Key outcome: Transforms optimal acceptance rate computation into subset selection problem, enabling efficient algorithms to compute theoretical upper bounds for different draft sampling methods

## Executive Summary
This paper introduces a new approach to measuring and optimizing the efficiency of multi-draft speculative decoding for large language models. The key contribution is transforming the optimal acceptance rate computation into a subset selection problem via the dual of an optimal transport formulation. The authors develop efficient algorithms to compute the theoretical upper bound of acceptance rates for different draft sampling methods, including sampling with replacement, without replacement, and a novel greedy approach. Experiments on real text distributions show that existing verification algorithms like RRS and K-SEQ have significant gaps from the theoretical upper bound, while the greedy method achieves the optimal rate in certain cases.

## Method Summary
The paper reformulates the optimal acceptance rate computation as a subset selection problem by analyzing the dual of an optimal transport formulation. For draft sampling with replacement, the optimal acceptance rate is computed by sorting tokens by their q(x)/p(x) ratio and performing a linear scan. For sampling without replacement, a dynamic programming approach on the generating function computes the optimal rate. The greedy method deterministically selects the top n-1 draft tokens and samples the last token without replacement, achieving optimal acceptance rates that exceed sampling without replacement in some cases. The approach transforms an exponential problem into polynomial time complexity, enabling practical computation of theoretical bounds.

## Key Results
- Greedy draft sampling achieves optimal acceptance rates exceeding sampling without replacement in certain cases
- Sampling without replacement consistently outperforms sampling with replacement across all tested model pairs and datasets
- Existing verification algorithms (RRS, K-SEQ) show significant gaps (0.6-3.3 percentage points) from theoretical upper bounds
- Optimal acceptance rate can be computed in O(|Σ| log |Σ|) time using subset selection formulation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Computing the optimal MDSD acceptance rate is equivalent to a subset selection problem solvable in polynomial time.
- Mechanism: The original optimal transport problem (exponential in draft count n) is reformulated via its dual as a weighted vertex cover on a bipartite graph. Total unimodularity of the constraint matrix guarantees integer optimal solutions, reducing to: α*(p, pdraft) = 1 + min_{H⊂Σ}(∑_{i∈H} p(i) - ∑_{ī∈H^n} pdraft(ī)). Sorting by q(x)/p(x) ratios enables O(|Σ| log |Σ|) computation.
- Core assumption: The draft distribution pdraft admits a "q-convex" structure (satisfied by with/without replacement sampling).
- Evidence anchors:
  - [abstract] "transform the optimal acceptance rate computation into a subset selection problem by analyzing the dual of an optimal transport formulation"
  - [section 3.1-3.3] Derives dual problem (10), proves total unimodularity, obtains subset formulation (8)
  - [corpus] Related work (Sun et al. 2024e, Khisti et al. 2024) treats special cases; this generalizes beyond n=2 or specific sampling methods.
- Break condition: If draft distribution is neither with/without replacement nor q-convex, the efficient sorting-based algorithm may not apply; general submodular minimization is still polynomial but slower.

### Mechanism 2
- Claim: Sampling without replacement achieves higher optimal acceptance rates than sampling with replacement.
- Mechanism: Without replacement prevents duplicate draft tokens, increasing coverage of target distribution support. The paper proves Q(H) is q-convex for both cases, but the generating function structure differs: with replacement uses Q(H) = (∑_{x∈H} q(x))^n while without replacement uses coefficients of ∏_{i∈H}(1 + q(i)t), yielding higher acceptance.
- Core assumption: Target and draft distributions have non-trivial overlap; duplicates reduce effective draft diversity.
- Evidence anchors:
  - [abstract] "sampling without replacement outperforming sampling with replacement"
  - [Table 1] Across all model pairs and tasks, α*(without replacement) exceeds α*(with replacement) by 1-7 percentage points
  - [corpus] Related papers (Jeon et al. 2024, Yang et al. 2024b) use RRS with without-replacement but don't quantify optimality gaps.
- Break condition: At high temperatures where distributions flatten, the gap narrows because with-replacement sampling is less likely to produce duplicates (Figure 1).

### Mechanism 3
- Claim: Greedy draft sampling (top n-1 tokens deterministic, last token random) can exceed the optimal acceptance rate of without-replacement sampling.
- Mechanism: By deterministically including the highest-probability draft tokens, the method guarantees coverage of the most likely target outputs. Only the nth token introduces randomness, simplifying verification to single-draft optimal transport: α* = ∑_{i∈Top_{n-1}(q)} p(i) + ∑_{i∈Σ} min(p(i), q_{¬Top_{n-1}(q)}(i)).
- Core assumption: The draft model's top tokens align reasonably with the target model's high-probability tokens.
- Evidence anchors:
  - [abstract] "A novel greedy draft sampling method achieves optimal acceptance rates that exceed sampling without replacement in some cases"
  - [section 5.1-5.2, Theorem 7] Proves greedy acceptance rate equals the closed-form expression
  - [corpus] SpecHub (Sun et al. 2024b) is similar for n=2; this generalizes and provides simpler verification.
- Break condition: At high temperatures (T→1), greedy underperforms (Figure 1, Table 2 at T=1.0) because deterministic top tokens may not align with broader target distribution.

## Foundational Learning

- Concept: **Optimal Transport / Earth Mover's Distance**
  - Why needed here: The verification algorithm's acceptance rate is fundamentally a transport problem—how to map draft token distribution to target distribution while maximizing diagonal mass (matches).
  - Quick check question: Given two distributions p=[0.5, 0.5] and q=[0.8, 0.2], what's the maximum probability that a sample from q equals a sample from p under optimal coupling?

- Concept: **Total Unimodularity in Integer Programming**
  - Why needed here: Explains why the dual LP has integer solutions, enabling reduction from continuous transport to discrete subset selection.
  - Quick check question: Why does a totally unimodular constraint matrix with integer RHS guarantee integer optimal solutions?

- Concept: **Submodular Function Minimization**
  - Why needed here: The objective f(H) = P(H) - Q(H) is supermodular (negative is submodular), enabling polynomial-time minimization beyond naive enumeration.
  - Quick check question: If f(S) is submodular, is -f(S) submodular? What algorithmic advantage does submodularity provide?

## Architecture Onboarding

- Component map: Draft Generator -> Parallel Target Scorer -> Verification Module -> Acceptance Rate Calculator
- Critical path: Draft sampling → parallel target probability computation → verification → (if accepted) bonus token generation. The verification algorithm must balance acceptance rate against computational overhead.
- Design tradeoffs:
  - More drafts → higher α* but diminishing returns and more parallel compute
  - Without-replacement → higher α* but requires maintaining exclusion set
  - Greedy → highest α* at low T but sensitive to draft-target misalignment at high T
  - RRS vs K-SEQ: RRS simpler; K-SEQ has (1-e^{-1}) approximation guarantee but still gaps from optimal
- Failure signatures:
  - Acceptance rate plateau despite increasing drafts → suggests with-replacement duplicates or poor draft-target alignment
  - Greedy underperforms at high temperature → expected per Figure 1; switch to without-replacement
  - α* computation slow for large vocabulary → verify using the O(|Σ| log |Σ|) sorting method, not naive LP
- First 3 experiments:
  1. Reproduce Table 1 for your target/draft model pair: compute α* for with-replacement, without-replacement, and greedy; measure gaps for RRS and K-SEQ
  2. Ablation over temperature (Figure 1): identify the temperature threshold where greedy loses advantage over without-replacement
  3. Scale study over draft count n (Figure 2): measure both α* and wall-clock speedup to find optimal n for your latency budget

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can verification algorithms be developed that achieve the theoretical optimal acceptance rate for both sampling with replacement and sampling without replacement?
- Basis in paper: [explicit] The authors state "existing verification algorithms do not reach the theoretical upper bound for both without replacement and with replacement sampling" and conclude by suggesting "carefully designed...verification algorithms that closely match the theoretical upper bound" as future work.
- Why unresolved: RRS and K-SEQ show consistent gaps (0.6–3.3 percentage points) from the theoretical bound across all model pairs and datasets.
- What evidence would resolve it: A verification algorithm whose empirical acceptance rate statistically matches the computed theoretical upper bound α* for standard sampling schemes.

### Open Question 2
- Question: Can the efficient computation methods for single-step MDSD be extended to the multi-step tree-structured speculative decoding scenario?
- Basis in paper: [explicit] In Appendix B.3, the authors state: "Combining both improvements in the multi-draft and multi-step scenario would be ideal, and could be a direction for future research."
- Why unresolved: The paper's analysis and efficient algorithms are limited to single-step MDSD; multi-step tree structures introduce exponentially larger joint distribution spaces.
- What evidence would resolve it: A polynomial-time algorithm to compute optimal acceptance rates for multi-step MDSD with arbitrary tree topologies, validated on realistic vocabulary sizes.

### Open Question 3
- Question: Can draft sampling methods be designed that combine the benefits of greedy selection at low temperatures and sampling without replacement at high temperatures?
- Basis in paper: [inferred] Figure 1 and Section 6.4 show the greedy method outperforms at low temperatures but loses its advantage at T=1.0, while sampling without replacement shows more stable performance across temperatures.
- Why unresolved: The paper does not provide a unified sampling strategy that adapts to or performs well across different temperature settings.
- What evidence would resolve it: A temperature-adaptive or hybrid draft sampling method that achieves optimal or near-optimal acceptance rates across the full temperature range (0.1–1.0).

## Limitations

- The theoretical framework relies on specific distributional properties (q-convexity) that may not hold for all draft distributions
- Analysis focuses on token-level matching rather than sequence-level quality, potentially missing coherence issues
- Empirical validation covers only four model pairs and three datasets, limiting generalizability
- Paper doesn't demonstrate practical wall-clock speedup improvements from achieving optimal acceptance rates

## Confidence

**High Confidence**: The transformation of optimal acceptance rate to subset selection problem is mathematically rigorous. The dual formulation and total unimodularity proof are sound, and the O(|Σ| log |Σ|) algorithm is well-specified. The empirical observation that existing verification algorithms (RRS, K-SEQ) have significant gaps from theoretical upper bounds is reproducible.

**Medium Confidence**: The relative performance ordering (greedy > without-replacement > with-replacement at low temperatures) is supported by theory and experiments, but the magnitude of differences may vary with different model pairs and datasets. The claim that greedy achieves optimal acceptance rates in some cases is conditional on specific distributional properties.

**Low Confidence**: The practical significance of achieving optimal acceptance rates remains unclear. The paper doesn't demonstrate that closing the gap to theoretical upper bounds translates to meaningful improvements in real-world latency or quality. The recommendation to use greedy sampling at low temperatures assumes that verification overhead is negligible, which may not hold in practice.

## Next Checks

1. **Temperature Sweep Validation**: Reproduce Figure 1 for a new model pair (e.g., Mistral-7B draft, Llama-3-8B target) across temperatures 0.1 to 1.0. Verify that greedy outperforms without-replacement at T ≤ 0.5 but underperforms at T ≥ 0.9, and measure the exact crossover point.

2. **Vocabulary Pruning Impact**: Test whether filtering the vocabulary to top-k tokens by q(x) + p(x) affects the computed α* values and acceptance rate gaps. Compare results using full vocabulary vs. top 50k tokens for LLaMA models.

3. **Real-World Speedup Correlation**: Measure actual wall-clock latency for a complete speculative decoding pipeline (draft generation + verification + acceptance/rejection) on a single GPU. Compare the relationship between α* and measured speedup for each sampling method to determine if optimal acceptance rates predict practical performance gains.