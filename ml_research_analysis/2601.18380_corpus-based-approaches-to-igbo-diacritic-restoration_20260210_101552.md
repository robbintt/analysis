---
ver: rpa2
title: Corpus-Based Approaches to Igbo Diacritic Restoration
arxiv_id: '2601.18380'
source_url: https://arxiv.org/abs/2601.18380
tags:
- restoration
- diacritic
- words
- igbo
- page
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This thesis investigates automatic diacritic restoration for Igbo,
  a low-resource language with orthographic and tonal diacritics that are often omitted
  in electronic texts. To address the lack of standard datasets and effective methods
  for this task, the author developed a generic framework for generating training
  data from diacritically marked corpora and applied three main approaches: n-gram
  models, classification models, and embedding models.'
---

# Corpus-Based Approaches to Igbo Diacritic Restoration
## Quick Facts
- arXiv ID: 2601.18380
- Source URL: https://arxiv.org/abs/2601.18380
- Reference count: 40
- Primary result: Developed framework and models achieving up to 98.71% accuracy for automatic diacritic restoration in Igbo

## Executive Summary
This thesis addresses the challenge of automatic diacritic restoration for Igbo, a low-resource language where orthographic and tonal diacritics are frequently omitted in electronic texts. The work develops a generic framework for generating training data from diacritically marked corpora and evaluates three main approaches: n-gram models, classification models, and embedding models. The best systems achieved up to 98.71% accuracy on full corpus testing, significantly outperforming baseline models. The research also created intrinsic evaluation datasets for Igbo embeddings and demonstrated that diacritic restoration improves machine translation performance, providing a robust baseline for future research on Igbo and similar low-resource languages.

## Method Summary
The thesis presents a comprehensive approach to automatic diacritic restoration for Igbo through three main modeling strategies. N-gram models used maximum likelihood estimation to select diacritic variants based on preceding words, with performance improving up to 5-grams. Classification models employed machine learning algorithms using context words as features, with logistic regression achieving the highest accuracy of 81.55%. Embedding models introduced a novel approach using word vectors trained on small Igbo data and projected from large English models, though these showed lower performance than other methods. The framework includes a generic method for generating training data from diacritically marked corpora, addressing the lack of standard datasets for this task.

## Key Results
- N-gram models improved accuracy up to 5-grams, demonstrating the value of longer context windows
- Logistic regression classification achieved highest accuracy of 81.55% among machine learning approaches
- Best systems reached 98.71% accuracy on full corpus testing, significantly outperforming baseline unigram model
- Diacritic restoration was shown to improve machine translation performance
- Novel intrinsic evaluation datasets were developed for assessing Igbo embeddings

## Why This Works (Mechanism)
The framework's effectiveness stems from leveraging contextual information to disambiguate diacritic variants, addressing the ambiguity inherent in diacritic omission. By generating training data from existing diacritically marked corpora, the approach circumvents the lack of standard datasets for low-resource languages. The multi-method evaluation demonstrates that different modeling approaches capture different aspects of the diacritic restoration task, with n-gram models excelling at local context capture and classification models providing more flexible feature-based discrimination.

## Foundational Learning
- N-gram language models: Statistical models that estimate word sequence probabilities based on preceding context; needed for capturing local contextual patterns in diacritic restoration
- Maximum likelihood estimation: Method for parameter estimation that selects values maximizing the likelihood of observed data; needed for determining optimal n-gram probabilities
- Logistic regression: Classification algorithm that models probability of class membership using logistic function; needed for discriminating between diacritic variants based on contextual features
- Word embeddings: Dense vector representations of words that capture semantic relationships; needed for modeling semantic context in diacritic restoration
- Cross-lingual projection: Technique for transferring representations from resource-rich to resource-poor languages; needed for leveraging English embedding models for Igbo
- Intrinsic evaluation: Assessment of embedding quality using specific tasks like word similarity; needed for evaluating the quality of learned Igbo representations

## Architecture Onboarding
Component map: Training data generation -> N-gram models -> Classification models -> Embedding models -> Evaluation pipeline
Critical path: Training data generation is prerequisite for all modeling approaches; evaluation pipeline connects all models to performance metrics
Design tradeoffs: Simpler n-gram models offer interpretability and efficiency but limited context capture versus more complex classification/embedding models that handle broader context but require more resources
Failure signatures: N-gram models fail with sparse contexts; classification models struggle with feature engineering limitations; embedding models underperform due to data scarcity
First experiments: 1) Generate training data from diacritically marked corpus 2) Train and evaluate baseline unigram model 3) Implement and test 2-gram model to establish context benefits

## Open Questions the Paper Calls Out
None

## Limitations
- High accuracy results achieved using data from same corpus as training, raising overfitting concerns
- Intrinsic evaluation of Igbo embeddings conducted on small, task-specific dataset limiting generalizability
- Applicability to other low-resource languages hypothesized but not empirically validated
- Embedding model performance remains suboptimal despite novel approach

## Confidence
- N-gram model improvements with longer contexts: High confidence (well-established NLP principle)
- Classification model results: Medium confidence (dependent on feature engineering quality)
- Intrinsic embedding evaluation: Low confidence (small, task-specific dataset)
- Full corpus testing results: Medium confidence (potential overfitting from same-corpus training)

## Next Checks
1. Independent test set evaluation using diacritically marked Igbo texts from different sources than training corpus
2. Cross-linguistic validation by applying framework to at least two other low-resource tonal languages
3. Systematic ablation studies on embedding model components examining effects of different projection methods and corpus sizes