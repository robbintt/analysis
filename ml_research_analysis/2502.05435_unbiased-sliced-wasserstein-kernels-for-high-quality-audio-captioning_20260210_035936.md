---
ver: rpa2
title: Unbiased Sliced Wasserstein Kernels for High-Quality Audio Captioning
arxiv_id: '2502.05435'
source_url: https://arxiv.org/abs/2502.05435
tags:
- audio
- captioning
- wasserstein
- sliced
- enclap
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the ACUS framework to address exposure bias
  in audio captioning by developing an unbiased sliced Wasserstein RBF (USW-RBF) kernel.
  The USW-RBF kernel measures similarity between audio and text sequences while incorporating
  temporal information through rotary positional embeddings.
---

# Unbiased Sliced Wasserstein Kernels for High-Quality Audio Captioning

## Quick Facts
- **arXiv ID**: 2502.05435
- **Source URL**: https://arxiv.org/abs/2502.05435
- **Reference count**: 40
- **Primary result**: USW-RBF kernel improves audio captioning metrics significantly (up to 0.262 METEOR, 0.509 ROUGE-L, 0.807 CIDEr, 0.192 SPICE, and 0.5 SPIDEr on AudioCaps)

## Executive Summary
This paper addresses exposure bias in audio captioning through the ACUS framework, which employs an unbiased sliced Wasserstein RBF (USW-RBF) kernel. The kernel measures similarity between audio and text sequences while incorporating temporal information via rotary positional embeddings. The key innovation is providing an unbiased estimation through Monte Carlo sampling, enabling stochastic gradient optimization with O(L⁻¹/²) approximation error. The framework uses stochastic decoding at inference to mitigate caption degeneration. Experiments on AudioCaps and Clotho datasets show substantial improvements across multiple evaluation metrics.

## Method Summary
The ACUS framework introduces the USW-RBF kernel to overcome exposure bias in audio captioning. Unlike traditional cross-entropy approaches that suffer from training-inference mismatch, the USW-RBF kernel provides an unbiased similarity measure between audio and text sequences. The kernel incorporates temporal structure through rotary positional embeddings and uses Monte Carlo sampling for unbiased estimation with O(L⁻¹/²) approximation error. The framework leverages stochastic decoding methods during inference to prevent caption degeneration. The approach is theoretically grounded with error bounds for the Monte Carlo approximation.

## Key Results
- Achieved up to 0.262 METEOR, 0.509 ROUGE-L, 0.807 CIDEr, 0.192 SPICE, and 0.5 SPIDEr on AudioCaps dataset
- Demonstrated improved lexical diversity and longer captions compared to baselines
- Showed better text-to-audio retrieval performance than existing methods
- Successfully mitigated exposure bias through unbiased kernel approximation

## Why This Works (Mechanism)
The USW-RBF kernel works by providing an unbiased similarity measure between audio and text sequences, addressing the fundamental exposure bias problem in sequence generation. Traditional cross-entropy training creates a mismatch between training (teacher forcing) and inference (autoregressive), leading to error accumulation. The unbiased kernel estimation through Monte Carlo sampling allows proper gradient flow during training while maintaining temporal structure through rotary positional embeddings. This enables the model to learn robust audio-text alignments without the degradation that occurs with standard approaches.

## Foundational Learning
- **Exposure bias**: Why needed - prevents error accumulation during autoregressive generation; Quick check - verify gradient flow through kernel during training
- **Sliced Wasserstein distance**: Why needed - provides efficient, differentiable similarity measure for sequences; Quick check - confirm computational efficiency vs. standard Wasserstein
- **Rotary positional embeddings**: Why needed - incorporates temporal information without additional parameters; Quick check - validate positional information preservation
- **Monte Carlo approximation**: Why needed - enables unbiased gradient estimation with theoretical error bounds; Quick check - verify O(L⁻¹/²) convergence empirically
- **Stochastic decoding**: Why needed - prevents caption degeneration at inference; Quick check - compare deterministic vs. stochastic outputs

## Architecture Onboarding

**Component map**: Audio encoder -> Rotary positional embeddings -> USW-RBF kernel -> Caption decoder -> Stochastic decoding

**Critical path**: The core computation path involves audio encoding, temporal embedding through rotary positions, kernel-based similarity computation, and stochastic decoding for inference.

**Design tradeoffs**: The framework trades computational complexity of the Monte Carlo approximation for unbiased gradient estimation. The rotary positional embeddings add minimal parameters while preserving temporal structure. Stochastic decoding increases inference variance but prevents degeneration.

**Failure signatures**: Performance degradation may occur if Monte Carlo samples are insufficient (increasing O(L⁻¹/²) error), rotary embeddings fail to capture temporal patterns, or stochastic decoding introduces excessive noise during inference.

**3 first experiments**:
1. Validate unbiased kernel approximation by comparing training loss convergence with/without Monte Carlo sampling
2. Test rotary positional embedding effectiveness by comparing temporal alignment metrics
3. Evaluate stochastic decoding impact by measuring caption degeneration rates

## Open Questions the Paper Calls Out
The paper does not explicitly identify open questions or limitations in its discussion.

## Limitations
- Experimental validation relies entirely on standard captioning metrics which may not fully capture semantic accuracy improvements
- Incomplete ablation studies - contribution of rotary positional embeddings versus unbiased kernel approximation is not isolated
- Limited to two datasets (AudioCaps and Clotho) without testing generalization to other domains
- Text-to-audio retrieval evaluation uses relatively simple contrastive learning without exploring advanced alignment techniques

## Confidence
- **High confidence**: The mathematical formulation of the unbiased sliced Wasserstein kernel and its O(L⁻¹/²) error bound
- **Medium confidence**: The claimed improvements over baselines and the effectiveness of stochastic decoding at inference
- **Low confidence**: The specific contribution of rotary positional embeddings versus the kernel design, and the generalization beyond the tested datasets

## Next Checks
1. Conduct controlled ablation studies isolating the impact of unbiased kernel approximation versus rotary positional embeddings on captioning quality
2. Evaluate on additional audio captioning datasets beyond AudioCaps and Clotho to assess generalization
3. Perform human evaluation studies to validate that metric improvements correspond to meaningful semantic accuracy gains, particularly for the longer captions produced