---
ver: rpa2
title: High-accuracy sampling for diffusion models and log-concave distributions
arxiv_id: '2602.01338'
source_url: https://arxiv.org/abs/2602.01338
tags:
- theorem
- where
- then
- sampling
- holds
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces first-order rejection sampling (FORS), a
  new meta-algorithm for high-accuracy sampling that only uses gradient queries. FORS
  generates samples from a target distribution by performing rejection sampling with
  a base distribution and an unknown tilt function, using unbiased estimators of the
  tilt based on first-order information.
---

# High-accuracy sampling for diffusion models and log-concave distributions

## Quick Facts
- arXiv ID: 2602.01338
- Source URL: https://arxiv.org/abs/2602.01338
- Reference count: 40
- Introduces FORS (first-order rejection sampling) achieving polylog(1/δ) complexity for high-accuracy sampling using only gradient queries

## Executive Summary
This paper presents First-Order Rejection Sampling (FORS), a novel meta-algorithm for high-accuracy sampling from diffusion models and log-concave distributions. The key innovation is using gradient-based information to construct unbiased estimators of a target distribution's tilt function, enabling rejection sampling without requiring density evaluations. The method achieves significant complexity improvements over prior work, particularly for high-accuracy requirements, by leveraging path integral constructions to estimate the unknown normalization constant.

## Method Summary
FORS operates by performing rejection sampling between a base distribution and a target distribution, where the acceptance probability depends on the ratio of their densities. The core challenge is estimating the normalization constant of the target distribution, which is addressed by constructing unbiased estimators using path integrals based on gradient information. The algorithm makes multiple gradient queries per sample to estimate the tilt function, then applies standard rejection sampling techniques. Under various assumptions about the target distribution's smoothness and boundedness properties, FORS achieves polylogarithmic complexity in the accuracy parameter δ, significantly improving upon previous methods that required polynomial dependence on 1/δ.

## Key Results
- Achieves δ-error in O(d log²(M/δ) + log³(M/δ)) steps for diffusion model sampling under minimal assumptions
- Under non-uniform Lipschitz condition, achieves δ-error in O(√(dL) log³/²(M/δ) + L log²(M/δ)) steps
- For low-dimensional data with intrinsic dimension d⋆, achieves δ-error in O(d⋆ log²(M/δ) + log³(M/δ)) steps
- Provides first polylog(1/δ) complexity sampler for general log-concave distributions using only gradient evaluations

## Why This Works (Mechanism)
FORS leverages the mathematical structure of log-concave distributions and diffusion models to construct unbiased estimators of the normalization constant through path integrals. By using gradient information to navigate the distribution's geometry, the method can accurately estimate acceptance probabilities without explicit density evaluations. The rejection sampling framework provides a natural way to handle the unknown normalization while maintaining theoretical guarantees on sample quality. The polylogarithmic complexity arises from the efficient use of gradient information to construct accurate tilt function estimates with minimal queries.

## Foundational Learning
- **Log-concave distributions**: Distributions where the logarithm of the density is concave; needed for theoretical guarantees on sampling algorithms; quick check: verify log-density is concave
- **Rejection sampling**: A fundamental sampling technique that generates samples from a target distribution using a proposal distribution; needed for the algorithmic framework; quick check: acceptance probability calculation
- **Path integrals**: Mathematical tools for constructing unbiased estimators of normalization constants; needed for the core estimation technique; quick check: path integral convergence
- **Lipschitz continuity**: A smoothness condition on functions that bounds the rate of change; needed for complexity analysis; quick check: verify Lipschitz constant
- **Intrinsic dimension**: The effective dimensionality of data in high-dimensional spaces; needed for complexity analysis in low-dimensional settings; quick check: estimate intrinsic dimension
- **Gradient queries**: Evaluations of the gradient of the log-density; needed as the only information source; quick check: gradient computation efficiency

## Architecture Onboarding
**Component Map:** Base distribution → Gradient estimator → Tilt function estimator → Acceptance probability → Sample output

**Critical Path:** The algorithm's performance bottleneck is the gradient estimation step, which requires multiple gradient queries per sample to achieve accurate tilt function estimates. The rejection sampling step introduces additional overhead through potential resampling, but this is typically less significant than the gradient estimation cost.

**Design Tradeoffs:** FORS trades computational efficiency per iteration (requiring multiple gradient queries) for significantly improved sample complexity. The method sacrifices the simplicity of density-based approaches for the generality of gradient-only methods, enabling applications where density evaluation is expensive or impossible.

**Failure Signatures:** The algorithm may fail when the base distribution is poorly chosen (leading to very low acceptance rates), when the gradient estimates are too noisy (causing incorrect acceptance decisions), or when the distribution does not satisfy the required smoothness assumptions (invalidating theoretical guarantees).

**First Experiments:**
1. Implement FORS on a simple Gaussian distribution to verify basic functionality and acceptance rates
2. Test on a strongly log-concave distribution to validate the theoretical complexity improvements
3. Apply to a synthetic diffusion model to assess practical performance on relevant distributions

## Open Questions the Paper Calls Out
None

## Limitations
- Complexity improvements depend heavily on assumptions about distribution smoothness and second moment boundedness
- Non-uniform Lipschitz condition may be restrictive and difficult to verify for practical applications
- Multiple gradient evaluations per sample may be computationally expensive in practice
- Lack of empirical validation on real-world diffusion models and log-concave distributions

## Confidence
- **High Confidence**: Theoretical framework and mathematical derivations are sound with rigorous proofs
- **Medium Confidence**: Complexity improvements are well-established theoretically but practical impact varies
- **Low Confidence**: Practical performance and empirical validation are not demonstrated in the paper

## Next Checks
1. Implement and test FORS on standard benchmark diffusion models and log-concave distributions to verify theoretical complexity claims
2. Develop methods to verify the non-uniform Lipschitz condition and other key assumptions for common distributions
3. Conduct systematic comparison of FORS with existing high-accuracy sampling methods, including both theoretical and empirical analyses