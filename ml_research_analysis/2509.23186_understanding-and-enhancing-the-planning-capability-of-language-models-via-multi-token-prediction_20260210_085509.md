---
ver: rpa2
title: Understanding and Enhancing the Planning Capability of Language Models via
  Multi-Token Prediction
arxiv_id: '2509.23186'
source_url: https://arxiv.org/abs/2509.23186
tags:
- token
- prediction
- layer
- transfer
- reachability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies how Multi-Token Prediction (MTP) can improve
  the ability of large language models to learn transitive relations, which are essential
  for planning tasks. The authors theoretically analyze a simplified Transformer model
  to show that MTP enables learning of both adjacency and reachability beyond what
  standard next-token prediction achieves.
---

# Understanding and Enhancing the Planning Capability of Language Models via Multi-Token Prediction

## Quick Facts
- **arXiv ID**: 2509.23186
- **Source URL**: https://arxiv.org/abs/2509.23186
- **Reference count**: 40
- **Primary result**: Multi-Token Prediction with architectural enhancements achieves up to 71.32% accuracy on degree-2 paths in synthetic graphs, compared to 63.80% with baseline next-token prediction

## Executive Summary
This paper addresses the fundamental limitation of autoregressive language models in learning transitive relations essential for planning tasks. Through theoretical analysis of a simplified Transformer model, the authors demonstrate that standard next-token prediction cannot effectively learn multi-step adjacency and reachability relations in directed acyclic graphs. They propose Multi-Token Prediction (MTP) with two key architectural enhancements: Next-Token Injection (NTI) to stabilize transfer layer learning, and a Transformer-based transfer layer for better modeling of multi-step relations. Experiments on synthetic graphs and the Blocksworld planning benchmark show significant accuracy improvements, particularly for complex transitive paths.

## Method Summary
The authors propose Multi-Token Prediction (MTP) where the model predicts multiple future tokens simultaneously rather than just the next token. The architecture consists of a backbone Transformer that processes the input sequence, followed by a transfer layer that maps the hidden state to predictions for multiple future steps. The key innovation is learning a transfer matrix W^T that captures multi-step adjacency information, which then enables the backbone to learn transitive reachability relations. Two enhancements are introduced: Next-Token Injection (NTI) which adds the ground-truth next-token embedding to the transfer layer input for stable supervision, and a Transformer-based transfer layer (1-6 layers) that better models complex multi-hop relations compared to the baseline linear layer.

## Key Results
- MTP with NTI and Transformer transfer layer achieves 71.32% accuracy on degree-2 paths in synthetic graphs vs 63.80% with baseline next-token prediction
- NTI improves degree-2 accuracy by 2.11% on average by stabilizing transfer layer learning
- The proposed architecture maintains advantages on structured planning tasks like Blocksworld (52.84% vs 45.62% baseline with 100 training paths)
- Transfer matrix visualization confirms W^T learns multi-step adjacency powers, with adjacency entries averaging 4.01 vs 0.82 without NTI

## Why This Works (Mechanism)

### Mechanism 1: Transfer Layer Encodes Multi-Step Adjacency
The transfer layer W^T learns to approximate powers of the graph adjacency matrix through multi-token prediction gradients. When the 2nd-step prediction underestimates probability of reaching node k′ from current node i, the gradient increases W^T(d,k′) for all intermediate nodes d with positive correlation. This couples adjacency learning across hops, enabling the model to capture multi-step relations that standard next-token prediction cannot learn.

### Mechanism 2: Backbone Captures Transitive Reachability via Gradient Backpropagation
The 2nd-step prediction loss propagates gradients through the transfer layer to strengthen unobserved reachability relations in backbone weights. When W^T(k,k′) is large (confident transition) and the model underestimates k′ probability, negative gradient increases W^V(j,k), strengthening the k⇝j reachability relation. This enables learning reachability beyond observed training paths, overcoming the fundamental limitation of autoregressive models.

### Mechanism 3: Next-Token Injection Creates Residual Shortcut for Stable Supervision
Injecting ground-truth next-token embeddings into transfer layer input preserves supervision signal quality even with noisy backbone predictions. The residual connection enables gradients to bypass unstable backbone states via an identity-like shortcut, directly optimizing the transfer layer. This prevents the transfer layer from learning corrupted adjacency patterns when the backbone makes prediction errors.

## Foundational Learning

- **Concept: Graph Adjacency vs Reachability Matrices**
  - Why needed here: The entire theoretical framework hinges on distinguishing direct edges (A^{true}) from multi-hop reachability (R^{true}). Confusing these leads to misinterpreting what "degree-2" paths measure.
  - Quick check question: Given nodes A→B→C with no direct A→C edge, is (A,C) in the adjacency matrix? Is it in the reachability matrix?

- **Concept: Cross-Entropy Loss Gradient Flow**
  - Why needed here: Understanding how prediction errors create gradients that flow through the transfer layer to backbone weights is essential for debugging why MTP helps (Theorems 1-2).
  - Quick check question: If the model predicts p=0.3 but ground truth is p=0.7, does the gradient increase or decrease the corresponding logit weight?

- **Concept: Transformer Self-Attention as Matrix Operations**
  - Why needed here: The simplified theoretical model replaces softmax attention with fixed matrices to make gradient analysis tractable. Recognizing this simplification helps interpret which results transfer to full models.
  - Quick check question: In the simplified model, what does setting attention to always attend to position 2 imply about the information each hidden state receives?

## Architecture Onboarding

- **Component map:**
  Input tokens → Embedding (W^t) → Backbone Transformer layers → Hidden state h_n → Transfer layer W^T(k-1) → Output head (W^o) → Softmax → p(u_{n+k})

- **Critical path:** The transfer layer learning sequence (W^T must learn adjacency → backbone can learn transitive reachability via backprop) determines overall success. Monitor transfer matrix adjacency correlation first.

- **Design tradeoffs:**
  - Shared output head (this paper) vs independent heads (Meta): Shared enables parameter efficiency and unified patterns; independent provides flexibility but loses interpretability
  - Linear vs Transformer transfer layer: Linear is analytically tractable; Transformer (1-6 layers) captures dimension interactions for complex multi-hop relations (Table 1 shows 71.32% vs 69.51% on degree-2)
  - 2-token vs 3-token prediction: Diminishing returns; 3-token adds complexity without proportional gains on degree-2/3 (Table 1)

- **Failure signatures:**
  - Degree-2/3 accuracy plateau at ~60%: Transfer layer not learning proper adjacency
  - Transfer matrix weights flat/uniform: Insufficient learning signal or backbone too noisy
  - High spurious adjacency in W^M: Over-strong transitive gradient signal corrupting adjacency learning
  - Performance degradation with larger graphs but fixed embedding: Node count exceeding embedding capacity causes supervision conflicts

- **First 3 experiments:**
  1. **Sanity check on 20-node graph:** Train simplified 1-layer model with fixed W^T=ground-truth adjacency. Verify W^M learns true adjacency and W^V learns observed reachability.
  2. **Ablate NTI with 100-node DAG:** Compare degree-2 accuracy with/without NTI. Visualize transfer matrices to confirm adjacency gap increases.
  3. **Scale to Blocksworld:** Test transfer to structured planning domain with 73 states. Vary training paths and confirm NTI+6-layer Transformer transfer maintains advantage.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can the Next-Token Injection (NTI) mechanism be extended to generate guiding signals in unsupervised settings where ground-truth next tokens are unavailable? The conclusion states the framework "can be enhanced by extending the NTI mechanism to generate guiding signals in unsupervised settings," but this requires removing the dependency on ground-truth next tokens.

- **Open Question 2:** How can the conflict between supervision signals from different token positions be resolved when the number of nodes exceeds the embedding capacity? Table 2 shows performance degrades on 300-node graphs with 120-dim embeddings, and the paper notes "supervision signals from different tokens may conflict, limiting the model's ability to encode structural patterns."

- **Open Question 3:** Can the spurious adjacency problem introduced during transitive reachability learning be systematically mitigated without sacrificing generalization? The theoretical analysis notes that "spurious adjacency (i, k) may be introduced into W^M when learning transitive reachability... mechanically difficult to avoid due to the tight coupling between adjacency and reachability learning."

## Limitations
- Theoretical framework relies on simplifying assumptions about attention mechanisms that may not fully capture real-world Transformer behavior
- Experimental evaluation limited to synthetic graph datasets and a single Blocksworld planning benchmark, raising generalization concerns
- MTP approach requires k times more computation during training than standard next-token prediction, impacting practical applicability

## Confidence
- **High confidence:** The empirical improvements in accuracy (71.32% vs 63.80% on degree-2 paths) are well-documented with clear baselines and ablation studies
- **Medium confidence:** The theoretical analysis connecting transfer layer gradients to adjacency matrix learning is internally consistent but relies on simplified model assumptions
- **Low confidence:** The generalization of MTP benefits to complex, real-world planning tasks beyond synthetic graphs and Blocksworld

## Next Checks
1. **Transfer Layer Visualization on Real Data:** Apply the MTP model to a natural language planning task (e.g., recipe planning or navigation instructions) and visualize the learned transfer matrix to verify it captures meaningful adjacency patterns rather than random noise.

2. **Complexity Analysis with Larger Graphs:** Systematically evaluate model performance as graph size increases beyond 300 nodes while scaling embedding dimensions proportionally, measuring both accuracy degradation and computational overhead.

3. **Robustness to Edge Distribution:** Test MTP performance on graphs with non-uniform edge distributions (e.g., power-law or clustered structures) to assess whether the theoretical benefits hold across diverse graph topologies.