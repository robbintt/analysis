---
ver: rpa2
title: 'Empowering Multimodal LLMs with External Tools: A Comprehensive Survey'
arxiv_id: '2508.10955'
source_url: https://arxiv.org/abs/2508.10955
tags:
- multimodal
- arxiv
- mllms
- large
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This survey presents a comprehensive review of how external tools
  can enhance Multimodal Large Language Models (MLLMs) across four key dimensions:
  high-quality data acquisition, challenging task performance, thorough evaluation,
  and future research directions. The authors categorize external tools into knowledge
  bases, expert models, APIs, physical tools, and program tools, highlighting their
  benefits for knowledge acquisition, expertise enhancement, efficiency, adaptability,
  interpretability, and robustness.'
---

# Empowering Multimodal LLMs with External Tools: A Comprehensive Survey

## Quick Facts
- arXiv ID: 2508.10955
- Source URL: https://arxiv.org/abs/2508.10955
- Reference count: 40
- One-line primary result: Comprehensive survey categorizing external tools that enhance MLLMs across data acquisition, task performance, evaluation, and future directions

## Executive Summary
This survey provides a systematic review of how external tools can enhance Multimodal Large Language Models (MLLMs) across four key dimensions: high-quality data acquisition, challenging task performance, thorough evaluation, and future research directions. The authors categorize external tools into knowledge bases, expert models, APIs, physical tools, and program tools, highlighting their benefits for knowledge acquisition, expertise enhancement, efficiency, adaptability, interpretability, and robustness. The survey examines how external tools can be leveraged for data collection, synthesis, annotation, and cleaning to address the data bottleneck in MLLM development. It then explores how these tools can improve MLLM performance on complex tasks such as multimodal retrieval-augmented generation, reasoning, hallucination detection and mitigation, safety, agent-based applications, and video perception. The survey also reviews external tool-based approaches for MLLM evaluation, including keyword extraction, embedding-based metrics, MLLM-based evaluation, and evaluation platforms. Finally, it identifies key challenges including efficiency, privacy, proactivity, trustworthiness, cost, fairness, and diversity, while outlining promising future research directions for developing more capable and reliable tool-augmented MLLMs.

## Method Summary
The survey systematically categorizes external tools that augment MLLMs, dividing them into knowledge bases, expert models, APIs, physical tools, and program tools. For each category, the authors review how these tools can be applied to enhance MLLMs across four key dimensions: data acquisition (collection, synthesis, annotation, cleaning), challenging task performance (MRAG, reasoning, hallucination detection, safety, agents, video perception), evaluation (keyword extraction, embedding metrics, MLLM-based evaluation, platforms), and future research directions. The methodology involves comprehensive literature review across these domains, organizing findings into a structured taxonomy while identifying key challenges and opportunities. However, the survey does not provide specific implementation details or hyperparameters for individual methods, focusing instead on conceptual frameworks and categorical organization.

## Key Results
- External knowledge retrieval reduces hallucinations by grounding MLLM outputs in verifiable sources through RAG systems
- Expert model delegation improves task-specific performance by routing subproblems to specialized tools like Grounding DINO and Stable Diffusion
- Data quality enhancement via tool-assisted pipelines improves downstream MLLM reliability through better training data

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** External knowledge retrieval reduces hallucinations by grounding MLLM outputs in verifiable sources.
- **Mechanism:** Retrieval-Augmented Generation (RAG) systems employ a three-stage pipeline: (1) embedding-based retrieval from external knowledge bases, (2) reranking to filter noisy candidates, and (3) knowledge integration via in-context learning or instruction tuning. This provides factual anchors that constrain the model's generative process.
- **Core assumption:** Retrieved knowledge is itself accurate and relevant; retrieval models correctly identify knowledge needed for the query.
- **Evidence anchors:**
  - [Section 4.1]: "MRAG aims to improve the factual accuracy of Multimodal Large Language Models (MLLMs) and reduce hallucinations by retrieving and incorporating knowledge from external knowledge bases."
  - [Section 4.3.3]: "ARA retrieves external captions with CLIP to enrich the MLLM's context and reduce hallucinated content."
  - [Corpus]: Related survey "Efficient Multimodal Large Language Models" (FMR=0.64) confirms RAG as efficiency challenge, suggesting tradeoffs remain active research.
- **Break condition:** If retrieval noise exceeds signal, or if knowledge bases contain outdated/incorrect information, grounding may amplify rather than reduce errors.

### Mechanism 2
- **Claim:** Expert model delegation improves task-specific performance by routing subproblems to specialized tools.
- **Mechanism:** The MLLM acts as an orchestrator that parses queries, identifies task requirements (e.g., object detection, image generation), invokes appropriate expert models via API calls, and synthesizes their outputs. Tools like Grounding DINO, SAM, and Stable Diffusion provide capabilities the base MLLM lacks.
- **Core assumption:** The MLLM can accurately determine which tools to invoke and correctly interpret their outputs.
- **Evidence anchors:**
  - [Section 2.2]: "Domain-specific expert models, such as grounding models and diffusion models, can enhance MLLM performance on challenging tasks."
  - [Section 4.5.1]: "HuggingGPT connects diverse community models to handle AI tasks collaboratively."
  - [Corpus]: "Compound AI Systems" survey (FMR=0.55) validates this orchestration paradigm as emerging standard.
- **Break condition:** If tool invocation decisions are unreliable, or if tool outputs are misinterpreted, compounded errors cascade through the pipeline.

### Mechanism 3
- **Claim:** Data quality enhancement via tool-assisted pipelines improves downstream MLLM reliability.
- **Mechanism:** External tools enable scalable data collection (web crawlers), synthesis (LLM-generated annotations), expert annotation (GPT-4V labeling), and cleaning (CLIP-based filtering). Higher-quality training data yields models with better grounding and reduced hallucination tendencies.
- **Core