---
ver: rpa2
title: 'BlackboxNLP-2025 MIB Shared Task: Improving Circuit Faithfulness via Better
  Edge Selection'
arxiv_id: '2510.25786'
source_url: https://arxiv.org/abs/2510.25786
tags:
- edges
- circuit
- edge
- scores
- greedy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work addresses the challenge of circuit discovery in mechanistic
  interpretability, specifically focusing on the selection stage of building subgraphs
  that capture a model''s behavior for a given task. The authors propose three key
  improvements to the standard pipeline: (1) using bootstrapping to identify edges
  with consistently-signed attribution scores, filtering out unstable ones; (2) introducing
  a ratio-based selection strategy (PNR) that balances the proportion of positive
  and negative edges; and (3) replacing greedy selection with an integer linear programming
  (ILP) formulation for globally optimal subgraph construction.'
---

# BlackboxNLP-2025 MIB Shared Task: Improving Circuit Faithfulness via Better Edge Selection

## Quick Facts
- arXiv ID: 2510.25786
- Source URL: https://arxiv.org/abs/2510.25786
- Reference count: 7
- Key outcome: Proposed edge selection improvements yield more faithful circuits across GPT-2, Gemma-2, and Qwen-2.5 models

## Executive Summary
This work addresses the circuit discovery challenge in mechanistic interpretability by improving the edge selection stage of subgraph construction. The authors introduce three key innovations: bootstrapping to filter unstable attribution edges, a ratio-based selection strategy (PNR) that balances positive and negative edges, and integer linear programming for globally optimal subgraph construction. Applied across multiple model-task pairs including IOI, MCQA, and ARC-E, these methods consistently improve circuit faithfulness metrics, demonstrating that principled edge selection can significantly enhance the quality of discovered circuits.

## Method Summary
The authors propose three improvements to the standard circuit discovery pipeline. First, they employ bootstrapping to identify edges with consistently-signed attribution scores, filtering out unstable ones that vary across samples. Second, they introduce a ratio-based selection strategy (PNR) that aims to balance the proportion of positive and negative edges in the subgraph. Third, they replace the greedy selection approach with an integer linear programming (ILP) formulation that finds the globally optimal subgraph construction. These methods are evaluated across multiple models (GPT-2, Gemma-2, Qwen-2.5) and tasks (IOI, MCQA, ARC-E), showing improved faithfulness as measured by CMD and CPR metrics.

## Key Results
- ILP combined with PNR improves CMD (lower is better) across most model-task combinations
- Bootstrapping improves CPR (higher is better) for circuit faithfulness
- The proposed methods yield more faithful circuits than prior approaches across GPT-2, Gemma-2, and Qwen-2.5 models

## Why This Works (Mechanism)
The improvements work by addressing key weaknesses in traditional circuit discovery pipelines. Bootstrapping identifies and filters out attribution edges that are unstable across different input samples, removing noise from the circuit construction process. The PNR strategy ensures a balanced representation of both positively and negatively contributing edges, capturing the full dynamic range of the model's behavior. ILP optimization replaces local greedy decisions with global optimization, finding subgraphs that better represent the underlying computational structure while respecting the constraints of the problem.

## Foundational Learning

1. **Bootstrapping in attribution analysis** - why needed: To assess the stability of attribution scores across samples and filter out unreliable edges
   - quick check: Compute standard deviation of attribution scores across bootstrap samples

2. **Integer Linear Programming for subgraph selection** - why needed: To find globally optimal subgraphs rather than relying on greedy local decisions
   - quick check: Compare ILP solution quality against greedy baseline on small instances

3. **Circuit Faithfulness Metrics (CMD, CPR)** - why needed: To quantitatively measure how well discovered circuits represent the model's actual behavior
   - quick check: Verify that improvements in these metrics correlate with human interpretability

## Architecture Onboarding

Component map: Input samples → Attribution computation → Bootstrapping filter → Edge selection (PNR/ILP) → Circuit subgraph

Critical path: The attribution computation and bootstrapping stages are bottlenecks, as they require running multiple forward passes and computing gradients for each sample in the bootstrap set.

Design tradeoffs: The ILP approach guarantees optimality but may not scale to very large models, while the greedy approach is faster but suboptimal. The PNR strategy trades off pure performance for balanced representation of positive and negative edges.

Failure signatures: Poor bootstrapping may leave unstable edges in the circuit, leading to low CPR scores. Over-aggressive PNR may exclude important edges, degrading CMD. ILP may fail to find feasible solutions on highly constrained instances.

First experiments:
1. Run attribution analysis with and without bootstrapping on a small model-task pair
2. Compare greedy vs ILP selection on circuits of increasing size
3. Test PNR sensitivity by varying the positive/negative edge ratio targets

## Open Questions the Paper Calls Out

The paper identifies several key uncertainties: whether the improvements generalize beyond the specific model-task pairs tested, how well the ILP approach scales to larger models and more complex tasks, and how sensitive the bootstrapping method is to the quality and representativeness of input samples used for sampling.

## Limitations

- The evaluation focuses on a limited set of benchmarks, raising questions about generalizability
- The ILP approach may not scale well to larger models or more complex tasks
- Bootstrapping effectiveness depends on the quality and representativeness of input samples

## Confidence

| Claim | Confidence |
|-------|------------|
| Empirical improvements in circuit faithfulness metrics (CMD and CPR) | High |
| Generalizability of edge selection strategies to other contexts | Medium |
| Computational efficiency and scalability of ILP approach | Low |

## Next Checks

1. Test the proposed methods on additional model architectures and tasks not included in the original evaluation to assess generalizability.

2. Conduct computational efficiency analysis for the ILP-based approach on larger models to determine scalability limits.

3. Perform ablation studies to isolate the contribution of each proposed improvement (bootstrapping, PNR, ILP) to the overall performance gains.