---
ver: rpa2
title: A Novel Diffusion Model for Pairwise Geoscience Data Generation with Unbalanced
  Training Dataset
arxiv_id: '2501.00941'
source_url: https://arxiv.org/abs/2501.00941
tags:
- data
- seismic
- ub-diff
- velocity
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# A Novel Diffusion Model for Pairwise Geoscience Data Generation with Unbalanced Training Dataset

## Quick Facts
- arXiv ID: 2501.00941
- Source URL: https://arxiv.org/abs/2501.00941
- Reference count: 21
- Key outcome: UB-Diff achieves state-of-the-art generation quality on OpenFWI benchmarks, with FID improvements of 7-22% on velocity maps and 8-10% on seismic waveforms.

## Executive Summary
This paper introduces UB-Diff, a novel diffusion model for generating paired multi-modal geoscience data from unbalanced training datasets. The model addresses the challenge of scarce paired data (seismic waveforms) by leveraging abundant unpaired data (velocity maps) through a two-step training approach. UB-Diff uses a shared co-latent space to represent both modalities, with modality-specific decoders (CNN for velocity, Transformer for seismic) to preserve domain-specific structures. Experimental results on OpenFWI datasets show that UB-Diff outperforms state-of-the-art diffusion models in generation quality and pairwise consistency, enabling more effective training of downstream inversion models.

## Method Summary
UB-Diff employs a 1-in-2-out encoder-decoder architecture with a shared co-latent space to generate paired velocity maps and seismic waveforms. The model is trained in two steps: first, the encoder and velocity decoder are pre-trained on all available velocity maps using self-supervised reconstruction; second, the seismic decoder is fine-tuned on the scarce paired data while optionally freezing the encoder and velocity decoder. A latent diffusion model operates on the co-latent space to generate diverse samples, which are then decoded into both modalities. This approach leverages the abundance of unpaired data to improve the quality of generated paired samples, particularly for the minority modality.

## Key Results
- UB-Diff achieves FID improvements of 7-22% on velocity maps and 8-10% on seismic waveforms compared to state-of-the-art diffusion models.
- InversionNet trained on UB-Diff generated pairs shows improved performance (lower MAE, MSE, higher SSIM) on real data compared to models trained on pairs from other diffusion methods.
- The two-step training scheme is crucial, as ablation studies show that UB-Diff without the optimization step performs worse than the full model.

## Why This Works (Mechanism)

### Mechanism 1: Co-Latent Space Enables Cross-Modal Generation
- **Claim**: A shared latent representation allows generating paired data from a single modality input.
- **Mechanism**: The encoder compresses velocity maps to a co-latent space (z ∈ R^c×1×1). Two fully-connected layers transform z to modality-specific latents (z'_v, z'_s), which separate decoders reconstruct. The diffusion process operates only on the co-latent, so sampling z yields both outputs.
- **Core assumption**: Seismic waveforms and velocity maps share learnable structure in latent space (paper cites Feng et al. 2022b for "near-linear relationship").
- **Evidence anchors**:
  - [Introduction]: "we consider utilizing one co-latent variable to represent seismic waveform and velocity map once their latent spaces can be aligned"
  - [Encoder-Decoder Design]: Equation 1 and the 1-in-2-out architecture description
  - [corpus]: Weak direct evidence; related work (SeisRDT, RED-DiffEq) explores latent diffusion for seismic but not cross-modal co-latent specifically
- **Break condition**: If modalities lack shared structure (e.g., unrelated physical phenomena), the co-latent will not transfer, and generated pairs will be physically inconsistent.

### Mechanism 2: Two-Step Training Leverages Imbalanced Data
- **Claim**: Pre-training on abundant majority data, then fine-tuning on limited paired data, outperforms joint training on scarce pairs alone.
- **Mechanism**: Step 1 (Equation 2) trains encoder + majority decoder via self-supervised reconstruction on all m majority samples. Step 2 (Equation 3) fine-tunes with n paired samples (m >> n), optionally freezing encoder/decoder. This learns robust latent representations before minority adaptation.
- **Core assumption**: The encoder trained on majority data captures features transferable to minority modality.
- **Evidence anchors**:
  - [Table 2]: "UB-Diff w/o opt" (without two-step) performs worse than UB-Diff across all datasets
  - [Encoder-Decoder Design]: Equations 2-4 formalize the training scheme with freeze flag F
  - [corpus]: No direct comparison in neighbors; training schemes for imbalanced multi-modal data remain underexplored
- **Break condition**: If majority and minority modalities share no transferable features, Step 1 provides no benefit, and freezing may hurt minority performance.

### Mechanism 3: Physics-Aware Decoder Design Preserves Domain Structure
- **Claim**: Modality-specific decoder architectures (CNN for spatial, Transformer for temporal) preserve physical characteristics better than generic decoders.
- **Mechanism**: Velocity maps are spatial → CNN decoder (Dv) captures spatial correlations. Seismic waveforms are temporal → Transformer decoder (Ds) captures sequential dependencies. This matches inductive bias to data structure.
- **Core assumption**: Seismic waveforms benefit from Transformer's sequence modeling; velocity maps benefit from CNN's spatial inductive bias.
- **Evidence anchors**:
  - [Encoder-Decoder Design]: "seismic data is temporal, we design Ds as a transformer-based decoder... velocity map is spatial data, and we design Dv using a CNN-based decoder"
  - [Figure 6]: UB-Diff generates reflected waves more accurately than MT-Diffusion, suggesting physics-aware design helps
  - [corpus]: Related work (InversionNet, SeismoGen) uses CNNs for seismic; Transformer use is less common
- **Break condition**: If data modalities have mismatched structure (e.g., both spatial), specialized decoders may over-constrain and underfit.

---

## Foundational Learning

- **Concept: Diffusion Models (DDPM/Latent Diffusion)**
  - Why needed here: UB-Diff builds on latent diffusion; you must understand forward/reverse processes, noise scheduling, and training objectives (predicting ε or u).
  - Quick check question: Can you explain why diffusion in latent space (vs. pixel space) improves efficiency and enables conditioning?

- **Concept: Encoder-Decoder Architectures with Bottleneck Latents**
  - Why needed here: The 1-in-2-out structure compresses to 1×1 latent; understanding reconstruction trade-offs is critical.
  - Quick check question: What happens to output fidelity if the latent dimension c is too small? Too large?

- **Concept: Full Waveform Inversion (FWI) Physics**
  - Why needed here: The generated pairs must satisfy physical consistency (wave propagation through velocity maps produces seismic data). Without this, generated data may not train useful downstream models.
  - Quick check question: Why does the paper compare generated seismic waveforms against physical forward modeling (Figure 6)?

---

## Architecture Onboarding

- **Component map**:
  - Encoder E (CNN) -> co-latent z (dim 128) -> FC layers -> z'_v, z'_s -> Decoder Dv (CNN) for velocity, Decoder Ds (Transformer) for seismic
  - U-Net operates on co-latent z_t during diffusion
  - Training: Step 1 (Eq 2) pre-trains Enc+Dv on velocity; Step 2 (Eq 3) fine-tunes with paired data

- **Critical path**:
  1. Pre-train encoder + Dv on all velocity maps (self-supervised reconstruction).
  2. Fine-tune encoder + Dv and train Ds on n paired samples.
  3. Train diffusion U-Net on encoded velocity maps (majority data).
  4. Inference: Sample z_T ~ N(0,I), denoise to z_0, decode via both decoders → paired output.

- **Design tradeoffs**:
  - Freeze vs. unfreeze in Step 2: Freezing protects majority decoder but may limit minority adaptation. Paper experiments with both.
  - Latent dimension c: Too small loses information; too large increases diffusion training cost. Paper uses c=128.
  - Timestep T: Paper uses 256; fewer steps speeds inference but may reduce quality.

- **Failure signatures**:
  - High FID for one modality but not the other → co-latent not aligning properly; check encoder training.
  - Generated seismic lacks reflected waves (Figure 6) → decoder architecture or diffusion training insufficient.
  - UB-Diff w/o opt outperforms UB-Diff → two-step training hurting; consider unfreezing or reducing Step 1 epochs.
  - InversionNet trained on generated data performs poorly → pairwise physical consistency violated; validate with forward modeling.

- **First 3 experiments**:
  1. **Baseline reconstruction test**: Train encoder + single decoder on velocity maps only. Verify reconstruction quality (FID, visual inspection) before adding second decoder.
  2. **Co-latent alignment test**: Encode paired data, visualize z'_v and z'_s distributions. If they don't overlap, the co-latent assumption fails.
  3. **Ablation on paired data ratio**: Test with 1k, 5k, 10k paired samples to characterize sensitivity to imbalance severity. Compare freeze vs. unfreeze strategies.

## Open Questions the Paper Calls Out
- **Question**: Can UB-Diff effectively generalize to other scientific domains where a clear "near-linear relationship" between modalities is not present?
- **Question**: What is the optimal strategy for managing the encoder-decoder "freeze" state during the two-step training optimization to minimize the trade-off between majority and minority generation quality?
- **Question**: How robust is UB-Diff when applied to real-world field data compared to the simulated OpenFWI benchmark datasets?

## Limitations
- The paper assumes a "near-linear relationship" between seismic and velocity modalities without providing quantitative evidence or measuring latent alignment quality.
- While FID scores are reported, perceptual studies or downstream task performance on real data (beyond InversionNet) are not included.
- The two-step training scheme's hyperparameters (when to freeze/unfreeze, number of epochs) are not thoroughly tuned or analyzed.

## Confidence
- **High Confidence**: The core mechanism of using a shared co-latent space for cross-modal generation is well-defined and supported by the architecture description and Equation 1.
- **Medium Confidence**: The two-step training approach is plausible and the ablation (UB-Diff w/o opt) shows it helps, but the optimal configuration for freezing/unfreezing is not fully explored.
- **Medium Confidence**: The physics-aware decoder design (CNN for spatial, Transformer for temporal) is a reasonable inductive bias, but direct comparisons to generic decoders are missing.

## Next Checks
1. **Latent Alignment Analysis**: Visualize and quantify the alignment between z'_v and z'_s for paired training data using techniques like t-SNE or CCA to verify the co-latent assumption.
2. **Decoder Architecture Ablation**: Train a version of UB-Diff with a CNN decoder for seismic data and compare FID and InversionNet performance against the Transformer-based version.
3. **Physics Consistency Test**: Use a forward modeling engine to compute the difference between generated seismic waveforms and the waveforms physically predicted by the generated velocity maps. Quantify this difference for UB-Diff and baseline models.