---
ver: rpa2
title: SignBart -- New approach with the skeleton sequence for Isolated Sign language
  Recognition
arxiv_id: '2506.21592'
source_url: https://arxiv.org/abs/2506.21592
tags:
- language
- sign
- recognition
- skeleton
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces SignBart, a novel approach for isolated sign
  language recognition (ISLR) that overcomes the limitations of existing models by
  independently encoding x and y coordinates of skeleton sequences while maintaining
  their interrelation via Cross-Attention. Traditional models struggle with vanishing
  gradients, high computational costs, and insufficient use of coordinate relationships.
---

# SignBart -- New approach with the skeleton sequence for Isolated Sign language Recognition

## Quick Facts
- arXiv ID: 2506.21592
- Source URL: https://arxiv.org/abs/2506.21592
- Reference count: 40
- Key outcome: SignBart achieves 96.04% accuracy on LSA-64 with only 749,888 parameters by independently encoding x and y coordinates and restoring their spatial relationship via Cross-Attention.

## Executive Summary
This paper introduces SignBart, a novel architecture for isolated sign language recognition (ISLR) that addresses the limitations of existing models. Traditional approaches struggle with vanishing gradients, high computational costs, and insufficient use of coordinate relationships. SignBart independently encodes x and y coordinates of skeleton sequences while maintaining their interrelation via Cross-Attention, leveraging the BART encoder-decoder architecture. The model achieves 96.04% accuracy on LSA-64 with only 749,888 parameters—significantly outperforming previous models with over one million parameters. It also demonstrates strong generalization across WLASL and ASL-Citizen datasets. Ablation studies confirm the importance of coordinate projection, normalization, and multi-part skeleton input in boosting model efficacy.

## Method Summary
SignBart processes skeleton sequences by splitting x and y coordinates, projecting them to higher dimensions via learned linear layers, and processing them through a BART-based architecture. The encoder uses self-attention on x-coordinates while the decoder uses self-causal-attention on y-coordinates plus cross-attention to the encoded x-context. Local normalization is applied using independent bounding boxes for body, left hand, and right hand with 5% margins. The model is trained with AdamW optimizer (weight decay 1e-2), learning rate 2e-4 with cosine annealing plus warmup, and batch size 128. The architecture uses 2 encoder layers, 2 decoder layers, and 16 attention heads, with parameters adjusted per dataset.

## Key Results
- Achieves 96.04% accuracy on LSA-64 with only 749,888 parameters
- Outperforms previous models with over one million parameters
- Demonstrates strong generalization across WLASL and ASL-Citizen datasets
- Ablation studies confirm critical importance of coordinate projection (34% accuracy gain) and three-part normalization (13.5% accuracy gain)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Independent encoding of x and y coordinates with delayed re-integration via Cross-Attention improves feature extraction compared to joint coordinate encoding.
- **Mechanism:** The architecture splits the input skeleton tensor into separate x and y sequences. The Encoder processes x coordinates using bidirectional Self-Attention, while the Decoder processes y coordinates using Self-Causal-Attention. Cross-Attention then queries the encoded x context using the y context, restoring the spatial relationship without early entanglement.
- **Core assumption:** Treating (x, y) as inseparable pairs in standard models limits the network's ability to learn distinct axial features, and cross-attention is sufficient to recover spatial dependencies lost during separation.
- **Evidence anchors:** Abstract confirms the split-coordinate approach; section 3.1 explains the limitation of treating coordinates as inseparable pairs; corpus neighbors do not validate this specific mechanism.
- **Break condition:** If Cross-Attention fails to converge due to insufficient training data, the model learns two disjointed 1D representations lacking spatial coherence, leading to random classification.

### Mechanism 2
- **Claim:** Localized normalization of skeleton parts (body, hands) significantly boosts accuracy by reducing variance in signer position and camera framing.
- **Mechanism:** Instead of normalizing the entire pose to a single global box, the system calculates independent bounding boxes for the body, left hand, and right hand. Coordinates are scaled to [0, 1] relative to their local box with a 5% margin.
- **Core assumption:** The semantics of a sign are contained in the relative shape/movement of the hand within its local bounding box, rather than the hand's absolute position relative to the body center.
- **Evidence anchors:** Section 3.4 describes the three-part normalization approach; Table 8 shows 82.50% → 96.04% improvement; corpus neighbors do not explicitly compare this specific strategy.
- **Break condition:** If a signer's hand moves significantly outside the calculated bounding box, the 5% margin clips the coordinates, destroying information about gesture amplitude.

### Mechanism 3
- **Claim:** Linear projection of raw coordinates to higher dimension (d_model) is prerequisite for meaningful attention operations.
- **Mechanism:** Raw scalar coordinates (x or y) are projected via learned linear layers into embedding vectors of size d_model before entering attention blocks.
- **Core assumption:** Raw scalar values lack the representational richness required for dot-product attention mechanism to compute meaningful similarity scores.
- **Evidence anchors:** Section 3.2 explains the necessity of projection; Table 7 shows 62.08% → 96.04% improvement; corpus neighbors do not mention this requirement.
- **Break condition:** If projection weights are poorly initialized or d_model is too small, attention mechanism operates on low-dimensional data, failing to differentiate between distinct spatial configurations.

## Foundational Learning

- **Concept: BART (Bidirectional and Auto-Regressive Transformers)**
  - **Why needed here:** Unlike standard Transformers or BERT, BART combines bidirectional encoder (seeing whole sequence) with autoregressive decoder (seeing past context). This paper exploits this split to process x (Encoder) and y (Decoder) differently.
  - **Quick check question:** How does the attention mask in the BART decoder differ from the encoder, and why does the paper map y-coordinates to the decoder?

- **Concept: Skeleton/Pose Sequences (T × K × 2)**
  - **Why needed here:** Input is not video pixels but time-series of joint coordinates. Understanding tensor shape (T=time, K=keypoints, 2=coords) is vital for visualizing the "split" operation.
  - **Quick check question:** If input is shape (30, 75, 2), what are the shapes of tensors input to Encoder and Decoder respectively after the split?

- **Concept: Cross-Attention vs. Self-Attention**
  - **Why needed here:** This is the bridge connecting split x and y streams. Must understand that Cross-Attention takes Query from one stream (Decoder/y) and Key/Value from another (Encoder/x).
  - **Quick check question:** In SignBart Cross-Attention block, which coordinate stream provides the Query vector?

## Architecture Onboarding

- **Component map:** Input → Split (x/y) → Local Normalization → Projection → Encoder (x) → Decoder (y) → Cross-Attention (y queries x) → Head (Linear + Softmax)

- **Critical path:** The flow of information from Encoder → Decoder Cross-Attention is the most critical and novel path. If this fails, x and y coordinates remain disconnected.

- **Design tradeoffs:**
  - **Efficiency vs. Complexity:** Model reduces parameters (~750k) compared to SOTA (~84M+), but relies on specific inductive bias (x/y independence) that may not generalize to all 3D motion tasks.
  - **Hand Dominance:** Model inherently weights right hand higher (70% accuracy) than left (23% accuracy) in ablation, suggesting potential bias toward right-handed signers.

- **Failure signatures:**
  - **Symptom:** High training loss, low accuracy (~60%)
  - **Cause:** Likely missing Projection layer or incorrect implementation of coordinate split
  - **Symptom:** Good accuracy on centered signers, failure on moving signers
  - **Cause:** Normalization logic error (e.g., using global frame size instead of local bounding boxes)

- **First 3 experiments:**
  1. **Projection Ablation:** Implement model with and without linear projection layer on LSA-64 to verify 34% accuracy gap claimed in Table 7
  2. **Normalization Stress Test:** Train on LSA-64 with "No Normalization" vs. "Three Bounding Boxes" to confirm 13.5% gain
  3. **Decoder Attention Mask Check:** Run forward pass with zero-mask vs. causal mask in decoder to ensure Self-Causal-Attention strictly enforces sequential constraint on y-coordinates

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the independent encoding of x and y coordinates be adapted for Continuous Sign Language Recognition (CSLR) without losing temporal coherence between glosses?
- **Basis in paper:** The authors state the method "has not been evaluated on the CSLR" and requires additional investigation to improve practical utility.
- **Why unresolved:** Current architecture is validated only on isolated signs (ISLR); CSLR requires processing continuous streams where sign boundaries are ambiguous.
- **What evidence would resolve it:** Benchmarking SignBart on CSLR datasets (e.g., Phoenix-2014T) to evaluate Word Error Rate (WER) and temporal segmentation accuracy.

### Open Question 2
- **Question:** Does the use of three distinct attention mechanisms (Self, Self-Causal, Cross) create computational bottleneck that hinders deployment on mobile devices?
- **Basis in paper:** The paper notes that "three Attention machines could increase the computational cost, especially with datasets containing a lot of keypoints, impacting... mobile devices."
- **Why unresolved:** While parameters are low (750k), sequential attention operations may introduce latency or memory overhead unsuitable for real-time mobile inference.
- **What evidence would resolve it:** Profiling inference speed (FPS) and energy consumption on standard mobile hardware (e.g., Android/iOS) with varying keypoint densities.

### Open Question 3
- **Question:** Does the architectural separation of x and y coordinates result in information loss regarding true spatial dynamics of complex gestures?
- **Basis in paper:** The authors admit that encoding values "may not fully reflect the actual spatial relationship and dynamics of the gesture, losing important information."
- **Why unresolved:** It remains unclear if Cross-Attention is sufficient to fully restore spatial interdependencies lost when axes are processed independently.
- **What evidence would resolve it:** Comparative analysis of trajectory reconstruction error between SignBart and models that process coordinates as coupled pairs.

## Limitations
- **Dataset Specificity:** Reported 96.04% accuracy on LSA-64 is from a single curated dataset; robustness to real-world noise (occlusion, signer variation, background clutter) remains untested.
- **Generalizability of Coordinate Splitting:** Core innovation relies on assumption that spatial dependencies can be recovered solely through cross-attention, not validated on 3D skeleton data or tasks requiring simultaneous encoding of depth and motion.
- **Ablation Control:** Normalization contributes ~13.5% accuracy but conflates effect of bounding-box normalization with specific choice of three-part segmentation; marginal benefit of separating body from hands vs. treating as single part not quantified.

## Confidence
- **High Confidence:** Local bounding-box normalization improving accuracy is well-supported (Table 8, 96.04% vs 82.50%) and aligns with established pose normalization literature.
- **Medium Confidence:** Coordinate-projection requirement (62.08% → 96.04%) is empirically validated but lacks theoretical justification for why scalar-to-vector mapping is necessary beyond enabling attention computation.
- **Low Confidence:** Claim that independent x/y encoding with cross-attention is "more efficient" than joint encoding is weakly supported; no ablation tests performance of standard BART baseline on same task.

## Next Checks
1. **Coordinate Splitting Ablation:** Implement SignBart variant where x and y are concatenated and processed jointly in both encoder and decoder. Compare accuracy and parameter count to proposed split-coord variant on LSA-64 to isolate benefit of architectural choice.

2. **Normalization Granularity Test:** Train variants using (a) global normalization, (b) three-part normalization (body + hands), and (c) full 75-joint normalization. Measure accuracy and parameter efficiency to determine if three-part split is optimal.

3. **Cross-Attention Robustness:** Evaluate model performance when cross-attention is removed (decoder only sees y-context). This will quantify contribution of x/y interrelation mechanism and test claim that spatial dependencies are fully recoverable post-split.