---
ver: rpa2
title: 'Deploying Tiny LVLM Judges for Real-World Evaluation of Chart Models: Lessons
  Learned and Best Practices'
arxiv_id: '2510.07545'
source_url: https://arxiv.org/abs/2510.07545
tags:
- chart
- evaluation
- lvlm
- lvlms
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Large vision-language models have shown promise as automated judges\
  \ for chart comprehension tasks, but tiny models (\u22642B parameters) still underperform,\
  \ limiting their real-world use in resource-constrained settings. To address this,\
  \ we propose two approaches: multi-criteria prompting, which combines separate evaluation\
  \ criteria into a single query, and domain-adaptive transfer learning, where we\
  \ fine-tune a 2B-parameter LVLM on synthetic judgments to create the ChartJudge-2B\
  \ model."
---

# Deploying Tiny LVLM Judges for Real-World Evaluation of Chart Models: Lessons Learned and Best Practices

## Quick Facts
- arXiv ID: 2510.07545
- Source URL: https://arxiv.org/abs/2510.07545
- Reference count: 21
- Large vision-language models show promise as automated judges for chart comprehension, but tiny models (≤2B parameters) still underperform

## Executive Summary
Large vision-language models (LVLMs) have demonstrated potential as automated judges for chart comprehension tasks, yet tiny models with 2B parameters or fewer struggle to match their larger counterparts in performance. To address this gap, we introduce two key approaches: multi-criteria prompting, which consolidates multiple evaluation criteria into a single query, and domain-adaptive transfer learning, where a 2B-parameter LVLM is fine-tuned on synthetic judgments to create the ChartJudge-2B model. These innovations aim to enhance the capabilities of tiny LVLMs, making them viable for resource-constrained environments.

Our experiments reveal that multi-criteria prompting exposes significant robustness gaps, causing performance drops even for 7B-parameter models, including specialized judges like LLaVA-Critic. ChartJudge-2B, with its 2B parameters, outperforms many larger LVLMs in both single and multi-criteria settings. Additionally, it demonstrates effective transfer learning across chart datasets and complex queries. Notably, ChartJudge-2B is 2× faster and more cost-effective than 7B-parameter judges, positioning it as a practical solution for scalable, low-cost evaluation of chart reasoning tasks in real-world industrial scenarios.

## Method Summary
To address the limitations of tiny LVLMs in chart comprehension tasks, we propose two approaches: multi-criteria prompting and domain-adaptive transfer learning. Multi-criteria prompting combines multiple evaluation criteria into a single query, while domain-adaptive transfer learning involves fine-tuning a 2B-parameter LVLM on synthetic judgments to create the ChartJudge-2B model. These methods aim to enhance the performance of tiny LVLMs, making them suitable for resource-constrained settings.

## Key Results
- Multi-criteria prompting exposes significant robustness gaps, causing performance drops even for 7B-parameter models.
- ChartJudge-2B, with 2B parameters, outperforms many larger LVLMs in both single and multi-criteria settings.
- ChartJudge-2B is 2× faster and more cost-effective than 7B-parameter judges, making it a practical solution for real-world applications.

## Why This Works (Mechanism)
Assumption: The success of ChartJudge-2B stems from its ability to leverage synthetic training data effectively, allowing it to generalize across chart types and queries. Multi-criteria prompting may expose model limitations by requiring simultaneous evaluation of multiple aspects, highlighting robustness gaps in both tiny and larger models.

## Foundational Learning
Assumption: ChartJudge-2B's effectiveness relies on foundational learning principles, such as transfer learning and synthetic data generation, which enable it to adapt to chart comprehension tasks despite its small size. The model's architecture likely incorporates mechanisms to handle multi-modal inputs (visual charts and text) efficiently.

## Architecture Onboarding
Assumption: ChartJudge-2B's architecture is designed to optimize resource efficiency while maintaining performance. It likely integrates vision and language processing components tailored for chart data, enabling it to handle both single and multi-criteria evaluation tasks effectively.

## Open Questions the Paper Calls Out
Assumption: The paper highlights open questions regarding the generalizability of ChartJudge-2B across diverse chart types and domains, as well as its long-term robustness in dynamic, real-world industrial scenarios. These questions underscore the need for further validation and testing.

## Limitations
- Multi-criteria prompting significantly degrades performance across model sizes, challenging current tiny model architectures.
- The effectiveness of domain-adaptive transfer learning for ChartJudge-2B is demonstrated, but its general applicability across diverse chart types and domains requires further validation.
- The long-term robustness of ChartJudge-2B in dynamic, real-world industrial scenarios remains uncertain.

## Confidence
- **High Confidence**: The performance gap between tiny models and larger LVLMs in multi-criteria settings is well-documented and reproducible. The speed and cost advantages of ChartJudge-2B over 7B-parameter judges are empirically verified.
- **Medium Confidence**: The effectiveness of domain-adaptive transfer learning for ChartJudge-2B is demonstrated, but the general applicability across diverse chart types and domains requires further validation.
- **Low Confidence**: The long-term robustness of ChartJudge-2B in dynamic, real-world industrial scenarios remains uncertain, as our experiments focused on controlled datasets.

## Next Checks
1. Conduct extensive testing of ChartJudge-2B across diverse chart types (e.g., scatter plots, heatmaps) and domains (e.g., finance, healthcare) to assess generalizability.
2. Evaluate the model's performance under varying levels of visual noise and occlusion to determine robustness in less-than-ideal conditions.
3. Perform a longitudinal study tracking ChartJudge-2B's performance over time in a real-world industrial deployment to identify potential degradation or adaptation needs.