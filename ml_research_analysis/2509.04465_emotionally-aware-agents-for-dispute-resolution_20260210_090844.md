---
ver: rpa2
title: Emotionally-Aware Agents for Dispute Resolution
arxiv_id: '2509.04465'
source_url: https://arxiv.org/abs/2509.04465
tags:
- emotion
- disputes
- dispute
- emotional
- anger
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether automatic text emotion recognition
  can provide insights into dispute resolution by analyzing emotional expressions
  in a large corpus of buyer-seller dispute dialogues. Using large language models
  (LLMs) like GPT-4o, the authors demonstrate significantly improved emotion recognition
  compared to previous methods, with GPT-4o better matching human annotators and capturing
  nuanced emotions such as fear and sadness that previous models missed.
---

# Emotionally-Aware Agents for Dispute Resolution

## Quick Facts
- arXiv ID: 2509.04465
- Source URL: https://arxiv.org/abs/2509.04465
- Reference count: 40
- One-line primary result: LLM-based emotion recognition (GPT-4o) explains up to 40% of variance in subjective dispute outcomes, significantly outperforming prior methods.

## Executive Summary
This study demonstrates that large language models can effectively recognize emotions in buyer-seller dispute dialogues and that these emotions strongly predict subjective resolution outcomes. Using GPT-4o with dialogue context and nuanced emotion labels, the authors achieved significantly better performance than previous methods, explaining 25-40% of variance in participants' feelings about dispute resolution. The analysis reveals that sellers expressing compassion early tend to achieve resolution, while reciprocating buyer anger leads to escalation and impasse.

## Method Summary
The authors compared a fine-tuned T5 transformer baseline with GPT-4o for emotion recognition in the KODIS corpus of 2,025 buyer-seller dispute dialogues. GPT-4o was prompted with dialogue history, role instructions, and in-context examples to output soft emotion intensity vectors (anger, joy, sadness, fear, compassion, surprise, neutral) summing to 1. These per-utterance intensities were aggregated to dialogue level and used to predict Subjective Value Inventory (SVI) scores through linear regression. Human annotations on 100 utterances served as ground truth for validation.

## Key Results
- GPT-4o emotion recognition better matches human annotators and captures nuanced emotions (fear, sadness, compassion) missed by previous models
- Emotion labels explain 25-40% of variance in subjective dispute outcomes (SVI scores)
- Sellers expressing compassion early achieve resolution; reciprocating buyer anger leads to escalation
- T5 model's lack of neutral/compassion labels hindered performance in dispute context

## Why This Works (Mechanism)

### Mechanism 1: Contextual Emotion Recognition via LLMs
LLMs process dialogue history to disambiguate emotional intent, outputting nuanced intensity vectors rather than single labels. This sequential understanding captures emotions like compassion and fear that T5 missed by treating utterances in isolation.

### Mechanism 2: The Escalation-Suppression Spiral
Sellers hold the "circuit breaker" role in disputes. Expressing compassion dampens buyer anger and promotes resolution, while reciprocating anger triggers escalation. The buyer typically initiates with higher anger due to customer service context.

### Mechanism 3: Subjective Value Prediction
Aggregated emotion intensity vectors predict subjective dispute outcomes better than instrumental outcomes. The emotional experience (captured by anger/compassion ratios) correlates more strongly with satisfaction than the actual refund/apology received.

## Foundational Learning

- **Concept**: Subjective Value Inventory (SVI)
  - **Why needed here**: Disputes are about relationship and process fairness, not just outcomes. SVI measures subjective satisfaction beyond instrumental results.
  - **Quick check question**: Can you distinguish between an "Instrumental Outcome" (getting the money back) and "Self" outcome (feeling like you didn't lose face)?

- **Concept**: Mixed-Motive Interactions
  - **Why needed here**: Disputes differ from negotiations; parties are already linked and cannot walk away easily, creating specific escalation dynamics.
  - **Quick check question**: Why does expressing anger work in a negotiation (deal-making) but fail in a dispute (conflict resolution), according to the paper?

- **Concept**: Soft Labeling / Intensity Vectors
  - **Why needed here**: Single-label classification cannot capture mixed emotional states like "frustrated compassion" that are common in disputes.
  - **Quick check question**: How does the T5 model's lack of a "neutral" or "compassion" label specifically hinder its performance in dispute analysis?

## Architecture Onboarding

- **Component map**: Context Manager -> LLM Annotator -> Outcome Predictor -> Intervention Logic
- **Critical path**: Prompt engineering for LLM Annotator is most sensitive; includes dialogue history, role instructions, JSON schema, and in-context learning examples
- **Design tradeoffs**:
  - Accuracy vs. Context Window: Full history improves accuracy but increases latency and token cost
  - Label Granularity: Adding "compassion" aids dispute analysis but may confuse models trained on standard sentiment datasets
  - Model Size: GPT-4o outperforms GPT-4o-mini but at significant cost difference
- **Failure signatures**:
  - Misclassification of "Joy": T5 labeled neutral queries as "Joy" due to lack of context
  - The "Love" Trap: Standard Ekman/T5 labels result in false positives for "Love" where "Compassion" is the actual social signal
- **First 3 experiments**:
  1. Run T5 vs. LLM on 100 utterances and correlate with human annotator scores (targeting >0.6 for Fear/Compassion)
  2. Simulate 100 buyer-only dialogues with high anger; test impasse prediction when seller reciprocates anger
  3. Ablate context (0, 1-turn, full) to quantify R² drop for SVI prediction

## Open Questions the Paper Calls Out

- **Open Question 1**: How do gender and cultural differences interact with automatically recognized emotion to influence dispute resolution outcomes?
  - Basis: Authors explicitly state this as future work; current study didn't analyze demographic interaction effects despite diverse participant pool.

- **Open Question 2**: Can AI agents leverage emotion recognition to successfully intervene and mediate human disputes in real-time?
  - Basis: Authors conclude by proposing to create agents that can effectively mediate disputes; current study only validates recognition, not intervention.

- **Open Question 3**: Does semantic content of conflict dialogue provide predictive power over dispute outcomes beyond emotional expressions?
  - Basis: Authors note future work will explore semantic content annotation beyond emotion; current models leave semantic strategies' contribution unquantified.

## Limitations

- Prompt engineering sensitivity creates significant reproducibility barriers without exact few-shot examples and role instructions
- Small human annotation validation set (100 utterances, N=336) limits confidence in correlation claims
- Cultural and domain generalizability uncertain; findings may not transfer beyond buyer-seller disputes in specific cultural contexts

## Confidence

**High Confidence**: GPT-4o significantly outperforms T5 in emotion recognition accuracy, particularly for nuanced emotions like compassion and fear. Human annotation correlation improvements and R² values of 0.25-0.40 are credible.

**Medium Confidence**: Specific emotional trajectories (compassion early → resolution, anger early → impasse) are supported but may reflect confounding factors. Causal interpretation of sellers "breaking the escalation spiral" needs more controlled experimentation.

**Low Confidence**: Generalizability across dispute domains, cultures, and LLM architectures remains unproven. Exact contribution of each prompt element to performance gain is not systematically isolated.

## Next Checks

1. **Ablation Study on Prompt Components**: Systematically remove or modify individual prompt elements to quantify their independent contribution to emotion recognition accuracy.

2. **Cross-Domain Transfer Validation**: Test emotion recognition and outcome prediction models on different dispute corpus (workplace conflict or legal mediation) to assess generalizability beyond buyer-seller interactions.

3. **Controlled Escalation Simulation**: Create synthetic dispute dialogues with systematically varied buyer anger and experimentally controlled seller responses to provide stronger causal evidence for escalation suppression.