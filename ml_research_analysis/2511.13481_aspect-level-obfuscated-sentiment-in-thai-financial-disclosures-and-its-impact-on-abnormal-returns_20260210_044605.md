---
ver: rpa2
title: Aspect-Level Obfuscated Sentiment in Thai Financial Disclosures and Its Impact
  on Abnormal Returns
arxiv_id: '2511.13481'
source_url: https://arxiv.org/abs/2511.13481
tags:
- sentiment
- financial
- company
- market
- negative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study develops a novel Aspect-Based Sentiment Analysis (ABSA)
  framework to decode obfuscated sentiment in Thai financial annual reports. The authors
  create specialized annotation guidelines and annotate over 100 reports, achieving
  strong inter-annotator agreement.
---

# Aspect-Level Obfuscated Sentiment in Thai Financial Disclosures and Its Impact on Abnormal Returns

## Quick Facts
- arXiv ID: 2511.13481
- Source URL: https://arxiv.org/abs/2511.13481
- Reference count: 8
- Key outcome: Novel ABSA framework decodes obfuscated sentiment in Thai financial reports, with WangchanBERTa outperforming baselines and only Profit/Loss aspect significantly predicting abnormal returns

## Executive Summary
This study develops a novel Aspect-Based Sentiment Analysis (ABSA) framework to decode obfuscated sentiment in Thai financial annual reports. The authors create specialized annotation guidelines and annotate over 100 reports, achieving strong inter-annotator agreement. They fine-tune WangchanBERTa on this dataset, outperforming baseline models (MaxEnt, CNN) in both aspect and sentiment classification, with BERT-based models showing particular strength in capturing contextual meaning. An event study reveals that only specific aspects (notably Profit/Loss) significantly predict abnormal returns, with market reactions being selective and context-dependent. The study finds that negative sentiment does not necessarily decrease returns, highlighting the complexity of sentiment analysis in financial texts and the importance of considering broader market conditions. The dataset and models are publicly available.

## Method Summary
The study creates a specialized dataset of Thai Form 56-1 annual reports (11,702 paragraphs from 189 companies) annotated with 16 aspects and 3 sentiment categories. They fine-tune WangchanBERTa-base-att-spm-uncased with task-specific heads, using preprocessing with pythainlp tokenizer and specified hyperparameters (aspect: lr=3e-5, batch=16, epochs=5; sentiment: lr=5e-5, same otherwise). Baselines include MaxEnt (BoW counts) and CNN (Attacut tokenizer, Universal Sentence Encoder). The dataset is publicly available at https://github.com/nlp-chula/finnlp-sentiment with train/dev/test splits of 8,191/1,756/1,755 paragraphs.

## Key Results
- WangchanBERTa outperforms baseline models (MaxEnt, CNN) in both aspect and sentiment classification
- Only Profit/Loss aspect significantly predicts abnormal returns in event study analysis
- BERT-based models show particular strength in capturing contextual meaning for obfuscated sentiment
- Negative sentiment does not necessarily decrease returns, indicating complex market interpretation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Contextual language models capture obfuscated sentiment more effectively than keyword-based or narrow-context approaches.
- Mechanism: WangchanBERTa's self-attention mechanism models dependencies between distant sentence constituents, enabling detection of strategically framed language where surface positivity conceals underlying negative implications (e.g., "strategic realignment" masking layoffs). The model learns paragraph-level patterns across companies rather than relying on isolated lexical cues.
- Core assumption: Obfuscated sentiment in financial texts requires understanding linguistic context beyond individual keywords or short n-grams.
- Evidence anchors: "BERT-based models showing particular strength in capturing contextual meaning" and "WangchanBERTa can consider a broader linguistic context than CNN due to its use of self-attention... accuracy by 5% over keyword-based models"
- Break condition: When companies employ entirely novel framing strategies absent from training data, or when sentiment is encoded through numerical disclosures rather than narrative text.

### Mechanism 2
- Claim: Domain-expert annotation guidelines enable consistent identification of sentiment that contradicts surface-level positive framing.
- Mechanism: Guidelines operationalize the insight that corporate disclosures use optimistic language to redirect attention from risks. Annotators with economics training learn to recognize patterns where positive framing (expanding into new media, conditional investment language) may signal underlying financial stress or uncertainty.
- Core assumption: Human experts can reliably distinguish between genuinely positive news and strategically obfuscated negative conditions based on contextual cues.
- Evidence anchors: "create specialized annotation guidelines and annotate over 100 reports, achieving strong inter-annotator agreement" with average inter-annotator Cohen's kappa score of 0.73 for aspect annotation and 0.77 for sentiment annotation
- Break condition: When annotation guidelines fail to capture emerging obfuscation strategies, or when annotator expertise varies significantly.

### Mechanism 3
- Claim: Market reactions to annual report sentiment are aspect-selective, with Profit/Loss information driving abnormal returns while other aspects show weak or counterintuitive effects.
- Mechanism: Investors rapidly incorporate financially material information (Profit/Loss) at report release, as evidenced by higher R-squared in shorter windows. Other aspects may be pre-priced, less financially material, or interpreted counterintuitively (e.g., negative Technology sentiment showing positive market impact, possibly signaling investment in future capabilities).
- Core assumption: Form 56-1 releases provide new information that reduces asymmetric information; markets process this information rapidly and rationally based on financial materiality.
- Evidence anchors: "only specific aspects (notably Profit/Loss) significantly predict abnormal returns" and "R-squared values rise from relatively low levels in the ±5-day window to substantially higher values in the ±1-day window... model explains over half of the variation in CAAR"
- Break condition: When information leaks before official release, when market conditions override normal pricing mechanisms, or when investor attention is captured by non-fundamental factors.

## Foundational Learning

- **Aspect-Based Sentiment Analysis (ABSA)**:
  - Why needed here: Unlike document-level sentiment, ABSA disentangles sentiment by topic (16 aspects like Profit/Loss, Governance, M&A), enabling granular analysis of which specific corporate disclosures drive market reactions.
  - Quick check question: Can you explain why "positive sentiment about workforce expansion" and "positive sentiment about dividend increases" might have different market implications?

- **Event Study Methodology**:
  - Why needed here: To establish whether NLP-extracted sentiment has real-world financial impact, the study uses cumulative abnormal returns (CAAR) with Fama-French factor adjustments to isolate report-specific effects from general market movements.
  - Quick check question: Why would you use a 250-day estimation window and multiple event windows (±1, ±3, ±5 days) when analyzing disclosure impacts?

- **Transfer Learning for Low-Resource Languages**:
  - Why needed here: Thai financial NLP lacks sufficient labeled data; WangchanBERTa provides pre-trained Thai language representations that can be fine-tuned on the relatively small annotated dataset (~8,000 training paragraphs).
  - Quick check question: What risks arise when fine-tuning a general-domain language model on domain-specific data with potential annotation biases?

## Architecture Onboarding

- **Component map**: PDF extraction -> Section segmentation -> Paragraph tokenization (pythainlp) -> Expert annotation (16 aspects × 3 sentiments) -> WangchanBERTa fine-tuning -> Aspect classifier / Sentiment classifier -> Event study linkage -> Regression analysis (OLS/Ridge)

- **Critical path**: Annotation guideline development and validator agreement (Cohen's κ > 0.70 is non-negotiable threshold) → Fine-tuning with proper train/dev/test temporal splits (avoiding data leakage from same-year reports) → Event study with appropriate expected return model selection

- **Design tradeoffs**: Multi-class vs. multi-label classification: Paper restricts to multi-class (single aspect/sentiment per paragraph) despite acknowledging multi-label reality, trading accuracy for modeling simplicity; Window size selection: Shorter windows (±1 day) capture immediate reactions with higher R-squared; longer windows (±5 days) may miss effects due to noise from confounding events; OLS vs. Ridge regression: Ridge addresses multicollinearity from correlated aspect-sentiment predictors but complicates coefficient interpretation

- **Failure signatures**: Low Cohen's kappa (< 0.60): Annotation guidelines insufficiently specified for obfuscated language; CNN outperforming BERT on rare aspects: Model overfitting to high-frequency classes; consider class weighting; No significant coefficients in regression: Check for information leakage (events priced before t+1), insufficient observations per aspect-sentiment combination, or market inefficiency; Negative and positive sentiment showing same-direction effects: Possible label confusion or aspect-sentiment interaction effects not modeled

- **First 3 experiments**: Baseline replication with confidence intervals: Train MaxEnt, CNN, and WangchanBERTa on provided train/dev/test splits; use bootstrap resampling to establish whether performance differences are statistically significant; Error analysis by aspect frequency: Identify whether rare aspects (Investment: 0.45%, M&A: 0.74%) systematically underperform; if so, test class-weighted loss or focal loss; Temporal robustness check: Train on 2015-2017 data, validate on 2018, test on 2019 to simulate real-world deployment where obfuscation strategies may evolve

## Open Questions the Paper Calls Out
None

## Limitations
- Annotation subjectivity for obfuscated sentiment may limit generalizability beyond expert annotators
- Multi-class classification simplification potentially loses nuanced information about multiple co-occurring aspects
- 16-aspect taxonomy may not comprehensively capture all relevant financial disclosure dimensions

## Confidence

**High Confidence** (backed by multiple evidence anchors and robust methodology):
- BERT-based models outperform keyword-based and CNN baselines in capturing contextual meaning for aspect and sentiment classification
- Only Profit/Loss aspect significantly predicts abnormal returns in event study analysis
- Inter-annotator agreement scores (0.73-0.77) indicate reliable expert annotation for Thai financial text

**Medium Confidence** (mechanisms plausible but require deeper validation):
- Contextual language models specifically capture obfuscated sentiment better than surface-level approaches
- Market reactions are selective and aspect-dependent, with negative sentiment not necessarily decreasing returns
- Human expert annotation guidelines reliably operationalize obfuscated sentiment identification

**Low Confidence** (claims with limited direct support):
- The multi-class simplification accurately represents complex financial disclosures where multiple aspects naturally co-occur
- The 16-aspect taxonomy comprehensively captures all relevant financial disclosure dimensions
- WangchanBERTa's self-attention mechanism specifically enables detection of novel obfuscation strategies

## Next Checks
1. **Annotation reliability stress test**: Conduct additional annotation rounds with varying expertise levels (economics students vs. industry experts) to establish whether the strong inter-annotator agreement generalizes beyond the initial annotator group and to quantify uncertainty in obfuscated sentiment classification.

2. **Multi-label classification validation**: Re-run the classification pipeline using multi-label approaches (e.g., binary relevance, classifier chains) to quantify information loss from the multi-class simplification and assess whether combined aspect-sentiment patterns improve predictive performance.

3. **Temporal robustness evaluation**: Train and evaluate models on temporally distinct periods (e.g., 2015-2017 train, 2018 validate, 2019 test) to assess whether the framework maintains performance as obfuscation strategies evolve and to identify aspects showing degradation over time.