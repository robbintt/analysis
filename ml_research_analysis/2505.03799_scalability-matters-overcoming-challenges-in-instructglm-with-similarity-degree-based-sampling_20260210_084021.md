---
ver: rpa2
title: 'Scalability Matters: Overcoming Challenges in InstructGLM with Similarity-Degree-Based
  Sampling'
arxiv_id: '2505.03799'
source_url: https://arxiv.org/abs/2505.03799
tags:
- graph
- node
- sdm-instructglm
- available
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SDM-InstructGLM, a method to enhance Large
  Language Models (LLMs) for graph-based tasks without relying on Graph Neural Networks
  (GNNs). The core challenge addressed is the limited ability of LLMs to process large-scale
  graph structures due to token constraints and lack of dedicated graph mechanisms.
---

# Scalability Matters: Overcoming Challenges in InstructGLM with Similarity-Degree-Based Sampling

## Quick Facts
- **arXiv ID:** 2505.03799
- **Source URL:** https://arxiv.org/abs/2505.03799
- **Reference count:** 40
- **Primary result:** SDM-InstructGLM achieves 81.74% (CORA, 1-hop) and 91.70% (PUBMED, 1-hop) accuracy using biased random walk with cosine similarity and degree centrality

## Executive Summary
This paper introduces SDM-InstructGLM, a method to enhance Large Language Models (LLMs) for graph-based tasks without relying on Graph Neural Networks (GNNs). The core challenge addressed is the limited ability of LLMs to process large-scale graph structures due to token constraints and lack of dedicated graph mechanisms. SDM-InstructGLM introduces a similarity-degree-based biased random walk that selectively samples nodes using cosine similarity of node features and degree centrality, enabling efficient and structured graph encoding. This approach improves token utilization and mitigates information loss from random sampling. Experiments on Cora and PubMed datasets show significant accuracy gains: on Cora, 1-hop accuracy improves by 19.2% (to 81.74%) and 2-hop by 16.3% (to 84.92%); on PubMed, 1-hop improves by 0.15% (to 91.70%) and 2-hop by 0.67% (to 91.48%). Ablation studies confirm the importance of both similarity and degree-based weighting, especially in sparse graphs. The results demonstrate SDM-InstructGLM's effectiveness in preserving structural and semantic information for graph learning with LLMs.

## Method Summary
SDM-InstructGLM enhances LLMs for graph tasks by implementing a similarity-degree-based biased random walk that selectively samples and orders nodes based on feature similarity and degree centrality. The method calculates transition probabilities proportional to the product of cosine similarity between node embeddings and the degree centrality of neighbors. Nodes are then ordered by a composite score (similarity × degree) to leverage LLM attention patterns, and hop-aware selection dynamically caps nodes per hop to fit token budget constraints. The approach was evaluated on Cora and PubMed citation networks using LLaMA-7B fine-tuned for 2 epochs with specific hyperparameters.

## Key Results
- Cora dataset: 1-hop accuracy improves from 62.54% to 81.74% (+19.2%), 2-hop from 68.62% to 84.92% (+16.3%)
- PubMed dataset: 1-hop accuracy improves from 91.55% to 91.70% (+0.15%), 2-hop from 90.81% to 91.48% (+0.67%)
- Ablation studies show ~20% accuracy drop on Cora when either similarity or degree is disabled
- Robust performance maintained under strict token constraints (e.g., 5 nodes for 1-hop)

## Why This Works (Mechanism)

### Mechanism 1: Similarity-Degree-Biased Random Walk
The model calculates a transition probability p(v|u) proportional to the product of cosine similarity between node embeddings (hu, hv) and the degree centrality of the candidate neighbor (deg(v)). This prioritizes transitions to neighbors that are both semantically related and structurally significant (hubs). The core assumption is that node feature embeddings possess sufficient discriminative power to serve as a reliable proxy for edge importance, and high-degree nodes act as essential structural carriers.

### Mechanism 2: Structured Node Ordering (Primacy Bias)
Sampled nodes V' are sorted in descending order of score s(v) = cosSim(hu, hv) × deg(v). Instead of a random sequence, the prompt presents the most "important" neighbors first, mapping graph topology to a structured text sequence. The core assumption is that the underlying LLM architecture assigns higher attention or importance to tokens appearing earlier in the sequence for graph reasoning tasks.

### Mechanism 3: Hop-Aware Token Budgeting
The method dynamically calculates Nsample(h) using the minimum of the actual hop count and a ratio of the max token budget (Tmax) to average token cost (Tavg). This ensures the encoded graph fits within the LLM's constraints. The core assumption is that the "average node count" is a sufficient statistic for allocating budget, and strict truncation at specific hop limits does not destroy critical paths required for prediction.

## Foundational Learning

- **Concept: Text-Attributed Graphs (TAGs)**
  - Why needed here: The mechanism relies on "node-feature similarity" using BERT embeddings. Understanding that nodes contain rich text (abstracts/titles) rather than just categorical IDs is crucial for grasping why the similarity bias works.
  - Quick check question: Do the node features in your target graph contain unstructured text (e.g., documents) or merely one-hot vectors?

- **Concept: Neighbor Explosion in GNNs vs. LLMs**
  - Why needed here: The paper frames itself against GNN scalability issues (neighbor explosion) but highlights LLM token limits as the analogous bottleneck. Recognizing this distinction explains why sampling is necessary even without message passing.
  - Quick check question: In a 3-hop traversal, does the number of neighbors grow linearly or exponentially with the hop count?

- **Concept: Instruction Tuning / In-Context Learning**
  - Why needed here: The framework (InstructGLM) treats graph tasks as generative problems (predicting class labels). You must understand that the graph structure is flattened into a natural language prompt (prefix + graph description + query).
  - Quick check question: Is the model learning new weights via backpropagation on the graph edges, or is it predicting the next token (class label) based on a text description of the graph?

## Architecture Onboarding

- **Component map:** Feature Encoder (BERT) -> SDM Sampler (Biased Random Walk) -> Textualizer (Template function) -> LLM (LLaMA-7B)
- **Critical path:** The SDM Sampler is the core novelty. Implementing the transition probability p(v|u) ∝ cos(hu, hv) × deg(v) is the most critical step. Errors here (e.g., normalizing incorrectly or using dot product instead of cosine) will break the structural bias.
- **Design tradeoffs:**
  - Degree vs. Similarity: Ablation shows degree is vital for sparse graphs (CORA), while similarity is less critical for feature-rich graphs (PUBMED). You may need to weight these terms (α · sim + β · deg) for your specific domain.
  - Prompt Length vs. Structure: Aggressive truncation (Hop-Aware Selection) saves tokens but risks losing weak signals.
- **Failure signatures:**
  - Mode Collapse: The random walk gets stuck in a cluster of high-degree nodes, failing to explore diverse regions of the graph.
  - Token Truncation: If Tmax is set too low relative to graph density, the prompt may only contain 1-hop neighbors, rendering the model unable to perform multi-hop reasoning.
- **First 3 experiments:**
  1. **Vanilla vs. SDM:** Run node classification on CORA with uniform random walk vs. SDM to reproduce the ~20% accuracy gain.
  2. **Ablation (w/o Sim):** Disable cosine similarity (rely only on degree) to verify if the semantic signal is actually adding value to your specific dataset.
  3. **Token Stress Test:** Reduce the token budget Tmax by 50% and observe if performance degrades gracefully (robustness check).

## Open Questions the Paper Calls Out

- **Open Question 1:** Can SDM-InstructGLM maintain its performance advantages on significantly larger benchmark datasets, such as ogbn-arxiv, which were excluded due to resource constraints?
- **Open Question 2:** Which specific topological or semantic characteristics determine whether the structured node ordering strategy will yield significant accuracy improvements?
- **Open Question 3:** Does the similarity-degree-based biased random walk mechanism generalize effectively to non-citation domains such as social or biological networks?

## Limitations

- Several key implementation details remain underspecified, limiting direct reproducibility including exact instruction prompt template and critical hyperparameters for hop-aware selection
- Evaluation focuses exclusively on Cora and PubMed datasets with specific characteristics (homophilic, text-attributed graphs), raising questions about generalizability to heterophilic graphs or graphs without text attributes
- Computational overhead of the biased random walk compared to standard random sampling is not quantified
- Claims about computational efficiency and scalability advantages over GNNs are not empirically validated in this paper

## Confidence

**High Confidence:** The core mechanism of similarity-degree-based biased random walk and its implementation is well-specified and supported by ablation results. The claim that both similarity and degree contribute to performance (demonstrated by ~20% accuracy drop when either is disabled) is strongly supported by empirical evidence.

**Medium Confidence:** The hop-aware token budgeting approach is conceptually sound and shows robust performance in limited-node ablation tests, but the exact implementation details and parameter settings are unclear. The claim of effective performance under strict token constraints is supported by Table IV but lacks full methodological transparency.

**Low Confidence:** Claims about computational efficiency and scalability advantages over GNNs are not empirically validated in this paper. The comparison to GNN baselines focuses on accuracy rather than training/inference time, memory usage, or energy consumption.

## Next Checks

1. **Implementation Verification:** Reproduce the Cora dataset experiments comparing uniform random walk versus SDM sampling to verify the claimed ~20% accuracy improvement, ensuring the biased random walk implementation correctly calculates transition probabilities using cosine similarity × degree centrality.

2. **Ablation Replication:** Conduct a systematic ablation study disabling either the similarity component or degree component (as described in Table III) to confirm their individual contributions to performance, particularly examining differences between sparse graphs (CORA) and denser graphs (PUBMED).

3. **Token Budget Sensitivity:** Perform a controlled experiment varying the token budget Tmax across a range of values (e.g., 50%, 75%, 100% of the reported setting) to assess how performance degrades under token constraints and validate the robustness claims in Table IV.