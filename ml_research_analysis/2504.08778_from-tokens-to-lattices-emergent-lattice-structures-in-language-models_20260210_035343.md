---
ver: rpa2
title: 'From Tokens to Lattices: Emergent Lattice Structures in Language Models'
arxiv_id: '2504.08778'
source_url: https://arxiv.org/abs/2504.08778
tags:
- formal
- concept
- attributes
- context
- objects
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a framework to explain how masked language
  models (MLMs) learn hierarchical concept structures using formal concept analysis
  (FCA). The core idea is that MLMs implicitly model object-attribute relationships
  via conditional probabilities, which can be interpreted as a probabilistic formal
  context.
---

# From Tokens to Lattices: Emergent Lattice Structures in Language Models

## Quick Facts
- arXiv ID: 2504.08778
- Source URL: https://arxiv.org/abs/2504.08778
- Reference count: 13
- Primary result: MLMs implicitly learn hierarchical concept lattices via FCA, achieving up to 0.71 F1 and strong MAP in concept classification across three datasets

## Executive Summary
This paper demonstrates that masked language models (MLMs) implicitly learn hierarchical concept structures that can be formally reconstructed using formal concept analysis (FCA). By probing MLMs with structured patterns and interpreting conditional probabilities as object-attribute relationships, the authors show that complete concept lattices—including latent concepts not predefined by humans—emerge naturally from the MLM's pretraining objective. Experiments across three domains validate the approach, showing strong alignment with ground truth concepts and outperforming baseline embedding methods.

## Method Summary
The method extracts a probabilistic formal context from MLMs by designing domain-specific patterns that capture object-attribute relationships, then probing the model to obtain conditional probabilities p(attribute|object). These probabilities are aggregated across patterns, binarized via min-max normalization and thresholding, and fed into FCA to reconstruct the concept lattice. The approach leverages the MLM's bidirectional context to capture complete dependency information, with pattern quality being the critical factor in dependency fidelity.

## Key Results
- MLM-derived formal contexts align well with ground truth, achieving high F1 scores (up to 0.71) and mean average precision in concept classification
- Outperforms baseline embedding methods in concept classification tasks
- Successfully reconstructs latent concepts not predefined by human experts, such as "German and French speaking regions"
- Shows domain adaptation effects, with BioBERT outperforming BERT on biomedical datasets

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** MLMs implicitly learn a probabilistic formal context that encodes object-attribute relationships, enabling concept lattice reconstruction.
- **Mechanism:** The masked language modeling objective trains the model to predict masked tokens from bidirectional context. When objects and attributes appear in structured patterns (e.g., "The eagle is an animal that can [MASK]"), the conditional probability p(attribute|object) approximates the incidence relation in formal concept analysis. By probing with multiple patterns and aggregating, a triadic formal context tensor emerges.
- **Core assumption:** The pretraining corpus contains sufficient object-attribute co-occurrences in predictable syntactic patterns.
- **Evidence anchors:**
  - [abstract] "We show that the MLM's objective implicitly learns a formal context that describes objects, attributes, and their dependencies."
  - [Section 3.1, Definition 7] Formalizes probabilistic triadic context construction from pθ(g|b·,m) or pθ(m|bg,·).
  - [corpus] Related work on formal context extraction (arxiv 2504.06285) confirms corpus-derived context extraction is viable but labor-intensive manually.
- **Break condition:** If patterns contain confounding latent variables (high H(Z|b)), or if object-attribute pairs are rare in pretraining data, the recovered formal context will deviate from ground truth.

### Mechanism 2
- **Claim:** Pattern quality governs the fidelity of dependency capture between objects and attributes.
- **Mechanism:** Conditional mutual information between object g and attribute m, conditioned on pattern b, captures the true dependency only when the pattern constrains confounding factors. Lemma 2 bounds the divergence between observed CMI and true dependency by 2H(Z|b)—the conditional entropy of latent confounders given the pattern.
- **Core assumption:** Patterns can be designed to minimize irrelevant information (H(Z|b) ≈ 0).
- **Evidence anchors:**
  - [Section 3.2, Lemma 2] "The difference between |CMIpθ(g; m|b)| and CMIp(g; m|Z; b) is bounded by 2H(Z|b)."
  - [Section 3.2, Takeaway 1] "The precision of the lattice construction depends mainly on the quality of the chosen pattern."
  - [corpus] Weak direct evidence; no corpus papers directly address pattern design for FCA.
- **Break condition:** Poorly chosen patterns (e.g., ambiguous or multi-domain templates) introduce confounders; performance degrades as H(Z|b) increases.

### Mechanism 3
- **Claim:** Concept lattices emerge deterministically from the closure properties of object-attribute sets via FCA.
- **Mechanism:** Once a binary incidence matrix I is obtained (via thresholding normalized conditional probabilities), FCA applies closure operators: a formal concept (G1, M1) exists iff all objects in G1 share exactly the attributes M1 and vice versa. Partial order ≤C follows from set inclusion, structuring concepts into a complete lattice.
- **Core assumption:** The binarization threshold α appropriately discretizes the probabilistic context.
- **Evidence anchors:**
  - [Section 2, Definitions 3–4] Formal concepts and partial order defined via closure and inclusion.
  - [Section 3.1, Eq. 7] Binarization via min-max normalization with threshold α.
  - [Section 4.4, Fig. 4(a)] F1 scores peak at α ≈ 0.5–0.6, showing threshold sensitivity.
- **Break condition:** If α is too low (noise retained) or too high (signal lost), concept recovery fails; min-max normalization shows more robustness than element-wise sigmoid.

## Foundational Learning

- **Concept: Formal Concept Analysis (FCA)**
  - **Why needed here:** This is the core mathematical framework that transforms raw conditional probabilities into hierarchical concept structures. Without understanding closure operators and partial orders, the lattice reconstruction appears as a black box.
  - **Quick check question:** Given objects {eagle, dove, wolf} and attributes {fly, hunt, swim}, can you identify which pairs satisfy the formal concept closure property?

- **Concept: Conditional Mutual Information (CMI)**
  - **Why needed here:** Lemma 2 uses CMI to formalize why pattern quality matters—it quantifies how much information objects and attributes share beyond what confounders explain.
  - **Quick check question:** If H(Z|b) = 0, what does that imply about the pattern's ability to isolate object-attribute dependencies?

- **Concept: Masked Language Modeling as Dependency Learning**
  - **Why needed here:** The paper reframes MLM not just as token prediction, but as learning a fully-connected dependency graph among tokens. This perspective justifies why pθ(g|b·,m) encodes meaningful relations.
  - **Quick check question:** In the pseudo-likelihood objective, what does each term log pθ(wt|w\t) incentivize the model to learn about token relationships?

## Architecture Onboarding

- **Component map:** Pattern bank -> Probing engine -> Aggregation module -> Binarizer -> FCA constructor
- **Critical path:** Pattern design → probing → aggregation → binarization → FCA. Pattern quality is the single most influential factor.
- **Design tradeoffs:**
  - **Average vs. max pooling:** Average is more stable; max may capture rare but informative patterns.
  - **Threshold selection:** Lower α yields denser lattices (more false positives); higher α yields sparser lattices (potential false negatives). Min-max normalization tolerates higher thresholds better than sigmoid.
  - **Single vs. multi-token attributes:** Objects can be multi-token; attributes in Region-language are single-token. Implementation must handle both via indexing.
- **Failure signatures:**
  - **Low Hit@k on formal context recovery:** Likely pattern mismatch or domain shift (e.g., BERT on biomedical data vs. BioBERT—see Fig. 3a).
  - **Missing latent concepts in lattice:** Threshold too aggressive; try lowering α.
  - **Noisy/no meaningful lattice structure:** Patterns confound multiple relations; redesign to reduce H(Z|b).
- **First 3 experiments:**
  1. **Reproduce Region-language lattice:** Use provided patterns, BERT-base, α = 0.5; verify Hit@10 ≈ 0.975 and F1 ≈ 0.70. Confirm "German and French speaking regions" latent concept emerges (Fig. 4b–c).
  2. **Ablate pattern quality:** Replace informative patterns with vague ones (e.g., "The [obj] is related to [attr]"); expect MRR/HIT degradation per Lemma 2.
  3. **Domain transfer test:** Apply BERT vs. BioBERT on Disease-symptom dataset; quantify performance gap (Table 3) to validate corpus frequency effects.

## Open Questions the Paper Calls Out
- **Open Question 1:** Can the FCA framework be extended to model multi-relational data where objects share multiple distinct types of attributes simultaneously? The authors state the framework is currently limited to single-relational data and list "multi-relational concept analysis" as immediate future work.
- **Open Question 2:** How can the lattice construction framework be effectively adapted for autoregressive language models (e.g., GPT) given their unidirectional context constraints? The paper notes that adapting to autoregressive models requires placing masked tokens at the end of the concept pattern, which may not fit all domains naturally.
- **Open Question 3:** How robust is the reconstructed lattice to the selection of "concept patterns" and the presence of confounding information? While the theory suggests that patterns with high confounding noise degrade the lattice, the empirical sensitivity to automated or sub-optimal pattern selection is not fully explored.

## Limitations
- Pattern quality dependency is critical but poorly characterized—no systematic study of what constitutes "good" patterns
- Assumes object-attribute co-occurrences in pretraining data follow predictable syntactic patterns, but doesn't quantify corpus frequency effects
- Threshold sensitivity analysis doesn't address how noise in probabilistic context affects downstream lattice quality

## Confidence
**High Confidence Claims:**
- MLMs implicitly learn a formal context structure during pretraining (supported by theoretical framework and multiple experimental datasets)
- Pattern quality directly impacts dependency capture accuracy (Theorem 2 and empirical validation)
- FCA can reconstruct both predefined and latent concepts from MLM-derived contexts (demonstrated across three datasets with quantitative metrics)

**Medium Confidence Claims:**
- The min-max normalization approach is more robust than sigmoid for binarization (supported by ablation but limited parameter exploration)
- Domain-matched pretraining data improves performance (one controlled experiment with BioBERT vs BERT)

**Low Confidence Claims:**
- The framework generalizes to arbitrary domains without pattern engineering (no evidence beyond three hand-curated datasets)
- The observed latent concepts are semantically meaningful rather than artifacts (qualitative assessment only)

## Next Checks
1. **Pattern Family Ablation Study:** Systematically vary pattern specificity (specific vs. vague templates) and measure the relationship between H(Z|b) and lattice reconstruction accuracy. This would validate Lemma 2's practical implications.
2. **Cross-Domain Transfer Analysis:** Apply the framework to a domain with no existing pattern templates (e.g., legal documents) and measure performance degradation. Then attempt automated pattern discovery and measure recovery.
3. **Noise Injection Experiment:** Add controlled noise to the probabilistic context before binarization and measure how different α thresholds affect concept recovery rates. This would quantify the framework's robustness to imperfect dependency estimation.