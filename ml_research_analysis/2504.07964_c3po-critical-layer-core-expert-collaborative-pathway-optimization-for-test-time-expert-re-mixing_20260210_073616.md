---
ver: rpa2
title: 'C3PO: Critical-Layer, Core-Expert, Collaborative Pathway Optimization for
  Test-Time Expert Re-Mixing'
arxiv_id: '2504.07964'
source_url: https://arxiv.org/abs/2504.07964
tags:
- optimization
- performance
- experts
- layers
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Mixture-of-Experts (MoE) LLMs suffer from sub-optimal expert pathways,
  with a 10-20% accuracy gap between base models and oracle performance. C3PO addresses
  this by dynamically optimizing expert routing weights at test time using a reference
  set of successful samples.
---

# C3PO: Critical-Layer, Core-Expert, Collaborative Pathway Optimization for Test-Time Expert Re-Mixing

## Quick Facts
- **arXiv ID:** 2504.07964
- **Source URL:** https://arxiv.org/abs/2504.07964
- **Reference count:** 27
- **Primary result:** Achieves 7-15% accuracy improvements over base models by optimizing expert routing at test time using reference neighbors, outperforming 7-9B dense models with 1B active parameters

## Executive Summary
C3PO addresses the sub-optimal expert pathways in Mixture-of-Experts LLMs, which create a 10-20% accuracy gap between base models and oracle performance. The method dynamically optimizes expert routing weights at test time using a reference set of successful samples, without requiring ground truth labels. By focusing on critical layers (last 5) and core experts (top-20), C3PO achieves significant accuracy improvements while maintaining computational efficiency, with OLMoE-C3PO surpassing 7-9B dense models using only 1B active parameters.

## Method Summary
C3PO optimizes expert routing pathways at test time by leveraging successful neighbors from a reference set of correctly-answered samples. The method employs three surrogate objectives—mode finding, kernel regression, and weighted loss minimization—to guide pathway optimization without ground truth labels. Key efficiency optimizations include focusing on critical layers (last 5), core experts (top-20 per layer), and the last token only. The approach uses Neighborhood Gradient Descent (NGD) as the primary optimization method, achieving ~93% of oracle performance while maintaining test-time efficiency.

## Key Results
- 7-15% accuracy improvements over base models on six benchmarks (MMLU, HellaSwag, ARC-C, ARC-E, PIQA, WinoGrande)
- Outperforms established baselines like ICL and prompt tuning
- OLMoE-C3PO with 1B active parameters surpasses 7-9B dense models
- Last 5 layers (L5) yield highest accuracy vs. full-layer optimization (All16)
- Top-20 expert coverage captures 99.8% of post-optimization top-8 experts

## Why This Works (Mechanism)

### Mechanism 1: Surrogate Objective Optimization via Reference Neighbors
Test-time pathway optimization can be performed without ground truth labels by leveraging successful neighbors from a reference set. Given a test sample, C3PO retrieves k nearest neighbors from a reference set of correctly-answered samples and optimizes routing weights using one of three surrogates: mode finding via mean-shift in pathway space, kernel-weighted pathway interpolation, or neighborhood gradient descent on the weighted loss of similar samples. The core assumption is that samples with similar embeddings will benefit from similar expert routing patterns.

### Mechanism 2: Critical Layer Concentration
Optimizing only the last 5 layers achieves superior performance compared to full-layer optimization because deeper layers disproportionately contribute to task-specific refinement. By restricting optimization to layers 12-16 in a 16-layer model, C3PO reduces optimization variables while focusing on high-level semantic specialization rather than low-level feature extraction. The core assumption is that task-relevant routing adjustments primarily occur in later layers.

### Mechanism 3: Core Expert Coverage via Pre-Optimization Top-N Selection
Optimizing only the top 20 experts (by pre-optimization router scores) covers 99.8% of the post-optimization top-8 activated experts. The pretrained router's initial ranking is informative enough that the optimal experts post-optimization are contained within the top-20 candidates. This reduces optimization from 64 to 20 experts per layer without accuracy loss, based on the assumption that pretrained router scores are sufficiently correlated with expert relevance.

## Foundational Learning

- **Concept: Mixture-of-Experts (MoE) Routing**
  - Why needed here: C3PO operates on routing weights; understanding how routers select experts per token is prerequisite to understanding what optimization targets.
  - Quick check question: Can you explain the difference between token-choice routing and expert-choice routing, and which OLMoE uses?

- **Concept: k-Nearest Neighbors with Embedding Models**
  - Why needed here: C3PO retrieves successful neighbors using embedding similarity; the choice of embedding model significantly impacts performance.
  - Quick check question: Given a test sample, how would you compute its k nearest neighbors from a reference set using cosine similarity in embedding space?

- **Concept: Gradient-Free vs. Gradient-Based Optimization**
  - Why needed here: C3PO offers both gradient-free (mode finding, kernel regression) and gradient-based (NGD) methods with different cost-accuracy tradeoffs.
  - Quick check question: What is the computational difference between optimizing via mean-shift vs. gradient descent?

## Architecture Onboarding

- **Component map:**
  Test Sample → Embedding Model → kNN Search → Reference Set (successful pathways)
                                    ↓
  Pretrained Router → Initial Pathway ω → Surrogate Objective → Optimized Pathway ω*
                                    ↓
                            Critical Layers Only (Last 5)
                                    ↓
                            Core Experts Only (Top 20)

- **Critical path:**
  1. Reference set construction: Collect samples with correct model predictions and cache their pathways
  2. Embedding computation: Use high-quality embedding model (NV-Embed-V2 recommended)
  3. Neighbor retrieval: k=3 neighbors via kNN in embedding space
  4. Pathway optimization: Apply NGD for 10 steps with cosine learning rate schedule
  5. Inference: Run forward pass with optimized routing weights on last token only

- **Design tradeoffs:**
  - Mode Finding vs. Kernel Regression vs. NGD: Mode finding is fastest but achieves ~4% lower accuracy than NGD; NGD requires backpropagation but captures ~93% of oracle performance
  - Layer selection: Last 5 layers optimal; adding earlier layers adds computation without accuracy gain
  - Expert selection: Top-8 is insufficient (71.3% coverage), top-20 achieves 99.8% coverage
  - Token optimization: Last token only outperforms 3-token optimization by 1.3%

- **Failure signatures:**
  - Accuracy plateaus at <5 steps: Likely learning rate too high or too few optimization steps
  - Accuracy degrades vs. baseline: Check for reference set contamination (samples with >0.95 similarity to test should be removed)
  - Inconsistent results across runs: Kernel choice matters—Gaussian kernel outperforms Matern by 2.9%
  - High variance across benchmarks: Embedding model quality varies—ensure using recommended NV-Embed-V2

- **First 3 experiments:**
  1. **Baseline validation**: Run OLMoE base model on ARC-C subset (e.g., 100 samples), record accuracy. Should match ~51.3% baseline.
  2. **Critical layer ablation**: Apply C3PO-NGD optimizing only last layer vs. last 5 layers on same subset. Confirm L5 > L1 by ~13%.
  3. **Neighbor count sensitivity**: Test k=1, 3, 5 neighbors on same subset. Confirm k=3 optimal before proceeding to full evaluation.

## Open Questions the Paper Calls Out

### Open Question 1
Can gradient-based C3PO methods (NGD) be adapted for real-time, low-latency inference in production environments, or are they strictly offline optimization tools? The paper reports accuracy and FLOPs reduction but does not provide latency benchmarks or throughput metrics required for deployment evaluation.

### Open Question 2
Does optimizing routing weights for the "last token" effectively transfer to open-ended generation tasks (e.g., summarization, chat) or longer reasoning chains? The optimization strategy relies on a specific token's embedding for loss calculation; it is unclear if this local optimization scales to global coherence in long-form generation.

### Open Question 3
How robust is C3PO when the test sample distribution significantly diverges from the reference set of "successful samples"? The methodology assumes access to a reference set of successful pathways, but the experiments use standard benchmarks with corresponding in-distribution reference sets.

## Limitations

- Empirical validation gaps: The assumption that embedding similarity correlates with optimal pathway similarity is not directly validated
- Reference set quality dependence: C3PO's performance is fundamentally tied to the quality and diversity of the reference set
- Computational overhead opacity: Full computational cost including embedding computation, kNN search, and optimization steps is not comprehensively reported

## Confidence

**High confidence claims** (backed by direct experimental evidence):
- C3PO achieves 7-15% accuracy improvements over base models on six benchmarks
- Optimizing only the last 5 layers (L5) outperforms full-layer optimization (All16)
- Top-20 expert coverage captures 99.8% of post-optimization top-8 experts
- NGD surrogate objective outperforms mode finding and kernel regression

**Medium confidence claims** (supported by ablation studies but with methodological limitations):
- Gaussian kernel consistently outperforms Matern kernel
- Last-token-only optimization matches or exceeds multi-token optimization
- k=3 neighbors provides optimal trade-off between accuracy and stability

**Low confidence claims** (lacking direct validation or theoretical support):
- Embedding similarity correlates with optimal pathway similarity (fundamental assumption not tested)
- Critical layer selection is architecture-agnostic (only validated on OLMoE)
- Core expert coverage assumption holds across diverse task domains (only validated on current reference sets)

## Next Checks

**Check 1: Embedding-Pathway Correlation Validation**
Test whether embedding similarity actually correlates with optimal pathway similarity by selecting pairs of semantically similar test samples, computing their optimal pathways using oracle ground truth labels, and measuring pathway similarity against embedding similarity.

**Check 2: Reference Set Quality Sensitivity Analysis**
Systematically vary reference set characteristics (size, quality threshold, domain diversity) and measure accuracy degradation/gain across these variations to quantify robustness to reference set quality.

**Check 3: Layer Criticality Cross-Architecture Validation**
Apply C3PO with varying layer selections to a different MoE architecture (e.g., DeepSeekMoE) on the same benchmark suite and compare whether the last-5-layers optimality holds or if different architectures show different critical layer patterns.