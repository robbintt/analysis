---
ver: rpa2
title: Dr. GPT Will See You Now, but Should It? Exploring the Benefits and Harms of
  Large Language Models in Medical Diagnosis using Crowdsourced Clinical Cases
arxiv_id: '2506.13805'
source_url: https://arxiv.org/abs/2506.13805
tags:
- medical
- llms
- responses
- health
- queries
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluated the effectiveness and safety of large language
  models (LLMs) in answering everyday health queries using a novel crowdsourced approach.
  A university-level competition engaged 34 participants to generate 212 health-related
  prompts for four publicly available LLMs, with responses evaluated by nine board-certified
  physicians across four metrics.
---

# Dr. GPT Will See You Now, but Should It? Exploring the Benefits and Harms of Large Language Models in Medical Diagnosis using Crowdsourced Clinical Cases

## Quick Facts
- arXiv ID: 2506.13805
- Source URL: https://arxiv.org/abs/2506.13805
- Reference count: 38
- Primary result: Large language models demonstrate 76% accuracy for everyday health queries, with concerns about safety and overreliance requiring ethical oversight

## Executive Summary
This study evaluates the effectiveness and safety of large language models (LLMs) in answering everyday health queries through a novel crowdsourced approach. A university-level competition engaged 34 participants to generate 212 health-related prompts for four publicly available LLMs, with responses evaluated by nine board-certified physicians across four metrics. Results showed that 76% of LLM responses were deemed accurate, with ChatGPT-4o achieving the highest accuracy (84.6%). Retrieval-Augmented Generation (RAG) models did not consistently improve response quality. Interviews with seven medical professionals revealed that LLMs are most effective for specific, well-researched queries and can support health literacy, but concerns remain about inaccuracies, overreliance, and potential harm.

## Method Summary
The research employed a crowdsourced approach where 34 participants generated 212 health-related prompts for evaluation of four publicly available LLMs. Nine board-certified physicians evaluated the responses across four metrics including accuracy, safety, completeness, and helpfulness. The study also included interviews with seven medical professionals to gather qualitative insights about LLM performance and potential impacts on healthcare delivery. The methodology combined quantitative performance metrics with qualitative professional perspectives to provide a comprehensive assessment of LLM capabilities in medical contexts.

## Key Results
- 76% of LLM responses were deemed accurate by board-certified physicians
- ChatGPT-4o achieved the highest accuracy at 84.6% among tested models
- RAG models did not consistently improve response quality
- LLMs are most effective for specific, well-researched queries and can support health literacy

## Why This Works (Mechanism)
Large language models leverage transformer-based architectures trained on vast medical and general knowledge corpora to generate contextually relevant responses to health queries. The models' ability to process natural language and synthesize information from multiple sources enables them to provide coherent medical information. The evaluation framework using multiple physician raters ensures clinical validity assessment, while the crowdsourced prompt generation captures real-world query diversity.

## Foundational Learning
1. **Transformer Architecture** - Why needed: Enables parallel processing of sequential data for efficient language understanding; Quick check: Verify model uses attention mechanisms
2. **Retrieval-Augmented Generation** - Why needed: Supplements model knowledge with external information retrieval; Quick check: Confirm RAG implementation includes vector database search
3. **Prompt Engineering** - Why needed: Optimizes model performance for specific task types; Quick check: Document prompt templates used across models
4. **Clinical Evaluation Metrics** - Why needed: Ensures medical accuracy and safety standards; Quick check: Validate physician evaluation criteria against clinical guidelines
5. **Crowdsourced Data Collection** - Why needed: Generates diverse, representative real-world queries; Quick check: Analyze prompt distribution across health domains
6. **Physician Review Process** - Why needed: Provides expert validation of model outputs; Quick check: Document inter-rater reliability scores

## Architecture Onboarding
**Component Map:** Participants -> Prompt Generation -> LLM Models -> Physician Evaluation -> Quality Assessment
**Critical Path:** Prompt generation → LLM response generation → Physician evaluation → Accuracy scoring
**Design Tradeoffs:** Public LLMs vs. specialized medical models (accessibility vs. accuracy), crowdsourced prompts vs. curated clinical cases (diversity vs. standardization), single evaluation vs. multi-rater reliability (efficiency vs. validity)
**Failure Signatures:** Inaccurate medical information, inconsistent performance across query types, overreliance on model responses, safety concerns in clinical recommendations
**First Experiments:**
1. Compare LLM performance across different health query categories
2. Test RAG effectiveness with varying knowledge base sizes
3. Evaluate impact of prompt engineering on response quality

## Open Questions the Paper Calls Out
None

## Limitations
- Crowdsourced prompt generation may introduce selection bias and lack representation of typical health information seekers
- Small sample of 212 prompts limits generalizability to full spectrum of everyday health queries
- Limited number of physician evaluators per response may affect reliability of accuracy metrics
- Cross-sectional design precludes understanding of how performance changes over time
- Focus on publicly available LLMs may not capture specialized medical AI systems

## Confidence
- High confidence: LLMs demonstrate accuracy rates around 76% for everyday health queries
- Medium confidence: ChatGPT-4o outperforms other tested models
- Medium confidence: RAG does not consistently improve response quality
- Medium confidence: LLMs are most effective for specific, well-researched queries
- Medium confidence: Concerns about inaccuracies and overreliance are valid

## Next Checks
1. Replicate the study with a larger, more diverse set of health queries and a broader participant pool for prompt generation
2. Conduct longitudinal assessment of LLM performance across multiple time points and with varying prompt engineering techniques
3. Expand evaluation to include specialized medical LLMs and implement multi-rater reliability testing to strengthen validity of accuracy assessments