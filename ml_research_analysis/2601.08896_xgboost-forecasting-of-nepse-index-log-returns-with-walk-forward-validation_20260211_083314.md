---
ver: rpa2
title: XGBoost Forecasting of NEPSE Index Log Returns with Walk Forward Validation
arxiv_id: '2601.08896'
source_url: https://arxiv.org/abs/2601.08896
tags:
- xgboost
- learning
- forecasting
- nepse
- index
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study develops a machine learning framework for one-step-ahead
  forecasting of NEPSE Index log-returns using XGBoost. A comprehensive feature set
  is engineered, including lagged log-returns (up to 30 days) and technical indicators
  such as rolling volatility measures and the 14-period RSI.
---

# XGBoost Forecasting of NEPSE Index Log Returns with Walk Forward Validation

## Quick Facts
- arXiv ID: 2601.08896
- Source URL: https://arxiv.org/abs/2601.08896
- Reference count: 6
- Primary result: XGBoost achieves 65.15% directional accuracy in NEPSE Index log-return forecasting, outperforming ARIMA and Ridge regression benchmarks

## Executive Summary
This study develops a machine learning framework for one-step-ahead forecasting of NEPSE Index log-returns using XGBoost. A comprehensive feature set is engineered, including lagged log-returns (up to 30 days) and technical indicators such as rolling volatility measures and the 14-period RSI. Hyperparameter optimization is performed using Optuna with time-series cross-validation. Out-of-sample performance is rigorously assessed via walk-forward validation under both expanding and fixed-length rolling window schemes. The optimal configuration—an expanding window with 20 lags—achieves the lowest log-return RMSE (0.013450) and MAE (0.009814) alongside a directional accuracy of 65.15%, significantly outperforming tuned ARIMA and Ridge regression benchmarks. Feature importance analysis and visual inspection further enhance interpretability. These findings demonstrate the effectiveness of gradient boosting ensembles in modeling nonlinear dynamics in volatile emerging market time series and establish a reproducible benchmark for NEPSE Index forecasting.

## Method Summary
The methodology employs XGBoost for time series forecasting of NEPSE Index log-returns, using engineered features including lagged returns, technical indicators (RSI, rolling volatility), and hyperparameter optimization via Optuna. Walk-forward validation with expanding and rolling window schemes is used for robust out-of-sample evaluation. The framework includes comprehensive benchmark comparison against ARIMA and Ridge regression models, with feature importance analysis and interpretability visualization.

## Key Results
- Optimal configuration achieves RMSE of 0.013450 and MAE of 0.009814 for log-return forecasting
- Directional accuracy reaches 65.15%, significantly outperforming benchmark models
- Expanding window with 20 lags proves most effective validation scheme for this dataset

## Why This Works (Mechanism)
XGBoost's gradient boosting framework effectively captures nonlinear relationships and complex interactions in financial time series data. The combination of lagged returns and technical indicators provides rich temporal features that the ensemble method can leverage. Optuna's hyperparameter optimization ensures optimal model configuration for the specific characteristics of the NEPSE Index. The walk-forward validation approach respects temporal dependencies and provides realistic out-of-sample performance estimates for time series forecasting tasks.

## Foundational Learning
- **Time Series Cross-Validation**: Why needed - to prevent look-ahead bias and ensure temporal validity; Quick check - verify that validation folds respect chronological order
- **Walk-Forward Validation**: Why needed - to simulate real forecasting conditions with expanding/rolling windows; Quick check - confirm window sizes and step increments are properly implemented
- **Feature Engineering for Time Series**: Why needed - to capture temporal dependencies and market dynamics; Quick check - validate that engineered features add predictive value over raw lags
- **Gradient Boosting Ensembles**: Why needed - to model complex nonlinear relationships in financial data; Quick check - monitor overfitting through validation performance
- **Hyperparameter Optimization**: Why needed - to maximize model performance for specific dataset characteristics; Quick check - ensure optimization space covers relevant parameters

## Architecture Onboarding
**Component Map**: Data Preprocessing -> Feature Engineering -> Model Training (XGBoost) -> Hyperparameter Optimization (Optuna) -> Walk-Forward Validation -> Performance Evaluation

**Critical Path**: Data → Features → XGBoost Model → Optuna Tuning → Walk-Forward Testing → Results

**Design Tradeoffs**: Fixed vs. expanding windows balances stability vs. adaptability; Lag length tradeoff between information richness and overfitting; Technical indicators add domain knowledge but increase complexity

**Failure Signatures**: Poor out-of-sample performance indicates overfitting or regime change; Low directional accuracy suggests model misses market dynamics; High RMSE reveals poor point forecast capability

**First Experiments**: 1) Compare expanding vs. rolling window performance sensitivity; 2) Test feature importance stability across different validation schemes; 3) Benchmark XGBoost against simpler linear models with identical features

## Open Questions the Paper Calls Out
None

## Limitations
- Single market focus limits generalizability to other emerging markets or asset classes
- 65.15% directional accuracy still implies substantial error rate with potential trading losses
- Feature engineering may not capture regime shifts common in emerging market volatility

## Confidence
- **High**: Technical implementation of XGBoost with Optuna hyperparameter tuning; benchmark comparison methodology
- **Medium**: Outperformance claims relative to ARIMA and Ridge regression; directional accuracy interpretation
- **Low**: Generalization to other markets; robustness across different time periods; economic significance of forecast errors

## Next Checks
1. Test model robustness using multiple time periods including financial crises and different market regimes
2. Conduct out-of-sample testing on other emerging market indices to assess generalizability
3. Implement transaction cost modeling and risk-adjusted performance metrics to evaluate economic significance beyond statistical accuracy