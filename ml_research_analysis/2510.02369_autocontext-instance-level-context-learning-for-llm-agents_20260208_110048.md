---
ver: rpa2
title: 'AutoContext: Instance-Level Context Learning for LLM Agents'
arxiv_id: '2510.02369'
source_url: https://arxiv.org/abs/2510.02369
tags:
- stone
- wood
- agents
- action
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AutoContext, a method that performs a one-off
  exploration to construct a reusable knowledge graph of instance-level context (environment
  structure, configurations, and mechanics) for LLM agents. By decoupling exploration
  from task solving, AutoContext enables downstream agents to access necessary facts
  directly without redundant exploration.
---

# AutoContext: Instance-Level Context Learning for LLM Agents

## Quick Facts
- arXiv ID: 2510.02369
- Source URL: https://arxiv.org/abs/2510.02369
- Reference count: 32
- One-line primary result: AutoContext achieves 95% success rate on TextWorld (vs 37% baseline) by decoupling exploration from task-solving

## Executive Summary
AutoContext introduces a method for constructing reusable knowledge graphs of instance-level context through systematic one-off exploration. By decoupling exploration from task-solving, AutoContext enables downstream LLM agents to access necessary environment facts directly without redundant exploration. The approach uses a TODO Forest to maintain exploration history compactly and an LLM-driven extractor to convert trajectories into structured knowledge. Experiments across TextWorld, ALFWorld, Crafter, and InterCode-Bash demonstrate substantial performance gains and improved interaction efficiency.

## Method Summary
AutoContext performs systematic exploration to construct a reusable knowledge graph for each environment instance, which is then serialized and appended to downstream agent prompts. The method consists of a Plan-Act-Extract loop: the Planner proposes TODO paths (action/subtask sequences), the Actor executes them and stores trajectories, and the Extractor updates a free-form knowledge graph with triplet facts. The TODO Forest maintains exploration history through state promotion and shallow tree structures, while the knowledge graph is generated without a fixed schema by leveraging LLM internal knowledge. This enables any downstream agent to access instance-specific facts directly without online exploration.

## Key Results
- TextWorld ReAct success rate improves from 37% to 95% with AutoContext
- Interaction efficiency significantly improved across all benchmarks (TextWorld, ALFWorld, Crafter, InterCode-Bash)
- TODO Forest ablation causes pronounced degradation in TextWorld maze navigation
- Extractor ablation leads to performance degradation in ALFWorld and increased verbosity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decoupling exploration from task-solving eliminates redundant rediscovery of instance-specific facts.
- Mechanism: AutoContext performs one-off exploration to construct reusable knowledge graph containing environment structure, configurations, and local mechanics.
- Core assumption: Environment instance is stable enough that facts remain valid across multiple tasks.
- Evidence anchors: [abstract] "one-off exploration to construct a reusable knowledge graph for each environment instance"; [section 3] Formalizes objective as maximizing amortized utility.

### Mechanism 2
- Claim: TODO Forest maintains exploration history compactly, enabling recovery from failures and systematic coverage.
- Mechanism: Forest organizes explored states as tree roots with action/subtask nodes capturing trajectories and key results; failed attempts record negative feedback.
- Core assumption: LLM can reason over serialized forest structure to identify gaps and correct errors within context limits.
- Evidence anchors: [section 4.1] "forest serves as history of valid state transitions and infeasible attempts"; [section 5.2 ablation] "w/o TODO Forest causes pronounced degradation in TEXTWORLD."

### Mechanism 3
- Claim: LLM-driven extraction converts trajectories into structured triplets, enabling agent-agnostic knowledge reuse.
- Mechanism: Extractor prompts LLM to analyze trajectories and propose knowledge graph edits (add/remove triplets) without predefined ontologies.
- Core assumption: LLMs can reliably extract factual triplets from noisy trajectories.
- Evidence anchors: [section 4.2] "prompt the Extractor to extract atomic facts from trajectories in triplet format"; [section 5.2 ablation] "w/o Extractor leads to performance degradation in ALFWORLD."

## Foundational Learning

- Concept: Partially Observable Markov Decision Process (POMDP)
  - Why needed here: AutoContext models environment instances as POMDPs where hidden facts are only revealed upon reaching certain states.
  - Quick check question: Can you explain why a POMDP formulation requires exploration to uncover latent environment structure?

- Concept: Knowledge Graph Triplet Format
  - Why needed here: Instance context is materialized as triplets (subject, relation, object) for downstream agent consumption.
  - Quick check question: Given the triplet "Place Furnace, requires, 4 stone", how would an agent use this to plan?

- Concept: Explore-and-Solve Paradigm in LLM Agents
  - Why needed here: AutoContext critiques existing methods that intertwine exploration with execution.
  - Quick check question: What are two failure modes of intertwined explore-and-solve approaches that AutoContext aims to address?

## Architecture Onboarding

- Component map: Environment → Planner proposes TODO → Actor executes and returns trajectory → Extractor updates KG → Planner promotes informative states → loop until coverage or budget exhaustion → serialize KG for downstream agents

- Critical path: Environment → Planner proposes TODO → Actor executes and returns trajectory → Extractor updates KG → Planner promotes informative states → loop until coverage or budget exhaustion → serialize KG for downstream agents

- Design tradeoffs:
  - Action mode vs Agent mode: Action mode for shorter-horizon environments (TextWorld, ALFWorld, InterCode-Bash); Agent mode for long-horizon survival environments (Crafter)
  - Exploration budget vs coverage: 200 steps achieve 95% entity coverage in TextWorld; budget allocation affects amortized utility
  - Model selection: DeepSeek-V3 for most tasks, DeepSeek-R1 for Crafter's complex exploration

- Failure signatures:
  - Low coverage despite budget exhaustion: Check if Planner strategies are triggering (examine proposed TODO diversity)
  - KG contains contradictions: Verify Extractor correctly processes negative feedback from failed actions
  - Downstream agents show no improvement: Confirm KG serialization correctly appended to prompts

- First 3 experiments:
  1. Replicate TextWorld ReAct baseline (37% success) and verify +AutoContext improvement (95% success)
  2. Ablate TODO Forest and measure coverage/step efficiency on TextWorld
  3. Test transferability: Construct KG on one TextWorld instance, apply to different instance without re-exploration

## Open Questions the Paper Calls Out

- How can AutoContext be extended to support online adjustment mechanisms for dynamically changing environments?
- Can the upfront exploration cost be reduced for disposable environments discarded after single use?
- How does LLM internal knowledge reliance during extraction affect factual accuracy of generated knowledge graph?
- To what extent does maximizing environment coverage correlate with utility for specific task distributions?

## Limitations

- The one-off exploration introduces upfront cost, making method less suitable for disposable environments discarded after single use
- Method assumes environment instances are stable enough for precomputed knowledge to remain valid across tasks
- Context window constraints may limit scalability for very large environments despite TODO Forest compression

## Confidence

- **High Confidence**: Core contribution of decoupling exploration from task-solving is well-supported by substantial performance improvements across all four benchmarks
- **Medium Confidence**: TODO Forest's ability to maintain systematic exploration within context limits is supported by ablation results but lacks detailed scaling analysis
- **Low Confidence**: Extractor reliability for noisy trajectory data is only indirectly supported through performance gains without quantitative accuracy analysis

## Next Checks

1. Context Degradation Test: Apply precomputed knowledge graph to modified environment instance to quantify performance degradation when instance assumptions are violated

2. Extractor Accuracy Analysis: Manually validate precision and recall of LLM extractor on subset of trajectories across different environments

3. Forest Scaling Study: Systematically measure TODO Forest size across environments of increasing complexity against context window limits to identify practical scalability boundaries