---
ver: rpa2
title: Can We Test Consciousness Theories on AI? Ablations, Markers, and Robustness
arxiv_id: '2512.19155'
source_url: https://arxiv.org/abs/2512.19155
tags:
- workspace
- capacity
- self-model
- agents
- noise
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "We test three consciousness theories (Global Workspace Theory,\
  \ Higher-Order Theories, and Integrated Information Theory) in artificial agents\
  \ to determine whether they describe complementary functional layers rather than\
  \ competing accounts. Across three experiments with n=20 seeds per condition, we\
  \ find: (1) ablating the Self-Model abolishes metacognitive calibration (Type-2\
  \ AUROC collapses from 0.92 to 0.50) while preserving first-order task performance,\
  \ yielding a synthetic blindsight analogue consistent with HOT predictions; (2)\
  \ workspace capacity is causally necessary for information access - complete workspace\
  \ lesion produces qualitative collapse in access markers while partial reductions\
  \ show graded degradation, consistent with GWT's ignition framework; (3) GWT-style\
  \ broadcasting amplifies internal noise, creating extreme fragility (L75 \u2248\
  \ 0.04), while agents with both workspace and Self-Model exhibit noise-attenuation\
  \ (L75 0.50), even in Self-Model-off / workspace-read controls; and (4) raw perturbational\
  \ complexity (PCI-A) decreases under workspace bottleneck, cautioning against naive\
  \ transfer of IIT-adjacent proxies to engineered agents."
---

# Can We Test Consciousness Theories on AI? Ablations, Markers, and Robustness

## Quick Facts
- arXiv ID: 2512.19155
- Source URL: https://arxiv.org/abs/2512.19155
- Reference count: 13
- Primary result: Ablating the Self-Model in a synthetic agent abolishes calibrated metacognition while preserving task performance, yielding a "synthetic blindsight" analogue consistent with Higher-Order Theory predictions.

## Executive Summary
This paper tests three major consciousness theories—Global Workspace Theory, Higher-Order Theories, and Integrated Information Theory—in artificial agents to determine if they describe complementary functional layers rather than competing accounts. Through systematic ablation experiments, the study finds that metacognitive calibration can be selectively abolished while preserving first-order task performance, workspace capacity is causally necessary for information access with graded degradation under partial lesions, and GWT-style broadcasting alone amplifies internal noise while the combination with a Self-Model provides noise-attenuation. The results suggest a hierarchical design principle where GWT provides broadcast capacity while HOT provides quality control, neither alone being sufficient for robust agency.

## Method Summary
The study employs MiniGrid environments with a dual-task paradigm requiring agents to process two cues, maintain information through delays, and produce both action and confidence reports. Four agent architectures are tested: A0 (CNN→MLP baseline), A1 (CNN→GRU recurrent baseline), B1 (GWT agent with capacity-limited workspace bus), and B2 (HOT-inspired agent extending B1 with a Self-Model). Training uses behavior cloning from hard-coded oracles with auxiliary losses for confidence calibration. Key experimental manipulations include Self-Model ablation (zeroing the compressed latent while preserving task policy), workspace capacity reduction (4→2→0 slots), and latent noise injection into workspace slots. Performance is measured via Type-2 AUROC for metacognition, conjunction accuracy for access, L75 noise tolerance, and synthetic markers like GBI and PCI-A.

## Key Results
- Ablating the Self-Model abolishes metacognitive calibration (Type-2 AUROC collapses from 0.92 to 0.50) while preserving first-order task performance, yielding a synthetic blindsight analogue consistent with HOT predictions.
- Workspace capacity is causally necessary for information access—complete workspace lesion produces qualitative collapse in access markers while partial reductions show graded degradation, consistent with GWT's ignition framework.
- GWT-style broadcasting amplifies internal noise, creating extreme fragility (L75 ≈ 0.04), while agents with both workspace and Self-Model exhibit noise-attenuation (L75 > 0.50), even in Self-Model-off / workspace-read controls.
- Raw perturbational complexity (PCI-A) decreases under workspace bottleneck, cautioning against naive transfer of IIT-adjacent proxies to engineered agents.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Metacognitive calibration can be selectively abolished by ablating a dedicated Self-Model ($z_{\text{self}}$) while preserving first-order task performance, yielding a synthetic blindsight analogue.
- Mechanism: The Self-Model compresses workspace state, recurrent carrier, and intended actions into a low-dimensional latent. The confidence/wagering head reads exclusively from $z_{\text{self}}$. A no-rewire lesion (zeroing $z_{\text{self}}$) severs metacognitive output while leaving the action policy (workspace-read) intact.
- Core assumption: Metacognitive access requires a higher-order re-representation, not just first-order competence.
- Evidence anchors:
  - [abstract] "ablating the Self-Model abolishes metacognitive calibration (Type-2 AUROC collapses from 0.92 to 0.50) while preserving first-order task performance, yielding a synthetic blindsight analogue consistent with HOT predictions"
  - [section 5.1.2] "Task accuracy...88.5% ± 4.0% accuracy (self-on)...88.2% ± 3.7% accuracy (self-removed)...Type-2 AUROC of 0.92 (self-on)...collapsed to chance (AUROC= 0.50 for all seeds)"
  - [corpus] Corpus evidence on HOT-style metacognitive lesions in AI is sparse; related work on meta-cognitive monitoring in LLMs (e.g., arxiv:2602.02467) does not provide direct lesion-based dissociation evidence.
- Break condition: If first-order performance drops under Self-Model ablation (due to shared pathways), or if confidence does not read exclusively from $z_{\text{self}}$, the double dissociation fails.

### Mechanism 2
- Claim: Workspace capacity is causally necessary for information access, with a discontinuous collapse at full lesion (bus-off) and graded degradation under partial reduction.
- Mechanism: A capacity-limited bus (K slots) stores and broadcasts task-critical cues. Under strong-lesion wiring, cues are routed exclusively through the workspace. Reducing K shortens cue persistence under interference; K=0 eliminates the access pathway entirely.
- Core assumption: Information integration for access-like behavior depends on a centralized broadcast, not distributed recurrence alone.
- Evidence anchors:
  - [abstract] "workspace capacity is causally necessary for information access - complete workspace lesion produces qualitative collapse in access markers while partial reductions show graded degradation, consistent with GWT's ignition framework"
  - [section 5.2.2] "at full capacity (4 slots), B1 achieved 99.5% ± 2.0% conjunction accuracy...At reduced capacity (2 slots), performance dropped to 28.1% ± 9.7%...At bus-off (0 slots), conjunction accuracy collapsed to 0.0% ± 0.0%"
  - [corpus] GWT-inspired AI work (e.g., arxiv:2505.13969) discusses broadcast advantages but does not report capacity-lesion experiments; direct support for capacity-dependent collapse is limited outside this work.
- Break condition: If trunk/recurrent pathways compensate for workspace loss, or cues leak through non-workspace channels, the causal necessity claim weakens.

### Mechanism 3
- Claim: GWT-style broadcast alone amplifies internal noise (fragility), while agents with both workspace and Self-Model training exhibit noise-attenuation, even in Self-Model-off / workspace-read controls.
- Mechanism: In GWT-only agents, the policy reads directly from workspace slots; noise in the workspace propagates unfiltered to actions. In B2-family agents, architectural/training factors confer robustness that persists even when $z_{\text{self}}$ is not used at inference.
- Core assumption: Noise-attenuation is not inherent to broadcast; it requires complementary structure.
- Evidence anchors:
  - [abstract] "GWT-style broadcasting amplifies internal noise, creating extreme fragility (L75 ≈ 0.04), while agents with both workspace and Self-Model exhibit noise-attenuation (L75 > 0.50), even in Self-Model-off / workspace-read controls"
  - [section 5.3.2] "B1 melts instantly...L75=0.036...B2 shrugs off noise...L75>0.50...robustness persisted in the Self-Model-off / workspace-read control"
  - [corpus] Prior GWT-inspired AI work does not document broadcast-amplification failure modes or Self-Model-based attenuation.
- Break condition: If standard regularization or augmentation eliminates B1 fragility (contradicted by section 5.3.2), or if robustness depends solely on inference-time $z_{\text{self}}$ routing, the hierarchical interpretation weakens.

## Foundational Learning
- Concept: Double dissociation (Type-1 vs. Type-2 performance)
  - Why needed here: Essential for interpreting Experiment 1's claim that Self-Model ablation selectively impairs metacognition without affecting task performance.
  - Quick check question: Can you name an example (neuroscience or AI) where lesion X impairs function A but not B, while lesion Y impairs B but not A?

- Concept: Global Workspace Theory (GWT) / ignition
  - Why needed here: The paper operationalizes GWT via a capacity-limited broadcast bus and ignition-like discontinuities; understanding GWT is prerequisite to interpreting workspace capacity and lesion results.
  - Quick check question: In GWT, what is the proposed relationship between "ignition" and conscious access?

- Concept: Perturbational Complexity Index (PCI) and IIT proxies
  - Why needed here: The paper tests an IIT-adjacent proxy (PCI-A) and reports an explicit negative result (inversion under workspace bottleneck). Understanding what PCI measures in biological systems helps interpret the transfer failure.
  - Quick check question: In biological systems, what does higher PCI typically indicate about the brain's state?

## Architecture Onboarding
- Component map:
  - Observation → CNN encoder embedding → Recurrent state (A1/B1/B2) or directly to policy (A0) → Workspace write (B1/B2) → Workspace broadcast → Policy head (B1) and/or Self-Model input (B2) → Self-Model → $z_{\text{self}}$ → Confidence head (B2) → Policy head → Action logits

- Critical path:
  1. Observation → encoder embedding.
  2. Embedding → recurrent state (A1/B1/B2) or directly to policy (A0).
  3. Recurrent state → workspace write (B1/B2).
  4. Workspace broadcast → policy head (B1) and/or Self-Model input (B2).
  5. Self-Model → $z_{\text{self}}$ → confidence head (B2).
  6. Policy head → action logits.

- Design tradeoffs:
  - Workspace capacity vs. interference robustness: Fewer slots reduce bandwidth and shorten cue persistence under masking.
  - Self-Model compression vs. information loss: ~98% dimensionality reduction risks destroying signal if workspace is weak.
  - Routing choice (workspace-read vs. $z_{\text{self}}$-read): Affects whether Self-Model ablation preserves task performance and whether noise-attenuation depends on inference-time routing.

- Failure signatures:
  - Self-Model lesion (no-rewire): Type-2 AUROC → 0.50; confidence constant (~0.54); task accuracy preserved.
  - Workspace lesion (bus-off): Conjunction accuracy → 0%; GBI ≈ 0; ignition sharpness = 0; no cue signal.
  - Latent workspace noise (B1): L75 ≈ 0.04 (broadcast-amplification).
  - Latent workspace noise (B2): L75 > 0.50 (noise-attenuation, even in self-off/workspace-read control).

- First 3 experiments:
  1. Experiment 1 (HOT): Train B2 on wagering task; evaluate with Self-Model on vs. off. Expect preserved accuracy, collapsed AUROC when off (synthetic blindsight).
  2. Experiment 2 (GWT): Train B1 on dual-task with strong-lesion wiring; evaluate across K ∈ {4, 2, 0}. Expect graded degradation and collapse at K=0.
  3. Experiment 3 (Triangulation): Train B1/B2 on dual-task; inject latent noise into workspace; measure L75. Expect B1 fragile (L75≈0.04), B2 robust (L75>0.50). Compute composite markers (GBI + ΔPCI + AUROC) vs. OOD gap.

## Open Questions the Paper Calls Out
- Can calibrated metacognition emerge in reinforcement learning agents trained solely on reward signals, without the explicit metacognitive supervision used in this study?
- Can perturbation protocols or integration metrics be designed that recover the expected theoretical monotonicity (higher integration equals higher complexity) in engineered agents?
- Does the hierarchical design principle (GWT for broadcast, HOT for quality control) generalize to high-dimensional architectures like large language models (LLMs)?
- What is the precise causal mechanism underlying the "noise-attenuation" effect in the B2 agent family, given that it persists in Self-Model-off controls?

## Limitations
- The ablation-induced synthetic blindsight hinges on strict isolation of the Self-Model pathway, which is not visually verified in the provided diagrams.
- GWT capacity-lesion results depend on "strong-lesion wiring" that may not fully isolate workspace from recurrent pathways.
- The noise-attenuation result for B2 agents depends on architectural constraints that may not generalize to larger models, and the claim that robustness persists in Self-Model-off controls is based on limited pilot data.

## Confidence
- High: Workspace capacity causally necessary for access (Experiment 2) - direct, unambiguous collapse at K=0.
- Medium: Self-Model ablation yields synthetic blindsight (Experiment 1) - double dissociation plausible but pathway isolation unverified.
- Low: GWT broadcast amplifies noise (Experiment 3) - the B1 fragility claim is plausible but may depend on narrow architectural conditions.

## Next Checks
1. **Pathway audit**: Trace the exact read routes for policy and confidence heads in both Self-Model-on and Self-Model-off configurations. Confirm zero cross-talk in the ablated state.
2. **Capacity control**: Re-run Experiment 2 with alternative lesion protocols (e.g., gradual K decay, masked workspace read) to verify the discontinuity is not an artifact of strong-lesion wiring.
3. **Noise generalization**: Test latent noise injection at varying workspace read frequencies (per-step vs. per-episode) and with alternative noise distributions to confirm the L75 fragility is robust to implementation details.