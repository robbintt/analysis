---
ver: rpa2
title: 'CausalEmbed: Auto-Regressive Multi-Vector Generation in Latent Space for Visual
  Document Embedding'
arxiv_id: '2601.21262'
source_url: https://arxiv.org/abs/2601.21262
tags:
- arxiv
- document
- embedding
- visual
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "We propose CAUSALEMBED, a novel auto-regressive generation approach\
  \ for visual document embedding that sequentially synthesizes compact, latent multi-vector\
  \ representations in a token-wise fashion. By incorporating iterative margin loss\
  \ and diversity regularization during contrastive training, our method learns compact,\
  \ well-structured embeddings that enable efficient retrieval using only dozens of\
  \ visual tokens\u2014achieving a 30-155x reduction in token count while maintaining\
  \ highly competitive performance across various backbones and benchmarks."
---

# CausalEmbed: Auto-Regressive Multi-Vector Generation in Latent Space for Visual Document Embedding

## Quick Facts
- arXiv ID: 2601.21262
- Source URL: https://arxiv.org/abs/2601.21262
- Reference count: 40
- Key outcome: Achieves 30-155× token reduction while maintaining competitive visual document retrieval performance through auto-regressive latent multi-vector generation

## Executive Summary
CausalEmbed introduces a novel auto-regressive generation approach for visual document embedding that sequentially synthesizes compact, latent multi-vector representations in a token-wise fashion. By incorporating iterative margin loss and diversity regularization during contrastive training, the method learns compact, well-structured embeddings that enable efficient retrieval using only dozens of visual tokens. The approach achieves highly competitive performance across various backbones and benchmarks while dramatically reducing token count compared to full-resource baselines.

## Method Summary
CausalEmbed generates document embeddings through an auto-regressive transformer that conditions each new token on all previously generated tokens. The model is trained with a combination of contrastive loss, progressive refinement loss that encourages each additional token to improve retrieval performance, and diversity regularization that prevents token collapse. During inference, the method supports test-time scaling where users can trade accuracy for latency by adjusting the number of generated tokens.

## Key Results
- Achieves 30-155× reduction in token count compared to full-resource baselines
- Maintains highly competitive retrieval performance across various backbones and benchmarks
- Outperforms underperforming models like PaliGemma by 14.6% with 30× fewer tokens
- Introduces a flexible test-time scaling strategy for multi-vector VDR representations

## Why This Works (Mechanism)

### Mechanism 1: Auto-Regressive Gradient Chain Coverage
Sequential token generation enables more comprehensive gradient propagation during contrastive training compared to parallel patch-level encoding. The auto-regressive dependency means gradients propagate through all preceding generated tokens via the chain rule, providing approximately 2× the expected preceding-token coverage when Nd ≪ Nv.

### Mechanism 2: Progressive Refinement Loss (Ld)
Explicitly enforcing marginal retrieval improvement from each additional token prevents the auto-regressive generator from producing redundant or ineffective vectors. This loss creates a telescoping constraint that rewards progressive enhancement of positive matching while penalizing delayed negative discrimination.

### Mechanism 3: Diversity Regularization (Lq)
Penalizing pairwise cosine similarity between generated query tokens prevents the auto-regressive process from collapsing into repetitive, homogeneous representations. This forces tokens to occupy distinct regions of the embedding space, ensuring generated representations remain diverse and expressive.

## Foundational Learning

- **Late Interaction (MaxSim) Scoring**: Why needed here: CausalEmbed's training objective and theoretical analysis both assume MaxSim aggregation. Quick check: Given query embeddings [q1, q2] and document embeddings [d1, d2, d3], compute S(Q, D) under MaxSim.

- **Contrastive Learning with Hard Negatives**: Why needed here: The margin loss Lm compares positive scores against hardest in-batch negatives. Quick check: In a batch of 8 query-document pairs, how many negative scores does each query consider for Lm?

- **Auto-Regressive Generation in Transformers**: Why needed here: CausalEmbed generates embeddings token-by-token conditioning on all previous tokens. Quick check: Why does auto-regressive generation with KV caching have lower adaptation latency than K-Means clustering of pre-computed embeddings?

## Architecture Onboarding

- **Component map**: Input: Visual document I → Vision encoder Φ → Visual features H^(v) → Generator: LM Ψ → Document embeddings D_g = [d_1, ..., d_Nd]

- **Critical path**: 1. Visual encoding (forward pass through Φ) 2. Auto-regressive generation loop (sequential calls to Ψ with growing context) 3. Loss computation (MaxSim + three loss terms) 4. Backpropagation through prefix-recursive dependencies

- **Design tradeoffs**: Token budget (Nd): Higher improves retrieval but increases latency linearly; 32 tokens achieves strong performance. Loss weights: λ_m=1, λ_d=λ_q=0.1 as defaults. Backbone selection: Qwen2.5-VL outperforms PaliGemma in absolute terms.

- **Failure signatures**: Training collapse to near-zero accuracy (likely missing Lm), generated tokens become nearly identical (check Lq implementation), no improvement from additional tokens (Ld may be ineffective), excessive latency despite few tokens (KV caching may not be enabled).

- **First 3 experiments**: 1. Train CausalQwen with Nd=32 on small ViDoRe subset to verify training loss decreases and nDCG@5 reaches >0.3. 2. Remove Ld, then Lq, then Lm individually to confirm each component's contribution. 3. Train with Nd∈{32,64,128}, then evaluate with inference budgets from 1 to 128 tokens to verify monotonic improvement.

## Open Questions the Paper Calls Out

### Open Question 1
Is the dense patch-level representation a theoretical upper bound for this auto-regressive approach? The paper shows generated embeddings approach but never surpass the ColQwen baseline, raising questions about whether generation can synthesize features superior to original patches.

### Open Question 2
How does the method perform on pure text retrieval or general image retrieval compared to VDR? The scope is strictly Visual Document Retrieval, and it's unclear if the iterative margin loss is effective for non-document modalities where structural layout is absent.

### Open Question 3
Does the auto-regressive latency penalty outweigh storage savings when scaling to longer sequences required for high accuracy? While latency benefits are claimed at 32 tokens, optimal performance requires longer chains, and the linear increase in generation time versus constant time of parallel encoding needs profiling.

## Limitations
- Efficiency gains may be less dramatic when compared against other state-of-the-art multi-vector approaches rather than ColPali-style methods
- Theoretical analysis relies on the assumption of approximately uniform MaxSim index selection, which may not hold for documents with highly skewed visual importance
- Loss functions are specifically designed for VDR task and multi-vector generation scenario, limiting generalizability to other domains

## Confidence

- **High Confidence**: Core architectural design and basic retrieval performance claims are well-supported by comprehensive experiments
- **Medium Confidence**: Theoretical analysis provides plausible mechanism but relies on simplifying assumptions; ablation studies convincing but domain-limited
- **Low Confidence**: Scalability analysis shows monotonic improvement but practical significance of test-time scaling remains unclear; efficiency comparison may overstate gains when accounting for generation latency

## Next Checks

1. **Latency-Accuracy Tradeoff Analysis**: Implement comprehensive benchmark measuring end-to-end retrieval latency (including generation time) across different token budgets on ViDoRe V1/V2, comparing against both single-vector and multi-vector baselines to quantify true efficiency advantage.

2. **Cross-Domain Generalization Test**: Apply CausalEmbed to a non-VDR multi-vector retrieval task using the same architecture and loss configurations to evaluate whether auto-regressive generation and loss functions provide similar benefits outside visual document domain.

3. **Gradient Coverage Validation**: Design controlled experiment with deliberately skewed document visual importance to measure actual gradient magnitudes reaching different token positions during training, comparing between CausalEmbed and ColPali baseline to empirically validate theoretical coverage advantage claims.