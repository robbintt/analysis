---
ver: rpa2
title: Mitigating Catastrophic Forgetting and Mode Collapse in Text-to-Image Diffusion
  via Latent Replay
arxiv_id: '2509.10529'
source_url: https://arxiv.org/abs/2509.10529
tags:
- learning
- replay
- latent
- tasks
- forgetting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This thesis investigates continual learning for text-to-image diffusion
  models, addressing catastrophic forgetting and mode collapse through a neuroscience-inspired
  approach called Latent Replay. By storing compact latent representations extracted
  from the model's internal architecture rather than full images, the method significantly
  reduces memory requirements while preserving critical information needed to maintain
  previously learned concepts.
---

# Mitigating Catastrophic Forgetting and Mode Collapse in Text-to-Image Diffusion via Latent Replay

## Quick Facts
- arXiv ID: 2509.10529
- Source URL: https://arxiv.org/abs/2509.10529
- Authors: Aoi Otani
- Reference count: 11
- Key outcome: Latent Replay preserves 77.59% image alignment on earliest concept while reducing memory requirements

## Executive Summary
This thesis addresses the challenge of continual learning in text-to-image diffusion models, where models typically suffer from catastrophic forgetting when learning new visual concepts sequentially. The proposed Latent Replay method stores compact latent representations extracted from the model's internal architecture rather than full images, dramatically reducing memory requirements while preserving critical information needed to maintain previously learned concepts. Through experiments with five sequentially learned visual concepts, the approach demonstrates substantial improvements over baseline methods, retaining 77.59% Image Alignment on the earliest concept—14% higher than alternatives—while maintaining diverse outputs.

The research reveals that random selection of stored latent examples outperforms similarity-based strategies, a counterintuitive finding that suggests the importance of maintaining diverse replay samples rather than selecting only the most similar ones. The method successfully preserves both concept fidelity and generation diversity, achieving performance approaching that of offline training while using only a fraction of the memory. This work paves the way for personalized text-to-image models that can evolve with user needs without excessive computational costs, addressing a critical limitation in current diffusion model deployment.

## Method Summary
The Latent Replay approach addresses catastrophic forgetting in text-to-image diffusion models by storing compressed latent representations rather than full images. The method extracts embeddings from the model's internal layers during training on each concept, creating a compact memory store that captures essential visual information while requiring significantly less storage than image-based replay. During subsequent training on new concepts, these latent representations are replayed to the model, helping maintain knowledge of previously learned concepts. The approach leverages the inherent structure of diffusion models, using their internal representations as a natural compression mechanism that preserves the semantic content necessary for faithful generation.

## Key Results
- Latent Replay achieved 77.59% Image Alignment on earliest concept, 14% higher than baseline methods
- Random selection of latent examples outperformed similarity-based selection strategies
- Memory requirements reduced by storing latent representations instead of full images
- Maintained generation diversity while preserving concept fidelity

## Why This Works (Mechanism)
The Latent Replay method works by leveraging the hierarchical structure of diffusion models, where internal latent representations capture progressively refined visual information. By storing these compressed embeddings rather than full images, the approach maintains the essential semantic content needed for generation while dramatically reducing memory overhead. The replay mechanism ensures that gradients from previously learned concepts continue to influence the model during training on new concepts, preventing the overwriting of knowledge that causes catastrophic forgetting. The surprising effectiveness of random selection suggests that maintaining diverse replay samples, rather than selecting only the most similar ones, provides broader coverage of the concept space and prevents overfitting to specific patterns.

## Foundational Learning
- **Catastrophic Forgetting**: The tendency of neural networks to rapidly lose previously learned information when trained on new tasks sequentially. This is fundamental because it represents the core problem being solved.
- **Mode Collapse**: A phenomenon where generative models produce limited variations of outputs, losing diversity. Critical for understanding why maintaining diversity alongside concept preservation matters.
- **Diffusion Models**: Generative models that denoise random noise into coherent images through iterative steps. Essential background as the target architecture being adapted for continual learning.
- **Latent Representations**: Compressed embeddings that capture semantic content of inputs. The key innovation uses these instead of full images for memory efficiency.
- **Replay Mechanisms**: Techniques that reintroduce previous data during new training to prevent forgetting. Forms the basis of the solution strategy.
- **Image Alignment Metrics**: Quantitative measures of how well generated images match target concepts. Needed to evaluate whether the approach successfully preserves learned concepts.

## Architecture Onboarding

Component Map: Text Prompt -> Text Encoder -> Latent Space -> Diffusion UNet -> Latent Replay Buffer -> Final Image Generation

Critical Path: Text input flows through encoder into latent space, where the UNet generates images. The replay buffer injects previously learned latent representations during training to prevent forgetting.

Design Tradeoffs: The method trades some generation fidelity for memory efficiency by using compressed latent representations instead of full images. Random selection trades potential precision for diversity maintenance.

Failure Signatures: Mode collapse would manifest as repetitive outputs lacking variation. Catastrophic forgetting would show as degraded performance on earlier concepts while learning new ones.

First Experiments:
1. Compare image alignment metrics across baseline, full-image replay, and latent replay methods
2. Measure memory usage differences between storing full images versus latent representations
3. Evaluate generation diversity using standard metrics across all approaches

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Latent representations may not fully capture semantic richness of original images
- Random selection superiority may be dataset-specific and not generalize across different visual concept sequences
- Evaluation focuses on image alignment and diversity metrics, potentially overlooking semantic coherence and prompt adherence

## Confidence

- High Confidence: Memory efficiency claims and core finding that Latent Replay reduces memory requirements while maintaining generation quality
- Medium Confidence: Superiority of random selection over similarity-based strategies, requires further validation across different datasets
- Medium Confidence: Performance approaching offline training levels, comparison may not account for all quality dimensions

## Next Checks

1. Conduct ablation studies to quantify the contribution of each component (diffusion model selection, latent representation extraction, replay mechanism) to performance improvements

2. Test the approach across multiple task sequences with varying degrees of semantic similarity between consecutive concepts to assess robustness

3. Evaluate generated images using human perceptual studies to validate whether quantitative metrics align with subjective quality assessments