---
ver: rpa2
title: 'Emission-GPT: A domain-specific language model agent for knowledge retrieval,
  emission inventory and data analysis'
arxiv_id: '2510.02359'
source_url: https://arxiv.org/abs/2510.02359
tags:
- emission
- data
- emissions
- dust
- sources
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Emission-GPT is a domain-specific large language model agent designed
  to support knowledge retrieval, emission inventory compilation, and data analysis
  in atmospheric emissions. Built on a curated knowledge base of over 10,000 documents
  and a modular architecture integrating retrieval-augmented generation, function
  calling, and prompt engineering, it enables users to interact with emission data
  and standards through natural language.
---

# Emission-GPT: A domain-specific language model agent for knowledge retrieval, emission inventory and data analysis

## Quick Facts
- arXiv ID: 2510.02359
- Source URL: https://arxiv.org/abs/2510.02359
- Authors: Jiashu Ye; Tong Wu; Weiwen Chen; Hao Zhang; Zeteng Lin; Xingxing Li; Shujuan Weng; Manni Zhu; Xin Yuan; Xinlong Hong; Jingjie Li; Junyu Zheng; Zhijiong Huang; Jing Tang
- Reference count: 40
- Key outcome: Domain-specific LLM agent for emission knowledge retrieval, inventory compilation, and data analysis with high answer accuracy and expert-evaluated superiority over baselines.

## Executive Summary
Emission-GPT is a domain-specific large language model agent designed to support knowledge retrieval, emission inventory compilation, and data analysis in atmospheric emissions. Built on a curated knowledge base of over 10,000 documents and a modular architecture integrating retrieval-augmented generation, function calling, and prompt engineering, it enables users to interact with emission data and standards through natural language. In a benchmark test, Emission-GPT achieved high answer relevancy (>0.90) and faithfulness (>0.70) across categories and difficulty levels. Expert evaluation showed it outperformed baseline models (GPT-4o and DeepSeek R1) in accuracy, citation quality, and relevance. Case studies in Guangdong Province demonstrated its capability to retrieve emission factors and analyze sectoral emission trends with interpretable visual outputs.

## Method Summary
Emission-GPT employs a three-stage pipeline: query classification, knowledge retrieval via RAG, and function calling for data analysis. The system uses a curated corpus of 10,332 documents (~1M text chunks), indexed with BGE-M3 embeddings for semantic retrieval. Queries are classified into Category I (knowledge retrieval) or Category II (data analysis). Category I queries trigger RAG with Qwen-plus for evidence-based generation; Category II queries invoke structured function calling with JSON-validated schemas for API/SQL execution. The system integrates emission factor and inventory databases, and includes visualization modules for data analysis outputs.

## Key Results
- Achieved high answer relevancy (>0.90) and faithfulness (>0.70) across categories and difficulty levels in benchmark tests.
- Outperformed baseline models (GPT-4o, DeepSeek R1) in expert evaluation for accuracy, citation quality, and relevance.
- Successfully retrieved emission factors and analyzed sectoral emission trends in Guangdong Province with interpretable visual outputs.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Grounding LLM outputs in a curated, domain-specific corpus via RAG reduces hallucination and improves factual accuracy for technical emission queries.
- Mechanism: User queries are embedded using BGE-M3, matched against ~1M pre-chunked document segments via cosine similarity, and the retrieved context is injected into the Qwen-plus generator before response synthesis.
- Core assumption: Retrieval quality is sufficient; semantic similarity alone can surface the right evidence chunks for domain questions.
- Evidence anchors:
  - [abstract] "Built on a curated knowledge base of over 10,000 documents... achieved high answer relevancy (>0.90) and faithfulness (>0.70)."
  - [section 2.3] Describes BGE-M3 embeddings and Qwen-plus for retrieval and generation; notes improved accuracy via evidence-based generation.
  - [corpus] Weak direct corpus support for this specific RAG architecture; nearest papers discuss emission modeling tools but not RAG-based QA systems.
- Break condition: Retrieval fails (low context precision), or queries are ambiguous/multilingual in ways the embedding model cannot resolve.

### Mechanism 2
- Claim: Explicit query classification before processing improves task-appropriate routing and output reliability.
- Mechanism: A first-stage LLM classifies each query as Category I (knowledge retrieval) or Category II (data analysis). Category I triggers RAG; Category II invokes function calling to construct API/SQL queries against emission databases.
- Core assumption: The classification model reliably distinguishes knowledge-seeking from analysis-seeking intent.
- Evidence anchors:
  - [section 2.1] "Upon receiving a user query, the first-stage LLM classifies the question into one of two categories... For Category I queries, a second-stage expert LLM performs knowledge retrieval using RAG... For Category II queries, a third-stage LLM is invoked to construct API-level requests and SQL-like queries."
  - [corpus] No direct corpus evidence on query classification effectiveness; related tools (e.g., CarbonChat) use LLMs for domain QA but don't describe multi-stage routing.
- Break condition: Misclassification (e.g., a data analysis query routed to RAG) causes missing or irrelevant outputs.

### Mechanism 3
- Claim: Structured prompt engineering with JSON-validated function schemas enables reliable translation from natural language to executable database operations.
- Mechanism: Each tool is defined with a JSON schema (name, description, input schema). The LLM generates structured JSON function calls; a chain-of-thought layer interprets and executes them. Invalid outputs trigger clarification rather than silent failure.
- Core assumption: The LLM can consistently generate syntactically and semantically correct JSON aligned with backend schemas.
- Evidence anchors:
  - [section 2.5.1] "Each function is defined at initialization with a unique name, a concise description... and a formal input schema based on the JSON format."
  - [section 2.5.2] "Following generation, all outputs are validated against predefined function metadata... Invalid outputs trigger clarification protocols rather than silent failure."
  - [corpus] Limited corpus support; CarbonChat uses LLM-based climate Q&A but doesn't describe function-calling architectures.
- Break condition: Schema drift, ambiguous user intent, or complex multi-hop queries exceed the model's ability to produce valid JSON.

## Foundational Learning

- Concept: Retrieval-Augmented Generation (RAG)
  - Why needed here: Core mechanism for grounding emission knowledge answers in curated documents rather than model weights.
  - Quick check question: Given a domain query and a corpus, can you explain why retrieving context before generation improves factual accuracy compared to prompting alone?

- Concept: Function Calling / Tool Use in LLMs
  - Why needed here: Enables natural-language control over structured data analysis operations (SQL queries, visualizations) without user coding.
  - Quick check question: How does a JSON-structured function schema constrain LLM outputs, and what happens when validation fails?

- Concept: Multi-stage Agent Pipelines
  - Why needed here: Emission-GPT separates classification, retrieval, and execution into specialized stages for robustness.
  - Quick check question: What is the risk of routing a data analysis query to the RAG module instead of the function-calling module?

## Architecture Onboarding

- Component map: Front-end -> Query Classification -> (RAG OR Function Call) -> Validation -> Response
- Critical path: Query → Classification → (RAG OR Function Call) → Validation → Response. Monitor classification accuracy, retrieval recall, and JSON validation failure rates.
- Design tradeoffs:
  - Chunk size (256 tokens) balances granularity vs context; smaller chunks improve precision but may lose coherence.
  - Dual-stage EF retrieval prioritizes regulatory sources (high trust) over literature (empirical richness) — trades compliance coverage for scientific completeness.
  - Multilingual corpus improves breadth but reduced context precision scores suggest embedding/retrieval challenges with mixed Chinese-English content.
- Failure signatures:
  - Low context precision (<0.5) indicates retrieval returning irrelevant chunks.
  - JSON validation failures suggest ambiguous queries or schema drift.
  - Misclassification symptoms: knowledge questions getting code/SQL outputs, or analysis queries receiving text-only answers.
- First 3 experiments:
  1. Ablation test: Run the benchmark dataset (60 questions) with and without RAG to quantify hallucination reduction and faithfulness delta.
  2. Classification audit: Manually label 100 queries and compare against model classification to measure routing accuracy.
  3. Retrieval quality probe: For failed or low-scored answers, analyze which chunks were retrieved and whether the correct evidence was present in top-k results.

## Open Questions the Paper Calls Out
None

## Limitations
- Generalization to other domains: Performance on non-Chinese emission contexts remains untested.
- Multilingual retrieval quality: Context precision drops for Chinese queries suggest embedding/retrieval challenges with mixed-language content.
- Evaluation scope: Benchmark tests used 60 expert-annotated questions; real-world queries may exhibit more diverse patterns and edge cases.
- Function calling reliability: Limited data on failure rates or robustness under ambiguous queries.

## Confidence
- **High confidence**: Retrieval-augmented generation improves factual accuracy over base LLM prompting (supported by benchmark results showing high relevancy and faithfulness scores).
- **Medium confidence**: Multi-stage routing between knowledge retrieval and data analysis reliably improves task-specific outputs (mechanism is clear but routing accuracy is not independently validated).
- **Medium confidence**: Structured function calling with JSON schema validation prevents silent failures (mechanism is described but failure rate statistics are not provided).

## Next Checks
1. **Cross-domain transfer test**: Evaluate Emission-GPT on emission inventories from non-Chinese contexts (e.g., EU or US datasets) to measure generalization limits.
2. **Routing accuracy audit**: Manually classify 200 real-world user queries and compare against the system's classification decisions to quantify routing error rates.
3. **Function calling robustness probe**: Design ambiguous or complex queries that require multiple API calls or conditional logic, then measure JSON validation success rates and error recovery behavior.