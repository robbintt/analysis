---
ver: rpa2
title: A New Benchmark for Online Learning with Budget-Balancing Constraints
arxiv_id: '2503.14796'
source_url: https://arxiv.org/abs/2503.14796
tags:
- regret
- time
- budget
- benchmark
- action
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a new benchmark for the adversarial Bandit\
  \ with Knapsack (BwK) problem that overcomes the \"spend-or-save\" impossibility\
  \ result. The key innovation is using Earth Mover's Distance (EMD) to measure similarity\
  \ between spending patterns, defining the benchmark as the best strategy within\
  \ EMD o(T\xB2) of any sub-pacing spending pattern."
---

# A New Benchmark for Online Learning with Budget-Balancing Constraints

## Quick Facts
- arXiv ID: 2503.14796
- Source URL: https://arxiv.org/abs/2503.14796
- Reference count: 28
- Key outcome: Introduces EMD-based benchmark for BwK that overcomes spend-or-save impossibility

## Executive Summary
This paper resolves a fundamental challenge in the Bandit with Knapsack (BwK) problem by introducing a new benchmark based on Earth Mover's Distance (EMD) for measuring spending pattern similarity. Traditional BwK benchmarks fail due to the "spend-or-save" impossibility, where any strategy must be compared against both spenders and savers simultaneously. The EMD framework enables meaningful sublinear regret guarantees by comparing strategies to nearby spending patterns within EMD o(T²) distance.

The authors propose LagrangianEMD, a primal-dual algorithm that achieves O(√(T log|F| + D)) regret against this benchmark, where F is the set of strategies and D is the permitted EMD distance. This framework naturally captures pacing constraints like changing distributions every w rounds, achieving regret Õ(T/√w + √(wT)). A matching lower bound proves this regret is optimal, establishing EMD as the right metric for characterizing viable spending patterns in budget-constrained online learning.

## Method Summary
The paper introduces a novel benchmark definition using Earth Mover's Distance to measure similarity between spending patterns in the Bandit with Knapsack problem. The benchmark is defined as the best strategy within EMD o(T²) of any sub-pacing spending pattern. The authors develop LagrangianEMD, a primal-dual algorithm that achieves sublinear regret O(√(T log|F| + D)) against this EMD-based benchmark. The algorithm uses a Lagrangian relaxation approach with carefully tuned penalty parameters to balance exploration and budget constraints. The framework captures natural pacing benchmarks where strategies can change distributions periodically, providing a general algorithmic solution for various budget-constrained online learning scenarios.

## Key Results
- Introduces EMD-based benchmark that overcomes spend-or-save impossibility in BwK
- Proposes LagrangianEMD algorithm achieving O(√(T log|F| + D)) regret against EMD-based benchmark
- Proves matching lower bound showing regret is optimal
- Captures natural pacing benchmarks like "pacing over windows" with Õ(T/√w + √(wT)) regret
- Establishes EMD as the right metric for characterizing viable spending patterns in BwK

## Why This Works (Mechanism)
The mechanism works by redefining the benchmark using Earth Mover's Distance, which measures the minimum "work" required to transform one spending pattern into another. This allows the algorithm to focus on competing against nearby strategies rather than all possible strategies simultaneously. The LagrangianEMD algorithm uses primal-dual updates to maintain a balance between exploration and budget constraints, with penalty parameters tuned based on the EMD distance D. By limiting comparison to strategies within o(T²) EMD distance, the framework avoids the fundamental impossibility of simultaneously competing with both spenders and savers.

## Foundational Learning

**Earth Mover's Distance (EMD)**: A metric measuring the minimum cost to transform one distribution into another, used here to measure similarity between spending patterns. Needed to define meaningful benchmarks in BwK. Quick check: Verify EMD satisfies triangle inequality and can be computed efficiently for the problem dimensions.

**Primal-Dual Algorithm Framework**: A method for solving constrained optimization problems by maintaining dual variables that penalize constraint violations. Needed to handle budget constraints while optimizing regret. Quick check: Confirm the Lagrangian relaxation approach maintains feasibility while achieving sublinear regret.

**Bandit with Knapsack (BwK)**: The problem setting where an agent must balance reward maximization with resource constraints. Needed as the target application domain. Quick check: Validate that the EMD framework applies to both stochastic and adversarial reward settings.

## Architecture Onboarding

Component Map: Input -> LagrangianEMD Algorithm -> Output Strategy -> Budget Check -> Regret Calculation

Critical Path: The algorithm maintains dual variables for budget constraints, updates action probabilities based on observed rewards, and adjusts penalties based on spending patterns. The critical path involves computing EMD distances between current and benchmark strategies, updating the Lagrangian multipliers, and selecting actions to minimize regret while respecting budget constraints.

Design Tradeoffs: The framework trades off between the permitted EMD distance D and achievable regret - larger D allows more flexible benchmarks but requires more exploration. The algorithm complexity increases with the dimension of the action space due to EMD computation requirements.

Failure Signatures: If EMD distance D approaches T², the algorithm fails to achieve sublinear regret. High-dimensional action spaces may make EMD computation intractable. Incorrect tuning of penalty parameters can lead to budget violations or poor regret performance.

First Experiments:
1. Implement LagrangianEMD on a simple 2-action BwK problem with known optimal pacing strategy
2. Test algorithm performance as EMD distance D varies from o(T²) to Ω(T²)
3. Compare EMD-based benchmarking against traditional benchmarks on synthetic data

## Open Questions the Paper Calls Out
None explicitly mentioned in the source material.

## Limitations
- EMD-based regret guarantees depend on D being subquadratic in T, limiting applicability
- Computational complexity of EMD in high-dimensional action spaces not addressed
- Theoretical optimality assumes specific problem structures that may not generalize
- Practical implementation challenges for real-world budget-constrained learning problems

## Confidence
- EMD as the right metric for characterizing viable spending patterns: Medium confidence (specific problem setup studied)
- Matching lower bound optimality: High confidence (strong mathematical arguments provided)
- General applicability to all BwK variants: Medium confidence (assumes specific constraint structures)

## Next Checks
1. Implement LagrangianEMD on a synthetic BwK problem with known optimal pacing strategy to empirically verify sublinear regret bounds
2. Test the algorithm's performance when EMD distance D approaches T² to identify the practical limits of the framework
3. Compare EMD-based benchmarking against alternative distance metrics (e.g., total variation, Wasserstein distance) on realistic budget-constrained learning problems