---
ver: rpa2
title: Speculative Sampling for Parametric Temporal Point Processes
arxiv_id: '2510.20031'
source_url: https://arxiv.org/abs/2510.20031
tags:
- sampling
- distribution
- rejection
- constant
- events
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces speculative sampling for temporal point processes
  (TPPs) to address the inefficiency of sequential sampling in autoregressive models.
  The method leverages rejection sampling to generate multiple future events in parallel
  without modifying or retraining existing models.
---

# Speculative Sampling for Parametric Temporal Point Processes

## Quick Facts
- arXiv ID: 2510.20031
- Source URL: https://arxiv.org/abs/2510.20031
- Reference count: 40
- Key outcome: Speculative sampling for TPPs achieves up to 8x faster runtime while maintaining sample quality through rejection sampling and parallel event generation

## Executive Summary
This paper introduces speculative sampling for temporal point processes (TPPs) to address the inefficiency of sequential sampling in autoregressive models. The method leverages rejection sampling to generate multiple future events in parallel without modifying or retraining existing models. It uses the model's predicted distribution as a proposal and accepts proposed samples until the first divergence from the target distribution. The authors provide theoretical guarantees and efficient algorithms for computing rejection constants for common distributions. Experiments on benchmark datasets show significant runtime improvements while maintaining sample quality, with average acceptance rates of 2-9 events per speculative step.

## Method Summary
The method reformulates TPPs as autoregressive density models where the encoder processes history into hidden states that predict conditional distributions for next events. Speculative sampling uses these predictions as proposals to generate multiple future events simultaneously through rejection sampling. Linear density bounds are constructed around inflection points to compute rejection constants efficiently. The algorithm samples l proposed events, computes all updated hidden states and target distributions in parallel, then accepts events sequentially until the first rejection. This preserves exact sampling while enabling parallel computation of the expensive encoder and decoder operations.

## Key Results
- Up to 8x runtime improvement on benchmark datasets while maintaining sample quality
- Average acceptance rates of 2-9 events per speculative step across datasets
- Rejection constant computation overhead remains under 100ms in worst case
- Method works effectively for non-stationary real-world data with up to 80 dimensions
- Practical utility demonstrated in financial limit order book applications

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using the current conditional distribution as a proposal for multiple future events works because sequentially dependent events in TPPs often maintain similar distributional characteristics over short horizons.
- Mechanism: The encoder processes history H into hidden state h, predicting p(τ, x|h). This single distribution serves as proposal for the next l events. Since each subsequent event's true distribution conditions on incrementally updated history, and historical influence evolves gradually, proposal and target distributions remain sufficiently close for efficient rejection sampling.
- Core assumption: Adjacent events in the sequence have conditionally similar distributions (non-divergent densities over short horizons).
- Evidence anchors:
  - [abstract]: "reuse this prediction as a proposal distribution to generate multiple future events simultaneously"
  - [Section 5.1, Figure 3]: Multivariate Hawkes experiments show acceptance rates remain viable even with 80 dimensions and varying sparsity/connectivity
  - [corpus]: TPP-SD paper (arxiv:2507.09252) identifies structural parallels between TPP thinning and speculative decoding, supporting this approach
- Break condition: Deterministic mark transitions (e.g., Taxi dataset where mark 1 always follows mark 2) cause acceptance rates to drop to ~1.0, nullifying parallelization benefits.

### Mechanism 2
- Claim: Piecewise linear upper/lower bounds on density functions provide computationally tractable computation of rejection constants M without requiring global optimization.
- Mechanism: Identify convex/concave regions by solving f''(x) = 0 for inflection points. Construct grid {x₀, x₁, ..., xₙ} containing all inflection points. In convex regions [xᵢ, xᵢ₊₁], upper bound is secant line through (xᵢ, f(xᵢ)) and (xᵢ₊₁, f(xᵢ₊₁)); lower bound is tangent at midpoint. Reverse for concave regions. Theorem 3.1 proves M̃ = maxᵢ g_T(xᵢ)/h_P(xᵢ) upper-bounds true M.
- Core assumption: The density is twice differentiable with finitely many inflection points in any bounded interval.
- Evidence anchors:
  - [Section 3.2]: "Theorem 3.1 shows us how to construct the grid made out of piecewise linear segments"
  - [Table 1]: Provides closed-form inflection points for exponential (∅), Gamma ((α-1±√(α-1))/β), log-normal, and Weibull
  - [corpus]: Edit-Based Flow Matching (arxiv:2510.06050) addresses similar sequential sampling limitations through non-autoregressive approaches, but via different mechanism
- Break condition: Distributions lacking closed-form inflection points or with infinite oscillations require Monte Carlo approximation, increasing computational cost.

### Mechanism 3
- Claim: Processing all speculative events in parallel while applying sequential accept/reject verification preserves exact sampling from the target distribution.
- Mechanism: Generate l proposals from p(τᵢ, xᵢ|hᵢ). Compute all l updated hidden states {hᵢ₊₁, ..., hᵢ₊ₗ} and target distributions {p*ᵢ₊₁, ..., p*ᵢ₊ₗ} in parallel. For each j, compute rejection constant Mᵢ₊ⱼ and acceptance probability Pᵢ₊ⱼ = p*/(M·p). Find first rejection index k, accept events i+1 through i+k-1, discard remainder. The "chain of validity" ensures each accepted event conditions on valid history.
- Core assumption: The rejection constant M correctly bounds the ratio between target density (conditioned on true evolved history) and proposal density (conditioned on static initial history) for all intermediate states.
- Evidence anchors:
  - [Section 3.4]: "This results in exact sampling from the model. This is easy to show by examining the chain of validity that governs sequential events in TPPs"
  - [Algorithm 1, lines 7-16]: Formalizes the parallel-then-accept-prefix procedure
  - [corpus]: No direct corpus evidence for this specific proof structure; related work focuses on model architecture rather than sampling verification
- Break condition: Approximate variants (top-k sampling accepting up to k-th rejection) sacrifice exactness—Lemma A.4 shows δ-truncated rejection introduces bounded total variation distance ≤ δ.

## Foundational Learning

- Concept: **Rejection Sampling**
  - Why needed here: This is the probabilistic substrate enabling the entire method. The core idea—sampling from proposal g(x) and accepting with probability f(x)/(M·g(x))—must be intuitively grasped to understand why linear bounds matter and why the acceptance threshold determines exactness.
  - Quick check question: Given proposal g(x) = Uniform(0,1) and target f(x) = 2x on [0,1], what is the minimum rejection constant M, and what fraction of samples are accepted?

- Concept: **Autoregressive TPP Formulation (Density-Based)**
  - Why needed here: TPPs are traditionally taught via intensity functions λ(t|H) with thinning algorithms. This paper reformulates as autoregressive density models p(τ, x|H), which directly enables speculative sampling. Without this shift, the connection to parallel decoding is opaque.
  - Quick check question: For a Hawkes process with intensity λ(t) = μ + Σᵢ α·exp(-(t-tᵢ)), write the equivalent conditional density p(τ|H) for inter-event times.

- Concept: **Convexity Analysis and Inflection Points**
  - Why needed here: The method's efficiency hinges on constructing linear bounds, which requires partitioning the domain into convex/concave regions. Computing f''(x) = 0 analytically for common distributions is prerequisite to implementing Algorithm 2.
  - Quick check question: For Gamma(α=3, β=1), compute the inflection points. Between x=1 and x=4, is the PDF convex or concave, and what linear bound would you construct?

## Architecture Onboarding

- Component map:
History Hᵢ → Encoder (GRU/Transformer/CNN) → Hidden State hᵢ
                                                    ↓
                           Decoder → Proposal Distribution p(τᵢ₊₁, xᵢ₊₁|hᵢ)
                                                    ↓
                          Sample l events → Proposals {(τᵢ₊ⱼ, xᵢ₊ⱼ)}ⱼ₌₁ˡ
                                                    ↓
                     Parallel computation for each j:
                       • hᵢ₊ⱼ = Enc(extended history with proposals 1..j-1)
                       • p*ᵢ₊ⱼ = Dec(hᵢ₊ⱼ)  [target distribution]
                       • Mᵢ₊ⱼ = RejectionConst(p, p*ᵢ₊ⱼ)  [via Algorithm 3]
                       • Accept flag = Bernoulli(p*/(M·p))
                                                    ↓
                     Find first rejection index k → Accept events i+1..i+k-1
                                                    ↓
                     Update h ← hᵢ₊ₖ₋₁, repeat until sequence complete

- Critical path:
  1. **Rejection constant computation (Algorithms 2-3)**: Must implement efficient grid construction with inflection points, derivative evaluation, and ratio maximization. This is the dominant overhead not present in standard sampling.
  2. **Parallel encoder forward passes**: Batched computation of l hidden states must be memory-efficient; for RNNs this requires careful state management.
  3. **Distribution-specific modules**: Each distribution family needs: (a) inflection point solver, (b) PDF and derivative evaluators, (c) bound construction logic respecting convexity.

- Design tradeoffs:
  - **Speculative step l**: Larger l increases parallelism but raises rejection probability and memory. Paper uses l=5; Table 8 shows average accepted steps range 1.0–3.77 across datasets.
  - **Exact vs. top-k approximate**: Top-k (accepting up to k-th rejection) improves throughput but introduces distributional drift. Table 2 shows top-3 maintains quality on most datasets except Taxi.
  - **Grid density vs. tightness**: Finer grids → tighter M bounds → higher acceptance, but more computation. Paper uses percentile-based domain restriction (e.g., 99th percentile coverage).

- Failure signatures:
  1. **Acceptance rate < 1.5**: Proposal-target mismatch. Check for deterministic transitions (Taxi pattern), abrupt regime shifts, or overly tight/loose bounds. Remedy: augment proposal, reduce l, or relax grid.
  2. **KL divergence > baseline autoreg variance**: Bounds may be incorrect (inflection points missed, convexity misidentified). Validate against Monte Carlo M estimation (Appendix D.4).
  3. **Memory overflow with large l**: Batched hidden states accumulate. Implement packed sequences or dynamic batch trimming as described in Section 3.4 "Batching."

- First 3 experiments:
  1. **Reproduce Table 8 on Amazon dataset**: Train GRU (256 hidden) + log-normal mixture (32 components). Implement exact speculative sampling with l=5. Verify: acceptance step ~2.89, MMD ~0.20, encoder runtime reduction ~54%.
  2. **Distribution ablation**: Compare exponential vs. Weibull vs. log-normal mixture decoders on Earthquake data. Measure rejection constants (Table 8: 1.53 for log-normal vs. 1.98 for exponential) and acceptance rates. Hypothesis: mixtures yield lower M through flexibility.
  3. **Scaling analysis**: On Taobao dataset, profile wall-clock time breakdown (encoder/decoder/sampling/rejection) as l varies from 1→15. Identify crossover point where rejection overhead exceeds parallelization gains.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can adaptive or learned proposal distributions improve speculative sampling efficiency beyond using the current encoder's prediction?
- Basis in paper: [explicit] The authors state in Section 6: "Future work might explore better proposal distributions to further boost efficiency."
- Why unresolved: The current method uses the encoder's single-step prediction as the proposal, which may diverge quickly from target distributions, limiting how many events can be accepted in parallel.
- What evidence would resolve it: Experiments comparing alternative proposal mechanisms (e.g., learned multi-step predictors, mixture proposals) showing higher average accepted step sizes while maintaining sampling quality metrics (KL divergence, MMD).

### Open Question 2
- Question: How can the rejection constant computation be optimized to reduce its overhead below the reported 100ms worst-case time?
- Basis in paper: [explicit] The authors note: "The current implementation prioritizes clarity and didactic value rather than computational efficiency, while other modules leverage optimized native operations" and "the total time spent on computing the constant can be up to 100ms."
- Why unresolved: While the algorithm has linear complexity in grid points, practical efficiency depends on implementation details not explored in this work.
- What evidence would resolve it: Benchmarking optimized implementations (e.g., GPU-accelerated, adaptive grid selection) showing reduced rejection constant computation time relative to encoder/decoder runtime.

### Open Question 3
- Question: Can the method be extended to handle datasets with highly structured mark transitions (like the Taxi dataset) without requiring domain-specific augmentations?
- Basis in paper: [explicit] The authors report: "The only exception is the Taxi dataset, which has specific structure where marks alternate between two values, i.e., mark 1 always follows mark 2 and vice versa, limiting the effectiveness of our approach...it can be fixed by augmenting the proposal distribution."
- Why unresolved: The deterministic mark transition structure causes high rejection rates for categorical distributions (mark constant of 4228–509 for Taxi vs. 1.2–2.5 for other datasets), but no general solution is proposed.
- What evidence would resolve it: A modified algorithm or proposal mechanism that achieves competitive acceptance rates on the Taxi dataset without manual domain-specific tuning, validated through the same quality metrics.

## Limitations

- The parallel acceptance mechanism requires careful implementation to maintain the chain of validity, particularly for RNN-based encoders where hidden state dependencies must be managed precisely.
- Performance degrades significantly on datasets with deterministic mark transitions, as seen with the Taxi dataset where acceptance rates drop to ~1.0.
- The method assumes twice differentiability with finitely many inflection points in bounded intervals, limiting applicability to certain distribution families with complex or infinite inflection points.

## Confidence

**High Confidence (8-10/10):** The core theoretical framework connecting speculative sampling to TPP autoregressive models is sound, supported by the structural analysis in Section 3 and the empirical validation across seven benchmark datasets. The proof of exact sampling preservation through parallel-then-accept-prefix is mathematically rigorous.

**Medium Confidence (5-7/10):** The practical implementation details, particularly grid construction parameters and training hyperparameters, are underspecified. While the general methodology is clear, reproducing the exact performance numbers requires additional experimentation with hyperparameters and grid resolution strategies.

**Low Confidence (1-4/10):** The method's behavior on real-world datasets with complex temporal dynamics beyond the tested benchmarks remains uncertain. The paper doesn't extensively explore edge cases such as highly non-stationary processes or datasets with long-range dependencies that could violate the short-horizon distributional similarity assumption.

## Next Checks

1. **Distribution-Specific Bound Analysis**: Systematically evaluate the computational overhead of rejection constant computation across all tested distributions (exponential, Weibull, log-normal mixtures) on synthetic data where ground truth bounds are known. Compare the proposed linear bound approach against Monte Carlo estimation in terms of both accuracy and runtime.

2. **Dataset Edge Case Exploration**: Apply speculative sampling to datasets with known challenging characteristics (e.g., highly bursty Hawkes processes with strong self-excitation, or Hawkes processes with time-varying background rates) to identify the limits of the distributional similarity assumption and measure performance degradation.

3. **Parallel Efficiency Scaling**: Profile the complete speculative sampling pipeline (including rejection constant computation, parallel encoding, and acceptance verification) on a GPU cluster to determine the optimal speculative step size l as a function of sequence length and model complexity, identifying the exact crossover point where rejection overhead outweighs parallelization benefits.