---
ver: rpa2
title: Comparing and Contrasting DLWP Backbones on Navier-Stokes and Atmospheric Dynamics
arxiv_id: '2407.14129'
source_url: https://arxiv.org/abs/2407.14129
tags:
- parameters
- days
- figure
- fourcastnet
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work provides a controlled empirical comparison of Deep Learning
  Weather Prediction (DLWP) architectures on synthetic Navier-Stokes and real-world
  atmospheric dynamics. The authors evaluate prominent backbones (U-Net, Transformer,
  Graph Neural Network, and Fourier Neural Operator) under identical training protocols
  and varying parameter counts.
---

# Comparing and Contrasting DLWP Backbones on Navier-Stokes and Atmospheric Dynamics

## Quick Facts
- arXiv ID: 2407.14129
- Source URL: https://arxiv.org/abs/2407.14129
- Authors: Matthias Karlbauer; Danielle C. Maddix; Abdul Fatir Ansari; Boran Han; Gaurav Gupta; Yuyang Wang; Andrew Stuart; Michael W. Mahoney
- Reference count: 40
- Key outcome: This work provides a controlled empirical comparison of Deep Learning Weather Prediction (DLWP) architectures on synthetic Navier-Stokes and real-world atmospheric dynamics.

## Executive Summary
This study presents a comprehensive empirical benchmark comparing nine prominent DLWP architectures (U-Net, Transformer, Graph Neural Network, Fourier Neural Operator, and variants) on both synthetic Navier-Stokes dynamics and real-world weather forecasting. The authors systematically vary parameter counts and training protocols to identify performance patterns and architectural strengths. They find that while FNO excels on periodic synthetic data, ConvLSTM and SwinTransformer perform best for short-to-mid-range weather forecasts, with spherical architectures demonstrating superior long-term stability.

## Method Summary
The authors evaluate nine DLWP architectures on synthetic Navier-Stokes data (Re=1×10³, 1k/10k samples) and real-world WeatherBench data (5.625° resolution, 8 prognostic variables). Models are scaled across parameter counts (50k-128M) with identical training protocols: Adam optimizer, cosine LR scheduling, 24-hour constrained optimization, and MSE loss. Performance is assessed via RMSE/ACC at 3/5/7 day lead times, long-range stability (365 days, 50 years), and power spectra analysis. Key architectural variations include LatLon vs. HEALPix spherical representations and equirectangular vs. periodic boundary conditions.

## Key Results
- Fourier Neural Operators achieve best performance on synthetic Navier-Stokes dynamics due to spectral inductive bias alignment
- ConvLSTM and SwinTransformer excel at short-to-mid-range forecasts (up to 14 days) on real weather data
- Spherical architectures (GraphCast, Spherical FNO) demonstrate superior stability and physical accuracy for long-range predictions up to 50 years
- All methods exhibit performance saturation with increased parameters, data, or compute, indicating neural scaling limitations in scientific ML

## Why This Works (Mechanism)

### Mechanism 1
- Claim: FNO variants achieve best performance on periodic synthetic Navier-Stokes dynamics due to spectral inductive bias alignment.
- Mechanism: FNO learns function-to-function mappings by operating in both physical space and the wavenumber/frequency domain. The periodic boundary conditions of the synthetic Navier-Stokes data align with FNO's Fourier-based spectral convolutions, enabling efficient capture of periodic dynamics.
- Core assumption: The periodic structure of the target dynamics is well-represented in the frequency domain, and boundary conditions match the architectural assumptions.
- Evidence anchors:
  - [abstract]: "On synthetic data, we observe favorable performance of FNO, followed by SwinTransformer and ConvLSTM"
  - [Section 3.1]: "We find TFNO to be most suitable for predicting periodic Navier-Stokes dynamics across different parameter counts"
  - [corpus]: Related work "Meta-Learning Fourier Neural Operators" discusses FNO applications in PDE-based weather prediction; corpus evidence is moderate with FMR~0.50
- Break condition: Performance degrades on non-periodic equirectangular weather data where FNO's boundary assumptions are violated (Section 4 notes FNO "does not satisfy boundary conditions" on such data).

### Mechanism 2
- Claim: Spherical data representations (HEALPix mesh, spherical harmonics) enable long-range forecast stability by reducing pole distortions.
- Mechanism: HEALPix mesh partitions the sphere into 12 equal-area faces, dissolving latitude-dependent distortions inherent in equirectangular grids. Spherical harmonics in SFNO provide physically-motivated inductive bias that respects Earth's geometry. This prevents models from learning spurious latitude-area corrections and maintains physical soundness over extended rollouts.
- Core assumption: Explicit spherical representation transfers to better generalization on global atmospheric dynamics and prevents error accumulation from geometric artifacts.
- Evidence anchors:
  - [abstract]: "spherical architectures (GraphCast and Spherical FNO) demonstrate superior stability and physical accuracy for long-range predictions up to 50 years"
  - [Section 3.2.2]: "Given that the HEALPix mesh used here only counts 8×8×12 = 768 pixels, the improvement over the LatLon mesh with 64×32 = 2048 pixels is even more significant"
  - [corpus]: "Principled Operator Learning in Ocean Dynamics" mentions long-term prediction stability challenges; corpus provides contextual support
- Break condition: Models without spherical representation (ConvLSTM on cylinder mesh) predict implausibly high pressures near poles within days and blow up on climate timescales (Figure 16).

### Mechanism 3
- Claim: ConvLSTM's recurrent structure provides competitive short-to-mid-range accuracy despite being the oldest architecture evaluated.
- Mechanism: ConvLSTM replaces scalar LSTM gate computations with convolution operations, enabling simultaneous spatial and temporal processing. The recurrent cell structure may better capture short-term temporal dependencies through explicit state propagation, particularly when trained with constrained optimization horizons.
- Core assumption: Recurrent temporal modeling provides advantages for limited forecast horizons where autoregressive error accumulation is still manageable.
- Evidence anchors:
  - [abstract]: "ConvLSTM and SwinTransformer excel at short-to-mid-ranged forecasts (up to 14 days)"
  - [Section 3.2.1]: "Intriguingly, the recurrent ConvLSTM with 16 M parameters yields accurate predictions on short lead times"
  - [corpus]: Weak direct corpus evidence on ConvLSTM specifically; "Improving regional weather forecasts" focuses on interpolation methods
- Break condition: Performance deteriorates at longer lead times (7+ days), and models become unstable beyond ~40 days on climate rollouts (Section 3.2.2, Figure 16).

## Foundational Learning

- **Concept: Inductive Biases in Scientific ML**
  - Why needed here: The paper's central finding is that matching architectural inductive biases (periodicity, spherical geometry) to data characteristics critically determines performance across forecast horizons.
  - Quick check question: Why does FNO excel on periodic Navier-Stokes but underperform on equirectangular weather data?

- **Concept: Autoregressive Rollout and Error Accumulation**
  - Why needed here: All evaluated models use autoregressive prediction; understanding how errors compound over rollout length is essential for interpreting stability results.
  - Quick check question: What distinguishes models that remain stable at 365-day rollouts from those that "blow up"?

- **Concept: Spherical Data Representations**
  - Why needed here: HEALPix mesh and spherical harmonics are presented as key innovations for long-range stability; practitioners must understand when this preprocessing overhead is justified.
  - Quick check question: Why does the 768-pixel HEALPix mesh outperform the 2048-pixel LatLon grid at longer lead times?

## Architecture Onboarding

- **Component map:**
  Input preprocessing -> Encoder (conv layers or patch embedding) -> Core backbone (ConvLSTM cells / U-Net encoder-decoder / SwinTransformer blocks / FNO spectral layers / GNN message passing) -> Output projection (linear layer to 8 prognostic variables) -> Training (24-hour constrained optimization, 4 autoregressive steps)

- **Critical path:**
  1. Select data representation based on forecast horizon (LatLon acceptable for ≤14 days; HEALPix/spherical recommended for climate scales)
  2. Choose backbone: ConvLSTM/SwinTransformer for short-mid range; SFNO/GraphCast for long-range stability
  3. Configure parameters via channel depth, layer count, and block structure (see Table 4 for mappings)
  4. Apply circular padding on periodic (longitude) dimension, zero-padding on latitude
  5. Train with 24-hour constrained loss, cosine LR scheduling, batch size 1-16

- **Design tradeoffs:**
  - Short-range accuracy vs. long-range stability: ConvLSTM/SwinTransformer win at 3-7 days; SFNO/GraphCast win at 365+ days
  - Parameter scaling: All models saturate; U-Net uniquely shows monotonic improvement; others plateau or degrade beyond ~16M-64M params
  - Compute efficiency: TFNO2D offers best accuracy/memory/runtime tradeoff on synthetic data; SwinTransformer is most expensive (Figure 1)
  - Patch size in FourCastNet: 1×2 patches outperform 1×1 by matching data aspect ratio (Figure 21)

- **Failure signatures:**
  - Pole artifacts: ConvLSTM-Cyl predicts implausibly high pressures near poles within days
  - Tropical pressure loss: ConvLSTM-HPX degrades after ~40 days
  - Blow-up: ConvLSTM, U-Net, FNO, TFNO produce severe artifacts at 365 days (Figure 15)
  - Power spectrum deviation: GraphCast shows noise at 7 days, indicating overfitting to high frequencies (Figure 20)
  - Patching artifacts: SwinTransformer/FourCastNet generate window/patch-structure patterns (Appendix A.2.4)
  - Training stall: Models >64M params fail to converge due to complex loss landscapes (Section 3.2.1)

- **First 3 experiments:**
  1. Parameter sweep (50k-128M) on synthetic Navier-Stokes (Re=1×10³) to establish baseline ranking and saturation points for each backbone.
  2. LatLon vs. HEALPix ablation on WeatherBench at 3/5/7-day lead times for ConvLSTM, U-Net, SwinTransformer to quantify spherical representation gains.
  3. 365-day rollout stability test with power spectrum analysis to identify physically stable architectures and verify kinetic energy conservation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can neural scaling behavior be achieved in Deep Learning Weather Prediction (DLWP) architectures given the observed performance saturation when scaling parameters, data, or compute?
- Basis in paper: [explicit] The authors state: "performance improvement of all of these models saturates... highlighting an important future direction for making model backbones... more broadly applicable."
- Why unresolved: The controlled experiments showed that increasing parameter counts beyond a certain point caused optimization issues or stalled error reduction across U-Net, Transformer, GNN, and FNO backbones.
- What evidence would resolve it: Identification of architectural modifications or optimization protocols that demonstrate monotonic performance improvement (scaling laws) beyond the 128M parameter limit tested.

### Open Question 2
- Question: Can recurrent probabilistic DLWP models be designed to provide reliable uncertainty estimation without sacrificing the stability required for long-range climate rollouts?
- Basis in paper: [explicit] The Discussion section identifies "The design of recurrent probabilistic DLWP models (that provide an uncertainty estimation as output) is a promising direction for future research."
- Why unresolved: Current deterministic models struggle with stability, and the trade-off between introducing probabilistic complexity (which often adds noise or variance) and maintaining the physical stability observed in models like GraphCast is unknown.
- What evidence would resolve it: A controlled benchmark comparing probabilistic variants (e.g., diffusion or ensemble models) against deterministic baselines on 50-year stability metrics and physical soundness (e.g., zonal wind patterns).

### Open Question 3
- Question: To what extent does the explicit incorporation of conservation laws improve the physical soundness and long-term stability of non-spherical backbones?
- Basis in paper: [explicit] The authors list "the incorporation of established physical relations such as conservation laws" as a distinct direction for future research.
- Why unresolved: Pure backbones (U-Net, ConvLSTM) lacking spherical inductive biases failed to replicate physical phenomena (e.g., Trade Winds) and diverged in power spectra over long lead times.
- What evidence would resolve it: Demonstrating that adding conservation law constraints to standard backbones allows them to match the physical accuracy and stability of spherical architectures like SFNO or GraphCast.

## Limitations
- Performance saturation indicates fundamental limitations in current architectures when scaling parameters, data, or compute
- Spherical representation preprocessing overhead may not justify deployment benefits in all operational contexts
- Study focuses on deterministic forecasts, leaving probabilistic skill and uncertainty quantification unaddressed

## Confidence
- High confidence: Comparative ranking of architectures for short-range weather prediction (3-14 days)
- Medium confidence: Long-range stability findings for 365-day and 50-year rollouts
- Low confidence: Transferability claims between synthetic Navier-Stokes and real atmospheric dynamics

## Next Checks
1. Test spherical representations on regional rather than global domains to assess scalability benefits
2. Compare against operational ensemble baselines like IFS or GFS to contextualize performance
3. Validate long-range stability on independent climate datasets beyond WeatherBench to confirm generalizability