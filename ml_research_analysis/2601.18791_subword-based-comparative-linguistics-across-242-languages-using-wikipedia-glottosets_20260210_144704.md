---
ver: rpa2
title: Subword-Based Comparative Linguistics across 242 Languages Using Wikipedia
  Glottosets
arxiv_id: '2601.18791'
source_url: https://arxiv.org/abs/2601.18791
tags:
- languages
- latin
- language
- linguistics
- across
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a subword-based comparative linguistics framework
  using BPE tokenization to analyze 242 Latin and Cyrillic-script languages simultaneously.
  By constructing "glottosets" from Wikipedia lexicons and comparing rank-based subword
  vectors, the method captures vocabulary overlap, lexical divergence, and language
  similarity at scale.
---

# Subword-Based Comparative Linguistics across 242 Languages Using Wikipedia Glottosets

## Quick Facts
- arXiv ID: 2601.18791
- Source URL: https://arxiv.org/abs/2601.18791
- Reference count: 10
- Primary result: BPE tokenization captures phylogenetic signal (Mantel r = 0.329, p < 0.001) and morphological boundaries (F1 = 0.34 vs 0.15 random baseline) across 242 languages

## Executive Summary
This study introduces a subword-based comparative linguistics framework using BPE tokenization to analyze 242 Latin and Cyrillic-script languages simultaneously. By constructing "glottosets" from Wikipedia lexicons and comparing rank-based subword vectors, the method captures vocabulary overlap, lexical divergence, and language similarity at scale. Evaluations show BPE segmentation aligns with morpheme boundaries 95% better than random baseline (F1 = 0.34 vs 0.15) across 15 languages. BPE vocabulary similarity correlates significantly with genetic language relatedness (Mantel r = 0.329, p < 0.001), with Romance languages forming the tightest cluster (mean distance 0.51). The approach successfully discriminates between 26,939 cross-linguistic homographs, with 48.7% receiving different segmentations across related languages.

## Method Summary
The framework constructs language-specific glottosets from Wikipedia dumps, training BPE tokenizers per language and combined-script corpora. Tokenizers operate with 4096-token vocabularies or "ultimate" mode (merge until no pair frequency > 1). Glottosets include Term Frequency and Document Frequency features. Rank-based token vectors are built across all languages, enabling pairwise Jaccard distance computation between vocabularies. This produces language similarity matrices analyzed against phylogenetic classifications (Glottolog) and morphological boundaries (MorphyNet). The method processes 242 Latin and Cyrillic-script languages simultaneously, enabling large-scale comparative analysis while reducing manual annotation requirements.

## Key Results
- BPE segmentation aligns with morpheme boundaries 95% better than random baseline (F1 = 0.34 vs 0.15) across 15 languages
- BPE vocabulary similarity correlates significantly with genetic language relatedness (Mantel r = 0.329, p < 0.001)
- Romance languages form the tightest BPE cluster (mean distance 0.51) among evaluated language families
- 48.7% of cross-linguistic homographs receive different segmentations across related languages

## Why This Works (Mechanism)

### Mechanism 1
- Claim: BPE tokenization incidentally captures morphologically meaningful boundaries through frequency-based compression.
- Mechanism: BPE iteratively merges the most frequent character pairs. Recurring morphemes (e.g., "un-", "-ing") appear across many words, triggering early merges that preserve these units as stable subword tokens. The algorithm has no linguistic knowledge—it discovers structure through statistical exposure.
- Core assumption: Frequent character sequences in a corpus correspond to linguistically meaningful units (morphemes or morpheme-like segments).
- Evidence anchors:
  - [abstract] "BPE segmentation aligns with morpheme boundaries 95% better than random baseline (F1 = 0.34 vs 0.15)"
  - [section 4.2] "BPE segmentation aligns with morpheme boundaries significantly better than random baseline across all 15 tested languages"
  - [section 5.1] "This emergent morphological sensitivity arises because BPE's frequency-based merge operations preferentially preserve character sequences that recur across many words"
  - [corpus] MoVoC paper (FMR 0.52) confirms BPE struggles with morphological boundaries in Geez script, supporting that this mechanism depends on corpus characteristics.
- Break condition: Low-resource languages with sparse data may lack sufficient frequency evidence for BPE to converge on morpheme-like units. Highly irregular morphology (fusional languages with unpredictable stem changes) may not produce consistent merge patterns.

### Mechanism 2
- Claim: BPE vocabulary overlap captures phylogenetic signal and contact-induced lexical similarity.
- Mechanism: Related languages share inherited vocabulary and parallel word-formation patterns. When trained on each language separately, BPE tokenizers develop similar vocabularies because shared words generate similar merge sequences. The Jaccard similarity between tokenizer vocabularies reflects this shared lexical heritage.
- Core assumption: Vocabulary overlap approximates genetic relatedness; the signal is not confounded by script-sharing alone.
- Evidence anchors:
  - [abstract] "BPE vocabulary similarity correlates significantly with genetic language relatedness (Mantel r = 0.329, p < 0.001)"
  - [section 4.3] "Within-family BPE distance: 0.67 (mean); Between-family BPE distance: 0.82 (mean)"
  - [section 5.2] "Romance languages form the tightest BPE cluster (mean distance 0.506)... Germanic languages show higher internal distance (0.713) despite comparable phylogenetic closeness"
  - [corpus] No direct corpus validation of phylogenetic correlation claims; rely on paper's internal evidence.
- Break condition: Languages with extensive borrowing (e.g., English with Romance loans) may cluster with donor language families rather than genetic relatives. Script-based filtering is required—mixed-script comparisons create artificial clustering.

### Mechanism 3
- Claim: Language-specific BPE tokenizers segment identical orthographic forms (homographs) differently based on corpus-specific frequency distributions.
- Mechanism: Even when two languages share a word spelling, each language's Wikipedia corpus contains different collocations, contexts, and frequency patterns. These differences propagate through BPE training, producing divergent merge hierarchies and thus different segmentations for the same surface form.
- Core assumption: Corpus composition differences between language Wikipedias are sufficient to create measurable segmentation divergence.
- Evidence anchors:
  - [abstract] "48.7% receiving different segmentations across related languages"
  - [section 4.4] "Russian-Ukrainian (both East Slavic): 31.2% different; Belarusian-Macedonian (East vs. South): 61.9% different"
  - [section 5.4] "The name 'димитров' receives five completely different segmentations across five Slavic languages"
  - [corpus] Teaching Old Tokenizers New Words (FMR 0.55) supports that tokenizer behavior is sensitive to training corpus composition.
- Break condition: High-frequency international vocabulary (e.g., borrowings like "катастрофа") may converge on identical segmentation across languages due to similar frequency profiles.

## Foundational Learning

- Concept: **Byte-Pair Encoding (BPE) tokenization**
  - Why needed here: The entire framework depends on understanding how BPE builds vocabularies through iterative merge operations based on frequency.
  - Quick check question: Given the character sequence "a b a b a b c" with pair frequencies ab:3, ba:2, bc:1, which pair merges first and what is the resulting sequence?

- Concept: **Mantel test for matrix correlation**
  - Why needed here: The phylogenetic signal evaluation (Section 4.3) uses this statistical test to compare distance matrices. Understanding what r=0.329 means requires knowing the test.
  - Quick check question: If two distance matrices have Mantel r=0.0, what does that imply about the relationship between the two sets of pairwise distances?

- Concept: **Jaccard similarity for vocabulary comparison**
  - Why needed here: Language distance is computed as 1 - Jaccard similarity between BPE vocabularies. This is the core metric for comparative analysis.
  - Quick check question: If Language A has 1000 BPE tokens and Language B has 1200 BPE tokens with 600 shared tokens, what is the Jaccard similarity?

## Architecture Onboarding

- Component map: Wikipedia dumps (ZIM) -> Paragraph extraction -> Script filtering -> Glottoset construction (TF/DF) -> BPE tokenizer training -> Rank-based token vectors -> Distance computation -> Comparative analysis

- Critical path:
  1. Download Wikipedia ZIM files for 320+ languages
  2. Extract and clean paragraph text (remove HTML, resolve redirects)
  3. Filter by script (Cyrillic: 37 languages, Latin: 205 languages)
  4. Build glottosets with Term Frequency and Document Frequency
  5. Train BPE tokenizers (per-language and combined-script)
  6. Construct rank vectors for each token across all languages
  7. Compute pairwise Jaccard distances between language vocabularies

- Design tradeoffs:
  - Lowercase normalization: Significantly improves tokenization quality but loses case information
  - Vocabulary size (4096 vs. "ultimate"): Fixed size enables comparison; ultimate tokenization is corpus-size dependent
  - Script-level vs. language-level filtering: Script filtering is tractable; language detection at 242 languages is unreliable
  - Wikipedia-only corpus: Controlled but biased (formal register, topic skew); Common Crawl would extend coverage with noise tradeoff

- Failure signatures:
  - High cross-script contamination in filtered output (check Table 1 columns for unexpected Cyrillic/Latin tokens)
  - Tokenizer training time >10 minutes suggests corpus size anomaly
  - Romance languages not clustering tightly may indicate data quality issues
  - Homograph segmentation identical across all languages suggests tokenizer not language-specific

- First 3 experiments:
  1. **Reproduce morphological boundary alignment (E2)**: Take MorphyNet data for 2-3 languages, train BPE tokenizers on Wikipedia glottosets, compute boundary F1 against gold morpheme boundaries. Target: F1 > 0.30.
  2. **Validate phylogenetic correlation on subset**: Select 10 Latin-script languages from different families, compute pairwise BPE vocabulary distances, correlate with Glottolog phylogenetic distances using Mantel test. Target: r > 0.25, p < 0.05.
  3. **Homograph segmentation divergence test**: Take shared vocabulary between Russian and Ukrainian (frequency ≥100), tokenize with each language's BPE, compute percentage receiving different segmentation. Target: 25-40% different.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do BPE-based language similarity patterns generalize beyond Wikipedia to web-scraped corpora like Common Crawl?
- Basis in paper: [explicit] "The application of this framework to Common Crawl would test whether the patterns we observe generalize beyond Wikipedia's controlled environment."
- Why unresolved: Wikipedia has controlled editorial quality and domain biases; web data introduces noise but broader lexical coverage, particularly for informal language.
- What evidence would resolve it: Replicating the phylogenetic correlation and homograph discrimination analyses on filtered Common Crawl data across the same 242 languages.

### Open Question 2
- Question: Does BPE vocabulary similarity capture morphological typology (analytic vs. synthetic, fusional vs. agglutinative) independent of lexical similarity?
- Basis in paper: [explicit] "Our BPE-based distance measures could be compared against typological databases such as WALS and Grambank."
- Why unresolved: The current study shows BPE captures phylogenetic signal and lexical similarity, but whether it reflects structural typological features remains untested.
- What evidence would resolve it: Correlation analysis between BPE distance metrics and grammatical feature vectors from WALS/Grambank, controlling for genetic relatedness.

### Open Question 3
- Question: How does BPE segmentation alignment with morpheme boundaries differ between derivational and inflectional morphology?
- Basis in paper: [inferred] "Our morphological boundary evaluation (E2) is limited to derivational morphology from MorphyNet... Inflectional morphology, including case endings and verb conjugations, was not evaluated."
- Why unresolved: Inflectional morphology operates differently (paradigmatic regularity vs. derivational productivity), and BPE may capture these patterns differently.
- What evidence would resolve it: Extending the F1 boundary agreement evaluation to inflectional morphology datasets across the same 15 languages.

## Limitations
- Script filtering methodology not specified—paper claims "no reliable tool" exists for script detection across 242 languages but doesn't detail the actual filtering algorithm used
- Morphological alignment evaluation methodology underspecified—F1 computation between BPE tokenization and gold morpheme boundaries lacks implementation details
- Phylogenetic correlation relies entirely on internal Wikipedia data without external corpus validation (Common Crawl or other sources)
- Homograph discrimination statistical significance not tested—48.7% figure lacks broader language family coverage and p-value computation

## Confidence

**High confidence**: BPE vocabulary overlap captures phylogenetic signal when comparing languages sharing the same script family (Romance, Slavic). The internal evidence (Table 5, Figure 2) shows consistent clustering patterns within language families.

**Medium confidence**: BPE segmentation captures morphological boundaries better than random baseline. The 95% improvement claim is based on F1 comparison, but the absolute F1 values (0.34 vs 0.15) indicate BPE still performs poorly on morphological segmentation compared to dedicated morphological analyzers.

**Low confidence**: Claims about cross-linguistic homograph discrimination being language-specific. The 48.7% figure lacks statistical testing and broader language family coverage. The mechanism assumes corpus composition differences are sufficient, but this needs validation across more diverse language pairs.

## Next Checks

1. **Morphological boundary alignment replication**: Implement the MorphyNet evaluation pipeline to compute BPE boundary F1 scores for 5-10 languages. Compare against random baseline using the same evaluation framework to verify the 95% improvement claim holds with faithful reproduction.

2. **Phylogenetic correlation with external corpus**: Replicate the Mantel test analysis using Common Crawl data instead of Wikipedia for a subset of 10-15 languages. Compute correlation between BPE distances and Glottolog classifications to test whether the phylogenetic signal persists across different corpora.

3. **Homograph discrimination statistical testing**: For Russian-Ukrainian pair, compute the statistical significance of the 31.2% different segmentation rate using permutation testing. Generate null distribution by randomly assigning segmentations to shared vocabulary and compare against observed rate.