---
ver: rpa2
title: 'Fine-Grained Chinese Hate Speech Understanding: Span-Level Resources, Coded
  Term Lexicon, and Enhanced Detection Frameworks'
arxiv_id: '2507.11292'
source_url: https://arxiv.org/abs/2507.11292
tags:
- hate
- chinese
- speech
- terms
- coded
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the gap in Chinese hate speech detection,
  particularly in span-level fine-grained analysis and interpretability. The authors
  introduce STATE TOXI CN, the first span-level Chinese hate speech dataset, containing
  8,029 posts and 9,533 quadruples annotating targets, arguments, groups, and hateful
  attributes.
---

# Fine-Grained Chinese Hate Speech Understanding: Span-Level Resources, Coded Term Lexicon, and Enhanced Detection Frameworks

## Quick Facts
- arXiv ID: 2507.11292
- Source URL: https://arxiv.org/abs/2507.11292
- Reference count: 40
- Primary result: Introduces the first span-level Chinese hate speech dataset with 8,029 posts and 9,533 quadruples, plus a lexicon of 830 coded hate terms, achieving F1 scores of 70.57 (COLD) and 60.04 (CDial-Bias) using a two-stage fine-tuning framework

## Executive Summary
This paper addresses the critical gap in Chinese hate speech detection by introducing span-level annotation and interpretability mechanisms. The authors present STATE TOXI CN, the first dataset to decompose hate speech into structured quadruples (Target-Argument-Hateful-Group), enabling fine-grained analysis beyond binary classification. They also create a lexicon of 830 coded hate terms, categorized by formation patterns, and propose a two-stage fine-tuning framework that integrates this lexicon into detection models. The approach significantly improves detection performance on two additional Chinese hate speech datasets, demonstrating the value of combining explicit knowledge injection with contextual learning.

## Method Summary
The approach combines span-level annotation with lexicon-integrated fine-tuning. First, they create STATE TOXI CN by annotating Chinese posts with quadruple structures (target, argument, hateful indicator, demographic group). Second, they compile a lexicon of 830 coded hate terms, categorized into phono-graphemic variations and hateful semantic terms. Third, they implement a two-stage fine-tuning framework: Stage 1 pre-trains models on the lexicon for 4 epochs (lr=5e-5), then Stage 2 fine-tunes on task-specific datasets using LoRA (lr=2e-5). The method uses hard and soft matching for span evaluation and reports macro-F1, recall, and explanation quality metrics.

## Key Results
- STATE TOXI CN dataset contains 8,029 posts with 9,533 quadruples at span level
- Two-stage framework achieves F1 of 70.57 on COLD and 60.04 on CDial-Bias
- Lexicon integration improves performance over single-stage training (68.68 → 70.57 F1 on COLD)
- DeepSeek-v3 achieves 81.00 soft-match on phono-graphemic terms vs 78.21 on semantic terms

## Why This Works (Mechanism)

### Mechanism 1: Span-Level Quadruple Decomposition
Decomposing hate speech into Target-Argument-Hateful-Group quadruples enables models to capture structural relationships rather than treating sentences as monolithic units. This disentangles multi-target scenarios and implicit hate that sentence-level labels conflate. The approach assumes hate speech operates through identifiable target-argument relationships. Evidence shows sentence-level labels "fail to teach models the underlying structure of hate speech." Break condition: Low Inter-Annotator Agreement on argument spans (κ=0.61) or inability to localize hateful intent to discrete spans.

### Mechanism 2: Two-Stage Lexicon-Integrated Fine-Tuning
Sequential training—first on coded hate lexicon, then on task-specific datasets—outperforms either approach alone by balancing explicit knowledge injection with contextual discrimination. Stage 1 builds feature representations for coded hate terms (achieving 87.83 recall on COLD), while Stage 2 contextualizes this knowledge, reducing false positives while retaining coverage. The approach assumes coded hate terms form learnable patterns transferable to broader contexts. Evidence shows Two-Stage achieved highest F1 on both COLD (70.57) and CDial-Bias (60.04). Break condition: Lexicon terms too domain-specific to transfer, or Stage 2 causes catastrophic forgetting of Stage 1 knowledge.

### Mechanism 3: Coded Term Taxonomy-Based Detection
Separating coded hate terms into phono-graphemic variations versus hateful semantic terms enables differentiated reasoning strategies. Phono-graphemic terms require linguistic decoding of sound/character manipulation, while semantic terms require cultural knowledge extraction. DeepSeek-v3 shows 81.00 soft-match on phono-graphemic vs 78.21 on semantic terms; explanation win rates drop from 76.94% (semantic) to 63.84% (phono-graphemic). The approach assumes coded hate terms follow systematic formation patterns. Evidence confirms explaining Phono-Graphemic Variation Terms is significantly more challenging. Break condition: Terms evolve faster than lexicon updates, or terms are entirely context-dependent.

## Foundational Learning

- **Concept**: Span Extraction vs. Sequence Classification
  - Why needed here: Traditional hate speech detection uses sentence-level classification. This paper requires token-level span extraction—identifying exact character sequences for targets and arguments.
  - Quick check question: For "河南人最勤奋了，扫大街最适合" (Henan people are hardworking, best suited for street sweeping), identify the target span, argument span, and explain why this is implicit hate.

- **Concept**: Coded Language and Linguistic Disguise
  - Why needed here: Chinese online hate speech extensively uses homophones, character combinations, and culturally-loaded words that appear benign under literal interpretation.
  - Quick check question: Why might "坦克" (tank) function as a hate term, and how does this differ from character-combination slurs like "魄"?

- **Concept**: Two-Stage Transfer Learning
  - Why needed here: The architectural contribution is sequential fine-tuning (lexicon → task data). Understanding why this outperforms single-stage training requires grasping knowledge transfer dynamics.
  - Quick check question: Why does "Only Lexicon" achieve high recall (87.83) but lower precision, and how does Stage 2 address this tradeoff?

## Architecture Onboarding

- **Component map**: Input → [Span Extraction] → Target + Argument spans → [Hatefulness Classifier] → Hateful/Non-hate → [Group Classifier] → Gender/Race/Region/LGBTQ/Others
- **Critical path**: 1) Data filtering: 5-500 characters, remove corrupted/meaningless samples; 2) Annotation: 2+ annotators per sample, expert arbitration, maintain shared lexicon document; 3) Stage 1: Fine-tune on lexicon (captures coded terms); 4) Stage 2: Fine-tune on task data with lower learning rate (contextualizes knowledge); 5) Evaluate: Hard-match (exact span) + soft-match (0.5 threshold overlap)
- **Design tradeoffs**: Hard vs. soft matching: Chinese lacks clear word boundaries; hard-match penalizes near-correct spans, soft-match inflates scores; Lexicon-only vs. two-stage: Lexicon maximizes recall but increases false positives; two-stage requires careful lr tuning (5e-5 → 2e-5); API vs. fine-tuned: APIs bring cultural knowledge but fail on span boundaries (3-12% hard-match); fine-tuned achieve ~50% soft-match but require task data
- **Failure signatures**: Low argument span agreement (κ=0.61): Model will struggle to learn consistent argument patterns; Implicit hate miss: Performs well on slurs but fails on sarcastic praise → learned surface patterns, not hate semantics; Stage 2 forgetting: Dramatic drop in coded term recall indicates learning rate too high
- **First 3 experiments**: 1) Baseline on STATE TOXICN test set (1,605 posts): Report hard/soft F1 at each level (Target → Quadruple). Target: ~25% hard, ~47% soft on quadruples; 2) Two-stage ablation on COLD/CDial-Bias: Compare Only LoRA vs. Only Lexicon vs. Two-Stage. Isolate lexicon contribution and contextual refinement value; 3) Coded term subset analysis: Test on 502 posts with coded terms. Performance drop vs. full set indicates weak disguise robustness; unexpected improvement suggests over-reliance on explicit cues

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Can the two-stage fine-tuning framework and coded hate lexicon be effectively adapted for multimodal hate speech detection in images and videos?
- **Basis in paper**: The Conclusion states that a "significant future direction lies in expanding these methods into the multimodal domain."
- **Why unresolved**: The current study focuses exclusively on textual data from platforms like Zhihu and Tieba, whereas real-world hate speech frequently involves complex visual-textual interactions.
- **What evidence would resolve it**: Successful application of the lexicon-integrated framework to a multimodal Chinese dataset, demonstrating improved detection over text-only baselines.

### Open Question 2
- **Question**: How can models balance broad background knowledge with task-specific precision during fine-tuning to mitigate capability loss?
- **Basis in paper**: The Conclusion suggests future research must "effectively balance the broad background knowledge of large language models with the task-specific precision gained from fine-tuning."
- **Why unresolved**: While fine-tuning improves specific detection metrics, it often degrades the model's general reasoning capabilities or broad semantic understanding (catastrophic forgetting).
- **What evidence would resolve it**: A training methodology that maintains performance on general NLP benchmarks while achieving state-of-the-art results on the STATE TOXICN dataset.

### Open Question 3
- **Question**: How can the detection framework adapt to the evolving nature of coded hate terms without requiring constant manual lexicon updates?
- **Basis in paper**: The authors call for "enhancing the adaptability and dynamism of our two-stage... framework through evolving lexicons and adaptive learning mechanisms."
- **Why unresolved**: Coded hate terms change rapidly to evade detection; a static lexicon inevitably becomes obsolete, limiting long-term model robustness.
- **What evidence would resolve it**: An automated pipeline or continual learning approach that identifies and incorporates new phono-graphemic variations in real-time.

## Limitations

- Data Representativeness: The 5-500 character filtering criterion excludes very short posts and longer discourse threads, potentially biasing toward mid-length statements
- Annotation Subjectivity: Argument span annotation shows moderate agreement (κ=0.61), suggesting inherent ambiguity in identifying what constitutes an "argument" in hate speech
- Model Generalizability: Framework's effectiveness on genuinely out-of-domain Chinese hate speech remains untested; reliance on specific model families limits conclusions

## Confidence

**High Confidence (8-10/10)**: The span-level annotation methodology and dataset construction are methodologically sound with clear documentation and IAA metrics.

**Medium Confidence (6-7/10)**: The two-stage fine-tuning framework's performance improvements are well-demonstrated on tested datasets, though hyperparameter choices may be dataset-dependent.

**Low Confidence (3-5/10)**: Claims about interpretability improvements are somewhat overstated as explanations remain surface-level rather than providing deep causal reasoning about hate speech dynamics.

## Next Checks

1. **Cross-Domain Generalization Test**: Evaluate the two-stage framework on a genuinely out-of-domain Chinese hate speech dataset (e.g., from different platform/region/time period than STATE TOXI CN, COLD, or CDial-Bias) to quantify domain transfer limitations.

2. **Lexicon Evolution Simulation**: Implement a time-series test where the lexicon is artificially aged by removing 10% of terms per "year" and measuring performance decline to quantify framework's sensitivity to lexicon staleness.

3. **Cultural Context Transfer**: Test the framework on hate speech datasets from other Chinese-speaking regions (e.g., Taiwan, Hong Kong, Singapore) to assess whether current lexicon and annotation schema capture pan-Chinese hate speech patterns or are specific to Mainland Chinese discourse norms.