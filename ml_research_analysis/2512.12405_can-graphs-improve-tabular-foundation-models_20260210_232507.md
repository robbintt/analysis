---
ver: rpa2
title: Can Graphs Improve Tabular Foundation Models?
arxiv_id: '2512.12405'
source_url: https://arxiv.org/abs/2512.12405
tags:
- tabular
- graph
- classification
- bolero
- pretrained
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces BOLERO, a method that adds lightweight graph
  priors to pretrained tabular transformers to capture inter-instance relationships.
  It builds on RoBERTa-Tab by attaching a static bipartite graph linking each row
  to feature/value anchors and a small GNN, while keeping the backbone frozen.
---

# Can Graphs Improve Tabular Foundation Models?

## Quick Facts
- arXiv ID: 2512.12405
- Source URL: https://arxiv.org/abs/2512.12405
- Reference count: 8
- Primary result: Graph augmentation yields consistent, statistically significant improvements across 144 tabular datasets, with macro-F1 gains up to 0.11 points and RMSE reductions up to 26.7%.

## Executive Summary
BOLERO introduces a method to augment frozen pretrained tabular transformers with lightweight graph priors, capturing inter-instance relationships via a bipartite graph linking rows to feature/value anchors and a small GNN. Evaluated on 80 classification and 64 regression datasets, BOLERO achieves the highest number of statistically significant wins across all baselines. The method demonstrates that graph augmentation yields consistent, meaningful gains over both classical and foundation-model baselines.

## Method Summary
BOLERO builds on RoBERTa-Tab by attaching a static bipartite graph linking each row to feature/value anchors and a small GNN, while keeping the backbone frozen. The bipartite graph includes instance-to-anchor edges (unit for categorical; normalized for continuous) and PPMI-weighted anchor-to-anchor edges capturing co-occurrence statistics. Only the graph head and anchor embeddings are trained, with the frozen backbone extracting initial instance embeddings that are refined through TransformerConv message passing.

## Key Results
- BOLERO achieves the highest number of statistically significant wins across all baselines on 144 tabular datasets.
- For classification, it improves macro-F1 by up to 0.11 points (p < 0.001).
- For regression, it reduces RMSE by up to 26.7% (p < 0.01).

## Why This Works (Mechanism)

### Mechanism 1: Inter-Instance Dependency Modeling via Bipartite Graph Structure
Explicitly encoding relationships among instances improves prediction when similar samples share related outcomes. A static bipartite graph connects each instance to feature/value anchors; a GNN propagates information across instances sharing similar attribute patterns, enriching their representations with relational context. This works when real-world tabular domains exhibit relational structure—e.g., customers with similar credit histories have correlated default probabilities.

### Mechanism 2: Frozen-Backbone Augmentation via Trainable Graph Head
Lightweight graph priors can improve pretrained transformers without backbone fine-tuning. Instance embeddings from frozen RoBERTa-Tab are refined through TransformerConv message passing over anchor nodes; only the graph head and anchor embeddings are trained. This isolates the effect of the graph prior and avoids overfitting on small datasets.

### Mechanism 3: PPMI-Weighted Anchor-to-Anchor Edges for Feature Co-occurrence
Encoding feature co-occurrence statistics via pointwise mutual information enables beneficial lateral information flow between anchors. Anchor-anchor edges weighted by PPMI (derived from training co-occurrence) connect related features, allowing the GNN to propagate context beyond direct instance connections.

## Foundational Learning

- **Concept: Transductive vs. Inductive Learning**
  - Why needed here: BOLERO uses a transductive evaluation setting—the graph is precomputed covering all instances (train/val/test), but test labels remain hidden. This differs from standard supervised learning and mirrors in-context learners like TabPFN.
  - Quick check question: Can you explain why test instances are included in the graph at inference time but their labels must remain hidden?

- **Concept: Graph Neural Networks / Message Passing**
  - Why needed here: BOLERO uses TransformerConv layers to refine instance and anchor embeddings through neighborhood aggregation.
  - Quick check question: How does a GNN layer update a node's representation differently from a standard feedforward layer?

- **Concept: Masked-Token Pretraining for Tabular Data**
  - Why needed here: RoBERTa-Tab is pretrained with masked-token prediction on tabular corpora. Understanding this helps interpret what frozen embeddings encode before graph augmentation.
  - Quick check question: What does predicting masked tokens teach a model about tabular data structure?

## Architecture Onboarding

- **Component map:** RoBERTa-Tab backbone (frozen) -> Bipartite graph constructor -> Graph head (TransformerConv) -> Linear prediction head
- **Critical path:** 1) Precompute anchor set from schema; 2) Build edges (instance-anchor with weights, anchor-anchor with PPMI); 3) Run frozen backbone to extract initial instance embeddings; 4) Apply TransformerConv layers to jointly refine instance and anchor representations; 5) Feed refined embeddings to task-specific linear head
- **Design tradeoffs:** Frozen vs. fine-tuned backbone (frozen isolates graph contribution and improves stability); Static vs. dynamic graph (static is precomputed once and stable); Transductive vs. inductive deployment (current setup is transductive)
- **Failure signatures:** Performance gains vanish on datasets with independent instances lacking relational structure; Overfitting on very small datasets; PPMI edges add noise when feature co-occurrence is random or task-irrelevant
- **First 3 experiments:** 1) Ablation: Remove anchor-anchor (PPMI) edges and measure performance change to isolate their contribution; 2) Backbone comparison: Run BOLERO with fine-tuned vs. frozen backbone on a subset of datasets to quantify tradeoffs; 3) Scalability probe: Measure inference latency and memory scaling as graph size (instances × anchors) increases

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do graph priors affect performance on larger, more heterogeneous datasets beyond the small-to-medium scale evaluated in this work?
- Basis in paper: Future Work states: "Our evaluation covers 144 datasets, mostly small to medium in scale... A natural next step is to study graph-augmented tabular FMs on larger, more heterogeneous datasets to understand how the benefits of graph priors evolve with scale."
- Why unresolved: Current benchmarks may not reflect scalability behavior or whether GNN overhead remains justified as dataset size grows.
- What evidence would resolve it: Evaluation on large-scale industrial tabular datasets (e.g., >100K instances, >100 features) with comparisons to baselines.

### Open Question 2
- Question: Can BOLERO's graph augmentation perform effectively in fully inductive deployment where new instances are added at inference time?
- Basis in paper: Future Work notes: "while we use a transductive setting, many applications require inductive deployment. BOLERO can attach new instances to the anchor graph at inference time; evaluating this remains future work."
- Why unresolved: The current study precomputes a static graph covering all splits; real-world systems often require predictions on entirely unseen instances without graph reconstruction.
- What evidence would resolve it: Benchmarks showing performance when test instances are incrementally added to a fixed anchor graph versus full recomputation.

### Open Question 3
- Question: Would jointly fine-tuning the transformer backbone and graph layers, or integrating graph structure into pretraining, yield additional gains over the frozen-backbone design?
- Basis in paper: Future Work proposes: "A further direction is to jointly fine-tune the transformer and graph layers or integrate graph structure into pretraining."
- Why unresolved: The frozen backbone isolates graph effects but may leave performance on the table if backbone representations could adapt to relational structure.
- What evidence would resolve it: Ablation studies comparing frozen vs. fine-tuned backbones and pretraining-with-graph vs. post-hoc graph augmentation.

## Limitations
- Performance gains depend on the presence of relational structure in the data, vanishing when instances are truly independent.
- The transductive graph construction may not generalize to fully inductive settings where test instances arrive without prior co-occurrence data.
- Reproducibility is limited by unspecified hyperparameters for the TransformerConv layers, anchor embedding dimensions, and the exact PPMI smoothing scheme.

## Confidence
- **High Confidence:** The claim that graph priors improve tabular foundation models when relational structure exists in the data, supported by extensive statistical significance across 144 datasets.
- **Medium Confidence:** The assertion that frozen-backbone augmentation isolates the effect of the graph prior, though this assumes no representational drift in the frozen embeddings.
- **Low Confidence:** The PPMI edge contribution to performance, as it lacks direct empirical ablation evidence in the paper.

## Next Checks
1. **Ablation Study:** Remove PPMI-weighted anchor-anchor edges and compare performance to quantify their specific contribution.
2. **Inductive Capability Test:** Adapt the graph construction to a fully inductive setting (new test instances without precomputed co-occurrence) and evaluate whether gains persist.
3. **Hyperparameter Sensitivity:** Systematically vary TransformerConv depth, hidden dimension, and learning rate to assess robustness and optimal configuration ranges.