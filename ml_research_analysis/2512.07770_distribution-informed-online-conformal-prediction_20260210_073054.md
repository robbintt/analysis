---
ver: rpa2
title: Distribution-informed Online Conformal Prediction
arxiv_id: '2512.07770'
source_url: https://arxiv.org/abs/2512.07770
tags:
- coverage
- prediction
- learning
- width
- online
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Conformal Optimistic Prediction (COP), a
  novel online conformal prediction algorithm designed to handle data distribution
  shifts in adversarial environments. Unlike traditional methods that rely solely
  on past errors, COP incorporates an estimated cumulative distribution function (CDF)
  of non-conformity scores into its update rule, enabling more efficient prediction
  sets when predictable patterns exist.
---

# Distribution-informed Online Conformal Prediction

## Quick Facts
- **arXiv ID:** 2512.07770
- **Source URL:** https://arxiv.org/abs/2512.07770
- **Reference count:** 40
- **Primary result:** COP algorithm achieves tighter prediction intervals than pure gradient methods while maintaining distribution-free coverage under arbitrary learning rates

## Executive Summary
This paper introduces Conformal Optimistic Prediction (COP), a novel online conformal prediction algorithm designed to handle data distribution shifts in adversarial environments. Unlike traditional methods that rely solely on past errors, COP incorporates an estimated cumulative distribution function (CDF) of non-conformity scores into its update rule, enabling more efficient prediction sets when predictable patterns exist. The method is connected to online optimistic gradient descent, with a distribution-informed hint, and establishes a joint regret–coverage bound. Theoretically, COP achieves distribution-free, finite-sample coverage under arbitrary learning rates and converges with i.i.d. scores. Empirically, COP outperforms state-of-the-art baselines on simulation datasets under changepoints, distribution drift, and real-world time series from finance, energy, and climate domains, maintaining target coverage while producing tighter prediction intervals.

## Method Summary
COP addresses online conformal prediction by extending optimistic online gradient descent with a distribution-informed refinement step. The algorithm maintains a threshold parameter updated via two stages: first a standard OGD step using recent prediction errors, then a refinement using an estimated CDF of non-conformity scores. This refinement leverages predictable patterns in the data distribution to produce tighter prediction sets while preserving coverage guarantees. The method handles adversarial environments through its distribution-free theoretical guarantees and demonstrates practical effectiveness across multiple real-world time series datasets.

## Key Results
- COP produces tighter prediction intervals than pure gradient-based methods while maintaining valid coverage
- Coverage guarantees hold distribution-free under arbitrary learning rates
- Under i.i.d. scores with properly decaying learning rates, COP thresholds converge to the true quantile
- COP outperforms state-of-the-art baselines on simulation and real-world datasets

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** COP produces tighter prediction intervals than pure gradient-based methods while maintaining valid coverage.
- **Mechanism:** The algorithm introduces a refinement step after the standard OGD update. After computing $\hat{q}_{t+1} = \hat{q}_t + \eta(\text{err}_t - \alpha)$, COP applies $q_{t+1} = \hat{q}_{t+1} - \lambda_{t+1}(\hat{F}_{t+1}(\hat{q}_{t+1}) - (1-\alpha))$, where $\hat{F}_{t+1}$ is an estimated CDF. When the estimated CDF correctly indicates the threshold is above/below the target quantile, this step moves $q_{t+1}$ closer to the optimal value.
- **Core assumption:** $\hat{F}_{t+1}(\hat{q}_{t+1}) - (1-\alpha)$ and the true $F_{t+1}(\hat{q}_{t+1}) - (1-\alpha)$ share the same sign (Proposition 1). The paper notes this is unverifiable in practice but shows the method tolerates bounded estimation error.
- **Evidence anchors:**
  - [abstract] "refinement step that uses linear approximation of expected quantile loss combined with the estimated CDF to produce tighter prediction sets"
  - [Section 3.1, Proposition 1] Shows expected quantile loss decreases under same-sign condition
  - [corpus] Weak direct evidence; neighbor papers focus on different efficiency approaches
- **Break condition:** If $\hat{F}$ systematically misestimates direction (wrong sign), the refinement moves thresholds away from optimal, widening intervals unnecessarily. The empirical robustness test (Appendix G) shows coverage remains valid but intervals widen under adversarial $\hat{F}$.

### Mechanism 2
- **Claim:** Coverage guarantees hold distribution-free under arbitrary learning rates.
- **Mechanism:** The coverage bound (Theorem 2) derives from telescoping the quantile threshold updates. Since both the OGD step and the optimistic refinement are bounded operations on $q_t$, the accumulated error is controlled: $|\frac{1}{T}\sum_{t=1}^T \text{err}_t - \alpha| \leq \frac{B + (2+6M)\Omega_T}{T\|\Delta_{1:T}\|_1}$. The refinement term $M_t$ remains bounded because $\lambda_{t+1}/\eta_t \leq 1$ and $M_t \in [\alpha-1, \alpha]$.
- **Core assumption:** Non-conformity scores $s_t \in [0, B]$ and optimistic terms $M_t \in [-M, M]$ are bounded.
- **Evidence anchors:**
  - [abstract] "distribution-free finite-sample coverage under arbitrary learning rates"
  - [Section 3.3, Theorem 2] Full proof in Appendix B.4
  - [corpus] Related papers (ACI, OGD variants) share similar coverage guarantees but without the refinement step
- **Break condition:** Unbounded scores or unbounded scale factors violate the proof structure. In practice, extreme outliers could push thresholds to numerical limits.

### Mechanism 3
- **Claim:** Under i.i.d. scores with properly decaying learning rates, COP thresholds converge to the true quantile.
- **Mechanism:** Theorem 3 establishes $q_t \to q^*$ asymptotically when learning rates satisfy Robbins-Monro conditions ($\sum \eta_t = \infty$, $\sum \eta_t^2 < \infty$). The proof uses martingale convergence and shows the bounded optimistic terms don't prevent convergence because they decay with $\eta_t$.
- **Core assumption:** Scores are i.i.d. with continuous distribution function $F$, and $q^*$ is uniquely identifiable (strictly increasing $F$ near quantile).
- **Evidence anchors:**
  - [Section 3.3, Theorem 3] Full proof in Appendix B.4
  - [abstract] "asymptotic consistency with i.i.d. scores"
  - [corpus] Similar convergence results appear in related online CP literature
- **Break condition:** Non-i.i.d. settings with persistent distribution shift prevent convergence to a fixed quantile; the algorithm instead tracks the shifting target reactively.

## Foundational Learning

- **Quantile loss gradient structure**
  - Why needed here: The core update rule exploits that $\nabla_q \mathbb{E}[\ell_{1-\alpha}(s_{t+1} - q)] = F_{t+1}(q) - (1-\alpha)$, connecting CDF estimation directly to gradient computation.
  - Quick check question: Given a threshold $q$ and true CDF $F$, what is the gradient of expected quantile loss at $q$?

- **Optimistic online gradient descent**
  - Why needed here: COP is reformulated as OOGD with "hint" $M_{t+1} = (\hat{F}_{t+1}(\hat{q}_{t+1}) - (1-\alpha)) \cdot \lambda_{t+1}/\eta$, enabling the joint regret-coverage analysis in Theorem 1.
  - Quick check question: In OOGD, what is the role of the optimistic term $M_{t+1}$ compared to standard OGD?

- **Empirical CDF estimation with sliding windows**
  - Why needed here: The default $\hat{F}$ uses a windowed ECDF; understanding its bias-variance tradeoff under distribution shift is critical for tuning.
  - Quick check question: If data shifts from distribution A to B at time $t_c$, how many steps before a window-$w$ ECDF reflects B entirely?

## Architecture Onboarding

- **Component map:**
  1. Base predictor $\hat{f}_t$ → produces point prediction $\hat{Y}_t$
  2. Non-conformity score computer → $s_t = |Y_t - \hat{f}_t(X_t)|$
  3. CDF estimator → maintains $\hat{F}_{t+1}$ from recent scores (default: windowed ECDF)
  4. Primary threshold updater → $\hat{q}_{t+1}$ via OGD step
  5. Refinement module → adjusts $\hat{q}_{t+1}$ using $\hat{F}_{t+1}$ to produce final $q_{t+1}$
  6. Prediction set constructor → $\hat{C}_t = [\hat{Y}_t - q_t, \hat{Y}_t + q_t]$

- **Critical path:** Score computation → CDF update → primary update → refinement → output. The refinement step (line 7 in Algorithm 1) is the novel contribution; everything else follows standard online CP.

- **Design tradeoffs:**
  - Window length $w$: Larger windows stabilize $\hat{F}$ but slow adaptation to shift
  - Scale factor $\lambda/\eta$: Higher values trust $\hat{F}$ more, risking instability if $\hat{F}$ is inaccurate
  - Learning rate $\eta$: Standard tradeoff; paper uses adaptive $\eta_t = \eta \cdot (\max_w s_t - \min_w s_t)$

- **Failure signatures:**
  - Coverage systematically below target: Learning rate too high or $\lambda$ too aggressive
  - Intervals infinitely wide (like ACI): Algorithm stuck in conservative regime; check if $\eta$-scaling produces near-zero effective step sizes
  - Intervals wider than baselines despite good $\hat{F}$: Likely same-sign condition violated; check if $\hat{F}$ systematically biased

- **First 3 experiments:**
  1. **Ablation on window size**: Run COP on the changepoint simulation with $w \in \{50, 100, 200\}$, plotting coverage recovery time after each changepoint vs. average interval width. Expect larger $w$ → slower recovery but more stable intervals.
  2. **Scale factor sensitivity**: Test $\lambda/\eta \in \{0.1, 0.5, 1.0\}$ on a dataset with known distribution shift (Amazon stock). Verify that $\lambda = 1.0$ produces tightest intervals when $\hat{F}$ is accurate but degrades gracefully (Table 7 shows coverage stays valid).
  3. **Adversarial CDF robustness**: Replicate Appendix G experiment—corrupt $\hat{F}$ with uniform noise at level $\gamma$. Confirm coverage remains at target while widths increase as $\gamma \to 0$, validating that the OGD backbone protects coverage regardless of refinement quality.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the threshold parameter $\epsilon_{t+1}$ in the modified update rule (Eq. 14) be adaptively estimated online to guarantee the "same-sign" condition required for improved efficiency?
- **Basis in paper:** [explicit] Appendix A.3 introduces a modified update to avoid the unverifiable "same-sign" assumption of Proposition 1, but notes that the threshold $\epsilon_{t+1}$ "can be viewed as a hyperparameter that depends on the temporal properties."
- **Why unresolved:** The threshold depends on the sup-norm error between the estimated and true CDF, $\sup_q |F_{t+1}(q) - \hat{F}_{t+1}(q)|$, which is generally unknown in distribution-free settings.
- **What evidence would resolve it:** A principled, online method for bounding CDF estimation error that preserves finite-sample coverage without relying on manual tuning of $\epsilon$.

### Open Question 2
- **Question:** Can the scale factor $\lambda_{t+1}$ (or optimistic term $M_{t+1}$) be optimized dynamically using an online meta-algorithm to minimize the joint regret-coverage bound?
- **Basis in paper:** [explicit] Section 3.2 states that properly choosing $M_t$ can simultaneously reduce bounds for both regret and coverage, noting that the optimal choice coincides with the true CDF deviation. The authors empirically choose a fixed $\lambda=0.5$ (Appendix H).
- **Why unresolved:** The optimal selection depends on the unpredictable accuracy of the estimated CDF relative to the ground truth, which varies over time.
- **What evidence would resolve it:** Theoretical analysis showing an adaptive $\lambda_t$ strategy that achieves sublinear regret while maintaining the coverage validity guarantees established for fixed learning rates.

### Open Question 3
- **Question:** Under what specific structural conditions on the non-conformity score sequence does minimizing the dynamic regret in the COP framework guarantee strictly optimal prediction set width?
- **Basis in paper:** [explicit] Section 3.2 states that "regret bounds and coverage bounds of online CP do not imply each other" in the general distribution-free setting, despite the joint bound provided in Theorem 1.
- **Why unresolved:** The joint bound links the two quantities, but it does not prove that the direction of improvement is always aligned (i.e., lower regret might not always result in tighter intervals) for arbitrary adversarial or non-stationary sequences.
- **What evidence would resolve it:** Identification of specific classes of non-stationary processes or constraint sets where the regret minimization objective is mathematically equivalent to minimizing the expected interval width.

## Limitations
- The refinement mechanism's robustness to systematically biased CDF estimates remains incompletely characterized, with intervals widening when the same-sign assumption is violated
- Performance under heavy-tailed or multimodal score distributions is not explored
- The analysis assumes bounded non-conformity scores, which may not hold in practice with extreme outliers

## Confidence
- **High Confidence:** Coverage guarantees hold distribution-free (Theorem 2), asymptotic convergence under i.i.d. scores (Theorem 3), and baseline performance claims on real-world datasets
- **Medium Confidence:** The refinement mechanism's practical benefits depend on accurate CDF estimation, which is sensitive to window size and score distribution properties not fully explored
- **Low Confidence:** Theoretical characterization of the refinement step's behavior under persistent adversarial CDF corruption beyond bounded error regimes

## Next Checks
1. **Sensitivity to window size and score distribution:** Run COP across multiple window sizes (w=50, 100, 200) on simulated datasets with heavy-tailed and multimodal score distributions, measuring coverage stability and interval efficiency
2. **Refinement step ablation under CDF bias:** Implement COP variants with corrupted CDF estimators (systematic bias levels γ ∈ {0.05, 0.1, 0.2}) and compare coverage/interval width trade-offs against pure OGD baseline
3. **Robustness to unbounded scores:** Test COP on datasets with injected outliers (extreme value injection at rates 1%, 5%, 10%) to verify coverage bounds remain valid and quantify interval width inflation