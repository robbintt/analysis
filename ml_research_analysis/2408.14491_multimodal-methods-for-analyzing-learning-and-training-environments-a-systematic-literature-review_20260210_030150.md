---
ver: rpa2
title: 'Multimodal Methods for Analyzing Learning and Training Environments: A Systematic
  Literature Review'
arxiv_id: '2408.14491'
source_url: https://arxiv.org/abs/2408.14491
tags:
- learning
- multimodal
- data
- analytics
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This systematic literature review examines how multimodal learning
  analytics (MMLA) has evolved, particularly following the rise of large language
  models (LLMs) and generative AI. The authors developed a unified framework and taxonomy
  to analyze empirical practices in learning and training environments, identifying
  five modality groups and three research archetypes: method development, outcome
  analysis, and behavior exploration.'
---

# Multimodal Methods for Analyzing Learning and Training Environments: A Systematic Literature Review

## Quick Facts
- **arXiv ID:** 2408.14491
- **Source URL:** https://arxiv.org/abs/2408.14491
- **Reference count:** 40
- **Key outcome:** Shift from vision/sensor-focused methods pre-LLM to text/artifact-centered approaches post-ChatGPT, with increased emphasis on collaboration and human-centered feedback

## Executive Summary
This systematic literature review examines the evolution of multimodal learning analytics (MMLA) before and after the rise of large language models. The authors developed a unified framework and taxonomy to analyze empirical practices, identifying five modality groups and three research archetypes. Their corpus analysis reveals a significant methodological shift toward text-based approaches and LLM integration, while highlighting persistent challenges in cross-modal data integration and system interpretability.

## Method Summary
The authors conducted systematic searches across 21 query phrases on Google Scholar, retrieving 2,965 initial papers. They applied automated citation graph pruning followed by manual screening using strict inclusion/exclusion criteria. The final corpus of 122 papers was coded for modality usage, research archetypes, fusion types, and analytical approaches. Post-LLM research (2022-2025) was further analyzed using LLM-based screening methods.

## Key Results
- Pre-LLM corpus: 78% model-based analysis, predominantly vision and sensor modalities
- Post-LLM corpus: 67% model-free analysis, with 82% using NLP and 65% incorporating LLMs
- Three research archetypes identified: method development, outcome analysis, and behavior exploration
- Persistent challenges include cross-modal data integration, small sample sizes, and interpretability of LLM-based systems

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Integrating multiple data modalities reveals learner behaviors that any single modality alone would miss.
- **Mechanism:** Different sensors capture orthogonal dimensions of the learner's state, creating a higher-dimensional observation space where latent patterns become discriminable.
- **Core assumption:** Target learner constructs are not fully observable in any single data stream but emerge from their temporal and semantic interaction.
- **Evidence anchors:** Abstract states integrating modalities enables richer insights; corpus shows norm of using 3-5 distinct modalities per study.
- **Break condition:** Poorly synchronized or semantically unrelated modalities add noise rather than signal.

### Mechanism 2
- **Claim:** The analytical approach should be chosen based on the structural properties of the learning domain and research objective.
- **Mechanism:** Structured domains lend themselves to model-based analysis, while unstructured domains require model-free approaches to discover emergent patterns.
- **Core assumption:** The chosen analytical framework aligns with the inherent "shape" of the learning task and data.
- **Evidence anchors:** Section 4.1.1 distinguishes structured vs unstructured domain analysis; corpus shows shift from 78% model-based to 67% model-free post-LLM.
- **Break condition:** Applying complex model-based methods to small, messy datasets from unstructured domains will likely overfit.

### Mechanism 3
- **Claim:** LLMs can act as a late-fusion, interpretive layer, transforming discrete multimodal features into human-readable feedback and explanations.
- **Mechanism:** LLM-based late fusion distills each modality into textual summaries, then fuses them within the LLM's prompt context to generate coherent narratives.
- **Core assumption:** Pedagogical value of natural-language explanations outweighs loss of fine-grained feature attribution.
- **Evidence anchors:** Section 4.3.1 describes LLMs as accepting multimodal input and internally extracting features; corpus shows sharp rise in text-based modalities and LLM use.
- **Break condition:** Quality of LLM output is highly sensitive to prompt engineering and faithfulness of initial textual summaries.

## Foundational Learning

- **Concept: Modality vs. Data Collection Medium**
  - **Why needed here:** Framework distinguishes that a single medium can yield multiple modalities, and a single modality can be derived from multiple media.
  - **Quick check question:** Can a single Kinect sensor provide data for both the "Pose" and "Gesture" modalities? (Answer: Yes)

- **Concept: The Observability Line & Fusion Types**
  - **Why needed here:** Separates directly measurable signals from inferred constructs, refining fusion taxonomy into Early, Mid, Late, and Hybrid.
  - **Quick check question:** If you first use a pre-trained model to classify "frustration" from facial video and then combine that label with log data to predict "giving up," what type of fusion are you using? (Answer: Late fusion)

- **Concept: The Three Research Archetypes**
  - **Why needed here:** Synthesizes practice into three archetypes: Method Development, Outcome Analysis, and Behavior Exploration.
  - **Quick check question:** Your team builds a new sensor glove to measure hand posture during surgical training and focuses on reporting its accuracy. Which archetype does this primarily align with? (Answer: Designing and Developing Methods)

## Architecture Onboarding

- **Component map:** Environment -> Data Collection Media -> Multimodal Data Processing -> Learning Analytics (Fusion + Analysis) -> Feedback
- **Critical path:** Data Synchronization & Alignment - reconciling different sampling rates, clock sources, and missing data windows
- **Design tradeoffs:**
  - Interpretability vs. Performance: LLM-based feedback offers fluent explanations but obscures feature importance
  - Model-Based vs. Model-Free: Structured tasks favor model-based; exploring complex behaviors favors model-free
  - Data Richness vs. Privacy/Scalability: High-fidelity sensors provide rich data but are invasive and hard to scale
- **Failure signatures:**
  - Cross-Modal Misalignment: Temporal lag or missing windows corrupts fusion
  - Feature Engineering Bottleneck: Inability to scale beyond small curated datasets
  - LLM Hallucination in Feedback: System provides confident but incorrect explanations
- **First 3 experiments:**
  1. Establish baseline with mid fusion using OpenFace for video features and openSMILE for audio, with Random Forest classifier
  2. Pilot LLM-based late fusion for feedback using textual summaries from logs and transcribed speech
  3. Conduct small-scale in-the-wild study focusing on practical challenges: synchronization accuracy, data loss, privacy concerns

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can researchers ensure learner engagement and stakeholder buy-in when deploying multimodal learning and training systems?
- **Basis in paper:** Authors explicitly pose question about students choosing not to engage with systems, noting even sophisticated systems risk failing without collective buy-in.
- **Why unresolved:** Literature focuses on technological advancement, often overlooking fundamental practical issue of whether learners will attend to and act on feedback.
- **What evidence would resolve it:** Empirical studies correlating stakeholder engagement levels with efficacy, or frameworks co-designing systems with educators and students.

### Open Question 2
- **Question:** What standards for data logging and synchronization are necessary to enable scalable, longitudinal multimodal analysis?
- **Basis in paper:** Review notes longitudinal research remains scarce due to data standardization and synchronization complexity challenges.
- **Why unresolved:** Current technical barriers make maintaining synchronized, heterogeneous data streams over extended periods resource-intensive and prone to error.
- **What evidence would resolve it:** Successful development and adoption of interoperable, open-source data standards extending xAPI.

### Open Question 3
- **Question:** How can the interpretability of LLM-based multimodal systems be improved to ensure pedagogical alignment and trust?
- **Basis in paper:** While LLMs lower barriers, authors note inner workings remain opaque, creating significant challenge for trust and pedagogical alignment.
- **Why unresolved:** Foundation models typically accept multimodal input and internally extract unobservable features, making it difficult for educators to audit reasoning.
- **What evidence would resolve it:** Research demonstrating techniques like chain-of-thought prompting or visual explanations that make LLM decision-making transparent and verifiable.

## Limitations
- Automated citation graph pruning may have excluded relevant papers if initial search failed to capture key connector nodes
- LLM-based screening introduces non-determinism due to undisclosed prompts and model updates
- Small sample sizes (average n=22) limit generalizability of findings

## Confidence
- **High Confidence:** Identified shift from sensor-focused to text/LLM-centric approaches post-2022 is well-supported by corpus statistics
- **Medium Confidence:** Proposed unified framework effectively captures existing practices, though some nuanced fusion types may require refinement
- **Medium Confidence:** Cross-modal integration challenges are consistently reported across studies, though solutions remain emergent

## Next Checks
1. Replicate citation graph pruning process with current search results to verify corpus stability
2. Test framework's applicability on a small, diverse set of recent MMLA studies not included in original corpus
3. Conduct focused literature search on post-2023 LLM-based fusion methods to identify emerging best practices