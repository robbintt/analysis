---
ver: rpa2
title: Incomplete Utterance Rewriting with Editing Operation Guidance and Utterance
  Augmentation
arxiv_id: '2503.16043'
source_url: https://arxiv.org/abs/2503.16043
tags:
- utterance
- utterances
- incomplete
- editing
- dialogue
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of incomplete utterance rewriting
  (IUR) in dialogues, where utterances often contain ellipsis or coreference, making
  them difficult for AI systems to understand. The authors propose a multi-task learning
  framework, EO-IUR, which introduces editing operation labels generated by a sequence
  labeling module to guide the generation model to focus on critical tokens in the
  dialogue context.
---

# Incomplete Utterance Rewriting with Editing Operation Guidance and Utterance Augmentation

## Quick Facts
- **arXiv ID:** 2503.16043
- **Source URL:** https://arxiv.org/abs/2503.16043
- **Reference count:** 12
- **Primary result:** Proposes EO-IUR, a multi-task learning framework for incomplete utterance rewriting that uses editing operation labels to guide generation and outperforms state-of-the-art baselines on BLEU, ROUGE, and exact match metrics.

## Executive Summary
This paper addresses the challenge of incomplete utterance rewriting (IUR) in multi-turn dialogues, where utterances often contain ellipsis and coreference making them difficult for AI systems to understand. The authors propose a multi-task learning framework called EO-IUR that introduces editing operation labels to guide the generation model's attention and uses a token-level heterogeneous graph to capture syntactic and coreference relationships. Additionally, they develop a two-dimensional utterance augmentation strategy to address limited training data. Experimental results on three datasets demonstrate that EO-IUR significantly outperforms previous state-of-the-art baselines, achieving improvements of 0.9-5.3% in exact match and substantial gains in BLEU and ROUGE scores.

## Method Summary
The EO-IUR framework combines three key innovations: (1) a sequence labeling module that predicts editing operation labels (NA, RP, NW, IN) for each token, which are then used to scale cross-attention scores during generation; (2) a token-level heterogeneous graph with four edge types (intra-utterance syntax, inter-utterance root-to-root, speaker-utterance, and pseudo-coreference) processed through a GCN to capture structural relationships; and (3) a two-dimensional utterance augmentation strategy that includes editing operation-based augmentation (converting between ellipsis and coreference) and LLM-based historical utterance augmentation. The model is trained using a multi-task learning approach with a 3-epoch warm-up period before joint optimization of both generation and labeling tasks.

## Key Results
- EO-IUR achieves significant improvements over state-of-the-art baselines on three datasets: REWRITE, RES200K, and TASK
- Exact Match scores improve by 0.9-5.3% compared to the best baseline models
- Human evaluation confirms EO-IUR outperforms baselines like HCT, BARTbase, and MIUR in handling coreference and ellipsis resolution
- The model shows particularly strong performance on complex utterances requiring multiple editing operations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Explicitly classifying editing operations guides the generation model to focus on critical tokens in the dialogue context, reducing redundancy.
- **Mechanism:** A sequence labeling module assigns token-level labels (NA, RP, NW, IN) to the input dialogue. The probability of a token belonging to the "RP" (replace), "NW" (new token for replacement), or "IN" (insert) classes is used as an influence factor (`λ`) to scale the cross-attention scores in the decoder. This `λ` is integrated into the attention calculation as `exp((τd + λi) × attn<j,i>)`, forcing the decoder to attend more to these "key" tokens during generation.
- **Core assumption:** The sequence labeling module can reliably identify critical tokens, and guiding attention towards these tokens is more effective than standard attention mechanisms alone.
- **Evidence anchors:**
  - [abstract] "...introduces the editing operation labels generated by a sequence labeling module to guide generation model to focus on critical tokens."
  - [section 3.4] "To use the labels of editing operations to facilitate the utterance generation... we modify the cross-attention layer... by multiplying the attention score by an influence factor..."
  - [corpus] This aligns with findings in a related paper, *Two-stage Incomplete Utterance Rewriting on Editing Operation*, which also leverages explicit editing operations for the IUR task.
- **Break condition:** The mechanism fails if the sequence labeling module produces inaccurate labels, which would misguide the decoder's attention. The authors note in Section 4.6 that "approximately a quarter of the generated labels were incorrect," which can negatively impact generation.

### Mechanism 2
- **Claim:** A token-level heterogeneous graph captures the syntactic and coreference relationships required to resolve ellipsis and coreference.
- **Mechanism:** The dialogue is represented as a graph `G = (V, E, R)` where nodes are tokens and speakers. Four types of edges connect these nodes: intra-utterance (syntax tree), inter-utterance (root-to-root), speaker-utterance, and pseudo-coreference (all pronouns to all pronouns/nouns). A Graph Convolutional Network (GCN) then aggregates features from neighboring nodes, allowing the model to learn structural relationships.
- **Core assumption:** Syntactic structure and explicit links between potential coreferent tokens are strong signals for resolving incomplete utterances, and a GCN can effectively aggregate this structural information.
- **Evidence anchors:**
  - [abstract] "...token-level heterogeneous graph to represent dialogues, enabling the model to learn syntactic structure corresponding to omitted tokens..."
  - [section 3.3] "To facilitate the learning of the syntactic structure... we introduce graph neural networks to further enhance dialogue information."
- **Break condition:** The mechanism is brittle if the dependency parsing tool (spacy) produces incorrect syntactic trees. The pseudo-coreference edge strategy is a heuristic that connects *all* pronouns to *all* nouns, which could introduce significant noise if not handled well by the GCN.

### Mechanism 3
- **Claim:** A two-dimensional utterance augmentation strategy mitigates data scarcity and improves model robustness.
- **Mechanism:** This strategy has two parts: 1) *Editing operation-based augmentation*: artificially creates training samples by bi-directionally converting between ellipsis (omission) and coreference (using a pronoun). 2) *LLM-based historical utterance augmentation*: uses an LLM (GPT-3.5) to rewrite historical context without altering semantics, providing diverse training contexts.
- **Core assumption:** Ellipsis and coreference can be mechanically swapped to create valid new examples, and LLMs can generate high-quality, semantically equivalent rewrites that improve generalization.
- **Evidence anchors:**
  - [abstract] "...two-dimensional utterance augmentation strategy: editing operation-based incomplete utterance augmentation and LLM-based historical utterance augmentation."
  - [section 3.5] "This approach enables bidirectional conversion between ellipsis and coreference."
- **Break condition:** The first augmentation could create unnatural dialogue. The second is dependent on the quality of the LLM; if the LLM alters semantics or hallucinates, it will poison the training data.

## Foundational Learning

- **Concept: Multi-task Learning**
  - **Why needed here:** The EO-IUR framework is explicitly a multi-task setup, jointly training on a primary generation task and an auxiliary sequence labeling task.
  - **Quick check question:** How does the loss function combine the two tasks, and why is a warm-up phase used before adding the sequence labeling task?

- **Concept: Graph Neural Networks (GCNs)**
  - **Why needed here:** The model uses a GCN to process a token-level heterogeneous graph. Understanding neighborhood aggregation is key to understanding how it learns structure.
  - **Quick check question:** In the EO-IUR GCN, what do the nodes and edges represent, and how does a node update its feature vector based on its neighbors?

- **Concept: Cross-Attention Mechanism**
  - **Why needed here:** The core innovation in the generation guidance is modifying cross-attention scores based on external labels.
  - **Quick check question:** What is the standard role of the cross-attention layer in an encoder-decoder model, and how is its computation altered in this paper?

## Architecture Onboarding

- **Component map:** Input Dialogue -> BART Encoder -> GCN -> Sequence Labeling MLP -> (Labels used to scale attention) -> BART Decoder -> Rewritten Utterance

- **Critical path:** The most critical data path is: `Input Dialogue -> BART Encoder -> GCN -> Sequence Labeling MLP -> (Labels used to scale attention) -> BART Decoder -> Rewritten Utterance`. The interaction between the labeling MLP's output and the decoder's attention is the core novelty.

- **Design tradeoffs:**
  - **Soft vs. One-hot Labels:** The paper argues for using soft labels (probabilities) as influence factors (`λ`) instead of one-hot labels. This prevents overfitting and allows the model to still attend to tokens labeled "NA" if their probability isn't zero, making it more robust to labeling errors.
  - **GCN Complexity vs. Performance:** Adding a GCN introduces "additional computational resources" (Limitations) compared to a standard BART baseline, a trade-off accepted for performance gains on syntactic tasks.

- **Failure signatures:**
  - **Degraded attention:** If the influence factor `λ` or temperature `τd` is poorly tuned, the cross-attention could become overly focused or collapse, leading to poor generation.
  - **Noisy graph inputs:** Failure of the dependency parser or a poorly connected pseudo-coreference edge could turn the GCN into a source of noise.

- **First 3 experiments:**
  1.  **Ablation of Guidance:** Run the model "w/o ED guidance" to isolate the performance gain from scaling cross-attention with editing operation labels.
  2.  **Ablation of Graph Structure:** Remove the heterogeneous graph ("w/o Heterogeneous graph") to quantify its contribution versus a standard BART encoder.
  3.  **Label Analysis:** Investigate the correlation between the sequence labeling module's accuracy (76.35 EM) and final generation quality (79.9 EM) to determine which label errors are most catastrophic for generation.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can Incomplete Utterance Rewriting models maintain high performance in complex scenarios involving multiple editing operations?
- **Basis in paper:** [explicit] Section 4.3 states, "How to address incomplete utterance rewriting in complex scenarios is also a research direction worthy of exploration in the future."
- **Why unresolved:** The analysis in Table 9 reveals that model performance drops significantly as the number of editing operations increases, with Exact Match scores falling to 0% for utterances requiring five operations.
- **What evidence would resolve it:** An architectural improvement or training strategy that sustains high Exact Match scores (>80%) on test subsets containing 4 or more editing operations per utterance.

### Open Question 2
- **Question:** How can Large Language Models (LLMs) be effectively employed to facilitate utterance generation while avoiding hallucination and under-rewriting?
- **Basis in paper:** [explicit] The Conclusion notes, "In the future, we intend to employ large language models (LLMs) to facilitate utterance generation."
- **Why unresolved:** Section 4.5 demonstrates that GPT-4 currently underperforms compared to the proposed EO-IUR, suffering from "under-rewriting" and hallucination issues despite its scale.
- **What evidence would resolve it:** A fine-tuned or prompted LLM approach that surpasses EO-IUR's Exact Match scores on the REWRITE dataset without generating context-contradicting tokens.

### Open Question 3
- **Question:** How can the integration of graph information and the combination of classification with generation be optimized for efficiency and robustness?
- **Basis in paper:** [explicit] The Limitations section states, "It is worthwhile to explore how to efficiently integrate graph information and better combine classification and generation in future research."
- **Why unresolved:** The current use of Graph Convolutional Networks incurs additional computational resources, and errors in the sequence labeling module (editing operation classification) can negatively impact the subsequent generation.
- **What evidence would resolve it:** A model variant that reduces computational overhead (e.g., inference time) and decouples generation from strict label dependency while maintaining the current BLEU and ROUGE scores.

## Limitations
- **Sequence Labeling Accuracy Impact:** The editing operation sequence labeling module achieves 76.35% exact match accuracy, and the relationship between labeling accuracy and final generation performance remains unclear.
- **Graph Construction Heuristics:** The token-level heterogeneous graph relies on spaCy for dependency parsing and uses a "pseudo-coreference" strategy that connects all pronouns to all nouns/pronouns, potentially introducing significant noise.
- **Augmentation Quality Control:** The two-dimensional augmentation strategy depends heavily on the quality of both the automatic editing operation conversions and the LLM (GPT-3.5) rewrites, with no systematic evaluation of whether augmented data introduces artifacts.

## Confidence
- **High Confidence:** The core architectural innovations (guided attention using editing operations, heterogeneous graph representation) are clearly specified and the experimental results demonstrate consistent improvements over baselines across multiple datasets and metrics.
- **Medium Confidence:** The ablation studies show the relative contributions of individual components, but the paper does not provide uncertainty estimates or variance across multiple runs. The human evaluation methodology lacks detail for full reproducibility assessment.
- **Low Confidence:** The data augmentation pipeline's effectiveness is primarily measured through end-to-end performance rather than isolating the quality of augmented examples or their impact on model robustness to specific error types.

## Next Checks
1. **Label Error Analysis:** Conduct a systematic correlation study between sequence labeling accuracy (broken down by label type: NA, RP, NW, IN) and final generation metrics. This would identify which labeling errors are most detrimental and validate whether the soft-label approach appropriately handles each error type.

2. **Graph Robustness Test:** Create controlled test cases with known parsing errors or systematically remove pseudo-coreference edges. Measure performance degradation to quantify how much the GCN contributes versus how much it amplifies noise from imperfect graph construction.

3. **Augmentation Quality Audit:** Sample and manually evaluate a subset of augmented examples from both strategies (editing operation conversions and LLM rewrites). Measure semantic preservation rates and identify any systematic biases or artifacts introduced during augmentation.