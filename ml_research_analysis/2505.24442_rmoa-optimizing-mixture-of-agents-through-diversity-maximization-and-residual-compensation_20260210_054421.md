---
ver: rpa2
title: 'RMoA: Optimizing Mixture-of-Agents through Diversity Maximization and Residual
  Compensation'
arxiv_id: '2505.24442'
source_url: https://arxiv.org/abs/2505.24442
tags:
- residual
- rmoa
- broadway
- arxiv
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Residual Mixture-of-Agents (RMoA), an enhanced
  multi-agent architecture that addresses high computational costs, information loss,
  and robustness issues in traditional Mixture-of-Agents systems. The method incorporates
  greedy diversity embedding selection to maximize information heterogeneity, residual
  extraction and aggregation agents to preserve cross-layer incremental information,
  and an adaptive termination mechanism to dynamically halt processing based on residual
  convergence.
---

# RMoA: Optimizing Mixture-of-Agents through Diversity Maximization and Residual Compensation

## Quick Facts
- arXiv ID: 2505.24442
- Source URL: https://arxiv.org/abs/2505.24442
- Authors: Zhentao Xie; Chengcheng Han; Jinxin Shi; Wenjun Cui; Xin Zhao; Xingjiao Wu; Jiabao Zhao
- Reference count: 40
- This paper introduces Residual Mixture-of-Agents (RMoA), an enhanced multi-agent architecture that addresses high computational costs, information loss, and robustness issues in traditional Mixture-of-Agents systems.

## Executive Summary
RMoA is an enhanced multi-agent architecture that optimizes Mixture-of-Agents (MoA) systems through three key innovations: greedy diversity embedding selection to filter redundant responses, residual extraction and aggregation to preserve cross-layer incremental information, and adaptive termination to dynamically halt processing based on residual convergence. The method achieves state-of-the-art performance across four benchmarks (AlpacaEval 2.0, MATH, CRUX, MMLU-redux) while significantly reducing computational overhead compared to baseline MoA systems. Experiments demonstrate that RMoA maintains performance gains in deeper iterations without degradation.

## Method Summary
RMoA modifies the standard MoA architecture by implementing a greedy diversity selection algorithm that filters K diverse responses from N proposer outputs using cosine similarity in embedding space. It introduces residual extraction agents that identify incremental information between consecutive layers through LLM-based comparison, and a final residual aggregation agent that synthesizes all residuals. An adaptive termination mechanism halts processing when residuals show no change across m consecutive layers. The framework maintains the multi-layer structure with 6 identical proposer agents per layer but optimizes information flow through diversity filtering and residual preservation, enabling deeper iteration without performance degradation.

## Key Results
- RMoA achieves state-of-the-art performance on AlpacaEval 2.0, MATH, CRUX, and MMLU-redux benchmarks
- Greedy diversity selection with K=3 balances performance and computational cost across all tasks
- Residual extraction and aggregation preserve cross-layer incremental information, preventing degradation in deeper iterations
- Adaptive termination reduces computational costs while preventing hallucination from over-iteration

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Greedy diversity embedding selection reduces computational overhead while preserving information heterogeneity by filtering redundant responses.
- Mechanism: Responses are converted to embeddings, pairwise cosine similarity is computed, and a greedy algorithm iteratively selects K responses maximizing minimum distance from already-selected items.
- Core assumption: Semantic diversity in embedding space correlates with information heterogeneity useful for downstream reasoning.
- Evidence anchors: K=3 achieves balance between performance and cost across benchmarks; performance degrades when K≥4 due to noise or exceeding context utility.

### Mechanism 2
- Claim: Residual extraction and aggregation preserve cross-layer incremental information that would otherwise be lost during deep multi-layer aggregation.
- Mechanism: A Residual Extraction Agent compares responses from consecutive layers using structured prompts to identify differences. Extracted residuals are concatenated with previous-layer responses as reference for the next layer. A final Residual Aggregation Agent synthesizes all residuals with reference responses.
- Core assumption: LLM-based comparison captures meaningful "residuals" that quantitative similarity metrics miss.
- Evidence anchors: Stronger models as extractors improve performance; LLM-based residual judgment outperforms similarity thresholds and variance metrics on MATH500.

### Mechanism 3
- Claim: Adaptive termination based on residual convergence halts unnecessary computation while preventing hallucination from over-iteration.
- Mechanism: If residuals show "no change" or "no update" across m consecutive layers, iteration stops. This prevents small models from continuing to modify already-correct answers.
- Core assumption: Residual absence signals convergence to a stable solution.
- Evidence anchors: Adaptive Termination improves CRUX by +1.38% and saves $17.01 in costs; reduces hallucination rate on MATH from ~5% to ~1-2% across rounds.

## Foundational Learning

- Concept: **ResNet-style residual learning**
  - Why needed here: RMoA's core innovation is adapting residual connections from computer vision to multi-agent text aggregation, requiring intuition about how incremental information flow prevents degradation in deep architectures.
  - Quick check question: Can you explain why adding the input to a transformation output helps preserve information through many layers?

- Concept: **Mixture-of-Agents (MoA) architecture**
  - Why needed here: RMoA is an optimization of MoA; understanding the baseline (layered proposer agents, final aggregator) is prerequisite to understanding what RMoA modifies.
  - Quick check question: In standard MoA, what happens to all N proposer outputs from layer l when they become input to layer l+1?

- Concept: **Embedding-based semantic similarity**
  - Why needed here: The greedy diversity selection relies on cosine similarity in embedding space to filter responses.
  - Quick check question: Why might two semantically similar responses have low value when combined, even if both are high-quality individually?

## Architecture Onboarding

- Component map:
Input Query -> Layer 1: N Proposer Agents -> [Greedy Diversity Selection] -> K diverse responses -> Layer 2+: Proposers receive (K previous responses + extracted residuals) -> [Residual Extraction Agent] -> ΔR (differences vs. previous layer) -> Final Layer: [Residual Aggregation Agent] -> Final Output

- Critical path: Proposer outputs → Greedy selection → Residual extraction → Next layer input. If greedy selection fails to capture diversity, or residual extraction misses key differences, downstream layers operate on degraded information.

- Design tradeoffs:
  - K (selection count): Higher K preserves more information but increases token cost and potential noise
  - Number of layers: RMoA maintains performance in deeper layers, while MoA degrades—but each layer adds cost
  - Model choice for extractors/aggregators: Stronger models improve results significantly

- Failure signatures:
  - High hallucination rate on simple tasks: Adaptive termination may not be triggering
  - Performance degrades with depth: Residual extraction may be failing
  - High cost without accuracy gain: K may be set too high, or greedy selection not filtering effectively

- First 3 experiments:
  1. Reproduce K=3 baseline on MATH500: Use Qwen2.5-7B-Instruct for all agents, 4 layers, K=3. Verify accuracy improvement over baseline.
  2. Ablate residual extraction: Run RMoA with K=3 but skip residual extraction. Measure performance drop and cost change.
  3. Test adaptive termination trigger rate: Run RMoA on a simple task and verify early termination occurs at layer 2.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the specific scaling laws governing the relationship between RMoA performance and iteration depth across different model families?
- Basis in paper: The Limitations section states future work aims to evaluate performance limits across different depths and analyze scaling laws.
- Why unresolved: Time and cost constraints prevented testing beyond 6 layers or determining if performance gains continue linearly or plateau.
- What evidence would resolve it: Empirical results from experiments running RMoA with significantly deeper architectures (10–20 layers) on diverse model architectures to plot performance scaling curves.

### Open Question 2
- Question: Can deterministic, non-LLM-based metrics be designed to accurately detect residual convergence without relying on expensive LLM-based judgments?
- Basis in paper: Appendix C.1 concludes that embedding representations fundamentally limit improvements through basic semantic similarity measures.
- Why unresolved: The paper demonstrates that quantitative metrics underperform compared to LLM judgments for adaptive termination, but does not propose a solution to bridge this efficiency-accuracy gap.
- What evidence would resolve it: A new quantitative metric or hybrid approach that correlates highly with LLM-based residual detection while maintaining low computational overhead.

### Open Question 3
- Question: How does the "curse of knowledge" in high-capability aggregation models affect the reliability of residual compensation in specialized domains?
- Basis in paper: Section 5.1 and Appendix C.5 observe that stronger aggregators improve performance by leveraging their own knowledge rather than strictly adhering to reference information.
- Why unresolved: While beneficial in tested math tasks, it is unclear if this behavior causes the system to ignore novel or correct insights from proposer agents in domains where the aggregator's internal knowledge is flawed or outdated.
- What evidence would resolve it: Experiments in low-resource or adversarial domains where the aggregator's internal knowledge conflicts with the diverse information provided by proposer agents.

## Limitations
- The greedy diversity selection mechanism relies on semantic embedding similarity as a proxy for information heterogeneity, but this correlation remains unproven beyond empirical results
- Adaptive termination's threshold parameter (m) and its optimal value across different task types are not systematically explored
- The residual extraction mechanism depends heavily on LLM-based comparison, which may fail when extractors lack sufficient capability

## Confidence
- **High confidence**: Computational efficiency improvements and cost reduction claims are well-supported by ablation studies and quantitative comparisons across all four benchmarks
- **Medium confidence**: Performance improvements on reasoning tasks (MATH, CRUX) are robust, though the exact contribution of each component is harder to isolate due to interaction effects
- **Low confidence**: Claims about preventing hallucination through adaptive termination are based on limited analysis; the mechanism assumes residuals reliably signal convergence, which may not hold for all task types

## Next Checks
1. **Systematic hyperparameter sweep**: Test RMoA across varying K values (2-5) and m values (1-3) on MATH to quantify sensitivity and establish optimal configurations for different task complexities
2. **Cross-task termination analysis**: Apply RMoA to tasks requiring legitimate multi-step refinement (e.g., complex reasoning chains) to test whether adaptive termination prematurely halts beneficial iterations
3. **Residual extraction robustness test**: Compare LLM-based residual extraction against simpler statistical methods (variance, mean similarity) across diverse model capacities to establish minimum effective model size and validate the approach's reliance on LLM reasoning for difference detection