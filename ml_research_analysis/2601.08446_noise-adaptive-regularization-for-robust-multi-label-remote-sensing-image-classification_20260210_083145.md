---
ver: rpa2
title: Noise-Adaptive Regularization for Robust Multi-Label Remote Sensing Image Classification
arxiv_id: '2601.08446'
source_url: https://arxiv.org/abs/2601.08446
tags:
- noise
- label
- learning
- subtractive
- additive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of multi-label remote sensing
  image classification under noisy annotations, which commonly arise from crowdsourced
  or thematic product labeling. The authors propose NAR, a noise-adaptive regularization
  method that explicitly distinguishes between additive and subtractive noise types
  within a semi-supervised learning framework.
---

# Noise-Adaptive Regularization for Robust Multi-Label Remote Sensing Image Classification

## Quick Facts
- **arXiv ID:** 2601.08446
- **Source URL:** https://arxiv.org/abs/2601.08446
- **Reference count:** 40
- **Primary result:** NAR consistently outperforms existing methods, particularly under subtractive and mixed noise conditions, with performance improvements of 2-6% in mAP macro across noise rates up to 60%.

## Executive Summary
This paper addresses the challenge of multi-label remote sensing image classification under noisy annotations, which commonly arise from crowdsourced or thematic product labeling. The authors propose NAR, a noise-adaptive regularization method that explicitly distinguishes between additive and subtractive noise types within a semi-supervised learning framework. NAR employs a three-state mechanism that dynamically retains high-confidence label entries, deactivates moderately uncertain entries, and corrects low-confidence entries through flipping. This selective attenuation of supervision is integrated with early-learning regularization (ELR) to stabilize training and mitigate overfitting to corrupted labels. Experiments across three datasets (UCMerdes, DeepGlobe-ML, AID-ML) and various noise scenarios show that NAR consistently outperforms existing methods, particularly under subtractive and mixed noise conditions.

## Method Summary
NAR introduces a confidence-based label handling mechanism that treats each label entry independently, classifying it into one of three states: retained (high confidence agreement between prediction and label), deactivated (moderate confidence, treated as unlabeled), or flipped (low confidence, corrected based on model prediction). This semi-supervised approach is combined with early-learning regularization that penalizes deviation from early predictions to stabilize training and suppress memorization of corrupted labels. The method distinguishes between additive (false positives) and subtractive (false negatives) noise types, using separate thresholds for each, and integrates these components into a unified loss function that combines confidence-weighted binary cross-entropy with multi-label early-learning regularization.

## Key Results
- NAR outperforms baselines by 2-6% in mAP macro under subtractive and mixed noise conditions
- Deactivation recovers approximately 80% of performance loss under subtractive noise; flipping provides marginal additional gains
- Performance is most pronounced under subtractive noise where present classes are unannotated
- Optimal threshold values shift with noise rate: tw0 decreases with higher noise rates under subtractive noise
- ELR integration provides stability but benefits vary by dataset (less effective on DeepGlobe-ML)

## Why This Works (Mechanism)

### Mechanism 1: Confidence-Based Three-State Label Handling
Treating noisy labels as partially reliable and dynamically adapting supervision per label entry improves robustness over uniform treatment. The mechanism converts noisy supervised learning into semi-supervised learning at the label-entry level by classifying each entry into retain, deactivate, or flip states based on model confidence. The core assumption is that model predictions during early training are more reliable than corrupted labels, and confidence values meaningfully distinguish clean from noisy entries. Break condition: if model confidence does not correlate with label correctness, the three-state mechanism may misclassify clean entries as noisy or vice versa.

### Mechanism 2: Early-Learning Regularization (ELR) Adaptation
Penalizing deviation from early learned patterns stabilizes training and suppresses memorization of corrupted labels. ELR exploits the early-learning phenomenon where neural networks fit clean labels before memorizing noise. The multi-label adaptation applies a label-entry-wise regularization term: log(1 - pi,c · yi,c), which reinforces early-learned reliable patterns while attenuating gradients from uncertain entries. Core assumption: neural networks exhibit an early-learning phase where clean labels are learned preferentially, transferring from single-label to multi-label settings. Break condition: if the warm-up phase is too short or the learning rate schedule prevents sufficient early learning of clean patterns, ELR may lock in incorrect pseudo-labels.

### Mechanism 3: Asymmetric Handling of Additive vs. Subtractive Noise
Subtractive noise (false negatives) causes stronger degradation than additive noise (false positives) and requires more aggressive correction strategies. The mechanism uses separate thresholds for additive and subtractive noise detection, prioritizing deactivation over flipping to avoid corrupting clean labels, with flipping reserved for high-confidence noise detection, particularly for subtractive noise. Core assumption: additive and subtractive noise affect model learning differently, requiring different optimal correction strategies. Break condition: if noise rate is extremely high (>60%) or noise is non-random, threshold tuning may fail to distinguish noise types.

## Foundational Learning

- **Concept: Early-Learning Phenomenon**
  - Why needed here: NAR relies on the assumption that neural networks learn clean patterns before memorizing noise. Understanding this behavior is essential for setting warm-up duration and ELR strength.
  - Quick check question: Can you explain why neural networks tend to learn simple/clean patterns before complex/noisy ones, and how learning rate schedules affect this?

- **Concept: Semi-Supervised Learning with Consistency Regularization**
  - Why needed here: NAR converts unreliable labels to unlabeled entries, requiring understanding of how to train on mixed labeled/unlabeled data.
  - Quick check question: How does treating uncertain label entries as unlabeled differ from simply dropping them, and what role does consistency regularization play?

- **Concept: Multi-Label Classification with Binary Relevance**
  - Why needed here: NAR operates at the label-entry level using BCE loss; understanding independent binary classification per class is prerequisite.
  - Quick check question: Why is binary cross-entropy applied independently per class in MLC, and how does this interact with label correlations?

## Architecture Onboarding

- **Component map:** Input image xi and noisy multi-label vector yi → ResNet-18 backbone → per-class probabilities pi,c → Confidence-Based Label Handler (four thresholds) → corrected labels ỹi,c and weights wi,c → Loss Computation (LBCE-CW + LELR-ML) → Output per-class predictions

- **Critical path:**
  1. Forward pass → obtain confidence scores pi,c
  2. For each label entry, compare pi,c against four thresholds to determine state (retain/deactivate/flip)
  3. Compute LBCE-CW using corrected labels and weights
  4. Compute LELR-ML using original labels and predictions
  5. Backpropagate combined loss

- **Design tradeoffs:**
  - Deactivation vs. Flipping: Deactivation is safer but discards information; flipping recovers more but risks corrupting clean labels. Paper recommends prioritizing deactivation (~80% of gains from deactivation alone).
  - Threshold selection: Higher thresholds → more aggressive deactivation/flipping but higher false positive rate; optimal values depend on noise rate and type.
  - ELR inclusion: ELR improves stability but adds hyperparameter λ; NAR without ELR sometimes outperforms on DeepGlobe-ML, suggesting dataset-dependent benefit.

- **Failure signatures:**
  - Over-aggressive flipping: Sudden performance drop, especially under subtractive noise, indicates thresholds too low → clean labels being corrupted.
  - Under-deactivation: Performance degrades linearly with noise rate without recovery → thresholds too high → noisy labels not being filtered.
  - ELR conflict: Oscillating training loss or failure to converge → ELR strength λ too high relative to BCE loss.

- **First 3 experiments:**
  1. Replicate oracle analysis (Section V-A): On UCMerced with 40% subtractive/additive noise, implement oracle-identified deactivation and flipping to verify that deactivation recovers ~80% of performance and flipping adds marginal gains.
  2. Threshold sensitivity sweep (Section V-C): Vary tw0 and tw1 on UCMerced under 20-60% mixed noise to identify optimal ranges; verify that optimal tw0 decreases with noise rate.
  3. Baselines comparison (Section V-B): Implement NAR (with/without ELR) against BCE, ELR, SAT, ASL on one dataset across all three noise types to validate reported improvements (2-6% under subtractive/mixed noise).

## Open Questions the Paper Calls Out
The paper explicitly states in its conclusion that future work includes investigating how the proposed semi-supervised, noise-adaptive mechanism can be combined with self-supervised learning, suggesting this integration could enhance robustness and generalization.

## Limitations
- Effectiveness depends critically on threshold calibration strategy and assumption that early-learning regularization generalizes from single-label to multi-label settings
- Optimal threshold values are dataset-dependent and not fully specified in the paper, creating reproducibility gaps
- ELR integration shows inconsistent benefits across datasets, suggesting the early-learning behavior assumption requires further validation in multi-label settings

## Confidence

- **High confidence:** NAR outperforms baselines on subtractive and mixed noise scenarios; performance improvements of 2-6% mAP macro are well-supported by experimental results across three datasets
- **Medium confidence:** The three-state mechanism is effective but optimal threshold ranges are dataset-dependent and not fully specified; reported sensitivity analysis provides guidance but exact operational values remain unclear
- **Medium confidence:** ELR integration provides stability but the benefit is inconsistent across datasets (notably less effective on DeepGlobe-ML), suggesting the assumption about early-learning behavior in multi-label settings requires further validation

## Next Checks

1. **Threshold calibration experiment:** Systematically sweep the four threshold parameters (t_w0_0, t_flip_0, t_w0_1, t_flip_1) on UCMerced under 20-60% mixed noise to identify stable operating ranges and verify the paper's sensitivity claims.

2. **Oracle ablation validation:** Implement the oracle-identified deactivation and flipping strategies from Section V-A on UCMerced with 40% subtractive/additive noise to confirm that deactivation recovers ~80% of performance and flipping provides marginal additional gains.

3. **Early-learning phenomenon validation:** Monitor the correlation between early-predicted and final-predicted labels during training on one dataset to verify that the early-learning assumption holds in the multi-label context, and test whether shorter/longer warm-up periods affect NAR's performance stability.