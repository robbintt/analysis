---
ver: rpa2
title: 'FlexFed: Mitigating Catastrophic Forgetting in Heterogeneous Federated Learning
  in Pervasive Computing Environments'
arxiv_id: '2505.13576'
source_url: https://arxiv.org/abs/2505.13576
tags:
- data
- client
- learning
- training
- forgetting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FlexFed addresses catastrophic forgetting in federated learning
  for human activity recognition (HAR) environments with intermittent client availability
  and limited storage. Unlike continuous learning, FlexFed cannot use replay mechanisms
  due to privacy constraints, so it prioritizes data retention for efficient memory
  use and dynamically adjusts offline training frequency based on distribution shifts,
  client capability and offline duration.
---

# FlexFed: Mitigating Catastrophic Forgetting in Heterogeneous Federated Learning in Pervasive Computing Environments

## Quick Facts
- arXiv ID: 2505.13576
- Source URL: https://arxiv.org/abs/2505.13576
- Reference count: 40
- Key outcome: FlexFed addresses catastrophic forgetting in federated learning for human activity recognition (HAR) environments with intermittent client availability and limited storage.

## Executive Summary
FlexFed introduces a federated learning framework specifically designed to mitigate catastrophic forgetting in human activity recognition (HAR) environments where clients have intermittent availability and limited storage capacity. The system dynamically adjusts offline training frequency based on distribution shifts, client capability, and offline duration, while prioritizing data retention for efficient memory use. Unlike traditional continuous learning approaches, FlexFed cannot use replay mechanisms due to privacy constraints, so it employs performance-adaptive memory allocation and a novel per-class forgetting metric to quantify and prevent knowledge loss.

The framework demonstrates significant improvements over baseline methods like FedAvg, MIFA, and REFL, achieving 10-15% better federated learning efficiency and faster, more stable convergence. This is particularly important for infrequent or under-represented activities in HAR datasets. The system uses a new metric that accounts for under-represented data, enabling more accurate evaluations of catastrophic forgetting in heterogeneous federated learning environments.

## Method Summary
FlexFed addresses catastrophic forgetting in federated learning for HAR by implementing three core mechanisms: opportunistic offline training, performance-adaptive memory allocation, and a per-class minimum forgetting metric. The system allows clients to continue local training during offline periods when they have power and idle time but lack server connectivity, accepting updates only if they improve local performance. Memory allocation for retaining old data is dynamically adjusted inversely to local model performance, prioritizing retention of under-represented or "forgotten" classes. The framework evaluates on WISDM dataset using FedScale benchmark with streaming data, dynamic distributions, imbalances, and varying availability.

## Key Results
- Achieves 10-15% better federated learning efficiency compared to FedAvg, MIFA, and REFL
- Demonstrates faster and more stable convergence, particularly for infrequent or under-represented data
- Successfully mitigates catastrophic forgetting in HAR environments with intermittent client availability and limited storage

## Why This Works (Mechanism)

### Mechanism 1: Opportunistic Offline Training
Decoupling local training from server connectivity allows clients to continue learning during intermittent availability, preventing the model from becoming stale. Clients detect "offline available" states and perform local updates, only accepting them if performance on local test data improves. This ensures only constructive updates are kept for future synchronization.

### Mechanism 2: Performance-Adaptive Memory Allocation
Dynamically assigning memory buffer size inversely to local model performance prioritizes retention of under-represented or "forgotten" classes. Clients measure local performance and allocate memory for infrequent classes proportionally to the inverse of their performance, ensuring rare activities are not purged from memory buffers.

### Mechanism 3: Per-Class Minimum Forgetting Metric
Standard averaging of accuracy hides catastrophic forgetting in minority classes. The metric calculates accuracy drops between current and historical max accuracy for each class, summing only negative changes. This prevents improvements in frequent classes from masking degradation in rare classes.

## Foundational Learning

- **Concept: Catastrophic Forgetting (CF) in Federated Systems**
  - Why needed: In HAR, user activities change (data distribution shift). Standard FL aggregates models based on currently available data; if an activity disappears from the buffer, the global model forgets how to recognize it.
  - Quick check: If a client trains exclusively on "Sitting" for 50 rounds, will the global model accuracy for "Jogging" (trained previously) drop?

- **Concept: Non-IID Data & Streaming Constraints**
  - Why needed: HAR data is inherently unbalanced and streaming. Devices have limited memory (FIFO buffers). Understanding that the "current data snapshot" is not the "total data distribution" is key to understanding why forgetting occurs.
  - Quick check: Why does a FIFO memory buffer exacerbate the forgetting of rare events in a streaming architecture?

- **Concept: Federated Averaging (FedAvg) Limitations**
  - Why needed: FlexFed modifies FedAvg. Standard FedAvg assumes stable participation and static data. Knowing how weights are aggregated helps understand why "stale" models need specific handling.
  - Quick check: What happens to the global model in FedAvg if only 10% of clients participate every round, and those clients have skewed data distributions?

## Architecture Onboarding

- **Component map:** Server (Advertising/Selection, Staleness-based Aggregation, Global Model) -> Client (Local Trainer, Memory Manager, Performance Monitor, Scheduler) -> Data (Streaming Sensor Input -> FIFO Buffer + Performance-Adaptive Buffer)

- **Critical path:** Client receives global model -> Client evaluates performance -> Memory Manager adjusts buffer allocation -> If Online: Train on current buffer + adaptive buffer, send update -> If Offline: Train locally, compare new vs stored model, keep winner

- **Design tradeoffs:**
  - Compute vs. Convergence: Offline training improves convergence speed but consumes client battery/compute during idle times
  - Storage vs. Privacy: FlexFed retains raw samples of rare classes locally, improving accuracy but requiring strict local isolation
  - Staleness vs. Participation: System accepts "stale" updates via scaling factor, trading update freshness for higher client participation

- **Failure signatures:**
  - Runaway Offline Drift: If local test data is unrepresentative, client may iterate offline indefinitely in wrong direction
  - Minority Class Collapse: If memory budget is too small, rare classes are purged and forgetting continues
  - High Variance: Incorrect staleness factor may destabilize global model with old updates

- **First 3 experiments:**
  1. Baseline Convergence: Run FlexFed vs. FedAvg on generated HAR dataset with 30% client availability; plot global accuracy over rounds
  2. Memory Ablation: Force fixed memory allocation vs. Performance-Adaptive allocation; measure forgetting metric for infrequent classes
  3. Offline Impact: Toggle Offline Training ON/OFF; measure time-to-convergence and total client compute cycles

## Open Questions the Paper Calls Out
None

## Limitations
- The framework assumes local test data is representative for offline training validation, which may not hold during severe concept drift
- Specific implementation details for identifying infrequent classes and staleness scaling factor are not fully specified
- Memory budget constraints may still be insufficient to capture meaningful variance of minority classes

## Confidence

| Claim | Confidence |
|-------|------------|
| General framework architecture and motivation | High |
| 10-15% efficiency improvement magnitude | Medium |
| Forgetting metric robustness in noisy environments | Low |

## Next Checks
1. Evaluate forgetting metric on synthetic data with random accuracy fluctuations to assess false positive rates
2. Systematically vary total memory budget and observe performance degradation for minority classes
3. Monitor direction and magnitude of updates from extended offline training sessions to detect model drift when local test data becomes unrepresentative