---
ver: rpa2
title: Disentanglement and Assessment of Shortcuts in Ophthalmological Retinal Imaging
  Exams
arxiv_id: '2507.09640'
source_url: https://arxiv.org/abs/2507.09640
tags:
- https
- fairness
- disentanglement
- auroc
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses fairness in AI-driven diabetic retinopathy
  (DR) detection using handheld fundus camera images. The authors evaluate three deep
  learning models (ConvNeXt V2, DINOv2, Swin V2) for DR prediction and sensitive attribute
  (SA) prediction (age, gender, education, insurance, obesity).
---

# Disentanglement and Assessment of Shortcuts in Ophthalmological Retinal Imaging Exams

## Quick Facts
- arXiv ID: 2507.09640
- Source URL: https://arxiv.org/abs/2507.09640
- Authors: Leonor Fernandes; Tiago Gonçalves; João Matos; Luis Filipe Nakayama; Jaime S. Cardoso
- Reference count: 32
- Primary result: Disentanglement improved DINOv2 performance and fairness (2% AUROC gain), but degraded ConvNeXt V2 and Swin V2 performance (7% and 3% AUROC drops, respectively).

## Executive Summary
This study evaluates fairness in AI-driven diabetic retinopathy (DR) detection using handheld fundus camera images. The authors test three deep learning models (ConvNeXt V2, DINOv2, Swin V2) for DR prediction and sensitive attribute prediction across age, gender, education, insurance, and obesity. All models achieved strong DR prediction performance (up to 94% AUROC), but exhibited fairness disparities across sensitive attribute subgroups, particularly in DINOv2 (up to 12% AUROC gap between insurance groups). A disentanglement autoencoder was developed to separate medical features from sensitive attribute features. The results show mixed outcomes: disentanglement improved DINOv2 performance and fairness, but degraded performance in the other two models, highlighting the complexity of balancing fairness and diagnostic accuracy in medical imaging AI.

## Method Summary
The study evaluates three vision transformer and convolutional architectures (ConvNeXt V2, DINOv2, Swin V2) on the mBRSET dataset (5,164 images) for diabetic retinopathy classification and sensitive attribute prediction. Models are trained with focal loss and evaluated using AUROC metrics, with fairness assessed via AUROC disparities between demographic subgroups. A disentanglement autoencoder is implemented to separate medical features (E_med) from sensitive attribute features (E_sensit) using a three-component loss function (classification, realism, and disentanglement losses). The disentangled representations are then used for DR classification to assess whether removing sensitive attribute shortcuts improves both fairness and performance.

## Key Results
- All three models achieved high DR prediction performance (up to 94% AUROC) and could predict sensitive attributes with reasonable accuracy (age: 91% AUROC, gender: 77% AUROC)
- ConvNeXt V2 showed the most balanced performance with AUROC differences typically within 1-3% across subgroups, while DINOv2 had the largest disparities (age: 10%, education: 7%, insurance: 12%)
- Disentanglement improved DINOv2 performance (2% AUROC gain) but degraded ConvNeXt V2 and Swin V2 performance (7% and 3% AUROC drops, respectively)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Disentanglement can improve fairness and performance when models rely on sensitive attribute shortcuts, but may degrade performance when sensitive attributes are weakly encoded.
- Mechanism: The architecture forces separation of medical features (E_med) and sensitive attribute features (E_sensit) into independent latent vectors through a combination of disentanglement loss (penalizing cross-contamination), classification loss (ensuring each vector captures its intended information), and realism loss (maintaining reconstruction quality).
- Core assumption: Medical features and sensitive attributes occupy separable regions in the latent space and can be independently manipulated without destroying diagnostic information.
- Evidence anchors:
  - [abstract]: "Disentanglement improved DINOv2 performance (2% AUROC gain), but led to performance drops in ConvNeXt V2 and Swin V2 (7% and 3%, respectively)."
  - [section 4.2]: "DINOv2 - Disentangling medical from sex information. Disentanglement improved AUROC from 88% to 90%... ConvNeXt V2 - Disentangling medical from age information. Disentanglement reduced AUROC from 94% to 87%."
  - [corpus]: Related work (arXiv:2509.11436) demonstrates that disentanglement of biological and technical factors can improve disease pattern discovery, supporting the theoretical basis for this approach.
- Break condition: When sensitive attributes are highly predictable (e.g., age at 90% AUROC), models likely depend on them for DR prediction; disentanglement removes useful signal, causing performance collapse. When SAs are weakly predicted (e.g., sex at 53% AUROC for DINOv2), removing them imposes minimal cost.

### Mechanism 2
- Claim: Shortcut learning manifests as high predictability of sensitive attributes from medical images, which correlates with fairness disparities across subgroups.
- Mechanism: Models trained on imbalanced datasets learn dataset-specific associations between demographic features and disease labels. These shortcuts reduce generalization and create performance gaps between subgroups with different demographic distributions.
- Core assumption: The correlation between sensitive attributes and disease labels in the training data reflects systematic bias rather than legitimate biological signal.
- Evidence anchors:
  - [abstract]: "All models achieved high DR prediction performance in diagnosing (up to 94% AUROC) and could reasonably predict age and gender/sex (91% and 77% AUROC, respectively)."
  - [section 2]: "In medical imaging, SAs are often encoded in the data, allowing models to rely on these features as predictive shortcuts, which can lead to both unfairness and decreased domain generalization."
  - [corpus]: Evidence is limited; related papers focus on disease detection performance rather than shortcut assessment methodology.
- Break condition: When the correlation between SA and disease reflects true biological risk (e.g., age genuinely affects DR prevalence), removing this information may harm clinical validity rather than improve fairness.

### Mechanism 3
- Claim: Vision transformers (DINOv2, Swin V2) exhibit higher fairness disparities than convolutional networks (ConvNeXt V2) on this task, potentially due to different feature extraction patterns.
- Mechanism: Architectural differences affect how models capture and rely on demographic features. DINOv2 showed 10% AUROC gap between age groups and 12% between insurance groups, while ConvNeXt V2 maintained gaps within 1-3%.
- Core assumption: Architectural inductive biases influence the degree to which models learn demographic shortcuts versus pathology-specific features.
- Evidence anchors:
  - [section 4.1, Table 2]: "ConvNeXt V2 had the most balanced performance, with AUROC differences typically within 1-3%, indicating strong generalizability and fairness. DINOv2 had the largest discrepancies, including age (10%), educational level (7%), and insurance (12%)."
  - [section 3.2]: Models were trained with identical hyperparameters (Adam optimizer, focal loss, early stopping), isolating architecture as the variable.
  - [corpus]: Related work (arXiv:2502.06289) compares DINOv2 to retina-specific foundation models but does not address fairness disparities across architectures.
- Break condition: Architectural effects may be confounded by pretraining data differences; DINOv2's self-supervised pretraining on natural images may encode different biases than ConvNeXt V2's supervised ImageNet pretraining.

## Foundational Learning

- Concept: Disentanglement Learning
  - Why needed here: The paper's primary intervention is a disentanglement autoencoder that separates medical and demographic features. Understanding this requires grasping how latent space factorization works and the trade-offs between independence constraints and information preservation.
  - Quick check question: Given a latent vector z = [z_med, z_sensit], if you perturb z_sensit while holding z_med constant, should the reconstructed image change its demographic appearance, its pathological features, both, or neither?

- Concept: Group Fairness Metrics (AUROC Gap, DCA)
  - Why needed here: The paper evaluates fairness using AUROC disparities and decision curve analysis across demographic subgroups. Interpreting results requires understanding when equalized odds vs. demographic parity is appropriate.
  - Quick check question: If a model achieves 95% AUROC on Group A and 85% AUROC on Group B, is this necessarily unfair? What additional information would you need to determine if the gap represents bias versus legitimate clinical difficulty?

- Concept: Shortcut Learning and Spurious Correlations
  - Why needed here: The paper frames sensitive attribute prediction as evidence of shortcut learning. This concept connects model behavior to dataset structure and explains why high training performance doesn't guarantee fairness or generalization.
  - Quick check question: A DR detection model trained on images from a single hospital system achieves 98% accuracy but performs poorly on external data. List three possible shortcuts the model might have learned that would explain this failure.

## Architecture Onboarding

- Component map:
  Encoder (E) -> DR Classifier (C_med) & SA Classifier (C_sensit) & Decoder (D)
  - Encoder produces two 256-dim vectors: E_med (medical features) and E_sensit (sensitive attributes)
  - DR Classifier uses E_med for binary DR classification
  - SA Classifier uses E_sensit for sensitive attribute prediction
  - Decoder reconstructs images from concatenated [E_med, E_sensit]

- Critical path:
  1. Input image (224×224×3) → Encoder → E_med (256-dim), E_sensit (256-dim)
  2. E_med → DR Classifier → DR prediction loss
  3. E_sensit → SA Classifier → SA prediction loss
  4. [E_med, E_sensit] → Decoder → Reconstructed image → Realism loss
  5. Perturbation loop: Add noise to one vector, re-encode reconstructed image, measure contamination in other vector → Disentanglement loss
  6. Backpropagate weighted sum: L_total = L_classifier + λ_r × L_realism + λ_d × L_disent (λ_r=1, λ_d=5)

- Design tradeoffs:
  - **Higher λ_d** → Stronger disentanglement but risk of destroying fine-grained diagnostic features (paper shows 7% AUROC drop for ConvNeXt V2)
  - **Latent dimension (256)** → Larger dims preserve more information but make independence harder to enforce
  - **SA selection** → Disentangling highly predictable SAs (age: 90% AUROC) harms performance more than weakly predictable ones (sex: 53% AUROC for DINOv2)
  - **Architecture choice** → ConvNeXt V2 has better baseline fairness; DINOv2 benefits more from disentanglement

- Failure signatures:
  - **Performance collapse after disentanglement** (>5% AUROC drop): Model was relying on SA features for diagnosis; consider whether SA contains legitimate biological signal
  - **Increased fairness gaps after disentanglement**: Confounding between SA and medical features not captured by simple independence loss (paper notes "latent dependencies may persist")
  - **Reconstruction artifacts**: Realism loss weight too low or encoder bottleneck too tight
  - **SA classifier stuck at random accuracy**: E_sensit not capturing target attribute; check if SA is actually predictable from images

- First 3 experiments:
  1. **Baseline SA predictability audit**: Train simple classifiers to predict each sensitive attribute from images before implementing disentanglement. If AUROC < 60%, disentanglement will likely have minimal effect or harm performance. Use this to prioritize which SAs to target.
  2. **Ablation on λ_d values**: Test λ_d ∈ {1, 3, 5, 10} on a holdout validation set. Plot DR AUROC vs. fairness gap (max AUROC disparity across subgroups). The paper used λ_d=5 but optimal value likely depends on SA predictability.
  3. **Per-subgroup reconstruction quality**: After training, compute SSIM/PSNR separately for each SA subgroup. If reconstruction quality varies significantly across groups, the decoder may be reintroducing bias through unequal feature preservation.

## Open Questions the Paper Calls Out
None

## Limitations
- The disentanglement approach assumes sensitive attributes are spurious correlations rather than legitimate biological signals, which may not hold for clinically relevant features like age that genuinely affect disease prevalence.
- The study lacks external validation on datasets with different demographic distributions, limiting conclusions about whether fairness improvements generalize beyond the training population.
- The optimal disentanglement strength (λ_d) appears to depend on sensitive attribute predictability, but the paper uses a fixed value (λ_d=5) without systematic hyperparameter optimization.

## Confidence
- **High Confidence**: The experimental methodology for measuring subgroup fairness gaps is sound and reproducible. The observed baseline fairness disparities across architectures (DINOv2 showing 12% AUROC gaps) are well-documented.
- **Medium Confidence**: The disentanglement architecture and training procedure appear technically correct, but the optimal hyperparameters (particularly λ_d) and whether the approach generalizes beyond this specific dataset remain uncertain.
- **Low Confidence**: Claims about the mechanism by which disentanglement improves fairness (e.g., removing "shortcuts") assume that high SA predictability necessarily indicates problematic shortcut learning rather than legitimate clinical associations.

## Next Checks
1. **Biological signal validation**: Conduct a clinician review of whether the sensitive attributes removed by disentanglement have legitimate biological relationships to DR outcomes, distinguishing true confounders from spurious correlations.
2. **Cross-dataset fairness assessment**: Evaluate model performance on an independent retinal imaging dataset with different demographic distributions to test whether fairness improvements generalize beyond the training population.
3. **Latent space interpretability**: Perform probing experiments on the disentangled latent vectors (E_med, E_sensit) to verify that medical features actually encode pathological information while sensitive attributes encode only demographic features, checking for residual cross-contamination.