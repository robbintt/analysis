---
ver: rpa2
title: 'Reasoning Over the Glyphs: Evaluation of LLM''s Decipherment of Rare Scripts'
arxiv_id: '2501.17785'
source_url: https://arxiv.org/abs/2501.17785
tags:
- token
- linguistic
- tokens
- puzzles
- unicode
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The study explores the ability of large language and vision models\
  \ to decipher rare scripts that are not encoded in Unicode, such as Avoiuli, Mandombe,\
  \ and Ditema tsa Dinoko. To address this challenge, the authors develop a tokenization\
  \ method that segments glyph images into visual tokens and two approaches\u2014\
  Picture Method for LVLMs and Description Method for LLMs\u2014to enable model understanding\
  \ of these tokens."
---

# Reasoning Over the Glyphs: Evaluation of LLM's Decipherment of Rare Scripts

## Quick Facts
- arXiv ID: 2501.17785
- Source URL: https://arxiv.org/abs/2501.17785
- Authors: Yu-Fei Shih; Zheng-Lin Lin; Shu-Kai Hsieh
- Reference count: 6
- Primary result: Current LLMs and LVLMs struggle with decipherment of rare scripts not in Unicode, with performance heavily dependent on pre-trained knowledge and the quality of visual description generation.

## Executive Summary
This study evaluates the ability of large language and vision models to decipher rare scripts that are not encoded in Unicode, such as Avoiuli, Mandombe, and Ditema tsa Dinoko. The authors develop a tokenization method that segments glyph images into visual tokens and two approaches—Picture Method for LVLMs and Description Method for LLMs—to enable model understanding of these tokens. Experiments with GPT-4o, Gemini, and Claude 3.5 Sonnet show that while models can make some inferences from descriptions, they struggle with complex glyph structures and often produce incorrect geometric interpretations from images. Performance improves with Unicode encoding for common languages like Malayalam, where models leverage pre-trained knowledge, but remains poor for low-resource languages like Meroitic regardless of encoding.

## Method Summary
The authors use linguistic Olympiad puzzles from UKLO and NACLO as decipherment tasks, focusing on five scripts: three non-Unicode (Avoiuli, Mandombe, Ditema tsa Dinoko) and two Unicode-encodable (Malayalam, Meroitic). They implement a rule-based tokenization algorithm that segments glyph sequences by identifying vertical white line gaps, with exceptions for horizontal extensions. For evaluation, they employ two methods: Picture Method (providing labeled glyph images for LVLMs) and Description Method (generating ≤35-word visual descriptions per token for LLMs). The study compares model performance across these input formats and with native Unicode encoding to isolate reasoning from pre-trained knowledge effects.

## Key Results
- Models show significant struggles with complex glyph structures and often produce incorrect geometric interpretations from images
- Performance substantially improves for common languages like Malayalam when using Unicode encoding due to pre-trained knowledge
- The quality of LVLM-generated token descriptions is a critical bottleneck, with high error rates in direction identification and detail provision
- Low-resource languages like Meroitic remain challenging regardless of encoding method

## Why This Works (Mechanism)
The study works by creating a controlled evaluation framework that isolates reasoning from pre-trained knowledge through novel tokenization methods and input formatting strategies. By using linguistic Olympiad puzzles as structured decipherment tasks and comparing performance across different encoding approaches (placeholder tokens vs. Unicode), the authors can measure the extent to which models rely on learned patterns versus genuine pattern recognition. The Picture and Description methods serve as bridges between visual glyph information and model reasoning capabilities, revealing specific failure modes in how current AI systems process visual language tokens.

## Foundational Learning

**Concept: Visual Tokenization of Glyphs**
- Why needed here: To handle scripts not in Unicode, a fundamental unit (the glyph) must be isolated and represented. The paper introduces a rule-based method (vertical white line separation) to segment script images into individual tokens, which are then assigned placeholders (e.g., `<token_i>`). This is the foundational step for both the Picture and Description methods.
- Quick check question: Given a line of text in an unknown script, can you define the boundary condition for separating two adjacent glyphs?

**Concept: Linguistic Olympiad Problems as Decipherment Proxies**
- Why needed here: The paper uses puzzles from competitions like UKLO and NACLO. These problems are structured, self-contained decipherment tasks that test pattern recognition and rule application. Understanding this paradigm is key to grasping the evaluation context—the models are not doing open-ended decipherment but solving constrained logical puzzles.
- Quick check question: What is the core difference between deciphering a script from scratch and solving a "Rosetta Stone"-style linguistic puzzle?

**Concept: Pre-trained Knowledge vs. Pure Reasoning**
- Why needed here: A central finding is the confounding effect of pre-trained knowledge. The study explicitly isolates reasoning by using a novel tokenization method (placeholders) for common languages. Distinguishing between a model recalling a known grammar and a model inferring a new one is critical for interpreting the results.
- Quick check question: If a model correctly solves a puzzle in a language it was trained on, what alternative explanation exists besides "it reasoned through the problem"?

## Architecture Onboarding

**Component Map:** Linguistic Olympiad puzzles → Tokenization Module (glyph segmentation → `<token_i>` placeholders) → Method Adapters (Picture Method for LVLMs / Description Method for LLMs) → Subject Models (GPT-4o, Gemini, Claude 3.5 Sonnet) → Evaluation (qualitative reasoning analysis + quantitative answer checking)

**Critical Path:** The most critical and fragile part of the architecture is the Description Method's generation of token descriptions (Evidence: Section 5.1). The entire pipeline for text-only models depends on the accuracy of these descriptions. Errors in this stage—such as lack of detail, wrong details, or direction confusion—propagate directly, making the reasoning task impossible.

**Design Tradeoffs:**
- Rule-based vs. Learned Tokenization: The authors chose a simple, interpretable rule for segmentation. This is transparent but may not generalize to all scripts (e.g., cursive or highly complex layouts). A learned segmenter could be more robust but would add another layer of potential error.
- Picture vs. Description Method: The Picture Method leverages the LVLM's native visual capabilities but was shown to often hinder reasoning due to incorrect geometric interpretations. The Description Method relies on accurate proxy descriptions, which models struggled to generate. The tradeoff is between direct but potentially misleading visual grounding and indirect but fragile textual grounding.

**Failure Signatures:**
- Incorrect Geometric Interpretation (Picture Method): The model hallucinates meaning from visual shapes (e.g., interpreting a glyph as a number) rather than analyzing its structural components (Evidence: Section 5.2, Figure 2)
- Direction Confusion (Description Method): Descriptions incorrectly identify top/bottom/left/right components of a glyph (Evidence: Section 5.1)
- Reliance on Pre-trained Knowledge: When Unicode is used for common languages, the model may succeed but without a clear reasoning chain, making it unclear if it solved the puzzle or recalled the answer

**First 3 Experiments:**
1. Ablation on Input Modality: Run a single puzzle (e.g., Avoiuli) across three conditions: (a) Picture Method, (b) Description Method, and (c) Placeholders-only. Analyze the qualitative difference in reasoning chains to understand how visual information helps or hinders.
2. Pre-training Confounder Test: Select a puzzle in a common language (e.g., Malayalam) and run it in two conditions: (a) using native Unicode, and (b) using the paper's placeholder tokenization. A large performance drop from (a) to (b) quantifies reliance on memorization vs. reasoning.
3. Error Taxonomy Construction: Generate descriptions for a set of tokens and then manually inspect them. Categorize errors into the types identified in the paper (lack of detail, direction confusion, misleading elaboration) to create a quantitative baseline for this bottleneck.

## Open Questions the Paper Calls Out
None

## Limitations
- The study's scope is constrained to five linguistic puzzles, limiting statistical generalizability across different script types and complexity levels
- The evaluation framework depends heavily on the quality of LVLM-generated token descriptions, which showed significant error rates that directly impacted LLM reasoning performance
- The manual, rule-based tokenization method may not generalize to all script types and requires careful exception handling for specific glyph structures

## Confidence

**High Confidence:**
- Models struggle with complex glyph structures and often produce incorrect geometric interpretations from images (supported by systematic error analysis in Section 5.2)
- Performance improves with Unicode encoding for common languages like Malayalam due to pre-trained knowledge (demonstrated through direct comparison of Unicode vs. placeholder conditions)
- The Description Method's token description generation is a critical bottleneck (validated through the description pairing experiment)

**Medium Confidence:**
- Current AI methods have fundamental limitations for linguistic decipherment (inferred from results but requires broader testing across more scripts and puzzle types)
- Pre-trained knowledge confounds evaluation of pure reasoning capabilities (supported by Malayalam results but not fully isolated for all tested languages)
- The Picture Method often hinders reasoning due to incorrect geometric interpretations (based on qualitative analysis but could benefit from more systematic quantification)

**Low Confidence:**
- The specific claims about why models fail (e.g., "hallucinate meaning from visual shapes") are interpretive and would benefit from more controlled experiments
- The extent to which these findings generalize beyond the specific scripts and puzzles tested remains uncertain

## Next Checks

1. **Cross-script Generalization Test**: Apply the same evaluation pipeline to additional rare scripts (e.g., Bamum, Bassa Vah, or Vai) to determine if the observed limitations are script-specific or represent broader architectural constraints in LLMs/LVLMs.

2. **Controlled Reasoning Isolation**: Design a set of puzzles where the only variable is the amount of pre-training data available, ranging from completely novel scripts to moderately known ones, to more precisely quantify the reasoning vs. memorization tradeoff.

3. **Alternative Description Methods**: Implement and test automated description generation using a different LVLM or a fine-tuned model specifically trained on glyph description tasks to determine if the quality bottleneck is inherent to the approach or specific to the model used.