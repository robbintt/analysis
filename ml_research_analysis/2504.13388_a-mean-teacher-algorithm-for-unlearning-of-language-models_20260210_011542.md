---
ver: rpa2
title: A mean teacher algorithm for unlearning of language models
arxiv_id: '2504.13388'
source_url: https://arxiv.org/abs/2504.13388
tags:
- unlearning
- loss
- which
- arxiv
- teacher
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the mean teacher algorithm for language
  model unlearning, aiming to reduce memorization of specific text instances while
  maintaining model utility. The key insight is that mean teacher can approximate
  slow natural gradient descent, which inherently seeks low-curvature updates less
  likely to degrade model performance.
---

# A mean teacher algorithm for unlearning of language models

## Quick Facts
- arXiv ID: 2504.13388
- Source URL: https://arxiv.org/abs/2504.13388
- Authors: Yegor Klochkov
- Reference count: 40
- Key outcome: Mean teacher algorithm combined with NLUL loss improves unlearning metrics on MUSE benchmarks

## Executive Summary
This paper introduces a novel approach to language model unlearning using a mean teacher algorithm combined with a new negative log-unlikelihood (NLUL) loss. The method aims to remove memorization of specific text instances while preserving overall model utility. The mean teacher algorithm is shown to approximate slow natural gradient descent, which inherently seeks low-curvature updates that are less likely to degrade performance. The NLUL loss addresses vanishing gradient issues common with existing unlearning losses, enabling more effective unlearning.

## Method Summary
The method combines mean teacher algorithm with a new NLUL loss for language model unlearning. Mean teacher creates a slowly moving average of model parameters to stabilize training. The NLUL loss is designed to work effectively with mean teacher, addressing vanishing gradient problems common in unlearning scenarios. This combination approximates slow natural gradient descent, seeking low-curvature updates that preserve model utility while removing memorized information.

## Key Results
- Combination of mean teacher and NLUL loss improves various unlearning metrics compared to baselines on MUSE benchmarks
- Successfully reduces both verbatim memorization and knowledge memorization of forget data
- Maintains utility on retain data while reducing privacy leakage
- Further finetuning can recover knowledge memorization, indicating some encoded knowledge remains

## Why This Works (Mechanism)
The mean teacher algorithm approximates slow natural gradient descent, which inherently seeks low-curvature updates less likely to degrade model performance. This property makes it well-suited for unlearning tasks where we want to remove specific information without harming overall model capabilities. The NLUL loss is specifically designed to work with this framework, addressing vanishing gradient issues that typically plague unlearning methods.

## Foundational Learning
- Natural gradient descent: Needed for understanding why mean teacher works; Quick check: Compare NGD vs regular GD on a simple loss landscape
- Knowledge unlearning: Essential concept; Quick check: Verify forgetting of specific instances while maintaining general capability
- Mean teacher algorithm: Core method; Quick check: Compare with standard teacher-student approaches
- Privacy leakage metrics: Important evaluation criteria; Quick check: Measure remaining information about forget data
- Vanishing gradients in unlearning: Problem being solved; Quick check: Monitor gradient norms during training

## Architecture Onboarding
Component map: Input data -> Forget/Retain split -> NLUL loss computation -> Mean teacher averaging -> Updated parameters
Critical path: NLUL loss calculation depends on mean teacher parameters, which are updated based on current model
Design tradeoffs: NLUL loss vs traditional cross-entropy for unlearning effectiveness vs stability
Failure signatures: Vanishing gradients, degraded performance on retain data, incomplete forgetting
First experiments: 1) Verify NLUL loss works with mean teacher on simple memorization task, 2) Test forgetting rate vs retention of utility, 3) Measure privacy leakage reduction

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focused on specific MUSE benchmark without broader generalization testing
- Theoretical justification for NLUL loss effectiveness not fully explored
- Implications of continual updates on unlearning effectiveness not thoroughly addressed
- Privacy leakage reduction quantification lacks detailed risk analysis

## Confidence
- High: The combination of mean teacher and NLUL improves unlearning metrics compared to baselines on the MUSE benchmarks.
- Medium: The reduction in privacy leakage and memorization is robust, though the extent of remaining vulnerabilities post-unlearning is uncertain.
- Low: The claim that mean teacher inherently seeks low-curvature updates is theoretically grounded but lacks rigorous validation in the context of unlearning.

## Next Checks
1. Test the method on diverse datasets and model architectures beyond MUSE to assess generalizability.
2. Conduct ablation studies to isolate the contributions of mean teacher and NLUL loss to the observed improvements.
3. Evaluate the long-term stability of unlearning by simulating continuous model updates and measuring the persistence of unlearned information.