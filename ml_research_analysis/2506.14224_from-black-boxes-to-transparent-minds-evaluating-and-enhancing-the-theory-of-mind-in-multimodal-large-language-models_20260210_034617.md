---
ver: rpa2
title: 'From Black Boxes to Transparent Minds: Evaluating and Enhancing the Theory
  of Mind in Multimodal Large Language Models'
arxiv_id: '2506.14224'
source_url: https://arxiv.org/abs/2506.14224
tags:
- belief
- agent
- room
- tasks
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes GridToM, a multimodal ToM dataset based on
  a 2D grid world, enabling comprehensive evaluation of multimodal large language
  models (MLLMs) on Theory of Mind (ToM) tasks. Unlike existing unimodal or video-based
  datasets, GridToM provides controllable perceptual information from multiple perspectives
  and includes both first-order and second-order belief tasks.
---

# From Black Boxes to Transparent Minds: Evaluating and Enhancing the Theory of Mind in Multimodal Large Language Models

## Quick Facts
- **arXiv ID:** 2506.14224
- **Source URL:** https://arxiv.org/abs/2506.14224
- **Reference count:** 30
- **Primary result:** Introduces GridToM, a controlled multimodal ToM dataset and training-free intervention method that significantly improves MLLM performance on first-order and second-order belief tasks

## Executive Summary
This paper addresses the challenge of evaluating and enhancing Theory of Mind (ToM) capabilities in Multimodal Large Language Models (MLLMs) by introducing GridToM, a novel dataset based on a 2D grid world. Unlike existing unimodal or video-based datasets, GridToM provides controlled perceptual information from multiple perspectives and includes both first-order and second-order belief tasks. The study conducts interpretability-driven analysis showing that MLLM attention heads can distinguish cognitive information across perspectives, and introduces a training-free intervention method that adjusts attention activations to significantly improve ToM performance.

## Method Summary
The research presents a comprehensive approach to ToM evaluation and enhancement in MLLMs through GridToM, a controlled 2D grid world dataset that enables systematic testing of perspective-taking and belief reasoning. The method involves creating grid-based scenarios where agents have different visual perspectives and beliefs about objects or other agents' knowledge states. Through interpretability analysis, the researchers identify how attention mechanisms process cognitive information across different viewpoints. They then develop a training-free intervention that modifies attention activations to enhance ToM reasoning capabilities, achieving significant improvements in both first-order (predicting others' beliefs) and second-order (predicting what others believe about others' beliefs) tasks.

## Key Results
- GridToM enables controlled evaluation of MLLMs on ToM tasks with multiple perceptual perspectives
- Attention heads in MLLMs can distinguish cognitive information across different viewpoints
- Training-free intervention method significantly improves ToM performance in both first-order and second-order belief tasks
- Enhanced ToM reasoning validated through systematic performance improvements on GridToM benchmark

## Why This Works (Mechanism)
The mechanism works by leveraging the attention mechanisms within MLLMs to process and integrate information from multiple perceptual perspectives. The training-free intervention modifies attention activations to better capture the cognitive distinctions necessary for ToM reasoning, effectively guiding the model to focus on relevant belief-related information while filtering out perspective-conflicting details. This approach exploits the inherent representational capabilities of MLLMs without requiring additional training data or model architecture changes.

## Foundational Learning
- **Theory of Mind (ToM):** The ability to attribute mental states, beliefs, and intentions to others and understand that others can have different beliefs from one's own. **Why needed:** Core cognitive capability being evaluated and enhanced in MLLMs. **Quick check:** Can the model predict what another agent knows or believes about a situation?
- **Multimodal Large Language Models (MLLMs):** AI systems that process and integrate multiple types of input (text, images, etc.) to perform reasoning tasks. **Why needed:** Target models for ToM evaluation and enhancement. **Quick check:** Can the model process both visual and textual information simultaneously?
- **Attention Mechanisms:** Neural network components that weigh the importance of different input elements when processing information. **Why needed:** Key to understanding how MLLMs process cognitive information across perspectives. **Quick check:** Which attention heads activate when processing belief-related information?
- **First-order vs Second-order Beliefs:** First-order involves predicting others' beliefs; second-order involves predicting what others believe about others' beliefs. **Why needed:** Provides hierarchical structure for comprehensive ToM evaluation. **Quick check:** Can the model handle recursive belief attribution?

## Architecture Onboarding
**Component Map:** GridToM dataset -> MLLM input processing -> Attention mechanism analysis -> Training-free intervention -> ToM performance evaluation

**Critical Path:** Input scenario generation → Multimodal processing → Attention pattern analysis → Intervention application → Belief prediction evaluation

**Design Tradeoffs:** Controlled grid environment provides precise experimental control but may lack ecological validity compared to real-world scenarios; training-free intervention avoids costly fine-tuning but may have limited generalization compared to end-to-end training approaches.

**Failure Signatures:** Poor performance on belief prediction tasks despite successful multimodal processing indicates attention mechanisms not effectively capturing cognitive distinctions; failure to generalize beyond controlled scenarios suggests limited transfer to naturalistic ToM tasks.

**First Experiments:** 1) Baseline ToM performance assessment on GridToM without intervention; 2) Attention head activation analysis during ToM task processing; 3) Post-intervention performance comparison across first-order and second-order belief tasks.

## Open Questions the Paper Calls Out
None

## Limitations
- GridToM dataset uses simplified 2D grid environments that may not fully capture real-world social interaction complexity
- Training-free intervention lacks explicit grounding in cognitive theory and operates through somewhat opaque attention modifications
- Evaluation focuses primarily on perspective-taking tasks, potentially missing other crucial ToM aspects like emotional reasoning

## Confidence
- High confidence in technical implementation and dataset construction methodology
- Medium confidence in generalizability of findings to real-world ToM tasks
- Medium confidence in interpretability analysis of attention mechanisms
- Medium confidence in effectiveness of training-free intervention method

## Next Checks
1. Conduct cross-dataset validation by testing GridToM-trained models on established ToM benchmarks like ToM-SSI or video-based ToM datasets to assess generalizability
2. Perform ablation studies on the attention intervention method to determine which specific attention head modifications contribute most significantly to performance improvements
3. Evaluate model performance on dynamic, real-world scenarios involving spontaneous social interactions to test practical applicability beyond controlled grid environments