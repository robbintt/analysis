---
ver: rpa2
title: 'AyurParam: A State-of-the-Art Bilingual Language Model for Ayurveda'
arxiv_id: '2511.02374'
source_url: https://arxiv.org/abs/2511.02374
tags:
- clinical
- ayurvedic
- language
- ayurveda
- ayurparam
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: AyurParam-2.9B is a bilingual (English-Hindi) language model fine-tuned
  from Param-1-2.9B-Instruct on a domain-specific Ayurveda corpus. The model was trained
  using 4.75 million Q&A pairs derived from classical Ayurvedic texts and clinical
  literature.
---

# AyurParam: A State-of-the-Art Bilingual Language Model for Ayurveda

## Quick Facts
- **arXiv ID**: 2511.02374
- **Source URL**: https://arxiv.org/abs/2511.02374
- **Reference count**: 40
- **Primary result**: 39.97% accuracy on BhashaBench-Ayur benchmark, outperforming 1.5-3B instruction-tuned models

## Executive Summary
AyurParam-2.9B is a bilingual (English-Hindi) language model fine-tuned from Param-1-2.9B-Instruct on a domain-specific Ayurveda corpus. The model was trained using 4.75 million Q&A pairs derived from classical Ayurvedic texts and clinical literature. On the BhashaBench-Ayur benchmark, AyurParam-2.9B achieved 39.97% overall accuracy, outperforming other 1.5-3B parameter instruction-tuned models (e.g., Llama-3.2-3B: 33.20%, Qwen2.5-3B: 32.68%) and matching larger models. The model demonstrated particularly strong performance on multiple-choice questions (40.12% accuracy) and maintained consistent results across easy, medium, and hard difficulty levels. This work demonstrates that targeted domain adaptation with high-quality supervision enables small-scale models to achieve outsized gains in specialized benchmarks.

## Method Summary
AyurParam uses supervised fine-tuning (SFT) on Param-1-2.9B-Instruct with 4.75M curated Q&A pairs from ~1,000 Ayurvedic texts (~150K pages, ~54.5M words). The corpus was collected using a taxonomy-driven approach to ensure balanced domain coverage across BAMS curriculum areas. Q&A pairs were generated using Qwen-3 235B under strict evidence constraints, followed by human-in-the-loop calibration to reduce hallucination. Training employed Hugging Face TRL with NVIDIA H100, using bfloat16, learning rate 5e-6, 3 epochs, and batch size 1024. The model uses structured dialogue format with task-specific tokens for bilingual instruction-following.

## Key Results
- AyurParam-2.9B achieved 39.97% overall accuracy on BhashaBench-Ayur benchmark
- Outperformed 1.5-3B instruction-tuned models (Llama-3.2-3B: 33.20%, Qwen2.5-3B: 32.68%)
- Strong performance on multiple-choice questions (40.12% accuracy)
- Consistent results across difficulty levels (easy: 41.28%, medium: 41.01%, hard: 39.21%)

## Why This Works (Mechanism)

### Mechanism 1
Curriculum-aligned taxonomy prevents domain skew and ensures balanced representation across Ayurvedic subfields. A taxonomy derived from BAMS curriculum and canonical compendia guides corpus collection with per-domain quotas, acting as a retrieval lens and enforcing stratified coverage. Domain coverage balance correlates with downstream benchmark performance across diverse question types and specialties.

### Mechanism 2
Knowledge-grounded Q&A synthesis with human-in-the-loop calibration reduces hallucination while scaling supervision. High-capacity LLM generates Q&A pairs under strict constraints (responses derivable from source spans, no external elaboration). Human experts review sampled pages to identify over-generalization and unsupported reasoning, iteratively refining synthesis policy. Constraining generation to source passages and calibrating with expert feedback yields factually grounded supervision that transfers to model performance.

### Mechanism 3
Explicit supervision markers in dialogue format improve instruction-following for bilingual conversational tasks. Training data uses structured tags (`<user>`, `<assistant>`, `<actual response>`) with 6 task-specific tokens, creating clear separation between prompts and ground-truth outputs across single-turn and multi-turn dialogues. Marker-based supervision format helps the model learn turn-taking and response boundaries, particularly for code-switched English-Hindi contexts.

## Foundational Learning

- **Supervised Fine-Tuning vs. Continual Pre-training**: AyurParam uses SFT on Param-1-2.9B-Instruct rather than pre-training from scratch; understanding this distinction clarifies why domain adaptation works with only 4.75M samples. Quick check: Can you explain why SFT requires fewer samples than pre-training to achieve domain specialization?

- **OCR Confidence Filtering and Post-Processing for Indic Scripts**: ~150K pages from scanned PDFs required Surya OCR with confidence scoring; low-confidence pages were flagged or excluded to prevent noise in training data. Quick check: What post-OCR normalization steps are specific to Devanagari script (e.g., akshara handling, danda detection)?

- **Evaluation Benchmark Design for Specialized Domains**: BhashaBench-Ayur (14,963 questions, 15+ domains) evaluates factual recall and clinical reasoning; understanding its structure helps interpret 39.97% accuracy meaningfully. Quick check: Why might MCQ accuracy (40.12%) not correlate with open-ended consultation quality?

## Architecture Onboarding

- **Component map**: Taxonomy -> Corpus collection (~1K books, ~150K pages) -> License filtering -> Surya OCR -> Normalization -> Q&A synthesis (Qwen-3 235B) -> Human calibration -> Quality filters -> 4.75M training pairs -> Param-1-2.9B-Instruct base -> Hugging Face TRL SFT -> AyurParam-2.9B

- **Critical path**: 
  1. Taxonomy definition must precede collection to avoid domain skew
  2. OCR confidence filtering gates data quality before synthesis
  3. Evidence anchoring in Q&A generation determines factual grounding
  4. SFT hyperparameters (LR 5e-6, 3 epochs) balance adaptation vs. catastrophic forgetting

- **Design tradeoffs**:
  - Model size vs. specialization: 2.9B model outperforms 3B generalist baselines but requires 4.75M domain-specific samples
  - English-Hindi balance: Hindi accuracy (38.04%) lags English (41.12%); corpus was 50.6% English vs. 22.6% Hindi
  - Synthetic vs. expert validation: LLM-generated Q&A scaled supervision but required human-in-the-loop for hallucination reduction

- **Failure signatures**:
  - Performance drop on Hindi queries indicates insufficient multilingual representation
  - Lower accuracy on reasoning-intensive domains (Panchakarma & Rasayana) suggests synthesis templates miss complex inference patterns
  - Assertion-reason questions (44.44%) underperform vs. Gemma-27B (55.56%) on larger models, suggesting scale matters for multi-step reasoning

- **First 3 experiments**:
  1. Ablate taxonomy-guided collection: Train on randomly collected corpus (no per-domain quotas) and compare BhashaBench-Ayur domain-level accuracy to identify coverage gaps.
  2. Test Hindi data augmentation: Upsample Hindi Q&A pairs or add Hindi-only fine-tuning stage; measure Hindi accuracy delta (baseline: 38.04%).
  3. Evaluate on open-ended consultation: Beyond MCQ, run human expert evaluation on generated responses to clinical scenarios; assess safety, factual accuracy, and cultural appropriateness.

## Open Questions the Paper Calls Out

### Open Question 1
What interventions can effectively close the Hindi-English performance gap in AyurParam (currently 38.04% vs. 41.12% accuracy)? The authors explicitly note that "performance in Hindi lagged behind English" and list "improving Hindi and Sanskrit understanding" as essential for the next phase of research. This remains unresolved as the paper identifies the gap but does not diagnose whether it stems from training data imbalance, tokenization issues, or fine-tuning methodology.

### Open Question 2
How does AyurParam perform on open-ended clinical consultation tasks and realistic diagnostic reasoning, beyond structured exam questions? The limitations section states that evaluation "relies exclusively on structured exam-style questions" and does not capture "open-ended generation quality" or "clinical reasoning in realistic consultation scenarios." BhashaBench-Ayur only assesses MCQ, fill-in-blank, and matching formats; no human evaluation or open-response benchmarks were used.

### Open Question 3
What safety guardrails are required to prevent AyurParam from generating harmful or inappropriate medical advice? The authors acknowledge AyurParam "lacks explicit safety mechanisms to prevent generation of inappropriate, unsafe, or potentially harmful medical advice" and call for "explicit safety layers" in future work. The model was trained on factual content but not aligned with safety constraints; no refusal mechanisms or uncertainty quantification are implemented.

## Limitations
- Evaluation relies exclusively on structured exam-style questions and does not capture open-ended generation quality or clinical reasoning in realistic consultation scenarios
- Performance in Hindi lagged behind English, indicating insufficient multilingual representation despite balanced corpus design
- Lacks explicit safety mechanisms to prevent generation of inappropriate, unsafe, or potentially harmful medical advice

## Confidence
- **High Confidence**: AyurParam-2.9B's SFT methodology, parameter settings (LR 5e-6, 3 epochs), and BhashaBench-Ayur benchmark structure are explicitly specified and reproducible
- **Medium Confidence**: Domain adaptation performance gains are well-supported by comparative results, but the relative contributions of taxonomy guidance, Q&A synthesis quality, and bilingual balancing require controlled ablation studies
- **Low Confidence**: The long-term generalization of synthetic supervision to open-ended clinical reasoning tasks and the model's safety profile for medical consultation remain unvalidated per Section 7

## Next Checks
1. **Ablate taxonomy-guided collection**: Train on randomly collected corpus (no per-domain quotas) and compare BhashaBench-Ayur domain-level accuracy to identify coverage gaps and quantify taxonomy contribution.

2. **Test Hindi data augmentation**: Upsample Hindi Q&A pairs or add Hindi-only fine-tuning stage; measure Hindi accuracy delta (baseline: 38.04%) to validate bilingual balancing hypothesis.

3. **Evaluate on open-ended consultation**: Beyond MCQ, run human expert evaluation on generated responses to clinical scenarios; assess safety, factual accuracy, and cultural appropriateness (currently unmeasured per Section 7).