---
ver: rpa2
title: Explainable Artificial Intelligence for identifying profitability predictors
  in Financial Statements
arxiv_id: '2501.17676'
source_url: https://arxiv.org/abs/2501.17676
tags:
- features
- financial
- data
- classification
- shap
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates profitability prediction in Italian listed
  companies using raw financial statements data and Machine Learning (ML) models.
  The research applies tree-based ensemble methods (XgBoost, Random Forest) and compares
  their performance against SVM and Logistic Regression on both raw financial data
  and financial ratios.
---

# Explainable Artificial Intelligence for identifying profitability predictors in Financial Statements

## Quick Facts
- arXiv ID: 2501.17676
- Source URL: https://arxiv.org/abs/2501.17676
- Authors: Marco Piazza; Mauro Passacantando; Francesca Magli; Federica Doni; Andrea Amaduzzi; Enza Messina
- Reference count: 24
- One-line primary result: Tree-based models outperform linear approaches, with XgBoost achieving 0.64 accuracy and 0.64 roc-auc on raw financial data

## Executive Summary
This study investigates profitability prediction in Italian listed companies using raw financial statements data and Machine Learning models. The research applies tree-based ensemble methods (XgBoost, Random Forest) and compares their performance against SVM and Logistic Regression on both raw financial data and financial ratios. The study integrates eXplainable AI techniques using SHAP to identify the most influential features and validate their importance. The results show that tree-based models outperform other approaches, with XgBoost achieving 0.64 accuracy and 0.64 roc-auc score on raw data. SHAP analysis reveals that features from the Financial Profile section are consistently the most important predictors.

## Method Summary
The methodology extracts raw financial features from the AIDA database (Bureau van Dijk) covering 327 Italian listed companies from 2013-2022. After removing 20 non-numeric features, the study trains four models (XGBoost, Random Forest, SVM, Logistic Regression) on 301 features to predict ROI direction changes. SHAP values are computed using PartitionSHAP for section-level analysis and KernelSHAP for feature-level attribution. The validation involves feature ranking by SHAP frequency, then retraining on Top-201 features (excluding bottom 100) to demonstrate that removing low-importance features improves accuracy from 0.64 to 0.68.

## Key Results
- Tree-based models outperform linear models, with XGBoost achieving 0.64 accuracy and 0.64 roc-auc on raw financial data
- Financial Profile section features are consistently identified as most important predictors by SHAP analysis
- Removing bottom 100 SHAP-ranked features improves accuracy to 0.68, demonstrating effective noise reduction

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Tree-based ensemble models capture non-linear financial relationships better than linear models when using high-dimensional raw financial data.
- Mechanism: Tree ensembles partition the feature space hierarchically, automatically modeling interactions between financial variables without explicit engineering. Gradient boosting (XGBoost) sequentially corrects residual errors, while Random Forest averages multiple decorrelated trees.
- Core assumption: Profitability signals emerge from complex interactions among raw financial statement items that pre-computed ratios cannot fully represent.
- Evidence anchors:
  - [abstract]: "tree-based models outperform other approaches, with XgBoost achieving 0.64 accuracy and 0.64 roc-auc score on raw data"
  - [section 3.1]: "The tree-based models are the best choice for classifying financial statements data, likely due to their strong ability with tabular data"
  - [corpus]: "Enhancing ML Models Interpretability for Credit Scoring" confirms modern ML methods often outperform traditional regression in financial prediction

### Mechanism 2
- Claim: SHAP values identify influential features by computing each feature's average marginal contribution across all possible feature coalitions.
- Mechanism: SHAP models features as "players" in a cooperative game. For each prediction, it computes Shapley values—the change in model output when a feature is added to a coalition, averaged across all coalition orderings. PartitionSHAP groups features by document section; KernelSHAP provides fine-grained attribution.
- Core assumption: Marginal contribution to model predictions correlates with genuine feature importance for the underlying financial phenomenon.
- Evidence anchors:
  - [abstract]: "SHAP analysis reveals that features from the Financial Profile section are consistently the most important predictors"
  - [section 2]: "Shapley Value corresponds to the average marginal contribution that each player brings to each coalition"
  - [corpus]: "Explaining the Unexplainable: A Systematic Review of Explainable AI in Finance" positions XAI at the intersection of accuracy and transparency in finance

### Mechanism 3
- Claim: Removing features with consistently low SHAP values improves classification by reducing noise without sacrificing signal.
- Mechanism: Features ranked in the bottom 100 by SHAP-derived frequency analysis contribute minimal marginal predictive value. Eliminating them reduces dimensionality from 301 to 201 features, potentially improving generalization.
- Core assumption: Low-SHAP features are genuinely uninformative rather than conditionally important for rare cases or specific subgroups.
- Evidence anchors:
  - [abstract]: "eliminating noisy features (bottom 100) improves accuracy to 0.68"
  - [section 3.3]: "eliminating less important features leads to an increase in classification performance, up to 0.04 accuracy points"
  - [corpus]: Weak direct evidence—corpus papers focus on XAI applications rather than feature selection validation methodology

## Foundational Learning

- Concept: **Shapley Values and Cooperative Game Theory**
  - Why needed here: SHAP's theoretical guarantee (efficiency, symmetry, dummy player property) comes from game theory. Understanding why Shapley values provide "fair" attribution helps interpret results correctly.
  - Quick check question: If two features are perfectly correlated, how would their Shapley values compare to their individual importances?

- Concept: **Tree Ensembles: Bagging vs. Boosting**
  - Why needed here: The paper uses both Random Forest (bagging) and XGBoost (boosting). Knowing their differences guides model selection and hyperparameter tuning.
  - Quick check question: Which ensemble method is more prone to overfitting on noisy financial data, and why?

- Concept: **Raw Financial Features vs. Engineered Ratios**
  - Why needed here: The study explicitly compares raw data to pre-computed ratios, showing raw data outperforms with non-linear models.
  - Quick check question: Why might financial ratios discard information that tree-based models could recover from raw line items?

## Architecture Onboarding

- Component map:
  - AIDA database -> 327 Italian listed companies -> 321 features across 4 sections (Financial Profile, Balance Sheet, Income Statement, Ratios)
  - Remove 20 non-numeric features; temporal split (train: 2013-2020, test: 2021)
  - Model layer: XGBoost (primary), Random Forest, SVM, Logistic Regression (baselines)
  - Explanation layer: PartitionSHAP for section-level analysis; KernelSHAP for feature-level attribution
  - Validation layer: Feature ranking by SHAP frequency -> subset retraining -> accuracy comparison

- Critical path:
  1. Extract raw features from financial statements (not pre-computed ratios)
  2. Train XGBoost for binary ROI direction prediction
  3. Apply KernelSHAP to compute per-instance feature importance
  4. Aggregate SHAP rankings across test set
  5. Retrain on Top-201 features (exclude bottom 100) for validation

- Design tradeoffs:
  - Raw data vs. ratios: Raw (321 features) preserves more signal but requires robust models; ratios simplify but lose information
  - XGBoost vs. Random Forest: Random Forest achieved slightly higher raw-data accuracy (0.67 vs. 0.64), but XGBoost was used for SHAP validation
  - PartitionSHAP vs. KernelSHAP: Partition faster for document-section analysis; KernelSHAP more precise but computationally expensive (O(2^n) approximation)
  - Aggressive vs. conservative pruning: Top-100 (0.61 accuracy) vs. Top-201 (0.68 accuracy)—moderate pruning outperforms aggressive

- Failure signatures:
  - Accuracy collapse when switching from raw to ratio features with tree models (XGBoost: 0.64 → 0.55)
  - Transition zone between Balance Sheet and Income Statement shows consistently low SHAP values—potential data quality issue
  - Class-specific feature selection yields minimal improvement over global selection (0.69 vs. 0.68)

- First 3 experiments:
  1. Replicate baseline: Train XGBoost on all 301 raw features with temporal split; verify ~0.64 accuracy on 2021 test
  2. SHAP feature analysis: Run KernelSHAP, compute feature frequency in top-50 across test instances; confirm Financial Profile dominance
  3. Feature ablation validation: Exclude bottom 100 SHAP-ranked features; retrain and confirm accuracy improvement to ~0.68

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does integrating unstructured text from financial statement notes significantly improve profitability prediction accuracy?
- Basis in paper: [explicit] The authors state they "plan to extend the model in multi-modal settings, integrating the free text information contained in additional notes."
- Why unresolved: The current study is limited to structured tabular data, ignoring potential qualitative signals in notes.
- What evidence would resolve it: Comparative performance metrics of models using NLP/LLM-derived text features versus the tabular baseline.

### Open Question 2
- Question: Does expanding the dataset to include more years, companies, and international markets enhance the performance of ML-based profitability prediction?
- Basis in paper: [explicit] The authors suggest "augmentation of the current dataset... can be fundamental to fully explore the potential of ML-based algorithms."
- Why unresolved: The current sample is restricted to 327 Italian companies, which may limit the algorithms' learning potential.
- What evidence would resolve it: Performance validation of the methodology applied to a larger, cross-border dataset.

### Open Question 3
- Question: How can the validity of SHAP explanations be objectively evaluated beyond observing changes in classification accuracy?
- Basis in paper: [inferred] The paper identifies the "absence of a recognized and objective method for evaluating proposed explanations" as a gap, using feature removal as a proxy.
- Why unresolved: Validating explanations solely by accuracy changes (0.61 to 0.68) does not confirm the explanation reflects true economic causality.
- What evidence would resolve it: Testing the method on synthetic data with known ground-truth feature importance or comparison with expert qualitative analysis.

## Limitations

- Missing hyperparameter specifications make exact replication challenging
- ROI calculation methodology not fully specified
- Feature selection validation assumes SHAP rankings are stable across model restarts

## Confidence

- High confidence: Tree-based models outperform linear approaches on raw financial data
- Medium confidence: SHAP feature importance correctly identifies Financial Profile section dominance
- Medium confidence: Feature elimination validation methodology

## Next Checks

1. Verify temporal split implementation and target calculation methodology with sample company
2. Compare SHAP-derived feature rankings across multiple model training runs to assess stability
3. Test SHAP ranking stability under different coalition sampling strategies (KernelSHAP approximations)