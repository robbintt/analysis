---
ver: rpa2
title: 'GEM+: Scalable State-of-the-Art Private Synthetic Data with Generator Networks'
arxiv_id: '2511.09672'
source_url: https://arxiv.org/abs/2511.09672
tags:
- data
- privacy
- columns
- synthetic
- generator
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: GEM+ addresses the scalability limitations of state-of-the-art
  differentially private synthetic data methods like AIM by integrating AIM's adaptive
  measurement framework with GEM's scalable generator neural networks. AIM's use of
  graphical models becomes computationally infeasible for high-dimensional data due
  to memory constraints and retraining overhead, while GEM lacks AIM's adaptive privacy-aware
  selection strategy.
---

# GEM+: Scalable State-of-the-Art Private Synthetic Data with Generator Networks

## Quick Facts
- arXiv ID: 2511.09672
- Source URL: https://arxiv.org/abs/2511.09672
- Authors: Samuel Maddock; Shripad Gade; Graham Cormode; Will Bullock
- Reference count: 12
- Primary result: GEM+ achieves up to 4x lower L1 error than GEM while scaling to 120 columns where AIM fails

## Executive Summary
GEM+ addresses the scalability limitations of state-of-the-art differentially private synthetic data methods by integrating AIM's adaptive measurement framework with GEM's scalable generator neural networks. AIM's use of graphical models becomes computationally infeasible for high-dimensional data due to memory constraints and retraining overhead, while GEM lacks AIM's adaptive privacy-aware selection strategy. GEM+ combines the strengths of both approaches through workload closure for comprehensive query coverage, adaptive budget allocation favoring measurement, enhanced selection using AIM's scoring, candidate filtering to prevent redundant measurements, and marginal closure to estimate lower-order queries at no extra privacy cost.

Experimental results on the Criteo Ads dataset demonstrate GEM+'s superior performance: it outperforms AIM in utility when tractable (d ≤ 60), scales to 120 columns where AIM fails due to computational constraints, and achieves up to 4x lower L1 error compared to GEM. Runtime analysis shows GEM+ scales linearly with column count (41 hours for 120 columns) versus AIM's exponential growth (exceeding 5 days for 60 columns). The method sets a new benchmark for private synthetic data generation in real-world high-dimensional scenarios.

## Method Summary
GEM+ is a differentially private synthetic data generation method that combines the adaptive measurement strategy of AIM with the scalable generator neural networks of GEM. The method addresses AIM's computational infeasibility for high-dimensional data (where graphical model construction becomes memory-prohibitive) while retaining AIM's adaptive privacy-aware selection mechanism. GEM+ uses workload closure to ensure comprehensive query coverage, allocates more privacy budget to measurements than generator training, employs candidate filtering to prevent redundant measurements, and leverages marginal closure to estimate lower-order queries without additional privacy cost. The approach scales linearly with the number of columns, enabling practical deployment on datasets with hundreds of features where previous methods fail.

## Key Results
- Achieves up to 4x lower L1 error compared to GEM on the Criteo Ads dataset
- Scales to 120 columns where AIM fails due to computational constraints (runtime exceeds 5 days for 60 columns)
- Maintains linear runtime scaling (41 hours for 120 columns) versus AIM's exponential growth
- Outperforms AIM in utility when both methods are tractable (d ≤ 60 columns)

## Why This Works (Mechanism)
GEM+ succeeds by addressing the fundamental trade-off between adaptive privacy selection and computational scalability in private synthetic data generation. AIM's strength lies in its adaptive measurement framework that intelligently selects which marginals to measure based on their utility for the query workload, but this requires constructing and working with graphical models that become computationally intractable as dimensionality increases. GEM's generator neural networks scale well but lack the adaptive measurement strategy that enables efficient privacy budget allocation. GEM+ bridges this gap by using generator networks to learn the data distribution while incorporating AIM's adaptive measurement framework for privacy budget allocation and marginal selection. The marginal closure property ensures that higher-order measurements automatically provide information about lower-order queries, preventing privacy budget waste. Candidate filtering prevents redundant measurements, and the workload closure ensures comprehensive coverage of all possible queries without exponential overhead.

## Foundational Learning

**Differentially Private Synthetic Data Generation**: Creating synthetic datasets that preserve statistical properties while providing formal privacy guarantees. Needed because real data often contains sensitive information that cannot be directly shared. Quick check: Verify that synthetic data satisfies ε-differential privacy guarantees.

**Adaptive Measurement Framework**: Dynamically selecting which statistical queries to measure based on their expected utility. Needed because privacy budgets are limited and should be allocated to measurements that maximize overall data utility. Quick check: Confirm that measurement selection algorithm provides theoretical privacy guarantees.

**Marginal Closure**: The property that measuring a k-way marginal automatically provides information about all its lower-order subsets. Needed to prevent wasting privacy budget on redundant lower-order measurements. Quick check: Verify that measuring P(A,B,C) implies accurate estimation of P(A), P(B), P(C), and P(A,B).

**Workload Closure**: The property that synthetic data generated from a workload covers all possible queries over that workload. Needed to ensure comprehensive utility across all potential analytical queries. Quick check: Confirm that synthetic data supports accurate estimation of all 2-way and 3-way marginals.

**Generator Neural Networks**: Deep learning models that learn to generate synthetic data matching the statistical properties of real data. Needed for scalability to high-dimensional data where graphical models become infeasible. Quick check: Validate that generator produces data with similar marginal distributions to real data.

## Architecture Onboarding

Component map: Real Data -> Marginal Selection -> Privacy Budget Allocation -> Measurement Queries -> Generator Training -> Synthetic Data -> Query Evaluation

Critical path: Marginal Selection -> Privacy Budget Allocation -> Measurement Queries -> Generator Training -> Synthetic Data generation. This path determines the quality and utility of the final synthetic data.

Design tradeoffs: GEM+ trades off some of AIM's theoretical optimality for practical scalability. While AIM provides optimal measurement selection through graphical models, GEM+ uses generator networks that may not achieve the same theoretical guarantees but scale to much larger datasets. The method also prioritizes measurement over generator training in privacy budget allocation, accepting potentially less sophisticated generators in exchange for more accurate measurements.

Failure signatures: Performance degradation occurs when: 1) The generator fails to learn complex data distributions, 2) Marginal selection misses important features, 3) Privacy budget allocation is suboptimal, or 4) The dataset has highly complex correlations that cannot be captured by the chosen model architecture.

First experiments:
1. Compare GEM+ utility on simple synthetic datasets with known ground truth to validate accuracy
2. Test scalability by measuring runtime on datasets with increasing dimensionality (10, 20, 40, 80 columns)
3. Evaluate privacy-utility tradeoff by varying ε across orders of magnitude (0.1, 1, 10)

## Open Questions the Paper Calls Out

None

## Limitations

- Claims of "state-of-the-art" performance primarily based on comparison to only two methods (GEM and AIM), leaving uncertainty about performance relative to other approaches like PrivBayes or MWEM variants
- Utility improvements demonstrated on a single real-world dataset (Criteo Ads), raising questions about generalizability across different data distributions and query workloads
- Limited empirical validation of the "comprehensive query coverage" claim through workload closure beyond reported metrics

## Confidence

High confidence in scalability claims (runtime comparisons with AIM are concrete and reproducible)
Medium confidence in utility improvements (based on single dataset, limited comparison set)
Medium confidence in adaptive measurement strategy (theoretical soundness established, empirical validation limited)

## Next Checks

1. Benchmark GEM+ against additional state-of-the-art methods (PrivBayes, MWEM, PrivPGM) on the same Criteo Ads dataset to establish true relative performance
2. Evaluate GEM+ on multiple diverse datasets with varying characteristics (categorical vs continuous, correlated vs independent features) to test generalizability
3. Conduct ablation studies to quantify the individual contributions of each proposed component (adaptive measurement, candidate filtering, marginal closure) to the overall performance gains