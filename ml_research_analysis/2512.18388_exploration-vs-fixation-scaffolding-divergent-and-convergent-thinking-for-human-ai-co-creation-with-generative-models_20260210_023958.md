---
ver: rpa2
title: 'Exploration vs. Fixation: Scaffolding Divergent and Convergent Thinking for
  Human-AI Co-Creation with Generative Models'
arxiv_id: '2512.18388'
source_url: https://arxiv.org/abs/2512.18388
tags:
- users
- image
- participants
- thinking
- design
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of design fixation and premature
  convergence in human-AI co-creation workflows, where users often settle on early
  "good enough" results and struggle to explore broader creative spaces. The authors
  propose a structured, process-oriented paradigm grounded in Wallas's model of creativity,
  explicitly scaffolding divergent (conceptual exploration) and convergent (refinement)
  thinking stages.
---

# Exploration vs. Fixation: Scaffolding Divergent and Convergent Thinking for Human-AI Co-Creation with Generative Models

## Quick Facts
- arXiv ID: 2512.18388
- Source URL: https://arxiv.org/abs/2512.18388
- Authors: Chao Wen; Tung Phung; Pronita Mehrotra; Sumit Gulwani; Tomohiro Nagashima; Adish Singla
- Reference count: 40
- Primary result: Two-stage workflow significantly improves creativity support, usability, and novelty of final images versus direct generation.

## Executive Summary
This paper addresses the challenge of design fixation and premature convergence in human-AI co-creation workflows, where users often settle on early "good enough" results and struggle to explore broader creative spaces. The authors propose a structured, process-oriented paradigm grounded in Wallas's model of creativity, explicitly scaffolding divergent (conceptual exploration) and convergent (refinement) thinking stages. They implement this in HAIExplore, a system with a brainstorming stage for generating diverse high-level ideas using associative thinking prompts, and a refinement stage with interpretable parameters and options for controllable iteration. A within-subjects study (N=12) comparing HAIExplore to ChatGPT for poster design showed that HAIExplore significantly improved creativity support (Enjoyment p=0.0034, Exploration p=0.0029, Results Worth Effort p=0.0137), system usability (p=0.0059), and novelty of final images (p=0.004). Participants also reported significantly higher perceived learning (p=0.0059) and appreciated the structured workflow for reducing cognitive load and fostering transferable prompting skills.

## Method Summary
The authors developed HAIExplore, a two-stage system using GPT-5 for idea generation and Sketch synthesis, and GPT-Image-1 for image generation. The brainstorming stage uses associative-thinking prompting to generate 9 conceptual ideas with 3×3 tiled thumbnails. The refinement stage synthesizes "Sketch" functions (Python code) that map abstract parameters to concrete prompts, enabling real-time parameter adjustment. A within-subjects study (N=12) with counterbalanced conditions compared HAIExplore to ChatGPT across three task pairs, measuring creativity support (CSI), usability (UMUX-Lite), image novelty (human ratings), diversity (CLIP embeddings), and perceived learning.

## Key Results
- HAIExplore significantly outperformed ChatGPT on CSI dimensions: Enjoyment (p=0.0034), Exploration (p=0.0029), and Results Worth Effort (p=0.0137)
- System usability significantly higher (UMUX-Lite p=0.0059)
- Final images showed significantly higher novelty (p=0.004)
- Participants reported significantly higher perceived learning (p=0.0059)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Structuring human-AI co-creation into explicit divergent (brainstorming) and convergent (refinement) stages reduces design fixation and premature convergence.
- Mechanism: The stage separation interrupts the "slot machine" workflow where users immediately generate artifacts and settle on early "good enough" results. By forcing a conceptual exploration phase before generation, users explore a broader design space before committing.
- Core assumption: Users will engage meaningfully with the brainstorming stage rather than rushing through it to reach generation.
- Evidence anchors:
  - [abstract] "Our findings show that explicitly scaffolding the creative process into brainstorming and refinement stages can mitigate design fixation, improve perceived controllability and alignment with users' intentions"
  - [section 6.1] "Participants rated HAIExplore significantly higher on Enjoyment (p=0.0034), Exploration (p=0.0029), and Results Worth Effort (p=0.0137)"
  - [corpus] "Scaffolding Creativity: How Divergent and Convergent LLM Personas..." confirms structured personas for divergent/convergent thinking shape creative problem-solving
- Break condition: If the brainstorming stage surfaces too many options without adequate filtering, users experience cognitive overload ("sometimes overstimulating" - P1).

### Mechanism 2
- Claim: Explicitly prompting LLMs to use associative thinking during ideation increases idea diversity and novelty.
- Mechanism: The system instructs the generative model to draw connections from diverse domains (artworks, historical events, mythology, metaphors) rather than generating obvious variations. This produces conceptually distinct ideas that push users beyond their initial mental models.
- Core assumption: The LLM can surface associations that are both diverse enough to be valuable and coherent enough to be useful.
- Evidence anchors:
  - [section 4.1] "we explicitly prompt the generative model to perform associative thinking during idea generation by drawing connections from various domains (e.g., artworks, historical events, mythology, metaphors)"
  - [section 6.2] "associative-thinking prompting significantly outperformed the counterpart (p=0.016), producing higher diversity scores (M=0.64, SD=0.05 vs. M=0.61, SD=0.06)"
  - [corpus] Limited direct evidence; corpus papers focus on ideation workflows but not specifically on associative prompting efficacy
- Break condition: If associations are too obscure or culturally specific, users may not recognize their relevance or feel alienated.

### Mechanism 3
- Claim: Externalizing users' refinement intentions as interpretable parameters and selectable options bridges the "gulf of envisioning" and reduces trial-and-error prompting.
- Mechanism: When users describe high-level refinement goals (e.g., "make it more lively"), the system synthesizes a Sketch—a parametric function that infers relevant dimensions and generates concrete options. Users select rather than author, shifting from recall-based to recognition-based interaction.
- Core assumption: The system can accurately infer which parameters are relevant and provide meaningful options for each.
- Evidence anchors:
  - [abstract] "scaffolds convergent refinement through an interface that externalizes users' refinement intentions as interpretable parameters and options, making the refinement process more controllable"
  - [section 6.3] "Default Option Adoption... 26.4% (SD=29.7%)... indicating the importance of having users in the loop, selecting their own preferences"
  - [corpus] Weak corpus evidence on this specific parametric approach; related work (PromptCharm, GenTune) focuses on prompt optimization rather than user-selectable parameters
- Break condition: If parameters are too abstract (e.g., "mosaic" style), users struggle to map text options to visual outcomes without preview thumbnails.

## Foundational Learning

- **Divergent vs. Convergent Thinking (Guilford/Wallas)**
  - Why needed here: The entire system architecture is built on distinguishing these cognitive modes. Without understanding that early-stage exploration (divergent) requires different scaffolding than late-stage refinement (convergent), the two-stage workflow will seem arbitrary.
  - Quick check question: Can you explain why showing users a generated image immediately after their first prompt might harm divergent exploration?

- **Design Fixation**
  - Why needed here: The core problem the paper addresses. Users anchor on early outputs and fail to explore alternatives. Understanding this bias is essential for evaluating why structured stages help.
  - Quick check question: What is the difference between "good enough" convergence and premature design fixation?

- **The Gulf of Envisioning (Subramanyam et al.)**
  - Why needed here: The refinement stage is specifically designed to bridge this gap—users know what they want to change but cannot express it in precise prompts. The Sketch mechanism externalizes tacit intent.
  - Quick check question: Why might a user say "make it livelier" but reject the image when the model adds bright saturated colors?

## Architecture Onboarding

- **Component map:** User Prompt -> Associative Brainstorming (GPT-5) -> Idea Cards + Thumbnails (GPT-Image-1-mini) -> Refinement Prompt -> Sketch Synthesis (GPT-5) -> Parameters + Options -> Prompt Preview -> Image Generation (GPT-Image-1)

- **Critical path:**
  1. User enters ideation prompt → Backend queries GPT-5 with associative-thinking instructions → Returns 9 Idea Cards
  2. GPT-Image-1-mini generates composite 3×3 tile image → Frontend slices into 9 thumbnails
  3. User selects Idea Card → Backend generates full image with GPT-Image-1 (Medium quality)
  4. User clicks Refine → New tab opens → User enters refinement prompt → Backend synthesizes Sketch function
  5. Sketch execution generates Parameters + Options → User selects/edits → Prompt Preview updates → User generates refined image (Auto quality)

- **Design tradeoffs:**
  - Structured guidance vs. user agency: Some participants (P1, P8) felt reduced ownership when the system provided too many suggestions
  - Divergence quantity vs. cognitive load: More ideas increase exploration but risk overwhelming users
  - Transparency vs. simplicity: Showing full prompts aids learning but adds complexity; hiding them reduces cognitive burden but limits skill transfer

- **Failure signatures:**
  - Cognitive overload: User stares at Idea Grid without selecting anything for >60 seconds
  - Fixation in refinement: User generates >5 variations of the same image cluster without branching
  - Parameter confusion: User generates image, immediately regenerates with different options, repeats without downloading (suggests options don't match mental model)
  - Agency loss: User reports "the ideas are mostly the system's, not mine" in feedback

- **First 3 experiments:**
  1. **Ablate associative prompting:** Run the same user prompts with and without associative-thinking instructions; measure idea diversity via CLIP embedding distance. Expected: associative condition produces higher pairwise cosine distance.
  2. **Measure Sketch inference accuracy:** For a held-out set of refinement prompts, manually label ground-truth parameters; compare system-inferred parameters to ground truth. Target: >70% relevance.
  3. **Transfer learning check:** Have users complete one session with HAIExplore, then switch to ChatGPT. Count how many users spontaneously request brainstorming ideas in their first ChatGPT prompt. Baseline: users without HAIExplore exposure should rarely do this (<20%).

## Open Questions the Paper Calls Out
None

## Limitations
- Small sample size (N=12) limits generalizability and may inflate effect sizes
- Within-subjects design may introduce learning effects despite counterbalancing
- Reliance on GPT-5 for associative thinking and Sketch synthesis creates reproducibility barriers
- Reduced user agency reported by some participants suggests potential tradeoff between guidance and ownership

## Confidence

**High confidence:** The two-stage workflow improves usability (UMUX-Lite p=0.0059) and reduces premature convergence through explicit stage separation. The associative-thinking prompting significantly improves idea diversity (p=0.016).

**Medium confidence:** The system reduces design fixation and improves perceived learning (p=0.0059), though these effects may be partially attributable to novelty effects given the small sample size and single task domain.

**Low confidence:** The long-term transferability of prompting skills and the generalizability of the "gulf of envisioning" reduction mechanism to other creative domains remain uncertain.

## Next Checks

1. **Ablate associative prompting:** Run the same user prompts with and without associative-thinking instructions; measure idea diversity via CLIP embedding distance. Expected: associative condition produces higher pairwise cosine distance.

2. **Measure Sketch inference accuracy:** For a held-out set of refinement prompts, manually label ground-truth parameters; compare system-inferred parameters to ground truth. Target: >70% relevance.

3. **Transfer learning check:** Have users complete one session with HAIExplore, then switch to ChatGPT. Count how many users spontaneously request brainstorming ideas in their first ChatGPT prompt. Baseline: users without HAIExplore exposure should rarely do this (<20%).