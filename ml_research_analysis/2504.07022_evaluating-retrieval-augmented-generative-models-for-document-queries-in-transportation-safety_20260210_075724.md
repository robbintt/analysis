---
ver: rpa2
title: Evaluating Retrieval Augmented Generative Models for Document Queries in Transportation
  Safety
arxiv_id: '2504.07022'
source_url: https://arxiv.org/abs/2504.07022
tags:
- information
- regulations
- llama
- transportation
- generative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study evaluates generative Large Language Models (LLMs) for\
  \ retrieving regulatory information in hazardous materials transportation. Three\
  \ fine-tuned models\u2014ChatGPT, Google Vertex AI, and ORNL Retrieval Augmented\
  \ Generation (RAG) with LLaMA 2 and LLaMA 3\u2014were tested using 100 queries derived\
  \ from 40 regulatory documents."
---

# Evaluating Retrieval Augmented Generative Models for Document Queries in Transportation Safety

## Quick Facts
- **arXiv ID:** 2504.07022
- **Source URL:** https://arxiv.org/abs/2504.07022
- **Reference count:** 11
- **Primary result:** RAG-augmented LLaMA models outperformed ChatGPT and Vertex AI in regulatory query accuracy

## Executive Summary
This study evaluates generative Large Language Models (LLMs) for retrieving regulatory information in hazardous materials transportation. Three fine-tuned models—ChatGPT, Google Vertex AI, and ORNL Retrieval Augmented Generation (RAG) with LLaMA 2 and LLaMA 3—were tested using 100 queries derived from 40 regulatory documents. Qualitative ratings (1–5 scale) assessed accuracy, detail, and relevance, while semantic similarity measured response consistency. The RAG-augmented LLaMA models outperformed others, scoring an average of 4.03, compared to 3.41 for Vertex AI and 3.03 for ChatGPT. Semantic similarity analysis showed high consistency among RAG models (average >0.9) but greater variation with ChatGPT. Results highlight RAG's potential for domain-specific applications, though occasional inconsistencies emphasize the need for further refinement.

## Method Summary
The study employed a comparative evaluation framework using three fine-tuned LLM approaches: ChatGPT, Google Vertex AI, and ORNL's RAG system using LLaMA 2 and LLaMA 3. Researchers constructed 100 test queries from 40 regulatory documents related to hazardous materials transportation. Model performance was assessed through qualitative ratings on accuracy, detail, and relevance using a 1-5 scale, supplemented by semantic similarity analysis to measure response consistency. The evaluation focused on domain-specific regulatory information retrieval capabilities.

## Key Results
- RAG-augmented LLaMA models achieved the highest average score (4.03) across qualitative metrics
- Semantic similarity analysis revealed high consistency among RAG models (average >0.9)
- ChatGPT showed greater variation in response consistency compared to RAG models

## Why This Works (Mechanism)
RAG-augmented LLaMA models likely excel due to their retrieval mechanism that grounds responses in relevant regulatory documents. By incorporating external knowledge sources during inference, these models can access and reference specific regulatory content rather than relying solely on pre-trained knowledge. This document-grounded approach enables more accurate and detailed responses to domain-specific queries, particularly in complex regulatory contexts where precise information retrieval is critical.

## Foundational Learning
The study builds on prior work demonstrating RAG's effectiveness in domain-specific knowledge retrieval tasks. It extends existing research by applying RAG techniques to hazardous materials transportation regulations, a domain requiring high precision and regulatory compliance. The comparative framework with commercial LLMs (ChatGPT, Vertex AI) provides insights into when retrieval augmentation offers advantages over purely generative approaches in specialized knowledge domains.

## Architecture Onboarding
The RAG architecture combines a pre-trained LLaMA language model with a retrieval component that accesses regulatory documents during inference. When a query is received, the system first retrieves relevant passages from the document corpus using semantic search techniques, then feeds both the query and retrieved passages to the LLaMA model for generation. This hybrid approach allows the model to ground its responses in actual regulatory text while maintaining the generative capabilities of the language model. The fine-tuning process adapts both the retrieval and generation components to the hazardous materials domain.

## Open Questions the Paper Calls Out
- How do RAG-augmented models perform with real-time regulatory updates versus static document corpora?
- What is the optimal balance between retrieval scope and computational efficiency in domain-specific applications?
- Can the qualitative rating methodology be standardized to reduce subjective interpretation variability?
- How do these models generalize to other transportation safety domains with different regulatory structures?

## Limitations
- Qualitative rating methodology introduces subjective interpretation variability
- Sample size of 100 queries may not capture full complexity of hazardous materials scenarios
- Semantic similarity metrics cannot fully capture semantic correctness or regulatory accuracy
- Limited testing across diverse regulatory domains beyond hazardous materials transportation
- Potential bias in query construction from the selected 40 regulatory documents

## Confidence
- High confidence: RAG-LLaMA models demonstrated superior performance in quantitative metrics
- Medium confidence: Qualitative rating comparisons between models
- Medium confidence: Semantic similarity consistency findings

## Next Checks
1. Expand evaluation to include adversarial and edge-case regulatory queries to test model robustness
2. Conduct blind evaluation with domain experts to validate qualitative rating reliability
3. Test model performance across multiple transportation safety domains (e.g., passenger rail, maritime) to assess generalizability