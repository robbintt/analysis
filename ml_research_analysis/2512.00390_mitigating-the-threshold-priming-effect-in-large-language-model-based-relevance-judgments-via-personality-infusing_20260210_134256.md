---
ver: rpa2
title: Mitigating the Threshold Priming Effect in Large Language Model-Based Relevance
  Judgments via Personality Infusing
arxiv_id: '2512.00390'
source_url: https://arxiv.org/abs/2512.00390
tags:
- personality
- relevance
- priming
- llms
- biases
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates threshold priming in LLM-based relevance
  judgments and proposes personality-infused prompting as a mitigation strategy. By
  simulating Big Five personality traits in multiple LLMs using TREC datasets, the
  authors find that specific personalities consistently reduce priming effects: Low
  Conscientiousness (LC), Low Neuroticism (LN), and High Openness (HO) are most effective.'
---

# Mitigating the Threshold Priming Effect in Large Language Model-Based Relevance Judgments via Personality Infusing

## Quick Facts
- **arXiv ID**: 2512.00390
- **Source URL**: https://arxiv.org/abs/2512.00390
- **Reference count**: 40
- **Primary result**: Personality-infused prompting significantly reduces threshold priming in LLM-based relevance judgments, with optimal profiles varying by model and task type.

## Executive Summary
This paper investigates threshold priming in LLM-based relevance judgments and proposes personality-infused prompting as a mitigation strategy. By simulating Big Five personality traits in multiple LLMs using TREC datasets, the authors find that specific personalities consistently reduce priming effects: Low Conscientiousness (LC), Low Neuroticism (LN), and High Openness (HO) are most effective. The optimal personality profile varies by model and task type, with HO excelling in exploration and exploitation tasks, while LN performs better in known-item tasks. Results show personality conditioning significantly improves judgment stability, with some personalities achieving 6-8/8 improvements over default settings across different experimental configurations.

## Method Summary
The method uses Big Five personality simulation to mitigate threshold priming in LLM-based relevance assessment. Personality instructions are generated iteratively using an LLM, creating 10 profiles (High/Low for each trait). Document batches are constructed with prologues at different quality thresholds (low/high) and identical epilogues. The priming effect is quantified as the absolute difference in mean relevance scores between high-threshold and low-threshold conditions. The approach is tested across three models (GPT-3.5-turbo, LLaMA-3-8B, LLaMA-3-70B) using TREC Deep Learning Track data, with queries classified into known-item, exploitation, and exploration types.

## Key Results
- Personality-infused prompting significantly reduces threshold priming effects in LLM-based relevance judgments
- Low Conscientiousness (LC), Low Neuroticism (LN), and High Openness (HO) consistently outperform default settings
- Optimal personality profiles vary by model: GPT-3.5-turbo responds best to LN/HC, while LLaMA-3-70B responds best to HA/LC/HO
- Task-specific alignment shows HO excelling in exploration/exploitation tasks and LN performing better in known-item tasks

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Personality conditioning reduces the LLM's sensitivity to contextual threshold priming during batched relevance assessments.
- **Mechanism:** Simulated personality traits (particularly High Openness, Low Neuroticism, Low Conscientiousness) alter the attentional and decision-making patterns in LLM outputs, reducing how much prior document quality influences subsequent relevance scores. High Openness promotes cognitive flexibility that resists anchoring; Low Neuroticism reduces emotional reactivity to contextual shifts; Low Conscientiousness decreases rigid adherence to patterns.
- **Core assumption:** LLMs trained on human-generated text have internalized associations between personality traits and cognitive processing styles that mirror human psychology.
- **Evidence anchors:**
  - [abstract] "Our results show that certain profiles, such as High Openness and Low Neuroticism, consistently reduce priming susceptibility."
  - [Section 5.1] "LC, LN, and HO consistently promote more stable and flexible decision-making, reducing over-adjustment to low-quality context and producing more consistent relevance judgments."
  - [corpus] Related work on personality steering in LLMs (arXiv:2601.05302, arXiv:2502.17669) shows personality conditioning can influence cooperative behavior and syntactic priming, though corpus evidence for this specific mechanism in relevance judgment is limited.

### Mechanism 2
- **Claim:** The optimal personality profile for priming mitigation depends on task type, with High Openness excelling in exploration/exploitation tasks and Low Neuroticism in known-item tasks.
- **Mechanism:** Different search tasks require different cognitive orientations. Exploration tasks benefit from curiosity-driven, flexible evaluation (High Openness). Known-item tasks benefit from stable, emotionally consistent judgment (Low Neuroticism). The personality-trait conditioning aligns the LLM's "cognitive orientation" with task demands, reducing unnecessary sensitivity to contextual thresholds.
- **Core assumption:** Search task types have distinct cognitive demand profiles that differentially benefit from specific personality-driven judgment styles.
- **Evidence anchors:**
  - [abstract] "HO excelling in exploration and exploitation tasks, while LN performs better in known-item tasks."
  - [Section 5.2.1] "For gpt-3.5-turbo, LN (6/8) and LO (5/8) perform best, suggesting that emotional stability and preference for established information yield the most reliable results for factual retrieval."
  - [Section 5.2.2] "HN improves gpt-3.5-turbo in 7/8 cases and llama-3-8b in all 8, while HO excels especially on llama-3-70b (7/8)."
  - [corpus] No direct corpus support for task-specific personality-task alignment in IR; this is an exploratory finding from the current paper.

### Mechanism 3
- **Claim:** Personality simulation effectiveness varies by model architecture and training, requiring model-specific personality profile selection.
- **Mechanism:** Different LLMs have different prior associations between personality keywords and behavioral patterns based on their training data and fine-tuning. GPT-3.5-turbo responds best to LN and HC; LLaMA-3-70b responds best to HA, LC, and HO. The same personality prompt activates different behavioral patterns across models.
- **Core assumption:** The personality prompts trigger model-specific learned associations rather than universal personality expressions.
- **Evidence anchors:**
  - [abstract] "The optimal personality profile varies by model and task type."
  - [Section 5.1] "For gpt-3.5-turbo, LN and HC are most effective... For llama-3-70b, HA, LC, and HO outperform the default in all eight configurations... For llama-3-8b, HA and HN also achieve 8/8 improvements."
  - [corpus] Corpus provides weak direct evidence; arXiv:2601.05302 shows personality effects in LLM agents, but doesn't address model-specific variations.

## Foundational Learning

- **Concept: Threshold Priming Effect in Sequential Judgment**
  - **Why needed here:** The paper's core problem is that batched relevance assessments create context-dependent bias: prior document quality becomes an unconscious reference threshold that skews subsequent judgments. Understanding this is essential to grasping what personality conditioning tries to solve.
  - **Quick check question:** If an assessor sees three highly relevant documents first, then judges a moderately relevant document, would they rate it higher or lower than if they had seen three irrelevant documents first? (Answer: Lower—the high threshold primes them to be more critical.)

- **Concept: Big Five Personality Model and Cognitive Processing**
  - **Why needed here:** The intervention uses Big Five traits as the vocabulary for conditioning. You need to understand what each trait represents cognitively: Openness = cognitive flexibility/novelty-seeking; Neuroticism = emotional reactivity/threat-sensitivity; Conscientiousness = systematic/rule-following; etc.
  - **Quick check question:** Which Big Five trait would you expect to reduce anchoring bias by promoting flexible reconsideration of evidence? (Answer: High Openness, associated with cognitive flexibility and openness to new information.)

- **Concept: LLM as Judge and Evaluation Alignment**
  - **Why needed here:** This work sits in the broader context of using LLMs as automated evaluators. The paper doesn't address whether personality conditioning improves accuracy vs. human judgments—only whether it reduces context-dependent instability. This distinction matters for practical deployment.
  - **Quick check question:** If personality conditioning reduces priming but also systematically shifts all relevance scores down by 0.5 points, would this be a successful intervention according to the paper's stated goals? (Answer: Yes, the paper measures priming reduction via Δ stability, not accuracy alignment with ground truth. Limitation acknowledged in Section 6.)

## Architecture Onboarding

- **Component map:** Personality Instruction Generator -> Batch Assessment Pipeline -> Priming Effect Quantifier -> Task Type Classifier

- **Critical path:**
  1. Generate 10 personality prompts (High/Low for each Big Five trait) using the two-step keyword-then-instruction method.
  2. For each topic, sample epilogue documents (fixed set) and create LT/HT batches with different prologues.
  3. Run batched relevance assessment with each personality prompt + default.
  4. Compute Δ for each personality configuration; count how many of the 8 experimental configurations show Δ reduction vs. default.
  5. Stratify results by model and task type to identify optimal profiles.

- **Design tradeoffs:**
  - **Prompt-generation LLM choice**: Paper uses GPT-4o-mini to generate personality instructions. A different model might produce different trait keyword associations. Assumption: The instruction-generation LLM's understanding of personality aligns with the assessment LLM's interpretation.
  - **Batch length variations**: Paper tests PL/EL combinations (4/4, 4/8, 8/4, 8/8). Longer prologues may create stronger priming but also more realistic assessment scenarios. Trade-off between detecting priming and ecological validity.
  - **Exclusion criteria**: Topics with <12 passages at any relevance level excluded. This limits generalizability to sparse judgment scenarios.

- **Failure signatures:**
  - **Δ increases vs. default**: Personality conditioning amplifies priming rather than reducing it (seen in some HA/LA configurations for GPT-3.5-turbo in Table 1).
  - **High variance across trials**: Even with same personality, Δ varies substantially across 10 trials → personality prompt not producing stable behavioral pattern.
  - **Task-type mismatch**: Using HO for known-item tasks on GPT-3.5-turbo shows 0/8 improvement (Table 2) → wrong personality-task pairing.
  - **Model-specific failure**: Profile that works for LLaMA-3-70B (HA: 8/8) may fail for GPT-3.5-turbo (HA: 0/8).

- **First 3 experiments:**
  1. **Baseline validation**: Replicate the default (no personality) threshold priming effect on 5 topics from TRDL22. Confirm Δ > 0 and direction matches prior work (low prologue → higher epilogue scores). Expected: Clear priming effect present.
  2. **Single-personality test**: Apply High Openness conditioning to same 5 topics across both batch configurations. Compare Δ reduction rate vs. default. Expected: 4-6/8 configurations show improvement, consistent with paper's aggregate findings.
  3. **Model transfer check**: Take the optimal personality profile for LLaMA-3-70B (HA, LC, HO) and apply to a different model not in the paper (e.g., Mistral-7B). Test whether improvements transfer or whether model-specific calibration is required. Expected: Uncertain—this tests the model-specificity claim.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does personality conditioning trade-off judgment stability for absolute prediction accuracy?
- **Basis in paper:** [explicit] The authors explicitly state, "A key limitation is that we do not address the prediction accuracy of LLM-based relevance judgments."
- **Why unresolved:** The study focused solely on measuring the reduction of the priming effect ($\Delta$) rather than verifying if the resulting labels aligned closer with ground truth.
- **What evidence would resolve it:** A comparative analysis of agreement scores (e.g., Cohen's Kappa) between personality-infused judgments and human labels versus the default baseline.

### Open Question 2
- **Question:** Can a universal, model-agnostic personality profile be derived for threshold priming mitigation?
- **Basis in paper:** [inferred] Tables 1 and 2 show that optimal profiles vary significantly; for example, High Neuroticism helps Llama-3-8b in Exploration tasks but hinders GPT-3.5-turbo.
- **Why unresolved:** The variance suggests that different model architectures may interpret or "simulate" personality instructions differently, preventing a one-size-fits-all solution.
- **What evidence would resolve it:** A large-scale benchmark across diverse model families identifying a profile that yields statistically significant priming reduction in all of them.

### Open Question 3
- **Question:** Does combining personality infusion with continual pre-training offer superior mitigation compared to prompting alone?
- **Basis in paper:** [explicit] The authors propose to "explore combining personality conditioning with techniques such as continual pre-training" in future work.
- **Why unresolved:** It is currently unknown if the transient effects of prompting are sufficient or if embedding these traits into the model weights provides more robust resistance to cognitive biases.
- **What evidence would resolve it:** Experiments comparing prompted LLMs against personality-fine-tuned LLMs on the same threshold priming tasks.

## Limitations
- The study does not address prediction accuracy of LLM-based relevance judgments versus human judgments
- Personality effectiveness varies substantially across different model architectures, requiring model-specific calibration
- Task-type alignment findings lack strong corpus validation and remain exploratory

## Confidence
- **High Confidence**: Threshold priming exists in LLM batched assessments (mechanism and measurement validated)
- **Medium Confidence**: Personality conditioning reduces priming effects (consistent across models but magnitude varies)
- **Low Confidence**: Task-specific personality optimization (limited corpus support, exploratory finding)

## Next Checks
1. Test whether personality profiles transfer across models: Apply LLaMA-3-70B's optimal personalities (HA, LC, HO) to Mistral-7B to validate model-specificity claims
2. Validate task classification reliability: Manually verify GPT-4o-mini's query categorization against human judgment for 20 randomly selected queries
3. Measure accuracy impact: Compare personality-conditioned judgments against human relevance assessments to determine if priming reduction comes at accuracy cost