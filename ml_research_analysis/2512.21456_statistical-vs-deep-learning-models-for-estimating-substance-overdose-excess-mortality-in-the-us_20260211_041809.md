---
ver: rpa2
title: Statistical vs. Deep Learning Models for Estimating Substance Overdose Excess
  Mortality in the US
arxiv_id: '2512.21456'
source_url: https://arxiv.org/abs/2512.21456
tags:
- mortality
- lstm
- data
- validation
- projection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study compares traditional statistical methods with deep
  learning models for estimating substance overdose excess mortality during the COVID-19
  pandemic in the United States. Using national CDC data (2015-2019 for training/validation,
  2020-2023 for projection), the authors evaluate SARIMA against three deep learning
  architectures: LSTM, Seq2Seq, and Transformer.'
---

# Statistical vs. Deep Learning Models for Estimating Substance Overdose Excess Mortality in the US

## Quick Facts
- arXiv ID: 2512.21456
- Source URL: https://arxiv.org/abs/2512.21456
- Reference count: 40
- Primary result: LSTM outperforms SARIMA with 17.08% MAPE versus 23.88% MAPE for overdose mortality prediction

## Executive Summary
This study systematically compares traditional statistical methods (SARIMA) against deep learning architectures (LSTM, Seq2Seq, Transformer) for estimating substance overdose excess mortality in the United States during the COVID-19 pandemic. Using national CDC data from 2015-2019 for training and 2020-2023 for validation, the research establishes that carefully validated deep learning models can provide more reliable counterfactual estimates than traditional statistical approaches. The LSTM model demonstrates superior predictive performance and better-calibrated uncertainty quantification, making it particularly suitable for public health planning applications where accurate mortality estimates are critical for resource allocation and intervention strategies.

## Method Summary
The authors develop a counterfactual framework to estimate excess overdose mortality by comparing observed deaths against model-predicted baseline trends. The methodology employs three modeling approaches: statistical SARIMA for time series decomposition, LSTM for sequential pattern learning, and attention-based models (Seq2Seq, Transformer) for capturing complex temporal dependencies. Models are trained on pre-pandemic data (2015-2019) and validated against actual 2020-2023 mortality data, with performance evaluated using MAPE and prediction interval coverage metrics. The study emphasizes reproducibility through an open-source pipeline designed for deployment with state health departments, enabling broader public health applications.

## Key Results
- LSTM achieves 17.08% MAPE compared to SARIMA's 23.88% MAPE
- LSTM provides better-calibrated uncertainty with 68.8% prediction interval coverage versus SARIMA's 47.9%
- Attention-based models (Seq2Seq, Transformer) underperform due to overfitting to historical means rather than capturing emergent pandemic trends

## Why This Works (Mechanism)
The LSTM model's superior performance stems from its ability to capture non-linear temporal dependencies and adapt to the unprecedented mortality patterns observed during the COVID-19 pandemic. Unlike traditional statistical methods that rely on seasonal decomposition and linear assumptions, LSTM networks can learn complex sequential relationships and emergent trends through their recurrent architecture. The study demonstrates that attention-based models fail to generalize because they become overly sensitive to historical patterns, treating the pandemic period as anomalous noise rather than learning to adapt to regime shifts. This highlights the importance of model architecture selection and validation in high-stakes public health applications where traditional assumptions about stationarity may not hold.

## Foundational Learning

**Time Series Forecasting**: Understanding sequential dependencies in mortality data; why needed for modeling overdose trends; quick check: can decompose seasonal patterns

**Counterfactual Estimation**: Framework for comparing observed versus predicted mortality; why needed for excess death calculation; quick check: defines baseline against which to measure excess

**Model Calibration**: Techniques for ensuring predicted uncertainty matches actual uncertainty; why needed for reliable public health decision-making; quick check: prediction intervals achieve nominal coverage

**Deep Learning Validation**: Methods for preventing overfitting in high-stakes domains; why needed when model errors have real-world consequences; quick check: performance generalizes to unseen pandemic period

## Architecture Onboarding

**Component Map**: CDC mortality data -> preprocessing pipeline -> model training (SARIMA, LSTM, Seq2Seq, Transformer) -> validation on 2020-2023 data -> performance evaluation

**Critical Path**: Data preparation -> model selection and training -> hyperparameter tuning -> validation -> uncertainty quantification -> deployment pipeline

**Design Tradeoffs**: Statistical methods offer interpretability but limited adaptability versus deep learning's flexibility but reduced transparency; attention mechanisms provide interpretability but risk overfitting

**Failure Signatures**: Overfitting to historical means, poor calibration of uncertainty intervals, failure to capture regime shifts during pandemic

**First Experiments**: 
1. Compare LSTM performance on state-level versus national data
2. Test calibration techniques on existing model outputs
3. Implement ensemble methods combining statistical and deep learning approaches

## Open Questions the Paper Calls Out
None

## Limitations
- Analysis focuses exclusively on US data during pandemic period, limiting external validity
- Attention-based models' underperformance may reflect architecture choices rather than fundamental limitations
- Counterfactual framework assumes stationarity in pre-pandemic trends that may not hold for evolving substance use patterns

## Confidence
High confidence in LSTM model's superior predictive performance (MAPE of 17.08% vs 23.88% for SARIMA)
High confidence in methodological framework and open-source implementation
Medium confidence in claims about deep learning superiority across all contexts

## Next Checks
1. Test the LSTM model on state-level data to assess performance across diverse demographic and geographic contexts
2. Implement calibration techniques (temperature scaling, isotonic regression) to further improve uncertainty quantification
3. Compare performance using alternative baseline methods (Prophet, TBATS) to strengthen relative advantage claims