---
ver: rpa2
title: 'FedGreed: A Byzantine-Robust Loss-Based Aggregation Method for Federated Learning'
arxiv_id: '2508.18060'
source_url: https://arxiv.org/abs/2508.18060
tags:
- clients
- client
- adversarial
- server
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FedGreed is a Byzantine-robust federated learning method that uses
  a server-side trusted dataset to evaluate and select clients' model updates based
  on their loss values. It employs a greedy selection strategy to aggregate updates
  from clients whose models exhibit the lowest evaluation loss, without requiring
  assumptions about the number of malicious clients.
---

# FedGreed: A Byzantine-Robust Loss-Based Aggregation Method for Federated Learning

## Quick Facts
- arXiv ID: 2508.18060
- Source URL: https://arxiv.org/abs/2508.18060
- Authors: Emmanouil Kritharakis; Antonios Makris; Dusan Jakovetic; Konstantinos Tserpes
- Reference count: 25
- Primary result: FedGreed outperforms standard and robust baselines under non-IID data distributions and adversarial attacks, maintaining high accuracy with up to 80% malicious clients.

## Executive Summary
FedGreed introduces a novel Byzantine-robust federated learning method that leverages a trusted server-side dataset to evaluate and select client model updates based on their loss values. The method employs a greedy selection strategy to aggregate updates from clients whose models exhibit the lowest evaluation loss, without requiring assumptions about the number of malicious clients. Experimental results demonstrate significant improvements over standard and robust aggregation baselines across multiple datasets and adversarial scenarios.

## Method Summary
FedGreed operates by having the server maintain a small trusted dataset that is not shared with clients. During each round of federated learning, clients submit their model updates to the server, which then evaluates these updates using the trusted dataset. The server selects the updates with the lowest evaluation loss and aggregates them using a weighted combination, where weights are inversely proportional to the evaluation loss. This greedy selection mechanism allows FedGreed to effectively identify and exclude malicious updates, even when the number of Byzantine clients is unknown.

## Key Results
- FedGreed significantly outperforms standard aggregation methods (Mean, Trimmed Mean, Median) and robust baselines (Krum, Multi-Krum) across MNIST, FMNIST, and CIFAR-10 datasets.
- The method maintains high centralized accuracy even with up to 80% malicious clients under label flipping and Gaussian noise injection attacks.
- FedGreed demonstrates robustness to non-IID data distributions, a common challenge in real-world federated learning scenarios.

## Why This Works (Mechanism)
FedGreed's effectiveness stems from its ability to directly measure the quality of client updates using a trusted server-side dataset. By evaluating the loss of each client's update on this dataset, the server can identify updates that are likely to be malicious or of poor quality. The greedy selection strategy then ensures that only the most promising updates are aggregated, effectively filtering out Byzantine clients. This approach is particularly powerful because it does not require assumptions about the number of malicious clients or the nature of their attacks.

## Foundational Learning
- Federated Learning: Distributed machine learning paradigm where clients collaboratively train a global model without sharing raw data. Needed to understand the context and challenges of Byzantine-robust aggregation.
- Byzantine Robustness: Ability of a system to tolerate malicious or faulty participants. Quick check: Identify the types of attacks (e.g., label flipping, Gaussian noise) that FedGreed is designed to withstand.
- Non-IID Data Distributions: Real-world scenario where clients' data are not identically and independently distributed. Quick check: Verify that FedGreed's performance is tested under non-IID conditions.

## Architecture Onboarding

### Component Map
Server -> Trusted Dataset -> Client Update Evaluation -> Greedy Selection -> Weighted Aggregation

### Critical Path
1. Clients compute local model updates and send to server
2. Server evaluates each update using trusted dataset
3. Server selects updates with lowest evaluation loss
4. Server aggregates selected updates with inverse loss weighting

### Design Tradeoffs
- Reliance on trusted server-side dataset vs. distributed robustness
- Greedy selection may miss potentially useful updates with slightly higher loss
- Inverse loss weighting balances contribution of selected updates

### Failure Signatures
- Poor performance if trusted dataset is small or unrepresentative
- Vulnerability to attacks that manipulate loss values without degrading model performance
- Potential single point of failure if server or trusted dataset is compromised

### First Experiments
1. Evaluate FedGreed's performance on high-dimensional datasets (e.g., ImageNet) to assess scalability and robustness.
2. Test the method's vulnerability to adaptive attacks that manipulate loss values while maintaining model performance.
3. Investigate the impact of server-side dataset size and quality on the method's effectiveness in Byzantine-robust aggregation.

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on a trusted server-side dataset, which may not be available in all federated learning scenarios and could introduce a single point of failure if compromised.
- Untested performance in extremely high-dimensional tasks beyond CIFAR-10 (e.g., ImageNet).
- Scalability concerns with a large number of clients.

## Confidence
- High confidence in experimental results on MNIST, FMNIST, and CIFAR-10 under controlled adversarial conditions
- Medium confidence in the generalizability of results to other datasets and real-world scenarios
- Low confidence in the method's performance against advanced adaptive attacks that could manipulate loss values strategically

## Next Checks
1. Test FedGreed's performance on high-dimensional datasets (e.g., ImageNet) to assess scalability and robustness.
2. Evaluate the method's vulnerability to adaptive attacks that manipulate loss values while maintaining model performance.
3. Investigate the impact of server-side dataset size and quality on the method's effectiveness in Byzantine-robust aggregation.