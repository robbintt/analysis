---
ver: rpa2
title: 'DIAMOND: An LLM-Driven Agent for Context-Aware Baseball Highlight Summarization'
arxiv_id: '2506.02351'
source_url: https://arxiv.org/abs/2506.02351
tags:
- play
- game
- diamond
- plays
- highlight
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DIAMOND addresses the challenge of generating baseball highlights
  that balance statistical impact with narrative coherence. Traditional methods, such
  as WPA-based ranking or vision-driven detection, often miss strategic plays and
  momentum shifts, while manual curation is resource-intensive.
---

# DIAMOND: An LLM-Driven Agent for Context-Aware Baseball Highlight Summarization

## Quick Facts
- **arXiv ID:** 2506.02351
- **Source URL:** https://arxiv.org/abs/2506.02351
- **Reference count:** 11
- **Primary result:** F1-score increases from 42.9% (WPA-only) to 84.8% using LLM-driven context-aware scoring

## Executive Summary
DIAMOND is an LLM-driven agent designed to generate baseball highlight summaries that balance statistical impact with narrative coherence. Traditional methods often miss strategic plays and momentum shifts, while manual curation is resource-intensive. DIAMOND combines sabermetric features—Win Expectancy, WPA, and Leverage Index—with LLM-based contextual analysis to rank plays by both statistical and narrative importance. Evaluated on five diverse Korean Baseball Organization games, DIAMOND outperforms commercial and statistical baselines with an F1-score of 84.8%.

## Method Summary
DIAMOND employs a three-stage pipeline: (1) Preparation—compute sabermetrics and build sliding window context with up to five prior plays; (2) Decision—transform WPA to scores (1–60), apply LLM-based adjustment (+1 to +20), and correct using Leverage Index (up to +20 points for high-LI/low-WPA plays); (3) Reflection—refine based on user preferences and select top-K plays (optimal K≈60). The framework uses structured JSON prompts and evaluates against manually annotated ground-truth highlights.

## Key Results
- F1-score improves from 42.9% (WPA-only) to 84.8% (DIAMOND)
- Outperforms commercial NAVER AI baseline (F1 84.8% vs 50.2%)
- Ablation study shows each stage contributes: Preparation (0.673→0.793 F1), Decision (0.793→0.848 F1), Reflection (0.848 F1)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Combining WPA with LLM-based qualitative analysis improves highlight selection accuracy over purely statistical or commercial vision-based baselines.
- **Mechanism:** Framework calculates quantitative "base" score using WPA, then employs LLM to generate "adjustment" score based on narrative context (e.g., momentum, visual excitement), summing them to rank plays.
- **Core assumption:** LLM can reliably distinguish between "statistically significant" and "narratively significant" plays without hallucinating context when provided with structured JSON logs.
- **Evidence anchors:** Reports F1-score increase from 42.9% (WPA-only) to 84.8% on five KBO games; Table 1 shows full DIAMOND pipeline significantly outperforming WPA-based method (0.848 vs 0.673 F1).
- **Break condition:** If LLM assigns high narrative scores to objectively irrelevant plays (e.g., routine outs in blowout games), hybrid score noise degrades precision below WPA baseline.

### Mechanism 2
- **Claim:** Contextualizing plays within sliding window of prior events captures "momentum shifts" that isolated metrics miss.
- **Mechanism:** Preparation Stage feeds LLM structured input containing current play and up to five preceding plays, enabling model to reason about continuity (e.g., hit following walk) rather than evaluating events in isolation.
- **Core assumption:** Window of five plays is sufficient to establish game momentum, and LLM's attention mechanism effectively utilizes this history within context window.
- **Evidence anchors:** "We adopt sliding window approach: each play evaluated in context of up to five prior plays..."; Example input shows "previous_plays" array included in prompt.
- **Break condition:** If token limits truncate critical early-game context or LLM fails to attend to history list, "momentum" analysis reverts to single-play inference.

### Mechanism 3
- **Claim:** Rule-based "Reflection Stage" corrects systematic blind spots in WPA, specifically undervaluing high-leverage plays that do not immediately change score.
- **Mechanism:** System calculates rank difference (ΔR) between Leverage Index (LI) and WPA; plays with high LI but low WPA receive fixed heuristic point boost (up to 20 points) to ensure strategic tension is represented.
- **Core assumption:** Leverage Index is valid proxy for "strategic importance" that correlates with human highlight selection preferences better than WPA alone in specific scenarios.
- **Evidence anchors:** "Since WPA can undervalue non-scoring plays... we adjust scores based on LI... top-ranked play receives additional 20 points"; Ablation study shows removing Reflection Stage drops F1 from 0.793 to 0.765.
- **Break condition:** If game is "blowout," high LI plays may still be boring to viewers, and boosting them might lower user satisfaction despite maintaining "strategic" fidelity.

## Foundational Learning

- **Concept: Win Probability Added (WPA) & Leverage Index (LI)**
  - **Why needed here:** These are foundational numerical inputs. Without understanding that WPA measures change in win probability while LI measures potential importance, need for Reflection Stage correction is unclear.
  - **Quick check question:** If batter hits double in 10-0 game (low LI) vs. walk in tie game (high LI), which raw WPA value is likely higher, and how would DIAMOND adjust ranking?

- **Concept: Structured Prompting (JSON Context Injection)**
  - **Why needed here:** DIAMOND relies on passing structured game logs (JSON) into LLM rather than natural language descriptions. Understanding how to format "previous_plays" for model consumption is critical for Preparation Stage.
  - **Quick check question:** How does system handle "sliding window" if play occurs in first inning where < 5 prior plays exist?

- **Concept: F1-Score in Retrieval vs. Generation**
  - **Why needed here:** Paper frames summarization as retrieval (classification) task (Precision/Recall/F1) rather than text generation task.
  - **Quick check question:** Why does NAVER AI baseline have high Precision (0.818) but very low Recall (0.292), and what does this imply about its "selectivity"?

## Architecture Onboarding

- **Component map:** Input (raw game logs) → Preparation (sabermetrics Engine → Context Assembler) → Decision (LLM Scorer → Heuristic Adjuster) → Reflection (User Preference Filter → Top-K Selector) → Output (video timestamps)

- **Critical path:** Interaction between Decision Stage's LLM and LI Correction Heuristic. LLM handles "narrative" delta, but explicit math of LI boost is deterministic code. Debugging ranking errors requires isolating which of these two steps caused misranking.

- **Design tradeoffs:**
  - **Modularity vs. Latency:** Pipeline runs three distinct LLM steps (Analysis, Transformation, Adjustment). This ensures interpretability but introduces latency, making it currently suitable only for post-game processing, not real-time highlighting.
  - **Recall vs. Precision:** System optimizes for high Recall (0.886), prioritizing comprehensive coverage of key moments over strict brevity of commercial baselines.

- **Failure signatures:**
  - **"Boring" Highlights in Blowouts:** Metrics (WPA/LI) may stay low throughout blowout. LLM might "hallucinate" excitement to fulfill prompt instructions, or system selects low-quality plays just to fill quota.
  - **Context Drift:** If "5-play window" crosses pitching change or inning break, "momentum" context might be logically disconnected, leading to irrelevant narrative analysis.

- **First 3 experiments:**
  1. **Ablation Replication:** Run pipeline with only WPA-Transformation step (disable Narrative Adjustment and LI Correction) to establish baseline F1 on your data.
  2. **Sensitivity Analysis (K):** Plot F1-score against K (number of plays selected) to see if "peaking at 60" finding holds for different leagues or game styles (e.g., MLB vs. KBO).
  3. **Prompt Injection Test:** Modify "User Preferences" in Reflection Stage to force inclusion of specific play types (e.g., "only defense") and verify Top-K selector respects constraint without dropping critical offensive plays.

## Open Questions the Paper Calls Out
- **Question:** Does integration of visual and auditory signals (e.g., crowd reactions, player gestures) significantly improve highlight selection accuracy compared to text-only DIAMOND framework?
  - **Basis in paper:** Explicitly lists "Absence of multimodal signals" as limitation, noting system currently omits visual and auditory cues that capture excitement and atmosphere.
  - **Why unresolved:** Current architecture relies exclusively on structured text logs and LLM reasoning; unclear how multimodal data would be fused with existing sabermetric scoring without losing framework's interpretability.
  - **Evidence to resolve it:** Ablation studies on existing dataset that augment text-based inputs with audio/video features, measuring change in F1-score and user preference ratings.

- **Question:** Can DIAMOND be adapted for real-time, live-game summarization using lightweight LLMs without significant degradation in narrative quality or latency?
  - **Basis in paper:** "Limitations" section identifies "Real-time applicability and efficiency" as challenge, stating system is currently designed for post-game processing.
  - **Why unresolved:** Current implementation uses large model (Mistral-Large) and multi-stage pipeline (Preparation, Decision, Reflection), which may introduce latency unacceptable for live broadcast scenarios.
  - **Evidence to resolve it:** Benchmarks comparing inference speed and highlight quality (F1-score) between current model and distilled or smaller models when processed in streaming simulation.

- **Question:** How effectively does framework generalize to continuous-action sports (e.g., soccer, basketball) or other domains when replacing WPA with domain-specific metrics?
  - **Basis in paper:** While authors claim framework is "modular and domain-agnostic," experiments are strictly limited to episodic structure of baseball (KBO).
  - **Why unresolved:** Paper provides no empirical evidence that "sliding window" context approach works for sports with fluid, non-stop action where discrete "plays" are harder to define.
  - **Evidence to resolve it:** Evaluation results from applying DIAMOND to soccer or basketball dataset, substituting WPA with metrics like Expected Goals (xG) or Player Efficiency Rating (PER).

## Limitations
- **Reproducibility barrier:** Ground-truth highlight annotations for five KBO games not publicly released; only video links provided.
- **Missing components:** Specific historical win probability tables used for WPA/LI computation are referenced but not shared.
- **Real-time constraints:** Current implementation using large model and multi-stage pipeline makes real-time application impractical.

## Confidence
- **High confidence** in hybrid scoring mechanism's validity (WPA + LLM adjustment + LI correction) given significant F1 improvement (42.9% → 84.8%) and ablation study showing each component's contribution.
- **Medium confidence** in generalizability claims, as results based on only five KBO games without cross-league validation.
- **Low confidence** in real-time applicability claims, as paper explicitly acknowledges system is currently suited only for post-game processing.

## Next Checks
1. **Ground-truth replication test:** Contact authors for access to manual highlight annotations or implement consensus annotation protocol across three independent annotators on provided KBO games.

2. **Cross-league generalization:** Apply pipeline to MLB game data using publicly available Retrosheet logs and compare F1-scores against KBO results to test generalizability.

3. **Commercial baseline replication:** Implement simplified vision-based highlight system using optical tracking data or player detection to create reproducible baseline for direct comparison with NAVER AI results.