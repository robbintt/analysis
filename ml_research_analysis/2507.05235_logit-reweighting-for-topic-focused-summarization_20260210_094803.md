---
ver: rpa2
title: Logit Reweighting for Topic-Focused Summarization
arxiv_id: '2507.05235'
source_url: https://arxiv.org/abs/2507.05235
tags:
- summary
- topical
- scores
- quality
- topic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generating topic-focused
  summaries from language models without resource-intensive fine-tuning. The authors
  propose a lightweight method that directly reweights the logits of topic-relevant
  tokens during generation, enabling control over topical content while preserving
  summary quality.
---

# Logit Reweighting for Topic-Focused Summarization

## Quick Facts
- arXiv ID: 2507.05235
- Source URL: https://arxiv.org/abs/2507.05235
- Reference count: 8
- Primary result: Lightweight logit reweighting methods enable topic-focused summarization without fine-tuning

## Executive Summary
This paper presents a practical approach for controlling topical content in language model-generated summaries without resource-intensive fine-tuning. The authors propose three logit reweighting techniques - Constant Shift, Factor Scaling, and Threshold Selection - that modify token selection probabilities during inference. Experiments on the NEWTS dataset using Gemma-2B and Llama-3-8B models demonstrate that these methods effectively increase topical vocabulary usage while maintaining summary quality. The Threshold Selection method particularly excels at balancing topical focus with fluency, offering a resource-efficient alternative to fine-tuning for applications requiring thematic control over generated text.

## Method Summary
The method implements three logit reweighting techniques as custom Hugging Face LogitsProcessors that intercept and modify the model's output logits during generation. Constant Shift adds a fixed value to topic-relevant token logits, Factor Scaling multiplies them by a scaling factor (requiring careful tuning based on model-specific logit sign distributions), and Threshold Selection boosts logits that exceed a probability threshold. Topic-relevant tokens are identified using an external LDA model (top 25 words per topic) and mapped to multiple token variants through lemmatization, stemming, and case variation. The intervention occurs before nucleus sampling, allowing controlled generation without modifying model weights.

## Key Results
- Threshold Selection method achieves superior balance between topical focus and summary quality
- Logit reweighting increases topical vocabulary usage by 10-15% compared to baseline
- Method preserves ROUGE-L scores while improving topic-specific metrics
- Factor Scaling requires careful tuning due to model-dependent logit sign distributions

## Why This Works (Mechanism)

### Mechanism 1: Selective Probability Amplification (Threshold Selection)
If topic-relevant tokens are boosted only when they already have baseline probability above threshold θ, topical focus increases without degrading fluency. This "soft gate" amplifies tokens the model already considers plausible rather than forcing unlikely vocabulary. Core assumption: the model has sufficient intrinsic knowledge to associate topic words with source text; bottleneck is sampling probability, not capability. Evidence: Threshold Selection reliably increases topic scores without impacting summary quality when θ is properly tuned.

### Mechanism 2: Context-Agnostic Bias Injection (Constant Shift)
Adding constant value c to topic token logits creates uniform bias that increases selection likelihood but requires careful tuning to avoid coherence loss. This directly alters logit vector before softmax, simulating prior preference for topic. Core assumption: summary generation is robust enough to integrate injected tokens without fracturing structure. Evidence: If shift constant exceeds 10, summaries become lists of topic words, severely compromising quality.

### Mechanism 3: Distribution-Dependent Scaling (Factor Scaling)
Multiplying logits by factor α is effective only if sign of logits is known (model-dependent), making it fragile for cross-model deployment. Scaling changes "steepness" of probability distribution, but sign dependency means same factor can suppress or enhance probability depending on model. Core assumption: engineer knows sign of logit distribution for specific model. Evidence: For Gemma (negative logits), scaling factors below 1 increased logits; for Llama (positive logits), factors greater than 1 increased logits.

## Foundational Learning

- **Softmax and the Logit Space**
  - Why needed: Paper manipulates "logits" (unnormalized scores) rather than probabilities; understanding logits → softmax → probabilities is essential to grasp why adding constant vs multiplying has different effects
  - Quick check: If model outputs negative logits, does multiplying by 2 make associated token more or less likely to be sampled?

- **LDA (Latent Dirichlet Allocation)**
  - Why needed: Method relies on predefined list of "topic-relevant tokens" identified using LDA to define topics (top 25 words)
  - Quick check: How does system handle mismatch between LDA "words" and LLM "tokens" (subwords)?

- **Nucleus Sampling (Top-p)**
  - Why needed: Paper intervenes during decoding; understanding that LogitsProcessor modifies candidate pool before nucleus sampling filter clarifies why method controls generation without changing model weights
  - Quick check: Does logit reweighting happen before or after model calculates initial probabilities for next token?

## Architecture Onboarding

- **Component map:** Input: Source Text + Topic ID → Topic Resolver: LDA Model → Top 25 Words → Lemmatizer/Stemmer → Token Variants (3-5 per word) → LogitsProcessor: Custom class intercepts output vector → Logic: Applies one of three transformations (Shift, Scale, Threshold) to indices corresponding to Token Variants → Generator: Standard autoregressive loop (Beam Search or Greedy)

- **Critical path:** Token Variant Generator is most brittle component. If LDA topic word is "running" but tokenizer splits it into "run" and "ning," or if model expects "run," naive match fails. Paper explicitly generates capitalization and lemmatization variations to ensure intervention hits right indices in logit vector.

- **Design tradeoffs:**
  - Threshold Selection vs. Constant Shift: Threshold Selection is more robust across models (probability space normalized 0-1), while Constant Shift requires tuning based on logit magnitude (varies by model size/architecture)
  - Prompt Engineering vs. Logit Reweighting: Prompting creates "instruction-following" overhead (reiterating instructions) and uses context window; logit reweighting is invisible to context but requires code access to inference

- **Failure signatures:**
  - Mode Collapse (Fluency Loss): Output is repetitive list of keywords (occurs if Constant Shift > 10)
  - Instruction Echoing: Model outputs "Here is a summary focused on [topic]..." (occurs with prompt engineering, avoided by logit methods)
  - Negative Suppression: Topic scores drop (occurs if Factor Scaling direction is wrong for logit sign)

- **First 3 experiments:**
  1. Validation of Token Mapping: Run single instance with Constant Shift (+10). If output is gibberish keywords, token mapping working but value too high. If nothing changes, token mapping is broken.
  2. Threshold Sweep (Gemma-2B): Replicate Threshold Selection experiment (Fig 11). Sweep θ from 0.1 to 0.001. Verify that Topic Score rises while ROUGE-L remains flat.
  3. Baseline Comparison: Compare standard prompt ("Summarize focusing on [words]") against Threshold Selection on 10 examples. Check for "Instruction Echoing" in prompted version.

## Open Questions the Paper Calls Out

- Can dynamic intervention schedules based on grammatical context improve efficiency of topical control? The authors propose adapting intervention strength dynamically, noting that bias is unnecessary for function words but beneficial for content words. This remains unresolved as current Threshold Selection uses static probability cutoff.

- How does logit reweighting compare to intermediate activation steering for controlling topical content? The authors identify activation steering as promising alternative approach to control text properties, though its efficacy for free-form generation is largely untested.

- Does effectiveness of logit reweighting generalize to significantly larger models or non-instruction-tuned base models? The authors note results were obtained only on Gemma-2B and Llama-3-8B instruction-tuned models, and behavior may differ for larger or base models.

## Limitations

- Parameter sensitivity and model dependence: Effectiveness shows significant dependence on model-specific characteristics, with Factor Scaling requiring different scaling factors for models with different logit sign distributions
- Token mapping reliability: Approach depends on accurately mapping LDA topic words to model token IDs, with unclear reliability across diverse vocabulary and morphological variations
- Evaluation scope: Uses automated metrics but lacks human evaluation to assess practical utility of generated summaries for their intended purpose

## Confidence

**High Confidence:**
- Logit reweighting methods can increase topical vocabulary usage in generated summaries
- Threshold Selection outperforms other methods in balancing topical focus and summary quality
- Method provides practical alternative to fine-tuning for controlling topical content

**Medium Confidence:**
- Threshold Selection is more robust across models than other approaches
- Method preserves summary quality while improving topical focus
- Factor Scaling effectiveness depends on logit sign distributions

**Low-Medium Confidence:**
- Method's generalizability across different model architectures without extensive tuning
- Reliability of token mapping across diverse vocabulary and morphological variations
- Practical utility of generated summaries for their intended use case

## Next Checks

1. **Cross-Model Parameter Transferability Test:** Implement Threshold Selection on two different model architectures (Gemma-2B and Llama-3-8B) using identical parameter settings (θ = 0.005, β = 2.0). Measure performance degradation when transferring parameters versus tuning per model to quantify parameter sensitivity.

2. **Edge Case Token Mapping Validation:** Systematically test token mapping approach on topic words with complex morphology (plural forms, verb conjugations, compound words). Verify all generated token variations successfully map to valid token IDs and measure false negative rate where topic-relevant tokens fail to be boosted due to mapping failures.

3. **Human Evaluation of Practical Utility:** Conduct user study where participants evaluate topic-focused summaries against standard summaries for usefulness in understanding specific aspects of source documents. Compare subjective ratings of coherence, informativeness, and topical relevance between logit-reweighted and standard summaries.