---
ver: rpa2
title: 'PROPER: A Progressive Learning Framework for Personalized Large Language Models
  with Group-Level Adaptation'
arxiv_id: '2503.01303'
source_url: https://arxiv.org/abs/2503.01303
tags:
- user
- proper
- group-level
- adaptation
- stage
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of personalizing large language
  models (LLMs) to individual user preferences while dealing with data sparsity. The
  proposed method, PROPER, introduces a progressive learning framework that bridges
  population-level and user-level models by incorporating a group-level adaptation
  stage.
---

# PROPER: A Progressive Learning Framework for Personalized Large Language Models with Group-Level Adaptation

## Quick Facts
- arXiv ID: 2503.01303
- Source URL: https://arxiv.org/abs/2503.01303
- Reference count: 20
- Primary result: Progressive three-stage learning (population → group → user) achieves 4.69-5.02% relative improvement over end-to-end training on LaMP benchmark

## Executive Summary
PROPER addresses LLM personalization for users with sparse data by introducing a three-stage progressive learning framework. The method learns population-level preferences first, then group-level patterns via MoE experts, and finally individual user preferences. This hierarchical decomposition allows PROPER to effectively personalize LLMs even for users with minimal interaction history by leveraging shared group knowledge while maintaining individual specificity.

## Method Summary
PROPER employs a three-stage progressive learning approach: (1) Train population-level LoRA on all task data, (2) Learn group-level LoRA experts using user-aware routing and constraint loss, and (3) Adapt user-specific LoRAs with LoRA-aware routing. The framework uses a Mixture-of-Experts structure combined with Low-Rank Adaptation to enable efficient personalization across diverse user preferences while maintaining computational efficiency through parameter-efficient fine-tuning.

## Key Results
- PROPER achieves state-of-the-art performance across multiple LaMP tasks, outperforming baselines by 4.69-5.02% relative improvement
- Progressive learning shows consistent improvements over end-to-end training (Stage 1→2: 4.69%, Stage 2→3: 5.02%)
- Constraint loss effectively prevents expert collapse, with k=5 experts identified as optimal through ablation studies
- LoRA-aware router provides 2-3% relative improvement by dynamically blending group and user knowledge

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Residual Decomposition
PROPER treats personalization as progressive residual refinement, where group-level preferences are learned as residual shifts from population-level, and user-level as residuals beyond group-level. This decomposes sparse learning into three denser sub-problems: population preferences, group patterns, and individual residuals.

### Mechanism 2: Constraint-Enforced Expert Diversification
The constraint loss forces distinct users toward different expert combinations, preventing expert collapse and ensuring meaningful group differentiation. Instead of uniform expert selection, it maximizes dissimilarity between router weight distributions across users.

### Mechanism 3: LoRA-Aware Router for Cross-Level Integration
The LoRA-aware router enables dynamic blending of group and user knowledge by routing based on user-LoRA hidden states. This allows the model to select relevant group knowledge conditioned on what the user-LoRA already captures.

## Foundational Learning

- **Low-Rank Adaptation (LoRA)**: Why needed: All three stages use LoRA for parameter-efficient adaptation. Quick check: Can you explain why LoRA's low-rank assumption enables training separate parameters per user without exploding memory?
- **Mixture-of-Experts (MoE) Routing**: Why needed: Stage 2 uses LoRAMoE where each expert is a group-level LoRA. Quick check: How does sparse MoE routing differ from ensemble averaging, and what problem does load balancing address?
- **Progressive/curriculum learning**: Why needed: PROPER's three-stage training freezes earlier stages rather than end-to-end joint training. Quick check: Why might freezing population-level LoRA before training group-level be better than joint training, especially when user data is sparse?

## Architecture Onboarding

- **Component map**: Stage 1: Backbone LLM + Population LoRA (Ωp) → merged into Wp → Stage 2: Wp (frozen) + k Group LoRA experts + User-aware router + Constraint loss → Stage 3: Wg (frozen) + User-specific LoRA + LoRA-aware router
- **Critical path**: 1) Train population LoRA on all task data → merge to backbone 2) Initialize k group experts + user embeddings → train with constraint loss 3) Freeze group experts → train individual user LoRAs with LoRA-aware router 4) At inference, route input through user-LoRA → compute router weights → blend group + user outputs
- **Design tradeoffs**: Expert count k=5 optimal (k=2 underfits, k=8 overfits); LoRA rank: population r=8, group/user r=4; End-to-end vs. progressive: progressive shows 2-3% relative improvement
- **Failure signatures**: Experts show highly overlapping weight distributions → constraint loss not working or k too large; Stage 3 underperforms Stage 2 significantly → user data too sparse; Large gap between train and test user performance → overfitting
- **First 3 experiments**: 1) Reproduce progressive vs. end-to-end ablation 2) Vary expert count (k=2,5,8) on single task 3) Low-resource user test: select bottom 100 users by history length

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the framework be extended to handle dynamic user preferences that evolve over time within a continual learning paradigm?
- Basis: The authors state PROPER assumes static user preferences and suggest future research on dynamically modeling these preferences
- Why unresolved: Current progressive stages are static and don't update group assignments or user LoRAs based on new data streams
- What evidence would resolve it: Evaluation on temporal dataset where user preferences shift, demonstrating updates without catastrophic forgetting

### Open Question 2
- Question: How does group-level adaptation performance change in multi-task learning settings across different domains?
- Basis: Authors note current evaluation separates tasks but suggest considering LLM personalization within multi-task learning framework
- Why unresolved: Unclear if single set of group-level experts can capture preferences across diverse tasks or if task-specific experts are required
- What evidence would resolve it: Experiments on multi-task benchmark analyzing shared vs. task-specific group experts

### Open Question 3
- Question: Can the optimal number of group experts (k) be determined automatically or adaptively based on user population complexity?
- Basis: Appendix A.4 analyzes expert count but relies on manual grid search, implying pre-defined hyperparameters
- Why unresolved: Fixed k may be insufficient for diverse datasets; lacks mechanism to detect when more/fewer groups are needed
- What evidence would resolve it: Method that dynamically adjusts k or theoretical bound predicting optimal k without expensive tuning

## Limitations
- Data representation bias: LaMP benchmark may not capture rare preference patterns or cross-cultural variations
- Hyperparameter sensitivity: Performance could be sensitive to expert count, LoRA rank, and constraint loss weight
- Scalability concerns: Three-stage progressive training increases complexity, potentially prohibitive for very large user bases

## Confidence
- **High Confidence**: Hierarchical decomposition mechanism works as described; constraint loss prevents expert collapse; LoRA-aware router provides measurable benefit
- **Medium Confidence**: k=5 experts optimal for all tasks; generalization beyond LaMP benchmark; performance claims relative to baselines
- **Low Confidence**: Long-term stability of learned preferences; behavior with significantly sparser users; transferability to non-conversational tasks

## Next Checks
1. **Ablation on user embedding dimension**: Vary d from 32 to 256 to verify d=128 is optimal and not overfit to benchmark
2. **Cross-domain transfer test**: Train PROPER on LaMP-1 then evaluate on different personalization task to test generalization
3. **Stress test with minimal data**: Select users with <10 interactions and compare PROPER vs. OPPU vs. direct user LoRA training to quantify benefits for extreme sparse cases