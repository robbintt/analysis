---
ver: rpa2
title: 'ECG-EmotionNet: Nested Mixture of Expert (NMoE) Adaptation of ECG-Foundation
  Model for Driver Emotion Recognition'
arxiv_id: '2503.01750'
source_url: https://arxiv.org/abs/2503.01750
tags:
- emotion
- recognition
- signals
- driver
- driving
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes ECG-EmotionNet, a novel architecture for driver
  emotion recognition using single-channel ECG signals in dynamic driving environments.
  It adapts a pretrained ECG Foundation Model via a nested Mixture of Experts (NMoE)
  approach, where each transformer layer is treated as an expert and their embeddings
  are fused using trainable weights.
---

# ECG-EmotionNet: Nested Mixture of Expert (NMoE) Adaptation of ECG-Foundation Model for Driver Emotion Recognition

## Quick Facts
- **arXiv ID:** 2503.01750
- **Source URL:** https://arxiv.org/abs/2503.01750
- **Reference count:** 33
- **Primary result:** 5-class driver emotion recognition (anger, fear, neutral, sadness, surprise) from single-channel ECG signals with 82.45% accuracy and 77.11% F1 score

## Executive Summary
ECG-EmotionNet introduces a novel architecture for driver emotion recognition using single-channel ECG signals in dynamic driving environments. The approach adapts a pretrained ECG Foundation Model via a nested Mixture of Experts (NMoE) strategy, treating each transformer layer as an expert and fusing their embeddings using trainable weights. This preserves the model's generalization capability while improving computational efficiency and capturing both global and local ECG features. Evaluated on the challenging manD 1.0 dataset, the system achieves state-of-the-art performance with 82.45% average accuracy and 77.11% F1 score across five emotional states, demonstrating robustness in noisy conditions.

## Method Summary
The method adapts a pretrained ECG-FM backbone using a nested Mixture of Experts approach. The architecture extracts embeddings from all 12 transformer layers of the frozen backbone, then fuses them using trainable gating weights that learn to emphasize the most relevant expert outputs for emotion classification. A simple classification head consisting of average pooling, dense layers with batch normalization and dropout, and a final dense layer for 5-class prediction is appended. The model is trained for 10 epochs using Adam optimizer with 5-fold cross-validation on the manD 1.0 dataset, achieving superior performance compared to existing methods while maintaining computational efficiency through parameter freezing.

## Key Results
- Achieves 82.45% classification accuracy across five emotional states (anger, fear, neutral, sadness, surprise)
- Obtains 77.11% F1 score, demonstrating strong class balance performance
- Outperforms state-of-the-art methods on the challenging manD 1.0 driver emotion monitoring dataset
- Demonstrates robustness in noisy driving environment conditions

## Why This Works (Mechanism)
The nested MoE adaptation works by leveraging the diverse feature extraction capabilities of different transformer layers while maintaining the generalization properties of the pretrained foundation model. Each transformer layer captures different levels of abstraction from the ECG signals - from fine-grained temporal patterns to higher-level semantic features. The trainable gating mechanism learns to dynamically weight these layer-specific representations based on their relevance to emotion classification, effectively creating a learned ensemble of experts without the computational overhead of full fine-tuning. This approach preserves the broad ECG understanding developed during pretraining while specializing the model for the specific task of emotion recognition in driving contexts.

## Foundational Learning
- **ECG signal preprocessing:** High-pass filtering and normalization are essential for removing baseline wander and standardizing input scale
  - *Why needed:* Raw ECG contains noise and baseline drift that can obscure emotion-related features
  - *Quick check:* Verify filtered signal retains QRS complexes and RR intervals
- **Transformer layer embeddings:** Each layer produces distinct feature representations capturing different abstraction levels
  - *Why needed:* Different layers specialize in different aspects of signal interpretation
  - *Quick check:* Visualize embedding distributions across layers for sample inputs
- **Mixture of Experts gating:** Learnable weights determine optimal combination of layer outputs
  - *Why needed:* Enables dynamic selection of most relevant features for emotion classification
  - *Quick check:* Examine gating weight distributions to confirm learning occurs
- **Foundation model adaptation:** Freezing backbone while adapting only gating and head parameters
  - *Why needed:* Preserves generalization while reducing computational cost
  - *Quick check:* Compare frozen vs. fine-tuned backbone performance on validation set

## Architecture Onboarding
**Component Map:** Raw ECG -> Preprocessing -> ECG-FM Backbone (frozen) -> 12 Transformer Layer Embeddings -> Gating Mechanism -> Weighted Aggregation -> Classification Head -> Emotion Output

**Critical Path:** Input signal → preprocessing → backbone feature extraction → NMoE fusion → classification head → output

**Design Tradeoffs:** The architecture prioritizes computational efficiency by freezing the foundation model weights while sacrificing some task-specific optimization that full fine-tuning would provide. The 75% overlap in sliding windows increases training data diversity but risks overfitting due to high correlation between samples.

**Failure Signatures:** 
- Shape mismatches in aggregation suggest incorrect handling of transformer output sequences
- Overfitting manifests as large train-validation accuracy gaps, likely due to high overlap percentage
- Poor performance may indicate inadequate gating weight learning or improper backbone initialization

**First Experiments:**
1. Verify transformer layer embedding extraction by checking output dimensions and basic statistics
2. Test gating mechanism with synthetic weights to confirm proper aggregation
3. Run a single training epoch with reduced overlap (50%) to establish baseline performance before optimization

## Open Questions the Paper Calls Out
None

## Limitations
- High dependency on availability of pretrained ECG-FM backbone weights, which may not be publicly accessible
- Gating mechanism implementation details are ambiguous regarding static vs. dynamic weight computation
- Performance assumes specific data split and augmentation strategy, making results potentially sensitive to preprocessing variations
- Computational requirements for reproducing the foundation model pretraining are substantial if weights are unavailable

## Confidence
- **Core innovation (NMoE adaptation):** Medium - well-specified but depends on external backbone availability
- **Reported performance:** Medium - relies on proprietary dataset and precise hyperparameter settings
- **Reproducibility:** Low - key implementation details (gating function, aggregation dimensions) are inferred rather than explicitly stated

## Next Checks
1. Confirm availability of the ECG-FM pretrained weights or release a minimal pretrained checkpoint for reproducibility
2. Clarify and implement the gating mechanism (static vs. dynamic weights) and validate the aggregation procedure on a toy dataset
3. Perform an ablation study on the overlap percentage to ensure the reported 75% setting is optimal and not overfit to the validation split