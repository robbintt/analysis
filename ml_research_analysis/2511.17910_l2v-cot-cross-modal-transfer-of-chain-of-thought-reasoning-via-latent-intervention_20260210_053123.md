---
ver: rpa2
title: 'L2V-CoT: Cross-Modal Transfer of Chain-of-Thought Reasoning via Latent Intervention'
arxiv_id: '2511.17910'
source_url: https://arxiv.org/abs/2511.17910
tags:
- reasoning
- vlms
- representations
- llms
- l2v-cot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of enhancing vision-language
  models' (VLMs) multi-step reasoning capabilities, which are limited by scarce multimodal
  reasoning data. The authors propose L2V-CoT, a training-free method that transfers
  Chain-of-Thought (CoT) reasoning from large language models (LLMs) to VLMs through
  latent intervention.
---

# L2V-CoT: Cross-Modal Transfer of Chain-of-Thought Reasoning via Latent Intervention

## Quick Facts
- arXiv ID: 2511.17910
- Source URL: https://arxiv.org/abs/2511.17910
- Reference count: 26
- Primary result: Training-free method achieves 3.7% average performance gain on visual reasoning benchmarks

## Executive Summary
This paper introduces L2V-CoT, a training-free approach that transfers Chain-of-Thought reasoning capabilities from large language models to vision-language models through latent intervention. The key insight is that VLMs and LLMs share similar low-frequency CoT representations despite architectural differences. By extracting and resampling these low-frequency patterns from LLMs and injecting them into VLMs during inference, L2V-CoT significantly improves multi-step visual reasoning performance across multiple benchmarks, with gains of up to 8.6% over training-free baselines.

## Method Summary
L2V-CoT operates by first analyzing CoT representations across modalities using Linear Artificial Tomography (LAT), which reveals shared low-frequency patterns between LLMs and VLMs. The method then extracts these low-frequency CoT patterns from LLMs and resamples them for injection into VLMs during inference. This approach avoids the need for expensive training while still enabling cross-modal knowledge transfer. The latent intervention process modifies the internal representations of VLMs in real-time, effectively transferring the reasoning capabilities learned by LLMs to visual reasoning tasks.

## Key Results
- Achieves 3.7% average performance improvement across visual reasoning benchmarks
- Outperforms training-free baselines by up to 8.6% on specific tasks
- Shows consistent improvements on MathVista, MathVerse, MMStar, DynaMath, and MathVision benchmarks
- Competes with or exceeds supervised fine-tuned models in several cases

## Why This Works (Mechanism)
L2V-CoT leverages the discovery that VLMs and LLMs share similar low-frequency CoT representations despite their different architectures. The method extracts these shared patterns from LLMs and resamples them for injection into VLMs during inference. This cross-modal transfer works because the low-frequency components of CoT reasoning appear to be modality-agnostic, capturing fundamental reasoning structures that can be applied across different input types. The latent intervention approach modifies the internal representations of VLMs in real-time, enabling the transfer of reasoning capabilities without requiring model retraining.

## Foundational Learning

**Linear Artificial Tomography (LAT)**
- Why needed: Enables analysis of CoT representations across different model architectures to identify shared patterns
- Quick check: Verify LAT can consistently identify low-frequency components across various model pairs

**Low-frequency CoT representations**
- Why needed: These shared representations form the basis for cross-modal transfer of reasoning capabilities
- Quick check: Confirm low-frequency patterns are indeed modality-agnostic through ablation studies

**Latent intervention technique**
- Why needed: Allows real-time modification of model representations during inference without retraining
- Quick check: Measure performance impact of different intervention strengths on reasoning accuracy

## Architecture Onboarding

**Component map:**
LLM CoT extraction -> LAT analysis -> Low-frequency pattern resampling -> VLM latent intervention -> Improved reasoning output

**Critical path:**
CoT extraction from LLM → LAT-based pattern identification → Resampling of low-frequency components → Injection into VLM latent space → Enhanced reasoning generation

**Design tradeoffs:**
- Training-free approach vs. potentially higher performance from fine-tuning
- Real-time inference overhead vs. pre-computed solutions
- Generalizability across tasks vs. task-specific optimization

**Failure signatures:**
- Degradation in performance when CoT patterns are mismatched with task complexity
- Increased computational overhead during inference affecting latency
- Potential for introducing reasoning artifacts when resampling is too aggressive

**First experiments to run:**
1. Ablation study on LAT sensitivity to different hyperparameters
2. Cross-task transfer validation on novel reasoning domains
3. Scalability testing with longer reasoning chains and larger model sizes

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but several areas for future investigation are implied by the limitations discussed, including the generalizability of the approach to other reasoning tasks, the sensitivity of LAT to different model architectures, and the computational overhead implications for real-world deployment.

## Limitations

- Modest absolute performance gains (3.7% average) despite consistent improvements
- Computational overhead during inference not fully characterized
- Limited testing to specific VLM architectures and benchmark datasets
- No systematic ablation studies on LAT hyperparameter sensitivity

## Confidence

- **High Confidence:** Discovery of shared low-frequency CoT representations across modalities is well-supported by experimental evidence
- **Medium Confidence:** Effectiveness of L2V-CoT in improving VLM performance demonstrated, but magnitude and robustness need further validation
- **Medium Confidence:** Theoretical framework of LAT-based representation analysis is sound but requires broader applicability testing

## Next Checks

1. Conduct systematic ablation studies on LAT hyperparameters to understand their impact on CoT transfer effectiveness across different model sizes and architectures

2. Evaluate L2V-CoT on out-of-distribution reasoning tasks, including novel visual puzzles and multi-modal reasoning scenarios not present in the training data

3. Characterize the computational overhead of latent resampling during inference and assess scalability for longer reasoning chains or larger models