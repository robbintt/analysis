---
ver: rpa2
title: Cross-Model Semantics in Representation Learning
arxiv_id: '2508.03649'
source_url: https://arxiv.org/abs/2508.03649
tags:
- alignment
- representations
- across
- learning
- architectural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates representational alignment across deep
  networks with distinct architectural structures. The authors formalize alignment
  as the existence of a transformation T that maps representations from one model
  to another while preserving task-relevant semantics.
---

# Cross-Model Semantics in Representation Learning

## Quick Facts
- arXiv ID: 2508.03649
- Source URL: https://arxiv.org/abs/2508.03649
- Reference count: 32
- This paper investigates representational alignment across deep networks with distinct architectural structures, showing that structured architectures (PGNN) achieve faster convergence, slightly higher accuracy, and improved early training dynamics compared to a baseline MLP.

## Executive Summary
This paper investigates representational alignment across deep networks with distinct architectural structures. The authors formalize alignment as the existence of a transformation T that maps representations from one model to another while preserving task-relevant semantics. They develop a theoretical framework for measuring alignment through metrics such as CKA, subspace overlap via principal angles, and cross-model transfer accuracy, along with empirical protocols across multiple seeds and layers. Experimental results show that structured architectures (PGNN) with projection-based operators achieve faster convergence, slightly higher accuracy, and improved early training dynamics compared to a baseline MLP. Ablation studies confirm the benefit of structured transformations. Transfer probes reveal partial semantic alignment between architectures, particularly in low-frequency subspaces, suggesting that structural priors can enhance cross-model representational interoperability.

## Method Summary
The paper proposes a framework for measuring representational alignment between models with different architectures using metrics like Centered Kernel Alignment (CKA), principal angles, and cross-model transfer accuracy. The PGNN architecture is defined as fi(x) = SiWix + φi(x), where Si is a structural projection operator encoding architectural priors, Wi is a learnable linear map, and φi is a corrective residual path. The method involves training PGNN and baseline models on FashionMNIST, CIFAR-10, and synthetic tasks, then extracting penultimate-layer representations to compute alignment metrics. Linear probes are trained on one model's frozen representations and tested on another to measure semantic transfer. The training uses Adam optimizer with learning rate 1e-3, batch size 128, early stopping on validation loss, and 5 random seeds.

## Key Results
- Structured architectures (PGNN) achieve faster convergence and improved early training dynamics compared to baseline MLP
- Cross-model transfer accuracy reveals partial semantic alignment between architectures, particularly in low-frequency subspaces
- Principal angle analysis shows higher subspace overlap in high-variance task-relevant directions

## Why This Works (Mechanism)

### Mechanism 1: Structural Constraints Induce Consistent Representational Geometry
Structural constraints (linear shaping operators) induce consistent representational geometry that improves cross-model alignment tractability. The architecture decomposes each layer as fi(x) = SiWix + φi(x), where Si is a task-independent structural projection (e.g., low-rank, spectral) applied before learnable weights. This constrains the hypothesis class, producing representations whose manifolds share topological properties (cluster structure, class margins) across seeds and architectures.

### Mechanism 2: Residual Corrective Paths Restore Expressivity
Residual corrective paths (φi) restore expressivity lost to structural constraints, maintaining accuracy while preserving alignment benefits. After SiWi projects activations into a constrained subspace, φi (typically a smaller MLP or skip connection) learns to correct errors. This keeps the effective hypothesis class near-universal while gradient flow is stabilized by Si's conditioning.

### Mechanism 3: Alignment Strongest in Task-Relevant Subspaces
Alignment is strongest in task-relevant and low-frequency subspaces, enabling partial transfer even across heterogeneous architectures. Principal angle analysis reveals that high-variance directions (often task-discriminative) show higher subspace overlap. CKA captures relational similarity invariant to rotation/scaling. Linear probes trained on one model transfer to another when these subspaces align.

## Foundational Learning

- **Concept: Centered Kernel Alignment (CKA)**
  - **Why needed here:** Core metric for comparing representations across architectures with different widths/depths, invariant to orthogonal transformations.
  - **Quick check question:** Given two activation matrices X and Y, what does CKA ≈ 1 imply about their geometric relationship?

- **Concept: Principal Angles and Subspace Overlap**
  - **Why needed here:** Quantifies orientation alignment of learned manifolds beyond scalar similarity scores.
  - **Quick check question:** If Overlap_k(X, Y) = 0.3 for k=10, what does this suggest about shared feature directions?

- **Concept: Inductive Bias as Hypothesis Class Restriction**
  - **Why needed here:** Explains why structural constraints can improve transfer without harming performance—they restrict how solutions are reached, not what solutions are reachable.
  - **Quick check question:** Why might two architectures with identical expressivity learn representations with low mutual alignment?

## Architecture Onboarding

- **Component map:**
  Input → Si projection → Wi linear → Nonlinearity → φi correction → Output
  Alignment diagnostics: Extract penultimate-layer activations → Normalize → Compute CKA, principal angles, transfer probes.

- **Critical path:**
  Input → Si projection → Wi linear → Nonlinearity → φi correction → Output
  Alignment diagnostics: Extract penultimate-layer activations → Normalize → Compute CKA, principal angles, transfer probes.

- **Design tradeoffs:**
  - Stronger Si constraint (lower rank, tighter spectral decay) → better conditioning and alignment but higher risk of underfitting
  - Larger φi → more capacity but potential gradient instability and reduced alignment
  - Depth vs. alignment: Earlier layers often show higher cross-model overlap; deeper layers diverge more

- **Failure signatures:**
  - Training loss plateaus higher than baseline → Si too restrictive; increase rank or relax spectral constraint
  - CKA high but transfer accuracy low → alignment is geometric but not semantic; probe may need nonlinearity
  - High variance across seeds → initialization sensitivity; check Si conditioning or add explicit normalization

- **First 3 experiments:**
  1. Train PGNN and MLP on FashionMNIST with identical hyperparameters; plot loss curves and final accuracy. Confirm PGNN converges faster (Figure 2/3 behavior).
  2. Remove Si (set to identity) and compare; verify performance drops as in Figure 5.
  3. Extract penultimate-layer activations from both models; compute CKA and Overlap_k (k=10, 50). Expect CKA > 0.5 and Overlap_10 > 0.4 for well-aligned pairs; lower values indicate need for Si tuning.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the PGNN framework and its cross-model alignment benefits be effectively scaled to more complex data distributions and domains beyond the simple vision benchmarks tested?
- **Basis in paper:** [explicit] The authors explicitly list "adapting and scaling PGNN to broader domains and more complex data distributions" as a key direction for future work, noting that CIFAR-10 results did not show a major advantage.
- **Why unresolved:** The empirical validation was restricted to FashionMNIST, CIFAR-10, and synthetic tasks, leaving high-complexity domains unexplored.
- **What evidence would resolve it:** Successful application and maintained alignment metrics of PGNN on large-scale datasets (e.g., ImageNet) or different modalities like natural language.

### Open Question 2
- **Question:** To what extent does the restriction to linear mappings limit the discovery of semantic alignment between structurally diverse architectures?
- **Basis in paper:** [inferred] The methodology section notes the framework focuses "primarily on linear alignment" for interpretability, acknowledging that mappings may be nonlinear but not empirically testing them.
- **Why unresolved:** If the true mapping T between manifolds M₁ and M₂ is inherently nonlinear, the current linear metrics (CKA, linear probes) may underestimate the true semantic interoperability.
- **What evidence would resolve it:** Experiments utilizing nonlinear probes or manifold alignment techniques that demonstrate significantly higher transfer accuracy than linear methods.

### Open Question 3
- **Question:** How does the specific form of the structural constraint operator Si alter the geometry of the representation manifold independent of the corrective path?
- **Basis in paper:** [inferred] While the theoretical framework generalizes to various structural constraints, the empirical results isolate a specific projection-based structure (PGNN), leaving the geometric effects of other constraints unverified.
- **Why unresolved:** It is unclear if the improved alignment is a general property of any structured prior or specifically the result of the projection-based approach used in PGNN.
- **What evidence would resolve it:** Comparative ablations using different implementations of Si (e.g., spectral vs. sparse operators) showing consistent or diverging effects on representational geometry.

## Limitations
- PGNN architectural details (exact form of Si, Wi, and φi operators) are underspecified in the abstract and must be inferred from equations and figures
- Experimental validation focuses on synthetic and benchmark datasets; generalization to larger-scale or real-world domains is untested
- Cross-model alignment results are measured in low-dimensional subspaces and early layers; semantic transfer in deeper or more complex representations remains uncertain

## Confidence
- **High confidence**: Claims about faster convergence and improved early training dynamics for PGNN (supported by ablation and empirical curves)
- **Medium confidence**: Claims about partial alignment in low-frequency subspaces and the role of Si in stabilizing geometry (supported by metrics but underspecified in method)
- **Low confidence**: Claims about universal benefits of structural constraints across all architectures and tasks (lacking breadth of validation)

## Next Checks
1. Implement and compare PGNN with multiple Si variants (low-rank, spectral, identity) on FashionMNIST to isolate the impact of each structural constraint on alignment and accuracy
2. Test transfer accuracy using nonlinear probes (MLP) instead of linear classifiers to verify that CKA and subspace overlap are not overly optimistic about semantic alignment
3. Evaluate cross-model alignment across deeper layers and multiple seeds to determine if early-layer alignment patterns persist or degrade with depth