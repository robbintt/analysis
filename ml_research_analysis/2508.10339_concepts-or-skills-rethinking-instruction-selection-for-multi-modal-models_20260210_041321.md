---
ver: rpa2
title: Concepts or Skills? Rethinking Instruction Selection for Multi-modal Models
arxiv_id: '2508.10339'
source_url: https://arxiv.org/abs/2508.10339
tags:
- selection
- instruction
- visual
- skill
- skills
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper studies how different vision-language instruction selection
  strategies affect downstream benchmark performance. The key finding is that benchmarks
  fall into two categories: those benefiting more from concept-aligned training (visual
  content similarity) and those benefiting more from skill-aligned training (reasoning
  ability similarity).'
---

# Concepts or Skills? Rethinking Instruction Selection for Multi-modal Models

## Quick Facts
- arXiv ID: 2508.10339
- Source URL: https://arxiv.org/abs/2508.10339
- Reference count: 8
- Key outcome: Targeted instruction selection based on concept vs. skill alignment improves VL benchmark performance by +0.9% overall, +1.5% on skill-focused tasks.

## Executive Summary
This paper studies how different vision-language instruction selection strategies affect downstream benchmark performance. The key finding is that benchmarks fall into two categories: those benefiting more from concept-aligned training (visual content similarity) and those benefiting more from skill-aligned training (reasoning ability similarity). The authors propose a targeted selection method that first classifies benchmarks as concept- or skill-dominant, then selects training instructions matching that type. Experiments on 12+ benchmarks show an average +0.9% improvement over best untargeted baselines, with +1.5% on skill-focused benchmarks. They also demonstrate a simple cross-ranking heuristic can predict which selection strategy works best for a given benchmark without running both. The work highlights the importance of aligning instruction selection with the specific demands of each task.

## Method Summary
The method involves creating concept and skill embeddings for both training instructions and benchmark samples, then retrieving nearest neighbors based on each type of similarity. Concept embeddings use CLIP image features, while skill embeddings are generated by prompting GPT-4o to list required visual skills and encoding the response with MiniLM-L6-v2. For each benchmark, the dominant alignment (concept or skill) is predicted using mutual ranking analysis of cross-ranks between concept and skill neighbors. The selected training subset is then used to fine-tune LLaVA-1.5 with LoRA. The approach aims to match the training data distribution to the specific characteristics of each target benchmark.

## Key Results
- Benchmarks benefit most when training instructions share their dominant trait (visual concepts vs. reasoning skills)
- Simple cross-ranking heuristic predicts optimal selection strategy without running both
- Targeted selection achieves +0.9% average improvement over best untargeted baselines
- Skill-focused benchmarks show +1.5% improvement with skill-aligned training

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Vision-language benchmarks can be primarily categorized as benefiting from either concept-aligned or skill-aligned training data.
- **Mechanism:** Benchmarks exhibit a "dichotomy" where downstream performance improves most when the training instructions share the benchmark's dominant trait (visual entities vs. reasoning operations). This alignment allows the model to focus on the most relevant inductive biases.
- **Core assumption:** The paper assumes that "concepts" (what objects appear) and "skills" (how to reason about them) are sufficiently distinct and can be decoupled for effective data selection.
- **Evidence anchors:**
  - [abstract] The paper states it found that "vision-language benchmarks fall into the dichotomy of mainly benefiting from training on instructions with similar skills or visual concepts."
  - [section 1] The introduction asks, "Should instruction selection prioritize alignment with the skills required by a task or the concepts present in the visual content?"
  - [corpus] Related work in the corpus, such as "Cream of the Crop," also addresses multi-modal data selection for instruction fine-tuning, supporting the importance of this research area.
- **Break condition:** This dichotomy may break down for benchmarks that require a highly integrated and balanced mix of both specific concepts and complex skills, which the paper notes hybrid strategies failed to address effectively.

### Mechanism 2
- **Claim:** Skill representations derived from LLM-extracted descriptions create a meaningful embedding space for retrieving beneficial training instructions.
- **Mechanism:** An LLM is prompted to describe the "visual skills" required for an instruction (e.g., "object counting," "spatial reasoning"). These descriptions are embedded into vectors, defining a space where proximity corresponds to similar cognitive demands. Retrieving nearest neighbors in this space yields a skill-aligned dataset.
- **Core assumption:** The paper assumes that an LLM can accurately and comprehensively identify the required visual skills from the text of an instruction and that a sentence embedding model can capture the semantic similarities between these skill descriptions.
- **Evidence anchors:**
  - [section 4.2] The methodology details the "Skill isolation through large language models" and subsequent embedding extraction.
  - [section 6.5] A qualitative study confirms the pipeline captures meaningful information, with examples like "interpreting graph trends across months."
  - [corpus] Evidence in the corpus for this specific skill-extraction mechanism is weak or missing; related papers focus on other selection criteria like reward modeling.
- **Break condition:** The mechanism depends on the LLM's ability to infer skills from text. It may fail for ambiguous instructions where the required skill is not evident from the question alone but depends heavily on the specific image content.

### Mechanism 3
- **Claim:** The dominant alignment factor for a benchmark can be predicted via a simple, lightweight mutual ranking analysis of concept and skill nearest neighbors, avoiding costly fine-tuning experiments.
- **Mechanism:** For a given benchmark, the method compares the cross-ranks of the top-1 concept and skill neighbors. An asymmetric pattern (e.g., low skill-to-concept rank but high concept-to-skill rank) indicates whether the benchmark is skill-driven or concept-driven. This heuristic predicts the optimal selection strategy.
- **Core assumption:** This approach assumes that the distributional relationship between concepts and skills in the training pool is consistent and that a simple rank-based metric is a sufficient proxy for the complex learning dynamics during fine-tuning.
- **Evidence anchors:**
  - [section 6.4] The paper introduces "Predicting Benchmark Alignment via Mutual Ranking" and describes the method using cross-ranks R_c|s and R_s|c.
  - [section 6.4, Figure 1] The scatter plot is cited as showing the simple heuristic "successfully predicted the preferred alignment type."
  - [corpus] Evidence in the corpus for this specific predictive technique is absent.
- **Break condition:** This predictive approach is benchmark-specific and may not generalize well to novel tasks with unique or poorly represented concept/skill distributions in the training data.

## Foundational Learning

- **Concept:** Vision-Language (VL) Instruction Tuning
  - **Why needed here:** The entire paper is predicated on this process, which serves two purposes: teaching models visual concepts and teaching them visual skills. Understanding this dual purpose is essential for grasping the selection problem.
  - **Quick check question:** What are the two main purposes of vision-language instruction tuning identified in the paper?

- **Concept:** Concepts vs. Skills Dichotomy
  - **Why needed here:** This is the paper's core analytical framework. One must understand that "concepts" refer to *what* is in an image (e.g., objects), while "skills" refer to *how* to reason about it (e.g., counting, spatial inference).
  - **Quick check question:** According to the paper, what is the key difference between a visual concept and a visual skill?

- **Concept:** Nearest-Neighbor Retrieval in Embedding Space
  - **Why needed here:** The proposed solution uses this technique to build both concept-aligned and skill-aligned datasets. Familiarity with how semantic similarity is computed and used for retrieval is required.
  - **Quick check question:** How are "skill embeddings" created and used to select training data?

## Architecture Onboarding

- **Component map:** Benchmark skill/concept extractor (LLM + vision encoder) -> Training pool embedder (concept/CLIP + skill/LLM) -> Retrieval module (FAISS) -> Mutual ranking analyzer -> VLM training loop (LLaVA-1.5 framework)
- **Critical path:** The most critical path is the **skill extraction and embedding pipeline**. Errors or noise introduced by the LLM when generating skill descriptions will directly impact the quality of the skill embedding space and the subsequent retrieval, potentially undermining the entire targeted selection strategy.
- **Design tradeoffs:** The primary tradeoff is between selection specificity and generality. The paper demonstrates that trying to combine concept and skill signals ("hybrid strategies") dilutes effectiveness. Engineers must choose to prioritize one alignment factor, accepting that performance on tasks dominated by the other factor may not be optimal.
- **Failure signatures:**
  - **Poor skill retrieval:** The LLM provides generic or inaccurate skill descriptions (e.g., "recognizing objects" for a complex reasoning task), causing the skill embedding space to be uninformative.
  - **Incorrect alignment prediction:** The mutual ranking heuristic fails for a benchmark with a unique data distribution, leading to the wrong selection strategy and suboptimal performance compared to a random baseline.
  - **Data scarcity:** In very low-data regimes, even the targeted selection might fail if the training pool lacks sufficient examples of the required concepts or skills.
- **First 3 experiments:**
  1.  **Reproduce the mutual ranking prediction:** Pick 2-3 known benchmarks (e.g., VQAv2, SQA-I), compute the mutual rank difference (Rs|c - Rc|s), and verify if it correctly predicts the optimal alignment as per the paper's findings.
  2.  **Run a targeted selection ablation:** For a single benchmark, create two small training subsets (e.g., 5% budget) using only concept-based retrieval and only skill-based retrieval. Fine-tune a model on each and compare performance to validate the alignment hypothesis.
  3.  **Qualitative skill embedding validation:** Manually inspect the LLM-generated skill descriptions and their nearest neighbors in the training pool for a few samples, similar to Table 5, to ensure the retrieval is semantically meaningful before scaling up.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can benchmark alignment preferences be inferred without supervision to enable zero-shot selection for completely novel tasks?
- **Basis in paper:** [explicit] The authors explicitly state in Future Work the goal to "develop automatic methods to infer benchmark alignment preferences without supervision, enabling dynamic, zero-shot selection for unseen tasks."
- **Why unresolved:** The current method requires access to the target benchmark's samples to compute embeddings and mutual rankings, which is not possible for private or undefined tasks.
- **What evidence would resolve it:** A model or heuristic that predicts the dominant alignment factor (concept vs. skill) from a task description alone, achieving selection performance comparable to the current benchmark-aware method.

### Open Question 2
- **Question:** How does targeted instruction selection affect multi-task generalization and interference when training a single unified model?
- **Basis in paper:** [inferred] The Limitations section notes the approach "treats each benchmark in isolation and does not account for multi-task generalization or interference effects."
- **Why unresolved:** Optimizing data selection for one specific benchmark may create a model that overfits to that benchmark's alignment type, potentially degrading performance on others or failing to learn a robust, general representation.
- **What evidence would resolve it:** An analysis of performance trade-offs when training on a dataset selected for a mixture of alignments, compared to training separate models or using untargeted data.

### Open Question 3
- **Question:** Can fine-grained selection criteria modeling interaction effects between concepts and skills overcome the failure of simple hybrid strategies?
- **Basis in paper:** [inferred] Section 6.3 shows that naive hybrid strategies (sum, max, split) consistently underperform single-targeted ones, and Future Work suggests exploring "fine-grained selection criteria that consider interaction effects."
- **Why unresolved:** The dichotomy suggests benchmarks favor one factor strongly, but the failure of hybrids indicates the interaction is complex and not resolvable through simple linear combinations or budget splitting.
- **What evidence would resolve it:** A new selection algorithm that successfully combines concept and skill signals (e.g., via attention or conditional weighting) and statistically outperforms the single-targeted baselines on mixed-alignment benchmarks.

## Limitations
- The concept/skill dichotomy may not capture all benchmark characteristics, particularly for tasks requiring balanced integration of both factors
- The mutual ranking heuristic's reliability for novel benchmarks with unique data distributions is uncertain
- The approach treats each benchmark in isolation without accounting for multi-task generalization or interference effects

## Confidence
- **High** for the practical efficacy of targeted selection given demonstrated +0.9% average improvement
- **Medium** for the reliability of the mutual ranking heuristic for novel benchmarks
- **Medium** for the generality of the concept/skill dichotomy beyond tested benchmarks

## Next Checks
1. Replicate the mutual ranking prediction on 2-3 held-out benchmarks to confirm the heuristic's reliability without fine-tuning
2. Run a controlled ablation comparing concept-only vs skill-only training subsets (e.g., 5% budget) on a single benchmark to validate the alignment hypothesis
3. Inspect LLM-generated skill descriptions and their nearest neighbors for semantic coherence, as in Table 5, to ensure the retrieval pipeline is meaningful