---
ver: rpa2
title: 'Diff2Flow: Training Flow Matching Models via Diffusion Model Alignment'
arxiv_id: '2506.02221'
source_url: https://arxiv.org/abs/2506.02221
tags:
- diffusion
- flow
- matching
- diff2flow
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Diff2Flow enables efficient knowledge transfer from diffusion to
  flow matching models by aligning their trajectories through timestep rescaling and
  interpolant alignment, allowing direct flow matching finetuning of diffusion priors.
  It addresses the computational bottleneck of large flow matching models by leveraging
  pre-trained diffusion models like Stable Diffusion.
---

# Diff2Flow: Training Flow Matching Models via Diffusion Model Alignment

## Quick Facts
- **arXiv ID:** 2506.02221
- **Source URL:** https://arxiv.org/abs/2506.02221
- **Reference count:** 40
- **Primary result:** Enables efficient knowledge transfer from diffusion to flow matching models through trajectory alignment, achieving faster convergence and better FID scores, particularly under LoRA constraints.

## Executive Summary
Diff2Flow addresses the computational bottleneck of training large flow matching models by aligning pre-trained diffusion models (like Stable Diffusion) to the flow matching framework. The method achieves this through timestep rescaling and interpolant alignment, allowing direct finetuning of diffusion priors into flow matching models. Experiments demonstrate that Diff2Flow outperforms naïve flow matching and diffusion finetuning, especially under parameter-efficient constraints like LoRA. For text-to-image tasks, it achieves faster convergence and better FID scores. In monocular depth estimation, it matches or exceeds state-of-the-art generative methods with reduced training iterations, and enables faster inference via trajectory rectification.

## Method Summary
Diff2Flow converts pre-trained diffusion models into flow matching models by aligning their trajectories through mathematical transformations. The method involves rescaling discrete diffusion timesteps to continuous flow matching timesteps using noise schedule coefficients (αt, σt), aligning the diffusion interpolant to the linear flow matching interpolant, and deriving the flow matching velocity field from diffusion predictions. The approach leverages pre-trained Stable Diffusion models and applies Low-Rank Adaptation (LoRA) for efficient finetuning. The unified objective prevents the optimizer from fighting the pretrained weight initialization, enabling stable conversion without retraining the backbone.

## Key Results
- Outperforms naïve flow matching and diffusion finetuning, particularly under LoRA constraints
- Achieves faster convergence and better FID scores for text-to-image tasks
- Enables 2-4 step sampling for depth estimation while maintaining quality
- Matches or exceeds state-of-the-art generative methods for monocular depth estimation

## Why This Works (Mechanism)

### Mechanism 1: Timestep Rescaling and Interpolant Alignment
Mapping discrete diffusion timesteps to continuous flow matching timesteps preserves the pretrained prior's SNR structure. The paper defines a mapping function ft that converts discrete tDM ∈ [0,T] to continuous tFM ∈ [0,1] based on diffusion coefficients αt and σt, aligning the diffusion interpolant to the linear FM interpolant via fx.

### Mechanism 2: Objective Unification via Velocity Derivation
The method analytically derives the FM velocity field from diffusion predictions (v-prediction or ε-prediction) to prevent the optimizer from fighting pretrained weight initialization. Instead of training from scratch, Diff2Flow uses the mathematical relationship between diffusion prediction and FM velocity.

### Mechanism 3: Parameter-Efficient Alignment (LoRA)
Alignment allows LoRA to succeed where naïve FM finetuning fails because the low-rank update is sufficient to warp the trajectory without unlearning the base model's features. The method reduces the task to "trajectory warping," which fits within the low-rank constraint.

## Foundational Learning

- **Flow Matching (Rectified Flow):** FM seeks a straight line (ODE) from noise to data, unlike curved stochastic paths of diffusion. Needed to understand why Diff2Flow converts diffusion models into this framework. Quick check: Can you explain why a straighter trajectory allows for fewer sampling steps?
- **Diffusion Noise Schedules (SNR):** The core contribution relies on mapping timesteps based on αt and σt. Needed to distinguish between variance-preserving (VP) and variance-exploding (VE) schedules. Quick check: Given a timestep t, how do αt and σt determine the signal-to-noise balance?
- **Parameterizations (ε vs v vs Velocity):** The paper derives conversion formulas specifically for v-prediction models. Needed to know if your base model predicts noise (ε) or velocity (v). Quick check: If a model outputs ε, how would you mathematically recover the x0 estimate needed for the FM velocity formula?

## Architecture Onboarding

- **Component map:** Continuous tFM ∈ [0,1], Noisy sample xFM -> Rescaling Module (converts tFM → tDM and xFM → xDM) -> Base Model (frozen U-Net processes xDM, tDM) -> Objective Adapter (converts Base Model output vpred to FM velocity vFM) -> Optimizer (updates LoRA weights using LFM)
- **Critical path:** The calculation of f⁻¹(tFM) (Eq. 12) is the most sensitive implementation detail, requiring exact noise schedule coefficients of the base model.
- **Design tradeoffs:** Speed vs. Precision (linear interpolation vs. higher-order), PEFT Rank (lower ranks work for style transfer, higher ranks needed for structural changes)
- **Failure signatures:** Gray Outputs (zero-terminal SNR issues), Convergence Stalls (loss plateaus early with LoRA)
- **First 3 experiments:**
  1. Sanity Check Inference: Run base diffusion model using non-integer timesteps with interpolated α/σ to verify image quality.
  2. Ablation on Alignment: Train LoRA adapter using (A) Naive FM loss and (B) Diff2Flow aligned loss to validate "alignment gap."
  3. Depth/Reflow Task: Finetune aligned model for 2-4 NFE steps to test trajectory straightening.

## Open Questions the Paper Calls Out

### Open Question 1
Is the success of continuous timestep interpolation dependent on sinusoidal positional embeddings? The authors hypothesize that sinusoidal embeddings create a well-defined continuous time space, but do not verify if this holds for other encoding schemes or if it contributes to error accumulation.

### Open Question 2
Does applying iterative rectification (e.g., 2-Reflow) to a Diff2Flow model result in further trajectory straightening, or does the initial alignment constrain the potential for straighter paths? The paper demonstrates 1-rectified flow for 2-step sampling but does not explore if residual curvature from the original diffusion process is fully eliminated.

### Open Question 3
Can the Diff2Flow alignment formulation be extended to non-linear flow matching paths, such as those utilizing Optimal Transport (OT) couplings? The method relies on aligning to a linear FM interpolant, whereas advanced flow matching often uses OT paths to reduce travel time.

## Limitations
- The paper assumes continuous differentiability of the diffusion trajectory via sinusoidal embeddings without rigorous empirical validation
- Theoretical guarantees for trajectory straightening are heuristic rather than formally proven
- Implementation details for depth estimation head architecture are sparse, potentially blocking exact reproduction

## Confidence
- **High:** The core alignment mechanism (timestep rescaling + interpolant alignment) is mathematically sound and well-supported by experimental results
- **Medium:** Parameter-efficient LoRA claims are demonstrated empirically but lack ablation studies explaining why naïve FM fails under LoRA constraints
- **Low:** Trajectory rectification claims for 2-4 step sampling are promising but only validated on depth estimation, with unclear generalization to other domains

## Next Checks
1. Implement and verify continuous interpolation scheme by comparing generated images against paper's Figure 2, measuring quality degradation across fractional timesteps
2. Conduct ablation study isolating alignment effect: train identical LoRA adapters using (A) naïve FM loss and (B) Diff2Flow aligned loss, measuring convergence speed and final FID
3. Test trajectory rectification by generating images from depth model using 2, 4, and 10 NFE steps, measuring quality degradation and confirming sample efficiency claims