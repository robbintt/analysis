---
ver: rpa2
title: Consistency-Aware Parameter-Preserving Knowledge Editing Framework for Multi-Hop
  Question Answering
arxiv_id: '2509.18655'
source_url: https://arxiv.org/abs/2509.18655
tags:
- knowledge
- retrieval
- edited
- consistency
- editing
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of parameter-preserving knowledge
  editing for multi-hop question answering, where existing methods struggle with consistency
  issues such as knowledge contamination, unstable updates, and misaligned retrieval
  behaviors. The proposed CAPE-KG framework introduces a consistency-aware approach
  by constructing a multi-layer knowledge graph architecture that separates factual
  and edited knowledge, implementing case-isolated update mechanisms with conflict
  arbitration, and designing an edit-aware retrieval module with progressive strategies.
---

# Consistency-Aware Parameter-Preserving Knowledge Editing Framework for Multi-Hop Question Answering

## Quick Facts
- arXiv ID: 2509.18655
- Source URL: https://arxiv.org/abs/2509.18655
- Authors: Lingwen Deng; Yifei Han; Long Zhang; Yue Du; Bin Li
- Reference count: 29
- Key outcome: CAPE-KG achieves 78.03% multi-hop accuracy and 70.35% holistic accuracy on MQuAKE-CF-3K, and 93.39% multi-hop accuracy and 84.52% holistic accuracy on MQuAKE-T, significantly outperforming existing parameter-preserving baselines.

## Executive Summary
This paper addresses the challenge of parameter-preserving knowledge editing for multi-hop question answering, where existing methods struggle with consistency issues such as knowledge contamination, unstable updates, and misaligned retrieval behaviors. The proposed CAPE-KG framework introduces a consistency-aware approach by constructing a multi-layer knowledge graph architecture that separates factual and edited knowledge, implementing case-isolated update mechanisms with conflict arbitration, and designing an edit-aware retrieval module with progressive strategies. Extensive experiments on the MQuAKE benchmark demonstrate that CAPE-KG significantly outperforms existing baselines, achieving substantial improvements in both multi-hop and holistic accuracy metrics.

## Method Summary
CAPE-KG is a parameter-preserving knowledge editing framework that maintains a multi-layer knowledge graph with a base layer for factual triples and case-specific overlay layers for edits. The framework uses case-isolated updates with conflict arbitration to prevent knowledge contamination, and implements an edit-aware progressive retrieval strategy that routes queries based on edit impact surfaces. Edits are processed as structured triples (subject, relation, object) using entity/relation detectors, and retrieval operates through a three-stage progressive strategy with LLM fallback injection for failed cases.

## Key Results
- Achieves 78.03% multi-hop accuracy and 70.35% holistic accuracy on MQuAKE-CF-3K benchmark
- Achieves 93.39% multi-hop accuracy and 84.52% holistic accuracy on MQUAKE-T benchmark
- Outperforms existing parameter-preserving baselines by significant margins on both benchmarks

## Why This Works (Mechanism)

### Mechanism 1: Multi-Layer Knowledge Boundary Isolation
Separating unedited facts from edited knowledge into distinct graph layers prevents cross-case contamination during multi-hop reasoning. The system maintains a Base Layer ($B$) derived solely from factual triples and Overlay Layers ($O_c$) for case-specific edits, with reasoning queries explicitly routed to one layer or the other.

### Mechanism 2: Case-Isolated Update with Conflict Arbitration
Restricting update operations to case-specific overlays with deterministic conflict resolution prevents unstable overwrites and maintains update consistency. Updates are strictly limited to the overlay of the current case, with a conflict arbitration module applying deterministic rules when multiple edits target the same subject-relation pair.

### Mechanism 3: Edit-Aware Progressive Retrieval
Routing queries based on an "edit impact surface" and using progressive fallbacks ensures retrieval aligns with the intent of the edit even when entity extraction is uncertain. The system defines an edit impact surface and routes sub-questions to the Overlay if they touch this surface, with a Failure Stage that injects the edited triple into the LLM context when retrieval confidence is low.

## Foundational Learning

### Concept: Parameter-Preserving Knowledge Editing (PPKE)
**Why needed:** The framework explicitly avoids modifying model weights (unlike ROME/MEMIT), requiring external structures (KGs) and retrieval strategies to incorporate new facts without retraining.
**Quick check:** Does this method require gradient updates or retraining to incorporate new facts? (Answer: No).

### Concept: Multi-Hop Question Answering (MHQA)
**Why needed:** The core challenge is reasoning over a chain of facts where edits may invalidate intermediate steps, making single-hop editing logic insufficient.
**Quick check:** If fact A changes, and the answer to Question Q depends on A -> B -> C, which steps must reflect the edit?

### Concept: Knowledge Graph Triples $(s, r, o)$
**Why needed:** The architecture relies on structuring edits as triples (Subject, Relation, Object) to populate the Base and Overlay layers.
**Quick check:** How is the edit "The capital of X is Y" represented structurally?

## Architecture Onboarding

### Component map:
KG Construction -> Update Module -> Retrieval Module
(Base Layer + Overlay Layers) -> (Conflict Arbitration) -> (Edit-Aware Progressive Retrieval)

### Critical path:
The Retrieval Router (Section 3.3, Eq. 1) is critical - if it misidentifies the edit impact surface ($S_{edit}, P_{edit}$), queries will hit the wrong layer, breaking consistency.

### Design tradeoffs:
- Latency vs. Consistency: Progressive retrieval improves accuracy/holistic scores but significantly increases inference latency (+20-30% latency per sub-question).
- Isolation vs. Generality: The case-isolated assumption ensures stability for specific users but restricts global knowledge updates.

### Failure signatures:
- Knowledge Contamination: Retrieving an edited entity when the query intended factual knowledge, signaling boundary isolation failure.
- Intent Drift: The model answers with original facts despite an edit existing, signaling edit-aware routing or entity detection failure.

### First 3 experiments:
1. Sanity Check (MQuAKE-1): Run a single edit to verify the Overlay mechanism correctly updates the answer for a 2-hop question.
2. Stress Test (Batch Edits): Run 100 concurrent edits to verify case isolation prevents accuracy drop (check if M-Acc remains stable vs. baselines).
3. Ablation on Retrieval: Disable the progressive retrieval module to measure the drop in Holistic Accuracy (H-Acc) and confirm the contribution of intent consistency.

## Open Questions the Paper Calls Out

### Open Question 1
How can CAPE-KG be extended to support continual knowledge editing where edits evolve and accumulate over time? The current framework is evaluated on static batch edits, and its ability to maintain consistency and performance over long sequences of temporal updates remains untested.

### Open Question 2
Can the architecture be modified to handle globally shared knowledge updates that violate the case-isolated edit assumption? The current design isolates edits in specific overlay layers to prevent contamination, but it's unclear how it would manage scenarios where a single edit must logically propagate across different users or cases.

### Open Question 3
Can the progressive retrieval strategy be optimized to reduce the inference latency overhead identified in deeper reasoning chains? While the paper validates the effectiveness of progressive retrieval for accuracy, it does not explore methods to mitigate the increased latency (approximately +1000ms per question).

## Limitations
- Case-isolated edits limit applicability to scenarios requiring global knowledge updates across multiple user contexts
- Performance heavily depends on accuracy of entity/relation detectors from KEDKG, which are not fully specified
- Progressive retrieval strategy introduces significant latency overhead (approximately +20-30% per sub-question)
- Conflict arbitration mechanism's deterministic rules may not scale well to complex, concurrent editing scenarios

## Confidence
- High Confidence: Experimental results demonstrating superior performance on MQuAKE benchmarks are well-documented with specific accuracy metrics
- Medium Confidence: Mechanism descriptions are theoretically sound, but implementation details for critical components like KEDKG integration are underspecified
- Low Confidence: Scalability analysis for high-volume concurrent edits and framework behavior under edge cases are not thoroughly explored

## Next Checks
1. **Cross-Case Consistency Test:** Perform 100+ concurrent edits across different user cases and measure whether case isolation prevents accuracy degradation in unrelated queries.

2. **Detector Robustness Evaluation:** Systematically degrade entity/relation detection accuracy and measure the impact on retrieval routing accuracy and overall M-Acc/H-Acc performance.

3. **Latency-Performance Tradeoff Analysis:** Quantify the exact latency overhead introduced by progressive retrieval across different hop depths and determine if accuracy gains justify performance cost in real-time applications.