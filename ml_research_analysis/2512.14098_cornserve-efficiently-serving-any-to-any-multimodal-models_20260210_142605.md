---
ver: rpa2
title: 'Cornserve: Efficiently Serving Any-to-Any Multimodal Models'
arxiv_id: '2512.14098'
source_url: https://arxiv.org/abs/2512.14098
tags:
- request
- throughput
- cornserve
- text
- serving
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Cornserve is the first system to efficiently serve Any-to-Any\
  \ multimodal models that accept and generate combinations of text, images, video,\
  \ and audio. It introduces a planner that automatically determines the optimal deployment\
  \ strategy\u2014monolithic, disaggregated, or hybrid\u2014based on model and workload\
  \ characteristics."
---

# Cornserve: Efficiently Serving Any-to-Any Multimodal Models

## Quick Facts
- arXiv ID: 2512.14098
- Source URL: https://arxiv.org/abs/2512.14098
- Authors: Jeff J. Ma; Jae-Won Chung; Jisang Ahn; Yizhuo Liang; Akshay Jajoo; Myungjin Lee; Mosharaf Chowdhury
- Reference count: 40
- Primary result: First system to efficiently serve Any-to-Any multimodal models, achieving up to 3.81× throughput and 5.79× tail latency improvements

## Executive Summary
Cornserve is the first system designed to efficiently serve Any-to-Any multimodal models that accept and generate combinations of text, images, video, and audio. It introduces a planner that automatically determines the optimal deployment strategy—monolithic, disaggregated, or hybrid—based on model and workload characteristics. The system uses a cell abstraction to simplify the NP-hard resource allocation problem and enables efficient adaptation to changing load. Evaluations show Cornserve significantly outperforms existing solutions across diverse state-of-the-art models.

## Method Summary
Cornserve addresses the challenge of serving Any-to-Any multimodal models through a two-component architecture: a planner and a distributed runtime. The planner profiles model components to understand their throughput characteristics, then solves a multicommodity network design problem using a cell abstraction to determine optimal deployment strategies. The runtime executes these plans using record & replay for flexible computation graphs and request-static routing for efficient load balancing without runtime control overhead.

## Key Results
- Improves throughput by up to 3.81× compared to existing solutions
- Reduces tail latency by up to 5.79× across diverse state-of-the-art models
- Successfully serves large models like Qwen 3 Omni 30B that OOM on monolithic deployment
- Achieves efficient load balancing with zero dynamic control overhead using request-static routing

## Why This Works (Mechanism)

### Mechanism 1: Cell-based planning for tractable resource allocation
Decomposing the NP-hard multicommodity network design problem into pre-computed cell configurations enables efficient scaling without solving the full optimization problem at runtime. The planner pre-computes optimal deployment strategies for power-of-two-sized GPU allocations (cells of size 1, 2, 4, 8... GPUs). Each cell captures the best deployment for a complete model instance within that allocation. At runtime, the planner uses a greedy algorithm to compose cells—since larger efficient cells are guaranteed to achieve throughput ≥ any combination of smaller cells totaling the same GPUs, the greedy selection is optimal.

### Mechanism 2: Request-static routing eliminates control plane overhead
Pre-computing path selection probabilities during planning and sampling deterministically per-request achieves load balancing without runtime queue queries. The planner's multicommodity flow solution already specifies how to split each request type's rate across valid execution paths. The runtime samples a path on request arrival using these probabilities, then routes statically along that path. No executor queue length queries are needed, providing 3.7× higher throughput than dynamic load balancing.

### Mechanism 3: Record & Replay enables flexible computation graphs
Executing the model's invoke() method twice—first to record the computation subgraph with mock results, then to replay with real executor results—supports arbitrary control flow without requiring static graph declaration. On request arrival, invoke() runs in "record" mode where unit tasks return mock objects and log their invocations and data dependencies. The recorded subgraph is dispatched to executors. Then invoke() runs again in "replay" mode, receiving real results. This handles branches and loops naturally.

## Foundational Learning

- **Concept: Any-to-Any model architecture**
  - Why needed here: Cornserve's entire design centers on models composed of heterogeneous components (encoders, LLMs, generators) with different throughput characteristics and computation paths depending on input/output modality combinations.
  - Quick check question: Can you sketch the computation graph for a model that takes image+text input and produces audio output? What components are invoked?

- **Concept: Disaggregation strategies (PD, EPD, component-wise)**
  - Why needed here: The planner must understand when disaggregating components improves throughput vs. when monolithic deployment is better. Figure 2 shows the same model (InternVL 3) has different optimal deployments under different workloads.
  - Quick check question: For an MLLM with a large vision encoder (6B params), when would encoder disaggregation help throughput vs. hurt it? (Hint: think about KV cache memory and GPU utilization tradeoffs.)

- **Concept: Multicommodity network flow formulation**
  - Why needed here: The planning problem is explicitly framed as a multicommodity network design problem where each request type is a commodity flowing through the executor graph with capacity constraints.
  - Quick check question: Why does the cell abstraction reduce the problem complexity? What is traded off?

## Architecture Onboarding

- **Component map**: Gateway -> Planner (Profiler, Solver) -> Task Managers -> Task Executors
- **Critical path**:
  1. Model deployment: Gateway receives task definition → Planner profiles components → Solver computes optimal cell mixture → Task Managers spawn Executors
  2. Request handling: Gateway receives request → Record pass (mock execution) → Task Dispatcher sends subgraph to Executors → Replay pass (real results)
- **Design tradeoffs**:
  - Communication vs. isolation: Disaggregation balances load but adds data transfer overhead (Figure 12 shows 20-60ms latency for 8-32MB transfers under load)
  - Cell size vs. flexibility: Larger cells enable more balancing options but coarser scaling granularity
  - Static vs. dynamic routing: Static routing is faster but requires workload stability
- **Failure signatures**:
  - OOM on monolithic deployment: Indicates need for disaggregation (seen with Qwen 3 Omni 30B in Figure 6b)
  - Load imbalance (queue buildup on specific executors): Check if actual workload matches planned distribution; may need re-planning
  - High tail latency with disaggregation: Communication overhead dominating; check if cell placement respects network topology
- **First 3 experiments**:
  1. Profile individual component throughput: Deploy the target model monolithically and measure each component's throughput in isolation to understand computation scaling heterogeneity
  2. Compare deployment strategies under fixed workload: Using a representative request trace, compare monolithic vs. disaggregated vs. hybrid deployments on throughput and latency
  3. Validate request-static routing efficiency: For a deployment with multiple valid paths, measure throughput with request-static routing vs. a dynamic load balancer that queries queue lengths

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can Cornserve be extended to explicitly optimize for latency Service Level Objectives (SLOs) or goodput instead of focusing primarily on throughput?
- Basis in paper: Section 3.1 states that "Optimizing latency SLO or goodput is a non-goal for this work and can be a good future direction."
- Why unresolved: The current mathematical formulation minimizes GPU usage or maximizes throughput without incorporating latency constraints into the solver's objective function.
- What evidence would resolve it: A modified planner implementation that successfully integrates P99 latency bounds into the multicommodity network design problem.

### Open Question 2
- Question: Can techniques like multicast scaling effectively mitigate the multi-minute pod startup times to enable rapid autoscaling?
- Basis in paper: Appendix E identifies executor startup times up to 185 seconds and suggests "this startup time could be further reduced if applying techniques such as multicast scaling."
- Why unresolved: While the system supports scaling, the high initialization latency limits its agility in responding to sudden spikes in load without pre-provisioning.
- What evidence would resolve it: A comparative evaluation measuring time-to-ready for executors using multicast model loading versus the standard unicast implementation.

### Open Question 3
- Question: How robust is the request-static routing strategy when the real-time request modality mix deviates significantly from the offline profile?
- Basis in paper: The planner relies on a static "representative request dataset" to determine fixed routing probabilities.
- Why unresolved: A mismatch between the planned distribution and the actual online traffic mix could lead to executor load imbalance, as the routing is static.
- What evidence would resolve it: Stress tests evaluating throughput and queueing delays under workload distributions that dynamically drift away from the planner's initial input assumptions.

## Limitations

- Claims rely heavily on synthetic and controlled benchmarks rather than production deployment data
- Cell abstraction's effectiveness depends on specific network topology assumptions that may not hold in all deployments
- Request-static routing assumes workload stability but doesn't quantify performance degradation under significant distribution shifts
- Record & replay mechanism requires deterministic invoke() methods, limiting generalizability to all model architectures

## Confidence

- **High confidence**: Throughput and latency improvements over baselines (3.81× and 5.79× gains) are well-supported by controlled experiments across multiple models and workloads
- **Medium confidence**: The cell-based planning approach's optimality claims hold under the stated assumptions about network topology and component throughput heterogeneity
- **Medium confidence**: Request-static routing's efficiency gains are demonstrated, but real-world effectiveness depends on workload predictability
- **Low confidence**: The system's behavior under rapid load changes, non-deterministic model control flow, or heterogeneous GPU clusters is not characterized

## Next Checks

1. **Network topology sensitivity**: Test Cornserve's performance when cells span racks with varying network bandwidth to validate the assumption that intra-cell communication doesn't become the bottleneck
2. **Workload shift robustness**: Measure throughput degradation when the actual request distribution deviates significantly from the planned distribution (e.g., 50% shift in request type mix)
3. **Model control flow generality**: Deploy a model with non-trivial control flow (branches, loops) that has side effects or non-deterministic behavior to test record & replay mechanism limitations