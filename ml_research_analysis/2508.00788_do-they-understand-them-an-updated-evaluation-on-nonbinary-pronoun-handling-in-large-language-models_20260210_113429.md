---
ver: rpa2
title: Do They Understand Them? An Updated Evaluation on Nonbinary Pronoun Handling
  in Large Language Models
arxiv_id: '2508.00788'
source_url: https://arxiv.org/abs/2508.00788
tags:
- pronoun
- llms
- pronouns
- gender
- identity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study introduces MISGENDERED+, an updated benchmark for evaluating\
  \ large language models\u2019 (LLMs) handling of nonbinary pronouns. It addresses\
  \ limitations in prior work by incorporating a gender identity inference task and\
  \ testing modern LLMs (GPT-4o, Claude-4, DeepSeek-V3, Qwen-Turbo, Qwen2.5) across\
  \ zero-shot, few-shot, and inference settings."
---

# Do They Understand Them? An Updated Evaluation on Nonbinary Pronoun Handling in Large Language Models

## Quick Facts
- **arXiv ID:** 2508.00788
- **Source URL:** https://arxiv.org/abs/2508.00788
- **Reference count:** 29
- **Primary result:** Few-shot prompting substantially improves neopronoun accuracy across LLMs, but name-based gender priors still override pronoun signals in identity inference tasks.

## Executive Summary
This study introduces MISGENDERED+, an updated benchmark for evaluating large language models’ (LLMs) handling of nonbinary pronouns. It addresses limitations in prior work by incorporating a gender identity inference task and testing modern LLMs (GPT-4o, Claude-4, DeepSeek-V3, Qwen-Turbo, Qwen2.5) across zero-shot, few-shot, and inference settings. Results show significant improvements in binary and gender-neutral pronoun accuracy compared to earlier studies, with few-shot prompting substantially boosting performance—especially for underrepresented neopronouns. However, persistent gaps remain in neopronoun generalization and in avoiding name-based gender biases during identity inference. The findings highlight ongoing challenges in inclusive language modeling and provide a foundation for future fairness-focused LLM development.

## Method Summary
The study evaluates LLMs on nonbinary pronoun handling through two tasks: Pronoun Fidelity (filling masked pronouns given identity declarations) and Gender Identity Inference (predicting gender from name-pronoun pairs). The benchmark uses 11 pronoun sets across 5 grammatical forms, testing zero-shot, few-shot (6 examples), and inference settings with matched/mismatched name-pronoun combinations. Models are queried via API with constrained outputs, and accuracy is measured across different pronoun categories and grammatical forms.

## Key Results
- Few-shot prompting dramatically improves neopronoun accuracy, with DeepSeek-V3 jumping from 21.0% to 77.9% on "he" and Qwen2.5 improving "co" from 74.5% to 95.5%
- Reflexive and possessive-independent forms consistently underperform other grammatical forms across all models
- Name-based gender priors override pronoun signals in identity inference, with Claude-4-Sonnet achieving only 41.7% on female-name/male-pronoun mismatches
- High-alignment models (GPT-4o, Claude-4) show superior pronoun fidelity, particularly for neopronouns, compared to multilingual-focused models

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Few-shot prompting substantially improves pronoun fidelity, especially for underrepresented neopronouns and models with weak zero-shot baselines.
- **Mechanism:** In-context examples activate latent syntactic capabilities that exist but remain dormant without explicit demonstrations.
- **Core assumption:** Models have internalized pronoun paradigms during pretraining but lack reliable retrieval pathways without exemplars.
- **Evidence anchors:** DeepSeek-V3 accuracy on "he" jumps from 21.0% (zero-shot) to 77.9% (few-shot); similar patterns across neopronouns.

### Mechanism 2
- **Claim:** Gender identity inference tasks expose implicit name-based priors that override pronoun signals.
- **Mechanism:** When tasked with inferring gender from sentences containing mismatched name-pronoun pairs, models revert to statistical associations between names and binary gender rather than respecting pronoun cues.
- **Core assumption:** Models learn co-occurrence patterns between names and gender categories that function as heuristic shortcuts.
- **Evidence anchors:** Claude-4-Sonnet achieves only 41.7% accuracy on female-name/male-pronoun mismatches despite high performance elsewhere.

### Mechanism 3
- **Claim:** High-alignment, safety-focused models demonstrate superior pronoun fidelity, particularly for neopronouns.
- **Mechanism:** Models trained with reinforcement learning from human feedback (RLHF) and explicit safety alignment receive signals that prioritize respectful, inclusive language use.
- **Core assumption:** Alignment procedures expose models to inclusive language norms underrepresented in raw web corpora.
- **Evidence anchors:** GPT-4o and Claude-4-Sonnet achieve 95%+ accuracy on most neopronouns in zero-shot, while DeepSeek-V3 and Qwen variants show substantial gaps.

## Foundational Learning

- **Concept: Neopronouns vs. Gender-Neutral vs. Binary Pronouns**
  - **Why needed here:** The benchmark evaluates three distinct categories with markedly different accuracy profiles.
  - **Quick check question:** Can you explain why "they/them" (gender-neutral) might be easier for models than "xe/xem" (neopronoun) despite both being non-binary?

- **Concept: In-Context Learning**
  - **Why needed here:** The zero-shot vs. few-shot comparison is the core experimental manipulation.
  - **Quick check question:** Why does adding 6 examples to a prompt improve accuracy without any model retraining?

- **Concept: Tokenization and Subword Fragmentation**
  - **Why needed here:** The paper references that neopronouns "are frequently tokenized into subword fragments by byte pair encoding," impairing representation.
  - **Quick check question:** How might "xe/xem" being tokenized as multiple tokens affect a model's ability to learn consistent usage patterns?

## Architecture Onboarding

- **Component map:** Pronoun Declaration -> Masked Template -> Grammatical Form Coverage -> Gender Identity Inference Module -> Mismatch Combinations
- **Critical path:** Parse pronoun declaration → Retrieve grammatical form → Generate pronoun OR infer identity → Handle name-pronoun conflicts
- **Design tradeoffs:** Template coverage vs. naturalness; balanced mismatches vs. real-world distribution; classification-only output vs. free generation
- **Failure signatures:** Reflexive and possessive-independent forms underperform (63.9% and 64.9% reflexive/possession-independent in zero-shot); neopronoun accuracy collapses without few-shot examples (DeepSeek-V3 achieves 1.4% on "e" zero-shot); name-based overrides in inference task
- **First 3 experiments:** 1) Reproduce zero-shot vs. few-shot delta on single pronoun type across two model families; 2) Ablate grammatical form by testing only nominative vs. only reflexive; 3) Extend mismatch analysis with neopronoun-name pairs using unisex names

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does the proportion of English-centric data in multilingual LLMs directly cause the observed performance deficits in nonbinary pronoun handling?
- **Basis in paper:** Section 6.1 hypothesizes that underperformance may stem from English data constituting a smaller portion of pretraining corpora.
- **Why unresolved:** The study establishes correlation but does not isolate training data composition as the causal variable versus other architectural or alignment differences.
- **What evidence would resolve it:** Ablation studies controlling for the ratio of English-to-non-English data during pre-training, specifically measuring the impact on neopronoun fidelity.

### Open Question 2
- **Question:** Can fine-tuning with augmented inclusive corpora enable generalization to *novel* neopronouns, or does it merely improve performance on explicitly memorized forms?
- **Basis in paper:** Section 6.2 proposes "Augmented Training with Inclusive Corpora" while noting persistent failures on "novel invented forms" suggest limitations in generalization.
- **Why unresolved:** It is unclear if data augmentation resolves the underlying syntactic generalization problem or if models still rely on statistical frequency of specific tokens.
- **What evidence would resolve it:** Evaluating models fine-tuned on specific neopronoun sets on entirely synthetic or "invented" neopronoun sets to test rule abstraction.

### Open Question 3
- **Question:** How can evaluation benchmarks effectively distinguish between syntactic correctness and social respectfulness in ambiguous identity contexts?
- **Basis in paper:** Section 6.2 identifies "Evaluation Ambiguity" as a key challenge, noting difficulty in assessing whether outputs are technically correct yet socially disrespectful.
- **Why unresolved:** Current metrics rely heavily on exact match accuracy, failing to capture the nuance of "socially respectful" language use when multiple pronouns might be syntactically permissible but socially loaded.
- **What evidence would resolve it:** Development of a standardized metric or human-annotated dataset that validates not just the pronoun case, but the appropriateness of the inference in context.

## Limitations
- Template-based design may