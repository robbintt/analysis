---
ver: rpa2
title: Investigating Fine- and Coarse-grained Structural Correspondences Between Deep
  Neural Networks and Human Object Image Similarity Judgments Using Unsupervised Alignment
arxiv_id: '2505.16419'
source_url: https://arxiv.org/abs/2505.16419
tags:
- human
- learning
- matching
- object
- representations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates how deep neural networks trained with different
  learning paradigms align with human object representations at both fine-grained
  and coarse-grained levels. Using an unsupervised alignment method based on Gromov-Wasserstein
  Optimal Transport, the researchers compared 27 DNN models across four learning paradigms
  (supervised, self-supervised, self-sup+sup, and CLIP) with human similarity judgments
  for 1,854 objects from the THINGS dataset.
---

# Investigating Fine- and Coarse-grained Structural Correspondences Between Deep Neural Networks and Human Object Image Similarity Judgments Using Unsupervised Alignment

## Quick Facts
- **arXiv ID:** 2505.16419
- **Source URL:** https://arxiv.org/abs/2505.16419
- **Reference count:** 40
- **Primary result:** CLIP models achieve 20% fine-grained matching with humans, outperforming other paradigms, while self-supervised models show 25% coarse-grained alignment

## Executive Summary
This study investigates how deep neural networks trained with different learning paradigms align with human object representations at fine-grained and coarse-grained levels. Using Gromov-Wasserstein Optimal Transport to align 27 DNN models with human similarity judgments for 1,854 objects, the researchers found that CLIP models (vision-language) achieved the strongest fine-grained alignment (20% top-1 matching), while self-supervised models failed at this level but showed modest coarse-grained alignment (25% category matching). The results demonstrate that linguistic information is crucial for precise object representations, while self-supervised learning can capture basic categorical structures without language, potentially modeling prelinguistic category formation in infants.

## Method Summary
The study compared 27 DNN models across four learning paradigms (supervised, self-supervised, self-sup+sup, and CLIP) with human similarity judgments from the THINGS dataset. Human representations were extracted using SPoSE embeddings from odd-one-out behavioral tasks. Model embeddings were obtained from final layers of ResNet/ViT architectures. Gromov-Wasserstein Optimal Transport with entropy regularization (ε ∈ [0.0001, 0.001]) was used to align human and model RDMs without external labels. Fine-grained alignment was measured by top-1 matching rate, while coarse-grained alignment used category matching rates. Hyperparameters were optimized using Optuna, with multiple random initializations to avoid local minima.

## Key Results
- CLIP models achieved 20% top-1 fine-grained matching with human similarity judgments
- Self-supervised models failed at fine-grained alignment but achieved 25% category matching
- Clustering analysis confirmed self-supervised models formed human-like coarse categories
- Supervised and self-sup+sup models showed intermediate performance between CLIP and self-supervised models

## Why This Works (Mechanism)

### Mechanism 1: Linguistic Information Drives Fine-Grained Alignment
Vision-language models (CLIP) and supervised models map visual features to semantic labels or text, enforcing representational geometry where semantically distinct objects are pulled apart, matching human semantic structure. Purely visual self-supervised models lack this external semantic anchor, causing embeddings to collapse onto visual similarity alone, failing to differentiate conceptually distinct but visually similar items. This assumes human similarity judgments are driven primarily by semantic knowledge rather than low-level visual features.

### Mechanism 2: GWOT Exposes Structural Differences
Unlike RSA, which computes a single correlation value assuming fixed correspondence, GWOT solves for optimal transport between distance matrices, explicitly testing if Object A in human space maps to Object A in model space (fine-grained) or merely to correct category (coarse-grained). This reveals the "resolution" of alignment obscured by previous methods. Assumes distance geometry is robust enough to guide meaningful mapping without external labels.

### Mechanism 3: Contrastive Learning Induces Coarse Categories
Contrastive objectives push apart augmented views of different images while pulling views of same image together, naturally clustering visually distinct high-level categories without requiring labels. This mimics perceptual grouping observed in infants before language acquisition. Assumes coarse categories in THINGS dataset are visually distinct enough to be separated by low/mid-level visual features alone.

## Foundational Learning

- **Concept: Representational Dissimilarity Matrices (RDMs)**
  - **Why needed here:** Fundamental data structure for comparing humans and models; entire paper rests on idea that RDM "shape" is fingerprint of representation
  - **Quick check question:** If two models have identical RDM correlations with human RDM via RSA, does this paper argue they have identical representations?

- **Concept: Gromov-Wasserstein Optimal Transport (GWOT)**
  - **Why needed here:** Specific tool to "align" human and model spaces; understand as "soft" matching algorithm finding best map between two clouds based on relative distances
  - **Quick check question:** Why does this paper use GWOT instead of simply correlating flattened upper-triangular vectors of RDMs (standard RSA)?

- **Concept: Fine-grained vs. Coarse-grained Alignment**
  - **Why needed here:** Paper's central thesis that "alignment" is not binary; model can be "aligned" in broad categories (coarse) but fail completely at specific object identification (fine)
  - **Quick check question:** A model maps specific "Golden Retriever" image to "Poodle" image. Is this failure of coarse alignment, fine alignment, or both?

## Architecture Onboarding

- **Component map:** Stimuli (1,854 THINGS objects) → Representation Extractors (Human: SPoSE from odd-one-out task → Human RDM; Model: DNN final layer → Model RDM) → Comparator (Gromov-Wasserstein OT) → Metrics (Fine-grained: Top-1 Matching Rate; Coarse-grained: Category Matching Rate)

- **Critical path:** Efficacy depends on hyperparameter tuning of GWOT entropy term (ε). If transport plan not optimized correctly, matching rate metrics are invalid.

- **Design tradeoffs:**
  - Entropy Regularization: Adds entropy (smoothes transport plan, making optimization faster and more stable) but potentially blurs sharp one-to-one mappings required for high fine-grained matching
  - RSA vs. GWOT: RSA is computationally cheap and standard but conflates coarse and fine structure; GWOT is computationally expensive but separates these scales

- **Failure signatures:**
  - "Chance-level" Matching: Rate hovering near 1/N (where N=1854) or random simulation baselines indicates model representation structurally incompatible with human one at that resolution
  - High RSA, Low GWOT: Indicates model gets "gist" (coarse categories) right but fails on specific object semantics (fine-grained)

- **First 3 experiments:**
  1. Baseline Verification: Replicate "Chance Level" simulation to confirm GWOT implementation doesn't hallucinate matches in random noise
  2. Ablation on Layers: Extract embeddings from intermediate layers to determine if fine-grained semantic alignment shifts deeper into network
  3. Visualization of Transport Plans: Replicate Figure 3d vs 3e; visual inspection of "diagonal" vs "scattered" transport plans is quickest sanity check to verify quantitative "Matching Rate" accurately reflects qualitative alignment

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Do self-supervised learning mechanisms in DNNs accurately mirror prelinguistic categorical formation processes observed in human infants?
- **Basis in paper:** Authors state in Section 4.1 that "Future research could directly test this by comparing model behavior with infant developmental data," building on suggestion that SSL mirrors how infants organize environments before language acquisition
- **Why unresolved:** Current study relied on adult human similarity judgments rather than developmental data from prelinguistic subjects
- **What evidence would resolve it:** Study directly comparing representational structures of self-supervised models against behavioral or neural data collected from infants during early visual category learning

### Open Question 2
- **Question:** To what extent do model architecture and training dataset size contribute to fine- and coarse-grained alignment, independent of learning paradigm?
- **Basis in paper:** Authors acknowledge in Section 4.3 that "high computational cost of Gromov-Wasserstein Optimal Transport limited number of models we could evaluate," rendering them "unable to systematically control for effects of architectural variations or dataset-specific factors"
- **Why unresolved:** Computational constraints prevented factorial analysis of architecture and data scale separate from learning objective
- **What evidence would resolve it:** Large-scale ablation study varying architectures and dataset sizes across fixed learning paradigms using same GWOT alignment metrics

### Open Question 3
- **Question:** Why does Masked Image Modeling (MAE) fail to capture coarse categorical structures that other self-supervised methods successfully capture?
- **Basis in paper:** In Sections 3.4 and 4, authors note that while contrastive SSL models showed above-chance coarse alignment, "MAE model... remains at chance level," highlighting "variations within self-supervised learning approaches" without definitive explanation
- **Why unresolved:** Paper documents performance gap but doesn't isolate representational cause for MAE's inability to form human-like coarse clusters
- **What evidence would resolve it:** Probing experiments to determine if MAE's focus on pixel-reconstruction hinders formation of invariant semantic features required for coarse category alignment

## Limitations
- GWOT entropy hyperparameter (ε) critically influences matching rates, but sensitivity analysis across full range is limited
- SPoSE model regularization term is underspecified, potentially affecting human embedding space geometry
- Fine-grained matching remains low (20% for CLIP) despite being best-performing paradigm, suggesting fundamental representational gaps persist

## Confidence

- **High Confidence:** Self-supervised models capture coarse categorical structure without linguistic information (validated by clustering AMI scores and category matching rates)
- **Medium Confidence:** Linguistic information is crucial for fine-grained alignment (based on CLIP vs self-supervised comparison, but alternative explanations like dataset scale remain unexplored)
- **Low Confidence:** Specific numerical alignment percentages reflect true representational similarity rather than GWOT optimization artifacts (requires extensive hyperparameter sensitivity testing)

## Next Checks

1. **Hyperparameter Sensitivity:** Systematically vary GWOT entropy regularization ε across full range with multiple random seeds to determine if matching rates are stable or optimization-dependent

2. **Layer-wise Analysis:** Extract embeddings from intermediate DNN layers to determine if fine-grained alignment improves at specific network depths, revealing where semantic processing emerges

3. **Visual Transport Plan Inspection:** Replicate and visually examine Figure 3d vs 3e for multiple model-human comparisons to confirm quantitative matching rates correspond to qualitatively meaningful one-to-one mappings