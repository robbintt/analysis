---
ver: rpa2
title: 'Segment to Focus: Guiding Latent Action Models in the Presence of Distractors'
arxiv_id: '2602.02259'
source_url: https://arxiv.org/abs/2602.02259
tags:
- latent
- action
- masklam
- distractors
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of learning latent action representations
  from unlabelled videos in visually complex environments. Existing approaches struggle
  to disentangle action-relevant features from action-correlated noise, such as background
  motion, leading to suboptimal latent action spaces.
---

# Segment to Focus: Guiding Latent Action Models in the Presence of Distractors

## Quick Facts
- **arXiv ID:** 2602.02259
- **Source URL:** https://arxiv.org/abs/2602.02259
- **Authors:** Hamza Adnan; Matthew T. Jackson; Alexey Zakharov
- **Reference count:** 17
- **Primary result:** MaskLAM achieves up to 3x better latent action quality (linear probe MSE) and 4x higher downstream control performance by using segmentation masks to focus latent action learning on agent dynamics, ignoring action-correlated background noise.

## Executive Summary
This paper tackles the challenge of learning latent action representations from unlabelled videos in visually complex environments. Existing approaches struggle to disentangle action-relevant features from action-correlated noise, such as background motion, leading to suboptimal latent action spaces. The proposed method, MaskLAM, is a lightweight modification that incorporates visual agent segmentation to weight the reconstruction loss, prioritizing salient information over background elements. It uses segmentation masks from pretrained foundation models to focus the learning of latent action models (LAMs) on agent-specific dynamics, effectively ignoring irrelevant visual changes. Experiments on continuous-control MuJoCo tasks modified with action-correlated background noise demonstrate that MaskLAM significantly improves latent action quality, as evidenced by up to a 3x improvement in linear probe evaluation. It also yields up to a 4x increase in downstream control performance compared to standard baselines, while requiring no architectural modifications.

## Method Summary
MaskLAM modifies the reconstruction objective of latent action models by element-wise multiplying the reconstruction loss with a binary segmentation mask. This masks out background pixels during training, forcing the model to focus on agent dynamics. The method uses SAM 2.1-hiera-tiny to generate segmentation masks from video frames, requiring only a bounding box initialization on the first frame. The modified loss is: L = ||M_{t+1} ⊙ (o_{t+1} - ô_{t+1})||². The approach is tested on Distracting Control Suite environments with action-correlated background noise, showing significant improvements in latent action quality and downstream control performance while requiring no architectural changes to existing LAM frameworks.

## Key Results
- **3x improvement** in linear probe evaluation (MSE between latent actions and ground-truth actions)
- **4x increase** in downstream control performance (normalized returns) compared to standard baselines
- **Significant compression benefit**: MaskLAM achieves higher evaluation returns and lower linear probe MSE with a 64-dimensional latent action space than LAPO achieves with an 8192-dimensional space

## Why This Works (Mechanism)

### Mechanism 1: Gradient Isolation via Spatial Loss Masking
- **Claim:** Zeroing reconstruction loss on background pixels prevents gradient flow for non-agent features.
- **Mechanism:** The binary mask Mt+1 is element-wise multiplied with the pixel-wise reconstruction error before backpropagation. Where Mt+1=0, the loss contribution is zero, so no gradients propagate to update encoder weights for those spatial regions. The encoder therefore receives no training signal to preserve background information.
- **Core assumption:** Action-relevant visual changes are spatially concentrated in agent-occupied regions; background changes are action-correlated noise rather than control-relevant signals.
- **Evidence anchors:**
  - [Section 4]: "Since the loss is zeroed out for background pixels, there are no longer gradients corresponding to environmental visual features. As such, the encoder receives no feedback signal to preserve background information."
  - [Section 4]: "Crucially, the masking operation alters the gradient landscape during backpropagation."
  - [corpus]: Related work (LAOF, Object-Centric Latent Action Learning) confirms distractor sensitivity is an active research problem, though different solutions are proposed.
- **Break condition:** If agent dynamics critically depend on background elements (e.g., tracking moving objects), the mask may over-prune relevant information.

### Mechanism 2: Implicit Information Bottleneck Compression
- **Claim:** The masked objective creates a tighter effective bottleneck, requiring fewer latent dimensions to capture action-relevant information.
- **Mechanism:** Standard LAMs must encode all pixel variation (including distractors) to minimize global reconstruction. The masked objective reduces the variance the latent must explain, allowing smaller latent spaces to capture agent dynamics without background noise entanglement.
- **Core assumption:** The ground-truth action space is lower-dimensional than full visual dynamics; distractors add spurious dimensions.
- **Evidence anchors:**
  - [Section 6.2]: "MaskLAM attains both higher evaluation returns and a lower linear probe MSE with a 64-dimensional latent action space than LAPO achieves with an 8192-dimensional space."
  - [Section 6.2]: "MaskLAM learns more action-aligned representations using significantly more compact latent action spaces."
  - [corpus]: "What Do Latent Action Models Actually Learn?" (arxiv 2506.15691) raises the question of whether latents capture controllable changes vs. noise—this paper provides empirical evidence for the compression benefit.
- **Break condition:** If the latent dimension is set too low even for agent dynamics, the bottleneck may underfit. The paper shows robustness across dimensions [64, 8192], but lower bounds are task-dependent.

### Mechanism 3: Inductive Bias Toward Agent Morphology
- **Claim:** Weighting reconstruction toward agent regions encodes a structural prior that latent actions should explain proprioceptive-like changes.
- **Mechanism:** The paper argues that motor control signals have "immediate and direct causal influence over the agent's own visual state" whereas environmental changes are "secondary or sparse." By forcing the latent to explain only agent-region transitions, the model learns representations more aligned with ground-truth control signals.
- **Core assumption:** Agent motion is the primary causal factor for visual changes in agent-occupied pixels; distractors are spatiotemporally correlated but not causally linked to actions.
- **Evidence anchors:**
  - [Section 4]: "Motor control signals exercise immediate and direct causal influence over the agent's own visual state (e.g., robot's joint articulation via applied torques), whereas environmental changes are often secondary or sparse."
  - [Section 6.2]: Linear probe MSE is lower for MaskLAM across all environments, indicating better alignment with ground-truth actions.
  - [Section 6.2/Section 8 OOD]: MaskLAM generalizes better to out-of-distribution distractors, suggesting the latent captures action-relevant features rather than memorizing specific background correlations.
  - [corpus]: "Latent Action Learning Requires Supervision in the Presence of Distractors" (arxiv 2502.00379) confirms LAPO struggles with action-correlated noise; MaskLAM provides a lightweight alternative to supervision.
- **Break condition:** If background elements are causally relevant to the task (e.g., navigating around obstacles), the mask may remove necessary context. The paper tests locomotion tasks where this assumption holds; manipulation or navigation tasks may differ.

## Foundational Learning

- **Concept: Latent Action Models (LAMs)**
  - **Why needed here:** MaskLAM is a modification to LAM training. Without understanding that LAMs learn an inverse dynamics model (IDM) to map observation pairs to latent actions and a forward dynamics model (FDM) to predict the next observation, the weighted loss modification will not make sense.
  - **Quick check question:** Given two consecutive frames ot and ot+1, what does the IDM predict, and what does the FDM predict given ot and the latent zt?

- **Concept: Reconstruction Objectives in Pixel Space**
  - **Why needed here:** The core intervention changes the reconstruction loss from global MSE to masked MSE. Understanding why pixel-space reconstruction forces encoding of distractors (global objective liability) is essential to grasp the motivation.
  - **Quick check question:** Why would a global MSE reconstruction objective cause a model to encode background motion even if it's irrelevant to control?

- **Concept: Foundation Models for Segmentation (SAM Family)**
  - **Why needed here:** MaskLAM relies on pre-computed segmentation masks from SAM 2.1. Understanding that these are zero-shot, require minimal initialization (bounding box or text prompt), and can be run efficiently is critical for practical deployment.
  - **Quick check question:** What minimal supervision does SAM 2.1 require to track an agent through a video, and can this be automated?

## Architecture Onboarding

- **Component map:**
  - IDM (Inverse Dynamics Model) -> Convolutional residual encoder -> Linear bottleneck (latent action zt ∈ Rd)
  - FDM (Forward Dynamics Model) -> Transpose convolutions
  - Segmentation Module (external) -> SAM 2.1-hiera-tiny -> Binary masks Mt+1
  - BC Policy -> Residual encoder + 3-layer MLP decoder -> Latent action prediction
  - Action Decoder (lightweight) -> MLP trained on small labeled subset -> Maps zt → ground-truth action at

- **Critical path:**
  1. Pre-compute segmentation masks for all training frames using SAM (one-time cost)
  2. Train LAM with masked reconstruction: L = ||Mt+1 ⊙ (ot+1 − ôt+1)||²
  3. Use trained IDM to label large unlabeled dataset with latent actions
  4. Train BC policy on (ot, zt) pairs
  5. Train action decoder on small labeled subset to map z → a
  6. Deploy: BC policy predicts z, decoder maps to executable a

- **Design tradeoffs:**
  - SAM model size vs. speed: The paper uses SAM 2.1-hiera-tiny (38.9M params, 91.5 FPS on A100). Larger models may give better masks but slower pre-computation.
  - Latent dimension: MaskLAM works well with smaller dimensions (64–1024) vs. LAPO's need for 8192. Smaller is more efficient but may underfit complex morphologies.
  - Mask quality dependency: Noisy or inaccurate masks (e.g., partial agent coverage) will degrade performance. The paper notes this as a limitation in highly cluttered scenes.
  - Frame stack size: The paper uses frame stack = 1 (single observation pair), unlike prior work using 3. This prevents exploiting future information but may reduce temporal context.

- **Failure signatures:**
  - High linear probe MSE despite masking: Suggests masks are not isolating agent regions effectively (check visualization of masks)
  - Blurred agent in FDM reconstructions: If the agent (not just background) is blurry, the mask may be too aggressive or latent dimension too low
  - OOD performance collapse: If masks overfit to training backgrounds, OOD generalization may suffer (though paper shows improved OOD robustness)
  - No improvement over baseline in Walker-like environments: If the agent already occupies most of the frame, global vs. masked objectives converge (diminishing returns)

- **First 3 experiments:**
  1. **Sanity check with clean data:** Train MaskLAM on distractor-free MuJoCo data and compare to LAPO. Expect near-identical performance to verify the modification introduces no regression when distractors are absent.
  2. **Ablation on mask quality:** Manually corrupt masks (e.g., dilate/erode, add random noise) and measure linear probe MSE and downstream returns. This quantifies robustness to segmentation errors.
  3. **Latent dimension sweep:** Train MaskLAM and LAPO across d ∈ {64, 256, 1024, 8192} on a single environment (e.g., HalfCheetah with distractors). Plot probe MSE and returns to confirm the compression benefit and identify the minimal viable dimension for your compute budget.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How robust is MaskLAM to inaccuracies in the segmentation masks generated by foundation models?
- Basis in paper: [explicit] The limitations section notes that "inaccuracies or inconsistencies in these zero-shot masks can propagate into the training signal," potentially reducing performance in cluttered scenes.
- Why unresolved: The experiments utilize controlled MuJoCo environments where the agent is distinct; the sensitivity of the gradient masking to mask noise (false positives/negatives) is not quantified.
- What evidence would resolve it: Evaluation on datasets with synthetic mask noise or highly cluttered real-world scenes where segmentation models struggle with occlusion.

### Open Question 2
- Question: Can the method be adapted to feature-space reconstruction to mitigate the drawbacks of pixel-level objectives?
- Basis in paper: [explicit] The authors list "sensitivity to high-frequency noise or computational cost" as limitations of the pixel-level reconstruction dependency.
- Why unresolved: It is unclear if the spatial weighting logic transfers effectively to latent spaces (e.g., embedding reconstruction) used in methods like LAOM, which avoid pixel-space issues.
- What evidence would resolve it: A hybrid implementation using perceptual losses or feature-metric error terms, comparing performance and training efficiency against the pixel-based baseline.

### Open Question 3
- Question: Why does MaskLAM fail to fully recover the upper-bound performance of the distractor-free oracle?
- Basis in paper: [explicit] The limitations section states that while performance gaps are narrowed, the method "does not fully recover the upper-bound performance."
- Why unresolved: It is undetermined if the residual gap stems from the masking loss ignoring useful context, artifacts in the SAM masks, or limitations in the underlying LAPO architecture.
- What evidence would resolve it: Ablation studies analyzing the latent space geometry of MaskLAM versus the oracle to identify remaining entanglements or information loss.

## Limitations
- **Segmentation quality dependency:** The method's performance critically depends on the quality and coverage of segmentation masks, with inaccuracies potentially propagating into the training signal.
- **Task applicability constraint:** The assumption that background changes are always action-correlated noise may not hold in navigation or manipulation tasks where environmental context is causally relevant to the action space.
- **Partial performance recovery:** While MaskLAM narrows performance gaps, it does not fully recover the upper-bound performance of the distractor-free oracle, suggesting residual information loss or architectural limitations.

## Confidence
- **High confidence:** The core mechanism of gradient isolation via spatial loss masking is well-supported by the ablation showing that removing the mask eliminates the performance gain.
- **Medium confidence:** The information bottleneck compression benefit is demonstrated empirically but could be further validated with theoretical analysis of the effective dimensionality reduction.
- **Medium confidence:** The generalization to out-of-distribution distractors is promising but tested on limited distractor variations; more diverse OOD scenarios would strengthen this claim.

## Next Checks
1. **Ablation on mask quality:** Systematically degrade mask quality (through dilation, erosion, or noise addition) and measure the impact on linear probe MSE and downstream returns to quantify robustness to segmentation errors.
2. **Task dependency test:** Apply MaskLAM to a navigation task where background elements (obstacles) are causally relevant to the action space, to identify break conditions for the core assumption.
3. **Real-robot transfer:** Validate the approach on a real robot with dynamic backgrounds (e.g., varying lighting, moving people) to assess practical deployment challenges beyond simulated distractors.