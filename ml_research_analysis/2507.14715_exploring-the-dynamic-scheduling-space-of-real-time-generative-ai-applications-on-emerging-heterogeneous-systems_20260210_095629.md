---
ver: rpa2
title: Exploring the Dynamic Scheduling Space of Real-Time Generative AI Applications
  on Emerging Heterogeneous Systems
arxiv_id: '2507.14715'
source_url: https://arxiv.org/abs/2507.14715
tags:
- scheduling
- real-time
- workloads
- rtgen
- deadline
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the challenge of scheduling real-time generative\
  \ AI (RTGen) workloads on heterogeneous systems-on-chip (SoCs) that integrate CPUs,\
  \ GPUs, and NPUs. The authors characterize RTGen workloads inspired by real-world\
  \ applications such as video conferencing and gaming, profiling model performance\
  \ across all available backends on AMD\u2019s Ryzen AI."
---

# Exploring the Dynamic Scheduling Space of Real-Time Generative AI Applications on Emerging Heterogeneous Systems

## Quick Facts
- arXiv ID: 2507.14715
- Source URL: https://arxiv.org/abs/2507.14715
- Reference count: 40
- Primary result: Scheduling decisions significantly impact RTGen performance, with a 41.7% difference in deadline violation rates across policies

## Executive Summary
This paper addresses the challenge of scheduling real-time generative AI (RTGen) workloads on heterogeneous systems-on-chip (SoCs) that integrate CPUs, GPUs, and NPUs. The authors characterize RTGen workloads inspired by real-world applications such as video conferencing and gaming, profiling model performance across all available backends on AMD's Ryzen AI. They evaluate five scheduling policies—including deadline-aware, dynamic, and GenAI-aware approaches—using a runtime simulator. Results show that scheduling decisions significantly impact performance, with a 41.7% difference in deadline violation rates observed across policies. The study highlights the need for workload-aware, dynamic heterogeneous scheduling strategies to meet the diverse demands of RTGen applications.

## Method Summary
The study profiles Llama3-1B (LLM), GTE Encoder (RAG), PointPainting (segmentation), RCAN (super-resolution), and YOLOv3 (object detection) models on AMD Ryzen AI 9 365 using RyzenAI SW with ONNX Runtime. Models are quantized via AWQ (INT4 for LLMs, INT8 for CNNs, BFloat16/Float16 for encoder). The researchers construct a latency database capturing prefill/decode latencies across varying sequence lengths (16-4096) for each backend. A Python runtime simulator implements five scheduling policies (FCFS-AOT, FCFS-DYN, EDF-AOT, EDF-DYN, FTF) and evaluates them across four RTGen scenarios with 100+ inference cycles each, measuring deadline violation rates, TTFT, and TPT.

## Key Results
- NPU excels at compute-intensive prefill (3.0× faster than GPU), while GPU excels at memory-intensive decode (7.5× faster than NPU)
- Dynamic scheduling reduces deadline violations from 99.5% to 0.5% in certain scenarios compared to static assignment
- GenAI-aware scheduling (FTF) prevents LLM starvation under EDF while maintaining real-time constraints better than FCFS
- Scheduling decisions impact deadline violation rates by up to 41.7% across evaluated policies

## Why This Works (Mechanism)

### Mechanism 1
Heterogeneous backend selection improves RTGen performance because compute-bound and memory-bound workload stages prefer different accelerators. NPU excels at compute-intensive prefill (3.0× faster than GPU); GPU excels at memory-intensive decode (7.5× faster than NPU). Stage-aware mapping reduces latency. Core assumption: Profiling data accurately reflects runtime behavior under concurrent multi-model execution. Evidence: NPU is better suited for compute-bound workloads while the GPU is more suited for memory/BW-bound workloads on our evaluated system; Hybrid Learning and Optimization-Based Dynamic Scheduling confirms heterogeneity challenges in GPU clusters.

### Mechanism 2
Dynamic hardware selection reduces deadline violations compared to ahead-of-time static assignment by adapting to runtime backend availability. FCFS-DYN checks hardware availability at scheduling time and dispatches to the best available backend, reducing SR-60 deadline violations from 99.5% to 0.5%. Core assumption: Backend availability variability is the primary cause of deadline misses under static scheduling. Evidence: Switching to FCFS-DYN that dynamically schedule layers on the best available HW decreases the deadline violation rate to 39.9%; Adaptive Request Scheduling for CodeLLM Serving similarly uses SLA-aware adaptive scheduling.

### Mechanism 3
GenAI-aware scheduling (treating TTFT as high-priority deadline) prevents LLM starvation under EDF while maintaining real-time constraints better than FCFS. EDF starves LLMs because single-layer latency (98.62ms) exceeds frame duration (16.67ms). FTF prioritizes first-token generation, then falls back to EDF for decode stage where latencies are comparable to other models. Core assumption: Users perceive TTFT as more critical than TPT for interactive RTGen applications. Evidence: EDF consistently prioritizes the model with the closest deadline, preempting LLM execution... leading to starvation; FTF does not starve the LLM, achieves a TTFT that matches the standalone performance.

## Foundational Learning

- **LLM Inference Stages (Prefill vs Decode)**
  - Why needed here: Backend preference differs between stages—understanding this is prerequisite to stage-aware scheduling.
  - Quick check question: For a prompt with 512 input tokens generating 100 output tokens, which stage runs more iterations and which is memory-bound?

- **Real-Time Scheduling Fundamentals (EDF, FCFS, Deadline Awareness)**
  - Why needed here: The paper evaluates five policies built on these foundations; understanding trade-offs enables policy selection.
  - Quick check question: Under EDF, what happens when a task's execution time exceeds the minimum inter-arrival time of higher-priority tasks?

- **Heterogeneous SoC Architecture (CPU/GPU/NPU Characteristics)**
  - Why needed here: Backend selection requires knowing that NPU optimizes for throughput/compute, GPU for parallelism/memory-bandwidth.
  - Quick check question: Given a CNN layer and a memory-bandwidth-bound attention decode operation, which backend would you select for each?

## Architecture Onboarding

- **Component map**: Inference Generator -> Request Queue -> Scheduler Engine (Priority Policy + Cost Estimation + HW Availability Checker) -> Backend Dispatch (CPU/GPU/NPU) -> Latency DB
- **Critical path**: 1. Profile all models on all backends (prefill/decode separately for LLMs) 2. Construct latency database with input-length-dependent entries 3. At runtime: dequeue request → estimate cost → check HW availability → apply scheduling policy → dispatch
- **Design tradeoffs**: FTF vs FCFS: FTF reduces deadline violations by 47.8% vs FCFS but increases TPT by 5.7× to 7.4×; Dynamic vs Static: Dynamic selection adapts to availability but may increase TPT under contention (95.1% decode layers offloaded to NPU for short sequences); EDF vs LLM-fairness: EDF guarantees real-time deadlines but starves LLMs entirely
- **Failure signatures**: LLM starvation: Under EDF, LLM TTFT becomes infinite—preemption exceeds layer latency; Short-sequence TPT spike: For 32-64 token inputs, 95.1% decode layers dispatch to slow NPU backend due to prefill-induced availability shifts; Deadline cascade: When prefill occupies NPU for long sequences (2048 tokens), deadline violations increase from 1.7% to 10.7%
- **First 3 experiments**: 1. Baseline profiling: Measure SR, Seg, OD on CPU/GPU/NPU; measure LLM prefill and decode separately across sequence lengths 16-4096 on GPU and NPU. Confirm NPU prefill advantage and GPU decode advantage. 2. Policy comparison under Scenario C (Gaming II): Run all five schedulers for 60-second simulation. Record deadline violation rate per model, TTFT, and TPT. Verify FTF achieves <45% deadline violation while maintaining finite TTFT. 3. Sequence length sensitivity: Run Scenario D with input lengths 32, 256, 1024, 2048 under FTF. Confirm deadline violation scaling and identify TPT crossover point where NPU offloading becomes beneficial.

## Open Questions the Paper Calls Out

- **Open Question 1**: How can schedulers mitigate the severe Time-Per-Token (TPT) degradation observed in GenAI-aware policies (like FTF) while maintaining low deadline violation rates? The authors note that while the FTF scheduler improved deadline violations, "the TPT significantly increases... 5.7× [and] 7.4×" and conclude that "These findings underscore the need for a workload-aware scheduler that dynamically adapts."

- **Open Question 2**: How can runtime schedulers efficiently account for dynamic input shapes (e.g., prompt length) that alter the optimal backend preference in real-time? The paper observes that backend suitability shifts with sequence length and that "static ahead-of-time (AoT) input-unaware scheduling will fail."

- **Open Question 3**: What are the performance impacts of system overheads, such as context switching and memory migration, on RTGen scheduling policies in real-world deployments? The study utilizes a "Python-level simulator" driven by profiled latency data that does not account for data movement overheads between CPU, GPU, and NPU memory spaces or preemption costs during dynamic switching.

## Limitations
- Study focuses on a single hardware platform (AMD Ryzen AI 9 365) and specific model configurations
- Simulator-based evaluation cannot capture real-world contention patterns, thermal throttling effects, or non-deterministic runtime variations
- Profiling methodology assumes static latency relationships across sequence lengths, which may not hold for different model architectures or quantization schemes

## Confidence
- **High confidence**: The core observation that heterogeneous backends exhibit complementary strengths (NPU for compute-bound prefill, GPU for memory-bound decode) is well-supported by the profiling data and aligns with architectural expectations
- **Medium confidence**: The comparative policy evaluation results are internally consistent but rely on simulator assumptions that may not generalize to real deployment scenarios
- **Medium confidence**: The claim that dynamic scheduling reduces deadline violations by adapting to backend availability is supported by specific numerical improvements but depends on the accuracy of the simulator's contention modeling

## Next Checks
1. **Hardware validation**: Implement the FTF scheduler on actual AMD Ryzen AI 9 365 hardware and measure real-world deadline violation rates, TTFT, and TPT across the same scenarios
2. **Cross-platform generalization**: Profile the same models on different heterogeneous SoCs (e.g., Intel Meteor Lake, Apple M-series) to verify if the NPU-GPU specialization pattern holds across architectures
3. **Robustness to model variation**: Test scheduling policies with different LLM architectures (Mistral, Gemma) and quantization schemes to determine if backend preferences remain consistent when model parameters change