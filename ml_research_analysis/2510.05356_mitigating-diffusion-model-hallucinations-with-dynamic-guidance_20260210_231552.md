---
ver: rpa2
title: Mitigating Diffusion Model Hallucinations with Dynamic Guidance
arxiv_id: '2510.05356'
source_url: https://arxiv.org/abs/2510.05356
tags:
- guidance
- dynamic
- hallucinations
- score
- samples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Diffusion models often generate hallucinatory samples with structural
  inconsistencies that lie outside the true data distribution, arising from excessive
  smoothing between modes. Dynamic Guidance mitigates these hallucinations by selectively
  sharpening the score function only along pre-determined directions known to cause
  artifacts, while preserving valid semantic variations.
---

# Mitigating Diffusion Model Hallucinations with Dynamic Guidance

## Quick Facts
- **arXiv ID**: 2510.05356
- **Source URL**: https://arxiv.org/abs/2510.05356
- **Reference count**: 19
- **Primary result**: Dynamic Guidance reduces diffusion model hallucinations by at least 50% through selective score sharpening along artifact-causing directions

## Executive Summary
Diffusion models frequently generate hallucinatory samples that exhibit structural inconsistencies by smoothing between modes in the data distribution. Dynamic Guidance addresses this fundamental problem by selectively sharpening the score function only along pre-determined directions known to cause artifacts, while preserving valid semantic variations. Unlike static guidance methods that apply uniform corrections, Dynamic Guidance adaptively chooses guidance targets at each denoising step using a noisy-sample classifier, making it the first approach to address hallucinations during generation rather than through post-hoc filtering.

The method demonstrates significant improvements on both controlled datasets and ImageNet, achieving at least 50% reduction in hallucinations even with few-step DDIM sampling. By improving precision and Inception Score on ImageNet, Dynamic Guidance outperforms static guidance baselines while maintaining the creative flexibility of diffusion models.

## Method Summary
Dynamic Guidance mitigates diffusion model hallucinations by implementing a selective sharpening mechanism that targets only artifact-causing directions in the score function. The approach uses a noisy-sample classifier to adaptively select guidance targets at each denoising step, rather than committing to fixed conditions as in traditional classifier-free guidance. This dynamic selection allows the model to sharpen along problematic directions while preserving valid semantic variations. The method is evaluated on controlled datasets where hallucination modes are pre-defined, as well as on ImageNet, demonstrating significant reductions in hallucinatory outputs even with few-step DDIM sampling.

## Key Results
- Reduces hallucinations by at least 50% on controlled datasets with pre-defined hallucination modes
- Improves precision and Inception Score on ImageNet compared to static guidance baselines
- Maintains effectiveness with few-step DDIM sampling, enabling faster generation
- First approach to address hallucinations during generation rather than through post-hoc filtering

## Why This Works (Mechanism)
The method works by selectively sharpening the score function only along pre-determined directions known to cause hallucinations, rather than applying uniform corrections across all dimensions. This selective approach prevents the loss of valid semantic variations that would occur with aggressive smoothing. The adaptive guidance target selection at each denoising step allows the model to respond dynamically to the current state of the sample being generated, focusing computational effort where it's most needed. By addressing hallucinations during the generation process itself, Dynamic Guidance prevents the propagation of artifacts that would otherwise require costly post-generation filtering.

## Foundational Learning
- **Diffusion model score matching**: Understanding how diffusion models learn to denoise samples by estimating gradients of log-density
  - Why needed: Core mechanism being modified by selective sharpening
  - Quick check: Can explain how score functions guide denoising steps

- **Classifier-free guidance**: Understanding static guidance approaches that mix conditional and unconditional predictions
  - Why needed: Current state-of-the-art baseline being improved upon
  - Quick check: Can describe trade-offs between guidance scale and sample quality

- **DDIM sampling**: Understanding deterministic sampling variants that reduce generation steps
  - Why needed: Method shows effectiveness with few-step sampling
  - Quick check: Can explain how DDIM differs from stochastic sampling

- **Hallucination modes**: Understanding structural inconsistencies in generated samples
  - Why needed: Target problem being addressed
  - Quick check: Can identify common types of diffusion model artifacts

- **Noisy-sample classification**: Understanding how classifiers work with intermediate noisy representations
  - Why needed: Key component for adaptive guidance selection
  - Quick check: Can explain how noise affects classifier performance

## Architecture Onboarding

Component map:
Noisy sample -> Classifier -> Guidance direction selector -> Score function modifier -> Denoiser -> Generated sample

Critical path:
The critical path flows from the noisy sample through the classifier to determine guidance directions, which then modify the score function before it reaches the denoiser. This path must execute efficiently at each denoising step to maintain generation speed.

Design tradeoffs:
- Selective vs. uniform sharpening: Selective sharpening preserves semantic diversity but requires accurate hallucination detection
- Adaptive vs. fixed guidance: Adaptive selection responds to sample state but adds computational overhead
- Classifier complexity vs. speed: More sophisticated classifiers improve guidance but slow generation

Failure signatures:
- Over-sharpening in non-problematic directions leading to loss of valid variations
- Misclassification of valid semantic variations as hallucinations
- Computational bottleneck at guidance direction selection step

Three first experiments:
1. Ablation study comparing selective vs. uniform sharpening on controlled hallucination datasets
2. Runtime analysis of adaptive guidance selection overhead across different classifier architectures
3. Sensitivity analysis of guidance scale parameters on hallucination reduction vs. semantic diversity

## Open Questions the Paper Calls Out
The paper acknowledges that its claims about being the "first approach to address hallucinations during generation" may overlook prior work on classifier-free guidance variations that implicitly handle similar issues. The method's effectiveness on diverse, real-world datasets with ambiguous or complex distributions remains uncertain, as current evaluations focus on controlled environments and ImageNet. The trade-off between hallucination reduction and potential loss of valid semantic diversity requires further exploration, as does the impact of classifier biases on guidance selection accuracy.

## Limitations
- Claims of 50% hallucination reduction rely heavily on controlled datasets with pre-defined hallucination modes
- Generalizability to complex real-world distributions beyond ImageNet remains unproven
- Potential trade-off between hallucination reduction and loss of valid semantic diversity not thoroughly explored
- Adaptive guidance selection may introduce computational overhead affecting generation speed

## Confidence
- Hallucination reduction on controlled datasets: **High** - Clear ground truth for detection
- ImageNet results: **Medium** - Indirect metrics (precision, Inception Score) rather than direct hallucination detection
- Generalizability claims: **Low** - Limited testing on diverse real-world datasets
- Computational efficiency claims: **Medium** - Runtime analysis not fully detailed

## Next Checks
1. Test Dynamic Guidance on diverse, real-world datasets with ambiguous or complex distributions to assess robustness beyond controlled environments
2. Conduct ablation studies isolating the contribution of adaptive guidance selection versus the sharpening mechanism itself
3. Evaluate the impact on semantic diversity metrics to ensure hallucination reduction doesn't come at the cost of creative variation