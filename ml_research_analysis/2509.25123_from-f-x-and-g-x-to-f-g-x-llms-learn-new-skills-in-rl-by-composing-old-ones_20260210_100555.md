---
ver: rpa2
title: 'From $f(x)$ and $g(x)$ to $f(g(x))$: LLMs Learn New Skills in RL by Composing
  Old Ones'
arxiv_id: '2509.25123'
source_url: https://arxiv.org/abs/2509.25123
tags:
- level
- func
- string
- skills
- compositional
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether reinforcement learning (RL) can
  teach large language models (LLMs) genuinely new skills by composing existing ones.
  The authors construct a synthetic framework using string transformation prediction
  tasks, where atomic skills are defined as single transformations and compositional
  skills as their nested combinations.
---

# From $f(x)$ and $g(x)$ to $f(g(x))$: LLMs Learn New Skills in RL by Composing Old Ones

## Quick Facts
- arXiv ID: 2509.25123
- Source URL: https://arxiv.org/abs/2509.25123
- Authors: Lifan Yuan; Weize Chen; Yuchen Zhang; Ganqu Cui; Hanbin Wang; Ziming You; Ning Ding; Zhiyuan Liu; Maosong Sun; Hao Peng
- Reference count: 40
- Primary result: RL on compositional data enables LLMs to learn new compositional skills that generalize to unseen compositions and higher difficulty levels

## Executive Summary
This paper demonstrates that reinforcement learning can teach large language models genuinely new compositional skills by combining existing atomic capabilities. Through synthetic string transformation tasks, the authors show that RL on compositional problems (Level-2) enables models to generalize to unseen compositions at higher difficulty levels (Level-3+), achieving 30% accuracy versus near-zero for supervised fine-tuning. The compositional skills learned through RL transfer to different tasks when atomic skills are present, and behavioral analysis reveals RL fundamentally changes reasoning patterns by eliminating compositional errors and shifting failures to atomic execution.

## Method Summary
The authors use a two-stage training approach on Llama-3.1-8B-Instruct: Stage 1 applies rejection fine-tuning (RFT) on atomic transformation problems to learn base skills, then Stage 2 applies RL (DAPO) on compositional problems with binary correctness rewards. The synthetic tasks use meaningless function identifiers (e.g., func_16) to prevent contamination. Evaluation uses pass@k metrics on held-out function compositions across difficulty levels 1-8, with failure mode analysis to distinguish compositional from atomic errors.

## Key Results
- RL on compositional data (Level-2) improves accuracy from near-zero to 30% on unseen Level-3 problems and from 1% to 15% on Level-4 problems
- RL on atomic data alone fails to generalize to compositional tasks
- Compositional skills learned via RL transfer to different tasks (Countdown) when target task has required atomic skills
- RL fundamentally changes failure modes, eliminating compositional errors and shifting failures to atomic-level execution

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** RL on compositional problems teaches models to systematically combine atomic skills, generalizing to unseen compositions at higher difficulty levels
- **Mechanism:** Binary outcome rewards on Level-2 compositions force the model to discover compositional reasoning strategies. Unlike next-token prediction, which learns surface patterns, RL's sparse reward signal incentivizes the model to develop a generalizable "composition operator" that applies regardless of which specific atomic functions are involved
- **Core assumption:** Atomic skills are already internalized from Stage-1 training, so RL can focus purely on learning composition rather than simultaneously acquiring base capabilities
- **Evidence anchors:**
  - [abstract] "RL on compositional data led to substantial improvements on held-out tasks: from near-zero accuracy on Level 3 problems to 30%, and from 1% to 15% on Level 4"
  - [Section 4.1] Fig. 2 shows RL Level-2 training generalizes to Level 3-6 while RL Level-1 does not
- **Break condition:** If atomic skills are insufficiently learned in Stage 1, RL cannot bootstrap composition—the model lacks building blocks to combine

### Mechanism 2
- **Claim:** Compositional skills learned via RL transfer across tasks when the target task's atomic skills are already present
- **Mechanism:** RL learns a meta-skill for composition that is task-agnostic. Once the model learns how to chain operations on string transformations, it applies the same compositional reasoning pattern to Countdown math problems. Critically, the target task's atomic skills must exist as prerequisites—composition alone cannot substitute for missing base knowledge
- **Core assumption:** Composition is a transferable reasoning pattern, not task-specific procedural knowledge
- **Evidence anchors:**
  - [abstract] "compositional skill acquired on a source task transfers to a different target task. This transfer happens even without compositional training on the target, requiring only prior knowledge of the target's atomic skills"
  - [Section 4.3] Fig. 4 shows Multi-Base + RL L1+2 achieves 35% on Countdown Level-3 vs. 17% for Multi-Base baseline
- **Break condition:** Transfer fails if target task lacks atomic prerequisites—the String-Base + RL L1+2 model fails completely on Countdown despite having compositional skills

### Mechanism 3
- **Claim:** RL fundamentally transforms reasoning behavior by eliminating compositional errors and shifting failures to atomic execution
- **Mechanism:** RL training creates internal representations that properly parse nested function structure. Pre-RL models predominantly fail by ignoring composition (>50%) or misinterpreting nesting relationships (>35%). Post-RL models correctly decompose problems into sequential atomic operations, with remaining failures caused by errors in executing individual atomic functions rather than misunderstanding the compositional structure itself
- **Core assumption:** The shift in failure modes indicates genuine skill acquisition rather than memorization or output reweighting
- **Evidence anchors:**
  - [abstract] "RL fundamentally changed failure modes—reducing compositional errors and shifting failures to atomic-level execution"
  - [Section 4.5] Fig. 6 shows RL Level-2 eliminates "Ignores Composition" errors entirely; primary failure becomes "Atomic Error" (55%)
- **Break condition:** If evaluation uses mixed-difficulty benchmarks without isolating compositional skill, this behavioral shift may be masked in aggregate metrics

## Foundational Learning

- **Concept: Atomic vs. Compositional Skills**
  - **Why needed here:** The entire framework depends on cleanly separating base capabilities (Level-1 functions like `remove_vowels`) from compositional reasoning (chaining functions). Without this distinction, you cannot attribute improvements to skill acquisition vs. activation
  - **Quick check question:** Can you decompose `func_2(func_16(func_7(x)))` into three distinct operations that could each be trained independently?

- **Concept: Pass@k Analysis for Skill Acquisition Detection**
  - **Why needed here:** The paper uses pass@k curves to distinguish reranking (gap shrinks as k increases on easy problems) from genuine skill acquisition (gap grows on hard problems where base model fails)
  - **Quick check question:** If a base model achieves pass@1000 = 0.05 and an RL model achieves pass@1000 = 0.30 on the same task, what does this suggest about skill acquisition vs. reranking?

- **Concept: Synthetic Task Design for Contamination Control**
  - **Why needed here:** Meaningless function identifiers (e.g., `func_16` instead of `compress_repeats`) prevent models from leveraging pretrained knowledge. This isolation is critical for causal claims about learning
  - **Quick check question:** Why would using `def reverse_string(s)` contaminate your evaluation in ways that `def func_7(s)` would not?

## Architecture Onboarding

- **Component map:** Stage 1 RFT -> Stage 2 RL -> Evaluation
- **Critical path:**
  1. Generate 50k Level-1 problems, collect 10 responses per problem from base model
  2. Filter to correct responses, remove function definitions from prompts, fine-tune (Stage 1)
  3. Generate Level-2 compositional problems with hidden definitions
  4. Run RL with outcome-based rewards OR run iterative RFT as baseline
  5. Evaluate on held-out functions at Levels 1-8, analyze failure modes
- **Design tradeoffs:**
  - Synthetic vs. real tasks: Synthetic enables causal inference but may not capture real-world complexity
  - Llama-3.1-8B-Instruct chosen for cleaner RL testbed per prior work (Shao et al., Agarwal et al.)
  - Binary vs. shaped rewards: Paper uses binary correctness; potential for process-based rewards unexplored
  - Level-2 vs. higher training: Training on simplest compositions still generalizes to Level 4+
- **Failure signatures:**
  - RFT on compositional data achieves only 15% on Level-2 (worse than RL's 64%), fails to generalize at all
  - RL Level-1 (atomic-only training) shows near-zero accuracy on Level 3+
  - Transfer fails when target task lacks atomic prerequisites (String-Base model on Countdown)
- **First 3 experiments:**
  1. Replicate RL Level-2 vs. RFT Level-2 comparison on a single held-out function set to validate compositional skill acquisition
  2. Vary the difficulty of compositional training data (Level-2 only vs. Level-2+3 mixed) to test if harder training examples improve or degrade generalization
  3. Ablate atomic skill quality by training Stage-1 with reduced data, then measure compositional RL effectiveness to establish the prerequisite skill threshold

## Open Questions the Paper Calls Out

- **Question:** Can RL be scaled to acquire both atomic and compositional skills simultaneously without supervised scaffolding?
  - **Basis in paper:** [explicit] "Future work may investigate the open question of whether RL can be scaled to acquire both atomic and compositional skills simultaneously without supervised scaffolding." (Conclusion)
  - **Why unresolved:** All experiments used two-stage training with supervised RFT for atomic skill acquisition before RL for composition; simultaneous acquisition was not tested
  - **What evidence would resolve it:** Experiments training models with RL from scratch on compositional tasks without prior atomic skill scaffolding, measuring both atomic and compositional acquisition rates

- **Question:** Do these findings extend to natural reasoning domains such as mathematical problem-solving, code generation, or scientific reasoning?
  - **Basis in paper:** [explicit] "Demonstrating these findings in natural reasoning domains... represents an important direction for future work. Extending these findings to realistic applications remains a valuable open challenge." (Limitations)
  - **Why unresolved:** Experiments used synthetic string transformation tasks specifically designed for controlled evaluation; real-world reasoning has less clearly delineated skills and more varied compositional structures
  - **What evidence would resolve it:** Replication of key findings (RL compositionality advantage, cross-task transfer) on natural language reasoning benchmarks with defined atomic and compositional skill hierarchies

- **Question:** Why does RL on compositional data succeed while supervised fine-tuning on identical data fails to induce compositional generalization?
  - **Basis in paper:** [inferred] The paper demonstrates the empirical gap (RL Level 2: 64% vs RFT Level 2: 15% on Level 2; 27% vs 2.6% on Level 3) but provides limited mechanistic explanation for why identical training data produces divergent outcomes
  - **Why unresolved:** The analysis focuses on behavioral changes (failure mode shifts) rather than underlying computational or representational mechanisms differentiating RL from SFT learning dynamics
  - **What evidence would resolve it:** Mechanistic interpretability studies comparing internal representations, gradient dynamics, or attention patterns between RL and RFT models during compositional training

- **Question:** Is possessing atomic skills strictly necessary for compositional skill transfer, or are there alternative pathways to enable composition?
  - **Basis in paper:** [explicit] "While our results show that possessing atomic skills is a sufficient condition for RL to unlock compositional capabilities, we do not claim it is strictly necessary." (Conclusion)
  - **Why unresolved:** All transfer experiments required atomic skills in the target domain (Countdown); the counterfactual case—transfer without target atomic skills—was not systematically tested
  - **What evidence would resolve it:** Experiments where models receive compositional RL training on Task A, then are tested on Task B compositional problems without having acquired Task B's atomic skills (with atomic skills provided in-context instead)

## Limitations
- Synthetic task design, while enabling causal inference, may not capture the complexity of real-world compositional reasoning
- The assumption that atomic skills are fully learned in Stage 1 is critical but not quantified—the quality threshold for atomic skills is unclear
- Limited ecological validity: 25 meaningless function identifiers may not reflect the richness of natural language compositionality

## Confidence

- **High confidence:** The RL vs. RFT comparison on identical compositional data (64% vs 15% on Level-2) is robust and well-supported by behavioral analysis showing fundamental changes in failure modes
- **Medium confidence:** Transfer to Countdown task demonstrates generalization, but the simpler baseline comparison (35% vs 17%) leaves room for alternative explanations
- **Low confidence:** Claims about RL learning composition "regardless of which specific atomic functions are involved" are difficult to fully validate given the limited number of atomic functions (25) and the synthetic nature of the task

## Next Checks

1. Systematically vary the quality/quantity of atomic skill training (Stage 1) and measure how this affects RL's ability to learn compositional skills, establishing the minimum atomic skill threshold
2. Test RL-trained models on compositional tasks with novel atomic functions that weren't in the original vocabulary to verify true composition learning vs. memorization of specific function combinations
3. Apply the same RL methodology to a real-world compositional task (e.g., multi-step reasoning in math word problems) to assess ecological validity beyond synthetic string transformations