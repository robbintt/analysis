---
ver: rpa2
title: Mitigating Cross-Image Information Leakage in LVLMs for Multi-Image Tasks
arxiv_id: '2508.13744'
source_url: https://arxiv.org/abs/2508.13744
tags:
- image
- multi-image
- focus
- information
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of cross-image information leakage
  in Large Vision-Language Models (LVLMs), where visual cues from multiple input images
  become entangled, degrading performance on multi-image tasks. The proposed method,
  FOCUS, is a training-free and architecture-agnostic decoding strategy that mitigates
  this issue by sequentially masking all but one image with random noise, guiding
  the model to focus on a single clean image at a time.
---

# Mitigating Cross-Image Information Leakage in LVLMs for Multi-Image Tasks

## Quick Facts
- arXiv ID: 2508.13744
- Source URL: https://arxiv.org/abs/2508.13744
- Reference count: 8
- The paper addresses cross-image information leakage in LVLMs where visual cues from multiple input images become entangled, degrading performance on multi-image tasks.

## Executive Summary
This paper addresses the problem of cross-image information leakage in Large Vision-Language Models (LVLMs) when processing multiple images simultaneously. The proposed method, FOCUS, is a training-free and architecture-agnostic decoding strategy that mitigates this issue by sequentially masking all but one image with random noise. The method performs multiple forward passes, each with a partially masked input, and aggregates the resulting logits contrastively using a noise-only reference input to suppress residual signals from masked images.

Experiments on four multi-image benchmarks across three LVLM families show consistent improvements without additional training or architectural changes. The method achieves gains up to +32.1 Image and +29.9 Group score on VisMin, +18.8 Image and +16.8 Group score on Winoground, +5.5%pts accuracy on Mantis-Eval, and +1.5%pts on MuirBench.

## Method Summary
FOCUS is a training-free decoding strategy that prevents cross-image information leakage by sequentially masking all but one image with random noise. The method runs N+1 forward passes: N passes each focusing on a single clean image while masking others with uniform noise, plus one all-noise reference pass. Logits are aggregated contrastively by subtracting the noise-reference logit from each focused logit to suppress residual signals. The approach preserves positional context by maintaining original image order and boundaries while preventing feature entanglement through noise-isolated visual attention.

## Key Results
- VisMin benchmark: +32.1 Image Score and +29.9 Group Score improvements
- Winoground benchmark: +18.8 Image Score and +16.8 Group Score improvements  
- Mantis-Eval: +5.5%pts accuracy improvement
- MuirBench: +1.5%pts accuracy improvement
- Method works across three LVLM families (InternVL3, Qwen2.5-VL, LLaVA-OneVision) without architectural changes

## Why This Works (Mechanism)

### Mechanism 1: Noise-Isolated Visual Attention
Masking non-target images with random noise forces the model's attention mechanism to process each image independently, preventing inter-image causal attention from creating mingled representations in the latent space.

### Mechanism 2: Contrastive Logit Suppression
A noise-only reference logit captures residual bias from masked images; subtracting it from focused inference logits suppresses spurious signals and prevents information leakage.

### Mechanism 3: Positional Context Preservation Through Masked Structure
Maintaining original image positions during masking preserves positional semantics needed for multi-image reasoning, allowing the model to understand "which image is being queried" while preventing visual feature entanglement.

## Foundational Learning

- **Attention Mechanism in Transformers**: Understanding why visual tokens from multiple images become entangled requires knowing how self-attention mixes information across all positions in a sequence.
  - Quick check: Can you explain why increasing the number of images in an LVLM would cause attention outputs to blend features from different images?

- **Logit Manipulation for Controlled Generation**: FOCUS operates entirely at the logit level; understanding how logits relate to token probabilities and how subtraction affects sampling is essential.
  - Quick check: If you subtract a noise-reference logit from a focused logit, what happens to the probability distribution after softmax?

- **Vision Encoder Invariance Properties**: The method assumes noise-masked images produce "empty" or neutral visual embeddings; this depends on how the encoder responds to corrupted inputs.
  - Quick check: Would a vision encoder trained with heavy augmentation be more or less resistant to noise-masking? Why might this matter for FOCUS?

## Architecture Onboarding

- **Component map**: Vision encoder → visual tokens → noise module → N+1 forward passes → aggregation module → multinomial sampling
- **Critical path**: 1) Encode all N images → [v1, v2, ..., vN]; 2) For k=1 to N: mask all images except Ik, encode, run forward pass → fk; 3) Encode all-noise input → fnoise; 4) Aggregate: ffinal = Σ(fk − α·fnoise); 5) Sample from ffinal
- **Design tradeoffs**: Inference cost scales linearly (N+1 forward passes); uniform noise optimal vs. Gaussian/impulse; α must balance suppression vs. signal preservation
- **Failure signatures**: Over-suppression (α=1.0) causes generic outputs; under-masking (λ=0.1) preserves leakage; over-masking (λ=1.0) destroys structural info; high image similarity worsens leakage
- **First 3 experiments**: 1) Reproduce leakage analysis on VisMin with single vs. multi-image settings; 2) Ablate noise types on Mantis validation; 3) End-to-end FOCUS on Winoground with InternVL3-2B

## Open Questions the Paper Calls Out
None explicitly called out in the paper.

## Limitations
- Method's effectiveness may vary across different vision encoder architectures and training regimes
- Contrastive suppression mechanism could inadvertently suppress subtle but valid visual features
- Preservation of positional context may be insufficient for tasks requiring spatial relationships within images

## Confidence
- High Confidence: Cross-image leakage exists and harms multi-image LVLM performance
- Medium Confidence: Noise-isolated visual attention effectively prevents feature entanglement  
- Medium Confidence: Contrastive logit suppression removes spurious signals
- Low Confidence: Positional context preservation is sufficient for all multi-image reasoning tasks

## Next Checks
1. Extract attention weights from the vision-language transformer during single-image vs. multi-image vs. FOCUS inference to quantify cross-image attention flow
2. Apply FOCUS to LVLMs using different vision encoders (SigLIP vs. CLIP vs. custom CNN) to measure noise-masking efficacy across architectures
3. Analyze token-level output distributions to identify whether over-suppression occurs for specific token types and adjust α per-token or per-task