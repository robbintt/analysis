---
ver: rpa2
title: 'Rethinking Memory in LLM based Agents: Representations, Operations, and Emerging
  Topics'
arxiv_id: '2505.00675'
source_url: https://arxiv.org/abs/2505.00675
tags:
- memory
- arxiv
- retrieval
- language
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This survey presents a comprehensive taxonomy of memory in LLM-based
  agents, categorizing memory into parametric (model-internal) and contextual (external)
  forms, and defining six core operations: Consolidation, Updating, Indexing, Forgetting,
  Retrieval, and Condensation. It identifies four key research topics: long-term memory,
  long-context memory, parametric memory modification, and multi-source memory, each
  addressing critical challenges such as personalization, efficiency, adaptation,
  and cross-modal integration.'
---

# Rethinking Memory in LLM based Agents: Representations, Operations, and Emerging Topics

## Quick Facts
- arXiv ID: 2505.00675
- Source URL: https://arxiv.org/abs/2505.00675
- Reference count: 40
- Primary result: Systematic taxonomy of memory mechanisms in LLM-based agents, categorizing into parametric and contextual forms with six core operations and identifying four key research topics.

## Executive Summary
This survey presents a comprehensive framework for understanding memory in LLM-based agents, distinguishing between parametric (model-internal) and contextual (external) memory representations. The authors define six core memory operations—Consolidation, Updating, Indexing, Forgetting, Retrieval, and Condensation—and identify four emerging research topics: long-term memory, long-context memory, parametric memory modification, and multi-source memory. Through systematic analysis of 37 high-impact papers and evaluation of current methods, datasets, and tools, the survey reveals critical gaps in memory evaluation, dynamic operations, and scalability, providing a structured foundation for advancing agent memory systems.

## Method Summary
The authors conducted a systematic literature review of 30,000+ papers from top NLP/ML venues (2022-2025), curating 37 seed papers using a Relative Citation Index (RCI) methodology. RCI was calculated using a log-log regression model: log(C_i+1) = β + α·log(A_i) + ε, then RCI_i = C_i / Ĉ_i. GPT-4o-mini relevance scoring (threshold ≥8/10) filtered papers, and the team manually validated results. The systematic framework was validated through implementation examples and analysis of current benchmarks, datasets, and tools available in their public repository.

## Key Results
- Memory taxonomy clearly separates parametric (LLM weights) from contextual (external storage) representations with six defined operations
- Current evaluation frameworks fail to assess dynamic memory operations like updating, forgetting, and consolidation across multi-session interactions
- Parametric memory modification techniques show promise but face scalability challenges beyond 20B parameters and risk model degradation through ripple effects
- A significant performance gap exists between retrieval accuracy (Recall@5 > 90) and generation quality (F1 scores) in memory-grounded tasks

## Why This Works (Mechanism)

### Mechanism 1: Memory Consolidation via Externalization
- **Claim:** Interaction history transformed into structured/summary format enables continuity across sessions exceeding native context windows
- **Mechanism:** Raw interactions processed through consolidation (summarization/triplet extraction) into external databases (Vector/Graph), later queried to augment context
- **Core assumption:** Consolidation algorithms extract salient information without losing nuances or introducing hallucinations
- **Evidence anchors:** Section 3.1.1 defines consolidation as stabilizing short-term context into enduring representations; Section 2.4.1 formalizes this transformation
- **Break condition:** Consolidation introduces factual errors or storage format loses semantic nuance

### Mechanism 2: KV Cache Eviction for Infinite Context
- **Claim:** Removing non-essential cached KV pairs enables processing longer sequences without retraining
- **Mechanism:** StreamingLLM/H2O identify "attention sinks" (high attention tokens) and evict intermediate tokens to constrain memory growth
- **Core assumption:** Attention mechanism is sparse enough that evicted tokens are genuinely redundant
- **Evidence anchors:** Section 3.2.1 describes Λ-shaped sparse patterns and Heavy Hitter token retention
- **Break condition:** Critical information encoded in evicted tokens causes incoherent generation

### Mechanism 3: Parametric Editing via Localized Updates
- **Claim:** Precise weight modifications can update factual knowledge without catastrophic forgetting
- **Mechanism:** ROME/MEMIT locate fact-processing layers using causal tracing, then apply constrained rank-one updates
- **Core assumption:** Knowledge is linearly stored and sufficiently disentangled for local updates without ripple effects
- **Evidence anchors:** Section 3.3 discusses locating-then-editing methods and notes risks of ripple effects
- **Break condition:** Edit affects neighboring weights or causes overfitting

## Foundational Learning

- **Concept:** Context Window vs. Persistent Memory
  - **Why needed here:** Distinguishes immediate attention (Working Memory) from retained knowledge (Long-term Memory)
  - **Quick check:** Does your system need to remember this fact in the next 5 minutes or the next 5 days?

- **Concept:** Semantic vs. Episodic Memory
  - **Why needed here:** Determines storage format—facts (Knowledge Graphs) vs. event sequences (Dialogue Logs)
  - **Quick check:** Do we need to know what the user likes (Semantic) or when/why they mentioned it (Episodic)?

- **Concept:** Retrieve-then-Read (RAG) Pipeline
  - **Why needed here:** Standard operational loop bridging storage and generation
  - **Quick check:** Is the bottleneck in finding information (Retrieval) or synthesizing answers (Generation)?

## Architecture Onboarding

- **Component map:** User Input → Query Formulation → Retrieval (Indexing) → Condensation (Context Window fitting) → LLM Inference → Consolidation (Updating Memory)
- **Critical path:** User Input → Query Formulation → Retrieval → Condensation → LLM Inference → Consolidation
- **Design tradeoffs:**
  - Compression Rate vs. Signal Loss: Aggressive condensation saves tokens but risks "Lost in the Middle"
  - Update Speed vs. Stability: Fast parametric editing is efficient but risks model collapse vs. safe RAG updates
  - Specificity vs. Generality: Parametric edits are hard to reverse; Contextual memory easier to update/delete
- **Failure signatures:**
  - Hallucination: Retrieval failed; Parametric memory dominates
  - Repetition/Looping: Memory Updating failed to prune redundant context
  - Identity Drift: Consolidation overwriting user preferences with generic knowledge
- **First 3 experiments:**
  1. Baseline Retrieval: Implement Vector Store for user history; measure recall accuracy over 10-turn conversation
  2. Context Condensation: Implement basic summarization; compare token usage vs. F1 score
  3. Forgetting Test: Explicitly instruct forgetting; verify removal from Vector Store and Context

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can evaluation frameworks shift from static benchmarks to dynamic protocols assessing updating, forgetting, and consolidation?
- **Basis in paper:** [explicit] Current benchmarks "often assume static memory and overlook dynamic operations such as updating, selective retention, and temporal continuity" (Section 3.1.5)
- **Why unresolved:** Existing datasets treat memory as static repository rather than dynamic system
- **What evidence would resolve it:** Benchmarks requiring agents to modify internal states, selectively discard outdated data, and maintain consistency across extended time horizons

### Open Question 2
- **Question:** What context engineering strategies bridge the gap where high retrieval performance fails to translate into effective memory-grounded generation?
- **Basis in paper:** [explicit] Identifies "mismatch between memory retrieval and memory-grounded generation" with high retrieval scores (Recall@5 > 90) but lagging generation metrics (F1) (Section 3.1.5)
- **Why unresolved:** Current systems struggle to structure retrieved memories for decoding; more items often introduce noise
- **What evidence would resolve it:** Methods improving generation F1 scores proportionally to retrieval recall through concise condensation

### Open Question 3
- **Question:** How can parametric modification techniques scale effectively for LLMs exceeding 20 billion parameters?
- **Basis in paper:** [explicit] Analysis shows non-prompt-based editing faces "scalability challenges" for larger models (Section 3.3.4)
- **Why unresolved:** Techniques rely on components that don't scale linearly with parameter counts
- **What evidence would resolve it:** Model editing method maintaining high specificity on 70B+ parameters without prohibitive overhead

## Limitations

- Survey relies heavily on recent literature (2022-2025), potentially missing foundational pre-LLM memory system work
- Emerging topics like parametric memory modification remain largely theoretical with limited empirical validation in production
- RCI methodology depends on citation patterns that may not fully capture practical adoption or effectiveness

## Confidence

- **High Confidence:** Taxonomy structure (parametric vs. contextual memory with six operations) is well-supported by multiple literature sources
- **Medium Confidence:** Analysis of consolidation and retrieval mechanisms is grounded in established research
- **Medium Confidence:** Identification of key research topics is timely but may shift as empirical results emerge
- **Low Confidence:** Predictions about industry adoption and practical deployment challenges are speculative

## Next Checks

1. **Empirical Validation:** Implement benchmark comparing consolidation strategies (summarization vs. triplet extraction) on PersonChat dataset to measure compression vs. retrieval accuracy trade-offs
2. **Cross-Domain Analysis:** Test taxonomy's applicability beyond conversational agents by analyzing memory systems in code generation or scientific reasoning LLMs
3. **Longitudinal Study:** Track RCI scores of identified key papers over 12 months to assess whether methodology accurately predicts lasting impact versus temporary citation spikes