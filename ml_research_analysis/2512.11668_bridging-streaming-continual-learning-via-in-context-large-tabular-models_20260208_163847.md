---
ver: rpa2
title: Bridging Streaming Continual Learning via In-Context Large Tabular Models
arxiv_id: '2512.11668'
source_url: https://arxiv.org/abs/2512.11668
tags:
- learning
- data
- arxiv
- preprint
- conference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes large tabular models (LTMs) as a bridge between
  streaming continual learning (SCL) and existing paradigms of continual learning
  (CL) and stream learning (SL). The key idea is that unbounded data streams can be
  summarized on-the-fly into compact sketches and consumed by LTMs, combining SL's
  compression goal with CL's experience-replay objective.
---

# Bridging Streaming Continual Learning via In-Context Large Tabular Models

## Quick Facts
- arXiv ID: 2512.11668
- Source URL: https://arxiv.org/abs/2512.11668
- Authors: Afonso Lourenço; João Gama; Eric P. Xing; Goreti Marreiros
- Reference count: 37
- Key outcome: Proposes large tabular models (LTMs) as a unifying framework for streaming continual learning, combining distribution matching and compression principles.

## Executive Summary
This paper addresses the challenge of streaming continual learning (SCL) by proposing large tabular models (LTMs) as a bridge between continual learning (CL) and stream learning (SL) paradigms. The key innovation is using LTMs to perform in-context learning on compact data sketches, enabling adaptation without parameter updates. The authors argue that SCL should be structured around two core principles: distribution matching (balancing plasticity and stability) and distribution compression (controlling memory size through diversification and retrieval). Their approach uses dual-memory FIFO systems and data selection strategies inspired by active learning and training dynamics to maintain representative samples while adapting to concept drifts.

## Method Summary
The proposed method uses pre-trained transformer models (TabPFN) with frozen weights that accept tabular input-output pairs as context tokens. A dual-memory FIFO system maintains two buffers: M_short stores recent samples for plasticity, while M_long stores fixed-size samples across all known classes for stability. At inference, samples from both memories are concatenated as context for the LTM. Data selection strategies based on informativeness (entropy, loss, margin) and representativeness (distance to centroid, cluster membership) guide which samples are retained. The approach performs classification through in-context learning without fine-tuning, adapting to concept drifts by updating the context composition.

## Key Results
- LTMs enable data-centric continual learning where stability, plasticity, diversification, and retrieval are controlled through context design rather than complex architectural interventions
- The dual-memory FIFO system achieves balance between long-term stability and rapid adaptability to short-term fluctuations
- Distribution compression via informativeness and representativeness scoring produces non-redundant, high-utility context sets

## Why This Works (Mechanism)

### Mechanism 1: In-Context Learning Substitutes for Parameter Updates
- Claim: LTMs perform classification without fine-tuning by conditioning on context examples, bypassing the need for gradient-based adaptation.
- Mechanism: Pretrained transformer models accept tabular input-output pairs as context tokens. The attention mechanism implicitly constructs decision boundaries from these examples at inference time, rather than storing knowledge in weights.
- Core assumption: The pretrained prior distribution sufficiently covers the hypothesis space of downstream tabular tasks.
- Evidence anchors:
  - [abstract] "LTMs enable a data-centric view where stability, plasticity, diversification, and retrieval are controlled through context design rather than complex architectural interventions"
  - [page 5] "Unlike traditional models, LTMs perform instant classification without fine-tuning. They adapt to unseen datasets in a single forward pass by using various training examples as context"
  - [corpus] Neighbor paper "In-context Learning of Evolving Data Streams with Tabular Foundational Models" provides empirical validation
- Break condition: If context window limits are exceeded by stream volume, or if concept drift moves outside the pretrained prior, in-context learning may fail without architectural fallback.

### Mechanism 2: Dual-Memory FIFO System Balances Plasticity and Stability
- Claim: A two-tier memory structure enables simultaneous adaptation to recent patterns and retention of rare historical classes.
- Mechanism: Short-term memory (M_short) maintains the most recent stream portion using FIFO eviction, capturing local variations and transient sub-concepts. Long-term memory (M_long) stores fixed-size samples across all known classes, preserving infrequently seen categories. Both memories are concatenated as context at inference.
- Core assumption: Recent samples are more representative of the current distribution than older samples.
- Evidence anchors:
  - [abstract] "proposed approach uses dual-memory FIFO systems and data selection strategies"
  - [page 6] "By combining these two memories, the model achieves a balance between long-term stability and rapid adaptability to short-term fluctuations"
  - [corpus] Weak direct corpus evidence; neighboring papers focus on single-memory approaches
- Break condition: If concept recurrence occurs after long-term memory has evicted relevant samples, or if sudden distribution shifts render short-term memory misleading, performance degrades.

### Mechanism 3: Distribution Compression via Informativeness and Representativeness Scoring
- Claim: Sample selection based on dual criteria (informativeness and representativeness) produces non-redundant, high-utility context sets.
- Mechanism: Informativeness scores favor uncertain or boundary samples (high entropy, high loss, hard examples). Representativeness scores capture distribution coverage (distance to class mean, cluster membership). Sequential selection methods that jointly optimize both criteria outperform naive top-K similarity selection.
- Core assumption: Individual sample scores approximate collective influence on generalization.
- Evidence anchors:
  - [page 7] "sequential methods that explicitly balance similarity to the query with diversity among selected examples consistently outperform naive strategies"
  - [page 7] Figure 16 illustrates informativeness vs. representativeness tradeoffs
  - [corpus] Neighbor "IMLP" paper addresses energy-efficient continual learning on tabular streams with related selection heuristics
- Break condition: If scoring heuristics become stale under rapid concept drift, or if the joint optimization is computationally infeasible for real-time constraints, naive selection may be required as fallback.

## Foundational Learning

- Concept: **Plasticity-Stability Tradeoff**
  - Why needed here: The core tension in streaming continual learning—adapting to new distributions while retaining past knowledge—is framed throughout the paper as the fundamental design constraint.
  - Quick check question: Can you explain why gradient-based optimization for stability (e.g., EWC regularization) can cause temporary forgetting even when the regularized optimum is eventually reached?

- Concept: **In-Context Learning (ICL)**
  - Why needed here: LTMs operate entirely through ICL, requiring no parameter updates. Understanding how attention mechanisms construct implicit models from context tokens is essential.
  - Quick check question: How does the Kullback-Leibler criterion relate to the frequentist bias-variance perspective on in-context learning described in the paper?

- Concept: **Distribution Compression / Synopsis Techniques**
  - Why needed here: The paper explicitly connects SL's sketch-based stream summarization with CL's experience replay. Core-set selection, herding, and clustering-based synopsis methods are presented as foundational.
  - Quick check question: What is the difference between a core-set selection approach and a naive top-K most similar sample selection, and why does the paper argue the former better supports diversification?

## Architecture Onboarding

- Component map:
  - LTM Backbone (TabPFN transformer) -> Dual-Memory Buffer (M_short + M_long) -> Selection Module (informativeness + representativeness scoring) -> Context Assembler -> Inference Output

- Critical path:
  1. Stream sample arrives → add to M_short (evict oldest if full)
  2. Periodically evaluate M_long candidates → add representative samples, evict redundant ones
  3. Query arrives → retrieve relevant samples from both memories via selection module
  4. Assemble context → pass to LTM for single forward-pass inference

- Design tradeoffs:
  - Context window size vs. inference latency (larger context improves accuracy but increases compute)
  - M_short / M_long ratio (more M_short = higher plasticity; more M_long = higher stability)
  - Selection complexity vs. real-time constraints (joint optimization is more accurate but slower than top-K)

- Failure signatures:
  - **Catastrophic forgetting**: M_long fails to preserve rare classes; check class balance statistics
  - **Plasticity loss**: M_short is too small or selection over-emphasizes old samples; check recency distribution
  - **Context window overflow**: Combined memories exceed LTM's maximum context length; enforce hard caps
  - **Redundancy accumulation**: Selection module degrades to storing near-duplicates; check pairwise distances

- First 3 experiments:
  1. **Ablate memory ratio**: Vary M_short size (10%, 30%, 50% of total memory) on a benchmark with known concept drift (e.g., NOAA, Electricity). Measure prequential accuracy across drift points.
  2. **Compare selection strategies**: Implement (a) random sampling, (b) top-K similarity, (c) joint diversity-similarity optimization. Evaluate on a class-incremental stream to isolate forgetting behavior.
  3. **Probe context composition**: For a held-out test set, compute per-class accuracy as a function of that class's representation in the context. Verify that M_long maintains sufficient support for minority classes.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can data selection strategies be effectively framed as online learning-to-rank (LTR) problems to leverage counterfactual effects of sample inclusion while minimizing LTM calls?
- Basis in paper: [explicit] "To make this approach tractable in practice, data selection can be framed as an online learning-to-rank (LTR) problem... The core challenge is balancing exploration (testing new rankings) with exploitation (using the best-known ranking)."
- Why unresolved: The paper proposes this framing conceptually but provides no empirical validation; the exploration-exploitation tradeoff in this context remains uncharacterized.
- What evidence would resolve it: Empirical comparison of LTR-based data selection against heuristic score-based methods on streaming benchmarks, measuring both predictive performance and computational overhead.

### Open Question 2
- Question: How can fine-tuning strategies for retrieval-based performance be adapted to work specifically in continual learning settings without causing forgetting?
- Basis in paper: [explicit] "However, applying such strategies in continual learning remains a significant challenge across all modalities of foundational models" despite evidence that "fine-tuning improves retrieval-based performance."
- Why unresolved: Fine-tuning has shown promise for retrieval in static settings, but the inherent tension between adaptation and retention in SCL creates unique constraints not yet addressed for LTMs.
- What evidence would resolve it: Ablation studies comparing pre-trained vs. fine-tuned LTM retrieval mechanisms on SCL benchmarks with recurring concept drift, measuring both adaptation speed and forgetting rates.

### Open Question 3
- Question: How can the dual-memory FIFO system be enhanced to provide proactive (rather than purely reactive) plasticity and ensure invariant representations across all concepts?
- Basis in paper: [explicit] "However, this approach is naive. Plasticity is largely reactive, implemented via fading strategies rather than proactive adaptation, while stability only addresses catastrophic forgetting of classes, without ensuring invariant representations across all concepts."
- Why unresolved: The paper identifies this limitation and suggests diversification and retrieval principles as remedies, but does not specify concrete mechanisms for proactive plasticity or representation invariance.
- What evidence would resolve it: Comparative evaluation of proactive plasticity mechanisms (e.g., anticipatory sampling) against reactive fading strategies, with analysis of representation drift across evolving stream concepts.

## Limitations
- **Memory Configuration Ambiguity**: Specific sizes and allocation ratios between M_short and M_long are not specified, creating ambiguity in replication.
- **Selection Algorithm Gaps**: While informativeness and representativeness are defined conceptually, the exact scoring functions and joint optimization procedures remain unspecified.
- **Extreme Stream Constraints**: The authors acknowledge that extreme real-time constraints still require smaller, faster models, but do not specify performance thresholds or operational limits.

## Confidence
- **High Confidence**: The dual-memory FIFO mechanism and its conceptual purpose (balancing plasticity/stability) are clearly articulated with sufficient supporting rationale.
- **Medium Confidence**: The distribution compression principles (informativeness vs. representativeness) are theoretically sound but lack concrete implementation specifications.
- **Low Confidence**: The practical limits of LTM-based streaming systems under extreme concept drift or severe computational constraints are acknowledged but not quantified.

## Next Checks
1. **Memory Size Sensitivity**: Systematically vary M_short/M_long ratios (10/90, 30/70, 50/50) on a benchmark with multiple concept drifts (e.g., Electricity) to identify optimal allocation and identify breaking points.
2. **Selection Strategy Benchmarking**: Implement and compare three selection strategies (random, top-K similarity, joint diversity-similarity optimization) on class-incremental streams to quantify the practical impact of sophisticated selection.
3. **Context Window Stress Test**: Gradually increase stream rate and measure LTM performance degradation points, identifying when context window limits or computational constraints become bottlenecks.