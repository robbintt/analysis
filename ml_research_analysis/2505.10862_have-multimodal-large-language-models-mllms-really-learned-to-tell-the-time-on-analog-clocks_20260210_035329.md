---
ver: rpa2
title: Have Multimodal Large Language Models (MLLMs) Really Learned to Tell the Time
  on Analog Clocks?
arxiv_id: '2505.10862'
source_url: https://arxiv.org/abs/2505.10862
tags:
- clocks
- clock
- time
- mllms
- hands
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the ability of multimodal large language
  models (MLLMs) to tell time on analog clocks, revealing that despite advances in
  image understanding, these models struggle with this seemingly simple task. The
  study focuses on GPT-4.1, demonstrating that its success on standard clock images
  stems from memorization of patterns in training data rather than genuine understanding.
---

# Have Multimodal Large Language Models (MLLMs) Really Learned to Tell the Time on Analog Clocks?

## Quick Facts
- **arXiv ID**: 2505.10862
- **Source URL**: https://arxiv.org/abs/2505.10862
- **Reference count**: 8
- **Primary result**: GPT-4.1 struggles with telling time on deformed analog clocks, with mean absolute errors increasing from 232.5 seconds on normal clocks to 1,380.7 and 3,726.9 seconds respectively for deformed shapes and altered hand designs.

## Executive Summary
This paper investigates whether multimodal large language models (MLLMs) can genuinely understand how to read analog clocks or merely memorize patterns from training data. The study focuses on GPT-4.1, revealing that while the model performs well on standard clock images, its performance degrades significantly when faced with deformed clock shapes or altered hand designs. The research demonstrates that GPT-4.1's success on normal clocks stems from pattern memorization rather than true comprehension of the underlying concept of time-telling.

The findings highlight two critical failure modes: confusion about clock hand functions when hands are modified, and impaired directional perception. Even after fine-tuning on diverse clock variants, the model shows limited generalization to novel clock designs. These results suggest that current MLLMs operate at a superficial level of pattern recognition rather than achieving the abstract understanding required for robust real-world applications. The study calls for new approaches that enable models to learn at higher levels of abstraction rather than relying on memorized patterns.

## Method Summary
The study evaluates GPT-4.1's ability to read analog clocks using a test set of 200 clock images, divided into three categories: normal clocks, deformed clock shapes, and clocks with altered hand designs. Performance is measured using mean absolute error (MAE) in seconds between predicted and actual times. The researchers also conduct fine-tuning experiments using 800 training images to assess whether targeted training can improve generalization to novel clock variants. The analysis focuses on identifying specific failure modes and understanding the limitations of current MLLM approaches to visual reasoning tasks.

## Key Results
- GPT-4.1 achieves a mean absolute error of 232.5 seconds on normal clocks but degrades to 1,380.7 seconds on deformed clock shapes and 3,726.9 seconds on altered hand designs
- Fine-tuning improves performance but shows limited generalization to novel clock variants
- Two key failure modes identified: confusion about clock hand functions and impaired directional perception
- Fine-tuning is less effective when multiple sources of interference are present simultaneously

## Why This Works (Mechanism)
The mechanism underlying GPT-4.1's clock-reading capability appears to rely heavily on pattern matching against memorized visual templates rather than genuine spatial reasoning. When clock appearances deviate from learned patterns through shape deformation or hand modification, the model's visual feature extraction fails to properly identify clock components, leading to cascading errors in time calculation. The fine-tuning experiments suggest that the model can adapt to specific variations within its training distribution but lacks the abstract reasoning capabilities needed to generalize across fundamentally different clock designs. This indicates that current MLLMs process visual information through learned statistical associations rather than developing conceptual understanding of temporal relationships and spatial configurations.

## Foundational Learning
- **Pattern memorization vs. abstract understanding**: Models may appear competent by memorizing common patterns rather than learning underlying principles; quick check: test with systematically varied inputs
- **Visual reasoning decomposition**: Breaking down complex visual tasks into interpretable sub-components; quick check: isolate and test individual reasoning steps
- **Generalization boundaries**: Understanding when models fail on inputs outside their training distribution; quick check: measure performance degradation on controlled perturbations
- **Fine-tuning limitations**: Recognizing when additional training data fails to produce robust behavior; quick check: evaluate on held-out variants
- **Interference effects**: Understanding how multiple modifications compound model errors; quick check: test combinations of perturbations

## Architecture Onboarding
**Component Map**: Image Encoder -> Feature Extractor -> Temporal Reasoning Module -> Text Generation Output

**Critical Path**: Input Image → Visual Feature Extraction → Clock Hand Detection → Time Calculation → Natural Language Output

**Design Tradeoffs**: The study implicitly reveals tradeoffs between model capacity for memorization versus abstraction, and between training data diversity versus model generalization capabilities.

**Failure Signatures**: 
- Confusion between hour and minute hands when hand designs are altered
- Loss of directional perception in deformed clock geometries
- Inability to transfer learned patterns to novel clock variants
- Compounded errors when multiple clock modifications are present

**First Experiments**:
1. Test GPT-4.1 on standard clock images to establish baseline performance
2. Evaluate performance degradation on systematically deformed clock shapes
3. Assess fine-tuning effectiveness on altered hand design variants

## Open Questions the Paper Calls Out
The paper raises several open questions regarding the fundamental nature of MLLM capabilities. It questions whether current architectures can ever achieve true abstract understanding of visual concepts or if they are fundamentally limited to pattern recognition. The research also highlights the need to understand how different fine-tuning strategies might overcome generalization limitations, and whether architectural modifications could enable models to develop more robust visual reasoning capabilities. Additionally, the study suggests exploring alternative evaluation methods that can better distinguish between memorization and genuine comprehension in visual reasoning tasks.

## Limitations
- Narrow focus on single MLLM (GPT-4.1) limits generalizability to other models
- Evaluation relies on synthetic clock deformations rather than real-world clock variations
- Fine-tuning approach uses relatively small dataset (800 images)
- Does not explore whether failures stem from architectural limitations or training methodology
- Limited exploration of alternative MLLM architectures or training approaches
- Focuses solely on time-telling task without examining related visual reasoning capabilities

## Confidence
- **High confidence**: GPT-4.1's degraded performance on deformed variants, identification of specific failure modes, limited fine-tuning generalization
- **Medium confidence**: Claim that GPT-4.1 relies on pattern memorization rather than genuine understanding
- **Low confidence**: Broader implications for MLLM design and fundamental learning capabilities

## Next Checks
1. Test additional MLLMs (including open-source models) on the same clock-reading benchmarks to assess whether limitations are model-specific or represent broader MLLM challenges

2. Evaluate models on real-world clock images with natural variations in style, lighting, and orientation to validate whether synthetic deformations accurately predict real-world performance

3. Investigate alternative fine-tuning strategies using larger, more diverse clock datasets and different training objectives (e.g., contrastive learning or curriculum learning approaches) to determine if limited generalization is due to dataset size or fundamental architectural constraints