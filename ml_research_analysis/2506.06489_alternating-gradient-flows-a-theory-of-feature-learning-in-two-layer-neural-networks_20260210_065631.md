---
ver: rpa2
title: 'Alternating Gradient Flows: A Theory of Feature Learning in Two-layer Neural
  Networks'
arxiv_id: '2506.06489'
source_url: https://arxiv.org/abs/2506.06489
tags:
- learning
- utility
- networks
- neurons
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Alternating Gradient Flows (AGF), a framework
  that approximates gradient flow in two-layer neural networks with small initialization
  by alternating between utility maximization over dormant neurons and cost minimization
  over active ones. AGF characterizes feature learning as a saddle-to-saddle process
  where each iteration involves dormant neurons independently maximizing their utility
  (alignment to residuals) before the first to reach a threshold becomes active and
  joins a collective cost minimization phase.
---

# Alternating Gradient Flows: A Theory of Feature Learning in Two-layer Neural Networks

## Quick Facts
- arXiv ID: 2506.06489
- Source URL: https://arxiv.org/abs/2506.06489
- Reference count: 40
- Primary result: Alternating Gradient Flows (AGF) approximates gradient flow in two-layer networks with small initialization by alternating between utility maximization over dormant neurons and cost minimization over active ones.

## Executive Summary
This paper introduces Alternating Gradient Flows (AGF), a framework that approximates gradient flow in two-layer neural networks with small initialization by alternating between utility maximization over dormant neurons and cost minimization over active ones. AGF characterizes feature learning as a saddle-to-saddle process where each iteration involves dormant neurons independently maximizing their utility (alignment to residuals) before the first to reach a threshold becomes active and joins a collective cost minimization phase. The authors prove AGF converges to gradient flow for diagonal linear networks in the vanishing initialization limit, unifies prior analyses of saddle-to-saddle dynamics in fully connected linear networks (learning singular vectors) and attention-only linear transformers (learning principal components), and extends to novel settings by characterizing Fourier feature emergence in modular addition tasks. Experiments across these architectures show AGF accurately predicts the order, timing, and magnitude of loss drops during training, offering a promising step toward understanding feature learning through optimization dynamics.

## Method Summary
AGF approximates gradient flow in two-layer networks by partitioning neurons into dormant and active sets. Dormant neurons evolve independently on the unit sphere via projected gradient flow, maximizing alignment to the current residual. When a dormant neuron's accumulated utility exceeds a threshold, it activates and joins active neurons in collective cost minimization. This process iterates, with each activation removing one feature from the residual. The framework requires small initialization (α ≪ 1) for timescale separation between directional alignment and radial growth, and homogeneous activation functions where utility inherits homogeneity of degree κ = k+1.

## Key Results
- AGF converges to gradient flow for diagonal linear networks as initialization vanishes
- Unified analysis of saddle-to-saddle dynamics across linear networks, transformers, and modular addition
- Predicts sequential feature emergence in order of feature utility (singular values, Fourier coefficients)
- Accurately forecasts loss drops: order, timing, and magnitude across multiple architectures
- Characterizes timescale separation: directional dynamics dominates radial dynamics near origin

## Why This Works (Mechanism)

### Mechanism 1: Timescale Separation Near Saddles
- Near saddle points, directional dynamics of dormant neurons evolve much faster than radial dynamics, enabling alignment before growth. For dormant neurons with small norm, directional dynamics scale as ||θ_i||^(κ−2) while radial dynamics scale as ||θ_i||^(κ−1). Since ||θ_i|| ≪ 1, directional dynamics dominates, allowing neurons to first align to useful directions before growing in norm. This creates the plateau-then-drop pattern in training loss. The mechanism requires origin-passing activations and homogeneous functions where κ = k+1 is the leading order of utility Taylor expansion near origin.

### Mechanism 2: Utility-Driven Activation Race
- Dormant neurons compete to maximize accumulated utility, with the first to reach a threshold activating and joining collective optimization. Each dormant neuron independently maximizes utility U_i(θ;r) = E_x[⟨f_i(x;θ), r(x)⟩] via projected gradient flow on the unit sphere. The accumulated utility S_i(t) = ∫_0^t κŪ_i(s)ds is tracked. When S_i exceeds threshold c_i/η, the neuron activates. This creates a race condition where the neuron most aligned with the residual activates first. The mechanism assumes dormant neurons evolve independently with residual determined solely by active neurons.

### Mechanism 3: Iterative Residual Refinement
- Each AGF iteration removes one feature from the residual, causing subsequent iterations to target progressively weaker features in a greedy manner. After cost minimization converges, the new residual r^new = y − f(Θ_A^*) excludes contributions from learned features. The utility function for remaining dormant neurons is recomputed with this updated residual. This sequential refinement yields learning in order of feature utility (singular values for linear networks, Fourier coefficient magnitudes for modular addition). The mechanism assumes features learned in different iterations remain approximately orthogonal or decoupled during cost minimization.

## Foundational Learning

- **Gradient Flow vs. Gradient Descent**: AGF is derived as an approximation to gradient flow (continuous-time gradient descent limit). Understanding the continuous formulation is essential to follow the directional/radial decomposition. Quick check: Can you explain why gradient flow with time rescaling η captures the same trajectory as unscaled flow but with different traversal speed?

- **Homogeneous Functions and Euler's Theorem**: The derivation of Equation 2 relies on homogeneous activation functions where the utility inherits homogeneity of degree κ = k+1. Euler's theorem connects gradient dot products to function values. Quick check: For a κ-homogeneous function U(θ), what does Euler's theorem tell you about ⟨θ, ∇_θ U(θ)⟩?

- **Saddle Points and Critical Manifolds**: AGF models training as jumps between saddle points structured by dormant/active partitions. The origin is a saddle with all neurons dormant; each activation changes the partition structure. Quick check: In the two-layer network loss landscape, why does setting dormant neuron parameters to zero create valid critical points of the full loss?

## Architecture Onboarding

- **Component map**: Two-layer network → Dormant/Active partition → Utility maximization → Activation threshold → Cost minimization → Residual update → Next iteration
- **Parameter groups**: θ_i = (w_i, a_i) for each neuron; dormant set D and active set A partition neurons
- **Utility function**: U_i(θ; r) = E_x[⟨f_i(x;θ), r(x)⟩] measures neuron-residual alignment
- **Accumulated utility**: S_i(t) = ∫ κŪ_i(s)ds determines activation timing
- **Residual**: r(x) = y(x) − f(x; Θ_A) drives dormant neuron dynamics

- **Critical path**: 
  1. Initialize all neurons dormant with small norm ||θ_i(0)|| = O(α) where α ≪ 1
  2. Utility maximization: Dormant neurons follow projected gradient flow dθ̄_i/dt ∝ P_⊥∇U until first neuron reaches S_i = c_i/η
  3. Activation: Transfer neuron i* from D to A
  4. Cost minimization: Active neurons follow dθ_j/dt = −∇_θ_j L(Θ_A) until convergence
  5. Residual update: Compute new r(x), return to step 2 until ∇L(Θ_D) = 0

- **Design tradeoffs**:
  - Activation function choice: κ = 2 (linear, ReLU) gives instantaneous alignment in vanishing α limit; κ > 2 requires adaptive learning rate η_i = ||θ_i||^(2−κ)η for comparable behavior
  - Initialization scale α: Smaller α gives sharper saddle-to-saddle behavior but longer plateaus; larger α causes overlapping phases and smoother loss curves
  - Width H: Must be sufficient to capture all features; AGF accuracy degrades if multiple neurons activate simultaneously

- **Failure signatures**:
  - Non-stepwise loss at small α: Indicates either initialization not sufficiently small, or multiple neurons activating together (try smaller α or learning rate)
  - Wrong feature order: Check if orthogonality assumptions hold (e.g., Σ_xx commutes with Σ_yx^TΣ_yx); non-commutative settings may violate ordering predictions
  - Neurons not aligning to predicted directions: Verify homogeneous activation assumption; non-homogeneous activations require Taylor expansion leading order analysis

- **First 3 experiments**:
  1. Diagonal linear network sparse regression: Implement AGF and gradient flow for β = u ⊙ v on synthetic sparse data with varying α; verify loss plateaus match AGF predictions and converge as α → 0 (replicate Figure 3)
  2. Fully connected linear network singular value learning: Train two-layer linear network on Gaussian data; compare learned singular value emergence order and timing to Conjecture 4.1 predictions under commuting vs. non-commuting conditions
  3. Modular addition Fourier features: Train quadratic network on modular addition task p = 20 with template x containing three cosine components; verify Fourier features emerge in order of |x̂[k]| magnitude and compare AGF jump time bounds to empirical dynamics (replicate Figure 6)

## Open Questions the Paper Calls Out

### Open Question 1
Does AGF converge to gradient flow in the vanishing initialization limit (α→0) for general two-layer networks, beyond diagonal linear networks? While AGF and GF exhibit similar behaviors at small-scale initialization (α≪1), a natural question is whether their trajectories converge to each other as α→0. While a general proof remains open (see Section 6)... Theorem 3.1 only establishes convergence for diagonal linear networks. The general case faces theoretical challenges from the coupled dynamics between dormant and active neurons, and empirical validation requires taking both initialization scale and learning rate to zero simultaneously.

### Open Question 2
Does Conjecture 4.1 hold for fully connected linear networks when the input covariance Σxx does not commute with Σ⊺_yxΣyx? Conjecture 4.1 is stated without proof; the authors note "When Σxx and Σ⊺_yxΣyx do not commute, in order to prove Conjecture 4.1, it is necessary to understand the relation between the SVD of P⊥_UkΣyx and of Σyx, as k varies." The classical Poincaré separation theorem only describes singular value interlacing, but the geometry of singular vectors—which is crucial for alignment—remains uncharacterized in the non-commuting case.

### Open Question 3
How can AGF be extended to deeper networks while preserving its analytical tractability? The central limitation of the framework is its focus on two-layer networks, leaving open how it might generalize to deeper and more realistic architectures. The AGF framework relies on the clean partition into dormant/active neurons and the utility/cost decomposition, both of which become complex when layers interact nonlinearly. Conserved quantities and symmetry structures differ in deep networks.

### Open Question 4
Why do loss curves transition from staircase-like to smooth as network width increases, and does AGF remain valid in this overlapping regime? On natural data tasks, loss curves are often not visibly stepwise even at very small initialization scales... suggesting there may be limitations to AGF. That said, if many dormant neurons reach their activation thresholds in close succession, their cost-minimization phases could interleave, causing the aggregate loss to appear smooth. The paper offers two competing hypotheses: (1) AGF remains valid but phases overlap due to width, or (2) AGF fundamentally breaks down.

## Limitations
- Applicability restricted to vanishing initialization regimes where timescale separation holds
- Assumes homogeneous activation functions and orthogonal/decooupled feature spaces
- Theoretical guarantees proven only for diagonal linear networks; broader extensions remain conjectural
- Cannot handle practical networks trained from larger initializations where directional and radial dynamics couple

## Confidence
- **High Confidence**: Timescale separation mechanism and saddle-to-saddle dynamics framework for diagonal linear networks with proven convergence
- **Medium Confidence**: Utility-driven activation race and sequential residual refinement for diagonal linear networks, relies on conjecture for broader architectures
- **Medium Confidence**: Empirical predictions for fully connected linear networks, attention transformers, and modular addition tasks align with experimental observations but lack rigorous convergence proofs

## Next Checks
1. **Initialization Sensitivity Analysis**: Systematically vary α across orders of magnitude in diagonal linear networks to quantify the breakdown point where AGF predictions deviate from observed gradient flow dynamics, establishing practical bounds on the framework's applicability.

2. **Non-Commutative Feature Learning**: Design synthetic experiments for fully connected linear networks where Σ_xx and Σ_yx^T Σ_yx do not commute, testing Conjecture 4.1 predictions against empirical singular value emergence orders to probe the limits of the orthogonality assumption.

3. **Multi-Neuron Activation Dynamics**: Extend modular addition experiments to cases where multiple neurons have similar Fourier coefficient magnitudes, measuring the impact on loss curve smoothness and feature emergence timing to validate the race condition assumptions in Mechanism 2.