---
ver: rpa2
title: Do LLMs Really Struggle at NL-FOL Translation? Revealing their Strengths via
  a Novel Benchmarking Strategy
arxiv_id: '2511.11816'
source_url: https://arxiv.org/abs/2511.11816
tags:
- translation
- logical
- formula
- task
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper critiques current NL-FOL translation benchmarks, showing\
  \ they conflate ontology extraction with logical translation and use flawed metrics\
  \ like LE and BLEU that fail to capture logical equivalence. To address this, the\
  \ authors propose a novel benchmarking strategy that: (1) provides a fixed FOL signature\
  \ and ontology upfront to isolate logical translation; (2) generates random logical\
  \ perturbations on the fly to create candidate sets, reducing memorization and pattern-matching;\
  \ and (3) evaluates through three tasks\u2014logical translation (using SMT solver\
  \ equivalence), most similar (select closest semantic match), and ranking (order\
  \ by semantic similarity, including negations and equivalents)."
---

# Do LLMs Really Struggle at NL-FOL Translation? Revealing their Strengths via a Novel Benchmarking Strategy

## Quick Facts
- arXiv ID: 2511.11816
- Source URL: https://arxiv.org/abs/2511.11816
- Authors: Andrea Brunello; Luca Geatti; Michele Mignani; Angelo Montanari; Nicola Saccomanno
- Reference count: 19
- Primary result: Strong dialogue-oriented models (GPT-4O-MINI, O3-MINI) demonstrate genuine semantic grasp of FOL translation when evaluated with perturbation-based tasks, while embedding-centric models perform significantly worse.

## Executive Summary
This paper critiques current NL-FOL translation benchmarks for conflating ontology extraction with logical translation and using flawed metrics that fail to capture logical equivalence. The authors propose a novel benchmarking strategy that isolates logical translation by providing a fixed FOL signature and ontology upfront, uses on-the-fly perturbation generation to create candidate sets resistant to memorization, and evaluates through three tasks: logical translation (SMT solver equivalence), most similar (select closest semantic match), and ranking (order by semantic similarity). Experiments show that strong dialogue-oriented models achieve high logical translation scores that reflect genuine semantic understanding rather than superficial pattern matching, while embedding-centric models struggle despite high performance on other semantic tasks.

## Method Summary
The evaluation pipeline uses triplets (p, φ, Ω) where p is a natural language utterance, φ is the corresponding FOL formula, and Ω is a predefined ontology containing signature symbols and their natural language glosses. The approach isolates logical translation by providing Ω upfront, eliminating the need for ontology extraction. Perturbation sets are generated on-the-fly for each reference formula through single-edit transformations (connective swaps, quantifier flips, negation insertions) and equivalence transformations (De Morgan's laws, double negation, distributivity). Models are evaluated zero-shot using Automatic Chain-of-Thought prompting with structured outputs. Logical translation outputs are verified using Z3 SMT solver equivalence checking, while most similar and ranking tasks use cosine similarity for embedding models or model ranking for dialogue models.

## Key Results
- Dialogue-oriented models (O3-MINI, GPT-4O-MINI, Qwen3) achieve strong logical translation scores (80-90%) when provided with predefined ontologies, demonstrating genuine semantic understanding
- Embedding-centric models (Qwen3-Embedding-8B, Gemini-Embedding-001) perform markedly worse on FOL tasks despite strong performance on other semantic benchmarks
- Most similar and ranking tasks show minimal memorization effects and dataset leakage resistance due to on-the-fly perturbation generation
- O3-MINI achieves the highest logical translation accuracy (~80%) across both datasets, with GPT-4O-MINI close behind (~73%)
- Embedding models show significant performance gaps between NL and FOL variants of tasks, indicating poor FOL parsing capability

## Why This Works (Mechanism)

### Mechanism 1: Task Decomposition (Ontology Extraction vs. Logical Translation)
By separating NL-FOL translation into Ontology Extraction and Logical Translation subtasks, the evaluation isolates genuine logical capability from vocabulary mapping confusion. Providing a predefined ontology Ω = (σ, γ) constrains models to only perform logical mapping, eliminating confounds where models fail due to symbol invention rather than logical reasoning.

### Mechanism 2: Perturbation-Based Semantic Discrimination
On-the-fly perturbation tasks (most-similar, ranking) generate candidate sets dynamically using single-edit transformations and equivalence operations. This approach resists memorization and dataset contamination, forcing models to demonstrate semantic understanding rather than surface pattern matching.

### Mechanism 3: SMT-Based Equivalence Verification
Automated theorem proving via Z3 solver provides ground-truth verification of logical equivalence by checking satisfiability of ¬(φ ↔ φ'). This replaces flawed similarity metrics that treat FOL as propositional logic and ignore predicate dependencies.

## Foundational Learning

- **Concept: First-Order Logic Syntax and Semantics**
  - Why needed here: Understanding predicates, quantifiers (∀, ∃), connectives (∧, ∨, →, ↔, ¬), and how σ-structures assign meaning is prerequisite to interpreting benchmark results
  - Quick check question: Given φ = ∀x(Cube(x) → Small(x)) and a structure with domain {a, b} where Cube(a)=true, Small(a)=true, Cube(b)=true, Small(b)=false, does A ⊨ φ?

- **Concept: Negation Normal Form (NNF) and Equivalence Transformations**
  - Why needed here: The ranking task includes (¬φ)_nnf, requiring understanding that pushing negations to literals preserves meaning but changes syntax dramatically
  - Quick check question: Convert ¬(∀x(P(x) ∧ Q(x))) to NNF

- **Concept: Dialogue-Oriented vs. Embedding-Centric Model Paradigms**
  - Why needed here: Paper shows these architectures have fundamentally different FOL capabilities; results don't transfer between paradigms
  - Quick check question: Why would an embedding model optimized for semantic similarity struggle with FOL formulas despite high MTEB scores?

## Architecture Onboarding

- **Component map:**
  Dataset layer -> Task layer -> Verification layer -> Perturbation engine

- **Critical path:**
  1. Prepare dataset with manually defined ontologies
  2. For each triplet, generate perturbation sets F_ms (k=8) and F_r (k=3 + ¬φ + (¬φ)_nnf + φ_eq)
  3. Query model with structured output constraints
  4. Verify LT outputs via Z3, compute accuracy over 5 seeds for dialogue models

- **Design tradeoffs:**
  - Providing ontology Ω isolates LT but underestimates full NL-FOL pipeline capability
  - Zero-shot evaluation gives lower bounds but may underestimate achievable performance
  - Perturbation-only tasks resist memorization but don't measure generative capability
  - SMT verification is exact but limited to decidable fragments

- **Failure signatures:**
  - Models rank ¬φ and (¬φ)_nnf incorrectly → relying on syntactic similarity, not semantics
  - Large performance gap between NL and FOL variants → poor FOL parsing
  - High most-similar but low ranking scores → can identify correct answer but can't discriminate fine-grained differences

- **First 3 experiments:**
  1. Run zero-shot LT on D_FOLIO subset with provided Ω, verify with Z3
  2. Run most-similar task with varying perturbation counts (k=4, 8, 12)
  3. Train few-shot exemplars from D_Stanford, evaluate on D_FOLIO

## Open Questions the Paper Calls Out

- **Open Question 1:** Can current LLMs effectively perform Ontology Extraction (OE) independently, and what methods improve it?
  - Basis: Authors explicitly exclude OE to isolate Logical Translation, stating it "warrants a dedicated and rigorous analysis... we leave this subtask to future work"

- **Open Question 2:** To what extent do advanced prompting strategies (e.g., few-shot) improve NL-FOL translation accuracy?
  - Basis: Authors note that "a thorough analysis of prompting strategies... is left for future work," as they utilized zero-shot settings

- **Open Question 3:** Can embedding-centric models be improved to capture logical semantics comparably to dialogue-oriented models?
  - Basis: Paper identifies underperformance of embedding models and suggests "exploring alternative embedding-similarity metrics" as future work

## Limitations
- Manual ontology construction approach may not generalize to broader NL-FOL domains
- Evaluation limited to two specific datasets with relatively small instance counts
- Full pipeline capability (joint ontology extraction + logical translation) remains untested

## Confidence
- **Confidence Level: Medium** - Novel benchmarking strategy demonstrates advantages but limited to specific datasets
- **Confidence Level: Low** - Perturbation resistance claim relies on assumption about pre-training contamination
- **Confidence Level: High** - SMT-based equivalence verification is mechanistically sound for tested formula classes

## Next Checks
1. **Cross-Dataset Generalization Test**: Evaluate models trained on D_FOLIO against a held-out test set from a completely different FOL corpus to measure true generalization

2. **Perturbation Robustness Analysis**: Systematically vary perturbation counts (k=4, 8, 12) in most-similar tasks while monitoring accuracy degradation

3. **Full Pipeline Capability Assessment**: Implement joint ontology extraction + logical translation evaluation on models that excel at the isolated LT task