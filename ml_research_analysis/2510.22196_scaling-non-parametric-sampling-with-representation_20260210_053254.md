---
ver: rpa2
title: Scaling Non-Parametric Sampling with Representation
arxiv_id: '2510.22196'
source_url: https://arxiv.org/abs/2510.22196
tags:
- image
- statistics
- arxiv
- images
- class
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes a minimalistic, white-box generative model
  that leverages three principles of natural images: spatial non-stationarity, low-level
  regularities, and high-level semantics. The method generates each pixel by sampling
  from an empirical conditional distribution derived from a pool of similar source
  patches retrieved from the dataset, conditioned on both local context and a global
  representation.'
---

# Scaling Non-Parametric Sampling with Representation

## Quick Facts
- **arXiv ID:** 2510.22196
- **Source URL:** https://arxiv.org/abs/2510.22196
- **Reference count:** 40
- **Primary result:** Non-parametric generative model produces CIFAR-10 images with FID 60.357, achieving part-whole generalization via compositional recombination of patches from training corpus.

## Executive Summary
This paper introduces a white-box, non-parametric generative model that synthesizes images by sampling pixels from an empirical distribution over training patches. Grounded in three principles—spatial non-stationarity, low-level regularities, and high-level semantics—the method conditions retrieval on both local context and global SSL embeddings. Experiments on MNIST and CIFAR-10 demonstrate high-fidelity generation and compositional "part-whole" generalization, where coherent wholes are assembled from multiple source images. Source-tracing analysis reveals low class entropy paired with high image-ID entropy, confirming that the model recombines semantic parts rather than copying whole images.

## Method Summary
The model generates each pixel by retrieving patches from the training set that minimize a composite distance: Gaussian-weighted SSD for local texture, L∞ norm for spatial locality, and L2 distance in a SimCLR embedding space for global semantics. Patches meeting adaptive thresholds form an empirical distribution; the center pixel is sampled uniformly. Generation proceeds in concentric shells from an 8×8 seed, requiring no training beyond SSL encoder pre-computation. The approach enables full source traceability for mechanistic analysis.

## Key Results
- Achieves CIFAR-10 FID of 60.357 and IS of 5.903 without any training.
- Reveals "part-whole generalization": generated objects are composed from semantically coherent parts across multiple source images.
- Demonstrates compositional generation through source-tracing: low class entropy (semantic purity) with high image-ID entropy (multi-image composition).

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** High-fidelity generation via compositional patch recombination, constrained by local texture and global semantic similarity.
- **Mechanism:** Empirical pixel distribution built from training patches minimizing composite distance (SSD + locality + SSL embedding).
- **Core assumption:** SSL embeddings disentangle object identity from background, ensuring semantic compatibility of retrieved patches.
- **Evidence anchors:** [abstract] "generates each pixel by sampling from an empirical distribution over patches... conditioned on local context window and a global representation." [section 2.4] "Candidates must agree not only on local appearance but also on a compact, global summary of the content."
- **Break condition:** Insufficient context window or weak SSL embedding leads to texture synthesis (incoherent fragments) or loss of object identity.

### Mechanism 2
- **Claim:** Spatial non-stationarity prevents "texture of squiggles" failure by restricting patch retrieval to similar spatial coordinates.
- **Mechanism:** Locality constraint (d_loc ≤ R_loc) limits candidates to patches centered at similar relative positions in source images.
- **Core assumption:** Training dataset exhibits consistent spatial statistics (e.g., centered objects).
- **Evidence anchors:** [abstract] "...grounded in three principles of natural images: spatial non-stationarity..." [section 2.4] "sampling with d_SSD produces patchwork artifacts... [with locality] samples generated... resemble coherent digits much more."
- **Break condition:** Strict locality constraints suppress valid modes in datasets requiring diverse spatial layouts.

### Mechanism 3
- **Claim:** Generalization occurs through "part-whole" composition, not memorization, enforced by high entropy in source image IDs within semantically pure regions.
- **Mechanism:** Source-tracing shows generated objects assembled from multiple distinct source images of the same class.
- **Core assumption:** Semantic coherence equals class purity in source maps.
- **Evidence anchors:** [abstract] "...revealing a compositional 'part-whole generalization' where the model assembles new wholes from coherent parts drawn from multiple training images." [section 3.3] "...signature of part-whole generalization is low class-entropy together with high image-ID entropy."
- **Break condition:** Overly restrictive candidate pool threshold (R) causes image-ID entropy to drop to zero, indicating exact copying (overfitting).

## Foundational Learning

- **Concept:** **Non-Parametric Statistics (k-NN / Kernel Density)**
  - **Why needed here:** Core generator estimates densities directly from data; understanding bias-variance tradeoffs in nearest-neighbor search is critical.
  - **Quick check question:** How does the threshold radius R affect the bias (blurriness) vs. variance (noise) of the generated pixel?

- **Concept:** **Self-Supervised Learning (SSL) Representations**
  - **Why needed here:** Model relies on pre-trained encoders (e.g., SimCLR) to define semantic similarity; without this, cannot distinguish "dog texture" from "dog object."
  - **Quick check question:** Does the SSL encoder enforce invariance to position? If so, does this conflict with the spatial non-stationarity constraint?

- **Concept:** **Autoregressive Generation**
  - **Why needed here:** Image synthesized sequentially (shell-by-shell); errors in early pixels propagate into future context windows.
  - **Quick check question:** How does the order of pixel synthesis (e.g., concentric shells vs. raster scan) impact the accumulation of error artifacts?

## Architecture Onboarding

- **Component map:** Canvas -> Context Window (ω(p)) -> Retrieval System (computes d_SSD, d_loc, d_SSL) -> Sampler (draws from histogram of center pixels)
- **Critical path:** Adaptive thresholds (R_SSD, R_SSL) in Section 2.4 determine candidate pool size; too tight stalls generation, too loose loses coherence.
- **Design tradeoffs:**
  - Explicit SSL conditioning vs. Class-Conditional: SSL more general but yields higher FID; class-conditional better for benchmarks.
  - White-box interpretability vs. Performance: Sacrifices raw SOTA metrics for full source-traceability.
- **Failure signatures:**
  - "Shattered" Strokes: High-frequency details broken; fix by tightening d_SSD or increasing context window.
  - Patchwork/Texture Artifacts: Object identity lost; fix by strengthening d_SSL weighting or verifying SSL encoder quality.
  - Copying (Overfitting): Generated images identical to training; fix by loosening thresholds to increase candidate pool entropy.
- **First 3 experiments:**
  1. Ablation on Principles: Generate MNIST using only d_SSD, then add d_loc, then d_SSL to visualize artifact reduction (Fig 2).
  2. Source-Tracing Analysis: Generate CIFAR image, plot Class Map and Image-ID Map (Fig 6); verify high image-ID entropy (recombination) with low class-map entropy (coherence).
  3. Threshold Sensitivity: Vary locality radius R_loc on dataset with high pose variance to test if strict locality breaks generation.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Do large-scale autoregressive transformers implicitly implement a simple non-parametric retrieval algorithm in their latent token space, similar to the proposed model's patch-matching mechanism?
- **Basis in paper:** [explicit] Authors propose testing: "We could encode image into token like the standard process of autoregressive model, then perform our non-parametric model in the token space, then compare the generation result with a transformer based autoregressive model."
- **Why unresolved:** While the hypothesis is suggested, no experimental validation comparing token-space non-parametric sampling against standard transformer outputs is provided.
- **What evidence would resolve it:** Experiment showing non-parametric sampler on pre-trained Vision Transformer tokens generates images statistically similar to the original transformer.

### Open Question 2
- **Question:** Can replacing raw pixel copying with a dictionary of human-readable "atomic" parts (e.g., Gabor-like elements) improve generalization capability and efficiency of non-parametric generators?
- **Basis in paper:** [explicit] Listed as future direction: "moving from copying raw pixels to composing a small dictionary of 'atomic' parts (e.g., steerable/Gabor-like elements or learned but human-readable primitives) before rendering pixels."
- **Why unresolved:** Current implementation copies raw pixels; it remains untested whether abstracting into a parts dictionary preserves "part-whole generalization" capability.
- **What evidence would resolve it:** Implementation retrieving dictionary indices/coefficients rather than pixels, followed by analysis showing improved FID/IS or better handling of high-frequency details.

### Open Question 3
- **Question:** To what extent can stronger self-supervised representation encoders close the quantitative performance gap between representation-conditioned and class-conditional generative models?
- **Basis in paper:** [explicit] Authors note current SSL embedding (SimCLR) "under-represents portions of the semantic space," resulting in performance gap vs. class-conditional sampling, and suggest "stronger or task-aligned conditioning representations" as improvement avenue.
- **Why unresolved:** Unclear if observed performance gap (FID 60.357 vs 32.924) is inherent limitation of non-parametric approach or specific failure of SimCLR features to capture fine-grained semantic distinctions.
- **What evidence would resolve it:** Ablation studies substituting SimCLR with more modern representations (e.g., DINOv2, MAE) and measuring resulting reduction in FID gap on CIFAR-10.

### Open Question 4
- **Question:** Can incorporating light, non-parametric mechanisms for long-range interaction (such as attention-like retrieval) improve spatial coherence without sacrificing interpretability?
- **Basis in paper:** [explicit] Authors identify need for "modeling long-range interaction" and suggest "a multi-scale or attention-like retrieval that remains non-parametric" as potential method to close gap with SOTA models.
- **Why unresolved:** Current model relies on global representation vector for long-range coherence, which may lack precision of explicit long-range spatial mechanisms.
- **What evidence would resolve it:** Extending context window or similarity metric to include multi-scale patch comparisons, demonstrating reduction in structural artifacts (e.g., broken strokes) while maintaining source-traceability.

## Limitations
- Scalability to larger, more complex datasets (e.g., ImageNet) without significant modifications to retrieval and sampling pipeline remains untested.
- Heavy dependence on pre-trained SSL encoders, though technically "no training" is claimed.
- Spatial non-stationarity prior may limit applicability to datasets with irregular object layouts.

## Confidence
- **High Confidence:** White-box nature and interpretability through source-tracing; compositional generation mechanism well-demonstrated.
- **Medium Confidence:** Claims of competitive performance without SOTA and generalizability of three principles across datasets.
- **Low Confidence:** Scalability claims to larger, more complex datasets without significant modifications.

## Next Checks
1. **Threshold Sensitivity Analysis:** Systematically vary R_SSD, R_SSL, and R_loc across orders of magnitude to quantify impact on FID, IS, and source-tracing entropy metrics.
2. **Dataset Diversity Test:** Apply model to dataset with high spatial variance (e.g., LSUN bedrooms with random object placement) to test if locality constraint breaks generation.
3. **SSL Encoder Ablation:** Replace SimCLR encoder with weaker representation (e.g., raw pixels, randomly initialized network) to verify SSL constraint necessity for semantic coherence.