---
ver: rpa2
title: Quantum Model Parallelism for MRI-Based Classification of Alzheimer's Disease
  Stages
arxiv_id: '2602.00128'
source_url: https://arxiv.org/abs/2602.00128
tags:
- quantum
- classification
- https
- classical
- alzheimer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study proposes a Quantum-Based Parallel Model (QBPM) for classifying
  Alzheimer's disease stages using MRI data. Inspired by classical model parallelism,
  the QBPM employs two distinct quantum circuits that run in parallel on a quantum
  simulator to capture complex patterns in MRI images, such as brain atrophy and ventricular
  enlargement.
---

# Quantum Model Parallelism for MRI-Based Classification of Alzheimer's Disease Stages

## Quick Facts
- arXiv ID: 2602.00128
- Source URL: https://arxiv.org/abs/2602.00128
- Reference count: 40
- One-line result: Quantum-Based Parallel Model achieves 0.90 training and 0.93 validation accuracy on Alzheimer's MRI classification, outperforming classical transfer learning methods.

## Executive Summary
This study proposes a Quantum-Based Parallel Model (QBPM) for classifying Alzheimer's disease stages using MRI data. The model employs two distinct quantum circuits running in parallel on a quantum simulator to capture complex patterns in MRI images, such as brain atrophy and ventricular enlargement. When evaluated on the OASIS-1 dataset, the QBPM achieved training and validation accuracies of 0.90 and 0.93, respectively, outperforming five classical transfer learning methods while using fewer circuit parameters. The model demonstrates robust performance under high-level Gaussian noise, showing practical applicability for early-stage Alzheimer's disease classification.

## Method Summary
The QBPM architecture processes MRI images through amplitude encoding into 15 qubits, then applies two parallel parameterized quantum circuits (20 layers each) with distinct entanglement topologies. Circuit 1 uses CNOT gates for dense all-to-all and cyclic ring entanglement, while Circuit 2 employs CY gates for global entanglement. Both circuits incorporate rotational and entanglement blocks, outputting expectation values via Pauli-Z measurements. The results are concatenated and passed through a softmax layer for classification. The model was trained using the Adam optimizer with parameter-shift rule for gradient computation on the OASIS-1 dataset, achieving 0.90 training and 0.93 validation accuracy.

## Key Results
- Achieved 0.90 training and 0.93 validation accuracy on original OASIS-1 dataset
- Outperformed five classical transfer learning methods (EfficientNetB0, InceptionV3, MobileNetV2, ResNet50, VGG16)
- Maintained robust performance under high-level Gaussian noise, demonstrating practical applicability
- Used fewer circuit parameters compared to classical baselines (1,803 vs ~6,000 in ResNet50)

## Why This Works (Mechanism)

### Mechanism 1
Parallel quantum circuits with distinct entanglement topologies capture complementary feature patterns in MRI data. Two parameterized quantum circuits execute simultaneously on the same simulator - Circuit 1 uses CNOT gates for dense all-to-all and cyclic ring entanglement, while Circuit 2 uses CY gates for global entanglement. Each circuit learns parameters independently via gradient descent, then outputs are concatenated post-measurement. The distinct entanglement patterns induce different correlation structures that, when combined, improve discrimination of AD stages such as brain atrophy and ventricular enlargement.

### Mechanism 2
Amplitude encoding enables logarithmic qubit efficiency for high-dimensional MRI inputs. An N-dimensional feature vector is encoded into log₂(N) qubits by mapping normalized pixel values to quantum state amplitudes: |ψ⟩ = Σᵢ xᵢ |i⟩. This projects data into a high-dimensional Hilbert space without requiring N qubits. For the 10,000-dimensional input vector (100×100×3 images), only 15 qubits are needed. The normalization preserves discriminative spatial information from MRI scans after resizing and Min-Max scaling.

### Mechanism 3
Unified decision-making via measurement concatenation improves classification over single-circuit outputs. Both parallel circuits output expectation values ⟨Zₖ⟩ ∈ [-1, 1] via Pauli-Z measurements. These vectors are concatenated: logit = concat(logitₖ, logit'ₖ) + bias, then passed to softmax for class probabilities. The two circuits extract non-redundant information, and concatenation yields a richer representation than either circuit alone.

## Foundational Learning

- **Parameterized Quantum Circuits (PQCs) and Ansatz Design**: The QBPM architecture is built on layered PQCs with rotation (U₃, Rₓ, Rᵧ) and entanglement (CNOT, CY, CCNOT) blocks. Understanding how parameterized gates form trainable quantum neural networks is essential.
  - Why needed here: The entire model architecture depends on these quantum circuit designs
  - Quick check question: Can you explain why the parameter-shift rule enables gradient computation without backpropagation through quantum states?

- **Amplitude Encoding and Hilbert Space Representation**: The model maps MRI pixel data to quantum state amplitudes. This determines qubit count, normalization requirements, and information density.
  - Why needed here: The encoding method directly affects model capacity and efficiency
  - Quick check question: For a 10,000-dimensional input vector, how many qubits are required for amplitude encoding?

- **Classical Model Parallelism (Inspiration for QBPM)**: The paper explicitly draws analogy to distributing model layers across GPUs. Understanding this helps interpret why two circuits run on the same simulator rather than truly distributed hardware.
  - Why needed here: Provides context for the parallel architecture design choice
  - Quick check question: How does quantum parallel circuit execution differ fundamentally from classical model parallelism across GPUs?

## Architecture Onboarding

- **Component map**: Preprocessing (Classical) → Feature Mapping (Quantum) → Parallel PQCs (Quantum) → Measurement (Quantum) → Post-Processing (Classical) → Optimization (Hybrid)
- **Critical path**: Data → Normalization → Amplitude Encoding → Parallel Circuits → Measurements → Concatenation → Softmax → Loss → Parameter Update
- **Design tradeoffs**: 1,803 trainable parameters vs. ~6,000 in frozen ResNet50 (parameter efficiency); 20 layers depth balances expressivity against NISQ noise sensitivity; parameter sharing in Rₓ and Rᵧ gates reduces overfitting risk but limits circuit expressivity; simulation on PennyLane default.qubit does not model hardware noise natively
- **Failure signatures**: High validation loss with low training loss indicates late-stage overfitting (observed at epoch ~12); accuracy drop under gate-level noise from 0.93 → 0.77 validation accuracy; class imbalance with Moderate dementia having only 488 samples vs. 67,222 non-demented
- **First 3 experiments**:
  1. Ablation study: Run each PQC (Circuit 1, Circuit 2) independently and compare accuracy vs. parallel concatenated output to validate the unified decision mechanism
  2. Noise robustness sweep: Test Gaussian noise factors (0.1, 0.3, 0.5) on both images and gate parameters to identify degradation thresholds before 10% accuracy loss
  3. Encoding comparison: Replace amplitude encoding with angle encoding and measure impact on qubit count, training time, and classification accuracy under identical conditions

## Open Questions the Paper Calls Out

### Open Question 1
Can the proposed QBPM architecture maintain robust classification performance when executed on real NISQ devices utilizing error correction codes?
- Basis in paper: The authors acknowledge that since the model was executed on a simulator (default.qubit), error correction codes were not employed. They explicitly aim to use actual quantum computers in future studies to integrate these codes.
- Why unresolved: The current results rely on idealized simulations; real quantum hardware introduces physical noise and decoherence that simulation-based noise models may not fully capture.
- What evidence would resolve it: Reproducing the classification accuracy and noise resilience benchmarks on physical quantum hardware equipped with error mitigation strategies.

### Open Question 2
How does the integration of multimodal data (genomic, clinical, PET) impact the learning capacity and decision-making of the QBPM architecture?
- Basis in paper: The authors state a future goal to transform the model into an "end-to-end quantum artificial intelligence system" that integrates genomic, clinical, and PET data alongside MRI.
- Why unresolved: The current architecture is optimized solely for MRI image classification using amplitude encoding; it is unclear how the model will handle the dimensionality and heterogeneity of other data modalities.
- What evidence would resolve it: Demonstrated performance metrics of a modified QBPM architecture trained on combined multimodal datasets compared to MRI-only baselines.

### Open Question 3
Does the model maintain generalization capability when tested on larger datasets obtained from more diverse demographic and clinical sources?
- Basis in paper: The authors identify a limitation that the model was only evaluated on two specific datasets (OASIS-1 and ADNI) and call for testing on larger datasets to better assess robustness.
- Why unresolved: While external validation was performed, the limited variety in data sources may not fully represent the variability found in global patient populations.
- What evidence would resolve it: Consistent accuracy, precision, and recall scores across significantly larger, multi-center datasets with diverse patient profiles.

## Limitations

- The amplitude encoding implementation is not fully specified for non-power-of-two input dimensions, creating uncertainty about data preprocessing steps
- The model's sensitivity to Gaussian noise (accuracy dropping from 0.93 to 0.77) raises concerns about practical deployment on real-world, noisy MRI data
- Missing ablation study comparing single vs. parallel circuit performance makes it difficult to quantify the true benefit of the parallel architecture

## Confidence

- **High Confidence**: The parallel circuit architecture and amplitude encoding mechanism are clearly described in the methodology section, with specific gate implementations and entanglement patterns detailed
- **Medium Confidence**: The classification performance metrics (0.90 training, 0.93 validation accuracy) are well-documented, though external validation on ADNI dataset lacks comparative benchmarks
- **Low Confidence**: The specific benefits of parallel circuit execution versus single-circuit alternatives remain unproven due to missing ablation experiments

## Next Checks

1. **Ablation Study**: Train and evaluate Circuit 1 and Circuit 2 independently, then compare their combined performance against the parallel concatenated model to quantify the parallel architecture benefit

2. **Encoding Method Comparison**: Replace amplitude encoding with angle encoding while maintaining identical model architecture to measure impact on qubit requirements, training efficiency, and classification accuracy

3. **Noise Robustness Analysis**: Systematically test Gaussian noise levels (0.1, 0.3, 0.5) on both input images and gate parameters to identify degradation thresholds and compare against classical transfer learning baselines under identical conditions