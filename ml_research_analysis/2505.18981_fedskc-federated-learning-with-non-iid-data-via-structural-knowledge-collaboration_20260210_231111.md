---
ver: rpa2
title: 'FedSKC: Federated Learning with Non-IID Data via Structural Knowledge Collaboration'
arxiv_id: '2505.18981'
source_url: https://arxiv.org/abs/2505.18981
tags:
- global
- local
- knowledge
- structural
- fedskc
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'FedSKC addresses the challenge of non-IID data in federated learning
  by decomposing the problem into three drift sub-problems: local, global, and sampling
  drift. The method introduces a novel framework that leverages structural knowledge
  collaboration across clients.'
---

# FedSKC: Federated Learning with Non-IID Data via Structural Knowledge Collaboration

## Quick Facts
- arXiv ID: 2505.18981
- Source URL: https://arxiv.org/abs/2505.18981
- Authors: Huan Wang; Haoran Li; Huaming Chen; Jun Yan; Lijuan Wang; Jiahua Shi; Shiping Chen; Jun Shen
- Reference count: 40
- Primary result: FedSKC addresses non-IID federated learning through structural knowledge collaboration, achieving state-of-the-art accuracy with faster convergence

## Executive Summary
FedSKC introduces a novel federated learning framework that decomposes data heterogeneity into three drift sub-problems: local, global, and sampling drift. The method leverages structural knowledge collaboration by extracting class-wise prototype features from each client's local model and aggregating these into global structural knowledge at the server. Through three key components - Local Contrastive Learning, Global Discrepancy Aggregation, and Global Period Review - FedSKC effectively addresses non-IID challenges while maintaining strong theoretical convergence guarantees. Experimental results demonstrate significant improvements over state-of-the-art methods across multiple challenging scenarios including non-IID data, long-tailed distributions, and few-shot learning.

## Method Summary
FedSKC decomposes federated learning heterogeneity into three drift sub-problems and addresses each through structural knowledge collaboration. The framework extracts class-wise prototype features (structural knowledge) from each client's local model, which are aggregated at the server to form global structural knowledge. Three components work in tandem: Local Contrastive Learning aligns local features to global prototypes using contrastive loss; Global Discrepancy Aggregation weights client contributions based on data volume and structural knowledge discrepancy; and Global Period Review applies momentum-based blending of consecutive global models weighted by structural knowledge variance. The approach is theoretically analyzed under non-convex objectives and validated across multiple challenging federated learning scenarios.

## Key Results
- On CIFAR-10 with α=0.2, FedSKC achieves 82.35% accuracy, outperforming baselines by 3.74%
- Requires fewer communication rounds to converge while achieving higher accuracy than state-of-the-art methods
- Demonstrates significant improvements across multiple challenging scenarios including non-IID data, long-tailed distributions (ρ=100), and few-shot learning (5-way 5-shot)
- Shows superior performance on EMNIST and CIFAR-100 benchmarks with similar relative gains

## Why This Works (Mechanism)

### Mechanism 1: Local Contrastive Learning (LCL)
- Claim: Aligning local feature representations to global class prototypes reduces local drift by providing consistent class-wise decision boundaries across heterogeneous clients
- Mechanism: For each sample, the output feature and its corresponding global structural knowledge form a positive pair; features and non-matching class prototypes form negative pairs. The contrastive loss pulls same-class features toward the aggregated prototype while pushing different-class features away
- Core assumption: Global structural knowledge (class prototypes) represents a reliable, unbiased class-wise decision boundary that generalizes better than local optima
- Evidence anchors:
  - [abstract] "Local Contrastive Learning (LCL) uses inter-contrastive learning to regulate local training by maximizing similarity between local features and global structural knowledge"
  - [section III-B] Equation (3): LCL loss formulation with positive/negative pair structure
  - [corpus] Related work FedRCL and MOON similarly leverage contrastive learning in FL, suggesting this is an established direction
- Break condition: If global structural knowledge is itself biased (e.g., heavily skewed by dominant clients), LCL may reinforce incorrect decision boundaries rather than correct them

### Mechanism 2: Global Discrepancy Aggregation (GDA)
- Claim: Weighting client contributions by both data volume and structural knowledge discrepancy produces more representative global models under non-IID conditions
- Mechanism: The aggregation weight combines client data size N_k with discrepancy d_k (L2 distance between local and global prototypes). Clients with larger datasets and smaller discrepancy receive higher weights. Sigmoid normalization balances these factors
- Core assumption: Structural knowledge discrepancy correlates with how much a client's update should contribute—lower discrepancy implies better alignment with the global objective
- Evidence anchors:
  - [abstract] "Global Discrepancy Aggregation (GDA) optimizes aggregation weights by considering the discrepancy between local and global structural knowledge"
  - [section III-B] Equation (4): aggregation weight formulation using Sigmoid(N_k - a_k·d_k + b_k)
  - [corpus] FedDisco and similar methods explore discrepancy-aware aggregation, indicating this is a recognized strategy
- Break condition: If all participating clients in a round are highly non-representative of the global distribution, GDA cannot recover from sampling bias—it only reweights among available clients

### Mechanism 3: Global Period Review (GPR)
- Claim: Momentum-based blending of consecutive global models, weighted by structural knowledge variance, stabilizes training under random client sampling
- Mechanism: The global model is updated by interpolating between current and previous models. The interpolation coefficient depends on variance changes in global structural knowledge—larger variance increases suggests instability, triggering more reliance on historical momentum
- Core assumption: Variance in global structural knowledge reflects training stability; increasing variance signals need for conservative updates
- Evidence anchors:
  - [abstract] "Global Period Review (GPR) combines previous and current global models through relative confidence based on structural knowledge variance to correct sampling drift"
  - [section III-B] Equation (5): w_g^r = β·w_g^r + (1-β)·(variance-based adjustment term)
  - [corpus] Related papers (FedHiP, FedRCL) do not explicitly address sampling drift correction, suggesting GPR is a distinct contribution
- Break condition: Under systematic distribution shift (e.g., concept drift over time), momentum-based correction may inappropriately anchor to outdated models

## Foundational Learning

- Concept: **Contrastive Learning (InfoNCE Loss)**
  - Why needed here: LCL uses contrastive loss to structure the feature space. Understanding temperature τ, positive/negative pairs, and the softmax-over-similarity formulation is essential
  - Quick check question: Can you explain why lower temperature sharpens the contrastive objective and what failure mode occurs if τ is too small?

- Concept: **Prototype Learning in FL**
  - Why needed here: FedSKC extracts class prototypes as structural knowledge. Understanding how prototypes represent class distributions and why averaging features preserves privacy (vs. raw data) is foundational
  - Quick check question: Why might a class prototype from a single non-IID client be misleading as a global representative?

- Concept: **FL Drift Decomposition (Local/Global/Sampling)**
  - Why needed here: The paper decomposes heterogeneity into three drift types, each addressed by a different component. Understanding this taxonomy clarifies why three mechanisms are needed
  - Quick check question: For a scenario with 100 clients where only 10 participate per round with highly skewed label distributions, which drift type dominates?

## Architecture Onboarding

- Component map:
  - Client-side: Feature extractor h_k → classifier g_k → local prototype extraction c_k → LCL loss computation using received global prototypes
  - Server-side: Prototype aggregation (structure-aware adjacency matrix) → GDA weight computation → model aggregation → GPR momentum update
  - Communication: Models (w_k) + local prototypes (c_k) uploaded; global models (w_g) + global prototypes (c̃) downloaded

- Critical path:
  1. Client receives w_g^r and c̃^r from server
  2. Local training: L_total = L_CE + L_LCL (Equation 3)
  3. Client computes local prototypes c_k and uploads with w_k
  4. Server builds adjacency matrix A_j (Equation 1), aggregates global prototypes c̃
  5. Server computes GDA weights e_k (Equation 4) and aggregates model
  6. Server applies GPR adjustment (Equation 5), broadcasts w_g^{r+1}, c̃^{r+1}

- Design tradeoffs:
  - Communication overhead: Transmitting C prototypes (C = number of classes) per client adds O(C·d) per round. For C=100 and d=512, this is ~51KB—acceptable for most scenarios but non-trivial on bandwidth-constrained edges
  - Privacy vs. utility: Prototypes are aggregated means with non-linear transforms; the paper claims this is irreversible. However, with very few samples per class, prototype leakage risk increases
  - M parameter (similar clients): M=1 (merge with nearest client) improves prototype quality; larger M dilutes semantic specificity. Default M=1 is empirically validated

- Failure signatures:
  - NaN in LCL loss: Temperature τ too small (τ < 0.01) causes numerical instability; check normalization term U
  - Accuracy collapse on long-tailed classes: GDA may underweight clients with rare classes if discrepancy is high; consider per-class discrepancy normalization
  - Oscillating convergence: β (momentum in GPR) set too low (< 0.8) causes instability under high sampling variance; increase β toward 0.95

- First 3 experiments:
  1. Sanity check on CIFAR-10 with α=0.2: Reproduce the 82.35% accuracy claim. Verify each component contributes via ablation (Table V). If accuracy is >2% off, check prototype extraction pipeline first
  2. Convergence rate validation: Plot test accuracy vs. communication rounds for FedSKC vs. FedAvg. Confirm FedSKC reaches 75% accuracy in ~84 rounds vs. FedAvg's 165 (Table III, CIFAR-10 α=0.2)
  3. Long-tailed stress test (CIFAR-10-LT ρ=100): Validate GDA effectiveness on severe imbalance. Expected: FedSKC achieves ~57.55% vs. FedAvg's 53.09%. If underperforming, inspect per-class prototype quality via t-SNE visualization (Figure 4 pattern)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Is the transfer of structural knowledge (prototypes) robust against advanced prototype inversion attacks?
- Basis in paper: [inferred] The Discussion section claims privacy preservation by asserting the transformation is "irreversible" without providing an empirical security analysis against reconstruction attacks
- Why unresolved: While the method avoids sharing raw gradients, sharing class-wise mean feature vectors (prototypes) can potentially leak semantic information if not rigorously tested against inversion techniques
- What evidence would resolve it: Empirical evaluation using gradient or prototype inversion attacks to quantify the information leakage from the shared $c_k$ vectors

### Open Question 2
- Question: How does FedSKC scale to cross-device scenarios with significantly larger client populations?
- Basis in paper: [inferred] The Experimental Setup limits the evaluation to $K=20$ clients (total), whereas real-world federated networks often involve thousands of devices
- Why unresolved: The Global Discrepancy Aggregation (GDA) and Global Period Review (GPR) modules rely on statistical properties (discrepancy/variance) which may behave differently or become computationally burdensome with massive client participation
- What evidence would resolve it: Experimental results on standard large-scale FL benchmarks (e.g., LEAF) or simulations with $K > 100$ to validate stability and communication efficiency

### Open Question 3
- Question: Can FedSKC be adapted to support heterogeneous model architectures across clients?
- Basis in paper: [inferred] The Preliminaries assume a consistent feature extractor $h_k$ mapping to a $d$-dim vector for all clients
- Why unresolved: The method relies on direct calculation of discrepancy ($d_k$) and cosine similarity in the embedding space, which requires aligned feature dimensions
- What evidence would resolve it: A modified framework or theoretical proof demonstrating knowledge collaboration between clients with different model backbones (e.g., varying ResNet depths)

## Limitations
- The convergence analysis under non-convex objectives relies on simplified assumptions about gradient boundedness and smoothness
- The structural knowledge framework introduces additional communication overhead through prototype transmission, which could be prohibitive in bandwidth-constrained edge environments
- Performance on extremely long-tailed distributions (ρ > 100) and robustness to concept drift over time are not thoroughly evaluated
- Privacy analysis of prototype aggregation could be more rigorous, particularly regarding membership inference attacks when class samples are very sparse

## Confidence
- **LCL Mechanism Effectiveness**: High confidence - Well-supported by ablation studies and consistent with established contrastive learning theory
- **GDA Weighting Strategy**: Medium confidence - Theoretically sound but assumption may break down in pathological non-IID scenarios
- **GPR Momentum Correction**: Medium confidence - Novel but lacks extensive validation across different sampling strategies and concept drift scenarios
- **State-of-the-art Claims**: High confidence - Substantial and consistent accuracy improvements across multiple benchmarks and heterogeneity levels

## Next Checks
1. **Ablation on M Parameter**: Systematically vary M (1, 3, 5) in the nearest-neighbor prototype merging to quantify the tradeoff between prototype quality and computational overhead, particularly for datasets with many classes

2. **Communication Efficiency Analysis**: Measure the actual bandwidth consumption per round (including prototypes) and compare against FedAvg with compressed updates to assess practical deployability in low-bandwidth scenarios

3. **Privacy Leakage Assessment**: Conduct membership inference attacks on extracted prototypes when class samples are minimal (≤5 per class) to quantify privacy-utility tradeoff and identify vulnerability thresholds