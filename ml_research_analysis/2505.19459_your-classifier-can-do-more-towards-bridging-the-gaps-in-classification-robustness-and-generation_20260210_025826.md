---
ver: rpa2
title: 'Your Classifier Can Do More: Towards Bridging the Gaps in Classification,
  Robustness, and Generation'
arxiv_id: '2505.19459'
source_url: https://arxiv.org/abs/2505.19459
tags:
- adversarial
- robustness
- training
- clean
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the triple trade-off between classification
  accuracy, adversarial robustness, and generative capability in deep learning models.
  While Joint Energy-based Models (JEMs) can achieve high accuracy and generation,
  they lack robustness compared to adversarial training (AT), which sacrifices accuracy
  and generation.
---

# Your Classifier Can Do More: Towards Bridging the Gaps in Classification, Robustness, and Generation

## Quick Facts
- arXiv ID: 2505.19459
- Source URL: https://arxiv.org/abs/2505.19459
- Authors: Kaichao Jiang; He Wang; Xiaoshuai Hao; Xiulong Yang; Ajian Liu; Qi Chu; Yunfeng Diao
- Reference count: 40
- Primary result: EB-JDAT achieves state-of-the-art robustness (68.76%, 35.63%, and 32.40% under AutoAttack) while maintaining near-original accuracy and generative performance on CIFAR-10, CIFAR-100, and ImageNet subsets.

## Executive Summary
This paper addresses the fundamental trade-off between classification accuracy, adversarial robustness, and generative capability in deep learning models. While Joint Energy-based Models (JEMs) excel at accuracy and generation, they lack robustness compared to adversarial training (AT), which sacrifices accuracy and generation. The authors propose Energy-based Joint Distribution Adversarial Training (EB-JDAT) to bridge these gaps by aligning the energy distributions of clean, adversarial, and generated samples through joint probability modeling. Extensive experiments demonstrate that EB-JDAT resolves the triple trade-off, achieving state-of-the-art robustness while preserving accuracy and generative performance.

## Method Summary
EB-JDAT extends adversarial training by incorporating energy-based modeling of clean, adversarial, and generated samples. The method uses a min-max energy optimization framework where the inner maximization finds high-energy adversarial examples, and the outer minimization aligns their energy with clean samples. The model jointly optimizes three gradient components: generative (h₁), adversarial density (h₂), and classification (h₃). SGLD sampling generates synthetic samples for training, while adversarial examples are created through energy maximization. The approach is compatible with various JEM variants and maintains stability through careful gradient balancing.

## Key Results
- Achieves 68.76%, 35.63%, and 32.40% AutoAttack robustness on CIFAR-10, CIFAR-100, and ImageNet subset respectively
- Maintains near-original classification accuracy while adding robustness (e.g., 90.39% vs 96.03% clean accuracy)
- Preserves strong generative performance (comparable FID/IS scores to base JEMs)
- Outperforms existing AT methods and energy-based approaches on triple trade-off benchmarks

## Why This Works (Mechanism)

### Mechanism 1: Energy Distribution Alignment
The method aligns energy distributions across clean, adversarial, and generated samples by jointly modeling their probability distribution. This resolves the fundamental misalignment that causes the accuracy-robustness-generation trade-off. The core assumption is that aligning these energy landscapes can simultaneously optimize all three objectives.

### Mechanism 2: Min-Max Energy Optimization for Adversarial Sampling
Adversarial training is reformulated as a min-max game over energy values rather than logits. The inner maximization searches for high-energy adversarial examples, while the outer minimization pulls them back into low-energy regions. This approach better represents the adversarial distribution and fills energy gaps.

### Mechanism 3: Joint Gradient Decomposition
Training signals are decomposed into three distinct gradient components (generative, adversarial, classification) that are combined to stabilize hybrid model training. This explicit balancing prevents the conflicts that typically arise when combining generative and discriminative objectives.

## Foundational Learning

- **Energy-Based Models (EBMs)**: Required to understand how the classifier is reinterpreted as an energy function where logits represent energy values. Quick check: How does the partition function affect the distinction between softmax classifiers and EBMs?

- **Stochastic Gradient Langevin Dynamics (SGLD)**: Used to sample from the model distribution for gradient estimation and negative sample generation. Quick check: Why must Gaussian noise be added to gradient steps during sampling?

- **Adversarial Training (AT) as Saddle Point Problem**: EB-JDAT extends standard AT's min-max formulation. Quick check: In standard AT, what does the inner maximization optimize for, and how does EB-JDAT modify this objective?

## Architecture Onboarding

- **Component map**: Backbone (WRN28-10) -> Energy Function (Linear head) -> Sampler (SGLD module) -> Loss Compositor (gradient aggregator)

- **Critical path**: Calculation of h₂ (Adversarial Gradient) via the min-max optimization loop. Errors in this step break the alignment between clean and adversarial energy distributions.

- **Design tradeoffs**: 
  - Sampling Steps (M_adv): Too few yield weak adversarial samples; too many risk model collapse (paper recommends 5 steps)
  - Weights (w₁, w₂, w₃): All set to 1 for optimal trade-off; setting w₂=0 reverts to standard JEM
  - Compute requirements: Significantly higher than standard AT due to sampling iterations

- **Failure signatures**: 
  - Model Collapse: Generation quality degrades to noise; monitor FID scores
  - Robustness-Accuracy Gap: If robustness improves but accuracy drops significantly
  - Training Divergence: If gradients become too large or samples become mode-dominated

- **First 3 experiments**:
  1. Sanity Check: Replicate JEM++ training on CIFAR-10 to verify SGLD sampling stability
  2. Ablation on Adversarial Steps: Train with M_adv ∈ {1, 5, 10} to identify stability thresholds
  3. Energy Visualization: Plot energy distributions for clean vs. PGD-20 samples before/after training

## Open Questions the Paper Calls Out

- **Open Question 1**: Can EB-JDAT be stabilized for full-scale, high-resolution datasets? The paper notes training on complex, high-dimensional data remains challenging due to sharp probability distributions leading to inaccurate guidance in low-density regions.

- **Open Question 2**: Is it theoretically possible to completely eliminate the 6% clean accuracy degradation when applying adversarial training to JEMs? While the method improves the trade-off, it doesn't achieve a "free lunch" where robustness is added without any cost to discriminative performance.

- **Open Question 3**: Does the min-max energy optimization framework generalize to non-ResNet architectures like Vision Transformers? All experiments were conducted using WideResNet, and the energy landscape of Transformers may differ significantly.

## Limitations
- Method requires significantly more computational resources than standard adversarial training due to sampling iterations
- Training stability is sensitive to hyperparameter tuning, particularly SGLD step sizes
- Current experiments are limited to small-scale datasets (CIFAR, 64×64 ImageNet subset)
- Theoretical connection between energy overlap and robustness lacks rigorous mathematical proof

## Confidence
- **High Confidence**: Experimental results showing state-of-the-art robustness while maintaining generation quality are well-supported by quantitative metrics across multiple datasets
- **Medium Confidence**: Theoretical framework connecting energy distribution alignment to triple trade-off is logically coherent but could benefit from deeper mathematical analysis
- **Low Confidence**: Claims about generalizability to other JEM variants and absence of specific failure rate data reduce confidence in real-world deployment

## Next Checks
1. **Failure Mode Analysis**: Systematically quantify frequency and severity of model collapse across different hyperparameter settings and datasets
2. **Mathematical Proof Extension**: Develop rigorous proofs connecting energy distribution overlap hypothesis to adversarial robustness guarantees
3. **Cross-Architecture Generalization**: Validate method compatibility with architectures beyond WideResNet (e.g., Vision Transformers)