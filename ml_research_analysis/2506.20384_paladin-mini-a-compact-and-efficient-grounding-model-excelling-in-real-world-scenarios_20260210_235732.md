---
ver: rpa2
title: 'Paladin-mini: A Compact and Efficient Grounding Model Excelling in Real-World
  Scenarios'
arxiv_id: '2506.20384'
source_url: https://arxiv.org/abs/2506.20384
tags:
- paladin-mini
- performance
- data
- claim
- grounding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Paladin-mini is a 3.8B parameter open-source grounding model trained
  to classify claims as grounded or ungrounded in a document. It uses synthetic data
  focused on real-world weaknesses like numerical and temporal reasoning, rather than
  general fact-checking.
---

# Paladin-mini: A Compact and Efficient Grounding Model Excelling in Real-World Scenarios

## Quick Facts
- **arXiv ID**: 2506.20384
- **Source URL**: https://arxiv.org/abs/2506.20384
- **Authors**: Dror Ivry; Oran Nahum
- **Reference count**: 0
- **Primary result**: 3.8B model achieves 96% BACC on price/math tasks vs 46% for 7B competitor

## Executive Summary
Paladin-mini is a 3.8B parameter open-source grounding model that excels at classifying claims as grounded or ungrounded in documents, particularly for numerical and temporal reasoning tasks. Trained on synthetic data targeting real-world weaknesses rather than general fact-checking, it achieves 96% balanced accuracy on price/math tasks compared to 46% for a 7B competitor, while maintaining competitive performance on general benchmarks. The model demonstrates that compact, specialized models can outperform larger generalist models in practical, high-stakes scenarios with significantly better latency (70ms vs 7s) and smaller footprint.

## Method Summary
Paladin-mini uses full supervised fine-tuning on microsoft/Phi-4-mini-instruct (3.8B params) with a combination of public datasets (C2D/D2C-MiniCheck, AggreFact, TofuEval, FactCheck-GPT, ExpertQA, RAGTruth) and proprietary synthetic datasets targeting numerical, temporal, and logical reasoning errors. The model is trained on 23K samples with float16 precision and evaluated on a new grounding-benchmark across four categories: General, Logical, Time/Dates, and Prices/Math. The synthetic data generation follows a minimality condition ensuring every piece of evidence is essential for claim entailment.

## Key Results
- Achieves 96.0% balanced accuracy on Prices/Math tasks vs 46.0% for 7B competitor
- Maintains competitive 79.31% average BACC across all benchmarks vs 77.87% for larger model
- Demonstrates 70ms inference latency vs 7s for larger model, with ~7GB memory footprint
- Strong performance on logical reasoning (97.1% BACC) while maintaining general capabilities

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Domain-targeted synthetic data outperforms general-purpose synthetic data for specialized reasoning tasks.
- Mechanism: Training samples engineered to expose specific failure modes (numerical miscalculation, temporal comparison errors) create stronger supervision signals for those reasoning patterns than randomly generated claim-document pairs.
- Core assumption: The distribution of errors in real-world deployments is sufficiently captured by the synthetic data design process.
- Evidence anchors: Section 5.1 shows Paladin-mini attains 96.0% on Prices/Math while Bespoke-MiniCheck-7B scores only 46.0%.

### Mechanism 2
- Claim: Compact models with targeted training can outperform larger generalist models on specialized tasks.
- Mechanism: A 3.8B parameter model fine-tuned on 23K domain-specific samples achieves better inductive bias for the target task than a 7B model trained on broader data.
- Core assumption: The base model (Phi-4-mini-instruct) already possesses sufficient reasoning capacity; the bottleneck is task-specific alignment.
- Evidence anchors: Table 4 shows Paladin-mini achieves 79.31% avg BACC vs Bespoke-MiniCheck-7B's 77.87% despite being 46% smaller.

### Mechanism 3
- Claim: Minimal support formalism for synthetic data generation produces training examples with higher information content.
- Mechanism: By ensuring evidence sets satisfy a minimality condition—where removing any evidence Di makes the claim ungrounded—the generated triplets avoid redundant supervision.
- Core assumption: Logically rigorous synthetic examples translate to better generalization than procedurally generated examples without formal verification.
- Evidence anchors: Section 3.3 describes the formal framework ensuring every piece of supporting evidence is essential.

## Foundational Learning

- Concept: **Semantic Entailment (D ⊨ c)**
  - Why needed here: The paper's core formalism defines grounding as entailment—you cannot understand the minimality condition or the binary classification task without grasping what it means for evidence to logically necessitate a claim.
  - Quick check question: Given D = {"AllPremium members pay $50/month", "Enterprise tier costs 2x Premium"}, does D entail c = "Enterprise costs $100/month"?

- Concept: **Balanced Accuracy (BACC)**
  - Why needed here: The paper argues that standard accuracy masks class imbalance problems critical in grounding tasks where false positives may be costlier than false negatives.
  - Quick check question: If a model achieves 90% accuracy on a dataset with 90% grounded samples by always predicting "grounded," what is its BACC?

- Concept: **Synthetic Data Generation (C2D / D2C)**
  - Why needed here: Paladin-mini builds on MiniCheck's C2D (claim→document) and D2C (document→claim) techniques but adds targeted perturbations—you need to understand the baseline to see what's being improved.
  - Quick check question: For C2D generation, what types of documents would a model generate for the claim "Revenue increased by 15% YoY"?

## Architecture Onboarding

- Component map: Phi-4-mini-instruct (3.8B params, 128K context) -> SFT on 23K samples -> float16 inference model
- Critical path: Load Phi-4-mini-instruct checkpoint -> Apply SFT weights -> Tokenize (D, c) pair -> Forward pass -> Return binary label
- Design tradeoffs:
  - Size vs. breadth: 3.8B enables 70ms latency but sacrifices Time/Dates performance (82% vs 90%)
  - Specialization vs. generality: Strong on Prices/Math (96%) but weaker on LLM-AggreFact subsets vs. Bespoke-MiniCheck-7B
  - Float16 vs. quantization: Paper explicitly avoids quantization to preserve reasoning
- Failure signatures:
  - Temporal reasoning gaps: Expect lower accuracy on date comparison, scheduling, duration calculations
  - Out-of-domain claims: Performance on domains not covered by synthetic data is unverified
  - Long documents near 128K tokens: Performance degradation at context limits is unreported
- First 3 experiments:
  1. Baseline validation: Run Paladin-mini on grounding-benchmark and verify reported BACC scores
  2. Latency stress test: Measure inference latency across batch sizes on target hardware
  3. Domain transfer probe: Test on 50-100 samples from actual use case domain

## Open Questions the Paper Calls Out

- **Open Question 1**: Can the temporal reasoning performance of Paladin-mini be improved to match its numerical capabilities without increasing model size?
  - Basis: Section 5.1 identifies the lower score in "Time & Dates" category (82.0%) and states "This is candidly identified as an area for future work."
  - Evidence needed: Evaluation of retrained version with expanded/refined temporal dataset showing statistically significant BACC increase.

- **Open Question 2**: Does high performance on grounding-benchmark correlate more strongly with success in downstream RAG applications than scores on general benchmarks?
  - Basis: The paper argues benchmark-utility gap exists but provides no empirical data measuring impact on final accuracy of RAG pipeline.
  - Evidence needed: Comparative study measuring hallucination rate reduction when using Paladin-mini vs Bespoke-MiniCheck-7B in live LLM application.

- **Open Question 3**: To what extent does the choice of Phi-4-mini-instruct base model contribute to observed reasoning capabilities compared to specialized synthetic training data?
  - Basis: The paper attributes success to "targeted training" but also selects a base model "known for strong reasoning capabilities."
  - Evidence needed: Ablation experiments training same synthetic dataset on standard base model and comparing resulting scores.

## Limitations
- Unreleased proprietary synthetic datasets prevent independent verification of domain-specific performance claims
- Training configuration opacity (hyperparameters not specified) introduces variability in reproduction attempts
- 82% BACC on Time/Dates trails 7B competitor's 90%, indicating specialization tradeoff
- No empirical validation that minimal support formalism produces better generalization than standard methods

## Confidence

- **Performance Claims (High)**: Relative performance advantages well-supported by grounding-benchmark evaluation
- **Efficiency Claims (Medium)**: 70ms latency and 7GB footprint reported but not independently verified
- **Mechanism Claims (Low-Medium)**: Targeted training approach logically sound but insufficient evidence that specific synthetic data design is superior

## Next Checks

1. **Synthetic Data Generation Replication**: Implement C2D/D2C methods with targeted perturbations for numerical, temporal, and logical reasoning. Generate 5,000-10,000 samples and evaluate whether Paladin-mini's performance can be matched without proprietary datasets.

2. **Cross-Domain Transfer Testing**: Evaluate Paladin-mini on 100-200 samples from domains not covered in grounding-benchmark (medical, legal, scientific). Compare performance against 7B generalist model to quantify specialization tradeoff.

3. **Latency and Resource Profiling**: Measure inference latency, memory usage, and throughput across batch sizes (1, 8, 32, 128) on multiple hardware configurations. Document performance degradation at context window limits and test quantization to assess float16 necessity.