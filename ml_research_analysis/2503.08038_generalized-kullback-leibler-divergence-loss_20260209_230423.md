---
ver: rpa2
title: Generalized Kullback-Leibler Divergence Loss
arxiv_id: '2503.08038'
source_url: https://arxiv.org/abs/2503.08038
tags:
- loss
- distillation
- training
- knowledge
- adversarial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes the Generalized Kullback-Leibler (GKL) Divergence
  loss, derived from the Decoupled Kullback-Leibler (DKL) Divergence loss, which is
  mathematically equivalent to the traditional Kullback-Leibler (KL) Divergence loss.
  The GKL loss addresses two key limitations of the KL loss: asymmetric optimization
  and imbalanced predicted score distributions in soft labels.'
---

# Generalized Kullback-Leibler Divergence Loss

## Quick Facts
- arXiv ID: 2503.08038
- Source URL: https://arxiv.org/abs/2503.08038
- Authors: Jiequan Cui; Beier Zhu; Qingshan Xu; Zhuotao Tian; Xiaojuan Qi; Bei Yu; Hanwang Zhang; Richang Hong
- Reference count: 40
- Primary result: Introduces GKL loss derived from DKL loss, achieving state-of-the-art adversarial robustness and competitive knowledge distillation performance

## Executive Summary
This paper proposes the Generalized Kullback-Leibler (GKL) Divergence loss, derived from the Decoupled Kullback-Leibler (DKL) Divergence loss, which is mathematically equivalent to the traditional Kullback-Leibler (KL) Divergence loss. The GKL loss addresses two key limitations of the KL loss: asymmetric optimization and imbalanced predicted score distributions in soft labels. It achieves this by breaking the asymmetric optimization property and introducing smoother weight functions that incorporate class-wise global information. The proposed GKL loss is evaluated on CIFAR-10/100, ImageNet, and vision-language datasets for adversarial training and knowledge distillation tasks.

## Method Summary
The paper introduces the Generalized Kullback-Leibler (GKL) Divergence loss as an improvement over the traditional Kullback-Leibler (KL) Divergence loss. The GKL loss is derived from the Decoupled Kullback-Leibler (DKL) Divergence loss, which the authors claim is mathematically equivalent to the KL divergence loss. The GKL loss addresses two key limitations of the KL loss: asymmetric optimization and imbalanced predicted score distributions in soft labels. It achieves this by breaking the asymmetric optimization property and introducing smoother weight functions that incorporate class-wise global information. The GKL loss is evaluated on CIFAR-10/100, ImageNet, and vision-language datasets for adversarial training and knowledge distillation tasks.

## Key Results
- Achieves state-of-the-art adversarial robustness on RobustBench
- Demonstrates competitive performance in knowledge distillation tasks
- Successfully addresses limitations of traditional KL loss in terms of asymmetric optimization and imbalanced predicted score distributions

## Why This Works (Mechanism)
The GKL loss works by addressing the asymmetric optimization property of the traditional KL loss and introducing smoother weight functions that incorporate class-wise global information. This mechanism allows for more balanced optimization and better handling of imbalanced predicted score distributions in soft labels. The proposed loss function is particularly effective in adversarial training and knowledge distillation tasks, where these limitations of the KL loss are most pronounced.

## Foundational Learning
1. Kullback-Leibler (KL) Divergence: A measure of how one probability distribution diverges from a second, expected probability distribution. Why needed: Understanding the limitations of KL divergence is crucial for appreciating the improvements offered by GKL loss.
2. Decoupled Kullback-Leibler (DKL) Divergence: A variant of KL divergence claimed to be mathematically equivalent to KL divergence. Why needed: DKL serves as the basis for deriving the GKL loss.
3. Adversarial Training: A technique for improving model robustness against adversarial attacks. Why needed: One of the primary applications where GKL loss shows significant improvements.
4. Knowledge Distillation: A method for transferring knowledge from a larger model to a smaller one. Why needed: Another key application area where GKL loss demonstrates competitive performance.
5. RobustBench: A standardized benchmark for evaluating adversarial robustness of models. Why needed: The platform used to demonstrate state-of-the-art performance of GKL-based adversarial training.
6. Soft Labels: Probability distributions over classes produced by a model, used in knowledge distillation. Why needed: Understanding the limitations of soft labels in KL divergence is key to appreciating the improvements offered by GKL loss.

## Architecture Onboarding
**Component Map:**
DKL Loss -> GKL Loss -> Application in Adversarial Training/Knowledge Distillation

**Critical Path:**
The critical path involves deriving the GKL loss from DKL, implementing it in adversarial training and knowledge distillation frameworks, and evaluating its performance against traditional KL loss and other state-of-the-art methods.

**Design Tradeoffs:**
- Computational complexity: GKL loss may introduce additional computational overhead compared to KL loss.
- Model compatibility: Ensuring GKL loss can be easily integrated into existing frameworks for adversarial training and knowledge distillation.
- Hyperparameter tuning: Balancing the effects of class-wise global information incorporation.

**Failure Signatures:**
- If GKL loss fails to improve upon KL loss, it may indicate issues with the mathematical equivalence claim between DKL and KL divergence.
- Poor performance in knowledge distillation could suggest that the smoother weight functions are not effectively capturing the relevant information.

**First Experiments:**
1. Implement GKL loss in a simple adversarial training setup on CIFAR-10 to verify its effectiveness in improving robustness.
2. Compare GKL-based knowledge distillation against traditional KL-based distillation on a small vision-language dataset.
3. Conduct ablation studies to isolate the effects of breaking asymmetric optimization and incorporating class-wise global information.

## Open Questions the Paper Calls Out
None

## Limitations
- The paper does not provide a rigorous proof or detailed explanation of the mathematical equivalence between DKL and KL divergence losses.
- The effectiveness of GKL loss in addressing the limitations of KL loss is primarily demonstrated through empirical results, lacking in-depth theoretical analysis.
- Evaluation is limited to a specific set of datasets and tasks, which may not fully represent the generalizability of GKL loss.

## Confidence
- High confidence: The theoretical motivation behind the GKL loss and its potential to address the limitations of the KL loss.
- Medium confidence: The empirical results demonstrating the effectiveness of the GKL loss on the evaluated datasets and tasks.
- Low confidence: The mathematical equivalence between the DKL and KL divergence losses, as well as the generalizability of the GKL loss to other datasets and tasks.

## Next Checks
1. Provide a rigorous proof or detailed explanation of the mathematical equivalence between the DKL and KL divergence losses to solidify the theoretical foundation of the GKL loss.
2. Conduct a more in-depth theoretical analysis of how the GKL loss specifically addresses the asymmetric optimization and imbalanced predicted score distribution issues compared to the KL loss.
3. Evaluate the GKL loss on a wider range of datasets and tasks, including those with different characteristics (e.g., smaller or larger datasets, different types of adversarial attacks, other knowledge distillation scenarios) to assess its generalizability and robustness.