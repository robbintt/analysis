---
ver: rpa2
title: 'Software Engineering Principles for Fairer Systems: Experiments with GroupCART'
arxiv_id: '2504.12587'
source_url: https://arxiv.org/abs/2504.12587
tags:
- fairness
- software
- groupcart
- data
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: GroupCART addresses the problem of algorithmic bias in decision
  tree models by proposing a multi-objective optimization approach that avoids bias
  during model construction. The method optimizes both for decreased entropy in the
  target attribute and increased entropy in protected attributes, using fairness-aware
  decision trees with tunable weights.
---

# Software Engineering Principles for Fairer Systems: Experiments with GroupCART

## Quick Facts
- arXiv ID: 2504.12587
- Source URL: https://arxiv.org/abs/2504.12587
- Reference count: 40
- Primary result: GroupCART achieves up to 50% improvement in distance to heaven scores and perfect flip rate scores compared to state-of-the-art fairness methods.

## Executive Summary
GroupCART addresses algorithmic bias in decision tree models by constructing fairness-aware trees that balance accuracy and protected-attribute entropy during splits. The method uses multi-objective optimization to identify Pareto-optimal configurations and aggregates their predictions via ensemble voting. Experimental results demonstrate superior performance-fairness trade-offs compared to existing methods, with the ability to handle multiple protected attributes simultaneously.

## Method Summary
GroupCART implements fairness-aware decision trees by modifying the split criterion to balance information gain on target classes and protected attributes. The method trains 20 trees with varying weight ratios, evaluates them using performance and fairness metrics, and applies multi-objective optimization to identify Pareto-optimal models. Final predictions are produced through majority voting of the selected models. The approach uses standard preprocessing and validation splits to tune the ensemble.

## Key Results
- Achieves up to 50% improvement in distance to heaven scores compared to state-of-the-art methods
- Perfect flip rate scores (individual fairness) on tested datasets
- Successfully handles multiple protected attributes simultaneously with smooth tuning surfaces

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Injecting protected-attribute entropy into the split criterion yields trees that are both predictive and fairness-aware by construction.
- **Mechanism:** At each node, the learner balances maximizing information gain on the target class and maximizing information gain on protected attributes, sweeping the weight ratio across [0,1] to produce controllable fairness-performance bias.
- **Core assumption:** Splitting on high-IGS features prevents downstream leaves from becoming homogeneous in protected attributes, reducing disparate treatment.
- **Evidence anchors:** Abstract states optimizing for both decreased entropy in target and increased entropy in protected attributes; §4.1 describes fairness-aware decision trees combining multiple constraints.
- **Break condition:** If protected attributes are highly correlated with informative features, maximizing IGS may excessively degrade predictive power.

### Mechanism 2
- **Claim:** Multi-objective optimization over a small, stratified configuration pool surfaces diverse Pareto-optimal fairness-performance tradeoffs.
- **Mechanism:** GroupCART instantiates N trees with distinct weight ratios, evaluates them on validation data using performance and fairness metrics, then applies non-dominated sorting to extract the Pareto frontier.
- **Core assumption:** The weight ratio is a sufficient proxy for the full hyperparameter space.
- **Evidence anchors:** Abstract mentions constructing fairness-aware trees by adjusting internal weight ratio and using multi-objective optimization; §5.2 describes filtering models to achieve superior trade-offs.
- **Break condition:** If the objective space is highly concave or dominated by a single configuration, the frontier contains few solutions.

### Mechanism 3
- **Claim:** Aggregating predictions from multiple Pareto-optimal trees via ensemble voting stabilizes outputs and improves individual fairness.
- **Mechanism:** Final predictions are produced by majority voting (standard GroupCART) or weighted voting (AdaBoost variant), where model weights derive from validation-set error rates.
- **Core assumption:** Non-dominated trees make independent errors on protected-group instances; their aggregation cancels biased flips.
- **Evidence anchors:** Abstract mentions aggregating predictions via ensemble voting; §5.3 states ensemble voting is helpful as GroupCART usually finds more than one Pareto frontier configuration.
- **Break condition:** If frontier trees are highly correlated, voting provides little variance reduction.

## Foundational Learning

- **Concept:** Information Gain and Entropy in Decision Trees
  - **Why needed here:** GroupCART's core intervention is modifying the split criterion; understanding how IG measures node impurity reduction is prerequisite to grasping the fairness-aware variant.
  - **Quick check question:** Given a binary split, can you compute the entropy before and after to verify IG is positive?

- **Concept:** Pareto Frontier and Dominance
  - **Why needed here:** The method identifies "optimal" models via non-dominated sorting; you must understand why no single solution dominates all objectives simultaneously.
  - **Quick check question:** In a 2D objective space (Accuracy vs DI), sketch three points and identify which are Pareto-optimal under binary domination.

- **Concept:** Ensemble Aggregation (Bagging/Boosting)
  - **Why needed here:** Final predictions emerge from voting across frontier models; distinguishing majority vs weighted voting clarifies design choices.
  - **Quick check question:** If three models predict [1,0,1] for an instance, what is the majority vote? If their weights are [0.5,0.3,0.2], what is the weighted vote?

## Architecture Onboarding

- **Component map:** Fairness-Aware Split Calculator -> Tree Trainer -> Multi-Objective Evaluator -> Pareto Filter -> Ensemble Aggregator

- **Critical path:**
  1. Initialize 20 trees with distinct weight ratios (i/N for i=0..N-1)
  2. Train each FDT on training split; evaluate on validation split
  3. Compute continuous domination scores; retain non-dominated models
  4. Aggregate test-set predictions via majority voting

- **Design tradeoffs:**
  - **Ensemble size (N):** Larger N improves frontier coverage and individual fairness (FR→0) but increases training cost. Paper finds N=20 sufficient for FR=0 on tested datasets.
  - **Continuous vs binary domination:** Continuous domination provides scalar ranking when frontiers are large; binary domination is simpler but may yield ambiguous frontiers.
  - **Metric selection for optimization:** Paper uses Accuracy, F1, AOD, DI; alternative combinations may shift frontier composition.

- **Failure signatures:**
  - FR does not reach zero as N increases: Protected attributes may be proxies for informative features; consider pre-processing or additional constraints.
  - Pareto frontier contains only 1-2 models: Weight ratio sweep may be too coarse; increase N or inspect metric correlations.
  - Accuracy collapses (<60%) even at low w_IGS: Dataset may lack separability; verify feature quality and preprocessing.

- **First 3 experiments:**
  1. Baseline replication: Run GroupCART with N=20 on Adult dataset (protected=sex). Plot d2h vs w_IGS to confirm U-shaped tradeoff and identify frontier size.
  2. Ablation on ensemble size: Compare N∈{5,10,20} on Compas dataset. Record FR, d2h, and training time to validate early-stopping heuristic.
  3. Multi-attribute test: Run GroupCART on Adult with both sex and race protected. Visualize DI scores for each attribute across weight configurations to verify smooth tuning surfaces.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the GroupCART multi-objective optimization framework be effectively extended to non-tree-based classifiers?
- **Basis in paper:** Authors state in "Instrumental Validity" that the approach currently relies on tree-based algorithms but could theoretically extend to other models.
- **Why unresolved:** The implementation relies on tree-specific splitting criteria (adjusting weight ratios between information gain on class and protected attributes).
- **What evidence would resolve it:** Empirical results applying the Pareto frontier selection method to non-tree algorithms like neural networks or SVMs.

### Open Question 2
- **Question:** Does the GroupCART framework maintain its effectiveness when applied to multi-class classification and regression problems?
- **Basis in paper:** In "External Validity," authors note the work is limited to binary classification but can easily be extended to other domains in the future.
- **Why unresolved:** Fairness definitions and optimization dynamics differ significantly in non-binary or continuous target spaces compared to binary classification.
- **What evidence would resolve it:** Experiments measuring performance-fairness trade-offs on datasets with continuous targets or multiple class labels.

### Open Question 3
- **Question:** Does the choice of specific objective metrics significantly influence the quality of the resulting Pareto frontier?
- **Basis in paper:** Authors note in "Internal Validity" that different or additional metrics might yield better results, representing a design choice based on preliminary observations.
- **Why unresolved:** Authors selected four specific metrics (Accuracy, F1, AOD, DI) but did not verify if alternative combinations produce superior frontiers.
- **What evidence would resolve it:** An ablation study comparing "distance to heaven" scores when optimizing for different subsets of performance and fairness metrics.

## Limitations
- The precise mathematical formulation of the fairness-aware split criterion remains underspecified, with no explicit equations for the weighted IG combination.
- Handling of multiple protected attributes during splitting is not explicitly defined - whether IG_S is summed, averaged, or vectorized across attributes is unclear.
- The experimental setup assumes AIF360-standard preprocessing, but exact encoding and scaling choices could materially affect fairness baselines.

## Confidence

- **High confidence** in the core mechanism: augmenting decision tree splits with protected-attribute entropy to improve fairness.
- **Medium confidence** in the multi-objective Pareto optimization approach, as the concept is sound but implementation details are sparse.
- **Low confidence** in the scalability claims (50% d2h improvement) without access to the exact hyperparameter tuning protocol and metric definitions used in evaluation.

## Next Checks
1. Implement and verify the fairness-aware split criterion (linear combination vs. ratio of IGC/IGS) on a small synthetic dataset to confirm it reduces protected-group homogeneity in leaves.
2. Run GroupCART with N=20 on the Adult dataset, reproduce the d2h vs. w_IGS curve, and verify that the Pareto frontier contains more than 1-2 models.
3. Test multi-attribute fairness on Adult (sex + race) and plot DI scores for each protected attribute across weight configurations to confirm smooth tuning surfaces.