---
ver: rpa2
title: 'Robust Fine-Tuning from Non-Robust Pretrained Models: Mitigating Suboptimal
  Transfer With Adversarial Scheduling'
arxiv_id: '2509.23325'
source_url: https://arxiv.org/abs/2509.23325
tags:
- training
- clean
- accuracy
- robustness
- adversarial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper identifies a key challenge in robust fine-tuning (RFT)
  from non-robust pretrained models: when optimizing a robust objective, the task
  adaptation phase is delayed, leading to suboptimal transfer and low clean accuracy.
  The authors propose Epsilon-Scheduling, a two-hinge linear schedule that starts
  with standard fine-tuning (zero perturbation), then linearly increases perturbation
  strength to the target level.'
---

# Robust Fine-Tuning from Non-Robust Pretrained Models: Mitigating Suboptimal Transfer With Adversarial Scheduling

## Quick Facts
- **arXiv ID:** 2509.23325
- **Source URL:** https://arxiv.org/abs/2509.23325
- **Reference count:** 40
- **Primary result:** Epsilon-Scheduling prevents suboptimal transfer in robust fine-tuning by linearly increasing perturbation strength from 0 to target, improving both clean accuracy and expected robustness.

## Executive Summary
This paper addresses a critical failure mode in robust fine-tuning (RFT) from non-robust pretrained models, where optimizing for adversarial robustness delays task adaptation and leads to suboptimal transfer—severe degradation of clean accuracy. The authors propose Epsilon-Scheduling, a two-hinge linear schedule that starts with standard fine-tuning (zero perturbation) and gradually increases perturbation strength to the target level. This approach ensures the model first learns the task before incorporating robustness constraints. Experiments across six backbones and five fine-grained classification datasets demonstrate that Epsilon-Scheduling consistently prevents suboptimal transfer, achieves better expected robustness (AUC of accuracy across perturbation levels), and improves clean accuracy compared to standard RFT-fix methods.

## Method Summary
Epsilon-Scheduling is a two-hinge linear schedule for robust fine-tuning that controls the perturbation strength ε during training. The schedule starts with ε=0 for T1 epochs (standard fine-tuning), then linearly ramps from 0 to target εg over T2-T1 epochs, and finally maintains εg for the remaining epochs. This approach ensures task adaptation occurs before robustness training begins, preventing the delayed adaptation problem observed in standard RFT-fix methods. The method is evaluated using expected robustness—the AUC of accuracy across the perturbation range [0, εg]—computed via trapezoidal integration with 1/255 steps. Training uses APGD with 7 steps for adversarial example generation, and evaluation uses APGD with 10 steps under ℓ∞-norm.

## Key Results
- Epsilon-Scheduling consistently prevents suboptimal transfer across all six backbones and five datasets tested.
- The method achieves superior expected robustness compared to RFT-fix, even at high perturbation regimes (8/255).
- Clean accuracy is improved while maintaining competitive robustness compared to RFT-fix.
- The two-hinge schedule (T1=12, T2=37 out of 50 epochs) is shown to be effective, though hyperparameter sensitivity is noted.

## Why This Works (Mechanism)
The core mechanism addresses the "task adaptation delay" problem in RFT. When applying full robustness constraints from the start (RFT-fix), the model struggles to learn the downstream task because it must simultaneously optimize for clean accuracy and robustness. This creates a difficult optimization landscape that delays convergence. Epsilon-Scheduling solves this by first allowing the model to adapt to the task using standard fine-tuning (ε=0), then gradually introducing robustness constraints. This staged approach ensures the model learns the task before tackling the harder robustness optimization, preventing the severe clean accuracy degradation characteristic of suboptimal transfer.

## Foundational Learning

- **Concept: Adversarial Training (AT)**
  - **Why needed here:** This is the fundamental defense technique being adapted. Robust Fine-Tuning (RFT) is the application of AT to a pretrained model.
  - **Quick check question:** In classical adversarial training, how is an adversarial example for a given input generated and used in the loss calculation?

- **Concept: Transfer Learning & Fine-Tuning**
  - **Why needed here:** The entire paper is in the context of adapting a *pretrained* model to a new task. Suboptimal transfer is a failure mode specific to this transfer process.
  - **Quick check question:** What is the key difference between training a model from scratch versus fine-tuning a pretrained model?

- **Concept: The Accuracy-Robustness Trade-off**
  - **Why needed here:** This is the core problem. Adding robustness constraints typically degrades performance on clean data. The paper's method aims to find a better balance.
  - **Quick check question:** Why does optimizing a model for robustness often cause its accuracy on clean, unperturbed data to drop?

## Architecture Onboarding

- **Component Map:** Input → Backbone (pretrained, non-robust) → Classifier Head (randomly initialized) → Loss Function (Cross-Entropy) → Epsilon-Scheduler → Adversarial Attacker (APGD) → Perturbed Input

- **Critical Path:** The path from input x through the backbone, head, and loss function remains standard. The new critical path is the *control flow*: at the start of each training epoch, the scheduler is queried for the current ε. This ε is then used by the adversarial attacker to perturb the batch before it is fed to the model for loss calculation.

- **Design Tradeoffs:**
  - **T1 (Adaptation Phase Length):**
    - **Tradeoff:** Increasing T1 improves final clean accuracy but reduces the number of epochs available for robustness training.
    - **Guidance:** Set T1 to the epoch where a standard fine-tuning run achieves ~90% of its final clean accuracy.
  - **T2 (Transition Steepness):**
    - **Tradeoff:** A larger gap (T2 - T1) means a more gradual increase in perturbation, which is more stable but delays reaching the target robustness budget.
    - **Guidance:** Set T2 to an epoch after the typical "task adaptation delay" period observed in a failed RFT-fix run (e.g., 75% of total epochs).
  - **Target Perturbation (εg):**
    - **Tradeoff:** Higher εg provides stronger robustness guarantees but is a more difficult optimization landscape, increasing the risk of suboptimal transfer.
    - **Guidance:** The paper shows Epsilon-Scheduling makes high εg (e.g., 8/255) feasible where RFT-fix fails.

- **Failure Signatures:**
  1. **Suboptimal Transfer (The core problem):** Validation accuracy remains near-random for many epochs, then rises slightly but finishes far below standard fine-tuning. This is the signature of RFT-fix failing.
  2. **Unstable Transition:** Validation accuracy increases during T1, then drops sharply and fails to recover when the schedule kicks in. This indicates T1 was too short or the transition (T2-T1) was too abrupt.
  3. **High Clean, Low Robust Accuracy:** The model achieves excellent clean accuracy but near-zero robust accuracy at εg. This indicates T1 was too long or T2 was too late, leaving insufficient time for robust optimization.

- **First 3 Experiments:**
  1. **Establish a Baseline Failure:** On a chosen dataset (e.g., Aircraft) and model (e.g., Swin), run RFT-fix with εg=8/255. Observe and document the "task adaptation delay" (epochs until validation accuracy > 5%). Confirm the final suboptimal transfer (low clean accuracy).
  2. **Implement & Verify Scheduler:** Implement the Epsilon-Scheduler logic. Using the delay time from Experiment 1, set T1 and T2 (e.g., T1 = delay_epoch * 0.5, T2 = delay_epoch * 1.5). Run the same fine-tuning job and verify that validation accuracy now rises from epoch 1.
  3. **Evaluate Expected Robustness:** On the model from Experiment 2, compute robust accuracy at multiple epsilons in [0, εg] (e.g., at steps of 1/255). Plot the curve and calculate its AUC (Expected Robustness). Compare this single value against the baseline to demonstrate improved trade-off.

## Open Questions the Paper Calls Out

- **Open Question 1**
  - **Question:** Does the suboptimal transfer phenomenon and the efficacy of Epsilon-Scheduling extend to modalities beyond computer vision, such as Natural Language Processing?
  - **Basis in paper:** [explicit] The "Limitations and Future Work" section explicitly lists "investigating whether similar dynamics occur in other modalities, such as natural language processing" as an open question.
  - **Why unresolved:** The experimental scope is restricted to image classification datasets (Caltech, CUB, Dogs, Cars, Aircraft) and vision architectures.
  - **Evidence:** Applying the proposed scheduling method to non-robust NLP backbones (e.g., BERT) during fine-tuning and analyzing the trade-off between task adaptation and robustness.

- **Open Question 2**
  - **Question:** Can Epsilon-Scheduling be effectively adapted for parameter-efficient fine-tuning methods like LoRA?
  - **Basis in paper:** [explicit] The "Limitations and Future Work" section identifies "applying the framework to parameter-efficient methods like LoRA" as a specific area for future research.
  - **Why unresolved:** The paper focuses exclusively on full fine-tuning where all backbone parameters are trainable, leaving the interaction between perturbation scheduling and low-rank adaptation unexplored.
  - **Evidence:** Experiments applying Epsilon-Scheduling to LoRA-based adaptation to see if it prevents suboptimal transfer while maintaining parameter efficiency.

- **Open Question 3**
  - **Question:** Is there a theoretically grounded or automated method to determine the optimal schedule shape or hyperparameters (T1, T2) for specific tasks?
  - **Basis in paper:** [explicit] The authors state that "exploring other scheduling strategies, either heuristic, theoretically motivated, or learning-based" is a future direction, noting that their method relies on a heuristic derived from a specific severe case.
  - **Why unresolved:** The current method requires manual setting of hinge points based on the "SWIN-Aircraft" case, which may not be optimal for all configurations.
  - **Evidence:** Developing a learning-based optimizer that dynamically adjusts ε during training and demonstrating it outperforms the fixed two-hinge schedule across diverse datasets.

## Limitations

- The method's sensitivity to hyperparameter choices (T1, T2, learning rate) is not extensively explored across all configurations.
- The expected robustness metric is specific to ℓ∞-norm attacks and may not generalize to other threat models.
- The analysis focuses on fine-grained classification tasks; performance on other domains (e.g., object detection, segmentation) remains untested.

## Confidence

- **High Confidence:** The existence of suboptimal transfer in RFT-fix (clean accuracy degradation), the effectiveness of Epsilon-Scheduling in preventing this failure mode, and the general superiority of the method over RFT-fix across all tested configurations.
- **Medium Confidence:** The precise optimal values for T1 and T2 are dataset-dependent and require validation; the claimed improvements in expected robustness are consistent but their practical significance depends on the threat model.
- **Low Confidence:** The paper's claims about the method's performance on non-ℓ∞ threat models and its applicability to non-classification tasks are speculative.

## Next Checks

1. **Hyperparameter Sensitivity Analysis:** Systematically vary T1 and T2 across a broader range (e.g., T1 ∈ [5, 20], T2 ∈ [T1+5, 50]) for a representative backbone-dataset pair to map the method's performance landscape.

2. **Alternative Threat Models:** Evaluate Epsilon-Scheduling under ℓ2 and ℓ1 adversarial attacks to verify if the expected robustness metric and the method's benefits generalize beyond ℓ∞.

3. **Generalization to Other Tasks:** Apply Epsilon-Scheduling to a transfer learning task outside of fine-grained classification (e.g., fine-tuning a detector like YOLO on a new dataset) to assess broader applicability.