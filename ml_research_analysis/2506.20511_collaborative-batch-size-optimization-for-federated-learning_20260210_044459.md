---
ver: rpa2
title: Collaborative Batch Size Optimization for Federated Learning
arxiv_id: '2506.20511'
source_url: https://arxiv.org/abs/2506.20511
tags:
- batch
- size
- learning
- training
- federated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of optimizing batch sizes in
  federated learning (FL) to improve training efficiency while avoiding hardware failures.
  In FL, participants train models locally with fixed hardware constraints, but without
  information exchange, improper batch size configurations can hinder performance
  or cause training failures.
---

# Collaborative Batch Size Optimization for Federated Learning

## Quick Facts
- **arXiv ID:** 2506.20511
- **Source URL:** https://arxiv.org/abs/2506.20511
- **Reference count:** 21
- **Primary result:** Randomized binary search finds optimal shared batch size in 3 rounds, achieving up to 15.68× speedup on MNIST

## Executive Summary
This paper addresses the challenge of optimizing batch sizes in federated learning where participants have heterogeneous hardware constraints. Without information exchange, improper batch size configurations can hinder performance or cause training failures. The authors propose RASBA, a randomized binary search-based method that automatically determines the maximum achievable shared batch size across all participants in the first few training rounds. Experiments on MNIST and CIFAR-10 datasets show the method successfully finds optimal batch sizes within 3 rounds while maintaining near-optimal accuracy.

## Method Summary
RASBA employs a randomized binary search where clients sample batch sizes within bounds and report success or failure to a central server. During search rounds, a fraction f of clients train safely with minimum batch size while others explore. The server aggregates bounds via maximum of minimums and minimum of maximums. When bounds converge, the federation proceeds with the discovered batch size. The method uses Flower 1.18 + PyTorch 2.7.0, Adam optimizer, and FedAvg aggregation across 10 clients with Dirichlet data splits.

## Key Results
- Successfully finds optimal shared batch size within 3 rounds
- Achieves 96.09% accuracy on MNIST and 73.42% on CIFAR-10
- Up to 15.68× speedup compared to baseline batch size 4
- Maintains training continuity during search with fraction-based fallback mechanism

## Why This Works (Mechanism)

### Mechanism 1: Parallelized Randomized Binary Search
A federated randomized binary search converges faster than sequential binary search by leveraging parallel sampling across multiple participants. Each client independently samples a random batch size within [bmin, bmax]. Successful training raises bmin to that value; OutOfMemoryError lowers bmax. The server aggregates via bmin = max(all client bmin) and bmax = min(all client bmax), narrowing the search space in O(log n / m) rounds where m = client count.

### Mechanism 2: Fraction-Based Training Continuity
Reserving a fraction f of clients to train with safe batch size bmin prevents complete training round loss during search. During search rounds, fraction f trains the model using bmin (guaranteed safe), while (1-f) participate in batch size exploration. Model updates continue even if all explorers fail.

### Mechanism 3: Conservative Aggregation for Federation Stability
Selecting the minimum viable batch size across all clients prevents federation collapse at the cost of potential underutilization. Final batch size converges to bmin = bmax = min(all clients' maximum supported batch size). This guarantees no client experiences OutOfMemoryError.

## Foundational Learning

- **Binary Search Time Complexity:** Why needed here: Understanding why O(log n) matters for rapid convergence—search space halves each iteration. Quick check: With bounds [4, 256], what's the maximum iterations needed to find exact value? (Answer: log₂(252) ≈ 8)
- **GPU Memory-Batch Size Relationship:** Why needed here: Batch size directly determines VRAM consumption; larger batches = fewer load operations = faster training, until OOM. Quick check: If a model requires 100MB per sample and GPU has 8GB VRAM, what's the approximate maximum batch size? (Answer: ~80, minus overhead)
- **Federated Averaging (FedAvg):** Why needed here: This is the aggregation strategy used; understanding how local models combine into global model. Quick check: In FedAvg, what do clients send to the server—gradients, model weights, or raw data? (Answer: Model weights only)

## Architecture Onboarding

**Component map:**
Central Server -> Search Coordinator, Aggregator, Bound Calculator
Client -> Sampler, Trainer, Error Handler, Reporter

**Critical path:**
1. Server initializes: model, bmin=4, bmax=64
2. Round 1: Fraction (1-f) explores; fraction f trains safely
3. Server aggregates bounds and models
4. Repeat until bmin == bmax (convergence)
5. Continue standard FL with discovered batch size

**Design tradeoffs:**
| Parameter | Increase | Decrease |
|-----------|----------|----------|
| f (safe fraction) | More training progress/round | Faster search convergence |
| Initial bmax | Faster if hardware supports | More early failures |
| Final batch size | Faster training | Risk of client exclusion |

**Failure signatures:**
- OutOfMemoryError: Batch size exceeds client VRAM → client reports bmax = current_b
- Round stall: bmin never reaches bmax after 10+ rounds → likely heterogeneous hardware, consider client grouping
- Accuracy degradation: Final batch size > 128 may harm convergence (see Table I: batch=256 gives 83.17% vs batch=64 gives 91.21% on MNIST)

**First 3 experiments:**
1. Baseline validation: Replicate Table I results—train MNIST with fixed batch sizes [4, 8, 16, 32, 64, 128, 256], measure time and accuracy to confirm speedup claims.
2. Convergence speed test: Run RASBA with f ∈ {0.3, 0.5, 0.7}, measure rounds to convergence and final accuracy—verify "at most 3 rounds" claim.
3. Heterogeneous hardware simulation: Artificially limit VRAM for subset of clients (e.g., 50% can handle batch=64, 50% only batch=16), verify method finds batch=16 without crashes.

## Open Questions the Paper Calls Out

### Open Question 1
Can the randomized binary search method be extended to group clients by hardware capability tiers rather than forcing a single shared batch size? The conclusion states that future work should focus on "improving our method when dealing with heterogeneous federations" and suggests grouping clients by their reported maximal batch sizes to improve scheduling.

### Open Question 2
How does the selection of the initial upper bound (bmax) impact the efficiency and convergence speed of the search process? The paper states that "the initial value for bmax determines the speed with which our method finds an optimal shared mini-batch size" and manually sets it to 64 based on prior observations.

### Open Question 3
Does optimizing for the maximum hardware-compatible batch size compromise final model accuracy compared to using smaller, generalization-optimized batch sizes? The background acknowledges that "small batch sizes have been shown to lead to more stable training and higher model accuracy," yet the proposed method greedily searches for the maximum batch size to minimize computation time.

## Limitations

- Conservative aggregation strategy severely underutilizes powerful clients in heterogeneous federations
- Reliance on homogeneous client hardware in experiments despite claims of federation-wide applicability
- No comparison against oracle-selected smaller batch sizes that might offer better accuracy

## Confidence

- **High confidence:** The randomized binary search mechanism converges in O(log n) rounds and successfully finds feasible batch sizes without causing federation collapse
- **Medium confidence:** The 15.68× speedup claim for MNIST batch size 256 - while methodology is sound, the comparison baseline may not reflect practical scenarios
- **Low confidence:** Generalization to highly heterogeneous federations with multiple hardware tiers - experiments use identical clients

## Next Checks

1. Test RASBA on federations with extreme hardware heterogeneity (mix of edge devices with 2GB VRAM and cloud GPUs with 80GB VRAM) to measure performance degradation
2. Implement client grouping based on hardware capabilities and compare RASBA performance against federation-level batch size optimization
3. Measure the trade-off between search convergence speed and training continuity across different f values (f ∈ {0.3, 0.5, 0.7}) in longer training runs (50+ rounds)