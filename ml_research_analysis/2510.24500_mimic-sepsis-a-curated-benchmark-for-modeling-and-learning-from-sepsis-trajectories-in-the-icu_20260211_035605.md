---
ver: rpa2
title: 'MIMIC-Sepsis: A Curated Benchmark for Modeling and Learning from Sepsis Trajectories
  in the ICU'
arxiv_id: '2510.24500'
source_url: https://arxiv.org/abs/2510.24500
tags:
- sepsis
- clinical
- treatment
- benchmark
- care
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MIMIC-Sepsis, a curated benchmark dataset
  and evaluation framework for modeling sepsis trajectories in the ICU, addressing
  the need for standardized, reproducible sepsis research pipelines. Derived from
  MIMIC-IV, the cohort includes 35,239 patients with aligned clinical variables and
  treatment interventions (vasopressors, fluids, antibiotics, mechanical ventilation)
  based on Sepsis-3 criteria.
---

# MIMIC-Sepsis: A Curated Benchmark for Modeling and Learning from Sepsis Trajectories in the ICU

## Quick Facts
- arXiv ID: 2510.24500
- Source URL: https://arxiv.org/abs/2510.24500
- Authors: Yong Huang; Zhongqi Yang; Amir Rahmani
- Reference count: 23
- Primary result: MIMIC-Sepsis provides standardized benchmark tasks showing Transformer architectures outperform LSTM and linear models when incorporating treatment variables

## Executive Summary
This paper introduces MIMIC-Sepsis, a curated benchmark dataset and evaluation framework for modeling sepsis trajectories in the ICU. Derived from MIMIC-IV, the cohort includes 35,239 patients with aligned clinical variables and treatment interventions (vasopressors, fluids, antibiotics, mechanical ventilation) based on Sepsis-3 criteria. A transparent preprocessing pipeline handles temporal alignment, unit harmonization, multi-level imputation, and outlier removal. Benchmark tasks include early mortality prediction, length-of-stay estimation, and dynamic classification of vasopressor requirement and septic shock. Experiments show that incorporating treatment variables improves model performance, especially for Transformer architectures, which outperform linear and LSTM models across tasks. MIMIC-Sepsis provides a standardized platform for advancing machine learning applications in critical care.

## Method Summary
MIMIC-Sepsis is derived from MIMIC-IV and includes 35,239 ICU patients meeting Sepsis-3 criteria (SOFA increase ≥2 with infection). The pipeline extracts static demographics, longitudinal clinical measurements, and interventions, aligning all data to sepsis onset (24h before to 72h after). Variables are resampled to 4-hour intervals, outliers removed, and missing data imputed through a tiered approach. Four benchmark tasks are defined: static In-Hospital Mortality (binary) and Length of Stay (regression), plus dynamic Vasopressor Requirement and Septic Shock classification. Models evaluated include Linear (flattened features), LSTM (2-layer, dropout=0.1), and Transformer (8 heads, 2 layers, dropout=0.1), with and without treatment variables. Performance is measured using AUROC/AUPRC for classification and MAE/RMSE for regression.

## Key Results
- Transformer architectures outperform LSTM and linear models across all tasks when treatment variables are included
- Incorporating treatment variables (vasopressors, fluids, antibiotics, ventilation) improves model performance, particularly for dynamic tasks
- LSTM model shows 0.112 AUROC and 0.235 AUPRC improvement in vasopressor requirement task with treatment variables
- Static tasks show limited improvement from treatment variables due to the short 6-hour observation window

## Why This Works (Mechanism)

### Mechanism 1
Treatment variable inclusion improves dynamic prediction performance because treatment decisions encode clinician assessments of patient severity that are predictive of future states. This information complements physiological measurements rather than redundantly overlapping with them. The mechanism breaks if treatments are administered based on already-included variables or if documentation timing is too inconsistent.

### Mechanism 2
Transformer architectures leverage temporal treatment dynamics more effectively than sequential models because self-attention mechanisms can directly model relationships between distant timepoints and treatment events without information degradation. This captures delayed treatment effects and intervention-response patterns. The mechanism breaks if the temporal window is too short or intervals too coarse for attention to provide advantage.

### Mechanism 3
Temporal alignment to sepsis onset enables consistent trajectory modeling across patients by creating comparable temporal reference frames that reduce heterogeneity in disease phase. The mechanism breaks if onset identification errors create misaligned trajectories or if individual variation in disease progression makes a common reference frame uninformative.

## Foundational Learning

- Concept: Sepsis-3 criteria and SOFA scoring
  - Why needed here: Cohort definition, septic shock classification, and sepsis onset identification all depend on understanding Sepsis-3 definitions and SOFA score calculation.
  - Quick check question: Can you explain why a patient with infection and SOFA increase of 1 point would not meet Sepsis-3 criteria?

- Concept: Confounding by indication in observational clinical data
  - Why needed here: The paper notes patients receiving treatments have worse outcomes—this reflects selection bias where sicker patients receive interventions, not treatment harm.
  - Quick check question: Why does higher mortality in patients who received vasopressors not imply vasopressors cause death?

- Concept: AUROC vs AUPRC for imbalanced classification
  - Why needed here: Sepsis mortality (14.5%) and septic shock (12.4%) are minority classes; the paper correctly uses AUROC/AUPRC rather than accuracy.
  - Quick check question: If 85% of patients survive, what accuracy would a naive "always predict survive" model achieve?

## Architecture Onboarding

- Component map:
Raw MIMIC-IV → Cohort Selection (Sepsis-3 filter) → Feature Extraction → Temporal Alignment (-24h to +72h from onset) → Unit Harmonization + Outlier Removal → 4-hour Resampling + Tiered Imputation → Treatment Variable Integration → Benchmark Tasks (4) → Model Training/Evaluation

- Critical path: Sepsis onset identification → SOFA score computation → Temporal alignment. Errors in onset detection propagate through all downstream tasks. Validate infection time by cross-referencing antibiotic administration with culture orders.

- Design tradeoffs:
  - 4-hour intervals reduce granularity but improve missingness; shorter intervals increase temporal resolution but sparsify data.
  - Forward-fill imputation preserves trends but may extend stale values; KNN imputation captures cross-patient patterns but may introduce artifacts.
  - Excluding variables with >80% missingness reduces imputation bias but may discard clinically meaningful sparse signals.

- Failure signatures:
  - Static tasks showing minimal treatment variable impact (expected per paper: "limited observation window" effect).
  - Large performance gaps between train and test indicating overfitting to single-institution patterns.
  - Septic shock AUPRC substantially lower than AUROC indicating poor calibration on rare positive class.

- First 3 experiments:
  1. Replicate baseline results: Train linear, LSTM, and Transformer on IHM task with/without treatment variables; verify AUROC within ±0.02 of reported values.
  2. Ablate imputation strategy: Replace tiered imputation with simple forward-fill; quantify performance degradation on VR task (highest treatment sensitivity).
  3. Horizon sensitivity: Test dynamic tasks with 12-hour and 48-hour prediction horizons; verify paper's claim that "performance was relatively robust to horizon length."

## Open Questions the Paper Calls Out

### Open Question 1
Can reinforcement learning (RL) algorithms leverage the MIMIC-Sepsis benchmark to derive optimal, personalized treatment strategies for sepsis? The authors explicitly state this as a promising direction for guiding sequential decision-making in sepsis care, but the current study focuses on supervised learning tasks without implementing RL agents.

### Open Question 2
Does the integration of unstructured clinical text (e.g., progress notes, discharge summaries) improve the predictive performance of models trained on the MIMIC-Sepsis benchmark? The Discussion notes this as an important extension, but the benchmark explicitly excludes unstructured data to focus on standardized variables.

### Open Question 3
Can specific representation learning methods capture interaction effects between interventions and physiology to improve early static predictions where treatment variables currently show limited impact? The authors suggest exploring better representations or incorporating interaction effects for early static prediction tasks.

## Limitations
- Single-institution data source (MIMIC-IV) limits generalizability across different healthcare systems and populations
- No external validation cohort provided to assess model performance on truly independent data
- Unspecified model hyperparameters (hidden dimensions, learning rate, epochs) for LSTM and Transformer models

## Confidence

High confidence: Core contribution (standardized sepsis trajectory benchmark), empirical findings (Transformer superiority, treatment variable benefits), preprocessing pipeline transparency

Medium confidence: Specific implementation details (model hyperparameters, exact variable inclusion criteria), clinical relevance across different healthcare settings, single-institution generalizability

Low confidence: External validation results, real-world deployment performance, impact of unmeasured confounders

## Next Checks

1. Verify cohort construction by reproducing the 35,239 patient count using Sepsis-3 criteria with explicit SOFA computation and infection identification

2. Benchmark ablation study: Train models with/without treatment variables on VR task to confirm reported 0.112 AUROC improvement

3. Implement cross-validation with multiple random seeds to assess stability of reported performance metrics