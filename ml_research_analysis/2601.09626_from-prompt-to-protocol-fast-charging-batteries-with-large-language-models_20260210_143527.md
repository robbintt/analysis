---
ver: rpa2
title: 'From Prompt to Protocol: Fast Charging Batteries with Large Language Models'
arxiv_id: '2601.09626'
source_url: https://arxiv.org/abs/2601.09626
tags:
- pybamm
- charging
- self
- optimization
- protocol
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LLM-guided methods (P2O and P2P) significantly outperform conventional
  battery charging protocol optimization, achieving ~4.2% improvement in state-of-health
  (SOH) over a state-of-the-art multi-step constant-current baseline in realistic
  fast-charging scenarios. P2O combines LLM-driven neural network architecture evolution
  with gradient-free parameter optimization (SAASBO), while P2P directly generates
  executable protocols from prompts.
---

# From Prompt to Protocol: Fast Charging Batteries with Large Language Models

## Quick Facts
- arXiv ID: 2601.09626
- Source URL: https://arxiv.org/abs/2601.09626
- Reference count: 40
- Primary result: LLM-guided methods achieve ~4.2% SOH improvement over conventional baselines in battery fast-charging optimization

## Executive Summary
This paper demonstrates that Large Language Models can effectively guide the optimization of battery charging protocols, achieving significant improvements over conventional methods. The authors propose two approaches: P2O (Prompt-to-Optimization) which combines LLM-driven neural network architecture evolution with gradient-free parameter optimization, and P2P (Prompt-to-Protocol) which directly generates executable protocols from natural language prompts. Both methods successfully navigate the slow, costly, and non-differentiable evaluation landscape of battery experiments. P2P achieves the best SOH performance under matched evaluation budgets by leveraging language-based constraints to generate voltage-safe protocols without inner-loop optimization, while P2O attains the overall best performance after evolutionary refinement.

## Method Summary
The authors present two LLM-guided approaches for battery charging protocol optimization. P2O uses LLMs to evolve neural network architectures that represent charging protocols, then applies gradient-free optimization (SAASBO) to refine parameters. P2P directly generates executable protocols from natural language prompts, incorporating voltage constraints through the LLM's interpretation of prompt descriptions. Both methods operate in a black-box optimization setting where protocol evaluation is expensive and non-differentiable. The evaluation framework uses a realistic fast-charging scenario with a multi-step constant-current baseline for comparison. The approaches successfully expand the search space beyond manually defined parameterizations, enabling efficient optimization in high-cost experimental settings.

## Key Results
- P2O and P2P methods achieve ~4.2% improvement in state-of-health (SOH) compared to state-of-the-art multi-step constant-current baseline
- P2P generates voltage-safe protocols directly from natural language constraints without inner-loop optimization
- P2O attains overall best performance after evolutionary refinement, though at higher computational cost
- Both methods successfully navigate non-differentiable, expensive protocol evaluation landscape

## Why This Works (Mechanism)
The LLM-guided approaches work by leveraging the model's ability to interpret natural language constraints and generate novel protocol structures beyond human-designed parameterizations. P2P directly maps prompt descriptions to executable protocols, using the LLM's language understanding to incorporate safety constraints (like voltage limits) that would be difficult to encode in traditional optimization frameworks. P2O uses the LLM to evolve network architectures that represent charging protocols, then applies gradient-free optimization to refine parameters within the evolved structure. Both approaches effectively transform the protocol design problem into a language-guided search problem, where the LLM's generalization capabilities expand the solution space while natural language constraints guide the search toward feasible, safe solutions.

## Foundational Learning
- **Battery charging dynamics** - Understanding how different current profiles affect battery degradation over time; needed to evaluate protocol performance and SOH impact
- **Gradient-free optimization** - Methods like SAASBO that don't require differentiable objective functions; needed because battery experiments are expensive and non-differentiable
- **Neural architecture search** - Using LLMs to evolve network structures that represent charging protocols; needed to expand search space beyond manual parameterizations
- **Natural language constraint encoding** - Interpreting safety requirements (voltage limits) from text; needed to generate feasible protocols without explicit constraint programming
- **Black-box optimization** - Framework for optimizing expensive-to-evaluate functions; needed for realistic battery testing scenarios
- **Protocol parameterization** - Representing charging protocols as mathematical functions or network architectures; needed to enable LLM-guided evolution and optimization

## Architecture Onboarding

**Component map:**
LLM -> Protocol Generator -> Evaluation Function -> Performance Feedback -> Optimization Loop

**Critical path:**
Prompt Input -> LLM Protocol Generation -> Protocol Evaluation -> SOH Calculation -> Performance Comparison

**Design tradeoffs:**
- P2O offers better performance but requires expensive evolutionary search vs P2P's faster direct generation
- LLM interpretation of constraints vs explicit mathematical constraint encoding
- Expanded search space vs computational overhead of LLM queries
- Direct protocol generation vs architecture evolution followed by parameter optimization

**Failure signatures:**
- LLM misinterpretation of voltage constraints leading to unsafe protocols
- Evolutionary search getting stuck in local optima
- Generated protocols failing to generalize across battery types
- Computational expense exceeding practical deployment limits

**3 first experiments:**
1. Test protocol generation with simplified prompts to verify LLM constraint interpretation
2. Compare P2P-generated protocols against manually designed safety-constrained protocols
3. Run small-scale evolutionary search with P2O to validate architecture evolution capability

## Open Questions the Paper Calls Out
None

## Limitations
- Generalizability to different battery chemistries and cell types remains uncertain
- Computational expense of evolutionary search component in P2O may limit practical deployment
- Voltage-safety constraints rely on LLM's interpretation of natural language, introducing potential variability

## Confidence

**Core findings:**
- High confidence in demonstrated SOH improvement over conventional baselines under tested conditions
- Medium confidence in claims about broad applicability to real-world battery systems

**Methodological aspects:**
- High confidence in experimental setup and evaluation metrics
- Medium confidence in the assertion that LLMs effectively expand protocol search spaces

## Next Checks
1. Test P2O and P2P methods across multiple battery chemistries and cell types to assess generalizability
2. Implement systematic comparison of protocol generation time and computational overhead between LLM-guided methods and traditional optimization approaches under identical resource constraints
3. Conduct sensitivity analysis on LLM's constraint interpretation by varying natural language descriptions of voltage limits and observing protocol adherence across different model versions or implementations