---
ver: rpa2
title: Pre-Filtering Code Suggestions using Developer Behavioral Telemetry to Optimize
  LLM-Assisted Programming
arxiv_id: '2511.18849'
source_url: https://arxiv.org/abs/2511.18849
tags:
- code
- developer
- suggestion
- behavioral
- acceptance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper presents a behavioral pre-filtering approach to optimize\
  \ Large Language Model (LLM)-based code suggestions in IDEs. By leveraging real-time\
  \ developer telemetry\u2014such as typing speed, file navigation, and editing activity\u2014\
  the method predicts whether a suggestion will likely be accepted before invoking\
  \ the LLM."
---

# Pre-Filtering Code Suggestions using Developer Behavioral Telemetry to Optimize LLM-Assisted Programming

## Quick Facts
- **arXiv ID**: 2511.18849
- **Source URL**: https://arxiv.org/abs/2511.18849
- **Reference count**: 23
- **Primary result**: Behavioral pre-filtering increased LLM suggestion acceptance from 18.4% to 34.2% while suppressing 35% of low-value LLM calls

## Executive Summary
This paper presents a behavioral pre-filtering approach to optimize Large Language Model (LLM)-based code suggestions in IDEs. By leveraging real-time developer telemetry—such as typing speed, file navigation, and editing activity—the method predicts whether a suggestion will likely be accepted before invoking the LLM. Deployed in a production Visual Studio Code plugin over four months, the system nearly doubled the acceptance rate of suggestions (18.4% → 34.2%) while suppressing 35% of low-value LLM calls. These results demonstrate that developer behavioral context can significantly enhance both the efficiency and user experience of AI-assisted programming tools, offering a lightweight, privacy-preserving solution for adaptive suggestion timing.

## Method Summary
The authors developed a machine learning model that uses developer behavioral telemetry to predict whether an LLM code suggestion will be accepted. The system collects features including typing speed, file navigation patterns, and editing activity in real-time, then applies a trained classifier to decide whether to invoke the LLM. When deployed as a Visual Studio Code plugin with 25 invited participants over four months, the approach successfully identified receptivity windows and suppressed unnecessary LLM calls while maintaining high suggestion quality. The model was trained on pooled data from all participants and used a single set of thresholds across the user population.

## Key Results
- Acceptance rate of LLM suggestions increased from 18.4% to 34.2% with behavioral pre-filtering
- 35% reduction in LLM invocations for suggestions unlikely to be accepted
- Field deployment in production Visual Studio Code plugin with 25 invited participants over four months

## Why This Works (Mechanism)
The approach works by leveraging observable patterns in developer behavior that correlate with receptivity to code suggestions. When developers are in focused coding states, they exhibit different behavioral patterns (such as faster typing and specific navigation sequences) compared to when they are exploring or problem-solving. By detecting these patterns in real-time, the system can predict when developers are likely to find suggestions useful and when they would dismiss them. This allows the system to invoke the LLM only during receptivity windows, improving both the acceptance rate and the user experience while reducing computational waste from low-value suggestions.

## Foundational Learning
- **Developer Behavioral Telemetry**: Why needed - Provides real-time context about developer state and receptivity; Quick check - Verify that telemetry features capture meaningful differences between focused coding and exploration states
- **Machine Learning Classification for Acceptance Prediction**: Why needed - Enables automated decision-making about when to invoke LLM; Quick check - Assess classification accuracy and false positive/negative rates
- **Receptivity Window Detection**: Why needed - Identifies optimal timing for suggestion delivery; Quick check - Measure improvement in acceptance rates when filtering based on predicted receptivity
- **Privacy-Preserving Telemetry**: Why needed - Ensures ethical data collection in production environments; Quick check - Review data collection methods for compliance with privacy standards
- **IDE Integration Patterns**: Why needed - Enables seamless deployment in real development workflows; Quick check - Validate plugin performance impact on IDE responsiveness
- **Real-time Feature Extraction**: Why needed - Allows immediate prediction without disrupting developer workflow; Quick check - Measure latency of feature computation and prediction

## Architecture Onboarding

Component map: Developer IDE -> Telemetry Collector -> Feature Extractor -> Acceptance Predictor -> LLM Invoker -> Suggestion Renderer

Critical path: Developer action → Telemetry collection → Feature extraction → Prediction → LLM invocation (if predicted accepted)

Design tradeoffs: The system trades some potential suggestions (false negatives) for improved acceptance rates and reduced computational waste. The lightweight telemetry approach avoids complex context analysis but may miss nuanced receptivity signals.

Failure signatures: False negatives occur when the system suppresses suggestions during actual receptivity windows; false positives occur when the system invokes LLM during low-receptivity states; latency issues arise if feature extraction or prediction becomes too slow.

First experiments:
1. Baseline measurement: Record acceptance rates and LLM invocation frequency without pre-filtering
2. Cross-validation: Test model performance on held-out developer sessions to assess generalizability
3. Threshold sensitivity: Evaluate how different prediction thresholds affect the balance between acceptance rate and LLM invocation reduction

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can per-user or per-session adaptive thresholds, potentially using online learning, outperform population-level pooled models in acceptance prediction accuracy?
- Basis in paper: [explicit] The authors state: "Future Work... Develop per-user or per-session adaptive thresholds, potentially using online learning from ongoing acceptance/rejection feedback to refine responsiveness."
- Why unresolved: The deployed model used a single model trained on pooled data from all participants, which does not adapt to individual developer profiles or working styles.
- What evidence would resolve it: A controlled study comparing personalized vs. pooled models, measuring acceptance rates and false negative rates across developer cohorts.

### Open Question 2
- Question: Do behavioral pre-filtering models generalize to large-scale industrial settings with diverse developer populations and workflows?
- Basis in paper: [explicit] The authors acknowledge: "Future work will extend deployment to larger and more diverse industrial cohorts to further validate generalization."
- Why unresolved: The study involved only 25 invited participants (9 active users) in an academic research environment, which may not represent industrial workflow diversity.
- What evidence would resolve it: Deployment across multiple industrial organizations with varying team sizes, languages, and development practices, showing consistent acceptance-rate improvements.

### Open Question 3
- Question: Can higher-order temporal dynamics capturing transitions between focus, exploration, and problem-solving states improve filtering decisions beyond surface-level metrics?
- Basis in paper: [explicit] The authors propose: "Extend beyond surface-level interaction metrics to capture higher-order temporal dynamics and transitions between states of focus, exploration, and problem-solving."
- Why unresolved: Current features (typing speed, pauses, navigation) are aggregate summaries that may not distinguish different cognitive states with similar telemetry patterns.
- What evidence would resolve it: A study incorporating sequential modeling of behavioral states and measuring whether state-aware filtering reduces false negatives during genuine receptivity windows.

## Limitations
- Limited to Visual Studio Code IDE, may not generalize to other development environments
- Simple behavioral features may not capture full complexity of developer context and receptivity
- No comprehensive privacy impact assessment or ethical analysis of behavioral data collection
- Small sample size (25 participants, 9 active) may not represent diverse industrial workflows
- Pooled model approach doesn't account for individual developer differences in working styles

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Behavioral pre-filtering increases acceptance rates and reduces LLM invocations | High |
| The approach is lightweight and privacy-preserving | Medium |
| The method generalizes across different LLM-based code suggestion systems | Low |

## Next Checks
1. Conduct a cross-IDE validation study to test the behavioral pre-filtering approach in multiple development environments (e.g., JetBrains IDEs, Eclipse) and programming languages.
2. Perform a comprehensive privacy impact assessment comparing the telemetry data collection methods used in this study with alternative approaches.
3. Implement and evaluate the pre-filtering system with more sophisticated behavioral features and machine learning models to assess potential improvements in accuracy and generalizability.