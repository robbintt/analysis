---
ver: rpa2
title: Impact of Comments on LLM Comprehension of Legacy Code
arxiv_id: '2506.11007'
source_url: https://arxiv.org/abs/2506.11007
tags:
- comments
- code
- llms
- quiz
- comprehension
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates how code comments affect large language models'
  (LLMs) comprehension of legacy code using multiple-choice question answering (MCQA).
  Experiments with a legacy assembler module (L8W AIT) and four LLMs show that increased
  comment prevalence improves LLM comprehension (up to 16% score improvement), while
  completely inaccurate comments degrade comprehension by 12%.
---

# Impact of Comments on Legacy LLM Comprehension of Legacy Code

## Quick Facts
- arXiv ID: 2506.11007
- Source URL: https://arxiv.org/abs/2506.11007
- Reference count: 15
- Primary result: Comment prevalence improves LLM comprehension by up to 16%, while major inaccuracies degrade it by 12%

## Executive Summary
This study evaluates how code comments affect large language models' (LLMs) comprehension of legacy code using multiple-choice question answering (MCQA). Experiments with a legacy assembler module (L8W AIT) and four LLMs show that increased comment prevalence improves LLM comprehension (up to 16% score improvement), while completely inaccurate comments degrade comprehension by 12%. Minor inaccuracies are tolerated, but major inaccuracies lead LLMs to conflate code and comments, generating false conclusions. These findings highlight the importance of accurate, comprehensive documentation for reliable LLM performance in legacy code tasks.

## Method Summary
The study uses a legacy IBM Z/OS assembler module (L8WAIT) with six comment variants (no comments, function-level only, line-wise only, all comments, 20% inaccurate, 100% inaccurate) and three quiz types (Basic 20Q, Advanced 37Q, Modified for inaccuracy detection). Four LLMs (Claude-3, Llama 3, Mixtral, GPT-4) are evaluated on each variant-quiz combination, repeated three times. Quiz questions cover program function, command meaning, and data processing, with accuracy measured as percentage correct.

## Key Results
- Comment prevalence improved LLM comprehension scores by up to 16% across all tested LLMs
- Major inaccuracies (100% inaccurate comments) degraded comprehension by 12% compared to accurate comments
- Minor inaccuracies (20% inaccurate comments) had negligible effect on quiz scores
- LLMs showed a tendency to conflate code and comments when faced with major inaccuracies, generating false conclusions

## Why This Works (Mechanism)

### Mechanism 1
Comment prevalence improves LLM comprehension by providing natural language semantic anchors for low-level operations. Comments bridge the gap between limited legacy language training data and operational understanding by offering high-level descriptions that LLMs can map to code patterns.

### Mechanism 2
LLMs treat all input (code and comments) as valid, attempting to reconcile discrepancies rather than flagging contradictions. When presented with contradictory information, models attempt to find a coherent interpretation, sometimes generating false conclusions that blend inaccurate comments with code semantics.

### Mechanism 3
Minor comment inaccuracies are tolerated because LLMs can override sparse erroneous signals when code semantics are sufficiently clear. When inaccurate comments represent a small fraction of total context (20%), the preponderance of accurate code and remaining comments allows the model to compute correct answers.

## Foundational Learning

- **Concept: Multiple-Choice Question Answering (MCQA) as LLM Evaluation**
  - Why needed here: This paper uses MCQA as a proxy for comprehension. Understanding how MCQA works—presenting options, measuring selection accuracy—is essential to interpreting reported results.
  - Quick check question: Why might MCQA be preferable to free-form output evaluation for measuring code comprehension?

- **Concept: Legacy vs. Modern Language Training Data Distribution**
  - Why needed here: The paper hypothesizes that legacy languages have less training representation. This affects how much LLMs rely on supplementary context like comments.
  - Quick check question: Which factors might cause an LLM to perform worse on assembly versus Python, assuming equal comment coverage?

- **Concept: Comment Prevalence Levels (Function-Level vs. Line-Wise)**
  - Why needed here: The study distinguishes between function-level ("remarks" in assembler) and line-wise comments, testing each independently. Understanding this hierarchy helps interpret which documentation investments matter most.
  - Quick check question: In the experiment, did function-level comments alone improve scores compared to no comments? What does this suggest about documentation priorities?

## Architecture Onboarding

- **Component map**: Input layer (code variants) -> Evaluation layer (MCQ quizzes) -> Model layer (4 LLMs) -> Scoring layer (accuracy averaged across 3 runs)
- **Critical path**: 1) Select L8WAIT assembler module, 2) Generate comment variants, 3) Create validated MCQs with SME review, 4) Run each LLM on each variant-quiz combination (3x), 5) Compare scores across conditions
- **Design tradeoffs**: Single module limits generalizability; manual quiz creation ensures quality but scales poorly; potential training data contamination from L8WAIT's presence in pretraining corpus
- **Failure signatures**: Score degradation with accurate comments suggests model over-reliance on comments; high variance across runs indicates prompt sensitivity; LLM generating detailed descriptions of functionality not present in code indicates comment-code conflation
- **First 3 experiments**: 1) Replicate on COBOL/Fortran to test language independence, 2) Introduce graduated inaccuracy levels (10%, 30%, 50%) to identify tolerance threshold, 3) Add explicit "verify comment accuracy" prompt to test mitigation of conflation behavior

## Open Questions the Paper Calls Out

### Open Question 1
Do the positive effects of comment prevalence and negative effects of inaccurate comments on LLM comprehension generalize across diverse legacy languages (e.g., COBOL, Fortran) and larger, multi-file codebases? The authors identify validation on larger, more complex codebases across multiple legacy languages as a primary future objective.

### Open Question 2
Can LLMs reliably automate the generation of multiple-choice quizzes for legacy code evaluation to a standard that matches human Subject Matter Experts (SMEs)? The authors note that human quiz creation is time-intensive and state a strategic objective to explore automated quiz generation.

### Open Question 3
To what degree does the positioning of the correct answer in multiple-choice options (MCQA bias) inflate or deflate the measured comprehension scores of legacy code? The authors acknowledge that sensitivity of LLMs to answer positioning in MCQA is well-documented and list mitigating this bias as a key future objective.

## Limitations

- Results based on single assembler module (L8WAIT) limit generalizability to other legacy languages and larger codebases
- Manual quiz creation is time-intensive and doesn't scale to larger or more diverse codebases
- Potential training data contamination from L8WAIT module's presence in pretraining corpus may inflate baseline scores

## Confidence

- **High Confidence**: Comment prevalence improves LLM comprehension (16% improvement)
- **Medium Confidence**: Minor inaccuracies are tolerated while major inaccuracies degrade comprehension
- **Low Confidence**: LLMs conflate code and comments to generate false conclusions

## Next Checks

1. Replicate the experiment on a COBOL or Fortran module to determine if comment effects are language-agnostic or specific to assembly
2. Create 10%, 30%, 50%, and 70% inaccurate comment variants to identify the precise threshold where degradation accelerates
3. Add explicit instructions to verify comment accuracy before answering questions to test whether this mitigates the conflation behavior observed in major inaccuracy conditions