---
ver: rpa2
title: "Treatment Stitching with Schr\xF6dinger Bridge for Enhancing Offline Reinforcement\
  \ Learning in Adaptive Treatment Strategies"
arxiv_id: '2511.12075'
source_url: https://arxiv.org/abs/2511.12075
tags:
- data
- treatment
- trajectories
- clinical
- offline
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Treatment Stitching (TreatStitch), a data
  augmentation framework designed to enhance offline reinforcement learning for adaptive
  treatment strategies in clinical settings. By intelligently stitching segments from
  existing treatment trajectories, TreatStitch generates clinically valid synthetic
  trajectories that address data scarcity challenges.
---

# Treatment Stitching with Schrödinger Bridge for Enhancing Offline Reinforcement Learning in Adaptive Treatment Strategies

## Quick Facts
- arXiv ID: 2511.12075
- Source URL: https://arxiv.org/abs/2511.12075
- Reference count: 31
- Primary result: TreatStitch framework improves offline RL performance by generating clinically valid synthetic trajectories through intelligent stitching and Schrödinger bridge bridging.

## Executive Summary
This paper introduces Treatment Stitching (TreatStitch), a data augmentation framework designed to enhance offline reinforcement learning for adaptive treatment strategies in clinical settings. By intelligently stitching segments from existing treatment trajectories, TreatStitch generates clinically valid synthetic trajectories that address data scarcity challenges. The method identifies similar intermediate patient states across different trajectories and combines their segments. When direct stitching is not possible due to dissimilar states, TreatStitch employs the Schrödinger bridge method to construct smooth bridging trajectories. Extensive experiments on both the EpiCare benchmark and real-world MIMIC-III datasets demonstrate that TreatStitch significantly improves offline RL performance compared to state-of-the-art data augmentation methods.

## Method Summary
TreatStitch is a data augmentation framework for offline reinforcement learning that generates clinically valid synthetic trajectories through intelligent stitching. The method first splits trajectories into high-reward and low-reward groups, then uses priority sampling to identify informative trajectory pairs. When intermediate states are similar (cosine similarity ≥0.95), it directly stitches trajectory segments. For dissimilar states, it employs the Schrödinger bridge method to generate smooth bridging trajectories between states. The framework uses a conservative Q-learning backbone to prevent overestimation of out-of-distribution state-action pairs, with theoretical guarantees that stitched trajectories remain within a bounded neighborhood of original data.

## Key Results
- TreatStitch significantly improves offline RL performance on EpiCare benchmark compared to state-of-the-art data augmentation methods
- Schrödinger bridge extension provides additional benefits particularly in restricted data settings
- Framework preserves clinical validity by avoiding out-of-distribution transitions through theoretical Lipschitz continuity guarantees
- Extensive experiments demonstrate robust performance across both simulated and real-world clinical datasets

## Why This Works (Mechanism)

### Mechanism 1: Trajectory Stitching via Intermediate State Matching
- Claim: Stitching trajectory segments at similar intermediate states creates clinically valid synthetic trajectories that expand dataset coverage while remaining within the original data support.
- Mechanism: The framework computes cosine similarity between all intermediate state pairs across trajectories. When similarity exceeds threshold δ=0.95, it concatenates the early segment from a low-reward trajectory with the late segment from a high-reward trajectory at the matching point, preserving authentic state-action transitions.
- Core assumption: Similar intermediate states represent equivalent underlying clinical conditions, enabling valid cross-trajectory transitions that maintain physiological plausibility.

### Mechanism 2: Schrödinger Bridge for Dissimilar State Connection
- Claim: When direct stitching is impossible due to dissimilar states, optimal transport via Schrödinger bridge generates minimal, smooth bridging trajectories that expand augmentation coverage.
- Mechanism: A neural network G_φ learns Schrödinger potentials through conditional score matching, generating K bridging states between dissimilar start and target states. An inverse dynamics model I_ψ infers actions, and a reward model R_ρ estimates rewards to complete the trajectory.
- Core assumption: Patient state dynamics can be modeled as a smooth stochastic process where entropy-regularized optimal transport produces clinically plausible state sequences.

### Mechanism 3: Conservative Q-Learning Backbone with Regularization
- Claim: CQL's conservative regularization prevents overestimation of OOD state-action pairs, maintaining training stability with augmented data.
- Mechanism: CQL minimizes Bellman error while penalizing high Q-values for actions sampled from a distribution μ (typically uniform or current policy), using regularization parameter β to balance accuracy and conservatism.
- Core assumption: Theorem 1's proof that stitched trajectories remain within O(L√(2(1-δ))) neighborhood of original data ensures CQL's conservatism is appropriate for augmented samples.

## Foundational Learning

- Concept: **Offline RL Distributional Shift**
  - Why needed here: Understanding why offline RL struggles with data scarcity is fundamental; TreatStitch directly addresses extrapolation error from limited dataset coverage.
  - Quick check question: Why does a policy trained on limited offline data perform poorly on state-action pairs it rarely or never observed?

- Concept: **Optimal Transport and Entropy Regularization**
  - Why needed here: The Schrödinger bridge component formulates bridging trajectory generation as an entropy-regularized optimal transport problem between state distributions.
  - Quick check question: How does minimizing KL divergence between a target path measure and a reference Brownian motion process produce smooth trajectories?

- Concept: **Inverse Dynamics Models for Trajectory Completion**
  - Why needed here: After generating bridging states, the framework must infer plausible actions that would cause those state transitions to complete trajectories.
  - Quick check question: Given states s_t and s_{t+1}, what does an inverse dynamics model predict, and why is this easier than forward dynamics prediction?

## Architecture Onboarding

- Component map:
  Trajectory Preprocessor -> Reward-Based Splitter -> Priority Sampler -> Similarity Assessor -> Direct Stitcher / SB Generator -> Trajectory Completer -> Offline RL Backbone

- Critical path:
  1. Load offline dataset D → compute cumulative rewards → split into D_high/D_low
  2. Priority sample (τ_A from D_high, τ_B from D_low) → compute max similarity pair
  3. Branch: if similarity ≥0.95 → direct stitch; else → generate SB bridge
  4. For SB: sample (s_C^t, s_D^t') → train/run G_φ → apply I_ψ and R_ρ → form τ_bridge
  5. Augment D with stitched trajectories → train CQL → evaluate

- Design tradeoffs:
  - Similarity threshold δ: 0.95 balances clinical validity with augmentation rate; higher values reduce OOD risk but limit stitching
  - Temperature α: Controls sampling sharpness; lower α prioritizes extreme reward pairs early, higher α shifts toward uniform coverage
  - Reward split percentile q: 50 (median) ensures balanced groups; 75 may help in data-rich settings but hurts with sparse data
  - Backbone selection: CQL offers best performance but framework is model-agnostic; IQL/DQN show similar augmentation benefits

- Failure signatures:
  - Low stitching rate (<10%): Threshold δ too high or dataset too sparse → lower to 0.90 or enable SB extension
  - CQL performance below baseline: Augmented trajectories may violate Theorem 1 bounds → validate Lipschitz assumption empirically
  - SB generates long/erratic bridges: G_φ undertrained or data insufficient → check bridging length distribution
  - Performance worse on restricted data: Priority sampling may overfit to few high-reward trajectories → increase temperature α

- First 3 experiments:
  1. Replicate Table 1 baseline: CQL alone vs. CQL+TreatStitch on EpiCare full data (131K episodes) with δ=0.95
  2. Restricted data ablation: Compare direct stitching vs. TreatStitch w/ SB on 1024-episode subset
  3. Threshold sensitivity sweep: Test δ ∈ {0.90, 0.92, 0.95, 0.98} on both full and restricted settings

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can domain-informed similarity metrics improve the identification of valid stitching points compared to the currently used cosine similarity?
- Basis in paper: Appendix K states that "domain-informed similarity metrics tailored to clinical settings could further strengthen the validity of the stitching process."
- Why unresolved: The current framework uses cosine similarity for simplicity, which may fail to capture complex physiological dependencies or causal relationships between patient states.
- What evidence would resolve it: A comparative study showing that medically-grounded similarity metrics result in synthetic trajectories with higher clinician approval ratings or better physiological consistency.

### Open Question 2
- Question: How can the Schrödinger bridge framework be modified to enforce hard clinical safety constraints during the generation of bridging trajectories?
- Basis in paper: Appendix K suggests "incorporating domain-specific constraints... such as constraining bridging trajectories to respect known physiological relationships."
- Why unresolved: The current Schrödinger bridge method optimizes for energy-efficient transitions without explicitly encoding hard safety limits, such as dosage thresholds or contraindications.
- What evidence would resolve it: An algorithmic modification that guarantees generated bridging states satisfy defined safety predicates while maintaining the diversity benefits of data augmentation.

### Open Question 3
- Question: Do the synthetic stitched trajectories generated by TreatStitch align with established evidence-based clinical treatment protocols?
- Basis in paper: Appendix K calls for "comparing stitched trajectories to formal clinical guidelines and treatment protocols" to ensure clinical utility.
- Why unresolved: The current evaluation relies on retrospective quantitative metrics, which do not verify if the agent's logic mirrors recognized therapeutic strategies.
- What evidence would resolve it: Case studies where clinical experts successfully map the generated stitched trajectories to standard treatment pathways without identifying implausible transitions.

## Limitations

- The framework's reliance on Theorem 1's Lipschitz continuity assumption for clinical validity is not empirically validated on real-world datasets
- The extension to MIMIC-III sepsis data lacks detailed ablations of SB performance across varying patient subgroups
- The paper does not report sensitivity to hyperparameter choices like temperature schedule for α or the number of synthetic trajectories M

## Confidence

- **High Confidence**: Direct trajectory stitching mechanism with cosine similarity threshold (δ=0.95) and priority sampling effectiveness
- **Medium Confidence**: CQL backbone performance improvement with augmentation (Table 4 results)
- **Medium Confidence**: SB extension benefits in restricted data settings (Table 2 results)
- **Low Confidence**: Clinical validity preservation guarantees in real-world settings without empirical Lipschitz verification

## Next Checks

1. **Lipschitz Continuity Verification**: Empirically measure the Lipschitz constant of the transition dynamics in MIMIC-III to validate Theorem 1's assumptions about trajectory augmentation bounds.

2. **Hyperparameter Sensitivity Analysis**: Conduct comprehensive sweeps of temperature α, similarity threshold δ, and reward split percentile q across both full and restricted data regimes to identify stable operating regions.

3. **Generalization Cross-Domain**: Test TreatStitch on a third clinical dataset with different treatment modalities (e.g., oncology or chronic disease management) to assess robustness beyond sepsis and benchmark environments.