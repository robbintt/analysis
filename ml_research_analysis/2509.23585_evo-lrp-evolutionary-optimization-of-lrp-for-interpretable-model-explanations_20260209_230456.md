---
ver: rpa2
title: 'EVO-LRP: Evolutionary Optimization of LRP for Interpretable Model Explanations'
arxiv_id: '2509.23585'
source_url: https://arxiv.org/abs/2509.23585
tags:
- evo-lrp
- relevance
- optimization
- these
- rule
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: EVO-LRP optimizes Layer-wise Relevance Propagation (LRP) hyperparameters
  using Covariance Matrix Adaptation Evolution Strategy (CMA-ES) to maximize interpretability
  metrics such as faithfulness, sparseness, and sensitivity. Experiments on the ImageNet
  validation set show that EVO-LRP outperforms traditional baselines (GradCAM, LIME,
  Integrated Gradients, LRP-0) by achieving significantly higher faithfulness (1.46
  vs 0.08-0.57), higher sparseness (0.67 vs 0.24-0.49), and lower average sensitivity
  (0.0027 vs 0.41-1.16).
---

# EVO-LRP: Evolutionary Optimization of LRP for Interpretable Model Explanations

## Quick Facts
- arXiv ID: 2509.23585
- Source URL: https://arxiv.org/abs/2509.23585
- Reference count: 40
- Optimized LRP hyperparameters using CMA-ES to achieve significantly higher faithfulness (1.46 vs 0.08-0.57), sparseness (0.67 vs 0.24-0.49), and lower sensitivity (0.0027 vs 0.41-1.16) compared to traditional baselines

## Executive Summary
EVO-LRP introduces an evolutionary optimization framework that systematically tunes Layer-wise Relevance Propagation (LRP) hyperparameters to maximize interpretability metrics including faithfulness, sparseness, and sensitivity. Using Covariance Matrix Adaptation Evolution Strategy (CMA-ES), the method optimizes alpha and epsilon parameters to generate more accurate and sparse explanations that better align with model predictions. Experiments on ImageNet demonstrate substantial improvements over traditional baselines like GradCAM, LIME, and Integrated Gradients, with quantitative results showing EVO-LRP produces explanations that are significantly more faithful to model predictions while maintaining high sparseness.

## Method Summary
EVO-LRP employs CMA-ES to optimize LRP hyperparameters through a population-based evolutionary approach. The method iteratively evaluates candidate hyperparameter sets by generating relevance maps and computing interpretability metrics. Each generation produces offspring through sampling from a Gaussian distribution centered around the mean of the current population, with selection pressure favoring individuals that maximize the weighted combination of faithfulness, sparseness, and sensitivity metrics. The optimization process continues until convergence or a maximum number of iterations is reached, resulting in optimized alpha and epsilon parameters that produce superior explanations compared to traditional fixed-parameter LRP methods.

## Key Results
- Achieved faithfulness score of 1.46 compared to 0.08-0.57 for traditional baselines (GradCAM, LIME, Integrated Gradients, LRP-0)
- Obtained sparseness score of 0.67 versus 0.24-0.49 for baseline methods, indicating more focused relevance attribution
- Demonstrated significantly lower average sensitivity (0.0027) compared to baseline methods (0.41-1.16), indicating more stable explanations

## Why This Works (Mechanism)
EVO-LRP works by treating LRP hyperparameter optimization as a black-box optimization problem where interpretability metrics serve as the objective function. The CMA-ES algorithm efficiently explores the hyperparameter space by maintaining a covariance matrix that captures the relationships between alpha and epsilon parameters. This evolutionary approach allows systematic discovery of hyperparameter combinations that balance competing objectives: high faithfulness ensures explanations accurately reflect model decisions, high sparseness produces clean, interpretable maps, and low sensitivity guarantees stability across input perturbations. By directly optimizing for these metrics rather than relying on heuristic parameter choices, EVO-LRP discovers configurations that traditional approaches miss.

## Foundational Learning
- **Layer-wise Relevance Propagation (LRP)**: A technique that propagates relevance backward through neural network layers to assign attribution scores to input features; needed to understand the base explanation method being optimized
- **Covariance Matrix Adaptation Evolution Strategy (CMA-ES)**: An evolutionary algorithm that adapts its search distribution based on successful candidates; needed to understand the optimization mechanism
- **Interpretability Metrics (Faithfulness, Sparseness, Sensitivity)**: Quantitative measures of explanation quality; needed to understand the optimization objectives
- **Alpha-beta rule in LRP**: Governs how relevance is distributed between positive and negative contributions; needed to understand the hyperparameter space
- **Epsilon stabilization**: Prevents numerical instability during relevance propagation; needed to understand numerical considerations
- **ImageNet validation set**: Standard benchmark dataset for evaluating computer vision models; needed to contextualize experimental results

## Architecture Onboarding
Component Map: Input Images -> LRP Propagation -> Relevance Maps -> Metric Computation -> CMA-ES Optimization -> Updated Hyperparameters -> Output Explanations

Critical Path: The optimization loop forms the critical path where each iteration requires: (1) generating explanations with current hyperparameters, (2) computing faithfulness, sparseness, and sensitivity metrics, (3) updating the CMA-ES population based on metric scores. The bottleneck is metric computation, particularly sensitivity analysis which requires multiple forward passes with perturbed inputs.

Design Tradeoffs: EVO-LRP trades computational efficiency for explanation quality. While traditional LRP uses fixed parameters (often alpha=1, epsilon=0.001) computed in a single forward-backward pass, EVO-LRP requires iterative optimization with multiple metric evaluations per iteration. The choice of three interpretability metrics creates a multi-objective optimization problem that better captures explanation quality but increases computational cost.

Failure Signatures: Poor convergence may occur if the metric landscape is too flat or contains many local optima. Overfitting to the validation set metrics is possible if the optimization runs too long. The method may fail if the chosen metrics are poorly correlated with human judgment of interpretability.

First Experiments: 1) Run CMA-ES optimization on a small subset of ImageNet to verify convergence behavior and metric improvement trends. 2) Compare EVO-LRP explanations with ground truth segmentation masks on datasets with available annotations. 3) Perform ablation studies removing individual metrics from the optimization objective to quantify their relative importance.

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but implicit questions include: How well does EVO-LRP generalize to domains beyond ImageNet? What is the computational overhead compared to real-time requirements? How do the optimized hyperparameters transfer across different model architectures?

## Limitations
- Computational cost of CMA-ES optimization is substantial and not explicitly quantified, potentially limiting practical deployment
- Results are primarily validated on ImageNet validation set, limiting generalizability to other domains or datasets
- Dependence on specific interpretability metrics may not fully capture human perception of what constitutes a "good" explanation

## Confidence
- High confidence: Quantitative comparisons between EVO-LRP and baseline methods are methodologically sound with clear statistical improvements across all three metrics
- Medium confidence: Claims about class-specific relevance maps distinguishing competing objects are supported by qualitative examples but need more systematic quantitative validation
- Medium confidence: Assertions about sparse maps highlighting object boundaries effectively need validation through human studies or comparison with established segmentation methods

## Next Checks
1. Conduct user studies to verify that optimized explanations align with human judgment of interpretability beyond automated metrics
2. Test EVO-LRP on diverse datasets beyond ImageNet (medical imaging, satellite imagery, or text classification) to assess domain generalization
3. Perform ablation studies to quantify the relative contribution of each interpretability metric to final explanation quality and determine if all three are necessary