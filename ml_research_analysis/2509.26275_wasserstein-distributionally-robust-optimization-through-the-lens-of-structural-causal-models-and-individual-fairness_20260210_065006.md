---
ver: rpa2
title: Wasserstein Distributionally Robust Optimization Through the Lens of Structural
  Causal Models and Individual Fairness
arxiv_id: '2509.26275'
source_url: https://arxiv.org/abs/2509.26275
tags:
- function
- sensitive
- have
- theorem
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Causally Fair Distributionally Robust Optimization
  (CDRO), which integrates causal structures and sensitive attributes into the DRO
  framework to address individual fairness. The authors define a Causally Fair Dissimilarity
  Function (CFDF) that incorporates counterfactuals and sensitive attribute perturbations,
  and prove a strong duality theorem for their causally fair DRO formulation.
---

# Wasserstein Distributionally Robust Optimization Through the Lens of Structural Causal Models and Individual Fairness

## Quick Facts
- **arXiv ID:** 2509.26275
- **Source URL:** https://arxiv.org/abs/2509.26275
- **Reference count:** 40
- **One-line primary result:** CDRO achieves lower unfair areas (0.01-0.02) and counterfactual unfairness (0-0.01) vs 0.02-0.04 and 0.04-0.19 for baselines, with competitive accuracy (73-67%)

## Executive Summary
This paper introduces Causally Fair Distributionally Robust Optimization (CDRO), which integrates causal structures and sensitive attributes into the DRO framework to address individual fairness. The authors define a Causally Fair Dissimilarity Function (CFDF) that incorporates counterfactuals and sensitive attribute perturbations, and prove a strong duality theorem for their causally fair DRO formulation. They derive closed-form regularizers for linear SCMs and first-order estimates for non-linear cases, showing that CDRO reduces to classical robust optimization under certain conditions. The method provides finite-sample guarantees when the SCM is unknown.

## Method Summary
The CDRO framework extends distributionally robust optimization by incorporating causal knowledge through Structural Causal Models (SCMs) to define a causally fair dissimilarity function (CFDF). The method uses counterfactual reasoning to measure individual fairness by considering what would happen to similar individuals if their sensitive attributes were different. For linear SCMs, the authors derive closed-form regularizers that can be added to the empirical risk minimization objective, while for non-linear cases they provide first-order approximations. The framework assumes Additive Noise Models (ANMs) and proves strong duality between the primal and dual optimization problems, enabling tractable computation through regularized empirical risk minimization.

## Key Results
- CDRO achieves significantly lower unfair area (0.01-0.02) compared to baselines (0.02-0.04) on real datasets
- Counterfactual unfairness is substantially reduced (0-0.01) versus baselines (0.04-0.19)
- Maintains competitive accuracy (73-67%) with only minor trade-offs
- Strong duality theorem enables tractable optimization through regularization
- Closed-form regularizers derived for linear SCMs

## Why This Works (Mechanism)
The method works by explicitly modeling causal relationships between variables and using this structure to define fairer distance metrics. By incorporating counterfactual reasoning through the CFDF, the framework ensures that predictions are robust not just to perturbations in observed features, but to what would happen under different sensitive attribute values. The strong duality result transforms the computationally intractable worst-case DRO problem into a tractable regularized optimization problem, where the regularizer naturally encodes causal fairness constraints through the SCM structure.

## Foundational Learning
- **Structural Causal Models (SCMs):** Directed acyclic graphs representing causal relationships with functional equations and exogenous noise - needed to formalize the causal assumptions and derive counterfactuals
- **Distributionally Robust Optimization (DRO):** Optimization framework that minimizes worst-case expected loss over an ambiguity set - needed to provide theoretical guarantees against distributional shifts
- **Individual Fairness:** Notion that similar individuals should receive similar outcomes - needed to formalize the fairness objective in terms of pairwise comparisons
- **Counterfactual Reasoning:** Reasoning about hypothetical scenarios where certain variables take different values - needed to define the CFDF that captures causal fairness
- **Strong Duality:** Property where primal and dual optimization problems have the same optimal value - needed to convert the intractable DRO problem into tractable regularized optimization
- **Semi-latent Maps:** Transformations that map from observed variables to latent exogenous variables - needed to decompose the feature space into sensitive and non-sensitive components

## Architecture Onboarding

**Component Map:** Data -> SCM Fitting -> CDRO Regularizer -> Empirical Risk Minimization -> Evaluation Metrics

**Critical Path:** The core computation involves fitting the SCM to obtain matrix M, computing the projection P_X onto non-sensitive exogenous space, and using these to calculate the regularizer term that modifies the base loss function during optimization.

**Design Tradeoffs:** The framework trades off exact fairness (through counterfactual reasoning) for computational tractability (via strong duality), and requires specifying a causal structure which may not always be available or identifiable from data.

**Failure Signatures:** If the SCM inversion fails (non-invertible M), the CFDF becomes undefined. If the Lipschitz constant estimation is incorrect, the regularization may be too weak or too strong. Poor causal structure specification leads to incorrect fairness metrics.

**First Experiments:** 1) Verify SCM inversion produces invertible matrix M on synthetic data with known ground truth, 2) Test regularizer implementation on simple linear case with closed-form solution, 3) Validate counterfactual sampling produces meaningful perturbations within Wasserstein ball

## Open Questions the Paper Calls Out
- What is the theoretical relationship between the proposed Causally Fair DRO method and causal optimal transport?
- How can the framework be extended to Structural Causal Models that do not satisfy the Additive Noise Model (ANM) assumption?
- Can exact closed-form regularizers be derived for the more general cases omitted from Theorems 2 and 3?

## Limitations
- Requires specification of causal structure which may not be identifiable from observational data alone
- Currently limited to Additive Noise Models, which may not capture all real-world causal relationships
- Training requires tuning of Wasserstein radius δ, which is not fully specified in experiments
- Computational overhead from SCM fitting and counterfactual generation

## Confidence
- **High Confidence:** Theoretical framework (Theorems 1-3), general CDRO objective formulation, evaluation metrics (U_Δ and CF)
- **Medium Confidence:** Empirical results can be approximately reproduced with correct SCM fitting procedure
- **Low Confidence:** Exact replication depends on unspecified training hyperparameters and specific causal structure estimation method

## Next Checks
1. **SCM Inversion Verification:** Implement linear ANM fitting using both OLS and LiNGAM on Adult dataset, verify resulting M matrix is invertible and produces reasonable counterfactual samples
2. **Regularizer Implementation:** Cross-validate dual norm calculation for regularizer term against base perturbation norm used in Wasserstein ball definition
3. **Baseline Replication:** Re-implement DRO and CPV baselines using same logistic regression framework to verify reported accuracy-fairness trade-offs