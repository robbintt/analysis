---
ver: rpa2
title: A note on the impossibility of conditional PAC-efficient reasoning in large
  language models
arxiv_id: '2512.03057'
source_url: https://arxiv.org/abs/2512.03057
tags:
- conditional
- efficiency
- fast
- expert
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper establishes an impossibility result for conditional\
  \ Probably Approximately Correct (PAC)-efficient reasoning in large language models.\
  \ The core method involves proving that any algorithm achieving conditional PAC\
  \ efficiency must be trivial in the sense that it defers to the expensive expert\
  \ model with probability at least 1-\u03B1 for almost every input."
---

# A note on the impossibility of conditional PAC-efficient reasoning in large language models

## Quick Facts
- arXiv ID: 2512.03057
- Source URL: https://arxiv.org/abs/2512.03057
- Reference count: 2
- Primary result: Establishes impossibility of non-trivial conditional PAC-efficient reasoning in LLM routing systems

## Executive Summary
This paper proves that conditional Probably Approximately Correct (PAC)-efficient reasoning is impossible for non-trivial algorithms in the distribution-free setting. The result shows that any algorithm achieving conditional PAC efficiency must defer to the expensive expert model with probability at least 1-α for almost every input. This impossibility extends classical results from conformal prediction to the PAC reasoning framework, demonstrating that pointwise conditional guarantees fundamentally conflict with computational efficiency. The practical implication is that practitioners should focus on marginal PAC efficiency guarantees rather than conditional ones, as the latter eliminate most computational savings.

## Method Summary
The paper establishes impossibility through a construction showing finite-sample indistinguishability between distributions while maintaining high loss at specific points. The proof demonstrates that for any algorithm achieving conditional PAC efficiency, one can construct a distribution that differs locally around any target point but is indistinguishable from the true distribution using only finite calibration samples. This forces the algorithm to defer to the expert model with probability ≥ 1-α at that point. The key mechanism relies on the fact that individual points in a non-atomic space have zero probability mass, making it impossible to detect local distributional changes from finite samples.

## Key Results
- Conditional PAC efficiency is impossible for non-trivial algorithms in the distribution-free setting
- Any algorithm achieving conditional PAC efficiency must defer to expert with probability ≥ 1-α almost everywhere
- Marginal PAC efficiency remains achievable through calibration-based threshold selection
- The impossibility extends classical conformal prediction results to the PAC reasoning framework

## Why This Works (Mechanism)

### Mechanism 1
Routing between expert and fast models can provide marginal risk guarantees but cannot provide pointwise conditional guarantees without becoming trivial. A routing function g(x) determines whether to use expert or fast model, with pointwise risk controlled at marginal level by thresholding a score function on calibration data. The impossibility arises because conditional control requires g(x)=0 with probability ≤ α for almost every x. Core assumption: input space X is non-atomic with fast model having non-trivial loss on positive measure set.

### Mechanism 2
The impossibility arises from finite-sample indistinguishability—calibration data cannot distinguish between distributions that differ only locally around any specific input point. For any target point x* and η > 0, construct distribution P' matching P everywhere except in a small ball where fast model has high loss. The probability any calibration sample falls in this ball is bounded, making P' indistinguishable from P in finite samples. Since algorithm cannot distinguish P' from P, it must defer to expert with probability ≥ 1-α at x* under P as well.

### Mechanism 3
Marginal PAC efficiency remains achievable through calibration-based threshold selection using the Learn-Then-Test framework. Given a score function s(x) measuring difficulty, set threshold τ on calibration data to control marginal risk P(R(f̂;X) > ε) ≤ α. This controls average risk without requiring pointwise guarantees. Core assumption: calibration dataset is i.i.d. from deployment distribution.

## Foundational Learning

- **Total Variation Distance**
  - Why needed here: Proof relies on bounding TV((P')^n, P^n) to establish finite samples cannot distinguish distributions
  - Quick check question: Can you explain why TV(P^n, Q^n) ≤ n·TV(P, Q)?

- **Non-atomic Measure Spaces**
  - Why needed here: Impossibility requires individual points have zero probability mass, enabling small-ball construction
  - Quick check question: Why would result fail if X = {x_1, x_2} with P_X(x_1) = 0.5?

- **Conformal Prediction / Distribution-Free Inference**
  - Why needed here: Extends classical impossibility results from conformal prediction to PAC reasoning
  - Quick check question: What is the difference between marginal coverage (1-α on average) and conditional coverage (1-α for each x)?

## Architecture Onboarding

- **Component map**: Expert model f -> Fast model f̃ -> Router g(x) -> Score function s(x) -> Calibration dataset D_cal

- **Critical path**:
  1. Define loss function ℓ (e.g., 0-1 loss for correctness)
  2. Design score function s(x) correlated with fast model failure
  3. Collect calibration data with expert outputs
  4. Apply Learn-Then-Test to find threshold τ satisfying marginal risk bound
  5. Deploy router with g(x) = 1{s(x) > τ}

- **Design tradeoffs**:
  - Marginal vs Conditional Guarantees: Marginal allows efficiency gains; conditional is impossible non-trivially
  - Score function quality: Better scores → higher deferral rates to fast model while maintaining risk bound
  - Calibration set size n: Larger n → tighter bounds, but higher setup cost

- **Failure signatures**:
  - Attempting conditional guarantees: Algorithm will be forced to defer to expert with probability ≥ 1-α almost everywhere
  - Distribution shift: Calibration bounds no longer valid at deployment
  - Atomic input spaces: Impossibility proof may not apply (check P_X assumptions)

- **First 3 experiments**:
  1. Validate marginal PAC efficiency: Implement threshold selection on held-out calibration data; verify P(R > ε) ≤ α empirically across multiple splits
  2. Measure efficiency gain: Compute fraction of inputs routed to fast model; compare to theoretical maximum (1-α meaningless for conditional case)
  3. Test distribution shift sensitivity: Evaluate router on out-of-distribution inputs; observe whether risk bound degrades

## Open Questions the Paper Calls Out

### Open Question 1
What specific distributional assumptions enable non-trivial conditional PAC efficiency? The paper concludes practitioners should explore relaxed notions under distributional assumptions, but does not investigate conditions (e.g., Lipschitz continuity) that might allow non-trivial routing. Evidence would be derivation of an algorithm achieving conditional efficiency with deferral rates lower than 1-α under defined distributional constraints.

### Open Question 2
Does the impossibility result hold for finite or atomic input spaces? Theorem 3 relies on non-atomic complete separable metric space assumption. The proof technique requires constructing small balls with arbitrarily small probability mass, which is not possible in discrete or atomic spaces where individual points may have non-zero mass. Evidence would be proof of impossibility for atomic spaces or construction of non-trivial conditional PAC-efficient algorithm for discrete inputs.

### Open Question 3
Can "group-conditional" PAC efficiency be achieved in a distribution-free manner? The paper contrasts marginal vs. conditional (pointwise) guarantees but does not address group-conditional guarantees common in conformal prediction literature. While pointwise guarantees are shown to be trivial, it is unknown if controlling risk over pre-defined groups allows for meaningful efficiency gains without distributional assumptions. Evidence would be modification of PAC reasoning framework providing distribution-free guarantees for input subgroups while maintaining non-trivial deferral rates.

## Limitations

- The impossibility critically depends on non-atomic input spaces; result may not hold for discrete or atomic spaces
- Proof construction assumes fast model has non-trivial loss on positive measure set; may not apply if fast model nearly matches expert everywhere
- Construction in Lemma 5 for creating locally-modified distributions requires careful handling of loss function properties not fully specified

## Confidence

- **High Confidence**: Backward direction of Theorem 3 showing conditional PAC efficiency implies trivial deferral, based on finite-sample indistinguishability argument via total variation distance
- **Medium Confidence**: Separability argument extending result from individual points to almost-everywhere statements, which relies on properties of complete separable metric spaces
- **Medium Confidence**: Practical implication that marginal PAC efficiency remains viable, though this depends on score function quality and distribution stability assumptions

## Next Checks

1. Check the construction in Lemma 5: Verify the explicit construction of distribution Q_ε that ensures fast model has loss exceeding ε for all possible outputs, which is crucial for the impossibility proof but lacks detailed specification.

2. Test atomic input spaces: Examine whether impossibility result holds when X has atoms (discrete points with positive probability mass). Construct simple counterexample with X = {x₁, x₂} to verify separability argument fails in discrete settings.

3. Validate marginality vs. conditionality: Implement simple router system with varying score functions and calibration set sizes to empirically demonstrate efficiency gains possible with marginal guarantees versus trivial behavior under conditional requirements.