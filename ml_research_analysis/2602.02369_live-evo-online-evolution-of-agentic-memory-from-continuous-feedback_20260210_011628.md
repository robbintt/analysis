---
ver: rpa2
title: 'Live-Evo: Online Evolution of Agentic Memory from Continuous Feedback'
arxiv_id: '2602.02369'
source_url: https://arxiv.org/abs/2602.02369
tags:
- memory
- agent
- experience
- experiences
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Live-Evo introduces a memory system for LLM agents that learns\
  \ online from streaming feedback, decoupling stored experiences from task-specific\
  \ usage guidelines. It maintains an Experience Bank and a Meta-Guideline Bank, using\
  \ a four-stage loop\u2014Retrieve, Compile, Act, Update\u2014to adapt guidance over\
  \ time."
---

# Live-Evo: Online Evolution of Agentic Memory from Continuous Feedback

## Quick Facts
- **arXiv ID:** 2602.02369
- **Source URL:** https://arxiv.org/abs/2602.02369
- **Reference count:** 11
- **Primary result:** Improves Brier score by 20.8% and market returns by 12.9% over 10 weeks on live Prophet Arena benchmark

## Executive Summary
Live-Evo is a memory system for LLM agents that evolves agentic memory from streaming feedback. It decouples stored experiences from task-specific usage guidelines, maintaining separate Experience and Meta-Guideline Banks. The system uses a four-stage loop—Retrieve, Compile, Act, Update—to adapt guidance over time. On a live financial forecasting benchmark, Live-Evo demonstrates consistent improvements in calibration and decision-making under non-stationary conditions.

## Method Summary
Live-Evo introduces a memory system that learns online from continuous feedback streams. It maintains two separate banks: an Experience Bank storing raw experiences, and a Meta-Guideline Bank containing task-specific usage instructions. The system operates through a four-stage loop: retrieving relevant experiences, compiling them into guidelines, acting on tasks, and updating both banks based on feedback. This architecture allows agents to filter stale experiences and reinforce useful ones, enabling progressive improvement in calibration and decision-making even as task conditions change.

## Key Results
- Improves Brier score by 20.8% and market returns by 12.9% over 10 weeks on live Prophet Arena benchmark
- Shows consistent gains on deep-research tasks across multiple evaluation periods
- Ablation study confirms each component (Experience Bank, Meta-Guideline Bank, four-stage loop) is essential for performance

## Why This Works (Mechanism)
The core mechanism is the separation of experiences from their usage guidelines, allowing the system to adapt task-specific instructions while preserving raw experiences. By maintaining distinct Experience and Meta-Guideline Banks, Live-Evo can evolve its decision-making process without losing historical context. The four-stage loop enables continuous learning from feedback, filtering out irrelevant experiences while reinforcing useful patterns. This architecture particularly excels in non-stationary environments where task conditions change over time, as the system can adapt its guidelines while maintaining a rich repository of experiences.

## Foundational Learning

**Experience-Guideline Decoupling**
*Why needed:* Prevents task-specific instructions from becoming outdated as conditions change
*Quick check:* Verify that experiences remain relevant even when guidelines are updated

**Online Feedback Integration**
*Why needed:* Enables continuous adaptation without retraining from scratch
*Quick check:* Confirm system improves with each feedback cycle

**Experience Filtering Mechanism**
*Why needed:* Maintains relevance by removing stale or unhelpful experiences
*Quick check:* Ensure system performance doesn't degrade with accumulated experiences

**Non-stationary Adaptation**
*Why needed:* Critical for environments where task conditions evolve over time
*Quick check:* Test performance across different time periods with changing conditions

## Architecture Onboarding

**Component Map:**
Experience Bank -> Retrieve Module -> Compile Module -> Act Module -> Update Module -> Meta-Guideline Bank -> (feedback loop)

**Critical Path:**
Experience retrieval → Guideline compilation → Action execution → Feedback integration

**Design Tradeoffs:**
- Separate banks increase complexity but enable more flexible adaptation
- Four-stage loop adds latency but provides structured learning
- Experience filtering prevents memory bloat but requires careful threshold tuning

**Failure Signatures:**
- Performance degradation indicates outdated guidelines
- Memory bloat suggests ineffective filtering
- Inconsistent improvements may signal feedback processing issues

**First Experiments:**
1. Run baseline without feedback loop to establish performance floor
2. Test experience filtering thresholds with synthetic data
3. Validate guideline compilation with controlled task variations

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to one financial forecasting task and single benchmark (Prophet Arena)
- Does not address scalability issues with large numbers of experiences or tasks
- No explicit testing of robustness to noisy or adversarial feedback

## Confidence
- Performance improvements are statistically significant within evaluated setup: **High**
- Generalizability to other domains and non-stationary conditions: **Medium**
- Computational overhead and memory requirements at scale: **Low**

## Next Checks
1. Test Live-Evo's performance on multiple non-stationary tasks beyond financial forecasting to assess domain generalization
2. Evaluate the system's resilience to noisy or adversarial feedback to ensure robustness in real-world deployment
3. Measure and analyze the computational overhead and memory requirements as the Experience and Meta-Guideline Banks scale up