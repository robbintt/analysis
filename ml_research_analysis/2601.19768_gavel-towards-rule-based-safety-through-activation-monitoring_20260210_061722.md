---
ver: rpa2
title: 'GAVEL: Towards rule-based safety through activation monitoring'
arxiv_id: '2601.19768'
source_url: https://arxiv.org/abs/2601.19768
tags:
- uni00000048
- uni00000044
- uni00000055
- uni00000052
- uni00000051
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "GAVEL introduces a rule-based framework for activation-based safety\
  \ in LLMs, addressing the limitations of current methods\u2014poor precision, inflexibility,\
  \ and lack of interpretability. It defines Cognitive Elements (CEs) as interpretable\
  \ activation-level primitives, such as \u201Cmaking a threat\u201D or \u201Cpayment\
  \ processing,\u201D and enables rules over CEs to detect nuanced behaviors with\
  \ high precision."
---

# GAVEL: Towards rule-based safety through activation monitoring

## Quick Facts
- arXiv ID: 2601.19768
- Source URL: https://arxiv.org/abs/2601.19768
- Reference count: 36
- Primary result: GAVEL achieves over 98% TPR and near-zero FPR across diverse misuse scenarios, outperforming baseline methods

## Executive Summary
GAVEL introduces a rule-based framework for activation-based safety in LLMs, addressing the limitations of current methods—poor precision, inflexibility, and lack of interpretability. It defines Cognitive Elements (CEs) as interpretable activation-level primitives, such as "making a threat" or "payment processing," and enables rules over CEs to detect nuanced behaviors with high precision. By decoupling activation engineering from rule configuration, GAVEL supports rapid, customizable safety enforcement without retraining models or detectors.

## Method Summary
GAVEL works by first eliciting CE-specific activations from a target LLM using excitation datasets and ERI prompting. These attention outputs are captured from mid-to-later layers and stacked to form token-level representations. A multi-label RNN classifier is trained to predict CE presence from these activation vectors. At inference, the system classifies each token, aggregates CE presence over a temporal window, and evaluates human-defined Boolean rules over the resulting vector. When a rule fires, an enforcement action is triggered.

## Key Results
- GAVEL achieves over 98% True Positive Rate (TPR) across diverse misuse scenarios
- Near-zero False Positive Rate (FPR) on benign conversations
- Runtime overhead remains under 1% while maintaining high detection accuracy

## Why This Works (Mechanism)

### Mechanism 1: Cognitive Element (CE) Detection via Attention Output Classification
Fine-grained, interpretable model behaviors (CEs) are detected by training a lightweight multi-label classifier on model attention outputs. The process involves eliciting activations through excitation datasets, representing tokens using stacked attention outputs, and classifying with an RNN. Core assumption: attention patterns contain learnable signatures for specific behaviors. Evidence shows attention outputs achieve 95.5% TPR vs 82.3% for MLP outputs.

### Mechanism 2: Composition of CEs into Boolean Rules for Precision
High-precision detection is achieved by composing atomic CE predictions with logical rules. CE predictions are aggregated into a temporal presence vector, and rules are expressed as Boolean predicates over this vector. Core assumption: complex violations can be decomposed into conjunctions/disjunctions of simpler behavioral primitives. This avoids false positives from benign but partially similar conversations.

### Mechanism 3: Decoupling Activation Engineering from Rule Configuration
System agility is achieved by separating model-specific activation engineering from model-agnostic rule configuration. Activation engineering involves creating excitation datasets and training the CE detector, while rule configuration uses a textual syntax that operates on abstract CE predictions. This allows practitioners to adopt, share, and modify rules without retraining the underlying detector.

## Foundational Learning

- **Concept: Activation-based Monitoring & Representation Engineering**
  - Why needed here: GAVEL is fundamentally an activation-monitoring system that extracts internal concepts from high-dimensional activation space.
  - Quick check question: Why does GAVEL monitor attention outputs instead of final hidden states? (A: Ablation showed attention outputs yielded higher TPR and lower FPR, capturing richer contextual information.)

- **Concept: Multi-label vs. Multi-class Classification**
  - Why needed here: The CE detector must predict multiple simultaneous behaviors per token, requiring multi-label classification.
  - Quick check question: How does the CE classifier output differ from standard classification? (A: Output is a vector of independent probabilities for each CE, allowing multiple CEs to be active simultaneously.)

- **Concept: Boolean Logic & Predicate Rules**
  - Why needed here: The core of GAVEL's safety is composing CEs using AND, OR, and NOT operations.
  - Quick check question: How would you translate the Phishing rule `c8 ∧ (c2 ∨ c6 ∨ c20)`? (A: Model must be Creating Content AND (Click/Enter OR Provide/Give OR Personal information).)

## Architecture Onboarding

- **Component Map:**
  1. Target LLM (`f_θ`) -> 2. Attention Output Capture -> 3. CE Detector (`g`) -> 4. Rule Engine -> 5. Enforcement Actions

- **Critical Path:**
  1. Define CEs & Rules (Table 2)
  2. Create Excitation Data (D_c) for each CE
  3. Train CE Detector on activation datasets
  4. Deploy & Monitor: classify tokens, evaluate rules, trigger actions

- **Design Tradeoffs:**
  - Granularity vs. Complexity: CEs must be specific enough for precision but not so numerous that rules become unwieldy
  - Interpretability vs. Performance: Simple RNN makes it fast and interpretable but may miss complex non-linear relationships
  - Static vs. Adaptive Window: Fixed window is simpler but may miss context-sensitive behaviors

- **Failure Signatures:**
  - High FPR: Miscalibrated CE detector, examine excitation datasets for noise
  - High FNR: Classifier fails to detect CEs, excitation data may not be representative
  - CE-Level Jailbreak: Attackers trigger harm without CE activation, monitor for adversarial attacks

- **First 3 Experiments:**
  1. Reproduce ablation comparing attention outputs vs hidden states on single CE
  2. Test CE transfer by training on Mistral-7B and evaluating on LLaMA-3 without retraining
  3. Rule precision analysis measuring FPR on curated benign dataset vs misuse dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can adversaries construct "CE-level jailbreaks" that trigger harmful behaviors while evading detection by suppressing associated CE signatures?
- Basis: Paper identifies theoretical vulnerability but doesn't evaluate CE-level evasion attacks
- What evidence would resolve: Empirical evaluation of gradient-based attacks targeting CE classifier evasion

### Open Question 2
- Question: Would alternative detection architectures (transformers, Sparse Autoencoders) improve CE detection accuracy or enable discovery of more fine-grained cognitive elements?
- Basis: Paper suggests exploring alternative CE detection methods beyond the current RNN
- What evidence would resolve: Head-to-head comparison of transformer/SAE-based detectors vs RNN baseline

### Open Question 3
- Question: Can adaptive or dynamic temporal windowing strategies improve detection of context-sensitive violations compared to fixed full-conversation window?
- Basis: Paper notes that shorter or adaptive windows may better capture context-sensitive behaviors
- What evidence would resolve: Ablation study comparing fixed vs adaptive windowing schemes across misuse categories

### Open Question 4
- Question: How does GAVEL's performance scale as the CE vocabulary expands from 23 elements to hundreds or thousands of community-contributed elements?
- Basis: Paper acknowledges key design challenge about CE granularity vs rule complexity
- What evidence would resolve: Evaluation of classifier accuracy, inference latency, and rule specificity with large CE vocabularies

## Limitations
- Cross-model generalization requires retraining CE detector for each model family
- System remains vulnerable to CE-level jailbreaks where attackers evade detection
- Effectiveness fundamentally depends on quality of CE definitions and completeness of vocabulary

## Confidence
- **CE Detection Performance (TPR >98%, near-zero FPR):** High confidence - supported by extensive ablation studies
- **Rule-Based Precision Improvement:** High confidence - demonstrated through compositional rule evaluation
- **Model-Agnostic Design:** Medium confidence - validated on two model families but limited cross-architecture testing
- **Runtime Efficiency:** Medium confidence - claimed but not extensively benchmarked with absolute timing data

## Next Checks
1. Cross-Architecture Transfer Test: Train CE detectors on Mistral-7B and evaluate on completely different architectures (GPT-2, OPT, BLOOM)
2. Adversarial Attack Simulation: Systematically test for CE-level jailbreaks by having red teams attempt to bypass detection
3. Real-World Deployment Benchmark: Deploy GAVEL in production setting and measure actual runtime overhead and false positive rates