---
ver: rpa2
title: 'Readability $\ne$ Learnability: Rethinking the Role of Simplicity in Training
  Small Language Models'
arxiv_id: '2510.13915'
source_url: https://arxiv.org/abs/2510.13915
tags:
- start
- they
- readability
- lily
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Recent studies suggest that very small language models (SLMs)\
  \ can generate surprisingly coherent text when trained on simplified, child-directed\
  \ corpora such as TinyStories. These findings have been interpreted as evidence\
  \ that readability\u2014characterized by accessible vocabulary, familiar narrative\
  \ structure, and simple syntax\u2014plays a key role in enabling such capabilities\
  \ to emerge."
---

# Readability $\ne$ Learnability: Rethinking the Role of Simplicity in Training Small Language Models

## Quick Facts
- **arXiv ID:** 2510.13915
- **Source URL:** https://arxiv.org/abs/2510.13915
- **Reference count:** 40
- **Primary result:** Readability alone does not predict coherence or learning efficiency in small language models; statistical simplicity, measured by n-gram diversity, is a stronger predictor of learnability.

## Executive Summary
Recent studies suggest that very small language models can generate surprisingly coherent text when trained on simplified, child-directed corpora. This has been interpreted as evidence that readability plays a key role in enabling such capabilities. In this paper, the authors challenge that interpretation by constructing synthetic datasets with matched structure but varied readability. They find that readability alone does not predict coherence or learning efficiency; instead, statistical simplicity, as measured by n-gram diversity, is a stronger predictor. Models trained on complex, adult-level text perform comparably to those trained on simplified language and can even develop coherence faster during training. The findings caution against anthropomorphizing language model training and call for more precise reasoning about what properties actually support capability emergence in small models.

## Method Summary
The authors generate synthetic datasets using Llama-3.1-8B-Instruct with controlled readability (child-friendly vs. GRE-level vocabulary) and train small transformer models (262K–33M parameters) from scratch. They evaluate coherence using Llama-3.1-70B-Instruct as a judge and measure n-gram diversity, learnability ratio (output coherence / train data coherence), and n-gram novelty to distinguish memorization from recombination. Training runs for 10 epochs on 1B-token datasets, with 1000 completions per model evaluated in-distribution and cross-distribution.

## Key Results
- Readability (as measured by vocabulary and syntax) does not predict coherence or learning efficiency in small language models.
- Statistical simplicity (low n-gram diversity) is a stronger predictor of in-distribution coherence emergence.
- Models trained on complex-but-statistically-simple text can achieve high coherence faster than those trained on simple-vocabulary text.
- High in-distribution coherence from statistically simple data does not translate to robust out-of-distribution performance.

## Why This Works (Mechanism)

### Mechanism 1: Statistical Simplicity Drives Learnability in SLMs
- **Claim:** Low n-gram diversity enables small models to achieve high in-distribution coherence more effectively than human-readable simplicity.
- **Mechanism:** SLMs have limited capacity to model complex distributions. Datasets with fewer unique n-grams present a narrower, more compressible token-sequence distribution, reducing the hypothesis space the model must navigate.
- **Core assumption:** Coherence scores measured by LLM-as-a-judge accurately reflect meaningful text quality.
- **Evidence anchors:** Inverse correlation between learnability ratio and unique 3-gram counts (Figure 4a).
- **Break condition:** If a more sophisticated measure of distributional complexity disconfirms n-gram diversity as the key predictor.

### Mechanism 2: Rapid Coherence Emergence from Complex, Statistically Simple Text
- **Claim:** Models trained on text with complex vocabulary but low n-gram diversity can achieve high coherence faster during training than models trained on simple-vocabulary, child-directed text.
- **Mechanism:** Low n-gram diversity means fewer distinct sequence patterns to learn, allowing the model to quickly capture repetitive structural templates.
- **Core assumption:** Template-based generation produces text with inherent structural regularity that is easier to statistically model than it appears to human readers.
- **Evidence anchors:** LlamaTales-GRE models surpassing coherence score 85 after first epoch, while TinyStories models have a steeper learning curve (Figure 4b).
- **Break condition:** If vocabulary complexity introduces optimization noise that slows convergence.

### Mechanism 3: Generalization Failure from Narrow Distributional Learning
- **Claim:** High in-distribution coherence from statistically simple training data does not translate to robust out-of-distribution performance.
- **Mechanism:** The model learns to exploit high-probability n-gram sequences and structural templates specific to its narrow training distribution, failing to generalize to novel prompts.
- **Core assumption:** Observed n-gram novelty in generations indicates genuine pattern recombination within the learned narrow distribution.
- **Evidence anchors:** Performance degradation when models are tested on prompts from other datasets (Figure 3).
- **Break condition:** If training on a mixture of multiple statistically simple synthetic distributions yields SLMs with robust cross-distribution coherence.

## Foundational Learning

- **Concept: N-gram Diversity as Statistical Simplicity Proxy**
  - **Why needed here:** This is the paper's core predictive metric; understanding that fewer unique n-grams = a more repetitive, compressible, and statistically simple dataset is essential for grasping the main findings.
  - **Quick check question:** Why would a dataset with fewer unique 3-gram sequences be easier for a small model to learn from, even if its individual words are complex?

- **Concept: Disentangling Readability from Statistical Learnability**
  - **Why needed here:** The paper's central argument; readability is a human-centric property, while statistical learnability is a model-centric property. Conflating them leads to incorrect causal attributions.
  - **Quick check question:** According to the paper, why is it a mistake to assume that because TinyStories works well for SLMs, all "simple" human-readable text will be equally effective?

- **Concept: The Learnability Ratio (Output Coherence / Train Data Coherence)**
  - **Why needed here:** This operationalizes how well a model captures the "coherence potential" of its training data; a ratio near 1.0 means the model's output matches the coherence level of the data it was trained on.
  - **Quick check question:** A model trained on a dataset with a coherence score of 90 produces outputs with a coherence score of 60. What is its learnability ratio, and what does this suggest about the dataset's statistical properties?

## Architecture Onboarding

- **Component Map:** Template-based generators (Llama-3.1-8B-Instruct) → Controlled-vocabulary prompts → Synthetic datasets (LlamaTales-Jr/GRE/variants) → Small-scale transformers (262K–33M params) → LLM-as-a-Judge (Llama-3.1-70B-Instruct) → N-gram diversity and novelty analysis

- **Critical Path:** Define target n-gram diversity and readability via prompt engineering → Generate ~1B token training corpus → Train SLMs for 10 epochs (10B tokens total) → Evaluate in-distribution and cross-distribution coherence at multiple checkpoints

- **Design Tradeoffs:**
  - **Low N-gram Diversity vs. Generalization:** Optimize for learnability by minimizing diversity, but risk creating a narrow model that fails on real-world data.
  - **Template Rigidity vs. Text Variety:** Strict templates ensure statistical simplicity but may reduce text diversity; looser templates increase diversity but may harm learnability.
  - **LLM-as-Judge Scale:** Using a 70B judge is expensive but correlates best with human judgment; smaller judges are cheaper but noisier.

- **Failure Signatures:**
  1. **Memorization, not Learning:** Output n-grams show near-zero novelty relative to training set.
  2. **In-Distribution Overfitting:** High coherence on prompts from training distribution, near-random coherence on any other prompts.
  3. **Metric Gaming:** The SLM learns to exploit specific phrases or structures that artificially inflate the LLM-judge's coherence score without genuine narrative flow.

- **First 3 Experiments:**
  1. **Diversity Control:** Generate two datasets with identical readability prompts but different template repetition levels to measure the direct impact of n-gram diversity on learnability ratio.
  2. **Generalization Probe:** Train on a 50/50 mix of LlamaTales-Jr and LlamaTales-GRE, then evaluate coherence on prompts from both, as well as a held-out third domain (e.g., LlamaTales-News).
  3. **Novelty Analysis:** For the best-performing SLM, systematically vary the novelty of test prompts (measured by n-gram overlap with train) and plot the coherence degradation curve to quantify the fragility of the learned distribution.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can richer, more comprehensive measures of dataset complexity and learnability be developed beyond simple n-gram diversity?
- **Basis in paper:** [explicit] The authors explicitly state that n-gram diversity is a simple proxy and call for "developing richer, more comprehensive measures... beyond simple n-grams."
- **Why unresolved:** The paper establishes n-grams as a strong predictor but suggests they likely capture only one facet of a broader set of properties (e.g., compressibility, structural consistency).
- **What evidence would resolve it:** The creation and validation of a complexity metric that correlates with learnability more accurately than n-gram diversity across varied natural and synthetic corpora.

### Open Question 2
- **Question:** What training curricula or data selection strategies can leverage statistical simplicity without sacrificing generalization capabilities?
- **Basis in paper:** [explicit] The authors list "designing training curricula... that leverage statistical simplicity without sacrificing generalization" as a key direction for future work.
- **Why unresolved:** The results show that statistical simplicity enables high in-distribution coherence but leads to brittle models that fail to generalize beyond their narrow training distribution.
- **What evidence would resolve it:** A training methodology that maintains the learning efficiency of statistically simple data while achieving robust performance on out-of-distribution tasks.

### Open Question 3
- **Question:** How can evaluation methods effectively disentangle genuine linguistic capabilities from pattern matching facilitated by statistically simple data structures?
- **Basis in paper:** [explicit] The authors explicitly call for "creating evaluation methods that effectively disentangle genuine capabilities from pattern matching."
- **Why unresolved:** The paper demonstrates that high coherence scores can arise from simple statistical recombination rather than robust understanding, making standard metrics potentially misleading.
- **What evidence would resolve it:** New evaluation protocols or metrics that penalize outputs derived from narrow statistical pattern matching and reward structural generalization.

## Limitations

- The study focuses exclusively on template-generated synthetic data, which may not reflect the statistical properties of natural text distributions.
- Evaluation relies entirely on LLM-as-a-judge coherence scoring, which may be biased toward the repetitive structures present in synthetic corpora.
- The claim that "readability ≠ learnability" is demonstrated within the narrow context of controlled generation and may not extend to naturally occurring simplified text.

## Confidence

- **High confidence:** The inverse relationship between n-gram diversity and learnability ratio, and the faster coherence emergence from complex-but-simple text.
- **Medium confidence:** The claim that readability alone does not predict learnability, given the synthetic nature of the data.
- **Medium confidence:** The generalization failure findings, pending broader distribution testing.

## Next Checks

1. **Natural Data Validation:** Train small models on naturally occurring simplified text (e.g., children's books, educational materials) and compare coherence emergence to models trained on adult-level text matched for n-gram diversity.

2. **Alternative Statistical Measures:** Replicate the learnability experiments using alternative complexity metrics such as entropy rate, perplexity, or compressibility to verify that n-gram diversity is the key driver rather than a correlated proxy.

3. **Robustness Benchmarking:** Systematically evaluate the best-performing models on a diverse suite of out-of-distribution prompts (different domains, styles, and coherence patterns) to quantify the generalization limits and test whether mixed-distribution training mitigates the observed brittleness.