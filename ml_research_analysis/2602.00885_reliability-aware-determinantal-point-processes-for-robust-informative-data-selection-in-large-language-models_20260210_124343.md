---
ver: rpa2
title: Reliability-Aware Determinantal Point Processes for Robust Informative Data
  Selection in Large Language Models
arxiv_id: '2602.00885'
source_url: https://arxiv.org/abs/2602.00885
tags:
- selection
- data
- probdpp
- reliability-aware
- stochastic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of robust informative data selection
  for large language models (LLMs) under stochastic data availability. Traditional
  subset selection methods like Determinantal Point Processes (DPP) assume error-free
  data access, but in practice, data batches can be lost due to storage outages, communication
  errors, or tool failures.
---

# Reliability-Aware Determinantal Point Processes for Robust Informative Data Selection in Large Language Models

## Quick Facts
- **arXiv ID**: 2602.00885
- **Source URL**: https://arxiv.org/abs/2602.00885
- **Reference count**: 27
- **Primary result**: Introduces ProbDPP, a reliability-aware DPP formulation that achieves up to 36% gains in Exact Match and 13.5% in BERTScore on MeetingBank by explicitly accounting for stochastic data availability.

## Executive Summary
This paper addresses the challenge of robust informative data selection for large language models (LLMs) under stochastic data availability. Traditional subset selection methods like Determinantal Point Processes (DPP) assume error-free data access, but in practice, data batches can be lost due to storage outages, communication errors, or tool failures. The authors show that directly incorporating unreliability into the DPP objective leads to an ill-posed problem where the expected log-determinant diverges to negative infinity when any selected unit has a non-zero failure probability. To address this, the authors introduce ProbDPP, a reliability-aware DPP formulation that adds a regularization term to restore well-posedness, enabling principled subset selection under probabilistic data access with known success probabilities.

## Method Summary
ProbDPP solves the subset selection problem under stochastic data availability by adding regularization to the DPP objective, creating a well-posed optimization that decomposes into diversity and reliability terms. For unknown reliabilities, it uses a KL-UCB combinatorial semi-bandit algorithm to learn reliability online. The method operates on unit-norm embeddings to construct a Gram matrix, then selects subsets that balance diversity (measured by log-determinant) with reliability (additive per-item term). Experiments demonstrate consistent improvements over baselines on MeetingBank and HotpotQA datasets using an LLM (llama3) for downstream evaluation.

## Key Results
- On MeetingBank: ProbDPP achieves 31.3 Token-F1, 31.2 ROUGE-L, 36.9 BERTScore, and 19.4 Exact Match, with gains of 13.5% in BERTScore and 36% in Exact Match over the best baseline
- On HotpotQA: ProbDPP achieves 34.14 Token-F1 and 34.14 ROUGE-L with K=3, outperforming both reliability-only and diversity-only baselines by 9.4% and 3.9% respectively
- Theoretical regret bound of O(log T) for the KL-UCB-based online learning algorithm under Bernoulli outcomes

## Why This Works (Mechanism)

### Mechanism 1: Regularization Rescues the Ill-Posed Objective
The naive expected log-determinant under Bernoulli dropouts diverges to −∞; adding ε-regularization restores well-posedness. When any selected unit fails (z_i,t = 0), the masked kernel Σ_{L,L}(z_t) becomes singular with log det = −∞. Since E[log det] includes this event with probability (1 − α_i) > 0, the expectation is unbounded. Regularization via W_L(z_t) = M_L(z_t) + εI ensures the kernel remains positive definite even with dropouts.

### Mechanism 2: Exact Decomposition Separates Diversity from Reliability
The regularized objective D_ε(L) decomposes into a pure diversity term plus an additive per-item reliability reward. Using Cholesky decomposition G_{L,L} = R_L R_L^⊤ and properties of determinants, the expected log-det becomes log det(G_{L,L}) + Σ_{i∈L} r_i(α_i, ε), where r_i(α, ε) = 2[α log(1 + ε) + (1 − α) log ε]. This separates the combinatorial diversity structure from reliability estimation.

### Mechanism 3: KL-UCB Optimism for Online Reliability Learning
A UCB-style algorithm with KL-divergence confidence bounds achieves O(log T) regret for subset selection with unknown reliabilities. At each round, construct optimistic reliability bounds U_α^i(t) via KL-UCB, map to optimistic coefficients θ̃_i(t) = r_i(U_α^i(t), ε), and select S_t = argmax_{|S|=K} {log det(G_{S,S}) + Σ_{i∈S} θ̃_i(t)}. Semi-bandit feedback updates α̂_i(t) from observed successes.

## Foundational Learning

- **Concept**: Determinantal Point Processes (DPPs) and k-DPP
  - **Why needed here**: Core mathematical object for diversity-aware subset selection; log-determinant measures volume spanned by selected embeddings
  - **Quick check question**: Given a 3×3 Gram matrix G with eigenvalues [2, 1, 0.5], what is log det(G) for the full set?

- **Concept**: Combinatorial Semi-Bandits
  - **Why needed here**: The online learning formulation requires selecting K items per round and observing individual outcomes; understanding the semi-bandit structure is essential
  - **Quick check question**: How does semi-bandit feedback differ from full-bandit feedback in a K=3 selection problem?

- **Concept**: KL-UCB Confidence Bounds
  - **Why needed here**: The algorithm uses KL-divergence-based optimism for Bernoulli parameters; understanding why KL-UCB is optimal for Bernoulli arms clarifies the regret analysis
  - **Quick check question**: Why is KL-UCB preferred over Hoeffding-based UCB for Bernoulli rewards?

## Architecture Onboarding

- **Component map**: Input layer (N candidates with embeddings) -> Gram matrix construction (G_{ij} = ⟨f_i, f_j⟩) -> Reliability estimator (maintains (n_i(t), α̂_i(t))) -> KL-UCB bound computation (U_α^i(t)) -> Objective optimizer (solves max_{|S|=K} {log det(G_{S,S}) + Σ_{i∈S} r̃_i(t)}) -> Feedback collector (observes {z_i,t : i ∈ S_t})

- **Critical path**: The selection step (objective optimizer) is the computational bottleneck; requires either exact k-DPP inference or greedy approximation. For large N, use greedy selection with O(NK^2) complexity per round.

- **Design tradeoffs**:
  - ε selection: Small ε → better sensitivity to reliability differences but potential numerical instability; large ε → stable but may overwhelm reliability term
  - Exploration constant c: Controls exploration-exploitation balance; larger c increases exploration but slows convergence
  - Greedy vs. exact k-DPP: Greedy is faster but may be suboptimal; exact is exponential in K

- **Failure signatures**:
  - All selections unreliable: If α_i ≈ 0 for most items, the reliability term dominates and diversity is ignored
  - Numerical underflow in log-det: If G has near-zero eigenvalues, log det may underflow; add ridge δI to G before computation
  - Regret plateauing: If E[Reg_T] stops decreasing, check if α_i estimates have converged to incorrect values due to biased sampling

- **First 3 experiments**:
  1. Synthetic validation: Generate N=20 items with known α_i ∈ {0.3, 0.5, 0.7, 0.9} and 2D embeddings; run ProbDPP for T=1000 rounds; verify regret scales as O(log T) and α̂_i(t) → α_i
  2. Ablation on ε: On MeetingBank subset, vary ε ∈ {0.01, 0.1, 1.0} with fixed dropout rate α=0.3; measure Token-F1 and BERTScore to find stability-sensitivity sweet spot
  3. Greedy vs. exact comparison: For small N=15, K=3, compare greedy selection against exact k-DPP enumeration; quantify performance gap and runtime difference

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can ProbDPP be extended to handle correlated or adversarial failure patterns rather than independent Bernoulli dropouts?
- Basis in paper: [explicit] "Our analysis assumes independent data dropout, capturing random unavailability but not structured failures such as correlated or adversarial outages; extending ProbDPP to these settings is an important future direction to pursue."
- Why unresolved: The current decomposition relies on independence; correlation breaks the additive reliability term structure and requires new analysis.
- What evidence would resolve it: A modified ProbDPP formulation with regret bounds under correlated failure models (e.g., block failures, adversarial deletions).

### Open Question 2
- Question: Can reliability-aware selection achieve similar guarantees when only aggregate (non-per-item) feedback is available?
- Basis in paper: [explicit] "Our online setting assumes semi-bandit per-item feedback, while some systems observe only aggregate output quality, motivating bandit extensions for end-to-end feedback."
- Why unresolved: Without per-item outcomes, estimating individual reliabilities becomes an inverse problem; standard UCB-style counting arguments do not apply.
- What evidence would resolve it: A bandit algorithm using only aggregate reward signals with theoretical regret analysis or empirical validation on aggregate-feedback benchmarks.

### Open Question 3
- Question: Does adaptive selection of the regularization parameter ε yield provably better robustness-utility trade-offs than fixed ε?
- Basis in paper: [explicit] "The parameter ε governs a stability–sensitivity trade-off; although a fixed value performs well empirically, adaptive selection could further improve robustness."
- Why unresolved: The relationship between ε, failure rates, and downstream performance is not characterized; no adaptive scheme is proposed.
- What evidence would resolve it: An adaptive ε schedule with analysis showing improved regret or empirical gains across varying failure regimes.

## Limitations
- The method assumes independent Bernoulli dropouts, which may not capture correlated or adversarial failure patterns in real-world systems
- Performance is tightly coupled to the quality of unit-norm embeddings, which are not specified in the paper
- The KL-UCB regret analysis assumes stationary Bernoulli reliabilities, which may not hold in dynamic environments with drifting reliability

## Confidence
- **High**: The decomposition mechanism and its formal proof; the divergence result under independent dropouts; the KL-UCB regret bound for Bernoulli bandits
- **Medium**: The practical effectiveness on MeetingBank and HotpotQA; the exact impact of ε selection; the robustness to correlated failures
- **Low**: Generalization to non-stationary reliabilities; performance with alternative embedding models; scalability beyond small N and K

## Next Checks
1. **ε sensitivity analysis**: Run ablation experiments across ε ∈ {0.01, 0.1, 1.0} on MeetingBank to quantify performance tradeoffs and identify numerical stability thresholds
2. **Embedding robustness test**: Replace the unspecified embedding model with alternatives (e.g., sentence-transformers, CLIP) and measure impact on Gram matrix conditioning and selection quality
3. **Non-stationary reliability simulation**: Implement a version of ProbDPP where α_i(t) drifts over time; compare regret growth and estimation accuracy against the stationary assumption