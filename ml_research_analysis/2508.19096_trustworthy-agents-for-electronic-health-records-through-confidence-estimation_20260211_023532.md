---
ver: rpa2
title: Trustworthy Agents for Electronic Health Records through Confidence Estimation
arxiv_id: '2508.19096'
source_url: https://arxiv.org/abs/2508.19096
tags:
- confidence
- clinical
- reliability
- estimation
- trustehragent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of deploying large language
  models (LLMs) in clinical settings by proposing a novel framework for trustworthy
  Electronic Health Record (EHR) question answering. The authors introduce Hallucination-Controlled
  Accuracy at k% (HCAcc@k%), a new evaluation metric that quantifies the accuracy-reliability
  trade-off at varying confidence thresholds.
---

# Trustworthy Agents for Electronic Health Records through Confidence Estimation

## Quick Facts
- arXiv ID: 2508.19096
- Source URL: https://arxiv.org/abs/2508.19096
- Reference count: 30
- One-line primary result: TrustEHRAgent achieves 44.23%p and 25.34%p improvements over baselines at HCAcc@70% while baseline methods fail completely at this threshold

## Executive Summary
This paper addresses the challenge of deploying large language models (LLMs) in clinical settings by proposing a novel framework for trustworthy Electronic Health Record (EHR) question answering. The authors introduce Hallucination-Controlled Accuracy at k% (HCAcc@k%), a new evaluation metric that quantifies the accuracy-reliability trade-off at varying confidence thresholds. They also develop TrustEHRAgent, a confidence-aware agent that incorporates step-wise confidence estimation for clinical query resolution. Experiments on MIMIC-III and eICU datasets demonstrate that TrustEHRAgent significantly outperforms baseline methods under strict reliability constraints while maintaining competitive performance in traditional accuracy settings.

## Method Summary
TrustEHRAgent builds upon a code-based reasoning framework (EHRAgent) by adding step-wise confidence estimation and a final confidence estimator. The agent generates Python code/SQL solutions for clinical queries while verbalizing confidence scores (0-10) at each reasoning step. These step-wise scores are aggregated and fed to a Confidence Estimator LLM, which produces a final confidence score between 0-1 using weighted token log-probabilities. The system applies a threshold τ to either output the answer or reject the query, trading coverage for reliability. The framework is evaluated on EHRSQL-derived QA datasets from MIMIC-III and eICU using the novel HCAcc@k% metric.

## Key Results
- TrustEHRAgent achieves 44.23%p and 25.34%p improvements over baselines at HCAcc@70% while baseline methods fail completely at these thresholds
- The agent maintains competitive performance in traditional accuracy settings, showing 3.16%p and 6.72%p improvements over original EHRAgent at HCAcc@0%
- Step-wise confidence estimation proves critical, with ablation studies showing significant performance drops when disabled

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Injecting explicit verbalized confidence scores at intermediate reasoning steps improves the reliability of the final uncertainty estimate.
- **Mechanism:** The framework modifies the agent's reasoning loop by prompting it to self-rate confidence (0-10) at each step. These scores are aggregated into the "reasoning history," providing the final Confidence Estimator with granular signal about where uncertainty might have been introduced.
- **Core assumption:** LLMs can accurately critique their own intermediate reasoning quality, and this self-assessment correlates with the likelihood of a final correct answer.
- **Evidence anchors:** "confidence-aware agent that incorporates step-wise confidence estimation" [abstract]; "These scores reflect the data quality, query complexity, and interpretation ambiguity specific to each step..." [section 3.2]
- **Break condition:** If the agent hallucinates high confidence during a flawed reasoning step, the aggregated signal misleads the final estimator.

### Mechanism 2
- **Claim:** Using a weighted sum of token log-probabilities yields a more robust confidence signal than discrete integer scoring or binary classification.
- **Mechanism:** Instead of forcing the LLM to output a single confidence integer, the estimator extracts log-probabilities for tokens representing levels 0-4. It computes a weighted average ($C = \sum i \cdot P(S=i) / S_{max}$), effectively smoothing the confidence score into a continuous spectrum.
- **Core assumption:** The internal probability distribution of the LLM is better calibrated and more granular than its top-1 decoded output.
- **Evidence anchors:** "we utilize token log-probabilities rather than direct discrete outputs... to achieve more fine-grained scoring" [section 3.2]; "Comparison shows weighted sum produces 'smooth performance curves' while discrete scoring 'fails to provide effective confidence estimation.'" [section 6.2]
- **Break condition:** If the LLM is systematically overconfident across all token options, the weighted average will merely reflect that bias rather than true uncertainty.

### Mechanism 3
- **Claim:** Enforcing a strict confidence threshold ($\tau$) enables a "reject" option that filters out low-confidence predictions, trading coverage for reliability.
- **Mechanism:** The system compares the final score $C$ against threshold $\tau$. If $C < \tau$, the agent outputs "reject" rather than an answer. By sweeping $\tau$, one controls the Hallucination Rate (HR), maximizing accuracy only within the subset of queries where the agent is sufficiently confident.
- **Core assumption:** Correct answers tend to have higher confidence scores than incorrect answers (separability), allowing a threshold to effectively filter errors.
- **Evidence anchors:** "...quantifying the accuracy-reliability trade-off at varying confidence thresholds." [abstract]; "When $C < \tau$, the agent rejects the query to prevent potential clinical errors." [section 3.3]
- **Break condition:** If the difficulty distribution shifts, the agent may reject almost all queries to maintain safety, rendering it operationally useless despite high theoretical reliability.

## Foundational Learning

- **Concept:** **Uncertainty Quantification (UQ) in NLP**
  - **Why needed here:** You cannot understand "Hallucination-Controlled Accuracy" without grasping that LLMs produce probability distributions, not facts. You must understand the difference between aleatoric uncertainty (data ambiguity) and epistemic uncertainty (model ignorance).
  - **Quick check question:** If a model predicts "Diagnosis A" with 51% probability and "Diagnosis B" with 49%, how should a high-reliability system handle this versus a standard classifier?

- **Concept:** **Selective Prediction (Abstention)**
  - **Why needed here:** The core contribution is an agent that learns to say "I don't know." This contrasts with standard evaluation (Accuracy @ 100% coverage).
  - **Quick check question:** Why does increasing the rejection threshold ($\tau$) generally increase Precision (Conditional Accuracy) but decrease Recall (Response Rate)?

- **Concept:** **Agentic Reasoning (ReACT/CoT)**
  - **Why needed here:** TrustEHRAgent builds on code-based reasoning chains. Understanding that an error in Step 1 cascades to Step 5 is vital for understanding why "Step-wise" estimation is proposed.
  - **Quick check question:** How does error propagation in a multi-step SQL generation chain differ from a single-shot classification error?

## Architecture Onboarding

- **Component map:** Base Agent (EHRAgent/GPT-4o-mini) -> Step-wise Confidence Scores -> Confidence Estimator (LLM) -> Scoring Module (weighted log-probabilities) -> Threshold Gate -> Output/Reject
- **Critical path:** The latency bottleneck is the sequential dependency: Base Agent execution -> Estimator LLM call -> Scoring. The rejection decision happens *after* the expensive reasoning is done (post-hoc filtering).
- **Design tradeoffs:**
  - **Safety vs. Utility:** Setting $\tau$ high (e.g., for HCAcc@70%) guarantees low hallucination but may result in the agent refusing to answer most questions (low Response Rate).
  - **Overhead:** Requires two LLM invocations per query (one for reasoning, one for confidence estimation).
- **Failure signatures:**
  - **Total Abstention:** At HCAcc@90%, the system collapses and answers almost nothing (Acc ~2-3%).
  - **Calibration Drift:** The model is consistently overconfident on out-of-distribution medical abbreviations, leading to false positives (passing the threshold while being wrong).
- **First 3 experiments:**
  1. **Ablation of Step-wise Signal:** Run TrustEHRAgent on MIMIC-III with the "step-wise confidence" prompt disabled. Compare HCAcc@70% drops to quantify the value of intermediate signals (Figure 4).
  2. **Threshold Calibration Curve:** Sweep $\tau$ from 0.0 to 1.0 on a validation set. Plot Response Rate vs. Hallucination Rate to visualize the operating envelope.
  3. **Method Comparison:** Replicate the comparison in Section 6.2: Replace the "Weighted Sum" scorer with a "Discrete Scorer" and observe if the performance curve becomes unstable or "sharp."

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can advanced calibration techniques (temperature scaling, ensemble methods, Bayesian calibration) improve the accuracy-reliability trade-off at stringent thresholds (HCAcc@≥90%) compared to the current weighted log-probability approach?
- Basis in paper: [explicit] The limitations section states: "Our current weighted log probability approach, while effective, could benefit from more sophisticated calibration techniques. Future work should explore methods such as temperature scaling, ensemble approaches, or Bayesian calibration."
- Why unresolved: Only weighted log-probability was evaluated; no comparative analysis of calibration methods was conducted at high reliability thresholds.
- What evidence would resolve it: Systematic comparison showing HCAcc@90% improvements with alternative calibration techniques on MIMIC-III/eICU.

### Open Question 2
- Question: How well does TrustEHRAgent generalize to diverse EHR systems, healthcare institutions, and clinical query types beyond the evaluated datasets?
- Basis in paper: [explicit] The limitations acknowledge that MIMIC-III and eICU "may not fully represent the diversity of real-world clinical settings, patient populations, or EHR systems" and that 580 question-answer pairs "might not capture the full spectrum of clinical queries."
- Why unresolved: Evaluation was limited to two specific ICU datasets with constrained query diversity.
- What evidence would resolve it: Performance benchmarks on additional EHR systems (e.g., Epic, Cerner) with broader query types and diverse patient populations.

### Open Question 3
- Question: What is the impact of using different backbone LLMs or multi-model ensembles on confidence estimation quality and HCAcc@k% performance?
- Basis in paper: [inferred] All experiments used only GPT-4.1-mini with temperature 0.0; no analysis of model architecture effects on confidence calibration was provided.
- Why unresolved: Confidence estimation may be model-dependent, and calibration quality could vary across different LLM families.
- What evidence would resolve it: Comparative study across multiple LLM backbones (e.g., Claude, Llama, Gemini) using identical experimental conditions.

## Limitations
- **Missing Implementation Details:** The paper lacks exact base agent prompt templates, 4-shot demonstrations, and tool definitions needed for faithful reproduction.
- **Clinical Validation Gap:** All experiments use synthetic EHRSQL-derived datasets rather than direct evaluation on real clinical workflows and actual EHR systems.
- **Calibration Reliability Uncertainty:** The framework's confidence estimation reliability across different medical subdomains and novel clinical terminology remains untested.

## Confidence
- **High Confidence:** The novel HCAcc@k% metric and its demonstration as superior to traditional accuracy for evaluating healthcare AI agents under reliability constraints.
- **Medium Confidence:** The effectiveness of step-wise confidence estimation mechanism and weighted token log-probability scoring.
- **Low Confidence:** The generalizability of these findings to broader clinical applications and different EHR systems.

## Next Checks
1. **Prompt and Tool Reproducibility Audit:** Obtain and verify the exact base agent prompt template, 4-shot demonstrations, and tool definitions from the authors. Implement the complete system and reproduce HCAcc@70% performance within ±2% margin on MIMIC-III dataset.

2. **Calibration Stability Analysis:** Evaluate TrustEHRAgent across multiple clinical subdomains (cardiology, neurology, oncology questions) within the same dataset. Measure whether confidence scores remain well-calibrated and whether rejection rates become domain-dependent.

3. **External Clinical Validation:** Test the framework on an independent clinical dataset with different EHR schema or question patterns. Compare performance degradation relative to the original datasets and assess whether the confidence estimation mechanism generalizes to new clinical contexts.