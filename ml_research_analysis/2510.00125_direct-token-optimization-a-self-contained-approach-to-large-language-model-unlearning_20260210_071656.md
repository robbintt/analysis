---
ver: rpa2
title: 'Direct Token Optimization: A Self-contained Approach to Large Language Model
  Unlearning'
arxiv_id: '2510.00125'
source_url: https://arxiv.org/abs/2510.00125
tags:
- unlearning
- forget
- tokens
- utility
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper introduces Direct Token Optimization (DTO), a self-contained
  method for unlearning fine-tuned large language models without external resources
  like auxiliary models, retain datasets, or commercial AI services. DTO identifies
  two types of tokens in a forget set: target tokens that encode critical knowledge
  for unlearning and non-target tokens that preserve model utility.'
---

# Direct Token Optimization: A Self-contained Approach to Large Language Model Unlearning

## Quick Facts
- **arXiv ID:** 2510.00125
- **Source URL:** https://arxiv.org/abs/2510.00125
- **Reference count:** 12
- **Primary result:** Achieves up to 16.8× improvement in forget quality compared to state-of-the-art baselines

## Executive Summary
Direct Token Optimization (DTO) introduces a novel self-contained method for unlearning specific knowledge from fine-tuned large language models without requiring external resources like auxiliary models, retain datasets, or commercial AI services. The approach identifies and optimizes two distinct types of tokens within a forget set: target tokens that encode critical knowledge for unlearning, and non-target tokens that preserve model utility. Through a combination of delta-score metric for target token identification and KL-divergence optimization for non-target tokens, DTO achieves state-of-the-art performance on forget quality while maintaining linguistic fluency and model utility.

## Method Summary
DTO operates by first identifying target tokens that encode critical knowledge to be unlearned using a delta-score metric that measures the impact of prefix token perturbations on suffix generation. These target tokens are then optimized via gradient ascent to reduce their influence on model outputs. Non-target tokens, which preserve model utility, are optimized to minimize KL-divergence with the original model's outputs. This dual optimization strategy allows DTO to achieve selective forgetting while maintaining overall model performance. The method is evaluated on the TOFU and MUSE benchmarks, demonstrating significant improvements over existing approaches like FLAT and DELM.

## Key Results
- Achieves up to 16.8× improvement in forget quality compared to state-of-the-art baselines
- On Llama-2-7B with 1% forget set, DTO achieved forget quality of 0.918 versus 0.054 for FLAT
- Maintains model utility while effectively removing specified knowledge

## Why This Works (Mechanism)
DTO works by leveraging the token-level granularity of language models to selectively modify knowledge representations. By distinguishing between target tokens (which encode the knowledge to be forgotten) and non-target tokens (which preserve utility), the method can apply different optimization strategies to each type. Target tokens are pushed away from their current values through gradient ascent, reducing their influence on model outputs, while non-target tokens are optimized to maintain similarity with the original model through KL-divergence minimization. This targeted approach allows for precise control over what knowledge is removed while preserving overall model functionality.

## Foundational Learning
- **Token-level optimization:** Understanding how individual tokens contribute to knowledge representation in LLMs; needed to implement the selective modification approach
- **Delta-score metric:** A measure of token influence on model outputs; required for identifying which tokens encode target knowledge
- **KL-divergence optimization:** Technique for maintaining similarity between original and modified models; essential for preserving utility
- **Gradient ascent for token modification:** Method for systematically adjusting token values; critical for the unlearning process
- **Target/non-target token separation:** The conceptual framework that enables selective forgetting; fundamental to DTO's approach
- **Model utility preservation:** The goal of maintaining performance while removing knowledge; guides the optimization strategy

## Architecture Onboarding

### Component Map
Input sequence → Token identification (delta-score) → Target token optimization (gradient ascent) → Non-target token optimization (KL-divergence) → Output sequence

### Critical Path
1. Token identification via delta-score computation
2. Target token gradient ascent optimization
3. Non-target token KL-divergence optimization

### Design Tradeoffs
- **Self-contained vs. external resources:** DTO eliminates dependency on auxiliary models and datasets but may have higher computational requirements during optimization
- **Selective vs. wholesale forgetting:** The token-level approach enables precise control but requires careful token identification
- **Gradient-based vs. other optimization methods:** Gradient ascent provides systematic modification but may require careful hyperparameter tuning

### Failure Signatures
- Over-optimization of target tokens leading to complete knowledge removal rather than selective forgetting
- Insufficient KL-divergence minimization causing degradation in model utility
- Incorrect target/non-target token separation resulting in either incomplete forgetting or excessive utility loss

### First Experiments
1. Apply DTO to a simple fact-forgetting task (e.g., removing a single date) to verify basic functionality
2. Test on a mixed-knowledge prompt to evaluate the target/non-target separation capability
3. Measure performance degradation on general language tasks to assess utility preservation

## Open Questions the Paper Calls Out
- How the delta-score metric performs across diverse knowledge domains
- Whether the 120-220 token guidance for target token identification translates to consistent performance across different model sizes and architectures
- If the assumption of clean separation between target and non-target tokens holds for complex or interleaved knowledge representations

## Limitations
- Delta-score metric may not be robust across all knowledge domains
- Token separation assumption may not hold for complex knowledge representations
- Scalability to very large models or extremely long sequences requires further optimization

## Confidence
- **High confidence** in method's ability to improve forget quality metrics on tested benchmarks
- **Medium confidence** in generalizability of target/non-target token separation across different knowledge types
- **Medium confidence** in preservation of utility, depending on evaluation metrics and tasks
- **Low confidence** in scalability to very large models or long sequences without further optimization

## Next Checks
1. Test DTO on forgetting tasks involving multiple interleaved knowledge domains to verify target/non-target separation under complex conditions
2. Evaluate the method on models significantly larger than Llama-2-7B (e.g., 70B+ parameters) to assess computational feasibility and performance scaling
3. Conduct ablation studies to quantify the contribution of each component (delta-score, KL-divergence optimization, token separation) to overall performance