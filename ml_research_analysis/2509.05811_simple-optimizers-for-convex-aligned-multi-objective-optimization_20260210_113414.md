---
ver: rpa2
title: Simple Optimizers for Convex Aligned Multi-Objective Optimization
arxiv_id: '2509.05811'
source_url: https://arxiv.org/abs/2509.05811
tags:
- lemma
- theorem
- holds
- amoo
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the convex Aligned Multi-Objective Optimization
  (AMOO) setting, relaxing the strong convexity assumption commonly used in prior
  work. The authors introduce a new metric, the Maximum Gap (MG), to measure convergence
  in this setting.
---

# Simple Optimizers for Convex Aligned Multi-Objective Optimization

## Quick Facts
- arXiv ID: 2509.05811
- Source URL: https://arxiv.org/abs/2509.05811
- Reference count: 40
- Authors: Ben Kretzu; Karen Ullrich; Yonathan Efroni
- Primary result: Proposes MG-AMOO, a meta-algorithm using any single-objective optimizer to solve convex AMOO problems, achieving faster convergence than equal-weight methods without PAMOO's computational overhead

## Executive Summary
This paper studies Aligned Multi-Objective Optimization (AMOO) under convexity rather than strong convexity, introducing a new metric called Maximum Gap (MG) to measure convergence when unique optima don't exist. The authors prove that naive equal-weight approaches suffer polynomial degradation in the number of objectives, and propose MG-AMOO - a meta-algorithm that selects the objective with largest gap and applies any single-objective optimizer to it. Experiments show MG-AMOO achieves faster convergence than equal-weight methods while maintaining low computational cost compared to PAMOO.

## Method Summary
The paper proposes MG-AMOO, a meta-algorithm that reduces AMOO to single-objective optimization by selecting the objective with the largest gap (f_i(x) - f*_i) at each iteration and applying a standard optimizer to that objective. The method works with any single-objective optimizer (SGD, Adam, Polyak step-size) and provides convergence guarantees for both G-Lipschitz and β-smooth convex functions. The key innovation is the Maximum Gap metric, which measures worst-case suboptimality across all objectives and enables convergence measurement without requiring strong convexity or unique optima.

## Key Results
- Proves EW suffers Ω(√m) dependence on number of objectives
- MG-AMOO achieves O(1/√K) for G-Lipschitz and O(1/K) for smooth functions, independent of m
- Empirical results show MG-AMOO outperforms EW and approaches PAMOO performance on network distillation tasks
- MG-AMOO maintains O(m) per-iteration cost while PAMOO requires O(nm²)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Maximum Gap (MG) metric enables convergence measurement without unique optima.
- Mechanism: When strong convexity is relaxed, the optimal set C* may contain multiple points, making ||x - x*|| meaningless. MG(x) = max_i(f_i(x) - f*_i) measures worst-case suboptimality across all objectives. Under alignment, all objectives share at least one minimizer, so MG(x) → 0 indicates convergence to a point in C*.
- Core assumption: Objectives are aligned (non-empty C*); functions are convex and either G-Lipschitz or β-smooth.
- Evidence anchors:
  - [abstract] "This generalization requires new analytical tools and metrics to characterize convergence in the convex AMOO setting."
  - [section 4] "MG(x) := max_{i∈[m]} (f_i(x) - f*_i). The MG metric characterizes the worst-case convergence across all functions."
  - [corpus] Related work "Aligned Multi Objective Optimization" (Efroni et al., 2025) introduced AMOO under strong convexity; this paper extends to convex setting.

### Mechanism 2
- Claim: MG-AMOO reduces AMOO to single-objective optimization via max-gap selection.
- Mechanism: At each iteration, identify I(k) = argmax_i(f_i(x_k) - f*_i), then apply any single-objective optimizer to f_{I(k)}. Lemma 2 shows MG(x̄) ≤ (1/K) Σ_k [f_{I(k)}(x_k) - f*_{I(k)}], bounding the worst-case gap by average regret on selected functions. This enables black-box use of Online GD, Polyak, or standard GD.
- Core assumption: Access to optimal values {f*_i} (or estimates); the single-objective optimizer provides appropriate regret/decrease guarantees.
- Evidence anchors:
  - [abstract] "propose MG-AMOO, a meta-algorithm that uses any single-objective optimizer to solve AMOO problems"
  - [section 5.2] "Lemma 2 (Reduction: AMOO to Single-Objective Optimization)... MG(x̄) ≤ 1/K Σ_k [f_{I(k)}(x_k) - f*_{I(k)}]"
  - [corpus] "BINGO! Simple Optimizers Win Big" shows simple optimizers can be surprisingly effective when problem structure collapses - conceptually related to why max-gap selection suffices.

### Mechanism 3
- Claim: Equal-Weight (EW) suffers polynomial degradation in the number of objectives m.
- Mechanism: EW computes f_EW(x) = (1/m) Σ_i f_i(x) and applies standard GD. The lower bound (Theorem 1) constructs G-Lipschitz convex functions where MG(x̄) ∈ Ω(√m · G·||x₁ - x*|| / √K). The averaging dilutes gradient signal - progress on one objective can be offset by others.
- Core assumption: Functions are convex and G-Lipschitz; K ≤ m iterations.
- Evidence anchors:
  - [abstract] "prove a novel lower bound that demonstrates the suboptimality of naive equal-weight approaches"
  - [section 4, Theorem 1] "MG(x̄) ∈ Ω(√m·G·||x₁ - x*_EW|| / √K)"

## Foundational Learning

- Concept: **Convex vs. Strongly Convex Functions**
  - Why needed here: The key contribution is relaxing strong convexity (μ > 0, unique minimizer) to standard convexity. Without strong convexity, you cannot measure convergence as distance to a unique x*.
  - Quick check question: Given f(x) = x² and g(x) = |x|, which is strongly convex and which is merely convex?

- Concept: **Lipschitz Continuity and Smoothness**
  - Why needed here: Convergence rates differ for G-Lipschitz (O(1/√K)) vs. β-smooth (O(1/K)) functions. The paper provides separate guarantees for each class.
  - Quick check question: If ||∇f(x)|| ≤ 5 for all x, is f G-Lipschitz? What is G?

- Concept: **Online Learning Regret**
  - Why needed here: MG-AMOO with online learners relies on Regret(K)/K bounds. Understanding that sublinear regret (o(K)) implies vanishing average loss is essential.
  - Quick check question: If an online learner has Regret(K) = O(√K), what is the average regret bound after 10,000 iterations?

## Architecture Onboarding

- Component map:
  - EW Baseline -> O(m) per iteration (sum gradients) -> returns average iterate -> Simple but suffers √m dependence
  - PAMOO -> O(nm²) per iteration (Jacobian + QP) -> best convergence but expensive
  - MG-AMOO -> O(m) per iteration (find max-gap index) -> delegates to single-objective optimizer -> Matches EW cost with m-independent convergence

- Critical path:
  1. Verify alignment assumption exists (check if C* ≠ ∅ or C_ε ≠ ∅)
  2. Choose algorithm based on compute budget and m size
  3. Estimate or obtain {f*_i} values
  4. Implement max-gap selection loop
  5. Integrate with existing optimizer (SGD, Adam, or Polyak step-size)

- Design tradeoffs:
  - **PAMOO vs. MG-AMOO**: PAMOO achieves slightly better constants but requires Jacobian computation (O(nm²)) and solving a constrained QP each iteration. MG-AMOO matches EW's O(m) cost.
  - **Polyak vs. GD**: Polyak is adaptive (no learning rate tuning) but requires f* estimates. GD needs step-size tuning (η ≤ 1/β for smooth case).
  - **Online learner choice**: Any online algorithm with vanishing regret works; Online GD gives O(1/√K), more sophisticated methods may improve constants.

- Failure signatures:
  - **MG not decreasing**: Possible misalignment (C* = ∅) or incorrect {f*_i} estimates
  - **EW outperforming MG-AMOO**: Likely implementation bug in max-gap selection or step-size issues
  - **PAMOO numerically unstable**: QP solver issues; check Jacobian conditioning
  - **Divergence with Polyak**: f* estimates too optimistic (f* < actual minimum)

- First 3 experiments:
  1. **Synthetic validation**: Replicate the paper's P1-P3 experiments (network distillation with 3 losses) to verify MG-AMOO converges faster than EW and approaches PAMOO performance. Track MG(x) vs. iterations.
  2. **Scalability test**: Vary m ∈ {3, 10, 50, 100} on aligned quadratic objectives. Confirm EW degrades with √m while MG-AMOO rate is m-independent.
  3. **Approximate Alignment robustness**: Test on ε-approximate AMOO (objectives nearly but not perfectly aligned). Verify MG-AMOO converges to MG(x̄) ≤ ε + O(1/K) as Theorem 9 predicts.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the convergence guarantees for MG-AMOO be extended to stochastic or non-convex settings, which are more representative of deep learning practice?
- Basis in paper: [explicit] The conclusion states, "Neither our work nor prior efforts have explored the stochastic or non-convex AMOOO settings, which are important for practical applications."
- Why unresolved: The current theoretical analysis relies on convexity and deterministic gradients to bound the Maximum Gap (MG) metric, tools which do not directly transfer to non-convex loss landscapes or stochastic noise.
- What evidence would resolve it: Proofs of convergence for MG-AMOO in the non-convex setting (e.g., to a stationary point) or in the stochastic setting (e.g., in expectation), potentially requiring new metrics or bounds.

### Open Question 2
- Question: Do the theoretical advantages of MG-AMOO translate to empirical gains in large-scale domains such as computer vision, reinforcement learning, or LLM post-training?
- Basis in paper: [explicit] The authors state, "Further research should also include large-scale experiments on computer vision, reinforcement learning, or LLMs with multiple reward signals."
- Why unresolved: The paper's experiments are limited to synthetic or smaller-scale "teacher-student" neural network problems; it is unknown if the O(1/√K) convergence holds or matters in high-dimensional parameter spaces.
- What evidence would resolve it: Empirical benchmarks on standard large-scale multi-task datasets (e.g., Meta-World for RL or multi-reward alignment for LLMs) showing MG-AMOO outperforming Equal-Weight baselines in terms of the Maximum Gap metric.

### Open Question 3
- Question: Can AMOO algorithms be utilized as an initialization phase to improve the efficiency of finding Pareto-optimal solutions in general (potentially conflicting) Multi-Objective Optimization?
- Basis in paper: [explicit] The authors conjecture, "AMOO algorithms may benefit general multi-objective optimization by first identifying a strong common solution, followed by fine-tuning to satisfy specific trade-offs."
- Why unresolved: This proposed "identification then fine-tuning" paradigm is a conceptual contribution in the conclusion but has not been empirically or theoretically validated against standard MOO methods that start from random initialization.
- What evidence would resolve it: A study demonstrating that initializing a general MOO solver (like MGDA or gradient surgery) at the solution found by MG-AMOO leads to faster convergence to the Pareto front compared to random initialization.

## Limitations

- Requires access to optimal values {f*_i} or accurate estimates, which may be difficult to obtain in practice
- Relies on the alignment assumption (C* ≠ ∅), which is not empirically verified in experiments
- While O(m) per iteration, the need to compute all gaps f_i(x_k) - f*_i may create overhead for very large m

## Confidence

- **High Confidence**: Lower bound showing EW's √m dependence (Theorem 1), reduction from AMOO to single-objective optimization (Lemma 2), MG-AMOO's O(1/√K) and O(1/K) convergence rates
- **Medium Confidence**: Practical superiority of MG-AMOO over EW in real-world experiments, claim that MG-AMOO achieves "PAMOO-like convergence without computational overhead"
- **Low Confidence**: Performance on truly large-scale problems (m >> 3), robustness to approximate alignment (Theorem 9)

## Next Checks

1. **Alignment Verification**: Implement a diagnostic to verify C* ≠ ∅ or C_ε ≠ ∅ for the neural network objectives by checking gradient alignments or running EW for many iterations.

2. **Optimal Value Estimation**: Develop and validate methods for estimating f*_i in practice for the network distillation setting, as this is critical for the max-gap selection but not addressed in the paper.

3. **Scalability Benchmark**: Test MG-AMOO on synthetic problems with m ∈ {10, 50, 100} to empirically verify the claimed m-independence and identify any hidden scaling factors.