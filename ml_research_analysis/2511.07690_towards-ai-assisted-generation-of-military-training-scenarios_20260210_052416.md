---
ver: rpa2
title: Towards AI-Assisted Generation of Military Training Scenarios
arxiv_id: '2511.07690'
source_url: https://arxiv.org/abs/2511.07690
tags:
- scenario
- agent
- generation
- reasoning
- unit
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of automating complex military
  training scenario generation by introducing a multi-agent, multi-modal reasoning
  framework that leverages Large Language Models (LLMs). The framework decomposes
  scenario generation into subproblems and employs specialized LLM agents to address
  each, enabling both human-in-the-loop and fully automated generation of training
  artifacts like Operations Orders.
---

# Towards AI-Assisted Generation of Military Training Scenarios

## Quick Facts
- arXiv ID: 2511.07690
- Source URL: https://arxiv.org/abs/2511.07690
- Reference count: 3
- One-line primary result: A multi-agent framework with specialized LLM agents can automate military training scenario generation, producing coherent doctrinal documents and accurate unit movement predictions.

## Executive Summary
This work addresses the challenge of automating complex military training scenario generation by introducing a multi-agent, multi-modal reasoning framework that leverages Large Language Models (LLMs). The framework decomposes scenario generation into subproblems and employs specialized LLM agents to address each, enabling both human-in-the-loop and fully automated generation of training artifacts like Operations Orders. Results show the framework can produce coherent doctrinal documents, accurately predict unit positions over time, and generate complex tactical content such as the Scheme of Movement and Maneuver section, demonstrating improved feasibility and accuracy compared to prior AI approaches.

## Method Summary
The approach uses a multi-agent framework where an Orchestrator Agent employs a ReAct (Reasoning + Acting) paradigm to manage a dependency graph of information blocks. Specialized Helper Agents use RAG (Retrieval-Augmented Generation) to query structured scenario data (JSON) for domain-specific information. A Map and MCOO Helper Agent generates simplified visual overlays to improve LLM spatial reasoning. The system supports recursive correction, allowing the orchestrator to backtrack and revise outputs when inconsistencies arise. No training is involved—pure inference with structured prompting using GPT-4o.

## Key Results
- The framework successfully generates coherent doctrinal OPORD documents and accurately predicts time-based unit positions over terrain.
- Simplified visual representations (rather than full maps) significantly improve LLM spatial reasoning for movement and obstacle navigation.
- The multi-agent, dependency-graph approach overcomes limitations of single-agent prompting when tackling complex scenario generation tasks.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decomposing scenario generation into a dependency hierarchy of subproblems enables specialized agents to handle discrete reasoning tasks more reliably than single-agent prompting.
- Mechanism: The framework maps information blocks as nodes in a directed graph. Each block is assigned to a specialized helper agent. The orchestrator queries agents sequentially based on dependency order, integrating outputs to maintain logical consistency.
- Core assumption: Complex scenario generation can be modularized without losing coherence; errors in upstream blocks do not catastrophically propagate.
- Evidence anchors:
  - [abstract] "We structure our framework by decomposing scenario generation into a hierarchy of subproblems... Our framework employs specialized LLM-based agents to address distinct subproblems."
  - [section] "This multi-agent strategy overcomes the limitations of basic prompting or single-agent approaches when tackling such highly complex tasks."
- Break condition: If dependencies are incorrectly modeled or missing edges in the graph, downstream agents will receive incomplete context, producing incoherent outputs.

### Mechanism 2
- Claim: Providing simplified, task-specific visual representations (rather than full maps) improves LLM spatial reasoning for movement and terrain analysis.
- Mechanism: The Map and MCOO Helper Agent filters map data to render only relevant elements—locations, obstacles, phase lines—based on orchestrator queries. The multimodal LLM then reasons over these focused visuals to infer paths and positions.
- Core assumption: LLM multimodal capabilities are sufficient for tactical spatial reasoning when noise is reduced; simplified visuals preserve decision-relevant information.
- Evidence anchors:
  - [section] "Earlier attempts to describe this information purely in text led to poor results—LLMs often misinterpreted spatial layouts, confused directions, or failed to relate terrain features to movement planning."
  - [section] "This filtered, focused rendering improves the orchestrator's ability to reason accurately about space and movement."
- Break condition: If simplified visuals omit critical terrain features (e.g., hidden ambush points), the orchestrator may select tactically unsound paths.

### Mechanism 3
- Claim: ReAct-style orchestration with recursive correction improves output reliability by enabling iterative refinement when intermediate results are unsatisfactory.
- Mechanism: The Orchestrator alternates between reasoning steps (interpreting state) and action steps (querying helpers, calling functions, or revising outputs). Observations from helpers inform subsequent reasoning, and the orchestrator can backtrack and reissue queries if results are inconsistent.
- Core assumption: The orchestrator can reliably detect unsatisfactory outputs; backtracking does not cause infinite loops or excessive latency.
- Evidence anchors:
  - [section] "The framework supports recursive control: if the Orchestrator determines that an action has produced an unsatisfactory or inconsistent outcome, it is capable of backtracking and reissuing a corrected or alternative query."
  - [section] "This iterative strategy leads to greater robustness, enabling the orchestrator to revise its own intermediate conclusions if errors or inconsistencies arise."
- Break condition: If the orchestrator lacks clear criteria for "unsatisfactory" outputs, it may either accept poor results or loop indefinitely.

## Foundational Learning

- Concept: **ReAct (Reasoning + Acting) Paradigm**
  - Why needed here: The orchestrator's core control loop depends on alternating thought and action steps to decompose tasks and integrate helper responses.
  - Quick check question: Can you explain how a ReAct agent decides when to query a tool versus produce a final answer?

- Concept: **Retrieval-Augmented Generation (RAG)**
  - Why needed here: Each helper agent uses RAG to ground responses in scenario-specific documents (e.g., JSON files with unit data).
  - Quick check question: How does RAG differ from standard prompting in terms of how external knowledge is incorporated?

- Concept: **Dependency Graphs for Task Decomposition**
  - Why needed here: The framework's information flow graph defines execution order and input-output relationships between agents.
  - Quick check question: Given three tasks A, B, C where C depends on A and B, what happens if B's output is delayed or incorrect?

## Architecture Onboarding

- Component map:
  - Orchestrator Agent -> Helper Agents (RAG-based) -> Map and MCOO Helper Agent
  - Orchestrator Agent manages reasoning flow, queries helpers, and synthesizes final outputs.
  - Helper Agents provide scoped information for each information block (e.g., High-Level Unit Purpose, Decision Support Matrix, Unit Positions Time Based).
  - Map and MCOO Helper Agent generates simplified visual overlays and waypoint-based path representations.

- Critical path:
  1. Define learning objectives and backstory (human-driven or purple blocks).
  2. Generate force groupings and red/blue objectives.
  3. Compute time-based unit positions (queries MCOO helper for paths).
  4. Synthesize OPORD sections (e.g., Scheme of Movement and Maneuver) using upstream block outputs.

- Design tradeoffs:
  - **Visual simplification vs. completeness**: Filtered visuals reduce noise but risk omitting tactically relevant features.
  - **Automation level (green/orange/purple)**: Green blocks are fully automatable; orange require human verification; purple need human-led ideation. Over-automating orange/purple blocks may reduce scenario quality.
  - **Model agnosticism vs. capability dependence**: Framework is model-agnostic but relies on multimodal reasoning capabilities; weaker models may fail on spatial tasks.

- Failure signatures:
  - **Spatial hallucinations**: LLM misinterprets terrain or selects implausible routes (often due to incomplete visual context).
  - **Dependency violations**: Downstream agent outputs inconsistent with upstream blocks (e.g., unit positions conflicting with force groupings).
  - **Infinite backtracking loops**: Orchestrator repeatedly revises without converging when satisfaction criteria are undefined.

- First 3 experiments:
  1. **Unit position prediction accuracy**: Provide known starting positions and objectives; compare predicted time-based positions against ground truth from PACIFIC AEGIS scenarios. Measure deviation in coordinates and path plausibility.
  2. **OPORD section quality evaluation**: Generate Scheme of Movement and Maneuver sections; have domain experts blind-score LLM outputs vs. human-authored versions for coherence, doctrinal accuracy, and completeness.
  3. **Ablation of visual context**: Run the same spatial reasoning tasks with (a) full map images, (b) simplified visuals, (c) text-only descriptions. Compare path selection accuracy and error rates to isolate the contribution of filtered visual representations.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the multi-agent framework scale to generate a complete Operations Order (OPORD) while maintaining global consistency across all dependency blocks?
- Basis in paper: [inferred] The paper validates the framework using only a proof-of-concept for specific subsections (Scheme of Maneuver and Time-Based Unit Positions) rather than the entire scenario dependency hierarchy.
- Why unresolved: Generating isolated blocks is distinct from synthesizing a full document where dozens of information blocks must remain logically consistent with the backstory, terrain, and opposing forces simultaneously.
- What evidence would resolve it: Successful automated generation of a full OPORD where all sections (e.g., intelligence, logistics, maneuver) align without contradictory information.

### Open Question 2
- Question: Can the system perform spatial reasoning directly on raw, high-resolution terrain maps without the need for pre-processed, simplified visualizations?
- Basis in paper: [explicit] The authors note that "large, high-resolution images... tend to overwhelm multimodal LLMs," necessitating a helper agent to extract and render simplified visual overlays.
- Why unresolved: The system currently relies on filtering noise programmatically before the LLM processes the visual data; it is unclear if the LLM can handle complex, unfiltered geospatial inputs directly.
- What evidence would resolve it: Successful pathfinding and obstacle identification using raw MCOO (Modified Combined Obstacle Overlay) images without intermediate simplification steps.

### Open Question 3
- Question: Does the use of AI-generated scenario artifacts improve training outcomes compared to traditional human-authored scenarios?
- Basis in paper: [inferred] The paper focuses on the feasibility and coherence of the generation process (output quality) but does not measure the pedagogical effectiveness of the resulting training scenarios.
- Why unresolved: A scenario may be logically sound and doctrinally accurate (coherent) yet fail to stimulate the specific learning objectives or challenge the trainee effectively.
- What evidence would resolve it: A comparative study measuring trainee performance and retention in exercises using AI-generated versus human-authored OPORDs.

## Limitations
- No quantitative metrics or test set size are reported for scenario generation accuracy.
- Expert comparison methodology for OPORD evaluation lacks detail on rater calibration or inter-rater reliability.
- RAG implementation specifics (embedding model, chunking, retrieval parameters) are unspecified, limiting reproducibility.

## Confidence
- **High Confidence**: The modular decomposition strategy and ReAct orchestration pattern are theoretically sound and supported by clear implementation details in the text.
- **Medium Confidence**: Visual simplification improves spatial reasoning, but lacks corpus evidence and quantitative ablation results to isolate its contribution.
- **Low Confidence**: Claims about expert-validated accuracy are not substantiated with measurable outcomes or comparison baselines.

## Next Checks
1. **Quantitative Accuracy Assessment**: Measure deviation between LLM-predicted unit positions and ground-truth coordinates from PACIFIC AEGIS scenarios; compute path plausibility scores.
2. **Blind Expert Evaluation**: Have military domain experts score LLM-generated OPORD sections against human-authored versions for doctrinal accuracy and completeness, with inter-rater reliability reported.
3. **Ablation Study**: Compare spatial reasoning performance across three conditions—full maps, simplified visuals, and text-only descriptions—to isolate the impact of visual filtering on path selection accuracy.