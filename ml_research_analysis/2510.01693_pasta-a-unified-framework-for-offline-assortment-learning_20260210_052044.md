---
ver: rpa2
title: 'PASTA: A Unified Framework for Offline Assortment Learning'
arxiv_id: '2510.01693'
source_url: https://arxiv.org/abs/2510.01693
tags:
- assortment
- choice
- optimization
- pasta
- have
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces PASTA, a pessimistic learning framework for
  offline assortment optimization under general choice models. The core challenge
  addressed is insufficient data coverage, where historical data may lack observations
  for certain assortments, making traditional estimation-then-optimization approaches
  unreliable.
---

# PASTA: A Unified Framework for Offline Assortment Learning

## Quick Facts
- arXiv ID: 2510.01693
- Source URL: https://arxiv.org/abs/2510.01693
- Reference count: 40
- Primary result: Pessimistic offline assortment optimization framework with finite-sample regret guarantees

## Executive Summary
This paper introduces PASTA, a unified framework for offline assortment optimization under general choice models that addresses the critical challenge of insufficient data coverage. The framework constructs an uncertainty set via likelihood ratio tests and optimizes for worst-case revenue across all models within this set, ensuring robustness against estimation errors for under-explored assortments. PASTA achieves theoretical guarantees showing finite-sample regret bounds under broad choice model classes (MNL, latent class logit, nested logit) with only coverage at the optimal assortment required.

The framework is shown to be minimax optimal under the MNL model and demonstrates superior empirical performance compared to baseline methods across multiple choice models, maintaining gains across varying levels of data coverage and model complexity. The approach provides a principled solution to the fundamental problem of learning optimal assortments when historical data may lack observations for certain product combinations.

## Method Summary
PASTA addresses offline assortment optimization by constructing an uncertainty set around empirical choice probabilities using likelihood ratio tests. The framework then solves a pessimistic optimization problem that maximizes the minimum expected revenue across all choice models within this uncertainty set. This approach is robust to estimation errors for assortments with poor historical coverage while maintaining performance for well-covered options. The method requires only that the optimal assortment be observed in historical data, making it applicable to settings where traditional estimation-then-optimization approaches fail due to data sparsity.

## Key Results
- Achieves finite-sample regret bounds under broad choice model classes (MNL, latent class logit, nested logit)
- Demonstrates minimax optimality under the MNL model
- Outperforms baseline methods in both regret and assortment accuracy across multiple choice models
- Maintains performance stability across varying levels of data coverage and model complexity

## Why This Works (Mechanism)
PASTA works by explicitly accounting for estimation uncertainty in choice probabilities through pessimistic optimization. Instead of relying on point estimates of choice models, it constructs an uncertainty set containing all models consistent with observed data up to a statistical confidence level. By optimizing for the worst-case revenue within this set, PASTA guards against overfitting to potentially noisy estimates for poorly observed assortments. This approach naturally balances exploration and exploitation without requiring explicit exploration parameters, as the pessimistic formulation inherently accounts for uncertainty.

## Foundational Learning
- **Likelihood Ratio Tests**: Statistical method for constructing confidence regions around probability estimates; needed to create the uncertainty set around choice probabilities; quick check: verify test statistic follows chi-squared distribution asymptotically
- **Choice Models (MNL, Latent Class Logit, Nested Logit)**: Models describing how customers select products from assortments; needed to represent customer choice behavior; quick check: validate model assumptions against historical purchase data
- **Pessimistic Optimization**: Optimization framework that maximizes the minimum value across an uncertainty set; needed to ensure robust performance under model uncertainty; quick check: verify that optimal solution lies at boundary of uncertainty set
- **Regret Analysis**: Framework for measuring the performance gap between learned and optimal policies; needed to establish theoretical performance guarantees; quick check: compute empirical regret on held-out test data
- **Finite-Sample Guarantees**: Statistical bounds that hold for finite sample sizes rather than asymptotic regimes; needed to ensure reliable performance in practical settings; quick check: verify bound constants through simulation
- **Offline Reinforcement Learning**: Learning framework that uses only historical data without online interaction; needed to apply to real-world retail settings where experimentation is costly; quick check: confirm data collection protocol satisfies coverage conditions

## Architecture Onboarding
**Component Map**: Data -> Likelihood Ratio Tests -> Uncertainty Set -> Pessimistic Optimization -> Assortment Policy

**Critical Path**: The core computational bottleneck lies in solving the pessimistic optimization problem, which requires evaluating revenue across all models in the uncertainty set. The complexity scales with both the number of products (n) and the size of the uncertainty set, which grows with the inverse of the desired confidence level.

**Design Tradeoffs**: The framework trades computational efficiency for robustness, as pessimistic optimization is inherently more complex than point estimate approaches. The coverage requirement (only optimal assortment needs observation) significantly relaxes data requirements but may lead to overly conservative policies when coverage is poor.

**Failure Signatures**: Performance degradation occurs when: (1) the optimal assortment is not observed in historical data, violating the coverage condition; (2) the uncertainty set is too conservative due to strict confidence levels; (3) computational limitations prevent solving the pessimistic optimization to sufficient precision.

**First Experiments**:
1. Verify uncertainty set coverage by checking proportion of true models contained within constructed sets on synthetic data
2. Benchmark computational time scaling with assortment size (n = 10, 50, 100 products)
3. Test sensitivity to confidence level parameter by varying it across multiple orders of magnitude

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on pessimistic optimization may lead to overly conservative assortments in practice
- Coverage condition requiring only optimal assortment observation may be difficult to verify in real-world applications
- Computational complexity scales with uncertainty set size, potentially prohibitive for large assortment spaces

## Confidence
- Theoretical claims (MNL): High
- Theoretical claims (complex choice models): Medium
- Empirical results (synthetic data): Medium
- Robustness claims (poor coverage): High
- Robustness claims (well-covered data): Medium

## Next Checks
1. Test framework performance on real-world retail datasets with varying coverage patterns to validate synthetic results
2. Benchmark computational efficiency against existing approaches for large assortment spaces (n > 100 products)
3. Evaluate framework behavior when the coverage condition is violated in practice