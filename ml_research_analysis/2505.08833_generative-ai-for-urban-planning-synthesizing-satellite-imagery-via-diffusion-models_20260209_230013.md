---
ver: rpa2
title: 'Generative AI for Urban Planning: Synthesizing Satellite Imagery via Diffusion
  Models'
arxiv_id: '2505.08833'
source_url: https://arxiv.org/abs/2505.08833
tags:
- urban
- land
- satellite
- residential
- design
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study adapts Stable Diffusion with ControlNet to generate
  high-fidelity satellite imagery for urban planning by conditioning on land use descriptions
  and infrastructure constraints. It spatially aligns OpenStreetMap data with satellite
  imagery to address data scarcity, enabling large-scale training across three U.S.
---

# Generative AI for Urban Planning: Synthesizing Satellite Imagery via Diffusion Models

## Quick Facts
- arXiv ID: 2505.08833
- Source URL: https://arxiv.org/abs/2505.08833
- Reference count: 29
- Primary result: Adapts Stable Diffusion with ControlNet to generate high-fidelity satellite imagery for urban planning by conditioning on land use descriptions and infrastructure constraints

## Executive Summary
This study presents a novel approach to generating synthetic satellite imagery for urban planning applications using diffusion models. By adapting Stable Diffusion with ControlNet and conditioning on land use descriptions and infrastructure constraints, the researchers developed a system capable of producing realistic urban landscapes that align with specific planning requirements. The model addresses data scarcity issues by spatially aligning OpenStreetMap data with satellite imagery, enabling large-scale training across multiple U.S. cities.

The research demonstrates that generative AI can capture city-specific styles while supporting diverse prompting approaches, offering planners a powerful tool for visualization and public engagement. Quantitative evaluations show strong fidelity metrics (FID 58.94, KID 0.03514), and user studies indicate generated images are actually preferred over real satellite imagery, suggesting potential for enhancing planning workflows and community involvement in urban development processes.

## Method Summary
The researchers adapted Stable Diffusion with ControlNet to generate satellite imagery conditioned on land use descriptions and infrastructure constraints. They addressed data scarcity by spatially aligning OpenStreetMap data with satellite imagery, creating a large-scale training dataset across three U.S. cities. The system generates diverse, realistic urban landscapes that capture city-specific styles while supporting various prompting formats. The approach combines diffusion model capabilities with structured urban data to produce imagery that meets specific planning requirements.

## Key Results
- Generated satellite imagery achieves FID score of 58.94 and KID score of 0.03514, indicating strong fidelity
- User studies show generated images are preferred over real satellite imagery and closely match design constraints
- Model successfully captures city-specific styles and generates diverse urban landscapes across three U.S. cities

## Why This Works (Mechanism)
The approach leverages diffusion models' ability to learn complex spatial patterns while ControlNet provides structure through OpenStreetMap alignment. By conditioning on land use descriptions and infrastructure constraints, the model learns to generate imagery that respects urban planning parameters. The spatial alignment of OSM data with satellite imagery creates a rich training dataset that captures both the visual characteristics and structural elements of urban environments.

## Foundational Learning
- Diffusion models for image generation: Learn to denoise images progressively, enabling high-quality synthesis of complex visual patterns
- ControlNet integration: Provides additional structural guidance to diffusion models, ensuring generated content adheres to specified constraints
- OpenStreetMap data utilization: Leverages freely available structured urban data to guide generation and provide semantic context
- Conditional generation techniques: Enables generation based on specific input parameters like land use and infrastructure requirements
- Satellite imagery processing: Handles the unique challenges of high-resolution overhead imagery with complex spatial relationships

## Architecture Onboarding

**Component map:** User input (prompts + constraints) -> ControlNet preprocessor -> Stable Diffusion backbone -> Output satellite imagery

**Critical path:** Input conditioning → OSM alignment preprocessing → ControlNet conditioning → Diffusion sampling → Final image generation

**Design tradeoffs:** Balance between generation diversity and constraint adherence, computational cost vs. quality, training data scale vs. geographic specificity

**Failure signatures:** Blurry or unrealistic urban features, misalignment between generated content and specified constraints, loss of city-specific characteristics, generation artifacts at building boundaries

**3 first experiments:** 1) Test basic generation with simple land use prompts to verify system functionality, 2) Evaluate constraint adherence by comparing generated imagery against specified infrastructure requirements, 3) Assess city-specific style capture by generating imagery for different urban contexts using identical prompts

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Evaluation metrics are difficult to contextualize without comparison to other urban imagery generation methods
- User preference for generated images over real ones raises questions about practical planning utility beyond visual appeal
- Three-city scope (U.S.-based) may not capture global urban diversity and planning scenarios

## Confidence
- High confidence: Technical implementation of ControlNet with Stable Diffusion for conditional generation is sound and reproducible
- Medium confidence: Quality of generated imagery and city-specific style capture demonstrated but needs larger-scale validation
- Medium confidence: Planning utility and public engagement benefits suggested but not empirically validated in real workflows

## Next Checks
1. Conduct comparative study evaluating generated imagery against multiple baseline approaches using same metrics and user study methodology
2. Implement pilot study where generated imagery is used in actual planning workshops with stakeholders to assess practical utility beyond visual preference
3. Expand testing to include cities with varying OpenStreetMap data quality to quantify how data alignment robustness affects generation quality across different urban contexts