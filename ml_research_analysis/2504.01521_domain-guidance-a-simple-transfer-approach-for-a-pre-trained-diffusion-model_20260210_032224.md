---
ver: rpa2
title: 'Domain Guidance: A Simple Transfer Approach for a Pre-trained Diffusion Model'
arxiv_id: '2504.01521'
source_url: https://arxiv.org/abs/2504.01521
tags:
- domain
- guidance
- pre-trained
- diffusion
- transfer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Domain Guidance (DoG), a novel transfer learning
  approach for diffusion models that leverages pre-trained knowledge to improve generation
  quality in target domains. DoG treats transfer as conditional generation, using
  the pre-trained model as an unconditional guide to direct the fine-tuned model toward
  the target domain, similar to classifier-free guidance.
---

# Domain Guidance: A Simple Transfer Approach for a Pre-trained Diffusion Model

## Quick Facts
- **arXiv ID:** 2504.01521
- **Source URL:** https://arxiv.org/abs/2504.01521
- **Reference count:** 17
- **Primary result:** DoG achieves 19.6% FID improvement and 23.4% FDDINOv2 improvement over standard fine-tuning with classifier-free guidance

## Executive Summary
Domain Guidance (DoG) introduces a novel transfer learning approach for diffusion models that treats transfer as conditional generation. By using a frozen pre-trained model as an unconditional guide during inference, DoG preserves valuable pre-trained knowledge and reduces out-of-distribution sampling errors. The method is theoretically grounded and shows significant empirical improvements across seven fine-grained benchmarks, with the added benefit that existing fine-tuned models can seamlessly integrate DoG without additional training.

## Method Summary
DoG leverages a frozen pre-trained diffusion model as an unconditional guide during inference, replacing the noisy unconditional branch typically trained on limited target data. The fine-tuned model predicts noise conditioned on the target domain, while the pre-trained model provides a stable unconditional reference. At each sampling step, DoG computes a weighted difference between the fine-tuned and pre-trained predictions, effectively steering the generation toward the target domain while maintaining alignment with the source's learned distribution. This approach eliminates the need for training an unconditional branch on small target datasets, thereby avoiding catastrophic forgetting and reducing OOD errors.

## Key Results
- Achieves 19.6% improvement in FID compared to standard fine-tuning with classifier-free guidance
- Shows 23.4% improvement in FDDINOv2 metric across seven fine-grained benchmarks
- Existing fine-tuned models can integrate DoG without additional training, simply by loading the original pre-trained weights

## Why This Works (Mechanism)

### Mechanism 1: Pre-trained Distribution as an OOD Anchor
The pre-trained model provides a robust unconditional guide that approximates the ground truth marginal distribution better than an underfitted unconditional model trained on limited target data. This reduces out-of-distribution sampling errors by regularizing the sampling trajectory with the stable source domain distribution.

### Mechanism 2: Implicit Domain Classification via Score Extrapolation
DoG functions as implicit classifier guidance, where the difference between fine-tuned and pre-trained scores approximates the gradient of the log-likelihood of the target domain. This pushes samples away from OOD regions and toward the target manifold.

### Mechanism 3: Decoupled Conditional Optimization
By removing the conflicting objective of jointly training conditional and unconditional branches, DoG allows the fine-tuning process to focus solely on domain alignment. This eliminates the data splitting between two objectives and dedicates 100% of training compute to fitting the target conditional distribution.

## Foundational Learning

- **Concept: Classifier-Free Guidance (CFG)**
  - Why needed here: DoG is structurally identical to CFG but reinterprets the inputs. You must understand the standard CFG formula to grasp that DoG swaps the unconditional branch with the frozen pre-trained model.
  - Quick check question: In the CFG formula, what happens to the output if the guidance scale s=1?

- **Concept: Score Matching & Score Distillation**
  - Why needed here: The paper formulates transfer as "conditional generation" using score functions (gradients of log-density). Understanding that diffusion models predict noise/scores to move samples along a manifold is necessary to interpret the theoretical proof.
  - Quick check question: Does a diffusion model predict the clean image directly or the gradient of the data density (score)?

- **Concept: Catastrophic Forgetting**
  - Why needed here: This is the core failure mode DoG attempts to solve. You need to know that fine-tuning on a small dataset causes the model to lose the generic features learned from the large dataset.
  - Quick check question: Why might a model fine-tuned on "Dogs" suddenly perform poorly at generating "Cats" if they share low-level features?

## Architecture Onboarding

- **Component map:** Frozen Pre-trained Model -> Tunable Fine-tuned Model -> DoG Sampling Wrapper
- **Critical path:**
  1. Load Pre-trained Model (State A)
  2. Create a deep copy for the Target Model (State B)
  3. Train State B without unconditional dropout on the target dataset
  4. During inference, run both models and apply the DoG formula at each timestep

- **Design tradeoffs:**
  - Inference Cost: Doubles forward pass cost per step (same as standard CFG)
  - Memory: Requires storing two sets of model weights in VRAM during inference
  - Dependency: Cannot discard original pre-trained weights after fine-tuning

- **Failure signatures:**
  - "Washing Out": Guidance weight too high, causing loss of detail
  - Domain Conflict: Source and target disjoint domains causing ghosting or averaging
  - OOM: Loading two XL-sized models simultaneously

- **First 3 experiments:**
  1. Zero-Shot Retrofit: Apply DoG to an existing fine-tuned checkpoint and verify FID improvement
  2. Hyperparameter Sensitivity: Sweep guidance scale w in [1.0, 2.5] on a small validation set
  3. Ablation on Dropout: Compare convergence speed and final FID between standard dropout and dropout=0 training

## Open Questions the Paper Calls Out

- **Open Question 1:** Can compositional guiding models be constructed for transfer learning to simultaneously handle multiple distinct target domains or concepts?
- **Open Question 2:** Can a single general large-scale pre-trained model serve as a unified guiding model to improve transfer performance across arbitrary downstream tasks?
- **Open Question 3:** What are the formal properties required to unify Domain Guidance (DoG) and Autoguidance into a single theoretical framework?
- **Open Question 4:** Does a time-dependent or dynamic scheduling of the DoG guidance weight improve generation quality compared to fixed weights?

## Limitations
- The assumption that the pre-trained unconditional distribution is a valid anchor may fail when source and target domains are structurally incompatible
- Theoretical proofs rely on assumptions about the pre-trained model's score approximation that are not rigorously validated on real-world datasets
- Seamless integration claims lack extensive empirical validation across diverse pre-trained models and target domains

## Confidence
- **High Confidence:** 19.6% FID improvement and 23.4% FDDINOv2 improvement claims
- **Medium Confidence:** Mechanism of reducing OOD sampling errors via pre-trained guide
- **Low Confidence:** Seamless integration with existing fine-tuned models without additional training

## Next Checks
1. Evaluate DoG's performance when transferring between structurally incompatible domains to assess limits of pre-trained anchor assumption
2. Conduct experiments with varying dataset sizes to empirically validate theoretical claims about DoG's advantage in low-data regimes
3. Test DoG's effectiveness with different pre-trained diffusion models and target domains to assess generalizability beyond DiT-XL/2