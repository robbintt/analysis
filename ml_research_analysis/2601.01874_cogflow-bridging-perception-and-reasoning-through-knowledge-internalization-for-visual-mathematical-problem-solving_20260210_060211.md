---
ver: rpa2
title: 'CogFlow: Bridging Perception and Reasoning through Knowledge Internalization
  for Visual Mathematical Problem Solving'
arxiv_id: '2601.01874'
source_url: https://arxiv.org/abs/2601.01874
tags:
- reasoning
- visual
- perception
- zhang
- internalization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper tackles the challenge of visual mathematical problem
  solving, where existing models struggle with accurate visual perception and faithful
  integration of extracted visual cues into reasoning. To address this, the authors
  propose CogFlow, a three-stage framework that mirrors human cognitive reasoning:
  perception, knowledge internalization, and reasoning.'
---

# CogFlow: Bridging Perception and Reasoning through Knowledge Internalization for Visual Mathematical Problem Solving

## Quick Facts
- arXiv ID: 2601.01874
- Source URL: https://arxiv.org/abs/2601.01874
- Reference count: 40
- Primary result: CogFlow achieves 66.0% accuracy on FlowVerse and 53.9% on MathVerse, surpassing all open-source baselines

## Executive Summary
CogFlow addresses the challenge of visual mathematical problem solving by proposing a three-stage framework that mirrors human cognitive reasoning: perception, knowledge internalization, and reasoning. The method introduces synergistic visual rewards for enhanced perception, a knowledge internalization reward to bridge perception and reasoning, and visual-gated policy optimization for grounded reasoning. The framework is evaluated on multiple visual mathematical reasoning benchmarks, demonstrating consistent improvements over state-of-the-art models and achieving significant performance gains on both FlowVerse and MathVerse datasets.

## Method Summary
CogFlow is a three-stage framework that explicitly separates perception, knowledge internalization, and reasoning to mitigate "reasoning drift" in visual mathematical problem solving. The method uses synergistic visual rewards (combining parametric and semantic rewards) to enhance perception accuracy, trains a knowledge internalization reward model to ensure reasoning is grounded in visual evidence, and employs visual-gated policy optimization to stabilize reinforcement learning. The framework builds on Qwen2.5-VL as the base policy and is trained on the MathCog dataset through a multi-stage process involving supervised fine-tuning, reward model training, and reinforcement learning with the visual gate mechanism.

## Key Results
- Achieves 66.0% accuracy on FlowVerse benchmark
- Achieves 53.9% accuracy on MathVerse benchmark
- Outperforms all open-source baselines on visual mathematical reasoning tasks
- Demonstrates consistent improvements across multiple evaluation metrics including CoT-E

## Why This Works (Mechanism)

### Mechanism 1: Synergistic Visual Rewards for Dual-Space Grounding
The combination of Visual Parameterized Reward (VPR) and Visual Semantic Reward (VSR) stabilizes geometric perception better than pixel-level loss alone. VPR enforces local geometric fidelity through Euclidean distance calculations using Hungarian matching, while VSR ensures global consistency through semantic embedding comparison after rendering predicted descriptions back into images.

### Mechanism 2: Knowledge Internalization Reward for Drift Mitigation
Training the IntlzR reward model using Softmax-DPO on contrastive reasoning trajectories reduces "reasoning drift" where logic disconnects from visual evidence. The reward model is trained to convert raw visual cues into canonical context before reasoning steps, penalizing logically coherent but visually ungrounded chains.

### Mechanism 3: Visual-Gated Policy Optimization (VGPO)
The visual gate mechanism filters low-quality perception trajectories during training by computing a perception score and rejecting samples below threshold τ. This prevents the policy gradient from updating on samples where reasoning is correct but based on flawed perception, breaking typical credit assignment noise in multimodal RL.

## Foundational Learning

- **Concept: Group Relative Policy Optimization (GRPO)**
  - Why needed: CogFlow builds its VGPO on top of GRPO for training stability
  - Quick check: How does the advantage estimation in VGPO differ from standard PPO's critic-based advantage?

- **Concept: Direct Preference Optimization (DPO) & Softmax-DPO**
  - Why needed: The Knowledge Internalization Reward (IntlzR) is trained via Softmax-DPO
  - Quick check: Why does the paper use Softmax-DPO (comparing one positive against multiple negatives) for IntlzR instead of standard binary DPO?

- **Concept: Hungarian Algorithm for Assignment**
  - Why needed: The Visual Parameterized Reward (VPR) relies on optimal matching between predicted and ground-truth primitives
  - Quick check: How does VPR handle matching cost if the model predicts a line that is geometrically close to ground-truth but has different semantic label or endpoint ordering?

## Architecture Onboarding

- **Component map:** Image+Question → Vision Encoder → Perception Stage (SynVRs) → Visual Gate → Internalization Stage → Reasoning Stage (IntlzR + InfR) → Policy Model → VGPO Optimization

- **Critical path:** 1) SFT: Fine-tune Qwen2.5-VL on MathCog-SFT 2) IntlzR Training: Train reward model on MathCog-IntlzR 3) RL: Train Policy Model with VGPO using SynVRs, IntlzR, and InfR

- **Design tradeoffs:** Latency vs. Accuracy (strict threshold improves accuracy but increases inference latency), Coupling (VPR offers precise geometry but is brittle, VSR is robust but lacks metric precision, α=0.6 balances)

- **Failure signatures:** Reasoning Drift (fluent explanation contradicts diagram), Perception Collapse (generic descriptions without parametric details), Training Instability (loss spikes during RL)

- **First 3 experiments:** 1) Ablate the Gate: Disable visual gate during training 2) Reward Sensitivity: Vary α in SynVRs 3) Error Analysis: Classify errors into 5 types or new "Unknown" category

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the CogFlow framework be effectively adapted to general natural scenes where visual primitives are semantic objects rather than geometric elements?
- **Basis:** Appendix A.4 explicitly states intention to expand method to general scenes using detection or segmentation models
- **Why unresolved:** Current implementation relies on geometric primitives (points, lines, circles) using OpenCV, not native to unstructured natural images
- **What evidence would resolve it:** Successful application on general vision-language benchmarks (e.g., VQAv2) using bounding boxes or segmentation masks

### Open Question 2
- **Question:** Is it possible to reduce the high computational demand of the Visual-Gated Policy Optimization (VGPO) training pipeline?
- **Basis:** Appendix A.4 identifies computational intensity as primary limitation
- **Why unresolved:** Multi-stage RL framework with visual gate and multiple reward models requires substantial GPU resources
- **What evidence would resolve it:** Modified training regime maintaining reasoning precision while significantly lowering FLOPs or wall-clock time

### Open Question 3
- **Question:** To what extent does the cognitive pipeline (Perception → Internalization → Reasoning) generalize to other vision-language domains like medical imaging or chart understanding?
- **Basis:** Appendix A.4 suggests pipeline generalizes beyond visual math, but validated only on geometry problems
- **Why unresolved:** Assumes "notion of primitives" naturally extends, but Synergistic Visual Rewards rely on parametric precision that may not translate to semantic data
- **What evidence would resolve it:** Evaluation on non-geometric benchmarks (e.g., ChartQA) to determine if internalization reward effectively bridges perception and reasoning

## Limitations
- The paper does not fully specify the visual gate threshold (τ) or primitive extraction pipeline details critical for reproduction
- Model's reliance on specific MathCog dataset raises questions about generalizability to other visual mathematical reasoning tasks
- Claim that five error types cover all reasoning drifts is not fully validated across different contexts

## Confidence
- **High Confidence:** Empirical results showing CogFlow's superior performance on FlowVerse and MathVerse benchmarks
- **Medium Confidence:** Theoretical mechanisms (synergistic visual rewards, knowledge internalization, visual-gated optimization) are logically sound
- **Low Confidence:** Claim that five error types cover all reasoning drifts in mathematical contexts is not fully validated

## Next Checks
1. **Ablate the Visual Gate:** Train model with VGPO but disable visual gate during training to isolate impact of "gated training" vs. "gated inference"
2. **Reward Sensitivity Analysis:** Vary weight α in SynVRs to determine domain reliance on parametric precision vs. semantic consistency
3. **Error Type Classification:** Run trained model on MathVerse and manually classify errors into 5 defined types or new "Unknown" category to validate IntlzR effectiveness and identify novel error types