---
ver: rpa2
title: 'Impact of Latent Space Dimension on IoT Botnet Detection Performance: VAE-Encoder
  Versus ViT-Encoder'
arxiv_id: '2504.14879'
source_url: https://arxiv.org/abs/2504.14879
tags:
- latent
- performance
- dimension
- dataset
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study investigates how latent space dimension affects the\
  \ performance of deep learning classifiers for IoT botnet detection. It compares\
  \ two state-of-the-art encoder architectures\u2014Variational Auto-Encoder (VAE)\
  \ and Vision Transformer (ViT)\u2014for reducing high-dimensional IoT traffic data\
  \ to low-dimensional latent representations."
---

# Impact of Latent Space Dimension on IoT Botnet Detection Performance: VAE-Encoder Versus ViT-Encoder

## Quick Facts
- arXiv ID: 2504.14879
- Source URL: https://arxiv.org/abs/2504.14879
- Authors: Hassan Wasswa; Aziida Nanyonga; Timothy Lynar
- Reference count: 28
- Primary result: VAE-based dimension reduction outperforms ViT-based reduction for IoT botnet detection due to absence of spatial patterns in the datasets

## Executive Summary
This study investigates how latent space dimension affects deep learning classifier performance for IoT botnet detection, comparing Variational Auto-Encoder (VAE) and Vision Transformer (ViT) encoders for reducing high-dimensional IoT traffic data. Five deep learning models (DNN, LSTM, BLSTM, GRU, sRNN) are trained on N-BaIoT and CICIoT2022 datasets across four latent dimensions (2, 6, 10, 14). Results show VAE-based encoders consistently outperform ViT-based encoders across all metrics, likely because the datasets lack spatial patterns that ViT models are designed to capture. Model performance improves with latent dimension up to size 10, after which gains plateau.

## Method Summary
The study compares VAE and ViT encoders for dimensionality reduction of IoT traffic data, extracting latent representations that are then classified by five deep learning models. Input data (N-BaIoT with 115 features, CICIoT2022 with 84 features) undergoes preprocessing to remove IP addresses and packet IDs, handle missing values, and reshape instances into pseudo-images. Latent vectors of dimensions 2, 6, 10, and 14 are extracted and used to train classifiers with 4 hidden layers, ReLU activation, softmax output, Adam optimizer, and dropout regularization. Performance is evaluated using accuracy, precision, recall, and F1-score.

## Key Results
- VAE-based dimension reduction consistently outperforms ViT-based reduction across all metrics
- Model performance improves with latent dimension up to size 10, then plateaus
- ViT-based models converge faster (within ~5 epochs) than VAE-based models but achieve lower accuracy
- The performance gap is attributed to absence of spatial patterns in the datasets that ViT is designed to capture

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** VAE-based dimension reduction outperforms ViT-based reduction for structured IoT traffic data because the data lacks spatial patterns that ViT is designed to extract.
- **Mechanism:** VAE learns probabilistic distributions over input features without assuming spatial structure, compressing features based on statistical relationships. ViT partitions input into patches and applies self-attention to capture spatial relationships between patches. When applied to reshaped 1D tabular data (e.g., 115 features → 5×23×1 "image"), ViT's patch-based attention operates on artificial spatial structure that does not exist in the original data.
- **Core assumption:** The performance gap stems from architecture-data mismatch rather than hyperparameter tuning or training duration.
- **Evidence anchors:**
  - [abstract] "VAE-encoder based dimension reduction outperforms ViT-encoder based dimension reduction... which can be attributed to absence of spatial patterns in the datasets the ViT model attempts to learn and extract from image instances."
  - [section IV.E] "This relatively low performance of ViT-based models can be attributed to the datasets' lack of spatial patterns for which the ViT model was initially designed to learn and extract from image and video datasets."
  - [corpus] Paper 2504.18781 confirms transformer applicability is limited by "absence of spatial patterns" in IoT network flow data.
- **Break condition:** If the tabular data were first transformed via meaningful spatial encoding (e.g., heatmaps, topological maps) rather than naive reshaping, ViT may capture structure; alternatively, if VAE's regularization harms reconstruction fidelity on certain datasets, the advantage may reverse.

### Mechanism 2
- **Claim:** Classification performance improves with latent dimension up to a dataset-specific threshold (observed at dimension 10), after which gains plateau.
- **Mechanism:** As latent dimension increases, the encoder can preserve more information relevant for class discrimination. Below the threshold, critical discriminative features are compressed away. At the threshold, sufficient information is retained. Beyond the threshold, additional dimensions capture noise or redundant variance without improving separability.
- **Core assumption:** The plateau indicates sufficiency rather than model capacity limits; classifier architectures (DNN, LSTM, etc.) are not the bottleneck.
- **Evidence anchors:**
  - [abstract] "Model performance improves with latent dimension up to size 10, after which gains plateau."
  - [section IV.A] "The insignificant change in performance between latent dimension 10 and latent dimension 14 implies that, with the right parameter setting, a latent size of 10 is sufficient for the models to precisely discriminate between N-BaIoT traffic instances."
  - [corpus] Paper 2505.17357 shows similar dimension reduction evaluation (VAE vs AE vs PCA) but does not test latent dimension as an independent variable; generalization of the threshold claim requires additional datasets.
- **Break condition:** For datasets with higher intrinsic complexity (more classes, subtler attack signatures), the threshold may shift higher; for simpler binary classification, it may be lower.

### Mechanism 3
- **Claim:** ViT-based models converge faster (within ~5 epochs) than VAE-based models but achieve lower final accuracy.
- **Mechanism:** ViT's multi-head self-attention enables parallel processing and gradient flow across all patches simultaneously, accelerating early learning. VAE's training involves optimizing both encoder and decoder with KL-divergence regularization, which introduces a more complex loss landscape requiring more epochs to reach equilibrium.
- **Core assumption:** Faster convergence is not due to overfitting or premature plateauing at a suboptimal solution.
- **Evidence anchors:**
  - [abstract] "VAE-based models also converge more slowly than ViT-based models but achieve higher detection accuracy."
  - [section IV.E] "Because of the multi-head attention mechanism that allows parallel processing, the ViT-based models converge faster than the VAE-based models. For all models the ViT-based models reached the optimal performance within 5 epochs during training."
  - [corpus] Corpus papers do not directly compare ViT vs VAE convergence rates; this mechanism is primarily anchored in the paper's reported observations.
- **Break condition:** If training time is severely constrained, ViT's faster convergence may make it preferable despite lower peak accuracy; if decoder training is decoupled or pretrained VAE encoders are transferred, convergence gap may narrow.

## Foundational Learning

- **Concept:** Latent Space Representation
  - **Why needed here:** Understanding that the encoder projects high-dimensional input (84-115 features) into a compressed vector (2-14 dimensions) is essential for interpreting why dimension size affects classifier performance.
  - **Quick check question:** If latent dimension is 2 and input has 115 features, what type of information is most likely lost?

- **Concept:** Variational Autoencoder (VAE)
  - **Why needed here:** VAE differs from standard autoencoders by regularizing the latent space toward a learned distribution (typically Gaussian), enabling both reconstruction and sampling.
  - **Quick check question:** What does the KL-divergence term in VAE loss enforce on the latent space?

- **Concept:** Vision Transformer (ViT) Patch Embedding
  - **Why needed here:** ViT requires input reshaped into patches; the paper reshapes CSV rows into pseudo-images, which affects whether spatial attention is meaningful.
  - **Quick check question:** Why does splitting a 1D feature vector into 5×23 patches and treating them as spatial regions not introduce useful structure?

## Architecture Onboarding

- **Component map:** Input preprocessing -> Encoder (VAE or ViT) -> Latent vector extraction -> Classifier training -> Evaluation
- **Critical path:** Preprocessing reshaping → encoder selection → latent dimension choice → classifier training → evaluation on 4 metrics
- **Design tradeoffs:**
  - VAE encoder: Higher accuracy, slower convergence, no spatial assumption
  - ViT encoder: Faster convergence, lower accuracy, assumes spatial structure
  - Latent dim 2: Fastest inference, highest compression, poorest accuracy
  - Latent dim 10+: Better accuracy, plateau beyond 10, marginal compute increase
  - RNN classifiers (LSTM/GRU): Better for sequential interpretation; DNN: simpler, faster
- **Failure signatures:**
  - Accuracy <80% with dim=2: Information bottleneck confirmed
  - ViT accuracy < VAE accuracy by >5%: Architecture-data mismatch (no spatial patterns)
  - No improvement from dim 10→14: Threshold reached; check if more classes require higher dim
  - Fast convergence with low final accuracy: Likely ViT reaching suboptimal local minimum
- **First 3 experiments:**
  1. Replicate VAE vs ViT comparison on N-BaIoT with dim=10; confirm performance gap and log epoch-wise loss to verify convergence difference.
  2. Ablation: Test latent dims {2, 4, 6, 8, 10, 12, 14, 16} to locate plateau precisely and check if threshold shifts with dataset complexity.
  3. Data transformation test: Apply meaningful spatial encoding (e.g., correlation heatmap per sample) before ViT to assess whether spatial structure injection closes the performance gap.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** What data transformation techniques could create meaningful spatial patterns in structured IoT traffic data to better leverage ViT's self-attention mechanism?
- **Basis in paper:** [explicit] The authors attribute ViT's underperformance to "absence of spatial patterns in the datasets the ViT model attempts to learn and extract from image instances," but only tested a simple reshaping approach (converting CSV rows to single-channel 2D images).
- **Why unresolved:** The paper does not explore alternative feature engineering methods (e.g., correlation-based spatial arrangement, attention heatmaps) that might preserve or create spatial relationships suitable for transformer-based architectures.
- **What evidence would resolve it:** Experiments comparing different data-to-image transformation techniques on ViT performance for the same datasets.

### Open Question 2
- **Question:** What is the optimal latent dimension beyond 14, and does the performance plateau or degrade at higher dimensions?
- **Basis in paper:** [inferred] The study only tested four latent dimensions (2, 6, 10, 14) and observed plateauing at 10-14, but did not test higher dimensions to determine if this represents a true optimum or merely an artifact of the tested range.
- **Why unresolved:** No theoretical justification is provided for why dimension 10 should be sufficient, and no experiments explored dimensions >14 or used principled dimension selection methods.
- **What evidence would resolve it:** Testing a wider range of latent dimensions (e.g., 18, 25, 50) and analyzing reconstruction loss and classification performance trade-offs.

### Open Question 3
- **Question:** Can hybrid VAE-ViT architectures combine VAE's feature extraction quality with ViT's faster convergence for real-time IoT botnet detection?
- **Basis in paper:** [explicit] "VAE-based models converge more slowly than ViT-based models but achieve higher detection accuracy," and ViT reached "optimal performance within 5 epochs."
- **Why unresolved:** The paper treats VAE and ViT as competing approaches rather than complementary components, leaving the potential synergy unexplored.
- **What evidence would resolve it:** Designing and evaluating models that use VAE-encoded latent representations processed through transformer attention mechanisms.

## Limitations

- VAE and ViT encoder architectures are not fully specified (layer sizes, hyperparameters, training regimes)
- The effectiveness of reshaping tabular data into pseudo-images for ViT is assumed rather than validated
- No ablation studies on latent dimension beyond the four tested values to precisely locate the performance plateau
- Claims about convergence speed are observational without rigorous statistical testing

## Confidence

- **High Confidence:** VAE outperforms ViT for this dataset type; performance improves with latent dimension up to ~10; ViT converges faster but achieves lower accuracy
- **Medium Confidence:** The attribution of ViT's underperformance to lack of spatial patterns is plausible but not definitively proven
- **Low Confidence:** The precise location of the performance plateau and its generalizability to other datasets

## Next Checks

1. Conduct ablation study testing latent dimensions {2, 4, 6, 8, 10, 12, 14, 16} to precisely locate the performance plateau and test for dataset-specific thresholds
2. Test ViT performance on tabular data with meaningful spatial encoding (e.g., correlation heatmaps) to validate whether spatial pattern absence explains the performance gap
3. Compare training curves with statistical significance testing to confirm that faster ViT convergence is not due to overfitting or premature stopping