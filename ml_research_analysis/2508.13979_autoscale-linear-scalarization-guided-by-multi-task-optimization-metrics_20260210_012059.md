---
ver: rpa2
title: 'AutoScale: Linear Scalarization Guided by Multi-Task Optimization Metrics'
arxiv_id: '2508.13979'
source_url: https://arxiv.org/abs/2508.13979
tags:
- scalarization
- learning
- gradient
- task
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates linear scalarization for multi-task learning
  and introduces AutoScale, a two-phase framework that uses multi-task optimization
  (MTO) metrics to automatically determine optimal task weights without costly hyperparameter
  search. The key insight is that well-performing linear scalarization weights exhibit
  specific trends in certain MTO metrics such as high gradient magnitude similarity
  and low condition number.
---

# AutoScale: Linear Scalarization Guided by Multi-Task Optimization Metrics

## Quick Facts
- arXiv ID: 2508.13979
- Source URL: https://arxiv.org/abs/2508.13979
- Reference count: 40
- AutoScale achieves state-of-the-art performance on NuScenes with 0.703 NDS and 0.703 mAP while being 2-3× faster than gradient-manipulating MTO methods

## Executive Summary
This paper addresses the critical challenge of determining optimal task weights in multi-task learning (MTL) by introducing AutoScale, a framework that leverages multi-task optimization (MTO) metrics to automatically select linear scalarization weights. Unlike traditional methods that rely on expensive hyperparameter search or complex gradient manipulation, AutoScale exploits empirical correlations between well-performing weights and specific MTO metric trends. The framework operates in two phases: an optimization phase that selects weights by minimizing a chosen MTO metric over local training windows, followed by a fixed-weight training phase. Extensive experiments across three diverse datasets, including the large-scale NuScenes autonomous driving benchmark, demonstrate that AutoScale consistently outperforms state-of-the-art methods while requiring significantly less computational overhead.

## Method Summary
AutoScale addresses linear scalarization weight selection in multi-task learning by using multi-task optimization metrics as proxies for performance. The framework operates in two phases: first, it optimizes task weights over local training windows by minimizing a chosen MTO metric (low condition number, equal gradient magnitude, or equal loss scale), then fixes these weights for the remainder of training. The key insight is that optimal weights exhibit specific patterns in MTO metrics - particularly high gradient similarity and low condition numbers. AutoScale exploits this by using these metrics as cost functions to guide weight selection without requiring expensive grid searches or complex gradient manipulation. The method is evaluated across three diverse datasets and shows consistent improvements over state-of-the-art MTO methods while being 2-3× faster than gradient-manipulating approaches.

## Key Results
- On NuScenes dataset, AutoScale with low condition number metric achieves 0.703 NDS and 0.703 mAP, outperforming grid-searched weights
- AutoScale is 2-3× faster than gradient-manipulating MTO methods while maintaining superior performance
- The framework shows consistent improvements across three diverse datasets including CityScapes, NYUv2, and NuScenes
- Low condition number metric consistently outperforms gradient magnitude and loss scale balancing across all evaluated datasets

## Why This Works (Mechanism)
AutoScale works by exploiting the empirical observation that well-performing linear scalarization weights exhibit specific patterns in multi-task optimization metrics during training. The framework identifies that optimal weights tend to have high gradient magnitude similarity across tasks and low condition numbers of the weighted gradient matrix. By using these metrics as cost functions in a two-phase optimization approach, AutoScale can automatically select effective weights without expensive hyperparameter search. The local window optimization in phase one allows the framework to adapt to changing task dynamics during training, while the fixed-weight phase ensures training stability once optimal weights are identified.

## Foundational Learning
- Multi-task optimization metrics: Why needed - to quantify task alignment and training stability; Quick check - compute gradient cosine similarity and condition number on a simple MTL problem
- Linear scalarization: Why needed - provides a simple yet effective way to combine multiple task losses; Quick check - verify that different weight combinations produce different optimization dynamics
- Gradient magnitude similarity: Why needed - indicates how aligned task gradients are, affecting convergence; Quick check - measure gradient cosine similarity across tasks during training
- Condition number of gradient matrix: Why needed - low condition numbers indicate better training stability; Quick check - calculate condition number for different weight configurations
- Two-phase training approach: Why needed - balances adaptability with training stability; Quick check - compare single vs two-phase approaches on a simple MTL benchmark

## Architecture Onboarding

Component Map:
Input tasks -> Loss computation -> Weight optimization (Phase 1) -> Fixed weights -> Main training (Phase 2) -> Output model

Critical Path:
The critical path is the two-phase weight optimization followed by fixed-weight training. Phase one involves local window optimization of task weights using the chosen MTO metric, which requires computing gradients, calculating the metric, and updating weights. Phase two uses the fixed weights for the remainder of training, which is computationally simpler but requires the phase one optimization to be effective.

Design Tradeoffs:
The main tradeoff is between adaptability and computational efficiency. The two-phase approach allows adaptation to changing task dynamics during phase one but adds complexity compared to fixed-weight methods. The choice of MTO metric involves a tradeoff between different aspects of optimization quality - gradient magnitude similarity vs condition number vs loss scale balancing. The local window size in phase one affects both the quality of weight selection and computational overhead.

Failure Signatures:
- Poor performance if the chosen MTO metric doesn't correlate well with actual task performance for the specific problem
- Suboptimal results if task relationships change dramatically after phase one weight selection
- Computational overhead if local window optimization is too frequent or window size is too small
- Instability if the condition number metric is used on highly imbalanced tasks

First Experiments:
1. Compare AutoScale against equal weights baseline on a simple MTL problem with known optimal weights
2. Evaluate sensitivity to local window size by testing different window configurations on CityScapes
3. Test different MTO metrics (condition number vs gradient similarity) on a controlled synthetic MTL task

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can a composite cost function simultaneously optimizing multiple MTO metrics (e.g., combining low condition number with gradient magnitude similarity) outperform the single-metric AutoScale variants?
- Basis in paper: The authors note in the Conclusion that "These findings indicate that the values of MTO metrics are interrelated... This interdependence will potentially be the focus of future works."
- Why unresolved: The paper evaluates three cost functions in isolation and observes they influence each other, but does not experiment with a unified objective that minimizes multiple metrics at once.
- What evidence would resolve it: Experiments comparing the current single-metric AutoScale against a variant using a weighted sum or multi-objective cost function that penalizes high condition numbers while enforcing gradient magnitude similarity.

### Open Question 2
- Question: What are the theoretical or geometric properties that cause the low condition number metric to consistently outperform gradient magnitude and loss scale balancing across diverse datasets?
- Basis in paper: The authors observe in Section 8 that "Given the observed performance ranking... Low Cond. > Equal |g| > Equal |l|, it is reasonable to infer that these fluctuations contribute to the lower performance," but do not fully formalize why minimizing the condition number is superior.
- Why unresolved: While the paper demonstrates empirical superiority, it does not provide a theoretical proof explaining why training stability (low condition number) is a stronger proxy for generalization than explicit gradient or loss balancing.
- What evidence would resolve it: A theoretical analysis linking the condition number of the weighted gradient matrix to the convergence rate or generalization error bounds in multi-task learning.

### Open Question 3
- Question: Does the correlation between specific MTO metrics (high gradient similarity, low condition number) and optimal performance persist in non-computer-vision domains, such as reinforcement learning or natural language processing?
- Basis in paper: The empirical validation is restricted to "CityScapes, NYUv2, and NuScenes," which are all visual perception or autonomous driving benchmarks.
- Why unresolved: Multi-task dynamics in vision often rely on spatial feature sharing; it remains unclear if the observed "aligned MTO metrics" are universal or specific to convolutional/transformer-based vision architectures.
- What evidence would resolve it: Evaluation of AutoScale and the correlation analysis on standard MTL benchmarks from other domains (e.g., Multi-task RL environments or GLUE/NLP tasks).

## Limitations
- Assumes optimal weights exhibit consistent MTO metric trends across training stages, which may not hold for highly imbalanced tasks
- Limited validation on non-computer-vision domains, with all experiments focused on visual perception tasks
- Introduces additional hyperparameters (window size, optimization steps) in phase one that aren't thoroughly examined for sensitivity
- May not capture all relevant aspects of multi-task optimization dynamics with the chosen set of MTO metrics

## Confidence
- High: The 2-3× speedup claim over gradient-manipulating methods is well-demonstrated through ablation studies
- Medium: The generalizability claim across diverse datasets is supported but NuScenes remains the largest benchmark with more variable results on other datasets
- Medium: The assumption about consistent MTO metric trends during training is effective but not fully explored for edge cases

## Next Checks
1. Test AutoScale's performance when task relationships change dramatically during training
2. Evaluate sensitivity to local window optimization hyperparameters across different dataset scales
3. Compare AutoScale against non-linear scalarization methods on tasks with known optimal non-linear weight distributions