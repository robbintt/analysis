---
ver: rpa2
title: 'Geometric Stability: The Missing Axis of Representations'
arxiv_id: '2601.09173'
source_url: https://arxiv.org/abs/2601.09173
tags:
- stability
- shesha
- geometric
- across
- drift
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces geometric stability as a complementary axis
  to similarity for analyzing learned representations. While similarity metrics measure
  alignment with external references, stability quantifies the internal consistency
  of representational geometry under perturbation.
---

# Geometric Stability: The Missing Axis of Representations

## Quick Facts
- arXiv ID: 2601.09173
- Source URL: https://arxiv.org/abs/2601.09173
- Reference count: 40
- Key outcome: Introduces geometric stability as orthogonal axis to similarity for analyzing learned representations, showing near-zero correlation (ρ≈0.01) across 2,463 configurations in seven domains

## Executive Summary
This paper introduces geometric stability as a complementary axis to similarity for analyzing learned representations. While similarity metrics measure alignment with external references, stability quantifies the internal consistency of representational geometry under perturbation. The authors present Shesha, a framework that measures this stability through self-consistency of Representational Dissimilarity Matrices (RDMs). Across 2,463 configurations in seven domains, stability and similarity show near-zero correlation (ρ≈0.01) and capture mechanistically distinct information: similarity metrics collapse after removing top principal components, while stability retains sensitivity to fine-grained manifold structure.

## Method Summary
The Shesha framework measures geometric stability by computing the self-consistency of Representational Dissimilarity Matrices (RDMs) under controlled perturbations. The method compares how representation geometry changes when inputs are slightly modified, capturing the internal coherence of the representation space. This contrasts with similarity metrics that compare representations to external references. The framework was tested across seven diverse domains including vision, language, biology, and neuroscience, using 2,463 different configuration settings to establish the orthogonality of stability and similarity as measurement axes.

## Key Results
- Stability and similarity show near-zero correlation (ρ≈0.01) across 2,463 configurations, confirming they capture mechanistically distinct information
- Stability predicts linear controllability with strong correlations (ρ=0.89-0.96), while similarity metrics fail to capture this property
- Stability detects post-training alignment drift nearly 2× more sensitively than CKA while avoiding false alarms from rigid distance metrics

## Why This Works (Mechanism)
The framework works by quantifying the internal consistency of representational geometry rather than its alignment with external references. By measuring how RDMs change under perturbations, it captures the intrinsic structure of the representation space. This approach reveals information that similarity metrics miss, particularly fine-grained manifold structure that persists even after removing top principal components. The orthogonality emerges because stability measures self-consistency while similarity measures alignment, creating two complementary perspectives on representation quality.

## Foundational Learning
- **Representational Dissimilarity Matrices (RDMs)**: Square matrices capturing pairwise distances between representations; needed to quantify geometric structure; quick check: visualize as heatmaps to verify expected patterns
- **Principal Component Analysis (PCA)**: Dimensionality reduction technique; needed to show stability captures information beyond dominant directions; quick check: verify variance explained by top components
- **Linear Controllability**: Property measuring how easily representations can be manipulated through linear operations; needed to validate practical utility of stability; quick check: compute controllability metrics on benchmark datasets
- **Transferability**: Measure of how well representations generalize to new tasks; needed to identify "geometric tax" in transfer optimization; quick check: evaluate transfer performance across domains
- **CKA (Centered Kernel Alignment)**: Similarity metric for comparing representations; needed as baseline for drift detection; quick check: verify CKA values between identical representations equal 1

## Architecture Onboarding

**Component Map**: Input perturbations → RDM computation → Stability measurement → Correlation analysis with similarity metrics

**Critical Path**: Perturb inputs → Compute RDMs under perturbation → Measure self-consistency → Compare with external similarity metrics → Analyze correlation and predictive power

**Design Tradeoffs**: 
- High perturbation magnitude increases stability sensitivity but may break semantic relationships
- Complex perturbation schemes capture more geometric features but increase computational cost
- Self-consistency measures are computationally efficient but may miss certain invariances

**Failure Signatures**:
- High stability with poor downstream performance indicates over-regularization
- Low stability across all representations suggests insufficient training or unstable optimization
- Correlation between stability and similarity breaks down when representations become degenerate

**First 3 Experiments**:
1. Apply Shesha to pretrained vision transformers with varying layer depths to map stability progression
2. Compare stability metrics on representations trained with different regularization strengths
3. Test stability's predictive power for fine-tuning performance on held-out tasks

## Open Questions the Paper Calls Out
None

## Limitations
- The observed stability-dissimilarity separation may not generalize beyond tested domains and could be specific to certain representation geometries
- Strong correlation between stability and controllability requires careful interpretation due to multiple contributing factors
- The "geometric tax" concept in transfer optimization remains qualitative without rigorous theoretical grounding

## Confidence

| Claim | Confidence |
|-------|------------|
| Orthogonality of stability and similarity as measurement axes | High |
| Practical utility of stability for controllability prediction | Medium |
| Generalizability of stability benefits across all representation learning domains | Low |

## Next Checks
1. Test Shesha's stability metrics on representations from emerging architectures (e.g., state-space models, multimodal transformers) to verify domain generalizability
2. Conduct ablation studies removing different numbers of principal components to characterize the exact geometric features each metric captures
3. Design controlled experiments varying training objectives to systematically study the relationship between optimization pressure and the stability-transferability trade-off