---
ver: rpa2
title: Redefining Machine Translation on Social Network Services with Large Language
  Models
arxiv_id: '2504.07901'
source_url: https://arxiv.org/abs/2504.07901
tags:
- translation
- data
- language
- bleu
- wang
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of machine translation on social
  networking services (SNS), where existing models struggle with culturally nuanced
  content like memes, slang, and pop culture references. The authors propose RedTrans,
  a 72B parameter large language model tailored for SNS translation.
---

# Redefining Machine Translation on Social Network Services with Large Language Models

## Quick Facts
- arXiv ID: 2504.07901
- Source URL: https://arxiv.org/abs/2504.07901
- Reference count: 33
- Primary result: RedTrans-72B achieves 0.5030 BLEU on RedTrans-Bench vs. 0.4845 for DPO

## Executive Summary
This paper introduces RedTrans, a 72B parameter large language model specifically designed for machine translation on social networking services (SNS). Existing translation models struggle with culturally nuanced content such as memes, slang, and pop culture references common on social platforms. RedTrans addresses this gap through three key innovations: a novel unsupervised data selection method using dual-LLM back-translation sampling, a rewritten preference optimization algorithm for correcting erroneous preference pairs, and the first benchmark specifically designed for SNS translation. The model has been deployed in a real-world production environment, demonstrating that domain-specific adaptation effectively bridges the gap between generic and culturally grounded translation systems.

## Method Summary
RedTrans is built on Qwen-2.5-72B-Instruct and employs a two-stage training pipeline. First, Supervised Fine-tuning (SFT) uses a dual-LLM back-translation sampling approach where two LLMs independently forward-translate and back-translate candidate pairs, and data is stratified-sampled based on BLEU difference between the two translations. This unsupervised method selects diverse, high-quality data without requiring human annotations. Second, Rewritten Preference Optimization (RePO) addresses erroneous preference pairs by having experts rewrite low-quality translations when both candidates fall below a quality threshold, creating new preference pairs with the rewritten version. The model is trained on a combined corpus of 3.86M pairs (3.26M general + 600K SNS-specific) and evaluated on RedTrans-Bench, a newly introduced benchmark with 2,858 test cases specifically designed to evaluate SNS translation phenomena like humor localization, emoji semantics, and meme adaptation.

## Key Results
- RedTrans-72B (RePO) achieves 0.5030 BLEU on RedTrans-Bench, outperforming DPO baseline at 0.4845
- Model shows superior performance on culturally nuanced content including memes, slang, and pop culture references
- RedTrans outperforms state-of-the-art LLMs on multiple benchmarks including WMT22-24 and FLORES200
- Successful deployment in real-world production environment demonstrates practical effectiveness

## Why This Works (Mechanism)
RedTrans succeeds by addressing the fundamental challenge that SNS content contains cultural nuances, idioms, and context-dependent references that generic translation models miss. The dual-LLM back-translation sampling method creates a diverse training corpus by selecting data where different translation approaches yield different results, capturing linguistic variation. The RePO algorithm specifically targets and corrects erroneous preference pairs through expert intervention, ensuring the model learns from high-quality examples rather than propagating translation errors. The RedTrans-Bench benchmark provides proper evaluation of culturally-grounded translation phenomena that traditional MT benchmarks overlook.

## Foundational Learning
- **Dual-LLM Back-Translation Sampling**: Why needed: Creates diverse training data without human annotation costs; Quick check: Verify BLEU difference distribution across sampled pairs shows preference for higher variance ranges
- **Rewritten Preference Optimization (RePO)**: Why needed: Corrects systematic errors in preference learning; Quick check: Monitor reward margin improvements during RePO training
- **Cultural Translation Phenomena**: Why needed: Traditional BLEU doesn't capture meme adaptation or humor localization; Quick check: Evaluate RedTrans-Bench examples for cultural preservation
- **Large-Scale Preference Learning**: Why needed: Aligns model outputs with human preferences at scale; Quick check: Compare chosen vs rejected reward distributions post-training
- **SNS Domain Adaptation**: Why needed: Social media language differs significantly from formal text; Quick check: Test on out-of-domain SNS content from different time periods
- **Expert Annotation Protocols**: Why needed: Ensures quality control in preference corpus construction; Quick check: Verify inter-annotator agreement rates meet thresholds

## Architecture Onboarding
- **Component Map**: Qwen-2.5-72B-Instruct -> SFT (Dual-LLM Back-Translation) -> RePO (Expert Rewriting) -> RedTrans-Bench Evaluation
- **Critical Path**: Data collection → LLM-based quality filtering → Dual-LLM back-translation → Stratified sampling → SFT → Preference pair generation → Expert rewriting → RePO training → Benchmark evaluation
- **Design Tradeoffs**: The dual-LLM approach trades computational cost for data diversity, while expert rewriting adds human cost but improves preference quality. The 72B parameter model size balances performance with deployment feasibility.
- **Failure Signatures**: Poor performance on RedTrans-Bench indicates insufficient cultural adaptation; low BLEU improvement from SFT suggests ineffective data sampling; unstable RePO training indicates poor preference pair quality.
- **3 First Experiments**:
  1. Implement dual-LLM back-translation sampling and validate stratified sampling effectiveness on held-out data
  2. Run SFT with different sampling ranges to confirm optimal BLEU difference thresholds
  3. Test RePO with synthetic preference pairs to verify reward margin improvements

## Open Questions the Paper Calls Out
None

## Limitations
- Dataset construction lacks specification of exact LLM versions and quality estimators, making faithful reproduction impossible
- Generalization to other language pairs beyond English-Chinese remains untested
- Real-world deployment claims lack quantitative metrics on user satisfaction and production performance
- Expert annotation protocol details are insufficient for replication

## Confidence
**High Confidence**: Core methodological innovations are clearly described and theoretically sound, with reproducible experimental results on specified datasets
**Medium Confidence**: Ablation studies are internally consistent, but key hyperparameters (quality estimators, thresholds, LLM versions) are unspecified
**Low Confidence**: Cultural grounding claims rely heavily on newly introduced RedTrans-Bench; effectiveness on unseen cultural phenomena is speculative

## Next Checks
1. Replicate dual-LLM back-translation sampling with two distinct strong LLMs and validate stratified sampling effectiveness
2. Test RePO on diverse preference corpora with different quality estimators to ensure training stability
3. Evaluate RedTrans on temporally separated SNS data to assess handling of emerging cultural phenomena