---
ver: rpa2
title: 'Beyond Feature Importance: Feature Interactions in Predicting Post-Stroke
  Rigidity with Graph Explainable AI'
arxiv_id: '2504.08150'
source_url: https://arxiv.org/abs/2504.08150
tags:
- feature
- rigidity
- diag
- stroke
- post-stroke
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study predicts post-stroke rigidity using graph-based explainable
  AI, analyzing 519K stroke hospitalization records from the Healthcare Cost and Utilization
  Project. We developed incremental modeling that progressively incorporates clinical
  features, comparing traditional methods (Logistic Regression, XGBoost, Transformer)
  with graph-based models (Graphormer, GATv2) that inherently capture feature interactions.
---

# Beyond Feature Importance: Feature Interactions in Predicting Post-Stroke Rigidity with Graph Explainable AI

## Quick Facts
- arXiv ID: 2504.08150
- Source URL: https://arxiv.org/abs/2504.08150
- Reference count: 30
- AUROC 0.75 achieved with graph-based models, outperforming traditional ML approaches for post-stroke rigidity prediction

## Executive Summary
This study develops graph-based explainable AI models to predict post-stroke rigidity using 519K hospitalization records. By representing patient features as graph nodes and applying attention mechanisms, the approach captures feature interactions that traditional methods miss. The research demonstrates that NIH Stroke Scale and APR-DRG mortality risk scores are key predictors, with graph models revealing clinically relevant interaction pathways. The work advances interpretable AI for stroke prognosis, enabling early identification and personalized rehabilitation strategies.

## Method Summary
The study employs incremental modeling that progressively incorporates clinical features in four stages: admission demographics, during-hospital assessments, ICD diagnosis categories, and discharge variables. Five models are compared: Logistic Regression, XGBoost, Transformer, Graphormer, and GATv2. Graph models represent each patient's features as fully connected directed graphs, using attention mechanisms to capture feature interactions. Node attention provides feature importance while edge attention reveals interaction pathways. Model performance is evaluated using AUROC and accuracy metrics.

## Key Results
- Graph-based models achieved the best performance (AUROC 0.75) compared to traditional methods
- NIH Stroke Scale (NIHSS) and APR-DRG mortality risk scores emerged as key predictors
- Incremental modeling showed largest performance boost (approximately 11%) when adding during-hospital clinical assessments
- Graph models revealed feature interaction pathways missed by conventional approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Graph-based models capture feature interactions that traditional methods miss
- Mechanism: Patient clinical features become nodes in fully connected directed graphs; attention mechanisms compute edge weights representing how much one feature influences another's representation before prediction
- Core assumption: Clinical outcomes emerge from interactions among features, not just additive effects
- Evidence anchors:
  - Graph models revealed feature interaction pathways missed by conventional approaches
  - Table 4 shows specific interactions: PL_NCHS → APRDRG_Risk_Mortality (0.0051), ELECTIVE → APRDRG_Risk_Mortality (0.0049)
  - Related work confirms dataset-specific feature interactions are central to tabular data performance
- Break condition: If attention weights don't correspond to clinically meaningful relationships, interaction explanations become untrustworthy

### Mechanism 2
- Claim: Incremental modeling identifies when prediction becomes feasible during hospitalization
- Mechanism: Four sequential models add feature groups by clinical timeline; performance jumps reveal which information stage drives predictability
- Core assumption: Features become available at different times; identifying earliest reliable prediction point has clinical utility
- Evidence anchors:
  - Incremental modeling progressively incorporates clinical features
  - Largest boost (approximately 11%) from Model 2 when adding during-hospital clinical assessments
  - Mirrors clinical workflows
- Break condition: If target label is recorded before later feature stages, temporal causality is compromised

### Mechanism 3
- Claim: Node attention pooled globally provides patient-level feature importance; edge attention × node importance yields interaction explanations
- Mechanism: GATv2 computes αji = softmax(a^T LeakyReLU(W_left·h_i + W_right·h_j)); Graphormer uses dot-product attention. Global attention pooling aggregates node embeddings; βi weights indicate feature contribution. Interaction importance = αji × βi
- Core assumption: Attention weights can be interpreted as explanation strength (debated in literature)
- Evidence anchors:
  - Incorporate intrinsic or post-hoc explainability
  - Derive likelihood, feature importance, and feature interactions with example showing NIHSS contributes 10.259%, APRDRG_Risk_Mortality 14.841%
  - Acknowledges debate on whether attention metrics can be interpreted as explainability
- Break condition: If attention weights correlate poorly with ground-truth feature relevance, explanations mislead users

## Foundational Learning

- Concept: Graph Neural Networks (GNNs) with attention
  - Why needed here: Architecture represents features as nodes; understanding message passing and attention aggregation is prerequisite to interpreting outputs
  - Quick check question: Given nodes A, B, C with attention weights 0.5, 0.3, 0.2 to target node T, what does each weight represent?

- Concept: SHAP vs. intrinsic explainability
  - Why needed here: Compares post-hoc SHAP (Logistic Regression, XGBoost, Transformer) with intrinsic attention-based explanations (Graphormer, GATv2); understanding tradeoffs is essential
  - Quick check question: Why might post-hoc explanations fail to capture feature interactions that intrinsic methods capture?

- Concept: Clinical temporal prediction design
  - Why needed here: Incremental modeling mirrors clinical workflows; misalignment between feature availability and target label timing creates leakage
  - Quick check question: If discharge features are added (Model 4) but rigidity is diagnosed during hospitalization, what validity concern arises?

## Architecture Onboarding

- Component map:
  Input features → Graph construction (fully connected directed) → Node embedding (64-dim) → Attention layer (GATv2/Graphormer) → Global attention pooling → MLP with softmax → Binary rigidity prediction

- Critical path:
  1. Feature preprocessing → 2. Per-patient graph construction → 3. Node embedding (64-dim) → 4. Attention computation (captures interactions) → 5. Global pooling (captures importance) → 6. MLP prediction → 7. Extract βi (feature importance), αji×βi (interaction importance)

- Design tradeoffs:
  - Graphormer vs. GATv2: Different attention mechanisms yield slightly different interaction pathways
  - Intrinsic vs. post-hoc: Graph models avoid SHAP approximation error but inherit attention-as-explanation debates
  - Model complexity vs. interpretability: 68% accuracy / 0.75 AUROC reflects task difficulty; richer features could improve both

- Failure signatures:
  - Low AUROC (~0.56) with only admission features → insufficient signal before clinical assessments
  - High specificity, low sensitivity (e.g., Model 1 Graphormer: 0.894 specificity, 0.152 sensitivity) → class imbalance or threshold issues
  - Inconsistent top features across models → unstable explanations or task complexity

- First 3 experiments:
  1. Reproduce Model 2 (admission + assessments) with GATv2 on 10% data sample; verify AUROC approaches 0.72 and that APRDRG_Severity, APRDRG_Risk_Mortality, NIHSS appear in top features
  2. Extract edge attention matrix for 100 patients; manually inspect whether top interactions (e.g., ELECTIVE → APRDRG_Risk_Mortality) are clinically plausible per domain expert
  3. Compare SHAP interaction values (XGBoost) vs. graph attention interactions on same patients; quantify overlap in ranked interaction pairs using Spearman correlation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent would incorporating granular clinical assessments (e.g., imaging or biomarkers) improve the model's predictive performance beyond the achieved AUROC of 0.75?
- Basis in paper: Conclusion states that "richer feature sets—incorporating more detailed clinical assessments—could further improve both predictive accuracy and the granularity of feature interaction insights."
- Why unresolved: Study relies on administrative data (HCUP) which lacks high-resolution clinical details, potentially capping model performance
- What evidence would resolve it: Replicating framework on datasets with high-fidelity clinical variables and measuring performance gains

### Open Question 2
- Question: Do the feature interaction pathways identified by the graph models generalize to external, geographically diverse patient populations?
- Basis in paper: Conclusion explicitly calls for "validation across broader patient populations to strengthen the robustness and applicability of these findings."
- Why unresolved: While dataset is large (519K records), it represents specific source, and identified interactions may contain dataset-specific artifacts
- What evidence would resolve it: Testing trained graph models on independent stroke registries or international cohorts to verify stability of interaction edges

### Open Question 3
- Question: How can the reliability of attention-based feature interactions be verified to ensure they represent meaningful clinical relationships rather than spurious correlations?
- Basis in paper: Conclusion acknowledges that "The debate on whether attention metrics can be interpreted as explainability is ongoing" and calls for "more effort... to develop reliable XAI methods."
- Why unresolved: Attention weights provide mathematical proxy for interaction but don't guarantee causal validity, critical requirement for high-stakes clinical decision-making
- What evidence would resolve it: Systematic study comparing attention-based interactions against known clinical causal pathways or conducting randomized expert evaluations to validate clinical utility of explanations

## Limitations
- Attention-based explanations remain methodologically debated without clinical validation of identified interactions
- Class imbalance appears significant given high specificity but low sensitivity values in early models
- AUROC of 0.75, while showing graph models outperforming traditional approaches, still indicates substantial room for improvement

## Confidence

- Graph models achieving superior AUROC (0.75) compared to traditional methods: **High confidence** (statistically tested, consistent across models)
- Attention weights representing clinically meaningful feature interactions: **Low confidence** (methodologically debated, not clinically validated)
- Incremental modeling revealing clinical timeline importance: **Medium confidence** (supported by performance jumps but lacks temporal causality validation)

## Next Checks

1. Conduct clinician review of top 20 feature interactions identified by graph models to assess clinical plausibility and actionable insights
2. Perform ablation studies systematically removing individual features to verify reported importance weights correspond to actual performance degradation
3. Test model generalization on an independent stroke dataset from different healthcare system to confirm findings aren't dataset-specific artifacts