---
ver: rpa2
title: 'Chinchunmei at SemEval-2025 Task 11: Boosting the Large Language Model''s
  Capability of Emotion Perception using Contrastive Learning'
arxiv_id: '2507.15714'
source_url: https://arxiv.org/abs/2507.15714
tags:
- track
- emotion
- contrastive
- english
- label
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work explores two contrastive learning approaches\u2014sample-based\
  \ (Contrastive Reasoning Calibration) and generation-based (DPO, SimPO)\u2014to\
  \ enhance emotion perception in multilingual text-based emotion detection. The sample-based\
  \ method trains the model by comparing pairs of samples to generate more reliable\
  \ predictions, while the generation-based approach refines predictions by differentiating\
  \ between correct and incorrect outputs."
---

# Chinchunmei at SemEval-2025 Task 11: Boosting the Large Language Model's Capability of Emotion Perception using Contrastive Learning

## Quick Facts
- arXiv ID: 2507.15714
- Source URL: https://arxiv.org/abs/2507.15714
- Authors: Tian Li; Yujian Sun; Huizhi Liang
- Reference count: 25
- This work explores two contrastive learning approaches—sample-based (Contrastive Reasoning Calibration) and generation-based (DPO, SimPO)—to enhance emotion perception in multilingual text-based emotion detection

## Executive Summary
This paper investigates two contrastive learning approaches to improve emotion perception in large language models for multilingual emotion detection. The authors fine-tune LLaMa3-Instruct-8B using LoRA and evaluate both sample-based (comparing sample pairs) and generation-based (refining output predictions) contrastive methods. Their results show that while multilingual training degrades English performance due to cultural-linguistic conflicts, generation-based contrastive learning significantly improves intensity prediction. The system achieved 9th place in Track A and 6th place in Track B for English, ranking among top performers for other languages.

## Method Summary
The authors fine-tune LLaMa3-Instruct-8B with LoRA (rank=8, alpha=16) using three approaches: Standard Prediction (SFT), Contrastive Reasoning Calibration (CRC) for sample-based comparison, and preference optimization (DPO/SimPO) for generation-based refinement. For Track A (multi-label classification), they use English-only training and CRC with N=3 voting; for Track B (intensity prediction), they apply DPO with label mutation. All models are trained for 3 epochs with AdamW optimizer and cosine learning rate decay. The dev set (116 samples) is deemed unreliable due to label imbalance.

## Key Results
- Multilingual training degrades English emotion detection performance in both Track A and Track B
- Generation-based contrastive learning (DPO) significantly improves intensity prediction, with >90% of errors within one intensity level
- Sample-based contrastive learning (CRC) provides limited benefit and introduces additional uncertainty for ambiguous emotion cases
- The system achieved 9th place in Track A and 6th place in Track B for English

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DPO (Direct Preference Optimization) improves emotion intensity prediction (Track B) by refining the model's sensitivity to scoring granularity.
- Mechanism: DPO maximizes the relative log-probability ratio between correct (preferred) and incorrect (dispreferred) outputs using a reference model constraint (πref). This pushes the model to assign higher probability to correct intensity scores while suppressing mutated/incorrect scores. The reference model prevents catastrophic drift from the original distribution.
- Core assumption: Label mutation strategy (randomly altering intensity scores) generates meaningful negative examples that teach the model to discriminate fine-grained intensity differences.
- Evidence anchors:
  - [abstract] "DPO significantly improves Track B results"
  - [section 4.2] "In Track B, DPO secures the top position across all evaluation metrics except for anger and joy. Over 90% of errors differ from ground truth by only one intensity level."
  - [corpus] No direct DPO-for-emotion comparisons in neighbor papers; evidence is paper-specific.
- Break condition: When the reference model is removed (SimPO), formatting degrades and parsing errors increase, suggesting the reference model's constraint on output distribution is critical.

### Mechanism 2
- Claim: Sample-based contrastive learning (CRC) provides limited benefit and can introduce additional prediction uncertainty for ambiguous emotion cases.
- Mechanism: CRC trains the model to compare pairs of samples and generate contrastive summaries before predicting. During inference, each test sample is paired with N random training samples, and majority voting determines the final prediction.
- Core assumption: Training samples serve as stable reference anchors that reduce prediction uncertainty.
- Evidence anchors:
  - [abstract] "Sample-based contrastive learning yields limited benefit"
  - [section 4.2] "70% of the errors are due to the model incorrectly predicting a neutral emotional state... borderlines of anger definition... comparing them with other samples can easily influence their predictions, causing uncertainty and error"
  - [corpus] No neighbor papers validate CRC specifically; mechanism remains unconfirmed beyond this dataset.
- Break condition: When samples are inherently ambiguous or culturally dependent, comparison introduces noise rather than calibration.

### Mechanism 3
- Claim: Multilingual joint training degrades English emotion detection performance due to cultural-linguistic conflicts in emotion perception.
- Mechanism: Combining data from 28 languages creates conflicting supervision signals because emotion expression and labeling norms differ across cultures. The model cannot simultaneously optimize for all cultural contexts.
- Core assumption: Emotion perception is culturally contingent; what signals "anger" or "joy" intensity varies by linguistic community.
- Evidence anchors:
  - [abstract] "multilingual training degrades English performance due to cultural and linguistic differences in emotion perception"
  - [section 4.1] "multilingual training underperforms compared to English-only training in both Track A and Track B... significant differences in emotion perception across languages and cultural contexts can introduce conflicts"
  - [corpus] Neighbor papers (JNLP, CSIRO-LT) use multilingual models but don't isolate this degradation effect; evidence is paper-specific.
- Break condition: Assumption: If languages share similar cultural emotion expression norms, degradation may not occur (not tested).

## Foundational Learning

- **LoRA (Low-Rank Adaptation)**
  - Why needed here: All fine-tuning uses LoRA (rank=8, alpha=16) to reduce computational cost while adapting LLaMA3-8B.
  - Quick check question: Can you explain why LoRA allows training 8B-parameter models on limited GPUs without updating all weights?

- **Preference Optimization (DPO vs. SimPO)**
  - Why needed here: The paper compares reference-based (DPO) and reference-free (SimPO) preference optimization. Understanding the reference model's role is critical to interpreting why SimPO failed.
  - Quick check question: What does πref contribute to DPO's loss function, and what happens when you remove it (SimPO)?

- **Contrastive Learning Paradigms**
  - Why needed here: Two distinct contrastive approaches (sample-based vs. generation-based) are compared. Understanding what is being contrasted—samples vs. outputs—clarifies why they perform differently.
  - Quick check question: In CRC, what serves as the contrastive signal? In DPO, what serves as the contrastive signal?

## Architecture Onboarding

- **Component map:** LLaMA3-Instruct-8B -> LoRA fine-tuning (rank=8, alpha=16) -> SP/CRC/DPO training -> inference with voting (N=3 for Track A, N=7 for Track B)

- **Critical path:**
  1. Validate LLaMA3 tokenizer supports all 28 languages (encode/decode consistency check)
  2. Prepare SP dataset -> train SP model (English-only)
  3. Generate preference pairs via label mutation -> apply DPO
  4. Evaluate on test set (dev set unreliable due to small size and label imbalance)

- **Design tradeoffs:**
  - Multilingual vs. monolingual: Paper chose to submit multilingual for non-English, English-only for English—requires training separate models.
  - DPO vs. SimPO: DPO requires storing reference model (more memory); SimPO is simpler but lost formatting capability.
  - CRC voting N: Higher N increases inference cost; paper chose 3 and 7 pragmatically.

- **Failure signatures:**
  - SimPO output format corruption -> parsing errors (section 4.2)
  - CRC neutral prediction bias on ambiguous samples (70% of errors)
  - Dev set misleading results due to 116 samples with imbalanced labels (Appendix A.2)

- **First 3 experiments:**
  1. Replicate SP English-only baseline; confirm tokenizer consistency for target languages.
  2. Apply DPO with label mutation (5 mutations per Track A sample, 15 per Track B); verify >90% of Track B errors are within 1 intensity level.
  3. Run CRC inference with N=3 voting on a held-out English subset; manually inspect borderline cases where model predicts neutral to confirm uncertainty amplification.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why does multilingual training degrade English emotion detection performance, and can this negative transfer be mitigated through culturally-aware training strategies?
- Basis in paper: [explicit] Authors state: "experimental results indicate that incorporating non-English data degrades performance in both classification tasks (Track A) and scoring tasks (Track B)" and attribute this to "significant differences in emotion perception across languages and cultural contexts."
- Why unresolved: The paper identifies the problem but does not investigate whether cultural conflicts can be disentangled from beneficial cross-lingual transfer, or whether language-specific adapters/cultural prompting could preserve multilingual benefits.
- What evidence would resolve it: Ablation studies comparing joint multilingual training vs. language-specific adapter approaches, or experiments with culturally-grounded prompting that explicitly models regional emotion expression norms.

### Open Question 2
- Question: Why does DPO significantly improve intensity prediction (Track B) but show minimal benefit for classification (Track A)?
- Basis in paper: [explicit] Tables 1-2 show DPO achieves top performance across Track B metrics but marginal gains in Track A; authors note "generation-based contrastive learning provides consistent improvements in intensity prediction, though its effectiveness varies significantly across different techniques."
- Why unresolved: The paper does not explain whether the differential benefit stems from the ordinal nature of intensity scoring vs. binary classification, or from how preference optimization interacts with each task's label space.
- What evidence would resolve it: Controlled experiments varying label granularity (e.g., 2-class vs. 4-class vs. continuous intensity) to isolate whether DPO's advantage scales with prediction granularity.

### Open Question 3
- Question: Can samples unsuitable for contrastive comparison be automatically identified and filtered to improve CRC effectiveness?
- Basis in paper: [explicit] Bad case analysis revealed 70% of CRC anger misclassifications involved "borderline" cases where "comparing them with other samples can easily influence their predictions, causing uncertainty and error," leading authors to conclude "the dataset may not be well-suited for sample-based comparison approach."
- Why unresolved: The paper diagnoses the problem but does not propose a mechanism to detect or exclude ambiguous samples that introduce comparison noise.
- What evidence would resolve it: Development of an entropy-based or confidence-based filter that excludes low-certainty samples from CRC training pairs, with comparison of filtered vs. unfiltered CRC performance.

## Limitations
- The paper's contrastive learning claims rely heavily on paper-specific evidence rather than established literature
- Key hyperparameters (β, γ values for DPO/SimPO, LoRA target modules, random seeds, inference generation parameters) are unspecified
- The dev set's unreliability (116 samples, label imbalance) raises concerns about model selection validity
- The cultural-linguistic degradation claim lacks controlled experiments isolating cultural vs. linguistic factors

## Confidence
- High confidence: DPO improves Track B intensity prediction (supported by quantitative results showing >90% errors within one intensity level)
- Medium confidence: Multilingual training degrades English performance (supported by comparative results but lacking controlled experiments)
- Low confidence: Sample-based contrastive learning provides limited benefit (mechanism understood but evidence is paper-specific without external validation)

## Next Checks
1. Replicate the English-only SP baseline and verify that LLaMA3 tokenizer supports all 28 target languages consistently
2. Apply DPO with label mutation to the SP checkpoint and verify that Track B errors remain within one intensity level for >90% of cases
3. Run CRC inference with N=3 voting on a held-out English subset and manually inspect borderline cases to confirm uncertainty amplification in neutral predictions