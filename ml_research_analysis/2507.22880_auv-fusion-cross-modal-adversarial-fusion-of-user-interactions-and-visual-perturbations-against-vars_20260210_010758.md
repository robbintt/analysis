---
ver: rpa2
title: 'AUV-Fusion: Cross-Modal Adversarial Fusion of User Interactions and Visual
  Perturbations Against VARS'
arxiv_id: '2507.22880'
source_url: https://arxiv.org/abs/2507.22880
tags:
- user
- adversarial
- visual
- auv-fusion
- attacks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: AUV-Fusion is a novel adversarial attack framework designed to
  enhance the robustness testing of Visual-Aware Recommender Systems (VARS) by integrating
  user interaction data with visual perturbations. Unlike existing approaches that
  rely solely on visual modifications or require costly fake user profiles, AUV-Fusion
  combines a high-order user preference modeling module with a diffusion-based cross-modal
  adversary generation process.
---

# AUV-Fusion: Cross-Modal Adversarial Fusion of User Interactions and Visual Perturbations Against VARS

## Quick Facts
- **arXiv ID:** 2507.22880
- **Source URL:** https://arxiv.org/abs/2507.22880
- **Reference count:** 40
- **Primary result:** AUV-Fusion achieves higher HR@5 and AUC than baselines on Amazon Men and Tradesy.com datasets by integrating user interaction data with visual perturbations in VARS.

## Executive Summary
AUV-Fusion is a novel adversarial attack framework designed to enhance the robustness testing of Visual-Aware Recommender Systems (VARS) by integrating user interaction data with visual perturbations. Unlike existing approaches that rely solely on visual modifications or require costly fake user profiles, AUV-Fusion combines a high-order user preference modeling module with a diffusion-based cross-modal adversary generation process. This method captures deep user-item interaction patterns using graph convolution networks and injects user-aligned perturbations into the latent space of a diffusion model to produce visually plausible adversarial images. Experiments on real-world datasets (Amazon Men and Tradesy.com) across three VARS architectures (VBPR, DVBPR, and AMR) demonstrate that AUV-Fusion significantly improves the exposure of target (cold-start) items compared to baseline methods like INSA, EXPA, and SPAF. For instance, on the Amazon Men dataset with VBPR, AUV-Fusion achieves an HR@5 of 0.02047, outperforming INSA’s 0.00117 and SPAF’s 0.00241. The framework also maintains high imperceptibility, with user studies showing that participants could not distinguish adversarial images from original ones. Ablation studies confirm the importance of user alignment and adversarial injection for effectiveness and stability. AUV-Fusion sets a new benchmark for stealthy and effective attacks in VARS, addressing critical gaps in current adversarial research.

## Method Summary
AUV-Fusion integrates user interaction data with visual perturbations to enhance the robustness testing of Visual-Aware Recommender Systems (VARS). The method employs a high-order user preference modeling module based on graph convolution networks to capture deep user-item interaction patterns. These patterns are then used to inject user-aligned perturbations into the latent space of a diffusion model, producing visually plausible adversarial images. This cross-modal fusion approach allows AUV-Fusion to outperform existing methods like INSA, EXPA, and SPAF in terms of both effectiveness and stealthiness. The framework is evaluated on real-world datasets (Amazon Men and Tradesy.com) across three VARS architectures (VBPR, DVBPR, and AMR), demonstrating significant improvements in the exposure of target items while maintaining high imperceptibility.

## Key Results
- AUV-Fusion achieves an HR@5 of 0.02047 on the Amazon Men dataset with VBPR, significantly outperforming INSA (0.00117) and SPAF (0.00241).
- The framework maintains high imperceptibility, with user studies showing participants could not distinguish adversarial images from original ones.
- Ablation studies confirm the importance of user alignment and adversarial injection for effectiveness and stability.

## Why This Works (Mechanism)
AUV-Fusion works by integrating user interaction data with visual perturbations to create adversarial examples that are both effective and stealthy. The method leverages graph convolution networks to model high-order user preferences, capturing deep interaction patterns between users and items. These patterns are then used to inject user-aligned perturbations into the latent space of a diffusion model, ensuring that the resulting adversarial images are visually plausible and aligned with user preferences. This cross-modal fusion approach allows AUV-Fusion to bypass the limitations of existing methods that rely solely on visual modifications or require costly fake user profiles. By combining user interaction data with visual perturbations, AUV-Fusion can effectively manipulate VARS to expose target items while maintaining high imperceptibility.

## Foundational Learning
- **Graph Convolution Networks (GCNs):** Used to model high-order user preferences by capturing deep interaction patterns between users and items. *Why needed:* To understand complex user-item relationships beyond immediate interactions. *Quick check:* Ensure the GCN layer correctly aggregates neighborhood information and updates node embeddings.
- **Diffusion Models:** Employed to generate visually plausible adversarial images by injecting user-aligned perturbations into the latent space. *Why needed:* To create adversarial examples that are both effective and stealthy. *Quick check:* Verify that the diffusion model produces high-quality images with minimal artifacts.
- **Cross-Modal Fusion:** Integrates user interaction data with visual perturbations to create adversarial examples that are aligned with user preferences. *Why needed:* To bypass the limitations of existing methods that rely solely on visual modifications or require costly fake user profiles. *Quick check:* Ensure the fusion process effectively combines user and visual information without introducing noise or bias.

## Architecture Onboarding
- **Component Map:** User Interaction Data -> GCN -> User Preference Embeddings -> Diffusion Model -> Latent Space Perturbation -> Adversarial Images
- **Critical Path:** GCN -> User Preference Embeddings -> Diffusion Model -> Latent Space Perturbation
- **Design Tradeoffs:** Balancing the complexity of the GCN with the efficiency of the diffusion model; ensuring user alignment without sacrificing visual quality.
- **Failure Signatures:** Poor user preference modeling leading to ineffective perturbations; diffusion model producing low-quality or easily detectable adversarial images.
- **First Experiments:**
  1. Test the GCN’s ability to capture high-order user preferences on a small dataset.
  2. Evaluate the diffusion model’s capability to generate visually plausible images with minimal artifacts.
  3. Assess the effectiveness of user-aligned perturbations in manipulating VARS on a small-scale experiment.

## Open Questions the Paper Calls Out
The paper does not explicitly call out any open questions. However, it addresses the critical gap in current adversarial research by demonstrating the effectiveness and stealthiness of AUV-Fusion in manipulating VARS.

## Limitations
- The framework’s reliance on real-world datasets (Amazon Men and Tradesy.com) with limited size and domain specificity raises questions about generalizability to larger, more diverse e-commerce platforms.
- The user study assessing imperceptibility, while positive, involved only 20 participants without detailed demographic or expertise information, limiting confidence in the "stealthy" claim.
- The paper does not explore defense mechanisms or the robustness of VARS against AUV-Fusion-style attacks, leaving a critical gap in understanding real-world vulnerability.

## Confidence
- **High confidence:** Improved HR@5 metrics over baselines on tested datasets; effectiveness of user preference modeling via GCN; ablation study results showing importance of key components.
- **Medium confidence:** Claims of high imperceptibility based on user study; superiority over existing methods in terms of both effectiveness and stealth; stability of attack across different VARS architectures.
- **Low confidence:** Generalizability to other domains or larger datasets; computational efficiency and scalability; resistance to potential defense strategies.

## Next Checks
1. Evaluate AUV-Fusion on larger, more diverse e-commerce datasets (e.g., Amazon full dataset, eBay) to test scalability and domain transfer.
2. Conduct a larger-scale, demographically balanced user study with expert reviewers to validate imperceptibility claims.
3. Test AUV-Fusion against common adversarial defense mechanisms (e.g., adversarial training, input preprocessing) to assess practical robustness.