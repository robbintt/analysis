---
ver: rpa2
title: Measuring and Fostering Peace through Machine Learning and Artificial Intelligence
arxiv_id: '2601.05232'
source_url: https://arxiv.org/abs/2601.05232
tags:
- peace
- news
- media
- social
- columbia
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study aimed to measure peace levels in news and social media
  using machine learning and develop tools to promote peace by helping users understand
  their media consumption. Researchers trained neural networks on news data to classify
  peace levels with up to 97.48% accuracy, and used LLMs and emotion models to analyze
  YouTube transcripts for five peace-related dimensions.
---

# Measuring and Fostering Peace through Machine Learning and Artificial Intelligence

## Quick Facts
- arXiv ID: 2601.05232
- Source URL: https://arxiv.org/abs/2601.05232
- Reference count: 17
- Researchers trained neural networks on news data to classify peace levels with up to 97.48% accuracy.

## Executive Summary
This paper presents a multi-faceted approach to measuring and fostering peace through machine learning and AI. The research demonstrates that neural networks can classify peace levels from news text embeddings with high accuracy, while large language models (LLMs) outperform simpler emotion models for evaluating peace-related dimensions in video content. The work introduces MirrorMirror, a Chrome extension providing real-time feedback on YouTube video peacefulness, aiming to increase user awareness and potentially shift consumption toward less polarizing content.

## Method Summary
The research employs a two-pronged approach: First, news articles are embedded using OpenAI's text-embedding-3-small (1,536 dimensions) and classified using neural networks (CNN and feed-forward architectures) trained on the NOW corpus with binary peace labels. Second, YouTube transcripts are analyzed using both GoEmotions for word-level emotion detection and LLMs for holistic context understanding across five peace dimensions. The Chrome extension MirrorMirror provides real-time feedback by processing transcripts and displaying peace scores during video viewing.

## Key Results
- Neural networks achieved up to 97.48% accuracy in classifying peace levels from news text embeddings
- LLMs outperformed emotion-only models, achieving correlations up to r=0.773 with human expert annotations for peace dimensions
- MirrorMirror Chrome extension provides real-time feedback on YouTube video peacefulness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Neural networks can classify peace levels from news text embeddings with high accuracy and cross-dataset generalization.
- Mechanism: Pre-trained text embeddings encode semantic meaning; neural architectures learn distributed patterns that distinguish high-peace vs. low-peace discourse. Global semantic relationships across embedding dimensions capture subtle linguistic markers of peaceful language.
- Core assumption: Peace indices from external surveys validly proxy the "peacefulness" of national media discourse; linguistic markers generalize across countries and datasets.
- Evidence anchors: Researchers trained neural networks on news data to classify peace levels with up to 97.48% accuracy. When grouped and averaged at the country level, all three networks successfully classified every country in accordance with its peace label.
- Break condition: If peace indices don't reflect discourse quality, or if embeddings fail to capture pragmatic/conversational features (e.g., video transcripts), accuracy degrades. The paper shows failure on YouTube transcripts (95–100% classified as "high-peace").

### Mechanism 2
- Claim: LLMs outperform emotion-only models for evaluating peace-related social dimensions in video content because they capture context, framing, and rhetorical structure.
- Mechanism: LLMs process full transcripts holistically, integrating tone, implicit messaging, and narrative arc. GoEmotions fails due to limited context windows, high neutrality baselines (40–70%), and "averaging-out" of emotional volatility. LLMs can synthesize quantitative emotion features with contextual reasoning.
- Core assumption: Peace dimensions (compassion–contempt, nuance–simplistic, etc.) are observable constructs with sufficient inter-rater reliability for human grounding.
- Evidence anchors: LLMs outperformed simpler models, with correlations up to r=0.773 for peace dimensions. GoEmotions "lacking a broader, holistic understanding of the video's full narrative arc... process effectively erased the very nuance we intended to measure." Gemini 3 Pro Preview achieved the highest correlations across all five dimensions... +0.317 improvement over previous iterations in the challenging Nuance dimension.
- Break condition: If human annotations lack reliability, or if LLMs lack domain-specific knowledge (e.g., cultural context), correlations drop. The Nuance dimension remains challenging, suggesting retrieval-augmented or fact-aware models may be needed.

### Mechanism 3
- Claim: Real-time feedback on media peacefulness can increase user awareness and potentially shift consumption behavior toward less polarizing content.
- Mechanism: MirrorMirror provides immediate, interpretable metrics on peace dimensions during video viewing. This creates a feedback loop: users see their "media diet" reflected, which may motivate more intentional consumption choices. The mechanism relies on self-awareness as a precursor to behavior change.
- Core assumption: Users value peace-related feedback and will adjust behavior; feedback does not backfire (e.g., reinforcing outrage-seeking).
- Evidence anchors: MirrorMirror, a Chrome extension, provides real-time feedback to YouTube viewers about the peacefulness of the media they are watching. Content creators... are biased towards creating videos with emotional activation... We developed and tested a Chrome extension... to better understand the tone of their media creation and consumption. to do behavioral testing to measure the effects of MirrorMirror on users choice of videos—note: behavioral validation is planned, not yet completed.
- Break condition: If users ignore or dismiss feedback, or if feedback feels judgmental, engagement drops. Behavioral testing is required to validate causal impact.

## Foundational Learning

- Concept: **Text embeddings and semantic vector spaces**
  - Why needed here: The news classification pipeline depends on embedding models (e.g., OpenAI text-embedding-3-small) to convert articles into dense vectors. Understanding that embeddings encode semantic similarity—not just keyword matching—is essential for debugging classification failures.
  - Quick check question: Given two articles with similar embeddings but different explicit topics, would you expect a classifier to group them? Why or why not?

- Concept: **Transfer learning and domain shift**
  - Why needed here: The paper shows high accuracy on news (97.48%) but failure on YouTube transcripts (95–100% classified as high-peace). This illustrates domain shift: models trained on formal text don't generalize to conversational speech transcripts without adaptation.
  - Quick check question: A model trained on news articles is applied to podcast transcripts. What systematic differences might cause performance degradation?

- Concept: **Human-AI alignment and inter-rater reliability**
  - Why needed here: LLM outputs are evaluated against human expert annotations (r > 0.93 for three dimensions). Without reliable human ground truth, model benchmarking lacks validity. This is especially critical for subjective constructs like "compassion" or "nuance."
  - Quick check question: If two expert annotators disagree on a transcript's "nuance" score, what does that imply for training an AI model to predict it?

## Architecture Onboarding

- Component map: NOW corpus -> n-gram preprocessing -> OpenAI embeddings -> neural networks (CNN, feed-forward, revised CNN) -> binary peace classification. Transcript extraction -> GoEmotions + LLM -> 5-dimensional peace scoring. Real-time transcript processing -> model inference -> UI feedback overlay.

- Critical path: Embedding quality determines news classification accuracy. LLM prompt design and human-annotated gold standard determine YouTube scoring reliability. User trust in feedback metrics determines intervention effectiveness.

- Design tradeoffs: CNN vs. feed-forward: CNN captures local n-gram patterns; feed-forward integrates global semantics. Feed-forward slightly outperformed (97.48% vs. 97.24%). GoEmotions vs. LLM: GoEmotions is faster but context-limited; LLMs are slower but achieve higher human correlation (r = 0.773). Binary classification vs. multi-dimensional scoring: News uses binary; YouTube uses 5 dimensions. Binary is simpler but loses granularity.

- Failure signatures: News models on YouTube transcripts: 95–100% classified as "high-peace"—indicates domain shift from formal to conversational text. GoEmotions neutrality: 40–70% of transcript segments labeled "neutral," obscuring meaningful emotional cues. Averaging-out: Aggregated emotion scores mask volatility, erasing nuance.

- First 3 experiments:
  1. **Domain adaptation test**: Fine-tune news-trained models on a small labeled YouTube transcript dataset; measure accuracy improvement vs. zero-shot transfer.
  2. **LLM prompt ablation**: Compare LLM-only vs. LLM + GoEmotions hybrid prompting; isolate whether emotion features improve correlations with human annotations.
  3. **Behavioral pilot**: Deploy MirrorMirror to 20 users for 2 weeks; log video choices and self-reported awareness changes. Analyze whether exposure to feedback correlates with shifts in consumed content peacefulness.

## Open Questions the Paper Calls Out

- Does real-time peace feedback from MirrorMirror actually change users' video consumption patterns and lead to improved behaviors with others? The Discussion section states the need for "behavioral testing to measure the effects of MirrorMirror on users choice of videos and if those choices lead to improved behaviors with others." The current work only demonstrates technical feasibility of peace measurement and interface design; no longitudinal behavioral study has been conducted.

- Can neural networks trained on formal news text be effectively adapted to video transcripts, or do cross-domain differences require fundamentally different architectures? Section IV.A.4 reports that all news-trained networks exhibited "severe overgeneralization, classifying 95–100% of the videos as 'high-peace'" when applied to YouTube transcripts. The stylistic and pragmatic differences between written and spoken media (conversational fillers, immediacy, emotional activation) disrupt transfer learning.

- Would incorporating audio-visual features (tone of voice, facial expressions, imagery) significantly improve peace dimension classification accuracy beyond text-only analysis? The Results section lists "lack of multimodal cues" as a limitation and identifies "integrating audio-visual features" as a clear next step. Current models rely solely on transcript text, missing non-verbal signals that may carry substantial information about peaceful vs. inflammatory content.

- Can smaller, fine-tuned models achieve comparable peace dimension scoring to large LLMs like Gemini 3 Pro Preview for practical edge deployment? The paper explicitly calls for "developing smaller fine-tuned models for edge deployment" in the Multimodality and Agents discussion. The best-performing models (Gemini 3 Pro, GPT-5.1) require substantial compute; running these in real-time browser extensions may be impractical.

## Limitations

- Domain Generalization: The model's high accuracy on news text (97.48%) does not transfer to YouTube transcripts, with 95–100% classified as "high-peace," indicating significant domain shift between formal news and conversational video content.

- Ground Truth Reliability: Human expert annotations for YouTube peace dimensions, while correlated with LLM outputs (r up to 0.773), are subjective and may lack inter-rater reliability, especially for nuanced constructs like "nuance" and "compassion."

- Behavioral Impact Unproven: MirrorMirror's effectiveness at changing user behavior is hypothesized but not empirically validated; planned behavioral testing has not yet been completed.

## Confidence

- High Confidence: Neural networks can classify peace levels from news text embeddings with high accuracy when trained and tested on data from the same domain (NOW corpus).

- Medium Confidence: LLMs outperform emotion-only models for evaluating peace-related dimensions in video content, as evidenced by higher correlations with human annotations.

- Low Confidence: Real-time feedback on media peacefulness will increase user awareness and shift consumption behavior toward less polarizing content, as behavioral testing is pending.

## Next Checks

1. **Domain Adaptation Test**: Fine-tune news-trained models on a small labeled YouTube transcript dataset to measure accuracy improvement versus zero-shot transfer, addressing the domain shift issue.

2. **LLM Prompt Ablation**: Compare LLM-only versus LLM + GoEmotions hybrid prompting to isolate whether emotion features improve correlations with human annotations, clarifying the added value of hybrid approaches.

3. **Behavioral Pilot**: Deploy MirrorMirror to 20 users for two weeks, logging video choices and self-reported awareness changes, to analyze whether exposure to feedback correlates with shifts in consumed content peacefulness.