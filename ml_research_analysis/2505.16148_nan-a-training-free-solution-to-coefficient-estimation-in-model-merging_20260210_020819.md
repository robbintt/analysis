---
ver: rpa2
title: 'NAN: A Training-Free Solution to Coefficient Estimation in Model Merging'
arxiv_id: '2505.16148'
source_url: https://arxiv.org/abs/2505.16148
tags:
- merging
- arxiv
- task
- preprint
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of coefficient estimation in
  model merging, a technique for combining independently fine-tuned models into a
  unified one without access to raw data. Existing approaches often rely on heuristics
  or additional statistics to determine merging coefficients, limiting their scalability
  and generality.
---

# NAN: A Training-Free Solution to Coefficient Estimation in Model Merging

## Quick Facts
- **arXiv ID**: 2505.16148
- **Source URL**: https://arxiv.org/abs/2505.16148
- **Reference count**: 15
- **Primary result**: Training-free method using inverse parameter norm improves model merging performance by 2.5% on language tasks and 0.5-1.5% on vision/VLM tasks compared to baselines

## Executive Summary
NAN addresses the challenge of estimating merging coefficients in multi-task model merging without access to raw training data. The method proposes using the inverse of parameter norms as a proxy for task-specific information content, derived from theoretical analysis of least-squares optimization. NAN is a plug-and-play solution that works with various merging strategies and shows consistent performance improvements across vision, language, and VLM tasks. The approach is simple, training-free, and scalable to multiple models.

## Method Summary
NAN estimates merging coefficients by computing the inverse Frobenius norm of each fine-tuned model's weights, then normalizing these values to create a probability distribution over model contributions. The method is based on the theoretical insight that optimal merging weights should scale with task-specific information, which can be proxied by parameter norms under certain assumptions. NAN can be applied to raw weights or task vectors (fine-tuned minus pre-trained) and includes a global scaling factor for stability when merging many models. The approach works as a plugin to existing merging methods like Task Arithmetic and Ties-Merging.

## Key Results
- Improved average performance by 2.5% across four language benchmarks compared to best baseline
- Achieved 0.5-1.5% gains on vision and VLM tasks (SUN397, Cars, RESISC45, EuroSAT, SVHN, GTSRB, MNIST, DTD)
- Demonstrated consistent improvements across diverse architectures (ViT, LLaMA2, LLaVA) and tasks
- Showed effectiveness in both two-model and many-model merging scenarios

## Why This Works (Mechanism)

### Mechanism 1: Least-Squares Optimality of Data-Proportional Weighting
NAN's theoretical foundation comes from framing model merging as a joint least-squares optimization problem. The optimal merged model is a weighted average of individual task models, where weights correspond to the information content (sample size) of each task. Under normalized input features, the optimal solution uses sample-size-weighted averaging, where $X^T X$ approximates sample size $n$. This provides the theoretical justification for using data-proportional weighting in merging.

### Mechanism 2: Inverse Parameter Norm as a Training Volume Proxy
The method leverages the statistical relationship between weight variance and training data volume: variance decreases as data volume increases ($n \propto 1/\text{Var}(W)$). Since most fine-tuned weights are approximately zero-centered, the variance is proportional to the squared norm. Therefore, models with larger norms likely saw less data, and NAN weights these models lower using the inverse norm $1/\|W\|_F$ as a proxy for optimal merging coefficients.

### Mechanism 3: Stable Normalization for Aggregation
To prevent numerical instability from large scaling disparities between models, NAN normalizes the inverse norms to create a stable probability distribution. A global scaling factor ($m/2$) is applied to the final merged weights to maintain magnitude parity with base models, preventing signal dilution when merging many models. This normalization ensures comparability across heterogeneous tasks.

## Foundational Learning

- **Concept**: **Frobenius Norm**
  - **Why needed here**: This is the core metric NAN uses to estimate "task importance" as a proxy for parameter variance
  - **Quick check question**: If Model A has a Frobenius norm of 100 and Model B has 10, which model does NAN consider "richer" in specific information, and which coefficient will be larger?

- **Concept**: **Task Arithmetic (Model Merging)**
  - **Why needed here**: NAN is a "plugin" for methods like Task Arithmetic that add/subtract weight vectors to modify a base model
  - **Quick check question**: In Task Arithmetic, how is a "task vector" defined, and where does NAN's coefficient $\alpha$ fit into the equation $\theta_{new} = \theta_{pretrained} + \sum \alpha_i \tau_i$?

- **Concept**: **Linear Regression (Least Squares)**
  - **Why needed here**: The theoretical justification comes from linear algebra solutions to least squares problems where $(X^T X)$ represents data covariance
  - **Quick check question**: Why does the matrix $X^T X$ relate to "information content" or sample size in a least-squares solution?

## Architecture Onboarding

- **Component map**: Pre-trained model -> Fine-tuned models $\{W_1, \dots, W_m\}$ -> Norm Calculator -> Coefficient Estimator -> Merger -> Scaler -> Merged model

- **Critical path**: The exact calculation of the Frobenius norm across all parameters. If implementation aggregates layer-wise norms incorrectly or skips bias terms, the proxy for "data volume" will be biased.

- **Design tradeoffs**:
  - **Weight vs. Task Vector**: Applying to *task vectors* (fine-tuned minus pre-trained) likely yields a purer signal of "added information" versus raw weights including base knowledge
  - **Squared vs. Linear Norm**: The paper chooses linear norm ($L_2$) over squared norm ($L_2^2$) for stability, as squared norms would exaggerate differences between models

- **Failure signatures**:
  - **Heterogeneous Architectures**: NAN fails if models have different backbones, as parameter counts and norm scales are incomparable
  - **Non-Zero-Center Data**: If weight updates are not zero-centered (e.g., massive bias shift in one layer), the variance proxy breaks
  - **Dominated Merging**: With one very "small norm" model and many "large norm" models, NAN might over-prioritize the single small-norm model, potentially ignoring useful sparse features from others

- **First 3 experiments**:
  1. **Single-Domain Validation**: Take two models fine-tuned on the same dataset but with different seeds/subsets of known sizes. Verify that NAN assigns higher coefficients to the model trained on more data or produces merged accuracy â‰¥ either individual model.
  2. **Baseline Integration**: Implement NAN on Task Arithmetic using ViT-B/32 backbone. Reproduce the ~1-2% average lift over standard Task Arithmetic to validate the pipeline.
  3. **Ablation on Norm Type**: Compare merging performance using (a) Inverse Frobenius Norm, (b) Inverse Squared Frobenius Norm, and (c) Uniform coefficients. Test specifically on tasks where one model is significantly larger/overfitted (high norm) than others.

## Open Questions the Paper Calls Out

- **Open Question 1**: Can NAN be adapted to merge models with heterogeneous architectures or distinct pre-trained backbones? The authors explicitly state the method focuses on shared backbones and may require adaptation for heterogeneous architectures.

- **Open Question 2**: Does the theoretical justification based on linear least-squares optimization hold for highly non-linear deep networks? The method is derived using linear regression formulations yet applied to complex Vision Transformers and LLMs.

- **Open Question 3**: Is the inverse parameter norm a reliable proxy for sample size when fine-tuning involves aggressive regularization or varying learning rates? Weight norms are heavily influenced by optimization hyperparameters independently of dataset size.

## Limitations
- Method assumes shared backbones and cannot directly handle heterogeneous architectures
- Theoretical justification relies on linear least-squares assumptions that may not hold for complex deep networks
- Inverse norm proxy may be unreliable when fine-tuning involves aggressive regularization or non-zero mean shifts

## Confidence
- **High**: Experimental results showing consistent improvements over baselines (2.5% average lift on language tasks, +0.5% to +1.5% on vision/VLM tasks) are robust and reproducible
- **Medium**: Theoretical justification for inverse norm proxy is sound under stated assumptions, but these assumptions are not empirically validated
- **Medium**: Simplicity and plug-and-play nature are clearly demonstrated, but generality across all merging strategies and architectures is assumed rather than proven

## Next Checks
1. **Controlled Norm-Size Correlation**: Fine-tune two models on the same dataset with controlled, different subset sizes. Measure if NAN's inverse norm coefficients correlate with true data volumes, validating the proxy assumption.

2. **Ablation on Parameter Scope**: Compare merging performance using (a) Inverse Frobenius Norm of full weights, (b) Inverse Frobenius Norm of task vectors only, and (c) Inverse norm restricted to specific layers (e.g., classification head).

3. **Interaction with Task Arithmetic Baseline**: Implement NAN on Task Arithmetic with ViT-B/32 on two vision tasks. Verify the reported ~1-2% average lift over standard Task Arithmetic to validate the basic pipeline.