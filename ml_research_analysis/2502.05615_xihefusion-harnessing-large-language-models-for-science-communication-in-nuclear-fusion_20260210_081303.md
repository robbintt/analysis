---
ver: rpa2
title: 'XiHeFusion: Harnessing Large Language Models for Science Communication in
  Nuclear Fusion'
arxiv_id: '2502.05615'
source_url: https://arxiv.org/abs/2502.05615
tags:
- fusion
- nuclear
- large
- xihefusion
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: XiHeFusion is the first large language model specifically developed
  for nuclear fusion science communication. Built on Qwen2.5-14B via supervised fine-tuning,
  it integrates multi-source fusion knowledge and employs chain-of-thought reasoning
  to enhance logical, detailed responses.
---

# XiHeFusion: Harnessing Large Language Models for Science Communication in Nuclear Fusion

## Quick Facts
- **arXiv ID**: 2502.05615
- **Source URL**: https://arxiv.org/abs/2502.05615
- **Reference count**: 40
- **Primary result**: First LLM specifically developed for nuclear fusion science communication, achieving strong performance in answering fusion-related queries with bilingual support.

## Executive Summary
XiHeFusion is a specialized large language model developed to enhance public understanding and engagement in nuclear fusion research. Built on Qwen2.5-14B via supervised fine-tuning, it integrates multi-source fusion knowledge and employs chain-of-thought reasoning to deliver logical, detailed responses. The model supports bilingual dialogue (Chinese/English) and includes a custom 180+ question test set for evaluation. Extensive experiments demonstrate strong performance in answering fusion-related queries, with improved accuracy and depth when using CoT prompting. Results show XiHeFusion matches or exceeds strong LLMs like DeepSeek V3 and Baichuan 2 on fusion tasks. The model is open-sourced and designed to accelerate public understanding and engagement in fusion energy research.

## Method Summary
XiHeFusion is developed by fine-tuning Qwen2.5-14B using supervised learning on curated nuclear fusion knowledge sources. The model incorporates chain-of-thought reasoning to improve logical response generation. A custom test set of 180+ questions is created for evaluation, covering both Chinese and English queries. The model's performance is benchmarked against selected LLMs (DeepSeek V3, Baichuan 2, Qwen2.5-14B) on fusion-specific tasks, demonstrating strong accuracy and depth in responses.

## Key Results
- XiHeFusion achieves strong performance in answering fusion-related queries, with improved accuracy and depth using CoT prompting.
- The model matches or exceeds strong LLMs like DeepSeek V3 and Baichuan 2 on fusion-specific tasks.
- Supports bilingual dialogue (Chinese/English) and is open-sourced for public use.

## Why This Works (Mechanism)
The model leverages supervised fine-tuning on Qwen2.5-14B, integrating multi-source fusion knowledge and employing chain-of-thought reasoning to enhance logical, detailed responses. This approach enables XiHeFusion to provide accurate, contextually rich answers to fusion-related queries, addressing the need for specialized science communication in the nuclear fusion domain.

## Foundational Learning
- **Supervised Fine-Tuning**: Why needed: To adapt a general-purpose LLM to the specialized domain of nuclear fusion. Quick check: Verify the quality and relevance of the fine-tuning dataset.
- **Chain-of-Thought Reasoning**: Why needed: To improve logical flow and depth in responses. Quick check: Evaluate the coherence and correctness of CoT-generated answers.
- **Bilingual Support**: Why needed: To reach a broader audience and facilitate international collaboration. Quick check: Test model performance in both Chinese and English on fusion queries.

## Architecture Onboarding
- **Component Map**: Qwen2.5-14B -> Supervised Fine-Tuning -> Fusion Knowledge Integration -> Chain-of-Thought Reasoning -> Bilingual Response Generation
- **Critical Path**: Supervised fine-tuning on fusion knowledge → CoT reasoning → Response generation
- **Design Tradeoffs**: Specialized domain knowledge vs. general-purpose versatility; bilingual support vs. depth in a single language
- **Failure Signatures**: Potential overfitting to internal test set; reduced performance on ambiguous or low-resource queries
- **First Experiments**: 1) Benchmark against a wider range of LLMs; 2) Conduct third-party evaluations with independent test sets; 3) Perform comprehensive error analysis and user studies

## Open Questions the Paper Calls Out
None

## Limitations
- Lack of independent benchmarking against a broader set of LLMs limits generalizability of performance claims.
- Custom test set not validated by external reviewers, raising concerns about bias or overfitting.
- No reinforcement learning or human feedback loops mentioned, potentially constraining adaptability to evolving fusion knowledge.

## Confidence
- **High**: Development process (supervised fine-tuning on Qwen2.5-14B, integration of multi-source fusion knowledge) and core functionality (bilingual support, chain-of-thought reasoning) are well-documented and reproducible.
- **Medium**: Claims of superior or comparable performance to selected LLMs are supported by experiments but lack broader external validation.
- **Low**: Assertions about accelerating public understanding and engagement are aspirational and not empirically substantiated within the paper.

## Next Checks
1. Conduct third-party evaluations using an independently curated, diverse test set of fusion-related questions to assess model robustness and avoid potential overfitting.
2. Benchmark XiHeFusion against a wider range of state-of-the-art general-purpose and domain-specific LLMs to establish relative performance more definitively.
3. Perform a comprehensive error analysis, including failure mode identification and user studies, to quantify model reliability and usability in real-world science communication contexts.