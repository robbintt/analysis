---
ver: rpa2
title: Sentiment-guided Commonsense-aware Response Generation for Mental Health Counseling
arxiv_id: '2501.03088'
source_url: https://arxiv.org/abs/2501.03088
tags:
- empres
- commonsense
- knowledge
- generation
- responses
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of generating effective responses
  in mental health counseling by virtual assistants. It proposes a novel method called
  EmpRes, which uses sentiment-guided commonsense-aware response generation.
---

# Sentiment-guided Commonsense-aware Response Generation for Mental Health Counseling

## Quick Facts
- arXiv ID: 2501.03088
- Source URL: https://arxiv.org/abs/2501.03088
- Reference count: 40
- One-line primary result: EmpRes achieves +12.26% BERTScore and +51.28% METEOR improvements over baselines on the HOPE dataset

## Executive Summary
EmpRes introduces a novel method for mental health counseling response generation that leverages sentiment-guided commonsense knowledge to positively influence client sentiment. The system uses a graph-based architecture to incorporate both dialogue context and sentiment-conditioned commonsense inferences, enabling more therapeutically appropriate responses. Evaluated on the HOPE dataset, EmpRes significantly outperforms 12 baselines across five metrics and demonstrates strong user acceptance in deployment studies.

## Method Summary
EmpRes combines sentiment pseudo-labeling with conditional commonsense knowledge extraction to generate therapeutic responses. The method constructs two parallel graphs: SC-Graph captures dialogue structure with speaker and temporal edges, while SGCR-Graph encodes sentiment-conditioned commonsense knowledge from COMET. These graphs are processed through Graph Attention Networks and fused into GPT-2's attention mechanism, allowing the model to attend to both contextual and knowledge-enriched representations during generation.

## Key Results
- +12.26% improvement in BERTScore over baselines
- +51.28% improvement in METEOR over baselines
- 91% of users found the system effective in deployment study
- 80% user satisfaction rate reported
- Over 85% willingness to continue using and recommending the system

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Conditionally selecting commonsense relations based on client sentiment produces more therapeutically appropriate responses than uniform knowledge extraction.
- Mechanism: The Knowledge Extractor routes to different COMET relation types: for negative client sentiment, it retrieves `oReact` and `oWant` (what others feel/want for the client, enabling consolation); for positive sentiment, it retrieves `xReact`, `xWant`, `xIntent` (self-focused attributes to reinforce positive states). Top-5 inferences per utterance are encoded and structured into SGCR-Graph.
- Core assumption: Clients in negative states benefit from external (other-oriented) perspectives, while clients in positive states benefit from self-reinforcing introspection—a pattern grounded in cited psychological theories (Amutio et al., 2015; Karkar et al., 2021).
- Evidence anchors:
  - [abstract] "EmpRes leverages commonsense knowledge and sentiment guidance to influence clients' sentiments positively."
  - [Section IV-B] "For utterances expressing positive sentiments, we select COMET relations such as xReact, xWant, and xIntent... Conversely, for utterances reflecting negative sentiments, we employ COMET relations such as oReact and oWant."
  - [corpus] Weak direct evidence—neighbor papers focus on empathy and stage recognition (EmoStage) or preference learning, but do not specifically validate sentiment-conditional knowledge routing.
- Break condition: If sentiment labels are inaccurate (pseudo-labeling noise), or if COMET retrieves irrelevant/commonsensically weak inferences for domain-specific counseling language, the conditional routing may inject noise rather than signal.

### Mechanism 2
- Claim: Fusing speaker-context structure with sentiment-guided commonsense knowledge yields richer dialogue representations than either alone.
- Mechanism: Two parallel graphs—SC-Graph (utterance nodes connected to speaker labels and sequential edges) and SGCR-Graph (knowledge representation nodes connected to speakers and temporal flow)—are each processed through Graph Attention layers (GAT-SC, GAT-SGCR). Their outputs are concatenated and fed as keys/values to the decoder's attention.
- Core assumption: Counseling effectiveness depends on both structural context (who said what, when) and semantic-pragmatic enrichment (commonsense implications of what was said).
- Evidence anchors:
  - [Section IV-A & IV-B] Formal definitions of SC-Graph and SGCR-Graph structures with edge semantics.
  - [Section V-C Ablation] Removing SC-Graph drops BERTScore from 0.8532 to 0.7654; removing SGCR-Graph drops it to 0.6363—both components contribute substantively.
  - [corpus] No direct corpus validation; neighbor works like CEM and CoMAE use multi-factor empathy frameworks but do not compare graph-fusion vs. single-stream architectures.
- Break condition: If dialogue context exceeds typical session length, graph attention may struggle with long-range dependencies; if knowledge extraction produces sparse or generic outputs, SGCR-Graph provides diminishing returns.

### Mechanism 3
- Claim: Modifying GPT-2's attention to accept external graph representations as keys/values enables controlled, knowledge-grounded generation without fine-tuning a larger model.
- Mechanism: Knowledge Aware Attention replaces standard self-attention keys/values with fused GAT-SC and GAT-SGCR representations. Queries remain from the decoder's previous layer. This cross-attention-style modification injects structured external context while preserving GPT-2's generative capabilities.
- Core assumption: Smaller models (GPT-2) allow more effective control over external knowledge injection than larger models where internal representations may dilute external signals.
- Evidence anchors:
  - [Section IV-C] "The parametric size of GPT-2 (and others) is particularly suitable for our approach, as it allows for effective control of external knowledge without introducing significant noise."
  - [Section V-B] EmpRes outperforms DialoGPT, ProphetNet-Dialog, and DialogVED across all metrics.
  - [corpus] Neighbor papers (e.g., Psy-Copilot, PAIR-SAFE) use LLMs with chain-of-thought or paired-agent auditing but do not evaluate modified attention mechanisms.
- Break condition: If the knowledge representations are misaligned with the decoder's query space, attention may attend to irrelevant graph nodes, producing incoherent or hallucinated responses (20% of users in the study observed minor hallucinations).

## Foundational Learning

- Concept: **Graph Attention Networks (GAT)**
  - Why needed here: Both SC-Graph and SGCR-Graph rely on GAT layers to compute attention-weighted node representations, enabling selective focus on salient utterances/knowledge.
  - Quick check question: Can you explain how GAT differs from GCNs in aggregating neighbor information, and why attention weights matter for dialogue context?

- Concept: **COMET Commonsense Relations**
  - Why needed here: The model conditionally selects from nine ATOMIC-style relations (xAttr, oReact, xWant, etc.); understanding their semantics is essential for debugging knowledge extraction.
  - Quick check question: Given a client utterance "I feel hopeless about my job," what would `oWant` versus `xIntent` likely generate, and which would EmpRes use if sentiment is negative?

- Concept: **Cross-Attention in Decoder-Only Models**
  - Why needed here: EmpRes modifies GPT-2's self-attention to accept external keys/values—conceptually similar to encoder-decoder cross-attention but applied within a decoder-only architecture.
  - Quick check question: How does injecting external representations as K/V (while keeping Q from the decoder) change what the model attends to during generation?

## Architecture Onboarding

- Component map:
  ```
  Input Dialogue → [Sentiment Pseudo-Labeler (BERT+COMET xAttr)]
                  ↓
  [COMET Knowledge Extractor] ← (sentiment-conditional relation selection)
                  ↓
  SC-Graph ← Utterance Encoder (BERT)    SGCR-Graph ← Knowledge Encoder (BERT)
       ↓                                        ↓
  GAT-SC                                    GAT-SGCR
       └──────────────┬─────────────────────────┘
                      ↓ (concatenated K, V)
              [GPT-2 Decoder w/ Knowledge Aware Attention]
                      ↓
                Generated Response
  ```

- Critical path: Sentiment labeling → COMET relation selection → Graph construction → GAT encoding → Fused representations → Modified GPT-2 attention → Response generation. Errors in sentiment labeling cascade to relation selection and graph quality.

- Design tradeoffs:
  - GPT-2 vs. larger LLMs: Authors explicitly chose GPT-2 for controllability; larger models may dilute external knowledge signal.
  - Pseudo-labeling vs. gold sentiment: Dataset lacked sentiment labels; pseudo-labeling introduces noise but enables training.
  - Top-5 knowledge inferences: Balances richness vs. noise; fewer may miss signal, more may introduce irrelevant content.

- Failure signatures:
  - Generic/uninfluential responses: Often trace to weak knowledge extraction or missing sentiment signal.
  - Hallucinated content: May indicate attention attending to noisy graph nodes; ~20% of users observed minor hallucinations.
  - Inconsistent therapeutic tone: Can result from SC-Graph failing to capture speaker context adequately.

- First 3 experiments:
  1. **Sanity check**: Run sentiment pseudo-labeler on held-out HOPE utterances; manually verify label accuracy to establish baseline noise floor.
  2. **Ablation replication**: Train EmpRes, then separately disable SC-Graph and SGCR-Graph to reproduce ablation results (target: ~0.77 and ~0.64 BERTScore respectively).
  3. **Relation sensitivity**: For a fixed set of negative-sentiment utterances, compare responses using `{oReact, oWant}` vs. all nine COMET relations to validate conditional selection rationale.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the EmpRes architecture be adapted to handle high-risk scenarios, such as suicidal ideation, and extended to support multilingual counseling contexts?
- Basis in paper: [explicit] The authors explicitly list "scope of improvement in certain aspects, such as the model’s ability to handle extreme cases such as suicidal thoughts and accommodate linguistic diversity such as languages other than English" in the Limitations section (Section VII).
- Why unresolved: The current model and the HOPE dataset focus primarily on general sentiment stabilization rather than crisis intervention, and the implementation is strictly monolingual (English).
- What evidence would resolve it: Successful evaluation on crisis-specific datasets (e.g., containing self-harm intent) and cross-lingual benchmarks demonstrating safe, effective response generation in non-English languages.

### Open Question 2
- Question: How can the Knowledge Aware Attention mechanism be refined to minimize the hallucinations observed during the deployment user study?
- Basis in paper: [explicit] The Deployment Limitations section notes that approximately 76% of participants reported "occasional minor hallucination," highlighting the need for better control over the model's generation (Section VI.D).
- Why unresolved: While commonsense knowledge guides the response, the underlying generative capabilities of GPT-2 still produce plausible but unsupported statements, indicating the attention mechanism does not fully ground the output.
- What evidence would resolve it: A modified architecture that demonstrates a statistically significant reduction in hallucination rates in a subsequent user study or via automated faithfulness metrics.

### Open Question 3
- Question: Does the efficacy of explicit commonsense integration diminish when applied to larger foundation models compared to the GPT-2 base used in this study?
- Basis in paper: [explicit] The authors justify selecting GPT-2 by stating, "Larger models, while more powerful, tend to dilute the impact of external knowledge" (Section IV.C).
- Why unresolved: This claim is stated as a justification for model selection but is not empirically tested against larger state-of-the-art models within the paper.
- What evidence would resolve it: A comparative ablation study applying the EmpRes framework to varying sizes of Large Language Models (LLMs) to measure the marginal utility of the external knowledge graph.

### Open Question 4
- Question: How can the system be transitioned from a preliminary stabilization module to a comprehensive, end-to-end treatment framework?
- Basis in paper: [explicit] The authors state that the system "serves as a crucial preliminary module within an end-to-end VMHA framework" rather than a complete treatment solution (Section VII).
- Why unresolved: The current methodology focuses on immediate sentiment influence (making the client receptive) but lacks the components necessary for long-term therapeutic strategy or sustained mental health management.
- What evidence would resolve it: Longitudinal studies integrating EmpRes with downstream therapeutic tasks (e.g., Cognitive Behavioral Therapy exercises) to measure sustained client improvement.

## Limitations
- The method's performance depends heavily on pseudo-labeled sentiment labels, but the pseudo-labeling pipeline's accuracy and validation are not reported.
- Critical architectural details for GAT layers and the Knowledge-Encoder are underspecified, limiting reproducibility.
- The claim that GPT-2 is "particularly suitable" for knowledge injection lacks comparative evidence against other model sizes.
- Human evaluation results are promising but not statistically tested.
- User-study hallucinations (~20%) suggest potential reliability concerns.

## Confidence

**High confidence**: BERTScore and METEOR improvements over baselines are well-supported by quantitative results.

**Medium confidence**: The sentiment-conditional commonsense routing mechanism is plausible but lacks direct validation beyond ablation; pseudo-labeling introduces uncertainty.

**Low confidence**: Claims about GPT-2's suitability for knowledge injection, and human evaluation superiority over gold responses, lack rigorous statistical or comparative support.

## Next Checks

1. **Validate pseudo-labeling pipeline**: Run the BERT+COMET sentiment classifier on a held-out subset of HOPE and manually assess accuracy to establish the noise floor in sentiment labels.

2. **Replicate GAT ablation**: Train EmpRes and separately disable SC-Graph and SGCR-Graph to reproduce the BERTScore drops (~0.77 and ~0.64) and confirm both components are essential.

3. **Test conditional knowledge routing**: For a fixed set of negative-sentiment utterances, generate responses using all nine COMET relations versus only {oReact, oWant}, and evaluate whether the restricted set yields more therapeutically appropriate outputs.