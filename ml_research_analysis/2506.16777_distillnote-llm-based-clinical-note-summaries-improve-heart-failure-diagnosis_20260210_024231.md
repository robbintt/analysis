---
ver: rpa2
title: 'DistillNote: LLM-based clinical note summaries improve heart failure diagnosis'
arxiv_id: '2506.16777'
source_url: https://arxiv.org/abs/2506.16777
tags:
- note
- admission
- summaries
- clinical
- summary
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'DistillNote is a framework for LLM-based clinical note summarization
  that generates admission note summaries to improve heart failure diagnosis. It employs
  three summarization strategies: one-step direct summarization, structured summarization
  that independently extracts clinical insights (chief complaint, medical history,
  exam findings, social history), and distilled summarization that further condenses
  structured summaries.'
---

# DistillNote: LLM-based clinical note summaries improve heart failure diagnosis
## Quick Facts
- arXiv ID: 2506.16777
- Source URL: https://arxiv.org/abs/2506.16777
- Reference count: 40
- DistillNote achieves 79% text compression while maintaining 95.8% of baseline F1-score performance for heart failure diagnosis

## Executive Summary
DistillNote is an LLM-based framework that generates clinical note summaries to improve heart failure diagnosis from admission notes. The framework employs three summarization strategies: one-step direct summarization, structured summarization that independently extracts clinical insights (chief complaint, medical history, exam findings, social history), and distilled summarization that further condenses structured summaries. The system was evaluated using over 64,000 admission notes, demonstrating that structured summaries achieved the highest diagnostic performance while distilled summaries achieved 79% compression with minimal performance loss. The divide-and-conquer approach significantly reduced hallucinations compared to one-step summarization.

## Method Summary
DistillNote was developed as a comprehensive framework for clinical note summarization using large language models. The system processes admission notes through three distinct summarization strategies: direct one-step summarization, structured summarization that independently extracts specific clinical insights, and distilled summarization that condenses structured summaries further. The framework was evaluated on a dataset of over 64,000 admission notes, comparing heart failure prediction performance across strategies using both automated metrics (AUROC, AUPRC, F1-score) and quality assessments through LLM-as-judge evaluation and clinician validation. The evaluation specifically measured text compression ratios, diagnostic performance retention, and hallucination rates across different summarization approaches.

## Key Results
- Structured summaries achieved the highest AUROC/AUPRC for heart failure diagnosis
- Distilled summaries achieved 79% text compression while maintaining 95.8% of baseline F1-score performance
- Divide-and-conquer approach significantly reduced hallucinations compared to one-step summarization

## Why This Works (Mechanism)
The divide-and-conquer approach of structured summarization reduces hallucinations by constraining the summarization task to specific clinical domains, preventing the model from inventing content outside the scope of each clinical insight category. The hierarchical summarization (structured â†’ distilled) allows for progressive information compression while maintaining clinical relevance, as each stage focuses on a specific level of abstraction. The LLM-as-judge evaluation provides scalable quality assessment that correlates with human judgment, enabling rapid iteration and optimization of summarization strategies.

## Foundational Learning
- Clinical note structure and components: Understanding admission note organization is essential for effective extraction of relevant clinical information
- Heart failure diagnostic criteria: Required for evaluating the accuracy and clinical utility of generated summaries
- LLM-based summarization techniques: Knowledge of different summarization approaches (extractive vs. abstractive) informs strategy selection
- Medical domain-specific prompt engineering: Critical for guiding LLMs to extract clinically relevant information accurately
- Evaluation metrics for clinical NLP: Understanding appropriate metrics (AUROC, AUPRC, F1) for assessing diagnostic performance
- Hallucination detection in LLMs: Important for ensuring generated summaries maintain fidelity to source content

## Architecture Onboarding
**Component Map:** Admission Notes -> Preprocessing -> Summarization Strategies (One-step, Structured, Distilled) -> Evaluation Metrics -> Quality Assessment (LLM-as-judge + Clinician Validation)

**Critical Path:** Raw admission notes undergo preprocessing, then pass through three summarization strategies in parallel. Each strategy generates summaries evaluated for diagnostic performance (heart failure prediction) and quality metrics (compression ratio, hallucination rate).

**Design Tradeoffs:** One-step summarization offers simplicity but higher hallucination risk; structured summarization provides better control and accuracy but requires more complex prompt engineering; distilled summarization maximizes compression but may lose some diagnostic information.

**Failure Signatures:** Hallucinations manifest as invented clinical information; performance degradation occurs when critical diagnostic features are lost during compression; summary incompleteness results from inadequate prompt engineering for specific clinical insight extraction.

**3 First Experiments:** 1) Compare diagnostic performance of one-step vs. structured summarization on a subset of admission notes, 2) Evaluate hallucination rates using both automated detection and clinician review, 3) Test different compression thresholds for distilled summarization to optimize the F1-score retention trade-off.

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focused exclusively on heart failure diagnosis, limiting generalizability to other clinical conditions
- Reliance on synthetic ground truth data for automated evaluation introduces uncertainty about real-world clinical utility
- Automated hallucination assessment may not capture all clinically significant errors requiring comprehensive expert review

## Confidence
- **High confidence**: Comparative performance of different summarization strategies and their impact on text compression ratios and F1-score retention
- **Medium confidence**: Clinical utility and accuracy of generated summaries for heart failure diagnosis, supported by both automated metrics and limited clinician validation
- **Medium confidence**: Effectiveness of divide-and-conquer approach in reducing hallucinations, though this requires further clinical validation

## Next Checks
1. Conduct prospective clinical validation with practicing cardiologists using DistillNote summaries in real diagnostic workflows to assess practical utility and accuracy
2. Evaluate DistillNote's performance across multiple cardiovascular conditions beyond heart failure to establish generalizability
3. Perform comprehensive side-by-side comparison of DistillNote summaries against physician-generated admission summaries using blinded clinician reviewers to validate clinical accuracy and completeness