---
ver: rpa2
title: 'From Detection to Mitigation: Addressing Gender Bias in Chinese Texts via
  Efficient Tuning and Voting-Based Rebalancing'
arxiv_id: '2509.07889'
source_url: https://arxiv.org/abs/2509.07889
tags:
- bias
- gender
- classification
- text
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a method for detecting, classifying, and mitigating
  gender bias in Chinese texts using large language models. The approach employs LoRA-based
  fine-tuning for efficient adaptation to bias detection, constructs balanced training
  sets to address class imbalance, and uses majority voting across multiple expert
  models to enhance classification performance.
---

# From Detection to Mitigation: Addressing Gender Bias in Chinese Texts via Efficient Tuning and Voting-Based Rebalancing

## Quick Facts
- arXiv ID: 2509.07889
- Source URL: https://arxiv.org/abs/2509.07889
- Reference count: 40
- This paper presents a method for detecting, classifying, and mitigating gender bias in Chinese texts using large language models

## Executive Summary
This paper addresses gender bias in Chinese texts through a comprehensive approach combining detection, classification, and mitigation. The authors propose using LoRA-based fine-tuning for efficient adaptation to bias detection tasks, while addressing class imbalance through balanced training set construction. The method employs majority voting across multiple expert models to enhance classification performance and introduces a multi-temperature sampling mechanism to improve the diversity of bias-mitigated outputs. The approach achieved an average score of 47.90%, ranking fourth in the NLPCC-2025 Shared Task 7 competition.

## Method Summary
The method employs LoRA-based fine-tuning to efficiently adapt large language models for gender bias detection in Chinese texts. To address class imbalance issues in the training data, the authors construct balanced training sets. For classification tasks, a majority voting mechanism aggregates predictions from multiple expert models to enhance accuracy. The mitigation process incorporates a multi-temperature sampling approach that generates diverse outputs while reducing gender bias. This comprehensive pipeline addresses both detection and mitigation of gender bias in Chinese text processing.

## Key Results
- Achieved average score of 47.90% in NLPCC-2025 Shared Task 7 competition
- Ranked fourth place in the competition
- Demonstrated effectiveness of LoRA-based fine-tuning for efficient model adaptation

## Why This Works (Mechanism)
The approach works by leveraging efficient fine-tuning through LoRA adapters, which allows rapid adaptation of large language models to gender bias detection tasks without full fine-tuning. The voting mechanism aggregates multiple expert models' predictions, reducing individual model biases and improving overall classification accuracy. The multi-temperature sampling mechanism generates diverse outputs by sampling from different temperature distributions, helping to explore a wider range of bias-mitigated alternatives. The balanced training set construction directly addresses class imbalance, ensuring the model learns to recognize all bias types equally well.

## Foundational Learning
- LoRA fine-tuning: Why needed - Efficient adaptation of large models without full fine-tuning; Quick check - Verify adapter weights are smaller than base model parameters
- Multi-temperature sampling: Why needed - Generate diverse outputs while maintaining quality; Quick check - Compare diversity metrics across different temperature settings
- Voting ensemble: Why needed - Reduce individual model biases and improve robustness; Quick check - Measure performance improvement over single model baseline

## Architecture Onboarding
Component map: Input text -> LoRA fine-tuning -> Bias detection classifier -> Voting ensemble -> Multi-temperature sampling -> Bias-mitigated output

Critical path: Input → Detection → Classification → Mitigation
The system processes input text through detection and classification stages before applying mitigation techniques. The voting mechanism serves as a critical decision point where multiple models contribute to final classification.

Design tradeoffs:
- LoRA vs full fine-tuning: computational efficiency vs potential performance gains
- Single vs multiple temperature sampling: output diversity vs generation quality
- Voting vs single model: robustness vs computational overhead

Failure signatures:
- Poor performance on minority bias types suggests class imbalance issues
- Inconsistent mitigation outputs indicate temperature sampling instability
- Low voting agreement points to model disagreement or ambiguous inputs

First experiments:
1. Test LoRA adapter performance against full fine-tuning baseline
2. Evaluate voting mechanism with varying numbers of expert models
3. Compare output diversity across different temperature configurations

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation relies on automatic metrics that may not capture nuanced gender bias perceptions
- No human evaluation results to validate practical effectiveness of mitigation strategies
- Focus on Chinese texts limits generalizability to other languages

## Confidence
- High confidence in technical implementation of LoRA fine-tuning and voting mechanisms
- Medium confidence in classification accuracy improvements due to limited baseline comparisons
- Low confidence in practical effectiveness of bias mitigation without human evaluation

## Next Checks
1. Conduct human evaluation studies with native Chinese speakers to assess whether mitigated texts are perceived as genuinely unbiased across demographic groups
2. Test the approach on Chinese texts from diverse domains (news, social media, literature) to evaluate generalizability beyond competition dataset
3. Perform ablation studies to quantify individual contributions of LoRA fine-tuning, voting mechanisms, and temperature sampling to overall performance gains