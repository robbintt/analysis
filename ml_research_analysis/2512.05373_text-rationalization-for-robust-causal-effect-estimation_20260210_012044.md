---
ver: rpa2
title: Text Rationalization for Robust Causal Effect Estimation
arxiv_id: '2512.05373'
source_url: https://arxiv.org/abs/2512.05373
tags:
- causal
- text
- treatment
- confounding
- positivity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses a fundamental challenge in causal inference
  with high-dimensional text confounders: observational-level positivity violations.
  These violations occur when irrelevant or spurious text features inflate dimensionality,
  causing estimated propensity scores to concentrate near 0 or 1, even when the underlying
  positivity assumption holds.'
---

# Text Rationalization for Robust Causal Effect Estimation

## Quick Facts
- arXiv ID: 2512.05373
- Source URL: https://arxiv.org/abs/2512.05373
- Authors: Lijinghua Zhang; Hengrui Cai
- Reference count: 17
- High-dimensional text confounders cause observational-level positivity violations

## Executive Summary
This paper addresses a fundamental challenge in causal inference with high-dimensional text confounders: observational-level positivity violations. These violations occur when irrelevant or spurious text features inflate dimensionality, causing estimated propensity scores to concentrate near 0 or 1, even when the underlying positivity assumption holds. This leads to unstable inverse probability weights and inflated variance in causal effect estimates. The authors propose Confounding-Aware Token Rationalization (CATR), a framework that selects sparse token subsets sufficient for confounding adjustment while mitigating observational-level positivity violations.

## Method Summary
CATR uses residual Hilbert-Schmidt Independence Criterion (HSIC) as a diagnostic to identify token subsets that preserve the conditional independence structure required for unconfoundedness. The method balances predictive accuracy, sparsity, and sufficiency for valid causal adjustment through an objective function incorporating supervised loss, sparsity regularization, and HSIC penalty. Experiments on synthetic data and real-world MIMIC-III clinical data demonstrate that CATR consistently improves overlap, reduces weight instability and variance, and yields more stable and interpretable ATE estimates compared to existing baselines. The framework also extends naturally to multimodal settings, combining structured and unstructured data. Theoretical analysis establishes nonasymptotic error bounds and asymptotic normality for the resulting estimators, positioning CATR within the semiparametric efficiency framework.

## Key Results
- CATR improves overlap and reduces weight instability in high-dimensional text confounders
- Experiments show consistent ATE estimate stability improvements on synthetic and MIMIC-III data
- Residual HSIC effectively identifies token subsets preserving causal adjustment requirements
- Framework extends to multimodal settings combining structured and unstructured data

## Why This Works (Mechanism)
The framework addresses observational-level positivity violations by selecting sparse token subsets that maintain the necessary conditional independence structure for valid causal adjustment. By using residual HSIC as a diagnostic, CATR identifies tokens that capture confounding relationships while avoiding spurious features that inflate dimensionality and cause propensity score concentration. The objective function balances three competing objectives: maintaining predictive accuracy for treatment assignment, enforcing sparsity to reduce dimensionality, and preserving the independence structure required for unconfoundedness.

## Foundational Learning
1. **Positivity assumption violation** - Why needed: Ensures every unit has nonzero probability of receiving any treatment level given confounders. Quick check: Verify propensity scores are bounded away from 0 and 1.
2. **Inverse probability weighting** - Why needed: Standard method for estimating causal effects by reweighting to create pseudo-population where treatment assignment is independent of confounders. Quick check: Examine weight distributions for extreme values.
3. **Hilbert-Schmidt Independence Criterion** - Why needed: Measures statistical independence between variables, used here to diagnose token subset sufficiency. Quick check: Compare HSIC values before and after token rationalization.
4. **Residual HSIC** - Why needed: Measures remaining dependence after accounting for selected features, identifying spurious confounders. Quick check: Verify residual HSIC decreases as sufficient token subsets are identified.
5. **Semiparametric efficiency** - Why needed: Framework for establishing optimality of estimators when only part of the model is parametric. Quick check: Confirm estimator achieves smallest possible asymptotic variance.

## Architecture Onboarding

### Component Map
Raw text data -> Token preprocessing -> CATR objective function -> Token subset selection -> Propensity score estimation -> Inverse probability weighting -> ATE estimation

### Critical Path
1. Raw text data and treatment/covariate information
2. Token preprocessing and feature extraction
3. CATR objective function computation (supervised loss + sparsity + residual HSIC)
4. Token subset selection via optimization
5. Propensity score estimation using selected tokens
6. Inverse probability weighting and ATE estimation

### Design Tradeoffs
- Sparsity vs. predictive accuracy: More tokens improve prediction but increase positivity violation risk
- Computational complexity: HSIC computation scales with token set size
- Kernel choice sensitivity: Residual HSIC depends on kernel parameters
- Binary vs. multi-valued treatments: Framework currently validated primarily for binary settings

### Failure Signatures
- Weight distributions concentrated near 0 or 1 despite CATR application
- Residual HSIC remaining high after token selection
- ATE estimates showing high variance across bootstrap samples
- Model performance degradation when extending to multi-valued treatments

### 3 First Experiments
1. Synthetic data generation with known confounding structure to validate CATR's ability to identify sufficient token subsets
2. Ablation study removing HSIC penalty to demonstrate its necessity for positivity improvement
3. Sensitivity analysis varying kernel bandwidth parameters in residual HSIC computation

## Open Questions the Paper Calls Out
None

## Limitations
- HSIC diagnostic sensitivity to kernel choice and bandwidth parameters may affect token subset selection consistency
- Experiments primarily focus on binary treatment settings, leaving scalability to multi-valued treatments unclear
- Real-world evaluation relies on a single clinical dataset (MIMIC-III), potentially limiting generalizability

## Confidence

**Confidence Labels:**
- Observational-level positivity violation claims: High - well-supported by both theory and experiments
- CATR framework effectiveness: Medium-High - demonstrated improvements but limited to specific settings
- HSIC diagnostic utility: Medium - theoretically sound but practical sensitivity to hyperparameters unclear
- Extension to multimodal settings: Low-Medium - mentioned but not thoroughly validated

## Next Checks

1. Test CATR's performance across diverse text domains (e.g., social media, legal documents) to assess generalizability beyond clinical text
2. Conduct sensitivity analysis on kernel parameters and bandwidth choices in the residual HSIC computation to establish robustness
3. Evaluate CATR's behavior in multi-valued treatment settings with â‰¥3 treatment groups to verify scalability beyond binary treatments