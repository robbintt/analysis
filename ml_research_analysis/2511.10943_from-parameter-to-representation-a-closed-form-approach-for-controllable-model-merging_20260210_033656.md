---
ver: rpa2
title: 'From Parameter to Representation: A Closed-Form Approach for Controllable
  Model Merging'
arxiv_id: '2511.10943'
source_url: https://arxiv.org/abs/2511.10943
tags:
- uni00000013
- uni00000011
- uni00000046
- uni00000003
- merging
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of controllable model merging, where
  multiple fine-tuned models are combined into a single network that can balance task
  performance according to user preferences. The authors identify that existing methods
  suffer from high computational cost and poor scalability due to complex parameter-space
  optimization.
---

# From Parameter to Representation: A Closed-Form Approach for Controllable Model Merging

## Quick Facts
- **arXiv ID**: 2511.10943
- **Source URL**: https://arxiv.org/abs/2511.10943
- **Reference count**: 22
- **Primary result**: Achieves superior performance, better preference alignment, and drastically reduced computational cost compared to state-of-the-art baselines for controllable model merging

## Executive Summary
This paper introduces a novel closed-form approach for controllable model merging that transforms the parameter-space optimization problem into a representation correction task. By modeling the discrepancy between merged and individual task representations as linear distortion, the authors derive a Pareto-optimal solution that bypasses iterative optimization entirely. The method achieves superior performance and better preference alignment while drastically reducing computational cost compared to existing approaches, maintaining strong results even with limited calibration data.

## Method Summary
The authors reframe controllable model merging as a representation correction problem rather than traditional parameter-space optimization. They model the difference between merged model representations and individual task representations as a linear distortion that can be corrected through learned transformations. This insight allows them to derive a closed-form, Pareto-optimal solution that eliminates the need for computationally expensive iterative optimization. The approach involves identifying the linear transformation that best aligns the merged model's representations with those of individual fine-tuned models, enabling controllable interpolation between tasks based on user preferences.

## Key Results
- Achieves superior performance compared to state-of-the-art baselines in controllable model merging
- Demonstrates better preference alignment while maintaining strong performance with limited calibration data
- Reduces computational cost dramatically by eliminating iterative optimization in favor of closed-form solution

## Why This Works (Mechanism)
The method works by recognizing that the core challenge in model merging is not parameter optimization but representation alignment. When multiple fine-tuned models are merged, their combined representations often deviate from the ideal task-specific representations. By modeling this deviation as a linear transformation, the problem becomes one of finding the optimal correction matrix that maps merged representations back to their target distributions. This transformation can be computed in closed form, making the approach both theoretically elegant and computationally efficient.

## Foundational Learning
- **Linear representation correction**: The core assumption that inter-task representation discrepancies can be captured through linear transformations
  - *Why needed*: Enables closed-form solution by reducing a complex optimization to a tractable linear algebra problem
  - *Quick check*: Verify that merged model representations are approximately linear combinations of individual task representations

- **Pareto optimality in multi-task learning**: The mathematical framework for finding optimal trade-offs between competing objectives
  - *Why needed*: Provides the theoretical foundation for deriving the closed-form solution
  - *Quick check*: Confirm that the solution lies on the Pareto frontier across all task combinations

- **Representation space geometry**: Understanding how neural network representations behave in the space where merging occurs
  - *Why needed*: Critical for validating the linear correction assumption
  - *Quick check*: Analyze representation similarity metrics between merged and individual models

## Architecture Onboarding

**Component Map**: Input representations -> Linear correction layer -> Output predictions

**Critical Path**: 
1. Merge base model parameters from multiple fine-tuned models
2. Compute representation discrepancy matrix between merged and individual models
3. Derive closed-form linear correction transformation
4. Apply correction during inference for controllable task balancing

**Design Tradeoffs**: 
- Linear correction assumption vs. potential non-linear representation discrepancies
- Closed-form computation speed vs. possible accuracy loss from simplified model
- Calibration data requirements vs. generalization to new task combinations

**Failure Signatures**: 
- Poor performance when merging models with fundamentally different architectures
- Degradation when task representations are highly non-linear or disjoint
- Suboptimal results with very limited calibration data

**First Experiments**:
1. Merge 2-3 models trained on related tasks to validate basic functionality
2. Test controllable interpolation between extreme preference points
3. Measure computational speedup compared to iterative optimization baselines

## Open Questions the Paper Calls Out
None specified in the provided material.

## Limitations
- Performance guarantees rely heavily on linear correction assumption, which may not hold for tasks with highly non-linear decision boundaries
- Experimental validation uses relatively small task sets (3-5 tasks), raising questions about scalability to dozens of tasks
- Computational complexity analysis doesn't fully account for calibration data collection and processing costs across all tasks

## Confidence
- **Closed-form optimality**: Medium - Theoretical derivation appears sound but empirical validation across diverse task combinations is limited
- **Linear correction sufficiency**: Low - Assumption may break down for complex task relationships without systematic evaluation of failure modes
- **Scalability claims**: Medium - Computational efficiency demonstrated but practical scalability with many tasks needs more evidence

## Next Checks
1. Test the method with 10+ diverse tasks spanning different domains to verify scalability claims and assess when linear correction assumptions fail
2. Compare against baselines when using minimal calibration data (1-2 examples per task) to validate robustness claims
3. Evaluate performance when merging models with different architectures or trained with different hyperparameters to assess practical applicability limits