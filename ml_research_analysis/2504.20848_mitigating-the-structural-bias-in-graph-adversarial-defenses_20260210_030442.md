---
ver: rpa2
title: Mitigating the Structural Bias in Graph Adversarial Defenses
arxiv_id: '2504.20848'
source_url: https://arxiv.org/abs/2504.20848
tags:
- graph
- nodes
- adversarial
- degree
- uni00000013
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper tackles the structural bias in graph neural network
  (GNN) defenses, where current methods perform poorly on nodes with low degree, especially
  under adversarial attacks. The authors propose De2GNN, a defense and debiasing framework
  that includes three key modules: hetero-homo augmented graph construction (removing
  heterophilic links and adding homophilic links for low-degree nodes), kNN augmented
  graph construction (creating an attack-agnostic graph based on node features), and
  multi-view node-wise attention (combining information from both graph views).'
---

# Mitigating the Structural Bias in Graph Adversarial Defenses

## Quick Facts
- **arXiv ID:** 2504.20848
- **Source URL:** https://arxiv.org/abs/2504.20848
- **Reference count:** 40
- **Primary result:** De2GNN achieves state-of-the-art defense performance against adversarial attacks while improving accuracy for low-degree nodes through heterophilic link removal, homophilic link addition, and multi-view attention.

## Executive Summary
This paper addresses the structural bias in graph adversarial defenses, where existing methods perform poorly on low-degree nodes under attack. The authors propose De2GNN, a three-module framework that purifies the graph by removing heterophilic links, enriches low-degree node neighborhoods by adding predicted homophilic links, and combines information from both the purified and attack-agnostic kNN graphs using node-wise attention. De2GNN demonstrates significant improvements in both overall accuracy and tail-node accuracy on benchmark datasets under strong attack scenarios.

## Method Summary
De2GNN introduces a defense and debiasing framework consisting of three key modules: (1) hetero-homo augmented graph construction that removes heterophilic links and adds homophilic links for low-degree nodes, (2) kNN augmented graph construction that creates an attack-agnostic graph based on node features, and (3) multi-view node-wise attention that combines information from both graph views. The framework addresses structural bias by purifying the graph from adversarial heterophilic perturbations and enriching the neighborhood of low-degree nodes with predicted same-class neighbors.

## Key Results
- Achieves state-of-the-art results on Cora, Citeseer, and Pubmed under strong Metattack scenarios
- Significantly improves accuracy for low-degree (tail) nodes compared to existing defense methods
- Multi-view attention mechanism provides ~5-7% accuracy improvement over single-view approaches
- Effectively mitigates structural bias while maintaining strong overall defense performance

## Why This Works (Mechanism)

### Mechanism 1: Heterophilic Link Removal as Adversarial Noise Detection
- Claim: Removing edges connecting nodes with dissimilar features filters adversarial perturbations added by attackers.
- Mechanism: Compute feature similarity (Jaccard for discrete, Cosine for continuous features) for each edge. Remove edges where similarity < threshold t1, producing a "purified" graph G⁻hetero.
- Core assumption: Attackers predominantly add heterophilic links (connecting dissimilar nodes) rather than homophilic ones.
- Evidence anchors:
  - [abstract] "removing heterophilic links (i.e., links connecting nodes with dissimilar features) globally"
  - [section V.A.1] "attackers usually tend to add some heterophilic links where connected nodes tend to share dissimilar features"
  - [corpus] Related work (Jaccard defense) uses similar similarity-based filtering; no contradicting evidence found.
- Break condition: If attackers use feature-aware attacks that add homophilic perturbations, this filtering becomes ineffective.

### Mechanism 2: Homophilic Link Addition for Low-Degree Node Neighborhood Enrichment
- Claim: Adding predicted-same-class neighbors for low-degree nodes reduces structural bias by providing more aggregation signal.
- Mechanism: Train surrogate GNN on purified graph; for each tail node with confidence > threshold t2, connect to top-p nodes predicted as same class.
- Core assumption: The surrogate GNN predictions are sufficiently accurate on the purified graph to identify valid homophilic neighbors.
- Evidence anchors:
  - [abstract] "adding homophilic links...for nodes with low degree"
  - [section V.A.2] "enrich the neighborhood of nodes with low degree"
  - [corpus] Weak direct evidence; Tail-GNN and related works address degree bias but not under adversarial conditions.
- Break condition: If surrogate model is compromised or purified graph still contains significant noise, added links may introduce incorrect connections.

### Mechanism 3: kNN Graph as Attack-Agnostic Alternative View
- Claim: A k-nearest-neighbor graph built from raw node features provides structural information independent of adversarial edge manipulations.
- Mechanism: Construct graph GkNN where each node connects to k most feature-similar nodes, bypassing the (potentially perturbed) original adjacency.
- Core assumption: Node features are not significantly perturbed (attack is structure-focused).
- Evidence anchors:
  - [abstract] "kNN augmented graph construction (creating an attack-agnostic graph based on node features)"
  - [section V.B] "utilize raw features of nodes...to obtain an attack-agnostic augmented graph"
  - [corpus] No direct corroboration; corpus focuses on topology-based defenses.
- Break condition: If attackers also perturb node features, kNN graph inherits corrupted information.

### Mechanism 4: Node-wise Attention for Adaptive View Fusion
- Claim: Per-node attention weights allow the model to favor the more reliable graph view for each node individually.
- Mechanism: Learn attention scores α via softmax over concatenated representations from both views; compute final representation as weighted sum.
- Core assumption: The two views provide complementary robustness; some nodes benefit more from one view than the other.
- Evidence anchors:
  - [abstract] "multi-view node-wise attention (combining information from both graph views)"
  - [Table IV] De2GNN-attn shows ~5-7% accuracy drop without attention, indicating contribution.
  - [corpus] No contradicting evidence; attention mechanisms common in multi-view learning.
- Break condition: If both views are similarly corrupted for a node, attention cannot recover performance.

## Foundational Learning

- **Concept: Message Passing / Neighborhood Aggregation in GNNs**
  - Why needed here: The entire defense strategy relies on understanding how GNNs aggregate neighbor information and why sparse neighborhoods (low degree) lead to poor representations.
  - Quick check question: Can you explain why a node with degree 2 receives less informative representations than a node with degree 50 under standard GCN aggregation?

- **Concept: Homophily vs. Heterophily in Graphs**
  - Why needed here: The paper's heterophilic link removal assumes heterophilic edges are more likely adversarial; understanding this distinction is critical for evaluating the assumption.
  - Quick check question: Would removing heterophilic links be appropriate in a molecular graph where different atom types naturally bond?

- **Concept: Poisoning vs. Evasion Attacks**
  - Why needed here: The paper focuses on poisoning attacks (Metattack modifies training graph); understanding this distinction matters for assessing when De2GNN applies.
  - Quick check question: Would De2GNN's pre-processing defense help against an evasion attack where the graph is modified at test time only?

## Architecture Onboarding

- **Component map:**
  Input Graph G' -> [Heterophilic Filter] -> G⁻hetero -> [Surrogate GNN] -> [Homophilic Link Adder] -> G+homo -> GNN1 -> H+homo
  -> [kNN Constructor] -> GkNN -> GNN2 -> HkNN
  -> [Node-wise Attention] -> Y_final -> Prediction

- **Critical path:** Heterophilic link removal -> Purified graph quality -> Surrogate GNN accuracy -> Quality of added homophilic links. If early filtering is poor, downstream enrichment adds noise.

- **Design tradeoffs:**
  - Threshold t1: Lower values keep more edges (higher recall, lower precision on adversarial detection); higher values risk removing legitimate heterophilic edges.
  - Parameter p (added neighbors): Larger p adds more signal but increases noise risk from surrogate errors.
  - k in kNN: Larger k densifies graph but may connect dissimilar nodes.

- **Failure signatures:**
  - Accuracy on tail nodes significantly lower than head nodes after training -> homophilic addition may be ineffective or surrogate is unreliable.
  - Performance degrades vs. vanilla GCN on clean graphs -> over-aggressive heterophilic removal.
  - High variance across runs -> attention mechanism unstable; check initialization.

- **First 3 experiments:**
  1. **Reproduce structural bias visualization (Fig. 3-4):** Run Jaccard and SVD defenses on Cora with 25% Metattack perturbation; plot accuracy vs. node degree to confirm bias exists before implementing full De2GNN.
  2. **Ablation on heterophilic removal threshold t1:** Sweep t1 ∈ [0.1, 0.5] on Citeseer under attack; measure overall accuracy and tail-node accuracy to find operating point.
  3. **Surrogate quality validation:** Train surrogate GNN on purified graphs with varying noise levels; report prediction confidence calibration to assess whether homophilic link addition is trustworthy.

## Open Questions the Paper Calls Out
None

## Limitations
- Framework effectiveness hinges on assumptions about attacker behavior (primarily adding heterophilic links) and feature integrity that may not hold for all attack strategies
- Hyper-parameter sensitivity (thresholds t1 and t2, number of added neighbors p, k in kNN) could significantly impact real-world deployment
- Limited exploration of performance degradation when core assumptions are violated

## Confidence

- **High confidence:** The structural bias problem exists and affects low-degree nodes under adversarial attacks
- **Medium confidence:** Heterophilic link removal effectively filters adversarial noise
- **Medium confidence:** The multi-view attention mechanism provides meaningful improvement
- **Low confidence:** Homophilic link addition consistently improves tail node performance across different attack scenarios

## Next Checks

1. **Attack agnosticism test:** Evaluate De2GNN against a feature-aware attack (e.g., Nettack with feature perturbations) to assess whether the kNN augmentation remains effective when both structure and features are compromised.

2. **Threshold sensitivity analysis:** Systematically vary t1 and t2 across multiple datasets and attack strengths, reporting both overall accuracy and tail-node accuracy to identify optimal operating points and robustness to parameter choice.

3. **Surrogate model validation:** Quantify the accuracy of the surrogate GNN on the purified graph across different perturbation levels, and measure the precision/recall of added homophilic links to establish when this mechanism introduces more noise than signal.