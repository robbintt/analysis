---
ver: rpa2
title: Error Detection and Correction for Interpretable Mathematics in Large Language
  Models
arxiv_id: '2508.03500'
source_url: https://arxiv.org/abs/2508.03500
tags:
- equations
- error
- correction
- edcim
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces EDCIM, a method to detect and correct errors
  in interpretable mathematical reasoning tasks where LLMs must generate exact functional
  forms. EDCIM uses symbolic error detection rules to identify problematic outputs
  and selectively triggers correction with cloud-based models, while initial generation
  is done with lightweight local LLMs.
---

# Error Detection and Correction for Interpretable Mathematics in Large Language Models

## Quick Facts
- arXiv ID: 2508.03500
- Source URL: https://arxiv.org/abs/2508.03500
- Authors: Yijin Yang; Cristina Cornelio; Mario Leiva; Paulo Shakarian
- Reference count: 25
- Primary result: EDCIM reduces re-prompting to ~36% while maintaining over 90% of full re-prompt accuracy on DRAW-1K and GSM-8K.

## Executive Summary
This paper introduces EDCIM, a method to detect and correct errors in interpretable mathematical reasoning tasks where LLMs must generate exact functional forms. EDCIM uses symbolic error detection rules to identify problematic outputs and selectively triggers correction with cloud-based models, while initial generation is done with lightweight local LLMs. The framework controls the cost-accuracy trade-off via a single hyperparameter. Experiments on DRAW-1K and GSM-8K show EDCIM reduces re-prompting to ~36% while maintaining over 90% of full re-prompt accuracy. It also consistently improves equation quality even when full correction is not achieved.

## Method Summary
EDCIM converts natural language math word problems into explicit systems of symbolic equations. It uses Phi-3 (local) for initial generation, then applies error detection rules learned via DetRuleLearn on diversity and complexity metrics. If errors are flagged or SymPy fails to parse, GPT-4o (cloud) is called with a correction prompt. A single hyperparameter ε controls the cost-accuracy trade-off. The method is evaluated on DRAW-1K and GSM-8K datasets, measuring accuracy, re-prompt rate, and equation distance.

## Key Results
- EDCIM reduces re-prompting to ~36% compared to full correction on both DRAW-1K and GSM-8K.
- Maintains over 90% of full re-prompt accuracy while lowering cost.
- Consistently improves equation quality (ΔEqD) even when full correction is not achieved.

## Why This Works (Mechanism)
EDCIM works by combining lightweight local generation with selective, rule-driven cloud correction. The symbolic error detection rules identify high-risk outputs early, allowing expensive corrections only when needed. This balances computational cost with solution accuracy, and the use of SymPy ensures mathematical correctness of final outputs.

## Foundational Learning
- **SymPy parsing:** Converts symbolic expressions to executable form. *Why needed:* Validates generated equations. *Quick check:* Parse sample ground truth equations.
- **LLM error detection rules:** Conditions to flag problematic outputs. *Why needed:* Avoids unnecessary expensive corrections. *Quick check:* Apply rules to known correct/incorrect samples.
- **DetRuleLearn algorithm:** Selects optimal error rules from candidates. *Why needed:* Adapts detection to dataset. *Quick check:* Verify rule selection stability across folds.
- **Diversity metrics (Entropy, Gini):** Measures variation across LLM samples. *Why needed:* Identifies unreliable generations. *Quick check:* Compute on synthetic low/high diversity sets.
- **AST depth and operator count:** Quantifies equation complexity. *Why needed:* Flags overly complex or malformed equations. *Quick check:* Parse and measure sample equations.

## Architecture Onboarding

**Component Map:** Phi-3 (local) -> Error Detection (rules + metrics) -> SymPy validation -> (Optional) GPT-4o correction -> SymPy solve

**Critical Path:** Phi-3 generation → Diversity/complexity feature extraction → Rule evaluation → (Conditional) GPT-4o correction → SymPy solve → Accuracy check

**Design Tradeoffs:** Local vs. cloud model usage; rule sensitivity vs. correction frequency; token budget for correction prompts.

**Failure Signatures:** False positives trigger unnecessary cloud calls; SymPy parsing errors break the pipeline; high diversity indicates unreliable local generation.

**First Experiments:** 1) Run DetRuleLearn on 10% training split with ε=0.1 to identify active rules. 2) Generate 10 samples per problem and compute diversity metrics. 3) Apply learned rules to a held-out set and measure re-prompt rate.

## Open Questions the Paper Calls Out
1. Can the Error Detection Rules (EDRs) be generated or learned automatically, eliminating the need for manual definition by domain experts?
2. How effectively does the EDCIM framework transfer to other structured tasks, such as theorem proving or complex knowledge extraction?
3. Does EDCIM yield significant performance improvements when applied to state-of-the-art models on high-difficulty benchmarks like the MATH dataset?

## Limitations
- Exact candidate rule intervals for complexity and diversity checks are not specified, requiring experimenter definition.
- SymPy parsing robustness is assumed but not detailed; edge cases in LLM output may break parsing.
- No token-limit-aware logic for combining multiple correction prompts when several rules trigger.

## Confidence
- Core design (symbolic rules + selective re-prompting): High confidence
- Learned rule selection algorithm: Medium confidence (due to unspecified candidate rule granularity)
- End-to-end accuracy claims: Medium confidence (pending SymPy parsing validation)

## Next Checks
1. Re-run DetRuleLearn with a fixed candidate rule pool covering complexity bins [1,2,3,4,5,6,7,8,9,10+] and diversity thresholds in [0.1, 0.2, 0.3, 0.4, 0.5] to confirm rule stability.
2. Verify the SymPy parser handles edge cases in LLM output (e.g., implicit multiplication, unicode symbols) on a held-out sample of ground truth equations.
3. Benchmark token usage per correction prompt under multi-rule triggers to ensure prompt templates respect practical API limits.