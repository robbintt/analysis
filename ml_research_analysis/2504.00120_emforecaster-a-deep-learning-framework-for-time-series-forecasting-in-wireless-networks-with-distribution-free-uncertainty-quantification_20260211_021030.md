---
ver: rpa2
title: 'EMForecaster: A Deep Learning Framework for Time Series Forecasting in Wireless
  Networks with Distribution-Free Uncertainty Quantification'
arxiv_id: '2504.00120'
source_url: https://arxiv.org/abs/2504.00120
tags:
- time
- series
- forecasting
- prediction
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces EMForecaster, a deep learning framework for
  electromagnetic field (EMF) exposure forecasting in wireless networks. The model
  employs patching with reversible instance normalization and spatiotemporal mixing
  operations to efficiently capture temporal patterns across multiple scales.
---

# EMForecaster: A Deep Learning Framework for Time Series Forecasting in Wireless Networks with Distribution-Free Uncertainty Quantification

## Quick Facts
- arXiv ID: 2504.00120
- Source URL: https://arxiv.org/abs/2504.00120
- Reference count: 40
- Key outcome: EMForecaster achieves 53.97% MSE improvement over Transformers and 38.44% over average baseline, with 24.73% TOS improvement in conformal forecasting

## Executive Summary
EMForecaster introduces a deep learning framework for electromagnetic field (EMF) exposure forecasting in wireless networks that combines patching with reversible instance normalization and spatiotemporal mixing operations. The model efficiently captures temporal patterns across multiple scales while being enhanced with conformal prediction for distribution-free uncertainty quantification. A novel Trade-off Score (TOS) metric balances prediction interval coverage and width. The framework demonstrates state-of-the-art performance on both point forecasting and uncertainty quantification tasks using real EMF datasets from Italy and Turkey.

## Method Summary
EMForecaster employs reversible instance normalization (RevIN) to handle non-stationary EMF data, followed by patching to create subsequences that are embedded and processed through a spatiotemporal backbone. This backbone applies temporal and patch dimension mixing operations with residual connections. The framework includes a conformal prediction mechanism that generates prediction intervals with guaranteed coverage under exchangeability assumptions. A new TOS metric balances the trade-off between coverage and interval width. The model is trained on EMF datasets with 6-minute intervals (Italy) and 15-second intervals (Turkey), using sliding windows for sequence processing.

## Key Results
- Outperforms state-of-the-art models in point forecasting with 53.97% MSE improvement over Transformers and 38.44% over average baseline
- Achieves superior performance in conformal forecasting with 24.73% TOS improvement over average baseline
- Demonstrates effective handling of non-stationary EMF data through RevIN and conformal prediction mechanisms

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Reversible Instance Normalization (RevIN) mitigates performance degradation from distribution shifts in non-stationary EMF time series.
- Mechanism: RevIN applies symmetric normalize-then-denormalize operations: input windows are normalized using their own statistics (mean μ, std σ) before processing, then denormalized after forecasting. This decouples the model from dataset-level statistics that may shift between training and deployment.
- Core assumption: EMF exposure data exhibits non-stationarity or distribution shift between training and inference periods.
- Evidence anchors:
  - [abstract] "complemented by reversible instance normalization...for efficient feature extraction"
  - [Section IV-B] "RevIN has been proven to be effective for reducing the impact of distribution shifts and non-stationarity in time series"
  - [corpus] Weak direct support; corpus papers focus on conformal prediction, not RevIN specifically.
- Break condition: If the time series is strictly stationary with consistent statistics across all time periods, RevIN provides minimal benefit and adds unnecessary computational overhead.

### Mechanism 2
- Claim: Patching combined with spatiotemporal mixing captures hierarchical temporal patterns at multiple scales more efficiently than point-wise processing.
- Mechanism: The input sequence is divided into patches of size P (subsequences), which are embedded into dimension D. The Spatiotemporal Backbone (STB) then applies two complementary MLP operations per block: (1) temporal MLP mixing across the N patch positions, and (2) patch MLP mixing across the D embedding features. Residual connections stabilize training.
- Core assumption: Local temporal neighborhoods (patches) carry semantic information analogous to words in language, enabling better pattern representation than individual time points.
- Evidence anchors:
  - [abstract] "employs patching to process temporal patterns at multiple scales...mixing operations along both temporal and patch dimensions"
  - [Section IV-C] "subseries-level patches enhances the model and captures higher semantic information"
  - [Section IV-D] "Applying the STB to patch-embedded data represents a novel fusion where the mixer operates on learned patch representations"
  - [corpus] Weak; corpus focuses on conformal prediction extensions, not patching architectures.
- Break condition: If patch size P is too large relative to the input length L, temporal resolution is lost. The paper shows increasing P leads to higher MSE (Figure 6).

### Mechanism 3
- Claim: Conformal prediction provides distribution-free prediction intervals with provable coverage guarantees (1-α) under exchangeability.
- Mechanism: After model training, a held-out calibration set computes nonconformity scores (absolute residuals). The (1-α) quantile of these scores defines the interval half-width. For multi-step forecasting with horizon O, Bonferroni correction adjusts the per-timestep error rate to α/O.
- Core assumption: Calibration windows are exchangeable (approximately i.i.d.)—satisfied when time series is stationary or when using locally exchangeable windows.
- Evidence anchors:
  - [abstract] "conformal prediction mechanism...independent of the data distribution...ensuring that the ground truth lies within a prediction interval with target error rate α"
  - [Section V-A] "CP enables constructing prediction intervals with guaranteed finite-sample coverage under minimal assumptions...requiring only exchangeability"
  - [corpus] "Conformal prediction has emerged as a promising distribution-free framework for generating prediction intervals with rigorous theoretical guarantees" [arXiv:2601.18509]; "coverage guarantees...crucially rely on the assumption of exchangeability" [arXiv:2511.13608]
- Break condition: If data exhibits strong temporal dependencies violating exchangeability (e.g., highly non-stationary series without differencing), coverage guarantees may not hold. The paper notes Turkey datasets showed non-stationarity and modest conformal performance.

## Foundational Learning

- Concept: **Stationarity and Exchangeability**
  - Why needed here: Conformal prediction's theoretical guarantees require exchangeable data. Stationarity (constant statistical properties over time) implies windows are approximately i.i.d., satisfying exchangeability. The ADF test quantifies this.
  - Quick check question: Can you explain why a non-stationary time series might violate the exchangeability assumption needed for valid conformal prediction intervals?

- Concept: **Patching in Time Series**
  - Why needed here: Unlike NLP where words have semantic meaning, individual time points lack inherent semantics. Patching groups adjacent points into subsequences, allowing the model to learn local temporal patterns as meaningful units.
  - Quick check question: What happens to temporal resolution if you use a patch size P = 24 on a sequence of length L = 96?

- Concept: **Coverage-Width Trade-off in Uncertainty Quantification**
  - Why needed here: Wider prediction intervals yield higher coverage (more true values captured) but are less useful (less precise). The Trade-off Score (TOS) metric formalizes this balance for model comparison.
  - Quick check question: If a model achieves 99% coverage but with intervals 10× wider than necessary, why might this be practically problematic?

## Architecture Onboarding

- Component map:
  Input (L) -> RevIN (normalize) -> Patcher (P, stride S) -> PatchEmbed (D) -> STB [K blocks: TemporalMLP + PatchMLP + residuals] -> LayerNorm + Activation -> Flatten -> Linear Head -> RevIN⁻¹ (denormalize) -> Output (O)

  Conformal Prediction (post-hoc): Trained model + Calibration set -> Nonconformity scores -> Quantile -> Prediction intervals

- Critical path: RevIN normalization -> patch embedding dimension D (controls representational capacity) -> STB mixing operations -> RevIN denormalization. For conformal prediction: calibration set quality directly determines interval validity.

- Design tradeoffs:
  - **Patch size P vs. temporal resolution**: Smaller P = finer granularity but more patches to process. Paper shows P=8 outperforms P=36 (Figure 6).
  - **Embedding dimension D vs. model capacity**: Larger D improves performance (Figure 6) but increases parameters and compute.
  - **β and λ in TOS**: β weights joint vs. independent coverage; λ balances coverage vs. interval width. Paper recommends β=2/3, λ=1/2.
  - **Temporal resolution (Δt)**: Finer sampling (6 min vs. 30 min) yields narrower intervals but potentially higher MSE due to noise.

- Failure signatures:
  - **Non-stationary input data**: High MSE and poor conformal coverage on Turkey datasets (limited 24-hour recordings, non-stationary).
  - **Exchangeability violation**: Empirical coverage falls below theoretical (1-α) guarantee.
  - **Excessive patch size**: MSE increases as P grows (loses fine-grained patterns).
  - **Insufficient calibration data**: Unstable quantile estimates, erratic interval widths.

- First 3 experiments:
  1. **Stationarity validation**: Run ADF tests on your EMF dataset. If p > 0.05 (non-stationary), apply first-order differencing before training. Compare model performance with/without RevIN.
  2. **Hyperparameter sweep on patch configuration**: Fix L=336, O=96. Grid search P ∈ {8, 16, 24} and D ∈ {64, 128, 256}. Report MSE on validation set. Expect smaller P and larger D to perform better.
  3. **Conformal calibration check**: Train EMForecaster, reserve 20% of training data for calibration. Compute empirical IC and JC at α=0.1, 0.05, 0.01. Verify IC ≥ (1-α). If coverage is significantly below target, investigate exchangeability violations.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does EMForecaster perform when extended to Beyond 5G (B5G) frequencies and forecast horizons spanning multiple years?
- **Basis in paper**: [explicit] The conclusion explicitly lists "extending EMForecaster to Beyond 5G (B5G) data and expanding the forecast horizon to multiple years" as primary future research directions.
- **Why unresolved**: The current study validates the framework on specific sub-6 GHz EMF datasets with forecast horizons limited to approximately 50 hours, leaving long-term and higher-frequency performance untested.
- **What evidence would resolve it**: Empirical evaluation of EMForecaster's point forecasting accuracy and conformal prediction validity on B5G datasets with multi-year temporal spans.

### Open Question 2
- **Question**: To what extent does the violation of the exchangeability assumption in non-stationary EMF data degrade the theoretical coverage guarantees of the conformal prediction mechanism?
- **Basis in paper**: [inferred] The paper notes that Conformal Prediction (CP) requires exchangeability, which time series data inherently violates. While the authors rely on stationarity (found in the Italy datasets) to satisfy this, they acknowledge the Turkey dataset is non-stationary.
- **Why unresolved**: The paper asserts CP validity through "locally exchangeable windows" but simultaneously reports lower performance on non-stationary data, leaving the robustness of the finite-sample coverage guarantee under non-stationarity uncertain.
- **What evidence would resolve it**: A theoretical analysis or ablation study quantifying the deviation from the target error rate α when applying CP to explicitly non-stationary EMF test sets.

### Open Question 3
- **Question**: Can the EMForecaster architecture be modified to better capture patterns in non-stationary, short-term datasets where current performance is comparatively lower?
- **Basis in paper**: [inferred] Section VII.B.1 states that EMForecaster showed "slightly lower performance on the Turkish dataset due to inherent non-stationarity and limited data availability," suggesting the current use of RevIN and patching may struggle with these specific data characteristics.
- **Why unresolved**: The current architecture relies on reversible instance normalization (RevIN) to handle distribution shifts, but this approach appeared insufficient for the non-stationary dynamics present in the short-term Turkey dataset.
- **What evidence would resolve it**: Comparative results on non-stationary datasets using EMForecaster variants with advanced non-stationarity modules (e.g., decomposition-based normalization) integrated into the Spatiotemporal Backbone.

## Limitations

- Limited generalizability beyond EMF domain due to specialized data characteristics and RevIN requirements
- Performance degradation on non-stationary data (Turkey datasets) reveals architecture limitations
- Hyperparameter values and calibration set specifications not fully detailed, complicating exact reproduction

## Confidence

- **High Confidence**: Core architectural components (patching, spatiotemporal mixing, RevIN) and their basic functionality are well-established; MSE improvements over baselines are supported by direct comparisons
- **Medium Confidence**: TOS metric formulation and effectiveness in balancing coverage-width tradeoffs is reasonable but relies on subjective weighting parameters
- **Low Confidence**: Generalizability to non-EMF domains and robustness of conformal coverage guarantees under varying stationarity conditions are uncertain due to limited experimental scope

## Next Checks

1. **Stationarity Validation**: Run Augmented Dickey-Fuller tests on your EMF dataset to verify stationarity assumptions. Compare model performance with and without RevIN on stationary vs. non-stationary subsets to quantify RevIN's effectiveness in mitigating distribution shifts.

2. **TOS Parameter Sensitivity**: Conduct ablation studies varying β (coverage weighting) and λ (tradeoff balance) in the TOS metric. Evaluate whether the recommended values (β=2/3, λ=1/2) provide optimal performance across different datasets and error tolerances.

3. **Calibration Set Independence**: Design experiments testing whether using the validation set versus a separate calibration set affects conformal coverage guarantees. Measure empirical coverage vs. theoretical coverage across multiple α levels to assess the impact of calibration data selection.