---
ver: rpa2
title: Eliciting Risk Aversion with Inverse Reinforcement Learning via Interactive
  Questioning
arxiv_id: '2308.08427'
source_url: https://arxiv.org/abs/2308.08427
tags:
- risk
- aversion
- learning
- lemma
- have
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes an interactive inverse reinforcement learning\
  \ framework to elicit non-expert clients' risk aversion using binary-choice questionnaires.\
  \ The method models risk aversion with cost functions and spectral risk measures,\
  \ proving finite-sample identifiability and a \u221AN convergence rate (up to logarithmic\
  \ factors)."
---

# Eliciting Risk Aversion with Inverse Reinforcement Learning via Interactive Questioning

## Quick Facts
- **arXiv ID:** 2308.08427
- **Source URL:** https://arxiv.org/abs/2308.08427
- **Reference count:** 40
- **One-line primary result:** Interactive binary-questionnaire framework achieves satisfactory risk aversion elicitation accuracy with fewer than 50 questions.

## Executive Summary
This paper introduces an interactive inverse reinforcement learning (IRL) framework to elicit non-expert clients' risk aversion profiles using adaptive binary-choice questionnaires. The method models risk aversion via cost functions and spectral risk measures (SRMs), proving finite-sample identifiability and a √N convergence rate. By maximizing the "distinguishing power" between candidate risk profiles, the framework efficiently narrows down the client's true risk preferences. Experiments validate the approach in both discrete and continuous parameter spaces, showing robustness to model misspecification.

## Method Summary
The framework represents risk aversion using a cost function $c_0$ and a spectral risk measure $\mu_0$, which together define an indifference curve over binary choices. Given a static environment with states and probabilistic transitions, the system generates questions to maximize the gap between expected client choices under different candidate profiles. In the discrete case, it maintains a probability distribution over 36 candidate risk aversions and updates beliefs based on optimality gaps. In the continuous case, it uses a particle-based algorithm with 1000 particles to approximate the continuous space, updating particle parameters via gradient descent on a loss combining optimality gap and smoothness penalties.

## Key Results
- Proves finite-sample identifiability of risk aversion with binary questions and establishes a √N convergence rate.
- Achieves satisfactory accuracy with fewer than 50 questions by maximizing distinguishing power between candidates.
- Demonstrates robustness to model misspecification in simulated experiments comparing different question design strategies.
- Extends framework to infinite-horizon settings with discount factors, establishing qualitative identifiability.

## Why This Works (Mechanism)

### Mechanism 1: Spectral Risk Measure (SRM) Parameterization
Risk aversion is modeled as a probability measure $\mu$ on $[0,1]$ integrated against Average Value-at-Risk (AV@R), allowing for non-parametric elicitation. The client's risk profile is represented by a pair $(c_0, \mu_0)$, where $c_0$ is a cost function and $\mu_0$ is the spectral measure. The system maps these parameters to an "indifference curve" (Eq 3.9), which defines the boundary where a client is indifferent between two binary choices. By locating this boundary, the system recovers the parameters.

### Mechanism 2: Interactive Elicitation via Distinguishing Power
The learner maintains a probability distribution $Q_N$ over candidate risk aversions and designs questions to maximize the "distinguishing power" $\Psi$ (Eq 3.6), which measures the gap between the client's expected choice under one profile versus another. This effectively cuts the hypothesis space in half with each interaction.

### Mechanism 3: Particle-Based Gradient Inference
A discrete particle system approximates the continuous risk measure space, allowing for gradient-based updates to the learner's belief. The system represents uncertainty using $K$ particles (candidate profiles) and updates particle parameters via a policy-gradient-inspired loss function (Eq 7.6), effectively moving the particles toward the region of the parameter space consistent with the client's history.

## Foundational Learning

- **Concept: Coherent Risk Measures (Spectral Risk Measures)**
  - **Why needed here:** To understand the mathematical structure of $\rho_\mu(Z)$ and why the specific distance metric $\mathfrak{U}$ (Eq 3.2) is used instead of standard Euclidean distance.
  - **Quick check question:** Can you explain why a spectral risk measure is considered "coherent" and how the weighting function $\sigma_\mu$ dictates risk aversion?

- **Concept: Inverse Reinforcement Learning (IRL)**
  - **Why needed here:** The problem is framed as IRL—inferring the objective function (risk profile) from optimal behavior (binary choices).
  - **Quick check question:** In standard IRL, why is identifiability a problem, and how does "interactive questioning" resolve it in this paper?

- **Concept: Active Learning / Experimental Design**
  - **Why needed here:** The paper's efficiency relies on "distinguishing power," a concept from optimal experimental design, to select the most informative queries.
  - **Quick check question:** How does the "expected" design rule (7.3) differ from a "greedy" rule in balancing exploration vs. exploitation?

## Architecture Onboarding

- **Component map:** Environment (State Space) -> Client (Agent) -> Learner (Robo-Advisor) -> Environment
  - Environment: Monetary losses $\mathcal{X}=\{x_0, x_1, x_2\}$ and transition matrix $G_{p,q}$
  - Client: Simulated/real human choosing $\min \rho_\mu$
  - Learner: Belief State (probability measure $Q_N$), Question Designer (optimizing $\Psi$), Updater (particle filter/gradient descent)

- **Critical path:** 1. Initialize particle system 2. Generate binary choice question by maximizing expected distinguishing power 3. Observe client action 4. Compute loss and update particle positions/costs 5. Eliminate inconsistent particles and replenish

- **Design tradeoffs:** Static vs. Dynamic settings (static has rigorous convergence proofs), Binary questions (easier for clients but require more rounds) vs. Multiple-choice questions (faster but risk overwhelming client), Model Misspecification (system converges to closest available proxy)

- **Failure signatures:** Stagnant $\Psi$ (distinguishing power drops without convergence), Oscillating Beliefs (high variance in answers or learning rate too high), Misspecification (client violates SRM assumptions)

- **First 3 experiments:**
  1. Implement grid-based questioning strategy to verify $\sqrt{N}$ rate
  2. Compare "Uniform" vs. "Greedy" vs. "Expected" design rules to measure rounds-to-convergence
  3. Run particle-based experiment with varying discretization levels to quantify trade-off between computational cost and estimation error

## Open Questions the Paper Calls Out

- **Open Question 1:** Does identifiability hold without boundedness assumption on density function $\sigma_\mu$ (when $\lambda = \infty$)?
- **Open Question 2:** How do guarantees change when client exhibits uncertainty or stochastic behavior rather than precise preferences?
- **Open Question 3:** Can a single multiple-choice question distinguish between distinct risk aversion profiles in the general static setting?
- **Open Question 4:** Can neural networks be formally validated to extend framework to continuous state and action spaces?

## Limitations
- Assumes clients perfectly follow SRM axioms and can consistently identify lesser risks, which may not hold for real humans
- Infinite-horizon extension lacks rigorous √N convergence rate, providing only qualitative identifiability
- Proxy space approximation may not uniformly capture all risk measures, particularly pathological ones

## Confidence
- **High Confidence:** Finite-sample identifiability proofs and √N convergence rate are mathematically rigorous
- **Medium Confidence:** Experimental results demonstrate effectiveness in simulation, but simplified environment may not capture real-world complexity
- **Low Confidence:** Behavioral assumptions about human clients (strict adherence to SRM axioms) are optimistic and not empirically validated

## Next Checks
1. Test system with simulated clients exhibiting bounded violations of coherence to quantify estimation accuracy degradation
2. Conduct small-scale human pilot study to identify practical failure modes not captured in simulation
3. Evaluate method's performance as state space dimension increases beyond three states, measuring computational cost and estimation error