---
ver: rpa2
title: Multi-View Graph Convolution Network for Internal Talent Recommendation Based
  on Enterprise Emails
arxiv_id: '2508.20328'
source_url: https://arxiv.org/abs/2508.20328
tags:
- data
- network
- graph
- semantic
- applied
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study addresses the problem of internal talent recommendation,
  where conventional methods relying on limited managerial input often miss qualified
  candidates. It proposes a novel framework that models two dimensions of employee
  position fit from email data: WHAT they do (semantic task similarity) and HOW they
  work (structural interaction patterns).'
---

# Multi-View Graph Convolution Network for Internal Talent Recommendation Based on Enterprise Emails

## Quick Facts
- arXiv ID: 2508.20328
- Source URL: https://arxiv.org/abs/2508.20328
- Authors: Soo Hyun Kim; Jang-Hyun Kim
- Reference count: 6
- Primary result: Dual GCN with gating fusion achieves 40.9% Hit@100 on internal talent recommendation

## Executive Summary
This paper addresses the challenge of internal talent recommendation by modeling employee position fit from email data through two complementary dimensions: WHAT employees do (semantic task similarity) and HOW they work (structural interaction patterns). The proposed framework uses dual Graph Convolutional Networks to encode these views separately, then adaptively fuses them using a gating mechanism. Experiments demonstrate that this approach outperforms both single-view models and static fusion strategies, achieving 40.9% Hit@100 while providing interpretable insights into role-specific fusion preferences.

## Method Summary
The method constructs two separate graphs from enterprise email data: a Structure Network with edges weighted by email frequency and a Semantic Similarity Network with edges based on cosine similarity of subject line embeddings (threshold 0.75). Employee representations combine 100-dimensional Word2Vec embeddings of subject lines with four centrality metrics (degree, closeness, betweenness, eigenvector) into 104-dimensional feature vectors. A dual GCN architecture independently processes each graph, followed by feature-level gating fusion. Training uses weak supervision from HR metadata (job family + role pairs) with pairwise ranking loss to maximize margins between positive and negative candidate pairs.

## Key Results
- Dual GCN with gating fusion achieves 40.9% Hit@100, outperforming single-view and static fusion baselines
- Gating mechanism learns role-specific fusion strategies (e.g., 88% structural weight for sales vs. 56:44 balance for research)
- Semantic embeddings excel at job family separation (Silhouette Score 0.338) while centrality metrics better distinguish roles (AUC 0.713)
- Combined semantic and structural features yield peak F1-score of 0.9012

## Why This Works (Mechanism)

### Mechanism 1: Orthogonal View Complementarity
If professional fit and relational competency capture distinct dimensions of organizational behavior, fusing them recovers candidate fit signals that either dimension misses in isolation. The architecture forces separation: Semantic Similarity Network propagates task-based affinities while Structure Network propagates interaction-based affinities, combining only in the fusion layer. Evidence shows semantic embeddings separate job families well but poorly distinguish roles, while centrality metrics excel at role separation but fail for job families. Combining both yields peak F1-scores.

### Mechanism 2: Context-Aware Gating Fusion
If optimal ratios of task similarity versus relational style vary by job family, a learnable gating mechanism outperforms static fusion. The gating vector modulates feature-level mixing, allowing the model to emphasize expertise (Research) or connectivity (Sales) as needed. Analysis shows sales roles receive 88% weight on structural information while research gets a balanced 56:44 mix. The gating approach addresses the limitation that different roles require different model parameters.

### Mechanism 3: Inductive Homophily Injection
If relevant candidates exist in disconnected parts of the interaction graph, artificially creating semantic edges enables information propagation to isolated but competent nodes. The Semantic Similarity Network constructs edges based on subject line similarity regardless of actual email exchange, engineering homophily. This allows the GNN to treat semantically similar nodes as neighbors, providing an inductive bias that connects isolated employees doing similar work.

## Foundational Learning

- **Weak Supervision via Proxy Labels**: Explicit ground truth for replacements is rare, requiring the model to learn relative fit without absolute successor labels. Why needed: practical proxy for position similarity. Quick check: Can you explain why "Job Family + Role" was chosen over "Same Department"?

- **Pairwise Ranking Loss**: The goal is a ranked list of candidates, not binary classification, requiring the model to pull positive pairs closer than negative pairs in embedding space. Why needed: succession planning requires ranking. Quick check: How does the margin shape the geometric relationship between departed employee and candidate embeddings?

- **Node Feature Concatenation**: GNNs update node states based on neighbors, requiring initial features to contain both semantic and structural information. Why needed: single features cannot recover full employee context. Quick check: Why concatenate features rather than use separate GNN layers?

## Architecture Onboarding

- **Component map**: Email Logs (Subject + Sender/Receiver) -> Word2Vec (Subject → Vector) -> Centrality Calculation (Graph → Degree/Betweenness) -> Graph Construction (G_str + G_sim) -> Dual GCN Encoders -> Gating Mechanism (g_i = σ(W_g[h_str‖h_sim] + b_g)) -> Pairwise Ranking Loss

- **Critical path**: Thresholding (graph construction) is brittle—cosine similarity threshold affects graph density. Label alignment (training) effectiveness relies entirely on the assumption that matching Job Family + Role = Positive Pair.

- **Design tradeoffs**: Word2Vec vs. Transformers—chose Word2Vec for short subject lines to prioritize term meaning over long-range context. Early vs. Late Fusion—uses Late Fusion to learn independent embeddings first at computational cost of two GNNs.

- **Failure signatures**: "Isolated Hub"—high centrality but irrelevant semantic content ranks high if structural weight is too high. "Semantic Bleed"—dense semantic network blends unique roles with generic ones.

- **First 3 experiments**: 1) Baseline Sanity Check: heuristic score-based model vs. Random GCN to confirm GNN learns from edge structure. 2) Ablation on Fusion: Single-GCN (Structure only) vs. Single-GCN (Semantic only) vs. Late-Fusion (Concat) to verify fusion outperforms singles. 3) Threshold Sensitivity: vary semantic similarity threshold (0.6 vs 0.75 vs 0.9) to observe impact on different job families.

## Open Questions the Paper Calls Out

- **Role-aware Structural Embeddings**: Can Struc2Vec improve identification of functional successors compared to simple centrality metrics? Unresolved because current model relies on basic centrality which may fail to capture nuanced functional roles. Evidence needed: ablation study comparing centrality-based features against Struc2Vec embeddings.

- **Temporal Dynamics**: How would Dynamic GNNs affect accuracy given recent interactions might be more relevant than older ones? Unresolved because current study uses static aggregation over six months. Evidence needed: comparative experiment with time-sliced snapshots using Dynamic GNN vs. static GCN.

- **Relational GCNs**: Can modeling different relationship types (intra-team vs. inter-departmental) using R-GCNs improve context-awareness? Unresolved because current model treats all email edges identically. Evidence needed: R-GCN implementation assigning weights to different edge types based on organizational hierarchy.

## Limitations
- Performance heavily depends on quality of HR metadata used for weak supervision—noisy labels may teach incorrect position-fit signals
- Optimal semantic threshold (0.75) and centrality metrics likely tuned on specific dataset, unclear if generalizable to different organizational structures
- Absolute performance numbers (40.9% Hit@100) cannot be independently verified without access to dataset and exact preprocessing pipeline

## Confidence
- **High confidence**: Core mechanism that combining semantic task similarity with structural interaction patterns improves over single-view approaches
- **Medium confidence**: Gating mechanism's ability to learn context-aware fusion strategies, based primarily on single dataset
- **Low confidence**: Absolute performance numbers without ability to reproduce preprocessing pipeline

## Next Checks
1. Conduct sensitivity analysis by varying semantic similarity threshold (0.6-0.9) across job families to test graph construction robustness
2. Implement human evaluation where HR professionals assess top-10 recommendations for randomly selected departed positions
3. Test model transferability by training on one department/organization and evaluating on another to assess generalizability of learned fusion strategies