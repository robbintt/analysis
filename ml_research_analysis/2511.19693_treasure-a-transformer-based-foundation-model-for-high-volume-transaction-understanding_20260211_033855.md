---
ver: rpa2
title: 'TREASURE: A Transformer-Based Foundation Model for High-Volume Transaction
  Understanding'
arxiv_id: '2511.19693'
source_url: https://arxiv.org/abs/2511.19693
tags:
- treasure
- transaction
- attributes
- data
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TREASURE is a transformer-based foundation model for payment transaction
  data that simultaneously captures cardholder behavior and payment network signals.
  It addresses the challenge of modeling sequential tabular data with both static
  (card-level) and dynamic (transaction-level) attributes, as well as high-cardinality
  categorical features.
---

# TREASURE: A Transformer-Based Foundation Model for High-Volume Transaction Understanding

## Quick Facts
- arXiv ID: 2511.19693
- Source URL: https://arxiv.org/abs/2511.19693
- Reference count: 39
- Primary result: Achieves 111% relative improvement in abnormal behavior detection compared to production systems and 104% improvement in recommendation performance.

## Executive Summary
TREASURE is a transformer-based foundation model designed for payment transaction data that simultaneously captures cardholder behavior and payment network signals. The model addresses the challenge of modeling sequential tabular data with both static (card-level) and dynamic (transaction-level) attributes, as well as high-cardinality categorical features. Evaluated on industry-grade datasets, TREASURE achieves significant improvements over production systems in abnormal behavior detection and provides embeddings that enhance recommendation model performance.

## Method Summary
TREASURE employs specialized input modules for static and dynamic attributes, efficient training with shared negative sampling for high-cardinality prediction, and two prediction heads for transaction attributes and network signals. The model uses a decoder-only Transformer architecture with 3 layers and 4 attention heads, processing sequences of up to 512 transactions per card. Training involves dynamic loss scaling that prioritizes the primary task (abnormal behavior detection) while capping auxiliary task gradients, with AdamW optimizer at learning rate 1e-4 for 20 epochs.

## Key Results
- Achieves 111% relative improvement in abnormal behavior detection compared to production systems
- Provides embeddings that improve recommendation model performance by 104%
- Demonstrates strong scaling properties with both data and parameter size
- Shows Prec@1 of 0.1421 for merchant prediction using shared negative sampling vs 0.0600 with independent sampling

## Why This Works (Mechanism)

### Mechanism 1
Separating static and dynamic attribute processing improves both efficiency and representation quality for sequential tabular data. Static attributes (card-level, unchanging) are processed once per sequence through a dedicated input module, while dynamic attributes (transaction-level) are processed through a parallel module with shared weights across time steps. The static representation is positioned first in the Transformer sequence, allowing all dynamic vectors to attend to it via causal masking.

### Mechanism 2
Shared negative sampling across batch samples and time steps makes high-cardinality categorical prediction computationally tractable without degrading learning signal. Instead of computing full softmax over 100M+ categories or sampling negatives independently per position, the model samples a fixed set of negative indices shared across all positions in a batch. InfoNCE loss is computed using the positive category and these shared negatives.

### Mechanism 3
Dynamic loss scaling that prioritizes the primary task (abnormal behavior detection) while capping auxiliary task gradients improves multi-task learning stability. The overall loss uses the abnormal behavior loss as a reference scale, with auxiliary losses down-weighted if they exceed the primary loss magnitude to prevent them from dominating gradient updates.

## Foundational Learning

- **Decoder-only Transformer with causal masking**: Required for autoregressive prediction of future transactions from past sequences. Quick check: Can position i attend to position i+1? If yes, the mask is incorrectly configured.
- **Contrastive learning (InfoNCE)**: Provides tractable approximation for high-cardinality categorical prediction. Quick check: Given hidden vector h and embedding matrix E, how is the loss computed if the positive category is index y and negatives are indices I? Answer: -log(exp(h·E[y]) / Σ_{i∈I∪{y}} exp(h·E[i])).
- **Log-normal distribution modeling for numerical attributes**: Captures long-tail distributions of transaction amounts and time deltas better than point estimates. Quick check: If the model predicts μ=2.0 and σ=0.5 for a log-scaled amount, what is the expected value in original dollars? Answer: exp(μ + σ²/2) ≈ $8.17.

## Architecture Onboarding

- **Component map**: Input Module (static) -> Input Module (dynamic) -> Concatenation -> Transformer Decoder -> Output Module (next transaction attributes) -> Output Module (network signals)
- **Critical path**: Batch construction groups transactions by card, extracts static and dynamic vectors, pads/truncates to max 512 transactions, processes through input modules, feeds to Transformer decoder with causal masking, generates predictions, computes losses with dynamic scaling, backpropagates.
- **Design tradeoffs**: Sequence length capped at 512 covers ~2 years of history but may miss longer-term patterns; no positional encoding simplifies architecture but may affect length generalization; shared negatives enable 1024 negatives vs OOM at >64 with independent sampling.
- **Failure signatures**: OOM during training indicates incorrect negative sampling or batch size too large; abnormal detection RI near 0 suggests loss scaling implementation error; categorical prediction stuck at random baseline indicates embedding table learning issues; numerical predictions always near mean suggests σ collapsing to near-zero.
- **First 3 experiments**: (1) Validate input module separation by training with unified vs separated modules; (2) Negative sampling ablation comparing shared (1024 negatives) vs independent (64 negatives); (3) Loss scaling validation comparing simple sum vs TREASURE dynamic scaling.

## Open Questions the Paper Calls Out
- How can graph-based modeling approaches be integrated into TREASURE to leverage multi-hop relationships between entities, such as cards interacting with shared merchants?
- Can in-context learning be effectively adopted within TREASURE to dynamically adapt to data drift in transaction streams?
- To what extent can optimization techniques like quantization reduce the inference latency of TREASURE without compromising its high-cardinality prediction accuracy?

## Limitations
- Core results depend on proprietary datasets and internal metrics that cannot be independently verified
- Effectiveness of mechanisms demonstrated only on specific dataset, generalizability to other domains uncertain
- Paper does not report variance across multiple runs or ablations, limiting statistical significance assessment

## Confidence
- **High confidence**: Architectural mechanisms are technically sound and partially validated through controlled ablations
- **Medium confidence**: Large improvements reported but rely on internal, non-public metrics and datasets
- **Low confidence**: Claim about providing cardholder behavioral embeddings lacks specificity about embedding space geometry

## Next Checks
1. Reimplement TREASURE on an open financial transaction dataset and evaluate against standard baselines using public metrics
2. Systematically vary the number of shared negatives and compare Prec@1 on high-cardinality attributes while monitoring memory usage
3. Train TREASURE with alternative loss weighting schemes and track per-task loss curves to determine if dynamic scaling consistently prevents auxiliary task dominance