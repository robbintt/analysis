---
ver: rpa2
title: Explainable Depression Detection using Masked Hard Instance Mining
arxiv_id: '2505.24609'
source_url: https://arxiv.org/abs/2505.24609
tags:
- attention
- encoder
- dual
- depression
- mhim
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method to improve explainability in text-based
  depression detection using Masked Hard Instance Mining (MHIM). The core idea is
  to strategically mask high-attention features in the model, forcing it to distribute
  attention across a wider range of salient features.
---

# Explainable Depression Detection using Masked Hard Instance Mining

## Quick Facts
- arXiv ID: 2505.24609
- Source URL: https://arxiv.org/abs/2505.24609
- Reference count: 0
- Primary result: MHIM improves depression detection accuracy and attention-based explainability on Thai-Maywe and DAIC-WOZ datasets

## Executive Summary
This paper introduces Masked Hard Instance Mining (MHIM) to improve explainability in text-based depression detection. The method strategically masks high-attention features during training, forcing the model to distribute attention across a wider range of salient features. Evaluated on Thai-Maywe and DAIC-WOZ datasets, MHIM significantly improves both prediction accuracy and explainability metrics. The approach demonstrates that controlling attention patterns through masking can enhance model interpretability while maintaining or improving predictive performance.

## Method Summary
The method uses a two-phase training pipeline for Multi-Instance Learning depression detection. Phase-1 trains a Dual Encoder (Prefix Encoder + Sentence Encoder → Bi-LSTM → Attention → score) on interview dialogues. Phase-2 applies Masked Hard Instance Mining by masking attention-guided tokens from Phase-1's output: top t tokens from top r attention weights and bottom b tokens, where r = 2t and N = t + b. This creates "hard" training samples that force the receiver model to develop diverse attention patterns rather than over-relying on easily detectable signals.

## Key Results
- Thai-Maywe dataset: Dual Encoder with MHIM achieved RMSE 0.48 and MAE 0.33 for HAM-D prediction versus 0.54 and 0.37 without MHIM
- Attention entropy increased from 2.158 to 2.496 on Thai-Maywe, indicating better feature distribution
- Recall@k explainability improved across all thresholds (k=50%: 0.52 → 0.62)
- Similar improvements observed on DAIC-WOZ dataset

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Masking high-attention features forces the model to distribute attention across a wider range of salient features, improving both prediction and explainability.
- **Mechanism:** During Phase-2 training, the "receiver" model is blinded to features that the Phase-1 "donor" model strongly attended to. This creates a learning pressure to identify secondary indicators rather than overfitting to a few dominant signals (e.g., suicide mentions while ignoring sleep disturbances).
- **Core assumption:** Depression manifests through multiple linguistic cues across a conversation, and models trained on low-resource data overfit to easily detectable signals.
- **Evidence anchors:** [abstract] "MHIM strategically masks attention weights within the model, compelling it to distribute attention across a wider range of salient features." [section 3] "This effectively blinds the receiver from attending to the doner's top attentive tokens, encouraging diverse attention pattern in the receiver." [corpus] LMILAtt paper supports the MIL + attention combination for depression detection, but does not directly validate MHIM's masking approach.
- **Break condition:** If the donor model's attention is already well-distributed (high entropy), masking may degrade performance by removing genuinely important features.

### Mechanism 2
- **Claim:** The two-phase training pipeline creates a form of self-supervised data augmentation within the MIL framework.
- **Mechanism:** The donor model's attention weights serve as pseudo-labels for which instances are "easy." By masking these, MHIM synthesizes harder training samples without requiring additional annotations.
- **Core assumption:** The donor model's high-attention features represent over-reliance rather than true signal importance.
- **Evidence anchors:** [section 3] "We believe that by spreading out the attention weights, more diverse information aggregation is encouraged, providing better prediction performance and explainability at the same time." [section 2.3] "MHIM is a data augmentation technique designed for MIL models... creates 'hard' positive or negative samples by masking portions of the input." [corpus] Related papers (DepressionX, AttentionDep) explore attention-based explainability but do not address the low-data overfitting problem MHIM targets.
- **Break condition:** If the donor model is severely undertrained or misidentifies key features, the receiver inherits poor masking guidance.

### Mechanism 3
- **Claim:** Entropy of attention weights serves as a proxy for explainability quality.
- **Mechanism:** Higher attention entropy indicates the model is considering more dialogue turns. This is validated through Recall@k against human-annotated Importance Sentence Labels (ISL).
- **Core assumption:** Human experts' ISL annotations correctly identify all depression-relevant sentences; dispersed attention should align with these.
- **Evidence anchors:** [section 5.1] "The entropy increases when the MHIM is applied" (2.158 → 2.819 for overall HAM-D). [table 2] Recall@k improves at all k thresholds (e.g., k=50%: 0.52 → 0.62). [corpus] No direct corpus validation for entropy as explainability proxy in depression detection.
- **Break condition:** If ISL annotations miss subtle indicators or disagree across annotators, Recall@k becomes unreliable.

## Foundational Learning

- **Concept: Multi-Instance Learning (MIL)**
  - **Why needed here:** Interviews are weakly labeled—one score for the entire conversation. MIL treats turns as unlabeled instances within a labeled bag.
  - **Quick check question:** Given a bag label yi=1 and instances {xi1, xi2, xi3}, can you determine which instance caused the positive label? (Answer: No, individual instance labels are unknown in weak supervision.)

- **Concept: Attention as Aggregation and Explanation**
  - **Why needed here:** The attention layer both summarizes the conversation and provides interpretability through weight inspection.
  - **Quick check question:** If attention weights are [0.7, 0.1, 0.1, 0.1], what does this imply about the model's reliance? (Answer: The model is over-relying on the first instance.)

- **Concept: Hard Instance Mining**
  - **Why needed here:** MHIM augments training by masking "easy" instances, forcing the model to learn from harder ones.
  - **Quick check question:** Why mask both top and bottom attention instances? (Answer: Top masks prevent over-reliance; bottom masks encourage generalization/diversification.)

## Architecture Onboarding

- **Component map:** Input Dialogue → [Prefix Encoder + Sentence Encoder] → Turn Embeddings → Bi-LSTM → Attention Layer (with MHIM masking in Phase-2) → Weighted Sum → Depression Score (HAM-D/PHQ-8)

- **Critical path:** The attention layer is the bottleneck for both prediction and explainability. MHIM operates exclusively here during training.

- **Design tradeoffs:**
  - **Masking ratio (t, b, r):** Higher t increases regularization but risks removing critical signal. Paper sets r=2t and tunes t/b on validation.
  - **Two-phase vs. end-to-end:** Two-phase is simpler but requires training two models. End-to-end could be more efficient but is unexplored.
  - **Complete masking vs. soft masking:** Paper uses hard masking; partial masking could preserve some signal from important features.

- **Failure signatures:**
  - Low entropy + high accuracy: Model may be overfitting to artifacts (e.g., specific phrases).
  - High entropy + low accuracy: Masking too aggressive; model cannot find signal.
  - Large gap between donor and receiver attention distributions: Potential training instability.

- **First 3 experiments:**
  1. **Reproduce baseline metrics** on Thai-Maywe (5-fold CV) without MHIM to establish Dual Encoder RMSE/MAE baseline.
  2. **Ablation on masking ratios:** Sweep t ∈ {1, 2, 3, 5} and b ∈ {0, 1, 2} to find optimal N = t + b for your dataset size.
  3. **Attention entropy monitoring:** Log entropy per epoch during Phase-2 training to verify convergence to higher entropy than Phase-1.

## Open Questions the Paper Calls Out
None

## Limitations
- Unknown masking ratio parameters (t, b, r) prevent exact reproduction of reported improvements
- Two-phase training doubles training time and requires careful checkpoint management
- No validation of entropy as explainability proxy against clinical interpretability standards
- Does not explore soft masking variants or end-to-end training alternatives

## Confidence
- **High confidence:** MHIM improves attention entropy distribution (measured via entropy increase from 2.158 to 2.496 on Thai-Maywe)
- **Medium confidence:** MHIM improves Recall@k explainability metrics (e.g., k=50% from 0.52 to 0.62)
- **Medium confidence:** MHIM improves prediction accuracy (RMSE 0.48 vs 0.54 on Thai-Maywe)
- **Low confidence:** The mechanism that masking high-attention features prevents overfitting to "easily detectable signals" like suicide mentions

## Next Checks
1. **Reproduce the baseline Dual Encoder performance** on Thai-Maywe using 5-fold cross-validation without MHIM. Verify that your Phase-1 model achieves RMSE ≈ 0.54 and MAE ≈ 0.37 for HAM-D prediction before proceeding to Phase-2.

2. **Ablate the masking ratios** systematically. For your dataset, sweep t ∈ {1, 2, 3, 5} with b ∈ {0, 1, 2} and r = 2t. Plot both validation RMSE and attention entropy per epoch to identify the optimal N = t + b that balances performance and explainability.

3. **Validate the entropy-explainability correlation** independently. Compute Recall@k on your Phase-1 and Phase-2 models, then correlate these scores with attention entropy across epochs. Check if higher entropy consistently aligns with better Recall@k, or if there are regimes where entropy increases without explainability gains.