---
ver: rpa2
title: 'WanJuanSiLu: A High-Quality Open-Source Webtext Dataset for Low-Resource Languages'
arxiv_id: '2501.14506'
source_url: https://arxiv.org/abs/2501.14506
tags:
- data
- quality
- corpus
- language
- content
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents WanJuanSiLu, a high-quality open-source webtext
  dataset for low-resource languages. The dataset addresses the challenge of developing
  large language models for low-resource languages by providing a systematic data
  processing framework that includes data extraction, corpus cleaning, deduplication,
  security filtering, quality evaluation, and theme classification.
---

# WanJuanSiLu: A High-Quality Open-Source Webtext Dataset for Low-Resource Languages

## Quick Facts
- arXiv ID: 2501.14506
- Source URL: https://arxiv.org/abs/2501.14506
- Reference count: 14
- Primary result: 350M+ documents, 1.2TB data, 300B tokens across 5 low-resource languages with 95.74% quality scores and comprehensive security filtering

## Executive Summary
This paper introduces WanJuanSiLu, a systematically processed webtext dataset designed for low-resource language modeling across Thai, Russian, Arabic, Korean, and Vietnamese. The dataset addresses the scarcity of high-quality training data for these languages through a comprehensive pipeline that includes text extraction, language detection, noise removal, two-stage quality filtering using perplexity and BERT classification, fuzzy deduplication, multi-level security filtering, and structured thematic classification. The resulting corpus achieves high quality scores (95.74% average) while maintaining strong safety standards, with 7 major categories and 34 subcategories for domain-aware training data composition.

## Method Summary
The method employs a multi-stage processing pipeline: raw HTML is extracted and converted to JSON Lines, then filtered by language using FastText detection. Rule-based cleaning removes noise including short documents, HTML artifacts, and abnormal whitespace. Two-stage quality filtering uses KenLM 5-gram perplexity scoring (threshold ≤0.2) followed by multilingual-BERT classification trained on contrastive high/low-quality pairs. MinHash-based fuzzy deduplication removes near-duplicates using Jaccard similarity. Security filtering combines domain blacklisting, optimized sensitive word lists, and an XLM-RoBERTa-base multi-label classifier for pornography, gambling, drugs, and violence detection. Finally, a FastText classifier assigns documents to 7 primary and 34 secondary thematic categories using LLM-generated training labels.

## Key Results
- 350 million documents, 1.2TB of data, 300 billion tokens across 5 low-resource languages
- Comprehensive quality evaluation showing 95.74% average quality scores across languages
- Security filtering system achieves high recall and precision rates for benign samples (0.939 and 0.968) and good performance for harmful content detection (0.72 and 0.589)
- Data volume reduced by 30-50% through two-stage quality filtering while preserving high-value content

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Two-stage quality filtering efficiently reduces noise while retaining high-value content for low-resource languages.
- Mechanism: Stage 1 uses perplexity (PPL) scoring against Wikipedia reference corpora with a 5-gram language model to filter low-quality text (threshold: PPL ≤ 0.2). Stage 2 applies a multilingual-BERT classifier trained on contrastive high/low-quality pairs to refine remaining candidates. This cascaded approach filters 30-50% of data while preserving high-quality samples.
- Core assumption: PPL correlates inversely with text quality in low-resource languages, and Wikipedia provides a valid reference distribution.
- Evidence anchors:
  - [abstract] "comprehensive quality evaluation showing 95.74% average quality scores across languages"
  - [section 3.2] "this method reduced the data volume by 37% for Korean data, with reductions of 30% to 50% in other languages"
  - [corpus] Neighbor papers (LaoBench, LuxInstruct) confirm quality filtering is critical for low-resource language datasets, though specific PPL thresholds are not validated externally.
- Break condition: If PPL thresholds are set too aggressively, domain-specific vocabulary (e.g., technical, legal terms) may be incorrectly filtered, reducing diversity.

### Mechanism 2
- Claim: Multi-level security filtering combines lexical and semantic methods to detect harmful content with acceptable precision-recall trade-offs.
- Mechanism: Three layers operate sequentially: (1) domain blacklist blocks known harmful sources, (2) optimized sensitive word lists filtered using IDF and intra-document density metrics reduce false positives, (3) an xlm-roberta-base multi-label classifier detects pornography, gambling, drugs, and violence across languages. Training data is augmented via cross-lingual translation and stratified sampling by sensitive word density.
- Core assumption: Harmful content patterns transfer across related languages via translation augmentation, and expert-validated sensitive word lists generalize beyond annotated samples.
- Evidence anchors:
  - [abstract] "security filtering system achieves high recall and precision rates for benign samples (0.939 and 0.968) and good performance for harmful content detection (0.72 and 0.589)"
  - [section 3.3] "model achieved recall and precision rates of 0.939 and 0.968 for benign samples, respectively, and recall and precision rates of 0.72 and 0.589 for harmful samples"
  - [corpus] No direct external validation of these specific security metrics found in neighbor papers. Assumption: Performance may vary significantly by language and harm category.
- Break condition: Low precision for harmful content (0.589) indicates ~41% false positive rate; over-filtering may remove legitimate cultural or medical content, particularly for topics like "drugs" in healthcare contexts.

### Mechanism 3
- Claim: Structured thematic classification with LLM-generated labels enables domain-aware training data composition.
- Mechanism: A two-tier taxonomy (7 primary, 34 secondary categories) is defined based on corpus distribution analysis. LLM prompting generates initial high-quality labels on sample documents. A FastText classifier trained on these labels then scales to the full corpus, providing efficient multilingual document categorization.
- Core assumption: LLM-generated labels are sufficiently accurate to serve as training targets, and FastText's linear architecture captures enough semantic signal for cross-lingual topic transfer.
- Evidence anchors:
  - [abstract] "organized into 7 major categories and 34 subcategories"
  - [section 3.4] "employed the Prompt technique of large language models to generate high-quality classification labels"
  - [corpus] No external validation of classification accuracy metrics. Assumption: Topic boundary ambiguity (e.g., "Local Life" vs. "Culture") may cause inconsistent labeling across languages.
- Break condition: If LLM prompt quality varies by language or topic, label noise propagates through FastText training, degrading downstream domain balancing.

## Foundational Learning

- Concept: **Perplexity (PPL) as quality proxy**
  - Why needed here: Understanding why PPL filtering works requires grasping how language models assign probability to sequences and why "unnatural" text (spam, boilerplate, encoding errors) yields higher PPL.
  - Quick check question: Given a PPL threshold of 0.2, would formal legal documents with specialized terminology likely be retained or filtered?

- Concept: **MinHash-based fuzzy deduplication**
  - Why needed here: The pipeline uses MinHash for near-duplicate detection; understanding Jaccard similarity approximation via hash signatures is essential for tuning dedup parameters.
  - Quick check question: If two documents share 80% n-gram overlap but one has additional unique paragraphs, will MinHash with default settings likely flag them as duplicates?

- Concept: **Cross-lingual transfer for low-resource NLP**
  - Why needed here: The security model uses xlm-roberta-base, trained on high-resource languages, applied to low-resource targets; understanding representation sharing across languages explains both successes and failure modes.
  - Quick check question: If Arabic harmful content training data is limited, how does the model leverage English or Russian patterns to detect Arabic violations?

## Architecture Onboarding

- Component map:
  ```
  Raw HTML → [Text Extraction] → JSON Lines
           → [Language Detection (FastText)] → Target Language Filter
           → [Rule-based Cleaning] → Noise Removal
           → [PPL Scoring (KenLM 5-gram)] → Stage 1 Quality Filter
           → [Quality Classifier (mBERT)] → Stage 2 Quality Filter
           → [MinHash Deduplication] → Redundancy Removal
           → [Security Pipeline: Blacklist + Sensitive Words + XLM-RoBERTa] → Safe Corpus
           → [Topic Classifier (FastText)] → Labeled Output
  ```

- Critical path: The PPL threshold setting (currently 0.2) is the highest-leverage parameter—small changes cascade through all downstream stages, affecting final data volume by 20-40%.

- Design tradeoffs:
  - PPL filtering is fast but language-specific; requires separate KenLM models per language.
  - BERT quality classifier is accurate but computationally expensive; applied only post-PPL to reduce cost.
  - Security classifier favors benign precision (0.968) over harmful precision (0.589); prioritizes avoiding false accusations over catching all violations.

- Failure signatures:
  - Sudden topic distribution skew after classification → LLM prompt quality degraded for specific language.
  - High dedup removal rate (>90%) → Hash collision or overly aggressive similarity threshold.
  - Security model flags medical/pharmaceutical content → "Drugs" category lacks domain context handling.

- First 3 experiments:
  1. Ablation study: Train identical models on (a) full pipeline output, (b) PPL-filtered only, (c) no filtering. Measure downstream task performance (MGSM, language understanding benchmarks) to quantify each stage's contribution.
  2. Threshold sensitivity analysis: Vary PPL threshold (0.1, 0.15, 0.2, 0.25, 0.3) for one language; plot retained data volume vs. quality score distribution to identify optimal operating point.
  3. Security model error analysis: Sample 200 false positives from the harmful content classifier across all five languages; manually categorize error types (domain context, translation artifacts, cultural nuance) to guide list refinement.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the precision gap in toxic content detection (0.589) be improved without compromising benign sample recall (0.939)?
- Basis in paper: [explicit] Table 5 shows asymmetric performance: non-toxic precision/recall (0.968/0.939) versus toxic precision/recall (0.589/0.72), indicating the safety model struggles with harmful content identification.
- Why unresolved: The paper acknowledges the security filtering system but does not propose methods to address the 38% precision gap between benign and toxic detection.
- What evidence would resolve it: Experiments with class-balanced training data, threshold tuning, or ensemble methods showing improved toxic precision while maintaining benign recall above 0.90.

### Open Question 2
- Question: Does the perplexity threshold of 0.2, empirically determined on Korean data, generalize optimally across all five languages?
- Basis in paper: [inferred] Section 3.2 states the PPL threshold was set based on Korean data analysis (Figure 4), then applied to all languages with 30-50% data reduction, but language-specific validation is not provided.
- Why unresolved: The relationship between PPL and quality scores may vary across languages with different morphological complexity or corpus characteristics.
- What evidence would resolve it: Language-specific PPL-quality correlation analyses and ablation studies testing different thresholds per language on downstream task performance.

### Open Question 3
- Question: Is a 20,000-sample manual inspection statistically representative for quality assessment across 350+ million documents spanning five languages?
- Basis in paper: [inferred] Section 4.2 mentions experts reviewed "over 20,000 sample entries" for a corpus containing 356,786,875 documents—a sampling rate of approximately 0.0056%.
- Why unresolved: The paper does not report confidence intervals, stratification by language/theme, or statistical power analysis for this sampling strategy.
- What evidence would resolve it: Statistical analysis showing confidence bounds for quality estimates, or comparison of random vs stratified sampling approaches with variance metrics.

### Open Question 4
- Question: What is the downstream task performance impact across diverse NLP benchmarks beyond MGSM?
- Basis in paper: [inferred] Section 4.3 mentions only MGSM (math reasoning) as validation; broader linguistic capabilities—translation, QA, classification—across low-resource languages remain unreported.
- Why unresolved: The paper claims the dataset advances multilingual model development but provides limited evidence of generalization benefits.
- What evidence would resolve it: Comprehensive benchmark evaluations (e.g., FLORES, XNLI, TyDi QA) comparing models trained on WanJuanSiLu versus baselines across multiple task types.

## Limitations

- **Data provenance and representativeness**: The specific web sources, time periods, and sampling strategies remain underspecified, raising concerns about coverage and potential biases across different low-resource language web ecosystems.
- **Quality evaluation methodology**: Reliance on LLM-generated binary judgments across seven dimensions without reporting inter-rater reliability or human validation limits confidence in the 95.74% quality score claims.
- **Security filtering trade-offs**: The asymmetric performance (0.589 precision for harmful vs 0.968 for benign content) suggests conservative filtering that may remove legitimate content while still failing to catch all harmful material.

## Confidence

- **Data volume and organization claims**: High confidence - The abstract provides specific, verifiable numbers (350M documents, 1.2TB, 300B tokens, 7/34 category taxonomy) that can be independently validated through dataset inspection.
- **Quality filtering effectiveness**: Medium confidence - While the paper reports specific metrics (37% reduction for Korean, 30-50% for others) and 95.74% quality scores, the lack of external validation or comparison with alternative filtering approaches limits confidence in these claims.
- **Security filtering performance**: Medium confidence - The reported recall/precision metrics (0.939/0.968 for benign, 0.72/0.589 for harmful) are specific but appear only in abstract and methodology sections without detailed error analysis or cross-validation across languages.
- **Thematic classification accuracy**: Low confidence - The paper claims successful LLM-generated labeling and FastText classification but provides no accuracy metrics, confusion matrices, or human evaluation of topic assignment quality.

## Next Checks

1. **Ablation study on downstream performance**: Train identical language models using (a) full WanJuanSiLu pipeline output, (b) PPL-filtered only, (c) no filtering, and (d) alternative datasets like CCAligned or WikiMatrix. Measure performance on MGSM benchmarks and language understanding tasks to quantify each filtering stage's contribution and validate the 95.74% quality score claim.

2. **Security model bias and error analysis**: Sample 200 false positives and 200 false negatives from the harmful content classifier across all five languages. Categorize errors by type (domain context, translation artifacts, cultural nuance, ambiguous content) and language to identify systematic biases. Compute per-language and per-harm category precision-recall curves to validate the aggregate 0.72/0.589 metrics.

3. **Topic classification consistency audit**: Randomly sample 500 documents from each language and manually verify their assigned topic labels against the 7 primary and 34 secondary categories. Measure inter-annotator agreement and compute classification accuracy compared to LLM-generated labels. Analyze cross-lingual label consistency for identical topics (e.g., "Sports" in Thai vs. Korean) to validate the taxonomy's cross-lingual applicability.