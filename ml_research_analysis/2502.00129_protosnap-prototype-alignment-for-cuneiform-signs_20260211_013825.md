---
ver: rpa2
title: 'ProtoSnap: Prototype Alignment for Cuneiform Signs'
arxiv_id: '2502.00129'
source_url: https://arxiv.org/abs/2502.00129
tags:
- cuneiform
- sign
- image
- signs
- prototype
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ProtoSnap, an unsupervised method for aligning
  prototype skeletons to photographed cuneiform signs. The approach leverages deep
  diffusion features to compute a semantically-adapted similarity volume between prototype
  font images and real cuneiform images, followed by global alignment using best-buddies
  correspondences and local refinement via skeleton-based optimization.
---

# ProtoSnap: Prototype Alignment for Cuneiform Signs

## Quick Facts
- **arXiv ID**: 2502.00129
- **Source URL**: https://arxiv.org/abs/2502.00129
- **Reference count**: 28
- **Primary result**: Unsupervised method aligning prototype skeletons to photographed cuneiform signs, achieving state-of-the-art OCR results for rare signs.

## Executive Summary
ProtoSnap introduces an unsupervised method for aligning prototype font images of cuneiform signs to photographed tablet images. The approach leverages fine-tuned diffusion features, best-buddies correspondences, and per-stroke projective optimization to achieve accurate keypoint localization. The method significantly outperforms generic baselines on expert-annotated data and demonstrates utility for generating synthetic training data that improves rare sign recognition.

## Method Summary
ProtoSnap aligns skeleton-based prototype images to photographed cuneiform signs through a three-stage process. First, it extracts semantically-adapted diffusion features by fine-tuning Stable Diffusion on cuneiform images. Second, it computes a 4D similarity volume between prototype and target, identifies best-buddies correspondences, and fits a global affine transformation. Third, it refines alignment locally by optimizing per-stroke projective transformations to maximize feature similarity while respecting saliency and regularization constraints.

## Key Results
- Outperforms generic correspondence matching baselines on expert-annotated benchmark (F1@20/30/40 metrics)
- Achieves state-of-the-art OCR results for rare signs using synthetic data generated via ProtoSnap alignment
- Demonstrates generalization to previously unseen sign types and languages through qualitative examples

## Why This Works (Mechanism)

### Mechanism 1
Fine-tuned diffusion features capture cuneiform semantics better than generic visual features. Standard Stable Diffusion features are adapted by fine-tuning on cuneiform images with sign names as text prompts, grounding the feature space in the target domain and enabling meaningful similarity comparisons between prototype font images and photographed signs. The core assumption is that cuneiform signs share enough structural regularity across variants for a single fine-tuned model to capture their semantics.

### Mechanism 2
Best-buddies correspondences provide sparse but robust alignment anchors for global fitting. Mutual nearest-neighbor pairs in the 4D similarity volume identify reliable matches, which are then fit with an affine transformation using RANSAC. This allows rotation, scaling, shear, and translation while rejecting outliers. The core assumption is that at least some stroke regions will have mutual maximum similarity between prototype and target.

### Mechanism 3
Per-stroke projective transformations refine alignment while preventing degenerate solutions. Each stroke gets its own projective transformation applied atop the global alignment. The loss combines feature similarity between prototype and transformed skeleton points, saliency encouraging strokes to land on visible wedge regions, and L1 and out-of-bounds regularization. The core assumption is that individual strokes deviate locally from canonical positions but the overall sign identity is preserved by the global transform.

## Foundational Learning

**Concept: Diffusion features (DIFT)**
- Why needed here: ProtoSnap extracts features from intermediate U-Net layers of a denoising diffusion model rather than using standard CNN features. Understanding how generative models encode semantics is essential for debugging the similarity volume.
- Quick check question: Can you explain why adding noise to an image and passing it through a denoising network yields semantically meaningful features?

**Concept: Mutual nearest neighbors (best-buddies)**
- Why needed here: The global alignment depends on identifying correspondences that are each other's closest match in feature space, which is more robust than one-way nearest neighbors.
- Quick check question: Given two sets of points in a shared feature space, how would you identify best-buddy pairs, and why might this reject spurious matches?

**Concept: Projective transformations**
- Why needed here: Local refinement uses per-stroke projective transforms (8 DOF) rather than affine (6 DOF) or rigid transforms, allowing perspective-like deformations for handwritten variation.
- Quick check question: What is the difference between affine and projective transformations in terms of what geometric properties they preserve?

## Architecture Onboarding

**Component map:**
1. SD-ùíû (fine-tuned Stable Diffusion) ‚Üí DIFT feature extraction
2. 4D similarity volume S ‚Üí pairwise cosine similarities (H√óW√óH√óW)
3. Best-buddies extraction ‚Üí sparse correspondences
4. RANSAC + affine fitting ‚Üí global transformation G
5. Per-stroke projective transforms P^(i) ‚Üí local refinement
6. Loss function (Lsim, Lsal, Lreg) ‚Üí gradient descent optimization

**Critical path:** Fine-tuned diffusion model quality ‚Üí meaningful DIFT features ‚Üí valid best-buddies ‚Üí accurate global alignment ‚Üí initialized local transforms ‚Üí converged per-stroke positions. Failures propagate downstream.

**Design tradeoffs:**
- Affine (global) vs projective (local): Global uses affine to preserve sign structure; local uses projective for finer stroke-level flexibility
- Sparse vs dense correspondences: Best-buddies are sparse but robust; using all correspondences would be noisy
- Regularization strength: Too high ‚Üí strokes cannot adapt; too low ‚Üí degenerate configurations

**Failure signatures:**
- Low inlier count in RANSAC: Prototype and target may be structurally different variants
- Strokes collapsing to single point: Regularization too weak or saliency map unreliable
- Out-of-bounds keypoints: Global transform may have failed; check input image quality

**First 3 experiments:**
1. Reproduce the DIFT feature extraction on a single prototype-target pair; visualize the 4D similarity volume slices to verify meaningful peaks exist
2. Ablate the fine-tuned SD-ùíû by using base Stable Diffusion; compare F1@20/30/40 scores on the annotated test set to quantify domain adaptation impact (Table 5 shows drop from 27.14% to 19.01% F1@20)
3. Test the full pipeline on the JOCCH dataset (Hittite signs, Figure 11) to verify generalization to unseen sign types and languages; inspect qualitative alignment quality

## Open Questions the Paper Calls Out

### Open Question 1
Can a confidence measure be developed to automatically detect alignment failure cases, such as when a scan depicts a structurally different sign variant or suffers from extreme deformation? The paper explicitly states future work might investigate confidence measures to detect such failure cases, as the current method may fail on low-quality scans or structurally different variants without flagging these errors.

### Open Question 2
Can the per-stroke optimization framework be adapted for ancient scripts with curved geometric configurations, such as Chinese oracle bone inscriptions, by replacing wedge primitives with Bezier splines? The conclusion suggests future work might extend this to other ancient scripts with different geometric configurations using more flexible primitives like Bezier splines.

### Open Question 3
Can ProtoSnap be integrated into a pipeline that processes full lines of text or 3D scans directly, rather than relying on pre-cropped images of individual signs? The paper foresees future work extending these results to lines of text applied either to images or directly to 3D scans of inscriptions, as the current method inputs are single sign crops and relies on existing bounding boxes.

## Limitations
- Fine-tuned model is trained exclusively on eBL dataset, with unquantified performance on structurally distinct cuneiform variants from other time periods or languages
- Method requires high-quality prototype skeletons as input, with untested robustness to annotation errors or tablet damage that obscures critical stroke regions
- Local refinement stage uses fixed regularization weights without sensitivity analysis showing how performance varies across different sign types or tablet conditions

## Confidence
- **High Confidence**: Fine-tuning diffusion features for domain adaptation (Table 5 shows 8-point F1@20 improvement) and using best-buddies correspondences for robust global alignment
- **Medium Confidence**: Downstream OCR performance claims depend on quality of synthetic data generated through ProtoSnap alignment, with synthetic-to-real transfer efficacy not fully isolated
- **Low Confidence**: Claim that ProtoSnap "generalizes to previously unseen sign types" is based on qualitative inspection of Hittite signs rather than quantitative metrics on held-out sign categories

## Next Checks
1. Evaluate ProtoSnap on a completely separate cuneiform corpus (different language, time period, or collection) with expert-annotated alignments to assess true domain adaptation rather than dataset memorization
2. Systematically corrupt prototype skeletons (add noise, remove keypoints, shift positions) and measure degradation in alignment accuracy to quantify sensitivity to imperfect input skeletons
3. Perform grid search over regularization weights (Œª_sal, Œª_reg) and report alignment performance variance with sensitivity plot showing how F1 scores change with each parameter to identify potential brittleness in local refinement stage