---
ver: rpa2
title: 'AIDetection: A Generative AI Detection Tool for Educators Using Syntactic
  Matching of Common ASCII Characters As Potential ''AI Traces'' Within Users'' Internet
  Browser'
arxiv_id: '2503.16503'
source_url: https://arxiv.org/abs/2503.16503
tags:
- text
- chatgpt
- aidetection
- detection
- ascii
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: AIDetection.info is a JavaScript-based web application that helps
  educators detect AI-generated content in student writing by identifying syntactic
  traces left by generative AI models. The tool scans documents for inconsistent text
  encoding, particularly ASCII quotation marks and apostrophes, which are common in
  AI-generated text.
---

# AIDetection: A Generative AI Detection Tool for Educators Using Syntactic Matching of Common ASCII Characters As Potential 'AI Traces' Within Users' Internet Browser

## Quick Facts
- arXiv ID: 2503.16503
- Source URL: https://arxiv.org/abs/2503.16503
- Authors: Andy Buschmann
- Reference count: 0
- Primary result: Heuristic-based JavaScript tool detects AI-generated content via ASCII encoding inconsistencies and AI tool mentions

## Executive Summary
AIDetection.info is a JavaScript-based web application that helps educators detect AI-generated content in student writing by identifying syntactic traces left by generative AI models. The tool scans documents for inconsistent text encoding, particularly ASCII quotation marks and apostrophes, which are common in AI-generated text. It also detects direct mentions of AI tools to assess whether students have properly acknowledged AI use. The application processes PDF and Word files in bulk, provides color-coded visual summaries, and generates downloadable Excel and CSV reports. By performing client-side analysis within the browser, AIDetection complies with data privacy regulations while offering educators a transparent, heuristic-based alternative to opaque machine learning detectors.

## Method Summary
The tool processes PDF and Word documents entirely within the user's browser using JavaScript libraries (PDF.js for PDF parsing, Mammoth.js for Word extraction, ExcelJS for reporting) loaded via CDN. It applies regular expressions to count ASCII versus non-ASCII quotation marks and apostrophes, flagging intra-document inconsistency. The tool also scans for case-insensitive mentions of known AI tools (ChatGPT, Claude, Gemini, Llama/Meta, Copilot, Grammarly) to detect acknowledgment. Results are color-coded: green for no traces or acknowledged use, red for traces without acknowledgment, and black for all-ASCII (indeterminate) documents. No document content is transmitted to external servers, ensuring compliance with FERPA/GDPR regulations.

## Key Results
- Successfully identified inconsistent ASCII encoding in AI-generated student essays
- Detected unacknowledged AI use in an undergraduate writing course
- Provided educators with transparent, explainable detection results without data privacy concerns

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Inconsistent character encoding within a single document can indicate copy-pasted AI-generated text.
- Mechanism: LLMs predominantly output ASCII-encoded punctuation (straight quotes: `"` and `'`) due to training on plain-text corpora and tokenization efficiency. Modern word processors (MS Word, Google Docs) default to UTF-8/UTF-16, producing typographic curly quotes (`" "` and `' '`). When users copy-paste AI output into these processors, ASCII characters persist as embedded artifacts. The tool applies regular expressions to count ASCII versus non-ASCII quotation marks and apostrophes, flagging intra-document inconsistency.
- Core assumption: Students submit essays written primarily in word processors that produce non-ASCII punctuation, and mixed encoding indicates external copy-paste sources.
- Evidence anchors: [section] "ASCII characters, particularly quotation marks, frequently appear in LLM outputs for multiple reasons... LLMs are also trained on published (and commented) source code. Programming languages are (usually) limited to ASCII characters."
- Break condition: If a student writes entirely in an ASCII-only editor (e.g., certain code editors, FreeBSD environments) or consistently copies from ASCII-based web sources (e.g., Wikipedia), the heuristic yields uninterpretable results (flagged as "Black" in the UI).

### Mechanism 2
- Claim: Explicit AI tool mentions can differentiate acknowledged versus unacknowledged AI use.
- Mechanism: The tool applies case-insensitive regular expressions to scan extracted text for string variants of known AI tools (ChatGPT, Claude, Gemini, Llama/Meta, Copilot, Grammarly). Presence of these terms flags potential acknowledgment; absence combined with encoding anomalies suggests unacknowledged use.
- Core assumption: Students who acknowledge AI use will explicitly name the tool in the document, and those who do not name it have not acknowledged it.
- Evidence anchors: [abstract] "It also detects direct mentions of AI tools to assess whether students have properly acknowledged AI use."
- Break condition: Essays about AI topics (e.g., a paper discussing ChatGPT's societal impact) will trigger false positives for AI acknowledgment even when no AI was used in writing.

### Mechanism 3
- Claim: Client-side JavaScript processing preserves student data privacy while enabling bulk document analysis.
- Mechanism: The application runs entirely within the user's browser using JavaScript libraries (PDF.js for PDF parsing, Mammoth.js for Word extraction, ExcelJS for reporting) loaded via CDN. No document content is transmitted to external servers. This architecture satisfies FERPA/GDPR constraints without requiring institutional data agreements.
- Core assumption: Educators have modern browsers with sufficient local memory to process documents; users trust CDN-delivered libraries.
- Evidence anchors: [abstract] "By performing client-side analysis within the browser, AIDetection complies with data privacy regulations while offering educators a transparent, heuristic-based alternative to opaque machine learning detectors."
- Break condition: Processing >1000 documents in a single session may cause browser crashes depending on local resources.

## Foundational Learning

- Concept: **Character Encoding (ASCII vs. UTF-8/UTF-16)**
  - Why needed here: The entire detection mechanism rests on understanding that ASCII uses 7-8 bits with limited character support, while UTF-8/16 are variable-width encodings that include typographic variants. Without this, the "straight vs. curly quote" distinction is opaque.
  - Quick check question: In UTF-8, does the character `"` (straight quote) require more or fewer bytes than `"` (left curly quote)?

- Concept: **Regular Expressions for Pattern Matching**
  - Why needed here: The tool uses regex to count quotation mark variants and detect AI tool name variants. Understanding regex flags (case-insensitivity, whitespace tolerance) is necessary to modify or extend detection patterns.
  - Quick check question: Write a case-insensitive regex that matches "chatgpt" with optional whitespace (e.g., "Chat GPT").

- Concept: **Client-Side JavaScript Application Architecture**
  - Why needed here: The privacy claim depends on understanding that JavaScript executes in the browser sandbox, and CDN-loaded libraries do not by default send user data externally. This informs trust and compliance assessments.
  - Quick check question: If a JavaScript library loaded via CDN uses `fetch()` to POST data to an external API, would the tool still be "client-side only"?

## Architecture Onboarding

- Component map: File upload -> Date/extension validation -> Text extraction -> Regex detection (encoding + keywords) -> Result classification -> UI display + export generation
- Critical path: File upload → Date/extension validation → Text extraction → Regex detection (encoding + keywords) → Result classification → UI display + export generation
- Design tradeoffs:
  - **Heuristic transparency vs. detection accuracy**: The tool trades ML-classifier sophistication for explainable rules; educators can understand why a document was flagged but may miss AI-written text that uses consistent Unicode or avoids named tool mentions.
  - **Client-side privacy vs. scalability**: No server infrastructure required, but browser memory limits constrain bulk processing (~1000+ documents risk crashes).
  - **Obfuscated production code vs. open-source transparency**: The live site uses JS obfuscation to prevent student reverse-engineering; the accompanying repository provides unobfuscated source for educators.
- Failure signatures:
  - **All-ASCII documents**: Tool returns "Black" (indeterminate); cannot distinguish AI-generated from ASCII-editor-authored text.
  - **Pre-ChatGPT documents with ASCII artifacts**: Likely human plagiarism from web sources, misattributed as AI traces.
  - **AI-discussion essays**: False positive acknowledgment detection when AI tool names appear in analytical content.
  - **Non-Latin scripts**: Chinese, Arabic, and other non-ASCII-compatible languages are not supported.
- First 3 experiments:
  1. **Baseline validation**: Assemble 50 human-written essays (pre-2020) and 50 ChatGPT-generated essays on identical prompts. Run through AIDetection.info and calculate true positive rate, false positive rate, and indeterminate rate. Document which ASCII characters are most discriminative.
  2. **Encoding consistency stress test**: Generate AI text, manually copy-paste into MS Word, Google Docs, and Notepad. Re-export as .docx and .pdf from each. Run detection to verify whether export format affects encoding artifact preservation.
  3. **Acknowledgment keyword audit**: Submit essays that discuss AI tools without using them (e.g., a media studies paper analyzing ChatGPT). Verify whether the tool incorrectly classifies these as "acknowledged AI use" and document threshold adjustments needed.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Will syntactic indicators (ASCII character patterns) persist in LLM outputs as models evolve, or will future models adopt Unicode formatting by default?
- Basis in paper: [explicit] "While detection tools that analyze semantics may become increasingly unreliable as AI progresses, syntactic indicators of AI use are likely to persist."
- Why unresolved: This is a conjecture based on current model behavior; training data and tokenization choices may change in future LLM versions.
- What evidence would resolve it: Longitudinal analysis of ASCII vs. Unicode character usage across successive generations of major LLMs (GPT-4, GPT-5, Claude versions, etc.).

### Open Question 2
- Question: What is the false positive rate of AIDetection when analyzing student writing composed in ASCII-only text editors or copied from non-AI web sources?
- Basis in paper: [inferred] The paper acknowledges that "ASCII characters could originate from other copied sources like Wikipedia or uncommon document editors that do not support Unicode" but provides no quantification.
- Why unresolved: No controlled validation study comparing detection results against ground truth for non-AI texts with ASCII artifacts.
- What evidence would resolve it: Systematic evaluation on a corpus of pre-ChatGPT student papers and web-sourced texts processed through ASCII-only editors.

### Open Question 3
- Question: How does the heuristic-based ASCII detection accuracy compare to ML-based AI detectors in correctly identifying AI-generated vs. human-written student work?
- Basis in paper: [inferred] The paper positions the tool as an alternative to "opaque machine learning detectors" but does not benchmark performance against them.
- Why unresolved: No comparative evaluation was conducted; the tool was only tested in one course intervention without formal accuracy metrics.
- What evidence would resolve it: Side-by-side evaluation on labeled corpora comparing true positive, false positive, and false negative rates against tools like Turnitin's AI detector and GPTZero.

## Limitations

- Limited validation scope with no systematic evaluation of precision, recall, or false positive rates
- ASCII-encoding heuristic may break down with non-Latin scripts or ASCII-only writing environments
- Simplistic acknowledgment detection conflates analytical discussion with disclosure of AI assistance

## Confidence

**High confidence**: The JavaScript-based client-side architecture and file processing workflow are clearly specified and technically sound. The regex-based text extraction methodology is standard and reproducible.

**Medium confidence**: The ASCII encoding heuristic is plausible given documented LLM text generation patterns, but lacks systematic validation across diverse writing samples and contexts.

**Low confidence**: The effectiveness of the tool for actual AI detection in educational settings is not empirically demonstrated beyond a single case study. The "acknowledged use" detection mechanism is too simplistic for reliable policy enforcement.

## Next Checks

1. **Cross-dataset validation**: Test the tool on a diverse corpus of 500+ essays spanning different disciplines, languages, and writing contexts (human-written, AI-generated, mixed). Calculate precision, recall, F1-score, and false positive/negative rates for both encoding and acknowledgment detection.

2. **Adversarial robustness testing**: Systematically evaluate whether students can evade detection by: (a) manually converting curly quotes to straight quotes, (b) using AI tool synonyms and paraphrasing, (c) writing entirely in ASCII environments, or (d) copying from ASCII-encoded web sources. Document detection failure rates for each evasion strategy.

3. **Comparative effectiveness study**: Benchmark AIDetection against established plagiarism detectors (Turnitin, Copyleaks) and commercial AI detection tools (GPTZero, Originality.ai) using identical test corpora. Measure detection overlap, unique detections, and error patterns to assess relative value for educational policy enforcement.