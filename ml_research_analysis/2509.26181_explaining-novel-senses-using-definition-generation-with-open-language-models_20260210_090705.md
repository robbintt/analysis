---
ver: rpa2
title: Explaining novel senses using definition generation with open language models
arxiv_id: '2509.26181'
source_url: https://arxiv.org/abs/2509.26181
tags:
- definition
- axolotl
- definitions
- sense
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper explores the use of open-weight large language models\
  \ (LLMs) for generating definitions of novel word senses, addressing the challenge\
  \ of interpreting semantic change. The authors fine-tune three instruction-tuned\
  \ open-source models\u2014mT0, Aya-101, and TowerInstruct\u2014on datasets from\
  \ the AXOLOTL\u201924 shared task, which includes Finnish, Russian, and German languages."
---

# Explaining novel senses using definition generation with open language models

## Quick Facts
- **arXiv ID:** 2509.26181
- **Source URL:** https://arxiv.org/abs/2509.26181
- **Reference count:** 21
- **Primary result:** Open-source models (mT0, Aya-101, TowerInstruct) fine-tuned on AXOLOTL'24 data + Dbnary achieve higher BLEU/BERTScore than prior closed-model submissions for novel word-sense definition generation.

## Executive Summary
This paper investigates the use of open-weight large language models for generating human-readable definitions of novel word senses, a task central to understanding semantic change. The authors fine-tune three instruction-tuned models—mT0-XL, Aya-101, and TowerInstruct-7B—on multilingual data from the AXOLOTL'24 shared task (Finnish, Russian, German), augmented with Dbnary (Wiktionary-derived). Their approach achieves higher performance than previous submissions using proprietary models, demonstrating the viability of open-source models for this task. The study also reveals that larger models and datasets improve results, and manual evaluation highlights differences in fluency, adequacy, and circularity across models.

## Method Summary
The authors fine-tune three open-source models (mT0-XL, Aya-101, TowerInstruct-7B) using QLoRA on a combination of AXOLOTL'24 shared task data and Dbnary, with careful filtering to avoid test contamination. For each novel sense, definitions are generated for multiple usage examples using beam search, then embedded and aggregated by selecting the candidate closest to the centroid of all sense definitions. Evaluation uses BLEU and BERTScore, with manual assessment of fluency, adequacy, and circularity. The study compares encoder-decoder (mT0, Aya) and decoder-only (Tower) architectures, as well as training with/without Dbnary.

## Key Results
- Open-source models (mT0-XL + Dbnary) achieve BLEU = 40.5 for German, outperforming prior closed-model submissions.
- Larger models and training datasets consistently improve BLEU and BERTScore across all languages.
- Encoder-decoder and decoder-only models perform similarly; mT0-XL and Aya-101 show higher circularity (self-referential definitions) than TowerInstruct.
- Manual evaluation reveals mT0/Aya models tend to overgenerate dictionary tags, boosting BLEU but reducing fluency.

## Why This Works (Mechanism)
The approach leverages instruction-tuned open models fine-tuned on both AXOLOTL'24 task data and Dbnary, enabling generation of contextually appropriate definitions for novel senses. By aggregating multiple generated definitions per sense via centroid selection, the method reduces noise and selects the most representative definition. The use of multilingual embeddings (distiluse-base-multilingual-cased-v1) allows consistent comparison across languages.

## Foundational Learning
- **QLoRA fine-tuning:** Why needed—efficiently adapts large models to new tasks without full fine-tuning; Quick check—verify LoRA rank and alpha match paper specs.
- **Definition aggregation via centroid selection:** Why needed—reduces variability and selects most prototypical definition; Quick check—inspect top-3 candidates per sense for diversity.
- **Manual evaluation of circularity:** Why needed—BLEU/BERTScore don't capture self-referential definitions; Quick check—sample definitions and count target word occurrences.
- **Dbnary filtering for test contamination:** Why needed—prevents data leakage and inflated metrics; Quick check—confirm no AXOLOTL test words appear in training data.
- **Beam search generation:** Why needed—balances diversity and quality in outputs; Quick check—vary num_beams and length_penalty to observe effect on fluency.

## Architecture Onboarding

**Component map:** AXOLOTL'24 data + Dbnary → QLoRA fine-tuning → Beam search generation → Multilingual embedding → Centroid selection → Final definition

**Critical path:** Data preparation → QLoRA fine-tuning → Inference (beam search) → Aggregation (centroid) → Evaluation (BLEU/BERTScore + manual)

**Design tradeoffs:** Open models vs. proprietary (cost, accessibility, performance); aggregation by centroid vs. random/most confident (robustness vs. simplicity); inclusion of Dbnary vs. task-only (data size vs. contamination risk).

**Failure signatures:**
- High circularity—model defines word using itself (e.g., "a table is a table").
- Label overfitting—excessive dictionary tags instead of semantic content.
- Non-unique definitions—same definition assigned to multiple senses.

**First experiments:**
1. Verify data filtering: ensure no AXOLOTL test words appear in training data.
2. Run a single fine-tuning epoch and inspect generated definitions for circularity.
3. Test aggregation by centroid vs. random selection to measure impact on BLEU/BERTScore.

## Open Questions the Paper Calls Out
None

## Limitations
- Exact Dbnary dump version not specified, introducing potential variability.
- Manual evaluation limited to 20 examples, not fully representative.
- No ablation on aggregation strategy or model size to isolate contributions.

## Confidence

- **High Confidence:** General methodology (QLoRA, prompt-based generation, centroid aggregation) is well-defined and reproducible; BLEU/BERTScore trends align with expectations.
- **Medium Confidence:** Specific performance numbers likely reproducible but may vary with data versions; manual evaluation findings are robust but limited in scope.
- **Low Confidence:** Comparative advantage over closed-model submissions is plausible but not definitively proven without full reproducibility of prior setups.

## Next Checks
1. Confirm exact Dbnary dump version and AXOLOTL'24 data splits; rerun preprocessing to ensure no test contamination and consistent input formatting.
2. Compare definition quality (BLEU/BERTScore + manual metrics) using alternative aggregation strategies (random, majority vote, highest-confidence) to isolate centroid selection impact.
3. Systematically test the effect of different prompt formulations (with/without explicit context, alternative wording) on definition quality and circularity, especially for encoder-decoder vs. decoder-only models.