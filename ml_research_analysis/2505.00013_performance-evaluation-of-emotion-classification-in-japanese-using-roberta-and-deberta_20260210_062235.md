---
ver: rpa2
title: Performance Evaluation of Emotion Classification in Japanese Using RoBERTa
  and DeBERTa
arxiv_id: '2505.00013'
source_url: https://arxiv.org/abs/2505.00013
tags:
- emotion
- emotions
- japanese
- wrime
- eight
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates fine-tuned Japanese PLMs for emotion classification.
  It compares BERT, RoBERTa, and DeBERTa-v3 variants against LLMs on WRIME, a corpus
  with reader-centric emotion annotations.
---

# Performance Evaluation of Emotion Classification in Japanese Using RoBERTa and DeBERTa

## Quick Facts
- arXiv ID: 2505.00013
- Source URL: https://arxiv.org/abs/2505.00013
- Reference count: 31
- Primary result: DeBERTa-v3-large achieves highest mean accuracy (0.860) and F1-score (0.662) on WRIME emotion classification

## Executive Summary
This study evaluates fine-tuned Japanese PLMs for emotion classification using the WRIME corpus, which contains reader-centric emotion annotations. The research compares BERT, RoBERTa, and DeBERTa-v3 variants against LLMs across eight Plutchik emotions. DeBERTa-v3-large achieved the highest performance with 0.860 mean accuracy and 0.662 mean F1-score. The study demonstrates that fine-tuned PLMs significantly outperform LLMs for this task, with ChatGPT-4o and TinySwallow scoring substantially lower at 0.527 and 0.292 mean F1 respectively. A pip-installable package is released for practical deployment.

## Method Summary
The study fine-tuned four Japanese PLMs (BERT, RoBERTa, DeBERTa-v3-base, DeBERTa-v3-large) on the WRIME dataset using binary classification of reader-averaged intensity scores. Each of the eight Plutchik emotions was treated as an independent binary classification task with intensity ≥1 indicating presence. Models were trained with 30 epochs, learning rate 1e-6, batch size 16, and warmup steps 2500. The best checkpoint was selected based on validation F1-score. Performance was evaluated using accuracy and F1-score to address severe class imbalance in the dataset.

## Key Results
- DeBERTa-v3-large achieved the highest mean accuracy (0.860) and F1-score (0.662) among all models tested
- Fine-tuned PLMs significantly outperformed LLMs, with ChatGPT-4o scoring 0.527 F1 and TinySwallow 0.292 F1
- DeBERTa-v3-large maintained robust performance across both high- and low-frequency emotions
- Binary reformulation of multi-class intensity labels helped mitigate class imbalance effects

## Why This Works (Mechanism)

### Mechanism 1
Binary reformulation of multi-class intensity labels mitigates class imbalance and stabilizes training by converting 4-level intensity scores to binary presence/absence labels. This consolidates sparse positive classes, providing more training examples per class and reducing the dominance of the "no emotion" class (69-97% of data depending on emotion). The information loss from collapsing intensity gradations is outweighed by improved model learning on underrepresented emotions.

### Mechanism 2
DeBERTa-v3's disentangled attention mechanism improves emotion detection over standard BERT/RoBERTa attention patterns by separating content and position embeddings in attention computation. This enables more precise modeling of word relationships—particularly relevant for Japanese where emotional cues often depend on particle usage and word order. Japanese emotional expressions benefit from disentangled attention more than English (not directly tested in this paper).

### Mechanism 3
Task-specific fine-tuning currently outperforms general-purpose LLM prompting for emotion classification because fine-tuned PLMs optimize directly for the binary classification objective on domain-specific data, whereas LLMs must infer task structure from prompts without gradient updates—leading to poorer calibration on imbalanced classes. The prompt design was reasonably optimized; poor LLM performance is not primarily a prompt-engineering failure.

## Foundational Learning

- **Class imbalance and F1-score prioritization**: WRIME has 69-97% negative class prevalence; accuracy alone masks poor minority-class detection. Quick check: If a model achieves 97% accuracy on "Anger" detection, what additional metric would reveal whether it's actually detecting anger or just predicting "absent" every time?

- **Multi-label binary classification (8 independent classifiers)**: Each post can express multiple emotions simultaneously; training 8 separate binary classifiers avoids the combinatorial explosion of multi-class multi-label approaches. Quick check: Why not train a single 8-output classifier instead of 8 independent ones? What tradeoff does this introduce?

- **Disentangled attention (DeBERTa architecture)**: Understanding why DeBERTa-v3 outperforms BERT/RoBERTa requires knowing how it differs from standard self-attention. Quick check: In standard BERT attention, how are content and position information combined? How does DeBERTa's approach differ?

## Architecture Onboarding

- **Component map**: WRIME dataset → Binary label transformation → 8 independent fine-tuned DeBERTa-v3-large classifiers → Aggregated emotion predictions

- **Critical path**: 1) Load WRIME corpus and compute mean reader intensity scores per emotion; 2) Binarize labels (intensity ≥ 1 → positive class); 3) Train 8 separate DeBERTa-v3-large models with specified hyperparameters; 4) Select best checkpoint by validation F1-score; 5) Deploy via pip install deberta-emotion-predictor

- **Design tradeoffs**: Binary vs intensity regression (simplifies training but loses granularity); 8 independent models vs unified multi-output (enables parallel training and per-emotion tuning vs reduces inference overhead); DeBERTa-v3-large vs base (+3.2% mean F1 gain at cost of ~2x parameters)

- **Failure signatures**: Anger and Trust F1-scores remain low (0.549 and 0.496 for DeBERTa-v3-large) despite overall improvement—indicates positive-sample scarcity; LLM F1-scores <0.2 on multiple emotions suggest systematic prediction bias toward majority class

- **First 3 experiments**: 1) Baseline replication: Train BERT-base on WRIME binary labels with paper hyperparameters; verify mean F1 ≈ 0.572; 2) Ablation: Compare DeBERTa-v3-base vs DeBERTa-v3-large on low-frequency emotions (Anger, Trust) to quantify scale benefits; 3) Class imbalance intervention: Apply targeted oversampling or augmentation for emotions with <5% positive rate; measure F1 delta on Anger/Trust

## Open Questions the Paper Calls Out

### Open Question 1
Can advanced prompt engineering strategies close the performance gap between general LLMs and fine-tuned PLMs for Japanese emotion classification? The study tested LLMs with a standard prompt, but the substantial gap suggests current prompting methods are insufficient for fine-grained emotion tasks. Demonstration of a prompt strategy that enables an LLM to achieve an F1-score statistically comparable to the fine-tuned DeBERTa-v3-large baseline would resolve this.

### Open Question 2
To what extent can targeted data augmentation or collection improve the classification of rare emotions such as Anger and Trust? The authors note that "The poor F1-scores for Anger and Trust stem from the scarcity of positive samples" and identify "targeted data-collection or augmentation strategies" as indispensable future work. Experiments showing significant F1-score improvements for these specific emotions after balancing the training distribution via augmentation would resolve this.

### Open Question 3
Is it feasible to extend the current binary classification framework to accurate multi-class regression for emotion intensity? The conclusion lists "explore regression approaches to predict emotion intensity" as a specific direction for future work. The current study deliberately simplified the task to binary classification to mitigate the "severe class imbalance" inherent in the 4-level intensity labels. A model that successfully predicts the original 4-level intensity scale with reliable accuracy would resolve this.

### Open Question 4
Can the DeBERTa-v3-large model be compressed or distilled for efficient deployment without significant loss in accuracy? The conclusion explicitly identifies the need to "lighten model size" as a goal for future research. While DeBERTa-v3-large proved the most reliable, large transformer models are computationally expensive, potentially hindering practical application in resource-constrained environments. A distilled or pruned variant of the model that retains a mean F1-score near 0.662 while significantly reducing parameter count and inference latency would resolve this.

## Limitations

- **Unbalanced evaluation scope**: Results focus on mean F1-scores, masking large variance across emotions. Anger and Trust F1-scores (0.549 and 0.496) remain problematic despite overall improvement, suggesting limited positive-sample availability.

- **LLM prompting limitations**: Poor LLM performance (TinySwallow F1 0.292, ChatGPT-4o F1 0.527) may reflect suboptimal prompt engineering rather than inherent architectural disadvantage. The paper acknowledges this but does not explore prompt optimization.

- **Binary simplification trade-off**: Collapsing 4-level intensity scores to binary labels simplifies training but eliminates granular emotional intensity information that might be clinically or contextually relevant.

## Confidence

- **High confidence**: DeBERTa-v3-large outperforms BERT and RoBERTa on Japanese emotion classification (supported by direct experimental comparison with consistent hyperparameters)
- **Medium confidence**: DeBERTa-v3's disentangled attention mechanism drives performance gains (architectural advantage demonstrated, but task-specific attribution not isolated)
- **Medium confidence**: Fine-tuned PLMs currently outperform LLMs for this task (result holds, but LLM performance may improve significantly with better prompting)
- **Low confidence**: DeBERTa-v3-large is optimal for all emotions (per-emotion analysis shows variable performance; no ablation across all eight emotions)

## Next Checks

1. **Ablation on attention mechanisms**: Train BERT and RoBERTa with disentangled attention layers (or vice versa) to isolate architectural contribution from pre-training differences.

2. **Intensity regression baseline**: Train models to predict original 0-3 intensity scores rather than binary labels to assess information loss from binary transformation.

3. **Prompt engineering intervention**: Systematically test few-shot prompting, chain-of-thought reasoning, and emotion-specific templates with ChatGPT-4o to establish lower bounds on LLM performance before concluding architectural inferiority.