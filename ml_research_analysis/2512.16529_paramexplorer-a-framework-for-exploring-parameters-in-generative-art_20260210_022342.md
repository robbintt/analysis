---
ver: rpa2
title: 'ParamExplorer: A framework for exploring parameters in generative art'
arxiv_id: '2512.16529'
source_url: https://arxiv.org/abs/2512.16529
tags:
- agent
- parameter
- exploration
- parameters
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ParamExplorer, a reinforcement-learning-inspired
  framework for exploring high-dimensional parameter spaces in generative art. The
  authors address the challenge of navigating complex, multimodal parameter spaces
  where aesthetically compelling outputs occupy only small, fragmented regions.
---

# ParamExplorer: A framework for exploring parameters in generative art

## Quick Facts
- arXiv ID: 2512.16529
- Source URL: https://arxiv.org/abs/2512.16529
- Authors: Julien Gachadoat; Guillaume Lagarde
- Reference count: 14
- One-line primary result: Reinforcement-learning-inspired framework for exploring high-dimensional parameter spaces in generative art

## Executive Summary
ParamExplorer is a novel framework designed to help artists systematically explore high-dimensional parameter spaces in generative art. The framework addresses the challenge of finding aesthetically compelling outputs in complex, multimodal parameter spaces where interesting results occupy only small, fragmented regions. By integrating reinforcement learning principles with interactive human feedback, ParamExplorer enables both automated and artist-guided exploration of generative systems, making it particularly valuable for navigating the vast combinatorial spaces that characterize modern generative art.

## Method Summary
The ParamExplorer framework employs three distinct exploration strategies: Random (baseline), Gaussian (local exploration with clustering for diversity), and Open-ended (dynamically expanding search regions). The system seamlessly integrates with existing p5.js projects and supports both human-in-the-loop interaction and automated feedback through interactive agents. The framework was tested on two generative systems - Superformula and Suburbia - to evaluate its effectiveness in discovering diverse, visually interesting outputs compared to random sampling approaches.

## Key Results
- Agents using ParamExplorer discovered diverse, visually interesting outputs more efficiently than random sampling methods
- Seeded exploration led to rapid emergence of compelling outputs in both test systems
- Unseeded runs demonstrated the agent's inherent exploratory capacity across parameter spaces

## Why This Works (Mechanism)
The framework's effectiveness stems from its RL-inspired approach to parameter space exploration, where the agent learns to navigate toward regions of high aesthetic value while maintaining diversity through clustering mechanisms. The integration of human feedback creates a reinforcement loop that guides exploration toward artistically meaningful territories, while the open-ended strategy ensures the agent doesn't get trapped in local optima by dynamically expanding search regions as interesting patterns emerge.

## Foundational Learning
- **Reinforcement learning principles** - why needed: To create an adaptive exploration strategy that improves over time based on feedback; quick check: Can the agent improve its selection of parameters across multiple iterations?
- **Parameter space clustering** - why needed: To maintain diversity in discovered outputs and avoid redundant exploration; quick check: Does the system prevent the agent from repeatedly visiting similar parameter configurations?
- **Interactive human feedback loops** - why needed: To align automated exploration with human aesthetic preferences; quick check: Can artists effectively guide the exploration toward personally meaningful outputs?
- **Generative art systems** - why needed: To understand the specific challenges of navigating parameter spaces in creative applications; quick check: Does the framework work across different types of generative systems with varying dimensionalities?

## Architecture Onboarding

**Component map**: User Interface -> Agent Core -> p5.js Integration -> Feedback Loop

**Critical path**: The agent core receives feedback (human or automated), updates its exploration strategy, generates new parameter sets, and passes them to the p5.js integration for rendering. The resulting output is then evaluated and fed back into the agent for the next iteration.

**Design tradeoffs**: The framework prioritizes ease of integration with existing p5.js projects over raw performance, choosing interpretability and artist accessibility over computational efficiency. The three exploration strategies represent different points on the exploration-exploitation spectrum, allowing users to choose between rapid discovery and systematic coverage.

**Failure signatures**: The system may converge too quickly to local optima if feedback is too narrow, or fail to find compelling outputs if the initial exploration is too sparse. The open-ended strategy mitigates this by expanding search regions, but may still miss optimal configurations in very high-dimensional spaces.

**3 first experiments**:
1. Run the framework with random strategy on a simple parametric system to verify basic functionality
2. Test Gaussian strategy with clustering enabled on the Superformula system to evaluate diversity maintenance
3. Implement human-in-the-loop feedback on a small generative system to validate interactive capabilities

## Open Questions the Paper Calls Out
None

## Limitations
- Lack of quantitative evaluation for aesthetic quality of discovered outputs
- No systematic comparison of the three exploration strategies' relative effectiveness
- Framework scalability to very high-dimensional parameter spaces remains unverified
- No formal benchmarks against existing parameter exploration methods in generative art

## Confidence

**High confidence**: The technical implementation details of ParamExplorer, including the three exploration strategies and p5.js integration, appear sound based on the described methodology.

**Medium confidence**: The claim that ParamExplorer enables "efficient" discovery of diverse outputs compared to random sampling, as this relies on visual inspection rather than quantitative metrics.

**Low confidence**: The assertion that the framework significantly advances the state of the art in generative art exploration, as this is not supported by comparative analysis with existing methods.

## Next Checks

1. Conduct user studies with artists to evaluate whether ParamExplorer demonstrably improves their creative workflow compared to manual parameter exploration or random sampling.

2. Implement quantitative metrics for output diversity and aesthetic quality (e.g., image feature statistics, computational aesthetic measures) to objectively compare the three exploration strategies.

3. Test the framework on more complex generative systems with higher-dimensional parameter spaces to assess scalability and identify potential limitations.