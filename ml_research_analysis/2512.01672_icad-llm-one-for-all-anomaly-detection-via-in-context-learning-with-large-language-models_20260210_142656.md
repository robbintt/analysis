---
ver: rpa2
title: 'ICAD-LLM: One-for-All Anomaly Detection via In-Context Learning with Large
  Language Models'
arxiv_id: '2512.01672'
source_url: https://arxiv.org/abs/2512.01672
tags:
- data
- anomaly
- detection
- time
- icad-llm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ICAD-LLM addresses the challenge of unified anomaly detection across
  heterogeneous data modalities (time series, logs, tabular) by introducing In-Context
  Anomaly Detection (ICAD), which defines anomalies through contextual comparison
  rather than static distribution learning. The method employs a modality-aware encoder
  to project diverse inputs into a unified embedding space, uses a prompt-guided representation
  module with a pre-trained LLM to extract semantically rich representations sensitive
  to subtle discrepancies, and trains with contextual contrastive learning to discriminate
  between normal and anomalous patterns.
---

# ICAD-LLM: One-for-All Anomaly Detection via In-Context Learning with Large Language Models

## Quick Facts
- arXiv ID: 2512.01672
- Source URL: https://arxiv.org/abs/2512.01672
- Reference count: 30
- One-line primary result: First unified anomaly detection framework handling time series, logs, and tabular data within a single in-context learning model, achieving competitive performance with task-specific methods.

## Executive Summary
ICAD-LLM introduces In-Context Anomaly Detection (ICAD), a unified framework that defines anomalies through contextual comparison rather than static distribution learning. The method employs a modality-aware encoder to project diverse inputs into a unified embedding space, uses a prompt-guided representation module with a pre-trained LLM to extract semantically rich representations, and trains with contextual contrastive learning to discriminate between normal and anomalous patterns. Extensive experiments demonstrate ICAD-LLM achieves competitive performance with task-specific methods and strong generalization to unseen tasks across time series, logs, and tabular modalities.

## Method Summary
ICAD-LLM processes heterogeneous data through modality-specific encoders (CNN for time series, Transformer for logs, MLP for tabular) into unified embeddings, then feeds these with a reference set into a pre-trained LLM with special tokens ([REF TOK], [TGT TOK]) to extract contextualized representations. The model learns a discrepancy function through contextual contrastive learning using simple negatives (cross-dataset normals) and hard negatives (intra-dataset anomalies), enabling it to identify anomalies by comparing target samples against reference sets rather than memorizing fixed normality distributions.

## Key Results
- Achieves 88.47 F1 on SMD time series dataset and 94.69 AUROC on Cardio tabular dataset
- Demonstrates strong cross-modal generalization, performing well on unseen datasets across all three modalities
- First model capable of handling AD tasks across diverse domains and modalities within a single framework

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Shifting from static distribution memorization to dynamic contextual comparison enables cross-modal generalization without task-specific retraining.
- **Mechanism:** By explicitly providing a reference set of normal samples at inference time and training the model to compare targets against this context, ICAD decouples anomaly detection from learning fixed "normality" distributions. The model learns a general discrepancy function δ(R, x_tgt) rather than task-specific decision boundaries.
- **Core assumption:** Anomalies can be consistently identified through relative dissimilarity to normal reference samples across fundamentally different data modalities.
- **Evidence anchors:**
  - [abstract]: "anomalies are defined by their dissimilarity to a relevant reference set of normal samples"
  - [section]: "By shifting the objective from memorization to in-context comparison, this approach is inherently more flexible and readily applicable across diverse data modalities"
  - [corpus]: RAAD (arXiv:2502.19534) employs similar retrieval-based adjustment for anomaly detection (0.61 FMR), supporting the retrieval-context principle
- **Break condition:** If reference sets fail to capture the full diversity of normal behavior for a task, the discrepancy function will produce false positives on legitimate but out-of-distribution normal samples.

### Mechanism 2
- **Claim:** Special learnable tokens ([REF TOK], [TGT TOK]) compel the LLM to produce fixed-dimensional, semantically rich representations that aggregate variable-length inputs while preserving sensitivity to contextual differences.
- **Mechanism:** These tokens act as attention sinks—the LLM's self-attention mechanism pools information from the entire reference set or target sample into a single token position. The instruction prompt primes the LLM toward comparison reasoning rather than general language understanding.
- **Core assumption:** The pre-trained LLM's attention mechanism can meaningfully compress variable-length, multi-modal embeddings into unified representations that preserve task-relevant semantic differences.
- **Evidence anchors:**
  - [abstract]: "uses a prompt-guided representation module with a pre-trained LLM to extract semantically rich representations sensitive to subtle discrepancies"
  - [section]: "These tokens are inserted into the input sequence, compelling the LLM to aggregate and summarize the information of the reference set and the target sample into their respective token positions"
  - [corpus]: No direct corpus evidence for token-anchored representation pooling in AD; this appears novel to ICAD-LLM
- **Break condition:** If the LLM backbone lacks sufficient capacity (0.5B may be borderline), token representations may fail to capture subtle discrepancies needed for fine-grained anomaly detection.

### Mechanism 3
- **Claim:** Training with a mixture of simple negatives (cross-dataset, same modality) and hard negatives (intra-dataset anomalies) creates a curriculum that builds both coarse-grained discriminative ability and fine-grained anomaly sensitivity.
- **Mechanism:** Simple negatives teach the model that samples from different distributions can be normal—the model learns what "different but still normal" looks like. Hard negatives then refine this to identify truly anomalous deviations. The margin α enforces a minimum separation between positive and negative pairs.
- **Core assumption:** The 8:2 simple-to-hard ratio generalizes to unseen tasks; the model learns a transferable "comparison skill" rather than dataset-specific patterns.
- **Evidence anchors:**
  - [abstract]: "trains with contextual contrastive learning to discriminate between normal and anomalous patterns"
  - [section]: "Simple Negative Sample: A normal sample drawn from a different dataset D' of the same modality M... Hard Negative Sample: An anomalous sample from the source dataset D, teaching the model to identify subtle, fine-grained deviations"
  - [corpus]: NeuTraL AD and UniAD (mentioned as baselines) use unified approaches but lack the simple/hard negative curriculum, potentially explaining their weaker cross-modal performance
- **Break condition:** If the training task distribution doesn't cover the diversity of inference scenarios, the learned discrepancy function will not transfer.

## Foundational Learning

- **Concept: Contrastive Learning with Margin**
  - Why needed here: The CCL loss L = max(s(h_R, h_x+) - s(h_R, h_x-) + α, 0) is the core training objective. Understanding why margins prevent trivial solutions is essential.
  - Quick check question: What happens to the learned representations if α = 0 and all samples (positive and negative) are easily separable?

- **Concept: In-Context Learning in LLMs**
  - Why needed here: ICAD-LLM exploits the LLM's ability to reason over provided context (reference sets) rather than relying on parametric knowledge acquired during pretraining.
  - Quick check question: How does providing a reference set in the prompt differ from fine-tuning the model on that same data?

- **Concept: Multi-Modal Feature Alignment**
  - Why needed here: The modality-aware encoder must project time series (via CNN), logs (via Transformer), and tabular data (via MLP) into the same embedding dimension (d_model) for unified LLM processing.
  - Quick check question: What failure modes occur if one modality's encoder produces embeddings with significantly different magnitude or variance than others?

## Architecture Onboarding

- **Component map:**
  Raw input → Sample preparation → Modality-specific encoder → Concatenate with prompt + special tokens → LLM forward → Extract token representations → Compute cosine similarity → Threshold comparison

- **Critical path:**
  Raw input → Sample preparation → Modality-specific encoder → Concatenate with prompt + special tokens → LLM forward → Extract token representations → Compute cosine similarity → Threshold comparison

- **Design tradeoffs:**
  - **K=5 reference samples:** Paper shows K>5 yields diminishing returns (Figure 5a); smaller K risks incomplete normal representation
  - **200k training samples:** Marginal gains beyond this (Figure 5b); balances performance vs. compute
  - **0.5B LLM:** Smaller models may lack reasoning capacity; larger models increase inference latency and memory
  - **8:2 simple:hard negative ratio:** Assumption: this curriculum balances coarse vs. fine discrimination

- **Failure signatures:**
  - **High false positive rate:** Reference set may not capture normal variability; increase K or improve reference selection
  - **Low anomaly detection recall:** Model may have learned overly permissive boundaries; increase hard negative ratio or margin α
  - **Modality-specific degradation:** Encoder outputs may have mismatched scales; add normalization or verify embedding statistics
  - **Poor unseen task performance:** Training task distribution may be too narrow; diversify training data sources

- **First 3 experiments:**
  1. **Encoder alignment validation:** Visualize modality-specific encoder outputs (before LLM) using t-SNE/UMAP on a held-out dataset per modality. Confirm embeddings from different modalities occupy comparable regions and scales.
  2. **Reference set size ablation:** On one time series and one tabular dataset, sweep K ∈ {1, 2, 3, 5, 7, 10} and plot F1/AUROC. Verify K=5 is near the elbow before diminishing returns.
  3. **Cross-modal zero-shot test:** Train on time series + tabular only; test on log datasets (BGL, Thunderbird) without any log training data. Compare against full training to quantify cross-modal transfer gap.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can reference set selection be optimized beyond random sampling to maximize representative coverage of normal behavior?
- **Basis in paper:** [inferred] The paper uses random selection for constructing reference sets (K=5 samples) and notes that "smaller reference set sizes may not adequately capture the common characteristics of normal instances, while larger sizes yield diminishing marginal returns," but does not explore intelligent or clustering-based selection strategies.
- **Why unresolved:** Random selection may produce suboptimal reference sets that fail to capture the full diversity of normal patterns, especially in complex or multi-modal normal distributions.
- **What evidence would resolve it:** Systematic comparison of reference set selection methods (e.g., clustering centroids, diversity-maximizing selection, core-set approaches) against random baseline across all modalities.

### Open Question 2
- **Question:** How does ICAD-LLM's performance scale with LLM backbone size, and what is the minimum viable model capacity for effective in-context anomaly detection?
- **Basis in paper:** [inferred] The implementation uses Qwen2.5-0.5B but provides no ablation on backbone size or analysis of the efficiency-performance trade-off, which is critical for practical deployment.
- **Why unresolved:** Smaller models may suffice for the discrimination task, while larger models may offer better generalization at higher computational cost—the optimal point is unknown.
- **What evidence would resolve it:** Controlled experiments varying backbone sizes (e.g., 0.5B, 1.5B, 3B, 7B) with identical training procedures, reporting both performance metrics and inference latency.

### Open Question 3
- **Question:** Can the task-specific discrepancy threshold θ′τ be automatically calibrated for completely unseen tasks without labeled validation data?
- **Basis in paper:** [inferred] The paper defines ICAD's detection process using threshold θ′τ but does not specify how this threshold is determined for new tasks during the generalization experiments on unseen datasets.
- **Why unresolved:** Practical deployment requires automated threshold selection; manual tuning defeats the purpose of a "train-once, apply-broadly" framework.
- **What evidence would resolve it:** Evaluation of unsupervised threshold calibration methods (e.g., percentile-based, statistical outlier tests on discrepancy scores) on held-out datasets.

### Open Question 4
- **Question:** Does cross-modal transfer occur during joint training, where knowledge from one modality improves performance on another?
- **Basis in paper:** [inferred] The universal setting trains on all three modalities jointly, but the paper does not ablate whether cross-modal training provides benefits over modality-isolated training.
- **Why unresolved:** Understanding transfer is essential for determining whether joint training is merely convenient or fundamentally enables better anomaly discrimination.
- **What evidence would resolve it:** Comparison of models trained on single modalities versus jointly trained models, analyzed for performance gains attributable to cross-modal knowledge sharing.

## Limitations
- The 0.5B parameter LLM may struggle with extremely subtle anomalies or very long sequences, potentially limiting detection sensitivity in some domains.
- Cross-modal generalization relies heavily on fixed hyperparameters (K=5 reference samples, 8:2 simple-to-hard negative ratio) that may not be optimal for all unseen tasks.
- Scalability to much larger datasets or real-time streaming applications hasn't been demonstrated, and computational efficiency relative to task-specific methods remains unclear.

## Confidence
- **High confidence:** The core mechanism of using in-context learning with reference sets for anomaly detection is well-supported by experimental results across multiple modalities. The ablation studies for reference set size (K) and training sample count provide strong empirical backing.
- **Medium confidence:** The cross-modal transfer claims are supported by experiments, but the extent of generalization to completely unseen anomaly types or data distributions remains uncertain. The simple-to-hard negative ratio (8:2) appears effective but may not be optimal for all scenarios.
- **Low confidence:** The scalability of the approach to much larger datasets or real-time streaming applications hasn't been demonstrated. The computational efficiency relative to task-specific methods for individual modalities is also unclear.

## Next Checks
1. **Extreme anomaly sensitivity test:** Evaluate ICAD-LLM on datasets with increasingly subtle anomalies (e.g., HeartDisease, Thyroid from ADBench) and compare detection rates against the most sensitive task-specific methods to quantify the 0.5B LLM's detection limits.
2. **Dynamic reference set evaluation:** Instead of fixed K=5, implement an adaptive reference selection mechanism that adjusts K based on dataset complexity or normal behavior diversity, then measure impact on cross-modal generalization performance.
3. **Computational overhead benchmarking:** Measure inference latency and memory usage across all modalities and compare against state-of-the-art task-specific anomaly detection methods to quantify the unified framework's practical deployment costs.