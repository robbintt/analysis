---
ver: rpa2
title: 'KERAP: A Knowledge-Enhanced Reasoning Approach for Accurate Zero-shot Diagnosis
  Prediction Using Multi-agent LLMs'
arxiv_id: '2507.02773'
source_url: https://arxiv.org/abs/2507.02773
tags:
- prediction
- knowledge
- diagnosis
- reasoning
- medical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces KERAP, a knowledge-enhanced reasoning approach\
  \ for zero-shot diagnosis prediction using multi-agent LLMs. KERAP employs a three-agent\
  \ framework\u2014linkage, retrieval, and prediction\u2014to integrate biomedical\
  \ knowledge graphs with patient EHR data, enabling structured medical reasoning."
---

# KERAP: A Knowledge-Enhanced Reasoning Approach for Accurate Zero-shot Diagnosis Prediction Using Multi-agent LLMs

## Quick Facts
- arXiv ID: 2507.02773
- Source URL: https://arxiv.org/abs/2507.02773
- Reference count: 31
- Primary result: Three-agent LLM framework achieves up to 76.16% accuracy on CKD diagnosis prediction

## Executive Summary
This paper introduces KERAP, a knowledge-enhanced reasoning approach for zero-shot diagnosis prediction using multi-agent LLMs. KERAP employs a three-agent framework—linkage, retrieval, and prediction—to integrate biomedical knowledge graphs with patient EHR data, enabling structured medical reasoning. Experiments on four EHR datasets show KERAP achieves superior accuracy and F1-scores compared to baseline methods like direct prompting and KG-augmented prompting, reaching up to 76.16% accuracy on CKD. While more computationally intensive, KERAP offers scalable, interpretable solutions for clinical AI, particularly valuable where labeled data is scarce. Case studies demonstrate its ability to reduce hallucinations and improve prediction reliability.

## Method Summary
KERAP introduces a three-agent framework for zero-shot diagnosis prediction that combines biomedical knowledge graphs with electronic health record data. The linkage agent maps EHR concepts to knowledge graph entities, the retrieval agent extracts relevant medical knowledge, and the prediction agent synthesizes information to generate diagnostic predictions. The approach leverages multi-agent LLMs to create structured reasoning paths and evidence trees that enhance interpretability. KERAP operates in zero-shot settings, requiring no labeled training data, making it particularly valuable for rare disease diagnosis and situations where medical expertise is limited.

## Key Results
- Achieves up to 76.16% accuracy on CKD dataset, outperforming baseline methods
- Demonstrates superior F1-scores across all four tested EHR datasets
- Reduces hallucinations through structured evidence tree generation
- Provides interpretable reasoning paths for clinical validation

## Why This Works (Mechanism)
KERAP's effectiveness stems from its structured multi-agent approach that bridges raw EHR data with curated biomedical knowledge. By decomposing the diagnostic reasoning task into specialized agents, the system can leverage domain-specific knowledge while maintaining logical consistency. The linkage agent ensures accurate concept mapping between clinical terminology and knowledge graph entities, while the retrieval agent surfaces relevant medical literature and clinical guidelines. The prediction agent then synthesizes this information through chain-of-thought reasoning, producing both predictions and supporting evidence. This architecture reduces the likelihood of spurious correlations and hallucinations common in direct LLM prompting approaches.

## Foundational Learning

**Biomedical Knowledge Graphs**: Structured representations of medical concepts and their relationships, essential for providing domain context to LLMs
- Why needed: Enables LLMs to access verified medical knowledge beyond their training data
- Quick check: Verify graph coverage includes target diseases and relevant clinical concepts

**Multi-agent LLM Frameworks**: Decomposing complex tasks into specialized agents that collaborate
- Why needed: Allows task-specific optimization and reduces cognitive load on individual agents
- Quick check: Confirm agent communication protocols and knowledge sharing mechanisms

**Zero-shot Learning**: Making predictions without task-specific training data
- Why needed: Critical for rare diseases and novel clinical scenarios where labeled data is unavailable
- Quick check: Validate performance across diverse clinical conditions and data distributions

**Evidence Trees**: Hierarchical representations of reasoning paths supporting predictions
- Why needed: Provides transparency and enables clinical validation of AI-generated diagnoses
- Quick check: Assess tree completeness and logical consistency of inference paths

## Architecture Onboarding

**Component Map**: EHR Data -> Linkage Agent -> Knowledge Graph -> Retrieval Agent -> Medical Literature -> Prediction Agent -> Diagnostic Output + Evidence Tree

**Critical Path**: Patient data enters linkage agent for concept mapping, flows to retrieval agent for knowledge extraction, then to prediction agent for diagnosis generation with evidence tree construction

**Design Tradeoffs**: KERAP prioritizes accuracy and interpretability over computational efficiency, accepting higher resource requirements for improved clinical reliability and transparency

**Failure Signatures**: 
- Poor concept mapping in linkage agent leads to irrelevant knowledge retrieval
- Incomplete knowledge graph coverage results in missing critical diagnostic information
- Prediction agent hallucinations when faced with conflicting evidence sources

**First 3 Experiments to Run**:
1. Validate concept mapping accuracy between EHR terminology and knowledge graph entities
2. Test retrieval agent's ability to surface relevant medical literature for diverse clinical scenarios
3. Evaluate evidence tree generation quality and clinical interpretability through physician review

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Limited dataset diversity and small sample sizes (maximum 10,000 samples) may affect generalizability
- Focus on single-disease prediction tasks doesn't reflect real-world multi-disease clinical complexity
- Computational resource requirements and runtime specifications not clearly quantified
- Clinical interpretability claims lack systematic validation through physician usability studies

## Confidence

**Performance claims**: Medium - Superior accuracy demonstrated but on limited datasets
**Methodology validity**: Medium - Innovative approach but lacks comprehensive scalability analysis
**Scalability assessment**: Low - Computational requirements not quantified for real-world deployment
**Clinical interpretability**: Low - Evidence tree benefits not systematically validated with clinicians

## Next Checks

1. Conduct external validation on larger, more diverse EHR datasets including multi-disease prediction tasks and evaluate performance across different clinical specialties

2. Perform comprehensive computational resource analysis comparing KERAP's runtime and infrastructure requirements against baseline methods in cloud and on-premise environments

3. Design clinician usability studies to evaluate how effectively medical professionals can interpret, validate, and act upon KERAP's evidence trees in clinical decision-making scenarios