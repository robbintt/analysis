---
ver: rpa2
title: Human-AI Collaboration Increases Efficiency in Regulatory Writing
arxiv_id: '2509.09738'
source_url: https://arxiv.org/abs/2509.09738
tags:
- regulatory
- quality
- time
- autoind
- writing
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: An AI-assisted regulatory writing platform (AutoIND) reduced first-draft
  preparation time by ~97% (from ~100 h to 2.6-3.7 h) for large IND documents (11,425-18,870
  pages), maintaining quality scores of 69.6-77.9%. No critical regulatory errors
  were detected, but drafts required expert refinement to address systematic deficiencies
  in emphasis, conciseness, and clarity.
---

# Human-AI Collaboration Increases Efficiency in Regulatory Writing

## Quick Facts
- arXiv ID: 2509.09738
- Source URL: https://arxiv.org/abs/2509.09.09738
- Reference count: 2
- Primary result: AI-assisted platform reduced first-draft preparation time by ~97% for large IND documents while maintaining quality scores of 69.6-77.9

## Executive Summary
This study evaluates an AI-assisted regulatory writing platform (AutoIND) that dramatically reduces first-draft preparation time for large IND documents. The platform achieved a 97% reduction in drafting time (from ~100 hours to 2.6-3.7 hours) while maintaining quality scores between 69.6-77.9. The AI-generated drafts required expert refinement to address systematic deficiencies in emphasis, conciseness, and clarity, but no critical regulatory errors were detected. The results demonstrate that human-AI collaboration can significantly accelerate regulatory document preparation while maintaining acceptable quality standards.

## Method Summary
The study compared manual drafting versus AI-assisted drafting of IND documents using the AutoIND platform. The platform ingested study documents, protocols, and previous submissions to generate first drafts of Module 2 (clinical overview and investigational plan) and Module 3 (protocol, safety reporting, and statistical analysis) sections. Three INDs were created: one using manual drafting, one using AI-assisted drafting, and one using a hybrid approach. Quality assessment was performed by the sponsor's clinical and regulatory teams using internally developed scoring rubrics that evaluated regulatory compliance, clarity, completeness, and presentation. Timing data was collected for first-draft preparation, and both drafts underwent internal review by medical and regulatory experts.

## Key Results
- First-draft preparation time reduced by ~97% (from ~100 hours to 2.6-3.7 hours)
- Quality scores maintained at 69.6-77.9 for AI-assisted drafts versus manual drafts
- No critical regulatory errors detected in AI-generated content
- Expert refinement required to address systematic deficiencies in emphasis, conciseness, and clarity

## Why This Works (Mechanism)
The AI-assisted platform works by leveraging large language models to process and synthesize regulatory documentation requirements, study protocols, and previous submission content into structured regulatory document formats. The system uses prompt engineering to generate content that addresses specific regulatory sections while maintaining consistency with established templates and guidelines. The human-in-the-loop approach ensures that expert reviewers can refine AI-generated content to address nuanced regulatory requirements and improve clarity, resulting in a collaborative workflow that combines AI efficiency with human expertise.

## Foundational Learning
- Regulatory document structure: Why needed - to ensure AI generates content that meets regulatory formatting requirements; Quick check - verify generated sections follow ICH guidelines
- Clinical trial protocol interpretation: Why needed - to accurately translate study design into regulatory language; Quick check - compare AI-generated content against source protocols
- Medical terminology standardization: Why needed - to maintain consistency across large documents; Quick check - audit terminology usage across different sections
- Quality scoring rubrics: Why needed - to objectively evaluate AI-generated content against regulatory standards; Quick check - validate rubric criteria against regulatory agency expectations
- Expert refinement workflows: Why needed - to address AI limitations in nuanced regulatory requirements; Quick check - measure time spent on refinement versus manual drafting
- AI content validation: Why needed - to ensure generated content meets regulatory accuracy standards; Quick check - conduct blind review of AI vs manual sections

## Architecture Onboarding
Component map: Document ingestion -> NLP processing -> Prompt generation -> Content synthesis -> Quality scoring -> Expert refinement -> Final submission
Critical path: Document ingestion through expert refinement represents the end-to-end workflow
Design tradeoffs: Prioritized speed and automation over perfect initial accuracy, relying on human refinement
Failure signatures: Repetitive phrasing, inconsistent emphasis, generic language lacking regulatory specificity
First experiments: 1) Test single-section generation on small document; 2) Compare quality scores across different prompt templates; 3) Measure refinement time for various document types

## Open Questions the Paper Calls Out
None

## Limitations
- Quality evaluation performed internally rather than by independent regulatory reviewers
- Small sample size (n=1-2 per IND) limits generalizability of results
- No formal statistical analysis of quality differences across treatment groups
- Does not address long-term implications for regulatory submissions and amendments

## Confidence
- ~97% reduction in drafting time: High confidence
- Quality scores maintained: Medium confidence
- No critical regulatory errors detected: High confidence
- Expert refinement needed: High confidence

## Next Checks
1. Independent validation by regulatory authorities to assess actual regulatory acceptability
2. Systematic comparison of downstream review and approval timelines between approaches
3. Implementation of formal statistical analysis with larger sample sizes across therapeutic areas