---
ver: rpa2
title: Model Specific Task Similarity for Vision Language Model Selection via Layer
  Conductance
arxiv_id: '2602.01346'
source_url: https://arxiv.org/abs/2602.01346
tags:
- task
- conductance
- similarity
- layer
- selection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of selecting the best vision-language
  model (VLM) for a specific downstream task using only a few unlabeled images, without
  needing expensive full evaluations. The authors propose using layer-wise conductance
  from the visual encoder to represent each task as a model-specific functional profile.
---

# Model Specific Task Similarity for Vision Language Model Selection via Layer Conductance

## Quick Facts
- arXiv ID: 2602.01346
- Source URL: https://arxiv.org/abs/2602.01346
- Reference count: 40
- This paper achieves a 14.7% improvement in NDCG@5 over prior state-of-the-art (SWAB) for vision-language model selection

## Executive Summary
This paper introduces a method for selecting the optimal vision-language model (VLM) from a zoo of 48 models for a specific downstream task, using only a few unlabeled images without full evaluation. The approach represents each task as a model-specific functional profile using layer-wise conductance from the visual encoder, then derives a target-conditioned block-importance distribution. The key innovation is Directional Conductance Divergence (DCD), an asymmetric metric that captures how well a source task covers the target's critical model blocks. Evaluated across 21 datasets, the method achieves state-of-the-art performance with NDCG@5 of 0.707 and Kendall's τ of 0.365.

## Method Summary
The method computes layer-wise conductance using the ℓ₂ norm of image embeddings as a label-free scalar objective, creating task representations by aggregating over unlabeled samples. These representations are normalized and used to compute a block-importance distribution for each task-model pair. DCD measures asymmetric divergence between source and target task representations, capturing coverage semantics. Source models are ranked by aggregating their ranks weighted by DCD-based similarities, avoiding expensive full evaluations. The approach uses hyperparameters η=2.0, γ=5.0, and ε=10⁻⁸.

## Key Results
- Achieves 14.7% improvement in NDCG@5 over prior state-of-the-art (SWAB)
- Top-5 NDCG of 0.707 and Kendall's τ of 0.365 across 21 datasets
- Tested on 48 diverse VLMs including CLIP variants, ViT, EVA, CoCa, and ConvNeXt
- Demonstrates effectiveness using only 25 unlabeled samples per task

## Why This Works (Mechanism)
The method works by creating a model-specific functional profile for each task through layer-wise conductance analysis. Unlike traditional similarity metrics, DCD's asymmetric nature captures coverage semantics - how well source tasks represent the critical blocks needed for the target task. This is particularly effective because different tasks activate different model components differently. The approach avoids direct inference by using the ℓ₂ norm of embeddings as a proxy for downstream performance, which correlates better than text embeddings while remaining architecture-agnostic.

## Foundational Learning
- **Layer Conductance**: Measures the importance of each layer by computing the attribution of the input to the output through the gradient. Why needed: Captures which model blocks are critical for task-specific representations. Quick check: Verify attributions sum to approximately the output magnitude.
- **Directional Conductance Divergence (DCD)**: Asymmetric divergence measuring coverage from source to target task. Why needed: Captures the directional nature of task similarity where source must cover target requirements. Quick check: Confirm DCD(A→B) ≠ DCD(B→A) for non-symmetric cases.
- **Block-importance Distribution**: Softmax-normalized layer conductance aggregated over task samples. Why needed: Creates a normalized representation of which blocks matter for each task. Quick check: Verify distribution sums to 1 across blocks.
- **Leave-one-out Protocol**: Cross-validation where each dataset serves as target while others are sources. Why needed: Provides robust evaluation across all possible target-source combinations. Quick check: Ensure each dataset appears exactly once as target.
- **Zero-shot Accuracy**: Ground truth rankings based on LOVM template-based evaluation. Why needed: Provides objective measure without fine-tuning for validation. Quick check: Verify accuracy computation matches LOVM template specifications.
- **Softmin Similarity**: Converts divergence to similarity via temperature-scaled softmin. Why needed: Transforms asymmetric divergence into usable similarity scores for ranking. Quick check: Confirm similarity decreases as divergence increases.

## Architecture Onboarding

**Component Map**
Visual Encoder -> Layer Conductance -> Task Representation -> Block-importance Distribution -> DCD Computation -> Similarity Matrix -> Rank Aggregation

**Critical Path**
The core pipeline flows from raw images through the visual encoder to layer conductance computation, then aggregates these attributions into task representations. The DCD computation between source and target representations forms the similarity matrix, which drives the final rank aggregation. The critical dependency is accurate layer conductance computation, as errors propagate through all downstream metrics.

**Design Tradeoffs**
The choice of ℓ₂ norm as scalar objective provides architecture-agnostic simplicity but may miss task-specific nuances captured by alternative objectives. The asymmetric DCD captures coverage semantics but requires careful normalization to avoid numerical instability. Using only visual encoder conductance ignores cross-modal interactions, trading computational efficiency for potential loss of alignment information.

**Failure Signatures**
Division-by-small-values errors in DCD when target block activations approach zero, inconsistent block counts across architectures causing shape mismatches, and poor correlation between zero-shot accuracy and fine-tuned performance. Numerical instability manifests as NaN values in similarity scores or extreme rankings dominated by single models.

**First 3 Experiments**
1. Verify layer conductance computation on a single model-dataset pair, checking that attributions sum to output magnitude and are stable across random seeds
2. Test DCD computation between two known task pairs (one should have higher similarity than another) to validate asymmetric behavior
3. Run complete pipeline on a reduced subset (3 models, 3 datasets) to verify rank aggregation produces sensible orderings before full-scale evaluation

## Open Questions the Paper Calls Out
- **Architecture Alignment**: How to adapt the framework to align functional blocks across heterogeneous backbones (CNNs vs. Transformers) to improve generalizability. This remains unresolved as the current method computes conductance individually without unified mapping between fundamentally different architectures.
- **Cross-modal Attribution**: Can incorporating attribution signals from vision-language interaction layers improve selection for alignment-sensitive tasks? The methodology currently isolates the visual encoder, potentially missing critical cross-modal alignment mechanisms.
- **Objective Function Choice**: Is the ℓ₂ norm of image embeddings the optimal unsupervised scalar objective, or does it bias selection toward high-magnitude representations? The paper acknowledges this choice without comparing against alternatives like entropy or variance.

## Limitations
- Theoretical justification for asymmetric divergence assumes perfect coverage semantics that may not hold in practice with fundamentally different feature spaces
- Reliance on zero-shot accuracy as ground truth introduces potential bias as it may not correlate perfectly with fine-tuned downstream performance
- Conductance-based representation depends heavily on block decomposition choices that vary across architectures, affecting comparability

## Confidence
- High confidence in experimental methodology and evaluation protocol
- Medium confidence in theoretical analysis of asymmetric divergence necessity
- Medium confidence in generalizability across diverse VLM architectures
- Low confidence in method's robustness to noisy or adversarial unlabeled samples

## Next Checks
1. Verify DCD's robustness to different block decompositions by testing with alternative architectural groupings and measuring sensitivity
2. Conduct ablation studies removing the asymmetric component to quantify its contribution versus symmetric alternatives
3. Test the method's performance when source task representations are corrupted with varying levels of noise to assess robustness