---
ver: rpa2
title: 'Align Where the Words Look: Cross-Attention-Guided Patch Alignment with Contrastive
  and Transport Regularization for Bengali Captioning'
arxiv_id: '2509.18369'
source_url: https://arxiv.org/abs/2509.18369
tags:
- synthetic
- bengali
- real
- decoder
- infonce
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We address Bengali image captioning under scarce paired data by
  proposing a compute-aware pipeline that combines PAL, InfoNCE, and OT. PAL uses
  decoder cross-attention to weight and align real vs.
---

# Align Where the Words Look: Cross-Attention-Guided Patch Alignment with Contrastive and Transport Regularization for Bengali Captioning

## Quick Facts
- arXiv ID: 2509.18369
- Source URL: https://arxiv.org/abs/2509.18369
- Reference count: 40
- Primary result: BLEU-4 of 12.29 and METEOR of 27.98 on Flickr30k-1k with PAL+InfoNCE+OT pipeline

## Executive Summary
This work tackles Bengali image captioning under scarce paired data by introducing a compute-aware pipeline combining patch alignment, contrastive, and transport regularization. The model leverages synthetic image-caption pairs alongside real data, using decoder cross-attention to guide patch alignment. The approach shows improved grounding and cross-domain generalization, achieving strong performance on Flickr30k and MSCOCO benchmarks.

## Method Summary
The method integrates Patch Alignment via Cross-Attention (PAL) with InfoNCE contrastive loss and optimal transport (OT) regularization. PAL uses decoder cross-attention to weight and align real vs. synthetic patch descriptors, while InfoNCE enforces global discrimination between pooled features. OT regularizes fine-grained patch correspondence. The model is trained on 80k real and synthetic images with LaBSE-verified captions.

## Key Results
- BLEU-4 of 12.29 and METEOR of 27.98 on Flickr30k-1k
- BLEU-4 of 12.00 and METEOR of 28.14 on MSCOCO-1k
- Outperforms CE baselines and narrows real-synthetic centroid gap by 41%

## Why This Works (Mechanism)
The approach combines targeted patch alignment with contrastive and transport regularization to improve visual grounding. By using decoder cross-attention to guide alignment, the model focuses on relevant image regions while reducing compute compared to full contrastive training. The InfoNCE loss enforces global discrimination, and OT regularization ensures fine-grained patch correspondence, leading to better cross-domain generalization.

## Foundational Learning
- **Cross-attention**: Why needed: Guides patch alignment by weighting relevant regions. Quick check: Verify attention maps focus on objects mentioned in captions.
- **Contrastive learning**: Why needed: Enforces global discrimination between pooled features. Quick check: Confirm InfoNCE loss improves feature separability.
- **Optimal transport**: Why needed: Regularizes fine-grained patch correspondence. Quick check: Validate OT reduces patch-level misalignment.
- **LaBSE verification**: Why needed: Ensures caption quality for training. Quick check: Assess LaBSE filtering effectiveness on Bengali captions.

## Architecture Onboarding
- **Component map**: Image patches → PAL weighting → Contrastive loss → OT regularization → Caption generation
- **Critical path**: Cross-attention → Patch alignment → Feature pooling → Caption decoding
- **Design tradeoffs**: PAL reduces compute vs full contrastive but may miss complex spatial relations. InfoNCE improves global discrimination but may blur fine-grained alignment without OT.
- **Failure signatures**: Diffuse attention maps lead to poor alignment. Synthetic bias affects grounding in cultural contexts. OT instability with high-dimensional patches.
- **First experiments**:
  1. Ablate PAL vs full contrastive to isolate alignment benefit from compute reduction.
  2. Evaluate caption semantic similarity between synthetic and real captions (e.g., BERTScore).
  3. Conduct human evaluation of grounding by assessing cross-attention-weighted patch relevance.

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can incorporating explicit region cues (e.g., SAM masks or object boxes) improve the robustness of patch alignment when decoder cross-attention is diffuse?
- Basis in paper: The Conclusion suggests extending alignment "beyond cross-attention maps by incorporating region cues," and the Limitations section notes that PAL "relies on decoder cross-attention" which may fail when attention is diffuse (e.g., in "counting/relations").
- Why unresolved: The current pipeline relies solely on the model's internal cross-attention mechanism to identify relevant patches, which may be insufficient for complex spatial reasoning tasks where attention maps lack sharpness.
- What evidence would resolve it: An ablation study comparing the current PAL mechanism against a version augmented with external segmentation masks on a benchmark rich in counting and relational reasoning tasks.

### Open Question 2
- Question: How effectively does the PAL+InfoNCE+OT pipeline transfer to morphologically rich or low-resource languages outside the Indo-Aryan family?
- Basis in paper: The Conclusion claims the design enables "easy transfer to other low-resource languages," but the methodology is tailored to Bengali (Indo-Aryan) using specific mBART-50 tokenization.
- Why unresolved: The efficacy of the tri-loss objective and the "Bengali-native" decoder bridge may depend heavily on the subword tokenization quality and syntactic structure of the specific target language, which may vary significantly from Bengali.
- What evidence would resolve it: Replicating the training pipeline for a diverse low-resource language (e.g., a Dravidian or agglutinative language) and comparing the resulting BLEU/METEOR scores and centroid gap reduction against the Bengali baseline.

### Open Question 3
- Question: Does adding lightweight LLM critics for reranking or caption-to-QA consistency significantly improve the semantic reasoning capabilities of the model?
- Basis in paper: The Conclusion proposes that "Semantic reasoning could be enhanced by adding lightweight LLM critics for reranking or enforcing caption→QA→caption consistency."
- Why unresolved: The current optimization focuses on patch alignment and contrastive losses, which improve grounding but do not explicitly optimize for high-level logical consistency or factual accuracy in the generated text.
- What evidence would resolve it: A comparative evaluation measuring factual consistency scores (e.g., using a dedicated QA model or human eval) on captions generated with and without an LLM critic in the loop.

### Open Question 4
- Question: To what extent do the stylistic and cultural biases of the synthetic image generator (Kandinsky 2.1) propagate into the visual grounding of the final captioning model?
- Basis in paper: The Limitations section notes that "generated images can carry style/cultural biases," but the paper does not analyze if this creates a domain shift where the model learns to ground Bengali text better in synthetic scenes than in authentic local cultural contexts.
- Why unresolved: While the paper shows a reduction in the real-synthetic feature gap, it does not verify if the semantic content of the synthetic images aligns with the visual reality of the Bengali-speaking demographic.
- What evidence would resolve it: A qualitative and quantitative analysis of caption performance specifically on images depicting distinct cultural scenarios (e.g., local festivals, attire) versus the standardized objects found in MSCOCO/Flickr30k.

## Limitations
- Modest BLEU-4 improvement (10.4 to 12.29) may be partly due to domain shift rather than alignment mechanism.
- Grounding analysis via cross-attention weight distribution lacks quantitative validation.
- Claim of 41% centroid gap reduction is measured only between pooled features, not at the patch level.
- LaBSE filtering assumes cross-lingual reliability on Bengali, which is unverified.
- Synthetic caption generation quality is critical but not assessed for semantic fidelity or diversity.

## Confidence
- **High**: PAL's compute-aware weighting reduces cost vs full contrastive training.
- **Medium**: Contrastive regularization improves global discrimination (supported by metrics but not robustly ablated).
- **Low**: OT regularization meaningfully improves patch-level alignment (lack of ablation and quantitative grounding evidence).

## Next Checks
1. Ablate PAL vs full contrastive loss to isolate alignment benefit from compute reduction.
2. Evaluate caption semantic similarity between synthetic and real captions (e.g., BERTScore) to quantify synthetic data quality.
3. Conduct human evaluation of grounding by asking annotators to assess cross-attention-weighted patch relevance to caption tokens.