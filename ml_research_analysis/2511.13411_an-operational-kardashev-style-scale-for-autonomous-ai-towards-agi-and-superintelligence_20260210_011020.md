---
ver: rpa2
title: An Operational Kardashev-Style Scale for Autonomous AI - Towards AGI and Superintelligence
arxiv_id: '2511.13411'
source_url: https://arxiv.org/abs/2511.13411
tags:
- drift
- tool
- define
- resource
- gates
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an operational Kardashev-style scale for
  autonomous AI (AAI) that moves beyond descriptive ladders to provide a multi-axis,
  testable framework for measuring progression from fixed automation to full AGI and
  superintelligence. The scale defines ten capability axes (Autonomy, Generality,
  Planning, Memory/Persistence, Tool Economy, Self-Revision, Sociality/Coordination,
  Embodiment, World-Model Fidelity, Economic Throughput) aggregated into a composite
  AAI-Index using weighted geometric mean.
---

# An Operational Kardashev-Style Scale for Autonomous AI - Towards AGI and Superintelligence

## Quick Facts
- arXiv ID: 2511.13411
- Source URL: https://arxiv.org/abs/2511.13411
- Authors: Przemyslaw Chojecki
- Reference count: 27
- Introduces an operational Kardashev-style scale for autonomous AI with 10 capability axes and level gates from AAI-0 to AAI-5

## Executive Summary
This paper presents a novel operational Kardashev-style scale for measuring autonomous AI progression from fixed automation to full AGI and superintelligence. The framework introduces ten capability axes (Autonomy, Generality, Planning, Memory/Persistence, Tool Economy, Self-Revision, Sociality/Coordination, Embodiment, World-Model Fidelity, Economic Throughput) aggregated into a composite AAI-Index using weighted geometric mean. A key innovation is the Self-Improvement Coefficient κ that measures capability growth per unit of agent-initiated resources, combined with closure properties that convert "self-improving AI" into falsifiable criteria. The authors define level gates for AAI-0 through AAI-4 with concrete thresholds and prove that any AAI-3 agent with sufficient self-improvement rate will eventually become AAI-5 (superintelligence).

## Method Summary
The authors develop a multi-axis framework for measuring autonomous AI progression by defining ten capability axes that capture different dimensions of intelligence and autonomy. These axes are aggregated into a composite AAI-Index using weighted geometric mean, with level gates established for each stage from AAI-0 to AAI-4. The scale introduces the Self-Improvement Coefficient κ to measure capability growth per unit of agent-initiated resources, combined with closure properties (maintenance and expansion) that provide falsifiable criteria for self-improvement. The framework includes OWA-Bench, an open-world agency benchmark suite, and proves a theorem that AAI-3 agents with sufficient self-improvement rates will eventually achieve superintelligence (AAI-5).

## Key Results
- Introduces a multi-axis framework with 10 capability axes aggregated into AAI-Index using weighted geometric mean
- Defines Self-Improvement Coefficient κ measuring capability growth per unit of agent-initiated resources
- Establishes level gates for AAI-0 through AAI-4 with concrete thresholds and operational criteria
- Proves theorem that any AAI-3 agent with sufficient self-improvement rate will eventually become AAI-5 (superintelligence)

## Why This Works (Mechanism)
The scale works by decomposing autonomous AI progression into measurable capability axes that can be independently evaluated and aggregated. The Self-Improvement Coefficient κ provides a quantitative measure of how effectively an agent converts resources into capability growth, while the closure properties ensure that self-improvement claims are falsifiable through maintenance and expansion criteria. The level gates create clear progression milestones with concrete thresholds, enabling systematic tracking of AI development. The theorem linking AAI-3 to eventual superintelligence provides a theoretical foundation for understanding how intermediate-level agents can scale to AGI and beyond through self-improvement mechanisms.

## Foundational Learning

**Self-Improvement Coefficient κ**: Measures capability growth per unit of agent-initiated resources
*Why needed*: Quantifies efficiency of resource-to-capability conversion
*Quick check*: Calculate κ for existing AI systems using resource consumption and capability improvement metrics

**Closure Properties**: Maintenance and expansion criteria for self-improvement
*Why needed*: Makes self-improvement claims falsifiable and testable
*Quick check*: Verify that agent can maintain performance while scaling resources and expand capabilities without external intervention

**Geometric Mean Aggregation**: Method for combining multiple capability axes into composite index
*Why needed*: Ensures balanced evaluation across diverse capability dimensions
*Quick check*: Test aggregation with synthetic agent profiles to verify balanced scoring

**Level Gates**: Concrete thresholds defining progression from AAI-0 to AAI-4
*Why needed*: Provides clear milestones for tracking autonomous AI development
*Quick check*: Apply level gate criteria to existing AI systems to validate threshold values

**Open-World Agency**: Ability to operate in novel, unconstrained environments
*Why needed*: Distinguishes true autonomous agents from narrow, fixed automation
*Quick check*: Test agent performance on OWA-Bench benchmark suite across diverse domains

## Architecture Onboarding

**Component map**: Capability Axes (10) -> Self-Improvement Coefficient κ -> Closure Properties -> Level Gates -> AAI-Index -> OWA-Bench Validation

**Critical path**: The progression from AAI-0 to AAI-5 depends on meeting level gate thresholds through improvement in the 10 capability axes, with self-improvement coefficient κ determining the rate of progression from AAI-3 onward

**Design tradeoffs**: Geometric mean aggregation balances all capability axes but may underweight exceptional performance in single dimensions; closure properties ensure falsifiability but may be difficult to verify experimentally

**Failure signatures**: Low κ values indicate inefficient resource utilization; failure to meet closure properties suggests superficial rather than genuine self-improvement; inability to progress through level gates despite high individual capability scores indicates aggregation methodology issues

**First 3 experiments**: 1) Calculate κ for multiple existing AI systems across different domains and resource constraints, 2) Validate OWA-Bench benchmark suite coverage completeness with diverse agents, 3) Test level gate thresholds with real-world AI systems to calibrate AAI-Index scoring

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical foundation of composite AAI-Index requires further validation, particularly regarding geometric mean aggregation and weight assignment
- Self-Improvement Coefficient κ needs empirical validation and may be sensitive to measurement methodology
- OWA-Bench benchmark suite has not been independently verified for coverage completeness or construct validity

## Confidence
- High confidence in the multi-axis framework structure and level definitions
- Medium confidence in the mathematical aggregation method and κ formulation
- Medium confidence in the level gates and threshold values
- Low confidence in the theorem proving eventual superintelligence emergence from AAI-3 agents

## Next Checks
1. Empirical validation of the Self-Improvement Coefficient κ using real-world AI systems across multiple domains and resource constraints
2. Independent replication of OWA-Bench benchmark suite with external agents to verify construct validity and coverage completeness
3. Experimental testing of level gate thresholds with diverse AI systems to calibrate the composite AAI-Index scoring methodology