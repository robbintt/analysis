---
ver: rpa2
title: 'WSSM: Geographic-enhanced hierarchical state-space model for global station
  weather forecast'
arxiv_id: '2501.11238'
source_url: https://arxiv.org/abs/2501.11238
tags:
- weather
- time
- forecasting
- hierarchical
- encoder
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of accurate global station weather
  forecasting, particularly for extreme weather events, by proposing a novel Weather
  State-space Model (WSSM) based on Mamba. The core method introduces geographical
  encoding to incorporate real-world time and location information, and employs a
  hierarchical Bi-Mamba encoder with time-frequency Bi-Mamba blocks to capture multi-scale
  temporal and frequency features.
---

# WSSM: Geographic-enhanced hierarchical state-space model for global station weather forecast

## Quick Facts
- **arXiv ID**: 2501.11238
- **Source URL**: https://arxiv.org/abs/2501.11238
- **Reference count**: 18
- **Primary result**: Achieves state-of-the-art performance on Weather-5K subset with 90% improvement in SEDI for extreme weather prediction

## Executive Summary
This paper introduces WSSM, a novel Weather State-space Model based on Mamba architecture for global station weather forecasting. The model addresses the challenge of accurate weather prediction, particularly for extreme events, by incorporating geographical encoding and a hierarchical Bi-Mamba encoder. WSSM effectively integrates real-world time and location information while capturing multi-scale temporal and frequency features. The model demonstrates superior performance on the Weather-5K subset, significantly outperforming existing methods in both overall prediction accuracy and extreme weather event forecasting.

## Method Summary
WSSM proposes a geographic-enhanced hierarchical state-space model that leverages Mamba architecture for weather forecasting. The core innovation lies in introducing geographical encoding to incorporate real-world time and location information into the model. The hierarchical Bi-Mamba encoder with time-frequency Bi-Mamba blocks enables the model to capture multi-scale temporal and frequency features. This architecture allows WSSM to effectively integrate geographical knowledge and synthesize coarse-to-fine features, resulting in improved prediction accuracy for both general weather conditions and extreme weather events.

## Key Results
- Achieves state-of-the-art performance on Weather-5K subset
- Surpasses existing methods with 90% improvement in Symmetric Extremal Dependence Index (SEDI) for extreme weather prediction
- Demonstrates particularly outstanding results in extreme weather forecasting
- Shows overall improvement in prediction accuracy across various weather conditions

## Why This Works (Mechanism)
The success of WSSM stems from its ability to effectively incorporate geographical context and capture multi-scale temporal patterns. By integrating real-world time and location information through geographical encoding, the model can better understand the spatial dependencies and local weather patterns that influence forecasting. The hierarchical Bi-Mamba encoder with time-frequency blocks allows for the extraction of features at different temporal scales and frequency bands, enabling the model to capture both short-term fluctuations and long-term trends in weather data. This multi-scale approach, combined with the state-space modeling capability of Mamba, provides a powerful framework for handling the complex, non-linear relationships inherent in weather systems.

## Foundational Learning
- **Geographical Encoding**: Why needed - To incorporate real-world location and time information into the model. Quick check - Verify if geographical features improve prediction accuracy over non-geographical baselines.
- **State-space Models**: Why needed - To handle long-range dependencies and complex temporal dynamics in weather data. Quick check - Compare performance against traditional RNN-based approaches.
- **Hierarchical Feature Extraction**: Why needed - To capture weather patterns at multiple scales (local to global). Quick check - Analyze feature importance at different levels of the hierarchy.
- **Time-frequency Analysis**: Why needed - To separate and analyze weather patterns occurring at different temporal frequencies. Quick check - Evaluate performance gains from frequency-specific feature extraction.
- **Bi-directional Processing**: Why needed - To incorporate both past and future context for better predictions. Quick check - Compare against uni-directional models in terms of prediction accuracy.
- **Mamba Architecture**: Why needed - To efficiently process long sequences while maintaining state information. Quick check - Benchmark against other sequence models (Transformer, LSTM) in terms of accuracy and computational efficiency.

## Architecture Onboarding

### Component Map
Geographical Encoding -> Hierarchical Bi-Mamba Encoder -> Time-Frequency Bi-Mamba Blocks -> Weather Prediction Layer

### Critical Path
1. Input weather station data and geographical coordinates
2. Geographical encoding layer transforms location and time into feature representations
3. Hierarchical Bi-Mamba encoder processes encoded features at multiple scales
4. Time-frequency Bi-Mamba blocks extract temporal and frequency-specific features
5. Weather prediction layer generates final forecasts

### Design Tradeoffs
- **Complexity vs. Performance**: The hierarchical structure and time-frequency blocks add computational overhead but significantly improve prediction accuracy, especially for extreme events.
- **Global vs. Local Focus**: Balancing global weather patterns with local geographical influences requires careful weighting in the model architecture.
- **Real-time vs. Accuracy**: The model's complexity may impact real-time forecasting capabilities, necessitating a tradeoff between prediction quality and inference speed.

### Failure Signatures
- Poor performance in regions with sparse weather station coverage
- Overfitting to specific geographical patterns, reducing generalization
- Computational bottlenecks in real-time applications due to model complexity
- Inaccurate predictions during rapid weather transitions not well-represented in training data

### First Experiments
1. Ablation study removing geographical encoding to quantify its contribution to overall performance
2. Comparison of single-scale vs. multi-scale feature extraction in the hierarchical encoder
3. Analysis of prediction accuracy across different temporal resolutions (hourly, daily, weekly)

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions in the provided content.

## Limitations
- Performance may degrade in regions with sparse weather station coverage due to reliance on geographical encoding
- Validation limited to Weather-5K subset, raising questions about scalability to larger, more diverse datasets
- Impressive 90% improvement in SEDI for extreme weather prediction may be dataset-dependent and require validation on independent extreme weather datasets
- Hierarchical Bi-Mamba encoder's complexity could pose challenges in terms of computational efficiency and interpretability, particularly for real-time forecasting applications

## Confidence
- **High confidence**: Overall accuracy improvements and state-of-the-art performance on Weather-5K subset
- **Medium confidence**: Ability to generalize to other datasets and regions, given the limited scope of validation
- **Low confidence**: Interpretability and computational efficiency of the hierarchical Bi-Mamba encoder, which requires further investigation

## Next Checks
1. Test WSSM on a larger, more diverse global weather dataset to assess scalability and generalization
2. Evaluate the model's performance in regions with sparse weather station coverage to determine the robustness of geographical encoding
3. Conduct ablation studies to isolate the contributions of the hierarchical Bi-Mamba encoder and time-frequency blocks to overall performance