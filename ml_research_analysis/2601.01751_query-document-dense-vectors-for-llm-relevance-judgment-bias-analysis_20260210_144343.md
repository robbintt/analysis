---
ver: rpa2
title: Query-Document Dense Vectors for LLM Relevance Judgment Bias Analysis
arxiv_id: '2601.01751'
source_url: https://arxiv.org/abs/2601.01751
tags:
- https
- relevance
- bias
- agreement
- queries
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel clustering-based framework for diagnosing
  bias in LLM-based relevance judgments by embedding query-document pairs into a joint
  semantic space using INSTRUCTOR embeddings. By applying HDBSCAN clustering, the
  method identifies semantically coherent neighborhoods where human and LLM agreement
  varies systematically, rather than being randomly distributed.
---

# Query-Document Dense Vectors for LLM Relevance Judgment Bias Analysis

## Quick Facts
- arXiv ID: 2601.01751
- Source URL: https://arxiv.org/abs/2601.01751
- Reference count: 0
- Key outcome: A clustering-based framework identifies systematic LLM relevance judgment bias by embedding query-document pairs into a joint semantic space and analyzing cluster-level human-LLM agreement variation.

## Executive Summary
This paper introduces a novel clustering-based framework for diagnosing bias in LLM-based relevance judgments by embedding query-document pairs into a joint semantic space using INSTRUCTOR embeddings. By applying HDBSCAN clustering, the method identifies semantically coherent neighborhoods where human and LLM agreement varies systematically, rather than being randomly distributed. Cluster-level analysis using Gwet's AC1—chosen for its robustness to label imbalance—reveals that disagreement concentrates in dense semantic regions rather than noise clusters. The cluster-based agreement variation measure quantifies how agreement shifts across clusters, identifying bias-prone queries where LLMs consistently under-recall or over-include relevant content. Qualitative analysis of the top 10 bias-prone queries in TREC DL-2019 and DL-2020 shows recurrent failures in definitional, policy-related, and ambiguous contexts.

## Method Summary
The framework embeds concatenated query-document pairs using INSTRUCTOR-XL with a task instruction ("Judge the document's relevance to the query for ad-hoc retrieval"), then applies HDBSCAN clustering to identify dense semantic neighborhoods. Post-hoc label attachment combines human relevance judgments (binarized from qrels) with LLM judgments from four models (Claude-3, Gemini-1.5, GPT-4o, Llama-3.1). Per-cluster agreement is measured using Gwet's AC1, and cluster-based agreement variation (ΔAC1) quantifies instability across clusters for each query. Bias-prone queries are identified using a heuristic requiring ΔAC1≥0.5, or outlier thresholds, or directional flips where maximum cluster AC1>0.8 and minimum<0.2.

## Key Results
- Systematic human-LLM disagreement concentrates in dense semantic clusters rather than distributing randomly across the embedding space
- Cluster-level agreement variation reveals bias-prone queries where LLMs show inconsistent judgment patterns across semantic contexts
- Top bias-prone queries exhibit recurring failure patterns: definitional rigidity (e.g., "what is ethical behavior"), policy-related mismatches, and ambiguous contexts
- Gwet's AC1 proves more robust than Cohen's κ for measuring agreement under label imbalance conditions

## Why This Works (Mechanism)

### Mechanism 1
- Joint query-document embeddings capture relational semantics that separate query or document embeddings cannot
- INSTRUCTOR encodes the Q–D pair with a task instruction, producing a single vector where relevance is implicit in the pair's representation
- Core assumption: Relevance is a relational property of the (query, document) pair, not decomposable into independent features
- Evidence anchors: Abstract emphasizes "embedding query-document pairs into a joint semantic space, treating relevance as a relational property"; section 3.2 notes INSTRUCTOR's task instruction capability
- Break condition: If relevance can be adequately captured by cosine similarity between separate query and document embeddings, joint embeddings add unnecessary complexity

### Mechanism 2
- Systematic human-LLM disagreement concentrates in dense semantic clusters rather than distributing randomly
- HDBSCAN identifies dense neighborhoods in the embedding space; post-hoc label attachment reveals agreement varies substantially across clusters
- Core assumption: Semantic similarity in embedding space correlates with judgment behavior similarity
- Evidence anchors: Abstract states "systematic disagreement between humans and LLMs is concentrated in specific semantic clusters rather than distributed randomly"; section 4.1 shows bias is larger in dense semantic neighborhoods
- Break condition: If cluster-level agreement variation is uniformly low across all clusters, disagreement is random rather than systematic

### Mechanism 3
- Cluster-based agreement variation (ΔAC1) localizes bias-prone queries by detecting semantic neighborhoods where LLM judgment diverges from human judgment
- For each query, compute AC1 within each cluster containing its Q–D pairs; the range quantifies instability. High variation signals queries where LLMs apply inconsistent heuristics
- Core assumption: Queries with high cross-cluster agreement variation are bias-prone rather than genuinely ambiguous even for humans
- Evidence anchors: Section 3.5 defines ΔAC1 as signaling "divergent alignment across contexts"; section 4.4 shows Claude-3 and LLaMA-3.1 with largest divergences in definitional queries
- Break condition: If high-variation queries also show high human–human disagreement, the signal reflects inherent ambiguity rather than LLM bias

## Foundational Learning

- **Gwet's AC1 agreement coefficient**: Needed because Cohen's κ collapses under label imbalance (the "κ paradox"), which is common in relevance judgment where relevant documents are sparse. AC1's chance-correction is based on disagreement probability, yielding stable estimates under imbalance.
  - Quick check: Given a cluster with 90% non-relevant labels where both human and LLM agree on 85% of cases, which metric (κ or AC1) would show higher agreement?

- **HDBSCAN density-based clustering**: Needed because unlike k-means, HDBSCAN does not assume spherical clusters and automatically identifies noise points (C−1), which the paper shows have different agreement properties than dense clusters.
  - Quick check: What happens to Q–D pairs that fall into the noise cluster C−1, and how should their agreement be interpreted differently?

- **Instruction-tuned embeddings (INSTRUCTOR)**: Needed because the embedding model conditions on natural-language instructions, allowing the same Q–D pair to be embedded differently for different tasks. The paper selected one instruction via cluster purity evaluation.
  - Quick check: If you change the instruction from "Judge relevance for ad-hoc retrieval" to "Compute semantic similarity," would you expect cluster purity to increase, decrease, or stay the same?

## Architecture Onboarding

- **Component map**: Raw Q–D pairs → INSTRUCTOR-XL embedding with task instruction → HDBSCAN clustering → Label attachment (human + LLM) → Per-cluster AC1 computation → ΔAC1 variation per query → Heuristic bias diagnosis → Qualitative pattern analysis
- **Critical path**: (1) Instruction selection via 80th-percentile cluster purity; (2) Correct handling of noise cluster vs. non-noise clusters; (3) Threshold selection for τ_abs (paper uses 0.5)
- **Design tradeoffs**: Conservative τ_abs (0.5) prioritizes precision over recall for bias detection; INSTRUCTOR-XL chosen over E5 and Qwen3 for stability, not raw benchmark performance; binary relevance binarization loses graded nuance
- **Failure signatures**: (1) Low cluster purity indicates instruction mismatch; (2) Agreement variation concentrated in noise cluster suggests embedding failure; (3) Consistent directional flips (AC1 > 0.8 in some clusters, < 0.2 in others) indicate semantic blind spots
- **First 3 experiments**:
  1. Replicate instruction selection: Embed a sample with multiple instructions, cluster with HDBSCAN, and compare 80th-percentile purity to verify "Judge relevance for ad-hoc retrieval" is optimal for your data
  2. Validate AC1 advantage: Compute both κ and AC1 on imbalanced clusters; confirm κ collapses toward zero while AC1 remains informative
  3. Pilot bias localization: Apply the ΔAC1 heuristic to a held-out query set; manually inspect top-5 bias-prone queries to verify they match the definitional/ambiguous patterns reported

## Open Questions the Paper Calls Out

- **Can the clustering-based framework serve as a pre-screening tool to predict bias-prone queries without requiring human labels for validation?**: The framework currently depends on human labels to compute AC1 agreement; the authors propose but do not test whether structural properties (cross-domain overlap, definitional framing, semantic ambiguity) alone can predict instability.

- **How do identified bias patterns generalize across diverse IR tasks, domains, and model families beyond TREC Deep Learning passage retrieval?**: The study is limited to two TREC DL datasets and four LLM judges; whether definitional rigidity and policy mismatches recur in web search, legal IR, or non-English collections remains unknown.

- **Does the choice of embedding model systematically affect which semantic neighborhoods are identified as bias-prone?**: Clustering is embedding-dependent; different semantic representations may partition the Q-D space differently, potentially flagging different queries as bias-prone.

- **Can insights from diagnosed failure modes inform improved prompting strategies that reduce systematic LLM judgment errors?**: The qualitative analysis identifies recurring error patterns, but the paper does not explore whether such diagnoses can guide intervention.

## Limitations
- HDBSCAN hyperparameter sensitivity is not addressed, with min_cluster_size, min_samples, and distance metric unspecified
- Instruction selection validation lacks detailed comparison methodology and baseline instructions
- Generalizability across datasets is limited to TREC DL-2019/2020 without testing on other IR tasks or domains

## Confidence
- **High confidence**: The core mechanism of using joint query-document embeddings with INSTRUCTOR is technically sound and well-supported by the literature on instruction-tuned models
- **Medium confidence**: The clustering-based bias localization approach is novel and methodologically rigorous, but depends on unspecified implementation details
- **Medium confidence**: The qualitative patterns of LLM failures (definitional, policy-related, ambiguous queries) align with existing literature but require broader validation

## Next Checks
1. **Hyperparameter sensitivity analysis**: Systematically vary HDBSCAN parameters (min_cluster_size from 5-50, min_samples from 1-10) and measure impact on cluster purity and agreement variation metrics
2. **Instruction ablation study**: Test alternative instructions (e.g., "Determine if document is relevant to query for ad-hoc retrieval" vs. "Judge semantic similarity") and compare 80th-percentile purity scores across multiple runs
3. **Cross-dataset validation**: Apply the framework to TREC Robust 2004 or MS MARCO passage ranking data to test whether identified bias patterns generalize beyond DL tracks