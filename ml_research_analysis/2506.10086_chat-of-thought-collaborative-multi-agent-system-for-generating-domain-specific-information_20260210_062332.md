---
ver: rpa2
title: 'Chat-of-Thought: Collaborative Multi-Agent System for Generating Domain Specific
  Information'
arxiv_id: '2506.10086'
source_url: https://arxiv.org/abs/2506.10086
tags:
- system
- chat-of-thought
- fmea
- generation
- failure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The Chat-of-Thought system addresses the labor-intensive and error-prone
  manual creation of Failure Modes and Effects Analysis (FMEA) documents for industrial
  assets by automating the process using a multi-agent framework with specialized
  roles. The core innovation lies in a dynamic, multi-persona-driven Chat-of-Thought
  mechanism, where LLM-based agents engage in iterative discussions to collaboratively
  refine FMEA outputs, extending beyond traditional Chain-of-Thought reasoning.
---

# Chat-of-Thought: Collaborative Multi-Agent System for Generating Domain Specific Information

## Quick Facts
- **arXiv ID**: 2506.10086
- **Source URL**: https://arxiv.org/abs/2506.10086
- **Reference count**: 5
- **Primary result**: Automates FMEA document generation for industrial assets using a multi-agent framework with specialized roles and iterative refinement

## Executive Summary
Chat-of-Thought is a multi-agent LLM framework that automates the labor-intensive process of creating Failure Modes and Effects Analysis (FMEA) documents for industrial assets. The system employs specialized agents with distinct roles—Facilitator, Reliability Engineer, Quality Engineer, SME Validator, and Summarizer—that engage in iterative, multi-round dialogues to collaboratively refine FMEA outputs. This dynamic Chat-of-Thought mechanism extends beyond traditional Chain-of-Thought reasoning by incorporating feedback loops and continuous improvement through structured agent interactions. Validation by Subject Matter Experts confirmed the system reliably generates accurate FMEA tables for both standard and out-of-scope assets, identifying failure modes, root causes, and effects with high precision.

## Method Summary
The system implements a role-specialized multi-agent framework where each agent is defined by a tuple (Ri, Si, Mi) representing role, skill set, and system messages. The process begins with Context Discovery to extract asset details, followed by a multi-round Chat-of-Thought mechanism where agents iteratively select questions from a bank, route them based on contextual understanding, and generate responses. The system progresses through four defined rounds—zero-shot baseline, in-context learning, chain-of-interaction with feedback loops, and random few-shot generalization. Quality control is maintained through a pre-trained classifier for filtering useless questions and self-BLEU scoring for duplicate removal. SME validation provides the final quality check before FMEA table generation.

## Key Results
- Subject Matter Experts validated that the system reliably generates accurate FMEA tables for both standard and out-of-scope industrial assets
- The multi-agent framework successfully identifies failure modes, root causes, and effects with high precision across diverse asset classes
- The iterative Chat-of-Thought mechanism extends beyond single-pass generation to produce validated, refined outputs through continuous feedback loops

## Why This Works (Mechanism)

### Mechanism 1: Role-Specialized Agent Collaboration
- Claim: Multi-agent collaboration with specialized roles improves FMEA output quality compared to single-agent approaches.
- Mechanism: Agents are initialized as tuples (Ri, Si, Mi) defining role, skill set, and system messages. Each persona contributes domain-specific expertise—Facilitator orchestrates, Reliability Engineer identifies failure modes, Quality Engineer reviews consistency, SME Validator ensures standards, Summarizer condenses outputs—creating division of cognitive labor across the FMEA generation pipeline.
- Core assumption: Decomposing expertise across specialized agents yields more comprehensive coverage than monolithic generation.
- Evidence anchors:
  - [abstract]: "Chat-of-Thought employs multiple collaborative Large Language Model (LLM)-based agents with specific roles"
  - [section 2.1]: "Each agent Ai is represented as a tuple (Ri, Si, Mi), where Ri denotes the role, Si represents the skill set, and Mi specifies the system messages guiding the agent's behavior"
  - [corpus]: "Talk Structurally, Act Hierarchically" (FMR 0.56) supports collaborative multi-agent frameworks for complex tasks, though direct comparison data for FMEA-specific quality gains is not provided

### Mechanism 2: Iterative Multi-Round Refinement (Chat-of-Thought)
- Claim: Multi-round, feedback-driven dialogue extends beyond Chain-of-Thought to produce validated, refined FMEA outputs.
- Mechanism: The system progresses through defined phases—Round 1 (zero-shot baseline), Round 2 (in-context learning with FMEA examples), Round 3 (chain-of-interaction with question-answer bank feedback loops), Round 4 (random few-shot for generalization). Each round builds on prior outputs, incorporating human feedback where available.
- Core assumption: Iterative refinement through simulated expert dialogue converges toward higher-quality outputs than single-pass generation.
- Evidence anchors:
  - [abstract]: "Chat of Thought, where dynamic, multi-persona-driven discussions enable iterative refinement of content"
  - [section 3]: "Chain-of-interaction techniques introduce feedback loops between the question bank and answer bank, enabling iterative learning and continuous improvement"
  - [corpus]: "Fault Cause Identification through Ontology-Guided FMEA Graph Learning with LLMs" (FMR 0.50) suggests iterative LLM approaches benefit FMEA tasks, but specific ablation data on round count is absent

### Mechanism 3: Template-Driven Context-Aware Routing
- Claim: Structured routing using templates and context improves task-agent matching and output consistency.
- Mechanism: Templates T define guidelines for routing questions to appropriate personas based on contextual understanding C and skill alignment Si. The Question Assignment Agent dynamically routes queries, and templates adjust to maintain relevance across asset classes.
- Core assumption: Explicit routing structures reduce ambiguity in task assignment and ensure consistent outputs across diverse scenarios.
- Evidence anchors:
  - [abstract]: "context-aware routing, and template-driven workflows"
  - [section 2.4]: "Each template T defines structured guidelines for routing questions to the appropriate personas. These templates are dynamically adjusted to maintain contextual relevance"
  - [corpus]: Evidence for template-driven routing effectiveness specifically is limited in available neighbors; "RubikSQL" (FMR 0.56) demonstrates agentic task routing in industrial NL2SQL but does not directly validate this mechanism

## Foundational Learning

- Concept: **Failure Modes and Effects Analysis (FMEA) Structure**
  - Why needed here: FMEA is the target output; understanding its components (failure modes, root causes, effects, severity/occurrence/detection ratings) is essential to evaluate system correctness.
  - Quick check question: For a centrifugal pump, can you list three distinct failure modes and their corresponding root causes?

- Concept: **Multi-Agent LLM Role Assignment**
  - Why needed here: The architecture depends on role-based prompting where system messages (Mi) guide agent behavior distinct from standard single-prompt approaches.
  - Quick check question: How does defining a "Reliability Engineer" persona via system message differ from asking a generic LLM about reliability?

- Concept: **Self-BLEU for Diversity Measurement**
  - Why needed here: Quality control filters duplicates using self-BLEU thresholds; understanding this metric is necessary for tuning filtration.
  - Quick check question: If a set of agent responses has a self-BLEU score of 0.85, what does this indicate about their lexical diversity?

## Architecture Onboarding

- Component map:
  Agent Initialization -> Context Discovery -> Question Selection (Facilitator) -> Dynamic Persona Assignment -> Response Generation -> Summary Aggregation -> Quality Check -> SME Validation

- Critical path:
  Context Discovery → Question Selection (Facilitator) → Dynamic Persona Assignment → Response Generation → Summary Aggregation → Quality Check → SME Validation

- Design tradeoffs:
  - **Agent count vs. coordination overhead**: More specialized agents improve coverage but increase orchestration complexity
  - **Round depth vs. latency**: Additional rounds improve refinement but multiply inference cost
  - **Template rigidity vs. adaptability**: Strict templates ensure consistency but risk failure on out-of-scope assets

- Failure signatures:
  - **Dialogue stagnation**: Agents converge to repetitive outputs without new insights (monitor self-BLEU trends across rounds)
  - **Routing gaps**: Questions fail to match any agent skill profile (log unmatched queries for template revision)
  - **Out-of-scope collapse**: Template exhaustion on novel assets produces generic or incomplete FMEA tables (flag early for human intervention)

- First 3 experiments:
  1. **Baseline comparison**: Generate FMEA for a standard asset (e.g., vertical close-coupled pump) using single-agent LLM vs. full Chat-of-Thought; measure precision/recall of failure mode identification against SME-validated ground truth
  2. **Round ablation**: Run the system with 1, 2, 3, and 4 rounds on both standard and out-of-scope assets; quantify incremental improvement in completeness and SME pass rate per round
  3. **Routing accuracy test**: Inject questions with known optimal agent targets; measure routing accuracy and analyze misrouting patterns to refine template definitions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the multi-agent architecture provide higher FMEA accuracy compared to a single-agent approach with equal token limits?
- Basis in paper: [inferred] The paper introduces complex multi-round interactions but lacks comparative benchmarks against simpler baselines.
- Why unresolved: It is unclear if the overhead of agent collaboration provides value beyond the underlying LLM's standard capabilities.
- What evidence would resolve it: Ablation studies comparing output correctness between the multi-agent framework and a single-agent baseline.

### Open Question 2
- Question: How does the system mitigate hallucinations for "out-of-scope" assets when the domain-specific knowledge repositories lack relevant historical data?
- Basis in paper: [inferred] The Context Discovery stage relies on "domain-specific knowledge repositories," yet the system targets novel or less-common assets.
- Why unresolved: The reliance on retrieval versus generation for sparse data contexts is not quantified.
- What evidence would resolve it: Evaluation of FMEA accuracy on assets deliberately excluded from the knowledge repository.

### Open Question 3
- Question: Can the "SME Validator" agent reliably detect factual errors without external tool use?
- Basis in paper: [inferred] The architecture uses an LLM-based "SME Validator" persona to check outputs.
- Why unresolved: Relying on an LLM to validate another LLM's engineering output risks reinforcing errors rather than correcting them.
- What evidence would resolve it: Measurement of the Validator agent's success rate in flagging known, artificially injected failure modes.

## Limitations

- The system's multi-round agent dialogue introduces significant computational overhead without clear timing or cost comparisons to single-pass approaches
- Effectiveness of template-driven routing for out-of-scope assets is claimed but not empirically validated across diverse asset classes
- The paper lacks detailed analysis of how agent persona conflicts are resolved when multiple agents provide contradictory outputs

## Confidence

- **High Confidence**: The core architecture of role-specialized agents with defined (Ri, Si, Mi) tuples is clearly specified and implementable
- **Medium Confidence**: The iterative refinement mechanism through multiple rounds is well-described, but the specific learning objectives and feedback incorporation strategies for each round are not detailed
- **Low Confidence**: The effectiveness of template-driven routing for out-of-scope assets is claimed but not empirically validated across diverse asset classes

## Next Checks

1. **Ablation Study**: Systematically remove one agent role at a time (e.g., Quality Engineer, SME Validator) to quantify each role's contribution to FMEA quality and identify potential redundancy
2. **Out-of-Scope Stress Test**: Apply the system to 10 novel asset classes not represented in the training data and measure template coverage, output completeness, and SME validation rates
3. **Computational Efficiency Analysis**: Measure total inference time and cost for single-agent vs. multi-agent approaches across 50 FMEA generation tasks, including memory usage and round-trip latency