---
ver: rpa2
title: Improving Romanian LLM Pretraining Data using Diversity and Quality Filtering
arxiv_id: '2511.01090'
source_url: https://arxiv.org/abs/2511.01090
tags:
- data
- romanian
- educational
- filtering
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a multi-dimensional filtering approach to
  improve Romanian pretraining data quality for Large Language Models (LLMs). The
  method involves training a lightweight multitask classifier on LLM-annotated Romanian
  texts, which predicts educational value, topic, format, and reader education level.
---

# Improving Romanian LLM Pretraining Data using Diversity and Quality Filtering

## Quick Facts
- **arXiv ID:** 2511.01090
- **Source URL:** https://arxiv.org/abs/2511.01090
- **Reference count:** 16
- **Primary result:** Romanian LLM pretraining data improved through multi-dimensional filtering shows significant benchmark performance gains

## Executive Summary
This paper addresses the challenge of low-quality pretraining data for Romanian Large Language Models by introducing a comprehensive filtering approach. The researchers developed a lightweight multitask classifier trained on LLM-annotated Romanian texts that predicts educational value, topic, format, and reader education level. By applying this classifier to the FineWeb2 corpus with a threshold of 3.5 for educational value, they created FineWeb2-Edu-Ro, a high-quality dataset that demonstrates significant performance improvements across multiple benchmarks when used for continual pretraining of a Llama-2-7B model.

## Method Summary
The researchers developed a multi-dimensional filtering approach for Romanian pretraining data that combines quality assessment with diversity preservation. They first created a multitask classifier trained on LLM-annotated Romanian texts, which predicts educational value, topic classification, format identification, and reader education level. This classifier was then applied to the FineWeb2 corpus, filtering out low-quality content based on educational value scores below 3.5. The resulting FineWeb2-Edu-Ro dataset maintains broader topic coverage while ensuring higher quality standards. The filtered dataset was used for continual pretraining of a Llama-2-7B model, with performance evaluated against multiple benchmarks including Ro-MMLU, Ro-ARC, and Ro-HellaSwag.

## Key Results
- Continual pretraining on FineWeb2-Edu-Ro dataset showed significant performance improvements across Ro-MMLU, Ro-ARC, and Ro-HellaSwag benchmarks compared to unfiltered data
- The multitask classifier successfully maintained topic diversity while improving quality, revealing notable differences between Romanian and English data distributions
- Romanian texts showed higher proportions of Finance & Business, Health, and Politics content compared to English counterparts
- The filtering approach outperformed another filtering method (JQL) in terms of downstream task performance

## Why This Works (Mechanism)
The filtering approach works by addressing two critical issues in pretraining data: quality and relevance. By training a multitask classifier on LLM-annotated Romanian texts, the system can effectively distinguish between high-quality educational content and low-value material. The educational value score serves as a primary quality filter, while topic classification ensures diversity across relevant domains. This combination prevents the model from learning from noise and irrelevant content while maintaining exposure to the full spectrum of Romanian language usage patterns. The classifier's ability to predict reader education level also helps ensure appropriate complexity in the training data.

## Foundational Learning

**Multitask Learning**
*Why needed:* Enables simultaneous prediction of multiple attributes (educational value, topic, format, education level) from the same input, improving efficiency and consistency
*Quick check:* Verify that all four prediction tasks converge during training and show reasonable accuracy on validation sets

**Educational Value Scoring**
*Why needed:* Provides quantitative measure to filter low-quality content while preserving diverse topics
*Quick check:* Ensure threshold selection (3.5) balances data retention with quality improvement through ablation studies

**Language-Specific Data Filtering**
*Why needed:* Romanian has unique linguistic characteristics requiring specialized filtering approaches rather than direct application of English models
*Quick check:* Compare topic distributions between filtered Romanian data and equivalent English datasets to identify language-specific patterns

## Architecture Onboarding

**Component Map**
Raw Text Data -> LLM Annotation Pipeline -> Multitask Classifier Training -> FineWeb2 Corpus Filtering -> FineWeb2-Edu-Ro Dataset -> Llama-2-7B Continual Pretraining -> Benchmark Evaluation

**Critical Path**
LLM annotation → multitask classifier training → educational value filtering → continual pretraining → benchmark evaluation

**Design Tradeoffs**
Quality vs. quantity: Higher educational value thresholds improve quality but reduce dataset size
Single-task vs. multitask: Multitask approach provides comprehensive filtering but increases complexity
LLM annotation vs. human annotation: LLM annotation is scalable but may introduce systematic biases

**Failure Signatures**
Poor benchmark performance despite filtering indicates classifier not capturing relevant quality signals
Significant topic imbalance suggests overly aggressive filtering or classifier bias
High false positive rate in educational value prediction leads to excessive data loss

**First 3 Experiments**
1. Train multitask classifier and evaluate on held-out annotated Romanian text
2. Apply classifier to FineWeb2 with varying educational value thresholds and measure dataset characteristics
3. Pretrain Llama-2-7B on filtered dataset and evaluate on Ro-MMLU benchmark

## Open Questions the Paper Calls Out
None

## Limitations

- Results may not generalize to other low-resource languages with different linguistic features
- Reliance on LLM-based annotation introduces potential systematic biases that remain unmeasured
- Limited comparison to alternative filtering methods beyond JQL
- Does not address potential trade-offs between quality filtering and linguistic diversity

## Confidence

**High confidence:** Methodology is well-documented and reproducible; benchmark results show consistent improvements; dataset statistics are clearly described

**Medium confidence:** Generalization to other languages not empirically validated; 3.5 threshold choice may not be optimal for all use cases; limited comparison with filtering alternatives

## Next Checks

1. Test the filtering methodology on another low-resource language with different linguistic characteristics to evaluate cross-linguistic applicability

2. Conduct comprehensive ablation study varying educational value threshold and examining trade-offs between data quantity, quality, and downstream performance

3. Implement and compare additional filtering approaches (e.g., perplexity-based filtering, human annotation) to evaluate multitask classifier advantages