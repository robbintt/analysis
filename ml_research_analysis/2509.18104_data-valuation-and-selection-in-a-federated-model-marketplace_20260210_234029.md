---
ver: rpa2
title: Data Valuation and Selection in a Federated Model Marketplace
arxiv_id: '2509.18104'
source_url: https://arxiv.org/abs/2509.18104
tags:
- data
- performance
- distance
- training
- wasserstein
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a framework for data valuation and selection
  in federated model marketplaces. The key technical contribution is a Wasserstein-based
  performance estimator that predicts model accuracy across unseen data combinations
  and scales without requiring full-scale training.
---

# Data Valuation and Selection in a Federated Model Marketplace

## Quick Facts
- arXiv ID: 2509.18104
- Source URL: https://arxiv.org/abs/2509.18104
- Authors: Wenqian Li; Youjia Yang; Ruoxi Jia; Yan Pang
- Reference count: 40
- Primary result: Introduces Wasserstein-based performance estimator for federated model marketplaces

## Executive Summary
This paper addresses the challenge of data valuation and selection in federated model marketplaces, where participants contribute data to train models while maintaining privacy. The authors propose a framework that uses Wasserstein distance to estimate model performance across different data combinations without requiring full-scale training or raw data sharing. By leveraging neural scaling laws and distributed computation, the method can predict accuracy for unseen data combinations and extrapolate performance from small pilot runs to larger training budgets.

## Method Summary
The authors introduce a Wasserstein-based performance estimator that predicts model accuracy across unseen data combinations in federated learning settings. The method uses distributed computation to approximate Wasserstein distance while preserving privacy, avoiding the need to share raw data. Neural scaling laws are leveraged to extrapolate performance from small pilot runs to larger training budgets. The approach is evaluated across diverse scenarios including label skew, mislabeled, and unlabeled data, demonstrating consistent identification of high-performing data combinations with correlation scores around 0.88 between predicted and actual accuracy.

## Key Results
- Achieves correlation scores around 0.88 between predicted and actual accuracy across diverse scenarios
- Successfully identifies high-performing data combinations in label skew, mislabeled, and unlabeled data scenarios
- Enables privacy-preserving model delivery and data value quantification without full-scale training requirements

## Why This Works (Mechanism)
The method works by using Wasserstein distance as a metric to quantify the relationship between data distributions and model performance. The distributed approximation of Wasserstein distance allows for privacy preservation while maintaining computational efficiency. Neural scaling laws provide a theoretical foundation for extrapolating performance from small-scale experiments to full training scenarios. This combination enables accurate prediction of model accuracy across data combinations without requiring direct access to raw data or complete training runs.

## Foundational Learning
- **Wasserstein Distance**: Measures the distance between probability distributions; needed for quantifying data distribution relationships without sharing raw data; quick check: verify mathematical properties hold under federated constraints
- **Neural Scaling Laws**: Describe how model performance scales with data and compute; needed for extrapolating from pilot runs to full training; quick check: validate scaling assumptions hold across diverse datasets
- **Federated Learning**: Distributed machine learning where data stays local; needed to maintain privacy in multi-party model training; quick check: ensure no raw data leakage in distance computations
- **Performance Estimation**: Predicting model accuracy without full training; needed to reduce computational overhead; quick check: compare predictions against actual training results
- **Privacy-Preserving Computation**: Techniques that maintain data confidentiality during processing; needed for federated marketplaces; quick check: verify no information leakage through Wasserstein approximations

## Architecture Onboarding

**Component Map**: Data Sources -> Distributed Wasserstein Computation -> Performance Estimation -> Model Selection

**Critical Path**: The critical path involves collecting pilot training results, computing Wasserstein distances in a distributed manner, applying neural scaling laws to extrapolate performance, and selecting optimal data combinations. This path must maintain privacy guarantees while achieving accurate predictions.

**Design Tradeoffs**: The primary tradeoff is between privacy preservation and prediction accuracy. More precise Wasserstein distance calculations improve accuracy but may require more communication between parties. The use of neural scaling laws trades off the need for full training against potential extrapolation errors. The distributed computation approach balances computational efficiency against approximation accuracy.

**Failure Signatures**: Poor correlation between predicted and actual accuracy may indicate violations of neural scaling law assumptions or insufficient pilot run data. Privacy breaches could occur if Wasserstein distance approximations inadvertently leak information about raw data distributions. Computational bottlenecks may arise when scaling to many data sources due to the distributed nature of Wasserstein calculations.

**3 First Experiments**:
1. Validate neural scaling law extrapolation by comparing predictions from small pilot runs against full training results on benchmark datasets
2. Test Wasserstein distance approximation accuracy in distributed settings by comparing centralized vs. distributed computation results
3. Evaluate privacy guarantees by attempting to reconstruct raw data distributions from the Wasserstein distance computations

## Open Questions the Paper Calls Out
None

## Limitations
- Effectiveness depends heavily on quality and representativeness of small pilot runs used for scaling law extrapolation
- Distributed Wasserstein distance approximation may introduce approximation errors affecting prediction accuracy
- Computational overhead could become significant as the number of data sources increases

## Confidence

**High Confidence**: The core methodology for privacy-preserving Wasserstein distance approximation and its theoretical foundation

**Medium Confidence**: The empirical correlation results (0.88) across the tested scenarios, given the limited scope of evaluated datasets

**Medium Confidence**: The generalizability of neural scaling law extrapolation to diverse federated learning environments

## Next Checks

1. **Cross-Dataset Validation**: Test the estimator on additional diverse datasets beyond the current evaluation set to verify robustness across different data modalities and distributions

2. **Scalability Analysis**: Evaluate the computational efficiency and prediction accuracy as the number of data sources scales to hundreds or thousands of participants

3. **Privacy-Fidelity Trade-off**: Systematically measure the impact of varying levels of privacy-preserving approximations on prediction accuracy to establish clear performance bounds