---
ver: rpa2
title: Evidence-Driven Marker Extraction for Social Media Suicide Risk Detection
arxiv_id: '2502.18823'
source_url: https://arxiv.org/abs/2502.18823
tags:
- risk
- cation
- marker
- suicide
- clinical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Evidence-Driven LLM (ED-LLM), a multi-task
  learning approach for suicide risk detection from social media text that simultaneously
  classifies risk levels and extracts clinical marker spans to improve interpretability.
  The method fine-tunes a Mistral-7B model with a combined loss function to optimize
  both clinical marker span identification and suicide risk classification.
---

# Evidence-Driven Marker Extraction for Social Media Suicide Risk Detection

## Quick Facts
- arXiv ID: 2502.18823
- Source URL: https://arxiv.org/abs/2502.18823
- Authors: Carter Adams; Caleb Carter; Jackson Simmons
- Reference count: 28
- Primary result: ED-LLM achieves competitive suicide risk classification (accuracy 0.72) while significantly outperforming baselines in clinical marker span extraction (F1-score 0.76 vs 0.51 for Mistral-7B-CLS)

## Executive Summary
This paper introduces Evidence-Driven LLM (ED-LLM), a multi-task learning approach for suicide risk detection from social media text that simultaneously classifies risk levels and extracts clinical marker spans to improve interpretability. The method fine-tunes a Mistral-7B model with a combined loss function to optimize both clinical marker span identification and suicide risk classification. Evaluated on CLPsych datasets, ED-LLM achieves competitive risk classification performance while significantly outperforming baselines in clinical marker span extraction, demonstrating the effectiveness of multi-task learning for clinically relevant suicide risk assessment applications.

## Method Summary
ED-LLM employs multi-task learning to jointly train a Mistral-7B model for two objectives: identifying clinical marker spans using BIO tagging and classifying suicide risk levels into four categories. The model uses a shared encoder with two specialized heads - one for token-level BIO classification and another for document-level risk classification. A combined loss function balances both tasks through a weighting parameter λ. The approach is evaluated on CLPsych 2019 and 2024 datasets using 5-fold cross-validation, with fine-tuning performed on NVIDIA A100 GPUs using PyTorch and the Transformers library.

## Key Results
- ED-LLM achieves competitive risk classification performance (accuracy 0.72, Macro F1 0.68, AUC-ROC 0.85)
- Clinical marker span extraction F1-score of 0.76 significantly outperforms baseline Mistral-7B-CLS (F1 0.51)
- Computational efficiency: 0.15s inference time, 1.8GB memory requirement
- Error analysis reveals false negatives often occur with subtle or implicit markers requiring cross-sentence reasoning

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Joint training for span extraction and classification improves both tasks compared to training either task alone.
- **Mechanism:** The shared encoder learns representations that must simultaneously support fine-grained token-level decisions (which words are markers) and document-level decisions (overall risk level). This creates a regularization pressure where the model cannot rely on spurious correlations that don't manifest as identifiable clinical markers.
- **Core assumption:** Clinical markers identified at the token level are causally relevant to overall risk assessment—i.e., the relationship between markers and risk is not incidental.
- **Evidence anchors:**
  - [abstract] "multi-task learning framework, jointly training a Mistral-7B based model to identify clinical marker spans and classify suicide risk levels"
  - [Table III ablation] ED-LLM achieves span F1 0.76 vs Mistral-7B-CLS 0.51, while maintaining comparable classification performance (0.72 vs 0.71 accuracy)
  - [corpus] Limited direct validation; neighbor papers focus on risk prediction but not multi-task extraction mechanisms
- **Break condition:** If span annotations are noisy or markers lack clinical validity, joint training may reinforce incorrect patterns rather than improve representations.

### Mechanism 2
- **Claim:** BIO tagging provides sufficient inductive bias for accurate span boundary detection in clinical marker extraction.
- **Mechanism:** The BIO scheme (Beginning-Inside-Outside) explicitly models span boundaries as a sequence labeling task. Each token receives a tag, forcing the model to learn transition constraints (e.g., I cannot follow O without an intervening B). This structure regularizes predictions toward coherent spans.
- **Core assumption:** Clinical markers form contiguous text spans that can be captured by sequential token labeling without requiring global context beyond what the LLM encoder provides.
- **Evidence anchors:**
  - [Section III.D.1] "We train the model to predict BIO tags for each token, delineating marker span boundaries"
  - [Table I] ED-LLM achieves precision 0.78, recall 0.75, F1 0.76 on span identification
  - [corpus] No direct corpus validation of BIO vs. alternative span extraction approaches
- **Break condition:** If markers are discontinuous, nested, or require cross-sentence reasoning, BIO tagging will systematically miss or fragment relevant evidence.

### Mechanism 3
- **Claim:** Combined loss weighting allows task-specific optimization while maintaining shared representation quality.
- **Mechanism:** The loss L_total = λL_span + (1-λ)L_cls balances gradient signals from both tasks. When λ is appropriately tuned, neither task dominates training, allowing the shared encoder to develop representations useful for both objectives without catastrophic interference.
- **Core assumption:** An optimal λ exists that balances both tasks; gradient directions from span and classification losses are not fundamentally conflicting.
- **Evidence anchors:**
  - [Section III.C] "λ ∈ [0, 1] balances task importance, tuned via hyper-parameter optimization"
  - [Section IV.C] "Hyperparameters, including learning rates, batch sizes, and the multi-task learning weight λ, are optimized via grid search"
  - [corpus] No corpus evidence on loss balancing strategies for clinical NLP multi-task learning
- **Break condition:** If span extraction and classification require fundamentally incompatible representations, no λ will yield strong performance on both tasks simultaneously.

## Foundational Learning

- **Concept: BIO Tagging Scheme (Beginning-Inside-Outside)**
  - **Why needed here:** The paper frames marker extraction as sequence labeling. Understanding BIO is essential to interpret model outputs and debug span boundary errors.
  - **Quick check question:** Given tags [B, I, I, O, O, B, I], how many spans are extracted and what are their token indices?

- **Concept: Multi-Task Learning with Shared Representations**
  - **Why needed here:** ED-LLM's core innovation is joint training. You need to understand how shared encoders work and why task synergy (or interference) occurs.
  - **Quick check question:** If one task has much higher loss magnitude than another, what happens to gradient updates without proper weighting?

- **Concept: Token-Level vs. Document-Level Classification Heads**
  - **Why needed here:** The architecture uses different head types for different tasks. Understanding when to apply each is critical for debugging and extension.
  - **Quick check question:** For span extraction, should the output layer operate per-token or per-document? Why?

## Architecture Onboarding

- **Component map:**
  - Input: Tokenized social media post → Mistral-7B encoder (shared layers)
  - Head 1 (Span): Encoder hidden states → Token-wise classifier → BIO tags → Decoded spans
  - Head 2 (Classification): [CLS] pooled representation → Softmax classifier → Risk level (a/b/c/d)
  - Loss Combiner: L_span + weighted L_cls → Backprop through shared encoder

- **Critical path:**
  1. Tokenization must preserve alignment with original text for span extraction evaluation
  2. BIO decoding logic must correctly convert tag sequences to span boundaries
  3. λ hyperparameter tuning determines whether the model prioritizes extraction vs. classification

- **Design tradeoffs:**
  - **Span granularity vs. noise sensitivity:** BIO tagging forces local decisions; may over-segment or miss implicit markers requiring inference
  - **Computational efficiency vs. interpretability:** ED-LLM requires full fine-tuning (0.15s inference, 1.8GB memory) vs. quantized CoT prompting (0.08s, 0.9GB) but provides explicit evidence spans
  - **Classification accuracy vs. explainability:** Multi-task learning maintains competitive classification (0.72 accuracy) while adding interpretability layer

- **Failure signatures:**
  - **Fragmented spans:** Model predicts isolated B tags without I tags—indicates insufficient training data or poor BIO transition learning
  - **Over-extraction:** High recall but low precision—λ too high, model flags all negative emotion as markers
  - **Under-extraction:** High precision but low recall—λ too low or training data has sparse annotations
  - **Classification degradation:** If adding span task hurts classification, task objectives may conflict

- **First 3 experiments:**
  1. **Baseline parity check:** Train Mistral-7B-CLS (classification-only) on same data. Confirm reported gap (F1 0.51 → 0.76 for spans) reproduces.
  2. **λ sensitivity sweep:** Vary λ from 0.1 to 0.9 in 0.1 increments. Plot span F1 vs. classification accuracy to identify Pareto frontier.
  3. **Error analysis on false negatives:** Extract cases where model misses ground-truth markers. Check if failures cluster around implicit markers (e.g., "quietly planning my escape" from Table IV) vs. explicit statements.

## Open Questions the Paper Calls Out

- **Question:** How can LLM prompting strategies be refined to mitigate hallucinations in clinical marker extraction while maintaining extraction accuracy?
  - **Basis in paper:** [explicit] The conclusion states: "Future work will focus on refining the LLM prompting strategies to further mitigate potential hallucinations and enhance the robustness of marker extraction."
  - **Why unresolved:** The current ED-LLM approach uses multi-task fine-tuning rather than prompting, and the quantized baseline (LLM-Q4-CoT) shows lower F1-scores (0.63 vs 0.76), suggesting prompting-based extraction is less reliable.
  - **What evidence would resolve it:** Comparative experiments showing prompting strategies that achieve comparable or superior F1-scores to ED-LLM (≥0.76) while reducing hallucinated marker spans, measured through human evaluation.

- **Question:** Can multimodal data integration improve model generalization across diverse platforms and demographic groups?
  - **Basis in paper:** [explicit] "Exploring the integration of multi-modal data, such as user behavior patterns and visual cues, represents another promising direction to improve model generalization and contextual understanding."
  - **Why unresolved:** ED-LLM is evaluated only on Reddit r/SuicideWatch posts; the paper acknowledges that "models trained on specific datasets may not generalize well to different social media platforms or demographic groups."
  - **What evidence would resolve it:** Cross-platform evaluation (e.g., Twitter, Instagram) and demographic-stratified performance analysis showing whether multimodal features reduce performance gaps across populations.

- **Question:** How can models be improved to detect subtle or implicit suicidal intent markers that are currently missed?
  - **Basis in paper:** [inferred] Table IV shows a false negative where the model misses "quietly planning my escape" — a subtle but critical marker. The error analysis notes "false negatives can occur when subtle or implicit markers are missed."
  - **Why unresolved:** The current BIO tagging approach relies on explicit span annotations; implicit markers may lack clear textual boundaries or require contextual reasoning beyond surface patterns.
  - **What evidence would resolve it:** Evaluation on a dataset annotated specifically for implicit markers, with demonstrated improvements in recall for implicit risk indicators without increasing false positives.

## Limitations

- **Dataset coverage and clinical validity:** The model is evaluated exclusively on Reddit data from CLPsych shared tasks, which may not generalize to other social media platforms or clinical populations.
- **BIO tagging assumptions:** The BIO scheme assumes markers are contiguous spans, but clinical markers in suicide risk often involve implicit or context-dependent indicators.
- **Clinical marker quality:** The paper assumes expert-annotated spans represent ground truth markers, but doesn't validate inter-annotator agreement or whether these annotations capture all clinically relevant indicators.

## Confidence

**High confidence:**
- The multi-task learning architecture (shared encoder with two heads) is clearly specified and reproducible
- The competitive classification performance (accuracy 0.72, Macro F1 0.68) on CLPsych 2019 is well-documented through 5-fold cross-validation
- The span extraction F1 improvement over baselines (0.76 vs 0.51) is clearly demonstrated on the CLPsych 2024 evaluation set

**Medium confidence:**
- The computational efficiency claims (0.15s inference, 1.8GB memory) are specific but only compared to one quantized baseline
- The interpretability value of extracted spans is assumed but not empirically validated through clinician studies or user evaluations
- The mechanism by which joint training improves both tasks is theoretically plausible but not empirically proven

**Low confidence:**
- Real-world clinical utility and generalizability to populations beyond Reddit users
- The assumption that BIO tagging captures all clinically meaningful markers
- The stability of performance across different λ values and whether improvements persist with larger or different datasets

## Next Checks

1. **External platform validation:** Test ED-LLM on suicide risk data from Twitter/X, Facebook, or clinical crisis intervention transcripts. Compare performance degradation to classification-only baselines to assess platform generalizability.

2. **Implicit marker analysis:** Conduct systematic error analysis on false negatives, specifically identifying cases where markers require inference (e.g., "quietly planning my escape") versus explicit statements. Measure the proportion of clinically relevant markers that are implicit and evaluate BIO tagging's ability to capture them.

3. **Annotation reliability study:** Compute inter-annotator agreement on a subset of CLPsych 2024 data. Compare model predictions to multiple expert annotations to determine whether span F1 reflects model performance or annotation inconsistencies.