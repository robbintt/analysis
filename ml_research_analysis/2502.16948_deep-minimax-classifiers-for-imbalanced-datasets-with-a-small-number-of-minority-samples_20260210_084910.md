---
ver: rpa2
title: Deep Minimax Classifiers for Imbalanced Datasets with a Small Number of Minority
  Samples
arxiv_id: '2502.16948'
source_url: https://arxiv.org/abs/2502.16948
tags:
- class
- loss
- prior
- worst
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a minimax learning algorithm for imbalanced
  datasets with limited minority samples. The core idea involves a targeted logit
  adjustment (TLA) loss function for model training and a linear ascent method for
  updating the target prior.
---

# Deep Minimax Classifiers for Imbalanced Datasets with a Small Number of Minority Samples

## Quick Facts
- **arXiv ID:** 2502.16948
- **Source URL:** https://arxiv.org/abs/2502.16948
- **Reference count:** 40
- **Primary result:** Achieves superior or comparable worst-class accuracy compared to existing methods on CIFAR10/100 with step and long-tailed imbalances.

## Executive Summary
This paper addresses the challenge of training deep classifiers on imbalanced datasets with very few minority samples. The proposed solution combines a targeted logit adjustment (TLA) loss function with a linear ascent method for updating the target prior. The algorithm alternates between minimizing the TLA loss to train the model and maximizing the prior to focus on worst-performing classes. Experiments on CIFAR10 and CIFAR100 demonstrate significant improvements in worst-class accuracy, particularly when minority class samples are scarce.

## Method Summary
The method uses a three-phase training approach with targeted logit adjustment (TLA) loss and linear ascent for prior updates. The TLA loss shifts decision boundaries by adding logit bias terms proportional to the gap between training and target priors. Linear ascent updates the target prior by moving it linearly toward the worst-performing classes identified on a held-out validation set. The training data is partitioned into 80% for model training and 20% for prior updates to prevent the zero-error problem in overparameterized networks.

## Key Results
- On CIFAR10 with step imbalance ratio 0.01, achieves worst-class accuracy of 51.52%, significantly higher than baseline methods
- TLA improves cat class accuracy from 22.4% to 65.0% while improving feature clustering (inter-intra distance ratio +58.94%)
- Linear ascent achieves highest worst-class prior values across most settings (e.g., 16.16% vs. 1.46% for EGA on CIFAR10-LT ρ=0.01)

## Why This Works (Mechanism)

### Mechanism 1: Targeted Logit Adjustment (TLA) Loss
TLA modifies cross-entropy by adding logit bias terms ℓ_y(π_t) = τ(log π_train^y - log π_t^y) to neural network outputs before softmax. This shifts decision boundaries proportionally to the gap between training and target priors, directly affecting per-class decision boundaries without damaging feature extraction quality.

### Mechanism 2: Linear Ascent for Prior Update
Linear ascent updates the target prior more robustly than exponential gradient ascent when minority samples are few. Instead of exponential updates, it computes π_{t+1} ← π_t + α(π_{t,max,M} - π_t), where π_{t,max,M} is a normalized binary vector indicating the M worst-performing classes. This linear shift avoids exponential amplification of estimation errors.

### Mechanism 3: Data Partitioning for Zero-Error Problem
Partitioning training data into D_model (80%) and D_prior (20%) prevents the zero-error problem where training error approaches zero in overparameterized networks, making error estimation unreliable. By holding out D_prior for prior updates, error estimates remain meaningful for worst-class identification.

## Foundational Learning

- **Concept: Minimax Classification (Statistical Decision Theory)**
  - **Why needed:** The paper's core objective R* = min_θ max_π R(π, θ) minimizes worst-case risk over all possible test priors. Without minimax principles, the alternating optimization rationale is opaque.
  - **Quick check:** If you have a classifier with per-class accuracies [95%, 70%, 60%] and test priors could be any distribution over 3 classes, what is the minimax risk?

- **Concept: Prior Shift and Class-Conditional Risk**
  - **Why needed:** The paper decomposes total risk as R(π, θ) = Σ_y π_y P_y,θ^(e), where π_y is the class prior and P_y,θ^(e) is class-conditional error. The minimax solution finds π* that maximizes this weighted sum.
  - **Quick check:** Given class-conditional errors [0.1, 0.3, 0.5] for classes 1, 2, 3, which prior maximizes total risk? Which minimizes worst-class risk?

- **Concept: Logit Adjustment vs. Weight Adjustment in CE Loss**
  - **Why needed:** TLA is contrasted with weighted CE. Weight adjustment multiplies the loss term, while logit adjustment adds to logits directly shifting softmax probabilities and decision boundaries.
  - **Quick check:** For a 3-class problem with logits [2, 1, 0], what happens to softmax outputs when you add logit adjustment [0.5, 0, -0.5]? What happens when you apply weights [1.5, 1.0, 0.5]?

## Architecture Onboarding

- **Component map:** Input data → Warmup phase (5 epochs, fixed prior) → Minimax training (295 epochs, alternating TLA loss minimization and linear ascent prior updates) → Fine-tuning phase (30 epochs, merged datasets)

- **Critical path:** The alternating optimization between TLA loss minimization (updates θ via SGD) and linear ascent maximization (updates π). Convergence requires that linear ascent correctly identifies worst classes, which depends on D_prior having sufficient minority samples.

- **Design tradeoffs:**
  - **M (worst classes count):** Smaller M → tighter convergence bound but slower; larger M → faster convergence but riskier. Paper uses M=3 for CIFAR10-LT, M=1 for step-imbalance.
  - **τ (logit adjustment scale):** Controls boundary shift strength. Paper uses τ=2.25 for CIFAR10-LT, τ=0.875-1.375 for CIFAR100.
  - **α (ascent step size):** Paper uses α=0.01 for linear ascent vs. α=0.1 for EGA baseline.

- **Failure signatures:**
  - **EGA oscillation:** When minority samples are few (N<16 per class), EGA prior values remain low (<2%) and worst-class accuracy degrades.
  - **TWCE feature damage:** t-SNE shows overlapping features for worst classes (cat/dog overlap in Figure 2).
  - **Prior collapse:** If M is too large relative to class count K, π_t fails to concentrate on true worst class.

- **First 3 experiments:**
  1. **Ablation on CIFAR10 step-imbalanced (ρ=0.01):** Compare [TWCE+EGA], [TLA+EGA], [TWCE+linear ascent], [TLA+linear ascent] to isolate each component's contribution. Key metric: worst-class accuracy (baseline ~27%, target >50%).
  2. **Sensitivity analysis on M:** Run linear ascent with M∈{1, 3, 5, 10} on CIFAR10-LT (ρ=0.01). Plot worst-class accuracy vs. convergence iterations. Expect M=3 optimal balance.
  3. **Feature quality validation:** Train TLA and TWCE on CIFAR10-step (ρ=0.01), extract penultimate layer features, compute inter-intra distance ratios for worst classes. Target: TLA shows >50% improvement over TWCE.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the selection of the hyperparameter M (the number of worst classes used in linear ascent) be automated or adaptively adjusted during training?
- **Basis:** The paper manually sets different values of M (3, 1, or 10) for different datasets and imbalance types, noting that M should be chosen to match the size of the group with error probabilities similar to the worst class.
- **Why unresolved:** While Theorem 6 suggests M=1 is theoretically optimal for the bound, the authors note it requires many iterations; conversely, larger M speeds convergence but loosens the bound. There is currently no mechanism to dynamically balance this trade-off during training without manual tuning.
- **What evidence would resolve it:** Development and experimental validation of an adaptive M selection strategy that adjusts based on the variance or distribution of class-wise errors during the training process.

### Open Question 2
- **Question:** Is the partitioning of the training dataset into separate subsets for minimization (D_model) and maximization (D_prior) strictly necessary, or can the zero-error problem be addressed via regularization?
- **Basis:** Section III-C states that the authors partition the training data to address the zero-error problem in overparameterized networks, but this effectively reduces the number of samples available for model training.
- **Why unresolved:** The partitioning strategy is a practical engineering choice to ensure reliable 0-1 loss estimation, but it may discard valuable training data. It is unclear if the same robustness could be achieved using the full dataset with different regularization techniques or loss formulations.
- **What evidence would resolve it:** Ablation studies comparing the current split method against using the full training dataset for both steps while employing regularization to prevent training loss from reaching zero.

### Open Question 3
- **Question:** Does the proposed TLA loss and linear ascent algorithm generalize to modern architectures such as Vision Transformers (ViT) or large-scale datasets beyond CIFAR?
- **Basis:** The experimental results are restricted to ResNet32 on CIFAR-10 and CIFAR-100.
- **Why unresolved:** The theoretical benefits of TLA regarding feature quality and decision boundary adjustment are demonstrated on convolutional features. It remains unverified whether the linear ascent method's robustness with small samples holds in the distinct optimization landscape and feature space of Transformers or high-resolution imagery.
- **What evidence would resolve it:** Experimental results applying the proposed minimax algorithm to large-scale benchmarks (e.g., ImageNet-LT or iNaturalist) using architectures like ViT or CNNs with attention mechanisms.

## Limitations

- **Major Uncertainties:** The paper's theoretical analysis relies heavily on idealized assumptions about neural network training. The empirical robustness of linear ascent depends critically on the 80/20 data split ratio and the number of samples in D_prior.
- **Confidence Labels:** High confidence in TLA mechanism (well-supported by theory and evidence), medium confidence in linear ascent (theoretically justified but empirically dependent on conditions), low confidence in convergence guarantees (assume perfect worst-class identification).
- **Next Validation Checks:**
  1. **Ablation on Data Partitioning:** Run experiments with different D_model:D_prior splits (e.g., 90/10, 70/30) on CIFAR10-LT to quantify the impact of the zero-error problem.
  2. **Sensitivity to M:** Systematically vary M (1, 3, 5, 10) on CIFAR100-LT and plot worst-class accuracy vs. convergence iterations to identify optimal settings.
  3. **Feature Quality Comparison:** Extract penultimate layer features from TLA and TWCE models on CIFAR10-step and compute inter-intra distance ratios for all classes, not just worst classes, to assess overall feature quality impact.