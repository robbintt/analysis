---
ver: rpa2
title: Communication Methods in Multi-Agent Reinforcement Learning
arxiv_id: '2601.12886'
source_url: https://arxiv.org/abs/2601.12886
tags:
- communication
- agents
- learning
- multi-agent
- reinforcement
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper provides a comprehensive survey of communication methods\
  \ in multi-agent reinforcement learning (MARL), categorizing them into explicit,\
  \ implicit, attention-based, graph-based, and hierarchical/role-based approaches.\
  \ It systematically compares their strengths and weaknesses, highlighting that no\
  \ single communication framework is universally optimal\u2014selection depends heavily\
  \ on the problem's structure, scale, and constraints."
---

# Communication Methods in Multi-Agent Reinforcement Learning

## Quick Facts
- arXiv ID: 2601.12886
- Source URL: https://arxiv.org/abs/2601.12886
- Authors: Christoph Wittner
- Reference count: 23
- One-line primary result: Comprehensive survey categorizing MARL communication methods into explicit, implicit, attention-based, graph-based, and hierarchical approaches, highlighting no single framework is universally optimal.

## Executive Summary
This paper provides a comprehensive survey of communication methods in multi-agent reinforcement learning (MARL), systematically categorizing them into five main approaches: explicit, implicit, attention-based, graph-based, and hierarchical/role-based frameworks. The survey identifies that communication method selection depends heavily on problem structure, scale, and constraints, with no single approach being universally optimal. The analysis reveals critical research gaps, particularly the need for standardized benchmarking of system-level metrics like communication overhead and scalability, as well as improved robustness under realistic conditions such as delays and noise.

## Method Summary
The paper synthesizes existing literature through systematic classification of MARL communication methods. It evaluates each approach based on information flow patterns, computational requirements, and coordination effectiveness. The survey analyzes trade-offs between global information access and computational efficiency, comparing fully connected message passing against sparse graph-based topologies. The methodology relies on qualitative synthesis of published works rather than novel empirical experiments, focusing on identifying patterns and gaps across the MARL communication literature.

## Key Results
- No single communication framework is universally optimal; selection depends on problem structure, scale, and constraints
- Fully connected message passing ensures global information flow but suffers from computational overhead and scalability issues
- Critical research gaps identified include need for standardized benchmarking and improved robustness under realistic constraints like delays and noise

## Why This Works (Mechanism)
The survey's effectiveness stems from its systematic categorization framework that captures the fundamental trade-offs in MARL communication design. By organizing methods along clear dimensions—information flow topology, computational complexity, and coordination mechanisms—it reveals why different approaches excel in different scenarios. The analysis demonstrates that communication effectiveness depends on matching the method's characteristics to the problem's structural requirements, explaining why approaches like attention-based methods work well for selective coordination while graph-based methods excel in large-scale sparse interactions.

## Foundational Learning
1. **Information Flow Topology**: Understanding how messages propagate through agent networks (fully connected vs. sparse graphs) is crucial because it determines both coordination quality and computational scalability. Quick check: Can you map your problem's communication requirements to the appropriate topology type?

2. **Computational Complexity Trade-offs**: The relationship between message passing frequency, agent count, and processing overhead determines real-world feasibility. Quick check: Have you measured your method's complexity scaling with agent count?

3. **Coordination vs. Autonomy Balance**: Different methods offer varying degrees of centralized coordination versus decentralized decision-making, affecting both performance and robustness. Quick check: Does your application require tight coordination or agent independence?

4. **Scalability Constraints**: Communication methods must handle increasing agent counts without prohibitive overhead, making sparse topologies essential for large-scale systems. Quick check: What is your method's communication complexity as agent count grows?

5. **Robustness Requirements**: Real-world MARL systems need to handle communication delays, noise, and bandwidth limitations that idealized simulations often ignore. Quick check: Have you tested your communication method under realistic network conditions?

## Architecture Onboarding

**Component Map**: Environment -> Agents (with Communication Modules) -> Message Passing Layer -> Coordination Mechanism -> Action Selection

**Critical Path**: State observation → Communication message generation → Message filtering/processing → Coordination decision → Action execution

**Design Tradeoffs**: Global information access vs. computational efficiency, tight coordination vs. decentralized autonomy, message overhead vs. coordination quality, scalability vs. coordination granularity

**Failure Signatures**: Communication bottlenecks under high agent density, coordination breakdown with message loss, performance degradation with increased delays, scalability collapse with fully connected topologies

**3 First Experiments**:
1. Compare communication overhead and task performance across all five method categories on a standard MARL benchmark
2. Test robustness by introducing variable message delays and noise into the communication channels
3. Measure scalability by evaluating performance as agent count increases from 2 to 100+ agents

## Open Questions the Paper Calls Out
The paper identifies several critical research gaps requiring attention. There is a pressing need for standardized benchmarking protocols that evaluate both task-specific performance and system-level metrics like communication overhead and scalability. The robustness of communication methods under realistic conditions—including variable delays, noise, and bandwidth limitations—remains largely unexplored. Additionally, the survey calls for improved methodologies to quantify the trade-offs between coordination quality and computational efficiency across different problem domains and scales.

## Limitations
- Relies on qualitative synthesis rather than systematic empirical benchmarking across standardized tasks
- Computational overhead and scalability claims are largely theoretical without extensive empirical validation
- Discussion of robustness under realistic constraints remains conceptual without experimental validation
- Comparative performance claims lack quantitative metrics to support qualitative assertions

## Confidence

**Classification framework**: High
**Comparative trade-off analysis**: Medium
**Scalability claims**: Medium
**Robustness discussion**: Low

## Next Checks

1. Conduct systematic experiments comparing all five communication method categories on standardized MARL benchmarks, measuring both task performance and communication efficiency metrics.

2. Implement and test the proposed communication methods under realistic constraints (variable delays, noise, bandwidth limitations) to validate robustness claims.

3. Develop a standardized evaluation protocol that includes both task-specific and system-level metrics to enable fair comparison across different communication frameworks.