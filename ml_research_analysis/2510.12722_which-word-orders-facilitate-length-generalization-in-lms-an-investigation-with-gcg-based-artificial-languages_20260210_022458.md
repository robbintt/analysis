---
ver: rpa2
title: Which Word Orders Facilitate Length Generalization in LMs? An Investigation
  with GCG-Based Artificial Languages
arxiv_id: '2510.12722'
source_url: https://arxiv.org/abs/2510.12722
tags:
- word
- order
- language
- npsubj
- languages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates which word orders facilitate length generalization
  in language models (LMs) using Generalized Categorial Grammar (GCG)-based artificial
  languages. The study extends prior work by adopting GCG to include more natural
  language constructions like unbounded dependencies and evaluating LMs' ability to
  generalize to longer sentences beyond training length.
---

# Which Word Orders Facilitate Length Generalization in LMs? An Investigation with GCG-Based Artificial Languages

## Quick Facts
- **arXiv ID**: 2510.12722
- **Source URL**: https://arxiv.org/abs/2510.12722
- **Reference count**: 35
- **Primary result**: Typologically plausible word orders (e.g., SOV, SVO) facilitate length generalization in language models, with RNNs showing strongest alignment with typological distributions across generalization tasks.

## Executive Summary
This paper investigates which word orders facilitate length generalization in language models using Generalized Categorial Grammar (GCG)-based artificial languages. The study extends prior work by incorporating more natural language constructions like unbounded dependencies and evaluating models' ability to generalize to longer sentences beyond training length. The primary finding is that typologically plausible word orders are easier for LMs to generalize to longer sentences, particularly for recurrent architectures like LSTM and RNN. RNNs showed the strongest alignment with typological distributions across generalization tasks, suggesting that working memory constraints shape typologically frequent word orders in natural language.

## Method Summary
The study used GCG to generate 96 artificial languages with varying word order parameters, training three model architectures (RNN, LSTM, Transformer) on sentences of 3-8 words and testing on both in-domain (SHORT/MEDIUM) and out-of-domain (LONG, 11-20 words) datasets. Models were trained using Fairseq with AdamW optimizer, inverse_sqrt scheduler, and early stopping. The key metric was Perplexity (PPL) on test sets, with Typological Alignment (TA) measured as Pearson correlation between PPL and WALS/Grambank word order frequencies. Grammaticality judgment accuracy was also evaluated as an additional metric.

## Key Results
- Typologically plausible word orders (e.g., SOV, SVO) are easier for LMs to generalize to longer sentences
- RNNs showed the strongest alignment with typological distributions across generalization tasks
- Transformers performed well on in-domain evaluation but less so on out-of-domain generalization
- Results are phenomenon-dependent, with significant correlation for embedded clauses but not for recursive ones

## Why This Works (Mechanism)
None

## Foundational Learning
- **Generalized Categorial Grammar (GCG)**: Extends categorial grammar with type-raising and composition operations, allowing flexible word order generation. Needed to create artificial languages with typologically plausible structures. Quick check: Verify GCG parser correctly handles all 96 language configurations.
- **Typological databases (WALS/Grambank)**: Provide empirical frequency distributions of word orders across natural languages. Needed to establish ground truth for typological plausibility. Quick check: Confirm correlation calculations use correct WALS feature codes.
- **Length generalization**: Models' ability to process sentences longer than those seen during training. Needed to evaluate inductive biases toward certain word orders. Quick check: Verify LONG test set contains only sentences longer than training maximum.

## Architecture Onboarding

**Component map**: GCG generator -> AL corpus -> LM training -> PPL evaluation -> TA correlation

**Critical path**: AL generation → Model training → PPL computation → Typological alignment analysis

**Design tradeoffs**: The study balances between artificial language simplicity (enabling controlled experiments) and natural language complexity (capturing realistic linguistic phenomena). Tradeoff between parameter count (Transformer larger) and generalization performance (RNNs better).

**Failure signatures**: PPL variance too small on SHORT test set (flat distribution reported); Invalid LONG templates due to improper augmentation; Incorrect TA calculation (wrong correlation sign or features).

**First experiments**: 1) Train RNN on SVO language and verify PPL decreases on SHORT test set. 2) Check Transformer PPL on LONG sentences exceeds SHORT. 3) Compute TA for LSTM and verify negative correlation with WALS frequencies.

## Open Questions the Paper Calls Out
- How do lexical ambiguity and subject-verb number agreement impact the inductive biases of LMs in GCG-based artificial languages? (The current study simplifies the lexicon by assigning each word to exactly one category and ignoring agreement rules, which removes complexities found in natural languages.)
- To what extent do different training methods influence the learning trajectory and generalization capabilities of LMs on these artificial languages? (The current experiments utilize a fixed set of hyperparameters and optimization strategies without ablation.)
- Why does typological plausibility facilitate generalization for embedded relative clauses but not for recursive relative clauses? (Section 6 notes that results are "phenomenon-dependent," observing a significant correlation for embedded clauses but not for recursive ones.)

## Limitations
- The study uses artificial languages rather than natural language data, which may not fully capture real-world linguistic complexity
- Results rely on perplexity as the primary metric, which may not capture all aspects of language model performance
- The comparison between model architectures is limited by their different parameter sizes and configurations

## Confidence
- **High confidence**: The experimental methodology is sound and the results regarding relative performance across architectures on the artificial language task are likely reliable
- **Medium confidence**: The conclusions about typological alignment and its relationship to working memory constraints, while plausible, require validation on more diverse language samples
- **Low confidence**: The claim that typologically frequent word orders emerge primarily due to working memory constraints, based solely on artificial language experiments

## Next Checks
1. Validate the findings on additional artificial language configurations with different parameter combinations to test robustness
2. Test the same models on natural language datasets with varying word orders to assess whether artificial language results generalize
3. Conduct ablation studies on the filtering heuristics to quantify their impact on the observed typological alignment patterns