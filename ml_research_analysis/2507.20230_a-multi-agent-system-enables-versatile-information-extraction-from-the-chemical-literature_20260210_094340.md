---
ver: rpa2
title: A Multi-Agent System Enables Versatile Information Extraction from the Chemical
  Literature
arxiv_id: '2507.20230'
source_url: https://arxiv.org/abs/2507.20230
tags:
- reaction
- chemical
- agent
- extraction
- chemeagle
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents ChemEAGLE, a multi-agent system for extracting
  chemical reaction information from complex, multimodal graphics in scientific literature.
  It decomposes the extraction task into sub-tasks handled by specialized agents,
  each combining an MLLM with domain-specific tools, and integrates results into structured
  datasets.
---

# A Multi-Agent System Enables Versatile Information Extraction from the Chemical Literature

## Quick Facts
- arXiv ID: 2507.20230
- Source URL: https://arxiv.org/abs/2507.20230
- Reference count: 40
- ChemEAGLE achieves 80.8% F1 score on reaction extraction, outperforming state-of-the-art (35.6%) and general MLLMs (<10%)

## Executive Summary
This paper introduces ChemEAGLE, a multi-agent system designed to extract chemical reaction information from complex multimodal graphics in scientific literature. The system decomposes the extraction task into specialized sub-tasks handled by different agents, each combining a multimodal large language model (MLLM) with domain-specific tools. By integrating results through collaborative agent interactions, ChemEAGLE achieves state-of-the-art performance on a new benchmark of 200 reaction graphics containing 1,120 reactions, demonstrating the effectiveness of multi-agent architectures for chemical information extraction.

## Method Summary
ChemEAGLE employs a multi-agent architecture where each agent specializes in a specific aspect of chemical information extraction from scientific graphics. The system combines MLLMs with domain-specific tools to handle tasks including molecular structure recognition, reaction image parsing, named entity recognition, and text-based reaction extraction. Agents communicate and collaborate to decompose complex extraction tasks, with results integrated into structured datasets. The approach addresses the challenge of extracting structured chemical data from diverse graphical representations in scientific literature, leveraging both visual and textual information through specialized tool integration.

## Key Results
- Achieved 80.8% F1 score on reaction extraction under hard-match criteria, outperforming previous state-of-the-art (35.6%)
- Molecular recognition task: 96.9% valid SMILES rate
- Reaction image parsing: 75.2% valid SMILES rate
- Named entity recognition: 89.8% F1 score
- Text-based reaction extraction: 82.7% F1 score

## Why This Works (Mechanism)
ChemEAGLE's effectiveness stems from its decomposition of complex chemical information extraction into specialized sub-tasks handled by dedicated agents. Each agent combines an MLLM with domain-specific tools tailored to its task, allowing for focused processing of molecular structures, reaction parsing, and entity recognition. The multi-agent collaboration enables comprehensive coverage of multimodal information in chemical graphics, with agents sharing context and coordinating to resolve ambiguities. This modular approach allows the system to handle the diverse representations and notations found in chemical literature more effectively than monolithic approaches.

## Foundational Learning
- **SMILES notation**: Text-based molecular structure representation needed for standardized chemical data extraction
  - Why needed: Provides canonical format for chemical structures across different extraction tasks
  - Quick check: Can the system generate valid SMILES for common organic molecules

- **Multimodal Large Language Models (MLLMs)**: Foundation models that process both visual and textual information
  - Why needed: Enables understanding of chemical graphics that combine images and text
  - Quick check: Does the MLLM correctly interpret chemical structure images and associated labels

- **Chemical Named Entity Recognition**: Identification of chemical compounds, reactions, and properties in text
  - Why needed: Essential for extracting structured information from reaction descriptions
  - Quick check: Can the system accurately identify chemical entities in reaction text

- **Reaction parsing**: Conversion of chemical graphics into structured reaction representations
  - Why needed: Transforms visual reaction information into machine-readable formats
  - Quick check: Does the system correctly parse reactant-product relationships in reaction images

- **Agent collaboration protocols**: Communication mechanisms between specialized agents
  - Why needed: Enables coordinated handling of complex, multimodal extraction tasks
  - Quick check: Can agents effectively share context and resolve conflicts in extraction decisions

## Architecture Onboarding

**Component map**: MLLM Backbone -> Domain-specific Tools -> Specialized Agents -> Collaboration Layer -> Structured Output

**Critical path**: Chemical graphic input → MLLM processing → Agent specialization → Tool integration → Collaborative extraction → Structured dataset

**Design tradeoffs**: 
- Modularity vs. integration complexity: Multi-agent approach enables specialization but requires sophisticated coordination
- Tool specificity vs. generalization: Domain-specific tools improve accuracy but may limit adaptability to new notation styles
- Evaluation rigor vs. practical utility: Hard-match criteria ensure precision but may penalize minor, acceptable variations

**Failure signatures**: 
- Incorrect molecular recognition propagates through downstream tasks
- Agent communication failures lead to incomplete or inconsistent extractions
- Tool mismatches cause systematic errors in specific notation types

**First experiments**:
1. Validate molecular recognition accuracy on diverse chemical structure representations
2. Test agent collaboration by running sub-tasks independently and comparing integrated results
3. Evaluate performance degradation when using general vs. domain-specific tools

## Open Questions the Paper Calls Out
None

## Limitations
- Performance heavily depends on MLLM quality and tool accuracy, which weren't extensively tested across different implementations
- The 200-reaction benchmark may not capture full diversity of chemical graphics in literature
- Hard-match evaluation criteria may underestimate practical utility due to minor notation variations being marked incorrect

## Confidence

**High confidence**: Multi-agent architecture effectiveness, superior performance vs general MLLMs, successful task decomposition

**Medium confidence**: Scalability to diverse graphics, robustness across literature sources, general superiority over all previous approaches

**Low confidence**: Performance on complex multi-reaction graphics, handling all notation variations, long-term maintenance requirements

## Next Checks

1. Test ChemEAGLE on a larger, more diverse corpus of chemical graphics from multiple publishers to assess generalizability

2. Evaluate system robustness by introducing controlled variations in chemical notation and comparing extraction accuracy across different MLLM versions and tool implementations

3. Conduct user studies with chemistry researchers to assess practical utility, error tolerance, and integration with existing research workflows