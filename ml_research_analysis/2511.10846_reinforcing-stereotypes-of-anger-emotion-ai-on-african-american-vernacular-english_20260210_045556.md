---
ver: rpa2
title: 'Reinforcing Stereotypes of Anger: Emotion AI on African American Vernacular
  English'
arxiv_id: '2511.10846'
source_url: https://arxiv.org/abs/2511.10846
tags:
- emotion
- aave
- american
- anger
- african
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how emotion recognition models handle African
  American Vernacular English (AAVE) and finds significant bias. Models falsely predict
  anger and disgust in AAVE at rates more than double those in General American English
  (GAE), with SpanEmo's false positive rate on anger increasing from 25% on GAE to
  60% on AAVE.
---

# Reinforcing Stereotypes of Anger: Emotion AI on African American Vernacular English

## Quick Facts
- arXiv ID: 2511.10846
- Source URL: https://arxiv.org/abs/2511.10846
- Authors: Rebecca Dorn; Christina Chance; Casandra Rusti; Charles Bickham; Kai-Wei Chang; Fred Morstatter; Kristina Lerman
- Reference count: 40
- Models falsely predict anger and disgust in AAVE at rates more than double those in General American English

## Executive Summary
This paper reveals significant bias in emotion recognition models when processing African American Vernacular English (AAVE). Models over-predict anger and disgust in AAVE at rates more than double those on General American English, with profanity-based AAVE features driving false positives. The study analyzes 2.7 million geo-tagged tweets from Los Angeles using community-informed annotations from African American AAVE speakers. Results show systematic amplification of anger stereotypes in predominantly Black neighborhoods, highlighting the need for culturally-informed affective computing systems.

## Method Summary
The study evaluates 875 manually annotated tweets (stratified by Dialect Density Metric) using 12 annotators (3 ingroup AAVE speakers, 9 outgroup). Silver labels were created using ingroup-only annotations for high-DDM tweets. Seven emotion models were tested including NRC lexicon, SpanEmo, and GPT-4o-mini with three prompt schemas. DDM scores were computed using 12 AAVE features including regex patterns, POS tagging, and perplexity differences. Neighborhood-level analysis joined tweets to 2014 LA County Census tract demographics to examine demographic spurious correlations.

## Key Results
- SpanEmo's false positive rate on anger increases from 25% on GAE to 60% on AAVE
- Models agree more with outgroup than ingroup annotators on anger/disgust for high-DDM tweets
- Neighborhoods with higher African American populations show higher anger predictions (r = 0.27) and lower joy predictions (r = -0.10)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Emotion models over-predict anger on AAVE text at rates more than double those on GAE text.
- Mechanism: Profanity-based AAVE features correlate more strongly with model predictions and outgroup annotations than with ingroup annotations. Models trained on GAE-dominant data associate profanity with anger regardless of context.
- Core assumption: Ingroup annotations better reflect intended emotion than model predictions or outgroup labels.
- Evidence anchors: SpanEmo FPR rises from 25% to 60% on AAVE; models more correlated with profanity-based features than ingroup labels.

### Mechanism 2
- Claim: Demographic spurious correlations emerge at neighborhood scale.
- Mechanism: Models learn associations between linguistic features and geography/demographics, producing systematic anger over-prediction in predominantly Black neighborhoods.
- Core assumption: Neighborhood racial composition proxies dialect density.
- Evidence anchors: Anger predictions positively correlated with percent African American across multiple models.

### Mechanism 3
- Claim: Ingroup annotators detect more emotion overall and disagree with models on disgust in high-AAVE texts.
- Mechanism: Cultural insiders interpret AAVE affective cues differently than outgroup annotators and models. Outgroup annotators over-label disgust on AAVE texts.
- Core assumption: Ingroup annotations provide more valid ground truth for AAVE texts.
- Evidence anchors: Ingroup annotators identify more emotion except disgust; models align more with outgroup labels except for love.

## Foundational Learning

- **Dialect Density Metric (DDM)**
  - Why needed here: Quantifies AAVE strength per text using computational approximations of sociolinguistic features. All bias measurements are conditional on DDM thresholds.
  - Quick check question: If DDM is miscalibrated (e.g., over-flagging GAE slang as AAVE), how would that affect the reported false positive rates?

- **False Positive Rate (FPR) vs. False Negative Rate (FNR)**
  - Why needed here: FPR measures over-detection of anger/disgust in AAVE; FNR measures under-detection of joy. The paper reports FPR ratios (AAVE/GAE) > 2 for anger across high-performing models.
  - Quick check question: Why might reducing FPR on anger inadvertently increase FNR for other emotions?

- **Silver Labels from Ingroup Annotators**
  - Why needed here: The paper constructs "silver" labels using only ingroup annotators for high-DDM tweets, acknowledging that emotion perception is culturally mediated. This is the evaluation baseline for all model comparisons.
  - Quick check question: What are the limitations of using a small sample of ingroup annotators (N=3) as ground truth?

## Architecture Onboarding

- **Component map**: Data pipeline (5.8M tweets → 2.7M filtered) → DDM module (12 features → scalar DDM) → Annotation layer (875 tweets → silver labels) → Model zoo (NRC, SpanEmo, RoBERTaGo, GPT-4o-mini, Latimer, Deepseek-Qwen, Llama-3.1) → Evaluation module (FPR/FNR, Kappa, regression) → Demographic join (tweets → Census tracts → neighborhood correlations)

- **Critical path**: DDM scoring → stratified sampling → ingroup annotation → silver label creation → model inference → FPR/FNR computation → regression on DDM features → neighborhood-level correlation analysis

- **Design tradeoffs**: Silver labels acknowledge subjectivity but introduce noise from small annotator pools; DDM threshold (≥0.07 for "high") is arbitrary; Tweet age (2010-2014) may not reflect current AAVE usage

- **Failure signatures**: Models agree more with outgroup than ingroup annotators on anger/disgust; FPR for anger > 2x on AAVE across all high-performing models; neighborhood-level anger predictions correlate with Black population even after controlling for text content

- **First 3 experiments**:
  1. Profanity ablation: Mask profanity-based DDM features and re-run model inference; check if FPR for anger converges toward GAE baseline
  2. Ingroup fine-tuning: Fine-tune SpanEmo or GPT-4o-mini on silver-labeled tweets and measure FPR reduction on held-out AAVE texts
  3. Counterfactual demographic shuffle: Randomly permute neighborhood labels and re-compute demographic correlations; if correlations persist, the mechanism is linguistic rather than geographic

## Open Questions the Paper Calls Out
None

## Limitations
- Data accessibility constraints prevent exact replication due to unavailable 2.7M tweet dataset and 875 annotated tweets
- Silver label validity is questionable given the small sample size of ingroup annotators (N=3)
- Geographic-demographic proxy assumption may not hold as users may not tweet from residential neighborhoods

## Confidence

- **High confidence**: Models show higher false positive anger rates on AAVE texts (60% vs 25% for SpanEmo) - well-supported by systematic evaluation across multiple models
- **Medium confidence**: Demographic spurious correlation mechanism - while neighborhood-level correlations are observed, the causal pathway remains partially speculative
- **Low confidence**: Models systematically agree more with outgroup than ingroup annotators on most emotions - depends heavily on quality and representativeness of small ingroup annotation sample

## Next Checks

1. **Profanity ablation study**: Mask or remove the five profanity-based DDM features and re-run emotion model inference on the same tweet samples. If false positive anger rates converge toward GAE baseline values, this would confirm that profanity-driven spurious correlations drive the observed bias.

2. **Ingroup fine-tuning experiment**: Fine-tune a subset of the emotion models (SpanEmo or GPT-4o-mini) on the 875 silver-labeled tweets or a larger ingroup-annotated AAVE dataset. Measure whether FPR for anger on held-out AAVE texts decreases significantly, validating that cultural insiders can train more accurate models.

3. **Counterfactual demographic analysis**: Randomly permute neighborhood demographic labels across the tweet dataset and re-compute Pearson correlations between racial composition and emotion predictions. If correlations persist despite broken demographic-text linkage, the mechanism is linguistic (DDM-driven). If correlations disappear, the geographic proxy assumption is critical to the spurious correlation finding.