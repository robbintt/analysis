---
ver: rpa2
title: 'FedMOA: Federated GRPO for Personalized Reasoning LLMs under Heterogeneous
  Rewards'
arxiv_id: '2602.00453'
source_url: https://arxiv.org/abs/2602.00453
tags:
- reward
- federated
- grpo
- fedmoa
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes FedMOA, a federated GRPO algorithm for multi-objective
  alignment under heterogeneous rewards. FedMOA addresses the challenges of heterogeneous
  rewards, multi-objective alignment, and high computational costs in federated GRPO
  by introducing adaptive objective weighting via hypergradient descent and progress-aware
  aggregation based on locally adapted reward weights.
---

# FedMOA: Federated GRPO for Personalized Reasoning LLMs under Heterogeneous Rewards

## Quick Facts
- **arXiv ID:** 2602.00453
- **Source URL:** https://arxiv.org/abs/2602.00453
- **Reference count:** 10
- **One-line primary result:** FedMOA improves global reasoning performance by up to 2.2% on MATH and 2.0% on GSM8K compared to federated baselines.

## Executive Summary
FedMOA introduces a federated GRPO framework for multi-objective alignment of reasoning LLMs under heterogeneous rewards. It addresses challenges of heterogeneous reward definitions, imbalanced multi-objective optimization, and high computational costs through adaptive objective weighting via hypergradient descent and progress-aware aggregation based on locally adapted reward weights. The method achieves consistent accuracy improvements on mathematical reasoning and code generation benchmarks while enabling more balanced multi-objective reward optimization under heterogeneous data-reward settings.

## Method Summary
FedMOA combines client-side hypergradient-based adaptive objective weighting with server-side accuracy-aware aggregation. Clients perform multi-objective GRPO with per-objective gradients computed at an intermediate layer, updating objective weights based on inner products of consecutive gradients. The server groups clients by task clusters, computes aggregation weights inversely proportional to accuracy weights (interpreted as progress proxies), and performs weighted aggregation within and across clusters. The framework uses Qwen2.5-1.5B-Instruct model, 10-15 clients, 3 global rounds, batch size 128, and 16 GRPO completions per prompt.

## Key Results
- FedMOA achieves accuracy gains of up to 2.2% on MATH and 2.0% on GSM8K compared to federated baselines
- The method consistently improves global reasoning performance under heterogeneous reward settings
- Ablation study shows adaptive weighting contributes up to 2.2% accuracy improvement on MATH

## Why This Works (Mechanism)

### Mechanism 1
Adaptive objective weighting via hypergradient descent stabilizes local multi-objective optimization by automatically prioritizing under-optimized objectives. Each client computes per-objective gradients with respect to an intermediate hidden layer. The inner product of consecutive gradients serves as a progress signal: aligned gradients indicate continued learning potential, triggering weight increase; misaligned gradients signal saturation or oscillation, triggering weight decrease. This creates a feedback loop where objectives making progress are amplified while stalled objectives are suppressed.

### Mechanism 2
Progress-aware aggregation improves global model quality by using adapted accuracy weights as inverse proxies for local training progress. The server interprets a smaller accuracy weight as evidence that accuracy is closer to saturation on that client. Clients with smaller accuracy weights receive larger aggregation weights via inverse scoring and softmax. This prioritizes updates from clients that have made more accuracy progress, under the assumption that their gradients carry higher-quality signal.

### Mechanism 3
Task clustering before aggregation enables coherent multi-objective alignment despite heterogeneous reward definitions across clients. Clients are grouped by reward component names, ensuring within-cluster clients share at least one comparable objective (accuracy). Aggregation proceeds in two stages: within-cluster accuracy-aware aggregation, and cross-cluster FedAvg-style aggregation weighted by data sizes. This hierarchical structure allows clients to maintain heterogeneous auxiliary objectives while still benefiting from shared progress on the primary accuracy objective.

## Foundational Learning

- **Concept: Group Relative Policy Optimization (GRPO)**
  - **Why needed here:** GRPO is the core RL algorithm underlying FedMOA; it eliminates the critic network by computing relative advantages within groups of responses, making on-device training feasible.
  - **Quick check question:** Can you explain how GRPO computes advantages differently from standard PPO, and why this reduces memory overhead?

- **Concept: Hypergradient Descent**
  - **Why needed here:** FedMOA uses hypergradient descent to adapt objective weights online; understanding how gradient inner products signal optimization progress is essential for debugging the weighting mechanism.
  - **Quick check question:** What does a negative inner product between consecutive gradients imply about the learning rate or objective weight update?

- **Concept: Federated Averaging (FedAvg)**
  - **Why needed here:** FedMOA builds on FedAvg for cross-cluster aggregation; familiarity with how FedAvg weights client updates by data size helps understand the two-stage aggregation design.
  - **Quick check question:** Why does FedAvg perform poorly when clients optimize different objective functions, and how does FedMOA's accuracy-aware aggregation mitigate this?

## Architecture Onboarding

- **Component map:** Client-side GRPO trainer -> Hypergradient weight adapter -> Communication interface -> Server-side task clusterer -> Accuracy-aware aggregator -> Cross-cluster aggregator -> Broadcast
- **Critical path:** Local GRPO → Hypergradient weight update → Communication → Task clustering → Accuracy-aware aggregation → Cross-cluster aggregation → Broadcast → Next round. The accuracy weight adaptation and its use in aggregation form the core feedback loop.
- **Design tradeoffs:** Gradient computation on intermediate layer only reduces compute overhead but may miss signal from deeper layers; interpreting w₀ as inverse progress proxy avoids needing validation data but relies on hypergradient dynamics; task clustering by reward names is simple but brittle to naming inconsistencies.
- **Failure signatures:** Accuracy weights collapse to near-zero or near-one (check λ); aggregation weights concentrate on few clients (verify task clustering); global model accuracy stagnates while auxiliary rewards saturate (verify hypergradient weighting).
- **First 3 experiments:** 1) Reproduce Homo+Homo baseline: FedGRPO on GSM8K with 10 clients, 3 rounds; 2) Ablate adaptive weighting only: enable hypergradient weight adaptation but disable accuracy-aware aggregation; 3) Stress-test under Heter+Heter with extreme reward heterogeneity: assign clients maximally divergent auxiliary rewards.

## Open Questions the Paper Calls Out

### Open Question 1
Does FedMOA maintain its convergence efficiency and memory advantages when applied to significantly larger LLMs (e.g., 7B–70B parameters) under federated constraints? The conclusion states results "motivate future work on scaling to larger models and more complex objective structures." This is unresolved because current experiments are restricted to Qwen2.5-1.5B-Instruct; scaling may introduce optimization instabilities not present in smaller parameter regime.

### Open Question 2
How does the adaptive weighting mechanism perform when dealing with complex objective structures where multiple primary rewards conflict without saturating? The conclusion identifies "more complex objective structures" as a specific area for future work. This is unresolved because the current setup primarily balances a primary accuracy reward against auxiliary rewards which saturate early; it's unclear if the hypergradient descent logic holds when balancing two non-saturating, competing primary objectives.

### Open Question 3
Is the progress-aware aggregation strategy robust when the server cannot accurately group clients into coherent task clusters due to heterogeneous reward naming or definitions? The method relies on the assumption that "clients can often be grouped into coarse task categories" using reward names. This is unresolved because if clients have unique task definitions or inconsistent naming schemes, clustering may fail, causing accuracy-aware aggregation to prioritize updates based on incomparable metrics.

## Limitations
- The paper lacks stability metrics or sensitivity analysis to hypergradient step size λ or task clustering quality
- The assumption that accuracy weights reliably indicate convergence progress is not validated on held-out data
- The paper lacks explicit analysis of computational overhead introduced by hypergradient computation and simplex projection

## Confidence

- **High confidence:** The mechanism of adaptive objective weighting via hypergradient descent is theoretically grounded and the ablation study clearly isolates its contribution (up to 2.2% accuracy gain on MATH).
- **Medium confidence:** The accuracy-aware aggregation strategy is plausible given reported performance gains, but relies on untested assumptions about weight-to-progress correlation; further validation on diverse reward structures is needed.
- **Low confidence:** The scalability and robustness of the two-stage aggregation under extreme heterogeneity or noisy reward definitions is not demonstrated; the paper's focus on relatively clean task clusters leaves generalization unclear.

## Next Checks

1. **Validate hypergradient step size sensitivity:** Run FedMOA across λ ∈ {0.001, 0.01, 0.1} on GSM8K with Heter+Heter data; measure accuracy variance and stability of objective weight trajectories to assess sensitivity.
2. **Test aggregation robustness under noisy reward weights:** Corrupt accuracy weights with Gaussian noise (σ=0.1, 0.3) and measure degradation in MATH accuracy vs. FedGRPO baseline to quantify robustness to hypergradient noise.
3. **Stress-test task clustering ambiguity:** Create synthetic clients with overlapping reward names (e.g., "math_problem" vs. "math_challenge") and measure whether FedMOA's aggregation still outperforms FedGRPO, or if performance collapses due to mixed-task updates.