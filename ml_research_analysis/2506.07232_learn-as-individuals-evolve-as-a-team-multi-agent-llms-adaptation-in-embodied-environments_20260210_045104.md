---
ver: rpa2
title: 'Learn as Individuals, Evolve as a Team: Multi-agent LLMs Adaptation in Embodied
  Environments'
arxiv_id: '2506.07232'
source_url: https://arxiv.org/abs/2506.07232
tags:
- agents
- liet
- multi-agent
- planning
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes LIET, a semi-centralized framework for multi-agent
  LLMs adaptation in embodied environments. The key idea is to enable agents to learn
  utility functions individually during exploration for informed decision-making,
  while collaboratively evolving a shared knowledge list for effective communication.
---

# Learn as Individuals, Evolve as a Team: Multi-agent LLMs Adaptation in Embodied Environments

## Quick Facts
- arXiv ID: 2506.07232
- Source URL: https://arxiv.org/abs/2506.07232
- Reference count: 40
- Primary result: LIET achieves 40.3 steps vs 48.4 for 2-agent C-WAH, and 79.6% vs 76.7% transport rate on TDW-MAT

## Executive Summary
This paper introduces LIET, a semi-centralized framework for adapting multi-agent LLMs in embodied environments. The framework enables agents to learn individual utility functions during exploration while collaboratively evolving a shared knowledge list for communication. LIET addresses the challenge of enabling multiple LLM agents to effectively coordinate and adapt in complex, dynamic embodied environments where traditional centralized control is impractical.

## Method Summary
LIET operates through a dual-component design: individual learning and team evolution. During exploration, each agent independently learns a utility function based on its experiences, enabling informed decision-making tailored to its specific role and observations. Simultaneously, agents contribute to and draw from a shared knowledge list that captures team-level insights and communication protocols. This semi-centralized approach balances the autonomy needed for individual adaptation with the coordination benefits of shared knowledge, allowing the team to collectively improve performance while maintaining agent-level flexibility.

## Key Results
- LIET achieves 40.3 steps vs 48.4 for 2-agent C-WAH benchmark
- LIET achieves 79.6% transport rate vs 76.7% on TDW-MAT benchmark
- Ablation studies confirm both individual learning and team evolution are critical for performance

## Why This Works (Mechanism)
LIET works by enabling agents to learn utility functions individually during exploration for informed decision-making, while collaboratively evolving a shared knowledge list for effective communication. This dual approach allows agents to adapt their individual behaviors based on personal experiences while maintaining team-level coordination through shared knowledge. The semi-centralized architecture provides the flexibility needed for individual learning while ensuring that team-level insights are captured and disseminated.

## Foundational Learning
- Embodied multi-agent systems: Needed for understanding how agents interact with physical environments and each other; Quick check: Can you explain the difference between embodied and non-embodied multi-agent systems?
- Utility function learning: Critical for agent decision-making; Quick check: How does individual utility function learning differ from shared policy learning?
- Knowledge sharing mechanisms: Essential for team coordination; Quick check: What are the trade-offs between centralized and distributed knowledge sharing?
- Semi-centralized architectures: Key to balancing autonomy and coordination; Quick check: What are the advantages of semi-centralized over purely centralized or decentralized approaches?
- LLM adaptation in dynamic environments: Fundamental to the problem being solved; Quick check: Why is LLM adaptation particularly challenging in embodied environments?

## Architecture Onboarding

**Component Map:** Agent exploration -> Individual utility learning -> Knowledge list contribution -> Team evolution -> Shared knowledge utilization

**Critical Path:** The critical execution path flows from individual exploration and utility function learning, through contribution to the shared knowledge list, to team evolution and eventual utilization of evolved knowledge by all agents. This creates a feedback loop where individual learning informs team evolution, which in turn enhances individual decision-making.

**Design Tradeoffs:** The semi-centralized approach trades some communication overhead for improved coordination compared to fully decentralized systems, while maintaining more flexibility than fully centralized approaches. The framework balances the computational cost of maintaining and evolving the knowledge list against the benefits of shared learning.

**Failure Signatures:** Performance degradation may occur if individual utility functions become too specialized and diverge from team needs, or if the knowledge list becomes outdated or inconsistent with individual experiences. Communication bottlenecks could arise if the knowledge sharing mechanism becomes a performance constraint.

**3 First Experiments:** 
1. Test individual agent performance with and without utility function learning to isolate its contribution
2. Evaluate knowledge list evolution effectiveness by comparing teams with static vs dynamic knowledge sharing
3. Assess scalability by varying agent counts and measuring performance impact on knowledge list management

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focuses on specific benchmarks (C-WAH and TDW-MAT) limiting generalizability
- Claims of "end-to-end" learning remain qualified as framework relies on pre-trained LLMs
- Ablation studies don't fully explore alternative architectural choices or hyperparameter sensitivity

## Confidence

**Performance claims on benchmark tasks:** Medium
**Claims about the necessity of both components (individual learning + team evolution):** Medium
**Claims about framework generalizability:** Low

## Next Checks
1. Test LIET on additional embodied environment benchmarks with different task types to assess generalizability beyond current domains
2. Conduct stress tests varying the number of agents to evaluate scalability and identify potential bottlenecks in knowledge list management
3. Perform ablation studies isolating the contribution of utility function learning mechanism versus knowledge list evolution