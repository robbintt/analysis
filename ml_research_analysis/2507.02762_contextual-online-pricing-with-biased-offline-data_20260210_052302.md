---
ver: rpa2
title: Contextual Online Pricing with (Biased) Offline Data
arxiv_id: '2507.02762'
source_url: https://arxiv.org/abs/2507.02762
tags:
- offline
- data
- online
- have
- regret
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work studies contextual online pricing with biased offline
  data, where a firm uses historical pricing logs that may not reflect current market
  conditions. A key challenge is that without information on the bias, no algorithm
  can uniformly outperform purely online methods.
---

# Contextual Online Pricing with (Biased) Offline Data

## Quick Facts
- arXiv ID: 2507.02762
- Source URL: https://arxiv.org/abs/2507.02762
- Reference count: 40
- Primary result: Propose optimism-based algorithms that leverage biased offline data for contextual pricing, achieving instance-dependent regret bounds that improve upon purely online methods when the bias is small.

## Executive Summary
This work studies contextual online pricing with biased offline data, where a firm uses historical pricing logs that may not reflect current market conditions. A key challenge is that without information on the bias, no algorithm can uniformly outperform purely online methods. When a bias bound is known, the authors propose optimism-based algorithms (CO3 for scalar elasticity, GCO3 for general elasticity) that construct a three- or two-ellipsoid confidence set to balance online safety and aggressive exploitation. For scalar elasticity, they identify an instance-dependent quantity δ² measuring the gap between offline data and the optimal price strategy; their algorithm achieves a regret of Õ(d₁√T ∧ (V²T + d₁T/(λₘᵢₙ(Σ̂)+(N∧T)δ²))), which can improve to O(δ²T) in well-conditioned regimes. For general elasticity, they obtain Õ((d₁+d₂)√T ∧ (V²T + (d₁+d₂)T/λₘᵢₙ(Σ̂))). They also present a robust variant (RCO3) for unknown bias bounds that guarantees sublinear regret and outperforms online-only methods when the true bias is small. Empirical results confirm that their algorithms strictly outperform purely online and naive offline-incorporating baselines when the bias bound is tight.

## Method Summary
The paper proposes algorithms that incorporate biased offline data into contextual online pricing by constructing confidence sets for the unknown demand parameters. The CO3 algorithm for scalar elasticity uses a three-ellipsoid construction (pure online safety, offline-boosted estimation, and combined online-offline data) to guarantee regret no worse than pure online methods while exploiting offline data when beneficial. The regret bound is governed by an instance-dependent quantity δ² measuring the deviation of offline pricing from the optimal strategy. For general elasticity, the GCO3 algorithm uses a simpler two-ellipsoid construction. When the bias bound is unknown, the RCO3 algorithm employs a test phase to detect small bias and switch between offline-assisted and pure online strategies.

## Key Results
- CO3 algorithm achieves regret of Õ(d₁√T ∧ (V²T + d₁T/(λₘᵢₙ(Σ̂)+(N∧T)δ²))) for scalar elasticity, improving to O(δ²T) in well-conditioned regimes.
- GCO3 algorithm obtains regret of Õ((d₁+d₂)√T ∧ (V²T + (d₁+d₂)T/λₘᵢₙ(Σ̂))) for general elasticity.
- RCO3 algorithm guarantees sublinear regret even with unknown bias bounds, outperforming online-only methods when the true bias is small.
- Empirical results confirm algorithms strictly outperform purely online and naive offline-incorporating baselines when the bias bound is tight.

## Why This Works (Mechanism)

### Mechanism 1: Three-Ellipsoid Confidence Set Construction (CO3 Algorithm)
- Claim: The CO3 algorithm achieves regret no worse than pure online methods while outperforming them when the bias bound is tight, by intersecting three distinct confidence ellipsoids.
- Mechanism: The algorithm constructs a confidence set C_t as the intersection of three ellipsoids: (1) ∥θ - θ̂_t,N∥_{Σ_t,N} ≤ w_t,N (combined online-offline data), (2) ∥θ - θ̂_t,N∥ ≤ ŵ_t,N (Euclidean offline-boosted estimation), and (3) ∥θ - θ̂_t∥_{Σ_t} ≤ w^o_t (pure online safety). Ellipsoid (3) guarantees "online safety," bounding regret at Õ(d√T). Ellipsoid (2) leverages offline data to sharpen parameter estimates. Ellipsoid (1) enables aggressive exploitation when offline data dispersion (λ_min(Σ̂)) is high or the instance-dependent quantity δ² is large.
- Core assumption: A valid bias bound V (‖θ'_* - θ_*‖ ≤ V) is known a priori. The offline data satisfies a minimum eigenvalue condition (Assumption 2: λ_min(Σ̂_x,x) ≥ cN).
- Evidence anchors:
  - [abstract]: An Optimism-in-the-Face-of-Uncertainty (OFU) policy achieves a minimax-optimal, instance-dependent regret bound.
  - [section 3.1]: "Our CO3 algorithm incorporates the biased offline dataset by constructing a confidence set as the intersection of three ellipsoids... guaranteeing regret no larger than Õ(d√T)."
  - [corpus]: Related work (Online Bandits with (Biased) Offline Data) addresses similar distribution mismatch but does not explicitly employ a three-ellipsoid construction for contextual pricing.
- Break condition: The mechanism fails if the provided bias bound V is a severe underestimate of the true bias. Theorem 1 shows that if V² ∈ Ω(T⁻¹/²), the algorithm cannot improve upon the Õ(√T) baseline. Corollary 1 establishes an impossibility result: without any bias information, no algorithm can uniformly outperform pure online methods.

### Mechanism 2: Instance-Dependent Quantity δ² for Scalar Elasticity
- Claim: The regret bound is governed by δ², a quantity measuring the deviation of the offline empirical pricing strategy from the unknown optimal online strategy. This term determines the transition between a low-regret regime (δ² small) and a regime where offline data accelerates learning (δ² large).
- Mechanism: The paper defines δ² := E_{x,y}[(p̂(x,y) - p^*_{θ_*}(x,y))²], where p̂(x,y) is an empirical policy derived from offline data. This quantity captures how "close" historical pricing was to the true optimum. The regret bound, Õ(d√T ∧ (V²T + dT / (λ_min(Σ̂) + (N ∧ T)δ²))), incorporates δ² directly. When λ_min(Σ̂) and (N ∧ T)δ² are large, the denominator grows, reducing the regret term. The CO3 algorithm adapts via a test phase (Line 1, Algorithm 1) to decide whether to deploy the empirical policy or use the full OFU approach.
- Core assumption: Offline and online features are drawn i.i.d. from the same feature distribution (though demand parameters differ). The problem is in the scalar price elasticity setting (d₂ = 1).
- Evidence anchors:
  - [abstract]: "For the scalar price elasticity case, we identify the instance-dependent quantity δ² that measures how far the offline data lies from the (unknown) online optimum."
  - [section 3]: "The quantity δ² measures the deviation of the offline data from the (unknown) optimal pricing strategy... a large δ² accelerates both exploration and exploitation."
  - [corpus]: No direct mechanism for this δ² term exists in the corpus; it appears novel to this formulation.
- Break condition: The mechanism's utility breaks if δ² is extremely small but the bias V is large (δ² ≲ max{V², 1/λ_min(Σ̂)} ≲ T⁻¹/²), which can lead to linear regret O(δ²T). If δ² is large but N is small, the term (N ∧ T)δ² may provide insufficient benefit.

### Mechanism 3: Robust Two-Phase Testing (RCO3 Algorithm)
- Claim: The RCO3 algorithm guarantees sub-linear regret even when the bias bound V is unknown, and strictly outperforms pure online methods when the true bias is small.
- Mechanism: RCO3 uses an initial test phase of length T' = Θ(T^α) for α ∈ (0, 1/2). Prices are chosen uniformly (e.g., from {l, u}) to generate an estimate θ̂_* of the online parameter, which is compared to the offline estimate θ̂'_* via ‖θ̂'_* - θ̂_*‖. A threshold f determines if the true bias is likely small (V_true ≲ T^{-α/2}) or large. If small, it exploits offline data; if large, it switches to a pure online policy. This ensures regret is Õ(T^{1-α}) in the worst case and Õ(T^α + V²_true T) when bias is small.
- Core assumption: The offline data dispersion is sufficiently strong, specifically λ_min(Σ̂) = Θ(T^β) for some β > 1/2.
- Evidence anchors:
  - [abstract]: "When the bias bound V is unknown, we design a robust variant that always guarantees sub-linear regret and strictly improves on purely online methods whenever the exact bias is small."
  - [section 4.2]: "RCO3 can achieve regret no larger than Õ(T^{1-α}) and also Õ(T^α) regret when V_true is relatively small."
  - [corpus]: Related work (Best Arm Identification with Possibly Biased Offline Data) proves an impossibility result for adaptive algorithms without bias knowledge, reinforcing the need for a robust approach.
- Break condition: If λ_min(Σ̂) is weak (λ_min(Σ̂) = O(√T)), Theorem 5 indicates the robust guarantee cannot be achieved. The choice of α involves a trade-off: smaller α reduces regret for small V_true but increases worst-case regret.

## Foundational Learning

- Concept: Optimism in the Face of Uncertainty (OFU) / Upper Confidence Bound (UCB)
  - Why needed here: This is the core algorithmic principle used in all proposed algorithms (CO3, GCO3). It balances exploration and exploitation by constructing a confidence set for the unknown parameter θ and choosing the action (price) that maximizes reward under the most optimistic plausible parameter.
  - Quick check question: Can you explain how a UCB algorithm for a stochastic bandit chooses an action at each step?

- Concept: Linear Regression and Least-Squares Estimators
  - Why needed here: The demand model is linear. The algorithms rely on ridge-regularized least-squares estimators (θ̂_t, θ̂_t,N) constructed from online and offline data to estimate the unknown demand parameters.
  - Quick check question: Given a dataset of features X and labels y, what is the closed-form solution for the ordinary least squares estimator?

- Concept: Subgaussian Random Variables and Confidence Ellipsoids
  - Why needed here: The paper assumes demand fluctuations are R-subgaussian (Assumption 1). This allows the construction of high-probability confidence ellipsoids around the least-squares estimators, which are essential for the OFU principle and regret analysis.
  - Quick check question: What does it mean for a random variable to be σ-subgaussian, and how does it relate to tail bounds?

## Architecture Onboarding

- Component map:
  1. Data Preprocessing/Stats -> Confidence Set Constructor -> Price Optimizer (OFU Core) -> Demand Observations and Model Updater
  2. For RCO3: Data Preprocessing/Stats -> Offline Data Validator -> Price Optimizer or Pure Online UCB

- Critical path:
  1. Initialization: Load offline data, compute Σ̂, λ_min(Σ̂). For RCO3, set test phase parameters (α, T').
  2. Per-Round Processing:
     a. Observe context (x_t, y_t).
     b. (RCO3 Only) If in test phase, select uniform price. Else, if test failed, use pure online UCB.
     c. Construct confidence set C_{t-1} via the Confidence Set Constructor.
     d. (CO3/GCO3 Only) Check the condition on line 1 of Algorithm 1. If met, charge p̂(x_t, y_t).
     e. Otherwise, invoke the Price Optimizer to find p_t.
     f. Observe demand D_t.
     g. Update the Model Updater with (x_t, y_t, p_t, D_t).

- Design tradeoffs:
  - Safety vs. Performance: The core tradeoff is between guaranteeing Õ(√T) regret (safety) and potentially achieving much lower regret (V²T or δ²T) if bias is small. A tighter bias bound V improves potential performance but increases risk if incorrect.
  - Complexity vs. Optimality: The three-ellipsoid design (CO3) is more complex than a two-ellipsoid (GCO3) but captures the instance-dependent δ² term for scalar elasticity, yielding a tighter bound. GCO3 is simpler but has a worst-case bound.
  - Test Phase Length (α) in RCO3: A smaller α makes the algorithm more aggressive in using offline data (lower regret for small V_true) but increases worst-case regret (T^{1-α}) if V_true is large. A larger α is more conservative.

- Failure signatures:
  1. Regret plateaus at Õ(√T): Indicates the bias bound V is too loose (V² ∈ Ω(T⁻¹/²)) or offline data dispersion λ_min(Σ̂) is too weak. The algorithm is effectively in pure online mode.
  2. Linear regret growth: Could occur if the provided bias bound V is a severe underestimate, causing misspecified confidence sets and consistently poor optimistic price choices.
  3. Regret spikes or oscillations: Might indicate issues with the constrained optimization solver (Price Optimizer) or numerical instability in computing matrix inverses for large d.

- First 3 experiments:
  1. Synthetic Data, Varying Bias (V): Generate offline data with known bias V_true. Run CO3 with tight (V = 1.1*V_true) and loose (V = 10*V_true) bounds. Plot cumulative regret against time T. Verify regret scales per Theorem 1 (e.g., stays below pure online baseline).
  2. Varying Offline Dispersion (λ_min(Σ̂)): Generate offline datasets with varying degrees of dispersion (by controlling feature/price covariance). Run GCO3 and measure final regret. Verify regret decreases as λ_min(Σ̂) increases, per Theorem 3.
  3. Unknown Bias (RCO3): Implement RCO3 with a fixed α. Generate offline-online pairs with varying true biases V_true from very small to large. Plot final regret against V_true. Verify the "V-shaped" or piecewise behavior predicted by Theorem 5: low regret for small V_true, peak around V_true ≈ T^{-α/2}, and fallback to Õ(√T) for large V_true.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can an instance-dependent distance metric (analogous to $\delta^2$ in the scalar case) be defined for the general price elasticity setting where $d_2 > 1$?
- Basis in paper: [explicit] Section 4.1 states: "For the general CB-OPOD setting, however, a clean analogue of the instance-dependent distance $\delta^2$ is still unknown... Defining an appropriate distance metric for richer contextual environments remains an attractive open problem."
- Why unresolved: The quantity $\delta^2$ measures the deviation of offline data from the optimum effectively only for scalar elasticity; the authors could not identify a suitable counterpart for multi-dimensional elasticity features.
- What evidence would resolve it: A mathematical definition of a metric that captures the statistical complexity of the general case and a modified regret bound incorporating this metric.

### Open Question 2
- Question: Can the dimension dependence in the CB-OPOD lower bounds be sharpened to match the upper bounds?
- Basis in paper: [explicit] The Conclusion explicitly lists "sharpening the dimension dependence in the CB-OPOD lower bound" as future work.
- Why unresolved: The current proof technique preserves offline data dispersion but destroys the original geometry, obscuring the dependence on the ambient dimension and leaving a gap with the upper bounds' linear factor of $d$.
- What evidence would resolve it: A lower bound construction that maintains both the offline dispersion properties and the optimal explicit dependence on the dimension.

### Open Question 3
- Question: Can a robust algorithm be designed for unknown bias $V$ that achieves uniformly optimal regret without requiring the pre-specification of the trade-off parameter $\alpha$?
- Basis in paper: [inferred] The discussion of Theorem 5 notes that "no single value of $\alpha \in (0, 1/2)$ is uniformly optimal" for the RCO3 algorithm, creating a performance trade-off between worst-case and small-bias regimes.
- Why unresolved: While RCO3 ensures robustness, the user must choose $\alpha$ a priori to optimize for either large or small biases, and an adaptive scheme to navigate this trade-off dynamically is not presented.
- What evidence would resolve it: An adaptive algorithm that simultaneously achieves the optimal regret bounds for both large and small bias cases without manual hyperparameter tuning.

## Limitations

- The assumption of known bias bound V is strong and may not hold in practice. While RCO3 addresses this, its robust guarantees require sufficiently strong offline data dispersion (λ_min(Σ̂) = Θ(T^β) for β > 1/2), which may not always be achievable.
- The instance-dependent quantity δ² relies on the offline data capturing meaningful variation in pricing strategies. If offline data is limited or pricing was uniform, δ² may be small, limiting the benefit of incorporating offline data.
- The regret bounds assume i.i.d. contexts and demand shocks. Real-world contexts may exhibit temporal correlation or non-stationarity, potentially invalidating the analysis.

## Confidence

- High Confidence: The impossibility result (Corollary 1) showing that without bias information, no algorithm can uniformly outperform pure online methods. The regret decomposition and the role of λ_min(Σ̂) in the bounds are well-supported.
- Medium Confidence: The specific regret bound forms (Õ(d√T ∧ (V²T + dT/(λ_min(Σ̂) + (N ∧ T)δ²)))) for scalar elasticity, particularly the instance-dependent term δ² and its interaction with N and T. While theoretically sound, practical estimation of δ² may be challenging.
- Medium Confidence: The robust variant RCO3's performance guarantee. The test phase design is sound, but the choice of α involves a trade-off that may require problem-specific tuning.

## Next Checks

1. Synthetic Experiment on Bias Bound Sensitivity: Generate offline data with known V_true. Run CO3 with various bias bounds (V = 0.5*V_true, V = V_true, V = 2*V_true, V = 10*V_true). Plot cumulative regret against time T. Verify that regret is close to the theoretical lower bound when V is tight and approaches pure online regret when V is too loose.

2. Real-World Data Experiment with RCO3: Apply RCO3 to a real-world pricing dataset (e.g., retail pricing logs) where a subset of data is designated as "offline" and the rest as "online." Compare RCO3's performance to pure online methods and a naive method that simply uses the offline-optimal price. Validate that RCO3 outperforms the baseline when the true bias is small and gracefully degrades when bias is large.

3. Stress Test on Offline Data Quality: Generate synthetic data where offline pricing is either very good (δ² small) or very poor (δ² large). Vary the amount of offline data N. Measure the regret of CO3 and GCO3. Verify that the algorithms correctly identify when offline data is useful (large N, large δ²) and when it is detrimental (small N, small δ²), and that the regret scales as predicted by the theoretical bounds.