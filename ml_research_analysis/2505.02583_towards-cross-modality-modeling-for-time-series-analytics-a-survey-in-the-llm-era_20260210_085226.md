---
ver: rpa2
title: 'Towards Cross-Modality Modeling for Time Series Analytics: A Survey in the
  LLM Era'
arxiv_id: '2505.02583'
source_url: https://arxiv.org/abs/2505.02583
tags:
- time
- series
- textual
- data
- forecasting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey examines LLM-based cross-modality modeling for time
  series analytics, addressing the gap between LLMs pre-trained on text and time series
  data. The authors propose a taxonomy classifying methods based on four types of
  textual data (numerical, statistical, contextual prompts, and word token embeddings)
  and two cross-modality strategies (alignment and fusion).
---

# Towards Cross-Modality Modeling for Time Series Analytics: A Survey in the LLM Era

## Quick Facts
- arXiv ID: 2505.02583
- Source URL: https://arxiv.org/abs/2505.02583
- Reference count: 7
- Primary result: Retrieval-based alignment with numerical prompts achieves ~22% MSE reduction in time series forecasting across multiple domains

## Executive Summary
This survey examines LLM-based cross-modality modeling for time series analytics, addressing the gap between LLMs pre-trained on text and time series data. The authors propose a taxonomy classifying methods based on four types of textual data (numerical, statistical, contextual prompts, and word token embeddings) and two cross-modality strategies (alignment and fusion). Experiments on multi-domain datasets show that incorporating textual data significantly improves forecasting performance, with numerical prompts and alignment methods yielding the best results. Retrieval-based alignment consistently outperforms fusion approaches. The study highlights that structured textual information enhances LLM capabilities for time series tasks and provides insights into effective combinations of textual data types and modeling strategies.

## Method Summary
The framework uses pre-trained GPT-2 (frozen weights) to embed textual data, while a Transformer-based encoder with reversible instance normalization processes time series data. Three integration strategies are tested: unidirectional retrieval-based alignment using cross-attention, addition-based fusion (element-wise sum), and concatenation-based fusion. The model employs Adam optimizer with Cosine Annealing scheduler, using lookback windows of 36 (weekly) or 8 (monthly) and 24-step forecasting horizon. Five domain datasets (Agriculture, Climate, Economy, Energy, Health) are used for evaluation, with code and datasets available at the provided GitHub repository.

## Key Results
- Retrieval-based alignment consistently outperforms fusion approaches across all domains
- Numerical prompts achieve the best performance, reducing MSE by 21.15% in climate and 17.95% in health domains compared to contextual prompts
- Alignment strategies preserve modality-specific representations while fusion methods suffer from "data entanglement issues"
- Word token embeddings perform worst, showing the importance of structured numerical information

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Retrieval-based alignment consistently outperforms fusion approaches because it preserves modality-specific representations while selectively transferring relevant information via cross-attention.
- **Mechanism:** Time series embeddings EX act as queries to retrieve from LLM-enhanced textual embeddings ET through learned projection matrices: EA = CrossAttention(EXWQ, ETWK, ETWV). This allows TS representations to "look up" relevant textual knowledge without entangling the modalities.
- **Core assumption:** Time series and textual modalities share underlying semantic structures discoverable through attention-based similarity matching.
- **Evidence anchors:**
  - [abstract]: "Retrieval-based alignment consistently outperforms fusion approaches"
  - [section 3.1, Eq. 2-4]: Formal cross-attention definition with Q/K/V projections
  - [corpus]: FiCoTS paper implements hierarchical cross-modality interaction; TimeCAP shows contextual information essential for accurate predictions
- **Break condition:** When textual embeddings contain insufficient structured numerical signal (e.g., generic word token embeddings alone), retrieval fails because similarity matching has no meaningful patterns to retrieve.

### Mechanism 2
- **Claim:** Numerical and statistical prompts outperform contextual prompts and word token embeddings because they preserve direct correlation with time series patterns.
- **Mechanism:** Numerical prompts PN transform TS values into text format; statistical prompts PS encode features (mean, max, min, trend). When processed by LLMs, these produce embeddings that maintain structural correspondence with original time series.
- **Core assumption:** LLMs pre-trained on text can extract meaningful representations from numerically-structured text that correlate with sequential numerical patterns.
- **Evidence anchors:**
  - [abstract]: "numerical prompts and alignment methods yielding the best results"
  - [section 5.4, Table 2]: "In climate and health domains, numerical prompts reduce MSE by 21.15% and 17.95%, respectively, compared to contextual prompts"
  - [corpus]: Weak direct corpus support for numerical vs. contextual comparison; Dual-Forecaster emphasizes integrating descriptive and predictive texts
- **Break condition:** When domains rely heavily on external factors not captured by textual descriptions (e.g., agriculture with weather dependencies), numerical prompts show only moderate improvements.

### Mechanism 3
- **Claim:** Contrastive learning creates shared representation spaces enabling cross-modal knowledge transfer by maximizing mutual information between aligned pairs.
- **Mechanism:** Contrastive loss Lcontrast = -log[exp(sim(EX, ET)/τ) / Σ exp(sim(EX, ĒT)/τ)] maximizes similarity between corresponding TS-text pairs while minimizing similarity with negative samples.
- **Core assumption:** Corresponding time series and textual descriptions share semantic information capturable through similarity optimization in a shared embedding space.
- **Evidence anchors:**
  - [abstract]: No explicit claim about contrastive performance vs. other methods
  - [section 3.2, Eq. 7]: Formal contrastive loss definition with temperature τ and negative sample set N
  - [corpus]: METS paper uses contrastive strategy for ECG-report alignment; LLM-TSI uses contrastive module for TS-textual alignment
- **Break condition:** When negative samples are poorly selected (semantically similar but non-corresponding pairs), contrastive learning may incorrectly push apart representations that should be close.

## Foundational Learning

- **Concept: Cross-Attention Mechanism (Q/K/V Projections)**
  - Why needed here: Core to retrieval-based alignment; understanding how queries retrieve from keys/values is essential for implementing and debugging the alignment layer.
  - Quick check question: If your retrieval-based model shows high loss but alignment embeddings appear reasonable, would you first check the projection matrices (WQ, WK, WV) or the temperature parameter in contrastive loss?

- **Concept: Prompt Type Selection (Numerical/Statistical/Contextual)**
  - Why needed here: The paper demonstrates prompt type significantly impacts performance; knowing when to use each type is critical for domain-specific applications.
  - Quick check question: Given a time series of stock prices, would you first create a numerical prompt with raw values or a statistical prompt with mean/trend values, and what factors inform this choice?

- **Concept: Modality Gap in Pre-trained LLMs**
  - Why needed here: The fundamental challenge is that LLMs are pre-trained on text, not time series; understanding this gap informs why alignment strategies are necessary.
  - Quick check question: Based on Table 2, would you expect word token embeddings from GPT-2 to outperform numerical prompts for forecasting electricity load, and why does the paper suggest this fails?

## Architecture Onboarding

- **Component map:**
  - Pre-trained LLM (frozen GPT-2): Tokenizer + embedding layer for textual data
  - TS Encoder: Transformer-based encoder with reversible instance normalization (RevIN)
  - Alignment/Fusion Layer: Retrieval (cross-attention with projections) OR Fusion (addition/concatenation)
  - Task Adapter: Linear projection layer for forecasting with de-normalization

- **Critical path:**
  1. Time series X → RevIN → Encoder → TS embedding EX
  2. Textual data T → LLM tokenizer → Frozen LLM → Textual embedding ET
  3. Alignment: CrossAttention(EXWQ, ETWK, ETWV) → EA
  4. EA → Linear projection → De-normalization → Prediction Y

- **Design tradeoffs:**
  - Alignment (retrieval) preserves modality-specific features but adds cross-attention compute; fusion is faster but causes "data entanglement issues" (section 4)
  - Numerical/statistical prompts require domain knowledge; word token embeddings are generic but perform worst
  - Unidirectional retrieval is simpler; bidirectional allows deeper interaction at 2× computation cost

- **Failure signatures:**
  - High MSE with retrieval but good baseline → Check if textual embeddings contain meaningful signal
  - Overfitting on specific domains → Excessive LLM parameters; consider knowledge distillation
  - Concatenation underperforms addition → Entanglement issue; switch to retrieval
  - Contextual prompts perform poorly → Domain may lack textual signal; try numerical prompts

- **First 3 experiments:**
  1. Run TS-only baseline vs. retrieval-based alignment with numerical prompts on one domain (climate); verify ~22.6% MSE reduction.
  2. Ablate prompt types (numerical, statistical, contextual, word tokens) using retrieval; confirm ordering: numerical > statistical > contextual > word tokens.
  3. Compare retrieval vs. addition fusion vs. concatenation fusion with numerical prompts; verify retrieval outperforms both fusion methods.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the reasoning processes of LLMs be made transparent to mitigate hallucinations and ensure reliability in high-stakes time series applications like healthcare?
- Basis in paper: [explicit] Section 6 identifies the "Transparency of LLMs" as a key future direction, noting that models often operate as "black-box" systems and are prone to generating plausible but incorrect outputs (hallucinations).
- Why unresolved: Current research primarily focuses on applying or fine-tuning LLMs without explicitly exposing internal reasoning, which hinders trust and deployment in critical domains.
- What evidence would resolve it: Development of explainable AI (XAI) techniques specific to time-series-to-text mappings that can visually or logically trace a forecast back to specific textual prompts or time steps.

### Open Question 2
- Question: What architectural innovations are required to optimize the computational efficiency of LLM-based time series modeling, particularly for multivariate data with long sequences?
- Basis in paper: [explicit] Section 6 highlights "Efficient Optimization" as a challenge, citing high computational costs due to the high dimensionality of multivariate time series and the complexity of multi-head attention mechanisms.
- Why unresolved: The quadratic complexity of standard attention mechanisms in LLMs makes processing long, multivariate sequences prohibitively expensive.
- What evidence would resolve it: Demonstration of lightweight attention mechanisms or adaptive computation frameworks that reduce latency and resource consumption without degrading forecasting accuracy.

### Open Question 3
- Question: Why do LLM-based cross-modality methods frequently underperform compared to smaller, task-specific models, and how can dynamic model selection or meta-learning bridge this gap?
- Basis in paper: [explicit] Section 6 notes under "Improving Effectiveness" that LLM-based methods "do not always surpass smaller, task-specific models" and may suffer from overfitting.
- Why unresolved: The conditions under which the generic knowledge of LLMs outweighs the specialized inductive biases of smaller models remain poorly understood.
- What evidence would resolve it: A comparative study identifying specific data characteristics (e.g., seasonality vs. noise) where LLMs fail against specialized models, followed by a hybrid approach that dynamically selects the optimal architecture.

### Open Question 4
- Question: Under what specific data distribution conditions does fusion-based modeling outperform alignment-based modeling?
- Basis in paper: [inferred] While Section 5.4 concludes that "Alignment Outperforms Fusion" generally, it also notes that for Energy forecasting, "addition-based fusion" achieved the best results. The paper does not explain the underlying cause of this anomaly.
- Why unresolved: The taxonomy presents alignment and fusion as competing strategies, but the experimental results suggest the optimal strategy is domain-dependent rather than universal.
- What evidence would resolve it: An ablation study analyzing the signal-to-noise ratio of textual data in different domains to determine if fusion is superior only when textual data is highly dense and directly correlated with the target variable.

## Limitations
- Experimental results based on small datasets (≤ 3,400 instances per domain) may not generalize to domains with different data characteristics
- Focus on GPT-2 as frozen LLM backbone limits understanding of how different LLM architectures affect performance
- Limited exploration of domain-specific knowledge incorporation and potential biases in textual data

## Confidence

- **High Confidence:** The taxonomy framework for classifying cross-modality methods (four textual data types × two strategy types) is well-defined and supported by formal definitions in sections 3.1-3.2
- **Medium Confidence:** The empirical claim that retrieval-based alignment outperforms fusion approaches is supported by experimental results, but the underlying mechanism could be domain-specific rather than universally applicable
- **Medium Confidence:** The ranking of prompt types (numerical > statistical > contextual > word tokens) is based on experimental evidence, but the survey doesn't explore why certain domains respond better to specific prompt types
- **Low Confidence:** The assertion that contrastive learning creates shared representation spaces for cross-modal knowledge transfer lacks direct experimental validation within this survey's results

## Next Checks

1. **Cross-Domain Generalization Test:** Apply the best-performing method (retrieval-based alignment with numerical prompts) to a new domain not included in the original five (e.g., transportation or retail sales) and verify if the ~22% MSE improvement holds

2. **LLM Backbone Ablation Study:** Replace GPT-2 with BERT or T5 for textual embedding generation while keeping all other components constant, then measure performance changes to assess LLM architecture sensitivity

3. **Negative Sample Quality Analysis:** Systematically vary the quality and relevance of negative samples in the contrastive learning experiments to quantify their impact on representation alignment and overall forecasting accuracy