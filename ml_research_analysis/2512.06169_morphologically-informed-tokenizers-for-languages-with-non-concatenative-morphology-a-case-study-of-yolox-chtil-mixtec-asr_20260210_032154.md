---
ver: rpa2
title: "Morphologically-Informed Tokenizers for Languages with Non-Concatenative Morphology:\
  \ A case study of Yolox\xF3chtil Mixtec ASR"
arxiv_id: '2512.06169'
source_url: https://arxiv.org/abs/2512.06169
tags:
- tokenizers
- which
- tokenizer
- morphology
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the challenge of automatic speech recognition\
  \ (ASR) for languages with non-concatenative morphology, focusing on Yolox\xF3chitl\
  \ Mixtec (YM). The authors propose two novel tokenization schemes that separate\
  \ tonal and segmental information to better capture the language's complex morphology."
---

# Morphologically-Informed Tokenizers for Languages with Non-Concatenative Morphology: A case study of Yoloxóchtil Mixtec ASR

## Quick Facts
- **arXiv ID**: 2512.06169
- **Source URL**: https://arxiv.org/abs/2512.06169
- **Reference count**: 0
- **Primary result**: Novel tokenizers separating tonal and segmental information improve ASR WER for Yoloxóchitl Mixtec compared to standard methods

## Executive Summary
This paper addresses the challenge of automatic speech recognition (ASR) for languages with non-concatenative morphology, focusing on Yoloxóchitl Mixtec (YM). The authors propose two novel tokenization schemes that separate tonal and segmental information to better capture the language's complex morphology. The Segment-and-Melody tokenizer extracts tones without predicting segmentation, while the Sequence-of-Processes tokenizer predicts segmentation for words. Experiments show these novel tokenizers are competitive with traditional methods like BPE and Unigram, with the Segment-and-Melody model outperforming in word error rate (WER) but not character error rate (CER). Morphological consistency scores correlate with ASR performance, suggesting morphology-aware tokenizers are beneficial. The paper highlights the potential of nonlinear tokenizers for languages with non-concatenative morphology, though further research is needed to evaluate their effectiveness in downstream tasks.

## Method Summary
The authors implement two novel tokenizers for Yoloxóchitl Mixtec ASR: Segment-and-Melody (SegMel) and Sequence-of-Processes (SoP). SegMel uses regex-based splitting to separate tonal sequences from segmental strings, creating distinct token streams. SoP employs Finite-State Transducers (FSTs) to model non-concatenative morphology rules, with a neural LM (ByT5) for disambiguation. Both are integrated into ESPnet2's Transformer/Conformer ASR pipeline with hybrid CTC/Attention architecture. The YM corpus (52.4 hours) is processed using practical orthography with tonal numbers 1-4. Models are trained with Adam optimizer, Noam scheduler, and SpecAugment preprocessing, evaluated using CER and WER against unsegmented text.

## Key Results
- SegMel Base tokenizer achieves lowest mean WER (22.5%) compared to BPE/500 (22.9%)
- Morphological consistency (Morph.-F1) correlates significantly with ASR performance (Spearman's ρ = -0.469)
- Novel tokenizers show competitive performance to traditional methods but do not consistently outperform them in CER
- Augmenting novel tokenizers with BPE or Unigram significantly reduces ASR performance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Separating tonal sequences from segmental strings (Segment-and-Melody tokenization) reduces WER in languages with non-concatenative morphology.
- **Mechanism:** The tokenizer splits words into distinct token streams (e.g., `ta'14bi4` → `ta'|bi` + `14|4`), isolating lexical roots from inflectional prosody and reducing vocabulary size required to cover morphological space.
- **Core assumption:** Acoustic features of segments and tones are sufficiently independent that parallel decoding streams improve learning efficiency.
- **Evidence anchors:** [Abstract] Segment-and-Melody "outperforms traditional tokenizers in terms of word error rate"; [Section 5.3] SegMel Base achieves lowest mean WER (22.5%); [Section 4.2.1] regex-based extraction described.
- **Break condition:** May degrade if language relies heavily on contour tones that cannot be easily separated from segmental duration or acoustic context.

### Mechanism 2
- **Claim:** Morphological consistency of a tokenizer correlates with downstream ASR performance.
- **Mechanism:** Tokenizers aligning boundaries with morpheme boundaries produce representations that better capture compositional meaning of words, reducing fragmentation of meaningful morphemes into arbitrary subword units.
- **Core assumption:** Morpheme boundaries are the optimal unit of representation for the acoustic model's decoder.
- **Evidence anchors:** [Abstract] "Morphological consistency scores correlate with ASR performance"; [Section 5.3.1] significant negative Spearman's correlation (ρ = -0.469) between Morph.-F1 and WER.
- **Break condition:** Correlation does not imply causation; relationship might break for agglutinative languages where optimal subword units may not strictly align with human-annotated morphemes.

### Mechanism 3
- **Claim:** Cascaded system using FSTs and LM rescoring can linearize non-concatenative processes for SoP tokenizer.
- **Mechanism:** FST generates all licensed surface-form-to-lemma mappings, handling non-concatenative morphology rules. Neural LM (ByT5) scores candidate paths based on contextual likelihood, selecting best segmentation without requiring ASR model to learn complex rewrite rules natively.
- **Core assumption:** FST rules are comprehensive enough to license correct segmentation, and LM has sufficient context to disambiguate between licensed alternatives.
- **Evidence anchors:** [Section 4.2.2] describes algorithm where FST accepts input string and LM provides scores; [Section 6.2] discusses "cascade of errors" potential and high runtime.
- **Break condition:** Mechanism relies on deterministic rules; if FST is incomplete or LM is weak, system may fail to resolve ambiguities, leading to incorrect segmentations.

## Foundational Learning

- **Concept:** Non-Concatenative Morphology (specifically Tonal Morphology)
  - **Why needed here:** Standard BPE assumes words are built by stringing units together (concatenation). YM modifies words by changing internal properties (tones). You must understand this to see why standard BPE "breaks" morphology in this context.
  - **Quick check question:** In the word `sa{3>4}ta{>2}4`, is the morphology represented by adding a suffix or by modifying internal features?

- **Concept:** Finite-State Transducers (FSTs)
  - **Why needed here:** The Sequence-of-Processes tokenizer relies on FSTs to mathematically model and execute the complex rewrite rules of YM morphology.
  - **Quick check question:** Why is an FST preferred over a simple regex substitution for handling context-sensitive tonal changes?

- **Concept:** Word Error Rate (WER) vs. Character Error Rate (CER)
  - **Why needed here:** The paper highlights a trade-off where the novel tokenizer improves WER (better for human annotators correcting whole words) but not CER.
  - **Quick check question:** If a model outputs "cat" instead of "car," how does this impact WER versus CER differently?

## Architecture Onboarding

- **Component map:** Data Prep -> Tokenizer Implementation -> Training -> Evaluation
- **Critical path:**
  1. Data Prep: Clean YM corpus (52.4 hours) and handle enclitics/punctuation
  2. Tokenizer Implementation: Implement SegMel tokenizer first (simpler regex) as it performed best
  3. Training: Train Transformer (Xavier init, 4x subsampling) using custom tokenizer vocabulary
- **Design tradeoffs:**
  - SegMel: Lower WER and better morphological consistency, but slightly higher CER than BPE; structurally rigid
  - BPE/Unigram: Lower CER and faster training, but higher WER and lower morphological consistency
  - SoP: Theoretically capable of generating segmentations directly, but computationally expensive (9 hours to preprocess) and currently underperforming
- **Failure signatures:**
  - WordPiece Tokenizer: WER approaching 100% due to naive preprocessing inserting spaces around hyphens/enclitics
  - ProcSeq: High error rates and long runtimes caused by non-deterministic FSTs and redundant arcs
  - Conformer Model: CER ~90% due to lack of fine-tuning time compared to Transformer
- **First 3 experiments:**
  1. Baseline Establishment: Train Transformer with Unigram tokenizer (vocab 500) to replicate ~8.6% CER baseline
  2. SegMel Integration: Implement SegMel tokenizer, generate vocabulary (~2100 tokens), verify WER improvement (target <23%)
  3. Correlation Check: Calculate Morph.-F1 for trained tokenizers and plot against observed WER to validate correlation claim

## Open Questions the Paper Calls Out

- **Open Question 1:** Can the proposed nonlinear tokenizers improve performance on downstream morphological segmentation and glossing tasks (wav2gloss) compared to standard text-to-sequence cascades? [explicit] The abstract states, "Further research will be necessary to determine the applicability of these tokenizers in downstream processing tasks," and Section 7.1 notes the inability to evaluate segmentation performance due to lack of gold-standard dataset. Why unresolved: Authors did not have access to finalized gold-standard segmentation dataset for Yoloxóchitl Mixtec. What evidence would resolve it: Comparative study evaluating tokenizers on completed segmentation dataset to see if they outperform cascaded ASR-to-text models.

- **Open Question 2:** Are the benefits of morphologically-informed nonlinear tokenizers generalizable to other languages with non-concatenative morphology, such as Arabic? [explicit] Section 7.1 suggests, "Further study would need to be done to compare the efficacy of unaugmented tokenizers such as SegMel in other languages with more abundant non-concatenative morphology." Why unresolved: Study limited to single case study (Yoloxóchitl Mixtec), authors speculate results might differ in languages with denser morphological patterns. What evidence would resolve it: Applying Segment-and-Melody or Sequence-of-Processes tokenizers to higher-resource language with non-concatenative morphology and measuring ASR/segmentation performance.

- **Open Question 3:** Why does augmenting the novel tokenizers with BPE or Unigram significantly reduce ASR performance in this context, contrary to findings in previous literature? [explicit] Section 6.2 notes, "A somewhat surprising result is that running BPE on top of either of our novel nonlinear tokenizers resulted in worse performance... This goes against the results of Asgari et al., 2025, and Amrhein and Sennrich, 2021." Why unresolved: Authors hypothesize it may be due to differences in dataset size (low-resource vs. high-resource) or specific distribution of tonal morphology, but did not isolate cause. What evidence would resolve it: Ablation studies varying dataset sizes and morphological densities to determine under which conditions BPE augmentation becomes detrimental.

- **Open Question 4:** Is Word Error Rate (WER) a better predictor of human annotation efficiency than Character Error Rate (CER) for low-resource language documentation? [explicit] Section 7 concludes, "We posit that, given multiple ASR systems of a sufficiently low CER... the one with the lowest WER is optimal... Further research into this hypothesis is necessary..." Why unresolved: While SegMel achieved best WER but not best CER, authors rely on theoretical arguments about annotator workload without empirical time-trial data. What evidence would resolve it: User study measuring actual time required for human annotators to correct transcripts from models with similar CERs but different WERs.

## Limitations

- **Corpus accessibility:** The 52.4-hour YM corpus remains unpublished and requires direct permission from authors, blocking independent replication and making long-term reproducibility uncertain.
- **FST implementation details:** While Process Sequence tokenizer conceptually relies on FSTs, exact replacement rules, arc weighting schemes, and determinization procedures are not fully specified.
- **Downstream task validation:** Paper demonstrates competitive ASR performance but does not evaluate whether morphological tokenization benefits downstream NLP tasks.

## Confidence

- **Segment-and-Melody tokenizer improves WER:** High confidence - experimental results show consistent WER improvements across multiple trials with statistically significant differences
- **Morphological consistency correlates with ASR performance:** Medium confidence - negative Spearman correlation (ρ = -0.469) is statistically significant but mechanistic link remains correlative rather than causal
- **Non-concatenative morphology requires specialized tokenization:** Medium confidence - comparative results support this for YM specifically, but generalizability requires further validation

## Next Checks

1. **Independent corpus acquisition and preprocessing:** Attempt to obtain YM corpus through academic channels and reproduce exact preprocessing pipeline (handling of enclitics, Spanish loanwords, punctuation) to verify reported baseline performances.

2. **Morphological consistency measurement validation:** Recompute Morph.-F1 scores for all tokenizers using published YM dictionary and morphological annotation guidelines to confirm correlation claims with ASR metrics.

3. **Runtime and complexity analysis of Process Sequence tokenizer:** Profile FST construction and ByT5 rescoring pipeline to identify optimization opportunities and verify whether computational constraints explain underperformance relative to simpler approaches.