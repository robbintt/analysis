---
ver: rpa2
title: 'SFT-GO: Supervised Fine-Tuning with Group Optimization for Large Language
  Models'
arxiv_id: '2506.15021'
source_url: https://arxiv.org/abs/2506.15021
tags:
- tokens
- token
- llama-3
- loss
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SFT-GO, a novel approach for supervised fine-tuning
  (SFT) of large language models (LLMs) that groups tokens based on importance and
  optimizes using a weighted combination of standard cross-entropy and worst-group
  loss. The method addresses the issue that not all tokens contribute equally to task-specific
  semantics during SFT, with semantically rich tokens often being under-optimized
  compared to common functional words.
---

# SFT-GO: Supervised Fine-Tuning with Group Optimization for Large Language Models

## Quick Facts
- arXiv ID: 2506.15021
- Source URL: https://arxiv.org/abs/2506.15021
- Authors: Gyuhak Kim; Sumiran Singh Thakur; Su Min Park; Wei Wei; Yujia Bao
- Reference count: 40
- Key outcome: Novel SFT-GO approach that groups tokens by importance and optimizes using weighted combination of cross-entropy and worst-group loss, showing consistent improvements across seven benchmarks

## Executive Summary
This paper introduces SFT-GO, a novel supervised fine-tuning approach for large language models that addresses the imbalance in token importance during fine-tuning. The method groups tokens based on their semantic contribution and applies a weighted loss function that combines standard cross-entropy with worst-group loss to ensure semantically rich tokens receive adequate optimization. Three grouping strategies are explored: TF-IDF (statistics-based), LLMLingua-2 (semantics-based), and Rho-1 (loss-based). Experiments on Llama models demonstrate consistent improvements across multiple benchmarks, with LLMLingua-2 and TF-IDF particularly effective for general reasoning tasks.

## Method Summary
SFT-GO introduces a group-based optimization framework for supervised fine-tuning that recognizes not all tokens contribute equally to task-specific semantics. The approach divides tokens into groups based on importance metrics (TF-IDF, semantic compression scores, or loss values) and applies a weighted loss function combining standard cross-entropy with worst-group loss. This ensures that semantically rich but often under-optimized tokens receive adequate attention during training. The method maintains computational efficiency while improving model performance on downstream tasks, particularly those requiring deeper semantic understanding. Theoretical analysis proves convergence properties, demonstrating the effectiveness of focusing on challenging token groups during optimization.

## Key Results
- SFT-GO consistently outperforms baseline SFT approaches across seven benchmarks
- LLMLingua-2 and TF-IDF grouping strategies particularly improve performance on general reasoning tasks
- Theoretical convergence analysis proves effectiveness of group-based optimization
- Demonstrated improvements on LIMA and Alpaca datasets using Llama 3.2-3B and Llama 3.1-8B models

## Why This Works (Mechanism)
The method works by recognizing that standard supervised fine-tuning treats all tokens equally, despite their varying semantic contributions. Function words like "the" and "is" are optimized efficiently due to their high frequency, while semantically rich tokens that carry task-specific meaning often receive insufficient optimization. By grouping tokens based on importance and applying worst-group loss, SFT-GO ensures that challenging, semantically significant tokens are properly optimized. This targeted approach addresses the fundamental limitation of uniform token treatment in standard fine-tuning, leading to better downstream performance.

## Foundational Learning

**Token Importance Imbalance**: Why needed - Standard SFT treats all tokens equally despite varying semantic contributions. Quick check: Analyze token frequency distributions and semantic contributions in fine-tuning datasets.

**Group-Based Optimization**: Why needed - Enables targeted optimization of challenging token groups. Quick check: Verify that worst-group loss effectively improves optimization of underrepresented token categories.

**Cross-Entropy vs. Worst-Group Loss**: Why needed - Different loss functions address different optimization challenges. Quick check: Compare convergence rates and final performance using different loss weightings.

**Semantic vs. Statistical Token Grouping**: Why needed - Different grouping strategies capture different aspects of token importance. Quick check: Evaluate grouping strategy effectiveness on various task types.

## Architecture Onboarding

**Component Map**: Data Preprocessing -> Token Grouping -> Weighted Loss Computation -> Model Update -> Evaluation

**Critical Path**: Token grouping strategy selection and implementation is the most critical component, as it determines which tokens receive focused optimization and directly impacts downstream performance.

**Design Tradeoffs**: The paper balances computational efficiency with optimization effectiveness by using simple grouping strategies (TF-IDF) alongside more complex semantic approaches (LLMLingua-2), allowing practitioners to choose based on their specific needs and computational constraints.

**Failure Signatures**: Poor grouping strategy selection may lead to over-optimization of irrelevant tokens or insufficient focus on semantically important ones, potentially degrading downstream performance.

**First Experiments**: 1) Compare baseline SFT vs SFT-GO on a simple classification task with known token importance patterns, 2) Evaluate different grouping strategies on a held-out validation set, 3) Analyze worst-group loss weighting impact on convergence speed and final accuracy.

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Theoretical convergence analysis limited to simplified loss landscapes that may not capture real-world LLM fine-tuning complexity
- Empirical evaluation constrained by small scale (only two base models and two datasets) and focus on Llama architectures
- Performance gains are generally modest (typically 1-3% improvements), which may limit practical significance
- Computational overhead and training efficiency impact not thoroughly analyzed

## Confidence

**High confidence**: Core observation about token importance imbalance is well-supported and represents genuine problem in current fine-tuning approaches.

**Medium confidence**: Proposed methodology and theoretical framework are sound, though convergence proofs may not fully translate to practical scenarios.

**Medium confidence**: Empirical results demonstrate consistent improvements, but limited scope of experiments and modest effect sizes warrant cautious interpretation.

## Next Checks

1. Evaluate SFT-GO on additional model architectures (e.g., Mistral, GPT variants) and larger model scales (70B+ parameters) to assess generalizability.

2. Conduct ablation studies isolating the impact of each component (grouping strategies, worst-group loss weighting) to better understand their individual contributions.

3. Perform extensive computational efficiency analysis comparing training time, memory usage, and convergence speed against standard SFT baselines across different hardware configurations.