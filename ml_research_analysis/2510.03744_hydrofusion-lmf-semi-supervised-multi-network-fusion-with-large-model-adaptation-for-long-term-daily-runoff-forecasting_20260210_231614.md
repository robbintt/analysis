---
ver: rpa2
title: 'HydroFusion-LMF: Semi-Supervised Multi-Network Fusion with Large-Model Adaptation
  for Long-Term Daily Runoff Forecasting'
arxiv_id: '2510.03744'
source_url: https://arxiv.org/abs/2510.03744
tags:
- runoff
- forecasting
- expert
- hydrologic
- decomposition
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses decade-scale daily runoff forecasting in small
  watersheds, where signals blend drifting trends, multi-scale seasonal cycles, regime
  shifts, and sparse extremes. Prior deep models typically target single facets and
  under-utilize unlabeled spans, limiting regime adaptivity.
---

# HydroFusion-LMF: Semi-Supervised Multi-Network Fusion with Large-Model Adaptation for Long-Term Daily Runoff Forecasting

## Quick Facts
- **arXiv ID:** 2510.03744
- **Source URL:** https://arxiv.org/abs/2510.03744
- **Reference count:** 9
- **Key outcome:** Improves decade-scale daily runoff forecasting MSE by 10.2% over DLinear baseline, with semi-supervised multi-network fusion and large-model adaptation.

## Executive Summary
This paper introduces HydroFusion-LMF, a semi-supervised deep learning framework for long-term daily runoff forecasting in small watersheds. It combines a learnable trend-seasonal-residual decomposition with a heterogeneous expert set and a hydrologic context-aware gating mechanism. The model leverages unlabeled data through multi-task semi-supervised learning to improve generalization under non-stationarity. Results on a ~10-year daily dataset show significant performance gains over strong baselines, with interpretable components and sparse gating dynamics.

## Method Summary
HydroFusion-LMF first decomposes the input runoff signal into learnable trend, seasonality, and residual components. Five parallel experts (linear refinement, frequency kernel, patch Transformer, LSTM, and dynamically normalized attention) process the residual, with outputs fused via a context-aware gate conditioned on hydrologic covariates. The framework uses a semi-supervised multi-task loss including supervised error, masked reconstruction, contrastive alignment, augmentation consistency, and variance-filtered pseudo-labeling. Optional foundation-model adapters can be integrated for additional capacity. Training uses AdamW optimizer with early stopping on validation MSE.

## Key Results
- Achieves MSE 1.0128 and MAE 0.5818 on decade-scale daily runoff data.
- Outperforms strongest baseline (DLinear) by 10.2% (MSE) and 10.3% (MAE).
- Improves mean baseline by 24.6% (MSE) and 17.1% (MAE).
- Enhances extreme event forecasting through weighted loss terms.
- Demonstrates effective use of unlabeled data via semi-supervised learning.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Learnable trend-seasonal-residual (TSR) decomposition reduces non-stationarity in the input signal, simplifying the optimization landscape for downstream experts.
- **Mechanism:** A linear projection captures the trend ($T_t$), while a truncated Fourier basis with learnable coefficients captures seasonality ($S_t$). By subtracting these from the input $x_t$, the resulting residual $R_t$ has lower entropy and reduced distributional drift, preventing deep experts from overfitting to low-frequency trends.
- **Core assumption:** The runoff signal is additively composed of a smooth linear trend, quasi-periodic seasonality, and a stochastic residual. Assumption: The trend is approximately linear over the lookback window $L$.
- **Evidence anchors:**
  - [abstract]: "...performs a learnable trend-seasonal-residual decomposition to reduce non-stationarity..."
  - [section 3.1]: "This retains interpretability... while giving the optimizer freedom to emphasize multi-week patterns."
  - [corpus]: Neighbor papers (e.g., "A Multi-scale Representation Learning Framework") support the general efficacy of multi-scale decomposition in LTSF, though specific hydrologic validation relies on the paper's results.
- **Break condition:** If the trend exhibits sudden, non-linear regime shifts (e.g., rapid land-use change) that violate the linear projection assumption, the residual $R_t$ may retain high non-stationarity, potentially destabilizing expert training.

### Mechanism 2
- **Claim:** Heterogeneous expert fusion conditioned on hydrologic context minimizes conditional bias by dynamically selecting the inductive bias best suited for the current basin state.
- **Mechanism:** Five parallel experts (Linear, Frequency, Patch Transformer, LSTM, Attention) process the residual. A context vector $h_t$ (encoding day-of-year, antecedent precipitation, local variance, etc.) feeds a gating network to produce convex weights. This allows the model to favor frequency experts during periodic cycles and memory/recurrent experts during event-driven anomalies.
- **Core assumption:** No single architecture is optimal across all hydrologic regimes (low-flow, rising limb, flood peak), and the provided context variables $h_t$ are sufficient statistics for identifying the optimal expert.
- **Evidence anchors:**
  - [abstract]: "...fuses expert outputs via a hydrologic context-aware gate conditioned on day-of-year phase, antecedent precipitation..."
  - [section 3.2]: "The gating mechanism embodies the hypothesis that hydrologic regimes differ in which inductive bias... is most predictive."
  - [corpus]: Corpus lacks direct precedents for hydrologic-context gating, indicating this is a novel synthesis requiring validation specific to the data.
- **Break condition:** If the gating network suffers from "collapse" (assigning near-zero variance to weights, effectively using an ensemble average) or if context variables are uninformative during transition periods, the system loses adaptive capacity.

### Mechanism 3
- **Claim:** Semi-supervised multi-task objectives leverage unlabeled spans to regularize representations and improve generalization on sparse labeled data.
- **Mechanism:** The loss combines standard supervised errors (MSE/MAE/NSE) with self-supervised signals: masked reconstruction (forcing local structure learning), contrastive alignment (cross-scale consistency), and variance-filtered pseudo-labeling (using high-confidence predictions on unlabeled data as targets).
- **Core assumption:** Unlabeled time spans contain structural regularities (periodicity, autocorrelation) relevant to the supervised task, and high-consensus predictions are likely accurate.
- **Evidence anchors:**
  - [abstract]: "...augments supervision with a semi-supervised multi-task objective... [and] variance-filtered pseudo-labeling."
  - [section 3.3]: "This term suppresses brittle reliance on spurious perturbation-sensitive cues."
  - [corpus]: Related work in LTSF (e.g., "A Multi-scale Representation...") often utilizes self-supervised pre-training, supporting the utility of these signals.
- **Break condition:** If augmentations violate physical constraints (e.g., implausible noise) or if early pseudo-labels are confidently wrong (feedback loop), the model may learn spurious correlations or confirm its own biases.

## Foundational Learning

- **Concept:** **Additive Time Series Decomposition (STL/TSR)**
  - **Why needed here:** The model explicitly separates $x_t$ into $T_t + S_t + R_t$. Understanding how linear trend differencing and Fourier bases partition variance is required to debug why the residual might still contain trend leakage.
  - **Quick check question:** If the seasonal period $\tau$ is mis-specified (e.g., not 365), which component absorbs the error: the Trend, the Seasonal, or the Residual?

- **Concept:** **Mixture of Experts (MoE) & Gating Networks**
  - **Why needed here:** The core architecture relies on a soft-routing mechanism. One must understand how Softmax over expert scores ensures differentiability and how "load balancing" (preventing expert starvation) might be implicitly handled or required.
  - **Quick check question:** If the gate outputs weights $[0.9, 0.02, 0.02, 0.02, 0.02]$ for 90% of samples, what is the risk to the "specialist" experts?

- **Concept:** **Consistency Regularization & Pseudo-Labeling**
  - **Why needed here:** The semi-supervised loss relies on the model producing stable outputs under augmentation and using its own predictions as labels.
  - **Quick check question:** Why is "variance filtering" (checking $u_{t+h} < Q$) critical before accepting a pseudo-label? What happens to the loss $L_{pl}$ if the threshold $Q$ is too high?

## Architecture Onboarding

- **Component map:** Historical window $x_{t-L+1:t}$ + Exogenous vars -> TSR Decomposition: Linear Trend $T_t$ + Fourier Seasonality $S_t$ -> Residual Branch: $R_t = x_t - T_t - S_t$ -> Expert Parallel: [Linear, Freq-Kernel, PatchTST, LSTM, DynAttn] process $R_t$ -> Context Encoder: Maps static/hydrologic attributes -> context vector $h_t$ -> Gate: MLP Softmax over $h_t$ -> weights $g_t^{(k)}$ -> Fusion: $\sum g_t^{(k)} y_t^{(k)}$ -> Recombination: $\hat{x} = \hat{T} + \hat{S} + \hat{r}$ -> Loss: Composite of Supervised, Masked, Contrastive, Consistency, and Pseudo-label terms.

- **Critical path:** The **Residual-to-Gate interface**. The decomposition quality determines the difficulty of the expert task; the gate determines which expert sees the signal. If decomposition fails, experts see high-noise inputs. If the gate fails, experts are averaged blindly.

- **Design tradeoffs:**
  - **Decomposition:** Learnable TSR is adaptive but risks overfitting short windows; fixed STL is stable but rigid.
  - **Experts:** Heterogeneity increases capacity but complicates gradient harmony (different experts may converge at different speeds).
  - **Pseudo-labels:** Aggressive inclusion (high $Q$) adds data but injects noise; conservative inclusion is safe but slow.

- **Failure signatures:**
  - **Dominant Trend:** If Residuals remain non-stationary, the LSTM/Attention experts may struggle to converge.
  - **Gate Collapse:** Gate outputs uniform weights ($\approx 0.2$ for 5 experts) regardless of context, turning the model into a simple ensemble.
  - **Extreme Blindness:** If $L_{ext}$ (extreme emphasis) is under-weighted, the model smooths flood peaks to minimize MSE.

- **First 3 experiments:**
  1. **Ablate Decomposition:** Feed raw $x_t$ directly to experts vs. TSR $R_t$. Compare validation MSE to quantify the "variance reduction" benefit.
  2. **Visualize Gate Dynamics:** Plot gate weights $g_t$ over time, specifically during flood events vs. dry seasons. Verify that different experts activate (e.g., LSTM on rising limbs, Linear on baseflow).
  3. **Pseudo-Label Sensitivity:** Train on 10%, 30%, 50% labeled data with/without the semi-supervised loss terms. Measure the performance gap to establish label efficiency.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the integration of explicit mass-balance or soil moisture conservation constraints into the training objective prevent physically implausible extrapolations in the residual expert components?
- **Basis:** [explicit] The authors explicitly state in the Limitations section that they "have not yet embedded explicit mass-balance or soil moisture conservation constraints," noting that purely data-driven residual corrections might violate physical plausibility.
- **Why unresolved:** The current framework relies on data-driven regularization which may not enforce hard physical limits during extreme or out-of-distribution events.
- **What evidence would resolve it:** A comparative study showing that a physics-informed variant maintains mass conservation (e.g., water balance closure) in extrapolation scenarios where the current data-driven version fails.

### Open Question 2
- **Question:** Does coupling HydroFusion-LMF with real-time data assimilation (e.g., Ensemble Kalman Filter) significantly improve forecast reliability by updating internal states?
- **Basis:** [explicit] The Discussion identifies "Real-time data assimilation (e.g. EnKF) integration" as future work needed "to couple state updates with learned dynamics."
- **Why unresolved:** The current architecture produces forecasts based on static training and initial conditions without updating its internal state representations using real-time observations.
- **What evidence would resolve it:** Implementation of an EnKF interface showing improved short-term accuracy and reduced error growth rates when assimilating streamflow observations compared to the open-loop model.

### Open Question 3
- **Question:** Can tailored synthetic augmentation or physically informed storm surrogates effectively reduce prediction errors for extreme events exceeding the 0.99 quantile?
- **Basis:** [explicit] The authors note in the Discussion that "Extreme events beyond the 0.99 quantile remain scarce" and suggest "tailored synthetic augmentation or physically informed storm surrogates could further reduce tail error."
- **Why unresolved:** The current model, while improving on extremes, is still limited by the statistical sparsity of the most severe flood events in the training record.
- **What evidence would resolve it:** Ablation experiments showing reduced Peak Discharge Error and improved High-flow F1 scores on held-out extreme years when training includes physics-based synthetic storm events.

## Limitations

- **Trend Linearity Assumption:** Learnable TSR decomposition assumes runoff trend is approximately linear, which may fail under abrupt land-use or climate regime shifts.
- **Gating Novelty:** The hydrologic-context-aware gating mechanism is novel and lacks direct empirical precedents, raising questions about robustness to regime transitions.
- **Physical Realism of Pseudo-Labels:** Semi-supervised components depend on variance-filtered pseudo-labels, but the risk of physically implausible perturbations or feedback loops is not explicitly addressed.

## Confidence

- **High:** The 10.2% MSE improvement over DLinear, the explicit architecture design, and the semi-supervised multi-task framework structure.
- **Medium:** The learnable TSR decomposition's effectiveness in hydrologic time series and the gating mechanism's ability to route contextually.
- **Low:** The impact of unlabeled data augmentation on physical realism and the generalization of foundation-model adaptation to unseen watersheds.

## Next Checks

1. **TSR Ablation Test:** Train the full model with raw inputs vs. decomposed residuals; quantify the reduction in expert MSE to isolate decomposition value.
2. **Gate Behavior Audit:** During a known flood event, plot the temporal evolution of expert gate weights; verify non-uniform activation aligning with the hydrologic regime.
3. **Pseudo-Label Sensitivity Sweep:** Vary Q (threshold) and the fraction of labeled data; plot validation MSE vs. Q to identify the noise-risk boundary.