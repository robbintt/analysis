---
ver: rpa2
title: 'SaFARi: State-Space Models for Frame-Agnostic Representation'
arxiv_id: '2505.08977'
source_url: https://arxiv.org/abs/2505.08977
tags:
- frame
- representation
- safari
- error
- measure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SaFARi generalizes the HiPPO framework by enabling SSM construction
  with any frame or basis, not just orthogonal polynomials. It introduces a numerical
  method to derive SSM parameters A and B for arbitrary frames, extending applicability
  beyond polynomial bases.
---

# SaFARi: State-Space Models for Frame-Agnostic Representation

## Quick Facts
- **arXiv ID:** 2505.08977
- **Source URL:** https://arxiv.org/abs/2505.08977
- **Reference count:** 40
- **Primary result:** Generalizes HiPPO framework to arbitrary frames/bases using numerical SSM parameter derivation

## Executive Summary
SaFARi extends the HiPPO framework by enabling State-Space Model construction with any frame or basis, not just orthogonal polynomials. The approach introduces a numerical method to derive SSM parameters A and B for arbitrary frames, preserving key HiPPO properties like timescale robustness. The work provides two variants for uniform scaled and translated measures, with theoretical error bounds showing that truncation and mixing errors arise from frame truncation. Implementation considerations include strategies for finite-dimensional approximation (ToD vs DoT) and parallelization via convolution kernels.

## Method Summary
SaFARi derives SSM parameters numerically for arbitrary frames through frame and dual frame computation. Given a frame Φ and its dual ̃Φ, the A matrix is computed via integrals involving frame elements and their derivatives. For scaled measure: A = I + U_Υ U*_̃Φ where Υ is the "auxiliary derivative" of the frame. For translated measure: A = U_ẊΦ U*_̃Φ + Q_Φ Q*_̃Φ. The method discretizes the resulting ODE using Generalized Bilinear Transform and supports both sequential updates and parallel convolution kernels when A is diagonalizable.

## Key Results
- SaFARi converges to HiPPO closed-form solutions as discretization L increases
- DoT construction achieves minimal reconstruction error among equivalent truncation methods
- Mixing errors eliminated when A is lower-triangular, guaranteeing zero error propagation
- Supports diagonalizable SSMs with O(NL) complexity, extending beyond HiPPO-LegS limitations

## Why This Works (Mechanism)

### Mechanism 1
SaFARi derives SSM parameters (A, B) numerically for any frame, extending beyond closed-form polynomial solutions. Given a frame Φ and its dual ̃Φ, the A matrix is computed via integrals involving frame elements and their derivatives. For scaled measure: A = I + U_Υ U*_̃Φ where Υ is the "auxiliary derivative" of the frame (t·∂ϕₙ/∂t). For translated measure: A = U_ẊΦ U*_̃Φ + Q_Φ Q*_̃Φ. Core assumption: The frame and input signal are right-continuous; the frame is sufficiently sampled at resolution L for numerical integration.

### Mechanism 2
Mixing errors (error propagation across truncated coefficients) are eliminated when A is lower-triangular. Truncation at N discards coefficients cₙ for n > N. When A has non-zero elements in upper-right quadrant (i≤N, j>N), the Ac product contaminates retained coefficients with discarded ones. Lower-triangular A zeroes this quadrant, guaranteeing zero mixing error regardless of signal.

### Mechanism 3
DoT (Dual of Truncation) construction yields optimal reconstruction error among all SaFARi(N) variants. Given truncated frame Φ[0:N], DoT computes the pseudo-inverse dual ̃Φ^(N) = (ΦΦ^T)^(-1)Φ^T directly on the truncated frame, rather than truncating an infinite dual. This minimizes ||ξ||_F where ξ = Υ(̃ΦΦ - I), the mixing error kernel.

## Foundational Learning

- **Frame theory (frames, dual frames, frame operator)**: SaFARi's entire construction depends on representing signals via arbitrary frames and recovering them via dual frames. Without this, the A matrix derivations are opaque.
  - Quick check: Given a frame Φ with frame bounds A_frame, B_frame, what does it mean for the frame to be "tight"?

- **State-space models as online function approximation**: The paper reframes SSMs not as control systems but as mechanisms for maintaining compressive representations of streaming signals via ODE updates.
  - Quick check: Why does the ċ = -Ac + Bu formulation guarantee constant memory footprint regardless of sequence length?

- **Diagonalization for computational efficiency**: The paper's complexity claims (O(NL) vs O(N³L)) hinge on whether A is diagonalizable, enabling convolution kernel computation without matrix inversions.
  - Quick check: If A = VΛV⁻¹, how does solving in the diagonal basis reduce per-step complexity?

## Architecture Onboarding

- **Component map**: Frame selection module → Define Φ with N elements over domain [0,1] → Dual computation → Pseudo-inverse ̃Φ^(N) = (ΦΦ^T)^(-1)Φ^T → A/B matrix assembly → Numerical integration per Eq. 16 (scaled) or Eq. 20 (translated) → Discretization → GBT with parameter α (α=0.5 recommended) → Inference path → Either sequential GBT updates or convolution kernel (if diagonalizable)

- **Critical path**: 1) Choose frame compatible with expected signal class (polynomial for smooth, wavelet for localized) 2) Compute A matrix and check structure (lower-triangular → mixing-safe) 3) Attempt diagonalization; if successful, precompute convolution kernel; if not, plan for O(N²L) or O(N³log L) 4) Select N based on coefficient decay rate for your signal class

- **Design tradeoffs**: Scaled measure → Timescale robust (Appendix A.4), but A varies each step → higher compute; Translated measure → Constant A within window → O(N²L) sequential, but loses history beyond θ; Diagonalizable frames → O(NL) but may sacrifice lower-triangular structure; Higher N → Better approximation but increased compute and potential mixing if A not triangular

- **Failure signatures**: Exploding gradients during training → A has positive eigenvalues (stability violated); Accuracy plateaus despite increasing N → Frame incompatible with signal class; try different basis; Numerical divergence at large N/L → Integration discretization too coarse; increase L; Long-sequence degradation → Non-triangular A causing mixing error accumulation

- **First 3 experiments**: 1) Reproduce HiPPO-LegS using SaFARi with Legendre frame: verify A matrix converges to closed-form as L increases (Fig 3 validation) 2) Compare DoT vs ToD reconstruction error on truncated Fourier frame with synthetic bandlimited signals: confirm Theorem 5 3) Test diagonalizable vs non-diagonalizable frames (e.g., custom orthogonal frame) on sequence modeling task: measure training speed vs accuracy tradeoff

## Open Questions the Paper Calls Out

- **Open Question 1**: How can SaFARi be adapted to handle non-uniform weighting schemes, such as exponential decay measures, within its generalized framework? The authors state in Section 2.2 and Section 5 that they "consider only the case of uniform weighting" and explicitly "leave alternative weighting schemes to future work."

- **Open Question 2**: Can wavelet-based frames be effectively utilized within SaFARi to enhance localized and sparse representations beyond the capabilities of polynomial bases? Section 7 explicitly lists "the evaluation of wavelet and other structured frames within SaFARi" as a future direction.

- **Open Question 3**: Does integrating SaFARi into advanced SSM architectures like S4 and Mamba improve performance on long-range sequence modeling tasks? The conclusion states that "integrating SaFARi into advanced SSM architectures like S4 and Mamba offers promising avenues for improving long-range sequence modeling."

## Limitations
- Numerical integration accuracy for arbitrary frames remains unverified across diverse basis types, with no systematic error analysis for different quadrature schemes
- Mixing error mechanism, while theoretically sound for lower-triangular A, lacks empirical validation across non-Legendre frames and real-world sequence modeling tasks
- Diagonalizability claims are limited to four canonical HiPPO frames, with no characterization of diagonalizability conditions for arbitrary frame choices

## Confidence
- **High**: The numerical derivation framework for A and B matrices is mathematically rigorous and reproducible given proper frame definitions
- **Medium**: Error analysis and reconstruction bounds hold for the specific cases examined but require broader validation
- **Low**: Claims about computational efficiency gains (O(NL) vs O(N²L)) need empirical verification across different frame classes and sequence lengths

## Next Checks
1. Implement SaFARi with wavelet frames (as in WaLRUS) and validate numerical convergence against closed-form solutions where available
2. Systematically compare DoT vs ToD truncation constructions across multiple signal classes (polynomial, bandlimited, sparse) to verify error bounds
3. Benchmark diagonalizable vs non-diagonalizable frames on sequence modeling benchmarks, measuring both accuracy and training efficiency