---
ver: rpa2
title: 'CogMem: A Cognitive Memory Architecture for Sustained Multi-Turn Reasoning
  in Large Language Models'
arxiv_id: '2512.14118'
source_url: https://arxiv.org/abs/2512.14118
tags:
- reasoning
- memory
- turn
- message
- context
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of sustaining coherent reasoning
  in large language models over extended multi-turn interactions, where models often
  suffer from accuracy loss, task drift, and unbounded context growth. The authors
  propose CogMem, a cognitively inspired memory-augmented architecture that integrates
  three layers: long-term memory (LTM) for cross-session knowledge consolidation,
  direct-access (DA) memory for session-level notes and plans, and a focus-of-attention
  (FoA) mechanism for dynamic context reconstruction at each turn.'
---

# CogMem: A Cognitive Memory Architecture for Sustained Multi-Turn Reasoning in Large Language Models

## Quick Facts
- arXiv ID: 2512.14118
- Source URL: https://arxiv.org/abs/2512.14118
- Authors: Yiran Zhang; Jincheng Hu; Mark Dras; Usman Naseem
- Reference count: 10
- Primary result: Hierarchical memory architecture achieves 93% accuracy on TurnBench-MS vs 76% baseline

## Executive Summary
This paper addresses the challenge of sustaining coherent reasoning in large language models over extended multi-turn interactions, where models often suffer from accuracy loss, task drift, and unbounded context growth. The authors propose CogMem, a cognitively inspired memory-augmented architecture that integrates three layers: long-term memory (LTM) for cross-session knowledge consolidation, direct-access (DA) memory for session-level notes and plans, and a focus-of-attention (FoA) mechanism for dynamic context reconstruction at each turn. Experiments on TurnBench-MS show that each layer contributes incrementally to performance, with the full CogMem system achieving 93% accuracy in classic mode compared to 76% for the baseline Gemini 2.5 Flash model. Additionally, CogMem significantly reduces token usage, maintaining bounded context growth while improving reasoning stability and efficiency.

## Method Summary
CogMem implements a three-layer memory hierarchy with a two-agent system: a reasoning agent (Gemini 2.5 Flash) and a memory agent (Gemini 2.5 Flash Lite). The architecture consists of Focus of Attention (FoA) for dynamic turn-level context reconstruction, Direct Access (DA) memory for session-level notes stored in RAM with optional Redis caching, and Long-Term Memory (LTM) using Milvus vector database for cross-session strategy storage. The system processes user input through a session manager that identifies reusable sessions, then constructs a First Context Window using FoA. If the reasoning agent identifies missing context, FoA creates a Second Context Window with additional turn details. After reasoning, the memory agent asynchronously summarizes and updates DA and LTM. Session managers handle caching, expiration, and garbage collection with event-triggered cleanup.

## Key Results
- Full CogMem system achieves 93% accuracy on TurnBench-MS classic mode vs 76% baseline
- Each memory layer adds incremental accuracy gains: baseline (76%) → FoA (76%) → DA (84%) → full system (93%)
- CogMem maintains bounded token growth across turns while baseline shows linear growth
- Accuracy improves particularly on hard tasks where baseline accuracy drops to 40%

## Why This Works (Mechanism)

### Mechanism 1
Hierarchical memory organization enables reasoning at multiple temporal scales while controlling context growth. Three distinct memory layers operate with different persistence and accessibility profiles—FoA reconstructs turn-level context, DA maintains session notes, and LTM stores cross-session strategies. This separation prevents redundant information from accumulating in the active context while preserving critical reasoning traces.

### Mechanism 2
Dynamic context reconstruction at each turn reduces reasoning bias and memory decay by replacing raw history with curated, task-relevant context. FoA selectively integrates current notes, retrieved LTM entries, summarized dialogue history, and new input into a compact prompt. The reasoning agent can request missing turn details, triggering a second context window—this two-pass design ensures completeness without unbounded growth.

### Mechanism 3
Bidirectional memory flow between layers enables error recovery and cross-session knowledge accumulation. FoA pulls from DA and LTM; DA updates from reasoning outputs and retrieves from LTM; LTM distills insights from completed sessions. This continuous refinement allows early errors to be corrected as notes evolve, and successful strategies to persist across sessions.

## Foundational Learning

- **Working memory vs. long-term memory in cognitive architectures**: CogMem explicitly maps FoA/DA/LTM to Oberauer's cognitive model; understanding this distinction clarifies why each layer has different persistence and access patterns.
  - Quick check: Can you explain why FoA reconstructs context per-turn while LTM persists across sessions?

- **Vector semantic retrieval and similarity search**: LTM uses vectorized storage (Milvus) for semantic retrieval; understanding embedding-based search is essential for debugging retrieval quality.
  - Quick check: How would a poorly tuned similarity threshold affect LTM retrieval in CogMem?

- **Chain-of-thought prompting for multi-step reasoning**: All CogMem experiments use CoT; the architecture augments rather than replaces explicit reasoning steps.
  - Quick check: Why might CoT alone be insufficient for multi-turn reasoning without persistent memory?

## Architecture Onboarding

- **Component map**: User input → Session Manager → Memory Agent queries LTM → FoA constructs First Context Window → Reasoning Agent evaluates completeness → (optional) FoA constructs Second Context Window → Reasoning Agent generates response → Memory Agent summarizes and updates DA → async DA/LTM update → session cached

- **Critical path**: User input → Session Manager (reuse or new session) → Memory Agent queries LTM → FoA constructs First Context Window → Reasoning Agent evaluates completeness → (optional) FoA constructs Second Context Window with missing turns → Reasoning Agent generates response → Memory Agent summarizes and updates DA → async DA/LTM update → session cached

- **Design tradeoffs**: Two-pass context reconstruction improves completeness but adds latency; lightweight Memory Agent reduces cost but may produce lower-quality summaries; LTM distillation at session end reduces noise but risks losing nuanced strategies; session reuse improves efficiency but requires careful state validation

- **Failure signatures**: Unbounded token growth (FoA not filtering effectively, DA notes too verbose); repeated reasoning errors (LTM storing flawed strategies, DA not updating notes); missing context (Reasoning Agent not signaling incomplete FoA, retrieval threshold too strict); session state corruption (Inheritable session logic misidentifying prefixes, race conditions in async updates)

- **First 3 experiments**:
  1. Ablate each memory layer (FoA-only, FoA+DA, full system) on TurnBench to reproduce incremental gains and identify which layer contributes most to hard tasks.
  2. Measure token consumption across turn counts to verify bounded growth; compare against baseline to quantify efficiency gains.
  3. Inject deliberate errors in early turns and measure recovery rate with vs. without DA note updates to validate error correction claims.

## Open Questions the Paper Calls Out

- **Generalizability to smaller models**: It is unclear if smaller models possess the necessary capacity to utilize the abstracted memory notes (DA) and strategies (LTM) effectively without the strong priors of a frontier model like Gemini 2.5. Evaluation using open-source backbones (e.g., Llama 3, Mistral) on TurnBench-MS would resolve this.

- **Performance on semantic tasks**: TurnBench-MS focuses on hidden rule inference; it is untested whether the "distilled notes" mechanism preserves sufficient semantic detail for tasks like creative writing or empathetic dialogue. Benchmarks on semantic-heavy datasets (e.g., MT-Bench or LongBench) comparing summary-based memory to full-history baselines would resolve this.

- **Latency overhead**: While token usage is analyzed, the paper does not quantify the wall-clock time added by the asynchronous summarization and vector search steps per turn. Time-to-first-token (TTFT) and total turn latency measurements comparing the full CogMem pipeline against the baseline model would resolve this.

## Limitations

- **Memory configuration unknowns**: Critical parameters including embedding dimensions, similarity thresholds, exact note schema/format, and LTM distillation criteria are not specified, significantly impacting reproducibility.

- **Two-agent cost structure**: Computational overhead metrics for Memory Agent operations (summarization, LTM queries, note updates) are omitted, focusing only on token savings rather than complete efficiency analysis.

- **Session boundary definitions**: The mechanism for identifying "inheritable sessions" and determining when to reuse cached reasoning states is described but not precisely specified, affecting both efficiency gains and consistency claims.

## Confidence

- **High confidence** in the hierarchical memory architecture design and its alignment with cognitive memory models. The three-layer separation with distinct persistence and access patterns is well-grounded in established cognitive science.

- **Medium confidence** in the quantitative results and claimed performance improvements. While the accuracy progression and bounded token growth are demonstrated on TurnBench-MS, lack of specific configuration details creates uncertainty about exact reproducibility.

- **Low confidence** in the generalizability across domains and model sizes. The evaluation is confined to one benchmark with rule-discovery games, and all experiments use Gemini 2.5 Flash models.

## Next Checks

1. **Configuration sensitivity analysis**: Systematically vary key parameters including embedding dimensions (128, 256, 512), similarity thresholds (0.6, 0.7, 0.8), and note summary lengths to quantify their impact on both accuracy and token efficiency.

2. **Cross-domain generalization test**: Evaluate CogMem on established reasoning benchmarks beyond TurnBench-MS, such as GSM8K for mathematical reasoning or HotpotQA for multi-hop question answering.

3. **Cost-benefit analysis with timing metrics**: Measure end-to-end latency for single-turn and multi-turn interactions across all configurations, including overhead from Memory Agent operations and two-pass context reconstruction, to provide complete efficiency picture beyond token savings.