---
ver: rpa2
title: Shuffle and Joint Differential Privacy for Generalized Linear Contextual Bandits
arxiv_id: '2602.00417'
source_url: https://arxiv.org/abs/2602.00417
tags:
- theorem
- privacy
- lemma
- algorithm
- bandits
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents the first algorithms for generalized linear
  contextual bandits under shuffle differential privacy and joint differential privacy.
  The key contributions are: (1) a shuffle-DP algorithm for stochastic contexts achieving
  $\tilde{O}(d^{3/2}\sqrt{T}/\sqrt{\varepsilon})$ regret, and (2) a joint-DP algorithm
  for adversarial contexts achieving $\tilde{O}(d\sqrt{T}/\sqrt{\varepsilon})$ regret.'
---

# Shuffle and Joint Differential Privacy for Generalized Linear Contextual Bandits

## Quick Facts
- arXiv ID: 2602.00417
- Source URL: https://arxiv.org/abs/2602.00417
- Authors: Sahasrajit Sarmasarkar
- Reference count: 40
- One-line primary result: First algorithms for GL contextual bandits under shuffle-DP (stochastic contexts) and joint-DP (adversarial contexts), achieving $\tilde{O}(d^{3/2}\sqrt{T}/\sqrt{\varepsilon})$ and $\tilde{O}(d\sqrt{T}/\sqrt{\varepsilon})$ regret respectively without instance-dependent $\kappa$ dependence.

## Executive Summary
This paper introduces the first algorithms for generalized linear contextual bandits under shuffle differential privacy (DP) and joint differential privacy. The key insight is that by using a warm-up phase with scaled design matrices, the instance-dependent parameter $\kappa$ (which can be exponential in dimension) can be removed from the dominant $\sqrt{T}$ regret term. The shuffle-DP algorithm achieves $\tilde{O}(d^{3/2}\sqrt{T}/\sqrt{\varepsilon})$ regret for stochastic contexts, while the joint-DP algorithm achieves $\tilde{O}(d\sqrt{T}/\sqrt{\varepsilon})$ regret for adversarial contexts. Both algorithms maintain the same regret rates as their non-private counterparts up to privacy-dependent terms.

## Method Summary
The paper presents two algorithms: ShuffleGLM for stochastic contexts under shuffle-DP and JointGLM for adversarial contexts under joint-DP. ShuffleGLM uses batched G-optimal design with shuffled vector summation and a private convex optimizer (PGD), while JointGLM employs a binary-tree mechanism for continual release with a modified switching criterion that compares against the running maximum determinant. Both algorithms remove dependence on the instance-specific parameter $\kappa$ from the dominant $\sqrt{T}$ term by using a warm-up phase to establish a coarse estimate, then scaling subsequent design matrices to absorb the $\kappa$ factor into the confidence width.

## Key Results
- Shuffle-DP algorithm achieves $\tilde{O}(d^{3/2}\sqrt{T}/\sqrt{\varepsilon})$ regret, removing $\kappa$ dependence from the dominant term
- Joint-DP algorithm achieves $\tilde{O}(d\sqrt{T}/\sqrt{\varepsilon})$ regret, also removing $\kappa$ dependence
- Both algorithms match non-private regret rates up to $1/\sqrt{\varepsilon}$ factor
- Privacy analysis shows switching times are differentially private through binary tree decomposition

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Regret bounds can avoid dependence on the instance-specific parameter $\kappa$ (which can be exponential in dimension) in the dominant $\sqrt{T}$ term by using a warm-up phase and scaled design matrices.
- **Mechanism:** An initial warm-up phase (Batch $B_1$) incurs $\kappa$-dependent regret but establishes a coarse estimate $\hat{\theta}_1$. Subsequent batches use this estimate to construct scaled design matrices $H_k$ which absorb the $\kappa$ factor into the confidence width rather than the regret accumulation.
- **Core assumption:** The warm-up phase provides a sufficiently accurate initial estimate such that subsequent arm scaling effectively bounds the non-linearity.
- **Evidence anchors:** [abstract]: "Both algorithms remove dependence on the instance-specific parameter $\kappa$... from the dominant $\sqrt{T}$ term."; [Page 6, Algorithm 2]: "The warm-up batch $B_1$ incurs $\kappa$-dependent regret, but provides an estimate... subsequent batches can use scaled design matrices $H_k$ which absorb the $\kappa$ factor..."

### Mechanism 2
- **Claim:** The standard rarely-switching argument holds even when noise injection via the binary-tree mechanism makes design matrices non-monotone.
- **Mechanism:** Instead of triggering a policy update when the current determinant exceeds a threshold, the algorithm compares the current determinant against the **running maximum** determinant observed so far. This modification bounds the number of switches at $O(d \log T)$.
- **Core assumption:** The noise added to the design matrix is symmetric and bounded (specifically, $\|\hat{T}_s - T_s\|_2 \le \lambda/(4(\sqrt{d}+1))$).
- **Evidence anchors:** [Page 6, Section 6]: "We introduce a modified switching criterion that compares against the running maximum determinant... Lemma O.4 proves this modification preserves both the $O(d \log T)$ bound..."; [Page 30, Lemma O.4]: Proves the bound on switching steps using the determinant of the noisy estimate.

### Mechanism 3
- **Claim:** The set of exploration switching times $T_o$ is differentially private even though the decision to switch depends on the data itself.
- **Mechanism:** Privacy is analyzed by decomposing the log-likelihood ratio across the binary tree structure. Since changing one data point affects only $O(\log T)$ nodes in the tree, Gaussian composition over these nodes bounds the total privacy loss.
- **Core assumption:** Independence of noise added to different nodes in the binary tree and bounded sensitivity of the underlying statistic.
- **Evidence anchors:** [Page 6, Section 6]: "We prove that $T_o \setminus \{t\}$ is $(\varepsilon, \delta)$-indistinguishable... The proof decomposes the log-likelihood ratio across the binary tree structure."; [Page 22, Lemma I.5]: States the indistinguishability of switching indicators.

## Foundational Learning

- **Concept: Generalized Linear Models (GLM) & Link Functions**
  - **Why needed here:** Unlike linear models, GLMs do not have closed-form estimators, necessitating private convex optimization. Understanding the link function $\mu$ and the self-concordance parameter $\kappa$ is essential to grasp why removing $\kappa$ from the regret bound is difficult.
  - **Quick check question:** Can you explain why the lack of a closed-form ridge estimator forces the use of a private convex optimizer (PGD) rather than simple noise addition?

- **Concept: Shuffle vs. Joint Differential Privacy**
  - **Why needed here:** The paper presents two distinct algorithms based on the trust model (Shuffle) and context generation (Joint/Adversarial). Understanding the distinction is critical for choosing the correct implementation.
  - **Quick check question:** In which scenario would you use Joint DP instead of Shuffle DP, and how does this choice affect the context assumptions (stochastic vs. adversarial)?

- **Concept: Binary Tree Mechanism (Continual Observation)**
  - **Why needed here:** The Joint DP algorithm relies on this mechanism to release statistics at every round efficiently without linearly degrading privacy.
  - **Quick check question:** How does the binary tree mechanism ensure that the privacy cost scales logarithmically with time $T$ rather than linearly?

## Architecture Onboarding

- **Component map:** Local Randomizer -> Shuffler/Tree -> Analyzer -> Private Optimizer (PGD) -> Action Selector
- **Critical path:**
  1.  **Input:** Context $X_t$ observed.
  2.  **Update Mechanism:** Depending on the switching criterion (exploration vs. exploitation), update the design matrix via the appropriate privacy mechanism (Shuffle or Binary Tree).
  3.  **Optimization:** Run the Private Convex Optimizer (PGD) on the history buffer to update $\hat{\theta}$.
  4.  **Action:** Select arm based on UCB/LCB derived from the noisy matrix and $\hat{\theta}$.

- **Design tradeoffs:**
  - **Batching vs. Per-round:** The Shuffle model requires batching (less adaptivity) but achieves central-DP-level guarantees. The Joint model allows per-round decisions but requires the complexity of the Binary Tree mechanism.
  - **Accuracy vs. Privacy:** The regularization $\lambda$ must be set high enough to absorb privacy noise, which can increase estimation bias if not tuned correctly.

- **Failure signatures:**
  - **Exploding Switch Count:** If `count1` or `count2` exceed cutoffs, it implies the design matrices are too noisy or the switching threshold is too sensitive.
  - **High Regret Plateaus:** If regret scales linearly or grows excessively with $\kappa$, the warm-up phase initialization has failed.

- **First 3 experiments:**
  1.  **Baseline Comparison (Synthetic):** Reproduce the probit model experiment (Table 2) comparing against RS-GLinUCB to verify that regret remains stable as $\kappa$ increases (validating the $\kappa$-removal mechanism).
  2.  **Privacy Budget Calibration:** Vary $\epsilon$ (e.g., 2, 4, 8) and plot the privacy-dependent term in the regret bound to confirm the $1/\sqrt{\epsilon}$ scaling matches theory.
  3.  **Switching Frequency Analysis:** Log the number of policy switches (`count2`) over time to verify it stays bounded by $O(d \log T)$ despite the non-monotone noisy matrices.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the gap between the upper bound $\tilde{O}(d^{3/4}\sqrt{T}/\sqrt{\varepsilon})$ and the lower bound $\Omega(d/\varepsilon)$ for the privacy-dependent term be closed for joint-DP generalized linear contextual bandits?
- **Basis in paper:** [explicit] Remark 6.3 states: "Our upper bound has a privacy-dependent term of $\tilde{O}(d^{3/4}\sqrt{T}/\sqrt{\varepsilon})$, while the lower bound suggests $\Omega(d/\varepsilon}$. We note that this gap is not specific to GLMs: even for the simpler setting of joint-DP linear contextual bandits, the same gap persisted and was posed as an open problem in [21]."
- **Why unresolved:** The gap between $d^{3/4}$ and $d$ dependence persists even in simpler linear bandit settings; closing it requires new analytical techniques.
- **What evidence would resolve it:** An algorithm achieving $\tilde{O}(d\sqrt{T}/\sqrt{\varepsilon})$ regret matching the lower bound, or a stronger lower bound showing $d^{3/4}$ is unavoidable.

### Open Question 2
- **Question:** Can distributional optimal design be adapted to satisfy differential privacy constraints, thereby removing the extra $\sqrt{d}$ factor in the shuffle-DP regret bound?
- **Basis in paper:** [explicit] Remark 4.4 states: "While [27, 8] use distributional optimal design, we use G-optimal design because we could not compute the former under differential privacy constraints. This choice incurs an additional $\sqrt{d}$ factor in the leading regret term."
- **Why unresolved:** Distributional optimal design requires computing distributions over arms in a way that leaks information under DP; privatizing this computation remains unsolved.
- **What evidence would resolve it:** A shuffle-DP mechanism that privately computes distributional optimal designs, or a proof that the $\sqrt{d}$ factor is unavoidable under shuffle-DP.

### Open Question 3
- **Question:** Can matching lower bounds be established for generalized linear models under shuffle and joint differential privacy?
- **Basis in paper:** [explicit] The conclusion states: "Future work will focus on tightening these regret bounds for generalized linear models and establishing matching lower bounds for this privacy setting."
- **Why unresolved:** The current lower bound in Section 7 applies to fixed public contexts with central DP; extending to stochastic/adversarial contexts under shuffle/joint DP requires new hardness constructions.
- **What evidence would resolve it:** A lower bound showing the $\tilde{O}(d^{3/2}\sqrt{T}/\sqrt{\varepsilon})$ shuffle-DP rate is optimal, or an improved algorithm closing any gap.

## Limitations

- The algorithms assume known bounds on problem parameters ($\kappa$, $\|\theta^*\|$) that may not be available in practice
- Shuffle-DP algorithm requires batching, reducing adaptivity compared to per-round algorithms
- Binary tree mechanism introduces computational overhead and requires careful parameter tuning to balance privacy and utility

## Confidence

- **High Confidence:** The theoretical regret bounds and their comparison to non-private benchmarks are mathematically rigorous.
- **Medium Confidence:** The experimental results are promising but limited in scope (only two synthetic settings). The practical performance near non-private baselines needs broader validation across diverse problem instances.
- **Medium Confidence:** The privacy analysis relies on specific boundedness assumptions (bounded contexts, rewards, and parameters) that may not hold in all practical applications.

## Next Checks

1. **Generalization Testing:** Implement the algorithms on diverse synthetic and real-world datasets (e.g., recommendation systems, clinical trials) to verify robustness beyond the two demonstrated settings.
2. **Parameter Sensitivity Analysis:** Systematically vary the regularization parameter $\lambda$ and privacy budget $\varepsilon$ to quantify their impact on regret performance and switching frequency.
3. **Ablation Study:** Compare the proposed algorithms against simpler private bandit algorithms (e.g., adding Gaussian noise to linear bandit algorithms) to isolate the benefit of the sophisticated mechanisms employed.