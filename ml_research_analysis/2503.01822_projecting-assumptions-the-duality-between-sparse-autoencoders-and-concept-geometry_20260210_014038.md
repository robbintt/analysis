---
ver: rpa2
title: 'Projecting Assumptions: The Duality Between Sparse Autoencoders and Concept
  Geometry'
arxiv_id: '2503.01822'
source_url: https://arxiv.org/abs/2503.01822
tags:
- concepts
- saes
- data
- spade
- relu
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# Projecting Assumptions: The Duality Between Sparse Autoencoders and Concept Geometry

## Quick Facts
- arXiv ID: 2503.01822
- Source URL: https://arxiv.org/abs/2503.01822
- Authors: Sai Sumedh R. Hindupur; Ekdeep Singh Lubana; Thomas Fel; Demba Ba
- Reference count: 40
- Primary result: SAE architectures are not neutral; they impose structural assumptions about concept geometry that determine what they can detect.

## Executive Summary
This paper reveals that sparse autoencoders (SAEs) are not neutral feature extractors but impose structural assumptions about concept geometry through their encoder architecture. The authors introduce a framework where different SAE encoders (ReLU, TopK, JumpReLU) act as "projection nonlinearities" that map inputs onto specific constraint sets, defining what concepts can be detected. They propose SpaDE, a new SAE architecture using Euclidean distance and probability simplex projections, which can discover concepts that standard SAEs miss due to nonlinear separability or heterogeneous intrinsic dimensionality.

## Method Summary
The paper introduces SpaDE, an SAE architecture that computes Euclidean distances to prototype weights and projects onto the probability simplex via Sparsemax. This enables adaptive sparsity where the number of active latents varies per concept based on its intrinsic dimensionality. The method is evaluated against standard SAEs (ReLU, JumpReLU, TopK) on synthetic datasets testing nonlinear separability and heterogeneous dimensionality, as well as real-world activations from a 2-layer Transformer and DINOv2 vision model. Training uses distance-weighted L1 regularization and cosine decay learning rate schedules.

## Key Results
- ReLU and JumpReLU SAEs achieve bounded F1 scores (≤0.5) on nonlinearly separable concepts separated by magnitude rather than angle, while SpaDE achieves F1=1.0
- SpaDE adapts sparsity to match concept intrinsic dimensionality, whereas TopK SAEs show high reconstruction error when fixed sparsity mismatches concept dimension
- On real-world data, SpaDE shows improved monosemanticity and lower cross-concept correlations compared to baselines

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** An SAE's ability to detect concepts is determined by the alignment between its encoder's structural assumptions and the geometry of the data.
- **Mechanism:** SAE encoders act as "projection nonlinearities" that map inputs onto specific constraint sets (e.g., ReLU projects to positive orthant, TopK to k-sparse subspaces). These projections define "receptive fields" that determine what concepts can be detected.
- **Core assumption:** Concepts possess consistent geometric structure that matches the SAE's projection set.
- **Break condition:** If concepts don't conform to the geometry implied by the SAE's projection set, the mechanism fails.

### Mechanism 2
- **Claim:** Euclidean distance-based encoders can capture concepts that are nonlinearly separable, whereas standard linear encoders cannot.
- **Mechanism:** ReLU creates "half-space" receptive fields. If concepts are separated by norm rather than angle, linear boundaries cannot isolate them. SpaDE computes Euclidean distances to prototypes, creating receptive fields as unions of convex polytopes that can isolate local clusters regardless of linear separability.
- **Core assumption:** Concepts are locally clustered such that Euclidean distance serves as a valid discriminative metric.
- **Break condition:** If concepts are not locally clustered or Euclidean distance is not meaningful in activation space.

### Mechanism 3
- **Claim:** Projecting latents onto the probability simplex enables adaptive sparsity for concepts of heterogeneous intrinsic dimensionality.
- **Mechanism:** Standard TopK fixes sparsity level k. If one concept requires 6 dimensions and another 126, fixed k fails. SpaDE projects onto probability simplex using Sparsemax, allowing latents to be 1-sparse, 2-sparse, or dense, adapting to each concept's intrinsic dimension.
- **Core assumption:** Different concepts require varying numbers of basis vectors to be faithfully reconstructed.
- **Break condition:** If regularization forces solutions to simplex corners too aggressively, latents may capture noise rather than generalizable concepts.

## Foundational Learning

- **Concept: Projection Nonlinearity**
  - **Why needed here:** To understand that SAE architectures implicitly force data into specific shapes (positive orthant, simplex, etc.)
  - **Quick check:** Does a ReLU SAE assume data is best separated by hyperplanes or by radial distance?

- **Concept: Intrinsic Dimensionality**
  - **Why needed here:** To grasp why fixed-sparsity SAEs fail when concepts require different amounts of information
  - **Quick check:** If a concept lies on a 2D manifold and another on a 50D manifold, will a fixed-sparsity SAE encode both efficiently?

- **Concept: Bilevel Optimization**
  - **Why needed here:** To frame SAE training as outer problem (dictionary learning) constrained by inner problem (encoder architecture)
  - **Quick check:** In this framework, does the encoder architecture solve the reconstruction problem or merely constrain feasible solutions?

## Architecture Onboarding

- **Component map:** Input x -> Encoder (SpaDE: computes Euclidean distance d(x,W), applies Sparsemax to probability simplex) -> Latents z -> Decoder (linear with dictionary D) -> Reconstruction

- **Critical path:**
  1. Initialize prototype weights W
  2. Compute distances between input batch and prototypes
  3. Apply Sparsemax (enforces sum(z)=1 and z≥0, enabling adaptive sparsity)
  4. Reconstruct and compute loss (MSE + locality regularizer)

- **Design tradeoffs:**
  - ReLU/JumpReLU vs. SpaDE: ReLU assumes linear separability (global structure); SpaDE assumes distance-based separability (local structure)
  - TopK vs. SpaDE: TopK is computationally simpler but rigid; SpaDE is flexible but requires full distance matrix computation

- **Failure signatures:**
  - Overspecialization: Latents splitting into tiny sub-clusters if temperature λ is too high
  - Co-occurrence: High cosine similarity between latents if distance assumption is violated

- **First 3 experiments:**
  1. Synthetic Separability: Train on Gaussian clusters with varying norms; verify ReLU fails on low-norm clusters while SpaDE succeeds
  2. Synthetic Heterogeneity: Train on clusters with dimensions 6, 14, 30, etc.; verify TopK error correlates with dimension mismatch while SpaDE adapts
  3. Real-world Validation: Train on DINOv2/GPT activations; inspect if SpaDE separates classes/PoS better using F1 scores and latent co-occurrence matrices

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** What geometric properties of concepts beyond nonlinear separability and heterogeneity should be incorporated into SAE design?
- **Basis:** "Data properties beyond those considered here may be crucial for improved SAE performance"
- **Why unresolved:** Only two properties analyzed; other potentially important geometric properties unexplored
- **What evidence would resolve it:** Systematic characterization of concept geometry in real model activations

### Open Question 2
- **Question:** How does SpaDE perform on concepts that are not well-separated by Euclidean distance?
- **Basis:** "SpaDE implicitly assumes concepts are separated by Euclidean distance, which may still result in latent co-occurrence"
- **Why unresolved:** Not evaluated on datasets where concepts violate Euclidean distance assumption
- **What evidence would resolve it:** Experiments on synthetic/real datasets with non-Euclidean concept structures

### Open Question 3
- **Question:** How should SAE architectures be modified to handle overlapping, non-mutually-exclusive concepts?
- **Basis:** "While our arguments about SAE assumptions hold even when concepts overlap, the expected co-occurrence structure may differ"
- **Why unresolved:** All experiments use mutually exclusive concepts
- **What evidence would resolve it:** Experiments on data with controlled concept overlap

### Open Question 4
- **Question:** Does improved concept geometry matching translate to better performance on downstream interpretability tasks?
- **Basis:** Paper focuses on concept recovery metrics but doesn't evaluate steering/control efficacy
- **Why unresolved:** Link between concept geometry fidelity and steering efficacy untested
- **What evidence would resolve it:** Intervention experiments comparing SAE architectures on steering ability

## Limitations
- The core "projection duality" theorem remains largely conceptual without direct geometric validation
- Real-world experiments show smaller effect sizes than synthetic ones, suggesting proposed mechanisms may be less critical in practice
- SpaDE introduces additional hyperparameters (prototype initialization, temperature schedule) whose optimal values may be task-specific

## Confidence
- **High Confidence:** SAE architecture imposes structural assumptions on concept detection; Euclidean distance encoders can capture nonlinearly separable concepts
- **Medium Confidence:** Probability simplex projection enables adaptive sparsity for heterogeneous dimensionality; real-world SpaDE improvements
- **Low Confidence:** Existing SAEs fail primarily due to ignoring geometric properties

## Next Checks
1. Generate synthetic data where concepts are clearly separated by norm but not angle; visualize receptive fields learned by ReLU vs. SpaDE encoders; directly measure if receptive field geometry matches theoretical predictions
2. Train SpaDE variants where distance-weighted regularizer is removed or projection changed from simplex to TopK; isolate which architectural component drives performance improvements
3. For real-world experiments, compute F1 scores separately for each concept type rather than averaging; test if SpaDE consistently outperforms baselines across all concept types or only specific ones