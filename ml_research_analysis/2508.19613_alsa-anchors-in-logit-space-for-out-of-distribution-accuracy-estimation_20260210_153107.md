---
ver: rpa2
title: 'ALSA: Anchors in Logit Space for Out-of-Distribution Accuracy Estimation'
arxiv_id: '2508.19613'
source_url: https://arxiv.org/abs/2508.19613
tags:
- alsa
- distribution
- anchors
- logit
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of estimating model accuracy on
  unlabeled, out-of-distribution (OOD) datasets under distribution shifts, a critical
  challenge in real-world ML deployment. The proposed ALSA (Anchors in Logit Space
  for Accuracy estimation) operates directly in logit space to preserve richer information
  than softmax-based methods, which compress logits and lose magnitude differences.
---

# ALSA: Anchors in Logit Space for Out-of-Distribution Accuracy Estimation

## Quick Facts
- **arXiv ID:** 2508.19613
- **Source URL:** https://arxiv.org/abs/2508.19613
- **Authors:** Chenzhi Liu; Mahsa Baktashmotlagh; Yanran Tang; Zi Huang; Ruihong Qiu
- **Reference count:** 40
- **Primary result:** ALSA achieves consistently lower mean absolute error (MAE) than softmax- and similarity-based baselines for estimating accuracy on unlabeled, out-of-distribution datasets across vision, language, and graph benchmarks.

## Executive Summary
This paper addresses the problem of estimating model accuracy on unlabeled, out-of-distribution (OOD) datasets under distribution shifts, a critical challenge in real-world ML deployment. The proposed ALSA (Anchors in Logit Space for Accuracy estimation) operates directly in logit space to preserve richer information than softmax-based methods, which compress logits and lose magnitude differences. ALSA introduces learnable anchors in logit space, each with an influence function that captures subtle variations in logits, enabling robust accuracy estimation. Extensive experiments on vision, language, and graph benchmarks demonstrate ALSA's superiority over both softmax- and similarity-based baselines, with consistently low mean absolute error (MAE) across diverse distribution shifts, including subpopulation, synthetic, and temporal shifts. ALSA's robustness under significant distribution shifts highlights its potential as a practical tool for reliable model evaluation.

## Method Summary
ALSA operates by placing learnable anchors in the logit space of a pre-trained classifier and using distance-based influence functions to estimate the probability of correct predictions. Given raw logits from a classifier, ALSA computes the influence of each anchor (positioned, sized, and weighted during training) on the logit vector using cosine distance. The influences are aggregated and passed through a sigmoid function to estimate the probability of correctness. A rectification step maps low-influence predictions to random guessing ($1/c$) to handle uncertainty. Anchors are learned by minimizing binary cross-entropy between predicted and actual correctness on a labeled validation set, stopping when validation accuracy matches ground truth. This framework is applied to unlabeled OOD test sets to estimate accuracy.

## Key Results
- ALSA consistently achieves lower MAE than softmax-based and similarity-based baselines across diverse datasets and distribution shifts.
- Operating in logit space preserves magnitude information that is lost in softmax normalization, improving accuracy estimation.
- ALSA demonstrates robustness under significant distribution shifts, including subpopulation, synthetic, and temporal shifts, with stable performance across vision, language, and graph benchmarks.

## Why This Works (Mechanism)

### Mechanism 1: Logit Magnitude Preservation
Operating directly in logit space retains variance and magnitude information that is compressed or lost during softmax normalization. The softmax function is invariant to constant shifts, which flattens distinctions between high-confidence and low-confidence vector magnitudes. By aggregating logits directly, the model preserves the "band width" of the data distribution.

### Mechanism 2: Spatial Topology of Correctness
The spatial location of a logit vector within the logit hyperplane is strongly correlated with the probability of a correct prediction. Logits tend to cluster near a $(c-1)$-dimensional hyperplane, with correct predictions aggregating in specific regions. ALSA places "anchors" in this space; if a logit is close to an anchor with a positive "peak influence," the probability of correctness increases via a Gaussian-like influence function.

### Mechanism 3: Uncertainty Rectification via Thresholding
Treating low-influence predictions as "random guesses" ($1/c$) rather than "50/50 uncertainty" improves aggregate accuracy estimation. When a logit is far from all learned anchors, the cumulative influence approaches zero. A raw sigmoid output would default to 0.5 (probability of correct). This mechanism corrects that to $1/c$ (random guessing among $c$ classes), which is a more realistic prior for "unknown" regions.

## Foundational Learning

- **Concept: Logit Space vs. Probability Space**
  - **Why needed here:** ALSA explicitly rejects the standard practice of using softmax outputs. Understanding the non-linear compression of softmax is vital to understanding why ALSA works.
  - **Quick check question:** Why would two vectors, one with magnitudes $[10, 2]$ and another $[5, 1]$, produce the same softmax probability but represent different confidence levels in logit space?

- **Concept: Influence Functions (Gaussian/RBF)**
  - **Why needed here:** The paper models correctness probability using a distance-based influence function (similar to Radial Basis Functions).
  - **Quick check question:** In Equation 1, how does increasing the variance parameter $v_j$ change the "reach" of an anchor?

- **Concept: Distribution Shift (Covariate vs. Concept Shift)**
  - **Why needed here:** The method assumes validation data is sufficiently representative to "learn" anchors that generalize to shifted test data.
  - **Quick check question:** If the relationship between input $X$ and label $Y$ changes completely (concept shift), would anchor positions learned on validation data still be valid?

## Architecture Onboarding

- **Component map:** Raw Logits -> Anchor Module (k anchors: position, peak, variance) -> Influence Aggregator (cosine distance + weighted sum) -> Sigmoid -> Rectifier (threshold check, enforce $1/c$) -> Estimated Accuracy.

- **Critical path:**
  1. Extract logits from the pre-trained classifier on the validation set.
  2. Initialize anchors (e.g., sample random validation logits).
  3. **Learn Anchors:** Minimize Binary Cross Entropy (Eq 9) between predicted correctness (via influence) and actual correctness on validation data.
  4. **Inference:** Pass unlabeled test logits through the fixed anchors, sum influences, apply sigmoid, and rectify low-confidence outputs.

- **Design tradeoffs:**
  - **Gaussian vs. Exponential Influence:** Gaussian (ALSA-G) decays quadratically (faster falloff), while Exponential (ALSA-E) decays more gradually. The paper suggests Exponential can be better for certain shifts (Table 1/2).
  - **Number of Anchors:** Too few anchors miss complex probability regions; too many increase computation linearly without proportional gain (Appendix J).

- **Failure signatures:**
  - **Extreme Corruption:** Under severe synthetic corruption (e.g., CIFAR-10C max severity), the method tends to overestimate accuracy as the structural assumptions break down (Appendix I.3).
  - **Stalled Learning:** If training loss plateaus without reaching the stopping criterion (Eq 10), the anchor count $k$ may be insufficient for the complexity of the dataset.

- **First 3 experiments:**
  1. **Sanity Check (Validation Fit):** Train ALSA on the validation set and verify it can perfectly overfit the known accuracy before testing on OOD data.
  2. **Baseline Comparison:** Run ALSA-G vs. ATC (softmax baseline) on a moderate shift dataset (e.g., CIFAR-10.1) to observe the "information loss" delta.
  3. **Rectification Ablation:** Disable the rectification step (Section 3.3) and observe the change in MAE on datasets with high uncertainty/low accuracy to validate the $1/c$ assumption.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the ALSA framework be theoretically guaranteed or modified to remain robust when the conditional distribution $p(y|z)$ changes significantly between source and target domains (concept shift)?
- **Basis in paper:** [explicit] Appendix I.3 states the method "assumes approximate alignment between the source and target conditional distributions" and notes a tendency to overestimate in "extreme corruption cases" where this assumption fails.
- **Why unresolved:** The current theory relies on the covariate shift assumption and the structural consistency of the logit "bandwidth"; it lacks a mechanism to detect or adjust for shifts in the relationship between logits and correctness.
- **What evidence would resolve it:** A modified loss function or rectification step that detects conditional divergence, validated on benchmarks with explicit, severe concept shift where standard ALSA currently fails.

### Open Question 2
- **Question:** Can the confidence interval $\alpha$ or the number of anchors be determined adaptively based on the intrinsic complexity or density of the validation logit distribution?
- **Basis in paper:** [inferred] Appendix J.1 and J.2 analyze the sensitivity of MAE to the confidence interval $\alpha$ and number of anchors, showing that incorrect settings lead to under- or over-estimation, but provide no automated rule for selection.
- **Why unresolved:** The current implementation relies on manual tuning or fixed heuristics (e.g., peak value of 6), which may not generalize optimally to all dataset sizes or dimensionalities without search.
- **What evidence would resolve it:** An algorithm that sets $\alpha$ or anchor count based on logit space metrics (e.g., variance or density estimation) that achieves lower MAE than fixed defaults across diverse datasets.

### Open Question 3
- **Question:** Is there a theoretical justification for selecting a specific influence function (e.g., Gaussian-like vs. Exponential) based on the geometry of the model's logit clusters?
- **Basis in paper:** [inferred] Section 3.2 introduces the influence function but states "the choice... is not unique," offering Gaussian and Exponential options without theoretical criteria for preferring one over the other.
- **Why unresolved:** While both are evaluated, it remains unclear if the decay rate of the influence function must match specific statistical properties of the classifier's confidence distribution to minimize error.
- **What evidence would resolve it:** A theoretical analysis linking the heavy-tailedness of the logit distribution to the optimal decay rate of the influence function, supported by empirical results on architectures with varying calibration properties.

## Limitations

- **Anchor learning hyperparameters are not fully specified**, including learning rate, optimizer choice, and initialization strategy for anchors.
- **The method assumes the validation set is IID with the test set**, and performance degrades under severe concept shift where the relationship between input $X$ and label $Y$ changes.
- **ALSA tends to overestimate accuracy under extreme synthetic corruption**, suggesting the structural assumptions about logit distribution may fail under severe distribution shifts.

## Confidence

- **Logit Magnitude Preservation:** High confidence. Supported by clear theoretical arguments and empirical evidence in Section 2.2.
- **Spatial Topology of Correctness:** Medium confidence. The claim is supported by ablation studies and visualizations, but the underlying geometric assumptions may not hold under severe shifts.
- **Uncertainty Rectification via Thresholding:** Medium confidence. The $1/c$ correction is logically sound and supported by rationale in Appendix E, but its effectiveness depends on the distribution of low-influence samples.

## Next Checks

1. **Baseline Comparison:** Run ALSA-G vs. ATC (softmax baseline) on a moderate shift dataset (e.g., CIFAR-10.1) to quantify the "information loss" delta from operating in logit space versus probability space.

2. **Rectification Ablation:** Disable the rectification step (Section 3.3) and observe the change in MAE on datasets with high uncertainty/low accuracy to validate the $1/c$ assumption and its impact on accuracy estimation.

3. **Extreme Corruption Test:** Evaluate ALSA under severe synthetic corruption (e.g., CIFAR-10C max severity) to identify the failure threshold where spatial assumptions break down and accuracy overestimation occurs.