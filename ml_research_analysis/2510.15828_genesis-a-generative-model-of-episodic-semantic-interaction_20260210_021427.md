---
ver: rpa2
title: 'GENESIS: A Generative Model of Episodic-Semantic Interaction'
arxiv_id: '2510.15828'
source_url: https://arxiv.org/abs/2510.15828
tags:
- episodic
- memory
- semantic
- capacity
- cortical-vae
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces GENESIS, a computational model that formalizes
  memory as the interaction between two limited-capacity generative systems: a Cortical-VAE
  supporting semantic learning and a Hippocampal-VAE supporting episodic encoding
  and retrieval within a retrieval-augmented generation architecture. The model successfully
  reproduces key behavioral findings including generalization in semantic memory,
  recognition, serial recall effects, gist-based distortions in episodic memory, and
  constructive episodic simulation.'
---

# GENESIS: A Generative Model of Episodic-Semantic Interaction

## Quick Facts
- **arXiv ID**: 2510.15828
- **Source URL**: https://arxiv.org/abs/2510.15828
- **Reference count**: 17
- **Primary result**: Introduces GENESIS, a computational model integrating semantic and episodic memory via two limited-capacity VAEs within a retrieval-augmented generation framework, successfully reproducing key behavioral findings in human memory.

## Executive Summary
This paper introduces GENESIS, a computational model that formalizes memory as the interaction between two limited-capacity generative systems: a Cortical-VAE supporting semantic learning and a Hippocampal-VAE supporting episodic encoding and retrieval within a retrieval-augmented generation architecture. The model successfully reproduces key behavioral findings including generalization in semantic memory, recognition, serial recall effects, gist-based distortions in episodic memory, and constructive episodic simulation. It demonstrates how capacity constraints shape the fidelity and memorability of experiences, how semantic processing introduces systematic distortions in episodic recall, and how episodic replay can recombine previous experiences.

## Method Summary
GENESIS consists of two complementary VAEs operating at different timescales: a Cortical-VAE for semantic memory that learns compressed representations of colored digits, and a Hippocampal-VAE for episodic memory that encodes sequences of these semantic representations. The Cortical-VAE is a conditional β-VAE with FiLM conditioning trained on Colored MNIST (32x32, 10 digits, 5 colors) with capacity constraints ranging from 0 to 8 nats. The Hippocampal-VAE is an MLP-based β-VAE that compresses item embeddings extracted from the frozen Cortical-VAE. A retrieval-augmented generation system stores keys (Hippocampal latent + temporal embeddings) and values (Cortical embeddings) to enable episodic recall. The model is evaluated on generalization tasks, recognition memory across varying list lengths, and serial recall with recency effects.

## Key Results
- Successfully reproduces generalization in semantic memory with degradation as cortical capacity decreases
- Demonstrates recognition accuracy degradation with increasing list length in episodic memory
- Captures serial recall effects including recency bias and forward lag in temporal reconstruction
- Shows gist-based distortions in episodic recall when semantic representations are imperfect
- Enables constructive episodic simulation through recombination of stored experiences

## Why This Works (Mechanism)
The model works by creating a dual-system architecture where semantic memory (Cortical-VAE) learns to compress and generalize across experiences, while episodic memory (Hippocampal-VAE) preserves specific temporal sequences. The capacity constraints on both systems create the resource limitations that drive the observed behavioral effects. When cortical capacity is low, semantic representations become coarse, leading to gist-based distortions during recall. The hippocampal capacity limits determine how many episodes can be stored and accurately retrieved. The retrieval-augmented generation framework allows episodic memories to be reconstructed using semantic priors, creating the constructive nature of human memory.

## Foundational Learning
- **Colored MNIST Generation**: Why needed - creates controlled experimental stimuli with semantic (digit) and perceptual (color) dimensions; Quick check - verify 5 distinct colors are assigned consistently across digits
- **Conditional β-VAE with FiLM**: Why needed - enables semantic learning with capacity constraints; Quick check - monitor KL divergence and reconstruction quality during training
- **Temporal Embeddings with Rotation**: Why needed - encodes recency information for serial recall; Quick check - verify angular distance decreases monotonically over time
- **RAG Architecture**: Why needed - enables efficient episodic retrieval and reconstruction; Quick check - test retrieval accuracy with varying list lengths
- **Capacity Constraint Loss**: Why needed - implements resource limitations central to behavioral effects; Quick check - observe KL divergence tracking the specified capacity value

## Architecture Onboarding

**Component Map**: Colored MNIST -> Cortical-VAE -> Item Embeddings -> Hippocampal-VAE -> Temporal Embeddings -> RAG Memory -> Episodic Reconstruction

**Critical Path**: Semantic learning (Cortical-VAE) -> Episodic encoding (Hippocampal-VAE) -> Retrieval (RAG) -> Reconstruction (Cortical-VAE decoder)

**Design Tradeoffs**: Limited capacity in semantic system creates generalization but introduces distortions; limited episodic capacity constrains how many experiences can be stored; temporal embedding trade-off between recency and primacy effects

**Failure Signatures**: 
- Posterior collapse (KL divergence near zero, blurry reconstructions)
- Random retrieval order (no recency effects in serial recall)
- Poor generalization (classification accuracy drops with minimal capacity reduction)

**First Experiments**:
1. Train Cortical-VAE at C=0 nats for 10 epochs; verify posterior collapse occurs
2. Implement RAG system; test retrieval accuracy across list lengths from 1 to 10 items
3. Run serial recall simulation with φ=0.5; confirm recency effect shows decreasing recall probability with lag position

## Open Questions the Paper Calls Out
None

## Limitations
- Exact RGB values for Colored MNIST colors are not specified, requiring assumptions
- Temporal embedding initialization dimension is implicit from concatenation requirements
- The Graham-Smith algorithm for temporal angle schedule is referenced but not fully detailed
- Claims about neurobiological plausibility are speculative and not directly testable

## Confidence
**High confidence**: The conceptual framework (Cortical-VAE + Hippocampal-VAE + RAG) and overall training pipeline are clearly specified and verifiable

**Medium confidence**: Behavioral findings follow from model mechanisms but exact magnitudes depend on precise hyperparameter tuning

**Low confidence**: Neurobiological plausibility claims are speculative and not directly testable

## Next Checks
1. Train the Cortical-VAE at C=0 nats for 10 epochs; verify that KL divergence collapses to near zero and reconstructions become blurry or identical across inputs
2. Implement rotation-based temporal embeddings with φ=0.5; confirm probability of correct recall decreases monotonically with lag position and disappears when φ=0
3. Train Cortical-VAE at C=8 nats and C=1 nat; measure leave-one-pair-out classifier accuracy to confirm that generalization degrades sharply as capacity is reduced