---
ver: rpa2
title: Are We Really Learning the Score Function? Reinterpreting Diffusion Models
  Through Wasserstein Gradient Flow Matching
arxiv_id: '2509.00336'
source_url: https://arxiv.org/abs/2509.00336
tags:
- diffusion
- flow
- neural
- process
- field
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Diffusion models are typically interpreted as learning the score\
  \ function\u2014the gradient of the log-density of noisy data. However, this assumption\
  \ implies that the target is a conservative vector field, which is not enforced\
  \ by the neural network architectures used in practice."
---

# Are We Really Learning the Score Function? Reinterpreting Diffusion Models Through Wasserstein Gradient Flow Matching

## Quick Facts
- **arXiv ID**: 2509.00336
- **Source URL**: https://arxiv.org/abs/2509.00336
- **Reference count**: 30
- **Primary result**: Trained diffusion networks violate conservative field constraints yet generate well; reinterpretation as Wasserstein Gradient Flow matching explains success.

## Executive Summary
Diffusion models are conventionally understood as learning the score function—the gradient of log-density of noisy data. However, this implies the target is a conservative vector field, which is not enforced by standard neural architectures. Through numerical experiments, the authors demonstrate that trained diffusion networks violate both integral and differential constraints required of true score functions, yet still perform remarkably well as generative models. They propose a new theoretical perspective: diffusion training is better understood as flow matching to the velocity field of a Wasserstein Gradient Flow (WGF), rather than as score learning for reverse-time stochastic differential equations. This WGF framework naturally explains why probability flow ODEs emerge and why non-conservative approximations don't necessarily harm density transport.

## Method Summary
The authors train lightweight U-Net architectures (~4MB) with cosine scheduling to minimize L² error between neural velocity and analytically computed Wasserstein Gradient Flow velocity. They test conservativity constraints by computing line integrals of predicted scores around closed paths (should be zero for conservative fields) and Jacobian symmetry (∂s_i/∂x_j should equal ∂s_j/∂x_i). The WGF velocity field v_WGF = -x - ∇log ρ is derived from energy functional variation, showing equivalence between Fokker-Planck equation density evolution and gradient descent in Wasserstein geometry via the JKO scheme.

## Key Results
- Trained diffusion networks systematically violate both integral and differential constraints of conservative vector fields
- Despite non-conservative errors, generation remains successful because error fields approximately satisfy Stein operator null kernel condition
- Uniform time weighting in diffusion training is naturally justified under flow matching but appears ad hoc under reverse-time SDE frameworks
- The WGF perspective provides a principled theoretical foundation that eliminates need for reverse-time SDE theory while explaining probability flow emergence

## Why This Works (Mechanism)

### Mechanism 1
Trained diffusion networks learn useful vector fields that are not conservative score functions, yet remain effective because approximation errors are confined to a null kernel of the Stein operator. The neural network violates integral constraints (∮ s_θ·dx ≠ 0) and differential constraints (∂s_i/∂x_j ≠ ∂s_j/∂x_i), but generation succeeds because the error field e(x,t) = s(x,t) - NN(x,t) approximately satisfies ∇·e + s^T·e ≈ 0, meaning errors don't corrupt marginal density evolution governed by the generalized Liouville equation.

### Mechanism 2
Diffusion training is operationally equivalent to flow matching against the Wasserstein Gradient Flow velocity field v_WGF = -x - ∇log ρ, bypassing the need for reverse-time SDE theory. The Fokker-Planck equation describing the forward OU process can be reinterpreted via the JKO scheme as gradient descent on an energy functional E[ρ] = ∫(x²/2)ρ dx + ∫ρ log ρ dx in Wasserstein geometry. Training minimizes L² error between neural velocity and this WGF velocity; inference integrates the learned ODE backward.

### Mechanism 3
Uniform time weighting in diffusion training is naturally justified under flow matching, but appears ad hoc under reverse-time SDE/log-likelihood frameworks. Flow matching treats each time step as equally important for learning the velocity field, while log-likelihood maximization involves non-uniform time-dependent weights. DDPM's success by removing these weights effectively solved a flow-matching problem rather than likelihood optimization.

## Foundational Learning

- **Conservative vector fields**: A field is conservative if it equals the gradient of a scalar potential. Score functions s(x,t) = ∇log ρ(x,t) must be conservative; violations indicate the neural network isn't learning a true score. Quick check: Given a 2D vector field F(x,y), what test determines if F is conservative?

- **Wasserstein Gradient Flow & JKO scheme**: Provides theoretical grounding for reinterpreting diffusion as deterministic flow in probability measure space, explaining why probability flow ODEs emerge naturally. Quick check: In the JKO scheme, what two terms comprise the functional minimized at each implicit Euler step?

- **Fokker-Planck equation (forward Kolmogorov)**: Connects the stochastic forward SDE to deterministic density evolution; establishes equivalence between stochastic sample paths and WGF marginal evolution. Quick check: For dX_t = -X_t dt + √2 dW_t, write the FPE governing the density ρ(x,t).

## Architecture Onboarding

- **Component map**: Forward process (OU) -> Analytically compute target score s(x,t) -> Neural score/velocity network (U-Net) -> L² flow matching training -> Backward ODE integration for inference

- **Critical path**: Sample x_0 ~ data, generate x_t via forward SDE → Compute analytic score s(x_t, t) using transition kernel → Minimize ||NN(x_t, t) - s(x_t, t)||² across t ∈ {1,...,T} → At inference, integrate learned ODE backward from Gaussian prior

- **Design tradeoffs**: Architectural: Standard U-Nets lack conservativity constraints—enforcing them could improve theoretical soundness but may harm expressiveness. Training: Uniform vs. weighted time schedules—uniform aligns with flow matching but departs from strict likelihood bounds. Sampling: Deterministic ODE vs. stochastic SDE reverse—WGF framework naturally yields ODE.

- **Failure signatures**: High integral constraint violation in high-density regions indicates learned field far from conservative; may still generate well if error confined to Stein null kernel. Stein operator values ≫ 0 means error field corrupts density transport; expect sample quality degradation. Non-zero differential constraints at early t (near data) means local non-conservativity where precision matters most.

- **First 3 experiments**: 1) Reproduce constraint violations: Train MNIST diffusion, compute ∮ s_θ·dx along rotation paths and |∂s_i/∂x_j - ∂s_j/∂x_i| across time indices. 2) Stein null kernel test: Compute e(x,t) = s(x,t) - NN(x,t) and evaluate ∇·e + s^T·e on held-out samples. 3) Conservative regularization ablation: Add soft penalty on ||∂s_i/∂x_j - ∂s_j/∂x_i||² to loss and compare sample quality vs. baseline.

## Open Questions the Paper Calls Out

- **Sample-path equivalence**: Do non-conservative neural approximations disrupt the equivalence of sample paths between the reverse-time SDE and the probability flow ODE? The authors state they don't make claims about sample-path equivalence, limiting their theoretical claims to marginal densities. Evidence would come from comparing sample trajectories from neural ODE against theoretically exact reverse-time SDE.

- **Regularization exploitation**: Can the theoretical "error field" condition be exploited as an explicit regularization term during training? The authors suggest the framework could inspire regularizing flow-based models but don't experiment with enforcing the null-kernel condition. Evidence would come from training experiments using an auxiliary loss term penalizing deviations from the identified null-kernel condition.

- **Feature or bug**: Is the violation of conservative field constraint a beneficial feature or detrimental approximation error of current architectures? It's unclear if non-conservative nature is merely tolerated or provides implicit regularization that aids generative performance. Evidence would come from comparative studies of standard architectures against strictly constrained conservative architectures.

## Limitations
- Core numerical claims about constraint violations rely on specific implementations not fully specified, creating reproducibility gaps
- Theoretical connection between Stein operator null space and density preservation is established numerically but lacks formal proof
- Limited corpus evidence directly validates the Wasserstein Gradient Flow reinterpretation—related work establishes connections but doesn't test conservativity constraints

## Confidence

- **High confidence**: Numerical demonstration that trained diffusion networks violate conservative vector field constraints is directly supported by presented figures and equations
- **Medium confidence**: Claim that violations don't harm generation because errors lie in Stein null kernel is supported by numerical evidence but theoretical justification could be more rigorous
- **Medium confidence**: Reinterpretation as Wasserstein Gradient Flow matching is theoretically elegant and operationally equivalent, but paper doesn't fully explore edge cases where equivalence might break down

## Next Checks
1. **Conservative regularization ablation**: Add soft penalty on Jacobian asymmetry to training loss and measure impact on both constraint satisfaction and sample quality (FID)
2. **Time-dependent constraint analysis**: Quantify integral and differential constraint violations as a function of time index t to identify whether violations are uniformly distributed or concentrated in specific regions
3. **Alternative architectures**: Train diffusion models with explicitly conservative architectures (e.g., potential parameterization) and compare to standard unconstrained networks on constraint satisfaction and generation performance