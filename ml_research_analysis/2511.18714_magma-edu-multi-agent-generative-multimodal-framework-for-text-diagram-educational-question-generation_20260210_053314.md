---
ver: rpa2
title: 'MAGMA-Edu: Multi-Agent Generative Multimodal Framework for Text-Diagram Educational
  Question Generation'
arxiv_id: '2511.18714'
source_url: https://arxiv.org/abs/2511.18714
tags:
- image
- angle
- text
- multimodal
- question
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "MAGMA-Edu introduces a training-free multi-agent framework for\
  \ generating multimodal educational questions with text\u2013diagram pairs. It addresses\
  \ the challenge of creating pedagogically coherent and semantically consistent educational\
  \ visuals by decomposing the task into a two-stage process: text refinement (Stage\
  \ 1) and code-based diagram generation (Stage 2), each guided by iterative generation\u2013\
  verification\u2013reflection loops."
---

# MAGMA-Edu: Multi-Agent Generative Multimodal Framework for Text-Diagram Educational Question Generation

## Quick Facts
- arXiv ID: 2511.18714
- Source URL: https://arxiv.org/abs/2511.18714
- Authors: Zhenyu Wu; Jian Li; Hua Huang
- Reference count: 40
- Primary result: Training-free framework achieving Avg-Text 96.20 and ITC 99.12, outperforming GPT-4o baseline (Avg-Text 57.01, ITC 13.20).

## Executive Summary
MAGMA-Edu introduces a training-free multi-agent framework for generating multimodal educational questions with text–diagram pairs. It addresses the challenge of creating pedagogically coherent and semantically consistent educational visuals by decomposing the task into a two-stage process: text refinement (Stage 1) and code-based diagram generation (Stage 2), each guided by iterative generation–verification–reflection loops. Stage 1 produces mathematically accurate problem statements and image descriptions, while Stage 2 translates these descriptions into executable drawing code to ensure geometric fidelity and semantic alignment. Compared to GPT-4o, MAGMA-Edu improves average textual metrics from 57.01 to 92.31 (+35.3 pp) and boosts image–text consistency from 13.20 to 85.24 (+72 pp). Across all model backbones, it achieves the highest scores (Avg-Text 96.20, ITC 99.12), establishing a new state of the art for multimodal educational content generation.

## Method Summary
MAGMA-Edu employs a two-stage co-evolutionary pipeline: (1) a generation-verification-reflection loop that iteratively refines question statements and solutions for mathematical accuracy, and (2) a code-based intermediate representation that enforces geometric fidelity and semantic alignment during image rendering. The framework uses specialized agents (Generator, Validator, Reflector) in each stage to achieve autonomous quality improvement without external feedback or fine-tuning. The system generates executable Matplotlib code from image descriptions, which is then rendered and validated against textual content to ensure semantic consistency.

## Key Results
- Achieves highest textual quality scores across all model backbones: Avg-Text 96.20, ITC 99.12
- Outperforms GPT-4o baseline by +35.3 percentage points in average textual metrics
- Improves image–text consistency from 13.20 to 85.24 (+72 percentage points)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decomposing multimodal educational content generation into separate text refinement and code-based diagram stages improves pedagogical coherence.
- Mechanism: The framework employs a sequential pipeline where Stage 1 first iteratively refines text and image descriptions using a generation-verification-reflection loop. Only after this textual component is verified does Stage 2 translate descriptions into executable drawing code. This constrained separation prevents errors in one modality from cascading into the other.
- Core assumption: Separating problem statement generation from visual rendering allows for more focused verification and correction at each stage, with text providing a stable specification for visual synthesis.
- Evidence anchors:
  - [abstract] "MAGMA-Edu employs a two-stage co-evolutionary pipeline: (1) a generation-verification-reflection loop that iteratively refines question statements and solutions for mathematical accuracy, and (2) a code-based intermediate representation that enforces geometric fidelity and semantic alignment during image rendering."
  - [section 4] Details the two-stage methodology, with Stage 1 focusing on Q_text(T) and Stage 2 on Q_visual(G) and Consistency(T*, G).
  - [corpus] "Multi-Agent Collaborative Framework For Math Problem Generation" also uses multi-stage decomposition, supporting the efficacy of this approach for complex educational tasks.
- Break condition: If Stage 1 fails to converge on a semantically complete and unambiguous problem description, Stage 2 diagram generation will produce inconsistent or incorrect visuals regardless of code quality.

### Mechanism 2
- Claim: Internal multi-agent generate-validate-reflect loops enable autonomous quality improvement without external feedback or fine-tuning.
- Mechanism: Each stage employs specialized agents in a cycle: a Generator produces drafts, a Validator evaluates against predefined metrics, and a Reflector synthesizes feedback into actionable revision instructions. This loop continues until quality thresholds are met or maximum iteration count is reached.
- Core assumption: Validator agents can reliably assess quality and Reflector agents can produce actionable, non-contradictory revision instructions that lead to convergence rather than oscillation.
- Evidence anchors:
  - [abstract] "Both stages are guided by internal self-reflection modules that evaluate and revise outputs until domain-specific pedagogical constraints are met."
  - [section 4.1, 4.2] Detail the three-agent loops for text (Text Generator, Validator, Reflector) and four-agent loops for images (Code Generator, Executor, Validator, Reflector).
  - [corpus] Corpus evidence is moderate; related papers employ multi-agent collaboration but do not directly validate the specific generate-validate-reflect pattern for educational content.
- Break condition: If validation criteria are poorly defined or if agents enter repetitive correction cycles with contradictory feedback, the process will fail to converge on high-quality output.

### Mechanism 3
- Claim: Using executable code as an intermediate representation for diagrams enforces geometric precision and semantic alignment better than direct pixel-based image generation.
- Mechanism: Instead of generating images directly, the system generates Python/Matplotlib code that a deterministic executor renders. This code can be syntactically validated and its logic checked against textual descriptions, ensuring labeled elements and spatial relationships are explicitly defined.
- Core assumption: Code Generator Agents can produce syntactically correct and semantically faithful code, and validation logic can interpret code structure in relation to text descriptions.
- Evidence anchors:
  - [abstract] "a code-based intermediate representation that enforces geometric fidelity and semantic alignment during image rendering"
  - [section 4.2, Appendix D] Provides code examples and Figure 4 comparison showing code-based images are more accurate than LLM-generated ones.
  - [corpus] "Multi-Agent Collaborative Framework For Math Problem Generation" also leverages code for geometry, while "Generating Pedagogically Meaningful Visuals for Math Word Problems" finds text-to-image models lacking for precise diagrams.
- Break condition: If generated code contains subtle logic errors not caught by syntax or semantic validators, rendered images will be incorrect despite the code-based approach. Validators must possess deep semantic understanding of both text and code.

## Foundational Learning

- Concept: **Multi-Agent Systems (MAS)**
  - Why needed here: Core architectural pattern of MAGMA-Edu. Understanding how autonomous agents are assigned specialized roles (Generator, Validator, Reflector) and how they communicate is fundamental.
  - Quick check question: How do the Validator and Reflector agents contribute to self-correction in a way a single model could not achieve?

- Concept: **Iterative Refinement / Reflection in LLMs**
  - Why needed here: Framework's performance gain is explicitly linked to its Generate–Validate–Reflect loop. Grasping chain-of-thought reasoning and self-correction principles is crucial.
  - Quick check question: Why is an iterative process with explicit validation steps often more effective for complex tasks than single-pass generation?

- Concept: **Programmatic Image Generation**
  - Why needed here: Unlike most generative AI that outputs pixels, this system uses code to create diagrams. Understanding advantages (determinism, editability, precision) is key.
  - Quick check question: What are the primary benefits of generating diagrams via executable code compared to direct image-generation model output?

## Architecture Onboarding

- Component map:
  - **Stage 1 (Text Generation):** Text Generator Agent (creates problem draft with question, answer, explanation, image description) → Text Validator Agent (evaluates against six metrics: UO, LR, QF, AA, CA, IDQ) → Text Reflector Agent (aggregates feedback, provides revision instructions)
  - **Stage 2 (Image Generation):** Code Generator Agent (writes Python/Matplotlib code from image description) → Code Executor Agent (runs code to render diagram) → Image Validator Agent (validates syntax, code-text alignment, image-text consistency) → Image Reflector Agent (analyzes validation, suggests corrections)
  - **Orchestration:** Hidden controller managing flow between stages/agents, implementing loop termination logic (thresholds τ or I_max)

- Critical path: `User Prompt → Text Generator → [Validation Loop] → Verified Text & Image Description → Code Generator → Code Executor → Image Validator → [Correction Loop] → Final Question (Text + Diagram)`. Entire pipeline success depends on Stage 1 text quality as specification for Stage 2.

- Design tradeoffs:
  - **Latency vs. Quality:** Iterative loops improve quality but increase generation time; I_max parameter directly controls this tradeoff.
  - **Agent Backbone Choice:** Paper shows different models excel at different tasks; choosing involves tradeoffs between cost, speed, and capability in textual vs. visual reasoning.
  - **Rule-Based vs. Learned Validation:** Validators use mixed rule-based checks and LLM reasoning; fully learned systems are more flexible but less interpretable.

- Failure signatures:
  - **Non-Convergence:** System loops until I_max without meeting quality thresholds, producing subpar output—signals flaw in validation/reflection logic.
  - **Cascading Errors:** Undetected Stage 1 text errors lead to "correct" but nonsensical Stage 2 diagrams; cross-modal consistency check is primary defense.
  - **Code Hallucination:** Code Generator produces syntactically valid but semantically incorrect code (e.g., triangle instead of circle); Image Validator must catch this.

- First 3 experiments:
  1. **Validate Single Agent Role:** Select Code Generator agent, provide fixed image description, manually validate if generated code is syntactically correct and semantically faithful.
  2. **Trace Full Iteration:** Run full pipeline on simple problem, manually inspect intermediate JSON outputs at each step to understand how Reflector feedback transforms Generator output in next iteration.
  3. **Ablate Validation Metric:** Disable one metric (e.g., Correct Answer) and observe if final output frequently contains corresponding errors—demonstrates specific metric contribution.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the code-based intermediate representation effectively generalize to broader STEM domains beyond mathematics, such as chemistry or biology, where diagrams may not be strictly geometric?
- Basis in paper: [explicit] The Conclusion states, "In future work, we will extend MAGMA-Edu to broader STEM domains... enabling automated curriculum design."
- Why unresolved: The current framework and experiments focus specifically on mathematics (geometry, functions) where "executable drawing code" (Section 4.2) is well-defined. It is unclear if Matplotlib or TikZ are sufficient for organic or complex scientific illustrations.
- What evidence would resolve it: Results from applying MAGMA-Edu to non-math STEM datasets, showing successful code generation for diagrams like molecular structures or biological cells.

### Open Question 2
- Question: How can symbolic reasoning be more deeply integrated with the neural generation agents to further enhance the fidelity of educational content?
- Basis in paper: [explicit] The Conclusion notes, "We also plan to explore deeper integration of symbolic reasoning with neural generation to further enhance the fidelity and explainability."
- Why unresolved: The current framework relies on LLM-based agents for generation and validation (Section 4), which may still be prone to subtle logical hallucinations that formal symbolic systems would catch.
- What evidence would resolve it: Ablation studies comparing the current LLM-only validation against a hybrid system incorporating formal mathematical solvers (e.g., Wolfram Alpha integration) on complex reasoning problems.

### Open Question 3
- Question: Does the strict reliance on "programmatic intermediate representation" limit the pedagogical effectiveness of diagrams compared to natural, hand-drawn styles?
- Basis in paper: [inferred] Section 4.2 and Figure 4. The paper prioritizes "geometric fidelity" via code (Matplotlib) to fix the "semantic misalignment" of MLLs. However, Figure 4 shows the code-based output is rigid and grid-like, whereas the "real" examples in textbooks might be more organic.
- Why unresolved: The paper optimizes for metric-based consistency (ITC) but does not assess if the "soulless" or overly rigid nature