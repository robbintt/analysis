---
ver: rpa2
title: 'SF$^2$Bench: Evaluating Data-Driven Models for Compound Flood Forecasting
  in South Florida'
arxiv_id: '2506.04281'
source_url: https://arxiv.org/abs/2506.04281
tags:
- data
- forecasting
- time
- series
- stations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "SF2Bench is a new comprehensive time series dataset for compound\
  \ flood forecasting in South Florida, integrating five key factors: water level,\
  \ sea level, groundwater, rainfall, and human control activities. It addresses the\
  \ scarcity of multi-factor flood datasets by covering 2,452 monitoring stations\
  \ over 67,349 km\xB2 from 1985 to 2024."
---

# SF$^2$Bench: Evaluating Data-Driven Models for Compound Flood Forecasting in South Florida

## Quick Facts
- arXiv ID: 2506.04281
- Source URL: https://arxiv.org/abs/2506.04281
- Reference count: 40
- SF2Bench is a new comprehensive time series dataset for compound flood forecasting in South Florida, integrating five key factors: water level, sea level, groundwater, rainfall, and human control activities.

## Executive Summary
SF2Bench introduces a comprehensive time series dataset for compound flood forecasting in South Florida, integrating five key factors across 2,452 monitoring stations from 1985 to 2024. The dataset enables systematic analysis of how multiple drivers contribute to compound flooding. The authors benchmark six categories of deep learning methods—including MLPs, CNNs, RNNs, GNNs, Transformers, and LLMs—on SF2Bench, revealing that transformer-based models excel in standard accuracy metrics while GNNs perform best for extreme event prediction.

## Method Summary
SF2Bench covers 2,452 monitoring stations over 67,349 km² with hourly data from 1985-2024. The dataset includes water level, groundwater, rainfall, pump control, and gate control variables. Models are evaluated using 8 temporal splits, with z-score normalization per station and linear interpolation for missing continuous values. Six model categories are benchmarked: MLPs, CNNs, RNNs, GNNs (FourierGNN), Transformers (iTransformer, PatchTST), and LLMs (GPT4TS, AutoTimes). Performance is measured using MAE, MSE, and SEDI at 10%, 5%, and 1% quantile thresholds.

## Key Results
- Transformer-based models (iTransformer, PatchTST) and MLPs excel in MAE and MSE metrics
- GNNs (FourierGNN) perform best on extreme event prediction (SEDI)
- Groundwater information is particularly effective for forecasting accuracy
- Increasing both spatial and temporal input lengths improve forecasting accuracy

## Why This Works (Mechanism)

### Mechanism 1
Groundwater levels provide particularly informative signals for compound flood forecasting, outperforming other auxiliary factors like rainfall and human control. Groundwater dynamics reflect soil saturation capacity, which directly modulates how additional water inputs translate to surface flooding.

### Mechanism 2
Graph Neural Networks capture spatial dependencies critical for predicting extreme flood events. Extreme floods propagate across monitoring stations through river/canal networks, and GNNs explicitly model these spatial relationships via graph edges.

### Mechanism 3
Increasing temporal lookback window improves forecasting accuracy, but with diminishing returns beyond ~1 day for some architectures. Longer lookback provides more historical context for detecting slow-building flood conditions, though it increases optimization difficulty.

## Foundational Learning

- **SEDI (Symmetric Extremal Dependence Index)**: Needed to quantify how well models capture events at distribution tails, which standard MAE/MSE metrics miss. Quick check: If a model predicts 0.95 MAE but misses all 99th-percentile flood events, is it useful for early warning systems?

- **Compound flooding (multi-driver interaction)**: Needed because floods in South Florida result from concurrent tide, rainfall, groundwater, and human control—not single drivers. Quick check: Can a model trained only on rainfall data accurately predict flooding during a high-tide, low-groundwater-capacity event?

- **Channel-dependent vs. channel-independent modeling**: Needed to understand how multi-factor data is processed. Channel-independent treats each variable separately; channel-dependent mixes them. Quick check: If groundwater and rainfall have different temporal scales, should they share the same attention mechanism or be processed independently?

## Architecture Onboarding

- **Component map**: Input layer (5 modalities from 2,452 stations × L timesteps) -> Spatial encoder (optional GNN) -> Temporal encoder (variable) -> Fusion mechanism -> Output head
- **Critical path**: Load split-specific data -> Apply z-score normalization per station -> Handle missing values -> Select lookback L and horizon T -> Train with MSE loss, evaluate MAE/MSE/SEDI
- **Design tradeoffs**: MLP/Transformer vs. GNN (average accuracy vs. extreme detection), lookback length (accuracy vs. compute), channel handling (robustness vs. cross-factor interactions)
- **Failure signatures**: SEDI near 0 while MAE is low (model smoothing extremes), performance degrades with longer lookback (architecture cannot handle long sequences), removing groundwater hurts more than removing rainfall
- **First 3 experiments**: 1) Reproduce PatchTST baseline with 2-day lookback on split S6, 2) Ablate groundwater input to confirm relative importance, 3) Swap PatchTST for FourierGNN and compare SEDI performance

## Open Questions the Paper Calls Out

### Open Question 1
How does the integration of explicit hydraulic topology (canal/reservoir connectivity) impact the predictive performance of GNN-based architectures on this dataset? The current benchmark uses Delaunay triangulation or distance-based graphs, which do not capture the directed flow of water through canals and control structures.

### Open Question 2
Can a unified model architecture or custom loss function be developed to simultaneously optimize for both standard accuracy (MAE/MSE) and extreme event detection (SEDI)? Current standard loss functions (like MSE) penalize large errors but may not sufficiently prioritize the rare, high-magnitude events characteristic of flooding.

### Open Question 3
What spatial interpolation or alignment methods are most effective for fusing the provided flood observation data with the time-series monitoring stations? There is a spatial disconnect between point-based sensor readings (inputs) and reported flood extents (labels), hindering direct supervised learning for flood extent prediction.

## Limitations
- The dataset currently lacks explicit topological linkage information between monitoring stations due to the intricate nature of South Florida's water system
- The locations of flood observations may not directly correspond to monitoring stations, requiring spatial interpolation
- All models are evaluated only on South Florida conditions without testing generalization to other regions

## Confidence

**High confidence**: MAE/MSE benchmark results for transformer and MLP architectures; groundwater ablation study findings showing groundwater's relative importance.

**Medium confidence**: SEDI-based extreme event performance for GNNs; temporal lookback effect with diminishing returns.

**Low confidence**: Direct transfer of groundwater importance findings to other geographic regions; optimality of Delaunay triangulation for hydrological connectivity.

## Next Checks

1. Test FourierGNN on a different compound flood dataset (e.g., RiverMamba's global river dataset) to verify spatial modeling advantage generalizes beyond South Florida's specific connectivity patterns.

2. Implement a simple physics-informed loss term (e.g., mass conservation) in PatchTST and measure impact on extreme event prediction versus pure data-driven training.

3. Replace Delaunay triangulation with a hydrology-based graph (e.g., river network connectivity) and measure changes in SEDI performance to quantify the impact of spatial modeling quality.