---
ver: rpa2
title: Context-aware LLM-based AI Agents for Human-centered Energy Management Systems
  in Smart Buildings
arxiv_id: '2512.25055'
source_url: https://arxiv.org/abs/2512.25055
tags:
- energy
- agent
- user
- data
- queries
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study presents a conceptual framework and prototype for Large
  Language Model (LLM)-based AI agents to support context-aware energy management
  in smart buildings through natural language interaction. The framework consists
  of three modules: perception, central control, and action, forming a closed feedback
  loop for intelligent energy management.'
---

# Context-aware LLM-based AI Agents for Human-centered Energy Management Systems in Smart Buildings

## Quick Facts
- **arXiv ID:** 2512.25055
- **Source URL:** https://arxiv.org/abs/2512.25055
- **Reference count:** 40
- **Primary result:** 86% accuracy for device control, 97% for memory, 74% for scheduling, 77% for energy analysis, but only 49% for cost estimation

## Executive Summary
This study presents a conceptual framework and prototype for Large Language Model (LLM)-based AI agents to support context-aware energy management in smart buildings through natural language interaction. The framework consists of three modules: perception, central control, and action, forming a closed feedback loop for intelligent energy management. The prototype was evaluated using 120 user queries across four real-world residential energy datasets, assessing metrics including latency, functionality, capability, accuracy, and cost-effectiveness. Results showed promising performance, with response accuracy of 86% for device control, 97% for memory-related tasks, 74% for scheduling and automation, and 77% for energy analysis. More complex cost estimation tasks showed lower accuracy (49%), highlighting areas for improvement. The study provides a comprehensive assessment of LLM-based AI agents in smart building applications, offering a baseline for future research and identifying the trade-off between response accuracy and computational efficiency.

## Method Summary
The method implements a three-module LLM-based AI agent architecture for building energy management. The perception module ingests real-time smart meter data, historical consumption patterns, and third-party APIs (weather, grid constraints). The brain module uses GPT-4o via OpenAI Assistants API with tool augmentation (Code Interpreter, File Search, and 9 custom functions) to process user queries through Tree-of-Thought reasoning for intent classification and Chain-of-Thought for execution planning. The action module executes device controls, schedules, and provides user feedback. The system uses a sync-query-execute workflow to prevent device hallucination and employs hierarchical intent classification (6 primary, 24 secondary categories). The prototype was evaluated on 120 benchmark queries across four residential Pecan Street datasets, measuring accuracy, latency, and token costs.

## Key Results
- Response accuracy varied significantly by task type: 86% for device control, 97% for memory, 74% for scheduling, 77% for energy analysis, 49% for cost estimation
- Processing latency ranged from 6 seconds (memory tasks) to 34 seconds (cost estimation), with energy analysis averaging 22 seconds
- Token usage showed inverse correlation with accuracy: higher token consumption for complex tasks like cost management did not improve performance
- The agent autonomously generated visualizations in 33 instances without explicit user requests, demonstrating proactive behavior

## Why This Works (Mechanism)

### Mechanism 1: Three-Module Closed-Loop Architecture Enables Context-Awareness
- **Claim:** A perception-brain-action architecture enables context-aware energy management through continuous feedback loops between environment sensing, reasoning, and actuation.
- **Mechanism:** The perception module collects multimodal data (smart meters, sensors, occupancy, weather APIs); the brain module integrates this with user/building profiles and historical data for LLM-based reasoning; the action module executes device controls and provides user feedback. This closed loop captures, analyzes, and responds to energy data iteratively.
- **Core assumption:** Standardized data formats (JSON/CSV) can represent building states accurately, and the LLM can reason across multiple structured data modalities without significant information loss.
- **Evidence anchors:**
  - [abstract]: "The proposed framework comprises three modules: perception (sensing), central control (brain), and action (actuation and user interaction), forming a closed feedback loop"
  - [section 3.1.1-3.1.3]: Detailed specification of each module's components and data flows
  - [corpus]: UserCentrix (arXiv:2505.00472) supports modular agentic approaches for smart spaces with memory-augmented frameworks (FMR=0.528)

### Mechanism 2: Hierarchical Intent Classification with CoT/ToT Reasoning Improves Task Decomposition
- **Claim:** A two-level intent taxonomy (6 primary, 24 secondary categories) combined with Chain-of-Thought (CoT) and Tree-of-Thought (ToT) reasoning improves query understanding and tool selection.
- **Mechanism:** ToT enables branching exploration for intent disambiguation across multiple classification paths; CoT guides step-wise execution through intermediate reasoning steps before synthesizing final responses. This hierarchical approach maps queries to appropriate tools/functions.
- **Core assumption:** User queries can be reliably mapped to predefined intent categories, and LLM reasoning follows structured prompts without significant deviation.
- **Evidence anchors:**
  - [abstract]: Primary category classification accuracy of 91%, secondary category accuracy of 76%
  - [section 3.2.1, Table 2]: Intent taxonomy with 6 primary and 24 secondary categories synthesized from prior Human-AI interaction studies
  - [corpus]: Limited direct corpus evidence for hierarchical intent classification in BEMS; related work on LLM-based agents exists but specific intent taxonomies are domain-dependent

### Mechanism 3: Sync-Query-Execute Workflow Grounds Device Control Actions
- **Claim:** A structured sync-query-execute workflow minimizes hallucination risks in device control by validating device availability and state before command execution.
- **Mechanism:** Before executing control commands, the agent (1) synchronizes device metadata via `action-devices-SYNC`, (2) queries current device states via `action-devices-QUERY`, then (3) executes validated commands via `action-devices-EXECUTE`. This three-step pattern prevents actions on non-existent, offline, or unsupported devices.
- **Core assumption:** The device metadata in JSON files accurately reflects physical device states and capabilities at query time.
- **Evidence anchors:**
  - [abstract]: 86% accuracy for device control tasks
  - [section 3.2.2]: "A sync-query-execute workflow was implemented to ensure that the AI agent operates with grounded device information, rather than hallucinating unavailable devices"
  - [section 4.3.4]: Examples of correctly identifying offline kitchen kettle and absent TV, preventing erroneous actions
  - [corpus]: SAGE (arXiv:2311.00772, cited in discussion) employs similar grounded execution for smart home agents

## Foundational Learning

- **Concept: Modular LLM Agent Architecture (Perception-Brain-Action)**
  - **Why needed here:** Understanding how data flows between modules is essential for debugging, extending capabilities, and adapting the framework to new building configurations.
  - **Quick check question:** Can you trace the data path from a smart meter reading through the perception module, brain module reasoning, and action module response for the query "How much energy did my dishwasher use yesterday?"

- **Concept: Chain-of-Thought (CoT) vs. Tree-of-Thought (ToT) Reasoning**
  - **Why needed here:** The prototype uses ToT for intent classification (branching exploration) and CoT for step-wise execution; understanding when to apply each is critical for modifying reasoning strategies.
  - **Quick check question:** For a query like "Turn off all kitchen appliances if no one is home," which reasoning framework handles intent classification, and which handles the execution steps?

- **Concept: Tool-Augmented Function Calling with Guardrails**
  - **Why needed here:** The prototype extends LLM capabilities through Code Interpreter, File Search, and custom device/memory functions; understanding tool selection and the sync-query-execute pattern is necessary for adding new capabilities safely.
  - **Quick check question:** Why does the sync-query-execute pattern reduce hallucination risk compared to direct LLM command generation?

## Architecture Onboarding

- **Component map:** Perception module (smart meters JSON, historical energy CSV, third-party APIs) -> Brain module (LLM, profiles, memory, tools) -> Action module (user responses, device control)
- **Critical path:**
  1. User query received → ToT-based intent classification (primary + secondary category)
  2. Tool selection per Algorithm 1 (e.g., Code Interpreter for energy analysis, device functions for control)
  3. Function execution with data retrieval → CoT reasoning → Response synthesis
  4. Optional: Memory/state updates persisted to JSON files

- **Design tradeoffs:**
  - **Latency vs. Accuracy:** Cost management queries average 34s but achieve only 49% accuracy; device control averages 19s with 86% accuracy. Complex reasoning does not guarantee better results.
  - **Token Cost vs. Capability:** Energy analysis uses ~35,625 tokens/query; memory tasks use ~14,130 tokens. Higher resource usage correlates with lower accuracy for multi-step reasoning tasks.
  - **Proactive Automation vs. User Control:** Agent may autonomously create schedules or visualizations without explicit user requests (observed in 33 instances), which may not align with user preferences.

- **Failure signatures:**
  - **Cost estimation errors (49% accuracy):** Unit conversion mistakes (kW vs. kWh), misclassification of energy generation as cost rather than credit
  - **Energy prediction failures (60% accuracy):** Simplistic ML models (Random Forest, Linear Regression, ARIMA) trained on limited data (1 month, 15-minute intervals)
  - **Inefficient visualizations:** Generic single-bar charts lacking actionable insights vs. detailed daily breakdowns
  - **Intent classification bypass:** Simple queries (memory, general information) may skip structured reasoning, potentially reducing consistency

- **First 3 experiments:**
  1. **Baseline intent classification:** Run the 120 benchmark queries across all 24 secondary categories to establish primary/secondary classification accuracy per category; identify systematic misclassification patterns (e.g., energy optimization confused with energy suggestions).
  2. **Sync-query-execute validation:** Simulate device states with varying availability (online/offline, supported/unsupported traits) and verify the agent correctly handles edge cases (offline kettle, absent TV) without hallucinated actions.
  3. **Latency-accuracy profiling:** Measure processing time, token usage, and accuracy across all 6 primary categories to identify Pareto-optimal task types and prioritize optimization efforts (cost management is the weakest link).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the accuracy of complex computational tasks, specifically cost estimation, be improved in LLM-based BEMS agents?
- Basis in paper: [explicit] The authors note that cost estimation tasks showed lower accuracy (49%) and explicitly state that "Enhancements in instructional design and system architecture are necessary to further improve the AI agent’s accuracy of cost management."
- Why unresolved: The current prototype struggles with the multi-step data interpretation and analytical reasoning required for cost calculation, often misclassifying energy generation credits or using incorrect parameters.
- What evidence would resolve it: A revised agent architecture (potentially using multi-agent systems) that demonstrates significantly higher accuracy on cost estimation benchmarks compared to the reported 49% baseline.

### Open Question 2
- Question: To what extent do unanticipated, autonomously generated visualizations impact user satisfaction and decision-making effectiveness?
- Basis in paper: [explicit] The study observes that the agent often generates visualizations without explicit prompts, but notes that "the impact of unanticipated visualizations on user satisfaction with the AI agent’s responses needs further investigation in future studies."
- Why unresolved: While the agent can produce "efficient" visualizations, it also produces "inefficient" ones; it remains unclear if this autonomous behavior aids or hinders the user's ability to manage energy.
- What evidence would resolve it: User-centered studies correlating the presence of unanticipated visualizations with quantitative metrics of user satisfaction and successful task completion.

### Open Question 3
- Question: What is the net energy impact of deploying LLM-based agents when accounting for their own infrastructure-level operational costs?
- Basis in paper: [explicit] The authors state that "it would be counterproductive for BEMS AI agents... to contribute to the total energy use" and call for "life cycle evaluation of the BEMS AI agents."
- Why unresolved: The study evaluates the agent's ability to save energy for the building but does not quantify the significant GPU energy and water consumption required to run the LLM itself.
- What evidence would resolve it: A life-cycle assessment comparing the energy savings achieved by the agent against the energy consumed by the underlying model infrastructure.

## Limitations
- The evaluation framework relies on simulated device states and mock APIs, which may not capture real-world complexity of smart building infrastructure
- Cost estimation and energy prediction tasks show particularly low accuracy (49% and 60% respectively), suggesting fundamental limitations in the LLM's ability to handle quantitative energy calculations
- The study uses limited historical data (1 month of 15-minute interval readings) which may not represent seasonal variations or long-term patterns in building energy consumption

## Confidence
- **High confidence**: Three-module closed-loop architecture enables context-awareness, sync-query-execute workflow reduces hallucination risks, latency-accuracy trade-off characterization
- **Medium confidence**: Hierarchical intent classification effectiveness, tool selection methodology, proactive automation behaviors
- **Low confidence**: Energy prediction accuracy claims, cost estimation reliability, long-term memory persistence effectiveness

## Next Checks
1. Test the sync-query-execute workflow with real smart home device APIs to verify hallucination prevention works beyond simulated environments
2. Evaluate the framework with multi-month historical data to assess performance across different seasonal patterns and consumption behaviors
3. Conduct user studies to validate that proactive automation (33 observed instances) aligns with user preferences rather than creating unwanted interventions