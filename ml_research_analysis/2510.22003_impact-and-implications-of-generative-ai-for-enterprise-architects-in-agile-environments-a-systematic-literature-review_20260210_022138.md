---
ver: rpa2
title: 'Impact and Implications of Generative AI for Enterprise Architects in Agile
  Environments: A Systematic Literature Review'
arxiv_id: '2510.22003'
source_url: https://arxiv.org/abs/2510.22003
tags:
- genai
- agile
- https
- enterprise
- architects
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This systematic literature review examined the impact of generative
  AI on enterprise architects in agile environments, analyzing 33 studies from 1,697
  records. The research found that GenAI consistently supports design ideation, rapid
  artifact creation, and architectural decision-making while introducing risks including
  opacity, bias, and privacy concerns.
---

# Impact and Implications of Generative AI for Enterprise Architects in Agile Environments: A Systematic Literature Review

## Quick Facts
- **arXiv ID**: 2510.22003
- **Source URL**: https://arxiv.org/abs/2510.22003
- **Reference count**: 40
- **Primary result**: GenAI consistently supports design ideation, rapid artifact creation, and architectural decision-making while introducing risks including opacity, bias, and privacy concerns.

## Executive Summary
This systematic literature review examines the impact of generative AI on enterprise architects working in agile environments, analyzing 33 studies from an initial pool of 1,697 records. The research reveals that GenAI accelerates documentation and code generation while shifting architects' roles from primary creators to curators and validators of AI outputs. Key findings indicate that adoption depends on organizational readiness, governance maturity, and capability-building, with emerging skills like prompt engineering and model evaluation becoming critical competencies. The review highlights the need for dynamic governance frameworks to ensure responsible integration while maintaining architectural integrity.

## Method Summary
The study conducted a systematic literature review following Kitchenham and PRISMA protocols, searching IEEE Xplore and Scopus databases with four specific query sets. From 1,697 initial records, researchers applied inclusion/exclusion criteria across three screening phases (title, abstract, full-text) to identify 33 relevant studies. The review addressed five research questions through thematic analysis, mapping findings to opportunities, challenges, role evolution, adoption factors, and governance considerations.

## Key Results
- GenAI accelerates production of architectural artifacts (code, models, documentation) by automating content generation based on learned patterns
- Architects increasingly serve as curators and validators of AI outputs rather than primary creators
- Adoption depends on organizational readiness, governance maturity, and capability-building initiatives

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: GenAI accelerates production of architectural artifacts by automating content generation based on learned patterns.
- **Mechanism**: Large Language Models emulate input data structure to generate synthetic content, reducing manual drafting effort when architects provide prompts or model fragments.
- **Core assumption**: Models are trained on relevant architectural patterns and domain-specific languages sufficient to produce contextually plausible outputs.
- **Evidence anchors**: Abstract confirms GenAI supports "rapid creation and refinement of artifacts"; Section 4.1 shows LLMs accelerate architectural artifact creation; corpus supports LLM automation capabilities.
- **Break condition**: Model encounters context limits or lacks domain knowledge, producing hallucinations requiring more time to fix than manual creation.

### Mechanism 2
- **Claim**: GenAI shifts architect role from "primary creator" to "curator and validator" while maintaining architectural integrity.
- **Mechanism**: Offloading routine generation tasks to AI allows architects to focus cognitive resources on reviewing, validating, and integrating outputs.
- **Core assumption**: Architects possess necessary professional oversight and prompt engineering skills to detect subtle biases or contextually incorrect suggestions.
- **Evidence anchors**: Abstract identifies curators/validators role shift; Section 4.3 describes reconfiguration of core competencies; corpus implies curator role bridges policy-practice gaps.
- **Break condition**: "Social loafing" occurs when architects trust AI outputs without rigorous validation, leading to architectural debt.

### Mechanism 3
- **Claim**: Adoption and effectiveness depend on dynamic governance frameworks managing risk and privacy.
- **Mechanism**: GenAI introduces risks (opacity, bias, privacy) requiring "guardrails" through adaptive governance policies and traceability mechanisms.
- **Core assumption**: Organizations have maturity to implement adaptive governance rather than rigid controls that stifle agile feedback.
- **Evidence anchors**: Abstract links adoption to organizational readiness and governance maturity; Section 4.4 shows organizations with formalized AI policies integrate GenAI effectively; corpus directly links EA governance to scalable adoption.
- **Break condition**: Governance is absent (violations) or too rigid (negating speed advantage).

## Foundational Learning

- **Concept: Enterprise Architecture (EA) vs. Agile Tension**
  - **Why needed here**: Traditional EA often conflicts with agile speed; understanding this friction shows why GenAI bridges the gap by automating documentation to satisfy EA needs without slowing agile delivery.
  - **Quick check question**: Can you explain why "big design upfront" is problematic in Scrum or SAFe environments?

- **Concept: Prompt Engineering & Model Evaluation**
  - **Why needed here**: These critical emerging skills; curator mechanism fails without effective instruction and quality assessment capabilities.
  - **Quick check question**: What makes a prompt "effective" for generating a specific architectural artifact like a sequence diagram versus a generic text description?

- **Concept: Opacity and Hallucination in LLMs**
  - **Why needed here**: Primary risks listed; architects must understand why GenAI makes things up (probabilistic nature) to build appropriate validation workflows.
  - **Quick check question**: Why can't you simply trust a GenAI output for a compliance-critical architectural decision?

## Architecture Onboarding

- **Component map**: Architect (Human-in-the-Loop) -> Prompt Interface -> GenAI Engine -> Artifact Repository -> Governance & Validation Layer -> System/Product
- **Critical path**: 1. Readiness Assessment (data governance maturity, regulatory compatibility), 2. Skill Upskilling (prompt engineering, model evaluation), 3. Controlled Pilot (low-risk tasks), 4. Validation Protocol (mandatory human review)
- **Design tradeoffs**: Speed vs. Integrity (maximizing acceleration increases context error risk); Innovation vs. Compliance (open models offer better ideation but pose higher privacy risks)
- **Failure signatures**: Social Loafing (accepting AI suggestions without review), Rework Cycles (generated artifacts failing validation), Accountability Gaps (unclear ownership when AI-generated design causes failure)
- **First 3 experiments**: 1. Ideation Speed Run (measure time-to-proposal and diversity with/without GenAI), 2. Hallucination Audit (measure error rate in documentation for known systems), 3. Governance Stress Test (test data governance guardrails with sensitive data)

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: What are the longitudinal effects of GenAI adoption on architectural roles, inter-team collaboration, and enterprise agility over time?
- **Basis in paper**: [explicit] Authors state future work should pursue empirical studies on longitudinal effects.
- **Why unresolved**: Current literature is nascent and cross-sectional; no longitudinal studies identified in this SLR.
- **What evidence would resolve it**: Multi-year case studies or panel surveys tracking architects' roles and team dynamics before and after GenAI integration.

### Open Question 2
- **Question**: What principles and patterns effectively guide architects' responsible use of GenAI in agile environments?
- **Basis in paper**: [explicit] Conclusion identifies need to develop principles and patterns for effective and responsible use.
- **Why unresolved**: Existing governance frameworks need adaptation, but no validated design principles exist.
- **What evidence would resolve it**: Controlled experiments or multi-site case studies evaluating specific governance patterns against outcomes like decision quality, compliance, and role satisfaction.

### Open Question 3
- **Question**: How do GenAI impacts differ across specific architect roles (enterprise, solution, domain, business, IT) versus aggregated "architect" category?
- **Basis in paper**: [inferred] Limitation notes broad "architects" usage may blur role-specific nuances.
- **Why unresolved**: SLR synthesized findings across roles, potentially masking heterogeneity in tasks, skills, and GenAI applicability.
- **What evidence would resolve it**: Comparative studies isolating GenAI use cases and skill shifts by architect type, controlling for organizational context.

### Open Question 4
- **Question**: Which organizational readiness factors causally determine successful GenAI integration into architecture practices?
- **Basis in paper**: [inferred] Paper identifies enablers but notes many studies are conceptual/exploratory, calling for disciplined experimentation.
- **Why unresolved**: Correlational and conceptual evidence dominates; causal mechanisms remain untested.
- **What evidence would resolve it**: Quantitative studies (e.g., PLS-SEM, quasi-experiments) testing readiness factors as predictors of integration outcomes across organizations.

## Limitations
- Conclusions constrained by narrow scope (33 papers from 1,697 records) and rapidly evolving GenAI research
- Potential bias toward English-language publications and relatively recent emergence of GenAI in enterprise contexts
- Many findings based on preliminary implementations rather than mature, large-scale deployments

## Confidence
- **High Confidence**: Systematic methodology and consistent identification of GenAI's role in accelerating artifact creation and shifting responsibilities; well-documented risks of opacity, bias, and privacy
- **Medium Confidence**: Claims about adoption factors may vary significantly by industry sector and organizational culture; emerging skill requirements may evolve as technology matures
- **Low Confidence**: Predictions about long-term role evolution and effectiveness of proposed governance frameworks remain speculative given limited empirical evidence

## Next Checks
1. **Empirical Impact Study**: Conduct longitudinal study tracking GenAI adoption in enterprise architecture teams over 12-18 months, measuring productivity gains and architectural quality metrics
2. **Cross-Industry Validation**: Apply identified adoption factors and governance frameworks across different sectors (finance, healthcare, manufacturing) to identify universal versus context-dependent conditions
3. **Skills Gap Analysis**: Survey practicing enterprise architects to assess current state of critical emerging skills and identify specific training gaps, validating whether identified competency requirements align with actual practitioner needs