---
ver: rpa2
title: 'A Multidimensional AI-powered Framework for Analyzing Tourist Perception in
  Historic Urban Quarters: A Case Study in Shanghai'
arxiv_id: '2509.03830'
source_url: https://arxiv.org/abs/2509.03830
tags:
- color
- urban
- tourist
- quarters
- historic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study proposes a multidimensional AI-powered framework for
  analyzing tourist perception in historic urban quarters using multimodal social
  media data. The framework integrates semantic segmentation to identify visual focus
  areas, color theme analysis to assess aesthetic preferences, and multi-task sentiment
  modeling to evaluate satisfaction across four dimensions: tourist activities, built
  environment, service facilities, and business formats.'
---

# A Multidimensional AI-powered Framework for Analyzing Tourist Perception in Historic Urban Quarters: A Case Study in Shanghai

## Quick Facts
- **arXiv ID:** 2509.03830
- **Source URL:** https://arxiv.org/abs/2509.03830
- **Reference count:** 18
- **Primary result:** Multi-dimensional sentiment analysis reveals spatial variations in tourist satisfaction across historic quarters

## Executive Summary
This study presents a comprehensive AI-powered framework for analyzing tourist perception in historic urban quarters using multimodal social media data. The approach integrates semantic segmentation to identify visual focus areas, color theme analysis to assess aesthetic preferences, and multi-task sentiment modeling to evaluate satisfaction across four dimensions. Applied to 12 historic quarters in Shanghai, the framework reveals systematic patterns in how tourists visually engage with streetscapes and how their aesthetic preferences diverge from objective reality. The multi-dimensional sentiment analysis uncovers spatial variations in tourist experiences, providing actionable insights for heritage management and visitor-oriented urban design.

## Method Summary
The framework combines computer vision and natural language processing techniques to analyze tourist-generated content from Dianping. Semantic segmentation using DeepLabV3+ with MobileNetV2 backbone identifies which streetscape elements attract tourist attention in photos. Color theme analysis compares HSV color distributions between social media photos and Street View baselines using K-means clustering and Kolmogorov-Smirnov divergence. Multi-task sentiment classification employs BERT-base-Chinese with four independent heads to evaluate satisfaction across tourist activities, built environment, service facilities, and business formats. The models are trained on manually annotated and LLM-generated labels, then applied to 20,000+ photos and 32,949 reviews to generate district-level perception insights.

## Key Results
- Tourist photos systematically foreground key streetscape elements, with buildings (19.12%) and trees (10.80%) dominating visual attention
- Color compositions in social media diverge from real-world street views, with cool hues (green, blue) overrepresented compared to Street View's warm tones
- Satisfaction analysis reveals spatial variations in experience evaluations across the four dimensions, with specific quarters showing high/low satisfaction for different aspects

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuning semantic segmentation on domain-specific imagery identifies which physical elements capture tourist attention ("the gaze").
- Mechanism: The framework uses a DeepLabV3+ model with a MobileNetV2 backbone, trained on a custom dataset of 22 streetscape categories (e.g., building, tree, artwork). By calculating pixel proportions per class, it quantifies visual emphasis, revealing that tourist photos systematically prioritize buildings (19.12%) and trees (10.80%) over transient elements like vendors.
- Core assumption: Pixel area in a shared photo correlates positively with visual attention and perceived importance to the tourist.
- Evidence anchors:
  - [Section 3.1]: "Buildings account for the largest share, comprising 19.12% of total pixels, followed by trees at 10.80%... The aggregated results align with intuitive understanding."
  - [Section 2.3]: "Fine-tuning experiments showed that Deeplabv3+MobilenetV2... performed well... Considering the trade-offs between parameter size, computational cost, and inference speed, we ultimately adopted Deeplabv3."
  - [Corpus]: Evidence is weak in provided corpus for specific heritage segmentation; validation relies on internal dataset performance.
- Break condition: Fails if tourist photography is driven by social trends (e.g., selfies) rather than environmental features, or if distinct heritage elements fall into the same "background" class during segmentation.

### Mechanism 2
- Claim: Comparing color distributions between User Generated Content (UGC) and objective street views detects a "perception-reality" gap indicative of aesthetic curation.
- Mechanism: The framework converts images to HSV color space and applies K-means clustering to extract dominant palettes. It measures the Kolmogorov-Smirnov (KS) divergence between the hue distributions of tourist photos and Street View baselines.
- Core assumption: Street View imagery represents an objective "baseline" reality, while significant deviation in UGC reflects selective curation or "perceptual bias" rather than just lighting or camera sensor differences.
- Evidence anchors:
  - [Section 3.2]: "Cool hues (e.g., green... and blue...) are more prominent in social media content, whereas street-view baselines contain a higher proportion of warm tones... This divergence can plausibly arise from multiple mechanisms."
  - [Section 4]: "Tourists often post images with cooler, highly curated palettes that diverge from warmer street-level façades."
  - [Corpus]: [Weak/Missing] Corpus neighbors do not provide direct validation for this specific chromatic comparison method.
- Break condition: Fails if platform-side compression or automatic "beauty" filters on mobile devices are the sole causes of color shifts, rather than user intent.

### Mechanism 3
- Claim: Multi-task sentiment classification decouples satisfaction into distinct urban planning dimensions, providing higher resolution than generic polarity scores.
- Mechanism: A BERT-base-Chinese model is trained with four independent classification heads (Activities, Environment, Facilities, Business). This allows a single review to express positive sentiment for "Activities" while expressing negative sentiment for "Service Facilities" simultaneously.
- Core assumption: Tourist reviews can be reliably decomposed into these four specific planning dimensions without losing semantic context.
- Evidence anchors:
  - [Section 3.3]: "The multi-task BERT model demonstrates strong capability in capturing sentiment across four dimensions... identifying dissatisfaction with commercial composition and praise for specific event-based activities."
  - [Table 2]: Shows a review where "Built Environment" is positive (1) but "Service Facilities" is negative (-1), validating the separation of concerns.
  - [Corpus]: [Inconsistent Affective Reaction] supports the need for nuanced sentiment analysis in urban environments but does not validate this specific 4-dimension taxonomy.
- Break condition: Fails when reviews use sarcasm, or when the text is too short to contain cues for all four dimensions (though the model handles "neutral/0" for unmentioned dimensions).

## Foundational Learning

- Concept: **Semantic Segmentation (DeepLabV3 + MobileNetV2)**
  - Why needed here: To move beyond counting objects to measuring the *visual weight* of streetscape elements (façades, greenery) in tourist photography.
  - Quick check question: Can you explain why MobileNetV2 is preferred here over a heavier backbone like ResNet-101, given the need for processing thousands of high-resolution photos?

- Concept: **HSV Color Space & K-Means Clustering**
  - Why needed here: RGB does not separate chromaticity from luminance effectively for aesthetic analysis. HSV is required to isolate "Hue" for the cultural color comparison.
  - Quick check question: Why is the Gray World algorithm applied *before* K-means clustering for this specific outdoor/indoor mixed dataset?

- Concept: **Multi-Task Learning (MTL) with BERT**
  - Why needed here: A single sentiment score is insufficient for urban planners who need to know *what* specifically is failing (e.g., "crowding" vs "dirty streets"). MTL allows the model to learn shared representations across these four related tasks.
  - Quick check question: How does the loss function aggregate errors across the four classification heads during backpropagation?

## Architecture Onboarding

- Component map: Data Layer (Dianping Crawler + Baidu Street View API) -> Vision Module (DeepLabV3+ + K-Means) -> Text Module (BERT-base-Chinese) -> Integration Layer (Spatial joining)

- Critical path:
  1. **Dataset Construction:** Manually labeling 1k photos for Segmentation (Yolov8-assisted); Generating weak labels for Sentiment using DeepSeek LLM.
  2. **Model Training:** Train Segmentation (Frozen/Unfrozen stages); Train BERT (AdamW, LR=1e-5).
  3. **Inference:** Run batch inference on 20k+ photos; Extract color palettes; Classify reviews.
  4. **Analysis:** Calculate KS divergence for colors; Aggregate sentiment by quarter.

- Design tradeoffs:
  - **Labeling Strategy:** The study uses an LLM (DeepSeek) to label the sentiment dataset rather than human annotators. This scales faster but introduces "noise" and potential hallucination into the ground truth.
  - **Segmentation Architecture:** Chose DeepLabV3+MobileNetV2 over Mask2Former+Swin-L. The tradeoff favors inference speed and lower resource consumption over maximum theoretical accuracy, justified by the large batch size requirement.

- Failure signatures:
  - **Segmentation:** Small or rare items (fountains, animals) show poor recognition due to class imbalance (long-tailed distribution).
  - **Color Analysis:** Indoor vs. Outdoor scenes confuse the "façade color" analysis; the paper tries to mitigate this by masking out non-building segments.
  - **Sentiment:** Short reviews lacking context may result in all "0" (neutral) scores across dimensions.

- First 3 experiments:
  1. **Visual QA:** Run the segmentation model on 50 random street photos; verify if "Building" and "Tree" pixel masks align with visual boundaries (IoU check).
  2. **Color Consistency Check:** Extract top-5 colors from 10 Street View images and 10 "Instagram-style" photos from the same location; visually confirm if the "warm-to-cool" shift mentioned in the paper appears.
  3. **Dimension Separation:** Input a test review like "The architecture was stunning but the lines for the bathroom were terrible" into the BERT model; verify output is [0, 1, -1, 0] (or similar), confirming the model distinguishes Environment vs. Facilities.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** To what extent is the observed chromatic divergence (cool-tone enrichment) between tourist photos and street views attributable to user-side aesthetic curation versus platform-side technical processing?
- **Basis in paper:** [Explicit] The authors identify a consistent cool-tone shift in social media photos but state, "Because our dataset lacks standardized EXIF metadata... we do not attempt to attribute the observed shift to one dominant cause."
- **Why unresolved:** The study cannot isolate the specific mechanism (e.g., filters, compression, auto-white balance) causing the perception-reality gap.
- **What evidence would resolve it:** Controlled experiments using identical camera settings with/without filters, or access to platform-level image processing logs and EXIF metadata.

### Open Question 2
- **Question:** Does the proposed framework's relationship between visual attention and satisfaction remain stable when applied to historic quarters with different cultural contexts or heritage typologies?
- **Basis in paper:** [Explicit] The authors note that "transfer to other cities will require... examining whether perception–reality relationships differ across visitor groups and cultural backgrounds."
- **Why unresolved:** The current study is a single-case study in Shanghai, limiting the generalizability of the semantic taxonomy and satisfaction dimensions.
- **What evidence would resolve it:** Replicating the study in non-Chinese historic cities or across different heritage site types (e.g., archaeological vs. living heritage).

### Open Question 3
- **Question:** Can the predictive accuracy of dimension-specific satisfaction be improved by integrating quantitative street-level visual features directly into the sentiment model architecture?
- **Basis in paper:** [Explicit] The authors suggest that "integrating street-level visual features such as façade condition... into sentiment models would provide additional contextual grounding."
- **Why unresolved:** The current methodology analyzes visual and textual data in parallel but does not fuse them within the deep learning model to jointly predict satisfaction.
- **What evidence would resolve it:** A comparative performance analysis between the current text-only BERT model and a multimodal model trained on both review text and segmented image features.

## Limitations
- The framework relies heavily on automated labeling (LLM-generated sentiment annotations) without independent human validation, introducing potential noise into the sentiment analysis.
- The segmentation model struggles with rare visual elements (fountains, animals) due to class imbalance, and the color comparison assumes Street View represents objective reality without accounting for seasonal or lighting variations.
- The study focuses on one city (Shanghai) with specific heritage characteristics, limiting generalizability.

## Confidence
- **High Confidence:** Visual attention patterns (buildings/trees dominance) and sentiment dimension separation are empirically supported by pixel analysis and review classification results.
- **Medium Confidence:** Color palette divergence interpretation is plausible but lacks validation that the warm-to-cool shift isn't primarily due to technical factors (compression, filters) rather than user intent.
- **Low Confidence:** Automated sentiment labeling introduces uncertainty in the multi-dimensional satisfaction scores, as the LLM may misclassify nuanced opinions.

## Next Checks
1. **Segmentation Verification:** Manually annotate 50 random street photos with ground truth polygons and calculate IoU against the model's predictions to quantify accuracy for rare classes.
2. **Color Shift Attribution:** Extract top-5 colors from 20 photo pairs (same location, one Instagram-style, one street view) and conduct a blind visual survey to determine if humans perceive the warm-to-cool shift as aesthetic curation or technical artifact.
3. **Sentiment Label Accuracy:** Sample 100 reviews where the BERT model's predictions differ from LLM labels and have human annotators resolve the correct classification to estimate the noise rate in automated labeling.