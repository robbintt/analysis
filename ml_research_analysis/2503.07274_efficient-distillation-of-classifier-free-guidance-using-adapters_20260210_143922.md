---
ver: rpa2
title: Efficient Distillation of Classifier-Free Guidance using Adapters
arxiv_id: '2503.07274'
source_url: https://arxiv.org/abs/2503.07274
tags:
- diffusion
- guidance
- training
- trajectories
- adapters
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces Adapter Guidance Distillation (AGD), a method
  that doubles the sampling speed of classifier-free guidance (CFG) in diffusion models
  by training lightweight adapters instead of fine-tuning the entire model. Unlike
  prior methods that require two forward passes per inference step with CFG, AGD achieves
  similar or improved sample quality using only a single forward pass.
---

# Efficient Distillation of Classifier-Free Guidance using Adapters

## Quick Facts
- arXiv ID: 2503.07274
- Source URL: https://arxiv.org/abs/2503.07274
- Reference count: 40
- Primary result: Doubles sampling speed of CFG in diffusion models using lightweight adapters

## Executive Summary
This paper introduces Adapter Guidance Distillation (AGD), a method that enables classifier-free guidance (CFG) in diffusion models to run at double the speed by replacing the expensive dual forward passes with a single pass through a frozen base model plus lightweight adapters. The key innovation is training adapters on actual CFG-guided trajectories rather than standard diffusion trajectories, which addresses a critical distribution mismatch that limits previous distillation approaches. Experiments across Diffusion Transformer, Stable Diffusion 2.1, and Stable Diffusion XL demonstrate that AGD achieves comparable or superior sample quality to CFG while requiring only half the neural function evaluations, with the added benefit of being trainable on a single consumer GPU.

## Method Summary
AGD trains lightweight residual adapters (1-5% of parameters) to approximate the CFG correction term typically computed via dual forward passes. The adapters are conditioned on guidance scale ω, timestep t, and conditioning c, and are trained on trajectories generated by running the teacher model with CFG enabled. During inference, the frozen base model performs a single forward pass, and the adapter provides the CFG-like adjustment. The method requires pre-collecting CFG-guided trajectories from the teacher model, then training adapters to match the CFG predictions using L2 loss while keeping the base model frozen.

## Key Results
- AGD achieves FID 5.03 on ImageNet-256 with DiT versus CFG's 5.11 using half the NFEs
- SDXL distillation (2.6B params) achievable on single RTX 4090 GPU, while full fine-tuning OOMs
- AGD shows better guidance scale generalization than full fine-tuning, generating meaningful samples at ω=10 when trained on ω∈[1,6]
- Cross-attention adapters outperform offset adapters for text-to-image models, while offset adapters work better for DiT

## Why This Works (Mechanism)

### Mechanism 1
Training on CFG-guided trajectories reduces train-inference distribution mismatch and improves distillation quality. Standard diffusion trajectories differ significantly from guided reverse trajectories in input space. By collecting and training on actual guided trajectories, adapters learn to correct predictions in the exact input regimes encountered at inference. Evidence: AGD trained on guided trajectories achieves FID 5.03 vs 5.54 on diffusion trajectories (DiT). Break condition: Extreme guidance scales at inference may shift trajectory distributions.

### Mechanism 2
Lightweight residual adapters (~1-5% parameters) can approximate CFG's conditional-unconditional difference without modifying base weights. Adapters inject a learned correction term g_ψ(Z, ω, t, c) via residual connection after attention blocks, receiving guidance scale, timestep, and conditioning as inputs. Evidence: AGD achieves FID 5.03 with 16M params vs GD's FID 5.66 with 676M params. Break condition: Severely under-dimensioned adapters (<1% params) degrade FID significantly.

### Mechanism 3
Explicit guidance-scale conditioning enables adapters to generalize across ω values, including some out-of-distribution scales. Guidance scale ω is encoded via Fourier features + MLP and provided to adapters alongside condition embeddings. Training samples ω from a range, teaching the adapter to modulate its output based on guidance strength. Evidence: AGD generates meaningful images at ω=10 when trained on ω∈[1,6]; GD fails completely. Break condition: Extreme ω values far outside training distribution may still degrade quality.

## Foundational Learning

- **Concept**: Classifier-Free Guidance (CFG) fundamentals
  - **Why needed here**: AGD's entire purpose is to distill CFG; understanding why it doubles NFEs is prerequisite.
  - **Quick check question**: Given CFG with ω=3, how many forward passes are needed per denoising step, and what two predictions are combined?

- **Concept**: Diffusion ODE formulation and trajectory distributions
  - **Why needed here**: The core insight is that guided reverse trajectories differ from forward diffusion trajectories; understanding why requires grasping how sampling paths traverse different regions of data/noise space.
  - **Quick check question**: If you add Gaussian noise to an image (forward process) vs. run CFG-guided reverse sampling from noise, will the intermediate x_t values have the same distribution? Why or why not?

- **Concept**: Parameter-efficient fine-tuning (adapters/LoRA)
  - **Why needed here**: AGD uses adapter modules added to attention blocks; understanding residual injection, rank/dimensionality tradeoffs, and why base weights stay frozen is essential for implementation.
  - **Quick check question**: In a residual adapter g_ψ that adds to frozen layer output f_θ, what happens at initialization if adapter weights are zero-initialized vs. Xavier-initialized?

## Architecture Onboarding

- **Component map**: Base Diffusion Model (frozen θ) -> Attention Blocks -> Adapter g_ψ (trainable, ~2% params) -> Input: layer features Z, timestep t, condition c -> Guidance encoder: Fourier(ω) -> MLP -> embedding -> Output: residual added to attention output

- **Critical path**: 1) Generate CFG-guided trajectory dataset by running CFG sampling and caching (x_t, t, c, ω, ε̃_CFG) tuples 2) Initialize adapters (Xavier, not zero) and insert after attention blocks 3) Train adapters to match ε̃_CFG using L2 loss, base model frozen 4) Inference: single forward pass with adapter, no CFG computation

- **Design tradeoffs**: Adapter architecture differs by model type (offset for DiT, cross-attention for SD); adapter dimension 128 hidden dim (~2.5% params) optimal; training ω range affects generalization (wider range for better generalization but requires more trajectories)

- **Failure signatures**: Training on diffusion trajectories instead of guided trajectories causes ~0.5 FID degradation; zero initialization of adapters leads to worse FID than Xavier init; L1 loss performs poorly (FID 9.91 vs 5.03 with L2); excessive adapter capacity (>17% params) causes overfitting

- **First 3 experiments**: 1) Trajectory sanity check: compare adapter trained on CFG-guided vs. diffusion trajectories on small subset to verify ~0.5 FID improvement 2) Adapter dimensionality sweep: train offset adapters with dimensions [64, 128, 256] to confirm 128-dim sweet spot 3) Guidance scale generalization test: train on ω∈[1,6], evaluate at ω∈{2,4,6,8,10} to verify graceful degradation

## Open Questions the Paper Calls Out

### Open Question 1
Can AGD be successfully integrated with enhanced guidance algorithms (e.g., self-guidance, interval-guided methods) and adversarial distillation techniques to further reduce sampling steps beyond the current 2× speedup? Basis: The conclusion explicitly suggests this as a future research direction. Why unresolved: The paper demonstrates AGD for standard CFG only; compatibility with other guidance formulations remains unexplored. What evidence would resolve it: Experiments combining AGD with CADS, interval-guided sampling, or adversarial distillation reporting FID/NFE tradeoffs.

### Open Question 2
What explains the differential performance of adapter architectures across model types—specifically, why do offset adapters outperform cross-attention adapters for DiT while the reverse holds for text-to-image models? Basis: Tables 6 and 7 show performance differences without theoretical explanation. Why unresolved: The paper empirically selects architectures per model type without investigating the underlying mechanism. What evidence would resolve it: Analysis of attention pattern distributions or ablations isolating text-encoder versus spatial processing contributions.

### Open Question 3
How does the scale and diversity of the CFG-guided trajectory dataset impact distillation quality, and is there a saturation point beyond which additional trajectories provide diminishing returns? Basis: The paper uses only 500 COCO captions for SD2.1/SDXL trajectory collection without characterizing dataset size effects. Why unresolved: The method's data efficiency claims are not systematically tested. What evidence would resolve it: Ablation experiments varying trajectory count (100, 500, 2000, 10000 captions) and measuring FID convergence curves.

## Limitations

- Trajectory collection costs can be significant, potentially offsetting inference savings in some deployment scenarios
- Architecture specificity requires different adapter designs for different model types rather than a universal solution
- Generalization bounds for extreme guidance scales and novel conditioning distributions remain untested

## Confidence

**High Confidence**: The core distillation mechanism is well-supported by ablation studies showing trajectory-matching importance and initialization sensitivity. The 2x NFE reduction claim is straightforward to verify.

**Medium Confidence**: Claims about adapter architecture choices are supported by performance data but represent design decisions that may not generalize. The "doubles sampling speed" claim assumes comparable NFE settings between teacher and student.

**Low Confidence**: Claims about deployment accessibility don't account for trajectory collection overhead. The paper doesn't address whether AGD adapters can be combined with other parameter-efficient methods like LoRA.

## Next Checks

1. **Trajectory Collection Overhead Analysis**: Measure total time and compute required to collect CFG-guided trajectories for SDXL versus the training time of AGD adapters. Calculate the break-even point in inference volume where AGD's NFE savings offset collection costs.

2. **Cross-Architecture Adapter Transferability**: Train AGD adapters using the "wrong" architecture (e.g., cross-attention adapters on DiT or offset adapters on SD models). Quantify the performance degradation to establish whether architecture choice is critical.

3. **Extreme Guidance Scale Robustness**: Evaluate AGD trained on ω∈[1,6] at ω∈{1, 3, 6, 12, 20}. Compare failure modes against full fine-tuning and vanilla CFG to characterize the true limits of guidance scale generalization.