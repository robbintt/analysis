---
ver: rpa2
title: Joint Training And Decoding for Multilingual End-to-End Simultaneous Speech
  Translation
arxiv_id: '2503.11080'
source_url: https://arxiv.org/abs/2503.11080
tags:
- speech
- translation
- end-to-end
- training
- simultaneous
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper explores multilingual end-to-end simultaneous speech\
  \ translation, where speech in one language is translated into multiple target languages\
  \ in real time. It proposes two neural architectures\u2014a separate decoder model\
  \ and a unified model\u2014for joint synchronous training, and introduces an asynchronous\
  \ training strategy to improve cross-lingual knowledge transfer."
---

# Joint Training And Decoding for Multilingual End-to-End Simultaneous Speech Translation

## Quick Facts
- **arXiv ID:** 2503.11080
- **Source URL:** https://arxiv.org/abs/2503.11080
- **Reference count:** 0
- **Primary result:** Multilingual end-to-end simultaneous speech translation with joint training and decoding outperforms bilingual baselines.

## Executive Summary
This paper addresses multilingual end-to-end simultaneous speech translation (S2T), where speech in one source language is translated into multiple target languages in real time. The authors propose two neural architectures—a separate decoder model and a unified model—for joint synchronous training, along with an asynchronous training strategy to enhance cross-lingual knowledge transfer. A new multi-way aligned multilingual speech translation dataset is curated for evaluation. Experiments show that both proposed models significantly outperform bilingual baselines, with the unified model achieving the best performance using fewer parameters. Asynchronous training further improves results by enabling different latency levels for different target languages.

## Method Summary
The paper proposes two neural architectures for multilingual end-to-end simultaneous speech translation: a separate decoder model, where each target language has its own decoder, and a unified model, which uses a shared decoder for all target languages. Both models are trained jointly using synchronous training, where all target languages are processed simultaneously. Additionally, an asynchronous training strategy is introduced, allowing different latency levels for each target language during training to improve cross-lingual knowledge transfer. A multi-way aligned multilingual speech translation dataset is curated for evaluation, enabling direct comparison of translation quality across languages.

## Key Results
- Both proposed models (separate decoder and unified) significantly outperform bilingual baselines in translation quality.
- The unified model with fewer parameters achieves the best performance.
- Asynchronous training further improves results by allowing different latency levels for different target languages.

## Why This Works (Mechanism)
The unified model leverages shared parameters across target languages, enabling better cross-lingual transfer and parameter efficiency. Asynchronous training allows the model to adapt latency for each target language, optimizing the trade-off between translation quality and real-time performance. Joint training of multiple languages in a single model encourages the model to learn shared representations, improving generalization and reducing overfitting compared to bilingual models.

## Foundational Learning
- **End-to-End Simultaneous Speech Translation (S2T):** Translating speech from one language to text in another language in real time, without intermediate text representation. Needed to understand the real-time constraint and the goal of direct speech-to-text translation.
- **Joint Training:** Training a single model on multiple languages simultaneously. Needed to enable knowledge sharing and improve parameter efficiency across languages.
- **Cross-Lingual Knowledge Transfer:** The ability of a multilingual model to leverage information from one language to improve performance on another. Needed to explain how the unified model benefits from shared representations.
- **Latency-Quality Trade-off:** The balance between translation delay (latency) and translation accuracy (quality). Needed to understand the importance of asynchronous training in optimizing real-time performance.
- **Multi-Way Aligned Dataset:** A dataset where speech and translations are aligned across multiple languages. Needed to enable training and evaluation of multilingual S2T models.
- **Separate vs. Unified Decoders:** Architectural choices where each target language has its own decoder (separate) or shares a single decoder (unified). Needed to understand the design tradeoffs and their impact on performance.

## Architecture Onboarding
- **Component Map:** Speech input → Encoder → (Separate Decoders for each language OR Unified Decoder) → Target language translations
- **Critical Path:** Speech → Encoder → Decoder(s) → Translation output
- **Design Tradeoffs:** Separate decoders allow language-specific tuning but increase parameters; unified decoder is parameter-efficient but may struggle with language-specific nuances.
- **Failure Signatures:** Poor cross-lingual transfer, high latency for some languages, degraded quality for low-resource languages.
- **First Experiments:** (1) Train separate decoder model on two language pairs; (2) Train unified decoder model on same pairs; (3) Compare performance with bilingual baselines.

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation is based on a curated multilingual dataset with limited target language diversity (only two language pairs), restricting generalizability.
- The study does not address scalability to more languages or unbalanced language pairs.
- Performance comparisons rely on bilingual baselines without ablation studies isolating the contributions of joint training, decoding, and asynchronous strategies.

## Confidence
- **Core findings on joint training and decoding benefits:** High
- **Unified model with fewer parameters achieves best performance:** High
- **Broader applicability to more diverse multilingual settings:** Medium
- **Impact of asynchronous training on latency-quality trade-offs:** Medium

## Next Checks
1. Test the proposed architectures on a larger multilingual corpus with more target languages and varying language pairs.
2. Perform ablation studies to isolate the impact of joint training, unified decoding, and asynchronous strategies.
3. Analyze latency-quality trade-offs for each target language under the asynchronous training regime to validate its practical benefits.