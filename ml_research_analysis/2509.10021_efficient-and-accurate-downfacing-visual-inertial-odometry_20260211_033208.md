---
ver: rpa2
title: Efficient and Accurate Downfacing Visual Inertial Odometry
arxiv_id: '2509.10021'
source_url: https://arxiv.org/abs/2509.10021
tags:
- px4flow
- feature
- pipeline
- ieee
- superpoint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of deploying accurate Visual
  Inertial Odometry (VIO) on resource-constrained micro- and nano-drones by optimizing
  state-of-the-art feature tracking methods (ORB, SuperPoint, PX4FLOW) for ultra-low-power
  RISC-V-based SoCs like GAP9. The authors propose a template VIO pipeline that incorporates
  rigid-body motion estimation with outlier rejection to improve tracking accuracy,
  particularly for planar motion.
---

# Efficient and Accurate Downfacing Visual Inertial Odometry

## Quick Facts
- **arXiv ID**: 2509.10021
- **Source URL**: https://arxiv.org/abs/2509.10021
- **Reference count**: 38
- **Primary result**: Up to 3.65x RMSE reduction using rigid-body motion decomposition on GAP9 SoC

## Executive Summary
This paper addresses the challenge of deploying accurate Visual Inertial Odometry (VIO) on resource-constrained micro- and nano-drones by optimizing state-of-the-art feature tracking methods (ORB, SuperPoint, PX4FLOW) for ultra-low-power RISC-V-based SoCs like GAP9. The authors propose a template VIO pipeline that incorporates rigid-body motion estimation with outlier rejection to improve tracking accuracy, particularly for planar motion. They implement and evaluate quantized versions of ORB and SuperPoint alongside an optimized PX4FLOW variant on GAP9 hardware. Results show up to 3.65x reduction in RMSE compared to baseline when using ORB, with PX4FLOW achieving competitive accuracy for movements below 24 pixels/frame at lower computational cost.

## Method Summary
The method employs a downfacing VIO pipeline that integrates feature tracking with rigid-body motion estimation and outlier rejection on the GAP9 RISC-V SoC. Three feature trackers are implemented: quantized ORB using fixed-point arithmetic, quantized SuperPoint via 8-bit neural network inference, and an optimized PX4FLOW variant. The rigid-body estimator decomposes feature displacements into translational and rotational components using least-squares fitting, rejecting outliers through histogram voting and reprojection error checks before feeding estimates to an Extended Kalman Filter. The system is evaluated across indoor VICON and outdoor GPS-RTK datasets, measuring trajectory accuracy and computational latency.

## Key Results
- ORB with rigid-body estimator achieves up to 3.65x lower RMSE than baseline PX4FLOW on indoor sequences
- PX4FLOW maintains competitive accuracy for movements below 24 pixels/frame with significantly lower computational cost
- SuperPoint quantization to 8-bit activations/weights enables deployment but suffers from memory bottlenecks limiting frame rate to 11.9 FPS
- Multi-core parallelization on GAP9 provides 7.3x speedup for ORB tracking while maintaining real-time performance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Explicit rigid-body motion decomposition with outlier rejection yields higher planar tracking accuracy than averaging optical flow vectors, particularly during rotational movements.
- **Mechanism**: The pipeline models the drone as a rigid body, decomposing feature displacement into translation (Δu, Δv) and yaw rotation (Δψ) using a least-squares fit on inlier flow vectors. It rejects outliers via a two-stage histogram filter and a 1.5-pixel reprojection error threshold before solving the final motion estimate.
- **Core assumption**: Assumes the downfacing camera views a predominantly planar surface where feature motion can be accurately described by a single rigid-body transform.
- **Evidence anchors**:
  - [abstract] "...by employing a rigid body motion model, the pipeline reduces estimation errors and achieves improved accuracy in planar motion scenarios."
  - [Page 3, Section III-A] "...we model the movement as a rigid body movement... decompose the movement into the translational parts... and the yaw-rotation... to more accurately account for rotations instead of using averaged flow values."
- **Break condition**: Performance degrades in highly non-planar environments (e.g., staircases, obstacles) or if outliers exceed the statistical rejection capacity (e.g., repetitive textures causing systematic matching errors).

### Mechanism 2
- **Claim**: Integer-only arithmetic and 8-bit quantization enable "desktop-class" feature descriptors (ORB, SuperPoint) to run on ultra-low-power MCUs with minimal accuracy loss.
- **Mechanism**: The authors port ORB to fixed-point arithmetic (using 16-bit and 32-bit integers for Harris scores) and quantize the SuperPoint neural network to 8-bit activations/weights using the NNTool SDK. This leverages the GAP9's higher efficiency for 8-bit operations (15.6 GOPS) vs. floating point (3.3 GFLOPS).
- **Core assumption**: Assumes that the precision loss from quantization (e.g., SuperPoint's cosine similarity dropping to 0.91) remains within the error tolerance required for stable drone odometry.
- **Evidence anchors**:
  - [Page 5] "We use 8-bit quantization for activations and weights... The features... are matched using... cosine similarity."
- **Break condition**: Aggressive quantization fails if the descriptor discriminative power drops below the matching threshold (Hamming distance 20 for ORB), causing high outlier ratios that break the rigid-body estimator.

### Mechanism 3
- **Claim**: Optimizing for velocity constraints (pixel displacement range) allows for a strategic trade-off between the low compute of PX4FLOW and the large-baseline capability of ORB.
- **Mechanism**: PX4FLOW scales quadratically with search window size, making it efficient only for small displacements (<24 pixels/frame). ORB scales independently of displacement but has a higher base computational cost. The system selects the tracker based on the expected velocity envelope of the drone.
- **Core assumption**: Assumes the drone's maximum velocity and frame rate are known a priori to configure the correct tracker or search window.
- **Evidence anchors**:
  - [abstract] "...PX4FLOW achieves on-par tracking accuracy with ORB at a lower runtime for movement speeds below 24 pixels/frame."
  - [Page 9, Figure 6] Shows the crossover where ORB becomes more efficient than expanding the PX4FLOW search window beyond ~24 pixels.
- **Break condition**: If the drone abruptly accelerates beyond the PX4FLOW search window limit (e.g., >4.5 pixels/frame at 300 FPS), tracking is lost instantly, whereas ORB would likely survive but with higher latency.

## Foundational Learning

- **Concept**: **Visual Inertial Odometry (VIO)**
  - **Why needed here**: The paper assumes familiarity with why cameras (drift-free but scale-ambiguous) and IMUs (metric but drifting) must be fused via an Extended Kalman Filter (EKF) to provide stable, metric state estimates.
  - **Quick check question**: Why can't a downfacing camera alone estimate the metric velocity of a drone without an IMU or known height?

- **Concept**: **Feature Descriptors vs. Optical Flow**
  - **Why needed here**: The comparison between PX4FLOW (patch-based optical flow) and ORB/SuperPoint (feature description and matching) is central to the paper's contribution.
  - **Quick check question**: How does the computational complexity of patch-based flow scale with image displacement compared to a brute-force descriptor matcher?

- **Concept**: **Fixed-Point & Quantization**
  - **Why needed here**: The implementation relies on porting floating-point algorithms to the integer-only hardware accelerator of the GAP9 SoC.
  - **Quick check question**: If you quantize a Harris corner score from float32 to int16, what is the primary risk for features with low contrast gradients?

## Architecture Onboarding

- **Component map**: Camera (VD56G3) -> Sensor Readout (DMA to L1) -> Feature Tracker (Cluster) -> Rigid Body Decomposition (Cluster) -> EKF (Float) -> Downstream Task

- **Critical path**: The **Feature Tracking** stage dominates the latency budget.
  - *ORB Total*: ~2,899 kCycles (multi-core)
  - *PX4FLOW Total*: ~81 kCycles (multi-core)
  - *Template Overhead*: ~223 kCycles (Rigid Body + EKF)
  Target frame rate is set by the sum of Tracker + Overhead.

- **Design tradeoffs**:
  - **ORB**: Best accuracy and velocity range (arbitrary pixels/frame). Highest compute cost (~100 FPS limit).
  - **PX4FLOW**: Lowest compute cost (>1000 FPS potential). Limited to low speeds (<24 pixels/frame) and prone to rotation drift without the rigid-body fix.
  - **SuperPoint**: Poor fit for GAP9 due to L3 memory access bottlenecks (11.9 FPS), causing memory-bound latency despite parallelization.

- **Failure signatures**:
  - **Systematic Outliers**: SuperPoint often fails the rigid-body check because its 8x subsampling causes "systematic" outliers that statistical histogramming misses.
  - **Texture Voids**: ORB fails on the "Hardcourt" (sparse texture) sequences because it cannot detect sufficient corners; PX4FLOW performs better here as it does not require high-quality corners.
  - **Rotation Drift**: The "Original PX4FLOW" pipeline shows high RMSE on "Square" trajectories because it averages flow, misinterpreting rotational motion as translation.

- **First 3 experiments**:
  1. **Latency Profiling**: Run the ORB and PX4FLOW variants on the GVSoC simulator to measure the exact speedup of the 8-core parallelization vs. single-core (targeting the 7.3x factor cited in Table II).
  2. **Displacement Stress Test**: Record a sequence with linear acceleration exceeding 1.5 m/s². Verify if PX4FLOW loses tracking while ORB maintains the trajectory.
  3. **Outlier Threshold Tuning**: Modify the "5-pixel baseline" and "1.5-pixel reprojection" constants in the rigid-body estimator to see the effect on the RMSE of the "Random" indoor sequence.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does combining ORB feature detection with PX4FLOW's subpixel refinement improve VIO accuracy on resource-constrained devices without incurring high latency?
- Basis: [explicit] The Conclusion states, "For future work, we deem ORB, in combination with the subpixel refinement of PX4FLOW, an interesting combination."
- Why unresolved: The paper evaluated ORB and PX4FLOW independently; the specific accuracy/latency trade-offs of a hybrid approach were not tested.
- What evidence would resolve it: Implementation of the hybrid pipeline on GAP9 demonstrating improved subpixel accuracy over standalone ORB without dropping below real-time frame rates.

### Open Question 2
- Question: Can SuperPoint achieve real-time performance suitable for nano-drones if deployed on hardware with larger on-chip memory?
- Basis: [explicit] The Discussion notes, "The use of a SoC with large enough on-chip memory could render SuperPoint a competitive option."
- Why unresolved: On GAP9, SuperPoint was memory-bound (11.9 FPS) because the model required off-chip L3 memory access, creating a bottleneck.
- What evidence would resolve it: Deployment on a comparable ultra-low-power SoC with sufficient SRAM to hold the full model, achieving >30 FPS.

### Open Question 3
- Question: Can a PX4FLOW derivative utilizing a feature detector (like FAST) improve tracking scalability for fast movements better than the fixed-point method?
- Basis: [explicit] The Discussion suggests examining a "middle ground" where "a PX4FLOW derivative could use a feature detector like FAST."
- Why unresolved: Standard PX4FLOW scales quadratically with displacement; it is unknown if feature-seeding can mitigate this complexity for high-speed tracking.
- What evidence would resolve it: Profiling a FAST-guided optical flow implementation showing linear or sub-quadratic scaling with pixel displacement.

## Limitations

- The rigid-body motion model assumes planar surfaces and may fail in non-planar or feature-poor environments
- The 3.65x RMSE improvement is benchmarked only against a baseline PX4FLOW pipeline without modern structureless VIO comparisons
- SuperPoint quantization to 8-bit causes measurable descriptor quality degradation (cosine similarity from 1.0 to 0.91) with unquantified impact on final accuracy

## Confidence

- **High**: The computational efficiency claims for PX4FLOW vs. ORB are directly measured on the target hardware and are internally consistent with the algorithm scaling laws.
- **Medium**: The claim of "improved accuracy in planar motion scenarios" is well-supported by the indoor dataset but lacks validation in non-planar or feature-poor environments.
- **Low**: The assertion that "modern low-power SoCs can bridge the gap" to desktop-class VIO systems is an extrapolation not directly tested; the comparison is only to legacy, non-rigid-body-corrected pipelines.

## Next Checks

1. **Generalization Test**: Evaluate the pipeline on a non-planar sequence (e.g., stairs, ramp) to quantify the breakdown of the rigid-body motion assumption.
2. **Baseline Upgrade**: Replace the "Original PX4FLOW" baseline with a modern, structureless VIO system to isolate the benefit of the rigid-body estimator from the benefit of using a better baseline algorithm.
3. **Quantization Impact**: Conduct an ablation study where the rigid-body estimator is run with full-precision ORB descriptors vs. the quantized version to measure the exact contribution of descriptor quality to the final RMSE.