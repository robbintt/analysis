---
ver: rpa2
title: 'ACE: Adapting sampling for Counterfactual Explanations'
arxiv_id: '2509.26322'
source_url: https://arxiv.org/abs/2509.26322
tags:
- counterfactual
- explanations
- function
- datasets
- optimization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ACE introduces a Bayesian optimization approach for generating
  counterfactual explanations with minimal black-box evaluations. It combines Gaussian
  Process classification with Monte Carlo Expected Improvement to approximate the
  decision boundary efficiently.
---

# ACE: Adapting sampling for Counterfactual Explanations

## Quick Facts
- arXiv ID: 2509.26322
- Source URL: https://arxiv.org/abs/2509.26322
- Authors: Margarita A. Guerrero; Cristian R. Rojas
- Reference count: 40
- Primary result: ACE reduces black-box queries from 28,000+ to 70 while maintaining 100% validity and plausibility

## Executive Summary
ACE introduces a Bayesian optimization approach for generating counterfactual explanations with minimal black-box evaluations. It combines Gaussian Process classification with Monte Carlo Expected Improvement to approximate the decision boundary efficiently. The method handles mixed continuous and categorical inputs via L-BFGS-B and Branch-and-Bound optimization, and enforces sparsity, plausibility, and actionability through a penalized cost function. Across eight real-world datasets, ACE consistently required fewer queries while maintaining high validity and plausibility scores.

## Method Summary
ACE models the black-box classifier as a thresholded latent function and uses a Gaussian Process classifier to approximate this latent function based on observed input-output pairs. The algorithm employs an acquisition function (Monte Carlo Expected Improvement) that prioritizes querying points likely to be near the decision boundary. It uses L-BFGS-B for continuous variables and Branch-and-Bound for categorical variables to find optimal counterfactuals. A penalized cost function enforces sparsity, plausibility, and actionability constraints while maintaining validity through adaptive sampling.

## Key Results
- Query efficiency: 70 queries vs 28,000+ for Growing Spheres baseline
- Validity: 100% across all tested datasets
- Plausibility: α(x) ≈ 1 scores consistently achieved
- High-dimensional performance: Found valid MNIST counterfactuals in 9 queries vs 50+ for baselines

## Why This Works (Mechanism)

### Mechanism 1
ACE uses a Gaussian Process classifier as a surrogate model to approximate the black-box classifier's latent function. This allows the algorithm to estimate class membership probabilities and decision boundary locations without querying the expensive black-box model at every candidate point. The approach assumes the decision boundary is sufficiently smooth to be approximated by the GP kernel.

### Mechanism 2
Adaptive sampling via Monte Carlo Expected Improvement locates the decision boundary with fewer iterations than geometric expansion methods. The acquisition function prioritizes querying points that maximize expected gain in finding the decision boundary, balancing exploration of high-uncertainty regions with exploitation of known boundary-proximate regions.

### Mechanism 3
A hybrid optimization strategy combining gradient descent (L-BFGS-B) for continuous variables and combinatorial search (Branch-and-Bound) for categorical variables is required to maintain validity and plausibility in mixed data spaces. This ensures proposed counterfactuals remain valid while handling discrete constraints.

## Foundational Learning

- **Concept:** Gaussian Process (GP) Classification
  - **Why needed here:** ACE relies on a GP to act as a differentiable, probabilistic proxy for the non-differentiable black-box. Understanding how GPs define a distribution over functions is essential.
  - **Quick check question:** If a point $x_{new}$ is far from all observed points $x_{1:n}$, does the GP posterior variance at $x_{new}$ typically increase or decrease?

- **Concept:** Acquisition Functions (Expected Improvement)
  - **Why needed here:** This is the "steering wheel" of the algorithm. It explains how ACE decides where to look next. Understanding EI is crucial to distinguishing this "adaptive" method from random or grid search.
  - **Quick check question:** Does Expected Improvement favor points where the predicted mean is best, or points where there is high uncertainty that could lead to a better result?

- **Concept:** Penalty Methods (Lagrangian Relaxation)
  - **Why needed here:** The paper transforms a constrained problem into an unconstrained optimization problem via a cost function. Understanding the penalty term $\lambda_k$ is key to implementing the optimization loop.
  - **Quick check question:** As the penalty coefficient $\lambda_k$ increases during optimization, what happens to the priority of satisfying the constraint $|f(x) - 0.5| \approx 0$ vs. minimizing the distance $d(x, \tilde{x})$?

## Architecture Onboarding

- **Component map:** Data Store -> Surrogate Engine (GP) -> Acquisition Optimizer -> Evaluator -> Validator -> Data Store
- **Critical path:** The loop defined in Algorithm 1. Specifically, the inner `while` loop where `maximize EI` -> `Observe h(x)` -> `Update Data` drives the efficiency.
- **Design tradeoffs:**
  - Kernel Choice: Matérn 5/2 used; switching to RBF assumes smoother boundaries
  - MC Samples: Uses MC=1000; lowering speeds up acquisition but adds noise
  - Initialization: Sobol sequences used for final selection step to ensure coverage
- **Failure signatures:**
  - High-dimensional collapse if initial random samples don't span dataset variance
  - Stuck in local optima if surrogate surface is flat far from boundary
  - Implausible CFEs if LOF threshold τ is not tuned to data density
- **First 3 experiments:**
  1. Implement ACE on 2D `make_moons` dataset and visualize GP decision boundary vs true classifier
  2. Run ACE on Credit dataset and plot "Validity" vs "Number of Queries" against Random Search baseline
  3. Test on dataset with high-cardinality categorical features (>10 categories) to verify Branch-and-Bound scalability

## Open Questions the Paper Calls Out
- Can ACE be extended to simultaneously generate diverse sets of counterfactual explanations?
- What are the formal convergence guarantees and sample complexity bounds for the ACE algorithm?
- Does the computational overhead of Gaussian Process inversion limit ACE in problems requiring many queries?

## Limitations
- GP surrogate assumes smooth decision boundaries; performance degrades with highly non-linear or discontinuous functions
- Computational complexity grows cubically with number of observations due to GP inference
- Method requires careful tuning of LOF threshold τ and penalty parameters λₖ
- High-cardinality categorical features may cause combinatorial explosion in Branch-and-Bound optimization

## Confidence
- **High confidence**: Query efficiency gains (70 vs 28,000+ queries) - directly measured and compared against baselines with consistent results across 8 datasets
- **Medium confidence**: Plausibility and actionability enforcement - validated through synthetic metrics (α(x), β(x)) but less interpretable than human evaluation
- **Medium confidence**: High-dimensional MNIST results - fewer query comparisons (ACE: 9 vs Random: 50+) but limited to 2 digits, reducing generalizability

## Next Checks
1. Stress test ACE on datasets with high-cardinality categorical features (>10 categories) to measure Branch-and-Bound scalability and runtime
2. Conduct ablation studies varying the GP kernel (RBF vs Matérn) and acquisition function parameters (MC samples, EI variants) to quantify sensitivity
3. Perform user studies validating that ACE-generated counterfactuals are more actionable and interpretable than those from baselines in real-world decision contexts