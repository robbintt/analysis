---
ver: rpa2
title: 'SALAD: Improving Robustness and Generalization through Contrastive Learning
  with Structure-Aware and LLM-Driven Augmented Data'
arxiv_id: '2504.12185'
source_url: https://arxiv.org/abs/2504.12185
tags:
- data
- uni00000013
- uni00000011
- uni00000008
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses spurious correlations in NLP models, which
  harm generalization, especially on out-of-distribution data. SALAD improves robustness
  by combining structure-aware data augmentation with LLM-driven counterfactual generation
  and contrastive learning.
---

# SALAD: Improving Robustness and Generalization through Contrastive Learning with Structure-Aware and LLM-Driven Augmented Data

## Quick Facts
- arXiv ID: 2504.12185
- Source URL: https://arxiv.org/abs/2504.12185
- Reference count: 28
- Primary result: SALAD improves robustness by combining structure-aware augmentation and LLM-driven counterfactual generation, achieving 93.05% accuracy on sentiment classification and strong OOD performance

## Executive Summary
SALAD addresses spurious correlations in NLP models that harm generalization on out-of-distribution data. The method improves robustness through a novel combination of structure-aware data augmentation (using POS tagging to identify non-causal words) and LLM-driven counterfactual generation, integrated with contrastive learning. This approach generates diverse positive samples that preserve sentence structure while replacing spurious features, and diverse negative samples through LLM generation. Experiments across sentiment classification, sexism detection, and NLI tasks demonstrate significant improvements in both in-domain accuracy and out-of-distribution generalization compared to baseline models.

## Method Summary
SALAD combines structure-aware data augmentation with LLM-driven counterfactual generation within a contrastive learning framework. The method first identifies non-causal words contributing to spurious correlations using POS tagging heuristics. Structure-preserving augmentations generate positive samples by replacing these spurious features while maintaining sentence semantics. LLM-driven generation creates diverse negative samples by producing counterfactual examples that differ meaningfully from the original. These augmented samples are then used in a contrastive learning setup where the model learns to distinguish between positive and negative pairs, improving robustness to spurious patterns while maintaining generalization capability across domains.

## Key Results
- Achieved 93.05% overall accuracy on sentiment classification, outperforming baseline models
- Demonstrated significant improvements on out-of-distribution and cross-domain datasets across multiple tasks
- Showed robust performance on sexism detection and NLI tasks while maintaining strong in-domain accuracy

## Why This Works (Mechanism)
SALAD works by explicitly targeting spurious correlations through a dual-augmentation strategy. Structure-aware augmentation identifies and replaces non-causal words (detected via POS tagging) to generate positive samples that preserve semantic structure while removing spurious features. LLM-driven counterfactual generation creates diverse negative samples that expose the model to alternative scenarios. The contrastive learning framework then forces the model to learn representations that are invariant to these spurious variations while maintaining sensitivity to genuine task-relevant features. This combined approach reduces reliance on dataset-specific shortcuts and improves generalization to unseen distributions.

## Foundational Learning
- **Contrastive Learning**: Learning representations by comparing similar (positive) and dissimilar (negative) pairs; needed to distinguish spurious from genuine patterns; quick check: verify positive pairs are truly semantically similar while negatives are meaningfully different
- **POS-based Spurious Detection**: Using part-of-speech tagging to identify non-causal words; needed to systematically target words contributing to spurious correlations; quick check: validate that replaced words indeed correlate with dataset bias rather than task
- **LLM-driven Counterfactual Generation**: Using large language models to create diverse negative samples; needed to generate realistic variations that expose model to distribution shifts; quick check: assess diversity and quality of generated samples against human judgments
- **Structure-preserving Augmentation**: Maintaining sentence semantics while modifying specific features; needed to ensure positive samples remain valid examples; quick check: evaluate semantic preservation through automated metrics and human evaluation
- **Spurious Correlation Identification**: Detecting dataset-specific shortcuts that models learn instead of true task patterns; needed to understand what causes poor OOD performance; quick check: analyze feature importance and correlation with spurious patterns
- **Cross-domain Generalization**: Model performance across different data distributions; needed to evaluate true robustness beyond in-domain accuracy; quick check: test on multiple OOD splits and domains to verify consistent improvement

## Architecture Onboarding

**Component Map**: Data → POS Analysis → Structure-Aware Augmentation → LLM Generation → Contrastive Learning → Robust Model

**Critical Path**: Input text → POS-based spurious word identification → Structure-preserving positive augmentation → LLM-driven negative generation → Contrastive loss computation → Model parameter updates

**Design Tradeoffs**: Structure-aware augmentation provides targeted removal of spurious patterns but relies on heuristic POS detection; LLM generation offers diversity but introduces computational overhead and potential quality variability; contrastive learning enables explicit discrimination learning but requires careful sampling strategy

**Failure Signatures**: Poor OOD performance despite strong in-domain accuracy suggests insufficient spurious pattern removal; degraded performance with LLM augmentation indicates quality issues in generated samples; failure to improve with increased augmentation diversity suggests the model is memorizing rather than learning invariant representations

**First Experiments**: 1) Ablation study removing structure-aware augmentation to measure its individual contribution; 2) Controlled test with synthetic spurious correlations to verify detection capability; 3) Diversity analysis of LLM-generated samples using embedding-based metrics

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Heavy reliance on POS-based heuristics for spurious correlation detection may not generalize to domains where spurious patterns don't align with syntactic categories
- LLM-driven counterfactual generation quality, diversity, and potential bias are not thoroughly characterized or evaluated
- Requires labeled data for structure-aware augmentation, limiting applicability to low-resource settings
- Substantial computational overhead from LLM generation and maintaining multiple augmented views, though not explicitly quantified

## Confidence
- High: In-domain performance gains measured on standard benchmarks with consistent results across tasks
- Medium: OOD generalization claims rely on specific dataset splits that may not capture all forms of distribution shift
- Low: Claims about robustness to spurious correlations lack systematic validation through targeted adversarial tests

## Next Checks
1. Conduct controlled ablations to quantify individual contributions of structure-aware augmentation versus LLM-driven counterfactual generation
2. Test SALAD on truly low-resource settings where labeled data is scarce to evaluate practical scalability
3. Systematically analyze whether the model has actually learned to ignore spurious correlations (e.g., via targeted adversarial tests) rather than just memorizing more patterns