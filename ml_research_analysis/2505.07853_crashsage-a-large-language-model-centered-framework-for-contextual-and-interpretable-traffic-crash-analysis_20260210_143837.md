---
ver: rpa2
title: 'CrashSage: A Large Language Model-Centered Framework for Contextual and Interpretable
  Traffic Crash Analysis'
arxiv_id: '2505.07853'
source_url: https://arxiv.org/abs/2505.07853
tags:
- crash
- traffic
- factors
- safety
- attribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CrashSage addresses limitations in traffic crash analysis by converting
  structured crash data into enriched textual narratives using a tabular-to-text transformation
  combined with relational data integration. The framework applies context-aware data
  augmentation to improve narrative coherence and fine-tunes LLaMA3-8B for crash severity
  prediction, achieving superior performance over baseline approaches including zero-shot,
  chain-of-thought, and few-shot learning with multiple models (GPT-4o, GPT-4o-mini,
  LLaMA3-70B).
---

# CrashSage: A Large Language Model-Centered Framework for Contextual and Interpretable Traffic Crash Analysis

## Quick Facts
- arXiv ID: 2505.07853
- Source URL: https://arxiv.org/abs/2505.07853
- Authors: Hao Zhen; Jidong J. Yang
- Reference count: 40
- Primary result: Macro-F1 score of 0.7361, surpassing baselines ranging from 0.3693 to 0.7067

## Executive Summary
CrashSage addresses limitations in traffic crash analysis by converting structured crash data into enriched textual narratives using a tabular-to-text transformation combined with relational data integration. The framework applies context-aware data augmentation to improve narrative coherence and fine-tunes LLaMA3-8B for crash severity prediction, achieving superior performance over baseline approaches including zero-shot, chain-of-thought, and few-shot learning with multiple models (GPT-4o, GPT-4o-mini, LLaMA3-70B). CrashSage incorporates gradient-based explainability to provide interpretable insights into model decisions at both individual crash and broader risk factor levels. This interpretability enables targeted safety interventions by revealing complex interactions among environmental, behavioral, vehicle, and infrastructure factors.

## Method Summary
CrashSage processes structured crash data from four relational tables (crash, vehicle, person, road) by integrating them into a coherent schema and converting them into textual narratives using template-based generation. The framework applies context-aware data augmentation via LLaMA3-8B to clean and enhance narrative quality, then fine-tunes LLaMA3-8B with LoRA for binary severity classification. Gradient-based attribution provides interpretability by identifying key factors influencing predictions. The approach bridges structured data with natural language reasoning, enabling both accurate prediction and transparent analysis of crash risk factors.

## Key Results
- Macro-F1 score of 0.7361, surpassing all baseline methods (zero-shot: 0.6345-0.7067, CoT: 0.3693-0.6059, few-shot: 0.6902-0.7029)
- Fine-tuned LLaMA3-8B outperforms larger models like LLaMA3-70B using prompting strategies
- Attribution analysis identifies "motorcycle," "intoxication," and "dusk" as top severity predictors
- Framework provides interpretable insights at both individual crash and systemic risk factor levels

## Why This Works (Mechanism)

### Mechanism 1
Converting structured crash data into textual narratives may preserve relational and contextual information that is typically lost in tabular representations. The tabular-to-text transformation uses template-based generation to encode hierarchical relationships (crash → vehicle → person) as coherent narrative sequences. By separating descriptive narratives (pre-crash conditions) from outcome narratives (injury severity), the model can potentially learn associations between antecedent conditions and consequences rather than treating features as independent variables.

### Mechanism 2
Supervised fine-tuning on domain-specific crash narratives enables smaller models (LLaMA3-8B) to outperform larger general-purpose models on severity classification. LoRA-based parameter-efficient fine-tuning adapts the pre-trained model's weights to internalize domain-specific patterns in crash dynamics. The model learns to associate textual patterns (vehicle types, environmental conditions, behavioral descriptors) with severity outcomes through maximum likelihood estimation on labeled examples.

### Mechanism 3
Gradient-based attribution provides token-level importance scores that align with domain-expert risk factor identification. First-order Taylor approximation quantifies how removing each input token would change output probabilities. Normalized attribution scores highlight which narrative elements (e.g., "motorcycle," "intoxication," "dusk") most influence severity predictions. Aggregating attributions across categories (environmental, behavioral, vehicle, infrastructure) enables systematic risk factor analysis.

## Foundational Learning

- **Transformer attention and tokenization**
  - Why needed here: Understanding how LLaMA3-8B processes crash narratives as token sequences is essential for interpreting attribution results and debugging tokenization artifacts (e.g., sub-word splitting of technical terms)
  - Quick check question: Can you explain why "motorcycle's" might have different attribution scores than "motorcycle" in the gradient analysis?

- **Supervised fine-tuning vs. in-context learning**
  - Why needed here: The paper compares SFT against zero-shot, few-shot, and chain-of-thought prompting. Understanding the trade-offs helps interpret why SFT outperforms larger models using prompting strategies
  - Quick check question: Why might chain-of-thought prompting (0.3693–0.6059 Macro-F1) underperform zero-shot prompting (0.6345–0.7067) for GPT-4o in this domain?

- **Gradient-based attribution methods**
  - Why needed here: The Taylor approximation method (Equations 3–5) computes token importance. Understanding this helps assess whether attributions reflect causal reasoning or correlation artifacts
  - Quick check question: What does a normalized attribution score of 4.37 (e.g., "MAINLINE") actually represent in terms of probability change?

## Architecture Onboarding

- Component map: Raw crash tables (Crash, Vehicle, Person, Road) → Relational schema integration → Tabular-to-text transformation → Context-aware augmentation via LLaMA3-8B → Supervised fine-tuning on LLaMA3-8B with LoRA → Gradient-based attribution for explainability → Factor categorization and co-occurrence analysis

- Critical path: The data transformation pipeline (relational integration → narrative generation → augmentation) determines input quality. Errors here propagate through fine-tuning and affect attribution reliability. Verify narrative coherence on a sample before fine-tuning.

- Design tradeoffs:
  - **Model size vs. specialization**: LLaMA3-8B + SFT outperforms LLaMA3-70B with prompting, but requires labeled training data and fine-tuning infrastructure
  - **Narrative richness vs. computational cost**: Longer narratives (max 2,048 tokens) capture more context but increase training memory requirements
  - **Attribution granularity vs. interpretability**: Word-level attributions are intuitive but may miss phrase-level semantics (e.g., "no evidence of alcohol" vs. "alcohol")

- Failure signatures:
  - High variance in severity predictions across similar crash narratives suggests overfitting or insufficient data augmentation
  - Attribution scores concentrated on generic terms (e.g., "occurred," "vehicle") rather than domain-specific factors indicate the model learned surface patterns rather than crash dynamics
  - Co-occurrence analysis showing implausible factor combinations (e.g., "intoxication" strongly linked to "clear weather" without temporal context) suggests spurious correlations

- First 3 experiments:
  1. **Ablation on narrative components**: Train separate models using only environmental factors, only vehicle factors, and full narratives to quantify each component's contribution to Macro-F1
  2. **Cross-regional validation**: Fine-tune on Washington State data and evaluate on a different state's crash dataset to assess geographic generalization
  3. **Attribution consistency check**: For 50 crashes with similar characteristics, compare whether the same factors (e.g., "motorcycle," "dusk") consistently receive high attribution scores, or if attributions vary unpredictably

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can CrashSage be effectively extended from retrospective analysis to real-time proactive risk estimation in live traffic networks?
- Basis in paper: [explicit] The authors state, "extending CrashSage from retrospective analyses to proactive risk estimation, where evolving traffic events trigger real-time alerts, offers significant operational benefits."
- Why unresolved: The current framework processes static, historical crash records. Real-time deployment requires handling streaming data, lower latency inference, and integration with live traffic sensor feeds, which are architectural challenges not addressed in the current study.
- What evidence would resolve it: A system demonstration deploying CrashSage in a live traffic management center, measuring the latency of inference and the accuracy of risk alerts compared to actual crash occurrences.

### Open Question 2
- Question: How does the integration of multimodal data (video and sensors) impact the accuracy of severity predictions compared to the text-only approach?
- Basis in paper: [explicit] The paper notes, "integrating video and sensor data into the LLM pipeline could enhance crash narratives with real-time spatiotemporal context, improving model accuracy and robustness."
- Why unresolved: The current methodology converts structured tabular data into text, inherently discarding visual cues (e.g., dashcam footage) and raw sensor readings that may contain critical physical evidence of crash dynamics not captured in police reports.
- What evidence would resolve it: An ablation study comparing the Macro-F1 scores of the text-only CrashSage model against a multimodal variant trained on paired crash narratives and corresponding video/sensor data.

### Open Question 3
- Question: Does CrashSage generalize effectively to crash datasets from different geographical regions with varying reporting schemas?
- Basis in paper: [inferred] The study utilizes crash records exclusively from Washington State (WSDOT) from 2020–2022.
- Why unresolved: The "tabular-to-text transformation" templates are manually designed around the specific schema of the Washington dataset. Crash data structures, terminology, and reporting thresholds vary significantly across states and countries, potentially limiting the portability of the fine-tuned model.
- What evidence would resolve it: Evaluating the fine-tuned model's zero-shot or few-shot performance on an out-of-distribution dataset, such as crash records from a different state (e.g., California or Texas) with different feature columns.

### Open Question 4
- Question: To what extent do gradient-based attribution scores reflect the true causal reasoning of the model versus correlational patterns in the training data?
- Basis in paper: [inferred] The authors acknowledge that gradient-based explanations "rely on approximations of model behavior and may not fully capture the full depth of the model's internal representations or latent reasoning processes."
- Why unresolved: Gradient methods identify input sensitivity, but high attribution does not guarantee causality (e.g., a model might attend to "dusk" not because visibility is low, but because dusk correlates with rush hour traffic in the training data).
- What evidence would resolve it: A causal validation study where specific high-attribution factors in crash narratives are counterfactually edited (e.g., changing "dusk" to "noon" while holding crash dynamics constant) to verify if the model's prediction changes as theoretically expected.

## Limitations

- Performance gains may reflect dataset-specific characteristics of Washington State crash data rather than general superiority
- Gradient-based attribution relies on first-order Taylor approximation that may not capture non-linear interactions in crash severity prediction
- Tabular-to-text transformation's template-based approach could introduce artifacts if narrative structure doesn't align with actual crash progression patterns

## Confidence

- **High confidence**: The reported performance metrics (Macro-F1 = 0.7361) and methodological framework are clearly specified and internally consistent
- **Medium confidence**: Attribution results showing "motorcycle," "intoxication," and "dusk" as top severity predictors align with domain knowledge but require external validation
- **Low confidence**: Generalization claims across different geographic regions, temporal periods, or crash types lack empirical support

## Next Checks

1. **Cross-regional generalization test**: Fine-tune CrashSage on Washington State data (2020-2022) and evaluate on crash data from California or another state to quantify performance degradation and identify factors that don't transfer

2. **Attribution robustness validation**: For 100 crashes with similar severity outcomes, verify whether the same factors (e.g., vehicle types, environmental conditions) consistently receive high attribution scores across models trained on different random seeds

3. **Template sensitivity analysis**: Train separate models using alternative narrative templates that emphasize different aspects of crash progression (e.g., focusing on pre-crash vs. impact phase) to quantify how template choice affects both prediction accuracy and attribution patterns