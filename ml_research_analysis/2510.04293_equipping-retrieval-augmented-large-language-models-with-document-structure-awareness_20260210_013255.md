---
ver: rpa2
title: Equipping Retrieval-Augmented Large Language Models with Document Structure
  Awareness
arxiv_id: '2510.04293'
source_url: https://arxiv.org/abs/2510.04293
tags:
- document
- routing
- retrieval
- question
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the limitation of existing retrieval-augmented
  generation (RAG) systems that treat retrieved passages as isolated chunks, ignoring
  valuable document structure. The authors propose RDR2, a novel framework that explicitly
  incorporates structural information throughout the RAG process through an LLM-based
  router that dynamically navigates document structure trees.
---

# Equipping Retrieval-Augmented Large Language Models with Document Structure Awareness

## Quick Facts
- arXiv ID: 2510.04293
- Source URL: https://arxiv.org/abs/2510.04293
- Reference count: 40
- Primary result: State-of-the-art performance on 5 QA datasets by incorporating document structure awareness into RAG

## Executive Summary
This paper addresses a fundamental limitation in retrieval-augmented generation (RAG) systems: treating retrieved passages as isolated chunks while ignoring valuable document structure. The authors propose RDR2, a novel framework that explicitly incorporates structural information throughout the RAG process through an LLM-based router that dynamically navigates document structure trees. RDR2 achieves state-of-the-art performance across five challenging datasets by jointly evaluating content relevance and hierarchical relationships to assemble optimal evidence, demonstrating that explicit structural awareness significantly enhances RAG systems' ability to acquire and utilize knowledge, particularly in complex scenarios requiring multi-document synthesis.

## Method Summary
RDR2 introduces a structure-aware RAG framework that represents documents as hierarchical Document Structure Trees (DSTs) with structure nodes (headings) and content nodes (passages). The core innovation is an LLM-based router that navigates these trees using three learned actions: [ANS] selects relevant content nodes, [EXP] unfolds promising heading subtrees, and [REF] terminates unproductive branches. The router is trained without answer supervision through automatic action curation, where a teacher LLM generates synthetic routing actions from questions alone. The framework keeps both retriever and reader off-the-shelf while fine-tuning only the router via parameter-efficient LoRA, achieving significant performance gains on QA benchmarks while maintaining computational efficiency.

## Key Results
- State-of-the-art performance on ASQA, achieving 45.3 EM with expand-iter=5
- Significant improvements over baseline RAG on five datasets (TriviaQA, HotpotQA, ASQA, QAMPARI, ELI5)
- Ablation studies show router contribution of +5.6 EM and structure awareness of +7.5 EM on passages
- Qwen2.5-1.5B-Instruct router achieves 94% of Llama-3.1-8B performance with lower inference cost

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Navigation via Structure-Aware Actions
Representing documents as tree structures enables iterative, query-adaptive evidence gathering that flat chunking cannot achieve. The router traverses a Document Structure Tree using three learned actions: [ANS] selects relevant content nodes, [EXP] unfolds promising heading subtrees, and [REF] terminates unproductive branches. This mimics human reading strategies (browsing sections, expanding relevant headings, skipping irrelevant parts). Core assumption: Document structure encodes meaningful semantic and relational priors useful for locating relevant information beyond surface-level semantic similarity.

### Mechanism 2: Training Without Answer Supervision via Automatic Action Curation
Routing decisions can be learned from questions alone by leveraging an LLM to synthesize training trajectories. Given a question q, retrieve top-k passages, map to Document Structure Trees, then prompt a strong LLM (DeepSeek-V3) to generate single-turn routing actions conditioned on the subtree. This creates training triples without requiring human-annotated routing paths or gold answers. Core assumption: The teacher LLM's routing decisions generalize to the student router and approximate optimal navigation behavior.

### Mechanism 3: Test-Time Compute Scaling via Expansion Iterations
Increasing routing iterations improves evidence quality with controllable latency-accuracy tradeoffs. The expand-iter hyperparameter controls how many times the router can traverse and expand subtrees. More iterations allow deeper exploration of document hierarchies at linear computational cost. Core assumption: Additional iterations discover relevant content that single-pass retrieval misses, without excessive noise accumulation.

## Foundational Learning

- Concept: **Tree-based document representation**
  - Why needed here: RDR2 represents documents as hierarchical trees with structure nodes (headings) and content nodes (passages), requiring understanding of tree traversal and parent-child relationships.
  - Quick check question: Given a document with headings "Introduction → Methods → Results → Conclusion," can you identify the parent of the "Methods" node?

- Concept: **Supervised Fine-Tuning with LoRA**
  - Why needed here: The router is trained via parameter-efficient fine-tuning on curated routing actions; understanding LoRA's rank and alpha hyperparameters is necessary for reproduction.
  - Quick check question: If LoRA rank=8 and alpha=16, what is the effective scaling factor applied to the low-rank update?

- Concept: **RAG pipeline components (Retriever, Reader, Knowledge Base)**
  - Why needed here: RDR2 modifies only the routing stage while keeping retriever and reader off-the-shelf; understanding their interfaces is essential for integration.
  - Quick check question: In a standard RAG pipeline, what data format does the retriever return to the reader, and how does RDR2's router transform it?

## Architecture Onboarding

- Component map:
  Retriever (off-the-shelf: Contriever-MS MARCO) → retrieves top-k chunks + source documents
  Document Structure Tree Builder (offline) → parses Wikipedia into 5.82M DSTs with structure/content nodes
  Retrieval SubTree Deriver → constructs query-specific RSTs from DSTs (Algorithm 1)
  Router (Llama-3.1-8B-Instruct + LoRA) → generates routing actions
  Reader (off-the-shelf LLM) → generates final answer from routed passages

- Critical path:
  1. Offline DST construction for corpus (20 min for Wikipedia on 8 CPUs)
  2. Router training: curate actions with teacher LLM → fine-tune with LoRA (3.5 epochs, lr=1e-5)
  3. Inference: retrieve → derive RST → iterate routing (controlled by expand-iter) → concatenate routed passages → reader generates answer

- Design tradeoffs:
  - **expand-iter vs. latency**: More iterations improve EM but add linear token overhead (+2.031k input tokens for iter-5 vs. iter-0 on ASQA)
  - **RST size vs. context window**: Algorithm 1 constrains subtree size for stable token counts; may truncate useful context in deep documents
  - **Router scale vs. cost**: Qwen2.5-1.5B-Instruct achieves 94% of Llama-3.1-8B performance (Table 12) with lower inference cost

- Failure signatures:
  - Low EM with high passage EM: Router finds relevant content but reader fails to synthesize (check reader prompt formatting)
  - Excessive REF actions: Router over-cautious; may indicate training data imbalance (check Table 3 action distribution)
  - No improvement over baseline on shallow documents: Expected for depth ≤2; verify document depth distribution in target corpus

- First 3 experiments:
  1. **Baseline validation**: Run standard Retrieve-and-Read on ASQA with your chosen retriever/reader to establish benchmark EM
  2. **Router-only ablation**: Replace routing with identity function (return retrieved chunks unchanged) to isolate router contribution
  3. **Expand-iter sweep**: Test iter ∈ {0, 1, 3, 5} on held-out subset to calibrate latency-accuracy tradeoff for your deployment constraints

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the RDR2 framework be extended to model and utilize inter-document structural relationships rather than processing each document in isolation?
- Basis in paper: Page 9, Limitations: "While our routing mechanism effectively navigates intra-document hierarchies, it processes each document independently... potentially limiting inter-document knowledge integration."
- Why unresolved: The current architecture anchors the routing state to individual retrieved chunks and their parent documents. It lacks a mechanism to navigate structural links between different documents (e.g., hyperlinks or thematic connections), which is critical for complex multi-hop reasoning that spans disparate sources.
- What evidence would resolve it: A modified routing framework that constructs a "forest" of retrieval subtrees connected by inter-document edges, demonstrating superior performance on multi-hop QA benchmarks where answers require synthesizing information from multiple distinct documents.

### Open Question 2
- Question: Is it possible to dynamically construct Document Structure Trees (DSTs) on-demand to support real-time RAG applications without the need for offline pre-processing?
- Basis in paper: Page 9, Limitations: "The framework requires offline construction of Document Structure Trees (DSTs) for the entire datastore... potentially limiting [use] in dynamic environments."
- Why unresolved: The current reliance on offline construction restricts the system to static corpora. The feasibility of parsing and representing document hierarchies in real-time during the retrieval phase without introducing unacceptable latency remains unexplored.
- What evidence would resolve it: An implementation of a streaming or just-in-time DST parser that can ingest new documents and integrate them into the retrieval index dynamically, showing that structure-aware routing can function in a non-static environment.

### Open Question 3
- Question: Can the computational overhead of the iterative routing process be reduced through specialized routing architectures rather than general-purpose LLMs?
- Basis in paper: Page 9, Limitations: "The iterative routing process incurs computational overhead, which can be partially mitigated through controlled expansion iterations during inference."
- Why unresolved: The paper proposes controlling iteration depth as a mitigation, but the fundamental overhead of using a generative LLM for routing (vs. a simple classifier or ranker) is a bottleneck. It is unclear if a smaller, non-generative model could perform the routing task with similar efficacy.
- What evidence would resolve it: A comparative study replacing the Llama-3.1-8B router with a lightweight, fine-tuned BERT-sized model or a reinforcement learning agent to perform the navigation, measuring the trade-off between EM accuracy and inference latency.

## Limitations

- Performance critically depends on document structure quality, with limited validation on non-Wikipedia corpora and shallow documents (depth ≤2)
- Automatic action curation mechanism assumes teacher LLM outputs generalize to student routers without verification against human-annotated routing data
- Expand-iter hyperparameter shows diminishing returns after optimal depth, but lacks systematic analysis of iteration efficiency across document types

## Confidence

- **High confidence**: State-of-the-art performance claims on benchmark datasets (ASQA, TriviaQA, HotpotQA) are well-supported by comprehensive ablation studies showing consistent improvements over baselines.
- **Medium confidence**: The automatic training mechanism without answer supervision is plausible given teacher LLM capabilities, but untested against human-annotated routing data and may inherit systematic biases.
- **Low confidence**: Claims about expand-iter efficiency gains assume linear computational scaling holds across document types, but the paper lacks analysis of iteration efficiency versus document depth and content complexity.

## Next Checks

1. Validate automatic action curation by comparing teacher-generated routing decisions against human-annotated paths on a small subset of questions to measure annotation agreement and bias.
2. Test expand-iter efficiency on a document corpus with varied depths (shallow: depth ≤2, medium: depth 3-4, deep: depth >4) to establish iteration scaling curves and identify optimal depth thresholds.
3. Evaluate RDR2 performance on non-Wikipedia corpora (e.g., academic papers, legal documents) to assess generalization beyond the curated structure trees used in training.