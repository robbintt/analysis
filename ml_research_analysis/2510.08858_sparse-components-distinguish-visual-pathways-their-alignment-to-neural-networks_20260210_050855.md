---
ver: rpa2
title: Sparse components distinguish visual pathways & their alignment to neural networks
arxiv_id: '2510.08858'
source_url: https://arxiv.org/abs/2510.08858
tags:
- components
- alignment
- visual
- neural
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The ventral, dorsal, and lateral streams in human visual cortex
  are thought to process visual information along distinct computational pathways,
  yet deep neural networks trained on a single task capture all three pathways similarly
  well. This inconsistency was addressed by applying a sparse decomposition approach
  to identify dominant components in each stream.
---

# Sparse components distinguish visual pathways & their alignment to neural networks

## Quick Facts
- arXiv ID: 2510.08858
- Source URL: https://arxiv.org/abs/2510.08858
- Reference count: 36
- DNNs show stronger alignment with ventral than lateral or dorsal visual streams

## Executive Summary
The ventral, dorsal, and lateral streams in human visual cortex process visual information along distinct computational pathways, yet deep neural networks trained on a single task capture all three pathways similarly well according to standard alignment metrics. This study resolves this inconsistency by introducing a sparse decomposition approach to identify dominant components in each stream. Results reveal distinct response profiles: ventral stream components are selective for faces, scenes, bodies, food, and text; lateral stream components for group interactions, implied motion, hand actions, and reach-spaces; and dorsal stream components for scenes and implied motion.

The key innovation is a new measure called Sparse Component Alignment (SCA) that assesses representational alignment while preserving sensitivity to neural tuning axes. SCA reveals that DNNs are significantly more aligned with the ventral than lateral or dorsal streams (scores of 0.187, 0.047, and 0.058 respectively), a finding invisible to standard alignment metrics due to their rotational invariance. This demonstrates that DNNs share similar tuning properties with the ventral stream while highlighting the need for different modeling approaches to capture lateral and dorsal stream computations.

## Method Summary
The authors applied sparse principal component analysis to decompose fMRI responses from ventral, lateral, and dorsal visual streams into dominant components. They compared these components to DNN representations using a novel Sparse Component Alignment (SCA) metric that measures alignment between neural and DNN components while preserving tuning axis information. The analysis involved decomposing each stream into 30 sparse components and comparing them to representations from multiple DNN architectures. They also established baselines using untrained networks and evaluated component selectivity through controlled image sets representing different visual categories.

## Key Results
- Distinct representational profiles exist across ventral (faces, scenes, bodies, food, text), lateral (group interactions, implied motion, hand actions, reach-spaces), and dorsal (scenes, implied motion) streams
- SCA scores show DNNs are significantly more aligned with ventral stream (0.187) than lateral (0.047) or dorsal (0.058) streams
- Standard alignment metrics fail to detect these differences due to rotational invariance
- SCA reveals a consistent ventral stream preference across multiple DNN architectures

## Why This Works (Mechanism)
Standard alignment metrics like CKA are rotationally invariant, meaning they cannot detect differences in the specific tuning properties of neural populations even when overall representational geometries are similar. The SCA metric overcomes this limitation by explicitly measuring alignment between individual sparse components that capture the dominant tuning axes in each visual stream. By decomposing neural responses into sparse components and measuring their alignment to DNN representations, SCA can detect when DNNs capture the computational properties of one stream better than others, even when standard metrics show similar overall alignment.

## Foundational Learning
- Sparse principal component analysis: Needed to identify dominant tuning axes in noisy neural data; quick check: verify components capture known visual categories
- Representational alignment metrics: Needed to compare neural and DNN representations; quick check: test metric behavior on synthetic data with known alignments
- Visual stream organization: Needed to interpret component selectivity patterns; quick check: validate component locations match established stream boundaries
- fMRI signal interpretation: Needed to understand measurement limitations; quick check: assess component reliability across subjects
- Component selectivity analysis: Needed to characterize functional properties of each stream; quick check: validate selectivity using controlled image sets

## Architecture Onboarding

**Component Map**
Sparse PCA decomposition -> SCA alignment calculation -> Cross-stream comparison

**Critical Path**
1. Obtain fMRI data from three visual streams
2. Apply sparse PCA to extract 30 components per stream
3. Extract DNN representations for same image set
4. Calculate SCA scores between neural and DNN components
5. Compare SCA scores across streams

**Design Tradeoffs**
- Component number (30) balances granularity with statistical reliability
- Sparsity constraint affects component interpretability vs. variance captured
- SCA preserves tuning information at cost of computational complexity
- Using untrained networks as baseline controls for general representational geometry

**Failure Signatures**
- Inconsistent component selectivity across subjects suggests poor signal quality
- SCA scores near baseline levels indicate lack of meaningful alignment
- Standard metrics showing differences while SCA does not suggests rotational alignment
- Failure to reproduce known stream properties in component analysis indicates methodological issues

**First Experiments**
1. Test SCA on synthetic data with known ground truth alignments
2. Validate component decomposition sensitivity to parameter choices
3. Apply pipeline to additional DNN architectures to test generality

## Open Questions the Paper Calls Out
None

## Limitations
- Sparse decomposition results depend heavily on choice of sparsity constraints and component number
- SCA metric requires further validation on independent datasets and synthetic data
- Comparison to untrained networks does not directly test computational principle capture
- Finding that standard metrics are rotationally invariant may not hold for all such metrics

## Confidence
- High confidence: Distinct representational profiles exist across ventral, lateral, and dorsal streams
- Medium confidence: SCA metric validly captures stream-specific alignment beyond standard metrics
- Medium confidence: DNNs are more aligned with ventral than lateral/dorsal streams

## Next Checks
1. Test sensitivity of component decomposition results to varying numbers of components (10-50 range) and different sparsity constraints to ensure findings are not artifacts of parameter choices
2. Validate SCA metric on synthetic data with known ground truth alignments to confirm it captures intended properties and compare its behavior to other alignment metrics
3. Apply the analysis pipeline to additional DNN architectures (e.g., ViT, ResNet variants) to test whether the ventral stream preference is architecture-specific or general across models