---
ver: rpa2
title: 'Logits Replay + MoClip: Stabilized, Low-Cost Post-Training with Minimal Forgetting'
arxiv_id: '2510.09152'
source_url: https://arxiv.org/abs/2510.09152
tags:
- moclip
- adamw
- training
- replay
- logits
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses catastrophic forgetting in LLM post-training,
  where domain specialization degrades general capabilities. It introduces Logits
  Replay + MoClip, a two-stage framework that records dynamic Top-K token subsets
  during Stage 0 and replays them in Stage 1 with exact renormalized losses to reduce
  computation and implicit regularization.
---

# Logits Replay + MoClip: Stabilized, Low-Cost Post-Training with Minimal Forgetting

## Quick Facts
- **arXiv ID:** 2510.09152
- **Source URL:** https://arxiv.org/abs/2510.09152
- **Reference count:** 34
- **Primary result:** Improves domain performance on Communication Technology and NL2SQL tasks while preserving general reasoning (MMLU, BBH, GPQA, MATH) and reduces training cost by over 40%.

## Executive Summary
This paper addresses catastrophic forgetting in LLM post-training, where domain specialization degrades general capabilities. It introduces Logits Replay + MoClip, a two-stage framework that records dynamic Top-K token subsets during Stage 0 and replays them in Stage 1 with exact renormalized losses to reduce computation and implicit regularization. To stabilize training under sparse supervision, MoClip caps gradient-momentum angles and applies arctan2-based rescaling. Empirically, the method improves domain performance on Communication Technology and NL2SQL tasks while preserving general reasoning (MMLU, BBH, GPQA, MATH) and reduces training cost by over 40%, offering a scalable path for domain adaptation without sacrificing generalization.

## Method Summary
The method uses a two-stage framework. Stage 0 collects logits from the base model by running inference on training data, selecting token positions using a bucket-based strategy (5 buckets by token confidence), and extracting dynamic Top-K indices (K_max=200) covering probability mass τ, always including the gold token. Stage 1 trains using the MoClip optimizer, which computes cross-entropy over the restricted set S_t with renormalization, caps the angle between gradient and momentum at ∆_max=45°, and applies arctan2-based scaling with ε=0. The approach achieves ~40% training cost reduction while improving domain accuracy and preserving general capabilities.

## Key Results
- Improves domain accuracy on Communication Technology and NL2SQL tasks while preserving general reasoning benchmarks
- Reduces training cost by over 40% through restricted vocabulary computation
- Maintains Relative L2 distance to base weights below 3.5%, indicating minimal forgetting
- Stable training with MoClip prevents loss spikes common in sparse-supervision scenarios

## Why This Works (Mechanism)

### Mechanism 1: Restricted Vocabulary Renormalization as Implicit Regularization
Training on dynamic Top-K token subsets with renormalized softmax reduces forgetting by limiting gradient interference from low-probability tokens. During Stage 0, the base model's Top-K predictions are recorded. In Stage 1, cross-entropy is computed only over this subset with renormalization, filtering noisy gradients from the tail tokens that would otherwise push parameters toward sharp minima. The gradient bias introduced by vocabulary truncation is bounded by the outside mass ρ, and setting τ high (e.g., 0.95) keeps bias small.

### Mechanism 2: Gradient-Momentum Angle Clipping Prevents Destructive Oscillations
MoClip caps the angle between current gradient g_t and previous momentum m_{t-1} at ∆_max to prevent sharp directional changes that destabilize sparse-supervision training. If φ_t > ∆_max, the gradient is decomposed into parallel and perpendicular components, with the perpendicular component scaled so the resulting angle equals ∆_max. This enforces cosine similarity ≥ cos(∆_max) with prior momentum direction, preventing convergence issues while allowing sufficient plasticity.

### Mechanism 3: Arctan2 Scaling Bounds Update Magnitude Without ε
Replacing Adam's update formula with arctan2-based scaling guarantees per-coordinate step bounds regardless of second-moment magnitude. Standard Adam uses ∆θ_t = -α·m̂_t/(√v̂_t + ε), while MoClip uses ∆θ_t = -α·(m̂_t/|m̂_t|)·arctan(|m̂_t|/√v̂_t). Since arctan(x) ∈ [0, π/2] for x ≥ 0, per-coordinate updates satisfy |∆θ_t(i)| ≤ α·π/2, eliminating need for ε and preventing explosive steps when v̂_t → 0.

## Foundational Learning

- **Concept: Softmax and Cross-Entropy Gradient**
  - **Why needed here:** Understanding that ∂CE/∂z = p - y is essential to see why truncating vocabulary changes gradient direction.
  - **Quick check question:** If full vocabulary softmax gives p = [0.7, 0.2, 0.1] and we renormalize over first two tokens only, what is the new probability distribution?

- **Concept: Adam Optimizer Mechanics**
  - **Why needed here:** MoClip modifies Adam's momentum and variance estimates; you need to understand how m_t and v_t accumulate before seeing why angle clipping and arctan2 scaling help.
  - **Quick check question:** In Adam, what happens to the update magnitude when v_t (second moment) becomes very small for a parameter?

- **Concept: Catastrophic Forgetting and Weight Interference**
  - **Why needed here:** The core problem is that fine-tuning gradients overwrite base-model knowledge; understanding this motivates why restricting supervision and stabilizing updates mitigate forgetting.
  - **Quick check question:** Why does fine-tuning on domain-specific data degrade performance on MMLU or MATH benchmarks that were never seen during fine-tuning?

## Architecture Onboarding

- **Component map:** Stage 0 (Logits Collection) -> Stage 1 (Replay Fine-Tuning) -> MoClip Optimizer
- **Critical path:**
  1. Implement dynamic Top-K with cumulative mass threshold τ and cap K_max
  2. Ensure gold token x_t is always in S_t
  3. Implement renormalized softmax over S_t
  4. Implement MoClip angle clipping
  5. Implement arctan2 scaling
  6. Verify one-epoch storage fits in memory (~5% of full logits)
- **Design tradeoffs:**
  - τ vs. compute savings: Higher τ → larger S_t → less bias but smaller speedup. Median |S_t|≈100 gave ~40% training reduction.
  - ∆_max vs. plasticity: Lower ∆_max → more stable but slower convergence (15% more steps). Recommended: [45°, 60°].
  - Position selection: Random (simple), Last-token (good for generation), Bucket-based (balances easy/hard, best for NL2SQL). Paper recommends bucket.
- **Failure signatures:**
  - Loss spikes: MoClip angle clipping not active or ∆_max too large
  - Domain accuracy drops: S_t too small or gold token not included
  - General retention poor: Logits Replay not actually being used or Stage 0 data mismatch
  - Training doesn't converge: ∆_max < 30° or learning rate mismatch
- **First 3 experiments:**
  1. Run Stage 0 on small dataset, verify |S_t| distribution matches paper (median ~100), confirm gold token always in S_t
  2. Train with Logits Replay + AdamW vs. Logits Replay + MoClip on single domain, expect lower loss variance with MoClip
  3. Grid search ∆_max ∈ {30°, 45°, 60°, 90°} and measure loss variance, domain accuracy, and MMLU retention

## Open Questions the Paper Calls Out

- **PEFT Integration:** Can Logits Replay be effectively integrated with parameter-efficient tuning methods like LoRA? The current framework validates full-parameter fine-tuning, and it's unclear if compressed Top-K supervision provides sufficient gradient signal for constrained subspaces without causing under-fitting.
- **Multi-Modal Extension:** Does the entropy-adaptive Top-K selection strategy generalize to multi-modal outputs? The Dynamic Top-K algorithm is designed around discrete token entropy and may be ineffective for continuous output spaces or different entropy distributions in vision/audio data.
- **Scalability Limits:** Do the stability guarantees and efficiency scale to models significantly larger than 8B parameters? Optimizer dynamics may behave differently in higher-dimensional parameter spaces where variance is inherently larger.

## Limitations
- Optimal coverage threshold τ and angle cap ∆_max are empirically chosen without rigorous sensitivity analysis
- Exact implementation details of bucket-based position selection are underspecified
- Method assumes availability of domain-specific training data and base model checkpoint
- Evaluation limited to specific general capability benchmarks (MMLU, BBH, GPQA, MATH)

## Confidence
- **High confidence:** The general framework and empirical improvements on domain tasks are well-defined and reproducible
- **Medium confidence:** MoClip optimizer's stability benefits are supported, but specific hyperparameters may not transfer optimally
- **Low confidence:** Implementation details of position selection and optimal τ value are underspecified

## Next Checks
1. **Sensitivity analysis of τ and ∆_max:** Run a 4×4 grid over τ∈{0.85, 0.90, 0.95, 0.99} and ∆_max∈{30°, 45°, 60°, 90°} on a single domain to identify Pareto-optimal settings
2. **Alternative position selection strategies:** Compare bucket-based selection against Last-token and Random on both NL2SQL and Communication Technology tasks
3. **Generalization to other benchmarks:** Evaluate forgetting on additional general capability tests like HellaSwag, WinoGrande, or GSM8K to ensure retention isn't limited to the specific test set