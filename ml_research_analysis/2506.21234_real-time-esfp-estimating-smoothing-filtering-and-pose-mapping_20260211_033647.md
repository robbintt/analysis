---
ver: rpa2
title: 'Real-Time ESFP: Estimating, Smoothing, Filtering, and Pose-Mapping'
arxiv_id: '2506.21234'
source_url: https://arxiv.org/abs/2506.21234
tags:
- pose
- human
- noise
- joint
- hpstm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "ESFP is an end-to-end pipeline that converts monocular RGB video\
  \ into executable joint trajectories for a low-cost 4-DoF desktop arm. It uses ROMP\
  \ for initial pose estimation, then applies HPSTM\u2014a Transformer-based smoothing\
  \ module that jointly predicts joint means and full covariances while enforcing\
  \ kinematic constraints\u2014to produce anatomically plausible, low-jerk motion."
---

# Real-Time ESFP: Estimating, Smoothing, Filtering, and Pose-Mapping

## Quick Facts
- arXiv ID: 2506.21234
- Source URL: https://arxiv.org/abs/2506.21234
- Reference count: 34
- Key outcome: ESFP achieves MPJPE of 27.34 mm on noisy synthetic pose sequences, outperforming Savitzky-Golay baselines while reducing MeanJerk by 37× and maintaining bone-length consistency within 1.68 mm

## Executive Summary
ESFP is an end-to-end pipeline that converts monocular RGB video into executable joint trajectories for a low-cost 4-DoF desktop arm. It uses ROMP for initial pose estimation, then applies HPSTM—a Transformer-based smoothing module that jointly predicts joint means and full covariances while enforcing kinematic constraints—to produce anatomically plausible, low-jerk motion. A variance-weighted filter suppresses residual noise using HPSTM's uncertainty estimates, and a geometric retargeting layer maps shoulder-elbow-wrist triples to the robot's polar workspace. On synthetic noisy pose sequences, HPSTM achieved MPJPE of 27.34 mm and MeanJerk of 0.0005, outperforming Savitzky-Golay baselines while maintaining bone-length consistency within 33.5 mm.

## Method Summary
ESFP processes monocular RGB video through three stages: (1) ROMP extracts 24-joint 3D skeletons from each frame; (2) HPSTM—a sequence-to-sequence Transformer with self-attention—smooths these sequences while predicting joint means and full covariances, enforcing constant bone lengths via differentiable forward kinematics; (3) a variance-weighted filter suppresses residual noise using HPSTM's uncertainty estimates, and a geometric retargeting layer maps shoulder-elbow-wrist triples to the robot's polar workspace. The system is trained on AMASS motion-capture data with a three-stage curriculum that introduces noise augmentation and uncertainty modeling progressively.

## Key Results
- MPJPE of 27.34 mm on synthetic noisy sequences, compared to 25.79 mm for Savitzky-Golay baseline
- MeanJerk reduced from 0.0185 to 0.0005, a 37× improvement
- Bone-length consistency improved from 43.79 mm to 1.68 mm standard deviation
- Variance-weighted filtering reduces BoneStdDev further to 1.47 mm when using covariance estimates

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Self-attention over temporal windows enables smoothing that respects both long-range motion context and inter-joint correlations.
- Mechanism: The Transformer encoder aggregates spatio-temporal features across T=31 frames, allowing the decoder to predict joint rotations conditioned on past and future context. This replaces frame-wise or per-joint independence assumptions.
- Core assumption: Human motion exhibits temporal coherence that can be captured within ~1-second windows at 30 Hz.
- Evidence anchors:
  - [abstract] "HPSTM—a sequence-to-sequence Transformer with self-attention—combines long-range temporal context with a differentiable forward-kinematics decoder"
  - [Page 2, Section III-B] "multi-head self-attention captures long-range temporal dependencies and cross-joint correlations, unlike window-bound MLP smoothers such as SmoothNet or per-joint Kalman variants like FLK"
  - [corpus] Weak direct evidence; neighbor papers focus on control pipelines, not pose smoothing architectures.
- Break condition: If motions exceed 1-second windows or contain rapid discontinuities, attention may blur legitimate high-frequency actions.

### Mechanism 2
- Claim: Differentiable forward-kinematics decoding enforces anatomical plausibility by constraining outputs to a fixed bone-length manifold.
- Mechanism: Rather than regressing 3D coordinates directly, HPSTM predicts root translation, joint rotations (quaternions), and per-joint bone lengths. A differentiable FK layer reconstructs global joint positions, ensuring limb segments retain consistent lengths across frames.
- Core assumption: Human skeletal structure is rigid within a sequence; bone-length variation in input is noise, not signal.
- Evidence anchors:
  - [abstract] "enforcing constant bone lengths and anatomical plausibility"
  - [Page 2, Section III-B] "Because limb lengths are constrained by the learned positive bone-length vector, every output pose lies on the human kinematic manifold"
  - [Page 5, Table I] BoneStdDev reduced from 43.79mm (noisy input) to 1.68mm (HPSTM-New), vs. 21.12mm for Savitzky-Golay
- Break condition: If subjects have significantly non-standard proportions or objects extend effective limb length, manifold constraints will bias estimates.

### Mechanism 3
- Claim: Learned covariance estimates enable variance-weighted filtering that suppresses residual noise proportionally to prediction uncertainty.
- Mechanism: HPSTM predicts a Cholesky factor per joint per frame, parameterizing a full 3x3 covariance matrix. Downstream filtering weights trajectories inversely to predicted variance, reducing influence of high-uncertainty frames.
- Core assumption: Covariance predictions correlate with actual estimation error; high variance indicates unreliable estimates.
- Evidence anchors:
  - [abstract] "root-normalized trajectories are variance-weighted according to HPSTM's uncertainty estimates, suppressing residual noise"
  - [Page 2, Section III-B] "Neither SmoothNet nor FLK provides such uncertainty quantification"
  - [Page 6, Table II] Covariance-enabled models (Cfg-3, 4, 7, 8) show improved BoneStdDev but slightly elevated MPJPE, suggesting uncertainty modeling trades accuracy for plausibility
  - [corpus] No direct corpus validation of variance-weighted filtering in pose pipelines
- Break condition: If covariance estimates are systematically miscalibrated (e.g., overconfident on outliers), variance-weighting may amplify rather than suppress errors.

## Foundational Learning

- **Concept: Forward Kinematics (FK)**
  - Why needed here: HPSTM's decoder uses FK to convert joint rotations + bone lengths into 3D positions, guaranteeing anatomical validity.
  - Quick check question: Given a 2-DoF planar arm with segment lengths L1=0.3m, L2=0.25m and angles θ1=45°, θ2=-30°, compute the end-effector position.

- **Concept: Cholesky Decomposition for Covariance Parameterization**
  - Why needed here: HPSTM outputs Cholesky factors (lower-triangular matrices) to represent valid positive-definite covariance matrices during training with NLL loss.
  - Quick check question: Why can't a neural network directly output covariance matrix elements without constraint?

- **Concept: Negative Log-Likelihood (NLL) Loss for Uncertainty**
  - Why needed here: Stage 3 training uses Gaussian NLL to learn both mean predictions and calibrated uncertainty estimates.
  - Quick check question: In the NLL formula, what happens to the loss when predicted variance goes to zero but the prediction error is non-zero?

## Architecture Onboarding

- **Component map:**
RGB Frame → ROMP (frozen) → 24×3 joint coords (camera frame)
    → HPSTM Encoder (T=31 window, self-attention)
    → HPSTM Decoder (queries → rotations + bone lengths + Cholesky factors)
    → FK Layer → Smoothed 24×3 coords + covariances
    → Variance-weighted Filter → Shoulder-elbow-wrist extraction
    → Geometric Retargeting (scale λ, rotation RH→R, offset oR, clipping)
    → uArm SDK (set_position at 20Hz)

- **Critical path:** ROMP accuracy → HPSTM window latency → covariance calibration → retargeting clipping bounds. Errors propagate; ROMP failures cannot be recovered by downstream modules.

- **Design tradeoffs:**
  - MPJPE vs. smoothness: Table I shows Savitzky-Golay achieves 25.79mm MPJPE vs. HPSTM's 37.50mm, but HPSTM reduces MeanJerk by 37× (0.0005 vs. 0.0185).
  - Covariance head: Table II shows +Covariance improves BoneStdDev (1.47mm vs. 2.02mm) but raises MPJPE (36.09mm vs. 31.94mm on clean data).
  - Window size T=31: Longer windows improve smoothing but add latency; non-causal processing requires buffering.

- **Failure signatures:**
  - ROMP occlusion failures: If ROMP misses a person for >T frames, HPSTM buffer empties, causing motion discontinuity.
  - Covariance overconfidence: If BoneStdDev is low but MPJPE is high, covariance estimates may be miscalibrated.
  - Workspace clipping: If pcmd consistently hits axis limits, dynamic scaling λ may be incorrectly set or Lh fallback triggered.

- **First 3 experiments:**
  1. **ROMP quality baseline:** Run ROMP on validation sequences, record per-joint MPJPE and bone-length variance. This establishes the upper bound for downstream refinement.
  2. **HPSTM ablation (no noise training):** Train HPSTM Stage 1 only (clean data, no noise augmentation). Compare MPJPE and MeanJerk against full 3-stage training on held-out noisy test sequences.
  3. **Covariance calibration check:** On a validation set, compute correlation between predicted variance (trace of covariance) and actual squared error. If correlation < 0.5, uncertainty estimates are not reliable for filtering.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can learned approaches like Action Chunking Transformers (ACT) outperform geometric retargeting for handling complex kinematic discrepancies in high-DoF robots?
- Basis in paper: [explicit] Section V states future work lies in "leveraging learned approaches such as Action Chunking Transformers (ACT)" to better navigate kinematic discrepancies for "higher-DoF robots."
- Why unresolved: The current implementation relies on a geometric retargeting layer designed for a 4-DoF arm, which may not capture the temporal abstractions or intent required for more complex, high-DoF imitations.
- What evidence would resolve it: A comparative study showing ACT-based mapping achieves higher task success rates or motion naturalness scores than geometric mapping on a robot with >4 DoF.

### Open Question 2
- Question: How can HPSTM's covariance outputs be utilized for adaptive uncertainty-aware control?
- Basis in paper: [explicit] Section V notes that future work will "explore adaptive loss weighting and uncertainty-aware control that fully exploit HPSTM's covariance outputs."
- Why unresolved: While the pipeline currently uses variance for filtering noise, it does not yet modulate robot execution parameters (e.g., speed, compliance) based on the predicted uncertainty.
- What evidence would resolve it: A control system demonstration where the robot automatically slows down or increases compliance when HPSTM outputs high covariance values in real-time.

### Open Question 3
- Question: Can the inverse relationship between covariance prediction and positional accuracy (MPJPE) be decoupled?
- Basis in paper: [inferred] Table II and Section V show that enabling the covariance head consistently degrades MPJPE (e.g., increasing from 25.99 mm to 32.32 mm) while improving bone consistency.
- Why unresolved: The authors note a "competition between uncertainty modelling and point accuracy," suggesting the current training objective or architecture forces a trade-off.
- What evidence would resolve it: A modified training curriculum or architecture that achieves bone consistency improvements (BoneMAE < 30mm) without incurring the observed MPJPE penalty.

## Limitations
- Validation is limited to synthetic noise experiments without real-world RGB-to-robot demonstrations
- ROMP's performance on challenging in-the-wild sequences is not characterized
- Covariance-based filtering lacks independent verification of uncertainty calibration
- Robot retargeting assumes fixed camera-robot geometry and static calibration
- 20 Hz command rate and 1-second temporal window impose hard constraints on responsiveness

## Confidence
- **Medium-High**: Architectural design is well-grounded, but validation lacks real-world RGB-to-robot demonstrations
- **Medium**: ROMP performance characterization missing for in-the-wild sequences
- **Low**: No independent verification of covariance calibration or uncertainty-aware filtering effectiveness

## Next Checks
1. Run HPSTM on real RGB sequences with ground-truth poses to assess actual noise-handling
2. Perform ablation studies comparing uncertainty-aware filtering against heuristic variance-weighting
3. Validate bone-length consistency on real subjects with non-standard proportions to test manifold constraints