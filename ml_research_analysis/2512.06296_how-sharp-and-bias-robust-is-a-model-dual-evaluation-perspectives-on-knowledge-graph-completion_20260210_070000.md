---
ver: rpa2
title: How Sharp and Bias-Robust is a Model? Dual Evaluation Perspectives on Knowledge
  Graph Completion
arxiv_id: '2512.06296'
source_url: https://arxiv.org/abs/2512.06296
tags:
- uni00000013
- uni00000011
- evaluation
- knowledge
- uni00000018
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper identifies two critical limitations in existing knowledge
  graph completion (KGC) evaluation: (1) predictive sharpness - how strictly we evaluate
  individual predictions, and (2) popularity-bias robustness - how well models perform
  on low-popularity entities. The authors propose PROBE, a novel evaluation framework
  consisting of a rank transformer (RT) that converts prediction ranks to scores based
  on desired sharpness levels, and a rank aggregator (RA) that weights scores by entity
  popularity.'
---

# How Sharp and Bias-Robust is a Model? Dual Evaluation Perspectives on Knowledge Graph Completion

## Quick Facts
- **arXiv ID:** 2512.06296
- **Source URL:** https://arxiv.org/abs/2512.06296
- **Authors:** Sooho Moon; Yunyong Ko
- **Reference count:** 37
- **Primary result:** PROBE evaluation framework identifies model performance on low-popularity entities and adjusts evaluation strictness through parametric rank transformation

## Executive Summary
This paper addresses critical limitations in knowledge graph completion (KGC) evaluation by introducing PROBE, a dual-perspective framework that assesses both predictive sharpness and popularity-bias robustness. The authors identify that existing metrics like MRR and Hits@K fail to capture how strictly we evaluate predictions and how well models perform on low-popularity entities. PROBE consists of a rank transformer that converts prediction ranks to scores based on desired sharpness levels, and a rank aggregator that weights scores by entity popularity. Experiments on FB15k237 and WN18RR datasets demonstrate that PROBE provides more reliable and comprehensive evaluation results compared to traditional metrics.

## Method Summary
PROBE is a novel evaluation framework for KGC that addresses two critical limitations: predictive sharpness and popularity-bias robustness. The framework consists of two components: (1) a rank transformer (RT) that applies an exponential transformation to prediction ranks, allowing evaluation at varying strictness levels through a sharpness parameter α, and (2) a rank aggregator (RA) that weights scores by entity popularity using a robustness parameter β. The rank transformer applies affine normalization to ensure scores are bounded between 0 and 1, while the rank aggregator down-weights predictions involving high-popularity entities to reduce evaluation bias. The final PROBE score is computed as a weighted average of transformed ranks, where weights are determined by entity popularity in the training data.

## Key Results
- PROBE reveals that models like RNNLogic are overestimated by traditional metrics due to performance on popular entities
- RotatE shows better robustness to popularity bias that was previously undervalued by MRR and Hits@K
- The framework enables flexible evaluation under varying real-world requirements by adjusting sharpness (α) and popularity-bias robustness (β) parameters
- PROBE scores are bounded in [0,1] for any α, unlike MRR which only provides asymptotic lower bounds

## Why This Works (Mechanism)

### Mechanism 1: Parametric Rank Transformation for Adjustable Sharpness
The rank transformer applies exponential transformation f*(r, α) = (f(r,α) − 1)/(1 − |E|^(−α)) + 1 where f(r,α) = 1/r^α. Higher α exponentially penalizes incorrect predictions; lower α reduces penalty for near-misses. This enables evaluation at varying strictness levels, revealing model behavior that fixed metrics like MRR (α=1) miss.

### Mechanism 2: Popularity-Adjusted Weighted Aggregation
The rank aggregator assigns weight w_q = 1/(ε + δ(q)_train)^β where δ(q)_train is the training degree of the queried entity. Higher β more aggressively discounts high-degree entities, reducing evaluation bias toward frequently-seen training entities. This addresses the power-law degree distributions in real-world KGs where 80% of entities appear in <10 triples.

### Mechanism 3: Affine Normalization for Bounded, Interpretable Scores
After computing f(r,α), affine rescaling ensures f*(1,α) = 1 and f*(|E|,α) = 0 regardless of α or entity set size. This provides fixed bounds for all scores, improving cross-model comparison and avoiding the asymptotic lower bounds issue of MRR variants.

## Foundational Learning

- **Rank-Based Evaluation Metrics (MRR, Hits@K)**: PROBE directly extends and critiques these metrics; understanding their construction is prerequisite to grasping RT/RA modifications.
  - Quick check: Can you explain why MRR assigns score 1/r to a prediction at rank r, and what this implies about the penalty for rank-10 vs. rank-100 errors?

- **Knowledge Graph Completion Link Prediction Protocol**: The evaluation framework operates on query triples with masked entities (h,r,?) or (?,r,t); familiarity with head/tail prediction setup is essential.
  - Quick check: For a test triple (Barack Obama, born_in, Hawaii), what are the two evaluation queries generated, and which entity degree is used for weighting each?

- **Power-Law Degree Distributions in Real-World Graphs**: The popularity-bias mechanism relies on the assumption that entity degrees follow a skewed distribution, making low-degree entities underrepresented in training.
  - Quick check: In a KG where 5% of entities appear in >1000 triples but 80% appear in <10 triples, how would a standard MRR evaluation likely overestimate model generalization?

## Architecture Onboarding

- **Component map:** Prediction module → Rank output → Rank Transformer (α parameter) → Normalized score → Rank Aggregator (β parameter, entity degrees) → Final PROBE score

- **Critical path:**
  1. Obtain predicted ranks from KGC model for all test queries
  2. Apply f*(r, α) using chosen sharpness level for each rank
  3. Look up training degree of the target entity for each query
  4. Compute weight w_q using β parameter
  5. Aggregate: (1/W) × Σ(w_i × c_i)

- **Design tradeoffs:**
  - Higher α → more sensitive to top-rank accuracy, may undervalue consistent mid-rank performance
  - Higher β → stronger fairness to low-degree entities, but increases variance if few low-degree samples exist
  - Paper recommends α > 1 for high-stakes domains; β > 0.4 for applications requiring robustness to popularity bias

- **Failure signatures:**
  - Scores clustering near 0 or 1 without discrimination → check if α is too extreme or if |E| is very small
  - Large score variance across random seeds with high β → likely insufficient low-degree test samples
  - PROBE score contradicts MRR ranking substantially → verify degree statistics are correctly loaded from training set

- **First 3 experiments:**
  1. Compute PROBE scores at α=1, β=0 (equivalent to MRR) for 2+ KGC models on FB15k237; verify results match standard MRR within numerical tolerance.
  2. For one model (e.g., RotatE), plot PROBE score vs. α ∈ {0.25, 0.5, 1.0, 2.0} with β=0 fixed; observe how score decreases and whether relative ranking to another model changes.
  3. For two models with differing bias profiles (e.g., RotatE vs. RNNLogic), compute PROBE score at β ∈ {0.0, 0.2, 0.4, 0.8} with α=1; confirm the model with better low-degree performance improves in relative ranking as β increases.

## Open Questions the Paper Calls Out

- **To what extent does PROBE generalize to diverse real-world knowledge graphs and emerging KGC model architectures?**
  - The conclusion states, "In future work, we plan to explore how well PROBE generalizes to other real-world KGs and KG models."
  - The experimental validation is restricted to only two datasets (FB15k237, WN18RR) and four specific models (RotatE, TuckEr, pLogicNet, RNNLogic).

- **How can optimal values for the predictive sharpness (α) and popularity-bias robustness (β) factors be theoretically determined for a specific application?**
  - The paper provides heuristics (e.g., "α > 1 for medical KGs") but lacks a systematic method for selecting these hyperparameters.
  - Users must currently rely on intuition or manual tuning to set the strictness and bias weights.

- **Does a higher PROBE score correlate more strongly with improved performance on downstream tasks than traditional metrics?**
  - The introduction motivates the work with downstream applications like drug discovery and RAG, but experiments only measure link prediction accuracy in isolation.
  - It is unclear if the evaluation perspectives of "sharpness" and "robustness" actually serve as better proxies for real-world utility.

## Limitations
- The framework's effectiveness on large-scale KGs (millions of entities) and domain-specific KGs (e.g., biomedical) remains untested
- Optimal parameter selection strategies for specific applications are not provided, requiring manual tuning
- Two critical values are unspecified: the exact value of the small constant ε in the weight function and complete training hyperparameters for the KGC models

## Confidence

- **High confidence**: The mathematical framework for RT and RA is internally consistent and the core claims about fixed bounds [0,1] for PROBE scores are well-supported
- **Medium confidence**: The empirical demonstration that PROBE reveals different model rankings compared to MRR is convincing on the tested datasets, but generalizability requires further validation
- **Low confidence**: Claims about PROBE's superiority for "more reliable and comprehensive evaluation" are primarily demonstrated through correlation analysis rather than validation of improved downstream decision-making

## Next Checks

1. **Parameter sensitivity analysis**: Systematically vary α and β parameters beyond the tested ranges (e.g., α ∈ {0.1, 3.0, 5.0} and β ∈ {1.0, 2.0}) on FB15k237 to identify break points where PROBE loses discriminative power or becomes unstable.

2. **Cross-dataset validation**: Apply PROBE to at least two additional KGs with different characteristics (e.g., a biomedical KG and a social network KG) to verify that popularity bias patterns and model ranking shifts observed on FB15k237 and WN18RR generalize.

3. **Application-grounded evaluation**: Partner with domain experts to map specific application requirements (e.g., medical diagnosis KGs requiring high sharpness vs. recommendation systems tolerating more uncertainty) to PROBE parameter settings, then validate whether PROBE-guided model selection improves actual system performance compared to MRR-based selection.