---
ver: rpa2
title: 'Machine-Facing English: Defining a Hybrid Register Shaped by Human-AI Discourse'
arxiv_id: '2505.23035'
source_url: https://arxiv.org/abs/2505.23035
tags:
- language
- human
- english
- korean
- users
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Machine-Facing English (MFE) is a register emerging from sustained\
  \ human\u2013AI interaction, characterized by syntactic rigidity, pragmatic simplification,\
  \ and hyper-explicit phrasing to enhance machine parseability. Drawing on Halliday\u2019\
  s register theory, enregisterment, and pragmatics, the study defines five core traits\u2014\
  redundant clarity, directive syntax, controlled vocabulary, flattened prosody, and\
  \ single-intent structuring\u2014that improve execution accuracy but compress expressive\
  \ range."
---

# Machine-Facing English: Defining a Hybrid Register Shaped by Human-AI Discourse

## Quick Facts
- arXiv ID: 2505.23035
- Source URL: https://arxiv.org/abs/2505.23035
- Reference count: 9
- Primary result: Machine-Facing English is a human-AI register with syntactic rigidity, pragmatic simplification, and hyper-explicit phrasing that improves execution accuracy but compresses expressive range

## Executive Summary
Machine-Facing English (MFE) emerges from sustained human-AI interaction as a hybrid register optimized for machine parseability. Drawing on Halliday's register theory and pragmatics, MFE is characterized by five core traits: redundant clarity, directive syntax, controlled vocabulary, flattened prosody, and single-intent structuring. The study reveals that these adaptations yield significant improvements in task execution accuracy while highlighting tensions between communicative efficiency and linguistic richness. Through qualitative observations from bilingual voice- and text-based sessions, the research demonstrates that MFE represents an evolving linguistic phenomenon shaped by the practical demands of human-AI discourse.

## Method Summary
The study employs qualitative observations from bilingual voice- and text-based sessions supplemented by reflexive drafting via Natural Language Declarative Prompting (NLD-P). Researchers analyzed interaction patterns between humans and AI systems, documenting linguistic adaptations that emerged to enhance machine comprehension. The methodology combines theoretical frameworks from register theory and pragmatics with empirical observations of real-world human-AI communication patterns, though specific measurement protocols and sample sizes are not detailed in the available information.

## Key Results
- 37% reduction in mis-parsed reminders when redundant parameters are included
- 22% reduction in pitch range observed in machine-directed speech
- Five core MFE traits identified: redundant clarity, directive syntax, controlled vocabulary, flattened prosody, and single-intent structuring

## Why This Works (Mechanism)
MFE works because it systematically reduces ambiguity and cognitive load for machine processing systems. By employing redundant clarity, directive syntax, and controlled vocabulary, speakers create inputs that align with the parsing capabilities and expectations of AI systems. The flattened prosody and single-intent structuring further optimize for machine comprehension by eliminating prosodic variation and complex sentence structures that can confuse parsing algorithms. This adaptation represents a pragmatic shift where humans modify their natural communication patterns to accommodate machine processing constraints, resulting in more reliable task execution.

## Foundational Learning
- Register Theory (Halliday): Understanding how language varies according to context and purpose; needed to frame MFE as a legitimate linguistic phenomenon rather than mere "broken" communication
- Enregisterment: The process by which specific linguistic features become associated with particular social contexts; needed to explain how MFE becomes recognizable as a distinct communicative mode
- Pragmatics: The study of language use in context; needed to analyze how meaning is negotiated between humans and machines
- Natural Language Processing: Understanding how machines parse and interpret human language; needed to explain why certain linguistic features improve machine comprehension
- Speech Prosody: The patterns of stress and intonation in spoken language; needed to analyze the 22% reduction in pitch range in machine-directed speech

## Architecture Onboarding
**Component Map:** Human speaker -> MFE adaptation -> AI parser -> Task execution -> Feedback loop
**Critical Path:** Human communication → MFE trait application → Machine parsing → Execution success/failure → Iterative refinement
**Design Tradeoffs:** Communicative efficiency vs. expressive richness; syntactic precision vs. natural flow; task accuracy vs. user satisfaction
**Failure Signatures:** Persistent mis-parsing despite MFE adaptation; user frustration with compressed expressiveness; breakdown of communication naturalness
**First Experiments:**
1. Compare task execution accuracy between natural English and MFE prompts across 100+ diverse commands
2. Measure prosodic variation in human speech when addressing AI vs. human interlocutors using pitch analysis software
3. Conduct user satisfaction surveys comparing MFE and natural language interactions for routine vs. complex tasks

## Open Questions the Paper Calls Out
None specified in the provided information.

## Limitations
- Lack of detailed measurement protocols and sample sizes undermines confidence in reported performance gains
- Qualitative observations based on small-scale sessions without reported inter-rater reliability or systematic coding frameworks
- Theoretical framing not rigorously tested against baseline natural-language interactions or across diverse AI systems
- No clear description of how "mis-parsed reminders" or "pitch range" were quantified and measured

## Confidence
- Descriptive characterization of MFE traits: Medium (grounded in established linguistic theory)
- Quantified claims of execution accuracy improvement: Low (lacks methodological transparency)
- Link between MFE and communicative efficiency tensions: Medium (conceptually plausible but inferred)

## Next Checks
1. Conduct controlled experiments with larger, diverse participant pools to replicate and statistically validate the claimed reductions in mis-parsed prompts and prosodic flattening
2. Systematically compare MFE performance across multiple AI platforms and natural-language parsing engines to assess generalizability
3. Implement blinded coding of interaction transcripts to establish inter-rater reliability for identifying MFE traits and their correlation with execution accuracy