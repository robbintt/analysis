---
ver: rpa2
title: 'On the Evolution of Federated Post-Training Large Language Models: A Model
  Accessibility View'
arxiv_id: '2508.16261'
source_url: https://arxiv.org/abs/2508.16261
tags:
- federated
- tuning
- llms
- learning
- fedllm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper provides a comprehensive survey on federated post-training
  of large language models (FedLLM), addressing the challenges of computational efficiency
  and privacy preservation in decentralized settings. The authors propose a novel
  taxonomy categorizing FedLLM approaches along two axes: model access-based (white-box,
  gray-box, black-box) and parameter efficiency-based optimization.'
---

# On the Evolution of Federated Post-Training Large Language Models: A Model Accessibility View

## Quick Facts
- arXiv ID: 2508.16261
- Source URL: https://arxiv.org/abs/2508.16261
- Reference count: 15
- One-line primary result: First comprehensive survey exploring integration of model access-based and parameter efficiency-based optimization in federated post-training of large language models (FedLLM).

## Executive Summary
This paper presents a comprehensive survey of federated post-training methods for large language models (FedLLM), addressing the dual challenges of computational efficiency and privacy preservation in decentralized settings. The authors propose a novel taxonomy categorizing FedLLM approaches along two axes: model access-based (white-box, gray-box, black-box) and parameter efficiency-based optimization. They trace the evolution from full-model fine-tuning to parameter-efficient methods like LoRA and prompt tuning, and examine emerging black-box techniques that treat LLMs as inference APIs using gradient-free optimization. The survey highlights key challenges in federated value alignment and emphasizes the need for enhanced privacy and security mechanisms in black-box settings.

## Method Summary
The survey synthesizes existing FedLLM approaches through a novel two-dimensional taxonomy: model access level (white-box, gray-box, black-box) and parameter efficiency optimization. It examines representative methods including FedLoRA (gray-box with LoRA adapters), FedPrompt (white-box prompt tuning), FedBPT (black-box gradient-free prompt optimization), and FedBiOT (gray-box offsite tuning with emulator distillation). The paper provides theoretical formulations for FedAvg aggregation and bi-level optimization in FedBiOT, while identifying key challenges in federated value alignment and privacy preservation. The survey calls for future work on self-contained FL-RLAIF systems, computational integrity verification in black-box settings, and efficiency integration for FedDPO.

## Key Results
- Proposes first comprehensive taxonomy integrating model access-based and parameter efficiency-based optimization in FedLLM.
- Identifies three model access paradigms (white-box, gray-box, black-box) with distinct optimization strategies and privacy guarantees.
- Highlights FedBiOT as pioneering approach for ownership-preserving gray-box tuning through emulator-adapter proxies.
- Identifies critical challenges in federated value alignment (DPO, RLHF, RLAIF) and privacy/security in black-box settings.

## Why This Works (Mechanism)

### Mechanism 1: Low-Rank Adaptation (LoRA) Reduces Communication Overhead
- Claim: LoRA-based adapter methods can achieve performance comparable to full model fine-tuning while transmitting only a small fraction of parameters.
- Mechanism: LoRA decomposes weight update matrices into low-rank representations (A × B instead of full ΔW), reducing the dimensionality of updates. In FedLoRA, clients train local adapters and transmit only these low-rank matrices to the server for aggregation, rather than full model weights.
- Core assumption: The effective updates required for downstream adaptation reside in a low-dimensional subspace.
- Evidence anchors:
  - [abstract] "One notable advancement in computational and communication efficiency is the use of low-rank adapters (LoRA)... reducing the dimensionality of weight update matrices."
  - [section 1] "FedLoRA... improving efficiency without altering the model architecture."
  - [corpus] Weak direct validation; corpus focuses on benchmarking and post-training analysis rather than LoRA-specific FL mechanisms.
- Break condition: If downstream tasks require updates spanning high-dimensional subspaces (complex reasoning, domain shifts), low-rank approximation may degrade performance.

### Mechanism 2: Zeroth-Order Optimization Enables Black-Box Tuning
- Claim: Federated tuning can proceed without gradient access by using derivative-free optimization on input-output pairs.
- Mechanism: Zeroth-order methods (e.g., CMA-ES, random projection search) estimate gradient directions through forward-pass perturbations. FedBPT uses covariance matrix adaptation to search for optimal continuous prompt distributions; FedMeZO incorporates memory-efficient ZOO with LoRA for full-parameter tuning.
- Core assumption: The objective landscape is sufficiently smooth for finite-difference approximations to guide optimization.
- Evidence anchors:
  - [section 5] "FedMeZO incorporating a memory-efficient Zeroth-Order Optimization method... analyzes the convergence to examine the theoretical underpinnings of ZOO-based FL."
  - [section 5] "FedBPT adopts a gradient-free optimization that leverages CMA-ES to search for optimal distributions of the continuous prompt."
  - [corpus] FedOne (arXiv:2506.14929) addresses query efficiency in black-box discrete prompt learning, supporting feasibility but noting efficiency challenges.
- Break condition: High query costs (many forward passes per optimization step) and convergence instability under heterogeneous data distributions may limit practical deployment.

### Mechanism 3: Offsite Tuning Preserves Model Ownership While Enabling Local Adaptation
- Claim: Compressed model proxies (emulators + adapters) can substitute for full model access, enabling federated tuning without exposing proprietary weights.
- Mechanism: The server compresses the frozen LLM into a lightweight emulator (ε*) via layer-drop compression, pairs it with trainable adapters (A), and broadcasts only this proxy. Clients fine-tune adapters locally; only adapters return to the server. FedBiOT adds bi-level optimization to align emulator distributions with client data.
- Core assumption: Compressed emulators retain sufficient representational capacity for adapter training to transfer to the full model.
- Evidence anchors:
  - [section 4.1] "Off-site tuning significantly reduces computation overhead while preserving LLMs' ownership in the gray-box setting."
  - [section 4.1] FedBiOT equation (2-3) shows bi-level optimization minimizing data discrepancy between server and client distributions.
  - [corpus] No direct corpus validation; related work on post-training structural changes (arXiv:2509.17866) suggests compression may alter internal representations.
- Break condition: If layer-drop compression removes critical neurons, adapter training on emulators may not transfer, causing performance gaps.

## Foundational Learning

- Concept: Federated Averaging (FedAvg)
  - Why needed here: The foundational aggregation algorithm underlying all FedLLM methods; defines how local updates combine into global parameters.
  - Quick check question: Can you write the weighted averaging formula for aggregating client models with heterogeneous data sizes?

- Concept: Parameter-Efficient Fine-Tuning (PEFT)
  - Why needed here: Enables practical FedLLM by reducing memory and communication costs; includes LoRA, adapters, and prompt tuning.
  - Quick check question: What is the rank of a typical LoRA adapter, and how does it relate to the original weight matrix dimensions?

- Concept: Zeroth-Order Optimization
  - Why needed here: Required for black-box scenarios where only inference APIs are available; replaces backpropagation with forward-pass-based gradient estimation.
  - Quick check question: How many forward passes are needed to estimate a gradient via finite differences for a parameter vector of dimension d?

## Architecture Onboarding

- Component map: Server -> Clients -> Communication Layer -> Aggregation
- Critical path:
  1. Determine access level (white/gray/black-box) based on model availability.
  2. Select efficiency method (full fine-tuning, LoRA, prompt tuning) based on client compute.
  3. Choose optimization (gradient-based for white/gray-box; ZOO for black-box).
  4. Implement aggregation strategy (FedAvg for parameters; stacking for heterogeneous LoRA ranks).
- Design tradeoffs:
  - Full model access + full fine-tuning: Best performance, impractical communication costs.
  - Gray-box + LoRA: Balanced efficiency/performance; requires partial model access.
  - Black-box + prompt tuning: Highest privacy/efficiency; highest query costs; may underperform on complex tasks.
  - Offsite tuning: Preserves ownership but risks emulator-client distribution mismatch.
- Failure signatures:
  - Convergence stalls with heterogeneous clients → check LoRA rank heterogeneity handling (use FLoRA stacking).
  - Black-box tuning requires excessive API calls → implement seed-based communication (FedKSeed) or discrete token search.
  - Adapter performance degrades after aggregation → verify aggregation is mathematically valid for low-rank decomposition.
  - Emulator-trained adapters fail on full model → increase emulator fidelity or use layer-wise compression (FedPFT).
- First 3 experiments:
  1. Baseline comparison: Implement FedSFT (full model), FedLoRA, and FedPrompt on a standardized benchmark (e.g., instruction tuning) with controlled non-IID data; measure accuracy vs. communication cost.
  2. Black-box feasibility test: Deploy FedBPT with CMA-ES on an inference-only API; log query counts and convergence rate; compare against gradient-based prompt tuning.
  3. Ownership preservation validation: Implement FedBiOT with layer-drop vs. layer-wise compression; measure adapter transfer gap (performance difference between emulator-trained and full-model-trained adapters).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can a pre-trained model within a Federated Learning system effectively generate preferences to reward its own fine-tuned version, thereby creating a self-contained Federated RLAIF system?
- Basis in paper: [explicit] Section 6 asks, "can the pre-trained model in FedLLM effectively generate preferences to reward its fine-tuned version and create a self-contained FL system?"
- Why unresolved: RLAIF typically relies on an external, off-the-shelf LLM for annotation. Relying on the model being fine-tuned creates a circular dependency that may impact preference quality.
- Evidence: Empirical studies comparing the alignment performance of FedLLM using self-generated feedback versus external teacher models.

### Open Question 2
- Question: How can computational integrity be verified and malicious actors (e.g., trojans, poisoning) be detected in black-box, inference-only FedLLM settings?
- Basis in paper: [explicit] Section 6 states that the black-box nature of APIs makes it "more challenging to verify or audit computational integrity," making detection of trojans significantly harder.
- Why unresolved: Standard auditing requires access to model weights or gradients, which are unavailable in the inference-only paradigm.
- Evidence: Development of protocols that verify API computation correctness without accessing internal model states.

### Open Question 3
- Question: How can efficiency-based optimization methods be effectively integrated into a comprehensive workflow for Federated Direct Preference Optimization (FedDPO)?
- Basis in paper: [explicit] Section 6 identifies "applying existing efficiency-based optimization methods to FedDPO" as a "straightforward future direction" to bridge the gap in federated value alignment.
- Why unresolved: Most current efficiency research focuses on supervised fine-tuning (SFT); adapting these for the specific data pairs and loss functions of DPO in a federated context requires further framework integration.
- Evidence: A unified framework that successfully implements PEFT or prompt tuning within a FedDPO loop while maintaining communication efficiency.

## Limitations

- **Empirical validation gaps**: The survey lacks direct experimental evidence for many proposed mechanisms. For example, the effectiveness of FedBiOT's emulator-adapter transfer and the convergence properties of black-box methods like FedMeZO are theorized but not empirically demonstrated. This limits confidence in practical feasibility claims.
- **Hyperparameter and implementation ambiguity**: Key design choices (e.g., LoRA rank, local epochs, communication frequency) are not specified for the surveyed methods. Without these, reproducibility is challenging, and performance comparisons may be misleading.
- **Scope constraints**: The survey focuses on model access and parameter efficiency but does not address broader challenges like task heterogeneity, fairness in federated aggregation, or robustness to client dropout—critical for real-world deployment.

## Confidence

- **High confidence**: The taxonomy structure (model access-based and parameter efficiency-based axes) is well-grounded and logically consistent. The categorization of white-box, gray-box, and black-box scenarios is standard in federated learning literature.
- **Medium confidence**: The proposed mechanisms (LoRA, ZOO, offsite tuning) are theoretically sound and supported by related work, but their specific application to LLMs in federated settings lacks direct empirical validation in the survey.
- **Low confidence**: Claims about the superiority of black-box methods for privacy and efficiency are not substantiated with performance benchmarks or comparisons to gradient-based approaches.

## Next Checks

1. **Implement and benchmark FedLoRA**: Reproduce FedLoRA on a standard instruction-tuning dataset (e.g., FLAN) with non-IID client data. Measure accuracy vs. communication cost against full-model FedAvg. Diagnose convergence with heterogeneous LoRA ranks using FLoRA stacking.

2. **Test black-box feasibility with FedBPT**: Deploy FedBPT on an inference-only LLM API (e.g., OpenAI or open-source quantized model). Track API call counts, convergence rate, and final performance. Compare against gradient-based prompt tuning on the same task.

3. **Validate emulator transfer in FedBiOT**: Train adapters on a layer-drop compressed emulator (FedBiOT) and test transfer to the full model. Measure the performance gap between emulator-trained and full-model-trained adapters. Experiment with layer-wise vs. global compression to optimize fidelity.