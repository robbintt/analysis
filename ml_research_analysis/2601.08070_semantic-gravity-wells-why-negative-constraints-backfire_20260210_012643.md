---
ver: rpa2
title: 'Semantic Gravity Wells: Why Negative Constraints Backfire'
arxiv_id: '2601.08070'
source_url: https://arxiv.org/abs/2601.08070
tags:
- target
- failure
- failures
- instruction
- probability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper conducts the first comprehensive mechanistic investigation\
  \ of why negative constraints (e.g., \"do not use word X\") fail in large language\
  \ models. The study introduces semantic pressure, a measure of the model's intrinsic\
  \ probability of generating the forbidden token, and demonstrates that violation\
  \ probability follows a tight logistic relationship with pressure (p=\u03C3(-2.40+2.27\xB7\
  P0), n=40,000 samples, slope 95% CI [2.21,2.33])."
---

# Semantic Gravity Wells: Why Negative Constraints Backfire

## Quick Facts
- arXiv ID: 2601.08070
- Source URL: https://arxiv.org/abs/2601.08070
- Authors: Shailesh Rana
- Reference count: 5
- Key outcome: Negative constraints fail because forbidden tokens are paradoxically primed by their mention in instructions, with suppression signals 4.4× weaker in failures versus successes

## Executive Summary
This paper provides the first comprehensive mechanistic explanation for why negative constraints ("do not use word X") fail in large language models. The study introduces semantic pressure as a measure of the model's intrinsic probability of generating forbidden tokens, revealing that violation probability follows a tight logistic relationship with this pressure. Through layer-wise analysis using the logit lens technique, the research identifies two mechanistically distinct failure modes: priming failure, where mentioning the forbidden word paradoxically activates it, and override failure, where late-layer networks generate strong positive contributions toward the target. The findings reveal a fundamental tension in negative constraint design: the very act of naming a forbidden word primes the model to produce it.

## Method Summary
The study conducted large-scale experiments (n=40,000 samples) on GPT-3.5, introducing semantic pressure as a measure of intrinsic token generation probability. Using the logit lens technique, the researchers analyzed layer-wise contributions to constraint adherence, comparing successful versus failed constraint applications. Activation patching was employed to identify causally responsible layers, while statistical analysis quantified the relationship between semantic pressure and violation probability through logistic regression. The analysis distinguished between two failure modes based on attention patterns and layer contributions.

## Key Results
- Violation probability follows a tight logistic relationship with semantic pressure (p=σ(-2.40+2.27·P0), n=40,000 samples)
- Suppression signals are 4.4× weaker in failures (5.2% vs 22.8% in successes)
- Two mechanistically distinct failure modes identified: priming failure (87.5% of violations) and override failure (12.5%)
- Layers 23-27 are causally responsible for failures, confirmed through activation patching

## Why This Works (Mechanism)
The mechanism operates through a fundamental tension in negative constraint design. When an instruction mentions a forbidden word, it paradoxically activates the semantic representation of that word in the model's attention mechanisms. This priming effect is particularly strong in the middle layers of the transformer. The model then generates two types of failure responses: either the primed representation overwhelms the explicit suppression signal (priming failure), or late-layer feed-forward networks generate strong positive contributions toward the forbidden token, overriding earlier suppression signals (override failure). The semantic pressure metric captures the model's baseline propensity to generate the forbidden token, explaining why some negative constraints are more prone to failure than others.

## Foundational Learning
- **Semantic pressure**: A measure of intrinsic token generation probability, needed to quantify baseline propensity for forbidden tokens; quick check: verify pressure predictions match empirical generation frequencies
- **Logit lens technique**: Layer-wise analysis method, needed to trace how instructions transform into token predictions; quick check: confirm layer representations align with expected semantic transformations
- **Activation patching**: Causal intervention method, needed to identify which layers cause failures; quick check: verify patch results are reproducible across different constraint types
- **Attention mechanism**: How models process instruction semantics, needed to understand priming effects; quick check: confirm attention patterns match qualitative assessments of priming
- **Feed-forward networks**: Late-layer transformation mechanisms, needed to explain override failures; quick check: verify FF layer contributions correlate with override failure rates
- **Logistic regression**: Statistical modeling approach, needed to quantify relationship between pressure and violations; quick check: confirm confidence intervals are tight and stable

## Architecture Onboarding

**Component map**: Input embedding -> Attention heads (layers 1-12) -> Feed-forward networks (layers 1-12) -> Residual connections -> Layer normalization -> Output projection

**Critical path**: Instruction processing occurs through attention mechanisms that activate semantic representations, which are then transformed by feed-forward networks. The logit lens reveals how these representations evolve layer by layer toward final token predictions.

**Design tradeoffs**: The transformer architecture's attention mechanism naturally activates semantic representations mentioned in instructions, creating the priming effect. Feed-forward networks provide late-stage transformation capacity that can override earlier suppression signals, enabling override failures.

**Failure signatures**: Priming failures show early activation of forbidden tokens with weak suppression signals throughout. Override failures show strong late-layer feed-forward contributions toward forbidden tokens despite earlier suppression attempts.

**3 first experiments**: (1) Test semantic pressure predictions on new forbidden tokens, (2) Verify layer-wise asymmetries in a different model size, (3) Confirm activation patching results with alternative patching methods

## Open Questions the Paper Calls Out
None

## Limitations
- Analysis limited to single model architecture (GPT-3.5)
- Two failure modes may not be exhaustive of all failure types
- Semantic pressure metric may not capture all relevant factors

## Confidence
- **High**: Logistic relationship between violation probability and pressure, layer-wise asymmetries in suppression signals
- **Medium**: Specific failure mode characterizations, semantic pressure metric validity
- **Low**: Claims about generalizability beyond studied model

## Next Checks
1. Replicate logistic relationship and failure mode analysis across multiple model architectures and sizes
2. Test whether layers 23-27 show similar causal importance across different negative constraint types
3. Investigate alternative explanations for observed asymmetries, such as differences in residual stream representations