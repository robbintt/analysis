---
ver: rpa2
title: Closing the Data-Efficiency Gap Between Autoregressive and Masked Diffusion
  LLMs
arxiv_id: '2510.09885'
source_url: https://arxiv.org/abs/2510.09885
tags:
- masked
- fine-tuning
- paraphrases
- training
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper compares how autoregressive and diffusion language models
  learn new facts from unstructured text during fine-tuning. While autoregressive
  models require paraphrase augmentation to generalize knowledge into question-answering
  and still fail on backward questions due to the reversal curse, diffusion models
  learn both forward and backward QA effectively without paraphrases.
---

# Closing the Data-Efficiency Gap Between Autoregressive and Masked Diffusion LLMs

## Quick Facts
- arXiv ID: 2510.09885
- Source URL: https://arxiv.org/abs/2510.09885
- Reference count: 40
- This paper proposes masked fine-tuning for autoregressive models to match diffusion models' data efficiency for knowledge injection while preserving decoder-only architecture advantages

## Executive Summary
This paper addresses a fundamental efficiency gap in how autoregressive and diffusion language models learn new facts from unstructured text. Autoregressive models require paraphrase augmentation to generalize knowledge into question-answering and still fail on backward questions due to the reversal curse, while diffusion models learn both forward and backward QA effectively without paraphrases. The authors propose masked fine-tuning, which prompts autoregressive models to reconstruct masked documents in context during fine-tuning. This approach reduces reliance on paraphrases, mitigates the reversal curse, and improves math task performance over standard supervised fine-tuning. The method achieves comparable or better accuracy to diffusion models while maintaining the decoder-only architecture.

## Method Summary
The paper introduces masked fine-tuning as an alternative to standard supervised fine-tuning for autoregressive language models. Instead of training the model to predict the next token given previous context, masked fine-tuning prompts the model to reconstruct masked-out portions of documents in context. This creates a bidirectional learning signal that helps the model learn relationships in both directions, addressing the reversal curse problem where autoregressive models struggle to answer backward questions. The approach is evaluated against both standard supervised fine-tuning and diffusion models across factual knowledge injection tasks, demonstrating improved data efficiency and bidirectional generalization without requiring paraphrase augmentation.

## Key Results
- Masked fine-tuning achieves parity with diffusion models on forward and backward question-answering without requiring paraphrase augmentation
- The approach mitigates the reversal curse, enabling autoregressive models to answer both directions of fact pairs effectively
- Masked fine-tuning improves math task performance over standard supervised fine-tuning while maintaining decoder-only architecture advantages

## Why This Works (Mechanism)
The paper demonstrates that masked fine-tuning creates a bidirectional learning signal by forcing the autoregressive model to reconstruct masked portions of text. This contrasts with standard next-token prediction, which only learns unidirectional relationships. By training on document reconstruction tasks, the model learns to attend to both preceding and following context when filling in missing information, effectively simulating the bidirectional attention that diffusion models naturally possess. This bidirectional exposure during training enables the model to generalize knowledge in both forward and backward directions, solving the reversal curse that plagues standard autoregressive fine-tuning.

## Foundational Learning
- **Reversal curse**: A phenomenon where autoregressive models can answer "A is B" but fail to answer "B is what?" when learning from unstructured text. This occurs because standard fine-tuning only trains unidirectional relationships.
  - Why needed: Understanding this limitation is crucial as it explains why standard autoregressive models require extensive paraphrase augmentation for bidirectional knowledge generalization
  - Quick check: Test models on simple fact pairs (e.g., "Paris is the capital of France" vs "France's capital is what?") to verify bidirectional knowledge retention

- **Knowledge injection**: The process of adding new facts to pre-trained language models through fine-tuning on unstructured text containing those facts
  - Why needed: This is the core problem the paper addresses - improving how models learn new information from raw text without extensive augmentation
  - Quick check: Compare model performance on injected facts before and after fine-tuning to measure knowledge acquisition efficiency

- **Paraphrase augmentation**: Creating multiple textual variants of the same fact to improve model generalization during fine-tuning
  - Why needed: Standard autoregressive models heavily depend on this technique to overcome their unidirectional learning limitations
  - Quick check: Measure performance degradation when removing paraphrase augmentation from standard fine-tuning workflows

## Architecture Onboarding
- **Component map**: Input text -> Masked tokens -> Autoregressive decoder with bidirectional context attention -> Reconstructed text -> Loss computation (reconstruction error)
- **Critical path**: The reconstruction objective creates bidirectional context attention during training, which is the key innovation that enables learning relationships in both directions
- **Design tradeoffs**: Masked fine-tuning sacrifices the pure unidirectional nature of autoregressive models during training to gain bidirectional knowledge generalization, while diffusion models maintain bidirectional attention throughout but sacrifice inference speed
- **Failure signatures**: Models may overfit to reconstruction tasks at the expense of general language capabilities, or the masking strategy may not sufficiently expose bidirectional relationships for complex multi-hop reasoning
- **First experiments**:
  1. Test masked fine-tuning on simple fact pairs (A is B) to verify reversal curse mitigation
  2. Compare paraphrase augmentation requirements between standard and masked fine-tuning
  3. Evaluate math problem performance to assess procedural knowledge benefits

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can masked fine-tuning support continual learning in agentic systems without succumbing to catastrophic forgetting?
- Basis in paper: The authors conclude by stating, "We hope future work scales this paradigm to continual, real-world memory and agent learning settings."
- Why unresolved: The current experiments focus on single-session knowledge injection on static datasets, rather than sequential updates where the model must retain previously learned information
- What evidence would resolve it: Experiments testing sequential knowledge injection where the model is evaluated on both newly injected facts and facts from prior training steps

### Open Question 2
- Question: Does masked fine-tuning generalize to procedural knowledge domains beyond mathematics, such as coding or logical reasoning?
- Basis in paper: The authors suggest "broader applicability of the demasking objective" based on math SFT results but do not test other forms of procedural knowledge
- Why unresolved: The paper only verifies improved performance on GSM8K and MATH; it remains unconfirmed if the reconstruction objective aids structured logic or programming languages
- What evidence would resolve it: Application of masked SFT to coding tasks (e.g., HumanEval) or multi-step reasoning benchmarks (e.g., Big-Bench Hard) to compare against standard SFT

### Open Question 3
- Question: Does the bidirectional nature of masked fine-tuning degrade pre-existing general capabilities or cause unmeasured catastrophic forgetting?
- Basis in paper: The paper emphasizes successful knowledge injection but does not report metrics on the retention of general language proficiency or pre-trained factual knowledge unrelated to the injection targets
- Why unresolved: While the method solves the reversal curse, altering the fine-tuning objective could potentially interfere with the model's original distribution or capabilities
- What evidence would resolve it: Evaluation of general benchmarks (e.g., MMLU, HellaSwag) before and after masked fine-tuning to ensure stability of general capabilities

## Limitations
- The paper demonstrates improvements on specific factual recall and math tasks but does not extensively test on broader benchmarks or longer context windows where autoregressive models typically struggle
- The comparison with diffusion models assumes similar computational budgets and training setups, which may not hold in practice given different sampling characteristics and inference trade-offs
- The mechanism for why masked fine-tuning mitigates the reversal curse is not fully explained, though the empirical results are well-supported

## Confidence
- High: Masked fine-tuning reduces dependence on paraphrase augmentation compared to standard supervised fine-tuning
- High: Masked fine-tuning maintains decoder-only architecture advantages for autoregressive inference
- Medium: Masked fine-tuning generalizes to complex relational reasoning and multi-hop inference scenarios
- Medium: Masked fine-tuning provides consistent gains across different math domains beyond the tested arithmetic problems

## Next Checks
1. Test masked fine-tuning on long-document reasoning tasks (e.g., narrative understanding, multi-paragraph question answering) to evaluate performance degradation with increased context length
2. Evaluate the approach on multi-hop reasoning benchmarks to determine if reversal curse mitigation extends to complex inference chains beyond simple fact pairs
3. Compare inference efficiency and wall-clock time for masked fine-tuning fine-tuned autoregressive models versus diffusion models across different generation lengths to quantify the practical trade-offs of the architectural advantages claimed