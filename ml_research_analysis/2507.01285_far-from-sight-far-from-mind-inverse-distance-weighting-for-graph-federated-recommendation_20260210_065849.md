---
ver: rpa2
title: 'Far From Sight, Far From Mind: Inverse Distance Weighting for Graph Federated
  Recommendation'
arxiv_id: '2507.01285'
source_url: https://arxiv.org/abs/2507.01285
tags:
- uni00000013
- user
- uni00000048
- uni00000011
- uni00000014
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of aggregating user embeddings
  in graph federated recommendation systems, where existing methods fail to account
  for user similarity and the importance of anchor users. The authors propose Dist-FedAvg,
  a distance-based aggregation method that assigns higher weights to users with similar
  embeddings while preserving the influence of anchor users.
---

# Far From Sight, Far From Mind: Inverse Distance Weighting for Graph Federated Recommendation

## Quick Facts
- **arXiv ID**: 2507.01285
- **Source URL**: https://arxiv.org/abs/2507.01285
- **Reference count**: 40
- **Key outcome**: Dist-FedAvg outperforms baseline aggregation methods on five datasets with NDCG@10 improvements of 0.4027±0.018 on FilmTrust and HR@10 improvements of 0.89±0.0238

## Executive Summary
This paper addresses a fundamental challenge in graph federated recommendation systems: effectively aggregating user embeddings from decentralized clients while preserving user similarity and anchor user importance. Existing aggregation methods like FedAvg and SimpleAvg fail to account for the varying relevance of different users' embeddings to the global model. The authors propose Dist-FedAvg, an inverse distance weighting approach that assigns higher aggregation weights to users with similar embeddings while maintaining the influence of anchor users through linear interpolation.

The proposed method computes a distance matrix using Minkowski distance between user embeddings, normalizes inverse distances to create averaging weights, and applies linear interpolation with anchor user embeddings. Dist-FedAvg demonstrates consistent superiority over baseline methods across five datasets (MovieLens-100k, MovieLens-1M, LastFM-2k, Amazon Music, FilmTrust), achieving significant improvements in recommendation quality metrics. The method integrates seamlessly into existing federated frameworks and shows particular effectiveness when paired with simpler item aggregation methods.

## Method Summary
Dist-FedAvg introduces a distance-based aggregation strategy for federated recommendation systems that addresses the limitations of existing methods in handling user similarity and anchor user preservation. The method computes pairwise distances between user embeddings using Minkowski distance, then creates aggregation weights by normalizing inverse distances. These weights determine how much each user's embedding contributes to the global model. To preserve anchor user influence, Dist-FedAvg applies linear interpolation between the distance-weighted average and anchor user embeddings, with a decay parameter α that decreases over training rounds to handle early-round embedding irrelevance.

The aggregation process operates in two phases: user embedding aggregation and item embedding aggregation. For user embeddings, Dist-FedAvg calculates the weighted average based on inverse distances, then interpolates with anchor users. For item embeddings, the method can use either FedAvg or SimpleAvg. The decay strategies for α include exponential decay (α(t) = α₀ * e^(-λt)), step decay (α(t) = α₀ * decay^(t/T)), and cosine decay (α(t) = α₀ * (1 + cos(πt/T))/2), where t is the round number and T is the total number of rounds.

## Key Results
- Dist-FedAvg achieves NDCG@10 improvements of 0.4027±0.018 on FilmTrust dataset compared to baseline methods
- HR@10 improvements of 0.89±0.0238 are observed on FilmTrust when using Dist-FedAvg
- Consistent outperformance across five datasets including MovieLens-100k, MovieLens-1M, LastFM-2k, Amazon Music, and FilmTrust
- Method shows particular effectiveness when paired with simpler item aggregation methods like FedAvg or SimpleAvg

## Why This Works (Mechanism)
The inverse distance weighting mechanism works because user embeddings in federated recommendation systems exhibit meaningful geometric relationships that reflect user preferences and similarities. Users with similar embeddings are likely to have similar preferences, making their contributions more relevant to each other's recommendation quality. By assigning higher weights to closer embeddings, Dist-FedAvg ensures that the global model benefits more from similar users' preferences while still incorporating diverse perspectives through the distance-weighted averaging. The anchor user interpolation preserves critical user-specific information that might otherwise be lost in pure averaging, maintaining recommendation quality for key users throughout training.

## Foundational Learning
**Minkowski Distance**: A metric that generalizes Euclidean and Manhattan distances, calculated as d(x,y) = (Σ|xᵢ-yᵢ|ᵖ)^(1/p). Needed for measuring similarity between user embeddings; quick check involves verifying distance calculations between sample vectors.

**Inverse Distance Weighting**: A spatial interpolation technique that assigns weights inversely proportional to distance. Needed to prioritize similar users' contributions; quick check involves confirming weight normalization sums to 1.

**Linear Interpolation**: A weighted average between two values using parameter α. Needed to blend distance-weighted averages with anchor users; quick check involves verifying interpolation formula at boundary conditions.

**Exponential Decay**: Mathematical function α(t) = α₀ * e^(-λt) that decreases over time. Needed to reduce anchor user influence as embeddings become more reliable; quick check involves confirming decay rate affects final α appropriately.

**Federated Averaging (FedAvg)**: Standard aggregation method averaging client updates. Needed as baseline comparison; quick check involves verifying weight calculation and averaging process.

## Architecture Onboarding

### Component Map
Clients (N users) -> Distance Matrix Computation -> Inverse Distance Weighting -> Linear Interpolation with Anchors -> Global User Embedding -> Item Aggregation (FedAvg/SimpleAvg) -> Global Model

### Critical Path
1. Client-side user and item embedding computation
2. Distance matrix calculation between all user embeddings
3. Weight normalization and inverse distance weighting
4. Linear interpolation with anchor users
5. Item aggregation using chosen method
6. Global model update and broadcast

### Design Tradeoffs
The method trades computational overhead (O(N²) distance calculations) for improved aggregation quality. Anchor user interpolation adds complexity but preserves critical user information. Choice between FedAvg and SimpleAvg for item aggregation balances accuracy against computational efficiency.

### Failure Signatures
- Degraded performance when anchor users' embeddings become unreliable
- Computational bottlenecks with large user populations due to distance matrix computation
- Overfitting to local clusters if distance weighting becomes too extreme

### First Experiments
1. Baseline comparison using FedAvg and SimpleAvg on all five datasets
2. Sensitivity analysis for Minkowski distance parameter p (1, 2, 3)
3. Comparison of different decay strategies (exponential, step, cosine) for α parameter

## Open Questions the Paper Calls Out
None

## Limitations
- Computational scalability concerns with large user populations due to O(N²) distance matrix calculations
- Assumption that anchor users maintain consistent embedding quality throughout training
- Limited systematic analysis of hyperparameter sensitivity across diverse federated scenarios

## Confidence
**High Confidence**: Empirical results demonstrating Dist-FedAvg's superiority over baseline methods on five datasets with statistically significant improvements in NDCG@10 and HR@10 metrics.

**Medium Confidence**: Theoretical justification for inverse distance weighting in federated recommendation contexts, though connection between local embedding geometry and global recommendation quality requires further validation.

**Low Confidence**: Generalizability of decay strategy effectiveness across different federated learning scenarios and dataset characteristics, as paper focuses on specific settings without broader exploration.

## Next Checks
1. Evaluate Dist-FedAvg on larger-scale federated recommendation datasets (10M+ users) to assess computational overhead and aggregation quality degradation with increasing user count.

2. Conduct experiments where anchor users' data distributions are intentionally corrupted or drifted to test whether interpolation mechanism maintains effectiveness under adverse conditions.

3. Systematically explore impact of different decay rates, α initialization values, and Minkowski distance parameters across diverse federated scenarios to identify optimal configuration strategies.