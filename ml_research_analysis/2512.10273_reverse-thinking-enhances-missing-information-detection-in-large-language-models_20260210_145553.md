---
ver: rpa2
title: Reverse Thinking Enhances Missing Information Detection in Large Language Models
arxiv_id: '2512.10273'
source_url: https://arxiv.org/abs/2512.10273
tags:
- reasoning
- missing
- information
- reverse
- rt-ica
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Large language models struggle with problems containing missing
  information, often producing incorrect solutions or hallucinations when essential
  details are absent. This work introduces Reverse Thinking for Information Completeness
  Assessment (RT-ICA), a framework that addresses this limitation by employing backward
  reasoning to systematically identify missing prerequisites rather than deriving
  from potentially incomplete premises.
---

# Reverse Thinking Enhances Missing Information Detection in Large Language Models

## Quick Facts
- arXiv ID: 2512.10273
- Source URL: https://arxiv.org/abs/2512.10273
- Authors: Yuxin Liu; Chaojie Gu; Yihang Zhang; Bin Qian; Shibo He
- Reference count: 40
- Key outcome: GPT-3.5-turbo accuracy improved by 27.62 percentage points, achieving 96.19% on test gsm8k and 90.10% on test math datasets

## Executive Summary
Large language models often produce incorrect solutions or hallucinations when problems contain missing information. This work introduces Reverse Thinking for Information Completeness Assessment (RT-ICA), a framework that addresses this limitation by employing backward reasoning to systematically identify missing prerequisites. The approach works by first enumerating all necessary conditions for solving a problem, then verifying their availability in the given context. Experimental results show substantial performance gains across multiple models and datasets, demonstrating that reverse thinking provides a more effective paradigm for detecting missing information in LLM reasoning tasks.

## Method Summary
The RT-ICA framework addresses LLM limitations in handling missing information by reversing the traditional problem-solving approach. Instead of deriving solutions from potentially incomplete premises, the method first enumerates all necessary conditions required to solve a problem, then systematically verifies whether these conditions are present in the given context. This backward reasoning approach enables the model to identify missing prerequisites before attempting problem-solving, preventing incorrect inferences or hallucinations that occur when essential information is absent. The framework can be applied across different LLM architectures and problem domains, though evaluation focused on mathematical word problems from GSM8K and MATH datasets.

## Key Results
- GPT-3.5-turbo accuracy improved by 27.62 percentage points
- Achieved 96.19% accuracy on test GSM8K dataset
- Achieved 90.10% accuracy on test MATH dataset

## Why This Works (Mechanism)
The framework works by systematically identifying all necessary conditions for problem solution before attempting reasoning. By enumerating prerequisites first and verifying their availability, the model can detect missing information before it attempts to reason from incomplete premises. This prevents the cascading errors that occur when LLMs try to derive solutions from insufficient context, reducing hallucination and incorrect inference. The backward reasoning approach creates a completeness check that serves as a prerequisite gate for problem-solving, ensuring that all essential information is available before proceeding with solution derivation.

## Foundational Learning
- **Backward reasoning** - why needed: enables systematic identification of missing prerequisites; quick check: can enumerate all conditions required for problem solution
- **Information completeness assessment** - why needed: prevents reasoning from incomplete premises; quick check: verifies all necessary conditions are present before solving
- **Prerequisite enumeration** - why needed: identifies what information is required for solution; quick check: generates complete list of conditions needed for problem-solving
- **Context verification** - why needed: ensures enumerated conditions exist in problem statement; quick check: cross-references required conditions against available information

## Architecture Onboarding

**Component map**: Problem statement -> Condition enumeration module -> Context verification module -> Completeness assessment -> Solution generation (if complete) / Error reporting (if incomplete)

**Critical path**: The most important sequence is Condition enumeration -> Context verification -> Completeness assessment, as this backward reasoning chain prevents incorrect problem-solving attempts

**Design tradeoffs**: The framework trades computational overhead for accuracy by adding a completeness check step. This adds latency but prevents costly incorrect reasoning attempts and hallucinations

**Failure signatures**: Framework may miss subtle missing information if condition enumeration is incomplete, or may generate false positives if verification is too strict. Computational cost increases linearly with problem complexity

**First experiments**: 
1. Test RT-ICA on simple math word problems with obvious missing information to verify basic functionality
2. Evaluate performance on complete problems to ensure the framework doesn't introduce unnecessary complexity
3. Measure computational overhead compared to standard prompting approaches

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focuses primarily on mathematical word problems, limiting generalizability to other domains
- Computational overhead of condition enumeration may limit practical deployment in real-time applications
- Claims about universal effectiveness need qualification, as comparison is limited to standard prompting methods

## Confidence
- Cross-domain robustness: Low - limited to mathematical problems
- Computational efficiency: Medium - overhead not thoroughly characterized
- Universal applicability: Medium - claims need qualification

## Next Checks
1. Test RT-ICA on non-mathematical reasoning tasks including scientific, medical, and legal domains to assess cross-domain robustness
2. Compare computational efficiency and response time against alternative missing information detection methods under resource constraints
3. Conduct ablation studies to isolate which components of the reverse thinking framework contribute most to performance gains, particularly the condition enumeration versus verification steps