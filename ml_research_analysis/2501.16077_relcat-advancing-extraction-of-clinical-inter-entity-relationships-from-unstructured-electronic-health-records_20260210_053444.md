---
ver: rpa2
title: 'RelCAT: Advancing Extraction of Clinical Inter-Entity Relationships from Unstructured
  Electronic Health Records'
arxiv_id: '2501.16077'
source_url: https://arxiv.org/abs/2501.16077
tags:
- recall
- bert
- performance
- f1-score
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces RelCAT (Relation Concept Annotation Toolkit),
  a comprehensive NLP toolkit for extracting and classifying inter-entity relationships
  in clinical narratives. Building on the CogStack MedCAT framework, RelCAT employs
  state-of-the-art transformer models including BERT and Llama to identify relationships
  between SNOMED CT entities extracted from unstructured clinical text.
---

# RelCAT: Advancing Extraction of Clinical Inter-Entity Relationships from Unstructured Electronic Health Records

## Quick Facts
- arXiv ID: 2501.16077
- Source URL: https://arxiv.org/abs/2501.16077
- Reference count: 22
- Primary result: RelCAT achieves macro F1-score of 0.977 on n2c2 dataset, surpassing previous state-of-the-art of 0.9610

## Executive Summary
This paper introduces RelCAT, a comprehensive NLP toolkit for extracting and classifying inter-entity relationships in clinical narratives. Building on the CogStack MedCAT framework, RelCAT employs state-of-the-art transformer models including BERT and Llama to identify relationships between SNOMED CT entities extracted from unstructured clinical text. The toolkit implements multiple entity representation methods and incorporates strategies to address class imbalance in medical datasets, including class weighting and stratified batching.

Experimental results demonstrate superior performance: RelCAT achieves a macro F1-score of 0.977 on the gold-standard n2c2 dataset, surpassing previous state-of-the-art results (0.9610), with particularly strong performance on minority classes (ADE-Drug F1 0.866, Duration-Drug F1 0.933). On real-world NHS clinical datasets, BERT models achieved F1-scores ≥0.93, with Llama models also performing competitively. The complete source code is publicly available for community use and extension.

## Method Summary
RelCAT builds upon the CogStack MedCAT framework, integrating advanced transformer architectures (BERT, Llama) for clinical relation extraction. The system extracts SNOMED CT entities from unstructured clinical text and classifies relationships between them using multiple representation methods. To address class imbalance, the toolkit implements class weighting and stratified batching strategies. A novel annotation tool built within MedCATTrainer enables dataset creation and annotation, while also supporting automatic relation generation using ontology dictionaries. The framework was evaluated on both benchmark datasets (n2c2) and real-world NHS clinical data.

## Key Results
- RelCAT achieves macro F1-score of 0.977 on n2c2 dataset, surpassing previous state-of-the-art (0.9610)
- Strong performance on minority classes: ADE-Drug F1 0.866, Duration-Drug F1 0.933
- BERT models achieved F1-scores ≥0.93 on NHS clinical datasets, with Llama models also performing competitively

## Why This Works (Mechanism)
RelCAT's superior performance stems from its integration of state-of-the-art transformer architectures (BERT, Llama) with the established MedCAT framework. The combination of multiple entity representation methods allows the system to capture different aspects of clinical relationships. Class imbalance mitigation through class weighting and stratified batching ensures minority classes receive adequate representation during training. The toolkit's ability to leverage ontology dictionaries for automatic relation generation enhances its capacity to identify complex clinical relationships that might be missed by traditional rule-based approaches.

## Foundational Learning
RelCAT's effectiveness is built upon pre-training transformer models on large biomedical corpora, enabling them to understand medical terminology and context. The framework leverages transfer learning from general language models to clinical domains, adapting to the specific vocabulary and relationship patterns found in electronic health records. The integration with MedCAT's established entity recognition capabilities provides a strong foundation for relationship extraction by first accurately identifying clinical entities before attempting to classify their relationships.

## Architecture Onboarding
RelCAT extends the MedCAT framework by incorporating transformer-based classification modules for relationship detection. The architecture consists of three main components: entity recognition (inherited from MedCAT), entity representation generation using multiple methods, and relationship classification using BERT or Llama models. The annotation tool within MedCATTrainer serves as both a dataset creation interface and a deployment platform. Users can extend the toolkit by adding new entity types or relationship categories, though this requires corresponding annotations and may necessitate retraining of the transformer models.

## Open Questions the Paper Calls Out
The paper highlights several areas for future investigation: how RelCAT performs across diverse clinical domains beyond the evaluated NHS datasets, whether the class imbalance mitigation strategies generalize to datasets with different imbalance patterns, and the toolkit's effectiveness when applied to longitudinal clinical data spanning multiple encounters. Additionally, the authors note the need to evaluate how well the model transfers between different healthcare systems and clinical note styles.

## Limitations
- Results primarily based on curated n2c2 dataset, which may not fully represent real-world clinical variation
- Performance on NHS clinical datasets involves fewer entity types and may not capture full complexity of diverse clinical narratives
- Improvement over state-of-the-art (0.977 vs 0.9610 macro F1-score) may be influenced by dataset-specific characteristics and evaluation protocols
- Limited evaluation of the toolkit's ability to handle temporal relationships and evolving clinical contexts across multiple patient encounters

## Confidence
- **High confidence**: The toolkit's technical implementation and its superior performance on the n2c2 benchmark are well-documented and reproducible
- **Medium confidence**: The real-world NHS dataset results, while promising, are based on limited entity types and may not generalize across all clinical domains
- **Medium confidence**: The effectiveness of class imbalance mitigation strategies (class weighting, stratified batching) is demonstrated but may require further validation across diverse clinical datasets

## Next Checks
1. Evaluate RelCAT performance on multi-domain clinical datasets with broader entity types and relationship categories to assess generalizability
2. Conduct head-to-head comparisons with other state-of-the-art clinical relation extraction models on identical datasets using standardized evaluation protocols
3. Implement and validate the toolkit in a prospective clinical workflow to assess practical utility, including annotation efficiency and integration with existing clinical information systems