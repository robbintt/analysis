---
ver: rpa2
title: Towards Piece-by-Piece Explanations for Chess Positions with SHAP
arxiv_id: '2510.25775'
source_url: https://arxiv.org/abs/2510.25775
tags:
- chess
- position
- pieces
- shap
- evaluation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a SHAP-based method for attributing chess engine
  evaluations to individual pieces, aiming to provide interpretable explanations for
  centipawn scores. The key contribution is a perturbation protocol that systematically
  ablates non-king pieces and computes additive, per-piece contributions to the engine's
  evaluation using SHAP.
---

# Towards Piece-by-Piece Explanations for Chess Positions with SHAP
## Quick Facts
- arXiv ID: 2510.25775
- Source URL: https://arxiv.org/abs/2510.25775
- Reference count: 22
- Provides SHAP-based method for attributing chess engine evaluations to individual pieces

## Executive Summary
This paper presents a SHAP-based method for attributing chess engine evaluations to individual pieces, aiming to provide interpretable explanations for centipawn scores. The key contribution is a perturbation protocol that systematically ablates non-king pieces and computes additive, per-piece contributions to the engine's evaluation using SHAP. The approach treats each piece as a feature and measures its marginal impact on the predicted win probability for White, converting centipawn scores to probabilities via a logistic function. The method addresses the opacity of traditional engine outputs by providing fine-grained, position-specific attributions that decompose evaluations into interpretable piece-level contributions.

## Method Summary
The approach uses SHAP (SHapley Additive exPlanations) to attribute centipawn evaluations to individual chess pieces. The method treats each piece as a feature and measures its marginal impact on the predicted win probability for White. It converts centipawn scores to probabilities using a logistic function, then applies SHAP to compute additive contributions from each piece. The perturbation protocol systematically ablates non-king pieces to measure their individual and combined effects on the engine's evaluation. This creates a piece-by-piece breakdown of the evaluation score, providing interpretable explanations for why the engine assigns a particular value to a position.

## Key Results
- Demonstrates SHAP-based attribution method for chess engine evaluations
- Provides fine-grained, position-specific explanations by decomposing evaluations into piece-level contributions
- Identifies strategically important pieces through qualitative examples
- Shows limitations in attribution to the king piece and computational constraints with many pieces

## Why This Works (Mechanism)
The SHAP method works by treating each chess piece as a feature and measuring its marginal contribution to the model's output through systematic perturbations. By ablating individual pieces and observing the change in evaluation, the method captures the relative importance of each piece to the overall position assessment. The conversion from centipawn scores to win probabilities allows for more interpretable attributions, while the additive nature of SHAP values ensures that the sum of all piece contributions equals the total evaluation.

## Foundational Learning
1. SHAP (SHapley Additive exPlanations) - A game-theoretic approach for interpreting model predictions by measuring each feature's marginal contribution
   - Why needed: Provides a mathematically principled way to attribute model outputs to individual features
   - Quick check: Verify that SHAP values sum to the original model output

2. Centipawn evaluation - Chess engines assign numerical scores (in centipawns) representing the advantage of one side over the other
   - Why needed: Standard metric for chess engine evaluation that needs to be interpreted
   - Quick check: Confirm that positive values favor White, negative values favor Black

3. Logistic function conversion - Transforming centipawn scores to win probabilities for more interpretable attributions
   - Why needed: Makes the evaluation scores more intuitive and comparable across different positions
   - Quick check: Verify that the conversion produces reasonable probability estimates

## Architecture Onboarding
Component map: Chess position -> Piece ablation perturbation -> Engine evaluation -> Logistic conversion -> SHAP attribution -> Piece contributions
Critical path: Position → Feature encoding → Model prediction → SHAP calculation → Attribution output
Design tradeoffs: Linear additivity assumption vs. complex piece interactions; computational efficiency vs. attribution granularity
Failure signatures: Inability to attribute to king piece; computational limitations with many pieces; potential misattribution in positions with complex tactical motifs
First experiments:
1. Test on simple positions with clear material imbalances to verify attribution accuracy
2. Compare SHAP-based explanations with human expert assessments of piece importance
3. Evaluate performance across different chess engines to assess consistency

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions beyond the limitations mentioned in the main text.

## Limitations
- Cannot attribute evaluation contributions to the king piece as it serves as the baseline feature
- Computational complexity scales poorly with the number of pieces, limiting applicability to positions with many pieces
- Assumes linear additivity of piece contributions, which may not capture complex positional factors
- Conversion from centipawn scores to win probabilities introduces additional uncertainty

## Confidence
- High confidence in the methodological approach and perturbation protocol
- Medium confidence in the attribution results for standard positions with fewer pieces
- Low confidence in the method's scalability and performance in complex positions with many pieces

## Next Checks
1. Validate the attribution results by comparing SHAP-based explanations with human expert assessments of piece importance in the same positions
2. Test the method on positions with known tactical motifs to verify that it correctly identifies key attacking/defensive pieces
3. Conduct systematic evaluation of the method's performance across different chess engines to assess consistency of attributions