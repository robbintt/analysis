---
ver: rpa2
title: 'The Amazon Nova Family of Models: Technical Report and Model Card'
arxiv_id: '2506.12103'
source_url: https://arxiv.org/abs/2506.12103
tags:
- nova
- amazon
- answer
- https
- family
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The Amazon Nova family of foundation models delivers frontier intelligence
  with industry-leading price performance across text, image, and video modalities.
  Amazon Nova Pro, Lite, and Micro set new standards in accuracy, speed, and cost,
  with the Pro model achieving state-of-the-art performance on multimodal benchmarks
  like MMMU and V ATEX, and the Micro model excelling in text-only tasks such as MMLU
  and MATH.
---

# The Amazon Nova Family of Models: Technical Report and Model Card

## Quick Facts
- **arXiv ID**: 2506.12103
- **Source URL**: https://arxiv.org/abs/2506.12103
- **Reference count**: 40
- **Key outcome**: Amazon Nova family delivers frontier intelligence with industry-leading price performance across text, image, and video modalities, achieving state-of-the-art results on multimodal benchmarks while maintaining robust safety and efficiency.

## Executive Summary
The Amazon Nova family comprises foundation models spanning text understanding (Nova Micro/Lite/Pro), multimodal understanding (Nova Lite/Pro), image generation (Nova Canvas), and video generation (Nova Reel). Built on Transformer and latent diffusion architectures, these models were trained on multilingual/multimodal data across 200+ languages, then fine-tuned through supervised fine-tuning and preference alignment. The family achieves exceptional benchmark performance, with Nova Pro reaching 85.9 MMLU and 61.7 MMMU scores, while Nova Canvas and Reel generate professional-grade content with advanced customization controls. All models incorporate robust safety measures including watermarking and extensive red teaming, optimized for fast inference on AWS Trainium and GPU accelerators.

## Method Summary
The Nova models were developed through a staged training pipeline: pretraining on multilingual/multimodal data, followed by supervised fine-tuning on instruction-demonstration pairs, then alignment via reward model training and preference optimization (DPO/PPO). Nova Canvas and Reel employ latent diffusion with VAE-based latent space encoding, while Pro/Lite/Micro use Transformer architectures. Training infrastructure optimizations including Super-Selective Activation Checkpointing achieved up to 97% goodput efficiency. Models were built responsibly with robust safety measures including watermarking (C2PA metadata for images, frame-embedded for video) and extensive red teaming across 307 attack techniques.

## Key Results
- Nova Pro achieves state-of-the-art performance: 85.9 MMLU, 61.7 MMMU, and competitive results across math, reasoning, and coding benchmarks
- Nova Canvas outperforms DALL·E 3 in human evaluations (54.5% win rate) for image quality and text-image alignment
- Nova Reel demonstrates superior video consistency and quality (56.4% win rate vs Gen3 Alpha) with advanced customization controls
- Training efficiency reaches 97% goodput through infrastructure optimizations including SSC checkpointing and gradient reduction

## Why This Works (Mechanism)

### Mechanism 1
The Nova Pro/Lite/Micro models achieve strong benchmark performance through a staged training pipeline combining pretraining, supervised fine-tuning, and preference alignment. Models are first pretrained on multilingual/multimodal data (200+ languages), then undergo Supervised Fine-Tuning (SFT) on instruction-demonstration pairs, followed by reward model training and alignment via Direct Preference Optimization (DPO) and Proximal Policy Optimization (PPO) to match human preferences.

### Mechanism 2
Nova Canvas and Reel generate high-fidelity images and videos via latent diffusion conditioned on text encoders. A Variational AutoEncoder (VAE) maps image/video frames to latent variables. A text encoder tokenizes prompts into conditioning signals. At inference, random noise is iteratively denoised by the diffusion model, then decoded back to pixels.

### Mechanism 3
High training efficiency (up to 97% goodput) is achieved through infrastructure optimizations targeting checkpointing, gradient reduction, and memory management. Super-Selective Activation Checkpointing (SSC) reduces memory by ~50% with only ~2% re-computation overhead. Gradient reduction order/frequency adjustments improve communication overlap. Asynchronous checkpoint mapping reduces restart time from 3 minutes to 5 seconds.

## Foundational Learning

- **Transformer Architecture**: Nova Pro/Lite/Micro are explicitly Transformer-based; understanding attention mechanisms, positional encodings, and scaling laws is prerequisite to interpreting benchmark results and fine-tuning behavior. Quick check: Can you explain how multi-head attention differs from single-head attention in terms of representational capacity?
- **Latent Diffusion Models**: Nova Canvas and Reel use VAE-based latent diffusion; you need to understand the encoder-latent-decoder pipeline, noise scheduling, and classifier-free guidance to debug generation quality issues. Quick check: What is the computational advantage of running diffusion in latent space versus pixel space?
- **Reinforcement Learning from Human Feedback (RLHF)**: The training pipeline explicitly uses reward model training, DPO, and PPO for alignment; understanding preference optimization is critical for customizing safety/behavior via fine-tuning. Quick check: How does DPO differ from PPO in terms of whether an explicit reward model is required during optimization?

## Architecture Onboarding

- **Component map**:
  ```
  Nova Pro/Lite/Micro (Transformer-based LLMs)
  ├── Pretraining: Multilingual/multimodal corpus
  ├── SFT: Instruction-demonstration pairs
  └── Alignment: DPO + PPO from human preferences
  Nova Canvas/Reel (Latent Diffusion)
  ├── VAE Encoder: Image/video → latent space
  ├── Text Encoder: Prompt → conditioning tokens
  ├── Diffusion Model: Iterative denoising
  └── VAE Decoder: Latent → pixels
  Infrastructure Layer
  ├── Trainium (TRN1) + NVIDIA A100/H100 clusters
  ├── Super-Selective Activation Checkpointing (SSC)
  └── Async checkpoint mapping (6.5 min MTTR)
  ```

- **Critical path**:
  1. Model selection: Choose Pro (multimodal, 300K context), Lite (fast multimodal), or Micro (text-only, lowest latency) based on modality and latency requirements
  2. Fine-tuning: Use Bedrock APIs for custom fine-tuning (CFT) or distillation from larger to smaller models
  3. Safety layer: Input/output moderation models plus watermarking (C2PA metadata for images; frame-embedded watermarks for video)

- **Design tradeoffs**:
  - Pro vs Lite vs Micro: Pro offers highest accuracy (e.g., 85.9 MMLU, 61.7 MMMU) at 100 tok/sec; Micro offers 210 tok/sec at slightly lower accuracy (77.6 MMLU). Trade speed for capability
  - Training efficiency vs generality: The 97% goodput optimizations are tuned for Nova's specific model architectures; may not transfer to differently-shaped models
  - Watermark robustness vs quality: Watermarks are designed to survive H264 compression and basic edits, but aggressive post-processing may degrade detection confidence

- **Failure signatures**:
  - Long-context retrieval failure: If Needle-in-a-Haystack performance degrades at specific context depths, consider chunking strategies
  - Multimodal agent grounding errors: If GroundUI-1K or MM-Mind2Web accuracy drops, verify screenshot resolution matches training distribution
  - Video temporal inconsistency: If Nova Reel outputs show entity morphing, the VAE latent space may be underspecified for your motion complexity

- **First 3 experiments**:
  1. Benchmark baseline: Run your domain-specific test set through Nova Pro, Lite, and Micro; compare against your current model on accuracy, latency (TTFT, OTPS), and cost per 1K tokens
  2. Fine-tuning uplift: Select 500-1000 domain-specific instruction pairs; run CFT on Nova Lite; measure delta on held-out evaluation set
  3. Watermark detection robustness: Generate 10 images with Nova Canvas, apply common edits (resize, crop, color adjustment), and test detection API confidence scores to establish your forensic baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the precise trade-off curve between model size, training compute, and downstream task performance across the Nova family, and do these relationships follow established scaling laws?
- Basis in paper: The paper presents Pro, Lite, and Micro models with different sizes and capabilities but does not analyze or report scaling relationships systematically
- Why unresolved: No scaling law analysis is provided; the report focuses on benchmark comparisons rather than architectural efficiency analysis
- What evidence would resolve it: Parameter counts, training FLOPs, and systematic performance degradation curves across model tiers on held-out tasks

### Open Question 2
- Question: How does the Super-Selective Activation Checkpointing (SSC) technique compare to gradient checkpointing and selective activation recomputation methods in terms of memory-accuracy-throughput trade-offs?
- Basis in paper: "SSC minimizes activation re-computation in memory-constrained environments, reducing memory consumption by ~50% while adding ~2% re-computation overhead compared to NVidia's Selective Checkpointing"
- Why unresolved: Only a brief comparison to one baseline is provided; the algorithmic details and broader comparison to alternatives are not included
- What evidence would resolve it: Ablation studies with full algorithmic description, comparisons to standard gradient checkpointing, and throughput benchmarks on standardized workloads

### Open Question 3
- Question: What residual safety risks remain in the Nova models after extensive red teaming, and how do these risks quantitatively compare across model tiers and modalities?
- Basis in paper: The paper describes extensive red teaming (307 attack techniques, external partnerships) but provides no quantitative measure of residual risk or pre/post mitigation comparison
- Why unresolved: Red teaming is described qualitatively; attack success rates before and after mitigations are not reported
- What evidence would resolve it: Quantitative attack success rates (ASR) across categories before/after alignment, false refusal rates, and tier-by-tier safety metric comparisons

### Open Question 4
- Question: How robust is the invisible watermarking system against advanced adversarial attacks, and what is the detection confidence threshold for edited vs. unedited generated content?
- Basis in paper: "The new detection system covers both images and videos... makes confidence score-based predictions instead of a single binary prediction that reflects the extent to which the generated content has been edited"
- Why unresolved: Robustness claims (rotation, resizing, compression) are stated without quantitative adversarial robustness evaluations
- What evidence would resolve it: Detection ROC curves under various perturbation intensities, confidence score distributions for edited/unedited content, and adversarial attack success rates against watermark removal

## Limitations

- Model architecture details (layer counts, hidden dimensions, parameter counts) remain undisclosed, preventing accurate reproduction or architectural comparison
- Training data composition is vaguely described as "licensed, proprietary, and open-source" without specifying domain distributions, potential biases, or contamination risks
- Infrastructure claims of 97% training efficiency through SSC and gradient optimizations are not independently verified and may not transfer to non-AWS hardware
- Safety claims rely on proprietary red teaming procedures without public audit trails or third-party evaluation frameworks

## Confidence

- **High Confidence**: Transformer-based architecture for Nova Pro/Lite/Micro, latent diffusion approach for Nova Canvas/Reel, and basic training pipeline (pretrain → SFT → alignment) are well-established and verifiable through API behavior
- **Medium Confidence**: Benchmark performance metrics (MMLU, MMMU, etc.) are credible given the model family's capabilities, but lack peer-reviewed validation and may be sensitive to evaluation protocols
- **Low Confidence**: Safety and responsible AI claims lack independent verification; the proprietary nature of red teaming, moderation models, and watermark robustness testing prevents external assessment

## Next Checks

1. **Independent Benchmark Reproduction**: Run the publicly available Nova API through standardized evaluation suites (HELM, EleutherAI lm-evaluation-harness) on domain-relevant tasks to verify claimed accuracy, latency, and cost-per-token metrics across Pro, Lite, and Micro variants
2. **Safety System Audit**: Conduct controlled red teaming exercises using established frameworks (AdvBench, HarmBench) to test moderation model effectiveness and watermark detection robustness against common adversarial attacks (inpainting, GAN synthesis, compression artifacts)
3. **Infrastructure Portability Assessment**: Replicate the SSC and gradient optimization techniques on alternative hardware (NVIDIA H100 clusters, non-EFA fabrics) to verify the claimed 97% goodput is architecture-agnostic rather than AWS-specific optimization