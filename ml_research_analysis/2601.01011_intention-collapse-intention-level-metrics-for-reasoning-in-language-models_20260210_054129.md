---
ver: rpa2
title: 'Intention Collapse: Intention-Level Metrics for Reasoning in Language Models'
arxiv_id: '2601.01011'
source_url: https://arxiv.org/abs/2601.01011
tags:
- intention
- collapse
- reasoning
- pre-collapse
- entropy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces intention collapse as a framework for analyzing\
  \ how large language models compress high-dimensional internal states into discrete\
  \ token sequences. It proposes three model-agnostic metrics\u2014intention entropy,\
  \ effective dimensionality, and latent knowledge recoverability\u2014computed at\
  \ the pre-collapse boundary to quantify the geometry and information content of\
  \ internal states before generation begins."
---

# Intention Collapse: Intention-Level Metrics for Reasoning in Language Models

## Quick Facts
- **arXiv ID:** 2601.01011
- **Source URL:** https://arxiv.org/abs/2601.01011
- **Reference count:** 5
- **Primary result:** CoT consistently improves accuracy in free-response math but degrades performance in multiple-choice abstract reasoning tasks.

## Executive Summary
This paper introduces intention collapse as a framework for analyzing how large language models compress high-dimensional internal states into discrete token sequences. It proposes three model-agnostic metrics—intention entropy, effective dimensionality, and latent knowledge recoverability—computed at the pre-collapse boundary to quantify the geometry and information content of internal states before generation begins. An empirical 3×3 study across three model families and three reasoning benchmarks reveals that chain-of-thought prompting is not universally beneficial: it strongly improves accuracy in free-response math but consistently degrades performance in multiple-choice abstract reasoning. CoT induces distinct entropy regimes across models, and probe-based recoverability can dissociate from final accuracy, particularly in multiple-choice settings, suggesting that informative internal signal may not be reliably expressed in the final discrete decision. These findings highlight the importance of response format and commitment reliability, and motivate state-dependent decoding and format-aware collapse policies as practical extensions.

## Method Summary
The study introduces a model-agnostic framework for analyzing the "intention collapse" phenomenon—the process by which high-dimensional internal states compress into discrete token sequences. Three metrics are proposed: intention entropy (measuring uncertainty before collapse), effective dimensionality (capturing state space geometry), and latent knowledge recoverability (assessing probe-based retrieval of pre-collapse information). The empirical evaluation spans three model families (GPT-3.5, LLaMA-2, Mistral) and three reasoning benchmarks (GSM8K, AMPS, BigBench). Key methodological innovations include defining the pre-collapse boundary as the layer immediately before final token generation, using linear probes to recover latent knowledge, and implementing response-format-aware evaluation protocols. The study employs both free-response and multiple-choice formats to isolate the effect of commitment reliability on reasoning performance.

## Key Results
- Chain-of-thought prompting improves accuracy in free-response math (GSM8K) but degrades performance in multiple-choice abstract reasoning (AMPS, BigBench)
- CoT induces distinct entropy regimes across models, with some showing decreased entropy while others increase
- Probe-based recoverability can dissociate from final accuracy, particularly in multiple-choice settings
- Response format significantly moderates the benefits of intermediate reasoning steps
- State-dependent decoding and format-aware collapse policies are identified as promising extensions

## Why This Works (Mechanism)
Intention collapse provides a principled way to analyze the information bottleneck at the final stages of language model reasoning. By measuring entropy and dimensionality at the pre-collapse boundary, researchers can quantify how models compress high-dimensional internal states into discrete outputs. The framework reveals that this compression process is not uniform across tasks or models—some benefit from intermediate reasoning steps (chain-of-thought) while others suffer. The key insight is that the geometry of the internal state space and the reliability of final commitment determine whether reasoning traces improve or harm performance. This explains why CoT excels at free-response math (where exploration is rewarded) but fails at multiple-choice abstract reasoning (where premature commitment to wrong reasoning paths is penalized).

## Foundational Learning
- **Intention collapse**: The process by which high-dimensional internal states compress into discrete token sequences. Why needed: Provides a unifying framework for analyzing the final decision-making stage in language models.
- **Pre-collapse boundary**: The layer immediately before final token generation where internal states still retain high-dimensional information. Why needed: Enables measurement of information content before irreversible compression.
- **Chain-of-thought prompting**: Intermediate reasoning steps that may improve or harm final performance depending on task characteristics. Why needed: Reveals task-dependent effects of intermediate reasoning.
- **Response format dependency**: The observation that accuracy gains from reasoning traces depend on whether the task requires free-response or multiple-choice answers. Why needed: Explains contradictory findings in CoT literature.
- **Probe-based recoverability**: Using linear probes to assess latent knowledge content in internal states before final collapse. Why needed: Provides an independent measure of reasoning quality separate from final accuracy.
- **Commitment reliability**: The tendency of models to commit to conclusions reached through intermediate reasoning, which may be suboptimal. Why needed: Explains why CoT sometimes harms performance in multiple-choice settings.

## Architecture Onboarding

**Component Map**
Model Families -> Reasoning Benchmarks -> Pre-collapse Layer -> Intention Metrics -> Accuracy/Recoverability

**Critical Path**
Input Prompt → Model Forward Pass → Pre-collapse Boundary → Intention Metrics (Entropy, Dimensionality, Recoverability) → Final Token Generation → Output Evaluation

**Design Tradeoffs**
- Free-response vs. multiple-choice formats: Tradeoff between exploration flexibility and commitment reliability
- Intermediate reasoning steps: Balance between computational cost and potential accuracy gains
- Probe-based evaluation: Independence from final accuracy vs. added complexity
- State-dependent decoding: Potential accuracy improvements vs. inference overhead

**Failure Signatures**
- High entropy with low accuracy: Model uncertainty not translating to correct answers
- Low recoverability despite high accuracy: Final decisions not grounded in informative internal states
- Format mismatch: CoT benefits in free-response but harms in multiple-choice
- Dimensionality collapse: Premature compression losing critical reasoning information

**3 First Experiments**
1. Replicate the 3×3 study with additional model families to test generalizability
2. Implement state-dependent decoding that conditions collapse timing on entropy thresholds
3. Design format-aware prompting that adapts CoT usage based on response requirements

## Open Questions the Paper Calls Out
- How can state-dependent decoding be implemented efficiently in production systems?
- What are the optimal entropy thresholds for triggering format-aware collapse policies?
- Can the intention collapse framework be extended to other generative modalities beyond text?
- How do different tokenization schemes affect the geometry of pre-collapse states?
- What role does temperature sampling play in the intention collapse process?

## Limitations
- The framework focuses on text-only language models and may not generalize to multimodal systems
- Linear probes may not capture all forms of latent knowledge in complex reasoning tasks
- The 3×3 study design, while comprehensive, may not capture all reasoning task variations
- State-dependent decoding extensions remain theoretical without practical implementation details
- The framework assumes a single pre-collapse boundary, which may oversimplify hierarchical reasoning processes

## Confidence

| Claim | Confidence |
|-------|------------|
| CoT benefits free-response math | High |
| CoT harms multiple-choice abstract reasoning | High |
| Entropy regimes vary across models | Medium |
| Recoverability can dissociate from accuracy | Medium |
| Format-aware collapse policies are promising | Low |

## Next Checks
1. Implement and evaluate state-dependent decoding with entropy-based collapse timing
2. Extend the intention collapse framework to multimodal models and tasks
3. Develop adaptive prompting strategies that automatically select between CoT and direct answer based on task format and model state