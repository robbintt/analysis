---
ver: rpa2
title: Monte Carlo Permutation Search
arxiv_id: '2510.06381'
source_url: https://arxiv.org/abs/2510.06381
tags:
- game
- mcps
- grave
- games
- codes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper introduces Monte Carlo Permutation Search (MCPS), an
  enhancement of the GRAVE MCTS algorithm that incorporates statistics from playouts
  containing a sequence of moves in any order. MCPS uses three sources of statistics:
  standard playout statistics, All Moves As First (AMAF) statistics, and permutation
  statistics, combining them with derived optimal weights.'
---

# Monte Carlo Permutation Search
## Quick Facts
- arXiv ID: 2510.06381
- Source URL: https://arxiv.org/abs/2510.06381
- Reference count: 40
- The MCPS algorithm achieves 74-77% win rates in Hex 7x7 against GRAVE baseline with 5000 playouts

## Executive Summary
This paper introduces Monte Carlo Permutation Search (MCPS), an enhancement of the GRAVE MCTS algorithm that incorporates statistics from playouts containing sequences of moves in any order. The method combines three sources of statistics - standard playout statistics, All Moves As First (AMAF) statistics, and permutation statistics - using derived optimal weights. Extensive testing across ten different games demonstrates MCPS consistently outperforms GRAVE, with win rates ranging from 52% to 77% depending on the game and number of playouts.

The algorithm also introduces abstract codes for moves, which improve both MCPS and GRAVE by increasing the frequency of code occurrences in playouts. This abstraction technique proves especially effective in complex games like the Investment Pair Game, where MCPS with abstract codes achieves a 65.25% win rate against GRAVE with exact codes. The method is particularly relevant for general game playing where deep reinforcement learning is not feasible.

## Method Summary
MCPS extends the GRAVE MCTS algorithm by adding permutation statistics that track when a sequence of moves occurs in any order during playouts. The algorithm uses three sources of statistics: standard playout statistics Q(s,a), AMAF statistics Q̃(s,a), and permutation statistics Q̂(s,a). These are combined using weights α = c₁n/(c₁n+ñ+n̂), β = ñ/(c₁n+ñ+n̂), γ = n̂/(c₁n+ñ+n̂), where c₁ = (ñ+n̂)/ñ and Q*(s,a) = αQ(s,a) + βQ̃(s,a) + γQ̂(s,a). The method employs boolean matrix optimization to efficiently compute permutation statistics, maintaining a (moves × playouts) matrix to calculate n̂ via logical AND during tree descent. Abstract codes are introduced to improve statistics by grouping similar moves, particularly effective in games with many possible moves.

## Key Results
- MCPS achieves 74.12% win rate in Hex 7x7 with 5000 playouts against GRAVE
- Win rates range from 52% to 77% across six board games, wargame, investment game, video game, and three multiplayer games
- MCPS with abstract codes achieves 65.25% win rate in Investment Pair Game against GRAVE with exact codes
- Performance improvement is consistent across all tested two-player games

## Why This Works (Mechanism)
MCPS improves upon GRAVE by capturing additional statistical information about move sequences that occur in any order during playouts. While GRAVE uses standard playout statistics and AMAF statistics (which assumes moves are played first), MCPS adds permutation statistics that track when all moves in a path are played regardless of order. This is particularly valuable in games where move order is flexible or where certain combinations of moves are beneficial regardless of sequence. The boolean matrix optimization allows efficient computation of these permutation statistics without prohibitive computational cost.

## Foundational Learning
**MCTS Tree Search** - Why needed: MCPS builds upon MCTS as its foundation. Quick check: Verify understanding of selection, expansion, simulation, and backpropagation phases.
**AMAF Statistics** - Why needed: GRAVE's baseline uses AMAF which assumes moves are played first. Quick check: Understand how AMAF differs from standard playout statistics.
**Permutation Statistics** - Why needed: MCPS's key innovation is tracking moves in any order. Quick check: Verify the boolean matrix approach for O(depth) complexity.
**Abstract Codes** - Why needed: Improves statistics frequency in games with many moves. Quick check: Understand how encoding attacker-target pairs reduces move space.
**Weight Derivation** - Why needed: Combines three statistics sources optimally. Quick check: Verify the c₁ = (ñ+n̂)/ñ formula and its independence assumption.

## Architecture Onboarding
**Component Map:** Game Environment -> MCTS Node -> Selection -> Expansion -> Simulation (Playout) -> Backpropagation -> Statistics Update (Q, AMAF, Permutation)
**Critical Path:** Selection using UCB with Q* → Expansion when new node → Simulation with abstract codes → Backpropagation updating all three statistics → Weight calculation for next selection
**Design Tradeoffs:** Permutation statistics provide more information but require O(m×p) space; boolean matrix optimization reduces computation but adds implementation complexity; abstract codes improve statistics frequency but require domain knowledge.
**Failure Signatures:** Win rates near 50% indicates weight formula implementation error; slow performance suggests missing boolean matrix optimization; no improvement in two-player games suggests permutation statistics not being computed correctly.
**3 First Experiments:** 1) Implement GRAVE baseline and verify on simple game, 2) Add permutation statistics with boolean matrix optimization, 3) Test MCPS vs GRAVE on Hex 7x7 with 800 games at 1000 playouts.

## Open Questions the Paper Calls Out
**Open Question 1:** Can MCPS improve performance in non-game domains where deep reinforcement learning is currently used, such as robotics or chemical retrosynthesis? The paper hopes MCPS will be used beyond games as a general MCTS algorithm, but experimental validation is needed in optimization or scientific discovery domains.

**Open Question 2:** How does the violation of the independence assumption between Q, AMAF, and permutation statistics affect the accuracy of the mathematically derived weights? The paper derives weights assuming independence but doesn't validate if correlation between statistics introduces bias in practice.

**Open Question 3:** Can MCPS be modified to outperform GRAVE in multiplayer games, or is the lack of improvement strictly due to inherent game balance? The paper attributes stagnant multiplayer win rates to game nature rather than algorithm limitations, leaving multiplayer-specific improvements unexplored.

**Open Question 4:** Can the generation of effective abstract codes be automated for complex games? Current abstract code creation requires domain knowledge, limiting the algorithm's general game playing capabilities. An automated abstraction method analyzing move frequencies could make MCPS more broadly applicable.

## Limitations
- Requires significant implementation effort for 10+ different games with only partial abstract code specifications
- Lacks explicit details on UCB exploration constants and exact playout policies
- Abstract code specifications are incomplete, particularly for complex games beyond board games
- Permutation statistics optimization using boolean matrices adds implementation complexity

## Confidence
**High Confidence:** Core algorithmic contribution combining three statistics sources with derived weights is mathematically well-specified with explicit weight formulas.
**Medium Confidence:** Empirical results showing consistent MCPS improvements over GRAVE appear robust, though exact game implementations are not provided.
**Low Confidence:** Abstract code specifications are incomplete, limiting verification of performance improvements in complex games.

## Next Checks
1. Verify weight formula implementation by reproducing c₁ = (ñ+n̂)/ñ calculation and Q* combination on a simple game with known statistics
2. Profile the boolean matrix optimization for permutation statistics to ensure O(depth) per node complexity
3. Test MCPS vs GRAVE on Hex 7x7 with 800 games at both 1000 and 5000 playouts to confirm the 74-77% win rate improvement range reported in the paper