---
ver: rpa2
title: Risk-Aware Human-in-the-Loop Framework with Adaptive Intrusion Response for
  Autonomous Vehicles
arxiv_id: '2601.11781'
source_url: https://arxiv.org/abs/2601.11781
tags:
- learning
- rail
- risk
- safety
- rate
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'RAIL is a unified runtime framework that fuses heterogeneous risk
  cues into a single Intrusion Risk Score and translates elevated concern into graded,
  interpretable control adjustments blended with the nominal policy. By coupling a
  contextual bandit shield selector with risk-prioritized replay, RAIL achieves strong
  safety and performance: in MetaDrive, it attains a Test Return of 360.65, a Test
  Success Rate of 0.85, and only 29.07 training safety violations, outperforming RL,
  safe RL, offline/imitation learning, and prior HITL baselines.'
---

# Risk-Aware Human-in-the-Loop Framework with Adaptive Intrusion Response for Autonomous Vehicles

## Quick Facts
- arXiv ID: 2601.11781
- Source URL: https://arxiv.org/abs/2601.11781
- Reference count: 31
- Key outcome: RAIL fuses heterogeneous risk cues into a single Intrusion Risk Score and uses contextual bandit shield selection to achieve strong safety and performance, outperforming RL, safe RL, IL, and prior HITL baselines under both normal and cyber-physical attack conditions.

## Executive Summary
RAIL is a runtime framework that integrates heterogeneous runtime cues (curvature, time-to-collision, observation shift) into a single Intrusion Risk Score using weighted Noisy-OR fusion. When risk exceeds a threshold, RAIL blends the nominal policy action with a context-dependent safety shield selected by a contextual bandit. The system learns both the base driving policy (via SAC) and the shield selector from experience, with risk-prioritized replay emphasizing safety-critical transitions. RAIL achieves higher success rates, lower safety violations, and better attack resilience than baseline approaches in both MetaDrive and CARLA.

## Method Summary
RAIL builds on SAC with a runtime risk assessment layer that fuses three cues (curvature uncertainty, TTC, LiDAR observation shift) into an IRS via weighted Noisy-OR. When IRS > 0.3, a contextual bandit selects one of three interpretable shields (steering guard, brake bias, speed cap) and blends it with the policy action based on authority α. Training uses risk-prioritized replay to emphasize high-IRS and takeover transitions. The method is evaluated in MetaDrive (30K steps) and CARLA (8K steps) under normal and cyber-physical attack conditions.

## Key Results
- In MetaDrive: Test Return 360.65, Success Rate 0.85, Training Safety Violations 29.07
- Under attacks: LiDAR spoofing SR 0.80, CAN injection DRA 0.37, ASR 0.34
- Outperforms RL, safe RL, IL, and prior HITL baselines across all metrics
- CARLA: Test Return 1609.70, Success Rate 0.41 with only 8K training steps

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Fusing heterogeneous runtime cues via a weighted Noisy-OR gate produces a more reliable Intrusion Risk Score (IRS) than single-metric thresholds, allowing the system to detect diverse attack vectors (actuation vs. perception).
- **Mechanism:** The IRS (Eq. 1) aggregates probability-like risk signals $r_i$ such that $IRS = 1 - \prod (1 - w_i r_i)$. This ensures that a strong signal from any single cue (e.g., a sudden drop in Time-to-Collision) can drive the total risk to 1.0 even if other cues (e.g., LiDAR consistency) appear nominal.
- **Core assumption:** The selected cues (Curvature, TTC, Observation Shift) are sufficiently independent and cover the primary modes of cyber-physical failure; attacks cannot easily evade all three simultaneously.
- **Evidence anchors:**
  - [PAGE 3] Equation (1) and description of weighted Noisy-OR ensuring "a single high-confidence anomaly... is sufficient to elevate IRS."
  - [PAGE 7] Ablation study (Table IV) showing that removing the TTC cue drops Success Rate significantly (0.67 vs 0.85) and increases Safety Violations, confirming the necessity of fusion.
  - [corpus] Related work (e.g., FedSecureFormer, IRSDA) supports the trend toward multimodal fusion for robust intrusion detection, though specific Noisy-OR efficacy is internal to this paper.
- **Break condition:** If an adversary exploits a blind spot not covered by the three cues (e.g., GPS spoofing without immediate LiDAR/curvature mismatch), the IRS may remain low, failing to trigger shields.

### Mechanism 2
- **Claim:** Contextual bandit arbitration allows the system to adaptively select the optimal safety shield (e.g., steering guard vs. brake bias) based on the specific risk profile, outperforming fixed static responses.
- **Mechanism:** A lightweight bandit maintains linear scoring functions $z_k = \theta_k^T c_t$ for each shield $k$ based on the cue vector. It selects shields via softmax sampling and updates weights using a delayed success signal (no takeover + low effort), learning which shield best mitigates specific risk contexts.
- **Core assumption:** The relationship between risk context (cue vector) and optimal shield is learnable and roughly stationary, and the "success" signal correlates with the shield's effectiveness.
- **Evidence anchors:**
  - [PAGE 4] Section III.C describes the bandit formulation over a library of interpretable transforms.
  - [PAGE 7] Table IV shows that removing the bandit (fixed shields) increases Safety Violations (1.10 vs 0.75) and Disturbance Rate, validating the adaptive mechanism.
  - [corpus] IRSDA paper supports "agent-orchestrated" response logic, aligning with RAIL's use of a selector agent.
- **Break condition:** If the delay between action and success signal is too long or noisy, credit assignment fails, causing the bandit to oscillate or converge to a sub-optimal default shield.

### Mechanism 3
- **Claim:** Risk-prioritized replay concentrates gradient updates on safety-critical transitions, enabling faster policy alignment to safety constraints than standard uniform sampling.
- **Mechanism:** The replay buffer prioritizes transitions using a scalar combining TD error, IRS magnitude, and human takeover flags. This forces the SAC critic to frequently update value estimates for "near miss" states, reducing the policy's tendency to repeat dangerous actions.
- **Core assumption:** High IRS and takeover states provide a sufficient representation of the failure boundary; over-sampling them does not cause catastrophic forgetting of nominal driving dynamics.
- **Evidence anchors:**
  - [PAGE 4] Section III.D details the prioritization scalar combining TD error, IRS, and flags.
  - [PAGE 5] Figure 3 shows RAIL achieving lower disturbance and takeover rates faster than baselines during training.
  - [corpus] General RL literature supports prioritized replay for sample efficiency; this paper extends it specifically to safety metrics.
- **Break condition:** If the "risk" priority is weighted too heavily, the agent may learn overly conservative behavior (freezing) or lose competence in normal driving maneuvers.

## Foundational Learning

- **Concept: Soft Actor-Critic (SAC)**
  - **Why needed here:** RAIL builds its base policy and critics using SAC. Understanding off-policy learning, entropy regularization, and the actor-critic split is required to modify the reward structure and replay buffer.
  - **Quick check question:** How does SAC's entropy bonus affect the exploration of safety shields during training?

- **Concept: Contextual Bandits**
  - **Why needed here:** The shield selection mechanism is formulated as a contextual bandit, not a full RL problem. You must distinguish between bandit feedback (single-step reward) and RL feedback (cumulative return) to debug the shield selector.
  - **Quick check question:** Why is the shield selection treated as a bandit problem rather than part of the main MDP policy?

- **Concept: Noisy-OR Bayesian Fusion**
  - **Why needed here:** The IRS relies on this probabilistic logic to fuse cues. Understanding how Noisy-OR calculates the probability of a "hidden cause" (intrusion) from observed "effects" (cues) is vital for tuning the weights $w_i$.
  - **Quick check question:** In a Noisy-OR model, if one cue $r_i$ is 1.0 (max risk), what is the resulting IRS, regardless of other cue values?

## Architecture Onboarding

- **Component map:** Ego state, LiDAR (72-beam), Human intervention signal → Cue Extractors (Curvature, TTC, OOD) → Weighted Noisy-OR → IRS → Contextual Bandit → Shield selection → Blender (mixes $a_t$ and $\tilde{a}_t$ based on IRS authority $\alpha$) → Action execution → SAC/Bandit Updates (via Risk-Prioritized Replay)

- **Critical path:** The **IRS calculation to Blender** path is the safety-critical latency bottleneck. The Bandit must select a shield and compute $\alpha$ within the control cycle (10Hz) to intercept malicious actions in time.

- **Design tradeoffs:**
  - **Cue Complexity vs. Latency:** Adding more cues (e.g., V2X) improves coverage (break condition for M1) but may increase computation time, risking late interventions.
  - **Shield Strength vs. Progress:** Aggressive shielding (high $\alpha$) ensures safety but may prevent the agent from learning to recover on its own or cause "stop-and-go" traffic inefficiencies (Disturbance Rate).

- **Failure signatures:**
  - **High Disturbance Rate (DR):** Indicates "false positives" where IRS triggers shields unnecessarily during normal driving.
  - **High Disengagement Rate under Attack (DRA):** Indicates IRS is failing to detect the attack (false negatives), forcing the human to intervene.

- **First 3 experiments:**
  1.  **Cue Isolation Test:** Inject CAN faults and LiDAR spoofing separately to verify that $r_{CURV}$ and $r_{OOD}$ spike independently and trigger the correct shield.
  2.  **Bandit Convergence Check:** Freeze the SAC policy and run the Bandit learner. Plot shield selection frequency vs. attack type to verify it learns the correct mapping (e.g., Brake bias for TTC, Steering guard for Curvature).
  3.  **Ablation on Replay Priority:** Train two agents, one with risk-prioritized replay and one with uniform. Plot "Training Safety Violations" over time to validate the sample efficiency gain.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does RAIL perform under hardware-in-the-loop (HIL) conditions and real-world environmental noise?
- **Basis in paper:** [explicit] The authors explicitly list "transfer to hardware-in-the-loop tests" in the future work section.
- **Why unresolved:** The reported results are restricted to the MetaDrive and CARLA software simulators, which abstract away physical actuator dynamics, sensor latency, and real-world noise.
- **What evidence would resolve it:** Successful deployment on a HIL platform demonstrating stable Intrusion Risk Score calculations and shield arbitration with physical sensor feeds.

### Open Question 2
- **Question:** Can RAIL's architecture be extended to multi-agent traffic scenarios with cooperative risk sharing?
- **Basis in paper:** [explicit] The conclusion proposes to "scale to multi-agent traffic with cooperative risk sharing."
- **Why unresolved:** The current framework treats traffic participants as background agents (IDM/MOBIL models) and does not implement communication or coordination protocols for multiple autonomous agents.
- **What evidence would resolve it:** Experiments in a multi-agent environment showing reduced collision rates and coordinated emergency maneuvers enabled by sharing risk vectors between agents.

### Open Question 3
- **Question:** What are the quantitative effects of RAIL's interpretable shields on human operator cognitive load and trust?
- **Basis in paper:** [explicit] The paper notes the need to "expand human factors evaluation of transparency and workload."
- **Why unresolved:** The study uses "Disengagement Rate" as a proxy for operator burden but lacks subjective metrics (e.g., NASA-TLX) or physiological measures of operator stress.
- **What evidence would resolve it:** User studies comparing RAIL against opaque safety systems using standardized workload assessments and trust questionnaires.

### Open Question 4
- **Question:** Does RAIL maintain robustness against adaptive adversaries designed to evade the specific runtime cues used for the Intrusion Risk Score?
- **Basis in paper:** [inferred] The authors plan to "integrate stronger attack generation to stress-test generalization," implying current threat models may not specifically target the IRS calculation logic.
- **Why unresolved:** The paper tests fixed-pattern CAN injection and LiDAR spoofing, but these attacks are not gradient-based or adaptive to the IRS's specific fusion of curvature, TTC, and OOD cues.
- **What evidence would resolve it:** Evaluation against adversarial attacks explicitly optimized to minimize the IRS score (or keep it below the threshold $\tau$) while maximizing collision probability.

## Limitations
- Shield implementations are only named, not parameterized; their effect on action blending is unclear. (Medium confidence in method description)
- No ablation on the choice of cues or weight tuning; IRS performance may be sensitive to these design decisions. (Medium confidence in cue selection)
- Training safety violation counts improve vs. baselines, but long-term stability beyond 30K steps is not shown. (Medium confidence in safety claim)

## Confidence

- **High:** Empirical improvement in success rate and safety violations vs. RL, safe RL, IL, and HITL baselines in MetaDrive and CARLA.
- **Medium:** Efficacy of the Noisy-OR fusion (limited ablation) and contextual bandit (shield names only, no parameterization) mechanisms.
- **Medium:** Risk-prioritized replay contribution (no ablation) and its interaction with SAC stability.

## Next Checks

1. **Shield Parameterization Test:** Implement concrete transforms for steering guard (clamp ±0.1 rad), brake bias (reduce accel by 50%), and speed cap (clamp velocity) and verify their effects in isolation.
2. **Cue Ablation:** Remove each IRS cue (Curvature, TTC, OOD) one at a time and measure impact on Success Rate and Safety Violations to validate fusion necessity.
3. **Replay Prioritization Sensitivity:** Compare training Safety Violations and Disturbance Rate for RAIL with risk-prioritized replay vs. uniform sampling to confirm efficiency gains.