---
ver: rpa2
title: 'Tune It Up: Music Genre Transfer and Prediction'
arxiv_id: '2503.22008'
source_url: https://arxiv.org/abs/2503.22008
tags:
- transfer
- music
- genre
- domain
- jazz
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper adapts CycleGAN for music genre transfer between Jazz
  and Classical piano pieces, aiming to generate genre-transferred music while preserving
  melody. The authors convert MIDI data to grayscale images and train CycleGAN with
  ResNet generators, adding auxiliary discriminators and triplet loss to improve style
  transfer quality.
---

# Tune It Up: Music Genre Transfer and Prediction

## Quick Facts
- arXiv ID: 2503.22008
- Source URL: https://arxiv.org/abs/2503.22008
- Reference count: 3
- Primary result: CycleGAN-based music genre transfer between Jazz and Classical piano, preserving melody while altering style, achieving 69.4% accuracy for Jazz→Classical and 39.3% for Classical→Jazz transfer.

## Executive Summary
This paper presents an approach for music genre transfer between Jazz and Classical piano using CycleGAN, a generative adversarial network architecture originally designed for image-to-image translation. The authors adapt CycleGAN to symbolic music by converting MIDI data to grayscale images and training ResNet-based generators with auxiliary discriminators and triplet loss to improve style transfer quality. To evaluate transfer performance, they train an MLP classifier achieving 87.7% accuracy on genre prediction and use it as an objective metric. A subjective user study with 23 participants confirms the method preserves musical structure while effectively altering style, though with asymmetric performance between transfer directions.

## Method Summary
The approach converts MIDI files to 64×84 binary matrices representing beats and notes, then transforms these into grayscale images for CycleGAN processing. The CycleGAN architecture uses ResNet-9 generators instead of the original U-Net, with 70×70 PatchGAN discriminators. Key modifications include replacing tanh activation with Sigmoid, adding auxiliary discriminators for each domain, and incorporating triplet loss to improve feature alignment. The MLP genre classifier uses one hidden layer with 1000 neurons and ReLU activation. Transfer performance is evaluated both objectively through classifier accuracy (69.4% for Jazz→Classical, 39.3% for Classical→Jazz) and subjectively through a user study rating genre classification accuracy and melody conservation.

## Key Results
- MLP genre classifier achieves 87.7% test accuracy on Jazz vs Classical classification
- CycleGAN with ResNet generators outperforms U-Net baseline (56% vs 10% transfer accuracy)
- Best model combines auxiliary discriminators and triplet loss, achieving 69.4% accuracy for Jazz→Classical transfer
- Subjective evaluation shows 60.8% genre classification accuracy for Jazz→Classical and 56.5% for Classical→Jazz, with melody conservation rated 3.65/5 and 3.57/5 respectively

## Why This Works (Mechanism)
The method works by adapting image-to-image translation techniques to symbolic music through pixel-based representation. Converting MIDI to grayscale images allows leveraging CycleGAN's ability to learn cross-domain mappings without paired examples. The ResNet generator architecture provides better feature extraction for musical patterns compared to U-Net. Auxiliary discriminators help the model focus on style-specific features while triplet loss ensures better alignment of musical structures between domains. The Sigmoid activation better suits the binary nature of musical notes compared to tanh.

## Foundational Learning
- **CycleGAN**: Unpaired image-to-image translation framework using cycle consistency loss to ensure content preservation. Needed for transferring between domains without requiring matched examples. Quick check: Verify cycle consistency loss implementation and weight.
- **ResNet architecture**: Residual network with skip connections that helps train deeper networks by mitigating vanishing gradients. Needed for better feature extraction in musical patterns. Quick check: Confirm ResNet-9 configuration matches paper specifications.
- **Triplet loss**: Loss function that pulls together similar samples and pushes apart dissimilar ones using anchor-positive-negative triplets. Needed to improve feature alignment between musical styles. Quick check: Verify margin parameter is set to 1.0.
- **PatchGAN discriminator**: Discriminator that classifies patches of the image rather than the whole image, providing local realism assessment. Needed for efficient training while maintaining quality. Quick check: Confirm 70×70 patch size configuration.
- **MIDI to image conversion**: Process of converting symbolic music data to pixel representations for GAN processing. Needed to adapt image-based techniques to music. Quick check: Verify 64×84 matrix dimensions and grayscale conversion.

## Architecture Onboarding

**Component Map**: MIDI files -> Binary matrices (64×84) -> Grayscale images -> CycleGAN (ResNet-9 + auxiliary discriminators + triplet loss) -> Sigmoid outputs -> Thresholded MIDI

**Critical Path**: The most important components are the ResNet-9 generators, auxiliary discriminators, and triplet loss, as these directly impact transfer quality and distinguish this approach from baseline CycleGAN.

**Design Tradeoffs**: Using image-based representation enables leveraging powerful vision architectures but loses explicit musical structure. The choice of ResNet over U-Net prioritizes feature extraction depth over skip connections. Sigmoid activation better matches binary note representation but may limit output diversity compared to tanh.

**Failure Signatures**: Low transfer accuracy (<50%) likely indicates incorrect ResNet implementation or missing triplet loss. Asymmetric performance between transfer directions suggests classifier bias or domain imbalance. Poor melody conservation scores indicate insufficient content preservation in the cycle consistency loss.

**First Experiments**:
1. Train and validate the MLP genre classifier to confirm ~87% accuracy on the Jazz/Classical dataset
2. Train CycleGAN with only ResNet generators (no auxiliary discriminators or triplet loss) to establish baseline performance
3. Add auxiliary discriminators alone, then both auxiliary discriminators and triplet loss, measuring performance improvements at each step

## Open Questions the Paper Calls Out
- How does varying the weight (γ) of the auxiliary discriminator losses affect the balance between genre transfer accuracy and melody conservation?
- Can a CNN-based classifier provide a more reliable objective metric for transfer performance than the Multi-Layer Perceptron used in this study?
- Do alternative architectures like DiscoGAN offer improved feature alignment over the CycleGAN baseline for symbolic music transfer?

## Limitations
- Asymmetric transfer performance (69.4% vs 39.3%) is unexpected and not fully explained
- Small sample size (23 participants) limits generalizability of subjective evaluation
- Classifier accuracy as objective metric may not fully capture musical fidelity or perceptual quality
- Unknown data splits and hyperparameters make exact reproduction challenging

## Confidence
- High: The general approach of adapting CycleGAN with ResNet generators and auxiliary discriminators for music genre transfer is sound and supported by results
- Medium: The specific performance numbers are likely reproducible with the same data and setup, but exact values may vary
- Medium: Claims about melody preservation are supported by user study but limited by sample size
- Low: The explanation for asymmetric transfer performance is speculative and not fully validated

## Next Checks
1. Reproduce the MLP genre classifier to verify ~87% accuracy on the same data split
2. Train CycleGAN with ResNet-9 generator, auxiliary discriminators, and triplet loss; measure baseline vs augmented performance
3. Conduct ablation studies removing auxiliary discriminators or triplet loss to confirm their individual contributions to performance gains