---
ver: rpa2
title: 'It''s all the (Exponential) Family: An Equivalence between Maximum Likelihood
  Estimation and Control Variates for Sketching Algorithms'
arxiv_id: '2601.22378'
source_url: https://arxiv.org/abs/2601.22378
tags:
- variance
- given
- cv-em
- estimate
- equation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper establishes an equivalence between maximum likelihood
  estimation (MLE) and control variate estimation (CVE) for exponential family distributions,
  where optimal CVEs achieve the same asymptotic variance as MLEs. The authors prove
  this equivalence under conditions where each sufficient statistic's expectation
  equals its corresponding parameter.
---

# It's all the (Exponential) Family: An Equivalence between Maximum Likelihood Estimation and Control Variates for Sketching Algorithms

## Quick Facts
- arXiv ID: 2601.22378
- Source URL: https://arxiv.org/abs/2601.22378
- Reference count: 40
- This paper establishes an equivalence between maximum likelihood estimation (MLE) and control variate estimation (CVE) for exponential family distributions, where optimal CVEs achieve the same asymptotic variance as MLEs.

## Executive Summary
This paper presents a fundamental equivalence between maximum likelihood estimation (MLE) and control variate estimation (CVE) for exponential family distributions. The authors prove that when each sufficient statistic's expectation equals its corresponding parameter, the optimal control variates achieve the same asymptotic variance as MLEs. This equivalence provides new insights into sketching algorithms and addresses reproducibility issues in high-dimensional statistical estimation.

The work demonstrates that using control variates with iteratively updated weights forms an Expectation-Maximization (EM) algorithm that converges faster and more stably than traditional root-finding methods like Newton-Raphson or the Secant method, particularly for the bivariate Normal distribution. The paper also presents a heuristic for finding MLEs when CVE weights are known by treating the CVE as a fixed point iteration, successfully deriving Bekas' diagonal estimator for Hutchinson's trace estimation.

## Method Summary
The authors establish theoretical equivalence between MLE and CVE under conditions where sufficient statistics' expectations equal their corresponding parameters. They develop CV-EM, an iterative algorithm using control variates with updated weights that forms an EM algorithm converging faster than traditional methods. The approach is validated through experiments with feature hashing and random projections, showing reduced mean squared error and fewer update steps compared to baseline methods. A heuristic method is presented for finding MLEs when CVE weights are known, demonstrated through derivation of Bekas' diagonal estimator for Hutchinson's trace estimation.

## Key Results
- Optimal control variates achieve the same asymptotic variance as MLEs for exponential family distributions under specific conditions
- CV-EM algorithm converges faster and more stably than Newton-Raphson and Secant methods for bivariate Normal distribution
- Feature hashing and random projection experiments show CV-EM reduces mean squared error and requires fewer update steps
- Heuristic CVE-based MLE finding successfully derives Bekas' diagonal estimator for Hutchinson's trace estimation

## Why This Works (Mechanism)
The equivalence between MLE and CVE arises from the exponential family structure where sufficient statistics' expectations equal parameters. Control variates reduce variance in sketching algorithms by leveraging known expectations, while MLE finds parameters maximizing likelihood. When these expectations match parameters, the optimal control variate weights align with the score function used in MLE, creating theoretical equivalence. The CV-EM algorithm iteratively updates CVE weights to converge to MLE, combining variance reduction benefits with likelihood maximization.

## Foundational Learning
- **Exponential Family Distributions**: Probability distributions with specific mathematical form allowing factorization into natural parameters and sufficient statistics. Needed because the equivalence between MLE and CVE specifically applies to this distribution class.
- **Sufficient Statistics**: Functions of data that capture all information about parameters. Quick check: Verify that E[T(x)] = η for each sufficient statistic T and parameter η in the exponential family.
- **Control Variates**: Random variables with known expectations used to reduce variance in Monte Carlo estimation. Quick check: Ensure the control variate has high correlation with the target estimator.
- **Score Function**: Gradient of log-likelihood with respect to parameters. Quick check: Confirm the score function equals the difference between sufficient statistics and their expectations.
- **EM Algorithm**: Iterative method alternating between expectation and maximization steps. Quick check: Verify convergence by monitoring log-likelihood changes between iterations.
- **Sketched Estimators**: Compressed representations of data matrices used for efficient computation. Quick check: Compare estimation error between sketched and full-data approaches.

## Architecture Onboarding

**Component Map**
CVE weights estimation -> Control variate application -> MLE equivalence verification -> Iterative EM convergence

**Critical Path**
1. Initialize CVE weights based on sufficient statistics
2. Apply control variates to sketching algorithm
3. Update weights using EM framework
4. Verify convergence to MLE equivalence
5. Evaluate performance metrics

**Design Tradeoffs**
- Computational complexity vs. convergence speed: CV-EM requires more per-iteration computation but fewer total iterations
- Accuracy vs. scalability: The equivalence holds theoretically but may degrade in high dimensions
- Flexibility vs. generality: The method works specifically for exponential families, limiting broader applicability

**Failure Signatures**
- Divergence when sufficient statistics have high variance relative to parameters
- Slow convergence when initial CVE weights are far from optimal values
- Numerical instability when the exponential family conditions are not precisely met

**3 First Experiments**
1. Verify MLE-CVE equivalence for univariate Normal distribution with known analytical solutions
2. Compare CV-EM convergence against Newton-Raphson for bivariate Normal with varying correlation coefficients
3. Test heuristic CVE-based MLE finding on simple quadratic forms before applying to Hutchinson's trace estimation

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical equivalence relies on strict conditions that sufficient statistics' expectations equal corresponding parameters, limiting generality
- Empirical validation focuses primarily on bivariate Normal distributions, potentially missing behavior in higher dimensions
- Heuristic approach for finding MLEs when CVE weights are known requires broader validation across diverse statistical problems
- Computational complexity and scalability of CV-EM in high-dimensional settings remain unexplored
- Potential numerical stability issues when CVE weights are not perfectly known or sufficient statistics have high variance

## Confidence
- **High Confidence**: Theoretical framework establishing equivalence between MLE and CVE under stated conditions is well-founded and rigorously proven
- **Medium Confidence**: Empirical results demonstrating CV-EM's superior convergence speed and stability, though limited to specific examples
- **Medium Confidence**: Heuristic CVE-based MLE finding approach, validated on Hutchinson's trace estimation but requiring broader testing

## Next Checks
1. Test the CV-EM algorithm on higher-dimensional exponential family distributions beyond bivariate Normal to assess scalability and robustness

2. Conduct systematic comparisons of computational complexity and numerical stability between CV-EM and traditional MLE methods across diverse statistical problems

3. Validate the heuristic CVE-based MLE finding approach on additional statistical estimation problems, particularly those with non-standard sufficient statistics or constraints