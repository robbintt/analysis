---
ver: rpa2
title: First and Second Order Approximations to Stochastic Gradient Descent Methods
  with Momentum Terms
arxiv_id: '2504.13992'
source_url: https://arxiv.org/abs/2504.13992
tags:
- lemma
- theorem
- then
- proof
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper develops continuous approximations to stochastic gradient
  descent (SGD) methods with momentum terms, addressing the gap between empirical
  observations and rigorous mathematical analysis. The key innovation is extending
  existing diffusion approximation results to scenarios with both time-varying learning
  rates and momentum parameters.
---

# First and Second Order Approximations to Stochastic Gradient Descent Methods with Momentum Terms

## Quick Facts
- arXiv ID: 2504.13992
- Source URL: https://arxiv.org/abs/2504.13992
- Reference count: 4
- Key outcome: Develops continuous ODE/SDE approximations to momentum-based SGD with O(h²) error bounds, extending diffusion approximation theory to scenarios with time-varying learning rates and momentum parameters

## Executive Summary
This paper establishes rigorous mathematical foundations for continuous approximations of stochastic gradient descent (SGD) methods with momentum terms. The key innovation is extending existing diffusion approximation results to handle both time-varying learning rates and momentum parameters. By treating the discrete SGD process as a 2d-dimensional system that tracks consecutive iterates, the paper proves weak convergence to continuous processes with quantified O(h) and O(h²) approximation errors. The framework provides theoretical justification for empirical practices like using constant momentum values around 0.9 and demonstrates O(1/k²) convergence rates for momentum-based methods in convex settings.

## Method Summary
The method involves three key transformations: (1) converting the d-dimensional momentum-SGD into a 2d-dimensional process by tracking consecutive iterates, (2) reformulating momentum updates as standard gradient descent on a modified objective with cross-terms encoding velocity coupling, and (3) applying Taylor expansion analysis to establish O(h²) approximation error bounds. The discrete process χ_{n+1} = χ_n + η_n H_{γ(n)}(χ_n) + ζ_n(χ_n - χ_{n-1}) is analyzed through its 2d lift (χ_{n+1}, χ_n), which enables treatment via ordinary differential equations (ODEs) or stochastic differential equations (SDEs). The framework accommodates various learning rate schedules and momentum parameter choices while providing theoretical justification for common empirical practices.

## Key Results
- Establishes both ODE and SDE approximations that converge to discrete momentum-SGD as learning rate approaches zero
- Quantifies approximation error as O(h) for first-order and O(h²) for second-order approximations
- Proves O(1/k²) convergence rate for momentum-based methods in convex settings, improving upon standard SGD's O(1/k) rate
- Shows momentum-based SGD can be reformulated as standard SGD on a modified objective with cross-terms encoding velocity coupling

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Converting momentum-based SGD into a 2d-dimensional process enables diffusion approximation by eliminating explicit velocity terms.
- **Mechanism**: Define χ = (χ_{n+1}, χ_n) ∈ R^{2d}. The momentum update becomes χ_{n+1} = χ_n + ηJ(χ_n) where J is the gradient of a modified objective j(x,y).
- **Core assumption**: Momentum parameters ζ_n and learning rates η_n are diagonal matrices with entries bounded in (0,1].
- **Evidence anchors**: [abstract], [Section 3, Remark 1], [corpus: Li et al. 2017]

### Mechanism 2
- **Claim**: Momentum-SGD on objective f is equivalent to standard SGD on a modified objective j with cross-terms encoding velocity coupling.
- **Mechanism**: The modified objective j(x) = f(x_1,...,x_d) + Σ_i[(1+ζ_i)x_i²/(2η_i) + ζ_i x_{d+i}²/(2η_i) - ζ_i x_i x_{d+i}/η_i] has gradient J that naturally produces momentum updates.
- **Core assumption**: Assumption (A3*) — J̄ and √E are Lipschitz with bounded partial derivatives up to order 2.
- **Evidence anchors**: [Section 4.2], [Section 3, Theorem 2], [corpus: Ankirchner and Perko 2021]

### Mechanism 3
- **Claim**: O(h²) approximation error is achieved by controlling Taylor expansion remainders through polynomial growth bounds on the iterates.
- **Mechanism**: Taylor expand y_t(x + δ) where δ = Δχ^h_k is the one-step change. The remainder R_h(δ) involves third-order terms h^k(Δχ)^β.
- **Core assumption**: H_γ(x) ∈ G¹(R^d) (polynomial growth) and expected gradient H̄ has Lipschitz derivatives up to order 2.
- **Evidence anchors**: [Section 4, Lemma 5], [Section 4, Lemma 4], [corpus: Li et al. 2017 and Ankirchner and Perko 2021]

## Foundational Learning

- **Concept: Itô's Lemma and Stochastic Integration**
  - Why needed here: The SDE approximation requires computing how functions of diffusion processes evolve; Feynman-Kac (Theorem 1) connects SDEs to PDEs for computing expectations.
  - Quick check question: Given dX_t = μ(X_t)dt + σ(X_t)dW_t, write Itô's formula for df(t, X_t).

- **Concept: Weak Convergence vs Pathwise Convergence**
  - Why needed here: The paper proves weak convergence — E[g(χ^h_{T/h})] - E[g(X_T)] = O(h²) for smooth g — not that the paths themselves converge.
  - Quick check question: Explain why weak convergence allows expectations to converge even when sample paths don't converge pointwise.

- **Concept: Polynomial Growth Spaces G^κ and Lipschitz Spaces Lip^ℓ**
  - Why needed here: All approximation results require functions in these spaces; Lemma 3 proves y_t ∈ G^ℓ if g ∈ G^ℓ.
  - Quick check question: Verify that if g ∈ G^κ(R^d) and X has bounded p-th moments, then E[g(X)] is finite for appropriate p.

## Architecture Onboarding

- **Component map**:
  Initial (x_0, x_1) → 2d state lifting → Modified objective construction → Continuous process solution → Expectation via Feynman-Kac PDE

- **Critical path**:
  Initial (x_0, x_1) → 2d state lifting → Modified objective construction → Continuous process solution → Expectation via Feynman-Kac PDE

- **Design tradeoffs**:
  1. **ODE vs SDE**: ODE is computationally simpler (no diffusion term) but SDE captures gradient noise variance via Σ(x); use SDE when noise structure matters.
  2. **First-order vs second-order SDE (Theorem 7)**: Second-order achieves O(h²) in supremum norm max_n |E[g(χ^h_n)] - E[g(X^h_{nh})]| but requires drift correction -½h(y²_t∇J̄J̄ + u̇_tJ̄).
  3. **Constant vs varying schedules**: Varying schedules require time-dependent J̄_t and Feynman-Kac equation; constant schedules simplify analysis.

- **Failure signatures**:
  1. ||χ*||_{p,n} grows exponentially → assumption (A2) violated (gradient grows faster than linear).
  2. Error does not scale as O(h²) → check that h ∈ H = {h ∈ (0,1) : T/h ∈ ℕ} or that g ∉ G^∞.
  3. Modified objective j is poorly conditioned → momentum parameter ζ too large relative to η (cross-terms dominate).
  4. SDE approximation diverges → Σ(x) not Lipschitz or √Σ not well-defined.

- **First 3 experiments**:
  1. **Verify O(h²) scaling**: Implement momentum-SGD on f(x) = (1/2)x^T A x with known minimum. Plot |E[g(χ^h_{T/h})] - E[g(X_T)]|/h vs h for h ∈ {0.1, 0.05, 0.025, 0.0125}. Expect convergence to constant φ̄ = ∫_0^T φ_t(X_t)dt.
  2. **Compare ODE vs SDE approximations**: On a non-convex objective with significant gradient noise, compare: (a) ODE approximation, (b) SDE approximation, (c) actual momentum-SGD. Measure variance of E[g(χ_T)] estimates; SDE should better capture variance.
  3. **Stress-test assumption (A3)**: Use an objective where ∇²f is unbounded (e.g., f(x) = x^4). Measure approximation error and verify it exceeds O(h²), confirming the Lipschitz condition on second derivatives is necessary.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Can the ODE and SDE approximation results be extended to Nesterov accelerated gradient descent?
- **Basis in paper**: [explicit] The conclusion states: "extension to other methods such as Nesterov Acceleration"
- **Why unresolved**: Nesterov acceleration uses a different update mechanism with look-ahead gradients, not covered by the Heavy Ball formulation analyzed
- **What evidence would resolve it**: Proving weak convergence with O(h²) error for Nesterov SGD under similar Lipschitz and growth assumptions

### Open Question 2
- **Question**: What are the optimal learning rate and momentum schedules derivable from the continuous approximation framework?
- **Basis in paper**: [inferred] The paper proves approximation accuracy for general schedules u_t, v_t but does not address which schedules minimize expected loss
- **Why unresolved**: Approximation results describe dynamics but do not prescribe optimal hyperparameter choices for convergence
- **What evidence would resolve it**: Deriving schedules from the limiting SDE that provably minimize expected objective value

### Open Question 3
- **Question**: Do the approximation results extend to non-convex objective functions commonly encountered in deep learning?
- **Basis in paper**: [inferred] Assumption (A3) requires Lipschitz continuity of the expected gradient with bounded derivatives up to order two, which may fail for non-convex landscapes
- **Why unresolved**: The regularity conditions may be violated in non-convex settings; the proof relies on polynomial growth bounds
- **What evidence would resolve it**: Identifying subclasses of non-convex functions satisfying the growth conditions or weakening assumptions while retaining O(h²) convergence

## Limitations

- Theoretical framework assumes strong regularity conditions on objective functions (Lipschitz gradients, polynomial growth bounds) that may not hold for deep learning problems with non-smooth activation functions
- Analysis requires careful handling of learning rate schedules and momentum parameters that are diagonal matrices with bounded entries, potentially limiting applicability to more general adaptive methods
- Results rely on specific structural assumptions about the relationship between momentum parameters and learning rates (diagonal matrices, bounded entries)

## Confidence

- **High confidence**: The O(h) and O(h²) approximation error bounds for first and second-order continuous approximations, supported by rigorous Taylor expansion analysis and bounded moment assumptions
- **Medium confidence**: The equivalence between momentum-SGD and SGD on modified objectives j, as this requires specific structural assumptions on the cross-terms
- **Medium confidence**: The weak convergence results, which establish E[g(χ^h_{T/h})] - E[g(X_T)] = O(h²) for smooth test functions but don't guarantee pathwise convergence

## Next Checks

1. **Numerical validation of O(h²) scaling**: Implement momentum-SGD on quadratic objectives with varying learning rates and momentum parameters, then empirically verify the O(h²) convergence rate in the approximation error
2. **Robustness to schedule violations**: Test approximation quality when momentum or learning rate schedules violate diagonal matrix assumptions or boundedness conditions
3. **Extension to non-convex settings**: Evaluate how well the continuous approximations capture momentum-SGD behavior on non-convex objectives commonly found in deep learning