---
ver: rpa2
title: Rewarding Explainability in Drug Repurposing with Knowledge Graphs
arxiv_id: '2509.02276'
source_url: https://arxiv.org/abs/2509.02276
tags:
- paths
- scientific
- explanations
- explanation
- drug
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generating scientifically
  meaningful explanations for AI-driven drug repurposing hypotheses. The proposed
  REx method employs a reinforcement learning agent guided by reward mechanisms that
  balance fidelity to the hypothesis, relevance of entities, and simplicity of the
  explanation.
---

# Rewarding Explainability in Drug Repurposing with Knowledge Graphs

## Quick Facts
- arXiv ID: 2509.02276
- Source URL: https://arxiv.org/abs/2509.02276
- Reference count: 11
- Primary result: State-of-the-art predictive performance with MRR scores of 0.427, 0.376, and 0.278 on Hetionet, PrimeKG, and OREGANO, respectively

## Executive Summary
This paper introduces REx, a reinforcement learning method for generating scientifically meaningful explanations for drug repurposing hypotheses using knowledge graphs. REx balances fidelity to the hypothesis, relevance of entities, and simplicity of the explanation through a composite reward mechanism. The method employs clustered Information Content to mitigate research bias and enriches explanatory paths with ontology classes for coherence. Evaluated on three biomedical knowledge graphs, REx achieved state-of-the-art predictive performance and produced more relevant explanatory paths that received higher ratings from domain experts compared to baseline methods.

## Method Summary
REx uses a reinforcement learning agent to find paths between drug and disease entities in a knowledge graph, guided by a reward mechanism that balances fidelity (reaching the target) and relevance (information content of path entities). The method calculates Information Content on a clustered graph to reduce research bias effects, where entities are embedded and clustered before computing IC based on cluster degrees. Paths are enriched with ontology classes using Lowest Common Ancestor calculations for coherence. The system was evaluated on Hetionet, PrimeKG, and OREGANO, achieving MRR scores of 0.427, 0.376, and 0.278 respectively.

## Key Results
- Achieved state-of-the-art predictive performance with MRR scores of 0.427, 0.376, and 0.278 on three biomedical knowledge graphs
- Produced more relevant explanatory paths with higher Information Content compared to baseline methods
- Received higher ratings from domain experts for explanation quality and scientific plausibility
- Successfully identified both known and novel biologically plausible repurposing mechanisms

## Why This Works (Mechanism)

### Mechanism 1: Multi-Objective Reward Shaping
The RL agent receives a composite reward $R_{final} = R_{Fidelity} \times R_{Relevance}$. $R_{Fidelity}$ is binary (1 if target reached, 0 otherwise), while $R_{Relevance}$ is the average Information Content of path entities. This forces the agent to find paths that are both valid routes and dense with specific, low-frequency biomedical concepts.

### Mechanism 2: Clustered Information Content (CIC) for Bias Mitigation
Instead of raw node degrees, REx embeds entities using OWL2Vec*, clusters them with K-means, and calculates IC based on cluster degrees. This smooths variations where minor semantic duplicates artificially inflate or deflate a node's importance.

### Mechanism 3: Ontological Enrichment for Coherence
After extracting paths, REx identifies the Lowest Common Ancestor (LCA) of consecutive entities using external ontologies (NCIT, ChEBI). This adds semantic abstraction to raw paths, improving human interpretability.

## Foundational Learning

- **Concept:** Reinforcement Learning (RL) Markov Decision Processes (MDPs)
  - **Why needed here:** REx frames pathfinding as a sequential decision process where an agent learns a policy to maximize reward
  - **Quick check question:** Can you explain why a reward function of $R_{final} = R_{Fidelity} \times R_{Relevance}$ might be harder to optimize than a simple sum?

- **Concept:** Information Content (IC) in Knowledge Graphs
  - **Why needed here:** The method relies on entity occurrence probability to define "relevance"
  - **Quick check question:** Why would a node with a high degree (many connections) have *lower* Information Content in this context?

- **Concept:** Ontology Alignment & Lowest Common Ancestor (LCA)
  - **Why needed here:** The system relies on mapping KG entities to an external ontology to provide context
  - **Quick check question:** If two entities in a path have no common ancestor in the loaded ontology, what happens to the explanation coherence?

## Architecture Onboarding

- **Component map:** Input KG + Hypothesis triple -> Preprocess (embed+cluster+compute CIC) -> RL Engine (LSTM policy) -> Reward Calculator -> Output Module (prune+enrich+return subgraph)
- **Critical path:** The Reward Calculation is the bottleneck for performance. If IC scores are not pre-calculated efficiently or if the reward signal is too sparse, the policy network will not converge
- **Design tradeoffs:**
  - Simplicity vs. Detail: Early stopping mechanism ensures simplicity but may reduce completeness
  - Cluster Granularity: K-means clusters set to 10% of node count is heuristic; too few clusters = loss of specificity; too many = failure to mitigate bias
- **Failure signatures:**
  - Low MRR / High Variance: RL agent stuck in random walks; check RFidelity sparsity or learning rate
  - Generic Explanations: Paths return high-level concepts; check if CIC effectively penalizes high-degree generic nodes
  - Runaway Path Length: Agent loops or creates excessively long paths; verify Early Stopping policy is active
- **First 3 experiments:**
  1. Ablation on Reward: Run REx with only Fidelity vs. Full REx to verify delta caused by Relevance reward
  2. IC Method Comparison: Compare standard IC vs. Clustered IC vs. CIC-by-Relation on small validation set
  3. Expert Sampling: Generate explanations for 5 known drug-disease pairs and check if enriched ontology classes match known biological mechanism

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent is the modest predictive performance attributable to KG incompleteness versus genuine absence of scientific evidence?
- Basis in paper: [explicit] The conclusion states modest performance may be due to KG incompleteness or lack of scientific evidence
- Why unresolved: The paper does not disentangle these two potential causes
- What evidence would resolve it: Manual curation of failed predictions against literature, or controlled experiments augmenting KGs with known missing facts

### Open Question 2
- Question: How robust is the Clustered Information Content (CIC) approach to the choice of clustering method and the 10% cluster-count heuristic?
- Basis in paper: [inferred] The method uses OWL2vec* embeddings clustered with K-means at 10% of node count without ablation or sensitivity analysis
- Why unresolved: The paper does not evaluate alternative clustering algorithms or parameter settings
- What evidence would resolve it: Ablation experiments varying clustering algorithms and cluster counts, reporting impacts on MRR and path IC

### Open Question 3
- Question: Does the early stopping mechanism systematically sacrifice explanation completeness in complex multi-mechanism hypotheses?
- Basis in paper: [inferred] The paper frames simplicity and completeness as trade-offs but does not measure completeness directly
- Why unresolved: No quantitative metric or human evaluation specifically assesses whether important alternative paths are missed
- What evidence would resolve it: Compare REx against non-early-stopping variant on expert-rated completeness scores and diversity of discovered metapaths

### Open Question 4
- Question: What is the isolated contribution of ontology-based enrichment (LCA integration) to explanation quality and expert satisfaction?
- Basis in paper: [inferred] The method enriches paths with ontology classes but ablation studies do not isolate the LCA enrichment component
- Why unresolved: It remains unclear how much of the expert preference stems from this enrichment versus path relevance and simplicity
- What evidence would resolve it: Ablation comparing full REx to variant without LCA enrichment, using expert ratings and automated coherence metrics

## Limitations
- Performance critically depends on KG quality and ontology alignment accuracy
- Clustering heuristic (10% of nodes) lacks theoretical justification and may not generalize
- Binary fidelity rewards could create sparse gradients for RL agent in large, sparse graphs

## Confidence

- **High Confidence**: Predictive performance metrics (MRR, Hits@K) are empirically validated across three distinct KGs, and RL framework is technically sound
- **Medium Confidence**: Novelty of using clustered IC to mitigate research bias is conceptually justified but lacks comparative ablation with alternative bias-correction methods
- **Low Confidence**: Claim that ontology enrichment "improves coherence" is supported only by qualitative expert ratings, not rigorous semantic consistency measure

## Next Checks

1. **Ablation Study on Clustering**: Compare REx's clustered IC against non-clustered IC and alternative clustering strategies on a held-out KG to quantify impact of clustering heuristic on explanation quality
2. **Ontology Alignment Robustness**: Systematically vary quality of KG-to-ontology alignment and measure downstream effect on LCA enrichment and expert ratings
3. **Generalization to Unseen Domains**: Apply REx to KG from different biomedical subdomain and evaluate whether method maintains predictive and explanatory performance without retraining embeddings or clusters