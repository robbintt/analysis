---
ver: rpa2
title: Generative Adversarial Networks Applied for Privacy Preservation in Biometric-Based
  Authentication and Identification
arxiv_id: '2509.20024'
source_url: https://arxiv.org/abs/2509.20024
tags:
- images
- learning
- domain
- privacy
- faces
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes using GANs to translate face images into visually
  private domains (e.g., flowers, shoes) for privacy-preserving biometric authentication.
  The key idea is to train a classifier on translated images so that real faces are
  never exposed during authentication.
---

# Generative Adversarial Networks Applied for Privacy Preservation in Biometric-Based Authentication and Identification

## Quick Facts
- arXiv ID: 2509.20024
- Source URL: https://arxiv.org/abs/2509.20024
- Reference count: 35
- Primary result: GAN-based face-to-flower translation achieves 99.76% authentication accuracy while protecting privacy from inverse attacks.

## Executive Summary
This paper proposes using GANs to translate face images into visually private domains (e.g., flowers, shoes) for privacy-preserving biometric authentication. The key idea is to train a classifier on translated images so that real faces are never exposed during authentication. Experiments show that classifiers trained on flower-translated images achieve 99.76% accuracy and 86.11% F1 score, only slightly lower than those trained on real faces. TraVeLGAN outperforms other GAN frameworks, generating consistent and diverse translations. Inverse attacks were largely unsuccessful, especially when using asymmetric domains. The method balances privacy and utility effectively, requiring no server-side retraining and allowing flexible dataset or model choices.

## Method Summary
The method trains a GAN to translate face images into a target visual domain (flowers, shoes, etc.) while preserving identity features through a Siamese network loss. The generator, discriminator, and Siamese network are trained together using unpaired image-to-image translation. The translated images are then used to train a classifier for authentication, with the original faces never exposed to the server. The approach uses TraVeLGAN for its superior semantic consistency compared to CycleGAN or DiscoGAN, particularly for asymmetric domain pairs.

## Key Results
- Classifiers trained on flower-translated images achieve 99.76% accuracy and 86.11% F1 score, only slightly lower than those trained on real faces
- TraVeLGAN framework outperforms CycleGAN and DiscoGAN for asymmetric domain translation
- Inverse attacks were largely unsuccessful, especially when using asymmetric domains like faces to flowers
- The method requires no server-side retraining and allows flexible dataset or model choices

## Why This Works (Mechanism)

### Mechanism 1: Semantic Preservation via Transformation Vectors
Translating face images to unrelated visual domains preserves identity features sufficient for authentication if structural semantics are maintained. The architecture uses a Siamese network alongside the GAN generator to capture high-level semantics between domains by minimizing the distance between the generated image's feature vector and the input's feature vector in a latent space. This forces the generator to map identity-specific geometric relationships onto the target domain's texture space. The feature extractor must generalize well to both faces and the target domain to provide a useful loss signal. If the target domain lacks structural diversity, the generator collapses identities into similar outputs, failing classification.

### Mechanism 2: One-Way Mapping via Domain Asymmetry
Privacy is maintained because reconstructing the original face from the translated image is mathematically difficult without model access. The method relies on information loss inherent in translating between highly asymmetric domains. Since the target domain has different geometric constraints than the source, the mapping function creates a projection that retains identity but loses reversible pixel-data. Inverse Transformation Network attacks fail because the reverse mapping cannot recover the information discarded during initial translation. An attacker without access to the specific random initialization and weights of the user's local generator model cannot reconstruct the original face. However, if the target domain is structurally similar to faces, reconstruction error drops, compromising privacy.

### Mechanism 3: Centralized Trust Reduction
Moving the translation step to the client side eliminates the need for a trusted central server. The GAN resides and executes on the user's device, and the server only observes the output distribution (synthetic flowers) and trains the authentication classifier on this non-sensitive data. This creates an air gap where the biometric template never traverses the network. The user's local device must be secure and not compromised by malware inspecting RAM during translation. If the server acts as an active adversary and successfully poisons model updates to force generation of reversible features, privacy degrades.

## Foundational Learning

- **Concept: Unpaired Image-to-Image Translation**
  - Why needed here: We do not have a dataset of "face-flower" pairs. The model must learn to translate a face into a flower without direct 1:1 examples, relying instead on distributions.
  - Quick check question: Can you explain why CycleGAN would fail here compared to TraVeLGAN regarding identity preservation? (Hint: Think about "cycle consistency" vs. "semantic consistency").

- **Concept: Siamese Networks**
  - Why needed here: Standard GANs only ensure the output looks like a flower. A Siamese network is required to force the output flower to mathematically resemble the input face in feature space, ensuring the user can still be identified.
  - Quick check question: If you remove the Siamese loss term, what happens to the authentication accuracy? (Answer: It likely collapses to random chance because distinct faces would map to random flowers).

- **Concept: Inverse Transformation Networks (ITN)**
  - Why needed here: To evaluate security, you must understand how an attacker tries to "reverse" the process. An ITN attempts to learn the mapping Y → X by freezing the generator G (which does X → Y) and training a new network to minimize reconstruction error.
  - Quick check question: Why does training an ITN fail when the domains are asymmetric (e.g., faces and shoes) but might succeed with symmetric domains (e.g., day and night scenes)?

## Architecture Onboarding

- **Component map:**
  Input Face -> Generator (Face→Flower) -> Discriminator -> Siamese Network -> Classification Server

- **Critical path:**
  1. **Preprocessing:** Align and crop faces; augment with StarGAN to ensure intra-class variety
  2. **Translation Training:** Train TraVeLGAN (Face→Flower) until Discriminator loss stabilizes and Siamese loss is minimized
  3. **Synthesis:** Translate the entire authentication dataset into flowers
  4. **Authentication Training:** Train MobileNetV2 on the synthetic flowers

- **Design tradeoffs:**
  - **TraVeLGAN vs. CycleGAN:** CycleGAN enforces pixel-perfect reconstruction (cycle consistency), which makes inversion easier and often leads to mode collapse on asymmetric domains. TraVeLGAN enforces semantic consistency, which is harder to train but more robust against inversion.
  - **Accuracy vs. Privacy:** Using a more distinct domain (e.g., abstract art vs. shoes) increases privacy but may drop accuracy if the Siamese network cannot map features effectively.

- **Failure signatures:**
  - **Mode Collapse:** The generator produces the exact same flower for every input face (DiscoGAN/CycleGAN issue).
  - **Identity Leakage:** The generated flower looks like a face texture wrapped in flower colors (inverse attack success).
  - **Low Recall:** The classifier identifies impostors well but rejects the genuine user (30% drop in recall if layers are frozen).

- **First 3 experiments:**
  1. **Framework Baseline:** Train CycleGAN vs. TraVeLGAN on Face→Shoe. Verify if CycleGAN collapses (Discriminator loss → 0) as per Section 5.2.
  2. **Utility Verification:** Train a binary classifier on the generated images (Flowers) and compare the F1 score against a classifier trained on the original faces. Look for the "performance drop" gap (approx 6% in paper).
  3. **Attack Simulation:** Freeze the trained Generator and train a new "Inverse" network to map Flowers→Faces. Visually inspect if the reconstructed faces reveal identity or just generic gender/hair features.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the method scale to large-scale, open-set identification tasks (1:N) compared to the binary verification tasks tested?
- Basis in paper: The authors validated the method using binary classification on 93 identities, but the title claims applicability for "Identification," which typically implies searching a much larger database.
- Why unresolved: The feature distinctiveness of the generated "flower" domain may suffer from higher collision rates as the number of enrolled users increases, a limitation not tested in binary settings.
- What evidence would resolve it: Benchmarking the approach on datasets with thousands of identities to measure rank-1 identification accuracy and False Accept Rates.

### Open Question 2
- Question: Can an automated protocol be developed to update user credentials when their physical appearance changes significantly?
- Basis in paper: The conclusion identifies the need for an "update procedure allowing users to submit new synthetic images after changing the visage."
- Why unresolved: Biometric features naturally drift over time (aging, hairstyle); the current static approach requires manual intervention or re-training to handle these changes.
- What evidence would resolve it: A mechanism that detects feature drift in the translated domain and securely updates the server-side profile without retraining the GAN.

### Open Question 3
- Question: Can the utility gap between real-face and synthetic-domain classifiers be eliminated using more advanced generative architectures?
- Basis in paper: The authors list "improving the quality of synthetic images as well as the performance of classifiers" as a focus for future work.
- Why unresolved: While TraVeLGAN performed best, U-GAT-IT showed promise but was computationally infeasible to test, leaving the potential for better preservation of identity features unexplored.
- What evidence would resolve it: Implementing the method with high-capacity models (like U-GAT-IT) to demonstrate classification metrics statistically indistinguishable from real-face baselines.

## Limitations

- Privacy claims rely heavily on domain asymmetry but lack extensive empirical evidence about how quickly inverse attacks improve with model access or computational resources
- The ITN-attack results show reconstructed images reveal sex or hairstyle but not "real identity," yet specific reconstruction quality metrics (PSNR, SSIM) are not reported
- The background removal method for the 8,000 training images is unspecified, which could significantly impact translation quality and subsequent privacy guarantees

## Confidence

- **High Confidence:** The GAN translation methodology (TraVeLGAN framework, training procedure) and the utility metrics (99.76% accuracy, 86.11% F1 score) are well-documented and reproducible. The architectural choices and their effects on performance are clearly explained.
- **Medium Confidence:** The privacy claims regarding inverse attack resistance are supported by internal experiments but lack comparison to state-of-the-art inversion techniques. The asymmetric domain protection mechanism is theoretically sound but not extensively validated against adaptive adversaries.
- **Low Confidence:** The specific implementation details for background removal and StarGAN augmentation are not provided, creating potential reproducibility gaps. The paper does not address potential vulnerabilities from compromised client devices or side-channel attacks.

## Next Checks

1. **ITN Attack Robustness:** Conduct experiments varying the attacker's computational budget and model access (e.g., partial model exposure, knowledge of initialization) to quantify how privacy degrades under different threat models.

2. **Cross-Dataset Generalization:** Test the authentication accuracy when the classifier is trained on flowers from one domain (e.g., Oxford 102) but tested on faces translated to a different domain (e.g., Shoes) to verify domain transfer capabilities.

3. **Background Removal Impact:** Systematically evaluate how different background removal techniques (manual vs. automated segmentation) affect both translation quality and subsequent classification accuracy to isolate this preprocessing step's contribution.