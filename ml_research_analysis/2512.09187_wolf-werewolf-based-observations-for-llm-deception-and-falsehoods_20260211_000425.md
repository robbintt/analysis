---
ver: rpa2
title: 'WOLF: Werewolf-based Observations for LLM Deception and Falsehoods'
arxiv_id: '2512.09187'
source_url: https://arxiv.org/abs/2512.09187
tags:
- deception
- suspicion
- while
- werewolf
- wolf
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: WOLF addresses the gap in multi-agent deception evaluation by introducing
  a structured social deduction benchmark based on Werewolf. It uses role-grounded
  agents (Villager, Werewolf, Seer, Doctor) in a programmable LangGraph state machine,
  with strict night-day cycles, bidding-based debate turns, and majority voting.
---

# WOLF: Werewolf-based Observations for LLM Deception and Falsehoods

## Quick Facts
- arXiv ID: 2512.09187
- Source URL: https://arxiv.org/abs/2512.09187
- Reference count: 20
- Primary result: 31% deception rate by Werewolves with 71-73% detection precision

## Executive Summary
WOLF introduces a structured social deduction benchmark based on Werewolf to evaluate LLM capabilities in both producing and detecting deception within adversarial multi-agent settings. The system uses role-grounded agents (Villagers, Werewolves, Seer, Doctor) operating in programmable LangGraph state machines with strict night-day cycles and majority voting. Every public statement is analyzed at the statement level, with self-assessed honesty from speakers and peer-rated deceptiveness from others. Across 100 runs and 7,320 statements, deception production averaged 31% for Werewolves, while peer detection achieved 71-73% precision but only ~52% overall accuracy. Suspicion toward Werewolves rose from ~52% to over 60% across rounds, demonstrating that extended interaction improves discrimination against liars without compounding errors against truthful roles.

## Method Summary
WOLF employs LangGraph state machines to orchestrate Werewolf gameplay with 8 fixed-role agents (4 Villagers, 2 Werewolves, 1 Seer, 1 Doctor) across 100 runs. Night phases involve simultaneous actions (Werewolf targeting, Doctor protection, Seer investigation), while day phases use bidding (0-10) for debate turn order followed by majority voting. Each statement receives self-assessment and peer analysis, with deception categorized as omission, distortion, fabrication, or misdirection. Suspicion scores update longitudinally via exponential smoothing (α=0.7), and metrics include Brier scores, ROC/AUC, AUPRC, and cross-perception matrices. The system logs all events as NDJSON streams for reproducibility.

## Key Results
- Deception production: Werewolves produced deceptive statements in 31% of turns
- Detection performance: 71-73% precision but only ~52% overall accuracy
- Longitudinal dynamics: Werewolf suspicion rose from ~52% to over 60% across rounds while Villagers/Doctor stabilized at 44-46%

## Why This Works (Mechanism)

### Mechanism 1
Extended interaction improves discrimination between deceptive and truthful agents without compounding errors against honest roles through exponential smoothing (α=0.7) that aggregates suspicion over time, weighting new evidence heavily while retaining historical context. This allows suspicion toward Werewolves to rise measurably (+1.6 percentage points per round) while stabilizing for Villagers and Doctors.

### Mechanism 2
Deception type influences detectability—subtle forms (omission, misdirection) evade detection more effectively than overt fabrication. Omissions resemble natural uncertainty and don't contradict accumulated context, while fabrications introduce false claims that eventually conflict with shared information, triggering higher flag rates.

### Mechanism 3
High precision with low recall reflects cautious detection—peers rarely false-positive but frequently miss deceptive statements. Peer agents assign continuous suspicion scores; when they do flag deception, they're usually correct (71-73% precision), but they miss ~40-50% of actual deceptions (recall 48-61%).

## Foundational Learning

- **Exponential smoothing for sequential belief updates**: Needed to understand how suspicion scores evolve across rounds via D_t+1 = α·s(o,t) + (1-α)·D_t; quick check: If α=0.9 instead of 0.7, would suspicion be more reactive or more stable?
- **Social deduction games as partial-information reasoning**: Needed to understand why asymmetric information drives deception incentives; quick check: Why does the Seer face higher suspicion before revealing than after?
- **Self-assessment vs. peer evaluation as label sources**: Needed to interpret accuracy metrics since ground truth comes from speakers' private scratchpads; quick check: What biases might arise from using agent self-reports as ground truth?

## Architecture Onboarding

- **Component map**: LangGraph state machine -> Role-grounded agents -> Bidding system -> Statement analyzer -> Suspicion tracker -> Logging layer
- **Critical path**: 1) Game initialization with fixed role assignment, 2) Night phase with simultaneous actions, 3) Day phase with bidding → statements → assessments → voting, 4) Win condition check, 5) Post-game metric aggregation
- **Design tradeoffs**: Fixed roles ensure reproducibility but under-sample coalition strategies; self-assessment labels enable scale but may not match human judgment; bidding system creates naturalistic debate flow but adds stochasticity
- **Failure signatures**: Malformed outputs repaired via prompt engineering + conservative defaults; over-suspicion toward honest roles indicates calibration issues
- **First experiments**: 1) Run deterministic mock analyzer mode (<30 seconds/game) to verify suspicion trajectories, 2) Execute 10 full LLM games to check win rate distribution, 3) Analyze statement-level deception rates across roles

## Open Questions the Paper Calls Out

### Open Question 1
Do deception production and detection asymmetries persist across different LLM architectures and model scales? The paper evaluates only one model configuration, though it states "deception scales more quickly than detection" as a guiding hypothesis.

### Open Question 2
Can calibrated suspicion scores be transformed into actionable detection improvements in live gameplay? Section 5.7 notes "calibration adjustments could improve detection without altering gameplay" but does not implement or test this.

### Open Question 3
How would human-annotated ground truth labels change the measured deception detection performance? The limitations acknowledge that "labels come from model self-assessments rather than humans, so they reflect subjective judgments."

### Open Question 4
Do longer games with larger player sets and coalition formation reveal different deception-detection dynamics? Limitations state that fixed role distribution and player count "may under-sample longer-horizon or coalition-based strategies."

## Limitations
- Fixed role distribution ensures reproducibility but under-samples coalition strategies and complex social dynamics
- Self-assessment labels may not align with human judgment, introducing potential bias in accuracy metrics
- Only one LLM model was evaluated, limiting generalizability across architectures

## Confidence

**High Confidence**: Deception production rates (31% for Werewolves), detection precision (71-73%), and longitudinal suspicion trends (Werewolf suspicion rising from ~52% to >60%, Villagers/Doctor stabilizing at 44-46%)

**Medium Confidence**: Detection recall (48-61%) and overall accuracy (~52%) are reasonable given conservative agent behavior but could vary with different threshold settings

**Medium Confidence**: The mechanism that extended interaction improves discrimination without compounding errors against honest roles is supported by Theil-Sen slope analysis (+1.6 percentage points per round)

## Next Checks

1. **Cross-Annotator Validation**: Have human annotators independently label a sample of statements for deception type and compare agreement with agent self-assessments to quantify label reliability

2. **Model Ablation Test**: Run WOLF with different LLM models (GPT-4, Claude, Llama) to assess whether reported deception detection patterns are model-dependent or robust across architectures

3. **Temporal Dynamics Verification**: Plot suspicion trajectories across all 100 games to confirm that the reported Theil-Sen slope of +1.6 percentage points per round for Werewolf suspicion is representative, and examine variance across individual game runs