---
ver: rpa2
title: 'FAIR-QR: Enhancing Fairness-aware Information Retrieval through Query Refinement'
arxiv_id: '2503.21092'
source_url: https://arxiv.org/abs/2503.21092
tags:
- fairness
- query
- information
- retrieval
- documents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses fairness in information retrieval systems
  by proposing a novel query refinement-based approach (FAIR-QR) to improve group
  fairness while maintaining relevance. The method recursively refines search queries
  using large language models to retrieve more documents from underrepresented groups,
  then re-ranks results using the original query to preserve relevance.
---

# FAIR-QR: Enhancing Fairness-aware Information Retrieval through Query Refinement

## Quick Facts
- **arXiv ID**: 2503.21092
- **Source URL**: https://arxiv.org/abs/2503.21092
- **Reference count**: 25
- **Primary result**: FAIR-QR achieves highest nDCG*AWRF score (0.6083 for gender) by iteratively refining queries to improve group fairness while maintaining relevance

## Executive Summary
FAIR-QR addresses fairness in information retrieval by proposing a query refinement-based approach that improves group fairness while maintaining relevance. The method recursively refines search queries using large language models to retrieve more documents from underrepresented groups, then re-ranks results using the original query to preserve relevance. Experiments on the TREC Fair Ranking Track 2022 dataset show FAIR-QR outperforms existing fairness-aware IR methods in both biographic gender and geographic location fairness metrics (AWRF), achieving the highest nDCG*AWRF score indicating balanced fairness and relevance performance.

## Method Summary
FAIR-QR operates by first retrieving documents with an initial query using BM25, then computing the exposure distribution across groups. If the KL divergence between current and target exposure distributions is not sufficiently small, the system identifies the most underrepresented group and uses GPT-4o to generate refined query keywords targeting that group. This process repeats for up to 5 iterations or until divergence stops decreasing. Finally, all retrieved documents are re-ranked using the original query with BM25 to ensure relevance is preserved while the expanded document pool maintains improved fairness characteristics.

## Key Results
- FAIR-QR achieves highest nDCG*AWRF score of 0.6083 for biographic gender fairness
- FAIR-QR achieves highest AWRF score of 0.7661 for geographic location fairness
- FAIR-QR outperforms all baselines (BM25, Vector Search, DLF, DELTR, FA*IR, MMR) in combined nDCG*AWRF metric

## Why This Works (Mechanism)

### Mechanism 1: Iterative Query Expansion Targeting Underrepresented Groups
- Claim: Adding group-specific keywords to queries increases retrieval of documents from underrepresented groups.
- Mechanism: The system identifies the most underrepresented group ĝ in current results, then prompts an LLM to append keywords related to ĝ. This semantically biases the retrieval toward documents associated with that group, shifting the exposure distribution.
- Core assumption: The LLM can generate semantically relevant keywords that meaningfully connect the original query intent to the underrepresented group without drifting topic.
- Evidence anchors:
  - [abstract] "refines query keywords to retrieve documents from underrepresented groups"
  - [section 2.2] "we identify the most under-represented group ĝ... we refine the query using LLMs because ĝ is underrepresented, and related keywords should be added or modified"
  - [corpus] Weak direct evidence; neighbor papers address fairness in GNNs and synthetic data, not query-based fairness mechanisms.
- Break condition: If LLM-generated keywords are semantically disconnected from the original query intent, relevance degrades faster than fairness improves.

### Mechanism 2: Divergence-Gated Iteration Control
- Claim: KL divergence between current exposure distribution ε and target ε* provides a stopping criterion that prevents over-refinement.
- Mechanism: At each iteration, the system computes Δ(ε, ε*). If divergence does not decrease, iteration stops. This bounds the fairness-relevance tradeoff.
- Core assumption: Decreasing divergence correlates with improved fairness as defined by exposure-based group fairness, and the target distribution ε* is correctly specified.
- Evidence anchors:
  - [section 2.2] "If the difference (quantified by KL divergence) between these two distributions Δ(ε, ε*) is not small enough... we keep refining queries"
  - [section 3.2] "iterations will be terminated earlier if Δ(ε, ε*) does not decrease"
  - [corpus] No corpus papers validate divergence-based stopping for fair IR.
- Break condition: If the target distribution ε* is misspecified (e.g., based on incomplete annotations), the system optimizes toward an incorrect fairness goal.

### Mechanism 3: Original-Query Re-ranking for Relevance Preservation
- Claim: Re-ranking expanded retrieval results using the original query with BM25 recovers relevance while retaining fairness gains.
- Mechanism: Fairness-oriented query expansion may retrieve relevant-but-lower-ranked documents. Re-ranking with the original query reorders by original-query relevance, placing the most relevant documents at top positions while the overall document pool remains fairer.
- Core assumption: The retrieval function (BM25) reliably captures relevance when applied to the original query, and fairness improvements are not entirely concentrated in low-relevance documents.
- Evidence anchors:
  - [abstract] "re-ranked to ensure relevance"
  - [section 2.2] "re-rank the retrieved documents using the original query to ensure that the most relevant documents are ranked at the top"
  - [Table 1] FAIR-QR achieves nDCG@20 = 0.6530 (competitive) with highest nDCG*AWRF = 0.6083 (gender), demonstrating balanced tradeoff.
  - [corpus] No corpus evidence on re-ranking for fairness preservation.
- Break condition: If expanded queries retrieve documents largely irrelevant to the original query, re-ranking cannot recover relevance.

## Foundational Learning

- Concept: Exposure-based Group Fairness (AWRF metric)
  - Why needed here: The paper defines fairness as each group receiving expected exposure proportional to relevance, not equal exposure. AWRF quantifies this using Jensen-Shannon divergence between observed and target exposure distributions.
  - Quick check question: If Group A has 80% of relevant documents, what should its target exposure be?

- Concept: KL Divergence and Jensen-Shannon Divergence
  - Why needed here: These metrics measure distributional distance between current and target exposure. The system uses KL for iteration control; AWRF uses JS divergence for evaluation.
  - Quick check question: Why might JS divergence be preferred over KL divergence for fairness evaluation?

- Concept: Query Refinement in Information Retrieval
  - Why needed here: FAIR-QR's core intervention is modifying queries rather than post-processing results. Understanding how query terms affect retrieval is essential.
  - Quick check question: What is the risk of adding keywords to a query without understanding their semantic relationship to the original intent?

## Architecture Onboarding

- Component map: Retrieval Module -> Exposure Calculator -> Divergence Evaluator -> Query Refinement Module -> Re-ranking Module
- Critical path:
  1. Retrieve documents with current query
  2. Compute exposure distribution from group memberships
  3. Compare to target via KL divergence
  4. If divergence decreasing and below threshold → proceed to re-ranking
  5. Else → identify most underrepresented group → LLM refines query → repeat from step 1
  6. Re-rank final candidate set with original query
  7. Return top-k results
- Design tradeoffs:
  - **Max iterations vs. overfitting**: Paper sets max=5 empirically (75th percentile = 4 iterations). Higher values risk semantic drift.
  - **LLM temperature**: Set to 0.3 for reproducibility. Higher temperature increases exploration but reduces consistency.
  - **Retriever choice**: BM25 used; vector search underperformed (nDCG = 0.4771) because queries were keyword-extracted, not natural sentences.
- Failure signatures:
  - **Semantic drift**: Refined queries diverge from original intent → low nDCG despite high AWRF.
  - **Stagnation**: Divergence stops decreasing before reaching target → fairness ceiling hit.
  - **Annotation sparsity**: Missing group memberships cause "Unknown" group to dominate exposure distribution.
  - **LLM hallucination**: Generated keywords have no semantic link to any corpus documents → retrieval returns empty or irrelevant results.
- First 3 experiments:
  1. **Baseline replication**: Run BM25 on TREC Fair Ranking 2022, compute nDCG@20 and AWRF@20 for gender and geography. Compare to paper's reported values (nDCG=0.6638, AWRF_gender=0.8857, AWRF_geo=0.7895).
  2. **Ablation on re-ranking**: Run FAIR-QR without the re-ranking step. Compare nDCG and nDCG*AWRF to quantify relevance recovery (paper shows nDCG drops from 0.6530 to 0.6423 without re-ranking for gender).
  3. **Iteration sensitivity**: Run FAIR-QR with max_iterations ∈ {1, 3, 5, 10}. Plot AWRF and nDCG vs. iterations to validate the paper's choice of 5 and observe over-refinement patterns.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does FAIR-QR perform when implemented with alternative generative models or dense retrieval algorithms?
- Basis in paper: [explicit] The authors state, "We tested BM25 and GPT-4o in this work, and more different models will be explored in future studies."
- Why unresolved: The current study is restricted to a specific proprietary LLM (GPT-4o) and a sparse retrieval method (BM25). It is unclear if the framework depends on GPT-4o's specific instruction-following capabilities or if BM25's keyword matching is essential for the refined queries to be effective.
- What evidence would resolve it: Ablation studies using open-source LLMs (e.g., Llama, Mistral) and neural retrievers (e.g., ColBERT, bi-encoders) to measure performance variance against the current baseline.

### Open Question 2
- Question: To what extent can advanced prompt engineering optimize the trade-off between fairness and relevance or reduce the number of recursive iterations?
- Basis in paper: [explicit] The conclusion notes, "Given the focus of this work, we leave further prompt engineering to future work."
- Why unresolved: The current prompt was derived from ablation studies but remains a fixed component. Since LLM outputs are highly sensitive to input phrasing, optimized prompting could potentially retrieve fairer documents in fewer steps, lowering computational overhead.
- What evidence would resolve it: Comparative analysis of different prompt strategies (e.g., few-shot, chain-of-thought) measuring the convergence rate of the KL divergence constraint and the preservation of nDCG.

### Open Question 3
- Question: Is FAIR-QR effective on non-Wikipedia datasets or domains with different data sparsity and linguistic characteristics?
- Basis in paper: [explicit] The authors acknowledge, "since the data sparsity, we only tested FAIR-QR on one recent fair-ranking dataset."
- Why unresolved: The TREC 2022 dataset comprises structured Wikipedia articles. It is uncertain if the query refinement approach transfers effectively to noisier corpora (e.g., social media, news) or domains where group membership annotations are less consistent.
- What evidence would resolve it: Evaluation on diverse fair ranking benchmarks (e.g., TREC 2021, SemEval) or proprietary datasets to verify generalization beyond encyclopedic text.

### Open Question 4
- Question: What are the computational latency and cost implications of the recursive refinement loop compared to single-pass fair ranking baselines?
- Basis in paper: [inferred] The methodology relies on a recursive loop (mean 2 iterations, max 5) involving calls to GPT-4o, and the authors explicitly mention a trade-off between generalizability and "over-fitting" regarding iteration counts.
- Why unresolved: While the paper proves the effectiveness (nDCG/AWRF), it does not quantify the added latency or API costs. Recursive LLM calls may render the method impractical for real-time search requirements.
- What evidence would resolve it: Systematic measurement of query latency (ms/query) and token costs, compared against efficient baselines like FA*IR or DELTR.

## Limitations

- The approach depends heavily on the LLM's ability to generate semantically meaningful keywords, introducing uncertainty about semantic drift and reproducibility.
- The stopping criterion based on KL divergence assumes correctly specified target exposure distributions, which depends on complete and accurate group membership annotations.
- The paper does not specify the exact KL divergence threshold for stopping refinement, leaving a critical hyperparameter unspecified.
- Generalizability across different retrieval algorithms and fairness categories is asserted but not thoroughly tested beyond the TREC Fair Ranking 2022 dataset.

## Confidence

**High Confidence**: The mechanism of iterative query expansion to target underrepresented groups is well-specified and grounded in the paper's methodology. The use of BM25 re-ranking to preserve relevance while maintaining fairness gains is clearly described and demonstrated through experimental results.

**Medium Confidence**: The divergence-gated iteration control shows promise but lacks specific implementation details (KL threshold) that could affect performance. The LLM's ability to generate appropriate keywords without semantic drift is plausible but not empirically validated across diverse query types.

**Low Confidence**: The generalizability of FAIR-QR across different retrieval algorithms and fairness categories is asserted but not thoroughly tested beyond the TREC Fair Ranking 2022 dataset. The approach's robustness to annotation sparsity and LLM hallucination is not explicitly addressed.

## Next Checks

1. **Reproduce baseline metrics**: Implement BM25 baseline on TREC Fair Ranking 2022 dataset and verify nDCG@20 = 0.6638 and AWRF values match paper's reported 0.8857 (gender) and 0.7895 (geography).

2. **Test semantic drift**: Run FAIR-QR with and without re-ranking, measuring nDCG per iteration to quantify relevance preservation. Verify that nDCG drops from 0.6530 to 0.6423 without re-ranking as reported.

3. **Vary iteration limits**: Execute FAIR-QR with max_iterations ∈ {1, 3, 5, 10} and plot AWRF and nDCG trade-offs to validate the empirical choice of 5 iterations and identify over-refinement patterns.