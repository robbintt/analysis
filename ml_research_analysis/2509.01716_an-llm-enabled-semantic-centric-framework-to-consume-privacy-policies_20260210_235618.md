---
ver: rpa2
title: An LLM-enabled semantic-centric framework to consume privacy policies
arxiv_id: '2509.01716'
source_url: https://arxiv.org/abs/2509.01716
tags:
- data
- privacy
- policies
- policy
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents an LLM-enabled semantic-centric framework for
  automatically converting natural-language privacy policies into formal knowledge
  graphs, called Pr2Graph, using state-of-the-art large language models. The pipeline
  identifies key information about privacy practices including data entities, purposes,
  parties, actions, and their relations, with grounding from the Data Privacy Vocabulary
  (DPV) for better interoperability.
---

# An LLM-enabled semantic-centric framework to consume privacy policies

## Quick Facts
- **arXiv ID**: 2509.01716
- **Source URL**: https://arxiv.org/abs/2509.01716
- **Reference count**: 40
- **Key outcome**: LLM-enabled framework (Pr2Graph) converts privacy policies into formal knowledge graphs with F1-scores around 0.9, enabling automated analysis of online services' privacy practices

## Executive Summary
This paper presents Pr2Graph, an LLM-enabled framework that automatically converts natural-language privacy policies into formal knowledge graphs using large language models and grounding from the Data Privacy Vocabulary (DPV). The pipeline identifies key privacy practice elements including data entities, purposes, parties, and actions, with performance comparable to human annotators on the enriched Policy-IE dataset. The framework was applied to analyze the top-100 most-visited websites and demonstrated downstream applications including conversion to formal policy representations like ODRL and psDToU, addressing the critical need for scalable creation of formal privacy policies.

## Method Summary
The Pr2Graph framework employs a multi-stage pipeline where LLMs process privacy policies to extract structured information about data entities, purposes, parties, and actions. The extracted elements are then mapped to the Data Privacy Vocabulary (DPV) for semantic grounding and interoperability. The framework was evaluated on an enriched Policy-IE dataset with custom annotations by legal experts, achieving F1-scores around 0.9 for most tasks. The system also includes modules for converting extracted knowledge into formal policy representations such as ODRL (Open Digital Rights Language) and psDToU formats, enabling downstream applications for privacy analysis and automated decision-making.

## Key Results
- LLMs achieve F1-scores around 0.9 for extracting privacy practice elements from natural language policies
- Performance is comparable to human annotators, with small sample comparison (two annotators for 100 samples)
- Successfully generated Pr2Graph representations for top-100 most-visited websites
- Demonstrated downstream applications including conversion to ODRL and psDToU formal policy representations

## Why This Works (Mechanism)
The framework leverages large language models' natural language understanding capabilities to parse complex privacy policy text and identify structured privacy practice elements. By grounding extracted information to the Data Privacy Vocabulary (DPV), the system ensures semantic consistency and interoperability across different policy representations. The multi-stage pipeline approach allows for systematic extraction of entities, purposes, parties, and actions, while the use of expert-annotated datasets provides reliable ground truth for training and evaluation.

## Foundational Learning
- **LLM-based information extraction**: Needed to convert unstructured policy text into structured data; Quick check: Validate F1-scores across different policy types and domains
- **Data Privacy Vocabulary (DPV) grounding**: Provides standardized semantic framework for interoperability; Quick check: Test expressiveness for emerging privacy concepts not in current DPV
- **Multi-stage pipeline architecture**: Enables systematic processing of complex policy structures; Quick check: Evaluate performance impact of each pipeline stage
- **Formal policy representation conversion**: Allows integration with existing privacy frameworks; Quick check: Validate ODRL and psDToU conversions with real-world applications

## Architecture Onboarding

**Component map**: Privacy policy text -> LLM extraction module -> DPV grounding -> Knowledge graph generation -> ODRL/psDToU conversion

**Critical path**: LLM extraction → DPV mapping → Knowledge graph generation

**Design tradeoffs**: Standard DPV vocabulary provides interoperability but may limit expressiveness for emerging privacy concepts; LLM-based extraction offers flexibility but requires extensive training data

**Failure signatures**: Poor performance on less structured policies, domain-specific terminology not captured, DPV mapping failures for novel privacy concepts

**First experiments**: 1) Test extraction accuracy on diverse policy types (healthcare, finance, education); 2) Evaluate DPV mapping accuracy for emerging privacy concepts; 3) Measure performance degradation on policy updates and evolving practices

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Performance evaluation relies on single enriched dataset without broader validation across diverse policy types or languages
- Manual annotation process by legal experts introduces potential subjectivity in ground truth labels
- Small sample size for human annotator comparison limits statistical confidence

## Confidence

**High confidence**: Core methodology and pipeline architecture are sound and well-documented

**Medium confidence**: Performance metrics are valid within tested dataset but may not generalize

**Medium confidence**: Downstream applications demonstrate technical feasibility but lack extensive real-world validation

## Next Checks
1. Test Pr2Graph on diverse corpus of privacy policies from different sectors (healthcare, finance, education) to assess generalizability across domains
2. Conduct inter-annotator agreement studies with multiple legal experts to establish reliability of ground truth annotations
3. Perform longitudinal evaluation to assess how well framework handles privacy policy updates and evolving practices over time