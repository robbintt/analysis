---
ver: rpa2
title: 'Variance-Optimal Arm Selection: Regret Minimization and Best Arm Identification'
arxiv_id: '2505.11985'
source_url: https://arxiv.org/abs/2505.11985
tags:
- variance
- regret
- bound
- arms
- algorithm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of selecting the arm with the
  highest variance from a set of K independent arms in multi-armed bandit settings.
  The authors propose algorithms for two settings: regret minimization and best arm
  identification (BAI).'
---

# Variance-Optimal Arm Selection: Regret Minimization and Best Arm Identification

## Quick Facts
- **arXiv ID:** 2505.11985
- **Source URL:** https://arxiv.org/abs/2505.11985
- **Reference count:** 38
- **Primary result:** Order-optimal algorithms for variance maximization: UCB-VV achieves O(log n) regret with matching lower bound, SHVV achieves exponential error probability bound for best arm identification.

## Executive Summary
This paper addresses the problem of selecting the arm with the highest variance from a set of K independent arms in multi-armed bandit settings. The authors propose two algorithms: UCB-VV for regret minimization, which achieves logarithmic regret with order-optimal bounds, and SHVV for best arm identification (BAI), which provides exponential error probability guarantees. The framework extends from bounded distributions to sub-Gaussian distributions using novel concentration inequalities for sample variance and Sharpe ratio. Empirical simulations demonstrate superior performance of the proposed algorithms compared to baselines like ε-greedy and uniform sampling. A real-world case study on call option trading using simulated stock data validates the practical effectiveness of the approach.

## Method Summary
The paper proposes UCB-VV for regret minimization, which selects arms using an index combining empirical variance and a confidence bonus (B_i^VV = V̄_i(t) + √(2log t / s_i)). For BAI, SHVV implements sequential halving with K rounds, allocating samples equally among surviving arms and eliminating the bottom half based on variance estimates. Both algorithms assume independent arms with bounded or sub-Gaussian rewards. The theoretical analysis derives matching upper and lower bounds for regret and error probability. The framework extends to Sharpe ratio optimization by leveraging sub-Gaussian concentration properties. Implementation requires estimating sample mean and variance, computing confidence intervals, and managing arm elimination or selection strategies.

## Key Results
- UCB-VV achieves O(log n) regret bound matching the corresponding lower bound, proving order optimality
- SHVV achieves error probability bound matching the corresponding lower bound with exponential decay in budget
- Extension to sub-Gaussian distributions using novel concentration inequalities for sample variance and Sharpe ratio
- Empirical simulations show UCB-VV outperforming ε-greedy across different sub-optimality gaps
- Real-world case study demonstrates 4-5x higher cumulative rewards compared to standard UCB in call option trading

## Why This Works (Mechanism)

### Mechanism 1: Variance-Optimism via Upper Confidence Bounds
- **Claim:** If an agent selects arms based on an optimistically biased estimate of variance, it can achieve logarithmic regret while identifying the highest-variance arm.
- **Mechanism:** The UCB-VV algorithm constructs an index B_i^VV = V̄_i(t) + √(2log t / s_i). This index sums the empirical variance V̄_i and a confidence bonus. The bonus shrinks as samples s_i increase, forcing the algorithm to converge to the true highest variance arm while ensuring sub-optimal arms are not starved of exploration too early.
- **Core assumption:** Rewards are bounded in [l, u], allowing the use of McDiarmid's inequality to bound variance deviation.
- **Evidence anchors:** The abstract mentions UCB-VV as a "UCB-type algorithm that uses variance estimates... proving an O(log n) regret bound." Section equation (3) defines the index B_i^VV; Theorem 1 proves the upper bound scales as 8 Σ(log n / δ_i).
- **Break condition:** If rewards are unbounded and heavy-tailed (violating the bounded/sub-Gaussian assumption), the confidence radius √(2log t / s_i) becomes invalid, causing over-exploration or divergence.

### Mechanism 2: Sequential Halving for Fixed-Budget Identification
- **Claim:** If the budget is allocated iteratively to surviving arms while systematically eliminating those with lower empirical variance, the probability of identifying the optimal arm scales exponentially with the budget.
- **Mechanism:** The SHVV algorithm splits the total budget n into log₂ K rounds. It allocates samples equally among remaining arms in each round and eliminates the bottom half based on variance estimates. This filtering process concentrates the remaining budget on distinguishing the top candidates, avoiding wasted samples on clearly suboptimal arms.
- **Core assumption:** The budget n is fixed and known in advance; variance gaps δ_i exist to distinguish arms.
- **Evidence anchors:** The abstract describes SHVV as an "arm-elimination algorithm with error probability bound exp(-n/log(K)H)". Section Algorithm 2 details the loop where t_r = n / (|A_r| log₂ K) samples are allocated per round.
- **Break condition:** If the number of arms K scales such that n ≈ K log K, the per-arm budget t_r becomes too small for variance estimates to stabilize, leading to near-random elimination.

### Mechanism 3: Sub-Gaussian Concentration for Sharpe Ratio
- **Claim:** If rewards are sub-Gaussian, the sample variance and Sharpe Ratio (SR) concentrate around their true values, permitting a UCB approach for risk-adjusted optimization.
- **Mechanism:** The paper leverages the property that squared sub-Gaussian variables are sub-exponential. Using Bernstein's inequality, they bound the sample variance error (Theorem 5). This allows bounding the error of the SR (mean/variance), enabling UCB-Sharpe to optimize risk-adjusted returns without path-dependent analysis.
- **Core assumption:** The random variables are i.i.d. and sub-Gaussian with parameter v².
- **Evidence anchors:** The abstract mentions "deriving novel concentration inequalities for sample variance and Sharpe ratio." Section Theorem 6 provides the bound P(|V̄(n) - V| ≥ η) ≤ 4exp(-cn min(η², η)).
- **Break condition:** If the distribution has infinite variance or is not sub-Gaussian (e.g., Pareto with α ≤ 2), the concentration bounds fail, and the SR estimate may never converge.

## Foundational Learning

- **Concept: Multi-Armed Bandit (MAB) Regret**
  - **Why needed here:** The paper defines regret specifically in terms of variance gaps (δ_i) rather than reward gaps. Understanding standard regret is necessary to see how the authors adapt it for risk-seeking (variance maximization) or risk-aware (Sharpe) scenarios.
  - **Quick check question:** How does the definition of δ_i in Eq. (2) differ from standard stochastic bandit regret?

- **Concept: Concentration Inequalities (McDiarmid & Bernstein)**
  - **Why needed here:** The theoretical guarantees rely entirely on proving that sample variance stays close to true variance. McDiarmid bounds are used for bounded rewards (Lemma 1), while Bernstein bounds handle the sub-exponential nature of variance in the sub-Gaussian extension (Theorem 5).
  - **Quick check question:** Why does the proof switch from McDiarmid to Bernstein-type inequalities when moving from bounded to sub-Gaussian rewards?

- **Concept: Sub-Gaussian & Sub-Exponential Distributions**
  - **Why needed here:** The extension to "real-world" finance data (Section IV) assumes returns are sub-Gaussian. Understanding that sub-Gaussian variables have squared counterparts that are sub-exponential is key to understanding the variance concentration proofs.
  - **Quick check question:** If a distribution has heavier tails than Gaussian, does Theorem 5 still hold?

## Architecture Onboarding

- **Component map:** Estimator (updates sample mean and biased sample variance) -> Indexer (computes UCB indices or ranks arms for SHVV) -> Selector (chooses argmax for Regret or executes elimination for BAI)

- **Critical path:** The initialization phase (pulling all arms once) → iterative variance estimation → index calculation → arm selection

- **Design tradeoffs:**
  - UCB-VV vs. VTS: The paper notes VTS (Variance Thompson Sampling) outperforms UCB-VV empirically but lacks theoretical guarantees. Choose UCB-VV for safety guarantees; VTS for raw performance.
  - Bias in Variance: The paper uses a biased estimator (dividing by s_i rather than s_i-1). This is computationally simpler and asymptotically equivalent, but might skew early decisions with very few samples.

- **Failure signatures:**
  - **Stagnation:** If δ_i is extremely small (hard instance), UCB-VV regret grows logarithmically but constants are huge.
  - **Premature Elimination:** In SHVV, if the budget n is too low relative to K, the optimal arm is eliminated early (error probability e_n remains high).
  - **Non-stationarity:** The algorithms assume i.i.d. rewards. If market volatility regimes shift (e.g., GBM parameters change), the static variance assumption breaks.

- **First 3 experiments:**
  1. **Bounded Regret Validation:** Implement UCB-VV on a 2-arm Bernoulli bandit with δ = 0.1 and δ = 0.5 (replicating Fig 1) to verify logarithmic regret scaling.
  2. **BAI Scaling Stress Test:** Run SHVV with fixed budget n=2000 while increasing arms K ∈ {16, 32, 64} (replicating Fig 2) to observe error probability growth.
  3. **Sharpe Ratio Concentration:** Generate sub-Gaussian returns, compute sample Sharpe Ratios, and empirically verify the tail probability bounds described in Theorem 6.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can rigorous theoretical guarantees (regret bounds) be established for Variance Thompson Sampling (VTS) in variance-maximization settings?
  - **Basis in paper:** Page 6 notes that while UCB-VV is order optimal, "the superior performance of VTS highlights the need for a theoretical investigation of VTS."
  - **Why unresolved:** Thompson Sampling is often empirically superior to UCB variants but is notoriously harder to analyze theoretically due to its stochastic nature and the complexities of posterior updates for variance parameters.
  - **What evidence would resolve it:** A derivation of the asymptotic or finite-time regret bound for VTS specifically for variance rewards, showing if it matches or improves upon the O(log n) bound of UCB-VV.

- **Open Question 2:** Can order-optimal algorithms be developed for the fixed-confidence setting of best arm identification (BAI) for variance?
  - **Basis in paper:** The paper addresses the fixed-budget setting (SHVV) in Section III, deriving error probability bounds. It does not address the dual problem where the confidence level δ is fixed, and the goal is to minimize the expected number of samples.
  - **Why unresolved:** The theoretical tools and stopping rules for fixed-confidence (e.g., track-and-stop or successive rejects) differ significantly from the fixed-budget successive halving method (SHVV) analyzed in the paper.
  - **What evidence would resolve it:** A proposed algorithm with a proof of sample complexity upper bound that matches an information-theoretic lower bound for the fixed-confidence variance identification problem.

## Limitations

- The theoretical guarantees assume independent arms and stationary reward distributions, limiting applicability to dynamic or correlated environments.
- The extension to sub-Gaussian rewards, while novel, relies on Bernstein concentration inequalities whose tightness for high-dimensional variance estimation remains empirically unverified.
- The paper acknowledges VTS outperforms UCB-VV in practice but lacks theoretical analysis, suggesting the gap between theory and empirical performance persists.

## Confidence

- **Confidence in core regret minimization claims:** High (given the explicit matching upper and lower bounds)
- **Confidence in BAI guarantees:** Medium (the exponential error probability bound is proven but constants and practical behavior for non-power-of-2 arms require validation)
- **Confidence in sub-Gaussian extension:** Medium (the concentration results are derived but not extensively tested beyond synthetic examples)

## Next Checks

1. **Bounded Regret Validation:** Implement UCB-VV on a 2-armed Bernoulli bandit with δ = 0.1 and δ = 0.5 (replicating Fig 1) to verify logarithmic regret scaling with 1000 Monte Carlo runs.
2. **BAI Scaling Stress Test:** Run SHVV with fixed budget n=2000 while increasing arms K ∈ {16, 32, 64} (replicating Fig 2) to observe error probability growth and compare empirical error rates against the theoretical e_n ≤ exp(-n/log K H).
3. **Sub-Gaussian Variance Concentration:** Generate synthetic sub-Gaussian rewards and empirically measure tail probabilities of the sample variance deviations to validate the bounds described in Theorem 5.