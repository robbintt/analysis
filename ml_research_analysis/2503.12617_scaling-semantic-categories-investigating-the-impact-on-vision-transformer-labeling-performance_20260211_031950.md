---
ver: rpa2
title: 'Scaling Semantic Categories: Investigating the Impact on Vision Transformer
  Labeling Performance'
arxiv_id: '2503.12617'
source_url: https://arxiv.org/abs/2503.12617
tags:
- accuracy
- categories
- datasets
- semantic
- classification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates how scaling semantic categories affects
  the accuracy of vision transformers (ViTs) in image classification. The research
  introduces semantically equivalent categories alongside ground truth labels and
  measures classification accuracy using Jina AI's CLIP server across diverse datasets.
---

# Scaling Semantic Categories: Investigating the Impact on Vision Transformer Labeling Performance

## Quick Facts
- arXiv ID: 2503.12617
- Source URL: https://arxiv.org/abs/2503.12617
- Authors: Anthony Lamelas; Harrison Muchnic
- Reference count: 2
- Primary result: Semantic category scaling improves ViT accuracy by 2.3% on complex datasets, but gains plateau after ~10 additional categories

## Executive Summary
This study investigates how expanding semantic categories affects vision transformer performance in image classification. Using Jina AI's CLIP server, researchers added semantically equivalent label variants to ground truth categories and measured accuracy changes across diverse datasets. The results demonstrate that initial additions of semantic categories significantly improve classification accuracy, with diminishing returns beyond a critical threshold of approximately 10 new categories. Datasets with richer initial taxonomies (>10 categories) showed greater improvements than simpler datasets, though the mechanism behind this differential effect remains unexplained.

## Method Summary
The research employed a zero-shot classification approach using Jina AI's CLIP server, which compares image embeddings to text label embeddings. Researchers ran baseline classifications on datasets with original categories, then incrementally added semantic variants (singular/plural, size modifiers, broader categories) using a custom Python accuracy function that accepts dictionaries mapping ground truth to semantic equivalents. Classification accuracy was measured after each category addition until performance plateaued, declined, or fluctuated, typically around the 10th new category.

## Key Results
- Initial semantic category additions improved accuracy by 2.3% on datasets with >10 initial categories
- Accuracy gains plateaued or reversed after approximately 10 additional categories
- Datasets with <10 initial categories showed minimal improvement (1% average) or accuracy decreases
- The phenomenon was observed across diverse datasets but mechanism remains unexplained

## Why This Works (Mechanism)

### Mechanism 1: Semantic Redundancy Expands Classification Surface
Adding semantically equivalent categories increases the probability that model predictions match at least one valid label variant. CLIP-style ViTs embed both images and text labels into a shared embedding space, so when multiple semantically equivalent labels are provided, the image embedding has more opportunities to align closely with at least one of the label embeddings.

### Mechanism 2: Attention Dilution at Critical Threshold
Beyond approximately 10 additional categories, accuracy gains plateau or reverse due to label space fragmentation. As candidate labels multiply, the model must evaluate more text embeddings against each image, potentially introducing noise or splitting similarity scores across semantically adjacent concepts.

### Mechanism 3: Initial Category Density Modulates Scaling Effectiveness
Datasets with richer initial taxonomies (>10 categories) benefit more from semantic scaling than simpler datasets (<10 categories). Datasets with more initial classes may have finer-grained distinctions that benefit from expanded semantic coverage.

## Foundational Learning

- **CLIP-style Zero-Shot Classification**:
  - Why needed here: The study uses Jina AI's CLIP server, which classifies by comparing image embeddings to text label embeddings rather than using a fixed classifier head.
  - Quick check question: Can you explain how a CLIP model determines which text label best matches a given image?

- **Semantic Equivalence in Label Spaces**:
  - Why needed here: The core intervention relies on creating category variants that the model should treat as interchangeable with ground truth.
  - Quick check question: Given the category "flower," which of these are valid semantic equivalents for this experiment: "flowers," "blooming plant," "flora," "Large flower"?

- **Accuracy Measurement with Redundant Labels**:
  - Why needed here: Standard accuracy metrics assume one-to-one label matching; this study requires many-to-one matching where any semantic variant counts as correct.
  - Quick check question: How would you modify a classification accuracy function to accept a list of valid synonyms per ground truth class?

## Architecture Onboarding

- **Component map**: Image dataset -> CLIP server (Jina AI) -> Text embeddings (label variants) -> Similarity comparison -> Prediction output -> Accuracy evaluation function -> Semantic category generator

- **Critical path**: 1) Acquire dataset with ground truth encoded in file paths, 2) Extract base category list and run baseline classification, 3) Generate semantic variants using templates; update equivalence dictionary, 4) Re-run classification and compute accuracy against expanded label set, 5) Repeat until accuracy plateaus, declines, or fluctuates

- **Design tradeoffs**: Human-generated categories: Controlled but potentially biased; automation would scale but risks semantic drift; Template-based variants (singular/plural/size modifiers): Consistent across datasets but may not fit all semantic domains; Exponential category addition: Efficient for finding thresholds but may skip optimal intermediate points

- **Failure signatures**: Accuracy drops on first iteration: Semantic variants may not match model's learned representations; No improvement despite multiple iterations: Dataset may lack semantic ambiguity, or variants diverge from ground truth; High fluctuation between iterations: Category quality inconsistency or model sensitivity to specific label phrasings

- **First 3 experiments**: 1) Establish baseline: Run CLIP on dataset with original categories only; record accuracy, 2) Singular/plural expansion: Add "Cs" variant to all categories; measure delta, 3) Modifier expansion: Add size variants (Large C, Small C, Medium C); compare accuracy change to iteration 2

## Open Questions the Paper Calls Out

### Open Question 1
Does the semantic scaling phenomenon apply to non-transformer architectures like Convolutional Neural Networks (CNNs) or hybrid models? The study exclusively tested Vision Transformers, leaving the effects on other architectural inductive biases unknown.

### Open Question 2
What is the underlying mathematical theory that explains the accuracy plateau observed after the addition of approximately ten semantic categories? The research empirically observes the plateau but does not provide a formal theoretical framework explaining why performance degrades or stagnates specifically at that threshold.

### Open Question 3
Can an automated system effectively determine the optimal number of redundant categories to maximize accuracy without manual intervention? The current methodology relied on manual category generation and researcher intervention to identify stopping points, which is subject to human bias and computational inefficiency.

## Limitations
- Dataset composition: Only partial dataset names provided (Flowers10, Card4, Veg7), limiting reproducibility and generalizability
- Category generation methodology: Human-created variants introduce potential bias; template approach may not capture true semantic equivalence across all domains
- Threshold mechanism: The critical point around the 10th category is empirically observed but not mechanistically explained; could be dataset or model specific

## Confidence
- High confidence: Initial accuracy improvements from semantic scaling (2.3% average for datasets >10 categories) - directly supported by experimental results and clear measurement methodology
- Medium confidence: Diminishing returns beyond 10 categories - observed trend but mechanism not fully explained; could be dataset or model specific
- Low confidence: Category density hypothesis (rich initial taxonomies benefit more) - correlation observed but causal mechanism unproven; could reflect other dataset properties

## Next Checks
1. Cross-model validation: Test the same semantic scaling approach on different CLIP implementations (OpenAI, OpenCLIP) to verify if the 10-category threshold is CLIP-general or Jina-specific
2. Automated category generation: Replace human-generated variants with embeddings-based semantic expansion (using word vectors or sentence transformers) to eliminate human bias and scale testing
3. Controlled ablation study: Test semantic variants individually rather than in batches to identify which category types (singular/plural, size modifiers, etc.) drive the accuracy improvements