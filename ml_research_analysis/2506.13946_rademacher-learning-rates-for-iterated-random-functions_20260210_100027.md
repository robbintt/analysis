---
ver: rpa2
title: Rademacher learning rates for iterated random functions
arxiv_id: '2506.13946'
source_url: https://arxiv.org/abs/2506.13946
tags:
- learning
- random
- function
- rademacher
- iterated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies supervised machine learning when training data
  are generated by an iterated random function (a time-homogeneous Markov chain) rather
  than i.i.d. observations.
---

# Rademacher learning rates for iterated random functions

## Quick Facts
- arXiv ID: 2506.13946
- Source URL: https://arxiv.org/abs/2506.13946
- Reference count: 39
- One-line primary result: Establishes exponential learning rates for approximate empirical risk minimization on data generated by contractive iterated random functions, with bounds expressed in terms of Rademacher complexities and Wasserstein distances to the invariant measure.

## Executive Summary
This paper studies supervised machine learning when training data are generated by an iterated random function (a time-homogeneous Markov chain) rather than i.i.d. observations. Under contractivity and Lipschitz conditions on the generating function and loss, it establishes uniform convergence and learnability of the approximate empirical risk minimization algorithm with data-dependent sample complexity. Both bounds are expressed in terms of Rademacher complexities, making them sensitive to the data distribution. The rates are exponential in sample size and involve the Wasserstein distance to the invariant measure. Examples include iterated function systems for image generation. The approach generalizes prior results requiring irreducibility or aperiodicity, and relates Rademacher complexity to growth and shattering dimensions in specific cases.

## Method Summary
The paper derives learning rates for approximate empirical risk minimization when training data comes from an iterated random function (Markov chain) rather than i.i.d. samples. The key assumptions are that the data-generating function is contractive on average (expected Lipschitz constant < 1) and that the loss function and hypothesis class are uniformly bounded and Lipschitz. The method uses martingale concentration inequalities and symmetrization techniques to establish uniform convergence results, with bounds expressed in terms of Rademacher complexities relative to the invariant measure and Wasserstein distances measuring convergence to this invariant distribution.

## Key Results
- Establishes exponential learning rates for approximate empirical risk minimization on dependent data generated by iterated random functions
- Provides data-dependent sample complexity bounds using Rademacher complexities rather than worst-case distributions
- Generalizes prior results by relaxing irreducibility and aperiodicity requirements to contractivity conditions
- Demonstrates applications including iterated function systems for image generation

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** If the data-generating function is contractive on average, the Markov chain of data points converges exponentially to a unique invariant probability distribution.
- **Mechanism:** Assumption (A1) posits that the generating function $F(z, \theta)$ is contractive in its first argument with expected Lipschitz constant $\ell_F < 1$. This contractivity extends to the space of probability measures equipped with the Wasserstein distance $\mathcal{W}$. By the Banach fixed point theorem, repeated application of the transition operator reduces the distance between the current distribution $\mu \mathcal{P}^n$ and the invariant measure $\pi$ by a factor of $\ell_F^n$.
- **Core assumption:** The expected Lipschitz constant $\ell_F := E[\ell(\vartheta_1)]$ is strictly less than 1.
- **Evidence anchors:**
  - [Page 3] "Since $\ell_F < 1$, the mapping $\mu \mapsto \mu \mathcal{P}$ is a contraction... there exists a unique $\pi$."
  - [Page 4] "Rates are exponential in sample size and involve the Wasserstein distance..."
  - [Corpus] Corpus provides general context on concentration inequalities but lacks specific validation for this specific contraction-based Markov mechanism.
- **Break condition:** If the underlying system dynamics change such that $\ell_F \ge 1$ (e.g., chaotic dynamics or divergent state space), the convergence to a unique $\pi$ is not guaranteed by this theorem, and the Wasserstein distance term may fail to decay.

### Mechanism 2
- **Claim:** The generalization error of the approximate empirical risk minimization ($\epsilon$-ERM) algorithm can be bounded using a Hoeffding-type inequality adapted for dependent data.
- **Mechanism:** The proof constructs a martingale difference sequence using conditional expectations of the supremum of the empirical process. Because the loss is bounded and Lipschitz (A2), the variance of the martingale differences can be controlled. The dependent nature of the chain is managed by the contractivity property, which limits how much a single data point can influence future states, allowing the derivation of a concentration bound similar to the i.i.d. case but with a variance factor scaled by $(1 - \ell_F)$.
- **Core assumption:** The loss function $\mathcal{L}$ and hypothesis class $\mathcal{H}$ satisfy the uniform Lipschitz and boundedness conditions of (A2).
- **Evidence anchors:**
  - [Page 4] "Applying a Hoeffding's-type inequality, we first establish a uniform convergence result..."
  - [Page 10] "...bounded by $\ell_{\mathcal{H}} / (1 - \ell_F) / n$."
  - [Corpus] Paper "Concentration Inequalities for Stochastic Optimization..." (arXiv:2502.08628) discusses similar concentration needs for unbounded objectives, supporting the relevance of this mechanism.
- **Break condition:** If the loss function is unbounded or non-Lipschitz (e.g., squared error without bounded inputs), the variance terms in the exponential bound become unmanageable, and the specific rate derived here fails.

### Mechanism 3
- **Claim:** The sample complexity is data-dependent and scales with the Rademacher complexity of the hypothesis class relative to the invariant measure.
- **Mechanism:** The paper relates the expected suprema of the sample error to the Rademacher complexity $\mathfrak{R}_{n,\pi}(\mathcal{H})$ (Lemma 4.2). This connects the uniform convergence rate to the "richness" of the hypothesis class as measured against the target distribution $\pi$, rather than a worst-case distribution-independent bound. This allows for tighter bounds when the data distribution is simple, even if the hypothesis class is complex.
- **Core assumption:** The training data $Z_n$ is drawn from an iterated random function, and the Rademacher complexity is defined with respect to the invariant measure $\pi$.
- **Evidence anchors:**
  - [Page 5, Theorem 2.1] "Both rates are data-distribution dependent, expressed in terms of the Rademacher complexities..."
  - [Page 11, Lemma 4.2] "Inequality holds: $E_\mu[\phi] \le 2\mathfrak{R}_{n,\pi}(\mathcal{H}) + \ell_\mathcal{H}\mathcal{W}(\mu\mathcal{P}^n, \pi)$."
  - [Corpus] "Do we really need the Rademacher complexities?" (arXiv:2502.15118) explores the necessity of this specific complexity measure in learning bounds.
- **Break condition:** If the hypothesis class is extremely complex (e.g., Rademacher complexity does not decay to 0 as $n \to \infty$), the uniform convergence fails, and learnability is not guaranteed by this result.

## Foundational Learning

- **Concept: Iterated Random Functions (Markov Chains)**
  - **Why needed here:** This is the data generation model. Unlike standard i.i.d. assumptions, this model assumes temporal dependence where the next state depends on the current state via a random function.
  - **Quick check question:** Can you explain why a contractive iterated function guarantees a unique "steady state" (invariant measure) for the data, whereas a general random walk might not?

- **Concept: Wasserstein Distance**
  - **Why needed here:** This metric measures the "distance" between probability distributions. It is used here to quantify how fast the initial data distribution converges to the invariant distribution, which directly dictates the learning rate.
  - **Quick check question:** If $\mathcal{W}(\mu, \pi)$ is large, does the paper predict needing more or fewer samples to achieve the same error bound? (Answer: More, because the term $\mathcal{W}(\mu\mathcal{P}^n, \pi)$ decays with $n$).

- **Concept: Rademacher Complexity**
  - **Why needed here:** This measures the capacity of the hypothesis class to fit random noise. It serves as the primary term in the bound to control the "generalization gap."
  - **Quick check question:** How does the Rademacher complexity in this paper differ from the standard i.i.d. definition? (Hint: It is defined with respect to the invariant measure $\pi$ and involves dependent sampling).

## Architecture Onboarding

- **Component map:** Iterated Random Function simulator ($F, \vartheta, Z_0$) -> Approximate Empirical Risk Minimizer ($\epsilon$-ERM) -> Estimators for Lipschitz constants ($\ell_F, \ell_\mathcal{H}$) and Rademacher complexity

- **Critical path:** Validating Assumption (A1).
    The entire theoretical guarantee collapses if the system is not contractive ($\ell_F \ge 1$). You must first estimate the Lipschitz constant of the data dynamics before trusting the learning rates.

- **Design tradeoffs:**
  - **Contractivity vs. Realism:** The contractive assumption (A1) simplifies the math (guaranteeing exponential rates) but may exclude non-convergent or chaotic time-series often found in finance or turbulent physics.
  - **Lipschitz Loss vs. Accuracy:** Restricting the loss/hypothesis class to be Lipschitz (A2) ensures bounded variance but may prevent using unbounded loss functions (like standard MSE on unbounded domains) or "sharp" non-Lipschitz decision boundaries.

- **Failure signatures:**
  - **Non-convergence:** If the error rates plateau or degrade as sample size increases, check if the underlying process is drifting (violating the fixed-point assumption) or if $\ell_F$ is close to 1 (requiring massive $n$ to kill the Wasserstein term).
  - **Invalid Bounds:** If using non-Lipschitz activations (e.g., step functions) or losses, the probability bounds $1 - 2e^{-...}$ are mathematically void.

- **First 3 experiments:**
  1. **Synthetic Validation:** Implement a simple Linear Auto-Regressive (AR) process with known noise (e.g., $Z_{n+1} = 0.5 Z_n + \epsilon$). Verify that the empirical error tracks the theoretical bound $4\mathfrak{R} + 2\ell \ell^n \mathcal{W}$.
  2. **Sensitivity Analysis:** Systematically increase the spectral norm of the transition matrix in the synthetic data to approach $\ell_F = 1$. Plot the sample complexity required to maintain a fixed $\epsilon$ error to verify the exponential sensitivity.
  3. **Image Generation Test:** Apply the setup to an Iterated Function System (IFS) for image generation (Example 2.2). Compare the convergence rate when initializing the chain from a "far" distribution $\mu$ vs. starting near the invariant measure $\pi$.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the Rademacher learning rates be extended to time-inhomogeneous iterated random functions where the governing function F_n varies with time?
- Basis in paper: [explicit] The paper states that [1] extended concentration inequalities for iterated random functions "to a class of time-inhomogeneous iterated random functions" by replacing F(z,Î¸) with a sequence {F_n(z,Î¸)} satisfying the same conditions.
- Why unresolved: The current analysis relies on the time-homogeneous structure for the Wasserstein contraction argument and Rademacher complexity bounds.
- What evidence would resolve it: A theorem showing learning rates for F_n(z,Î¸) sequences with appropriate time-varying contractivity conditions, or a counterexample showing where the approach fails.

### Open Question 2
- Question: Can the contractivity assumption (A1) with â„“_F < 1 be relaxed to settings where the Markov chain exhibits ergodic convergence through mechanisms other than contraction?
- Basis in paper: [inferred] The paper explicitly contrasts its approach with prior work requiring irreducibility and aperiodicity, noting that some scenarios may not satisfy these or contractivity. Example 2.4 shows non-irreducible, non-aperiodic chains still work under contractivity, but the space between these conditions remains unexplored.
- Why unresolved: The proof fundamentally relies on the Banach fixed point theorem and Wasserstein contraction to establish the invariant measure and learning rates.
- What evidence would resolve it: Learning rate bounds established under alternative ergodicity conditions (e.g., Harris recurrence, geometric ergodicity without contraction) for the iterated random function setting.

### Open Question 3
- Question: Are the exponential learning rates in Theorem 2.1 minimax optimal, or can tighter lower bounds be established that reveal dependence on the Wasserstein distance term?
- Basis in paper: [inferred] The paper states "the learning rate obtained in Theorem 2.1 is exponential" and notes "a similar rate (with different constants) has also been established" in prior work, but provides no lower bound analysis or optimality discussion.
- Why unresolved: Upper bounds alone cannot establish whether the 4â„›_{n,Ï€}(â„‹) + 2â„“_â„‹â„“_F^nð’²(Î¼,Ï€) structure and constants are necessary.
- What evidence would resolve it: Matching lower bounds showing the dependence on both Rademacher complexity and Wasserstein distance terms is unavoidable, or improved upper bounds with smaller constants.

### Open Question 4
- Question: Can the Lipschitz assumption on the loss function (A2) be relaxed to accommodate non-Lipschitz losses common in practice (e.g., hinge loss, unbounded regression losses)?
- Basis in paper: [inferred] Assumption (A2) requires bounded Lipschitz losses. The paper notes this excludes some scenarios but does not address alternatives.
- Why unresolved: The boundedness and Lipschitz properties are used directly in the martingale concentration arguments (Lemmas 4.1-4.4) and the Rademacher complexity bounds.
- What evidence would resolve it: Modified learning rate bounds under weaker moment or tail conditions on the loss, potentially with slower rates.

## Limitations
- The contractivity assumption (A1) may not hold for many real-world time-series processes that exhibit non-convergent or chaotic behavior
- The bounds are sensitive to the accuracy of estimating Lipschitz constants and Rademacher complexities, which can be challenging in high-dimensional settings
- The learning rates are expressed in terms of the invariant measure Ï€, which may be difficult to compute or approximate for complex data-generating processes

## Confidence

- **High Confidence:** The core mechanism that contractivity leads to exponential convergence to a unique invariant measure is mathematically sound and well-established in the theory of iterated random functions.
- **Medium Confidence:** The application of Hoeffding-type concentration inequalities to dependent data is valid under the stated conditions, but the specific constants and rates may be conservative in practice.
- **Medium Confidence:** The connection between Rademacher complexity and generalization for dependent data is theoretically justified, but the practical computation of these complexities for complex hypothesis classes remains an open challenge.

## Next Checks

1. **Empirical Verification of Contractivity:** Implement the Linear AR(1) example (e.g., $Z_{n+1} = 0.5 Z_n + \epsilon$) and empirically measure the decay of $\mathcal{W}(\mu\mathcal{P}^n, \pi)$ to verify the exponential rate predicted by the theory.
2. **Robustness to Non-Contractive Dynamics:** Modify the AR(1) example to have a coefficient close to 1 (e.g., 0.99) and observe if the learning rates degrade as predicted when $\ell_F \to 1$, or if the theoretical bounds fail to capture the behavior.
3. **Complexity Computation for a Simple Class:** For the IFS image generation example (Example 2.2), attempt to compute or estimate the Rademacher complexity $\mathfrak{R}_{n,\pi}(\mathcal{H})$ for a simple hypothesis class (e.g., linear predictors) and verify that it decays with $n$ as required for the theory to yield meaningful bounds.