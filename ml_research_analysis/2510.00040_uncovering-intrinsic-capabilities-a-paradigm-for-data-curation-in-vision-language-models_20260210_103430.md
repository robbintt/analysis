---
ver: rpa2
title: 'Uncovering Intrinsic Capabilities: A Paradigm for Data Curation in Vision-Language
  Models'
arxiv_id: '2510.00040'
source_url: https://arxiv.org/abs/2510.00040
tags:
- data
- capabilities
- training
- recognition
- cadc
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Capability-Attributed Data Curation (CADC),
  a novel paradigm for instruction data curation in vision-language models. Instead
  of relying on heuristic task-based selection, CADC discovers intrinsic capabilities
  directly from gradient-based learning dynamics, attributes training data to these
  capabilities via influence estimation, and curates balanced subsets through capability-aware
  allocation and curriculum sequencing.
---

# Uncovering Intrinsic Capabilities: A Paradigm for Data Curation in Vision-Language Models

## Quick Facts
- **arXiv ID:** 2510.00040
- **Source URL:** https://arxiv.org/abs/2510.00040
- **Reference count:** 40
- **Primary result:** Achieves full-data performance using only 5% of training data across diverse multimodal benchmarks.

## Executive Summary
This paper introduces Capability-Attributed Data Curation (CADC), a novel paradigm for instruction data curation in vision-language models. Instead of relying on heuristic task-based selection, CADC discovers intrinsic capabilities directly from gradient-based learning dynamics, attributes training data to these capabilities via influence estimation, and curates balanced subsets through capability-aware allocation and curriculum sequencing. With as little as 5% of the original data, CADC surpasses full-data training across diverse multimodal benchmarks, including LLaVA-Wild, POPE, and MMT-Bench. The results validate intrinsic capabilities as the fundamental building blocks of model learning and establish CADC as a highly efficient and interpretable framework for instruction tuning.

## Method Summary
CADC operates in three phases: (1) discovers intrinsic capabilities by clustering AdamW gradient trajectories of validation samples via Leiden community detection; (2) attributes training samples to discovered capabilities using trajectory influence with soft assignment; (3) curates dataset by allocating budget proportional to self-influence and sequencing training via curriculum based on difficulty. The method uses LoRA-projected gradients with random projection for memory efficiency and demonstrates effectiveness across model scales from 256M to 7B parameters.

## Key Results
- Achieves 5% data performance matching or exceeding full-data training on multiple benchmarks
- Demonstrates that intrinsic capabilities (gradient-trajectory clusters) diverge from human-defined task labels
- Shows successful cross-scale transfer where data curated for small models benefits large models
- Validates curriculum sequencing based on self-influence as superior to random ordering

## Why This Works (Mechanism)

### Mechanism 1: Gradient Trajectory Clustering
Human-defined task labels misalign with how VLMs internally organize skills; clustering gradient trajectories reveals true "intrinsic capabilities." The method computes AdamW update trajectories for validation subtasks and uses community detection (Leiden) to group similar trajectories into capability clusters, bypassing semantic task labels. The geometry of optimizer update directions serves as a proxy for latent skills required to process samples.

### Mechanism 2: Influence-Based Data Attribution
Training samples can be attributed to specific latent capabilities by measuring alignment between their gradients and capability representative trajectories. For each training sample, the method calculates trajectory influence measuring how well sample updates align with aggregate updates of each capability, allowing soft assignment across multiple capabilities.

### Mechanism 3: Curriculum Sequencing by Difficulty
Sequencing data according to a capability's "self-influence" (difficulty) creates curriculum stabilizing learning and preventing interference. Capabilities with high early self-influence (indicating struggle) are prioritized, with staged training focusing on one capability while retaining previous data to mitigate forgetting.

## Foundational Learning

- **Gradient Trajectories:** Understanding that trajectory captures learning dynamics evolution over time, not just instantaneous loss. Quick check: Explain why averaging gradients over multiple checkpoints provides more information about a task than a single gradient step.

- **Influence Functions:** Grasping that influence is estimated via tractable gradient alignment rather than inverse Hessian methods. Quick check: If Sample A has negative trajectory influence on Capability B, what does that imply about training on Sample A?

- **Community Detection (Graph Clustering):** Understanding that Leiden algorithm discovers "intrinsic capabilities" without pre-defined labels. Quick check: Why is modularity-based clustering (Leiden) preferred over K-Means for identifying capabilities in this context?

## Architecture Onboarding

- **Component map:** Target Analyzer -> Capability Engine -> Attribution Module -> Curriculum Scheduler
- **Critical path:** The projection of high-dimensional gradients to lower-dimensional space via LoRA + Random Projection is most fragile step; if projection destroys directional signal, subsequent clustering and attribution fail.
- **Design tradeoffs:** Hard vs. soft assignment (tolerance δ allows versatile samples to support multiple capabilities); compute vs. granularity (number of snapshots determines temporal resolution).
- **Failure signatures:** Uniform Clustering (clusters exactly match meta-tasks, indicating failure to uncover latent structure); Forgetting Spikes (staged training causes performance drops, indicating replay fraction too low).
- **First 3 experiments:** 1) Hyperparameter Sensitivity (vary τ and δ); 2) Projection Validity (compare full gradients vs. LoRA+Random Projection); 3) Order Ablation (test reverse curriculum explicitly).

## Open Questions the Paper Calls Out

### Open Question 1
Does the number and structure of discovered intrinsic capabilities shift significantly when scaling model size, or are they invariant properties of the model architecture? The paper demonstrates cross-scale transfer but doesn't verify if larger models exhibit more granular capability sets than smaller models.

### Open Question 2
To what extent does the composition of the validation dataset bias the discovery of intrinsic capabilities? The framework relies on validation data to define intrinsic structure, creating circular dependency where discovered capabilities are limited by benchmark breadth.

### Open Question 3
Can the trajectory-based influence estimation be scaled to full-parameter fine-tuning without LoRA-based gradient projections? The paper explicitly uses LoRA parameters and random projection for memory efficiency, but it's unclear if intrinsic capabilities correlate perfectly with full-model weight dynamics.

## Limitations

- **Gradient trajectory fidelity:** LoRA-projected gradients via random projection may collapse distinct task dynamics into similar vectors, potentially failing the entire intrinsic capability discovery mechanism.
- **Curriculum ordering robustness:** The sequencing rule shows strong results but lacks testing of robustness to different ordering strategies or explanation of why exactly three capabilities emerge.
- **Data attribution noise:** Influence-based attribution lacks reporting on how many samples get assigned to multiple capabilities or sensitivity to tolerance parameter δ.

## Confidence

- **High confidence:** Core observation that intrinsic capabilities (gradient-trajectory clusters) differ from human-defined task labels is well-supported by divergence shown and strong 5% data results.
- **Medium confidence:** Influence-based data attribution and curriculum sequencing mechanisms are plausible but lack ablations on key hyperparameters confirming their necessity.
- **Low confidence:** Generalizability of K=3 capability structure and exact sequencing rule to other datasets or VLM architectures is unproven.

## Next Checks

1. **Projection sensitivity test:** Run capability clustering with varying random projection dimensions (m=16, 32, 64) and compare cluster purity vs. baseline full-gradient clustering.

2. **Curriculum robustness ablation:** Explicitly test reversed sequencing (c₃ ≺ c₂ ≺ c₁) and random orderings on same 5% data budget to confirm reported performance gaps.

3. **Attribution variance analysis:** Report distribution of samples assigned to 1, 2, or 3 capabilities under δ=0.01, and rerun with δ=0.001 and δ=0.05 to assess stability of data pools.