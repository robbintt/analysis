---
ver: rpa2
title: 'AdvGrasp: Adversarial Attacks on Robotic Grasping from a Physical Perspective'
arxiv_id: '2507.09857'
source_url: https://arxiv.org/abs/2507.09857
tags:
- grasp
- adversarial
- grasping
- attacks
- robotic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses adversarial attacks on robotic grasping systems
  from a physical perspective. The authors propose AdvGrasp, a framework that targets
  two core aspects of grasp performance: lift capability (ability to overcome gravity)
  and grasp stability (resistance to external disturbances).'
---

# AdvGrasp: Adversarial Attacks on Robotic Grasping from a Physical Perspective

## Quick Facts
- arXiv ID: 2507.09857
- Source URL: https://arxiv.org/abs/2507.09857
- Reference count: 10
- Primary result: Physical-aware adversarial attacks on robotic grasping by deforming object geometry to increase gravitational torque and reduce stability margin in wrench space

## Executive Summary
This paper introduces AdvGrasp, a framework for generating adversarial attacks on robotic grasping systems by physically deforming object geometry. Unlike previous attacks that target neural network predictions, AdvGrasp manipulates the physical properties of objects to degrade grasp performance by increasing gravitational torque and reducing stability margins in wrench space. The method uses a cage-based deformation approach optimized through simulated annealing to create adversarial meshes that systematically reduce grasp lift capability and stability. The authors establish AdvGrasp-20, a benchmark with 20 objects and diverse grasp configurations, and validate their approach through both simulation and real-world experiments with 3D-printed objects.

## Method Summary
AdvGrasp generates adversarial 3D objects by deforming mesh geometry to degrade robotic grasping performance through two physical mechanisms: increasing gravitational torque (lift capability) and reducing stability margin in wrench space (grasp stability). The framework takes a 3D mesh and grasp configuration as input, applies cage-based deformation using control points on a bounding grid, and optimizes the deformation through simulated annealing to minimize a composite objective function. The objective combines lift capability metrics based on gravitational torque, grasp stability metrics derived from wrench space calculations, and Laplacian regularization for shape smoothness. The method is evaluated using three metrics: minimal grasp force (MinGF), maximal lifting mass (MaxLM), and maximal external disturbance (MaxED), with grasp failure defined as displacement >0.02m or rotation >10°.

## Key Results
- AdvGrasp effectively increases the minimal grasp force required to lift a 1kg object from baseline levels
- The method decreases maximal lifting mass that can be successfully grasped by targeted objects
- Generated adversarial objects reduce resistance to external disturbances, causing grasps to fail at lower force thresholds
- Real-world validation with 3D-printed objects confirms simulation results, though with some performance gap requiring parameter calibration

## Why This Works (Mechanism)
The attack exploits the fundamental physics of grasping by manipulating the equilibrium between applied grasp forces and external torques. By deforming object geometry, AdvGrasp increases the gravitational torque that must be overcome while simultaneously reducing the wrench space margin that determines how much additional force can be applied before slippage occurs. The cage-based deformation allows precise control over how the object's shape changes in regions critical to the specific grasp configuration, while the simulated annealing optimization explores the non-convex deformation space to find perturbations that maximally degrade performance. The soft finger contact model ensures that generated deformations remain physically plausible within the constraints of friction and contact mechanics.

## Foundational Learning
- **Wrench and Grasp Wrench Space** - Why needed: Core attack mechanism relies on manipulating wrench equilibrium and stability margin calculations. Quick check: If you apply a force at a point not on the object's center of mass, does it create a non-zero torque component in the resulting wrench?
- **Soft Finger Contact Model** - Why needed: Simulation uses this model with torsional friction constraints that limit wrenches a gripper can apply. Quick check: According to the soft finger model, can a contact point resist a torque around the contact normal, and what limits this resistance?
- **Simulated Annealing Optimization** - Why needed: Adversarial objects generated via probabilistic optimization technique to find global minimum of non-convex objective. Quick check: What is the primary advantage of simulated annealing over gradient descent for this non-convex problem?

## Architecture Onboarding
- **Component map:** 3D Mesh (O) + Grasp Configuration (GSP) → Cage-based Deformation Grid → Objective Function (LC + GS + Lap) → Simulated Annealing Optimizer → Adversarial Mesh (O')
- **Critical path:** Physical simulation accuracy (wrench calculation) directly determines adversarial object effectiveness; simulator-friction mismatch causes real-world failure
- **Design tradeoffs:** Attack strength vs. imperceptibility (λ₂ tuning); target specificity (configuration-dependent attacks); simulation vs. reality gap
- **Failure signatures:** Grasp failure (displacement >0.02m or rotation >10°); attack ineffectiveness (no performance degradation); unrealistic geometry (spikes/self-intersections)
- **First 3 experiments:** 1) Reproduce baseline metrics on original AdvGrasp-20 objects; 2) Run single-objective attack using only LC to isolate MaxLM effects; 3) 3D print adversarial object and compare real vs. simulated failure modes to calibrate friction coefficients

## Open Questions the Paper Calls Out
- **Open Question 1:** How can adversarial attacks be extended to dynamic manipulation scenarios with moving objects or executing trajectories? The paper explicitly identifies this as future work, noting current quasi-static assumptions don't address inertial forces or time-varying contact conditions.
- **Open Question 2:** What defense mechanisms can detect or mitigate physical-aware adversarial perturbations without sacrificing grasp performance? The paper calls out defense design as a key future direction, noting the unique challenges of defending against actual geometric deformations.
- **Open Question 3:** Can attacks succeed when the attacker has no knowledge of the specific grasp configuration that will be used? This is inferred from the paper's assumption of known grasp configurations during optimization.

## Limitations
- Attack effectiveness heavily depends on accurate physical simulation parameters, particularly friction coefficients that were calibrated from limited real-world tests
- Performance gap between simulation and real-world validation suggests parameters may not generalize across different materials and environmental conditions
- Attacks target specific grasp configurations rather than grasping systems holistically, limiting effectiveness against different grasp strategies

## Confidence
- **High Confidence:** Core mechanism of deforming objects to increase gravitational torque and reduce wrench space stability margin is physically sound and experimentally validated
- **Medium Confidence:** Quantitative improvements in metrics (MinGF, MaxLM, MaxED) are reproducible within PyBullet simulation with specified parameters
- **Low Confidence:** Real-world transferability beyond tested Robotiq grippers and specific 3D-printed objects, particularly across different gripper designs and material properties

## Next Checks
1. **Parameter Sensitivity Analysis:** Systematically vary friction coefficients (μ, γ) across plausible ranges to quantify how simulation accuracy affects attack success rates and identify sensitivity to these parameters
2. **Cross-Gripper Generalization:** Test adversarial objects generated for Robotiq 2F-85 against Robotiq 3-finger gripper (and vice versa) to measure grasp-specificity and universal attack potential
3. **Material Property Impact:** 3D print identical adversarial geometries using different materials (PLA, ABS, TPU) and measure variance in attack effectiveness to establish real-world transferability bounds