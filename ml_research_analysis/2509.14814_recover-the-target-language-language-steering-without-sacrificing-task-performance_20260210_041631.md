---
ver: rpa2
title: 'ReCoVeR the Target Language: Language Steering without Sacrificing Task Performance'
arxiv_id: '2509.14814'
source_url: https://arxiv.org/abs/2509.14814
tags:
- language
- recover
- steering
- vectors
- representations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ReCoVeR is a lightweight approach to reduce language confusion
  in multilingual LLMs by steering hidden representations with language-specific vectors.
  It computes language representations from multi-parallel data and uses them for
  unsupervised or learned steering at inference time.
---

# ReCoVeR the Target Language: Language Steering without Sacrificing Task Performance

## Quick Facts
- **arXiv ID:** 2509.14814
- **Source URL:** https://arxiv.org/abs/2509.14814
- **Reference count:** 16
- **Key outcome:** ReCoVeR reduces language confusion in multilingual LLMs by steering hidden representations with language-specific vectors, retaining or improving task performance across 18 languages.

## Executive Summary
ReCoVeR is a lightweight approach to reduce language confusion in multilingual LLMs by steering hidden representations with language-specific vectors. It computes language representations from multi-parallel data and uses them for unsupervised or learned steering at inference time. Unlike prior methods, it does not rely on a dominant language, supports easy addition of new languages, and retains or improves task performance. Evaluated on three benchmarks across 18 languages, ReCoVeR substantially reduces language confusion in both monolingual and cross-lingual setups without harming answer accuracy.

## Method Summary
ReCoVeR isolates language vectors using a multi-parallel corpus (FLORES-200), then steers model hidden states toward target languages via vector arithmetic. The method computes per-language vectors by averaging hidden states across parallel sentences, derives a content vector to remove semantic information, and uses the difference as a steering vector. During inference, this vector is added to hidden states (with optional norm restoration) to guide generation. A learnable variant (ReCoVeR+) uses a low-rank intervention trained on machine-translated data. The approach works for both monolingual (reply in prompt language) and cross-lingual (reply in specified language â‰  prompt language) settings.

## Key Results
- ReCoVeR significantly reduces language confusion in both monolingual and cross-lingual setups across 18 languages.
- The method maintains or improves task performance (QA accuracy, summarization metrics) compared to baselines.
- Lower Transformer layers (1-2) are most effective for steering interventions.

## Why This Works (Mechanism)

### Mechanism 1: Content-Agnostic Language Isolation
Subtracting a global "content vector" from language-specific averages isolates the linguistic signal while discarding semantic noise. The authors average hidden states across a multi-parallel corpus (FLORES-200) to create a base content vector ($c$). By subtracting this from per-language averages ($v_l$), they derive a steering vector ($r_l$) that theoretically represents "language" independent of the specific text meaning. This assumes semantic content is approximately constant across parallel translations in the averaged representation space, so it cancels out.

### Mechanism 2: Arithmetic Vector Steering
Simple vector addition/subtraction at inference time shifts the model's generation trajectory toward the target language. For cross-lingual tasks, the intervention steers hidden states toward the target language ($r_{target}$) and explicitly away from the source language ($r_{source}$) using normalized vector arithmetic. This redirects the probability mass of the next token prediction. This assumes the direction of the language vector is stable enough to guide generation without fine-tuning.

### Mechanism 3: Norm Restoration for Stability
Preserving the original magnitude of hidden states prevents model collapse during steering. While steering adds a bias, the authors introduce a binary hyperparameter to restore the representation norms ($||\hat{h}^{(i)}|| = ||h^{(i)}||$). This ensures the modified activation remains within the distribution the model expects for subsequent layers. This assumes the *direction* of the vector matters for language, but the *magnitude* must remain stable to avoid disrupting downstream processing.

## Foundational Learning

**Concept: Linear Representation Hypothesis**
Why needed: The entire method relies on the idea that high-level features (like "language") are represented as linear directions in the activation space.
Quick check: If language were represented non-linearly (e.g., as a complex manifold), would simple vector addition still work?

**Concept: Multi-parallel Corpora**
Why needed: Unlike contrastive methods that use positive/negative pairs, ReCoVeR requires the same semantic content in multiple languages to effectively "subtract" meaning.
Quick check: Why is a multi-parallel dataset (like FLORES) more effective here than a monolingual classification dataset?

**Concept: Model Collapse**
Why needed: A primary risk of naive steering is pushing the model so far off its manifold that it outputs gibberish or repeats.
Quick check: What happens to the output token probabilities if the hidden state norm is increased by 10x during steering?

## Architecture Onboarding

**Component map:**
Vector Cache -> Steering Hook -> Arithmetic Logic

**Critical path:**
1. Run forward pass on FLORES-200 to aggregate mean vectors
2. Compute $c$ and $r_l$ offline
3. Register hooks on layers (e.g., Layers 1, 2, and top layers)
4. Inject steering vector during generation

**Design tradeoffs:**
- **Unsupervised vs. Learned:** Unsupervised is zero-shot and lightweight. Learned (ReCoVeR+) requires training data but potentially handles edge cases better.
- **Layer Selection:** Lower layers (1-2) are critical, whereas middle layers are less so.

**Failure signatures:**
- **Repetition loops:** Indicates $\alpha$ is too high or norm restoration failed
- **Language switching:** Indicates steering is applied to wrong layers or insufficient $\alpha$

**First 3 experiments:**
1. **Layer Ablation:** Test steering on Layer 1 only vs. Layer 10 only to verify early steering findings
2. **Alpha Sweep:** Vary the steering strength $\alpha$ on a low-resource language to find the collapse threshold
3. **Content Subtraction Ablation:** Steer using raw $v_l$ (without subtracting content vector $c$) to validate if task performance drops

## Open Questions the Paper Calls Out

### Open Question 1
What is the minimum number of samples required from a multi-parallel corpus to compute effective language representations?
Basis: The authors state they "do not address the question of how many samples are minimally required to obtain meaningful language representations."
Why unresolved: The current implementation uses all available samples in FLORES-200 without ablation studies on data volume.
What evidence would resolve it: An analysis of steering performance (LPR/Accuracy) against varying sizes of the multi-parallel seed data.

### Open Question 2
Can incorporating explicit linguistic information, such as syntactic roles or typological features, improve cross-lingual generalization?
Basis: The Conclusion suggests "Future work could leverage linguistic information to obtain more effective language steering... conditioned by (i) syntactic roles... or (ii) typological features."
Why unresolved: Current vectors are derived purely from aggregate hidden states without explicit linguistic conditioning.
What evidence would resolve it: Experiments comparing current vectors against vectors conditioned on syntactic trees or URIEL typological vectors.

### Open Question 3
To what extent do the computed language representations depend on the specific domain or composition of the multi-parallel dataset used (FLORES-200)?
Basis: The Limitations section notes that "demonstrating that our findings extend to other multi-parallel datasets requires further experiments."
Why unresolved: All experiments rely exclusively on FLORES-200, leaving domain sensitivity untested.
What evidence would resolve it: Evaluation of ReCoVeR using alternative multi-parallel datasets (e.g., WikiMatrix) to compute the steering vectors.

## Limitations
- The exact implementation of norm restoration is vaguely specified, which could impact stability
- The training objective for the learnable steering function (ReCoVeR+) is not fully detailed
- The specific sample counts and splits from FLORES-200 for vector computation are unspecified

## Confidence

**High Confidence:**
- Core language steering mechanism using vector arithmetic
- Evaluation methodology on LCB/MultiQ benchmarks
- General finding that ReCoVeR reduces language confusion without harming task performance

**Medium Confidence:**
- Claim that content vector subtraction meaningfully isolates language from semantics
- Specific layer selection (Layers 1-2 most effective)

**Low Confidence:**
- Claim that ReCoVeR can effectively handle any arbitrary language pair, especially distant language pairs with minimal shared vocabulary

## Next Checks

1. **Norm Restoration Verification:** Implement multiple norm restoration variants (rescaling, projection) and measure their impact on model stability and steering effectiveness to determine the critical implementation details.

2. **Cross-Lingual Robustness Test:** Evaluate ReCoVeR on truly distant language pairs (e.g., Korean-Japanese, Swahili-English) not well-represented in the training corpus to test the generalizability claim.

3. **Content Subtraction Ablation with Semantic Probes:** Beyond just measuring task performance, use semantic similarity metrics (e.g., sentence embeddings) to verify that the content vector truly captures meaning-agnostic information across parallel texts.