---
ver: rpa2
title: Online Learning for Approximately-Convex Functions with Long-term Adversarial
  Constraints
arxiv_id: '2508.16992'
source_url: https://arxiv.org/abs/2508.16992
tags:
- online
- regret
- convex
- where
- function
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper studies online learning with long-term adversarial\
  \ budget constraints where both the cost and consumption functions are \u03B1-approximately\
  \ convex. The authors propose an efficient first-order online algorithm that achieves\
  \ O(\u221AT) \u03B1-regret against the optimal fixed feasible benchmark while consuming\
  \ at most O(BT log T) + \xD5(\u221AT) resources in both full-information and bandit\
  \ feedback settings."
---

# Online Learning for Approximately-Convex Functions with Long-term Adversarial Constraints

## Quick Facts
- **arXiv ID**: 2508.16992
- **Source URL**: https://arxiv.org/abs/2508.16992
- **Reference count**: 40
- **Primary result**: O(√T) α-regret and O(B_T log T) + Õ(√T) resource consumption for online learning with long-term adversarial budget constraints where cost and consumption functions are α-approximately convex

## Executive Summary
This paper addresses online learning with long-term adversarial budget constraints where both cost and consumption functions are α-approximately convex. The authors propose an efficient first-order online algorithm that achieves O(√T) α-regret while consuming at most O(B_T log T) + Õ(√T) resources. The algorithm uses a Lyapunov drift analysis with adaptive AdaGrad step sizes to reduce the constrained problem to standard Online Linear Optimization. The work provides matching lower bounds showing these guarantees are tight and demonstrates applicability to problems like DR-submodular maximization, Online Vertex Cover, and Regularized Phase Retrieval.

## Method Summary
The algorithm reduces the constrained problem to standard Online Linear Optimization by constructing a surrogate cost function that combines the original cost with a Lyapunov-based penalty on consumption. It uses AdaGrad with adaptive step sizes to handle the potentially exploding gradients caused by the exponential growth of the Lyapunov function term. The method maintains cumulative consumption state and updates decisions using generalized subgradients of the surrogate cost, achieving sublinear α-regret while controlling long-term constraint violation.

## Key Results
- Achieves O(√T) α-regret against the optimal fixed feasible benchmark
- Consumes at most O(B_T log T) + Õ(√T) resources in both full-information and bandit feedback settings
- Provides matching lower bounds showing these guarantees are tight
- Demonstrates applicability to DR-submodular maximization, Online Vertex Cover, and Regularized Phase Retrieval
- Works for budget B_T=0 while maintaining O(√T) regret and O(√T) violation

## Why This Works (Mechanism)

### Mechanism 1: Surrogate Cost Decomposition with Lyapunov Drift
The algorithm minimizes cumulative cost while controlling long-term constraint violation by optimizing a "surrogate cost" function that penalizes consumption. A Lyapunov function Φ(Q(t)) tracks cumulative consumption Q(t), and the algorithm minimizes the drift-plus-penalty expression Φ(Q(t)) - Φ(Q(t-1)) + V(f_t(x_t) - αf_t(x*)). This transforms the problem into minimizing cumulative surrogate cost ĥ_t = Vf_t + Φ'(Q(t))g_t.

### Mechanism 2: Reduction to Online Linear Optimization (OLO)
The algorithm achieves sublinear α-regret by reducing the complex constrained problem to standard Online Linear Optimization. Using the property of α-approximately convex functions, for any f ∈ L_α, f(x) - αf(u) ≤ ⟨H(x), x-u⟩ for a generalized subgradient H. By minimizing the linear function f̃_t(x) = ⟨H_ĥ_t(x_t), x⟩, the algorithm implicitly minimizes the α-regret of the original non-convex surrogate cost.

### Mechanism 3: Adaptive Gradient Scaling (AdaGrad)
AdaGrad is critical to handle the scaling of gradients caused by the exponential growth of the Lyapunov function term. The norm of the generalized subgradient of the surrogate cost scales with Φ'(Q(t)). Standard Online Gradient Descent with fixed step size would diverge or require tuning dependent on unknown constants. AdaGrad adapts the step size η_t based on the sum of past squared gradients, ensuring stability.

## Foundational Learning

- **Concept: α-Approximately Convex Functions**
  - Why needed here: Generalizes standard convexity to broader non-convex problems like DR-submodular maximization. The algorithm is built on the assumption that cost/consumption functions satisfy f(x) ≤ αf(u) + ⟨H(x), x-u⟩.
  - Quick check question: Given a function f, can you find a convex function g such that g(x) ≤ f(x) ≤ αg(x), or does the biconjugate f** satisfy f ≤ αf**?

- **Concept: Lyapunov Drift Analysis**
  - Why needed here: Standard tool for analyzing systems with queues or long-term constraints. It allows derivation of bounds that trade off between "penalty" (regret) and "drift" (constraint violation).
  - Quick check question: How does adding a penalty term Vf_t(x_t) to the Lyapunov drift ΔL_t allow us to control the trade-off between queue length (violation) and cost?

- **Concept: Online Linear Optimization (OLO)**
  - Why needed here: The reduction step frames the problem as a game against a linear adversary. Understanding regret bounds of linear predictors is necessary to interpret the final √T regret guarantee.
  - Quick check question: Why is the regret for linear functions bounded by O(DG√T), and how does AdaGrad remove the need to know G in advance?

## Architecture Onboarding

- **Component map**: Constraint Monitor -> Lyapunov Engine -> Surrogate Builder -> Gradient Oracle -> Learner (AdaGrad)
- **Critical path**:
  1. Observe cost f_t and consumption g_t
  2. Update Cumulative Consumption Q(t)
  3. Calculate Lyapunov sensitivity Φ'(Q(t)) (exponential scaling)
  4. Form Surrogate Gradient H_ĥ_t ∝ V∇f_t + Φ'(Q(t))∇g_t
  5. AdaGrad Update: Adjust step size η_t and step in direction -H_ĥ_t
  6. Project back to decision set X
- **Design tradeoffs**: 
  - Lyapunov Function Choice: Exponential yields O(log T) competitive ratio but requires careful handling of exploding gradients
  - Benchmark Selection: Benchmarks against fixed offline action satisfying long-term constraints (less restrictive than per-round feasibility)
- **Failure signatures**:
  - Exploding Gradients: If Q(t) grows faster than expected, Φ'(Q(t)) explodes, potentially causing numerical instability
  - Vacuous Bounds: If budget B_T is very small, O(√T) additive violation might dominate useful capacity
- **First 3 experiments**:
  1. Baseline OGD vs. AdaGrad on synthetic α-convex problem to verify adaptive requirement
  2. Budget Scaling: Vary B_T from 0 to T and plot Cumulative Consumption vs. Regret
  3. Application Test (Online Vertex Cover): Implement for Online Vertex Cover problem to validate 1/2-approximately concave reward maximization

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the algorithm be extended to more general classes of non-convex functions beyond α-approximately convex functions while maintaining sublinear regret guarantees?
- Basis in paper: [explicit] The conclusion states: "In the future, it will be interesting to extend the algorithm to more general class of non-convex functions."
- Why unresolved: The current framework fundamentally relies on the α-approximate convexity property to construct generalized subgradients and bound the surrogate regret. Without this structure, the reduction to Online Linear Optimization fails.
- What evidence would resolve it: An algorithm achieving sublinear regret for a strictly larger function class or a lower bound showing that sublinear regret is impossible without α-approximate convexity.

### Open Question 2
- Question: Can the O(log T) competitive ratio for cumulative consumption be improved while maintaining O(√T) regret, particularly for small budgets?
- Basis in paper: [explicit] Theorem 5 proves that "the O(log T) multiplicative factor in front of BT in the expression for CC cannot be improved while maintaining a sublinear regret guarantee" even for linear functions.
- Why unresolved: The lower bound construction requires the budget to scale as B_T = Ω(√T). The tightness for general budget levels (particularly small B_T) remains open.
- What evidence would resolve it: A refined lower bound holding for all budget scalings, or an algorithm achieving better than O(log T) competitive ratio for specific budget regimes.

### Open Question 3
- Question: Is there a unified algorithmic framework that achieves optimal bounds using the same Lyapunov function construction for both full-information and bandit feedback settings?
- Basis in paper: [inferred] The paper uses exponential Lyapunov function (Φ(x) = exp(λx)) for full-information but switches to power-law function (Φ(x) = x^m) for bandits "for technical reasons."
- Why unresolved: The bandit analysis requires the surrogate loss at round t to be F_{t-1}-measurable, complicating the drift analysis. The power-law form enables specific bounds that the exponential form does not readily provide.
- What evidence would resolve it: A single algorithm using one Lyapunov construction achieving the stated bounds in both settings, or a proof that different constructions are fundamentally necessary.

## Limitations

- The analysis critically depends on the existence of generalized subgradients for α-approximately convex functions, which is defined axiomatically but not constructively in all cases
- The choice of exponential Lyapunov function creates potentially exploding gradient terms that rely heavily on AdaGrad's adaptive properties for stability
- The matching lower bounds assume specific problem structures that may not generalize to all settings within the problem class

## Confidence

- **High confidence**: The core regret and constraint violation bounds (Theorem 4, 5) given the stated assumptions; the reduction to OLO framework; the AdaGrad necessity argument in Section 5.1
- **Medium confidence**: The matching lower bound tightness (Theorem 6) and its implications for algorithm optimality; the exact competitive ratio constants in the O(log T) bound
- **Low confidence**: Practical performance on specific applications without concrete instantiation details; behavior when B_T is very small (approaching zero budget)

## Next Checks

1. Implement Algorithm 1 with synthetic α-approximately convex functions (e.g., f(x) = α·convex_component(x) + concave_perturbation(x)) and verify the surrogate cost construction and AdaGrad updates maintain stability across different Q(t) growth patterns.

2. For the Online Vertex Cover application, construct the edge arrival process and verify the 1/2-approximately concave reward structure, then compare the algorithm's performance against standard greedy heuristics on benchmark graph sequences.

3. Test the algorithm's sensitivity to the choice of Lyapunov function by comparing the exponential Φ(x) = exp(λx) against the power-law alternative mentioned for the bandit setting, measuring both constraint violation and computational overhead.