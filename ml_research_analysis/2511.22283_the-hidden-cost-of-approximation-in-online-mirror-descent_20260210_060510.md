---
ver: rpa2
title: The Hidden Cost of Approximation in Online Mirror Descent
arxiv_id: '2511.22283'
source_url: https://arxiv.org/abs/2511.22283
tags:
- theorem
- regret
- which
- proof
- trajectory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the effect of approximation errors in online
  mirror descent (OMD), a fundamental optimization and online learning algorithm.
  The authors systematically analyze how errors in solving the OMD subproblems propagate
  and affect regret.
---

# The Hidden Cost of Approximation in Online Mirror Descent

## Quick Facts
- arXiv ID: 2511.22283
- Source URL: https://arxiv.org/abs/2511.22283
- Reference count: 40
- Primary result: Shows negative entropy regularizer in OMD requires exponentially small approximation errors (ε=O(e⁻ηT)) to avoid linear regret, while log-barrier and Tsallis regularizers remain robust with only polynomially small errors (ε=O(η⁴(ηTd)⁻ᵛ/ᵛ⁻¹)).

## Executive Summary
This paper systematically analyzes how approximation errors in solving OMD subproblems propagate and affect regret across different regularizers. For smooth regularizers, the authors establish tight bounds showing errors must be O(1/T²) for optimal regret. The key insight reveals a sharp dichotomy: negative entropy requires exponentially small errors to avoid linear regret due to compounding effects that drive iterates exponentially close to zero, while log-barrier and Tsallis regularizers remain robust with only polynomially small errors. Surprisingly, negative entropy regains robustness under stochastic losses on the full simplex, where polynomially small errors suffice, but this property breaks on polyhedral subsets. The analysis introduces a novel "balance" framework to characterize trajectory behavior and provides tight lower bounds demonstrating the necessity of these error requirements.

## Method Summary
The paper studies ε-approximate OMD where w_{t+1} satisfies ϕ_t(w_{t+1}) ≤ min_w ϕ_t(w) + ε, with ϕ_t(w) = η⟨ℓ_t, w⟩ + D_R(w||w_t). The authors analyze regret bounds under different regularizers: negative entropy (multiplicative weights), Tsallis entropy, and log-barrier. For smooth regularizers, they prove Θ(TD√βε/η) excess regret bounds. For barrier regularizers, they show negative entropy requires exponentially small errors (ε=O(e⁻ηT)) to avoid linear regret, while log-barrier and Tsallis remain robust with polynomially small errors (ε=O(η⁴(ηTd)⁻ᵛ/ᵛ⁻¹)). The stochastic setting analysis reveals negative entropy regains robustness with polynomially small errors on the full simplex, but loses it on polyhedral subsets.

## Key Results
- Smooth regularizers: Tight Θ(TD√βε/η) excess regret bound
- Negative entropy barrier: Exponentially small errors (ε=O(e⁻ηT)) required to avoid linear regret
- Log-barrier/Tsallis barriers: Polynomially small errors (ε=O(η⁴(ηTd)⁻ᵛ/ᵛ⁻¹)) suffice
- Stochastic setting: Negative entropy regains robustness with polynomially small errors on full simplex
- Novel "balance" framework characterizes trajectory behavior under approximation errors

## Why This Works (Mechanism)
The mechanism behind these results lies in how approximation errors compound differently across regularizers. For negative entropy, errors accumulate multiplicatively, driving iterates exponentially close to zero when errors are too large, causing linear regret. The barrier property creates a "balance" between the learning rate and error magnitude that must be maintained. For smooth regularizers, errors add linearly to regret. The stochastic setting breaks the adversarial compounding because randomness prevents systematic drift toward zero. The Tsallis and log-barrier regularizers have curvature properties that limit error propagation, maintaining robustness even with larger approximation errors.

## Foundational Learning
- Bregman Divergence: Measures distance between points under a convex function; needed to quantify approximation quality in OMD updates
  - Quick check: Verify D_R(w||w_t) ≥ 0 with equality iff w = w_t
- Barrier Regularizers: Functions that approach infinity at boundary; needed to enforce constraints in OMD
  - Quick check: Confirm R(w) → ∞ as w approaches boundary of K
- Multiplicative Weights Update: Negative entropy OMD implementation; needed to understand the fragility mechanism
  - Quick check: Implement w_{t+1}[i] ∝ w_t[i]·exp(-ηℓ_t[i]) and verify normalization
- Polyhedral Geometry: Understanding simplex subsets; needed for stochastic lower bound construction
  - Quick check: Verify K ⊆ ∆_d is a polytope with linear constraints
- Regret Analysis: Cumulative loss comparison framework; needed to quantify approximation impact
  - Quick check: Compute Σ⟨ℓ_t, w_t⟩ - Σ⟨ℓ_t, w*⟩ for simple adversarial sequence

## Architecture Onboarding

**Component Map**: Decision set K ⊆ simplex ∆_d -> OMD update -> Approximate solution w_{t+1} -> Regret calculation

**Critical Path**: Loss vectors ℓ_t ∈ [-1,1]^d -> OMD subproblem solution -> Approximation error ε -> Regret accumulation

**Design Tradeoffs**: Negative entropy offers simplicity and fast convergence but extreme fragility to approximation errors; barrier regularizers trade some convergence speed for robustness to implementation errors

**Failure Signatures**: Linear regret growth indicates approximation errors too large for negative entropy; slow convergence suggests errors affecting barrier regularizers; numerical instability when coordinates hit zero

**First Experiments**:
1. Implement exact OMD with negative entropy (multiplicative weights) and verify O(ηT + log(d)/η) regret on random adversarial losses
2. Implement ε-approximate OMD by adding bounded noise to exact update, testing with ε = O(1/T²) vs ε = Ω(η·e⁻ηT)
3. Reproduce lower bound construction (Theorem 4) with d=2, verifying linear regret occurs when ε ≥ 4η·e⁻ηT/3

## Open Questions the Paper Calls Out
None

## Limitations
- Numerical instability with exponentially small error requirements for negative entropy
- Complex polyhedral construction for stochastic lower bounds requires careful parameter tuning
- Adversarial lower bounds may not reflect practical optimization error distributions

## Confidence
High: Smooth regularizer bounds, Tsallis/log-barrier robustness
Medium: Negative entropy stochastic result on full simplex
Low: Negative entropy adversarial lower bound requiring exponentially small errors

## Next Checks
1. Numerically verify adversarial lower bound by implementing d=2 construction with varying ε to confirm linear regret emerges when ε ≥ 4η·e⁻ηT/3
2. Test robustness recovery under stochastic losses by sampling random loss distributions and confirming O(√(T·log(d))) regret with polynomially small ε
3. Implement polyhedral subset construction to verify stochastic fragility on restricted domains