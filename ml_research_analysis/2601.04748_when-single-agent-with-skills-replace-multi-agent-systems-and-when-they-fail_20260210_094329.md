---
ver: rpa2
title: When Single-Agent with Skills Replace Multi-Agent Systems and When They Fail
arxiv_id: '2601.04748'
source_url: https://arxiv.org/abs/2601.04748
tags:
- skill
- selection
- skills
- accuracy
- library
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of replacing multi-agent systems
  (MAS) with single-agent systems that use a library of skills, aiming to reduce computational
  overhead while maintaining reasoning performance. The core idea is to compile specialized
  agent behaviors into selectable skills within a single model, trading inter-agent
  communication for skill selection.
---

# When Single-Agent with Skills Replace Multi-Agent Systems and When They Fail

## Quick Facts
- arXiv ID: 2601.04748
- Source URL: https://arxiv.org/abs/2601.04748
- Reference count: 40
- Primary result: Single-agent skill compilation achieves 54% token reduction and 50% latency improvement vs MAS while maintaining accuracy

## Executive Summary
This paper investigates when and why single-agent systems with skill libraries can effectively replace multi-agent systems (MAS) for complex reasoning tasks. The core innovation is compiling specialized agent behaviors into selectable skills within a single model, eliminating inter-agent communication overhead. Experiments on GSM8K, HumanEval, and HotpotQA demonstrate that this approach achieves comparable accuracy to MAS while significantly reducing computational costs. However, the work reveals a critical limitation: as skill libraries grow, selection accuracy degrades sharply beyond a threshold, exhibiting a phase transition reminiscent of cognitive capacity limits.

## Method Summary
The method compiles specialized agent behaviors from MAS into discrete skills within a single agent framework. Each skill represents a specialized reasoning capability (e.g., numerical reasoning, code generation). When faced with a task, the single agent uses a routing mechanism to select the appropriate skill from its library. The approach trades inter-agent communication for skill selection, maintaining reasoning performance while reducing token usage and latency. The key challenge addressed is managing the trade-off between skill library size (which increases coverage) and selection accuracy (which degrades with semantic confusability among similar skills).

## Key Results
- Single-agent skill compilation achieves 54% token reduction and 50% latency improvement over MAS
- Maintains comparable accuracy across GSM8K, HumanEval, and HotpotQA benchmarks
- Exhibits sharp performance degradation (phase transition) beyond critical skill library size thresholds
- Hierarchical routing mitigates selection failures by decomposing decisions into coarse-to-fine steps

## Why This Works (Mechanism)
The approach works by leveraging the LLM's ability to represent and select between specialized reasoning behaviors. By compiling MAS agent behaviors into discrete skills, the system avoids expensive inter-agent communication while preserving reasoning capabilities. The skill selection mechanism acts as a router that maps task requirements to appropriate specialized behaviors. This compilation is effective because many MAS tasks can be decomposed into sequential or parallel application of specialized skills rather than requiring continuous agent negotiation.

## Foundational Learning
- **Skill compilation**: Converting specialized agent behaviors into discrete, selectable units within a single model. Needed to eliminate inter-agent communication overhead. Quick check: Can the compiled skills reproduce individual agent behaviors from the original MAS?
- **Semantic confusability**: The phenomenon where similar skills become difficult to distinguish during selection, leading to errors. Needed to explain the phase transition in selection accuracy. Quick check: Does selection accuracy correlate with semantic similarity between skills?
- **Hierarchical routing**: Decomposing skill selection into multiple levels (coarse-to-fine) to improve accuracy. Needed to mitigate the limitations of flat selection mechanisms. Quick check: Does hierarchical routing maintain accuracy as library size increases?
- **Phase transition behavior**: The sharp drop in selection accuracy beyond a critical library size threshold. Needed to characterize fundamental scalability limits. Quick check: Is there a consistent critical threshold across different skill distributions?
- **Skill selection as cognitive bottleneck**: The parallel between skill selection limitations and human cognitive capacity constraints. Needed for understanding fundamental limits. Quick check: Do different skill distributions show similar phase transition patterns?

## Architecture Onboarding
**Component Map**: Task Input -> Skill Router -> Skill Library -> Skill Execution -> Output
**Critical Path**: Task → Skill Selection → Skill Execution → Result Aggregation
**Design Tradeoffs**: Larger skill libraries increase coverage but worsen selection accuracy; simpler routing is faster but less accurate for complex libraries
**Failure Signatures**: Sharp accuracy drop at critical library size; increased selection of semantically similar but incorrect skills
**First 3 Experiments**:
1. GSM8K benchmark with 10, 20, 50, 100 skill libraries to identify phase transition point
2. Ablation study comparing flat vs hierarchical routing on HotpotQA
3. Semantic similarity analysis of skill selection errors at different library sizes

## Open Questions the Paper Calls Out
None

## Limitations
- Skill selection exhibits sharp performance degradation beyond critical library size thresholds
- Semantic confusability among similar skills limits scalability more than raw library size
- Hierarchical routing partially mitigates but doesn't eliminate the fundamental scaling problem
- Cognitive parallels to human capacity constraints remain speculative

## Confidence
**High Confidence**: 54% token reduction and 50% latency improvement with maintained accuracy across multiple benchmarks
**Medium Confidence**: Semantic confusability as primary driver of selection failure; effectiveness of hierarchical routing
**Low Confidence**: Cognitive parallels to human capacity constraints; exact mechanisms of phase transition behavior

## Next Checks
1. Test skill compilation approach on biomedical and legal reasoning domains to assess cross-domain generalization
2. Evaluate dynamic skill library adaptation through active learning to extend scaling limits
3. Compare hierarchical routing against attention-based mixture-of-experts architectures for selection accuracy