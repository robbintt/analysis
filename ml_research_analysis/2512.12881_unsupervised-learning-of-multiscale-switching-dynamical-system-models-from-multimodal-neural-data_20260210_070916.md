---
ver: rpa2
title: Unsupervised learning of multiscale switching dynamical system models from
  multimodal neural data
arxiv_id: '2512.12881'
source_url: https://arxiv.org/abs/2512.12881
tags:
- switching
- multiscale
- neural
- regime
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper develops an unsupervised learning algorithm for switching
  multiscale dynamical system models using only multimodal neural observations, without
  requiring regime labels. The method combines a novel switching multiscale numerical
  integration filter (sMSNF) with an expectation-maximization framework to fuse information
  across spike and field potential modalities while tracking regime-dependent non-stationarity.
---

# Unsupervised learning of multiscale switching dynamical system models from multimodal neural data

## Quick Facts
- arXiv ID: 2512.12881
- Source URL: https://arxiv.org/abs/2512.12881
- Authors: DongKyu Kim; Han-Lin Hsieh; Maryam M. Shanechi
- Reference count: 0
- Primary result: An unsupervised learning algorithm that jointly models spike and field potential data using switching multiscale dynamical systems, outperforming single-modality and stationary approaches in decoding behavior and predicting neural activity.

## Executive Summary
This paper introduces a novel unsupervised learning algorithm for switching multiscale dynamical system (SMDS) models that can fuse spike and field potential data without requiring regime labels. The method combines a switching multiscale numerical integration filter (sMSNF) with an expectation-maximization framework to track regime-dependent non-stationarity while integrating information across modalities. The approach demonstrates superior performance in decoding behavior and predicting neural activity compared to both single-scale switching methods and stationary multiscale methods.

## Method Summary
The method learns SMDS models from multimodal neural observations (spikes and field potentials) using an EM algorithm. The E-step employs a switching multiscale numerical integration filter (sMSNF) that uses cubature integration to handle non-Gaussian Poisson observations, while the M-step updates model parameters including dynamics matrices, observation matrices, and transition probabilities. A key innovation is the introduction of a likelihood scaling parameter τ to balance the contributions of spike and field modalities during fusion. The approach is validated through simulations and real nonhuman primate motor cortical data.

## Key Results
- sMSNF-EM outperforms sMSF-EM, sKF-EM, and sPCF-EM in behavioral decoding across both simulated and real data
- Multiscale fusion improves performance over single-modality approaches, with optimal scaling parameter τ determined via cross-validation
- Switching models consistently outperform stationary models in decoding accuracy and neural self-prediction
- The method successfully identifies regime switches in both simulated data with ground truth and real neural recordings

## Why This Works (Mechanism)

### Mechanism 1: Multiscale Likelihood Fusion via Gaussian-Poisson Product
The filter computes a joint posterior by multiplying Gaussian likelihood of field potentials with Poisson likelihood of spikes, using a scaling parameter τ to balance contributions. This assumes conditional independence between spike and field observations given the latent state and regime. Evidence shows behavior decoding improves with multimodal fusion, and τ prevents modality dominance.

### Mechanism 2: Switching Multiscale Numerical Integration (sMSNF)
Replaces Laplace approximation with 5th-degree spherical radial cubature integration for more accurate moment computation in non-Gaussian posterior estimation. The cubature rule captures non-linearities in Poisson observation model better than local Taylor expansion. Outperforms Laplace-based approaches in behavioral decoding accuracy.

### Mechanism 3: Regime-Dependent State Space Modeling
Models neural dynamics as a Switching Linear Dynamical System where latent dynamics and observation parameters depend on discrete regime state. The filter tracks both continuous state and regime probabilities simultaneously. Superior to stationary models in capturing non-stationarity and decoding accuracy.

## Foundational Learning

- **Expectation-Maximization (EM) Algorithm**: Needed to estimate parameters without regime labels by alternating between inferring hidden states (E-step) and optimizing system parameters (M-step). Quick check: Why does the E-step require a smoother rather than just a filter?

- **Poisson Point Process Observation Model**: Required because spikes are discrete events, not continuous values. Links continuous latent state to discrete spike counts via exponential rate function. Quick check: How does firing rate λ relate mathematically to latent state x_t?

- **Conditional Independence in Multiscale Fusion**: The mathematical foundation allowing multiplication of spike and field likelihoods. Without it, joint probability calculation is invalid. Quick check: Does p(n,y|x) = p(n|x)p(y|x) hold if y causes n?

## Architecture Onboarding

- **Component map**: Binned spike counts and LFP power features -> sMSNF Filter Core (E-Step) -> Parameter Store (M-Step) -> Decoded latent state and Regime probability
- **Critical path**: Initialization of scaling parameter τ and regime transition matrix Φ. τ determined via grid search/cross-validation; incorrect values cause modality imbalance.
- **Design tradeoffs**: Laplace (faster, less accurate) vs Cubature (computationally heavier, necessary for unsupervised learning); exponential complexity with number of regimes M
- **Failure signatures**: Likelihood Collapse (log-likelihood to -infinity), Regime Stagnation (binary probabilities), Divergence (latent states drift to infinity)
- **First 3 experiments**: 1) Implement MSNF on simulated data to verify reconstruction better than KF on LFP alone; 2) Sweep scaling parameter τ on real data to verify optimal "sweet spot"; 3) Test regime recovery on simulated data with known switches

## Open Questions the Paper Calls Out

The paper doesn't explicitly call out open questions but has implicit limitations regarding model selection for number of regimes, automatic learning of scaling parameters, and conditional independence assumptions.

## Limitations

- **Identifiability uncertainty**: Doesn't rigorously test whether unsupervised EM can distinguish true regime transitions from multiscale fusion artifacts
- **Scalability concerns**: Computational complexity limits applicability to larger-scale recordings due to exponential scaling with regimes and latent dimensions
- **Gaussian assumption limitations**: Assumes Gaussian posteriors for moment matching, which may fail for highly non-Gaussian regimes or multimodal posteriors

## Confidence

- **High confidence**: Multiscale fusion mechanism with likelihood re-weighting and its empirical validation across simulations and real data
- **Medium confidence**: Unsupervised regime identification capability, as superior performance is shown but rigorous validation of learned regimes is lacking
- **Low confidence**: Generalization to datasets with significantly different statistics or temporal scales than validation data

## Next Checks

1. **Regime recovery validation**: Apply to simulated data with known regime switches, vary signal-to-noise ratio to quantify false positive/negative rates in regime detection
2. **Scaling parameter robustness**: Conduct ablation studies comparing fixed vs optimized τ across multiple datasets with varying spike-field statistics
3. **Non-Gaussian posterior stress test**: Design simulations with highly non-Gaussian (multi-modal or heavy-tailed) posteriors to measure when Gaussian assumption breaks down