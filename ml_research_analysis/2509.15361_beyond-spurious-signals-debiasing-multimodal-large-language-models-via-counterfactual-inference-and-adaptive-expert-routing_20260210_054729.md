---
ver: rpa2
title: 'Beyond Spurious Signals: Debiasing Multimodal Large Language Models via Counterfactual
  Inference and Adaptive Expert Routing'
arxiv_id: '2509.15361'
source_url: https://arxiv.org/abs/2509.15361
tags:
- debiasing
- multimodal
- counterfactual
- image
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of spurious correlation bias in
  multimodal large language models (MLLMs), where models rely on superficial cues
  rather than true multimodal reasoning. It introduces a causal mediation framework
  that distinguishes core semantics from spurious contexts via counterfactual examples
  and employs a Mixture-of-Experts (MoE) architecture with dynamic routing to selectively
  activate modality-specific debiasing experts.
---

# Beyond Spurious Signals: Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing

## Quick Facts
- arXiv ID: 2509.15361
- Source URL: https://arxiv.org/abs/2509.15361
- Authors: Zichen Wu; Hsiu-Yuan Huang; Yunfang Wu
- Reference count: 40
- Primary result: Achieved 87.2% F1 on MMSD2.0 and 62.4% F1 on MVSA-Multi through counterfactual debiasing

## Executive Summary
This paper addresses spurious correlation bias in multimodal large language models (MLLMs), where models rely on superficial cues rather than true multimodal reasoning. The authors propose a causal mediation framework that distinguishes core semantics from spurious contexts through counterfactual examples, combined with a Mixture-of-Experts (MoE) architecture featuring dynamic routing to selectively activate modality-specific debiasing experts. The method demonstrates state-of-the-art performance on multimodal sarcasm detection and sentiment analysis tasks, significantly reducing reliance on spurious correlations while improving robustness across debiasing categories.

## Method Summary
The proposed method employs a causal mediation framework that generates counterfactual examples to identify and mitigate spurious correlations in MLLMs. A Mixture-of-Experts architecture with dynamic routing selectively activates modality-specific debiasing experts based on input characteristics. The approach integrates counterfactual inference to distinguish between core semantic content and spurious contextual signals, enabling more robust multimodal reasoning. This framework is validated through extensive experiments on multimodal sarcasm detection and sentiment analysis tasks, demonstrating superior performance compared to existing methods.

## Key Results
- Achieved 87.2% F1 score on MMSD2.0 dataset, setting new state-of-the-art performance
- Reached 62.4% F1 score on MVSA-Multi dataset for multimodal sentiment analysis
- Demonstrated significant reduction in spurious correlation reliance across multiple debiasing categories

## Why This Works (Mechanism)
The method works by explicitly modeling the causal relationships between modalities and their spurious correlations. Through counterfactual inference, the framework identifies when models are relying on superficial correlations rather than genuine multimodal reasoning. The MoE architecture with adaptive expert routing allows for dynamic selection of specialized debiasing experts based on input characteristics, ensuring that spurious correlations are effectively filtered while preserving meaningful multimodal interactions. This combination of causal mediation and selective expert activation enables more robust and generalizable multimodal reasoning.

## Foundational Learning

**Counterfactual Inference**: Generating alternative scenarios by changing specific variables to understand causal relationships. Needed to identify spurious correlations by testing model behavior under modified conditions. Quick check: Can the model distinguish between genuine correlations and those that disappear under counterfactual perturbations?

**Causal Mediation Framework**: A statistical approach to decompose the effect of an intervention into direct and indirect pathways. Needed to separate core semantic signals from spurious contextual influences. Quick check: Does the framework correctly attribute performance changes to the appropriate causal pathways?

**Mixture-of-Experts (MoE)**: An ensemble architecture where different experts specialize in different input patterns, with a gating network routing inputs to appropriate experts. Needed to dynamically apply modality-specific debiasing strategies. Quick check: Does the routing mechanism effectively select the most appropriate debiasing expert for each input?

**Dynamic Routing**: Adaptive selection of model components based on input characteristics. Needed to ensure spurious correlations are addressed with specialized expertise while preserving valid multimodal interactions. Quick check: Is the routing mechanism responsive to subtle variations in input that might indicate different types of spurious correlations?

## Architecture Onboarding

**Component Map**: Input Text/Image -> Counterfactual Generator -> Causal Mediator -> MoE Gating Network -> Modality-Specific Debiasing Experts -> Final Prediction

**Critical Path**: The most critical path is Counterfactual Generation → Causal Mediation → MoE Routing → Expert Activation, as this sequence determines how spurious correlations are identified and mitigated.

**Design Tradeoffs**: The approach trades computational efficiency for robustness by maintaining multiple specialized experts and generating counterfactual examples. The benefit is improved generalization and reduced spurious correlation reliance, while the cost is increased model complexity and inference time.

**Failure Signatures**: The system may fail when counterfactual generation misses complex spurious correlations, when expert specialization is insufficient for novel spurious patterns, or when routing decisions become brittle in edge cases. Performance degradation may be task-specific rather than uniform across all multimodal scenarios.

**First 3 Experiments**: 1) Ablation study removing counterfactual generation to measure its individual contribution. 2) Routing analysis examining expert selection patterns across different spurious correlation types. 3) Adversarial testing with inputs designed to exploit residual spurious correlations.

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Counterfactual example generation may introduce artifacts or miss complex spurious correlations not easily captured through perturbations
- MoE routing effectiveness depends on quality and diversity of debiasing experts, with insufficient exploration of expert specialization limitations
- Evaluation focuses primarily on sarcasm detection and sentiment analysis, limiting generalizability to other multimodal domains

## Confidence

**High Confidence**: Performance metrics on MMSD2.0 and MVSA-Multi datasets are well-supported by reported results.

**Medium Confidence**: Causal mediation framework's ability to distinguish core semantics from spurious contexts is theoretically sound but needs more extensive ablation studies.

**Medium Confidence**: Claims about reducing spurious correlation reliance are supported by performance gains but require more detailed failure mode analysis.

## Next Checks

1. Conduct systematic ablation studies removing either counterfactual generation or MoE routing to quantify each component's individual contribution to performance gains.

2. Evaluate model performance on additional multimodal tasks beyond sarcasm detection and sentiment analysis to assess generalizability across different types of spurious correlations.

3. Implement stress tests with adversarial examples designed to exploit remaining spurious correlations to identify residual vulnerabilities in the debiasing approach.