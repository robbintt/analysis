---
ver: rpa2
title: Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of
  Large Language Models
arxiv_id: '2512.14427'
source_url: https://arxiv.org/abs/2512.14427
tags:
- packing
- documents
- arxiv
- pack
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how document packing strategies influence
  the latent multi-hop reasoning capabilities of large language models. The authors
  explore whether packing multiple documents into training sequences, rather than
  processing them individually, can improve model performance on reasoning tasks that
  require recalling and integrating multiple pieces of information.
---

# Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models

## Quick Facts
- arXiv ID: 2512.14427
- Source URL: https://arxiv.org/abs/2512.14427
- Reference count: 19
- Primary result: Packing 4-6 documents per sequence with cross-document attention and repacking each epoch improves multi-hop reasoning performance compared to no packing

## Executive Summary
This paper investigates how document packing strategies affect the multi-hop reasoning capabilities of large language models during pre-training. The authors find that packing multiple documents into training sequences, combined with cross-document attention and repacking at each epoch, significantly improves model performance on reasoning tasks requiring document recall and integration. Optimal performance is achieved with 4-6 documents per sequence, though this comes at increased computational cost. The study identifies cross-document attention and repacking as essential mechanisms for packing to provide benefits.

## Method Summary
The authors continually pre-train open-weight LLMs using various packing strategies: no packing, fixed packing (2, 4, 6, 8, 10 documents per sequence), and multi-packing (random pack sizes). Documents are concatenated with `<SEP>` tokens between them. After pre-training, models are instruction-tuned on question-answer pairs from HotpotQA and 2WikiMultiHopQA benchmarks, where the expected output format includes recalled document titles followed by the answer. Models are evaluated on precision (correct document recall), hallucination rate (accuracy of recalled content), and final answer correctness.

## Key Results
- Packing 4-6 documents per sequence provides optimal performance for multi-hop reasoning tasks
- Cross-document attention during pre-training is essential for packing benefits to manifest
- Repacking documents with different neighbors each epoch is crucial; fixed combinations degrade performance
- Packing increases computational requirements due to cross-document attention and need for more documents to achieve convergence
- Larger pack sizes increase hallucination rates due to representation entanglement

## Why This Works (Mechanism)

### Mechanism 1: Cross-Document Attention Enables Contextualized Representations
- When documents are packed with cross-document attention enabled, tokens can attend across document boundaries, creating joint representations that help the model learn relationships between documents
- Core assumption: Downstream tasks require integrating information that was seen together during training
- Evidence: Pack 2 performs comparably to no packing when cross-document attention is disabled
- Break condition: If your downstream task doesn't require integrating information across documents, cross-document attention may add noise

### Mechanism 2: Contextual Diversity from Repacking Prevents Overfitting
- Repacking documents with different neighbors each epoch prevents context-dependent representations that degrade recall
- Core assumption: The model will form context-dependent representations if given the opportunity; varied exposure counters this
- Evidence: No repacking achieves 56.95% accuracy vs 63.74% for repacking every epoch on HotpotQA
- Break condition: If training only runs one epoch or document combinations are inherently meaningful, repacking may not apply

### Mechanism 3: Pack Size Creates a Representational Trade-off
- 4-6 documents provides sweet spot where cross-document benefits outweigh entanglement costs
- Core assumption: Model has limited capacity to separate representations of many jointly-attended documents
- Evidence: Precision improves from Pack 2 to Pack 4 to Pack 6, then declines at Pack 8/10; hallucination rate rises with pack size
- Break condition: Sweet spot likely depends on document length, model size, and task

## Foundational Learning

- **Latent Multi-Hop Reasoning (Closed-Book QA)**: Models must recall documents from parametric memory before answering; differs from standard RAG where retrieval is explicit
  - Quick check: Can you explain why the model must recall documents before answering, and why this is different from standard RAG?

- **Causal Language Modeling with Document Boundaries**: Decoder-only LLMs with `<SEP>` tokens; causal attention with packed sequences
  - Quick check: In a packed sequence [Doc1 <SEP> Doc2], which tokens can Doc2 tokens attend to if cross-document attention is enabled vs disabled?

- **Precision vs. Hallucination Rate vs. Accuracy**: Precision measures correct document identification; hallucination rate measures accuracy of recalled content; accuracy measures final answer correctness
  - Quick check: If a model recalls correct document titles but hallucinates their content, which metric(s) are affected?

## Architecture Onboarding

- **Component map**: Pre-training (pack documents -> insert <SEP> -> enable cross-document attention -> repack each epoch) -> Instruction-tuning (Q/A pairs -> structured output) -> Evaluation (LLM-as-judge)
- **Critical path**: 1) Choose pack size (start with 4-6, sweep if possible) 2) Enable cross-document attention during pre-training 3) Repack documents at each epoch 4) Monitor training loss for convergence 5) Instruction-tune on Q/A pairs with structured output format
- **Design tradeoffs**: Packing improves precision/accuracy but increases compute; larger pack sizes may help relevance estimation but increase hallucination risk; multi-packing adds variability but showed no clear benefit
- **Failure signatures**: Performance matches or underperforms no-packing → check cross-document attention and repacking; high hallucination rate → pack size too large; model recalls wrong document titles → precision issue
- **First 3 experiments**: 1) Replicate Pack 4 vs. No Packing comparison on your own corpus 2) Ablate cross-document attention (Pack 4 with/without) 3) Sweep pack sizes (2, 4, 6, 8) and log precision, hallucination rate, and accuracy separately

## Open Questions the Paper Calls Out

- **Optimal document selection for packing**: What is the optimal method for selecting which documents to pack together in general pre-training scenarios where explicit relevance lists are unavailable? The study relied on benchmark datasets with explicit lists of relevant and distractor documents.

- **Selective cross-document attention**: Should cross-document attention be restricted to semantically related documents rather than permitted across all documents in a sequence? The study only evaluated fully enabled vs fully disabled cross-document attention.

- **Packing excerpts vs. full documents**: Is it more effective to pack entire documents or to aggregate only the most relevant excerpts or paragraphs from different sources? All experiments used full documents; packing granular excerpts was proposed but not investigated.

## Limitations

- Task specificity: Findings may not generalize to open-ended generation tasks, multi-modal reasoning, or scenarios where document recall is implicit
- Architecture constraints: Results based on decoder-only LLMs; optimal strategies may vary with different model architectures
- Generalization to different document types: Experiments used Wikipedia-based documents; effectiveness for other document types remains unknown

## Confidence

- **High confidence**: Cross-document attention is essential for packing benefits; packing increases computational requirements; LLM-as-judge methodology
- **Medium confidence**: Optimal pack size range of 4-6 documents; repacking each epoch is crucial; relative performance ordering of strategies
- **Low confidence**: Exact shape of performance curve across pack sizes; multi-packing provides no benefit; generalizability to non-Wikipedia document collections

## Next Checks

1. **Cross-architectural validation**: Replicate Pack 4 vs. No Packing vs. Pack 4 without cross-document attention using an encoder-decoder architecture like BERT or T5

2. **Document type generalization**: Test packing strategies on a different document corpus with distinct characteristics (scientific abstracts, news articles, or technical documentation)

3. **Computational trade-off analysis**: Measure training convergence speed, wall-clock time, and memory usage across different pack sizes and architectures to quantify practical trade-offs between performance gains and computational costs