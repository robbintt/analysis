---
ver: rpa2
title: Entropy-Based Adaptive Weighting for Self-Training
arxiv_id: '2503.23913'
source_url: https://arxiv.org/abs/2503.23913
tags:
- arxiv
- east
- preprint
- weighting
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Entropy-Based Adaptive Weighting for Self-Training
  (EAST), a method that improves mathematical reasoning in large language models by
  assigning higher weights to uncertain training examples during self-training. The
  approach uses entropy computed from clusters of generated answers to quantify model
  uncertainty and applies a mapping function with a tunable parameter to transform
  entropy values into adaptive weights.
---

# Entropy-Based Adaptive Weighting for Self-Training
## Quick Facts
- arXiv ID: 2503.23913
- Source URL: https://arxiv.org/abs/2503.23913
- Authors: Xiaoxuan Wang; Yihe Deng; Mingyu Derek Ma; Wei Wang
- Reference count: 16
- Primary result: Up to 1-2% performance gains on GSM8K and MATH benchmarks over baseline self-training

## Executive Summary
This paper introduces EAST (Entropy-Based Adaptive Weighting for Self-Training), a method that improves mathematical reasoning in large language models by assigning higher weights to uncertain training examples during self-training. The approach uses entropy computed from clusters of generated answers to quantify model uncertainty and applies a mapping function with a tunable parameter to transform entropy values into adaptive weights. Evaluated on GSM8K and MATH benchmarks, EAST achieves consistent improvements over baseline methods and demonstrates benefits across different loss functions (SFT, DPO, KTO).

## Method Summary
EAST modifies the standard self-training pipeline by introducing entropy-based adaptive weighting. For each question, the model generates multiple responses (default 128) that are clustered by final answer. Entropy is computed from the cluster distribution, where higher entropy indicates greater model uncertainty. A mapping function f(h) = hᵃ / Σhᵢᵃ with tunable exponent a transforms entropy values into weights that are applied to the training loss. This weighting scheme prioritizes uncertain examples over both confident correct answers and "stubborn" confident wrong answers, addressing limitations of accuracy-based and rejection-based alternatives.

## Key Results
- EAST achieves 51.2% accuracy on GSM8K and 29.0% on MATH, outperforming baseline methods
- The optimal exponent parameter a varies by task (a=1.5 for GSM8K, a=1 or 3 for MATH)
- Entropy-based weighting consistently outperforms accuracy-based (51.0% GSM8K) and rejection-based (50.5% GSM8K) alternatives
- Benefits are observed across all three loss functions: SFT, DPO, and KTO

## Why This Works (Mechanism)
### Mechanism 1
- Claim: Prioritizing high-entropy (uncertain) training examples improves reasoning capability over uniform weighting.
- Mechanism: For each question, the model generates n responses clustered by final answer. Entropy H(x) = -Σpⱼ log pⱼ is computed over the cluster distribution. Higher entropy indicates the model produces diverse answers (uncertainty); lower entropy indicates consistent answers (confidence). A mapping function f(h) transforms entropy into weights applied to the loss.
- Core assumption: Questions where the model produces diverse wrong answers are more "educational" than questions where it confidently produces the same wrong answer (stubborn errors).
- Evidence anchors:
  - [abstract] "EAST employs a mapping function with a tunable parameter that controls the sharpness of the weighting, assigning higher weights to data where the model exhibits greater uncertainty."
  - [section 3.1] "A larger number of sparse clusters (kᵢ) indicates greater model uncertainty for that question, while a distribution concentrated in a single cluster suggests higher model confidence."
  - [corpus] Related work DAST confirms difficulty-aware sampling improves self-training; Self-Training with Confident Reasoning shows complementary focus on high-confidence samples.
- Break condition: If entropy primarily captures noise (random guessing) rather than meaningful uncertainty, weighting by entropy may amplify low-quality data.

### Mechanism 2
- Claim: The mapping function f(h) = hᵃ / Σhᵢᵃ with tunable exponent a controls emphasis on uncertain vs. confident examples.
- Mechanism: The exponent parameter a reshapes the weight distribution: a > 1 amplifies differences (stronger focus on uncertain data), 0 < a < 1 compresses differences (more uniform), a < 0 inverts (prioritizes confident data). Normalization (mean = 1) prevents learning rate distortion.
- Core assumption: A single scalar parameter can capture the optimal trade-off between focusing on hard examples and maintaining training stability.
- Evidence anchors:
  - [section 3.2] "The exponent parameter a provides curvature control over the transformation: f(h) enhances differences between weights when a > 1; f(h) compresses differences when 0 < a < 1."
  - [figure 3] "The model achieves peak accuracy on GSM8K at a = 1.5... for MATH, performance reaches 29.3% at a = 1 and 29.4% at a = 3, outperforming 28.1% at a = -1."
  - [corpus] No direct corpus evidence for this specific mapping function formulation.
- Break condition: If optimal a varies significantly across domains or model scales without predictable patterns, tuning becomes prohibitive.

### Mechanism 3
- Claim: Entropy-based weighting outperforms accuracy-based and rejection-based alternatives because it downweights "stubborn" confident errors.
- Mechanism: Accuracy-based weighting prioritizes low-accuracy questions, but these may have high rejection scores (same wrong answer repeated). Entropy automatically downweights cases where one incorrect answer dominates. Rejection-based weighting explicitly upweights stubborn errors, which degrades performance.
- Core assumption: Stubborn errors (confident wrong answers) are less tractable through additional training than uncertain errors with diverse wrong answers.
- Evidence anchors:
  - [section 4.3] "Many of these low-accuracy samples still exhibit high R(xᵢ) values, indicating repeated, confident errors... entropy-based weighting effectively addresses this problem by automatically assigning lower weights to cases where a single incorrect answer dominates."
  - [figure 5] Entropy-based: 51.2% GSM8K / 29.0% MATH; Accuracy-based: 51.0% / 28.8%; Rejection-based: 50.5% / 28.6%.
  - [corpus] Limited corpus comparison; related work focuses on difficulty or confidence but not this three-way comparison.
- Break condition: If stubborn errors are actually tractable with different training strategies (e.g., contrastive learning), entropy-based downweighting could discard learnable signal.

## Foundational Learning
- Concept: **Self-training with rejection sampling**
  - Why needed here: EAST modifies the standard self-training pipeline where models generate reasoning paths, correct paths are selected, and the model is fine-tuned. Understanding this baseline is essential.
  - Quick check question: Given a question with 128 generated samples, 12 yielding correct answers, what data enters vanilla SFT training?

- Concept: **Entropy as uncertainty quantification**
  - Why needed here: The core innovation uses entropy over answer clusters as a proxy for model uncertainty. Without this, the weighting motivation is opaque.
  - Quick check question: If a question produces 50 samples with answer "42" and 50 with answer "17", what is the entropy? What if 99 samples produce "42" and 1 produces "17"?

- Concept: **Loss functions: SFT vs. DPO vs. KTO**
  - Why needed here: EAST is evaluated across all three. SFT uses only positive samples; DPO uses paired preferences; KTO uses unpaired samples. Weighting integrates differently into each.
  - Quick check question: In DPO, how would the weight f(h) be applied—to the chosen response loss, rejected response loss, or both?

## Architecture Onboarding
- Component map: Sample Generator -> Answer Clusterer -> Entropy Computer -> Weight Mapper -> Loss Integrator -> Trainer
- Critical path: Sample generation → Answer clustering → Entropy computation → Weight mapping → Weighted loss → Model update. The mapping function (Step 4) is the only novel component; all others are standard.
- Design tradeoffs:
  - **Sample count n**: More samples (128 used) give better entropy estimates but increase compute. Fewer samples may introduce noise.
  - **Exponent a**: a ∈ [1, 1.5] performed best. Higher a (>2) may over-emphasize outliers; negative a inverts the intended effect.
  - **Iteration count**: EAST benefits from iterative training, but vanilla SFT shows overfitting on GSM8K after multiple iterations.
- Failure signatures:
  - **No improvement on MATH with vanilla SFT**: Indicates self-generated data alone insufficient for hard tasks (Section 4.2: 28.4% vs. 28.5% default)
  - **Performance degradation with rejection-based weighting**: Confirms stubborn errors are harmful training signal (Figure 5: 50.5% vs. 51.2% entropy-based)
  - **Overfitting in iterative GSM8K**: Vanilla SFT degrades after iteration 1; EAST maintains gains (Figure 4)
- First 3 experiments:
  1. **Baseline replication**: Implement vanilla self-training (SFT on correct samples only) on GSM8K with Llama-3.2-1B. Verify ~3.9% improvement over backbone (46.2% → ~50.1%). If this fails, debug sample generation and correctness filtering first.
  2. **Entropy-weighted SFT with a=1.5**: Add EAST weighting with exponent a=1.5. Target: additional 1-2% over vanilla (reaching ~51.8%). Compare weight distribution across training samples—expect higher weights on questions with 3+ distinct answer clusters.
  3. **Ablation: Accuracy-based vs. entropy-based**: Implement both weighting strategies on same data split. Entropy should outperform accuracy-based by ~0.2-0.5% on GSM8K. Inspect cases where they diverge—accuracy-based should over-weight questions with one dominant wrong answer.

## Open Questions the Paper Calls Out
None

## Limitations
- The entropy metric relies on coarse clustering by final answer, which may miss subtle differences in reasoning quality
- The optimal exponent value appears task-dependent (a=1.5 for GSM8K vs. a=1 or 3 for MATH), suggesting limited generalizability
- The method requires generating 128 samples per question, creating significant computational overhead

## Confidence
- **High Confidence**: Entropy-based weighting outperforms rejection-based weighting (Figure 5 results, 0.7% GSM8K gain) - this is direct experimental evidence.
- **Medium Confidence**: The mapping function with tunable exponent works across different loss functions (SFT, DPO, KTO show consistent gains) - results are positive but exponent tuning varies by task.
- **Low Confidence**: The mechanism that uncertain examples are more "educational" than stubborn errors - this is inferred from comparative results but lacks direct analysis of why one type of error is more learnable.

## Next Checks
1. **Error pattern analysis**: Take questions where entropy-based and accuracy-based weighting diverge most strongly. Manually categorize the error patterns in high-entropy vs. high-accuracy questions. Determine whether diverse wrong answers actually contain more learnable signal than consistent wrong answers.

2. **Computational efficiency study**: Compare EAST performance using n=32, n=64, and n=128 samples per question. Quantify the trade-off between entropy estimation quality and computational cost to identify the minimum viable sample count.

3. **Generalization to different model scales**: Apply EAST to both smaller (7B) and larger (70B) models on the same tasks. Test whether the optimal exponent parameter scales predictably with model capacity, or whether different optimal values emerge, indicating fundamental differences in how uncertainty manifests across scales.