---
ver: rpa2
title: 'Psycholinguistic Word Features: a New Approach for the Evaluation of LLMs
  Alignment with Humans'
arxiv_id: '2506.22439'
source_url: https://arxiv.org/abs/2506.22439
tags:
- llms
- norms
- llama-3
- words
- pearson
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel approach to evaluate LLM alignment
  with humans using psycholinguistic word norms. Instead of relying on subjective
  human evaluations or other LLM-based judging, the authors leverage existing datasets
  of human ratings for word features such as arousal, concreteness, and sensory associations.
---

# Psycholinguistic Word Features: a New Approach for the Evaluation of LLMs Alignment with Humans

## Quick Facts
- arXiv ID: 2506.22439
- Source URL: https://arxiv.org/abs/2506.22439
- Reference count: 5
- This paper proposes a novel approach to evaluate LLM alignment with humans using psycholinguistic word norms.

## Executive Summary
This paper introduces a novel approach to evaluate LLM alignment with humans using psycholinguistic word norms. Instead of relying on subjective human evaluations or other LLM-based judging, the authors leverage existing datasets of human ratings for word features such as arousal, concreteness, and sensory associations. They evaluate the alignment of several LLMs with two psycholinguistic datasets: the Glasgow norms (covering features like arousal, valence, and concreteness) and the Lancaster norms (covering sensory associations like taste and touch). The results show that alignment is generally better for the Glasgow norms than the Lancaster norms, suggesting a potential limitation of current LLMs in aligning with human sensory associations due to their lack of embodied cognition. The authors conclude that psycholinguistic norms can provide valuable insights for LLM evaluation and understanding.

## Method Summary
The paper evaluates alignment between LLMs and human ratings on psycholinguistic word norms. The authors use two datasets: Glasgow norms (5,553 English words, 7 features) and Lancaster norms (39,707 English words, 6 perceptual modalities). They prompt LLMs with original human study questions and compute two estimates: direct token output and logprob-weighted average across rating scale (preferred). The models evaluated include Llama-3.2-3B-Instruct, Llama-3.1-8B-Instruct, Llama-3.2-11B-Vision-Instruct, Gemma-2-9B-it, Yi-1.5-9B-Chat, Occiglot-7B-es-en-instruct, GPT-4o, and GPT-4o-mini. Pearson and Spearman correlation coefficients are computed between LLM estimates and human ratings for both original and rounded integer values.

## Key Results
- Alignment is generally better for the Glasgow norms than the Lancaster norms.
- This suggests a potential limitation of current LLMs in aligning with human sensory associations due to their lack of embodied cognition.
- Psycholinguistic norms can provide valuable insights for LLM evaluation and understanding.

## Why This Works (Mechanism)
The paper proposes using existing psycholinguistic word norms to evaluate LLM alignment with humans. By leveraging established datasets of human ratings for word features, the authors can objectively measure how well LLMs align with human perceptions and associations. The use of correlation coefficients between LLM estimates and human ratings provides a quantitative measure of alignment.

## Foundational Learning
1. **Psycholinguistic word norms**: Human ratings of word features such as arousal, concreteness, and sensory associations. Why needed: To evaluate LLM alignment with human perceptions. Quick check: Verify that the Glasgow and Lancaster norm datasets are properly loaded and accessible.
2. **LLM evaluation**: Assessing how well LLMs align with human ratings on various word features. Why needed: To understand LLM performance and limitations. Quick check: Ensure that all models are correctly configured and running with temperature=0.
3. **Correlation coefficients**: Statistical measures (Pearson and Spearman) to quantify the relationship between LLM estimates and human ratings. Why needed: To provide objective metrics for alignment evaluation. Quick check: Verify that correlation calculations are correctly implemented and produce expected results.

## Architecture Onboarding
**Component map**: Human ratings -> LLM prompts -> LLM outputs -> Logprob-weighted averaging -> Correlation coefficients
**Critical path**: Prompt generation -> LLM inference -> Logprob extraction -> Correlation computation
**Design tradeoffs**: Using logprob-weighted averaging vs. direct token output for more accurate LLM estimates. Relying on existing psycholinguistic norms vs. conducting new human evaluations.
**Failure signatures**: Low correlations on Lancaster sensory norms indicate potential embodied cognition gap in LLMs.
**3 first experiments**:
1. Test logprob extraction on a small sample of words across all models to ensure consistent logprob-weighted averaging.
2. Verify that prompts for all 13 features match those used in the original human studies.
3. Confirm that the exact word sets used from both norm datasets match those specified in the paper.

## Open Questions the Paper Calls Out
None

## Limitations
- The paper does not specify the exact word samples used from the Glasgow and Lancaster norms.
- Prompts for all 13 psycholinguistic features are only partially specified (two examples given).
- Logprob extraction for proprietary models like GPT-4o may vary depending on API version.

## Confidence
- **High**: The core claim that LLMs show better alignment with Glasgow norms than Lancaster norms is supported by the methodology and results.
- **Medium**: The interpretation about embodied cognition as an explanation for the pattern of results is an explanatory inference from the data.
- **Medium**: The exact numerical values of correlation coefficients are pending clarification on the exact word samples used.

## Next Checks
1. Verify the exact word sets used from both norm datasets by checking the provided repository or contacting authors.
2. Confirm that prompts for all 13 features match those used in the original human studies, either from repository or reconstruction.
3. Test logprob extraction on a small sample of words across all models to ensure consistent logprob-weighted averaging, especially for proprietary models.