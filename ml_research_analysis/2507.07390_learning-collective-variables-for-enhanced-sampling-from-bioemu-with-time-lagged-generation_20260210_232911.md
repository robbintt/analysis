---
ver: rpa2
title: Learning Collective Variables for Enhanced Sampling from BioEmu with Time-Lagged
  Generation
arxiv_id: '2507.07390'
source_url: https://arxiv.org/abs/2507.07390
tags:
- state
- folded
- simulations
- protein
- states
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents BIOEMU-CV, a framework for learning collective
  variables (CVs) from the time-lagged conditioning signals of a frozen BioEmu foundation
  model. The approach extracts low-dimensional representations from BioEmu's single
  representation conditioned on future molecular states, promoting CVs to encode slow,
  long-term dynamics while filtering fast fluctuations.
---

# Learning Collective Variables for Enhanced Sampling from BioEmu with Time-Lagged Generation

## Quick Facts
- arXiv ID: 2507.07390
- Source URL: https://arxiv.org/abs/2507.07390
- Authors: Seonghyun Park; Kiyoung Seong; Soojung Yang; Rafael Gómez-Bombarelli; Sungsoo Ahn
- Reference count: 40
- Key outcome: BIOEMU-CV learns collective variables from time-lagged conditioning of BioEmu, showing competitive performance in free energy estimation and transition path sampling for three fast-folding proteins

## Executive Summary
This work presents BIOEMU-CV, a framework that learns collective variables (CVs) from the time-lagged conditioning signals of a frozen BioEmu foundation model. By extracting low-dimensional representations from BioEmu's single representation conditioned on future molecular states, the approach promotes CVs to encode slow, long-term dynamics while filtering fast fluctuations. Extensive benchmarking on three fast-folding proteins demonstrates competitive performance in two enhanced sampling tasks: estimating free energy differences with on-the-fly probability enhanced sampling (OPES) and sampling transition paths with steered molecular dynamics (SMD).

## Method Summary
BIOEMU-CV learns collective variables by training a lightweight encoder to map high-dimensional molecular structures to low-dimensional representations, which are then used to condition a frozen BioEmu foundation model to predict future states. The method leverages time-lagged generation to filter fast fluctuations and retain slow dynamical modes. The CV encoder is trained through score matching, where BioEmu's frozen score model predicts noise in future states based on the current CV representation. This approach allows for effective enhanced sampling by biasing simulations along CVs that capture the essential slow dynamics of the system.

## Key Results
- Competitive free energy estimation performance in OPES simulations with low standard deviations and high target hit percentages (up to 100% for Chignolin)
- Effective transition path sampling with steered MD, showing physically plausible folding routes
- Interpretability through sensitivity analysis revealing CV alignment with key structural motifs like TYR1-TYR10 contacts

## Why This Works (Mechanism)

### Mechanism 1: Time-Lagged Generation Filters Fast Fluctuations
- **Claim:** Conditioning a generative model to predict a future state $x_{t+\tau}$ from a current state $x_t$ forces the intermediate representation (the CV) to discard high-frequency noise and retain only slow, persistent dynamical modes.
- **Mechanism:** The encoder must compress $x_t$ into a low-dimensional CV $c_t$. If the model is trained to reconstruct $x_{t+\tau}$ (the future) using only $c_t$, information in $x_t$ that fluctuates randomly on timescales shorter than $\tau$ provides no predictive signal for the reconstruction loss. Therefore, gradient descent suppresses these fast modes in $c_t$, leaving only the slow degrees of freedom that correlate across the time lag.
- **Core assumption:** The relevant macroscopic dynamics (e.g., folding) evolve on timescales longer than $\tau$, while non-relevant motions decorrelate within $\tau$.
- **Evidence anchors:** [abstract] "promoting CVs to encode slow, long-term dynamics while filtering fast fluctuations." [section 3] "This time-lagged reconstruction forces $c_t$ to capture the slow degree of freedom... while disregarding fast and randomly fluctuating information."
- **Break condition:** If the time lag $\tau$ is too short, the CV captures fast noise (overfitting to instantaneous fluctuations); if $\tau$ is too long, the dynamics decorrelate entirely, and the CV learns nothing.

### Mechanism 2: Leveraging Frozen Foundation Model Priors
- **Claim:** By freezing the weights of the BioEmu foundation model and training only a lightweight adapter, the method extracts effective CVs without needing to relearn the complex physics of protein structure from scratch.
- **Mechanism:** BioEmu is pre-trained on vast equilibrium ensembles and possesses a strong internal representation of valid protein conformations (single $h$ and pair $z$ representations). The CV encoder $f_\theta$ merely learns to modulate this pre-existing "structural knowledge" via the condition $c_t$ to bias the generation toward the future state. This acts as a strong regularization, ensuring the CV respects physical constraints (e.g., bond geometry) implicitly encoded in BioEmu.
- **Core assumption:** The frozen foundation model's latent space is rich enough to represent the transition dynamics required for the specific enhanced sampling task.
- **Evidence anchors:** [section 1] "we re-purpose BioEmu... train an MLCV encoder to learn the latent representations in an existing molecular foundation model." [section 3] "To keep the training lightweight, we freeze parameters $\phi$ of BioEmu, and update the encoder..."
- **Break condition:** If the target system involves rare states (e.g., specific transition states) entirely absent from the foundation model's training distribution, the frozen backbone may lack the representational capacity to generate them, rendering the CV ineffective.

### Mechanism 3: Information Bottleneck for Dimensionality Reduction
- **Claim:** Mapping high-dimensional atomic coordinates to a low-dimensional vector (1D in this work) forces the model to prioritize the most energetically relevant reaction coordinates.
- **Mechanism:** The architecture imposes a hard information bottleneck ($x_t \to c_t \in \mathbb{R}^d$ where $d \ll 3N$). To minimize the loss of predicting $x_{t+\tau}$, the model must maximize the mutual information between $c_t$ and the future state. This mathematical constraint naturally selects for the "slowest" modes, which are typically the reaction coordinates driving phase transitions.
- **Core assumption:** The essential dynamics of the system (folding/unfolding) can be described by a low-dimensional manifold (ideally 1D).
- **Evidence anchors:** [section 3] "...learn an encoder $f_\theta$ that maps the high-dimensional structure into a low-dimensional representation $c=f_\theta(x) \in \mathbb{R}^d$." [table 1] The paper fixes dimensionality to one and shows competitive performance in free energy estimation.
- **Break condition:** If the true reaction mechanism requires two or more independent coordinates (e.g., distinct intermediate states not linearly correlated), a 1D CV will fail to distinguish them, conflating distinct metastable states.

## Foundational Learning

- **Concept: Enhanced Sampling & Collective Variables (CVs)**
  - **Why needed here:** The paper targets the "timescale problem" in Molecular Dynamics (MD). Standard MD wastes time simulating fast vibrations while waiting for rare folding events. You must understand that CVs act as a "biasing coordinate" (e.g., in OPES or Metadynamics) to force the simulation to explore these rare transitions efficiently.
  - **Quick check question:** Why is a CV that captures "fast" atomic vibrations useless for accelerating protein folding simulations?

- **Concept: BioEmu (Diffusion-based Protein Generator)**
  - **Why needed here:** The method builds on BioEmu, a diffusion model. You need to understand that BioEmu generates protein structures by denoising random noise. BIOEMU-CV modifies this by saying, "Generate the structure, but keep it consistent with this specific 1D value I'm giving you."
  - **Quick check question:** In the context of BioEmu, what does the "score model" predict, and how does the adapter modify its input?

- **Concept: Time-Lagged Independent Component Analysis (TICA)**
  - **Why needed here:** TICA is the mathematical ancestor of the "time-lagged" logic used here. It finds linear combinations of features that maximize autocorrelation over a lag time $\tau$. This paper essentially creates a non-linear, deep-learning version of TICA using a diffusion model objective.
  - **Quick check question:** How does maximizing autocorrelation over a time lag $\tau$ relate to identifying "slow" degrees of freedom?

## Architecture Onboarding

- **Component map:** Atomic coordinates $x_t$ -> Encoder ($f_\theta$) -> 1D CV $c_t$ -> Adapter (MLP) -> Modified single representation $h_t$ -> Frozen BioEmu with pair representation $z$ -> Predicted future state $x_{t+\tau}$

- **Critical path:** The integration of the adapter into BioEmu's single representation stream ($h_t = \text{MLP}(h, c_t)$). If this injection does not effectively steer the frozen model, the gradients for the encoder will vanish, and the CV will not learn dynamics.

- **Design tradeoffs:**
  - **1D vs High-Dim CVs:** The paper uses 1D for visibility and simplicity. High-dim might capture more complex intermediates but complicates visualization and biasing.
  - **Frozen vs. Fine-tuned:** Freezing BioEmu ensures stability and reduces compute (only training the small encoder), but may limit adaptation to highly novel conformations not seen during BioEmu pre-training.

- **Failure signatures:**
  - **VDE Scaling Failure:** As seen in baselines, methods like VDE may fail to discriminate states in larger proteins (Table 3), outputting constant values.
  - **OPES Non-convergence:** If the CV is poor, OPES simulations will get trapped or show large standard deviations in free energy differences ($\Delta F$), indicating the bias is not flattening the effective barrier.

- **First 3 experiments:**
  1. **Chignolin OPES Recovery:** Run 1µs OPES simulation on Chignolin (smallest system). Verify if the free energy difference converges to the reference value (approx -3.7 kJ/mol) and the CV separates folded/unfolded states.
  2. **Ablation on Time Lag ($\tau$):** Train BIOEMU-CV with $\tau=0$ (instant) vs. $\tau=1000$. Compare "Sensitivity Analysis" plots; the instantaneous model should highlight noisy contacts, while the lagged model should highlight structural motifs (e.g., TYR1-TYR10).
  3. **Steered MD Trajectory:** Visualize the transition path. Check if the protein follows a physically plausible folding route or if it "teleports" through high-energy steric clashes (which would imply the CV is guiding through non-physical space).

## Open Questions the Paper Calls Out
None explicitly called out in the paper.

## Limitations
- The framework assumes the target dynamics can be represented by a 1D collective variable, which may fail for systems requiring multiple reaction coordinates
- The frozen foundation model approach limits adaptation to rare states not present in BioEmu's training distribution
- The time-lagged training objective depends critically on appropriate lag time selection, with no systematic guidance provided for different systems

## Confidence
- **High Confidence**: The core mechanism of using time-lagged conditioning to filter fast fluctuations is theoretically sound and well-supported by the training objective formulation
- **Medium Confidence**: The competitive performance on enhanced sampling tasks is demonstrated, but comparisons are limited to 2-3 baselines across 3 proteins. The generalization to larger, more complex systems remains untested
- **Low Confidence**: The claim of "scalability" is not empirically validated beyond the three small fast-folding proteins tested. The method's performance on systems with multiple intermediates or rugged free energy landscapes is unknown

## Next Checks
1. **Multi-dimensional CV validation**: Test BIOEMU-CV with 2-3 dimensional representations on a protein with multiple intermediates to verify whether the 1D assumption limits performance
2. **Foundation model bias characterization**: Systematically evaluate BIOEMU-CV on structures significantly different from BioEmu's training distribution to quantify the frozen model's representational limitations
3. **Lag time sensitivity analysis**: Conduct a systematic study varying τ across multiple orders of magnitude on a single system to identify optimal lag times and characterize the filtering behavior