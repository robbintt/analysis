---
ver: rpa2
title: An Empirical Study of Sample Selection Strategies for Large Language Model
  Repair
arxiv_id: '2510.20428'
source_url: https://arxiv.org/abs/2510.20428
tags:
- repair
- saps
- selection
- data
- sample
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of efficiently repairing toxic
  behaviors in large language models (LLMs) while preserving general capabilities.
  The authors systematically evaluate five sample selection strategies for behavioral
  repair, including random sampling, K-Center, gradient-norm-based selection (GraNd),
  stratified coverage (CCS), and a novel Semantic-Aware Prioritized Sampling (SAPS)
  method that targets boundary samples in semantic space.
---

# An Empirical Study of Sample Selection Strategies for Large Language Model Repair

## Quick Facts
- arXiv ID: 2510.20428
- Source URL: https://arxiv.org/abs/2510.20428
- Authors: Xuran Li; Jingyi Wang
- Reference count: 40
- One-line primary result: Semantic-Aware Prioritized Sampling (SAPS) achieves the best balance between detoxification, utility preservation, and efficiency in LLM behavioral repair

## Executive Summary
This study systematically evaluates five sample selection strategies for repairing toxic behaviors in large language models while preserving general capabilities. The authors introduce SAPS, a novel boundary-aware sampling method that targets semantic space extremes, and compare it against established approaches like random sampling, K-Center, gradient-norm-based selection, and stratified coverage. Experiments across four model sizes (0.8B-2.8B parameters) and five repair methods demonstrate that sample selection strategy significantly impacts repair effectiveness, with SAPS achieving superior performance with substantially less data than traditional approaches.

The research establishes sample selection as a tunable component in repair pipelines, showing that optimal strategies depend on model scale and repair method. SAPS proves particularly effective for continued pre-training approaches, while larger models achieve strong results with simpler random selection. The findings provide concrete guidance for developing efficient, targeted repair approaches that maintain LLM reliability without requiring full retraining.

## Method Summary
The study evaluates five sample selection strategies combined with five behavioral repair methods on detoxification tasks. Selection strategies include random sampling, K-Center, gradient-norm-based selection (GraNd), stratified coverage (CCS), and the novel Semantic-Aware Prioritized Sampling (SAPS). SAPS operates by embedding samples, applying dimensionality reduction, clustering into groups, and selecting boundary samples farthest from cluster centroids. Repair methods tested include DAPT, DAPT+KL, DPO, IRepair, and IRepair+KL. The evaluation uses a detoxification dataset for repair, RealToxicityPrompts for toxicity measurement, and WikiText-2/LAMBADA for perplexity assessment across four model sizes (GPT-2 Large, GPT-2 XL, GPT-Neo, Pythia).

## Key Results
- SAPS achieves the best balance between detoxification, utility preservation, and efficiency, delivering comparable or superior repair outcomes with substantially less data
- Selection strategy significantly impacts repair effectiveness, with methods like DAPT showing high sensitivity to sample composition while DPO remains more robust
- Computational efficiency varies dramatically across strategies, with lightweight approaches like SAPS and random sampling proving practical alternatives to expensive methods like CCS and GraNd
- Optimal strategies depend on model scale and repair method, with boundary-aware sampling particularly effective for continued pre-training approaches

## Why This Works (Mechanism)
Sample selection strategies improve repair efficiency by targeting the most informative samples for behavioral correction. Boundary-aware sampling through SAPS identifies samples that represent extremes in semantic space, which are likely to be most influential in shifting model behavior during fine-tuning. By focusing on these critical samples rather than the full dataset, repair processes can achieve comparable detoxification results with significantly less computational cost. The effectiveness varies by repair method because different approaches respond differently to sample composition - some are more sensitive to boundary cases while others maintain robustness across varied sampling strategies.

## Foundational Learning

**LLM behavioral repair fundamentals** - Understanding how fine-tuning modifies model behavior to eliminate toxic outputs while preserving capabilities. Why needed: The entire study builds on this core capability. Quick check: Can the model produce both safe and contextually appropriate outputs after repair?

**Sample selection theory** - The principle that not all training samples contribute equally to learning objectives. Why needed: Justifies the research focus on efficient data selection rather than full dataset processing. Quick check: Does the selected subset achieve comparable results to full dataset training?

**Semantic space representation** - How text samples can be embedded and clustered to identify boundaries and extremes. Why needed: Core to SAPS methodology for identifying informative samples. Quick check: Are boundary samples correctly identified in the reduced dimensional space?

**Evaluation metrics for repair** - RPS, RES, and OPS scores that balance toxicity reduction against utility preservation. Why needed: These metrics enable quantitative comparison of selection strategies. Quick check: Do selected strategies show improvement across all three metrics simultaneously?

## Architecture Onboarding

**Component map**: Base Model <- Selection Strategy -> Repair Method -> Evaluation Pipeline

**Critical path**: Sample selection (SAPS) → behavioral fine-tuning → toxicity evaluation → utility assessment → performance scoring

**Design tradeoffs**: SAPS provides superior performance but requires embedding computation overhead; random sampling is fastest but may miss critical boundary cases; CCS and GraNd offer good performance but with high computational cost

**Failure signatures**: 
- Performance degradation with wrong α/boundary ratio (sweeping 30-90% α fixes this)
- Excessive selection overhead (>100s for CCS/GraNd indicates inefficient implementation)
- Toxicity/PPL imbalance suggests selection strategy doesn't match repair method requirements

**First experiments**:
1. Implement SAPS with sentence-transformers, PCA/UMAP, K-means and verify ~1-10s selection time
2. Run SAPS + DAPT on GPT-2 Large with α=50% and compare RPS to random sampling baseline
3. Sweep α from 30-90% to identify optimal boundary ratio for specific model/repair combination

## Open Questions the Paper Calls Out

**Generalization to other behavioral repair tasks** - The framework could extend to domains like reducing social bias, improving factual accuracy, or instruction-following capability. The current study's exclusive focus on detoxification limits confidence in broader applicability.

**Automated strategy selection framework** - A system that automatically recommends or combines strategies based on model scale, architecture, repair objectives, and computational budget would significantly lower practical deployment barriers.

**Transfer to extremely large-scale models** - The findings may not directly extend to encoder-decoder models or models with hundreds of billions of parameters, as experiments were limited to 0.8B-2.8B decoder-only models.

**Sensitivity to embedding encoder choice** - SAPS performance may vary significantly with different embedding models, and task-specific encoders might improve selection quality for specific repair objectives.

## Limitations

**Reproducibility gaps in SAPS implementation** - Critical implementation details including embedding encoder, dimensionality reduction parameters, and clustering configuration are not specified, creating uncertainty in reproducing exact results.

**Limited model diversity and scale** - Experiments cover only 0.8B-2.8B parameters, limiting confidence in findings for larger models where random sampling may be more effective according to the paper's claims.

**Dataset accessibility and potential selection bias** - The detoxification dataset may have restricted access, and the RealToxicityPrompts challenge subset of 50 prompts may not provide sufficient statistical power for reliable evaluation.

## Confidence

**High confidence**: The core finding that sample selection strategy significantly impacts repair effectiveness and efficiency is well-supported across multiple models and repair methods.

**Medium confidence**: The recommendation that SAPS provides the best balance between detoxification, utility preservation, and efficiency is supported but may be sensitive to implementation details not fully specified.

**Low confidence**: The generalizability of findings to larger models (>2.8B parameters) and different domains is not established, as the study focuses exclusively on toxicity detoxification.

## Next Checks

1. **Implement and validate SAPS with specified hyperparameters** - Reproduce the SAPS method using the exact embedding encoder, dimensionality reduction target, and clustering parameters. Compare results against the paper's reported RPS, RES, and OPS scores to verify implementation accuracy and assess sensitivity to these choices.

2. **Test random sampling on larger models** - Evaluate the effectiveness of random sampling for behavioral repair on models significantly larger than those tested (e.g., 10B+ parameters). This validates the claim about random sampling's effectiveness for larger models and tests the scalability of findings.

3. **Cross-domain applicability study** - Apply the sample selection strategies to a different behavioral repair task (e.g., factuality correction, stereotype mitigation) using similar experimental methodology. This tests whether the relative performance of selection strategies generalizes beyond toxicity detoxification.