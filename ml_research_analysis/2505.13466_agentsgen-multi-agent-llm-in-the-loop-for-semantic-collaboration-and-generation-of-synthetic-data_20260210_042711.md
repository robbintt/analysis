---
ver: rpa2
title: 'AgentSGEN: Multi-Agent LLM in the Loop for Semantic Collaboration and GENeration
  of Synthetic Data'
arxiv_id: '2505.13466'
source_url: https://arxiv.org/abs/2505.13466
tags:
- scene
- generation
- agent
- data
- synthetic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses the challenge of generating semantically rich
  synthetic data for safety-critical applications, particularly construction safety
  scenarios like blocked fire exits, where real-world data is scarce and difficult
  to collect. The proposed method, AgentSGEN, employs a multi-agent framework that
  iteratively refines 3D scenes using two LLM-driven agents: an Evaluator Agent (System
  2) for high-level reasoning and semantic constraint planning, and an Editor Agent
  (System 1) for low-level, reactive scene editing.'
---

# AgentSGEN: Multi-Agent LLM in the Loop for Semantic Collaboration and GENeration of Synthetic Data

## Quick Facts
- arXiv ID: 2505.13466
- Source URL: https://arxiv.org/abs/2505.13466
- Reference count: 31
- Key outcome: Multi-agent LLM framework generates semantically rich synthetic safety scenes, achieving Likert scores above 4.5/7 for blocking effectiveness and arrangement in construction safety scenarios

## Executive Summary
AgentSGEN addresses the challenge of generating semantically rich synthetic data for safety-critical applications, particularly construction safety scenarios like blocked fire exits, where real-world data is scarce and difficult to collect. The proposed method employs a multi-agent framework that iteratively refines 3D scenes using two LLM-driven agents: an Evaluator Agent (System 2) for high-level reasoning and semantic constraint planning, and an Editor Agent (System 1) for low-level, reactive scene editing. The framework integrates symbolic scene graphs with visual rendering for precise, constraint-aware scene generation. Evaluations using 53 indoor scenes show that AgentSGEN with collision checking achieved average Likert scores above 4.5 out of 7 for blocking effectiveness, arrangement, and scale appropriateness, significantly outperforming the Holodeck baseline (near minimum scores).

## Method Summary
AgentSGEN is a multi-agent framework that generates semantically rich synthetic data for safety-critical applications through iterative refinement of 3D scenes. The system employs two complementary LLM-driven agents: an Evaluator Agent (System 2) that performs high-level semantic reasoning and constraint planning, and an Editor Agent (System 1) that executes low-level, reactive scene editing. The framework integrates symbolic scene graphs with visual rendering to enable precise, constraint-aware scene generation. The approach was evaluated using 53 indoor construction safety scenes, with human annotators and LLM-based evaluations (GPT-4.1, Gemini 2.5 Pro) assessing blocking effectiveness, arrangement, and scale appropriateness. Collision checking was incorporated to improve physical plausibility, resulting in significant performance improvements over baseline methods.

## Key Results
- AgentSGEN achieved average Likert scores above 4.5 out of 7 for blocking effectiveness, arrangement, and scale appropriateness in construction safety scenes
- The method significantly outperformed the Holodeck baseline, which scored near minimum values across all evaluation metrics
- Human annotator agreement was moderate (κ = 0.406), while LLM-based evaluations corroborated the findings and favored AgentSGEN for goal alignment

## Why This Works (Mechanism)
The framework works by combining complementary cognitive systems: System 1 (Editor Agent) provides fast, reactive scene editing capabilities while System 2 (Evaluator Agent) offers deliberate, high-level semantic reasoning. This dual-system approach enables the framework to iteratively refine scenes by first identifying semantic gaps and constraints through reasoning, then executing precise modifications to address those gaps. The integration of symbolic scene graphs with visual rendering allows for both abstract semantic understanding and concrete visual representation, ensuring that generated scenes are both semantically meaningful and perceptually realistic.

## Foundational Learning
1. **Multi-agent collaborative reasoning** - Why needed: Enables decomposition of complex scene generation tasks into specialized reasoning and editing functions. Quick check: Can be verified by observing how agents coordinate to improve scene quality over iterations.
2. **Symbolic scene graph integration** - Why needed: Provides structured semantic representation for precise constraint handling. Quick check: Scene elements maintain consistent relationships and properties across editing operations.
3. **LLM-driven iterative refinement** - Why needed: Allows progressive improvement of generated scenes through multiple reasoning and editing cycles. Quick check: Scene quality metrics show monotonic improvement across refinement iterations.
4. **Human-in-the-loop evaluation** - Why needed: Validates generated scenes against real-world safety requirements and perceptual quality standards. Quick check: Human ratings correlate with objective safety metrics and LLM assessments.

## Architecture Onboarding

### Component Map
Scene Generator -> Evaluator Agent (System 2) -> Editor Agent (System 1) -> Visual Renderer -> Collision Checker -> Final Scene Output

### Critical Path
1. Scene initialization with semantic constraints
2. Evaluator Agent analysis and constraint planning
3. Editor Agent execution of scene modifications
4. Visual rendering and collision checking
5. Iterative refinement until convergence

### Design Tradeoffs
- Symbolic vs. neural representations: Symbolic scene graphs provide precise semantic control but may lack the flexibility of learned representations
- Human vs. automated evaluation: Human ratings ensure perceptual quality but introduce variability and scalability limitations
- Iterative vs. one-shot generation: Iterative refinement improves quality but increases computational cost and latency

### Failure Signatures
- Agent disagreement leading to oscillation between conflicting modifications
- Semantic constraints that cannot be satisfied given scene geometry
- LLM model drift causing inconsistent reasoning across iterations
- Collision checking failing to detect complex interpenetrations

### First Experiments to Run
1. Baseline comparison without collision checking to quantify its impact on scene quality
2. Single-agent variant to isolate the contribution of the multi-agent architecture
3. Cross-domain validation with non-construction safety scenarios to test generalizability

## Open Questions the Paper Calls Out
None identified in the provided material.

## Limitations
- Narrow domain focus on construction safety scenarios with only 53 indoor scenes evaluated, limiting generalizability to other safety-critical contexts
- Moderate human annotator agreement (κ = 0.406) indicates substantial inter-rater variability that may affect reliability of subjective assessments
- Dependence on specific LLM models (GPT-4.1, Gemini 2.5 Pro) introduces potential bias and raises questions about performance with alternative models or future LLM versions

## Confidence
- High confidence in the technical framework and multi-agent architecture design
- Medium confidence in the quantitative evaluation results due to moderate inter-annotator agreement
- Medium confidence in the comparative performance claims relative to Holodeck baseline
- Low confidence in generalizability beyond construction safety scenarios

## Next Checks
1. Conduct cross-domain validation testing AgentSGEN on safety scenarios from healthcare, manufacturing, or transportation to assess generalizability
2. Implement objective physical simulation metrics beyond collision checking to evaluate safety compliance more comprehensively
3. Perform longitudinal studies with multiple LLM model versions to assess robustness and potential model drift effects on generated scene quality