---
ver: rpa2
title: Speech Recognition for Automatically Assessing Afrikaans and isiXhosa Preschool
  Oral Narratives
arxiv_id: '2501.06478'
source_url: https://arxiv.org/abs/2501.06478
tags:
- speech
- data
- adult
- child
- isixhosa
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study develops automatic speech recognition (ASR) systems
  for stories told by Afrikaans and isiXhosa preschool children aged 4-5. The authors
  address the challenge of ASR for young children's spontaneous speech in low-resource
  languages, where only 5 minutes of transcribed in-domain data is available.
---

# Speech Recognition for Automatically Assessing Afrikaans and isiXhosa Preschool Oral Narratives

## Quick Facts
- arXiv ID: 2501.06478
- Source URL: https://arxiv.org/abs/2501.06478
- Reference count: 40
- This study develops ASR systems for stories told by Afrikaans and isiXhosa preschool children aged 4-5 with only 5 minutes of transcribed data.

## Executive Summary
This study develops automatic speech recognition (ASR) systems for stories told by Afrikaans and isiXhosa preschool children aged 4-5. The authors address the challenge of ASR for young children's spontaneous speech in low-resource languages, where only 5 minutes of transcribed in-domain data is available. Using Whisper as a base model, they explore various strategies including parameter-efficient fine-tuning, adult speech incorporation (both out-of-domain and in-domain), voice conversion, and semi-supervised learning. Their results show that in-domain adult speech provides the biggest improvement, especially when combined with voice conversion. Semi-supervised learning also helps, while parameter-efficient fine-tuning shows mixed results. The best combined system achieves WERs of 29.8% (Afrikaans) and 62.1% (isiXhosa) on development data, within 12% of the topline system using more than 3 hours of labelled data.

## Method Summary
The authors use Whisper small/medium as a base model and fine-tune on extremely limited data (5 minutes per language) from spontaneous oral narratives by 4-5-year-old children. They explore several strategies to improve performance: parameter-efficient fine-tuning with LoRA adapters, incorporating adult speech data (both out-of-domain NCHLT corpus and in-domain adult speech reading narrative transcripts), voice conversion using kNN-VC with cross-lingual child reference, and semi-supervised learning with quality-filtered pseudo-labels. The best system combines in-domain adult speech with voice conversion and semi-supervised learning, achieving WERs of 29.8% for Afrikaans and 62.1% for isiXhosa on development data.

## Key Results
- Best combined system achieves WERs of 29.8% (Afrikaans) and 62.1% (isiXhosa) on development data
- In-domain adult speech provides the biggest improvement, reducing WER from 47.4% to 33.7% (Afrikaans) and 80.4% to 70.2% (isiXhosa)
- Voice conversion improves results by 2-3% absolute when applied to in-domain adult speech
- Semi-supervised learning with quality-filtered pseudo-labels improves performance despite high initial WER
- LoRA fine-tuning helps Afrikaans but hurts isiXhosa performance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** In-domain adult speech improves child ASR when labeled child data is extremely limited.
- **Mechanism:** Adults reading transcripts from the target narrative domain provide linguistic patterns (vocabulary, syntax, story structure) that transfer to child speech recognition, even though acoustics differ. The model learns domain-specific language models implicitly.
- **Core assumption:** The linguistic overlap between adult and child narratives compensates for acoustic mismatch.
- **Evidence anchors:** [abstract] "additional in-domain adult data (adult speech matching the story domain) provides the biggest improvement"; [section IV-C] Adding 30 minutes of in-domain adult data reduced WER from 47.4% to 33.7% (Afrikaans) and 80.4% to 70.2% (isiXhosa); [corpus] Limited corpus support; related paper on Arabic children's ASR also notes severe data scarcity for low-resource languages
- **Break condition:** Benefit diminishes when more in-domain child data becomes available (authors note topline results did not improve with adult speech).

### Mechanism 2
- **Claim:** Voice conversion (VC) helps only when applied to linguistically matched data.
- **Mechanism:** kNN-VC converts adult speech acoustics toward child-like characteristics using reference child speech from another language (cross-lingual VC). This reduces acoustic mismatch while preserving linguistic content—but only works when the source adult speech shares the target domain.
- **Core assumption:** Acoustic characteristics can be transferred cross-lingually without degrading linguistic content.
- **Evidence anchors:** [abstract] "especially when coupled with voice conversion"; [section IV-D] Converting in-domain adult speech improved WER by 2-3% absolute; converting out-of-domain adult speech showed no gain; [corpus] Zhang et al. (2024, related) found VC improvements are "setting-specific"
- **Break condition:** VC fails when linguistic mismatch is large; also, simply augmenting child data with VC to other child voices gave no improvement.

### Mechanism 3
- **Claim:** Semi-supervised learning with quality-filtered pseudo-labels improves performance despite high initial WER.
- **Mechanism:** A 5-minute fine-tuned model generates pseudo-labels for untranscribed in-domain child speech. Filtering by log-likelihood scores retains higher-quality predictions. The expanded training set provides more acoustic diversity.
- **Core assumption:** Pseudo-labels from an 80% WER model still contain useful signal after filtering.
- **Evidence anchors:** [abstract] "Semi-supervised learning also helps for both languages"; [section IV-E] Top 1-hour of pseudo-labels improved isiXhosa WER from 80.4% to 74.5% despite the labeling model's poor accuracy; [corpus] Related work (Wang et al., Interspeech 2021) used similar semi-supervised approaches for low-resource child ASR
- **Break condition:** Performance degrades when using more than ~1 hour of pseudo-labels (noise overwhelms signal).

## Foundational Learning

- **Concept: Whisper encoder-decoder architecture with implicit language model**
  - Why needed here: Understanding that Whisper's decoder contains learned linguistic priors helps explain why it outperforms XLSR+external LM and why language token selection matters (Swahili token for isiXhosa).
  - Quick check question: What happens if you select an unrelated language token for a low-resource language?

- **Concept: Parameter-efficient fine-tuning (LoRA)**
  - Why needed here: The paper shows LoRA improves Afrikaans but hurts isiXhosa—understanding why requires knowing LoRA freezes original weights and only updates low-rank decompositions.
  - Quick check question: Why might LoRA hurt performance on languages underrepresented in the base model?

- **Concept: WER vs CER for agglutinative languages**
  - Why needed here: isiXhosa's agglutinative morphology causes higher WER penalty; CER shows smaller gap (27.9% vs 34.0%), informing metric selection.
  - Quick check question: For an agglutinative language, which metric better reflects actual usability?

## Architecture Onboarding

- **Component map:** Whisper small/medium (frozen or full fine-tuning) -> LoRA adapters (optional) -> Voice conversion (kNN-VC) -> Pseudo-label filtering (log-likelihood thresholding)

- **Critical path:** 1. Fine-tune Whisper on out-of-domain adult (NCHLT) -> transfer learning baseline; 2. Fine-tune further on pooled: 5m child + 30m in-domain adult + 30m VC-converted adult; 3. Generate pseudo-labels -> filter by likelihood -> retrain

- **Design tradeoffs:**
  - LoRA: computational savings vs potential harm for underrepresented languages
  - VC: 2-3% WER gain vs added complexity and need for reference child speech
  - Pseudo-label amount: more data vs noise accumulation (optimal ~1 hour)

- **Failure signatures:**
  - isiXhosa WER >100%: model not exposed to language; check language token
  - LoRA worse than full fine-tuning: underrepresented language—use full fine-tuning
  - VC no improvement: check linguistic domain match of source speech
  - Overfitting with 5-minute data: monitor dev WER; apply early stopping
  - Repetitive hallucinations from child stuttering: confirm length penalty (-0.5) is applied

- **First 3 experiments:**
  1. Establish baseline: fine-tune Whisper-medium on 5m child only; report WER and CER for both languages.
  2. Ablate in-domain adult: add 5m, 15m, 30m in-domain adult; plot WER curve to find saturation point.
  3. Test VC on in-domain only: convert 30m in-domain adult, train with/without conversion; verify 2-3% improvement holds.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the noisy transcripts produced by these ASR systems (with WERs between 30-60%) be reliably used to automate oral narrative assessment scores?
- Basis in paper: [explicit] The conclusion states that "Future work will investigate this in a full oral narrative assessment system" and notes that while WERs are high, previous studies suggest insights can still be extracted.
- Why unresolved: This study focused entirely on optimizing the ASR component (transcription); it did not implement or evaluate the subsequent step of scoring the child's narrative ability based on those transcripts.
- What evidence would resolve it: A study correlating automated assessment scores derived from the ASR transcripts against human expert scores on the same narratives.

### Open Question 2
- Question: Why does parameter-efficient fine-tuning (LoRA) fail for isiXhosa (an under-represented language) while succeeding for Afrikaans?
- Basis in paper: [inferred] The authors observe in Section IV.A that LoRA helps Afrikaans but hurts isiXhosa performance. They suggest this highlights the need for "particular strategies when dealing with under-represented languages" but do not determine the root cause.
- Why unresolved: The paper identifies the divergence in performance but leaves the mechanism—whether it is Whisper's pre-training bias or the language's morphological complexity—as an open point of investigation.
- What evidence would resolve it: An ablation study applying LoRA to multiple under-represented vs. well-represented language pairs to isolate whether the failure is specific to isiXhosa's lack of representation in the base model.

### Open Question 3
- Question: Is the strategy of using in-domain adult speech robust if the assumption of having perfect matching text transcriptions is removed?
- Basis in paper: [inferred] Section IV.C notes that the analysis is "idealised" because it assumes the availability of text corresponding to child oral narratives for adults to read, which may not always be easier to obtain than child recordings.
- Why unresolved: The efficacy of this best-performing strategy was validated only in an idealized scenario where the adult speech perfectly matched the target domain text.
- What evidence would resolve it: Experiments evaluating the degradation in WER when adult speech is recorded from loosely related or out-of-domain text rather than exact narrative transcriptions.

## Limitations

- The proprietary in-domain adult speech data is central to the main finding but cannot be independently verified
- The 5-minute child speech subset selection is not specified, creating potential variability in baseline establishment
- The semi-supervised learning results show improvement with 1 hour of pseudo-labels but degrade with more, yet the paper does not provide clear guidance on optimal filtering thresholds

## Confidence

**High Confidence:** The baseline finding that extremely limited data (5 minutes) produces poor WER (>80%) is well-supported and expected. The observation that full fine-tuning outperforms LoRA for isiXhosa, while LoRA helps Afrikaans, is reproducible given the known limitations of parameter-efficient methods for underrepresented languages.

**Medium Confidence:** The claim that in-domain adult speech provides the largest improvement relies on non-public data. While the magnitude of improvement (14.7% absolute for Afrikaans) is reported, independent verification is impossible without access to the specific recordings. The voice conversion results showing 2-3% improvement for in-domain adult speech are plausible but depend on the quality of the cross-lingual reference corpus and kNN-VC implementation details not fully specified.

**Low Confidence:** The semi-supervised learning results showing improvement with 1 hour of filtered pseudo-labels are promising but highly sensitive to the filtering threshold and selection criteria, which are not precisely defined. The comparison to the topline system using >3 hours of labeled data is illustrative but may not reflect real-world low-resource constraints where such data is unavailable.

## Next Checks

1. **Reproduce baseline with publicly available data only:** Using only the 5-minute child speech subset and NCHLT adult corpus, establish baseline WER for both languages. Verify that isiXhosa performance is substantially worse than Afrikaans (expect >80% WER) and that using the Swahili language token is necessary for reasonable performance.

2. **Test in-domain adult speech effect with proxy data:** Since the actual in-domain adult recordings are unavailable, simulate this condition by having adult speakers read narrative transcripts from the excluded training set in both languages. Measure WER improvement when adding 30 minutes of this proxy data to the 5-minute child subset, expecting 10-15% absolute improvement for Afrikaans and 8-12% for isiXhosa.

3. **Validate voice conversion impact:** Apply kNN-VC to convert the proxy in-domain adult speech toward child-like acoustics using the provided English child speech reference. Fine-tune on converted speech and measure WER improvement. Expect 2-3% absolute improvement only when converting in-domain speech, with no improvement for out-of-domain adult speech conversion.