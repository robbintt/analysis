---
ver: rpa2
title: On the Convergence of Jacobian-Free Backpropagation for Optimal Control Problems
  with Implicit Hamiltonians
arxiv_id: '2602.00921'
source_url: https://arxiv.org/abs/2602.00921
tags:
- control
- optimal
- implicit
- convergence
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work establishes convergence guarantees for Jacobian-Free
  Backpropagation (JFB) in stochastic minibatch training for optimal control problems
  with implicit Hamiltonians. The key challenge is that standard value function-based
  methods require solving a maximization problem that often lacks a closed-form solution,
  making training computationally expensive.
---

# On the Convergence of Jacobian-Free Backpropagation for Optimal Control Problems with Implicit Hamiltonians

## Quick Facts
- arXiv ID: 2602.00921
- Source URL: https://arxiv.org/abs/2602.00921
- Reference count: 40
- Key outcome: JFB-based SGD converges to stationary points for optimal control with implicit Hamiltonians despite biased gradient estimates, enabling scalable training for 100-agent problems

## Executive Summary
This work establishes convergence guarantees for Jacobian-Free Backpropagation (JFB) in stochastic minibatch training for optimal control problems with implicit Hamiltonians. The key challenge is that standard value function-based methods require solving a maximization problem that often lacks a closed-form solution, making training computationally expensive. JFB circumvents this by using a zeroth-order approximation of the Jacobian, enabling scalable training without storing intermediate fixed-point iterations. The authors prove that JFB-based SGD converges to stationary points under smoothness, contractivity, and variance assumptions, despite JFB producing biased gradient estimates.

## Method Summary
The method trains value function networks for optimal control with implicit Hamiltonians by using Jacobian-Free Backpropagation (JFB) to avoid costly Jacobian inversions. The control law is defined as a fixed point u*_θ = T_θ(u*_θ; t, z) satisfying the Hamiltonian maximization condition. JFB approximates the implicit differentiation by replacing the Jacobian inverse (I - ∂T_θ/∂u)^{-1} with the identity matrix, requiring only ∂T_θ/∂θ. The framework is analyzed theoretically and empirically validated on quadrotor control tasks, showing comparable control objectives with substantially less memory and computation than automatic differentiation or CVXPYLayers.

## Key Results
- Proves convergence of JFB-based SGD to stationary points under contractivity and variance assumptions
- Demonstrates JFB produces descent directions despite systematic bias through positive gradient alignment
- Achieves 10-100x memory reduction compared to automatic differentiation while maintaining comparable control objectives
- Scales to 100-agent problems (quadrotor swarms, consumption savings, bicycle control) where traditional methods fail

## Why This Works (Mechanism)

### Mechanism 1
JFB produces descent directions despite using a systematically biased gradient approximation. The key insight is that under contractivity (γ < 1 for the fixed-point operator T_θ), the true Jacobian J_θ = I - ∂T_θ/∂u has eigenvalues bounded in (1-γ, 1+γ), so the identity matrix remains a reasonable approximation. Lemma 4.7 proves that the inner product ⟨E_x[v_θ,x], E_x[w_θ,x]⟩ ≥ δ_θ² ≥ 0, showing JFB updates are positively aligned with true gradients in expectation.

### Mechanism 2
Biased SGD with JFB converges to stationary points under variance-controlled minibatch sampling. The variance bound (Assumption 4.5) controls noise relative to mean gradient magnitude. Combined with the alignment lemmas, this ensures the expected descent term dominates the second-order Taylor expansion error term in Lemma 4.9.

### Mechanism 3
Constant memory scaling enables application to 100-agent problems infeasible with automatic differentiation. JFB requires only ∂T_θ/∂θ (single operator Jacobian-vector product) rather than storing all intermediate fixed-point iterations. Standard AD through unrolled iterations requires O(K · dim) memory for K iterations; JFB achieves O(dim) memory regardless of iteration count.

## Foundational Learning

- **Implicit differentiation via fixed-point equations**: Why needed here - The optimal control u*_θ is defined as a fixed point satisfying u* = T_θ(u*; t, z); differentiating through this requires solving (I - ∂T_θ/∂u)^{-1} ∂T_θ/∂θ. Quick check: Given a fixed-point equation u = T(u; θ), what is ∂u/∂θ?
- **Pontryagin Maximum Principle and Hamiltonian structure**: Why needed here - The control problem couples state dynamics ż_x and adjoint dynamics ṗ_x through the Hamiltonian H(t, z, p, u) = -⟨p, f⟩ - L; the adjoint encodes value function gradient information. Quick check: How does the adjoint variable p_x(t) relate to the value function φ(t, z) along optimal trajectories?
- **Contraction mappings and Banach fixed-point theorem**: Why needed here - Contractivity of T_θ guarantees both (1) unique fixed points exist and (2) the JFB approximation error is bounded by the contraction factor γ. Quick check: If ‖T_θ(u₁) - T_θ(u₂)‖ ≤ γ‖u₁ - u₂‖ with γ = 0.9, what bound can you place on ‖J_θ - I‖?

## Architecture Onboarding

- **Component map**: Value function network ϕ_θ → Fixed-point operator T_θ → ODE integration → Loss J_x(θ) → JFB gradient → SGD update
- **Critical path**: Value network parameters θ → fixed-point solve for u*_θ → ODE integration → loss J_x(θ) → JFB gradient ∂T_θ^T h_θ,x/∂θ → SGD update
- **Design tradeoffs**: Larger fixed-point iteration counts improve control accuracy but increase forward-pass time (memory unaffected); Contractivity can be encouraged via smaller gradient step sizes in T_θ, but this slows fixed-point convergence; Minibatch size trades variance reduction against memory/compute per iteration
- **Failure signatures**: Loss divergence or oscillation - check if ‖∇_u T_θ‖ < 1 (contractivity); Gradient magnitude explosion - verify boundedness assumptions; Memory still growing - confirm intermediate fixed-point states are detached from computational graph
- **First 3 experiments**: 1) Contractivity verification: log ‖∇_u T_θ‖ per minibatch throughout training; confirm values remain below 1; 2) Gradient alignment check: compute angle between E_x[∇_θ J_x] and E_x[d^JFB_x]; verify it stays in [0, π/2); 3) Scalability benchmark: compare JFB vs AD vs CVXPYLayers on 1, 6, and 20 quadrotors; measure loss vs wall-clock time and peak GPU memory

## Open Questions the Paper Calls Out

### Open Question 1
Can JFB-based SGD convergence guarantees be extended to non-contractive or averaged operators, particularly when the Hamiltonian H is only locally concave rather than strongly concave? The current analysis critically depends on contractivity (Assumption 4.1), which may fail for sophisticated optimization schemes or locally concave Hamiltonians.

### Open Question 2
Can the convergence analysis be relaxed to accommodate cases where u*_θ corresponds to a local (rather than global) maximizer of the Hamiltonian H? Current proofs implicitly assume global maximizers through the contractivity structure, but many practical control problems only admit local optima.

### Open Question 3
Can the JFB framework be extended to mean-field control and mean-field game settings while preserving scalability advantages? Mean-field settings introduce additional coupling between agent distributions and value functions that may violate current assumptions.

## Limitations
- Convergence analysis requires technical conditions (contractivity, boundedness, variance control) that may not hold for all Hamiltonian optimization problems
- Memory efficiency claim assumes T_θ can be implemented differentiably without storing large intermediates
- Empirical results are demonstrated on a limited set of control tasks with unspecified network architectures and hyperparameters

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Memory-efficiency mechanism | High |
| Convergence guarantees | Medium |
| Exact empirical replication | Low |

## Next Checks
1. Verify contractivity bounds during training on a simple quadrotor task by logging ‖∇_u T_θ‖ per minibatch (should stay < 1)
2. Compare JFB vs full implicit differentiation gradients periodically to confirm alignment in [0, π/2)
3. Benchmark memory usage of JFB vs AD vs CVXPYLayers across 1, 6, and 20-agent quadrotor problems to identify the crossover point where AD becomes infeasible