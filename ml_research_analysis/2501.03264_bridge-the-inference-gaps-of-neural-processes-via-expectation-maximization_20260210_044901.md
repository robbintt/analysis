---
ver: rpa2
title: Bridge the Inference Gaps of Neural Processes via Expectation Maximization
arxiv_id: '2501.03264'
source_url: https://arxiv.org/abs/2501.03264
tags:
- functional
- prior
- points
- context
- si-nps
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses underfitting in neural processes (NPs) by analyzing
  their optimization objectives and proposing a novel method, Self-normalized Importance
  weighted Neural Process (SI-NP), based on variational expectation maximization.
  SI-NP optimizes a surrogate function of the target log-likelihood, avoiding the
  inference suboptimality of vanilla NPs.
---

# Bridge the Inference Gaps of Neural Processes via Expectation Maximization

## Quick Facts
- arXiv ID: 2501.03264
- Source URL: https://arxiv.org/abs/2501.03264
- Authors: Qi Wang; Marco Federici; Herke van Hoof
- Reference count: 40
- Key outcome: SI-NP addresses underfitting in neural processes by optimizing a variational EM surrogate objective with self-normalized importance sampling, outperforming CNP and ML-NP on synthetic and image completion tasks while maintaining uncertainty quantification.

## Executive Summary
This paper addresses underfitting in neural processes by analyzing their optimization objectives and proposing a novel method, Self-normalized Importance weighted Neural Process (SI-NP), based on variational expectation maximization. SI-NP optimizes a surrogate function of the target log-likelihood, avoiding the inference suboptimality of vanilla NPs. Experimental results demonstrate that SI-NP outperforms other NP objectives, including conditional NPs (CNPs) and Monte Carlo maximum likelihood NPs (ML-NPs), on synthetic regression tasks with various kernels (Matern-5/2, RBF, Periodic) and image completion tasks (MNIST, FMNIST, SVHN, CIFAR10).

## Method Summary
SI-NP reformulates neural process training as a variational expectation maximization problem. Instead of maximizing the approximate ELBO used in vanilla NPs, SI-NP introduces a surrogate objective that guarantees monotonic improvement of the meta-dataset log-likelihood. The method uses self-normalized importance sampling to approximate the intractable E-step, sampling latent variables from the functional prior and weighting them by their importance. This approach eliminates the "consistent regularizer" that causes suboptimal inference in standard neural processes while maintaining tractable optimization.

## Key Results
- SI-NP outperforms CNP and ML-NP baselines on synthetic regression tasks with Matern-5/2, RBF, and Periodic kernels
- Achieves state-of-the-art performance on image completion tasks (MNIST, FMNIST, SVHN, CIFAR10) when augmented with attention networks
- Learned functional prior shows positive correlation with semantic complexity, exhibiting higher uncertainty for more complex datasets
- Maintains uncertainty quantification while avoiding the prior collapse that affects simpler NP variants

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Replacing the approximate ELBO with an EM-based surrogate objective removes the "inconsistent regularizer" that causes suboptimal inference in vanilla Neural Processes.
- **Mechanism:** Vanilla NPs maximize an objective containing a KL divergence between an approximate posterior and an *approximate* prior, creating a "Prior Approximation Gap." SI-NP formulates a surrogate function in the variational EM framework using the exact functional prior rather than an approximation, aligning optimization with the true marginal likelihood.
- **Core assumption:** The "consistent regularizer" in vanilla NPs is the primary source of underfitting rather than model capacity.
- **Evidence anchors:** Section 3.1 identifies the KL divergence as the "consistent regularizer" source of inference suboptimality; Section 4 shows optimizing the surrogate function via variational EM leads to improvement guarantee.
- **Break condition:** If the functional prior is too complex or the dataset is too small, the surrogate objective might still suffer from high variance or local optima.

### Mechanism 2
- **Claim:** Self-normalized importance sampling (SNIS) enables tractable optimization of the intractable true posterior expectation required by the EM framework.
- **Mechanism:** The E-step requires the true posterior, which is intractable. SI-NP uses a proposal distribution (often set to the functional prior) to sample latent variables and calculates importance weights based on the joint density relative to the proposal. These weights scale gradient updates, performing soft selection over latent particles that best explain the data.
- **Core assumption:** The functional prior is a sufficiently good proposal distribution to keep variance of importance weights low enough for stable training.
- **Evidence anchors:** Section 4.1.2 introduces the proposal distribution and self-normalized importance sampling; Eq. 12 shows weight calculation.
- **Break condition:** If the proposal distribution has low density where the true posterior has high density, weights will degenerate (high variance), causing gradient instability.

### Mechanism 3
- **Claim:** Iterative EM updates enforce a monotonic improvement guarantee on the meta-dataset log-likelihood, bridging the gap between training objectives and test-time generalization.
- **Mechanism:** By alternating between updating the posterior distribution (E-step) and maximizing the expected complete-data log-likelihood (M-step), the algorithm treats learning of the functional prior as maximum likelihood estimation. This avoids "posterior collapse" or "prior approximation gap" found in standard variational inference for NPs.
- **Core assumption:** The Monte Carlo estimate of the gradient is sufficiently accurate to approximate the argmax operation in the M-step.
- **Evidence anchors:** Section E.1.2 provides proof of improvement guarantee showing L(θ^{k+1}) ≥ L(θ^k); Section 4.1 notes the benefit of guaranteeing performance improvement w.r.t. likelihood in iterations.
- **Break condition:** If the number of Monte Carlo samples B is too low (e.g., B=1), the prior collapses to a Dirac delta, reducing the model to a CNP and losing uncertainty quantification benefits.

## Foundational Learning

- **Concept: Variational Inference & ELBO**
  - **Why needed here:** The paper contrasts its method against the standard NP objective, which is an *approximate* ELBO. Understanding why replacing the true prior with an approximate one in the KL term creates an "invalid" objective is crucial.
  - **Quick check question:** Why does minimizing D_{KL}(q(z) || q(z|D_C)) not guarantee maximizing the marginal likelihood p(D_T|D_C)?

- **Concept: Expectation Maximization (EM)**
  - **Why needed here:** The proposed SI-NP is fundamentally an EM algorithm, not just a simple backpropagation loss. You must grasp the iterative nature of calculating the posterior (E-step) and updating parameters (M-step).
  - **Quick check question:** In the M-step of SI-NP, why can we treat the log-likelihood of the previous iteration's parameters as a constant?

- **Concept: Importance Sampling**
  - **Why needed here:** The "Self-normalized" aspect of SI-NP relies on weighting samples to estimate expectations. Understanding how weights reflect the "quality" of a sampled latent variable is key.
  - **Quick check question:** If a sampled latent variable z^{(b)} results in a very low generative likelihood p(D_T|z^{(b)}), what happens to its importance weight and its influence on the gradient?

## Architecture Onboarding

- **Component map:** Encoder -> Functional Prior (μ_θ, Σ_θ) -> Proposal Generator -> Weight Calculator -> Decoder
- **Critical path:**
  1. Batch tasks τ
  2. **E-step #1:** Calculate functional prior p(z|D_C; θ^k) using current params
  3. **Sampling:** Draw B particles z^{(b)} from the proposal (default: functional prior)
  4. **Weighting:** Calculate normalized weights ŵ^{(b)} (Eq. 12)
  5. **M-step:** Compute weighted gradient to update θ (maximize surrogate objective)
- **Design tradeoffs:**
  - **Particle Count (B):** Low B (e.g., 1) is fast but causes "Prior Collapse" (model acts like deterministic CNP). High B captures uncertainty better but increases compute/memory linearly. Paper uses B=8 or 16 for training.
  - **Proposal Distribution:** The paper suggests using the functional prior as the proposal for simplicity and stability, noting that learning a separate proposal (E-step #2) often leads to unstable optimization.
- **Failure signatures:**
  - **Prior Collapse:** Trace of covariance Σ → 0. The model ignores stochasticity and fits only the mean.
  - **High Variance Gradients:** If weights ŵ become extremely sparse (one weight ≈ 1, others ≈ 0), gradients become noisy.
  - **CNP Equivalence:** If performance is identical to CNP, check if the sampling step is effectively disabled or if B is forced to 1 improperly.
- **First 3 experiments:**
  1. **Ablation on Particles:** Run SI-NP with B ∈ {1, 4, 16, 32} on a simple 1D GP regression task. Verify that B=1 collapses to CNP behavior and B>1 captures predictive variance.
  2. **Objective Comparison:** Compare vanilla NP vs. SI-NP on an image completion task (e.g., MNIST). Plot the "consistent regularizer" gap vs. the SI-NP improvement guarantee.
  3. **Prior Uncertainty Analysis:** Visualize the trace of the covariance matrix (Fig 6) for datasets with varying semantic complexity (e.g., MNIST vs CIFAR). Confirm that SI-NP maintains higher uncertainty for more complex datasets.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can a learnable proposal distribution be stabilized and optimized effectively within the SI-NP framework?
- Basis in paper: [explicit] The authors state in Appendix A and Section H.1 that they made the proposal distribution update optional because "it is difficult to balance the optimization" and stabilize performance, ultimately defaulting to a fixed functional prior.
- Why unresolved: Simultaneous optimization of the proposal distribution (η) and the model parameters (θ) leads to training instability that the current weight assignment strategies cannot resolve.
- What evidence would resolve it: The development of a dynamic weight scheduling mechanism or a modified objective function that allows the learnable proposal to converge and outperform the default fixed proposal.

### Open Question 2
- Question: What is the mathematical relationship between the uncertainty of the learned functional prior and the predictive output distribution?
- Basis in paper: [explicit] The Conclusion notes that while uncertainty is intuitively forward propagated, "the influence of such uncertainty has not been mathematically studied."
- Why unresolved: The paper currently relies on empirical analysis of covariance traces rather than providing a theoretical derivation of how prior variance dictates predictive variance.
- What evidence would resolve it: A formal theoretical analysis or bound quantifying how specific changes in the functional prior's covariance matrix alter the uncertainty estimates in the target predictions.

### Open Question 3
- Question: Can the computational cost of SI-NP be reduced to match single-sample methods while maintaining the improvement guarantee?
- Basis in paper: [explicit] The Conclusion identifies the requirement for multiple Monte Carlo samples as an "Existing Limitation" that "consumes more computations" compared to vanilla NPs.
- Why unresolved: The current importance weighting objective degrades to a collapsed deterministic prior (CNP) when using a single sample, necessitating multiple samples for valid uncertainty quantification.
- What evidence would resolve it: A variance reduction technique or architectural modification that achieves high-fidelity uncertainty estimation with a single-sample estimator.

## Limitations
- Limited Real-World Validation: All experiments are conducted on synthetic regression and image datasets, leaving generalization to real-world structured data unexplored.
- Importance Weight Instability: The impact of extreme weight distributions when the proposal is poorly matched to the posterior is not explicitly addressed.
- Prior Collapse on Simple Tasks: The method collapses to a CNP on simple datasets like MNIST without explored mitigation strategies.

## Confidence
- **High**: The theoretical framework (EM-based surrogate objective, self-normalized importance sampling) is well-defined and internally consistent. The experimental comparisons against baselines (CNP, ML-NP) are methodologically sound.
- **Medium**: The claim that SI-NP "bridges the inference gaps" is supported by synthetic and image experiments but lacks validation on more diverse, real-world datasets.
- **Low**: The assertion that SI-NP "outperforms other NP objectives" is based on a limited set of baselines and does not account for recent advances in NP architectures.

## Next Checks
1. **Prior Collapse Analysis**: Systematically vary dataset complexity (e.g., MNIST → CIFAR → ImageNet) and quantify the covariance trace to confirm the relationship between semantic complexity and functional prior uncertainty.
2. **Proposal Distribution Study**: Compare the functional prior proposal against learned proposals (E-step #2) on a controlled synthetic task to assess the trade-off between stability and expressiveness.
3. **Cross-Domain Generalization**: Evaluate SI-NP on a non-image, non-synthetic dataset (e.g., molecular property prediction, sensor time series) to test robustness beyond the current experimental scope.