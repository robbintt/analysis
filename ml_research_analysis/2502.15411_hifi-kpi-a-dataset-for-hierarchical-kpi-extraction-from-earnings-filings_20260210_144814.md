---
ver: rpa2
title: 'HiFi-KPI: A Dataset for Hierarchical KPI Extraction from Earnings Filings'
arxiv_id: '2502.15411'
source_url: https://arxiv.org/abs/2502.15411
tags:
- label
- hifi-kpi
- xbrl
- us-gaap
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces HIFI-KPI, a large-scale dataset for hierarchical
  KPI extraction from SEC filings, addressing the challenge of limited label transferability
  in XBRL's highly granular taxonomy. The dataset comprises ~1.8M paragraphs and ~5M
  entities, organized using a taxonomy-based grouping method that enables extraction
  at different granularity levels.
---

# HiFi-KPI: A Dataset for Hierarchical KPI Extraction from Earnings Filings
## Quick Facts
- arXiv ID: 2502.15411
- Source URL: https://arxiv.org/abs/2502.15411
- Reference count: 40
- Hierarchical KPI extraction dataset from SEC filings using taxonomy-based grouping

## Executive Summary
This paper introduces HIFI-KPI, a large-scale dataset for hierarchical KPI extraction from SEC filings that addresses the challenge of limited label transferability in XBRL's highly granular taxonomy. The dataset comprises ~1.8M paragraphs and ~5M entities, organized using a taxonomy-based grouping method that enables extraction at different granularity levels. Experiments show that coarser taxonomy levels improve text classification performance, with sequence labeling outperforming text classification. LLM-based structured extraction achieves mixed results, with larger models performing better on label extraction. The dataset and baselines enable improved financial data extraction from unstructured text.

## Method Summary
The HIFI-KPI dataset was constructed by parsing SEC XBRL filings using a custom parser that extracts context paragraphs and entities, then filtering to well-formed segments. The dataset leverages the US GAAP XBRL taxonomy (2022) with 8,466 unique labels, organized hierarchically. To address the challenge of extracting highly specific labels, the authors implemented a taxonomy-based grouping method that recursively replaces child labels with their parents when siblings share the same parent, enabling extraction at different levels of granularity. This creates a hierarchy of datasets with varying label counts (from 8,466 down to 20 labels), allowing evaluation of extraction performance at different abstraction levels. The dataset contains ~1.8M paragraphs and ~5M entities, with each paragraph labeled with 0-5 labels.

## Key Results
- Coarser taxonomy levels show improved text classification performance with Macro F1 scores increasing from 0.415 (Level 5) to 0.531 (Level 1)
- Sequence labeling outperforms text classification across all taxonomy levels for paragraph-label extraction
- LLM-based structured extraction achieves Macro F1 of 0.79 for label extraction but struggles with specific labels (Macro F1 ~0.50 for NuExtract)

## Why This Works (Mechanism)
The hierarchical structure of the US GAAP taxonomy creates natural aggregation levels where child labels inherit semantic meaning from parent categories. By grouping sibling labels under common parents, the dataset reduces the semantic distance between labels and text, making classification more tractable. The sequence labeling approach captures local context within paragraphs more effectively than text classification, which must learn broader semantic mappings. The combination of taxonomy-based grouping and appropriate model architectures (BERT for classification, sequence labeling for extraction) addresses the fundamental challenge of mapping highly specific financial concepts to unstructured text.

## Foundational Learning
- **XBRL taxonomy structure**: Understanding the hierarchical nature of financial reporting standards and how concepts are organized into parent-child relationships
  - Why needed: The dataset's entire design philosophy depends on leveraging this hierarchical structure
  - Quick check: Verify that US GAAP taxonomy follows tree-like structure with semantic inheritance

- **SEC EDGAR parsing**: Familiarity with extracting structured data from SEC filings and handling XML-based financial reports
  - Why needed: The dataset construction relies on parsing real-world financial filings
  - Quick check: Test ability to extract context paragraphs and entities from sample XBRL files

- **Taxonomy-based label grouping**: Understanding how to create semantic groupings by replacing child labels with common parents
  - Why needed: Core methodology for creating multi-level extraction tasks
  - Quick check: Implement recursive parent replacement algorithm on small taxonomy example

## Architecture Onboarding
### Component Map
Parser -> Filter -> Taxonomy Grouping -> Dataset Levels (L5â†’L1) -> Model Training

### Critical Path
1. Parse XBRL filings to extract paragraphs and entities
2. Filter for well-formed segments (length constraints, entity presence)
3. Apply taxonomy-based grouping recursively from bottom-up
4. Create training/validation/test splits for each hierarchy level
5. Train and evaluate models on different task formulations

### Design Tradeoffs
- Granularity vs. performance: More specific labels (L5) vs. better extraction accuracy (L1)
- Parser complexity vs. dataset coverage: Strict filtering improves quality but reduces size
- Model architecture choice: Text classification vs. sequence labeling for different tasks

### Failure Signatures
- Poor performance at fine-grained levels indicates semantic ambiguity between specific labels
- Sequence labeling failure suggests local context is insufficient for entity recognition
- LLM extraction failures reveal limitations in handling specialized financial terminology

### First Experiments
1. Replicate Macro F1 scores for text classification across different taxonomy levels
2. Compare sequence labeling vs. text classification on paragraph-label extraction task
3. Evaluate LLM-based extraction on sample filings to verify label vs. value extraction differences

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can advanced hierarchical aggregation algorithms outperform the recursive bottom-up approach for taxonomy grouping?
- Basis in paper: [explicit] The Conclusion states the results "highlight the potential for even better aggregation algorithms" than the simple recursive method employed.
- Why unresolved: The authors utilized a bottom-up parent replacement strategy, leaving top-down or semantic clustering approaches unexplored.
- What evidence would resolve it: Comparing macro-F1 scores on extraction tasks using taxonomies processed via semantic clustering versus the recursive grouping method.

### Open Question 2
- Question: To what extent does the parser-induced selection bias limit model generalization to unfiltered financial text?
- Basis in paper: [explicit] The Limitations section notes the dataset includes "only snippets that match our simple parser methodology," introducing a specific bias.
- Why unresolved: Models are trained and evaluated exclusively on well-parsed segments; performance on the messy, rejected segments of SEC filings remains unknown.
- What evidence would resolve it: Evaluating the baseline models on a held-out set of raw SEC filings that failed the original parsing filters.

### Open Question 3
- Question: Can specialized fine-tuning enable LLMs to close the performance gap with encoder-based models on granular label extraction?
- Basis in paper: [inferred] Results show LLMs struggle with specific labels (Macro F1 near 0.5 for NuExtract) compared to fine-tuned BERT models, despite LLMs excelling at value extraction.
- Why unresolved: The paper evaluates few-shot LLMs but does not test if instruction tuning on the HIFI-KPI hierarchy improves their label classification capabilities.
- What evidence would resolve it: Fine-tuning an LLM (e.g., Qwen) on the training split and measuring the resulting Macro F1 for labels against the BERT baseline.

## Limitations
- Dataset dependency on XBRL taxonomy structure may not capture all relevant financial KPIs
- Taxonomy-based grouping assumes sibling nodes represent meaningful semantic relationships
- Focus on US SEC filings limits generalizability to other financial reporting contexts

## Confidence
- Hierarchical extraction benefits: High
- Sequence labeling superiority: High
- LLM extraction performance: Medium

## Next Checks
1. Evaluate HIFI-KPI's performance on financial reports from non-US jurisdictions to assess cross-domain generalizability
2. Conduct ablation studies removing the taxonomy-based grouping to determine the true contribution of this design choice
3. Test the dataset with fine-tuned smaller language models to establish whether the observed benefits require large, general-purpose LLMs