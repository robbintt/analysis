---
ver: rpa2
title: Generative Data Augmentation in Graph Contrastive Learning for Recommendation
arxiv_id: '2510.09129'
source_url: https://arxiv.org/abs/2510.09129
tags:
- contrastive
- learning
- data
- graph
- recommendation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of data sparsity in recommendation
  systems by proposing GDA4Rec, a framework that generates high-quality augmented
  views through deep generative models. The method introduces noise generation using
  Gaussian distributions and employs both reconstruction loss and distribution discrepancy
  loss to ensure the augmented views closely resemble the original data while maintaining
  diversity.
---

# Generative Data Augmentation in Graph Contrastive Learning for Recommendation

## Quick Facts
- arXiv ID: 2510.09129
- Source URL: https://arxiv.org/abs/2510.09129
- Reference count: 40
- This paper addresses data sparsity in recommendation systems by proposing GDA4Rec, achieving over 6% improvements in Top@20 metrics on Yelp2 through generative data augmentation and contrastive learning.

## Executive Summary
This paper introduces GDA4Rec, a framework that tackles data sparsity in recommendation systems by generating high-quality augmented views through deep generative models. The method employs a multi-task learning approach that combines recommendation, data augmentation, and contrastive learning objectives. By adaptively generating noise conditioned on embeddings rather than using fixed random distributions, and incorporating an item complement matrix for supplementary self-supervised signals, GDA4Rec demonstrates significant performance improvements over state-of-the-art baselines across three real-world datasets.

## Method Summary
GDA4Rec addresses data sparsity in graph-based collaborative filtering by generating augmented views through a deep generative model. The framework uses a 3-layer LightGCN backbone and introduces noise generation via a 3-layer MLP that outputs Gaussian parameters conditioned on embeddings. The noise is applied at each GNN layer using the reparameterization trick. The model optimizes a joint objective combining BPR loss for recommendation, InfoNCE loss for contrastive learning, and reconstruction loss for augmentation. An item complement matrix is constructed from the interaction matrix to capture latent item correlations, providing additional self-supervised signals. The method demonstrates superior performance across CiaoDVD, Yelp2, and Douban-book datasets with consistent gains in precision, recall, and NDCG metrics.

## Key Results
- GDA4Rec achieves over 6% improvements in Top@20 metrics on Yelp2 compared to state-of-the-art baselines
- Consistent performance gains across all three datasets (CiaoDVD, Yelp2, Douban-book) in precision, recall, and NDCG metrics
- Ablation studies confirm the effectiveness of adaptive noise generation versus fixed random noise distributions
- Performance remains stable with 3 GNN layers, avoiding over-smoothing issues observed in deeper architectures

## Why This Works (Mechanism)
The framework's effectiveness stems from its ability to generate high-quality augmented views that closely resemble original data while maintaining diversity. The generative augmentation module learns to produce noise conditioned on embeddings, ensuring semantic consistency while introducing meaningful variations. The item complement matrix captures latent correlations between items, providing supplementary self-supervised signals that enhance the model's understanding of item relationships. By integrating these components within a multi-task learning framework, GDA4Rec effectively addresses data sparsity while maintaining recommendation accuracy.

## Foundational Learning
- **Graph Neural Networks**: Used for learning user and item embeddings from the interaction graph; needed for capturing complex relationships in sparse data
- **Contrastive Learning**: Employs InfoNCE loss to learn invariant representations between augmented views; needed to improve generalization
- **Generative Models**: MLP-based noise generator produces conditional distributions; needed for creating diverse yet semantically consistent augmentations
- **Item Complement Matrix**: Constructed from interaction matrix to capture latent item correlations; needed for supplementary self-supervised signals
- **Multi-task Learning**: Joint optimization of recommendation, augmentation, and contrastive objectives; needed for balanced learning across tasks
- **Reparameterization Trick**: Enables gradient flow through stochastic noise generation; needed for training the generative augmentation module

## Architecture Onboarding

**Component Map**: User-Item Graph -> LightGCN -> Layer-wise Augmentation -> Generator MLP -> Noise Injection -> Embedding Fusion -> Contrastive Loss + BPR Loss + Reconstruction Loss

**Critical Path**: The core training loop involves: 1) Forward pass through LightGCN with layer-wise augmentation, 2) Generator MLP producing noise parameters conditioned on embeddings, 3) Joint optimization of BPR, InfoNCE, and reconstruction losses, 4) Update of both GNN and generator parameters.

**Design Tradeoffs**: The paper uses 3 GNN layers to balance expressiveness and avoid over-smoothing, employs a 3-layer MLP for the generator to ensure sufficient capacity while maintaining computational efficiency, and constructs the item complement matrix with a filter threshold to focus on meaningful item relationships.

**Failure Signatures**: Performance degradation may occur if: 1) The item complement matrix construction fails to remove self-loops or apply the filter threshold correctly, 2) The generator MLP dimensions are insufficient for the dataset complexity, or 3) The noise generation becomes too aggressive, distorting semantic relationships.

**3 First Experiments**:
1. Verify the LightGCN backbone implementation with 3 layers and 64-dimensional embeddings
2. Test the generator MLP architecture and noise generation mechanism with the reparameterization trick
3. Validate the item complement matrix construction and filtering process on a small subset of the interaction data

## Open Questions the Paper Calls Out
None

## Limitations
- Performance may degrade on extremely sparse datasets where even augmented views lack sufficient information
- The method requires careful tuning of multiple hyperparameters (generator dimensions, filter threshold, etc.)
- Computational overhead from the additional generative augmentation module may impact scalability

## Confidence
High confidence in the core methodology and results, as the paper provides comprehensive implementation details and publicly released code. The framework's novelty and effectiveness are well-supported by rigorous experiments and ablation studies.

## Next Checks
1. Verify the exact MLP architecture (hidden dimensions, activations) used in the generator and reconstructor
2. Confirm the number of negative samples per positive interaction in BPR loss
3. Test the impact of removing the adaptive noise generation (using fixed Gaussian noise instead) to validate the ablation results