---
ver: rpa2
title: Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large
  Language Models
arxiv_id: '2508.18609'
source_url: https://arxiv.org/abs/2508.18609
tags:
- scaling
- knowledge
- size
- quantization
- qwen3-14b
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper establishes the first task-stratified knowledge scaling
  laws for post-training quantized LLMs by incorporating model size, bit-width, group
  size, and calibration set size into a unified power-law framework. The empirical
  analysis on 293 diverse configurations reveals distinct sensitivities across knowledge
  capabilities: reasoning is precision-critical (most sensitive to bit-width and group
  size), knowledge application is scale-responsive (highest scaling exponent with
  model size), and memorization is calibration-sensitive (highest sensitivity to calibration
  data).'
---

# Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models

## Quick Facts
- arXiv ID: 2508.18609
- Source URL: https://arxiv.org/abs/2508.18609
- Authors: Chenxi Zhou; Pengfei Cao; Jiang Li; Jun Zhao; Kang Liu
- Reference count: 40
- Establishes the first task-stratified knowledge scaling laws for post-training quantized LLMs across model size, bit-width, group size, and calibration data

## Executive Summary
This paper introduces the first task-stratified knowledge scaling laws for post-training quantized large language models (PTQ-LLMs). By incorporating model size, bit-width, group size, and calibration set size into a unified power-law framework, the authors demonstrate that different knowledge capabilities exhibit systematically distinct sensitivities to quantization parameters. The framework achieves high goodness-of-fit (Adj.R2 > 0.92) and reveals that reasoning is precision-critical, knowledge application is scale-responsive, and memorization is calibration-sensitive.

## Method Summary
The study employs a grid-based experimental design using Qwen3 and Llama-3 model families across 293 configurations. GPTQ is applied with varying bit-widths (2-8), group sizes (32-1024), and calibration set sizes (8-1024 samples). Performance is evaluated on 14 benchmarks stratified into three knowledge capability types: Knowledge Memorization (KM), Knowledge Application (KA), and Knowledge Reasoning (KR). Scaling laws are fitted via OLS regression on log-transformed normalized accuracy metrics, with cross-architecture validation on held-out configurations.

## Key Results
- Task-stratified exponents show KR is most bit-width sensitive (β = -1.36), KM most calibration-sensitive (γ = -0.04), and KA most scale-responsive (α = -0.41)
- Low-bit sensitivity amplification: calibration elasticity triples and group size coefficient surges below 3-bit precision
- 2-bit models ≥4B can recover KM/KA performance with optimized group size and calibration data, but KR collapses structurally
- Goodness-of-fit exceeds 0.92 across architectures with consistent exponent patterns

## Why This Works (Mechanism)

### Mechanism 1: Multiplicative Power-Law Scaling of Quantization Loss
The negative log-normalized accuracy follows a multiplicative power-law across model size, bit-width, calibration size, and group size. Each factor contributes independently to quantization-induced degradation via learned exponents. Model size (α ≈ -0.36) and bit-width (β ≈ -1.07) dominate globally; group size (δ ≈ +0.07) penalizes coarse granularity; calibration size (γ ≈ -0.03) shows diminishing returns via log₂ transformation. The log-transformation linearizes bounded accuracy into convex loss-space. At 2-bit precision, scaling laws fail to converge for models <2B parameters (Adj.R² < 0), indicating representational collapse violates power-law assumptions.

### Mechanism 2: Task-Stratified Sensitivity Divergence
Different cognitive capabilities exhibit systematically different sensitivities to quantization parameters. Reasoning (KR) requires multi-step error propagation, making it precision-fragile (β = -1.36, 40% higher than KM/KA). Memorization (KM) relies on precise FFN key-value activation alignment, requiring calibration data (γ = -0.04, double KA's sensitivity). Application (KA) benefits from emergent scaling patterns, showing highest model-size responsiveness (α = -0.41). Bloom's taxonomy cognitive complexity levels correspond to quantization sensitivity hierarchies. At 2-bit, reasoning (KR) collapses structurally regardless of configuration (Adj.R² ≈ 0.22), while KM and KA remain recoverable with optimized parameters.

### Mechanism 3: Low-Bit Sensitivity Amplification
Fine-grained parameters (group size, calibration data) transition from marginal to critical below 3-bit precision. In 3-bit zone, calibration elasticity triples (|-0.032| → |-0.103|) and group size coefficient surges (0.073 → 0.117). At 2-bit, G exponent reaches ~0.60 for KM and ~0.33 for KA, meaning coarse grouping becomes actively destructive rather than merely suboptimal. Larger models (≥4B) possess sufficient representational redundancy to absorb extreme compression when granularity is fine-tuned. Models <2B at 2-bit show universal collapse across all tasks—no parameter tuning recovers performance.

## Foundational Learning

- **Concept:** Post-Training Quantization (PTQ) fundamentals
  - **Why needed here:** The entire framework models PTQ-specific parameters; understanding weight-only quantization, group-wise scaling, and calibration is prerequisite.
  - **Quick check question:** Can you explain why GPTQ uses calibration data and what group size controls?

- **Concept:** Power-law scaling in neural networks
  - **Why needed here:** The mathematical form extends Kaplan et al.'s scaling laws; understanding log-transformed loss metrics and exponent interpretation is essential.
  - **Quick check question:** Why does a negative exponent for model size mean performance improves as N increases?

- **Concept:** Knowledge capability taxonomy (Bloom's adaptation for LLMs)
  - **Why needed here:** Task stratification is the core contribution; distinguishing memorization vs. application vs. reasoning enables targeted quantization strategies.
  - **Quick check question:** Which capability would you expect to degrade most at 3-bit with group size 1024, and why?

## Architecture Onboarding

- **Component map:** Calibration data selection -> Group size configuration -> Bit-width decision -> Model size selection
- **Critical path:** Calibration data selection → Group size configuration → Bit-width decision → Model size selection (reverse order of typical engineering intuition)
- **Design tradeoffs:**
  - Smaller G (32-64) preserves reasoning but increases memory overhead for scale storage
  - Larger Cb (512-1024) helps memorization but adds calibration time
  - 3-bit offers compression sweet spot; 2-bit requires ≥4B models and aggressive fine-grained optimization
- **Failure signatures:**
  - Adj.R² < 0.90 in fitting indicates configuration space gap
  - KR performance flat across G variations signals precision collapse
  - Small models at 2-bit with Adj.R² < 0 indicates systemic failure mode
- **First 3 experiments:**
  1. Replicate general scaling law on Qwen3-1.7B across B ∈ {2,3,4,8} with fixed G=128, Cb=128; verify Adj.R² > 0.90
  2. Ablate group size (G ∈ {32,64,128,1024}) at 3-bit for KR tasks; confirm δ coefficient ~0.087
  3. Test 2-bit recovery on ≥4B model: vary G (32 vs 1024) and Cb (8 vs 1024); observe KM/KA recovery vs KR collapse

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does the proposed task-stratified scaling law framework generalize to Mixture-of-Experts (MoE) architectures?
- **Basis in paper:** [explicit] The Limitations section explicitly identifies the extension of these laws to alternative architectures, specifically Mixture-of-Experts (MoE), as a direction for future research.
- **Why unresolved:** The study is restricted to dense Transformer architectures (Qwen3, Llama-3), but MoE models possess distinct parameter efficiency and activation sparsity patterns that may alter the relationship between model size ($N$) and quantization sensitivity.
- **What evidence would resolve it:** Re-fitting the power-law framework on quantized MoE models (e.g., Mixtral or Qwen-MoE) to determine if the high goodness-of-fit (Adj.R2 > 0.92) and distinct task sensitivities persist.

### Open Question 2
- **Question:** Can the unified scaling framework accurately predict performance when applied to activation quantization rather than weight-only quantization?
- **Basis in paper:** [explicit] The authors state in the Limitations that the study primarily establishes laws for weight-only quantization and that extending to other paradigms like activation quantization is a necessary future step.
- **Why unresolved:** Activation quantization introduces dynamic range challenges and inter-layer dependencies not captured by the current static weight-focused variables ($N, B, G, C_b$), potentially requiring a different functional form.
- **What evidence would resolve it:** Validating the current formulation on Weight-Activation Quantization methods (e.g., AWQ or SmoothQuant) to see if the "precision-critical" nature of reasoning tasks holds for activation precision.

### Open Question 3
- **Question:** Is the structural collapse of reasoning capabilities at 2-bit a fundamental representational limit, or can it be mitigated by optimizing the distribution and quality of calibration data?
- **Basis in paper:** [inferred] Section 4.3.2 notes that knowledge reasoning (KR) exhibits a "flat surface" and structural collapse at 2-bit regardless of configuration. However, the study only varies calibration *size* ($C_b$) using generic C4 data, leaving the impact of calibration data *domain* or *quality* unexplored.
- **Why unresolved:** It remains unclear if the "phase transition" failure in reasoning is purely a bit-width capacity issue or if the distribution shift from generic calibration data fails to activate reasoning circuits effectively at low precision.
- **What evidence would resolve it:** Experiments using reasoning-heavy or task-specific calibration datasets at 2-bit precision to determine if the goodness-of-fit for KR can be recovered or if the collapse is absolute.

## Limitations

- Scaling law framework breaks at extreme compression (2-bit, <2B parameters) where Adj.R² < 0 indicates structural model collapse
- Calibration data dependence introduces evaluation instability due to unspecified random sampling methodology
- Task-stratified exponents rely on benchmark mapping assumptions that conflate knowledge types across benchmarks

## Confidence

**High Confidence:** The general scaling law formulation (Adj.R² > 0.92 across architectures) and the precision-criticality ranking (reasoning > memorization > application for bit-width sensitivity) are well-supported by the 293 configuration dataset and cross-validated on held-out Qwen3-32B models.

**Medium Confidence:** The low-bit sensitivity amplification mechanism (Cb elasticity tripling at 3-bit, G exponent surging to 0.60 for KM at 2-bit) is supported by observed trends but relies on extrapolation from limited 2-bit samples.

**Low Confidence:** The universal collapse prediction for <2B models at 2-bit is based on indirect evidence (Adj.R² trends) rather than exhaustive empirical testing.

## Next Checks

1. **Cross-dataset calibration validation:** Repeat the full 293-configuration experiment using a different calibration corpus (e.g., RedPajama or The Pile) to verify whether the KM sensitivity to Cb is dataset-specific or universal.

2. **Architecture-specific exponent mapping:** Fit the scaling law separately on Llama-3 and Qwen3 families to quantify cross-architecture consistency. Compare α, β, γ, δ distributions.

3. **Extreme-compression boundary test:** Systematically test 2-bit configurations across the full model size range (0.6B to 32B) with optimized G and Cb parameters to empirically verify the predicted collapse threshold for <2B models and recovery potential for ≥4B models.