---
ver: rpa2
title: Convergence Dynamics of Over-Parameterized Score Matching for a Single Gaussian
arxiv_id: '2511.22069'
source_url: https://arxiv.org/abs/2511.22069
tags:
- have
- lemma
- therefore
- preprint
- then
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper analyzes the convergence behavior of gradient descent
  on the score matching objective for learning a single Gaussian distribution using
  an over-parameterized student model. The authors study multiple noise regimes and
  initialization strategies, revealing rich and contrasting convergence behaviors.
---

# Convergence Dynamics of Over-Parameterized Score Matching for a Single Gaussian

## Quick Facts
- arXiv ID: 2511.22069
- Source URL: https://arxiv.org/abs/2511.22069
- Reference count: 40
- This paper analyzes the convergence behavior of gradient descent on the score matching objective for learning a single Gaussian distribution using an over-parameterized student model.

## Executive Summary
This paper analyzes the convergence behavior of gradient descent on the score matching objective for learning a single Gaussian distribution using an over-parameterized student model. The authors study multiple noise regimes and initialization strategies, revealing rich and contrasting convergence behaviors. For large noise scales, gradient descent achieves O(1/√τ) convergence rate to the ground truth parameters, while for small noise scales, stationary points with nonzero loss exist, preventing convergence from arbitrary initialization. The analysis demonstrates that over-parameterization under small noise can lead to unstable convergence behavior, highlighting the importance of large noise in ensuring stable and predictable training dynamics in score-based generative models.

## Method Summary
The paper studies gradient descent on the score matching objective for learning a single Gaussian distribution using an over-parameterized student model with n learnable parameters. The score network is parameterized as s_t(x) = Σ_i w_i,t(x)μ_i,t - x where w_i,t(x) = softmax over squared distances and μ_i,t = μ̃_i·exp(-t) represents time-scaled parameters. The population score matching loss L_t = E_{X_t∼N(μ*_t,I_d)}[‖s_t(X_t) - μ*_t + X_t‖²] is minimized using gradient descent with step size η. The analysis considers three distinct regimes: large noise scales (t > log(n) + log(M) + 2), exponentially small initialization (‖μ_i^(0)‖ ≤ exp(-10⁶ndM₀³)/(108nd)), and random Gaussian initialization with sufficient separation.

## Key Results
- For large noise scales (t > log(n) + log(M) + 2), gradient descent achieves O(1/√τ) convergence rate to the ground truth parameters
- For small noise scales, stationary points with nonzero loss exist, preventing convergence from arbitrary initialization
- With exponentially small initialization, all parameters converge to the ground truth
- With random Gaussian initialization far from ground truth, exactly one parameter converges while others diverge to infinity, yet the loss still converges at rate O(1/τ)

## Why This Works (Mechanism)

### Mechanism 1: Large-Noise Regularization via Score Matching
When noise scale t exceeds log(n) + log(M) + 2, gradient descent provably converges with rate O(1/√τ). Large noise flattens the loss landscape by exponentially shrinking parameter distances, making softmax weights more uniform. This suppresses cubic gradient terms that cause instability, allowing the dominant linear term to guide all parameters toward the ground truth—mirroring gradient EM dynamics. The analysis requires step size η ≤ O(1/(n⁴d²)) and finite initial max distance M.

### Mechanism 2: Exponentially Small Initialization Enables Full Parameter Recovery
Initializing all parameters within distance exp(-poly(M₀, n, d)) of zero ensures every μ_i converges to μ*. The geometric center A(τ) of parameters acts as a reference point that drifts toward μ* at rate η/n. When parameters start exponentially close together, they remain clustered around this center throughout training. The proof tracks ‖μ_i^(τ) - A(τ)·e_1‖ via induction, showing the cluster stays tighter than the center's drift rate.

### Mechanism 3: Competitive Exclusion Under Random Initialization
With random Gaussian initialization far from μ*, exactly one parameter converges to μ* while others diverge to infinity, yet loss still converges at O(1/τ). The parameter closest to μ* initially receives the largest gradient signal because its softmax weight dominates near the data distribution. This creates positive feedback: the closest parameter approaches μ* faster, increasing its weight further. Other parameters' gradients become exponentially small while their norms increase via repulsive cubic terms.

## Foundational Learning

- **Concept: Score Function and Score Matching** - Understanding that score matching minimizes ‖s_t(X_t) - ∇_x ln q_t(X_t)‖² is prerequisite to interpreting the loss landscape. *Quick check: Can you explain why learning the score function enables sampling from the data distribution via the reverse SDE?*

- **Concept: Softmax Weight Dynamics in Mixture Models** - The weights w_i(x) = exp(-‖x - μ_i‖²/2) / Σ_j exp(-‖x - μ_j‖²/2) determine gradient contributions. Their exponential dependence on distances creates the cubic terms and competitive exclusion behavior central to the paper. *Quick check: If μ_1 moves closer to x than μ_2, how does w_1/w_2 change, and what does this imply for their respective gradient magnitudes?*

- **Concept: Over-Parameterization and Parameter Identifiability** - The paper's core tension is that n > 1 parameters model a single Gaussian. Parameter recovery (all μ_i → μ*) is distinct from loss minimization. Recognizing this distinction explains why "loss converges" ≠ "parameters converge." *Quick check: Why might having more parameters than necessary slow convergence even if it doesn't prevent finding a solution?*

## Architecture Onboarding

- **Component map:** Ground truth Gaussian N(μ*, I_d) -> Student model n parameters μ̃_i -> Time-scaled parameters μ_i,t = μ̃_i·exp(-t) -> Score network s_t(x) = Σ_i w_i,t(x)μ_i,t - x -> Loss function L_t = E_{X_t∼N(μ*_t,I_d)}[‖s_t(X_t) - μ*_t + X_t‖²] -> Gradient descent optimizer

- **Critical path:** Initialize μ̃_i (choice determines convergence regime) -> Select noise scale t (large → stable; small → initialization-sensitive) -> Run gradient descent on μ_i,t for fixed t -> Monitor both loss L_t and parameter distances ‖μ_i,t - μ*_t‖

- **Design tradeoffs:** Large t vs. small t: Large noise guarantees convergence but blurs distribution details; small noise preserves structure but risks stagnation. Small initialization vs. random: Exponentially small init recovers all parameters but is impractical; random init loses parameter identifiability but still minimizes loss. Step size must balance η ≤ O(1/(n⁴d²)) for stability vs. convergence speed.

- **Failure signatures:** Loss plateaus at nonzero value → likely hit stationary point (small t, bad initialization). Some parameters explode to infinity → competitive exclusion active; single parameter may still converge. All parameters diverge → step size too large or initialization outside analyzed regimes.

- **First 3 experiments:** 1) Replicate Figure 1: Train n=5, d=3 with M=4 vs M=6 initialization; verify all-converge vs one-converge regimes and O(1/τ) loss scaling. 2) Noise scale sweep: Fix initialization, vary t from 0 to 10; identify threshold where convergence becomes guaranteed. 3) Initialization radius study: For fixed small t, sweep initialization scale from exp(-M³) to M^(1/3); find boundary between full-recovery and partial-recovery regimes.

## Open Questions the Paper Calls Out

- What are the convergence dynamics for initializations between the two extreme regimes (exponentially small initialization vs. random Gaussian initialization far from ground truth)? The paper proves convergence for two extreme cases but does not characterize the transition between these regimes or intermediate behaviors.

- Can the convergence guarantees be extended to multi-component Gaussian mixture ground truths? The analysis relies heavily on properties specific to a single Gaussian ground truth, particularly the simple form of the true score function.

- How do the dynamics change when training uses the time-averaged score matching loss over multiple noise levels rather than a fixed noise scale t? The paper analyzes convergence at a fixed noise scale t, while practical diffusion models aggregate gradients across timesteps.

## Limitations

- The analysis relies on population gradient computations that assume exact expectations, while practical implementations use finite samples
- The exponentially small initialization requirement appears impractical for real-world applications and may indicate a gap between theory and practice
- The analysis focuses on fixed noise scales t rather than the annealed schedules commonly used in diffusion models, limiting direct applicability to state-of-the-art score-based generative models

## Confidence

- **High confidence**: Large-noise convergence (Theorem 2.1) - supported by explicit convergence bound and clear mechanism
- **Medium confidence**: Exponential initialization convergence (Theorem 3.2) - proof is rigorous but initialization requirement is impractical
- **Medium confidence**: Competitive exclusion dynamics (Theorem 3.5) - two-stage analysis is thorough but relies on strong separation assumptions
- **Low confidence**: Practical applicability - theoretical requirements (step size, initialization) appear too restrictive for real implementations

## Next Checks

1. Verify initialization sensitivity: Systematically test convergence across initialization scales between exp(-M³) and M^(1/3) to empirically identify the transition boundary between all-parameters-converges and one-parameter-converges regimes

2. Validate gradient computation: Implement the exact gradient formula from Lemma B.1 and verify against numerical differentiation for small d and n to ensure no implementation errors in the core dynamics

3. Test step size limits: Experiment with step sizes larger than the theoretical bound η > O(1/(n⁴d²)) to understand practical convergence behavior and identify when divergence occurs