---
ver: rpa2
title: Model State Arithmetic for Machine Unlearning
arxiv_id: '2506.20941'
source_url: https://arxiv.org/abs/2506.20941
tags:
- unlearning
- forget
- arxiv
- ideal
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes MSA (Model State Arithmetic), a new approach
  for machine unlearning that leverages intermediate model checkpoints to more effectively
  remove the influence of targeted data points. MSA computes a forget vector from
  a checkpoint prior to exposure to the unlearning targets and applies it to the final
  model to reverse the effect of the target data.
---

# Model State Arithmetic for Machine Unlearning

## Quick Facts
- arXiv ID: 2506.20941
- Source URL: https://arxiv.org/abs/2506.20941
- Authors: Keivan Rezaei; Mehrdad Saberi; Abhilasha Ravichander; Soheil Feizi
- Reference count: 24
- Key outcome: MSA outperforms existing unlearning algorithms across multiple benchmarks while maintaining model utility

## Executive Summary
This paper introduces Model State Arithmetic (MSA), a novel approach to machine unlearning that leverages intermediate model checkpoints to effectively remove the influence of targeted data points. The method computes a forget vector from checkpoints prior to exposure to unlearning targets and applies it to the final model to reverse the effect of the target data. Through extensive experiments on TOFU, RESTOR, and MUSE-Books benchmarks, MSA consistently demonstrates superior performance in forgetting efficacy, utility preservation, and privacy leakage compared to existing methods. The approach shows remarkable robustness, maintaining strong performance even when using checkpoints hundreds of billions of tokens before the unlearning targets.

## Method Summary
MSA operates by leveraging intermediate model checkpoints during pretraining to compute a forget vector that captures the influence of target data on model parameters. When unlearning is required, MSA identifies a checkpoint from before the target data was encountered and computes the difference between this checkpoint and subsequent checkpoints that have been exposed to the target data. This difference, called the forget vector, is then applied to the final model to reverse the influence of the target data. The method is particularly effective because it directly addresses the challenge of aligning the post-unlearning model with an ideal reference model that has never seen the target data. Experiments demonstrate that MSA can achieve strong unlearning performance while maintaining model utility, even when checkpoints are spaced far apart in the pretraining timeline.

## Key Results
- MSA consistently outperforms or matches existing unlearning algorithms across multiple benchmarks (TOFU, RESTOR, MUSE-Books)
- The method achieves strong performance even when using checkpoints hundreds of billions of tokens before the unlearning targets
- MSA demonstrates robustness to checkpointing frequency while maintaining both forgetting efficacy and model utility preservation
- The approach effectively reduces privacy leakage while preserving model performance on downstream tasks

## Why This Works (Mechanism)
MSA works by leveraging the temporal structure of pretraining to capture and reverse the influence of target data. When a model is trained on data sequentially, each checkpoint represents the model state at a particular point in time. By computing the difference between checkpoints before and after exposure to target data, MSA can isolate the specific parameter changes induced by those data points. This forget vector essentially captures how the model adapted to the target data, allowing for targeted reversal of those adaptations. The method is particularly powerful because it doesn't require retraining from scratch or access to the full training data, instead using the checkpoint history to guide the unlearning process.

## Foundational Learning
- **Checkpoint arithmetic**: Understanding how to compute and apply parameter differences between model states; needed to implement the core forget vector computation; quick check: verify parameter differences preserve model behavior
- **Data influence analysis**: Ability to trace how specific data points affect model parameters; needed to identify which checkpoints contain relevant information; quick check: validate influence attribution accuracy
- **Linear approximation in parameter space**: Assumption that parameter changes due to data exposure can be approximated linearly; needed for efficient forget vector computation; quick check: measure approximation error across different model depths
- **Reference model alignment**: Concept of measuring unlearning success by comparing to a model never exposed to target data; needed to establish ground truth for evaluation; quick check: verify alignment metrics correlate with practical unlearning quality
- **Temporal dependency in pretraining**: Understanding how model states evolve sequentially during long pretraining runs; needed to select appropriate checkpoints for forget vector computation; quick check: analyze checkpoint spacing impact on unlearning performance

## Architecture Onboarding

**Component Map:**
Model checkpoints -> Forget vector computation -> Final model update -> Evaluation against reference model

**Critical Path:**
1. Pretraining with intermediate checkpointing
2. Forget vector computation using pre- and post-target checkpoints
3. Application of forget vector to final model
4. Evaluation of unlearning efficacy and utility preservation

**Design Tradeoffs:**
- Checkpoint frequency vs. storage overhead: More frequent checkpoints provide better unlearning precision but increase storage costs
- Linear approximation vs. exact computation: Linear methods are computationally efficient but may miss complex, non-linear influences
- Forward vs. backward unlearning: MSA works forward from historical checkpoints rather than backward from the final model, enabling better reference model alignment

**Failure Signatures:**
- Poor unlearning performance when checkpoint spacing exceeds the model's ability to linearly approximate parameter changes
- Utility degradation when forget vectors are over-aggressive or target data has complex, non-linear influences
- Scalability issues when checkpoint storage becomes prohibitive for extremely long pretraining runs

**3 First Experiments to Run:**
1. Ablation study on checkpoint frequency to identify optimal spacing for different model sizes
2. Comparison of MSA against exact unlearning methods on small models to measure linear approximation error
3. Cross-task evaluation to assess whether MSA generalizes beyond language modeling to vision and multimodal models

## Open Questions the Paper Calls Out
None

## Limitations
- Computational overhead of storing and managing multiple checkpoints across long pretraining runs
- Evaluation focuses primarily on language modeling benchmarks, leaving questions about performance on other architectures
- Linear approximation assumptions may not hold perfectly for deeper layers or complex data influences
- Scalability analysis for extremely long pretraining runs remains incomplete

## Confidence
- Forgetting efficacy results: **High** - Multiple benchmarks show consistent improvements over baselines with clear statistical significance
- Utility preservation claims: **Medium** - While results are positive, the evaluation could benefit from broader task diversity and more rigorous statistical analysis
- Scalability and practical deployment: **Low** - Limited analysis of computational overhead and checkpoint management at production scale

## Next Checks
1. Evaluate MSA on non-language tasks (vision, multimodal) to assess generalizability across different model architectures and data modalities
2. Conduct ablation studies on checkpoint frequency and model depth to quantify the linear approximation error and identify failure modes
3. Perform comprehensive computational overhead analysis comparing checkpoint storage costs against unlearning performance gains, including end-to-end pipeline timing