---
ver: rpa2
title: 'Designing for Learning with Generative AI is a Wicked Problem: An Illustrative
  Longitudinal Qualitative Case Series'
arxiv_id: '2507.17230'
source_url: https://arxiv.org/abs/2507.17230
tags:
- genai
- career
- students
- learning
- wicked
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper argues that designing for learning with generative AI
  (GenAI) is a "wicked problem," where progress in one area (e.g., GenAI skills) can
  impede progress in others (e.g., ethics, motivation, or career confidence). A longitudinal
  qualitative study of two students in a GenAI-integrated creative media course revealed
  these dynamics.
---

# Designing for Learning with Generative AI is a Wicked Problem: An Illustrative Longitudinal Qualitative Case Series

## Quick Facts
- arXiv ID: 2507.17230
- Source URL: https://arxiv.org/abs/2507.17230
- Reference count: 35
- Key outcome: GenAI integration creates wicked trade-offs where gains in one area (e.g., skills) can impede progress in others (e.g., ethics, motivation, career confidence)

## Executive Summary
This longitudinal qualitative study of two students in a GenAI-integrated creative media course reveals that designing for learning with GenAI is inherently a "wicked problem" - no clear solution exists because interventions in one dimension (skills, ethics, career confidence) can create new dilemmas in others. One student increased GenAI proficiency but lowered ethical standards, while another became more ethically aware but limited usage, impeding skill development. Both experienced decreased career confidence despite GenAI proficiency, suggesting that traditional uni-dimensional evaluation metrics miss critical trade-offs. The study calls for multi-dimensional evaluation tools and co-designed approaches to GenAI integration.

## Method Summary
The study conducted 4 semi-structured interviews each with 14 participants across one semester of a GenAI-integrated creative media course, focusing detailed analysis on 2 contrasting cases (Pat and Jay). Interviews ranged 42-102 minutes and used thematic analysis with a theory-driven codebook based on Social Cognitive Career Theory. Analysis compared interview 1 and 4 for each focus participant, creating pen portraits following Sheard & Marsh's four-stage method. Key RQs examined GenAI use evolution, career impact perceptions, and career outcome expectations.

## Key Results
- Pat increased GenAI skills but lowered ethical standards, describing himself as a "notorious cheater" who uses GenAI to get "all the right answers" while learning less
- Jay's heightened ethical awareness led to self-imposed usage limits (10 minutes daily) that impeded skill development
- Both students' career confidence decreased despite GenAI proficiency, with Jay expressing nervousness about professional writing

## Why This Works (Mechanism)

### Mechanism 1: Efficiency-over-engagement loops
- **Claim:** Increased GenAI proficiency correlates with lowered ethical standards for some students
- **Mechanism:** Efficiency gains create positive reinforcement loops where task completion speed overrides reflection on learning value. Students categorize work as "meaningless" and justify tool use for grades over engagement, short-circuiting the performance → self-efficacy → motivation loop.
- **Core assumption:** Students prioritize efficiency when perceived cost of reflection exceeds benefit of correct outputs
- **Evidence anchors:** Pat's statements about using AI to get "all the right answers" while acknowledging he's "learning less"
- **Break condition:** Design tasks where GenAI cannot produce passing outputs without student reflection

### Mechanism 2: Ethics-skill trade-offs
- **Claim:** Heightened ethical awareness reduces GenAI skill acquisition through self-imposed usage constraints
- **Mechanism:** Ethics instruction increases awareness of GenAI's externalities, triggering behavior change that limits practice opportunities and skill development.
- **Core assumption:** Students act consistently with ethical conclusions when they perceive agency over tool use
- **Evidence anchors:** Jay's 10-minute daily limit due to environmental concerns
- **Break condition:** Pair ethics instruction with minimal-use skill-building exercises

### Mechanism 3: Career confidence decoupling
- **Claim:** GenAI proficiency does not reliably improve career confidence and may reduce it when perceived as a labor market threat
- **Mechanism:** Students form career expectations from external narratives. Perceived threats to creative work amplify anxiety, which lowers outcome expectations and motivation regardless of individual skill gains.
- **Core assumption:** Career confidence is more sensitive to perceived structural changes than individual skill acquisition
- **Evidence anchors:** Jay's nervousness about professional writing due to rapid GenAI adoption
- **Break condition:** Career instruction with human-AI complementarity evidence and role models

## Foundational Learning

- **Concept: Wicked Problems (Rittel & Webber)**
  - **Why needed here:** Explains why GenAI integration has no clear solution and requires trade-off management rather than technical fixes
  - **Quick check question:** Can you name two characteristics that distinguish a wicked problem from a tame problem in educational design?

- **Concept: Social Cognitive Career Theory (SCCT)**
  - **Why needed here:** Provides mechanism linking task performance, self-efficacy, outcome expectations, and career motivation; explains how GenAI can short-circuit self-efficacy development
  - **Quick check question:** In SCCT, what three factors interact to shape career interests and choices?

- **Concept: Illusion of Competence**
  - **Why needed here:** Explains why students may feel academically confident despite relying on GenAI without genuine understanding
  - **Quick check question:** How might an illusion of competence persist even when a student explicitly knows they are relying on external assistance?

## Architecture Onboarding

- **Component map:** Students (varying GenAI exposure, ethics, career aspirations) → Instructional modules (prompt engineering → ethics reflection → industry panels → interleaved tasks) → Feedback loops (performance → self-efficacy → expectations → motivation) → Wicked interactions (skills ↔ ethics ↔ career confidence) → Multi-dimensional development trajectories

- **Critical path:** 1) Baseline assessment of skills, ethical reasoning, career confidence 2) Interleaved GenAI tasks with explicit ethics reflection 3) Longitudinal tracking across all three dimensions 4) Mid-course correction based on emerging trade-offs

- **Design tradeoffs:**
  - Ethics depth vs. skill practice: Deep ethical exploration may reduce usage; balance with minimal-use exercises
  - Efficiency vs. engagement: Tasks easily completed by GenAI risk shortcut behavior; design for reflection-required outputs
  - Career narratives: Honest discussion of disruption vs. anxiety amplification; pair threat awareness with agency-focused counter-narratives

- **Failure signatures:**
  - Students report high proficiency but describe work as "meaningless" or "stupid classes"
  - Ethical reflection leads to avoidance rather than discernment (total non-use vs. principled use)
  - Career confidence declines despite skill gains, especially in creative/knowledge domains

- **First 3 experiments:**
  1. Multi-dimensional baseline-to-endline tracking: Measure skills, ethical reasoning, and career confidence at course start and end for all students
  2. Minimal-use skill scaffolds: Design ethics-compatible GenAI exercises that build proficiency with minimal usage
  3. Counter-narrative intervention: Present human-AI complementarity evidence and role models in career modules

## Open Questions the Paper Calls Out

- **Open Question 1:** Can multi-dimensional measurement tools that jointly track GenAI skills, ethical reasoning, motivation, and career confidence reveal trade-offs that single-outcome metrics miss?
- **Open Question 2:** How do student trajectories differ when given different ethical, career, or disciplinary framings of GenAI (e.g., technical computing vs. creative media contexts)?
- **Open Question 3:** Do students like Pat, who express confidence despite acknowledged GenAI dependency, maintain that confidence when facing tasks without GenAI scaffolding?
- **Open Question 4:** Can co-designed GenAI integration approaches, where students participate in constructing use guidelines, reduce wicked problem dynamics compared to instructor-imposed policies?

## Limitations
- Sample size (n=2 focus participants) and attrition bias limit generalizability
- Causal mechanisms are inferred from qualitative data but not experimentally tested
- Course curriculum details are incomplete, making it difficult to assess specific instructional design features

## Confidence
- **High confidence:** GenAI integration presents multi-dimensional design challenges requiring evaluation beyond task performance metrics
- **Medium confidence:** Specific wicked problem dynamics (skills ↔ ethics ↔ career confidence trade-offs) based on two detailed longitudinal cases
- **Medium confidence:** SCCT-based mechanisms explaining why GenAI proficiency may not improve career confidence or may create ethical-skill tensions

## Next Checks
1. Replicate multi-dimensional tracking: Measure GenAI skills, ethical reasoning, and career confidence at course start and end for all students in a GenAI-integrated course
2. Test minimal-use skill scaffolds: Design ethics-compatible GenAI exercises and compare skill gains to traditional usage approaches
3. Evaluate counter-narrative interventions: Measure whether human-AI complementarity evidence buffers against confidence decline compared to control sections