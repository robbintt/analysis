---
ver: rpa2
title: 'Data-Driven Object Tracking: Integrating Modular Neural Networks into a Kalman
  Framework'
arxiv_id: '2504.02519'
source_url: https://arxiv.org/abs/2504.02519
tags:
- tracks
- association
- network
- tracking
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents a modular tracking framework integrating neural
  networks (NNs) into a Kalman Filter (KF) framework for Multi-Object Tracking (MOT)
  in ADAS. The work addresses challenges in trajectory prediction and sensor object-to-track
  association by developing three specialized NNs: SPENT (Single-Prediction Network)
  for trajectory prediction, SANT (Single-Association Network) for individual sensor
  object-to-track mapping, and MANTa (Multi-Association Network) for multiple sensor
  object-to-track associations.'
---

# Data-Driven Object Tracking: Integrating Modular Neural Networks into a Kalman Framework

## Quick Facts
- arXiv ID: 2504.02519
- Source URL: https://arxiv.org/abs/2504.02519
- Reference count: 40
- Primary result: SPENT reduces RMSE by 50% vs. standard KF; SANT/MANTa achieve up to 95% association accuracy

## Executive Summary
This paper presents a modular tracking framework integrating neural networks into a Kalman Filter for Multi-Object Tracking in ADAS. The work addresses trajectory prediction and sensor object-to-track association challenges through three specialized NNs: SPENT for trajectory prediction, SANT for individual sensor object-to-track mapping, and MANTa for multiple sensor object-to-track associations. Each network contains fewer than 50k trainable parameters and is designed for real-time, embedded inference. The NNs are seamlessly integrated into the KF framework while preserving modularity and interpretability. Evaluation on the KITTI tracking dataset demonstrates significant improvements in both prediction accuracy and association performance.

## Method Summary
The framework integrates three neural networks into a Kalman Filter framework for multi-object tracking. SPENT uses LSTM hidden states to learn motion priors for trajectory prediction, replacing hand-crafted Kalman dynamics. SANT frames sensor object-to-track association as a classification task using BiLSTM to eliminate distance metrics. MANTa extends this to multiple associations through parallel track-specific classification heads. All networks use less than 50k parameters and are trained on KITTI tracking data with synthetic association labels generated by perturbing trajectories with ≤3% noise. The framework maintains modularity while achieving significant performance improvements over traditional KF approaches.

## Key Results
- SPENT reduces Root Mean Square Error (RMSE) by 50% compared to standard KF
- SANT and MANTa achieve up to 95% accuracy in sensor object-to-track assignments
- SPENT's LSTM layer learns motion patterns directly from trajectory data rather than assuming constant velocity dynamics
- MANTa correctly assigns 95% of the dataset for timestamps containing one to six tracks

## Why This Works (Mechanism)

### Mechanism 1: LSTM Hidden States as Learned Motion Priors
Replacing hand-crafted Kalman dynamics with LSTM-learned motion patterns reduces prediction error when object trajectories exhibit non-linear behaviors. SPENT's LSTM layer accumulates temporal context in hidden states, which are updated at each timestamp. The network learns motion patterns directly from trajectory data rather than assuming constant velocity or other fixed dynamics models. Batch normalization and ReLU layers stabilize training while dropout prevents overfitting to specific motion patterns.

### Mechanism 2: Sequence-to-Classification Association Without Distance Metrics
Learning data association as a classification task eliminates reliance on hand-tuned distance thresholds and handles ambiguous assignments better than Hungarian Algorithm with fixed metrics. SANT concatenates one sensor object with n track state vectors into a matrix input. A BiLSTM layer processes this sequence bidirectionally, capturing context from both directions before dimension reduction. The FC layer outputs class probabilities via softmax, where each class represents assignment to a specific track index (or no assignment).

### Mechanism 3: Parallel Track-Specific Heads for Multi-Object Association
Decoupling multi-object association into parallel track-specific classification heads enables simultaneous m-to-n assignments while maintaining manageable output dimensionality. MANTa shares a BiLSTM encoder across all input data, then branches into T_max=16 parallel FC+softmax stacks, one per track. Each stack outputs an 18-class probability vector (16 track indices + 2 special cases). Concatenation yields a 288-element output representing all assignment hypotheses in one forward pass.

## Foundational Learning

- Concept: LSTM/Sequence Modeling
  - Why needed here: SPENT and SANT both rely on LSTM variants to capture temporal dependencies in trajectory sequences; understanding hidden state dynamics is essential for debugging prediction quality.
  - Quick check question: Can you explain why the paper uses pre-padding with sequence-length-sorted batching rather than post-padding for LSTM training?

- Concept: Cross-Entropy Loss for Structured Classification
  - Why needed here: Association networks frame track assignment as multi-class classification; understanding softmax and cross-entropy is required to interpret training diagnostics and failure modes.
  - Quick check question: Why does MANTa use 18 output classes per track rather than simply n classes for n tracks?

- Concept: Kalman Filter Fundamentals (State Prediction + Update)
  - Why needed here: The modular integration replaces specific KF components while preserving the overall TbD pipeline; understanding what each KF stage does clarifies what the NNs are replacing.
  - Quick check question: Which KF component does SPENT replace, and which components does it leave unchanged?

## Architecture Onboarding

- Component map:
  - SPENT: Input (normalized state vector, k=5) → LSTM layer → BatchNorm → ReLU → Dropout → FC → Output (predicted state)
  - SANT: Input (k×(n+1) matrix: n tracks + 1 sensor object) → BiLSTM (sequence-to-vector mode) → FC → Softmax → Output (n+1 class probabilities)
  - MANTa: Input (F_total×T_max matrix: features for all SOs and tracks) → BiLSTM → 16 parallel [FC → Softmax] heads → Concatenation → Output (288-element assignment vector)

- Critical path:
  1. Data preprocessing: Normalization (mean=0, variance=1) + sequence sorting by length + pre-padding
  2. SPENT inference: Predict T^c_{t,1:n} → X_{t,1:n} for next timestamp
  3. Association inference (SANT or MANTa): Match predicted tracks X to sensor observations Z → assignment matrix A
  4. Track management: Update confirmed tracks, initialize new tracks, delete stale tracks

- Design tradeoffs:
  - Parameter efficiency (<50k per network) vs. modeling capacity: LSTMs chosen over transformers for short-sequence computational efficiency
  - Modularity vs. end-to-end optimization: Each network trainable/evaluable independently, but no joint gradient flow
  - Synthetic GT vs. real labels: Association networks trained on perturbed trajectories; may not capture all real sensor failure modes

- Failure signatures:
  - SPENT: High RMSE on rare maneuver types (training underrepresentation)
  - SANT: Misclassification when sensor object has no valid track match (check softmax confidence on "no assignment" class)
  - MANTa: Accuracy drop for >6 simultaneous tracks (dataset imbalance; Fig. 7 shows 81.5% of samples have ≤6 tracks)

- First 3 experiments:
  1. **SPENT baseline comparison**: Train SPENT on KITTI train split, evaluate RMSE on held-out test tracks against a standard KF implementation (replicate Table I) to validate prediction improvement claims.
  2. **SANT noise sensitivity**: Generate synthetic association data with varying noise levels (1%, 3%, 5%, 10%) to characterize robustness bounds beyond the paper's 3% training noise assumption.
  3. **MANTa track-count stratification**: Evaluate MANTa accuracy separately for 1-3, 4-6, and 7+ simultaneous tracks to quantify the performance cliff and determine if oversampling or data augmentation for high-track-count scenarios helps.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do SPENT, SANT, and MANTa generalize to automotive datasets other than KITTI?
- Basis in paper: [explicit] The authors list "testing of the models on other datasets, to evaluate their generalization capabilities" as a primary topic for future research.
- Why unresolved: The current evaluation is restricted to the KITTI tracking dataset, which may not represent the full diversity of driving scenarios required for robust ADAS.
- What evidence would resolve it: Comparative performance metrics (RMSE and association accuracy) benchmarked on additional public datasets like nuScenes or Waymo Open Dataset.

### Open Question 2
- Question: How can the quantification of uncertainties be integrated into the modular framework to improve decision-making?
- Basis in paper: [explicit] The conclusion explicitly identifies "the quantification of uncertainties" as a target for future investigation.
- Why unresolved: The networks currently output deterministic state predictions and associations without confidence intervals, limiting the system's ability to weigh risks in ambiguous situations.
- What evidence would resolve it: A modified architecture that outputs probabilistic distributions and an analysis showing improved tracking reliability or failure prediction.

### Open Question 3
- Question: How can the MANTa architecture be stabilized to handle high-density scenes with seven or more simultaneous tracks?
- Basis in paper: [inferred] The paper reports that MANTa achieves 95% accuracy for 1-6 tracks but drops to 14% accuracy for 7-16 tracks, attributing this to unbalanced training data (Fig. 7).
- Why unresolved: The training set contains insufficient samples of high-track-count scenarios, causing the model to fail in complex, cluttered environments.
- What evidence would resolve it: Evaluation results showing consistent accuracy (>90%) across all track densities (1-16) achieved through data augmentation or architectural adjustments.

## Limitations

- Architecture hyperparameters (LSTM sizes, learning rates, dropout rates) are not specified
- Exact noise distribution (uniform vs. Gaussian) for synthetic association training data is undefined
- Baseline KF implementation details are internal and may not be directly reproducible
- MANTa performance degrades significantly (14%) for >6 simultaneous tracks due to dataset imbalance
- 95% accuracy claims for SANT/MANTa not validated against transformer-based joint association methods

## Confidence

- High confidence: SPENT's 50% RMSE reduction claims given clear methodology and direct comparison to KF baseline
- Medium confidence: SANT/MANTa's 95% accuracy claims due to synthetic training data limitations and lack of external validation
- Low confidence: Real-world generalization beyond KITTI cars/vans given limited motion pattern coverage

## Next Checks

1. Replicate SPENT vs. KF RMSE comparison on held-out KITTI test split to validate prediction improvement claims
2. Test SANT robustness across 1%, 3%, 5%, and 10% noise levels to characterize accuracy bounds
3. Stratify MANTa accuracy by track count (1-3, 4-6, 7+) to quantify performance cliff and evaluate oversampling strategies for high-track scenarios