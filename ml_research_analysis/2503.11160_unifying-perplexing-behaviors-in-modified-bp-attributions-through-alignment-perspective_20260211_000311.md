---
ver: rpa2
title: Unifying Perplexing Behaviors in Modified BP Attributions through Alignment
  Perspective
arxiv_id: '2503.11160'
source_url: https://arxiv.org/abs/2503.11160
tags:
- input
- attribution
- alignment
- information
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides a unified theoretical framework for explaining
  the perplexing behaviors of modified backpropagation (BP) attribution methods. The
  authors demonstrate that methods like GBP, RectGrad, LRP, and DTD belong to a Negative
  Filtering Rule (NFR) category, which aligns with input data through cascade alignment
  by combining weights of activated neurons.
---

# Unifying Perplexing Behaviors in Modified BP Attributions through Alignment Perspective

## Quick Facts
- **arXiv ID:** 2503.11160
- **Source URL:** https://arxiv.org/abs/2503.11160
- **Reference count:** 40
- **Primary Result:** Provides unified theoretical framework explaining perplexing behaviors of modified BP attribution methods through cascade alignment perspective

## Executive Summary
This paper presents a unified theoretical framework explaining the perplexing behaviors of modified backpropagation (BP) attribution methods including GBP, RectGrad, LRP, and DTD. The authors demonstrate that these methods belong to a Negative Filtering Rule (NFR) category that achieves alignment with input data through cascade alignment by combining weights of activated neurons. The framework explains why these methods produce better visualizations and are less sensitive to weight randomization. The paper introduces Key Information Sufficiency (KIS) as a new metric for evaluating attribution reliability, which correlates with model generalizability. Additionally, the authors categorize backdoor features into two types based on their reliance on contextual information, offering new insights for backdoor attack evaluation.

## Method Summary
The authors propose a unified framework based on Negative Filtering Rule (NFR) and cascade alignment to explain modified BP attribution methods. They introduce Key Information Sufficiency (KIS) as a metric for evaluating attribution reliability and categorize backdoor features into contextual and non-contextual types. The framework is validated through experiments on ImageNet and CIFAR-10 datasets, demonstrating improved visualization quality and reduced sensitivity to weight randomization compared to existing theories.

## Key Results
- Demonstrates that GBP, RectGrad, LRP, and DTD belong to NFR category achieving alignment through cascade alignment
- Introduces KIS metric showing correlation between attribution reliability and model generalizability
- Categorizes backdoor features into two types based on contextual information reliance
- Shows improved visualization quality and reduced weight randomization sensitivity for NFR methods

## Why This Works (Mechanism)
The unified framework works by recognizing that modified BP methods follow a Negative Filtering Rule that progressively filters out irrelevant information while preserving key features through cascade alignment. This alignment process combines weights of activated neurons in a way that naturally improves visualization quality and reduces sensitivity to weight randomization. The KIS metric captures this alignment quality by measuring how well the attribution preserves essential information for correct classification.

## Foundational Learning
- **Cascade Alignment:** Progressive alignment of attribution with input data through filtering - needed to understand how modified BP methods improve visualization quality
- **Negative Filtering Rule (NFR):** Mechanism that filters out irrelevant information while preserving key features - essential for understanding the unified framework
- **Key Information Sufficiency (KIS):** Metric measuring attribution reliability based on information preservation - crucial for evaluating attribution quality
- **Backdoor Feature Categorization:** Classification of backdoor features into contextual and non-contextual types - important for understanding backdoor attack evaluation
- **Attribution Alignment:** Process of aligning attribution maps with input data - fundamental to understanding visualization improvements
- **Weight Randomization Sensitivity:** Measure of attribution robustness to model weight changes - key for evaluating attribution reliability

## Architecture Onboarding
**Component Map:** Input Image -> Modified BP Attribution (GBP/RectGrad/LRP/DTD) -> Cascade Alignment Process -> KIS Metric -> Visualization Output

**Critical Path:** Input data flows through modified BP method, undergoes cascade alignment filtering, and produces attribution map evaluated by KIS metric for reliability assessment.

**Design Tradeoffs:** The framework prioritizes visualization quality and attribution reliability over computational efficiency, as the cascade alignment process may increase computational overhead compared to standard BP.

**Failure Signatures:** Poor visualization quality, high sensitivity to weight randomization, low KIS scores, and inability to distinguish between contextual and non-contextual backdoor features indicate framework limitations.

**First Experiments:**
1. Test cascade alignment framework across different model architectures (CNNs, transformers, RNNs)
2. Validate KIS metric correlation with generalizability across diverse datasets
3. Evaluate backdoor feature categorization using multiple attack scenarios and datasets

## Open Questions the Paper Calls Out
None specified in the provided information.

## Limitations
- Experimental validation primarily focuses on image classification tasks, limiting domain generalizability
- Framework's effectiveness across diverse model architectures beyond tested convolutional networks remains uncertain
- KIS metric correlation with generalizability may be dataset-dependent and requires broader validation
- Backdoor feature categorization methodology needs more rigorous statistical validation

## Confidence
- Cascade alignment theory explaining NFR methods: High
- KIS metric reliability: Medium
- Backdoor feature categorization: Medium
- Cross-domain Generalization: Low

## Next Checks
1. Test the cascade alignment framework and KIS metric across diverse model types (NLP, audio, multimodal) to verify domain generalizability
2. Conduct ablation studies on different network architectures (transformer-based, recurrent networks) to validate the robustness of the theoretical claims
3. Perform statistical analysis on the backdoor feature categorization method using larger datasets and multiple attack scenarios to confirm the reliability of the contextual vs. non-contextual distinction