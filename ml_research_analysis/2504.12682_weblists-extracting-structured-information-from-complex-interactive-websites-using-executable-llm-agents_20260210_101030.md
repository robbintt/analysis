---
ver: rpa2
title: 'WebLists: Extracting Structured Information From Complex Interactive Websites
  Using Executable LLM Agents'
arxiv_id: '2504.12682'
source_url: https://arxiv.org/abs/2504.12682
tags:
- agent
- data
- agents
- page
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces WebLists, a benchmark for evaluating web agents
  on structured data extraction tasks across diverse websites. The benchmark addresses
  the gap between academic web agent evaluations (focused on navigation and transactions)
  and real-world business needs (requiring structured data extraction at scale).
---

# WebLists: Extracting Structured Information From Complex Interactive Websites Using Executable LLM Agents

## Quick Facts
- arXiv ID: 2504.12682
- Source URL: https://arxiv.org/abs/2504.12682
- Reference count: 14
- The paper introduces WebLists, a benchmark for evaluating web agents on structured data extraction tasks across diverse websites, achieving 66% recall with their BardeenAgent framework.

## Executive Summary
This paper addresses the gap between academic web agent evaluations and real-world business needs by introducing WebLists, a benchmark for structured data extraction from complex interactive websites. The benchmark includes 200 tasks across four use-cases on 50 websites, requiring agents to navigate, interact with dynamic content, and extract data following specific schemas. The authors propose BardeenAgent, a novel framework that converts agent actions into executable programs with CSS selectors, enabling scalable data extraction with significantly improved recall and reduced costs compared to state-of-the-art web agents.

## Method Summary
BardeenAgent operates in two phases: recording and replay. During recording, an LLM agent navigates to a list structure and extracts a single item while recording actions. These actions are then compiled into a deterministic program with CSS selectors during replay, which processes the remaining items at scale. The framework leverages HTML structure regularity and uses specialized tools for navigation and data extraction, with LLM intervention limited to fallback scenarios. This approach reduces the compounding error rate and cost associated with large-scale data extraction by shifting computational load from repeated LLM inferences to a single program execution.

## Key Results
- BardeenAgent achieves 66% recall overall, more than doubling the performance of state-of-the-art web agents
- The framework reduces cost per output row by 3x compared to baseline approaches
- Outperforms commercial tools like Airtable AI and Zapier on structured data extraction tasks

## Why This Works (Mechanism)

### Mechanism 1: Record-Replay Pattern for Cost Efficiency
Converting agent actions into reusable programs significantly reduces the compounding error rate and cost associated with large-scale data extraction. The agent operates in two phases: a "Record" phase where it uses an LLM to navigate and extract a single item, and a "Replay" phase where the recorded actions are compiled into a deterministic program (script) to process the remaining items. This shifts the computational load from repeated LLM inferences (per item) to a single program execution (per list).

### Mechanism 2: HTML Structure Regularity for Complete Data Capture
Leveraging the regular structure of HTML via generalizable CSS selectors allows the agent to capture complete datasets that would otherwise exceed LLM context windows. Instead of treating the page as a bag of text, the agent identifies list structures and generates a CSS selector that matches all relevant elements, effectively "looping" through the DOM without re-querying the LLM for navigation steps.

### Mechanism 3: Decoupled Control Flow and Data Extraction
Decoupling the control flow (navigation) from the data extraction (content parsing) prevents hallucination and improves precision on structured tasks. The agent uses specific tools for specific data types which rely on DOM attributes rather than LLM text generation, relegating LLM intervention to a fallback tool used only when specific data cannot be cleanly parsed from the HTML structure.

## Foundational Learning

- **Concept: DOM Accessibility Trees vs. Raw HTML**
  - **Why needed here:** BardeenAgent relies on "leaf elements" and CSS selectors. Understanding the difference between raw source HTML and the rendered accessibility tree is critical to understanding why BardeenAgent can generate CSS selectors while others cannot.
  - **Quick check question:** Can you explain why an ID like `#item-482` might be a bad selector for a replay script compared to a class like `.blog-post`?

- **Concept: POMDP (Partially Observable Markov Decision Process)**
  - **Why needed here:** The paper explicitly models the web agent problem as a POMDP. Understanding that the agent only sees an "observation" (the DOM) and not the full "state" (server database) is key to understanding why it must "interact" to reveal data.
  - **Quick check question:** In the context of this paper, what constitutes the "observation" versus the "state" when a user is filtering a job board?

- **Concept: Record-Replay Patterns**
  - **Why needed here:** This is the core architectural shift in BardeenAgent. One must understand standard "Record-Replay" (used in testing) to see how the authors adapted it for LLMs (recording *intent* via CSS rather than just coordinates).
  - **Quick check question:** What is the specific failure mode the authors prevent by converting "temporary numeric DOM element IDs" into "robust CSS selectors" during the recording phase?

## Architecture Onboarding

- **Component map:**
  1. Browser Environment (live Chrome/Chromium instance executing actions)
  2. Policy Model (GPT-4 Turbo) -> 3. Selector Model (Gemini 1.5 Pro) -> 4. Verifier Model -> 5. Agent DSL

- **Critical path:**
  1. Goal Definition: Define the schema (columns) and the starting URL
  2. Recording: The Policy Model navigates to the list and calls `EnterList`
  3. Selector Generalization: The system identifies the CSS pattern for list items
  4. Single-Item Extraction: The Policy Model extracts data for *only* the first item
  5. Program Synthesis: The system wraps the single-item extraction in a loop using the generated CSS selector
  6. Replay: The synthesized program runs autonomously, paginating and extracting until the list ends

- **Design tradeoffs:**
  - Recall vs. Precision: Optimized for high recall but may suffer from lower precision if CSS selector is too broad
  - Cost vs. Latency: Initial setup expensive (large context windows) but replay phase is cheap

- **Failure signatures:**
  - Early Termination: Agent calls `Finish()` before extracting all items
  - List Misidentification: Agent enters list mode on navigation menu instead of content area
  - Pagination Loops: Agent fails to detect end of list, causing infinite loop

- **First 3 experiments:**
  1. Static List Extraction: Run BardeenAgent on single-page blog with 20 posts to verify `EnterList` and CSS selector generation
  2. Pagination Stress Test: Test on "Jobs" board with 5+ pages to verify Replay loop handles "Next" button state changes
  3. Dynamic Filter Interaction: Test "Job Categories" use case to verify Policy Model can interact with dropdowns/filters before Record phase

## Open Questions the Paper Calls Out
None

## Limitations
- The core claim of 66% recall relies heavily on the assumption that website structure remains consistent across list items, which may not hold for websites with dynamic content loading or adaptive layouts
- Cost efficiency claims don't account for total cost including the initial "Record" phase setup, which requires large-context LLM calls
- The benchmark's narrow scope on structured list extraction may not generalize to other common web agent use cases like form filling or complex decision-making scenarios

## Confidence
- **High Confidence**: The mechanism of converting agent actions into executable programs with CSS selectors is technically sound and demonstrably reduces per-item LLM inference costs
- **Medium Confidence**: The 66% recall improvement claim is robust within the benchmark's scope, but generalizability to unstructured websites remains uncertain
- **Low Confidence**: The scalability claims beyond the tested 50 websites and the assumption that all structured data extraction can be reduced to list-based CSS selectors

## Next Checks
1. Cross-Domain Stress Test: Deploy BardeenAgent on 10 additional websites from sectors not represented in the original benchmark (e.g., e-commerce product listings with infinite scroll, financial data tables with AJAX loading) to assess generalizability.

2. Dynamic Content Failure Analysis: Systematically test websites that employ common anti-scraping techniques (randomized class names, client-side rendering, rate limiting) to quantify the failure rate and determine whether CSS selector generalization breaks down under these conditions.

3. Cost-Benefit Break-Even Analysis: Calculate the minimum number of extraction tasks required to amortize the initial Record phase cost across different website types and extraction frequencies, providing practitioners with clear ROI thresholds for adopting this approach.