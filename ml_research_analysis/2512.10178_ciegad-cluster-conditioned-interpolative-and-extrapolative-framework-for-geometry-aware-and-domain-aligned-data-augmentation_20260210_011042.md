---
ver: rpa2
title: 'CIEGAD: Cluster-Conditioned Interpolative and Extrapolative Framework for
  Geometry-Aware and Domain-Aligned Data Augmentation'
arxiv_id: '2512.10178'
source_url: https://arxiv.org/abs/2512.10178
tags:
- data
- augmentation
- ciegad
- generation
- samples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CIEGAD addresses data scarcity and imbalance in deep learning by
  providing a framework that generates augmented data through both interpolative and
  extrapolative synthesis, guided by cluster-conditioned domain profiles. It employs
  a hierarchical frequency-geometric allocation to prioritize minority classes and
  sparse regions, and uses geometric constraint filtering combined with LLM-as-a-Judge
  for quality control.
---

# CIEGAD: Cluster-Conditioned Interpolative and Extrapolative Framework for Geometry-Aware and Domain-Aligned Data Augmentation

## Quick Facts
- arXiv ID: 2512.10178
- Source URL: https://arxiv.org/abs/2512.10178
- Reference count: 0
- Primary result: CIEGAD improves F1 and recall scores in imbalanced and multi-class scenarios by generating augmented data via cluster-conditioned domain profiles and geometric allocation.

## Executive Summary
CIEGAD addresses data scarcity and imbalance in deep learning by providing a framework that generates augmented data through both interpolative and extrapolative synthesis, guided by cluster-conditioned domain profiles. It employs a hierarchical frequency-geometric allocation to prioritize minority classes and sparse regions, and uses geometric constraint filtering combined with LLM-as-a-Judge for quality control. Experiments on IMDb, Yelp, Emo-6class, and Emo-13class datasets show that CIEGAD improves F1 and recall scores, particularly in long-tailed and multi-class scenarios, while maintaining strong domain alignment and semantic diversity.

## Method Summary
CIEGAD constructs domain profiles through cluster conditioning, where each class is partitioned into clusters using k-means, and core/periphery examples are selected based on distance from cluster centroids. LLM-generated summaries and structured information from these examples condition subsequent data generation. Hierarchical frequency-geometric allocation prioritizes minority classes and geometrically sparse regions, while geometric constraints guide interpolation (between inner/outer centroids) and extrapolation (beyond outer centroids). Quality control is enforced via similarity filters and LLM-as-a-Judge scoring, iterating until generation quotas are met.

## Key Results
- CIEGAD improves F1 and recall scores, especially in long-tailed (Emo-13class) and multi-class scenarios.
- Geometric constraint filtering reduces distributional drift (FED) and maintains domain alignment.
- HFGA allocation increases coverage of underrepresented regions while mitigating class imbalance.

## Why This Works (Mechanism)

### Mechanism 1: Cluster-Conditioned Domain Profiles
- Claim: Local domain profiles preserve lexical, stylistic, and emotional characteristics during generation that class-label conditioning alone cannot capture.
- Mechanism: For each class, k-means partitions data into K clusters (K determined by sample count). Within each cluster, the 10 samples nearest the centroid become "core examples" and 10 farthest become "periphery examples." An LLM extracts cluster-level summaries and structured topic/expression information from these examples, which then condition subsequent generation.
- Core assumption: Clusters correspond to meaningful sub-structures (stylistic, topical, affective) within class labels.
- Evidence anchors:
  - [abstract] "constructs domain profiles through cluster conditioning"
  - [Section III.B] Describes dynamic cluster number determination via K_y = min(⌊N_y/κ⌋+2, high) and core/periphery selection based on Euclidean distance from centroid.
  - [corpus] Weak direct evidence; related work on graph augmentation (SPECTRA) addresses sparse regions but does not validate cluster-conditioned profiles for text.
- Break condition: If clusters fragment semantic coherence (e.g., random partitioning) or if core/periphery samples fail to capture distributional shape, domain profiles will misguide generation.

### Mechanism 2: Hierarchical Frequency–Geometric Allocation (HFGA)
- Claim: Allocating more generation quota to small, isolated, and sparse clusters improves coverage of underrepresented regions while mitigating class imbalance.
- Mechanism: Two-level allocation. Class-level: inverse-frequency weighting prioritizes minority classes. Cluster-level: priority score v_{y,k} = α·(1/N_{y,k}) + β·min_separation + γ·local_sparsity. Generation quota distributes proportionally to v_{y,k}.
- Core assumption: Geometric indicators (cluster size, inter-cluster distance, intra-cluster sparsity) correlate with semantically uncovered regions.
- Evidence anchors:
  - [abstract] "allocates generation with a hierarchical frequency–geometric allocation integrating class frequency and geometric indicators"
  - [Section III.C] Equations (2)–(5) formalize the allocation; (α,β,γ)=(0.5,0.25,0.25) balances class imbalance correction with geometric diversity.
  - [corpus] SPECTRA addresses sparse target regions in molecular property prediction via spectral augmentation, offering weak analogical support for geometry-aware allocation in non-text domains.
- Break condition: If embedding geometry does not reflect semantic coverage gaps (e.g., embeddings cluster artifactually), allocation will misplace generation effort.

### Mechanism 3: Geometric Constraint Filters for Interpolation and Extrapolation
- Claim: Constraining accepted samples to lie between inner/outer centroids (interpolation) or beyond outer centroids (extrapolation) ensures generated data fills semantically uncovered regions without excessive distributional drift.
- Mechanism: Interpolation accepts samples where ||x_new − z̄_inner||² ≤ ||z̄_outer − z̄_inner||². Extrapolation accepts samples where ||x_new − z̄_outer||² ≥ γ·||z̄_outer − z̄_inner||² (γ=0.03). Samples violating constraints are discarded before quality evaluation.
- Core assumption: Embedding space distances meaningfully bound semantic containment and directional expansion.
- Evidence anchors:
  - [abstract] "finely controls generation directions via the coexistence of interpolative and extrapolative synthesis"
  - [Section III.D] Equations (6) and (7) define the geometric constraints; Algorithm 2 operationalizes the iterative generation loop.
  - [corpus] No direct external validation; Interpolative Decoding paper explores interpolation in LLM personality space but does not address geometric filtering for data augmentation.
- Break condition: If embeddings poorly encode task-relevant semantics (e.g., generic embeddings for domain-specific emotion nuance), geometric constraints may reject valid samples or accept irrelevant ones.

## Foundational Learning

- **K-means clustering and centroid-based partitioning**
  - Why needed here: CIEGAD dynamically clusters per-class data and uses centroids to define core/periphery and inner/outer sets.
  - Quick check question: Given a 2D point cloud with two visible blobs, can you sketch how k-means with k=2 would assign cluster labels and compute centroids?

- **Embedding spaces and distance metrics (Euclidean, cosine)**
  - Why needed here: All geometric constraints and similarity filters operate in embedding space; Euclidean distance defines containment, cosine similarity filters redundancy.
  - Quick check question: For two sentence embeddings with cosine similarity 0.95, what does this imply about their semantic relationship, and would a threshold of θ=0.85 filter one as redundant?

- **LLM prompting with in-context examples**
  - Why needed here: Domain profiles and inner/outer examples are injected into prompts to condition generation; prompt structure directly affects alignment and diversity.
  - Quick check question: If a prompt includes 10 core examples from a cluster and instructs "generate similar but novel sentences," what failure mode might occur if the examples are too homogeneous?

## Architecture Onboarding

- **Component map:**
  Embedding layer -> Clustering module -> Domain profile constructor -> HFGA allocator -> Generation controller -> Quality gate -> Iteration loop

- **Critical path:**
  Domain profile construction -> HFGA quota assignment -> Geometric constraint filtering. If any of these misfire (bad clusters, wrong quotas, loose constraints), downstream quality degrades.

- **Design tradeoffs:**
  - **Interpolation vs. extrapolation ratio:** More interpolation improves in-distribution density; more extrapolation improves OOD robustness but risks drift.
  - **Filter thresholds (θ=0.85 for intra-batch, θ=0.9 for prompt-overlap, γ=0.03 for extrapolation margin):** Stricter thresholds reduce noise but may discard useful samples.
  - **Cluster count formula (κ=800, high=18):** Higher granularity captures fine structure but risks over-segmentation and sparse clusters.

- **Failure signatures:**
  - **Distribution drift:** FED increases sharply; generated samples cluster away from real data in t-SNE.
  - **Low semantic novelty:** SNI near zero; generated samples overly similar to prompt references (prompt-overlap filter too loose).
  - **Over-rejection:** Few samples accepted despite many generation cycles; geometric constraints or LLM-as-a-Judge thresholds too strict.
  - **Imbalance persistence:** F1/recall gains minimal; HFGA not concentrating quota on minority clusters (check v_{y,k} distribution).

- **First 3 experiments:**
  1. **Binary classification pilot (IMDb subset):** Implement full pipeline with ρ=0.5. Verify OER, SNI, FED metrics are within expected ranges; inspect t-SNE for alignment.
  2. **Long-tailed multi-class stress test (Emo-13class):** Run HFGA allocation logging to confirm minority clusters receive higher quotas; compare F1/recall against baseline.
  3. **Ablation of geometric constraints:** Disable geometric filters (w/o Geometry variant) and measure FED and OER increase; confirm direction control mechanism contribution.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does varying the fixed sample size of the inner and outer sets (currently set to ten) impact the precision of geometric interpolation and extrapolation?
- **Basis in paper:** [explicit] Section VI.B notes that the sample size was fixed at ten and that "A systematic analysis of how these parameters influence generation quality and expansion efficiency remains an important direction."
- **Why unresolved:** The authors utilized a static configuration based on empirical stability, leaving the trade-off between finer directional control and computational overhead unexplored.
- **What evidence would resolve it:** An ablation study comparing generation quality (SNI, FED) and runtime across varying set sizes (e.g., 5, 10, 20, 50) on the Emo-13class dataset.

### Open Question 2
- **Question:** Can CIEGAD maintain high fidelity and factual consistency when applied to complex domains beyond emotion recognition, such as news classification or policy document analysis?
- **Basis in paper:** [explicit] Section VI.B states the evaluation was restricted to emotion recognition and suggests future work should explore "mechanisms that can dynamically balance generation diversity and fidelity" for domains requiring stricter factual consistency.
- **Why unresolved:** The current domain profiles focus on stylistic and affective features, which may not sufficiently constrain hallucinations in fact-sensitive tasks.
- **What evidence would resolve it:** Experimental results on factual datasets (e.g., news topic classification) measuring accuracy and hallucination rates before and after CIEGAD augmentation.

### Open Question 3
- **Question:** To what extent can the framework be reproduced using lightweight, open-source local models without losing controllability or coherence?
- **Basis in paper:** [explicit] Section VI.B highlights that "smaller open-source models struggle with precise output control" and identifies reproducing CIEGAD with local models as an important step for practical deployment.
- **Why unresolved:** The framework currently relies on closed, high-performing APIs (GPT-4) to ensure strict adherence to complex geometric and stylistic constraints.
- **What evidence would resolve it:** A comparative study implementing CIEGAD using open-source models (e.g., Llama 3, Mistral) and evaluating the resulting data against the OER, SNI, and FED benchmarks.

## Limitations
- The effectiveness of cluster-conditioned domain profiles relies heavily on the semantic coherence of k-means partitions, which may degrade for noisy or highly overlapping class distributions.
- Geometric constraint filtering assumes Euclidean distances in embedding space map meaningfully to semantic containment and directional expansion, which may fail if embeddings do not encode task-relevant nuance.
- The LLM-as-a-Judge introduces both cost and subjectivity; scores may not generalize across domains or model versions, and repeated filtering could bias the augmented set toward LLM-preferred patterns rather than task-relevant diversity.

## Confidence
- **High confidence:** Hierarchical frequency-geometric allocation (HFGA) as a principled method to balance class and geometric coverage; geometric constraint filtering as a mechanism for direction control in generation.
- **Medium confidence:** Cluster-conditioned domain profiles meaningfully improve domain alignment and semantic coherence; LLM-as-a-Judge provides consistent quality control across domains.
- **Low confidence:** The specific hyperparameter settings (κ=800, γ=0.03, θ thresholds) generalize beyond the tested datasets; the framework's robustness to embedding quality degradation or highly imbalanced real-world scenarios.

## Next Checks
1. **Embedding sensitivity test:** Repeat the full pipeline using two different Sentence Transformer variants (e.g., all-MiniLM-L6-v2 vs. paraphrase-MiniLM-L3-v2) on IMDb and Emo-13class; compare OER, SNI, FED, and downstream F1 to quantify embedding impact.
2. **Cluster coherence validation:** For each dataset, compute average silhouette score per class and inter-cluster semantic similarity (via LLM scoring of nearest-neighbor pairs across clusters); verify that k-means partitions align with semantic sub-structures.
3. **Geometric constraint ablation under drift:** Systematically relax geometric constraints (γ → 0.01, 0.05) and monitor FED and OER; confirm that direction control is both necessary and sufficient to prevent excessive distributional drift while maintaining semantic novelty.