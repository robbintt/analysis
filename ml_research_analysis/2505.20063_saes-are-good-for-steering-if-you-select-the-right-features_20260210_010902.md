---
ver: rpa2
title: SAEs Are Good for Steering -- If You Select the Right Features
arxiv_id: '2505.20063'
source_url: https://arxiv.org/abs/2505.20063
tags:
- features
- steering
- output
- score
- input
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates Sparse Autoencoder (SAE) features for steering
  large language models (LLMs) and distinguishes between input features (capturing
  input patterns) and output features (directly influencing generated tokens). The
  authors introduce input and output scores to identify these feature types, finding
  that high values for both scores rarely co-occur.
---

# SAEs Are Good for Steering -- If You Select the Right Features

## Quick Facts
- arXiv ID: 2505.20063
- Source URL: https://arxiv.org/abs/2505.20063
- Authors: Dana Arad; Aaron Mueller; Yonatan Belinkov
- Reference count: 40
- Primary result: SAE steering effectiveness improves 2-3x when filtering features by output scores, achieving 90.7% of supervised LoRA performance on AxBench

## Executive Summary
This paper addresses a fundamental challenge in Sparse Autoencoder (SAE) steering: selecting the right features to modify. The authors demonstrate that not all SAE features are equally effective for steering, with a crucial distinction between input features (capturing input patterns) and output features (directly influencing generated tokens). By introducing a systematic method to identify and filter features based on their output influence, the paper shows that SAE steering can achieve performance competitive with supervised methods like LoRA. The key insight is that features with high output scores are significantly more effective for steering tasks, and filtering out low-output-score features can improve steering effectiveness by 2-3x.

## Method Summary
The authors develop a systematic approach to identify and classify SAE features based on their role in the model. They introduce two metrics: input scores (measuring how much a feature responds to input patterns) and output scores (measuring how much a feature directly influences generated tokens). By analyzing the relationship between these scores across different features, they establish that features with high output scores are the most effective for steering. The method involves computing these scores for all features, then filtering out those with low output scores before applying steering interventions. This approach is evaluated across multiple steering tasks using the AxBench benchmark, comparing performance against both unfiltered SAE steering and supervised methods like LoRA.

## Key Results
- Features with high output scores are significantly more effective for steering, improving effectiveness by 2-3x when low-output-score features are filtered out
- SAE steering with output-score-based filtering achieves 90.7% of the performance of the best supervised method (LoRA) on AxBench
- High values for input and output scores rarely co-occur, confirming the distinction between input and output features
- The proposed feature selection method makes SAE steering competitive with supervised approaches for the first time

## Why This Works (Mechanism)
The effectiveness of SAE steering depends critically on selecting features that directly influence token generation rather than just capturing input patterns. The authors demonstrate that SAE features can be categorized into two types: those that primarily respond to input patterns (input features) and those that directly influence what tokens are generated (output features). By introducing metrics to quantify each feature's input and output influence, they show that steering works best when focusing on output features. The mechanism works because output features have a more direct causal relationship with the model's behavior, while input features may capture patterns that don't translate into meaningful steering changes.

## Foundational Learning

**Sparse Autoencoders (SAEs)**: Neural networks trained to compress and reconstruct activations with sparsity constraints. Needed to understand the feature decomposition approach; quick check: verify SAE reconstruction quality on held-out data.

**Feature Attribution**: Methods to determine which features contribute to model outputs. Needed to understand how features influence generation; quick check: compare feature importance rankings across different attribution methods.

**Steering in LLMs**: The practice of modifying model behavior without fine-tuning. Needed to understand the application context; quick check: verify baseline steering performance without feature selection.

**AxBench Benchmark**: A collection of steering tasks for evaluating LLM steering methods. Needed to understand evaluation methodology; quick check: confirm task diversity and difficulty levels.

**Feature Scoring Metrics**: Quantitative measures of feature influence on inputs vs outputs. Needed to understand the proposed selection methodology; quick check: validate score stability across different input samples.

## Architecture Onboarding

**Component Map**: SAE Encoder -> Feature Scores (Input/Output) -> Feature Filter -> Steering Intervention -> Model Outputs

**Critical Path**: Feature selection (input/output scoring) → feature filtering → steering intervention → output generation. The feature selection step is critical because poor feature choices can negate the benefits of steering entirely.

**Design Tradeoffs**: The paper trades computational overhead of feature scoring for improved steering effectiveness. While computing input/output scores adds preprocessing time, the 2-3x improvement in steering effectiveness justifies this cost for most applications.

**Failure Signatures**: Steering fails when applying features with high input scores but low output scores, resulting in minimal behavioral change. Also fails when the feature scoring method doesn't generalize to new inputs or tasks.

**First Experiments**: 1) Verify the input/output score distribution across features on held-out data, 2) Test steering effectiveness with different score thresholds for feature filtering, 3) Compare feature attribution methods to ensure score stability.

## Open Questions the Paper Calls Out

The paper identifies several open questions: How generalizable is the input/output feature distinction across different model architectures and training paradigms? Can the feature scoring methodology be extended to other unsupervised steering approaches? What is the relationship between SAE feature selection and other feature attribution methods?

## Limitations

- Results are primarily validated on Llama-2 7B, limiting generalizability to larger models or different architectures
- Evaluation relies heavily on the AxBench benchmark, which may not capture all steering challenges
- The claim that high input and output scores rarely co-occur may be dataset-dependent and needs broader validation
- The 2-3x improvement claim needs comparison with alternative filtering methods beyond just unfiltered features

## Confidence

**High Confidence**:
- The distinction between input and output features is well-supported by experimental evidence
- The 2-3x improvement in steering effectiveness with output-score filtering is consistently observed
- The competitive performance claim against LoRA (90.7%) is backed by benchmark results

## Next Checks

1. Test the feature selection methodology across multiple model families and sizes to assess generalizability
2. Validate the input-output feature distinction on tasks beyond those in AxBench
3. Compare SAE steering performance with other unsupervised steering methods to establish relative effectiveness