---
ver: rpa2
title: Noise-Adaptive Regularization for Robust Multi-Label Remote Sensing Image Classification
arxiv_id: '2601.08446'
source_url: https://arxiv.org/abs/2601.08446
tags:
- noise
- label
- learning
- subtractive
- additive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of multi-label remote sensing
  image classification under noisy annotations, which commonly arise from crowdsourced
  or thematic product labeling. The authors propose NAR, a noise-adaptive regularization
  method that explicitly distinguishes between additive and subtractive noise types
  within a semi-supervised learning framework.
---

# Noise-Adaptive Regularization for Robust Multi-Label Remote Sensing Image Classification

## Quick Facts
- arXiv ID: 2601.08446
- Source URL: https://arxiv.org/abs/2601.08446
- Reference count: 40
- Primary result: NAR consistently outperforms existing methods, particularly under subtractive and mixed noise conditions, achieving 2-6% improvements in mean average precision macro across noise rates up to 60%.

## Executive Summary
This paper addresses multi-label remote sensing image classification under noisy annotations by proposing NAR, a noise-adaptive regularization method that explicitly handles additive and subtractive noise types. NAR employs a confidence-based three-state mechanism that dynamically retains high-confidence label entries, deactivates moderately uncertain entries, and corrects low-confidence entries through flipping. This selective attenuation of supervision is integrated with early-learning regularization (ELR) to stabilize training and mitigate overfitting to corrupted labels. Experiments across three datasets (UCMerdes, DeepGlobe-ML, AID-ML) show consistent performance improvements, particularly under subtractive and mixed noise conditions.

## Method Summary
NAR modifies standard BCE by applying per-entry weights and corrected labels based on prediction confidence thresholds. The method employs a three-state mechanism: retain entries where prediction confidence aligns with labels, deactivate entries with moderate confidence (treating them as unlabeled), and flip entries where confidence strongly contradicts the label. This selective attenuation is integrated with early-learning regularization that penalizes deviation from early-learned patterns. The framework uses ResNet-18 with AdamW optimizer, cosine annealing learning rate, and validation-based model selection across noise rates from 10% to 60% with controlled additive, subtractive, and mixed noise injection.

## Key Results
- NAR achieves 2-6% improvements in mAP macro across noise rates up to 60% compared to baseline BCE and other regularization methods
- Under subtractive noise, NAR shows the largest improvements (up to 6%) as it effectively handles false negative annotations
- Oracle experiments show deactivation recovers approximately 80% of optimal performance, with flipping providing additional gains when noisy entries are accurately identified
- ELR regularization consistently improves performance across most datasets and noise types, though NAR without ELR occasionally performs better on specific configurations

## Why This Works (Mechanism)

### Mechanism 1: Confidence-Based Three-State Label Handling
NAR employs a confidence-based label handling mechanism that dynamically retains label entries with high confidence, temporarily deactivates entries with moderate confidence, and corrects low confidence entries via flipping. This transforms noisy supervision into a semi-supervised problem at the label-entry level, where four thresholds partition the confidence space into three actions. The core assumption is that model predictions become increasingly reliable indicators of ground truth as training progresses, and prediction confidence correlates with label correctness. Oracle experiments show deactivation recovers approximately 80% of attainable performance; flipping provides additional gains only when noisy entries are accurately identified.

### Mechanism 2: Early-Learning Regularization (ELR) Adaptation
The method integrates early-learning regularization to stabilize training and mitigate overfitting to corrupted labels. The ELR term penalizes deviation from early-learned patterns by reinforcing predictions made early in training when the network tends to fit clean labels before memorizing noise. This multi-label adaptation operates per label entry rather than per sample. The core assumption is that neural networks exhibit an "early learning" phase where they learn generalizable patterns before memorizing label noise, making early predictions more trustworthy than later ones for corrupted entries.

### Mechanism 3: Asymmetric Noise-Type Handling
NAR explicitly distinguishes between additive noise (false positives) and subtractive noise (false negatives) by using separate threshold pairs for each noise type. The oracle analysis shows subtractive noise causes stronger degradation than additive noise at equal rates, justifying more aggressive correction strategies for suspected false negatives. This asymmetric treatment addresses the limitation of previous work that commonly treats noisy annotations as supervised signals without mechanisms that explicitly adapt learning behavior to different noise types.

## Foundational Learning

- **Concept: Multi-label binary cross-entropy with per-label weighting**
  - Why needed here: NAR modifies BCE by applying per-entry weights (w_i,c) and corrected labels (ỹ_i,c); understanding base BCE is prerequisite to grasping the modification.
  - Quick check question: Given a 5-class multi-label problem where classes 1 and 3 are present, what is the BCE loss contribution from class 2 when the model predicts p_2 = 0.3?

- **Concept: Semi-supervised learning via unlabeled sample handling**
  - Why needed here: NAR treats moderate-confidence entries as unlabeled (zero weight), following SSL principles where uncertain supervision is excluded from labeled loss but may contribute through other terms.
  - Quick check question: In a semi-supervised framework, how does excluding a sample from the supervised loss differ from setting its target label to a specific value?

- **Concept: Confidence calibration and threshold selection**
  - Why needed here: The three-state mechanism depends on thresholds that must be tuned; poor calibration causes systematic errors in retain/deactivate/flip decisions.
  - Quick check question: If a model is overconfident (predictions near 0 or 1 when uncertainty should be higher), how would fixed thresholds affect the deactivation rate?

## Architecture Onboarding

- **Component map:** Input: Image x_i → ResNet-18 backbone → per-class probabilities p_i ∈ [0,1]^C → Label handler: Compare p_i,c with thresholds → generate corrected labels ỹ_i,c and weights w_i,c → Loss: L_NAR = L_BCE-CW(θ) + L_ELR-ML(θ)

- **Critical path:** 1. Forward pass through backbone 2. For each label entry, evaluate four thresholds to determine state (retain/deactivate/flip) 3. Compute confidence-weighted BCE using corrected labels 4. Add ELR regularization term 5. Backpropagate combined loss

- **Design tradeoffs:** ELR vs. no ELR: ELR stabilizes training but may slow adaptation to valid label patterns; paper shows ELR benefits most datasets but NAR without ELR occasionally better (DeepGlobe-ML, high noise). Aggressive flipping vs. conservative deactivation: Flipping provides higher potential gain but risks corrupting clean labels; deactivation is safer but leaves information unused. Threshold granularity: More thresholds allow finer control but increase hyperparameter sensitivity (see Figure 5).

- **Failure signatures:** Performance degrades below baseline: Likely threshold misconfiguration causing systematic incorrect flipping of clean labels. No improvement over BCE: Thresholds too conservative (all entries retained) or too aggressive (all deactivated/flipped). High variance across runs: ELR λ may be too low, or warm-up insufficient for stable early representations. Asymmetric performance (subtractive << additive): Increase t_w0_0 threshold to deactivate more suspected false negatives.

- **First 3 experiments:** 1. Baseline validation: Reproduce BCE and ELR baselines on UCMerced at 40% subtractive noise; verify mAP within ±1% of reported values before implementing NAR. 2. Oracle ablation: Implement oracle-based label handling (perfect noise identification) to establish upper bound on three-state mechanism; compare "ignore" vs. "flip" strategies on oracle-identified noisy entries. 3. Threshold sensitivity sweep: Fix all but t_w0_0, sweep from 0.3 to 0.7 at 40% subtractive noise; verify U-shaped performance curve and identify approximate optimal range before full hyperparameter search.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the integration of self-supervised learning (SSL) pre-training interact with the proposed noise-adaptive regularization mechanism to improve generalization?
- Basis in paper: The conclusion states: "As future work, we plan to investigate how the proposed semi-supervised, noise-adaptive mechanism can be combined with self-supervised learning to further improve robustness and generalization."
- Why unresolved: While SSL is known to mitigate warm-up memorization in single-label tasks, it is unclear if SSL representations align effectively with the three-state label handling (retain, deactivate, flip) specific to multi-label noise.
- What evidence would resolve it: Experimental results comparing standard supervised pre-training against SSL pre-training (e.g., contrastive learning) within the NAR framework on high-noise datasets.

### Open Question 2
- Question: Is NAR effective on datasets with inherent, uncontrolled real-world label noise, as opposed to the simulated noise injection used in the study?
- Basis in paper: The experimental setup relies entirely on a controlled noise simulation strategy that independently flips labels. The authors acknowledge that real-world noise from crowdsourcing may differ qualitatively from simulated noise.
- Why unresolved: The confidence thresholds are tuned based on validation sets that likely mirror the simulated noise distribution; performance may degrade if real-world noise follows a more structured or adversarial pattern.
- What evidence would resolve it: Evaluation of NAR on benchmark remote sensing or computer vision datasets containing naturally occurring, uncontrolled label errors without further hyperparameter tuning.

### Open Question 3
- Question: Can the confidence thresholds ($t_0^{w0}, t_1^{w0}$, etc.) be adapted dynamically during training rather than requiring fixed values?
- Basis in paper: Section V-C demonstrates that the optimal deactivation thresholds shift depending on the noise rate and type (e.g., optimal $t_0^{w0}$ decreases as noise increases).
- Why unresolved: In operational scenarios, the noise rate is unknown, making it difficult to select optimal fixed thresholds a priori. Static thresholds might be too aggressive or too lenient as the model's accuracy improves over epochs.
- What evidence would resolve it: A modified NAR implementation where thresholds are updated online based on training dynamics (e.g., moving average of prediction confidences) that achieves comparable or superior performance without manual tuning.

## Limitations
- The four threshold parameters are critical to performance but not reported in final form, requiring extensive hyperparameter search for reproduction
- All three datasets are remote sensing scenes, limiting generalization to domains with different label correlation structures or noise distributions
- The theoretical justification for ELR's effectiveness in multi-label settings relies on assumptions about early learning behavior validated in single-label contexts, with limited empirical validation specific to multi-label classification

## Confidence
- **High confidence:** The three-state confidence-based mechanism (retain/deactivate/flip) and its integration with BCE provides measurable performance gains, particularly under subtractive noise, supported by oracle experiments showing ~80% recovery of optimal performance through deactivation alone
- **Medium confidence:** The asymmetric noise-type handling (separate thresholds for additive vs. subtractive noise) provides consistent improvements across datasets, though threshold optimization may contribute to performance variation
- **Low confidence:** The theoretical justification for ELR's effectiveness in multi-label settings relies on assumptions about early learning behavior that were validated in single-label contexts, with limited empirical validation specific to multi-label classification

## Next Checks
1. Implement threshold sensitivity analysis across all three datasets with varying noise rates to establish optimal threshold ranges and verify the U-shaped performance curves shown in Figure 5 for different noise types
2. Measure the accuracy of NAR's implicit noise type classification (additive vs. subtractive) by comparing predicted flips against ground truth noisy labels in controlled experiments
3. Design experiments to measure prediction stability across training epochs for clean vs. noisy label entries, validating the assumption that early predictions are more reliable indicators of ground truth