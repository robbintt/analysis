---
ver: rpa2
title: 'HuAMR: A Hungarian AMR Parser and Dataset'
arxiv_id: '2502.20552'
source_url: https://arxiv.org/abs/2502.20552
tags:
- data
- language
- huamr
- hungarian
- silver
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents HuAMR, the first Abstract Meaning Representation
  (AMR) dataset for Hungarian. The authors translated the AMR 3.0 dataset into Hungarian
  and generated additional silver-standard AMR annotations using a Llama-3.1-70B model,
  creating HuAMR.
---

# HuAMR: A Hungarian AMR Parser and Dataset

## Quick Facts
- arXiv ID: 2502.20552
- Source URL: https://arxiv.org/abs/2502.20552
- Reference count: 7
- Primary result: First Hungarian AMR dataset with mT5 Large outperforming Llama-3.2-1B in parsing

## Executive Summary
This paper introduces HuAMR, the first Abstract Meaning Representation (AMR) dataset for Hungarian, created by translating the AMR 3.0 dataset and generating additional silver-standard annotations using a Llama-3.1-70B model. The authors developed AMR parsers using mT5 Large and Llama-3.2-1B models, evaluating their performance with Smatch scores. The mT5 Large model consistently outperformed Llama-3.2-1B across all configurations. While additional silver data did not consistently boost overall performance, it effectively improved parsing accuracy on Hungarian news data.

## Method Summary
The authors translated the English AMR 3.0 dataset into Hungarian to create the HuAMR dataset, then generated additional silver-standard AMR annotations using a Llama-3.1-70B model. They trained AMR parsers using mT5 Large and Llama-3.2-1B models on various training configurations. Performance was evaluated using Smatch scores, with comprehensive testing across different data splits and model architectures to assess the impact of silver data and model capacity on parsing quality.

## Key Results
- mT5 Large model consistently outperformed Llama-3.2-1B across all configurations
- Additional silver data did not consistently boost overall performance
- Silver data effectively improved parsing accuracy on Hungarian news data

## Why This Works (Mechanism)
The success of the mT5 Large model over Llama-3.2-1B demonstrates the importance of model capacity and pre-training for semantic parsing tasks. The mixed results with silver data suggest that while additional training examples can be beneficial, their quality and domain relevance are crucial factors. The improvement on Hungarian news data indicates that domain-specific silver annotations can enhance performance in targeted areas, even when general performance gains are not observed.

## Foundational Learning
- AMR (Abstract Meaning Representation): A semantic formalism representing sentence meaning as rooted, directed, acyclic graphs. Why needed: Provides the target representation format for semantic parsing. Quick check: Verify understanding of AMR node and edge conventions.
- Smatch score: Evaluation metric for AMR parsing measuring graph similarity. Why needed: Standard metric for comparing predicted and gold AMR graphs. Quick check: Understand the precision/recall calculation in Smatch.
- Silver-standard data: Automatically generated annotations used for training. Why needed: Expands training data beyond manually annotated gold standard. Quick check: Distinguish between gold and silver data quality characteristics.

## Architecture Onboarding
Component map: Input sentences -> AMR parser (mT5 Large/Llama-3.2-1B) -> Predicted AMR graphs -> Smatch evaluation
Critical path: Data preparation -> Model training -> Inference -> Evaluation
Design tradeoffs: Model capacity vs. computational efficiency, gold vs. silver data quality vs. quantity
Failure signatures: Low Smatch scores indicate parsing errors; domain-specific failures suggest need for targeted training data
First experiments:
1. Train mT5 Large on gold HuAMR data only
2. Train Llama-3.2-1B on mixed gold/silver data
3. Evaluate both models on Hungarian news domain data

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on automatic silver-standard data generation may introduce noise
- Translation process could cause semantic drift or cultural context loss
- Evaluation focuses primarily on Smatch scores, potentially overlooking other quality aspects

## Confidence
High: mT5 Large consistently outperformed Llama-3.2-1B based on direct empirical comparisons
Medium: Additional silver data did not consistently boost overall performance but improved Hungarian news parsing
Low: Broader implications for semantic parsing tasks due to single language focus

## Next Checks
1. Manual evaluation of a random sample of silver-standard HuAMR annotations to assess quality
2. Cross-lingual transfer experiments to test HuAMR's impact on related languages
3. Ablation studies varying gold vs. silver data proportions to find optimal training composition