---
ver: rpa2
title: Performance-driven Constrained Optimal Auto-Tuner for MPC
arxiv_id: '2503.07127'
source_url: https://arxiv.org/abs/2503.07127
tags:
- coat-mpc
- parameters
- performance
- function
- tuning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of tuning Model Predictive Control
  (MPC) cost function parameters while ensuring system performance stays above a certain
  threshold. The authors propose COAT-MPC, a constrained optimal auto-tuner that uses
  Gaussian processes to model the unknown performance function and explores the parameter
  space while satisfying performance constraints.
---

# Performance-driven Constrained Optimal Auto-Tuner for MPC

## Quick Facts
- arXiv ID: 2503.07127
- Source URL: https://arxiv.org/abs/2503.07127
- Authors: Albert Gassol Puigjaner; Manish Prajapat; Andrea Carron; Andreas Krause; Melanie N. Zeilinger
- Reference count: 30
- Primary result: Proposes COAT-MPC algorithm that tunes MPC parameters while guaranteeing performance constraints, achieving 0 violations vs. 1.8-16.4 for baselines in autonomous racing

## Executive Summary
This paper addresses the challenge of tuning Model Predictive Control (MPC) cost function parameters while ensuring system performance stays above a certain threshold. The authors propose COAT-MPC, a constrained optimal auto-tuner that uses Gaussian processes to model the unknown performance function and explores the parameter space while satisfying performance constraints. The method is theoretically analyzed, showing it satisfies performance constraints with arbitrarily high probability and converges to optimal parameters in finite time, with experimental results demonstrating superior performance compared to baselines in autonomous racing applications.

## Method Summary
COAT-MPC uses Gaussian Process regression to model an unknown performance function q(θ) where θ represents MPC cost function parameters. The algorithm maintains pessimistic (guaranteed-safe) and optimistic (potentially-safe) estimates of the safe parameter set using confidence bounds. It explores toward optimistic goals while sampling only from the pessimistic set, ensuring performance constraints are satisfied with high probability. The method converges to optimal parameters in finite time with sample complexity independent of discretization granularity, demonstrated through autonomous racing experiments where it achieved 0 constraint violations versus 1.8-16.4 for baselines.

## Key Results
- Achieved 0 constraint violations in hardware experiments vs. 1.8-16.4 violations for baseline methods
- Converged in 20-30 iterations vs. 70 iterations for baselines
- Outperformed baselines in autonomous racing simulation and 1:28 scale RC platform experiments
- Sample complexity bound removes explicit dependence on discretization step size, improving upon previous work

## Why This Works (Mechanism)

### Mechanism 1: Confidence-Bounded Safe Set Construction
Gaussian Process confidence intervals enable safe parameter exploration by constructing pessimistic (guaranteed-safe) and optimistic (potentially-safe) parameter sets. The algorithm builds intersecting lower and upper confidence bounds on the performance function using GP posteriors, with lower bounds non-decreasing and upper bounds non-increasing per iteration, progressively tightening the uncertainty envelope. Parameters in the pessimistic set satisfy performance constraints with probability ≥ 1-δ.

### Mechanism 2: Goal-Oriented Constrained Expansion
Directing exploration toward optimistic goals while sampling from pessimistic sets yields sample-efficient convergence without constraint violations. The algorithm selects a goal within the optimistic set using UCB criterion, then uses the Constrained Expansion subroutine to sample the closest point to the goal within the pessimistic set that has sufficient uncertainty. This ensures progress toward optimal regions while guaranteeing safety and maintaining exploration.

### Mechanism 3: Discretization-Independent Finite-Time Convergence
The algorithm converges within O(γn*/ϵ²) samples regardless of domain discretization granularity. The proof leverages that discrete pessimistic sets are subsets of continuous-domain versions, enabling tighter bounds without explicit dependence on discretization step size. Termination occurs when goal uncertainty drops below ϵ, at which point optimality within ϵ-tolerance is guaranteed.

## Foundational Learning

- **Gaussian Process Regression and Confidence Bounds**: Core to modeling unknown performance function with calibrated uncertainty. Quick check: Given observations {θi, yi}, can you compute the GP posterior mean and variance, and explain why βn scaling is needed for valid confidence intervals?

- **Safe Exploration via Reachability Operators**: Understanding how pessimistic/optimistic sets expand through Lipschitz propagation. Quick check: Explain how the one-step reachability operator uses Lipschitz continuity to identify safe neighbors, and why the pessimistic operator provides high-probability safety guarantees.

- **Bayesian Optimization Acquisition Functions**: Understanding UCB-based goal selection and exploration-exploitation tradeoffs. Quick check: Why does selecting θg = argmax un-1(θ) over the optimistic set encourage convergence to the global optimum?

## Architecture Onboarding

- **Component map**: GP Surrogate -> Confidence Tracker -> Set Expansion Engine -> Goal Selector -> Constrained Expansion Sampler -> Termination Monitor

- **Critical path**: 1) Initialize with S₀ containing known-safe parameters, 2) Loop: Select goal → Determine if goal reachable → Sample via constrained expansion or directly → Update GP → Expand sets, 3) Exit when goal in pessimistic set with wn(θg) < ϵ; return θg

- **Design tradeoffs**: ϵ controls accuracy vs. convergence speed (paper uses implicit via β=5.0); β controls conservatism vs. expansion rate; discretization affects memory (10,000 points used); initial seed quality affects convergence speed

- **Failure signatures**: Non-termination (ϵ too small relative to noise); constraint violations (β insufficient for noise level); slow convergence (L overestimated causing conservative expansion); numerical issues (GP covariance matrix conditioning)

- **First 3 experiments**: 1) Create test function with known constraint boundary to verify pessimistic set expansion matches theoretical predictions, 2) Run identical tuning task with varying domain granularities to confirm convergence iterations independent of discretization, 3) Systematically vary noise levels and β to empirically validate constraint satisfaction rate approaches 1-δ

## Open Questions the Paper Calls Out

1. **High-dimensional extension**: How can the method be extended to handle high-dimensional parameter spaces without incurring the exponential space complexity associated with the current discretization approach? The current implementation relies on a finite domain with 10,000 combinations, becoming computationally intractable as the number of tuning parameters increases.

2. **Heteroscedastic noise handling**: Can the safety guarantees be maintained under heteroscedastic or non-stationary noise conditions, such as the external odometry errors observed in the RC platform experiments? The theoretical analysis relies on sub-Gaussian noise assumptions that may not capture time-varying or state-dependent noise in physical systems.

3. **Contextual information integration**: How can contextual information be integrated into the COAT-MPC framework to allow parameter tuning to generalize across different environments or varying system dynamics? The current formulation learns a posterior over q(θ) for a specific task, but if the environment changes, the learned performance function and safe sets may no longer be valid.

## Limitations

- Unknown key parameters (Lipschitz constant L, termination threshold ε, GP noise variance ση) significantly impact algorithm behavior and constraint satisfaction rates
- Computational scalability bottleneck from 10,000 discretized parameter combinations creates memory and computational issues for higher-dimensional tuning problems
- Noise sensitivity evidenced by 0.33 constraint violations in hardware experiments attributed to odometry noise, potentially violating theoretical sub-Gaussian noise assumptions

## Confidence

**High Confidence**: Theoretical sample complexity bound removing discretization dependence is mathematically sound; experimental results showing 0 violations vs. 1.8-16.4 for baselines are well-supported; convergence in 20-30 iterations vs. 70 for baselines is clearly demonstrated.

**Medium Confidence**: Claim that method "outperforms baselines in terms of constraint violations" - while data supports this, baseline implementations may differ from original publications; claim that "safe exploration through confidence bounds" ensures constraint satisfaction - theoretically sound but practical implementation depends on unknown L parameter.

**Low Confidence**: Extrapolation to other MPC tuning scenarios beyond autonomous racing; performance in high-dimensional parameter spaces (>2 parameters).

## Next Checks

1. **Lipschitz Sensitivity Analysis**: Systematically vary the Lipschitz constant L parameter and measure its impact on pessimistic set expansion rate and constraint violation frequency to quantify sensitivity to this critical but unspecified parameter.

2. **Discretization Robustness Test**: Run the autonomous racing experiment with 1,000 vs. 50,000 discretized parameter points to measure convergence iterations and constraint violations, empirically validating the discretization-independent theoretical bound.

3. **Noise Distribution Validation**: Generate synthetic performance functions with non-sub-Gaussian noise distributions (e.g., heavy-tailed, multimodal) and measure constraint violation rates to test the robustness of the ση-sub-Gaussian assumption in practice.