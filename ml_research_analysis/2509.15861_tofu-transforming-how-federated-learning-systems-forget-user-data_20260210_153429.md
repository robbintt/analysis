---
ver: rpa2
title: 'ToFU: Transforming How Federated Learning Systems Forget User Data'
arxiv_id: '2509.15861'
source_url: https://arxiv.org/abs/2509.15861
tags:
- unlearning
- tofu
- learning
- performance
- transformation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a transformation-guided approach to federated
  unlearning (ToFU) that addresses the challenge of removing sensitive data from federated
  learning models. The key insight is that incorporating transformations during training
  reduces neural networks' tendency to memorize specific training instances, making
  subsequent unlearning more effective.
---

# ToFU: Transforming How Federated Learning Systems Forget User Data

## Quick Facts
- arXiv ID: 2509.15861
- Source URL: https://arxiv.org/abs/2509.15861
- Authors: Van-Tuan Tran; Hong-Hanh Nguyen-Le; Quoc-Viet Pham
- Reference count: 40
- Key outcome: ToFU achieves state-of-the-art unlearning performance across CIFAR-10 (0.6712 overall), CIFAR-100 (0.5798 overall), and MUFAC benchmarks, while improving existing FU methods by 4-11% when integrated as a plug-and-play framework and reducing unlearning time by 24-28%.

## Executive Summary
This paper introduces ToFU (Transformation-guided approach to Federated Unlearning), a novel method that addresses the challenge of removing sensitive data from federated learning models. The key insight is that incorporating transformations during training reduces neural networks' tendency to memorize specific training instances, making subsequent unlearning more effective. ToFU dynamically applies multiple transformations to training samples, forcing models to learn transformation-invariant features rather than instance-specific details.

The method achieves state-of-the-art unlearning performance across multiple benchmarks while also improving existing federated unlearning methods when used as a plug-in framework. ToFU demonstrates that by carefully orchestrating data transformations during the learning phase, the subsequent unlearning process becomes significantly more efficient and effective, reducing both the computational cost and the information retained about the forgotten data.

## Method Summary
ToFU operates by transforming training data during federated learning to reduce instance-specific memorization. During client-side training, ToFU applies multiple transformations to each sample based on its loss value - samples with lower loss receive more transformations. A transformation-invariant regularization term encourages consistent representations across transformations. During unlearning, the model is fine-tuned only on the retain set, achieving better performance than baselines due to the transformation-guided training phase. The method integrates seamlessly with existing federated learning frameworks while requiring minimal changes to the training procedure.

## Key Results
- Achieves state-of-the-art overall unlearning performance: 0.6712 (CIFAR-10), 0.5798 (CIFAR-100), and competitive results on MUFAC
- Reduces unlearning time by 24-28% compared to baseline methods
- Improves existing federated unlearning methods (FedEraser, FedPGD, FedAda) by 4-11% when used as a plug-in framework
- Maintains or improves model utility on test and retain sets while enhancing privacy protection

## Why This Works (Mechanism)

### Mechanism 1: Transformation-based memorization reduction
Increasing transformation intensity reduces instance-specific memorization, simplifying unlearning. Theoretical analysis shows composed transformations monotonically decrease mutual information with the forget set. Empirical results on CIFAR-100 demonstrate strong positive correlation (ρ: 1.0000, p-value: 0.000000) between transformation intensity and unlearning performance. Break condition: excessive transformations destroy task-relevant information, degrading model utility.

### Mechanism 2: Sample-dependent transformation strategy
Dynamically determining transformation counts per sample based on loss values optimizes the trade-off between reducing memorization and preserving task-relevant information. Samples with lower loss receive more transformations. ToFU improves existing FU methods by 4-11% when integrated as a plug-and-play framework. Break condition: if loss landscape is noisy or uncorrelated with memorization, the mapping from loss to transformation intensity may misallocate transformations.

### Mechanism 3: Transformation-invariant regularization
Enforcing consistency between representations of transformed and original samples encourages learning transformation-invariant features, further reducing memorization and improving unlearning robustness. A KL-divergence term between latent representations is added to the loss. Ablation study shows combining this with sample-dependent transformation and progressive training achieves the best overall performance (0.5798 on CIFAR-100). Break condition: if regularization weight is too high, it may overly constrain the model; if too low, representations may diverge.

## Foundational Learning

- **Mutual Information and KL Divergence:**
  - Why needed here: The theoretical foundation relies on bounding mutual information between model parameters and the forget set. Understanding how KL divergence measures distributional difference is essential to grasp the unlearning optimization objective.
  - Quick check question: Given two probability distributions P and Q, what does D_KL(P ∥ Q) measure, and what is its value when P = Q?

- **Data Processing Inequality (Markov Chains):**
  - Why needed here: The proof of Theorem 1 uses the data processing inequality for mutual information in Markov chains (θ → T_1(θ) → T_2(T_1(θ))). This establishes that composed transformations cannot increase mutual information with the forget set.
  - Quick check question: For a Markov chain X → Y → Z, what does the data processing inequality state about I(X; Z) compared to I(X; Y)?

- **Federated Learning Basics (FedAvg, Client-Server Protocol):**
  - Why needed here: ToFU operates within the FL paradigm, modifying the client-side training loop while preserving the server-side aggregation. Understanding federated averaging and the constraints of distributed data is necessary to interpret the system architecture and experimental setup.
  - Quick check question: In FedAvg, how does the server aggregate client models after each round, and what information does the server have access to (and not have access to)?

## Architecture Onboarding

- **Component map:**
  Server -> Client-side Training -> Sample-dependent Transformation Module -> Transformation Engine -> Regularization Module -> Unlearning Procedure -> Server aggregation

- **Critical path:**
  1. Server initializes global model
  2. Server broadcasts model to selected clients
  3. Each client computes batch losses on original data
  4. Client applies sample-dependent transformations based on inverse quantile of losses
  5. Client computes combined loss (task loss + regularization) on transformed data
  6. Client returns updated model to server
  7. Server aggregates to produce new global model
  8. Upon unlearning request, client fine-tunes on retain set only

- **Design tradeoffs:**
  - Transformation intensity vs. utility: Higher intensity reduces memorization but risks distorting task-relevant features
  - Training overhead vs. unlearning speed: ToFU increases training time but reduces unlearning time and improves performance
  - Regularization strength (γ): Too low may not enforce invariance; too high may over-constrain

- **Failure signatures:**
  - Excessive performance degradation on retain/test sets: May indicate overly aggressive transformations
  - Poor MIA efficacy (low values): May suggest insufficient memorization reduction
  - Unlearning time not reduced: Check if fine-tuning is correctly implemented on retain set only

- **First 3 experiments:**
  1. Baseline ToFU vs. FedAvg on CIFAR-10/100, comparing test accuracy, retain accuracy, and training time
  2. Ablation of ToFU components (sample-dependent transformation, regularization, progressive training) on CIFAR-100
  3. Integration with existing FU methods (FedEraser, FedPGD, FedAda) to measure improvement in overall FU performance

## Open Questions the Paper Calls Out

- How can transformation strategies be tailored to prevent utility degradation in specialized tasks like facial recognition on MUFAC, where standard transformations harm model performance?
- Can automatic augmentation policies (e.g., RandAugment) replace the fixed transformation set to enhance ToFU's generalizability across diverse architectures without manual hyperparameter tuning?
- Can the computational overhead during the training phase (up to 58.7% increase in wall-clock time) be reduced to make ToFU feasible for resource-constrained edge devices?

## Limitations
- Transformation-invariant regularization mechanism lacks formal theoretical grounding and serves as an empirical heuristic
- Sample-dependent transformation strategy assumes reliable correlation between loss values and memorization levels that may not hold across all datasets
- Paper does not address computational overhead of transformation application during training, which could be significant for large models

## Confidence
- **High confidence**: Transformation-based memorization reduction mechanism and its theoretical analysis (Theorem 1, Corollary 1) showing monotonic decrease in mutual information with forget set
- **Medium confidence**: Sample-dependent transformation strategy effectiveness - ablation shows strong performance but assumption needs broader validation
- **Medium confidence**: Overall unlearning performance improvements - results are compelling but evaluation focuses on specific metrics

## Next Checks
1. Conduct experiments to explicitly measure correlation between sample loss values and subsequent unlearning effectiveness across multiple training stages and datasets
2. Profile computational cost of ToFU's transformation application during training across different model sizes and transformation complexity levels
3. Test ToFU on text, tabular, or graph data to evaluate generalization beyond natural images and identify effective transformation types for different data modalities