---
ver: rpa2
title: Unifying Search and Recommendation in LLMs via Gradient Multi-Subspace Tuning
arxiv_id: '2601.09496'
source_url: https://arxiv.org/abs/2601.09496
tags:
- search
- gradient
- gems
- recommendation
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of unifying search and recommendation
  tasks in large language models (LLMs) by proposing a novel parameter-efficient framework
  called GEMS. The method introduces multi-subspace decomposition to disentangle shared
  and task-specific optimization signals into complementary low-rank subspaces, mitigating
  gradient conflicts.
---

# Unifying Search and Recommendation in LLMs via Gradient Multi-Subspace Tuning

## Quick Facts
- **arXiv ID:** 2601.09496
- **Source URL:** https://arxiv.org/abs/2601.09496
- **Reference count:** 40
- **One-line primary result:** GEMS framework unifies search and recommendation in LLMs, achieving Hit@5 of 0.3499 (rec) and 0.0552 (search) on Qilin dataset with Qwen-3B.

## Executive Summary
This paper addresses the fundamental challenge of unifying search and recommendation tasks in large language models by proposing the Gradient Multi-Subspace (GEMS) framework. The core insight is that traditional parameter-efficient fine-tuning methods fail to handle the gradient conflicts that arise when optimizing for both tasks simultaneously. GEMS introduces a novel approach that decomposes gradients into shared and task-specific subspaces while using null-space projection to preserve general-domain knowledge. The method achieves state-of-the-art performance across both tasks without introducing additional trainable parameters.

## Method Summary
GEMS is a parameter-efficient framework that unifies search and recommendation in LLMs through three key mechanisms: (1) multi-subspace decomposition that disentangles shared and task-specific optimization signals into complementary low-rank subspaces, (2) null-space projection that constrains updates orthogonal to the general-domain knowledge space to preserve language understanding, and (3) an adaptive gating network that dynamically balances the contributions from each subspace based on task statistics. The method processes raw gradients through separate subspace projectors for shared, search-specific, and recommendation-specific components, fuses them adaptively, and applies null-space projection before updating parameters.

## Key Results
- GEMS achieves Hit@5 scores of 0.3499 for recommendation and 0.0552 for search on Qilin dataset with Qwen-3B
- Outperforms LoRA and full fine-tuning baselines across both search and recommendation tasks
- Maintains performance gains on LLMs with billions of parameters without introducing additional trainable weights
- Effectively mitigates gradient conflicts between search and recommendation tasks

## Why This Works (Mechanism)
The framework works by addressing the fundamental gradient conflict problem in multi-task learning. When training for both search and recommendation, gradients often point in opposing directions, making it impossible to optimize both tasks simultaneously with standard methods. GEMS resolves this by decomposing the optimization space into complementary subspaces: a shared subspace for common patterns, and separate subspaces for task-specific features. The null-space projection ensures that updates remain orthogonal to the principal directions of pre-trained knowledge, preserving the model's general reasoning capabilities while adapting to task-specific requirements.

## Foundational Learning

- **Concept:** **Gradient Conflict in Multi-Task Learning**
  - **Why needed here:** This is the core problem GEMS addresses. You must understand that updating a single model for two tasks (search & recommendation) can lead to opposing gradient directions, where an update that improves one task degrades the other.
  - **Quick check question:** Can you explain why a gradient direction that minimizes search loss might increase recommendation loss in a unified model?

- **Concept:** **Low-Rank Subspaces and SVD**
  - **Why needed here:** The paper's core method relies on projecting gradients into low-rank subspaces. You need to understand how Singular Value Decomposition (SVD) identifies principal directions (singular vectors) to create a lower-dimensional basis for optimization.
  - **Quick check question:** If a gradient matrix G has SVD decomposition UΣVᵀ, what do the first r columns of U represent?

- **Concept:** **Parameter-Efficient Fine-Tuning (PEFT)**
  - **Why needed here:** The paper positions itself as an alternative or advancement to methods like LoRA. Understanding PEFT's goal of reducing trainable parameters is crucial for appreciating GEMS's "no additional trainable weights" claim and memory efficiency focus.
  - **Quick check question:** In LoRA, what matrices A and B are introduced, and how do they relate to the original weight matrix W?

## Architecture Onboarding

- **Component map:** Compute Raw Gradients (S, R, Shared) -> Subspace Projection & Update Computation -> Adaptive Fusion -> Null-Space Projection -> Apply Final Parameter Update

- **Critical path:** The critical data path for each training step is: Compute Raw Gradients (S, R, Shared) -> Subspace Projection & Update Computation -> Adaptive Fusion -> Null-Space Projection -> Apply Final Parameter Update. The SVD calculation for subspaces is on the critical path but is only executed every `T_svd` steps.

- **Design tradeoffs:**
  - **SVD Refresh Rate (`T_svd`):** A lower value updates subspaces more often, potentially better capturing gradient changes, but increases computation. The tradeoff is between adaptive accuracy and speed.
  - **Subspace Rank (`r`):** A higher rank captures more gradient information but increases memory for optimizer states. The paper suggests task-specific ranks should be smaller than shared ranks.
  - **Pre-trained Knowledge Basis (`k` singular vectors):** Choosing `k` for the null-space projection trades off how much of the pre-trained space is protected. A larger `k` protects more knowledge but may overly constrain the model's ability to adapt.

- **Failure signatures:**
  - **Training Instability:** If the adaptive gating weights collapse (e.g., `alpha_src` goes to 0), one task is being ignored.
  - **Catastrophic Forgetting:** If the null-space projection is ineffective or misconfigured, the model may lose general reasoning ability, evidenced by poor performance on general NLP tasks or "correct-before, incorrect-after" cases.
  - **Stagnant Loss:** If gradient conflicts are not resolved, the model may fail to converge for both tasks, oscillating or plateauing at a suboptimal point.
  - **Memory OOM:** Although GEMS is efficient, maintaining states for three subspaces can still cause Out-of-Memory errors if the rank `r` is set too high relative to available GPU memory.

- **First 3 experiments:**
  1. **Baseline Comparison (Ablation):** Run the full GEMS model on the Qilin dataset and compare it against versions with individual components disabled (w/o Multi-Subspace, w/o Null-Space) to validate the contribution of each part. This directly answers RQ2 from the paper.
  2. **Gradient Conflict Analysis:** Implement the Gradient Conflict Coefficient (ρ) metric. Train both a standard PEFT baseline and GEMS, and plot the average conflict coefficient over training steps/layers to quantitatively prove that GEMS reduces gradient conflict, as shown in Figure 4.
  3. **Hyperparameter Sensitivity:** Perform a grid search on the key hyperparameters (Scale Factor `α`, Gate Temperature `τ`) on a validation set. This verifies the robustness of the method and identifies stable operating ranges, as explored in the paper's Appendix A.4.

## Open Questions the Paper Calls Out
None

## Limitations
- Critical hyperparameters (SVD refresh interval T_svd, null-space rank k, learning rate, batch size) are not specified in the main text
- Experimental results primarily reported on Qilin dataset with limited cross-dataset validation
- "No additional trainable weights" claim requires understanding that optimizer states for subspaces still consume memory

## Confidence

- **High Confidence:** The core methodology (multi-subspace decomposition, null-space projection, adaptive gating) is clearly described and mathematically sound. The experimental design for comparing against LoRA and full fine-tuning is rigorous.
- **Medium Confidence:** The reported performance improvements (Hit@5 of 0.3499 for recommendation and 0.0552 for search on Qilin/Qwen-3B) are specific and verifiable, but the comparison against a potentially stronger baseline (adapter-based methods beyond LoRA) is limited.
- **Low Confidence:** The generalizability of the method across different domains and model sizes is asserted but not thoroughly demonstrated beyond the specific experiments shown.

## Next Checks

1. **Gradient Conflict Analysis:** Implement the Gradient Conflict Coefficient (ρ) metric and empirically verify that GEMS reduces gradient conflicts compared to standard PEFT baselines during training on both Qilin and Amazon datasets.

2. **Generalization Test:** Evaluate GEMS-trained models on out-of-domain search/recommendation tasks (e.g., movie or hotel recommendations) to assess whether the null-space projection effectively preserves general reasoning while maintaining task performance.

3. **Memory Efficiency Measurement:** Profile GPU memory usage during training to quantify the actual memory overhead of maintaining three subspace optimizer states versus the claimed efficiency gains, particularly for different rank configurations.