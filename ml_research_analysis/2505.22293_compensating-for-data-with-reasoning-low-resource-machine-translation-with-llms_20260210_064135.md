---
ver: rpa2
title: 'Compensating for Data with Reasoning: Low-Resource Machine Translation with
  LLMs'
arxiv_id: '2505.22293'
source_url: https://arxiv.org/abs/2505.22293
tags:
- translation
- language
- ladin
- low-resource
- languages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Fragment-Shot Prompting, a novel in-context
  learning method for low-resource machine translation that segments input sentences
  and retrieves translation examples based on syntactic coverage. An extension called
  Pivoted Fragment-Shot enables translation between languages without direct parallel
  data by using a pivot language.
---

# Compensating for Data with Reasoning: Low-Resource Machine Translation with LLMs

## Quick Facts
- arXiv ID: 2505.22293
- Source URL: https://arxiv.org/abs/2505.22293
- Reference count: 28
- Key outcome: Fragment-Shot Prompting improves low-resource machine translation by retrieving syntactic fragments, with reasoning-capable LLMs showing stronger performance gains

## Executive Summary
This paper addresses low-resource machine translation by introducing Fragment-Shot Prompting, which segments input sentences and retrieves translation examples based on syntactic coverage. The method shows particular effectiveness when translating into low-resource languages, where syntactic coverage correlates positively with translation quality. An extension called Pivoted Fragment-Shot enables translation between languages without direct parallel data by using a pivot language. The approach was evaluated across five LLMs (GPT-3.5, GPT-4o, o1-mini, Llama-3.3, and DeepSeek-R1) on Italian-Ladin translation tasks, demonstrating that models with stronger reasoning abilities make more effective use of retrieved knowledge.

## Method Summary
The core methodology involves Fragment-Shot Prompting, which breaks down input sentences into syntactic fragments and retrieves relevant translation examples based on coverage. For languages without direct parallel data, Pivoted Fragment-Shot uses an intermediate pivot language to enable translation. The approach leverages in-context learning by presenting retrieved examples alongside the translation task. Evaluation was conducted on translating between Italian and two Ladin variants, using both automatic metrics and manual syntactic coverage analysis. The method aims to compensate for limited parallel data by retrieving and utilizing existing translation knowledge effectively.

## Key Results
- Fragment-Shot Prompting effectively improves translation quality for low-resource languages, with syntactic coverage showing positive correlation with BLEU scores
- Models with stronger reasoning capabilities (GPT-4o, o1-mini, DeepSeek-R1) make more effective use of retrieved knowledge and produce better translations
- Pivoted Fragment-Shot significantly improves translation quality between Ladin variants when direct parallel data is unavailable
- Prompt engineering offers limited improvements when translating from low-resource to high-resource languages, where zero-shot prompting already yields satisfactory results

## Why This Works (Mechanism)
The approach works by compensating for limited parallel data through strategic retrieval of syntactically relevant translation examples. By breaking sentences into fragments and matching them against a retrieval corpus, the method provides LLMs with targeted in-context examples that directly address the syntactic structures present in the input. This targeted retrieval is particularly effective for low-resource languages where traditional parallel data is scarce. The positive correlation between syntactic coverage and translation quality suggests that the method effectively guides the model toward appropriate translation patterns for each syntactic structure.

## Foundational Learning

**In-context learning**: Why needed - Enables models to leverage retrieved examples without fine-tuning; Quick check - Verify that retrieved examples are properly formatted and presented in prompt

**Syntactic fragmentation**: Why needed - Allows targeted retrieval of translation examples for specific grammatical structures; Quick check - Ensure fragment segmentation preserves syntactic integrity and meaning

**Retrieval-based translation**: Why needed - Compensates for lack of parallel data by finding relevant translation examples; Quick check - Validate retrieval corpus quality and relevance to target language pair

**Pivot translation**: Why needed - Enables translation between languages without direct parallel data; Quick check - Verify pivot language choice preserves semantic relationships between source and target

## Architecture Onboarding

**Component map**: Sentence segmentation -> Syntactic fragment matching -> Example retrieval -> Prompt construction -> LLM translation

**Critical path**: The retrieval and matching process is critical, as it determines which examples the model will see during inference. Poor retrieval directly impacts translation quality.

**Design tradeoffs**: Fragment size vs. retrieval accuracy (smaller fragments may match better but lose context), retrieval corpus size vs. retrieval speed, and the choice between direct vs. pivoted translation approaches.

**Failure signatures**: Low syntactic coverage indicates poor retrieval matching; degraded translation quality when using simpler models suggests insufficient reasoning capability; poor performance on low-resource to high-resource translation indicates limitations of the approach.

**First experiments**: 1) Measure syntactic coverage correlation with BLEU scores across different fragment sizes; 2) Compare translation quality between direct and pivoted approaches; 3) Test model sensitivity to varying numbers of retrieved examples in prompts.

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focused on a specific language pair (Italian and Ladin variants) with limited dataset sizes, constraining generalizability
- Syntactic coverage metric relies on manual fragment alignment that may introduce subjectivity
- The study does not investigate optimal fragment size or retrieval corpus composition
- Assumes model capabilities are stable, though LLMs can exhibit variability across runs

## Confidence
- Syntactic coverage positively correlates with translation quality: High confidence
- Reasoning-capable models make more effective use of retrieved knowledge: High confidence
- Prompt engineering offers limited improvements for low-resource to high-resource translation: Medium confidence

## Next Checks
1. Replicate the correlation between syntactic coverage and translation quality across additional low-resource language pairs and larger datasets
2. Conduct ablation studies varying fragment sizes and retrieval corpus composition to optimize the Fragment-Shot approach
3. Test the method's robustness by measuring translation quality variance across multiple inference runs with the same model and prompt configuration