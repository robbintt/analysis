---
ver: rpa2
title: 'PSAT: Pediatric Segmentation Approaches via Adult Augmentations and Transfer
  Learning'
arxiv_id: '2507.05764'
source_url: https://arxiv.org/abs/2507.05764
tags:
- pediatric
- learning
- adult
- segmentation
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The study introduces PSAT (Pediatric Segmentation Approaches via
  Adult Augmentations and Transfer learning), a systematic framework that decomposes
  pediatric segmentation into four key components: training plan derivation, learning
  set composition, data augmentation, and transfer learning strategy. The framework
  addresses the challenge of domain shift between adult and pediatric medical imaging,
  where anatomical differences and developmental changes lead to suboptimal segmentation
  performance when applying adult-trained models directly.'
---

# PSAT: Pediatric Segmentation Approaches via Adult Augmentations and Transfer Learning

## Quick Facts
- arXiv ID: 2507.05764
- Source URL: https://arxiv.org/abs/2507.05764
- Authors: Tristan Kirscher; Sylvain Faisan; Xavier Coubez; Loris Barrier; Philippe Meyer
- Reference count: 15
- Primary result: Adult-derived training plans cause significant performance degradation on pediatric segmentation, especially for small structures; contraction-based augmentations and continual learning strategies mitigate these issues

## Executive Summary
This study addresses the challenge of domain shift between adult and pediatric medical imaging for organ segmentation. The authors introduce PSAT, a systematic framework that decomposes pediatric segmentation into four components: training plan derivation, learning set composition, data augmentation, and transfer learning strategy. Through comprehensive benchmarking on two pediatric CT datasets, the research demonstrates that using adult training plans on pediatric data causes significant performance degradation, particularly for small structures. The optimal approach combines mixed training plans with continual learning (PmSaAdTm), achieving performance close to direct learning while being more computationally efficient.

## Method Summary
The PSAT framework manipulates four orthogonal components of nnU-Net training: (1) Training Plan (P) - fingerprint-based configuration derived from adult (Pa), pediatric (Pp), or mixed (Pm) datasets; (2) Learning Set (S) - adult (Sa), pediatric (Sp), or mixed (Sm) training data; (3) Augmentation (A) - standard nnU-Net augmentations (Ad) or contraction-based augmentations allowing up to 50% volume reduction (Ac); and (4) Transfer (T) - direct inference (To), fine-tuning (Tp), or continual learning with adult replay (Tm). The method systematically evaluates 18 configurations across two pediatric datasets, comparing performance metrics and computational efficiency.

## Key Results
- Using adult training plans on pediatric data causes significant performance degradation, especially for small structures (e.g., adrenal gland DSC drops from 77% to 49%)
- Contraction-based augmentations (Ac) improve zero-shot generalization to pediatric anatomy, increasing bladder DSC from 66% to 84% on internal pediatric data
- Fine-tuning models on pediatric data exhibits catastrophic forgetting, with complete loss of prostate segmentation (DSC = 0%), while continual learning maintains comparable performance to direct learning
- The optimal PmSaAdTm configuration achieves performance close to direct learning while reducing training time by 60% (10 hours vs 25 hours)

## Why This Works (Mechanism)

### Mechanism 1
Adult-derived training plans misalign network architecture with pediatric anatomy, causing disproportionate degradation for small structures. nnU-Net derives preprocessing parameters from dataset fingerprints including median image shape and spacing distribution. When adult fingerprints configure the pipeline for pediatric data, the resulting patch sizes and resampling resolutions are optimized for larger organs, undersampling or misrepresenting fine pediatric structures.

### Mechanism 2
Contraction-based augmentations on adult data improve zero-shot generalization to pediatric anatomy by simulating smaller organ volumes. Standard nnU-Net augmentation limits isotropic scaling to ~29% volume reduction. The contraction strategy extends this to 50%, exposing the model to size distributions closer to pediatric organ scales during training, reducing the domain shift at inference without requiring pediatric labels.

### Mechanism 3
Continual learning with rehearsal preserves adult-derived representations during pediatric adaptation, mitigating catastrophic forgetting and improving inter-institutional generalization. Fine-tuning optimizes solely on pediatric data, overwriting weights critical for adult structures. CL mixes adult replay with pediatric data during adaptation, maintaining a gradient signal from both domains and stabilizing the optimization landscape.

## Foundational Learning

- **nnU-Net self-configuring pipeline**: Why needed here - PSAT manipulates nnU-Net's fingerprint-based training plans as a core variable; understanding how preprocessing and architecture are auto-derived is prerequisite to interpreting misalignment effects. Quick check: Given a dataset with median spacing 1.0mm and median shape 256×256×64, what resampling target and patch size would nnU-Net likely select for a 3D U-Net?

- **Transfer learning paradigms (fine-tuning vs. continual learning)**: Why needed here - The paper directly compares FT and CL for pediatric adaptation; catastrophic forgetting and replay-based mitigation are central to the optimal strategy selection. Quick check: In a rehearsal-based CL setup with 100 pediatric samples and an adult replay ratio of 0.5, how many adult samples are included per epoch?

- **Domain shift in medical imaging**: Why needed here - Pediatric-adult and inter-institutional shifts are the motivating problems; recognizing how anatomical, acquisition, and protocol differences manifest is essential for evaluating augmentation and transfer strategies. Quick check: List three specific factors that could cause domain shift between adult CT scans from Hospital A and pediatric CT scans from Hospital B.

## Architecture Onboarding

- **Component map**:
```
PSAT Framework
├── Training Plan (P)
│   ├── Pa: Adult fingerprint → nnU-Net config
│   ├── Pp: Pediatric fingerprint → nnU-Net config
│   └── Pm: Mixed fingerprint → nnU-Net config
├── Learning Set (S)
│   ├── Sa: Adult CTs only
│   ├── Sp: Pediatric CTs only
│   └── Sm: Mixed adult + pediatric
├── Augmentation (A)
│   ├── Ad: Default nnU-Net (29% max contraction)
│   └── Ac: Contraction-extended (50% max contraction)
└── Transfer (T)
    ├── To: Direct inference (no adaptation)
    ├── Tp: Fine-tuning on pediatric only
    └── Tm: Continual learning with adult replay
```

- **Critical path**: For inter-institutional pediatric deployment: (1) Start with mixed training plan (Pm) derived from combined fingerprint; (2) Pre-train on adult data (Sa) with contraction augmentations (Ac); (3) Apply continual learning (Tm) with adult replay during pediatric adaptation. This yields PmSaAcTm configuration.

- **Design tradeoffs**:
  - Direct pediatric learning (PpSpAdTo) maximizes intra-institutional performance but requires abundant pediatric labels (~25 hours training)
  - CL (PmSaAdTm) sacrifices ~1–2 DSC points for 60% time savings (~10 hours vs 25 hours) and better inter-institutional generalization
  - FT (PmSaAdTp) is fastest (~2.5 hours) but risks catastrophic forgetting for absent structures; use only when target structures overlap completely with pretraining classes

- **Failure signatures**:
  - Prostate DSC = 0% on adult test set after fine-tuning → catastrophic forgetting; switch to CL or reduce pediatric-only epochs
  - Small organ DSC (e.g., adrenal, gallbladder) drops >15 points on pediatric test → training plan mismatch; switch from Pa to Pm or Pp
  - Large inter-institutional DSC gap (>10 points) despite FT → institutional shift dominates; switch to CL with balanced replay

- **First 3 experiments**:
  1. **Baseline audit**: Run TotalSegmentator (PaSaAdTo) on your internal pediatric test set; document per-organ DSC to quantify the adult-to-pediatric gap
  2. **Augmentation ablation**: Train PaSaAcTo on public adult data; evaluate on held-out pediatric data; compare DSC gains per organ vs. PaSaAdTo to identify which structures benefit most from contraction
  3. **Transfer strategy comparison**: Starting from PmSaAc pretraining, run both Tp (fine-tuning) and Tm (continual learning with 0.5 adult replay ratio) on your pediatric training split; measure DSC on internal pediatric test set and adult test set to assess forgetting vs. adaptation tradeoffs

## Open Questions the Paper Calls Out
- Can organ-specific augmentation strategies yield higher segmentation accuracy than the global contraction-based augmentations proposed?
- How does the recommended PmSaAdTm strategy perform when stratified by specific age cohorts (e.g., neonates vs. adolescents) rather than the aggregate 0–16 range?
- Why do models pre-trained on adult data using pediatric-derived training plans (e.g., PpSa) fail to converge during transfer learning, and can this optimization barrier be overcome?

## Limitations
- The framework's effectiveness is demonstrated primarily on abdominal CT with 12 organs; performance on other anatomical regions and different imaging modalities remains untested
- The contraction augmentation strategy assumes size is the primary anatomical difference between adult and pediatric cases; this may not hold for all pediatric pathologies or developmental stages
- While continual learning offers time savings, the requirement to retain adult training data for replay may be prohibitive in resource-limited settings

## Confidence

- **High confidence**: The observation that adult training plans cause systematic performance degradation on pediatric data (supported by multiple experimental conditions and statistical validation)
- **Medium confidence**: The superiority of contraction-based augmentations for pediatric adaptation (mechanism well-reasoned but lacks external validation in the literature)
- **Medium confidence**: The catastrophic forgetting phenomenon during fine-tuning (consistent with established transfer learning literature but dataset-specific severity)

## Next Checks

1. **Anatomical generalization**: Apply PSAT framework to pediatric brain MRI segmentation; evaluate whether contraction augmentations and mixed training plans provide similar benefits across modalities and anatomical regions

2. **Developmental stage specificity**: Segment pediatric datasets stratified by age groups (infant, child, adolescent); analyze whether the optimal configuration varies across developmental stages

3. **Clinical implementation**: Deploy the optimal PmSaAdTm configuration in a clinical workflow; measure annotation time savings and segmentation accuracy against expert manual delineation on real-world cases