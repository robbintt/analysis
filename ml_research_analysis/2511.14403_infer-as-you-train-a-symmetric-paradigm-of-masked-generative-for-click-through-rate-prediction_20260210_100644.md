---
ver: rpa2
title: 'Infer As You Train: A Symmetric Paradigm of Masked Generative for Click-Through
  Rate Prediction'
arxiv_id: '2511.14403'
source_url: https://arxiv.org/abs/2511.14403
tags:
- generative
- prediction
- feature
- features
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the asymmetry between training and inference
  in generative CTR models, which prevents them from fully utilizing their generative
  capabilities to improve prediction accuracy. The authors propose SGCTR, a novel
  framework that applies generative capabilities during online inference by iteratively
  refining input features based on model confidence scores.
---

# Infer As You Train: A Symmetric Paradigm of Masked Generative for Click-Through Rate Prediction

## Quick Facts
- arXiv ID: 2511.14403
- Source URL: https://arxiv.org/abs/2511.14403
- Authors: Moyu Zhang; Yujun Jin; Yun Chen; Jinxin Hu; Yu Zhang; Xiaoyi Zeng
- Reference count: 15
- Primary result: Achieves AUC improvements of up to 0.8186 on Criteo dataset compared to state-of-the-art baselines

## Executive Summary
This paper addresses the fundamental asymmetry between training and inference in generative click-through rate (CTR) prediction models. While generative models can learn feature dependencies during training, they typically cannot utilize these capabilities during online inference, limiting their practical effectiveness. The authors propose SGCTR, a novel framework that bridges this gap by applying generative capabilities during inference through iterative feature refinement. The approach demonstrates significant performance improvements across multiple datasets and validates its effectiveness through online A/B testing with a 2.1% CTR improvement.

## Method Summary
SGCTR introduces a symmetric paradigm where generative capabilities learned during training are actively utilized during inference. The framework employs discrete diffusion during training to learn feature dependencies and distributions. During inference, an iterative refinement strategy uses model confidence scores to progressively denoise and refine input features. This creates a closed-loop system where the model's own predictions guide feature improvement, allowing it to leverage learned generative knowledge for more accurate CTR predictions in real-time scenarios.

## Key Results
- Achieves state-of-the-art AUC of 0.8186 on Criteo dataset
- Demonstrates 2.1% CTR improvement in online A/B testing
- Outperforms existing generative CTR models across four datasets (Criteo, Avazu, Malware, and industrial dataset)
- Shows consistent improvements across different feature types and distributions

## Why This Works (Mechanism)
The framework works by treating inference as an active refinement process rather than passive prediction. During training, discrete diffusion learns the joint distribution of features and their dependencies. At inference time, the model uses its confidence in current predictions to guide iterative feature refinement, effectively denoising corrupted or uncertain features. This symmetric approach allows the model to continuously improve its input representation based on learned generative knowledge, resulting in more accurate predictions than traditional one-pass inference methods.

## Foundational Learning
- **Discrete diffusion processes**: Required for modeling categorical feature distributions in CTR data. Quick check: Verify that diffusion steps preserve feature relationships and don't introduce artifacts.
- **Iterative refinement strategies**: Needed to progressively improve feature quality during inference. Quick check: Monitor convergence behavior and ensure refinement doesn't lead to feature drift.
- **Confidence-based gating**: Essential for determining when and how to refine features. Quick check: Validate that confidence scores correlate with actual prediction accuracy improvements.
- **Symmetric training-inference design**: Critical for maintaining consistency between learned generative capabilities and their practical application. Quick check: Ensure training objectives align with inference refinement goals.

## Architecture Onboarding

**Component Map**: Discrete Diffusion Layer -> Confidence Scoring Module -> Iterative Refinement Loop -> Final Prediction Layer

**Critical Path**: Input features → Discrete diffusion encoding → Initial prediction → Confidence assessment → Feature refinement (iterative) → Final prediction

**Design Tradeoffs**: The framework balances computational cost of iterative refinement against prediction accuracy gains. More refinement iterations improve accuracy but increase latency, requiring optimization for real-time serving scenarios.

**Failure Signatures**: 
- Convergence issues in iterative refinement (features oscillate or diverge)
- Confidence scores that don't correlate with actual prediction quality
- Training-inference mismatch where generative capabilities don't translate to inference improvements

**3 First Experiments**:
1. Ablation study removing iterative refinement to measure baseline impact
2. Varying number of refinement iterations to identify optimal trade-off
3. Testing on synthetic data with controlled feature corruption levels

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Reliance on discrete diffusion may not generalize well to continuous or high-cardinality categorical features
- Performance improvements may be dataset-dependent, primarily demonstrated on advertising-specific datasets
- Single case online A/B test without broader deployment validation across different contexts

## Confidence

**High Confidence**: The core architectural innovation of symmetric training-inference generative capabilities is technically sound and well-motivated

**Medium Confidence**: The quantitative improvements on benchmark datasets (AUC scores up to 0.8186) are reproducible but may be dataset-dependent

**Low Confidence**: The generalizability of the approach to non-advertising domains and the robustness of online performance across different market conditions

## Next Checks
1. Cross-domain validation: Test SGCTR on non-advertising CTR prediction tasks (e.g., e-commerce product recommendations, content recommendations) to assess domain transferability of the generative improvements

2. Feature type robustness analysis: Systematically evaluate performance when varying feature types (continuous, high-cardinality categorical, sparse vs. dense) to understand which feature characteristics benefit most from the generative refinement

3. Ablation study on refinement iterations: Conduct controlled experiments varying the number of refinement iterations during inference to identify the optimal trade-off between computational cost and prediction accuracy, particularly for real-time serving scenarios