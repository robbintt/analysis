---
ver: rpa2
title: Seasonal Station-Keeping of Short Duration High Altitude Balloons using Deep
  Reinforcement Learning
arxiv_id: '2502.05014'
source_url: https://arxiv.org/abs/2502.05014
tags:
- wind
- forecast
- forecasts
- era5
- altitude
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of station-keeping short-duration
  high-altitude balloons (HABs) in a region of interest using deep reinforcement learning
  (DRL). The authors develop a custom simulation environment and train Deep Q-Networks
  (DQN) agents to perform station-keeping maneuvers by adjusting altitude to leverage
  wind patterns.
---

# Seasonal Station-Keeping of Short Duration High Altitude Balloons using Deep Reinforcement Learning

## Quick Facts
- arXiv ID: 2502.05014
- Source URL: https://arxiv.org/abs/2502.05014
- Authors: Tristan K. Schuler; Chinthan Prasad; Georgiy Kiselev; Donald Sofge
- Reference count: 28
- Primary result: DQN agents achieve ~50% TWR50 using wind diversity (Forecast Score) for short-duration HAB station-keeping

## Executive Summary
This paper addresses the challenge of keeping short-duration high-altitude balloons within a designated region by adjusting altitude to exploit wind shear patterns. The authors develop a custom simulation environment and train Deep Q-Networks (DQN) to perform station-keeping maneuvers using a piecewise reward function optimized for short 20-hour flights. Synthetic wind forecasts generated from aggregated historical radiosonde data are closely correlated with ERA5 reanalysis, enabling realistic training scenarios. The paper introduces a Forecast Score algorithm to classify wind diversity and demonstrates its effectiveness in predicting station-keeping success across different seasons.

## Method Summary
The authors train DQN agents to station-keep short-duration high-altitude balloons by adjusting altitude to leverage wind patterns. They generate synthetic wind forecasts from historical radiosonde data, which correlate with ERA5 reanalysis, and use these for training in a custom simulation environment. The DQN observes a 7-level wind column (20-150 hPa) along with relative position data, outputting discrete ascend/descend/stay actions. Training uses approximately 150M timesteps with Optuna-tuned hyperparameters including learning rates between 1e-5 and 1e-4 and epsilon-greedy exploration decaying from 25-50% to 10-20%. The Forecast Score algorithm classifies wind diversity by counting opposing wind direction pairs across altitude levels.

## Key Results
- DQN agents achieve approximately 50% average time within 50km region (TWR50) for short-duration station-keeping
- Forecast Score algorithm effectively predicts station-keeping success, with low scores (like October's 73.4% zero rate) indicating physically unsolvable problems
- Synthetic winds generated from radiosonde data closely correlate with ERA5 reanalysis, validating the simulation-to-real approach
- Piecewise reward function (2.0 for <25km, 1.0 for <50km) outperforms continuous distance-based rewards for short-duration missions

## Why This Works (Mechanism)

### Mechanism 1
Wind diversity, not wind speed, determines station-keeping feasibility. The agent exploits opposing wind directions at different altitudes to generate horizontal control. If all wind layers blow uniformly, no opposing vectors exist for maintaining position. Core assumption: horizontal wind velocity dominates state variables; vertical motion is controllable enough to exploit shear layers. Evidence: Forecast Score algorithm shows probabilities of success vary with wind diversity; neighbor paper [72087] supports altitude control deriving from atmospheric stratification. Break condition: uniform wind direction across all reachable altitudes renders altitude control useless.

### Mechanism 2
Training on synthetic winds (radiosonde-derived) rather than ERA5 alone improves robustness against simulation-to-real gaps. ERA5 lacks vertical resolution (7 pressure levels), while synthetic winds created via high-res radiosonde interpolation introduce realistic deviations the agent must learn to navigate. Core assumption: interpolation of sparse horizontal and dense vertical radiosonde data creates statistically similar wind fields to true atmosphere. Evidence: Synthetic winds closely correlate with ERA5; paper notes simple noise is unrealistic for representing atmospheric physics. Break condition: overly sparse horizontal radiosonde network fails to capture mesoscale features like local jets.

### Mechanism 3
Piecewise reward function proves more effective than continuous rewards for short-duration station-keeping. The steep gradient (2.0 for <25km, 1.0 for <25-50km) encourages tighter station-keeping than Google Loon's linear approach. Core assumption: DQN can converge on steeper reward landscape without getting stuck in local optima like oscillating at 25km boundary. Evidence: Paper notes piecewise reward achieved best performance for short-duration missions; development of custom simulation environment specifically handles these dynamics. Break condition: agent learns to game reward by hovering just inside 50km boundary rather than targeting center.

## Foundational Learning

- **Deep Q-Networks (DQN)**
  - Why needed: Core control algorithm; understanding Q-value approximation helps troubleshoot convergence failures
  - Quick check: Explain why Bellman equation uses discount factor (Î³) and how Target Network prevents oscillation during training

- **Atmospheric Wind Shear & Stratification**
  - Why needed: Forecast Score and agent's action space rely entirely on atmospheric physics
  - Quick check: If wind direction is constant with altitude (no shear), is altitude control useful for station-keeping? (Answer: No)

- **Simulation-to-Real (Sim2Real) Transfer**
  - Why needed: Paper explicitly creates synthetic winds to bridge gap between low-res forecasts and reality
  - Quick check: Why is training on perfect forecasts (ERA5) dangerous when deploying to real balloons?

## Architecture Onboarding

- **Component map:** Data Ingest (ERA5 + radiosondes) -> Synthetic Wind Generator (interpolation/smoothing) -> Simulator Environment (OpenAI Gym) -> DQN Agent (3 discrete actions)

- **Critical path:** Data Preprocessing bottleneck - agent cannot train effectively if Synthetic Winds aren't correlated with ERA5 observations. 50 hPa pressure levels show high variance; incorrect preprocessing means agent learns on noise.

- **Design tradeoffs:**
  - Resolution vs. Speed: 7 pressure levels for observation (speed) vs 46 levels for synthetic "truth" (accuracy) creates asymmetry agent must handle
  - Exploration vs. Exploitation: Specific schedule (25-50% random action decay) required; standard DQN defaults often fail

- **Failure signatures:**
  - Constant Drift: Agent flies straight out of bounds. Likely cause: training on month with low Forecast Score (e.g., October)
  - Oscillation: Agent bounces rapidly between altitude floors/ceilings. Likely cause: incorrect reward function scaling or turbulent wind shear
  - Correlation Collapse: Agent performs well in Sim but fails real flight tests. Likely cause: synthetic winds didn't capture specific local turbulence

- **First 3 experiments:**
  1. Sanity Check (Perfect Foresight): Run simulation where Observation = Truth (ERA5 only). Agent should achieve near 100% TWR50 if wind diversity is non-zero, validating RL setup
  2. Forecast Score Correlation: Run Forecast Score algorithm on target region/season. If score < 0.3 (like October), don't train - problem is physically unsolvable with current constraints
  3. Hyperparameter Sweep: Using Optuna framework, verify learning rate sensitivity. Paper suggests 1e-5 to 1e-4; try training outside this range to confirm failure modes

## Open Questions the Paper Calls Out

- **Question 1:** How effectively do DQN agents trained on synthetic and ERA5 data transfer to station-keeping tasks on physical SHAB-V platforms in real atmospheric conditions?
  - Basis: Authors state plans to integrate trained DQN algorithms on SHAB-Vs for real flight evaluation
  - Why unresolved: Current study confined to simulation using synthetic winds from historical data, lacking validation against chaotic real dynamics
  - Evidence needed: Flight test results comparing TWR50 performance of trained agents against simulated baselines using real-time onboard sensor data

- **Question 2:** Can curriculum learning or training on larger, diverse datasets improve robustness when deploying in regions different from training set?
  - Basis: Models trained on Southwestern U.S. performed worse on equatorial regions due to unseen wind flows; authors note optimization strategies could help but are out of scope
  - Why unresolved: Agents appear overfitted to specific regional wind profiles lacking capacity to generalize to areas with different wind diversity
  - Evidence needed: Comparative evaluation of curriculum-trained agents across multiple latitudes showing improved TWR50 in previously unseen regions

- **Question 3:** How does station-keeping performance change when utilizing operational forward-predicted forecasts (GFS) instead of historical reanalysis (ERA5)?
  - Basis: Authors plan to compare synthetic forecasts and DQN performance on GFS forecasts versus ERA5 forecasts
  - Why unresolved: ERA5 acts as "perfect" historical hindcast, while operational flights must rely on GFS with lower temporal resolution and likely lower correlation with true atmospheric states
  - Evidence needed: Simulation results substituting ERA5 observations with GFS forecast data, quantifying resulting drop in TWR50 and Forecast Score correlation

- **Question 4:** Does incorporating uncertainty estimates or relative altitude values into wind column observation vector enhance agent's ability to handle forecast discrepancies?
  - Basis: Authors mention plans to experiment with including uncertainty estimates within observation space
  - Why unresolved: Current observation vector forces agent to implicitly learn discrepancies between synthetic and ERA5 winds without explicit forecast reliability data
  - Evidence needed: Ablation studies comparing convergence rates and TWR50 performance of agents with standard vectors versus augmented vectors with uncertainty metrics

## Limitations
- Primary limitation: Assumes wind diversity (opposing wind directions at different altitudes) is dominant factor for station-keeping feasibility
- Geographic constraint: Study limited to southwestern USA region, may not generalize to areas with different atmospheric dynamics
- Unvalidated transfer: Simulation-to-real gap remains unvalidated through field tests

## Confidence
- High: Mechanism linking wind diversity to station-keeping success (supported by Forecast Score correlation analysis)
- Medium: Synthetic wind generation approach (lacks direct validation against in-situ measurements)
- Low: Transferability of results to operational conditions (simulation-to-real gap unvalidated)

## Next Checks
1. Test Forecast Score predictions across multiple geographic regions to assess generalizability of wind diversity requirements
2. Validate synthetic wind generation by comparing interpolated profiles against high-resolution dropsonde data from field campaigns
3. Conduct closed-loop hardware-in-the-loop experiments using actual radiosonde-derived wind profiles to evaluate sim-to-real transfer before full deployment