---
ver: rpa2
title: 'AI-VERDE: A Gateway for Egalitarian Access to Large Language Model-Based Resources
  For Educational Institutions'
arxiv_id: '2502.09651'
source_url: https://arxiv.org/abs/2502.09651
tags:
- ai-verde
- access
- these
- university
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: AI-VERDE is a university-focused platform enabling seamless access
  to large language models (LLMs) for academic use. It addresses barriers like privacy,
  technical complexity, and limited access by providing a unified gateway to both
  commercial and open-source models, with features such as on-premises deployment,
  RAG support, automated access control, and budget management.
---

# AI-VERDE: A Gateway for Egalitarian Access to Large Language Model-Based Resources For Educational Institutions

## Quick Facts
- arXiv ID: 2502.09651
- Source URL: https://arxiv.org/abs/2502.09651
- Reference count: 40
- Key outcome: University-focused platform enabling seamless access to LLMs with on-premises RAG, budget management, and privacy controls

## Executive Summary
AI-VERDE is a university-focused platform enabling seamless access to large language models (LLMs) for academic use. It addresses barriers like privacy, technical complexity, and limited access by providing a unified gateway to both commercial and open-source models, with features such as on-premises deployment, RAG support, automated access control, and budget management. Deployed at the University of Arizona, it supported 78 users across courses and research projects, handling over 110 million tokens and 97,000 API calls in six months. By integrating authentication systems, offering tailored support, and reducing reliance on expensive commercial services, AI-VERDE democratizes AI access and supports diverse academic needs while ensuring data privacy and compliance.

## Method Summary
AI-VERDE implements a microservices architecture using Kubernetes to orchestrate vLLM for model serving, LiteLLM as a unified API proxy, Weaviate for vector databases, and CILogon for federated authentication. The system provides a reverse proxy interface that routes requests to either self-hosted open-source models or commercial APIs while enforcing budget limits and access controls. Document intake services process course materials into vector databases for RAG applications, all running on institutional infrastructure to ensure data sovereignty. The platform automates provisioning of API keys and vector databases for course-based tenants, enabling faculty to allocate class-specific budgets and resources.

## Key Results
- Supported 78 users across courses and research projects in six-month pilot
- Processed over 110 million tokens and handled 97,000 API calls
- Successfully integrated with university authentication and budget management systems

## Why This Works (Mechanism)

### Mechanism 1: Unified API Gateway Abstraction
- Claim: The platform reduces integration friction and centralizes cost management by abstracting disparate model backends behind a single, OpenAI-compatible interface.
- Mechanism: AI-VERDE uses LiteLLM as a reverse proxy. It intercepts standard API calls, routes them to the appropriate backend (vLLM for open-source models or direct APIs for commercial ones), and handles key management and usage metering centrally.
- Core assumption: Assumes that the majority of client libraries and user scripts target the OpenAI API standard, which is a common industry convention but not a universal guarantee.
- Evidence anchors:
  - [abstract] Mentions providing "both a conversational web interface and API access" to streamline management.
  - [section 2.1] States "LiteLLM behaves as a reverse proxy: It exposes an OpenAI-compliant API access point that routes the requests... [and] enables to implement user access control."
  - [corpus] "Institutional AI Sovereignty Through Gateway Architecture" supports the efficacy of gateway models for controlled access.
- Break condition: If a specific backend model requires input parameters (e.g., specific sampling methods or vision inputs) not supported by the LiteLLM proxy schema, the unified interface will fail or degrade functionality.

### Mechanism 2: Scoped Resource Partitioning (Courses as Tenants)
- Claim: The platform enables egalitarian access by mapping institutional roles to resource budgets, preventing "tragedy of the commons" in shared GPU/API environments.
- Mechanism: The system implements an abstraction where "courses" function as tenants. It automates the provisioning of API keys and vector databases for these groups, associating them with specific budget caps and model permissions.
- Core assumption: Assumes that the "Course" abstraction is flexible enough to represent research groups and labs, which may have different lifecycle dynamics than a semester-long class.
- Evidence anchors:
  - [section 2.2] "We implement the abstraction of groups as courses... Instructors also have access to the list of students and to the budget information."
  - [section 3.4] Notes that the system "automates budget management by enabling faculty to allocate class-specific funds."
  - [corpus] Corpus evidence on specific "course-tenant" mapping is weak; related papers focus more on general agent delegation.
- Break condition: If user roles change mid-semester (e.g., a student becomes a TA), manual re-keying or role updates might be required if the automation logic is rigid.

### Mechanism 3: On-Premises RAG for Data Sovereignty
- Claim: The architecture mitigates privacy risks and IP leakage by keeping document indexing and inference within institutional firewalls.
- Mechanism: A document intake service processes files into vectors stored in a local Weaviate instance. Queries retrieve context from this local store and feed it into locally hosted models (via vLLM) or sanitized proxied requests, ensuring raw data doesn't persist on external commercial servers.
- Core assumption: Assumes that the local GPU cluster has sufficient throughput to handle the RAG workload without the latency benefits of dedicated commercial edge networks.
- Evidence anchors:
  - [section 3.1] "AI-VERDE addresses these concerns by ensuring all data... is processed entirely on-premises... [and] does not store or reuse queries for model training."
  - [section 2.3] Describes the "Document Intake service... used to generate a corresponding vector database persisted into AI-VERDE's Weaviate service."
  - [corpus] "AgentSafe" and "Institutional AI Sovereignty" papers corroborate the trend toward local data management for security.
- Break condition: If the vector database scales beyond the memory limits of the on-premises cluster, retrieval latency may spike, breaking the "seamless" user experience.

## Foundational Learning

- Concept: **Reverse Proxy / API Gateway Pattern**
  - Why needed here: Essential to understand how AI-VERDE presents a single interface to users while managing multiple backend models (Llama, Mistral, GPT-4) behind the scenes.
  - Quick check question: Can you explain how a reverse proxy allows the client to change the target model (e.g., from GPT-4 to Llama) without changing the code?

- Concept: **Retrieval-Augmented Generation (RAG)**
  - Why needed here: This is the core feature enabling "specialized knowledge" and privacy, allowing the LLM to reference course materials without retraining.
  - Quick check question: Does the RAG mechanism in this architecture fine-tune the model weights, or does it inject context at inference time?

- Concept: **Token-based Usage Metering**
  - Why needed here: Understanding how the system enforces "budget management" and "financial compliance" is critical for the "egalitarian" allocation of resources.
  - Quick check question: If a user exceeds their token limit, should the system reject the request or throttle the speed? (Based on the paper, it implies rejection/budget caps).

## Architecture Onboarding

- Component map:
  Frontend: Web Chat Interface + API Client -> Auth: CILogon (Federated Identity) -> Controller: LiteLLM (Proxy/Key Management) -> Backend: vLLM (Self-hosted models) OR Commercial Proxy + Weaviate (Vector DB)

- Critical path:
  1. User authenticates via institutional ID (CILogon)
  2. System resolves user to a "Course" group and validates active Budget/API Key
  3. User sends prompt -> LiteLLM checks permissions -> Retrieves context from Weaviate (if RAG enabled)
  4. Request forwarded to vLLM (Open Source) or OpenAI (Commercial)
  5. Tokens counted -> Response returned -> Budget decremented

- Design tradeoffs:
  - Latency vs. Privacy: On-prem hosting ensures privacy but relies on institutional network/cluster speed compared to commercial cloud edge servers
  - Complexity vs. Control: Using Kubernetes and microservices (vLLM, Weaviate, LiteLLM) provides flexibility but increases maintenance overhead compared to a monolithic SaaS solution

- Failure signatures:
  - Silent Context Loss: RAG pipeline fails silently if Weaviate connection drops, causing the LLM to hallucinate (loss of grounding)
  - Budget Lockout: Users unable to access course materials if automated budget tracking drifts or miscalculates token usage
  - Model Starvation: If GPU allocation isn't elastic, one heavy research group could degrade performance for all other "Courses" sharing the vLLM cluster

- First 3 experiments:
  1. API Connectivity Test: Generate a test API key for a dummy "Course" and make a cURL request to the LiteLLM endpoint to verify routing and authentication
  2. RAG Ingestion Check: Upload a small PDF via the Document Intake service, query the specific vector collection, and verify the response cites the PDF content
  3. Budget Threshold Breach: Set a mock budget limit of 100 tokens for a test user and confirm the system blocks the request and logs the event correctly

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can AI-VERDE effectively detect or mitigate the inherent biases present in the underlying open-source models it serves?
- Basis in paper: [explicit] The "Ethics and Limitations" section states that because the platform exposes existing LLMs, "any inherent biases in those models will be exhibited too by Verde."
- Why unresolved: The current architecture relies on the model providers to address bias, lacking a platform-level solution for fairness or content filtering beyond basic guardrails.
- What evidence would resolve it: Implementation of a middleware layer that benchmarks model outputs against fairness metrics or successfully applies bias-correction adapters.

### Open Question 2
- Question: What are the specific technical and pedagogical impacts of integrating AI-VERDE directly into Learning Management Systems (LMS) like D2L?
- Basis in paper: [explicit] The "Conclusion and Future Work" section identifies integrating AI-VERDE into LMS platforms to enable course-specific instances as a primary development goal.
- Why unresolved: The current deployment operates as a standalone gateway; the interaction dynamics within an LMS environment (e.g., grade book integration, assignment feedback loops) are planned but not yet implemented or tested.
- What evidence would resolve it: A case study analyzing the deployment of AI-VERDE within a live LMS course environment, measuring both system latency and instructor satisfaction.

### Open Question 3
- Question: Is the on-premises infrastructure model financially and technically sustainable when scaled from a pilot (78 users) to a full university population?
- Basis in paper: [inferred] The paper highlights hardware constraints and high costs (often exceeding $50,000) as barriers to entry, while acknowledging the pilot was limited by the dedicated hardware available from CyVerse and Jetstream.
- Why unresolved: The paper demonstrates success with a small user base but does not model the resource elasticity required for university-wide adoption without significant new funding.
- What evidence would resolve it: A cost-benefit analysis showing stable performance and manageable marginal costs under a load-testing scenario simulating thousands of concurrent users.

## Limitations
- Deployment at single institution over six months limits generalizability to other contexts with different identity systems, funding models, and technical infrastructure
- Custom multi-tenant course management and budget tracking components are not open-sourced, making independent verification difficult
- Token usage statistics lack breakdown by model type, making cost-effectiveness analysis incomplete

## Confidence

**High Confidence**: The core architectural pattern (LiteLLM reverse proxy + vLLM + Weaviate + CILogon) is technically sound and aligns with established best practices in API gateway design and RAG implementation.

**Medium Confidence**: The "egalitarian access" claim is supported by the documented deployment but lacks comparative metrics against baseline scenarios without AI-VERDE.

**Low Confidence**: The long-term sustainability claims (operational stability, maintenance overhead, user adoption rates beyond initial deployment) are not supported by longitudinal data.

## Next Checks
1. **Security Audit**: Conduct a penetration test on the authentication and authorization flow, specifically testing for token leakage between course groups and unauthorized access to RAG databases through API endpoints.

2. **Performance Under Load**: Simulate concurrent usage from 200+ users across multiple courses to measure latency degradation, token processing throughput, and GPU memory exhaustion thresholds in the vLLM cluster.

3. **Cost-Effectiveness Analysis**: Track detailed token usage by model type (commercial vs. open-source) over a full academic year to quantify actual cost savings compared to direct commercial API access and validate the budget management system's effectiveness.