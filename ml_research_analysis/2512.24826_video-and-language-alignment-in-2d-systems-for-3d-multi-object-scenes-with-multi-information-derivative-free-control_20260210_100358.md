---
ver: rpa2
title: Video and Language Alignment in 2D Systems for 3D Multi-object Scenes with
  Multi-Information Derivative-Free Control
arxiv_id: '2512.24826'
source_url: https://arxiv.org/abs/2512.24826
tags:
- information
- scenes
- camera
- control
- regret
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of enabling 2D vision-language
  models to process 3D scenes by controlling an in-scene camera to provide optimal
  viewpoints. The authors propose a novel method called MI-ZO that estimates multivariate
  mutual information with active regret minimization using zeroth-order optimization.
---

# Video and Language Alignment in 2D Systems for 3D Multi-object Scenes with Multi-Information Derivative-Free Control

## Quick Facts
- arXiv ID: 2512.24826
- Source URL: https://arxiv.org/abs/2512.24826
- Reference count: 40
- This paper proposes MI-ZO, a method enabling 2D vision-language models to process 3D scenes by controlling camera viewpoints using multi-information derivative-free optimization.

## Executive Summary
This paper addresses the challenge of enabling 2D-trained vision-language models to reason over 3D multi-object scenes. The authors propose MI-ZO, a novel method that estimates multivariate mutual information using zeroth-order optimization with active regret minimization. This approach learns to minimize redundancy between visual and linguistic inputs to guide camera control without requiring access to model parameters or costly training. The method achieves up to 21% error reduction on three new benchmarks for cross-modal reasoning over 3D scenes.

## Method Summary
MI-ZO estimates multi-information over n>2 variables using zeroth-order optimization with active regret minimization. The algorithm forms a weighted mixture distribution over visual sources (global color histograms, local edge density, object-level features) and linguistic scaling factors, optimizing via finite differences to eliminate redundancies. A lightweight polynomial regression controller combines component models filtering VLM responses with an interaction matrix maintaining spatial relationships. The system operates in two rounds: a measurement round with default rotations and a correction round with controller-predicted actions.

## Key Results
- Achieves up to 21% error reduction compared to standard control methods on 3D multi-object scene benchmarks
- Demonstrates theoretical guarantees on the expressiveness of information estimates for n>2 variables
- Shows zeroth-order optimization effectively guides camera control without requiring gradient access or model parameter modification

## Why This Works (Mechanism)

### Mechanism 1
Active regret minimization in multi-information estimation separates informative from redundant variables when combining more than two entropy sources. The algorithm forms a weighted mixture distribution over visual sources and linguistic scaling factors, retaining signed weight changes only if running mean on MI increases—eliminating overlaps between variables that would otherwise produce negative MI values when n>2. This works because VLM prediction errors correlate with suboptimal viewpoint information, detectable through multivariate entropy combinations.

### Mechanism 2
Zeroth-order optimization enables parameter-free learning from noisy VLM outputs without gradient access. Finite difference approximation estimates optimal mixing weights by comparing current loss against accumulated mean loss across rounds, averaging multiple iterations to reduce noise. This avoids backpropagation through the VLM entirely, relying on the assumption that VLM outputs contain sufficient signal-to-noise ratio for function-value optimization to converge on useful camera control policies.

### Mechanism 3
Lightweight polynomial regression controller with information-theoretic scoring outperforms neural methods in low-data, online settings. Two component models filter VLM responses using least-squares on proxy labels, with a central unit combining error probability estimates and z-axis confidence scores. An interaction matrix maintains spatial relationships for action prediction, assuming the relationship between viewpoint quality and VLM correctness is approximately linear or low-order polynomial in extracted features.

## Foundational Learning

- Concept: **Mutual Information over Multiple Variables**
  - Why needed here: Standard bivariate MI fails for n>2 variables; can return negative values when redundant information exists between sources, invalidating the measure.
  - Quick check question: Given three entropy sources H₁, H₂, H₃ and target Y, when would MI(X:Y) become negative?

- Concept: **Zeroth-Order Optimization**
  - Why needed here: VLMs are black-box at inference; no gradient access. ZO methods optimize using only function evaluations.
  - Quick check question: How does finite difference approximation differ from gradient descent in convergence guarantees and query complexity?

- Concept: **Active Regret Minimization**
  - Why needed here: Online setting with limited demonstrations requires balancing exploration with exploitation. Regret bounds theoretical performance.
  - Quick check question: What is the relationship between cumulative regret and the margin γ between additive and reductive units in the hyperplane formulation?

## Architecture Onboarding

- Component map: Entropy extraction (color histograms + edge detection) -> MI-ZO scoring -> Component Model filtering -> Central Unit aggregation -> Action prediction -> VLM inference -> Feedback loop

- Critical path: Entropy extraction -> MI-ZO scoring -> Component Model filtering -> Central Unit aggregation -> Action prediction -> VLM inference -> Feedback loop

- Design tradeoffs:
  - HSV vs. CIELAB: HSV simpler (single hue axis), CIELAB more expressive (two color axes) but requires more sources
  - Polynomial vs. Neural controller: Polynomial more sample-efficient, neural scales better with data
  - 5 vs. 8 camera actions: More actions improve accuracy (+13-19% delta) but linear time cost

- Failure signatures:
  - MI scores collapsing to single value → entropy sources too correlated; add independent features
  - VLM always returning False → hard inference-time limit; cannot recover without model access
  - High variance across runs (σ > 2.0) → insufficient demonstrations; increase n

- First 3 experiments:
  1. **UC-3DS-MI diagnostic validation**: Run on 24 uniform + 24 complex polygon scenes with 50%/20% feedback settings. Verify MI-ar separates correct/incorrect VLM decisions into distinct score distributions (target separation > 0.3 between centers of mass).
  2. **Color space ablation**: Test Jzazbz, Oklab, HSV, CIELAB on GeoProperties-3DS. Confirm Table 3 ceiling effect—adding sources beyond 5 should not improve BER.
  3. **Controller comparison**: Benchmark polynomial + ZO + MI against PID, Extended Kalman, Linear+SGD, RBF on PartialView-3DS. Verify neural methods underperform in low-data regime (n=3 demonstrations).

## Open Questions the Paper Calls Out

### Open Question 1
Can the MI-ZO method maintain performance gains on 3D scenes with significantly higher object counts (beyond 3-4 objects), given the observed performance degradation in multi-object settings? The paper only tests up to 4 objects and attributes the limitation to VLM capabilities, but does not determine whether the control method itself scales or whether the information-theoretic measures become less discriminative in crowded scenes.

### Open Question 2
Is there a theoretical or empirical limit to the expressiveness gained by adding additional entropy sources beyond the 5-6 tested, and can this limit be characterized formally? The paper observes the ceiling empirically but does not provide theoretical bounds on when adding variables becomes redundant or counterproductive for multi-information estimation.

### Open Question 3
Can MI-ZO be combined with parameter-access methods (fine-tuning or gradient-based adaptation) to overcome the inference-only "hard limit" identified when VLMs return incorrect predictions on all viewpoints? The paper deliberately avoids parameter access to maintain computational efficiency but does not explore hybrid approaches that could use limited gradient access during an initial calibration phase.

## Limitations
- The method's dependence on accurate entropy estimation from limited visual features remains unvalidated across diverse 3D scene types, showing strong performance only on geometric and object-based scenes.
- The claim of "parameter-free" learning is qualified by the need for careful hyperparameter selection in zeroth-order optimization, which is not fully specified.
- The controller's polynomial regression assumption may fail when the relationship between viewpoint quality and VLM correctness becomes highly non-linear.

## Confidence
- **High**: The core theoretical framework for multi-information estimation over n>2 variables is well-founded, correctly identifying that standard bivariate MI fails for higher-order combinations.
- **Medium**: The empirical results showing 21% error reduction are compelling but may be specific to controlled 3D multi-object benchmark environments; performance on real-world, unconstrained video data remains unverified.
- **Low**: The claim that the method "requires no model access" is technically accurate but potentially misleading—the approach still requires a pre-trained VLM and careful calibration of the entropy extraction pipeline.

## Next Checks
1. **Dynamic Scene Generalization**: Test MI-ZO on video datasets with moving objects (e.g., Something-Something, EPIC-KITCHENS) to verify effectiveness beyond static 3D multi-object scenes.
2. **Feature Ablation Study**: Systematically remove individual entropy sources (color histograms, edge density, linguistic features) to quantify their relative contributions and identify the minimum viable feature set.
3. **Real-Time Performance Evaluation**: Measure inference latency and computational overhead of the MI-ZO controller compared to standard VLM processing to assess practical deployment viability in resource-constrained environments.