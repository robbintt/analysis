---
ver: rpa2
title: Mining Social Determinants of Health for Heart Failure Patient 30-Day Readmission
  via Large Language Model
arxiv_id: '2502.12158'
source_url: https://arxiv.org/abs/2502.12158
tags:
- sdoh
- notes
- readmission
- social
- health
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study applied large language models to extract Social Determinants
  of Health from unstructured clinical notes in MIMIC-III to analyze their association
  with 30-day heart failure readmissions. Using Llama-3.1-8B in a zero-shot manner,
  the model mined 14 SDOH attributes from discharge notes, achieving high accuracy
  for charted variables (gender: 98.27%, age: MAE 3.08) and moderate performance for
  non-charted attributes (tobacco: 79.19%, transportation: 95.71%).'
---

# Mining Social Determinants of Health for Heart Failure Patient 30-Day Readmission via Large Language Model

## Quick Facts
- arXiv ID: 2502.12158
- Source URL: https://arxiv.org/abs/2502.12158
- Reference count: 13
- Large language model extracted SDOH attributes from MIMIC-III discharge notes, identifying significant predictors of 30-day heart failure readmission

## Executive Summary
This study applied zero-shot prompting with Llama-3.1-8B to extract 14 Social Determinants of Health (SDOH) attributes from unstructured clinical discharge notes in MIMIC-III. The model successfully identified key SDOH factors associated with 30-day heart failure readmission, including older age, unspecified ethnicity, Medicare insurance, past tobacco use, transportation limitations, and lack of social support. The research demonstrates the potential of LLM-based SDOH extraction for readmission risk assessment and highlights modifiable factors for targeted interventions.

## Method Summary
The researchers extracted heart failure patients from MIMIC-III using ICD-9 codes, then applied zero-shot prompting with Llama-3.1-8B to extract 14 SDOH attributes from discharge notes. They focused on Social History, Physical Exam, and Medical History sections, using constrained-choice prompts for each attribute. Extracted SDOHs were validated against structured EHR fields for charted variables and external annotations for non-charted attributes. Logistic regression was then used to identify significant predictors of 30-day readmission, reporting odds ratios with 95% confidence intervals and p-values.

## Key Results
- LLM achieved 98.27% accuracy for gender extraction and MAE of 3.08 for age prediction
- Transportation limitations showed strong association with readmission (OR=2.07, 95% CI: 1.22-3.52, p<0.01)
- Medicare insurance was the strongest predictor (OR=5.23, 95% CI: 0.93-29.29, p<0.01)
- Lack of social support showed protective association (OR=0.58, 95% CI: 0.36-0.92, p<0.05)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Zero-shot prompting with a pre-trained LLM can extract structured SDOH attributes from unstructured discharge notes without task-specific training.
- Mechanism: The LLM's pre-training on biomedical literature and clinical corpora enables pattern recognition for SDOH concepts through natural language understanding, mapping free-text spans to categorical labels via templated prompts.
- Core assumption: The pre-training corpus contains sufficient exposure to clinical documentation patterns and SDOH-related language for generalization to MIMIC-III notes.
- Evidence anchors:
  - We utilize the checkpoint of an open source LLM, Llama-3.1-8B, where the 8 billion parameters θ have been pre-trained with massive amount of textual corpus including biomedical literature and public clinical databases
  - Table 2 shows Gender accuracy 98.27%, Tobacco 79.19%, Transportation 95.71%
  - Weak corpus validation—neighbor papers on LLM-based SDOH extraction exist but citation counts are low (avg 0.04), indicating emerging rather than established methodology.
- Break condition: Performance degrades significantly for rarely documented SDOH where insufficient examples exist even in pre-training data.

### Mechanism 2
- Claim: Logistic regression on extracted SDOH variables can identify statistically significant predictors of 30-day HF readmission.
- Mechanism: Binary outcome modeling with odds ratio calculation quantifies the magnitude and direction of each SDOH's association with readmission risk relative to reference groups.
- Core assumption: Extracted SDOH labels are sufficiently accurate that noise from extraction errors does not overwhelm true signal in downstream regression.
- Evidence anchors:
  - Logistic regression identified significant predictors: older age (OR=1.01), unspecified ethnicity (OR=1.73), Medicare insurance (OR=5.23), past tobacco use (OR=1.20), transportation limitations (OR=2.07), and lack of social support (OR=0.58)
  - Table 3 reports p-values and 95% CIs for significant predictors
  - Related work on readmission prediction with clinical notes exists but direct comparison of SDOH-specific predictors is limited.
- Break condition: Extraction inaccuracies for low-prevalence attributes may introduce measurement error that biases OR estimates toward null or produces spurious associations.

### Mechanism 3
- Claim: Targeting specific note sections improves SDOH extraction yield by focusing on high-probability regions.
- Mechanism: Clinical notes follow semi-structured formatting conventions where SDOH information concentrates in specific sections; section filtering reduces noise and computational cost while preserving signal.
- Core assumption: SDOH mentions predominantly occur in the selected sections and are not scattered throughout nursing notes, radiology reports, or other excluded sections.
- Evidence anchors:
  - For overly lengthy combined notes, we keep mainly Social History, Physical Exam, and Medical History sections that mostly likely mention SDOHs
  - Limitation explicitly notes we focus solely on discharge notes to extract SDOH information, excluding other potentially valuable sources such as nursing and physician notes
  - No direct corpus evidence on section-level extraction efficiency; this is an assumption requiring validation.
- Break condition: If SDOH documentation patterns vary across institutions or note types, section-based filtering may miss relevant information or fail to generalize.

## Foundational Learning

- Concept: Zero-shot prompting
  - Why needed here: The extraction pipeline relies entirely on prompting without fine-tuning; understanding prompt design trade-offs is essential for adapting to new SDOH types.
  - Quick check question: Can you explain why the prompt template uses constrained candidate choices ("present", "past", "never", "unspecified") rather than open-ended extraction?

- Concept: Social Determinants of Health (SDOH) taxonomy
  - Why needed here: The study distinguishes "charted" (structured EHR fields) from "non-charted" (narrative-only) SDOH; this determines validation strategy and expected performance ceilings.
  - Quick check question: Why would Transportation (95.71% accuracy) be easier to extract than Drug use (67.46% accuracy) from the same notes?

- Concept: Odds ratio interpretation in clinical context
  - Why needed here: Translating OR values into intervention prioritization requires understanding both statistical significance and clinical effect sizes.
  - Quick check question: Medicare insurance shows OR=5.23 but with CI spanning 0.93–29.29—what does this wide interval suggest about the estimate's reliability?

## Architecture Onboarding

- Component map:
  MIMIC-III -> ICD-9 HF cohort filter -> Discharge note aggregation -> Section extraction (Social History, Physical Exam, Medical History) -> Llama-3.1-8B zero-shot prompting (14 SDOH attributes) -> Structured SDOH matrix -> Logistic regression -> Odds ratios + significance tests

- Critical path:
  1. Cohort definition (ICD-9 codes) determines patient sample representativeness
  2. Prompt engineering directly impacts extraction accuracy—current template uses constrained choice format
  3. Regression assumes accurate SDOH labels; extraction errors propagate as measurement error

- Design tradeoffs:
  - Zero-shot vs. fine-tuned: Zero-shot avoids labeled data requirements but may underperform on institution-specific documentation patterns
  - Discharge notes only vs. multi-note: Reduces complexity but may miss SDOH documented in nursing/progress notes
  - Constrained vs. open-ended extraction: Improves consistency for categorical variables but may lose nuance

- Failure signatures:
  - High "unspecified" rates (>85%) indicate either documentation gaps or prompt mismatch
  - Wide confidence intervals on ORs (e.g., Medicare: 0.93–29.29) suggest sparse positive cases
  - Spec-Acc near 0% with low % Spec (e.g., Housing: 0.02%) means validation is underpowered

- First 3 experiments:
  1. Prompt ablation: Compare current constrained-choice prompt against open-span extraction + post-hoc classification to quantify precision-recall tradeoff
  2. Multi-note validation: Extract SDOH from nursing and physician progress notes for same patients; measure concordance with discharge note extractions
  3. Error analysis on low-performing attributes: Manually review 50 false positives/negatives for Drug (67.46%) and Social Support (44.29%) to identify systematic prompt failures or annotation inconsistencies

## Open Questions the Paper Calls Out

- Question: Does incorporating nursing and physician notes, in addition to discharge notes, improve the comprehensiveness and accuracy of SDOH extraction?
  - Basis in paper: The authors state a limitation: we focus solely on discharge notes to extract SDOH information, excluding other potentially valuable sources such as nursing and physician notes, and list extending coverage to various types of clinical notes as future work.
  - Why unresolved: The current study design filtered out non-discharge notes to manage scope and text length, leaving the added value of other note types untested.
  - What evidence would resolve it: A comparative study measuring SDOH extraction yield and accuracy when input data includes progress notes and nursing reports versus discharge notes alone.

- Question: Can advanced causal relationship mining identify novel SDOHs that provide actionable insights for reducing readmission rates beyond the associations found via logistic regression?
  - Basis in paper: In the conclusion, the authors state they plan to explore advanced causal relationship mining to identify novel SDOH to provide actionable insights.
  - Why unresolved: The current study relies on logistic regression to quantify associations (odds ratios), which does not establish causality or capture complex interactions between variables.
  - What evidence would resolve it: Results from causal inference models applied to the dataset to isolate the specific impact of modifying factors like transportation or social support.

- Question: What underlying data limitations, reporting biases, or historical factors explain the increased readmission risk associated with "unspecified" ethnicity?
  - Basis in paper: The authors note in the discussion that Unspecified ethnicity warrants further investigation, potentially reflecting data limitations, reporting biases, or reluctance due to historical bias.
  - Why unresolved: The study observed a high Odds Ratio (1.73) for this group but lacked the additional data or qualitative context to distinguish between missing data artifacts and genuine socio-demographic risks.
  - What evidence would resolve it: A follow-up analysis linking the "unspecified" cohort to external census data or performing manual chart reviews to determine if the lack of documentation correlates with other high-risk social factors.

## Limitations

- High "unspecified" rates (>85%) for several non-charted SDOH suggest the prompt-template may not capture institution-specific language variations
- Wide confidence intervals on OR estimates (e.g., Medicare: 0.93–29.29) indicate insufficient positive cases for robust effect estimation
- Section-based filtering strategy may systematically miss SDOH information documented in nursing and physician notes

## Confidence

- **Medium** on the generalizability of zero-shot SDOH extraction across institutions and note types
- **Low** on the statistical reliability of readmission predictors for rare SDOH categories
- **Medium** in the section-based filtering strategy's completeness

## Next Checks

1. **Prompt Generalization Test**: Apply the current zero-shot prompt to a second, independent clinical dataset (e.g., eICU or another hospital system) to measure extraction accuracy degradation and identify institution-specific prompt adaptations needed.

2. **Multi-Note Extraction Validation**: For 100 randomly selected patients, extract SDOH from nursing and physician progress notes alongside discharge notes, then measure concordance rates to quantify information loss from section-based filtering.

3. **Effect Size Reliability Analysis**: Perform power analysis for each SDOH predictor using observed prevalence rates and confidence intervals to determine which associations have sufficient statistical power for clinical decision-making versus those requiring larger samples.