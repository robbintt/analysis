---
ver: rpa2
title: 'PlanGPT-VL: Enhancing Urban Planning with Domain-Specific Vision-Language
  Models'
arxiv_id: '2505.14481'
source_url: https://arxiv.org/abs/2505.14481
tags:
- planning
- arxiv
- urban
- data
- zhang
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# PlanGPT-VL: Enhancing Urban Planning with Domain-Specific Vision-Language Models

## Quick Facts
- arXiv ID: 2505.14481
- Source URL: https://arxiv.org/abs/2505.14481
- Authors: He Zhu; Junyou Su; Minxin Chen; Wen Wang; Yijie Deng; Guanhua Chen; Wenjia Zhang
- Reference count: 40
- One-line primary result: +59.2% performance improvement on domain-specific planning benchmarks

## Executive Summary
PlanGPT-VL is a vision-language model fine-tuned for urban planning map interpretation that achieves substantial domain performance gains while preserving general visual capabilities through strategic freezing of the vision encoder. The model uses a comprehensive training methodology combining Critical Point Thinking for hallucination reduction, distributional instruction synthesis for high-quality data generation, and frozen vision encoder parameters during Supervised Fine-Tuning. Results show 72.1% improvement on PlanBench-V while maintaining POPE stability at 88.5 and limiting general capability loss to -11.2% on MMMU.

## Method Summary
PlanGPT-VL builds on Qwen2-7B-VL-Instruct and uses a frozen vision encoder during fine-tuning to preserve general visual capabilities while adapting to urban planning domain knowledge. The approach employs the PlanAnno-V framework to synthesize high-quality instruction-response pairs from ~5,000 urban planning maps, using expert seed data and distributional expansion across 8 task types. Critical Point Thinking reduces hallucinations through structured verification, and training uses AdamW optimizer with lr=2e-5 for 3 epochs on global batch size 128.

## Key Results
- +59.2% improvement on PlanBench-V domain benchmark
- 72.1% improvement over general VLMs on planning tasks
- POPE stability maintained at 88.5% with frozen vision encoder

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Critical Point Thinking reduces hallucinations by decomposing complex visual reasoning into atomic, verifiable claims.
- Mechanism: Extracts structured "critical points" from initial reasoning, formulates targeted verification queries for each point against visual input, corrects errors below threshold τ, merges redundant points, and reconstructs final response.
- Core assumption: Models perform better at focused verification tasks than open-ended generation when attention is concentrated on specific visual elements.
- Evidence anchors: [abstract] states CPT reduces hallucinations through structured verification; [section 3.3] describes systematic "Generate-Verify-Revise" paradigm.

### Mechanism 2
- Claim: Distributional instruction synthesis preserves expert quality while expanding task diversity.
- Mechanism: Starts with ~1k expert-curated instructions, extracts semantic intents via tagging, clusters into 8 task types with complexity hierarchies, then performs stratified replication using few-shot demonstrations with diversification prompts to expand to 15 categories.
- Core assumption: Expert seed data captures core domain semantics, and controlled expansion maintains distributional fidelity.
- Evidence anchors: [abstract] mentions PlanAnno-V framework for high-quality VQA data synthesis; [section 3.2] reports semantic alignment (Cosine Similarity = 0.9350) with controlled variation (MMD = 0.0515).

### Mechanism 3
- Claim: Freezing vision encoder during SFT preserves general visual capabilities while adapting domain-specific language.
- Mechanism: Only fine-tunes language model backbone (Qwen2-7B-Instruct); keeps vision encoder and projector layers frozen to prevent attention pattern collapse while maintaining object detection (POPE stable at 88.5) and gaining domain expertise (+72.1% on PlanBench-V).
- Core assumption: General visual features from pretraining transfer sufficiently to planning maps; domain knowledge is primarily linguistic/procedural.
- Evidence anchors: [abstract] describes "comprehensive training methodology combining Supervised Fine-Tuning with frozen vision encoder parameters"; [section 5.3] documents models without this configuration exhibit collapsed attention patterns.

## Foundational Learning

- Concept: Vision-Language Model (VLM) alignment via instruction tuning
  - Why needed here: PlanGPT-VL builds on Qwen2-VL-Instruct and requires understanding how visual features map to language outputs through supervised fine-tuning.
  - Quick check question: Can you explain how a frozen vision encoder's embeddings flow through a projector to the language model's embedding space?

- Concept: Hallucination in multimodal models
  - Why needed here: CPT is explicitly designed to mitigate hallucinations common in planning map interpretation.
  - Quick check question: What are three common causes of visual hallucinations in VLMs (e.g., over-reliance on language priors)?

- Concept: Catastrophic forgetting in fine-tuning
  - Why needed here: The paper documents trade-offs between domain specialization and general capabilities (MMMU drops 11.2%).
  - Quick check question: Why does freezing specific layers help mitigate catastrophic forgetting, and what are the trade-offs?

## Architecture Onboarding

- Component map:
  - Vision Encoder (ViT-based, frozen) -> Projector (frozen) -> Language Model (Qwen2-7B-Instruct, fine-tuned) -> CPT Module (inference-time verification)

- Critical path:
  1. Collect planning maps → filter for quality (resolution, information density, LLM-as-judge)
  2. Expert annotation of seed data (~50 maps, 800 examples)
  3. Distributional instruction synthesis → expand to ~10k instruction-response pairs
  4. Apply CPT during data synthesis for hallucination reduction
  5. SFT with frozen vision encoder (3 epochs, lr=2e-5, batch=128)
  6. Evaluate on PlanBench-V + general benchmarks

- Design tradeoffs:
  - Domain performance (+72.1%) vs. general capability preservation (MMMU -11.2%, GQA -10.1%)
  - 7B model efficiency vs. larger teacher model quality (32B teacher outperforms 72B-AWQ)
  - Frozen encoder stability vs. potential visual adaptation gains

- Failure signatures:
  - Attention collapse: If vision encoder is unfrozen, attention maps show diffuse/unfocused patterns
  - Hallucination persistence: Complex multi-scale maps with ambiguous boundaries may still produce errors
  - Language drift: Over-specialization causes non-professional communication patterns

- First 3 experiments:
  1. Replicate ablation: Train with CPT vs. standard CoT data on held-out subset; measure hallucination rate on verification queries.
  2. Test freezing configurations: Compare frozen encoder vs. frozen encoder+projector vs. full fine-tuning on both PlanBench-V and POPE to quantify trade-offs.
  3. Data scaling validation: Train on 100, 500, and 1000 images to verify documented threshold effect (performance stabilizes at ~500 images).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the training methodology be modified to preserve general visual reasoning capabilities while achieving domain specialization?
- **Basis in paper:** [explicit] The authors note trade-off where domain fine-tuning causes performance drops on general benchmarks (e.g., MMMU scores falling from 51.6 to 45.8) and explicitly state they "aim to address this limitation through mixed training strategies."
- **Why unresolved:** Current implementation shows domain performance skyrockets (+72.1%) at cost of general visual understanding, limiting model's versatility.
- **What evidence would resolve it:** Experiments demonstrating specific mixed-data ratio or architectural adjustment allows PlanGPT-VL to match/exceed base model's MMMU scores without losing gains on PlanBench-V.

### Open Question 2
- **Question:** To what extent does PlanGPT-VL generalize to non-Chinese planning contexts with different regulatory standards and cartographic symbologies?
- **Basis in paper:** [explicit] Limitations section specifies "current implementation primarily focused on Chinese urban planning contexts" and calls for "expanded cross-cultural planning data" in future work.
- **Why unresolved:** Model trained and evaluated almost exclusively on Chinese maps; unknown if learned features transfer to Western or other international planning standards using different visual languages.
- **What evidence would resolve it:** Evaluation results on newly curated benchmark of international planning maps (e.g., US or EU zoning maps) showing comparable performance to Chinese PlanBench-V results.

### Open Question 3
- **Question:** Can enhanced verification mechanisms be developed to completely eliminate hallucinations in complex, multi-scale planning maps?
- **Basis in paper:** [explicit] Paper states that while Critical Point Thinking reduces errors, "complete elimination of factual errors remains challenging, particularly for complex planning maps with ambiguous visual elements."
- **Why unresolved:** Current "Generate-Verify-Revise" paradigm successfully mitigates but does not eradicate hallucinations, specifically when visual elements are ambiguous or scales shift.
- **What evidence would resolve it:** Ablation study showing hallucination rate of near 0% on most complex map subset using proposed improved verification method compared to current CPT baseline.

## Limitations
- PlanBench-V benchmark is not publicly available, preventing independent validation of claimed +59.2% performance improvement
- Domain specialization causes general capability degradation (MMMU -11.2%, GQA -10.1%) that may vary with different training configurations
- Hallucination reduction effectiveness cannot be independently verified without access to verification methodology and baseline comparisons

## Confidence
- High confidence: Performance improvements on PlanBench-V (+59.2%) and POPE stability (88.5%) are supported by experimental results, though PlanBench-V is not publicly available for verification
- Medium confidence: Domain specialization trade-offs (-11.2% MMMU, -10.1% GQA) are documented with baseline comparisons, but extent may vary with different training configurations
- Medium confidence: Freezing strategy prevents attention collapse and preserves general capabilities, based on documented observations rather than controlled ablation studies
- Low confidence: CPT mechanism's hallucination reduction effectiveness cannot be independently verified without access to verification methodology
- Medium confidence: Distributional instruction synthesis maintains quality through semantic alignment metrics, but practical impact on performance remains untested through ablation

## Next Checks
1. **Hallucination Rate Validation**: Implement CPT framework and measure hallucination rates on held-out set of planning maps, comparing CPT-augmented responses against standard CoT responses using same verification queries
2. **Freezing Configuration Ablation**: Systematically test frozen vision encoder vs. frozen encoder+projector vs. full fine-tuning configurations on both PlanBench-V (when available) and POPE to quantify exact trade-offs
3. **Data Scaling Validation**: Train models on systematically varied dataset sizes (100, 500, 1000 images) to verify documented threshold effect where performance stabilizes at ~500 images