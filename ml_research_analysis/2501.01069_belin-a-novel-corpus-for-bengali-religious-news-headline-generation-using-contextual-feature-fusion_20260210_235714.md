---
ver: rpa2
title: 'BeliN: A Novel Corpus for Bengali Religious News Headline Generation using
  Contextual Feature Fusion'
arxiv_id: '2501.01069'
source_url: https://arxiv.org/abs/2501.01069
tags:
- news
- headline
- generation
- headlines
- religious
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces BeliN, a novel corpus for Bengali religious
  news headline generation, addressing the underexplored domain of automated headline
  generation for low-resource languages. The BeliN corpus includes 2,520 annotated
  religious news articles with additional contextual features such as category, aspect,
  and sentiment.
---

# BeliN: A Novel Corpus for Bengali Religious News Headline Generation using Contextual Feature Fusion

## Quick Facts
- arXiv ID: 2501.01069
- Source URL: https://arxiv.org/abs/2501.01069
- Reference count: 40
- Primary result: MultiGen achieves BLEU 18.61 and ROUGE-L 24.19 using contextual feature fusion for Bengali religious news headline generation

## Executive Summary
This study introduces BeliN, a novel corpus for Bengali religious news headline generation, addressing the underexplored domain of automated headline generation for low-resource languages. The BeliN corpus includes 2,520 annotated religious news articles with additional contextual features such as category, aspect, and sentiment. To leverage this enriched data, the MultiGen approach integrates these features alongside news content using transformer-based pre-trained models like BanglaT5, mT5, mBART, and mT0. Experimental results demonstrate that MultiGen outperforms the baseline content-only approach, achieving BLEU scores of 18.61 and ROUGE-L scores of 24.19, compared to 16.08 and 23.08, respectively. The findings highlight the importance of incorporating contextual information in headline generation for low-resource languages and offer practical insights for advancing text summarization systems in underrepresented languages.

## Method Summary
The MultiGen approach fuses article content with contextual features (category, aspect, sentiment) by concatenating them into a single input sequence separated by [SEP] tokens. This fused input is processed by transformer-based encoder-decoder models (BanglaT5, mT5, mBART, mT0) that have been fine-tuned on the BeliN corpus. The model generates headlines conditioned on both the article content and the explicit contextual information. The input sequence format is: [Article] [SEP] [Category] [SEP] [Aspect] [SEP] [Sentiment], with preprocessing including BUET normalization, noise removal, and prefix addition. The models are fine-tuned using standard transformer training procedures with hyperparameters optimized for BanglaT5.

## Key Results
- MultiGen achieves BLEU score of 18.61 and ROUGE-L score of 24.19
- Baseline content-only approach achieves BLEU 16.08 and ROUGE-L 23.08
- BanglaT5 outperforms multilingual models (mT5, mBART, mT0) on this task
- Contextual feature fusion provides meaningful performance gains over content-only generation

## Why This Works (Mechanism)

### Mechanism 1: Contextual Feature Fusion as Auxiliary Guidance
- Claim: Concatenating explicit contextual features (category, aspect, sentiment) with article content improves headline relevance and semantic alignment.
- Mechanism: The fusion strategy provides structured, high-level semantic signals alongside raw article text, conditioning the transformer's encoder to prioritize content consistent with these signals.
- Core assumption: Manually annotated features provide information not easily extracted from article text alone.
- Evidence anchors: [abstract] states fusion captures "critical contextual information often overlooked by traditional methods."

### Mechanism 2: Transformer Encoder-Decoder with In-Context Conditioning
- Claim: Standard transformer encoder-decoder can effectively use fused context for abstractive headline generation.
- Mechanism: The encoder processes fused input sequence, creating hidden states that entangle content and context, which the decoder uses via cross-attention.
- Core assumption: Pre-trained transformers have sufficient capacity to represent this fusion meaningfully.
- Evidence anchors: [section] details p_dec(H|Z) = p_dec(H|f_enc(I)), showing headline generation is conditioned on fused input.

### Mechanism 3: Language-Specific vs. Multilingual Pre-training Efficacy
- Claim: BanglaT5 outperforms multilingual models due to stronger prior for Bengali linguistic specifics.
- Mechanism: BanglaT5, pre-trained on large Bengali corpus, better captures Bengali grammar, vocabulary, and semantic nuances.
- Core assumption: Religious news domain in Bengali has linguistic specificities better captured by monolingual Bengali model.
- Evidence anchors: [section] Table 10 shows BanglaT5 achieves highest BLEU (18.61) and ROUGE-L (24.19).

## Foundational Learning

- **Abstractive vs. Extractive Summarization**
  - Why needed: Paper frames headline generation as abstractive summarization requiring rephrasing, not copying.
  - Quick check: Can you explain why an extractive approach would likely fail to generate a compelling, context-aware headline from BeliN corpus?

- **Transformer Encoder-Decoder Architecture**
  - Why needed: MultiGen is built on this architecture; understanding encoder/decoder roles is essential.
  - Quick check: Describe how the decoder in T5 architecture uses encoder output during headline generation.

- **Input Fusion and Conditioning**
  - Why needed: This is the core innovation; understanding how to format and concatenate multiple information types is critical.
  - Quick check: What is the specific format of input sequence I used by MultiGen to combine article with contextual features?

## Architecture Onboarding

- **Component map**: Preprocessing Module -> MultiGen Input Constructor -> Transformer Encoder-Decoder -> Trainer/Evaluator
- **Critical path**: Data -> Preprocessing -> Input Fusion -> Tokenizer -> Transformer Model -> Detokenizer -> Generated Headline
- **Design tradeoffs**:
  - Manual Annotation vs. Automatic Feature Extraction: Ensures quality but limits scalability vs. needing separate annotation pipeline
  - Language-Specific vs. Multilingual Model: BanglaT5 offers peak performance but limits transferability vs. mT5/mBART
- **Failure signatures**:
  - Low BLEU/ROUGE scores: Likely poor preprocessing, incorrect tokenization, or insufficient training data
  - Incoherent headlines: Can result from poor fusion, broken attention, or noisy annotations
  - Model hallucinates facts: Common in abstractive summarization; may be exacerbated by conflicting context features
- **First 3 experiments**:
  1. Reproduce Baseline: Train BanglaT5 on BeliN using only article content to establish baseline score
  2. Ablate Contextual Features: Add one contextual feature at a time to measure individual contribution
  3. Compare Pre-trained Models: Fine-tune mT5 using full MultiGen fusion and compare against BanglaT5

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can leveraging modern LLMs enhance real-time and multilingual headline generation performance compared to transformer-based models?
- Basis: [explicit] Authors state future work could involve "leveraging LLMs for real-time and multilingual headline generation."
- Why unresolved: Current study restricted evaluation to transformer-based pre-trained models.
- What evidence would resolve it: Comparative benchmarks of LLMs against MultiGen approach on BeliN corpus.

### Open Question 2
- Question: Can innovative data augmentation techniques compensate for scarcity of annotated Bengali datasets and enable fine-tuning of larger generative models?
- Basis: [explicit] Section 6.3 notes "innovative data augmentation techniques" as method to address data scarcity and hardware constraints.
- Why unresolved: Study relied on static dataset of 2,520 articles; hardware limitations restricted fine-tuning larger models.
- What evidence would resolve it: Performance improvements by large-scale models trained on augmented BeliN corpus.

### Open Question 3
- Question: What specific preprocessing or architectural refinements are required to mitigate inaccuracies caused by complex Bengali morphology and syntax?
- Basis: [explicit] Section 6.3 identifies "complexity of Bengali morphology and syntax" as challenge and suggests "enhancing preprocessing techniques."
- Why unresolved: Current methodology occasionally resulted in inaccuracies due to these linguistic complexities.
- What evidence would resolve it: Comparative error analysis showing reduced morphological errors with advanced preprocessing.

### Open Question 4
- Question: Is MultiGen feature fusion approach effective across diverse news domains beyond religious texts?
- Basis: [explicit] Section 6.3 suggests "expanding the dataset to include a wider variety of domains" to enhance models.
- Why unresolved: BeliN corpus and MultiGen experiments restricted exclusively to religious news domain.
- What evidence would resolve it: Evaluation of MultiGen architecture on multi-domain Bengali news dataset.

## Limitations
- Relies on manually annotated dataset (BeliN) introducing scalability constraints
- 2,520 sample size may not capture full diversity of Bengali religious news discourse
- No direct comparison with automatic feature extraction methods leaves questions about long-term viability
- Performance may not generalize to different religious domains or news genres

## Confidence

- **High Confidence (9/10)**: Empirical performance improvement of MultiGen over baseline is well-supported by reported metrics (BLEU: 18.61 vs 16.08, ROUGE-L: 24.19 vs 23.08)
- **Medium Confidence (7/10)**: Superiority of BanglaT5 over multilingual models demonstrated, but confidence intervals not provided
- **Low Confidence (5/10)**: Claim that manual features provide information "not easily or reliably extracted" lacks empirical validation through ablation studies

## Next Checks
1. **Ablation Study on Feature Sources**: Compare MultiGen's performance using manually annotated features versus features automatically extracted by trained classifiers to validate necessity of manual annotation.

2. **Cross-Domain Generalization Test**: Evaluate MultiGen on holdout set of Bengali news articles from different religious traditions or secular categories to assess generalization beyond BeliN's specific religious domain.

3. **Long-form Content Evaluation**: Test MultiGen on articles exceeding 512 tokens to determine performance degradation and whether alternative fusion strategies might better preserve context in truncated scenarios.