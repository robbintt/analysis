---
ver: rpa2
title: 'CLUES: Collaborative High-Quality Data Selection for LLMs via Training Dynamics'
arxiv_id: '2507.03004'
source_url: https://arxiv.org/abs/2507.03004
tags:
- data
- training
- quality
- merging
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CLUES, a method for high-quality data selection
  in collaborative LLM training settings where data silos prevent direct sharing.
  The core idea is to use training dynamics to measure data influence on an anchor
  dataset, identifying high-quality data based on similarity in training trajectories.
---

# CLUES: Collaborative High-Quality Data Selection for LLMs via Training Dynamics

## Quick Facts
- arXiv ID: 2507.03004
- Source URL: https://arxiv.org/abs/2507.03004
- Reference count: 40
- Primary result: CLUES achieves up to 67.3% improvement and over 96% of theoretical upper bound performance in collaborative LLM training across medical, multilingual, and financial QA tasks

## Executive Summary
CLUES introduces a method for high-quality data selection in collaborative LLM training settings where data silos prevent direct sharing. The approach uses training dynamics to measure data influence on an anchor dataset, identifying high-quality data based on similarity in training trajectories. The method computes per-sample gradients and uses their accumulated inner products as a quality score, establishing a global threshold from anchor data. Experiments show CLUES outperforms existing methods across medical, multilingual, and financial QA tasks, achieving up to 67.3% improvement and over 96% of theoretical upper bound performance in federated settings.

## Method Summary
CLUES implements a two-phase pipeline for collaborative LLM training with data silos. First, clients compute per-sample quality scores via accumulated gradient inner products with validation set using AdamW's preconditioned gradient formula, saving checkpoints during initial mixed-quality training. The server computes scores for 10 anchor samples and sets a global threshold as their average, broadcasting it to clients. Clients filter samples where scores exceed the threshold, then fine-tune locally with LoRA and send adapters to server for TIES merging or federated averaging. The method specifically uses first-layer gradients to avoid cancellation effects observed in later layers.

## Key Results
- Achieves up to 67.3% improvement over baselines across medical, multilingual, and financial QA tasks
- Reaches over 96% of theoretical upper bound performance in federated settings
- Outperforms existing methods (CLAP, LCS, LEEP) with up to 14.1% improvement in knowledge retention

## Why This Works (Mechanism)
CLUES leverages the observation that high-quality data produces similar training dynamics (gradient patterns) to an anchor dataset representing desired model behavior. By computing accumulated inner products of preconditioned gradients between validation samples and all training samples, the method captures how similarly each sample influences the model's learning trajectory. Samples with higher accumulated inner products are more likely to be high-quality because they induce training dynamics similar to the anchor data. The global threshold approach ensures consistent quality standards across heterogeneous client datasets.

## Foundational Learning
- **Training dynamics**: The evolution of model parameters and gradients during training - needed to measure data influence through trajectory similarity; quick check: plot gradient norms over training steps
- **AdamW preconditioned gradients**: Gradient updates adjusted by moving averages of gradients and squared gradients - needed for stable quality scoring; quick check: verify optimizer state matches AdamW equations
- **TIES merging**: Technique for combining LoRA adapters that trims redundant parameters and resolves sign conflicts - needed for effective federated aggregation; quick check: confirm merged parameters have matching signs
- **Data pollution**: Intentional corruption of datasets through cutting, deletion, or substitution - needed to simulate real-world data quality issues; quick check: verify polluted samples contain expected corruptions
- **Federated averaging**: Aggregating locally trained models by weighted averaging - needed for collaborative training without data sharing; quick check: ensure client model weights are properly weighted by dataset size

## Architecture Onboarding

**Component Map:**
Data silos -> Client gradient computation -> Server threshold calculation -> Client filtering -> Local LoRA fine-tuning -> Server aggregation (TIES/FA) -> Merged model

**Critical Path:**
Anchor data computation -> Global threshold broadcast -> Client filtering -> Local training -> Model aggregation

**Design Tradeoffs:**
- First-layer gradient computation vs. deeper layers (avoids cancellation but may miss context)
- 10 anchor samples vs. more samples (efficiency vs. robustness)
- LoRA rank 16 vs. higher ranks (efficiency vs. expressiveness)
- TIES merging vs. linear merging (better performance but more complex)

**Failure Signatures:**
- Using last-layer gradients instead of first layer causes severe cancellation effects
- Local ratio-based selection instead of global threshold drops accuracy from 97.91% to 75%
- Linear merging instead of TIES shows significant underperformance

**First Experiments:**
1. Verify gradient accumulation matches AdamW preconditioned gradient formula
2. Test global threshold selection with varying anchor sample sizes
3. Compare first-layer vs. last-layer gradient scoring on a small dataset

## Open Questions the Paper Calls Out
**Open Question 1:** How can the CLUES framework be adapted to support heterogeneous client environments where local models have different architectures or LoRA ranks? The current method relies on shared model architectures and suggests extending it for different low ranks, but the aggregation mechanism requires consistent parameter dimensions.

**Open Question 2:** To what extent does domain shift or noise in the small public anchor dataset impact the accuracy of the global threshold for data selection? The methodology uses only 10 anchor samples, and the paper doesn't analyze robustness when anchor data is misaligned with private data distribution or contains noise.

**Open Question 3:** Is the selection of the model's first layer for gradient tracing universally optimal, or does it vary depending on specific architectural features of the LLM? The authors select first layer empirically to minimize cancellation effects, but this choice may not be optimal for all architectures or skip-connection configurations.

## Limitations
- Relies on shared model architectures, limiting applicability to heterogeneous client environments
- Uses only 10 anchor samples for threshold setting without justification for sample size adequacy
- Unspecified data pollution implementations and checkpoint frequencies affect reproducibility
- Computational overhead of gradient storage and inner product computation not fully characterized for larger models

## Confidence
**High Confidence:** The core theoretical framework connecting training dynamics to data quality through gradient similarity is sound and well-motivated.

**Medium Confidence:** Empirical improvements are promising but require independent validation due to limited anchor samples and unspecified pollution implementations.

**Low Confidence:** Scalability claims beyond 7B parameter models are not validated, and computational overhead characterization is incomplete.

## Next Checks
1. **Anchor Sample Sensitivity**: Reproduce experiments with varying anchor sample sizes (5, 10, 20, 50) to determine minimum effective threshold and assess sensitivity to anchor data quantity.

2. **Pollution Implementation Fidelity**: Implement and test exact pollution mechanisms (cutting, deletion, substitution) to verify reported performance degradation matches contamination scenarios.

3. **Checkpoint Frequency Impact**: Systematically vary checkpoint frequency during initial training (every epoch, every 100 steps, every 500 steps) to measure how frequency affects score stability and selection quality.