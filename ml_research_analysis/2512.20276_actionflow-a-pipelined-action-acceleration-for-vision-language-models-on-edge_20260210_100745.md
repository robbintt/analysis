---
ver: rpa2
title: 'ActionFlow: A Pipelined Action Acceleration for Vision Language Models on
  Edge'
arxiv_id: '2512.20276'
source_url: https://arxiv.org/abs/2512.20276
tags:
- actionflow
- inference
- action
- arxiv
- decode
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ActionFlow introduces a system-level optimization framework for
  Vision-Language-Action (VLA) models deployed on edge devices. It addresses the bottleneck
  of autoregressive decoding by implementing a Cross-Request Pipelining strategy that
  overlaps compute-intensive prefill phases with memory-bound decode phases across
  sequential inference requests.
---

# ActionFlow: A Pipelined Action Acceleration for Vision Language Models on Edge

## Quick Facts
- arXiv ID: 2512.20276
- Source URL: https://arxiv.org/abs/2512.20276
- Reference count: 40
- Primary result: 2.55x FPS improvement on OpenVLA-7B for edge robotic inference

## Executive Summary
ActionFlow addresses the performance bottleneck of autoregressive decoding in Vision-Language-Action (VLA) models deployed on edge devices. The framework implements Cross-Request Pipelining, which overlaps compute-intensive prefill phases with memory-bound decode phases across sequential inference requests. By employing fused operators and a unified KV ring buffer, ActionFlow eliminates fragmented memory operations and synchronization overhead. The approach achieves significant FPS improvements on both Jetson AGX Orin and RTX 5090 platforms without requiring model retraining or sacrificing task success rates.

## Method Summary
ActionFlow introduces a system-level optimization framework specifically designed for VLA models on edge devices. The core innovation is Cross-Request Pipelining, which exploits the complementary resource requirements of prefill and decode phases by overlapping their execution across sequential inference requests. The framework implements operator fusion to reduce memory fragmentation and synchronization overhead, and introduces a unified KV ring buffer to efficiently manage attention states across requests. These optimizations work together to maximize GPU utilization while maintaining the autoregressive nature required for action generation in robotic applications.

## Key Results
- Achieves 2.55x FPS improvement on Jetson AGX Orin (3.20 vs 1.25 FPS)
- Achieves 2.55x FPS improvement on RTX 5090 (19.45 vs 7.62 FPS)
- Maintains task success rate without requiring model retraining

## Why This Works (Mechanism)
The effectiveness of ActionFlow stems from exploiting the complementary resource requirements of different inference phases. During autoregressive decoding, the prefill phase is compute-intensive while the decode phase is memory-bound. By pipelining these phases across multiple sequential requests, ActionFlow keeps the GPU continuously busy rather than experiencing idle periods. The operator fusion eliminates redundant memory operations and synchronization points that typically occur when processing multiple small operators separately. The unified KV ring buffer provides efficient reuse of attention states, reducing memory bandwidth requirements and enabling smoother pipelined execution.

## Foundational Learning

**Vision-Language-Action Models**: Neural architectures that process visual inputs, understand language commands, and generate physical actions. Why needed: Form the basis of robotic decision-making systems. Quick check: Verify the model can process image+text input and output action sequences.

**Autoregressive Decoding**: Sequential generation where each token prediction depends on previously generated tokens. Why needed: Essential for maintaining coherent action sequences in robotics. Quick check: Confirm generation proceeds token-by-token with dependency on prior outputs.

**Cross-Request Pipelining**: Overlapping execution of different phases across multiple sequential requests. Why needed: Exploits complementary resource usage patterns to improve throughput. Quick check: Measure overlap between prefill of request N and decode of request N-1.

**KV Cache Management**: Storage and reuse of key-value attention states during generation. Why needed: Reduces redundant computation across decoding steps. Quick check: Verify cache hit rates during decoding phases.

## Architecture Onboarding

**Component Map**: Vision Encoder -> Language Model -> Action Decoder -> Operator Fusion Layer -> KV Ring Buffer Manager -> GPU Pipeline Scheduler

**Critical Path**: Image preprocessing → Vision encoder prefill → Cross-attention decode → Action sequence generation → Execution

**Design Tradeoffs**: The framework prioritizes throughput over single-request latency, which is acceptable for robotic applications where action sequences are generated in batches. Memory overhead from the unified ring buffer is traded against reduced memory bandwidth pressure and better GPU utilization.

**Failure Signatures**: Stalls occur when request patterns deviate from sequential execution, when token patterns are highly variable across requests, or when GPU memory becomes a bottleneck due to insufficient unified buffer sizing.

**3 First Experiments**:
1. Measure prefill vs decode phase durations individually to verify complementary resource requirements
2. Test operator fusion impact by comparing fused vs unfused execution times for representative workloads
3. Validate KV ring buffer effectiveness by measuring memory bandwidth usage with and without unified buffer

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to OpenVLA-7B model and robotic manipulation tasks only
- Performance metrics focus on FPS without reporting latency distributions or tail latency
- Assumes homogeneous token patterns across requests, which may not hold in diverse scenarios

## Confidence

**FPS improvement claims**: High - Multiple runs across two hardware platforms with consistent 2.5x gains
**Task success rate preservation**: Medium - Single task type evaluated, no stress testing under varying conditions
**Cross-request pipelining generality**: Low - Only tested on sequential action generation scenarios

## Next Checks

1. Evaluate tail latency percentiles (95th, 99th) to ensure real-time robotic control guarantees under pipelined execution
2. Test Cross-Request Pipelining with non-sequential task patterns where intermediate states affect subsequent requests
3. Benchmark against alternative VLA architectures beyond OpenVLA to assess framework generality