---
ver: rpa2
title: 'Game-TARS: Pretrained Foundation Models for Scalable Generalist Multimodal
  Game Agents'
arxiv_id: '2510.23691'
source_url: https://arxiv.org/abs/2510.23691
tags:
- action
- agent
- arxiv
- data
- game
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Game-TARS introduces a unified, scalable action space grounded
  in native keyboard-mouse inputs, enabling large-scale continual pre-training across
  diverse domains including games, OS, and web environments. Key innovations include
  a decaying continual loss to reduce causal confusion and a Sparse-Thinking strategy
  that balances reasoning depth with inference cost.
---

# Game-TARS: Pretrained Foundation Models for Scalable Generalist Multimodal Game Agents
## Quick Facts
- arXiv ID: 2510.23691
- Source URL: https://arxiv.org/abs/2510.23691
- Reference count: 40
- Key outcome: Game-TARS achieves ~2× the success rate of prior state-of-the-art models on Minecraft and matches human-level generalization in unseen web 3D games

## Executive Summary
Game-TARS introduces a unified, scalable action space grounded in native keyboard-mouse inputs, enabling large-scale continual pre-training across diverse domains including games, OS, and web environments. Key innovations include a decaying continual loss to reduce causal confusion and a Sparse-Thinking strategy that balances reasoning depth with inference cost. Trained on over 500B tokens with multimodal data, Game-TARS achieves significant performance improvements over prior models across multiple game domains, demonstrating a promising path toward generalist computer-use agents.

## Method Summary
Game-TARS is built on a pretrained foundation model architecture that incorporates a unified action space representation using native keyboard-mouse inputs. The model employs continual pre-training with a decaying loss function to mitigate causal confusion between tasks, and introduces a Sparse-Thinking strategy to optimize the trade-off between reasoning depth and computational efficiency. The training corpus consists of over 500 billion tokens from diverse multimodal sources including games, operating systems, and web environments. The architecture is designed for scalability, allowing performance improvements as the action space and training data expand across different game domains.

## Key Results
- Achieves approximately 2× the success rate of prior state-of-the-art models on Minecraft benchmarks
- Matches human-level generalization performance in unseen web 3D games
- Outperforms GPT-5, Gemini-2.5-Pro, and Claude-4-Sonnet on FPS benchmarks

## Why This Works (Mechanism)
The unified action space grounded in native keyboard-mouse inputs provides a consistent representation framework across diverse environments, eliminating the need for environment-specific action abstractions. The decaying continual loss prevents the model from conflating causal relationships learned from different domains during pre-training, maintaining task-specific reasoning capabilities. The Sparse-Thinking strategy dynamically allocates computational resources based on task complexity, achieving efficiency gains without sacrificing performance on complex reasoning tasks. The large-scale multimodal training corpus (500B+ tokens) provides sufficient diversity for the model to develop generalizable skills across games, OS interfaces, and web environments.

## Foundational Learning
- **Continual Pre-training**: Why needed - Enables knowledge transfer across domains without catastrophic forgetting; Quick check - Monitor performance stability across sequential task exposure
- **Multimodal Integration**: Why needed - Games and computer interfaces require processing visual, textual, and spatial information simultaneously; Quick check - Validate performance on tasks requiring cross-modal reasoning
- **Action Space Design**: Why needed - A unified representation enables scalability across different environments; Quick check - Test performance consistency across environments with varying input complexity

## Architecture Onboarding
**Component Map**: Multimodal Encoder -> Action Space Decoder -> Sparse-Thinking Module -> Continual Loss Function
**Critical Path**: Input Processing (vision/text) → Action Space Mapping → Reasoning (Sparse-Thinking) → Output Action Selection
**Design Tradeoffs**: The unified keyboard-mouse action space sacrifices some environment-specific optimizations for scalability and generalization across domains. The Sparse-Thinking strategy trades deterministic reasoning depth for computational efficiency.
**Failure Signatures**: Performance degradation occurs when encountering environments with significantly different input modalities than training data; the model may exhibit causal confusion when domains share similar visual patterns but require different action sequences.
**First Experiments**: 1) Baseline performance comparison across single-game environments; 2) Cross-domain generalization test on unseen game types; 3) Computational overhead measurement of Sparse-Thinking vs. full reasoning

## Open Questions the Paper Calls Out
None

## Limitations
- The paper does not adequately address potential overfitting to the specific action space design
- Generalizability to truly novel environments beyond tested domains remains uncertain
- Computational costs associated with Sparse-Thinking strategy and decaying continual loss are not fully characterized

## Confidence
- High confidence in technical implementation and benchmark results
- Medium confidence in claimed generalization to unseen web 3D games
- Medium confidence in scalability claims without detailed computational overhead analysis

## Next Checks
1. Conduct ablation studies to isolate the contribution of each innovation (decaying continual loss, Sparse-Thinking, unified action space) to overall performance
2. Test the model on a broader range of novel environments outside the gaming domain to assess true generalist capabilities
3. Perform detailed analysis of inference time and computational overhead for the Sparse-Thinking strategy compared to standard reasoning approaches