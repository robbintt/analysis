---
ver: rpa2
title: '"Wait, did you mean the doctor?": Collecting a Dialogue Corpus for Topical
  Analysis'
arxiv_id: '2501.07947'
source_url: https://arxiv.org/abs/2501.07947
tags:
- topic
- dialogue
- topics
- participants
- conversation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study aimed to create a dialogue corpus for analyzing topical
  organization in conversation by developing a messaging tool that could manipulate
  message content during exchanges. The tool, built on Element/Matrix, allowed for
  controlled modifications of participants' messages while maintaining natural conversation
  flow.
---

# "Wait, did you mean the doctor?": Collecting a Dialogue Corpus for Topical Analysis

## Quick Facts
- arXiv ID: 2501.07947
- Source URL: https://arxiv.org/abs/2501.07947
- Reference count: 5
- Primary result: Novel tool for manipulating dialogue messages during conversation to study topical organization

## Executive Summary
This study presents a novel methodology for collecting dialogue corpora focused on topical organization in conversation. The researchers developed a messaging tool that allows controlled modifications of participants' messages during exchanges while maintaining natural conversation flow. The approach enables researchers to study how participants negotiate and establish shared understanding of topics when semantic elements are manipulated mid-conversation.

The tool, built on Element/Matrix, was tested in a pilot study with 12 participants in 18 dyads. Various message modification strategies were evaluated, with the most promising approach involving switching task-relevant terms (e.g., "doctor" to "pilot"). This strategy successfully created situations requiring explicit topic negotiation between speakers, making it particularly valuable for studying how conversational participants establish and maintain topical coherence.

## Method Summary
The methodology involves a custom messaging tool built on Element/Matrix that allows message manipulation during ongoing conversations. The tool uses separate bot-mediated chat rooms to enable flexible modifications while storing all data in SQLite databases. Participants engage in task-oriented conversations where certain words or concepts can be modified mid-conversation. The pilot study tested different modification strategies including removing task-related words or substituting them with alternatives. The most effective approach involved switching task-relevant terms to force participants to negotiate meaning and reach common understanding. The researchers plan to collect approximately 60 conversations across multiple languages using this methodology.

## Key Results
- The messaging tool successfully maintained natural conversation flow while enabling controlled message modifications
- Term-switching modifications (e.g., "doctor" to "pilot") effectively created topical negotiation scenarios
- Participants successfully reached common understanding despite semantic modifications
- The approach successfully created varying interpretations of topics among speakers

## Why This Works (Mechanism)
The tool works by intercepting messages in real-time and applying predetermined modifications before they reach the recipient. This creates a controlled environment where semantic shifts can be introduced without participants being aware of the manipulation. The use of separate bot-mediated chat rooms allows for flexible modification strategies while maintaining the appearance of a normal conversation. The SQLite database storage ensures comprehensive data collection for analysis. The approach leverages the natural human tendency to seek clarification and negotiate meaning when faced with semantic inconsistencies.

## Foundational Learning
1. **Semantic drift** - Why needed: Understanding how meaning changes during conversation; Quick check: Track topic drift using semantic similarity metrics
2. **Topical coherence** - Why needed: Core concept being studied; Quick check: Measure coherence before/after modifications
3. **Conversational repair** - Why needed: How participants resolve misunderstandings; Quick check: Count repair sequences per conversation
4. **Message interception** - Why needed: Technical foundation of the tool; Quick check: Verify all messages are captured
5. **Matrix/Element API** - Why needed: Technical infrastructure; Quick check: Test API rate limits and reliability
6. **SQLite database design** - Why needed: Data storage and retrieval; Quick check: Query time performance with increasing data

## Architecture Onboarding

Component map: Participant app -> Matrix server -> Bot mediator -> SQLite database -> Analysis tools

Critical path: Message sent by participant → Bot intercepts and modifies → Modified message delivered → Response generated → Cycle continues

Design tradeoffs:
- Real-time modification vs. conversation naturalness
- Complex modifications vs. participant confusion
- Technical complexity vs. ease of deployment
- Data richness vs. privacy concerns

Failure signatures:
- Message delivery failures (network/API issues)
- Incorrect modifications (bot logic errors)
- Participant confusion (excessive modifications)
- Data loss (database failures)

3 first experiments:
1. Test basic message interception and delivery
2. Verify modification logic with simple word substitutions
3. Validate conversation flow with single modification type

## Open Questions the Paper Calls Out
None

## Limitations
- Small pilot sample (12 participants, 18 dyads) limits generalizability
- Reliance on single messaging platform may not capture all conversational dynamics
- Term-switching modifications may introduce artificial conversational elements
- Focus on task-oriented conversations may not generalize to other conversation types

## Confidence
- High Confidence: Technical implementation and message modification capability
- Medium Confidence: Effectiveness of term-switching for creating topical negotiation
- Low Confidence: Naturalness of modified conversations and representativeness

## Next Checks
1. Conduct larger-scale study (60+ conversations) across multiple languages to assess generalizability
2. Compare topical negotiation patterns in modified vs. natural conversations on similar topics
3. Test alternative modification strategies beyond term-switching to evaluate effectiveness