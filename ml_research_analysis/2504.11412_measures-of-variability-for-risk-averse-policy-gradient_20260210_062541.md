---
ver: rpa2
title: Measures of Variability for Risk-averse Policy Gradient
arxiv_id: '2504.11412'
source_url: https://arxiv.org/abs/2504.11412
tags:
- deviation
- policy
- gradient
- variance
- cvar
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper systematically studies nine variability measures in
  risk-averse reinforcement learning (RARL), including four previously unexplored
  metrics. The authors derive policy gradient formulas for all metrics and implement
  them in both REINFORCE and PPO frameworks.
---

# Measures of Variability for Risk-averse Policy Gradient

## Quick Facts
- arXiv ID: 2504.11412
- Source URL: https://arxiv.org/abs/2504.11412
- Reference count: 8
- Primary result: Systematic empirical study comparing nine variability measures in RARL, identifying CVaR Deviation and Gini Deviation as most consistently stable and effective

## Executive Summary
This paper provides the first comprehensive empirical study of nine variability measures in risk-averse reinforcement learning (RARL). The authors systematically derive policy gradient formulas for all metrics and implement them in both REINFORCE and PPO frameworks. Through extensive experiments across multiple environments with different noise distributions, the study reveals that variance-based metrics lead to unstable policy updates due to their quadratic terms, while CVaR Deviation and Gini Deviation show consistent performance across different domains, effectively learning risk-averse policies while achieving high returns.

## Method Summary
The method optimizes a mean-variability objective where J(θ) = E[G₀] - λ·D[G₀], combining expected return with a variability penalty. Policy gradients are derived for nine variability measures: Variance, Gini Deviation, Mean Deviation, Mean-Median Deviation, Standard Deviation, Inter-Quantile Range, CVaR Deviation, Semi Variance, and Semi Standard Deviation. The implementation uses REINFORCE with baseline for discrete environments and PPO-clip for continuous control. For biased metrics (IQR, CVaR Deviation, Mean-Median Deviation), empirical quantiles are used with KDE for density estimation. Double sampling is required for unbiased estimation of metrics involving E[X]∇E[X] terms.

## Key Results
- Variance and Semi Variance exhibit significantly higher gradient variance, leading to unstable training and poor performance
- CVaR Deviation and Gini Deviation consistently deliver robust and reliable performance across different domains and noise distributions
- Mean Deviation and Semi Standard Deviation achieve competitive performance with lower gradient variance than variance-based metrics
- IQR is sensitive to λ and requires careful hyperparameter tuning, while MMD fails in several continuous control environments

## Why This Works (Mechanism)

### Mechanism 1
Variance-based metrics (Variance, Semi Variance) produce unstable policy updates due to their quadratic formulation. The policy gradient contains E[τ][R²_τ ω_τ(θ)], where R²_τ scales quadratically with reward magnitude, amplifying gradient variance during training. This instability correlates with convergence difficulty.

### Mechanism 2
CVaR Deviation and Gini Deviation achieve consistent performance across domains by using L1-based or quantile-based formulations that avoid quadratic scaling. Gini Deviation uses E[|X - X*|] instead of E[(X - X*)²], while CVaR Deviation uses conditional expectations on tail quantiles. Both formulations exhibit lower gradient variance across varying reward scales.

### Mechanism 3
Mean Deviation and Semi Standard Deviation achieve competitive performance with lower gradient variance than variance-based metrics. Mean Deviation uses L1 distance from the mean (E[|X - E[X]|]), while Semi STD scales variance gradients by 1/(2√SV[X]), reducing gradient magnitude and improving stability.

## Foundational Learning

- **Policy Gradient Methods (REINFORCE, PPO)**: Core optimization framework requiring understanding of ∇_θ log π_θ(a|s) and baseline subtraction. Quick check: Given trajectory returns {R_τ}, can you write the REINFORCE gradient estimator with baseline?

- **Measures of Variability vs Risk Measures**: These are distinct classes with different axioms. Variability measures require location invariance (ν(X - c) = ν(X)), while risk measures require translation invariance (ρ(X - c) = ρ(X) - c). A function cannot satisfy both. Quick check: Why is Variance not a coherent measure of variability?

- **Double Sampling in Gradient Estimation**: Required for metrics like Variance and Mean Deviation to compute E[X]∇E[X] without bias. Quick check: Which of the nine metrics require double sampling vs. single-sample estimation?

## Architecture Onboarding

- Component map: Mean-Variability Objective: J(θ) = E[G₀] - λ·D[G₀] -> E[G₀] Estimator: REINFORCE or PPO-clip -> D[G₀] Estimator: Variability metric gradient (metric-specific) -> Baseline: V_φ(s) for variance reduction -> Value Update: TD-style or Monte Carlo

- Critical path:
  1. Sample n trajectories under π_θ
  2. Compute trajectory returns {R_τᵢ} and log-probabilities
  3. For each metric, compute variability gradient per equations in Section 3
  4. Combine: θ ← θ + α(mean_grad - λ·variability_grad)
  5. Update value function baseline

- Design tradeoffs:
  - **CVaR/Gini Deviation**: Most stable, consistent across domains → choose for production
  - **Mean Deviation/Semi STD**: Competitive, lower gradient variance → good alternatives
  - **Variance/Semi Variance**: High gradient variance, hyperparameter-sensitive → avoid unless variance is specifically required
  - **IQR**: Sensitive to λ, requires KDE for density estimation → use only if tail-only risk is desired
  - **MMD**: Fails in LunarLander/InvertedPendulum → not recommended

- Failure signatures:
  - Exploding gradients → likely using Variance/Semi Variance with large rewards
  - No risk-averse behavior → λ too small or metric not penalizing correct tail
  - Inconsistent results across seeds → IQR with insufficient samples for quantile estimation
  - Policy collapse → double sampling not implemented correctly

- First 3 experiments:
  1. **Tabular validation on Maze domain**: Implement GD and CVaR Deviation with Gaussian noise; verify risk-averse path selection. Confirm gradient variance is lower than Variance.
  2. **Hyperparameter sensitivity sweep**: Fix learning rate, vary λ ∈ {0.1, ..., 1.5} for CVaR Deviation and Gini Deviation. Measure final return and risk-averse rate. CVaR Deviation should show wider stable range.
  3. **Continuous control transfer**: Train Semi STD and Mean Deviation on HalfCheetah with X-position noise. Compare risk-averse rate and return vs. PPO baseline.

## Open Questions the Paper Calls Out

### Open Question 1
Can unbiased policy gradient estimators be derived for Mean-Median Deviation, Inter-Quantile Range, and CVaR Deviation? The authors plan to derive unbiased estimators for metrics that currently lack them, as current estimators rely on empirical quantiles which introduce bias.

### Open Question 2
Does a generalized theoretical framework exist to prove the convergence of policy gradient methods using the various measures of variability studied? The authors identify a theoretical gap and aim to develop a generalized framework to prove convergence across different metrics.

### Open Question 3
Can the sample efficiency of risk-averse RL be improved by combining risk-neutral and risk-averse approaches through mixture parameterization? The authors suggest this combination might be promising to address the low sample efficiency that limits RARL deployment.

## Limitations

- The stability analysis relies on gradient variance measurements without direct links to convergence rates or sample complexity bounds
- Some metrics (IQR, MMD) show domain-specific failures without systematic diagnosis of failure modes
- Double sampling requirement is mentioned but not quantified in terms of additional sample complexity

## Confidence

- High confidence: CVaR Deviation and Gini Deviation consistently outperform other metrics across domains
- Medium confidence: Variance-based metrics cause instability due to quadratic terms
- Medium confidence: Mean Deviation and Semi Standard Deviation achieve competitive performance with lower gradient variance
- Low confidence: IQR's failure modes are fully understood

## Next Checks

1. Measure and report convergence rates (wall-clock time, iterations to reach target performance) alongside final performance to quantify stability claims about gradient variance
2. Conduct ablation studies on double sampling implementation to quantify the bias-variance tradeoff and sample complexity implications
3. Test the identified stable metrics (CVaR Deviation, Gini Deviation) on additional domains with different reward structures to verify domain transferability claims