---
ver: rpa2
title: A Polynomial-time Algorithm for Online Sparse Linear Regression with Improved
  Regret Bound under Weaker Conditions
arxiv_id: '2510.27177'
source_url: https://arxiv.org/abs/2510.27177
tags:
- lemma
- regret
- algorithm
- bound
- oslr
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the online sparse linear regression (OSLR)
  problem, where the algorithm is restricted to accessing only k out of d attributes
  per instance for prediction, which was proven to be NP-hard. Previous work gave
  polynomial-time algorithms under assumptions like linear independence of features,
  the compatibility condition, or the restricted isometry property.
---

# A Polynomial-time Algorithm for Online Sparse Linear Regression with Improved Regret Bound under Weaker Conditions

## Quick Facts
- arXiv ID: 2510.27177
- Source URL: https://arxiv.org/abs/2510.27177
- Reference count: 40
- Primary result: Polynomial-time algorithm achieving improved regret bounds for online sparse linear regression under compatibility condition

## Executive Summary
This paper addresses the online sparse linear regression (OSLR) problem where algorithms can only access k out of d attributes per instance. The problem was proven NP-hard, with previous polynomial-time solutions requiring strong assumptions like linear independence, compatibility condition, or restricted isometry property. The authors introduce DS-OSLRC, a new algorithm that achieves significantly improved regret bounds under the compatibility condition - a weaker assumption than previous approaches. The algorithm combines the Dantzig Selector with novel techniques including algorithm-dependent sampling, adaptive parameter tuning, and batching online Newton step with support-aware initialization.

## Method Summary
The DS-OSLRC algorithm alternates between exploration rounds (at s² for s=1,...,⌊√T⌋) and exploitation epochs. During exploration, it uses an algorithm-dependent sampling scheme to estimate the covariance matrix, computes unbiased estimators incrementally, and solves a Dantzig Selector linear program with adaptive thresholds. During exploitation, it runs Online Newton Step on the estimated support set with careful initialization that preserves previous computations when support remains stable. The algorithm achieves O(poly(d)) per-round time complexity while maintaining high-probability regret bounds that improve upon previous work in terms of d, T, and minimum coefficient magnitude.

## Key Results
- DS-OSLRC achieves a high-probability regret bound of 4√T + 1024k²d²/(δ⁸ₛh(w*)² ln²dT/δ) + O(1)
- Algorithm's per-round time complexity is O(poly(d)), making OSLR tractable
- Extension to OSLR with additional observations (k₀ extra attributes) improves previous regret bounds
- Improved regret bounds under compatibility condition, which is weaker than previous assumptions

## Why This Works (Mechanism)

### Mechanism 1: Algorithm-Dependent Sampling Scheme
- Claim: Sampling based on the previous estimator reduces variance in covariance matrix estimation compared to uniform sampling.
- Mechanism: At exploration round s, sample one feature from q_s = |ŵ_{s-1}|/‖ŵ_{s-1}‖_1 (where larger estimated coefficients get higher probability), then uniformly sample k-1 additional features without replacement. This approximates the optimal q* = |w*|/‖w*‖_1 which would only sample from true support S.
- Core assumption: ‖ŵ_s - w*‖_1 → 0 in probability as s increases (sequential estimator convergence).
- Break condition: If estimation error ‖Δ_s(S)‖_1 fails to decrease as Õ(√(kd/s)), the sampling probabilities become poorly aligned with true support, increasing variance and degrading regret bounds.

### Mechanism 2: Adaptive Parameter Tuning via Guess-Then-Verification
- Claim: The Dantzig Selector threshold γ_s can be set adaptively using only past observations while maintaining theoretical guarantees.
- Mechanism: The optimal γ_s depends on Σ_{τ=1}^s ‖Δ_{τ-1}(S)‖_1² which requires knowing w*. The algorithm: (1) assumes the ideal convergence rate to estimate these terms, (2) constructs ν_s ≥ √(Σ ‖Δ‖²)/s, (3) proves by induction that ĝ_s ≥ γ_s for all s ≥ 1, ensuring DS(ĝ_s) remains feasible.
- Core assumption: Compatibility condition (δ_S, S, 1) holds for all X_{I_s}, and T > (s_1 + 1)² for sufficient samples.
- Break condition: If ĝ_s < γ_s at any s, the Dantzig Selector becomes infeasible or returns ŵ_s with ‖ŵ_s‖_1 > ‖w*‖_1, breaking the compatibility argument.

### Mechanism 3: Batching ONS with Support-Aware Initialization
- Claim: Decomposing regret into ONS regret plus estimator error enables tighter constant factors and improved T-dependence.
- Mechanism: Within epoch T_s, run ONS on restricted features x_t(S_s) with initialization ŵ_s(S_s). Crucially, when S_s = S_{s-1}, inherit A_{s²} = A_{(s-1)²} and ŵ_{s²+1} = ŵ_{(s-1)²} from the previous epoch. The competitor is chosen as w_s = w*(S_s ∩ S) rather than the obvious ŵ_s(S_s), reducing constant factor by 3k.
- Core assumption: There exists s_2 such that S_s = S for all s > s_2 with high probability; s_2 depends on min_{i∈S} |w*_i|.
- Break condition: If support S_s oscillates frequently, constant re-initialization degrades regret to Õ(T^{2/3}) rather than Õ(√T).

## Foundational Learning

- **Dantzig Selector**: Why needed here: Core estimator used at exploration rounds; requires understanding why it achieves smaller constant factors than LASSO under compatibility condition. Quick check: Can you explain why min ‖w‖_1 subject to ‖X^T(y - Xw)‖_∞ ≤ γ is robust to correlated features compared to LASSO?

- **Compatibility Condition / Restricted Eigenvalues**: Why needed here: Weaker than RIP but sufficient for sparse recovery; the paper's main assumption. You must understand why δ_S²|S|·‖Δ(S)‖_1² ≤ ‖X·Δ‖_2² enables the induction. Quick check: Given a covariance matrix Σ, how would you verify the (δ_S, S, 1)-compatibility condition holds?

- **Martingale Concentration (Bernstein-type Inequalities)**: Why needed here: The sampling scheme creates non-independent observations; Lemma 7 handles random variance bounds. Essential for proving Lemma 13's high-probability feasibility. Quick check: Why does the standard Freedman/Azuma inequality fail when variance v depends on the martingale sequence itself?

## Architecture Onboarding

- Component map: SAMPLING(k, d, ŵ_{s-1}) → B_s → Estimate ẑ_{I_s}Y_{I_s} and H_{I_s} incrementally → Compute ĝ_s → Solve DS(ĝ_s) → ŵ_s, S_s → ONS on x_t(S_s) with initialization

- Critical path:
  1. Initialization: ŵ_0 = (1/d)·1_d, A_1 = ε·I_{k×k}, S_0 arbitrary
  2. Phase transition at s_2: Support recovery S_s = S triggers ONS warm-start benefit
  3. Threshold epochs: s_0 (burn-in), s_1 (error regime change), s_2 (support recovery)

- Design tradeoffs:
  - LP vs. First-order methods: DS requires O(d^{2.5}L) per exploration round; could use LASSO with ISTA for O(d) but larger constants
  - Batching frequency: Current design explores at s = 1, 4, 9, ..., s²; increasing frequency improves estimator quality but raises LP cost
  - Memory vs. computation: H_{I_s} requires O(d²) storage; could recompute online with O(d) if memory-constrained

- Failure signatures:
  - Regret grows as O(T) rather than O(√T): Check if compatibility condition violated (δ_S too small)
  - Support never converges: min_{i∈S} |w*_i| < 1 may be too small relative to noise σ
  - DS infeasibility: ĝ_s underestimated; verify ν_s computation follows Eq. (7) correctly

- First 3 experiments:
  1. Synthetic validation: Generate X with Gaussian entries (satisfies compatibility), k=5, d=100, T=10000. Verify regret scales as √T and support recovery occurs at predicted s_2.
  2. Ablation on sampling: Compare algorithm-dependent sampling vs. uniform sampling. Measure ‖Δ_s(S)‖_1 over time; should see factor improvement in convergence rate.
  3. Robustness to δ_S: Systematically reduce compatibility constant by making features more correlated. Plot regret vs. 1/δ_S^8 to confirm theoretical dependence.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can polynomial-time algorithms for OSLR avoid solving a linear programming problem at each exploration round while maintaining the current regret bounds?
- Basis in paper: Section 5 lists developing "more efficient algorithms... that can avoid solving a linear programming while maintaining the regret bound" as the first future direction.
- Why unresolved: The current DS-OSLRC algorithm relies on the Dantzig Selector, which requires solving a linear program, contributing significantly to the computational complexity (O(LP_d√T)).
- What evidence would resolve it: An algorithm using alternative optimization methods (e.g., online gradient descent) that achieves comparable regret bounds with O(d) per-round complexity.

### Open Question 2
- Question: What are the tight lower bounds on both the estimation error and regret for OSLR?
- Basis in paper: Section 5 lists establishing "tight lower bounds on both estimation error and regret" as the third future direction.
- Why unresolved: A gap of O(√d) exists between the upper and lower bounds for estimation error, and the lower bound on regret remains unestablished.
- What evidence would resolve it: A formal proof establishing a lower bound that matches the Õ(√(kd/s)) upper bound for estimation error or the O(√T + ...) regret bound.

### Open Question 3
- Question: Can the per-round time complexity for (k, k0, d)-OSLR be reduced to allow for recomputation at every round rather than batching?
- Basis in paper: Remark 2 suggests exploring "whether recomputing ŵ_s for s ∈ {2^0, 2^1, 2^2, ...} can decrease the per-round time complexity" as further work.
- Why unresolved: The current DS-POSLRC algorithm requires solving a linear program at each round, which may be too expensive for high-frequency updates compared to online gradient methods.
- What evidence would resolve it: An analysis showing that logarithmic or exponential batching schedules maintain the regret bound while reducing the amortized per-round cost.

## Limitations

- The analysis critically depends on the compatibility condition being satisfied with a sufficiently large constant δ_S, which requires careful feature correlation control.
- The Dantzig Selector LP solver introduces computational overhead O(d^{2.5}) per exploration round, which could be prohibitive for very high-dimensional problems.
- The adaptive parameter tuning via induction has limited empirical validation and the noise variance σ is assumed known rather than estimated.

## Confidence

- **High confidence**: Polynomial-time tractability claim (O(poly(d)) per round) and the core regret decomposition into ONS regret plus estimator error.
- **Medium confidence**: Improved regret bound constants and d-dependence, which depend critically on the compatibility constant and feature distribution assumptions.
- **Low confidence**: Practical performance claims without experimental validation demonstrating regret scaling or support recovery in realistic settings.

## Next Checks

1. **Compatibility condition verification**: For synthetic Gaussian data with varying correlation structures, systematically measure δ_S and validate whether the theoretical regret scaling 1/δ_S^8 holds empirically.

2. **Algorithm-dependent sampling effectiveness**: Implement uniform sampling as baseline and compare ‖Δ_s(S)‖_1 convergence rates over time. Quantify the factor improvement in convergence speed.

3. **Robustness to noise and feature scaling**: Test the algorithm on data where ∥x_t∥_∞ ≤ 1 is violated and when noise variance σ² is unknown and must be estimated. Measure impact on feasibility of Dantzig Selector and overall regret.