---
ver: rpa2
title: Expanding the Generative AI Design Space through Structured Prompting and Multimodal
  Interfaces
arxiv_id: '2504.14320'
source_url: https://arxiv.org/abs/2504.14320
tags:
- acai
- brand
- generative
- users
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses challenges faced by small business owners
  (SBOs) in using generative AI for advertising, including difficulties articulating
  brand intuition, producing generic outputs, and limited refinement options. The
  authors developed ACAI, a multimodal generative AI tool featuring structured input
  panels for branding, audience/ goals, and inspiration.
---

# Expanding the Generative AI Design Space through Structured Prompting and Multimodal Interfaces

## Quick Facts
- **arXiv ID**: 2504.14320
- **Source URL**: https://arxiv.org/abs/2504.14320
- **Reference count**: 17
- **Primary result**: ACAI multimodal tool enables small business owners to create brand-aligned advertisements through structured input panels and co-creation interface

## Executive Summary
This paper addresses challenges faced by small business owners (SBOs) in using generative AI for advertising, including difficulties articulating brand intuition, producing generic outputs, and limited refinement options. The authors developed ACAI, a multimodal generative AI tool featuring structured input panels for branding, audience/goals, and inspiration. The system uses a multimodal large language model to process inputs into a unified "super prompt" for brand-aligned content generation. ACAI enables co-creation through multimodal input, interactive style selection, and brand consistency constraints.

## Method Summary
The ACAI system features three structured input panels: Branding (color palettes, typography, brand values, logo/assets), Audience & Goals (ad objectives, target segments, emotional tone), and Inspiration Board (reference images with visual attribute extraction). A multimodal large language model (Gemini 1.5 Pro) synthesizes these inputs into a unified "super prompt" that generates a textual Ad Brief with Summary, Background, and Foreground sections. The tool enables co-creative control through multimodal input, interactive style selection, and brand consistency constraints, with a case study demonstrating application for a hypothetical travel agency.

## Key Results
- ACAI enables small business owners to create brand-aligned advertisement briefs through structured multimodal input
- The tool reduces cognitive effort in prompt formulation by organizing inputs into logical panels
- Co-creation capabilities allow interactive refinement and style selection while maintaining brand consistency

## Why This Works (Mechanism)
ACAI works by structuring the creative process into three logical input domains that capture different aspects of brand identity and campaign requirements. The multimodal LLM serves as a synthesis layer that transforms these structured inputs into a coherent prompt, effectively bridging the gap between intuitive brand understanding and precise prompt formulation. By constraining inputs through specific panels while allowing flexibility within each domain, the system balances creative control with guidance.

## Foundational Learning
**Multimodal Large Language Models (MLLMs)**: Models that can process and integrate multiple input modalities (text, images, audio) into unified representations. Needed for understanding visual brand assets and reference images alongside textual brand descriptions. Quick check: Can the model extract relevant visual attributes from uploaded images.

**Prompt Engineering with Structured Inputs**: The practice of organizing information into specific formats or templates to improve model output quality. Required to ensure brand values and visual attributes are properly incorporated into generated content. Quick check: Are brand elements consistently reflected in the final ad brief.

**Co-creation Interfaces**: Interactive systems that allow users to iteratively refine AI-generated content through multiple feedback cycles. Essential for maintaining user agency and brand authenticity. Quick check: Can users modify outputs without losing previously established brand constraints.

## Architecture Onboarding

**Component Map**: Branding Panel -> Audience/Goals Panel -> Inspiration Board -> Gemini 1.5 Pro MLLM -> Super Prompt Synthesis -> Ad Brief Generation

**Critical Path**: User input through three panels → Multimodal processing → Super prompt synthesis → Ad brief generation → Interactive refinement

**Design Tradeoffs**: Structured input panels provide guidance but may constrain creativity; multimodal processing enables richer brand representation but increases system complexity; co-creation interface improves control but requires more user interaction.

**Failure Signatures**: Generic outputs indicate poor prompt synthesis; misaligned visuals suggest inadequate image analysis; user frustration may result from overly rigid panel structures or unclear input requirements.

**First 3 Experiments**:
1. Test super prompt synthesis with controlled inputs to verify brand element incorporation
2. Validate Inspiration Board image annotation accuracy against human annotations
3. Conduct usability study comparing cognitive load between ACAI and direct prompting approaches

## Open Questions the Paper Calls Out
None

## Limitations
- Exact prompt engineering methodology for synthesizing structured inputs into a unified "super prompt" is unspecified
- Image segmentation and attribute extraction pipeline lacks implementation specifics
- No quantitative evaluation metrics provided for effectiveness comparison

## Confidence
**High Confidence**: Overall system architecture and three-panel interface design can be faithfully reproduced using standard web frameworks and Gemini 1.5 Pro API access

**Medium Confidence**: General workflow of multimodal input processing and ad brief generation is clear, though specific prompt templates and image processing parameters remain unknown

**Low Confidence**: Effectiveness for intended use case (small business owner co-creation) cannot be verified without access to evaluation study [9] or comparable benchmarks

## Next Checks
1. Test the super prompt synthesis logic with controlled inputs to verify that brand values, colors, and visual attributes are consistently incorporated into generated ad briefs
2. Validate the Inspiration Board's image annotation accuracy by comparing automated visual attribute extraction against human annotations for diverse reference images
3. Implement the three-panel interface and conduct a small-scale usability study with novice users to assess cognitive load reduction and creative control improvements compared to direct prompting approaches