---
ver: rpa2
title: 'Oolong: Evaluating Long Context Reasoning and Aggregation Capabilities'
arxiv_id: '2511.02817'
source_url: https://arxiv.org/abs/2511.02817
tags:
- context
- episode
- answer
- label
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Oolong, a benchmark designed to evaluate
  long-context reasoning and aggregation capabilities in language models. The key
  innovation is posing tasks that require analyzing individual segments of text and
  aggregating these analyses to answer distributional questions, going beyond simple
  retrieval or needle-in-a-haystack tasks.
---

# Oolong: Evaluating Long Context Reasoning and Aggregation Capabilities

## Quick Facts
- arXiv ID: 2511.02817
- Source URL: https://arxiv.org/abs/2511.02817
- Reference count: 13
- Primary result: Even frontier models achieve less than 50% accuracy on long-context aggregation tasks

## Executive Summary
Oolong introduces a benchmark designed to evaluate long-context reasoning and aggregation capabilities in language models. Unlike traditional long-context benchmarks that focus on retrieval or "needle-in-a-haystack" tasks, Oolong requires models to analyze individual segments of text and aggregate these analyses to answer distributional questions. The benchmark consists of two task sets: Oolong-synth, which uses synthetic tasks constructed from in-context learning datasets, and Oolong-real, which uses real-world conversational data from Dungeons & Dragons transcripts. Results show that current frontier models struggle with these aggregation tasks, achieving less than 50% accuracy even at 128K context length.

## Method Summary
Oolong evaluates long-context reasoning through distributional questions that require both identification of relevant context and aggregation of findings across multiple segments. The benchmark includes two task sets: Oolong-synth, constructed from existing in-context learning datasets with synthetic tasks, and Oolong-real, based on real conversational transcripts from Dungeons & Dragons sessions. Tasks require models to first classify individual segments (e.g., identifying whether a statement was made by a specific character) and then aggregate these classifications to answer questions about the overall distribution or patterns across the conversation. This multi-step process tests the model's ability to maintain and reason about information across long contexts.

## Key Results
- Frontier models (GPT-5, Claude-Sonnet-4, Gemini-2.5-Pro) achieve less than 50% accuracy on both Oolong-synth and Oolong-real tasks
- Performance degrades with longer context lengths, even for models with 128K context windows
- The aggregation requirement poses a significant challenge beyond simple retrieval or classification tasks

## Why This Works (Mechanism)
Oolong's design forces models to engage in multi-step reasoning by requiring them to first identify relevant segments within long contexts and then synthesize information across these segments to answer distributional questions. This approach tests whether models can maintain coherence and perform logical aggregation over extended sequences, which is critical for real-world applications involving lengthy documents or conversations. The synthetic tasks provide controlled evaluation while the real-world tasks ensure ecological validity.

## Foundational Learning
- **Long-context window processing**: Understanding how models handle and retrieve information from extended sequences is essential for evaluating their practical utility in real-world scenarios where inputs exceed typical token limits. Quick check: Verify model's context length support and retrieval mechanisms.
- **Distributional reasoning**: The ability to aggregate findings across multiple segments and answer questions about overall patterns represents a higher-order reasoning capability that goes beyond simple classification or retrieval. Quick check: Ensure tasks require both segment-level analysis and cross-segment synthesis.
- **In-context learning adaptation**: Using existing in-context learning datasets for synthetic task construction leverages established evaluation methodologies while creating novel long-context challenges. Quick check: Validate dataset compatibility and task transformation fidelity.

## Architecture Onboarding
**Component Map**: Task Generation -> Context Processing -> Segment Classification -> Aggregation Analysis -> Final Answer Generation

**Critical Path**: Input context → Segment identification → Individual classification → Aggregation computation → Answer generation

**Design Tradeoffs**: Oolong prioritizes testing aggregation capabilities over pure retrieval, sacrificing some task simplicity for more realistic evaluation of long-context reasoning. The use of both synthetic and real-world tasks balances controlled experimentation with ecological validity.

**Failure Signatures**: Models may excel at segment-level classification but fail at aggregation, indicating strong local reasoning but weak global synthesis. Alternatively, models might retrieve relevant segments but misclassify them, suggesting retrieval capabilities without proper comprehension.

**First Experiments**: 1) Run baseline retrieval-only tasks to establish retrieval performance ceiling, 2) Test segment classification accuracy independently of aggregation, 3) Evaluate aggregation performance on pre-classified segments to isolate the aggregation challenge.

## Open Questions the Paper Calls Out
None

## Limitations
- Benchmark focuses primarily on distributional questions and aggregation tasks, potentially missing other aspects of long-context reasoning
- Synthetic tasks may not fully represent real-world reasoning challenges despite controlled evaluation benefits
- Relatively small size of Oolong-real (100 samples) limits statistical power and generalizability

## Confidence

**High Confidence**: The claim that current frontier models achieve less than 50% accuracy on Oolong tasks is well-supported by reported experimental results across multiple model families and context lengths.

**Medium Confidence**: The assertion that Oolong effectively tests multi-step reasoning and aggregation capabilities is supported by task design, but the specific contribution to overall reasoning ability remains partially demonstrated.

**Medium Confidence**: The characterization of Oolong as going beyond simple retrieval or needle-in-a-haystack tasks is reasonable given the task design, though the boundary between retrieval and aggregation can be nuanced.

## Next Checks
1. Conduct inter-rater reliability studies on Oolong-synth task generation to ensure synthetic tasks accurately represent intended reasoning challenges and avoid unintended biases.
2. Expand Oolong-real to include a larger and more diverse set of conversational transcripts to improve statistical power and generalizability of results.
3. Perform ablation studies comparing performance on Oolong tasks versus traditional retrieval tasks to quantify the specific difficulty added by the aggregation requirement.