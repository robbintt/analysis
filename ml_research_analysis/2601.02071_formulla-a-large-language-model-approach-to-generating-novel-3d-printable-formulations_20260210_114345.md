---
ver: rpa2
title: 'FormuLLA: A Large Language Model Approach to Generating Novel 3D Printable
  Formulations'
arxiv_id: '2601.02071'
source_url: https://arxiv.org/abs/2601.02071
tags:
- llms
- formulation
- learning
- these
- excipients
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explored the use of large language models (LLMs) for
  recommending excipients in pharmaceutical 3D printing formulations. Four open-source
  LLMs were fine-tuned on a dataset of 1400+ formulations using parameter-efficient
  fine-tuning.
---

# FormuLLA: A Large Language Model Approach to Generating Novel 3D Printable Formulations

## Quick Facts
- **arXiv ID**: 2601.02071
- **Source URL**: https://arxiv.org/abs/2601.02071
- **Reference count**: 0
- **Primary result**: Llama2 emerged as the best performer for generating excipient recommendations in pharmaceutical 3D printing formulations

## Executive Summary
This study explored the use of large language models (LLMs) for recommending excipients in pharmaceutical 3D printing formulations. Four open-source LLMs were fine-tuned on a dataset of 1400+ formulations using parameter-efficient fine-tuning. The research demonstrated that Llama2 outperformed other models in generating practical excipient recommendations, though standard LLM evaluation metrics proved inadequate for assessing pharmaceutical formulation quality.

## Method Summary
The research team fine-tuned four open-source LLMs on a dataset containing over 1400 pharmaceutical formulations. Parameter-efficient fine-tuning techniques were employed to adapt the models to the domain-specific task of excipient recommendation. The study systematically evaluated different models and hyperparameters to identify optimal configurations for formulation generation tasks.

## Key Results
- Llama2 demonstrated superior performance in generating excipient recommendations compared to other tested LLMs
- Standard evaluation metrics (BLEU, ROUGE) were insufficient for assessing pharmaceutical formulation quality
- Smaller models exhibited catastrophic forgetting during fine-tuning, highlighting the importance of model selection and hyperparameter tuning

## Why This Works (Mechanism)
The study leveraged the pattern recognition capabilities of large language models to identify relationships between drug properties and suitable excipients from existing formulation data. By fine-tuning on pharmaceutical formulations, the models learned domain-specific terminology and common excipient combinations, enabling them to generate novel yet plausible recommendations for 3D printable drug formulations.

## Foundational Learning
- **Parameter-efficient fine-tuning**: Why needed - Reduces computational cost while adapting pre-trained models to new domains. Quick check - Compare performance with full fine-tuning on smaller validation set.
- **Catastrophic forgetting**: Why needed - Understanding when models lose previously learned knowledge during adaptation. Quick check - Monitor performance on original vs. fine-tuning tasks.
- **Domain-specific evaluation metrics**: Why needed - Standard metrics fail to capture pharmaceutical formulation quality. Quick check - Validate custom metrics against expert assessments.
- **LLM scaling laws**: Why needed - Explains performance differences between model sizes. Quick check - Plot performance vs. parameter count.
- **Fine-tuning hyperparameters**: Why needed - Critical for balancing adaptation and preservation of learned knowledge. Quick check - Grid search across learning rates and batch sizes.

## Architecture Onboarding

**Component Map**: Raw formulation data -> Preprocessing pipeline -> LLM fine-tuning -> VELVET evaluation -> Expert validation

**Critical Path**: Data preprocessing → Model fine-tuning → Custom metric development → Performance evaluation

**Design Tradeoffs**: Parameter-efficient fine-tuning vs. full fine-tuning (speed vs. performance), standard metrics vs. custom VELVET metric (generality vs. domain-specificity)

**Failure Signatures**: Catastrophic forgetting in smaller models, poor generalization to novel drug classes, generation of impractical or unsafe excipient combinations

**First Experiments**:
1. Compare BLEU/ROUGE scores against VELVET metric on validation set
2. Test model performance on hold-out formulations from different therapeutic classes
3. Evaluate catastrophic forgetting by testing on pre-fine-tuning benchmarks

## Open Questions the Paper Calls Out
None

## Limitations
- Custom VELVET metric requires independent validation for broader pharmaceutical applications
- Dataset may not fully represent diversity of pharmaceutical formulations, particularly novel drug delivery systems
- Focus limited to excipient recommendation without addressing drug-excipient interactions or stability considerations

## Confidence

**High Confidence**: Llama2's superior performance in excipient recommendation generation is well-supported by comparative testing against other LLMs.

**Medium Confidence**: The identified limitations of standard evaluation metrics (BLEU/ROUGE) for formulation quality assessment are logically sound but require broader validation across different pharmaceutical domains.

**Medium Confidence**: The observed catastrophic forgetting in smaller models is consistent with known challenges in fine-tuning approaches, though specific thresholds and mitigation strategies would benefit from further investigation.

## Next Checks

1. **Cross-validation with pharmaceutical experts**: Conduct blind testing where domain experts evaluate VELVET metric rankings against their own assessments of formulation quality and practicality.

2. **External dataset testing**: Evaluate the fine-tuned models on an independent, hold-out dataset of pharmaceutical formulations not seen during training to assess generalizability and identify potential overfitting.

3. **Expanded formulation scope**: Extend the LLM fine-tuning to include additional formulation parameters beyond excipients, such as drug-polymer interactions, stability requirements, and manufacturing constraints, to assess model capability for comprehensive formulation development.