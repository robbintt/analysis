---
ver: rpa2
title: Visual serial processing deficits explain divergences in human and VLM reasoning
arxiv_id: '2509.25142'
source_url: https://arxiv.org/abs/2509.25142
tags:
- human
- serial
- processing
- reasoning
- visual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Large vision-language models (VLMs) perform poorly on visual reasoning
  tasks that require serial processing, even when human accuracy remains high. The
  study hypothesized that this gap arises because VLMs lack effective visual serial
  processing capabilities.
---

# Visual serial processing deficits explain divergences in human and VLM reasoning

## Quick Facts
- **arXiv ID**: 2509.25142
- **Source URL**: https://arxiv.org/abs/2509.25142
- **Reference count**: 40
- **Primary result**: VLMs struggle with visual reasoning tasks requiring serial processing, especially when humans take longer to solve them

## Executive Summary
Large vision-language models (VLMs) perform poorly on visual reasoning tasks that require serial processing, even when human accuracy remains high. The study hypothesized that this gap arises because VLMs lack effective visual serial processing capabilities. Three task domains—geometric reasoning, visual enumeration, and mental rotation—were used to systematically vary serial processing demands. Results showed a consistent inverse correlation between human reaction time and VLM accuracy: tasks that took humans longer to solve were the ones where VLMs performed worst. This pattern held across all domains and suggests that VLMs struggle when visual reasoning requires sequential analysis rather than holistic or language-based decomposition. Augmenting VLMs with serial processing (e.g., Chain-of-Thought, reasoning training, tool use) improved performance, but only in cases where linguistic grounding was possible. The findings indicate that limitations in serial, visually grounded reasoning represent a fundamental bottleneck distinguishing current VLMs from human cognition.

## Method Summary
The study employed three visual reasoning task domains: geometric reasoning (matching triangle types to verbal descriptions), visual enumeration (counting items in images), and mental rotation (identifying rotated shapes). Researchers systematically varied serial processing demands within each domain by controlling whether tasks could be solved holistically or required sequential analysis. Human participants completed these tasks while reaction times were recorded. VLMs were evaluated on identical tasks, and their accuracy was compared against human performance and reaction times. The study also tested serial processing augmentations including Chain-of-Thought prompting, reasoning training, and tool use to assess whether these could improve VLM performance on visually demanding tasks.

## Key Results
- Inverse correlation between human reaction time and VLM accuracy across all three task domains
- VLMs perform worst on tasks requiring serial processing that takes humans longest to complete
- Serial processing augmentations improve VLM performance only when tasks allow linguistic decomposition
- Visual enumeration and mental rotation tasks show the largest VLM-human performance gaps

## Why This Works (Mechanism)
VLMs appear to process visual information through parallel, holistic feature extraction rather than sequential, step-by-step analysis. When tasks require serial processing—examining visual elements in sequence, building mental representations incrementally, or applying rules iteratively—VLMs fail because their architecture lacks the capacity for temporally extended visual reasoning. The success of linguistic serial processing augmentations suggests VLMs can leverage their strong language capabilities when tasks permit verbal decomposition, but they cannot perform genuine visual serial processing. This creates a fundamental mismatch between human visual reasoning, which often involves sequential mental operations, and VLM processing, which remains largely parallel and gestalt-based.

## Foundational Learning
- **Visual serial processing**: Sequential analysis of visual information over time, building understanding incrementally
  - *Why needed*: Many real-world visual reasoning tasks require step-by-step examination of visual elements
  - *Quick check*: Can you solve the task by looking at all visual information at once, or do you need to examine parts sequentially?

- **Holistic vs. sequential processing**: Two distinct modes of visual reasoning—parallel feature extraction versus temporal, step-by-step analysis
  - *Why needed*: Understanding whether a task requires holistic or sequential processing determines appropriate VLM approaches
  - *Quick check*: Does the task description suggest breaking down the problem into steps, or can it be solved by direct visual matching?

- **Visual-linguistic grounding**: The ability to connect visual features with linguistic concepts and reasoning
  - *Why needed*: VLMs rely heavily on linguistic representations; tasks requiring pure visual reasoning without linguistic anchors are particularly challenging
  - *Quick check*: Can the visual task be described entirely in words, or does it require understanding visual relationships that resist verbal description?

- **Chain-of-Thought reasoning**: Sequential decomposition of reasoning tasks into intermediate steps
  - *Why needed*: Helps VLMs handle complex reasoning by breaking problems into manageable sub-problems
  - *Quick check*: Does prompting with intermediate reasoning steps improve VLM performance on this task?

## Architecture Onboarding

**Component map**: Visual encoder -> Language model -> Output decoder

**Critical path**: Visual input → Feature extraction → Linguistic encoding → Sequential reasoning → Response generation

**Design tradeoffs**: VLMs prioritize parallel visual processing for speed and efficiency over sequential visual reasoning capabilities, reflecting training data biases toward holistic understanding

**Failure signatures**: 
- Poor performance on tasks requiring temporal visual analysis
- Inability to count or enumerate items accurately in complex scenes
- Failure on mental rotation tasks that humans solve through sequential spatial transformations
- Success on tasks that can be decomposed into linguistic reasoning steps

**First experiments**:
1. Test VLM performance on tasks with varying degrees of serial processing demands while controlling for overall task complexity
2. Apply Chain-of-Thought prompting to determine if linguistic serial processing improves visual task performance
3. Compare VLM accuracy on visual-only serial processing tasks versus linguistically decomposable tasks

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions, but the findings raise several important areas for future research. The effectiveness of serial processing augmentations appears domain-dependent, suggesting that improvements may reflect better use of existing language capabilities rather than genuine visual serial processing. The generalizability of findings across different VLM architectures and training paradigms remains unclear. The distinction between visual and linguistic serial processing requires further investigation to determine whether VLMs struggle with visual processing specifically or with integrating visual and sequential reasoning more broadly.

## Limitations
- Does not establish causation between serial processing deficits and VLM performance gaps
- Findings may not generalize across different VLM architectures and training approaches
- Human behavioral data comes from controlled experimental settings that may not reflect real-world variability
- Unclear whether observed deficits reflect purely visual processing limitations or broader integration challenges

## Confidence

**High confidence**: The inverse correlation between human reaction time and VLM accuracy is robust and replicable

**Medium confidence**: The claim that serial processing deficits are the primary bottleneck for VLM visual reasoning

**Medium confidence**: The effectiveness of serial processing augmentations, though domain-dependent

## Next Checks
1. Test whether the serial processing correlation holds across a broader range of VLM architectures, including more recent models with enhanced visual processing capabilities
2. Conduct ablation studies to isolate whether serial processing deficits stem from visual processing limitations or from difficulties integrating visual and sequential reasoning
3. Design tasks that require pure visual serial processing without linguistic decomposition to determine if VLMs can develop visual-only sequential reasoning strategies