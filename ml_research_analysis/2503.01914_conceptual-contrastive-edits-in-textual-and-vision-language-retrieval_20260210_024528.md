---
ver: rpa2
title: Conceptual Contrastive Edits in Textual and Vision-Language Retrieval
arxiv_id: '2503.01914'
source_url: https://arxiv.org/abs/2503.01914
tags:
- https
- contrastive
- retrieval
- edits
- interventions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents a black-box post-hoc explainability framework
  for unimodal and vision-language retrieval models, leveraging knowledge graphs to
  generate controllable and optimal contrastive conceptual edits. The framework employs
  minimum weight bipartite matching to ensure optimality and controllability in substituting
  concepts across parts of speech, while introducing an Average Contrastive Effect
  (ACE) metric to quantify the per-word influence of each intervention.
---

# Conceptual Contrastive Edits in Textual and Vision-Language Retrieval

## Quick Facts
- arXiv ID: 2503.01914
- Source URL: https://arxiv.org/abs/2503.01914
- Authors: Maria Lymperaiou; Giorgos Stamou
- Reference count: 40
- Primary result: Presents a black-box post-hoc explainability framework for unimodal and vision-language retrieval models using knowledge graphs and minimum weight bipartite matching

## Executive Summary
This work introduces a post-hoc explainability framework for unimodal and vision-language retrieval models that generates controllable and optimal contrastive conceptual edits. The framework leverages knowledge graphs to substitute concepts across parts of speech, employing minimum weight bipartite matching to ensure optimality and controllability in the substitutions. An Average Contrastive Effect (ACE) metric is introduced to quantify the per-word influence of each intervention, providing interpretable insights into model behavior.

The framework is applied to both textual and text-image retrieval tasks, revealing that retrieval models exhibit varying sensitivity to different parts of speech. The results show that SBERT models are largely order-invariant and robust to certain deletions, while multimodal models demonstrate modality-specific sensitivities, such as stronger reliance on color in visual contexts. The framework effectively exposes biases and representational limitations in retrieval models, demonstrating its utility for interpretable model analysis.

## Method Summary
The framework generates contrastive conceptual edits for unimodal and vision-language retrieval models through a knowledge graph-based approach. It uses minimum weight bipartite matching to ensure optimal and controllable substitutions of concepts across different parts of speech. The method introduces an Average Contrastive Effect (ACE) metric to quantify the influence of each intervention at the per-word level. The approach is designed as a black-box post-hoc explainability tool that can be applied to existing retrieval models without requiring access to their internal parameters.

## Key Results
- SBERT models demonstrate order-invariance and robustness to certain deletions
- Multimodal models show modality-specific sensitivities, with color having stronger influence in visual contexts
- Nouns and verbs generally have higher impact on retrieval than adjectives and adpositions

## Why This Works (Mechanism)
The framework leverages knowledge graphs to systematically substitute concepts while maintaining semantic coherence through minimum weight bipartite matching. This ensures that substitutions are both optimal and controllable, preventing arbitrary or semantically incoherent edits. The ACE metric provides a quantitative measure of intervention impact, enabling systematic analysis of how different parts of speech affect retrieval performance.

## Foundational Learning
- **Knowledge Graphs**: Why needed - Provide structured semantic relationships for concept substitution; Quick check - Verify graph coverage and connectivity for target concepts
- **Minimum Weight Bipartite Matching**: Why needed - Ensures optimal and controllable concept substitutions; Quick check - Validate matching quality across different parts of speech
- **Average Contrastive Effect (ACE)**: Why needed - Quantifies per-word influence of interventions; Quick check - Compare ACE scores across different substitution strategies
- **Black-box Post-hoc Explainability**: Why needed - Enables model analysis without internal access; Quick check - Test framework applicability across different retrieval architectures

## Architecture Onboarding
**Component Map**: Knowledge Graph -> Concept Substitutions -> Minimum Weight Bipartite Matching -> ACE Computation -> Model Intervention

**Critical Path**: Knowledge graph construction and maintenance → Bipartite matching optimization → ACE metric calculation → Intervention application and evaluation

**Design Tradeoffs**: 
- Manual knowledge graph curation provides control but limits scalability
- Black-box approach enables broad applicability but may miss internal model dynamics
- ACE metric offers quantitative insights but may not capture interaction effects

**Failure Signatures**:
- Incomplete knowledge graph coverage leading to suboptimal substitutions
- Bipartite matching producing semantically incoherent edits
- ACE metric failing to account for multi-concept interaction effects

**3 First Experiments**:
1. Test ACE metric reliability across different parts of speech categories
2. Validate bipartite matching quality on controlled concept substitution tasks
3. Compare framework performance across multiple retrieval model architectures

## Open Questions the Paper Calls Out
None

## Limitations
- Manual knowledge graph curation introduces scalability challenges and coverage gaps
- ACE metric does not account for interaction effects between multiple concept substitutions
- Framework validation limited to English language retrieval tasks

## Confidence
- High Confidence: SBERT order-invariance and deletion robustness findings
- Medium Confidence: Modality-specific sensitivities in multimodal models
- Medium Confidence: Relative impact differences between parts of speech

## Next Checks
1. Test framework effectiveness across multiple languages and multilingual retrieval tasks
2. Conduct ablation studies removing different knowledge graph components
3. Evaluate interaction effects by systematically combining multiple concept substitutions