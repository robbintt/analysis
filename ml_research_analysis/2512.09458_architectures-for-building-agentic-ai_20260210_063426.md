---
ver: rpa2
title: Architectures for Building Agentic AI
arxiv_id: '2512.09458'
source_url: https://arxiv.org/abs/2512.09458
tags:
- agents
- reasoning
- memory
- tool
- reliability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This chapter argues that reliability in agentic and generative
  AI is fundamentally an architectural property, not merely a model characteristic.
  It defines agentic systems as goal-directed, tool-using decision makers operating
  in closed loops and shows how reliability emerges from principled componentisation
  (goal manager, planner, tool-router, executor, memory, verifiers, safety monitor,
  telemetry), disciplined interfaces (schema-constrained, validated, least-privilege
  tool calls), and explicit control and assurance loops.
---

# Architectures for Building Agentic AI

## Quick Facts
- arXiv ID: 2512.09458
- Source URL: https://arxiv.org/abs/2512.09458
- Authors: Sławomir Nowaczyk
- Reference count: 4
- Primary result: Reliability in agentic and generative AI is fundamentally an architectural property requiring principled componentization and disciplined interfaces

## Executive Summary
This chapter establishes that reliability in agentic AI systems emerges from architectural patterns rather than model characteristics alone. It defines agentic systems as goal-directed, tool-using decision makers operating in closed loops, and demonstrates how reliability is achieved through disciplined componentization, schema-constrained interfaces, and explicit control mechanisms. The work provides a practical taxonomy of agent patterns and analyzes how each reshapes reliability requirements and failure modes.

## Method Summary
The chapter presents a conceptual framework for building reliable agentic AI systems through principled architectural design. It proposes decomposing systems into discrete components with strict interfaces (Goal Manager, Planner, Tool Router, Executor, Memory, Safety Monitor) and implementing assurance patterns like simulate-before-actuate, least-privilege tool calls, and memory provenance tracking. The methodology emphasizes treating reliability as an architectural property requiring explicit control and validation loops rather than relying on model capabilities alone.

## Key Results
- Reliability emerges from principled componentization that confines faults to well-defined boundaries
- "Simulate-before-actuate" loops prevent irreversible real-world side effects from speculative model reasoning
- Memory provenance and hygiene maintain reasoning quality over long time horizons by preventing context poisoning
- A practical taxonomy (tool-using agents, memory-augmented agents, planning and self-improvement agents, multi-agent systems, and embodied or web agents) helps analyze reliability envelopes

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Reliability is primarily an architectural property, not merely a model characteristic.
- **Mechanism:** Decomposing systems into discrete components with strict, schema-validated interfaces confines faults within specific boundaries, forcing generative model outputs through deterministic contract checks before action.
- **Core assumption:** Generative models will produce non-deterministic or erroneous outputs which must be caught by deterministic software layers.
- **Evidence anchors:** "reliability emerges from principled componentisation... and disciplined interfaces"; "Componentisation... confines faults to well-defined boundaries and limits their blast radius."
- **Break condition:** Tight coupling without clear contracts allows fault isolation to fail and errors to cascade.

### Mechanism 2
- **Claim:** "Simulate-before-actuate" loops prevent irreversible real-world side effects.
- **Mechanism:** A validation layer interposes between Planner and Executor, running proposed actions against a non-destructive environment before committing to the real world.
- **Core assumption:** A reliable simulation environment exists that can approximate real system behavior closely enough to catch safety violations.
- **Evidence anchors:** "explicit control and assurance loops... simulate-before-actuate safeguards"; "Actuation must be treated as a privileged boundary... Require a verifier's green light before issuing any irreversible command."
- **Break condition:** Simulation drift creates a reality gap where valid plans are rejected or dangerous plans pass verification.

### Mechanism 3
- **Claim:** Memory provenance and hygiene maintain reasoning quality over long time horizons.
- **Mechanism:** Memory is treated as an active subsystem with write-gates, where entries carry metadata and retrieval policies filter for freshness and trust tiers.
- **Core assumption:** Source and trustworthiness of information can be determined at ingestion time, and stale information is generally less reliable than recent information.
- **Evidence anchors:** "memory provenance and hygiene... explicit control and assurance loops"; "Guard the write path... user-generated content goes to quarantine until vetted."
- **Break condition:** Unvetted data promoted to long-term memory without verification causes early reasoning errors to calcify into permanent false beliefs.

## Foundational Learning

- **Concept: Belief-Desire-Intention (BDI) Architecture**
  - **Why needed here:** Maps modern GenAI agents to classical BDI model, helping separate state (Beliefs) from goals (Desires) and plans (Intentions) for structuring Goal Manager and Planner components.
  - **Quick check question:** Can you distinguish between the agent's current knowledge (Belief) and its committed course of action (Intention) in a proposed design?

- **Concept: Least-Privilege Access Control**
  - **Why needed here:** Tool Router and Execution Gateway rely on this security principle to scope tools (e.g., "read-only," "sim-only") so compromised planners cannot perform destructive actions.
  - **Quick check question:** If the Planner is compromised, what is the maximum blast radius of the tool calls it can authorized?

- **Concept: Idempotency & Transactional Semantics**
  - **Why needed here:** Ensures retrying tool calls doesn't result in duplicate side effects, crucial for Executor component operating in loops.
  - **Quick check question:** If the Execution Gateway crashes after sending a command but before logging success, how does the system behave upon restart?

## Architecture Onboarding

- **Component map:** Goal Manager -> Planner (Generative) -> Tool Router -> Safety Monitor -> Execution Gateway
- **Critical path:** The "Validate-Before-Actuate" chain: user intent enters Goal Manager → Planner generates proposal → Tool Router binds to schema → Safety Monitor runs simulation → Execution Gateway commits action. Most critical reliability point is hand-off between Router (intent) and Gateway (execution).
- **Design tradeoffs:**
  - Reliability vs. Latency: "Simulate-before-actuate" steps increase safety but add latency
  - Cost vs. Robustness: "Tree of Thoughts" planning improves reasoning quality but significantly increases token cost and computation time
- **Failure signatures:**
  - Hallucinated Tools: Planner calls non-existent API. Mitigation: Tool Router allow-lists
  - Infinite Loops: Agent retries failing step indefinitely. Mitigation: Supervisor enforces step caps/budgets
  - Context Poisoning: Bad tool output corrupts future reasoning. Mitigation: Sanitize untrusted outputs; quarantine writes
- **First 3 experiments:**
  1. **Schema Validation Stress Test:** Feed Planner malformed inputs and verify Tool Router rejects 100% of invalid schema calls without crashing
  2. **Budget Exhaustion Test:** Force Planner into loop and verify Safety Monitor triggers safe-halt exactly at configured step limit
  3. **Provenance Trace:** Execute multi-step RAG query and verify audit log correctly links output to specific retrieved documents used

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can developers systematically determine optimal thresholds for termination criteria (e.g., step limits, cost caps) rather than relying on ad-hoc heuristics?
- **Basis in paper:** Section 3.1 notes that while step caps are necessary to prevent infinite loops, "determining the exact thresholds... is not necessarily straightforward."
- **Why unresolved:** The paper provides the mechanism (budgets/termination) but not the methodology for tuning them dynamically across diverse tasks.
- **What evidence would resolve it:** Theoretical frameworks or empirical benchmarks correlating task complexity with safe resource bounds.

### Open Question 2
- **Question:** What is the measurable trade-off between architectural constraints (e.g., schema validation, least-privilege) and creative problem-solving capabilities of an agent?
- **Basis in paper:** Section 3.1 explicitly acknowledges a "tradeoff between reliability and creativity in constraining the use of tools available to the agent."
- **Why unresolved:** The paper argues for strict constraints to ensure safety but does not quantify the loss of utility or flexibility caused by these "blast radius" limitations.
- **What evidence would resolve it:** Studies comparing task success rates on open-ended problems between heavily constrained ("safe") and unconstrained ("creative") agent architectures.

### Open Question 3
- **Question:** How does fidelity of the simulation environment affect reliability guarantees of "simulate-before-actuate" patterns in embodied agents?
- **Basis in paper:** The paper strongly advocates for "simulate-before-actuate" (Section 3.5) and "digital twin" usage, but relies on assumption that simulation accurately reflects real world.
- **Why unresolved:** Architectural reliability depends on simulator accuracy; if simulator suffers from "reality gap," safety monitor may approve actions unsafe in physical environment.
- **What evidence would resolve it:** Analysis of failure modes in sim-to-real transfer specific to agentic decision loops.

## Limitations
- The paper presents a conceptual framework without specifying concrete implementation details, tool schemas, or specific model configurations
- The taxonomy of agent patterns is comprehensive but lacks empirical validation across different domains
- The balance between safety constraints and system utility is discussed qualitatively but not quantified

## Confidence

- **High confidence:** The core claim that reliability is an architectural property rather than purely a model characteristic is well-supported by systematic decomposition approach and established software engineering principles
- **Medium confidence:** The proposed taxonomy of agent patterns and their respective reliability envelopes is conceptually sound but lacks empirical validation
- **Medium confidence:** Mechanisms for memory provenance and hygiene are theoretically justified but practical effectiveness depends heavily on implementation details not specified

## Next Checks

1. **Schema Validation Efficacy Test:** Implement tool router with strict JSON schema validation and measure false negative rate (valid tool calls rejected) versus false positive rate (invalid calls accepted) across diverse planner outputs

2. **Blast Radius Measurement:** Systematically compromise each component (Planner, Tool Router, Executor) in isolation and measure actual propagation of failures to quantify effectiveness of proposed fault isolation boundaries

3. **Memory Provenance Audit:** Build multi-step reasoning agent with provenance tracking, then deliberately inject conflicting or outdated information into memory to measure how effectively retrieval policies prevent context poisoning in downstream decisions