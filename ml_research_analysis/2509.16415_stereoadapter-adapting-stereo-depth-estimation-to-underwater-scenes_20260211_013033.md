---
ver: rpa2
title: 'StereoAdapter: Adapting Stereo Depth Estimation to Underwater Scenes'
arxiv_id: '2509.16415'
source_url: https://arxiv.org/abs/2509.16415
tags:
- stereo
- depth
- underwater
- vision
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: StereoAdapter addresses the challenge of underwater stereo depth
  estimation by integrating a LoRA-adapted monocular foundation encoder with a recurrent
  stereo refinement module. The method parameter-efficiently adapts large vision models
  to underwater scenes using dynamic LoRA adaptation and synthetic pre-training on
  UW-StereoDepth-40K.
---

# StereoAdapter: Adapting Stereo Depth Estimation to Underwater Scenes

## Quick Facts
- arXiv ID: 2509.16415
- Source URL: https://arxiv.org/abs/2509.16415
- Authors: Zhengri Wu; Yiran Wang; Yu Wen; Zeyu Zhang; Biao Wu; Hao Tang
- Reference count: 40
- Primary result: 6.11% improvement on TartanAir and 5.12% on SQUID vs state-of-the-art methods

## Executive Summary
StereoAdapter addresses the challenge of underwater stereo depth estimation by integrating a LoRA-adapted monocular foundation encoder with a recurrent stereo refinement module. The method parameter-efficiently adapts large vision models to underwater scenes using dynamic LoRA adaptation and synthetic pre-training on UW-StereoDepth-40K. Comprehensive evaluations demonstrate significant improvements: 6.11% on TartanAir and 5.12% on SQUID compared to state-of-the-art methods, while real-world deployment with BlueROV2 shows consistent robustness. The approach achieves faster inference (1113 ms) than competitors while maintaining superior accuracy, enabling practical underwater robotics applications for navigation, inspection, and mapping.

## Method Summary
StereoAdapter introduces a two-stage pipeline that combines a LoRA-adapted monocular depth encoder with a recurrent stereo refinement module. The method uses dynamic LoRA to efficiently adapt the Depth Anything V2 encoder to underwater scenes by updating only a small fraction of weights with sparsity regularization. A synthetic dataset (UW-StereoDepth-40K) pre-trains the model on underwater-specific physics including caustics and turbidity. The framework leverages the monocular encoder's global context while using stereo geometry to correct local scale errors through a hybrid guidance loss that constrains refinement in textureless regions.

## Key Results
- Achieves 6.11% improvement on TartanAir and 5.12% on SQUID compared to state-of-the-art methods
- Faster inference (1113 ms on Jetson Orin NX) than FoundationStereo (1815 ms) while maintaining superior accuracy
- Real-world deployment with BlueROV2 demonstrates consistent robustness in practical underwater conditions
- Parameter-efficient adaptation: uses only 0.6% additional parameters through dynamic LoRA

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The framework bridges the domain gap between terrestrial pre-training and underwater deployment by updating only a small fraction of foundation model weights.
- **Mechanism:** Dynamic LoRA integrates trainable rank-decomposition matrices with $\ell_1$ sparsity regularization into the Depth Anything V2 encoder, forcing adaptation to underwater lighting and scattering physics without destabilizing pre-trained geometry.
- **Core assumption:** Low-rank subspace exists to represent underwater-specific distortions without overwriting general geometric priors.
- **Evidence anchors:** Section III.C describes dynamic LoRA with learnable importance weights; Table V ablation shows specific rank configurations significantly impact RMSE; SurfSLAM highlights sim-to-real transfer difficulty.

### Mechanism 2
- **Claim:** Metric accuracy is recovered by treating monocular depth as a "soft prior" rather than rigid constraint, allowing stereo geometry to correct scale errors iteratively.
- **Mechanism:** Two-stage pipeline uses LoRA-adapted monocular encoder for coarse disparity initialization, then recurrent GRU-based stereo module refines it with "Disparity Guidance Loss" that selectively constrains stereo updates.
- **Core assumption:** Monocular foundation model provides globally coherent structure but erroneous local scale that stereo correlation can fix.
- **Evidence anchors:** Section III.B.2 describes "Hybrid Scale Alignment" verifying mono depth against sparse stereo anchors; Section III.B.3 defines disparity guidance loss; BridgeDepth discusses complementary nature of monocular context and stereo geometry.

### Mechanism 3
- **Claim:** Robustness in data-scarce underwater environments is achieved through synthetic pre-training on high-fidelity simulator modeling underwater light physics.
- **Mechanism:** UW-StereoDepth-40K generated using Unreal Engine 5 with domain randomization across camera baselines and underwater optical effects including caustics and particles.
- **Core assumption:** Simulation-to-real gap is primarily defined by lighting/scattering distributions which UE5 ray-tracing can approximate closely enough for transferable features.
- **Evidence anchors:** Section III.D details UE5 rendering pipeline; Section IV.C shows pre-training alone achieves competitive zero-shot performance on TartanAir (RMSE 2.8947); SPADE emphasizes depth estimation difficulty in turbid water.

## Foundational Learning

- **Concept: Epipolar Geometry & Cost Volumes**
  - **Why needed here:** Core refinement mechanism relies on 4D cost volume constructed from stereo rectification for GRU updates.
  - **Quick check question:** Can you explain how the "lookup" operator extracts features from the correlation pyramid using the current disparity estimate?

- **Concept: Low-Rank Adaptation (LoRA)**
  - **Why needed here:** "Adapter" refers to freezing VFM weights and training low-rank matrices (W = W₀ + ΔW).
  - **Quick check question:** If a specific layer's importance weights (w) all drop to zero during dynamic LoRA training, what happens to that layer's effective capacity?

- **Concept: Self-Supervised Photometric Loss**
  - **Why needed here:** Method learns by warping one view to another and minimizing pixel difference (SSIM + L1).
  - **Quick check question:** Why does occlusion handling (masking M_occ) matter when calculating reconstruction loss L_rec?

## Architecture Onboarding

- **Component map:** Rectified Stereo Pair (I_L, I_R) + MobileIE pre-processing -> Depth Anything V2 Encoder with Dynamic LoRA -> SDFA Blocks -> Discrete Disparity Volume -> CNN Context Encoder + VFM Features -> Correlation Pyramid -> GRU Recurrent Updates -> Metric Depth

- **Critical path:** Feature alignment in Eq. (11) (h^(l) = Conv_align(h^(l)_ViT) + h^(l)_CNN) where domain-adapted VFM features must successfully fuse with local CNN features. Failure here causes noisy context to GRU, slowing convergence.

- **Design tradeoffs:**
  - **Accuracy vs. Speed:** Faster than FoundationStereo (1113ms vs 1815ms) but still >1 second on Jetson Orin NX, suitable for slow navigation but potentially too slow for high-speed maneuvering.
  - **Fixed vs. Dynamic LoRA:** Dynamic LoRA reduces parameters but introduces hyperparameters (κ, dense epoch ratio) requiring tuning to prevent premature pruning.

- **Failure signatures:**
  - "Halo" artifacts around objects: Likely failure in occlusion masking (M_occ) during guidance loss calculation
  - Scale drift in open water: If sparse stereo matching fails to find anchors, defaults to monocular prior which may be scale-ambiguous in textureless water
  - Burst artifacts: If Dynamic LoRA prunes too aggressively, encoder may lose capacity to represent fine details

- **First 3 experiments:**
  1. **Baseline Validation:** Run inference on SQUID subset without LoRA adaptation to isolate performance gain from "Adapter" mechanism
  2. **Ablation on Guidance:** Set λ₄ = 0 (removing Disparity Guidance Loss) to observe if stereo module diverges in textureless regions
  3. **Latency Profiling:** Profile Jetson inference to determine if bottleneck is VFM encoder extraction or 32-iteration GRU loop

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the limited global reasoning capability of the RAFT-style recurrent head be overcome to handle severe turbidity and non-Lambertian highlights effectively?
- **Basis in paper:** Explicit statement in Limitations section that current decoder emphasizes local matching with short-range memory, leaving global reasoning "still limited" under severe turbidity, non-Lambertian highlights, and large textureless spans
- **Why unresolved:** Current GRU-based iterative refinement lacks global context mechanisms required to robustly fill geometry where local stereo correspondences fail completely
- **What evidence would resolve it:** Comparative study evaluating integration of global context architectures (Mamba or RWKV decoders) against current GRU head on high-turbidity sequences

### Open Question 2
- **Question:** To what extent does the simplification of participating media physics in UW-StereoDepth-40K dataset induce a sim-to-real gap?
- **Basis in paper:** Explicit statement in Limitations section noting UE5 pipeline simplifies "participating-media multiple scattering, polarization effects, dynamic turbidity/particles, [and] sensor/ISP idiosyncrasies"
- **Why unresolved:** Current method relies on synthetic pre-training that may not fully capture complex light transport physics of real dense underwater environments
- **What evidence would resolve it:** Quantitative analysis of performance degradation when transferring models trained on UE5 data to real-world data enriched with physics-based participating media rendering

### Open Question 3
- **Question:** Is depth estimation performance sensitive to failure modes of the MobileIE visual enhancement pre-processing step?
- **Basis in paper:** Inferred from Implementation Details stating method relies on MobileIE module to remove water-induced effects before feature extraction, but evaluations don't isolate error propagation
- **Why unresolved:** Enhancement module may hallucinate edges or create artifacts that stereo feature extractor latches onto as false signals
- **What evidence would resolve it:** Ablation study measuring depth accuracy on raw versus enhanced images in extreme visibility conditions where enhancement models typically struggle

## Limitations
- Physical simulator fidelity: UE5 cannot fully capture dynamic phenomena like marine snow, biofouling, or complex scattering from real water bodies
- Computation latency: 1113ms inference time may still be prohibitive for high-speed underwater navigation or dynamic obstacle avoidance
- Dataset domain gaps: Evaluation relies on two underwater datasets that don't represent full diversity of real-world underwater conditions across different water types and turbidity levels

## Confidence
- **High Confidence:** Parameter efficiency claims (6.11% and 5.12% improvements) well-supported by comprehensive ablation studies and quantitative comparisons in Tables IV and V
- **Medium Confidence:** Synthetic pre-training effectiveness demonstrated but relies on assumption that UE5's underwater rendering captures essential physics; real-world deployment provides some validation but limited duration
- **Medium Confidence:** Dynamic LoRA mechanism's automatic pruning capability theoretically sound but sensitive to hyperparameters suggesting potential instability across different environments

## Next Checks
1. **Cross-Dataset Generalization:** Test StereoAdapter on additional underwater datasets with varying water conditions (clear tropical vs. turbid coastal) to quantify robustness across different domain shifts
2. **Real-Time Constraint Analysis:** Profile 32-iteration GRU loop separately from VFM encoder to identify bottlenecks and evaluate if TensorRT optimization could reduce latency below 500ms for dynamic applications
3. **Failure Mode Analysis:** Systematically test on sequences with known failure conditions (massive particle occlusion, extreme lighting variations) to characterize boundaries where mono-prior constraint fails and recurrent stereo module diverges