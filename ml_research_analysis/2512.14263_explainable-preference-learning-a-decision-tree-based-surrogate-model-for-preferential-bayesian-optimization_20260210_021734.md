---
ver: rpa2
title: 'Explainable Preference Learning: a Decision Tree-based Surrogate Model for
  Preferential Bayesian Optimization'
arxiv_id: '2512.14263'
source_url: https://arxiv.org/abs/2512.14263
tags:
- optimization
- data
- function
- functions
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a decision-tree-based surrogate model for
  Preferential Bayesian Optimization (PBO) to address interpretability and scalability
  issues with Gaussian Process (GP) models. The proposed method uses a novel splitting
  heuristic called Consistency Score to partition the space into leaves and fits Gaussian
  distributions to each leaf to estimate utility values.
---

# Explainable Preference Learning: a Decision Tree-based Surrogate Model for Preferential Bayesian Optimization

## Quick Facts
- **arXiv ID:** 2512.14263
- **Source URL:** https://arxiv.org/abs/2512.14263
- **Reference count:** 40
- **Primary result:** DT-based surrogate model outperforms GP alternatives on spiky functions while maintaining competitive performance on non-spiky ones, with significantly better scalability (30s vs 1000-2900s).

## Executive Summary
This paper introduces a decision-tree-based surrogate model for Preferential Bayesian Optimization (PBO) to address interpretability and scalability issues with Gaussian Process (GP) models. The proposed method uses a novel splitting heuristic called Consistency Score to partition the space into leaves and fits Gaussian distributions to each leaf to estimate utility values. Extensive experiments on eight increasingly spiky benchmark functions show that the DT model outperforms GP-based alternatives on spiky functions while maintaining competitive performance on non-spiky ones. The method also scales significantly better with dataset size, requiring only ~30 seconds versus ~1000-2900 seconds for GP models. A case study on the Sushi dataset demonstrates the model's interpretability and ability to handle both categorical and continuous data, with the tree revealing interpretable preference patterns like "cheaper sushi is generally less liked." The authors also show initial work on using historical preference data to accelerate learning for new users by clustering similar users and training item-specific trees for each cluster.

## Method Summary
The method introduces a decision-tree surrogate for PBO that partitions the search space using a consistency score splitting criterion. For each potential split, the algorithm counts pairs where winners and losers fall on opposite sides of a threshold, maximizing the absolute difference between these counts. Each leaf is assigned a Gaussian-distributed latent utility value estimated via Laplace Approximation with a sum-to-zero constraint. The qEUBO acquisition function selects query pairs based on expected improvement in the best option's utility using leaf-wise Gaussian predictions. The approach handles both continuous and categorical features and demonstrates superior scalability compared to GP-based methods.

## Key Results
- DT-based model outperforms GP-based alternatives on spiky functions (Branin, Levy, Rosenbrock) while maintaining competitive performance on smoother functions
- Runtime scales linearly with dataset size: DT requires ~30 seconds versus ~1000-2900 seconds for GP models on 1000+ comparisons
- Case study on Sushi dataset reveals interpretable patterns (e.g., "cheaper sushi is generally less liked") and handles mixed categorical/continuous features effectively
- Initial user clustering approach shows promise for accelerating learning for new users using historical preference data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A consistency score enables decision trees to learn directly from pairwise comparison data by finding splits that separate winners from losers.
- Mechanism: For each potential split (feature k, threshold t), the algorithm counts pairs where the winner falls above the threshold and loser below (n_right) versus the reverse (n_left). The absolute difference |n_right - n_left| measures how well the split aligns with observed preferences. The tree greedily maximizes this score, partitioning the space into regions with consistent preference patterns.
- Core assumption: Winners and losers can be separated by axis-aligned thresholds in feature space.
- Evidence anchors:
  - [Section 3.1]: "Sc(k, t) = |n_right(k, t) - n_left(k, t)|. Essentially, this score rates how well winners are separated from losers."
  - [Section 3.1]: "Pairs that straddle the split are discarded, since they provide conflicting information for that threshold."
  - [corpus]: Weak direct evidence; related PBO papers assume GP-based surrogate models.
- Break condition: When utility depends on complex feature interactions requiring diagonal splits, or when >10 dimensions cause excessive straddler discard.

### Mechanism 2
- Claim: Gaussian leaf distributions with Laplace approximation provide probabilistic estimates suitable for acquisition functions while remaining interpretable.
- Mechanism: Each leaf's latent utility value follows an independent zero-mean Gaussian prior. After observing preference pairs, the posterior is approximated via Laplace Approximation (maximizing log-posterior). A sum-to-zero constraint across all leaves removes translational invariance, preventing ill-conditioned Hessians. The resulting leaf Gaussians (μ_cond, Σ_cond) enable uncertainty-aware querying.
- Core assumption: Preferences follow the Bradley-Terry-like model where P(x ≻ x') = Φ((f(x) - f(x'))/√(2σ²_noise)).
- Evidence anchors:
  - [Section 3.2]: "We approximate the posterior with a Gaussian centered at the MAP estimate... via LA."
  - [Section 3.2]: "The model is made identifiable by adding a sum-to-zero constraint."
  - [corpus]: BARK paper uses Bayesian tree kernels but for regression, not preference learning.
- Break condition: When σ_prior is set too large, causing numerical instability; when within-leaf comparisons dominate and provide no gradient signal.

### Mechanism 3
- Claim: The qEUBO acquisition function guides exploration by selecting pairs expected to maximize improvement in the best option's utility.
- Mechanism: For each candidate pair (x, x'), qEUBO computes expected utility gain using leaf-wise Gaussian predictions. Pairs spanning different leaves are naturally favored; the authors add optional within-leaf prioritization to ensure dense coverage. This directly targets preference learning rather than adapting standard regression acquisition functions.
- Core assumption: The current posterior uncertainty estimates are meaningful for predicting information gain.
- Evidence anchors:
  - [Section 3.3]: "qEUBO acquisition function directly targets PC data... expected improvement in utility using the leaf-wise Gaussian predictions."
  - [Section 3.3]: "When both items fall into the same leaf... qEUBO to undervalue within-leaf comparisons."
  - [corpus]: Knowledge Gradient for Preference Learning explores similar acquisition function design.
- Break condition: Early iterations with few comparisons lead to highly uncertain leaf estimates; the model may initially select uninformative pairs.

## Foundational Learning

- Concept: Preferential Bayesian Optimization (PBO) loop
  - Why needed here: The entire paper operates within the PBO framework—understanding the surrogate model → acquisition → query → update cycle is prerequisite.
  - Quick check question: Can you explain why PBO uses pairwise comparisons instead of direct function evaluations, and what role the acquisition function plays?

- Concept: Laplace Approximation for Bayesian inference
  - Why needed here: Leaf parameter estimation relies on approximating an intractable posterior with a Gaussian centered at the MAP estimate.
  - Quick check question: Given a log-posterior L(f), how would you derive the Laplace approximation's mean and covariance?

- Concept: Decision tree splitting criteria (entropy, Gini, variance reduction)
  - Why needed here: The consistency score is a novel splitting criterion; understanding standard criteria provides baseline for comparison.
  - Quick check question: How does the consistency score differ from variance reduction when applied to the same dataset?

## Architecture Onboarding

- Component map:
Input: Pairwise comparisons D = {(x_w, x_l)}
    ↓
[Tree Builder] → Consistency Score → splits on (k*, t*)
    ↓              (discards straddlers)
[Leaf Estimator] → Laplace Approx. → (μ_cond, Σ_cond) per leaf
    ↓              (sum-to-zero constraint)
[Acquisition] → qEUBO → selects next pair (x, x')
    ↓
Output: Query to decision-maker

- Critical path:
1. Initialize with random comparisons (paper uses 20)
2. Build tree: iterate splits until min_split_score or min_samples threshold reached
3. Estimate leaf Gaussians: solve MAP optimization with sum-to-zero constraint
4. Evaluate qEUBO over candidate pairs (within-leaf prioritization optional)
5. Update dataset with new preference; repeat from step 2

- Design tradeoffs:
| Choice | Benefit | Cost |
|--------|---------|------|
| Discard straddlers | Purer partitions, shallower trees, no pruning needed | Data loss, problematic in >10D |
| Single tree (not forest) | Full interpretability | May underfit complex functions |
| Axis-aligned splits | Simple, explainable | Cannot capture diagonal boundaries |
| σ_noise ≈ σ_prior | Good empirical performance | Sensitive to noise level misspecification |

- Failure signatures:
- **High regret on non-spiky functions**: GP baselines will outperform; verify function smoothness before deployment.
- **Shallow trees with high leaf variance**: Insufficient comparisons or min_split_score set too high; reduce threshold.
- **Numerical instability in Hessian**: σ_prior too large or too many comparisons; check condition number, verify sum-to-zero constraint.

- First 3 experiments:
1. **Sanity check on Branin 2D**: Run 20 trials with 200 iterations; DT should achieve regret ~0.1-0.2, comparable to GP. If regret >0.5, debug tree depth and acquisition.
2. **Scalability test on synthetic data**: Generate 1000+ random comparisons in 5D; verify cumulative runtime stays under 60s (vs. GP's >1000s). Plot time vs. iteration to confirm linear scaling.
3. **Categorical feature test on modified Sushi**: Replace one continuous feature with 5-category encoding; confirm tree splits correctly without preprocessing. Compare regret against one-hot encoded GP baseline.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the performance degradation in high-dimensional spaces ($d>10$) caused by discarding "straddler" pairs be mitigated by retaining the pairs but excluding the split dimension from subsequent consistency score calculations?
- Basis in paper: [explicit] Page 3 notes that discarding straddlers poses a problem for functions with $d > 10$. The authors suggest: "Potentially this could be solved by not discarding the straddlers, but removing the dimension that was split on... This is left as future work."
- Why unresolved: The current method ensures internal consistency in child nodes by discarding pairs that cross a threshold, which reduces the effective training data in high dimensions.
- What evidence would resolve it: A comparative study on synthetic datasets with dimensionality $d > 10$ showing improved regret convergence rates when using the modified retention strategy versus the current discarding method.

### Open Question 2
- Question: How can the probabilistic model and likelihood function be extended to handle explicit indifference statements from the decision-maker?
- Basis in paper: [explicit] Page 8 states: "An interesting direction for future work is to allow the DM to state indifference between a PC."
- Why unresolved: The current likelihood function (Eq. 2) relies on the cumulative standard normal distribution to model strict preferences ($x \succ x'$), but lacks a mechanism to model equality or indifference.
- What evidence would resolve it: A formulation of a modified likelihood function including a "noise threshold" for indifference and experiments demonstrating that modeling indifference improves optimization efficiency.

### Open Question 3
- Question: Can monotonicity constraints be integrated into the tree construction or leaf estimation to align with known domain properties (e.g., "less is always better")?
- Basis in paper: [explicit] Page 8 suggests: "future work could look into incorporating a monotonicity constraint (e.g., lesser is always better) to the model."
- Why unresolved: The current consistency score (Eq. 5) splits based on maximal separation of winners and losers without enforcing directional constraints on specific features.
- What evidence would resolve it: An adaptation of the splitting heuristic that penalizes splits violating monotonicity, verified on benchmark functions with known monotonic attributes.

## Limitations

- The discarding of straddling pairs in high dimensions could severely limit scalability, though this is not explicitly quantified in the paper.
- The Laplace Approximation's reliability depends heavily on prior settings (σ_prior, σ_noise), with no sensitivity analysis provided.
- While interpretability is a key selling point, the paper doesn't systematically evaluate how tree depth affects human comprehension or decision quality.

## Confidence

- **High confidence:** The decision tree approach significantly outperforms GP models on spiky functions (Branin, Levy, Rosenbrock) while maintaining competitive performance on smoother functions. The runtime scalability claim (DT: ~30s vs GP: ~1000-2900s) is well-supported by empirical timing data.
- **Medium confidence:** The interpretability benefits demonstrated on the Sushi dataset are compelling but not rigorously quantified. The clustering approach for user personalization shows initial promise but is validated on only one dataset with limited user numbers.
- **Low confidence:** Theoretical guarantees about the consistency score's ability to find optimal splits are not established. The numerical stability claims around Laplace approximation depend on unspecified implementation details.

## Next Checks

1. **High-dimension scalability test:** Evaluate performance and data retention rates when d > 10 on synthetic spiky functions. Track percentage of pairs discarded per split and measure impact on regret convergence.
2. **Prior sensitivity analysis:** Systematically vary σ_prior and σ_noise across multiple orders of magnitude on benchmark functions. Quantify how posterior estimates and regret trajectories change with these hyperparameters.
3. **Interpretability evaluation:** Conduct user studies comparing decision tree explanations versus GP predictive distributions on the Sushi dataset. Measure comprehension time, decision confidence, and preference prediction accuracy between expert and novice users.