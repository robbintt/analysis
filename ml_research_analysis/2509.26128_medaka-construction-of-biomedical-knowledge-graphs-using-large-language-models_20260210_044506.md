---
ver: rpa2
title: 'MEDAKA: Construction of Biomedical Knowledge Graphs Using Large Language Models'
arxiv_id: '2509.26128'
source_url: https://arxiv.org/abs/2509.26128
tags:
- drug
- biomedical
- knowledge
- information
- leaflets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MEDAKA, a biomedical knowledge graph constructed
  from drug leaflets using a web scraper and large language models. The proposed pipeline
  extracts structured triples from unstructured text, capturing clinically relevant
  attributes such as side effects, warnings, contraindications, ingredients, dosage
  guidelines, storage instructions, and physical characteristics.
---

# MEDAKA: Construction of Biomedical Knowledge Graphs Using Large Language Models

## Quick Facts
- arXiv ID: 2509.26128
- Source URL: https://arxiv.org/abs/2509.26128
- Reference count: 36
- Primary result: Constructed a biomedical KG with 41,142 nodes and 466,359 edges from drug leaflets with 96.6% precision and 87.2% recall

## Executive Summary
MEDAKA is a biomedical knowledge graph constructed from drug leaflets using a web scraper and large language models. The pipeline extracts structured triples from unstructured text, capturing clinically relevant attributes such as side effects, warnings, contraindications, ingredients, dosage guidelines, storage instructions, and physical characteristics. The dataset comprises 41,142 nodes and 466,359 edges, with evaluations showing 96.6% precision via human annotation and 96.9% via LLM-as-a-judge, alongside 87.2% recall on a subset. MEDAKA covers a broader range of drug information than existing biomedical KGs and databases, supporting applications in patient safety monitoring and drug recommendation. The modular design enables adaptation to other domains.

## Method Summary
The MEDAKA pipeline consists of three main stages: web scraping drug leaflets from HPRA using BeautifulSoup, parsing PDF content to text using PyMuPDF, and extracting subject-relation-object triples using LLaMA 3.3 70B Instruct. The extraction process queries the LLM five times per document and applies majority voting (≥3 occurrences) to filter triples with confidence ≥0.5. The schema includes 10 entity types (Drug, SideEffect, etc.) and 9 relations (has_side_effect, etc.). The system processes ~13,000 drug leaflets containing 4,000–8,000 words each, maintaining single-pass extraction to avoid context window limitations of smaller models.

## Key Results
- Final knowledge graph contains 41,142 nodes and 466,359 edges
- Precision measured at 96.6% via human annotation and 96.9% via LLM-as-a-judge
- Recall achieved 87.2% on a subset of manually verified triples
- Covers broader range of drug information attributes compared to existing biomedical KGs

## Why This Works (Mechanism)
MEDAKA succeeds by leveraging the strong natural language understanding capabilities of large language models to extract structured knowledge from unstructured drug leaflet text. The majority voting approach (5 extractions per document, threshold of ≥3) significantly reduces hallucination and improves precision by requiring consensus across multiple generations. Using a 70B parameter model with sufficient context window enables processing entire documents in a single pass, avoiding the information loss and inconsistency issues that arise from document chunking. The modular pipeline design allows for adaptation to other biomedical domains beyond drug information extraction.

## Foundational Learning
- **Web scraping with BeautifulSoup**: Required for programmatically collecting drug leaflets from regulatory websites. Quick check: Verify scraper can successfully download PDF files from HPRA URLs.
- **PDF text extraction with PyMuPDF**: Needed to convert unstructured PDF documents into machine-readable text format. Quick check: Confirm extracted text preserves original content without corruption or loss.
- **Majority voting for LLM outputs**: Essential technique for reducing hallucination and improving confidence in extracted triples. Quick check: Validate that ≥3/5 agreement threshold consistently filters out incorrect extractions.
- **Knowledge graph schema design**: Critical for defining meaningful entity types and relationships specific to biomedical domain. Quick check: Ensure all extracted triples conform to predefined entity and relation types.

## Architecture Onboarding

Component Map: Web Scraper -> PDF Parser -> LLM Extractor -> Majority Voter -> KG Storage

Critical Path: The LLM extraction stage with majority voting is the core of the pipeline, as it directly determines the quality and accuracy of the final knowledge graph. The 70B parameter model with sufficient context window is essential for handling entire drug leaflets in single-pass processing.

Design Tradeoffs: Single-pass extraction vs. document chunking - the paper chose single-pass using LLaMA 3.3 70B to avoid context window limitations and maintain consistency, though this requires significant computational resources. Majority voting (5×, ≥3 threshold) vs. single extraction - the voting approach improves precision but increases computational cost.

Failure Signatures: Context window overflow occurs when documents exceed model limits, leading to incomplete extractions. High hallucination rates manifest as inconsistent triples across voting rounds, failing to meet the ≥3 agreement threshold. Incorrect schema mapping results in malformed triples that don't conform to entity/relation definitions.

Three First Experiments:
1. Test the web scraper on 10 sample HPRA URLs to verify PDF download functionality
2. Run PDF parser on a single leaflet to confirm text extraction quality and formatting
3. Execute LLM extraction with majority voting on one document to validate the full pipeline workflow

## Open Questions the Paper Calls Out
None

## Limitations
- Heavy dependence on a single LLM (LLaMA 3.3 70B) with no robustness testing across model variants
- Majority voting threshold (≥3/5) was not systematically optimized
- Claims about broader coverage than existing biomedical KGs lack quantitative comparison metrics
- Single-pass extraction may miss context-dependent relationships

## Confidence

High Confidence:
- Basic extraction pipeline design (scrape→parse→LLM→filter) and final dataset statistics are well-documented and verifiable

Medium Confidence:
- Evaluation metrics (96.6% precision, 96.9% via LLM-as-a-judge, 87.2% recall) are reported but lack independent validation and standardized benchmark comparisons

Low Confidence:
- Claims about superior coverage relative to existing biomedical knowledge graphs are not substantiated with specific quantitative comparisons or database citations

## Next Checks

1. **Benchmark Comparison**: Systematically compare MEDAKA's coverage and accuracy against established biomedical knowledge bases (e.g., DrugBank, SIDER) using standardized metrics like entity type distribution overlap and relation completeness.

2. **Model Robustness Testing**: Repeat the extraction pipeline using alternative LLMs (e.g., GPT-4, Claude) and different voting thresholds (2/5, 4/5) to assess sensitivity and reproducibility of the results.

3. **Longitudinal Validation**: Sample and manually verify a statistically significant subset of triples (n≥100) across all relation types to independently confirm the reported precision and recall rates.