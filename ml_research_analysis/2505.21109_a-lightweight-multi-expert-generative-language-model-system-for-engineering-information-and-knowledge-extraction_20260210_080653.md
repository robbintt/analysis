---
ver: rpa2
title: A Lightweight Multi-Expert Generative Language Model System for Engineering
  Information and Knowledge Extraction
arxiv_id: '2505.21109'
source_url: https://arxiv.org/abs/2505.21109
tags:
- language
- llama-3
- engineering
- data
- b-instruct
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces the Small Language Graph (SLG), a lightweight
  multi-expert generative language model system designed to improve domain-specific
  information extraction in engineering contexts while reducing hallucinations and
  computational overhead. SLG organizes fine-tuned small language models (1B parameters)
  as graph nodes, with an orchestrator routing user queries to the most relevant expert.
---

# A Lightweight Multi-Expert Generative Language Model System for Engineering Information and Knowledge Extraction

## Quick Facts
- arXiv ID: 2505.21109
- Source URL: https://arxiv.org/abs/2505.21109
- Authors: Bogdan Bogachov; Yaoyao Fiona Zhao
- Reference count: 40
- Primary result: SLG achieves 3x Exact Match improvement over 8B model while using 1.7x less training time

## Executive Summary
This study introduces the Small Language Graph (SLG), a lightweight multi-expert generative language model system designed to improve domain-specific information extraction in engineering contexts while reducing hallucinations and computational overhead. SLG organizes fine-tuned small language models (1B parameters) as graph nodes, with an orchestrator routing user queries to the most relevant expert. This architecture mitigates knowledge overlap and data overshadowing, which are common causes of hallucinations in larger models. Experimental results show that SLG outperforms a larger standalone model (8B parameters) by 3x on Exact Match accuracy, while being 1.7x faster to fine-tune. The system can be trained and run on a single RTX 4090 GPU, making it accessible to small-to-medium engineering firms without expensive compute infrastructure.

## Method Summary
SLG partitions engineering documentation (Cessna SRM) into non-overlapping subsection-based chunks, then uses Llama-3.3-70B-Instruct to generate synthetic Q&A pairs for each chunk. An orchestrator model (Llama-3.2-1B-Instruct) is fine-tuned to map questions to expert node identifiers (subsection names), while multiple expert models are fine-tuned on isolated knowledge segments. The system uses LoRA fine-tuning (r=16, alpha=16, lr=1e-3) and connects nodes via LangGraph routing. Each query flows through orchestrator → expert → response, with the orchestrator selecting the most relevant expert based on query content.

## Key Results
- SLG achieves Exact Match accuracy of 0.12 versus Llama-3.1-8B's 0.05 (3x improvement)
- Fine-tuning SLG takes 3475 seconds versus 5891 seconds for the 8B model (1.7x faster)
- System trains and runs on a single RTX 4090 GPU, making it accessible to small-to-medium engineering firms
- Orchestrator routing accuracy is approximately 70%, representing a significant limitation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Isolating training data per expert node reduces hallucinations caused by knowledge overshadowing in engineering domains.
- Mechanism: The system partitions domain documentation into non-overlapping chunks (by subsection), fine-tuning separate 1B-parameter models on each isolated segment. This prevents semantically similar but procedurally distinct content from blending during probabilistic token generation.
- Core assumption: Hallucinations in monolithic fine-tuned models primarily stem from overlapping contexts in training data (knowledge overshadowing), not from architectural limitations of transformers themselves.
- Evidence anchors:
  - [abstract] "This architecture mitigates knowledge overlap and data overshadowing, which are common causes of hallucinations in larger models."
  - [PAGE 3] Figure 1 and Figure 2 illustrate data overlapping and isolated training data splits; Table 1 shows concrete examples of overlapping sentences from the SRM.
  - [corpus] Weak direct corpus support for this specific mechanism; neighboring papers focus on parameter-efficient fine-tuning and multi-expert routing, not data isolation for hallucination reduction.
- Break condition: If hallucinations persist despite data isolation (e.g., from model architecture limitations, insufficient training data, or ambiguous queries), the mechanism's effectiveness diminishes.

### Mechanism 2
- Claim: A learned orchestrator enables domain-specific expert selection, improving retrieval-accuracy compared to monolithic model responses.
- Mechanism: The orchestrator model is fine-tuned to map questions to expert node identifiers (subsection names) rather than content answers. During inference, it routes queries to the most relevant expert, which then generates the actual response from its specialized knowledge base.
- Core assumption: Query-to-expert classification is simpler and more reliable than direct question-to-answer generation within a single model containing all domain knowledge.
- Evidence anchors:
  - [PAGE 4] Table 2 shows orchestrator answers (expert names) vs. expert answers (actual procedures) for identical questions.
  - [PAGE 4] "The expert names bear the names of the engineering document subjections. This approach allows the orchestrator to directly return the name of an appropriate expert."
  - [corpus] Task-Aware Multi-Expert (TAME, arXiv:2512.11243) demonstrates similar expert selection via task similarity, suggesting routing mechanisms transfer across domains.
- Break condition: If the orchestrator misroutes queries (reported ~70% success rate in PAGE 5), downstream expert accuracy becomes irrelevant.

### Mechanism 3
- Claim: Composing multiple small fine-tuned models achieves superior Exact Match accuracy with lower computational overhead compared to single large model fine-tuning.
- Mechanism: Each expert (1B parameters) is fine-tuned via LoRA on narrow data segments. Total system training time sums across experts but remains 1.7x faster than training one 8B model, while isolated knowledge yields 3x EM improvement.
- Core assumption: Engineering documentation's structured nature (clear section/subsection boundaries) enables clean data partitioning; this may not generalize to unstructured domains.
- Evidence anchors:
  - [PAGE 5] Table 6: SLG achieves EM=0.12 vs. Llama-3.1-8B's EM=0.05 (3x improvement claimed).
  - [PAGE 5] Table 5: SLG fine-tuning takes 3475s vs. Llama-3.1-8B's 5891s (1.7x faster).
  - [corpus] Parameter-Efficient Routed Fine-Tuning (arXiv:2508.02587) supports that adaptation modules with routing improve over monolithic PEFT.
- Break condition: If data segments are not cleanly separable, or if cross-domain queries require multi-expert synthesis, single-expert routing degrades.

## Foundational Learning

- Concept: **Knowledge Overshadowing in LLMs**
  - Why needed here: Understanding why monolithic models hallucinate on overlapping content motivates the entire graph-based isolation strategy.
  - Quick check question: Can you explain why two procedures with identical openings but different endings would cause an LLM to generate incorrect completions?

- Concept: **LoRA (Low-Rank Adaptation)**
  - Why needed here: All models (orchestrator and experts) use LoRA for efficient fine-tuning; understanding bottleneck adapters is prerequisite to reproducing results.
  - Quick check question: What does freezing the backbone model and training only low-rank decomposition matrices achieve in terms of parameter efficiency?

- Concept: **Graph-Based Agent Orchestration (LangGraph)**
  - Why needed here: The SLG system connects expert nodes via graph edges; familiarity with LangGraph's state management and routing is required for implementation.
  - Quick check question: How would you represent a conditional edge that routes a query to one expert if it contains "wing" and another if it contains "fuselage"?

## Architecture Onboarding

- Component map:
  - Orchestrator Node -> Expert Node(s) -> Response Generation
  - Orchestrator fine-tuned on question→expert-name pairs
  - Expert nodes fine-tuned on question→content pairs for isolated subsections
  - LangGraph-based edges connecting orchestrator to all experts

- Critical path:
  1. Partition source documentation into non-overlapping subsection-based chunks
  2. Generate synthetic Q&A pairs per chunk using Llama-3.3-70B-Instruct
  3. Fine-tune orchestrator on question→expert-name pairs
  4. Fine-tune each expert on question→content pairs for its assigned chunk
  5. Connect nodes via LangGraph; inference routes query→orchestrator→expert→response

- Design tradeoffs:
  - Orchestrator accuracy vs. system complexity: Current 70% routing accuracy limits gains; improving it requires larger orchestrator or multi-turn clarification, adding latency
  - Expert granularity vs. coverage: Finer chunks reduce overlap but increase node count and orchestration difficulty
  - EM vs. semantic similarity metrics: SLG excels at EM (0.12 vs 0.05) but ROUGE-L/METEOR are comparable; choose metrics based on whether exact procedural accuracy or fuzzy semantic matching matters

- Failure signatures:
  - Misrouting: Orchestrator sends "wing spar" query to "fuselage" expert→irrelevant response
  - Out-of-domain queries: No generic fallback expert; system may force inappropriate routing
  - Multi-hop questions: Single-expert design cannot synthesize across sections (e.g., comparing wing vs. fuselage repair criteria)

- First 3 experiments:
  1. Replicate orchestrator fine-tuning on Q→expert-name pairs; validate routing accuracy on held-out test set (target ~70%)
  2. Fine-tune one expert node on a single SRM subsection; measure EM on subsection-specific questions vs. baseline Llama-3.2-1B fine-tuned on full corpus
  3. Assemble minimal SLG (orchestrator + 2 experts); compare end-to-end EM and latency against Llama-3.1-8B-Instruct fine-tuned on the same combined data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the Small Language Graph (SLG) compare against Retrieval-Augmented Generation (RAG) systems and significantly larger models like Llama-3.3-70B-Instruct in terms of accuracy and hallucination rates?
- Basis in paper: [explicit] The authors explicitly state in the Limitations section that they plan to "conduct more extensive comparisons by including the bigger Llama-3.3-70B-Instruct LLM and RAG," as RAG is a "very powerful technique" for accessing up-to-date information.
- Why unresolved: The current study only compares SLG against smaller standalone models (1B and 8B parameters) and excludes RAG, leaving its relative efficacy against standard industry retrieval methods unproven.
- What evidence would resolve it: Experimental results benchmarking SLG against a RAG implementation and a 70B parameter model on the same engineering dataset (e.g., Cessna SRM) using ROUGE-L, Exact Match, and METEOR metrics.

### Open Question 2
- Question: Does the SLG system maintain its advantage in reducing hallucinations when evaluated using human assessment or dedicated fact-checking frameworks rather than Exact Match (EM) metrics?
- Basis in paper: [explicit] The authors acknowledge a "limited hallucinations check" in the current study, noting that while EM is used as a proxy, "human evaluation and fact-checking could be a more exhaustive way to estimate how well SLG can avoid hallucinations."
- Why unresolved: Exact Match is a strict string-based metric; it is unclear if the model generates factually correct synonyms or paraphrases that EM would penalize, or if it hallucinates in ways EM misses.
- What evidence would resolve it: A qualitative study involving domain experts reviewing SLG outputs for factual consistency, or benchmarking using a dedicated hallucination detection framework.

### Open Question 3
- Question: Can the SLG architecture be effectively adapted to handle multi-modal data, specifically images, which are currently excluded but "essential in engineering"?
- Basis in paper: [explicit] The paper lists "absence of images in the training data due to the pure text-based focus of the study" as a limitation, explicitly stating that "image data is essential in engineering" and must be considered in future work.
- Why unresolved: The current SLG methodology relies on text-based transformer models (Llama-3.2-1B-Instruct) and text-chunking strategies that do not account for visual information contained in engineering diagrams or schematics.
- What evidence would resolve it: A modified SLG implementation capable of processing image-text pairs from engineering manuals, demonstrating performance maintenance or improvement on visual QA tasks.

### Open Question 4
- Question: To what extent does the addition of conversational memory and an aggregator node improve the system's ability to handle multi-turn queries or questions requiring synthesis from multiple experts?
- Basis in paper: [explicit] The authors note that the current SLG "is not a full-scale chatbot, does not have memory, and does not keep conversational context." They propose adding an "aggregator node" and "generic expert node" to overcome routing issues and enable clarifying prompts.
- Why unresolved: Currently, each query is treated as a stand-alone question, and the orchestrator has a 70% success rate in routing. It is unknown if context retention would improve or complicate the routing and generation accuracy.
- What evidence would resolve it: Performance evaluation of an updated SLG architecture with memory modules on multi-turn conversational datasets, measuring the accuracy of context retention and expert selection over extended dialogues.

## Limitations
- Data isolation assumption may not hold for unstructured or less regimented engineering domains, limiting generalizability
- Orchestrator routing accuracy of ~70% represents a significant failure point that can produce irrelevant responses
- Synthetic data quality and coverage directly impact both orchestrator training and expert performance, but specific generation processes are not detailed
- Single-expert design cannot handle multi-hop reasoning or synthesis across multiple knowledge domains

## Confidence
- **High Confidence**: Claims regarding computational efficiency (1.7x faster training, RTX 4090 feasibility) are well-supported by specific timing metrics and hardware specifications
- **Medium Confidence**: The 3x EM improvement over the 8B model is demonstrated on a single dataset with specific evaluation metrics
- **Low Confidence**: Generalizability claims to "small-to-medium engineering firms" and assertions that distributed systems can replace "centralized clusters" lack supporting evidence beyond the specific SRM case

## Next Checks
1. Replicate SLG architecture on engineering documentation from different domains (mechanical, electrical, civil) to verify that clean subsection isolation is possible and that the 3x EM improvement persists
2. Systematically evaluate orchestrator performance on ambiguous queries, out-of-domain questions, and multi-hop reasoning tasks to identify routing failure patterns and develop fallback mechanisms
3. Compare SLG against other parameter-efficient approaches (LoRA, adapters, quantization) on the same hardware constraints to determine if the graph-based routing provides unique benefits beyond standard fine-tuning efficiency