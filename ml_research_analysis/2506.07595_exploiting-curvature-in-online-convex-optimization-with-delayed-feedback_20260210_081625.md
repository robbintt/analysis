---
ver: rpa2
title: Exploiting Curvature in Online Convex Optimization with Delayed Feedback
arxiv_id: '2506.07595'
source_url: https://arxiv.org/abs/2506.07595
tags:
- delayed
- regret
- dtot
- convex
- online
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies online convex optimization with delayed feedback
  under strongly convex and exp-concave losses. Existing approaches for strongly convex
  losses yield regret bounds of order $d{\max} \ln T$, which can be significantly
  worse than the $\sqrt{d{\mathrm{tot}}}$ bound achieved by delayed gradient descent,
  where $d{\max}$ is the maximum delay, $d{\mathrm{tot}}$ is the total delay, and
  $T$ is the time horizon.
---

# Exploiting Curvature in Online Convex Optimization with Delayed Feedback

## Quick Facts
- arXiv ID: 2506.07595
- Source URL: https://arxiv.org/abs/2506.07595
- Reference count: 40
- Primary result: Achieves O(min{σ_max ln T, √d_tot}) regret for strongly convex losses and O(min{d_max n ln T, √d_tot}) for exp-concave losses with delayed feedback

## Executive Summary
This paper addresses online convex optimization with delayed feedback, where the algorithm only observes gradients after a random delay. The key insight is exploiting the curvature of strongly convex and exp-concave losses to achieve regret bounds that depend on the number of missing observations (σ_max) rather than the maximum delay (d_max). For strongly convex losses, the authors propose a delayed FTRL variant that achieves O(min{σ_max ln T, √d_tot}) regret, which can be substantially better than existing methods when delays are bursty. They extend this approach to exp-concave losses using an adaptive Online Newton Step algorithm, and apply similar principles to unconstrained online linear regression.

## Method Summary
The paper proposes three algorithms for different loss types under delayed feedback. For strongly convex losses, Algorithm 1 uses delayed FTRL with regularization that includes all previous decisions (not just observed ones), enabling diameter-free regret bounds. For exp-concave losses, Algorithm 2 extends Online Newton Step with adaptive learning rate tuning that switches between logarithmic and sublinear regimes based on delay statistics. For unconstrained online linear regression, Algorithm 3 modifies the Vovk-Azoury-Warmuth forecaster with a clipping trick to handle the unbounded domain while maintaining similar regret guarantees. All algorithms track observed and missing gradients to compute adaptive parameters that optimize the regret bound.

## Key Results
- Delayed FTRL achieves O(min{σ_max ln T, √d_tot}) regret for strongly convex losses, improving over existing O(d_max ln T) bounds
- Adaptive ONS with η_t = min{a_t, b_t} + 1 achieves O(min{d_max n ln T, √d_tot}) for exp-concave losses
- Clipped VAW forecaster handles unconstrained OLR with O(∥u∥² · min{d_max n ln T, √d_tot}) regret
- Experiments show improved performance over baselines across various delay patterns and loss functions

## Why This Works (Mechanism)

### Mechanism 1
Delayed FTRL achieves O(min{σ_max ln T, √d_tot}) regret for strongly convex losses by sharing regularization between actual and "cheating" iterates. The update includes all previous decisions x_s in the λ/2 Σ∥x - x_s∥² regularization term (not just observed rounds). This ensures the "cheating" iterate x*_t (which assumes all gradients are known) and actual iterate x_t share the same regularizer. Lemma A.2 then bounds ∥x*_t - x_t∥² ≤ G|m_t|/(λ(t-1)). Summing over t yields either σ_max ln T (bounding |m_t| by σ_max) or √d_tot (using the inequality Σ |m_t|/√(Σ m_τ) ≤ 2√d_tot).

### Mechanism 2
Delayed ONS with adaptive learning rate η_t = min{a_t, b_t} + 1 achieves O(min{d_max n ln T, √d_tot}) for exp-concave losses. The algorithm tracks two regimes: a_t ∝ d_max n ln T (logarithmic bound via elliptical potential) and b_t ∝ √(Σ |m_s|) (sublinear bound). At each round, η_t uses whichever is smaller. If a_T ≤ b_T, Lemma C.1 yields the logarithmic bound; if b_T < a_T, the analysis splits at the last round τ* where a_τ* ≤ b_τ* and applies each bound to its respective segment.

### Mechanism 3
Clipped VAW forecaster handles unconstrained OLR with delayed labels, achieving O(∥u∥² · min{d_max n ln T, √d_tot}). The clipping trick (e_xt = x_t · min{ρ_t/|⟨z_t, x_t⟩|, 1}) bounds predicted labels within estimated label range ρ_t = max observed |y_τ|. This prevents gradient explosion in the unconstrained domain. The clipping error contributes O(Y² σ_max) to regret, which Lemma A.7 relates to √d_tot. Adaptive learning rate tuning mirrors Mechanism 2.

## Foundational Learning

- **Follow-The-Regularized-Leader (FTRL)**
  - Why needed here: Core framework for Algorithms 1 and 2; requires understanding how adding regularization stabilizes decisions against delayed gradients.
  - Quick check question: Given cumulative linear losses and a quadratic regularizer, can you derive the closed-form update x_t = -A^{-1}b?

- **Strong Convexity vs. Exp-Concavity**
  - Why needed here: Determines which algorithm variant applies and the achievable regret rate (logarithmic vs. O(√T)). Exp-concavity is strictly more general.
  - Quick check question: Is f(x) = exp(-x) exp-concave? Is it strongly convex? (Answer: yes, no.)

- **Elliptical Potential Lemma**
  - Why needed here: Bounds Σ ∥g_t∥²_{A^{-1}_t} = O(n ln T) for exp-concave analysis; the delayed variant (Lemma C.1) accounts for |m_t| weighting.
  - Quick check question: For A_t = I + Σ_{τ≤t} g_τ g_τ^⊤, what is ∥g_t∥²_{A^{-1}_t}? (Answer: ≤ 1 always.)

## Architecture Onboarding

- **Component map**: Observation buffer -> Missing set tracker -> Decision updater -> Learning rate scheduler

- **Critical path**:
  1. At round t, play x_t (computed from previous update).
  2. Receive delayed gradients {g_τ : τ + d_τ = t}; update o_{t+1} and m_{t+1}.
  3. Compute a_t, b_t from delay statistics; set η_t.
  4. Solve x_{t+1} = argmin_{x ∈ X} [cumulative loss + regularization].

- **Design tradeoffs**:
  - Computational cost: ONS requires O(n²) per round for matrix operations; FTRL is O(n) for strongly convex case. VAW is O(n²) but handles unconstrained domains.
  - Memory: Must store all past decisions x_s for regularization in FTRL; ONS needs gradient history for A_t. Trade-off between memory and diameter-free bounds.
  - Delay knowledge: Adaptive tuning requires tracking timestamps of received gradients to compute d_≤t_max. If unavailable, fall back to constant learning rate (losing min{} guarantee).

- **Failure signatures**:
  - Regret grows as O(d_max ln T) instead of O(σ_max ln T): Check if regularization includes decisions from m_t (should) vs. only o_t (incorrect).
  - Drift_T explodes: For ONS, verify A_t remains positive definite (η_0 > 0 ensures this). For VAW, check clipping is applied.
  - Adaptive rate never switches regimes: Verify b_t computation includes |m_t| + 1 (not just Σ|m_s|) to anticipate potential growth.

- **First 3 experiments**:
  1. **Strongly convex loss with uniform delay**: Sample d_t ∈ {0,...,5}; compare Algorithm 1 vs. DOGD-SC. Expect σ_max ≈ d_max and √d_tot ≈ √T; both algorithms should show logarithmic regret growth.
  2. **Exp-concave loss with heavy-tailed delay**: Set d_t = T - t with probability 0.1 (otherwise uniform). Here d_max ≈ T but σ_max ≈ 0.1T; verify Algorithm 2 achieves O(σ_max ln T) while DOGD degrades to O(√d_tot).
  3. **Unconstrained OLR with adversarial noise**: Use Pollock-inspired noise (Appendix F); verify clipping prevents gradient explosion and VAW outperforms DOGD in non-stationary settings.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Is it possible to achieve O(min{σ_max n ln T, √d_tot}) regret for exp-concave losses with delayed feedback?
- Basis in paper: [explicit] "It is still left open whether O(min{σ_max n ln T, √dtot}) is achievable for exp-concave losses."
- Why unresolved: The paper achieves this bound for strongly convex losses but only obtains O(min{d_max n ln T, √d_tot}) for exp-concave losses. The analysis techniques differ significantly between the two settings, and the ONS framework does not easily admit the σ_max-based analysis.
- What evidence would resolve it: Either a constructive algorithm achieving O(σ_max n ln T) for exp-concave losses, or a lower bound showing that O(d_max n ln T) is unavoidable in the exp-concave case.

### Open Question 2
- Question: Can the delay-dependent terms in the regret bounds be further improved, particularly achieving O(σ_max ln T) instead of O(σ_max ln T + ln T) for strongly convex losses?
- Basis in paper: [inferred] The regret bound for strongly convex losses includes both σ_max ln T and a separate ln T term. The paper shows these terms can both dominate in different regimes but does not establish whether they can be unified.
- Why unresolved: The analysis decomposes regret into cheating regret and drift terms, with the ln T term arising from the cheating regret independent of delay structure.
- What evidence would resolve it: An improved analysis showing O(σ_max ln T) suffices, or a lower bound demonstrating the additive ln T term is necessary.

### Open Question 3
- Question: What are the minimax optimal regret bounds for delayed OCO under curvature assumptions, particularly distinguishing between σ_max and d_max dependence?
- Basis in paper: [inferred] The paper provides upper bounds but does not establish matching lower bounds for any of the three problem settings (strongly convex, exp-concave, online linear regression).
- Why unresolved: Minimax lower bounds for delayed OCO with curvature remain unexplored in the literature.
- What evidence would resolve it: Derivation of matching lower bounds showing the bounds in Table 1 are tight, or improved algorithms closing any gaps.

### Open Question 4
- Question: Can the adaptive learning rate schemes be designed to avoid requiring knowledge of gradient time-stamps while achieving optimal regret?
- Basis in paper: [inferred] Section 4 notes that the adaptive tuning "requires the knowledge of the time-stamps of the received gradients since we need to compute d^≤t_max."
- Why unresolved: The adaptive learning rate mechanism tracks perceived maximum delay, which requires knowing when each gradient was generated.
- What evidence would resolve it: An algorithm achieving the same regret bounds using only ordinal information about delay magnitudes, without time-stamp knowledge.

## Limitations

- The analysis critically depends on the bounded gradient assumption (Assumption 2.3), which may not hold in practice for unbounded domains without clipping
- Theoretical bounds assume exact solutions to the argmin updates, but numerical optimization errors could degrade performance
- The adaptive learning rate mechanism requires tracking delay statistics across rounds, which may be computationally expensive for large-scale problems

## Confidence

- **High Confidence**: The O(min{σ_max ln T, √d_tot}) regret bound for strongly convex losses (Mechanism 1) - this follows directly from Lemma A.2 and the standard FTRL analysis with proper regularization
- **Medium Confidence**: The adaptive tuning approach for exp-concave losses (Mechanism 2) - while the theoretical framework is sound, the switching between logarithmic and sublinear regimes depends on accurate estimation of delay patterns
- **Medium Confidence**: The clipping trick for unconstrained OLR (Mechanism 3) - theoretically justified but requires careful parameter tuning in practice to balance exploration and stability

## Next Checks

1. **Theoretical verification**: Re-derive the diameter-free regret bound for delayed FTRL by explicitly showing how the regularization term Σ∥x - x_s∥² for all s ∈ [t-1] (not just o_t) enables the critical stability lemma

2. **Experimental stress test**: Implement Algorithm 1 with varying delay distributions (uniform vs. heavy-tailed) and verify that the regret indeed follows O(σ_max ln T) rather than O(d_max ln T) when σ_max ≪ d_max

3. **Numerical implementation**: Compare the empirical regret of the adaptive ONS (Algorithm 2) against both constant learning rate variants to demonstrate the practical benefit of the min{a_t, b_t} switching mechanism across different exp-concavity regimes