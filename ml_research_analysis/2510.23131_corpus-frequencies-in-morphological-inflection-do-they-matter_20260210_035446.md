---
ver: rpa2
title: 'Corpus Frequencies in Morphological Inflection: Do They Matter?'
arxiv_id: '2510.23131'
source_url: https://arxiv.org/abs/2510.23131
tags:
- accuracy
- training
- corpus
- token
- languages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates whether incorporating corpus frequency
  information improves morphological inflection systems. The authors propose three
  methodological improvements: a frequency-weighted lemma-disjoint train-dev-test
  split, token accuracy evaluation that weights correct predictions by word frequency,
  and frequency-aware training that samples frequent words more often during training.'
---

# Corpus Frequencies in Morphological Inflection: Do They Matter?

## Quick Facts
- arXiv ID: 2510.23131
- Source URL: https://arxiv.org/abs/2510.23131
- Reference count: 22
- Primary result: Frequency-aware training with temperature 0.5 improves morphological inflection accuracy in 26 of 43 languages

## Executive Summary
This paper investigates whether incorporating corpus frequency information improves morphological inflection systems. The authors propose three methodological improvements: a frequency-weighted lemma-disjoint train-dev-test split, token accuracy evaluation that weights correct predictions by word frequency, and frequency-aware training that samples frequent words more often during training. Experiments across 43 languages show that frequency-aware training with corpus-frequency temperature 0.5 (sample weights equal to the square root of word frequency) outperforms uniform sampling in 26 languages, with the best model improving over uniform sampling in 26 of 43 languages for token accuracy and 41 of 43 languages for type accuracy.

## Method Summary
The authors extract unique (lemma, tags, form) triples with corpus occurrence counts from Universal Dependencies, then create frequency-weighted lemma-disjoint splits where lemmas are sampled into train weighted by their total occurrence counts. They implement frequency-aware training by introducing sample weights w(A) = (c(A))^τ during batch construction, where c(A) is corpus count and τ is a temperature hyperparameter. Weighted random sampling increases the probability that frequent items appear in each training batch. The method uses a small encoder-decoder Transformer (3 layers, 256 dim, 4 attention heads) and evaluates using both type accuracy (uniform) and token accuracy (frequency-weighted).

## Key Results
- Frequency-aware training with τ=0.5 outperforms uniform sampling in 26 of 43 languages for token accuracy
- Best model improves over uniform sampling in 26 of 43 languages for token accuracy and 41 of 43 languages for type accuracy
- Token accuracy checkpoint selection vs. type-accuracy selection shows negligible difference (≤0.9% absolute)
- τ > 1.0 causes drastic accuracy drops, with macro average collapsing from 86.02% at τ=0.5 to 17.54% at τ=2.0

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Frequency-aware training improves inflection accuracy by biasing gradient updates toward frequent lemma-tag-form triples.
- **Mechanism:** The method introduces sample weights w(A) = (c(A))^τ during batch construction, where c(A) is corpus count and τ is a temperature hyperparameter. Weighted random sampling increases the probability that frequent items appear in each training batch, yielding more gradient signal from patterns that dominate real-world usage.
- **Core assumption:** Frequent words in dev/test sets inflect similarly to frequent words in training (even with lemma-disjoint split), so prioritizing them improves generalization to unseen frequent lemmas.
- **Evidence anchors:** [abstract] "We introduce a method novel in the context of inflection, frequency-aware training, which explicitly incorporates word frequency into the sampling process." [section 3.5] Equations 3-5 define sample weights and sampling probability ratios. [corpus] Weak direct evidence—no corpus papers explicitly validate this mechanism for morphological tasks.
- **Break condition:** If frequent and rare lemmas follow systematically different inflection patterns (e.g., frequent forms are irregular while rare forms are regular), frequency-aware training may hurt generalization.

### Mechanism 2
- **Claim:** Frequency-weighted lemma-disjoint splits produce more realistic train-test distributions while still evaluating generalization.
- **Mechanism:** Lemmas are sampled into train weighted by their total corpus occurrence count; remaining lemmas are split uniformly into dev/test. This ensures high-frequency items populate training while test items remain lemma-unseen, preventing artificial inflation from lemma overlap.
- **Core assumption:** Real-world deployments encounter frequency distributions matching corpus statistics (Zipfian), so training on biased-high-frequency data better prepares models.
- **Evidence anchors:** [abstract] "For train-dev-test split, we combine a lemma-disjoint approach... with a frequency-weighted strategy to better reflect the realistic distribution." [section 3.2] "Sample lemmas first into the train set, randomly, weighted by the occurrence counts." [corpus] Kodner et al. (2023, cited in paper) advocate frequency-weighted splits—no external replication found.
- **Break condition:** If your deployment domain has markedly different frequency distributions (e.g., technical jargon, domain-specific vocabulary), the corpus-weighted split may misrepresent test conditions.

### Mechanism 3
- **Claim:** Token accuracy better predicts real-world performance than type accuracy by weighting evaluation toward frequent forms.
- **Mechanism:** Type accuracy averages uniformly over unique lemma-tag-form triples; token accuracy sums correctness weighted by corpus occurrences (Equation 2). Token accuracy approximates running-text performance, where frequent forms dominate error counts.
- **Core assumption:** Deployment errors on frequent words are more costly than errors on rare words (either by user exposure or downstream impact).
- **Evidence anchors:** [abstract] "We complement the standard type accuracy... with token accuracy, which assigns greater weight to frequent words and better approximates performance on running text." [section 3.3] "Token accuracy corresponds to evaluation over a running text annotated with lemmas and tags." [corpus] Weak—no corpus papers directly compare token vs. type accuracy for deployment prediction.
- **Break condition:** If your application treats all errors equally regardless of frequency (e.g., lexicon completion), token accuracy is the wrong metric.

## Foundational Learning

- **Concept:** Morphological inflection as sequence-to-sequence transduction
  - **Why needed here:** The paper frames inflection as generating an inflected form from (lemma, morphological tags) input using encoder-decoder Transformers.
  - **Quick check question:** Can you explain why inflection is modeled as seq2seq rather than classification?

- **Concept:** Weighted random sampling in stochastic gradient descent
  - **Why needed here:** Frequency-aware training modifies the sampling distribution over training examples, changing which examples contribute to each gradient update.
  - **Quick check question:** If example A has 9× the corpus count of B, what is the probability ratio for sampling A vs. B when τ=0.5?

- **Concept:** Lemma-disjoint evaluation for generalization testing
  - **Why needed here:** The split methodology ensures test lemmas are unseen during training, measuring true morphological generalization rather than memorization.
  - **Quick check question:** Why does lemma overlap inflate reported accuracy?

## Architecture Onboarding

- **Component map:** Data extraction -> Frequency-weighted lemma-disjoint split -> Weighted random sampling with τ -> Encoder-decoder Transformer training -> Token accuracy checkpoint selection -> Type and token accuracy evaluation

- **Critical path:**
  1. Extract triples and counts from UD (Section 3.1)
  2. Implement frequency-weighted lemma-disjoint split (Section 3.2, steps 1-4)
  3. Modify DataLoader to use weighted random sampling via τ-controlled weights (Equation 3)
  4. Train with checkpoint selection on dev token accuracy (Table 1 hyperparameters)
  5. Evaluate on test set reporting both metrics (Table 4 format)

- **Design tradeoffs:**
  - Higher τ → more focus on frequent forms, potential overfitting to high-frequency patterns; τ=2.0 caused near-complete failure
  - Token-accuracy checkpoint selection vs. type-accuracy selection showed negligible difference (≤0.9% absolute)
  - Using UD directly yields lower lemma/form coverage vs. UniMorph alignment (trade-off: simplicity vs. coverage)

- **Failure signatures:**
  - τ > 1.0: Drastic accuracy drops (Table 2 shows macro avg collapsing from 86.02% at τ=0.5 to 17.54% at τ=2.0)
  - Copy baseline wins: Low Saxon and Old French test sets—indicates insufficient training data or extreme morphological complexity
  - Negative τ improvements in English/Galician/Slovak: Rare-form emphasis outperforms frequency-aware training, contrary to hypothesis

- **First 3 experiments:**
  1. **Baseline validation:** Train with τ=0 (uniform sampling), report type and token accuracy on your target language to establish a reference point.
  2. **Temperature sweep:** Run τ ∈ {0.0, 0.3, 0.5, 0.8, 1.0} on a development language; plot token accuracy vs. τ to identify the peak (Section 4.1 pattern: peak near 0.5 for most languages).
  3. **Metric sensitivity check:** Train two models selecting checkpoints by token vs. type accuracy; compare final token accuracy to quantify the selection-metric impact (Section 4.3 reports ≤0.9% difference).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Which specific linguistic or corpus-related properties determine whether a language benefits from frequency-aware training?
- **Basis in paper:** [explicit] The authors note that frequency-aware training improves performance in 26 languages but fails or degrades it in others (e.g., English, Galician, Slovak). In Section 5.1, they explicitly propose investigating "linguistic properties such as morphological richness and regularity, or corpus-related factors such as data size and variability" as future work.
- **Why unresolved:** The paper reports the variability in results across the 43 languages but does not perform a regression or qualitative analysis to correlate success with specific language features.
- **What evidence would resolve it:** A multivariate analysis correlating performance gains (using frequency-aware training) with metrics of morphological complexity, training data size, and frequency distribution skewness.

### Open Question 2
- **Question:** Can extracting frequencies from large raw corpora using automatic tagging improve results compared to using smaller, manually annotated corpora?
- **Basis in paper:** [explicit] In Section 3.1 and 5.1, the authors discuss using Universal Dependencies (UD) directly versus aligning raw text with UniMorph. They "leave the other approaches for future work," specifically suggesting the use of "large raw data... not dropping the UniMorph items with zero actual corpus occurrences."
- **Why unresolved:** The study relied solely on UD data to ensure clean frequency labels, but this limited the lexical coverage compared to UniMorph.
- **What evidence would resolve it:** Experiments comparing models trained on frequencies derived from automatic taggers on raw text against the current UD-based baseline, measuring both coverage and inflection accuracy.

### Open Question 3
- **Question:** Why does tuning the corpus-frequency temperature (τ) based on token accuracy result in greater improvements for type accuracy?
- **Basis in paper:** [explicit] In Section 4.4 and Section 5, the authors describe it as "surprising" that selecting τ based on dev token accuracy yields higher gains in test type accuracy than in token accuracy. They state, "It would be beneficial to explore this more in future work and to seek an explanation."
- **Why unresolved:** The authors hypothesize this may be due to frequent lemmas having a greater variety of distinct forms, but they did not validate this mechanism.
- **What evidence would resolve it:** An analysis of form diversity within high-frequency lemmas and ablation studies to see if frequency weighting inadvertently regularizes the model for diverse morphological paradigms.

## Limitations

- The frequency-weighted lemma-disjoint split may not generalize to languages with extreme morphological complexity where high-frequency lemmas exhibit systematic differences from low-frequency lemmas
- The optimal temperature parameter τ=0.5 may represent a local optimum rather than a universal best practice
- The small Transformer architecture (3 layers, 256 dimensions) may not capture all relevant morphological patterns

## Confidence

**High Confidence**: The empirical finding that frequency-aware training with τ=0.5 improves token accuracy in 26 of 43 languages is well-supported by the experimental results presented in Tables 2 and 4.

**Medium Confidence**: The claim that frequency-weighted lemma-disjoint splits better reflect realistic deployment scenarios is theoretically sound but lacks direct empirical validation.

**Low Confidence**: The assertion that token accuracy better approximates real-world performance than type accuracy is based on conceptual reasoning rather than empirical deployment studies.

## Next Checks

1. **Domain Transfer Validation**: Test frequency-aware training on a language pair where the training corpus and test domain have markedly different frequency distributions (e.g., using web corpus statistics for training but testing on formal literary text).

2. **Error Analysis by Frequency Band**: Conduct a detailed error analysis comparing model performance on high-frequency vs. low-frequency forms for languages where frequency-aware training showed minimal improvement.

3. **Multi-Model Architecture Comparison**: Replicate the experiments using larger Transformer architectures (10+ layers, 512+ dimensions) and modern pretraining approaches.