---
ver: rpa2
title: On the Representations of Entities in Auto-regressive Large Language Models
arxiv_id: '2510.09421'
source_url: https://arxiv.org/abs/2510.09421
tags:
- entity
- mention
- representations
- layer
- tokens
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces entity mention reconstruction as a framework
  to study how LLMs represent and manipulate named entities. It proposes using task
  vectors to decode complete multi-token entity mentions from internal model representations,
  challenging the assumption that last-token embeddings fully capture entity meaning.
---

# On the Representations of Entities in Auto-regressive Large Language Models

## Quick Facts
- arXiv ID: 2510.09421
- Source URL: https://arxiv.org/abs/2510.09421
- Authors: Victor Morand; Josiane Mothe; Benjamin Piwowarski
- Reference count: 32
- This paper introduces entity mention reconstruction as a framework to study how LLMs represent and manipulate named entities.

## Executive Summary
This paper introduces entity mention reconstruction as a framework to study how LLMs represent and manipulate named entities. It proposes using task vectors to decode complete multi-token entity mentions from internal model representations, challenging the assumption that last-token embeddings fully capture entity meaning. Results show that middle-layer representations perform best, entity frequency is more predictive than token length, and context significantly improves decoding. Alternative representations (averaged or cleaned) further improve performance. The method also extends to relation decoding and introduces the Entity Lens for visualizing entity-specific processing across layers.

## Method Summary
The paper introduces a novel framework for studying entity representations in auto-regressive LLMs through entity mention reconstruction. The core methodology involves training a small MLP (task vector) that maps the hidden state of a transformer model to a probability distribution over the vocabulary for the next token in an entity mention. Given an incomplete entity mention (typically just the first token), the model uses this task vector to generate the full entity mention by iteratively predicting subsequent tokens. The authors evaluate performance using exact match accuracy and investigate which layers produce the best representations, finding that middle layers consistently outperform both earlier and later layers. They also explore how different entity representations (raw token embeddings, averaged representations, cleaned representations) affect decoding performance and extend the framework to relation extraction tasks.

## Key Results
- Middle-layer representations consistently outperform both early and late layers for entity mention reconstruction
- Entity frequency correlates more strongly with reconstructability than token length
- Context significantly improves decoding performance, especially for rare entities
- Alternative entity representations (averaged or cleaned) improve performance over raw token embeddings

## Why This Works (Mechanism)
The task vector approach works because it learns a transformation that can decode the complete entity mention from partial internal representations. By training on known entity mentions, the task vector learns to map hidden states to the probability distribution over the vocabulary for the next token in the entity sequence. This allows the model to reconstruct complete multi-token entities from just their first token or other partial representations, revealing how entities are encoded throughout the model's layers.

## Foundational Learning
- **Entity Mention Reconstruction**: A framework for studying how LLMs represent named entities by attempting to reconstruct complete entity mentions from partial internal representations. Why needed: Traditional methods only examine how models handle single tokens, missing the multi-token nature of most named entities. Quick check: Can the model accurately reconstruct "New York City" from just "New" or "New York"?

- **Task Vectors**: Small MLPs trained to map hidden states to probability distributions over the vocabulary for next-token prediction in entity mentions. Why needed: Standard attention mechanisms are insufficient for decoding complete entity mentions from partial representations. Quick check: Does the task vector achieve higher exact match accuracy than direct token prediction?

- **Middle-Layer Optimality**: The empirical finding that middle layers of transformers provide optimal representations for entity manipulation tasks. Why needed: Challenges the assumption that final layer representations are always most informative for all tasks. Quick check: Compare exact match accuracy across all layers to identify the optimal layer(s).

## Architecture Onboarding
**Component Map**: Input token -> Transformer layers -> Hidden state at layer ℓ -> Task vector θ -> Probability distribution over vocabulary -> Generated entity mention

**Critical Path**: The task vector θ must be trained on entity mentions from the training set, then applied to hidden states extracted from specific layers of the frozen transformer model to generate complete entity mentions through iterative decoding.

**Design Tradeoffs**: Using separate task vectors for each layer allows optimal performance but increases parameter count; using a single generalist vector would be more practical but may sacrifice accuracy. The choice between exact match and partial match metrics affects how strictly entity reconstruction quality is measured.

**Failure Signatures**: Poor performance may indicate that entities are not well-represented in the chosen layer, that the task vector is underfit or overfit, or that the entity type is too rare or too common to be effectively reconstructed.

**First Experiments**: 1) Train and evaluate task vectors at each layer to identify optimal layer(s) for entity reconstruction. 2) Compare performance using raw token embeddings versus averaged/cleaned representations. 3) Test generalization by training on one entity type and evaluating on another.

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can a single "generalist" task vector be trained to function effectively across all transformer layers, rather than training separate vectors for each layer?
- Basis in paper: [explicit] The authors state in the Limitations section that current task vectors are layer-specific, and "a more practical implementation would leverage one generalist task vector, which we leave for future work."
- Why unresolved: While the paper demonstrates that task vectors generalize reasonably well to adjacent layers, a universal vector has not yet been successfully trained or evaluated.
- What evidence would resolve it: The successful training of one vector $\theta$ that maintains high exact match performance when decoding entity mentions from representations extracted at any layer $\ell$.

### Open Question 2
- Question: Can beam-search generation be integrated into the Entity Lens to retrieve the "top-k" entity mentions for a given representation?
- Basis in paper: [explicit] The paper notes that the current implementation generates only a single mention, a limitation that "could be addressed by employing beam-search generation."
- Why unresolved: The current methodology produces a single deterministic output, preventing the analysis of alternative entity possibilities the model might associate with a representation.
- What evidence would resolve it: A modified Entity Lens implementation that outputs a ranked list of probable entity mentions with associated probabilities, similar to traditional logit lens top-k token outputs.

### Open Question 3
- Question: Why does averaging token representations improve entity mention decoding while simultaneously degrading the recovery of relational knowledge?
- Basis in paper: [inferred] Section 4 shows averaging representations improves exact match scores for mentions, but Section 5 (Figure 7) shows these same averaged representations perform worse at linear relation decoding.
- Why unresolved: This suggests a trade-off where representations optimized for surface-form reconstruction (mention) lose semantic structure (relations), but the specific features lost or gained are not identified.
- What evidence would resolve it: Probing experiments that disentangle surface-form features from semantic features in the representation subspace, or the discovery of a transformation that improves both tasks simultaneously.

## Limitations
- Focus on English Wikipedia entities may not generalize to other languages or domains
- The reconstruction framework assumes entities follow predictable patterns that may not hold for out-of-distribution entities
- Entity Lens visualization tool requires more extensive validation to establish practical interpretability utility

## Confidence
- **High confidence**: Middle layers provide optimal entity representations; entity frequency correlates more strongly with reconstructability than token length
- **Medium confidence**: Alternative entity representations improve decoding performance; generalization to relation decoding appears methodologically sound
- **Low confidence**: Entity Lens visualization tool's practical utility; assumption that task vectors learned on one entity type will transfer effectively to others

## Next Checks
1. Test the entity mention reconstruction framework on non-English Wikipedia entities and entities from different domains (scientific papers, social media, code) to assess cross-domain generalization.
2. Conduct ablation studies removing context to quantify the exact contribution of surrounding tokens versus the entity's intrinsic representation across different entity types.
3. Validate the Entity Lens tool by conducting user studies with NLP practitioners to assess whether the visualizations actually improve understanding of model behavior compared to baseline interpretability methods.