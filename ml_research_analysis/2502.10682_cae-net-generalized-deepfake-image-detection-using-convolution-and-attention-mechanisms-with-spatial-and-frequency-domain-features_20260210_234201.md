---
ver: rpa2
title: 'CAE-Net: Generalized Deepfake Image Detection using Convolution and Attention
  Mechanisms with Spatial and Frequency Domain Features'
arxiv_id: '2502.10682'
source_url: https://arxiv.org/abs/2502.10682
tags:
- deepfake
- images
- detection
- ensemble
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of deepfake detection in the presence
  of diverse generation techniques and severe class imbalance. The authors propose
  CAE-Net, a convolution- and attention-based weighted ensemble network that combines
  spatial and frequency-domain features.
---

# CAE-Net: Generalized Deepfake Image Detection using Convolution and Attention Mechanisms with Spatial and Frequency Domain Features

## Quick Facts
- arXiv ID: 2502.10682
- Source URL: https://arxiv.org/abs/2502.10682
- Reference count: 40
- Key outcome: CAE-Net achieves 94.46% accuracy and 97.60% AUC on IEEE Signal Processing Cup 2025 dataset using a weighted ensemble of EfficientNet, DeiT, and ConvNeXt with wavelet preprocessing and multistage training.

## Executive Summary
This paper tackles the challenge of deepfake detection in the presence of diverse generation techniques and severe class imbalance. The authors propose CAE-Net, a convolution- and attention-based weighted ensemble network that combines spatial and frequency-domain features. The architecture integrates EfficientNet, DeiT, and ConvNeXt with wavelet preprocessing to learn complementary representations. To handle the 5:1 fake-to-real class imbalance in the IEEE Signal Processing Cup 2025 dataset, they introduce a multistage disjoint-subset training strategy that sequentially trains on non-overlapping fake subsets while retaining knowledge. Their approach achieves 94.46% accuracy and 97.60% AUC, outperforming conventional balancing methods. Visualizations confirm the network focuses on meaningful facial regions, and the ensemble demonstrates robustness against adversarial attacks.

## Method Summary
CAE-Net is a weighted ensemble of three backbones: EfficientNet-B0 for local spatial artifacts, DeiT-B for global contextual relationships, and ConvNeXt-Tiny with wavelet preprocessing for frequency-domain features. The 5:1 class imbalance is addressed through a multistage disjoint-subset training strategy where the fake class is partitioned into five non-overlapping subsets, and the model sequentially trains on each subset with warm-starting across stages. The final prediction is a weighted average of the three models' probabilities (0.35, 0.34, 0.31). The architecture uses 2D-DWT (Haar wavelets) to decompose images into approximation and detail coefficients for the ConvNeXt branch, while DeiT receives augmentation (flip, rotation, color jitter) and all models use Adam optimizer with learning rate 1e-4.

## Key Results
- Achieves 94.46% accuracy and 97.60% AUC on IEEE Signal Processing Cup 2025 validation set
- Outperforms individual backbones (EfficientNet 86.11%, DeiT 89.16%, ConvNeXt 91.24%) and conventional balancing methods
- Ablation study confirms the full ensemble with wavelet preprocessing and multistage training provides optimal performance
- Grad-CAM visualizations show the network focuses on meaningful facial regions rather than background

## Why This Works (Mechanism)

### Mechanism 1: Complementary Feature Extraction via Heterogeneous Ensemble
Combining convolutional, attention-based, and frequency-domain architectures enables more robust deepfake detection than any single backbone by capturing distinct artifact types. EfficientNet uses MBConv with SE blocks to capture local spatial artifacts, DeiT models global contextual relationships through self-attention, and ConvNeXt with wavelet preprocessing detects frequency-domain artifacts. The late fusion of their probability outputs synthesizes these distinct signals into a stronger classification boundary. Evidence shows the full ensemble (94.46%) outperforms individual models, and neighbor papers support multi-domain fusion approaches.

### Mechanism 2: Disjoint-Subset Multistage Training for Class Imbalance
Sequentially training on balanced, non-overlapping subsets of the majority (fake) class while retaining knowledge via weight warm-starting is more effective than conventional balancing techniques for extreme (5:1) imbalance. The large fake class is partitioned into five disjoint subsets, and the model trains in five stages, each using all real images plus one fake subset. Crucially, model weights from stage i warm-start stage i+1, allowing the model to accumulate knowledge of diverse fake types without being overwhelmed. This strategy prevents the gradient dominance issues caused by training on all fakes at once and avoids the overfitting risks of oversampling.

### Mechanism 3: Frequency-Domain Feature Enhancement via Wavelet Transform
Applying 2D Discrete Wavelet Transform as preprocessing exposes high-frequency artifacts that improve detection of manipulated images, complementing spatial analysis. The DWT decomposes images into four sub-bands (approximation and three detail coefficients) which are concatenated and fed to ConvNeXt. Many deepfake generation pipelines fail to perfectly replicate the high-frequency spectral characteristics of natural images, and these imperfections manifest in the wavelet detail coefficients. Comparative analysis shows ConvNeXt with Wavelet (89.49%) outperforms ResNet-34 with Wavelet (80.44%) and other frequency methods.

## Foundational Learning

- **Class Imbalance in Binary Classification**: Understanding how skewed class ratios (5:1 fake-to-real) affect loss functions and model bias is essential to appreciate the necessity of disjoint-subset training. Quick check: Why would a standard model trained on this imbalanced data achieve high accuracy by simply predicting "fake" most of the time, and how does CAE-Net's training strategy counteract this?

- **Discrete Wavelet Transform (DWT) in Image Processing**: Grasping that DWT decomposes images into spatial/frequency sub-bands (approximation and details) is crucial to understanding what features ConvNeXt actually "sees." Quick check: If a fake image has a subtle blending artifact at a face boundary, would it be more likely to appear in the Approximation (LL) or one of the Detail (LH, HL, HH) sub-bands, and why?

- **Late Fusion in Ensemble Learning**: Understanding that the final CAE-Net output is a weighted average of three separate models' probability scores is key to grasping the ensemble architecture. Quick check: What is the advantage of averaging probabilities (late fusion) versus concatenating feature maps from each model and training a single classifier head (early fusion), particularly for model modularity?

## Architecture Onboarding

- **Component map**: Input images → [EfficientNet-B0] → Classification probabilities; Input images → [DeiT-B with augmentation] → Classification probabilities; Input images → [2D-DWT preprocessing] → [ConvNeXt-Tiny] → Classification probabilities; [Weighted fusion layer: 0.35·p_eff + 0.34·p_deit + 0.31·p_conv] → Final prediction

- **Critical path**: Data loading and balancing with 5 disjoint fake subsets; stage-wise training with warm-starting weights across 5 stages (EfficientNet/DeiT: 5 epochs, ConvNeXt: 4 epochs); wavelet preprocessing for ConvNeXt branch; ensemble inference with weighted probability averaging

- **Design tradeoffs**: The ensemble achieves 94.46% accuracy but has 117.4M parameters and 24.8 GFLOPs. For resource-constrained edge deployment, a single EfficientNet-B0 (3.96M params, 0.4 GFLOPs) offers a faster, lighter alternative with ~8% accuracy drop. The optimized weighted ensemble is brittle under FGSM attacks (accuracy drops to ~13-20% at ε=0.01-0.03), while majority voting is more robust under attack but slightly less accurate on clean data.

- **Failure signatures**: Overfitting to repeated real samples across stages can be diagnosed by monitoring per-class validation accuracy; wavelet preprocessing dimension mismatch degrades accuracy by ~5-7%; misdirected attention shown in Grad-CAM visualizations leads to background-focused misclassifications; spectral sensitivity makes ConvNeXt+Wavelet highly vulnerable to adversarial perturbations (accuracy drops to 6.45% at ε=0.01).

- **First 3 experiments**: 1) Train individual backbones (EfficientNet-B0, DeiT-B, ConvNeXt-Tiny with Wavelet) independently on full imbalanced dataset to establish baselines and verify individual underperformance; 2) Compare CAE-Net ensemble trained with standard training vs. disjoint-subset multistage training to validate the core imbalance mechanism; 3) Train ensemble with and without DWT preprocessing on ConvNeXt branch to quantify frequency-domain contribution.

## Open Questions the Paper Calls Out

- **Attention Regularization**: Can attention regularization techniques mitigate misclassifications caused by the models focusing on irrelevant background regions? The paper identifies this issue through Grad-CAM visualizations showing misdirected focus but did not implement specific regularization methods to correct it. Evidence would be improved accuracy and Grad-CAM visualizations restricted to facial regions after implementing attention loss constraints.

- **Compression Robustness**: How robust are the frequency-domain features (wavelets) against common real-world image compression and degradation? The paper notes their evaluation does not assess performance on compressed or degraded images, and robustness of frequency-domain features to such compression artifacts requires further investigation. Evidence would be performance metrics on deepfake datasets subjected to JPEG compression, downsampling, and transmission noise.

- **Generalization to New Methods**: Does the proposed architecture generalize to emerging generation methods such as diffusion models and Neural Radiance Fields (NeRFs)? The paper lists this as a future research direction, noting that current training and validation datasets primarily consist of GAN-based manipulations. Evidence would be benchmarking on datasets containing high-quality deepfakes generated by diffusion and NeRF architectures.

## Limitations

- The disjoint-subset multistage training strategy, while novel, lacks strong corpus evidence for its efficacy and relies on assumptions about knowledge retention that are not fully validated through ablation studies.
- The approach is highly sensitive to adversarial perturbations, with the weighted ensemble's accuracy dropping to ~13-20% under FGSM attacks at ε=0.01-0.03, though majority voting provides better robustness.
- The method does not evaluate performance on compressed or degraded images, leaving open questions about real-world deployment robustness against common transmission artifacts.

## Confidence

- **High Confidence**: The complementary feature extraction via heterogeneous ensemble is well-supported by ablation studies showing the full ensemble (94.46%) outperforms individual models (EfficientNet 86.11%, DeiT 89.16%, ConvNeXt 91.24%) and external literature supporting multi-domain fusion approaches.
- **Medium Confidence**: The disjoint-subset multistage training strategy is novel and logically sound but lacks strong corpus validation and ablation evidence for knowledge retention across stages.
- **Medium Confidence**: The frequency-domain feature enhancement via wavelet is validated by comparative analysis (ConvNeXt with Wavelet 89.49% vs ResNet-34 with Wavelet 80.44%) but assumes spectral artifacts persist in improved deepfakes.

## Next Checks

1. **Probe Knowledge Retention**: Add intermediate validation after each training stage to measure per-class accuracy and track whether the model retains knowledge of earlier fake subsets, addressing the unverified assumption in the multistage training strategy.

2. **Test Stage Generalization**: After training on F1, test the model on F2...F5 to assess how well it generalizes to unseen fake types before full ensemble training, providing evidence for the disjoint-subset approach's effectiveness.

3. **Validate Real Class Stability**: Train the ensemble with and without repeated real samples across stages to isolate the impact of the imbalance strategy on real-class performance and diagnose potential overfitting risks.