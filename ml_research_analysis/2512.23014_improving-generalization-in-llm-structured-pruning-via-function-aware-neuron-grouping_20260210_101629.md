---
ver: rpa2
title: Improving Generalization in LLM Structured Pruning via Function-Aware Neuron
  Grouping
arxiv_id: '2512.23014'
source_url: https://arxiv.org/abs/2512.23014
tags:
- pruning
- sparsity
- neurons
- neuron
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of poor generalization in structured
  pruning of large language models when calibration sets fail to represent the pretraining
  data distribution. The proposed solution, Function-Aware Neuron Grouping (FANG),
  groups neurons by functional roles, prunes each group independently with reweighted
  importance metrics, retains shared neurons contributing across contexts, and adaptively
  allocates sparsity based on functional complexity.
---

# Improving Generalization in LLM Structured Pruning via Function-Aware Neuron Grouping

## Quick Facts
- arXiv ID: 2512.23014
- Source URL: https://arxiv.org/abs/2512.23014
- Reference count: 40
- One-line primary result: FANG achieves state-of-the-art structured pruning results, improving downstream accuracy by 1.5%-8.5% while maintaining low perplexity when combined with FLAP and OBC methods.

## Executive Summary
This paper addresses the critical problem of poor generalization in structured pruning of large language models when calibration sets fail to represent the pretraining data distribution. The proposed Function-Aware Neuron Grouping (FANG) method improves upon existing post-training structured pruning approaches by grouping neurons based on their functional roles in processing different semantic contexts, rather than treating all neurons uniformly. By incorporating semantic context clustering, importance reweighting, shared neuron retention, and adaptive sparsity allocation, FANG achieves significant improvements in downstream task performance while maintaining perplexity comparable to unpruned models.

## Method Summary
FANG groups FFN neurons by functional role using K-Means token clustering on PCA-reduced FFN inputs, computes Taylor-based sensitivity scores, assigns neurons via Linear Assignment Problem to ensure one-to-one matching, prunes each group independently with token-aware reweighting via softmax over negative L2 distances, retains shared neurons selected by multiple clusters, and allocates sparsity adaptively based on Functional Complexity (input-output cosine similarity). The method operates as a drop-in enhancement to existing structured pruning methods like OBC and FLAP, requiring only a small calibration set for neuron importance estimation.

## Key Results
- Achieves 1.5%-8.5% average zero-shot accuracy improvements across 7 downstream tasks (ARC-c, ARC-e, WinoGrande, BoolQ, HellaSwag, OpenBookQA, PIQA) when combined with OBC/FLAP
- Maintains perplexity comparable to unpruned models (PPL ~7.23 for LLaMA2-7B at 30% sparsity)
- Demonstrates state-of-the-art performance on both LLaMA2-7B and LLaMA3.1-8B models at various sparsity levels (20%-40%)
- Ablation studies show shared neuron retention and adaptive sparsity allocation each contribute ~0.5% accuracy improvement

## Why This Works (Mechanism)

### Mechanism 1: Context-Driven Neuron Functional Grouping
Grouping neurons by semantic context types they process improves pruning decisions when calibration data is limited. The method clusters input tokens via K-Means on PCA-reduced FFN inputs, computes sensitivity scores using Taylor expansion, and assigns neurons to functional groups via Linear Assignment Problem to ensure each group contains neurons most relevant to specific token clusters. This assumes neurons exhibit functional specialization, processing distinct semantic context types.

### Mechanism 2: Semantic Distance-Based Importance Reweighting
Weighting tokens by semantic relevance to each neuron group during importance estimation reduces calibration bias. For each group, relevance weights are computed via softmax over negative L2 distances between cluster centers, so tokens semantically aligned with a group's function contribute more to its neuron importance scores. This assumes tokens within a cluster that is semantically closer to group's assigned cluster provide more reliable importance signals.

### Mechanism 3: Shared Neuron Retention for Cross-Context Capacity
Preserving neurons that contribute across multiple context types protects general-purpose capabilities that rigid functional assignment would discard. For each token cluster, top-m scoring neurons are selected, and neurons selected by multiple clusters are ranked by frequency to form a shared group exempt from pruning. This assumes some neurons encode representations useful across diverse contexts.

## Foundational Learning

- **Structured vs. Unstructured Pruning**: FANG operates on structured pruning (removing entire neurons) which enables GPU speedup unlike unstructured sparse weights. Quick check: Can you explain why removing individual weights doesn't directly translate to inference speedup on standard GPUs?

- **Layer-wise Pruning with Reconstruction Error Minimization**: FANG builds on post-training methods like OBC and FLAP that prune each layer independently while minimizing output reconstruction error via Hessian-based compensation. Quick check: Why does layer-wise pruning avoid the need for end-to-end retraining, and what role does the calibration set play?

- **Linear Assignment Problem (LAP)**: Neuron-to-function assignment uses LAP to ensure one-to-one matching between neurons and functional groups, preventing all neurons from clustering on dominant contexts. Quick check: What would happen if neurons were assigned to groups greedily by highest score without the one-to-one constraint?

## Architecture Onboarding

- **Component map**: Context Clustering Module -> Cluster–Neuron Scoring -> Shared Neuron Identifier -> Functional Group Assignment -> Importance Reweighting -> Group-wise Pruning -> Adaptive Sparsity Allocation

- **Critical path**: Context clustering → Score matrix S → Shared neuron identification → Group assignment → Reweighted pruning per group. Errors in clustering propagate through all downstream steps.

- **Design tradeoffs**: K (number of groups) provides finer functional granularity but reduces neurons per group; PCA dimension balances clustering quality and compute; shared group size trades general-purpose capacity vs. achievable sparsity.

- **Failure signatures**: Perplexity spikes with minimal accuracy gain indicates shared group too small or reweighting misconfigured; high variance across downstream tasks suggests functional grouping may be incoherent; excessive runtime indicates context clustering bottleneck.

- **First 3 experiments**:
  1. Apply FANG to OBC on LLaMA2-7B at 30% sparsity with K=7, τ=9; verify PPL and accuracy match Table 1 (PPL ~7.23, Avg ~59.83)
  2. Disable shared neuron retention and adaptive sparsity separately; quantify accuracy drop to isolate contributions (expect ~0.5% each from Table 5)
  3. Visualize t-SNE of token representations colored by K-Means assignments; manually inspect whether clusters capture coherent semantic categories

## Open Questions the Paper Calls Out

- **Open Question 1**: Can the function-aware grouping strategy be effectively adapted for attention head pruning? The method is currently applied only to FFN pruning, leaving attention heads to baseline methods. The FFN-specific intermediate hidden features used for sensitivity scores don't have a direct equivalent in attention mechanisms.

- **Open Question 2**: How sensitive is model performance to the number of functional groups (K) relative to model scale? The paper fixes K=7 for all model sizes (7B to 70B) without providing an adaptive mechanism or ablation study on this hyperparameter.

- **Open Question 3**: Is the fixed ratio between shared and functional neuron groups optimal for all layers? The method sets shared group size m = Nn/(K+1), implicitly assuming shared neurons occupy the same volume as functional groups, but different Transformer blocks may require more or less "general-purpose" capacity.

## Limitations

- The functional grouping mechanism relies heavily on token clustering quality, which is not directly validated in the paper. The assumption that K-Means clustering on PCA-reduced FFN inputs produces semantically coherent groups requires empirical verification.

- The shared neuron retention mechanism lacks theoretical grounding and appears to be a heuristic frequency-based selection criterion rather than a principled decision. The theoretical justification for why frequency of selection across clusters indicates broad utility is not provided.

- The adaptive sparsity allocation based on functional complexity assumes that input-output cosine similarity reliably indicates pruning sensitivity, but this relationship is not empirically validated across diverse model architectures or against alternative complexity metrics.

## Confidence

- **High confidence**: The overall experimental results showing 1.5%-8.5% accuracy improvements when combining FANG with OBC/FLAP across 7 downstream tasks. The perplexity maintenance claims are supported by quantitative results in Table 1.

- **Medium confidence**: The specific mechanisms of functional grouping and importance reweighting. While the mathematical formulations are sound, the assumption that K-Means clustering on PCA-reduced FFN inputs produces semantically coherent groups requires empirical verification.

- **Low confidence**: The theoretical justification for shared neuron retention and adaptive sparsity allocation. These components appear to be engineering choices rather than theoretically motivated decisions.

## Next Checks

1. **Cluster Quality Validation**: Visualize and quantify the semantic coherence of K-Means clusters on a held-out validation set. Use topic modeling or manual inspection to verify that clusters correspond to distinct semantic domains (e.g., code vs. prose vs. reasoning). If clusters are semantically mixed, the functional grouping premise fails.

2. **Temperature Sensitivity Analysis**: Systematically sweep the temperature parameter τ across the full range [3,11] and plot downstream accuracy vs. perplexity trade-offs. The paper only reports τ=9 for LLaMA2-7B and τ=7 for LLaMA3.1-8B without showing sensitivity. Optimal τ should balance token weighting sharpness with stability.

3. **Shared Neuron Ablation with Analysis**: Beyond the single ablation in Table 5, conduct a controlled experiment where the shared group size m varies from 0 to Nn/(K+1). Track both accuracy and perplexity to quantify the trade-off between general-purpose capacity retention and sparsity targets. This reveals whether shared neuron retention is providing genuine benefit or merely reducing effective pruning.