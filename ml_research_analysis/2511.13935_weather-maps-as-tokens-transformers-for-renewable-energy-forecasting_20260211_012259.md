---
ver: rpa2
title: 'Weather Maps as Tokens: Transformers for Renewable Energy Forecasting'
arxiv_id: '2511.13935'
source_url: https://arxiv.org/abs/2511.13935
tags:
- forecasting
- wind
- energy
- renewable
- solar
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a novel transformer-based approach for renewable
  energy forecasting that treats weather maps as tokens, achieving substantial improvements
  over operational baselines. The method encodes hourly weather maps as spatial tokens
  using a lightweight CNN, then processes them with a transformer to capture temporal
  dynamics across a 45-hour horizon.
---

# Weather Maps as Tokens: Transformers for Renewable Energy Forecasting

## Quick Facts
- arXiv ID: 2511.13935
- Source URL: https://arxiv.org/abs/2511.13935
- Reference count: 24
- Key outcome: Achieves 63% reduction in RMSE for wind power forecasting and 20% improvement for solar power versus operational baselines using transformer-based weather map tokenization

## Executive Summary
This paper introduces a novel transformer-based approach for renewable energy forecasting that treats hourly weather maps as tokens. The method encodes 45-hour sequences of weather maps using a lightweight CNN to create spatial tokens, then processes them with a transformer to capture temporal dynamics. Evaluated against ENTSO-E operational forecasts, the model achieves substantial improvements: 63% reduction in RMSE for wind power (from 205.37 MW to 76.06 MW) and 20% improvement for solar power (from 92.89 MW to 73.78 MW). The architecture demonstrates consistent hourly error patterns and superior bias stability, particularly for wind forecasting, while maintaining computational efficiency with only 274,000 parameters and requiring just one to two hours of training on a single GPU.

## Method Summary
The approach encodes hourly weather maps as spatial tokens using a lightweight 2D CNN (two convolutional layers with 16 and 32 filters), then processes them with a transformer to capture temporal dynamics across a 45-hour horizon. Weather maps from the MOLOCH NWP model (1.25 km resolution, 128×256 pixels) are processed independently through the CNN to create 128-dimensional embeddings, augmented with sinusoidal positional encodings, and fed into a 2-block transformer encoder with 4-head attention. The model outputs renewable energy production forecasts for wind and solar power, trained separately due to different input channel requirements.

## Key Results
- Wind power forecasting: 63% reduction in RMSE (from 205.37 MW to 76.06 MW) versus ENTSO-E operational baseline
- Solar power forecasting: 20% improvement in RMSE (from 92.89 MW to 73.78 MW) versus ENTSO-E baseline
- Computational efficiency: 274,000 parameters, trained in 1-2 hours on single NVIDIA A100 GPU
- Stable performance across forecast horizon with limited systematic error degradation over extended lead times

## Why This Works (Mechanism)

### Mechanism 1: Spatial Tokenization Preserves Meteorological Context
The CNN encoder compresses full 128×256 weather maps into single 128-dimensional tokens, preserving spatial patterns that point measurements would miss. This allows the model to capture weather system relationships affecting regional energy production.

### Mechanism 2: Transformer Attention Captures Temporal Dependencies
The sequence of 45 weather tokens with sinusoidal positional encodings enables the transformer to model relationships across the entire forecast horizon, capturing diurnal cycles and weather system propagation better than sequential architectures.

### Mechanism 3: Unified Spatio-Temporal Processing
Unlike staged CNN-LSTM pipelines, feeding spatial tokens directly to the transformer allows attention to operate on jointly-learned representations, potentially reducing information loss from separate spatial and temporal processing stages.

## Foundational Learning

- **Tokenization of structured data**: Understanding how continuous spatial fields become discrete tokens is essential for adapting this architecture to new domains. Quick check: Can you explain why a 128×256 weather map becomes a single 128-dim vector rather than a sequence of patch tokens?

- **Positional encoding in transformers**: The transformer has no inherent notion of temporal order; positional encodings inject this information. Quick check: What would happen to forecast accuracy if positional encodings were removed from a 45-hour weather sequence?

- **Normalization to prevent leakage**: The paper computes normalization exclusively from training years (2017–2022); using validation/test data would artificially inflate performance. Quick check: Why must installed capacity interpolation use only historical data available at forecast time?

## Architecture Onboarding

- **Component map**: Weather maps → CNN encoder (Conv2d→BN→ReLU→Conv2d→BN→ReLU→Global Pool→FC) → Sinusoidal positional encodings → 2-block transformer encoder (4-head attention, FFN dim 256) → Linear prediction head

- **Critical path**: Weather map quality → CNN embedding richness → Transformer attention patterns → Prediction accuracy. The CNN is the bottleneck; if embeddings fail to capture relevant spatial patterns, the transformer cannot recover them.

- **Design tradeoffs**: Single-token-per-map vs. patch-based tokens (current uses one token per hour for computational efficiency); 2-block transformer depth trades expressiveness for fast training; separate models for wind/solar require retraining for different input channels.

- **Failure signatures**: High MAE during midday solar hours indicates cloud-cover encoding failure; degraded wind forecasts in specific seasons may indicate CNN fails to capture certain pressure patterns; R² near zero suggests embeddings lack predictive signal (check CNN gradient flow).

- **First 3 experiments**:
  1. **Ablate CNN depth**: Train with 1 vs. 2 conv layers to verify spatial encoding capacity is sufficient; monitor embedding variance across weather conditions.
  2. **Patch tokenization test**: Replace single-token encoding with 4×4 patch tokens per map to test whether within-map spatial attention improves accuracy.
  3. **Regional transfer**: Train on Sardinia data, evaluate on a different region with same architecture (no retraining) to probe embedding generalization.

## Open Questions the Paper Calls Out

- **Geographic generalization**: Can the approach generalize to regions with different geographical characteristics, climate patterns, and renewable infrastructure beyond the single-region validation in Sardinia? The model was evaluated only on Sardinia and remains untested across diverse geographies.

- **Individual plant-level adaptation**: What modifications are required to adapt the aggregate regional forecasting approach for individual plant-level predictions? The current architecture outputs regional aggregate production and may need plant-specific feature encoding.

- **NWP system sensitivity**: How sensitive is forecasting accuracy to the choice and quality of the underlying Numerical Weather Prediction system? The study uses only the MOLOCH model, and gains may not transfer across different NWP inputs.

## Limitations

- **Geographic scope**: Evaluation limited to single region (Sardinia), raising questions about generalization to different terrains and climate zones
- **Architecture capacity**: Shallow 2-block transformer may underfit complex weather regimes despite computational efficiency
- **Temporal resolution**: Fixed 1-hour intervals may miss rapid weather transitions affecting renewable generation

## Confidence

**High Confidence**: Computational efficiency claims (training time, parameter count) and specific numerical improvements over ENTSO-E baselines for Sardinia data are directly measurable and reproducible.

**Medium Confidence**: General pattern that transformers outperform traditional methods for renewable energy when using weather maps as tokens, though geographic generalization remains unproven.

**Low Confidence**: Claims about the "unified framework" enabling rapid regional adaptation and superiority of the "weather maps as tokens" paradigm over all existing approaches require broader validation.

## Next Checks

1. **Geographic transferability test**: Train on Sardinia data, evaluate on a different region without retraining to quantify geographic generalization limits and test whether embeddings capture universal weather-to-energy relationships.

2. **Resolution sensitivity analysis**: Re-train with MOLOCH data at 2.5 km resolution and compare performance to validate whether 1.25 km resolution is critical for claimed improvements.

3. **Tokenization granularity experiment**: Replace single-token-per-hour encoding with 4×4 patch tokens while maintaining same transformer architecture to identify whether within-map spatial attention provides meaningful improvements.