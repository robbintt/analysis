---
ver: rpa2
title: Probabilistically Tightened Linear Relaxation-based Perturbation Analysis for
  Neural Network Verification
arxiv_id: '2507.05405'
source_url: https://arxiv.org/abs/2507.05405
tags:
- bounds
- verification
- neural
- reachable
- crown
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a probabilistic framework for neural network
  verification that improves upon deterministic and existing probabilistic methods
  by providing tighter linear relaxation bounds with quantifiable confidence guarantees.
  The core idea combines statistical tolerance limits (Wilks' theorem) with extreme
  value theory to compute probabilistically sound intermediate reachable sets, which
  are then integrated into LiRPA-based verification methods.
---

# Probabilistically Tightened Linear Relaxation-based Perturbation Analysis for Neural Network Verification

## Quick Facts
- arXiv ID: 2507.05405
- Source URL: https://arxiv.org/abs/2507.05405
- Reference count: 12
- Primary result: Probabilistic framework achieving 1.4x-3.62x tighter certified bounds than deterministic methods

## Executive Summary
This paper introduces a probabilistic framework for neural network verification that improves upon deterministic and existing probabilistic methods by providing tighter linear relaxation bounds with quantifiable confidence guarantees. The core idea combines statistical tolerance limits (Wilks' theorem) with extreme value theory to compute probabilistically sound intermediate reachable sets, which are then integrated into LiRPA-based verification methods. By using sampling to estimate node bounds and adding EVT-based error corrections, the approach achieves tighter final output bounds while maintaining probabilistic soundness over the entire perturbation region.

## Method Summary
The method samples n random inputs uniformly from the perturbation region C, propagates them through the network to estimate intermediate neuron bounds, and applies EVT correction to quantify estimation error. These tightened bounds replace the standard reachable sets in LiRPA backward propagation (CROWN/α-CROWN/β-CROWN), producing probabilistically sound linear bounds. The approach requires 350k samples, ξ=0.85 parameter, and p=0.005 for 99% confidence, with minimal computational overhead (<1s per verification) due to GPU acceleration.

## Key Results
- Achieves 1.4x-3.62x improvement in certified robustness bounds over CROWN on VNN-COMP benchmarks
- Up to 3.31x improvement over other probabilistic methods (PROVEN, Randomized Smoothing)
- Provides at least 99% confidence guarantees on challenging verification benchmarks
- Minimal computational overhead compared to baseline deterministic methods

## Why This Works (Mechanism)

### Mechanism 1: Sample-Based Reachable Set Tightening
Uniform sampling within perturbation region C produces tighter intermediate bounds than worst-case over-approximation methods. Propagate n random samples through network, compute min/max pre-activation values at each neuron. Use Wilks' theorem to guarantee that with confidence ψ, at most fraction (1-R) of future samples violate bounds. EVT bounds magnitude of violations using order statistics Y₁, Y₂, ..., Yₙ.

### Mechanism 2: Probabilistic Linear Relaxation
Substituting tightened bounds into LiRPA diagonal matrices produces linear bounds that are probabilistically sound for the entire region C. Replace LiRPA's reachable sets [l_j, u_j] with EVT-corrected estimates [ĉl_j, û_j] in computing D^(i) diagonal matrices and b^(i) bias vectors. Bounds propagate backward through layers via A^(i) = A^(i+1)D^(i)W^(i).

### Mechanism 3: Confidence-Tightness Tradeoff
For moderate confidence (≤99.5%), PT-LiRPA produces tighter bounds; for higher confidence, bounds loosen and may exceed worst-case methods. Error term (Y₂-Y₁)/((1-p)^(-a)-1) grows as p→0, requiring larger safety margins.

## Foundational Learning

- **Linear Relaxation (LiRPA/CROWN):** Why needed: Core framework PT-LiRPA modifies. Quick check: Can you compute D^(i) diagonal matrix for unstable ReLU given bounds [l, u]?
- **Statistical Tolerance Limits (Wilks' Theorem):** Why needed: Determines sample size for guaranteed coverage. Quick check: Given R=0.999, ψ=0.99, calculate minimum n using n ≥ ln(1-ψ)/ln(R)
- **Extreme Value Theory (Order Statistics):** Why needed: Bounds magnitude of estimation errors. Quick check: Given sorted samples Y₁ ≤ Y₂ ≤ ... ≤ Yₙ, which values estimate tail index a?

## Architecture Onboarding

- **Component map:** Input (x₀, ε) → [PGD Attack] → [Uniform Sampling n points] → [Forward Pass: compute z(x) for each sample] → [Order Statistics + EVT correction (Alg 4)] → [LiRPA Backward Pass with tightened bounds (Alg 1)] → [Branch & Bound if needed (Alg 3)]
- **Critical path:** The EVT error estimation (Alg 4, lines 6-9) determines final bound quality. Incorrect tail index a → wrong error bounds → unsound verification.
- **Design tradeoffs:** Sample size n: Larger → tighter bounds but more GPU memory (350k works for CIFAR-scale); ξ parameter: Controls ν=⌊n^ξ⌋ order statistics used; 0.85 balances stability/accuracy; Confidence 1-2mp: Higher → looser bounds; 99% is practical sweet spot
- **Failure signatures:** Bounds looser than worst-case: Check if confidence >99.5% or sample size insufficient; Memory errors on large networks: Reduce batch size in sampling; NaN in tail index a: Y₃-Y₂ may be zero; increase sample size
- **First 3 experiments:** 1) Reproduce toy example (Fig. 5): Run PT-LiRPA on 2-layer network with n=10k, compare bounds to MIP ground truth; 2) Ablation on ξ: Test ξ∈{0.2, 0.5, 0.85, 0.95} on MNIST_3×[1024], measure mean error (expect Fig. 6 pattern); 3) VNN-COMP benchmark: Run CIFAR_biasfield with n=350k, compare verified accuracy to α,β-CROWN baseline (expect Table 4 results)

## Open Questions the Paper Calls Out

### Open Question 1
Can a closed-form expression be derived to determine the minimum number of samples required by the EVT-based bounds to achieve a specific precision and confidence level? The paper notes that unlike Wilks' theorem, Extreme Value Theory (Theorem 3.7) does not yield a closed-form expression for the minimum sample size, forcing the balance between tightness and soundness to be empirical. A theoretical derivation providing a formula for n based on p and Δ that does not require iterative doubling or empirical guessing would resolve this.

### Open Question 2
Does using adaptive or importance sampling strategies, rather than uniform random sampling, improve the efficiency or tightness of the estimated reachable sets? Section 6 states the framework relies on the assumption of uniform random sampling and that theoretical guarantees assume samples are representative of the true input distribution. Experiments comparing uniform sampling against gradient-guided or importance sampling methods, showing comparable or tighter bounds with fewer samples, would resolve this.

### Open Question 3
How effectively does PT-LiRPA scale to verification specifications beyond the ℓ∞ norm, such as geometric transformations or non-convex input constraints? The authors claim in Section 2.2 that PT-LiRPA is applicable whenever the underlying LiRPA method supports specifications beyond ℓ∞, but the empirical evaluation focuses primarily on ℓ∞ benchmarks. Empirical results on benchmarks like ACAS Xu (geometric) or other VNN-COMP tracks featuring non-standard perturbation sets would resolve this.

## Limitations
- EVT tail index estimation may be unstable for highly irregular ReLU activations or pathological network architectures
- Sample size scalability could face memory bottlenecks for deeper networks with 10^5+ nodes despite GPU acceleration
- Confidence-tidiness tradeoff means bounds loosen above 99.5% confidence, potentially exceeding worst-case methods

## Confidence
- PT-LiRPA achieves 1.4x-3.62x tighter bounds than CROWN: High confidence (supported by extensive VNN-COMP experiments across multiple architectures)
- Probabilistic soundness with quantifiable guarantees: High confidence (grounded in Wilks' theorem and EVT with explicit error terms)
- Minimal computational overhead: Medium confidence (typically <1s overhead reported, but not validated across diverse hardware configurations)

## Next Checks
1. **EVT Stability Analysis:** Systematically vary ξ ∈ [0.5, 0.95] and sample size n ∈ [50k, 500k] across all VNN-COMP benchmarks to measure tail index a stability and bound sensitivity. Plot coefficient of variation for a estimates to quantify estimator reliability.

2. **Scalability Benchmark:** Test PT-LiRPA on deeper MLPs (10+ layers, 4096+ neurons/layer) and ResNet variants from VNN-COMP, measuring memory usage and runtime scaling. Identify the exact depth/width threshold where OOM occurs and propose memory-efficient alternatives.

3. **Extreme Confidence Validation:** Run PT-LiRPA at p=0.001 (99.9% confidence) on ACAS xu and TinyImageNet benchmarks to empirically verify whether bounds indeed exceed worst-case CROWN bounds, as theoretically predicted in Fig. 8.