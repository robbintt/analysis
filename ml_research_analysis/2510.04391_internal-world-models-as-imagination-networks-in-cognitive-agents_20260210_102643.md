---
ver: rpa2
title: Internal World Models as Imagination Networks in Cognitive Agents
arxiv_id: '2510.04391'
source_url: https://arxiv.org/abs/2510.04391
tags:
- imagination
- networks
- world
- vividness
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether internal world models (IWMs) differ
  between humans and large language models (LLMs) using imagination networks derived
  from vividness ratings of imagined scenarios. Researchers constructed imagination
  networks from responses to two questionnaires (VVIQ-2 and PSIQ) across three human
  populations (Florida, Poland, London; N=2,743) and six LLM variants.
---

# Internal World Models as Imagination Networks in Cognitive Agents

## Quick Facts
- **arXiv ID:** 2510.04391
- **Source URL:** https://arxiv.org/abs/2510.04391
- **Authors:** Saurabh Ranjan; Brian Odegaard
- **Reference count:** 40
- **Key outcome:** Human imagination networks show consistent clustering and centrality correlations while LLM networks exhibit minimal clustering and weak correlations, revealing fundamental disparities in internal world models

## Executive Summary
This study investigates whether internal world models (IWMs) differ between humans and large language models (LLMs) using imagination networks derived from vividness ratings of imagined scenarios. Researchers constructed imagination networks from responses to two questionnaires (VVIQ-2 and PSIQ) across three human populations (Florida, Poland, London; N=2,743) and six LLM variants. The networks captured associations between vividness ratings of different imagined scenarios, with centrality measures and clustering patterns used to characterize IWMs. Human imagination networks showed consistent correlations across centrality measures and clear clustering patterns reflecting the questionnaire structure, indicating shared IWM organization. In contrast, LLM-derived networks exhibited minimal clustering and weak centrality correlations, even when manipulating conversational memory. These systematic differences persisted across both environmental scenes and sensory modalities, revealing fundamental disparities between human and artificial world models. The network-based approach provides a quantitative framework for comparing internally-generated representations across cognitive agents.

## Method Summary
The study compared internal world models by constructing "imagination networks" from vividness ratings using the VVIQ-2 (32 visual items) and PSIQ (21 sensory items) questionnaires. Researchers collected data from N=2,743 humans across Florida, Poland, and London, and simulated 1,000 runs per LLM model using 200 random personas from Persona-Chat and 5 imagery ability definitions. LLM outputs were filtered using "Population Diversity Sampling" to match human total vividness score quantiles. Networks were estimated using EBICglasso with Spearman correlations and gamma=0.5 tuning. The study compared networks at micro-level (centrality correlations) and meso-level (cluster alignment via Adjusted Rand Index using Walktrap algorithm) to identify systematic differences between human and LLM IWMs.

## Key Results
- Human imagination networks showed consistent correlations across centrality measures (Expected Influence, Strength, Closeness, Betweenness) while LLM networks showed minimal correlation
- Human networks exhibited clear clustering patterns aligned with questionnaire structure, whereas LLM networks showed minimal clustering across all models and conditions
- These systematic differences persisted across both environmental scenes (VVIQ-2) and sensory modalities (PSIQ), with no improvement from cumulative memory conditions

## Why This Works (Mechanism)
The network-based approach captures the associative structure of internal world models by treating vividness ratings of different imagined scenarios as interconnected nodes. By applying graphical lasso with EBIC regularization, the method identifies statistically significant associations between scenarios while controlling for spurious correlations. The consistency in human networks reflects shared cognitive structures for organizing and relating different types of imagery, while the fragmentation in LLM networks suggests artificial systems process these tasks through fundamentally different mechanisms that don't form the same associative patterns.

## Foundational Learning
- **Graphical Lasso (GLASSO):** Regularized precision matrix estimation that identifies conditional independence relationships between variables. Needed to construct sparse networks from correlation data while avoiding overfitting.
  - Quick check: Verify positive definiteness of estimated precision matrices
- **EBIC tuning parameter (gamma):** Controls regularization strength in graphical models, balancing model complexity and fit. Required to identify statistically meaningful edges in the network.
  - Quick check: Compare networks across gamma values (0.25, 0.5, 0.75) to ensure results are robust
- **Adjusted Rand Index (ARI):** Measures similarity between cluster assignments while correcting for chance agreement. Essential for quantifying cluster alignment between human and LLM networks.
  - Quick check: Calculate ARI between multiple human populations to establish baseline similarity
- **Centrality measures (Expected Influence, Strength, Closeness, Betweenness):** Capture different aspects of node importance in networks. Needed to characterize the structural role of different imagery scenarios.
  - Quick check: Verify centrality measures are stable using bootstrap methods
- **Population Diversity Sampling:** Quantile-based filtering procedure that matches LLM output distributions to human reference groups. Required to ensure fair comparison between human and artificial systems.
  - Quick check: Visualize distributions before and after sampling to confirm matching
- **Walktrap algorithm:** Community detection method based on random walks that identifies clusters in networks. Used to identify meaningful groupings in imagination networks.
  - Quick check: Compare Walktrap results with alternative clustering methods (e.g., Louvain)

## Architecture Onboarding
**Component Map:** Human Data Collection -> LLM Simulation -> Population Diversity Sampling -> Network Estimation -> Centrality Extraction -> Cluster Analysis -> Comparison

**Critical Path:** LLM Simulation → Population Diversity Sampling → Network Estimation → Comparison Metrics. This sequence is critical because the sampling step ensures fair comparison, and the network estimation step determines the structural features being compared.

**Design Tradeoffs:** The study prioritizes methodological rigor over model diversity, using only six LLM variants but with extensive persona variation (1,000 simulations per model). This allows deep exploration of within-model variability while maintaining comparability across different model families.

**Failure Signatures:** LLM networks producing single clusters (ARI=0) or fully connected graphs indicate issues with the EBIC penalty strength or input variance. Low centrality stability (CS-coefficients < 0.25) suggests using Spearman correlations instead of polychoric.

**Three First Experiments:**
1. Test network construction without Population Diversity Sampling to assess impact of distribution matching
2. Vary EBIC gamma parameter (0.25, 0.75) to test robustness of network structure to regularization
3. Apply identical network analysis to humans with constrained memory conditions to test whether memory affects network properties

## Open Questions the Paper Calls Out
- **Open Question 1:** Can the consistency of human internal world models (IWMs) be explained by the presence of shared "recovery maps" that approximate environmental transition states?
  - Basis in paper: [explicit] The Discussion section states, "It could be due to the presence of similar recovery map... Future empirical work will help to disentangle how recovery maps and network measures can both contribute to understanding of IWMs."
  - Why unresolved: While the study establishes that human populations share similar network structures, it does not empirically verify if this similarity stems from a shared computational mechanism for predicting environmental states.
  - What evidence would resolve it: Empirical data correlating the observed imagination network structures with independent behavioral measurements of state transition recovery maps in human agents.

- **Open Question 2:** Can LLM prompting or persona design be optimized to induce imagination networks that are structurally similar to those of humans?
  - Basis in paper: [explicit] The authors note, "However, it is not yet known how a persona can be designed that enables LLMs to possess a human-like richness of phenomenological experience, under which LLMs show high similarity to our measurements with humans."
  - Why unresolved: Current methods of inducing personas and imagination abilities produced vividness ratings in LLMs, but the resulting networks failed to show the clustering alignment and centrality correlations observed in humans.
  - What evidence would resolve it: The identification of specific prompting strategies or training regimes that result in LLM-derived networks with statistically significant Adjusted Rand Index (ARI) and centrality correlations compared to human networks.

- **Open Question 3:** How do internal world models differ when processing static versus dynamic imagination tasks?
  - Basis in paper: [explicit] The authors state, "Future research can explore dynamical properties of world models using network based methods using imagination of dynamical experiences."
  - Why unresolved: The questionnaires used (VVIQ-2 and PSIQ) primarily capture static or reproductive imagination scenarios, leaving the properties of dynamic imagination networks unexplored.
  - What evidence would resolve it: A comparative network analysis using tasks specifically designed to probe dynamic imagery (e.g., imagining moving objects or temporal sequences).

## Limitations
- The "Population Diversity Sampling" procedure cannot be exactly replicated without access to the raw human data (Florida dataset listed as "upon publication")
- LLM simulation lacks specification of crucial inference parameters (temperature, top-p, seeds) that significantly influence vividness rating variability
- The interpretation of network differences as fundamental disparities in "internal world models" is medium confidence due to alternative explanations including prompt engineering limitations

## Confidence
- **Human network consistency finding:** High confidence - supported by multiple robustness checks across different questionnaire structures, centrality measures, and memory conditions
- **LLM network fragmentation finding:** High confidence - systematic differences observed across all six models and conditions
- **Interpretation as fundamental IWM disparities:** Medium confidence - while network metrics differ substantially, alternative explanations exist

## Next Checks
1. Release the raw Florida human dataset to enable exact replication of the Population Diversity Sampling procedure
2. Systematically vary LLM sampling parameters (temperature, top-p, seeds) to test whether network differences persist across different levels of output diversity
3. Apply the same network analysis framework to humans with artificially constrained memory (e.g., asking participants to answer all items in a single session vs separated by time) to test whether the "cumulative memory" condition affects human network properties similarly to LLMs