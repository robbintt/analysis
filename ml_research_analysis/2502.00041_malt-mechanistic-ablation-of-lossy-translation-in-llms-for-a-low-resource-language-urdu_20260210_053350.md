---
ver: rpa2
title: 'MALT: Mechanistic Ablation of Lossy Translation in LLMs for a Low-Resource
  Language: Urdu'
arxiv_id: '2502.00041'
source_url: https://arxiv.org/abs/2502.00041
tags:
- llms
- translation
- languages
- language
- low-resource
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of poor performance of large
  language models (LLMs) on low-resource languages like Urdu, which are underrepresented
  in training data. The core idea is that LLMs primarily reason in English even when
  prompted in another language, with final layers acting as lossy translators to the
  target language.
---

# MALT: Mechanistic Ablation of Lossy Translation in LLMs for a Low-Resource Language: Urdu

## Quick Facts
- **arXiv ID**: 2502.00041
- **Source URL**: https://arxiv.org/abs/2502.00041
- **Reference count**: 11
- **Primary result**: Ablating lossy translation features and using external MT improves Urdu performance: Llama-3.2-3b from 11.6% to 55%, Gemma-2-2b from 0% to 15.6%

## Executive Summary
This paper addresses the challenge of poor LLM performance on low-resource languages like Urdu, which are underrepresented in training data. The core insight is that LLMs primarily reason in English internally, with final layers acting as lossy translators to the target language. MALT mechanistically removes these translation features from the final layers and replaces them with a dedicated machine translation model. Experiments on Gemma-2-2b and Llama-3.2-3b show significant improvements, with Llama-3.2-3b accuracy increasing from 11.6% to 55%. The approach preserves cultural nuances while producing more coherent responses.

## Method Summary
The MALT method identifies translation direction in the residual stream by computing mean activations for English and Urdu prompts at a target layer, then ablating this direction during inference. The model outputs an English latent response, which is translated to Urdu using a fine-tuned mBART model. For Gemma-2-2b, layer 24 is targeted; for Llama-3.2-3b, layer 25. The translation direction is computed as the normalized difference between mean Urdu and English activations, then subtracted from residual activations during generation.

## Key Results
- Llama-3.2-3b accuracy improved from 11.6% to 55% on Urdu tasks
- Gemma-2-2b accuracy improved from 0% to 15.6% on Urdu tasks
- Qualitative analysis shows preserved cultural nuances in responses
- Ablation successfully suppresses translation features while maintaining reasoning capabilities

## Why This Works (Mechanism)

### Mechanism 1: English-Centric Internal Reasoning
LLMs process non-English prompts by reasoning internally in English, with final layers responsible for translation to the target language. When prompted in Urdu, the model encodes input, processes through early/middle layers in English latent representation, and applies translation features in final layers. Core assumption: English latent representation contains coherent reasoning degraded during translation step.

### Mechanism 2: Lossy Translation Features in Final Layers
Translation from English to low-resource languages is mediated by a small number of neurons in final layers, causing significant degradation. The translation direction is concentrated in a single direction; ablating it suppresses translation while preserving the English latent response. Core assumption: Translation features are localized enough that ablation removes them without damaging reasoning.

### Mechanism 3: External Translation Model Replacement
Replacing internal translation features with dedicated MT produces more fluent outputs while preserving cultural nuances. After ablation, the model outputs English latent response, which is translated to Urdu using fine-tuned mBART. Core assumption: External translation model is sufficiently accurate for target language and domain.

## Foundational Learning

**Concept: Residual Stream Ablation**
- Why needed: Core intervention ablates direction in residual stream to suppress translation features
- Quick check: Can you explain how subtracting projection of activations onto a direction vector removes that feature?

**Concept: Language-Specific Neurons in LLMs**
- Why needed: Paper assumes translation features are localized to specific neurons/layers
- Quick check: Where would you look in an LLM to find features responsible for generating text in a specific language?

**Concept: Polysemanticity in Neural Networks**
- Why needed: Paper attributes errors to ablating non-translation features due to polysemantic neurons
- Quick check: Why might ablating one feature unintentionally affect other capabilities in a neural network?

## Architecture Onboarding

**Component map**: Input (Urdu prompt) -> LLM (Gemma-2-2b/Llama-3.2-3b) -> Ablation Layer (target layer) -> External Translation Model (fine-tuned mBART) -> Output (Urdu response)

**Critical path**:
1. Cache residual activations for English and Urdu prompts at target layer
2. Compute translation direction as normalized difference of mean activations
3. Ablate translation direction during inference to suppress translation features
4. Extract English latent response from ablated model
5. Translate English response to Urdu using external model

**Design tradeoffs**:
- Ablation precision vs. collateral damage: Ablation may remove non-translation features due to polysemanticity, causing fluency or relevance errors
- Model size vs. feature distribution: Larger models may have translation features distributed across multiple layers
- Cultural nuance preservation vs. translation quality: Paper claims nuances preserved but not quantitatively verified

**Failure signatures**:
- Fluency errors: Incoherent output with random characters
- Repetition errors: Model repeats query without generating answer
- Non-relevant errors: Coherent but irrelevant response, possibly due to poor input understanding

**First 3 experiments**:
1. Replicate ablation on Llama-3.2-3b with Urdu prompts and verify English latent response quality
2. Compare ablation performance across multiple low-resource languages to test generalizability
3. Test alternative translation models (e.g., NLLB, Google Translate) to evaluate sensitivity to translation quality

## Open Questions the Paper Calls Out

**Open Question 1**: Does the single-direction translation mechanism persist in larger LLMs (7B+ parameters), or do features become distributed across multiple layers?
- Basis: Authors note translation features "expected to become more distributed across multiple final layers" in larger models
- Status: Unresolved due to computational limitations to smaller models

**Open Question 2**: How does MALT generalize to low-resource languages with linguistic structures distinct from Urdu?
- Basis: "It remains to be seen how MALT generalizes to other low resource languages"
- Status: Unresolved; study exclusively used Urdu

**Open Question 3**: Can preservation of cultural nuances be quantitatively verified?
- Basis: "Although there are indications that cultural nuances are preserved, this observation has not been quantitatively verified"
- Status: Unresolved; findings rely on qualitative observation

**Open Question 4**: Does ablation of translation features inadvertently degrade safety alignment?
- Basis: "It remains to be studied whether ablated translation features affect the alignment of LLMs"
- Status: Unresolved; modifying residual stream could interfere with safety features

## Limitations

- Dataset of 239 question