---
ver: rpa2
title: 'After Retrieval, Before Generation: Enhancing the Trustworthiness of Large
  Language Models in RAG'
arxiv_id: '2505.17118'
source_url: https://arxiv.org/abs/2505.17118
tags:
- knowledge
- question
- external
- internal
- answer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# After Retrieval, Before Generation: Enhancing the Trustworthiness of Large Language Models in RAG

## Quick Facts
- arXiv ID: 2505.17118
- Source URL: https://arxiv.org/abs/2505.17118
- Authors: Xinbang Dai; Huikang Hu; Yuncheng Hua; Jiaqi Li; Yongrui Chen; Rihui Jin; Nan Hu; Guilin Qi
- Reference count: 40
- Primary result: BRIDGE improves trustworthiness in RAG by dynamically allocating knowledge collection between retrieval and generation, using a soft bias mechanism and decision tree to manage conflicts.

## Executive Summary
BRIDGE is a framework designed to enhance the trustworthiness of large language models in retrieval-augmented generation (RAG) systems. It introduces a dynamic "soft bias" mechanism to allocate queries between a retriever and a generator, guided by an Allocator module that estimates retrieval and generation dependency probabilities. A Maximum Soft-bias Decision Tree then selects an optimal response strategy (e.g., trust internal, trust external, integrate, or refuse) based on consistency and confidence scores. The framework is evaluated on the TRD benchmark, demonstrating improved accuracy and rejection rates compared to standard RAG baselines.

## Method Summary
BRIDGE constructs the TRD benchmark from NQ and TAQA, then trains an Allocator (via GRPO or ICL) to estimate retrieval ($r_p$) and generation ($g_p$) dependency probabilities for each query. Sub-queries are routed accordingly to a Multi-query Retriever or Multi-query Generator. A BGE-m3 scorer computes multi-granularity similarity scores between knowledge sources. A Maximum Soft-bias Decision Tree uses these scores and the Allocator’s biases to select one of four response strategies (FA, FI, FE, RA). For mid-confidence cases, a reflection loop iteratively refines queries up to three times. The system is evaluated on accuracy, rejection rate, exact match, and efficiency.

## Key Results
- BRIDGE improves trustworthiness in RAG by dynamically allocating knowledge collection between retrieval and generation.
- The soft bias mechanism and decision tree effectively manage conflicts between internal and external knowledge sources.
- The framework is evaluated on the TRD benchmark, demonstrating improved accuracy and rejection rates compared to standard RAG baselines.

## Why This Works (Mechanism)

### Mechanism 1
Dynamic "soft bias" allocation between knowledge sources guides the system toward the most promising information path. An Allocator module predicts retrieval-dependency ($r_p$) and generation-dependency ($g_p$) probabilities for each query, steering the system to rely more on internal parameters for stable facts or external retrieval for new information. Core assumption: the Allocator can be accurately calibrated to infer a question's temporal sensitivity or domain-specificity. Evidence: the Allocator produces $r_p$ and $g_p$ to allocate sub-queries. Break condition: Allocator misjudges a query, directing a question about a very recent event to the generator instead of the retriever.

### Mechanism 2
An interpretable decision tree selects an explicit response strategy, preventing naive knowledge merging. A "Maximum Soft-bias Decision Tree" uses computed confidence scores and consistency checks to select one of four discrete strategies: Integrate All (FA), Trust Internal (FI), Trust External (FE), or Refuse (RA). This replaces a single, monolithic generation prompt with conditional logic. Core assumption: calculated scores for knowledge quality and consistency are reliable proxies for making trust-based decisions. Evidence: the framework uses a "Maximum Soft-bias Decision Tree to evaluate knowledge and select optimal response strategies." Break condition: thresholds are poorly tuned, causing over-refusal on answerable questions or misplaced trust in a single corrupted source.

### Mechanism 3
A scoring and reflection loop refines decisions in ambiguous, mid-confidence cases. A Knowledge Scorer computes multi-granularity matching scores across all four knowledge sources. If the decision tree returns a mid-range confidence score, a reflection module re-writes sub-queries and re-runs the collection process. Core assumption: inconsistencies are detectable via semantic similarity metrics and can be resolved by iterative query refinement. Evidence: the framework "dynamically determines a comprehensive response strategy." Break condition: reflection queries drift or do not retrieve better evidence after three iterations, forcing a default refusal.

## Foundational Learning

- **Concept: Knowledge Conflicts in RAG**
  - Why needed here: The entire BRIDGE framework is designed to detect and manage conflicts between a model's internal (parametric) knowledge and external retrieved context.
  - Quick check question: Can you explain the difference between parametric and retrieved knowledge and why they might contradict?

- **Concept: In-Context Learning (ICL) vs. Fine-Tuning (GRPO)**
  - Why needed here: The paper presents two paradigms for the Allocator: using ICL with retrieved examples versus fine-tuning a model with GRPO. Understanding this trade-off is crucial for implementation.
  - Quick check question: How does the Allocator’s role differ between the ICL and GRPO paradigms described in the paper?

- **Concept: Multi-Granularity Text Embeddings**
  - Why needed here: The Knowledge Scorer relies on combining different matching signals—lexical (sparse), semantic (dense), and token-level (ColBERT)—to judge consistency.
  - Quick check question: Why would a system use multiple types of similarity scores (sparse, dense, ColBERT) instead of just one?

## Architecture Onboarding

- **Component map:**
  1. User Question (Input)
  2. Soft Bias Allocator: Estimates $r_p$ (retrieval bias) and $g_p$ (generation bias)
  3. Multi-query Decomposition: Generates sub-queries
  4. Bias-Guided Knowledge Collection: Routes sub-queries to Multi-query Retriever (gets $K_{ret}$) or Multi-query Generator (gets $K_{gen}$)
  5. Knowledge Sources: Internal knowledge ($K_{int}$), External knowledge ($K_{ext}$), Retrieved ($K_{ret}$), Generated ($K_{gen}$)
  6. Knowledge Scorer (BGE-m3): Computes 4 multi-granularity similarity scores ($S1, S2, S3, S4$) between knowledge sources
  7. Maximum Soft-bias Decision Tree: Uses scores and biases to select a response strategy (FA, FI, FE, RA)
  8. Reflection Module (Optional): Refines queries for mid-confidence cases
  9. Responser: Executes the selected strategy to produce the final answer

- **Critical path:**
  The Allocator’s bias probabilities ($r_p, g_p$) directly control the sub-query allocation. These probabilities and the Scorer’s consistency scores ($S1-S4$) are then fed into the Decision Tree. The tree's logic determines the entire downstream outcome (trust, refuse, etc.), making these components the central control flow.

- **Design tradeoffs:**
  - ICL vs. GRPO Allocator: ICL is simpler and uses the model's pre-trained abilities, while GRPO fine-tunes a smaller model for potentially more adaptive, calibrated bias prediction at the cost of training complexity.
  - Fixed vs. Adaptive Thresholds: The paper determines $\alpha$ and $\beta$ via grid search on the validation set. This ensures robustness but may require re-tuning for out-of-distribution domains.
  - Efficiency vs. Reliability: The system uses multiple API calls (avg. 5.34) for its multi-query and reflection loops, trading higher latency and cost for greater trustworthiness and accuracy.

- **Failure signatures:**
  - Allocator Misjudgment: If $r_p$ is incorrectly low for a new event, the system may rely on hallucinated internal knowledge, triggering the wrong strategy (FI instead of FE).
  - Over-Refusal: If thresholds ($\alpha$) are too conservative or the reflection loop fails to find better evidence, the system defaults to "I don't know" for answerable questions.
  - Blind Trust: If scoring weights fail to detect subtle but critical conflicts, the tree may select "Trust All" (FA) and produce a compromised response.

- **First 3 experiments:**
  1. Allocator Ablation: Disable the Allocator and set $r_p = g_p = 100\%$ for all queries. Compare overall accuracy and the rate of correct strategy selection to quantify the Allocator’s value.
  2. Decision Tree Ablation: Replace the Decision Tree with a standard generation prompt that receives all knowledge and scores. Measure the change in performance, especially on "Refuse to Answer" (RA) cases, to show the tree's role in strategy enforcement.
  3. Threshold Sensitivity: Run a parameter sweep on the decision thresholds ($\alpha$ and $\beta$) on the TRD validation set. Plot the trade-off between accuracy and rejection rate to find an optimal operating point for your specific risk tolerance.

## Open Questions the Paper Calls Out

### Open Question 1
How can the BRIDGE framework evaluate trustworthiness in LLMs that do not disclose their training data cutoff dates? The framework relies on the cutoff date to define the "Faithful to External" (FE) scenario, where internal knowledge is assumed to be outdated; without this date, the ground truth for "outdated" cannot be established. A methodology for dynamically estimating a model's knowledge boundary or a version of the TRD construction process that does not depend on strict temporal heuristics would resolve this.

### Open Question 2
Does the GRPO-based Allocator trained on the TRD dataset generalize effectively to specialized domains outside of general open-domain QA? While the framework works on NQ/TAQA, it is unclear if the "soft bias" analysis paths learned by the Allocator transfer to highly technical domains (e.g., medical or legal RAG) where the distinction between internal and external knowledge needs is structurally different. Zero-shot evaluation results of the trained BRIDGE Allocator on domain-specific RAG benchmarks without further fine-tuning would resolve this.

### Open Question 3
Is the Maximum Soft-bias Decision Tree robust to the choice of the underlying embedding model used for knowledge scoring? The framework assumes BGE-m3 as a fixed component. If the embedding model produces different similarity distributions (e.g., tighter or looser clusters), the fixed thresholds $\alpha$ and $\beta$ may no longer be optimal. An ablation study replacing BGE-m3 with alternative encoders (e.g., OpenAI embeddings, Voyage) to measure the variance in decision tree performance and threshold validity would resolve this.

## Limitations
- The framework's performance is heavily dependent on the Allocator's ability to accurately predict query difficulty and knowledge freshness, which is not fully validated across diverse domains beyond the TRD benchmark.
- The reliance on multiple API calls (avg. 5.34) raises concerns about scalability and real-world deployment costs.
- The fixed thresholds (α=0.5, β=1.1) may not generalize well to out-of-distribution questions or different knowledge domains.

## Confidence
- **High Confidence**: The overall architectural design and decision tree logic are clearly specified and reproducible.
- **Medium Confidence**: The Allocator's calibration using GRPO or ICL is well-defined, but its generalization to unseen domains remains uncertain.
- **Low Confidence**: The reflection loop's effectiveness in resolving ambiguous cases is only partially validated, with no clear stopping criteria for non-resolvable queries.

## Next Checks
1. **Domain Generalization Test**: Evaluate BRIDGE on a held-out domain (e.g., biomedical or legal) not represented in TRD to assess Allocator and scorer robustness.
2. **Threshold Robustness Analysis**: Perform a sensitivity analysis on α and β across different question types to quantify over-refusal and under-trust rates.
3. **Latency and Cost Benchmarking**: Measure end-to-end latency and API costs for BRIDGE versus baseline RAG systems under realistic query loads.