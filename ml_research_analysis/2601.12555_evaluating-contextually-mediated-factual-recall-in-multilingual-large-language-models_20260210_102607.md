---
ver: rpa2
title: Evaluating Contextually Mediated Factual Recall in Multilingual Large Language
  Models
arxiv_id: '2601.12555'
source_url: https://arxiv.org/abs/2601.12555
tags:
- contextual
- language
- factual
- direct
- names
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates contextually mediated factual recall in
  multilingual LLMs, addressing the gap between direct factual queries and natural
  language use where facts are accessed through context. The authors construct controlled
  prompts that embed target entities indirectly within naturalistic contexts while
  preserving the underlying facts, and compare synthetic names versus real names across
  five languages (English, Arabic, Japanese, Korean, Chinese) and nine relation types.
---

# Evaluating Contextually Mediated Factual Recall in Multilingual Large Language Models

## Quick Facts
- arXiv ID: 2601.12555
- Source URL: https://arxiv.org/abs/2601.12555
- Authors: Yihong Liu; Bingyu Xiong; Hinrich Schütze
- Reference count: 19
- This paper investigates contextually mediated factual recall in multilingual LLMs, finding that contextual mediation consistently degrades factual recall across all languages and relations, with larger models exhibiting greater robustness to this effect.

## Executive Summary
This paper investigates how natural language contexts affect factual recall in multilingual large language models. The authors construct controlled prompts that embed target entities indirectly within naturalistic contexts while preserving the underlying facts, comparing synthetic names versus real names across five languages and nine relation types. Results show that contextual mediation consistently degrades factual recall across all languages and relations, with larger models exhibiting greater robustness to this effect. The influence of real names versus synthetic names is mixed and unsystematic, suggesting that surrounding context plays a more dominant role than name surface forms.

## Method Summary
The study evaluates contextually mediated factual recall using the KLAR dataset with 1,742 facts across 9 relations in 5 languages. The authors construct two prompt types: direct queries (explicit entity naming) and contextually mediated queries (entity embedded in naturalistic context with placeholder names). They use synthetic names generated via ChatGPT-5.2 and filtered using Infini-gram, plus real names (50 per language, balanced gender). The evaluation uses 9 models from 3 families (LLaMA, Qwen, Gemma) at different scales, with 3-shot prompting and greedy decoding. The key comparison is accuracy gaps between direct and contextually mediated queries across relations, languages, and model scales.

## Key Results
- Contextual mediation consistently degrades factual recall across all languages and relations, with substantial variation across relations
- Larger models are more robust to contextual mediation, exhibiting a reduced performance gap
- Relations like native_language and capital are most sensitive to contextual mediation while continent remains largely stable
- Overall factual recall accuracy ranges from approximately 35-95% depending on relation and model size
- The influence of real names versus synthetic names is mixed and unsystematic

## Why This Works (Mechanism)

### Mechanism 1: Contextual Mediation Degrades Factual Recall
- **Claim:** Introducing indirect entity references through naturalistic context reduces factual recall accuracy compared to explicit queries.
- **Mechanism:** When entities are embedded in contextual sentences with placeholder names, models must (1) resolve the referent from context, (2) bind the placeholder to the target entity, and (3) retrieve the factual relation. Each step adds failure points that direct queries bypass.
- **Core assumption:** Factual knowledge retrieval and context processing compete for representational capacity during inference.
- **Evidence anchors:**
  - [abstract] "contextual mediation consistently degrades factual recall, with substantial variation across relations"
  - [Section 4.2] "Across all languages, contextually mediated queries lead to lower factual recall than direct queries"
  - [corpus] Related work (Shi et al., 2023) shows LLMs are distracted by irrelevant context, supporting interference effects, but no direct mechanistic evidence exists for this specific paradigm
- **Break condition:** If models process context and factual retrieval through fully independent pathways, degradation should not occur consistently.

### Mechanism 2: Scale Improves Context-Fact Integration
- **Claim:** Larger models exhibit reduced performance gaps between direct and contextually mediated queries.
- **Mechanism:** Increased capacity may enable (1) stronger entity representations that survive contextual embedding, (2) more effective attention for cross-sentence referent tracking, or (3) redundant retrieval pathways.
- **Core assumption:** Parameter scaling improves multi-step reasoning and context-to-knowledge binding.
- **Evidence anchors:**
  - [abstract] "Larger models are more robust to contextual mediation, exhibiting a reduced performance gap"
  - [Section 4.2] "larger models tend to be more robust... This trend is clearly observed in the LLaMA and Gemma families. In contrast, the Qwen family shows weaker or less consistent gains"
  - [corpus] No corpus papers directly address scale effects in multilingual contextual recall
- **Break condition:** If Qwen's inconsistent scaling generalizes to other families, mechanism requires revision to account for architecture-specific effects.

### Mechanism 3: Candidate Space Constrains Sensitivity
- **Claim:** Relations with constrained answer spaces show greater robustness to contextual mediation.
- **Mechanism:** Limited candidate pools (e.g., 7 continents) reduce ambiguity even with indirect entity access, allowing partial cues to disambiguate.
- **Core assumption:** Model uncertainty is bounded by answer-space cardinality.
- **Evidence anchors:**
  - [Section 4.2] "relations such as native_language, capital, and headquarters_location are consistently the most sensitive, while others, notably continent, remain largely stable"
  - [Section 4.2] authors "hypothesize that this robustness is related to the limited candidate space"
  - [corpus] No corpus papers systematically test candidate space effects
- **Break condition:** If high-sensitivity relations also have small candidate sets, hypothesis is invalid.

## Foundational Learning

- **Concept: Contextual Mediation**
  - **Why needed here:** This is the core construct—understanding how indirect entity access differs from explicit queries is essential for interpreting all results.
  - **Quick check question:** Given "After arriving in France, Alex visits the famous tower in its capital. What landmark does Alex see?", identify: (a) the target entity, (b) the mediating context element, (c) the factual relation queried.

- **Concept: Referential Resolution**
  - **Why needed here:** The paper assumes models must resolve placeholder names to entities; degradation likely stems from resolution failures.
  - **Quick check question:** In "Maria works at Google. She lives near its headquarters," how should a model track that "She"→"Maria" and "its"→"Google"?

- **Concept: Exact-Match Evaluation**
  - **Why needed here:** The metric (gold answer as prefix of generation) shapes what counts as success; understanding it prevents misinterpreting near-misses as total failures.
  - **Quick check question:** If gold answer is "Paris" and model outputs "Paris, France", is this correct under the paper's evaluation?

## Architecture Onboarding

- **Component map:** KLAR dataset (1,742 facts, 9 relations) → Prompt templates (direct vs contextual × synthetic vs real names × 5 languages) → 9 models (LLaMA, Qwen, Gemma families at 3 scales) → 3-shot prompting with vLLM → Greedy decoding (max 10 tokens) → Exact-match accuracy evaluation

- **Critical path:**
  1. Sample fact from KLAR
  2. Apply template (direct or contextual with synthetic/real name)
  3. Run inference with 3-shot examples
  4. Check if gold answer prefixes generation
  5. Aggregate by language, relation, model scale

- **Design tradeoffs:**
  - Synthetic names (Infini-gram filtered) minimize pretraining bias but may seem unnatural
  - Two-sentence prompts enable controlled comparison but lack natural discourse complexity
  - Translation-based templates risk artifacts across languages

- **Failure signatures:**
  - **Contextual-mediation failure:** Correct on direct, wrong on contextual for same fact (see Table 3 counts)
  - **Non-monotonic scaling:** Qwen shows inconsistent improvement on `capital`—flag if replicating
  - **Unexpected name-origin effects:** Systematic degradation with non-English names suggests template/transliteration issues

- **First 3 experiments:**
  1. Reproduce main effect: Test direct vs contextual on `native_language` in English across one model family to confirm degradation pattern.
  2. Ablate context length: Add distractor sentences before the query to measure interference scaling.
  3. Probe resolution vs retrieval: Replace placeholder with actual entity name mid-context to isolate referential resolution from pure contextual interference.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does factual knowledge remain equally accessible when queried through context versus direct queries?
- **Basis in paper:** [explicit] The introduction states: "This raises an open question: does factual knowledge remain equally accessible when it is queried through context?"
- **Why unresolved:** The paper demonstrates that contextual mediation degrades recall but with substantial variation across relations (e.g., native_language drops significantly while continent remains stable), suggesting the effect is not uniform.
- **What evidence would resolve it:** Mechanistic interpretability studies probing how entity representations and contextual integration interact during factual recall across relation types.

### Open Question 2
- **Question:** What explains the substantial variation in contextual mediation sensitivity across different relation types?
- **Basis in paper:** [inferred] Results show native_language and capital are highly sensitive while continent remains stable. The authors hypothesize this relates to "limited candidate space" but do not empirically validate this explanation.
- **What evidence would resolve it:** Controlled experiments manipulating answer candidate space size across relations, combined with attention pattern analysis during contextual resolution.

### Open Question 3
- **Question:** How do sociolinguistic factors such as name frequency and demographic variation influence contextual mediation effects?
- **Basis in paper:** [explicit] The limitations section states: "our analysis of name bias is based on a limited set of common names and does not consider sociolinguistic factors such as name frequency or variation across demographic groups."
- **Why unresolved:** Current analysis uses only 50 common names per language without systematic variation of sociolinguistic properties that may independently affect model behavior.
- **What evidence would resolve it:** Experiments with names stratified by corpus frequency, demographic associations, and cultural markers across languages.

### Open Question 4
- **Question:** Why does the Qwen family exhibit weaker scaling benefits for contextual mediation robustness compared to LLaMA and Gemma?
- **Basis in paper:** [inferred] Figure 2 shows LLaMA and Gemma gain robustness with scale, but the paper notes "the Qwen family shows a weaker or less consistent gains in robustness with scale."
- **What evidence would resolve it:** Comparative analysis of training data composition, architectural differences, or factual association representations across model families at matched scales.

## Limitations
- The study's reliance on synthetic names introduces uncertainty about ecological validity—results may not generalize to real-world usage where natural names appear.
- The exact prompt templates beyond English remain inaccessible, making faithful reproduction difficult across languages.
- The KLAR dataset access is unspecified, blocking full replication.
- The evaluation metric's strictness (exact-match prefix) may understate partial knowledge acquisition, particularly for relations with compositional answers.

## Confidence
- **High confidence:** Contextual mediation consistently degrades factual recall across languages and relations
- **Medium confidence:** Larger models exhibit reduced sensitivity to contextual mediation (trend observed but with notable Qwen family exceptions)
- **Medium confidence:** Relations with constrained answer spaces show greater robustness (hypothesis supported by data but lacking systematic testing)

## Next Checks
1. Reproduce the English direct-vs-contextual gap on `native_language` relation using the specified templates and exact-match evaluation to verify the core finding before extending to other languages
2. Test contextual interference scaling by adding distractor sentences to the context prompt and measuring degradation patterns across relations
3. Isolate referential resolution from pure contextual interference by replacing placeholder names with actual entity names mid-context in the same factual prompts