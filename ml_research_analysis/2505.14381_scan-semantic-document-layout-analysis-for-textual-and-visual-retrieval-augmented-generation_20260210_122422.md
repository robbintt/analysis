---
ver: rpa2
title: 'SCAN: Semantic Document Layout Analysis for Textual and Visual Retrieval-Augmented
  Generation'
arxiv_id: '2505.14381'
source_url: https://arxiv.org/abs/2505.14381
tags:
- scan
- document
- semantic
- layout
- page
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SCAN, a semantic document layout analysis
  approach designed to improve both textual and visual retrieval-augmented generation
  (RAG) systems. SCAN addresses the challenge of processing visually rich documents
  by dividing pages into coherent, semantically meaningful regions rather than fine-grained
  structural elements, thus preserving topical context and reducing processing complexity
  for vision-language models.
---

# SCAN: Semantic Document Layout Analysis for Textual and Visual Retrieval-Augmented Generation

## Quick Facts
- arXiv ID: 2505.14381
- Source URL: https://arxiv.org/abs/2505.14381
- Reference count: 13
- Key outcome: Improves RAG accuracy by up to 9.4 F1 points (textual) and 10.4 points (visual) using coarse-grained semantic layout segmentation.

## Executive Summary
This paper introduces SCAN, a semantic document layout analysis approach that enhances both textual and visual retrieval-augmented generation (RAG) systems by dividing pages into coherent, semantically meaningful regions rather than fine-grained structural elements. The method is trained by fine-tuning object detection models on a newly annotated dataset of over 24,000 document pages. Experimental results demonstrate that SCAN improves end-to-end RAG performance while reducing computational costs by lowering the number of input tokens per inference.

## Method Summary
SCAN fine-tunes object detection models (RT-DETR-X or YOLO11-X) to identify semantic regions in document pages, outputting six types of bounding boxes: semantic_box, title, header, footer, date, and author. The model processes page images and produces axis-aligned, non-overlapping rectangles that represent coherent subtopics. For textual RAG, these regions are converted to text via VLM-based OCR and concatenated; for visual RAG, the cropped images are indexed directly. The system is trained on 24,577 Japanese document pages with a matching-based IoU evaluation metric and achieves significant performance gains over fine-grained layout analysis methods.

## Key Results
- Improves end-to-end textual RAG performance by up to 9.4 points and visual RAG performance by up to 10.4 points
- Reduces computational costs by lowering the number of input tokens per inference
- Outperforms conventional layout analysis methods and commercial document processing solutions

## Why This Works (Mechanism)
SCAN works by providing vision-language models with appropriately sized, semantically coherent chunks of document content. Unlike fine-grained layout analysis that fragments documents into many small elements (paragraphs, figures, tables), SCAN groups related content into coarse-grained semantic regions. This preserves topical context within each chunk, allowing VLMs to better understand and process the information. The approach also reduces computational overhead by decreasing the total number of chunks and tokens that need to be processed, while maintaining or improving accuracy through better information coherence.

## Foundational Learning
- **Concept: Retrieval-Augmented Generation (RAG)**
  - Why needed here: The entire purpose of SCAN is to improve RAG systems on visually rich documents.
  - Quick check question: Explain the fundamental difference between a textual RAG pipeline and a visual RAG pipeline, as described in the paper's introduction.

- **Concept: Vision-Language Models (VLMs)**
  - Why needed here: VLMs are the core processing engine in this architecture and SCAN is explicitly designed to be "VLM-friendly."
  - Quick check question: What is the "common challenge" for VLMs that SCAN is designed to address?

- **Concept: Object Detection (and its application to Document Layout Analysis)**
  - Why needed here: The technical implementation of SCAN is to fine-tune an object detection model.
  - Quick check question: Instead of detecting cars or people, what two main types of "objects" is the SCAN model trained to detect in a document page?

## Architecture Onboarding
- **Component map:** Page image → SCAN layout analysis model → semantic/global bounding boxes → crop sub-images → (textual RAG: VLM OCR → text chunks → concatenate → text retriever) OR (visual RAG: multimodal retriever with image chunks) → LLM/VLM for answer generation

- **Critical path:** The layout analysis model's inference. Its accuracy directly determines whether a semantic unit is kept intact or improperly split, cascading to VLM performance and final RAG accuracy.

- **Design tradeoffs:** Between processing granularity and computational overhead. More chunks mean more VLM calls but each is faster and more focused, leading to better accuracy. Secondary tradeoff in annotation complexity—defining "semantic" regions is more subjective than labeling structural elements.

- **Failure signatures:**
  - Topic fragmentation: Key chart and explanatory text placed in separate boxes
  - Information overload: Single large box produced for dense page
  - Incorrect reading order: Concatenated text makes little sense due to complex layout
  - Cross-language domain gap: Japanese-trained model fails on English layouts

- **First 3 experiments:**
  1. Baseline Replication & Scan Integration: Build basic visual RAG pipeline using simple page splitter, measure baseline accuracy, then replace with pre-trained SCAN and measure performance delta.
  2. Ablation on Chunk Granularity: Create degraded versions with very large boxes (whole page) and very small boxes (fine-grained), compare against main SCAN model.
  3. Efficiency vs. Accuracy Trade-off Analysis: Measure end-to-end latency and total token count for full-page baseline vs SCAN-based pipeline.

## Open Questions the Paper Calls Out
- How can semantic layout analysis be adapted to merge spatially separated content that logically constitutes a single topic? The current model cannot connect content that belongs to a single semantic chunk if physically separated and not fitting in a rectangular box.
- Would training SCAN on native English data yield significant performance improvements over the current Japanese-trained model for English RAG tasks? The Japanese-trained model may be biased toward Japanese layout characteristics like vertical writing.
- Can an adaptive mechanism be designed to intelligently deactivate SCAN for simple pages to improve generalizability? SCAN was designed for dense, content-rich documents and may not be optimal for simpler pages.

## Limitations
- The 24k annotated dataset is not released, making independent validation difficult
- Fine-tuned SCAN model weights are not released, only training details provided
- Claims rely primarily on internal Japanese benchmarks and OHR-Bench test split

## Confidence
- **High**: Claims about SCAN's design principles and training methodology
- **Medium**: End-to-end RAG performance improvements due to non-public evaluation datasets
- **Low**: Generalizability to unseen languages and document layouts given exclusive use of Japanese documents

## Next Checks
1. **Cross-Domain Generalization**: Apply pre-trained SCAN to English-language visual document dataset and measure layout segmentation quality and downstream RAG performance.
2. **Annotation Efficiency Analysis**: Evaluate whether SCAN retains strong performance when fine-tuned on reduced subset (10% or 1%) of original 24k-page corpus.
3. **Error Case Analysis**: Conduct qualitative review of SCAN's failure modes on documents with non-standard layouts and measure frequency of semantic fragmentation compared to commercial baselines.