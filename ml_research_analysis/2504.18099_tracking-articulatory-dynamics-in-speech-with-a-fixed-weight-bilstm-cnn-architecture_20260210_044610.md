---
ver: rpa2
title: Tracking Articulatory Dynamics in Speech with a Fixed-Weight BiLSTM-CNN Architecture
arxiv_id: '2504.18099'
source_url: https://arxiv.org/abs/2504.18099
tags:
- speech
- articulatory
- features
- speaker
- weight
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a stacked BiLSTM-CNN architecture for predicting
  tongue and lip articulatory features from speech acoustics. The BiLSTM captures
  temporal dependencies in acoustic data, while a 1D CNN with fixed weights performs
  post-processing smoothing to ensure realistic articulatory trajectories.
---

# Tracking Articulatory Dynamics in Speech with a Fixed-Weight BiLSTM-CNN Architecture

## Quick Facts
- arXiv ID: 2504.18099
- Source URL: https://arxiv.org/abs/2504.18099
- Reference count: 40
- Fixed-weight CNN smoothing consistently improves articulatory feature prediction performance across evaluation modes

## Executive Summary
This paper presents a stacked BiLSTM-CNN architecture for predicting tongue and lip articulatory features from speech acoustics. The model combines temporal modeling through bidirectional LSTMs with post-processing smoothing via a 1D CNN with fixed weights to ensure realistic articulatory trajectories. Experiments across multiple evaluation scenarios (speaker-dependent, speaker-independent, corpus-dependent, and cross-corpus) demonstrate consistent performance improvements with fixed-weight initialization compared to adaptive approaches. The work addresses the challenge of converting acoustic signals into articulatory movements, which is crucial for applications in speech therapy, pronunciation training, and silent speech interfaces.

## Method Summary
The proposed architecture employs a two-stage approach: first, a stacked BiLSTM layer captures temporal dependencies in acoustic features extracted from speech signals; second, a 1D CNN with fixed weights performs post-processing smoothing on the predicted articulatory trajectories. The fixed-weight CNN serves as a regularization mechanism to constrain predictions toward realistic articulatory movements. The model is trained and evaluated on EMA (Electromagnetic Articulography) datasets from MOCHA and USC-TIMIT, representing UK and US English speakers respectively. Multiple evaluation scenarios are considered, including speaker-dependent, speaker-independent, corpus-dependent, and cross-corpus settings, to assess the model's generalization capabilities and robustness across different conditions.

## Key Results
- Fixed-weight CNN initialization achieved PCC of 0.810 and RMSE of 0.761 mm in speaker-dependent mode, outperforming adaptive initialization approaches
- The smoothing mechanism consistently improved performance across all evaluation scenarios, with PCC improvements ranging from 0.02 to 0.05 compared to BiLSTM-only baselines
- Cross-corpus performance degraded significantly between MOCHA and USC-TIMIT datasets, with PCC dropping by approximately 0.15-0.20, highlighting challenges in generalizing across different English dialects

## Why This Works (Mechanism)
The BiLSTM captures long-range temporal dependencies in acoustic features, modeling how articulatory configurations evolve over time. The fixed-weight CNN acts as a smoothing filter that constrains predictions to physically plausible trajectories without introducing learnable parameters that could overfit. This dual architecture leverages the BiLSTM's ability to model complex temporal patterns while the CNN ensures that the resulting articulatory movements remain smooth and realistic. The fixed weights provide a form of inductive bias that regularizes the model without requiring additional training data or computational overhead during fine-tuning.

## Foundational Learning
- EMA Articulography: Electromagnetic measurement of tongue and lip positions during speech; needed for ground truth articulatory data, quick check: understand spatial resolution and measurement constraints
- BiLSTM Networks: Bidirectional Long Short-Term Memory for temporal modeling; needed to capture dependencies in both forward and backward directions, quick check: verify memory cell and gate operations
- 1D Convolutional Smoothing: Spatial filtering along temporal dimension; needed for trajectory regularization, quick check: understand kernel size and stride effects
- Pearson Correlation Coefficient: Statistical measure of linear correlation; needed for evaluating prediction accuracy, quick check: know range [-1,1] and interpretation
- Root Mean Square Error: Distance metric between predictions and ground truth; needed for quantitative performance assessment, quick check: understand units (mm) and sensitivity to outliers

## Architecture Onboarding

**Component Map**
Speech features -> BiLSTM layers -> Raw articulatory predictions -> Fixed-weight 1D CNN -> Smoothed articulatory trajectories

**Critical Path**
The critical computational path flows from acoustic feature extraction through the stacked BiLSTM layers to produce raw articulatory predictions, which then pass through the fixed-weight CNN for smoothing. The BiLSTM layer is the primary computational bottleneck due to sequential processing, while the CNN operates as a lightweight post-processing step.

**Design Tradeoffs**
The key tradeoff involves using fixed weights versus learned weights in the smoothing CNN. Fixed weights provide regularization benefits and computational efficiency but sacrifice adaptability to dataset-specific characteristics. The architecture prioritizes generalization and robustness over fine-tuning capability. The BiLSTM choice over alternatives like Transformers balances temporal modeling capability with computational efficiency for the task.

**Failure Signatures**
Performance degradation in cross-corpus scenarios indicates phonetic and linguistic differences between datasets are not adequately captured. High RMSE values suggest the model struggles with rapid articulatory movements or speaker-specific articulation patterns. Poor PCC scores in speaker-independent settings reveal limitations in generalizing across speaker characteristics without adaptation.

**First Experiments**
1. Test fixed versus learned weight configurations on a validation split to quantify regularization benefits
2. Evaluate different BiLSTM layer depths to find optimal temporal modeling capacity
3. Measure performance sensitivity to acoustic feature representation choices (e.g., MFCCs vs filterbanks)

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Limited evaluation to only two EMA datasets (MOCHA and USC-TIMIT) may not represent full diversity of speech articulatory patterns
- Cross-corpus generalization remains challenging, with significant performance degradation between UK and US English datasets
- Fixed-weight CNN smoothing lacks theoretical justification for why specific weights yield better articulatory trajectories
- No exploration of alternative temporal modeling architectures beyond BiLSTM or different acoustic feature representations

## Confidence
High: Fixed-weight CNN smoothing consistently improves articulatory feature prediction performance across evaluation modes
Medium: Model demonstrates robustness in speaker-dependent and speaker-independent settings with strong results but limited dataset scope
Low: Cross-corpus generalization claims are limited by significant performance degradation between MOCHA and USC-TIMIT datasets

## Next Checks
1. Evaluate the model architecture on additional EMA datasets from different languages and speaker demographics to assess cross-linguistic generalization capabilities
2. Conduct ablation studies comparing fixed-weight CNN smoothing against alternative temporal regularization techniques such as recurrent dropout, attention mechanisms, or explicit smoothness constraints in the loss function
3. Perform detailed error analysis to identify specific articulatory features or phonetic contexts where prediction accuracy degrades most significantly, particularly in cross-corpus scenarios