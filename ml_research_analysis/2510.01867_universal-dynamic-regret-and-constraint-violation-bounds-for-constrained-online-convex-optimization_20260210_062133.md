---
ver: rpa2
title: Universal Dynamic Regret and Constraint Violation Bounds for Constrained Online
  Convex Optimization
arxiv_id: '2510.01867'
source_url: https://arxiv.org/abs/2510.01867
tags:
- regret
- algorithm
- cost
- dynamic
- functions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper considers online convex optimization with adversarial
  constraints, relaxing the common feasibility assumption found in prior work. Two
  new algorithms are proposed: one achieving optimal universal dynamic regret via
  a projection-based approach, and another projection-free algorithm that performs
  better in rapidly varying environments.'
---

# Universal Dynamic Regret and Constraint Violation Bounds for Constrained Online Convex Optimization

## Quick Facts
- arXiv ID: 2510.01867
- Source URL: https://arxiv.org/abs/2510.01867
- Reference count: 40
- Primary result: Two algorithms for adversarial constrained online convex optimization achieving universal dynamic regret and cumulative constraint violation bounds

## Executive Summary
This paper addresses online convex optimization with adversarial constraints, relaxing the common feasibility assumption found in prior work. The authors propose two algorithms: one achieving optimal universal dynamic regret via projection-based methods, and another projection-free algorithm better suited for rapidly varying environments. Both algorithms use a reduction to standard online convex optimization by constructing surrogate cost functions that balance regret and constraint violation. The first algorithm guarantees regret of $O(\sqrt{T(1+P_T)})$ and constraint violation $O(\sqrt{T(1+P_T^*)})$, while the second achieves regret $O((1+P_T)\sqrt{T})$ and constraint violation $O(T^{3/4} + \sqrt{T(1+P_T^*)})$, requiring only gradient feedback.

## Method Summary
The paper presents a reduction from constrained online convex optimization to standard OCO by constructing surrogate cost functions. Algorithm 2 uses a distance-based penalty forcing actions into the feasible set via projection, achieving optimal regret bounds but requiring expensive projections. Algorithm 5 uses a Lyapunov-based decomposition with a potential function to decouple regret and constraint violation, enabling projection-free updates using only gradient information. Both algorithms rely on an expert-ensemble strategy (AHAG) to handle unknown Lipschitz constants adaptively.

## Key Results
- Algorithm 2: Optimal universal dynamic regret $O(\sqrt{T(1+P_T)})$ and constraint violation $O(\sqrt{T(1+P_T^*)})$ via projection-based approach
- Algorithm 5: Projection-free regret $O((1+P_T)\sqrt{T})$ and constraint violation $O(T^{3/4} + \sqrt{T(1+P_T^*)})$ using only gradient feedback
- AHAG subroutine: Lipschitz-adaptive OCO algorithm of independent interest, handling unknown/unbounded Lipschitz constants

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Adding a geometric distance penalty to the cost function forces the minimizer of the surrogate loss to lie within the feasible set, ensuring regret is measured against a feasible benchmark.
- **Mechanism:** The algorithm constructs an auxiliary cost $\tilde{f}_t(x) = f_t(x) + 2G \cdot \text{dist}(x, X_t^*)$. This penalizes actions based on their Euclidean distance to the current feasible set $X_t^*$.
- **Core assumption:** The feasible set $X_t^*$ is convex and the distance function is computable (requires full constraint feedback).
- **Evidence anchors:**
  - [abstract]: "surrogate cost functions"
  - [section]: Section 3, Eqn (6) defines the auxiliary cost; Lemma 12 proves minimizers lie in $X_t^*$.
  - [corpus]: "Optimal Bounds for Adversarial Constrained Online Convex Optimization" (FMR 0.0) suggests optimality is linked to specific handling of constraints.
- **Break condition:** If the projection onto the time-varying feasible set $X_t^*$ is computationally prohibitive (e.g., high-dimensional complex polytopes), the algorithm stalls.

### Mechanism 2
- **Claim:** A Lyapunov-based decomposition decouples the trade-off between regret and constraint violation, allowing a projection-free update using only gradient information.
- **Mechanism:** The surrogate cost $\hat{f}_t(x) = V f_t(x) + \Phi'(Q(t))g_t^+(x)$ weights the cost and constraint violation based on a potential function $\Phi$ (quadratic) of cumulative violation $Q(t)$. This allows the learner to minimize a single composite objective.
- **Core assumption:** Cost and constraint functions are Lipschitz, but their constants need not be known a priori (adaptive).
- **Evidence anchors:**
  - [abstract]: "projection-free algorithm... requires only gradient feedback"
  - [section]: Section 4.2, Eqn (16) defines the surrogate; Inequality (19) establishes the regret decomposition.
  - [corpus]: "Projection-free Algorithms for Online Convex Optimization with Adversarial Constraints" (FMR 0.66) aligns with this mechanism.
- **Break condition:** If the environment varies slowly ($P_T$ is small), this method's regret bound $O((1+P_T)\sqrt{T})$ may be looser than the optimal $O(\sqrt{T(1+P_T)})$ of projection-based methods.

### Mechanism 3
- **Claim:** An expert-ensemble strategy (AHAG) handles unbounded Lipschitz constants in the surrogate costs, ensuring stability even as constraint violations grow.
- **Mechanism:** AHAG runs logarithmically many "expert" algorithms (AdaGrad instances) with different step-sizes (estimating path length) and aggregates them via AdaHedge. This adapts to the unknown path length $P_T$ and gradient norms.
- **Core assumption:** The decision set is bounded (diameter $D$).
- **Evidence anchors:**
  - [abstract]: "Lipschitz-adaptive OCO algorithm"
  - [section]: Section 4.1, Algorithm 4 details the AHAG structure; Theorem 19 provides the adaptive bound.
  - [corpus]: Corpus papers generally focus on static regret or fixed constraints; this specific adaptive dynamic mechanism is less explicitly detailed in neighbors but the "Dynamic Regret Bounds" paper (FMR 0.58) touches on related concepts.
- **Break condition:** If the number of experts $N$ is insufficient to cover the range of possible path lengths, the "best expert" guarantee degrades.

## Foundational Learning

- **Concept:** Universal Dynamic Regret
  - **Why needed here:** Unlike static regret (comparing to one fixed best action), this metric compares performance against *any* sequence of feasible actions. It is necessary because the paper drops the "common feasibility" assumption, meaning no single fixed point is feasible for all rounds.
  - **Quick check question:** How does the bound change if the comparator sequence is constant vs. time-varying?

- **Concept:** Constraint Violation (CCV)
  - **Why needed here:** The core problem is satisfying constraints $g_t(x) \leq 0$ revealed *after* an action is taken. CCV ($\sum \max(0, g_t(x))$) quantifies the penalty for infeasibility.
  - **Quick check question:** Does a sublinear CCV imply the constraints are eventually satisfied?

- **Concept:** Projections in OCO
  - **Why needed here:** Algorithm 2 relies on projecting onto the feasible set $X_t^*$, while Algorithm 5 explicitly avoids it. Understanding the computational cost of $\text{Proj}_{X_t^*}(x)$ is vital for selecting the right architecture.
  - **Quick check question:** Does the projection-free method avoid *all* projections or just projections onto the *constraint* sets?

## Architecture Onboarding

- **Component map:** Template (Algorithm 1) -> Construct Surrogate -> OCO Subroutine -> Play Action -> Receive Feedback
- **Critical path:**
  - **Alg 2:** Compute $\nabla \hat{f}_t \to$ Project onto $X \to$ **Project onto $X_t^*$** (Bottleneck).
  - **Alg 5:** Compute $\nabla f_t, \nabla g_t \to$ Update $Q(t) \to$ AHAG update (Expert aggregation).
- **Design tradeoffs:**
  - **Regret Optimality vs. Compute:** Alg 2 has optimal $O(\sqrt{T(1+P_T)})$ regret but requires costly projections. Alg 5 has $O((1+P_T)\sqrt{T})$ regret (suboptimal in $P_T$) but is projection-free.
  - **CCV Guarantees:** In rapidly varying environments, Alg 5 provides tighter CCV bounds ($O(T^{3/4})$) compared to Alg 2.
- **Failure signatures:**
  - **Linear CCV Growth:** If the surrogate cost for Alg 2 is constructed without the distance term (just $f + g^+$), CCV can grow linearly (see Appendix 7.2).
  - **Drift:** If the feasible sets $X_t^*$ drift faster than the algorithm's tracking capability, performance degrades relative to the path length $P_T$.
- **First 3 experiments:**
  1. **Feasibility Stress Test:** Construct a sequence of constraints where the feasible set "jumps" between two disjoint regions. Verify if Alg 5 handles the jump (via $P_T$) better than static baselines.
  2. **Computational Scaling:** Compare runtime of Alg 2 vs. Alg 5 on a high-dimensional decision space ($d \gg 100$) to quantify the projection bottleneck.
  3. **Lipschitz Sensitivity:** Perturb the cost functions to have unbounded Lipschitz constants locally. Verify if AHAG (Alg 5) remains stable while ADER (Alg 2) fails or requires hyperparameter retuning.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** What are the simultaneous lower bounds on universal dynamic regret and cumulative constraint violation?
- **Basis in paper:** [explicit] The conclusion explicitly states: "An important open direction is to establish simultaneous lower bounds on the universal dynamic regret and cumulative constraint violation."
- **Why unresolved:** The paper provides upper bounds (e.g., $O(\sqrt{T(1+P_T)})$), but it does not prove if these rates are minimax optimal when considering the trade-off between regret and constraint violation.
- **What evidence would resolve it:** A theoretical proof establishing a Pareto frontier or lower bound curve that no online algorithm can surpass.

### Open Question 2
- **Question:** Can the proposed framework be extended to bandit feedback settings?
- **Basis in paper:** [explicit] The conclusion notes: "It will also be interesting to extend the proposed framework to bandit feedback settings."
- **Why unresolved:** The proposed algorithms rely on full constraint information (Algorithm 2) or first-order gradient feedback (Algorithm 5), neither of which is available in the bandit setting.
- **What evidence would resolve it:** A new algorithm that achieves sublinear universal dynamic regret and constraint violation using only zeroth-order (function value) feedback.

### Open Question 3
- **Question:** Is it possible to achieve the minimax optimal universal dynamic regret $O(\sqrt{T(1+P_T)})$ in a projection-free manner?
- **Basis in paper:** [inferred] The authors highlight a trade-off: Algorithm 2 achieves optimal regret but requires projection, whereas the projection-free Algorithm 5 has a sub-optimal regret dependence of $O((1+P_T)\sqrt{T})$.
- **Why unresolved:** The paper does not determine if the projection-free constraint fundamentally necessitates the looser dependence on the path length $P_T$.
- **What evidence would resolve it:** A projection-free algorithm achieving $O(\sqrt{T(1+P_T)})$ regret or a proof that projection operations are necessary for that convergence rate.

## Limitations

- Algorithm 2 requires computationally expensive projections onto time-varying feasible sets, which may be infeasible for high-dimensional or complex constraint structures
- Performance bounds depend on the path length $P_T$, which must be either known a priori or adaptively estimated through the AHAG subroutine
- The Lipschitz continuity assumption for both cost and constraint functions, while standard, may not hold in practice for all problem domains

## Confidence

**High Confidence:** The universal dynamic regret framework and the reduction from COCO to OCO are well-established theoretical constructs. The regret bounds of $O(\sqrt{T(1+P_T)})$ for Algorithm 2 and $O((1+P_T)\sqrt{T})$ for Algorithm 5 follow directly from existing OCO analysis applied to the constructed surrogate functions.

**Medium Confidence:** The constraint violation bounds depend on the specific construction of surrogate costs and the behavior of the underlying OCO subroutines. While the theoretical analysis appears sound, the tightness of these bounds in practice may vary depending on problem structure and implementation details.

**Low Confidence:** The practical performance of the AHAG subroutine in Algorithm 5, particularly its ability to adapt to unknown/unbounded Lipschitz constants, requires empirical validation. The logarithmic number of experts ($N = \lceil 0.5 \log_2(1+DT) \rceil + 1$) may not adequately cover the range of possible path lengths in all scenarios.

## Next Checks

1. **Projection Complexity Analysis:** Implement Algorithm 2 on high-dimensional problems ($d > 100$) with complex constraint sets and measure the computational overhead of the projection step. Compare runtime and constraint violation performance against Algorithm 5.

2. **Path Length Adaptation Test:** Design experiments where the path length $P_T$ varies significantly across different time intervals. Verify that Algorithm 5's regret and constraint violation bounds scale appropriately with the actual path length, and that AHAG successfully identifies the correct expert sequence.

3. **Constraint Violation Stress Test:** Construct scenarios where constraints $g_t(x) \leq 0$ change rapidly or have sharp discontinuities. Measure the cumulative constraint violation for both algorithms and verify that the theoretical bounds accurately predict empirical performance, particularly the $O(T^{3/4})$ bound for Algorithm 5 in rapidly varying environments.