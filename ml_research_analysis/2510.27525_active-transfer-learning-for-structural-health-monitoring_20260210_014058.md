---
ver: rpa2
title: Active transfer learning for structural health monitoring
arxiv_id: '2510.27525'
source_url: https://arxiv.org/abs/2510.27525
tags:
- data
- target
- learning
- transfer
- mapping
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents an active transfer learning framework for structural
  health monitoring (SHM) that addresses the challenge of limited labelled data by
  leveraging information from multiple structures. The proposed method combines Bayesian
  domain adaptation with active learning to improve damage classification in target
  structures where labelled data are scarce.
---

# Active transfer learning for structural health monitoring

## Quick Facts
- arXiv ID: 2510.27525
- Source URL: https://arxiv.org/abs/2510.27525
- Authors: J. Poole; N. Dervilis; K. Worden; P. Gardner; V. Giglioni; R. Mills; A. Hughes
- Reference count: 40
- Primary result: DA-RVM framework achieves comparable damage classification performance to fully supervised methods while requiring 10-12% of labelled data versus 23-31% for conventional active learning

## Executive Summary
This paper presents an active transfer learning framework for structural health monitoring (SHM) that addresses the challenge of limited labelled data by leveraging information from multiple structures. The proposed method combines Bayesian domain adaptation with active learning to improve damage classification in target structures where labelled data are scarce. The framework is evaluated on a population of three laboratory-scale bridges tested under varying temperatures and damage states.

The core approach uses a probabilistic relevance vector machine (DA-RVM) that learns a shared classifier across source and target domains while maintaining uncertainty estimates. The method updates unsupervised domain adaptation mappings using limited target labels and incorporates an information-efficiency-based active sampling strategy to guide inspections toward the most informative observations. Results demonstrate significant reductions in required labelled data while maintaining classification accuracy, with practical benefits for reducing unnecessary inspections of undamaged structures.

## Method Summary
The framework combines Bayesian domain adaptation with active learning to enable damage classification in structures with limited labelled data. It uses a probabilistic relevance vector machine (DA-RVM) that jointly learns a classifier across source and target domains while maintaining uncertainty estimates. The method learns a linear mapping between source and target domains to align their distributions, then updates this mapping using a small number of target labels obtained through an active sampling strategy. The active sampling selects observations that maximize information gain while accounting for the cost of acquiring labels, balancing exploration of uncertain regions with exploitation of known information.

## Key Results
- DA-RVM achieved comparable classification performance to fully supervised classifiers while requiring only 10-12% of labelled samples
- The framework successfully classified damage states not previously observed in the target domain
- Method reduced unnecessary inspections of undamaged structures, demonstrating practical operational cost benefits
- Performance exceeded conventional active learning approaches that required 23-31% labelled data for similar accuracy

## Why This Works (Mechanism)
The approach works by leveraging shared structural characteristics across multiple bridges while accounting for domain-specific variations through probabilistic alignment. The Bayesian framework maintains uncertainty estimates that guide the active sampling process toward the most informative observations. By learning a shared classifier that generalizes across domains while adapting to local conditions through limited target labels, the method achieves data efficiency without sacrificing accuracy.

## Foundational Learning

**Bayesian Domain Adaptation**: Needed to align distributions between source and target domains while maintaining uncertainty quantification. Quick check: Verify domain alignment metrics and uncertainty calibration on validation data.

**Active Learning**: Required to efficiently select which observations to label when data acquisition is costly. Quick check: Compare sampling efficiency against random selection baselines.

**Relevance Vector Machines**: Provides sparse probabilistic classification with uncertainty estimates suitable for active learning. Quick check: Validate sparsity and predictive performance compared to alternative classifiers.

**Unsupervised Domain Adaptation**: Enables initial alignment before any target labels are available. Quick check: Assess alignment quality using domain discrepancy metrics before and after adaptation.

## Architecture Onboarding

**Component Map**: Raw sensor data -> Feature extraction -> Domain adaptation mapping -> Shared classifier -> Uncertainty estimation -> Active sampling -> Label acquisition -> Updated mapping

**Critical Path**: Feature extraction -> Domain adaptation -> Classification -> Uncertainty estimation -> Active sampling decision

**Design Tradeoffs**: Linear mapping assumption balances flexibility with data efficiency; Bayesian framework provides uncertainty but increases computational complexity; active sampling reduces label requirements but requires reliable uncertainty estimates.

**Failure Signatures**: Poor domain alignment leading to classification errors; overconfidence in uncertain regions causing suboptimal sampling; computational bottlenecks preventing real-time deployment; structural changes beyond model capacity.

**3 First Experiments**:
1. Test domain adaptation on synthetic data with known transformation parameters
2. Validate active sampling efficiency against random selection on controlled dataset
3. Benchmark computational performance for real-time SHM deployment scenarios

## Open Questions the Paper Calls Out

**Open Question 1**: Can the framework be extended to multi-source scenarios to aggregate class information from heterogeneous source domains? The current DA-RVM assumes a single source domain, but obtaining comprehensive source data is challenging. Future work could demonstrate the framework aligning a target domain with multiple source domains, each containing only a subset of total class labels.

**Open Question 2**: Can the active sampling strategy effectively query and classify novel health states in the target domain absent from the source domain? While the current approach assigns high sampling probability to unexplored regions, this capability requires validation on datasets where target structures exhibit damage modes not present in source training data.

**Open Question 3**: Can the linear mapping assumption be relaxed to accommodate more complex, non-linear transformations without overfitting to sparse data? The strict linear transformation minimizes overfitting risk when labelled target data are scarce. Future work could investigate flexible, non-linear mappings using sparsity-inducing priors and compare performance against linear DA-RVM on datasets with significant non-linear domain shifts.

## Limitations

- Validation conducted on only three laboratory-scale bridges, limiting generalizability to real-world structural systems
- Controlled laboratory conditions may not fully capture environmental and operational variability encountered in field deployments
- Performance with severe domain shift between source and target structures remains unclear
- Computational efficiency for real-time SHM applications with large sensor networks not explicitly addressed

## Confidence

High confidence: DA-RVM achieves comparable classification performance to fully supervised methods while requiring fewer labelled samples
Medium confidence: Framework transferability claims across different structures based on three-bridge validation
Low confidence: Real-world deployment assertions regarding computational scalability and performance under severe environmental variability

## Next Checks

1. Field validation on at least 10+ real bridges with varying structural designs and environmental conditions to assess generalizability beyond laboratory settings
2. Comparative analysis against state-of-the-art semi-supervised and few-shot learning approaches under identical experimental conditions
3. Computational benchmarking to quantify inference time and resource requirements for real-time SHM applications with high-dimensional sensor networks