---
ver: rpa2
title: Few-shot Class-incremental Fault Diagnosis by Preserving Class-Agnostic Knowledge
  with Dual-Granularity Representations
arxiv_id: '2508.16634'
source_url: https://arxiv.org/abs/2508.16634
tags:
- fault
- learning
- class
- feature
- incremental
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of Few-Shot Class-Incremental Fault
  Diagnosis (FSC-FD), where diagnostic models must continuously learn new fault types
  from very few samples while retaining knowledge of previously seen faults. The key
  challenge is preventing catastrophic forgetting of old knowledge while avoiding
  overfitting to scarce new data.
---

# Few-shot Class-incremental Fault Diagnosis by Preserving Class-Agnostic Knowledge with Dual-Granularity Representations

## Quick Facts
- arXiv ID: 2508.16634
- Source URL: https://arxiv.org/abs/2508.16634
- Authors: Zhendong Yang; Jie Wang; Liansong Zong; Xiaorong Liu; Quan Qian; Shiqian Chen
- Reference count: 40
- Primary result: Dual-granularity network achieves 90.41% average accuracy on TEP imbalanced benchmark, outperforming state-of-the-art FSC-FD methods by 4-5% in class-imbalanced settings

## Executive Summary
This paper addresses Few-Shot Class-Incremental Fault Diagnosis (FSC-FD), where diagnostic models must continuously learn new fault types from very few samples while retaining knowledge of previously seen faults. The key challenge is preventing catastrophic forgetting of old knowledge while avoiding overfitting to scarce new data. The authors propose a Dual-Granularity Guidance Network (DGGN) that decouples feature learning into two parallel streams: a fine-grained, class-specific stream for capturing discriminative features from limited new samples, and a coarse-grained, class-agnostic stream for preserving stable, shared knowledge across all fault types. These two representations are dynamically fused via a multi-semantic cross-attention mechanism, where the stable coarse-grained knowledge guides the learning of fine-grained features.

## Method Summary
DGGN uses a dual-branch architecture where a class-specific branch continuously updates to capture discriminative features from new fault samples, while a class-agnostic branch remains frozen after initial training to preserve general fault semantics. The class-agnostic branch accumulates shared knowledge across all sessions via self-supervised learning (SimCLR + CaSSLe prediction alignment). Multi-semantic cross-attention enables the class-agnostic knowledge to regularize class-specific feature learning, reducing overfitting to scarce samples. A Boundary-Aware Exemplar Prioritization strategy selects informative samples for replay buffer, and a decoupled Balanced Random Forest classifier addresses classification bias from data imbalance. The framework is trained with multiple loss terms: supervised contrastive loss for feature compactness, knowledge distillation for old-class preservation, KL divergence for cross-domain guidance, and self-supervised contrastive loss for class-agnostic representation learning.

## Key Results
- DGGN achieves 90.41% average accuracy on TEP imbalanced benchmark vs. 71.06% without class-agnostic guidance
- On MFF imbalanced dataset, DGGN reaches 99.59% accuracy vs. 97.33% without knowledge transfer
- Long-tailed scenario results show 85.13% accuracy on TEP vs. 73.84% without multi-semantic cross-attention

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decoupling feature learning into class-specific and class-agnostic streams prevents representation entanglement and provides stable guidance for incremental learning.
- Mechanism: Two parallel branches operate on each input: (1) a class-specific branch continuously updated per session to capture discriminative features, and (2) a class-agnostic branch frozen after each session that preserves general fault semantics. The class-agnostic branch accumulates shared knowledge across all sessions via self-supervised learning (SimCLR + CaSSLe prediction alignment).
- Core assumption: Fault signals contain both discriminative, class-specific patterns AND general, class-agnostic properties (e.g., operating conditions, noise profiles) that remain stable across fault types and can guide new-class learning.
- Evidence anchors: [abstract] "Our DGGN explicitly decouples feature learning into two parallel streams"; [Section III.D] Class-agnostic encoder uses "prediction-based self-supervised learning approach from CaSSLe" with InfoNCE loss; [Section IV.E, Table III] Removing class-agnostic model drops average accuracy from 90.41% to 71.06% (TEP imbalanced); [Section IV.F.4, Fig. 7] CKA similarity analysis shows class-agnostic features remain highly stable across sessions (0.92-0.99 similarity) while class-specific features evolve dynamically (0.37-0.52).

### Mechanism 2
- Claim: Multi-semantic cross-attention enables class-agnostic knowledge to regularize class-specific feature learning, reducing overfitting to scarce samples and alleviating feature conflicts between old and new classes.
- Mechanism: Class-specific features (zcs) query both class-specific and class-agnostic features (zca) via multi-head attention. The fused representation (zm) is supervised with cross-entropy loss, but gradients are stopped for class-agnostic branch. KL divergence between fused-feature predictions and class-specific predictions transfers knowledge back to the class-specific encoder.
- Core assumption: Class-agnostic features contain complementary information that, when properly attended to, can expand the effective representation space for new classes without requiring additional labeled data.
- Evidence anchors: [abstract] "multi-semantic cross-attention mechanism, where the stable coarse-grained knowledge guides the learning of fine-grained features, preventing overfitting and alleviating feature conflicts"; [Section III.E.1, Eq. 16-17] Explicit formulation of multi-head attention over concatenated [Kcs, Kca] and [Vcs, Vca] with stopped gradients on class-agnostic features; [Section IV.E, Table III] Removing MSCA drops TEP long-tailed accuracy from 85.13% to 73.84%; removing knowledge transfer (KL alignment) drops MFF imbalanced from 99.59% to 97.33%.

### Mechanism 3
- Claim: Multi-Order Interaction Aggregation (MOIA) captures multi-scale contextual dependencies from limited fault signals, improving discriminability without requiring large sample sizes.
- Mechanism: Within ResNet blocks, MOIA uses three parallel depthwise separable convolutions with dilation rates d∈{1,2,3} to extract low/mid/high-level contextual features. Features are split by channel, processed at different receptive fields, then concatenated and compressed via 1×1 convolution.
- Core assumption: Fault signatures manifest at multiple temporal scales simultaneously, and parallel multi-branch processing can capture these more efficiently than serial stacking under data scarcity.
- Evidence anchors: [Section III.C.1, Eq. 3-5] Formal specification: Xl, Xm, Xh split, then Xm processed with DW5×5,d=2, Xh with DW7×7,d=3; [Section IV.E, Table III] Removing MOIA drops MFF long-tailed accuracy from 99.99% to 97.85% and TEP long-tailed from 85.13% to 83.74%; [Section IV.F.1, Table IV] Parallel MOIA (9.91M params) achieves 90.41% vs. best serial config M3 (8.54M params) at 88.77% on TEP imbalanced—parallel structure outperforms despite fewer parameters in serial alternatives.

## Foundational Learning

- Concept: **Catastrophic Forgetting in Neural Networks**
  - Why needed here: FSC-FD explicitly addresses forgetting when sequentially learning fault classes; understanding this motivates the dual-branch design
  - Quick check question: Can you explain why standard fine-tuning fails when adding new fault classes sequentially?

- Concept: **Contrastive Learning (Self-Supervised and Supervised)**
  - Why needed here: Class-agnostic branch uses SimCLR/CaSSLe (self-supervised); class-specific branch uses supervised contrastive loss for feature compactness
  - Quick check question: What's the difference between InfoNCE (Eq. 9) and supervised contrastive loss (Eq. 6), and why use both?

- Concept: **Knowledge Distillation for Incremental Learning**
  - Why needed here: Feature-level distillation preserves old-class relationships; cross-domain KL alignment transfers guidance from fused to class-specific features
  - Quick check question: Why does Eq. 18 use StopGradient on pm instead of standard teacher-student distillation?

- Concept: **Class Imbalance and Long-Tailed Distributions**
  - Why needed here: Real-world fault data is inherently imbalanced; BRF classifier and BAEP strategy specifically address this
  - Quick check question: How does Balanced Random Forest differ from standard Random Forest in handling minority fault classes?

## Architecture Onboarding

- Component map:
Input Signal → [Class-Specific Branch (ResNet-18 + MOIA)] → zcs
            ↘ [Class-Agnostic Branch (ResNet-18, frozen per session)] → zca
            
zcs + zca → [Multi-Semantic Cross-Attention] → zm → [Classifier] → pm

zcs → [Class-Specific Classifier] → pcs
     ↖ [KL Alignment Loss: SG(pm) → pcs]

Training: Ltotal = Lscl + Lkd + Lkl + λ·Lca + μ·Lmcls (Eq. 19-20)

Inference: zcs → [Balanced Random Forest] → Final Prediction

- Critical path:
  1. Base session: Train both branches jointly with sufficient data; freeze class-agnostic encoder f_ca after base session
  2. Incremental session t:
     - Update class-specific encoder f_cs with new data + replay buffer
     - Run class-agnostic forward pass (frozen) to get zca
     - Compute multi-semantic attention to get zm
     - Apply Lscl + Lkd + Lkl for class-specific updates
     - Train new BRF on all stored features
  3. Buffer update: Apply BAEP (Eq. 21) to select k=M/t boundary exemplars per class

- Design tradeoffs:
  - Parallel vs. serial MOIA: Parallel multi-branch captures multi-scale context better (Table IV) but adds ~1.4M parameters vs. serial stacking
  - Frozen vs. updated class-agnostic branch: Freezing ensures stability for guidance but may limit adaptability to drastically different fault mechanisms
  - BRF vs. neural classifier: BRF handles imbalance better (Table V: +12.66% over FCC on long-tailed) but requires separate training phase and feature storage
  - Memory budget: BAEP with M=100 (TEP) or M=10 (MFF)—smaller M increases forgetting risk but reduces storage

- Failure signatures:
  - Attention collapse: If attention weights saturate to Kcs (>95%), check class-agnostic feature quality via CKA similarity (should be <0.5 vs. class-specific)
  - Overfitting on new classes: If new-class accuracy is high but old-class accuracy drops sharply, increase replay buffer size or reduce Lkl weight
  - BRF bias: If majority class dominates predictions, verify balanced sampling in BRF bootstrapping; check minority class representation in buffer
  - MOIA redundancy: If removing MOIA doesn't hurt performance, fault signals may be single-scale; simplify to single-branch DWConv

- First 3 experiments:
  1. Baseline comparison on single dataset: Replicate TEP imbalanced results from Table II (2+2+2+2+2 classes, M=100). Verify: (a) base session accuracy ~99%, (b) final session accuracy ~73%, (c) average ~90%. If significantly lower, check BAEP implementation (Eq. 21) and Lkd gradient flow.
  2. Ablation on class-agnostic guidance: Remove class-agnostic branch entirely (w/o CA model in Table III). Expect ~19% drop on TEP imbalanced (90.41%→71.06%). This validates that performance gains come from guidance mechanism, not just architecture depth.
  3. Attention weight visualization: Extract attention weights from multi-semantic cross-attention during incremental session 3. Compute average attention ratio [Kcs vs. Kca]. If Kca attention <10%, class-agnostic features may not be providing useful guidance—check InfoNCE convergence and CKA stability.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the fixed memory buffer allocation in BAEP be adapted to dynamically prioritize exemplars based on class complexity or evolving data distributions?
- Basis in paper: [explicit] The authors state future work will focus on "developing dynamic memory management methods." Currently, BAEP uses a fixed quota k = M/t per class, which does not account for differences in intra-class variance or difficulty across fault types.
- Why unresolved: The paper demonstrates BAEP's superiority over random/Herding strategies but does not explore adaptive buffer allocation as new classes with varying complexity arrive.
- What evidence would resolve it: Experiments comparing fixed vs. adaptive memory allocation strategies on datasets with heterogeneous class difficulty, measuring per-class accuracy retention over many incremental sessions.

### Open Question 2
- Question: Can the dual-branch DGGN architecture be compressed or made more efficient without sacrificing the benefits of class-agnostic guidance?
- Basis in paper: [explicit] The conclusion identifies "optimizing the model architecture for greater efficiency" as a key future direction. The framework requires two parallel ResNet-18 encoders, doubling inference and storage costs.
- Why unresolved: While ablation studies validate each component's contribution, there is no analysis of parameter sharing, pruning, or lightweight alternatives that could reduce computational overhead.
- What evidence would resolve it: Systematic experiments on model compression (e.g., shared backbones, knowledge distillation to smaller networks) showing accuracy-efficiency trade-offs on TEP and MFF.

### Open Question 3
- Question: How robust is DGGN to cross-device or cross-domain transfer where training and deployment systems differ in sensor configurations or operating conditions?
- Basis in paper: [explicit] The authors explicitly call for "extending the framework to more complex cross-device or cross-domain scenarios." All reported experiments are within-dataset (TEP or MFF independently).
- Why unresolved: Domain shift between training environments and real-world deployment remains untested; domain adaptation mechanisms are not incorporated into the current design.
- What evidence would resolve it: Cross-domain experiments (e.g., train on TEP, evaluate on MFF, or use different sensor modalities) with domain discrepancy metrics and adaptation strategies.

### Open Question 4
- Question: How sensitive is DGGN's performance to the choice of hyperparameters (λ, μ, τ) and can these be automatically tuned for different fault diagnosis scenarios?
- Basis in paper: [inferred] The paper specifies fixed values (λ=0.5, μ=0.6, τ=0.07) without ablation or sensitivity analysis, leaving unclear whether these generalize across datasets or require manual tuning.
- Why unresolved: No systematic study of how performance varies with different loss balancing weights or temperature parameters across imbalanced and long-tailed settings.
- What evidence would resolve it: Hyperparameter sensitivity curves on both datasets and investigation of adaptive/auto-tuning methods (e.g., grid search, meta-learning) to set λ, μ, τ.

## Limitations

- The assumption that fault signals contain both class-specific discriminative patterns and class-agnostic shared properties may not hold for fault types with completely different physical mechanisms
- BAEP strategy prioritizes boundary samples but may underrepresent central-class examples critical for robust decision boundaries
- BRF classifier requires offline training and stored features, which may not scale well to very large fault libraries

## Confidence

- **High confidence**: Dual-branch architecture improves FSC-FD performance (Table III ablation shows 19% drop without class-agnostic guidance). Multi-semantic cross-attention provides effective knowledge transfer (Table III shows 11.29% drop without KL alignment). MOIA parallel structure outperforms serial alternatives (Table IV).
- **Medium confidence**: Class-agnostic features remain stable across sessions (CKA analysis shows 0.92-0.99 similarity), but stability doesn't guarantee semantic relevance for all fault types. BAEP effectively handles imbalance (Table V shows BRF outperforming FCC by 12.66% on long-tailed), though buffer size sensitivity wasn't fully explored.
- **Low confidence**: Generalization to fault types with vastly different signal characteristics remains untested. The claim that class-agnostic features capture "shared knowledge" across all fault types is based on internal consistency rather than external validation.

## Next Checks

1. Test DGGN on fault types with fundamentally different signal characteristics (e.g., rotating machinery vs. electrical systems) to verify class-agnostic features remain semantically meaningful.
2. Conduct ablation study varying buffer size M across multiple orders of magnitude (M=10, 50, 100, 500) to quantify forgetting-accuracy tradeoff.
3. Visualize class-agnostic feature embeddings using t-SNE across all fault types to verify they capture meaningful shared structure rather than just noise patterns.