---
ver: rpa2
title: Multilingual Vision-Language Models, A Survey
arxiv_id: '2509.22123'
source_url: https://arxiv.org/abs/2509.22123
tags:
- language
- multilingual
- languages
- vision-language
- computational
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey analyzes 31 multilingual vision-language models and
  21 benchmarks, revealing a key tension between language neutrality (consistent cross-lingual
  representations) and cultural awareness (adaptation to cultural contexts). While
  current training methods prioritize neutrality through contrastive learning and
  cross-lingual alignment, cultural awareness depends on diverse training data.
---

# Multilingual Vision-Language Models, A Survey

## Quick Facts
- **arXiv ID**: 2509.22123
- **Source URL**: https://arxiv.org/abs/2509.22123
- **Reference count**: 40
- **Key outcome**: Survey analyzes 31 multilingual VL models and 21 benchmarks, revealing tension between language neutrality (consistent cross-lingual representations) and cultural awareness (adaptation to cultural contexts).

## Executive Summary
This survey examines the current state of multilingual vision-language models, analyzing 31 models and 21 evaluation benchmarks. The field has evolved from encoder-only architectures to generative models that map visual features into multilingual language model spaces. A central finding is the tension between language neutrality—achieved through contrastive learning and cross-lingual alignment—and cultural awareness, which depends on diverse training data. The survey identifies significant gaps between training objectives and evaluation goals, particularly for generative tasks and low-resource language support.

## Method Summary
The survey systematically reviews 31 multilingual vision-language models and 21 benchmarks, categorizing models by architecture (encoder-only, decoder-only) and analyzing their training objectives and multilingual capabilities. The analysis synthesizes information from model papers, focusing on how models achieve cross-lingual transfer and cultural awareness. The survey examines evaluation benchmarks to understand how they measure language neutrality versus cultural awareness, noting that two-thirds use translation-based approaches prioritizing semantic consistency over cultural representation.

## Key Results
- Current training methods prioritize language neutrality through contrastive learning and cross-lingual alignment
- Cultural awareness emerges primarily from diverse training data rather than explicit training objectives
- Two-thirds of evaluation benchmarks use translation-based approaches, limiting cultural representation
- The field has evolved from encoder-only to generative architectures, with most benchmarks focusing on high-resource languages

## Why This Works (Mechanism)

### Mechanism 1: Language Neutrality via Contrastive Alignment
Multilingual VL models achieve cross-lingual transferability by aligning representations of translated text pairs to the same visual features using contrastive objectives. The model learns to map semantically equivalent text inputs to a shared embedding space by minimizing the distance between these text embeddings and the corresponding image embedding, effectively stripping language-specific features to create "language-neutral" multimodal representations.

### Mechanism 2: Cultural Awareness via Data Distribution Shifts
Cultural awareness emerges from including non-Western, region-specific images and native text in pre-training or fine-tuning data. By exposing the model to authentic images from different cultural contexts and local language descriptions, the model learns to bind specific cultural signifiers to region-specific outputs, overriding Western-centric priors often found in web-scraped datasets.

### Mechanism 3: Generative Transfer via Vision-to-LLM Mapping
Modern generative VL models achieve multilinguality by projecting visual features into the latent space of pre-trained multilingual LLMs, treating vision as a "foreign language." A projection layer converts visual patches into tokens that the MLLM can process alongside text tokens, inheriting reasoning capabilities and multilingual knowledge from the frozen or lightly fine-tuned text decoder.

## Foundational Learning

- **Language Neutrality vs. Cultural Awareness**: Central tension between consistent cross-lingual representations (for factual retrieval) and context-specific adaptation (for nuanced generation). *Quick check: If you translate "dinner" into German and Swahili, should the model retrieve the exact same image (Neutrality) or images reflecting local cuisine (Cultural Awareness)?*

- **Contrastive Learning (CL)**: Dominant pre-training objective for dual-encoder models to align image and text embeddings. *Quick check: How does the loss function distinguish between a positive image-text pair and a negative (incorrect) pair in a batch?*

- **Zero-Shot Cross-Lingual Transfer**: Models perform tasks in languages unseen during fine-tuning by relying on implicit multilingual support of the underlying text encoder. *Quick check: Why can a model fine-tuned on English VQA data answer questions in Hindi without seeing any Hindi VQA examples?*

## Architecture Onboarding

- **Component map**: Vision Encoder (ViT/CNN) -> Text Encoder/Decoder (Multilingual Transformer) -> Fusion/Projection (Cross-attention/Linear Projector)

- **Critical path**: 1) Load pre-trained Multilingual LM and Vision Encoder 2) Train fusion layers on massive image-text pairs 3) Fine-tune on multilingual instruction data

- **Design tradeoffs**: Dual Encoder (fast retrieval, poor reasoning) vs. One-Tower Encoder (good reasoning, expensive) vs. Generative Decoder (flexible, difficult to evaluate)

- **Failure signatures**: Language Drift (generates English despite non-English prompt), Western Bias (uses Western concepts inappropriately), Loss of Resolution (fixed resolution distortion)

- **First 3 experiments**: 1) Zero-Shot Retrieval: Test encoder model on xFlickrCo for cross-lingual transfer 2) Neutrality vs. Culture Ablation: Evaluate generative model on translation-based vs. cultural benchmark 3) Visual Grounding Check: Input contradicting visual-text pairs in low-resource language

## Open Questions the Paper Calls Out

### Open Question 1
Can specific training objectives be formulated to explicitly optimize for cultural awareness, rather than relying implicitly on data diversity? The authors state that explicit cultural awareness objectives remain absent from current training procedures, as it is not clear how this could be achieved.

### Open Question 2
How can benchmarks be designed to rigorously evaluate the generative capabilities of decoder-only models, given the dominance of classification-based evaluation? Current evaluation benchmarks often rely on classification tasks, which do not adequately assess the generative capabilities of contemporary models.

### Open Question 3
How can multilingual vision-language models resolve the fundamental tension between language neutrality (consistent cross-lingual representations) and cultural awareness (context-specific adaptation)? The paper concludes that this tension remains unresolved despite being central to the field's progress.

### Open Question 4
How can evaluation metrics be improved to capture generation quality across languages without assuming semantic equivalence? Current language generation metrics often fail to capture generation quality appropriately, particularly when benchmarks rely on translation-based approaches that strip away cultural context.

## Limitations

- Analysis relies heavily on reported benchmark results rather than independent replication
- True magnitude of neutrality-awareness trade-off remains unquantified across models
- Paper does not systematically evaluate whether translation-based methodologies artificially constrain cultural representation

## Confidence

- **High Confidence**: Existence of 31 reviewed models and 21 benchmarks is verifiable; general distinction between encoder-only and generative architectures is well-established
- **Medium Confidence**: Claim that current training methods prioritize language neutrality through contrastive learning is supported by model descriptions
- **Low Confidence**: Assertion that cultural awareness depends primarily on diverse training data rather than explicit objectives lacks direct experimental validation

## Next Checks

1. Replicate Neutrality vs. Culture Gap: Select 3 representative models and evaluate them on both translation-based (XVNLI) and culturally grounded (MARVL) benchmarks to quantify performance differential

2. Test Visual Grounding Robustness: Design experiment where models receive contradicting visual-text pairs in low-resource languages to determine whether they prioritize visual input or language priors

3. Analyze Training Data Composition: Examine training data sources for 2-3 generative models to verify proportion of Western vs. non-Western content and correlate with performance on cultural reasoning tasks