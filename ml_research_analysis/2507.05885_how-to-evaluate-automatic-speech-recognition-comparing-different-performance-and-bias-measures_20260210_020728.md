---
ver: rpa2
title: 'How to Evaluate Automatic Speech Recognition: Comparing Different Performance
  and Bias Measures'
arxiv_id: '2507.05885'
source_url: https://arxiv.org/abs/2507.05885
tags:
- bias
- speech
- performance
- groups
- speaker
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates bias in automatic speech recognition (ASR)
  systems against diverse speaker groups such as children, teenagers, non-native speakers,
  and older adults. It compares various performance and bias measures to evaluate
  state-of-the-art end-to-end ASR models for Dutch, both before and after applying
  bias mitigation strategies.
---

# How to Evaluate Automatic Speech Recognition: Comparing Different Performance and Bias Measures

## Quick Facts
- **arXiv ID**: 2507.05885
- **Source URL**: https://arxiv.org/abs/2507.05885
- **Reference count**: 0
- **Primary result**: Averaged WERs mask ASR disparities; median+stdev and relative bias measures (G2min/G2norm) better capture group-level performance and persistent non-native speaker disadvantage.

## Executive Summary
This study investigates bias in Dutch ASR systems against children, teenagers, non-native speakers, and older adults. It compares performance and bias measures to evaluate state-of-the-art end-to-end models before and after augmentation-based mitigation. Results show that averaged error rates alone are insufficient, as they mask disparities across speaker groups. Key findings include significant performance variation within groups (high standard deviation) and persistent bias against non-native speakers despite mitigation efforts.

## Method Summary
The authors evaluate two ASR setups: a Conformer trained from scratch with ESPNet using 80-dim log-Mel + 3-dim pitch features, and Whisper-small fine-tuned on CGN. Training used three augmentation conditions (NoAug, SpAug with speed perturbation, SpAug + SpecAugment) on CGN (~430h adult native speech). Testing included CGN read/CTS and Jasmin corpus covering children (6-13), teenagers (12-18), non-native teens/adults, and older adults (65+). Performance metrics include mean, median, standard deviation, and range of WERs; bias measures include G2min/G2norm (absolute and relative differences) and Overall Bias meta-measures.

## Key Results
- Averaged WERs mask significant disparities across speaker groups.
- High standard deviation within groups reveals performance variation.
- Non-native speakers remain disadvantaged despite augmentation-based mitigation.
- Median and standard deviation better capture performance than mean alone.
- Relative bias measures (G2norm reldiff) highlight persistent non-native speaker disadvantage.

## Why This Works (Mechanism)
None provided.

## Foundational Learning
- **WER (Word Error Rate)**: Measures ASR accuracy by comparing hypotheses to reference transcripts. *Why needed*: Primary metric for quantifying ASR performance across speaker groups.
- **G2min/G2norm**: Bias measures comparing each group's WER to the best-performing group (G2min) and relative to that difference (G2norm). *Why needed*: Reveal systematic disparities masked by average WERs.
- **SpecAugment**: Data augmentation technique applying time/frequency masking to audio features. *Why needed*: Standard mitigation strategy whose differential impact on speaker groups is evaluated.
- **Standard Deviation of WERs**: Statistical measure of performance variation within and across groups. *Why needed*: High stdev indicates inconsistent performance that averages hide.
- **Median WER**: Robust central tendency measure less affected by outliers than mean. *Why needed*: Better represents typical group performance when distributions are skewed.

## Architecture Onboarding

**Component Map**
CGN training data → Feature extraction (80-dim log-Mel + 3-dim pitch) → Tokenizer (5k BPE) → Conformer/Whisper model → Augmentation pipeline → Evaluation on test sets → WER computation → Bias measure calculation

**Critical Path**
Feature extraction → Model training → Augmentation → Evaluation → Bias analysis

**Design Tradeoffs**
- Mean vs. median WER: Mean sensitive to outliers, median more robust but less sensitive to improvements in high-error groups
- Absolute vs. relative bias: Absolute shows raw differences, relative normalizes by best group performance
- Augmentation strength: Higher augmentation may improve average performance but exacerbate relative bias against non-native speakers

**Failure Signatures**
- Low average WER but high stdev across groups indicates masked bias
- Improvement in average WER accompanied by increased G2norm reldiff suggests augmentation benefits majority groups more
- Consistent high WER for non-native speakers across conditions indicates systematic bias

**3 First Experiments**
1. Train Conformer on CGN with NoAug condition and evaluate on all test sets
2. Apply speed perturbation (0.9×/1.1×) and measure change in average WER vs. G2norm reldiff
3. Fine-tune Whisper-small on CGN and compare Read vs. HMI WERs across speaker groups

## Open Questions the Paper Calls Out
- How do proposed statistical bias measures correlate with human perceptions of fairness and usability?
- Why do standard data augmentations improve average performance while simultaneously increasing relative bias against non-native speakers?
- Do the recommendations to report median and standard deviation generalize to languages with different phonological structures, such as tonal languages?

## Limitations
- Conformer architecture and training hyperparameters are not fully specified
- CGN and Jasmin corpus licensing/accessibility remain unclear
- Study focuses on WER-based bias without assessing perceptual impact of transcription errors
- Mitigation strategies show limited effectiveness against non-native speaker bias

## Confidence
- **High confidence**: Significant within-group WER variation and inadequacy of average error rates
- **Medium confidence**: Persistent non-native speaker disadvantage despite augmentation, due to unspecified augmentation parameters
- **Medium confidence**: Median and standard deviation recommendations, though sufficiency for capturing nuanced bias not fully validated

## Next Checks
1. Replicate Conformer and Whisper-small training on publicly accessible Dutch speech datasets to verify reported WER ranges
2. Compute and compare G2min and G2norm (absolute and relative) across speaker groups for baseline and augmented models
3. Assess impact of varying SpecAugment and speed perturbation parameters on both average WER and relative bias measures