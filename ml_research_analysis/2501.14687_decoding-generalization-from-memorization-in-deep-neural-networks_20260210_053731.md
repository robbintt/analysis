---
ver: rpa2
title: Decoding Generalization from Memorization in Deep Neural Networks
arxiv_id: '2501.14687'
source_url: https://arxiv.org/abs/2501.14687
tags:
- masc
- corruption
- accuracy
- training
- degree
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work explores why deep networks trained with shuffled labels\u2014\
  i.e., models that memorize\u2014tend to generalize poorly to true labels. It introduces\
  \ the Minimum Angle Subspace Classifier (MASC), a lightweight probe that classifies\
  \ data points by measuring the angle between layer outputs and class-conditioned\
  \ subspaces built from training data."
---

# Decoding Generalization from Memorization in Deep Neural Networks

## Quick Facts
- arXiv ID: 2501.14687
- Source URL: https://arxiv.org/abs/2501.14687
- Reference count: 40
- Introduces Minimum Angle Subspace Classifier (MASC) that outperforms deep networks on true labels even after label shuffling

## Executive Summary
This work introduces the Minimum Angle Subspace Classifier (MASC), a lightweight probe that measures the angle between layer outputs and class-conditioned subspaces built from training data. When applied to at least one layer of models trained with shuffled labels, MASC often achieves significantly higher test accuracy than the model itself—sometimes by over 150%. Experiments across MLP, CNN, AlexNet, and ResNet-18 models trained on MNIST, Fashion-MNIST, CIFAR-10, CIFAR-100, and Tiny ImageNet show that MASC, using true-label subspaces, performs even better, demonstrating that layerwise representations retain substantial ability to generalize to true labels.

## Method Summary
The Minimum Angle Subspace Classifier (MASC) is a probing mechanism that classifies data points by measuring the angle between layer outputs and class-conditioned subspaces built from training data. The method constructs subspaces for each class using layer activations from clean validation data, then assigns test samples to the class with the smallest subspace angle. This approach works even when models are trained on shuffled labels and generalizes across architectures including MLPs, CNNs, AlexNet, and ResNet-18 on datasets like MNIST, CIFAR-10, and Tiny ImageNet.

## Key Results
- MASC applied to at least one layer often achieves significantly higher test accuracy than the model itself—sometimes by over 150%
- Results persist even with high label corruption (e.g., 80% or 100%)
- MASC using true-label subspaces performs better than with shuffled labels, showing retained generalization capacity
- Probes like logistic regression and nearest-class mean show comparable performance in some settings
- MASC-based relabeling can modestly improve model generalization after retraining

## Why This Works (Mechanism)
The method exploits the geometric structure preserved in layerwise representations, even when models memorize shuffled labels. By measuring angles to class-conditioned subspaces, MASC extracts latent generalization capacity that the trained model fails to utilize.

## Foundational Learning
- **Subspace Geometry**: Understanding how data points relate to class-conditioned subspaces is crucial for interpreting MASC's angle-based classification. Quick check: Verify subspace construction correctly captures class-specific patterns.
- **Angle-Based Classification**: The minimum angle criterion is central to MASC's ability to distinguish between classes. Quick check: Confirm angle calculations are stable across different input distributions.
- **Layerwise Representations**: MASC leverages intermediate layer activations, so understanding how representations evolve through the network is key. Quick check: Test probe performance on different layers to identify optimal depth.
- **Label Noise Robustness**: The study's focus on models trained with shuffled labels highlights how probing can recover generalization even under extreme noise. Quick check: Compare MASC performance across varying noise levels.

## Architecture Onboarding
**Component Map**: Input -> Layerwise Activations -> Subspace Construction -> Angle Measurement -> Class Assignment
**Critical Path**: Clean validation data → Layer activation extraction → Class subspace building → Test sample angle computation → Minimum angle classification
**Design Tradeoffs**: Subspace dimensionality vs. overfitting; angle computation complexity vs. speed; layer selection depth vs. representation quality
**Failure Signatures**: High angle variance across classes suggests poor subspace separation; probe accuracy drops if validation data is noisy; performance degrades if layer activations are too abstract or too shallow
**First Experiments**: 1) Probe each layer separately to find optimal depth, 2) Compare angle-based vs. distance-based classification, 3) Test subspace dimensionality impact on accuracy

## Open Questions the Paper Calls Out
None

## Limitations
- Relies heavily on access to clean validation data to build subspaces
- Reported gains may be inflated by specific architectural or dataset choices; absent on larger-scale datasets
- Probing mechanism's sensitivity to layer selection, subspace dimensionality, and regularization choices is not fully explored

## Confidence
- Core claim (layerwise representations retain strong generalization capacity): **High** for controlled experiments, **Medium** for generalization across diverse real-world conditions
- Relabeling improvement effect: **Low** confidence due to limited ablation and statistical testing

## Next Checks
1. Replicate MASC's performance on larger-scale datasets (e.g., ImageNet) and diverse architectures (e.g., transformers, ViTs)
2. Test the probe's behavior under varying subspace dimensionality and compare robustness to other probing methods like logistic regression and nearest-class mean across more noise levels
3. Conduct ablation studies on layer selection strategies and assess whether improvements persist without clean validation data