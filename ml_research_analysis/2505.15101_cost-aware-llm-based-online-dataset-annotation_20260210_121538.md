---
ver: rpa2
title: Cost-aware LLM-based Online Dataset Annotation
arxiv_id: '2505.15101'
source_url: https://arxiv.org/abs/2505.15101
tags:
- accuracy
- camv
- cost
- kmin
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes CaMVo, a cost-aware online framework for LLM-based
  dataset annotation. The method adaptively selects a subset of LLMs for each data
  instance by estimating lower confidence bounds on labeling accuracy using contextual
  embeddings and a LinUCB-based selection mechanism.
---

# Cost-aware LLM-based Online Dataset Annotation

## Quick Facts
- arXiv ID: 2505.15101
- Source URL: https://arxiv.org/abs/2505.15101
- Reference count: 40
- Primary result: Achieves comparable accuracy to full majority voting while reducing labeling costs by up to 40% on MMLU and 50% on IMDB without ground-truth labels

## Executive Summary
This paper introduces CaMVo, a cost-aware online framework for LLM-based dataset annotation that adaptively selects subsets of LLMs per instance to minimize labeling costs while maintaining accuracy. The method estimates lower confidence bounds on labeling accuracy using contextual embeddings and a LinUCB-based selection mechanism, operating without ground-truth labels or pre-training. Experiments on MMLU and IMDB datasets demonstrate that CaMVo achieves comparable or superior accuracy to full majority voting while reducing labeling costs by up to 40% on MMLU and 50% on IMDB.

## Method Summary
CaMVo operates by maintaining per-LLM ridge regression parameters (A_i, b_i) that map d-dimensional embeddings to correctness estimates, computing confidence q_i,t(e_t) = e_t^T A_i^{-1} b_i with uncertainty terms. The algorithm selects minimum-cost LLM subsets whose aggregated confidence exceeds threshold δ, using weighted majority voting for final predictions. A Bayesian beta-mixture model calibrates LLM self-reported confidence scores against correctness, and the system updates estimates online during the annotation process without requiring ground-truth labels.

## Key Results
- Achieves 40% cost reduction on MMLU dataset while maintaining accuracy comparable to full majority voting
- Achieves 50% cost reduction on IMDB Movie Review dataset
- Outperforms baselines including lowest-cost LLM selection, highest-weight LLM selection, and random subset selection

## Why This Works (Mechanism)

### Mechanism 1: LinUCB-Based Contextual Confidence Estimation
The algorithm estimates a lower confidence bound on each LLM's correctness probability conditioned on input embeddings, enabling instance-specific model selection. It treats each LLM as a bandit arm, maintaining per-LLM ridge regression parameters that map embeddings to correctness estimates, computing confidence with uncertainty terms. The core assumption is that LLM correctness probability has a learnable relationship with input embeddings, and the evidence shows this enables adaptive selection without ground-truth labels.

### Mechanism 2: Bayesian Beta-Mixture Confidence Calibration
Self-reported LLM confidence scores are calibrated against correctness via Bayesian posterior estimation, transforming raw confidence into correctness probability. The model uses Beta-distributed random variables for conditional likelihood of confidence given latent correctness, computing posterior probabilities weighted by historical accuracy. The core assumption is that LLM self-confidence correlates with actual correctness, with evidence showing this calibration enables more accurate confidence estimation.

### Mechanism 3: Cost-Minimizing Subset Selection with Independence Assumption
The algorithm selects minimum-cost LLM subsets whose aggregated confidence exceeds threshold δ while maintaining accuracy. It solves an optimization problem to find lowest cost subset with sufficient confidence, using weighted majority voting for aggregation. The core assumption is that LLM outputs are conditionally independent given the input instance, though the evidence shows this assumption can break down when models have correlated error patterns.

## Foundational Learning

### Concept: Contextual Bandits and LinUCB
Why needed here: CaMVo frames LLM selection as a contextual bandit where embeddings provide context for per-instance decisions. Understanding exploration-exploitation tradeoffs and why uncertainty bonuses prevent premature convergence is essential for tuning α.
Quick check question: Why does LinUCB add α√(e^T A^{-1} e) to the reward estimate, and what failure mode occurs if α is set too low?

### Concept: Beta Distribution and Conjugate Bayesian Inference
Why needed here: The confidence calibration model uses Beta distributions as likelihoods. Understanding conjugate priors and method-of-moments estimation enables implementing and debugging Est_i().
Quick check question: Given confidence scores [0.8, 0.9, 0.7] for correct predictions and [0.3, 0.4] for incorrect predictions, sketch how method-of-moments would estimate Beta(α_1, β_1).

### Concept: Weighted Majority Voting Theory
Why needed here: CaMVo's theoretical foundation relies on confidence bounds for weighted majority voting. Understanding why aggregating independent >50%-accurate voters improves outcomes—and why correlation breaks this—is crucial for interpreting results.
Quick check question: Under independence, if three models have accuracies [0.6, 0.7, 0.8] with equal weights, what's the minimum probability majority voting succeeds?

## Architecture Onboarding

### Component Map:
Input x_t → Embedder (384-dim) → LinUCB Estimator [per LLM i] → Beta Estimator Est_i(θ_i,t) → L_i,t → Oracle: min cost subset A s.t. δ_A(L,ω) ≥ δ → Query LLMs in A → Responses {y_i,t} → Weighted Majority Vote ŷ_t → Update: A_i ← A_i + e_t e_t^T, b_i ← b_i + r_i,t e_t

### Critical Path:
1. **Embedding generation** (all-MiniLM-L6-v2, 384-dim)—must capture task-relevant semantics
2. **LinUCB confidence estimation** (matrix inversion O(d³) per LLM, but A_i updated incrementally)
3. **Bayesian posterior computation** (Beta mixture, O(1) per LLM)
4. **Oracle subset search** (exponential in K; greedy/heuristic approximation needed for large K)
5. **Parameter updates** (only when |A| > 1 to avoid trivial reward=1)

### Design Tradeoffs:
- **δ threshold**: Higher δ → higher accuracy, higher cost. Paper shows 0.96–0.99 practical; below 0.90 cost savings saturate at k_min floor
- **k_min**: Prevents degenerate single-model selection (no parameter updates when |A|=1). k_min=3 recommended; k_min=2 always favors higher-weight LLM
- **Approximation**: Full Lemma 2.1 (exponential sum) vs. Beta-CDF approximation trades exactness for O(1) computation
- **Correlation handling**: CCaMVo extension (Appendix G) adds Monte Carlo simulation over Gaussian copula—marginal gains, significant complexity

### Failure Signatures:
- **Accuracy drops below target**: Early subset selection bias; verify δ achievable given LLM accuracies; check if exploration parameter α too conservative
- **Cost doesn't decrease**: Embeddings not discriminating; LinUCB not learning (check A_i conditioning); verify reward signal r_i,t propagates
- **Single LLM dominates**: Independence assumption violated; models have correlated error patterns; consider CCaMVo or diversity-aware selection
- **Accuracy degrades with more models**: Observed on IMDB when individual accuracies diverge—ensemble gains diminish when performance gaps are large

### First 3 Experiments:
1. **Baseline validation**: Run full majority voting (all K LLMs) on 500–1000 held-out instances. Establish accuracy ceiling, cost floor, and per-LLM accuracies. Verify no single LLM dominates unexpectedly.
2. **δ sweep with k_min=3**: Test δ ∈ {0.95, 0.97, 0.99}. Plot cumulative accuracy and cost curves. Verify algorithm meets target accuracy at each δ. Check convergence speed.
3. **Embedding sensitivity**: Replace all-MiniLM-L6-v2 with alternative embedders. Measure impact on: (a) LinUCB convergence speed, (b) final accuracy-cost tradeoff. If performance degrades, embeddings may not capture task structure.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can a diversity-aware selection mechanism or a joint confidence model be integrated into CaMVo to better handle inter-LLM correlations without incurring the computational costs associated with the Monte Carlo methods used in CCaMVo?
- Basis in paper: [explicit] The Conclusion states, "Future work will explore diversity-aware selection and joint confidence models to mitigate correlated errors."
- Why unresolved: While CCaMVo (Appendix G) attempts to model correlations, the paper notes it yields only marginal improvements and adds complexity; a more principled method for diverse subset selection is needed.
- What evidence would resolve it: An algorithm that explicitly maximizes the diversity of the selected LLM subset and demonstrates statistically significant accuracy gains over CCaMVo in high-correlation regimes.

### Open Question 2
- Question: How can the aggregation and weight update steps be adapted for regression or ranking tasks where the discrete "correctness" signal used in classification is unavailable?
- Basis in paper: [explicit] The Conclusion notes, "Our method can be naturally extended... For regression... For ranking... Future work will explore [these extensions]."
- Why unresolved: The current algorithm relies on binary rewards to update weights via LinUCB; continuous or ordinal outputs require a different reward signal definition.
- What evidence would resolve it: A modified CaMVo framework tested on a regression benchmark or a ranking task that maintains cost efficiency without relying on binary label matching.

### Open Question 3
- Question: Does allowing CaMVo to revisit and refine previously annotated instances (iterative relabeling) significantly improve final dataset accuracy as contextual estimates converge?
- Basis in paper: [explicit] The Conclusion states, "We will also extend CaMVo to support iterative relabeling, allowing previously annotated instances to be revisited and refined..."
- Why unresolved: The current online framework makes a single sequential pass, meaning early labels are assigned when confidence estimates are least accurate.
- What evidence would resolve it: Experiments comparing the accuracy of labels assigned in early rounds versus those revised by a relabeling mechanism after the model has explored a sufficient number of instances.

## Limitations

- **Independence assumption fragility**: The core efficiency gain relies on LLM outputs being conditionally independent given the input, but this assumption frequently breaks in practice, particularly on correlated tasks like sentiment analysis.
- **Oracle scalability**: With K=7 LLMs, subset enumeration is feasible, but the approach doesn't scale to larger model pools and lacks approximation guarantees for the subset selection problem.
- **Embedding dependence**: Performance hinges on embeddings capturing task-relevant features for LinUCB to learn from, but no ablation studies test embedding quality or explore alternatives.

## Confidence

- **High confidence**: Cost reduction claims (40% MMLU, 50% IMDB) and accuracy maintenance relative to full majority voting are well-supported by experimental results.
- **Medium confidence**: The Beta-mixture calibration model and LinUCB confidence estimation mechanisms are theoretically sound, but lack extensive validation in isolation.
- **Low confidence**: The claim of operating "without ground-truth labels or pre-training" uses predicted labels as training signals, which deserves more scrutiny regarding learning dynamics and potential bias.

## Next Checks

1. **Independence violation quantification**: Systematically measure LLM output correlation on both datasets and test how correlation levels impact CaMVo's cost savings. If correlation exceeds 0.7, the current approach may need modification.
2. **Oracle approximation scalability**: Implement and test greedy or beam search approximations for subset selection with K=20+ LLMs. Measure accuracy-cost tradeoff degradation compared to exact enumeration.
3. **Embedding ablation study**: Replace all-MiniLM-L6-v2 with random embeddings, task-specific embeddings, and no embeddings. Quantify how embedding quality affects LinUCB learning speed and final cost savings.