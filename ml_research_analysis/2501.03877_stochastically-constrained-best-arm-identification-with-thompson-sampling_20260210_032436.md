---
ver: rpa2
title: Stochastically Constrained Best Arm Identification with Thompson Sampling
arxiv_id: '2501.03877'
source_url: https://arxiv.org/abs/2501.03877
tags:
- feasible
- arms
- best
- sampling
- probability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper tackles the Best Feasible Arm Identification (BFAI)\
  \ problem in a Bayesian setting, where the goal is to identify the best arm subject\
  \ to stochastic constraints on multiple performance measures. The authors extend\
  \ Thompson Sampling (TS) to BFAI by introducing a parameter \u03B2 to control sampling\
  \ probabilities, creating the BFAI-TS algorithm."
---

# Stochastically Constrained Best Arm Identification with Thompson Sampling
## Quick Facts
- arXiv ID: 2501.03877
- Source URL: https://arxiv.org/abs/2501.03877
- Reference count: 40
- Primary result: Asymptotic optimality in both sample allocation and posterior convergence rate for BFAI-TS algorithm

## Executive Summary
This paper addresses the Best Feasible Arm Identification (BFAI) problem in a Bayesian setting where the goal is to identify the optimal arm subject to stochastic constraints on multiple performance measures. The authors propose BFAI-TS, an extension of Thompson Sampling that incorporates a parameter β to control sampling probabilities and balance exploration with constraint satisfaction. Theoretical analysis establishes asymptotic optimality guarantees for the algorithm, showing it achieves the optimal convergence rate when β is properly chosen. Extensive numerical experiments on both synthetic and real-world datasets demonstrate that BFAI-TS outperforms existing benchmarks, particularly in scenarios with limited samples.

## Method Summary
The paper introduces BFAI-TS, a Thompson Sampling-based algorithm for Best Feasible Arm Identification with stochastic constraints. The algorithm extends standard Thompson Sampling by introducing a parameter β that controls the sampling probability of each arm based on both its expected reward and constraint satisfaction probability. At each iteration, arms are sampled from their posterior distributions, and the algorithm updates beliefs about both rewards and constraint satisfaction. The key innovation is the incorporation of constraint information into the sampling mechanism through the β parameter, which balances exploration of uncertain arms against exploitation of apparently optimal arms. Theoretical analysis shows that when β is set to the optimal value β*, the algorithm achieves asymptotically optimal sample allocation and posterior convergence rates.

## Key Results
- BFAI-TS achieves asymptotic optimality in sample allocation and posterior convergence rate
- Theoretical convergence rate is characterized by Γβ, which depends on the parameter β
- Numerical experiments show BFAI-TS outperforms benchmarks, especially in small-sample regimes
- Optimal performance is achieved when β is set to β*, though this may be impractical to compute

## Why This Works (Mechanism)
The mechanism relies on Thompson Sampling's inherent exploration-exploitation balance, enhanced by the β parameter that incorporates constraint satisfaction into the sampling probability calculation. By sampling from posterior distributions and updating beliefs based on observed rewards and constraint outcomes, the algorithm progressively concentrates samples on the optimal feasible arm while maintaining sufficient exploration to verify constraint satisfaction. The β parameter controls the trade-off between exploring arms with uncertain constraint satisfaction and exploiting arms that appear optimal, enabling the algorithm to adapt its sampling strategy based on the difficulty of satisfying constraints.

## Foundational Learning
1. Thompson Sampling basics: Understanding how TS balances exploration and exploitation through posterior sampling is crucial for grasping BFAI-TS's foundation
   - Why needed: Provides the baseline algorithm that BFAI-TS extends
   - Quick check: Can you explain how standard TS works in a simple multi-armed bandit setting?

2. Bayesian posterior updating: Knowledge of how to update posterior distributions for both rewards and constraint satisfaction probabilities is essential
   - Why needed: BFAI-TS relies on maintaining and updating posteriors for each arm
   - Quick check: Can you derive the posterior update equations for a Bernoulli bandit?

3. Stochastic constraints: Understanding how to handle constraints that are satisfied probabilistically rather than deterministically
   - Why needed: The core challenge of BFAI is identifying arms that satisfy constraints with high probability
   - Quick check: Can you explain the difference between deterministic and stochastic constraints in bandit problems?

4. Asymptotic analysis: Familiarity with techniques for proving convergence rates and optimality in the limit
   - Why needed: The paper's theoretical guarantees are asymptotic in nature
   - Quick check: Can you explain what it means for an algorithm to be asymptotically optimal?

## Architecture Onboarding
Component map: Prior distributions -> Thompson Sampling with β parameter -> Posterior updates -> Constraint satisfaction checking -> Optimal arm identification

Critical path: Initialize priors → Sample arms from posteriors → Observe rewards and constraints → Update posteriors → Repeat until confidence threshold reached → Return best feasible arm

Design tradeoffs: The β parameter allows flexible control over exploration vs. constraint satisfaction, but requires knowledge of problem-specific constants for optimal setting; the algorithm maintains full posterior distributions for each arm, providing rich uncertainty quantification but at computational cost.

Failure signatures: Algorithm may fail to identify the correct optimal arm if constraints are too difficult to verify; performance degrades when prior distributions are misspecified; computational complexity increases significantly with number of arms and constraints.

First experiments:
1. Verify basic TS behavior on a simple unconstrained bandit problem
2. Test constraint satisfaction probability estimation accuracy on synthetic data
3. Evaluate convergence rate on a small problem with known optimal solution

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided content.

## Limitations
- Theoretical analysis relies on asymptotic conditions that may not hold in finite-sample regimes
- Optimal parameter β* may be impractical to compute in real-world applications
- Assumes independent arms and known prior distributions, which may not hold in practice
- Focuses on fixed-confidence setting, leaving fixed-budget setting unexplored

## Confidence
- Asymptotic optimality claims: High
- Numerical performance superiority: Medium (small sample size results show promise but need more extensive validation)
- Parameter selection guidance: Low (theoretical β* may be impractical to compute)

## Next Checks
1. Empirical evaluation of the algorithm's performance when the optimal parameter β is unknown and must be estimated from data
2. Scalability testing with increasing numbers of arms and constraints to assess computational feasibility
3. Validation of the algorithm's performance in non-stationary environments where reward distributions may change over time