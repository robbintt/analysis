---
ver: rpa2
title: Safely Learning Controlled Stochastic Dynamics
arxiv_id: '2506.02754'
source_url: https://arxiv.org/abs/2506.02754
tags:
- safe
- safety
- control
- learning
- dynamics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a method for safely learning controlled stochastic
  dynamics from trajectory data. The approach ensures system safety during both training
  and deployment by incrementally expanding a known safe control set using kernel-based
  confidence bounds.
---

# Safely Learning Controlled Stochastic Dynamics

## Quick Facts
- arXiv ID: 2506.02754
- Source URL: https://arxiv.org/abs/2506.02754
- Authors: Luc Brogat-Motte; Alessandro Rudi; Riccardo Bonalli
- Reference count: 40
- This paper introduces a method for safely learning controlled stochastic dynamics from trajectory data, ensuring safety during both training and deployment.

## Executive Summary
This paper addresses the challenge of safely learning controlled stochastic dynamics from trajectory data. The method incrementally expands a known safe control set using kernel-based confidence bounds, ensuring safety during both training and deployment. It jointly learns three models - system dynamics, safety probabilities, and reset feasibility - all with uncertainty estimates. The approach requires only mild smoothness assumptions and an initial safe control set, making it broadly applicable. Theoretical guarantees ensure safety during exploration while providing estimation rates adaptive to the system's Sobolev regularity.

## Method Summary
The method learns controlled stochastic dynamics by jointly estimating system density, safety probabilities, and reset probabilities through kernel ridge regression. At each iteration, it computes lower confidence bounds on safety and reset probabilities, constructs a safe-resettable feasible set, and selects the next control by maximizing uncertainty over this set. The approach uses Matérn kernels to encode Sobolev smoothness assumptions, enabling adaptive estimation rates. Safety is maintained by only considering controls that satisfy confidence-based safety and reset constraints, while exploration is guided by uncertainty maximization to efficiently cover the control space.

## Key Results
- The method maintains safety during exploration with zero violations across multiple threshold settings
- Safety and reset probability estimates achieve MSE as low as 0.002 with relaxed thresholds
- The safe control set expands iteratively while ensuring all selected controls satisfy safety constraints

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The method maintains safety during exploration by using kernel-based confidence bounds to construct conservative lower bounds on safety and reset probabilities.
- **Mechanism:** At each iteration, safety level $s(\theta, t)$ and reset level $r(\theta, t)$ are estimated via kernel ridge regression with Matérn kernels. Predictive uncertainty $\sigma_N^2(\theta, t)$ is computed from the kernel posterior. Lower confidence bounds (LCBs) are formed: $\text{LCB}^s_N(\theta, T) = \inf_{t \in [0,T]} (\hat{s}_N(\theta, t) - \beta^s_N \sigma_N(\theta, t))$. Only controls satisfying LCB thresholds ($\geq 1-\varepsilon$ for safety, $\geq 1-\xi$ for reset) are considered for selection.
- **Core assumption:** The safety and reset functions lie in the RKHS induced by the kernel (Assumption A4), and an initial non-empty safe set $S_0$ exists (Assumption A1).
- **Evidence anchors:**
  - [Section 4.3]: "We implement these constraints via lower confidence bounds (LCBs)... We then define the safe-resettable feasible set $\Gamma_N$..."
  - [Section 5, Theorem 5.1]: "All selected triples $(\theta_i, t_i, T_i)$ satisfy $s_\infty(\theta_i, T_i) \geq 1-\varepsilon$ and $r(\theta_i, T_i) \geq 1-\xi$"
  - [corpus]: Safe exploration in RKHS (arxiv 2503.10352) provides related confidence-bound mechanisms; direct evidence for joint dynamics+safety learning is limited in corpus.
- **Break condition:** If the kernel RKHS norm bounds ($\beta^s_N, \beta^r_N$) are severely underestimated, or if the initial safe set is mislabeled, safety guarantees may be violated.

### Mechanism 2
- **Claim:** Joint estimation of dynamics, safety, and reset models enables accurate prediction from trajectory data without prior knowledge of system dynamics.
- **Mechanism:** Three models are fit simultaneously using the same kernel structure: (1) state density $\hat{p}_\theta(t, x)$ via kernel density estimation, (2) safety probability $\hat{s}_N(\theta, t)$ by integrating density over safe region, (3) reset probability $\hat{r}_N(\theta, t)$ by integrating over reset region. All use kernel ridge regression with shared kernel and regularization $\lambda$.
- **Core assumption:** The density map $p: (\theta, t, x) \mapsto p_\theta(t, x)$ has Sobolev regularity $\nu > \frac{1}{2}\max(n, m+1)$ (Assumption A3).
- **Evidence anchors:**
  - [Section 4.2, Eq. 12-14]: "We fit kernel ridge regressors for the density, safety, and reset functions using a Matérn kernel"
  - [Section 5]: Estimation bounds scale with Sobolev regularity: $\|\hat{p}_\theta(t,\cdot) - p_\theta(t,\cdot)\|_\infty \leq c_3 \eta$
  - [corpus]: EigenSafe (arxiv 2509.17750) addresses stochastic safety filtering but assumes known dynamics; this paper jointly learns dynamics.
- **Break condition:** If Sobolev regularity is overestimated (true dynamics are less smooth than assumed), convergence rates degrade.

### Mechanism 3
- **Claim:** Iterative uncertainty-maximizing sampling achieves efficient coverage while respecting safety constraints.
- **Mechanism:** Selection rule: $(\theta_{N+1}, t_{N+1}, T_{N+1}) = \arg\max_{(\theta,t,T) \in \Gamma_N} \sigma_N(\theta, t)$. This prioritizes regions with highest model uncertainty, accelerating exploration. The feasible set $\Gamma_N$ expands as confidence improves, gradually covering more of control space.
- **Core assumption:** Sublinear information growth $\gamma_N \leq cN^\alpha$ (Assumption A5), which holds for Matérn kernels with $\alpha > (m+1)/(m+1+2\nu)$.
- **Evidence anchors:**
  - [Section 4.3, Eq. 18]: "We choose the next $(\theta_{N+1}, t_{N+1}, T_{N+1})$ by maximizing uncertainty over the feasible set"
  - [Section 6, Figure 4]: "Relaxing thresholds leads to broader control coverage and faster information gain"
  - [corpus]: Related to Safe Online Control-Informed Learning (arxiv 2512.13868) but differs in kernel-based vs. EKF-based uncertainty.
- **Break condition:** If safety thresholds ($\varepsilon, \xi$) are too strict, exploration may stall before covering useful control regions.

## Foundational Learning

- **Concept: Stochastic Differential Equations (SDEs)**
  - Why needed here: The system dynamics are modeled as controlled SDEs $dX(t) = b(X,u)dt + a(X,u)dW(t)$; understanding diffusion terms and Brownian motion is essential for interpreting safety as trajectory-level probability constraints.
  - Quick check question: Can you explain why safety is defined as $\mathbb{P}(g(X(t)) \geq 0)$ rather than a deterministic constraint?

- **Concept: Reproducing Kernel Hilbert Spaces (RKHS) and Matérn kernels**
  - Why needed here: All estimators (density, safety, reset) are formulated as kernel ridge regression in an RKHS; the Matérn kernel encodes Sobolev smoothness assumptions that determine convergence rates.
  - Quick check question: How does the Matérn kernel's smoothness parameter $\nu$ affect the confidence bound width?

- **Concept: Confidence bounds in bandits/optimization (UCB/LCB)**
  - Why needed here: The safe exploration mechanism extends Safe UCB methods, using lower confidence bounds to ensure constraints are satisfied with high probability.
  - Quick check question: Why does the method use *lower* confidence bounds for safety rather than upper confidence bounds?

## Architecture Onboarding

- **Component map:** DensityEstimator -> ProbabilityComputer -> KernelMapFitter -> SafeSampler -> StoppingMonitor

- **Critical path:** Initialize with $S_0, R_0$ → [Loop] Simulate $Q$ trajectories at $(\theta_N, t_N)$ → Estimate density and probabilities → Update kernel maps → Compute LCBs → Select next point → [Until uncertainty < η]

- **Design tradeoffs:**
  - **Safety vs. coverage:** Lower $\varepsilon, \xi$ = stricter safety, slower exploration. Table 1 shows MSE drops from 0.70 to 0.002 when thresholds relaxed from 0.1 to +∞.
  - **Samples per control ($Q$) vs. iterations ($N$):** Theorem 5.1 requires $Q \gtrsim N^{\frac{2\nu+n}{2\nu-n}}$. Higher $\nu$ (smoother dynamics) allows fewer samples.
  - **Kernel bandwidth $R$:** Balances bias-variance in density estimation; set $R = Q^{1/(n+2\nu)}$ per theory.

- **Failure signatures:**
  - **Stalled exploration:** $\Gamma_N$ stops expanding despite $\sigma_N > \eta$ → thresholds too strict or initial set too small
  - **Safety violations:** Trajectories leave safe region → $\beta^s_N, \beta^r_N$ underestimated or kernel mismatch
  - **Numerical instability:** $(K + N\lambda I)$ ill-conditioned → increase $\lambda$ or check kernel scale parameter $\gamma$

- **First 3 experiments:**
  1. **Sanity check on known dynamics:** Generate trajectories from a linear SDE with known $b, a$; verify $\hat{p}_\theta(t, x)$ matches ground-truth density via KL divergence.
  2. **Ablation on safety thresholds:** Run with $(\varepsilon, \xi) \in \{(0.1, 0.1), (0.3, 0.3), (0.5, 0.5)\}$; plot control coverage vs. actual violation rate (estimated by out-of-sample MC).
  3. **Scalability test:** Fix dimension $n=2$, vary control dimension $m \in \{1, 2, 4\}$; measure iterations to reach $\eta$-convergence and wall-clock time per iteration.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the confidence parameters $\beta^s_N$ and $\beta^r_N$ be adaptively estimated without requiring prior knowledge of the safety and reset functions' RKHS norms?
- Basis in paper: [explicit] Remark 1 states that developing adaptive strategies to estimate these quantities without prior knowledge is a "promising direction for future work," noting that conservative overestimation ensures safety but slows exploration.
- Why unresolved: The current theoretical guarantees rely on known upper bounds of RKHS norms, which may not be available in practical applications.
- What evidence would resolve it: An algorithm using online adaptation techniques (e.g., the doubling trick) with proofs showing safety is maintained without a priori norm bounds.

### Open Question 2
- Question: Can the size of the final certified safe set $\Gamma_N$ be formally characterized?
- Basis in paper: [explicit] The discussion following Theorem 5.1 notes, "Although we do not analyze the size of $\Gamma_N$... a formal characterization of $\Gamma_N$ is left to future work."
- Why unresolved: The paper proves that the learned set is safe and provides estimation rates, but it does not theoretically quantify the coverage of the safe set.
- What evidence would resolve it: Theoretical bounds relating the volume of $\Gamma_N$ to the number of iterations or the smoothness of the dynamics.

### Open Question 3
- Question: Can the methodology be extended to handle abrupt dynamics and non-diffusive disturbances, such as jump processes?
- Basis in paper: [explicit] Section 7 identifies "extensions to handle abrupt dynamics and non-diffusive disturbances such as jump processes arising in pedestrian–vehicle interactions" as a subject for further research.
- Why unresolved: The current theoretical framework is built upon Sobolev smoothness (Assumption A3) and standard Brownian motion, which do not apply to discontinuous jump processes.
- What evidence would resolve it: A derivation of new confidence bounds and learning rates that accommodate discontinuities in the trajectory data.

### Open Question 4
- Question: Does the Sobolev regularity of the drift and diffusion coefficients of the underlying SDE imply the Sobolev regularity of the resulting state densities?
- Basis in paper: [explicit] Section 3 states that while this link is expected from parabolic PDE theory, a "formal analysis of this connection is beyond the scope of the present work."
- Why unresolved: The method assumes the density $p$ lies in a Sobolev space (Assumption A3), but this is an assumption about the solution rather than the typically known model components.
- What evidence would resolve it: A theorem proving that specific smoothness conditions on the drift $b$ and diffusion $a$ guarantee the required Sobolev regularity of the density $p$.

## Limitations
- The method relies heavily on accurate kernel hyperparameter selection and assumes sufficient smoothness (Sobolev regularity ν) of the underlying dynamics
- Theoretical bounds depend on RKHS norm constraints that may be conservative in practice, potentially limiting exploration efficiency
- Experimental results focus primarily on safety performance rather than demonstrating accurate dynamics estimation compared to ground truth

## Confidence
- **Safety guarantees:** High confidence based on rigorous theoretical guarantees (Theorem 5.1) and experimental validation showing zero safety violations
- **Joint learning mechanism:** Medium confidence - sound theoretical framework but experimental focus on safety over dynamics accuracy
- **Uncertainty-maximizing sampling:** Medium-High confidence - empirically demonstrated expansion of safe control set, though efficiency characterization could be improved

## Next Checks
1. **Ground Truth Validation:** Implement the method on a controlled SDE with analytically known dynamics and quantitatively compare estimated density, safety, and reset probabilities against exact values using metrics like KL divergence and absolute error.

2. **Safety Guarantee Stress Test:** Systematically vary the safety thresholds (ε, ξ) and initial safe set size to identify breaking points where theoretical safety guarantees fail in practice, documenting the relationship between conservatism and exploration coverage.

3. **Smoothness Sensitivity Analysis:** Test the method across systems with varying Sobolev regularity (both higher and lower than assumed) to empirically validate the theoretical convergence rates and identify practical limits of the smoothness assumption.