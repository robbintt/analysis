---
ver: rpa2
title: 'Deconstructing Generative Diversity: An Information Bottleneck Analysis of
  Discrete Latent Generative Models'
arxiv_id: '2512.01831'
source_url: https://arxiv.org/abs/2512.01831
tags:
- diversity
- generative
- codebook
- latent
- subset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces an information-theoretic framework grounded\
  \ in the Information Bottleneck principle to analyze and compare generative diversity\
  \ across discrete latent models like autoregressive (AR), masked image models (MIM),\
  \ and diffusion models. The authors decompose diversity into path-level (Hpath)\
  \ and execution-level (Hexec) components, then apply three zero-shot inference-time\
  \ interventions\u2014Codebook Subset, Argmax (deterministic sampling), and Paraphrase\u2014\
  to isolate and measure these components."
---

# Deconstructing Generative Diversity: An Information Bottleneck Analysis of Discrete Latent Generative Models

## Quick Facts
- arXiv ID: 2512.01831
- Source URL: https://arxiv.org/abs/2512.01831
- Reference count: 40
- This paper introduces an information-theoretic framework grounded in the Information Bottleneck principle to analyze and compare generative diversity across discrete latent models like autoregressive (AR), masked image models (MIM), and diffusion models.

## Executive Summary
This paper presents a theoretical framework based on the Information Bottleneck principle to analyze and compare generative diversity in discrete latent generative models. The authors decompose diversity into path-level and execution-level components and apply three inference-time interventions—Codebook Subset, Argmax sampling, and Paraphrase aggregation—to isolate and measure these components. Through experiments on LlamaGen, aMUSEd, and VQ-Diffusion, they reveal three distinct diversity strategies: AR models are compression-prioritized with collapsed codebook usage, MIM models are diversity-prioritized with strong sensitivity to sampling, and diffusion models are decoupled with stable execution randomness. The study demonstrates that targeted codebook subsetting and mixed-length paraphrases can enhance diversity without retraining.

## Method Summary
The authors introduce an Information Bottleneck framework to decompose generative diversity into path-level (Hpath) and execution-level (Hexec) components for discrete latent generative models. They implement three zero-shot inference probes: Codebook Subset (restricting to top-k frequent tokens from validation set), Argmax (replacing stochastic sampling with deterministic argmax), and Paraphrase (aggregating outputs across semantically equivalent prompts). The framework is applied to three model families—autoregressive (LlamaGen), masked image models (aMUSEd), and diffusion (VQ-Diffusion)—using DALL-E 3 synthetic captions dataset for generation and MSCOCO2014 for quality evaluation. Diversity is measured using LPIPS, pixel cosine distance, and SSIM, while quality is assessed with CLIP Score, CLIP IQA, and FID.

## Key Results
- AR models (LlamaGen) are compression-prioritized with negligible Hpath and collapsed codebook usage
- MIM models (aMUSEd) are diversity-prioritized with high Hexec and strong sensitivity to sampling and codebook capacity
- Diffusion models (VQ-Diffusion) are decoupled, relying primarily on Hpath with stable, independent execution randomness
- Targeted codebook subsetting and mixed-length paraphrases can enhance diversity without retraining

## Why This Works (Mechanism)
The framework works by applying Information Bottleneck theory to decompose the mutual information between input prompts and generated outputs into two components: path-level diversity (Hpath), which captures the model's learned ability to generate diverse outputs from different inputs, and execution-level diversity (Hexec), which captures the variability introduced by stochastic sampling at inference time. By systematically varying inference-time parameters through the three probes, the authors can isolate and measure each component's contribution to overall diversity.

## Foundational Learning
- Information Bottleneck Principle: A framework for analyzing information compression and relevance in neural networks; needed to formalize diversity decomposition; quick check: verify mutual information calculations for discrete variables
- Discrete Latent Spaces: Vector Quantization (VQ) methods that map continuous features to discrete tokens; needed as the model architecture foundation; quick check: confirm codebook size and token usage statistics
- Entropy Decomposition: Mathematical technique to split total diversity into path and execution components; needed for the theoretical framework; quick check: validate Hpath + Hexec = Htotal
- CLIP Embedding Space: Contrastive language-image pre-trained representations; needed for quality metrics like CLIP Score and CLIP IQA; quick check: ensure embeddings are properly normalized
- LPIPS Metric: Learned perceptual image patch similarity; needed as primary diversity metric; quick check: verify pairwise computation across generated images

## Architecture Onboarding
Component Map: Input Prompt -> Model (AR/MIM/Diffusion) -> Discrete Latent Space (Codebook) -> Image Generation -> Output Images
Critical Path: Prompt → Model Sampling Strategy → Codebook Token Selection → Image Decoding → LPIPS/CLIP/FID Evaluation
Design Tradeoffs: The choice between AR (compression), MIM (diversity), and Diffusion (decoupling) represents fundamental tradeoffs between output consistency, variability, and inference stability
Failure Signatures: Codebook subsetting crashes if subset is too small; diversity metrics become unstable with insufficient sample count; quality metrics degrade if prompts are semantically inconsistent
First Experiments:
1. Verify codebook frequency computation and subsetting works without crashes
2. Confirm argmax sampling produces deterministic outputs matching the highest-probability tokens
3. Test paraphrase generation with GPT-4/5 produces semantically equivalent prompts

## Open Questions the Paper Calls Out
- Can the proposed Information Bottleneck framework and its decomposition into path ($H_{path}$) and execution ($H_{exec}$) diversity be rigorously applied to continuous latent generative models, which lack discrete codebooks?
- Does disabling the most frequent codebook tokens to increase diversity cause semantic drift or conceptual bleeding between classes?
- Is the proposed inference-time diversity enhancement strategy (mixed paraphrasing + disabling frequent tokens) robust across larger-scale foundational models, or is it specific to the tested architectures?

## Limitations
- Exact codebook subset ratio for main experiments is unspecified (only ablation tests multiple ratios)
- Number of generated images per prompt for diversity metric computation is not explicitly stated
- Validation set used for computing codebook usage frequencies lacks detailed specification
- Base prompts for DALL-E 3 caption subset filtering criteria are not detailed

## Confidence
High: Theoretical framework and information decomposition are well-defined and clearly presented
Medium: Empirical findings about relative diversity behaviors across model types are well-supported but exact quantitative comparisons may depend on unspecified implementation choices
Low to Medium: Practical utility of the three interventions depends on unspecified parameters and implementation details

## Next Checks
1. Reproduce the codebook subset probe with different subset ratios (e.g., 25%, 50%, 75% of codebook) to verify the reported inflection points and ensure results are not artifacts of specific subset choice
2. Verify the LPIPS diversity measurements by computing with both 4 and 8 generated images per prompt to check sensitivity to sample count
3. Implement the argmax and paraphrase probes and confirm they produce the expected shifts in Hpath and Hexec components relative to stochastic sampling