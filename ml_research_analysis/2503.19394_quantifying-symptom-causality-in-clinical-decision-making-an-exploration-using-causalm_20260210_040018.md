---
ver: rpa2
title: 'Quantifying Symptom Causality in Clinical Decision Making: An Exploration
  Using CausaLM'
arxiv_id: '2503.19394'
source_url: https://arxiv.org/abs/2503.19394
tags:
- causal
- concept
- text
- medical
- symptoms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the problem of quantifying the causal influence
  of symptoms on clinical diagnosis predictions, moving beyond correlation to provide
  a more robust and interpretable approach. The core method idea involves using the
  CausaLM framework to generate counterfactual text representations where a target
  symptom (e.g., "chest pain") is effectively "forgotten," allowing for the estimation
  of its causal effect on model predictions.
---

# Quantifying Symptom Causality in Clinical Decision Making: An Exploration Using CausaLM

## Quick Facts
- arXiv ID: 2503.19394
- Source URL: https://arxiv.org/abs/2503.19394
- Reference count: 7
- This work addresses the problem of quantifying the causal influence of symptoms on clinical diagnosis predictions, moving beyond correlation to provide a more robust and interpretable approach.

## Executive Summary
This paper presents a novel approach to quantifying causal relationships between symptoms and disease diagnoses in clinical decision support systems. The authors propose using the CausaLM framework to generate counterfactual text representations where target symptoms are "forgotten," enabling principled estimation of causal effects through Textual Representation-based Average Treatment Effect (TReATE). By comparing disease probability distributions between factual and counterfactual representations, the method provides deeper insights into model decision-making beyond simple correlations. The approach is demonstrated on the DDXPlus dataset, showing significant causal effects for symptom-disease pairs like chest pain with Bronchitis and Anemia.

## Method Summary
The study uses an adversarial training approach where BERT is augmented with a Treatment Concept (TC) classification head and gradient reversal layer (λ=6). This forces the model to "forget" target symptoms while maintaining language modeling capabilities. The resulting counterfactual representations are used to compute TReATE by measuring shifts in disease probability distributions compared to standard BERT outputs. Disease predictions are made using a linear classifier with sparsemax activation to better match the sparse nature of clinical diagnoses. The method is evaluated on 15K test samples from the DDXPlus dataset, focusing on the causal influence of "chest pain" on various diseases.

## Key Results
- TReATE successfully captures causal influence of symptoms on disease predictions
- Significant probability distribution shifts observed for diseases like Bronchitis and Anemia when "chest pain" is considered
- Sparsemax activation produces clinically realistic sparse disease distributions
- TReATE identifies different symptom-disease relationships compared to correlation-only analysis (CONEXP)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Adversarial gradient reversal induces representation-level "forgetting" of target symptoms while preserving language modeling capability.
- **Mechanism:** A Treatment Concept (TC) classification head is added to BERT with a gradient reversal layer. During training, gradients from the TC loss are reversed by factor λ (found stable at 6), forcing the base model to maximize TC classification error while minimizing MLM and NSP losses. This creates representations agnostic to the treatment concept.
- **Core assumption:** If a model cannot classify concept presence yet maintains language modeling performance, its representations have effectively "forgotten" that concept, enabling counterfactual inference.
- **Evidence anchors:**
  - [abstract] "counterfactual text representations in which target concepts are effectively 'forgotten,' enabling a principled estimation of the causal effect"
  - [section 3.2] "We then added a gradient reversal layer between the TC head and the rest of the model to reverse the gradients of the loss for the TC classification task by a factor λ"
  - [corpus] No direct corpus support for this specific adversarial mechanism in clinical contexts; validation remains internal to this work.
- **Break condition:** If TC classification loss drops significantly (model learns to detect the concept), the counterfactual representation is compromised and causal claims weaken.

### Mechanism 2
- **Claim:** TReATE quantifies causal influence by measuring expected probability distribution shift between factual and counterfactual representations.
- **Mechanism:** TReATE computes the difference between expected disease distributions under original representations φ(X) and treatment-agnostic representations φ_Cj,Cm(X). For each disease, this yields a scalar representing how much the symptom's presence causally shifts prediction probability.
- **Core assumption:** The intervention (representation manipulation) approximates a true counterfactual where the symptom is genuinely absent, not merely obscured.
- **Evidence anchors:**
  - [abstract] "Textual Representation-based Average Treatment Effect (TReATE) to measure the shift in disease probability distribution"
  - [section 4.3] Full TReATE formula provided: TReATE = ⟨E[z(f(φ(X)))] - E[z(f(φ_Cj,Cm(X)))]⟩
  - [corpus] Related work (SimSUM) addresses linking unstructured clinical text to structured records, but does not validate TReATE specifically.
- **Break condition:** If multiple symptoms co-occur confoundingly, isolating single-symptom causal effects becomes unreliable without control concepts.

### Mechanism 3
- **Claim:** Sparsemax activation produces clinically realistic sparse disease distributions, improving causal effect estimation.
- **Mechanism:** Unlike softmax (which assigns non-zero probability to all classes), sparsemax assigns exactly zero probability to unlikely diseases, concentrating probability mass on a few plausible diagnoses—matching the observed data distribution where most cases have concentrated diagnoses.
- **Core assumption:** Clinical diagnosis is inherently sparse; forcing non-zero probabilities on all diseases dilutes causal signal.
- **Evidence anchors:**
  - [section 4.2] "The disease probability was highly sparse. It was concentrated on only a few out of the 49 possible diseases."
  - [section 4.2] Loss comparison: softmax (0.14→0.09) vs sparsemax (0.18→0.11), indicating sparsemax better captures distribution shape.
  - [corpus] Weak external validation; Sparsemax for clinical NLP remains underexplored in neighboring literature.
- **Break condition:** If true disease distribution is less sparse than assumed, sparsemax may prematurely eliminate viable diagnostic candidates.

## Foundational Learning

- **Concept: Gradient Reversal Layer (Domain-Adversarial Training)**
  - **Why needed here:** Core mechanism for inducing concept-agnostic representations without manual counterfactual text generation.
  - **Quick check question:** Can you explain why reversing gradients maximizes classification loss while the optimizer minimizes total loss?

- **Concept: Average Treatment Effect (ATE) in Causal Inference**
  - **Why needed here:** TReATE adapts ATE to textual representations; understanding counterfactual frameworks is prerequisite.
  - **Quick check question:** What is the difference between correlation (CONEXP) and causal effect (TReATE) in this context?

- **Concept: Sparsemax Activation**
  - **Why needed here:** Replaces softmax to match sparse clinical diagnosis distributions.
  - **Quick check question:** Why does sparsemax produce exact zeros while softmax does not?

## Architecture Onboarding

- **Component map:**
  Raw clinical notes (JSON) → Dialogue preprocessing → Tokenization → BERT-TC (adversarial training with TC head + gradient reversal, λ=6) → Frozen BERT-TC embeddings → BERT-CF (linear layer + sparsemax) → Disease probability distribution → TReATE computation (compare vs. standard BERT)

- **Critical path:**
  1. Preprocess DDXPlus JSON to dialogue format; annotate concept presence (e.g., "chest pain" via keyword matching).
  2. Train BERT-TC: monitor that TC loss stays high (~0.53) while MLM/NSP loss drops (9.4→0.117).
  3. Freeze BERT-TC, train linear classifier with sparsemax for disease prediction.
  4. Compute TReATE by comparing BERT-CF outputs against baseline BERT outputs.

- **Design tradeoffs:**
  - **λ value (6):** Higher λ strengthens forgetting but risks degrading representations; requires empirical tuning.
  - **Sparsemax vs. Softmax:** Sparsemax matches data sparsity but may over-prune candidates; validate against gold standard.
  - **Training sample size (65K of 1M+):** Subsampling for computational efficiency; may underrepresent rare diseases.

- **Failure signatures:**
  - TC classification loss dropping toward 0 → model learned to detect the concept; counterfactual invalid.
  - BERT-CF loss approaching 0 → distribution too similar to gold standard; treatment concept may not have been "forgotten."
  - TReATE values near 0 for clinically relevant symptom-disease pairs → potential issue with concept annotation or training.

- **First 3 experiments:**
  1. **Sanity check:** Train BERT-TC with λ=0 (no reversal); verify TC loss drops, confirming classification head works.
  2. **λ sensitivity:** Test λ ∈ {2, 4, 6, 8, 10}; monitor TC loss stability and MLM/NSP degradation to find optimal range.
  3. **Baseline comparison:** Compute CONEXP alongside TReATE for the same test set; verify TReATE identifies causal relationships (e.g., Bronchitis, Anemia) that differ meaningfully from correlation-only signals.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the CausaLM framework effectively handle multiple treatment concepts simultaneously while controlling for confounding variables?
- Basis in paper: [explicit] "Future work could address these challenges by exploring multiple treatment concepts simultaneously, controlling for sets of confounding variables, and further refining representation learning strategies."
- Why unresolved: The current study only examines a single symptom ("chest pain") in isolation, which oversimplifies clinical reality where patients present multiple co-occurring symptoms.
- What evidence would resolve it: Experiments extending the framework to model multiple symptoms as simultaneous treatment concepts, with results showing valid causal estimates that match clinical expectations.

### Open Question 2
- Question: Does imperfect "forgetting" during adversarial training compromise the validity of causal claims?
- Basis in paper: [explicit] "The causal interpretation hinges on the fidelity of the adversarial training process. Imperfect 'forgetting' or partial suppression of the target concept may affect the strength of causal claims."
- Why unresolved: The TC classification loss decreased from 0.627 to 0.53, suggesting incomplete concept suppression, but the implications for causal validity remain unquantified.
- What evidence would resolve it: Systematic analysis correlating degree of concept suppression (measured by TC head performance) with the stability and accuracy of TReATE estimates against known ground-truth causal relationships.

### Open Question 3
- Question: Would richer counterfactual interventions at the text level yield different causal inferences than representation-level manipulations?
- Basis in paper: [explicit] "considering richer counterfactual interventions (e.g., subtle text modifications rather than just representation-level manipulations) might yield more realistic causal inferences."
- Why unresolved: The current approach manipulates text representations rather than generating actual counterfactual text, potentially missing nuances in how symptom descriptions influence diagnoses.
- What evidence would resolve it: Comparative study measuring TReATE using text-level counterfactuals versus representation-level counterfactuals, with analysis of divergent cases and alignment with clinician judgments.

### Open Question 4
- Question: How robust are the causal findings across diverse clinical corpora and multilingual medical texts?
- Basis in paper: [explicit] "Beyond the current dataset, testing our approach on diverse clinical corpora would help validate its robustness and generalizability. Furthermore, extending causal analysis methods to multilingual and cross-cultural medical texts could provide insights into how language, culture, and medical practice patterns influence diagnostic reasoning worldwide."
- Why unresolved: Only the DDXPlus dataset was used, limiting understanding of how well the approach transfers to different clinical contexts, languages, and healthcare systems.
- What evidence would resolve it: Replication studies across multiple clinical datasets from different institutions and countries, including multilingual corpora, demonstrating consistent TReATE patterns for medically established symptom-disease relationships.

## Limitations

- The causal claims depend on successful "forgetting" of target symptoms via gradient reversal, but no ablation study demonstrates TC loss stability throughout training.
- The study focuses exclusively on "chest pain" as the treatment concept, limiting generalizability to other symptoms or multi-symptom interactions.
- Binary keyword-based concept annotation ("chest pain" via "chest"/"sternum") is simplistic and may miss nuanced symptom descriptions in clinical language.

## Confidence

- **High Confidence:** The TReATE framework's mathematical formulation and implementation details are clearly specified and internally consistent. The method correctly adapts ATE to textual representations.
- **Medium Confidence:** The claim that TReATE successfully captures causal influence is supported by internal results showing significant shifts for Bronchitis and Anemia, but lacks external validation or comparison with clinical gold standards.
- **Low Confidence:** The assertion that CausaLM provides "deeper insights into model decision-making" for clinical applications is premature without user studies or downstream validation showing improved clinical outcomes.

## Next Checks

1. **Ablation Study on Gradient Reversal:** Conduct experiments with varying λ values (including λ=0 for baseline) and monitor TC classification loss throughout training. Demonstrate that TC loss remains stable (~0.5-0.6) while MLM/NSP loss drops, validating the "forgetting" mechanism.

2. **Multi-Symptom Causal Analysis:** Extend the analysis beyond single symptoms to examine causal interactions between multiple symptoms (e.g., "chest pain" + "shortness of breath"). This would test the method's ability to handle realistic clinical scenarios where symptoms co-occur.

3. **Clinical Expert Validation:** Partner with clinical experts to review TReATE-identified causal relationships against their diagnostic reasoning. Compare TReATE's top causal symptom-disease pairs with expert-identified critical symptoms for each disease to assess clinical plausibility and utility.